thompson sample TS heuristic  bandit randomize algorithm bayesian recently generate significant demonstrate favorable empirical performance article novel almost tight martingale regret analysis thompson sample technique simultaneously yield dependent independent bound optimal independent bound NT lnt regret optimal dependent bound lnt regret bound proven technique conceptually easily extends distribution beta distribution TS algorithm version TS gaussian prior  bound NT regret optimality bound bound bound performance version thompson sample away bound NT  bandit CCS concept theory computation theory algorithm application domain machine theory reinforcement sequential decision additional multi bandit introduction  bandit mab model exploration exploitation tradeoff inherent sequential decision version generalization mab literature article version stochastic  bandit algorithm available stochastic mab popular upper confidence bound UCB algorithm lai robbins recently     theoretical guarantee algorithm  optimal strategy bayesian prior geometric discount reward stochastic mab thompson propose randomize bayesian algorithm minimize regret assume prior distribution parameter reward distribution accord posterior probability algorithm thompson sample TS member randomize probability algorithm TS algorithm  independently context reinforcement    braun recently TS attract considerable attention  scott   empirically demonstrate efficacy TS despite easy implement competitive TS lack theoretical analysis recently  weak guarantee namely bound regret timeT significant progress agrawal goyal agrawal goyal logarithmic bound regret TS proven bound asymptotic bound lai robbins however bound dependent regret bound logarithmic horizon parameter namely reward difference assume constant independent bound imply optimal obtain independent bound bound NT  article regret analysis TS optimal dependent optimal independent regret bound novel martingale analysis technique conceptually arguably simpler previous technique easily extends distribution beta distribution extends contextual bandit stochastic  bandit TS formally stochastic  bandit stochastic  bandit slot machine chosen played played yield random reward accord fix unknown distribution associate random reward obtain repeatedly independent reward immediately algorithm stochastic mab outcome  denote unknown reward  popular goal algorithm stochastic mab maximize reward timeT played expectation random choice algorithm equivalent regret amount lose optimal formally define regret introduce notation maxi denote played random variable regret define notion regret article denote regret mab instance fully specify journal acm vol article publication date september optimal regret bound thompson sample distribution fix instance fix reward distribution therefore dependent bound regret bound instance possibly distribution parameter associate independent bound bound regret function max maximization mab instance notion regret classic UCB algorithm  bandit lai robbins therefore bound directly comparable available UCB dependent regret bound NT independent regret bound UCB related notion regret recent TS  liu russo van roy bayesian regret bayesian regret regret prior instance terminology earlier bayesian regret define  prior reward distribution clearly weaker notion regret independent regret bound regret implies bound bayesian regret prior vice versa however prior accommodate context complex information structure bayesian regret bound complex setting incomparable regret bound thompson sample mention TS algorithm stochastic mab TS assume prior distribution underlie parameter reward distribution accord posterior probability TS specific algorithm due thompson article TS generally refer algorithm structure algorithm thompson structure TS involves description TS closely  parameter assume prior distribution parameter observation consist reward played assume likelihood function probability reward parameter posterior distribution likelihood function notation denotes probability density function probability function discrete random variable TS maintains posterior distribution underlie parameter reward TS accord posterior probability posterior probability achieve sample posterior distribution sample version TS beta prior bernoulli likelihood function gaussian prior gaussian likelihood journal acm vol article publication date september agrawal goyal emphasize beta prior bernoulli likelihood model gaussian prior gaussian likelihood model reward later thompson sample algorithm analysis algorithm allows model completely unrelated actual reward distribution assumption actual reward distribution mention namely reward generate upon description TS beta prior bernoulli likelihood simplicity description algorithm bernoulli bandit reward explain later algorithm analysis extend distribution reward thompson sample beta prior bernoulli likelihood bernoulli bandit reward likelihood reward probability beta prior convenient bernoulli reward prior beta distribution bernoulli trial posterior distribution simply beta beta trial failure respectively TS assumes prior beta beta uniform distribution informally choice capture knowledge reward failure reward algorithm update distribution beta algorithm generates independent sample posterior distribution  sample algorithm thompson sample beta prior foreach sample beta distribution arg maxi reward detail TS beta prior bernoulli bandit extension algorithm reward distribution described agrawal goyal extension reward toss coin bias outcome update beta distribution earlier easy regret bound algorithm extension thompson sample gaussian prior likelihood denote denote played denote reward define μˆi μˆi derive TS gaussian prior assume likelihood reward parameter pdf gaussian distribution assume prior μˆi played reward easy compute posterior distribution gaussian distribution μˆi TS gaussian prior generate independent sample distribution μˆi maximum played journal acm vol article publication date september optimal regret bound thompson sample algorithm thompson sample gaussian prior μˆi foreach sample independently μˆi distribution arg maxi reward μˆi μˆi article bound finite regret TS henceforth assume unique optimal arg maxi assume optimal convenience analysis algorithm assumption assumption unique optimal without loss generality decrease regret detail argument agrawal goyal theorem fix stochastic bandit satisfy assumption previous thompson sample beta prior regret lnt notation assumes constant theorem stochastic bandit thompson sample beta prior regret NT lnt notation hide absolute constant theorem stochastic bandit thompson sample gaussian prior regret NT notation hide absolute constant theorem exists instance stochastic bandit thompson sample gaussian prior regret NT hide absolute constant related contrast bound previous dependent regret bound regret bound parameter lai robbins essentially asymptotic bound lnt algorithm algorithm asymptotically achieve guarantee UCB algorithm achieves finite regret journal acm vol article publication date september agrawal goyal bound lnt recently bayes UCB algorithm   UCB algorithm achieve bound lai robbins regret bound theorem achieves bound lai robbins upper bound TS theorem TS beta distribution TS gaussian distribution achieve independent regret bound ofO NT lnt ando NT respectively analysis TS NT independent bound   bianchi stochastic mab within logarithmic factor dependent bound derive independent bound however previous TS imply suboptimal independent bound agrawal goyal imply independent bound additive dependent explicitly calculate derive imply independent bound preliminary examination suggests involve exist algorithm  bound regret UCB NT lnt   bianchi regret bound ofO NT TS gaussian prior improvement bound UCB recently   algorithm moss inspire UCB regret NT NT independent bound  bandit however algorithm horizon unclear NT regret achieve algorithm horizon interestingly theorem  TS gaussian prior bound NT regret bound TS differs bound conduct understand theoretical thompson sample public domain agrawal goyal conference version mention TS exponential distribution  spectral bandit agrawal goyal russo van roy contextual bandit reinforcement PROOFS upper BOUNDS theorem proof theorem diverge analysis proof outline proof martingale analysis essentially execution precede probability suboptimal bound linear function probability optimal proven lemma core analysis coefficient linear function decrease exponentially optimal lemma allows bound suboptimal bound regret difference analysis obtain logarithmic dependent bound theorem independent bound theorem theorem technical proof recall definition introduce earlier introduce journal acm vol article publication date september optimal regret bound thompson sample definition beta denotes cdf denotes probability function binomial distribution parameter beta denotes cdf beta distribution parameter definition quantity μˆi denotes played denotes denotes bernoulli bandit reward finally empirical μˆi define μˆi reward μˆi bernoulli bandit μˆi definition quantity denotes sample generate independently posterior distribution algorithm generate posterior distribution beta algorithm generate posterior distribution μˆi definition quantity threshold specific choice threshold dependent bound independent bound described appropriate proof definition μˆi intuitively estimate μˆi sample respectively later probability definition define sequence denotes played denotes reward define definition FT definition quantity define bernoulli reward μˆi distribution definition define probability random variable explicitly dependence notation brevity lemma thompson sample independent prior beta gaussian lemma instantiation journal acm vol article publication date september agrawal goyal proof recall instantiation assume otherwise probability inequality trivially suffices observation therefore therefore equality hence  distribution independent similarly combine previous inequality equation upper bound regret theorem proof theorem decompose suboptimal bound previous apply lemma algebraic manipulation conditional expectation journal acm vol article publication date september optimal regret bound thompson sample equality fix denote played kth distribution observation decompose previous lemma bound sum lemma denote kth trial happens proof proof inequality careful numerical estimate appendix substitute bound lemma equation obtain bound equation lemma bound remain equation increase probability violate decrease exponentially precisely lemma lemma function positive domain exist absolute constant domain journal acm vol article publication date september agrawal goyal proof denote kth trial happens recall define μˆi summand previous inequality fix random variable distribution μˆi depends μˆi latter simply average outcome bernoulli trial chernoff hoeffding bound obtain μˆi substitute μˆi exp inequality lemma lnt proof decompose probability previous decomposition bound bound trivially remains bound bound demonstrate satisfied probability violate recall define μˆi journal acm vol article publication date september optimal regret bound thompson sample μˆi equality previously definition μˆi therefore beta μˆi μˆi distribute random variable beta random variable stochastically dominate beta therefore μˆi distribution stochastically dominate beta therefore instantiation μˆi beta along chernoff hoeffding bound obtain fix beta lnt substitute instantiation μˆi instantiation indicator μˆi equation sum bound equation proof lemma substitute lemma lemma lemma equation obtain obtain dependent bound theorem lnt lnt algebraic manipulation equality obtain threshold obtain bound KL divergence  inspire   journal acm vol article publication date september agrawal goyal hiding function   substitute equation lnt lnt previously hide dependence   regret bound  lnt lnt previously hide   addition absolute constant completes proof theorem proof theorem proof theo NT lnt independent bound theorem basically proof theorem choice  inequality lnt lnt substitute bound equation lnt lnt lnt lnt therefore lnt regret bound  lnt lnt regret bound NT lnt regret bound NT lnt proof theorem journal acm vol article publication date september optimal regret bound thompson sample proof theorem regret analysis TS gaussian prior essentially analysis version beta prior lemma lemma bound equation obtain bound derivation lemma independent prior therefore derivation equation gaussian prior lemma correspond lemma lemma denote proof definition recall denotes probability exceed algorithm gaussian prior distribution μˆi fτj denote distribute gaussian random variable  geometric random variable denote consecutive independent trial sample becomes fτj fτj bound constant integer  random variable  denote maximum independent sample abbreviate    fτj  fτj  bound derive gaussian standard deviation formula   journal acm vol article publication date september agrawal goyal instantiation fτj fτj gaussian distribute  fτj fτj   therefore  fτj fτj substitute equation apply chernoff hoeffding bound bound probability recall definition chernoff bound adjust simply average observation instead sum observation definition therefore substitute prof constant bound journal acm vol article publication date september optimal regret bound thompson sample derive tighter bound distribute random variable therefore upper bound obtain instantiation fτj fτj fτj fτj TΔ define instantiation fτj fτj fτj earlier fτj fτj TΔ notation random variable fτj fτj    chernoff hoeffding bound TΔ  TΔ substitute TΔ substitute bound lemma equation obtain bound equation lemma proof lemma easily adapt gaussian prior lemma therefore  inequality journal acm vol article publication date september agrawal goyal lemma correspond lemma lemma lemma proof proof lemma proof lemma decompose summand previous decomposition bound bound trivially remains bound satisfied probability violate recall define μˆi μˆi μˆi distribute gaussian random variable distribute gaussian random variable variance stochastically dominate distribute therefore μˆi distribution stochastically dominate μˆi μˆi slightly abuse notation readability probability random variable distribute concentration gaussian distribution obtain fix journal acm vol article publication date september optimal regret bound thompson sample substitute μˆi TΔ sum bound equation proof lemma substitute bound lemma equation TΔ TΔ regret due upper bound  aforementioned decrease therefore regret bound regret bound NT bound regret NT NT assume prof theorem proof lower bound theorem construct instance TS regret NT played reward reward distribution distribution μˆi μˆi reward played played regret outcome define earlier μˆi define NT fix constantc specify later regret NT therefore assume otherwise regret NT NT instantiation probability suboptimal constant regret TΔ NT constant probability suboptimal gaussian therefore symmetry gaussian distribution journal acm vol article publication date september agrawal goyal instantiation independent gaussian distribute random variable variance therefore  inequality gaussian random variable instantiation NT previous inequality minimize NT substitute constant appropriately notation random variable  summarize probability suboptimal satisfies constant therefore regret  NT prof theorem conclusion article optimal dependent regret bound thompson sample stochastic mab bernoulli optimal dependent independent regret bound mab bound reward specifically technique yield independent regret upper bound NT lnt version TS beta prior upper bound NT version TS gaussian prior along bound availability  bound gaussian distribution derive tight upper bound version TS gaussian prior bound exist TS beta prior addition optimal regret bound important contribution article proof technique easily adapt optimal optimal dependent independent bound handle prior distribution technique adapt thompson sample regret bound contextual bandit subsequent journal acm vol article publication date september optimal regret bound thompson sample appendix   chernoff hoeffding bound independent necessarily exp exp chernoff hoeffding bound  random variable beta positive integer formula   derive concentration gaussian distribute random variable gaussian distribute random variable variance thompson sampling beta distribution proof lemma denote journal acm vol article publication date september agrawal goyal derivation abbreviate ryj ryj sum sum partial sum sum sum sum sum aforementioned estimate bound bound cdf binomial distribution  proposition journal acm vol article publication date september optimal regret bound thompson sample bound sum bound sum bound expression RHS ryj ryj ryj ryj ryj ryj inequality ryj ryj therefore substitute journal acm vol article publication date september agrawal goyal substitute equation sum bound sum sum ryj ryj inequality bound sum therefore bound  equation observation derive sum inequality chernoff hoeffding bound bound sum  bound journal acm vol article publication date september optimal regret bound thompson sample inequality sum combine