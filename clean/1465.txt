novel approach program repair sequence sequence devise implement evaluate technique sequencer fix bug sequence sequence source code approach mechanism overcome unlimited vocabulary occurs code data driven sample carefully curated commits source repository evaluate sequencer independent bug fix defectsj benchmark program repair research sequencer perfectly predict fix sample patch bug defectsj benchmark sequencer capture repair operator without domain specific introduction machine capable computer program machine software fiction machine modify exist program fix bug within software technology automate program repair program repair research active dominate technique static analysis  dynamic analysis CapGen progress achieve automate program repair limited fix mostly patch technique heavily intelligent domain specific knowledge bug fix specific application domain focus patch aim program repair agnostic generic manner fully rely machine capture syntax grammar compilable program approach aim foundation program repair machine program repair community benefit training bug datasets continued improvement machine algorithm library foundation model apply sequence sequence program repair sequence sequence statistical machine mostly machine translation algorithm learns translate text french another swedish generalize amount french swedish training data amount text already translate  BC technique explicit translate sequence another sequence program translate sequence program token buggy program sequence program token fix program training data readily available commits source code repository challenge overcome sequence sequence code raw unfiltered data noisy deploy significant effort identify curate commits focus task contrary misuse rare identifier etc fatal program error tolerable intelligence reader program compiler interpreter strict dependency refers within couple program dependency longer variable declare dozen tip address challenge sequence sequence maturity conceptually implementation fed sequence characteristic significantly recent progress various model source code approach sequence program repair repair bug source project java program program repair approach sequencer focus fix predict fix version buggy program carefully curated training dataset commits devise sequence sequence network architecture specifically address aforementioned challenge address unlimited vocabulary mechanism allows sequencer predict fix fix contains token rare api rare identifier vocabulary mechanism fix token training address dependency construct abstract buggy context buggy capture important context around buggy source code reduces complexity input sequence enables capture dependency fix evaluate sequencer compute accuracy commits curated source project accuracy ability predict fix exactly originally craft developer input buggy file buggy golden configuration perfectly predict fix percent sample baseline future research apply sequencer mainstream evaluation benchmark program repair defectsj bug defectsj replacement repair sequencer generates patch pas suite bug patch semantically equivalent generate patch bug knowledge report sequence sequence program repair validation overall novelty unique dataset evaluate technique program repair report mechanism seq seq source code buggy input dataset sequencer patch percent sample closest related sum contribution approach fix bug sequence sequence token sequence approach mechanism overcome unlimited vocabulary source code construction abstract buggy context leverage code context patch generation input program token sequence capture dependency fix implement approach publicly available program repair sequencer evaluate approach bug fix task contrary closest related assume bug golden model perfectly fix sample knowledge report task evaluate approach bug defectsj widely benchmark evaluate program repair contribution sequencer patch bug compile successfully plausible pas suite semantically equivalent patch developer qualitative analysis repair operator capture sequence sequence training dataset background neural machine translation sequence sequence sequencer buggy code input fix code output concept neural machine translation input sequence output sequence another brief introduction neural machine translation NMT neural machine translation dominant technique sequence sequence sequence refers sequence sequence sequence network recurrent neural network token generate output sequence input token denote input token eos token output token denote training output token fed network generation token equation hidden recurrent neural network  matrix computes input affect hidden  matrix related recurrence previous hidden affect hidden  matrix predict token output hidden supervise propagation   SourceRight click MathML additional feature  sequence sequence model  sequence sequence model softmax function probability likely token vocabulary matrix capture processing input sequence hidden eos encodes likely initial token output subsequent matrix predict likely token input precede token output matrix dependency input sequence generation described token training available output chicago  rare training vocabulary output successful approach overcome vocabulary mechanism intuition approach rare available vocabulary unknown refer unk directly input output translate relatively successful translate token easily task translate english chicago french assume token vocabulary chicago NMT model output  est unk mechanism model automatically replace unknown token token input chicago mechanism particularly relevant source code vocabulary corpus developer constrain vocabulary english define variable extremely vocabulary rare token infrequently specific context mechanism apply source code allows generate rare vocabulary identifier numeric somewhere input furthermore recipient context cope automatically translate program compiler semantic inference generation code predict num generate int discus mathematics mechanism context sequencer reader interested detail refer propose NMT goal bug fix patch translate entire buggy correspond fix translation author perform code abstraction transforms source code abstract version contains java keywords identifier frequent identifier literal selection idiom typify IDs var replace identifier literal code highlight difference improvement introduce sequencer another approach address vocabulary code byte encode BPE widely nlp apply source code sequencer preliminary BPE unlimited vocabulary effective mechanism approach seq seq repair sequencer sequence sequence model aim automatically fix bug generate patch bug fix replace buggy fix deletion token generation research desire sequencer combine lightweight kali deletion addition spectrum fault localization related effective addition patch percent bug defectsj fix replace exist source code software faulty behavior fail fault localization technique identify buggy suspicious buggy technique predict buggy candidate percent sequencer performs novel buggy context abstraction intelligently organizes fault localization data buggy representation concise suitable model preserve valuable information regard context bug predict fix representation fed sequence sequence model performs patch inference capable generate multiple code potential patch bug finally sequencer patch preparation generates concrete patch format code replace suspicious propose aforementioned training phase inference phase remainder discus specific training inference overview approach sequence sequence program repair definition buggy suite assume fault localization technique FL identifies potential bug location location consists buggy bci buggy bmi buggy bli loc loc FL bci bmi bli  bmi bci sourcethe predict generate fix fli bug location replace bli fli bmi suite bug fix sequencer tackle input fault localization data buggy attempt generate fix fli bci bmi bli fli notation throughout buggy context abstraction context bug fundamental role understand faulty behavior fix bug fix activity developer usually identify buggy analyze interact execution context variable fix possibly token context fix sequencer mimic construct abstract buggy context organize fault localization data representation concise retains context allows model predict fix sequencer balance contrast goal reduce buggy context reasonably concise sequence token sequence sequence model suffer retain information model context predict fix bug location bci bmi bli sequencer performs buggy bug insert token buggy bli bug insert token rationale propagate information extract fault localization technique model buggy mimic developer focus buggy bug fix activity buggy remainder buggy bmi representation rationale crucial information buggy interaction buggy buggy bci instance variable  along signature constructor non buggy buggy non  strip rationale choice model variable signature potential source building fix fli sequencer performs tokenization truncation abstract buggy context truncation limit abstract buggy context predetermine input sequence allows sequencer input file arbitrary without memory truncation summarize truncation chosen input file truncation buggy truncation limit token limit otherwise buggy abstract buggy context twice token truncation limit token token file buggy token bug bug token file abstract buggy context consist token buggy token buggy token buggy generally truncation delete actual definition input context buggy preserve aid patch generation abstract buggy context input sequence sequence network predict fix internally abstract buggy context sequence token belonging vocabulary vocabulary token token replace unknown token unk empirically derive vocabulary explain mechanism overcome unknown token output listing display buggy buggy context abstraction listing illustrates token vocabulary replace unknown token unk program token int replace unk vocabulary vocabulary token variable sequence sequence network receives listing input illustration abstract buggy context sequencer highlight highlight orange highlight sequence sequence network phase sequencer generate fix bug specifically sequence sequence network encoder decoder model attention mechanism translate abstract buggy context bug correspond target fix network rely dataset bug fix source explain bug fix training data evaluate sequence sequence network described model model sequence sequence java source code patch basis model recurrent neural network processing architecture training source token sequence abstract buggy context encoder token abstract buggy context decoder target sequence fix token fix propagation update parameter network stochastic gradient decent training parameter unchanged inference patch generation sequence sequence model sequencer patch preparation mechanism encoder encoder recurrent neural network lstm gate input bidirectional encoder allows encode token incorporate information token input data encoder convert source sequence sequence encoder hidden learnable recurrence function reading token hidden  context vector initialize decoder hei hei source decoder decoder recurrent neural network lstm gate initialize encoder production patch candidate token input previous output token decoder update hidden  learnable recurrence function   source initial learnable bridge function encoder decoder  token generation attention mechanism equation decoder generate token token generate model sequence token attention addition attention mechanism specific context vector output token decoder linear combination hidden encoder hei  sourcewhere  learnable attention context vector learnable function output token attention encoder hidden predict token vocabulary PV  source intuition mechanism operates patch generation mechanism significantly improve performance model token token abstract buggy context token training vocabulary empirically improvement approach vanilla sequence sequence model without mechanism mechanism contributes equation token candidate component calculates pgen probability decoder generates token initial vocabulary pgen probability token input token attention vector equation pgen  source  pgen   equation learnable function equation output token decoder token token training vocabulary unk token token abstract buggy context although unk target training patch PV computation uncertain token likelihood unk pgen unk token mechanism replace output discard patch inference sequence sequence network generate patch project outside training dataset patch inference generate abstract buggy context bug described beam generate multiple likely patch buggy related beam sequence decoder successor compute ranked cumulative probability sequence decoder width beam beam infinite corresponds breath listing prediction beam bug listing prediction model potential bug fix patch preparation described patch preparation raw output sequence sequence network cannot patch directly patch raw output prediction unk token handle mechanism listing illustrates token mechanism replaces unk sample mechanism replace token sample listing prediction token source code dot separator correspond identifier consequently patch preparation discard prediction unk reformulate remain prediction source code remove listing  adjust prediction listing remove contains unk token prediction candidate program replace buggy bli bug bug token replace model output formally remain candidate fix    replace buggy bli buggy generate candidate patch   verify patch validation technique suite validation suite weak specify bug patch   bug location suite correctness verify manual inspection implementation detail parameter setting library implement encoder decoder model  built python program pytorch neural network platform vocabulary vocabulary token knowledge vocabulary machine patch generation comparison  vocabulary vocabulary limit truncation truncate abstract buggy context longer token motivate abstract buggy context token sequencer  buggy remove statement definition definition abstract buggy context token network parameter explore variety setting network topology sequencer decision verify ablation variable detailed model batch iteration prevent overfitting dropout relation component primary matrix associate component along reference equation relate token embed model embed token encoder bidirectional lstm  decoder lstm function token generator function bridge encoder decoder hei initialize global attention  selector function beam inference default literature prof empirically input output summary input sequencer java non empty faulty within attempt repair identify another technique usually fault localization output fix token model usage sequencer predict fix bug sequencer input buggy file bug output patch diff format user patch validation validation manual inspection source code sequencer available http github com kth sequencer model identify synthesize patch evaluation evaluation sequencer research research focus machine RQ extent fix perfectly predict RQ mechanism generate vocabulary token patch abstract buggy context reference research domain specific perspective ass performance sequencer viewpoint program repair research RQ effective sequencer sequence sequence fix bug establish defectsj benchmark RQ repair operator capture sequence sequence experimental methodology methodology RQ sequencer parameter setting described training validation accuracy perplexity plot perplexity ppl measurement model predicts sample define ppl exp logp sourcewhere source sequence target sequence ith target token correlation perplexity translation quality model dataset CodRep sequencer approach  subset CodRep sample buggy limited token methodology RQ evaluate effectiveness mechanism described sample CodRep successfully predict categorize token token vocabulary token vocabulary input sequence location token analyze location vocabulary token importance context abstract buggy context define mechanism allows powerful token beyond vocabulary patch methodology RQ evaluate sequencer defectsj collection reproducible java bug recent approach program repair research java defectsj evaluation benchmark scope patch focus defectsj bug fix developer replace bug effectiveness sequence sequence isolate fault localization input sequencer actual buggy file buggy sequencer patch recall beam candidate patch patch compile execute suite developer candidate patch generate sequencer categorize compilable patch patch compile plausible patch patch compilable suite patch incorrect overfitting patch patch suite semantically equivalent patch semantic equivalence evaluation per definition strict inclusion structure category patch necessarily plausible compilable plausible patch necessarily compilable methodology RQ RQ aim qualitative understand sequence sequence repair approach research motivate understand grammatically code transformation capture sequencer purely token approach ast grammar knowledge gain understand mixed combine theory target analysis understand variety repair operator program syntax capture sequencer model output correctly data theory regularly sample successful dataset CodRep sequencer predict fix author consensus program perspective bug fix highlight phenomenon already previously target analysis specifically mechanism specific program construct involve reference literal training data sequencer modification source code commits combine source commits CodRep dataset  dataset dataset bug fix publish date datasets java code built source project CodRep dataset focus solely source code fix aka patch contains datasets curated commits source project  dataset contains diffs github march october bug fix commits heuristic bug fix commits neither dataset buggy project suite expose buggy behavior instead focus bug fix commits data preparation CodRep  datasets format unify datasets diffs  fix replacement filter diffs outside  dataset generic bug fix data mining multi fix fix outside statistic understand generality sequencer  contains commits percent patch within within domain sequencer dataset training data CodRep originally split numbered commits project training data consists CodRep datasets  dataset data CodRep dataset CodRep chose dataset approximately percent entire CodRep data data percent data percent CodRep contains representative project evaluate furthermore ensure duplicate sample training datasets model setup random subset percent training data model training percent validation dataset descriptive statistic datasets sample training sample input distribution abstract buggy context token truncation CodRep training data median token  dataset median token dataset median variation java project datasets distribution prediction abstract buggy context sample dataset median percent token typical output processing sum magnitude sequence sequence prediction receives input sequence average token output sequence average token vocabulary training data vocabulary token distribution occurrence vocabulary typical distribution limit training vocabulary token overview vocabulary token occurrence zipf distribution overview vocabulary token occurrence zipf distribution percent sample exceed token limit truncation experimental RQ perfect prediction model gpu nvidia typical training golden model training validation accuracy per token generate accuracy entire patch perplexity ppl per token generate training validation datasets perplexity accuracy validation dataset iteration chose iteration standard training model training validation accuracy training validation perplexity CodRep prediction task model sequencer generate perfect fix predict replaces buggy exactly fix implement developer mechanism comparison approach comparison knowledge approach approach source available approach limited fix inside consist token limitation due approach generates entire fix source code output decoder decoder generate sequence source code token challenge NMT model sequencer assumption buggy task CodRep buggy resides token task  dataset accuracy CodRep  accuracy sequencer percent percent indicator sequencer outperforms twice prediction construction abstract buggy context mechanism accuracy buggy context specific encode variable recent fault localization research indicates technique predict faulty percent faulty percent extrapolate percentage data sequencer likely patch prior replacement sequencer repair demonstrate concentrate effectiveness approach buggy overall sequencer accuracy longer percent accuracy  percent accuracy CodRep phenomenon explain fix usually complex involve context variable identifier literal easily capture phenomenon previously RQ mechanism extent mechanism origin token successfully predict per patch correspond successfully predict consist token token patch token vocabulary non mechanism predict fix overall minority patch percent token vocabulary extreme successful patch generate sequencer token successful patch without mechanism token histogram correctly generate patch token token vocabulary token buggy buggy buggy analyze location origin token patch token buggy majority percent however token buggy token buggy context capture encode listing replaces variable   patch  fix training data hence token vocabulary therefore sequencer generate patch vocabulary token  within buggy token patch contribute patch listing mechanism patch incorporate variable vocabulary broader context around buggy  null        null  null overall mechanism extensively percent abstraction enables predict buggy buggy understand benefit context mechanism distance token token generate patch token buggy median distance buggy token token percent within token percent within token distance token buggy median distance token token percent within token distance addition ablation precede data decision abstract buggy context RQ defectsj evaluation explain defectsj bug fix patch developer sequencer patch bug unable fix remain bug due bug localize inside requirement fault localization sequencer assumes input listing defectsj bug localize inside patch instead prediction filter patch preparation patch unk token statistic bug bug sequencer successfully generate patch bug bug compilable patch bug patch plausible bug correctly fix semantically identical patch bug plausible patch rank beam semantically patch sequencer defectsj bug sequencer defectsj bug listing defectsj defect math bug localize inside variable private static default epsilon private static default epsilon perspective data focus patch bug sequencer generate compilable patch percent patch sequencer plausible patch bug plausible patch bug phenomenon program repair defectsj bug weak suite knowledge report correctness patch generate sequence sequence model correctness passing suite semantically equivalent patch sequencer generate patch semantically equivalent bug fix  patch synthesize sequencer defectsj bug sequencer apply defectsj bug plausible patch ratio percent analysis prior technique  GenProg RSRepair AE patch ratio percent evaluate sequencer benchmark prior target java ratio evidence sequencer output reasonable patch proposal although directly fault localization evaluation sequencer estimate performance repair fault localization technique estimate percent correctly identify faulty candidate hence bug defectsj candidate abstract buggy context prepared input model fault localization  successfully localize faulty bug sequencer fix discus timing estimate machine automatically patch bug summation estimate fault localization bug identify likely faulty location abstract buggy context bug patch candidate candidate beam abstract buggy context estimate prune raw patch patch attempt compile patch patch estimate machine patch correctly fix bug listing sequencer patch math semantically equivalent patch contains unnecessary parenthesis behavior occasionally occurs patch sequencer unnecessary parenthesis generate patch training data sequencer occasionally replicates style parenthesis evaluation therefore sequencer patch math semantically equivalent patch interestingly  vocabulary buggy  define buggy capture abstract buggy context defectsj mechanism useful capture token patch listing patch math return  comparable return  comparable patch return  comparable sequencer patch patch recent program repair publicly available  CapGen  report correctly repair bug defectsj bug patch identical patch claimed correctly repair bug respectively bug sequencer majority claimed patch bug sequencer fix defectsj bug  CapGen  driven intelligent substantial configuration handcraft goal sequencer agnostic repair operator upfront CapGen implement context aware operator selection context aware ingredient prioritization CapGen implementation heavily relies code transformation carefully algorithm parameter metric  sequencer heavyweight parameter tune sequencer easily perform grid meta optimization technique extent remarkable generic approach bug fix synthesizes patch semantically equivalent repair without static dynamic analysis generic approach sequencer improve future machine sequence sequence technique improve bug fix training data sequencer learns repair operator  assume perfect fault localization related fault localization localize buggy source code fault localization algorithm implementation granularity versus assumption fault localization repair technique assume perfect fault localization purely focus patch generation algorithm RQ qualitative diversity repair operator capture sequencer cull patch sequencer generate  dataset buggy input patch repair operator highlight effectiveness mechanism bold underlined font token outside vocabulary token training evaluation data consist orient java software sequencer capture operation related  replace  listing  failure  failure deletion buggy chain successful prediction consists delete listing deletion  context     context   argument addition patch sequencer argument java another listing argument addition stage  update width height stage  update width height target successful patch  another target  instead  input context listing target     sequencer remove clause boolean formula listing intersection null intersection null java keyword sequencer generate patch involve replacement program keywords clue syntax understand listing java keyword access software engineering implement encapsulation instead directly access handle sequencer listing access app  texture atlas  app  texture atlas  repair finally sequencer repair classical error listing repair     overall sequencer token operation token deletion listing token addition listing token replacement listing ablation perform ablation understand relative importance component approach identify golden model greedy optimization parameter model described parameter reasonable report performance dataset ablation demonstrate parameter selection golden model acceptance rate configuration model parameter dataset likely yield reasonable training computer abstract buggy context context related buggy detail ablation aid future researcher understand variable likely improve model due randomness parameter configuration multiple report standard deviation model recommend assessment random algorithm goal model defectsj evaluation  model hence report percentage decrease model golden model due computational constraint model configuration report almost GB disk storage machine sequencer datasets recommend approach validation perform model  training coarse grain feature performance model simplistic seq seq model buggy input fix beam abstract buggy context improve model performance confirm RQ mechanism essential performance performance impact feature beam context golden model specific target model ablation ID training limit sufficient training data ID vocabulary token performs likely due loss token instance token abstract buggy context ID vocabulary token performs due additional token insufficient training embed understand vocabulary analyze raw output model patch preparation golden model  percent generate patch CodRep unk token discard ID percent ID percent hence although vocabulary raw unk token token vocabulary optimize model configuration parameter neighborhood golden model ID pretraining opportunity quality embed unsupervised pretraining data encoder decoder unsupervised data improve model worsen ID combine CodRep  data improve generalization model ID demonstrates remove bridge encoder decoder improve model tighten standard deviation hence golden model due bridge layer variation encoder hidden embed decoder hidden embed IDs demonstrate lstm network correctly presumably network cannot generalize model data whereas network freedom speculation layer encoder decoder network allows layer directly token embed focus matrix input syntax layer attention mechanism focus output generation ID loss accuracy abstract buggy context reduce buggy ID truncation otherwise memory error crash due memory per token sequence ID truncate token increase context golden model improve accuracy model ID token limit abstract buggy context hurt accuracy presumably opportunity token speculate advantage truncation instead unsupervised encoder hidden global attention mechanism ID remove bug bug token abstract buggy context input target output patch without label sequencer fault localization valid patch  buggy context coverage data information useful fault localization significant accuracy loss ID network patch primary model golden model sequencer project allows simpler model retrain model periodically ongoing project ID explores sequencer sample project buggy CodRep training data random sample remove sample CodRep  project file training data bug project data percent improvement model model viable integration sequencer project regression related built active research program repair machine code refer recent survey overview program repair latter focus automatic repair program repair technique syntactic semantic error program submit MOOCs previous statement predict statement replace statement probability patch probability chosen statement beam prediction another MOOCs repair submission python combine sketch synthesis approach considers mooc technique completely program trace predict bug affect submission difference context buggy program training complex submission program educational program  sequencer predicts delete insert replace token compute embed symbolic trace perform pilot fix error handle code concrete bug fix  program repair fix compiler error introductory program input program token data output fix vocabulary distinct token unique vocabulary tracer another program repair fix compiler error outperforms  rate refines evaluates dataset focus focus compiler error focus logical bug compiler error vocabulary token contrary address mechanism  attempt integrate machine program repair loop  leverage code similarity capture recursive autoencoders repair ingredient code fragment buggy code usage  machine code sequencer machine generate actual patch investigate feasibility neural machine translation bug fix patch via NMT author perform source code abstraction relies combination lexer parser replaces identifier literal code goal abstraction reduce vocabulary frequent identifier literal author analyze longer token medium longer token performance longer approach buggy input generates entire fix output maximum token address vocabulary rename rare identifier custom abstraction sequencer entire context buggy buggy model access token predict fix abstraction uniquely utilizes mechanism allows sequencer utilize token generate fix information context within abstract buggy context token beyond qualitative difference quantitative longer token restriction sequencer potentially generate patch within parallel discus network architecture apply diffs difference project specific training approach evaluate data project contrary global training sequencer capture repair operator applicable project qualitative unique respect  output compile execute predict patch suite repair approach input limited precise buggy code replace sequencer abstract buggy context allows broader token mechanism conclusion novel approach program repair sequencer sequence sequence approach uniquely combine encoder decoder architecture mechanism overcome vocabulary source code dataset task project training sequencer successfully predict defectsj bug sequencer plausible suite adequate patch knowledge effectiveness mechanism program repair mechanism alleviate unlimited vocabulary promising research direction aim improve adapt sequencer goal address multi patch tackle fix modify contiguous code hunk extend sequencer generate multiple code output token bug bug surround entire hunk fix modify multiple location envision sequencer generate finite combination program predict fix suspicious location preliminary transformation conceptually appropriate code parse technique augment supersede sequence sequence approach finally originality context abstraction capture dependency network architecture capture dependency beyond package application