software defect prediction aim identify potential defect software module advance construct effective prediction model however model performance susceptible irrelevant redundant feature addition previous mainly traditional data mining machine technique defect prediction prediction performance superior issue motivate software engineering leverage recently propose whale optimization algorithm WOA another complementary simulated anneal SA construct enhance metaheuristic feature selection algorithm EMWS effectively closely related representative feature issue employ hybrid neural network convolutional neural network cnn kernel extreme machine KELM construct unified defect prediction predictor WSHCKE integrate feature abstract semantic feature cnn boost prediction performance advantage classification capacity KELM conduct extensive feature selection extraction defect prediction across widely software project evaluation indicator experimental demonstrate superiority EMWS WSHCKE previous keywords software defect prediction metaheuristic feature selection whale optimization algorithm convolutional neural network kernel extreme machine introduction defective software unexpected deployment economic loss organization currently software defect prediction important software quality assurance technique extract historical defect data software repository leverage data mining machine algorithm construct effective prediction model detect defect proneness software module effective defect prediction model developer maintainer efficiently detect potentially defective module reasonably allocate limited software development maintenance resource building software defect datasets researcher inspect software defect module software feature software development code complexity feature helpful prediction performance model irrelevant redundant feature demonstrate feature source defect datasets irrelevant redundant feature seriously degrade prediction performance increase training model prior proven feature selection extraction avoid multicollinearity curse dimensionality therefore conduct feature selection extraction defect datasets software defect prediction recently feature selection extraction propose remove combine irrelevant redundant feature software defect datasets purpose feature selection optimal representative feature subset instead feature evaluate contribution module feature feature extraction technique decrease feature construct combine feature feature previous mainly utilized metaheuristic machine algorithm conduct feature selection extraction software defect prediction correlation feature selection perform  heuristic algorithm greedy  backtracking genetic metaheuristic intelligent algorithm recent metaheuristic algorithm widely optimization feature selection research domain metaheuristic algorithm investigate however due stochastic metaheuristic algorithm guarantee combination feature feature selection lunch  theorem optimization declares optimizer effective optimization feature selection numerous software project software defect prediction moreover exploitation optimal intensification exploration diversification contradictory goal account simultaneously employ metaheuristic algorithm feature selection relatively random optimal balance contradictory goal boost performance metaheuristic algorithm feature selection performance perform  exploitation capability local exploration capability capability optimal enhance motivate attempt investigate superior feature selection accord contradictory goal mention metaheuristic algorithm category exploitation orient algorithm  simulated anneal SA exploration orient algorithm population whale optimization algorithm WOA  lewis ant optimization   pour  SA mechanism algorithm SA adopts anneal mechanism SA regard upgraded version  achieve balance contradictory goal hybrid algorithm metaheuristic algorithm combine enhance performance algorithm nevertheless hybrid metaheuristic feature selection investigate thoroughly software defect prediction leverage recently propose exploration global orient algorithm whale optimization algorithm WOA another complementary exploitation local orient algorithm simulated anneal SA construct enhance metaheuristic feature selection algorithm EMWS context software defect prediction adopts roulette selection selection mechanism exploration stage logistic regression algorithm classifier feature selection utilized combination mechanism WOA SA hybrid model teamwork hybrid lth relay hybrid  intelligent algorithm optimization apply combination mechanism feature selection software defect prediction adopt selection mechanism exploration stage classifier feature selection enhance EMWS algorithm advantage local capability SA enhance weak exploitation performance WOA leverage global capability WOA boost weak exploration SA extent simultaneously WOA algorithm recently propose exploration orient optimization algorithm advantage optimization global capability structure adjustment parameter flexibility complement SA perfectly utilize WOA algorithm global optimal employ SA algorithm optimal basis exist optimal iterative loop obtain WOA limited iteration trap local optimum SA allows accept probability escape local optimum towards objective function SA enhance overcome stagnate local optimum WOA local optimum optimal obtain WOA unique WOA SA integrate hybrid metaheuristic algorithm achieve performance separately feature selection previous performance prediction model largely depends factor feature representation classifier motivate distinguish feature representation software project powerful classifier superior performance excellent defect feature representation feature discriminant inter separability reserve unaltered intra compactness recent due capability extract semantic feature discriminative capability ordinary machine convolutional neural network cnn highlight semantic recognition prior research demonstrate semantic feature discriminate capacity defective non defective traditional cnn network layer framework previous layer extract semantic feature softmax layer classifier discriminate feature however softmax intra compactness inter separation cannot advantage discriminative semantic feature extract previous convolutional layer softmax suitable multi classification task software defect prediction binary classification task addition verify classification capability softmax cnn inferior classifier elm extreme machine elm propose verify efficient classification algorithm due generalization performance training without iteration operation implementation super parameter intervention unlike traditional gradient algorithm elm propose generalize hidden layer neural SLFN network overcome rate local minimum epoch criterion elm widely adopt binary classification task advantage extract discriminative semantic feature elm KELM kernel extreme machine introduces nonlinear gaussian kernel upgraded version elm gaussian kernel classify feature nonlinear relationship investigation easily judge KELM classifier effective apply cnn structure motivate integrate advantage cnn KELM replace softmax classifier KELM classifier layer cnn consequence unified defect predictor WSHCKE hybrid convolutional neural network kernel extreme machine accord feature EMWS construct cnn data driven semantic feature extractor cascade KELM powerful classifier instead conventional softmax classifier cnn framework contribution leverage recently propose whale optimization algorithm WOA another complementary simulated anneal SA construct enhance metaheuristic feature selection algorithm EMWS selects optimal representative feature subset advantage local capability SA enhance exploitation performance WOA leverage global capability WOA boost exploration SA simultaneously knowledge attempt apply hybrid exploration orient algorithm population WOA exploitation orient algorithm SA feature selection software defect prediction construct unified defect predictor WSHCKE adopts hybrid neural network cnn KELM integrate defect feature data driven abstract semantic feature cnn boost prediction performance utilize discriminative capacity KELM conduct extensive feature selection extraction defect prediction across software project source datasets EMWS algorithm eleven feature selection extraction approach WSHCKE predictor classic defect predictor experimental demonstrate EMWS algorithm WSHCKE predictor achieve superior prediction performance evaluation indicator reminder organize background whale optimization algorithm simulated anneal introduces data preprocessing imbalance processing data standardization detail feature selection enhance EMWS algorithm detail propose WSHCKE model experimental setup benchmark datasets evaluation indicator experimental parameter setting scott knott difference esd wilcoxon rank cliff delta analysis evaluates discus performance EMWS algorithm WSHCKE predictor introduces threat validity describes related conclude future background leverage enhance metaheuristic algorithm EMWS contains whale optimization algorithm WOA simulated anneal SA optimal representative defect feature subset introduce WOA SA algorithm respectively whale optimization algorithm whale optimization algorithm recently propose metaheuristic algorithm stochastic population mimic intelligent forage behavior bubble net  whale  lewis WOA global capability structure adjustment parameter flexibility WOA consists stage exploitation stage shrink encircle prey spiral bubble net mechanism exploration stage prey exploitation stage  whale constantly adjust accord prey WOA assumes optimal candidate target prey closest target prey optimal candidate refers candidate feature subset context software defect prediction feature necessarily minimum define optimal whale towards optimal context software defect prediction movement whale towards prey analogous optimal feature subset calculate fitness calculate fitness agent whale fitness function mathematical expression iteration denotes target coordinate vector iteration denotes optimal obtain coefficient vector calculate respectively decrease linearly update maximum iteration random vector  whale shrink encircle mechanism towards prey spiral shrink encircle mechanism simulated decrease adjustment neighborhood optimal spiral calculate accord distance optimal spiral bubble net mechanism distance  whale optimal individual optimal obtain denotes constant defines logarithmic spiral random model shrink encircle mechanism upward spiral simultaneously assume probability update whale optimization random randomly chosen probability shrink encircle mechanism upward spiral mechanism WOA exploitation stage denotes achieve visualizes whale towards prey shrink encircle mechanism visualizes spiral update mechanism whale prey exploration stage  whale randomly prey update coefficient exceeds distance update accord roulette selection randomly selection whale deviate target prey prey WOA global capability mechanism mathematically model denotes location whale individual population accord roulette selection simulated anneal simulated anneal stochastic computational algorithm seek global extremum global optimal various intelligent optimization algorithm mimic anneal  involves initial heating simulated anneal obtain global optimal context software defect prediction global optimal refers feature subset minimum feature corresponds software project allows accept probability escape local optimum towards objective function global optimum characteristic simulated anneal local capability combine SA WOA overcome stagnate local optimum WOA simulated anneal exists optimal newly generate iteration improve accepted accepted probability boltzmann probability escape local optimum achieve global optimum difference fitness optimal generate important parameter convergence typically decrease iteration increase accord schedule schedule typical option proportional denotes proportional coefficient typically decrease iteration increase data preprocessing data preprocessing aspect imbalance processing data standardization imbalance processing imbalance software defect datasets distribution software defect project roughly pareto principle namely program module defect defective module non defective module majority serious imbalance software project prediction performance model relatively adopt  synthetic minority oversampling  algorithm imbalance processing upgraded auto tune version SMOTE  employ DE differential evolution explore parameter important parameter synthetic instance parameter minkowski distance metric thereby generate optimal parameter combination software project  perform previous imbalance technique critical software defect prediction prediction model bias towards non defective module majority improve performance defect prediction data standardization distribution defect feature difference magnitude feature defect prediction function comprehensive analysis highlight function relatively weaken ensure reliability prediction standardize feature feature consistent distribution standardization feature normalize calculate variance initial feature respectively feature selection enhance EMWS algorithm combine powerful unique WOA SA integrate enhance metaheuristic feature selection optimization algorithm advantage local capability SA enhance weak exploitation performance WOA leverage global capability WOA boost weak exploration SA extent simultaneously thereby achieve performance separately feature selection software defect prediction utilize WOA algorithm global optimal employ SA algorithm optimal basis exist optimal iterative loop obtain WOA limited iteration trap local optimum SA allows accept probability escape local optimum towards objective function SA enhance overcome stagnate local optimum WOA local optimum optimal obtain WOA context software defect prediction optimal candidate refers candidate feature subset feature necessarily minimum optimal refers feature subset minimum feature corresponds software project refers feature subset corresponds software project dimensional binary vector contains feature software project vector denotes correspond feature otherwise EMWS algorithm considers optimization objective feature selection software defect prediction optimization objective minimize feature another objective minimize classification error feature classification error previous adopt optimization goal feature selection balance feature minimum classification error minimum empirically priori coefficient objective decision maker integrate objective objective function obtain optimal sum EMWS wrapper feature selection algorithm adopt logistic regression LR classifier EMWS algorithm fitness function evaluate EMWS algorithm define denotes classification error logistic regression classifier denotes feature software project cardinality feature subset parameter correspond importance classification quality minimize classification error feature subset respectively EMWS algorithm feature selection software project prediction latter WSHCKE predictor specifically classification exploration WOA algorithm depends individual accord randomly meanwhile preserve diversity capability EMWS algorithm apply roulette selection mechanism individual population exploration stage mechanism weak image KB image image KB image pseudo code enhance metaheuristic EMWS algorithm algorithm fitness function enhance EMWS algorithm calculate WOA SA algorithm evaluate fitness function respectively randomly initialize population initial calculate fitness calculate fitness entire EMWS algorithm loop maximum iteration agent update series important parameter variable vector coefficient vector random accord model shrink encircle mechanism upward spiral simultaneously assume probability update whale optimization randomly chosen shrink encircle mechanism update exploitation phase accord update prey exploration phase accord roulette selection mechanism upward spiral calculate accord distance optimal spiral bubble net mechanism beyond amend calculate fitness update iteration WOA output WOA assign input initial SA SA iteration SA repetition schedule function denotes maximum iteration conduct function generate neighborhood difference fitness generate optimal gain improve accepted accepted probability boltzmann probability escape local optimum achieve global optimum denotes random important parameter convergence typically decrease iteration increase accord schedule typical option schedule proportional denotes proportional coefficient iteration calculate classification error rate feature subset feature subset software project EMWS algorithm feature selection assume feature feature dimensional binary vector contains feature subset denotes correspond feature employ WOA feature subset series shrink encircle prey spiral update correspond prey accord roulette selection mechanism utilize SA correspond optimal feature subset mechanism improve accepted accept probability exist feature subset obtain WOA series iteration achieve optimal feature subset optimal purple software project algorithm pseudo code feature selection EMWS defect prediction corresponds algorithm utilize WOA algorithm global optimal employ SA algorithm optimal basis exist optimal iterative loop obtain WOA limited iteration trap local optimum SA enhance local optimum optimal addition advantage local capability SA enhance weak exploitation performance WOA leverage global WOA boost weak exploration SA extent simultaneously unique WOA SA integrate hybrid metaheuristic algorithm achieve performance separately image KB image EMWS algorithm feature selection propose WSHCKE model construct unified defect predictor WSHCKE adopts hybrid neural network cnn KELM integrate defect feature data driven abstract semantic feature cnn boost prediction performance utilize discriminative capacity KELM therefore predictor contains functional module semantic feature representation cnn module network structure input layer convolutional layer relu nonlinear activation function flatten layer fully FC layer softmax layer softmax layer participates training defect prediction KELM softmax KELM verify efficient classification algorithm due generalization performance training without iteration operation implementation super parameter intervention KELM widely adopt binary classification task advantage extract discriminative semantic feature motivate integrate advantage cnn KELM replace softmax classifier KELM classifier layer cnn WSHCKE predictor consists training stage stage training stage cnn network component cnn feature extractor network softmax classifier cnn network utilized extract semantic feature representation training training stage cnn feature extractor training stage cascade KELM classifier network KELM classifier FC classification task semantic feature extract cnn output FC adopt input KELM stage WSHCKE predictor cnn KELM predict defect instance defective network architecture WSHCKE model semantic feature representation cnn training stage cnn network structure input layer convolutional layer relu nonlinear activation function flatten layer fully layer softmax layer feature dimension project feature selection network parameter WSHCKE predictor project dimensional feature EMWS algorithm dimensional feature refer feature dimension project feature selection dimension feature dimensional feature dimensional feature zero reshape dimensional feature matrix thereby facilitate subsequent convolution operation dimensional feature convenient subsequent convolution processing width height reshaped matrix inconsistent perform convolution operation neuron convolutional layer respectively convolution kernel respectively relu nonlinear activation function convolutional layer operation convert dimensional feature dimensional vector flatten FC layer softmax layer participates training training stage prior research demonstrate semantic feature discriminate capacity defective non defective cnn extract semantic feature hidden defect data series convolution operation employ convolution operation continuously enhance nonlinear fitting capability network extract discriminative feature series parameter adjustment relu nonlinear activation function convolutional layer boost nonlinear relationship layer training data software project define width height matrix reshaped defect instance training instance label defective non defective correspond training data project convolutional layer convolutional layer feature layer kernel feature denote height width filter kernel respectively denotes bias feature index feature layer convolutional layer convolutional layer transform feature representation defect instance semantic feature representation nonlinear mapping convolution operation rewrite denotes convolution operation layer feature denotes output layer output feature convolutional layer training extract semantic feature training fully layer KELM classifier semantic feature integrate cnn define feature vector parameter network involve define feature vector express mapping function feature vector integrate defect prediction KELM mention KELM advantage classification softmax therefore replace softmax layer KELM classifier cnn training stage KELM advantage extract discriminative semantic feature intra compactness inter separation predict instance module defective network structure KELM regard semantic feature training fully FC layer input KELM KELM classifier define input KELM semantic feature vector integrate cnn input neuron hidden neuron output neuron defect data defective non defective denotes input matrix input layer hidden layer denotes bias vector hidden layer denotes output matrix hidden layer output layer denotes output vector KELM image KB image network structure KELM therefore training data KELM classifier define feature vector defect instance defect instance training project output hidden layer output KELM output output layer respectively training software project output hidden layer correspond output label matrix respectively standard elm classifier approximate instance zero error applies KELM specific defect training exist obtain output matrix minimize error calculate accord denotes moore penrose generalize inverse output KELM classifier rewrite derivation KELM hyperparameter KELM classifier calculation relatively advantage KELM classifier standard elm hidden layer elm data feature dimensional dimension corresponds hidden however dimensional regard feature elm solves linear transformation adopt KELM gaussian kernel achieve nonlinear transformation dimensional feature dimensional equation gaussian kernel bandwidth radial action therefore define kernel matrix KELM output KELM identity matrix dimension positive diagonal achieve generalization performance network cnn network KELM classifier training stage stage output cnn KELM prediction label denote semantic feature vector extract cnn network accord denotes prediction stage output KELM network calculate accord prediction label denote component instance defective pseudo code propose WSHCKE predictor algorithm training stage defect instance project feature selection dimension reshape matrix zero reshape dimensional feature matrix thereby facilitate subsequent convolution operation dimensional feature convenient subsequent convolution processing cnn conduct iterative training maximum iteration network layer network layer input layer defect instance matrix cnn structure network layer convolutional conv layer convolution operation integrates defect feature accord employ relu nonlinear activation function nonlinear relationship thereby generate network bias network layer flatten layer layer flattens matrix correspond feature network layer fully FC layer layer convert dimensional feature dimensional vector network layer softmax layer network adopts sparse entropy loss function participates training cnn iteration error extract semantic feature FC layer training otherwise cnn propagation training stage extract semantic feature KELM classifier calculate output matrix hidden layer accord output matrix KELM accord obtain output KELM stage employ WSHCKE cnn KELM predict defect instance defective image KB image experimental setup experimental setup benchmark datasets evaluation indicator experimental parameter setting scott knott difference esd wilcoxon rank cliff delta analysis benchmark datasets datasets promise ReLink publicly available commonly benchmark datasets software defect prediction conduct extensive source software project datasets project promise project ReLink project promise dataset jureczko  project promise dataset metric feature orient OO metric McCabe cyclomatic metric CK metric ReLink dataset contains project apache  project metric dataset project dataset contains metric previous defect metric entropy metric source code metric entropy source code metric churn source code metric summarizes information project datasets project feature instance defective instance non defective instance defective ratio imbalance ratio project datasets imbalanced imbalance ratio jedit  LC datasets respectively therefore conduct imbalance processing software project addition instance project contains feature dependent variable denotes defect instance module label instance module contains defect otherwise label statistic software project datasets  feature instance defective instance non defective  ratio imbalance ratio  ant camel camel ivy jedit jedit poi prop synapse xalan xerces   LC EQ pde ML evaluation indicator evaluate performance model widely defect prediction performance evaluation classification confusion matrix describes prediction model classifies defect category actual classification comprehensive evaluation harmonic precision recall confusion matrix positive predict negative predict actual   actual  precision recall probability detection probability false alarm mcc matthew correlation coefficient correlation predict binary classification comprehensive evaluation comprehensive evaluation harmonic auc denotes receiver operating characteristic roc curve auc curve drawn dimensional probability false alarm axis probability detection axis auc independent cutoff threshold instance classify positive negative indicator prediction performance experimental conduct extensive feature selection extraction defect prediction baseline correspond research rqs eleven feature selection extraction approach RQ principal component analysis pca factor analysis FA diffusion DM stochastic embed sne locality preserve projection LPP neighborhood preserve embed NPE locally linear coordination llc manifold MC maximally collapse metric  feature extraction approach addition correlation feature selection approach genetic GS  BF EMWS algorithm eleven feature selection extraction approach defect predictor WSHCKE EMWS algorithm report minimum feature achieve minimum error project RQa classic defect predictor RQ naive bayes NB vector machine svm logistic regression LR decision DT knn random RF moreover model belief network DBN convolutional neural network cnn defect prediction  defect predictor feature EMWS algorithm rename   WSLR      WSDPDF respectively WS WOA SA baseline approach baseline approach efficiency RQ WSHCKE classic defect predictor verify WSHCKE predictor within acceptable generalization performance eleven feature selection extraction approach baseline approach classic defect predictor baseline approach RQ investigate generalization capacity EMWS feature selection algorithm WSHCKE predictor EMWS eleven feature selection extraction approach baseline defect predictor respectively classic defect predictor WSHCKE classic defect predictor baseline feature selection approach respectively eleven feature selection extraction approach defect feature without feature selection verify feature EMWS algorithm advantage prediction performance defect feature without feature selection WSHCKE EMWS EMWS adopt naive bayes NB knn classifier instead logistic regression LR classifier EMWS feature selection algorithm investigate feature selection capability EMWS algorithm comprehensively impact feature selection classifier within EMWS prediction performance replace LR classifier NB knn classifier EMWS feature selection algorithm conduct defect prediction defect predictor WSHCKE feature selection parameter setting feature selection perform training perform feature selection training thereby feature subset training correspond retains feature training ensure training feature dimension feature dimension training consistent employ machine model predict defect instance defective EMWS feature selection algorithm important parameter adjust agent agent conduct feature selection EMWS algorithm respectively feature feature selection WSHCKE predictor finally agent achieve auc software project agent cannot otherwise prediction performance ideal maximum iteration entire EMWS maximum iteration iteration SA respectively parameter setting eleven baseline feature selection extraction algorithm detailed pca pca eigenvalue adopt intrinsic dimensionality estimator FA dimensionality reduction conduct EM expectation maximization algorithm regularization parameter maximum iteration DM variable variance gaussian affinity computation variable determines operator apply graph sne conduct sne algorithm gaussian kernel fix perplexity default parameter rate maximum iteration initial momentum momentum LPP specify variable determines bandwidth gaussian kernel default NPE specify llc parameter tolerant error maximum iteration mixture MC parameter maximum iteration mixture  maximum iteration BF adopts strategy GS population maximum iteration crossover probability mutation probability respectively WSHCKE predictor network parameter adjust mention feature dimension project feature selection network parameter WSHCKE predictor project dimensional feature EMWS algorithm cnn structure cnn network structure input layer convolutional layer relu nonlinear activation function flatten layer fully layer softmax layer dimensional feature EMWS algorithm dimensional feature zero reshape matrix feature convolution operation perform convolution operation convolution kernel convolutional layer respectively convolution kernel respectively relu nonlinear activation function convolutional layer unlike image software project data complex convolutional layer ablation analysis gradually increase convolutional layer convolutional layer auc commonly adjust neural network parameter meanwhile manually convolution kernel generally height width relatively convolution kernel generally accord thereby convolution kernel convolution kernel auc respectively manually batch generally rate generally accord batch rate auc respectively moreover adopt optimization strategy training iteration strategy overfitting software project boost prediction performance adopt sparse softmax entropy loss function KELM structure salient characteristic KELM hidden layer tune elm originally propose employ random computational neuron hidden layer independent training data however KELM empty neuron empty KELM neuron exceeds elm prediction performance decrease computational complexity proportional  neuron dimensional feature EMWS algorithm neuron conduct respectively finally neuron auc parameter setting baseline predictor detailed  adopt kernel estimator achieve auc software project  adopt gaussian kernel kernel function mention hsu lin parameter kernel parameter optimal parameter combination parameter kernel parameter achieve accord auc grid WSLR random adopts distribution adopts tolerant error  criterion adopts minimum sample leaf minimum sample split  auc  generate variable random feature selection criterion adopts addition limit maximum depth elish elish  parameter setting parameter adjustment WSHCKE predictor ror  adopt parameter setting network structure WSDPDF adopt parameter setting decision scott knott difference esd employ scott knott difference esd rank multiple feature selection extraction approach multiple defect predictor indicator exhibit boxplots scott knott esd visual performance difference feature selection extraction approach defect predictor denotes rank statistically significant performance difference approach rank scott knott difference esd alternative approach scott knott comparison approach utilizes hierarchical cluster partition multiple approach statistically distinct non negligible difference considers magnitude difference multiple approach within wilcoxon rank cliff delta analysis employ wilcoxon rank cliff delta analysis model statistically significant wilcoxon rank data demand underlie experimental data data distribution multiple comparison induce false discovery rate employ benjamini hochberg correction adjust confidence difference approach statistically significant difference statistically significant effectiveness baseline leverage cliff delta model baseline cliff delta indicates non parametric evaluation difference approach evaluation interval indicates indicates completely overlap correspond effectiveness cliff delta effectiveness cliff delta effectiveness negligible medium experimental analysis focus performance EMWS algorithm WSHCKE predictor discus research rqs RQ enhance metaheuristic EMWS algorithm outperform eleven feature selection extraction approach software defect prediction validate feature enhance metaheuristic EMWS algorithm prediction performance subsequent WSHCKE model EMWS eleven feature selection extraction approach defect predictor WSHCKE across source software project datasets mcc auc pca FA DM sne LPP NPE llc MC  GS BF GS BF correlation feature selection approach feature extraction approach depicts mcc auc twelve feature selection extraction approach across software project datasets project promise project ReLink project average performance indicator project dataset promise ReLink average performance indicator project datasets marked bold EMWS algorithm achieve average performance indicator indicator ReLink dataset specifically datasets average EMWS gain improvement FA  average improvement average mcc EMWS achieves improvement BF llc average improvement average EMWS yield improvement FA  average improvement average auc EMWS obtains improvement FA  average improvement eleven baseline feature selection extraction approach conduct visual comparison prediction performance difference EMWS eleven baseline feature selection extraction approach exhibit boxplots scott knott esd evaluation indicator manifest scott knott esd twelve feature selection extraction approach across software project mcc auc respectively denotes rank approach rank statistically significant difference prediction performance model denotes median indicator feature selection extraction approach axis twelve feature selection extraction approach axis evaluation indicator enhance metaheuristic EMWS algorithm rank indicates EMWS achieve optimal prediction performance evaluation indicator eleven baseline feature selection extraction approach median gain EMWS gain eleven baseline feature selection extraction approach evaluation indicator respectively fully validates superiority EMWS average indicator EMWS eleven baseline feature selection extraction approach   mcc auc  mcc auc mcc auc  mcc auc cliff delta EMWS eleven baseline feature selection extraction approach evaluation indicator   pca FA DM sne LPP NPE llc MC  GS BF comprehensively reflect superiority EMWS employ wilcoxon rank validate performance difference EMWS eleven baseline feature selection extraction approach statistically significant employ benjamini hochberg correction adjust confidence performance difference approach statistically significant addition leverage cliff delta EMWS eleven baseline feature selection extraction approach cliff delta correspond effectiveness positive EMWS approach enhance prediction performance depicts cliff delta EMWS eleven baseline feature selection extraction approach evaluation indicator mcc auc significant negligible auc consistent observation significant feature extraction approach negligible sum enhance metaheuristic EMWS algorithm achieve prediction performance defect predictor WSHCKE evaluation indicator eleven feature selection extraction approach enhance EMWS algorithm advantage local capability SA enhance weak exploitation performance WOA leverage global capability WOA boost weak exploration SA extent simultaneously unique WOA SA integrate achieve performance separately optimal feature subset software project image KB image RQa enhance metaheuristic EMWS algorithm minimum feature achieve minimum error project average feature classification error achieve enhance EMWS algorithm project feature   ant ant camel camel ivy jedit jedit poi prop synapse xalan xerces apache  jdt LC EQ pde ML average indicator WSHCKE classic defect predictor   mcc auc  mcc auc mcc auc  mcc auc EMWS algorithm report minimum feature achieve minimum error project perform project EMWS algorithm average depicts average classification accuracy average feature average proportion average fitness achieve EMWS algorithm project subsequent WSHCKE model adopt feature feature rank project RQ WSHCKE predictor superior classic defect predictor adopt WSHCKE defect predictor investigate effectiveness defect predictor WSHCKE WSHCKE predictor classic predictor feature selection approach EMWS   WSLR      WSDPDF approach model WS WOA SA mcc auc defect predictor across software project datasets project promise project ReLink project average performance indicator project dataset promise ReLink average performance indicator project datasets marked bold WSHCKE predictor achieve optimal average performance indicator specifically datasets average WSHCKE yield improvement WSDPDF  average improvement average mcc WSHCKE obtains improvement WSDPDF  average improvement average WSHCKE gain improvement WSDPDF  average improvement average auc WSHCKE achieves improvement WSDPDF  average improvement classic defect predictor conduct visual comparison prediction performance difference WSHCKE baseline defect predictor exhibit boxplots scott knott esd evaluation indicator visualize scott knott esd defect predictor across software project mcc auc respectively median indicator defect predictor axis denotes defect predictor axis denotes evaluation indicator WSHCKE predictor rank WSHCKE predictor achieve prediction performance evaluation indicator classic defect predictor median gain WSHCKE gain classic defect predictor evaluation indicator respectively fully validates superiority WSHCKE predictor image KB image scott knott esd rank WSHCKE classic defect predictor evaluation indicator interpretation reference legend reader refer web version article cliff delta WSHCKE classic defect predictor evaluation indicator     WSLR      WSDPDF validate performance WSHCKE predictor utilize wilcoxon rank verify performance difference WSHCKE baseline defect predictor statistically significant moreover employ cliff delta WSHCKE baseline defect predictor benjamini hochberg correction cliff delta WSHCKE baseline defect predictor evaluation indicator auc significant negligible mcc significant WSDPDF WSLR mcc negligible conclusion WSHCKE predictor achieve optimal prediction performance feature selection approach EMWS evaluation indicator classic defect predictor cnn extract data driven abstract semantic feature hidden defect data inter separability reserve unaltered intra compactness prior research demonstrate semantic feature discriminate capacity defective non defective KELM generalization performance implementation super parameter intervention consequence integrate advantage cnn KELM construct unified defect predictor WSHCKE boost prediction performance image KB image RQ efficient WSHCKE predictor classic defect predictor WSHCKE baseline defect predictor  pca FA DM sne LPP NPE llc MC  GS BF EMWS avg indicator defect predictor explore efficient WSHCKE baseline predictor   WSLR      WSDPDF verify WSHCKE predictor within acceptable WSHCKE baseline defect predictor twelve feature selection extraction approach WSHCKE predictor across project cnn KELM WSHCKE training WSHCKE longer cnn predictor KELM classifier training determination network structure parameter cnn iterative training series convolution operation WSHCKE predictor training although WSHCKE predictor within acceptable applicable equivalent sacrifice efficiency effectiveness image KB image RQ generalization capacity EMWS feature selection algorithm WSHCKE predictor software defect prediction generalization capacity prediction performance model investigate generalization capacity EMWS feature selection algorithm WSHCKE predictor RQ EMWS algorithm eleven feature selection extraction approach defect predictor WSHCKE RQ WSHCKE predictor classic defect predictor feature selection approach WSHCKE RQ RQ EMWS eleven feature selection extraction approach baseline defect predictor respectively classic defect predictor WSHCKE classic defect predictor baseline feature selection extraction approach respectively eleven feature selection extraction approach specifically eleven baseline feature selection extraction approach classic baseline predictor perform across software project datasets mcc auc visualize boxplots scott knott esd rank verify generalization capacity twelve feature selection extraction approach defect predictor across project evaluation indicator respectively axis twelve feature selection extraction approach axis evaluation indicator denotes median indicator feature selection extraction approach EMWS algorithm rank rank contains EMWS demonstrates EMWS algorithm achieve optimal prediction performance evaluation indicator eleven feature selection extraction approach median gain EMWS gain eleven baseline feature selection extraction approach mcc auc respectively however EMWS algorithm performance performer accord median FA axis denotes defect predictor axis denotes evaluation indicator median indicator defect predictor  predictor rank rank contains  verifies  predictor achieve prediction performance evaluation indicator baseline defect predictor median obtain  obtain baseline defect predictor evaluation indicator respectively image KB image scott knott esd rank verify generalization capacity EMWS evaluation indicator interpretation reference legend reader refer web version article cliff delta verify generalization capacity EMWS evaluation indicator   pca FA DM sne LPP NPE llc MC  GS BF image KB image scott knott esd rank verify generalization capacity WSHCKE evaluation indicator interpretation reference legend reader refer web version article cliff delta verify generalization capacity WSHCKE evaluation indicator     WSLR      WSDPDF exhibit benjamini hochberg correction cliff delta verify generalization capacity EMWS algorithm WSHCKE predictor evaluation indicator pca FA BF auc indicates difference EMWS eleven baseline feature selection extraction approach statistically significant addition evaluation indicator FA evaluation indicator FA BF auc indicates performance difference negligible WSLR indicates difference WSHCKE baseline defect predictor statistically significant moreover evaluation indicator evaluation indicator WSLR WSLR  WSDPDF mcc WSDPDF auc indicates performance difference negligible observation consistent fully validates superiority EMWS algorithm WSHCKE predictor experimental analysis conclude EMWS algorithm WSHCKE predictor achieve optimal prediction performance eleven feature selection extraction approach classic baseline defect predictor EMWS algorithm WSHCKE predictor generalization capacity superior performance EMWS WSHCKE explain RQ RQ addition WSHCKE predictor employ feature feature selection extraction predict instance module defective feature robustness enhances generalization capacity WSHCKE predictor extent WSHCKE predictor adopt training iteration strategy overfitting software project boost prediction performance model image KB image RQ feature EMWS algorithm advantage prediction performance defect feature without feature selection prediction performance EMWS EMWS defect predictor performance comparison defect predictor EMWS without EMWS evaluation indicator defect predictor EMWS predictor EMWS achieve average improvement mcc auc respectively utilize wilcoxon rank cliff delta approach statistically significant evaluation indicator indicates difference defect predictor EMWS without EMWS statistically significant evaluation indicator moreover evaluation indicator auc performance difference negligible therefore feature EMWS algorithm significantly boost prediction performance model defect feature without feature selection EMWS feature selection approach optimal feature subset combination utilize global capability WOA local capability SA eliminates irrelevant redundant feature seriously degrade prediction performance image KB image performance comparison predictor EMWS without EMWS evaluation indicator  mcc auc    WSLR      WSDPDF WSHCKE avg RQ impact classifier EMWS feature selection algorithm prediction performance investigate feature selection capability EMWS algorithm comprehensively impact feature selection classifier within EMWS prediction performance replace LR classifier NB knn classifier EMWS feature selection algorithm conduct defect prediction defect predictor WSHCKE feature selection visualizes impact comparison classifier EMWS algorithm prediction performance evaluation indicator LR classifier achieve prediction knn NB employ wilcoxon rank benjamini hochberg correction cliff delta classifier statistically significant NB evaluation indicator indicates difference LR NB statistically significant knn mcc indicates difference LR knn statistically significant indicator auc knn addition NB evaluation indicator performance difference negligible knn mcc auc performance difference negligible image KB image threat validity discus validity threat affect experimental internal validity internal validity mainly concerned uncontrolled aspect threaten experimental error examine carefully error external validity external validity involves quality universality datasets conduct extensive source software project datasets project promise project ReLink project publicly available commonly benchmark datasets software defect prediction addition software project belong application program therefore datasets universality construct validity construct validity related applicability evaluation indicator evaluation indicator namely mcc auc widely previous software defect prediction construct validity acceptable addition parameter setting affect experimental recent defect prediction model parameter setting reduce threat parameter setting advanced automate parameter optimization technique related review typical software defect prediction feature selection extraction software defect prediction application technique software engineering software defect prediction exist software defect prediction roughly aspect researcher focus leverage machine algorithm construct effective defect prediction model propose succinct effective defect prediction learner fft  experimental fft outperform software analytics expectation maximization EM logistic SL elish elish vector machine svm construct defect prediction model statistical machine model nasa project   propose classification model superpose naive bayes  transforms naive bayes ensemble naive bayes model linear approximation leveraged active conduct defect prediction model significantly improve prediction performance propose novel semi supervise  sample prediction module helpful model training propose novel stage ensemble  approach defect prediction contains stage ensemble multi kernel domain adaptation stage ensemble data sample stage replicate project defect prediction propose researcher evaluate performance software project data propose organize mapping som prediction model threshold tester module without expert propose  defect prediction  non negative sparse graph adaboost algorithm improve performance model experimental  effectively issue imbalance label instance insufficiency research software defect prediction technique DBN cnn leveraged belief network DBN construct expressive feature initial feature experimental DBN significantly improve prediction performance defect prediction baseline model source project propose defect prediction framework  automatically extract feature representation code commit message convolutional neural network cnn experimental variant   combine achieve prediction performance construct novel defect prediction model  identify important feature utilize cascade strategy convert random classifier layer layer structure experimental effectiveness model adopt DBN cnn  baseline defect predictor WSHCKE predictor researcher paid attention data preprocessing rodríguez data preprocessing sample sensitive integration experimental significantly improve prediction performance propose stage semi supervise integration prediction capability unbalanced dataset classical machine analyze eleven algorithm data sample technique imbalance data negative impact prediction performance aspect mention aspect prediction performance superior previous mainly machine employ advanced technique boost prediction performance moreover conduct image classification  combine cnn extreme machine elm unlike research combine cnn kernel extreme machine KELM conduct software defect prediction task adjust network structure parameter suitable software defect datasets feature selection extraction software defect prediction recently feature selection extraction technique introduce software defect prediction eliminate irrelevant redundant feature feature selection decrease feature optimal representative feature subset feature extraction reduce feature building combine feature feature feature selection mainly filter wrapper wrapper algorithm classification algorithm filter feature depends feature specific algorithm computation filter faster performance cannot guaranteed filter prior mainly utilized feature selection conduct defect prediction feature extraction thoroughly investigate software defect prediction previous filter feature selection software defect prediction combine multiple feature selection technique representative feature subset ensemble propose sensitive feature selection sensitive variance  sensitive laplacian  sensitive constraint  incorporate information traditional feature selection experimental outperform exist stage sensitive classifier traditional blind feature selection conduct comprehensive empirical survey seventeen feature rank commonly feature rank signal filter threshold feature rank experimental ensemble ranker effective outperform ensemble multiple ranker filter feature rank technique information gain IG gain ratio GR sixteen defect project propose feature selection feature spectral cluster feature rank  predict software defect investigate feature selection filter subset filter rank wrapper subset feature selection classification promise nasa datasets experimental verify correlation feature selection  performs feature selection apply wrapper feature selection technique software defect prediction research impact feature selection technique wrapper technique software defect prediction experimental feature selection technique significant performance difference software project survey wrapper feature selection feature rank embed selection multiple software project feature extraction prior adopt principal component analysis pca  gupta kernel principal component analysis KPCA feature extraction software defect prediction utilized pca conduct defect prediction void issue multicollinearity independent variable  gupta pca feature selection experimental demonstrate pca perform leveraged KPCA project data latent feature nonlinear mapping experimental verify effectiveness KPCA previous feature selection software defect prediction leverage recently propose whale optimization algorithm WOA another complementary simulated anneal SA construct enhance metaheuristic feature selection algorithm instead algorithm attempt apply hybrid algorithm contains exploration orient algorithm population WOA exploitation orient algorithm SA feature selection software defect prediction addition unlike hybrid model teamwork hybrid lth relay hybrid  WOA SA propose   adopt roulette selection selection mechanism exploration stage logistic regression algorithm classifier feature selection   apply model software defect prediction intelligent algorithm optimization application technique software engineering recent researcher already apply technique cnn DBN improve task software engineering combine fourteen feature generate feature belief network DBN software defect prediction classifier construct defect prediction model model detect important defect feature cascade transforms random classifier layer layer structure verify extent nlp practically apply detect defect requirement document railway signal manufacturer combine information retrieval thereby enhance performance defect location cnn feature source code text defect report combine feature unified feature defect location propose defect prediction framework  automatically extract feature representation code commit message convolutional neural network cnn experimental variant   combine achieve prediction performance zhang utilized feedforward neural network fnn regularization technique predict performance highly configurable software experimental verify superiority approach eleven public available datasets propose neural model generate coherent summary combine code structure abstract syntax ast code experimental model outperform baseline model software engineering SE literature processing nlp literature technique report classification link prediction developer online forum software traceability conclusion future construct enhance metaheuristic feature selection algorithm EMWS effectively selects closely related representative feature software project advantage local capability SA enhance weak exploitation performance WOA leverage global capability WOA boost weak exploration SA simultaneously leverage hybrid neural network cnn KELM construct unified defect predictor WSHCKE accord defect feature EMWS algorithm integrate defect feature robust semantic feature cnn boost prediction performance utilize classification capacity KELM classifier conduct extensive feature selection extraction defect prediction widely software project evaluation indicator EMWS algorithm eleven feature selection extraction WSHCKE model classic defect predictor experimental verify EMWS WSHCKE outperform baseline basically future evaluate model source commercial project automate parameter optimization technique adjust parameter setting addition extend model multi source project version defect prediction effort aware defect prediction