description request PRs developer modification correspond PRs although PRs developer improve development efficiency developer usually ignore description PRs alleviate researcher generally utilize text summarization model automatically generate description PRs however rnn model challenge efficiency vocabulary OOV influence performance improvement model bottleneck propose novel model aim challenge PRHAN request description generation hybrid attention network specifically core PRHAN hybrid attention network faster execution efficiency rnn model moreover address OOV utilize byte encode algorithm vocabulary sub vocabulary OOV combine sub reduce sensitivity model effective entropy loss function label smooth baseline model leadcm transformer model built evaluate model source dataset rouge bleu evaluation experimental demonstrate PRHAN effective baseline moreover PRHAN execute faster model propose previous keywords PR description hybrid attention byte encode label smooth introduction request  PR PRs developer others repository collaborative cod platform github PR developer discus review potential collaborator commits merge therefore collaborative cod platform git technique developer contribution project request although access central repository request verify review core collaborator merge central repository generally PR compose correspond description related commits PR numpy project content PR developer correspond motivation    furthermore PR contains commits commit code comment commit correspond code comment PR enables reviewer developer quickly understand project improve development efficiency project however accord investigation literature PRs incomplete developer usually omit description PRs decrease development efficiency therefore construct effective model automatically generate PR description becomes important issue transform PR description generation task text summarization technology text summarization integrate attention mechanism pointer network critical sequence training  construct seqseq model generates PR description summarize commits dataset achieve competitive experimental metric rouge however approach performs badly bleu metric intuitively effective model perform relevant metric rouge bleu metric evaluate effectiveness propose model code summarization task undoubtedly model achieves competitive rouge bleu metric accord investigation dataset inference PR summarization longer generate approach contrast rouge metric bleu metric introduces brevity penalty penalize generate text reference text therefore rouge metric cannot comprehensively reflect effectiveness model improvement automate PR description generation image KB image PR numpy project improve quality automatically generate PR description propose novel approach PRHAN request description generation hybrid attention network improve performance aspect propose novel architecture hybrid attention network han han construct PR description generation model rnn approach han context information model generate quality PR description moreover due replace rnn architecture model faster execution efficiency effectively address OOV vocabulary exploit byte encode BPE PR dataset OOV combine sub vocabulary introduce label smooth technology entropy loss function model generalization evaluate performance PRHAN leadcm transformer approach propose baseline model conduct series source dataset contains PRs dataset project ensure obtain realistic experimental illustrate model outperforms baseline rouge bleu respectively besides evaluation model experimental PRHAN generate quality PR description researcher quickly reimplement approach code available github sum contribution improve quality automatically generate PR description propose han approach PRHAN knowledge automatically generate PR description solely han vocabulary compose sub BPE effectively address OOV additionally enforce generalization PRHAN introduce label smooth technology evaluate effectiveness PRHAN public dataset automate metric evaluation experimental demonstrate PRHAN performs baseline effectiveness besides faster execution efficiency model propose remain introduces background knowledge PRHAN motivation elaborate PRHAN detail han BPE label smooth setup experimental experimental setup experimental respectively discussion advantage limitation PRHAN introduce related finally conclude future research background motivation introduce background approach seqseq model attention mechanism afterward introduce motivation seqseq model seqseq sequence sequence propose   entire input fix vector perform machine translation afterward formally construct seqseq model machine translation task lstm model construct encoder mapping source fix vector encoder another lstm model construct decoder mapping fix vector target model promote development processing nlp recently seqseq model achieve nlp task machine translation text summarization recognition focus automatically generate quality PR description commits message text summarization regard PR description generation summarization commits message PR therefore advantage seqseq model automate PR description generation model attention network global attention network perform attention network san achieve global attention PR text PR text applies embed relatively pas embed vector linear projection obtain query vector vector vector define denotes embed vector learnable parameter obtain context vector contains semantic information entire PR dot attention model define factor avoid gradient disappear explosion model training phase feature dimension normalize function attention matrix obtain output global attention network san proficient capture dependence output global attention network contains abundant global semantic information model dependency local attention although san effectively capture dependency operation attention encodes disperse distribution attention ignores relation therefore introduce local attention attention specifically utilize gaussian bias denote local attention relevance central introduce later define standard deviation prior empirically calculate central goal normalize max input PR sequence calculate input sequence predict central correspond query vector query vector respectively trainable linear projection activation function learnable parameter gain local attention matrix exponential operation function local attention matrix transform attention distribution output local attention network calculate san capture dependence local attention effectively relation model local dependency motivation automatically generate description PRs propose attentional encoder decoder model model achieve rouge metric however source code stage training model moreover training stage tesla gpu although data model suitable dataset expensive consume however dataset becomes rapid development software additionally PR description generate shorter reference PR description additionally average PR description generate shorter dataset specifically PR description dataset longer generate although model achieve rouge metric model perform badly bleu metric bleu introduces brevity penalty penalize generate text reference text intuitively effective model perform relevant metric imply model cannot fully sufficient context information generate PR description therefore dive model effective model specifically rnn model cannot fully exploit gpus accelerate computation lstm output depends output output encoder input encoder therefore rnn model cannot achieve parallel compute gpus performance cannot accelerate rnn model besides lstm fully sufficient context information purpose  rouge metric directly optimize model decrease sensitivity model slight difference prediction truth however  stage training mode consume training phase model built vocabulary unique frequency integrate pointer network address OOV model complicate pointer network introduces parameter comparison PR description generate PR description dataset avg average PR description  dataset motivate mention actively explore transformer san enables achieve parallel compute context information achieve nlp task inspire novel architecture explore attention network construct suitable model PR dataset addition vocabulary OOV  adopt sub encode technique PR dataset finally introduce label smooth technology model reduce sensitivity neural network model slight difference enforce generalization exploration phase data pre processing apply BPE PR dataset construct vocabulary unique sub OOV combine sub directly utilize han construct model PRHAN account effectiveness efficiency automatically generate PR description PR han combination san local attention network learns sufficient context information achieve parallel compute finally optimize PRHAN label smooth entropy loss function reduce sensitivity neural network model slight difference enforce generalization moreover label smooth complicate model approach attention approach achieve nlp task inspire han combine global attention local attention network utilize han construct PRHAN PRHAN detail han BPE label smooth byte encode byte encode propose  compression algorithm combine frequent byte iteration apply BPE neural machine translation effectively alleviates OOV specifically BPE vocabulary fix vocabulary variable sequence BPE conduct sub encode initial vocabulary transforms sub therefore although vocabulary combine sub BPE improvement nlp task machine translation text classification implementation BPE introduce toy suppose corpus contains frequency firstly decompose minimum initial secondly minimum accord token frequency hence combine minimum sub sub initial vocabulary remove minimum sub finally frequency adjacent minimum vocabulary compress vocabulary BPE corpus vocabulary compose sub  est therefore although corpus combine sub est hybrid attention network leverage global local semantic information global local attention network construct hybrid attention network merge attention network generally directly addition operation achieve goal however operation cannot balance global local attention model cannot effectively advantage attention network therefore introduce learnable gate scalar achieve dynamic balance calculate sigmoid activation function described learnable parameter therefore output han compute vector contains abundant global local semantic information PRHAN sufficient context information generate quality PR description label smooth training neural network tend become confident prediction PR description generation task phenomenon reflect entropy loss function punishment slight difference prediction truth unfortunately influence performance generalization model alleviate integrate  reinforcement technology enables directly utilize rouge metric optimize model therefore model generate valid PR description however optimization mode stage training complicates model increase training moreover although  model obtain rouge model performs badly bleu metric therefore another effective objective label smooth effective training neural network effectively improve accuracy image classification machine translation recognition label smooth neural network become humble suspicious entropy loss function PRHAN encourage generate diverse PR description reduces sensitivity entropy loss function enforces generalization PRHAN specially label smooth complicate model extra entropy loss function label smooth entropy loss function training training phase calculate vocabulary distribution output han learnable parameter calculate predict token input decoder output encoder optimize model minimize revise entropy loss function trainable parameter truth token vocabulary mixture truth distribution random distribution define label smooth parameter introduce label smooth encourage PRHAN generate fluent generalization therefore reduce sensitivity entropy loss function improve generalization ability PRHAN besides adam optimizer optimize revise entropy loss function workflow PRHAN utilize BPE vocabulary unique sub vocabulary generate dataset compose sub afterward generate dataset model minimize revise entropy loss function training generate PR description PR inputting model setup dataset baseline dataset conduct source dataset specifically repository contains merge PR project accord merge PRs repository literature author randomly data dataset validation respectively remain data training however accord code project similarity therefore dataset PR project training dataset dataset simultaneously obtain evaluation dataset project randomly project dataset validation respectively remain project model dataset project difference validation dataset dataset prior apply pre processing filter non english tokenizing remove non ASCII token data utilize BPE perform compression operation pre data project generate dataset compose sub vocabulary contains unique sub PR pre processing statistic dataset project denotes project request description  training java validation java java image KB image PR denotes connection baseline leadcm PR sequence leadcm output commit message correspond description description generate leadcm commit message PR developer accustom commit core PR commit usually summarization commit reimplement leadcm transformer achieve task nlp transformer model code summarization task achieve java dataset ahmad relative encode pointer generator transformer enrich local context information alleviate OOV transformer representative implement transformer source code propose model aim task automatically generate PR description propose novel seqseq model integrates pointer network attention mechanism  source code dataset project evaluation metric prior PR summary task rouge metric evaluate model rouge metric text summarization highly correlate evaluation mainly rouge rouge rouge evaluate model metric calculate recall precision respectively specifically calculate rouge recall precision rouge denote PR description generate model reference description dataset respectively gram denote frequency occurs respectively rouge usually express percentage rouge quality generate PR description bleu quality bleu widely code summarization task PR description generation task code summarization task moreover effective model perform relevant metric specific definition bleu metric brevity penalty avoids shorter generate comment factor empirically geometric average modify gram precision accord previous bleu indicates bleu accurate fluent generate PR description comprehensively effectiveness model extra calculate rouge bleu express rogue bleu setting training phase model epoch revise entropy loss function evaluate model epoch specific parameter inference phase leverage beam algorithm generate PR description sequence beam algorithm software engineering nlp task code comment program repair machine translation text summarization parameter setting training   GB  GB feature dimension   han dropout label smooth  rate  iteration research focus research RQ image KB image motivation RQ verify PRHAN generate quality description PRs achieve goal utilize baseline PRHAN generate PR description PRs quality generate PR description rouge bleu RB metric approach model leadcm transformer model propose baseline evaluate performance baseline model PRHAN quality PR description generate rouge rouge rouge bleu RB generate PR description therefore effective model perform metric image KB image motivation RQ aim explore model efficiency although model generate valid PR description amount training generate PR description oppose model model PRHAN solely han execution efficiency therefore verify efficiency PRHAN approach firstly parameter model compute training generation sample directly reflect efficiency model image KB image motivation described PRHAN han addition introduce independent BPE label smooth improve performance PRHAN BPE aim OOV vocabulary label smooth reduces sensitivity PRHAN boost efficiency effectiveness therefore goal RQ verify validity component PRHAN approach evaluate effectiveness component extra model han BPE han han BPE denotes remove label smooth PRHAN han BPE denotes remove label smooth PRHAN RQ rouge bleu metric evaluate model verify effectiveness component experimental RQ model effectiveness performance baseline model  metric rouge rouge rouge bleu RB rouge metric calculate comprehensively reflect effectiveness model metric rouge  outperforms leadcm transformer liu model respectively rouge metric  outperforms leadcm transformer liu model respectively metric rouge  performance improvement leadcm transformer liu model respectively metric baseline  sufficient context information PR generate quality PR description comprehensively evaluate model extra calculate bleu RB bleu PRHAN outperforms baseline margin bleu introduces brevity penalty penalize generate text shorter reference text therefore bleu stricter metric model generate accurate PR description model sufficient context information PR baseline model PRHAN combine attention network fully advantage BPE sufficient context information PRs RB metric bleu baseline model PRHAN outperforms margin effective model perform relevant metric experimental PRHAN effective model automate PR description generation evaluate baseline PRHAN rouge bleu RB metric PR description generate PRHAN model accord investigation PR description generate shorter reference PR description PR description reference PR description PR description generate PRHAN shorter reference PR description reference PR description PRHAN obtains metric PRHAN generate quality PR description image KB image performance comparison  baseline model metric rouge bleu RB  rouge rouge  RB leadcm transformer liu  RQ model efficiency parameter model PRHAN therefore model memory GB PRHAN batch model almost memory gpu model efficiency fairly model experimental environment experimental demonstrate model PRHAN spends training PRHAN training dataset dataset becomes rapid development software  executes faster model suitable although model becomes faster batch suitable dataset cannot gpu memory increase iteration image KB image comparison efficiency model propose PRHAN parameter denote model parameter memory denotes gpu memory  liu GB PRHAN GB RQ ablation PRHAN seqseq model han vocabulary cope OOV introduce BPE additionally label smooth entropy loss function reduce sensitivity model enforce generalization utilize BPE vocabulary han BPE outperforms han rouge rouge rouge bleu RB respectively BPE helpful improve performance sub OOV rouge OOV harmful rouge metric continuity improvement bleu demonstrates BPE model generate fluent PR description reference PR description performance han BPE improve introduce label smooth label smooth brings improvement han BPE rouge rouge rouge bleu RB respectively therefore label smooth effectively reduce sensitivity model generate quality PR description label smooth cannot extra parameter model increase training effectiveness component  rouge rouge  RB han han BPE PRHAN moreover extra influence performance PRHAN parameter component han mainly evaluate influence PRHAN stack han layer feature dimension BPE generate multiple vocabulary estimate model PRHAN metric rouge rouge rouge average metric respectively increase rouge rouge rouge average PRHAN achieves performance distinctly stack han layer PRHAN obtains rouge rouge rouge average although stack han layer enables PRHAN obtain PRHAN han layer parameter han layer therefore PRHAN built han layer feature dimension achieve vocabulary PRHAN significant improvement rouge rouge rouge average therefore vocabulary choice image KB image image KB image influence PRHAN feature dimension respectively image KB image influence PRHAN layer han image KB image influence PRHAN vocabulary vocabulary respectively discussion propose model described han compose global attention network local attention network han model global information local information PR model deeply understand PR generate suitable description although han sufficient context information serious OOV PRs limit ability han context information PRs dataset PRs OOV token PRs OOV token alleviate OOV introduce sub encode BPE BPE vocabulary sub combine sub vocabulary although dataset training dataset combine sub vocabulary sub vocabulary PRs dataset OOV vanishes therefore BPE effectively OOV  potential han additionally BPE reduce vocabulary sub baseline PRHAN generate quality PR description han learns sufficient context information PR sub evaluation PRHAN achieves rouge bleu metric however rouge bleu automatic metric literature indicates obvious evidence correlation automatic metric evaluation comprehension cod task therefore conduct evaluation effectiveness PRHAN prior invite evaluator quality PR description generate approach baseline  developer java program proficient english evaluator PR description generate concerned model reference PR description quality generate PR description aspect similarity generate PR description reference naturalness generate PR description grammar fluency informativeness generate PR description amount content input PR generate description ignore fluency specifically randomly PRs dataset approach baseline generate PR description PR description generate PR PR description evaluator random PR description generate leadcm transformer model  evaluator output generate model generate questionnaire independently conduct generates questionnaire evaluator quality PR description generate model accord reference PR description quality generate PR description reference naturalness enrich informativeness remove quality PR description evaluator therefore PR description generate model obtains quality calculate average PRHAN obtains automatic conclusion PRHAN generate quality PR description baseline however PRHAN perform introduce detail evaluation baseline model PRHAN  leadcm transformer PRHAN PRHAN fail perform although PRHAN generate quality description PRs dataset realize PRs dataset contains sufficient text information PRHAN perform however PRs dataset without sufficient text information text information PRHAN perform automatic evaluation PRHAN cannot generate quality description PRs PRs lack text information PRs sufficient text information PRHAN cannot generate valid description PRs without sufficient text information inspire bug report enrichment enrich PR without sufficient quality text information PR usually related source code PR enrich introduce semantic information source code alleviate lack text information PRs future threat validity internal threat internal threat propose model focus aspect threat experimental environment threat evaluate model server however replicate baseline model performance deviation extend mitigate threat baseline model source code threat  experimental complexity neural network experimental cannot fully performance model mitigate threat average experimental external threat external threat dataset although PRHAN performs cannot applicable dataset dataset generalization ability propose model related related summarize software summarize software artifact attention mechanism automate description generation software commits PRs release software modification distinct granularity commit individual file file PR repository usually contains multiple commits release deployable software iteration package available wider audience automatically generate commit message summarization propose  propose  recognize stereotype modify commit introduce abstract syntax utilized pre define filter template generate description commit similarly construct seqseq model performs joint model code structure code semantics source code encoder apply mechanism mitigate OOV decoder propose reuse exist comment historical version generate commit description built seqseq model attention network adopt model generate commit comment diffs construct contextualized code representation utilize contextual information code commit sequence researcher propose approach automatic release generation construct generate release arena arena summary commit release generates release manually define template combine summary accord relevant information issue tracker manually analyze multiple release software identify information release machine algorithm recommend issue release PRs researcher mainly focus understand PRs development priority prediction PRs reviewer recommendation PRs popularity analysis development model motivate task propose automatic PR description task facilitate downstream task integrate pointer network built attentional seqseq model besides directly utilized rouge metric model introduce  difference approach propose generate description request mention approach mainly utilize hybrid attention network implement task performance effectiveness efficiency summarize software artifact software summarization source code app review another research pot source code recent research focus model propose code NN model attentional seqseq model code NN structure information source code attentional seqseq model introduce structure traversal traverse abstract syntax introduce graph attention network utilized contextual information generate valid code comment contrast traditional seqseq model building recurrent neural network variant han construct seqseq model app review built surf capture user review useful developer via conceptual model generate agenda recommend software summarize user review construct  summary app review multiple perspective salient topic abnormal topic difference mention approach automatically generate description request developer easily understand developer correspond addition utilize hybrid attention network implement goal performance conclusion commit improve performance PR description generation model effectiveness efficiency aim aspect propose novel model PRHAN training phase BPE reduce vocabulary address OOV training phase PRHAN solely han faster execution efficiency prediction accuracy besides utilized label smooth revise entropy loss function reduce sensitivity PRHAN enforce generalization ability experimental source dataset illustrate PRHAN effectively generate description PRs future focus aspect dataset develop useful effectively generate description PRs apply component PRHAN software engineering task source code summarization bug report summarization