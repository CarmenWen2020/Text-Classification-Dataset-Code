extensively variety software engineering task program classification defect prediction although technique eliminates feature engineering construction source code model significantly affect performance task recent mainly focus complement ast source code model introduce contextual dependency extract cfg however attention representation basis contextual dependency integrate ast cfg propose novel source code model embed hierarchical dependency neural network depends graph attention mechanism specifically introduce syntactic structural correspond ast source code model sufficient information gap evaluate model practical software engineering task model significantly improve performance perform baseline model reduces parameter achieves improvement accuracy program classification task previous keywords graph neural network program analysis abstract syntax graph introduction recently increasingly apply program analysis task program classification software defect prediction code summarization however performance task heavily depends choice source code model abstract syntax ast graph cfg hybrid model moreover structure ast adopt analysis ast source code model ast partial ast syntactic structure within ast illustrate information source code subtle however contextual dependency implicit ast cannot extract learnt effectively contrast cfg source code model contextual dependency learnt effectively graph neural network nevertheless cfg  information statement therefore research propose methodology embed contextual dependency cfg ast hybrid ast core source code model contextual dependency additional ast assistant feature however basis contextual dependency paid attention exist methodology contextual dependency effectively argue feature prioritize motivational code promise dataset defect return null  correspond fix return array analyze observation observation defect depends actual execution defect trigger met however caller  function properly handle exception defect trigger reasonable source code model reflect execution furthermore invocation  outside document source code model limited granularity image KB image motivate promise dataset interpretation reference legend reader refer web version article observation source code slightly semantics difference source code choice return identifier  null code exception  refers difference source code actually difference null moreover model textual feature bag null  uneven null occurs frequently  difficulty model difference accord observation cfg intuitively become choice source code model cfg potential execution construct granularity exists issue within cfg exist cfg mainly bag however accord observation utilize textual feature significantly relies frequency occurrence cannot effectively capture difference distinguish  null argue source code model introduce semantic difference difference null model textual distinction motivate observation propose novel source code model specifically overcome limitation mention observation cfg dataflow ECFG reflect actual execution backbone source code model address observation ast ast subtrees correspond ECFG source code illustrate benefit  null keyword syntax brings ast structure sum model outer inter procedure ECFG express dependency inner ast express structure source code model advantage benefiting ECFG granularity source code model flexibly adjust benefiting ECFG source code model potential execution explicitly contextual dependency capture effectively graph neural network benefiting substructure ast source code model informative representation hence feature within capture effectively neural network furthermore multi graph neural network MFGNN extract feature source code model calculation MFGNN obtain feature local feature  collection ast substructure correspond ECFG extract feature contextual feature ECFG local feature ECFG graph multi typed adopt attention mechanism slightly modification graph attention network gat specifically modify model graph multi typed attention graph network graph AGN4D apply apply fusion layer coalesce feature hybrid feature subsequent task specific contribution propose source code model combine ast cfg dataflow ECFG source code model reflect contextual dependency syntactic structure allows neural network richer program feature model obtain contextual semantics source code model namely multi graph neural network MFGNN MFGNN integrates attention graph layer evolves gat MFGNN implement evaluate typical task namely program classification software defect prediction code clone detection MFGNN extract richer program feature hence greatly improve performance task remainder organize introduces background describes source code model MFGNN report experimental evaluation respectively related finally conclude background introduce concept program representation program token sequence ast cfg ast cfg adopt widely introduce abstract syntax abstract syntax ast representation abstract syntactic structure source code program node ast  syntax program source program graph structure ast syntactic information program ast widely variety software engineering task graph graph cfg graph node namely sequentially execute instruction sequence cfg mostly static analysis compiler application accurately inside program graph reachability analysis cfg inaccessible code program syntax structure loop source code model cfg usually contextual dependency significant impact performance software engineering task graph neural network graph generic data structure effectively abstract connection widely across multiple domain social network chemical interaction knowledge model graph neural network GNNs information within graph obtain embed vector graph model GNNs mostly message passing mechanism consist function message function aggregate function message function transform vector node obtain hidden vector aggregate function aggregate transform vector node adjacency node obtain embed vector node message function generally parameter initial feature node transform feature node message function define initial dimension node feature transform dimension node feature GNNs aggregate function gcn summation aggregate function define collection adjacency node gat attention mechanism aggregate function gat calculates attention graph define concatenation operation attention mechanism gat linearly combine transform feature node accord attention define nonlinearity function image KB image comparison motivate combination cfg ast sequential execute orange conditional  false dash purple dataflow interpretation reference legend reader refer web version article approach introduce source code model model MFGNN construct graph combine ECFG ast combination ECFG ast program dependency graph backbone graph inter procedural cfg cfg program graph collection contains relationship address code llvm IR jimple java intermediate representation generate cfg analysis framework clang soot java motivate conclude precise model essential analysis therefore ast model express syntactic structure code information enrich information ast introduce data variable subtrees ast inherently lack information corresponds variable usage  node clang specifically data directly leaf node variable node user define refer mention accord camel conversion statement target accord ast subtree conversion node another aspect constant handle constant disassemble constant bitwise constant node disassemble node respectively address lack dataflow dependency ast cfg addition exception relationship cfg introduce data relationship graph specifically dataflow relationship intra procedural dataflow analysis traverse cfg built collection variable variable define variable dataflow relationship obtain definition analysis later category accord functionality sequential execution conditional conditional false switch category relationship label distinctly overall source code model graph motivate snippet respectively ast difference local feature version ast indicates static return faulty version ast indicates null return slight textual difference  null easily learnt neural network due significant difference ast dataflow dash purple jointly variable conditional orange precondition faulty combine difference local feature source code model context feature multi graph neural network neural network model obtain feature representation model multi graph neural network MFGNN overall structure model stage local feature embed stage contextual feature embed stage fusion stage stage network local feature stage attention graph neural network graph AGN4D contextual feature combine graph local feature stage fusion layer fuse local feature contextual feature contextual semantics obtain local feature embed convolutional neural network  obtain local feature  suitable extend ast additional content leaf node extend ast  ignores deeper node ast richer information therefore adjust preset  increase deeper node convolution  node richer information significant impact training model formula depth node entire depth entire node subtree sibling importance local feature fold feature local feature input AGN4D contextual feature local feature critical role within feature pas local feature fusion layer directly contextual feature embed source code model graph therefore gat network layer nest MFGNN attention graph neural network graph AGN4D handle graph multiple AGN4D extract contextual feature combination graph suppose instance combine graph reverse graph local feature obtain previous stage initial graph embed graph embed update collection successor graph reverse graph function graph layer reverse graph refers function graph layer reverse graph function function parameter layer obtain graph embed graph graph embed previous layer layer skip connection obtain graph representation layer function transform graph embed previous layer obtain feature layer parameterized matrix define function aggregate feature successor multiple attention mechanism gat define attention mechanism parameterized indicates importance dependency pas layer AGN4D fusion layer contextual feature fusion layer functionality fusion layer fuse local feature contextual feature hybrid feature program fusion layer local feature contextual feature fix program feature vector dynamic pool max pool pool function finally classifier logistic regression LR classification task evaluation conduct series evaluate MFGNN comparison exist gpus machine xeon GB ram research evaluate effectiveness source code model MFGNN particularly task particularly research RQ performance MFGNN classify datasets consists program textual semantic difference RQ performance MFGNN within project defect prediction WPDP task RQ performance MFGNN project defect prediction CPDP task RQ performance MFGNN functional code clone detection ccd task RQ extent component MFGNN influence performance datasets RQ RQ datasets namely    dataset compose submit user challenge namely sub  sum however challenge trivial implementation gcd algorithm cannot evaluate effectiveness thoroughly manually dataset namely  public website specifically consists submit user challenge challenge involve  dataset variety algorithm complicate disjoint union dijkstra greedy algorithm specifically detailed description challenge described statistic program classification dataset RQ RQ   instance avg code avg avg operator binary interval interval frequency interval calculate formula prefix sum algorithm challenge graph shortest specific node dijkstra algorithm challenge undirected graph component graph disjoint union challenge graph multiplier lcm calculate graph challenge correctly algorithm lcm algorithm collection interval subset minimum sum satisfy intersect interval greedy algorithm challenge program datasets label correspond program meaning label detailed accepted AC program pas WA program execute normally output incorrect runtime error program cannot execute normally generally due illegal memory access operation error zero limited exceed  program response within limit memory limited exceed MLE consume resource memory exceed requirement AC correspond defect source code source code  contains redundant loop source code WA contains functional error therefore argue reasonable source code model reflect difference classify effectively additionally conduct pre processing datasets remove source code irrelevant correspond challenge remove duplicate datasets avoid mislabeling generate accord requirement correspond challenge source code label label finally dataset challenge split training validation ratio metric datasets RQ RQ another public dataset namely promise widely software defect prediction consists source java project jedit version cannot compile properly remain java project correspond version identical previous comparison finally source code file cannot successfully soot generator remove dataset statistical description dataset RQ RQ remain research RQ public dataset namely  adopt online program judgement source code specifically  contains program task compose source code file submit user task user source code pas AC verdict functional code clone source code dataset label non clone clone similarly classify task shuffle split dataset training validation ratio statistic promise dataset specialized RQ RQ    rate lucene synapse xerces xalan camel logj ant jedit poi ivy setting setup RQ involve detailed setting choice baseline comparison metric setting MFGNN input MFGNN consists collection ast node vector collection ast substructure mapping graph mapping substructure correspond ECFG hyper parameter embed dimension ast node dimension AGN4D stack layer MFGNN optimize adamax epoch training parameter MFGNN perform validation evaluate setting baseline RQ illustrate effectiveness MFGNN representative comparison svm approach chose svm approach demonstrate datasets   consist source code textual semantic distinction classify source code file accord textual feature indistinguishable source code svm perform textual distinguishability dataset TF idf bow feature textual feature rbf kernel svm ast approach illustrate advantage source code model ast program classification chose typical ast approach specifically accord ast granularity ast approach category entire ast source code representative  lstm split ast accord code fragment  moreover codevec adopts ast source code learns feature network attention mechanism similarly codeseq codevec extract feature seqseq model setting ast approach ast    generate clang ast codevec codeseq generate  codevec embed dimension codeseq embed dimension decoder dimension hidden dimension graph approach recent focus program graph adopt graph extract dependency feature graph DGCNN chooses cfg source code model obtains feature gcn   insert extra dataflow ast extract feature GGNN setting graph approach GGNN hidden graph approach RQ evaluate performance MFGNN within project defect prediction WPDP task accord previous defect prediction task strategy training earlier version predict later version MFGNN typical WPDP accord adopt source code model defect prediction technology feature promise traditional machine adaboost multi layer perception mlp random RF others utilize ast feature representative specifically DBN obtain semantic feature ast classify feature classifier naive bayes logistic regression decision  ast parse  entire ast input prediction additionally chose another  DP  former visualize source code file binary file image obtain defect feature alexnet later acquire contextual dependency cfg DFG introduce ast feature RQ conduct project defect prediction CPDP performance MFGNN previous organize model source project predict target project target project accord transfer randomly data tune LR classifier predict DBN replace CPDP variant DBN CP chose baseline RQ additionally transfer namely TCA TNB promise feature machine RQ conduct functional code clone detection ccd demonstrate distinguishability semantics obtain MFGNN feature source code file within obtain MFGNN respectively difference define finally LR classifier code vector performance MFGNN model widely ccd task rae      RQ ablation approach source code model ECFG model AGN4D layer firstly explore impact choice source code model option ast bow feature dataflow embed source code model multi typed typed variant combination option ast cfg model cfg distinction ASTs ast DFG model DFG ASTs ast cfg multi model cfg distinguishes ASTs bow cfg DFG multi model cfg contains dataflows distinguishes bow secondly explore impact graph replace AGN4D layer graph convolution network gcn gate graph neural network GGNN respectively additionally across option AGN4D summation concatenation synthesize graph feature source code model metric RQ RQ chose accuracy macro evaluate prediction assume task accuracy define refers positive sample binary classification task define denotes positive false positive refers false negative multi label classification task binary classification task label assume task macro define RQ RQ addition buggy metric auc receiver operating characteristic curve evaluate performance defect prediction specifically auc refers probability classifier rank randomly positive sample randomly negative sample intuitively auc implies performance RQ evaluation metric previous precision recall performance model ccd task performance program classification task parenthesis parameter    TF idf svm bow    codevec codeseq  DGCNN  MFGNN RQ illustrates related RQ performance highlight bold correspond model svm approach  accord experimental insight dataset consist source code minimal textual difference svm reflect correspond indicates source code label dataset cannot effectively distinguish textual feature prof textual difference source code dataset distinguish effectively ast approach MFGNN achieves performance parameter  ast approach MFGNN reduces model parameter achieve improvement accuracy respectively additionally codevec codeseq perform model source code sample ast capture potential connection code token program classification task however identification actual dataflow information program execution cannot achieve model contrary source code model reflect actual execution program contextual information capture neural network MFGNN achieves significant performance improvement limited parameter graph approach graph approach DGCNN MFGNN increase parameter achieves improvement accuracy respectively similarly DGCNN parameter MFGNN MFGNN achieves improvement accuracy respectively illustrates performance MFGNN correlation parameter difference MFGNN traditional graph fold integration multiple information source code model clearly express dependency feature program attention mechanism allows MFGNN dynamically adjust mining feature WPDP promise    ant camel ivy jedit lucene logj poi synapse xalan xerces avg RQ performance approach within project defect prediction WPDP task performance highlight bold due limitation soot exception data item dataset lose entry project distribution dataset actually differs previous ensure fairness comparison implement DBN  mention multiple parameter randomly multiple namely  MFGNN achieve improvement auc respectively moreover MFGNN auc respectively  specifically auc model confidence prediction difference MFGNN ECFG source code model allows MFGNN capture contextual dependency  MFGNN improve auc respectively significant improvement attribute structural difference fold representation accord source implementation  embeds MFGNN ast ast feature  learns feature sample  adopt feature MFGNN graph MFGNN AGN4D capture dependency feature graph  nodevec information pdg advantage AGN4D nodevec introduction attention mechanism allows dependency feature fuse conclusion hybrid feature obtain MFGNN perform WPDP task CPDP promise RQ project defect prediction CPDP task mention RQ mainly evaluates contextual feature learnt model apply project propose MFGNN typical CPDP performance marked bold input data performance performance metric marked underline source code model marked MFGNN achieve overall auc metric MFGNN outperform auc respectively source code model MFGNN achieve auc task interestingly  perform WPDP task  auc MFGNN improve respectively improvement difference context dependent information fold  dependency feature assist ast feature MFGNN program context dependent feature critical CPDP task difference discrepancy performance  extract feature cfg DFG separately MFGNN combine ECFG extract feature uniformly AGN4D conclusion contextual feature obtain MFGNN generalize performance CPDP task RQ illustrates related RQ highlight bold MFGNN achieve recall relative precision interestingly  apply graph source code model however argue MFGNN capture program context dependency feature effectively difference graph mechanism adopt  adopt  MFGNN AGN4D attention mechanism adjust dependency information therefore context dependency feature MFGNN identify program variant effectively recall absolute distance feature derive MFGNN data  dot illustrates feature obtain MFGNN effectively distinguish source code functional code clone task conclusion MFGNN improve performance distinguish non clone clone source code ccd task    image KB image sne mapping absolute distance feature interpretation reference legend reader refer web version article RQ adjust default setting methodology performance program classification task default setting highlight bold obtain insight sensitivity dataflow differs challenge DFG source code model challenge sub sum operator within source code challenge complex computational logic related data heavily data critical role however cfg perform adopt DFG introduce cfg poorer performance introduce positive role challenge sub however challenge MFGNN performs source code model untyped challenge others imbalanced distribution ineffective optimization model therefore uneven distribution prevents MFGNN effectively fuse feature ast choice node representation setting ast node representation improve model performance significantly setting approach remove remove data remove approach perform node bag bow model instead ast model bow source code model improvement accuracy respectively node representation independent variable conclude ast node representation option task ast bow lack lexical syntactic structure essential representation ablation   concatenation summation gcn GGNN AGN4D AGN4D choice GNNs examine effectiveness AGN4D alter GNNs gcn GGNN respectively approach comparison AGN4D outperform GNNs average accuracy respectively summation choice concatenation contextual feature embed stage summation graph feature synthesis formula deliver performance concatenation AGN4D hidden dimension layer layer increase model parameter model overfitting issue threat validity conduct factor exist affect validity implementation baseline internal threat validity concerned implementation reproduce    DBN TCA   although implement baseline described cannot guarantee implementation exactly apply baseline dataset task baseline specifically task codevec goal perform function generation  goal perform var misuse detection although baseline cannot guarantee representation model project promise dataset RQ RQ promise dataset dataset version project available web conduct project directly experimental data DBN  cfg difference clang cfg convert program llvm IR address code cfg java soot cfg soot convert program jimple ssa cfg difference intermediate cfg exactly statement conduct task practical datasets evaluate feasibility effectiveness MFGNN conduct task program classification defect prediction datasets consist source code  source project variety evaluate task source datasets limited argue MFGNN robust industrial code perform task however future related source code representation perform program analysis representation model source code fundamental roughly ast cfg specifically ast source code model adopt ast generate program directly modification moreover extract generate ast conduct analysis chose collection ast token token source code model feature attention model unlike model chose split ast subtrees slightly integrity ast explicit contextual dependency cfg reassemble ast dependency salient easy cfg source code model factor significantly affect program analysis role graph specific assembly instruction bag model graph utilized role auxiliary role analysis graph role bag model compose ast grammatical node model similarly adopt graph role correspond subtree ast retain structure ast context independent grammatical difference model program classification program classification distinguish classify program feature various aspect software engineering task application functional code clone detection code snippet implement functionality achieve classify functional feature program functional feature feature defect feature structure feature widely adopt program classification task apply defect feature classify program task dataset code complexity relatively limited construct crawler manual effort software defect prediction software defect prediction challenge task research extensively prior researcher adopt machine achieve goal however technique feature engineering normally resource consume propose svm defect predict depends software metric software complexity metric technique eliminate feature engineering researcher focus improve prediction performance suitable source code model exist source code model contextual dependency distinguish subtle account specifically contextual dependency ECFG subtle subtle grammatical difference structural difference ast knowledge exist source code model achieve goal conclusion propose source code model ECFG attention model namely MFGNN source code model restricts MFGNN extract feature efficient effective MFGNN obtain program feature moreover evaluate MFGNN practical task program classification software defect prediction code clone detection MFGNN significantly outperform baseline source code model codeseq parameter decrease fold overall accuracy increase research illustrate performance heavily construction source code model additionally highlight research direction future apply project improve graph MFGNN performance