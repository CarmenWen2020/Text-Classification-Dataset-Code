neural network dnns various daily task detection processing machine translation however dnns suffer robustness perturbed input adversarial sample misbehavior dnns propose technique momentum iterative gradient bmi FGSM robustness dnn model technique knowledge structure target dnn exist technique access model internal information gradient technique approximates gradient differential evolution approximate gradient construct adversarial sample experimental technique achieve generate adversarial sample trigger misclassification generate sample trigger misclassification specific target output label demonstrates perturbation distance transferability technique technique efficient furthermore conduct commercial aliyun api successfully trigger misbehavior within limited query demonstrate feasibility attack previous keywords adversarial sample differential evolution neural network introduction neural network dnns achieve important application image classification processing machine translation efficacy outperforms software application increasingly dnns critical component  autonomous software ID amazon echo envision dnn model engineering become essential software development lifecycle debug dnn model importance however researcher reveal dnns robustness vulnerable adversarial sample benign input imperceptible perturbation dnns misclassify adversarial sample hinder utilization dnns safety critical related computer vision recognition vehicle medical analysis dnn application adversarial sample threat dnn model efficiently effectively generate adversarial sample expose robustness dnns adversarial sample generation category technique technique former access model internals model structure neuron gradient contrast latter treat model access model internals model output technique broader applicability remote application underlie dnns internet service provider alibaba google apis hide internal detail user technique applicable technique develop adversarial sample generation image classification model assume access model input output approach momentum iterative gradient bmi FGSM modifies input trigger model misclassification aim achieve goal mutation utilize differential evolution approximate gradient direction leverage candidate reuse improve efficiency explain later image KB image propose bmi FGSM imagenet sample adversarial sample misclassified target dnn perturbation magnify visualization bmi FGSM technique untargeted misclassifying output label target misclassifying specific output label transferability adversarial sample generate model trigger misbehavior another model widely datasets model propose bmi FGSM achieve rate untargeted target setting comparable approach generate adversarial sample within faster technique finally apply approach image recognition expose robustness summary contribution propose novel adversarial sample generation bmi FGSM technique knowledge model architecture gradient propose novel improve performance enlarge exploration distance candidate reuse approximate momentum guidance input perturbation critical generate effective adversarial sample bmi FGSM experimental mnist cifar imagenet datasets approach efficient zoo comparable rate MI FGSM furthermore bmi FGSM commercial aliyun image recognition api successfully trigger misbehavior remainder structure review exist research related adversarial sample generation technique research conclusion future related exist dnn robustness adversarial sample generation image classification review subsection dnn robustness robustness critical application dnns popular approach improve model robustness additional training validation data mainly generate additional data data augmentation generative adversarial network gan former augments training dataset transform data rotate flip image gan model compose generator discriminator generator random input mutate valid input discriminator determines mutate input compete ideally generator generate sample however exist data augmentation technique gans limited effectiveness hence practical gauge improve dnn robustness adversarial sample specifically input sample perturbed generate adversarial sample trigger model misclassification training enhance adversarial sample retrain dnn model improve robustness adversarial training dnns sensitive perturbation adversarial sample generation adversarial sample generation categorize assume knowledge target dnn model architecture neuron perturbation input image dnn model misclassification convert generation adversarial sample constrain minimization propose gradient FGSM gradient aim generation propose iterative generate powerful sample introduce momentum propose momentum iterative gradient MI FGSM balance rate transferability carlini wagner propose optimization technique systematically directly optimize perturbation adam optimizer additional propose mechanism binary variable assume access model internals instead query target model input correspond output technique perform model broader applicability assume internal information insufficient training data propose substitute model synthetic training dataset   discover phenomenon merely modify pixel model misclassification expose dnn robustness leverage differential evolution pixel propose zeroth optimization zoo derivative generation author exploit finite differencing calculate approximate gradient analyze loss function another dnn robustness transferability technique query target model neither generate sample instead adversarial sample another model target dnn underlie assumption adversarial sample confuse model likely equally confuse another model therefore transferability important quality metric generalization adversarial aim develop adversarial sample generation feature rate transferability effectiveness parallel adversarial generation remains unique approach evolution strategy finite difference estimate random gaussian basis estimate gradient project gradient descent formalizes gradient estimation develop bandit optimization framework incorporate data dependent information generate adversarial sample threat model leverage differential evolution approximate gradient convert iterative gradient version access model output develops gradient approach generate adversarial leverage genetic optimization fitness function define similarly CW loss prediction model author adopt dimensionality reduction adaptive parameter boost gradient optimization contrast approach model gradient combine candidate reuse strategy enables attack reliably generate adversarial sample another aim generate adversarial sample scenario focus label propose generic optimization algorithm apply discrete non continuous model neural network decision simulates scenario attacker access pool input proposes hybrid strategy combine optimization transferability dnns traditional software behavior DL structure dnns dimension dnn DeepXplore proposes differential algorithm systematically input trigger behavior multiple dnns propose neuron coverage systematically dnn input  coverage fuzzing neural network approximate algorithm  generates maximize activate neuron erroneous behavior realistic blurring fog DeepGauge proposes multi granularity coverage DL internal dnn criterion scalable complex dnns  adapts notion combinatorial introduces coverage criterion neuron input interaction layer dnns generation towards balance defect detection ability  proposes criterion dnns inspire MC DC criterion traditional software evaluate propose criterion neural network defect detection ability random  adapts concept mutation proposes mutation framework specialized dnns quality data mutation promising technique generate quality data exist DL detect erroneous behavior dnns realistic circumstance occlusion mostly focus criterion dnns transparent contrast adversarial sample generation demonstrates erroneous behavior dnns propose DL adversarial sample indistinguishable expose misbehavior attacker perspective bmi FGSM algorithm technique momentum iterative gradient bmi FGSM inspire iterative gradient differential evolution feature mechanism improve efficiency effectiveness generation framework input image pre dnn differential evolution derives gradient population candidate compete correspond perturbed input perturb input approximate gradient adversarial sample benign input image KB image framework momentum iterative gradient iterative gradient introduce differential evolution algorithm improvement mechanism candidate reuse iterative gradient throughout focus classifier dnn model image classification task input image dimension output denotes predict label formally define dnn compute hidden layer neuron matrix logits softmax function normalizes output denotes probability distribution predict label probability input belongs label classification label label probability adversarial sample generation assume dnn model pre fix neuron fix assume access input image output label output confidence assume access structure neuron intermediate output input truth label adversarial sample untargeted sample misclassified false label target sample misclassified specific false label threshold perturbation magnitude limit norm distance iterative gradient generation iteratively calculate gradient perturb input feature efficiency rate extensibility usually propagation craft adversarial sample neighborhood input iterative adversarial sample apply gradient gradient function generation yield superior iterative gradient balance rate transferability improve version iterative introduces momentum replace raw gradient accumulate gradient critical iterative gradient gradient computation attack gradient usually compute propagation differential evolution differential evolution DE evolutionary algorithm optimization DE input objective input mutation phase evolution crossover selection phase evolution crossover candidate generate selection fitness survive chosen iteration evolution DE advantage DE algorithm independent dnn hence improvement DE directly applicable DE solves non differentiable noisy dynamic handle continuous discontinuous without understand internal structure DE heuristic diversity insurance mechanism prevent trap local maximum minimum standard greedy gradient descent cannot algorithm employ DE gradient denote input image truth label output dnn initialize generation denotes gradient candidate generation variable feature randomly initialize population candidate generation visualizes candidate candidate essentially matrix input image image KB image visualization candidate differential evolution pixel denote correspond matrix candidate initial population candidate population evolution crossover generation define denotes factor differential vector denotes crossover probability crossover variant intuitively denotes mutant derive randomly candidate previous generation denote random assign function return valid gradient direction convergence denotes offspring recombine mutant previous candidate feature fitness generation however fitness function candidate gradient convert candidate perturbed image replace candidate apply fitness function dnns although confidence fitness acceptably ultimately fitness function fitness input fitness function aim suppress probability truth label enhance maximum probability false label visualizes candidate evolve generation serf approximate gradient image KB image momentum iterative gradient DE leverage algorithm approximate gradient candidate generate cannot directly candidate convert candidate perturbed image perturbed image fitness offspring candidate fitness approximate gradient additional overhead DE inevitable gradient compute propagation millisecond attack context precise estimation gradient neither image KB image extend bmi FGSM algorithm inherit advantage DE iterative gradient algorithm loop denotes procedure iterative gradient approximate gradient sample apply generate perturbed image sample iteration image return adversarial sample challenge bmi FGSM escape local optimum gain momentum hence mechanism candidate reuse perturbation propose bmi FGSM happens approximate gradient algorithm temporary perturbation perturb sample generate temporary image fitness evaluation loop iterative gradient algorithm permanent perturbation iteratively perturb image image KB image perturbation perturbation distance usually distance DE loop evaluate candidate temporary image perturbed distance DE procedure hence risk stuck local optimum version iterative gradient suffer calculate gradient propagation exploit distance perturbation specifically initialize gradient calculation initialize permanent perturbation iteration perturbed distance hence decrease exploration distance update satisfy parameter overall perturbation distance adversarial sample difference without denotes local optimum movement permanent perturbation denote DE without perturbation trap explore hence procedure escape local optimum intuitively enables considerable perturbation distance approximate gradient dynamic exploration distance enlarges potential achieve fitness assistance improve rate sample generation imagenet candidate reuse training dnns momentum introduce improve gradient descent accumulate gradient raw gradient escape local optimum converge researcher MI FGSM project leverage integrate momentum technique accumulate gradient balance transferability perturbation distance quality adversarial sample accord construct accumulate gradient cannot directly accumulation approximate gradient accumulation error candidate valid accumulate gradient appropriate image KB image candidate reuse novel mechanism candidate reuse achieve gradient accumulation specifically generation candidate gradient technique candidate initial population rate candidate reuse reuse candidate previous iteration gradient information participate evolution role momentum candidate reuse practical attack context accumulate gradient apply candidate reuse bmi FGSM available imagenet intel xeon cpu nvidia tesla gpu model training sample generation aim research RQ bmi FGSM perform exist RQ transferability bmi FGSM RQ candidate reuse improve bmi FGSM model dataset RQ dose bmi FGSM perform application report bmi FGSM substantially faster exist technique achieves comparable performance exist novel mechanism improve performance finally generate adversarial sample aliyun image recognition api RQ performance comparison dataset model mnist cifar datasets randomly image evaluation sample image image apply untargeted attack target generation untargeted sample target sample dataset target dnn model setting carlini wagner accuracy mnist accuracy cifar data normalize classification misclassified image ignore generation comparison mnist cifar propose bmi FGSM adversarial sample generation technique zoo MI FGSM untargeted target setting comparison refer code implementation  modification directly optimize perturbation optimizer zoo exploit finite difference calculate approximate gradient MI FGSM introduces momentum improve iterative evaluation adversarial sample generation mnist      MI FGSM zoo bmi FGSM evaluation adversarial sample generation cifar      MI FGSM zoo bmi FGSM parameter conduct binary parameter adam optimizer confidence robustness max perturbation distance iteration mnist cifar optimization terminates loss decrease tenth iteration zoo batch evaluate gradient update pixel zoo attack framework consistent iteration mnist iteration cifar MI FGSM maximum iteration mnist cifar per iteration upper bound perturbation distance respectively decay factor adversarial sample iteration return successfully misclassification bmi FGSM mnist cifar return activate report rate average perturbation distance mnist cifar respectively achieve rate untargeted rate approach target zoo perturbation distance ignore zoo optimize norm distance MI FGSM bmi FGSM norm bmi FGSM perturbation distance MI FGSM generates sample quality illustrate approach generates valid adversarial sample within untargeted attack target attack efficient zoo approach iterative gradient originally sample generation overall approach feature rate efficiency visualizes generate adversarial sample bmi FGSM generate image visual impression image malicious sample imperceptible distortion confuse dnns accuracy RQ transferability transferability indicates model usability adversarial sample evaluate transferability mnist cifar define transfer rate percentage transferable adversarial sample generate sample trigger misbehavior another model evaluation transfer rate mnist   MI FGSM zoo bmi FGSM evaluation transfer rate cifar   MI FGSM zoo bmi FGSM mnist FC network fully layer lenet target cifar convolution network  network network nin vgg network target model framework minor modification softmax layer output report transferability denote transfer rate generalization adversarial sample generate adversarial sample gradient MI FGSM bmi FGSM transfer rate optimization zoo optimization tolerate perturbation distance obtain transferability besides propose bmi FGSM advantage momentum introduce balance rate transferability achieve comparable MI FGSM transferability approach zoo mnist cifar RQ strategy dataset image classification application dataset complex model attack setting challenge expensive due input evaluate performance transferability imagenet dataset efficacy propose mechanism candidate reuse generate image limit iteration randomly image imagenet validation apply untargeted target generation image untargeted sample target sample vgg target model inceptionv resnet transfer model adapt cifar parameter setting untargeted adversarial sample valid truth label prediction adversarial sample generation imagenet      min min MI FGSM min min zoo min min bmi FGSM min min transfer rate imagenet   MI FGSM zoo bmi FGSM demonstrates performance transferability propose bmi FGSM achieves rate untargeted target technique MI FGSM approach perturbation distance due input image hence gradient approximate zoo approach significantly reduces consumption generates transferable sample plot generate sample distinguish sample strategy illustrate average distance valid iteration iteration successful adversarial sample evident distinction rate noticeably rate decrease without algorithm almost unusable without candidate reuse evaluate alternative perturbed image population gradient everything rate decrease incompatibility indicates strategy surely apply alternative investigate advantage candidate reuse iteration report confidence truth label versus iteration truth label confidence attack ability sample curve candidate reuse importance momentum information curve perturbation distance risk trap local optimum contrast dash curve indicates temporary perturbed image approximate gradient quickly bmi FGSM achieve confidence technique apply bmi FGSM generate visually undetectable adversarial sample effectively suppress probability truth label strategy comparison imagenet    valid bmi FGSM candidate reuse perturbed image population image KB image confidence truth versus iteration adversarial sample misbehavior DL illustrate ability bmi FGSM robustness dnn random without coverage guidance  coverage guidance baseline dnn technique report performance generate untargeted adversarial sample approach outperforms random  bmi FGSM appropriate robustness adversarial attack comparison technique imagenet   dist random  bmi FGSM RQ api validate reliability applicability application aliyun image recognition api commercial computer vision toolkit alibaba api classifier query output label image without internal detail goal perform adversarial sample generation trigger api misbehavior however aliyun api challenge model aliyun api trial query per query perspective attacker query efficient adversarial generation algorithm highly desirable cannot enumerate label api output label sum neither probability logits image KB image aliyun image recognition api image adversarial image adapt parameter setting perturbation distance bound perform untargeted generation budget query target api api prediction image fitness algorithm terminates prediction approach achieves rate aliyun api imagenet sample image adversarial sample image recognition api prediction api correctly classifies image confidence adversarial prediction adversarial sample mislabeled api image confidence misclassified restaurant image overall successfully trigger aliyun api misbehavior perturbed image conclusion introduce differential evolution develop adversarial sample generation bmi FGSM generate adversarial sample detect successfully attack dnns mnist cifar imagenet propose mechanism candidate reuse essential conduct validate efficacy experimental approach obtains rate perturbation distance transferability comparable technique reduce consumption considerably achieves performance dataset finally craft adversarial sample aliyun image recognition api expose robustness demonstrate approach perspective attacker future model defense technique model opportunity combine adversarial technique evolutionary algorithm differential evolution