rapid availability renewable source datacenter opportunity service provider reduce related minimize ecological impact infrastructure however renewables largely intermittent negatively affect user application performance therefore profit service provider furthermore service geographical location electricity relatively cheaper location degrade application performance potentially increase user ensure provider profit user non interactive workload execute geographical location offering price queue delayed execute later renewables solar peak however negative impact consumption workload performance user therefore ensure performance efficiency appropriate workload schedule placement migration resource management technique  infrastructure resource workload source propose workload placement migration policy maximize provider revenue ensure workload performance reduce consumption along reduce ecological impact user workload trace electricity price geographical location distribute heterogeneous datacenters experimental evaluation propose approach significant amount reduces service monetary improves maintains application performance increase provider revenue along environmental sustainability FF BF heuristic algorithm closest rival previous keywords datacenters performance migration efficiency introduction compute utility service user across impact increase demand compute resource cpu storage access network application business consumer scientific domain host resource datacenters datacenters return consume amount yield operation datacenters along environment affected carbon footprint  emit closely frequently carbon source solar achieve somehow shift timing compute task non urgent carbon source solar plentiful project datacenters utilized  utilization   essentially   accounting approximately worldwide approximately   almost carbon emission aviation consume datacenters approximately  electricity usage nearly electricity consume worldwide accord publish report  increase overall usage compute instance global datacenter within increase consumption due enormous increase service mobile device user iot internet device besides depicts conceivably due migration workload organization private public datacenters utilization conceivably unaltered till sort issue  mostly utilize resource allocation workload placement schedule consolidation efficient resource management technique resource management strategy dependent already available technology virtualization containerization container virtualization broadly utilized service provider resource IaaS infrastructure service client virtualization VM virtual machine whereas containerization portrays VM container virtualized server vms broadly utilized public IaaS broadly aware notion vms service provider microsoft azure google amazon EC VM container service client  execute application workload service inside vms container besides paas platform service SaaS software service supplier google app gmail IaaS execute application workload inside vms container  climate alter misplace assist contamination within spite renewable UK germany fractional coal worldwide  contamination proceeds expand pace within later alarm aware computation account priority basis without negative impact application performance renewable approximately   utilization expand consistently approximately increment renewable utilization approximately requirement met renewable source utilization renewable ought annually objective proportion datacenter usage source consumption public furthermore estimate approximately server hyper public datacenters basically amazon web service aws google compute facebook microsoft azure contract sort cheat whilst renewable probably generate somewhere datacenter potential option fix issue deploy renewable source local grid datacenter actually consume renewables location datacenters unpredictable intermittent albeit IaaS facility abundant renewables solar hydro others google achieve available renewables furthermore approach towards carbon intelligent compute shift workload peak renewable closer development contact source renewable specifically local network google publish article approach incorporates illustration concept however switch datacenter operation renewable approximately electricity generation united  fuel coal furthermore various price consumption resource provider user workload competitively cheap source price increase saving ecological impact however optimize network latency workload performance execution translate user bill exploration investigation research focus investigate workload geographically distribute datacenters minimize without negative performance impact moreover performance workload affected migrate location price availability renewable source google initiative shift workload cluster accord increase environmental sustainability however detail approach publish moreover knowledge notable exception buyya datacenter approach considers migrate workload across cluster besides limitation finding noteworthy respect saving provider revenue performance gain contribution research conduct placement policy FillUp LS appropriate workload appropriate cluster accord source price consolidation policy FollowMe location propose migrates workload across cluster geographically distribute offering variation price performance effective consolidation policy FollowMe source propose migrates workload across cluster fuel source renewables grid etc workload performance affected negatively investigate performance impact FollowMe location FollowMe source policy combination consolidation strategy FollowMe LS affect infrastructure consumption workload performance execution user propose scheduler placement plus consolidation distribute fashion global scheduler communicates local scheduler appropriate workload execution decision organize discus resource allocation placement consolidation geographically distribute datacenters along variation electricity price source production propose allocation policy workload appropriate resource furthermore propose consolidation approach FollowMe location FollowMe source prefer migrate workload  cluster accord electricity price source production respectively policy combine across consolidation FollowMe LS appropriate migration decision account electricity price source production simultaneously simulation configuration evaluation metric experimental parameter along simulation model evaluate validate propose policy workload datasets google demonstrate efficiency performance therefore respect exist addition briefly summarizes experimental outcome validity obtain along limitation overview related finally summarizes along shortcoming limitation proposes future research direction description largely service provider csp various source electricity fuel infrastructure device etc furthermore csp infrastructure datacenters distribute various geographical location notion availability zone amazon web service source geographical location price electricity besides service CSPs interested user application ecological effectively renewables intermittent available renewables cheaper grid environmental friendly therefore workload non interactive non task youtube video processing appropriate optimize objective renewables solar peak workload maximum effective moreover workload non interactive task delayed execution benefit renewables similarly electricity price varies location location particularly united CSPs decrease bill therefore increase profit reduce user monetary achieve VM placement schedule consolidation migration policy challenge implementation effective elastic scheduler resource management approach monitor infrastructure essential scheduler integral resource management responsible schedule vms appropriate resource usually schedule assume bin pack issue NP numerous heuristic algorithm albeit heuristic optimal schedule decision  convert classical heuristic approximate approach resource statistic conceivable yield adaptation decision strategic selection server execute geographic dynamic resource reconfiguration load balance resource migration allocation decision performance workload negatively affected performance loss translate increase user monetary furthermore essential objective guaranteed image KB image distribute datacenters various source location formulation assume multi objective optimization focus minimize bill consumption ecological environmental friendly consumption production improve maintain performance reduce user service bill consumption directly proportional assume objective moreover performance workload execution directly proportional user service assume objective furthermore execution improve performance user monetary workload performance inverse workload execution multi objective translate equivalent objective optimization former objective denote latter objective goal minimization therefore assume objective mathematically objective objective optimization constraint workload performance degrade workload exactly location datacenter besides constraint available multi objective optimization heuristic technique FF BF compute price consumption EC host cluster furthermore relate benchmarked described later host datacenter consumption kwh price per kwh translates similarly user monetary compute service price VM execution runtime workload workload execution sum task runtimes belong workload application workload runtime VM per translates workload runtimes inversely proportional workload performance performance runtimes user monetary vice versa circumstance performance preferably refer response service however user bill workload runtimes therefore prefer performance metric propose FollowMe LS technique heuristic technique appropriate optimal particularly online VM placement consolidation furthermore VM placement assume sub consolidation migration consolidation host utilized utilized vms migration host finally vms appropriate host describes VM allocation consolidation policy various objective criterion VM placement consolidation decision usually trigger scheduler centralize distribute scheduler specifically scheduler essential broker responsible manage infrastructure resource accord customer requirement quality service qos scheduler appropriate knowledge infrastructure suffers failure distribute scheduler additional communication manage heterogeneous resource effectively propose framework cluster geographical datacenter local scheduler local scheduler responsible assign vms appropriate host cluster monitoring module resource statistic utilization local scheduler optimization module intra cluster allocation decision statistic monitoring module storage preferably network storage NAS local scheduler global scheduler responsible appropriate workload placement intra cluster migration decision global scheduler data statistic local scheduler affective decision scheduler VM placement consolidation technique optimize various objective scheduler appropriate workload allocation migration decision statistic knowledge data cluster distribute scheduler involves additional communication forthcoming propose policy VM placement consolidation image KB image distribute schedule across various datacenters VM placement policy VM request propose allocation strategy cluster VM price source electricity price various location cluster fuel renewable cluster grid cluster placement similarly electricity price location location cluster location location cluster cluster location cluster prefer allocation ensure saving utilized host allocate guarantee host appropriate economical host allocate VM VM request cannot allocate due non availability resource queue schedule allocation involve allocation described alg  simplification usage effectiveness PUE evaluation metric efficiency cluster relation electricity source cluster PUE another cluster source infrastructure image KB image cluster appropriate allocation decision sort factor price source modify per objective account location source FollowMe LS ignore account objective FollowMe source FollowMe location remain others eliminate comment pseudocode approach FillUp LS VM placement policy FillUp source account source FillUp location account geographical location offering cheap ensures host cluster sort available capacity guarantee host utilized within cluster reduce consumption VM accord sort placement policy FF BF FillUp etc VM cannot switch host host switch VM unfortunately appropriate host VM pace vms reschedule periodically VM consolidation policy VM consolidation achieve migration migration VM host another host VM transparently service inside VM migration duration migration usually migration decrease consumption datacenter resource consolidate workload host switch unnecessary host consumption mode assume migration purpose reduce consumption utilize price available identify cluster location source fuel phase utilized utilized host marked vms migration allocation policy appropriate involve consolidation described alg image KB image appropriate cluster identify price source PUE detail host storage node repeatedly consolidation periodically migration opportunity migratable vms migratable vms schedule placement alg alg modify accord desirable heuristic approach FF BF FillUp alg modify per desirable migration policy ignore implementation FollowMe location policy eliminate FollowMe source policy due FollowMe LS policy account variation price due geographical location various source coal renewables FollowMe location migration policy prefers migrate vms location furthermore FollowMe source migration policy prioritize migration cluster cheaper renewable source implementation easily achieve sort appropriate available host capacity accommodate migratable vms location source approximate optimal algorithm description alg affective performance efficient VM allocation consolidation approach migrate vms inside cluster host across cluster various host belong cluster former intra cluster migration latter inter cluster migration implementation intra cluster migration assume migration policy target host alg target host within cluster source host migration aborted migratable entity migratable vms however reduce migration cluster resource strand therefore efficiency various reduce strand resource  allows allocate vms characteristic gap formally schedule heuristic optimize account gap sort vms former suitable latter appropriate various schedule heuristic approach propose allocation migration policy easily modify account choice evaluation perform simultaneously constraint migration reduce migration opportunity therefore economical increase migration performance VM migration reduce workload performance approximately besides performance degradation migration consume additional vms duration migration evaluation account migration performance moreover account performance variation application runtimes due cpu architectural heterogeneity location resource interference described later variant propose VM consolidation policy performance evaluation various workload empirical FollowMe location FollowMe location migrates workload across cluster geographically distribute offering variation price performance epc effective policy delayed workload non interactive service later price location dynamically FollowMe source FollowMe source migrates workload across cluster fuel source renewables grid etc workload performance affected negatively policy affective cluster IaaS resource renewables intermittent FollowMe LS FollowMe LS combine policy account geographical location price dynamically respect demand usage source various geographically distribute cluster VM placement account FillUp LS however migrate workload variant however FillUp LS policy easily modify account objective location price implementation methodology despite volume research available VM consolidation migration software available online consolidation geographically distribute literature source implementation server consolidation entropy framework VM management private  source implementation  framework server consolidation openstack overview consolidation previous discussion implementation reader understand propose resource management technique allocation consolidation migration implement production environment platform private IaaS easily update regard VM placement consolidation resource management policy unfortunately conduct public policy directly accessible requirement implementation propose algorithm functional hypervisor along management entropy   available furthermore global manager instal server local manager server cluster cluster local manager global manager various server consolidation technique implement distribute fashion  VM selection algorithm compute host VM allocation algorithm controller host core openstack compute module nova responsible vms provision management vms provision nova glance repository instance nova scheduler responsible vms placement onto host default random mechanism filter approach schedule approach easily replace propose policy available host respect slot available utilization consumption performance nova compute metric hypervisor metric hypervisor load workload vms vcpus available tenant metric core instance nova server metric hdd req useful resource utilization consumption performance external monitoring    usage data specific interval min scheduler VM placement decision virtual platform hypervisor access vms responsible consolidate workload vms nova docker migration vms migration approach nova manager api implement propose approach code modify migration trigger automatically min interval data monitoring api scheduler migrate vms destination host  buyya propose framework openstack project initiate VM migration global manager controller node host utilization threshold local manager compute node propose framework data collector apis responsible compute node statistic global manager VM migration placement decision another framework software consolidation closely resembles propose framework host host local manager monitoring agent local statistic monitoring consolidation manager periodically host along monitoring data monitoring reconfiguration migration informs local manager host appropriate action price renewable model framework consolidation manager performance data host storage simulation configuration model simulated geographically distribute evaluate performance propose allocation FillUp LS consolidation FollowMe LS policy ensure accuracy plausible simulation plausible realistic model workload trace cloudsim widely simulator research community easy model distribute cluster workload trace google cluster microsoft azure former capture containerize platform latter comprises VM instance datasets task assume workload container VM characteristic arrival submission resource cpu memory disk demand actual usage submit user moreover datasets seasonal aspect burstiness important feature VM arrival arrival rate resource usage execution important execution runtime task compute submission simulation arrival VM exactly arrival task datasets moreover user resource capacity usage  model VM execution performance metric workload application evaluation metric migration intra cluster inter cluster consumption kwh  execution bill user service performance evaluation metric intra cluster migration various host cluster inter cluster migration host belong cluster datacenters consumption host sum consumption vms accommodate host consumption VM compute host benchmarked consumption moreover workload performance sum vms execution workload similarly bill refers amount compute dynamically geographical location price benchmarked finally service sum amount vms workload user  model compute aware performance metric however execution performance metric user service provision resource capacity usage experimental evaluate propose algorithm model geographically distribute IaaS datacenter site cluster geographical location heterogeneous host respectively datacenters interconnect network bandwidth gbps network distance communication workload cluster assume global scheduler aware distance datacenter unique PUE PUE refer efficiency source cluster specific geographic PUE notion source essential host relate architecture cpu model furthermore assume electricity price location reflect price united reality price respect however  simplification assume price remains unchanged consumption host relate benchmarked various utilization specpower account peak demand burstiness workload arrival inter arrival ratio vms exactly submission inter arrival rate task datasets exception vms queue placement policy unknown workload vms however consolidation policy vms reserve pack onto available server appropriate host mapped instruction per mips consistent simulation platform cloudsim host model virtualized capability vms host capacity notion VM density somewhere performance parameter various host application benchmarked IaaS assume vms instance reflect amazon web service aws instance performance execution various host VM user resource capacity geographical location evaluate performance propose policy plausible simulation environment cluster data trace microsoft azure google realistic scenario workload mapped application statistical described later former virtualized platform latter containerize platform furthermore former consists task longer runtimes latter consists task duration workload consists task task characteristic runtime schedule resource requirement etc assume task cpu resource built cloudsim model stochastic utilization approach assume task workload application execution sum task execution assume VM task assumption application execution environment sensible simulated platform datacenters geographical location source price datacenter  price kwh source PUE DC  virginia DC san  california DC  oregon DC dallas texas various characteristic host amazon simulated cpu  mhz   GB amount  optimize various cluster minimize consumption assume vms migrate inside cluster host within cluster across cluster host belong cluster resource utilization host increase decrease pre define threshold former avoids performance degradation due resource subscription later switch utilized host assume subscription due constraint VM placement VM cannot host capacity later threshold utilization host decrease accommodate vms workload host migrate host moreover vms cheaper cluster appropriate vms cluster migrate optimization module periodically min interval migration opportunity furthermore approach demand trigger migration optimize datacenters frequent optimization module significantly affect migration therefore application performance infrastructure consumption amazon instance characteristic instance    mhz  GB storage GB reserve price virginia nano micro micro medium medium statistical model describes consumption host vms performance host vms model simulation purpose furthermore discus migration happens impact consumption workload performance degradation model plausible realistic simulation platform developed ensure accuracy obtain outcome consumption benchmarked specpower consumption various server however consumption VM compute linear model denote consumption server utilized respectively server consumption specpower benchmark various utilization moreover host resource allocate VM core vcpus refers vms host model equally idle consumption host various vms however approximate consumption VM migration compute accord model proportional amount VM memory source destination server model validate intra cluster migration however inter cluster migration usually longer network latter compute migration VM data network bandwidth assume constant later translate consumption network plus source destination host simulate VM migration across cluster migration downtime integrate migration model  simulator cloudsim  simulator realistic environment mimic VM migration pre various parameter network VM memory dirty rate etc detail migration model approach calculate duration downtime previous performance investigate  workload performance respect cpu platform workload application differently vms instance accommodate server cpu architecture standard deviation minimum min maximum max runtimes performance application coefficient variance cov compute denote lesser variation runtimes benchmarked denote normal distribution therefore cpu heterogeneity host performance assume workload runtimes host normally distribute implementation vms migrate host another increase decrease runtime compute normal distribution dataset comprises translate remain execution application server source equivalent execution destination server standard formally normalization standard normally calculate probability likelihood occurs interior datasets normally distribute statistic standard deviation furthermore relate belong various datasets essentially normally distribute utilized compute execution migrate application workload source server destination server distribution usually normally distribute along statistical standard deviation source destination server respectively denote estimate runtimes migrate application source destination server respectively furthermore narrate standard source destination server respectively mathematics allows predict VM runtimes translate increase decrease application performance destination server within dataset essentially normally distribute dataset consists performance runtime dissimilarity due resource workload platform heterogeneity rewrite compute execution workload performance migrate application destination server estimate remain execution source host normally distribute datasets replace mathematical definition normal normal distribution normally distribute datasets estimate execution calculate aware effective estimate predict estimate remain runtimes application moreover overlap exist performance multiple server application account euclidean distance overlap however assume overlap overlap assume redundant data euclidean distance possibly remove overlap however investigation associate redundant data runtimes appropriate cpu model instead ignore parameter application essentially perform server vice versa application performance important user resource  model application runtimes role business economics user resource usage execution appropriate performance measurement IaaS provider statistical model previous account increase decrease execution migrate application dissimilar cpu platform standard deviation application execution benchmarked image KB image mapping google data benchmark plausible assumption appropriate host povray workload performs furthermore assume performance degradation workload VM migrate intra cluster implementation VM migrate server another remain execution increase inter cluster migration exist model implement  simulator compute downtime remain runtime VM destination server however account performance loss due cpu heterogeneity concept normalization normal distribution described previous intra cluster migration downtime migrate VM translate equivalent degradation besides vms compete resource workload host suffer severe performance degradation however account finding  ascertain performance severely degrade furthermore resource subscribed load vms suffer performance issue however assume subscription notion VM density host accommodate vms sum capacity host entire capacity load situation allocation policy available capacity host assign VM resource allocation reject various application runtimes cpu architecture instance MB input file bzip ubuntu amd desktop iso file bip VM performs host povray performs cpu medium VM application performance around  suggests variation mapped normal distribution application    medium     application simulation realistic mapped google microsoft azure workload benchmarked application IaaS performance standard deviation  application bzip povray author performance various instance aws EC cpu architecture significantly varies model normally distribute furthermore combination various cpu model instance multi modal distribution data finding therefore monte carlo simulation data normal normal distribution actual benchmarked application runtimes task runtimes workload google microsoft azure appropriate multimodal distribution normal finally similarity distribution assume task belong benchmarked application cpu platform demonstrates actual benchmarked runtimes povray application task runtimes belong google dataset normalize google task runtimes mapped performance povray application appropriate host describes performance parameter application cpu platform similarly mimic performance application mapped microsoft azure dataset cpu architecture various distribution convert onto mapped visualization identify peak multi modal cpu platform architecture apart discussion vms server severe performance loss specifically host virtualized application compete resource resource interference empirically evaluate performance loss strongly dependent vms application execute server vms server performance vice versa essential account resource interference contention server implementation model performance variation various application cpu platform model resource interference regression equation respect vms server application prior cpu platform heterogeneity normally distribute respect application runtimes prior research finding mathematical model sensible realistic simulation environment  available github repository moreover datasets mapped application plausible assumption similarly resource application heterogeneity performance degradation model sensible benchmarked demonstrate prior execution various application vms workload   vms execution   image KB image mapping microsoft azure data benchmark plausible assumption appropriate host workload performs performance evaluation placement policy assign workload trace assume inside VM appropriate host consolidation policy ensures transform cluster ideal consume due host consolidation achieve VM migration various heuristic FF BF FillUp impact allocation consolidation policy consumption price profit workload performance albeit heuristic optimal however demonstrate optimal algorithm particularly besides discus approach migration intra cluster migrate vms across host belong cluster inter cluster migrate vms across host belong various cluster geographical experimental describes simulated environment various resource allocation migration technique migration placement policy FillUp approximately along marginal improvement workload performance classical FF algorithm however allocation aware price source saving increase along performance gain demonstrates workload largely DC price PUE furthermore DC expensive therefore placement avoid migration account variation saving across approach placement migration policy interestingly migrate price saving migrate  source instead adjust propose FollowMe LS policy approximate saving classical FF allocation policy saving essential loss workload performance non trivial application workload average saving propose placement policy classical FF approach saving classical BF policy furthermore migration expensive economical migrate consistent previous finding   BF FillUp LS policy migration approximately expensive migration approach respectively similarly intra cluster migration trigger intra cluster migration increase saving however tight pack allocation policy FillUp migration approximate loss saving intra cluster migration migration migration opportunity infrastructure user monetary respectively demonstrate FollowMe LS balance workload source price modify propose policy avoid expensive migration maintain user moreover additional constraint placement migration decision migrate renewable price migrate target host cluster economical performance efficient etc certainly improve saving bill maintain workload performance consumption kwh google workload trace denotes performance improvement efficiency loss performance management  consumption kwh saving exe performance gain loss migration  migration FF BF FillUp FillUp LS intra cluster migration FF BF FillUp FillUp LS FollowMe location FollowMe source FollowMe LS inter cluster migration FF BF FillUp FillUp LS FollowMe location FollowMe source FollowMe LS discussion briefly impact various allocation migration policy infrastructure consumption price source ascertain workload affect evaluate metric various obtain another workload trace microsoft azure largely consistent previous outcome however impact consumption performance clearly migration propose placement approach FillUp LS along improvement performance however migration scenario efficiency negatively impact albeit trivial performance improvement possibly due behaviour task workload workload longer absolutely consume resource renewables moreover workload longer migration opportunity decrease efficiency classical heuristic FF BF FillUp sketch entire infrastructure bill service paid customer workload demonstrate migration affective decrease provider bill however negative impact user service agreement SLAs violate SLAs subsequently switch customer provider penalty service provider option revenue effective provider public provider besides without migration various placement policy various revenue provider customer saving achieve affective placement policy significantly saving obtainable migration technique FollowMe location policy migrates workload geographical price reduces efficiency however provider consumption due longer execution performance degradation due resource heterogeneity longer migration duration FollowMe location policy workload efficient cluster essentially indicates price revenue customer provider due exist consumption workload performance therefore FollowMe location FollowMe source benefit approach achieve FollowMe LS prefers migrate workload host cluster price renewables source consumption kwh microsoft azure workload trace denotes performance improvement efficiency loss performance management  consumption kwh saving exe performance gain loss migration  migration FF BF FillUp FillUp LS intra cluster migration FF BF FillUp FillUp LS FollowMe location FollowMe source FollowMe LS inter cluster migration FF BF FillUp FillUp LS FollowMe location FollowMe source FollowMe LS finally demonstrates impact various policy consumption cluster price source workload placement policy various placement option consumption however workload non trivial impact infrastructure consumption creates gap investigation workload resource geographical cluster application delayed availability renewables public similarly migration geographical feasible due strict deadline besides workload efficient cluster consume loss performance workload frequently migrate trigger optimization datacenter frequently consume migration however efficiency performance workload utilizes resource cpu memory disk differently workload challenge essentially service provider placement consolidation policy manage infrastructure geographical various source outcome denote scalability approach heterogeneous various workload parameter however complexity algorithm essentially increase increase cluster geographical location host within cluster user demand service complexity average propose algorithm described image KB image infrastructure correspond PUE cluster compute non computation infrastructure facility migration migration image KB image user monetary migration migration comparison closest rival sketch comparison propose approach FollowMe LS placement workload shift algorithm WSA carbon efficient ECE VM placement renewable aware dynamic PUE cra DP placement account price source migration intra cluster inter cluster explore approach significant amount approximately approach non trivial performance loss albeit performance gain scenario however due variation various iteration denote standard deviation degradation minimize incorporate sort migration policy avoid costly migration migration relatively vms performance efficient host prefer due recover migration saving translate profit environmental friendly resource service reputation revenue service provider however performance loss impact user satisfaction provider revenue apart migration reduce intra cluster methodology approach outperform various evaluation metric efficiency performance loss user monetary possibly due migration overhead distance opportunity consolidation non migration migration expensive appropriate mechanism longer datacenter reconfiguration non frequent optimization module comparison closest rival accounting intra cluster inter cluster migration denotes standard deviation across various  metric consumption kwh performance user WSA ECE cra DP FollowMe location FollowMe source FollowMe LS summary related closest respect various evaluation criterion exe refers workload performance optimize denotes consolidation  multi metric    footprint  buyya buyya   FillUp LS FollowMe LS complexity alg source location sort respect price algorithm inner loop host within outer loop cluster therefore complexity VM outer loop executes placement decision inner loop executes therefore overall execution usually sort incorporate nest loop usually cluster geographical location assume constant average complexity alg occurs VM attempt ignore complexity alg complexity complexity complexity complexity assume cluster constant average complexity alg occurs VM attempt optimization phase complexity optimization phase placement alg complexity propose algorithm definitely increase respect workload demand user capacity availability usage IaaS resource however largely accepted scenario heuristic optimal algorithm complexity denotes amount memory algorithm obtain desire outcome specific input parameter complexity strongly dependent exponentially increase decrease arrival rate vms due VM significant amount memory instance image memory dirty workload propose placement consolidation algorithm dominant variable vms host characteristic cpu memory detail essential policy albeit additional memory consumption model host specify eleven cpu utilization increment percent specpower benchmark moreover optimize datacenter consolidation migratable vms eligible host therefore algorithm additional memory exponentially increase complexity infeasible validate outcome simulated vms host workload previous described situation detail conduct relatively simulated increase memory slot clearing heap explicitly exponential growth memory usage proportional increase host vms obtain google workload trace core cpu ghz GB memory operating overhead vertical axis duration longer duration potentially increase complexity propose algorithm summary finding validity limitation propose placement policy FillUp LS appropriate workload appropriate cluster accord source price furthermore consolidation policy FollowMe location FollowMe source FollowMe LS propose migrate workload across geographically distribute cluster performance effective schedule policy distribute fashion global scheduler communicates local scheduler appropriate workload execution decision briefly explain outcome precision obtain describes limitation finding empirical evaluation workload trace public service provider finding consolidation technique usually expensive negative impact workload performance user monetary VM allocation approach performance efficient consolidate policy workload migrate workload efficient however FillUp LS allocation efficient classical policy migrate FollowMe location migrate renewable source FollowMe source consumption workload performance user migrate workload propose FollowMe LS policy reduces approximately consumption user increase workload performance migration approach resource management policy outcome strongly dependent workload workload IaaS resource validity demonstrate previous developed version classical cloudsim simulator approximately accurate precise IaaS private accuracy compute appropriate statistical validation verification approach extend version cloudsim simulator experimentation  recently publish publicly available online github repository accuracy approximately error simulated outcome accuracy easily compute error performance efficiency various resource management policy resource management policy FollowMe LS approximately effective performance efficient migration technique potentially approximately user performance efficient migration approach approximately respectively limitation model shortcoming datacenters heterogeneous application diverse resource usage cpu memory disk network subsystem apart processor report noticeable consumption workload avoid model specific cpu intensive application impact consumption subsystem II moreover VM cpu utilization characterize VM workload correlate processor usage consumption however utilization indicator processor usage regard correlation consumption application utilization processor consumption instruction execute report aware issue propose framework vms interact propose scheduler  due delay communication network congestion response become response essentially affect performance respect subsequently affect consumption user issue likely arise increase vms secondly data maintain cluster node burden maintain calculate statistical information regard resource consumption addition perform task execution update information data server network storage NAS cluster node update information NAS server periodically generate traffic therefore burden datacenter network research account important issue besides united price respect usage peak research limited static price research investigation price across hourly unknown usage robust prediction technique useful estimate migration runtimes workload heterogeneity resource ensure workload independent performance epc aware resource VM allocation consolidation IaaS besides limitation discussion around future research related amount research around improve efficiency performance datacenters within research community efficiency datacenter achieve optimization software hardware intermediate respectively primary earlier efficiency VM consolidation dynamic voltage frequency DVFS approach incorporate approach dominant significant drawback discus situation datacenters overload overload datacenter scenario function improve performance efficiency due idle server consumes peak consumption therefore cpu approach minimum server resource management multi infrastructure geographically distribute approach earlier geographical load balance approach renewable reduce infrastructure balance web application load across multiple datacenters renewable available aim reduce overall electricity workload management aim reduce operational network another focus dynamic workload deferral target multi enable dynamic electricity price various location workload deadline workload schedule propose discus markov chain communicate workload renewable across geographically datacenters target reduce overall electricity consideration carbon footprint moreover performance account focus advantage various schedule consolidation increase efficiency workload performance decrease user etc VM consolidation aim consolidate vms host context resource utilization consumption reduce consumption increase utilization host allows active host data migrate host another host VM consolidation openstack propose  buyya discus efficiency approach qos intact multiple heuristic implement VM consolidation combination DVFS VM consolidation efficient orchestrator allows enhance balance  application performance simulation significant  usage orchestrator slight amount additional application VM consolidation efficiency balance migration usage specifically datacenters geographically distribute location achieve VM consolidation discus usage multiple prediction local heuristic enhance datacenter efficiency scenario focus prediction resource utilization optimal VM consolidation highlight load load host within datacenter distribute infrastructure workload migration placement propose focus renewable availability improve performance datacenters within distribute focus batch workload attention towards carbon footprint resource usage reduction consumption datacenters achieve graphic processing gpus approach analyse cluster equip grouped virtual gpus remote gpus enhance resource usage constraint met usage gpus finance application application efficiency obtain gpus despite aim workload distribute across datacenters geographically zone VM placement consolidation mechanism easily applicable heterogeneous infrastructure significant research available usage carbon footprint datacenters within VM placement discus reduction carbon datacenters geographically limitation location reside within carbon footprint management approach discus load balance consideration renewable focus   scheme propose prototype dynamic schedule enable workload source buyya considers server location comparison exist approach buyya workload shift schedule workload across various datacenters objective minimize overall carbon footprint average response request intact along objective focus geographically datacenters zone various carbon concentration renewable availability schedule source formulate enhance usage renewable considers reduce obtain conventional grid battery backup dynamic encompasses grid advantage evidently realistic ponder datacenter grid limitation implement dynamic contrary optimize usage battery boost capacity battery algorithm efficiency renewable efficiently  exploit workload schedule furthermore integrates workload management datacenters gain efficiency available demand exploit variation electricity price renewable availability efficient phase important feature integrate silo datacenters secondly theory model implementation core focus optimize workload management depicts reduction grid electricity consumption approximately impact quality service application relatively ignore performance aspect datacenters resource delay workload later execution moreover impact schedule policy datacenters relatively unexplored literature focus renewable source datacenters reduce brings challenge due issue highly discontinuous unstable solar similarly focus reduction overall account geographical location zone respect electricity price furthermore load balance approach implement reduce zone location electricity price deferral creates user dissatisfaction dynamic price load balance micro datacenters renewable source similarly DVFS VM consolidation approach utilization performance reduce usage however approach resource underutilized describes summary related information reader quickly identify gap research investigation improvement conclusion future electricity source price provision economical resource execute various application workload geographically distribute heterogeneous datacenters furthermore assume various cluster fuel source coal renewables electricity price location respect location location propose placement approach FillUp LS workload onto appropriate resource price performance efficiency geographical cluster furthermore propose variant migration policy FollowMe location FollowMe source FollowMe LS migrate workload price datacenter PUE respectively experimental workload trace electricity price saving reduction service monetary improvement application performance FF heuristic algorithm estimate error due simplification simulation model furthermore various application workload perform differently due heterogeneity IaaS resource source price therefore variation revenue consumption topic investigate research suggests investigation analysis public workload significantly private cluster distribute platform essential justify delay workload availability renewables shift migrate appropriate location efficiency along performance gain profit obtain respect workload strict deadline response application service cannot delayed however batch processing application delayed schedule later beneficial respect consumption provider revenue user ecological impact respect migration workload account aspect user location mobility impact workload performance importantly saving provider revenue achievable migrate accounting migration besides workload classification prediction approach workload placement policy scheduler  centralize multiple distribute hierarchical decentralize investigation performance efficiency heterogeneous cluster environment characterize workload significant effort prediction mechanism however prediction suffer occasionally issue considerable amount memory complex data structure user complex prediction approach significant computational storage storage network overhead maintain appropriate placement decision however demonstrate predictor excellent outcome obtain prediction algorithm average runtime recently submit terminate user easy implement almost computational storage overhead finding predictor successful capability due focus recent memory storage capacity contrast previously propose prediction largely focus similarity numerous characteristic runtimes resource requirement submit user workload resource usage future machine prediction technique integrate proposal trigger appropriate performance effective workload placement resource allocation migration decision finally accurate reasonable model consumption migration performance loss vms compete resource research investigation