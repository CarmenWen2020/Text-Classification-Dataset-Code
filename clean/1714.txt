graphic processing gpus evolve powerful processor cnn training feature introduce gpus concurrent kernel execution hyper technology challenge orchestrate concurrency cnn convolutional neural network training gpus introduce synchronization overhead resource utilization unlike previous research mainly focus layer coarse grain optimization introduce critical asynchronous parallelization mechanism propose optimization technique cnn training account global network architecture gpu resource usage propose effectively overlap synchronization computation training cnn accelerate integrate caffe experimental caffe integrate achieve performance speedup average caffe cudnn performance speedup achieve deeper wider complicate network introduction neural network dnn widely apply practical image classification detection recognition translation training neural network resource consume task purpose graphic processing gpus accelerate neural network training platform developed dnn convolution neural network gpus although exist platform optimize gpus revise gpu architecture evolve efficient feature architecture retain performance optimization non trivial task graphic processing gpus evolve powerful processor application addition significant increase chip resource faster compute core memory register feature introduce recently hyper technology concurrent kernel execution dynamic parallelism nvidia kepler architecture concurrent kernel execution enable simultaneous multiple cuda gpu multiple desire advantage data transfer host memory device memory parallel kernel computation effectively overlap computation communication memory execution multiple kernel interleave enhance resource utilization gpu program apply concurrent kernel technique enhance performance cnn convolution neural network training framework caffe cudnn apply concurrent kernel effectively enhance performance cnn training frequent synchronization computation convolution neural network consists layer layer BP propagation algorithm widely cnn training BP iterative computational algorithm iteration computation perform layer layer layer obtain loss backward computation perform propagate loss update parameter layer reverse cnn training model multiple iteration converge strict global synchronization generally simply multiple computational layer consecutive synchronization substantial performance improvement accumulative overhead frequent global synchronization significant impact overall performance moreover workload significantly inter layer inner layer frequent synchronization resource utilization gpu however argue layer computational task partition sub task careful dependency analysis training dag although sub task synchronize output previous layer input sub task local sub task output layer input therefore output specifically backward computation stage training feature bias layer update independently loss function gradient feature input layer computation update bias gradient local layer therefore feasibility grain task parallelism discrepancy dependency propagation loss update bias gradient opportunity promote performance handle properly exist mainly focus layer optimization coarse grain parallel distribute communication reduction characteristic network architecture dependency gpu introduce synchronization overhead resource utilization exploit global dependency discrepancy embrace feature gpu concurrent kernel execution aim improve gpu resource utilization reduce synchronization careful dependency analysis network model dag acyclic graph apply grain task parallelism multi inner layer asynchronous execution perform inter layer eliminate synchronization balance workload layer critical schedule strategy developed effectively contend resource fully idle resource specifically propose apply grain task parallelism careful dependency analysis utilize multiple gpu responsible gradient subtask compute core idle core allocate increase inner layer resource utilization computes gradient feature synchronize computation phase layer overlap synchronization computation adopt asynchronous mechanism execution update local bias strict global synchronization eliminate asynchronous execution gradient computation bias layer perform concurrently computation successive layer consequently workload layer balance resource utilization improve identify strict synchronization critical update local parameter synchronization non critical propose critical priority schedule strategy execution non critical delayed perform idle compute core critical effectively utilize resource idle contend iteration implement caffe develop efficient framework TurboDL experimental TurboDL improve performance approximately percent organize detail TurboDL optimization implementation described TurboDL analyze related finally conclusion future methodology elaborate motivation propose effective optimization cnn training grain parallelism inner layer asynchronous execution mechanism eliminate synchronization balance inter layer workload critical schedule policy effectively utilize resource idle contend iteration motivation neural network model gpus architecture rethink optimization scope dnn training neural network become wider deeper complicate dense connection multi due introduction convolution layer kernel depth wise separable convolution residual channel shuffle dense connection advanced feature gradually introduce generation gpus concurrent kernel execution hyper technology user opportunity improve performance application instal popular framework caffe along cudnn  nvidia gpus conduct typical neural network lenet vgg resnet googlenet CaffeNet identify performance issue popular framework utilized nvidia profile obtain resource usage gpus although caffe cudnn optimize function cudnn applies concurrent batch technique enhance resource utilization gpu resource utilization kernel occupancy percent average multi warp occupancy kernel percent computation peak resource utilization periodic synchronization layer training detailed profile issue framework substantial performance improvement simply apply multiple cnn training ignorant underlie network structure feature computation characteristic issue impact efficiency resource utilization typical cnn consists multiple layer convolution polling batch normalization loss cnn training consume computation backward phase expensive phase computation perform convolution layer computation perform layer layer imbalanced workload layer significantly affect resource utilization alexnet illustrate workload flop layer convolution connection convolution flop neural network characteristic output layer input layer parallelization exist cnn platform coarse grain perform computation synchronously layer another frequent synchronization layer reduce resource utilization observation propose technique subsection effectively address flop layer alexnet convolution connection layer respectively flop layer alexnet convolution connection layer respectively data dependency analysis grain task partition multi concurrency efficient utilize characteristic gpus multi core complicate gpu workload cnn training grain parallelism feasible dependency analysis data parallelism decompose task independent sub task sub task kernel concurrently improve resource utilization gpu cnn training previous research mainly focus parallelism layer independent convolution layer inception image mini batch convolution image parallel coarse grain parallelism grain parallelism sub task layer cnn training potentially improve resource utilization specifically convolution layer involves computation cnn training source source source source convolution computation express formula formula activation feature bias respectively convolution layer backward computation gradient computation feature bias layer denote respectively calculate formula formula computation layer addition local data backward stage independent layer typical cnn architecture depict illustrate data dependency layer grain decomposition layer backward propagation rectangle layer non linear cnn generality linear cnn orange ellipsis sub task consecutive layer data dependency denote dash arrow representation easily grain dag identify data dependency backward computation cnn training derive dag implement sub task individual kernel multiple sub task layer realize concurrent kernel execution moreover characteristic grain dependency layer optimization subsection worth definition sub task decomposition apply layer learnable parameter convolution connection asynchronous execution layer computational task layer partition sub task although sub task synchronize output previous layer input synchronization relation sub task rely previous layer entire layer output sub task previous layer local layer sub task local sub task insight scope performance improvement introduce pipeline mechanism along asynchronous execution improve parallelism layer eliminate strict global synchronization occasion balance workload layer partition task layer sub task identify data dependency apply concurrent kernel execute sub task layer simultaneously mention previously simply multiple achieve substantial performance improvement strict synchronization layer global synchronization layer computation completion computation layer frequent global synchronization incurs overhead severe load imbalance across layer consequence gpus resource waste resource utilization backward computation stage synchronous asynchronous execution layer backward propagation strip rectangle indicates synchronization overhead fortunately grain task parallelism opportunity increase resource utilization kernel concurrency eliminate synchronization overhead asynchronous execution impossible previous coarse grain layer centric approach sub task activation gradient layer input immediately becomes available layer independent longer completion computation layer apply asynchronous execution mechanism sub task execution largely remove strict global synchronization partial sub task layer fully asynchronous schedule pipeline manner ideal depict computation strictly synchronize however synchronization effectively overlap computation computation layer perform simultaneously computation layer layer achieve workload balance across layer issue asynchronous execution multi initial task partition important carefully partition task sub task subset sub task synchronization sub task independent optimization technique opportunity overlap computation synchronization across layer situation another situation ideal depict longer layer computation layer completion effectively situation strict global synchronization perform layer another optimization technique address sub critical sub task schedule grain inner layer parallelism asynchronous inter layer execution parallelism gpus resource sufficient sub task execute concurrently individual kernel however gpus resource sufficient afford kernel parallel longer resource shortage occurs arises schedule sub task efficient manner resource efficiently utilized overall iteration minimize perspective dag sub task layer characteristic local sub task reuse distance iteration specifically distance gradient computation iteration parameter usage subsequent iteration layer critical dag observation discrepancy dependency propose novel critical schedule mechanism assigns priority sub task accord cnn training execution sub task affect global iteration resource efficiency output sub task compute layer synchronize immediately input layer backward phase sub task deem critical sub task critical sub task constitute critical sub task output immediately sub task calculate output iteration classify non critical sub task non critical sub task non critical assign priority utilize discrepancy rationale assignment strategy prioritize execution critical task advance execution layer effectively overlap computation non critical sub task synchronization critical sub task non critical sub task advantage idle resource gpu non critical sub task restrict layer critical sub task layer gpu resource computation restrict layer layer layer predecessor accord topological idle resource layer strategy execution critical sub task significantly improves resource utilization training discus priority policy detail conduct analysis critical analysis layer analysis entire network analysis layer layer computation cnn training parameter gradient activation gradient parameter update update accord gradient data transfer exchange gradient parameter server architecture multiple node node equip multiple gpus computation characteristic activation gradient computation critical output immediately subsequent layer along strict synchronization therefore delay execution sub task delay subsequent layer schedule sub task priority reduce overall training parameter gradient non critical execution sub task delayed computation iteration layer therefore postpone execution sub task timing gpus resource utilization critical sub task synchronization transfer parameter server architecture feature parameter gradient sub task overlap communication computation data parameter server computation parameter gradient parameter server computation iteration layer situation critical schedule apply assign priority critical accord analysis therefore thread kernel priority schedule gpus prompt ith layer contrary non critical execution postpone critical sub task utilize gpu resource synchronization workload layer moreover non critical sub task restrict layer concurrently sub task layer balance workload layer reduces idle gpu resource iteration reduces computation critical sub task significantly training impose execution non critical sub task analysis entire network entire network multiple convolution channel image mini batch moreover multi convolution dense connection previous layer complicate connection layer increase quantity complexity network extend analysis layer entire network gain insight complex network structure identify global critical entire network abstract dag entire network sequence layer layer layer fork layer merge layer synchronization illustrates structure exemplar network layer entire network consists layer layer fork layer layer merge synchronization layer layer fork layer merge layer structure ubiquitous network inception googlenet residual resnet dense densenet analysis entire network layer sequence analyze critical layer layer fork layer merge layer layer consists layer assign priority layer priority priority layer priority sub task previous subsection priority assign estimate computation activation gradient layer computation layer regard distance layer layer critical assign priority assign priority computation fully asynchronously layer layer assign priority layer backward layer layer layer assign priority layer analysis layer apply assign priority individual sub task layer hierarchical priority assignment schedule strategy aware underlie network structure dag effectively increasingly complicate network evolve towards trend denser connection implementation apply previous cnn training caffe develop highly efficient neural network training framework TurboDL architecture introduce component integrate caffe discus issue overview architecture TurboDL contains module network decomposition module critical identification module schedule module dependency maintenance module network decomposition module receives network input decomposes network grain sub task critical identification module identifies critical decompose dag account network structure computation dependency schedule module schedule kernel parallel gpus priority specially multiple dependency maintenance module maintains synchronization callback guarantee training architecture network decomposition module network decomposition module automatically network file  file TurboDL user program code therefore TurboDL transparent user network information connection relative layer layer input tensor dimension parameter layer update memory footprint automatic inference gpus information core register memory capacity peak flop estimate calculation layer sub task revise profile alone iteration cnn training characteristic repetitive computation predictability information decompose network grain sub task layer parameter gradient computation activation gradient computation parameter update implement sub task individual kernel grain sub task reconstruct accord dependency implementation sub task decomposition layer manual analyze mathematical relationship input output layer obtain independent computational subset input automatic derivative function unknown layer encounter decompose recursively operation linear layer dependency subtasks correspond input decomposition entire grain dag construct automatically accord dependency batch image mini batch kernel cudnn reduces kernel launch matrix multiplication efficient multiple matrix multiplication rebuild accurate dag vertex computation sub task estimate reading dependency therefore completely dag caffe mxnet tensorflow vertex dag automatic injection synchronization code dag construction conduct automatically popular layer typical layer decompose sub task individual kernel offline network online dag factor layer layer accord topological grain node dependency layer conduct training iteration moreover scalable complexity depends layer network usually dozen algorithm critical identification construction algorithm  grain graph relative priority adjustment parameter output consist sub task priority node compute DD node ssp topological sort node layer layer layer layer layer sort layer assign priority layer accord layer sub task num layer layer sub task layer  sub task DD sub task DD sub task sub task  sub task priority layer priority sub task priority layer priority priority layer priority critical identification module gradient dag graph built opportunity inner layer inter layer parallelization exploit critical identification module responsible identification classification construction implement critical analysis hierarchical priority assignment layer critical identification algorithm outline algorithm algorithm DD dependency distance metric quantify importance sub task define distance node sub task reuse node across iteration aforementioned reuse distance worth convolution apply convolution layer convolution execute parallel omit algorithm simplicity critical identification module layer sub task layer reduce overhead creation management retain dependency relation schedule module schedule module responsible schedule implement asynchronous critical schedule strategy multiple priority cuda api  assigns schedule module schedule vertex dag correspond vertex assign vertex safely maintain dependency correctness kernel execute sequentially moreover vertex execute concurrently across gpu resource available kernel dependency dependency maintenance module apply lightweight synchronization callback mechanism enforce dependency subsection illustrate typical partial network architecture layer backward propagation layer decompose independent compute calculation critical layer assign priority critical sub task priority sub task calculate priority dependent dependency execution delayed execute parallel kernel subsequent phase gpu resource utilization priority reduce shortens iteration schedule multiple dependency maintenance module assign sub task fully exploit parallelism however arise reading dependency broken incorrect training dependency met stale iteration affect convergence synchronize apply cuda synchronization dag dependency kernel cuda api  synchronization source   synchronize target assign  kernel synchronize issue moreover callback function  update parameter asynchronously accord gradient reduce synchronization  instead  former later synchronizes incurs integrate caffe integrate propose caffe modify layer schedule code net responsible layer schedule kernel execution unlike caffe cudnn net globally per layer facilitate global schedule easily enforce priority assignment dependency per layer implementation modify backward decompose layer grain sub task implement individual kernel launch independently discussion implement issue assign priority sub task efficiently utilize gpus resource across layer implement accurate global dependency analysis multiple hierarchical priority assignment multiple priority priority priority however testbed priority propose assign kernel priority hardware priority priority kernel priority assign priority kernel kernel queue queue additional synchronization simulate priority difference multiple priority priority synchronization overall priority although introduce overhead hierarchical priority analysis apply future generation gpu device priority extension multiple gpus easily extend multiple gpus multiple gpus difference extra parameter propagation across multiple gpus communication scheme cpu parameter server local update multiple gpus reduce communication aggregate local update computation gpu mechanism improve performance TurboDL multi gpu backward propagation phase propagation optimization communicate gradient namely gradient layer calculate assign kernel gradient propagation individual calculate gradient previous layer effectively overlap communication computation gradient gpu concurrent communication computation iteration phase layer cannot parameter update synchronization parameter update computation grain subtask synchronization within layer across iteration effectively eliminate global synchronization iteration fully overlap communication computation iteration earlier moreover assign priority individual communication communicate gradient layer reuse distance gradient reuse distance define shorter communication gradient assign priority reduce subtasks extension application although mainly utilize cnn effectiveness excellent potential apply complicate multi stage application database query processing network architecture rnn neural network generative adversarial network graph convolutional neural network gcn characteristic workload critical analysis asynchronous execution propose applicable improve performance although complicate dependency account rnn critical layer within layer capture dependency gcn analyze critical apply pipeline asynchronous optimization layer consecutive graph detailed extension aspect future applicability framework worth equally applicable data framework mxnet tensorflow caffe pytorch graph analysis utilize data mechanism schedule operator input operator operator schedule execute apply technique optimize graph execution operator fusion subexpression elimination lack grain decomposition within operator ignore dependency difference grain subtasks critical network topological due coarse grain incur unnecessary synchronization overhead layer operator resource usage limited parallelism caffe cudnn optimization developed TurboDL apply extend exist framework integrate modify schedule module exist framework conduct grain decomposition exist dag utilize automatic derivative function kernel inside operation grain dag analyse iteration dependency distance prioritize schedule applicability demonstrate implementation caffe prototype implementation evaluation evaluate efficiency propose optimization integrate caffe popular framework research due easy program feature user network file construct custom network specify hyper parameter moreover caffe utilize highly optimize library cudnn accelerate computation layer optimize nvidia gpu conduct nvidia gpus network setup cluster configuration conduct gpus gpus core diverse architecture generation pascal kepler respectively computation capacity multiple hardware manage connection hyper parallel execution kernel without false dependency platform equip core xeon ghz CPUs GB memory  gcc version cuda cudnn conduct nvidia gpu conduct training iteration axis caffe cudnn TurboDL axis iteration milli training speedup iteration batch data batch iteration resnet layer comparison gpus workload configuration datasets image classification mnist contains image training category cifar contains image training category ILSVRC contains training category efficiency various network lenet alexnet CaffeNet vgg googlenet resnet network typical convolution network image classification configuration version caffe prototype integrate improve TurboDL conduct TurboDL caffe accelerate cudnn denote caffe cudnn evaluation training network batch network CaffeNet vgg lenet resnet googlenet alexnet respectively propose outperform caffe cudnn TurboDL achieve significant speedup average caffe performance grain parallel benefit combine concurrent kernel execution network computation characteristic caffe sub task layer sequence achieve performance speedup average caffe cudnn lenet vgg alexnet googlenet resnet CaffeNet respectively speedup speedup caffe caffe cudnn utilizes multiple parallel execution batching technique dedicate implementation kernel nvidia gpus however eliminate synchronization overhead layer exploit characteristic network architecture accelerate critical computation reduce iteration TurboDL speedup network achieve speedup resnet percent vgg percent due difference network architecture resnet complicate dense connection residual deeper layer layer opportunity concurrent execution kernel gpu resource utilization layer non critical sub task indicates approach benefit future network trend denser combination multiple model speedup TurboDL batch lenet vgg alexnet googlenet resnet CaffeNet caffe cudnn performance advantage decrease batch increase network performance advantage decrease percent vgg batch increase batch increase computation complexity sub task increase linearly batch image mini batch kernel efficiency kernel harder execute parallel idle resource inner layer processing therefore sub task non critical iteration due resource shortage situation outperform caffe cudnn usage layer resource although batch improves computation efficiency hinders statistical efficiency epoch converge iteration layer increase batch respectively reduce batch memory achieve speedup caffe cudnn increase trend experienced iteration becomes longer layer increase TurboDL critical asynchronous execution sub task idle resource layer non critical calculation performance performance gpus achieve performance caffe cudnn gpus speedup core hardware parallelism TurboDL gain benefit gpus powerful parallel capacity evaluate optimization strategy contributes performance gain conduct combination gain strategy lenet vgg alexnet googlenet resnet CaffeNet effectiveness grain parallelism multiple verify significant improvement caffe depict strategy caffe cudnn baseline inner layer asynchronous parallelism inner layer multiple apply resnet achieve speedup caffe cudnn critical schedule speedup increase contribute performance improvement network strategy combination iteration improvement strategy combination baseline performance obtain caffe cudnn speedup  asynchronous parallel cri critical schedule resource evaluation resource profile vgg caffe cudnn TurboDL vgg network obtain execution nvidia visual profiler caffe cudnn multiple profile periodic synchronization successive layer exist throughout backward workload significantly layer layer kernel concurrency layer profile kernel training phase warp occupancy kernel percent profile vgg axis rectangle kernel regard TurboDL kernel concurrency kernel critical overlap kernel critical periodic synchronization layer kernel non critical mostly overlap kernel layer asynchronous execution achieve TurboDL utilize resource layer balance workload layer moreover critical mostly critical prioritize execution non critical computation shorter overall iteration caffe cudnn vgg TurboDL vgg overhead manage schedule inefficiency kernel execution contention register allocation utilization memory future convergence evaluation verify propose guarantee correctness retain dependency convergence iteration vgg cifar dataset loss decrease iteration increase nearly loss rate caffe cudnn correctness moreover shorter convergence iteration therefore overall training convergence iteration reduce uneven convergence trend model parameter opportunity future optimization future convergence comparison inference accuracy model TurboDL caffe cudnn identical dataset iteration hyper parameter accuracy due limitation data dependency layer correctly maintain TurboDL consequently accuracy ensure achieve modify algorithm improve inner layer parallelism remove unnecessary inter layer synchronization optimize schedule grain sub task iteration network moreover grain decomposition critical identification priority assignment pre processing phase amortize iteration related gpu memory optimization DL gpu memory becomes bottleneck training network propose vDNN  propose mitigation strategy offload intermediate host memory pre fetch backward propose computation computation memory occupancy mxnet strategy memory data lifetime analysis however model limit practical deployment embed device research construct model parameter computation complexity reduce model MB MB gpu memory optimization particularly important dynamic graph optimization DL recent model dynamic neural network structure training  batching tensorflow fold proposes dynamic batching technology batch inter input inner input operation cavs introduces model graph processing dynamic network static vertex function dynamic instance specific graph avoid graph construction facilitates incorporate static graph optimization technology propose program model distribute machine dynamic tensorflow recursion exist program framework exploit efficient parallel node propose cellular batching improve latency throughput rnn inference improve expressiveness efficiency dynamic recursive network important trend machine model realistic deployment orthogonal literature apply dynamic network improve efficiency training optimization computation DL focus cnn training phase complicate directional dependency backward computation iterative characteristic improve training performance increase memory access efficiency transform storage dimension data apply kernel fusion technology parallelism operation data execution model apply framework tensorflow mxnet however framework apply topological schedule coarse grain operation ignore importance characteristic network structure suboptimal performance hardware manufacturer propose efficient linear algebra library intel mkl cuBLAS cudnn however library mainly focus layer coarse grain operation optimization matrix computation aware network feature adapt underlie gpu hardware feature pipedream proposes generalize pipeline model parallelize multiple worker inherently coarse grain propose generic communication scheduler introduce unified abstraction dependency proxy mechanism focus distribute dnn training communication bottleneck focus increase computation efficiency gpu propose computation graph optimizer automatically generates graph substitution formal theorem prover backtracking optimize graph orthogonal complementary enhance performance  improve parallelism incorporate concurrent kernel execution however optimizes layer training completely orthogonal conduct network architecture optimization grain asynchronous execution critical schedule priority conclusion develop TurboDL efficient framework accelerate training optimization developed TurboDL grain parallel mechanism decomposes computation layer expose parallel opportunity accurate dependency analysis asynchronous execution strategy eliminate synchronization isolation layer overlap computation balance workload critical schedule mechanism reduce overall although mainly utilize cnn effectiveness excellent potential apply complicate multi stage application detailed extension future