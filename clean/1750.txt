emerge application neural network demand chip memory bandwidth however stringent physical constraint chip package becomes expensive increase bandwidth chip memory besides transfer data across memory hierarchy constitutes consumption steadily increase  technology data reuse characteristic emerge application effectively increase bandwidth efficiency researcher reconsider processing memory pim architecture advance exploit recent integration technology 5D 3D stack albeit recent advance memory manufacturer developed proof concept silicon mention pim architecture host processor application code memory manufacturer cannot easily elegantly tackle aforementioned challenge propose innovative practical pim architecture demonstrate practicality effectiveness implement dram technology integrate unmodified commercial processor develop software stack exist application without source code evaluation pim improves performance memory bound neural network kernel application respectively atop performance improvement pim reduces per transfer overall efficiency application index processing memory neural network accelerator dram introduction neural network dnns machine ML algorithm widely various disruptive application significant economic societal impact convolutional neural network cnns computer vision CV recurrent neural network rnns processing isca program  lee shin  kang equally contribute nam sung kim correspond author nlp representative application recommendation model RM popular neural network NN layer compose network layer dominate execution NN layer popular NN model gate recurrent embed lookup batch normalization computational characteristic layer exhibit temporal spatial locality cache rate thereby demand chip memory bandwidth meanwhile demand improve efficiency continuously increase consume transfer data across memory hierarchy constitutes increase consumption  technology transfer data offchip dram device chip cache hierarchy register file processor consumes magnitude perform float FP operation processor performance efficiency execute layer primarily data transfer processor execution dram device bandwidth memory HBM introduce satisfy increase demand bandwidth per transfer bandwidth per transfer conventional dram tightly integrate processor substrate silicon interposer package instance tight integration package allows interconnects processor dram per transfer conventional ddr dram nonetheless recent rapidly model compute density memory bottleneck HBM costly increase overall bandwidth increase bandwidth per pin UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca interconnects stringent physical constraint package signal integrity factor expose bandwidth processor per transfer researcher reconsider processing memory pim architecture advance exploit recent package chip integration technology 5D 3D stack subsequently promising pim architecture emerge memory manufacturer developed proof concept silicon mention primary fold 3D 5D integration cannot automatically significantly bandwidth processor standard dram bandwidth dram device notably bandwidth processor considerable customization dram significantly increase orchestrate communication host memory processor pim architecture demand notable host processor application code memory manufacturer cannot easily elegantly tackle aforementioned challenge propose innovative practical pim architecture disturb component subarray commodity dram instead exploit parallelism bandwidth per transfer processor dram easily seamlessly integrate commodity dram demand component commercial processor dram controller architected host processor pim operation standard dram interface facilitate replacement JEDEC compliant dram pim dram demonstrate feasibility efficacy software stack implement propose pim architecture HBM dub pim HBM fabricate implementation dram technology integrate unmodified commercial processor concurrently exist NN application code without develop software stack knowledge HBM pim architecture fabricate dram manufacturer 5D integrate unmodified commercial processor software stack evaluation processor pim HBM execute memory bound NN kernel application faster respectively processor commodity HBM addition performance improvement pim reduces per transfer improves efficiency application organize II background dnn HBM pim architecture function standard dram pim dram IV detail pim microarchitecture focus execution depicts software stack pim VI describes chip implementation integration commercial processor vii evaluates performance efficiency IX discus related II background characteristic dnn application dnn comprises layer input output layer various application CV nlp RM composition layer develop dnn application efficiently popular ML program framework tensorflow pytorch apis mkl  formerly mkl dnn cudnn  apis built linear algebra subprogram blas blas scalar vector vector vector operation blas matrix vector operation benefit onchip cache data seldom reuse entire data chip cache consequently frequent chip memory access perform computation operation per byte performance ultimately bound memory bandwidth memory bound blas matrix matrix operation reuse considerable data chip cache operation per byte performance compute capability compute bound dnn application exhibit compute bound characteristic mainly perform compute operation matrix convolutional layer however memory bound layer gradually increase recent popular dnn application instance function rnn matrix vector multiplication memory bandwidth determines performance addition batch normalization BN skip connection layer contemporary cnns memory bound due data reuse characteristic embed lookup layer component RM memory bound memory access embed sparse sum SLS operation bandwidth memory compute capability processor significantly increase demand chip memory bandwidth satisfy demand HBM introduce HBM 3D stack multiple dram buffer comprises circuit memory built  feature debug memory bandwidth dram communicate buffer silicon vias TSVs buffer decoder driver amp decoder sub array amp local wordline TSVs logic logic pseudo channel host MC interposer BK ASIC ASIC DA IO IO package sip buffer HBM package sip comprise ASIC HBM device HBM dram organization host processor silicon interposer package integration host processor HBM device package sip package depicts typical sip comprise ASIC HBM device HBM dram organization HBM dram comprises pseudo channel  consist bgs logic data bus tsv circuitry comprises datapath resource  logic receives dram command address CA decodes CA generate signal address delivers generate signal target  data bus tsv circuit CA consists dram array decoder amplifier  driver dram array compose sub array sub wordline driver  bitline amplifier  local LIO sequence data access operation almost ddr dram activation RD WR precharge pre data access access HBM transfer data burst pch dram constitutes rank  HBM device stack dram rank capacity bandwidth  rank HBM dnns suffer limited memory bandwidth utilization processor limited performance bandwidth integrate processor HBM device however thermal budget sip connection silicon interposer limited pim dram architecture pim architecture exploit parallelism expose chip bandwidth standard dram processor practical although illustrate HBM applicable standard dram ddr LPDDR GDDR dram overview overview pim architecture pim HBM dram pim dram couple pim execution comprise instruction multiple data simd float FPU command scalar register file crf grf SRF datapath pim execution philosophy standard dram pim dram mode versatility minimize engineering dram sub array pim pim execution boundary pim mode pim execution across concurrently respond standard dram RD WR command host processor execute simd operation command pim instruction deterministic latency lock manner pim instruction crf instruction buffer dram command trigger execution pim instruction IV detail pim execution datapath operand  register bus address dram  URP     ULWH  HQVH PSV     DQN URP  ULWH    XV LH HBM dram organization couple pim pim datapath RD command determines address operand  per across parallel dram WR command operates manner dram RD command host processor driver pim register pim expose per pch bandwidth pim execution processor chip standard dram interface pim execution onchip compute bandwidth execution pim instruction standard dram command deterministic latency essential facilitate pim dram unmodified  dram controller finally host processor execution pim instruction load LD ST instruction translate standard dram command dram host processor precisely address timing pim operation pim operation couple dram command execute deterministic timing host processor independently pim operation memory channel addition pim execution access memory data access granularity host processor pim agnostic physical address mapping scheme host processor elegantly efficiently handle coherence consistency challenge without exist processor prior pim architecture parallelism pim mode standard dram device command target specific address BA BG activate response command refer standard dram operation mode mode SB mode mode contrast standard SB mode expose chip bandwidth dram pim execution concurrent access multiple dram command implement logic operation mode AB mode BA BG address ignore concurrently access lock manner dram command AB mode pim HBM per pch chip compute bandwidth standard HBM tCCD delay command AB mode tCCD delay command tCCD tck typically tCCD tck compute bandwidth improves PIMHBM operating 0GHz 8GB per pch  OO DQN   HPRU      II     DQN  HPRU   HPRU   HPRU   HPRU      HPRU   HPRU   BB LW BB   pim HBM operation mode SB mode AB mode pim  mode pim execution TB pch HBM 6GB per pch host processor pim mode addition AB mode AB pim mode proceed AB mode AB mode dram command apply mode however AB pim mode dram command trigger execution pim instruction crf update pim program counter PPC pim instruction AB pim mode consume transfer data circuit interface host processor consumption substantial offset increase pim execution operating concurrently vii transition mode transition SB AB mode unmodified host processor standard dram interface mode register MRS command however user cannot easily access mode register privileged supervisor typically mode invoke privileged kernel MRS approach overhead context switch incurs significant performance degradation implement mode transition SB AB mode performance overhead propose sequence standard dram command implement configuration register AB mode register  SB mode register  mapped reserve memory pim conf AB mode host processor sends sequence pre command specific address pim conf exit AB mode host processor  buffer conflict transition SB mode approach compatible processor adopt JEDEC compliant dram controller relies standard dram command exit AB pim mode pim OP mode register mapped address pim conf respectively relative mac dram technology normalize int mac accumulative register format int acc int acc int acc FP bfloat FP pim mode configuration command scalar register mapped specific reserve memory address access standard dram command instruction architecture data operation primary target accelerate memory bound ML kernel mention II blas axpy CV blas gemv nlp kernel memory bound although int operation widely inference FP operation become prevalent inference training besides brain float format bfloat optimize ML application emerge bfloat preserve exponent FP reduces significant allows conversion FP wider dynamic FP rationale bfloat minimize FP compute accuracy ML application however standard specialized int int FP bfloat FP accumulate mac dram technology FP mac implement dram limit mac compute capability FP bfloat mac wider dynamic int mac offering comparable int mac FP bfloat mac bfloat mac slightly energyefficient FP mac nonetheless FP natively processor widely ML application implement FP mac bfloat mac efficiently ML application application domain OpenCL opencv hpc application built legacy FP library addition relu operation NN layer typically activation function relu II operation operand source destination operand src operand src dst combination mul grf grf SRF grf grf SRF grf SRF grf mac grf grf SRF grf mad grf grf SRF SRF src grf mov relu grf grf return zero input negative otherwise return input various activation function relu widely advantage sigmoid variant implement multiplexer input friendly  ML accelerator inference accuracy sigmoid variant lastly data movement grf SRF IV detail grf SRF II pim operation operand source destination source operand grf SRF couple pim execution operation various combination operand source pim operand combination computation data movement implement relu data movement operation flag determines relu perform data movement IV detail instruction format pim execution typical RISC style instruction instruction summarize nop exit instruction mul mad mac arithmetic instruction chosen accelerate ML application mov data movement instruction load data register pim execution essential instruction pim microkernel program crf reduce overhead zero cycle instruction computation target address  iteration pre decode instruction fetch decode stage addition kernel execute host processor microkernel execute pim execution pim HBM instruction format opcode imm imm data opcode dst src dst src src alu opcode dst src src src dst src src technique address align mode AAM IV multi cycle nop efficiently implement instruction limited entry crf arithmetic instruction src src src instruction operand grf grf SRF SRF dst src src register index operand register file mac performs operation grf grf src grf grf register dst mad operation grf SRF SRF src src register index register file SRF SRF respectively denotes relu determines mov performs relu operation data movement mov relu indicates mov instruction unused finally address align mode arithmetic instruction IV pim microarchitecture microarchitecture pim execution component pipeline instruction mechanism component pim execution consists component simd FPU register file controller depict limit pim execution instead pim execution per pim execution access denote odd simd FPU consists FP multiplier adder stage register file crf grf SRF crf instruction buffer comprises register grf register evenly split grf grf odd respectively SRF replicates simd FPU source operand consists SRF SRF register scalar multiplication interface odd interface FP mult FP grf grf crf SRF local bus local bus odd internal command address microarchitecture pim execution instruction sequence manager register file simd FPU addition respectively controller fetch pim instruction crf decodes instruction pim instruction source operand simd FPU grf pipeline pim execution pipeline stage satisfy dram internal timing reading data stage fetch decodes pim instruction stage load data odd grf register input simd FPU address data buffer RD command host memory controller AB pim mode RD command transfer data chip external interface instead trigger execution pim instruction pim execution skip stage pim instruction data mad grf grf grf source operand specify instruction operand buffer specify instruction instance grf grf pim instruction explicitly specify instead memory address pim instruction implicit address currently address command trigger execution instruction PPC fourth stage mult respectively mac fourth stage mult skip fourth stage respectively fifth stage writes grf register instruction pim microkernel mac operation crf perform gemv mac instruction address RD command trigger execution instruction RD command host processor gemv kernel implicitly couple specific mac instruction command pim programmer pim dram however dram controller dram command maximize performance associate address mac instruction operand guarantee functional correctness pim microkernel warrant dram command pim dram programmer intend dram access however memory access fence incur considerable performance penalty minimize performance penalty propose mechanism tolerate outof memory access dubbed address align mode AAM       HPRU       HFXWLRQ   mac instruction gemv microkernel BA RA CA denote address assign AAM flag pim arithmetic instruction allows program mac operation pim instruction source destination operand src src dst ignore replace sub address dram command constraint assign register index src src dst program pim microkernel nonetheless constraint limitation although register src src dst operand source grf grf SRF SRF odd unique operand destination pim aim accelerate vector vector vector matrix operation kernel execute arithmetic instruction repeatedly incrementing source destination register index linearly moreover vector data parallelism operand fed operation propose mechanism pim instruction execute pim software stack programming model software  specifically pim software stack allows user unmodified source code popular ML framework tensorflow subsequently program model code software stack exist ML application adopt  without source code adapt exist ML software stack illustrate software stack orange additionally implement pim dram pim device driver reserve memory pim operation booting reserve memory uncacheable host processor sends dram command memory access pim memory request upper software layer pim device driver allocates physically contiguous memory allows worry virtual physical address translation pim kernel pim blas         RUH    HVHW            pim software stack native execution modification application source code orange arrow pim execution explicitly pim TF custom ops arrow DD denotes device driver linear algebra operation exploit pim vector scalar vector matrix multiplication pim blas implement pim runtime user access utilize pim execution without handle pim pim runtime user module pim blas function specifically consists module preprocessor memory manager executor pim preprocessor analyzes source code application tensorflow TF ops suitable pim acceleration runtime identify TF ops associate operand data memory pim friendly generates pim microkernel code pim memory manager governs memory allocate pim device driver generate pim microkernel code crf command operand data cache later pim executor configures invokes pim kernel lastly pim blas function directly TF pim custom ops implement tensorflow framework explicit manual pim operation currently custom TF operation mul relu lstm gemv BN illustrates execution stack gemv pim custom TF pim custom directly correspond function pim blas library subsequently pim blas function  LE           pim ops python ops pim gemv ops pim execution pim kernel microkernel crf dram command execute pim microkernel gemv pim microkernel consists pim instruction mac grf  grf mac execute loop program model normal compute kernel performs operation device illustrate pim kernel memory request dram pim microkernel code pim dram properly execute depict therefore important aspect pim kernel program generate memory request address ensure memory request fully utilize chip compute bandwidth pim dram fully utilize compute throughput pim dram pim kernel sufficient memory request dram multiple thread sends memory request contiguous memory byte access byte per access fully utilize grf operand arithmetic operation maximum memory access memory access apis processor ISA byte thread generate memory request access byte illustrate thread allocate thread execute lockstep manner instruction depict therefore thread thread concurrently memory request memory controller synchronize thread guarantee memory request barrier apis barrier enforces constraint memory request issue thread belonging thread                HPRU        HPRU     DQN   HPRU  HDG ULWH  DQN   DQN DQN DQN     program model processor exploit pim thread exclusively access dram channel minimize unnecessary fence overhead memory request channel instance implement pim kernel allocates thread pim HBM  HBM cube  described earlier thread comprises thread thread VI chip implementation integration propose pim architecture HBM fabricate dram rigorously manufacturing quality standard commercial engineering sample IV depict specification pim execution pim HBM device respectively pim execution pim execution consists simd lane FP multiplier FP adder entry crf entry grf entry SRF implement approximately logic gate consume frequency HBM dram mhz mhz deliver  throughput operating frequency HBM dram memory bus frequency 0GHz 2GHz replacement HBM pim HBM physical dimension HBM HBM preserve mechanical compatibility exist 5D sip pim execution reduce dram sub array besides pim execution pim execution pim HBM dram  pch standard HBM dram pim execution per pch  per pim HBM dram photo fabricate pim HBM dram subsequently fabricate pim HBM dram  buffer illustrate IV specification pim execution mul FPUs datapath width lane operating frequency mhz mhz throughput gflops mhz equivalent gate logic instruction register crf vector scalar register grf SRF specification pim HBM device ext frequency 2GHz timing parameter HBM  per pch pim exe per pch chip compute bandwidth TB TB chip bandwidth 6GB 2GB capacity 6GB dram odd odd TSVs periphery odd odd odd odd odd odd buffer HBM stack HBM stack HBM stack HBM stack ban  array IM execution array  RS         pim HBM implementation sip 5D integrate pim HBM device processor photo fabricate pim HBM 3D stack PIMHBM photo manufacture pim HBM package photo processor sip pim HBM dram 3D stack buffer HBM dram 3D stack atop PIMHBM 6GB capacity 4GB PIMHBM 8GB HBM TB chip compute bandwidth  per operating per pch  per device 7GB bandwidth gbps per operating per pch  per device photo fully assemble package pim HBM device stack micro pillar grid array  package pim HBM technical specification host processor signal dram timing parameter precisely conventional HBM 5D integrate pim HBM device processor fpga verify pim HBM compatible JEDEC compliant memory controller functionally fpga comprises xilinx zynq ultrascale fpga socket package encapsulates HBM  package standalone HBM device  package cannot directly pcb due integrate silicon interposer package conventional package pcb precisely operation pim HBM consumption pim HBM lastly pim HBM device 5D integrate processor evaluation integrate pim HBM device unmodified processor compute operating 5GHz chip memory bandwidth processor TB chip compute bandwidth pim execution TB vii evaluation benchmark evaluate performance efficiency PIMHBM microbenchmarks vector matrix multiplication gemv wise addition frequently compute residual connection evaluation microbenchmarks apply various input obtain application VI furthermore toend evaluation performance consumption representative ML application nlp application baidu  DS google rnn transducer rnn google neural machine translation GNMT popular CV application alexnet resnet embed layer recommendation model  memory capacity 6GB processor integrate HBM suitable application limited memory capacity 2GB HBM device evaluation batch batch data reusability llc rate application  increase throughput nonetheless increase response hence focus evaluation application batch target pim HBM memory bound  application commercial online service DS consists convolution layer bidirectional lstm layer fully layer rnn another recognition model combination network lstm encoder layer dropout lstm prediction layer dropout fully joint network layer relu dropout variant model mlperf benchmark suite input data recognition model linear spectrogram extract clip GNMT consists lstm encoders lstm decoder attention layer evaluation approximately input alexnet comprises convolution layer fully layer resnet layer perform convolution operation VI microbenchmark gemv dim dim gemv gemv gemv gemv enc dec gemv DS rnn GNMT alexnet resnet average llc rate relative performance baseline normal HBM performance gain avg llc rate relative performance average llc rate batch denote llc rate DS rnn  alexnet resnet consist multiple kernel cannot report performance monitoring report llc rate kernel identify shortcut connection skip layer although layer alexnet resnet compute bound target pim evaluate completeness evaluation input CV model image finally accelerate lstm layer DS rnn GNMT fully layer alexnet performance performance HBM PIMHBM microbenchmarks ML application various batch analyze performance microbenchmarks batch pim HBM performance HBM microbenchmarks pim HBM improves performance gemv HBM performance improvement significantly chip compute bandwidth increase pim HBM gemv software stack processor optimize fully utilize chip memory bandwidth HBM pim HBM improves performance HBM kernel operand compute instruction limited grf register host processor execute fence instruction pim HBM executes pim instruction IV pim instruction execute limited register grf discus reduce overhead frequently execute fence instruction later DS GNMT alexnet pim HBM performance HBM respectively pim HBM considerably improves performance DS HBM DS spends execute lstm layer suitable pim acceleration GNMT lstm decoder invoke pim kernel layer output layer previous becomes input layer hence overhead kernel limit performance improvement GNMT input lstm encoder available reduce kernel encoder PIMHBM improves lstm encoder performance HBM although convolutional layer dominate execution alexnet pim HBM improves performance accelerate fully layer resnet pim HBM performance HBM execution resnet dominate convolution layer compute bound demonstrate pim HBM hurt performance compute bound application batch increase performance improvement pim HBM decrease PIMHBM improves performance gemv batch respectively HBM however batch processor HBM outperform pim HBM becomes memory bound reuse data llc confirm llc rate decrease almost batching transforms memory bound blas gemv  blas gemm pim HBM improve performance batch evaluation meanwhile blas memory bound regardless batch becomes blas batching summary batch pim HBM performance HBM DS rnn respectively performance ML application evaluation unmodified processor barrier dram  guarantee execution pim instruction AAM handle execution pim instruction IV overhead fence instruction prevents exploit potential pim HBM processor guarantee dram command pim mode evaluation remove fence instruction pim HBM performance HBM microbenchmarks batch respectively processor manufacturer confirms    XV   XV   breakdown HBM pim HBM  dram RD command HBM pim HBM operating  random FP dram command preserve pim mode negligible hardware performance lastly fpga rnn accelerator brainwave performance evaluate microbenchmarks data chip SRAM fpga arria SRAM  relies capacity bandwidth SRAM data processing meanwhile PIMHBM capacity dram target application kernel data SRAM suppose pim execution parallel access significantly increase consumption pim HBM HBM consumption fabricate pim HBM chip however pim HBM consume chip bandwidth HBM pim HBM multiple pim execution couple consumption dram internal component  decoder depict orange increase proportionally nonetheless consumption internal global bus phys considerably decrease summary consumption pim HBM slightly HBM within thermal TDP limit HBM consumption pim HBM HBM implement feature eliminate unnecessary consumption buffer data circuit toggle pim mode orange therefore pim HBM thermal advantage HBM consumption pim HBM proc HBM proc HBM pim HBM  processor integrate pim HBM HBM device respectively proc HBM denotes hypothetical processor HBM device proc HBM described VI consumption execution PIMHBM proc HBM estimate consumption proc HBM proc  proc HBM proc  proc HBM proc  proc HBM proc  proc HBM proc  gemv DS GNMT alexnet relative eff relative rel rel efficiency relative consumption processor HBM pim HBM HBM execution proc HBM proc HBM increase HBM device gemv pim HBM efficiency proc HBM proc HBM efficiency proc HBM consumption performance increase proportionally bandwidth memory bound application pim HBM perform relatively efficiency perform gemv operation improvement performance improvement execution application improvement efficiency microbenchmarks pim operation cannot apply layer essential software stack DS GNMT alexnet pim HBM efficiency proc HBM respectively ML application pim HBM efficiency proc HBM respectively lastly average consumption DS demonstrates pim HBM improves efficiency shorter execution average consumption exploration exploration evaluate pim micro architecture implement due constraint pin compatibility timing JEDEC compliant dram controller evaluation pim micro architecture perform simulation modify version DRAMSim simulation DRAMSim model per watt HBM IM HBM  average DS gmean gmean gmean gmean gemv BN relative performance performance improvement processor pim HBM BA  processor HBM  host processor estimate performance theoretical upper bound performance memory bound kernel specifically simulate performance enhance pim architecture pim execution resource denote pim HBM access odd operand pim instruction pim HBM BA BA access byte data dram datapath WR command another byte data address odd pim HBM   simultaneous dram RD WR command performance improvement processor pim HBM BA  processor HBM evaluate batch normalization kernel BN input pim HBM geo performance pim HBM increase pim HBM BA geo performance useful reduces performance bottleneck limited grf register notably increase consumes pim HBM pim HBM  geomean performance pim HBM performance gemv vector grf register dram WR command execute operation subsequent dram RD command discussion discus various challenge tackle handle future cache bypassing pim data memory memory pim operates uncacheable flush cached data associate memory memory pim data approach however notable performance degradation reduce performance degradation cache bypass instruction   armv          DQN DQN  DQN DQN   data layout pim directly request memory  buffer pim target accelerate application data cache memory uncacheable reduces interference contention cache improves performance data pim ecc virtualization multi tenancy PIMHBM ecc however future pim propose architecture easily ecc pim execution writes data data access granularity host processor addition dram ecc HBM pim leverage ecc generate ecc parity pim mode currently developed ecc scheme HBM generation pim HBM integrate pim HBM unmodified processor lastly pim HBM virtualization multi tenancy allows processor independently pim operation memory channel memory interleave data layout earlier host processor independently pim operation memory channel pim execution access memory data access granularity host processor aspect pim architecture agnostic physical address mapping scheme host processor prior pim architecture suppose physical address mapping scheme depict operand allocate byte align boundary illustrate data layout standard processor vector multiple byte vector multiple byte concatenate dummy vector overhead inefficiency negligible target vector cache maximize performance gemv however pim architecture data layout software aware physical address mapping scheme currently pim blas apis automatically rearrange data layout host processor brings matrix memory  data rearrangement gemv HBM generation pim HBM architecture grain interleave SB AB pim mode pim architecture opportunity host processor pim perform gemv collaborative eliminate data layout rearrangement approach future IX related researcher explore diverse pim architecture architecture concept exploit  parallelism expose abundant chip bandwidth dram processor however pim architecture recent exploit  parallelism dubbed newton lack consideration practicality adoption interface host dram interface commercial processor dram device define JEDEC standard adopt custom dram device standard interface host processor customize engineering customize processor dram device building ecosystem inevitably hinder adoption driven compatibility standard dram interface essential successfully quickly deploy pim dram device commercial software stack prior pim discus program model software stack approximates program model software stack performance without implement contrast software stack pim architecture fully implement precisely evaluate performance perform non cacheable memory access translate virtual address physical correctly access target dram interleave scramble physical address maintain dram command ensure functional correctness execute exist application without minimal modification source code lastly newton depth newton accelerates matrix vector multiplication mac dram limit application benefit architecture furthermore dram command JEDEC standard increase complexity dram controller dram due CA pin associate standard dram interface lose compatibility exist  dram controller importantly unlike newton neither implement commercial dram technology integrate commercial processor software stack evaluation conclusion propose practical innovative pim architecture seamlessly unmodified commercial processor replacement standard dram demonstrate practicality efficacy implement propose pim architecture commercial HBM dram fabricate dram technology integrate fabricate pim HBM unmodified commercial processor developed software stack evaluation pim reduce execution  neural network kernel application respectively improve efficiency application silicon implementation software stack development evaluation memory manufacturer wider adoption development pim player