frequent translation lookaside buffer tlb incur performance due fetch correspond address translation prefetching entry PTEs ahead demand tlb access mitigate address translation performance bottleneck prefetch traverse trigger additional access memory hierarchy therefore tlb prefetching costly technique undermine performance prefetches accurate exploit locality reduce enhance effectiveness tlb prefetching fetch cache adjacent PTEs propose sample tlb prefetching SBFP dynamic scheme predicts usefulness PTEs prefetches likely prevent tlb demonstrate combine SBFP novel theart tlb prefetchers significantly improves coverage reduces memory access due moreover propose agile tlb prefetcher ATP novel composite tlb prefetcher particularly maximize benefit SBFP ATP efficiently combine tlb prefetchers disables tlb prefetching execution phase benefit unlike tlb prefetchers correlate feature stride PC distance ATP correlate multiple feature dynamically enables appropriate tlb prefetcher per tlb alleviate address translation performance bottleneck propose unified combine ATP SBFP across extensive industrial workload qualcomm ATP couple SBFP improves geometric speedup eliminates average memory reference due spec cpu spec cpu benchmark suite ATP SBFP increase geometric speedup eliminates memory reference apply data workload gap suite xsbench ATP SBFP yield geometric speedup reduce memory reference tlb prefetcher benchmark suite ATP SBFP achieves speedup qualcomm spec gap xsbench workload respectively introduction virtual memory memory access translation virtual physical address processor translation translation lookaside buffer tlb tlb processor traverse translation incur significant latency additional memory access hence address translation significantly contributes memory access workload memory footprint locality prior quantify tlb performance propose approach mitigate overhead address translation approach mainly category increase tlb introduce hardware OS reduce latency tlb reduce tlb prefetching entry PTEs focus category tlb prefetching operates microarchitecture independent relies memory access application disrupt exist virtual memory subsystem prior tlb prefetching mechanism trigger background prefetch pte incur additional memory reference tlb prefetching hurt performance prefetched PTEs consume future tlb access although tlb prefetching reduce tlb additional memory reference trigger undermine potential performance improvement increase consumption exploit locality PTEs improve performance tlb prefetching reduce memory access consumption thanks locality contiguous PTEs within cache prior leverage locality increase tlb reduce exploit enhance performance reduce tlb prefetching demonstrate naively prefetching PTEs tlb prefetch queue sub optimal performance gain response propose sample tlb prefetching SBFP dynamic scheme predicts sample PTEs likely prevent future tlb fetch tlb prefetch UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca queue highlight SBFP combine tlb prefetcher achieve notable performance enhancement reduce memory footprint consumption address translation moreover proposes agile tlb prefetcher ATP composite tlb prefetcher particularly exploit benefit SBFP ATP driven analysis finding theart tlb prefetcher performs application workload benefit tlb prefetching due irregular unlike tlb prefetchers correlate feature stride PC distance ATP combine tlb prefetchers adapts prefetching strategy memory access application ATP relies mechanism logic dynamically selects appropriate tlb prefetcher accuracy prefetched pte usefulness correspond prefetches SBFP scheme adaptive throttle mechanism disables tlb prefetching phase benefit summary contribution evaluate tlb prefetchers industrial workload qualcomm spec cpu spec cpu benchmark suite gap suite xsbench propose sample tlb prefetching SBFP dynamic scheme exploit locality predict adjacent PTEs cache likely future tlb prefetch tlb buffer demonstrate combine SBFP novel tlb prefetchers performance benefit propose agile tlb prefetcher ATP composite tlb prefetcher combine tlb prefetchers maximizes impact SBFP ATP introduces adaptive selection throttle scheme enable appropriate tlb prefetcher per tlb disable tlb prefetching helpful propose unified combine ATP SBFP approach yield geometric speedup average reduction memory reference qualcomm spec data gap xsbench workload tlb prefetching respectively tlb prefetcher benchmark suite ATP couple SBFP improves performance qualcomm spec data workload respectively II background virtual memory subsystem virtual memory memory operation translation virtual physical address software hardware architectural reduce address translation overhead  pdp PD PT SE cache byte byte PMLE pte XA pte XA pte XA pte XA pte XA pte XA pte XA pte XA pte pte pte pte pte pte pte pte CR llc LC offset offset offset offset offset  pde LC locality software OS manage structure contains virtual physical mapping load memory architecture implement radix  pdp PD PT leaf hardware memory management MMU accelerates address translation tlb MMU cache TLBs cache recently address translation memory access tlb translation tlb request translation transfer cpu tlb traverse request translation introduce reference memory hierarchy per MMU cache structure cache  avoid reference memory hierarchy cache intermediate reference MMU cache correspond translation entry memory hierarchy llc dram hence latency depends locality MMU cache cache hierarchy processor implement multi TLBs tlb account majority cycle spent tlb handler tlb refer tlb unless otherwise locality depicts perform architecture illustrates locality PTEs PTEs contiguously memory pte occupies byte cache PTEs request pte memory grouped PTEs byte cache hence cache request address translation plus PTEs additional memory operation prefetched PTEs contiguous virtual physical address non contiguous physical fragmentation tlb prefetching tlb trigger incur significant latency overhead prefetching PTEs ahead demand access effective approach mitigate latency tlb tlb vendor radix demand tlb return cpu enable return  demand tlb return cpu tlb return cpu cpu prefetch PQ enable PQ prefetch logic tlb tlb prefetching diamond decision action prefetching scheme typically prefetch queue PQ buffer entry prefetched PTEs avoid pollute tlb content operation tlb prefetcher memory access tlb tlb request pte PQ translation PQ correspond entry tlb avoid processor replay request PQ translation demand trigger fetch tlb prefetching scheme activate prefetches tlb occurs prefetch request prefetch trigger background prefetch prefetched pte PQ issue prefetches tlb prefetchers correspond prefetches already reside PQ correspond prefetch request cancel finally non fault prefetches permit tlb prefetchers sequential prefetcher SP SP prefetches pte trigger tlb arbitrary stride prefetcher asp asp tlb prefetcher capture stride prediction entry PC index previous tlb access PC stride stride unchanged consecutive tlb asp prediction PC correspond entry stride invalid counter reset asp update stride previous stride counter increase otherwise reset entry finally prefetch counter distance prefetcher DP DP tlb prefetcher correlate distance virtual consecutive tlb prediction entry correspond distance index predict distance tlb DP computes distance previous virtual DP issue prefetches predict distance entry otherwise entry insert prediction sphinx gem xalan xalan gcc milc mcf omnet omnet astar mcf cactus GM spec GM QMM GM BD speedup pte locality tlb prefetcher SP DP asp perfect tlb performance SP asp DP perfect tlb without exploit pte locality entry correspond previous tlb update insert distance previous recently prediction entry motivation motivates tlb prefetching approach highlight potential performance improvement pte locality exploit tlb prefetchers II entry PQ demonstrate benefit pte locality tlb prefetching enhance tlb prefetchers unbounded PQ available PTEs cache return demand prefetch tlb prefetcher pte locality exploit available PTEs PQ demand idealize scenario perfect tlb access evaluation considers industrial workload qualcomm QMM spec cpu spec cpu suite gap suite xsbench refer gap xsbench data BD workload vii explains detail experimental setup workload motivational analysis finding tlb prefetching potential improve performance performance deliver tlb prefetchers perfect tlb scenario unbounded PQ exploit pte locality speedup compute tlb prefetching without exploit pte locality SP DP asp perfect tlb yield geometric speedup spec QMM BD workload respectively performance perfect tlb reveals improve tlb performance QMM BD workload exists tlb prefetcher performs across workload reveals benchmark irregularly distribute stride tlb cactus asp DP outperform SP contrast benchmark sequential tlb sphinx configuration parameter tlb prefetchers propose QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD normalize memory reference without pte locality pte locality arithmetic  SP DP asp normalize memory reference due SP outperforms asp DP due conflict prediction conflict asp DP discard capture stride execution regular tlb identify stride moreover SP asp DP cannot capture highly irregular mcf although SP asp DP ineffective irregular scenario trigger prefetch inaccurate prefetches exploit pte locality tlb prefetching purpose potential significantly improve performance depicts tlb prefetchers scenario without tlb prefetcher performance gain exploit pte locality performance report tlb prefetchers scenario without tlb prefetcher exploit pte locality demand tlb prefetchers issue prefetch exploit pte locality prefetch tlb prefetching induces additional reference memory hierarchy memory reference demand plus prefetch SP DP asp scenario without tlb prefetcher  memory reference refers reference memory hierarchy llc dram methodology account cache locality vii scenario evaluate without exploit pte locality normalization factor memory reference without tlb prefetching without exploit pte locality SP DP asp burden additional memory reference tlb prefetching respectively BD workload asp memory reference overhead due prediction ensures accurate prefetches issue behavior spec QMM workload exploit pte locality reduces memory reference pte locality exploit memory reference due significantly reduce SP achieves reduction tlb prefetchers issue prefetch request stride likely already fetch PQ due pte locality DP asp stride slightly reduce impact pte locality report improvement exploit pte locality tlb prefetching purpose assume ideal indefinitely PQ however tlb prefetching fundamentally limited PQ due latency overhead therefore combine pte locality exploitation tlb prefetching context properly PQ smart useful PTEs per IV sampling BASED tlb prefetching SBFP proposes sample tlb prefetching SBFP dynamic scheme exploit locality reduce improve effectiveness tlb prefetching SBFP sample predict cache adjacent PTEs likely prevent future tlb fetch tlb prefetch queue PQ moreover SBFP reduces negative impact prefetch combine tlb prefetcher demand prefetch envelope tlb prefetching described II PTEs additional memory operation prefetched cache hierarchy naive approach prefetch available PTEs tlb PQ however tlb prefetching limited PQ PQ lookup PQ overhead naively available prefetches per PQ limit performance benefit evict useful prefetches pollute PQ inaccurate prefetches evaluate therefore exploit benefit locality realistic PQ scheme dynamically identifies prefetches useful PTEs per address sample tlb prefetching SBFP dynamic scheme predicts via sample usefulness PTEs per fetch PQ likely future tlb SBFP define distance distance within cache pte demand translation another pte obtain request pte cache distance exclude overview SBFP scheme associate pte distance leverage information predict usefulness correspond PTEs component functionality SBFP module sampler distance FDT prefetch queue PQ sampler buffer responsible detect phase distance previously useless useful prefetches sampler entry virtual correspond distance pte PQ decision pte PQ sampler FDT pte FDT thr virtual distance PQ sampler thr thr thr thr thr thr virtual physical distance pte pte pte pte pte pte pte sample tlb prefetching mechanism compose saturate counter FDT counter monitor ratio distance finally PQ fully associative buffer virtual physical correspond distance prefetches operation explain operation SBFP assumes trigger virtual correspond identify request pte inside cache extract significant pte resides within cache calculate distance PTEs reside cache associate pte distance pte associate distance prefetch PQ sampler FDT counter correspond distance threshold counter exceeds threshold prefetch fetch PQ otherwise sampler specifically pte distance saturate counter FDT corresponds distance threshold pte PQ sampler procedure pte cache PTEs physical address virtual compute insert PQ sampler virtual prefetches compute virtual demand translation plus correspond distance PQ sampler occurs FDT counter corresponds distance entry increase instance PQ sampler prefetch associate distance simply increment FDT counter prevent permanent saturation decay scheme shift FDT counter FDT counter saturates summarize SBFP adjusts FDT counter distance frequently PQ sampler SBFP capable predict useful PTEs per sampler PQ lookup PQ sampler generic tlb enable background critical demand update FDT prefetching tlb return cpu mechanism prefetch fetch prefetch PQ return cpu tlb PTEs sampler SB PQ FP module PTEs sampler SB PQ FP module combine SBFP generic tlb prefetcher diamond decision action critical FDT compose counter entry fully associative sampler fifo replacement policy finally threshold pte PQ sampler insight effectiveness SBFP workload typically multiple data structure distance perfect knowledge useful distance per data structure FDT per structure incur complexity alternatively propose generalize SBFP learns access decay mechanism ensure useful distance evaluate ideal scenario FDT per PC tlb modest performance gain generalize FDT worth complexity counter generalize FDT saturate decay mechanism lower increase sensitivity data structure finally analysis indicates counter saturate capture transition across data structure combine SBFP tlb prefetching scheme demonstrates SBFP combine tlb prefetching scheme exploit benefit locality demand prefetch generic tlb prefetching module SBFP operation interaction SBFP tlb prefetcher tlb prefetcher SBFP PQ prefetch request tlb request translation PQ PQ demand initiate fetch translation background sampler sampler increment FDT counter corresponds distance entry demand SBFP scheme operates decides PTEs PQ sampler explain IV PQ demand avoid translation transfer tlb prefetch increment FDT counter corresponds distance entry PQ tlb prefetcher activate prefetches prefetch trigger prefetch fetch correspond translation prefetch prefetched pte grouped PTEs prefetched due locality SBFP activate prefetches PQ sampler essentially apply lookahead prefetching finally prefetched PTEs PQ elaborate operation SBFP combine tlb prefetcher tlb virtual PQ demand initiate fetch correspond pte SBFP FDT counter threshold identify useful distance assume distance exceeds threshold SBFP fetch PQ pte PTEs sampler assume tlb prefetcher issue prefetch request similarly SBFP pte PQ PTEs sampler SBFP combine tlb prefetcher highlight enhance tlb prefetchers SBFP significantly improves effectiveness finally tlb prefetcher aim maximize benefit SBFP agile tlb prefetcher ATP introduces agile tlb prefetcher ATP novel composite tlb prefetcher implement decision unlike tlb prefetchers II correlate feature constant stride PC distance consecutive tlb ATP capture correlate feature combine tlb prefetchers ATP utilizes adaptive selection throttle scheme dynamically enable appropriate tlb prefetcher disable tlb prefetching helpful ATP overview depicts hardware component ATP tlb prefetchers prefetch queue PQ moreover ATP modest additional logic selection throttle mechanism saturate counter enable pref throttle mechanism saturate counter dynamically accurate tlb prefetcher fake prefetch queue FPQ per constituent prefetcher monitor accuracy update enable pref accordingly FPQ predict virtual correspond address translation hence fake FPQ ATP module FPQ PQ enable pref PQ logic SBFP update  FPQ FPQ FPQ logic SBFP FPQ logic SBFP FPQ update FPQ update FPQ FPQ FPQ FPQ enable pref disable prefetching disable prefetching functionality flowchart ATP operation operation ATP ATP translation virtual  constituent tlb prefetchers outcome saturate counter update FPQ enable pref increase issue prefetch request otherwise enable pref decrease increase confidence disable tlb prefetching ATP update saturate counter decision enable pref counter responsible enable disable tlb prefetching significant enable pref decision issue prefetch request probed individual tlb prefetcher generate prefetches tlb significant prefetcher reside leaf otherwise responsible prefetcher likewise significant prefetcher otherwise prefetcher issue prefetches finally significant enable pref zero prefetch request issue subsequently update content  constituent tlb prefetchers FPQ virtual correspond prefetches issue individually prefetches plus prefetches SBFP completion fake fake prefetches usefulness tlb prefetcher future tlb building ATP ATP compose easily implementable tlb prefetchers stride prefetcher stp stp aggressive version SP II stp stride prefetching tlb virtual stp prefetch PTEs prefetcher HP HP distance virtual tlb assume distance virtual tlb HP prefetch PTEs virtual modify arbitrary stride prefetcher MASP MASP evolution asp issue prefetch request asp consecutive prediction entry display stride policy increase accuracy asp prefetching opportunity MASP implement modification asp requirement stride twice consecutively remove prefetch tlb virtual correspond stride entry prediction MASP PC index previous virtual tlb access PC correspond stride assume tlb virtual prediction MASP respective entry virtual stride MASP prefetch PTEs computes distance insight effectiveness ATP ATP enables stp HP MASP tlb correlate stride distance virtual tlb PC respectively aggressiveness stp HP negatively impact performance trigger highlight ATP minimizes negative enable stp HP likely accurate prefetches tlb exhibit irregular throttle scheme ATP disables prefetching observes predictable constituent prefetchers leverage operation  assign leaf node HP MASP stp respectively finally counter enable pref respectively FPQ entry fully associative buffer fifo replacement policy VI important  ATP SBFP elaborates important aspect ATP SBFP account operating impact replacement policy prefetches speculative ideally influence access prefetched however memory consistency model architecture dictate TLBs accommodate translation status tlb prefetches oblige access consequence inaccurate prefetches negatively affect replacement policy sub optimal decision prior tlb prefetching impact replacement policy due memory capacity however advent heterogeneous memory OS migrate data memory accurately access important proposal ATP couple SBFP negligible impact replacement policy component description ITLB entry cycle entry MSHR DTLB entry cycle entry MSHR tlb entry cycle entry MSHR cycle structure split  cycle cache  entry fully pdp entry fully PD entry prefetch queue entry fully assoc cycle sampler entry fully assoc cycle icache KB cycle entry MSHR dcache KB cycle entry MSHR prefetcher cache KB cycle entry MSHR stride prefetcher llc MB cycle entry MSHR dram 4GB trp tRCD tcas simulation parameter multiple neither ATP SBFP modification multiple address translation ATP issue prefetch request per prefetch candidate assume KB MB granularity prefetch discard approach imply additional complexity architecture speculative SBFP prefetches valid translation entry PQ sampler valid PT entry PD entry PD entry MB PD entry PT entry finally PQ fully associative avoids index implication context switch ATP SBFP leverage structure quickly flush context switch tag address identifier vii methodology workload workload qualcomm QMM  benchmark spec cpu spec cpu suite data workload gap suite xsbench QMM industrial workload gap suite graph processing kernel input graph report input graph tlb intensive combination per kernel xsbench evaluate grid tlb intensive refer gap xsbench workload data BD workload massive memory footprint workload tlb MPKI rate tlb intensive account evaluation MPKI selection workload QMM workload spec cpu workload BD workload trace obtain simpoint methodology spec cpu BD workload warmup instruction billion instruction execute experimental QMM workload warmup instruction instruction simulation infrastructure evaluation ChampSim detailed simulator model prefetcher description SP static distance DP distance entry static distance asp PC entry static distance stp static distance HP static distance MASP PC entry static distance ATP MASP stp HP prefetchers fake PQ entry fully assoc static distance II configuration tlb prefetchers processor extend ChampSim realistic walker architecture model variant latency reference memory hierarchy cache locality prior specifically simulate walker split  walker concurrent tlb skylake microarchitecture initiate per cycle summarizes setup implement evaluate tlb prefetchers explain II II configuration evaluation focus KB evaluate consumption CACTI technology evaluation impact SBFP highlight benefit SBFP scenario prefetching exploit  prefetches PQ prefetches naively PQ  prefetcher optimal distance static offline exploration identifies useful distance per tlb prefetcher  explore distance performance tlb prefetcher II optimal statically distance tlb prefetchers performance impact tlb prefetching performance regard explain scenario tlb prefetchers assume entry PQ comment PQ speedup compute tlb prefetching reveals evaluate prefetchers achieve performance gain scenario prefetching   SBFP prefetching exploit  behavior prefetches PQ reduce demand prefetch request already prefetched avoid prefetch overall ATP SBFP yield geometric speedup QMM spec BD workload respectively regard tlb MPKI rate ATP SBFP reduces tlb MPKI reduction QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD speedup    SBFP SP DP asp stp HP MASP ATP performance impact tlb prefetching scenario QMM reduction spec reduction BD workload ATP SBFP stateof tlb prefetcher across benchmark suite scenario exploit prefetching ATP SBFP outperforms tlb prefetcher  QMM spec BD workload respectively addition ATP SBFP improves performance stateof tlb prefetcher  QMM spec BD workload respectively finally ATP SBFP outperforms tlb prefetcher  QMM spec BD workload respectively  outperforms  QMM BD workload spec workload behavior happens static selection overall useful distance static exploration cannot non distance seldom beneficial specific execution phase  outperforms  fetch available PTEs PQ disadvantage   examine usefulness prefetches PQ thrash however SBFP identifies useful PTEs per execution phase combine advantage   evaluation PQ entry average performance reduction respect entry PQ respectively  negligible performance improvement entry PQ entry PQ optimal tlb prefetching highlight prefetching reduces tlb prefetching normalize memory reference trigger demand plus prefetch scenario exploit prefetching tlb prefetchers memory reference refers reference memory hierarchy llc dram account cache locality memory reference vii normalization factor memory reference demand without tlb prefetching increase memory reference prefetching exploit  prefetches QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD QMM spec BD normalize memory reference SP DP asp stp HP MASP ATP    SBFP normalize memory reference due prefetch reduction demand prefetch introduce focus BD workload SP DP asp stp HP MASP ATP additional memory reference scenario without tlb prefetching respectively technique exploit prefetching significantly reduce memory reference majority prefetches prefetch proactively fetch PQ prefetches prefetches PQ demand prefetchers reduction memory reference SBFP behavior occurs SBFP tlb   eliminates demand overall ATP SBFP eliminates memory reference due scenario without tlb prefetching QMM spec BD workload respectively readability normalize memory reference trigger demand prefetch however memory reference cache hierarchy incur latency dram latency demand critical latency prefetch former critical latter performs background elaborates implication evaluation ATP couple SBFP ATP couple SBFP tlb prefetchers approach improve tlb performance prefetchers entry PQ performance performance SP DP asp ATP SBFP evaluate workload spec workload geometric suite GM non tlb intensive workload tlb intensive workload ATP SBFP outperforms prefetchers achieve geometric speedup already propose tlb prefetcher QMM spec BD workload respectively focus BD workload ATP couple SBFP overall improvement moreover workload  twitter DP performance exhibit distance correlation  qualcomm workload speedup SP DP asp ATP SBFP  SBFP  bfs kron bfs  twitter twitter kron twitter web twitter twitter kron hash  geomean speedup SP DP asp ATP SBFP sphinx gem xalan xalan gcc milc mcf omnet omnet astar mcf cactus GM GM  speedup SP DP asp ATP SBFP performance comparison ATP couple SBFP tlb prefetchers DP outperforms ATP ATP enables HP distance correlation although DP capable detect complex distance HP highlight ATP significantly outperforms constituent prefetchers stp HP MASP highlight ATP efficiently combine prefetchers appropriate prefetcher per tlb disable prefetching validate statement ATP enables constituent prefetcher stp HP MASP cannot capture access spec workload ATP disables prefetching xalan mcf benchmark stride milc ATP enables mostly stp MASP enable tlb correlate PC cactus mcf explain ATP enables HP confident HP useful prefetches HP distance pollute PQ content inaccurate prefetches reveals spec workload benefit distance correlation ATP enables HP contrarily QMM BD workload twitter  exhibit distance correlation tlb hence ATP enables HP QMM BD workload respectively specifically  ATP selects HP prefetching explain DP outperforms ATP selects MASP stp HP disables tlb prefetching QMM spec BD normalize PQ MASP stp HP SBFP ATP ATP ATP percentage PQ ATP constituent prefetchers SBFP ATP workload evaluation verifies combine ATP SBFP address finding furthermore breakdown normalize PQ proposal across workload PQ ATP SBFP module moreover PQ ATP subcategories PQ MASP stp HP constituent prefetchers ATP average prefetch request issue constituent prefetchers ATP responsible PQ regard QMM spec BD respectively notably SBFP tlb responsible PQ QMM spec BD workload respectively ATP SBFP equally significant role achieve significant performance enhancement tlb prefetching average normalize memory reference due demand plus prefetch memory reference demand without tlb prefetching moreover breakdown memory reference demand prefetch breakdown memory hierarchy serf memory reference demand prefetch QMM workload ATP SBFP reduces memory reference SP DP asp burden additional memory reference report spec workload BD workload reduction memory reference spec QMM workload prefetchers unable accurately detect highly irregular tlb notably ATP SBFP reduction demand workload PQ proposal reduces memory reference prefetch prefetchers exploit SBFP prefetch QMM spec SP BD QMM spec DP BD QMM spec asp BD QMM spec ATP SBFP BD normalize memory reference llc demand dram prefetch normalize memory reference due PTEs otherwise prefetch fetch throttle mechanism ATP disables tlb prefetching helpful stride selection mechanism ATP enables stp stride mostly prefetches addition proposal reduction memory reference dram access prefetchers workload ATP SBFP drastically reduces dram access demand performance benefit introduce dram access prefetch critical takeaway proposal reduces memory reference performance penalty hardware PQ entry virtual physical plus attribute prediction entry MASP PC virtual stride FPQ entry virtual entry PQ SP DP asp ATP KB KB KB KB respectively ATP slightly expensive tlb prefetchers sampler entry SBFP virtual plus distance FDT counter hence SBFP KB implement examine impact evaluate ATP couple SBFP tlb prefetchers MB prior significant MPKI reduction workload MB although tlb MPKI rate workload ATP SBFP reduces average tlb MB cannot eliminate speedup impact SP DP asp ATP SBFP MB scenario baseline implies MB without tlb prefetching ATP SBFP geometric speedup QMM spec BD workload respectively SP DP asp negligible speedup spec workload contains benchmark mcf workload MB eliminate tlb finally PQ average prefetches prefetching MB amount memory KB QMM SP spec BD QMM DP spec BD QMM asp spec BD QMM ATP SBFP spec BD speedup performance comparison MB QMM SP spec BD QMM DP spec BD QMM asp spec BD QMM ATP SBFP spec BD normalize dynamic normalize dynamic consumption consumption baseline dynamic consumption address translation account access ITLB DTLB tlb  memory reference tlb prefetcher dynamic reduce demand due PQ increase access PQ sampler FDT trigger reference memory hierarchy prefetch dynamic consume address translation ATP couple SBFP tlb prefetchers ATP SBFP lower dynamic QMM spec BD workload respectively SP DP asp increase dynamic usage BD workload remark behavior proposal demand PQ decrease prefetch leverage SBFP module regard static consumption negligible comparison approach ATP couple SBFP technique improve tlb performance iso storage proposal without tlb prefetching fairness enlarge tlb specifically tlb augment entry without affect access storage ATP plus SBFP KB KB ATP SBFP outperforms scenario QMM spec BD workload respectively prefetching tlb prior leverage pte locality fetch PTEs directly tlb demand approach tlb prefetchers  useful PTEs approach FP tlb reduces performance QMM spec workload respectively due eviction useful PTEs tlb consistent prior PTEs performance comparison approach directly tlb pollute content previous prefetches directly tlb data workload evaluation reveals PTEs tlb increase performance BD workload workload massive tlb MPKI rate thrash tlb useful PTEs tlb improves performance ATP couple SBFP outperforms scenario behavior proposal prefetches directly tlb recency tlb  software approach modifies pte virtual subsequently access fundamentally approach microarchitectural modification markov prefetchers consist prediction indexed virtual entry contains virtual predict access approximate behavior recency tlb  enhance markov prefetcher entry prediction reveals proposal outperforms approach QMM spec BD workload respectively finally approach hardware budget infeasible realistic tlb coalesce coalesce approach rely contiguity virtual physical memory limited benefit contiguity absent due fragmentation contrarily SBFP exploit virtual address contiguity ATP relies memory access application therefore proposal orthogonal tlb coalesce ATP couple SBFP scenario perfect contiguity virtual physical memory tlb entry adjacent PTEs scenario delivers performance gain increase tlb proposal outperforms scenario QMM BD workload difference spec workload negligible cache prefetching cache prefetchers typically stride within KB physical hence stride limited tlb prefetchers capture stride prefetched trigger tlb data cache prefetchers tlb prefetching intuitively limit tlb capture justify observation convert offset prefetcher bop data cache prefetcher prefetch tlb bop similarity ATP couple SBFP identify useful stride per execution phase enrich delta bop negative version bop positive delta underestimate potential tlb prefetching bop tlb prefetcher improves performance QMM spec BD workload respectively ATP SBFP significantly outperforms bop benchmark suite bop examines effectiveness predefined delta unable capture stride tlb proposal capture generic ATP activates tlb prefetcher per tlb SBFP selects useful PTEs per moreover bop offset per gain confidence prefetching contrast proposal identifies faster useful offset ATP leverage operation fake prefetch queue enable appropriate tlb prefetcher SBFP learns usefulness PTEs concurrently finally proposal aggressive bop ATP enables constituent prefetchers per tlb SBFP offset exceed confidence threshold bop offset prefetched address translation ASAP ASAP hardware scheme lower latency index prefetch deeper radix ASAP improves performance QMM spec BD workload respectively ASAP important benefit  display rate workload spec QMM  rate potential limited BD workload  rate ASAP significant performance benefit combine ATP SBFP ASAP tlb prefetching orthogonal technique latency ASAP lower latency accelerate prefetch ATP combine ATP SBFP ASAP improves performance QMM spec BD workload respectively ASAP increase speedup proposal reduces latency prefetched PTEs fetch faster PQ improves timeliness prefetching beyond boundary cache prefetching data cache prefetchers trigger prefetches boundary prefetches translation resides tlb tlb cache prefetch proceeds otherwise fetch correspond translation tlb quantify impact beyond boundary cache prefetching tlb performance signature prefetcher spp cache allows beyond boundary prefetching performance spp ATP SBFP spp baseline corresponds QMM spec BD speedup spp ATP SBFP spp performance comparison spp IP stride cache prefetcher without tlb prefetching previous spp improves performance workload capture IP stride tlb indeed combine spp ATP SBFP significantly improves performance thanks proposal timeliness cache prefetches improve tlb avoid ATP SBFP speedup cache prefetcher beyond boundary interaction OS replacement policy VI inaccurate tlb prefetches harm replacement policy prefetch harmful replacement policy access correspond pte evict PQ without belong active footprint application prefetch request ATP SBFP harmful replacement policy QMM spec BD workload negligible probability negatively affect replacement policy harmful prefetches SBFP prefetches useful PTEs ATP dynamically enables tlb prefetcher disables prefetching confident issue prefetches avoid harm replacement policy prefetch useless trigger background reset access correspond translation negligible due harmful prefetches introduce proposal IX related locality prior identify locality PTEs exploit locality modify tlb increase virtual physical contiguity SBFP solely exploit virtual contiguity locality increase tlb efficiency propose tlb organization multicore fetch directly tlb PTEs away currently technique operates demand issue tlb prefetches target multicore tlb exploit locality fetch available PTEs gpu application issue tlb MSHR avoid delay demand prefetch wang exploit locality fetch PTEs tlb buffer demand without concrete implementation instead propose practical implementation dynamically exploit tlb prefetching sample multiple tlb prefetchers exploit locality demand prefetch proposal improves performance private per core TLBs cpu application tlb prefetchers propose tlb prefetchers multicore exploit tlb virtual core tlb entry leader core DP exploit distance predictable tlb across core ATP latter scheme reduce tlb latency reduce tlb improve performance  another approach pom tlb tlb memory memory reference per  reduces tlb application define appropriate format memory reference per hash propose resolve tlb faster radix tlb prefetching orthogonal approach speculation speculation approach translation predict processor execute instruction speculatively validation perform background approach affected OS fragmentation allocate contiguous virtual contiguous physical predict address translation increase tlb processor OS vendor increase tlb prior focus combine tlb TLBs per increase tlb reduce susceptible performance issue OS cannot allocate mapping due fragmentation hardware limited respect application approach bypass limitation scheme orthogonal hardware tlb prefetching rely explicit OS hardware CONCLUSIONS evidence exploit locality tlb prefetching purpose potential performance benefit ameliorate address translation performance bottleneck proposes sample tlb prefetching SBFP dynamic sample scheme identifies prefetches useful entry per agile tlb prefetcher ATP composite tlb prefetcher comprise tlb prefetchers introduce selection throttle scheme enable appropriate tlb prefetcher per tlb disable tlb prefetching extensive contemporary industrial academic data workload demonstrate combine ATP SBFP significant performance enhancement reduce vast majority reference memory hierarchy