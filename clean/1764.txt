memory processing NMP integrate accelerator within DIMM dual inline memory module buffer chip potentially performance relatively manufacturing however inevitable communication bottleneck arises memory bus peer DIMMs host cpu communication bottleneck bus limited communication memory aggregate memory bandwidth  NMP DIMMs DIMMs channel per DIMM communication bandwidth whereas computation resource local memory bandwidth per DIMM important sparse data intensive workload graph application sparse tensor algebra identify communication DIMMs host cpu easily dominates processing procedure previous DIMM NMP severely bottleneck performance tackle challenge propose inter DIMM broadcast implement utilized memory DIMM NMP hardware memory bus naturally broadcast  effective bandwidth broadcast remains DIMMs grows software sparse application implement broadcast dominate communication abc DIMM alleviates bottleneck communication DIMM NMP consist integral broadcast mechanism broadcast program framework minimize modification commodity software hardware stack evaluation abc DIMM geo speedup core cpu baseline outperforms NMP baseline average index memory processing inter DIMM broadcast broadcast framework sparse application introduction emerge data intensive workload graph application desire capacity data transfer rate strict quality service requirement memory bandwidth memory however cannot easily satisfy increase demand tight pin constraint therefore pressure memory computer architecture correspond author  liu  tsinghua edu tackle challenge various memory processing architecture propose computation data thereby avoid data transmission bottleneck memory bus appeal choice DIMM NMP integrates computation memory buffer chip dual inline memory module DIMM perform computation memory access DIMM parallel aggregate bandwidth boost DIMMs grows architecture potential capacity bandwidth feature relatively besides easily integrate commodity strike balance various consideration however inevitable communication peer DIMMs memory bus severely limit scalability DIMM NMP parallel computation multiple DIMMs basis  NMP performance inevitable communication peer DIMMs host cpu memory bus important sparse data intensive workload graph application sparse matrix vector multiplication spmv identify communication easily dominates processing procedure  NMP severely bottleneck performance drawback DIMM NMP  limited communication memory aggregate bandwidth memory bus DIMMs within channel per DIMM communication bandwidth degradation per DIMM computation capacity local memory bandwidth rapidly widen gap bottleneck overall performance acceleration widely adopt application impractical tackle challenge propose inter DIMM broadcast implement utilized memory DIMM NMP hardware memory bus naturally broadcast UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca per DIMM effective bandwidth broadcast remains DIMMs grows software sparse application implement broadcast dominate communication abc DIMM hardware software holistic consist integral mechanism intra inter channel broadcast broadcast program framework alleviate bottleneck communication concretely intra channel broadcast mechanism consists broadcast broadcast former broadcast data host cpu memory controller MC DIMMs channel latter broadcast data DIMM DIMMs MC philosophy abc DIMM implementation challenge computer architecture consideration inter DIMM broadcast manage constrain modification within host cpu MC DIMM buffer chip operating OS stack memory command propose broadcast mechanism unmodified dram chip implement command translate regular command DIMM buffer chip interface memory command cpu minimize architecture introduce address mapping mechanism MC fourth timing constraint command MC finite machine FSMs fifth enhance robustness equip abc DIMM advanced ddr feature ecc error correction command address parity finally friendly efficient api hide resource management correctness guarantee detail user contribution identify communication memory bus bottleneck data intensive application DIMM NMP bus memory communication unscalable propose inter DIMM broadcast promising communication memory abc DIMM consist integral broadcast mechanism broadcast program framework optimize overall performance stack implementation abc DIMM minimizes modification evaluation abc DIMM geo speedup core cpu baseline outperforms NMP baseline average II background dram memory organization illustrate memory consists independent channel memory architecture NMP within buffer chip channel DIMMs host cpu memory controller data bus command address bus DIMM organize hierarchy rank compose multiple buffer ddr command host cpu access data sends activation command address bus inform load data buffer subsequently sends RD WR command offset address request data launch data access RD command desire data buffer data bus conversely WR command cpu data data bus data bus buffer replace data specify offset address cpu longer access data buffer access another inform precharge pre command data buffer belonging proceeds subsequent operation apart command mention cpu mode register MRS command modify mode register dram device mode ddr timing constraint memory operation operation specific explicitly define strictly  host memory controller issue ddr command MC generally complex finite machine calculate timing constraint  pending command timing parameter reading tcl interval issue RD command data transmission data bus  gap issue WR command data burst  rank rank switch minimum gap issue memory access command rank essentially exists environment data bus concretely  termination setup chameleon mapreduce framework NMP baseline architecture increase rank channel data transmission bus becomes due load capacitance growth buffer chip DIMMs signal integrity DIMMs data buffer load reduce DIMMs  interestingly  efficient memory processing integrate processor buffer chip multiple  channel parallel obtain aggregate bandwidth memory performance boost utilize rank parallelism achieve enable DIMM processor access local rank baseline architecture chameleon mapreduce framework mention performance DIMM NMP essentially depends DIMM parallelism inevitably introduces parallel program issue communication task partition schedule chameleon pioneer DIMM NMP inherits mapreduce framework nda 3D stack predecessor guideline NMP style parallel program chameleon mapreduce framework execution NMP phase cpu processing phase cpu split input data DIMMs calculate intermediate NMP phase cpu processing phase cpu intermediate DIMM reduces output iterative workload output become input iteration apart chameleon mapreduce memory channel network mcn communication model NMP program enables convenient inter DIMM cpu DIMM communication virtualizing homogeneous ethernet link however neither attempt tackle communication bottleneck inherent memory NMP motivational analysis abc DIMM motivate holistic observation hardware software perspective hardware perspective bandwidth scalability comparison inter DIMM broadcast solves bandwidth scalability communication memory bandwidth scalability comparison channel configuration memory bus multiplexing communication medium essence communication cpu transfer data DIMM suppose DIMMs memory channel DIMM concurrent communication demand DIMM posse channel bus memory channel bandwidth however possession actual communication per DIMM bandwidth merely channel bandwidth illustrate per DIMM bandwidth halve inter DIMM communication data load cpu cache source DIMM destination DIMM transmit twice memory bus data intensive  workload increasingly DIMMs memory capacity deteriorate bandwidth seriously bottleneck performance inter DIMM broadcast solves expand effective channel bandwidth inter DIMM broadcast host cpu broadcast data DIMMs DIMM broadcast data DIMMs host cpu effectively memory bus bandwidth communication bandwidth reduction perfectly offset per DIMM bandwidth becomes invariant DIMMs physical  broadcast physically implement inter DIMM broadcast memory bus intuitively DIMM cpu transfer data bus physically voltage bus termination capacitor DIMM bus merely desire communicate completes DIMM transmit data local termination broadcast phenomenon already physically exists currently  communication curse blessing waste implement inter DIMM broadcast advantage already exist physical mechanism waste treasure consequently inter DIMM broadcast trigger negligible increase memory bus DIMM NMP already parallel operation multiple DIMMs channel increase broadcast  NMP trivial concern exist signal integrity signal integrity optimize communication broadcast utilize identical parameter setting broadcast implementation fortunately ddr standard already signal integrity optimization dynamic termination ODT mechanism calibration mechanism former allows DIMMs dynamically termination impedance ddr command pre configure parameter achieve satisfactory signal integrity latter  parameter startup variant environment calibration mechanism signal  parameter timing compensation optimal signal sample incrementally broadcast specific parameter setting correspond calibration feature mechanism acceptable signal integrity realize inter DIMM broadcast apart physical  remain broadcast mechanism computer architecture minor challenge task consideration abc DIMM software perspective data intensive application severely bottleneck communication DIMM NMP implement broadcast dominant bottleneck significantly reduce broadcast pagerank illustrative pagerank graph application spmv interpret specific generalize sparse matrix vector multiplication define specific semiring difference generalize  normal multiplication addition substitute respectively user define reduce operator therefore although discussion limited pagerank simplicity insight reveals apply workload pagerank algorithm graph application pagerank matrix vector involve generally permutation adjacency matrix vertex vector non zero adjacency matrix indicates source vertex destination vertex graph non zero corresponds pagerank specifically vertex graph web indicates existent link source destination goal algorithm calculate rank reveals relative importance calculation iterative rank calculate generalize matrix vector multiplication iteration graph adjacency matrix pagerank graph iteration chameleon mapreduce style implementation pagerank rank converge iteration rank vertex inverse vertex pre input vector generalize spmv operator selects input vector adjacent matrix reduce operator define normal addition iteration formally involve constant multiplication addition vertex omit simplicity generally pre negligible generalize spmv chameleon mapreduce implementation pagerank implement broadcast style implementation pagerank performance variation DIMMs normalize DIMM performance chameleon mapreduce style implementation communication ratio bandwidth utilization  style implementation DIMMs communication ratio broadcast style implementation DIMMs chameleon mapreduce simplicity channel implementation pre stage iteration matrix slice distribute DIMM advance iteration cpu split rank vector DIMM compute DIMM partial generalize spmv calculates intermediate output vector finally cpu intermediate DIMM derives rank vector obviously implementation cannot advantage broadcast identical data transfer display performance  style pagerank WK graph  configuration simulation setup evaluation detailed scheme scalability DIMMs speedup grows slowly cpu processing ratio bandwidth utilization cpu processing phase obvious cpu processing severely bottleneck overall performance bandwidth utilization cpu processing bottleneck essentially  communication bottleneck broadcast implementation communication bottleneck DIMMs mapreduce pagerank cast shadow DIMM however refactoring mapreduce implementation  communication bottleneck eliminate aforementioned inter DIMM broadcast pagerank implement broadcast style illustrate matrix slice distribute DIMM advance iteration DIMM posse unique rank vector initialize iteration broadcast vector DIMM cpu DIMM posse version vector communication phase calculate correspond rank vector vector partial matrix obviously broadcast dominate communication phase another feature implementation computation workload offload DIMMs cpu communication performance communication ratio implementation style without hardware inter DIMM broadcast chameleon mapreduce communication bottleneck overall performance consistent analysis hardware perspective broadcast implementation dominate inter DIMM communication  communication chameleon mapreduce hardware inter DIMM broadcast however communication greatly reduce performance communication ratio communication bottleneck remove almost linear scalability illustrate motivation  IV abc DIMM detail software hardware abc DIMM IV proposes broadcast framework programmer refactor target workload broadcast friendly implementation enable inter DIMM broadcast hardware IV illustrates integral broadcast mechanism intra inter channel setting mechanism detail hardware architecture IV goal minimize modification commodity cpu memory architecture IV demonstrates user friendly broadcast apis encapsulate resource management correctness guarantee detail broadcast framework broadcast framework aim restructure  communication intensive workload  mapreduce task distribute splitting input data  creates task partition output instead gathering output data mapreduce communication task fulfil broadcasting input data summarizes execution  framework parallel NMP computation phase broadcast communication phase iterative workload pagerank iteration broadcast framework intra channel broadcast mechanism cpu detects DIMMs synchronization barrier proceeds broadcast phase partial broadcast DIMM DIMM iteration broadcast NMP phase calculate DIMM local data non iterative workload spmv broadcast phase data layout initialization stage input data originally distribute  broadcast initialization cpu cache normal access broadcast DIMMs NMP friendly address mapping broadcast framework workload intuitively workload tailor conquer paradigm output calculate DIMM input data DIMM NMP thereby   framework inter DIMM broadcast mechanism inter DIMM broadcast consists intra channel mechanism inter channel mechanism former mechanism implement tweak ddr whereas latter realize assistance software cpu intra channel broadcast mechanism intra channel broadcast mechanism compose broadcast broadcast dataflows illustrate broadcast mechanism correspond traditional ddr writes writes data cpu MC relevant rank channel instead MC appoint specific broadcast address rank data identical location rank flexibility performance issue command distinct address across multiple rank consumes bandwidth severely degrades broadcast performance issue command broadcast broadcast bandwidth fully utilized broadcast essence cpu DIMM broadcast mechanism inter DIMM broadcast broadcast cpu load data source DIMM cache broadcast writes data halve broadcast bandwidth avoid overhead broadcast broadcast corresponds traditional ddr actually concurrent  broadcast request cpu source DIMM data bus DIMMs contrary treat request command simultaneously data bus local rank data broadcast avoid superfluous broadcast besides  destination rank involve broadcast transmit data identical location source rank broadcast implement command broadcast bandwidth achieve inter channel broadcast mechanism inter channel broadcast easily implement software broadcast broadcast displayed data broadcast multichannel cpu broadcast local channel load cache finally broadcast cached channel multi core broadcast phase implementation fully  potential broadcast framework multi channel configuration optimize multi core implementation communication phase data slice core broadcast data channel robin fashion simplicity DIMM channel iterative algorithm displayed non iterative workload broadcast replace normal robin broadcast writes channel scheme wise access optimizes buffer rate robin fashion minimizes channel access contention bandwidth utilization achieve implementation broadcast percentage approach iterative algorithm data layout initialization amortize across iteration inter channel broadcast mechanism implementation broadcast communication phase multi channel configuration non iterative algorithm data layout initialization broadcast percentage channel configuration broadcast memory access hardware implementation subsection detailed hardware architecture implementation aforementioned  broadcast mechanism illustrate philosophy abc DIMM manage constrain within host memory controller DIMM buffer chip constrain rank avoid complex impact dram chip internal mechanism address remapping restrict within chip expose rank access broadcast mechanism ddr command signal format introduce IV unmodified dram chip translate command regular ddr command DIMM buffer chip described IV IV modify address mapping finite machine FSMs host MC aim interface command cpu minimize IV associate command NMP computation finally IV ecc parity abc DIMM briefly broadcast command encoding  introduces memory command broadcast mechanism    RDB  corresponds broadcast mechanism RDB corresponds broadcast mechanism however realize performance broadcast command specifically broadcast rank channel unfortunately rank host MC issue precharge command activation command  command issue although  activation rank parallelize delay introduce command issue significant performance degradation broadcast version pre command correspond   respectively crucial introduce command encode signal ddr ddr standard already limited extreme tackle propose chip ID refer command utilized appoint specific layer stack dram device theoretically height however layer device rarely meaning safely adopt illustrate chip ID indicates broadcast command abc DIMM mode register buffer chip introduce enable disable broadcast command compatibility introduce mode register modify realize broadcast command mask disable broadcast specific rank enable respond broadcast command CS chip signal within specific latter mechanism multi  environment non broadcast DIMMs register broadcast command naturally mask CS signal trigger CS signal appropriately mask OS address mapping broadcast enable DIMM buffer chip DIMM buffer chip role realize function command illustrate broadcast command buffer chip translate regular ddr command translator dram device translation    translator specific rank detects  command simply transforms command regular WR chip ID correspond CS signal   translator exactly behavior translation however precharge command idle already precharged fortunately idle automatically ignore redundant precharge command accord JEDEC standard translation RDB complex accord broadcast mechanism RDB data specific rank broadcast data rank host MC source rank data RDB regular RD rank data RDB WR hardware architecture overall channel architecture modify buffer chip architecture translation translator modify address mapping scheme host MC modify FSM scheduler architecture host MC ddr signal format format definition command timing diagram  timing diagram RDB however serious arises timing parameter dram chip unlike regular WR interval data burst RDB command issue tcl  fortunately tcl generally  enable destination rank data translate RDB WR delay interval tcl issue rank translation timing diagram RDB respectively tcl happens  rare occasion timing delay RD command source rank instead broadcast enable host MC host MC expose broadcast mechanism cpu maintain appropriate ddr timing cpu detects broadcast command physical address broadcast flag displayed address mapping identify incoming transaction broadcast broadcast transaction address NMP friendly maintain appropriate ddr timing broadcast command architecture FSMs scheduler modification illustrate architecture broadcast queue correspond scheduler queue pending transaction rank scheduler decodes transaction specific ddr command timing constraint  arbiter obviously introduction broadcast affect rank BG FSMs constrain within DIMM buffer chip without structure rank therefore broadcast relevant timing constraint pile timing constraint regular command involve broadcast rank rank switch  subsequent broadcast command access rank access recent command occasion exist overlap constraint scheduler finally schedule important MC broadcast schedule existent mechanism normal access apply multi program environment NMP DIMM generally occupy task broadcast schedule actually simpler normal access multi program environment program environment evaluation conventional FR FCFS strategy adopt NMP mechanism implement broadcast framework host cpu broadcast data broadcast command informs DIMM compute NMP phase subsequently cpu detects completion NMP phase polling compute interrupt trigger data DIMM status compute proceed abc DIMM simd compute core optimize capable efficiently utilize DIMM local memory bandwidth previous cacheline scratchpad compute cpu optional cpu information DIMM besides compute interrupt host cpu signal reserve ddr standard facilitate host cpu DIMM compute introduce  command abc DIMM command specific register DIMM compute inform compute behavior encode regular MRS host MC request address identify register transaction load register queue opcode command derive request data command actually involve memory operation issue bus idle issue buffer chip deliver compute target register specify opcode command non broadcast operates DIMM DIMM broadcast style command implementation broadcast framework command inform DIMMs NMP phase ecc parity abc DIMM ecc important feature reliability abc DIMM  chip compute equip ecc enable MC NMP phase ecc compute MC host MC inform host  signal uncorrectable error broadcast ecc generate host MC broadcast correspond dram chip rank broadcast delayed ecc scheme adopt execution broadcast command ecc host MC broadcast data compute ecc data transfer DIMM postpone data compute NMP phase obviously scheme correctable error uncorrectable error ecc host inform software abc DIMM compatible parity broadcast checked parallel related rank challenge  data overwrite occasion partial failure instance failure occurs destination rank broadcast host MC inform alert source rank command rank cannot subsequent command overwrite broadcast source data redo broadcast cannot correctly  furthermore failure subsequent broadcast command complex abc DIMM  data overwrite eliminate software restriction comfortably  framework implementation performance overhead IV concretely cpu physical address allocate broadcast release exclusively source broadcast exclusively destination broadcast identical source physical address exclusively broadcast writes non broadcast access broadcast physical address redo guaranteed parity failure handle inter DIMM broadcast api implementation precede hardware implementation interface software flag physical address utilize interface user easy task subsection discus implementation apis broadcast memory mapping management enable user application access broadcast flag physical address OS establish correspond virtual  address mapping correctly broadcast flag processor cache lock feature utilized prevent undesirable cacheline eviction memory cache buffer broadcast framework implementation finally avoid disturb channel interleave mechanism adopt conventional address mapping physical address location across relevant rank channel simultaneously allocate broadcast efficient software broadcast implementation cache consideration safety correctness broadcast operation guaranteed hardware implementation instance suppose access  address instruction expectation realize broadcast cache however cacheline address exists cache memory access trigger load data trigger  operation tackle software implementation efficient broadcast  utilize avx instruction data memory non temporal memory hint bypass cache directly data memory controller broadcast normal avx load intrinsics load trigger broadcast clflush invalidate cacheline enable future broadcast evaluation report evaluation  abc DIMM perform DIMM NMP baseline broadcast mechanism contribute performance scalability abc DIMM channel influence scalability abc DIMM baseline feature benchmark application datasets influence performance scalability evaluate methodology evaluate abc DIMM baseline core cpu baseline  mapreduce style NMP baseline  broadcast style mcn alike NMP baseline mcn configuration summarizes configuration cpu baseline NMP adopt identical configuration abc DIMM NMP baseline abc DIMM broadcast enable chameleon mcn feature cpu DIMM inter DIMM  communication respectively comparison focus communication assessment derive estimation simd rtl synthesis synopsys DC TSMC technology chip memory technology estimate destiny convert technology factor apart broadcast mechanism difference NMP baseline abc DIMM program framework chameleon adopts  framework mcn abc DIMM broadcast framework simulation integrate ramulator zsim accurate simulator evaluate performance cpu baseline host cpu NMP evaluation abc DIMM host cpu modifies ramulator integrates propose broadcast mechanism correspond timing constraint evaluate performance DIMM compute simulator simd integrates ramulator cycle accurate DIMM local memory access simulation cpu code baseline compile flag benchmark evaluate algorithm comparison pagerank PR previously spmv calculates multiplication sparse matrix dense vector source shortest shortest specific source vertex vertex average  follower calculates  follower user average user implementation average calculation configuration cpu baseline processor configuration processor core OoO 2GHz L1D KB LI KB associativity L1D LI lru KB associativity lru llc MB associativity lru NMP host processor configuration processor core OoO 2GHz L1D KB LI KB associativity L1D LI lru KB associativity lru llc MB associativity lru memory configuration ddr 4GB channel DIMMs rank FR FCFS entry RD WR queue policy dram timing parameter tbl    tcl tRCD trp  tRAS tRC    twr DIMM compute chip KB scratchpad eDRAM KB buffer memory simd array frequency 2GHz II graph sparse matrix datasets USED evaluation graph vertex sparse matrix non zero livejournal LJ  PK wikipedia WK edu edu NLR abc DIMM mcn specifically broadcast framework calculate local average DIMM cpu local derives global average generally negligible former application iterative latter datasets II typical datasets various source LJ PK obtain social network WK edu web link datasets NLR obtain numerical analysis application performance comparison advantage broadcast mechanism abc DIMM display performance chameleon mcn performance abc DIMM chameleon mcn normalize performance core cpu communication computation ratio abc DIMM chameleon mcn DIMM configuration speedup abc DIMM NMP baseline core cpu channel memory evaluate benchmark performance channel DIMM channel DIMM configuration displayed architecture former configuration involves minimum communication reveals compute DIMM latter involves maximum resource evaluate  potential performance separately displayed NMP baseline chameleon mcn poorly channel configuration maximum DIMMs communication computation ratio evaluate architecture benchmark DIMM configuration communication computation ratio define ratio NMP processing communication broadcast abc DIMM  cpu processing chameleon initialization glimpse performance variation observation abc DIMM outperforms chameleon mcn advantage channel DIMM configuration relative performance abc DIMM baseline respectively reveal speedup cpu achieve average performance chameleon mcn abc DIMM maintains geo speedup inter DIMM broadcast abc DIMM performance  mcn abc DIMM achieve almost identical performance channel DIMM configuration partly local compute processing task DIMMs critical factor performance difference architecture confirms role communication reveal  ratio chameleon mcn achieve average respectively abc DIMM however ideal geomean ratio thanks broadcast mechanism safely conclusion communication bottleneck severely limit baseline performance greatly reduce eliminate broadcast enable abc DIMM fully utilize parallelization DIMMs achieve impressive performance feature application datasets exert evident influence performance concretely NMP baseline abc DIMM perform unlike pagerank computes vertex increase sequential local memory access DIMM  increase NMP computation communication portion relatively lower scalability increase enhance performance however spmv involves access feature performance mainly due communication subsection application feature dataset feature influence speedup obvious performance achieve NMP baseline edu specifically chameleon mcn display speedup relative speedup abc DIMM NMP baseline edu DIMM configuration easily speedup abc DIMM chameleon mcn core cpu DIMMs channel configuration communication computation ratio abc DIMM chameleon mcn DIMMs channel configuration communication overhead significant dataset fundamentally sparsity edu vertex ratio NLR however contradictory deduction communication overhead edu speedup NLR lower NMP baseline performance locality feature disturbs cpu cache lower cpu baseline performance therefore relatively speedup sparser dataset serious communication bottleneck important broadcast NMP scalability comparison closer  baseline NMP DIMMs simplicity discus pagerank spmv workload LJ edu datasets channel speedup abc DIMM NMP baseline core cpu DIMMs channel configuration correspond communication computation ratio variation displayed conclusion previous subsection abc DIMM NMP baseline almost linear scalability although chameleon slightly mcn performance DIMMs sink thereafter broadcast abc DIMM scalability reveal communication computation ratio baseline soar increase DIMMs ratio abc DIMM grows slightly thanks broadcast mechanism sparsity feature edu dataset influence performance NMP baseline speedup abc DIMM chameleon mcn core cpu DIMMs channel configuration communication computation ratio abc DIMM chameleon mcn DIMMs per channel channel configuration exhibit scalability edu performance quickly degrades DIMMs broadcast abc DIMM rate LJ consistent observation previous subsection spmv involve access feature performance pagerank DIMM configuration  fundamental broadcast strategy adopt pagerank spmv communication phase pagerank broadcast data memory channel implement broadcast involve  operation spmv however broadcast data layout initialization phase input data originally broadcast host cpu load data cache broadcast DIMMs channel broadcast writes incurs communication traffic pagerank offset spmv advantage access confirm display communication computation ratio  spmv significantly pagerank multiple channel scalability curve channel discus channel configuration subsection simplicity display speedup  ratio variation channel configuration axis DIMMs per channel multiple channel configuration observation channel evaluation significant difference reduce scalability channel configuration abc DIMM longer linearly LJ performance increase edu scalability however chameleon mcn performance almost fails DIMMs per channel exceeds edu LJ underlie increase channel DIMMs per DIMM computation workload relatively communication portion reveal therefore increase channel worsens communication bottleneck broadcast important mechanism DIMM NMP another difference performance spmv although abc DIMM performs pagerank gap pagerank spmv relatively lower channel configuration data load memory cache amortize across channel reduce communication overhead relatively enhance performance spmv VI related aside NMP II  trace relevant broadcast memory cache coherence distribute memory chip 3D stack NMP etc aspect target alleviate communication bottleneck DIMM NMP aspect target communication reduction NMP however broadcast multicast implement network chip target chip 3D stack NMP propose inter DIMM broadcast ddr memory bus broadcast framework bottleneck although bus style broadcast communication optimization knowledge prior propose broadcast ddr memory bus benefit broadcast examine NMP consideration challenge compatibility ddr standard lower architectural stack tackle challenge vii conclusion identify communication memory bus bottleneck DIMM NMP application tackle challenge propose abc DIMM alleviates bottleneck integral inter DIMM broadcast mechanism  program framework  implementation minimizes modification computer evaluation cpu baseline NMP baseline abc DIMM achieves speedup average