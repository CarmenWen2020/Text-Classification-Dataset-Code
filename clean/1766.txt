recent demonstrate promise resistive random access memory ReRAM emerge technology perform inherently parallel analog domain situ matrix vector multiplication intensive computation neural network dnns however ReRAM crossbar conductance crossbar situ computation assumes crossbar architecture ReRAM crossbar positive negative prime offset become positive isaac neither ideal crossbar incur extra offset  address propose FORMS grain ReRAM dnn accelerator algorithm hardware instead positive negative principle enforce exactly assume situ computation ensure crossbar naturally avoids additional crossbar polarize nicely generate alternate direction multiplier ADMM regularize optimization dnn training exactly enforce dnn achieve accuracy crossbar logical sub array enforce within grain sub array crucially sub array unique opportunity input  significantly avoid unnecessary computation reduce computation hardware easy implement susceptible  coarse grain architecture optimize dnn model FORMS achieves throughput improvement gop gop isaac frame per optimize isaac almost interestingly FORMS optimization framework isaac reflect importance software hardware optimization introduction neural network dnns become fundamental core enabler ubiquitous artificial intelligence thanks accuracy excellent scalability adaptiveness dnn model computation memory storage dnn model introduce substantial data movement challenge conventional von neumann architecture author contribute equally storage computation reduce data movement model compression technique hardware accelerator intensively investigate however moore potential acceleration architecture conventional technology limited argue drastic improvement achieve generation emerge device circuit technology beyond CMOS vertical integration optimization algorithm architecture technology innovation deliver overall performance efficiency various application promising emerge technology recently discover resistive random access memory ReRAM device perform inherently parallel  matrix vector multiplication analog domain feature apply significant linear equation complexity interestingly building dnn accelerator computation dnns essentially express matrix vector multiplication ReRAM crossbar naturally accelerate dnns data movement computation due promising structure prune quantization developed facilitate reduce amount computation ReRAM hardware resource complication  dnn accelerator although ReRAM crossbar positive negative situ computation assumes crossbar positive negative approach tackle ReRAM crossbar positive negative magnitude separately ReRAM portion hardware contrast isaac offset become positive crossbar latter approach introduces additional hardware peripheral circuit extra offset circuit decrease network robustness hardware failure argue ideal attempt develop alternative approach performance UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca FORMS optimization  training ADMM regularize optimization optimize ReRAM aware dnn model prune pre dnn model prune fragment polarization quantization 2D format prune prune negative positive FORMS accelerator architecture data controller indicator driver zero skip zero skip zero skip zero skip DAC ADCs mcu driver DAC ADCs driver DAC ADCs driver DAC ADCs controller mcu mcu mcu mcu mcu mcu mcu mcu tile polarize quantize overall FORMS algorithm hardware offs previous approach additional hardware fix principle enforce exactly assume situ computation ensure crossbar opportunity algorithm hardware motivate capability powerful alternate direction multiplier ADMM regularize optimization exactly enforce dnn training maintain accuracy dnn model ADMM novel constraint mapped crossbar positive negative typical ReRAM crossbar coarse granularity accuracy degradation maintain accuracy propose crossbar logical subarrays enforce within grain sub array grain computation instead coarse grain computation calculate grain subarray however another mainstream advantage coarsegrained computation achieve performance frame per fps grain fps coarse grain optimization apply parallel analog digital converter ADCs parallel compensate performance degradation computation granularity generally hardware overhead coarse grain another fail actually deliberation fortunately opportunity significant performance improvement crucial observation input crossbar become zero simply skip cycle improve performance effectiveness input zero skip technique crossbar sub array input probability input become zero thereby zero skip zero skip unique opportunity sub array crossbar zero aggressively skip input moreover worth ADCs grain computation easy implement ADCs coarse grain computation susceptible non  proposes FORMS algorithm hardware grain ReRAM architecture leverage polarize overall FORMS algorithm hardware pretrained model apply structure prune matrix prune model fix fragment fragment corresponds crossbar sub array incorporate fragment polarization constraint ADMM regularize training fragment around polarize fragment finally quantization apply reduce multi ADMM structure prune polarization quantization significant model compression ratio achieve hardware grain dnn accelerator architecture leverage grain computation novel zero skip logic developed shift input avoids unnecessary zero layer dnns ReRAMs eliminate useless computation computation input apply input subarray fragment zero skip significantly reduces frame processing consumption II background CHALLENGES ReRAM crossbar ReRAM dnn acceleration recently significant progress fabricate nonvolatile memory 3D xpoint commercial non volatile memory fabricate jointly micron intel resistive ram non volatile memory nearly zero leakage integration density scalability research demonstrate fabricate ReRAM memory memory array neuromorphic accelerator ReRAM technology ReRAM situ mixed signal dnn accelerator isaac newton pipelayer prime puma multiscale   propose recent utilize combination analog digital computation besides recent timely propose enhance analog data locality computation analog domain data movement domain conversion  exploit sparsity activation achieve efficiency performance propose hardware mechanism however induces remarkable hardware overhead mechanism index rout hardware manage  proposes prune fix non zero ReRAM crossbar decrease accumulate adc resolution contrast FORMS proposes  optimization improve frame processing rate efficiency challenge despite recent research progress identify challenge ReRAM dnn acceleration mapping arbitrary dnn onto ReRAM crossbar challenge negative positive conductance prior address differently decompose positive magnitude portion negative magnitude portion crossbar portion hardware ReRAM crossbar instead isaac address shift offset negative become positive calculate isaac individual input input bias counting input crossbar parallel perform subtraction introduces significant overhead isaac moreover mapping decrease network robustness hardware failure extra resource consumption adc DAC implementation ensure throughput mainstream accelerator isaac prime puma advantage coarse grain computation ReRAM crossbar hence ADCs however adc CMOS technology recent report adc DAC become contributor chip adc crossbar isaac therefore adc switch motivation realize possibility generate polarize elegantly mapping positive negative ReRAM crossbar without crossbar introduce extra hardware compensation explore balance overall hardware performance extra overhead compensate performance degradation grain computation channel channel reshape filter  filter filter prune filter prune filter filter prune filter prune 2D format filter matrix prune matrix hardware  mapping filter filter  controller peripheral xbar peripheral xbar peripheral xbar peripheral xbar controller peripheral xbar peripheral xbar peripheral xbar peripheral xbar structure prune achieve benefit zero skip technique achieve significant performance improvement adc DAC implementation challenge theart coarse grain architecture isaac puma prime grain architecture susceptible non  coarse grain architecture achieve overall performance rate coarsegrained demonstrate leverage principle algorithm hardware propose significantly advance pave finegrained mixed signal accelerator hardware aware optimization framework software procedure generate hardware friendly dnn model novelty fragment polarization technique enforces fragment recent demonstrate structure prune quantization essential hardware friendly model compression universally applicable dnn accelerator perform structure prune fragment polarization ReRAM crossbar quantization fragment structurally prune model quantization apply structure uniformly alternate direction multiplier ADMM regularize optimization suitable dnn training explain express desire ADMM crossbar aware structure prune structure sparsity dnns FORMS combine structure prune filter prune filter prune reshape convolutional filter convolutional layer 2D matrix filter filter adopt prune entire matrix remove remain matrix dense structure prune matrix becomes effectively reduces ReRAM crossbar remove correspond peripheral circuit previous ReRAM accelerator apply structure prune aim prune ratio maintain acceptable accuracy loss ReRAM crossbar consideration therefore performance degradation prune model mapped onto ReRAM crossbar crossbar portion prune multiple actual crossbar reduction remain prune zero crossbar consequently prune waste accuracy incur without gain benefit FORMS perform crossbar aware structure prune crossbar carefully prune ratio dnn layer avoid unnecessary accuracy fragment polarization fragment consecutive mapped ReRAM crossbar fragment sub array fragment contains mapped sub array fragment polarize positive negative therefore accumulate operation perform ReRAM crossbar sub array suffer arbitrary operand concept fragment introduce issue fragment mapping policy sub array determines dnn model handle orchestrate fragment polarization training calculate sum fragment fragment principle sum fragment positive otherwise negative incorporate ADMM regularize optimization fragment polarization constraint regularize fragment become zero eventually negative positive eliminate positive negative fragment training continuously update fragment specifically fragment polarization fragment policy structurally prune model training fragment polarization assume training contains epoch entire training dataset update target fragment polarize fragment crossbar array channel height width sub array sub array sub array fragment fragment fragment mapping fragment direction polarization epoch epoch fragment calculate belonging fragment training fragment update mapping fragment convolution filter format width height channel dimension naturally polarization policy width polarization consecutive multiple consecutive filter mapped fragment consecutive fragment consecutive  filter mapped filter procedure detail regard ReRAM mapping scheme IV similarly define height polarization channel polarization channel mapped filter polarization policy determines policy affect accuracy observation polarization scheme achieves accuracy imagenet dataset polarization choice cifar dataset polarization scheme apply entire neural network uniformly correspond input advance directly ReRAM crossbar chosen polarization scheme enforce fragment polarization individually around polarize fragment incur hardware overhead due location index ReRAM customize quantization develop ReRAM customize quantization reduce representation parameter crossbar aware structure prune valid ReRAM conductance quantization constraint training reality ReRAM conductance limited resolution peripheral circuitry sophisticated peripheral circuitry due limited computational accuracy multiple ReRAM usually ReRAM ReRAM quantization effectively reduce consumption FORMS ReRAM quantization fully utilize resolution ReRAM importantly  representation dnn model representation ReRAM mapping introduce quantization training allows representation ADMM regularize optimization ADMM advanced optimization technique optimization decompose subproblems separately iteratively incorporate ADMM regularize training FORMS training achieve optimize crossbar aware structure prune fragment polarization ReRAM customize quantization feature ADMM guarantee feasibility satisfy ReRAM hardware constraint quality obvious accuracy degradation model compression hardware mapping layer layer dnn bias define loss function minimize loss function associate dnn model constraint FORMS overall minimize constraint  structure prune fragment polarization ReRAM customize quantization respectively crossbar aware structure prune constraint crossbar aware structure prune 2D format specific layer constraint conv layer becomes percentage nonzero filter  predefined hyperparameters suppose filter sparsity sparsity ith layer fragment polarization constraint fragment polarization constraint fragment crossbar sub array ReRAM crossbar sub array predefined hyperparameter fragment function  otherwise fragment customize quantization constraint ReRAM customize quantization layer mapped quantization quantization characteristic ReRAM device conductance valid pre model polarize model ReRAM crossbar aware structural prune ADMM regularization sub sub update  polarization ReRAM customize quantization euclidean projection optimize model procedure ADMM regularize optimization ADMM regularize optimization overall ADMM regularize optimization iterative training  thanks flexibility definition constraint constraint jointly apply individually incorporate constraint indicator function otherwise constraint cannot directly classic stochastic gradient descent sgd dnn training however ADMM regularization  iteratively reformulate minimize auxiliary variable formation aug  lagrangian decompose subproblems minimize minimize denotes dual variable iteration index positive scalar penalty hyperparameter regularization subproblem classic sgd subproblem euclidean projection thereby matrix structure prune fragment polarize customize quantize subproblems iteratively update iteration convergence detailed refer IV FORMS architecture describes FORMS accelerator architecture execute optimize dnn model generate FORMS optimization framework magnitude ReRAM crossbar without extra crossbar offset circuit ensure throughput develop pipelined incorporate zero skip logic mapping scheme dataflow FORMS instead mapping magnitude arbitrary mixed prior   machine isaac newton  prime puma magnitude ReRAM fragment ReRAM array ReRAM mapping scheme crossbar array assume physical crossbar array various specification partition crossbar array logical sub array sub array crossbar array filter mapped filter mapped onto crossbar array mapped onto crossbar array manner accommodate conv layer multiple ReRAM crossbar array reality due limitation ReRAM resolution multiple ReRAM ReRAM fragment instead fragment ReRAM optimize ReRAM aware dnn model obtain ADMM regularize optimization fragment polarization within fragment around satisfy polarization constraint fragment associate associate grouped indicator indicator accumulation digital domain convolution dataflow conv layer perform convolution input feature filter convolution accumulate passing intermediate activation function rectify linear inp inp inp inp inp inp fpn fragment sub array indicator filter crossbar array polarize ReRAM crossbar mapping scheme relu output feature procedure filter obtain output feature fetch digital input feature eDRAM dram dram input image eDRAM intermediate input buffer DAC output DAC becomes analog input ReRAM crossbar matrix vector multiplication perform leverage feature ReRAM crossbar output calculate  fragment ReRAM crossbar sub array intermediate accumulate intermediate fragment propagate adc convert digital propose accumulation along correspond indicator accumulation accumulation accumulate intermediate crossbar sub array indicator specifies adder mode output adder accumulate temporary fragment iteratively conv operation obtain output feature eDRAM become input feature layer indicator polarize ReRAM crossbar mapping crossbar positive negative separately isaac FORMS avoids introduce offset  overhead indicator moreover magnitude ReRAM crossbar FORMS advantage magnitude ReRAM crossbar allows FORMS achieve representation precision fragment exploration zero skip logic grain sub array feature FORMS architecture ensures accuracy feasible hardware implementation significant performance improvement perform understand relation fragment accuracy fragment introduces zero minor accuracy degradation polarize fragment accuracy degradation coarse grain crossbar fragment corresponds ADCs FORMS ADCs instead adc per crossbar isaac promise ADCs exponentially ADCs isaac adc unfortunately stringent hardware implementation requirement specifically adc switch convert analog digital within isaac impractical fabrication importantly finegrained fragment opportunity significantly improve performance employ novel zero skip logic reduces cycle input sub array significant performance improvement understand FORMS input cycle input representation cycle accuracy fragment accuracy  fragment vgg resnet resnet accuracy fragment cifar dataset input fed fragment parallel generally cycle input crossbar however input actually upper skip crossbar define effective input contribute output obtain remove consecutive significant zero input define effective input cycle EIC minimum cycle fed effective input fragment maximum effective input correspond fragment effective inp however EIC fragment inp effective fragment EIC coarse grain fragment generally grain fragment fragment probability input effective percentage EIC fragment input various fragment conv layer fragment becomes increase percentage fragment EIC fragment average EIC fragment layer fragment average EIC layer effective crossbar cycle EIC fragment cycle zero skip applicable coarse grain crossbar benefit drastically advantage propose zero skip logic dynamically input cycle skip redundant cycle zero contribute output consume increase latency FORMS achieves performance coarse grain inp inp inp inp cycle effective input cycle effective fragment input effective fragment EIC avg  input cycle fragment average  input cycle fragment resnet layer layer layer layer avg    input cycle   input cycle fragment resnet percentage effective input cycle fragment input data average effective input cycle various fragment overall architecture FORMS architectural circuit optimization perform exploration crossbar array ADCs DACs eDRAM storage FORMS organize multiple node tile layer cnn mapped multiple tile tile mesh network data layer tile pipelined manner chip controller orchestrates operation tile tile comprises multiple mac mcu eDRAMs digital DUs shift activation function output register mcu comprises crossbar array adc output register fragment FORMS employ ADCs unless mention explicitly assume fragment discussion isaac ADCs contribute tile tile consumption technology adc almost reduce adc resolution throughput factor fragment activate compute dot ADCs whereas isaac FORMS ReRAM exploration ReRAM delivers efficiency per adc increase increase ReRAM thereby consume importantly per ReRAM rigorous hardware fabrication introduces imprecision analog compute prone zero skip logic input shift register load input DAC zero skip logic eDRAM mcu mcu mcu output regs relu mcu mcu mcu mcu mcu DU tile architecture chip controller chip component FORMS architecture variation increase throughput perform optimization instance isaac crossbar per mcu adc per crossbar MCUs per tile tile FORMS adc per crossbar increase crossbar per mcu accordingly reduce MCUs tile reduce cannot increase throughput FORMS increase ADCs per crossbar increase throughput reduce iso comparison isaac increase ADCs per crossbar architecture mcu adc responsible instead isaac parallel increase throughput adc per crossbar importantly isaac adc switch cycle infeasible FORMS architecture solves ADCs sample rate  fashion addition due fragment buffer intermediate layer decrease isaac adc operates 2GHz processing active input 2GHz instead FORMS employ ADCs within adc frequency compute dot cycle 1GHz FORMS improves cycle assist increase throughput cannot adc resolution continuously improve frequency significant throughput moreover overhead orchestrate ADCs considerable propose pipeline FORMS sub array sub array crossbar array global driver sub array sub array sub array sub array sub array sub array sub array adc adc adc adc adc acc acc acc acc sub array sub array sub array input shift reg input shift reg input shift reg zero skip logic controller DAC sub array decoder indicator accumulation inv adder mux reg input shift reg input shift reg input shift reg zero skip logic DAC input shift reg input shift reg input shift reg zero skip logic DAC FORMS mcu architecture isaac pipeline stage stage layer pool skip logic circuit detects cycle shift input input normally cycle input crossbar array however FORMS cycle usually significant zero input crossbar computation faster addition zero waste input fed crossbar shift register parallel serial detect cycle shift input fragment zero skip logic shift register cycle operation per fragment trigger adc computation content shift register become zero output shift adc compute  contrast isaac iteration input variable FORMS skip cycle execution input zero happens frequently due fragment adc logic deliver shift accumulation output register fed activation function eDRAM input layer perform pool eDRAM cycle perform max pool max compute eDRAM evaluation RESULTS evaluate propose FORMS optimization framework model accuracy ReRAM crossbar reduction achieve combine  structure prune polarization quantization technique representative prune analyze FORMS accelerator architecture throughput performance rate stateof accelerator analyze impact variation software hardware perspective FORMS input activation ReRAM detailed experimental setup software hardware illustrate model compression evaluate representative benchmark network lenet resnet vgg mnist cifar imagenet datasets crossbar reduction crossbar aware structure prune polarize quantize model baseline model splitting mapping scheme model nvidia quadro RTX gpu server pytorch api mnist cifar mnist dataset lenet FORMS achieves crossbar reduction reduction crossbar aware structure prune reduction quantization reduction polarization eliminate crossbar positive negative fragment eDRAM  crossbar array adc crossbar array adc shift shift shift AF eDRAM cycle cycle cycle cycle cycle cycle cycle crossbar array adc shift cycle cycle shift cycle adc crossbar array adc shift potentially skip cycle pipeline FORMS architecture experimental FORMS multi layer network medium datasets acc prune ratio fragment acc crossbar reduction mnist  lenet lenet cifar  vgg  vgg vgg amc resnet  resnet resnet II experimental FORMS multi layer network medium datasets accuracy imagenet dataset acc prune ratio fragment acc crossbar reduction cifar  resnet resnet  resnet resnet network slim vgg vgg imagenet dcp resnet  resnet resnet resnet accuracy degradation accuracy model prune reduce overfitting minor accuracy loss fragment FORMS achieves crossbar reduction ratio  cifar dataset reference  ReRAM prune ADMM crossbar account achieve crossbar reduction ratio prune FORMS mcu hardware specification comparison isaac FORMS fragment isaac component parameter spec spec adc resolution frequency 1GHz 2GHz DAC resolution crossbar array skip logic indicator  prune ratio FORMS avoid unnecessary accuracy combine fragment polarization quantization overall crossbar reduction ratio  accuracy cifar imagenet cifar dataset classification task cifar imagenet dataset complicate imagenet redundant prune ratio cifar imagenet dataset II cifar dataset without accuracy loss minor accuracy loss achieve prune ratio crossbar reduction resnet resnet vgg respectively imagenet reference resnet model accuracy sensitive prune ratio imagenet dataset achieve overall crossbar reduction ratio maintain model accuracy aggressive prune strategy  achieve overall crossbar reduction accuracy fragment summary FORMS achieves crossbar reduction accuracy loss develop simulator model access latency buffer chip interconnects crossbar array performance FORMS utilizes CACTI   cam unified platform volatile non volatile memory  model variation threshold voltage transistor conservatively variation evaluation  ReRAM model zero skip logic model verilog hdl synthesize synopsys compiler technology methodology isaac model maxpooling shift adc DACs activation function max pool shift adapt isaac relu activation function circuit information prime IV comparison FORMS hardware characteristic isaac dadiannao FORMS fragment isaac dadiannao spec spec spec dig MCUs per tile NFU tile MCUs dig  tile MB tile global bus hypertransport freq 6GHz 6GHz hypertransport freq 6GHz hypertransport 4GB 4GB hypertransport GB chip chip comparison effective peak nominal throughput per architecture normalize isaac architecture gop gop isaac dadiannao puma tpu wax simba FORMS polarization FORMS polarization prune quantize isaac prune quantize puma FORMS optimization FORMS optimization pump circuit voltage ReRAM voltage vdd chip link hypertransport serial link isaac dadiannao DAC inverter adopt adc style adc isaac resolution memory vref buffer linearly capacitive DAC exponentially isaac utilize adc  methodology model peripheral circuitry comparison stateof fully digital dadiannao iso comparison throughput frame processing rate isaac FORMS isaac propose building IV component FORMS isaac dadiannao digital without incorporate prune quantization fragment specifically FORMS indicator array interconnects ADCs fragment noteworthy mention polarization accommodate crossbar exist technique addition FORMS performs computation isaac bandwidth versus isaac eDRAM KB KB isaac however adc FORMS generates generate isaac due fragment sample circuit faster overall sample circuit FORMS almost isaac addition  logic dynamic consumption input useless crossbar summary FORMS almost isaac difference negligible isaac puma return consume dadiannao throughput FORMS increase significantly throughput peak nominal efficiency FORMS fragment dnn accelerator operation perform per per operation perform per watt gop gop normalize isaac gop gop respectively demonstrate advantage propose prune quantization throughput isaac puma increase considerably potential increase achieve interconnects bandwidth processing crossbar polarization effective peak throughput FORMS fragment dadiannao tpu respectively increase fragment throughput increase increase fragment throughput FORMS polarization increase FORMS outperform exist architecture apply propose prune quantization polarization zero skip logic gop FORMS fragment outperforms non prune isaac prune quantize isaac respectively gop overall peak throughput FORMS exist wax simba tradeoff throughput efficiency reduce voltage frequency instance simba voltage frequency 2GHz whereas wax frequency 2GHz voltage mention frame processing rate throughput per goal acceleration instance throughput per efficiency commercial tpu gop moreover  application advantage frame per fps throughput detection  virtual augment reality application tend fps processing rate throughput per efficiency fps another crucial dnn accelerator frame per architecture apply assort propose technique frame per cifar various technique propose FORMS apply frame per cifar imagenet various technique propose FORMS apply cifar cifar imagenet dataset respectively normalize non prune isaac architecture demonstrate exist architecture isaac puma enjoy propose prune quantization technique structure prune quantization architecture agnostic upon neural network dataset apply prune frame processing rate isaac puma illustrate propose technique FORMS contribute frame processing rate model optimization prune quantization polarization increase FORMS fragment fragment benefit IV exist mixed signal cannot advantage zero skip logic FORMS utilizes novel optimization fps apply  model optimization fragment FORMS FORMS fragment demonstrate FORMS frame image faster  dnn accelerator variation analysis variation challenge building situ accelerator evaluate impact device variation ReRAM device imperfection fabrication technology VI accuracy degradation device variation resnet dataset lognormal distribution standard deviation dataset model polarization prune optimization cifar cifar imagenet model device variation normal distribution VI accuracy degradation resnet network datasets introduce device variation standard deviation accuracy degradation accuracy II average classification task imagenet harder cifar sensitive hardware variation instance model without adopt compression around accuracy degradation VI polarization quantization zero skip technique decrease network robustness prune introduces degradation robustness extra accuracy degradation prune prune rate remain becomes important network resistance variation reduces happens prune unique FORMS accuracy degradation relieve reduce prune ratio depends demand application worth prior technique improve robustness apply FORMS VI conclusion propose FORMS grain ReRAM dnn accelerator algorithm hardware optimization novel fragment polarization propose elegantly challenge positive negative ReRAM crossbar without crossbar introduce extra hardware compensation prune quantization technique combine explore balance overall hardware performance grain architecture robust non  adc implementation challenge coarse grain architecture crucially novel  logic significantly avoids unnecessary computation reduce computation FORMS optimization framework isaac combine optimization framework architecture FORMS achieves efficiency improvement gop gop optimize isaac almost