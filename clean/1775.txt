alignment consume genome sequence analysis widely software alignment bwa mem recently publish faster version bwa mem extend paradigm alignment alignment bottleneck contribute overall execution bwa mem align genome platinum genome dataset  bwa mem compress index structure FMD index bandwidth requirement primarily due processing instance dna byte FMD index bwa mem KB index data propose novel index data structure enumerate radix ert custom accelerator ert improves bandwidth efficiency bwa mem guarantee identical output software fitting GB dram overall propose accelerator implement aws fpga xlarge improves throughput bwa mem combine extension accelerator improvement overall alignment throughput  software implementation ert integrate bwa mem ert http github com bwa mem  ert source benefit research community index genomics sequence alignment bioinformatics computer architecture introduction genomics transform precision health decade genome essentially dna  giga genome primary analysis sequence split dna billion secondary analysis aligns reference genome determines genetic variant analyze genome reference focus precision health michigan kahn foundation NSF career award application architecture ada research sponsor src darpa align  DTC genomics currently service illumina sequencer alignment compute bottleneck secondary analysis align reference genome naively align reference genome computationally intractable  candidate location reference genome potentially align substring reference extension phase approximate alignment addition alignment important kernel sequence application metagenomics classification   assembly error correction efficient accelerator extension however efficient accelerator lack despite performance bottleneck commonly  instance contributes overall aligner bwa mem focus bwa mem available implementation bwa mem widely institute genomics pipeline primary performance bottleneck memory bandwidth bwa mem  compress index structure  bwa mem bwa mem compression factor index reduce memory bandwidth requirement iterative processing bandwidth requirement genome data per average KB UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca data TB data genome furthermore index access tends GB index data structure exhibit spatial temporal locality ert improves bandwidth efficiency FMD index software hardware acceleration bwa mem axis linearly typical roofline plot explanation index data perform platinum genome err memory bandwidth bottleneck understood roofline plot roofline maximum performance achievable peak bandwidth peak memory bandwidth GB data efficiency data per analyze data requirement per throughput aws cpu instance thread FMD index accelerator bwa mem utilize peak memory bandwidth hence infinitely parallel  hardware accelerator cannot achieve speedup cpu instance due memory bandwidth bottleneck unless data requirement algorithm reduce locality algorithm improve exist hardware accelerator FMD index limited upper limit address challenge novel data structure data efficiency bwa mem accompany custom accelerator architecture data structure innovation highly compress  bwa mem GB genome memory bandwidth memory contrast propose novel data structure increase memory reduce bandwidth fitting within server memory GB tradeoff spirit  institute intel compression factor FMD index GB index improves bandwidth efficiency virtue multi lookup exploit opportunity algorithm refer bandwidth efficient data structure enumerate radix ert FMD index ert enables variable functionality unlike FMD index avoids iterative lookup structure achieves coalesce substring reference genome mer minimum variant radix discus later ert allows multiple consecutive lookup exhibit spatial locality FMD index ert reduce computation substring within reference overlap prefix encode radix ert increase data efficiency data fetch per increase memory requirement GB within memory server accelerator inherently  algorithm cpu implementation compute bound inefficiency purpose processing gpus significant memory divergence traversal ert increase bandwidth efficiency unlocks significant acceleration potential roofline ideal ert accelerator achieve speedup  shift  exploit acceleration potential custom accelerator accelerator leverage butterfly network efficiently data parallel specialized processor processor leverage lightweight context switch compute density hide latency dram access radix mer frequently across multiple however typically radix access aggregate exceeds chip cache radix usually evict rate traditional cache expose latent temporal locality instead accelerator partition phase phase discovers radix extension phase fetch backward extension thereby increase ert binary equivalent acceleration fpga demonstration clinical relevance attention guarantee output bwa mem software ert equivalent fully verify summary contribution propose novel data structure enumerate radix ert increase memory footprint reduce memory bandwidth fitting within server memory GB accelerator fully exploit improve data efficiency ert accelerator specialized processor grain context switch hide latency dram access compute density improve memory bandwidth utilization evaluate ert  genome assembly illumina platinum genome software implementation ert speedup bwa mem fpga prototype ert implement aws fpga xlarge achieves throughput thread software bwa mem combine extension accelerator improvement overall alignment throughput bwa mem source ert software implementation benefit research community ert integrate bwa mem ert http github com bwa mem bwa mem ert II background motivation extension alignment important candidate acceleration contributes overall execution bwa mem extension contributes remain chain nearby reference output creation memory allocation overhead algorithm bwa mem algorithm bwa mem identify substring super maximal SMEMs reference genome maximal mem reference cannot extend direction without encounter mismatch SMEM maximal mem fully mem excessive verify extension longer incorrect alignment bwa mem report SMEMs minimum empirically performance accuracy involve SMEMs sample reference query pivot subsequent reference index  direction becomes pivot candidate reference location marked extension LEP genome dataset err consist super maximal backward identify super maximal SMEMs substring TC TCA  query identify MEMs extend backward direction guaranteed MEMs within identify LEP backward query identify previous LEP substring TC TCA  subsequent backward direction SMEMs identify discard MEMs fully longer   report SMEMs MEMs   discard fully another mem  SMEMs obtain assume alignment FMD index identify SMEMs location reference genome bwa mem highly compress data structure FMD index built strand dna FMD index consists array SA contains location lexicographically sort reference genome burrow wheeler transform bwt compute cyclically sort array reference lexicographically occurrence occ occurrence index array occurrence identify interval  matrix query exists reference perform iterative lookup successive query FM index reference backward FM index FMD index bottleneck FMD index allows lookup query reference approximately memory operation bwa mem implementation FMD index GB GB occurrence compress GB array compress GB  decompress occurrence array bwa mem improve performance slightly FMD index enables backward mem progressively longer substring extra memory lookup per however memory lookup GB data structure rarely exhibit spatial locality reduces effectiveness cache processor memory bandwidth requirement software implementation FMD index bwa mem attempt improve locality mem occurrence entry typically portion bwt tightly packed cache align data structure improve spatial locality index lookup backward substring prefix TC TCA perform lock access occurrence data belonging nearby cache despite optimization genome detail FMD index data requirement KB index data cycle spent core stall memory cache FMD index inherently involves sequential dependent memory access performance limited memory access latency mitigate hardware multiplexing physical compute context switch memory stall  radix TREES ert mer enumerate index FMD index compress representation exist reference genome lexicographic substring refer mer due genome variation sequence error mers exist reference hence FMD index therefore mer FMD index mer exists FMD index till desire kmer iterative access FMD index substantially increase dram access memory bottleneck aggravate access index rarely lexicographic exploit locality mer overcome limitation instead enumerate mers exist reference index mer index entry reference mers index memory access significantly reduce dram access furthermore subsequent access mer improve spatial locality LEP information mer lookup pre compute index entry index enumerate substring bwa mem report SMEMs minimum shorter substring excessive verify extension index tractable entry later discus effectively increase selectively multi index customize radix mer index entry mem longer option augment index FMD index iteratively mer prefix however within subset mer prefix FMD index lookup locality overcome radix naturally multi lookup radix merge singleton node thereby address multiple lookup memory access radix mer  index radix genome alphabet propose ert merges singleton GC variable internal node singleton designate uniform singleton encounter node onward enumerate radix ert ert multi lookup multi index radix index entry contains LEP II pointer indicates address node radix empty mer absent reference leaf mer unique occurrence reference mer exists reference pointer radix mer unique reference index entry mer index succinctly ert singleton variable internal node uniform multi lookup singleton leaf truncate leaf node reference genome compression leaf ert encodes prefix sequence reference genome absence prefix reference ert empty node uniform node valid prefix diverge node compression improve  ert mer frequently becomes unique reference genome increase prefix unique reference genome introduce uniform node ert singleton avoid instead replace pointer occurrence reference genome ert node marked leaf node pointer leaf node encounter mem decompress fetch reference correspond reference pointer leaf node pointer leaf node regardless compression technique location traverse kmer reference genome hence storage overhead instead optimization saving critical genome GB storage configuration server ert construction SMEM operation ert mer index correspond radix built enumerate mers query pre built FMD index reference genome mer accord exist sequence reference mer ert leaf corresponds unique sequence reference location sequence pointer leaf mer exist refer empty pointer ert SMEM implementation index entry empty empty entry compute LEP correspond mer index along mer backward traversal initiate ert index depends repetitiveness reference genome empirically estimate occupy ert index byte reference genome giga instance ert index genome GB index GB radix GB wheat genome giga GB ert index construction  genome thread ert index construction bottleneck per reference genome reuse across alignment construct ert MEMs accord SMEM algorithm II mer scan mem index mer dram access entry index exists mer fetch memory access mer traverse accord remain leaf node encounter empty node exist reference leaf node reference sequence correspond leaf fetch dram access empty node mem location mem exists reference leaf node downstream sub  traversal refer leaf gathering index entry contains LEP mer compute LEP mer diverge node encounter traversal ert LEP bitvector indicates across divergent node depth sub traversal completes backward traversal initiate LEP along traverse backward traversal operates traversal ert data structure MEMs reverse complement complement optimization prefix merge radix goal prefix merge radix across mem backward consecutive merge radix prefix data leaf node allows ert leverage prefix information perform multiple mem traversal opportunity computation spent backward mem important optimize average backward pivot adjacent query consecutive LEP normally multiple independent index lookup traversal insight unoptimized ert exists radix mer occurs reference adjacent slide mers ATG  recognize radix adjacent mers redundant information information reconstruct adjacent mer prefix information node  normally access ATG instead reconstruct  presence absence prefix node  observation prefix merge radix multiple backward   perform index lookup traversal prefix node leaf node  prefix mem  reduces mem augment node prefix information merge mer significant offset benefit merge therefore prefix optimize ert leaf node augment prefix per prefix correspond reference prefix information leaf node sufficient prefix information internal node reconstruct leaf node correspond sub chose prefix leaf node backward average prefix leaf node backward index entry mers merge radix ATG contains pointer adjacent mer  mer entry distinguish mers without merge radix optimization locality mer reuse goal increase index entry radix mer opportunity batch index radix access mers improve slightly batch highly redundant genome coverage sequence sequence error reference genome average however typically radix access aggregate exceeds chip cache radix usually evict rate traditional cache mitigate advance mers radix fetch dram insight backward phase SMEM algorithm perform sequentially instead decouple expose temporal locality specifically perform batch identify unique mers backward  fetch radix unique mer perform backward phase perform extension batch identify mers backward extension dash LEP mer metadata mer ID index metadata phase sort mers backward extension task involve mer phase perform backward extension involve mer exploit locality ert mer fetch dram reduce bandwidth requirement mer mer refer technique mer reuse describes perform leverage mer reuse processing batch backward compute mer metadata implement chip backward entry compose kmer backward ID batch backward batch sort entry metadata backward mer proceed mer compute backward associate mer sequentially mer encounter perform index lookup fetch portion mer chip cache subsequent backward extension consult cache skip otherwise mandatory dram access backward sort phase respectively optimization tile layout spatial locality spatial locality ert access improve tile layout radix node layout sub node likely access cluster cache dram tile breadth depth layout node tile layout guarantee node access per tile node tile optimization ert traverse node average per utilize data fetch memory optimization memory opportunity enumerate prefix index prohibitive overhead mer entry TB assume byte per entry however genome random genome cache friendly tile data layout ert alphabet repetitive genome distribution leaf node radix mers heavily skewed skewed distribution mers insight leverage skewed distribution mers genome multi index mers genome mers however mers dense radix compactly index instead enumerate prefix decompose index wherein enumerates mers subsequent enumerates subset mers min SMEM multi index extends benefit  lookup reduce traversal genome accommodate fan subset mer dense without increase overhead improves cpu performance shallow leaf node depth explore fan internal node ert optimization prune wasteful backward typically backward perform query candidate  however impose backward namely rightmost query proceed leftward prune subsequent backward illustrate prune wasteful backward perform backward pas partition multiple nonoverlapping MEMs backward guaranteed mem span across multiple pivot backward previous pivot backward guaranteed MEMs within redundant IV  accelerator overview overall architecture accelerator accelerator compose multiple parallel machine available dram channel crossbar network machine compose processor issue command processing processing PE provision multiple lightweight context performs sub task associate SMEM identification index lookup  depth leaf gathering processing issue memory request data fetcher rudimentary address generation memory controller memory stall occurs processing immediately switch context grain context switch greatly increase compute density machine essential fpga implementation limited logic rout resource memory request return data correspond PEs context memory context marked decode radix node node traverse ert operation SMEM algorithm consume compute ert prior custom functional explore RISC xilinx   however  node decode latency ert node LUTs flip flop custom node decoder custom node decoder combine  controller latency implement SMEM algorithm custom node decoder couple custom controller implementation processing index fetcher index fetcher responsible initiate convert mer index address request correspond entry ert index request immediately trigger context switch swap context request data return terminates index entry empty return processor proceed radix mer exists index fetcher issue request radix walker walker responsible traverse ert decode node reporting node decode correspond calculate ert node address walker detects ert data structure traversal request data data fetcher trigger context switch decode walker computes address node content exist node traversal ert node variable cycle decode node complexity uniform node comparison dna uniform comparison accomplish parallel xor gate priority encoders cycle leaf node compress comparison hardware implement comparison custom parallel hardware important feature specialized processor versus implementation software purpose cpu leaf  empty node cannot extend remain leaf sub identify reference location refer leaf gathering accomplish depth dfs ert sub dfs accomplish decode ert maintain stack ert node index explore node decode traverse walker however leaf  perform compression uniform node comparison hardware dram channel processor data fetcher channel axi channel axi SMEM butterfly network butterfly network SM SM SM SM SM SM SM SM dram channel dram channel dram channel TW TW LG LG walker index fetchers leaf  TW command queue context memory context memory machine SM mer reuse cache mer reuse batch mer sorter arbiter arbiter arbiter arbiter arbiter context switch context switch context switch context bram URAM logic mer reuse hardware offset node data LEP curr accelerator architecture walker TW responsible scan ert compute candidate SMEMs walker switch multiple context hide memory latency data fetcher DF responsible ert reference fetch request dram processor CP coordinate fetch mer reuse phase processor SMEM algorithm consists  conditional predict purpose processor processor overcomes implement algorithm SMEM hardware processor determines issue command leaf associate SMEM backward fail SMEM correspond processing command queue simplify hardware walker PEs hardware backward processor issue backward command index reverse complement backward processor maintains queue pending variable traversal schedule ensure compute utilization accelerator flexible implement algorithm FMD index FSMs processor hardware structure index fetchers walker leaf  crossbar reuse mer reuse metadata storage sort perform mer reuse backward  export mer metadata backward mer grouped parallel hardware sorter entry mer phase implement specially cache structure mer reuse cache cache index lookup ert node access ert access conservatively coverage detail batch account potential reuse coverage input repetitive genome wheat reuse benefit increase batch beyond reuse cache beyond MB mer reuse cache mapped mapped cache rate within fully associative cache mer reuse algorithm generate MEMs outof MEMs intermediate chip storage perform mem containment finally SMEMs reconciliation integration program api batch encode host void encode uint buf char int len pcie dma transfer byte host buffer accelerator memory offset int  uint buf int int configuration register accelerator processing batch int  status register accelerator completion int  byte offset accelerator memory host buffer buf int  uint buf int int listing program api accelerator host accelerator interface adopt configuration aws EC host accelerator physical memory dram assume existence communication channel host accelerator aws interface data transfer accelerator custom logic CL axi dma transaction  pcie gen link another issue command access memory mapped status register interface axi lite interface OCL listing api program accelerator aws fpga management library library apis reading chunk data accelerator via pcie dma handle interrupt memory mapped register accelerator configuration status monitoring implement overflow handle accelerator SMEMs overflow chip mem buffer accelerator flush designate overflow accelerator dram later host runtime extend multi thread model bwa mem worker thread manage optional extension accelerator interfaced pcie worker thread communicate via non producer consumer queue cpu thread allocates buffer  accelerator dram  transaction pre worker cpu thread allocates byte buffer encodes ambiguous host buffer accelerator dram thread acquires lock accelerator status register OCL interface signal accelerator computation monitor status register till accelerator update command another cpu thread retrieves SMEMs accelerator dram  transaction buffer overflow SMEMs pas chain optionally similarly extension accelerator implement buffering accelerator memory transfer accelerator pcie overlap computation encode format baseline prior chain reference genome eliminate overhead due additional data structure format conversion methodology reference genome input ert built reference genome assembly   genome browser decoy contigs  dna filter chromosome ert index input illumina platinum genome benchmark dataset err  consist prior ambiguous non host cpu ambiguous reference genome convert standard nucleotide procedure experimental setup software fpga ASIC version ert bwa mem release bwa mem commit ebc refer II ert PM prefix merge optimization ert KR prefix merge mer reuse software comparison perform available cpu instance aws EC xlarge thread bwa mem bwa mem software ert thread sufficient memory bandwidth detailed configuration cpu estimate intel RAPL interface software mer reuse optimization slowdown  ert overhead sort mers prior backward maintain backward mer metadata query software manage mer reuse cache index access report stage computation bwa mem SMEM generation  verify implementation identical bwa mem illumina platinum genome dataset estimate performance configuration ASIC ert developed cycle accurate model software implementation generate memory trace correspond software representative err perfect non perfect err dataset ramulator commit  estimate performance  commit  estimate dram xlarge intel xeon platinum aws EC instance ghz socket core thread cache KB instruction KB data cache MB cache MB memory GB dram baseline CONFIGURATIONS configuration description cpu bwa mem baseline bwa mem thread cpu bwa mem baseline bwa mem thread cpu ert configuration ert thread ert baseline ert ert PM ert prefix merge ert KR ert prefix merge mer reuse II comparison  evaluation ASIC configuration synthesis frequency rtl model accelerator synthesize synopsis compiler hpc  standard library processor achieves ghz frequency limited operating frequency SRAMs context memory SRAM structure ASIC compile separately dual requirement TSMC memory compiler estimation fpga prototype prototyped verify accelerator amazon EC fpga environment chose xlarge instance FPGAs equivalent bandwidth cpu configuration GB peak component configuration SRAM machine MB mer sorter metadata MB mer reuse cache MB accelerator dram channel NA ASIC configuration synthesis RESULTS component configuration lut bram URAM index FU walker FU leaf gathering FU command queue KB context memory KB processor data fetcher SMEM buffer KB misc machine mer sorter mer reuse cache MB accelerator aws IV per fpga configuration synthesis RESULTS bandwidth per fpga fpga instance xilinx XCVUP logic mbit ram mbit  accelerator implement verilog rout mhz configuration synthesis along overhead aws interface IV VI RESULTS performance performance express across configuration software version ert speedup bwa mem baseline thread ert greatly reduces amount data fetch per leverage  lookup optimization spatial locality overall ASIC ert achieves improvement throughput multi thread bwa mem ASIC  utilizes context saturate memory bandwidth achieves throughput improvement  ert prefix merge radix allows reduce backward extension improve throughput leverage temporal locality backward pas mer reuse improves overall throughput fpga ert achieves throughput speedup baseline cpu  fpga ert prototype inherits limitation aws fpga memory interface ert style access ASIC configuration instance customize memory controller IP return subsequent memory request dram latency unless axi burst transaction burst however  transaction ert access data wastage burst increase datapath complexity chip storage fpga issue request GB per channel ert access although peak channel bandwidth GB performance memory access characteristic understand improvement throughput discus memory access characteristic configuration memory request per data requirement per KB  average memory request data fetch bwa mem configuration ert bwa mem bwa mem ert memory request per ert node tightly packed cache improve spatial locality average ert node traverse per utilize data ert KR leverage mer reuse cache reduce memory request data requirement per KB dram breakdown ert KR performance breakdown efficiency distribution dram ert traversal leaf gathering contribute spatial locality respectively furthermore multi index ert reduces node traversal  lookup baseline ert penalty index radix lookup paid almost mer access random contribute dram buffer dram per across optimization prefix merge mer reuse leveraged reduce buffer prefix merge radix reduce backward reduce index lookup lookup traversal addition mer reuse amortizes backward across mers leverage temporal locality mer reuse cache reduce index lookup lookup traversal baseline ert reference fetch obtain leaf node account incurs nearly configuration mer reuse impose backward extension cannot advantage termination backward described slight increase dram leaf gathering baseline ert efficiency efficiency  bwa mem cpu bwa mem cpu cpu ert ASIC GenAx ASIC ert  efficiency efficiency efficiency cpu bwa mem cpu bwa mem ASIC GenAx configuration ASIC ert ASIC GenAx recent sequence alignment accelerator leverage  intersection perform ASIC GenAx chip SRAMs  lightweight walker improves efficiency overall alignment performance throughput fpga ert augment ert extension accelerator lane  accelerator  extension  instance throughput  bwa mem xlarge bwa mem xlarge fpga ert xlarge VI overall alignment performance aws EC  lane consists smith waterman PEs edit distance VI overall alignment performance software version bwa mem bwa mem fpga accelerate alignment integrate bwa mem fpga accelerate  throughput software version bwa mem vii resource consumption extension accelerator fpga component lut bram URAM accelerator extension accelerator aws vii  per fpga resource utilization fpga ert vii related cpu gpu FMD index involves irregular memory access bottleneck llc tlb CPUs prior explore reorder memory access perform lookup FMD index improve locality data requirement FMD index however implementation focus natively SMEM computation data parallel architecture gpus leveraged accelerate FMD index virtue available memory bandwidth memory parallelism however ert traversal inherently  significant memory divergence gpu simd gpu aligner soap achieves tesla gpu fpga ert couple extension accelerator  improve alignment throughput focus FMD index exists hash optimize cache behavior however hash couple filtration algorithm effective FMD index mapper bwa mem already prior extension alignment accelerator accelerator FMD index custom wise operation traverse index improve memory parallelism however implementation memory bandwidth roofline processing performance prior FMD index  alignment par bwa mem hardware accelerator propose alignment instance  genome fpga  achieves xlarge instance algorithm proprietary output bwa mem comparison fpga implementation ert maintains binary equivalency bwa mem achieves ASIC GenCache recent sequence alignment accelerator improves upon  leverage cache operation reduces redundant bloom filter ASIC GenAx ASIC GenCache ASIC ert iso throughput respectively darwin recent demonstrates impressive throughput alignment however focus technology error rate algorithm evolve radix application traversal acceleration conventional radix ert eliminates singleton efficient GB genome ert customize mem instance ert encodes prefix information leaf node across multiple traversal expose temporal locality reuse across batch ert asymmetric backward leverage reverse complementary reference dna strand radix utility generalpurpose index structure memory database ert leverage optimization database index accelerate traversal instance cache sub organization improve spatial locality leaf node pointer elimination structural reduction ert remove pointer leaf node variable width pointer reduce node internal node pointer retain ert node variable hardware graph accelerator purpose traverse ert however cannot leverage locality opportunity specific ert accelerator feature custom hardware bandwidth efficient SMEM computation ert instance hardware sorter mer reuse cache advantage across conclusion important bottleneck standard dna alignment genomics pipeline FMD index algorithm bandwidth inefficient spatial temporal locality demonstrates hardware software approach accelerate optimize memory bandwidth memory capacity propose accelerator implement aws combine theart extension accelerator achieve speedup bwa mem maintain binary compatibility potentially domain specific acceleration memory bound algorithm