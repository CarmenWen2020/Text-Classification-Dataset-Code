zero knowledge proof ZKP promising cryptographic protocol computation integrity privacy privacy preserve application verifiable outsource blockchains obstacle ZKP consume proof generation consists polynomial computation multi scalar multiplication elliptic curve efficiently practically ZKP application propose  pipelined accelerator subsystem handle aforementioned intensive compute task respectively subsystem novel dataflow decompose kernel execute bandwidth efficient hardware module optimize chip memory access chip compute resource subsystem adopts lightweight dynamic dispatch mechanism processing minimize resource underutilization load imbalance evaluate  achieve speedup standard cryptographic benchmark widely cryptocurrency application zcash introduction zero knowledge proof ZKP blossom rapidly recent attention researcher practitioner  protocol prover convince others verifier computational statement without leak information program output public input secret input ZKP protocol prover assure verifier secret satisfies without reveal fundamental primitive cryptography ZKP potential widely privacy critical application enable secure verifiable data processing electronic voting online auction anonymous credential verifiable database outsource verifiable machine privacy preserve cryptocurrencies various smart contract blockchains specifically verifiable outsource  gao  correspond author promising ZKP allows weak client outsource computation powerful efficiently verify correctness return another widely deployed application ZKP blockchains cryptocurrencies ZKP intensive computation chain node verify integrity lightweight proof critical birth tremendous effort cryptography researcher ZKP practical newly snark  succinct non interactive argument knowledge widely promising candidate suggests snark generates succinct proof within byte regardless complexity program proof verify deployment snark application blockchain community although snark proof succinct verify generation remains obstacle snark adoption generate proof program typical translate program constraint usually initial program prover performs arithmetic operation finite actual operation  super linear constraint hence longer generate snark proof program verify sometimes payment transaction  efficient pipelined architecture accelerate snark  mainly involves subsystem polynomial computation theoretic transforms NTTs multi scalar multiplication execute vector inner elliptic curve ECs phase UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca compute intensive implement specialized hardware accelerator combine cpu realize heterogeneous snark polynomial computation subsystem NTTs  challenge chip memory access chip compute resource due irregular stride access classical FFTs bitwidth propose novel dataflow recursively decomposes ntt kernel efficiently execute bandwidth efficient ntt hardware module lightweight FIFOs internally realize stride access leverage data tile chip matrix transpose improve chip bandwidth utilization multi scalar multiplication subsystem simply replicate multiple processing EC operation exploit EC multiplication vector inner  algorithm dominant EC processing lightweight dynamic dispatch mechanism alleviates resource underutilization load imbalance issue input data unpredictable distribution furthermore coarse grain manner processing independently guarantee straggler data distribution highly pathological summary contribution novel module decomposes largescale polynomial computation tile pipeline style achieves efficiency chip memory bandwidth chip logic resource utilization novel module multi scalar multiplication elliptic curve leverage optimize algorithm pipelined dataflow achieve processing throughput implement prototype propose architecture rtl synthesize ASIC evaluate heterogeneous host cpu approach overall achieve speedup standard cryptographic benchmark average application zcash individually execute subsystem  achieve speedup respectively beyond accelerator subsystem  independent wider application ntt module building homomorphic encryption public encryption scheme error lwe multi scalar multiplication module commonly vector commitment proof architecture insight inspire opportunity cryptographic algorithm practical towards purpose secure computation II background motivation zero knowledge proof ZKP powerful cryptographic primitive recently adopt application drawn attention academia ZKP allows prover verifier statement function input secret witness specifically prover generate proof validity checked verifier however verifier proof verify validity cannot obtain information prover secret remains secure zero knowledge ZKP guarantee prover privacy others private information without leak application zero knowledge proof fundamental primitive cryptography ZKP widely security application building enable secure verifiable data processing generally ZKP allows multiple perform compute task cooperative secure manner convince others valid without accidentally leak sensitive information application benefit electronic voting online auction anonymous credential verifiable database outsource verifiable machine privacy preserve cryptocurrencies various smart contract blockchains promising application ZKP verifiable outsource client weak compute outsources compute task powerful server datacenter computes potentially sensitive data generate return client database sql query machine scenario client ensure indeed server willing expose sensitive data ZKP allows server proof associate client efficiently integrity zero knowledge allows prover arbitrary statement compute function sensitive data without worry expose therefore naturally theoretically purpose outsource computation another widely deployed application ZKP blockchains cryptocurrencies conventional blockchain application node execute chain computation update brings overhead latency ZKP enables private decentralize verifiable computation offchain node integrity lightweight proof discover illegal transition instance  pack transaction proof allows node integrity efficiently verify proof enables verify integrity blockchain succinct proof feature greatly increase blockchain scalability furthermore zero knowledge allows user confidential transaction validity transaction zcash  coin transaction detail amount user address hidden computation requirement zero knowledge proof realize counter intuitive ZKP functionality computation communication introduction significant improvement computation efficiency ZKP practical zksnark ZKP protocol allows prover generate succinct proof greatly reduces verification formally proof snark important correctness zero knowledge succinctness correctness verification prover statement prover secret witness zero knowledge proof leak information succinctness proof byte verify within millisecond regardless complicate statement unfortunately although proof verification generate proof prover snark considerable computation overhead amount hinders snark adoption application therefore focus workflow component prover computation target hardware acceleration specific implementation snark security parameter computation complexity security strength specify data width security guarantee introduces significantly computation typically illustrate prover pre processing phase function typically program compile arithmetic constraint rank constraint rcs constraint contains linear polynomial equation input witness complexity function equation constraint application abuse notion security parameter simplicity usually directly related width parameter underlie elliptic curve pre processing     prover computation    computation polynomial multi scalar multiplication input witness def input witness return constraint var var var var var var var var var workflow prover illustrate constraint prover poly msm computation hardware acceleration meanwhile various random parameter prover secret witness constraint parameter pre processing phase subsequently output data later computation phase scalar vector vector dimension constraint extremely application zcash vector vector pre elliptic curve EC EC commonly cryptographic primitive operation addition padd  scalar multiplication PMULT leverage binary representation scalar PMULT broken series padd  scalar serial padd  operation bunch arithmetic operation finite algorithm EC operation typically projective coordinate avoid modular inverse adopt montgomery representation arithmetic operation finite data prover generate proof computation phase therefore target hardware acceleration involves  theoretic transforms NTTs complicate EC operation illustrate specifically computation phase mainly task polynomial computation poly input calculates resultant scalar vector coefficient  polynomial implementation NTTs inverse NTTs  fourier transforms FFTs instead finite reduce complexity poly nevertheless poly NTTs  ntt INTT considerable computation coefficient integer multi scalar multiplication msm calculation vector inner output poly respectively inner perform EC padd PMULT operation define scalar vector vector msm computation intensive inner proportional padd PMULT operation EC expensive arithmetic operation integer finite prover witness pre input poly msm output poly input msm proof output msm compose EC proof verify verifier within millisecond operation EC hardware acceleration opportunity workflow II prover computation particularly complicate significant compute zcash constraint generate proof anonymous transaction ordinary user sometimes prefer transparent transaction instead avoid generate proof privacy performance  function contains constraint generate proof actually blockchain application usually  function craft arithmetic computation easy transfer constraint purpose application II extremely computation overhead primary hinders adoption ZKP therefore hardware acceleration ZKP workload prover pre processing typically hence focus mostly poly msm computation poly mostly invokes ntt INTT module computation multiplication subtraction contribute NTTs extremely expensive FFTs NTTs complicate memory access stride stage moreover arithmetic operation multiplication exponentiation etc inside NTTs perform finite compute intensive focus hardware acceleration poly NTTs  msm computation intensive expensive PMULT operation EC previous proposal accelerate PMULT msm additionally PMULT inner brings opportunity efficient algorithm simply duplicate multiple PMULT snark scalar vector exhibit distribution advantage improve performance propose hardware framework msm hardware resource IV CPUs gpus operation poly msm arithmetic finite friendly traditional purpose compute platform CPUs gpus CPUs insufficient computation throughput cannot exploit parallelism inside operation gpus computation throughput mostly floatingpoint moreover memory architecture gpus efficient poly msm operation thread access limited software cache memory irregular global memory access component operation gpus significantly contrast integer arithmetic operation specialized circuit flexible generate customize memory access domain specific accelerator promising achieve performance efficiency prior prior achieve significant performance improvement polynomial computation homomorphic encryption customize hardware accelerate EC operation literature circuit however inefficient directly employ prior snark due issue polynomial computation zksnark homomorphic encryption induces intensive chip memory access cannot satisfied prior addition data bitwidth snark inefficient multiplexer input butterfly operation directly duplicate EC hardware cannot leverage ofthe algorithm optimization snark besides sparsity scalar resource underutilization pipeline compute msm detailed discussion IV recent  propose leverage apache spark distribute prover computation multiple machine reduce latency primary goal  snark super application machine model compute inefficient ordinary application anonymous payment privacy preserve smart contract due network latency computation therefore  regard complementary achieves efficiency distribute machine recently approach accelerate prover dedicate hardware gpu fpga leverage parallelism inside snark coda global competition accelerate gpu reward however acceleration competition cpu benchmark VI detail fpga implementation summary considerable gap exist performance requirement practical usage  polynomial computation poly snark mainly consists multiple NTTs  overcome challenge  NTTs introduce recursive ntt algorithm optimize overall dataflow efficient hardware ntt module alleviate chip bandwidth chip resource requirement ntt computation ntt computation def ntt define  array ωij scalar finite nth unity exponent twiddle factor constant specific chip memory assume twiddle factor precomputed introduce MB storage typical implementation ntt utilize twiddle factor compute recursively access standard fft algorithm ntt stage fix stride perform butterfly operation output stage overall ntt computation stage stride stage              data access ntt fft complicate data access challenge efficient hardware accelerator output reorder operation reverse alternatively reorder input generate output perform multiple NTTs sequence properly chain style alternately eliminate reverse operation challenge ntt important kernel commonly cryptography exist hardware accelerator ntt ntt hardware  specialized homomorphic encryption however poly computation snark substantially address  multiple NTTs data width normally hardly satisfied previous ntt hardware challenge properly address snark ntt data chip chip memory ntt data width MB data storage input data twiddle factor access cycle chip memory ntt module accelerator TB bandwidth relatively mhz frequency unrealistically exist alone complicate stride access reduce effective bandwidth therefore critical optimize chip data access ntt hardware module minimize bandwidth requirement balance computation data transfer contrast prior  assumes data buffer chip specially chip data access bitwidth ntt significant chip resource computation  data wider therefore adopts approach chip multiplexer computation input butterfly operation naively VL HG VL HG VL HG VL HG VL HG VL HG    recursive ntt algorithm bitwidth beyond snark overhead multiplexer increase significantly furthermore computation resource butterfly operation ntt module super linear fashion inefficient NTTs throughput recursive ntt algorithm overcome challenge adopt parallel ntt algorithm recursively decompose ntt arbitrary multiple ntt kernel allows implement ntt module onchip compute resource satisfy chip bandwidth limitation iteratively ntt module calculate ntt hardware ntt module ntt kernel therefore flexible decomposition overview algorithm precise description refer literature ntt decompose ntt NTTs convenience 1D input array matrix ntt output correspond twiddle factor  ntt finally output output 1D array bandwidth efficient ntt hardware module decomposition relatively ntt hardware module array previous  implement ntt module data access chip multiplexer deliver input correspond multiplier however recall directly fetch data chip memory cycle significant bandwidth consumption described therefore adopt  pipelined architecture building fully pipelined input output sequentially instead multiplexer FIFOs depth stride stage simplify ntt pipeline module contains stage stage ntt core butterfly operation stride generates stage core cycle latency arithmetic operation inside depth fifo stage stride stage stage pipeline reading per cycle memory cycle fifo stage cycle enable ntt core newly pop fifo input desire stride stride correctly enforce fifo instead multiplexer ntt core generates output cycle directly stage output buffer stage later reuse fifo stage purpose input fifo discard stage behavior fifo depth realize stride stage writes output memory reduce bandwidth per cycle mhz GB practical satisfy reduce superlinear multiplexer linear memory resource resource complex logic regular ram latency ntt cycle stage cycle buffering data across stage another cycle fully overlap ntt kernel module NT cycle compute ntt kernel parallel INTT INTT poly INTT module almost ntt execution butterfly ntt core operates reverse stage twiddle factor  butterfly core ntt INTT logic computation resource expensive multiplier dominant component poly NTTs  chain alternately adopt reorder style input output array module described eliminate reverse operation RUH RUH RUH RUH architecture bandwidth efficient ntt module various kernel ntt module easily various ntt kernel ntt kernel poly pad software bypass previous stage module later stage ntt stage module flexibly NTTs decomposition overall ntt dataflow recursive algorithm ntt kernel decompose manner ntt hardware module however overall data access data layout chip memory inefficient stride access poorly utilize available bandwidth illustrate issue input matrix layout memory generate 1D array ntt kernel data stride access layout output data naturally matrix pas wise multiplication however ntt kernel access data stride layout finally output ntt kernel another transpose another stride access alleviate bandwidth effectively data balance choice layout initiate chip SRAM buffer improve input data reuse aggregate output data implement multiple ntt module parallel fully utilize data fetch memory simplicity suppose ntt implement ntt module data chip memory 1D array fetch chip memory ntt module memory access sequential access bandwidth recall ntt module input cycle output per cycle initial pipeline   VL HG    HDG VL HG  PHPRU   overall dataflow ntt processing cycle sequential 2D array input NTTs equivalently simultaneously marked happens cycle fetch sub ntt module buffer output data chip transpose grey currently ntt module pipeline chip buffer resolve data layout issue perform matrix transpose data chip memory cycle module output chip buffer buffer chip memory access granularity allows data chip memory format achieve access granularity effective bandwidth detail processing already chip buffer buffer popped memory ntt module pipeline ntt module fully pipelined utilized pressure chip bandwidth alleviate  ntt module IV  multi scalar multiplication introduce computation task challenge msm algorithm correspond architecture accelerate msm computation illustrate II msm computation define  predetermine EC scalar finite  scalar multiplication PMULT msm padd serial  computation snark msm scalar vector poly witness vector ahead fix parameter application scalar vector accord witness expensive operation msm PMULT padd EC exponentiation algorithm expensive PMULT decompose series padd  serial fashion compute binary execute  padd PMULT invokes padd  sequentially accord scalar sparsity scalar impact overall latency binary contains ith PMULT padd operation challenge EC commonly kernel cryptographic application PMULT encrypt none previous accelerator ASICs specially msm involves PMULT operation finally accumulate padd directly duplicate exist PMULT accelerator inefficient computation demand padd  input scalar utilization PMULT module sparse scalar multiple PMULT module suffer load imbalance issue decrease overall performance optimize algorithm hardware module instead directly replicate PMULT module adopt  algorithm achieve resource utilization load balance firstly scalar radix chosen equivalent scalar chunk compute sum chunk sum  convert computation sub task compute sub task  algorithm chunk scalar correspond  algorithm scalar bucket scalar bitwidth bucket scalar zero directly skip correspond assign bucket sum per bucket compute correspond scalar bucket PMULT operation scalar vector bucket convert expensive PMULT operation lightweight padd within bucket detailed math radix chunk   algorithm msm becomes  efficient padd module padd module heavily pipelined stage expensive arithmetic modular operation modular datapath padd deterministic alleviate resource underutilization load imbalance issue remain  operation sum ibi  negligible evaluation overall architecture convert expensive PMULT cheaper padd operation overall architecture challenge phase efficient implementation msm scalar vector logic non trivial padd operation deterministic assign bucket hence padd operation skewed workload bucket therefore possibly imbalanced propose novel architecture  algorithm msm chip memory  ELW ELW ELW ELW ELW  ELW  XIIHU ELW   overall architecture  algorithm msm msm scalar load scalar projective coordinate onchip global buffer chip memory cycle scalar correspond chip buffer bucket accord correspond scalar depth bucket buffer bucket transfer centralize fifo bucket index label entry fifo contains label bucket index bucket entry FIFOs prepared scalar cycle entry FIFOs pipelined padd module resultant sum correspond bucket accord label accumulation however another entry fifo buffer conflict already exist data destination bucket basically newly obtain sum immediately fifo exist data bucket another padd operation padd module hence FIFOs newly load data padd cycle chunk scalar workflow overall architecture  algorithm centralize padd module bucket dynamically dispatch bucket achieve load balance padd module performance dominant resource utilization private padd module bucket dispatch mechanism lightweight avoid physically sort typical algorithm mostly rely buffer FIFOs stash data accumulate carefully provision buffer fifo allows avoid stall achieves throughput exploit parallelism balance load padd module architecture IV clearly performance bottleneck extend multiple padd module parallel straightforward  provision multiple padd FIFOs distribute FIFOs however complicate synchronization logic increase padd module idle cycle FIFOs empty decrease resource utilization balance workload padd module scalar independent parallel therefore replicate entire IV multiple processing PEs bucket FIFOs padd module PEs scalar PE exactly previously described chunk logic greatly simplify detailed workload balance PEs situation PE bucket padd dependency chain padd operation situation uniform distribution bucket evenly padd operation padd module across bucket PE aware bucket latency difference padd operation negligible therefore load balance multiple PEs maintain scalar polynomial computation expend witness directly dense regard approximately uniformly distribute ntt brings uncertainty data consequently possibility extremely sparse scalar arithmetic circuit usually bound constraint binary brings expend witness vector directly compute without pipelined acceleration hardware separately overall overall architecture  cpu expands witness transfer data accelerator ddr memory accelerator memory execute ntt  poly phase poly msm subsystem scalar filter fetch scalar parallel  XIIHU      overall architecture  vector output partial sum bucket cpu remain addition execution ECs actual msm implementation snark exactly algorithm benefit architecture introduce IV difference multiplication modular multiplication whereas resource implement however overall msm scalar vector sparse therefore host cpu achieve resource performance summary cpu generates witness msm accelerator poly msm heterogeneous interaction computation parallel VI evaluation evaluation consists microbenchmark various input constraint ntt msm module along typical workload application zcash showcased workload demonstrate practicality implementation experimental setup poly msm stack verilog implementation operation padd  PMULT montgomery optimization projective coordinate synthesize synopsys compiler UMC library detail ramulator simulate performance chip ddr memory ASIC poly msm module integrate along module trust setup witness generation  host cpu derive prototype illustrates denote ASIC gpu implementation denote  gpu implementation denote   bellman cpu CONFIGURATIONS   platform platform detailed configuration curve ASIC synopsys DC UMC library ddr mhz channel rank BN BLS mnt cpu intel xeon 0G logical core  ram BN mnt BLS  nvidia gtx TI BLS  nvidia gtx TI mnt II     ntt module input  cpu ASIC cpu ASIC server denote cpu respectively due limitation baseline implementation correspond curve detail evaluate ntt msm input microbenchmark ntt msm implementation ASICs input demonstrate scalability ntt msm evaluate underlie elliptic curve BN BLS mnt bitwidth respectively BN mnt  CPUs  BLS gpus ntt msm II speedup baseline attach latency ASIC latency ratio baseline ASIC cpu gpu implementation ASIC demonstrates speedup ntt msm respectively increase input implementation superiority carefully tailor tradeoff resource consumption ASIC implementation curve BN implement ntt pipeline PEs msm PE msm ntt mnt curve BLS implement ntt gpu implementation BLS faster cpu omit correspond latency cpu simplicity however gpu implementation demonstrates weaker performance core cpu server cpu BN mnt II BLS scalar performance ntt II     msm module input  cpu ASIC  ASIC cpu ASIC IV resource utilization consumption curve module frequency dyn    BN poly mhz msm mhz interface mhz overall BLS poly mhz msm mhz interface mhz overall mnt poly mhz msm mhz interface mhz overall pipeline PEs msm resource utilization curve module resource curve integer modular multiplication detail IV integer modular multiplication dominant role resource utilization performance improve careful resource efficient modular multiplication evaluate snark workload evaluate poly msm snark typical workload proof load parameter pcie compute poly msm chip processing cpu workload compile  execute  backend cpu gpu baseline evaluate curve mnt described msm offload cpu gpu baseline poly msm msm respectively overall proof  without breakdown due heterogeneous architecture intertwine timing msm poly gpu cpu ASIC implementation latency proof without ASIC latency msm cpu proof msm snark msm denotes computation  msm msm VI consists msm maximum latency execute parallel however msm usually dominates overall latency summary significant acceleration rate implementation baseline faster additional msm speedup evaluate zcash evaluate industrial application zcash cpu implementation currently available gpu implementation zcash VI workload    output zcash shield transaction compound proof combination workload transaction proof latency transaction generate signature occupy portion workload  accelerate generate shield transaction circuit   output reduce latency shield transaction overall acceleration rate acceleration rate module poly msm latency msm generate witness cpu msm gen witness dominate acceleration mention previous msm exactly architecture acceleration rate addition generate witness highly parallelizable software optimization overall accelerate overall speedup achieve implementation therefore effort technically trivial ASIC msm  witness generate future vii CONCLUSIONS zero knowledge proof introduce decade widely useful weapon establish trust preserve privacy however limited performance impede wider application propose  architectural effort significantly accelerate snark  proof protocol introduce implement various technique efficiently streamline operation NTTs  etc snark empirical demonstrate considerable speedup