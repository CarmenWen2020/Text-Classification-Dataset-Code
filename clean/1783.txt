computer designer building cache hierarchy capacity capture increase workload cache hierarchy capacity improve performance shift performance bottleneck address translation propose midgard intermediate address virtual physical address mitigate address translation overhead without program midgard leverage operating concept virtual memory VMAs realize midgard address VMAs uniquely mapped midgard address serf namespace data coherence domain cache hierarchy workload VMAs virtual address virtual midgard translation achieve hardware structure tlb hierarchy  midgard physical address translation llc become frequent cache consequence midgard instead amplify address translation overhead memory hierarchy cache reduce address translation overhead evaluation midgard achieves address translation overhead traditional tlb hierarchy KB MB aggregate llc midgard traditional tlb hierarchy MB MB aggregate llc cache hierarchy capacity midgard address translation overhead zero secondary tertiary data llc traditional TLBs suffer address translation overhead index virtual memory address translation memory hierarchy virtual cache datacenters server introduction propose evaluate midgard future proof virtual memory VM abstraction performance implementation complexity challenge emerge memory VM simplifies program model obviate programmer orchestrate data movement memory device persistent storage pointer pointer everywhere semantics across multiple cpu core accelerator gpus FPGAs NICs ASICs VM foundation author  realm     access memory protection mechanism ubiquitous computer security unfortunately VM plague cripple performance complexity challenge undermine programmability benefit central computer architect increasingly  cache hierarchy memory latter improves performance data workload evidence recent stack chiplets dram cache non volatile byte addressable memory however shift performance bottleneck virtual physical address translation consume overall performance architect consequently complex address translation hardware operating OS significant chip sophisticated heuristic complex hardware OS verification burden despite bug abound individual cpu core recent accelerator integrate tlb hierarchy entry TLBs multiple skew  TLBs cache multiple concurrently necessitate stagger amount OS logic  memory heuristic migrate heuristic performance pathology hence panacea processor vendor integrate specialized MMU cache per core accelerate specialized per core TLBs MMU cache necessitate sophisticated coherence protocol OS shootdowns buggy adoption asynchronous approach hide shootdown overhead core socket server circumvent cache hierarchy LLCs traditionally amplify VM overhead actually mitigate VM overhead redirect translation activity specialized translation hardware inspire prior virtual cache  UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca  cache address translation reduce address translation pressure defer physical address memory access unfortunately compromise programmability synonym homonym reliance inflexible fix approach address OSes tackle removal synonym homonym recompilation binary data unified virtual address  intermediate address cache hierarchy without shortcoming homonym synonym fix lightweight conversion virtual address heavier translation physical address access memory propose midgard abstraction intermediate address fuse OS concept virtual memory VMAs hardware application memory collection flexibly VMAs permission intermediate midgard address VMAs various uniquely mapped unique address serf namespace data coherence domain cache hierarchy access cache hierarchy translate program virtual address midgard address however latter accomplish translation structure TLBs VMAs workload translation midgard physical address filter situation access coherent cache hierarchy therefore instead amplify address translation overhead cache hierarchy leveraged reduce quantify midgard performance characteristic cache hierarchy MBs GBs modest MB SRAM cache hierarchy filter majority memory access memory reference translation midgard physical address characterize vma function dataset thread confirm vma seamless translation virtual midgard address average memory access AMAT analysis llc capacity MBs comfortably outperform traditional address translation MBs outperform evaluation midgard within address translation overhead conventional KB tlb hierarchy MB llc  tlb hierarchy MB llc unlike tlb hierarchy exhibit overhead cache hierarchy midgard overhead zero secondary tertiary data cache hierarchy finally pessimistic scenario LLCs midgard augment modest hardware assistance achieve competitive performance traditional address translation demonstrate fully midgard focus proof concept software model prototype architectural component future address spectrum topic realize midgard restrict OS verification implementation architecture detailed circuit hardware structure II virtual memory virtual memory abstraction OSes toolchains organize program virtual address VMAs contiguous various logical data code heap stack mapped file vma consists bound address permission optional VMAs adequately program logical without actually underlie physical resource program regularly VMAs handful frequently access constitute OS responsible allocate physical memory program mapping virtual physical address trivial approach vma identically contiguous physical memory latter external fragmentation moreover physical memory constrain resource OS target optimize towards efficient memory capacity management therefore virtual physical memory fix frame respectively virtual physical frame effectively utilize physical memory capacity becomes memory allocation vma capacity multiple OS typically program vma abstraction without directly encounter management physical memory OS VM subsystem combine access translation memory access undergo permission access additionally physical memory device virtual physical address translation virtual physical mapping VMAs dictate permission management granularity permission duplicate TLBs hardware structure cache entry access perform access address translation address translation bottleneck growth data orient service program become memory intensive online service host datacenter generate data rapidly memory capacity server operating datasets  already terabyte unfortunately physical memory terabyte linear growth translation metadata KB TB various arrangement address legend refers various address physical memory mapping locality data capture memory access server workload frequent lookup mapping already tlb entry per core magnitude moreover cannot provision tlb entry heterogeneous logic various core gpus accelerator mismatch requirement availability virtual memory critical bottleneck memory tlb incurs latency memory capacity latency increase tlb overhead intel already shift virtual address increase latency traffic proposal parallelize reduce latency incur latency remains performance bottleneck overall core latency operation undermine hierarchical structure memory complex operation delegate hierarchy introduce increase tlb unfortunately transparently program without internal fragmentation importantly program allocation  VM abstraction ideally program VMAs iso performance without explicitly request finally alignment constraint vma address furthermore dram memory become increasingly heterogeneous migrate dynamically heterogeneous device dram persistent memory bandwidth memory flash performance gain mapping modification expensive global tlb shootdowns invalidate correspond tlb entry core virtual cache hierarchy address OSes prior observes access memory access translation physical address physical memory access however traditional translate virtual address physical address index cache hierarchy physical address unique namespace mapping virtual midgard address VMAs mapping  address physical address cache hierarchy midgard address translation core TLBs granularity efficient capacity management memory virtual cache hierarchy aim delay translation memory remove complex tlb hierarchy critical memory access away core private virtual address namespace index cache hierarchy virtual hierarchy incorporate complexity resolve synonym homonym across virtual address implement OS access numerous proposal mechanism optimization implement virtual cache hierarchy implementation complexity remains prevent mainstream adoption address operating avoid synonym homonym virtual cache hierarchy easy adopt instead private virtual address OSes virtual address identify data unique virtual address unfortunately implement address operating significant modification program abstraction obstacle adoption midgard abstraction midgard conceptual pillar midgard enables placement coherent cache hierarchy namespace programmability traditional VM midgard quickly translates virtual address namespace permit access along significantly hardware resource per core TLBs MMU cache hierarchy translate midgard address physical address modest augmentation OSes midgard filter heavyweight translation physical address memory reference llc LLCs capture workload naturally enables performance traditional address translation building midgard atop virtual memory midgard injects VMAs directly hardware realize address decouple instead layer mapping per virtual physical frame logic CPUs cache hierarchy  virtual midgard address VMAs logic cache hierarchy vma midgard address physical frame translate granularity VMAs beneficial workload magnitude VMAs unrestricted fix whereas traditional VM relies specialized tlb MMU cache hierarchy multi midgard incorporates hardware OS translation midgard ability defer translation llc relatively costly translation granularity eliminate llc evaluation modestly LLCs MBs eliminate heavyweight translation physical frame memory reference graph processing workload integration multi GB eDRAM dram cache unlike traditional tlb translation midgard llc filter translation request future proof VM performance midgard obviates compromise programmability thanks indirection unique namespace midgard mitigates homonym synonym access limitation virtual cache hierarchy cache address translation midgard avoids modify exist program abstraction recompiling binary address OSes virtual interface unlike prior restrict VM abstraction fix midgard exist OS variable vma flexible manner operating midgard midgard OS augment VMAs per virtual address midgard memory  midgard address OS maintain vma mma mapping mma mapping physical frame midgard address per VMAs mapped midgard address without synonym homonym OS  VMAs across various VMAs occupy contiguous virtual midgard address therefore vma virtual address correspond mma  maintain adequate another maximize growth without collision ensue costly relocation fortunately  partly physical memory fully midgard address adequately physical address  practically accommodate  collide OS remap mma another midgard address cache flush splitting mma additional  vma mma mapping data structure OS vma vma mma mapping achieve VM translation data structure implement vma possibility per vma traditional per radix vma traditional invert midgard prototype compact per data structure realize arbitrarily VMAs span virtual address akin recent implement vma structure vma mapping bound virtual address capture vma vma mapping offset indicates relative offset vma virtual address mma midgard address bound offset align storage vma entry virtual midgard address vma entry permission access vma mapping therefore roughly byte relatively vma accommodate KB vma traditional detailed vma implementation future mma physical frame mapping data structure midgard OS  physical frame MP translation  unlike vma midgard granularity VMAs physical frame although alternative radix mapping memory allocation lazily akin demand mma mapped physical frame lookup cache hierarchy latter prompt MP translation prompt fault  OS lazily mma physical frame mapping initiate demand signal segmentation fault although correctness midgard performance benefit optimization midgard allocate contiguously explain subsequently contiguous allocation allows MP translation circuit lookup multiple radix implement midgard spirit operation  hardware structure cache contiguous allocation insight radix midgard layout hypothetical  radix sparsely utilized fully expand radix unmapped contiguous manner enable circuit MP hardware midgard midgard hardware within cpu memory hierarchy efficient operation register vma midgard vma mapped midgard address expose cpu per core vma register midgard address node contrast pointer physical address midgard maintain dedicate midgard register memory controller hardware fault fault due MP translation failure signal exception core memory request originate maintain precise exception fault instruction exception handler execute rollback easy implement load synchronous operation data arrives asynchronous operation processor retire reorder buffer address confirm completion buffer execution ahead MP translation fails speculation technique cannot imprecise exception midgard necessitates hardware extension buffer speculative pipeline buffer buffer previous mapping physical register file permit rollback register mapping MP translation failure detail mechanism future update midgard midgard entry conventional access dirty identify recently modify access tlb update memory access platform opt access upon tlb entry midgard update access upon llc cache correspond access approximate access recency information reset periodically OS coarse grain update access acceptable memory eviction infrequent contrast dirty precise information update upon llc writeback correspond accelerate VM translation per core virtual lookaside buffer  akin traditional TLBs accelerate VM translation vma  access translation virtual midgard address vma granularity program magnitude VMAs suffices  entry TLBs entry  significantly TLBs rely comparison vma correspond virtual address discus IV ensure comparison unduly VLB access accelerate MP translation majority memory reference satisfied cache hierarchy MP translation frequent VM translation nevertheless propose optimization accelerate MP translation foremost contiguous layout realize midgard permit circuit radix contiguous layout enables identification desire entry purely midgard address  logic performs MP translation calculate midgard address entry target midgard address data tandem address contiguous contiguous allocation permit circuit structure cache data target virtual address entry cache hierarchy directly calculate midgard address skip midgard request entry cache hierarchy  midgard traversal logic midgard entry physical address fetch memory subsequent algorithm traverse midgard towards physical address node none cache hierarchy explore optimization midgard lookaside buffer MLB cache frequently entry midgard mapping access information access dirty MLBs optional useful really constrain setting capacity llc relatively MB MLBs traditional associative TLBs access midgard address upon llc MLB midgard llc already absorbs temporal locality MLB lookup primarily spatial fundamentally traditional TLBs typically entry per thread logical memory reference VM translation MP translation diagram assumes optional MLB access TLBs MLB entry maintain status implement replacement policy summary address translation summarizes overall midgard hardware software feature optional MLB sequence VM translation VLB lookup lookup vma VLB vma absent cache hierarchy MP translation vma perform satisfied VLB vma cache hierarchy memory reference replayed data lookup proceeds lookup cache hierarchy MP translation MLB consult MLB commences midgard optimize via circuit structure cache style lookup llc accelerate midgard assume traversal vma midgard manage entirely hardware without OS intervention mirror hardware traditional conceptual benefit focus midgard ability reduce frequency heavyweight virtual physical address translation traditional via indirection however additional benefit midgard mitigation shootdown complexity VMAs  allocate deallocated frequently suffer permission switch vma VLB tlb expensive bug prone OS initiate shootdowns become anatomy multicore midgard dash MLB optional midgard moreover dedicate translation hardware MP translation reasonably LLCs OS initiate shootdowns entirely elide conservative scenario llc permit MLB shootdowns expensive versus broadcast mechanism implement maintain coherence across multiple TLBs MMU cache hierarchy private individual CPUs relative permission optimization opportunity data security outside scope flexible frame allocation midgard allows independent allocation VM MP translation independent allocation enable allocation granularity virtual memory allocate MB chunk physical memory allocate KB frame VM translation granularity virtual midgard address thereby increase index prior translation ameliorate limitation   cache hierarchy cache capacity implementation guard improve midgard logically united VMAs traditionally guard merge midgard guard unmapped MP translation IV  midgard discus implementation detail   mechanism accelerate MP translation without loss generality assume virtual address mapping  physical address mapping petabyte midgard address OS allocates memory KB granularity depicts anatomy midgard  multicore various component cod affected midgard specific parameter configuration discussion purpose virtual lookaside buffer   benefit abundant temporal spatial locality memory access application active VMAs VLB entry cache nevertheless unlike TLBs  perform lookup fundamentally hardware memory access VM translation VLB lookup core memory access rate understand impact lookup VLB access analyze VLB hardware CMOS library VLB entry bound register comparison virtual address comparison latency largely comparison width vma entry concurrently virtual address bound register vma capacity multiple KB entry VLB access consume entire cycle 2GHz prefer slack VLB access cycle accommodate optimization VLB rate therefore VLB hierarchy recently propose TLBs VLB traditional fix tlb VLB fully associative vma tlb VLB equality comparison core timing constraint VLB filter translation request maintain traditional translation datapath core VLB performs comparison VLB therefore tolerate cycle access latency entry capture active VMAs VLB translation succeed cache hierarchy access midgard address recall implementation midgard address wider physical address therefore cache directory midgard address integrates tag longer cache physical address assume KB instruction data cache MB llc cache per tile byte directory tag core midgard maintains tag extra per tag additional KB SRAM midgard finally dimension structure vma memory reference traversal VLB vma entry byte byte cache roughly vma entry accommodate vma balance btree vma mapping non leaf entry midgard pointer instead offset vma node bound register pointer leaf entry VLB midgard dimension structure midgard memory reference traversal traditional radix midgard physical address mapping granularity midgard address radix traverse midgard therefore sequential memory reference beyond traditional VM contiguous layout midgard enables circuit effectively hide latency deeper midgard midgard entry cacheable lookup MP translation logic responsible midgard generates request cache hierarchy llc slice closer walker logic intermediate cache therefore memory reference walker rout llc response coherence fabric retrieves recently update desire midgard entry cache hierarchy coherence fabric satisfies MP satisfies traditional  latency MP cache hierarchy coherence fabric desire midgard entry OS recently access midgard entry intermediate cache midgard frequent OS midgard entry lookup midgard entry usually llc cache hierarchy midgard address midgard mapped midgard address cacheable reserve memory chunk within midgard address midgard calculate memory chunk occupy byte midgard organize radix therefore byte reserve memory chunk byte midgard address midgard midgard register address chunk  recall contiguous layout midgard permit circuit lookup radix parallel lookup radix circuit lookup reduce latency midgard uniformly useful performance optimization parallel lookup midgard potentially reduce latency llc lookup deeper midgard frequent amplify llc lookup traffic potential utility parallel lookup multiple midgard average latency difference configuration evaluate midgard lookaside buffer MLB uncommon LLCs relatively integrate central MLB core centralize MLBs per core MLBs centralize MLBs utilization benefit versus private MLBs TLBs enjoy versus private TLBs allocate hardware resource individual core statically partition resource fix entry centralize MLBs eliminate replication mapping exist per core MLBs centralize MLBs simplify shootdown logic OS elide invalidation broadcast across multiple MLBs centralize MLB slice improve access latency bandwidth LLCs memory controller interleave policy MLB slice colocate memory controller manner  MLB slice memory controller benefit overall memory access latency MLB local memory controller directly access retrieve data memory finally MLBs concurrently cache mapping correspond TLBs traditional TLBs tolerate longer access latency therefore sequentially apply multiple hash function desire entry tlb detect mask input address accord tag MLB resides memory hierarchy receives traffic relaxed latency constraint TLBs relaxed latency MLB therefore ripe concurrently traditional methodology implement midgard  instrumentation built qemu detailed parameter evaluation model server cortex core operating 2GHz frequency core KB cache MB llc tile along aggregate 6GB memory core entry tlb entry tlb translation KB MB midgard conservatively model VLB core cortex traditional entry fully associative cycle tlb entry cycle cache KB byte cycle tag data llc MB tile cycle non inclusive memory 6GB capacity 6GB per core memory controller mesh midgard VLB entry fully associative cycle vma VLB vma entry cycle parameter simulation  capacity traditional tlb along entry VLB core mesh architecture memory controller midgard directly relies cache hierarchy address translation performance susceptible cache hierarchy capacity latency evaluate cache hierarchy MB SRAM cache GB dram cache AMAT estimate overall address translation overhead various approximate impact latency across cache hierarchy capacity assume cache hierarchy configuration model amd zen rome chiplet llc MB MB latency increase linearly cycle multi chiplet aggregate llc capacity MB MB chiplets remote chiplets cycle remote llc access latency backing MB local llc chiplet MB llc dram cache HBM capacity MB 6GB cycle access latency baseline midgard directly relies midgard perform MP translation evaluate midgard optional architectural MP translation filter request midgard conservative cache average memory access AMAT metric impact address translation memory access trace driven simulation model extract rate cache tlb hierarchy component assume constant average latency llc configuration described various hierarchy memory parallelism benchmark account latency overlap evaluate potential midgard graph processing workload gap benchmark suite graph highly irregular access reliance address translation performance gap benchmark suite contains graph algorithm benchmark breadth bfs betweenness centrality BC pagerank PR source shortest component CC counting TC evaluate graph algorithm uniform random uni kronecker kron graph benchmark behavior bfs dataset GB thread bfs II vma dataset thread gap suite kronecker graph graph specification benchmark graph evaluate vertex core VI evaluation evaluate midgard opportunity future proof virtual memory minimal vma abstraction midgard performance sensitivity cache hierarchy capacity comparison conventional tlb hierarchy finally evaluation architectural enhance midgard performance aggregate cache hierarchy capacity limited vma usage characterization confirm unique VMAs workload directly dictate vma entry VLB unique evaluate vma dataset thread bfs gap benchmark suite exhibit performance translation II depicts VMAs benchmark dataset 2GB 2GB vma increase possibly algorithm malloc mmap allocate vma plateau dataset 2GB 0GB datasets VMAs without affect II VMAs increase thread benchmark 0GB dataset additional thread VMAs comprise private stack adjoin guard VMAs private per thread addition imply increase VLB entry active thread finally depicts VLB benchmark benchmark VLB achieve rate benchmark access VMAs code stack heap memory mapped vma graph dataset TC benchmark achieves rate VLB entry benchmark entry achieve rate bfs graph benchmark entry corroborate prior finding entry sufficient server workload therefore conservatively provision VLB entry evaluation percent AMAT spent address translation address translation overhead besides vma translation directly hardware opportunity midgard exploit  cache hierarchy filter majority memory access MP translation  memory request cache address translation baseline midgard perform MP translation memory request filter cache hierarchy contrast traditional tlb typically provision resource tlb hierarchy MMU cache extend address translation increase aggregate cache hierarchy capacity overall address translation overhead AMAT midgard tlb plot geometric address translation overhead across benchmark cache hierarchy configuration described reflect aggregate capacity recent intel  amd zen rome intel knight address translation overhead traditional KB graph workload datasets minimally MB LLCs around tlb per instruction MPKI KB overall graph benchmark exception BC TC kron graph rate desktop workload 5GB server workload midgard achieves overall address translation overhead traditional KB tlb minimally llc virtually eliminate silicon provision per core entry TLBs KB SRAM obviate MMU cache hardware MP translation dataset server workload increase server feature increasingly aggregate cache hierarchy capacity increase aggregate cache capacity relative tlb traditional benchmark traditional tlb MPKI VLB capacity traffic filter llc avg cycle uni kron uni kron uni kron MB MB MB MB traditional midgard traditional midgard bfs BC PR CC TC graph analysis rate MPKI traditional KB TLBs VLB rate MP traffic filter latency traditional KB tlb midgard graph kronecker graph decrease average fetch data decrease due cache rate unsurprisingly address translation overhead traditional KB tlb exhibit overall increase thereby justify continued increase tlb entry core workload exhibit secondary tertiary capacity MB MB traditional KB address translation overhead increase limited tlb AMAT respectively contrast midgard address translation overhead dramatically secondary tertiary transition graph thanks correspond memory request filter cache hierarchy amount MP traffic filter MB MB LLCs MB already filter MP traffic majority benchmark data directly midgard namespace cache hierarchy MB llc benchmark traffic filter benchmark kron graph virtually eliminate translation traffic due enhance locality midgard address translation overhead MB MB llc comparison average latency KB tlb midgard midgard fetch leaf entry cache average access per llc tile cycle away contrast tlb lookup per lookup perform cache hierarchy typically llc access midgard achieves reduction latency tlb BC outlier locality lookup tlb average latency midgard comparison evaluate future proof virtual memory midgard midgard performance optimistic bound address translation overhead sensitivity MLB MB llc translation granularity MB 1GB thereby enhance tlb reduce overall address translation overhead prior indicates maintain throughout program execution costly memory defragmentation frequent tlb shootdowns inadvertently performance bottleneck migrate numa evaluate bound optimistically assume zero memory defragmentation tlb shootdown ideal MB address translation migration assume MB tlb entry per core KB depicts comparison address translation overhead midgard ideal MB tlb surprisingly MB dramatically outperforms tlb KB midgard minimally MB llc increase tlb KB tlb exhibit increase address translation overhead increase aggregate llc capacity overall address translation overhead MB MB cache capacity contrast KB exhibit drastic tlb MB MB cache MLB function llc capacity tertiary data 2GB overall tlb core entry tlb sensitivity tertiary fitting instead dram cache configuration assume transition multiple chiplets chiplet MB MB dram cache access latency overall AMAT dram cache access address translation overhead dram cache increase increase aggregate cache capacity comparison midgard performance continuously improves cache hierarchy capacity address translation overhead virtually eliminate midgard within performance MB cache capacity MB aggregate  llc capacity amd zen rome beyond 1GB cache capacity midgard compatible benefit midgard adequate performance traditional overall midgard performance address translation memory server without rely architectural MP translation future server integrate cache hierarchy memory access intensive workload exhibit non negligible sensitivity address translation overhead aggregate cache hierarchy capacity MB subsection evaluate architectural MP translation MLBs MLBs TLBs complicate overall complexity justified improvement address translation overhead cache hierarchy capacity analyze aggregate MLB MLB entry across memory controller gap benchmark minimally llc MB illustrates MPKI MP translation per kilo instruction function MLB MLB requirement across benchmark largely approximately exhibit MP translation primary average roughly around aggregate MLB entry benchmark exhibit function MPKI latter provision MLB entry per thread MP translation spatial KB frame memory beyond MP translation around MLB entry prohibitive thereby practical MLB entry per memory controller illustrates address translation overhead cache hierarchy upto MB aggregate MLB entry average gap benchmark midgard refers baseline without MLB corroborates average MLB entry sweet MB cache MB llc midgard address translation overhead traditional KB overall MLB entry entry per memory controller contrast practical provision MLB midgard ideal minimally llc MLB entry midgard virtually eliminate address translation overhead MB MB aggregate llc respectively moreover MLB entry midgard outperforms llc capacity MB finally llc capacity MB benefit architectural MP translation vii related virtual memory constraint virtual cache proposal virtual cache date recent propose virtual cache context gpus summarize variety tradeoff context virtual cache address operating eas virtual cache implementation significant software modification intermediate address propose global virtual address address cache however translation virtual global virtual address fix program replace propose intermediate address virtual address translate MB granularity GB memory TB memory propose intermediate address fix virtual application virtual VMAs midgard significant application toolchain modification target adoption implementation reduce address translation overhead midgard compatible proposal integration benefit MP translation performance recent introduce notion contiguous data virtual address mapped contiguous physical address optimization compatible midgard MP translation conclusion despite decade research building complex tlb MMU cache hardware hardware OS address translation remain  performance performance computer designer integrate cache hierarchy capacity address translation continued surge propose realize evaluate proof  midgard intermediate namespace data coherence domain cache hierarchy reduce address translation overhead future proof VM abstraction midgard decouples address translation requirement core access granularity VMAs memory translation granularity efficient capacity management midgard decouple enables lightweight core virtual midgard address translation leaner hardware traditional TLBs filter  midgard physical address translation situation llc vendor increase llc capacity primary secondary tertiary workload midgard physical address translation becomes infrequent AMAT analysis midgard achieves address translation overhead traditional tlb hierarchy KB MB aggregate llc midgard traditional tlb hierarchy MB MB aggregate llc cache hierarchy capacity midgard address translation overhead zero secondary tertiary data llc traditional TLBs suffer address translation overhead demonstrate fully midgard focus  concept software model prototype architectural component future address spectrum topic realize midgard