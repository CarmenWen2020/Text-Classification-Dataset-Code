importance graph workload limitation CPUs gpus graph processing accelerator propose approach prior accelerator focus graph algorithm variant  slice helpful specialization leaf performance potential flexibility complicates understand relationship graph workload algorithm specialization explore flexibility graph processing accelerator identify taxonomy algorithm variant develop template architecture polygraph flexible across variant modularly integrate specialization feature overall flexibility graph acceleration critical variant  priority vertex schedule graph slice achieve speedup perform accelerator  however static flexibility per workload improve performance dynamic flexibility per phase performance improves introduction graph fundamental data structure data mining navigation social network AI graph processing workload challenge traditional architecture CPUs gpus due data dependent memory access reuse parallelism however workload specialization opportunity commutative update resilience perform arbitrary repetitive structure memory access computation implies advantage specialization cpu offload accelerator generally assumption aspect graph processing simplicity limit ability generalize assume input graph diameter workload resilience frontier density importantly fundamental graph algorithm variant variant dramatically affect tradeoff throughput efficiency update visibility granularity graph update become visible vertex schedule grain schedule policy vertex update efficiency optimize sequential execution perform parallel execution algorithm variant optimize throughput optimize efficiency prior graph accel  synchronous locality slice robin  asynchronous creation non slice  asynchronous priority non slice  asynchronous locality slice locality vertex schedule creation ord priority ord locality vertex ID update visibility synchronous slice sync asynchronous slice schedule non slice graph slice eff slice locality slice rnd robin update direction algorithm variant dimension prior accelerator efficiency throughput tradeoff slice schedule graph update direction vertex update variant profoundly implication hardware implication graph workload prior graph accelerator focus algorithm variant algorithm variant tradeoff efficiency locality  load balance accelerator perform workload input graph throughput giga traverse per GTEPS versus efficiency model accelerator performance  throughput equi performance curve insight optimize performance flexibility algorithm variant graph workload workload phase UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca variant challenge architecture sufficient algorithm architecture flexibility performance overhead flexibility granularity task synchronous asynchronous update grain task schedule flexibly flexibility data structure approach augments prior efficient  accelerator data structure memory intensive breadth bfs compute intensive workload graph convolutional network gcn fundamental limitation exist decouple spatial accelerator lack grain data dependent parallelism task parallelism developed novel execution model taskflow integrates task abstraction data dependent schedule primitive within dataflow program representation integrate flexible hardware variant combination challenge integrate asynchronous variant slice execution mechanism switch slice orchestrate data slice transition task due pipelined dataflow execution develop throughput task scheduler rely mesh interconnect scalability local bandwidth multi spatial partition scheme critical ensure locality balance load accelerator polygraph combine mechanism programmable multicore specialized variant graph processing workload dynamic parallelism evaluation evaluate polygraph  simulation architecture feature encompass prior evaluate traditional ML graph workload graph billion  polygraph PG  diameter graph faster titan gpu importantly flexibility critical statically algorithm variant gain speedup dynamic flexibility speedup contribution flexibly dynamically switch specialized graph processing algorithm variant flexible taskflow execution model integrate dynamic task parallelism pipelined dataflow execution novel  pipelined task creation schedule leverage graph algorithm detailed comparison prior graph accelerator insight relationship graph workload algorithm variant architecture technique org background workload graph II discus taxonomy algorithm variant develop unified program IR  accelerator tile template slice slice spatial slice spatial slice slice slice logical execution slice memory hierarchy chip network conflict detection task scheduler compute address generator memory hierarchy chip network conflict detection task scheduler compute address generator accel tile accel tile accel tile accel tile accel tile accel tile accel tile accel tile accel tile temporal slice scheduler memory hierarchy chip network conflict detection task scheduler compute address generator accel tile accel tile accel tile accel tile accel tile accel tile accel tile accel tile accel tile temporal slice scheduler algorithm temporally slice algorithm variant chose vertex prop vert prop wgt vert prop prop vert prop prop active outgo vertex spatial slice parallel active vertex active vert prop init initialize vertex prop active initialize active init active active slice temporal slice procedure calc shortest graph temporal slice optional spatial slice chose vertex prop vert prop wgt vert prop prop vert prop prop active outgo vertex spatial slice parallel active vertex active vert prop init initialize vertex prop active initialize active init active active slice temporal slice procedure calc shortest graph temporal slice optional spatial slice algorithm mapping arch template ant IV within polygraph novel spatial partition VI finally evaluate discus related vii IX II graph acceleration background computational paradigm mapping template architecture graph workload vertex centric slice graph execution model vertex centric graph execution user define function execute vertex function access adjacent vertex execution converge preprocessing graph spatial temporal locality commonly graph temporal slice slice chip memory preprocessing graph core  locality spatial slice slice shortest code model active maintain temporal spatial slice initialization priority vertex comp vertex update prop dist src dist wgt min dist dst dist bfs depth src depth min depth dst depth CC comp ID min src dst PR deg src src deg dst CF grad src prop dst prop vec dst vec gcn inf matrix mult src vec dst vec graph workload prop vertex prop active vertex vertex prop sequential irregular depends vertex schedule vertex prop irregular atomic combine synch update async update sequential graph data structure algorithm iterates active temporal slice vertex active within temporal slice correspond spatial slice execute concurrently within spatial slice vertex schedule iteratively vertex execution update vertex destination vertex activate graph workload implement initial active vertex function compute vertex update function destination vertex optional characteristic priority hint vertex schedule decouple spatial template architecture relationship algorithm accelerator temporal slice scheduler chooses slice coarse graph phase spatial slice slice execute parallel across core task scheduler vertex execute per vertex computation mapped address generator compute atomic update vertex enforce conflict detection stall graph data structure overview essential data structure vertex index vertex contiguously destination vertex optional vertex algorithm computes active data structure buffer vertex depends algorithm variant workload graph graph diameter distance vertex uniform graph per vertex diameter  graph social network diameter vertex highly workload sensitivity graph workload iterative converge converge tends workload functionally resilient computation occurs however describes update direction incoming update vertex update visibility vertex schedule slice schedule graph synchronous slice synchronous asynchronous input graph shortest temporal slice iter sync iter iter sync sync iter slice switch slice switch locality vertex locality vertex creation creation eff priority slice locality slice slice slice slice robin slice slice slice efficiency slice slice slice distance distance variant graph processing algorithm workload amount task perform efficiency sensitive shortest algorithm explore farther away vertex vertex redundant distance farther vertex update shorter sensitivity varies workload breadth bfs sensitive depth likely non converge workload gcn insensitive workload frontier density dense frontier workload PR CF usually active vertex sparse frontier workload bfs sparse frontier workload graph convergence graph algorithm taxonomy systematically flexibility taxonomy dimension discus tradeoff update visibility defines writes become visible computation hence affect granularity task writes become visible pas graph graph synchronous slice slice synchronous immediately asynchronous barrier synchronize update propagation synchronous variant visualizes dependence slice execution graph processing graph slice chip memory dependence distance shrink arrow synchronous asynchronous tradeoff synchronous algorithm naturally sequential consistency vertex update implementation asynchronous variant lock vertex hence sequential consistency task converge workload workload expressible converge ALS barrier synchronous variant overhead due active vertex  slice synchronous bulk synchronous granularity vertex schedule defines processing active vertex relevant asynchronous variant depicts variant shortest locality improve vertex access locality schedule vertex creation schedule vertex activate  efficiency schedule vertex reduces redundant distance II explains intuition priority metric workload tradeoff active vertex access storage spatial locality enables memory bandwidth however efficiency critical update delayed creation fifo logic efficiency dynamic sort distribute sufficient temporal slice defines limited predefined slice graph vertex slice offline partition generally chip memory update data outside slice defer explicit phase switch slice combine barrier synchronous variant slice schedule variant depicts robin iterate slice locality repeatedly slice  prioritize slice slice chosen tradeoff non slice avoids barrier slice switch data movement costly active vertex slice harm optimal restrict schedule scope benefit temporal slice effective chip memory locality schedule improves intra slice reuse delay slice update  efficiency optimizes efficiency without hardware grain schedule update direction defines task update remote task update remote atomic update tradeoff reduces communication bandwidth communication update efficient multicast remote memory request request latency hidden due access reorder potential finally reading incoming active vertex however technique optimize eliminate access vertex convergence effectiveness depends prefetching capability notation shorthand sometimes expand denote variant combination default assume  explicit summary II summarizes throughput lack synchronization improves locality efficiency benefit reduces update latency priority graph active vertex update visibility synchronous asynchronous temporal slice non slice temporal slice sync granularity graph slice vertex creation local eff temporal slice rnd robin local eff shorthand algorithm variant throughput benefit eff benefit input optimize sync mem latency prio sen graph active task update dia active dia active dia active dia active dia active  dia active dia active dia active dia active II algorithm variant tradeoff IV unified graph processing representation variant efficiently unified hardware program representation flexible specialized graph workload develop approach data pipelined task execution slice schedule data representation taskflow requirement taskflow fully pipelined execution per vertex computation data dependent creation task programmatically specify update priority memory reuse taskflow satisfies requirement augment dataflow model priority task taskflow task invoked input argument args function graph workload typically task reconfigurable hardware straightforward task define graph compute memory task node compute node passive maintain item enables mapped systolic fabric efficiency memory node decouple memory access parameter constant creation dynamic consume another node fifo interface defines parameter behavior task node argument ingres egress graph instance task ingres task node task egress task node atomics memory atomics critical due handle memory conflict vertex update vid prio dist index vid cur feat index FL wgt index FL acc acc const FL feature source shortest version  eff graph convolution network version sync aggregation async mat vec task distance update outgo task matrix vector task aggregate feature vector source outgo prev idx idx vector prev idx idx  index FL min index FL dest vid prev dist vector sum filter vid prio dist filter task dest node update dist vid filter  index task dest node node  update dest vid  index memory node definition memory  FL index index idx pop index len pop idx idx len access array array addr index index idx pop index len pop idx idx len atomic array array behavior index fix constant execute remote core  index dist diff num atomic rmw array addr index legend  index  index feature vec task node memory node compute node dependence atomic access execute remote core task node update vid dist feat vid task agg core task acc acc update slice switch update    init pad pad taskflow taskflow memory marked  rmw atomic priority schedule coalesce task argument designate compile task priority task computes priority prior task creation serf hint schedule task priority another task argument indicates ID unique active task ID generally vertex task coalesce slice execution task ID treat update priority task task coalesce priority task upper ID task slice slice task defer slice active schedule slice core taskflow taskflow graph implement  eff workload task associate vertex data task iterates outgo source vertex compute distance creates task destination vertex distance update ID task vertex ID source destination vertex respectively execute core correspond ID task prioritize vertex distance efficiency task vertex become active task task invocation accumulate memory location identify slice switch IV gcn graph aggregation synchronous  asynchronous enables overlap memory intense aggregation task compute intensive matrix task coarse grain iterates vertex slice task node trigger creates cycle source vector feature task aggregate incoming vertex aggregation task asynchronously trigger matrix vector task aggregation identify node overlap split matrix matrix multiple matrix vector computation prevents broadcast matrix localize traffic response duplicate matrix core overhead consumes scratch taskflow flexibility summary synchronous variant   coarse grain task pas per graph per slice active asynchrony explicit grain task optionally priority hint argument slice schedule interface operation responsibility temporal slice scheduler configure chip memory slice execute manage data task orchestration slice scheduler invoked infrequently execute core limited extension data pin operation slice scheduler mechanism initial task data pin algorithm variant data reuse synchronous non slice sgn reuse distance vertex reuse  variant reuse lesser extent slice scheduler optimize reuse slice scheduler interface pin data chip memory offset essentially reserve portion cache pin vertex reuse non pin data treat normal cache access slice switch asynchronous variant decision switch slice asynchronous variant tradeoff efficiency switch sooner reuse switch later explain information slice boundary becomes stale inactive slice execution hurt efficiency impossible calculate staleness depends future execution therefore approximate counting vertex update switch slice exceed threshold slice slice slice slice slice memory load slice vertex task mirror vertex slice update vertex prop pending task load slice vertex slice slice slice slice slice memory data structure graph vertex array pend task slice pend task slice load slice pending task task slice mirror vertex chip memory task queue task queue slice vertex chip memory slice slice slice slice slice slice slice pending task vertex mirror vertex source slice dest slice task slice slice graph slice vertex switch slice slice scheduler core priority task disallows task issue perform slice transition explain slice preprocessing slice preprocessed hence update within slice accomplish mirror vertex slice destination slice remove slice source slice slice mirror vertex slice mirror retains remove vertex slice mirror vertex update slice transition explain slice transition data orchestrate slice transition slice reside chip memory memory contains graph vertex pending task slice mirror vertex transition slice vertex vertex scatter slice core vertex task destination slice task argument slice pending task slice meanwhile update slice vertex mirror vertex slice pending task update vertex memory parallel buffering vertex slice pin memory slice pending task memory schedule algorithm variant quantitative motivation grain effective throughput normalize efficiency algorithm variant axis normalize percentage execution significantly variant performance variant execution diameter graph sensitive SP  eff dominates due efficiency gain potential dynamically switch variant effective GTEPS useful throughput per  efficiency normalize  curve  execution slice slice active vertex sync sensitive dense frontier slice sync async  cluster load balance optimal cluster comp intensity dia graph sensitive sparse frontier slice schedule update visibility multi spatial partition algorithm dimension heuristic algorithm variant algorithm variant schedule sensitive bfs  eff  slice version improve chip rate however switch non slice iteration significant potential diameter graph  diameter graph vertex active iteration synchronization overhead critical therefore   slice consistently dominates dense frontier workload pagerank tension memory efficiency due active vertex efficiency due sensitivity therefore  balance tradeoff optimal CF   optimal initial iteration however   slice dominates later iteration active vertex switch synchronous asynchronous hurt efficiency proceed differently asynchronous leaf vertex active focus priority vertex synchronous conservatively active vertex iteration heuristic algorithm variant schedule algorithm variant slice effective throughput depends phase sufficient hide barrier overhead approximate active vertex  outperforms algorithm active vertex uniform graph  non slice consistently outperforms active vertex due diameter therefore algorithm switch non slice active vertex threshold update visibility dimension decision depends workload characteristic asynchronous version prefer sensitive workload dense frontier algorithm usually active vertex inherent spatial locality  prefer memory efficient maintain moderate efficiency propose flexible multi spatial partition optimize load locality workload graph detail explain VI schedule decision hardware parameter discus variant transition variant selection perform graph slice cycle asynchronous variant amortize latency switch transition algorithm variant core initialize data structure configure taskflow graph perform pin operation dynamic switch invoked chip memory flush taskflow reconfiguration pending task manage slice transition data orchestration polygraph hardware implementation polygraph multicore decouple spatial accelerator 2D triple mesh network  data comprise module besides core responsible execute taskflow graph decouple execution memory compute prior decouple spatial accelerator memory node maintain address generator access decouple hide memory latency softbrain cgra executes compute node pipelined fashion controller cgra FIFOs latency insensitive communication novel aspect task management priority task queue task task node define incoming task argument queue consume controller perform memory request task operation controller accept task task queue issue  task controller issue memory request memory node active task cgra pipeline computation compute node cgra task data output designate task creation consume task management hardware task trigger remotely perform processing data initial task core explicitly task argument task creation task management enables throughput priority task dispatch critical task therefore request multiple task pipelined task coalesces superfluous task throughput priority update maintain multiple network enable efficient scalar remote access chip memory task coalescer task queue prio sched task computation atomic interface task creation interface conflict core router config slice schedule explicit task enqueue implicit task enqueue mem ctrl mem ctrl mem ctrl mem ctrl mem ctrl mem ctrl mem ctrl mem ctrl polygraph config core mesh  dataflow cgra crossbar task  noc module translation address generation overflow memory TQ  polygraph modular hardware implementation bitvector flight task IDs task overflow task queue handle overflow protocol finally slice schedule implement core core inorder core polygraph core communicate slice scheduler memory atomics coordinate phase completion slice scheduler orchestrates data switch slice initiate task remote core prevent task issue task hardware detail task queue priority schedule task argument buffer maintains argument task instance execution statically split task partition configure correspond task argument task argument pointer task argument available task scheduler priority task scheduler described graph access task fifo schedule others vertex update task scheduler pipelined hardware heap memory priority heap pop operation node across lock fashion implies throughput enqueue dequeue operation cycle graph throughput insufficient therefore multiple priority heap per core alternate implies imperfect consecutive priority queue significantly hurt efficiency overflow reserve entry task queue task overflow buffer memory sufficient buffer drain queue entry freed priority calculate update vertex prop calculation priority update due coalesce overflow unfortunately disrupts priority hurt efficiency due delay priority task mitigate reserve task queue entry latent  task queue overflow active vertex frontier cluster partition    multi partition    legend core core core cluster novel multi spatial partition task allocate reserve entry priority priority task task coalesce reduce active task coalesce task ID implement SRAM bitvector corresponds task ID correspond task overflow buffer prevent task insertion ID graph processing task ID corresponds vertex bitvector maximum vertex temporally slice variant non slice polygraph coalesces vertex sufficient partitioner simply critical  vertex vertex memory architecture memory chip memory  cache multiple per polygraph core cache translation maintains mapping virtual address pin address data structure pin prior  NUCA technique slice scheduler core pin memory translation core bound along offset cache aside pin data core generate request acknowledgment subsequent memory request register mapped cache pin pin data structure flush cache newly pin address pin transition variant happens twice active vertex threshold overhead slice  atomic update update request local core network pending atomic request queue correspond conflict logic cam entry atomic latency detect delay aliasing request VI spatial partitioning offline partition  spatial partition mesh gpu     PG     compute GP SIMT ASIC ASIC cgra spad MB MB MB MB MB MB FP mem GB net bus xbar xbar xbar mesh net radix core mem architecture characteristic baseline graph vertex dia structure slice  livejournal twitter  random  uniform  uniform   gcn pubmed cora IV input graph domain PR slice slice CF gcn depends feature network highly effective spatial partition introduces tradeoff locality load balance naively cluster vertex reduce network traffic hurt load balance sparse frontier workload explain gridgraph observation apply broadly cluster slice dot progression sparse frontier workload bfs frontier iteration limited slice allocate core hence strategy extremely load balance multi scheme visually propose multi slice scheme respect load balance locality graph split cluster fix preserve locality cluster distribute equally core balance load implement bound depth depth cluster parameterizable distribute robin slice proportional active vertex hence diameter graph prefer load balance multi active vertex usually across iteration diameter cluster helpful locality vii methodology polygraph prototyped polygraph extend DSAGEN task schedule hardware extend dataflow ISA described synthesize polygraph core noc 1GHz UMC library cactus model eDRAM baseline architecture reference core SKL cpu gap benchmark CF gcn unavailable  graph somewhat representative network algorithm variant performance analysis gap graphmat gunrock respectively evaluate gunrock graph processing library titan gpu gunrock implement CC CF calculate gpu without workload performance model across variant developed custom cycle modular simulator memory model DRAMSim accelerator configuration memory capacity bandwidth max throughput assume preprocessing offline reuse across query temporal partition chunk gemini spatial partition fairness consistency simulation framework provision prior accelerator graphicionado implement capacity optimization extend graph slice coarsen  bypass sequential consistency module workload  model priority speculative execution  optimization slot per task implement variant allows vertex granularity task instead grain task polygraph noc  fpga  model task coalesce consistency simulator distribute schedule polygraph PG evaluate PG   configuration geomean speedup PG  flexibility incrementally per workload static per phase dynamic datasets IV summarizes input graph unweighted graph random assign due prohibitive simulation exploration evaluate graph twitter  overall performance workload evaluate workload graphbased machine workload PR CF optimize convergence rate algorithm variant asynchronous variant gcn inference implement graph synchronous variant asynchronous benefit minimal due gcn  behavior evaluation objective evaluate flexibility useful across graph workload analyze algorithm variant prior accelerator discus sensitivity algorithm hardware parameter algorithm variant performance comparison algorithm variant perform workload graph throughput efficiency overall asynchronous slice  optimal variant geomean speedup typical  static flexibility improve diameter graph diameter graph workload diameter graph highly sensitive asynchrony priority identify useful therefore speedup   scheme   modest efficiency addition synchronization overhead synchronous variant slice  significantly hurt diameter graph overall  slice performs scenario diameter graph priority workload efficiency benefit orkut diameter graph significant reuse due distribution slice greatly improves performance synchronization overhead minimal due active vertex iteration pagerank dense frontier   speedup memory efficiency overall      sufficient vector workload asynchrony collaborative filter gain however priority schedule  graph chip non slice slice update critical moreover vertex spatial locality reduces cache overhead competitive variant generally sufficient hardware priority asynchronous schedule synchronous slice efficiency competitive overall potential graph overall performance comparison gunrock implement CC CF gcn pure asynchronous implementation utilization efficiency tradeoff improve performance asynchronous variant iteration due dynamic task creation finally variant  optimization consistently performs due pipeline stall random efficiency loss access incoming irrespective active competitive counterpart graph undirected extra computation easy partition random mostly local efficiency throughput algorithm variant explains workload graph tradeoff slice improves memory efficiency diameter graph improve efficiency  workload diameter graph regular slice superior achieves rate avoid barrier overhead optimize efficiency dense frontier workload slice synchronous balance memory efficiency vector workload CF memory efficiency implicitly asynchronous variant dominate due faster convergence comparison prior accelerator overall comparison PG  allows variant flexibility workload  enables dynamic switch overall polygraph cumulative speedup novel feature outperforms cpu gpu prior accelerator  achieves speedup diameter graph polygraph achieves  gain gunrock  gpu version   non slice implementation inefficient variant  graph chip memory  PG  lose due slice overhead switch efficiency loss due delayed slice vertex non slice variant avoid overhead diameter graph sensitive PR  gain efficiency due vertex schedule slice significantly improve rate bfs CC sensitive PG  behaves graphicionado however dynamic switch improves performance bfs bfs vector workload gcn accelerator speedup efficient broadcast matrix gpu bottleneck unified cache bandwidth polygraph speedup overlap communication intensive aggregation  multiplication task CF gain efficiency synchrony throughput switch non slice variant later iteration novel feature cumulative speedup novel feature asynchronous accelerator slice significantly improves memory efficiency diameter graph  slowdown diameter graph due efficiency loss bfs  task coalesce particularly benefit dynamic switch threshold sensitivity slice switch heuristic slice vert slice diameter graph eliminate superfluous update vertex locality optimize multi partition fix cluster benefit bfs multi naive partition load primary bottleneck locality available optimal cluster depends input algorithm sensitivity dynamic switch heuristic dynamic switch heuristic described IV performance sweep switch threshold active vertex initial variant variant optimal  diameter graph   performance improves due avoid slice switch overhead performance reduces due memory efficiency non slice dominant non computation intensive workload bfs diameter graph speedup plateau non slice achieve memory efficiency static flexibility sufficient overall dynamic switch primarily diameter graph slice switch heuristic slice switch heuristic sensitive workload task switch outstanding task performance  bfs  converge diameter graph   prefer threshold cluster structure allows ratio intra slice inter slice update diameter graph  highly sensitive delayed update prefer switch earlier diameter graph efficiency loss  polygraph chip memory reduce chip memory sensitivity spatial partition cluster access algorithm variant SP dominates slice flexibility available chose heuristic slice threshold diameter graph diameter graph spatial partition evaluates multi spatial partition policy cluster  variant cluster optimize dynamic load balance cluster improve locality computation intensity bottleneck locality load balance hence cluster bfs prefers cluster memory parallelism critical due computation intensity default cluster diameter graph bfs overall flexible multilevel spatial partition performance gain conventional cluster per data structure reuse per phase access frequency vertex data structure subset variant access average phase synchronous cycle asynchronous vertex critical cache chip reuse finer grain random access although reuse significant iterate slice multiple  variant cache beneficial reduces vertex slice hurt efficiency finally vertex data structure access behavior vertex prop therefore pin vertex prop vertex chip slice variant evaluate CF gcn due vertex maximum cluster core memory bandwidth byte network sensitivity hardware resource hardware sensitivity discus performance sensitivity graph algorithm variant hardware resource workload geomean PR CF unordered bfs CC discus gcn separately polygraph core memory bandwidth performance limited available parallelism diameter graph highly sensitive memory bandwidth unordered workload limited parallelism workload suffer due loss efficiency network latency diameter graph easy partition ensure rate reduce dependence memory bandwidth  dia performance loss core sensitivity factor affect  network latency core network bandwidth sweep scalar network bandwidth slice variant diameter graph chip memory locality bottleneck network bandwidth diameter graph slice  variant achieve rate memory locality therefore slice variant bottleneck load imbalance due frequent synchronization non slice  proportional network bandwidth chip memory performance sensitivity chip memory proxy graph slice cache pressure sensitivity memory core priority task queue task coalescer chip mem ctrl cgra byte crossbar PG core byte mesh byte mesh PG breakdown PG flex consistent input data specific input graph saturation depends ratio graph chip memory workload memory improves efficiency lesser slice reduce barrier latter factor unordered   exception performance degrades chip memory happens core become unsynchronized hurt efficiency gcn sensitivity core gcn performance loss due load imbalance aggregation phase network bandwidth gcn improves linearly byte bandwidth computation becomes bottleneck chip memory MB memory bandwidth become bottleneck happens slice gcn graph maximum MB tradeoff polygraph breakdown occupies eDRAM consume graphicionado polygraph due mesh instead crossbar accelerator speedup overall polygraph graphicionado achieve speedup due optimization flexibility examine tradeoff polygraph remove component consume significant eliminate variant option without cache memory flexibility available hurt diameter graph without priority queue gain sensitive workload reduce dynamic task  variant accelerator performance efficiency convey update sooner memory efficiency locality schedule IX additional related VI categorizes prior variant variant combination polygraph graph framework flexibility software graph framework focus algorithm variant graphmat sgn others amount flexibility program model galois optional schedule vertex bucket data dependent priority  hardware CPUs  interaction update direction memory coherence consistency model gpus demonstrates usefulness flexibility usefulness flexibility across dimension update visibility vertex slice schedule powergraph synchronous asynchronous variant  heuristic switch sync async dynamically effective accelerator centric without sparse access vertex index centric polygraph incompatible optimization priority vertex dynamic task graph taxonomy classify distribute graph framework  taxonomy identifies factor impact graph execution topology synchronicity reorder graph operator hardware specialization slice hardware accelerator graphicionado accelerates synchronous variant  dynamic distribution  sequential consistency asynchronous graph processing ASIC template evaluate workload sequential consistency guarantee correctness CF converge faster consistency digraph multi gpu asynchronous graph processing  prior asynchronous accelerator grain priority schedule exploit multiple HMC node tesseract  extends tesseract phase program model enable efficient partition GraphQ hybrid execution model asynchronous within HMC non slice temporally slice  tesseract graphicionado  graphmat    GraphQ  GraphABCD  eff     giraph  graphlab   digraph  eff galois  VI prior taxonomy software framework  combine update across frequently access reduce execution overhead alternative improve efficiency graph spatial locality technique graph preprocessing employ improve spatial locality useful graph execute locality vertex HATS cpu offload accelerator dynamically discovers graph locality polymer explores spatial placement replication vertex distribute conclusion flexibility graph processing accelerator systematically analyze codesign tradeoff along graph algorithm variant broadly flexibility essential modest graph workload specifically synchronous asynchronous priority locality vertex schedule critical balance efficiency locality dynamically switch slice non slice variant across workload phase enable specialization diameter graph algorithm variant accelerator performance novel combination developed extension dataflow model embeds primitive dynamic parallelism specialized task management memory principle developed helpful broader workload grain task schedule management