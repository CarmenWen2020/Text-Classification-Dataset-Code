data application exhibit software stack instruction footprint frequently instruction cache degrade performance efficiency although numerous mechanism propose mitigate instruction cache ideal cache behavior furthermore introduce significant hardware overhead investigate exist cache mitigation mechanism achieve sub optimal performance data application widely instruction prefetchers due wasteful prefetch induced cache eviction handle exist replacement policy exist replacement policy unable mitigate wasteful eviction lack knowledge data application complex program behavior exist replacement policy aware  program behavior propose ripple novel  technique profile program program context inform underlie replacement policy efficient replacement decision ripple carefully identifies program context cache  injects cache eviction instruction suitable program location link evaluate ripple popular data application demonstrate ripple enables replacement policy achieve speedup closer ideal cache specifically ripple achieves average performance improvement prior due cache reduction introduction data application become increasingly complex application compose complex software stack various kernel networking module compression serialization code remote procedure library complex code stack intricate inter dependency unique instruction execute user request data application instruction magnitude instruction cache cache processor instruction  frequent cache cannot effectively hidden oforder mechanism manifest glare stall critical execution stall deteriorate application performance consume significant hence eliminate instruction achieve digit percent speedup yield immense performance per watt benefit cache reduction mechanism extensively prior propose predictor hardware instruction prefetchers others software mechanism perform code layout optimization improve instruction locality although technique promising additional hardware implement exist processor ideal cache behavior cache incurs completely eliminate cache critical understand exist cache mitigation mechanism achieve sub optimal performance data application performance gap achieve ideal application speedup comprehensively investigate exist cache mitigation technique ideal icache  significant cache per kilo instruction MPKI data application II investigation widely cache mitigation technique instruction prefetching ideal cache behavior exist prefetchers perform unnecessary prefetches pollute cache wasteful eviction wasteful eviction avoid effective cache replacement policy previous proposal global reuse predictor GHRP replacement policy specifically target cache knowledge additional technique originally propose data cache hawkeye harmony SRRIP DRRIP driven investigation propose ripple profile technique optimize cache replacement policy decision data application ripple performs offline analysis sequence instruction without execute data application via efficient hardware trace intel processor trace ripple determines cache ideal replacement policy evict trace ripple computes execution likely signal future eviction UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca ideal replacement policy likelihood threshold explore empirically ripple injects invalidation instruction evict victim cache intel recently introduce invalidation instruction  hence ripple readily implement upcoming processor evaluate ripple combination cache prefetching mechanism ripple yield average improvement prior reduces icache average ripple primarily software technique implement replacement policy already exists hardware evaluate variant ripple ripple recently lru optimize performance reduces cache MPKI previous proposal hawkeye harmony DRRIP SRRIP GHRP ripple random optimize storage overhead eliminate meta data storage overhead outperform prior ripple executes extra dynamic instruction insert static instruction average summary ripple significant performance gain ofthe cache mitigation mechanism minimize meta data storage overhead replacement policy summary contribution detailed analysis exist cache mitigation mechanism data application profile replacement software mechanism program behavior inform replacement decision ripple novel profile instruction cache mitigation mechanism readily exist replacement policy evaluation demonstrate ripple efficacy achieve ideal application speedup II  cache mitigation TECHNIQUES analyze exist technique mitigate cache  rate data application background information data application II perform limit maximum speedup obtain ideal cache application instruction footprint II evaluate exist prefetching mechanism nextline prefetcher FDIP analyze technique achieve sub optimal performance II finally analyze exist cache replacement policy lru harmony DRRIP SRRIP GHRP quantify performance gap optimal replacement policy II analysis foundation ripple novel prefetch aware icache replacement policy achieves performance minimal hardware overhead cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg speedup ideal cache speedup lru baseline without prefetching data application gain average speedup ideal cache background evaluate application widely data application suffer substantial cache application lose pipeline slot due frequent cache  application facebook OSS performance benchmark suite drupal php content management mediawiki wiki wordpress popular content management investigate java application  benchmark suite cassandra nosql database netflix kafka processing uber tomcat apache implementation java  websocket java  benchmark suite analyze finagle chirper twitter microblogging service finagle http twitter http server verilator hardware simulation experimental setup simulation parameter IV ideal cache theoretical upper bound processor performance greatly depends effectively instruction therefore processor dedicate cache typically access cycle maintain access latency processor typically cache KB overwhelmed data application multi megabyte instruction footprint incur frequent cache evaluate cache potential gain cache optimization explore speedup obtain data application ideal cache incurs prior compute speedup relative baseline cache configuration prefetching lru replacement policy ideal cache average speedup baseline cache configuration instruction prefetchers prior propose prefetching technique overcome performance challenge induced insufficiently cache fetch instruction cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg speedup FDIP lru FDIP ideal fetch instruction prefetching FDIP speedup lru baseline without prefetching FDIP speedup lru replacement policy however ideal cache replacement policy FDIP average speedup closer ideal cache speedup prefetching FDIP mechanism implement multiple processor due performance moderate implementation complexity FDIP speedup baseline cache configuration without prefetching FDIP baseline configuration lru replacement policy FDIP lru average speedup baseline performance loss ideal cache speedup analyze FDIP deliver ideal performance equip cache prefetch aware ideal replacement policy leverage revise version demand min prefetch aware replacement policy speedup increase average ideal cache FDIP prefetch aware ideal replacement policy outperforms FDIP lru observation highlight importance combine cache prefetching mechanism replacement policy confirm generality observation standard prefetcher nlp combination nlp prefetching ideal cache replacement speedup nlp baseline without perfect replacement policy understand ideal speedup prefetch aware ideal replacement policy briefly policy summarize ideal speedup quantify speedup ideal replacement policy data application evaluate prefetch aware ideal replacement policy ideal  replacement policy revise version demand min revise demand min evicts cache prefetched farthest future earlier demand access exists prefetch cache demand min evicts demand access farthest future detail quantify observation originally demand min evict inaccurately prefetched cache reduces cache evict prefetch cache reduces cache observation eviction inaccurately prefetched cache reduces cache ideal replacement policy evict inaccurately prefetched cache improve performance practical prefetchers FDIP inaccurately prefetches cache decision predictor occasionally mispredicts outcome however ideal replacement policy knowledge future access immediately evict inaccurately prefetched cache minimize negative performance impact across data application ideal cache replacement policy combine FDIP average speedup speedup FDIP ideal FDIP lru relative lru baseline replacement policy combine FDIP due eviction inaccurately prefetched cache observation evict prefetch cache reduces cache ideal replacement policy prefetch cache cache evict easy  cache cannot prefetched accuracy prefetch cache FDIP predictor cache prefetched outcome prefetched predictor cannot easily predict outcome due indirect prefetch easy prefetch cache cache prefetcher prefetch accurately cache FDIP prefetch outcome unconditional easy prefetch cache ideal replacement policy knowledge access prefetches accurately identify prefetch easy prefetch prefetching policy prioritize eviction easy prefetch prefetch across data application ideal cache replacement policy combine FDIP average speedup speedup FDIP ideal FDIP lru relative lru baseline replacement policy combine FDIP due evict prefetch summary exploit observation optimize prefetch aware replacement policy knowledge future instruction sequence likely execute information static controlflow analysis execution profile instruction trace described IV ripple leverage analysis technique performs inform replacement decision concert prefetcher achieve ideal performance exist replacement policy previous demonstrate  ideal cache replacement policy average speedup relative baseline lru replacement policy explore extent exist replacement policy speedup gap exist storage overhead replacement policy KB associative instruction cache cache replacement policy overhead lru per GHRP KB KB prediction prediction KB signature register SRRIP associativity DRRIP associativity hawkeye harmony KB KB sampler entry KB occupancy vector KB predictor  counter cache replacement policy apart GHRP explore data cache replacement policy lru hawkeye harmony SRRIP DRRIP apply cache GHRP eliminate cache target buffer BTB execution GHRP populates prediction indexed information predict cache alive replacement decision GHRP evict likely GHRP evicts cache counter update predictor evict cache likely similarly GHRP update predictor cache cache likely alive GHRP KB extra chip metadata KB cache primarily prediction hawkeye harmony data cache specifically cache llc simulate ideal cache replacement policy access hawkeye determines program counter PC cache friendly cache averse data access processor executes instruction correspond PC cache friendly access cache access cache friendly PC maintain lru cache replacement policy access cache averse PC marked remove opportunity harmony replacement policy prefetch awareness hawkeye simulates demand min access hardware categorize PCs prefetch friendly prefetch averse SRRIP mainly eliminate adverse scan cache access cache access without temporal locality sequence access SRRIP assumes newly access cache cache averse scan cache access SRRIP promotes status cache friendly DRRIP improves SRRIP thrash access application exceeds cache DRRIP reserve cache friendly cache averse via duel performance cache replacement policy lru baseline FDIP tab metadata storage overhead induced replacement policy none exist replacement policy performance storage benefit lru ideal cache replacement policy average speedup lru explain prior replacement policy significant benefit GHRP classifies cache alive prediction inform eviction decision issue GHRP increase classification confidence prediction eviction decision incorrect evict modify GHRP decrease confidence prediction eviction optimization GHRP outperforms lru hawkeye harmony predicts PC likely access cache friendly cache averse cache insight cache instruction PC responsible access cache exhibit cache friendly cache averse access however cache instruction PC responsible access cache contains instruction multiple cache friendly access cache averse access hawkeye predicts  therefore hawkeye cannot identify  access cannot adapt dynamic cache behavior cache access data application hawkeye predicts almost PCs cache friendly hence fails performance benefit lru SRRIP DRRIP significant performance benefit lru cache access scan access moreover DRRIP thrash access cache scan access rare hence classify scan introduces penalty lru quantify scan access data application compulsory MPKI cache access application compulsory MPKI average moreover SRRIP DRRIP arbitrarily assume cache access scan thrash hurt data application cache performance consequently SRRIP DRRIP cannot outperform lru cache access data application data application tend exhibit unique reuse distance behavior unique cache access associative consecutive access cache reference interval cache varies widely across program due variance cache cache friendly cache averse stage program execution exist adapt dynamic variance hence fail improve performance lru combine insight observation II ripple profile replacement policy data application cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg speedup harmony DRRIP GHRP SRRIP ideal speedup cache replacement policy lru baseline FDIP cache none exist policy outperform lru although ideal replacement policy average speedup ripple replacement mechanism analysis ideal cache replacement policy average speedup lru cache data application moreover exist instruction data cache replacement policy lru baseline ineffective avoid wasteful eviction due complex instruction access behavior hence critical assist underlie replacement policy smarter eviction decision inform complex instruction access propose augment exist replacement mechanism ripple novel profile replacement technique carefully identifies program context cache strives evict cache evict ideal policy ripple operation agnostic underlie cache replacement policy  injects cache eviction instruction suitable program location link assist arbitrary replacement policy implement hardware ripple introduces additional hardware overhead readily implement  release processor ripple enables exist replacement policy performance gap achieve ideal cache performance ripple component online ripple profile program execution sequence efficient hardware trace intel PT LBR ripple analyzes program trace offline ideal cache replacement policy compute cue cue execution almost ideal victim cache evict ripple analysis mimic ideal policy evict farthest future recompilation ripple injects instruction cue invalidates victim consequently cache insert cache victim belongs victim evict contrast prior ripple compute intensive task identify victim hardware release binary trace update binary offline eviction analysis online invalidation injection data ripple aware server runtime profile NT address NT ripple software thereby reduce hardware overhead detail ripple component runtime profile ripple profile data application intel PT trace dynamically execute program trace information instruction program NT denotes NT program indirect program trace address instruction ripple leverage program execution trace perform eviction analysis invalidation injection offline link eviction analysis ripple identifies cache omit speculative access hardware execution trace ripple eviction analysis cache evict hardware ripple leverage intel PT precise execution runtime performance overhead ripple intel PT efficient production scenario eviction access cache eviction ideal policy cache eviction execute execution eviction ideal cache replacement policy execute eviction execute eviction ripple calculates conditional probability eviction cache execution ripple eviction analysis eviction analysis goal ripple eviction analysis mimic ideal replacement policy evict cache access future trace allows ripple retroactively execution benefit invalidate cache cache replacement eviction analysis determines cue execution identify eviction victim cache probability ideal cache replacement policy cue runtime profile ripple analyzes eviction cache span access cache access trigger eviction ideal replacement policy eviction cache cache evict ideal cache replacement policy execution program compute eviction ripple iterates backward trace evict ideal replacement policy partially cache ripple identifies across eviction accurately signal eviction candidate cue described sec insert invalidation instruction mimic ideal cache replacement behavior ripple identifies candidate cue ripple calculates conditional probability cache eviction execution candidate cue probability calculation cache calculate conditional probability ripple calculates metric computes candidate cue execute application lifetime candidate cue execute respectively candidate cue ripple computes unique eviction correspond candidate cue unique eviction respectively ripple calculates conditional probability ratio candidate cue execution cue instance eviction execute denotes execution cache evict finally eviction ripple selects cue conditional probability arbitrarily ripple cue eviction respectively conditional probability threshold ripple inject explicit invalidation request recompilation invalidation instruction inject associate probability threshold injection invalidation instruction eviction analysis ripple selects cue eviction ripple insert explicit invalidation instruction cue invalidate victim cache ripple decision insert invalidation instruction inform conditional probability computes candidate cue specifically ripple insert invalidation instruction cue conditional probability invalidation threshold ripple determines invalidation threshold invalidation granularity ripple decides inject invalidation instruction evict cache detail invalidation instruction ripple relies invalidation threshold ripple considers metric invalidation threshold replacement coverage replacement accuracy define metric explain replacement coverage define replacement coverage ratio replacement decision perform policy replacement decision perform ideal replacement policy policy exhibit replacement coverage omits invalidation candidate optimal replacement policy chosen eviction replacement accuracy define replacement accuracy ratio optimal replacement decision policy replacement decision perform ideal replacement policy therefore ripple induces invalidation program lifetime invalidation introduce ideal cache replacement policy ripple accuracy percentage policy exhibit replacement accuracy evict cache ideal cache replacement policy evict coverage accuracy replacement coverage replacement accuracy useful metric cache replacement policy optimality software policy replacement coverage frequently revert underlie hardware policy suffer sub optimal decision policy  frequently evict program ripple leverage  aggressiveness eviction coverage accuracy although data application finagle http trend across data application evaluate threshold ripple almost coverage replacement decision ripple invalidation ripple accuracy suffers greatly invalidates cache introduce ideal cache replacement policy consequently threshold ripple additional performance underlie replacement policy similarly threshold ripple achieves perfect accuracy cache invalidate ripple incur extra ideal replacement policy however ripple coverage sharply replacement decision ripple insert invalidation therefore ripple performance benefit underlie hardware replacement policy decline rapidly invalidation threshold ripple simultaneously achieves coverage accuracy ripple performance benefit invalidation threshold application ripple chooses invalidation threshold performance application across application invalidation threshold varies invalidation granularity ripple injects invalidation instruction granularity invalidation instruction evict cache ripple suffer performance loss due mismatch ripple speedup evict granularity evict cache combination cache granularity invalidation instruction propose invalidation instruction invalidate address cache invalidation threshold percentage ideal MPKI reduction replacement coverage replacement accuracy coverage accuracy ripple finagle http application exhibit curve invalidation threshold performance across data application varies operand invalidates cache resides icache propose invalidate instruction exhibit difference exist cache flush instruction clflush instruction intel processor invalidate cache cache cache hierarchy instead propose invalidate instruction invalidates cache local cache thereby avoid costly cache coherency transaction unnecessary invalidation remote cache furthermore invalidate instruction latency potentially dirty cache cache instead invalidate regard hint freely reorder fence synchronization instruction intel recently introduce invalidation instruction   future server hence ripple readily implementable upcoming processor IV evaluation experimental methodology evaluate ripple performance metric trace collection execution trace data application intel processor trace PT specifically trace instruction application steady user kernel mode instruction intel PT allows capture application percentage kernel mode instruction induced cache however drupal mediawiki wordpress kernel code responsible cache simulation  processor propose invalidate instruction future intel processor functionally equivalent  instruction simulate invalidate instruction evaluate ripple simulation allows evaluate additional replacement policy interaction ripple extend zsim simulator implement propose invalidate instruction important parameter trace II simulator parameter parameter cpu intel xeon haswell core per socket instruction cache KiB data cache KiB unified cache MB unified cache MiB per socket core turbo frequency ghz cache latency cycle cache latency cycle cache latency cycle cache latency cycle memory latency cycle memory bandwidth GB driven zsim simulation II implement ripple cache data application input  data application described II evaluate ripple application input parameter client load generator request per thread evaluate ripple input training profile collection evaluation evaluate ripple performance metric data application described sec II speedup ripple ideal prior cache replacement policy cache MPKI reduction ripple ideal policy prefetching configuration evaluate ripple replacement coverage  described sec extra static dynamic instruction ripple introduces application binary finally evaluate ripple performs across multiple application input speedup speedup percentage improvement instruction per cycle ipc ripple lru baseline ripple speedup speedup prefetch aware ideal replacement policy additional prior cache replacement policy hawkeye harmony DRRIP SRRIP GHRP detail II ripple speedup primarily due underlie hardware replacement policy ripple speedup underlie hardware replacement policy random lru finally speedup replacement policy alter underlie cache prefetching mechanism prefetching nlp FDIP speedup ripple underlie lru hardware replacement policy ripple lru outperforms prior replacement policy across prefetcher configuration ripple lru average prefetching nlp FDIP speedup pure lru replacement policy baseline speedup correspond prefetching nlp FDIP speedup ideal cache replacement policy notably ripple random operates underlie random hardware replacement policy average lru average speedup lru baseline across cache prefetchers combination ripple random becomes feasible replacement policy eliminates meta data storage overhead hardware performance gap ripple ideal cache replacement policy stem primary ripple cannot eviction via software invalidation eviction ripple sacrifice eviction accuracy hurt performance software invalidation instruction insert ripple introduce static dynamic code bloat additional cache pressure contributes performance gap quantify overhead later cache MPKI reduction cache reduction ripple underlie hardware replacement policy lru random prior policy ripple lru reduces cache prior policy across application across prefetching configuration ripple avoid prefetching nlp FDIP cache avoid ideal replacement policy ripple reduces cache MPKI regardless underlie replacement policy underlie replacement policy random average lru ripple random incurs average lru application prefetching configuration replacement coverage described ripple coverage percentage replacement decision program initiate ripple invalidation ripple coverage application ripple achieves average coverage  application drupal mediawiki wordpress ripple coverage application ripple insert invalidate instruction compile jit compile code reuse instruction address execution render compile instruction injection technique challenge nevertheless jit application remains static code ripple optimize accuracy ripple replacement accuracy define ripple achieves accuracy average minimum improvement ripple accuracy average lru average accuracy thanks accuracy ripple avoids inaccurate replacement decision due underlie  hardware replacement policy average accuracy therefore overall replacement accuracy ripple lru average lru baseline instruction overhead quantify static dynamic code footprint increase introduce inject invalidate instruction static instruction overhead ripple dynamic instruction overhead verilator cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg speedup hawkeye random DRRIP GHRP SRRIP ripple random ripple lru ideal prefetching baseline ripple speedup ideal speedup average cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg speedup harmony random GHRP DRRIP SRRIP ripple random ripple lru ideal prefetching baseline ripple speedup ideal speedup average cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg speedup harmony random DRRIP GHRP SRRIP ripple random ripple lru ideal fetch instruction prefetching baseline ripple speedup ideal speedup average ripple speedup ideal replacement policy lru baseline hardware prefetching average ripple speedup ideal speedup application ripple executes extra instruction invalidate cache verilator ripple almost replacement policy decision via software invalidation coverage similarly ripple accuracy verilator therefore ripple executes relatively invalidation instruction verilator execute unnecessary invalidation instruction profile offline analysis overhead ripple leverage intel PT trace data application execution overhead adoption production setting ripple extraction analysis trace longer expensive analysis deployed production server instead anticipate extraction analysis invalidation injection component ripple perform offline exist profile optimization data application perform therefore overhead ripple offline analysis acceptable invalidation reduce lru priority underlie hardware cache replacement policy lru cache lru chain sufficient eviction lru specific optimization improve ripple ipc speedup apart verilator application benefit optimization ripple profile mechanism independent eviction mechanism performance across multiple application input investigate ripple performance data application cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg MPKI reduction hawkeye random DRRIP GHRP SRRIP ripple random ripple lru ideal prefetching ripple lru reduces cache reduction ideal replacement policy cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg MPKI reduction harmony random DRRIP GHRP SRRIP ripple random ripple lru ideal prefetching ripple lru reduces average cache reduction ideal replacement policy cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg MPKI reduction random harmony DRRIP GHRP SRRIP ripple random ripple lru ideal fetch instruction prefetching ripple lru reduces average cache reduction ideal replacement policy ripple cache reduction ideal replacement policy lru baseline hardware prefetching average ripple reduces lru cache reduction ideal replacement policy cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg coverage ripple coverage application average replacement request evict cache ripple invalidates input configuration application input configuration webpage client request client request per server thread random input data optimize application profile input ripple performance benefit input input performance improvement ripple optimizes application profile input ripple ipc gain  profile profile input specific cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg accuracy lru ripple overall ripple accuracy application average ripple accuracy ensures overall accuracy underlie lru accuracy cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg instruction overhead static instruction overhead introduce ripple average ripple insert static instruction brevity FDIP baseline prefetching baseline discussion ripple generates optimize binary target architecture processor cache associativity data deploy profile link optimization technique therefore ripple conveniently integrate exist optimization moreover cache KB associativity intel data processor stable target architecture ripple VI related instruction prefetching hardware instruction prefetchers decouple fetch prefetchers pervasively deployed commercial complex technique employ replay prefetchers highly effective reduce cache impractical chip metadata storage predictor prefetchers principle FDIP reduce chip metadata storage however overhaul underlie target prediction recent proposal instruction prefetching championship ipc cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress avg instruction overhead dynamic instruction overhead introduce ripple average ripple executes extra dynamic instruction optimal policy performance profile training input profile input cassandra drupal finagle chirper finagle http kafka mediawiki tomcat verilator wordpress ripple performance multiple application input FDIP baseline average ripple speedup input specific profile profile input kilobyte extra chip storage  performance workload FDIP fetch target queue potential performance benefit hybrid hardware software prefetchers analyze program information software inject dedicate prefetching instruction code exist hardware contrast instruction prefetchers alone performance gap due wasteful eviction handle smarter cache replacement cache replacement policy heuristic hardware data cache replacement policy lru variation  reference interval prediction reuse prediction others learningbased data cache replacement policy replacement binary classification cache friendly cache averse recent introduce machine technique perceptrons genetic algorithm policy information  optimal hawkeye glider parrot however policy mostly data cache instruction cache earlier sec II propose profile approach policy prefetch aware replacement policy prefetch aware replacement policy focus avoid cache pollution inaccurate prefetches prefetch aware policy feedback prefetchers identify inaccurate prefetches prefetcher modification others independently prefetcher estimate prefetch accuracy cache behavior prefetching  optimal policy becomes incomplete cannot distinguish easy prefetch cache prefetch cache address limitation demand min revise  optimal policy accommodate prefetching propose program counter PC classification predictor harmony emulate ideal performance revise  extra  predictor performs poorly cache address imprecision effectively emulate optimal cache behavior via profile software technique vii conclusion data application instruction footprint significant cache although numerous prior proposal aim mitigate cache ideal cache investigate exist cache mitigation mechanism achieve sub optimal speedup widely instruction prefetchers incur wasteful prefetch induced eviction exist replacement policy mitigate enable smarter eviction propose ripple novel profile replacement technique program context inform underlie replacement policy efficient replacement decision ripple identifies program context cache  injects cache eviction instruction suitable program location link evaluate ripple popular data application demonstrate replacement policy agnostic enables replacement policy achieve speedup closer ideal cache