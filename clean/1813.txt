capacity offload data task network become increasingly important faster growth network cpu frequency network compute alleviates host cpu load task directly network enable additional computation communication overlap potentially improve overall application performance however sustain bandwidth generation network gbit become challenge spin program model NIC compute user specify handler function execute NIC incoming packet belonging message enables cuda acceleration NIC equip lightweight processing network packet parallel investigate architectural specialty spin NIC enable performance flexible packet processing introduce PsPIN source spin implementation multi cluster RISC architecture accord identify architectural specialty investigate performance PsPIN cycle accurate simulation packet gbit introduce minimal latency packet occupy  index network compute packet processing specialized architecture spin motivation performance datacenters crucial pillar compute infrastructure unprecedented core collection machine network  per internal external traffic emerge online service video communication online collaboration increase incoming outgo traffic volume furthermore deployment specialized accelerator trend towards disaggregation exacerbates quickly network load packet processing capability performance target datacenters requirement modernization datacenter network bandwidth technology gbit gain adoption endpoint tune reduce packet processing overhead specifically remote memory access RDMA network packet protocol processing fixedfunction hardware network directly access data user memory greatly reduces packet processing overhead cpu incoming data flurry specialized technology exists additional processing network FPGAs virtualization rewrite trigger operation processing network spin defines unified program model architecture network acceleration beyond RDMA user interface cuda compute acceleration specialty constraint latency rate packet processing defines flexible programmable network instruction architecture  lower barrier entry demonstrate speedup serialization deserialization marshal non consecutive data  define spin implement exist  microarchitecture standard socs optimize packet processing task define source performance microarchitecture spin network interface NICs develop principle NIC microarchitectures enable flexible packet processing gbit rate core contribution establish principle flexible programmable  packet processing microarchitectures implement fully functional core soc packet processing NIC pipeline analyze latency message rate bandwidth processing handler source soc benefit community implement PsPIN synthesizable hardware description hdl code overall occupies  intel skylake xeon network compute task PsPIN achieve throughput complex architecture xeon UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca azure  fpga NICs steer  packet steer rewrite  memory NICs switch mellanox data aggregation reduction switch portal  sequence predefined action express trigger operation target NICs mellanox core sequence predefined action chain target switch cray  reduction data reduction byte switch quadric  user define thread NIC NIC programmable user  linux stack NIC offload code flash fpga packet parse pipeline packet parse packet fpga reconfiguration target NICs eBPF host user define code eBPF code virtual machine OS kernel eBPF   eBPF program offload NIC dpdk user application poll raw packet NIC  handler dma implement fpga NIC  bind kernel NIC accelerator user socket panic application compose execution pre instal compute target NICs spin application define packet handler message target NICs location    outside packet pipeline host cpu programmability fully programmable limited programmability predefined FUNCTIONS granularity message    usability usable APPLICATIONS privileged  privileged  II network compute network compute capability interconnection network steer data accord programmable action definition action depends specific network compute pre define action pas packet accord fully programmable packet message handler spin handler advantage compute network overlap application define action execute incoming data network execute allows application overlap task useful latency network promptly react incoming data portal trigger operation virtual function spin handler immediately execute action host application poll data dependent action execute throughput  enable processing incoming data spin packet handler incoming packet potentially improve overall throughput resource contention task network reduce volume data pcie bus memory hierarchy implies data movement memory contention cache pollution potentially improve performance host cpu task survey exist network compute classification focus characteristic location policy programmability granularity action apply usability location policy execute along endpoint data endpoint classify network compute network device NICs switch network device packet pipeline  network endpoint linux stack host CPUs programmability defines expressiveness action network enable fully programmable action access message packet header payload access NIC host memory issue network operation RDMA marked predefined action compose action portal trigger operation marked predefined function marked granularity action apply message fully message packet enable action marked usability defines entity install action network network compute enable user application library multi tenant setting install action marked elevate privilege service disruption device memory flash install action marked spin user application define per message per packet task handler execute NIC spin handler access modify packet data NIC memory issue NIC dma command handler instal NIC without disrupt operation memory isolation guaranteed focus spin program model investigate challenge building spin introduce PsPIN source spin implementation  hardware PsPIN permissive source license  encourage usage foster creation prototype anyone community spin processing network spin extend RDMA enable user define processing task handler execute directly NIC message NIC memory HPU HPU HPU dma packet scheduler interconnect HPU spin NIC packet network header payload completion host memory host CPUs upload handler manage memory spin abstract machine model network sequence packet packet define header completion intermediate payload packet message destination NIC invokes respective packet handler message handler define header handler execute header packet payload handler execute packet completion handler execute packet handler define application host compile NIC microarchitecture program model spin proposes cuda OpenCL difference framework application define kernel offload gpus spin kernel handler offload NIC execution trigger arrival packet sketch spin abstract machine model host application define packet handler associate message descriptor packet handler optional specify header completion handler payload handler packet handler message execute message descriptor packet handler instal NIC incoming packet message descriptor handler execute handler processing HPUs handler issue NIC command dma transfer host memory architectural specialty spin abstract machine model specifies execution model microarchitectural requirement classical specialized packet processing normally constraint action perform entity program traditional compute core outline architectural spin implementation enable fully programmable performance packet processing highly parallel payload packet parallel HPUs longer handler without become bottleneck schedule packet schedule HPU core maintain requirement mandate header handler execute payload handler execute completion handler explicit memory access packet processing temporal locality definition packet hence scratchpad memory cache local handler handler across packet message multiple message memory partition schedule ensure reachable addressable latency throughput minimize packet NIC packet spin handler execute minimize furthermore spin obstruct rate efficiency easy integration spin broader NIC architecture handler isolation handler processing message access memory belonging message belong application configurability spin easily reconfigurable network requirement  PsPIN spin implementation architecture specialty II PsPIN pulp parallel ultra platform  architectural template scalable efficient processing pulp implement riscv ISA organizes processing cluster cluster fix core issue cycle accessible scratchpad memory remove cluster implement hardware component PsPIN synthesizable hardware description hdl code architecture overview PsPIN modular architecture HPUs grouped processing cluster HPUs implement RISC core cluster equip  access scratchpad memory memory cluster interconnect HPUs access data remote cluster memory packet buffer handler memory program memory overview PsPIN integrates generic NIC model architecture adopt generic NIC model identify building NIC architecture later discus PsPIN integrate exist NIC architecture inbound outbound network interface host interface PsPIN command program memory handler memory packet buffer dma cluster packet scheduler command monitoring TCDM dma  cluster TCDM dma  cluster TCDM dma  cluster TCDM dma  cluster NIC model PsPIN architecture overview host application access program handler memory offload handler code data respectively management memory NIC driver expose interface application code data toolchain NIC driver extension offload handler code data scope code data handler offload host execution context contains pointer handler function header payload completion handler pointer allocate handler memory information packet accord execution context execution context offload NIC NIC inbound packet PsPIN data data NIC inbound normally interfaced host copying host memory PsPIN NIC inbound interfaced PsPIN inbound distinguish packet PsPIN classical non processing distinction packet PsPIN execution context packet PsPIN otherwise packet host normal network already concept packet RDMA NICs packet queue others concept introduce enable packet processing packet NIC packet buffer NIC inbound sends handler execution request PsPIN packet scheduler contains information schedule handler packet pointer packet packet buffer execution context packet buffer NIC inbound pressure sender explicit congestion notification packet connection policy adopt depends network PsPIN integrate choice host cannot consume incoming packet packet scheduler selects processing cluster packet cluster local scheduler  dma packet packet buffer tightly couple data memory TCDM idle HPU handler packet available packet processing completes notification NIC update packet buffer pointer packet buffer manage buffer data packet handler addition processing packet data data network data host memory data directly NIC spin api RDMA operation handler issue operation PsPIN runtime translates NIC command NIC outbound NIC outbound cannot command handler become available NIC outbound data packet memory handler memory memory specify host memory address data source behaving host issue command data host handler issue dma operation operation translate command cluster dma writes data host memory pcie task dispatcher command task task completion notification cmd resp cmd resp cmd resp cmd resp MPQ completion notification  cluster HPUs cluster HPUs cluster HPUs cluster HPUs packet scheduler dma cluster dma cluster NIC outbound NIC inbound PsPIN overview PsPIN  NIC inbound schedule packet handle command handler completion notification NIC inter cluster packet schedule PsPIN inform packet  NIC inbound packet scheduler compose message processing queue MPQ task dispatcher MPQ handle schedule dependency packet dependency define spin program model header handler execute packet message payload handler completion completion handler execute packet message payload handler message sequence packet mapped MPQ execution context NIC define packet message packet message arrives NIC correspond message flag PsPIN completion handler handler MPQ task dispatcher task dispatcher selects processing cluster task execution introduce dedicate hardware dispatch packet cluster software bandwidth schedule packet rate target bandwidth gbit packet packet schedule packet cycle average cluster accept task packet data message ID cluster message task dispatcher schedule packet cluster cluster cannot accept load cluster task dispatcher available cluster data byte cycle core latency byte  gbit core throughput local load dma remote load cycle load cycle cycle cycle cycle gbit dma gbit remote access gbit gbit gbit data latency bandwidth rationale concept cluster handler processing packet message memory hence schedule cluster avoids remote access memory latency bandwidth experienced core copying data local remote memory access load dma core execute memory access latency access chunk data increase linearly dma data burst multiple flight concurrently handler execution completion notification within processing cluster task execution request handle cluster local scheduler detail intra cluster handler schedule execution handler issue command handle command define command interact NIC outbound cluster dma NIC command data network handler packet generate dma command data host memory host virtual address application define data structure handler memory  command dma command instead source address immediate data directly host memory address command response inform handler completion issue command error handler terminates flight command response pending completion notification generate MPQ notification message queue queue header handler completes notification NIC inbound packet buffer  dma HPU driver HPU driver TCDM MiB interleave packet buffer KiB runtime KiB scratchpad KiB HPU driver RISC HPU RISC HPU RISC HPU TCDM interconnect fifo task task dispatcher command response command completion notification MPQ command command RR arbiter RR arbiter PsPIN processing cluster intra cluster handler schedule task cluster local scheduler  schedule HPUs task dma transfer packet data packet data enables cycle access core transfer completes correspond task popped queue schedule idle HPU gbit cluster receives task packet average budget sufficient handle intra cluster schedule software comparison issue dma command already cycle furthermore schedule algorithm HPUs cooperative schedule approach privilege mode guarantee handler isolation additional overhead hence opt hardware intra cluster scheduler lighter runtime HPUs HPUs interfaced memory mapped device HPU driver information task execute PsPIN runtime HPU consists loop execute handler function pointer HPU driver HPU driver task handler execute HPUs gate task arrives HPU enable load completes handler argument packet memory pointer handler function doorbell memory location HPU driver inform handler execution HPU driver sends completion notification detects flight command issue task HPU driver buffer task completion notification cannot processing multiple HPU driver feedback issue command robin arbiter cycle HPU feedback issue command overview PsPIN processing cluster connection relevant schedule handle handler command reality HPUs interfaced cluster dma issue arbitrary dma transfer accessible handler memory memory access protection handler processing packet execution context handler memory allocate application define execution context additionally message statically allocate scratchpad cluster memory MiB configuration packet buffer KiB runtime data structure HPU stack KiB message scratchpad KiB scratchpad allocate NIC driver associate execution context illegal memory access guarantee handler isolation HPU driver configures RISC physical memory protection PMP task core access subset address handler code packet memory scratchpad handler user mode memory access violation exception interrupt generate handle PsPIN runtime exception handle consists reset environment stack pointer handler execution inform HPU driver error HPU driver command  error execution context descriptor host memory fail handler release occupy resource monitoring processing packet NIC scenario prevent ensure operation packet message message due packet byte max handler handler duration throughput gbit gbit gbit gbit gbit cycle 1GHz relation handler execution rate factor network failure network congestion bug application protocol handler cannot packet rate detect pseudo lru active   packet MPQ access packet lru candidate victim packet threshold specify execution context message activate MPQ reset signal host execution context descriptor detect HPU driver watchdog timer generates interrupt HPU runtime reset timer configure accord threshold specify execution context NIC driver application handle similarly memory access violation notify host error execution context descriptor understand budget available handler relation handler execution rate assume PsPIN configuration HPUs maximum duration handler packet rate packet gbit gbit network processing throughput affected handler duration packet network data discus data within PsPIN explain choice guarantee optimal bandwidth equip PsPIN interconnects NIC host interconnect interface NIC host PsPIN memory dma interconnect interface  dma packet buffer handler memory processing PE interconnect allows HPUs memory remote NIC host dma interconnect data PE interconnect finer granularity access PsPIN clocked ghz bandwidth interconnects gbit gbit respectively PsPIN chip interconnects memory controller dma overview PsPIN memory interconnects data interfaced within PsPIN identify critical data bandwidth obstruct rate optimize PsPIN data achieve goal NIC inbound packet buffer cluster NIC inbound writes packet packet buffer rate data processing cluster dma cluster cluster cluster cluster program memory handler memory packet memory NIC outbound NIC inbound dma cluster host mst  host mux IOMMU host   mux mux mux dma interconnect  interconnect PE interconnect axi axi dma TCDM dma TCDM dma TCDM dma TCDM PsPIN data overview bold arrow axi connection data width arrow axi connection arrow axi handler bottleneck data packet buffer access direction host memory assume handler data host steady data towards host memory data source specify command issue handler packet buffer handler memory cluster data cluster dma interface IOMMU translate virtual address specify handler command physical IOMMU update NIC driver host register memory access NIC NIC outbound data towards NIC outbound assume NIC outbound dma data identify critical involve packet buffer avoid bottleneck memory bandwidth NIC inbound  dma plus bandwidth compose NIC outbound cluster dma gbit bandwidth load achieve goal implement packet buffer MiB  duplex multi interleave memory packet buffer suitable access load access HPUs handler frequently access packet execution context configure PsPIN packet handler maximum bandwidth packet buffer sustain gbit per duplex bandwidth achieve conflict packet buffer accessible NIC host interconnect NIC inbound NIC inbound hence bandwidth NIC host interconnect access packet buffer namely NIC outbound cluster dma bandwidth dma PE interconnects configuration allows maximum rate gbit PsPIN suitable gbit network handler program memory handler memory bandwidth critical packet buffer important configuration handler memory MiB spin program model allows host access memory NIC data handler data message fully host application allocate memory memory NIC driver manages allocation host data handler memory packet trigger handler memory information mpi datatypes deploy handler packet accord memory layout described handler memory differently packet buffer foresee handler memory target frequently HPUs access hence adopt reduce probability conflict similarly packet buffer handler memory involve maximum bandwidth gbit per duplex program memory KiB handler code access host offload code PE interconnect refill per cluster KiB instruction cache memory critical implement  duplex gbit bandwidth per cluster instruction cache associative concept cluster schedule packet message handler code cluster reduce instruction cache pollution NIC integration described PsPIN within context NIC model integrate PsPIN exist network identify NIC capability integrate PsPIN others optional richer handler semantic capability message packet handler define per message receiver NIC packet message identify handler execute explicitly define message depends network PsPIN integrate PsPIN message sequence packet target message processing queue MPQ feedback channel NIC inbound communicate MPQ becomes idle remapped NIC define message header packet PsPIN information characterize message requirement relaxed packet information identify message tcp udp NICs additional capability extend functionality handler access application assumption network behavior application query NIC capability potentially handler available capability capability reliability reliable network layer PsPIN guaranteed packet message duplicate packet capability application employ non idempotent handler otherwise handler account execute packet action NICs action abstraction ideal candidate PsPIN integration abstraction user install packet parse specific action integrate PsPIN action available packet PsPIN execution context associate action entry enables application define concept message flexibility application define tcp IP tcp header udp packet target specific affected  define programmed application http multiplex multiple within tcp connection define PsPIN message http header similarly transport protocol quic PsPIN message connection RDMA capable network remote memory access RDMA network application expose memory network enable remote access reading data RDMA application register memory NIC IOMMU translate virtual physical address whenever remote perform operation specify target memory data memory location directly specify target virtual memory address request indirectly indirect application register memory specifies descriptor incoming remote memory access request portal descriptor entry entry accord associate RDMA NICs already perform packet NIC NIC virtual address request physical address indirect NIC packet descriptor derive target memory location hence message capability attach PsPIN handler II report RDMA capable network PsPIN handler attach associate handler infiniband queue packet target queue PsPIN capability header infiniband delivery network already network cannot guarantee NIC buffer discard payload network interface handler descriptor infiniband   queue bull  cray  portal entry cray gemini cray    memory handle II RDMA NETWORKS spin  attach  packet header packet RDMA capable network already implement reliability network layer hence application adopt non idempotent handler NIC driver expose packet processing functionality NIC driver implement spin interface described driver manages NIC memory application allocate memory data handler memory code program memory PsPIN involve application memory management delegate software layer detailed description NIC driver scope exception PsPIN deadlock processing cluster accept task task dispatcher queue become available backpressure towards NIC inbound cannot deadlock processing cluster dependent  header payload dependency payload handler header guaranteed header already header requisite schedule guaranteed MPQ per message basis badly handler deadlock HPU driver watchdog trigger handler termination message fully deliver completion feedback trigger resource message MPQ freed PsPIN detect resource release encrypt traffic handle handler responsible decryption incoming data foresee possibility user handler library function crypto primitive modular PsPIN per cluster crypto deployed enable hardware accelerate crypto primitive aes ebc crypto pulp hence PsPIN compatible already exist evaluation future IV evaluation evaluation aim PsPIN synthesis HPUs PsPIN sustain rate choice implement spin RISC architecture  memory hierarchy offs complex architecture spin simulation environment simulate PsPIN cycleaccurate testbench comprise  module synthesizable module PsPIN component develop simulation module model NIC inbound outbound inbound trace packet input injects PsPIN rate outbound data PsPIN accord command generate memory pressure host interface emulate pcie model pcie lane implement fix rate data sink unless otherwise specify limit packet generator injection rate maximum throughput PsPIN packet handler compile pulp sdk contains extend version gcc riscv handler compile optimization  hardware synthesis synthesize PsPIN  fully deplete silicon   technology synopsys  timing ghz employ  memory compiler generate SRAM macro tailor architectural requirement measurement summarize memory entire accelerator complexity  overall cluster memory intra cluster scheduler occupy memory inter cluster scheduler inter cluster interconnect memory controller another memory macro occupy NIC architecture PsPIN integrate packet buffer mapped NIC packet buffer memory cluster dominate memory macro per cluster instruction cache cluster interconnect complexity kGE per cluster corresponds placement density core complexity kGE corresponds cluster architecture comparison infer mellanox  soc core occupy component perc perc PsPIN memory interconnect cluster core instr cache interconnect    relative component derive upper bound consumption architecture assume toggle rate logic activity memory macro overall envelope gate equivalent GE GF  dynamic cluster consume within cluster memory consumes memory consumes inter cluster scheduler consumes inter cluster interconnect memory controller consume architecture HPUs normalize HPUs microbenchmarks investigate performance characteristic PsPIN discus latency experienced packet PsPIN maximum packet processing throughput PsPIN achieve complexity packet handler affect packet latency define packet latency elapses PsPIN receives NIC inbound completion notification packet NIC inbound packet packet buffer measurement  cycle accurate simulation overall latency packet task execution request cluster local scheduler  packet cluster cluster local dma transfer latency packet packet data task assign HPU driver cycle HPU runtime invoke handler reading handler function pointer handler argument handler completes runtime cycle HPU driver inform completion completion notification NIC inbound delayed additional robin arbiter prioritize HPUs cluster respectively packet processing throughput critical data PsPIN inbound data NIC inbound packet memory memory processing cluster packet assign packet data memory handler packet header filter packet header plus packet payload handler  header packet data packet counting application specify byte handler packet data PsPIN outbound interface namely NIC outbound outbound NIC host interface pcie outbound host generate handler issue command data NIC host handler necessarily issue command directly consume data communicate instruction handler throughput gbit handler complexity instruction handler max HPUs utilization theoretical misalign PsPIN maximum throughput host message processing handler perform data reduction NIC completion handler data host inbound throughput PsPIN sustain inbound function frequency completion notification MPQ packet throughput handler execute instruction xaxis packet packet maximum throughput PsPIN achieve minimum interconnect bandwidth cumulative bandwidth HPUs execute instruction throughput misalign packet packet byte handler execute integer arithmetic instruction cycle axis handler duration nanosecond data PsPIN schedule align packet maximum available bandwidth HPU runtime introduces minimum overhead cycle per packet IV maximum HPUs utilized handler execute instruction packet PsPIN schedule packet per cycle empty handler HPUs overhead invoke handler packet budget increase handler instruction packet throughput HPU inbound outbound throughput packet PsPIN execution context configure packet outbound NIC develop handler perform udp ping pong swap source destination IPs udp issue NIC command network overall handler consists instruction swap issue command handler outbound host issue dma command packet host without modify packet packet buffer packet  gbit outbound NIC packet  gbit outbound host data data data data data PsPIN packet buffer optimize access perform dma involve TCDM filter histogram  reduce stride ddt gbit aggregate handler throughput PsPIN packet optimize access HPUs organize difference throughput conflict data packet outbound hardly gbit reading gbit reading data packet budget bandwidth handler characterization evaluate performance PsPIN realistic packet handler packet steer message processing throughput achieve PsPIN  throughput achievable PsPIN RISC achieve complex powerful architecture comparison aim analyze benefit employ complex architecture packet processing motivate choice employ RISC core HPUs simulate network zero inter packet delay network bound maximum achievable throughput data reduction reduce data multiple message core operation collective reduction accumulation message data item operation computes array entry entry reduction data item across message benchmark instance reduce packet integer payload handler accumulate data sum operator completion handler informs host available host command data aggregation utilized data mining application operation consists accumulate data item message benchmark aggregate MiB message integer sum completion handler aggregate host memory packet filter rewrite typical intrusion detection traffic monitoring packet sniff packet query application define hash source IP address udp destination overwritten host memory benchmark filter message hash entry cache  cache NIC cache implement  cache limit access maintain cache eviction victim chosen within aggregate filter histogram  reduce stride ddt gbit  throughput aggregate filter histogram  reduce stride ddt gbit   throughput PsPIN zynq ault per core handler throughput RISC generate ycsb workload request ratio cache associativity entry integer modulo scatter stride ddt model data transfer destination memory accord  memory layout benchmark sends MiB message host memory byte stride byte layout description stride histogram message summarizes data item application distribute algorithm instance message integer randomly generate interval handler data item per finally histogram host handler throughput throughput achieve handler PsPIN packet PsPIN achieves gbit filter  stride ddt already packet handler compute intensive packet nonetheless PsPIN achieves gbit network packet thanks modularity architecture scenario gbit sustain workload satisfied processing cluster RISC outline benefit adopt RISC architecture powerful complex representative architecture cpu memory subsystem configuration cache scratchpad ault core smt superscalar oforder execution intel skylake xeon ghz zynq xilinx zynq  MPSoC feature quad core cortex superscalar ghz architecture develop benchmark load predefined packet memory spawn worker thread statically assigns packet worker ideal dpdk execution packet already memory worker dpdk related overhead polling device copying burst local buffer otherwise specify packet KiB per core throughput architecture compute function median handler completion worker aggregate filter histogram  reduce stride ddt ault zynq PsPIN ault zynq PsPIN ault zynq PsPIN ault zynq PsPIN ault zynq PsPIN ault zynq PsPIN instruction mip cache thread thread handler performance architecture zynq ault worker thread upper whisker boxplot iqr iqr quartile iqr inter quartile respectively thread available core despite comparison  PsPIN potentially memory contention core PsPIN per core throughput competitor histogram  reduce memory bound workload powerful core ault zynq outperform PsPIN aggregate filter stride ddt however per core throughput without factor architecture ault PsPIN IV summarizes estimate per processing PE per processing PE production amount memory per PE report throughput normalize architecture PsPIN efficient zynq minimum stride ddt efficient ault minimum filter workload conclude powerful architecture achieve raw throughput compute intensive workload PsPIN efficiency sustain rate fully offload packet processing NIC cpu resource arch tech PEs memory PE PE ault MiB zynq MiB PsPIN MiB IV architectural CHARACTERISTICS PE processing gain insight performance characteristic handler performance metric architecture report handler execution execute instruction mips instruction per cache PsPIN access remote ault zynq performance cpu hardware counter resource contention worker thread contention worker parallel PsPIN contention architecture filter computes hash function byte compute intensive task allows ault handler faster PsPIN workload mainly execute arithmetic instruction aggregate filter frequently access packet memory stride ddt ault outperforms zynq PsPIN completion ault compiler optimizes aggregate simd packed integer instruction however difference account occupy architecture PsPIN simpler architecture ault zynq competes overall execution due comparable rate execute instruction per mips influence rate ault zynq histogram  reduce PsPIN packet directly cluster handler execute enable cycle access PsPIN hardware cache hence suffer cache ping pong scenario architecture histogram reduce RISC amos enable cycle atomic operation instruction implementation link load conditional reduce histogram discussion future PsPIN configuration analysis aim sustain gbit rate PsPIN sustain bandwidth memory interconnects core affect identify memory packet buffer depends network bandwidth packet PsPIN packet latency handler memory depends specific handler offload network bandwidth min max geomean gbit core gbit core gbit core  KiB pkt  KiB pkt  pkt packet KiB packet latency packet buffer packet latency rate horizontal min geometric max handler handler critical  handler bottleneck packet rate core combination packet buffer packet latency axis rate gbit gbit gbit packet latency packet arrives PsPIN freed packet buffer IV schedule handler processing packet packet simplicity account schedule latency discussion handler execution minimum maximum geometric handler IV gbit network packet latency packet buffer capacity KiB currently PsPIN MiB packet buffer sustain rate packet latency moreover account handler terminate within threshold bottleneck incoming data constrain packet buffer plot handler critical  threshold handler become bottleneck combination packet rate core  compute core rate  packet IV memory portion memory configuration partially independent network bandwidth handler memory partially provision packet buffer remain stable PsPIN sustain rate modular organization PsPIN allows processing cluster enable workload longer handler without become bottleneck however increase sustain network bandwidth balance processing cluster rate sustain  adopt data multiple PsPIN accelerator additional schedule future investigate integration snitch core cluster PsPIN simpler RISC core flexible cluster architecture virtual memory integration improve efficiency increase flexibility propose network compute accelerator additionally research aim evaluate benefit PsPIN integrate network switch enable packet processing deeper network VI related concept related PsPIN active message however model message atomic fully spin processing happens packet latency buffer requirement spin closely related user define action per packet basis switch architecture amt    architecture target switch packet header packet data  extends introduce modifiable memory enable grain steer dma receiver NIC extension partition steer request specific core however offload complex  task datatype processing demonstrate program model contrast PsPIN allows offload arbitrary function execute generalpurpose processing core hardware extension increase throughput reduce latency panic recent principle PsPIN difference PsPIN allows application define handler execute incoming packet panic enables express composition pre offload task programmable NICs quadric  employ accelerate collective implement version portal  NICs user offload module specialized NIC core approach NIC offload network engineer implement functionality fpga module PsPIN easy program RISC core differently approach spin enables user application define packet handler vii CONCLUSIONS processing data network application along network defines principle architectural characteristic packet processing RDMA acceleration propose PsPIN efficient RISC implement spin program model define interface NIC integration evaluate PsPIN packet gbit rate motivate architectural choice performance handler architecture PsPIN source project available