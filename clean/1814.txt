graphic processing gpus ubiquitous component across compute platform phone tablet personal computer server platform increase importance graphic video workload recent processor gpu device integrate chip integrate gpus resource cpu potential microarchitectural attack gpu cpu vice versa potential covert channel attack arise microarchitectural component cache contention domain bus illustrate channel develop reliable covert channel attack covert channel llc cache intel integrate gpu architecture contention channel target bus cpu gpu llc demonstrate microarchitectural attack component boundary gpu cpu vice versa component channel introduce challenge overcome across heterogeneous component computation model interconnect asymmetric memory hierarchy exploit gpu parallelism increase bandwidth communication without rely llc channel achieves bandwidth kbps error rate contention channel delivers kbps error rate demonstrate  concept prime probe channel attack probe llc gpu introduction recent micro architectural covert channel attack widely CPUs exploit optimization technique structure exfiltrate sensitive information  exploit cpu structure examine channel variety contention domain cache predictor random generator others compute increasingly heterogeneous consist federation cpu gpus NPUs specialized accelerator memory storage component interconnect essential understand micro architectural attack manifest within complex environment beyond cpu demonstrate covert channel attack cpu integrate gpu although covert channel demonstrate variety cpu structure discrete gpus attack significantly prior across heterogeneous component specifically knowledge prior demonstrate covert channel symmetric sender receiver identical typically thread access resource contention contrast component attack entity substantially computational model asymmetric resource attack necessitate careful reverse engineering asymmetric resource arise due asymmetry resource moreover attack demonstrate heterogeneous environment important insight threat model manifest extend understand threat model research defense  integrate cpu resource cache memory subsystem integration creates potential attack exploit resource interference component component microarchitectural attack specifically develop covert channel secret communication channel exploit contention integrate heterogeneous malicious application component cpu  transfer secret information via hardware resource II overview integrate cpu gpu architecture threat model demonstrate vulnerability widely microarchitectural attack UI OOVBM  PNQVUFS SDIJUFDUVSF acm annual international symposium computer architecture isca doi isca component attack due asymmetric communication cpu gpu memory hierarchy synchronization across heterogeneous component frequency disparity reconcile computational model memory hierarchy reliable finegrained timing mechanism demonstrate possibility dangerous channel attack attack concrete component attack heterogeneous expand understand microarchitectural attack mitigation strategy possibility covert channel component contention directly microarchitecture resource integrate cpu gpu cache llc serf channel contention multiplexed resource bus cache computational resource resource component resource perceive delay request contend limited resource illustrate channel building covert channel attack bus interconnect cpu gpu llc cache construct covert channel attack prime probe covert channel attack llc contention covert channel contention bus llc IV attack unique challenge arise due asymmetric channel memory hierarchy critical implication successful attack llc channel achieves bandwidth kbps error rate bus channel achieves bandwidth kbps error rate demonstrate prime probe channel attack gpu spy llc access generate cpu discus potential mitigation vii related attack summary contribution attack span component within heterogeneous challenge arise  attack due asymmetry communication attack cycle computational model cycle reverse engineering understand asymmetric memory hierarchy others issue generalize beyond specific environment characterize covert channel attack integrate cpu gpu proof concept prime probe channel attack gpu spy cache activity cpu IX discus future research conclude remark II background threat model introduce organization intel integrate gpu background understand attack threat model outline assumption attacker capability intel integrate cpu gpu traditionally discrete gpus pcie bus access physical memory therefore memory hierarchy cpu however intel  intel CPUs integrate gpus  incorporate cpu increasingly multimedia workload without bulky expensive hungry gpu gpu continued evolve generation performance feature iris plus gen intel graphic technology execution cuda core nvidia terminology  gpu performance purpose compute integrate gpus programmer OpenCL equivalent cuda program model nvidia discrete gpus application programmer launch thread grouped thread nvidia terminology thread execute instruction multiple data simd style lock manner wavefront analogous warp nvidia terminology integrate gpus simd width variable register requirement kernel  reside chip memory hierarchy cpu typically llc architecture intel soc processor integrate cpu core   CPUs interconnect byte bidirectional data bus gpu cache llc cpu serf gpus cache hierarchy gpu intel soc architecture intel integrate gpu architecture cpu access llc simultaneously however impact access latency due factor delay access bus access limitation llc characterize contention behavior IV gpu cpu component display controller pcie controller optional eDRAM controller memory controller architecture   analogous cuda core consolidated  SM nvidia terminology typically  slice slice varies soc model within generation slice modular fashion gpu configuration experimentally discover multiple allocate  roundrobin manner global thread dispatcher launch workgroups  simd width equivalent thread  launch  robin manner fix functional pipeline dedicate graphic processing  cache addition llc sampler cache solely graphic cache universal graphic computational application explain organization cache detail slice local memory SLM structure within complex programmer manage data thread within threat model covert channel attack originate integrate gpu cpu vice versa demonstrate proof concept channel attack gpu spy cpu covert channel trojan data spy communicate covertly indirect channel previously establish covert channel within physical device cpu gpu span contrast covert channel differs trojan spy communicate across heterogeneous component feature execution model memory hierarchy domain specifically trojan launch kernel gpu spy operates completely cpu communication demonstrate communication direction implement bidirectional covert channel explore covert channel prime probe style attack llc another contention concurrently access resource implement communication assume trojan spy user without additional privilege gpu another cpu explicit memory communication llc occurs  cache agreement contention attack relaxed dynamically identify communicate pursue implementation gpu attack program gpu user OpenCL api suspect channel establish OpenGL graphic kaby processor feature integrate intel gen HD graphic neo OpenCL version driver version ubuntu version lts linux kernel version attack developed unmodified generally additional workload gpu attack  capable multiple computation kernel context concurrently therefore gpu llc BASED covert channel covert channel attack prime probe channel llc cache prime probe strategy  attack strategy address strategy flush data cache prime probe spy access data cache prim trojan access data replace spy communicate communicate finally spy detect transfer access data probe access cache detects otherwise attack overview challenge attack cpu gpu communicate llc cache depicts overview attack illustrate attack trojan launch gpu communicate cpu spy launch cpu communication gpu cpu handshaking communication synchronize important heterogeneous component highly disparate communication rate gpu initiate handshake prim pre cache cpu cpu receives signal probe cache cpu acknowledges prim cache signal gpu phase gpu receives signal probe cache prim cpu handshaking phase attack gpu sends data cpu gpu prime llc cache probed cpu gpu prime cache cpu probe phase communication communicate secret covertly gpu cpu llc cpu gpu covert channel overview although attack strategy covert channel attack unique challenge implement channel cpu gpu challenge generally arise heterogeneous computational model component memory hierarchy llc overview challenge approach briefly lack gpu timer prime probe attack rely ability difference cache cache implement communication usually user hardware counter available access latency cpu unfortunately OpenCL  programmer custom user timer develop overcome svm reverse engineering llc gpu gpus mechanism cpu initializes launch gpu kernel cpu gpu scenario allows reverse engineer cache cpu establish technique gpu asymmetric llc gpu cache hierarchy discover llc gpu substantially cpu arises due asymmetric channel within  cache discover gpu cache inclusive relative llc unlike cpu cache understand gpu disabled OpenCL detail eviction rely inclusivity eviction another unique arise environment index gpu dissimilar llc eviction gpu llc significant atypical cache hierarchy eviction pollution target llc evict pollution without spurious access llc challenge communication rate across heterogeneous component spy trojan completely computation model operating substantially rate implement channel improve bandwidth reduce introduce asymmetry address combination access rate parallelism gpu optimize prime probe loop communication building custom timer access resolution timer essential ability cache covert channel without unable discriminate cache cache primary phenomenon communication although intel integrate gpus timer default manufacturer interface query OpenCL application OpenCL program execute intel device compile intel graphic compiler IGC debug mode query overload timer function program available programmer default mode  permission installation covert channel threat model attacker privileged access therefore alternative approach access latency within gpu application leverage gpu parallelism hardware local memory SLM custom timer local memory intel  memory structure across    local memory available per  local memory private thread launch thread conduct attack thread increment counter memory thread responsible attack timestamps access access principle technique cpu attack hardware available user mode due divergence within wavefront simd width thread execution thread wavefront serialize avoid thread wavefront access cache thread wavefront thread wavefront assign  memory llc cache consists probed parallel gpu thread thread however timer wavefront boundary thread thread ID avoid divergence accordingly thread involve conduct attack thread counter increment implement thread ideally wavefront probe timer however timer resolution obtain wavefront adequate distinguish access latency memory hierarchy remain thread implement counter custom timer characterization algorithm demonstrates custom timer code inside gpu kernel data access  OpenCL cached llc conduct covert channel attack attacker distinguish access memory llc algorithm variable volatile local counter declare timer volatile keyword counter variable cached inside thread register timer variable declare memory device local keyword memory data access algorithm custom timer algorithm volatile local counter uint   average float access thread ID simd atomic counter access thread ID average  idx buffer thread ID atomic counter  data buffer  atomic counter average access float average data llc llc access access resource contention erratic counter update custom timer launch kernel consist max thread per thread wavefront increment counter atomically algorithm atomic operation variable ensures variable access incremented properly data access counter atomically memory access average access measurement memory access llc data llc access llc data cached llc yield access timer access hierarchy access obtain counter clearly enable distinguish access hierarchy building llc conflict cpu gpu challenge attack formation eviction address cache prime probe attack briefly cpu attack llc however building eviction gpu compatible built cpu challenge overcome leverage OpenCL virtual memory svm zero feature derive llc conflict cpu LLCs slice processor architecture cache slice selection depends complex index hash scheme evenly distribute address across slice intel architecture MB cache slice MB cache associative byte cache cache per slice approach propose prior reverse engineer index hash processor discover index hash algorithm selects slice compute available user code avoid resolve virtual physical mapping simplify attack building gpu llc conflict svm derive conflict gpu complicate gpu cpu therefore llc eviction gpu simplify OpenCL intel gpus allows programmer allocate memory virtual address virtual memory svm physical address zero buffer user specifically cpu initializes launch gpu kernel eviction identify cpu gpu gpu kernel launch within address launch gpu attack spy trojan bypassing gpu cache handle memory asymmetry challenge generate prime probe gpu memory access filter cache gpu graphic workload otherwise bypass address generate access remove llc conflict address gpu cache access access llc prime probe reference reverse engineer cache gpu standard approach cache leverage cache inclusiveness relax inclusion propose defense attack inclusive cache data evict cache evict cache understand indeed inclusive discover another challenge due asymmetric  channel reverse engineer structure cache finally develop conflict traffic llc discover another occurs due asymmetry cache hash function index gpu cache incompatible hash function llc specifically address eviction gpu cache hash multiple llc unexpected interference understand access avoid interference reverse engineering inclusiveness inclusive buffer cpu gpu identify address access gpu cache data memory cached llc cpu access data cache flush data remove cache clflush llc inclusive cache removal flush data llc invalidation evict data cache gpu timing access gpu data access cache inclusive construct conflict llc due gpu parallel execution model associativity cache substantially llc llc due mismatch index hash address mapped cache conflict llc introduce novel challenge spill address llc without interference due additional address eviction associativity reverse engineering effort address organize slice slice KB slice cache configure KB cache KB local memory SLM earlier SLM declare SLM dedicate access pathway facility critical enable counter SLM without interfere cache access attack phase llc address llc slice llc eviction earlier prim probe phase address evict llc implementation prime probe non inclusive address cannot evict cpu counterpart instead eviction gpu conduct successful attack eviction pollution discriminate conflict evict llc due associativity gpu address pollution eviction llc target address discover hash index function gpu inconsistent llc pollution cache llc mismatch pollution eviction introduce interference attack reverse engineer relationship discover stride across llc across llc slice blindly pollution address access target llc interference failure attack target address mapped llc cache resides slice llc address cache attack phase address evict eventually llc simply eviction address hash slice llc without hash interference target llc address access target llc understand relationship mapping within cache correspond mapping within llc conduct standard pointer chase derive conflict within prior conflict hash across cache llc cache partition partition sub per cache address mapping cache additional address mapping cache cache sub additional address cache cache sub cache resides discover lsb address accounting cache offset index hash verify eviction address lsb conduct eviction replacement policy pseudo lru  access address multiple guarantee stable eviction target address  evict target address llc without interference llc  target address pollution hash slice llc eviction mapping gpu associative target address evict eviction cache hash slice llc cache llc target address hash slice target resides avoid interference slice target llc resides accomplish index hash function llc equation address llc conflict hash slice per equation address pollution hash slice llc channel spy launch cpu core cpu core launch gpu trojan transfer handshaking ensure synchronization spy trojan actual transmission llc cache phase attack conduct attack launch allocate sub slice implementation synchronization thread obtain within launch maximum thread thread permissible within thread perform prime probe attack thread boundary perform custom counter increment gpu initiate handshaking data transfer cpu gpu trojan signal data indicates gpu prime llc SA probe cpu gpu prim cpu spy probe SA phase handshaking indicates gpu trojan cpu spy llc cpu gpu covert channel detail cpu prime llc SB gpu probe SB probe llc gpu eviction custom timer delay described subsection exchange data llc SC prim gpu phase handshaking probe cpu conduct launch kernel gpu conduct within kernel loop transfer built reverse channel trojan cpu communicate spy gpu attack detail direction channel described role reverse specifically cpu initiate handshake prim SA gpu receives probe gpu sends signal prim SB cpu probe finally cpu sends communication gpu SC IV contention covert channel absent stateful microarchitectural component llc contention arise component bandwidth capacity limited microarchitectural structure bus situation measurable contention achieve component access structure concurrently slowdown although likely contention domain implement attack contention bus cpu gpu llc specifically cpu gpu generate traffic llc delay communicate contention contention relates concurrent resource accurate synchronization challenge presence frequency disparity cpu gpu cpu gpu data access delay cannot gpu data access limit systematic identify parameter contribute robust contention channel error rate bandwidth devise parameter frequency disparity computational resource attack detail remainder attack overview attack creates contention bus cpu gpu access llc attack cpu gpu generate address chosen pre allocate memory buffer cpu gpu buffer chosen llc avoid llc conflict distort contention signal access disjoint cache contention occurs strictly resource llc attack overview cpu launch core gpu launch core launch data allocation initialization trojan launch core launch gpu kernel data access cpu gpu simultaneously access cache cpu gpu data llc subsequent memory access llc generate contention resource contention resource reflect data access cpu contention channel attack methodology contention channel implementation covert channel identify parameter contribute towards building channel systematically optimize attack cpu TCPU access  byte data simultaneous access gpu access increase tov TT OT  access data cpu simultaneous gpu access equation overhead due simultaneous access function  byte data access gpu thread launch   iteration factor reflect iteration data access equation constraint cpu gpu data cache   cache equation another constraint llc mapped cpu buffer coincide mapped gpu buffer equation constraint ensure avoid llc latency due contention bus communicate contention channel related iteration factor communicate gpu access  byte data contention communicate gpu access TT OT  TCPU tov tov         cpu attack buffer  byte access offset cache access equivalent cache allocate buffer data access random pointer chase manner prefetching replacement cpu gpu data llc llc subsequent access service llc buffer chosen ensure data evict local cache llc access  gpu cache access thread launch memory address thread access  equation  cache thread novel asymmetric covert channel asymmetric resource gpu cpu frequency gpu overflow cache generate access llc unlike cpu derive conflict due index scheme without calibration mismatch inefficient communication reduce bandwidth increase error introduce notion iteration factor align channel equation gpu buffer execution varies launch iteration data access gpu ensures ratio gpu cpu execution evaluation evaluate covert channel channel bandwidth error rate llc bandwidth eviction strategy llc covert channel gpu cache  overflow access llc bandwidth channel direction cpu gpu gpu cpu channel strategy overflow naive establish covert channel perform clearing cache gpu parallelism accelerate advantage reverse engineer organization however clearing data cache KB thread parallelism substantially reduces bandwidth bandwidth llc covert channel iteration improve precise conflict construction eliminates interference llc described earlier bandwidth achieve technique gpu cpu channel cpu gpu channel optimization achieve reverse engineering eviction address precise eviction target address increase bandwidth cpu gpu channel error percentage cpu gpu channel achieve stable channel error rate bandwidth optimization precise eviction however error rate cpu gpu channel error BW llc reduce error rate increase channel resilience multiple llc monitoring cache multiple resolution communication however redundancy reduction available bandwidth potentially multiple communicate multiple parallel bandwidth error rate respect increase llc error rate  cpu channel cpu gpu channel reduces cpu  channel error rate reduces however bandwidth reduces acceptable reduction error rate reduces bandwidth reduces cache cpu gpu channel increase improvement error rate however bandwidth reduces steady rate attack stage attack llc cache iteration factor buffer contention covert channel cpu gpu access llc asymmetric pathway computational model impact rate communication asymmetric introduce concept iteration factor rate communication IV optimal iteration factor cpu buffer constant gpu buffer increase factor reduces correspondingly enable overlap bandwidth error bus channel IV contention covert channel buffer cpu gpu access gpu buffer affect contention consequently channel bandwidth error rate perform parameter obtain channel acceptable error rate bandwidth evaluation contention covert channel graph gpu buffer constant cpu buffer KB gpu buffer MB MB confidence interval bandwidth error rate axis obtain error rate configuration error rate obtain cpu buffer KB gpu buffer MB bandwidth error rate bandwidth error rate VI TRACKING user cache activity demonstrate efficacy attack model proof concept prime probe channel attack spy llc gpu observes cpu cache activity cache activity  cache distribution demonstrate experimental monitor cache parallel gpu cache activity cpu thread assign cache observation cpu access cache loop cache access loop almost delay subsequent access cache access fix delay subsequent access cache  llc axis axis cache vertical cache  interested visualize rate cache activity  cache activity cache cache activity application  access occurs shorter cache due frequency access loop without delay access activity reduces cache cpu application access cache delay subsequent access access till access due activity  evident user activity monitor gpu vii  defense developed microarchitectural covert channel potentially apply component attack heterogeneous static dynamic partition resource specifically llc partition scheme extend processor heterogeneous spy trojan partition cache replace cache eliminate contention traffic memory controller memory request processor grouped queue possibly access memory prior demonstrate efficient memory schedule strategy isolate cpu memory request gpu memory request improve performance memory request gpu seriously interfere cpu memory access performance isolation apply bus cpu gpu llc llc partition timer apply however customize timer hardware resource memory available gpu interfere timing straightforward related microarchitectural covert channel channel attack widely resource CPUs cache llc multicore CPUs concurrent develops contention channel attack cpu interconnect multiple core recent demonstrates gpus vulnerable microarchitectural covert channel attack propose discrete gpus dedicate memory architectural timing attack cpu gpu exploit dependent memory coalesce behavior construct covert channel resource within gpu demonstrate series gpu channel attack threat scenario graphic computational stack across implement website fingerprint gpu memory utilization api gpu performance counter user activity interact website keyboard addition develop neural network model extraction attack defense propose gpu specific intra SM partition scheme isolate contention victim spy eliminate contention channel detection microarchitectural attack defense propose processor cpu discrete gpu develop microarchitectural covert channel widely integrate cpu gpu limited rowhammer attack heterogeneous timing attack rowhammer attack heterogeneous fpga cpu platform integrate gpu available apis WebGL remote javascript program WebGL timing apis implement rowhammer attack integrate gpus mobile socs WebGL timer contiguous physical memory conduct rowhammer response attack chrome firefox disabled WebGL timer resolution timer  hardware precise cache conduct cache attack easily disabled IX CONCLUDING REMARKS microarchitectural covert channel attack span component soc component resource contention typically computational model attack introduce novel difficulty arise due asymmetry llc inclusive cpu non inclusive gpu moreover index gpu cache hierarchy llc conflict overflow gpu risk  llc calibrate communication loop improve bandwidth asymmetric pathway access channel channel improves understand threat microarchitectural attack beyond component threat model increase importance increasingly towards heterogeneous compute platform channel prime probe channel target llc contention channel exploit contention access pathway llc channel overcome challenge representative component attack channel achieve bandwidth error rate