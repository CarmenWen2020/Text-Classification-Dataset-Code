multicores ubiquitous programmer sequential code speculative parallelization entice approach parallelize code retain sequential program parallelism pervasive however prior speculative parallelize compiler architecture achieve limited speedup due recover misspeculation hardware scalability bottleneck parallelize compiler successfully leverage recent hardware feature speculative execution opportunity challenge automatic parallelization transforms sequential program timestamped task introduces novel compiler technique expose parallelism aggressively across entire program application task instruction task unfold parallel enable  throughput exploit selective abort recover misspeculation cheaply exploit parallelism across function loop loop nest performs transformation reduce task spawn avoid false exploit data locality grain task parallelize spec cpu benchmark core prior attain speedup introduction multicore ubiquitous programmer sequential code parallel program remains specialized pitfall deadlock data non determinism although application feature regular computation easy parallelize program feature data dependent imperative update multiple indirection codebases file library feature improve productivity  parallelization sequential code programmer compiler cannot reliably independent parallel parallelize program retain sequential semantics speculative parallelization speculative parallelization compiler code task likely independent runtime likely independent task parallel detect dependence dependence task aborted execute preserve sequential behavior speculative parallelization efficiently hardware reuse exist mechanism cache version management cache coherence detect dependence  mit unfortunately prior compiler architecture speculative parallelization sequential code  speculation TLS proven highly profitable limited achieve speedup realworld application TLS architecture suffer shortfall limited scalability resolve dependence abort later task  abort expensive task spawn commit mechanism bottleneck parallelism task lack locality aware execution recent speculative architecture propose mechanism address scalability limitation TLS hardware explicitly parallelize code adapt TLS compiler technique yield performance architecture demand approach automatic parallelization without utility limited address challenge compiler speculatively parallelizes sequential program successfully leverage recent hardware speculative parallelism timestamped task summarizes tackle limitation TLS compiler specifically contributes novel technique program task function entire program task instruction granularity expose parallelism aggressively isolates contentious memory access abort cheap spawn task parallel task serial chain spawn TLS assigns task timestamp program spawn task timestamped task expand parallel quickly enable selective abort spawn task input thread TLS carefully manages memory register allocation task spawn cheap avoid false eliminate stack exploit locality task access data tile reduce data movement execute task efficiently target recent swarm architecture sec II implement within llvm compiler framework sec evaluate spec cpu program frequent dependence limited effectiveness acm annual international symposium computer architecture isca doi isca speedup lbm  milc soplex astar geo TLS TLS selective abort core performance significantly exceeds TLS compiler prior speedup relative serial code compile detail sec IX prior sec IX broadens application benefit speculative parallelization yield scalability improvement prior compiler technique challenge application performance TLS combine feature prior benchmark core swarm novel automatic program transformation contribute significant scalability compiler technique exploit hardware scalable speculative parallelization sufficient compiler hardware speculative parallelization sequential program core contentious memory access modify source code interface data structure program sequential  programmer unlock parallelism retain simplicity sequential program hardware simulator source publicly available http swarm  mit edu II TREES timestamped TASKS illustrate limitation prior TLS compiler introduce feature overcome limitation explain speedup detail swarm hardware baseline avoid scalability bottleneck spawner task enable selective abort code loop program iteration performs compute local highlight performs modify memory operation highlight illustrates prior TLS parallelize loop task spawn chain iteration loop task spawn program TLS architecture mechanism schedule task spawn preserve sequential semantics memory address access task detect conflict access location access task writes address conflict task conflict resolve abort execute correctly later task incorrect data abort  UG LPH UG     code loop TLS task chain abort abort later task   UG LPH  UG    HH HFXWLRQ  spawner abort without abort task execution timeline speculatively parallelize loop iteration constitute task task conflict address task abort implement cascade abort prior TLS architecture conservatively abort later task   abort  discard impede scalability global synchronization stall execution later task rollback address leverage swarm distribute selective abort wherein abort task trigger additional abort dependent task however swarm TLS permit dynamic task spawn task abort abort due misspeculation avoid cascade abort compiler avoid unnecessary relationship simplest accomplishes chain spawner task decouples spawn spawner spawn spawner chain worker task execute loop abort without affect later task spawner neither access suffer conflict application data avoid unnecessary abort cascade selective abort yield speedup TLS task abort cheap modify writes array abort abort execute entire loop iteration waste amount function abort cheap spawn task contentious access continuation task boundary serf checkpoint isolate contentious access conflict  UG LPH  UG  UG iteration task grain task grain task spatial hint serialization heuristic UG UG  execution timeline depict data dependence memory task abort cheap enable spatial hint abort execute cheap task function contains loop additional function split task splitting modify operation task allows important optimization spawn tag task cache access spatial hint swarm hardware hint task chip tile exploit locality sec II avoids ping  cache across chip furthermore swarm serializes execution hint task avoid abort altogether hint dynamic information task parallel task abort cheap achieve parallelism hardware instruction task cycle shorter core spawn dispatch commit task per cycle prior TLS achieve throughput spawn task feature task ata commit mechanism bottleneck throughput task consequently static  technique coarse task merge task coarse runtime amortize spawn commit bottleneck coarse task sacrifice parallelism abort costly enormously costly abort prior limited speculative parallelization loop program dependence abort rare ability abort cheap allows aggressively speculate parallelism application conflict memory access soplex astar exponential task spawn task quickly core strategy software serial chain spawner cannot achieve spawn throughput core spawn task serial task spawn bottleneck performance limit speedup percent innermost loop spec cpu  exponential spawner improve parallelism address issue transforms code exponentially expand parallel spawner depict introduces progressive expansion spawner loop unknown bound exit sec VI loop execute spawner rapidly expand distribute load spawner worker across task dramatic benefit performance selective abort baseline hardware architecture parallelizes sequential code leverage swarm architecture swarm extends multicore standard multithreaded program hardware speculative task swarm task instruction core technique apply performs efficient speculative execution task explain swarm execution model highlight microarchitectural feature exploit achieve performance swarm execution model swarm program output sequential model execution schedule monotone priority queue swarm program consists task task timestamp priority queue swarm guarantee task timestamp thread pop timestamp task priority queue pop task task spawn task insert priority queue timestamps timestamp swarm precise exception behavior conforms sequential model arbitrary memory access microarchitecture software swarm task speculatively exploit parallelism focus swarm distribute hardware mechanism software exploit achieve performance HP HP HP HP  RUH    RUH RUH RUH RUH        core tile swarm processor configuration                    IV VI vii                 structure correspond implement series llvm transformation newly implement highlight orange goal hardware mechanism compiler transform composable timestamps domain topological task avoid dependence none stack elimination cheap abort selective abort spawner task cheap task spawn async task spawn task register communication reduction parallel task spawn distribute task progressive expansion exploit locality spatial hint spatial hint generation achieve goal introduces program transformation exploit hardware feature hardware implementation detail prior summarizes swarm feature couple compiler technique effective speculative parallelization swarm extends prior mechanism speculation implement selective abort recovery misspeculation abort task subtrees leaf task centralize priority queue swarm distribute task queue task core implementation task core tile task overhead standard multicore core spawn task task buffer local task task directly register involvement core cycle subsequently task task message without involve core central scheduler hardware task queue tile task task queue task per tile spill task memory rare task queue prioritize dispatch task program timestamps spawn profitable spawn task advance exploit locality task spatial hint integer denotes memory location task likely access hint operand task spawn instruction hardware sends hint task tile hash hint destination tile ID within tile hardware serializes hint task avoid likely conflict core task task task speculative commit queue task commits core execute task task commit commit queue task per tile core task ahead commit drain commit queue swarm throughput commit protocol hierarchical min reduction infer task commit swarm eager undo version management eager coherence conflict detection bloom filter LogTM SE task commit per cycle task queue task core chip communication latency however task challenge task achieve unfold parallel spawn task core implementation overview swarm previously manually parallelize algorithm explicit timestamps graph kernel schedule task priority queue instead timestamps implicitly preserve sequential semantics scalable develops technique extract parallelism despite irregular maintain deterministic sequential code without sequential application algorithm data structure unlike prior profile heuristic limit speculation coarse task code dependence rare entire program task expose speculative parallelism instruction fractal extension swarm compose parallelize code perform speculative execution granularity task overview component transformation llvm clang compiler toolchain intraprocedural compiler performs function without rely expensive interprocedural analysis compilation proportional code towards llvm register promotion ssa rename function inlining optimization reduce redundant computation already simplify IR parallelizes sequential IR phase correspond sec IV reduce memory dependence improve parallelism avoid false optimizes allocation local variable avoids stack sec decompose program task code task loop iteration function task boundary tag task timestamps program spawner spawn task parallel within code sec VI loop expansion generates spawner loop exploit swarm distribute task parallel task spawn generate spawner loop unknown  progressive expansion sec vii reduce communication coarsens task stride access generates spatial hint exploit locality finally task llvm IR function reduce register memory access task spawn avoids per task memory allocation llvm backend generates machine code IV  stack parallelize code transforms reduce false eliminate function stack otherwise become contention parallel task accomplish introduces transformation sequential code rely hardware bundling local variable heap allocation transform function return  style cps bundling replaces local variable normally allocate stack bundling heap chunk chunk allocate function freed variable bundle program explicitly pointer reference prevent compiler promote variable register local variable bundle instead promote register ordinary compiler optimization register spill thread private stack stack task privatization bundling variable  variable scoped within loop allocate instance iteration loop avoids false dependence loop iteration cps conversion continuation passing style conversion eliminates stack function frame eliminates notion function return caller allocate memory function stack frame pointer return address convert function return cps modify accept optional extra argument continuation closure implementation closure allocate heap reference closure pointer continuation code subsequent capture caller continuation cps conversion modifies  construct continuation closure pas callee callee execution program continuation return register code allows launch parallel without contention allocate stack frame cps conversion allows pas return continuation without contend stack transformation bundling privatization cps conversion sequential code parallelization source false dependence remove code longer stack easy spawn task parallel comparison prior cactus stack  parallel closest technique stack elimination technique parallel task dynamically spawn task function without contention stack allocation however stack elimination technique important benefit cactus stack selective heap allocation whereas cactus stack heap allocation task spawn task individual memory allocation data heap variable frequently local  stack avoids spurious conflict data  stack frame cps conversion compiler functional intermediate representation simplifies optimization eas code generation adapt cps compilation eliminate contention stack speculative parallelization knowledge automate cps conversion sequential program grain parallelization parallelize entire program exploit structure loop function preserve program unbounded nest task spawn task delineation code task loop iteration loop continuation function function continuation task prior approach naturally limit task fairly execution demonstrate loop iteration computation performs modify memory modify incur conflict abort automatically isolates  task function continuation task splitting annotation automatic task delineation suffices compile code  task abort cheap contention programmer annotate code split task manual annotation isolate contentious memory access enjoy benefit cheap abort spatial hint sec II annotation affect performance program semantics program retains sequential deterministic behavior future profile grain task boundary automatically identify contentious variable abort task target fractal extends swarm execution model task hierarchy nest domain task subdomain spawn subdomain hardware construct unique priority task domain creator execute atomic within domain task timestamps domain simplify composition separately parallelize code independent timestamp scheme task combination timestamps fractal domain graph cfg function graph node function internal task creates domain task assign timestamps contract loop node remain cfg becomes acyclic topologically sort node acyclic cfg assigns timestamps task topological treat loop task guaranteed timestamps reflect program loop creates fractal subdomain task delineation within loop iteration timestamp multiple loop index examines cfg loop remove topological sort nest loop contract assign timestamps reflect task within iteration recursively nest loop task loop nest parallel task spawn sequential code task determines spawn task heuristic aggressively expose parallelism enable selective abort task spawn task descendant register return continuation spawn continuation parallel continuation spawn continuation compute task abort cheap sec II otherwise function continuation task return function task spawn sibling task parallel aborted selectively sec II VI parallel loop expansion adopts multifaceted strategy parallelize loop central strategy spawner described sec II compiler transformation strategy expand loop generate spawner progressive expansion bound expansion chain expansion progressive expansion strategy unique critical parallelize program irregular parallel loop expansion differs prior TLS compiler spawn iteration loop serially exponentially expand spawner expose asymptotically parallelism critical task spawn grows logarithmically iteration instead linearly task spawn critical generates spawner llvm scalar evolution analysis identify eliminate induction variable unnecessary dependence iteration avoid flood machine task spawner timestamped accord loop iteration spawn prioritizes spawner properly expand gracefully node splitting cycle loop         LWHU LWHU  LWHU LWHU LWHU LWHU LWHU LWHU LWHU LWHU LWHU LWHU LWHU LWHU         progressive expansion loop pseudocode task transform loop foo spawn nest task progressive expansion progressive expansion generates spawner loop iteration unknown progressive expansion action unknown  loop spawner task loop iteration task task timestamp spawner spawn loop iteration directly spawn spawner stride spawner ensures subtrees balance spawner interleave iteration spawner spawner interleave timestamps exploit swarm ability spawn task initiate loop execution spawn initial spawner task spawner eventual spawn loop iteration evaluation spawner spawn loop iteration spawner fanout improves scalability handle unknown termination progressive expansion transforms dependence data dependence newly flag exit loop flag loop iteration spawner task flag exit loop already terminate flag ordinary memory resident variable exploit swarm ordinary mechanism scalable speculation task variable brings cache flag finally upon loop termination cache invalidation trigger discovery conflict abort task  loop bound expansion loop llvm analysis expression iteration compiler  runtime variable  loop generate          chain expansion avoids conflict ptr execution spawn nest task parallel spawner without speculation spawner responsible consecutive iteration evenly across spawner balance implementation compiler optimization  loop tapir however improve parallelism increase fanout internal spawner spawn spawner leaf spawner spawn loop iteration chain expansion progressive expansion loop spawner unprofitable loop iteration depends previous iteration update ptr identifies serialize variable meeting iteration unconditionally writes computation loop dependent variable variable induction variable rewrite eliminate met performs chain expansion loop rarely chain expansion chain expansion loop iteration slice computes serialize orange slice consumes chain expansion performs outer loop consume slice inner loop function nest parallel task optimization schedule orange task location spawn rate insensitive communication latency  vii  communication  performs optimization reduce data movement task exploit locality coarsen task stride access generate spatial hint pack reduce task spawn loop task coarsen cache alignment reduce false abort identifies inner loop scan memory fix stride per iteration coarsens task associate loop task  coarsen task cache consecutive task access disjoint cache byte cache access stride byte per iteration coarsens factor generates prolog  code task cache adapt strip mining prolog loop generation simd vectorization however automatic vectorization relies fragile pointer analysis programmer annotation restrict keyword memory access parallelize coarsens loop task without rely aliasing guarantee eliminate false due stride access inner loop spatial hint generation locality aware speculation spatial hint exploit spatial locality irregular access generate spatial hint identifies task memory address related memory address address within cache candidate spatial hint candidate task hoist computation access address task hoist easy task task boundary precede memory access address computation successfully hoist cache address compute shift hint reduces ping  frequently cache sec II sec crucial obtain scalability task reduction task code nest within function approach tapir task transformation reuse exist llvm analysis data across task boundary finalize task boundary task code llvm IR function spawn site capture task closure task register hardware task descriptor addition function pointer timestamp implementation entire closure register avoid memory access register task allocates extra heap pointer task performs optimization reduce closure loop environment allocates heap loop invariant loop iteration location achieve rate  task cheaply recomputed available multiple address compute constant offset pointer sink computation task register pack generates instruction shift remain minimum machine register program integer pack task spawn instruction task unpack register optimization increase instruction reduce task spawn data movement optimization task spawn capture register task descriptor cheap chip network hardware task queue  technique combine parallelize challenge loop astar due frequent data dependence prior TLS report significant speedup astar lambda closure conversion chapter int   index  index index  NW identical code  index    index    index    index num index   return  identical code index index  identical code index index  NE identical code repetition index identical code listing code cpp astar compress code omit RUH RUH RUH RUH RUH RUH RUH RUH LPH execution timeline astar task listing denote loop iteration arrow spawn append task listing loop astar 2D grid loop iteration node identify index node grid identify index code append queue  later happens per iteration average however avoid frequent expensive abort isolate appends append depends previous update  delineates task iteration task spawn task split task annotation spatial hint sec vii exploit locality  array task access cache within  parallel task spawn append task orange append task cache  spatial hint access contentious variable execute serially tile critical achieve speedup sec IX abort task execute swarm timestamp prioritization limit frequency abort core parallelize task across loop iteration unknown  loop due return statement inside loop progressive expansion spawn iteration quickly core core tile core tile ghz ISA haswell OoO superscalar cache KB per core split cycle latency cache MB per tile inclusive cycle latency cache MB static NUCA MB tile inclusive cycle latency coherence MESI cache directory noc mesh link rout cycle hop cycle tile mem controller chip cycle latency queue task queue entry core commit queue entry core conflict kbit bloom filter hash function tile cycle bloom filter cycle per timestamp commit queue commit tile update virtual arbiter cycle spill spill task task queue configuration core benchmark code modify cycle per task mcf none milc namd none soplex hmmer libquantum none href lbm astar sphinx spec cpu benchmark evaluation code exclude comment whitespace IX evaluation experimental methodology simulated hardware cycle simulator pin model swarm parameter detailed core cache network memory model simulate task speculation overhead task traffic  task abort simulate conflict rollback delay traffic etc simulate tile per core cache queue capacity constant equivalent partition core reduce waste implement hardware heuristic throttle overly eager speculation task repeatedly aborted task delay dispatch delay grows additional abort throttle hurt performance benchmark execution benchmark ratio abort avoid cache ping  network contention  memory operation benchmark evaluate application spec cpu exclude fortran benchmark float scientific application manually parallelize version already exist program evaluate auto parallelize speculation knowledge obtain previous speedup benchmark core core combine core core core core speedup lbm  milc soplex astar gmean benchmark sphinx  namd gmean benchmark performance normalize serial code execution lbm  milc soplex astar sphinx hmmer mcf namd non task task commit task abort throttle commit queue task breakdown execution core normalize serial code core advanced compiler technique hardware TLS synchronization benchmark cannot compile feature exist implementation rely heavily conventional stack layout exception   evaluate benchmark compile llvm clang compile benchmark ordinary serial binary compile llvm clang version compile verify compile benchmark deterministically serial version evaluate benchmark ref input simpoints sample serial version execution billion dynamic instruction representative steady execution none benchmark spends sample loop sample transition loop code ensure simulate sample regardless compiler transformation automatically function entry heartbeat simulator heartbeat sample modify source code benchmark compiler uncover parallelism report program code soplex sphinx modification annotation task explain sec astar  repetitive code annotation task sec manually perform loop fission hmmer stride memory access parallel task access cache sec vii loop fission automate future lbm milc href modification avoid false milc href declaration variable loop within loop iteration enables privatization avoid false dependence sec IV organize evaluation analyze overall performance sec IX spawner performance sec IX task splitting annotation future address passing escape continuation non trivial engineering due exception handle llvm hint sec IX task optimization sec IX sensitivity core microarchitecture sec IX performance report performance relative serial code core benchmark hottest inner loop iteration independent iteration benchmark hottest loop mutable scalar variable access iteration data dependence necessarily limit scalability benchmark focus benchmark benchmark achieve gmean speedup multiple benchmark core speedup core lbm insight height execution core relative execution serial version core core introduces modest overhead gmean across benchmark majority overhead instruction generates pack unpack spawn task load loop environment sec vii overhead astar soplex href task cycle return task abort cheap confer speedup breakdown cycle spent average across core core execute task later commit later abort cycle idle throttle heuristic commit queue task available breakdown benchmark core core spent execute useful commit benchmark beyond core execution core additional core mainly speculative task abort throttle task abort repeatedly benchmark core abort minority execution core core rarely stall task commit commit queue sec II occupancy average buffer task commit per tile across benchmark core rarely lack task task queue average runnable task per tile timestamp prioritize spawner sec VI unfold gradually lose spill task queue commit abort throttle commit queue task execution lbm  milc soplex astar benchmark core sphinx hmmer mcf namd benchmark core execution ideal TLS baseline successively enable feature selective abort bound expansion finally progressive expansion execution soplex astar sphinx core execution without  annotation benchmark lbm libquantum milc plentiful parallelism prior data dependence iteration inner loop rare achieve limited scalability due inefficient mechanism spawn speculative task benchmark highly parallel spawner significant parallelism soplex astar yield speedup respectively data dependence benchmark noticeable abort abort selective impede scalability independent majority soplex inner loop resemble meanwhile astar inner loop described sec  operation feature significant spatial locality spatial hint exploit benchmark benchmark dominate loop iteration unconditionally access mutable variable critical data dependence limit parallelism sphinx mcf extract parallelism isolate dependence task sphinx task generate due manual annotation sec IX meanwhile mcf spends  loop data dependence loop pipeline execution loop iteration chain expansion sec VI without source code annotation performance prior TLS parallelism limited hmmer href yield speedup namd benchmark inner loop loop dependence independent parallel prior obtains slightly speedup benchmark aggressive compiler optimization instruction critical compiler technique implement improve performance benchmark however focus application spawner task spatial hint avoid rigid critical task parallel without loop iteration participate serial bottleneck benefit spawner spawner benchmark variability scalability spawner yield benefit across benchmark execution variant idealize TLS baseline task spatial hint swarm hardware task spawn task commit conflict detection core benchmark benchmark core performance meaningfully improve beyond core TLS baseline function nest loop benefit parallel spawn iteration within loop spawn prior conflict detect broadcast tile perform idealize abort rollback later task cycle idealize abort TLS limitation beyond hardware bottleneck variant spawner enable swarm selective abort sec II enable selective abort waste reduces task cycle abort independent task available benefit benchmark lbm abort lbm slightly ideal baseline model latency writes abort variant enables bound spawner  loop sec VI brings significant benefit hottest inner loop libquantum lbm soplex variant enables progressive expansion unknown  loop benchmark lbm spawn quickly spawner reduce core idle progressive expansion mixed abort speculative task abort task queue quickly reduce abort benchmark task queue prioritize dispatch speculative timestamp task task splitting annotation spatial hint performance impact disable code annotation instruct split task finer granularity sec benchmark annotation soplex astar sphinx benchmark dominate loop computation spent parallelizable compute update apply data spent update data without annotation task boundary loop iteration function expensive parallelizable computation task conflict prone memory access benchmark become dominate expensive abort throttle abort task throttle disabled execution importance identify access contentious data isolate task abort cheap enables spatial hint sec II task splitting annotation cannot program output insert without careful analysis annotate portion code benchmark compiler obtain meaningful speedup astar soplex prior TLS effort achieve speedup astar core importance task enable spatial hint sec vii hint critical scalability otherwise frequently cache  abort speedup hint hint astar spatial hint generation astar repeatedly update variable  serialize operation critical limit program performance sec spatial hint generation critical astar without achieve speedup core deteriorate thereafter without spatial hint task random tile  cache  resides task spawn traffic reduction optimization task input crucial enables spawn task distribute across chip bandwidth volume transfer task without loop environment  sec vii optimization reduce register task descriptor across network overhead associate task spawn optimization spawn task register sec II cheaper prior TLS register context task spawn allocate memory optimization optimization benchmark byte task mem alloc byte task mem alloc lbm  milc soplex astar sphinx hmmer mcf href namd average task optimization reduce noc traffic due task reduce memory allocation task spawn core core core core speedup lbm  milc soplex astar gmean benchmark sphinx  namd gmean benchmark performance core normalize serial code core microarchitecture superscalar OoO core reflect available orthogonal core microarchitecture comparison performance scalar core despite core microarchitectures core enjoys speedup OoO core OoO core gmean faster core exploit ILP within task exploit speculative parallelism task OoO core related parallelize sequential code approach discus nonspeculative parallelization achieves scalability efficiency loop fails apply program discus speculative parallelization software advanced technique significantly benefit workload software technique combine finally review prior TLS combine hardware code transformation carefully schedule task extract parallelism challenge application frequent dependence goal TLS approach dynamically schedule task exploit grain parallelism locality mechanism avoid serial bottleneck non speculative parallelize compiler non speculative parallelize compiler sequential code task guaranteed independent parallel limitation compiler ensure task independent impossible compile polyhedral compiler parallelize loop perform regular access array matrix program irregular multiple indirection pointer structure static analysis ineffective addition program span multiple translation library compiler limited visibility invoked code impede non speculative parallelization irregular program non speculative parallelization focus exploit pipeline parallelism inner loop  pin loop iteration fragment across core localize loop dependence relies hardware grain inter core communication  implement efficient inter thread communication software suffices program  RC hardware inter thread communication accelerate broader benchmark non speculative parallelization technique highly efficient loop apply rely static analysis partition loop stage unidirectional dependence inapplicable loop contains occasional cyclic dependence conservative serial execution code outside loop parallelize compose parallelism across nest loop function speculative parallelization software compiler leverage speculation parallelize broader sequential program software speculative parallelization incurs significant overhead recover misspeculation profitable application dependence abort extremely rare compiler exploit application reduce dependence abort speculative privatization compiler technique eliminates false dependence increase memory usage validate safety data access recent profile static analysis reduce overhead suffers expensive misspeculation recovery unprofitable application frequent conflict future technique fully automate privatization extend privatization heap beneficial strip mining avoid false loop stride access loop task coarsen fully automates strip mining strip selection generates prolog  loop align task boundary cache instead assume array access cache additionally spatial hint stack elimination reduce abort uniquely swarm nest task spawn exploit selective abort task boundary checkpoint isolate contentious access spawner task repurpose swarm cheap task spawn mechanism achieve benefit alternative misspeculation recovery technique abort portion task instead entire task garc√≠a  software performs selective abort however parallelizes loop abort loop iteration nest task spawn thread speculation TLS TLS architecture propose hardware mechanism speculative parallelization broadly beneficial sequential program unfortunately TLS architecture suffer expensive  abort serial spawn commit mechanism cannot task core sec II swarm address issue enable novel technique TLS architecture relaxes requirement task spawn serial speculative task spawn independently architecture exploit nest parallelism however decouple spawn execution core immediately execute task spawn task speculative unlikely commit moreover restrictive interleave task timestamps progressive expansion finally performs serial commits bottleneck performance TLS architecture address per task overhead adaptively merges task task core  coarsest granularity machine task prone expensive  abort contrast swarm distribute queue manage task core exploit cheap selective abort TLS compiler limited architecture target task TLS architecture function loop iteration however without sufficient hardware task previous compiler focus selectively parallelize coarser task  spawn function loop iteration focus profile task boundary prefer sufficiently coarse task amortize task overhead TLS compiler technique focus parallelize iteration loop technique limit speculation avoid significant  abort propose model statically estimate likelihood data dependence avoid parallelize loop yield frequent abort develop compiler technique synchronize frequent data dependence instead speculate distribute loop iteration core rigid fashion enable predictable communication synchronization cheap synchronization critical iteration loop rigid synchronization benefit significant drawback application dominate inner loop dependent iteration benchmark sec IX synchronization ensures critical program contrast suffers abort due violation spatial hint sec rigid synchronization nest task spawn stall core per iteration  balance core idle iteration independent benchmark contrast spatial hint serialize dependent task task whenever available core moreover parallelizes program compose parallelism across loop nest function future combine benefit approach task spawn overhead eliminate speedup spawn task inner loop  reduces loop parallelization overhead constant factor pipelining loop fragment across core communication latency critical chain expansion spatial hint achieve benefit loop communicate iteration another task yield asymptotically parallelism parallelize task spawn delivers  speedup task TLS compiler communicate memory prevent promotion register resident memory task boundary impedes standard compiler optimization bandwidth requirement entire cache task spawn challenge task core TLS introduce hardware mechanism register task software register task optimization reduce amount data architecture task spawn cheaper swarm prior proposes exploit semantic commutativity programmer reduces abort speculative parallelization sequential semantics programmer nondeterministic program output contrast preserve sequential semantics programmer worry XI conclusion compiler approach speculatively parallelize sequential program task spawn task advance exploit swarm hardware task practical task unlock opportunity abort cheap expose parallelism efficiently spawn task introduces novel transformation progressive expansion exponential irregular loop  cps conversion eliminate contention stack task optimization task spawn cheap task enable spatial hint generation speculative parallelization dynamic information sequential code exploit locality combine software hardware technique broadly improves scalability prior extract parallelism core irregular code defeat prior