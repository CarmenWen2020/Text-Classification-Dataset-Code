heterogeneous ISA multi core performance consumption benefit numerous component NVRAMs smart NICs already built processor core ISAs host CPUs heterogeneous ISA multi core unfortunately program efficiently extensive host operating exist program complex dramatic incur significant performance overhead address challenge propose flick lightweight ISA migrate thread heterogeneous ISA multi core leverage hardware virtual memory standard operating mechanism software thread transparently migrate core ISAs prototype heterogeneous ISA multi core FPGAs shelf hardware software evaluate flick microbenchmarks bfs application flick minor exist OS software incurs overhead migrate thread pcie faster prior index heterogeneous ISA multi core thread migration virtual memory fpga introduction multi core processor  MPSoCs dominate cpu architecture decade improve processor performance within constrain budget researcher propose deployed heterogeneous multi core processor  heterogeneous multi core heterogeneous ISA multi core processor deployed massive warehouse datacenter server smartphones embed heterogeneous multi core processor heterogeneous ISA multi core  MPSoCs effort effectively utilize diversity architecture ISAs microarchitecture performance efficiency addition intentionally heterogeneous ISA  MPSoCs component smart NICs  FPGAs built purpose processor NxPs  communication smart NICs data  accelerator FPGAs typically ISAs host processor microarchitectures tailor target workload efficiently incorporate NxPs numerous compute already heterogeneous ISA opportunity computation communication across core ISAs achieve performance efficiency however although benefit heterogeneous ISA multicore attractive benefit significant challenge software developer challenge particularly pronounce NxPs private memory software developer NxPs offload program style cuda OpenCL gpus offload software organization differs greatly conventional purpose multi core program environment familiar developer NxPs developer typically handle communication host processor NxPs data address movement increase complexity potentially reduce performance address programmability challenge researcher propose operating modification exist operating aim hide complexity heterogeneous ISA multi core traditional multi core environment familiar developer approach typically assume software thread permit freely migrate core execution enable thread migration dynamically profile load thread migration capability prior employ complex technique binary translation thread transformation integrate mechanism heavily modify brand operating unfortunately although generally achieve goal programmability convenience approach impose performance overhead execution heterogeneous ISA software conveniently programmable heterogeneous ISA performance achievable sacrifice amount purity associate migrate particularly nxp software developer partition software data technique prior introduce unnecessary complexity overhead illusion efficient memory multi core environment user enable easily develop software acm annual international symposium computer architecture isca doi isca core ISAs therefore principled approach identify minimum requirement heterogeneous ISA multi core program environment easy minimal deviation traditional ISA multi core program achieve without introduce modification exist operating hardware develop flick lightweight ISA migrate thread heterogeneous ISA environment maintain expectation conventional multi core flick guarantee unified physical memory address software thread observes virtual memory address core regardless ISA hardware memory organization convenient lightweight generic thread migration mechanism capable transfer thread core  function boundary flick mechanism readily available access entry non intrusive exist software technique fault handle dynamic library loader ultimately flick allows software developer conventional software target multicore function ISA thereby transparently migrate thread desire core program function across designate ISA boundary prototype evaluate flick heterogeneous ISA multi core platform shelf server pcie fpga flick achieves migration loc modification shelf linux operating oppose microsecond overhead loc modification prior bfs application flick achieves speedup perform thread migration organize II depth discussion background motivation describes architecture flick IV describes detail implementation evaluation VI discus related vii concludes II background motivation heterogeneity improve performance efficiency heterogeneous purpose core accelerator gpus researcher explore heterogeneous multi core integrate purpose core characteristic leverage core strength performance consumption heterogeneous multi core achieve overall execution efficiency maintain flexibility task execution purpose various heterogeneous multi core heterogeneous ISA multicore extreme combine core architecture ISAs achieve efficiency specialization heterogeneity parallelism multicore heterogeneous ISA multi core achieve speedup saving homogeneous multi core heterogeneous ISA multi core integration integrate core ISAs primarily physical location core spectrum core tightly couple chip heterogeneous ISA cmp MPSoC core memory hierarchy latency communication however although heterogeneous ISA  propose academia rarely spectrum data connects processor ISAs network heterogeneous ISA however core across server developer limited distribute program technique communication overhead integration option heterogeneous ISA core across multiple chip within machine component already core ISAs host core execute specifically target component server smart NICs nvme controller FPGAs integrate core core typically NxPs reside network storage accelerator data access latency task tailor architecture NxPs highly efficient target workload importantly NxPs within machine host CPUs relatively easy memory communicate host CPUs NxPs expose utilized developer opportunity achieve overall performance efficiency program style challenge unfortunately although hardware designer effort improve efficiency heterogeneity heterogeneous ISA multi core inherit program challenge heterogeneous addition obstacle concurrently multiple ISAs difficulty develop software  multi core introduces burden developer limit adoption unlike gpus widely adopt program framework cuda OpenCL generally accepted software purpose core ISAs multiple independent operating across heterogeneous ISA core developer partition software completely independent application compile separately operating manually handle communication data movement RPCs nxp developer usually treat NxPs processor explicitly offload program style host CPUs data command descriptor core fetch descriptor execute notably adapt gpu program framework heterogeneous ISA multi core program NxPs gpu framework around computational kernel target massive parallelism bulk data transfer coarse grain host software traditional multi core NxPs characteristic significant adapt  program framework without convenient nxp program framework developer tear apart software handle separately integrity software extra software maintenance rewrite software program style framework consume error prone additional debug verification effort manually handle communication data movement core careful avoid performance loss although heterogeneous ISA multi core attractive theory software developer develop nxp attractive heterogeneous ISA operating address programmability challenge researcher propose modify exist operating specifically heterogeneous ISA multi core goal memory homogeneous multi core environment software developer hiding complexity within operating developer software convenient familiar memory program style compile exist software ideally without modification hiding complexity ability operating migrate thread core ISAs transparently user software encounter code core ISA operating suspends thread core transfer thread core resume execution target core operating handle abi application binary interface difference ISAs convention stack layout ensure thread correctly target core addition handle heterogeneity operating manage resource memory storage thread access data instruction core offering friendly program environment developer operating minimize impact efficiency along convenience abstraction layer software  multi core hardware introduces overhead affect efficiency thread migration extra cycle suspend resume thread handle abi difference transfer thread consumes bandwidth manage resource availability effort operating overhead reduce benefit heterogeneous ISA multicore developer return complicate offload program style achieve efficiency although prior useful abstraction developer suffer overhead enable thread freely migrate core ISAs execution prior employ complex technique binary translation stack frame transformation microsecond millisecond context switch fault usually microsecond overhead prevents frequent thread migration limit usefulness addition runtime overhead implement thread migration technique data management prior develops operating scratch limit academia research lab heavily modifies exist operating creates difficulty maintenance situation hamper adoption heterogeneous ISA multi core opportunity overhead technique integrate  core typically appropriate nxp NxPs usually powerful host CPUs migrate thread nxp thread something nxp graph workload graph nvme graph traversal function core nvme storage program operation desire node host CPUs characteristic largely reduces migration program migration static usually function return boundary utilize operating longer technique prior eliminate overhead complexity technique unified memory host nxp another opportunity reduce migration overhead nxp conventional software thread access data instruction core bus unique opportunity efficient unified memory nxp interconnect protocol pcie already CPUs device global memory interface  gen latency cache coherency pcie unified memory thread migration address translation avoid serialization transfer data memory restrict migration function return boundary utilize unified memory host component enables flick lightweight ISA mechanism migrate thread nxp flick attains overhead thread migration retains program execution environment homogeneous multi core achieves minimal exist compiler toolchains operating flick architecture flick architecture comprises inter dependent component hardware software unified memory thread migration mechanism generation execution multi ISA binary modification operating describes component detail unified memory flick thread migration mechanism relies unified memory virtual address within thread address physical address host CPUs NxPs physical address component host memory nxp local memory unified memory allows software thread access instruction data core without modify application source code moreover directly pas pointer host nxp without code address translation enable unified physical memory flick pcie bridge host memory nxp address export nxp memory peripheral host pcie unified virtual memory nxp utilizes local tlb translate virtual address physical address host CPUs local MMU host structure nxp tlb register  host cpu local MMU TLBs demand flick avoids host interaction nxp perform context switch challenge  local nxp tlb penalty due latency host memory however although reduce latency tlb rate mitigate amortizes latency operation across access specialized NxPs freedom implement address translation mechanism reduce tlb CR register architecture physical memory nxp host tlb tlb MMU  MMU virt addr phys addr execute thread nxp host physical address register  therefore virtual memory allows address core seamlessly thread migration execute fault migrate thread host nxp core extra code function return boundary migration transparent software developer migration code insert program compiler runtime operating although compiler insert migration code customize straightforward drawback software function pointer function compiler pointer target host function nxp function runtime handle function pointer compiler insert migration code function moreover function invoked host core nxp core migration code incur additional overhead thread currently trigger migration typical software routinely function pre compile library standard library migration code insert migration program link library challenge static compiler approach instead insert migration code compiler flick OS trigger manage thread migration non executable NX entry implement fault trigger migration function nxp load binary memory NX entry host cpu execute function instruction fault occurs operating fault handler function address user migration handler link application binary migration handler parameter function information  pid performs migration host nxp nxp scheduler host nxp worker thread idle thread thread nxp func host func return host func return nxp func host nxp function encounter NX fault thread migration migration handler host host nxp descriptor sends nxp  thread host processor descriptor picked nxp thread context switch execute target function nxp function execution nxp host function trigger fault nxp sends nxp host descriptor host receives descriptor execute target host function host function sends host nxp return descriptor nxp resume target function eventually sends  host return descriptor host host receives return descriptor execution information execute target function function execution nxp scheduler performs return migration nxp host trigger interrupt host cpu thread function return similarly nxp function host cpu mechanism difference nxp NX direction nxp function resides without NX fault occurs fault handler nxp performs migration nxp host cpu function execution host cpu performs return migration host nxp thread resume execution nxp although fault function significant overhead developer explicitly designate function nxp benefit nxp significant mitigate overhead notably gathering information function argument passing nxp overhead conventional offload style program model combination unified memory NX trigger thread migration serf overhead mechanism allows transparent migration host nxp core vice versa multi ISA binary flick aim software execution environment ISA user launch binary file application binary file heterogeneous ISA instruction ISAs universal binary  however universal binary  entire program compile instruction ISA binary file whereas flick program logically partition ISAs function granularity function target ISA core ISA instead linker binary entire program executable flick linker handle ISAs simultaneously resolve address function ISAs within address execute multi ISA binary file toolchain compilation text ISA relocate ISA relocation NX entry load binary toolchain transparent application developer addition command flag compilation link instruction data placement nxp core access memory host memory nxp local memory creates numa environment host core access host memory latency access nxp local memory visa versa ideally core access data within numa moreover dominant bus protocol pcie limited cache coherence capability placement instruction stack heap data multi ISA executables instruction instruction footprint nxp core relatively text nxp core reside host memory rely cache nxp core minimize access latency stack thread migration flick happens function boundary assume core unlikely access data core stack assumption extend migrate thread stack nxp local memory thread typically local stack avoid costly memory access bus rare callee function pointer access data caller stack frame unified address ensures execution execute core heap memory allocator core local memory link program linker relocates memory allocation core text correspond memory allocator avoid application code software developer allocate memory memory allocation annotate source code  HPRU LGH HPRU  HPRU LGH HPRU  HPRU LGH HPRU  HPRU  LGH HPRU   HPRU   host nxp platform physical address remapping nxp allocator latter useful storage computation host core allocate initialize data storage processor finally flick data host memory necessitate limited pcie cache coherency capability nxp core cannot coherent cache content automatically invalidate host access global variable access bus workaround coherence host frequently access variable data structure software developer directive source code variable allocate nxp local memory compiler variable nxp specific data enable loader nxp local memory notably unlike pcie emerge bus protocol    avoid workarounds IV implementation DETAILS prototype flick built heterogeneous ISA multi core comprise host core RISC nxp core choice ISA dictate dominance server RISC ISA ubiquitous ISA available implementation tailor nxp core component tlb MMU specific adapt linux kernel standard gnu enable compile link load  application binary unified memory unified memory host nxp core customize RISC core MMU tlb replace  tlb MMU counterpart counterpart understand host structure MB 1GB tlb tlb entry cycle latency access important data access due pcie restriction data cache enable nxp memory coherence host core notably tlb MMU nxp core virtual address bootstrap environment tlb entry nxp core reset address rom nxp bootstrap instruction bootstrap instruction nxp stack pointer nxp scheduler trigger tlb normal execution virtual address host tlb cache tlb memory access MMU traverse structure host memory update virtual physical translation tlb instead implement fix function MMU implement MMU micro controller core development effort enable future research optimization nxp address translation programmable MMU opportunity runtime optimization MMU configure nxp virtual address bypassing traversal nxp core directly access nxp component debug purpose access local physical memory without traverse host memory implementation performance private scratchpad memory perform virtual physical translation TLBs ensure nxp physical memory host host memory directly physical address nxp platform address however nxp local memory peripheral expose host pcie  address assign dynamically host physical address nxp core remapping functionality tlb remapping shift address local memory peripheral nxp local address instead host address remapping nxp local memory address expose host however host address address dynamically assign host driver host calculates mapping offset writes register nxp tlb execution tlb translates virtual address physical address address tlb register content adjust physical address actual address nxp local address mapping nxp local memory peripheral address offset tlb enables nxp physical memory host core host memory nxp component listing host migration handler pseudocode host migration handler arg migration allocate nxp stack host nxp arg ioctl migrate suspend nxp host args fetch nxp desc host rtn target host func args host nxp return host rtn ioctl migrate suspend nxp rtn fetch nxp return desc return nxp rtn thread migration detail flick thread migration mechanism software hardware component ensure execution overhead perform thread migration across core ISAs split description scenario thread migration migration happens host nxp function migration happens nxp host function host nxp function flick thread execution host migration nxp core happens nxp function migration thread host nxp migration thread host fetch nxp core instruction memory NX entry trigger inst fault transfer fault handler fault handler fault address address function nxp address automatically host core stack return address fault handler fault address task struct thread replace address stack address flick host migration handler fault handler return instead fetch nxp instruction thread resume execution host migration handler migration host nxp host migration handler listing examines nxp stack pointer initialize null uninitialized stack pointer indicates migration thread migration handler allocate nxp local memory thread nxp stack listing hijack function redirect execution migration handler handler receives function argument handler argument host migration handler argument kernel ioctl listing internally ioctl auxiliary information target address stack pointer CR  pid identify wake execution eventually return host thread task struct listing nxp migration handler pseudocode nxp migration handler arg nxp host arg migrate suspend host nxp args fetch host desc nxp rtn target nxp func args host nxp return nxp rtn migrate context switch host rtn fetch host return desc return host rtn package function argument  nxp descriptor finally ioctl concludes suspend thread host trigger transfer descriptor nxp thread resume execution nxp minimize overhead transfer descriptor multiple memory operation across pcie flick dma controller entire descriptor pcie burst transfer nxp scheduler poll dma status register discover migration descriptor transfer host nxp scheduler observes dma status register host nxp migration descriptor extract nxp stack pointer stack pointer context switch target thread nxp stack carefully initialize host beforehand target thread execution inside loop nxp migration handler listing inside loop nxp target function target address argument host nxp descriptor target function return return pid nxp host return descriptor thread performs context switch nxp scheduler listing scheduler transfer nxp host return descriptor host memory dma controller dma controller trigger interrupt host wake thread pid thread wake inside ioctl migration handler return host migration handler  host descriptor listing migration handler nxp host migration explain host nxp return migration return nxp core migration handler return return return descriptor listing hijack function return normal return target function execution host core migration execution nxp core therefore entirely transparent future attempt function compile nxp ISA similarly inst fault trigger migration reuse nxp stack allocate previously nxp perform context switch thread resume inside loop nxp migration handler previously listing  descriptor function return host nxp host function host function nxp nxp function host migration thread host recall host relies inst fault notably migration RISC nxp core host trigger additional mechanism host inst fault trigger MMU nxp attempt fetch instruction function compile host ISA flick meaning NX invert nxp tlb trigger exception NX  instruction instruction fetch host function trigger RISC misalign instruction address exception treat exception indicator migration exception mechanism transfer RISC migration handler listing nxp migration handler host counterpart nxp migration handler perform stack initialization thread originate host stack migration handler prepares  host descriptor dma controller descriptor host memory listing trigger host core interrupt handler wake correspond thread pid previously suspend inside ioctl execution host resume user migration handler listing return nxp function nxp host latter host migration handler loop retrieves target function address argument descriptor function host listing host function return migration handler prepares host nxp return descriptor return nxp migration handler ioctl initiate dma transfer descriptor host nxp migration thread host listing suspend nxp core host function host thread remains loop  nxp host migration however host thread  request nxp host return migration  host migration host loop thread resume execution host site migration nxp nxp nxp scheduler receives migration descriptor performs context switch correspond thread previously suspend inside nxp migration handler listing migration handler return migration host migration host return nxp migration handler initiate return procedure descriptor listing nxp migration handler enters loop execute function host remain loop receives host nxp return descriptor loop return nxp caller function nest bidirectional function host nxp migration handler  notably rely function trigger migration standard function convention ensures multiple migration handler local variable reside location thread stack simultaneously interfere consequently  migration mechanism application code freely function executable recursively transparently migrates execution forth core ISAs multi ISA binary generation execution generate execute multi ISA binary conventional linux introduce compiler linker loader toolchain compiler compile code multiple ISAs rely user annotation source code script partition annotate source code function target ISAs temporary source file separately invoke unmodified compiler ISA target flick migration happens automatically runtime transparent fault mechanism perform source binary instrumentation furthermore host nxp core virtual address compiler convert address provision pointer notable introduce RISC toolchain elf text compile code text riscv approach handle ISA target without complex compiler modification merge compiler multiple ISAs linker generate file native host linker merge file custom linker script linker script prevents nxp automatically merge host maintains target ISA custom linker script ensures KB alignment text ensure code ISA entry file merge linker performs relocation modify linker source relocation function host nxp RISC core linker invokes correspond relocation function resolve across internal reference multi ISA executable core virtual address linker link normally without address handle notably specification host dual xeon 4GB ddr fpga NetFPGA  xilinx  fpga memory 4GB ddr nxp core scalar RV mhz interconnect pcie operating ubuntu linux toolchain gcc binutils glibc executable link internal reference resolve instruction data reference ISA boundary host code directly refers code data nxp nxp code directly refers code data host binary dynamic linker loader flick multi ISA binary text ISA load address align boundary multi ISA binary glibc user dynamic linker load text executable linker extend mprotect configure appropriate entry enables trigger thread migration respective fault dual ISA executables RISC nxp ISA host ISA loader NX text riscv leaf text load program execution jumping application entry fault handler migration handler transparently migrate thread appropriate nxp host core ISA boundary throughout program execution notably executables ISAs loader additional entry distinguish nxp ISAs kernel flick thread migration mechanism linux kernel flick relies fault trigger thread migration exploit mprotect non executable modify default linux fault handler recognize NX fault trigger migration NX fault occurs handler manipulates stack return flick migration handler described IV addition NX fault handler flick modification kernel elf loader  kernel module multi ISA executables multi ISA kernel module function host nxp platform initialization host ioctl function nxp nxp scheduler nxp migration handler implement mechanism multi ISA module kernel user program compilation link multi ISA kernel module kernel module loader nxp dram fpga rvi core axi interconnect migration dma ddr controller pcie bridge host machine ITLB DTLB MMU ram nxp stack fpga evaluation platform flick modify handle relocation function host nxp core accord finally flick minor modification linux scheduler user migration handler issue migration request via ioctl kernel creates descriptor execute target function suspends thread host core task  scheduler context switch away thread host trigger dma transfer descriptor nxp notably linux scheduler modify trigger dma controller context switch away thread transfer trigger thread execution already suspend facilitate migration flag task struct prior suspend thread trigger descriptor transfer scheduler thread suspend although intrusive mechanism trigger descriptor transfer thread suspend avoid nxp descriptor execute target function return host completes suspend thread host core evaluation testbed evaluate flick prototyped heterogeneous ISA shelf intel xeon server host pcie fpga emulate device nxp detail environment depicts fpga platform scalar RV core serf nxp connects chip ram local stack fpga 4GB ddr SDRAM DIMM nxp data storage fpga platform pcie bridge host allows RISC core access host memory direction entire 4GB nxp data storage memorymapped host via pcie pcie bridge enable host core directly access nxp data storage load instruction memory heterogeneous ISA multicore measurement host II thread migration overhead prior flick core core interconnect overhead  mips 2GHz mhz  xeon 4GHz xeon phi 1GHz pcie isca xeon 5GHz cortex mhz pcie gen cortex 8GHz cortex onchip network flick xeon 4GHz RISC rvi mhz pcie gen flick thread migration overhead host nxp host nxp host nxp core nxp RISC core access nxp storage approximately respectively xilinx  core programmable MMU handle tlb host memory tlb penalty due pcie memory access 1GB 4GB nxp data storage tlb entry nxp local storage avoid consume tlb normal operation evaluation purpose flick microbenchmarks closely environment understand precisely characterize migration overhead breadth application demonstrate behavior flick technique practical thread migration overhead examine thread migration overhead flick critical overall performance microbenchmark host function nxp immediately return microbenchmark function average roundtrip overhead host nxp similarly overhead nxp function host processor nxp function host function immediately return host nxp overhead measurement nxp host overhead flick host nxp host nxp host nxp thread migration respectively investigation indicates host fault incurs migration overhead efficiency fault trigger thread migration II overhead prior flick migration overhead already prior heterogeneous ISA thread migration flick migration pcie faster  migration chip network within commercial socs notably nxp core core mhz anticipate overhead flick reduce harden core microbenchmark pointer chase performance flick environment developed pointer chase microbenchmark traverse variable link nxp storage chose pointer chase representative data structure beneficial migrate thread data access goal understand overhead thread migration affect potential speedup microbenchmark loop function nxp traverse link data storage node address byte align randomly across 4GB swept traverse node per function increment average traversal traverse emulates amount perform per migration normalize performance baseline host core directly traverse link pcie additionally understand thread migration overhead affect overall performance introduce extra migration latency mimic overhead incur prior normalize performance host frequently migrates thread nxp delay insert function memory access per migration flick solid achieve performance baseline memory access increase amortize thread migration overhead flick performance benefit increase stabilize relative difference latency host core nxp access nxp storage dash flick performance alternative migration latency migration latency prevents achieve baseline performance within reasonably access per migration demonstrates crucial importance migration migration overhead access per migration benefit nxp infrequent migration migrates thread corresponds scenario host therefore portion overall execution spent pointer chase migration overhead becomes significant penalty baseline performance memory access per migration although flick outperforms baseline normalize performance memory access per migration migration interval normalize performance memory access per migration flick TM latency TM latency migration interval pointer chase microbenchmark thread migration latency migration interval IV bfs datasets execution  dataset vertex baseline flick epinions MB  GB livejournal GB benefit thread migration reduce approximately overall highlight importance thread migration latency flick overhead effective frequent migration application bfs bfs breadth benchmark graph traversal benchmark graph bfs source vertex recursively explores reachable vertex discover graph traversal central component analytics recommendation social medium model route optimization social network datasets stanford network analysis project snap IV evaluate flick graph graph generate datasets nxp dram flick migrates entire traversal function nxp host traversal function loop calculates average execution iteration emulate scenario host software perform task vertex traversal function nxp dummy host function newly discover vertex execution migrate host return average execution baseline host core directly traverse graph via pcie rightmost IV dataset vertex ratio datasets migration overhead flick performance baseline however datasets thread migrate vertex flick outperforms baseline speedup approach migration overhead highlight overhead flick enables application frequent thread migration VI related heterogeneous ISA thread migration prior heterogeneous ISA thread migration demonstrates benefit heterogeneous ISA however migration overhead technique microsecond limit infrequent thread migration flick migration overhead significantly overhead microsecond microsecond facilitate frequent thread migration beyond performance benefit flick modification operating prior report loc linux kernel loc compiler flick loc although target heterogeneous ISA multicores prior UD fault invalid opcode trigger unidirectional thread migration overlap ISA heterogeneous multicore whereas flick non executable NX entry bidirectional thread migration core ISAs heterogeneous multi core operating heterogeneous multi core operating core ISAs however completely redesign OS limited impact acceptance heterogeneous ISA flick minor exist operating benefit widely available commodity server unified memory requirement flick although focus unified memory entire already target virtual memory gpus academia virtual memory accelerator flick benefit advance accelerator tlb improve accelerator virtual memory distinction prior flick unifies virtual physical address NxPs storage processing  processing demonstrate NxPs improve performance efficiency however conventional offload program style utilize NxPs integrity software manual orchestration communication data movement core flick utilizes virtual memory fault trigger thread migration enable transparent utilization NxPs achieves performance benefit vii CONCLUSIONS propose flick ISA mechanism transparent thread migration heterogeneous ISA multi core restrict migration function boundary unify physical address leverage hardware virtual memory flick eliminates majority thread migration overhead minor exist operating evaluate flick pcie fpga shelf hardware software microbenchmarks bfs application flick thread migration overhead prior