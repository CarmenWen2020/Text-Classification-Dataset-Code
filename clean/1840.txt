domain specific hardware accelerator magnitude speedup efficiency purpose processor however extensive manual effort hardware software stack development automate ASIC generation HLS insufficient hardware becomes inflexible ideal accelerator generation framework  enable specialization domain maintain uniform program interface insight prior accelerator architecture approximate compose hardware primitive specifically spatial architecture careful compiler understand available primitive modular composable transformation advantage feature program suggests paradigm accelerator generate within accelerator affinity input program hardware primitive interaction approach develop DSAGEN framework automates hardware software reconfigurable accelerator exist accelerator evaluation demonstrates compiler achieve performance manually tune version automate exploration target multiple workload prior accelerator generate hardware perf prior programmable accelerator introduction response technology specialized accelerator proliferate setting across variety domain strategy emerge develop accelerator benefit limitation automate HLS synthesis compiles pragmas custom hardware HLS nearly automatic generally limited programmable domain specific approach customizes hardware kernel within domain domain specific hardware software interface advantage performance sufficient flexibility hardware software effort workload evolve    liu author conference micro purpose gpu dsp simd extension approach enables uniform program interface stability lack specialization application approach satisfy flexibility algorithm diversity hardware domain specific hardware software stack implementation cannot justified setting ideal specialization approach yield automation HLS enable specialization domain maintain uniform program interface ideal approach enable user tradeoff specialization efficiency generality intelligently tune flexibility hardware hardware software interface approach within flexible architecture computation memory desire target program central challenge define enable specialization prior decouple spatial accelerator promising candidate spatial refers hardware software interface expose underlie hardware feature decouple refers separation memory access computation pipeline architecture attractive efficient expose hardware detail advantage enable specialization memory access importantly define  primitive semantics understandable compiler flexibly compose modular unified hardware software interface modest programmer hint developed goal develop principle usable framework refer programmable accelerator synthesis involves input kernel minimal programmer annotation define desire functionality proxy generality output synthesizable hardware artifact specialized input application customize hardware software interface logically compiler target acm annual international symposium computer architecture isca doi isca target kernel pragmas kernel architecture description graph ADG decouple spatial arch compiler llvm kernel transforms kernel   hardware mapper efficiency model eliminate due hardware limitation optimize compile kernel eliminate due impossible mapping eliminate performance metric mem mem rtl hardware generation converge accel rtl hardware generation exploration normal compilation legend overview programmable accelerator synthesis framework DSAGEN develop DSAGEN decouple spatial architecture generator depict architecture graph architecture description graph ADG compose primitive component processing switch flexible connectivity framework normal compilation ADG instance hardware  exploration DSE ADG synthesize iterative refinement compiler transforms input kernel decouple dataflow representation version kernel transformation target architecture feature hardware mapper distribute program hardware resource evaluate efficiency metric performance model legal version compile program chosen exploration DSE hardware mapping modify ADG improve efficiency convergence challenge approach programmable accelerator synthesis challenge sufficient hypothetically define template architecture parameter instead extreme choice feature ISA irregular connectivity component closer specialization domain specific architecture dsa compilation modular feature compile modular feature challenge transformation feature approach develop transformation target various hardware feature multiple combination mapping hardware eliminate ADG intelligent exploration DSE framework manipulate ADG improve hardware efficiency challenge vast source repository http github com  dsa framework DSAGEN generate domain specific architecture spatial architecture compiler propose codesign algorithm leverage application aware performance model evaluation objective function integrates novel repair spatial architecture scheduler DSE avoid redundant compilation hardware generation arbitrary topology generate configure hardware non trivial important switch program phase develop architecture aware simulated anneal approach accord evaluation hardware primitive expressive approximate decouple spatial accelerator compiler generate code execution manual version across domain memory irregularity demonstrate capability hardware software algorithm achieve balance performance contribution recognize hardware primitive compose spatial accelerator automate software hardware codesign modular compilation composable primitive repair spatial schedule technique configuration generation irregular spatial topology organization discus background decouple spatial architecture II discus formulation hardware primitive compiler IV DSE hardware generation VI methodology evaluation vii finally discus related IX II  spatial architecture background decouple spatial architecture capability attain performance overhead retain programmability decouple spatial architecture define characteristic decouple customize pipeline program decouple dataflow decouple spatial architecture interface sync interface sync memory processing initial const decouple program mapping handle memory access computation spatial aspect hardware execution network schedule operation expose hardware software interface mapping application decouple spatial hardware involves decouple data access computation operation mapping memory access correspond mapping computation onto processing communication chip network concrete vector dot program decouple dataflow graph memory access coarse grain computation dataflow graph computation unrolled iteration decouple dataflow eliminates implicit memory constraint program disambiguate memory simpler decouple memory spatial architecture compose memory processing switch synchronization later refine component modular primitive mapping program hardware substrate operation mapped onto PEs instruction dependence mapped onto chip network memory generates memory request array mapped memory processing data arrives conventional von neumann model distribute PEs enables concurrency without overhead multi thread memory access PEs instruction dispatch overhead amortize spatial fabric configuration  spatial overview graph approach hardware description modular hardware primitive parameter architecture expressible within specifically request initiator response receiver decouple explicit decouple data orchestration  processing config req resp delay sync config processing config req resp delay sync config operation desire dynamic static schedule dedicate instr per PE temporal instr per PE temporal instruction temporal input output dedicate per temporal per instruction temporal rout connectivity matrix capacity banking bandwidth reorder address ID min max delay buffer backpressure expressiveness memory switch memory controller dimension access inductive memory access implicit vector pad indirect memory access modular spatial architecture component decouple spatial primitive approach develop architecture primitive composable parameterizable yield substantial benefit customization define execution model understood compiler primitive overall architecture described graph architecture description graph ADG describes propose spatial architecture primitive processing PEs perform computation memory abstraction memory switch connection network synchronize phase program component specify datapath bitwidth detailed description execution model parameter important factor tradeoff generality efficiency execution model component perform action  important dimension dynamic static schedule PEs switch static dynamic schedule instruction execution rout static schedule operation data arrival compiler whereas dynamic schedule operation chosen dynamically data arrival dynamic schedule implement logic operand readiness proportional instruction PE moreover network balance rate incoming operand static schedule loses flexibility gain overhead dedicate dedicate instruction rout decision PEs systolic array coarse grain reconfigurable architecture whereas temporally multiplex static instruction rout decision CGRAs parameterized instruction dedicate PEs throughput avoid contention overhead instruction buffer PEs enable instruction concurrency processing PEs addition PEs specify instruction functional fus function hardware generation decomposable fus fus decompose function adder adder dynamically schedule PEs enables conditionally reuse input abstain computation useful operation sparse linear algebra database ops switch central approach flexibility switch input output  rout connectivity matrix describes input output granularity byte switch optionally decomposable bitwidth route finer grain datatypes independently switch complexity determiner tradeoff complexity efficiency complex network multiple switch switch flop output compound rout stage execute cycle connection communication hardware specify connection naturally ADG delay delay essentially FIFOs pipeline balance parameterized depth deeper delay implies compiler timing requirement static schedule delay fix delay dynamic schedule delay buffer drain opportunistically synchronization interface dynamically schedule memory dynamic PEs static static PEs purpose synchronize multiple input computation enable static timing dependent implement fifo buffer configure popped simultaneously presence data coordinate programmable logic configure statically  cgra tile delay pipeline balance proc  dedicate static sched mul bitwise logical bitwise logical cca accelerator MAERI accelerator ctrl mem cgra tile sync sync distribution ctrl cgra tile softbrain accelerator mem architecture description graph   synchronization memory execution model memory arbitrates access concurrent coarse grain memory refer relative synchronize barrier memory parameterized capacity width concurrent presently fix candidate controller linear indirect linear controller address generator  generate inductive memory enable triangular access indirect generator controller SPU generate indirect memory access optionally atomic update operation embed compute within component accepts input configures coarse amount access memory computation graph PEs switch distributes component synchronizes phase algorithm assume programmable core dataflow ISA encode command principle composition benefit ADG abstraction ability customize datapath memory feature parameter related program later discus compiler framework attempt advantage available resource topology overview principle consideration composition statically schedule PEs switch hardware overhead dynamic counterpart input available synchronization guarantee buffering release data coordinate fashion analogously dedicate hardware overhead arbitrate multiple instruction however timing input operand perform pipeline become imbalanced indeed throughput loss proportional imbalance delay allows configurable delay aid compiler compensate enable dedicate efficiently switch PEs regardless static dynamic schedule dedicate hardware generator output appropriate switch connector compiler enforce static dynamic PEs without sync dedicate temporal PEs due overwhelm temporal PE capability limitation ability express exist architecture architecture description graph  compose primitive exist architecture graph demonstrate topological generality ratio datapath flexibility versus switch overhead cca switch limited flexibility softbrain flexible overhead beyond topology exist accelerator approximate primarily CGRAs bound expressiveness explain limitation ADG category limitation DSAGEN feature hypothetically fundamental limitation potential feature coalesce implement memory coalesce irregular access currently banking flexible bus another arbitrary bus topology within architecture network bus memory synchronization output processing alternate core programmability replace core simpler FSMs fix ram heterogeneous core ADG model instance decouple architecture core multiple unique instance custom inter core network fundamental feature limitation memory consistency DSAGEN maintain strict sequential memory access semantics barrier wise synchronization memory access therefore compiler programmer responsible maintain correctness memory speculation DSAGEN speculative execution memory disambiguation     tartan expressible limitation concrete discus DSAGEN approximate accelerator explore  hierarchical mesh static schedule temporal PEs scratchpad approximate  decouple scratchpad PE datapath plasticine scalar vector FIFOs purpose sync datapath compose static schedule dedicate PEs memory pmu combination datapath plus scratchpad  memory datapath nest grain parallelism dataflow graph communicate memory coalesce scratchpad schedule plasticine similarly approximate temporal PEs classic CGRAs static schedule PEs approximate necessarily employ decouple memory domain specific domain specific approximate fus primitive datatypes DSAGEN  diannao instantiate scratchpad static schedule dedicate PEs binary interconnect harder approximate non primitive datatypes clarification goal ADG approximate exist architecture seek compiler rival prior domain specific compiler challenge remainder goal compiler explorer  program representation IV modular  spatial compilation challenge building DSE framework compile domain neutral program representation variety hardware unique combination parameter ISA feature compiler responsibility modular compilation approach compiler overview compilation involves choice program offload concurrency concurrently analyze memory access decouple without violate program semantics translate dataflow transform dataflow IR apply loop transformation apply generic transformation spatial temporal locality apply modular transformation apply transformation specific hardware feature ADG schedule computation resource concurrent program hardware resource code generation generate code spatial hardware configuration ideally compilation fully automate however limitation compiler analysis program instead rely programmer aspect accomplish domainspecific compiler tvm tensorflow assume programmer framework perform loop transformation extract locality loop rely additional information memory aliasing decouple memory access finally rely program offload aspect easily automate whereas subsection program interface compilation generic transformation approach modular compilation program interface typical approach program accelerator domain specific DSL appropriate fix hardware domain goal enable maximum freedom program idiom purpose program interface serf purpose semantics generally information offload memory alias freedom therefore program interface expose information without violate semantics purpose pragmas pragmas usage pragma dsa config pragma dsa decouple pragma dsa offload annotate program pragma dsa offload pragma defines code computation desire offload spatial accelerator pragma dsa decouple pragma informs compiler memory dependence within annotate enforce data dependence unknown aliasing enables compiler hoist involve memory operation code cmp sel data graph loop header loop cleanup graph transform dependence data dependence pragma dsa config pragma defines program scope reconfiguration happens indicates offload concurrent scope pragmas inform compiler concurrency memory reorder information agnostic underlie hardware programmer compiler transformation compilation involves decouple memory computation apply modular transformation spatial schedule code generation decouple memory compute decouple computation memory operation compiler inspects code marked offload pragma slice memory operation typically load llvm address computation analyze llvm  module information later hoist encode memory operation intrinsics slice decouple address computation remain operation transform dataflow representation data dependence transformation mapping onto spatial accelerator transform dependence data dependence variant transformation program dependence graph code graph transform data dependence graph execute selector accord comparison modular compilation compiler optimizes ADG hardware feature perform hardware dependent transformation compiler inspect underlie hardware correspond feature ensure fallback feature guarantee compilation program indirect memory access ideally encode idiom indirect intrinsics however underlie hardware capable analysis transformation pas idiom skip disabled code generation compiler generate scalar operation memory access IV discus technical detail transformation spatial schedule responsibility spatial schedule instruction memory  mapped instruction unmapped instruction compatible PEs memory route instruction operand dependence network  algorithm recompute timing min max instr compute objective timing mapping commit PE yield objective objective converges maximum iters algorithm structure schedule algorithm iteration onto hardware route dependence onto network timing operand arrival static component responsibility extend PEs execution model data dependent mapped PEs dynamic schedule transform predication instruction rate computation  PEs moreover scheduler enforce constraint ADG component execution model communicate adopt stochastic algorithm spirit prior fpga cgra scheduler schedule iteration attempt improve objective remapping instruction algorithm avoid local minimum rout PE resource   objective minimization minimize  objective formulate function prioritizes minimize  PEs network maximum initiation interval dedicate PEs latency recurrence algorithm completes  objective converge stable iteration code generation compiler candidate code transformation chooses estimate performance detail estimation model code generation code generator remove operation offload spatial architecture encodes decouple data access communication controller intrinsics injects memory fence enforce semantics generic optimization enforce dependence stall spatial architecture significantly harm performance idiom useful avoid producer consumer offload consume idiom compiler generate code directly consumer avoids synchronization overhead introduce producer phase enables pipelining producer consumer pragma dsa decouple pragma dsa offload pragma dsa offload pragma dsa decouple int pragma dsa offload int producer consumer repetitive update typical idiom avoid serialization repetitive update array undergo repetitive update compiler inspects data update compiler capability chip synchronization buffer data buffer compiler route data directly producer consumer datapath avoid unnecessary memory traffic memory fence otherwise compiler rewrite update loop tile data update capability synchronization buffer modular code transformation discus modular code transformation resource allocation hardware feature compiler robust computation memory bandwidth accomplish vectorization hardware capability unknown vectorize concurrent program depends efficient schedule exists ADG vectorization becomes modular feature compiler explores dependent memory access dependent memory access kernel perform merge sort database sparse tensor operation program sparse  graph naive mapping program spatial architecture preserve data dependence decision pointer increment backwards introduces recurrence chain limit performance avoid decouple memory access reuse input decouple dataflow automates transformation transformation valid hardware dynamic schedule data consumption data dependent however compiler transformation successful mapping program hardware uncertain exists PEs switch dynamic schedule topology consume resource feature compiler explores pop pop implicitly acc compute pop acc latch acc cmp pop exe pop pop code sparse inner graph data dependence graph decouple cond predication computation inst data dependence  pop generic ctrl dominate comparison dependent memory access transform data dependence indirect memory access indirect memory access atomic update critical workload irregular memory  graph processing sparse matrix operation underlie hardware indirect memory controller compiler vectorize operation however hardware instance idiom memory bandwidth available schedule program therefore transformation modular feature explore compiler  exploration DSAGEN perform automate codesign input program hardware transformation program along grain selection hardware feature iterative graph iterative approach codesign initial default ADG modify ADG random component remove random connectivity without exceed budget schedule input kernel spatial architecture version kernel correspond unroll vectorization factor estimate performance version kernel performance model perform version kernel estimate objective function objective improves ADG objective perf converges subsection improve per iteration novel spatial schedule repair technique performance model DSE repair scheduler challenge DSE consume aspect iteration evaluate performance aspect objective function due performance spatial architecture acc acc acc PEs PEs acc schedule repair repair acc sync elem PEs PEs acc delete PE acc sync elem PEs PEs acc delete PE   acc sync elem PEs PEs acc delete PE   dense vec mult sparse vec mult input decouple dataflow ADG update sched repair reschedule mem mem DSE schedule repair program mapped hardware mapping affect memory resource contention latency critical dependency unfortunately spatial schedule lengthy algorithm practical heuristic sometimes longer exacerbates compiler transformation due modular approach overhead factor insight ADG iteration completely increase network connectivity processing increase performance subset delete improve overhead incrementally  previous schedule valid hardware component program delete remainder schedule valid repair spatial scheduler therefore propose  repair spatial scheduler ADG modification schedule explore update reflect hardware specifically aspect input program delete ADG component delete schedule schedule repair perform attempt repair incomplete schedule advantage hardware feature schedule repair iterative stochastic spatial scheduler described IV algorithm  iterative repair implement initial possibly unfinished schedule DSE input program dense sparse vector explore ADG modification ADG modifier randomly chooses delete PE invalidates timing accumulate sparse scheduler perform schedule repair dataflow accumulate another available PE performance model approach estimate performance transform code estimate ipc ipc insts activity ratio activity ratio limited bandwidth memory dependence within program therefore performance model computes memory bandwidth achieve fully pipelined execution dependence loop dependence impact dependence activity ratio memory bandwidth activity ratio compute minimum ratio bandwidth request bandwidth memory dependence activity ratio compute concurrent computation instance pipeline hide dependence dependence latency concurrent instance analyze data dependence latency available spatial schedule finally execution frequency normalize importance leverage llvm  model approach iterative exploration approach accurate evaluation propose hardware traditional synthesis consume achieve practical DSE therefore analytical regression model evaluation dataset hardware module sample parameter link data width register file etc synthesize analytical model PEs overhead constituent function optimization develop functional multiple function adder perform decompose adder limitation assume chip network topology parameter component significantly affect frequency implement hardware difficulty estimate synthesis timing violation therefore fix switch flop output switch becomes stage datapath pipeline likely network significantly harm critical fix feature DSE similarly feature fix DSE ADG express memory currently assume memory interface fix scratchpad parameter explore parameter core VI hardware generation hardware generator rtl formalizes software hardware interface bitstream encode component spatial architecture local register bitstream encodes programmable information switch bitstream encodes rout information PE bitstream encodes instruction opcodes execution timing static PEs instruction tag PEs synchronization bitstream encodes cycle delay spatial architecture configure load bitstream register configuration extra chip network configuration message rout accord static hardware generator exist multiple configuration configuration data ID destination component identify relevant configuration data relevant data config generation framework arbitrary topology construct configuration minimizes configuration define node ADG minimizes approach span algorithm multiple initial iteratively apply heuristic node nearby shorter maximum converges limitation hardware generator limited capability encode format module future optimization reduce configuration specify register register another potential optimization efficient implementation gate functionality latency throughput frequency tradeoff replace  adder lookahead adder capability generator reuse hardware circuit implement functionality limited reuse hardware adder achieve simd addition currently reuse alignment circuit float divider shift operation optimization circuit functional composition future benchmark  sparse dsp polybench workload ellpack stencil stencil histogram  fft  bicg mvt data workload specification vii methodology ISA compiler riscv core extend clang implement pragmas conveyed metadata llvm compiler riscv gcc assembler backend target accelerator chose accelerator instantiate approximately stress hardware feature softbrain instantiate mesh  dedicate PEs switch  scratchpad memory MAERI approximate similarly softbrain novel topology trigger instruction approximate mesh dynamic schedule temporal PEs assume PEs access decouple scratchpad SPU dynamic schedule dedicate PEs scratchpad  composes static schedule  PEs mesh allows communication synchronization assume accelerator integrate bandwidth cache GB simulation performance implement cycle simulator ADG component integrate gem riscv core core benchmark workload multiple domain workload  benchmark polybench microbenchmarks SPU workload dsp workload target  data workload compiler pragmas IV implement manually mapped accelerator code assembly code baseline compile gcc intel xeon 0GHz analysis implement parameterized cgra generator chisel backend generate accelerator rtl synthesize generate rtl synopsys DC UMC UHD library SVT target 1GHz float matlab hdl coder synopsys smc synthesis construct analytical regression model estimation within explorer evaluation evaluate DSAGEN compiler explorer hardware generator takeaway compiler achieves performance manually tune version modularized compilation feature independently enable disabled accord estimation explorer initial hardware automate DSE generates hardware perf prior programmable accelerator across multiple workload modular compilation performance compiler achieves performance manually tune version performance degradation mainly due lack peephole optimization compiler manual version exploit feature ISA reduce instruction outlier fft  trigger instruction iteration fft stride data access becomes compile version generate request  scratchpad bandwidth manual version peel underutilized iteration combine request avoid modularity demonstrate robustness modularity evaluate performance baseline architecture feature baseline architecture mesh dedicate static PEs network scratchpad feature individually enable disabled replace dedicate PEs PEs balance resource utilization across inner outer loop dynamic schedule  ability handle dependent data reuse aka indirect vectorized indirect load update feature affect performance correspond feature disabled enable polybench workload dense linear kernel mostly perfect loop remove feature performance however dsp workload heavily benefit PEs outer loop computation sparse workload benefit indirect access dynamic schedule due frequent data dependence across workload feature exploration goal exploration demonstrate ability automatically tune grain hardware software feature architecture topology evaluate workload  variety workload irregularity allows DSAGEN  accelerator workload softbrain compiler versus manual tune performance repair versus mapping modular compilation impact performance configuration ideal generate dense neural network evaluate convolution pool classifier kernel regular access allows generate  softbrain domain specific accelerator diannao sparse convolutional neural network workload outer  regular computation data dependent memory access  scnn fix accelerator SPU programmable accelerator sparse workload perform DSE initial hardware mesh capability FU decomposability indirect memory controller explorer estimate performance model objective function perf explorer schedule iteration initialize repair mapping hardware algorithm exit iteration without objective improvement overall objective intensity evolve exploration iteration initialize exploration datapaths mapped initial hardware iteration redundant feature unneeded functional address generation capability remove objective function achieve performance priority resource therefore DSE estimate performance enhance explorer trim redundant resource sparse cnn datapaths onto initial hardware within iteration explorer iteration redundant compute rout resource difficulty mapping  memory bandwidth bottleneck explorer subsequently explorer focus enhance automate exploration  chip network across multiple workload minimize synchronization depth overall explorer achieve objective improvement initial hardware across workload generate hardware prior accelerator model validation validate regression model synthesis bold label correspond hardware DSE generate hardware exist reconfigurable accelerator est synth estimate regression model obtain synthesis obtain prior technology respectively generate hardware estimate synthesis model tune synthesize component alone extra structure timing fabric estimate model somewhat discrepancy estimate softbrain SPU partly due microarchitecture technology difference overhead due protocol modularity validate performance model simulate generate hardware compile program DSE model performance error maximum error maximum error stencil model capture performance impact excessive instruction quality generate hardware comparison DSAGEN correspond specialized programmable accelerator softbrain SPU accord regression model estimation   cnn SPU softbrain respective workload  introduces overhead softbrain speedup favorable objective function domain specific accelerator diannao scnn reference particularly accurate due technology difference  overhead diannao  scnn overhead mainly reconfigurability accelerator specific network diannao DSAGEN irregular network converge perfectly specific optimal topology future improve exploration softbrain assume delay structure eliminate compiler prior schedule repair strategy traditional schedule entire dataflow iteration schedule repair approach DSE iteration hardware update perform schedule iteration  workload stage strategy objective abundant resource hardware schedule remapping schedule succeed within iteration hardware resource become tight traditional scheduler cannot succeed efficient discover entire mapping overall schedule repair objective DSE configuration improve configuration aid performance program configuration dominate configuration evaluate generator multiple mesh spatial architecture PEs constraint configuration dash ideal network node cannot shorter solid actual generator introduces overhead versus ideal IX related DSE purpose processor custom processor framework application specialized VLIW somewhat related proposal target customize VLIW superscalar pipeline codesign another related purpose processor liberty microarchitecture specification generate simulator perform DSE framework expression  lisa none spatial architecture network synthesis network synthesis technique enable customize network topology workload  performs network topology synthesis technique developed irregular network topology  network generator tailor FPGAs  particularly relevant generates network application task graph noc generator address network without computation application onto potentially irregular NoCs perform codesign accelerator framework cgra framework static schedule CGRAs program strategy model framework generic spatial scheduler topology integer linear program DSE explore CGRAs    develop exploration framework tailor dsp application  another template cgra compound functional composition  cgra generator genetic algorithm compound PEs corpus application propose cgra heterogeneous fus amenable DSE spatial compiler DSE parallel program FPGAs plasticine cgra optimizer  fundamentally orthogonal target compilation DSE architecture  IR framework application specific accelerator expose microarchitecture feature primitive difference none multiple execution model dynamic static schedule dedicate temporal PEs perform topology specialize hardware datapath program conclusion broaden potential acceleration develops approach framework DSAGEN programmable accelerator synthesis paradigm accelerator developed compose spatial architecture primitive generate automate codesign codesign compiler understand primitive compose architecture description graph modular compiler transformation robustly target accelerator ISA feature parameterizations topology traditional relatively programmer intervention broadly computer architecture historically grapple layer abstraction hardware software enable efficient fix ISA typical assumption persistent burden suggests ISA hardware software abstraction designer rely domain accelerator instead modular accelerator description purpose enable flexibility explore deeply specialized