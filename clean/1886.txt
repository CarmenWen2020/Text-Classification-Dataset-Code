availability dramatically improve efficiency address translation application contiguous memory however allocate due fragment memory non movable split regular permission status furthermore expensive due memory bloating sparse access application data enable allocation MB presence fragment physical memory via perforate perforate permit OS punch KB physical address allocate address enables benefit presence fragmentation allows permission exist within enhance flexibility addition allows unused elsewhere mitigate memory bloating minimize perforate reuse  entry location translates regular KB performance propose technique cache translation TLBs via cached bitmap tlb enable presence physical memory fragmentation perforate increase applicability benefit minor hardware OS evaluate effectiveness perforate timing simulation diverse realistic fragmentation scenario fragment memory perforate accomplish performance achievable ideal memory allocation performance conventional fragment memory index virtual memory address translation translation lookaside buffer memory management virtualization introduction dramatic increase memory footprint  application efficiency address translation become critical performance bottleneck numerous proposal increase efficiency translation aside buffer tlb widely adopt increase MB 1GB thereby translation coverage tlb entry MB additional operating application however reduce translation overhead improve tlb physical memory bloating application contiguous content effective furthermore cannot promote  KB KB permission physical fundamentally impose translation efficiency memory management flexibility mitigate flexibility overcome aforementioned limitation mitigate propose ability punch KB MB via perforate enables allocate avoids bloating allocate contiguously physical memory handle fragmentation permission increase perforate allocate physical memory  enable situation VA punch perforate overlap  physical virtual mapped physical KB VA perforate sub permission status partial permission within permit perforate remains similarly mapped KB physical enable remainder perforate situation architecture split KB implementation translation non portion perforate comparable performance overhead traditional efficiently arbitrary perforate overlap mapping regular perforate improve tlb performance flexible memory management regular propose exist address translation mechanism perforate entry pte perforate address MB physical memory chunk address pte virtual UI OOVBM  PNQVUFS SDIJUFDUVSF address belong physical address pte calculate translate address address  pte access translation pte address implement shadow PTEs perforate additional address pte enables arbitrary perforate enables efficient identification within perforate translation bitmap cached regular tlb entry bitmap unused perforate pte tlb unused perforate MB unused address translation standard KB bitmap filter access bitmap coarse grain perforate  bitmap indicates KB sub MB perforate access pte translation bitmap reserve physical memory cached tlb along PTEs demand access bitmap filter access virtualized fragmentation due fragmentation hypervisor guest operating address extend perforate dimensional interaction hypervisor guest bitmap contribution overlap MB regular KB enable presence fragmentation efficient implementation perforate shadow PTEs demand tlb cached hierarchical bitmap rapid translation flexibility minimal HW SW advantage exist pte structure walker address guest host fragmentation virtualized evaluate perforate execution simulator diverse realistic fragmentation scenario perforate allocation physical backing MB fragment  allows sub permission portion perforate unallocated avoid physical memory bloat demonstrate perforate enable overlap mapping minor performance degradation fragmentation ratio fragmentation severe randomly perforate performance regular evaluate perforate review challenge previous approach II impact fragmentation architectural IV virtualization software VI evaluate proposal via simulation vii II background compatibility selection available organization KB correspond coverage entry pte PTEs correspond MB 1GB respectively organization easy appropriate data increase hardware tlb capacity multi tlb structure deliver average latency effective capacity architecture tlb entry PTEs tlb entry MB KB array OS operating application effective interface application explicitly request allocate memory linux mmap  flag allocation align desire allocation however interface application memory allocation code friendly interface linux transparent THP THP user automatically whenever opportunity allocate user request allocation align available contiguous mapping kernel allocate transparently whenever user decides modify permission etc transparent kernel split regular entry request kernel transparently promote regular improve tlb performance however sufficient contiguous physical memory explicit expensive compaction relocation exist allocation MB however approach apply variety related numerous prior address translation performance workload improve tlb coverage propose coalesce multiple adjacent translation cluster virtual physical nearby translate permutation memory mapping within propose contiguous translation OS adapt contiguity runtime revive segmentation efficiently translate contiguous memory multiple flexibility introduce translation delay translation cache approach contiguous physical memory fragmentation challenge propose OS efficiently generate contiguous hamper  recent improve linux transparent target latency performance variability memory consumption minimize waste effort compact non movable multiple reduce tlb latency improve walker employ prefetching investigate translation challenge virtualized apply speculation glue  hypervisor contiguous allocation predict mechanism along speculation minimize latency apply approach reduce latency propose non contiguous physical backing intermediate address layer enable core cache non contiguous physical via memory controller tlb approach benefit workload cache propose non contiguous physical memory vii bitmap widely grain memory management prior dram cache heterogeneous memory bitmap finegrained movement storage bitmap tlb access dirty  validity coalesce cluster mapping propose bitmap cacheline overlay grain virtual memory feature bitmap perforate motivation management challenge memory bloating application physical memory allocate waste physical memory memory bloating occurs operating transparent THP aware access application allocate virtual address multiple MB MB align identical permission application access data sparsely MB data allocate physical memory amount actually thereby increase memory consumption KB memory bloating recommend disabled application redis mongodb splunk  perforate address punch regular application OS regular physical correspond perforate efficient memory utilization sparsely performance benefit memory performance VMware transparent linux kernel merge  service virtualized environment memory deduplication service detect content mapping identical memory service increase translation efficiency reduce opportunity identical content decrease previous address regular KB increase identical evaluate conduct  linux virtual machine VM execute mcf benchmark vms consume 6GB  reduce vms regular almost due reduction VM suffer increase tlb translate performance loss performance memory perforate accommodate non identical sub compaction overhead  promote contiguous physical memory however longer memory becomes fragment linux kernel actively compact physical memory contiguous memory contiguous memory memory compaction expensive scan copying physical location update PTEs tlb shootdowns linux performs compaction fault handler increase fault latency background thread consumes memory bandwidth cpu core unfortunately compact device driver redis performance function factor regular memory allocation GB tlb MPKI normalize performance request file cache operating service marked  prevent compaction perforate enable cheaper promotion OS exist generate contiguous movable punch perforate promote punch  sub flexibility reduces OS compaction burden cheaper overhead compaction memory bloating investigate application memory bloat address translation performance regular redis inmemory database configure redis KB significant memory bloating configuration transparent enable allocate memory tlb per kilo instruction MPKI normalize performance MB regular KB memory allocation bloat evaluate performance request random issue server tlb execution tlb MPKI regular benefit increase translation coverage performance improvement request per understand potential perforate trace simulation tlb regular perforate timing performance evaluate gem execution model earlier hardware allocate KB entry redis obtain memory address trace via pin random access fed access trace tlb simulator entry perforate simulation report tlb  regular KB MB perforate respectively redis random access memory cannot drastically reduce tlb however harsh propose technique reduce tlb significantly achieve roughly tlb reduction pure without negative bloating inherent fragmentation understand fragmentation challenge examine memory machine linux 2GB physical memory benchmark compile linux kernel allocates memory user compiler kernel kernel metadata file cache cache performance OS cache memory particularly relevant kernel cache allocation non movable thereby memory compaction allocation evaluate severity kernel compilation memory deplete benchmark attempt allocate 2GB memory benchmark request allocation MB due memory fragmentation benchmark idle kernel compact memory background fragmentation reduce MB application memory investigate potential perforate simulated policy perforate performance evaluation vii MB non movable filter fragment allocate MB perforate conventional MB cannot allocate allocate regular evaluate scenario perforate OS deliver apply perforate creation policy additional 2GB allocate MB perforate task processing memory pressure cache freed benchmark unlike OS deliver MB potential allocate perforate improvement ability allocate perforate due reduction  measurement demonstrate fragmentation severe typical workload ass performance implication perforate scenario simulated performance improvement random access benchmark vii indicates performance improvement perforate execution entire memory allocate perforate performance improvement conventional memory remain regular IV architecture overview proposal standard MB contiguous physical flexible MB perforate non contiguous physical architecture MB KB regular apply combination VA perforate virtual address mapped physical contiguous perforate furthermore perforate virtual address VA address permission allocation KB permission perforate VA another KB physical appropriate permission illustrates   situation address perforate address  mapping permission perforate OS split perforate identify perforate translation identify bitmap sub efficient access bitmap purpose tlb entry cache bitmap demand coarse grain bitmap filter improve storage efficiency latency translate upon standard multi structure shadow entry perforate pte perforate contains physical address MB shadow pte node translation KB addition avoid  tlb handle perforate tlb access translate KB regular tlb future perforate bitmap efficiently exist perforate shadow PTEs access translation KB shadow PTEs access translation perforate pte address physical address MB non portion physical address node translation PTEs address employ shadow shadow node shadow node adjacent correspond node simplifies address calculation shadow node KB offset node address shadow node thereby perforate shadow allocate adjacent buddy allocator extra MB pte bitmap filter avoid additional indirection easy allocate thanks kernel buddy allocator perforate pte contains address MB data shadow pte contains address node access translation shadow PTEs tlb instead access translate KB KB pte instal tlb however accelerate content shadow cache regular cache hierarchy tlb regular KB MB perforate MB KB bitmap identify bitmap per KB sub perforate access shadow pte naive implementation bitmap storage extend pte status along pte entry however approach fold increase tlb capacity node instead decouple bitmap pte contiguously allocate physical memory bitmap physical address KB bitmap location relevant bitmap easily calculate location bitmap storage physical location physical memory MB 8GB translation perforate bitmap KB sub corresponds shadow pte access return KB translation translation directly generate MB physical address perforate efficient maintain coarse grain bitmap serf filter reduce access bitmap coarse grain bitmap generate KB ıve approach tlb entry perforate PP bitmap detection bitmap initiate load KB translation demand approach load bitmap unused bitmap tlb entry filter perforate tlb entry identify bitmap thereby avoid tlb pte MB perforate address translation KB unused available pte repurpose bitmap filter filter indicates correspond coarsegrained bitmap KB MB filter pte cached perforate tlb entry approach avoid access bitmap coarse grain perforate tlb extension leaf latency sensitive tlb untouched accomplish generate KB sub perforate directly tlb install tlb tlb however modify access perforate bitmap access bitmap faster cache tlb entry machine physical address width intel amd FX physical address plus permission assume bitmap tlb entry thereby tlb entry cache perforate bitmap ıve approach load bitmap tlb perforate bitmap entry perforate cache memory access sufficient tlb entry perforate translation translation request tlb perforate tlb service generate KB instal tlb handle filter determines additional access filter bitmap tlb fetch memory access entry fetch via otherwise perforate generates KB tlb entry tlb eventual KB translation entry however approach bitmap unused perforate thereby waste tlb capacity translation efficient approach load bitmap demand tlb capacity translation perforate access propose combine coarse grain filter bitmap perforate tlb entry demand load bitmap data avoids waste tlb capacity bitmap filter bitmap tlb actually access  load address translation perforate tlb lookup logic propose address translation tlb access correspond MB KB entry standard manner translation regular KB MB entry already translate KB entry translation core insert tlb lookup perforate tlb filter bitmap tlb entry filter indicates translation coarse grain perforate KB translation generate MB perforate insert tlb handle future request additional overhead however filter indicates bitmap consult via tlb access already cached tlb memory access access bitmap translation initiate via shadow pte entry KB translation instal TLBs overhead analysis storage overall structure perforate shadow pte KB additional data per perforate plus storage bitmap physical memory HW HW mostly limited tlb controller fetch bitmap walker logic perforate generate KB regular potential performance overhead tlb translation latency increase due secondary tlb access bitmap memory access bitmap rightmost tlb capacity consume bitmap entry additional tlb entry per perforate filter ineffective access increase coverage perforate exceeds maximum increase tlb usage tlb shootdown perforate shootdown invalidate translation perforate bitmap entry tlb entry TLBs generate non entry tlb entry instead individually approach linux kernel flush tlb shootdowns non perforate punch patch exist occurs due  writes  compaction already shootdowns punch patch update perforate bitmap invalidate bitmap entry tlb update bitmap memory bitmap batch exist shootdowns negligible subsequent translation bitmap fetch although update tlb ISA perforate entry entry bitmap entry sub baseline mapping data KB entry perforate entry efficient tlb capacity per tlb flush reduce TLBs tlb shootdowns expensive synchronization participate HW core latency invalidation tlb 2D translation virtualized bitmap filter guest host combine bitwise walker addition update bitmap patch regular shootdown TLBs subsequent translation perforate simply generate translation non similarly punch update bitmap regular shootdown non tlb subsequent translation fault generate access shadow pte KB entry normal regular shootdowns  punch compaction patch already issue virtualization virtualization widely adopt improve utilization consolidate multiple virtual machine physical virtualization guest virtual address gVA within virtual machine VM translate guest physical address gPA virtual physical address VM guest physical address translate host machine address address translation HW 2D nest essential performance virtualized environment virtualized TLBs translation gVA intermediate translation gVA gPA gPA cannot mapped gVA gPA gPA mapping translation intermediate guest regular host machine cannot mapping gVA instead mapping gVA gPA regular mapping gPA perforate virtualized status properly guest host detail translation mapping perforate guest host translation perforate entry tlb perforate guest avoid  guest physical address however host independent layer mapping effort install perforate entry gVA mapping bitmap cached tlb aware guest host mapping therefore walker traverse bitmap mapping bitmap mapping combine bitwise operation insert tlb location host bitmap directly accessible host machine address however location guest bitmap guest physical address access guest bitmap additional gPA translation translation frequently access rarely host cache address guest host bitmap guest register VI operating interaction perforate operating allocate perforate multiple regular KB depends application access fragmentation status memory application access portion perforate perform fragment compact chunk effective bitmap filter tradeoff explore vii allocation OS allocates node allocate contiguous shadow node allocation handle buddy allocator allocation easily modify allocate contiguous OS allocates node manner exist allocation perforate allocate mapping insert pte OS bitmap however allocate lazily subsequent fault OS flexibility lazily allocate physical marked bitmap perforate allocate shootdowns allocate bitmap entry update lazy allocation potentially reservation allocation perforate unallocated perforate reserve actually patch regular actually prevent unused mapping memory bloating bitmap update patch operation tlb shootdowns thereby trading shootdowns memory utilization modify mapping application regular OS remaps regular another  OS  regular punch bitmap II simulation CONFIGURATIONS component configuration processor 2GHz processor cache cycle KB cache cycle MB memory ddr channel tlb cycle entry KB cycle entry MB tlb cycle entry KB MB entry struct cache entry cache entry entry cache entry transition perforate punch perforate perforate OS trigger tlb shootdown affected tlb entry bitmap entry IV perforate patch remove reconstruct non perforate memory compaction unusable memory previously  freed OS compact perforate remove punch patch appropriate tlb shootdown vii evaluation simulation methodology evaluate perforate implement HW OS gem simulator emulation SE mode simulated computational application memory mapping setup prior simulated significant memory mapping application simulation core cache tlb parameter II SE mode model tlb latency multi tlb walker cache delay associate tlb TLBs organize similarly intel skylake microarchitecture tlb contains entry MB entry KB tlb tlb entry MB KB perforate bitmap entry others assume KB MB entry concurrently tlb implement translation cache intel structure cache  finally tlb per core independently core evaluate core performance impact perforate microbenchmark tlb baseline allocation scenario capacity pressure optimal memory allocation conclusion conservative configuration mcf omnetpp libquantum zeusmp spec cpu    suite spec cpu sensitivity portion percentage MB fragment percentage perforate fragmentation percentage unallocated within MB perforate ipc normalize performance baseline KB tlb tlb content breakdown various distribution fragmentation axis portion percentage MB fragment percentage perforate omnetpp impact perforate application explore scenario emulate fragment distribution disperse cluster disperse sub throughout fragment MB cluster cluster distribution perform due bitmap filter secondly severity fragmentation explore portion MB fragment fragmentation within MB sensitivity fragmentation explore performance regard application fragmentation assume memory access scenario tlb random memory access benchmark 2GB dataset tlb MB fragmentation increase conventional split regular reduce effective tlb hurt performance performance impact fragmentation across portion fragment MB axis fragmentation inside curve cluster disperse distribution normalize KB dash curve performance conventional MB KB fragmentation scenario fragment MB cluster corresponds curve frag cluster axis portion potential performance benefit perforate frag traditional MB KB benchmark suite evaluate tlb sensitive difference portion fragmentation portion fragment MB increase towards performance decrease MB KB conventional tlb split due fragmentation reduce tlb coverage increase perforate significantly performance loss fragmentation increase maintain nearly benefit portion increase axis performance decrease tlb extreme fragmentation perforate performance roughly equivalent baseline MB KB essentially therefore KB translation tlb perforate benefit tlb access largely negates benefit breakdown tlb entry scenario portion fragment MB increase portion MB entry tlb decrease perforate entry increase fragmentation perforate increase portion KB tlb increase reduce effective coverage fragmentation per increase fragmentation perforate access bitmap frequently bitmap KB translation tlb occupy tlb entry entry thereby reduce effective coverage fragmentation tlb fragmentation decrease ratio perforate MB tlb entry increase KB decrease analysis suggests performance perforate performance native workload normalize performance KB tlb beyond performance baseline MB KB unallocated allocate unallocated access correspond insert tlb therefore unallocated effective tlb coverage performance extreme unallocated dot curve cluster unallocated curve dot curve fragmentation bitmap filter effective fragmentation performance fragmentation however disperse filter ineffective slightly performance due bitmap lookup breakdown tlb entry allocate unallocated unallocated correspond KB load tlb perforate entry perforate MB bitmap entry data perforate significantly performance environment unallocated particularly cluster unallocated disperse performance portion frag perforate performance perform configuration MB portion perforate faster baseline MB KB tlb distribution perforate perform cluster bitmap filter lookup bitmap thereby additional tlb access bitmap tlb capacity bitmap disperse filter ineffective distribute across cluster distribution allows effective filter avoids performance ipc improvement GTSM perforate ideal MB normalize KB tlb baseline bitmap lookup bitmap insert tlb application performance application performance distribution amount fragmentation portion fragment MB evaluate unallocated workload unused OS assume memory allocate across application perforate performance decrease portion fragment fragmentation within effectiveness filter clearly significantly performance cluster solid distribution disperse dash mcf fragmentation fragment bitmap filter eliminate bitmap access bitmap entry tlb enable effective tlb coverage translation performance libquantum absolute tlb MPKI cluster disperse heavily sensitive translation latency significantly performance disperse fragmentation due tlb access bitmap non filter access fragmentation allocate memory  performance virtualized execution normalize performance KB tlb virtualized remain fragment sub cluster correspond configuration perforate achieve ideal performance fragmentation ipc improvement conventional TLBs fragment comparison GTSM gap tolerant sequential mapping GTSM enables allocation presence memory fault fragmentation memory fault prevent GTSM physical memory MB chunk flexible mapping sub KB generate MB within MB chunk remain sub regular KB allows mapping around fault limit allocation available memory flexible mapping approach punch faulty physical within remapping functional regular thereby enable otherwise faulty utilize perforate GTSM specific fragmentation scenario GTSM target randomly fault zero fragment MB beyond error rate GTSM cannot memory increase walker cache entry GTSM GTSM sensitive walker cache parameter GTSM performance improvement perforate GTSM ideal MB fragmentation scenario normalize ipc KB analysis  MB MB MB fundamental perforate outperform GTSM average scenario limited fragmentation virtualized implement dimensional virtualization simulation infrastructure mapping guest memory guest another host access guest physical native physical memory access augment address translation guest physical host machine address described reading bitmap virtualization reading guest host bitmap addition standard 2D cache dimensional average memory access default perforate beneficial regular due tlb coverage virtualized performance improvement native due increase tlb becomes benefit perforate libquantum perform disperse distribution virtualized context outperforms non perforate baseline configuration fragmentation perforate achieve ideal performance ipc improvement conventional TLBs fragment evaluation explore fragment memory environment perforate effective retain benefit effective tlb across variety fragmentation scenario standard KB MB benefit increase virtualized environment tlb expensive decrease cluster perforate filter becomes effective tlb access bitmap storage conclusion improve translation efficiency increase effective tlb strict requirement contiguous physical memory limit context physical memory bloat application sparse memory usage address inflexibility introduce perforate OS punch KB MB benefit physical backing memory fragment  variation permission remove requirement allocate physical memory reduce bloat implement perforate efficiently building upon exist hierarchical shadow pte entry translate bitmap filter cached tlb perforate benefit extend improvement native environment improvement virtualized environment presence realistic memory fragmentation prevents