conflict performance bottleneck memory intensive workload idealize remove conflict collectively improve performance average multi programmed memory intensive workload propose duplicon cache mitigate conflict penalty duplicate data alternate memory controller freedom source data avoids conflict duplicon cache entirely implement memory controller commodity memory identify address challenge associate duplication duplicate data efficiently identify data duplicate replace stale duplicate data useful evaluation duplicon cache configure MB storage 6GB memory improves performance reduce index conflict conflict duplication associative cache sectored cache demand activates filter usefulness probabilistic replacement introduction memory dynamic random access memory dram organize independent mem  request service concurrently increase parallelism performance conflict request however service serially conflict mitigate conflict request alternatively service another idle data conflict request previously duplicate idle data duplication across decrease likelihood conflict increase storage coherence complexity tradeoff exploit improve performance propose duplicon mitigates conflict duplicate data memory alternate duplicate data access latency average service alternate lower average access latency duplicon effectively cache memory whereby duplicon cache duplicate intel corporation  foundation continued generous financial  research col col col col duplicon cache entirely implement memory controller commodity memory feature associative sectored  tion efficient duplicate data demand activates filter identify duplicate usefulness probabilistic replacement stale duplicate data replace useful duplicate data overwritten evaluation duplicon improves performance reduce  average organize II background information dram motivates data duplication mitigate conflict IV describes component duplicon cache describes evaluation methodology VI discus related vii summarizes II background dram activate access data already activate buffer latency access data currently activate precharge activate desire desire activate command issue desire within activate annual acm international symposium microarchitecture doi micro col    ccd col ccd ccd col col rcd RP rcd RP rcd RP rcd col    command address rcd col col pre col pre col pre RAS RAS RAS command address command address rcd ccd ccd ccd col col col conflict conflict conflict concurrent memory request conflict conflict conflict activate pre precharge circuit limitation impose timing constraint precharge activate operation issue multiple memory request data within latency precharge activate operation perform serially degrade memory latency bandwidth instance request mapping conflict reduces likelihood conflict costly memory architecture fourth generation data rate ddr dram reduce additional partition hierarchically impose additional timing constraint operation additional delay activate operation conflict denote memory request incur additional delay otherwise request mapped organization ddr dram device notation denote partition motivation core thread memory multiple outstanding memory request dimension 8GB ddr dram device evaluation detail concurrent memory request service request conflict conflict conflict precharged request completely serialize service latency dominate tRAS minimum delay activate subsequent precharge pre trp minimum delay precharge subsequent activate dram cycle processor cycle assume ddr dram 2GHz processor service request request activate operation partially overlap tRRD version tRRD minimum delay activates operation proceed tRCD cycle appropriate activate tCCD version tCCD minimum delay writes dram cycle processor cycle service request request overlap extent activates tRRD version tRRD minimum delay activates delay halve similarly tCCD cycle processor cycle service request devise series idealize impact conflict load approximates convert conflict conflict relax WL WL WL WL WL WL WL WL WL WL WL gmean performance improvement conflict conflict conflict conflict conflict request alternative request alternative performance improvement conflict remove mitigate mapping within request service request mapped alternatively service essence convert approximates remove conflict conflict variant timing constraint variant tRRD tRRD tCCD tCCD   essence convert however remain conflict suffer serialize  activates approximates remove conflict relax mapping constraint request alternatively service convert access access across eleven core multi programmed workload memory intensive spec benchmark graph workload II remove conflict improve performance across workload average remove conflict improve performance across workload average remove conflict improve performance across workload average remove significantly improve performance remove improve performance remove isolation approximate remove conflict request service relaxation data request access  delay burst subsequent fully duplicate unfortunately duplication unacceptable storage coherence overhead duplication infeasible limited  cation sufficient remove conflict penalty mapping relaxed request alternatively service mod retains benefit improve performance across workload average restricts duplication request alternatively service mod improves performance across workload average substantial duplication data oppose duplication reduce duplication apply cache principle duplicate subset data propose duplicon cache technique mitigates penalty conflict duplicate data alternate identify address component duplicon reserve storage duplicate sec tion IV identify granularity duplication IV duplicate data IV duplicate data memory controller IV limit duplication overhead IV ensure coherence duplicate IV data duplicate IV duplicate data replace IV IV duplicon cache data reserve storage duplicate cache data tag duplicon cache data reserve duplicate data reserve physical memory address boot reserve physical address reserve storage byte physical memory capacity reserve byte address duplicate data operating OS byte physical memory avail allocate memory reserve storage evaluate configuration reserve MB storage 6GB physical memory storage overhead granularity duplication width ddr dram data bus individual dram device narrower interface width data bus device tag offset tag offset byte bus col BG col BG col col index byte bus col BG col BG col col byte bus col BG col BG col col byte bus col BG col BG col col byte bus col BG col BG col col byte bus col BG col BG col col index tag index reserve storage reserve physical memory duplicate physical address duplication destination mapped duplicon cache duplication destination associative duplicon cache channel rank channel rank controller controller memory memory cpu rank rank memory controller channel rank interface device device dram device combine width data bus combine dram device dram rank device rank device device device rank lockstep command address tuple specifies byte data rank ddr dram transfer data burst typical burst access burst succession transfer align transfer burst belong another burst etc specifies byte data rank transfer burst access granularity access ddr dram byte byte duplicon cache granularity access dram duplicate data byte granularity associativity duplicate data rank data command address bus dram processor data command address bus channel typically multiple channel data dram uniquely identify channel rank BG col tuple channel memory controller hierarchy memory controller channel rank mapping function physical address   BG col tuple component tuple compute hash subset physical address mapping function channel imply channel rank imply rank per channel imply per per specify byte byte data bus offset within mapping evaluation maximize baseline performance mapping mapping channel data memory location address data duplicate location reserve storage access reserve storage address dictate reserve storage access duplicate data reserve storage principal decision duplicon cache various constraint tradeoff duplicate location reserve storage span overlap hash address overlap almost exists almost entropy address maximize interleave minimize conflict mapping scheme outside xor ing multiple address duplicate data across channel undesirable necessitates data memory con  incur additional data movement  con duplicate data within channel data reside channel span reserve  duplicate reserve storage almost span channel channel usually entropy address maximize channel interleave constraint exist duplication destination location destination channel flexibility exists duplication rank extreme mapped scheme duplication destination address identical address  replace BG BG BG BG mod scheme data duplicate location BG alternatively duplicon organize associative cache addition  replace BG BG completely duplication destination address meaning data duplicate BG analogy traditional cache traditional cache mapped scheme data cached location associative scheme data cached cache BG associative duplicon cache traditional cache address offset dictate byte offset within index dictate location data cached tag tracked differentiate data index breakdown offset index tag mapped associative scheme mapped cache corresponds data alternatively service mod associative cache corresponds request alternatively service mod associative cache performs associative  tion tag duplicate duplicon maintains tag dedicate SRAM memory controller data duplicate tag upon memory request duplicate exists duplicon cache ordinary pro  cache duplicon cache MB evaluation tag data expensive duplicon reduces storage tag via sectored cache cache sector dram sector address tag reduce tag tag additionally maintains valid per sector duplicate valid per duplicon cache duplicon valid valid sector collectively valid valid mask channel memory con  tag maintain channel duplicate data within channel channel mask valid address tag activates counter useful demand mask valid tag activates counter useful demand channel tag address non channel non index duplicon cache tag non belong sector address tag index address index tag address tag identify sector dram sector contains valid mask identify valid data demand activates counter DAC saturate counter duplicon cache insertion policy IV useful duplicon cache replacement policy IV tag channel access duplicon cache address tag sector correspond valid mask address tag tag KB channel evaluate configuration KB channel cache duplication data duplicate duplicon cache data memory normal request data memory normal request data memory controller duplication request appropriate location storage duplication request queue service memory controller normal request reduce interference normal request already interfere service request typically memory controller buffer batch request request service without interference buffer drain duplicon   relies buffer batch duplication request minimize interference buffer duplication request simply coherence exist duplicate invalidate request clearing appropriate valid mask tag entry addition buffer remove pending duplication request increase buffer hardware complexity exist buffer already data buffer request subsequent request duplication policy demand activates filter duplication incurs non trivial storage extra memory traffic important duplicate data likely impact program performance duplicon criterion data duplicate duplicon data access via demand oppose prefetch request request prefetch request demand request request likely program critical duplicon data suffers dram conflict access incur longer latency criterion counting demand activates data demand activate activate demand request demand activates identifies demand non buffer access data buffer activate duplicon demand activates tag maintains saturate demand activates counter DAC cache sector IV allocate sector tag demand activate increment DAC subsequent demand activate duplication proceeds DAC surpasses threshold thrsh threshold duplicate access demand activates swept thrsh sweet evaluate configuration duplicate parameter insertion duplication policy duplicate multiple duplicate data decrease likelihood conflict data storage duplicate duplicate replacement policy duplicon cache limited storage associativity fully occupy overwrite exist sector replace allocate bypass usefulness duplicon adopts replace  policy tage predictor usefulness duplicate cache sector via useful tag IV sector marked useful become useful duplicate sector duplicate source request conflict sector marked useful definitely cannot replace periodically useful swept useful reset reset useful memory request although sensitivity reset useful demand activates counter DAC cache sector memory invalid DAC allocate cache sector cache sector empty monitoring DAC thrsh allocate cache sector demand activates increment DAC duplicate duplicate useful DAC thrsh useful allocate cache sector duplicate access writes prefetches duplicate data sector replace duplicate useful DAC thrsh useful allocate cache sector duplicate access writes prefetches  data sector replace probabilistic replacement useful protects sec tor duplicate useful overwritten sector sector monitoring duplicate useful duplicate useful introduce parameter probability sector monitoring duplicate useful replace properly chosen parameter beneficial sector monitoring duplicate useful become useful eventually replace sector perform sweep parameter machine cache sector cache sector invalid transition monitoring demand activate sector allocate sector monitoring DAC incremented sub sequent demand activate DAC thrsh sector transition duplicate useful data duplicate subsequent access prefetches writes sector allocate sector monitoring  useful replace probability another allocate replacement occurs address tag update valid mask useful demand activates counter sector monitoring sector duplicate useful promote duplicate useful duplicate sector duplicate useful replacement useful reset sector duplicate useful  duplicate useful duplicate monitoring useful DAC thrsh activate demand DAC thrsh duplicate useful useful replace reset invalid DAC activate demand replace activate demand thrsh DAC thrsh useful thrsh cache sector diagram cache sector allocate empty cache sectored available replace exist cache sector replace cache sector allocate cache sector increment DAC duplicate exists threshold cache sector allocate DAC duplicate faster access buffer duplication request duplicate valid valid mask source source duplicate cache sector useful demand activate summarizes sequence request summarizes sequence request action enclose boldface evaluation methodology evaluate mechanism execution driven cycle accurate simulator core processor frontend simulator  simulator model contention queue conflict throughout cache hierarchy detailed ddr SDRAM model model tcl  threshold cache sector allocate DAC buffer duplication request duplicate valid valid mask invalidate exist duplicate pending duplication request request trp tRCD tRAS trt tCCD tRRD AW  describes baseline  ration chip model McPAT dram model CACTI conflict probability dependent thread ratio ratio likely conflict intel xeon processor server cpu thread ddr channel server typically configure rank per channel optimal memory performance load channel beyond rank channel frequency hurt performance per rank rank per channel channel thread thread ratio evaluate configuration channel rank per channel thread thread ratio thread ratio hence evaluation conservatively underestimate impact conflict mimic virtual physical address trans  simulator pas virtual VPN concatenate processor ID hash function paul hsieh  generate baseline configuration core issue entry rob RS hybrid predictor ghz cache KB cache KB cache byte cache cycle latency associative MB byte cache cycle latency cache associative inclusive memory entry memory queue FR FCFS controller policy prefetcher prefetcher distance queue feedback prefetching FDP throttle prefetcher dram channel rank channel rank 8GB ddr chip bus frequency 6GHz ddr 2GHz tRCD trp tcl KB buffer KB physical frame combine offset physical address dram chan  address compute mapping function generate physical address processor ID virtual physical  function ensure virtual benchmark multi programmed workload mapped physical frame introduce additional virtual physical hash simulation already maximize entropy channel consequently conflict rate evaluation probably conflict rate achievable actual hash function xor memory intensive spec benchmark thread cache llc per kilo instruction MPKI without prefetching along graph benchmark  core multi programmed workload benchmark workload II workload workload simulated application workload instruction representative simpoint static structure dissipate completion entire load dynamic counter update upon benchmark completion report harmonic IPCs chip multiprocessor cmp performance harmonic IPCs reciprocal average normalize turnaround ANTT fairness throughput   graph report harmonic IPCs unless otherwise additionally report speedup unfairness perform configuration speedup differs harmonic II  multi programmed WORKLOADS workload WL bwaves graph lbm mcf WL bwaves lbm mcf sphinx WL bwaves lbm omnetpp milc WL gemsfdtd bwaves graph leslied WL gemsfdtd graph milc soplex WL gemsfdtd lbm mcf libquantum WL gemsfdtd leslied omnetpp soplex WL graph leslied libquantum omnetpp WL leslied libquantum soplex sphinx WL libquantum mcf milc sphinx WL milc omnetpp soplex sphinx IPCs speedup throughput equation harmonic IPCs  speedup WS unfairness    WS   unfairness max  alone  alone  alone min  alone  alone  alone core  ipc application alone core cmp core idle  ipc application core application concurrently core alone cycle application alone  cycle application application performance analysis ideal realize performance ide  performance potential duplicon cache actual realize performance idealize  recall request alternatively service mod effectively idealize duplicon cache everything already duplicate data duplicate alternate duplicate available duplicate demand activate filter tag reserve storage infinitely duplication request interference idealize assumption remove realistic duplicon cache implementation data encounter service alternate introduce remove WL WL WL WL WL WL WL WL WL WL WL gmean performance improvement ideal max max filter max filter GB max filter GB max filter MB max filter MB max filter perform duplication request MB ideal realize performance improvement potential reduce average potential performance gain limit maximum duplicate data assign alternate encounter subsequent access alternatively source data previously request service alternate constraint potential performance gain justifies choice limit maximum duplicate IV WL WL limit max  duplicate actually improve   source alternate actually reduce buffer locality alternate buffer locality improves limit duplication request interfere however conflict penalty data duplicate another considers demand activates filter IV demand activates filter reduces useless duplication limit duplicate decrease performance gain potential model infinite tag tracked demand activates dram encounter recall duplication demand activates threshold thrsh data threshold source alternate average demand activates filter reduces potential workload WL WL WL demand activates filter limit duplication buffer locality improve performance duplicon cache infinite 8GB 2GB MB MB average performance gain respectively duplicon cache additional WL WL WL WL WL WL WL WL WL WL WL gmean performance improvement demand activates filter usefulness usefulness demand activates filter neither performance without demand activates filter usefulness ing gain additional memory tag storage assume duplication considers actually perform duplication request performance gain performance gain realize constraint effectiveness insertion replacement policy  con employ demand activates filter IV reduce useless duplication usefulness IV useful duplicate importance mechanism performance gain mechanism demand activates filter remove monitoring remove diagram usefulness remove duplicate useful remove demand activates filter usefulness remove clearly mechanism remove demand activates filter average performance gain remove usefulness filter average performance gain remove average performance gain synergy mechanism usefulness actual duplication outcome something duplicate WL WL WL WL WL WL WL WL WL WL WL gmean performance improvement WL WL WL WL WL WL WL WL WL WL WL gmean performance improvement speedup WL WL WL WL WL WL WL WL WL WL WL gmean unfairness duplicon cache baseline MB llc baseline MB llc performance comparison baseline llc metric harmonic IPCs speedup unfairness actually later whereas demand activates filter heuristic heuristic demand activates filter suitable duplication usefulness rigorously evaluate duplicate performance comparison equivalent baseline duplicon cache tag non trivial amount storage KB evaluate configuration detail additional storage alternatively elsewhere chip improve   increase chip cache llc evaluate MB associative llc increment llc increase extra KB nearly amount storage nonetheless conservatively duplicon cache MB llc con baseline MB llc con addition baseline MB llc llc con addition reporting performance harmonic  report speedup unfairness unfairness metric comparison duplicon outperforms baseline MB llc workload metric duplicon  baseline MB llc duplicon additional chip tag extra justified storage analysis tag tag dedicate SRAM memory controller tag entry address tag valid mask demand activates counter useful width compute address tag tag associative scheme physical address physical address valid mask duplicon cache valid sector valid demand activates counter empirically demand activates counter threshold saturate counter useful tag entry tag per recall index tag non channel non index physical address physical address tag KB per tag KB channel recall maintain tag per channel configuration channel storage KB KB non negligible acceptable amount storage uncore floorplan processor performance sensitive uncore latency oppose core latency dram storage duplicon incurs MB core memory capacity overhead normal fluctuation peak  memory utilization datacenter already exceeds MB core reasonably provision absorb additional overhead datacenters typically around memory duplicon introduces extra extra leakage tag extra dynamic due tag access extra dram duplication request model tag cache McPAT model access tag access cache contribution cache account duplication request CACTI dram model duplicon reduces workload reduce WL WL WL WL WL WL WL WL WL WL WL gmean duplicon cache evaluation average saving reduce workload execution VI related principle duplicate data reliability performance raid establish aware prior specifically duplicate data dram reduce conflict data duplication dram propose RowClone duplicon differs significantly RowClone data duplication RowClone perform program array copying zero duplication RowClone architecturally visible explicit software via  instruction contrast duplicon cache duplication perform   completely transparent software reduce memory latency modify dram mapping data tiered latency dram partition subarrays isolation transistor cached data charm subarrays aspect ratio mapped dynamic asymmetric subarray dram lisa built upon tiered latency dram charm propose mechanism data adjacent subarrays bulk data transfer migrate data subarrays lisa reduce precharge latency multiple clone dram reduce access latency multiple physical logical increase reduce latency however scheme conflict request serially although queue delay reduce conflict request contrast duplicon allows conflict request service concurrently addition scheme commodity dram duplicon micron reduce latency dram  fujitsu  reduce per bitline  SRAM density SRAM faster access latency dram numerous exam  SRAM cache dram however approach per commodity dram cannot memory storage whereas duplicon cache built commodity dram propose reduce conflict via OS partition approach problematic per thread isolation per thread achieve performance processor thread memory channel rank per channel intel xeon processor thread ratio furthermore thread ratio per thread guarantee thread conflict improve performance improve physical address mapping thread conflict ideal mapping  alter mapping dynamically feedback approach problematic data become mapping alter relocate data location expensive performance  aware prefetch issue  increase par  prioritize prefetches baseline implementation effectively already    prefetches request service become salp reduce conflict penalty operation overlap subarrays however salp dram duplicon duplicate data across rank channel source data alternate rank rank refresh propose duplication reduce conflict vii conclusion dram conflict significantly degrade program performance duplicon cache effective technique mitigate conflict penalty identify duplicate data across multiple duplicon built exist commodity dram dram duplicon associative sectored architecture allows efficient duplicate data demand activates filter identify dram duplicate usefulness probabilistic replacement useful data overwritten stale data replace evaluation duplicon improves performance reduce average