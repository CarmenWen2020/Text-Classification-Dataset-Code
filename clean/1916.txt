dram access latency bottleneck performance access data dram memory controller activates dram array restores activate performs operation activate  array activation restoration operation responsible portion dram access latency frequent restoration operation perform dram fully restore activate dram exploit reduce restoration latency dram periodically refresh avoid data loss due leakage dram refresh partially restore refresh correctly detect data dram activate partially restore activation correctly detect data however partial restoration carefully activate restore minimum undermine benefit complementary mechanism reduce activation highly enable effective latency reduction activation restoration propose aware ahead partial restoration cal cal consists component cal accurately predicts access restoration operation activation cal predict access refresh reduce restoration ensure amount partial restoration maintain benefit reduce activation highly implement cal fully memory controller without dram module across variety application cal improves average performance core reduces average dram consumption introduction memory dram access latency become critical bottleneck performance dram capacity increase due manufacturing technology dram access latency decrease significantly decade due combination increase core application increasingly data intensive inherent limitation increase memory bandwidth dram access latency become obstacle improve overall performance dram access latency predominantly compose latency fundamental dram operation activation restoration precharge dram data  array data amount capacitor dram memory controller activate array contains target activation correspond bitline amplifier detects data bitline data latch buffer memory controller issue command bitline  amount compensate depletion avoid data loss dram restore restoration memory controller issue command activate memory controller  array empty buffer prepares array activation operation dram capacitor leak access prevent data loss dram issue periodic refresh operation refresh operation brings ddr dram refresh normal operating prior exploit reduce activation restoration latency dram access refresh recently within contains amount leakage restoration refresh operation mechanism exploit observation reduce activation latency highly likewise activate schedule refresh restoration operation fully restore refresh operation restore truncation mechanism partially restores access amount ensure refresh operation correctly data restore clarity consistency opportunity reality opportunity TU OOVBM   ref acc acc acc restore ref min decay normal restoration ref acc acc acc ref decay restore refresh correctly min refresh partial restoration decay ref acc acc acc ref restore access correctly min cal partial restoration normal restoration memory access acc refresh ref restoration restore truncation restoration cal truncation reduce dram access latency achieve benefit partial restoration observation restoration dram addition partial restoration  dram partial restoration  reactivate dram enable access latency reduction recent dram access temporal locality  likely access predict currently activate activate partially restore future activation correctly data partial restoration reactivate dram performance benefit latency saving partial restoration mechanism reduce activation latency highly naive approach partial restoration reduce minimum activation previously highly longer benefit activation latency reduction mechanism optimal amount allows perform partial restoration reduce restoration latency advantage activation latency reduction mechanism maximize overall access latency reduction observation goal mechanism effectively enable partial restoration refresh  effectively exploit benefit activation latency reduction propose aware ahead partial restoration cal cal balance activation restoration latency reduction reactivate maximizes overall reduction dram latency cal consists component cal ahead future memory access predict activate dram reactivate predictor achieves accuracy core application multi core workload average cal prediction schedule refresh activate apply aware partial restoration observation restoration latency reduction activation latency reduction cal partially restores dram activate maximizes overall access latency reduction due restoration activation evaluation cal improves performance ddr dram reduces dram average across core workload performance benefit cal robust across mechanism parameter management policy address mapping scheme restoration operating cal outperforms restore truncation ChargeCache stateof exploit partial restoration  respectively outperforms employ combination restore truncation ChargeCache core workload cal dram chip module combine easily complementary dram architecture optimization performance improvement contribution dram access future safely apply partial restoration reduce restoration latency however restoration latency activation latency reduction highly overall dram access latency reduction achieve balance restoration activation latency reduction propose aware ahead partial restoration cal mechanism effectively reduces dram access latency carefully exploit partial restoration activation latency reduction cal dram chip module implement completely memory controller comprehensively evaluate performance efficiency cal cal substantially improves performance efficiency ddr dram demonstrate cal performance gain robust across mechanism parameter background introduce background dram organization fundamental dram operation discus mechanism exploit dram reduce access latency dram dram organization memory subsystem dram organize hierarchical manner topmost hierarchy memory channel channel connects dram module pin limited bus processor channel memory controller sends command manages module channel module consists multiple dram chip chip contains dram dram consists capacitor data access transistor organize perform operation parallel contains multiple dimensional array dram subarrays highlevel subarray subarray wordline enable access transistor activate bitline data activate bitline local amplifier amplifier subarray buffer dram amplifier buffer wordline bitline wordline bitline dram subarray organization structure chip dram module grouped rank cache dram distribute across chip rank cache chip rank access concurrently respond dram command fundamental dram operation fundamental operation perform access data dram activation dram data buffer restoration ensures drain dram activation restore prevent data loss writes perform data dram architecture ddr dram employ contains dram module activate buffer precharge release data buffer memory controller issue writes activate prepares activate timeline command issue perform cache data memory controller issue command activate pre precharge restoration explicit command instead trigger automatically command spent operation dictate timing parameter dram vendor command operates granularity simplicity dram operation affect dram tRCD tRAS trp activation activation restoration precharge timing parameter tRCD burst twr timing parameter pre pre command timing parameter reading data dram activate restore initial precharged bitline voltage vdd vdd dram voltage wordline therefore bitline disconnect capacitor memory controller issue command wordline thereby dram capacitor bitline voltage capacitor bitline bitline voltage bitline vdd amplifier sens deviation bitline amplifies deviation correspondingly phase refer amplification eventually voltage bitline voltage vdd wordline bitline capacitor vdd precharged vdd vdd amplification vdd restoration dram operation amplifier sufficiently amplify data bitline voltage vdd memory controller issue command access data buffer command specify timing parameter tRCD command issue amplification phase voltage bitline voltage bitline vdd fully restore correctly update dram request latency fully restore timing parameter tRAS dram request fully update twr restoration bitline precharged pre command subarray future access disconnect bitline lower voltage wordline reset voltage bitline vdd precharge operation specify timing parameter trp leakage refresh dram leak disconnect bitline described dram access fully restores access eventually decay data cannot correctly maintain data integrity dram periodically refresh accord ddr ddr dram specification dram refresh achieve dram chip assign refresh bin bin refresh auto refresh command ref interval ref command refresh interval tREFI ddr ddr dram chip maintains internal counter bin refresh receives ref command prior assume memory controller mapping bin address memory controller knowledge bin refresh correspond bin exploit reduce latency conventional dram chip perform activation restoration operation fix latency timing parameter however prior exploit reduce activation restoration latency dram noticeable activation latency correspond voltage perturbation bitline activation faster consequently amplifier ChargeCache mechanism exploit insight safely reduce tRCD tRAS timing parameter highly ChargeCache recently access amount elapse restore therefore  activate within interval ChargeCache tRCD tRAS reduces overall dram access latency approach apply reduce restoration latency conventional dram chip command trigger restoration operation fully restores activate likewise refresh operation fully restores fix interval DDRx dram restoration operation fully restore schedule refresh restoration operation propose restore truncation mechanism partially restores retain data refresh latency partial restoration restore truncation refresh interval sub activate sub closest refresh operation refresh therefore restore partial restore truncation activate earlier sub restore partial longer refresh operation restore reduce decrease tRAS twr timing parameter reduce overall dram access latency reduces motivation discus prior propose mechanism reduce activation latency  restoration latency  principle advantage opportunity latency reduction complementary exist approach apply concept partial restoration  addition refresh perform detailed opportunity offs related perform partial restoration reactivate across core multi core workload experimental methodology discus observation emerge  opportunity apply partial restoration reactivate reduce restoration latency reduce activation latency highly reduction partial restoration reactivate discus restoration operation memory access refresh operation restore restore truncation mechanism insight reduce restoration operation latency activation trigger restoration shortly refresh operation likewise activation shortly another activation  reactivate similarly reduce latency restoration operation trigger earlier activation understand potential partial restoration  reactivate distribution  access interval define pre command command across memory operation application access access interval access refresh interval pre command refresh operation discus restore truncation categorizes access refresh interval sub methodology distribution access refresh access access interval core core workload interval distribution category  observation core core workload memory access refresh restoration latency refresh happens fix interval independent memory access refresh interval sub memory access sub tends unlike access refresh interval vast majority access access interval core core workload due combination access locality application conflict due conflict access likely due conflict reactivate access prior demonstrates partially restore correctly yield decrease restoration latency partial restoration  mechanism predict reactivate prediction restoration  significant diversity access access interval distribution sub additional benefit classify interval sub significantly simplify mechanism access access interval interval within  accurately predict access access interval  access interval relationship access access interval core core workload access access interval otherwise classify interval dram access entire execution core workload core workload classify access access interval access access interval highly likely conclude simply access access interval accurately predict access access interval balance activation restoration latency reduction discus prior activation latency reduce dram combine activation latency reduction highly partial restoration reactivate however partial restoration reduce eliminate ability reduce activation latency highly reactivate partial restoration reduces longer highly  naively combine activation latency reduction mechanism restoration latency reduction mechanism partial restoration mechanism maximize restoration latency reduction combine mechanism yield slight improvement individual mechanism fundamental restoration latency reduction activation latency reduction exploit maximize overall reduction dram access latency understand tradeoff perform spice simulation core dram circuitry decoder capacitor access transistor amplifier bitline capacitance resistance ptm transistor model parameter  model spice simulation command issue affect activation latency distribution access access access refresh interval core core workload interval express millisecond distribution access access interval core core workload bitline voltage activation dram initial activation activate restoration activate partial restoration restores voltage  restoration activate almost restoration refresh activation minimum activation tRCD restoration tRAS latency exploit highly  voltage operation  access restoration voltage vdd quickly activation minimum partial restoration lose amount tRCD reduction allows significantly reduce tRAS tRCD tRAS reduction tRAS  bitline voltage normalize vdd  access   aer  aer  aer    tRCD       restoration tRCD activation tRAS restoration latency reduction heuristic approximate maximum benefit tRCD tRAS reduction quantify  benefit partially restore voltage      equation   tRCD reduction    reduction tRCD tRAS partially restore voltage minimize overall dram access latency maximize  without sacrifice data integrity min voltage guarantee data integrity partial restoration recall apply partial restoration reactivate refresh within precharge precharge operation voltage vmin voltage data correctly dram capacitor data amount decay min ensure decay rate  voltage vmin min vmin  monte carlo simulation spice model variation component vmin vdd model decay rate  employ linear decay model conservative actual document exponential decay behavior   vmin vdd  voltage restoration vdd equation  vmin  equation min vdd maximum  vdd spice simulation   equation  partial restoration voltage vdd restoration latency reduction activation latency reduction perform sensitivity partial restoration voltage summary goal motivational conclude opportunity apply partial restoration  reactivate reactivate conservative prior assumes vmin vdd predict accuracy restoration latency reduction activation latency reduction highly  maximize overall dram access latency reduction conclusion goal mechanism effectively exploit partial restoration reactivate refresh cal observation propose aware ahead partial restoration cal dram cal predict dram reactivate refresh perform careful partial restoration maximizes overall access latency due reduction restoration activation latency cal consists component cal access access interval predict activate within cal prediction along information schedule refresh restoration latency reduce component enable hardware structure timer implement memory controller timer access access interval recently access cal allocates entry timer precharged access timer timer indicates highly likely access access cal timer entry exists timer non zero likely access access latency cal reduces activation restoration latency highly reduces restoration latency otherwise timer illustrates structure timer timer associative structure indexed dram address access access interval recently access dram timer entry contains tag dram address timer elapse precharged partially restore PR zero entry allocate whenever partially restore valid zero unallocated entry operation perform cal timer insertion cal insert entry whenever memory controller issue pre command timer implement per core evaluation assume core dedicate timer per core timer avoid tune optimal core simplify organization potentially evict exist entry cal tag entry address valid PR zero timer initialization whenever precharged cal initializes timer timer update entry timer timer zero timer decrement timer lookup memory controller issue command cal query entry exists entry exists cal information reduce activation restoration latency cal PR entry partially restores cal PR partially restore fully restore access access interval pre insert timer update evict pre lookup timer tag timer PR pre initialization overview timer operation maintain timer whenever precharged cal activate allows cal access access interval predict access access interval  access interval cal query timer entry precharged entry exist cal insert entry timer contains fix entry entry insertion evict exist entry lru replacement cal initializes entry timer access access timer resolution timer decrement timer entry millisecond prior  meaningful exploitation resolution exploitation timer decrement entry timer timer timer correspond entry activate access access interval partially restore PR timer entry exist entry evict evict entry partially restore PR cal fully restore entry evict maintain data integrity detail cal fully restore maintain data integrity timer reduce latency cal timer activate reduce activation restoration latency timer indicates access access interval category timer recall timer counting timer indicates precharged currently  access interval cal reduces activation restoration latency reduce latency PR timer zero indicates precharged longer access access interval cal reduces restoration latency reduce activation latency without possibility data loss PR timer zero indicates precharged likely access access interval cal reduce activation restoration latency PR cal cannot exist entry timer assumes category ensure reliable operation handle access access interval timer zero  timer entry evict cal correspond entry partially restore PR partially restore anymore cal access access interval access access interval actually entry timer zero longer accurately tracked entry evict maintain data integrity cal fully restore minimum amount correctly cal immediately issue pre command preempt pending command memory controller pre activation restoration latency ensure fully restore ensure command issue without violate requirement cal guarantee command plenty schedule command ensure cal initializes timer partial restoration latency workload evaluate extra command perform fully restore partially restore performance overhead entry timer per core evaluation account overhead cal significant speedup outperforms mechanism reduce activation restoration latency methodology modify version ramulator source cycle accurate dram simulator conjunction cpu cache model pin evaluate cal mechanism detailed configuration parameter simulated latency parameter cal mechanism obtain timing parameter spice model described component parameter processor core ghz issue entry inst MSHRs core cache MB core cache memory controller entry RD WR request queue FR FCFS schedule policy dram ddr mhz bus frequency channel rank baseline tRCD tRAS twr ChargeCache entry core associative lru replacement policy cache duration reduce tRCD tRAS restore reduce tRAS twr truncation sub cal entry core associativity lru replacement policy reduce tRCD tRAS twr within simulated configuration model prior capture component evaluate cpu core cache chip interconnect dram model multiple McPAT cpu core CACTI cache orion interconnect version  dram modify accurately capture consumption cal estimate overhead cal McPAT mechanism parameter cache associative structure cal timer entry per core ensure comparison evaluate ChargeCache capacity associativity replacement policy highly access cache  workload evaluate thread application tpc  memory schedule championship  spec cpu benchmark suite  identify representative phase application classify application category memory intensive cache per kilo instruction MPKI memory non intensive MPKI evaluate cal multicore application multiprogrammed workload load memory generate workload application memory intensive thread application multiprogrammed workload core executes billion instruction report instruction per cycle ipc speedup thread application speedup performance metric multiprogrammed workload evaluation cal conventional baseline memory subsystem memory latency reduction mechanism ChargeCache CC reduces tRCD tRAS highly simulate entire software stack service context switch VM exit context switch VM exit timer flush incur performance overhead however employ timer entry overhead context switch additional pre command fully restore entry flush calculate overhead approximately overall execution context switch frequency per correspond overhead around restore truncation RT reduces tRAS twr refresh mechanism naively combine technique reduce activation restoration latency  combine mechanism partially restores refresh restore truncation reduces activation latency highly partially restore ChargeCache  partial restoration mechanism cal greedily maximizes restoration latency reduction without impact potential reduce activation latency reduce latency cal ChargeCache restore truncation addition performance comparison idealize  version latency reduction mechanism upper bound potential speedup various mechanism  access reduce tRCD tRAS latency ChargeCache  restore reduce tRAS twr latency restore truncation  activate restore reduce tRCD tRAS twr latency cal impact performance performance improvement core speedup improvement core application workload memory intensity observation II iij II speedup core II iij II speedup core cal outperforms mechanism CC RT   core cal average speedup memory non intensive application memory intensive application core cal improves speedup average workload memory intensive category respectively across core workload average performance improvement cal carefully balance benefit offs activation latency reduction restoration latency reduction cal outperform   naively combine activation restoration latency reduction mechanism demonstrates judicious cal important improve performance restoration latency reduction activation latency reduction performance gain naive combination already cal outperforms   tradeoff understand importance overall memory access latency     achieves performance   respectively core memory intensive workload  decrease tRCD  decrease tRAS twr memory access benefit cal increase workload memory intensity increase memory intensity rate conflict due constraint particularly multiprogrammed workload multiple concurrently execute application interfere access conflict occurs precharged activate highly likely due temporal spatial locality precharged access future conflict rate increase activation increase creates opportunity cal core memory channel average speedup cal increase baseline core channel configuration conflict core fourth cal approach ideal performance improvement exploit partial restoration highly  within average core  improves performance cal assumes ideally access minimal activation restoration latency access access interval timer perfect entry evict explore sensitivity cal timer conclude cal significantly reduces dram latency outperforms mechanism dram latency reduction combination impact overall consumption cal CC RT average across workload category consume cpu cache chip interconnect  dram dram broken activate precharge pre refresh ref idle  OI  QR breakdown cal reduces average workload category memory intensive thread application cal reduces consumption average reduction increase memory intensity average reduction core workload application workload memory intensive cal achieves consumption CC RT respectively core memory intensive workload cal reduces cpu cache interconnect reduce execution application primary source reduction dram reduce consume activation precharge cal reduces amount spent activate restore reduces activation restoration latency overall conclude cal effective reduce consumption due ability reduce dram latency overhead overhead cal predominantly consists storage timer memory controller entry consists address tag timer PR valid width tag dependent dram core contains GB dram tag entry consumes assume per core timer entry therefore timer consumes core consume timer McPAT compute overhead consume MB cache timer predominant source consumption cal timer entry insertion lookup update operation increase dynamic consumption dissipates static analyze timer activity application accounting operation consumes average average consume cache additional consumption evaluation aside timer introduce mechanism allows cal reduce activation restoration latency introduce command ddr interface perform shorten activation restoration command undefined encoding reserve future ddr specification unused encoding already account specification additional command bus introduce command conclude cal incurs chip consumption dram interface overhead timer capacity perform sensitivity entry timer affect performance speedup cal core timer entry along speedup infinite capacity observation speedup timer capacity timer capacity increase cal performance improvement increase entry reduces eviction potential opportunity cal reduce activation restoration latency otherwise evict cal performance improvement taper timer increase entry improves performance core workload application memory intensive application benefit cal entry additional storage overhead overhead yield diminish return additional storage effective infinite timer improves performance average across application entry conclude timer entry performance performance improvement diminish capacity implement entry per core timer achieve balance performance improvement storage overhead restoration restoration affect cal performance affect tRCD tRAS twr reduction recall restoration achieve tRAS twr reduction expense reduce amount cal reduce tRCD vdd optimal examine performance restoration performance speedup cal restoration optimal restoration opt vdd vdd respectively vdd vdd respectively speedup restoration opt outperforms choice workload conclude restoration dram important role balance performance benefit restoration latency reduction activation latency reduction dram management policy policy dram policy dram pending request memory controller request buffer target conversely policy request schedule memory controller policy affect opportunity available cal reduce activation restoration therefore evaluate sensitivity cal management policy minimalist minimum delay activation within unless pending request speedup cal policy cal  cant speedup policy speedup cal minimalist average core workload minimalist policy reduce buffer conflict activation restoration operation however opportunity cal reduce latency minimalist policy overall conclude cal effective management policy speedup management policy address mapping policy commonly channel interleave address mapping scheme physical address tuple ID rank ID  ID ID channel ID ID cache offset cache offset corresponds significant address analyze performance address mapping scheme implement permutation mapping scheme pam  ID ID ID ID pam randomizes ID reduce buffer conflict evaluate sensitivity cal address mapping policy pam offline address mapping scheme OAM OAM idealize address mapping policy analyzes entropy address offline address mapping suppose minimize conflict speedup cal address mapping policy pam impact speedup cal achieves OAM slightly impact speedup cal OAM channel interleave average core memory intensive workload however cal significant performance improvement OAM mapping feasible offline address mapping conclude cal effectively improves performance address mapping scheme assume  interval maintains data integrity normal refresh interval reduces evaluate sensitivity cal refresh interval interval  speedup address mapping scheme refresh interval linearly maximum access access interval cal applies partial restoration account increase rate decay refresh interval partial restoration apply access access interval speedup cal refresh interval speedup decrease refresh interval becomes decrease maximum  access interval interval likely similarly access access interval future reduce accuracy cal access access interval predictor cal effective reduce refresh interval improve performance cal sophisticated prediction future speedup refresh interval refresh rate refresh becomes significant becomes promising extend cal partial refresh restoration refresh reduce shorten refresh latency activate refresh extension future conclude cal robust refresh interval related knowledge enable partial restoration access access interval cooperatively exploit restoration latency reduction reactivate activation latency reduction already   demonstrate cal outperforms ofthe mechanism partial restoration activation latency reduction combination related exploitation characterization dram optimization dram architecture modification memory schedule exploitation ChargeCache  employ reduce dram timing parameter recently refresh dram  orthogonal combine cal mechanism target opportunity latency reduction smart refresh eliminates unnecessary refresh operation recently access reduce refresh operation schedule memory access fully restore refresh operation contrast cal reduces latency restoration operation complementary mechanism combine cal mechanism achieve performance improvement characterization dram optimization experimentally investigate various reliability data retention latency characteristic dram chip opportunity dram latency consumption cal achieves latency reduction independent operating characteristic combine mechanism propose  improve performance dram architecture modification memory schedule tiered latency dram TL dram bitline enables faster access closer amplifier lisa isolation transistor inter subarray connection within quickly cache frequently access subarray reduce precharge latency propose mechanism allows request memory activate propose optimize dram architecture dram latency consumption efficient memory schedule mechanism reduce dram latency exist dram resource mechanism largely orthogonal cal cal implement improve dram performance efficiency conclusion propose cal novel overhead mechanism performs partial restoration refresh reactivate mitigates negative partial restoration activation latency reduction highly dram cal consists component accuracy cal predicts reactivate future cal future  refresh reduce activation restoration latency decrease overall dram access latency implement cal fully within memory controller without dram module cal improves average performance core reduces average dram consumption across workload cal outperforms mechanism dram restoration activation latency reduction combination conclude cal effective mechanism significantly reduce dram access latency bottleneck compute