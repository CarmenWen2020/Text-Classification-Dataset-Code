computer architect significant effort exploration processor determines overall characteristic performance thoroughly explore achieve evaluation throughput ability quickly ass minimal unfortunately exist simulator performance model inaccurate demand architect sacrifice coverage sub optimal address challenge propose RpStacks MT methodology evaluate multi core processor throughput propose graph multi core performance model overcomes limitation exist model accurately multi core processor performance behavior propose reuse distance memory model dynamic schedule reconstruction graph model quickly performance processor lastly combine model exploration evaluate multiple processor efficient evaluation RpStacks MT achieves extremely evaluation throughput versus conventional cycle simulator versus accelerate simulator average evaluate maintain simulator accuracy index exploration performance analysis simulation introduction exploration critical development processor overall characteristic successful exploration examine investigate tradeoff optimal candidate unfortunately exploration become increasingly challenge due complexity evaluation multi core processor become extremely complex simplify candidate thoroughly explore investigate tradeoff unfortunately processor core consist complex module functional buffer cache architect explore parameter combination combination core easily moreover core diverse module LI L1D mem div mul   optimization speedup parsec swaptions thread processor simplicity apply optimization combination L1D div carefully explore optimal candidate successful development maximize optimal important performance characteristic application within processor heterogeneous multi core processor grows evaluation multi core processor already prohibitively core per processor increase core become complex simulation load significantly increase model increase inter core communication microarchitecture module detailed multi core simulator multiple magnitude hardware address challenge achieve evaluation throughput evaluate per machine resource architect propose various optimization technique accelerate simulation binary translation parallelization sample load reduction hardware acceleration successfully increase evaluation efficiency eventually  speedup benefit II another predict performance analytic performance model avoid expensive simulation model information regard processor performance execute operation latency architect understand performance bottleneck instantly predict performance upon alleviate bottleneck annual acm international symposium microarchitecture doi micro however discover portion estimation inaccurate prediction behavior become invalid performance behavior recent significantly improves accuracy simultaneously multiple performance behavior applicability limited core processor operation latency adjustment II propose RpStacks MT methodology evaluate multi core processor throughput accuracy representative execution analyze limitation exist simulator analytic model clarify requirement  evaluation minimize per evaluation overhead therefore utilize analytic model prediction achieve goal investigation recent analytic model none exist proposal properly handle performance critical multi core behavior resource dynamic schedule obstacle prevent analytic model multi core evaluation address propose graph performance model multi core processor reuse  memory model dynamic schedule reconstruction specifically multi core processor behavior graph code snippet thread core inter core thread interaction synchronization model dependency graph perform throughput evaluation model estimate execution performance multiple processor evaluation exploit representative execution RpStacks II account multicore performance behavior maintain accuracy develop memory model describes resource behavior estimate contention schedule reconstruction generates thread graph execution scenario processor evaluation parsec benchmark suite RpStacks MT achieves throughput conventional cycle simulator throughput accelerate simulator evaluate highly accurate emphasize allows highly parallel analysis beyond core target analysis core target user therefore evaluation throughput faster individual analysis contribution graph multi core performance model propose novel graph performance model accurately performance critical factor resource schedule multi core processor knowledge attempt analytically model multi core processor detailed microarchitectural pipeline stage graph efficient reuse distance memory model propose efficient reuse distance memory model quickly estimate resource llc interconnect performance multiple model greatly enhances capability accuracy evaluation without incur significant overhead dynamic schedule reconstruction propose reconstruct dynamic schedule behavior graph model allows accurately performance multi core schedule behavior throughput evaluation combine model introduce construct holistic throughput multi core evaluation ass maintain simulator accuracy user efficiently investigate tradeoff optimal candidate II discus simulator performance model identify limitation motivate approach perform analysis analytic model exploration clarify goal explain  IV implementation detail VI accuracy throughput evaluation vii related discus improve RpStacks MT conclude IX II background LIMITATIONS detailed cycle simulator simulator popular model evaluate processor introduce various simulation limitation thread cycle simulator singlethreaded simulator  gem   accurately model multi core processor calculate microarchitectural cycle accuracy slowest due complexity model addition linear slowdown multicore thread simulates core target processor accordingly suitable detailed performance debug analyze pipeline bubble exploration binary translation parallel simulator recent multicore simulator zsim sniper graphite cycle breakdown alu L1D mem instruction div mul dispatch execute writeback commit fetch cycle latency div incorrect estimation pipeline stage estimation graph processor performance model analytic performance model achieve extremely dynamic binary translation parallelization specifically adopt faster functional behavior model native execution instrumentation instead emulation parallelize simulation coarser grain inter core synchronization successfully boost multicore simulation become effective evaluation throughput speedup benefit parallelization disappear dominates simulation load maximize evaluation throughput core simulation host limited resource thread simulation evaluate thread simulation speedup  sub linear speedup native execution remains valid however insufficient reasonable II hardware accelerate simulator hardware accelerate simulator utilize hardware prototyping platform FPGAs achieve native however generally modification overhead therefore suitable evaluate discus analytic performance model analytic performance model collection information regard processor behavior typical outcome analytic model stack operation perform along amount spent operation architect understand bottleneck predict performance upon alleviate bottleneck via stack component performance prediction operation analytic model estimate performance multiple processor negligible  overhead analysis overhead model evaluate multiple extremely throughput discus limitation model illustrate cannot multi core despite throughput advantage graph model graph analytic model workload instruction microarchitectural behavior graph node node pipeline stage instruction node dependency pipeline stage operation latency node operation source node cycle trigger destination node operation stage instruction stage instruction critical derive cycle execute instruction performance identify cycle spent bottleneck graph model processor graph operation latency calculate performance component performance stack apply latency assume critical critical graph option estimate performance negligible overhead however inaccurate critical upon formerly critical overestimate performance accurately derives performance traversal graph model critical typical graph simulation node instruction incur simulation overhead therefore cannot scalable summarize exist graph model suitable accurate efficient evaluation counter model counter analytic model hardware performance counter analyze performance stack thanks overhead model widely employ assist performance optimization scheme however graph model  analysis utilize critical estimate performance inaccurate therefore conclude model acceptable accurate evaluation exploration conventional graph counter analytic model inaccurate prediction estimate performance critical execution address recent proposal suggests multiple execution graph model utilize accurately predict performance execution extremely author propose various technique identify representative likely become critical unfortunately approach limited evaluation throughput  normalize cycle sim budget evaluation cpu cycle sim sim analytic inaccurate RpStacks MT evaluation throughput various billion instruction simulation core processor discus handle multiple core thread dynamic schedule behavior knowledge none exist discus graph performance model multi core processor furthermore discover naively expand exist core model highly inaccurate therefore aim define accurate graph multi core performance model utilize effectively explore lesson analysis summarizes evaluation throughput simulator fix evaluation throughput simulation accordingly simulation explore accelerate simulation faster cannot thoroughly multicore processor reasonable budget realistic simulation vcpu core simulation instance approx USD amazon EC USD vcpu reduce manageable RpStacks MT USD handle aim develop sensitive fortunately confirm analytic model estimation negligible per evaluation overhead therefore despite initial analysis overhead increase evaluation throughput identify accuracy lack multiple performance critical consideration absence multi core processor model develop performance model multi core improve multiple consideration accordingly propose RpStacks MT throughput multi core evaluation analysis motivation evaluate analytic performance model investigate max determines performance core core naive expansion core graph performance model multi core processor model evaluate multi core processor insight goal RpStacks MT model ıve expansion multi core introduce analytic model evaluation naively apply multicore illustrate multi core processor collection core apply exist graphbased core model analysis individual core performance execution core overall performance slowest core determines limitation ıve expansion discus simply expand core model fails accurately estimate multi core performance lack resource consideration exist graph core processor model cannot accurately resource behavior cache interconnects impact multi core performance mechanism inform core resource status fundamental limitation resource behavior cod graph instance memory instruction marked outcome baseline llc bus latency cycle whereas shrink cache llc become therefore quickly reconstruct resource behavior accurately apply graph model lack dynamic schedule consideration exist analytic model lack description schedule behavior performance multi core processor categorize schedule behavior explain thread creation multi core processor multithreaded application dynamically thread illustrates scenario thread spawn another thread slows progress adjust accordingly however naive model statically embed cannot account delay incorrect creates thread creation incorrect lock incorrect barrier incorrect conditional variable naively expand analytic model inaccurate model performance critical thread interaction estimate performance incorrect scenario ahead creation lock lock critical thread proceed thread currently occupy thread leaf processor alters lock related behavior slows longer lock release however naive model statically marked behavior overlap critical fail correctly model performance behavior barrier barrier synchronize multiple thread progress application thread barrier thread thread barrier resume execution barrier duration upon slows longer naive model cannot reproduce behavior barrier delay cod graph model conditional variable conditional variable thread pause resume requirement met producer consumer data processing consumer thread halt data wake producer generates data illustrates slows producer thread accordingly consumer thread longer naive model incorrectly wake consumer wakeup baseline architecture goal RpStacks MT fundamental naively expand model generate important multi core behavior resource dynamic schedule performance impact significantly performance thread progress accurately model multi core processor performance therefore aim develop graph analytical performance model efficiently embeds resource schedule information model information quickly construct performance behavior upon processor thread core core thread thread fail acquire lock thread thread thread spawn graph multi core processor performance model IV  MT  introduces RpStacks MT overcome challenge enable accurate throughput multi core evaluation graph multi core model novel graph performance model multi core processor instead generate graph per core graph per code snippet thread schedule synchronization schedule synchronization separately dependency later reschedule graph code snippet thread preserve synchronization semantics graph reuse distance efficiently memory resource behavior memory access trace reuse distance enables performance estimation various memory resource scenario lastly improve pipeline detail graph model multi core specific performance detail reuse distance memory model accurately estimate performance implication resource behavior develop efficient reuse distance memory model reuse distance reuse distance unique address reference identical address assume cache buffer lru replacement policy access address memory access unique address RD buffer buffer access access concept reuse distance associativity RD access distribute binomial distribution RD assoc model associative cache core rate RD core RD scenario core rate core access core memory access unique address affect reuse distance unique address model cache reuse distance memory model buffer reuse distance buffer technique quickly identify access various buffer without simulation model associative cache model associative cache reuse distance associativity determines buffer multiple address contend cache access distribute across multiple multinomial distribution utilize analysis construct model accurately estimate memory access associative cache model cache cache multiple access contend reuse distance increase access access amount relative memory access rate address overlap access address increase reuse distance unique address model accurately adjust reuse distance account contention model interconnect interconnect bus memory another critical resource multi core processor therefore develop queue interconnect model accurately resource contention specifically model bus queue request poisson rate server bus handle fix rate average request express multinomial distribution implies uniform access cache account workload specific sequential stride profile cache access frequency workload correspond distribution express non uniformity model network chip noc interconnects replace queue complex model core core schedule runnable progress cycle acquire release schedule logic runnable schedule lock acquisition fail core core runnable schedule wakeup runnable notification core core idle become runnable dynamic schedule reconstruction average increase request rate approach handle rate handle rate derive workload baseline workload request rate calculate graph memory instruction instruction confirm precisely estimate bus latency estimate performance impact typical reuse distance queue model focus accurately estimate rate delay interested affect individual execution performance introduce translate statistic performance cache access hierarchy mem execution graph impose penalty accord access latency latency accurately adjust memory access latency cache behavior interconnect calculate average per graph contention latency impose interconnect latency per latency define access interconnect average approach accurately derives latency individual dynamic schedule reconstruction performance impact synchronization schedule load balance dynamically runtime accord performance processor accurately model non deterministic critical execution span across multiple core core core performance cycle core core performance cycle throughput evaluation develop dynamic schedule reconstruction generates realistic thread execution scenario describes schedule logic schedule graph processor core model multiple thread multi core processor graph schedule runnable runnable immediately execute core activate iterate core core slowest progress cycle schedule runnable core schedule advance core progress cycle iterative schedule ensures progress across core majority OSes scheduler achieve schedule multiple thread multiple core schedule load balance algorithm implement reproduce correspond schedule behavior runnable runnable violate schedule synchronization semantics cannot execute immediately runnable lock cannot execute core core already acquire lock schedule failure fail schedule core another runnable available schedule slowest progress core schedule onto core schedule describes happens become runnable synchronization schedule lock release thread spawn wake runnable core lock release notifies due specific lock becomes runnable schedule core execute synchronization schedule trigger handle complex synchronization propose accurately handle complex synchronization exclude lock already described thread creation default thread thread initial thread creates thread thread spawn trigger thread become runnable thread barrier barrier synchronization variable initialize thread participate barrier later thread barrier correspond thread others barrier barrier operation wake previously feasible thread participate barrier conditional variable conditional variable relatively straightforward signal simply wake correspond thread unlike simply discard signal recipient signal recipient consumes prevent deadlock thread throughput evaluation lastly introduce combine model novel throughput evaluation graph extract representative execution II detailed performance bottleneck information cycle stack instantly estimate graph execution performance cycle execute code snippet graph multiple stack component brevity graph translates execution performance schedule graph dynamic schedule reconstruction essentially construct multi core critical execution per graph critical interaction schedule constraint schedule scenario due execution performance critical utilize memory model resource behavior adjust finalize execution performance schedule estimate overall performance emphasize graph instruction therefore schedule reconstruction incurs negligible overhead refer VI detail implementation framework overview illustrates overview RpStacks MT framework trace cycle timing simulation multi core processor purpose per core execution trace information regard workload execution specifically trace contains execute instruction timing instruction pipeline simulator trace performance reschedule model trace simulation trace generation serialize evaluate evaluation parallelizable model performance model construction parallelizable trace extract representative extraction parallelizable graph overview RpStacks MT framework stage dependency instruction performance instruction cache interrupt etc execution context thread IDs synchronization schedule reuse distance memory instruction model construct multi core graph performance model trace IV graph per code snippet extract extract representative execution graph adopt handful cycle stack performance bottleneck potential performance critical fourth evaluate estimate performance explain IV estimate performance graph apply specification cycle stack accordingly perform reschedule memory behavior estimation derive overall performance incorporate factor optimization investigate tradeoff fourth negligible overhead explore throughput identify optimal candidate achieve throughput latency throughput achieve evaluation throughput optimization effort evaluate overhead reading graph performance extract account majority overhead file therefore  asynchronous minimize overhead latency development absolute evaluation important factor exploration available future fortunately RpStacks MT parallel analysis user tradeoff evaluation throughput latency fetch tlb rename dispatch address address II tlb execute commit commit rename dispatch execute commit fetch instruction rename dispatch commit fetch instruction previous instruction execute non memory instruction operation dependence finite fetch bandwidth fetch finite fetch buffer rename fetch dependency instruction fetch finite rob commit rename finite rename bandwidth rename rename issue dependency execute dispatch finite dispatch width dispatch dispatch data dependency address finite physical register commit data dependency address dependency execute execute cache finite commit width commit commit uop dependency commit interrupt commit fetch memory fence commit inter instruction dependency intra instruction dependency instruction execute classification alu    logic    memory remote mem split bus queue latency pipeline model detail RpStacks MT graph model execute dependence classify instruction newly introduce augment component denote asterisk parallelize basically parallel analysis independent data trace graph target trace successfully achieve speedup beyond target core typical bound parallel simulator maximize parallelism apply chunk graph specifically instruction previous segmentation degrade accuracy model VI parallelization speedup improve pipeline detail graph model achieve simulation performance evaluation accuracy crucial accurately depict processor pipeline graph model illustrates detail model pipeline stage vertical node CA DE FA FE FL ST SW core core error simulator workload graph model SMS  CA DE FA FE FL ST SW   CA DE FA FE FL ST SW  CA DE FA FE FL ST SW baseline KB MB KB KB KB MB access CA canneal DE dedup FA facesim FE ferret FL fluidanimate ST streamcluster SW swaptions mem simulator model memory model validate accuracy individual model instruction microarchitectural operation dependence pipeline stage identify weakness model augment detail accurately multi core operation interrupt memory fence significant performance impact multi core classify memory instruction operation latency model split bus queue latency interconnect model IV adjusts accurately account resource contention VI evaluation experimental setup  cycle simulator reference accuracy throughput trace implement simulator instruction trace performance reuse distance memory access schedule pthread switch kernel function etc parameter baseline multi core processor workload application parsec benchmark suite application linkage distance similarity analysis selection II various synchronization parallelization model resource sensitivity accuracy validation multi core graph model validate accuracy graph multi core performance model accurate performance estimation baseline multi core processor parameter parameter core pipeline width rob lsq IQ cache per core KB L1D KB LI latency cycle cache MB latency cycle memory cycle integer multiplication cycle integer cycle float addition cycle float multiplication cycle integer vector cycle float vector cycle target parameter optimize accurate specifically critical performance baseline model reference performance cycle simulator error confirm accuracy graph model memory model accuracy reuse distance memory model various access model cycle simulator model precisely estimate access private mem resource deliver accurate performance implication evaluation finally RpStacks MT accurately estimate performance impact processor evaluate randomly parameter denote reduce cache capacity application perform evaluate highlight importance model naively expand model multi core graph model schedule reconstruction multi core graph model memory model RpStacks MT error distribution evaluation violin plot whisker quartile violin density sample  sample naive error model critical multi core performance behavior schedule slightly reduces average error schedule sensitive application ferret dedup error accurate performance estimation applies memory model II summary parsec application workload parallelization synchronization resource model sensitivity canneal unstructured dedup pipeline facesim data parallel medium ferret pipeline medium fluidanimate data parallel streamcluster data parallel medium swaptions data parallel medium lock barrier variable error naïve model multi core model schedule multi core model memory model RpStacks MT average canneal dedup facesim ferret fluidanimate streamcluster swaptions mrn mrn mrn mrn mrn performance estimation error core target processor             MT        mrn mrn mrn mrn mrn performance estimation error core target processor performance baseline accord simulator simulator RpStacks MT naive canneal dedup facesim ferret fluidanimate streamcluster swaptions performance spectrum core sort simulator  similarity naïve core RpStacks MT core naïve core RpStacks MT core canneal dedup facesim ferret fluidanimate streamcluster swaptions average workload similarity RpStacks MT performance rank simulator rank truth validate accuracy exploration drastically reduces error accurately cache schedule sensitive application error lastly RpStacks MT correctly account behavior minimizes error naive model error core average application reduces error core facilitate accurate multi core processor evaluation performance spectrum performance baseline modification introduce significant performance RpStacks MT distribution naive model naive model fails detect increase performance ferret whereas accurately trend validate RpStacks MT performance rank simulator similarity indicates simulator naive RpStacks MT robustly identifies perform ferret dedup software pipelined application dynamic complex schedule synchronization behavior tight producer consumer communication pipeline stage heterogeneity stage characteristic instruction correspond mismatch incur frequent stall producer consumer vastly characteristic instruction memory intensity correspond mismatch generates frequent stall data furthermore producer consumer dependency span multiple thread dependency chain usefulness realistic exploration scenario deeper individual application behavior application spends execution cycle aggregate core application hugely benefit memory model portion  canneal pipelined application cycle emphasize accurate dynamic schedule reconstruction data parallel application cycle dynamic behavior streamcluster cycle schedule relatively deterministic dynamic overhead analysis actual throughput discus evaluation overhead RpStacks MT illustrate achieves throughput analyze overhead RpStacks MT trace          cycle breakdown core baseline canneal dedup facesim ferret fluidanimate streamcluster swaptions average overhead evaluate model trace extract workload latency decomposition evaluate thread RpStacks MT core target RpStacks MT evaluation throughput thread RpStacks MT simulator core target canneal dedup facesim ferret fluidanimate streamcluster swaptions average extract speedup thread parallelism workload speedup parallelize RpStacks MT core target model extract evaluate overhead thread execution discus parallelization speedup VI overhead trace model proportional simulation simulation performance model overhead simulation initial model construction performance estimation RpStacks MT analytic model simulation extract account majority overhead expensive graph traversal combine  similarity comparison however stage highly parallelizable user analysis machine resource VI evaluate overhead proportional perform schedule reconstruction memory model nonetheless reconstruction overhead negligible simulation consists graph IV schedule operation relatively thanks usually instruction therefore RpStacks MT successfully evaluates maintain overhead throughput evaluation discus evaluation throughput RpStacks MT throughput baseline simulator accelerate simulator dynamic binary translation parallelization II comparison simulation RpStacks MT stable project throughput throughput baseline simulator assume evaluation simulator fix throughput regardless additional evaluation another simulation RpStacks MT throughput initial model construction analysis overhead however grows RpStacks MT throughput almost fix overhead independent average RpStacks MT throughput exceeds simulator evaluate realistically  throughput baseline accelerate simulator respectively RpStacks MT reduce exploration magnitude parallelization speedup lastly RpStacks MT simulation resource accelerate analysis parallelization useful evaluation throughput latency important speedup speedup consume extract baseline cycle simulation RpStacks MT initial analysis overhead analysis exploration explore practically infinite negligible overhead initial analysis extract independent graph parallel framework speedup slightly ideal due non parallelizable trace emphasize scalability serialize account relatively portion overhead RpStacks MT allows easy tradeoff evaluation throughput latency various demand processor development vii related model uarch analysis performance estimation mechanistic model mechanistic model microarchitectural insight construct pipeline model efficiently analyze performance interval analysis successor representative improve mechanical model combine empirical approach graph model graph model interpret processor component node operation behavior information analyze performance bottleneck predict performance upon critical slack non critical operation graph model optimize processor expands model identify bottleneck operation understand instruction interact overall performance improves accuracy graph model model queue misprediction penalty empirical model empirical performance model estimate processor behavior machine technique microarchitectural operation popular concept linear regression non linear spline model utilized suggests rank model perform relative comparison instead estimate absolute performance performance monitoring performance monitoring  notify microarchitectural overhead facilitate various performance analysis improvement initial simply analyze bottleneck later proposal sample investigate adjacent instruction overlap instruction frontend pmu mechanistic model understand overlap bottleneck core improves instruction critical identifies performance criticality thread multi core processor implement efficient acceleration via DVFS optimize processor evaluation trace driven simulator trace driven simulator graph performance analysis analyze input information trace quickly derive performance previous approach successfully reconstruct performance multi thread application overhead limited specific parallelization model task workload limitation simulator sample simulation load reduction sample effective popular accelerate simulation volume reduce analysis load improve evaluation efficiency technique sample eliminate duplicate orthogonal therefore apply combination improve efficiency evaluation discussion   MT discus improve RpStacks MT capability model utilization reliability estimation utilization microarchitectural component alu allows explore reliability processor addition performance activity deterministic characteristic workload identify activation workload execution trace RpStacks MT reconstructs cycle execute trace performance estimate activation per cycle utilization information model reliability processor model heterogeneous core model heterogeneous core processor construct graph model per core code snippet translates multiple graph accord core scheduler graph core construct performance behavior exploit redundancy increase throughput boost throughput RpStacks MT exploit redundancy trace RpStacks MT sample technique previous graphbased model utilizes simpoints loop inside graph exploit suggests analyze unique reduce simulation load adopt accelerate RpStacks MT IX conclusion RpStacks MT evaluates multi core processor throughput successfully obtain optimal candidate graphbased multi core performance model quickly multiple maintain accuracy reuse  memory model dynamic schedule reconstruction evaluation parsec workload suite RpStacks MT achieves evaluation throughput conventional multi core simulator accelerate simulator evaluate maintain error acknowledgment partly research program national research foundation korea NRF fund ministry ict  NRF MCA NRF  institute information communication technology promotion  grant fund korea government  creative pioneer researcher program  national appreciate automation research institute  inter semiconductor research isrc neural processing research   national