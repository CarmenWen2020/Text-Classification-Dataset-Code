rely  neural network topology massive amount label training data extensive training compute resource perform efficient image classification recognition unfortunately away implement adaptive purpose intelligent autonomously unknown environment access component reinforcement evolutionary algorithm EA circumvent continuously interact environment update model obtain reward however deploy algorithm ubiquitous autonomous agent robot drone demand extremely efficiency due tight budget continuous lifelong interaction environment intermittent connectivity  processing address genesys HW SW prototype EA comprises loop eve inference adam eve evolve topology neural network completely hardware task without optimization  training adam continuously interacts environment optimize efficiently irregular neural network generate eve genesys identifies leverage multiple unique avenue parallelism unique eas gene parallelism population parallelism genesys suite environment OpenAI gym magnitude efficiency embed desktop cpu gpu introduction computer intelligent entity  humanity  era thanks computer program parallel surpass accuracy task visual perception synthesis however reality despite equip powerful algorithm computer away realize purpose AI development supervise mostly loop typical model  neural network NN topology expert multiple iteration trial error topology  amount label NSF  grant training label data env inference reward input environment output action eve adam reinforcement inference gpu ASIC gpu ASIC fpga error input output supervise genesys conceptual genesys within machine environment squat generation population neuro evolutionary algorithm output max average target fitness generation normalize fitness NE action evolve nns mario data petabyte compute cluster obtain model hence obtain deployed inference accelerator gpus FPGAs ASICs unfortunately supervise operates unavailability structure label data unknown NN topology dynamically unavailability compute cluster training algorithmic promising reinforcement RL algorithm address challenge RL algorithm model agent agent interacts environment perform action policy function NN interaction periodically generate reward effectiveness action task algorithm reward obtain iteration update policy function till converges upon optimal policy extremely promising demonstration RL google  supercomputer autonomously AlphaGo beating champion unfortunately RL algorithm cannot address fourth challenge supervise training algorithm cannot annual acm international symposium microarchitecture doi micro  NN upon receipt reward extremely computation memory purpose AI autonomous device algorithm architecture synergistically challenge attempt genesys target towards efficient acceleration neuro evolutionary NE algorithm NE algorithm akin RL algorithm attempt evolve topology NN via genetic algorithm  surprisingly robustness challenge mention earlier resurgence OpenAI google brain uber AI lab however demonstration rely compute memory challenge attempt via clever HW SW contribution characterize NE algorithm neat identify compute memory requirement across suite environment OpenAI gym identify opportunity parallelism population parallelism PLP gene parallelism GLP data reuse genome reuse GLR unique NE algorithm architect insight efficient algorithm discus attribute compute communication within NE algorithm inefficient gpus dnn accelerator novel accelerator evolution eve accelerator dense addition multiplication adam optimize inference NE respectively hardware architectural offs along overview genesys soc evaluate optimize NE implementation embed desktop CPUs gpus magnitude improvement runtime efficiency optimize hardware  revolution genesys subsequent enable deployment intelligent device capable autonomously II background description brief introduction concept reader appreciate discussion supervise supervise arguably widely involves policy function NN topology via trial error ML researcher tremendous amount label data output model compute input exist label generate error error  BP via NN compute error gradient update iteratively till convergence achieve supervise limitation training purpose AI dependence structure label datasets perform effectively without overfitting effectiveness heavily NN topology witness deeper convolution topology birth extreme compute memory requirement network compute cluster consist gpus reinforcement RL reinforcement structure underlie policy function instance suppose robot finite output direction aim policy function robot closer target destination random initialization agent performs action receives reward environment metric failure goal goal RL algorithm update policy future reward maximize iteratively perturb action compute correspond update NN parameter via BP RL algorithm environment scarce datasets without assumption underlie NN topology reliance BP computationally expensive evolutionary algorithm EA evolutionary algorithm biological evolution abstract sample population individual successful individual constitution future generation illustrates algorithm pool individual agent independently perform action environment individual assign fitness upon effectiveness action biological individual genome parameter gene encode characteristic individual fitness calculation generation individual mutate genome reproduction individual fitness chosen ensure gene generation multiple completion criterion met mathematically eas stochastic optimization technique assumption structure underlie function optimize evaluate lookup function pool offspring pool crossover mutation num offspring probability probability interaction environment desire fitness achieve reproduce generation generate  population evaluate population fitness neat fitness function genome genome operation description crossover mutation perturb mutation gene mutation delete gene attribute gene perturb amount remove node connection genome gene genome default attribute gene attribute gene relative fitness configurable parameter genome gene evolutionary algorithm neat algorithm gene genome context nns ops neat fundamental difference RL EA optimize reward RL perturbs action backpropagation computation memory compute parameter update EA perturbs parameter node connection inside NN directly eas highly robust algorithm various algorithm perspective task remains perturb parameter maximize reward neat algorithm  eas evolve topology NN simultaneously neuroevolution augment topology neat algorithm developed neat architecture genesys extend  depicts neat algorithm terminology throughout text population population neat NN topology generation environment fitness gene building neat gene NN node neuron connection synapse node gene uniquely described activation relu bias associate connection described node hyperparameters enable genome collection gene uniquely describes NN population highlight initialization neat initial population topology comprise input output layer evolves complex sophisticated topology mutation crossover function mutation akin biological operation mutation operation gene generate tweak parameter gene instance connection gene mutate modify parameter gene mutation involve addition deletion gene probability crossover crossover operation gene generation cherry parameter gene  fitness evolutionary algorithm essence pit individual population competitively however scheme prematurely prune individual useful topological feature feature optimize hence contribute fitness neat feature counteract  fitness  individual within population niche within specie fitness individual artificially increase  pit fitter individual ensure innovation generation optimize fitness augment fitness genome competitive computational behavior eas characterizes computational behavior eas neat specific insight relevant computer architect target environment suite environment described OpenAI gym environment involves task source python implementation neat accuracy robustness NN topology input node observation environment output node action environment fully connection zero codebase application fitness function environment target fitness demonstrate robustness neat demonstrates evolution behavior environment across multiple observation across environment variance average environment source implementation AC DQN popular RL algorithm OpenAI environment converge tune RL parameter converge however comprehensive comparison RL NE beyond scope AI gym environment environment goal observation action  balance complex invert pendulum construct link rigid rod float float  evolve locomotion legged robot terrain float float  criterion balance invert pendulum platform consecutive float binary  goal task  peak float integer direction  goal module specific lunar sequence  float integer  atari agent atari button  ram alien ram  ram  ram environment byte ram integer button target fitness num gene generation fitness gene reuse evolution behavior AI gym function generation relative frequency relative frequency relative frequency relative frequency computation crossover mutation ops memory footprint application OpenAI gym generation distribution plot across generation till convergence application generation converge within environment longer others converge evolution probabilistic target fitness realize generation generation observation efficient hardware NE algorithm runtime specific task compute behavior parallelism eas essentially comprise outer loop evolutionary algorithm genome nns generation inner loop perform inference genome prior computation demand eas backpropagation evolution neat primarily computation crossover mutation distribution crossover mutation operation within generation distribution plot across generation till application converge across application mutation crossover application another insight crossover mutation gene parallel demonstrates raw parallelism eas prior accelerate eas leveraged gene parallelism GLP moreover environment become complex nns gene amount GLP actually increase inference inference neat involves inference nns population environment inference neat however traditional multilevel perceptron mlp nns recall neat topology connection node via mutation network irregular topology lens dnn inference highly sparse topology inference topology basically processing acyclic graph evolution multiple genome undergo inference concurrently dependence within genome opportunity parallelism arises population parallelism PLP memory behavior plot gene NN evolves memory footprint important memory footprint eas simply gene genome within generation algorithm previous generation effectively perform training eas highly attractive memory footprint BP error gradient datasets epoch stochastic gradient descent inference however lack regularity layer structure genome cannot encode efficiently convolutional neural network NE algorithm  mechanism encode genome efficiently leveraged application AI gym overall memory footprint per generation MB application memory footprint per generation memory training algorithm due mention enable memory EA cached chip communication bandwidth leverage GLP PLP gene compute increase memory bandwidth pressure cache gene genome chip leverage bandwidth network chip noc bandwidth demonstrate via genesys opportunity data reuse data reuse technique accelerator unlike dnn inference accelerator regular layer convolution directly expose reuse across filter NN highly irregular evolutionary algorithm however identify reuse genome reuse GLR generation generate multiple quantify opportunity application generation reuse application  lunar lander increase genome generate generation offering tremendous opportunity genome memory locally memory bandwidth II DQN EA DQN EA compute mac ops pas gradient calculation BP mac ops inference crossover mutation evolution memory MB replay memory entry MB parameter activation mini batch MB entire generation parallelism mac gradient update parallelize per layer GLP PLP described regularity dense cnn regularity opportunity reuse highly sparse irregular network acceleration takeaway compute memory analysis EA compute memory requirement EA conventional RL II DQN candidate atari EA memory compute DQN reasonable memory MB application GLR opportunity evident sufficiently chip memory remove reduce chip access significantly bandwidth compute operation EA crossover mutation hardware friendly furthermore absence gradient calculation significant communication overhead facilitate scalability inference phase eas akin graph processing sparse matrix multiplication traditional dense GEMMs conventional dnns dictate choice hardware platform reduce consumption compute ops implement hardware pack compute factor genome chip complex behavior evolve mobile autonomous agent seek genesys IV genesys microarchitecture overview genesys soc evolutionary algorithm hardware knowledge perform evolutionary inference chip overview component soc eve eve accelerator propose responsible selection reproduction neat algorithm neat algorithm across genome population consists collection processing PEs efficient implementation crossover mutation operation along PEs gene split split genome individual gene chip interconnect gene PEs gene gene merge merge gene genome inference adam neural net generate neat highly irregular irregularity deems traditional dnn accelerator  inference optimize gene genome NN topology reward fitness gene selector PE PE PE PE PE PE gene split gene merge interconnect genome fitness fitness fitness fitness genome genome genome genome fitness fitness fitness genome fitness action action reward reward genome evolution eve accelerator dense addition multiplication adam genesys soc environment instance dram genome buffer SRAM genome fitness cpu genome crossover perturbation module delete gene mutation module gene mutation module gene node ID regs random mutation crossover  gene config PRNG PRNG config processing PE genome ID gene attribute src node connection gene node node gene attribute dest node connection gene reserve node gene gene ID gene ID attribute attribute bias node gene activation node gene response node gene aggregation node gene node conn gene  connection gene enable node connection gene  connection gene reserve node gene hidden layer input layer output layer reserve connection gene genome neural network gene node connection population input vector systolic array output vector vectorize overview genesys cpu algorithm config inference adam eve eve PE assumption topology dense cascade layer inference closer graph processing dnn inference essentially sequence multiple vertex update node NN graph adam consists systolic array mac perform parallel vertex evaluation vectorize routine cpu pack node input vector dense matrix vector multiplication input vector creation vectorize routine generates matrix genome generation spawn however matrix within generation reuse multiple inference vertex evaluation input vector cpu cortex cpu embed cortex cpu perform configuration neat algorithm various probability population fitness equation manage data conversion movement eve adam chip SRAM genome buffer SRAM multi SRAM harbor genome generation access adam eve dram genome chip walkthrough brief execution sequence demonstrate dataflow population genome generation memory described genesys evolves genome generation genome nns genome buffer SRAM mapped mac adam adam environment evaluation environment OpenAI gym inference perform multiple vertex update operation vertex simultaneously update pack input vertex vector cpu matrix vector multiplication systolic array inference genome marked output vertex update output activation translate action fed environment multiple completion criterion met OpenAI failure task cumulative reward obtain environment proxy performance NN reward translate fitness cpu thread reward depends upon application environment fitness augment genome SRAM fitness individual population obtain reproduction generation neat individual fitness threshold participate reproduction selector logic cpu factor account selects individual generation genome eve gene splitting logic curate gene genome aligns PEs eve PEs gene interconnect perform crossover mutation gene gene interconnect gene merge logic organizes gene entire genome genome genome buffer overwrite genome previous generation genome becomes launch adam cpu detects target fitness application achieve leverage PLP leverage GLP selection serial microarchitecture eve gene parallelism GLP leverage parallelism within evolutionary namely gene earlier operation EA broadly categorize crossover mutation neat mutation perturbation addition deletion operation described operation serial dependence gene moreover operation per generation indicates massive GLP exploit propose microarchitecture via multiple PEs gene encode structure gene neat gene construct genome node gene vertex connection gene neural network graph capture gene node gene attribute bias response activation aggregation connection gene attribute source destination node processing PE schematic eve PE  pipeline stage perturbation delete gene gene mutation crossover crossover receives gene genome described II crossover attribute genome construct genome random PRNG bias attribute ability program bias contributes attribute  default logic replicate attribute perturbation perturbation probability generate mutate attribute gene generate crossover delete gene gene genome node connection implement gene deletion differs irrespective decision delete gene deletion probability generate PRNG node deletion addition probability previously delete node checked threshold amount node previously delete mode deletion happens genome alive node nullified ID ID later source destination IDs connection gene ensure dangle connection exist genome deletion connection fairly deletion decision gene IDs mention deletion probability gene fourth stage PE pipeline previous stage upon gene implementation varies node gene logic insert gene default attribute node ID node network additionally connection gene generate incoming connection gene addition connection gene cycle connection gene arrives selection logic random addition probability random source incoming gene connection gene arrives logic destination gene appends source default attribute creates connection gene mechanism ensures connection gene stage valid source destination gene movement manage gene movement gene selector II individual population opportunity contribute towards reproduction generation selection perform fitness threshold eliminate individual threshold II neat mechanism feature population  fitness selection logic fitness individual generation adjust implement fitness threshold calculate adjust fitness finally generation chosen gene splitting logic handle software thread cpu gene split gene split orchestrates movement gene genome buffer PEs inside eve crossover stage node gene however gene misalignment gene participate gene split therefore sits PEs genome buffer ensure alignment maintain gene PEs cycle addition receives gene selector assign gene num delete node deletion probability rand node node ID gene perturbation demux node IDs gene addition probability rand default node gene default conn gene node ID regs gene gene delete gene gene delete gene gene sel sel sel bias rand sel gene gene crossover gene mutate val mutate val mutate val rand limit quantize mutate val mutate rand perturb prob sel mutation gene gene gene gene gene attribute crossover perturbation node ID regs delete  max config crossover mutation perturb delete probability random PRNG schematic depict various module eve PE PEs generate genome assignment policy benefit IV gene merge gene generate gene memory genome handle gene merge pseudo random generator PRNG PRNG random cycle PEs xor wow algorithm within nvidia gpus implement PRNG network chip noc noc manages distribution gene gene split PEs collection gene gene merge explore option network bandwidth bus distribution collection however recall neat algorithm opportunity reuse genome across multiple network multicast evaluate saving SRAM VI integration briefly component genome organization described earlier gene node connection gene uniquely identify gene IDs implementation identify node gene positive integer connection gene node IDs source destination within genome gene logical cluster within cluster gene sort ascend IDs ensure organization eas implementation gene reproduction gene gene maintain newly gene gene merge logic ensures sequence memory eve dataflow gene selector finalizes respective gene split gene split logic allocates PEs generation implementation allocate PE per genome PE allocation greedy policy maximum currently SRAM exploit reuse opportunity reproduction algorithm minimize SRAM PE node gene valid node IDs genome gene addition deletion mutation information valid node prune dangle connection assignment node IDs node connection addition node connection gene genome gene cycle load fitness information microarchitecture adam mention IV adam evaluates nns generate eve processing vertex irregular NN graph choice conventional graph accelerator graphicionado pack irregular NN dense matrix vector multiplication recall eas memory requirement unlike conventional graph workload cache optimization moreover workload neural network vertex operation accumulate latter approach adam performs multiple vertex update concurrently individual vector vector multiplication packed matrix vector multiplication systolic array accumulate mac structure efficient matrix vector multiplication hardware essentially adam microarchitecture however node input vector packed matrix vector multiplication task serialization cpu generate vector node genome systolic array graph processing heavily investigate technique literature omit detail implementation sake brevity genome across multiple PEs gene genome gene merge complicate implementation genesys parameter mac PE eve PE eve adam systolic array SRAM cpu rout genesys soc consumption increase PE eve footprint increase PE eve implementation genesys soc implement genesys soc  FreePDK implement  mac adam synthesis eve PEs synthesize adam roofline function eve PEs roofline calculate assumption genesys compute capture maximum actual later discus overly pessimistic assumption consumption lower motivate memory footprint allocate MB chip SRAM SRAM exploit reuse reduce conflict data adam account contribute interconnect cortex processor core synthesis relationship SRAM PEs generate footprint PE depicts operation frequency mhz typical publish neural network accelerator PEs comfortably blanket target configuration legend inference evolution platform cpu serial serial gen cpu PLP serial gen gpu BSP PLP nvidia gtx gpu BSP PLP PLP nvidia gtx cpu serial serial cortex cpu PLP serial cortex gpu BSP PLP nvidia tegra gpu BSP PLP PLP nvidia tegra genesys PLP PLP GLP genesys PLP GLP population gene parallelism BSP bulk synchronous parallelism gpu VI evaluation methodology runtime memory footprint metric genesys correspond metric embed desktop cpu gpu platform neat python code modify evolution inference module per modify code optimize runtime efficiency gpu cpu platform exploit parallelism generate trace reproduction operation various workload cpu evaluation completion measurement cpu desktop embed desktop cpu generation intel embed cpu cortex jetson TX desktop measurement perform intel gadget jetson onboard instrumentation amplifier  capture average runtime evolution inference codebase calculate consumption gpu evaluation cpu measurement desktop nvidia gtx embed nvidia tegra jetson TX gpu node desktop gpu nvidia smi utility onboard  gpu TX runtime capture nvprof utility kernel data transfer calculation ensure correctness operation maintain apply constraint crossover precede mutation genesys evaluation trace along parameter obtain analysis estimate consumption chosen eve trace capture generation gene genome operation mutation crossover parameter delete operation trace proxy workload evaluate eve adam implementation runtime runtime OpenAI gym environment various platform evolution inference cpu evolution happens sequentially exploit PLP inference multithreading concurrent thread cpu cpu parallel inference cpu faster serial counterpart exploit maximum parallelism gpu mapping PLP GLP BSP paradigm inference implementation genesys outperforms gpu  runtime OpenAI gym environment across cpu gpu genesys runtime inference runtime evolution memory footprint distribution spent data transfer compute gpu config gpu config genesys depicts variation memory footprint application various platform  inference gpu implementation discus observation gpu dive gpu exploit GLP compaction input vector serially evaluate multiple vertex parallel genome gpu multiple vertex across genome evaluate parallel exploit GLP PLP however input longer compact sparse tensor depict contribution memory transfer runtime memory transfer runtime gpu gpu runtime memory transfer genesys comparison memory transfer however data chip actual runtime depicts overall chip memory requirement gpu gpu genesys gpu footprint sparse input matrix around gpu compact matrix genome genesys entire population memory footprint gpu population genesys footprint gpu gpu genome  chip distribution connection node various workload connection gene denser matrix inference hence utilization adam consumption consumption per generation OpenAI gym workload platform adam contributes efficiency eve magnitude efficient gpu efficient platform choice PEs SRAMs interconnect impact network chip neural network accelerator advantage reuse data reduce SRAM hence consumption data multiple PEs reading data multicasting consumer reuse multiple therefore reduce SRAM network versus multicast network reduction SRAM multicasts network motivate intelligent interconnect intelligent interconnect multiple mapping strategy gene across PEs topic future research parallelize evolution till eve PE GLP reduce compute implement GA operation hardware GLP  SRAM consumption evolution generation function eve PEs adam SRAM constant SRAM curve indicates almost monotonic improvement efficiency eve PEs linear decrease curve exponential decrease exponential increase PEs consequence GLR PE genome PEs generate operand  ram alien ram  ram composition gene genome workload SRAM per cycle multicast SRAM consumption runtime per generation function eve PE average atari workload PEs increase multiple service employ appropriate interconnect capable multicasting divert attention runtime plot reveals couple trend cycle inference intuitively typical neural network attribute factor network generate neat significantly traditional MLPs adam throughput aid  computation implement vertex update trend eve PE evolution runtime disproportionately inference exponential depicts performance wise evolution compute bound agreement observation GLP PLP decrease generation runtime benefit simulated environment interact instantly however workload interaction enables circuit technique gate compute genesys interact environment hint taper trend PEs due exploit PLP population intentionally restrict exploitable parallelism vii discussion related future direction important evolutionary algorithm application EA optimal parameter fitness function reward naturally parameter becomes convergence eas increase scenario genesys conjunction supervise former enable rapid topology exploration conventional training tune neuro evolution generate neural network category definition gene neuro evolution research eas ongoing decade evolutionary technique topology generation apart neat algorithm hyper neat  evolution nns report decade online traditional reinforcement gain traction google announce automl situ environment approach direction spike neural net SNN recently intel release SNN online chip loihi ibm truenorth SNN chip SNNs however manage demonstrate accuracy across complex task dnn acceleration hardware acceleration neural network research topic architecture choice silicon implementation accelerator replace adam inference gene layer MLPs however eve remains non replaceable hardware platform efficient evolution knowledge   kwon  chen   michael      anonymous reviewer insight IX conclusion genesys perform automate NN topology generation completely hardware characterize NE algorithm neat identify massive opportunity parallelism exploit accelerator eve adam accelerate inference component neat hardware perform optimize cpu gpu implementation suffer consumption performance due extensive memory optimize NE algorithm hardware avenue future research