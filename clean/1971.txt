effectiveness neural network dnn vision processing prompt tremendous demand efficient performance dnn inference due increase memory intensity dnn workload memory dominate consumption stall effective reduce consumption increase performance dnn inference approximate memory operates reduce voltage reduce access latency parameter violate standard specification approximate memory reduces reliability error rate fortunately neural network intrinsic capacity tolerate increase error enable efficient performance neural network inference approximate dram device observation propose eden framework reduces dnn consumption dnn evaluation latency approximate dram device strictly meeting user specify target dnn accuracy eden relies retrain dnn target approximate dram device increase dnn error tolerance efficient mapping error tolerance individual dnn data correspond approximate dram partition user specify dnn accuracy requirement evaluate eden multi core CPUs gpus dnn accelerator error model obtain approximate dram device eden dnn retrain technique reliably improves error resiliency dnn magnitude target accuracy within dnn eden enables average dram reduction cpu gpu dnn accelerator architecture respectively across variety ofthe network average maximum speedup cpu gpu architecture respectively evaluate latency bound neural network CCS CONCEPTS compute methodology neural network computer organization neural network purpose hardware dynamic memory keywords neural network error tolerance efficiency machine dram memory introduction neural network dnns effective challenge computer vision recognition translation drug discovery robotics particle physic domain dnns various flavor convolutional neural network fullyconnected neural network recurrent neural network commonly evaluate setting device demand response unfortunately dnns computational memory demand performance requirement fulfill neural network recent accelerator dnn focus architecture recent focus building specialized architecture efficient computation schedule dataflow execute dnns improvement accelerator efficiency dnn optimize gpu kernel library efficiently leverage instruction extension improve computational efficiency dnn evaluation however improve memory efficiency dnn evaluation challenge memory intensity dnn inference increase dnns grown dramatically recent model ILSVRC image recognition challenge resnext contains FP parameter GB parameter alexnet model recent model broken billion FP parameter GB machine community trend towards expressive neural network chip memory bottleneck dnn evaluation focus alleviate issue latency chip dram neural network workload dram consumption prior dnn accelerator report consume dram dram latency load cache llc longer service cache prior accelerator target dram latency challenge sparse irregular dnn inference overcome dram latency issue recent approach reduce numeric bitwidth reuse model algorithmic strategy reduce memory requirement dnn workload propose dram  latency commodity dram propose processing memory approach reduce data movement access data latency propose approach orthogonal exist customize operational parameter voltage latency exist dram chip intrinsic characteristic dnn approach insight dnns demonstrate remarkable robustness error introduce input output data error tolerance allows accurate dnn evaluation unreliable hardware dnn error tolerance accurately characterize error rate appropriately dram manufacturer performance reliability prior reduce dram voltage timing parameter improves dram consumption latency respectively reduce reliability increase error rate exploit insight propose eden framework improves efficiency performance dnn inference approximate dram operates reduce dram parameter voltage latency eden strictly user specify target dnn accuracy framework retrain mechanism improve accuracy dnn execute approximate dram dnn approximate dram information obtain rigorous characterization dnn error tolerance dram error eden eden improves error tolerance target dnn retrain dnn error characteristic approximate dram module eden profile improve dnn identify error tolerance dnn data layer dnn eden dnn data dram partition datum characteristic accordingly selects voltage latency parameter dram partition apply eden arbitrary dnn workload arbitrary approximate dram module evaluate dnn performance accuracy benefit approach eden inference dnns approximate dram reduce dram voltage vdd decrease dram consumption reduce dram latency reduce execution latency bound dnns eden adjusts dram voltage dram latency interaction memory controller firmware target accuracy within dnn eden enables average dram reduction across cpu gpu dnn accelerator tensor processing architecture cycle reduction evaluate latency bound neural network evaluation indicates benefit eden stem capacity hardware platform neural network inference CPUs gpus FPGAs dnn accelerator eden approach principle apply platform dram across memory technology parameter voltage latency expense reliability although evaluation examines voltage access latency reduction eden framework improve performance eden increase efficient neural network inference approximate dram effective memory bandwidth increase data bus frequency expense reliability contribution introduce eden framework increase efficiency performance dnn inference approximate dram operates reduce voltage latency parameter expense reliability eden systematic memory parameter voltage latency achieve user specify dnn accuracy target introduce methodology retain dnn accuracy presence approximate dram evaluation eden increase error tolerance dnn network customize retrain procedure curricular retrain systematic empirical characterization resiliency dnn workload error introduce approximate dram examine error resiliency across numeric precision prune data dnn layer precision dnn data closer layer exhibit error resiliency  prune significant impact error resiliency propose error model error approximate dram device exhibit characterize flip distribution reduce voltage latency parameter ddr dram module evaluate eden multi core CPUs gpus dnn accelerator target accuracy within dnn eden enables average dram reduction cpu gpu dnn accelerator architecture respectively across variety network average maximum speedup cpu gpu architecture respectively evaluate latency bound neural network target accuracy eden enables average saving average speedup cpu architecture background neural network neural network dnn neural network layer dnns compose variety layer convolutional layer fully layer pool layer data dnn layer dnn layer layer define matrix via  training execute dnn inference dnn data load memory layer input feature IFMs output feature OFMs layer IFMs layer OFMs OFMs layer fed layer layer IFMs explore introduction error data layer dnns layer dnn trainable existence commonly refer  source dnn accuracy layer layer layer OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs OFMs IFMs dnn layer layer compose input feature IFMs output feature OFMs  allows model sufficient capacity network approximate complex  function adequately capture semantics characteristic input image importantly  allows network obtain error resilience generalize across input robust insignificant input background pixel image training technique input feature dropout network rely ofm enable robustness presence statistical variance IFMs adapt dnns training procedure achieve partial error robustness error approximate dram fundamentally advantage  dnn quantization quantize float OFMs precision fix greatly improve performance consumption dnns prior demonstrate quantize dnns limited numeric precision integer without significantly affect dnn accuracy evaluation quantize dnn model numeric precision int int int FP prune prune reduces memory footprint dnn sparsifying feature zero magnitude retrain prune evaluation training training estimate maximize accuracy dnn inference training usually perform iterative gradient descent algorithm training dataset training dataset batch iteration batch epoch epoch completes entire dataset training algorithm dram organization operation dram organization dram device organize hierarchically dram consists capacitor access transistor capacitor encodes dram capacitor bitline via access transistor wordline dram organize 2D array subarray subarray bitline access transistor capacitor bitline shift bitline voltage capacitor bitline amplifier SA circuit detects shift amplifies wordline subarray refer dram decoder wordline enable dram therefore amplification granularity array amplifier subarray refer buffer subarray SA SA SA SA SA SA  wordline bitline access         bus dram organization typically consists typically KB organization subarrays chip dram device partially decodes address selects correspond subarray buffer operation logic sends request portion target correspond subarray buffer memory controller dram chip contains multiple parallel dram device compose multiple dram chip command address bus simultaneously access bandwidth capacity typical memory controller interface dram bus refer reader detail dram structure dram operation access data sequence memory controller command illustrate activation command activates wordline enable amplification manufacturer specify tRCD nanosecond data reliably amplify buffer command data buffer IO circuitry manufacturer specify CL nanosecond data available memory bus precharge command pre prepares dram activation another precharge command issue manufacturer specify tRAS nanosecond activation command activation command issue trp nanosecond precharge command tRCD tRAS trp CL dram timing parameter nominal dram ddr datasheets respectively pre data tRCD CL tRAS trp timing parameter command  dram timing explore reduction  tRAS trp eden evaluation CL characteristic device adjustable memory controller reduce dram parameter characterize dram behavior sub reliable operation regime voltage latency parameter dram voltage reduction voltage reduction critical reduce dram consumption proportional voltage vdd prior research reduce voltage increase propagation delay signal error unmodified timing parameter avoids error increase tRCD trp latency ensure reliable operation contrast goal aggressively reduce consumption latency decrease voltage timing parameter inevitably error flip weak dram dram approximate error exhibit locality flip accumulate dram dram access latency reduction latency reduction critical increase performance heavily emphasize recent workload dram interaction previous characterize dram device minimum reliable activation tRCD precharge trp latency accord minimum dram latency significantly datasheets report due conservative  introduce dram manufacturer reduce latency flip weak unstable dram dram refresh rate reduction voltage latency previous research reduce refresh rate dram chip increase performance reduce consumption introduce error tolerable workload tolerate error eden framework efficiently latency issue chip dram neural network workload propose eden eden framework improves efficiency performance neural network inference approximate dram eden insight neural network tolerant error dram timing parameter voltage reduce introduce error overview eden explain eden finally explains target dnn inference dnn generate eden eden overview eden enables effective execution dnn workload approximate dram boost dnn error tolerance dnn error tolerance characterization  mapping iteratively eden aggressive dnn dram configuration target accuracy requirement eden transforms dnn reliable hardware device tune dnn approximate dram target accuracy eden allows tight accuracy performance enable user specify maximal tolerable accuracy degradation overview eden boost dnn error tolerance eden introduces curricular retrain retrain mechanism boost dnn error tolerance target approximate dram module curricular retrain mechanism error characteristic target approximate dram inject error dnn training procedure boost dnn accuracy novelty curricular retrain inject error progressive rate training goal increase dnn error tolerance avoid accuracy collapse error correction eden boost dnn  mapping baseline dnn dnn error profile dnn accuracy target boost dnn     dram error profile overview eden framework intrinsic error tolerance baseline dnn boost mechanism dnn error tolerance characterization eden characterizes error resilience boost dnn data IFMs OFMs dnn identify limit error tolerance eden error overall accuracy dnn validation dataset error tolerance characterization dnn dram mapping eden error tolerance dnn data correspond approximate dram partition chip subarray specify accuracy requirement maximize performance dnn dram mapping eden enable baseline dnn become specialized dnn error tolerant device tune target approximate dram eden enables efficient highperformance dnn inference target approximate dram user define accuracy boost dnn error tolerance accord evaluation error tolerance dnns sufficient enable significant dram voltage timing parameter reduction overcome issue propose curricular retrain retrain mechanism improves error tolerance dnn approximate dram injects error memory location access dnn curricular retrain observation introduce error rate immediately retrain occasionally training divergence phenomenon accuracy collapse mitigate curricular retrain slowly increase error rate approximate dram target wise fashion training convergence rate increase error rate epoch entire training dataset eden approximate dram pas reliable dram backward pas demonstrate curricular retrain mechanism effective improve accuracy dnn inference execute approximate dram curricular retrain improve dnn accuracy reliable dram implies introduce error regularization technique obtain congruence dnn training algorithm error inject approximate dram implausible execute curricular retrain error exponent float regularization technique slight modification training algorithm dnn model generalizes accuracy collapse dnn error exponent creates enormously propagates dnn layer dominate significantly avoid issue propose mechanism avoid accuracy collapse error introduce approximate dram mechanism implausible load memory mechanism probabilistically detects data likely contains error predefined threshold threshold curricular retrain data compute training baseline dnn dram nominal parameter threshold usually squeezenet within upon detection error threshold curricular retrain eden corrects erroneous zero curricular retrain mechanism implausible implement software implementation modifies dnn framework extra instruction implausible dnn memory access hardware implementation hardware logic memory controller corrects implausible approximate dram memory request describes hardware implementation mechanism implausible increase tolerable error rate achieve accuracy degradation FP dnns analyze evaluate alternative mechanism error correction saturates threshold reset closest threshold instead zero saturate obtains dnn accuracy zero approximate dram error rate across dnn model cifar imagenet implausible execution dnn inference improve inference accuracy dnn error tolerance characterization eden aim guarantee accuracy dnn minimum user eden characterizes boost dnn obtain boost mechanism maximum tolerable error rate ber progressively decrease approximate dram parameter voltage latency eden performs coarse grain grain dnn error tolerance characterization coarse grain characterization eden coarse grain characterization determines ber apply uniformly entire dnn meeting accuracy requirement user characterization useful mapping dnn commodity apply reduce dram parameter entire dram module without grain ber satisfies accuracy goal coarse grain characterization performs  binary error rate binary dnn error tolerance curve monotonically decrease adjust ber characterization eden tune parameter approximate dram dram error model inject error memory location eden optimizes error resiliency dnn cycle dnn error tolerance boost coarse grain dnn characterization dnn dram mapping tolerable ber improve evaluate coarse grain characterization mechanism grain characterization eden exploit variation error tolerance dnn data cluster data accord error tolerance assign cluster dram partition error rate error tolerance cluster convolutional layer tolerable bers average layer dnn agreement prior conduct grain dnn characterization eden tolerable ber ifm yield acceptable dnn accuracy exponential respect dnn layer tackle challenge eden employ dnn data sweep procedure performs iteration dnn data mechanism increase tolerable error rate data amount dnn accuracy requirement dnn data cannot tolerate increase error rate remove sweep evaluate grain characterization mechanism prune eden prune boost routine due observation dnn sparsification improve error tolerance sparsity aware prune error tolerance FP int dnns dnn error tolerance improve significantly zero network increase prune sensitive memory error perturbation dnn dram mapping characterize error tolerance dnn data eden data appropriate dram partition appropriate voltage latency parameter satisfies data error tolerance mechanism aim data tolerant  error dram partition ber error tolerance dnn ber dram partition dram error rate characterization obtain ber characteristic dram device aggregate partition perform reduce voltage reduce latency data voltage iteratively consecutive invert data evaluation reduce timing parameter tRCD characterization grain dram timing parameter voltage eden characterization mechanism experimental dram characterization mechanism propose evaluate prior dram voltage dram latency coarse grain dnn dram module mapping dnn data within dram module expose dram voltage timing parameter parameter tune error rate tolerable dnn data mapped module coarse grain mapping application modify algorithm dnn inference oblivious dram mapping memory controller memory controller inference related request appropriate approximate dram module data cannot tolerate error reduce voltage latency dram module voltage latency parameter manufacturer specification coarse grain mapping easily exist modification   RP parameter bios across entire dram module describes hardware coarse grain mapping evaluate coarse grain mapping mechanism grain dnn dram module mapping dnn data dram partition expose dram voltage timing parameter dram partition chip rank subarray granularity algorithm describes algorithm grain mapping dnn data dram partition algorithm rigorous dram characterization dnn characterization iteratively assign dnn data dram partition mechanism dram partition bers tolerable ber dnn data dram partition parameter reduction ber requirement partition available mechanism assigns dnn data dram partition evaluate grain mapping mechanism algorithm grain dnn dram mapping function dnn dram mapping dnn characterization dram characterization sort data sort dnn data dnn characterization target ber dnn data sort data dram partition voltage latency target ber dnn data dram partition dram characterization partition params voltage latency dram partition target ber dnn data dram partition partition params parameter parameter partition params chosen partition dram partition dram partition dnn data mapping chosen partition append dnn data return mapping grain mapping memory controller voltage latency adjustment dram voltage adjustment hardware grain mapping dnn inference approximate dram eden generates boost dnn inference target approximate dram eden modification dnn inference hardware framework algorithm implausible happens curricular retrain error exponent float accuracy collapse dnn inference mechanism implausible curricular retrain mechanism zero outside predefined threshold avoid accuracy collapse error introduce approximate dram dnn inference  eden error MODELS eden extensive characterization target approximate dram device boost dnn error tolerance characterization dnn error tolerance mapping dnn approximate dram device however apply eden target dnn inference perform feasible practical  dnn inference accelerator perform slowly execute curricular retrain mechanism optimize training similarly target hardware available limited availability pre production phase approximate hardware enable eden target dram device available characterization propose execute eden framework target approximate eden offload challenge offload eden faithfully emulate error inject target approximate dram dnn address challenge error model representative error approximate dram module eden dram error model eden probabilistic error model closely error approximate dram module model information location weak dram module spatial distribution error dnn error tolerance boost error model data obtain characterization exist dram device SoftMC variety ddr ddr dram module error model consistent error prior addition error model parameterizable tune model individual dram chip rank subarrays vendor error model error uniform random distribution across dram prior reduce activation latency tRCD precharge latency trp randomly distribute flip due manufacturing variation dram model error parameter percentage weak fail reduce dram parameter FA probability error weak uniform random distribution already prior error model error vertical distribution across bitlines dram prior bitlines flip others reduce dram parameter due manufacturing variation across amplifier induced latency variation arises distance bitlines decoder model error distribution parameter PB percentage weak bitline FB probability error weak bitline error rate vendor xff  xaa voltage vendor vendor error rate vendor tRCD vendor vendor error rate data dram reduce voltage reduce tRCD motivate error model data ddr dram module vendor error model error horizontal distribution across wordlines dram prior dram flip others reduce dram parameter due manufacturing variation across dram induced latency variation arises distance dram buffer model error distribution parameter PW percentage weak wordline FW probability error weak wordline error model error uniform random distribution depends content data dependent error model illustrates error rate data dram reduce voltage reduce tRCD flip tRCD flip voltage prior rigorous analysis data dram reduce voltage timing parameter error model parameter percentage weak FV probability error weak FV probability error weak model selection eden applies maximum likelihood estimation MLE procedure parameter FA PB FB PW FW FV FV error model error model likely error approximate dram chip model probability error selection mechanism chooses error model error model randomly otherwise selection mechanism error model error model performs generate inject error software error model dnn retrain inference faster inject error error model experimental setup error model reasonable approximation error model max FB min FB PB reasonable approximation error model max FW min FW PW handle error variation error rate error factor factor intrinsic dram device intrinsic factor manufacturer chip variability intrinsic factor establish dram fabrication factor extrinsic dram device environmental operating extrinsic factor data extrinsic factor introduce significant variability error eden capture intrinsic factor error model unique dram characterization pas however capture extrinsic factor error model challenge dnn model capture factor extrinsic dram device eden capture data dependent error generate error model dnn model ifm memory dnn model eden actual ifm target approximate dram characterization capture data dependency eden capture variation generate error model approximate dram operating error increase model dnn inference execution eden capture dram periodically regenerate error model dram module error temporally consistent stable continuous execution deviation profile without characterization prior report evaluation error model sufficiently expressive generate boost dnn executes approximate dram minimal accuracy loss error model sufficiently expressive encompass error model propose prior memory controller obtain eden modify memory controller implausible curricular retrain dnn inference coarse grain memory mapping grain memory mapping hardware implausible implausible accuracy collapse curricular retrain dnn inference mechanism load upper bound bound threshold zero load zero bound operation memory access load dnn significant performance degradation perform software mitigate issue incorporate hardware logic memory controller bound logic bound logic exponent load float dnn specific upper bound bound threshold zero input bound implementation latency logic cycle hardware negligible enable coarse grain mapping coarse grain mapping applies voltage timing parameter entire dram execute dnn workload however dnn workload apply dram parameter maximize saving performance exist commodity memory controller dram voltage timing parameter runtime overcome limitation memory controller minimal hardware dram parameter dram module runtime enable grain mapping grain mapping applies voltage timing parameter dram partition apply voltage memory partition eden adopts approach  implement robust voltage granularity modest delivery network memory partition operating voltage implement mechanism commodity ddr LPDDR chip eden meta data voltage apply timing parameter memory partition eden memory controller configure target memory partition specific timing parameter memory partition operating latency timing parameter evaluation tRCD encode parameter resolution sufficient eden split dram partition commonly dnn architecture error resilient IFMs eden KB metadata partition mapping subarray granularity granularity eden amount metadata 8GB ddr dram module subarrays eden KB metadata dnn accuracy evaluation evaluate eden ability improve dnn accuracy approximate dram explain methodology evaluate accuracy error model evaluate error tolerance dnn baseline analyze accuracy curricular retrain mechanism methodology fpga infrastructure SoftMC reduce dram voltage timing parameter SoftMC allows execute memory controller command individual modify tRCD dram timing parameter perform infrastructure obtain characteristic approximate dram device however infrastructure performance limitation delay introduce SoftMC fpga buffering  data transmission instruction batching fpga overcome performance limitation emulate approximate dram module error model described ensure evaluation accurate validate error model approximate dram device incorporate eden error model dnn inference library methodology described framework pytorch allows modify load IFMs pytorch implementation injects error ifm dram error model applies mechanism implausible error IFMs dram error model implement custom gpu kernel efficient integration pytorch simulation allows obtain dnn accuracy estimate faster SoftMC infrastructure    ifm  implausible ifm methodology incorporate dram error model dnn evaluation framework dnn baseline dnn baseline evaluation eden commonly dnn model evaluate target cifar ILSVRC image classification datasets resnet vgg densenet model winner imagenet ILSVRC competition google MobileNetV  network widely mobile platform squeezenet embed application sum IFMs network processing input indicator memory intensity dnn model model dataset model ifm resnet cifar MB MB MobileNetV cifar MB MB vgg ILSVRC MB MB densenet ILSVRC MB MB squeezenet ILSVRC MB MB alexnet cifar MB MB yolo mscoco MB MB yolo mscoco MB MB lenet cifar MB MB model evaluation experimental setup model dnn model evaluation model sum ifm FP variant model accuracy obtain baseline network across numeric precision int int int FP reliable commodity dram quantize popular symmetric linear dnn quantization scheme quantization scheme applies dependent affine linearly target model precision yolo yolo framework int FP numeric precision baseline accuracy relevant literature model densenet squeezenet suffer accuracy collapse precision hyper parameter tune baseline subsequent default dnn architecture rate accuracy validation error model eden error obtain dram device accurate error model profile dram model int int int FP resnet MobileNetV vgg densenet squeezenet alexnet yolo yolo lenet model average precision  instead accuracy metric baseline accuracy network evaluation reliable dram memory error numeric precision dnn inference environmental factor affect error error model accurate environmental significantly prior derive probabilistic error model data obtain dram module fpga infrastructure described profile 4GB ddr dram module evaluation setup profile sophisticated dram profile methodology validate error model dnn accuracy obtain inject error dram error model accuracy obtain approximate dram module dnn accuracy obtain dram module vendor reduce voltage tRCD dnn accuracy obtain error model error model model error dram module observation dnn accuracy obtain model obtain approximate dram device conclude error model mimic error approximate dram device voltage accuracy tRCD vendor SoftMC vendor SoftMC vendor SoftMC vendor error model vendor error model vendor error model lenet cifar accuracy obtain approximate dram device via SoftMC error model error confidence interval error model error tolerance baseline dnns understand baseline error tolerance dnn boost error tolerance examine error tolerance baseline dnns difference quantization error model ber potentially affect dnn accuracy accuracy resnet precision bers error model dnns exhibit accuracy ber error model dnns error model  error dnn IFMs error model exhibit extreme offs FP dnns experimental setup IFMs align dram  dnn data mapped bitline percentage weak bitline PB dnn suffers msb failure however error model distributes weak failure uniformly randomly across msb failure error model capture distribution weak across data layout memory greatly affect impact error curve accuracy error model error model ber accuracy error model ber error model resnet accuracy across bers axis quantization error model inject error parameter error model error reduce tRCD dram device vendor quantization precision affect error model error tolerance curve error model int dnn weak error tolerance curve error model cluster weak along corrupt error model indicates weak wordline contrast precision distribute evenly across error model capture error locality error model cluster erroneous significant accuracy error compound faster interact dnn locality error bitwidth precision spatial correlation error model error model dnn dnns vgg error resilient model exhibit accuracy ber model squeezenet plot accuracy collapse accuracy collapse phenomenon implausible increase error rate network implausible propagate accuracy collapse dnn curricular retrain evaluation dnn inference dram device boost dnn model generate curricular retrain mechanism knowledge demonstration dnn inference approximate memory evaluate curricular retrain mechanism error model experimental setup evaluate curricular retrain dram device lenet cifar validation dataset SoftMC vdd tRCD fpga infrastructure ddr dram module evaluate curricular retrain error model resnet cifar validation dataset dram accuracy baseline lenet without apply retrain mechanism baseline lenet boost curricular retrain mechanism boost function dram voltage tRCD observation eden boost lenet allows voltage reduction tRCD reduction maintain accuracy equivalent nominal voltage nominal tRCD accuracy baseline lenet decrease quickly reduce voltage tRCD nominal conclude curricular retrain mechanism effectively boost accuracy lenet approximate dram reduce voltage tRCD voltage accuracy baseline boost tRCD lenet accuracy baseline boost dnns error model  resnet model error model closely device error model observation retrain error model yield improvement baseline retrain retrain error model improves ber accuracy shift ber curve conclude error model retrain mechanism critical avoid accuracy collapse effectiveness curricular retrain mechanism error model observation accuracy dnn regular retrain purple collapse baseline dnn retrain dnn curricular retrain orange exhibit boost error tolerance conclude curricular retrain mechanism effective boost dnn accuracy approximate dram retrain epoch sufficient boost tolerable bers achieve dnn accuracy error rate accuracy error model error model baseline non curricular retrain curricular retrain baseline accuracy boost resnet dnns presence memory error accuracy error model accuracy non curricular curricular retrain error model baseline dnn execute dram nominal parameter resnet cifar nvidia tesla boost completes within coarse grain dnn characterization mapping eden coarse grain dnn characterization target dnn model approximate dram optimize parameter target accuracy degradation characterization dnn maximum tolerable ber dnn model FP int numeric precision FP int model ber vdd tRCD ber vdd tRCD resnet MobileNetV vgg densenet squeezenet alexnet yolo yolo maximum tolerable ber dnn eden coarse grain characterization dram parameter reduction achieve maximum tolerable ber nominal parameter vdd tRCD maximum tolerable ber demonstrates significant variation dnn model yolo tolerates ber squeezenet tolerates conclude maximum tolerable ber highly depends dnn model dnn characterization optimize approximate dram parameter dnn model mapping eden dnn model approximate dram module operates maximum reduction voltage vdd tRCD tRCD ber maximum dnn tolerable ber dnn model maximum reduction dram voltage vdd tRCD tRCD dram ber maximum tolerable ber target dram module vendor nominal dram parameter dram module vdd tRCD observation tolerable ber network directly related maximum tolerable vdd tRCD reduction reduction vdd tRCD significant nominal eden reduce voltage tRCD yolo maintain dnn accuracy within accuracy grain dnn characterization mapping characterization characterize resnet dnn model grain dnn characterization procedure ifm iteratively increase error rate maximum tolerable ber data target accuracy degradation perform network retrain iteration reduce runtime procedure sample validation inference obtain accuracy estimate bootstrap bers ber coarse grain dnn characterization linear increment around resnet characterization completes intel xeon cpu maximum tolerable ber ifm resnet obtain grain dnn characterization assume maximum accuracy loss ber tolerance ifm depth dnn deeper observation grain characterization enables individual IFMs tolerate ber maximum tolerable ber coarse grain approach resnet usually tolerate error IFMs maximum tolerable ber layer layer dnn conclude grain dnn characterization enables significant increase maximum tolerable ber coarse grain characterization IFMs ber IFMs grain characterization tolerable bers resnet IFMs deeper layer mapping individual ifm dram partition ber tolerance ifm ber dram partition algorithm resnet IFMs dram partition voltage parameter introduce bers horizontal algorithm conclude tolerable bers across resnet data enables dram partition significant voltage reduction horizontal dram partition moderate voltage reduction horizontal evaluation evaluate eden dnn inference architecture CPUs gpus inference accelerator IFMs ber IFMs mapping resnet IFMs partition vdd horizontal cpu inference experimental setup evaluate eden multi core OoO cpu simulated core configuration zsim ramulator simulate core dram subsystem respectively  estimate consumption ddr device channel 8GB ddr dram device core core ghz OoO buffer entry fetch entry decode entry reorder buffer cache KB cycle split data instr cache KB per core cycle data instr prefetcher cache MB per core cycle data instr prefetcher memory 8GB ddr dram channel channel simulated configuration twelve inference benchmark intel  toolkit  fork darknet framework dnn FP int quantize variant quantization baseline commonly production cpu workload evaluate eden coarse grain dnn characterization procedure target accuracy degradation reduce vdd tRCD dram dram saving eden dram operating nominal voltage nominal latency observation eden achieves significant dram saving across dnn model average dram saving across workload yolo vgg dram saving FP int roughly voltage reduction precision FP int FP int FP int FP int FP int FP int FP int dram reduction yolo yolo resnet vgg  gmean dram saving eden FP quantize int network perform evaluation target accuracy eden enables average dram reduction conclude eden effective dnn inference reduce voltage maintain dnn accuracy within performance speedup eden reduce tRCD speedup dram module ideal tRCD dram nominal timing parameter observation yolo dnns exhibit speedup eden speedup yolo average yolo sensitive dram latency yolo non maximum suppression confidence iou thresholding perform arbitrary index matrix random memory access cannot easily predict prefetchers average speedup eden average speedup ideal tRCD squeezenet resnet exhibit maximum theoretical speedup bottleneck memory latency FP int FP int FP int FP int FP int FP int FP int speedup yolo yolo resnet vgg squeezenet densenet gmean eden tRCD speedup eden baseline versus ideal activation latency FP quantize int network perform evaluation target accuracy eden enables average performance gain conclude eden effective improve dnn inference performance reduce dram latency maintain dnn accuracy within dnns sensitive memory latency accelerator evaluate eden accelerator gpu eyeriss tpu gpu inference evaluate eden gpu cycleaccurate gpgpu sim simulator  evaluate overall gpu consumption detail nvidia titan gpu model evaluation reduce tRCD vdd accuracy degradation adapt darknet binary inference FP int yolo yolo dnns shader core SMs mhz SIMT width warp per SM  scheduler per core private cache KB per SMM cache memory KB cache MB memory GDDR mhz channel chip simulated nvidia titan gpu configuration eden average reduction yolo yolo gpu dram nominal parameter eden average speedup yolo yolo gpu dram nominal parameter dram ideal tRCD tRCD speedup yolo speedup yolo yolo dnn dram latency bound evaluation configuration eden achieve ideal speedup zero activation latency dnn latency bound neural network inference accelerator evaluate eden eyeriss google tensor processing tpu cycle accurate sim simulator  obtain dram consumption memory trace sim built int alexnet yolo model accelerator specific dataflows dram parameter yield maximum accuracy loss detail configuration eyeriss tpu inference accelerator eyeriss array processing PEs KB SRAM buffer data IFMs OFMs tpu array PEs MB SRAM buffer data evaluate accelerator ddr LPDDR dram configuration alexnet yolo workload eyeriss tpu array PEs PEs SRAM buffer KB MB memory 4GB ddr 4GB ddr 4GB LPDDR 4GB LPDDR simulated eyeriss tpu configuration reduce voltage ddr dram significant dram reduction eyeriss tpu accelerator eden average dram saving eyeriss yolo alexnet average dram saving tpu yolo alexnet reduce voltage LPDDR ddr eden average dram reduction eyeriss tpu accelerator yolo alexnet accelerator network cache dram breakdown eyeriss evaluation alexnet estimate eden systemlevel reduction fully layer systemlevel reduction convolutional layer reduce tRCD LPDDR ddr eyeriss tpu exhibit speedup reduce tRCD prefetchers effective architecture memory access evaluate dnns predictable related knowledge propose framework reduces consumption increase performance dnn inference approximate dram reduce voltage latency eden introduces methodology improve dnn tolerance approximate dram error dnn error tolerance characterization curricular retrain mechanism demonstrate effectiveness eden error approximate dram device discus closely related approximate compute hardware dnn workload modify dram parameter approximate compute hardware dnn workload prior propose approximate compute hardware execute machine workload propose technique improve dnn tolerance approximate hardware mechanism error injection rate eden unique approximate dram reduce voltage latency demonstration dnn inference error characterization approximate dram device novel curricular retrain mechanism customize dnn tolerate error rate inject target approximate dram mapping dnn data dram partition error tolerance dnn data error rate dram partition classify related approximate hardware dnn workload category reduce dram refresh dnn rana  propose reduce dram refresh rate embed dram eDRAM memory dnn accelerator propose apply refresh optimization technique chip dram dnn accelerator mechanism customize retrain mechanism improve accuracy dnn presence moderate amount error error tolerance neural network uniform random fault SRAM memory analyze various numeric representation error tolerance  proposes algorithm aware fault mitigation technique mitigate voltage SRAM dnn accelerator approximate arithmetic logic dnn workload  proposes  voltage arithmetic fault mitigation technique neural network minimize error faulty register logic prune retrain fourth approximate emerge memory technology neural network acceleration kim propose neuromorphic accelerator   proof concept fuzzy neural network fifth approximate storage device dnn workload error tolerance neural network approximate non volatile memory nvm medium author ecc nvm medium neural network data propose mitigate unreliable disk specialized ecc variant aim mitigate error shallow neural network sixth intrinsic error resilience dnns inject randomly distribute error dnn data assume error component target specific approximate hardware component accuracy dnns error injection rate propose various error mitigation technique probabilistic artificially inject error dnn model  algorithm optimizes dnn accuracy account error tolerance criticality component network quality configurable neuromorphic processing  processing dynamically configurable accuracy execute approximate neural network modify dram parameter prior modify dram parameter reliability performance consumption already discus prior reduce dram voltage access latency refresh rate eden leverage characterization technique introduce  flexible latency dram perform dram characterization dnn approximate dram reduce voltage reduce latency classify related modify dram parameter category aim characterize reduce consumption reduce voltage propose memory dynamic voltage frequency DVFS reduce dram MemScale dynamic voltage frequency memory reduce consumption meeting maximum tolerable performance degradation  voltage reduction dram device detail proposes reduce voltage reliably error characteristic performance requirement  proposes dram model characteristic dram device investigate dram characteristic reduce access latency adaptive latency dram characterizes  timing parameter define dram manufacturer exploit extra timing margin reliably reduce dram latency across chip flexible latency dram analyzes spatial distribution reduce latency induced failure information reliably access dram timing parameter  dram proposes automatic reliable operation latency dram via combination runtime profile ecc aim reduce dram latency modify microarchitecture dram memory controller reduce latency without introduce error conclusion introduces eden framework enables efficient performance dnn inference via approximate dram strictly meeting target dnn accuracy eden iterative mechanism profile dnn target approximate dram reduce voltage timing parameter eden improves dnn accuracy novel curricular retrain mechanism tolerates error rate evaluate eden simulation hardware evaluation eden enables average dram reduction cpu gpu eyeriss tpu architecture respectively across variety dnns average maximum performance gain CPUs gpus latency bound dnns core principle eden generalize across memory device memory parameter memory technology eden enables research development approximate memory machine workload