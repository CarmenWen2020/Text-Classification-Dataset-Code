generalize tensor algebra prime candidate acceleration via customize ASICs tensor feature data sparsity density non zero proposes novel approach accelerate tensor kernel principle hierarchical elimination computation presence sparsity approach relies rapidly   operand multiplication non  data fetch mechanism avoid memory latency overhead associate sparse kernel implement software propose extensor accelerator novel handle sparsity hardware enable bandwidth utilization compute throughput evaluate extensor kernel relative library intel mkl tensor algebra compiler taco bandwidth normalize demonstrate average speedup SpMSpM SpMM  ttm SDDMM kernel respectively server cpu CCS CONCEPTS computer organization purpose keywords tensor algebra sparse computation hardware acceleration introduction recently surge generalize tensor algebra  machine data physical engineering graph analytics tensor generalize vector matrix dimension tensor kernel combine tensor computation traditional dimensional dense sparse linear algebra sequence  intensive operation matrix multiplication tensor operation sparse data percentage data non zero percentage non zero domain domain feature tensor density tensor compress representation via metadata compress sparse csr compress sparse  CSF non zero tensor variety tensor kernel extreme sparsity compress representation tensor algebra challenge platform architecture community propose accelerator sparse linear algebra relatively dense data neural network speciic kernel sparse matrix vector purpose platform CPUs gpus cannot peak performance variety memory latency proposes novel approach accelerate generalize tensor algebra eicient handle sparse tensor opportunity sparsity tensor operation potential exploit axiom scalar various platform exploit opportunity remove inefectual computation avoid deliver stag  perform insight micro october columbus usa  dense linear algebra dense neural network sparse neural network density internet social medium recommendation fluid dynamic computational chemistry  protein statistic circuit simulation finite density tensor sparsity workload domain tensor algebra opportunity applies scalar tile recognize operand transfer data metadata entire tile evaluate tensor computation recognize operand skip operation data metadata transfer opportunity  corresponds tile tensor mathematically detect skip calculate intersection   non zero tensor operand importantly coordinate associate scalar tile sub computation etc hierarchically eliminate intersection propose extensor accelerator architecture built around perform hierarchical composition intersection eliminate inefectual computation extensor tensor metadata data processing decouple metadata aggressively ahead computation discover inefectual computation deliver arithmetic apply bufer hierarchy stage sub tile sub computation arithmetic perform minimal amount overall contribution knowledge propose irst accelerator sparse tensor algebra  intersection coordinate non zero  intersection opportunity skip due sparsity sparse tensor algebra applies diferent granularity scalar tile propose hardware mechanism optimization perform intersection multiple accelerator memory hierarchy extensively evaluate extensor tensor kernel implement core hardware component rtl bandwidth normalize demonstrate average geomean speedup SpMSpM SpMM  ttm SDDMM kernel respectively server cpu biology extensor muscle contraction limb  analogous perform intersection unravel sparse tensor computation linear desire operation tensor coordinate dimension dimension entry dense tensor csr compress representation dimension minor dimension entry per nonzero compress array coordinate array array tensor terminology compression csr background review detail tensor algebra relevant computer architecture propose approach additional information terminology mathematical notation taco tensor algebra compiler tensor terminology representation tensor multi dimensional array arbitrary dimensionality notation tensor brevity tensor scalar tensor vector tensor matrix tensor tensor matrix  location tensor refer  tuple coordinate dimension notation coordinate concatenate subscript tensor xij concatenation introduces ambiguity clarify parenthesis tensor frequently sparse compress representation avoid zero data memory various domain speciic compress representation exist minimize storage enable highperformance access non zero data generally compress format metadata index compress data structure actual data non zero tensor memory dense uncompressed tensor translation coordinate data permit eicient random access compress representation random access coordinate sequential traversal tensor leverage metadata format improve  tensor compress sparse csr format access completely random memory indirection ind bound via array appropriate inner dimension coordinate coordinate array however perform non zero derivable meaning operation subsequent non zero perform tensor representation dimension dense uncompressed compress extensor accelerator sparse tensor algebra micro october columbus usa tensor kernel blas routine scalar tensor tensor convolution consistency precedence meaning gemv  tensor index notation gemv   gemm zij    zij  ttm   SDDMM zij cij  MTTKRP zij  2D conv  cnn layer    refer speciic format notation deined regular expression taxonomy tensor matrix csr format categorize correspond irst dimension uncompressed dimension compress compress sparse csc format categorize irst dimension dimension representation compress sparse fiber CSF format corresponds representation described dimensional tensor dimension uncompressed compress random access storage random access translate tuple coordinate data  dimension uncompressed dimension traverse compress dimension storage uncompressed dimension allocate metadata proportional dimension whereas compress dimension allocate storage proportional non zero dimension importantly dimension compress opportunity avoid data metadata dimension tensor compress metadata data contains zero tensor algebra kernel tensor algebra perform binary operation multiplies dot tensor tensor tensor index notation compact kernel functionality matrix AB zij  output dot along important kernel kernel useful diferent domain gemv gemm application SDDMM kernel machine counting MTTKRP tensor decomposition 2D conv image processing application cnn layer core kernel image recognition tile tensor algebra sparse tensor tile improve locality dimension tensor representation matrix csr dimensional tile dimension representation outer dimension tile csr traverse outer dimension index tile importantly compress outer dimension imply storage tile zero multiple tile entail dimension eicient tile dependent traversal kernel  pre processing acceptable tensor community appropriate compression format data intersection  tensor kernel composition computation generate iteration possibly diferent dimension tensor equation matrix perform iteration dimension corresponds traverse correspond matrix matrix iteration merge source tensor sometimes additionally reduce via accumulate via dot min max important observation iteration multiplication merge intersection operation intersection coordinate correspond non zero operand intersection enable skip computation data transfer diferent intersection opportunity matrix equation matrix takeaway intersection model comparison coordinate hardware mechanism perform diferent intersection illustrate matrix matrix matrix AB matrix indicates zero along dimension coordinate dimension operand intersection visualize tensor indicates coordinate dimension unique non zero data associate coordinate matrix dimension label outermost immediately subtree coordinate   micro october columbus usa  contains zero data omit subtree dimension corresponds diferent data layout  intend traversal diferent  output stationary prefer matrix diferent layout col zij aik  zij aik  output stationary stationary  matrix intersection coordinate datalow dash oval importantly representation conveys information representation csr CSF hiding implementation detail furthermore format generally coordinate within sequentially memory spatial locality traverse intersection within dot suppose matrix kernel implement output stationary datalow output zij compute output stationary correspond active nonzero operation intersection coordinate respectively corresponds intersect coordinate dimension matrix representation coordinate involve intersection compute dot  dash oval coordinate oval data matrix matrix compute upon subtrees intersect coordinate scalar intersection load computes associate scalar operation intersection across dot intersect coordinate tensor dimension closer diferent eliminates associate entire  intersection stationary datalow matrix laid intersection coordinate dimension irst dimension coordinate dimension eliminates multiplies subtree coordinate irst dimension broadcasting scalar across eliminate fetch data metadata multiplies coordinate irst dimension zero eliminates associate scalar matrix intersection tile granularity recall tile implement additional dimension compress representation opportunity apply scalar etc matrix replace tile subtrees meaning perform intersection tile granularity eliminate load compute tile entire tile zero intersection opportunity hierarchical composition intersection intersection opportunity arise kernel involve tensor SDDMM kernel performs wise multiplication matrix matrix multiplication composition intersection compute intermediate matrix AB coordinate subsequently intersect suppose intersect compute coordinate intersect dot AB inefectual skip likewise dot AB zero occurs empty intersection correspond eliminate fetch compute data   previous multiple opportunity intersection various arithmetic data metadata transfer sub computation etc observation various intersection opportunity computation namely intersection operation coordinate dash oval hardware content oval coordinate hardware  intersect iterate tensor kernel hierarchically intersect described simplicity simplest intersection coordinate intersection however individual coordinate consists metadata storage interface hardware FSM iterates storage combine scanner scanner perform operation iterate output coordinate metadata storage increase coordinate denote explicit command interface extensor accelerator sparse tensor algebra micro october columbus usa iteration FSM metadata storage iterate request response coordinate coordinate eos scanner scanner hardware storage shade hardware syntax assume iterate output coordinate iteration scanner output eos metadata storage implement multiple cache  scratchpad  implementation mechanism ill coordinate metadata storage  scratchpad storage ill demand load iteration FSM explicit fetch respectively simplify iterate command implementation coordinate  increase intersect intersect iterate scanner parallel processing hardware intersect generalizes intersect parallel discus simplicity scanner scanner intersect empty empty flush flush peek peek pop peek peek pop peek peek pop pop iterate iterate intersection hardware algorithm fifo terminology irst consumer denote respectively tick coordinate generate scanner respectively checked via peek coordinate coordinate  coordinate output otherwise coordinate lag inefectual via pop output cycle functionally coordinate finally empty intersection exit via flush  coordinate employ vector pipeline intersect scanner vector coordinate assume scanner coordinate per cycle simplicity  hardware scanner pipelined iterator coordinate per cycle likewise intersect pipelined perform iteration loop per cycle completes intersection   cycle intersection hardware performance  ideally intersect   cycle minimum amount output coordinate   intersection proportional sum timing intersect cycle cycle intersect intersect architecture  timing coordinate lighten previous cycle popped previous cycle coordinate terminate intersection iterate partially completely coordinate coordinate scenario occurs frequently intersect data tensor highly diferent density occurs important application breadth irst empty intersection detect terminate intersection immediately output empty  intersection propose optimize intersection architecture remove bottleneck previous observation illustrate intersection contains coordinate generally intersection coordinate semantically content addressable lookup strawman implement linear iterate micro october columbus usa  coordinate speedup intersection core task architect faster content addressable coordinate consecutive coordinate interpret coordinate inefectual consecutive coordinate interpret hint scanner coordinate interval namely coordinate inefectual output scheme   coordinate shot importantly  skip coordinate within content addressable lookup previous identify skip mechanism combine observation functionality scanner SkipRange tuple coordinate input scanner SkipRange command bidirectional fashion decrease coordinate intersect quickly respective suppose scanner iterate operation output scanner receives SkipRange command skip output coordinate coordinate coord scanner scanner handle coord output coord consume SkipRange command cycle coord output coord consume SkipRange command cycle coord output coord consume SkipRange command SkipRange efect scanner coordinate already scanner enters multiple cycle transition coordinate architect eicient content addressable lookup immediately intersect scanner scanner iterate iterate SkipTo SkipTo coordinate coordinate metadata storage priority decoder mux coordinate address request  response intersection  skip coordinate SkipTo implementation input coordinate  cam capacity  cam register storage shade overall iterate scanner conceptually scanner initiate SkipRange operation consecutive coordinate SkipRange internally performs content addressable lookup advance consecutive tuples coordinate trigger SkipRange coordinate optimization implement SkipRange coordinate coordinate denote  variant SkipTo clarity importantly synchronization correctness scanner consume SkipTo command coordinate coordinate argument previous SkipTo cycle eos timing optimize intersect architecture simplicity assumes SkipTo skip coordinate cycle crucially SkipTo operation trigger coordinate successfully output scanner timing corresponds assume implement content addressable lookup cycle scanner initiate SkipTo operation scanner coordinate scanner previously SkipTo command scanner skip coordinate iteration scanner coordinate content addressable lookup coordinate input SkipTo  ind address metadata storage correspond coordinate    ability quickly ind  coordinate coord critical  SkipTo diferent implementation diferent ofs binary hash simplicity implement hardware cam parallel comparators coarse grain cam comparator coordinate address coordinate metadata storage coordinate coordinate assign comparator partition coordinate pre compute representation assume coordinate assign consecutive   calculate  metadata perform SkipTo command scanner advance coordinate associate comparator  comparators parallel extensor accelerator sparse tensor algebra micro october columbus usa lookup cycle parameter SkipTo  yield coarser grain potentially skip increase lastly coordinate load register comparators iterate although scanner sequence hide comparator load bufer register associate comparators metadata storage ill register earlier intersect   intersect coordinate evaluate tensor kernel intersect multiple sequence stage intersection subsequent intersection arithmetic operation perform task hardware coordinator coordinator coordinator scanner intersect FSM schedule scanner memory tensor data logic corresponds loop nest representation tensor kernel   sequencer scanner MD storage scanner MD storage data storage data storage coord coord SkipTo   coord configure TCA TCB coord output  input  coordinator indicates nonempty iterate MD metadata TCA TCB append tile coordinate output data output derive later throughout output stationary sequence source assume scanner metadata storage generalize multidimensional tile coordinate corresponds  tile representation conceptually subtree argument scanner iterate functionality node dimension node coordinate coordinate reserve iterate coordinate matrix information  coordinate subpath tile node iterate specify dimension node coordinate iterate return empty representation extra hardware per scanner feature traversal logic sequencer responsible iterate scanner tensor kernel purpose sequencer  configure programmed kernel representation kernel loop nest implementation bound stride loop kernel associate loop variable tensor dimension index purpose counter loop output stationary datalow scanner matrix loop bound stride dimension outermost loop index corresponds outer dimension innermost loop index corresponds inner dimension sparse loop nest skip col sparse loop nest skip col col col col col data storage data storage output coordinate sparse sequence output stationary iterate scanner perform intersection coordinate bracket irst argument matrix respectively  sparse sequence optimize sequencer traverse sparse loop nest output stationary dense loop nest iterate matrix matrix coordinate matrix empty sparse tensor   empty exploit skip iterate cycle skip iterate encounter empty feedback scanner sequencer inform sequencer node increase non empty  tensor representation tensor kernel loop nest tensor dimension iterate output stationary iterates matrix sequence intersection operation output stationary kernel logic convolution  expression straightforward discus simplicity micro october columbus usa  node non empty straightforward CSF representation compress dimension sequence coordinate correspond non empty sequentially memory dimension sequence tile discussion concern sequence within tile entire kernel sequencer outer loop sequence tile scanner implementation tile  metadata storage implement load tile tag coordinate identify tile sequencer information adjust internal counter enables sparse loop tile coordinate along intersection intersect intersection survive coordinate lookup output tensor data tensor intersection matrix matrix coordinate associate data data lookup transport data along coordinate metadata tile tile load  coordinator coordinate metadata metadata storage data memory data storage reduce inefectual data storage fetch data intersection perform implement scheme naively  lookup coordinate data storage eliminate expensive lookup generate pointer data storage coordinate intersection generate tensor  metadata data storage intersection operates tuples coordinate coordinate survive intersection lookup data memory tensor data correspond scalar  coordinate metadata data coordinator output  data tag data coordinate identify overall tensor suicient information important calculate partial output pre intersection optimization tensor data within tile  coordinator fetch unless intersection data deems  scheme intersection ill whereas scheme ill tensor data pre intersection intersection ill bandwidth coordinator input fetch data storage intersection data load data memory scheme mechanism hide latency fetch data later indirection intersect data contiguous data memory diicult implement arithmetic data per coordinate scalar latency critical implement scheme dram latency indirection amortize tile ill accelerator finally discus integrate coordinator extensor accelerator architecture evaluate tensor kernel hierarchically intersect intersection logic diferent accelerator memory hierarchy coordinator closer memory perform  intersection tile pas  closer arithmetic performs  intersection scalar  compute precisely intersection architecture data memory compute reduce inefectual data metadata transfer multiple granularity granularity inefectual detect macro architecture architecture evaluate dram channel bufer LLB input tensor partial output bufer pob partial output partial sum  noc processing PEs PE   arithmetic datapath register perform  scalar computation sequencer scanner coordinator instantiate memory hierarchy sequence intersect coordinate correspond diferent tile noc  unicast multicast broadcast data previous accelerator proposal extensor accelerator PE PE coordinator contains PE buffer datapath PE array dram sequencer scanner coordinator buffer LLB partial output buffer pob extensor accelerator sparse sparse sparse dense dense dense computation tensor kernel tensor optimize accelerator sparse sparse dense dense tensor operand computation evaluate sparse sparse tensor sparse perform intersection described previously evaluate sparse dense intersection degenerate coordinate sparse operand  coordinate access dense operand dense dense intersection disabled extensor accelerator sparse tensor algebra micro october columbus usa kernel SDDMM  perform analysis across tensor simultaneously intersect evaluate  allocate additional scanner PE metadata storage scanner idle datalow tile coordinator coniguration    sequencer described speciic datalow matrix evaluation  kernel matrix matrix LLB tile PE tile LLB tile MD LLB tile data PE tile MD PE tile data scalar datapath MD tile matrix representation datalow matrix multiplication MD metadata loop innermost loop outermost loop datalow input matrix broken LLB tile broken PE tile broken datapath tile datapath tile scalar PE output stationary dimension iterate matrix simultaneously PE tile matrix stationary across LLB tile switch PE tile LLB tile matrix stationary LLB tile within LLB tile data tile representation input tensor representation memory hierarchy assume CSF tile pre tensor  compress metadata tile fully tile representation matrix coordinate specify rectangular subtile LLB PE datapath tile broken  closer arithmetic outer metadata PE tile data PEs PE tile metadata tile tile chosen coordinate tile non zero another tile LLB tile LLB tile LLB tensor evaluate conservative strategy untenable PEs without incur   tile  uncommon split tile across PEs emulate  distribute SkipTo architecture longer  perform intersection baseline scheme stag data transfer intersection sequencer scanner coordinator memory hierarchy perform intersection stage hierarchy matrix terminology dram closest dram sequencer scanner without intersection logic data memory bootstrap kernel traverse LLB metadata sequence LLB tile LLB closest dram implement scanner metadata storage cache memory dram LLB coordinator LLB intersects PE tile metadata ill data intersection intersect coordinate corresponds PE tile intersection ill avoids reading inefectual PE tile data dram within LLB tile PE coordinator intersects datapath metadata ill datapath tile scalar pre intersection datalow datapath tile scalar PE tile matrix intersection scalar arithmetic sequencer traverse respective loop nest sparse avoid spending cycle iterate empty aside dram scanner scanner metadata storage implement  tile memory closer dram closer compute partial output management computation dot matrix perform PEs mechanism combine partial output partial sum generate computation storage partial output complicate unlike input tensor sparsity dynamically output completely empty becomes dense computation proceeds observation partial output  handle input sparse tensor compute PE tile likely generate sparse partial output output stationary matrix partial output generate intersection correspond PE tile non empty PE tile relative overall matrix computation PE generate partial output iteration tensor kernel reduce via associative operator sum reduction max min meaning partial output reduction reorder observation extensor manages partial output partial output content addressable memory alongside LLB partial output bufer pob load  output tile dram output tile coo format contiguous micro october columbus usa  tensor evaluation matrix  tensor  tensor domain dimension non zero density  economic bcsstk structural bcsstk structural bcsstk structural  protein data rma fluid dynamic cant fem cantilever  fem concentric sphere   tunnel  fem detail mac  fwd  model tensor chicago crime data security uber pickup transportation NIPS publication academia dram dram allocate output tile output tile  pob coo convert content addressable hash representation hash iterate sequentially unload dram partial output PEs pob along coordinate coordinate hash output locally accumulate hash contains entry coordinate output allocate accumulation background critical program model extensor accelerator  speciic tensor algebra kernel kernel coniguration  input tensor tile tensor representation kernel loop nest datalow connectivity  intersection math datapaths detail  omit involve  dma partition  FSMs  chip network route physical component accelerator turing compute algebra equation accepted taco tensor algebra compiler generate conigurations directly taco future evaluation evaluate inal extensor propose evaluation extensor variant optimize cpu code perform exploration extensor hardware  extensor scanner methodology tensor evaluate performance tensor  tensor data SuiteSparse matrix collection datasets span multiple domain coo output alongside coordinate   dynamic  model non zero density dimension tensor pre representation CSF evaluate layer prune alexnet density tensor kernel evaluate tensor kernel gemm  ttm SDDMM  ttm compute dimensional tensor SDDMM computes matrix tensor evaluation precision data simulation framework evaluate extensor model python evaluates performance tensor kernel input tensor performance model component core intersection  coordinator  model cycle  evaluates cycle intersect PE tile accelerator  LLB noc dram interface schedule  model analytically component evaluate data access schedule output handle chip datalow dram noc queue model data transfer exceed peak bandwidth queue model suicient model dram noc extensor data access movement  extensor access data tile granularity achieve spatial locality dram burst bufer granularity therefore achieve dram utilization data similarly datalow multicast unicast tile across PEs ixed regular allows model NoCs analytically peak bandwidth exceed baseline platform extensor intel xeon server cpu core thread ghz turbo ghz MB llc cpu dram channel theoretical maximum bandwidth GB kernel intel mkl library taco tensor compiler performance extensor performance relative cpu baseline tensor kernel variant extensor skip inal assume ghz comparison extensor LLB dram bandwidth cpu PEs KB  local bufer metadata data storage scanner scanner coarse grain cam entry extensor skip extensor skip without intersection optimization described version performs intersection intersect perform computation dense cpu increase extensor frequency  improve performance extensor accelerator sparse tensor algebra micro october columbus usa mac     cant rma  bcsstk bcsstk bcsstk  alexnet alexnet alexnet geomean cpu mkl extensor skip extensor skip extensor relative mkl SpMSpM  sec intensity  byte cpu roofline extensor roofline extensor mkl  analysis extensor cpu SpMSpM mac     cant rma  bcsstk bcsstk bcsstk  geomean cpu mkl extensor extensor relative mkl SpMM  matrix multiplication gemm gemm core kernel linear algebra remain widely kernel compute application graph processing evaluate variant gemm sparse sparse gemm SpMSpM  kernel sparse matrix sparse matrix SpMSpM application linear algebra graph processing sparse neural network evaluate SpMSpM matrix SuiteSparse collection graph algorithm  counting extensor variant mkl SpMSpM extensor skip faster cpu average outperforms cpu matrix extensor improves performance logic memory sequencer scanner hierarchical coordinator ahead computation ensure dram bus highly utilized intersection logic dram LLB PE datapath remove inefectual data tile metadata remove redundant bandwidth utilization extensor skip  extensor skip workload sparsity evident  uber chi crime  uber chi crime  cant   ttm SDDMM cpu taco extensor performance comparison extensor variant taco generalize tensor algebra extensor skip outperforms extensor skip workload alexnet density  analysis mkl memory latency bound SpMSpM extensor memory bandwidth bound interestingly speedup function matrix sparsity core strength extensor intersection intersection eliminates sparsity simply sparsity LLB PE tile granularity within PE scalar granularity performance improvement extensor skip relative extensor skip illustrates importance sparsity PE kernel sensitive intersection sparse dense gemm SpMM kernel sparse matrix dense matrix extensor evaluates SpMM matrix randomly generate dense matrix multiplication sparse matrix skinny dense matrix kernel application algebraic graph algorithm extensor variant mkl SpMM kernel extensor skip performance improves performance cpu average performance gap extensor cpu narrow SpMM SpMSpM kernel SpMM dram bandwidth bound extensor provision bandwidth recall intersection coordinate sparse dense tensor simply yield coordinate sparse tensor performance improvement dram utilization scanner memory perform analogous  analysis cpu extensor dram bandwidth bound SpMM memory bound SpMM cpu extensor improve cpu generalize tensor algebra evaluates tensor kernel  ttm along SDDMM kernel taco compiler tensor algebra  ttm contract dimensional sparse tensor dense vector matrix respectively SDDMM computes   hadamard sparse matrix dense rectangular matrix hadamard SDDMM opportunity intersection avoid computation dot average speedup  ttm SDDMM kernel respectively ttm ttm kernel extensor tile strategy improve data reuse taco micro october columbus usa  mac     cant rma  bcsstk bcsstk bcsstk  geomean cpu model model model model model extensor bottleneck variant kernel mainly due lack tile inability  avoid inefectual hierarchical intersection permit extensor avoid inefectual tile schedule LLB PEs pronounce extremely sparse tensor similarly SDDMM  ability skip entire dot tile sparsity matrix bottleneck analysis extensor variant realism insight future improve methodology  variant model idealize account MACC available extensor matrix  multiplication calculate runtime calculate multiplication available MACC model dram bandwidth constraint previous model  runtime calculate maximum model input matrix matrix dram bus model realistic LLB tile scheme previous model LLB tile model accurately chip behavior idealize PE tile distribute PEs idealize fashion minimize load imbalance oppose constrain speciic chip datalow intersection calculate   model realistic cam PE intersect previous model model realistic extensor model evaluate realistic PE tile distribution previous model model performance ceiling accelerator model likely implementable model implementable improve distribute PE tile perform intersection average performance gap model model model respectively synthetic data matrix analyze extensor  matrix diferent dimension sparsity sparsity isolate performance  synthetically generate matrix uniform sparsity distribution sparsity matrix dimension  ixed non zero runtime matrix dimension nnz nnz nnz nnz extensor SpMSpM performance across dimension constant non zero nnz per matrix nnz generate matrix diferent dimension evaluate runtime SpMSpM PE tile constant coordinate nnz performance regime dimension sparsity nnz matrix empty scalar empty PE tile empty within tile average increase dimension runtime increase non empty tile increase outweigh  scalar granularity skip  sparsity namely nnz per tile trend revers phase although non empty tile increase empty within PE tile sparse loop optimization activates reduces overall runtime sparsity empty PE tile runtime  increase sparsity non empty tile likely non zero bandwidth previous normalize extensor chip storage dram bandwidth exemplify  intersection technique architecture perform sensitivity parameter sweep dram bandwidth  impact increase dram bandwidth extensor SpMSpM chip previous sweep baseline bandwidth GB representative gpus extensor model bottleneck prevent performance dram bandwidth  increase dram bandwidth GB improves performance model extensor model  intersection PE tile distribution  matrix LLB performance matrix   kernel dominate factor latency average performance improvement bandwidth increase address bottleneck model prevent future fix dram bandwidth sweep impact LLB dominant source overall kernel runtime increase LLB takeaway matrix performance sensitive LLB LLB shrink MB extensor accelerator sparse tensor algebra micro october columbus usa mac     cant rma  bcsstk bcsstk bcsstk  geomean cpu baseline baseline baseline baseline extensor model SpMSpM cpu extensor dram bandwidth runtime LLB MBs mac    cant rma bcsstk bcsstk pareto frontier SpMSpM performance per optimal outline  intersection highly depends sparsity distribution matrix oppose absolute matrix matrix generate relatively dense output non zero distribution hardware implementation focus rtl implementation novel accelerator coordinator module ALUs noc  etc already implement coordinator verilog assume KB PE bufer content addressable memory entry coordinate suicient tile evaluation synthesize commercial timing ghz performance evaluation SRAM obtain CACTI compute intersection synthesis overall ind PE SRAM bufer precision arithmetic logic intersection extrapolate PE plus project LLB pob estimate chip parameter intersection logic across PEs consume away coordinator logic dominate accelerator budget related accelerator target tensor algebra machine  attention furthermore accelerator exploit sparsity reduce extensor tensor algebra machine accelerator tensor algebra accelerator ubiquity matrix operation data application spur research accelerate sparse matrix dense vector spmv SpMM kernel intersect coordinate sparse matrix dense data trivial skip inefectual computation multiplication entire dot empty efect compress format sparse matrix csr csc none extend tensor compound expression SDDMM focus extensor recent investigate accelerator sparse matrix sparse vector  multiplication SpMSpM perform inner matrix multiplication load entire sparse matrix processor processing sparse matrix basis proposal apply coordinate intersection fetch meta data memory data load extensor avoids memory traic hierarchically intersect tile  memory bufer hierarchy lazily load intersection alternately accelerator focus outer multiplication avoid coordinate intersection approach sparse matrix sparse matrix generate partial essence approach improves memory traic  multiplication introduces additional merge partial memory reduce inal extensor performs eicient inner multiplication achieves memory traic intersection skip tile reduce meta data memory traic machine accelerator recent cnn accelerator recognize prevalence inefectual computation focus skip multiplication incur memory access overhead operand chip extensor skip entire dot tensor tile zero extensor reduces avoid memory access associate inefectual computation conclusion tensor algebra ripe domain contribution computer architect extensor approach perform tensor algebra hierarchical compositional intersection multiple avenue future eicient conversion compress format online oppose  tile simd datapaths address performance artifact hinder bandwidth applicability algebra compress tensor become foundational building accelerator construction