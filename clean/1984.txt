importance sparse matrix dense vector multiplication spmv operation graph analytics numerous scientific application development custom accelerator intend overcome difficulty sparse data operation purpose architecture however efficient spmv operation exceeds chip storage severely constrain due dependence limited amount random access memory additionally unstructured matrix sparsity difficulty rely exploitation data locality algorithm optimize scalable hardware architecture efficiently billion node highly sparse avg graph significantly chip memory exist novel parallelization methodology implement throughput multi merge network enabler performance spmv accelerator additionally data compression scheme reduce offchip traffic computation node exceptionally commonly graph accelerator demonstrate fabricate ASIC  fpga platform experimental magnitude improvement custom hardware magnitude improvement commercial shelf COTS architecture performance efficiency keywords spmv custom hardware sparse matrix merge parallelization introduction spmv denote sparse matrix respectively source resultant dense vector spmv application graph analytics kernel becomes bottleneck render peak processor performance efficiency COTS architecture utilization chip memory bandwidth due frequent random access excessive chip traffic overhead additionally purpose architecture instruction sparse matrix operation responsible traverse graph relevant node load argument computation incurs overhead arithmetic operation schedule instruction core consumes custom architecture recently explore spmv acceleration refer graph data chip storage memory sub data multiple billion node graph memory custom architecture efficiently handle compute requirement met however performance efficiency spmv memory custom architecture aggravate billion node due dependence onchip memory static random access memory SRAM embed dram eDRAM etc dependence stem custom accelerator portion sparse micro october columbus usa  ASIC specification frequency ghz occupy leakage dynamic FinFET ASIC fabricate computation core propose accelerator meta data vertex chip random access memory severely limit capability chip memory programmable gate array fpga report maximum graph dimension node MB chip SRAM dimension efficiently handle application specific integrate circuit ASIC node despite MB eDRAM scratchpad hence alone billion node graph accelerate memory custom hardware another difficulty spmv operation matrix experienced data become sparse avg unstructured spmv acceleration technique somehow exploit locality nonzero sparse data sophisticated format precondition register widely literature cache computation paradigm however temporal spatial locality highly sparse matrix render ineffective algorithm optimize custom memory hardware accelerator depict performance efficient spmv operation highly sparse graph data exceeds chip storage computational core accelerator demonstrate ASIC fabricate technology intel  fpga demonstrate another platform propose custom architecture goal accelerator utilization memory bandwidth dependence chip memory reduction chip traffic data locality  computational scheme avoidance costly pre processing utilization dram bandwidth adopt algorithm namely conduct spmv phase ensure dram access incurs chip traffic algorithm matrix hence algorithm posse favorable data access characteristic efficiently utilize chip bandwidth furthermore algorithm spatial temporal data locality costly pre processing matrix however challenge implement algorithm primarily focus address challenge contribution efficient implementation spmv computationally parallel multi merge operation fully utilize bandwidth dram TB 3D stack bandwidth memory HBM  intermediate sparse vector width depends memory spmv algorithm proposes novel radix pre sorter scalable multi merge parallelization scheme throughput saturate extreme bandwidth 3D stack technology fully utilize chip bandwidth demonstrate matrix scheme buffering enable spmv implementation without significantly increase chip memory requirement enables propose accelerator handle graph billion node reasonably amount MB chip memory proposes meta data compression technique namely variable delta index VLDI significantly reduce chip traffic improve performance demonstrate optimization iterative spmv increase throughput  chip traffic develops bloom filter enhance spmv performance graph node disproportionately allows avoid complicate sparse format ensures efficient execution without chip storage organize overview spmv algorithm propose implementation detailed additional optimization reduce traffic improve performance demonstrate afterwards later chip memory comparison lastly experimental various benchmark conclusion spmv algorithm suggests spmv conduct depict assume disk access machine dam model memory hierarchy chip storage access chip memory access transfer spmv fundamentally depends matrix partition 1D multiway merge operation source vector matrix partition vertical stripe sparse format coordinate RM coo compress sparse csr partial spmv source vector correspond matrix stripe conduct icient spmv operation highly sparse matrix scalable multi merge parallelization micro october columbus usa payload latency bound spmv spmv matrix intermediate traffic source vector cache wastage chip traffic latency bound spmv conduct node graph average chip memory dram memory computation core intermediate sparse vector format sequentially traverse increase index generate sequentially dram partial spmv conduct intermediate sparse vector dram intermediate sparse vector vks memory computation core multi merge operation conduct accumulate resultant dense vector intermediate vector sort ascend nonzero index access sequentially multi merge operation resultant vector generate sequentially dram offs advantage insight spmv random access latency due cache dram sequential access compute algorithm intermediate vector dram vector dram additional dram sequential access related compute overhead propose algorithm fundamental eliminate latency random memory access access compute beneficial access necessarily translate dram traffic due elimination cache wastage byte fetch unused actually incurs chip traffic overall highly sparse moreover dram traffic algorithm transfer access bandwidth random access bandwidth performance efficiency algorithm report despite overhead dram access capture insight offchip traffic latency bound spmv depict algorithmically latency bound spmv memory access latency bound predominant stall algorithm due latency fetch memory cache dram random access overall chip traffic spmv despite incur payload data actual computation mention eliminates wastage cache transfer dram almost access importantly spmv sequential access dram potentially leveraged fully utilize offchip bandwidth completely amortize dram buffer opening spmv incurs chip algorithm additionally spmv matrix precondition independent nonzero locality detailed analysis spmv algorithm available challenge challenge algorithm implementation multi merge operation essentially compute bound accomplish COTS custom architecture due behavior saturate dram bandwidth multi merge implementation throughput scalable parallelization scheme absent literature custom architecture multi merge implementation report achieve maximum throughput 0GB whereas bandwidth 3D stack HBM 0GB furthermore sort merge multi merge network resource intensive grows exponentially increase importantly traditional parallelization increase throughput become unscalable chip memory requirement grows linearly multi merge core difficulty implementation multi merge operation discard algorithm despite efficient memory access behavior contribution development multi merge hardware parallelize saturate extreme bandwidth without incur significant increase chip memory requirement PROPOSED architecture propose architecture efficient spmv implementation depict memory multiple  3D stack memory extreme bandwidth TB multiple stack entire sits passive interposer channel memory computation core scratchpad random access storage algorithm eDRAM due density leakage SRAM furthermore eDRAM operation modest penalty random access bandwidth vector width completely dictate available chip scratchpad utilize extreme chip bandwidth efficient propose custom hardware core computation demonstrate ASIC chip fabricate FinFET specification computational core spmv ASIC accelerator core fpga platform demonstrate intel  computation core propose accelerator custom hardware core spmv explain subsection micro october columbus usa  chip scratchpad multiple FP multiplier FP adder chain FP multiplier FP adder chain FP multiplier FP adder chain output vector data implementation algorithm implementation computational hardware conduct partial spmv relatively comprises multiple float FP multiplier FP adder chain series vector dram chip scratchpad memory consists multiple afterwards matrix stripe dram computation FP multiplier adder chain parallelly data matrix stripe sparse scratchpad independent random access significant conflict introduce stall computation pipeline denote output multiplier index multiplier output val matrix stripe sparse format however important matrix sparsity matrix stripe become hyper sparse matrix  nnz nnz nonzeros dimension  matrix stripe csr become wasteful complexity pointer array  due repetition completely empty RM coo matrix complexity  efficient  detailed description implementation scheme alternative approach literature detail avoid methodology already available researcher implementation critical spmv implementation multi merge network multiple sort billion throughput saturate bandwidth implement binary multi merge network denote merge core MC depict generally multi merge binary register FIFOs pipeline however intermediate vector vks grows storage overhead FIFOs becomes impractical therefore custom SRAM pipeline stage consecutive SRAM logically fifo buffer pipeline stage fifo fifo fifo fifo fifo fifo fifo fifo fifo fifo fifo stage activate sorter fifo fifo fifo fifo stage stage stage SRAM memory binary pipelined MC output per cycle highlight activate cycle FIFOs packed memory implementation significantly improves scalability MC grows increase circuit detail MC available skip scope output bandwidth MC inadequate despite frequency technology node ASIC implementation MC saturates 8GB bandwidth whereas HBM memory subsystem 2GB hence approximately magnitude improvement multi merge throughput utilize dram bandwidth achieve parallel multi merge propose namely parallelization radix pre sorter PRaP parallel multi merge implementation spmv parallel multi merge parallelization partition parallelization 2D matrix depict eventually generate intermediate vector intermediate vector horizontally partition input MCs assume partition hence MCs deployed independently merge partition ultimately resultant vector MC throughput per cycle instead achieve parallelization entire input chip memory however chip storage becomes unscalable due explain multi merge operation access sequentially however cycle dequeues selection practically random reside chip memory random access utilization chip bandwidth practical ensure utilization chip bandwidth prefetch dram buffer data whenever access chip chip memory namely prefetch buffer guaranteed icient spmv operation highly sparse matrix scalable multi merge parallelization micro october columbus usa multi merge parallelization partition input spmv becomes unscalable chip memory later reuse input prefetch buffer KB data prefetched overall MB chip memory partition MC partition MB chip memory prefetch buffer significantly amount allocate prefetch buffer chip memory dedicate chip memory requirement grows linearly increase partition hence partition input parallel multi merge operation scalable strictly depends limited chip memory parallelization radix pre sorter PRaP discussion apparent parallelization scheme increase prefetch buffer parallel MCs propose PRaP depict implement independent MCs radix within purpose dram radix pre sorter destination MC define significant lsbs radix pre sort hence MCs multi merge network output width per cycle achieve benefit PRaP irrespective chip prefetch buffer MB previously parallel MCs fed data prefetch buffer incremented without chip storage PRaP significantly scalable effective handle important PRaP parallelization guaranteed sort output dense vector output vector spmv elaborate later radix pre sorter implementation without loss generality assume dram interface width hence whenever dram cycle prefetched data pipelined radix pre sorter pre  implement  sort network output per cycle merge core radix lsbs pre sorter incoming dram output merge core parallelization radix pre sorter PRaP radix PRaP pre sort lsbs radix selection pre sort PRaP  pre sorter sort lsbs dram MC MC MC MC parallel MCs prefetch buffer  dram  storage slot radix slot radix slot radix slot radix slot radix radix pre sorter implementation  sorter prefetch buffer explanation assume radix input rate depict  network simplistic manner horizontal data downward upward arrow comparison swap operation ascend descend respectively important comparison operation pre sorter hence logic resource requirement PRaP pre sorter significantly comparison pre sort mandatory maintain sequence posse radix radix precede imperative MC input sort radix within pre sort output prefetch buffer allocate location prefetch buffer allocates  storage internally within buffer radix sort slot appropriate MC radix  buffer consumption MC load balance synchronization incoming imbalanced micro october columbus usa  prefetch buffer  dram  storage MC MC MC MC slot radix slot radix slot radix slot radix parallel merge core dequeued cycle dequeued cycle dequeued cycle output output queue val val queue dram load balance synchronization insertion PRaP output dense radix data unevenly distribute MCs potential load imbalance importantly independent MCs radix sort synchronization output core generate sort output issue effectively resolve observation output dense vector hence guaranteed MC sequentially deliver monotonously increase assume sort ascend additionally mandatory index sparse intermediate vector spmv resultant dense vector assume input data radix MC sequentially delivers hence output MC handle scenario logic MC whenever detect output artificially inject output along delayed artificial inject delayed insertion necessitate dense output vector solves load imbalance synchronization firstly data unevenly distribute core output MC rate hence load imbalance practically hidden occurs secondly output core   independently queue queue synchronously dequeued dram   consecutive dense output vector furthermore dequeued cycle consecutive dense vector sort logic synchronize output independent multi merge core therefore propose parallelization PRaP multiple core without increase chip buffer requirement achieve throughput memory bandwidth later radix pre sort core fabricate delta index distance VLDI VLDI VLDI VLDI construction VLDI delta index ASIC saturate extreme HBM bandwidth GBs additional  meta data compression spmv intermediate vector sparse format dram incurs chip traffic overhead reduce overhead distance consecutive instead absolute index intermediate vector however distance within propose scheme namely variable delta index VLDI practically enables allocation variable width meta data explain delta index nonzero express distance previous nonzero delta index multiple VLDI predefined width VLDI comprise significant pad extra zero encompass entire afterwards append extra construct VLDI extra propagation delta index indicates continuation confirms termination delta index VLDI feasible sequential generation access guaranteed intermediate vector spmv index matrix stripe sequential dram access apply VLDI compress matrix VLDI optimum VLDI besides sparsity matrix directly correlate nonzeros matrix stripe sparse vector indirectly depends chip memory chip memory matrix stripe becomes narrow due render distance nonzeros average hence fix VLDI efficient reduces overhead however VLDI wastage therefore VLDI important platform chip memory sparsity achieve efficient compression probability distribution delta index width chip memory MB MB chip traffic chip storage VLDI compute minimum traffic occurs VLDI VLDI MB MB chip memory accordingly hence hardware parameter memory resource characteristic tune icient spmv operation highly sparse matrix scalable multi merge parallelization micro october columbus usa optimum VLDI optimum VLDI narrow matrix stripe chip memory MB matrix stripe chip memory MB probability delta index delta index optimum VLDI optimum VLDI probability distribution delta index width chip memory randomly generate erdos rényi graph avg quadruple quarter compression VLDI vector VLDI matrix vector chip traffic GB data precision chip traffic reduction VLDI advantage elaborate VLDI meta data compression benefit chip traffic random sparse matrix MB chip memory separately compression capability intermediate sparse vector compress matrix stripe compress data precision nonzeros comparison meta data compress VLDI compression ratio increase data precision decrease graph sparse matrix unweighted binary matrix meta data nonzero VLDI maximum compression benefit iteration overlap optimization application pagerank spmv kernel iteratively resultant vector iteration serf source vector iteration overlap computation spmv consecutive iteration depict decrease chip traffic significantly improve computation throughput optimization iteration overlap parallelly conduct iteration along instead iteration completely independently chip traffic due dram transition iteration effectively eliminate enabler optimization iteration overlap resultant vector iteration generate sequentially algorithm despite iteration overlap iteration source vector storage memory computation iteration output iteration chip traffic optimize iteration overlap spmv entirety chip source vector completely generate chip memory initiate computation iteration iteration conduct source vector iteration concurrently resultant vector another chip buffer computation iteration iteration overlap besides reduce chip traffic subtle important advantage computation resource active significantly improves overall spmv throughput saturate bandwidth buffer source vector chip memory instead hence amount onchip memory maximum matrix dimension handle roughly therefore maximum dimension performance efficiency optimization graph graph commonly social network posse node distribution varies inverse relationship hence node denote node  disproportionately  incur numerous collision accumulation spmv efficient pipeline specially tune accumulator  however detection HDN efficiently computation challenge HDN detection standard format RM coo csr flag HDN however widely standard matrix format specific task prior HDN information chip access resolve propose bloom filter detection scheme bloom filter compact data structure enables membership data bloom filter array encodes membership information hash function member hash random location bloom filter array correspond assert membership similarly hash deem member micro october columbus usa  hash func hash func hash func index HDN membership array membership information  bloom filter membership multiple hash function matrix intermediate vector vector stripe scratchpad SRAM eDRAM bram fabric fabric ASIC fpga fabric memory HDN detection bloom filter HDN pipeline pipeline pipeline HDN computation bloom filter filter efficiently  without significant chip memory overhead bloom filter graph  metadata dram threshold node array bloom filter membership information  index node hash later computation node checked HDN computation pipeline partial spmv diagram scheme bloom filter false positive false negative treat regular node HDN considerable inefficiency regular node significant stall HDN pipeline bloom filter implementation important factor bloom filter implementation false positive ratio processing complexity overhead bloom filter array maximum member HDN respectively ratio load factor denote hash function parameter probability treat non member member encode membership hash function  hash random location entire array SRAM access memory implement memory access propose hash function  hash width SRAM respectively graph twitter  graph collection graph node billion average maximum graph HDN node HDN node however conservative bloom filter encode  node analysis false positive ratio load factor hence calculate bloom filter mbit KB insignificant chip overhead additionally SRAM width hash implementation xor hardware hash function generate hash overall processing overhead detection  false positive ratio reasonable significant resource chip memory requirement chip memory requirement report custom hardware COTS literature memory propose ASIC without optimization iteration overlap denote TS accordingly developed ASIC MB eDRAM scratchpad memory vector storage MB prefetch buffer MB along MB SRAM computation core MB storage mention maximum TS nevertheless propose relatively chip memory handle graph significantly dimension despite MB eDRAM scratchpad ASIC handle node without slice partition graph whereas propose handle multiple billion node significantly chip storage chip memory requirement graph dimension comparison propose chip max vertex memory MB fpga ASIC cpu socket cpu dual socket propose ASIC TS propose ASIC expand chip memory exist technology propose easily significantly icient spmv operation highly sparse matrix scalable multi merge parallelization micro october columbus usa source vector buffer expand MB MB handle graph twice dimension graph vertex TS accordingly ability imperative fpga implementation handle graph fpga limited amount onchip ram bram efficiency fpga implementation largely depends utilization bram fpga literature report handle graph node graph relevant chip memory spmv implementation dictate requirement memory storage developed accelerator experimental RESULTS propose spmv accelerator implement multiple FinFET ASIC  fpga platform implementation various maximum dimension maximum computation throughout implementation prefix namely TS VC implementation iteration overlap iteration overlap VLDI vector compression respectively maximum graph dimension throughput implementation variation propose spmv accelerator platform implementation maximum sustain computation ID node throughput GB TS ASIC ASIC ASIC VC ASIC TS fpga fpga fpga TS fpga fpga fpga ASIC implementation ASIC computation logic entire accelerator fabricate implement sixteen MCs ASIC ASIC accelerator HBM memory eDRAM scratchpad emulate cactus destiny TS ASIC source vector memory maximum matrix dimension handle billion ASIC VC ASIC handle billion variation iteration overlap optimization however ASIC VC ASIC relatively computational throughput TS ASIC VC ASIC relatively sustain throughput ASIC dram bandwidth saturation VLDI decrease traffic throughput implementation fpga implementation demonstrate portability custom hardware propose accelerator implement intel  fpga  namely fpga fpga fpga handle relatively fpga computational throughput fpga utilizes available hardware resource implement MCs input fpga MCs enables fpga handle however fpga parallel MCs fpga fpga implement MCs parallel core MCs fpga deliver throughput fpga fpga fpga scratchpad memory synthesize bram HBM memory simulated ASIC assume channel performance efficiency comparison exist performance efficiency developed accelerator exit custom hardware gpu cpu processor description custom hardware gpu benchmark along reference description assign ID benchmark comparison cpu manycore processor intel math kernel library mkl routine mkl  dual socket xeon thread cpu xeon phi core processor architecture MB cache llc peak bandwidth 2GB cpu 2GB coprocessor custom hardware gpu benchmark architecture ID description BM ASIC ASIC MB eDRAM scratchpad custom BM fpga virtex bram  hardware BM fpga virtex bram gpu BM gpu node tesla 6GB GDDR data comparison graph data comparison custom hardware gpu accordingly relatively graph report related noteworthy report graph custom hardware gpu node whereas graph data comparison cpu processor graph  sparse matrix collection random erdos rényi graph demonstration purpose propose accelerator capability handle synthetically generate graph prefix performance custom performance comparison giga traverse per GTEPS ASIC implementation custom benchmark comparison benchmark micro october columbus usa  graph comparison custom benchmark ID description node avg FR flickr FB facebook wiki wikipedia RMAT  LJ livejournal WK wikipedia TW twitter web ND web  web web google web web  web wiki graph comparison gpu benchmark ID description node avg ara arabic graph comparison cpu processor node avg patent   italy osm edu germany osm asia osm central   europe osm ASIC implementation achieve magnitude improvement fpga benchmark faster ASIC benchmark despite significantly chip memory iteration overlap optimization technique ASIC VC ASIC speedup TS ASIC VC ASIC achieves performance sustain computation throughput bandwidth 2GB VLDI compression reduces chip traffic graph report benchmark propose accelerator handle detailed sec apart 3D dram bandwidth ASIC technology achieve contribute mainly factor firstly propose architecture incur cache wastage due adoption algorithm secondly memory bandwidth saturation peak sustain bandwidth propose architecture due dram access improvement bandwidth utilization significantly surpasses overhead algorithm memory intermediate vector propose fpga implementation achieve performance ASIC implementation however overall speedup custom benchmark significant efficiency comparison related report comparable metric FR FB wiki RMAT LJ WK TW web ND web web web ASIC fpga benchmark TS ASIC ASIC VC ASIC BM ASIC BM fpga BM fpga improvement GTEPS comparison GTEPS propose ASIC custom hardware benchmark FR FB wiki RMAT LJ WK TW web ND web web web ASIC fpga benchmark TS fpga fpga TS fpga fpga BM ASIC BM fpga BM fpga GTEPS improvement comparison GTEPS propose fpga implementation custom hardware benchmark performance  gpu performance efficiency comparison propose ASIC gpu benchmark VC ASIC achieve magnitude improvement GTEPS efficiency improvement per traversal magnitude almost graph gpus commonly consume due parallel core arithmetic depicts comparison fpga implementation plot significant improvement performance efficiency gpu comparison cpu processor demonstrates speedup consumption propose ASIC intel mkl cpu xeon phi processor report architecture successfully graph icient spmv operation highly sparse matrix scalable multi merge parallelization micro october columbus usa ara wiki wiki wiki wiki edu gpu benchmark TS ASIC ASIC VC ASIC spmv performance efficiency GTEPS improvement ara wiki per traversal improvement comparison GTEPS traversal propose ASIC accelerator gpu benchmark ara wiki wiki wiki wiki edu gpu benchmark TS fpga fpga TS fpga fpga ara wiki GTEPS improvement per traversal improvement comparison GTEPS traversal propose fpga accelerator gpu benchmark node xeon xeon phi respectively plot performance propose billion node graph propose ASIC achieves improvement GTEPS consumption respectively depicts comparison propose fpga implementation due multi merge network ASIC handle graph fpga implementation mention propose accelerator fpga platform achieves significant multiple magnitude improvement performance efficiency graph conclusion highly sparse matrix unique challenge spmv scalability performance efficiency proposes custom architecture implementation spmv algorithm convert random access regular access ensures memory contribution develop scalable parallelization multi merge operation handle highly sparse graph without significantly chip memory knowledge approach spmv merge sort sparse accumulation fundamental operation spmv performance efficiency cpu xeon thread xeon phi TS ASIC ASIC VC ASIC improvement GTEPS per traversal improvement increase matrix dimension comparison GTEPS traversal ASIC accelerator cpu processor improvement GTEPS xeon thread xeon phi TS fpga fpga TS fpga fpga per traversal improvement increase matrix dimension comparison GTEPS traversal fpga accelerator cpu processor application architecture explore utilized beyond spmv