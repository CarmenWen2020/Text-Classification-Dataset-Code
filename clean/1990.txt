sprint mechanism significant performance boost temporarily exceed thermal propose DynaSprint software runtime manages sprint dynamically predict utility model thermal headroom moreover propose sprint mechanism cache increase capacity briefly enhance performance extends cache capacity MB MB per core absorb DynaSprint cache sprint improve performance average non sprint performance outcome within oracular policy DynaSprint accurately predicts phase behavior sprint utility CCS CONCEPTS computer organization architecture hardware keywords performance optimization thermal management cache introduction computational sprint mechanism silicon describes peak resource sprint significant performance boost activate reserve core increase frequency voltage sprint extra temporarily increase chip beyond thermal TDP sprint permission digital personal classroom grant without fee distribute profit commercial advantage citation copyright component others acm honor abstract credit permit otherwise republish server redistribute prior specific permission fee request permission permission acm org micro october columbus usa association compute machinery acm  http doi org thermal package deploy phase increase thermal capacitance buffer sprint dissipate normal operation sprint cannot sustain mechanism sprint mechanism ass benefit performance gain thermal headroom consume prior rely obvious trigger parallel code activates additional core offline profile estimate utility however approach limited sprint cannot adapt workload dynamic propose DynaSprint utility thermal aware determines initiate terminate sprint hardware available processor software framework evaluates utility sprint decision framework integrates approach online phase classification prior approach phase prediction management epoch framework predicts workload utility sprint ass thermal profile prediction accurate permit judicious sprint demonstrate DynaSprint sprint increase microarchitectural capacity specifically propose cache sprint expand cache capacity exceed TDP capacity useful cache microarchitectural sprint apply resource reorder buffer issue queue etc prior llc minimizes interference maximizes throughput improves fairness however sprint challenge sprint decision affect future pace sprint maximize performance thermal constraint cache sprint demonstrates viability utility extra cache capacity varies across program execution phase behavior permit judicious sprint increase capacity utility utility furthermore model cache sprint duration capture lengthy utility phase longer duration increase cache capacity intensive activate core voltage frequency implement DynaSprint software evaluate  application prototype intel xeon broadwell cache allocation via intel cache allocation technology DynaSprint cache sprint improve performance average micro october columbus usa  huang    rico andrew hilton benjamin lee moreover DynaSprint outperforms greedy policy sprint opportunity performs within oracular policy perfect knowledge sprint utility thermal  computational sprint temporarily exceeds chip sustainable thermal budget boost performance activates additional core boost frequency exceed processor thermal TDP magnitude sprint additional core activate parallel benefit frequency boost relatively easy estimate however manage sprint microarchitectural resource maximize performance challenge framework DynaSprint manage microarchitectural sprint identify sprint opportunity accurately minimize hardware management overhead application application varied microarchitectural sprint mechanism DynaSprint beyond trigger propose processor core allocation instead integrates approach online phase classification prior phase prediction sprint application phase characteristic accuracy DynaSprint sprint really sprint without justified benefit waste potentially hinder future sprint DynaSprint multiple predictor ensure sprint decision confidence overhead sprint usually apply thermal constrain management framework incur overhead DynaSprint software runtime utilizes hardware already available processor moreover DynaSprint coarse grain epoch span instruction management overhead negligible motivates goal snapshot program execution split phase DynaSprint task confirm previous epoch actually phase predict epoch phase predict utility sprint phase thermal headroom epoch permit sprint phase DynaSprint task accurately efficiently program execution phase management architecture overview DynaSprint DynaSprint manages sprint data previous epoch epoch phase classifier ass hardware performance counter phase signature epoch corresponds previously phase DynaSprint series prediction epoch sprint phase predictor recently epoch phase query phase predict epoch phase utility predictor epoch phase historical performance measurement predict sprint thermal tracker previous epoch consumption thermal headroom remains finally sprint coordinator aggregate prediction sprint epoch phase classifier DynaSprint classifies epoch phase facilitate prediction utility sprint epoch associate phase exhibit characteristic instruction parallelism memory intensity prediction accuracy etc DynaSprint capture characteristic hardware performance counter available processor DynaSprint phase signature define data counter classify epoch correspond phase phase signature DynaSprint construct phase signature performance counter cache per instruction mispredictions per instruction abbreviate BR MPKI hardware counter advantage counter indicator program phase cache utility activity datapath cache distinguish program phase moreover counter independent cache capacity phase signature instruction normal cache sprint mode finally counter available processor DynaSprint compatible portable phase signature boundary DynaSprint phase correspond signature program execution epoch DynaSprint determines signature previously phase differs prior signature phase DynaSprint determination specify boundary around phase correspond signature signature within exist phase boundary epoch associate phase beyond exist boundary epoch associate phase epoch phase signature counter dimensional counter respective coordinate 2D phase signature consists counter MPKI BR MPKI phase classifier already identify phase rectangle solid dot within rectangle program epoch classify correspond phase suppose coordinate epoch within rectangle phase classify phase phase boundary update DynaSprint microarchitectural sprint dynamic utility thermal management micro october columbus usa DynaSprint overview phase classifier phase signature ipc counter epoch monitor thermal tracker counter phase classifier identifies phase epoch phase predictor predicts phase utility predictor predicts sprint utility epoch thermal tracker calculates thermal headroom sprint coordinator sprint utility threshold sprint coordinator decides sprint epoch however suppose coordinate epoch within exist rectangle phase phase classifier algorithm detail analysis phase signature boundary epoch DynaSprint signature epoch  algorithm determines signature neighborhood signature previous phase  phase signature PS within boundary PS counter signature relative difference PS PS boundary parameter brd absolute difference PS PS parameter ass absolute relative difference comparison relative difference DynaSprint associate epoch signature phase euclidean distance boundary parameter brd phase granularity ultimately determines phase program boundary phase phase mitigate classifier overhead linear phase algorithm boundary phase classification procedure classify    closest int max psi  PS psi  psi brd psi  dist   psi dist closest closest dist  psi        phase increase analysis granularity permit accurate prediction utility finer granularity variance improve prediction utility phase boundary parameter brd parameter phase predict utility accurately phase predictor DynaSprint implement phase prediction global phase  predictor classifier assigns epoch phase classify phase index update finally predict epoch phase detail global phase  structure consists global shift register global phase register  phase  content index PHT cache previously phase PHT tag correspond prediction micro october columbus usa  huang    rico andrew hilton benjamin lee phase PHT pred recency information invalid  PHT tag predictor prediction predict phase  phase predictor effective statistical predictor particularly highly variable program phase prediction strategy exploit program consist phase characteristic behavior accurately predict phase program benefit various online optimization hardware reconfiguration voltage frequency DVFS thermal management  optimization phase behavior repetitive prior propose predictor capture phase future prediction utility predictor DynaSprint historical data phase classifier predict utility sprint epoch classifier phase instruction throughput processor normal sprint mode  IPCs update predictor epoch classify assign phase performance profile update classifier data correspond phase mode classifier encounter epoch phase performance profile normal sprint mode later classifier encounter epoch phase sprint coordinator data mode initiate halt sprint mechanism ensures classifier data normal sprint mode phase thereby explore utility sprint classifier initialize phase entry epoch performance update automatically sprint coordinator decision invoke predictor phase predictor forecast epoch phase phase ID ID index phase classifier correspond historical data instruction throughput processor predict utility sprint epoch thermal tracker thermal tracker monitor dissipation thermal headroom constrain sprint decision tracker measurement model DynaSprint measurement thermal model calculates headroom quantifies joule expend exceed processor package thermal capacitance package phase thermal model parameter  phase thermal capacitance determines buffer  phase thermal resistance determines maximum dissipate sprint  processor package thermal resistance determines quickly transfer phase ambient sprint  thermal resistance determines processor maximum sustain denote nominal sprint thermal denote thermal headroom suppose sprint without exhaust thermal headroom operates normal mode estimate thermal headroom sprint coordinator sprint coordinator initiate terminates sprint decision sprint balance utility future encapsulate significant utility epoch  potential utility future sprint reduces thermal headroom sprint exploit  epoch future permit thermal headroom judiciously enhance performance coordinator pursues objective utility prediction thermal model epoch coordinator aggressive sprint utility deplete thermal headroom helpful future coordinator conservative sprint utility lose opportunity translate thermal headroom performance thermal proportional threshold TP propose policy TP determines coordinator initiate sprint epoch equation TP threshold initiate sprint  thermal headroom already consume maximum utility umax derive recent sprint epoch coordinator initiate sprint predict utility exceeds threshold posse sufficient thermal headroom  umax   coordinator treat thermal headroom resource varies amount available treat utility return spending resource amount thermal headroom decrease becomes valuable coordinator return consume cache  architecture highlight advantage DynaSprint cache sprint instance technique microarchitectural capacity sprint cache sprint briefly expands processor cache llc capacity beyond dictate thermal normal operation llc unused sprint remain sprint llc dissipates dynamic DynaSprint microarchitectural sprint dynamic utility thermal management micro october columbus usa performance comparison frequency increase llc capacity baseline 1GHz MB llc performance gain gcc MB llc baseline MB access twice tag cache data response llc dissipates static cache sprint cache sprint complement prior mechanism computational sprint activate additional core boost frequency sprint cache serf memory bound application benefit boost processor core performance impact performance gain alternative sprint mechanism consume extra frequency increase llc capacity intel xeon broadwell processor frequency 1GHz 3GHz improves performance compute intensive application average memory intensive application contrast increase cache capacity MB MB improves performance memory intensive application significantly although potential benefit llc sprint significant management mechanism exploit potential utility intelligent sprint utility cache capacity varies across phase permit sprint utility utility variance exists workload gcc axis epoch instruction axis speedup MB llc MB llc epoch utility varies excellent sustain excellent sprint density llc density processor core prior sprint cache sprint exhibit delta due cache density difference max average delta permit longer aggressive sprint thermal constraint although cache sprint generate extra primarily due static llc unlikely become hotspot datapath structure register file ALUs exhibit cache sprint constrain processor global profile local framework generalizes beyond llc sprint memory microarchitectures technology  MB llc benefit sprint framework exploit capacity manage limited capability architecture DynaSprint software runtime cache sprint software decides sprint communicates decision hardware via register although hardware permit decision finer granularity software permit sophisticated management policy operating information behavior perform complex computation coarse granularity inform sprint decision reflect program behavior sprint additional cache empty sprint timely useful data micro october columbus usa  huang    rico andrew hilton benjamin lee rate increase performance improves sprint progress consumes chip thermal headroom processor safety tolerance transform phase  sprint software utility extra cache capacity hardware thermal headroom exhaust sprint sufficient thermal headroom dirty data memory extreme additional dirty address distribute poorly across memory MB dirty data microsecond negligible transition delay sprint span although software decision utility cannot trust chip physical safety hardware monitor thermal headroom halt sprint override operating headroom exhaust specifically hardware machine register msr sprint zero ignore writes register thermal headroom restore cache sprint without  thermal budget thermal emergency hardware halt processor core cache experimental methodology setup emulate llc sprint shelf chip multiprocessor restrict llc capacity nominal mode restore capacity sprint mode focus sprint evaluation serial workload core llc capacity accordingly summarizes configuration conduct physical hardware core intel broadwell xeon processor xeon processor MB cache corresponds MB per core normal mode configure intel cache allocation technology restrict core thread program MB MB allocates cache capacity MB granularity sprint mode permit core MB cache configure minimize interference ensure deterministic disable DVFS fix core frequency 1GHz disable watchdog hang timer address layout randomization non essential daemon service fourth  command cpu shield core target finally application average report performance relevant hardware counter phase signature performance application program interface  instruction  overflow function application evaluate  splash  benchmark suite focus llc sensitive application exhibit performance gain cache capacity processor frequency application  splash completion input usually application specification core core broadwell 1GHz cache KB private split cache KB private cache MB partition intel memory 8GB  ddr MT OS enterprise linux linux kernel version  multiple input instruction execute model estimate consumption intel average limit RAPL driver static estimate microbenchmark function dynamic execution minus estimate static available RAPL domain package core llc memory controller breakdown prior estimate individual core llc summary estimate nominal sprint core MB llc respectively llc consumes per MB thermal model thermal model prior sprint pcm increase thermal capacitance spreader thermal resistance processor uniform distribution sink amount pcm absorbs melt completely enable sprint span pcm parameter affect thermal model emulate  intelligent sprint baseline TDP core MB llc evaluate sensitivity parameter evaluation evaluate DynaSprint thermal proportional threshold policy alternative prior manage llc sprint policy knowledge sprint utility thermal headroom greedy initiate sprint whenever thermal headroom available ignore utility thermal headroom exhaust pcm transition  completes restore thermal headroom sprint local oracle LO perfect knowledge sprint utility prior epoch  epoch  initiate sprint  average  otherwise LO oracular policy heuristic incorporate local information obtain online profile prediction sprint threshold utility alone DynaSprint microarchitectural sprint dynamic utility thermal management micro october columbus usa DynaSprint performance various policy global oracle perfect knowledge sprint utility future epoch program execution sort epoch sprint utility iteratively selects epoch utility sprint execution epoch cannot sprint due lack thermal headroom epoch marked normal execution proceeds epoch global information obtain offline profile cannot implement online however policy upper bound performance cache sprint thermal proportional threshold TP predicts sprint utility epoch  maximum utility sprint recent umax sprint utility threshold  percentage already consume thermal headroom umax equation finally initiate sprint  exceeds  performance performance gain llc sprint baseline operates nominal dot upper bound performance unlimited thermal headroom continuous MB sprint DynaSprint llc sprint improve performance average alternative DynaSprint TP policy outperforms greedy heuristic competitive oracular policy comparison greedy TP significantly outperforms benchmark sprint judicious timely probability density sprint utility application gcc ocean bfs benchmark suite sprint utility distribution bimodal reveal epoch benefit greatly sprint variance sprint utility TP opportunity limited thermal budget wisely maximize performance gain instance ocean frequently achieves performance gain achieves performance gain TP likely reserve sprint gain greedy waste thermal budget utility epoch insufficient headroom utility greedy performs comparably TP benchmark probability density sprint utility application exhibit variance sprint pdf utility bimodal unimodal utility epoch benefit similarly sprint soplex epoch report utility opportunity prioritize sprint utility epoch TP threshold average sprint utility epoch thermal headroom available TP behaves similarly greedy comparison local oracle LO TP performance LO indeed TP performs LO benchmark although LO perfect knowledge local utility sprint threshold neglect thermal LO sprint conservatively thermal headroom abundant aggressively thermal headroom scarce TP aware thermal constraint pace sprint accord available headroom LO outperforms TP bfs due bimodal utility distribution LO sprint threshold average micro october columbus usa  huang    rico andrew hilton benjamin lee DynaSprint 1GHz MB configuration relative MB baseline DynaSprint sprint behavior ocean ncp gcc local utility utility epoch exhibit utility threshold application tend recur phase local information capture global behavior comparison global oracle average TP performs within performance upper bound perfect knowledge sprint utility epoch perfect knowledge thermal oracular knowledge persists epoch normal sprint computation performance gap TP indicates DynaSprint accurately predicts sprint utility TP threshold effective pace sprint maximize performance gain DynaSprint consumption baseline configuration MB llc overhead configuration constantly MB llc plot reference average DynaSprint increase application bfs DynaSprint reduces due significant reduction execution although goal sprint improve efficiency maximize performance thermal constraint sprint improve efficiency sprint dynamic dynamic execution ocean ncp orange plot offline profile sprint utility plot online measurement sprint utility achieve DynaSprint microarchitectural sprint dynamic utility thermal management micro october columbus usa impact phase signature definition phase classification accuracy impact signature boundary phase classification accuracy phase DynaSprint TP policy orange align available thermal headroom DynaSprint threshold sprint illustrates behavior DynaSprint accurately identifies utility epoch executes sprint epoch benefit sprint orange overlap DynaSprint dynamically adjusts sprint threshold accord recently performance data available thermal headroom accord TP policy ocean ncp representative application  phase bimodal utility distribution DynaSprint manage sprint effectively application phase classifier predict capture phase behavior effectively moreover TP policy easily identify utility epoch trigger timely sprint dynamic application gcc ocean ncp gcc phase phase repetitive gcc representative application stage execution application harder manage predictable however DynaSprint performs sprint utility epoch dynamically adapt threshold phase thermal budget gap TP mainly phase utility mispredictions prediction accuracy phase classification DynaSprint assigns epoch phase predict utility critical effectiveness TP policy accuracy assign epoch phase tracked classifier closely phase performance predicts epoch performance error percentage difference phase instruction throughput epoch actual throughput affect accuracy micro october columbus usa  huang    rico andrew hilton benjamin lee utility prediction accuracy definition phase signature boundary define neighborhood around phase signature classification error varied hardware counter phase signature counter signature improves accuracy counter perform poorly bzip counter significantly improves accuracy moreover diverse activity improves accuracy signature define counter combine MPKI BR MPKI performs combine MPKI MPKI characterize memory intensity BR MPKI characterizes datapath activity DynaSprint counter define phase signature achieve accuracy across application classification error varied boundary brd around phase signature boundary capture  phase improve accuracy however finer grain phase increase phase classifier increase overhead DynaSprint brd limit phase accurately classify performance within actual although narrow boundary brd improves accuracy slightly significantly increase phase application broadening boundary brd noticeably reduces accuracy without reduce phase utility prediction ass phase classifier accuracy translates utility predictor accuracy error percentage difference predict actual speedup cache sprint speedup predict instruction throughput report classifier overall DynaSprint accurately predicts utility sprint speedup within actual utility prediction accuracy exhibit variance across application phase classification accuracy application achieve accuracy relatively stable phase sprint utility omnetpp fft application harder predict variance phase bzip sprint utility xalancbmk  benchmark report error phase classification utility prediction epoch phase signature performance profile sensitivity analysis thermal TDP evaluate operates nominally sprint constrain thermal duration restores thermal headroom sprint duration spent generate TDP spent dissipate TDP sprint ratio performance tighter thermal constraint TDP closer nominal gap nominal thermal narrow sprint parameter duration longer sprint duration sprint ratio sprint become expensive degrade sprint performance across policy costly sprint reduce tolerance decision TP advantage grows tighter thermal constraint fft bfs mst TP identifies utility epoch sprint judiciously whereas luckily sprint utility epoch thermal headroom generous suffers decision headroom becomes scarce sprint become expensive prediction accuracy becomes important TP cannot compete wth oracular policy TP underperforms LO benefit perfect knowledge sprint utility bzip gcc thermal headroom tth evaluate pcm thermal headroom performance headroom halve performance unaffected application headroom determines duration sprint permit sprint application prefer sprint exceed duration headroom impact performance TDP maximum sustainable sprint ratio application derives varied utility sprint across TP exploit utility epoch judiciously exploit thermal headroom dynamically threshold sprint sprint intensity SI evaluate sprint llc capacity MB MB performance sprint triple capacity MB intense sprint necessarily translate performance application benefit sprint intensity increase MB sprint increase maximum sustainable  ratio spent sprint sprint expands cache capacity MB MB unless performance MB MB intense sprint justify extra cache capacity suffers diminish marginal return application benefit significantly MB MB bimodal operation sprint normal architect understand application performance sensitivity resource allocation ideally sprint normal mode configure maximize marginal performance gain marginal resource allocation application sensitivity multiple sprint intensity DynaSprint easily DynaSprint microarchitectural sprint dynamic utility thermal management micro october columbus usa performance sensitivity TDP thermal headroom sprint intensity MB impact sprint intensity sprint performance sprint mode application phase mode improves performance efficiently comparison sustain operation TDP baseline nominal thermal dictate sustainable however DynaSprint operating dissipates assume processor exactly thermal model per MB cache capacity sustain operation permit sustain MB llc performance sprint dynamic MB MB mode sustain operation TDP static MB mode DynaSprint performance perfect TDP relative baseline MB mode application exhibit variance sprint utility DynaSprint significantly outperforms sustain operation TDP application exhibit variance performance depends application sensitivity cache application omnetpp benefit cache permissible TDP prefer alternate sprint nominal mode others xalancbmk soplex insensitive cache MB MB sustain operation MB performance sprint micro october columbus usa  huang    rico andrew hilton benjamin lee discussion multi core implication although evaluate core application DynaSprint naturally extend manage multi program sprint phase predictor remain effective framework per performance counter however program sprint strategy account dynamic program decision program request sprint utility grant sprint performance fairness metric multi resource implication focus manage sprint resource cache DynaSprint extend manage sprint multiple resource DynaSprint ass compute memory intensity within across application boost core frequency expand cache capacity DynaSprint apply various technique reduce management overhead instance DynaSprint already epoch utility cache sprint boost core frequency  complement related computational sprint apply datacenters constrains processor chip server cluster uncoordinated sprint risk circuit breaker although battery computation emergency future sprint forbidden battery recharge management policy propose partition  cache minimize interference maximize throughput improve fairness performance centric partition mechanism construct rate curve MRC characterize rate function cache allocation utility cache partition  hardware monitor estimate MRC rely stack lru replacement policy  analytical model relies transient behavior  assumption future cache microarchitecture prior estimate MRC software trace memory address analytical model unfortunately trace memory address expensive introduces significant slowdown native execution hardware technique propose dynamically resize cache technique focus reduce leakage constraint performance degradation contrast sprint seek maximize performance gain thermal constraint ass offs sprint sprint future dynamic phase analysis technique performance strongly correlate execute code technique execution frequency vector  identify code execute prior construct  instruction unfortunately  expensive multiple sample instruction address accuracy performance counter skid precise instruction address intel  introduce additional overhead prior approach dynamic phase analysis predict future application behavior phase recur prior predictor capture phase technique tailor phase definition boundary specific optimization prior define phase ratio memory bus transaction micro ops statically determines phase boundary DVFS sophisticated dynamic resource management careful phase definition conclusion propose DynaSprint software runtime manages sprint intelligently application sprint utility thermal headroom propose cache sprint dynamically allocates cache capacity modest amount thermal headroom phase DynaSprint cache sprint improve performance average non sprint moreover performs within globally optimize oracular policy