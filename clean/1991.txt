hash widely inefficient core resource poorly suffer limited spatial locality cache address issue propose hta technique accelerates hash operation via ISA extension hardware hta adopts efficient hash format leverage characteristic cache hta accelerates operation hardware leaf rare software implementation hta hta hierarchical hta hta adopts hierarchy oblivious layout reduces runtime overhead core hierarchical hta complex implementation hierarchy aware layout improve spatial locality intermediate cache cache modest benefit hta evaluate hta hash intensive benchmark accelerate memoization technique cache reuses output repetitive computation hta improves performance hash intensive application hierarchical hta outperforms hta hta outperforms software memoization CCS CONCEPTS computer organization processor memory architecture serial architecture parallel architecture keywords hash memoization cache microarchitecture specialization introduction impend moore transistor scarce resource therefore crucial investigate abstraction mechanism span hardware software exist architectural component focus architectural accelerate hash operation hash widely consume majority cycle application database genomics hash extensively optimize software significant performance due  hardware software interface specifically hash suffer inefficiency conventional sec core utilization hash operation consists sequence instruction compute hash memory access comparison instruction predict data dependent waste cycle incur latency cache limit instruction parallelism spatial locality reduce mapping conflict hash uniformly across hash allocate memory spatial locality mixed reuse frequently access rarely access waste significant portion cache capacity address propose hta technique accelerates hash operation combination expressive ISA extension hardware sec hta adopts hash format leverage associative cache hta introduces instruction perform hash lookup update instruction leverage exist core structure prediction mechanism hash lookup semantics leverage core predictor avoid stall hta function instruction consume pipeline resource conventional hash operation instruction memory parallelism exploit hta accelerates hash operation rare software allows overflow conventional software hash implementation hta hta sec hierarchical hta sec implementation introduce core reduce runtime overhead hta adopts hierarchy oblivious layout hash uniform reuse hierarchical hta adopts multi hierarchy aware layout cache frequently access improve spatial locality hash mixed reuse hierarchical hta cache controller modest benefit hta implementation reserve cache instead dynamically cache capacity non hta data evaluate hta hash intensive benchmark accelerate memoization technique cache repetitive computation program skip sec micro october columbus usa  zhang daniel sanchez hta accelerates hash intensive application hierarchical hta outperforms hta moreover hta outperforms software memoization achieves comparable performance conventional hardware memoization without specialized chip storage background hash unordered associative container keyvalue operation lookup retrieve data associate insertion deletion remove hash perform operation amortize constant complexity heavily domain database networking genomics memoization hash typically implement array indexed hash collision happens multiple array index collision become array utilization grows utilization hash collision resolution strategy probe additional location resize utilization threshold implementation aspect hash function selection collision resolution resize mechanism hash function xor fold selection prone hotspot complex hash function universal hash distribute uniformly incur overhead collision resolution strategy chain address upon collision chain appends exist link address probe hash resize perform incrementally hash implementation algorithmic tradeoff trading efficiency lookup efficiency instance cuckoo hash improves efficiency lookup performance increase average lookup complexity variant focus reduce memory access per lookup improve locality hash performance analysis despite hash implementation suffer issue core utilization spatial locality core utilization overhead limit performance hash intensive application analyze overhead evaluate hash operation hash implementation detailed simulation sec methodology detail ofthe software baseline  unordered google dense hash hta execution implementation lookup update insertion hash initialize randomly generate footprint MB program performs lookup update exist randomly chosen hash normalize cycle lookup update insert memory stall llc stall stall stall function stall fetch decode stall execution issue micro ops execution cycle breakdown hash microbenchmarks hash implementation  unordered google dense hash hta empty distinct randomly chosen keyvalue insert hash grows accommodate insert execution cycle core activity cpi stack methodology specifically cycle core issue commit instruction execute instruction due misprediction stall unable issue due frontend fetch decode stall due backend functional cache cache llc memory reveals source overhead software hash predict underutilized backend parallelism predict hash probe cycle cycle spent execution unordered dense hash operation another hash probe data load memory resolve challenge predictor hash operation backend resource exploit instruction memory parallelism hash operation sequence instruction hash calculation memory access comparison instruction occupy micro µop slot comparable reorder buffer limit memory parallelism significantly backend stall spent memory response reorder buffer resource overlap multiple hta effectively reduces overhead improves performance avoids predict reduce eliminate execution hash operation µop slot improve memory parallelism reduce backend stall spatial locality issue software hash hash uniformly across allocate memory hinders spatial locality frequently access usually frequently access waste significant portion cache capacity illustrate microbenchmark previous hash occupy MB pre insert hash MB instead MB hash load artificially reduce mispredictions software leverage cache accelerate hash memoization micro october columbus usa version load probe almost succeed however inefficient benchmark performs series dependent lookup subset normalize cycle memory stall llc stall stall stall function stall fetch decode stall execution issue micro ops execution cycle breakdown mixed reuse microbenchmark previous hash hierarchical hta execution cycle breakdown previous hash implementation plus hierarchical hta mispredictions lookup benchmark limited parallelism hta outperforms software implementation spends cycle llc response contrast adopt multi hierarchy aware hash layout hierarchical hta densely pack frequently access keyvalue cache reduce hierarchical hta serf lookup instead llc outperform hta prior accelerate hash prior introduce hardware reduce hash overhead database prior leverage inter parallelism database operator exploit data parallelism technique optimize throughput latency hash access memory storage acceleration bypass cache hierarchy entirely sensible choice operating hash locality avoid spatial locality cache hash however incur latency poorly hash access locality hardware technique introduce specialized hardware hash comparison instead processor pipeline allocate dedicate chip storage hash typically specialized application php processing distribute hta technique reduce latency hash operation unlike hta technique introduce storage structure rival exceed cache proposal accelerate memoization consumes KB however application benefit storage dedicate storage waste otherwise devote cache hurt consumption contrast hta optimizes throughput latency hash operation hta avoids specialized chip storage hash cache scarce chip memory capacity program data memoization memoization technique improve performance efficiency memoization cache repetitive computation program skip memoized computation pure repetitive input memoization cornerstone important algorithm dynamic program widely functional introduce  implement software hardware significant drawback address hta software memoization relies hash memoize  runtime overhead hash hamper software memoization significantly later memoizable function merely instruction comparable cheaper hash lookup memoizing harmful  feitelson software memoization incurs significant overhead function memoizing mathematical function indiscriminately software memoization incurs performance loss hardware approach yield improvement avoid performance software scheme apply memoization selectively rely careful benefit analysis memoizable compiler profile programmer prior propose hardware accelerate memoization unlock memoization potential prior hardware memoization focus automate detection memoizable various granularity others rely ISA program memoizable however prior hardware technique dedicate storage memoization cache therefore incur significant overhead program cannot exploit memoization prior propose architectural runtime implicit input output memoized function enable memoizing impure function orthogonal acceleration hash focus hta easily combine hta hardware software interface hta hash acceleration technique hta handle hash access hardware leaf rare overflow resize software hta introduces software visible feature accelerate hash operation hardware hta adopts format hash exploit characteristic cache lookup update hta hash cacheable memory avoids specialized hardware cache prior hardware technique hta statically partition cache capacity hash data normal program data instead data manage unified cache replacement policy cache capacity dynamically access hta introduces hash instruction lookup update amenable implementation whereas software hash lookup multiple instruction predict hta hash lookup instruction semantics outcome lookup resolve predict accurately core exist predictor avoid stall micro october columbus usa  zhang daniel sanchez cacheable memory overflow hta pin overflow cacheable memory overflow hierarchical hta overview hta implementation overview hta implementation hta hierarchical hta feature hta across hta software hash hta cacheable memory across multiple cache memory hta software hash victim cache overflow hta hierarchical hta extends hta cache retain individual cache specifically cache hta cache specific hta stash overflow hta stash handle improves spatial locality intermediate cache frequently access however hierarchical hta improve spatial locality cache complicate interface memory benefit hta modest  hta stash pin ISA hta hierarchical hta implementation hta hash format hta contiguous fix memory hta storage format leverage characteristic cache cache fix format byte cache hash entry cache within lookup hash input data cache index fetch index access cache retains associativity within reduce collision avoid valid hta initializes entry invalid simply hash hta leaf collision resolution software specifically overflow cannot due capacity constraint overflow handle software software hash memory reg reg cache unused hta format hta ISA extension hta hta descriptor architectural register descriptor address implementation hta descriptor program hash manage descriptor accordingly load register operating hash hta instruction perform hash operation hta lookup hta update hta swap hta delete instruction semantics sample code implement thread lookup insertion sec describes instruction implement thread hash multithreaded application hta lookup performs lookup hta hash descriptor specify hta lookup integer float integer float register hta lookup integer float register core decodes fix register register mapping ISA convention instance num int register rdi rsi similarly int indicates integer floatingpoint rax xmm accordingly lookup resolve hta lookup target PC encode instruction PC relative format overflow flag lookup succeed update register correspond lookup resolve hta lookup non execute instruction hta update update hta hash hta lookup hta update encodes register hta update update cache target PC lookup hta lookup  int int target hta lookup implement thread hash lookup leverage cache accelerate hash memoization micro october columbus usa otherwise already hta update modify anything execute instruction hta swap attempt insert aggressively hta update hta update hta swap encodes register upon hta swap hta swap performs operation hta update update cache target PC however hta swap selects victim randomly update victim register hta swap non software update insert victim software hash distinction hta update hta swap useful thread hash sec hta delete remove format identical hta lookup replace delete instruction otherwise hta delete non software delete invalid hta lookup interpret delete empty lookup overflow software hta update hta swap interpret delete empty hta pre specify chooses invalid delete invalid delete thread lookup implementation hash lookup hta instruction lookup hta lookup instruction resolve hta lookup program execution otherwise program software perform lookup software hash hta hash behaves exclusive cache conventional software hash access handle quickly software rarely execute therefore introduces performance impact thread insertion similarly illustrates implement insertion hta already exists insertion update hta swap hta update resolve hta swap instruction skip software unresolved hta swap software insert victim software hash software hash newly insert remove overflow stale ISA alternative hta ISA integrate processor hta instruction encode compact format decode multiple µops upon execution sec alternative  implementation expose µops instruction however choice important spent frontend stall issue µops negligible CISC RISC style instruction significantly benefit hta reduce execution backend stall insert hta swap  hta swap implement thread hash insertion hta implementation hta hta cacheable memory hta substantially reduces overhead software hash suffers spatial locality core pipeline hta core functional executes lookup update swap delete instruction fed register possibly multiple cycle hta lookup instruction hash input index restrict hta crc instruction compute hash ISAs implement crc cheap hash crc distribution hash hta functional load appropriate cache output software skip correspond hta update hta swap functional update appropriate hta delete return hta leverage exist core mechanism improve performance integrate instruction superscalar core intel haswell sec frontend treat hta instruction hta instruction leverage exist target buffer predictor predict code instruction skip core overlap execution lookup update execution software resolution predict continuation resolution predict effectively hide latency hta instruction implementation backend executes hta lookup multiple RISC µops decoder µops input register hta functional hta µop instructs functional resolution µop fetch decode issue execute commit address calculation comparison hta addition mem hta core pipeline micro october columbus usa  zhang daniel sanchez circuit address calculation comparison core hta functional lookup predict resolve µop lookup destination register instruction implementation hardware implement hta functional rtl synthesize  FreePDK standard library functional target ghz frequency address calculation circuit mainly consists adder gate register hta descriptor comparison circuit comparators empty slot parallel report consume component overall functional  core manufacture hta overhead negligible software software performs lookup update conventional software hash handle rare overflow access hta besides software resizes hta dynamically resize algorithm hta adopts hta access software threshold threshold software hta  exist hta software hash hta assign counter memory address counter incremented rarely hta access implementation hence approximately monitor hta access software maintains counter software invocation software counter calculate access overflow decides resize hta parallel hash implementation multiple thread hash operation refinement thread leverage hta instruction atomic core already machinery ensure instruction lock verification load guarantee atomicity operation invoke software software invoked synchronization strategy guarantee atomicity grain lock protects implementation however hta orthogonal synchronization technique software technique combine transactional memory thread lookup thread implementation lookup software involves acquire lock lookup hta lookup  hta lookup release  release  hta lookup implement thread hash lookup software grain lock insert hta update  hta swap release  release  hta instruction implement thread insert software grain lock execute hta lookup instruction access software hash finally release lock hta lookup invoked lock avoid insertion thread insertion code thread update code hta update hta swap hta update modify hta software invoked important avoid hta swap lock modification properly synchronize hierarchical hta implementation hierarchical hta extends hta cache individual keyvalue hta cache specific hta stash stash specific cache stash reserve capacity cache partition cache instead hta stash capacity normal program data actual capacity stash consumes depends workload access hierarchy aware layout improves spatial locality intermediate cache improve cache utilization reduce whereas hta core hierarchical hta modifies cache controller fetch cache however hierarchical hta improve spatial locality llc llc manage complicate interface memory optimize transfer therefore hierarchical hta yield modest gain hta hta restriction simplicity introduce restriction backing hta contiguous physical memory  hta  virtual memory restriction restriction physical address avoid TLBs cache simplify address leverage cache accelerate hash memoization micro october columbus usa legend frequently access infrequently access empty slot cache hta stash format hta stash format layout hta stash correspond hta simplicity hta stash contiguous cache cache stash suppose hta hta address hta stash address compute zero offset within hta hta stash hta cache controller information hta stash address correspond hta format limit hierarchical hta hash cache hash implementation per management cache controller extend manipulate communicate individual within perform fetch GETS exclusive fetch GETX dirty writebacks  analogous request fetch eviction conventional cache hta operation hash hta stash sequence hta stash eventually hta access stash cannot resolve operation illustrates hierarchical hta operation cache hierarchy pin hta stash suppose empty hta lookup trigger GETS request hta access hta fetch memory responds associate allocates hta stash installs hta inclusive hta stash update lookup issue GETX exclusive request update hta insert hta cache evict hta stash individual marked modify simply overflow overflow hta stash transparent software cache evicts randomly chosen overflow hta treat hta invoke software fallback update hta inclusive hta stash overflow eviction hta stash hta overflow coherence finally maintain coherence conservatively coherence tracked cache hta llc hta evict hta lookup resp core core GETS initial  core core  ack ack legend empty slot hta lookup eviction grain memory ops hierarchical hta exclusive request sharer invalidation cache hta stash exclusive request due update hta stash permission due lookup policy reuse coherence metadata precise perform coherence hta  memoization memoization improves performance cache reuse output repetitive computation sec prior software hardware memoization technique significant drawback software memoization suffers runtime overhead limited computation prior hardware technique achieve overhead memoize function rely purpose memoization cache waste significant leverage hta accelerate memoization cheaply performance prior hardware memoization technique without dedicate chip storage memoization allocate memoizable function memoization hash argument return memoization hta implement hta conventional software manipulate software hash instead hta software simply memoizable function tradeoff execute function cheaper software hash lookup memoization operation implement hta instruction code leverage hta instruction memoize argument function exp memo exp hta lookup exp hta swap hta instruction memoize exp function micro october columbus usa  zhang daniel sanchez hta lookup memoized function correspond return return register function skip otherwise function execute memoized hta swap memoization accommodate extra item insertion simply replace entry software hta swap target PC victim simply affect correctness program tradeoff memoizing function longer function blown hta accelerate hash exploit memoizable developed  identify memoizable pure function function define memoizable satisfies memory data stack memory writes restrict stack manually hta lookup hta swap instruction function  due overhead hta perform selective memoization benefit analysis software technique therefore memoize function identifies memoizable memoize application standard library function methodology perform microarchitectural execution driven simulation zsim evaluate core core chip parameter core model haswell cache hierarchy inclusive llc MB per core hta implementation register hta descriptor hta instruction incur cache load access plus cycle perform comparison model access per cycle due simd instruction avx encode hta lookup hta update hta swap hta delete ops emit compiler evaluate hta workload hash implementation leverage memoization improve performance achieve statistically significant introduce amount nondeterminism perform achieve confidence interval hash workload analyze application hash heavily  memory efficient software  dna sequence data essential bioinformatics genome  assembly  heavily update hash mers dna sequence encode input lzw text compression benchmark lzw algorithm widely lossless data compression technique hash bible input text file core ISA ghz haswell    PHT decoder execution commit cache KB associative cycle latency split cache KB associative cycle latency inclusive cache MB per core associative cycle latency inclusive mem ddr channel core channel core configuration simulated hta baseline hta swap input hash lookup update    lzw bible unordered hashjoin  google ycsb dense hash ycsb hash benchmark characteristic hashjoin thread implementation hash algorithm hashjoin synthetic phase program phase inner scan hash phase outer scan hash probed output tuples ycsb implementation yahoo benchmark dbx hash hash index evaluate ycsb configuration query query detail application characteristic modify application multiple hash implementation template  without runtime overhead implementation baseline hash application  unordered google dense hash baseline implementation outperforms application exist hash hta hierarchical hta evaluate hta hash implementation hta hash access hta lookup update swap delete instruction hta hash empty resize insert specifically software invocation hta access hta involves allocate hta twice insert previous hta software hash hta application hta software hash baseline hta rarely software hash performance insensitive choice software hash hta SW analyze hta illustrate performance difference implement software scheme hta SW implement algorithm hta without hardware hta SW format software hash resize algorithm hta SW rely hardware hash operation leverage cache accelerate hash memoization micro october columbus usa memoization benchmark input memoizable per lang suite function function bwaves fortran  ref  pow KB  exp  parsec native  exp  KB equake  ref phi phi phi KB splash exp KB semphy   KB nab  ref exp  avx KB memoization benchmark characteristic hash comparison memory access implement purely software hta SW within cache contiguous format comparison implement simd load comparison instruction specifically intel avx vector load mask instruction exploit parallelism lookup application skip initialization data load ycsb simulate completion memoization workload analyze program benchmark suite application memoization potential suite detail application characteristic application memoization memoized function report yield performance sec insight application billion instruction program heartbeat report  progress timestep transaction heartbeat baseline without memoization completes billion instruction amount across scheme memoization instruction execute evaluation hta thread application performance baseline hta SW hta  baseline  lzw hashjoin ycsb ycsb breakdown core cycle format sec trend  lzw benefit mainly reduce mispredicted hashjoin ycsb gain mostly backend parallelism hta outperforms hta SW substantially  lzw hashjoin ycsb ycsb benefit stem reduce execution backend stall specifically hta incurs cache hta SW application abundant operation parallelism hashjoin ycsb benefit hta significantly reorder buffer hash operation µops operation overlap reduce backend stall ycsb benefit ycsb  improves update lookup sec baseline hta SW hta speedup lzw ycsb ycsb speedup hta hta SW software baseline thread application issue micro ops execution fetch decode stall function stall stall stall llc stall memory stall normalize cycle lzw ycsb ycsb cycle breakdown baseline hta SW hta moreover hta SW consistently improve performance hta SW outperforms baseline substantially  lzw respectively hta sometimes outperform hash implement entirely software however hta SW performance degradation hashjoin ycsb ycsb application performance improvement hta hardware acceleration beyond performance efficiency important consideration hash report memory consumption implementation hta SW memory layout hta hence exactly memory consumption overall hta undue storage  difference hash exponentially difference resize threshold difference  lzw unordered baseline hta baseline hashjoin ycsb dense hash baseline hta baseline baseline hta hta SW hta software  unordered MB MB MB lzw MB MB KB hashjoin dense MB MB ycsb hash MB MB ycsb MB MB memory usage baseline hta micro october columbus usa  zhang daniel sanchez hta multithreaded application evaluate hta multithreaded application hta baseline core speedup ycsb core ycsb speedup  baseline ycsb core speedup relative thread baseline  lzw hashjoin thread multithreaded implementation  ycsb core hta outperforms baseline ycsb ycsb speedup serial version hta operation perform without acquire lock hta hierarchy aware layout performance hta  hierarchical hta KB hta stash pin cache KB hta stash pin cache hta cached llc performance scheme  ycsb mixed reuse hierarchical hta reduces respectively happens hierarchical hta densely packed reduction translates performance improvement ycsb however ycsb attains performance hta completely hide latency update exploit memory parallelism sec finally application exhibit mixed reuse hierarchical hta significantly improve performance hta hta multiprogrammed workload evaluate hta impact application thread ycsb thread spec omp application simultaneously core thread application pin core hta hierarchical hta speedup lzw ycsb ycsb speedup hierarchical hta  baseline hta speedup spec ycsb spec ycsb spec ycsb kdtree others ycsb spec ycsb spec ycsb spec ycsb kdtree others ycsb speedup hta baseline spec omp app ycsb simultaneously baseline hta MPKI kdtree ycsb kdtree ycsb MPKI kdtree ycsb summarizes performance impact hta performance spec omp application kdtree affected replace baseline hash  others kdtree  application hta interference default hash ycsb  kdtree performance improve hta accelerates ycsb perform hash operation faster insight reporting per  MPKI ycsb kdtree without hta despite rate operation ycsb MPKI leaf capacity memory bandwidth kdtree ycsb hta kdtree performance due increase cache capacity contention however ycsb faster hta performs hash operation faster baseline ycsb version incur MPKI overall hta introduce undue memory memory pressure hta memoization leverage hta memoization performance baseline implementation conventional hardware software memoization technique hta baseline performance  memoization baseline benchmark perform memoization hta improves performance substantially bwaves  equake semphy nab detail reporting per function statistic bwaves memoizing pow function benefit pow instruction calculate around bwaves memoizing pow contributes instruction reduction bwaves leverage cache accelerate hash memoization micro october columbus usa baseline hta speedup bwaves  equake semphy nab speedup hta memoization baseline benchmark memoization baseline hta access relative baseline bwaves  equake semphy nab data cache access relative baseline bwaves  equake semphy nab data cache data cache access hta memoization relative baseline without memoization beyond reduce execution hta reduces cache access significantly access reduction nab bwaves happens access memoization exceed additional access incur memoization operation moreover hta incur extra capacity contention cache hta increase data cache overall exception  incurs hta however significant baseline rate valuable memoization data improve performance equake hta reduces data function  data footprint memoization function instrs per rate func hta lookup bwaves  pow  exp   exp  equake phi phi phi exp semphy nab exp  avx per function breakdown hta lookup hta dedicate hardware buffer speedup bwaves  equake semphy nab per application speedup hta conventional hardware memoization dedicate buffer KB hta conventional hardware memoization implement conventional hardware memoization technique leverage hta ISA pipeline dedicate storage buffer prior instead memory memoization beyond hardware conventional hardware memoization lack flexibility memoization buffer waste memoization buffer sacrifice memoization potential quantifies performance hardware memoization across memoization buffer KB buffer associative entry dynamically memoized function optimistically model cycle buffer access latency application sensitive memoization buffer KB sufficient equake nab semphy prefer KB bwaves  prefer KB buffer application increase memoization sacrifice speedup memoization finally hta hardware memoization dedicate storage KB application achieve hta dedicate storage significant tradeoff memoization memory longer lookup latency dedicate buffer however lookup latency mostly prediction effectively hide latency hta software memoization implement software memoization function wrapper  memoization implement fix  software memoization speedup bwaves  equake semphy nab per application speedup hta software memoization per function mapped hash micro october columbus usa  zhang daniel sanchez mapped hash access function update memoization performance hta software memoization hta outperforms software memoization  equake semphy nab hta outperforms software memoization due overhead semphy memoizable function instruction average software memoization software memoization baseline explains software memoization careful benefit analysis avoid performance degradation contrast hta improves performance semphy outperform software memoization similarly software memoization nab hta improves performance conclusion introduce hta technique leverage cache accelerate hash hta introduces ISA extension hardware address runtime overhead spatial locality conventional hash implementation hta adopts hash format exploit characteristic cache hta instruction leverage exist core structure accelerate hash lookup update implementation hta hta hierarchical hta hta adopts  memory layout reduces runtime overhead core hierarchical hta multi hierarchy aware layout modification cache improve spatial locality hta outperforms implementation hash intensive application hierarchical hta outperforms hta finally hta leveraged accelerate memoization hta bridge gap hardware software memoization hta outperforms software memoization performance conventional hardware technique avoids overhead dedicate buffer