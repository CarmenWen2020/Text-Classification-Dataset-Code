compression technique increase ective cache capacity unfortunately compression technique incur tag overhead restrict cache placement address ideally compress cache without restriction overhead proposes touché framework multiple compress arbitrary address within cacheline without tag overhead touché framework consists component rst component signature creates shorten signature tag address compress due multiple signature tag entry cache access physical cacheline access signature negligible probability false positive component tag append data TADA mechanism tag address data TADA enables touché detect false positive signature tag address component superblock marker SMARK mechanism unique marker tag entry compress cache physical address cacheline touché hardware achieves average speedup ideal uncompressed baseline CCS CONCEPTS hardware chip resource management static memory keywords compression cache tag array data array hash introduction moore slows transistor per core cache llc tends stagnate employ data compression  increase ective llc capacity per core unfortunately naively adopt data compression incur significant tag overhead conventional cache tag compression increase within llc llc tag overhead increase reduce tag overhead compress address enables overlap tag compress however approach restricts adoption data compression contiguous compress ideally employ data compression within llc without data placement restriction tag overhead tag overhead roadblock cache compression instance ective llc capacity increase incur overhead maintain unique tag furthermore likely unique tag locality cannot combine therefore incur signi cant overhead reduce tag overhead placement restriction instance compress memory address reside physical cacheline overlap tag contiguous compress superblock tag superblock tag MB cache superblock tag compress per cacheline tag restrict placement superblocks reduces bene compression ective llc capacity execute memory intensive spec workload mixed rate mode MB llc rst baseline llc without data compression employ data compression llc superblocks tag baseline increase ective llc capacity address compress cacheline data compression compress arbitrary address within cacheline increase ective llc capacity tag fourth ideal compress arbitrary address cacheline without overhead micro october columbus usa hong    nair ective capacity tag overhead MB cache employ compression  tag ective capacity arbitrary tag tag ective capacity goal obtain ective capacity tag overhead touché framework achieve fourth enable ideal llc compression touché mitigates tag overhead shorten signature tag address compress bene signature tag address due multiple signature erent tag address originally reserve tag address enable arbitrary signature reside overcome restriction prior compress address furthermore compression creates unused data array tag address append compress unused touché framework consists component rst component signature creates shorten signature tag address tag array component tag append data TADA mechanism appends tag address compress data array component superblock marker SMARK mechanism unique marker tag enable touché identify superblocks contiguous compress physical address mechanism signature touché framework implement within llc controller core llc controller physical address request llc controller physical address index appropriate touché invokes shorten signature tag signature signature correspond compress access data array signature signature belonging erent tag address reside tag entry instance MB llc byte cachelines tag entry tag address signature tag address enables touché compress arbitrary address within cacheline without tag overhead unfortunately simply shorten signature false positive tag signature collision signature collision llc controller incorrectly access tag address access instance workload cache rate scenario signature average signature collision rate furthermore signature touché potentially signature llc scenario signature collision rate therefore essential tag address signature collision tag append data TADA mechanism tag address compress data array touché provision portion additional obtain compression tag address touché tag append data TADA mechanism append tag beside compress TADA mechanism appends metadata information compressibility dirty valid tag address compress overall TADA increase byte minimally reduces ective llc capacity access TADA interprets compress cacheline metadata tag address TADA tag signature collision guarantee correctness llc access superblock marker SMARK mechanism shorten signature enable compress however instance cachelines compress address superblock address scenario touché superblock marker SMARK mechanism generate unique marker touché marker tag marker superblock within cacheline negligible probability unique marker signature scenario SMARK collision fortunately SMARK collision correctness marker collision TADA mechanism data array tag collision tag address compress llc SMARK mechanism enables touché derive bene superblocks enable storage compress arbitrary address touché speedup ideal without overhead llc touché comparators lookup within llc controller therefore touché completely hardware framework enables ideal compression background motivation brief background cache organization highlight potential data compression cache processor tend chip cache cache exploit spatial temporal locality access due cache improve performance processor reduce chip access reduce latency touché towards ideal icient cache compression mitigate tag overhead micro october columbus usa memory request cache usually progressively previous consequently cache llc tends typically occupies signi cant chip estate due bene  increase llc capacity per core enable designer chip reduce chip access cache capacity stagnation llc capacity per core commercial intel amd processor average core increase llc capacity per core reduce multi core llc capacity per core tends MB therefore future bene  technique improve ective capacity llc llc MB core logical core intel amd cache llc capacity per logical core intel amd processor average core increase llc capacity per core reduce cache organization cache llc organize data array tag array cacheline data array correspond tag entry tag array furthermore cachelines cacheline corresponds llc signi  physical address llc controller tag address tag entry uniquely identify cacheline instance MB llc byte tag address cache access tag entry parallel llc controller llc controller MB cache tag array data array cache memory tag entry cacheline tag byte organization MB cache llc llc consists data array tag array llc controller tag tag entry across parallel compression ective capacity prior propose cient latency algorithm compress thereby improve ective llc capacity typically llc compression technique implement within llc controller icient data compression algorithm delta immediate bdi frequent compression FPC latency compression algorithm bdi insight data tend within therefore compress FPC insight frequent zero etc FPC frequent prior bdi FPC implement execute cycle delay implement within llc controller llc controller data array cache memory decompression tag manager compression compress compress tag array llc compression decompression compression decompression tap data bus compressibility information tag entry compression decompression llc controller implement compression decompression tap bus cache data array llc controller contains tag manager manage tag entry compression decompression implement bdi FPC chooses algorithm tag manager maintains compressibility information tag entry distribution compress data distribution compression spec workload rate mixed workload average compress byte furthermore compress byte therefore workload tend entropy bene compression mcf lbm  libquantum omnetpp  sphinx gemsfdtd  cactusADM zeusmp bzip dealii xalancbmk  percentage memory byte byte byte byte distribution spec workload rate mode average compress byte micro october columbus usa hong    nair llc compression tag overhead compute tend byte tag entry cacheline data array MB llc employ compression tag entry valid dirty furthermore assume replacement policy maintain cacheline cacheline evict reduce encode tag array compress byte byte byte boundary reduce tag entry restrict cachelines contiguous address contiguous superblock prior superblocks compress reduce tag overhead MB llc per cacheline tag entry superblocks reduce tag overhead limit potential bene llc compression restrict placement address arbitrary address unlock bene llc compression however disadvantage approach MB llc per cacheline tag entry baseline tag entry tag array cacheline data array valid dirty tag address replacement policy byte baseline compression memory compression superblock tag address memory memory memory compression arbitrary tag address compress compress tag overhead erent technique baseline technique employ compression tag overhead superblock technique increase tag arbitrary tag increase tag llc compression potential overhead bene llc compression technique baseline technique employ compression tag overhead average rate technique employ superblocks compression tag increase average rate technique highlight potential rate compression cacheline compress unfortunately technique tag increase average llc rate rate average rate baseline superblock tag ideal tag potential llc compression enable arbitrary address increase average rate llc touché framework overview overview touché framework touché consists component rst component signature generates shorten signature tag address within tag manager component tag append data TADA mechanism attache tag address compress memory TADA mechanism tap data bus compression decompression obtains tag address tag manager component superblock marker SMARK mechanism superblocks unique marker tag entry SMARK mechanism implement tag manager touché llc controller llc controller data array cache memory decompression tag manager compression compress compress tag array SMARK TADA tag address overview touché touché consists component signature tag append data TADA mechanism superblock marker SMARK mechanism component implement llc controller llc signature signature implement tag manager generates shorten signature tag address access llc identify compress llc  informs tag manager compressible compress tag touché towards ideal icient cache compression mitigate tag overhead micro october columbus usa manager valid dirty tag entry encode information insight valid valid dirty exist instance cacheline cannot marked invalid dirty tag manager unused cachelines compress thereafter cacheline compress tag address dirty tag manager valid dirty tag entry identify cacheline contains valid compress cacheline deem valid compress tag manager tag address dirty identify compress cacheline status valid dirty tag address tag address invalid uncompressed valid uncompressed valid dirty compress valid compress valid dirty shorten signature multiple signature within tag entry shortens tag address signature MB llc tag address cacheline compress tag address tag entry already dirty unused remain tag address therefore signature correspond compress signature generator signature generator tag address XORed generate output output index entry hash entry hash boot unique hash hash generates unique signature input overall latency generate signature delay xor gate parallel hash lookup performance processor execute 2GHz estimate signature generation incur cycle furthermore latency signature generation masked latency reading tag entry llc access cycle tag address xor signature entry hash signature generator within signature generator xor operation hash lookup llc access signature llc tag manager tag entry indexed signature tag manager tag manager  cacheline contains compress valid dirty uncompressed cacheline tag manager ignores signature tag address cacheline contains valid compress tag manager ignores rst tag address thereafter remain tag address tag entry partition entry tag manager entry signature entry signature guaranteed absent signature likely signature tag address entry comparison signature false positive false positive signature signature collision collision rate signature tag entry signature llc  signature comparison access signature shorter tag tag signature perform signature likely llc access signature collision probability collision signature varies zero uncompressed compress erent llc rate probability signature collision per access signature entry rate rate rate rate rate probability collision signature signature entry worstcase llc signature collision access workload rate collision signature collision llc incorrect tag address core essential tag tag append data TADA mechanism tag append data TADA mechanism implement llc controller tap data bus  data array micro october columbus usa hong    nair append tag address data llc TADA mechanism tag tag manager TADA mechanism appends tag address valid dirty compressibility information cacheline byte cacheline compress TADA mechanism append information cacheline tag entry tag array cacheline data array valid dirty signature replacement policy tag valid dirty compressibility tag valid dirty compressibility tag valid dirty compressibility byte cacheline compress TADA mechanism TADA mechanism appends tag address valid dirty compressibility information cacheline append tag address data TADA mechanism appends byte information cacheline compress TADA reduces available compress compress compress data array compressibility information eld fortunately additional loss reduce ective capacity reduction ective llc capacity due TADA llc arbitrary compress TADA decrease ective cache capacity ideal scheme compress arbitrary address without storage overhead rate average baseline TADA storage compress ideal compress effective capacity llc reduction ective llc capacity TADA storage overhead TADA byte per compress decrease ective llc capacity ideal scheme metadata storage data array detect collision signature TADA detect signature collision signature collision cachelines data array tag manager TADA mechanism extract tag address cachelines tag address llc access TADA signature collision therefore TADA guarantee detection signature collision thereby ensures correctness furthermore TADA extract compressibility information decompression valid dirty compress TADA therefore TADA avoid additional tag entry additional information latency overhead data array access signature collision increase llc access latency additional access data array baseline llc access probe indexed tag array cacheline data array llc tag access occurs access irrespective access tag array access latency data array typically access llc tag array incurs latency overhead cycle reading llc data array incurs overhead cycle processor touché framework data array likely access llc incur signature collision invoke TADA mechanism access data array detect signature collision worstcase workload rate scenario therefore signature collision increase overall latency llc access average latency llc access collision additional data array access collision data array access probability latency cycle average access cache collision probability collision increase access latency cycle workload rate increase llc tag access latency denote equation tag access latency mitigate latency overhead dynamic touché mitigate signature collision latency overhead compress useful touché continuously monitor average memory latency llc controller average memory latency ned latency experienced request emanate llc memory touché towards ideal icient cache compression mitigate tag overhead micro october columbus usa touché enables compression average memory access latency latency overhead signature collision signature collision increase llc tag access latency cycle touché enables compression average memory latency cycle advantage touché enable workload showcase memory latency bene llc compression latency overhead touché capped memory intensive benchmark average memory latency cycle signi  cycle therefore latency overhead touché mcf lbm  libquantum omnetpp  sphinx gemsfdtd  cactusADM zeusmp bzip dealii xalancbmk  average memory latency cycle average memory latency average average memory access latency cycle therefore touché latency overhead superblock marker SMARK mechanism enables storage however cachelines superblocks benefit superblocks  touché maintain compress scheme superblocks superblock touché compress byte enables touché bene superblock tag arbitrary tag superblocks arbitrary increase average rate touché rate average rate touché arbitrary touché arbitrary superblocks average rate touché versus superblocks average rate increase combine superblocks identify potential cachelines llc install compressible candidate cacheline already contains compress address cacheline superblock candidate TADA mechanism identify superblock candidate extract tag address cacheline llc install generate marker touché implement superblock marker SMARK mechanism tag manager SMARK mechanism generates random marker boot marker throughout operational TADA mechanism  superblock cacheline informs tag manager tag manager retrieves marker SMARK mechanism informs ignore correspond address tag address generate unique signature ensures address superblock generate signature thereafter tag manager appends signature marker writes tag rst within superblock cacheline TADA mechanism appends dirty per compress data array valid superblock compress within superblock valid therefore TADA append additional per valid superblock marker mechanism tag entry tag array cacheline data array superblock superblock tag metadata SMARK tag manager superblock marker SMARK mechanism marker tag manager marker compress within marker tag manager signature generate ignore signi cant signature cacheline data array TADA mechanism extract tag address llc access within superblock llc controller likely cacheline request simply false positive signature collision scenario marker collision ect marker collision marker collision extremely rare marker instance cache probability marker collision access impact llc latency negligible furthermore marker collision TADA mechanism ensures tag address checked compress therefore SMARK TADA guarantee correctness superblocks touché operation writes  touché llc access install request respectively touché invokes TADA SMARK mechanism compress data incompressible data touché baseline furthermore TADA mechanism invoked llc compress enables touché guarantee correctness micro october columbus usa hong    nair request invoke SMARK marker invoke signature invoke signature memory TADA mechanism signature marker collision invoke baseline compressible llc compressible candidate superblock tag tag entry baseline memory TADA mechanism signature install access tag entry invoke superblock signature SMARK superblock invoke TADA data superblock tag  detail operation touché install access request  install request  access request discussion baseline llc tag entry contains metadata replacement policy coherence private LLCs discus ect touché handle cache coherence touché assumes llc therefore encounter coherence concern however llc private snoop coherence protocol employ touché maintain coherence minimal overhead touché coherence tag compress data array llc controller access data array tag coherence operation increase latency tag coherence request however operation incur performance overhead additional access data array signature coherence update critical request service additionally coherence request  request another core service core entire request core anyway additional data array access performance overhead furthermore implement commercial processor eliminate performance impact snoop coherence protocol simply directory coherence protocol handle cache replacement policy tag entry baseline already equip replacement information touché multiple compress per cacheline ideally preferable equip additional replacement tag entry however per compress tag entry minimize overhead replacement information whenever cacheline access touché update replacement touché individual replacement replacement touché selects victim cacheline replacement randomly evicts within victim cacheline experimental methodology evaluate performance bene touché develop  cache simulator  detailed memory simulator extend  model processor core detailed cache hierarchy processor model implement OoO execution benchmark trace detailed cache model various replacement policy lru DRRIP dip baseline con  described enable cient compression compression model cache model employ bdi FPC compression algorithm algorithm compression ratio cacheline prior bdi FPC assume compression decompression data incurs cycle latency touché previous scheme yacc superblocks scheme ideal scheme arbitrary superblock without overhead ideal scheme replacement policy touché described baseline con  core OoO processor ghz issue width cache private KB cycle cache private KB cycle cache MB llc tag access latency cycle llc data access latency cycle memory bus frequency mhz ddr mhz memory channel rank per channel per per cache per dram access timing  trp tcas dram refresh timing  touché towards ideal icient cache compression mitigate tag overhead micro october columbus usa mcf lbm  libquantum omnetpp  sphinx gemsfdtd  cactusADM zeusmp bzip dealii   gmean speedup baseline yacc touché ideal speedup touché baseline employ compression average touché achieves speedup ideal yacc enable compress arbitrary address superblocks mcf lbm  libquantum omnetpp  sphinx gemsfdtd  cactusADM zeusmp bzip dealii    rate baseline yacc touché ideal rate touché baseline employ compression average touché increase rate ideal yacc within llc chose memory intensive benchmark MPKI llc per instruction spec cpu benchmark cache billion instruction execute billion instruction ensure adequate representation compressibility performance billion instruction sample instruction per billion instruction billion instruction execute benchmark rate mode twelve thread mixed workload category spec benchmark MPKI category MPKI category described randomly benchmark category MPKI mixed workload medium MPKI mixed workload perform timing simulation benchmark workload  execution workload mcf libquantum gemsfdtd wrf lbm gcc bzip bwaves milc sphinx leslied zeusmp soplex omnetpp cactusADM dealii xalancbmk mcf gcc sphinx omnetpp lbm milc xalancbmk astar mcf milc calculix omnetpp gobmk sjeng libquantum namd gcc lbm dealii soplex tonto hmmer perlbench gemsfdtd bwaves povray zeusmp wrf xalancbmk RESULTS discus performance rate sensitivity touché performance impact speedup touché baseline employ compression average touché speedup ideally compress memory without overhead tag data array speedup yacc achieves speedup capture superblocks analysis gcc bene llc compression gcc extremely sensitive llc capacity rate gcc due touché gcc memory access latency rate almost llc therefore gcc speedup due touché workload rate speedup ect cache rate speedup touché baseline employ compression average touché increase rate ideal compress memory arbitrary address without overhead tag data array rate increase yacc increase rate furthermore workload gcc obtain signi cant increase rate micro october columbus usa hong    nair mcf lbm  libquantum omnetpp  sphinx gemsfdtd  cactusADM zeusmp bzip dealii   gmean speedup baseline touché lru touché dip touché DRRIP sensitivity touché erent replacement policy touché llc compression framework orthogonal replacement policy touché increase speedup lru dip DRRIP replacement policy respectively rate touché increase remain benchmark furthermore touché closely rate ideal llc compression technique slight loss rate ideal llc compression loss capacity within data array TADA mechanism sensitivity replacement policy touché llc compression technique orthogonal replacement policy typically llc controller victim cacheline replacement policy touché evicts random within victim cacheline therefore erent replacement policy combine alongside touché speedup touché erent cache replacement policy average touché increase speedup lru dip speedup increase DRRIP replacement policy therefore irrespective replacement policy touché performance cient compression impact memory latency impact touché average memory latency touché llc rate reduces average memory latency average touché reduces memory latency cycle cycle ideal reduce average memory latency cycle scheme slightly rate rate average baseline touché ideal average memory latency average memory latency touché average touché reduces memory latency cycle cycle sensitivity cache impact llc  touché touché ective erent llc instance MB cache touché average speedup llc MB MB touché average speedup MB MB MB speedup baseline touché sensitivity touché llc llc touché average speedup  impact MPKI benchmark MPKI benchmark however implementation purpose vital touché hurt performance MPKI benchmark impact touché performance MPKI workload spec suite overall touché slowdown MPKI benchmark contrary touché average speedup workload hmmer perlbench astar gromacs gobmk sjeng namd tonto calculix povray gmean speedup baseline touché ideal impact touché MPKI workload touché hurt performance MPKI benchmark touché average speedup workload touché towards ideal icient cache compression mitigate tag overhead micro october columbus usa comparison cient tag management technique technique cache dram cache variable touché tag cache bandwidth granularity cache compression superblocks  maintains entire memory tag overhead related prior closely related cient compression algorithm cache compression algorithm frequent compression FPC delta immediate bdi cache packer CPACK decompression latency implementation overhead pack algorithm improve detect zero cache recently introduce compression algorithm transformation achieve compression ratio touché orthogonal compression algorithm touché algorithm hardware budget latency constraint application requirement cache compression tag management prior propose compress cache architecture improve ective cache capacity instance variable compress cache architecture FPC propose architecture cache cachelines compress twice tag entry technique propose cient tag management reduce tag overhead compress cache dcc scc superblocks multiple tag entry recently yacc propose reduce complexity scc exploit compression spatial locality yacc restricts mapping compress cachelines superblocks cachelines address furthermore yacc cachelines compress touché eliminates fundamental limitation super compress cache average yacc speedup additional tag tag touché speedup without overhead increase llc   cache proposes tag data eliminate tag however tag  memory within cache dram cache encounter tag storage tend bandwidth sensitive compression dram cache improve capacity bandwidth dynamically compression deduplication data deduplication exploit observation memory llc identical improve  technique memory within llc technique maintain tag memory exploit presence identical memory llc dedup llc enable tag data tag array decouple data array tag entry equip pointer enable arbitrary memory data array touché orthogonal dedup touché compression technique compress arbitrary memory independently enables dedup apply memory compression technique compression memory  compress data improve bandwidth memory   propose cient technique improve ective capacity memory compression compression non volatile memory nvm reduce improve performance compression increase toggle bus  minimizes toggle reduces bus consumption recently compresso memory propose reduce additional data movement metadata access additional translation compressibility cacheline compression across cacheline boundary similarly DMC propose improve memory capacity compression software increase memory capacity ibm mxt   balloon driver allocate unused memory data becomes incompressible virtual machine exceed capacity threshold compression context memory security morphable counter compress integrity encryption counter reduce height integrity within memory metadata management memory reduce metadata bandwidth overhead compression   enables data metadata access  describes challenge maintain metadata memory recommend ecc metadata technique useful memory module ecc llc tag entry rely ecc metadata however touché expand ecc within llc metadata relevant  cachelines compressibility  propose compress data throughout memory hierarchy approach reduces overhead compression decompression memory hierarchy micro october columbus usa hong    nair memory bandwidth lossy lossless compression gpus recent han  compression neural network signi  improve performance reduce prior orthogonal touché cache compression reduce cache consumption residue cache architecture reduces cache prior propose negative impact compression replacement ecm reduces cache aware insertion aware replacement exploit compress cache reuse indicator  propose avoid performance degradation due compression replacement performance  touché improve prior summary cache llc capacity per core stagnate decade increase ective capacity llc employ data compression data compression enables llc controller pack memory within llc unfortunately additional compress memory additional tag entry llc designer provision additional tag tag entry compress restrict data placement within cacheline address superblocks reduce tag overhead ideally bene llc compression without incur tag overhead proposes touché framework enables llc compression without overhead tag data array touché shorten signature tag address appends tag compress memory data array enables touché arbitrary memory furthermore touché enhance superblocks touché completely hardware achieves ideal speedup ideal without overhead tag data array