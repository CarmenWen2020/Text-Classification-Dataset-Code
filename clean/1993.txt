datacenter operator deploy persistent memory PM leverage combination access persistence significant performance gain challenge PM aware software maintain performance achieve atomic durability latter typically introduces considerable overhead additional cpu cycle traffic requirement exploit data  inherent memory hierarchy achieve atomic durability without lad relies persistent buffering memory controller MCs already CPUs speculatively accumulate transaction update atomically commit PM lad employ chip distribute commit protocol hardware manage distribute speculative transaction accumulates across multiple MCs demonstrate lad practical rely modest hardware modification atomically durable transaction deliver ideal PM oblivious software performance CCS CONCEPTS computer organization processor memory architecture information storage memory phase memory keywords persistent memory atomic durability atomicity introduction persistent memory PM  datacenters  dram already production emerge non volatile memory technology intel 3D xpoint popularize PM deployment PM promise performance gain data intensive application replace disk memory access byte addressable memory effective PM software specially crash consistency popular program abstraction transaction crash consistency transaction atomically durable atomic durability guarantee upon failure none transaction update durable challenge software achieve atomic durability without significantly hurt performance boost gain replace conventional storage PM mainstream approach atomic durability instance rely software ahead research proposal accelerate hardware strength weakness specific implementation introduces programmability hurdle notable performance overhead excess cpu cycle PM writes constraint transaction leverage multiple version data inherently memory hierarchy eschew PM data valid transaction transaction runtime update speculative stag memory hierarchy atomically commit PM transaction commits critical requirement stag persistent guarantee atomic propagation transaction update PM failure argue request queue memory controller MCs excellent candidate implement stag battery backing requirement modest capacity queue battery MCs already available server CPUs introduce lad logless atomic durability hardware mechanism expose familiar interface transaction software guarantee transaction update propagate atomically PM without lad buffer update persistent MC queue transaction atomically commits PM transaction concept lad relies eschew namely persistent stag within memory hierarchy data atomically commit PM introduce kiln unlike kiln lad limit persistence requirement MCs without llc modification scalable memory hierarchy feature centralization unified llc memory hierarchy server CPUs distribute NUCA llc multiple MCs address critical challenge manage speculative distribute transaction update data reside memory location lad employ variant phase commit protocol implement micro october columbus usa  gupta     hardware handle distribute speculative atomic commit decision prior atomic isolation involves management distribute speculative however propose technique directly applicable atomic durability concept failure recovery qualitatively context failure context atomic durability abrupt loss instance recovery persistent consistent contribution hardware mechanism atomic durability contains hardware extension L1D cache MCs without chip cache persistent lad obviates software overhead creation avoids altogether consistent technological trend non volatile chip component lad relies MCs already battery recent server CPUs furthermore detail implementation distribute hardware manage protocol atomic decision robust crash failure organize discus prior argue recent technology trend battery MCs introduces opportunity highperformance atomic durability lad implementation respectively methodology evaluation conclude background related PM byte addressable persistent memory non volatile memory technology intel 3D xpoint battery dram PM gain momentum promise significant performance gain data intensive application offering persistence traditionally attainable operation storage device memory latency benefit PM persistence software PM specific contract crash consistent namely guarantee PM content application recover valid operational crash source complexity crash consistent software arises data update PM memory cpu cpu memory model completely transparent software performance CPUs feature cache hierarchy memory typically volatile deploy PM unlike data reside PM content volatile cache hierarchy lose upon crash cache data PM upon eviction therefore update PM drastically program unless software issue unordered data update PM corrupt application reboots crash software update propagation PM server CPUs extend ISA flush instruction explicitly target cache PM cache persistent memory controller MC acknowledges flush completion intel processor feature clwb instruction purpose remove latency PM critical intel recently MCs PM persistent enhancement allows flush cache attain durability status chip MC clwb message immediately acknowledge MC atomic durability PM aware software ISA extension clwb selective propagation data update PM persistent update however alone flexible software program abstraction transaction instruction atomically exist transaction semantics acid popular instance multiple desirable focus subset acid atomic durability guarantee upon crash transaction update persistent collectively discard exist mechanism atomic durability significantly hamper performance extensive hardware modification introduce practical alternative preserve PM performance propose contributes improve atomic durability performance lad combine concurrency mechanism attain acid transaction implementation detail readily  conventional lock mechanism prior pursue goal performance atomic durability broadly classify category hardware versioning briefly proposal category highlight inherent overhead hardware versioning alleviates underline salient difference propose logless atomic durability kiln relevant prior proposal leverage hardware versioning ahead creates explicit duplicate version data persistent update crash restore data consistent mechanism undo redo data update respectively popular mechanism atomic durability implement software hardware software flush instruction clwb PM data update become persistent  TX instead maintains replica dataset undo remove critical transaction directly apply update replica asynchronously update background hardware technique introduce hardware improve performance instance generate cpu hardware accelerates management creation PM preserve exist MCs truly persistent battery backup flush queue content memory upon failure purpose therefore refer MCs feature persistent distribute logless atomic durability persistent memory micro october columbus usa update proposal offload dedicate hardware altogether incur overhead related creation management software cpu executes potentially significant additional instruction per transaction serialize persistent inplace update undo dynamic transaction address update advance incur multiple explicitly action hurt cpu throughput redo update delayed respect creation guarantee data access PM increase bandwidth demand  utility crash rare rarely recovery simply erase shortly creation non trivial application code introduce programmability burden implement without library primitive hardware versioning explicitly creates version transaction update data enable rollback crash kiln leverage data  inherent multi memory hierarchy obviate associate overhead demonstrates conventional PM assume battery MCs chip component volatile configuration achieve atomic durability serialize writes chip memory incur latency operation tackle challenge kiln brings persistent domain closer cpu replace default SRAM llc persistent memory technology stt ram leverage quickly accessible persistent llc remove altogether transaction update accumulate persistent llc marked speculative transaction update instantaneously commit PM simply clearing speculative marker upon crash reboot persistent llc discard cache speculative overall kiln address shortcoming assumption generally server CPUs llc persistent centralize elaborate limit assumption lad address distribute persistent MCs speculatively buffering update within quickly accessible persistent domain effective approach achieve atomic durability tackle performance programmability overhead inspire persistent MCs server CPUs investigate persistent MC queue similarly stag speculative update atomically durable transaction demonstrate propose lad address challenge manage distribute speculative decision atomically commit transaction PM fundamentally arises presence MCs server MCs distribute socket intel mesh CPUs MCs physically disjoint chip location IMC tile PM PM speculative PM persistent cpu chip legend volatile core baseline chip distribute MC llc MC core core persistent domain stag speculative buffering atomic durability dash persistence boundary amd epyc socket multi chip package comprise chip  MC MC distribution significantly affect atomic commit protocol message cpu core MCs MCs decision unison maintain atomicity crash partial delivery message handle atomic durability fundamentally treat involve chip resource cpu core MCs distribute complication manage distribute artifact MCs stag ubiquitous presence distribute LLCs NUCA server CPUs stag llc per kiln proposal distribute speculative future server adopt persistent NUCA LLCs leverage atomic durability distribute commit protocol finally lad persistent llc performance atomic durability limit persistent domain MCs feature readily available server CPUs sufficient extend persistent domain beyond MCs llc largely unnecessary modification diminish return distribute context prior persist barrier update flush llc PM identify consensus llc distribute author developed distribute consensus protocol synchronize flush across llc slice contrast lad protocol developed achieve atomicity guarantee concept underlie lad propose mechanism atomic persistence similarity hardware transactional memory transactional memory implementation greatly concerned management speculative achieve atomicity context isolation relevance lad mechanism manage distribute speculative atomic decision hardware necessarily frame context transactional memory instance chip hardware implementation distribute protocol resemble phase micro october columbus usa  gupta     commit protocol deployed achieve sequential consistency update coherence atomically commit memory operation improve performance memory multiprocessing although implementation aspect proposal lad goal consensus multiple agent atomic decision protocol operation steady stage difference prior proposal lad mechanism employ achieve atomic durability isolation qualitative difference introduces limitation challenge identify appropriate chip component manage speculative atomically durable MCs preserve atomic durability trait arbitrarily transaction speculative buffer overflow preserve recover atomicity crash failure aspect differentiates lad protocol distribute management atomic decision failure model recovery failure mechanism atomic isolation transaction fails another transaction detect speculative due target domain significant flexibility maintain failure detect conflict transaction abort react eagerly lazily etc context atomic durability failure associate concurrency abrupt failure crash loss introduces protocol failure loss precludes MCs broadcast message hence mechanism maintain resilient persistent consistent failure enables recovery fully consistent normal operation later diverge assumption context choice frequency failure context atomic durability extremely failure concurrency clearly tip optimistic pessimistic mechanism demonstration guideline choice undo fallback mechanism lad overview lad existence chip persistent domain accessible cpu latency MCs stag transaction update speculatively atomically commit PM mechanism replaces achieve atomic durability lad cpu MC controller interact deliver atomically durable transaction DTX refer cpu controller lad controller lad controller manages stage DTX executes cpu interacts MC controller server CPUs feature MCs DTX update across multiple MCs therefore achieve atomic durability coordination lad controller MCs DTX core lad ctrl MC MC PM PM cache hierarchy architecture lad ctrl MC MC flush ack phase commit ack commit phase DTX ack protocol timeline distribute commit protocol speculative lad employ distribute protocol handle distribute speculative guarantee DTX atomic durability detail lad distribute commit protocol lad distribute commit mechanism inspire phase commit PC protocol commonly implement software distribute lad adaptation PC implement hardware handle distribute speculative DTX accumulates MCs execution lad controller collocate per cpu core protocol directly interacts MCs describes concrete lad controller implementation demonstrates protocol phase exchange message DTX phase commit phase cpu executes DTX lad controller flush cpu writes reside cache hierarchy PM address MCs flush update unique identifier comprise thread ID private per thread DTX ID incremented DTX DTX update MC queue marked speculative PM cpu DTX lad controller outstanding flush acknowledge MCs proceed commit phase commit phase lad controller sends commit message DTX identifier MCs MCs acknowledge commit message reception drain DTX correspond update queue PM finally lad controller notifies cpu DTX durability receives commit ack MC MCs physically distribute across chip commit message message reception inherently non atomic crash subset MCs DTX commit message MCs commit message crash commit speculative data persistent memory DTX atomic durability violate inconsistent resolve challenge leverage speculative update guaranteed MCs commit phase crash MCs snapshot queue PM restore upon reboot distribute logless atomic durability persistent memory micro october columbus usa inter MC communication phase MCs consensus regard  commit crash consistent recover MCs receives commit message DTX crash reboot MC notifies MCs DTX correspond update queue PM MC queue content correspond uncommitted  discard speculative buffer overflow lad phase transactional update buffer within MCs persistent queue multiple concurrent  queue become oversubscribed overflow capacity exists hardware atomicity mechanism speculative buffer limited capacity intel RTM limit speculative cache handle overflow abort transaction discard speculative update revert software fallback handler lad handle overflow hardware LogTM MC queue capacity speculative data drain queue speculative data dedicate PM address  proceed eventually commit detail fallback implementation lad creates undo handle overflow undo appeal choice crash rare update likely useful inplace update simplify software remove future memory access redo PM potential update DTX commits update partially overflow DTX simply discard update already PM update remain MC queue PM DTX update finally undo memory friendly buffer activation replace update activation undo entry activation contrast redo involves activation entry later entry apply update failure recovery lad recovers consistent upon reboot sequential MCs exchange information consensus  active failure achieve commit status crash MC commit notification DTX DTX deem commit undo persistent memory chronological entry entry belonging uncommitted DTX entry content restore correspond location persistent memory MC entry writeback queue MC writes entry correspond location persistent memory entry belongs commit update update TX TX concurrency atomic durability software TX TX update atomic durability update concurrency atomically durable structure crash consistent acid transaction DTX discard otherwise detail precise lad recovery mechanism implementation programmability program perspective lad expose software interface atomically durable persistent unmodified volatile code interface simplicity facilitates program crash consistent software  standalone atomic durability combine concurrency mechanism construct acid transaction graphically illustrates structure  acid transaction versus annotate atomically durable annotate interface facilitates conversion code originally volatile memory crash consistent code addition transaction dynamically incur multiple action update advance contrast annotate eschew complication acid transaction express encapsulate durable within concurrency mechanism critical elaborate implication concurrency programmability aspect annotate atomically durable versus durability transactional memory versus grain lock concurrency PM aware library ameliorate complexity associate programmability burden grain however performance overhead stem additional instruction synchronization remains concurrency choice concurrency mechanism orthogonal atomic durability importance requirement isolation atomic durability typically lad seamlessly  pessimistic concurrency mechanism lock preclude abort assume software lad guarantee data persist memory happens software transaction schedule recoverable micro october columbus usa  gupta     recoverable schedule transaction commit transaction depends commit consequently context pessimistic concurrency recoverability achieve transaction lock commit guarantee transaction access update precede transaction transaction already commit update persistent recoverable schedule dependent transaction lad commit transaction guaranteed update MCs transaction access update invariant guarantee persistence memory impose concurrency demonstrate  schedule inconsistent memory lad guarantee happens presence recoverable schedule principle lad couple optimistic concurrency mechanism combination lad transactional memory implementation hardware software program primitive denote concurrency durability requirement TX DTX trivially merge however optimistic concurrency allows mid transaction abort revert speculative data update reside throughout memory hierarchy undo speculative update throughout memory hierarchy entail significant complication beyond lad scope introduce novel mechanism atomic durability assumes couple pessimistic concurrency overall increase update PM aware software tip pessimistic concurrency mechanism abort become expensive relatively volatile software exception therefore PM aware focus pessimistic concurrency mechanism lad implementation describes lad implementation ISA OS extension L1D cache MC modification lad protocol machine fallback mechanism recovery sequence ISA OS extension implement lad controller extension cpu core L1D cache controller core notifies lad controller DTX instruction DTX DTX ISA extension resemble intel RTM convey transaction lad controller assumes cache reception DTX DTX belong DTX instruction core buffer drain notify lad controller thread migration context switch associate DTX update software thread execute DTX OS assigns unique lad thread ID henceforth lad tid thread intend lad lad tid DTX tag data cache controller lad controller DTX DTX ID lad tid cache DTX ack counter L1D cache extension addr data DTX ID lad tid spec DTX cid entry request queue MC extension L1D cache MC extension lad OS kernel thread lad hardware structure maintain status software thread lad tid cap maximum thread concurrently lad limitation mainly affect hardware resource provision trivially relaxed DTX execution disrupt exception interrupt lad controller simply pause incoming writes DTX resume abstraction lad thread enables resume DTX software thread reschedule another core lad controller L1D cache extension lad controller DTX update coordinate distribute commit protocol transfer update stag MCs atomically commit PM illustrates extension data cache lad controller feature DTX structure comprise component lad tid buffer lad tid currently lad thread DTX buffer tracked DTX lad controller machine DTX ID buffer incremented DTX DTX ID private per lad thread DTX ID lad tid uniquely identify DTX update cache DTX bitvector feature per cache indicates correspond cache update DTX currently DTX ack counter buffer outstanding message lad controller flush commits acknowledge MCs KB cache DTX structure lad trivially core multiple hardware context distribute logless atomic durability persistent memory micro october columbus usa DTX ack DTX ack counter commit flush DTX ID flush commits unblock core trigger transition lad transition diagram smt provision structure per hardware context OS scheduler suspends lad thread lad controller DTX bitvector flush marked cache PM DTX ack counter zero DTX DTX ID thread along thread lad tid restore lad controller core thread reschedule enable seamless continuation pending DTX memory controller extension lad relies existence persistent request queue MCs extends additional hardware structure bookkeeping persistent battery illustrates hardware structure entry request queue extend additional DTX ID lad tid speculative identify DTX ID lad thread cache belongs speculative indicates cache normal writeback request belongs ongoing DTX addition request queue MC maintains mapped structure DTX cid instrumental role crash recovery detailed DTX cid vector entry per lad thread lad thread DTX ID commit storage MC standard request queue depth correspond storage overhead per MC impact increase thread lad concurrently hardware overhead logarithmic linear increase lad tid bitwidth DTX cid vector width respectively lad protocol lad cache MC hardware addition deliver atomic durability lad controller core cache controller protocol execution demonstrate lad controller transition diagram action respectively DTX cpu executes DTX instruction cpu stall buffer drain DTX retires lad controller notify DTX lad controller increment DTX ID transition cache correspond DTX bitvector update DTX cache eviction coherence request ack evict service decrement ack counter flush evict service decrement ack counter commit decrement ack counter DTX flush increment ack counter lad controller action cache benefit locality coalesce future update cache flush MCs upon eviction cache controller DTX completion external coherence request DTX stall cpu buffer drain ensure lad controller DTX writes cpu notifies lad controller immediately transition flush flush lad controller DTX bitvector flush marked cache cache incrementing ack counter flush DTX flush cache data DTX ID lad tid llc cache update DTX flush correspond MC flush operation clwb modification coherence protocol MC cache DTX flush persistent request queue queue entry DTX ID lad tid speculative sends ack originate lad controller ack lad controller decrement ack counter ack counter controller transition flush commit flush DTX update transfer MCs persistent queue speculative finally commit lad controller sends DTX commit message commit DTX lad tid DTX ID MCs reception DTX commit MC atomically update DTX cid vector DTX cid lad tid DTX ID speculative entry request queue belonging lad tid DTX ID sends ack message originate lad controller DTX completes ack MC policy particularly beneficial multi socket processor latency remote socket MCs considerably local lad controller flush resident cache update DTX update cache DTX enters flush eviction external coherence message coherence message marked arrives peer cache lad controller flush request cache update llc content llc responds peer cache request theoretically DTX flush subsequent DTX flush cache update peer cache however concurrency mechanism micro october columbus usa  gupta     DTX ST ST ST DTX llc MC llc MC DTX ST ST ST DTX DTX ST ST ST DTX DTX ST ST ST DTX eviction flush ack DTX ST ST ST DTX DTX ST ST ST DTX flush DTX ST ST ST DTX commit DTX ST ST ST DTX commit legend data speculative data persistent data DTX ST ST ST DTX ack ack ack ack lad enforce isolation across  render risk update inversion impossible phase synchronous guarantee DTX flush concurrent  MCs dictate concurrency demonstrates lad operation cpu execute DTX DTX notify lad controller DTX lad controller transition cpu writes cache already cache cpu update lad controller correspond DTX bitvector cpu writes cache conflict trigger eviction cache described flush correspond llc tile MC lad controller increment ack counter correspond DTX bitvector newly cache MC receives flush cache request queue speculative cpu executes DTX notify lad controller transition flush meanwhile MC sends ack cache flush lad controller decrement DTX ack counter lad controller flush marked cache cache correspond MCs llc lad controller increment ack counter flush perform flush correspond DTX bitvector MCs flush request queue marked speculative cpu stall DTX signal durability completion lad controller MC independently acknowledges flush ack lad controller decrement ack counter counter zero lad controller transition commit transition commit phase lad controller sends commit message MCs asynchronously MCs commit message MC speculative cache belonging commit DTX DTX becomes effectively persistent MC acknowledges commit request lad controller receives ack MC transition sends notification cpu DTX instruction retires unblock cpu DTX atomically durable logless distribute manner detailed lad preserve happens update memory concurrency recoverable transaction schedule demonstrates  schedule corrupt persistent memory recoverable schedule guarantee memory update preserve distribute logless atomic durability persistent memory micro october columbus usa persistent DTX lock unlock DTX persistent lock unlock DTX failure DTX  schedule lock persistent unlock lock persistent unlock DTX DTX failure recoverable schedule interplay lad atomically durable concurrency assume initial  schedule transaction exit critical commit lad atomically durable encapsulate within critical failure DTX commit persistent memory failure DTX phase DTX update MCs regardless DTX update discard lad recovery protocol upon reboot memory content recovery inconsistent culprit erroneous concurrency sequence DTX execution lad atomic persistence correctly within critical failure DTX update MCs however DTX commit protocol DTX update MCs discard recovery memory consistent demonstrates lad preserve update properly combine concurrency allows recoverable schedule invariant DTX access update precede DTX DTX update MCs fallback MC queue bound overflow speculative writebacks described lad fallback overflow MC drain request queue PM chronological fifo implement undo dedicate pre allocate OS purpose per MC basis allocation directly manage MCs implementation request queue entry occupy speculative cache undo entry contains cache lad tid DTX ID speculative cache correspond PM PM retrieve undo entry background OS thread periodically reclaims memory undo allocates additional MCs rare MCs depletion interrupt notify OS thread allocate additional prior manage hardware interplay coherence lad coherence protocol modification serf informal proof lad protocol interplay coherence deadlock briefly resource acquire freed lad operation cache llc MCs chip interconnect cache lad cache release immediately upon coherence request ack counter  resource independent coherence remains allocate pending DTX flush acknowledge llc lad reserve resource llc DTX flush update cache llc MC lad reserve entry MC queue DTX advance cache flush MC queue limited capacity pressure entry drain PM PM assume infinite resource lad purpose allocate lad drain MC queue interconnect assume interconnect vcs coherence request leverage vcs lad message request DTX flush DTX commit acks lad message completion upon reception cache llc MC lad message cannot coherence message interconnect failure recovery lad assumes crash content MC queue preserve achieve leverage technology already exists persistence aware MCs intel server sufficiently battery flush queue content memory upon failure approach lad  failure policy slight modification policy implement MCs MC structure lad commit speculative therefore instead drain pending request queue correspond location PM upon failure modify MC differentiates writebacks marked lad normal lad writebacks drain chronological  dedicate KBs PM temporary non volatile recover reboot pending writebacks normally correspond location PM upon reboot pre crash content MCs queue recover reading  content recovery perform restarts OS resume normal operation consistent memory establish DTX cid vector lad thread implementation MCI contains DTX ID commit DTX per lad thread vector  max max MCs micro october columbus usa  gupta     writes DTX description cache  update location transaction  rbt del entry CQ insert delete entry queue PC modify hash SPS random swap array tpcc transaction tpc evaluate benchmark compile MCs  vector summarizes MCs consensus regard core commit DTX failure partial reception DTX commit message DTX MC private undo entry entry lad tid DTX ID DTX ID  lad tid MCs restore correspond location PM undo content  entry belonging commit  directly correspond location PM chronological entry belonging uncommitted discard undo  resume normal operation assume coordinate machine per MC alternatively core bios mode memory perform sequentially MC undergoes another failure recovery recovery restarts anew recovery related operation idempotent undo  preserve recovery completes successfully lad recovery procedure trivially sustain recursive failure methodology application benchmark suite durable transaction prior briefly describes benchmark update cache per DTX datasets benchmark exceed capacity chip cache memory resident rbt operates llc resident dataset focus transaction leverage lad logless fashion demonstrate prior persistence aware software dominate transaction  CQ transaction ratio rbt transaction traverse operation private cache volatile transaction generate traffic memory PC SPS tpcc transaction increase intensity workload execute transaction stress lad therefore extreme application execute operation beside durable transaction architecture assume tile core cpu distribute llc memory address horizontally partition core cortex 2GHz OoO tso dispatch retirement entry rob cache KB L1D KB LI byte MSHRs cycle latency tag data llc interleave NUCA non inclusive MB tile cycle access coherence directory MESI interconnect 2D mesh link cycle hop dram tck tRAS tRCD timing tcas trp lad DTX structure per cache MCs socket overhead entry request queue per MC parameter simulation  volatile persistent model PM  ddr dram representative PM deployment commercial datacenters pin workload core core OS stress lad distribute commit protocol model MCs evaluation socket setup evaluate impact increase latency subset MCs typically occurs beyond socket emulate dual socket MCs inject additional delay response lad relevant hardware logless atomic durability kiln however kiln distribute NUCA llc extend functionality lad distribute commit protocol llc controller MCs optimistically model persistent battery llc stt ram enable persistence without latency penalty volatile SRAM llc configuration lad llc idealize implementation logless atomic durability mechanism evaluate configuration evaluate configuration volatile transaction volatile data configuration ideal performance associate atomic durability lad llc transaction attain durability update data persistent battery llc lad transaction attain durability update data persistent battery MCs default DTX commits lad controller receives ack MC evaluate lad configuration lack optimize commit ack policy lad controller acks SW transaction software atomic durability undo persistent MCs clwb operation simulation evaluate configuration  cycle accurate simulator couple DRAMSim dram simulation summarizes simulation parameter distribute logless atomic durability persistent memory micro october columbus usa  rbt CQ PC SPS tpcc geomean throughput normalize volatile lad llc lad lad SW performance synchronous transaction evaluation atomic durability performance throughput transaction per configuration normalize volatile volatile outperforms  average lad llc transaction cpu transaction update resident data flush persistent llc software strict synchronous durability requirement workload affected differently atomic durability requirement memory access durability workload transaction  frequency cpu software severely degrades throughput workload average tpcc remains unaffected overhead amortize tpcc transaction spectrum CQ intensive workload mlp transaction multiple serialization introduce severely hurt performance lad outperforms software across reduces instruction footprint writes memory demonstrate lad closely performance deliver optimistic lad llc configuration performance gap attribute lad requirement flush MCs llc despite despite magnitude capacity speculative buffering transaction update KB MB lad performs within lad llc average overall effort battery backing llc yield  performance improvement crash consistent software lad persistent MCs latter readily available server CPUs practicality understand performance impact distribute commit protocol version lad DTX commit acks MC commit phase lad socket modest performance degradation avg lad lad demonstrates outcome protocol spends flush commit flush involves data L1D cache MC message minimal socket dual socket lad llc lad lad SW throughput geomean socket  configuration normalize volatile performance ack commit consequence socket core distance MCs almost uniform despite average performance difference lad lad workload  benefit skip ack  spends flush commit lad faster lad summarizes average throughput aforementioned configuration socket dual socket performance gap configuration volatile grows dual socket increase latency synchronous operation introduce mechanism enable atomic durability ack MCs commit phase becomes significant increase performance difference lad lad average  summary lad enables synchronous atomically durable transaction within volatile socket performance kiln mechanism synchronous atomic durability closely emulate lad llc configuration delivers significantly intrusive hardware lad extend L1D cache MCs additional volatile SRAM buffer entire llc nonvolatile finally lad performance directly comparable propose asynchronous durability DudeTM relaxes strict semantics synchronous atomic durability performance gain lad overhead breakdown workload per transaction latency lad spent commit phase unsurprisingly phase overhead commit phase involves flush data cache MCs commit phase involves roundtrip message MCs latency largely insensitive workload variability commit phase latency attribute workload dependent contention interconnect verify hypothesis  thread instance workload indeed fix commit phase latency cycle consequently performance improvement accelerate commit phase proactive flush mechanism potential reduce phase overhead remove cache flush critical ideal proactive flush mechanism accuracy flush cache update within DTX yield micro october columbus usa  gupta     workload commit perf improv phase phase upper bound  rbt CQ PC SPS tpcc lad per transaction latency breakdown cycle upper performance improvement bound ideal flush mechanism marginal performance improvement estimate upper improvement bound replace workload phase latency absolute minimum latency flush MC llc MC return ack latency cycle  phase latency   cache flush critical estimate performance improvement workload displayed phase overhead bandwidth latency bound drastically reduce remain performance margin lad volatile explore asynchronous commit mechanism relaxation strict semantics synchronous atomicity sensitivity MC request queue memory access per transaction average across workload evaluate crash consistent configuration MC queue secondary axis performance normalize volatile MC queue software increase memory access mainly entry flush update increase memory location cpu lad increase memory access cache per transaction memory attain persistence lad llc memory access volatile baseline flush durability purpose absorbed llc memory focus MC queue affect frequency lad fallback mechanism conversely performance commonly model MC queue entry evaluate benchmark suite entry MC queue lad fallback mechanism trigger measurable memory traffic fallback mechanism shrink MC queue fold entry performance queue tpcc CQ fallback introduces memory writebacks baseline queue additional writebacks hurt tpcc CQ performance respectively CQ affected  additional writes bandwidth intensive finally software suffers significantly MC queue pressure memory validate lad delivers atomic lad llc lad SW throughput normalize volatile memory access per transaction writes flush throughput sensitivity memory controller queue durability logless manner despite limited buffering available MCs impact non volatile memory evaluation model PM battery dram observation nonvolatile memory nvm technology nvm spectrum access latency disparity however nvm dram replacement likely faster spectrum therefore evaluation memory access latency representative nvm despite absolute relative performance across configuration marginally shift therefore omit detailed data brevity takeaway regard fallback frequency remain unaffected MC queue remains sufficient nvm workload bottleneck memory bandwidth lad entry MC queue  battery dram conclusion lad logless atomic durability mechanism utilizes data  inherent memory hierarchy leverage persistent MCs already feature server accumulate speculative commit atomically PM lad feature distribute protocol hardware manage speculative reside across chip MCs atomic commit decision enables atomically durable synchronous transaction performance intrusive hardware modification extend persistent domain MCs memory hierarchy hardly justifiable