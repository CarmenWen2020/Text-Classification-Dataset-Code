memory latency limit performance performance core dram latency remain nearly generation dram bandwidth grown significantly due frequency newer architecture ddr LPDDR GDDR 3D stack memory packaging HBM prefetchers extract performance dram bandwidth available prefetchers ability dynamically adapt available bandwidth boost prefetch prefetch coverage headroom exists throttle achieve accuracy bandwidth utilization peak dual spatial prefetcher DSPatch standalone prefetcher lightweight adjunct spatial prefetcher delta signature prefetcher spp DSPatch novel intuitive modulate spatial program access physical anchor trigger access spatial access bias towards coverage another bias towards accuracy dram bandwidth utilization generate prefetches across diverse workload KB storage DSPatch improves performance aggressive baseline PC stride prefetcher cache spp prefetcher cache memory intensive workload moreover performance DSPatch spp increase dram bandwidth spp dram bandwidth CCS CONCEPTS computer organization processor memory architecture keywords data prefetching microarchitecture memory latency introduction memory latency limit performance performance core prefetching approach mitigate performance impact memory latency primary metric improve performance prefetchers coverage program load memory remove prefetcher odds coverage important prefetcher accuracy issue prefetches actually program load inaccurate prefetches pollute cache excessive pressure memory bandwidth increase latency response memory dram latency remain nearly decade dram bandwidth grown significantly dram core frequency dram architecture ddr LPDDR GDDR boost memory bandwidth memory interface width newer 3D stack memory package enable bandwidth increase memory interface width dram bandwidth headroom available negative impact due inaccurate prefetches dram bandwidth multiple core prior across mobile client server available memory bandwidth heavily utilized latency bottleneck bandwidth active thread thread memory sensitive memory parallelism program fully utilize memory bandwidth demonstrate prefetchers signature prefetcher spp offset prefetcher bop spatial memory SMS performance increase peak dram bandwidth prefetching technique evolve critical dram bandwidth resource budget available specifically prefetchers posse ability dynamically adapt available dram bandwidth boost prediction coverage headroom exists throttle achieve accuracy bandwidth utilization peak prefetching speculation mechanism predict future address access program address access various address offset spatial typically KB address delta access address access representation expose boost prefetch coverage performance address access readily apparent global accumulative access visible BW reflect increase memory bandwidth confuse performance trend evaluation methodology workload described micro october columbus usa   peak dram bandwidth gbps performance delta baseline peak dram bandwidth gbps bop SMS spp BW prefetcher performance dram bandwidth correspond dual channel ddr restrict delta recent consecutive access illustrates multiple access within spatial representation various format access trigger access access trigger offset spatial offset temporal variation typically artifact reorder due schedule core cache memory sub longer access sequence probability variation access representation successive address delta access realize actually spatial access trigger offset delta representation representation BP crucially anchor trigger offset rotate access anchor anchor essentially delta delta consecutive access local delta delta relative trigger access global delta multiple address access memory spatial bitpattern anchor respective trigger access anchor spatial boost coverage ability adapt prefetch coverage available resource dram bandwidth multiple access spatial anchor exactly propose novel intuitive approach simultaneously optimize coverage accuracy bias towards coverage another towards accuracy bitwise operation recently anchor memory resultant coverage bias modulates resultant coverage similarly bitwise operation recently anchor memory subtracts away resultant accuracy bias modulates resultant accuracy multiple address memory anchor modulate coverage bias bitpattern accuracy bias dynamic modulation enables simultaneous optimization coverage accuracy metric odds available memory bandwidth headroom couple quantify accuracy coverage modulate dynamically illustration modulate DSPatch advantage dual spatial prefetcher DSPatch lightweight spatial prefetcher standalone prefetcher adjunct spatial prefetcher theart delta signature prefetcher spp DSPatch intuitive logical operation modulate spatial representation access memory physical bias towards coverage bias towards accuracy DSPatch employ effective coverage accuracy characteristic modulate bitpattern overall dram bandwidth utilization information DSPatch dynamically selects bitpattern generate prefetches dram bandwidth utilization DSPatch selects accuracy bias prefetching dram bandwidth utilization DSPatch selects coverage bias accuracy accuracy bias otherwise contribution DSPatch dual spatial prefetcher micro october columbus usa peak dram bandwidth newer dram architecture package ofthe prefetcher performance dram bandwidth spatial representation anchor around trigger access effectively capture delta local global trigger transformation expose otherwise obfuscate due memory access reorder processor memory subsystem introduce prefetching algorithm learns modulate prefetch memory logical operation bitpattern bias towards coverage bias towards accuracy propose dram bandwidth utilization coverage accuracy modulate enables effective dynamic selection generate prefetch candidate across diverse workload KB storage DSPatch improves performance aggressive baseline employ PC stride prefetcher cache spp cache memory intensive workload standalone prefetcher DSPatch slightly performance spp storage requirement spp spp DSPatch combine benefit theart grain delta prefetching prefetching simultaneously optimize coverage accuracy increase coverage DSPatch increase mispredictions finally performance DSPatch spp increase memory bandwidth spp dram bandwidth background motivation prefetching speculation technique predicts address latency access program brings associate data latency cache program  access typically dram memory stall retirement instruction core reduce ahead instruction parallelism ILP extraction buffer rob due memory access related stall prevents allocation independent instruction processor structure multiple mechanism address access program address access via various address offset spatial typically KB address delta consecutive access identify prefetchers typically examine subset memory access filter program context PC stride prefetcher constant stride consecutive cacheline address reference program counter PC PC program context filter access easily discover access program context filter access signature signature construct memory access information program physical address offset delta consecutive access potentially augment program information PC prefetchers typically program address access correlate signature predict learnt signature choice prefetcher signature address access representation determines effectiveness optimize metric prefetching coverage latency memory access program prefetcher timeliness latency latency access hidden prefetcher accuracy prefetched address later program storage hardware storage requirement prefetcher comprehensively examine prefetchers spp bop SMS respect choice signature address access representation analyze workload performance identify merit prefetching finally prefetchers wherever evaluate potential dynamic bandwidth aware tune opportunity coverage prefetcher scalability presence memory bandwidth headroom signature prefetcher spp spp delta prefetcher signature comprise solely recent consecutive address delta local delta KB signature delta prefetch candidate along confidence associate candidate allows spp complex address delta spp recursive ahead mechanism boost prefetch distance timeliness spp appends prefetch candidate delta recursively candidate delta signature generate prefetch candidate confidence prefetch candidate cascade confidence candidate candidate confidence prefetch delta candidate cascade confidence threshold trigger prefetch advantage delta prefetcher access participate generate prefetches effectively allows multiple bite coverage boost performance storage requirement cascade confidence spp grain coverage timeliness accuracy spp outperforms bop SMS workload category average describes evaluation methodology workload micro october columbus usa   client server hpc FSPEC ISPEC FSPEC ISPEC sysmark geomean performance delta baseline bop SMS spp performance bop SMS spp prefetchers baseline PC stride prefetcher channel ddr however scenario spp loses coverage timeliness sparse highly irregular access spp cannot delta lose coverage delta confidence limit recursive prefetch distance hence timeliness due shortcoming spp performs prefetchers ISPEC sysmark workload category bandwidth aware tune opportunity spp static confidence threshold prefetching candidate delta dynamic scheme monitor available dram bandwidth headroom modulate threshold dram bandwidth utilization evaluate enhance version spp  ability confidence threshold dram bandwidth utilized  performance memory bandwidth offset prefetcher bop bop delta prefetcher aim optimal global delta access within memory KB program series successive local delta bop identifies global delta multiple effective representation address access program bop utilizes appropriate global delta achieve timeliness multiple unlike spp construct local access bop construct global access bop global expose memory restrict local consecutive access bop predict future access workload irregular access access per global robust program access reorder disrupt restrict local access bop prefetch performance prefetchers ISPEC workload category however bop learns limited global delta access program statically define epoch define access severely limit bop coverage timeliness hpc server workload category bandwidth aware tune opportunity bop proposal limited global delta KB delta exist statically scheme monitoring available bandwidth headroom global delta per epoch prefetch evaluate enhance bandwidth aware version bop  adapt dram bandwidth headroom  default prefetch dynamically increase bandwidth headroom respectively neither bop  performance improvement additional memory bandwidth bop prediction suffer accuracy bop program context information signature generate prefetches limit prefetch hurt bop coverage spatial memory SMS SMS address access within spatial KB KB spatial address access signature comprise trigger access PC trigger offset trigger access define access structure recently access SMS effectively exploit spatial correlation access PC access representation inherently capture global access conjunction trigger PC signature SMS performs spp ISPEC sysmark workload category however SMS static decision negatively affect overall performance available workload statically decides KB KB accuracy thereby limit prefetch distance timeliness opportunity spp bop explicit mechanism accuracy SMS relies access filter sophisticated signature PC offset therefore increase overall coverage SMS relies signature increase storage requirement KB reduce entry correlation signature SMS baseline entry associative KB storage entry KB storage approximately SMS average performance improvement across evaluate workload furthermore SMS opportunity dynamically tune performance increase dram bandwidth performance delta baseline SMS entry performance impact reduce SMS storage entry KB entry KB average across workload DSPatch dual spatial prefetcher micro october columbus usa cache pollution inaccurate prefetches pollution cache evict useful cache impact pollution mitigate via prediction prefetch aware replacement insertion policy multiple generation cache replacement policy specifically target identify replace significant pollution impact inaccurate prefetches pressure memory bandwidth resource primary negative impact inaccurate prefetches stateof prefetchers examine performance prefetchers memory bandwidth performance improvement prefetcher increase memory bandwidth conclusion performance improvement none prefetchers increase memory bandwidth benefit prefetcher saturates memory bandwidth increase rate increase performance improvement increase memory bandwidth SMS performance improvement SMS spp memory bandwidth benefit spatial prefetching presence memory bandwidth  enjoys performance memory bandwidth due dynamic modulation prefetch however lack program context information limited prefetching constrains  coverage leaf significant performance peak dram bandwidth gbps performance delta baseline peak dram bandwidth gbps bop SMS spp   BW none prefetchers examine   performance dram bandwidth takeaway goal summary analysis prefetchers takeaway none prefetchers examine performance dram bandwidth available SMS inherently lack ability available memory bandwidth algorithm tune prefetch aggressiveness spp bop bandwidth aware appendix detail poorly performance   spatial representation anchor around trigger access memory effectively capture delta local delta consecutive access global delta respect trigger access representation expose otherwise obfuscate reorder processor memory subsystem operation recently access memory modulate bias towards coverage bias towards accuracy dynamically appropriate generate prefetches increase prefetch coverage memory bandwidth utilization increase prefetch accuracy memory bandwidth utilization goal spatial prefetcher integrates memory bandwidth inherently algorithm dynamically adjust notion aggressiveness performance improvement memory bandwidth dual spatial prefetcher DSPatch dual modulate spatial introduce earlier simultaneously optimize prefetch coverage accuracy memory bandwidth utilization dual spatial prefetcher dual spatial prefetcher DSPatch spatial prefetcher learns per memory physical associate program counter PC signature  bias towards coverage calculate recently spatial program access physical operation learnt grows coverage threshold AccP bias towards accuracy calculate  CovP currently program access physical operation reduces maximize accuracy AccP derive CovP coverage DSPatch mainly comprises hardware structure buffer PB signature spt purpose PB spatial program access physical purpose spt modulate spatial CovP  derive previously associate trigger PC DSPatch observes program access per physical learns overall program access agnostic associate spatial trigger PC signature spt trigger PC physical access retrieve modulate CovP AccP goal DSPatch dynamically adapt prefetching coverage accuracy dram bandwidth utilization bandwidth utilization signal broadcast memory controller micro october columbus usa   core DSPatch selects CovP memory bandwidth utilization AccP memory bandwidth utilization prefetching DSPatch discus DSPatch overall bandwidth utilization across core subsequent algorithm modulate predict spatial overview depicts overall architecture DSPatch buffer PB signature prediction spt program access BW utilization CovP AccP DSPatch diagram overall organization buffer PB signature prediction spt prime structure DSPatch PB entry access KB physical accumulates access KB KB physical eligible trigger prefetches PC trigger access PB entry index spt retrieves CovP AccP goodness selection logic detailed memory bandwidth utilization generate prefetch candidate anchor rotate align trigger access offset issue prefetches eviction PB trigger per KB anchor rotate trigger offset spt trigger PC counter update described bandwidth utilization DSPatch memory bandwidth utilization counter memory controller issue dram access CAS command tRC cycle tRC minimum dram activation hysteresis counter halve channel width channel determines peak dram bandwidth peak CAS command tRC bucket counter quartile dram access command content dram indicates data transfer dram chip hence directly capture dram data bus activity detail dram operation refer reader prior peak bandwidth tRC cycle counter quartile threshold quantize quartile bandwidth utilization indicates bandwidth utilization whereas indicates bandwidth utilization quantize bandwidth utilization broadcast core representative memory bandwidth utilization DSPatch algorithm anchor spatial maximize possibility expose data access DSPatch program access representation robust reorder access processor memory hierarchy motivates spatial anchor trigger access memory capture local global delta trigger DSPatch anchor  predict program address access memory implementation DSPatch employ buffer PB recently access KB physical cache PB entry bitpattern accumulates cache address reference program load choice signature signature mapping choice signature significant impact prefetcher information signature encodes prefetch filter achieve hence accuracy prior prefetchers PC trigger access along offset actual address implicitly prediction accuracy hence per signature without explicitly accuracy however extra storage prefetcher frequently signature achieve coverage DSPatch PC trigger access physical signature learns modulate recently access physical associate PC signature signature spt upon encounter signature DSPatch spt selects generate prefetch candidate associate signature DSPatch organizes spt entry tagless mapped structure fold xor hash PC index structure index reduce storage requirement associate offs accuracy coverage PC program signature accuracy aliasing multiple PCs entry unpredictable impact therefore DSPatch mechanism bitwise popcount operation coverage accuracy crucially DSPatch modulate bias towards coverage operation bias towards accuracy operation allows DSPatch simultaneously optimize coverage accuracy component DSPatch subsequent DSPatch dual spatial prefetcher micro october columbus usa quantify accuracy coverage depicts scheme quantify accuracy coverage prediction physical popcount predict prefetch cpr whereas popcount access generate program program access eal similarly popcount bitwise operation program predict accurate prefetch cacc prediction accuracy compute ratio cacc cpr whereas prediction coverage compute cacc eal instead compute fractional quantize accuracy coverage quartile via shift operation popcount program predict bitwise prediction accuracy prediction coverage prediction accuracy coverage bitwise popcount operation modulate dual coverage bias accuracy bias crucial goal DSPatch ability simultaneously optimize prefetch coverage accuracy memory bandwidth utilization DSPatch modulate per spt entry bias towards coverage CovP bias towards accuracy AccP modulate spatial simultaneously optimize coverage accuracy coverage bias CovP anchor bitpattern effectively capture delta trigger access delta increase prediction coverage appropriate quartile compute shift denominator numerator quartile compute difference denominator numerator difference denominator shift achieve via bitwise operation predict bitpattern program however ORS eventually limit update operation DSPatch saturate counter  CovP operation  incremented operation predict DSPatch employ saturate counter  quantify goodness CovP  incremented CovP prediction accuracy threshold  prefetch coverage CovP threshold  saturate  essentially indicates prefetching CovP lack prefetch accuracy prefetch coverage hence CovP  scratch DSPatch reset CovP program  saturate satisfied memory bandwidth utilization quartile prefetch coverage quartile threshold   accuracy bias AccP accuracy bias bitpattern retain recur achieve operation recursive operation AccP update AccP replace bitwise operation program CovP  DSPatch saturate counter  quantify goodness AccP  incremented AccP prediction accuracy decremented otherwise saturate  counter essentially indicates prefetching AccP lack prefetch accuracy DSPatch  completely throttle prediction memory bandwidth utilization selection prefetch generation algorithm DSPatch CovP AccP prefetch generation dram bandwidth utilization quartile AccP prefetching  saturate bandwidth utilization quartile AccP prefetching  saturate CovP inaccurate CovP otherwise bandwidth utilization simply CovP prefetching minimize pollution bandwidth utilization prefetched priority cache llc  saturate CovP inaccurate KB KB prediction multiple trigger prior prefetching proposal explicitly accuracy hence statically limit KB DSPatch incorporates accuracy throttle prediction dynamically prediction KB KB memory instead CovP AccP split   counter micro october columbus usa   BW utilization prefetch AccP prefetches BW utilization  saturate prefetch CovP  saturate selection CovP versus AccP prefetching dram bandwidth utilization goodness prediction KB prefetch generation per KB KB splitting enables benefit DSPatch prefetch trigger per KB per KB trigger access KB KB attempt trigger prefetches trigger KB predict KB trigger KB predict KB relative trigger compress reduce storage requirement DSPatch optimization reduce storage overhead delta frequently delta program delta average therefore instead cacheline compress bitpattern adjacent cachelines compression technique granularity compression resultant compress granularity granularity compression DSPatch storage requirement compression technique theoretically inaccuracy prediction misprediction cacheline prediction inaccuracy distribution misprediction rate granularity compression across evaluate thread workload  compression incurs mispredictions across workload granularity compression consume storage misprediction rate granularity compression storage requirement DSPatch KB storage configuration evaluate methodology evaluate DSPatch cycle accurate simulator model dynamically schedule core clocked ghz delta delta occurrence distribution distribution misprediction rate due granularity compression exactly exactly frequently delta across workload granularity compression induces mispredictions structure entry entry PB PC offset spt CovP    AccP  eacc KB DSPatch storage overhead core micro architectural parameter intel skylake processor thread ST simulation MB llc ddr channel multi programmed MP simulation MB llc across core ddr channel therefore ST MP configuration llc capacity per core MP configuration memory bandwidth per core  ST  core core OoO entry rob entry load buffer cache private KB lru MSHRs cycle latency cache private KB lru MSHRs cycle latency llc ST MB MP MB prefetch aware predictor MSHRs per llc cycle latency memory ST channel MP dual channel ddr mhz rank channel rank data bus width per channel KB buffer tcl tRCD trp tRAS L1D prefetch PC stride prefetcher PCs simulation parameter prefetchers baseline configuration PC stride prefetcher cache evaluate prior prefetching proposal SMS bop spp DSPatch prefetcher prefetcher demand prefetch prefetched cache llc tune prefetcher individually simulation environment prefetcher configuration evaluate  prefetcher performs prefetchers thread simulation DSPatch dual spatial prefetcher micro october columbus usa bop entry RR    ST MT KB SMS KB entry entry FT entry PHT KB spp entry ST entry PT entry  compress delta feedback KB parameter evaluate prefetcher workload evaluate diverse workload benchmark spec cpu spec cpu suite workload span various application categorize workload along workload average performance geometric performance across workload workload client zip compression decompression encode decode server tpc specjbb  spark pagerank hpc linpack NAS parallel benchmark parsec spec accel spec mpi FSPEC benchmark sphinx soplex gemsfdtd ISPEC benchmark gcc mcf omnetpp FSPEC benchmark namd povray lbm ISPEC benchmark omnetpp xalancbmk leela  cassandra hadoop hbase kmeans sysmark sysmark excel photoshop  evaluate workload category homogeneous heterogeneous workload simulate multi programmed construct homogeneous workload MPKI workload workload core simulator construct heterogeneous workload randomly workload MPKI workload generate heterogeneous workload evaluation thread performance performance comparison prior prefetchers DSPatch standalone prefetcher adjunct prefetcher spp observation standalone prefetcher DSPatch outperforms SMS client server hpc FSPEC ISPEC FSPEC ISPEC sysmark geomean performance delta baseline bop SMS spp DSPatch DSPatch spp thread performance average across workload storage requirement SMS dual modulate multiple trigger DSPatch outperform workload MPKI llc MPKI traditional prefetching employ SMS DSPatch performs spp average storage spp DSPatch gain spp mainly sysmark ISPEC workload category workload category showcase benefit grain delta prefetching paradigm employ spp combination grain delta prefetching spp dual modulate spatial prefetching DSPatch achieves performance improvement standalone spp average outperform standalone prefetcher workload category clearly DSPatch lightweight adjunct prefetcher spp extract benefit prefetching paradigm performance graph memory intensive thread workload average combine DSPatch spp prefetcher outperforms standalone spp DSPatch spp performs SMS tpc workload code footprint trigger PCs per kilo instruction SMS benefit signature storage capability entry DSPatch spp outperforms standalone spp NPB  sysmark excel mcf ISPEC workload performance delta baseline workload SMS spp DSPatch spp gcc mcf NPB  tpc sysmark excel performance graph memory intensive thread workload performance bop entry SMS iso storage DSPatch adjunct prefetchers spp observation adjunct prefetcher client server hpc FSPEC ISPEC FSPEC ISPEC sysmark geomean performance delta baseline spp bop spp SMS iso storage spp DSPatch spp performance bop entry SMS DSPatch adjunct prefetchers spp spp DSPatch performance bop SMS storage requirement DSPatch spp outperforms bop spp mainly DSPatch spp prefetch coverage bop spp micro october columbus usa   comprehensiveness evaluate DSPatch conjunction spp bop DSPatch improves average performance spp bop combination prefetcher average clearly indicates non overlap coverage opportunity bop DSPatch encourage optimization research direction performance memory bandwidth performance improvement prefetchers dram bandwidth channel ddr  bandwidth dual channel ddr gbps bandwidth performance delta baseline peak dram bandwidth gbps bop SMS spp  spp DSPatch spp performance dram bandwidth takeaway emerge data performance DSPatch spp increase memory bandwidth spp memory bandwidth channel ddr dual channel ddr adjunct prefetcher spp performance gap  spp DSPatch spp increase increase memory bandwidth headroom channel ddr dual channel ddr conclude DSPatch via fundamental choice extract performance memory bandwidth impact coverage accuracy quantifies coverage misprediction rate evaluate prefetchers average DSPatch spp coverage standalone spp prefetcher increase rate mispredictions DSPatch dual modulate simultaneously optimize coverage accuracy achieve ratio impact coverage accuracy increase coverage increase mispredictions multi programmed performance multiple core compete dram bandwidth resource reduces headroom prefetchers boost coverage performance accuracy bias DSPatch crucial role scenario generate highly accurate prefetches scarce dram bandwidth performance improvement prefetchers homogeneous workload observation adjunct prefetcher spp DSPatch improves performance standalone spp SMS outperforms standalone spp sysmark workload category DSPatch spp outperforms SMS workload category client server hpc FSPEC FSPEC ISPEC ISPEC sysmark geomean performance delta baseline bop SMS spp DSPatch spp multi programmed performance across homogeneous workload performance improvement prefetchers homogeneous heterogeneous workload dram bandwidth configuration dual channel ddr mhz mhz observation baseline ddr channel DSPatch improves average performance standalone spp across bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp bop SMS spp DSPatch spp client server hpc FSPEC ISPEC FSPEC ISPEC sysmark avg access uncovered mispredicted coverage mispredictions prefetchers DSPatch dual spatial prefetcher micro october columbus usa heterogeneous increase dram channel frequency mhz mhz increase performance DSPatch spp outperforms standalone spp conclude DSPatch maintains ability performance available memory bandwidth memory bandwidth scarce resource homogeneous heterogeneous homogeneous heterogeneous ddr ddr performance delta baseline bop SMS spp DSPatch spp performance improvement prefetchers homogeneous heterogeneous multi programmed workload dram bandwidth contribution accuracy bias performance impact contribution  prediction DSPatch DSPatch  highly accurate prediction memory bandwidth utilization peak blown DSPatch performance improvement along configuration DSPatch  prediction DSPatch configuration  CovP prediction dram bandwidth utilization another DSPatch configuration  dynamically throttle CovP restrict aggressiveness dram bandwidth utilization observation CovP prediction irrespective memory bandwidth utilization significantly hurt performance  loses performance blown DSPatch throttle CovP prediction dram bandwidth utilization scenario alone  loses performance blown DSPatch conclude statically sub optimal performance modulate enable dynamic selection appropriate DSPatch   performance delta baseline performance improvement blown DSPatch versus DSPatch variant accuracy bias axis related prefetching extensively approach hide memory latency decade algorithm implementation knowledge spatial  driven dynamic selection achieve scalability performance memory bandwidth prefetching category pre computation temporal non temporal prefetchers DSPatch category prior  mechanism highlight DSPatch fundamentally differs pre computation prefetchers flavor prefetching relies pre computation hide latency runahead execution helper thread prefetching proposal pre computation proposal highly accurate ability coverage exist address access however pre computation prefetchers complexity hardware prefetchers capture access DSPatch traditional prefetching proposal differs completely pre computation prefetchers predicts future access access temporal prefetchers temporal prefetchers  isb domino prefetcher built markov prefetching model temporal cache address access address delta cacheline offset spatial cacheline address accurate multi megabyte storage requirement necessitates meta data memory DSPatch KB easily inside core non temporal prefetchers prefetchers predict delta spatial KB KB significantly storage requirement generally complexity pre computation temporal prefetchers stride prefetchers capture delta recently prefetching proposal capture complex delta series delta emerge categorize prefetchers delta prefetchers delta prefetchers VLDP spp address delta inspire tage predictor predict future delta evaluate spp prefetch confidence recursively prefetch ahead improve timeliness bop global delta capture series delta already comprehensively DSPatch spp bop proposal another prior proposal PC prefetching cache replacement policy aware however prefetching component   identical spp evaluation prefetching component  significant improvement spp prefetchers prefetchers exemplify SMS PC signature predict prefetchers storage requirement KB delta micro october columbus usa   prefetchers rotate eliminate cacheline offset spatial KB signature reduce storage requirement around KB DSPatch reduces storage compress instead cacheline recent bingo extends prefetching inspire tage predictor addition offset along PC signature terminology bingo signature utilize cacheline address bingo fuse signature prediction enable multiple prediction entry coverage SMS however bingo consumes KB DSPatch significantly simplifies bitpattern prefetching mere KB storage anchor along mechanism boost coverage accuracy performance DSPatch choice fundamentally enable performance memory bandwidth prefetch throttle mechanism prefetcher throttle mechanism crucial role aggressive prefetcher multiple prior proposal prefetching metric coverage accuracy bandwidth consumption consideration selectively throttle prefetch request attempt reduce prefetcher induced pollution cache capacity available memory bandwidth DSPatch inherently mechanism prefetch accuracy coverage along ability performance increase memory bandwidth prior prefetch throttle proposal orthogonally apply DSPatch adjust prefetch aggressiveness summary introduce DSPatch spatial prefetcher memory bandwidth utilization inherently algorithm adjust prefetch aggressiveness performance improvement increase memory bandwidth DSPatch exploit learns spatial generate prefetches memory physical logical operation bias towards coverage bias towards accuracy DSPatch dynamically selects generate prefetches memory bandwidth utilization coverage accuracy unison DSPatch achieve performance increase memory bandwidth prefetchers evaluation KB hardware storage DSPatch improves performance average across thread workload aggressive baseline PC stride prefetcher cache spp prefetcher cache DSPatch performance improvement grows dram bandwidth memory bandwidth increase improvement dram architecture packaging generation processor significantly benefit DSPatch ability extract performance presence memory bandwidth