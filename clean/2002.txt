computational genomics proven potential precise customize health however adoption generation sequence  technology dna alignment crucial computational genomics become challenge due boom bio data consequently various hardware approach explore accelerate dna core consume dna alignment previous hardware approach leverage multi core gpu fpga accelerate dna however dna bound memory hardware approach focus computation data processing ndp dna unfortunately exist ndp accelerator dna challenge grain random memory access scalability demand boom bio data address challenge propose practical efficient dual inline memory module DIMM ndp accelerator dna algorithm medal shelf dram component database within dram rank propose intra rank algorithm specific address mapping bandwidth aware data mapping individual chip ICS address challenge grain random memory access improve parallelism bandwidth utilization furthermore tackle challenge scalability database propose inter rank polling communication interrupt communication non volatile DIMM nvdimm addition propose algorithm specific data compression technique reduce memory footprint introduce data mapping reduce communication overhead experimental propose average medal achieve speedup reduction thread cpu baseline ndp accelerator respectively introduction dna bottleneck stage computational genomics drawn tremendous attention computational genomics develop rapidly motivate potential adoption precise customize medical physician drug treatment suitable specific pathology cancer throughput efficiency generation sequence  technology bio data boom severe stress genomics analysis due data shorter budget dna alignment aligns dna subsequence reference genome commonly core consume genomics analysis dna alignment contains consume dna extension dna generates reference genome extension extends longer gap dna extension equally dominate compute dna alignment worth accelerate importance dna motivates plenty research accelerate various compute centric hardware approach multi core gpu fpga explore accelerate dna however innovation focus computation limited improvement dna memory bound dna introduces amount random data movement bottleneck performance data processing ndp architecture emerges acceleration dna address issue data movement architecture integrates computation memory closely embrace internal memory bandwidth reduce overhead data movement MPU  accelerates dna RISC core logic HMC chameleon aim practical leverage dual inline memory module DIMM accelerator shelf commodity dram component however exist ndp accelerator dna challenge challenge grain random memory access randomness stress memory bandwidth due channel conflict granularity bandwidth utilization bwa mem widely software dna alignment micro october columbus usa  byte data useful average byte cacheline memory access addition inter task divergence memory access application efficiently simd hardware previous chameleon purpose simd ndp accelerator fails tackle challenge grain random memory access suboptimal performance dna communication mechanism challenge demand scalability due explode dna data biological data exponentially data genome shotgun  project national biotechnology information ncbi approximately  project contains trillion rapidly increase data demand scalability previous aim proposes accelerate dna dram link customize fpga accelerator dedicate data bus DIMMs however rank parallelism within aim aim access memory coarse granularity byte potential memory bandwidth fully utilized chameleon bandwidth utilization ratio although leverage rank parallelism purpose simply due inter task divergence dna chameleon simd style processing goal ndp accelerator dna grain memory accessibility bandwidth utilization scalability propose accelerator medal DIMM dram component standard data bus medal highlight practicability shelf dram component standard ddr protocol medal leverage rank grain chip memory bandwidth within rank propose technique address challenge grain random memory access improve parallelism bandwidth utilization propose advantage depth characterization target dna algorithm technique algorithm specific address mapping continuous data dram chip improve locality potential chip parallelism grain memory access reduces communication instead interleave data across multiple chip technique bandwidth aware data mapping duplicate remaps data across available chip fully utilizes potential memory bandwidth technique individual chip selection ICS leverage chip selection CS signal chip parallelism grain memory access improve bandwidth efficiency across rank index data cannot rank propose option address multi rank issue explode data challenge propose highlight practicability leverage cpu polling inter rank communication option interrupt occupy host memory bus polling operation reserve future  pin ddr trigger  alternatively introduces nvdimm dna index within dense non volatile memory nvm reduce eliminate inter rank communication addition propose algorithm specific data compression technique reduce memory footprint introduce data mapping utilize reduce communication overhead specific contribution propose practical efficient ndp accelerator architecture medal dna shelf dram component intra rank propose application specific technique algorithm specific address mapping bandwidth aware data mapping ICS address challenge grain random memory access improve parallelism bandwidth utilization inter rank propose alternative approach polling communication interrupt communication nvdimm overcome challenge data addition propose algorithm specific data compression technique reduce memory footprint introduce data mapping utilize reduce communication overhead performance improvement experimental evaluation medal performance efficiency thread cpu baseline ndp accelerator respectively background introduces dna algorithm buffer DIMM rotation CT  reference sequence     AG tac  AC    sort rotation      AC  tac AG 4G SR CT  sort BR  data structure FM index dna dna algorithm dna refers sequence fragment  reference genome dna algorithm usually pre index reference genome speedup FM index hash index mainstream index dna  algorithm preferable combination extension approach FM index algorithm performance local alignment blast extension hash index algorithm FM index algorithm suffers irregular memory access longer data reuse distance hence challenge therefore target accelerate FM index medal scalable DIMM data processing accelerator dna algorithm micro october columbus usa algorithm generality compatible hash index algorithm evaluate FM index algorithm contains offline preprocessing index building online preprocessing data reference genome calculate prepared BR len burrow wheeler transform BR SR len array SA sort rotation sort CR accumulative array index appearance sort BR len occurrence array occurrence nucleotide BR reference sequence  algorithm terminates reference sequence unique rotation generate rotation sort alphabet entry sort rotation BR len SR len derive finally BR len sort BR len len CR generate algorithm FM index algorithm input query sequence reference genome len output location preprocess derive BR len SR len CR len      CT OT   CT OT    location SR return location algorithm extends nucleotide iteration reading CR algorithm  upper index sequence prefix SD SR contains occurrence prefix SD buffer dual inline memory module dual inline memory module DIMM widely memory package data DQ pin DIMM multiple dram chip rank rank package DIMM load reduce DIMM LRDIMM introduce address signal integrity issue frequency memory interface component LRDIMM memory buffer MB enhances DQ signal MB register driver rcd per DIMM buffer signal data buffer DB dram chip improve signal integrity DQ signal  CHALLENGES justify selection target application dna dna dominates  dna alignment bwa mem widely dna alignment contains dna extension previous dna consume dna alignment runtime whereas extension furthermore evaluation scenario metagenomics align sequence unknown specie reference database dna runtime presence extension due rate extension compute bound extensively ASIC gpu fpga speedup cpu baseline advanced accelerator extension already developed memory bound dna becomes outstanding bottleneck core  int icache dcache dram core cache dram instrs int load load instruction cpi stack mem mem mem dram core cache dram profile dna bwa mem sniper configuration cpi stack instruction statistic breakdown memory bottleneck dna motivate adopt ndp architecture profile quantitatively bottleneck dram access account cpi stack analysis load instruction instruction breakdown consumption consume dram ndp architecture dna application motivate challenge execution longer execution distribution elemental task bwt  atomic function parallel dna challenge grain randomness divergence challenge memory bandwidth utilization workload imbalance simd architecture memory access FM index dna random finegrained profile cache llc rate micro october columbus usa  elemental task average peak rate granularity memory access due actual data iteration integer fetch memory challenge grain random memory access inevitable demand memory bandwidth bandwidth utilization memory access average cacheline actually furthermore behavior individual task divergent profile majority elemental task difference task longer billion sequence moore bio bio data  data moore reduction sequence boom bio data challenge data bio data faster growth moore sequence genome reduces faster moore database specie become practical affordable bio data grows exponentially data growth faster moore currently gpu genome genome library   super linear challenge data demand capacity dram node limited communication overhead non uniform memory access numa remote memory access RDMA stress memory addition profile performance degrades average memory latency medal architecture introduce medal architecture overview architecture technique intra inter rank scenario architecture overview goal medal leverage ndp architecture exploit extra bandwidth dna remain practical shelf host processor dram component medal exploit extra bandwidth parallelism inside per channel DIMM memory conduct modification DIMM circuit pcb simultaneously activates dram rank assume typical memory conventional rank channel access parallel medal exploit bandwidth coverage reference library genome tesla gpu ndp previous exploit DIMM parallelism instead rank parallelism medal exploit bandwidth furthermore medal leverage chip parallelism within rank via decouple CS signal specifically medal built modify commercial LRDIMM component DB accelerator attach dna specific hardware accelerator DB LRDIMM DB accelerator input output data fifo inter chip hierarchical data bus sends accelerator ID request fifo connects inter chip hierarchical ID address bus perform task described algorithm accelerator contains register query sequence register file CR data reorganization calculate data structure unsigned adder update  address translation convert virtual address dram device address detail DB multiplexer multiplexer output DB addition data ddr bus DB data inter chip hierarchical data bus DB fifo multiplexer dedicate enable signal rcd MC rcd memory controller MC DB accelerator creates challenge host accelerator access dram host aware request issue accelerator request conflict coordinate philosophy enable rcd coordinate memory request rcd information memory request host accelerator modify rcd LRDIMM rcd MC propose host prioritize request schedule detail address issue rcd serf enhancement module signal medal modification component signal host detour rcd MC dram component MC merges schedule request host DB accelerator request queue schedule scheduler prioritize hostside request host MC aware accelerator request host memory access expectation host detail accelerator request applies  scheme scheduler dram timing constraint met controller generate enable signal controller generate dedicate CS signal DB accord timing information MC scheduler instead global CS bus detail chip selection optimization introduce controller generate enable signal fifo DB multiplexer data access accelerator transfer medal scalable DIMM data processing accelerator dna algorithm micro october columbus usa mem ctrl buffer arbiter rcd cpu CH CH CH LRDIMM LRDIMM medal mem ctrl CH mem ctrl mem ctrl mem ctrl LRDIMM rank rcd DB DB rank rank dram chip rank connection DB DB FM index query FM index query mux host CS CS CR ctrl data bus data bus data bus comp mux adr trans bus acc zoom SR rcd ctrl acc acc acc acc architecture medal architecture LRDIMM micro architecture DB lightweight customize logic insert within connection rcd DB dram chip data bus enable signal fifo buffer data bus data transfer inter chip hierarchical bus another challenge propose algorithm specific data mapping dram component across rank distribute data DB accelerator data dram component rank however connection dram component within rank vanilla DIMM forbid inter chip communication address challenge inter chip hierarchical bus specifically ID address bus data bus ID address bus transfer accelerator ID memory request accelerator rcd MC accelerator data ID address rcd MC data bus transfer data DB belonging dram component destination accelerator FIFOs DB multiplexer data dram data accelerator bus multi channel bus bus simplify standard bus  contains signal reset signal bus dedicate selection signal data signal ID address bus direction data signal data bus burst ID address bus transfer accelerator ID address burst data bus bus address signal eliminate  arbitrator introduce detail already aware source destination module transfer rcd MC simply assign bus selection signal choice consideration minimize wiring complexity pcb simplify channel bus conduct extra DBs per DIMM rcd bus arbitrator arbitrator assigns bus bus bus arbitrator applies server scheme grant bus accelerator memory request rcd MC data bus arbitrator selection signal dram data transfer  multiplexer accelerator arbitrator aid rcd MC accelerator ID request MC MC data dram accelerator request data information arbitrator data transfer data describes detailed data medal simpler memory footprint rank focus intra rank optimization address grain randomness divergence challenge memory footprint inter rank communication focus technique address data challenge intra rank workflow optimization subsection detailed description architecture address grain randomness divergence challenge propose algorithm specific data mapping bandwidth aware data mapping individual chip selection ICS data rank focus address challenge however technique applicable database medal execution genome data dram address mapping data mapping introduce later host sends ddr command reserve dram mode register rcd MC command broadcast DB accelerator reset reset signal inter chip data bus SR dram DB accelerator sends request rcd MC inter chip ID address bus schedule MC sends signal dram component bus informs DB accelerator via selection signal inter chip data bus finally  accelerator receives data inter chip data bus accelerator iterate till propose algorithm specific address mapping improve data locality potential chip parallelism grain memory access bandwidth aware data mapping fully leverage memory bandwidth ICS leverage chip parallelism grain memory access algorithm specific address mapping propose address mapping aggregate previous interleave data address mapping reduce communication potential chip parallelism grain memory access improve bandwidth utilization propose logic device micro october columbus usa  address mapping scheme address challenge grain random memory access scheme optimization address mapping memory configuration channel rank index mapped significant logic address improve memory parallelism effective bandwidth however interleave data across channel rank destroys locality ndp remote data access dram component instead interleave data across channel rank optimization significant address aggregate adjacent data within rank locally another remains data interleave across chip rank chip interleave coarse grain memory access within rank cannot fully utilized dna moreover prevents chip parallel challenge optimization propose col rank burst chip width rank col burst chip width rank chip col burst width host bandwidth aware coarse grain ndp aware without chip parallelism cache burst grain ndp aware chip parallelism burst finegrained potential chip parallelism algorithm specific address mapping CS signal device address detail enable individual chip originally chip selection address embed significant logic address access cacheline chip index significant address manner adjacent data chip DB chip DB chip DB improves task locality inter chip communication minimize hence improves chip parallelism bandwidth aware data mapping propose data mapping fully leverage available memory bandwidth chip bandwidth aware data placement chip duplicate index data  data mapping duplicate index index access parallel chip another index data bandwidth aware data mapping evenly index chip fully leverage available memory bandwidth chip enable individual chip ICS mention inter task divergence prevents DB accelerator simd style although algorithm specific address mapping potential chip parallelism grain memory access lock conventional DIMM prevents propose enable individual CS signal dram chip overcome challenge introduce conventional DIMM description propose technique convention DIMM CS signal dram chip rank lock DIMM suffer divergence dna upper DB accelerator perform operation chip chip lock manner address random tRC cycle output data chip chip useful propose ICS technique dedicate CS dram chip rcd MC disabled CS signal input command address dram chip receives clk signal enable  signal previous memory command RD pre burst RD pre RD pre RD pre burst burst burst burst CS data CS data without individual chip ICS burst CS data CS data mask mask mask mask mask mask individual chip ICS chip CS mask burst data chip chip burst data chip burst useless data   without individual chip ICS latency ICS technique enable chip disable chip CS signal strobe activation  address enable chip switch CS signal enable chip disable chip enable chip disabled chip lock activation command previous command similarly precharge command chip chip respectively data another adopt propose ICS technique latency reduce due pipelined command furthermore output data fully useful inter rank subsection application memory footprint involve multiple rank besides adopt intra rank optimization described propose reduce inter rank communication overhead overcome data challenge inter rank without modification hardware incoming nvdimm hardware address issue scalability finally propose algorithm specific data compression scheme reduce memory footprint communication overhead medal scalable DIMM data processing accelerator dna algorithm micro october columbus usa inter rank comm cpu polling goal inter rank without modification host DIMM hardware leverage host cpu poll DIMMs periodically inter rank data access request rank host coordinate data transfer aim additional bus across DIMMs addition simplicity achieve speedup reduction aim detail cpu polling inter rank communication host issue polling request DIMM address router redirects polling request indicator remote data buffer RDB fetch host remote data access host issue another request information remote data access address router redirects request remote data access information remote data info RDB information remote data access host issue memory access request destination DIMM fetch data host sends target data DB data LRDIMM rank rcd DB rank rank dram chip rank ctrl cpu MC MC MC MC CH CH LRDIMM LRDIMM polling interrupt data buffer DB remote data info indicator addr router reserve future  pin CH acc acc acc DB acc polling interrupt inter rank communication inter rank comm interruption  suffers occupy host ddr bus without data transfer due occupancy memory bus polling effective bandwidth memory bus transfer data reduce addition polling operation operation medal propose host prioritize request schedule apply extra latency performance degradation issue propose leverage interrupt mechanism reserve future  pin LRDIMM request DB accelerator notify cpu  pin advanced programmable interrupt controller  specifically interrupt inter rank communication DB access remote data issue interrupt signal host via  pin host issue request DB information remote data access address router redirects request remote data access information remote data info RDB information remote data access host issue memory access request destination DIMM fetch data host sends target data DB data host prioritize request schedule mention previously host MC rcd MC request dram host MC aware request rcd MC timing issue arise request schedule satisfy ddr timing constraint host MC data RD pre burst burst RD pre RD pre data RD pre burst burst RD pre RD pre without schedule schedule data RD pre burst RD pre policy tRCD tcas unpredictable latency tRCD tcas trp host chip receives data data chip host burst data host acc burst data acc rcd CAS host request prioritize issue host prioritize request schedule implement policy host MC host prioritize request schedule rcd MC policy host MC memory request dram tRCD tcas however rcd MC issue memory request dram without specific schedule latency memory request host MC unpredictable issue ddr timing constraint address issue rcd MC host prioritize request schedule memory request host dram task host MC modify ddr timing parameter tRCD tcas host MC longer expectation data return rcd MC schedule request reduce inter rank traffic nvdimm  interruption technique goal inter rank communication propose nvdimm approach eliminate inter rank communication nvdimm storage DIMM memory DIMM leverage nonvolatile memory nvm DIMM backup purpose nvdimm integrates dram nvm DIMM micro october columbus usa  release alongside dram nvm nvdimm memory mapped intel optane technology capacity nvm memory cache nvdimm nvdimm host DB byte accessibility dram nvm leverage NVMs denser dram nvdimm eliminate inter rank traffic specifically index data remote rank nvm locally described dram access target data within dram otherwise memory request nvm nvdimm medal convert remote memory access remote rank local memory access DIMM nvm reduce memory footprint comm data compression reduce memory footprint communication propose algorithm specific data compression propose data compression described additional benefit counter data structure dna occurrence  access frequently entry occurrence nucleotide BR nucleotide BR  respectively summarize occurrence array array counter   target CG GC GA GC AG AA CG bwa mem bucket compress bucket compress bucket bucket compress bucket compress bucket GGT tac GGT cta  grain bucket medal bucket bucket  DB ctrl DB dram nvm dram DB DB DB ctrl dram nvm dram dram DB  ctrl dram nvm dram rank  DB ctrl dram nvm dram nvdimm rank processing within nvdimm  transform reference sequence target bucket structure bwa mem grain bucket medal bucket bucket compress bucket bucket data structure software genome entry BR reduce memory footprint widely software bwa mem leverage data structure bucket bucket consists bucket bucket bucket checkpoint date BR within bucket manner entry bwa mem target bucket bucket nucleotide BR within bucket finally target reconstruct date checkpoint BR via counting bucket structure bucket nucleotide bucket compress grain bucket precision data within bucket data bucket data compression reduce precision data bucket via grain checkpoint bwa mem instead global checkpoint grain checkpoint propose data compression bucket propose data compression bucket compress bucket data compression dram bucket global checkpoint data bucket compress bucket contains grain local checkpoint meaning precision data bucket compress bucket propose data compression medal access bucket bucket retrieves target compress bucket target derive local counter compress bucket global counter bucket bucket derive subtraction discussion extension application medal grain random memory access future extend medal application replace logic DBs purpose processor FPGAs application graph processing database sparse matrix compute benefit propose technique interface choice  ddr interface medal due ddr interface configure DIMMs regular memory dna perform flexibility DIMM approach easily optimization technique propose easily apply pcie IO accelerator integration user interface medal modification dram component cpu chip medal connects standard ddr bus DIMM slot described host medal memory instruction software stack modification ndp pim OS reserve memory DIMMs medal mapping user access physical address memory channel perform dna dedicate task host task data mapped memory channel program model medal cuda application program interface api programmer application memory allocation medal memcpy function data user memory application memory medal data memory medal user launch accelerator perform dna medal scalable DIMM data processing accelerator dna algorithm micro october columbus usa DB   DB   DB   DB   DB   performance improvement database inter rank performance improvement chameleon polling aim polling interrupt nvdimm polling data compression interrupt data compression nvdimm data compression DB   DB   DB   DB   DB   reduction database inter rank reduction chameleon polling aim polling interrupt nvdimm polling data compression interrupt data compression nvdimm data compression DB   DB   DB   DB homo  DB   performance improvement database intra rank performance improvement chameleon polling aim address data mapping ICS DB   DB   DB   DB homo  DB   reduction database intra rank reduction chameleon polling aim address data mapping ICS performance improvement reduction medal ndp accelerator FM index dna normalize thread cpu intra rank performance improvement intra rank reduction inter rank performance improvement inter rank reduction configure server medal configuration server cpu model intel xeon cpu frequency ghz memory capacity GB KB KB MB cache configuration medal memory capacity GB memory channel DIMMs per memory channel rank per DIMM dram chip per rank dram chip per DB parameter ddr dram capacity 4GB per  frequency tck mhz tRCD tcas trp experimental RESULTS experimental setup analysis experimental experimental setup configuration baseline baseline FM index dna hash index dna bwa mem  respectively server intel xeon cpu detailed configuration information server configuration medal ramulator modify cycle accurate simulator medal configuration medal timing parameter DB customize logic estimate pre layout compiler technology timing constraint 2GHz circuit slack layout parameter customize logic DB address router involves comparators component command parameter customize logic DB module latency cycle leakage addr trans SMEM timing parameter dram chip consumption dram  command trace dram ramulator  parameter datapath CACTI IO timing parameter nvm nvdimm estimate intel optane memory correctness simulation guaranteed hardware compute arithmetic execution data access software simulator ensures correctness trace software ndp accelerator comparison modify ramulator cycle accurate simulator chameleon aim memory configuration accelerator chameleon communication polling communication mechanism database genome billion billion ncbi database DB DB query sequence query sequence extract exactly correspond genome intra rank evaluation database dram rank performance efficiency comparison medal DIMM ndp accelerator dna normalize thread cpu intra rank task propose address data mapping medal outperforms thread cpu chameleon aim ICS improves performance micro october columbus usa  DB DB DB DB DB DB DB DB DB DB BW utilization database evaluation BW utilization bwa mem chameleon aim medal DB DB DB DB DB polling breakdown computation communication dram DB DB DB DB DB interrupt breakdown computation communication dram DB DB DB DB DB nvdimm breakdown computation communication dram nvdimm breakdown medal bandwidth utilization platform medal via enable efficient grain memory access chip parallelism algorithm specific data compression improves performance medal effectively reduces memory footprint leaf data mapping utilize propose technique medal outperforms thread cpu chameleon aim respectively comparison aim performs coarse grain memory access without extra memory bandwidth chameleon performs grain memory access however data fetch memory chameleon useless due inter task divergence dna simd style processing chameleon chip parallelism chameleon performance medal others parallelism rank chip parallelism grain memory access bandwidth utilization wise medal reduces consumption thread cpu chameleon aim respectively bandwidth utilization processing contribute efficiency inter rank evaluation database cannot within rank inter rank communication similarly comparison inter rank task average polling outperforms thread cpu chameleon aim respectively interrupt outperforms platform respectively nvdimm outperforms respectively polling interrupt performance due interrupt occupy memory channel polling operation meaning negative data transfer polling operation operation due propose host prioritize request schedule extra latency operation host degrade performance polling modification   host hardware interrupt vector superior strength nvdimm approach DB DB DB DB DB DB DB DB DB DB data  index GB database evaluation data compression index compression index compression data compression data compression performance improvement sensitivity intra rank homo  inter rank   evaluation data compression sensitivity shelf nvdimm issue communication without occupation memory channel performance wise polling reduces consumption thread cpu chameleon aim respectively interrupt reduces consumption platform respectively nvdimm reduces consumption platform respectively breakdown breakdown medal computation consumes dna involves integer operation customize lightweight logic efficient communication consumes communication mechanism efficient polling  nvdimm dram consumes respectively dram domination consumption due efficient lightweight logic communication mechanism nvdimm approach nvm consumes average portion consume nvm grows database database possibility memory request nvm bandwidth utilization define bandwidth utilization ratio useful data actual amount data fetch memory average medal bandwidth utilization ratio chameleon bandwidth ratio bandwidth utilization ratio medal grain memory accessibility propose address mapping potential grain memory access ICS reality comparison coarse grain memory access lag bandwidth utilization ratio aim chameleon optimization non simd processing data dram chip become useless reduce bandwidth utilization ratio medal scalable DIMM data processing accelerator dna algorithm micro october columbus usa DB DB DB DB DB DB DB DB DB DB performance improvement database performance improvement hash index chameleon aim medal DB DB DB DB DB DB DB DB DB DB reduction database reduction hash index chameleon aim medal performance improvement reduction medal ndp accelerator hash index dna normalize thread cpu performance data compression data compression reduces dna index average reduction memory footprint data mapping utilize addition amount data fetch iteration reduce due compress bucket extra memory access performance degradation data compression sensitivity typical generation sequence technology representative medal experimental intra rank inter rank various  medal interrupt speedup cpu longer due benefit memory traffic inter rank performance stable respect communication compensates benefit memory traffic longer algorithm darwin customize logic inside DBs algorithm performance gain ultra memory bound medal hash index dna algorithm hash index dna experimental  experimental medal outperforms thread cpu chameleon aim respectively energyefficiency medal outperforms platform respectively related introduces related medal accelerator dna previous proposes fpga gpu dna darwin GenAx accelerator dna alignment ASIC automaton majorly focus dna extension hash index instead FM index medal majorly focus FM index hash index although architecture computation capability data movement serious issue moreover mention dna bound memory limited improvement approach optimize computation contrast medal focus memory performs computation data ndp dna MPU  leverage HMC accelerate dna RISC core logic however 3D stack memory efficient limited capacity extra internal bandwidth aim attache FPGAs dedicate bus DIMMs accelerate dna however aim leverage rank parallelism DIMMs limited performance improvement aim medal specifically optimizes grain memory access address mapping data mapping individual chip selection bandwidth parallelism furthermore medal explores novel approach enhance scalability chameleon purpose simd style DIMM ndp architecture however chameleon focus simd style processing communication mechanism dna medal outperforms aim chameleon average  technology potential accelerate dna couple lightweight logic memory migrate thread pim dna  modifies dram accelerate dna alignment  prins leverage resistive random access memory ReRAM perform dna extension platform modification dram architecture contrast medal leverage shelf dram component practical approach conclusion accelerate dna efficient propose medal practical efficient ndp architecture database propose intra rank algorithm specific address mapping bandwidth aware data mapping individual chip ICS address challenge random memory access improve parallelism bandwidth utilization furthermore address challenge scalability propose inter rank polling communication interrupt communication nvdimm addition propose algorithm specific data compression technique reduce memory footprint introduce data mapping reduce communication overhead experimental propose average medal achieve speedup reduction thread cpu baseline ndp accelerator respectively