graph analytics emerge application extract insight processing volume highly data namely graph parallel processing graph exploit algorithm incurs irregularity onto compute memory significantly hinder efficient architecture irregularity partially tackle prior domain specific accelerator schedule data access others remain unsolved unlike prior effort fully alleviate irregularity origin data dependent program behavior achieve goal propose GraphDynS hardware software decouple datapath data aware dynamic schedule aware data dependency extract decouple datapath GraphDynS elaborately schedule program maximize parallelism extract data dependency runtime propose program model synergy microarchitecture datapath decouple data dependency information data aware strategy dynamically schedule workload data access computation overall GraphDynS achieves speedup average memory bandwidth gpgpu graph analytics accelerator GraphDynS achieves speedup average memory bandwidth CCS CONCEPTS hardware application specific integrate circuit keywords graph analytics accelerator software hardware introduction data era graph effective representation data scenario graph analytics valuable insight data variety application social network analysis cybersecurity analysis knowledge graph autonomous vehicle brain web robot navigation although graph analytics inherently posse parallelism achieve practical acceleration due irregularity challenge parallelism exists vertex simultaneously via popular vertex centric program model VCPM widely recent however due data dependent program behavior graph algorithm exist architecture challenge specifically imbalanced workload amount random memory access across diverse memory redundant computation irregularity workload irregularity workload thread significantly imbalanced VCPM partition program thread active vertex attribute distinct thread consequently various thread vertex usually associate graph traversal irregularity traverse irregularly iteration active vertex iteration irregular connection active vertex unpredictable traversal iteration critical difficulty introduces random memory access due locality incurs latency atomic operation multiple update vertex update irregularity update vertex activation vertex iteration iteration although vertex actually update activate program update irregularity amount unnecessary computation memory access solves irregularity irregularity gpu graphicionado workload expensive preprocessing traversal inefficient update micro october columbus usa  due aforementioned irregularity gpu suffer workload imbalance memory divergence synchronization overhead divergence gpu rely preprocessing tackle irregularity however preprocessing costly unless multiple application static graph repeatedly preprocessing overhead usually offset benefit recently domain specific hardware propose partially address irregularity challenge graph analytics graphicionado graph analytics accelerator almost data random access chip scratchpad memory mitigate traversal irregularity therefore achieves speedup consume software graph analytics framework however workload update irregularity remain unsolved irregularity data dependent program behavior critical graph analytics schedule program data dependency tackle irregularity inspire introduces GraphDynS hardware software decouple datapath data aware dynamic schedule GraphDynS alleviate irregularity graph analytics origin decouple datapath extract data dependency microarchitecture dispatch processing program model propose extract workload prefetching indication access data moreover execution decouple pipelined stage along propose program model microarchitecture propose facilitate decouple microarchitecture datapath data aware dynamic schedule schedule program data dependency address workload irregularity dynamically dispatch workload processing balance manner knowledge  workload mitigate traversal irregularity perform prefetching prefetch graph data knowledge prefetching indication furthermore propose reduce mechanism microarchitectural pipeline dynamically schedule data access eliminate stall atomicity update irregularity maintain bitmap update vertex indication propose pipeline update marked vertex schedule compute contribution summarize propose dispatch processing program model accelerator architecture decouple microarchitecture datapath data dependency extraction runtime propose data aware dynamic schedule data dependency elaborately schedule program effectively tackle irregularity implement GraphDynS rtl evaluate detailed microarchitectural simulation comprehensive evaluation involve graph analytics algorithm graph synthetic graph gpgpu GraphDynS achieves speedup average memory bandwidth graph analytics accelerator GraphDynS achieves speedup average memory bandwidth background introduce graph representation program model graph analytics algorithm graph representation compress sparse csr efficient popular format graph widely various software framework graph accelerator due efficient usage memory storage csr format graph dimensional array offset vertex offset array offset vertex array array successively outgo neighbour IDs graph vertex vertex array vertex offset vertex array indexed vertex ID array indexed offset vertex ID offset array array neighbour IDs vertex prop array random access offset random access random access vertex prop conflict vertex ID csr representation graph csr format random data access graph program model derive scatter structure graph vertex simultaneously iteratively exploit parallelism graph analytics vertex centric program model VCPM propose google pregel advantage simplicity scalability expressiveness VCPM widely adopt various software framework graph accelerator implementation VCPM PB VCPM algorithm consists alternately phase scatter apply scatter phase outgo active vertex traverse update temporary vertex tProp destination vertex application define reduce function apply phase apply function execute constant vertex  tProp apply function  vertex prop prop update vertex activate finally executes iteratively vertex activate maximum iteration application define function PB VCPM graph analytics algorithm breadth bfs source shortest component alleviate irregularity graph analytics acceleration hardware software approach micro october columbus usa CC source SSWP pagerank PR algorithm vertex centric program model scatter phase ive ver tex offset  vid  vid vid  offset  prop tProp reduce tProp  apply phase ver tex  apply prop tProp  prop  prop  activate vertex vid prop application define function source vertex destination vertex algorithm reduce apply bfs prop min rop min prop rop prop iдht min rop min prop rop CC prop min rop min prop rop SSWP min prop iдht max rop max prop rop PR prop rop rop deд edдe   constant motivation motivate approach identify irregularity graph analytics limitation prior challenge graph analytics although VCPM exploit parallelism graph analytics incurs significant irregular compute memory difficulty efficient architecture mention irregularity categorize workload irregularity traversal irregularity update irregularity workload irregularity active vertex iteration usually distribution active vertex within iteration significantly iteration active vertex VCPM partition distributes workload distinct thread active vertex workload varies significantly thread workload irregularity degrade gpu utilization commonly graph analytics algorithm traversal irregularity traverse irregularly iteration due diverse connection graph pointer chase traversal introduces abundant random memory access challenge efficient prefetching possibly incurs raw conflict random access access offset vertex random memory access limited cache efficiency bandwidth demand rate cache graph traversal workload cpu moreover thread vertex latency atomic operation adopt avoid thread contention multiple thread modify vertex previous atomic operation update irregularity runtime vertex irregularly update activate across iteration although vertex update activate actually vertex checked program execution therefore unnecessary computation memory access introduce irregularity update iteration update vertex iteration update vertex graph vertex accord evaluation unnecessary memory access memory access performance overhead graphicionado iteration update active vertex interval vertex  active vertex within interval vertex update flickr dataset iteration workload limitation graphicionado partially address traversal irregularity via chip buffer improve performance efficiency however overhead atomics within traversal irregularity workload irregularity update irregularity mention workload irregularity workload imbalance within pipeline active vertex posse average pipeline workload moreover hash random workload allocate pipeline pipeline workload graphicionado enforces atomicity stall pipeline contention detect stall additional execution update irregularity additional execution additional consumption irregularity data dependent program behavior relies intermediate within across iteration therefore propose hardware software micro october columbus usa  completely tackle irregularity data dependency aware schedule  architecture overhead introduce workload traversal update irregularity propose hardware software optimize program model hardware accelerator data aware dynamic schedule strategy address issue optimize program model allows GraphDynS enable hardware datapath decouple endow visibility schedule hardware extract runtime data dependency dynamic schedule fully utilizes knowledge data dependency schedule workload data access update optimize program model optimize program model VCPM practicality VCPM adopt recent graph processing framework accelerator program model programmability VCPM optimization transparent user optimization workload execution schedule balance workload obtain prefetching indication execution prefetching decouple phase pipeline stage overlap workload schedule execution dynamically workload obviate workload imbalance overhead introduce workload irregularity optimize program model export workload statistic active vertex offset array apply phase scatter phase iteration workload processing dependent active vertex active vertex scatter phase vertex apply phase active vertex vertex directly obtain PB VCPM active vertex iteration vertex fix dataset specify however active vertex counter edgeCnt dependent vertex ID active vertex iteration cannot obtain PB VCPM therefore modify program model acquire offset array  apply phase edgeCnt calculation algorithm access offset array sequentially processing stage apply phase offset vertex succeed vertex calculate edgeCnt active vertex prop  activate vertex constitutes active vertex data dynamically acquire workload hint schedule acquire prefetch indication quantitative analysis towards graph application active vertex posse cacheline byte therefore access limited data locality become bottleneck algorithm optimize program model dispatch stage scatter phase active vertex dispatch prop offset edgeCnt PE processing stage scatter phase    prop tProp reduce tProp   stage apply phase vertex dispatch   vertex PE processing stage apply phase vid    edgeCnt  vid  vid  apply  prop  tProp    prop   prop  activate   prop  vid edgeCnt random access vertex issue address issue propose prefetching technique prefetching data prefetched deterministic prefetching address amount prefetch prefetching maximize flight memory request utilize memory bandwidth efficiently hide memory latency sequentially access data active vertex data vertex data prefetched exactly data address amount prefetch available data prefetch data exactly prefetching indication offset edgeCnt active vertex mention sec acquire offset edgeCnt active vertex program model detail prefetching hardware implementation sec decouple execution overlap latency schedule execution decouple scatter apply phase dispatch processing stage algorithm dispatch stage workload dispatch processing PEs scatter phase workload active vertex dispatch PEs apply phase vertex workload dispatch PE processing stage PEs workload scatter phase PEs workload execute reduce alleviate irregularity graph analytics acceleration hardware software approach micro october columbus usa hardware data aware dynamic schedule hardware layer schedule workload data access update enable datapath decouple extract data dependency bandwidth memory PE DE DE dispatcher processor UE updater   crossbar SIMT core RU AU VB dispatcher processor updater dispatch workload active vertex data reduce temp vertex dispatch vertex workload generate vertex workload update activate vertex vertex apply vertex RB prefetcher dispatcher processor updater SV optimize program model endow visibility GraphDynS architecture overview layer hardware hardware platform stage scatter phase apply phase function apply phase PEs vertex workload execute apply function activate vertex iteration hardware conjunction propose program model propose GraphDynS hardware component decouple datapath microarchitecture hardware component GraphDynS consists component dispatcher dispatcher dispatch workload processor consists dispatch DEs core processor processor receives workload dispatcher workload processor consists PEs PE consists scalar vector SV SIMT lane core SV transform workload scalar SIMT vector construct PE precision float adder multiplier comparators prefetcher prefetcher prefetches graph data bandwidth memory HBM consists vertex prefetcher  prefetcher   prefetches active vertex vertex data vertex prefetching buffer VPB  prefetches data prefetching buffer EPB updater updater receives processor update vertex activates vertex compose radix crossbar switch update UE UE consists vertex buffer VB KB dual chip eDRAM update bitmap RB entry reduce RU activate AU VB cache temporary vertex data graph VB cannot temporary vertex graph slice slice slice slice technique propose graphicionado RB  update vertex RU execute reduce function microarchitecture pipeline reduce pipeline AU activate vertex consists entry buffer queue active vertex hardware platform stage accord functionality aforementioned component hardware platform stage scatter phase apply phase described scatter phase DE active vertex data VPB dispatch workload PEs PE EPB executes function finally UE temporary vertex VB executes reduce writes VB apply phase DE generates vertex index vertex workload dispatch vertex workload PE PE vertex data VPB executes apply function vertex finally UE update vertex activates vertex iteration decouple datapath acquire information runtime decouple datapath optimize program model aforementioned component workload management sub datapath dispatch processing workload DE dispatch workload PE SV transforms workload vector workload loop unroll fashion alleviate workload irregularity dispatch workload PE balance extend workload processing SIMT execution model improve workload processing throughput information workload sec detail data access sub datapath chip memory access onchip memory access prefetcher exactly prefetches graph data chip memory processor dispatcher coalesce access data chip memory VPB EPB VB RU access VB atomically alleviate traversal irregularity schedule data access data information access access address reduce random access improve data access throughput remove atomic stall sec detail data update sub datapath data update vertex update vertex activation scatter phase RU writes RB vertex update temporary vertex modify apply phase prefetcher prefetches vertex data informs dispatcher dispatch vertex workload PE update computation AU update vertex activates vertex alleviate update irregularity dynamically update vertex modification status prefetch data moreover coalesce chip memory active vertex update computation sec detail micro october columbus usa  vectorize workload processing loop unroll SIMT workload queue thread thread thread vectorized workload SIMT core SV thread ram threshold threshold PE EPB crossbar switch RU UE VB RU VB UE data vector access data scalar ram ram ram  data VPB EPB ram PE VPB UE UE apply vertex ram vertex vertex vertex vertex vertex VB AU VB AU SIMT SIMT PE PE DE DE data aware dynamic schedule DEs dispatch workload PEs threshold SV vectorizes workload processing loop unroll data organization VPB EPB chip vectorized access procedure PE scatter phase apply phase data aware dynamic scheduling leverage information optimize program model decouple datapath data aware dynamic schedule scheme schedule workload data access update computation propose architecture propose technique tackle workload traversal update irregularity workload schedule balance workload workload explain improve workload processing throughput SIMT execution model workload balance dispatch achieve workload balance dynamically dispatch workload PE accord workload graphicionado vertex PE batch distributes active vertex PE evenly schedule operation reduce significantly workload balance PE schedule scatter phase DE active vertex data VPB dispatch active vertex PE accord edgeCnt DE dispatch entire processing workload PE dei sends pei edgeCnt predefined threshold  otherwise DE partition sub sub  dispatch PE edgeCnt active vertex   DE dispatch entire workload PE splitting sub dispatch PE PE workload queue processing apply phase DE generates vertex vertex  dispatch processing workload vertex PE dei sends pei vertex generate dei  stride DE  workload processing vectorization improve workload processing throughput extend execution PE SIMT execution model SV execute loop unroll workload vertex workload transform scalar vector SV PE workload queue assigns SIMT thread simultaneously SIMT core executes workload addition combine workload thread SIMT core improve SIMT efficiency optimization improve processing throughput improves computation efficiency configuration dispatch vectorization improve workload dispatch processing efficiency appropriately SIMT thread  sub    active vertex iteration active vertex iteration moreover active vertex average efficiency SIMT distribution  reduce complexity dispatcher workload imbalance due active vertex  data access granularity PE latency EPB  simplify access VB  sec data access schedule propose prefetching hardware implementation vectorize data access chip memory finally propose zero stall atomic maintenance mechanism customize microarchitecture pipeline prefetching implementation random access vertex data chip memory graphicionado access locality become bottleneck mention sec prefetching indication program model prefetcher prefetches sequentially access data prefetching active vertex execute  address active vertex array active vertex active vertex access request HBM  receives offset edgeCnt  sends offset edgeCnt   offset edgeCnt access request HBM  receives data EPB alleviate irregularity graph analytics acceleration hardware software approach micro october columbus usa previous introduce latency prefetching chip memory cache offset array reduce latency random access location offset active vertex ID addition additional memory storage abundant unnecessary memory access source vertex ID src vid previous data src vid active vertex ID vid traversal active vertex traversal access extra waste bandwidth contrary prefetching access offset rely active vertex ID offset prefetched prefetcher edgeCnt prefetch efficiently prefetch without unnecessary data access additional memory storage moreover chip memory request acquires significant amount active vertex data offset counter coalesce memory access data maximize flight memory request consequently optimization enables utilization bandwidth vectorizing chip data access improve chip memory access efficiency throughput vectorize chip memory access organize data prefetching buffer SIMT granularity data access vertex buffer prefetching buffer organization VPB EPB RAMs vertex data placement hash algorithm ram access ram ram VPB EPB access specific DE PE dei pei access  active vertex varies  maintain processing vector PE correspond data vector EPB therefore  adopts  strategy DE data EPB illustrate chip data organization VPB EPB ram VPB ram EPB PE ram VPB ram EPB PE active vertex ram VPB dependent access workload active vertex dispatch correspond PE accord dispatch strategy workload partial workload assign PE meantime  sequentially active vertex data VPB data prefetching prefetched data  data active vertex correspond ram accord edgeCnt  workload dispatch data ram EPB data ram ram evenly PE data partial correspond workload pei access  data  VB data access arrangement scatter phase improve VB access throughput scatter phase split vertex temporary data evenly partition accord hash algorithm  respectively VB ID vertex ID UE moreover crossbar switch route access thread  access address illustrates chip memory access procedure PE scatter phase PE vector ram EPB PE vector processing function PE sends processing vector updater updater crossbar switch route processing thread ues destination vertex temporary address RU destination vertex temporary VB executes reduce function RU writes reduce VB detail data access inside updater explain sec access VB explain complex logic data VB PE transform scalar data vector data VB data access arrangement apply phase simplify access VB improve VB access throughput apply phase PE access  consecutive  vertex IDs within vertex consecutive generate DE vector access PE directly access  consecutive  moreover vertex generate DE stride DE  mention access PEs distribute  specific  hence conflict arise access  avoid PE receives data  register access data return UE access latency constant illustrates chip memory access procedure PE apply phase PE  vertex vector ram VPB PE temporary vertex vector VB PE vertex vector execute apply function PE sends vector updater updater sends thread AU respectively detail data access inside updater explain sec access VB explain PE logic transform scalar data vector data maintain atomicity zero stall previous atomic operation another bottleneck due parallel data conflict scatter feature graph processing graph distribution addition atomic bottleneck access algorithm pagerank becomes significant issue address introduces stall access temporary vertex performance degradation opportunity fortunately opportunity eliminate stall atomic operation observation raw occurs reduce function tProp modify algorithm specify reduce function reduce function graph workload accumulation operation instruction instruction operation observation propose  mechanism microarchitecture pipeline micro october columbus usa  shorten distance raw conflict data arithmetic date data execute arithmetic specially shorten distance compute pipeline data cycle reduce mechanism customize compute pipeline shorten distance cycle finally date data access address source operand destination operand data arithmetic inside microarchitecture pipeline implementation transform reduce operation tProp operation VB execute reduce function RU namely reduce PE executes operation address tProp processing  updater crossbar switch inside updater route data thread correspond UE tProp address RU tProp VB executes reduce function writes tProp VB cycle VB RD cycle execution exe return cycle VB WB operation register OP OP operand register VB VB operation register operand register address pipeline register register OP addr pipeline register address address register  addr pipeline register register float arithmetic vertex buffer access  operation register signal data signal return mux mux mux reduce pipeline avoid pipeline stall inside RU stage pipeline reduce pipeline execute reduce function remove instruction fetch instruction decode stage classic stage pipeline operation graph algorithm specify RD stage tProp VB address tProp tProp return WB stage operand register address comparison address RD stage WB stage return operand register address otherwise tProp operand register address pipelined exe stage exe stage float arithmetic logical  calculates RD stage operand  address comparison return WB stage  address otherwise operand register  address WB stage execution stage consumes cycle due simplicity reduce operation WB stage tProp VB address return RD stage exe stage integrate reduce pipeline RU stall remove atomicity maintain data update schedule apply phase update vertex avoid unnecessary update vertex update indication RU reduce irregular intermittent memory access due random update coalesce intermittent access effectively bandwidth update data opportunity implementation selects update data opportunity reduce function vertex update algorithm therefore opportunity vertex update via RU algorithm apply function reduce function modification  algorithm indicates vertex update indication RU maintain bitmap namely update bitmap RB vertex update scatter phase update update vertex apply phase computation memory access unnecessary update eliminate implementation integrate RB UE tProp vertex modify scatter phase iteration apply phase  prefetches update vertex data DE generates update vertex workload RB bitmap unnecessary computation bitmap implementation overhead simplify hardware implementation leverage SIMT advantage status consecutive vertex experimental effective reduce unnecessary computation coalesce intermittent access alleviate memory bandwidth pressure random update coalesce intermittent chip memory access active vertex array opportunity active vertex array update data dependent algorithm introduces intermittent access chip memory inefficient bandwidth utilization transform conditional operation UE buffer queue buffer fashion buffer active vertex data chip memory buffer queue apply phase stall possibility incur buffer queue reduce chip memory access efficiency improve implementation operation execute PE sends conditional flag  offset edgeCnt UE AU UE activates vertex flag writes active vertex data buffer queue vertex chip memory flag reduce random access summary summarize extract data dependency runtime decouple datapath optimize program model hardware dynamically schedule balance workload data access elaborately eliminate unnecessary update data dependency aware scheme mitigate workload irregularity dispatcher leverage workload information balance workload across alleviate irregularity graph analytics acceleration hardware software approach micro october columbus usa multiple PEs processor utilizes SIMT execution model workload vector address traversal irregularity prefetcher leverage offset various data structure exactly prefetch graph data vectorize chip memory access moreover updater leverage access address vertex maintain atomicity zero stall observation simplicity reduce operation address update irregularity updater utilizes modification status temporary vertex implement selective update coalesces intermittent chip access active vertex data experimental methodology methodology performance GraphDynS graphicionado accelerator simulator performance evaluation customize cycle accurate simulator implement execution cycle simulator model microarchitectural behavior hardware module addition performance model implement detailed cycle accurate scratchpad memory model crossbar switch model integrate ramulator memory simulator simulate cycle accurate behavior memory access HBM CAD critical delay cycle measurement implement verilog version hardware module synthesize synopsys compiler TSMC standard VT library synthesis estimate consumption synopsys primetime PX eDRAM crossbar switch HBM measurement access latency chip scratchpad memory estimate cactus cactus technology apply factor convert technology throughput crossbar switch estimate rout resource physical parameter layer model similarly apply factor mention convert technology HBM estimate baseline performance efficiency GraphDynS evaluate graphicionado gpu gunrock linux workstation equip intel xeon cpu 6GB memory nvidia gpu configuration implementation GraphDynS baseline GraphDynS graphicionado gunrock compute  SIMT   core chip memory MB eDRAM MB eDRAM MB chip memory 2GB HBM 2GB HBM 0GB HBM gpu chip memory consists register file memory cache graph datasets algorithm describes graph datasets evaluation graph synthetic graph evaluation CC bfs SSWP PR algorithm evaluate GraphDynS evaluation unweighted graph random integer assign graph datasets evaluation graph vertex brief explanation flickr FR flickr crawl  PK  social network livejournal LJ livejournal follower hollywood HO movie actor social  crawl  orkut orkut social network RMAT RM synthetic graph RMAT RM synthetic graph RMAT RM synthetic graph RMAT RM synthetic graph RMAT RM synthetic graph experimental RESULTS GraphDynS baseline analysis speedup performance speedup normalize gunrock label GM geometric across algorithm overall GraphDynS achieves speedup gunrock posse chip memory bandwidth meanwhile graphicionado GraphDynS achieves speedup consumes chip memory performance GraphDynS others highly effective memory bandwidth utilization elimination atomic stall reduction update operation analyze performance improvement application gunrock speedup CC algorithm algorithm online preprocessing gunrock efficiently reduces unnecessary workload filter unnecessary active vertex PR algorithm achieves speedup GraphDynS graphicionado due random access chip memory graphicionado GraphDynS achieves speedup PR algorithm algorithm prefetching eliminates redundant data access harvest bandwidth improve throughput zero stall atomic optimization eliminates stall frequent raw conflict introduce throughput graph compute algorithm performance speedup PR due latency introduce non sequential access active vertex furthermore active vertex chip memory access granularity underutilized bandwidth analyze influence dataset speedup HO dataset datasets HO dataset vertex ratio data posse spatial locality access latency hidden FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO bfs CC SSWP PR GM speedup gunrock graphicionado GraphDynS speedup gunrock throughput additionally throughput technique throughput define per GTEPS giga traverse micro october columbus usa  per ideal peak throughput GTEPS GraphDynS achieves GTEPS average graphicionado gunrock achieve GTEPS GTEPS respectively although GraphDynS achieves throughput gunrock average average speedup gunrock online preprocessing dominates execution gunrock GraphDynS due atomic operation stall data access throughput prefetch buffer PR algorithm graphicionado achieves GTEPS throughput average optimization zero stall atomics prefetch buffer organization PR algorithm GraphDynS achieves throughput GTEPS average although PR algorithm iteratively PR algorithm achieve peak throughput dram refresh memory access vertex data consumes bandwidth algorithm CC achieves throughput SSWP bfs average vertex vertex iteration active vertex converges quickly FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO bfs CC SSWP PR GM throughput GTEPS gunrock graphicionado GraphDynS throughput breakdown GraphDynS HBM GraphDynS respectively dispatcher prefetcher meanwhile processor due processing updater due MB eDRAM crossbar switch however graphicionado MB eDRAM cache temporary vertex array offset array hence although GraphDynS compose reduce pipeline active graphicionado graphicionado dispatcher processor updater prefetcher dispatcher processor updater prefetcher breakdown normalize consumption GraphDynS baseline consumption HBM normalize gunrock GraphDynS reduces consumption gunrock average reduces consumption average reduction memory access due prefetching unnecessary update gunrock CC algorithm FR dataset PR algorithm dataset efficient GraphDynS introduce chip memory access consume average component GraphDynS consume chip memory access HBM graph algorithm extremely computation  ratio processor consumes updater consumes component consume FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO bfs CC SSWP PR GM normalize graphicionado GraphDynS consumption normalize gunrock HBM FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO bfs CC SSWP PR GM breakdown prefetcher dispatcher processor updater breakdown memory storage usage maximum chip memory storage usage GraphDynS baseline runtime normalize gunrock GraphDynS memory storage respect gunrock graphicionado average reduction memory storage GraphDynS extra information preprocessing metadata additional data gunrock storage graph data preprocessing metadata graphicionado data source vertex ID src vid active vertex data active vertex ID vid contrarily src vid vid GraphDynS counter offset active vertex FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO bfs CC SSWP PR GM normalize storage graphicionado GraphDynS chip memory storage usage normalize gunrock memory access data access chip memory GraphDynS baseline runtime normalize gunrock although GraphDynS access offset array additionally iteration GraphDynS reduces data access average gunrock graphicionado gunrock memory request random access traversal however online preprocessing gunrock significantly reduce data access CC algorithm data access gunrock CC algorithm FR dataset PR algorithm dataset alleviate irregularity graph analytics acceleration hardware software approach micro october columbus usa GraphDynS data locality vertex GraphDynS graphicionado chip memory reduce amount random access nevertheless mention access graphicionado src vid extra access proportional FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO bfs CC SSWP PR GM normalize access graphicionado GraphDynS memory access normalize gunrock utilization memory bandwidth average memory bandwidth utilization GraphDynS others benefiting prefetcher GraphDynS achieves memory bandwidth utilization average amount random access bandwidth utilization gunrock graphicionado bandwidth utilization GraphDynS graphicionado sequential access data extra access src vid GraphDynS average buffer rate GraphDynS however GraphDynS performs graphicionado due efficient utilization memory bandwidth FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO FR PK LJ HO bfs CC SSWP PR GM bandwidth utilization gunrock graphicionado GraphDynS memory bandwidth utilization schedule optimization detailed evaluation LJ dataset insight schedule optimization optimization workload balance WB prefetching EP atomic optimization AO update schedule combination understand effectiveness propose technique combine workload balance  technique combine atomic optimization technique  combine  update schedule technique  workload schedule evaluate load balance schedule schedule operation reduction GraphDynS respect GraphDynS without workload schedule optimization WB optimization GraphDynS reduces schedule operation average meanwhile reduce DEs DEs reduces dispatcher although DEs reduce performance degrade schedule complexity reduction propose coarse granularity batch vertex schedule mechanism enable DEs achieve peak throughput processor normalize workload PEs heaviest workload iteration SSWP algorithm ideal normalize average workload correspond iteration GraphDynS WB optimization improves performance performance average hence WB optimization reduces schedule overhead balance workload efficiently data access schedule analyze effectiveness data access schedule achieves speedup average graphicionado data access HBM reduce prefetching optimization EP average EP optimization prefetcher prefetches quickly access active vertex data therefore scatter phase memory parallelism improve performance stall due data reduce prefetching significantly improve memory access efficiency traversal irregularity algorithm bfs algorithm exhibit speedup spends apply phase instead scatter phase analyze performance  speedup graphicionado specifically PR CC algorithm benefit AO optimization achieve performance improvement respectively raw conflict per cycle algorithm due throughput PR CC HO dataset performance improvement achieves respectively HO dataset vertex ratio deteriorates raw conflict throughput summary data access schedule reduce amount unnecessary data access execution efficiently overcomes traversal irregularity update schedule lastly evaluate effectiveness update schedule  achieves speedup graphicionado technique alone reduces execution breakdown improvement update operation data access reduction data access chip memory reduce graphicionado update operation eliminate technique specifically bfs algorithm reduces update operation data access execution algorithm apply phase occupies execution algorithm occupies PR algorithm cannot improvement PR update vertex iteration algorithm reduces update operation data access however reduces execution apply phase occupies execution summary update schedule greatly reduces unnecessary update operation data access efficiently address update irregularity reduces execution scalability analysis performance ues performance ues LJ dataset normalize micro october columbus usa  bfs CC SSWP PR GM speedup WB   bfs CC SSWP PR GM access reduction ratio EP bfs CC SSWP PR GM schedule reduction  workload PE bfs CC SSWP PR normalize performance throughput GTEPS GraphDynS graphicionado efficiency dynamic schedule scalability reduction ratio schedule DEs normalize workload PEs iteration breakdown speedup normalize chip data access graphicionado performance ues throughput synthetic graph performance ues PR CC algorithm respectively ues ues affected heavily ues reduce operation SIMT lane PEs access ues situation contention ues algorithm achieve GTEPS throughput ues others achieve GTEPS therefore contention algorithm performance degradation summary algorithm achieves throughput sensitive ues throughput synthetic graph throughput synthetic graph vertex ratio PR algorithm throughput PR algorithm evaluate scalability performance throughput PR algorithm heavily depends  vertex ratio graph throughput GraphDynS slows slightly graph slice slice repetitive access active vertex however graphicionado cache temporary vertex GraphDynS throughput graphicionado slows gradually GraphDynS GraphDynS graphicionado graph related graph analytics accelerator recent fpga accelerate graph workload specific data partition reduce random memory access raw conflict furthermore limited hardware resource fpga cannot efficiently accelerate graph processing performance overcome limitation architecture template asynchronous execution model exploit memory parallelism although achieves throughput complex ensure sequential consistency traversal irregularity inefficient bandwidth utilization random memory access exit graphicionado chip memory reduce amount random memory access achieves performance efficiency whereas cannot tackle workload update irregularity address irregularity efficiently achieves speedup consume graphicionado besides recent modify logic layer 3D memory technology hybrid memory cube HMC offload graph workload HMC utilize internal bandwidth memory centric architecture nevertheless logic layer limited thermal budget implement ReRAM graph processing accelerator leverage efficient compute capacity ReRAM cannot adopt memory technology immature practical leverage shelf HBM gpu integrate bandwidth memory gpu achieve magnitude performance improvement cpu however expensive offline online preprocessing transform irregularity regular dominates execution processing gunrock however alleviates irregularity without preprocessing achieves speedup reduce consumption gunrock conclusion propose hardware software graph analytics GraphDynS decouple datapath GraphDynS schedule workload data access update computation data dependency runtime alleviate irregularity graph analytics GraphDynS achieves speedup consume graph analytics accelerator stateof gpu nvidia gpu GraphDynS achieves speedup memory bandwidth consume