processing memory pim architecture recent technology advance hybrid memory cube demonstrate potential graph processing however exist address challenge graph processing irregular data movement proposes GraphQ improve pim graph processing architecture recent architecture tesseract fundamentally eliminates irregular data movement GraphQ inspire distribute graph processing irregular application enable static structure communication runtime architecture specifically GraphQ realizes batch overlap inter cube communication reorder vertex processing streamline inter cube communication heterogeneous core access moreover tackle discrepancy inter cube inter node bandwidth propose hybrid execution model performs additional local computation inter node communication model applicable asynchronous iterative algorithm tolerate bound stale GraphQ simultaneously maximizes intra cube inter cube internode communication throughput zsim simulator graph algorithm GraphQ achieves average maximum speedup tesseract increase memory pim proportionally increase compute capability node GraphQ achieves speedup node memory conventional memory hierarchy CCS CONCEPTS computer organization parallel architecture hardware 3D integrate circuit emerge architecture keywords graph analytics data movement memory 3D stack memory processing memory data processing introduction graph capture relationship data item interaction dependency graph analytics emerge important understand relationship heterogeneous data data analyst valuable insight data application machine task processing anomaly detection cluster recommendation social influence analysis bioinformatics improve programmability graph orient program model vertex program easily express graph algorithm programmer vertex programmer express algorithm vertex function vertex graph adjacency matrix source destination typically adjacency matrix sparse compress representation compress sparse csr array vertex array vertex sequentially entry vertex outgo array vertex sequentially compute array update destination vertex access vertex array mostly sequential access compute array random moreover graph algorithm memory bandwidth perform amount computation randomly access data essence irregular data movement conventional memory hierarchy processing memory pim reduce data movement memory computation compute logic inside memory impractical pim recently becomes attractive architecture due emerge 3D stack memory technology micro october columbus usa  hybrid memory cube HMC bandwidth memory HBM architecture compose multiple memory cube external link SerDes link HMC 0GB per link within cube multiple dram stack silicon via tsv internal memory bandwidth 0GB computation logic core embed perform computation memory compute logic reduce data movement memory hierarchy importantly pim memory capacity proportional bandwidth scalability tesseract pim graph processing architecture vertex program model architectural primitive enable inter cube communication  another architecture program model architecture reduce inter cube communication scheme reduce data movement irregular implication overhead handle message inter cube communication unpredictable arrival communication graph partition graph data partition memory cube source destination vertex assign cube inter cube communication update correspond remote compute array entry communication unpredictable depends processing destination vertex tesseract remote cube handle inter cube message interrupt executes function perform update due unpredictable message arrival incurs performance overhead receiver cube local execution interrupt addition load imbalance cube message ideal cube message source processing core cube perform sequential access vertex array random access compute array access  cache locality interference moreover locality affected perform remote compute array update request inter cube communication prior architecture pim node multi node vertex program model runtime transparently extend remote destination vertex update inter cube internode communication challenge substantial bandwidth inter node communication 6GB  0GB intra cube 0GB communication address challenge proposes GraphQ improve pim graph processing architecture recent architecture tesseract eliminates irregular data movement GraphQ inspire distribute graph processing irregular application enable static structure communication runtime architecture specifically GraphQ realizes batch overlap inter cube communication reorder vertex processing streamline inter cube communication heterogeneous core access eliminate interference moreover GraphQ  graph processing architecture multi node tackle discrepancy inter cube inter node communication bandwidth propose hybrid execution model midpoint synchronous asynchronous execution perform additional local iteration inter node communication model apply asynchronous iterative algorithm tolerate bound stale GraphQ simultaneously maximizes intra cube inter cube inter node communication throughput code modification runtime transparently realizes minor architecture  another pim graph processing architecture interconnection reconfiguration relies host processor switch status connection closely related reduces irregularity inter cube data movement unlike GraphQ  improves inter cube communication purely implement hardware cannot enjoy flexibility approach evaluate GraphQ zsim simulator realworld graph algorithm GraphQ achieves average maximum speedup tesseract  GraphQ achieves speedup tesseract hybrid model node GraphQ achieves average speedup node GraphQ speedup node memory conventional memory hierarchy background  graph processing vertex program apis function input output  source vertex partial update reduce reduce partial update reduce update apply reduce update graph vertex   comp dest temp reduce temp graph vertex active apply comp temp vertex program model graph define vertex development graph algorithm domain specific program model vertex principle propose vertex program apply scatter program   program framework vertex program software hardware accelerate graph processing framework tesseract graphlab graphicionado semantics apis vertex program graph application express primitive GraphQ scalable pim graph processing micro october columbus usa vault cube inter cube bandwidth 0GB per link dram layer logic layer silicon via tsv intra cube bandwidth 0GB 0GB processing memory pim node node node node inter node bandwidth 6GB processing memory architecture processing vertex vertex array outgo array involve outgo vertex function  computes contribution source vertex destination vertex access reduce perspective update return  combine reduce function exist compute array temp incur random access apply graph iteration vertex compute array apply vertex array apply function iterative graph algorithm procedure multiple iteration convergence summarize characteristic graph processing random access compute array ratio memory access computation  typically graph algorithm incur random access memory bandwidth processing memory processing memory pim architecture reduces data movement perform computation data 3D memory technology hybrid memory cube HMC bandwidth memory HBM pim feasible integrate memory compute logic package achieve memory bandwidth latency tesseract  considers pim architecture capture feature specific pim implementation architecture compose multiple cube external link SerDes link HMC 0GB per link within cube multiple dram stack silicon via tsv internal memory bandwidth 0GB computational logic core embed tesseract issue core logic vault feasible cortex processor FPU core corresponds dram GraphQ assumes cube delivers TB memory bandwidth considerably conventional memory moreover memory bandwidth grows proportionally capacity scalable manner pim graph processing tesseract pim graph processing accelerator cube tesseract primitive vertex program model vertex program iterates executes function signature function void func void destination vertex source vertex cube cube cube cube irregular message cube cube  sequential source vertex access sequential access random destination vertex access  remote func reduce apply batching tesseract communication access arg arg void  addr executes function func argument arg cube therefore remote destination vertex resides cube source vertex otherwise local function barrier ensures operation iteration perform iteration inter cube communication adjacency matrix correspond source destination vertex dot vertex partition cube cube assign dot vertex cube vertex cube corresponds inter cube message cube cube across cube incurs message destination cube graph structure destination irregular inter cube message generate execution unpredictable destination cube receiver core interrupt execute remote function incur overhead due context switch tesseract batching mitigate interrupt overhead buffering remote function queue execute multiple function later function correspond inside execute batch core remote cube due inter cube message batch generate offset performance impact interrupt overhead moreover irregular communication cube incur imbalanced load hardware utilization due graph dependent communication message cube sender message queue become backpressure network prevent sender generate message core receiver cube overwhelmed handle remote function request without progress processing local data finally dynamic communication excessive consumption inter cube link  link mode HMC however optimization applicable scenario message intra cube data movement destination local cube local apply perform incurs random access locality interference specifically access vertex array array sequential however access compute array destination vertex random besides remote function incur random access