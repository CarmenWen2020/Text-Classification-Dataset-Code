propose holistic address important challenge issue storage data management emerge nvdimm architecture namely performance model nvdimm migration architectural NVDIMMs migration optimization novel nvdimm heterogeneous storage performance model propose effectively address bus contention issue NVDIMMs memory bus develop nvdimm lazy migration scheme effectively minimize adverse memory traffic interference storage data management finally nvdimm architectural migration optimization propose increase channel parallelism destination NVDIMMs bypass buffer cache source NVDIMMs impact memory traffic alleviate detailed evaluation analysis quantify technique enhance performance workload via efficient heterogeneous storage hierarchy management experimental overall propose technique yield performance improvement stateof technique CCS CONCEPTS computer organization secondary storage organization hardware memory dense storage keywords nvdimm heterogeneous storage bus contention machine introduction data application demand performance enormous amount data transfer memory storage device processing workload typically execute virtualized data various storage resource virtualized data storage resource abstract data multiple  virtual machine disk distribute across physical device various workload storage device imbalanced performance objective storage management achieve balance performance latency throughput via resource utilization nvdimm non volatile dual memory module become popular storage medium due latency superior capacity scalability hardware JEDEC define NVDIMMs nvdimm nvdimm nvdimm nvdimm limited capacity mainly data dram nand flash loss nvdimm nvdimm non volatile memory memory address thereby significantly increase capacity  device integrate storage various ibm lenovo however NVDIMMs challenge storage management predict performance nvdimm device traditional storage device transfer data via nvdimm module instal ddr slot data deliver via memory channel therefore performance model workload memory traffic cannot exist traditional storage architecture accurately predict performance nvdimm device critical optimize initial data placement imbalance detection data migration without  micro october columbus usa overload nvdimm device unnecessary data migration nvdimm device trigger significant overhead density  increase rapidly data workload online balance performance across data critical specifically nvdimm device transfer traffic via memory channel amount data nvdimm device transfer via memory bus inevitably brings adverse memory traffic deteriorate performance server node involve data migration influence normal business operation important minimize adverse enormous amount data  migrate NVDIMMs significant challenge nvdimm performance therefore nvdimm architecture technique urgently exploit characteristic NVDIMMs data migration storage data management exist storage management cannot effectively propose nvdimm storage management technique architectural optimization address challenge technique address initial data placement load imbalance detection data migration nvdimm architectural respectively initial data placement load imbalance detection  heterogeneous storage performance model address bus contention nvdimm device data migration lazy migration scheme developed minimize adverse memory traffic interference via reduce unnecessary data transfer nvdimm architectural optimization technique increase channel parallelism destination NVDIMMs bypass nvdimm buffer cache source NVDIMMs adverse data migration alleviate conduct various data benchmark simulation environment demonstrate effectiveness propose holistic technique various aspect experimental overall propose technique yield performance improvement technique contribution knowledge nvdimm storage data management technique architectural optimization address data migration storage resource management virtualized data propose novel nvdimm heterogeneous storage performance model effectively bus contention nvdimm device developed lazy migration scheme manage data migration effectively minimize adverse memory traffic interference novel architectural optimization technique alleviate adverse nvdimm source destination data migration background prior server nvdimm storage device server node nvdimm storage device data application traditional storage device cpu memory controller controller hub SATA controller server pcie ssd SDRAM DIMM nvdimm SATA hdd app OS VM app OS VM app OS VM SDRAM flash flash flash flash SDRAM SDRAM SDRAM SDRAM SDRAM nand flash nand flash nand flash nand flash nand flash nand flash server node nvdimm via controller hub interface SATA serial ata pcie pci express contrary nvdimm module instal ddr slot transfer data memory channel specifically NVDIMMs dram DIMMs memory channel application transparently utilize nvdimm technique interface NVDIMMs dram DIMMs memory channel channel slot resource fully utilized limited channel parallelism dram DIMMs NVDIMMs memory channel slot ibm lenovo server channel slot dedicate DIMMs channel slot resource useful sever request idle therefore NVDIMMs dram DIMMs channel  ibm lenovo attribute nvdimm pcie ssd SATA hdd latency latency capacity 0GB 2GB 2GB price GB comprehensive comparison storage device nvdimm device greatly alleviate latency limited capacity virtual machine disk image typically multiple  consolidated storage achieve balance performance latency throughput utilization effective capacity critical intelligently distribute data initial placement dynamic migration across heterogeneous storage device consist NVDIMMs SSDs HDDs performance tradeoff capacity nvdimm comparable ssd hdd price nvdimm lower development technology therefore reasonable  NVDIMMs addition regardless usage scenario expensive NVDIMMs cache data workload data consolidated nvdimm device response workload become ultra therefore achieve balance performance latency throughput utilization effective capacity intelligently distributes data initial placement dynamic migration across heterogeneous storage device consist NVDIMMs SSDs HDDs performance tradeoff towards efficient nvdimm heterogeneous storage hierarchy management data workload micro october columbus usa data management heterogeneous storage VMDK management important technique improve overall storage utilization across multiple physical device storage manager   performs data placement migration cluster storage device trigger data relocation imbalanced device utilization detect overload SATA hdd underloaded nvdimm server node equip storage device illustrate storage architecture storage management multiple server node dram DIMM nvdimm storage manager server pcie ssd SATA hdd dram DIMM nvdimm memory controller SATA interface pcie switch VMDK channel VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK channel VMDK storage manager server pcie ssd SATA hdd memory controller SATA interface pcie switch dram DIMM nvdimm VMDK underload VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK underload overload dram DIMM nvdimm overload VMDK VMDK VMDK channel channel dram DIMM nvdimm storage manager server pcie ssd SATA hdd dram DIMM nvdimm memory controller SATA interface pcie switch VMDK channel VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK channel VMDK memory controller pcie switch storage manager server dram DIMM nvdimm dram DIMM nvdimm dram traffic overload VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK memory controller pcie switch storage manager server dram DIMM nvdimm dram DIMM nvdimm dram traffic underload VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK channel channel pcie ssd  channel pcie ssd VMDK imbalanced load storage data migration load balance perform data migration  source storage device destination storage device accomplish procedure issue effectively detect overload react migrate VMDK image challenge overload heavily depends characteristic workload underlie storage device address issue migration scheme propose basil software automatically manages placement performs load balance across device basil online device model load balance lack benefit analysis decision pesto propose completely automate load balance management data benefit analysis LightSRM leverage mirror redirect request without virtual disk thereby mitigate storage migration scheme effectively manage traditional storage however accomplish efficient data management nvdimm heterogeneous storage hierarchy conquer challenge introduce nvdimm architecture traditional storage device transfer data via nvdimm module instal onto ddr slot data deliver via memory channel prior focus balance memory bus resource allocation NVDIMMs dram DIMMs demonstrate bus contention important role nvdimm performance therefore performance model nvdimm storage hierarchy workload memory traffic cannot exist assume traditional storage architecture nvdimm module traffic transfer via memory channel inevitable interference memory traffic VMDK migration performance server node deteriorate memory traffic interference mitigate adverse VMDK migration investigate motivation illustrate interference issue introduce mixed nvdimm dram DIMM traffic impact data management efficiency heterogeneous storage hierarchy memory controller pcie switch storage manager server dram DIMM nvdimm dram DIMM nvdimm dram traffic overload VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK memory controller pcie switch storage manager server dram DIMM nvdimm dram DIMM nvdimm dram traffic underload VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK VMDK channel channel pcie ssd  channel pcie ssd VMDK unnecessary data migration introduce prior data migrate nvdimm pcie ssd data migrate pcie ssd nvdimm prior storage management scheme pesto bus contention consideration unnecessary data migration trigger dram memory traffic heavily occupies memory bus nvdimm performance throttle bus contention traditional scheme pesto mistakenly detect nvdimm overload trigger unnecessary data migration nvdimm pcie ssd later dram memory traffic reduce recognize nvdimm underloaded VM disk image previously migrate pcie ssd nvdimm similarly unnecessary VMDK migration initial  introduce prior instance memory bus traffic newly VMDK device underloaded nvdimm later bus traffic becomes VMDK migrate nvdimm thereby unnecessary data transfer analyze overhead introduce prior scheme conduct hibench spec cpu hibench representative data benchmark suite illustration purpose typical data application namely bayes  etc spec cpu mcf chosen representative memory intensive application experimental environment default nvdimm buffer cache configure MB  algorithm illustrate interference impact conduct data application separately concurrently mcf node multiple server node respectively normalize latency adopt quantitatively analyze performance obtain average latency workload calculate average statistic across workload normalize latency workload obtain average statistic across workload micro october columbus usa interference impact nvdimm device greatly influence efficiency storage data management demonstrate conduct data application heterogeneous storage detailed configuration described load balance scheme basil pesto LightSRM adopt manage data migration respectively scheme implement storage management mechanism manage nvdimm ssd hdd conduct data application concurrently mcf bus contention introduce significant storage data management overhead across load balance scheme assume traditional storage architecture exist workload performance model scheme fail accurately estimate nvdimm performance frequently trigger data migration nvdimm device therefore investigate performance model nvdimm device correspond optimization scheme alleviate interference impact nvdimm heterogeneous storage architecture environment scheme overhead node basil pesto LightSRM multiple node basil pesto LightSRM migration overhead without memory interference memory traffic nvdimm performance examine memory behavior nvdimm performance latency nvdimm memory intensity memory writes nvdimm performance periodically fluctuates memory traffic variation essential memory access cpu computation interleave application behavior reflect   memory writes per kilo instruction workload described identify behavior avoid unnecessary data migration reduce memory bus contention migrate data dram memory traffic storage device performance bus contention modeling nvdimm heterogeneous storage environment reduce unnecessary data migration critical construct performance model effectively efficiently predict performance nvdimm device memory bus contention issue utilize motivational illustrate relationship device performance workload propose performance model bus contention model machine implementation model verification relationship device performance workload characteristic performance variation data access characteristic device examine factor influence performance pcie SSDs synthetic trace  sort data application utilized analyze outstanding randomness obtain directly trace pcie ssd latency arises linearly outstanding operation increase reveals random operation latency become outstanding relationship device latency randomness nonlinear workload manifest randomness relationship latency randomness hdd device ssd latency varies linearly operation become random randomness operation increase overall rotational delay HDDs increase linearly nvdimm device latency tends linearly memory intensity nvdimm device bus contention delay increase linearly memory traffic hdd ssd data nvdimm device ddr interface hdd ssd device SATA pcie interface transfer data nvdimm device bus contention important factor predict nvdimm performance load balance parameter representative reflect relationship workload characteristic device performance workload characteristic role device performance illustrate workload characteristic role performance towards efficient nvdimm heterogeneous storage hierarchy management data workload micro october columbus usa device nvdimm performance influence memory intensity unique motivate model model relationship workload characteristic device performance performance model device performance affected factor factor impact device static model cannot predict device performance propose machine dynamically predict relationship workload characteristic device performance specifically blackbox model predict storage device performance function workload characteristic model workload characteristic WC input parameter output predict performance metric PP PP WC WC ratio  IOS rand rand ree ratio equation calculate storage device performance WC workload characteristic factor equation ratio ratio define percentage writes request  outstanding request IOS request rand rand percentage random access request respectively deduce random writes access address request access adjacent address request sequential writes otherwise request random access request ree ratio equation ratio specifically reflect GC garbage collection flash storage device invalid flash reclaim GC cliff seriously degrades flash storage device performance GC eliminate implementation preemptive approach limited GC trigger frequently cliff seriously affect performance ree ratio introduce reflect GC nvdimm device unlike previous model GC SSDs internal information provision ratio GC policy model prior knowledge ree ratio obtain training FTL activity leveling incorporate model FTL activity affect model performance investigate future construct model training data consist workload characteristic correspond performance storage device training data representative span spectrum sufficient adequate statistical machine algorithm capture mapping workload characteristic independent variable performance metric dependent variable approach training data input regression algorithm apply calculate predictive function input desire output bus contention model bus contention estimate predict device performance device performance bcd  ppd NV DIMM equation  device performance latency device response delay bus contention ppd predict device performance reflect device performance without bus contention calculate equation machine implementation apply performance bus contention model equation relationship workload characteristic device performance linear regression approach model relationship scalar dependent variable explanatory variable independent variable focus explanatory variable multiple linear regression regression obtain performance model linear regression performance prediction workload characteristic linear regression approach model relationship scalar dependent variable explanatory variable independent variable model satisfy requirement predict device performance multiple workload characteristic model verification demonstrate accuracy propose model model introduce noticeable computation overhead model aggregation model however aggregation model outstanding IOs linear regression model considers non factor linear regression model regression regression function generate recursively splitting input independent variable leaf node binary sequence leaf node predict dependent variable constant function independent variable recursively built manner node recursion building algorithm determines predictor variable training data split node leaf node split minimize difference deviation RMSD sample leaf node error difference sample average sample leaf node split leaf node sample ratio IOS ratio latency KB KB KB KB KB KB training sample micro october columbus usa ratio ratio IOS KB IOS KB ratio ratio IOS KB ratio ratio building regression sample training sample predictor variable ratio request ratio predict device latency predictor variable equation illustrative purpose splitting factor ratio request ratio however splitting ratio yield RMSD leaf node leaf homogeneous therefore ree ratio split node algorithm recursively performs subset predictor variable split multiple variable IOS split model verification comparison predict nvdimm performance nvdimm response verify accuracy propose bus contention model conduct hibench spec cpu mcf spec cpu chosen representative memory intensive application conduct environment described training data generate synthetic workload generator data workload workload characteristic input parameter generates series request nvdimm device workload access storage ree ratio 0GB data representative span spectrum sufficient adequate model experimental curve dot nvdimm performance memory traffic workload curve predict nvdimm performance model described equation denotes nvdimm performance without memory traffic latency nvdimm without memory traffic predict nvdimm response predict nvdimm latency nvdimm performance without mixed memory traffic model introduces loss accuracy limited frequent garbage collection error propose model negligible performance deviation bus contention nvdimm performance predict nvdimm performance predict bus contention status closely estimate nvdimm BASED heterogeneous storage management storage manager server pcie ssd SATA hdd memory controller SATA interface pcie switch dram DIMM nvdimm VMDK VMDK VMDK VMDK VMDK VMDK dram DIMM nvdimm VMDK VMDK underload VMDK VMDK overload VMDK VMDK VMDK VMDK candidate selection lazy data migration architectural optimization imbalance detection initial data placement overview propose scheme propose holistic optimize  heterogeneous storage hierarchy management overview propose scheme bus contention aware migration management address critical VMDK management namely initial data placement imbalance detection candidate selection optimization scheme propose alleviate migration overhead data migration architectural perspective respectively bus contention aware management initial data placement initial storage data placement  important reduce potential imbalance issue future workload placement effectively exploit advantage storage device eliminate unnecessary data migration initial data placement scheme aim VMDK onto storage device introduce minimum overall overhead trigger data migration achieve VMDK onto device minimum overhead min    equation device device VMDK  predict performance VMDK  performance device calculate accord equation towards efficient nvdimm heterogeneous storage hierarchy management data workload micro october columbus usa equation obtain average performance VMDK onto device device minimum average performance candidate however simply VMDK candidate device introduce data migration avoid data migration imbalance threshold described VMDK candidate trigger data migration predict equation remove candidate redo procedure migration occurs imbalance detection candidate selection aim distribute load proportionally storage device achieve goal detect imbalanced device candidate workload perform load balance performance directly reflect device status overload widely imbalance detection candidate selection traditional load balance however suitable nvdimm storage architecture directly performance attribute bus contention latency device performance predict workload performance calculate nvdimm performance   NV DIMM ppd  NV DIMM workload device ith workload device performance  calculate equation   denote workload device performance respectively ppw workload performance obtain accord equation ppw calculate predict nvdimm performance ppd max min maximum performance minimum performance respectively imbalance define max min imbalance detection scheme max predefined threshold data migration trigger candidate device minimum maximum load respectively perform data migration VMDK migrate device maximum load minimum load  performance bus contention latency disregard technique migrate VMDK relatively performance influence nvdimm device memory traffic fluctuation cancel relatively execution lazy data migration lazy data migration feature mirror technique benefit function address balance performance issue reduce memory bus contention migration scheme directly data location location mirror technique propose lazily redirect upcoming request location adopt technique upcoming request redirect location reduce unnecessary data transfer data propose benefit function migration function data migrate benefit guarantee data migration enhance overall storage performance migration bitmap utilized location data migrate migrate mechanism introduces performance overhead consumption acceptable nvdimm device GB KB data 0GB MB addition reclaim migration performance overhead negligible mechanism introduce complicate data lookup data location data migration induces non trivial performance overhead source destination dominant phase data movement propose scheme calculates performance source destination model described equation specifically data movement nvdimm device calculate      equation   consume migrate data KB source destination respectively   consume bus contention data source destination NVDIMMs respectively  migrate data volume spent migrate  obtain equation benefit data movement calculate benefit source destination device performance load destination load migrate workload calculation destination specifically equation compute benefit bene      migration respectively performance enhancement calculate predict source destination device latency processing data data migration   source destination device latency processing data   benefit calculate device performance enhancement data volume data migration  architectural optimization propose novel mechanism perform architectural optimization maximally utilize nvdimm device data migration specifically explore unique feature migrate data eliminate bus contention destination NVDIMMs cache pollution source NVDIMMs migration aware bus schedule destination NVDIMMs propose migration aware schedule police fully explore parallelism channel parallelism  NVDIMMs storage device nvdimm device data consistency valid another valid request persistent consistency vital persistent guard data corruption due crash failure primary consistency technique micro october columbus usa memory controller pending request memory controller FC FC RA MB RA FC RB MB RB FC RD MB RD FC MB FC RF MB RF FC RH MB RH FC RC MB RC FC RG MB RG FC FCFS schedule FC FC FC FC schedule policy regardless barrier schedule policy priority migrate data RA MB RA FC RB MB RB FC RD MB RD FC MB FC RF MB RF FC RC MB RC FC RG MB RG FC RH MB RH FC RA MB RA FC RB MB RB FC MB FC RF MB RF FC RC MB RC FC RG MB RG FC RH MB RH FC RD MB RD FC RA RB RC RD RF RG RH barrier request migration persistent request nvdimm controller flash controller DDRx cmd address bus DDRx data bus source flash data bus flash cmd bus flash buffer request queue flash flash FTL propose schedule police persistent update mechanism software journaling shadow update enforce writes hardware guarantee consistency flash NVDIMMs hardware cache controller buffer memory controller component respect barrier perform request however barrier persistent data sacrifice potential parallelism nvdimm illustrate persistent data parallelism baseline FCFS schedule policy request RA RB RH barrier memory controller RA RB RD RF RH flash channel FC nvdimm passing memory bus MB RC RG flash channel illustrates schedule algorithm respect barrier schedule scheme RB RC RD cannot issue RA barrier similarly pending RB RC RD RF RG RH consistency prohibits scheduler fully exploit available channel parallelism critical performance factor nvdimm architecture migrate data feature persistent data mirror another data migrate data migrate data easily recover mirror suffer failure treat migrate data non persistent data constraint schedule algorithm barrier restrict access sequence migrate data phenomenon optimal nvdimm dual role migrate data persistent simultaneously suppose request RA RB RF belong persistent others belong migrate data non persistent RH concurrently RA RH belongs migrate request observation propose schedule policy migrate data schedule regardless barrier barrier intend restrict request persistent memory controller schedule migrate request barrier constraint policy writes persistent prioritize writes migrate data prioritize request dependency chain barrier  multiple writes epoch creates dependency epoch epoch cannot execution precede epoch completes therefore schedule writes persistent presence barrier subsequent persistent writes available memory scheduler earlier thereby expose opportunity exploit channel parallelism schedule policy schedule policy reorder migrate normal writes migrate access location normal writes involve reorder migrate directly discard FC FC FC FC FC FC delayed issue non persistent barrier barrier persistent request request migration non persistent barrier RA MB RA FC RD MB RD FC RF MB RF FC RH MB RH FC RC MB RC FC RB MB RB FC MB FC RG MB RG FC RI MB RI FC RA MB RA FC RD MB RD FC RF MB RF FC RH MB RH FC MB FC RC MB RC FC RB MB RB FC RG MB RG FC RI MB RI FC RA MB RA FC RD MB RD FC RF MB RF FC RH MB RH FC MB FC RG MB RG FC RB MB RB FC RC MB RC FC RI MB RI FC non persistent barrier  issue schedule policy introduce delayed issue upcoming persistent request delay response migrate request undetermined illustrate issue address issue propose non persistent barrier mechanism  barrier migrate request issue NVDIMMs immediately insertion non persistent barrier perform memory controller memory controller monitor request transaction queue migrate request arrives predefined earlier persistent writes memory controller insert non persistent barrier respond migration request nvdimm controller FTL DDRx data bus DDRx cmd address bus source memory controller DDRx bus flash data bus flash cmd bus flash buffer request queue flash flash flash controller bypassing buffer cache migrate data buffer cache bypassing source NVDIMMs data migration load balance affect ratio nvdimm towards efficient nvdimm heterogeneous storage hierarchy management data workload micro october columbus usa buffer cache impact nvdimm performance illustrates buffer cache traditional knowledge access request access data cached buffer cache access migrate request issue nvdimm controller deems data access future kick data data eviction trigger data buffer cache flash memory introduces extra data operation incurs lengthy garbage collection however migrate data access data redirect device enormous amount data VMDK migration heavily pollute buffer cache nvdimm performance severely degrade address issue propose bypassing mechanism classifies data migrate data normal data request directly transfer migrate data flash memory memory controller effectively reduce deleterious impact buffer cache greatly improves nvdimm performance implementation implement propose architectural optimization scheme request migrate data normal data request deliver storage manager nvdimm controller software layer request header utilized information migrate data request encode information virtual address convert IO request nvdimm memory access covert request header something memory controller logic identify pas information physical address address translation specifically OS modify knowledge connotation significant msb virtual connotation physical address msb address denote request migrate data request hardware layer augment memory controller command signal transfer request nvdimm controller evaluation experimental setup  DRAMSim  achieve  cycle accurate simulator  cpu simulation qemu emulator DRAMSim cycle accurate simulator memory  develop ssd nvdimm simulator adopt FTL ssd nvdimm controller memory trace  integrate DRAMSim trace data workload inject mixed memory traffic simulator integration DRAMSim  simulate nvdimm integrate heterogeneous storage management another simulation dram emulate nvdimm extra latency however factor impede simulation methodology internal structure nvdimm parallel component cpu ghz issue KB KB private MB private MB private memory controller memory channel dram DIMM transaction queue depth nvdimm transaction queue depth dram DIMM GB ddr chip rank active command command command precharge command precharge operation refresh refresh nvdimm GB mlc flash channel nand flash chip channel per KB latency latency erase latency synchronization buffer access latency request queue depth command queue depth MB ddr mhz interface ssd GB mlc flash channel nand flash chip channel per KB latency latency erase latency synchronization buffer access latency MB pcie interface hdd TB rpm rotational MB SATA  interface configuration reflect dram addition physical layout dram DIMM nvdimm reflect bus contention simulated therefore simulation adopt configuration simulated memory controller connects memory bus channel channel contains dram DIMM nvdimm dram DIMM nvdimm queue depth configure dram DIMM memory consists GB organize rank rank contains rank entry command queue memory controller buffer pending command request capacity nvdimm configure 6GB flash channel parameter ssd hdd device simulator described ssd simulator FTL adopt ethernet connection parameter standard NE NIC device model benchmark description bayes  file MB file  file MB file kmeans sample dimension  pagerank sort data wordcount data     mcf lbm milc configuration mixed workload summarizes workload combination evaluation typical server simultaneously computation memory storage resource resource application intensive data workload cpu memory intensive spec application jointly data workload typical workload behavior combine data workload spec cpu workload namely mcf micro october columbus usa lbm milc spec cpu workload chosen memory intensity   memory writes per kilo instruction workload evaluation adopt node server node multiple server node server node focus distribute storage architecture adopt hadoop cluster storage compute integrate server node server node equip ssd hdd nvdimm nvdimm device deployed server node VM execution architecture normal IO data pcie device local memory cache nvdimm device data deliver via memory channel propose technique various representative heterogeneous storage management mechanism basil pesto LightSRM experimental assign workload server randomly greedy manner balance arrangement allows focus evaluate performance management algorithm workload device baseline scheme recommend additional workload movement hdd ssd nvdimm hdd ssd nvdimm hdd ssd nvdimm normalize latency basil pesto LightSRM BCA hdd hdd  nvdimm nvdimm nvdimm hdd hdd  nvdimm nvdimm nvdimm hdd hdd  nvdimm nvdimm nvdimm normalize latency basil pesto LightSRM BCA hdd ssd nvdimm hdd ssd nvdimm hdd ssd nvdimm normalize latency basil pesto LightSRM BCA hdd ssd nvdimm hdd ssd nvdimm hdd ssd nvdimm normalize latency basil pesto LightSRM BCA device performance data workload mixed mcf node data workload mixed mcf multiple node data workload mixed lbm node data workload mixed milc node bus contention aware BCA management illustrates normalize device latency normalize slowest device latency initial placement plot data data migration performance improvement average average average basil pesto LightSRM respectively data workload node experimental multiple node exhibit trend average performance improvement baseline scheme BCA effective hdd ssd BCA reduce unnecessary data migration hdd ssd enhance performance hdd ssd migration threshold parameter evaluate impact increase migration overhead decrease however device performance becomes device performance become balance decrease memory intensity benefit propose scheme decrease mixed mcf mixed milc average memory intensity scheme accurately predict nvdimm performance reduce unnecessary data movement demonstrates bus contention important role nvdimm management impact bus contention data workload mixed mcf normalize overhead migration threshold basil pesto LightSRM BCA without lazy migration BCA lazy migration normalize overhead migration threshold basil pesto LightSRM BCA without lazy migration BCA lazy migration migration overhead node multiple node lazy data migration evaluate lazy data migration normalize migration server node propose bus contention aware scheme BCA without lazy migration migration overhead reduce average basil pesto LightSRM respectively baseline ignore bus contention inaccurately predict nvdimm performance enlarge data migration increase migration threshold reduce migration overhead greatly reduces trigger frequency data migration however threshold becomes device performance unbalanced overall performance improve lazy migration scheme reduce migration migration reduce average bus contention aware without lazy migration BCA without lazy migration achievement benefit propose mirror migration benefit migration mirror technique effectively reduce data reduce migration benefit migration eliminate resource contention memory bus contention accelerate migration procedure towards efficient nvdimm heterogeneous storage hierarchy management data workload micro october columbus usa architectural optimization baseline adopts schedule policy policy without barrier adopts schedule policy policy priority schedule migrate data adopts policy policy normalize speedup metric performance improvement data workload obtain throughput execute operation per cycle workload calculate average throughput across workload normalize speedup obtain throughput average throughput performance improvement propose schedule policy focus evaluate benefit schedule policy average performance improvement data workload average baseline policy performance improve average policy policy adopt performance improve average demonstrate propose schedule policy role accelerate performance data workload interact cache bypassing node multiple node experimental nvdimm buffer cache ratio  cache management cache ratio dramatically nvdimm receives request server node data migration amount data migrate nvdimm valid data evict buffer cache bypassing mechanism data migration occurs cache ratio stable performance improvement propose schedule policy bypassing scheme migration aware schedule policy bypassing cache management benefit nvdimm architecture aspect former increase parallelism later enhances cache ratio comb technique archive benefit overall performance enhance average performance improvement propose scheme bus contention aware management lazy migration architectural optimization load balance benefit nvdimm architecture aspect demonstrates integrate propose technique significantly improves performance average basil technique performance gain employ propose BCA technique propose scheme effectively reduce unnecessary data migration bus contention propose reduce migration impact memory intensive spec workload CONCLUSIONS novel nvdimm storage management technique architectural optimization overcome bottleneck data workload maximally optimize data management heterogeneous storage environment naively NVDIMMs server yield suboptimal due inaccurately predict nvdimm performance unnecessary data migration nvdimm device fully utilize NVDIMMs propose technique namely bus contention aware management lazy data migration architecture migration data workload demonstrate propose achieves performance improvement baseline scheme obtain implement technique linux DAX nvdimm performance enhance native memory