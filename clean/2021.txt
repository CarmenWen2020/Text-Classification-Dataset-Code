task parallelism parallel program model code annotation construct outline task pointer parameter access execute parallel asynchronously runtime capable infer honor data dependence relationship parallelization framework openmp  overhead related automatic dependence inference schedule task performance limit factor task parallel amortize overhead programmer usually parallelism leveraged finer grain partition runtime efficiency coarser grain partition severe core task spawn frequency preserve core starvation grows linearly mitigate researcher hardware accelerator improve runtime performance nevertheless cpu accelerator communication overhead hamper gain propose RISC architecture minimizes communication overhead HW task scheduler cpu task schedule software directly interact former custom instruction empirical evaluation architecture fpga prototype feature core linux capable rocket chip implement instruction evaluate prototype performance adapt nanos mature task schedule runtime benefit task schedule accelerate instruction developed phentos HW accelerate task schedule runtime task parallel program nanos RV nanos version average faster service baseline nanos program phentos faster geometric core nanos RV deliver speedup respect serial execution phentos speedup index task schedule rocket chip  interface picos RISC chisel introduction parallel program performance consequently efficient parallel software productive daunt task multi core heterogeneous recently become commonplace smartphones category software development tap potential improve rate task parallelism parallel program model allows task schedule runtime automatically schedule task available processor respect data dependency runtime library implement model automatically infer data dependency task execution information programmer annotation memory address task argue task parallelism understood technique  transform sequential imperative program dataflow representation elementary operation perform concurrently asynchronously input data become available others task parallelism task  algorithm instruction infers data relationship array processing accord data dependency task schedule automatic inference data dependency ompss openmp  correspond software runtime implementation nonetheless acknowledge software task schedule extract coarse grain parallelism cope workload involve task architecture core latency software runtime comparable task execution impact performance insufficient schedule throughput software runtime core become starve overhead due runtime latency central role degrade performance research sought improve maximum throughput task schedule resort hardware acceleration largely successful picos task schedule accelerator proven capable significantly improve performance task parallel program fpga accelerate task schedule substantially expands applicability task parallelism respect software runtimes cpu fpga communication overhead fpga rate reliance software driver access accelerator serious performance penalty prevent handle demand workload proposes architecture tightly integrates task schedule HW accelerator purpose cpu minimize communication latency reduce runtime overhead consequently increase performance application parallelize task schedule contribution prototyped task schedule functionality accelerator external cpu logic processor visible application custom instruction ruling fpga cpu communication latency architecture drastically reduces task schedule overhead meaning task schedule core rate architecture involve chisel integrate picos mature task schedule accelerator rocket chip source silicon proven multi core implementation RISC task parallel application performance platform adapt nanos software task schedule runtime target ompss program model developed lightweight highperformance task schedule runtime phentos scratch building upon lesson adapt nanos semantics custom instruction HW scheduler integrate VI increase maximum task schedule throughput closely related advantage previous task granularity constant task schedule program efficiently schedule core core constant workload task efficiently execute workload involve grain task delivers application speedup average respect scenario task schedule acceleration performance degradation analyze workload involve program structure II approach context related describes background IV detail propose hardware architecture describes software developed architecture task schedule application VI discus experimental setup remark vii II related researcher aware hardware acceleration task consist processor extension improve schedule dependence task  later openmp introduce task data dependency architecture propose reduce task graph management overhead hdl implementation architecture conceive developed hardware task queue accelerate dynamic schedule task dependency aim improve load balance core implement HW steal mechanism   argue software  runtime available deliver schedule throughput task parallel program scenario core conclude hardware acceleration propose task superscalar architecture aim improve schedule performance task dependency evaluate adapt processor simulator fed task parallel application trace domain  hardware architecture nexus accelerate  runtimes architecture optimize version prior HW task scheduler nexus although goal task superscalar encompass actual VHDL prototype precise performance evaluation HW task scheduler picos perform thorough exploration component performance program trace timing analysis picos VHDL implementation extend picos embed task schedule capable linux application zynq xilinx development platform confirm HW task schedule outperform software alternative  communication latency impact program performance picos VHDL implementation integrate rocket chip afterwards unveiled picos version picos nest task improve fpga cpu communication performance ass impact communication latency cpu HW task scheduler consequently performance report favorable report implementation picos picos moreover implementation succeed HW task schedule consistently outperforms SW task schedule important limitation program execute core dual core quad core fpga socs picos greatly improves upon picos fpga cpu communication scheme lifetime processing task processor cycle degrade performance grain task application overcomes limitation rocket chip enables program execution float enable core fpga choice zcu ES additionally embed task schedule logic processor fpga cpu communication latency eliminate reduce amount cycle schedule task magnitude respect previous accelerator greatly expands application efficiently handle task schedule background task schedule task schedule paradigm involves schedule elementary computational task processor accord dependence relationship activity typically coordinate software task schedule runtime accord paradigm task task generate proposition task writes memory raw dependence task writes memory writes  dependence task memory writes dependence rocket chip rocket chip  source chisel soc generator RISC capable emit synthesizable rtl code generate core multi core processor rocket core boom pipeline cache interconnects aspect tailor user define parameter rocket core rocket core source RISC implementation instantiate easy integration custom accelerator  interface  interface interface allows compliant accelerator cache coherent memory access expose user program custom instruction  instruction format described optional operand register encodes optional destination register operand respectively opcode instruction opcode finally  encodes desire behavior instruction identical opcodes trigger distinct accelerator functionality  opcode  src src dest custom format  instruction terminology subsection defines task granularity refers duration task task grain comparatively execution conversely coarse grain comparatively execution task retirement refers action program informs task schedule task execute flight task refers task currently execute pending task refers task submit execution task refers task inflight pending task consequently execute task submission refers action program request task schedule task task dependence graph maximum task throughput task task schedule retire per schedule overhead assume task payload instantly execute worker processor IV picos RISC integration architecture overview native task schedule rocket chip processor integrate picos task schedule accelerator introduces chisel module picos manager instantiate visible core picos delegate module implement  interface instantiate processor core additionally picos manager decouples cpu api HW scheduler consequence architecture custom instruction integrate HW scheduler picos simplify architecture overview picos rocket chip architecture task schedule functionality picos expose core custom instruction implement core specific  picos delegate instance  acc stub instance interact picos mediation picos manager implement logic ensure atomicity picos cpu transaction reduce submission packet CPUs compress null packet arbitrate distribution packet core chisel queue rocket chip correctly interact picos queue implement handshake protocol buffering picos cpu transaction hiding picos downtime future picos manager develop optimization task schedule aware cache prefetching faster parameter passing task etc software interface goal develop schedule overhead leveraged picos task dependency faster software runtimes communication latency task schedule application picos minimum communication latency limited latency picos cpu dedicate datapaths bypassing memory provision custom processor instruction request task schedule functionality existence instruction simplifies construction middleware task application underlie task schedule hardware avoid additional software overhead picos manager auxiliary picos delegate opt instruction non instruction retire task context instruction return description submission request informs core execute instruction attempt submit task submit packet submits submission packet submit packet submits submission packet task request request task packet global queue queue execute core fetch SW ID queue execution core empty return SW ID relative queue fetch picos ID queue execution core empty SW ID relative queue already fetch return picos ID pop queue retire task informs retirement task picos ID  custom task scheduling  correspond transaction picos manager core execute instruction instruction non freedom runtime application programmer picos accept task task cannot action related instruction return failure flag program quickly failure allows runtime programmer core amount perform alternative action request context switch operating additionally non instruction eas development deadlock discus subsection IV retire task instruction picos retirement signal capability reporting failure useless reduces compiler register pressure non version instruction register available instruction execute instruction implement picos delegate described typical scenario execution task parallel application core issue submission request assume task dependency executes submit packet packet encode task dependency core possibly issue task request private queue eventually picos manager picos manager task global queue previous task request core chronological trivially satisfied request previously issue pop data global queue encodes entry private queue core core issue fetch SW ID SW ID core task submission finally core execute task issue retire task ensure picos remove task task graph possibly task execution avoid deadlock non instruction previously mention ensure submission fetch instruction non eas development deadlock scenario instruction deadlock discus avoid deadlock scenario submission instruction suppose thread execute task submit task picos suppose successfully executes task request fetch task fails fetch SW ID finally suppose latter instruction execute picos manager core specific queue descriptor submission related instruction submission request submit packet submit packet recover submission submission request buffer internal data structure picos picos manager become available buffer data structure task descriptor core specific queue execute consequently perform submission related operation situation succeed consumes core specific queue stall deadlock scenario request instruction suppose thread execute task submits task picos suppose prior execution task request rout queue fetch arbiter task request instruction issue rout queue nonetheless queue descriptor picos  queue rout queue deplete task distribute task request execute return task available task submission succeed submission task fed picos manager none deadlock deadlock scenario avoid manner opt submission fetch instruction non allows thread responsibility generate task freely switch role alternatively instruction atomic variable ensure thread multiple role perform action related role pending action regard role approach software complexity slightly performance due atomic memory transaction task ID task ID deps address address directionality dep address address directionality dep dep dep packet header zero pad picos encode task data dependency task described packet task data dependency packet zero packet submit task schedule runtime picos manager zero packet append submission handler picos picos module responsible task schedule functionality communication interface queue information task task graph submission queue inform outside task execute queue inform task retire retirement queue chose picos instead picos prompt access picos picos display exactly performance cpu scheduler communication scheme effectively replaces asynchronous communication module picos faster picos interested explore nest task picos implement picos replace picos picos straightforward HW interface gain report reflect advantage previous propose architecture  picos literature picos delegate ISA extension interface define architecture implement picos delegate instantiate core accelerator implement custom instruction submission request issue submission packet software core issue submission request packet submit serf purpose submission packet core picos packet relative later submission core allows infer zero packet picos non zero packet picos packet non zero packet task data dependency zero packet null packet automatically generate picos manager relevant picos delegate sends non zero packet submit packet picos delegate fulfills submit packet instruction simply register operand picos manager responsible packet picos submit packet submit packet instruction variation submit packet submits packet submission packet retrieve operand register instruction useful reduce amount cycle submit task non zero packet picos task descriptor multiple task submission accomplish without resort simpler packet version instruction task request picos delegate access queue picos pop content core specific queue inside picos manager picos manager packet picos private queue request picos delegate issue request upon decode task request instruction request core queue picos manager guaranteed later task request core satisfied consequently picos manager distributes  task task request core fetch SW ID suppose core private queue issue fetch SW ID instruction empty picos delegate instance core fulfills instruction return failure otherwise fulfills instruction return SW ID encode queue internal flag signal pop fetch picos ID suppose core private queue issue fetch picos ID instruction empty previous fetch SW ID instruction succeed retrieve SW ID encode fulfills instruction return picos ID encode pop reset internal flag previous fetch SW ID instruction empty previous fetch SW ID instruction succeed retrieve fetch picos ID return failure internal picos manager retire task picos delegate fulfils retire task instruction payload operand register robin arbiter picos manager operation retire task instruction succeed arbiter mediate transaction core frequently retirement packet away picos consumes retirement packet internal retirement queue packet serialize robin arbiter picos manager submission request  zero  buffer submission handler protocol trigger logic submission packet picos submission interface diagram submission handler module instantiate picos manager transmission task descriptor picos submission robin arbiter submission handler fetch arbiter packet encoder  queue per core queue task submission request fetch request submission interface retirement interface picos interface  interface protocol protocol task submission request fetch request submission interface retirement interface internals picos manager module picos manager allows communication picos core specific picos delegate without modification picos interface additionally improves performance convert compact submission packet sequence picos delegate packet picos compliant submission packet sequence packet interface picos manager picos core specific picos delegate core specific interface replicate core queue retirement queue submission queue submission request queue fetch request queue picos interface retirement submission queue finally debug interface omit simplicity output signal encode error omit structural described picos manager comprises robin arbiter submission handler fetch arbiter protocol module packet encoder core specific queue discus behavior implementation submission handler submission handler detail module handle processing submission packet behalf picos manager serf purpose submission packet sequence core interleave picos task submission atomically enable faster submission operation automatically pad non zero submission packet sequence zero packet packet sequence picos implement protocol logic standard chisel queue employ rocket chip adequately interact submission interface picos achieve goal submission handler relies arbiter core transmit submission packet picos access picos submission interface transfer core specific submission buffer transmission sequence finally zero pad packet sequence implement zero  module fetch arbiter fetch arbiter responsible distribute task descriptor core accord request data implement arbiter  available rocket chip source stock library module additional abstraction logic protocol module module standard chisel queue employ picos manager correctly interface task retirement task interface picos ensure picos queue standard chisel queue correctly interact spite former non  latter  packet encoder module compress task encode packet picos task packet central task queue robin arbiter standard chisel module arbitrates multiple producer consumer connection robin fashion merge task retirement signal core retirement interface picos core specific queue buffer picos ID SW ID tuples task picos manager contains instance buffer core buffer ensures scenario plenty task cycle latency fetch picos packet  task hidden application fetch correspond data cycle  instruction fetch SW ID fetch picos ID  tightly  task scheduling runtimes purpose evaluate performance linux task schedule runtimes nanos SW mature task schedule runtime target ompss program model phentos performance task schedule runtime scratch endeavor useful capable ompss comply task parallel application generate nest task iteration picos integrate develop minimal runtime opportunity avoid source SW overhead identify nanos easily remove without library discus runtimes built tightly integrate task schedule accelerator contribute improve performance respect nanos SW building nanos RV nanos SW nanos software runtime ompss program model maintain barcelona supercomputing easily accommodate feature plugins dynamically link core environmental variable  argument important task parallel construct automatically infer data dependence introduce ompss model integrate openmp plugin interface nanos developed nanos module capable offload data  computation picos custom instruction implement architecture plugin activate NX args environment variable NX args deps picos custom instruction submit task descriptor picos fetch  task inform picos retire task picos dependence infer plugin replaces default plugin achieves software refer nanos plugin nanos SW nanos picos plugin nanos RV nanos modularity price plugin interface relies heavily virtual function implement policy orient extra memory access task submission retirement fetch additionally nanos code mutexes conditional variable coordinate access data structure performance penalty related moreover task identify picos immediately schedule core fetch correspond task descriptor redirect scheduler singleton descriptor fetch core task queue core access inefficient VI  substantially faster nanos SW overhead issue motivate implement runtime enforce optimization target architecture phentos runtime phentos goal avoid non IO syscalls related mutexes conditional variable minimize cache invalidation per submission minimize cache per  minimize function overhead runtime api  application code mitigate cache bounce minimize writes atomic variable avoid false cache aware data pack phentos implement header  library spirit  boost library allows phentos api inlined application code compiler comply goal phentos data structure thread task metadata array array task metadata descriptor atomic counter task retirement implement  construct task parallel application avoid false contribute minimization cache invalidation per submission goal task metadata array implement corresponds cache sufficient fifteen task dependence respectively pre processor macro accord task parallel application employ phentos phentos active task metadata array access thread  correspond thread obtain identifier fetch SW ID instruction described IV consequently mere thread compete data deems synchronization artifact mutexes conditional variable unnecessary context contribute goal widely spin lock thread frequently verify memory frequently update thread cache bounce combine memory access cache traffic relevant core dominate operation transmit data memory modify core monitoring performance participate core quickly degrades cache interconnect bandwidth available memory access additionally individual update contend longer writer fetch update content writer perform update specially problematic multi core implement MESI coherence protocol rocket chip platform prototype protocol dirty cache directly communicate cache instead dirty cache communicate cache memory avoid spin lock strategy employ implement phentos minimize contention atomic counter task retirement involves core private retirement counter freely update core update atomic counter private counter non zero  failure counter update perform spin lock thread monitoring atomic counter variable cycle  task parallel application fulfills goal finally compact cache task metadata representation employ phentos allows task metadata task fetch cache transfer contribute goal VI experimental evaluation evaluate hypothesis phentos usually performance nanos RV nanos SW nanos RV usually performance nanos SW performance gap runtimes decrease task granularity increase verify hypothesis implies architecture described IV succeed accelerate task schedule workload hypothesis implies performance gain architecture significant grain workload methodology performance task schedule runtimes HW assistance evaluate input task granularity benchmark described sub subsection VI useful assess relationship task granularity performance gap runtimes processor parameter influential benchmark performance described sub subsection VI parameter rocket chip prototype core processor KB core specific cache coherent data instruction cache implement MESI protocol cache absent meaning data movement mediate memory consequently performance specially sensitive inter core synchronization cache mitigate memory mhz modify rocket chip mhz benchmark execute minimal SMP capable linux image benchmark version serial compile optimization strength ompss application compile  compiler  benchmark version target serial phentos execution compile gcc optimization strength serial version benchmark nanos SW nanos RV phentos speedup serial execution exceed factor brevity compile task parallel application speedup correspond execution serial binary benchmark performance evaluate program domain described blackscholes application financial analysis domain solves scholes partial differential equation evaluate price european style option varies underlie asset implementation code parsec ompss gitlab repository augments parsec benchmark suite offering ompss task implementation benchmark highly data parallel application  jacobi application fundamental linear algebra domain solves pseudo random sparse linear jacobi iterative equation solver poisson equation dimension program derive implementation  benchmark suite deps  program micro benchmark evaluate performance handle memory intense computation routine copying data memory array http bsc gitlab benchmark parsec ompss version array etc benchmark compound operation complex scheme data dependency target parallelization task schedule implementation benchmark ompss github repository benchmark execute input task granularity frequently achieve partition input matrix arbitrary analysis nanos SW nanos RV phentos benchmark performance available runtimes relevant benchmark input performance nanos RV custom task schedule instruction generally superior nanos SW instruction geomean speedup respect latter additionally normalize performance phentos almost  generally nanos RV gain synchronization intra core communication overhead version nanos geomean speedup respect nanos RV geomean speedup nanos SW nanos SW nanos RV increase benchmark option generally increase performance frequently phentos difference runtimes probably phentos generates schedule overhead runtimes task schedule overhead reduction increase meaningful reduce generate task possibly reduce available parallelism amplify load balance benchmark implement increase cache usage deps  performance increase runtimes increase program define fix derive theoretical speedup bound MTT described subsection maximum task throughput MTT maximum task specific uniform workload task schedule platform execute per metric important task schedule defines constraint task granularity core efficiently service core task schedule runtime MTT inequality http github com bsc ompss  texec texec fix task  average core actively task fed task schedule runtime consequently derive speedup bound MS function task MS task schedule overhead experienced task lifetime MS define function texec MS workload task schedule overhead nanos RV phentos previous task schedule picos implement picos cpu communication asynchronous axi transaction dedicate dma communication module clearly extent picos RV phentos reduce lifetime task schedule overhead workload phentos lifetime overhead reduction respect  nanos RV reduction measurement  benchmark task generates independent task monitor pointer parameter task chain generates interdependent task data dependence chain task monitor pointer parameter similarly task chain dep equation evaluate maximum speedup bound various task schedule platform function task reduce lifetime overhead phentos substantially improves MTT maximum speedup respect platform task concretely task around cycle  maximum speedup phentos platform platform maximum speedup moreover task around cycle maximum speedup phentos already saturate available core whereas platform fail deliver maximum speedup task granularity  VI task greatly influence maximum speedup task schedule deliver correspond serial execution discussion speedup task schedule platform respect MTT platform task cycle  speedup TT der   speedup cor phentos ano RV ano axi ano SW theoretical MTT derive speedup bound task schedule platform core task dep task deps task chain dep task chain deps phentos nanos RV nanos axi nanos SW task cycle lifetime task schedule overhead platform rocket chip equivalent cycle nanos RV phentos platform correspond described data nanos axi derives recent picos measurement report latter perform cortex quad core processor report ratio average instruction per cycle metric cortex rocket chip report consequently nanos axi report described correspond serial execution depends task data correspond benchmark execution report resource utilization II showcase resource utilization relevant component task schedule sub picos picos manager delegate resource octa core soc cpu core relatively HW module production grade soc feature core cache hierarchy module usage description core core FPU  float dcache cache core icache cache core  picos picos manager delegate II resource usage breakdown fpga CELLS task cycle speedup speedup ser  ver  task cycle speedup speedup ano SW task cycle speedup speedup ano RV phentos ano RV ano SW speedup program platform respect correspond serial execution equivalent MTT platform blackscholes jacobi spar  str eam str eam deps ano SW ano RV phentos normalize benchmark performance input runtimes task cycle speedup phentos task cycle speedup ano RV task cycle speedup ano SW experimental speedup data task schedule application correspond serial execution theoretical MTT derive bound MTT derive task chain execution involve monitor pointer parameter par task vii conclusion propose architecture capability task schedule accelerator available task schedule runtimes latency custom processor instruction dedicate accelerator cpu interconnects previous rely MMIO cpu accelerator communication greatly reduce lifetime schedule overhead proportional gain application speedup validate propose architecture linux capable core fpga prototype rocket chip popular soc generator feature  linux capable multi core processor evaluate performance gain task parallel program execute ompss task parallel benchmark nanos SW widely available ompss runtime HW acceleration nanos RV nanos SW architecture phentos completely lightweight performance task schedule runtime  allows application achieve average speedup respect execution nanos SW phentos delivers average speedup baseline gain latency task schedule capability lifetime schedule overhead respect nanos SW reduce nanos RV phentos