bug multi thread program unintended data detection data facilitate programmer explicitly specify intend verify compliance intention novel dynamic checker approach   prevents global unless program explicitly specifies policy permit policy enforce shelf hardware mechanism specifically  conventional MMU performance optimization exploit memory protection MPKs recently ISA policy dynamically unordered unordered access detect  happens policy verify implement  program evaluate benchmark thread  memory overhead benchmark overhead remain  performance overhead exceed benchmark overhead CCS CONCEPTS software engineering synchronization software debug virtual memory keywords data detection concurrency memory protection introduction data concurrency bug data unintended hence motivate limitation various alternative approach detect data programmer specify intend annotation detect access violate intention approach simplify reduce overhead data detection approach autonomously differentiate access correspond intend violate intention data detector closest SharC  refer DCOP dynamically ownership policy combination static analysis software instrumentation memory access novel  prevention unintended program similarly annotate detection unintended implement shelf hardware  rely static analysis overhead software instrumentation normal memory access  allocate statically dynamically annotation indicates policy private accessible thread potentially readable thread subsequently policy annotation policy  accessible thread annotate program extra burden programmer prior positive indication programmer willing annotate program purpose logically  policy per thread access permission enforces permission without normal memory access ideally enforcement perform specialized hardware efficiently grain memory protection variable contribution  efficient implementation mechanism shelf hardware utilize protection  protection data detection however  address data thread acquires lock another thread access without acquire lock  cannot detect data furthermore  incurs overhead lock repeatedly access thread thread perform conflict policy operation unordered concurrent vector frame epoch unordered conflict access data detect simply policy violation  identifies conflict unordered policy operation utilize  algorithm perform happens operation micro october columbus usa  zhou  tamir policy operation program normal access hence performance overhead perform  dramatically mechanism  access potential enhance dynamic detector relies explicit policy  implement straightforward manner thread implementation significant OS kernel involve memory overhead multiple importantly implementation involve performance overhead policy synchronously update critically lock acquire release  avoids disadvantage novel memory protection MPKs recently ISA multiple additional optimization reduce performance memory overhead straightforward implementation evaluate   TSan TSan widely maintain data detector gcc advantage TSan  annotation comparison benchmark thread performance overhead additional execution relative stock application TSan  furthermore  overhead exceed application application TSan slowdown exceed maximum overhead  application detection neither TSan  false positive identify false exclude due standard library  detect data detect TSan deployment scenario  production TSan restrict offline debug evaluate  benchmark mention thread application dynamically allocate maximum virtual memory overhead additional virtual memory relative stock application  remain benchmark virtual memory overhead negligible performance overhead benchmark due rate policy benchmark performance overhead thread  detect data mention detect TSan contribution novel technique  MPKs efficient data detection prevention unintended couple happens policy optimization increase detection accuracy reduce memory performance overhead enhance annotation kernel software cache universal hash function analysis source overhead  effectiveness optimization comparison  closely related annotation detector scheme TSan overview policy annotation framework  approach prevent unintended access permission protection domain detailed description implementation various optimization potential impact experimental setup evaluation respectively summary limitation disadvantage  implementation related overview  data detection mechanism detection violation explicitly specify intend issue intend specify violation intention detect core policy  permit policy described avoid hiding data combination policy operation perform thread concurrent happens operation detect situation described  relies hardware enforce protection domain detect unintended facilitate efficient implementation  addition core policy sticky lock explain specific scenario lock policy false negative undetected overview  mapping policy access permission ideal protection domain implementation shelf hardware described execution  dynamic data detector detect code actually execute however  pseudo completeness define sufficient execution  eventually detect data  synchronization operation explicitly identify pthreads operation currently core policy policy core policy  essentially identical DCOP global potentially  associate policy henceforth refer tracked core policy private  inaccessible untouched private refer policy private similarly etc additional policy sticky lock respectively private accessible thread  potentially readable thread  accessible thread policy intentionally  synchronization lock variable inaccessible accessible thread untouched becomes private thread access initial policy  data detection hardware prevention unintended micro october columbus usa    rel    rel code data policy correctly annotate possibility detection failure execution interleavings specify static declare dynamically allocate static annotate untouched allocate dynamically standard api malloc private invoke thread  policy allows incorrect annotation hide however standard policy remove internally synchronization without  incorrect annotation cannot false negative incorrect annotation false positive however eliminate annotation atomics currently execution intend accessibility private later become multiple thread hence  runtime policy operation acquire release operation thread private thread release association thread similarly acquire release operation disallow thread reading thread cannot another relinquish access thread acquire untouched inaccessible lock thread similarly thread acquire untouched inaccessible lock private thread thread release thread becomes inaccessible untouched inaccessible  ensure policy simply enforce policy guarantee data detect thread private release permission later without intervene synchronization operation another thread acquire scenario limitation prior data detector detection policy violation  detects conflict concurrent policy  algorithm happens specifically thread exclusive access  deployment  acquire release writes acquire release happens perform policy combine hardware enforcement policy significantly reduce performance overhead conventional mechanism happens without incur false negative happens policy ideal implementation  precise false negative positive without instrumentation normal access drawback happens memory overhead tracked overhead particularly  mitigates overhead introduce sticky policy thread sticky sticky policy hence perform compromise soundness avoid false negative policy sticky happens guarantee thread  enforces constraint flag violation enforce protection domain  prevents unintended associate global logical protection domain   denotes address thread access permission access permission thread policy enforce assign access permission   implement software instrumentation normal memory access excessive performance overhead ideally  implement hardware enforce granularity variable protection domain overhead associate protection domain increase domain increase motivates   enforce protection domain  multiple epd regardless physical location thread   private thread epd policy untouched inaccessible  sticky  policy mapped epd consolidation   impact soundness   epd consolidation impact soundness strictly enforce requirement thread acquire thread performs acquire thread  detect data thread writes private later another thread finally thread intervene synchronization fortunately reading thread execute code none thread thread perform acquire possibility data detect DCOP core annotation critical policy access private inaccessible policy private incur prohibitive overhead hence  lock policy associate specific lock multiple associate lock micro october columbus usa  zhou  tamir lock accessible thread lock associate  lock lock mapped epd policy lock writes policy lock thread associate lock access access unordered respect prior access policy lock thread performs policy operation lock  actually inaccessible epd hence access trap  verifies access perform thread lock access  respect policy verification succeed epd associate lock subsequent access lock data access lock lock access thread associate lock policy lock respect access lock verify involve happens access lock performance  avoids normal access hence execution implementation  fail detect access lock unordered respect policy lock possibility fail detect data implementation  usable widely available shelf hardware development  motivate introduction memory protection MPKs intel ISA describes implementation  motivate evaluate optimization subsection describes straightforward implementation shelf hardware modification OS thread subsection deficiency straightforward implementation  optimization mitigate impact deficiency remain subsection implementation  implement  protection specifically epd implement access permission access permission described straightforward implementation thread standard OS kernel thread implementation kernel memory subsystem implementation access permission enforce granularity hence tracked policy virtual tracked virtual policy memory tracked policy future virtual  tracked upon creation statically allocate script modifies alignment global assembly file  modify functionality function malloc due glibc heap allocator handle metadata suitable  instead  link application tcmalloc heap allocator dedicate memory metadata  implementation local allocate stack lock acquire release operation access permission lock accessible thread acquire appropriate lock  utilizes wrap option linux linker intercept pthreads synchronization operation functionality alignment requirement dynamic memory allocation enforce  incurs storage overhead metadata tracked synchronization execute thread tracked metadata consists byte byte happens storage overhead synchronization execute thread mostly vector synchronization execute thread typically related storage overhead insignificant address deficiency straightforward implementation thread significant OS kernel memory subsystem properly synchronize incurs significant overhead operation perform  permission performance overhead exacerbate item relevant operation acquire release lock allocate dynamically allocate policy allocate tracked incurs substantial memory overhead due internal fragmentation remain waste permission management MPKs straightforward implementation  deficiency largely alleviate memory protection MPKs recently ISA optimization focus subsection MPKs virtual tag entry protection domain domain per thread user accessible register PKRU access permission protection domain thread access permission access access access access memory succeed entry permission PKRU correspond protection domain permit access MPKs enable user program modify memory access permission thread without overhead mprotect linux specifically perform simply content PKRU register experimental platform PKRU register approximately latency mprotect thread respectively  data detection hardware prevention unintended micro october columbus usa   MPKs eliminate specifically access permission thread  content PKRU register MPKs reduce overhead acquire release lock specifically lock mpk domain thread appropriate PKRU register access default PKRU register thread prevent access lock acquire operation augment modify PKRU register thread access thread acquires lock actually release lock lock release operation PKRU register restore  prior lock acquire lock acquire release operation perform without mprotect ctrace benchmark demonstrate MPKs  ctrace lock protects hash access frequently multiple thread setup lock protects without MPKs  implementation invoke mprotect twelve critical entry exit approximate execution ctrace implementation  without mpk optimization delay thread acquire release lock latency mprotect invocation execution thread  execution stock version increase version without mpk optimization execution increase factor    inaccessible untouched domain domain normal permission access permission appropriate policy access epd private thread epd lock lock epd epd mapped mpk domain chosen domain domain mpk domain memory tracked private lock   thread IDs lock address respectively mpk domain limited MPKs sum thread lock exceeds mpk domain available private lock   hash thread IDs lock address domain obviously multiple  mpk domain hash collision hide data lock address domain thread ID thread access without acquire lock address lock mpk domain thread IDs thread domain  mechanism mitigate subsection sum thread lock instance occurs probability detect hash function occurs probability instance detect however probability instance basis  mechanism mitigate hash collision  periodically hash function universal hash function mod prime linearity expectation input thread IDs lock address mpk domain hash function input upper bound probability collision hash function bound useful  upper bound due hash collision encounter occurs multiple program detect later another hash function hash function chosen program executes execute program multiple ensure detection occurs program implement timer periodically interrupt thread generate hash function signal thread thread iterates metadata tracked mpk domain private lock reset hash function thread signal thread resume execution hash function application thread initialize PKRU register protection domain private domain domain correspond lock currently thread facilitate operation  runtime maintains lock currently thread finally thread return user application entire rehash procedure effectively atomic thread duration effectiveness rehash mechanism demonstrate hash function performance overhead rehash negligible reduce memory overhead array  memory overhead directly related tracked due fragmentation deficiency metadata array policy tracked allocate implementation  incur prohibitive memory overhead focus memory overhead  scenario reduce reduce overhead metadata incrementally increase metadata demand reduce impact fragmentation memory mapping annotation specify array slice within slice policy metadata address optimization array metadata structure policy slice array modify metadata structure allocate slice micro october columbus usa  zhou  tamir optimization reduces memory overhead array structs policy epd optimization mapping multiple contiguous virtual physical allocate virtual offset physical memory waste consecutive mapped consecutive address physical memory refer array struct optimization apply split array split struct respectively unfortunately linux memory subsystem implementation mapping incurs prohibitive performance memory overhead platform empirically mapping practical limit hence optimization suitable array optimization facilitates efficient handle array exceeds mapping limit suitable application array array slice policy runtime function allows programmer specify slice array allocate slice handle tracked array allocate manage slice array split struct split array slice array member virtual address generate standard compiler prototype implementation modify application source code split struct pad manually insert struct definition split array slice array script replace reference array macro computes memory address metadata slice array array index slice access slice array code index memory address metadata array reduce performance overhead access per thread software cache maintain slice array cache recently access slice demonstrate potential benefit software cache micro benchmark iterates integer array consists slice software cache reduces execution overhead  reduce permission overhead focus optimization mitigate performance overhead deficiency recycle recently freed tag domain eliminate unnecessary remote tlb shootdowns upon allocation dynamically allocate epd protection domain tag correspond entry PTEs freed domain tag correspond PTEs restore freed reuse application component standard library annotate  optimization reduces pte associate allocate operation protection domain  maintains software cache domain cache contiguous consist allocate cache freed cache allocate cache cache without cache domain tag cache   effective reduce overall overhead swaptions without   increase execution factor thread respectively optimization overhead  optimization reduces performance overhead tlb shootdowns PTEs PTEs flush tlb cache multithreaded program PTEs cached TLBs multiple CPUs tlb consistency ensure broadcasting IPIs inter processor interrupt core flush stale PTEs IPIs incur significant overhead thread increase limit scalability  optimization utilizes information  annotation identify stale pte possibly cached remote TLBs specifically private inaccessible cannot access remote CPUs correspond PTEs cannot cached remote TLBs policy operation apply ipi broadcasting optimization implement kernel modification local counterpart pkey mprotect entry pkey mprotect local version broadcast IPIs tlb flush policy invoked private inaccessible pkey mprotect invoked critical correctly thread migrate core hence application thread pin specific core pfscan illustrate benefit optimization originally thread execution increase respectively due pkey mprotect average respectively optimization pkey mprotect replace pkey mprotect average latency pkey mprotect thread respectively application execution increase respectively dependency pkey mprotect latency thread due contention kernel memory subsystem lock experimental setup perform machine  linux kernel version machine equip 2GB memory 3GHz intel xeon processor chip chip contains core MB cache benchmark ctrace multithreading debug library evaluate printing debug pfscan parallel file scanner evaluate dsn proceeding pbzip parallel version bzip file compressor evaluate compress 2GB file random content nullhttpd  webserver evaluate multiple client retrieve KB  data detection hardware prevention unintended micro october columbus usa file memcached memory cache evaluate workload ycsb KB request streamcluster blackscholes swaptions ferret  benchmark suite fft splash native input ctrace pbzip pfscan nullhttpd facilitate comparison SharC DCOP benchmark input execution maximum thread benchmark minimize performance skew disk input output file  thread pin dedicate core eliminate intrusion thread migration eliminate variable network latency nullhttpd memcached client program machine server program disjoint core  currently benchmark pbzip streamcluster swaptions fft verify performance affected remove operation distort performance measurement ctrace remove printf extensive activity replace  serializes thread customize scalable version remove unnecessary nullhttpd evaluation discover data information regard annotation source code validation rehash mechanism memory overhead performance overhead comparison  SharC DCOP TSan annotation code memory performance overhead discover data  detect data violation intend policy due detection conflict concurrent policy data ferret nullhttpd streamcluster memcached pbzip policy violation thread attempt private another thread remain relevant lock thread attempt access without acquire lock nullhttpd pbzip identify due detection conflict concurrent policy related customize synchronization code concurrent memory access standard prohibits access normal variable data insert code policy operation avoid  detect violation intend policy  detect conflict concurrent policy validate  benchmark TSan TSan detect  however related standard library function TSan version data detection function handle acquire  detect annotation overhead code  benchmark loc annotation ctrace pfscan pbzip fft streamcluster blackscholes swaptions ferret nullhttpd memcached annotation code  related data detector programmer annotate code subsection quantifies burden benchmark annotation overhead  loc code stock benchmark without blank comment cloc source code modification due pad split struct addition report script replace reference split array slice array macro script fft streamcluster blackscholes swaptions similarly annotation trial  approach benchmark  without annotation benchmark abort access analyze code annotation methodology annotation benchmark within exception streamcluster around due complicate almost spent code annotation understand code familiar hence task easy developer maintainer code annotation burden comparison annotation burden  DCOP SharC sum annotation code refer mod pfscan pbzip ctrace nullhttpd mod  DCOP DCOP burden DCOP lack lock policy insertion annotation access critical DCOP statically allocate default policy inaccessible oppose untouched  pfscan pbzip mod  SharC mod comparable  SharC  additional annotation function argument local variable function return unlike  SharC annotation micro october columbus usa  zhou  tamir access barrier annotation  significantly reduce annotation overhead program barrier streamcluster validation effectiveness rehash demonstrates effectiveness mechanism periodically hash function thread IDs lock address mpk domain data report detect violation intend policy detect ferret memcached pbzip streamcluster rehash interval thread benchmark execute execution benchmark report detect execution pbzip execution detect data remain occurs program exit rehash execution obviously increase potential impact domain collision thread IDs lock address mapped mpk domain furthermore application minimal thread trigger fix hash function data probability escape detection remain streamcluster performs multiple iteration input data iteration creates thread thread IDs terminate iteration consequently setup probability escape detection detect hash function per detection data execution relevant code execute multiple execution program periodically hash function data pbzip pbzip processing memory overhead  memory overhead evaluation effectiveness optimization mechanism memory usage  maximum virtual memory vsize resident execution benchmark maximum thread benchmark execute average report measurement variation stock benchmark link tcmalloc overhead  additional library memory fragmentation metadata measurement completely accurate due granularity tcmalloc allocates virtual memory application benchmark measurable overhead vsize swaptions memory overhead vsize max thread ctrace fft  pfscan   pbzip  mem ferret maximum tracked application thread memcached workload thread ctrace fft  pfscan   pbzip  mem thread ferret NA NA memcached workload ferret increase MB MB MB respectively vsize memory overhead increase negligibly thread report maximum thread explain  memory overhead directly related tracked due fragmentation metadata associate memory overhead explain maximum tracked application benchmark tracked memory overhead measurement procedure detect source memory overhead  however benchmark overhead due source negligible memory overhead due metadata calculate tracked metadata byte swaptions memcached ferret storage metadata KB MB MB respectively overhead negligible vsize overhead due happens metadata overhead significant portion overhead report metadata overhead  vector happens however benchmark due sticky policy  ferret benefit sticky policy multiple thread sticky policy metadata overhead ferret source memory overhead fragmentation memory overhead optimization technique benchmark opportunity benefit split struct split array optimization  data detection hardware prevention unintended micro october columbus usa memory overhead comparison additional memory percentage stock application  TSan max thread ctrace fft  pfscan   pbzip  mem ferret situation split struct struct member lock struct tracked benefit split struct ferret instance split struct useful array beyond limit handle split array optimization reduction memory overhead KB swaptions MB streamcluster benchmark effective memory overhead reduction technique slice array data parallel program fft blackscholes thread disjoint array slice array array without slice array memory overhead prohibitive memory overhead reduction fft without slice array TB memory array however slice array memory overhead negligible memory overhead comparison closely related annotation detector available evaluation configuration hence publish benchmark evaluate  SharC benchmark pbzip pfscan benchmark memory overhead  report memory overhead SharC negligible DCOP benchmark ctrace nullhttpd pbzip pfscan benchmark memory overhead  negligible report overhead DCOP enhance flag unordered policy memory overhead dynamically checked byte increase byte byte  extra metadata per oppose per fix benchmark evaluate  memory overhead advantage  memory overhead TSan evaluate TSan experimental platform due TSan implementation vsize measurement meaningless benchmark  memory overhead ferret  memory overhead weigh  dramatically factor performance overhead maximum thread TSan benchmark thread affect memory overhead pbzip pfscan TSan performance overhead performance overhead percentage policy rate thread policy rate per thread ctrace fft  pfscan   pbzip  mem mem ferret thread performance overhead NA NA NA NA NA NA NA NA policy rate NA NA affect execution characteristic TSan maximum memory decrease decrease thread memory overhead pfscan  thread pbzip maximum memory significantly stock application thread performance overhead performance overhead  performance optimization performance overhead  thread benchmark performance execution memcached nullhttpd maximum throughput report overhead average execution measurement varied NA indicates benchmark correspond thread benchmark performance overhead thread memcached ycsb workload overhead thread overhead thread ctrace memcached due frequent lock operation performance overhead modify PKRU register happens fft blackscholes overhead due additional spent access array slice array benchmark overhead due permission policy policy rate benchmark performance overhead  overhead highly correlate policy rate benchmark performance overhead happens insignificant exception ctrace memcached ctrace thread happens micro october columbus usa  zhou  tamir responsible overhead thread responsible nearly overhead memcached happens responsible overhead streamcluster pfscan overhead  highly dependent thread due linux kernel lock mmap sem serializes invoked thread directly quantify impact serialization mmap sem average spent streamcluster thread active invoked average latency operation thread latency  periodically hash function hash thread IDs lock address mpk domain latency operation contributes performance overhead  latency benchmark thread latency hash function memcached thread benchmark latency benchmark hash function associate overhead negligible significant factor latency hash function private lock factor affect spent reset protection domain memcached extreme lock performance overhead comparison SharC benchmark pbzip pfscan execute thread respectively report performance overhead respectively  correspond overhead overhead thread DCOP benchmark ctrace nullhttpd pbzip pfscan execute thread respectively report performance overhead respectively  closest correspond overhead significantly respectively  overhead thread explain modify ctrace nullhttpd obtain meaningful performance however comparison DCOP evaluate version ctrace nullhttpd unmodified ctrace  incur performance overhead nullhttpd thread DCOP report overhead cpu cycle  incur overhead cpu cycle throughput latency enhance flag unordered policy  performance overhead advantage specifically byte operation modify metadata multiple oppose  metadata per performance overhead comparison  TSan  overhead factor magnitude performance overhead comparison additional execution percentage stock application execution  TSan ctrace fft  pfscan   pbzip  mem mem ferret thread max thread reinforce argument  production TSan restrict offline debug LIMITATIONS  data detector  limitation disadvantage inherent associate tradeoff efficient implementation due implementation enhancement summarizes limitation disadvantage despite  currently implement useful important advantage exist detector disadvantage  annotation code furthermore  relies happens execution escape detection happens escape detection  implementation consideration motivate mapping   consequence epd introduces possibility fail detect limited specific scenario lock policy introduce performance optimization associate scenario policy lock  implementation relies virtual prohibitive memory overhead  optimization mitigate  generally memory overhead relative competitive scheme however optimization constrain limitation linux memory implement kernel overcome limitation  implementation relies MPKs potential due limited MPKs mitigate periodically hash function rehash mechanism highly effective probability due hash collision execution program pkey mprotect optimization thread pin core cannot performance overhead increase significantly  data detection hardware prevention unintended micro october columbus usa related variety data detection static analysis dynamic combination static analysis incur overhead normal operation data rarely execute code however susceptible rate false positive negative apply dynamic checker generally perform  analysis happens analysis instrumentation normal memory access potentially incur performance overhead technique rely customize hardware mechanism combine static analysis dynamic analysis reduce runtime overhead sample target potential production sacrifice soundness performance overhead accuracy generally performance overhead  unlike  continuously memory reference accuracy however sample annotation negligible memory overhead utilize protection facilitate data detection  protection detect access memory location frame  develops per thread identify multiple thread machinery memory access closest   dynamic detector overhead  comparison relevant     data report thread blackscholes streamcluster swaptions ferret mechanism incur overhead  overhead streamcluster thread overhead  overhead  closely related SharC  DCOP fundamental difference   hardware enforce policy  happens identify conflict concurrent policy false negative reduce overhead execution SharC static analysis enforce private  policy police enforce runtime memory access facilitate static analysis requirement impose policy reference policy pointer policy null requirement SharC apply data structure link  partially mitigates impact SharC restriction introduce concept policy atomically  barrier policy allows thread barrier operation however remain restriction dynamic policy increase burden programmer furthermore SharC DCOP runtime mechanism reference incurs performance overhead DCOP memory access enforce specify policy runtime static analysis eliminate redundant instrumentation core annotation  essentially identical DCOP furthermore DCOP sticky annotation however purpose  DCOP reduce annotation burden  reduce memory overhead difference annotation DCOP  DCOP annotation overhead  performance memory overhead conclusion decade development date detector technique widely precision soundness detect performance overhead memory overhead scalability burden impose programmer applicability various program useful subspace detector explicit specification intend identify violation intention infer intend potential reduce complexity increase precision soundness reduce overhead  advance subspace described introduce happens conflict concurrent policy novel feature  shelf hardware reduce performance overhead detect unintended aspect implementation  memory protection MPKs  universal hash function overcome limitation  implementation MPKs additional optimization enhance annotation OS kernel reduce memory performance overhead performance overhead  allows production evaluate  benchmark thread  detect comparison  exclude due standard library data  memory overhead benchmark  performance overhead exceed benchmark overhead target evaluation various optimization introduce extreme  novel MPKs reduces performance overhead factor additional annotation dramatically reduce  memory overhead