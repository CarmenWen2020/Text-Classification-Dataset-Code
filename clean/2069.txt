3D visual compute data spatially sparse exploit sparsity developed hierarchical sparse data structure multilevel sparse voxel grid particle 3D hash however develop performance sparse data structure challenge due intrinsic complexity overhead propose taichi data orient program efficiently author access maintain data structure data structure agnostic interface computation code user independently specifies data structure elementary component sparsity arbitrarily compose multi sparse data structure decouple data structure computation easy data structure without computation code allows user computation dense array compiler semantics data structure index analysis automatically optimize locality remove redundant operation coherent access maintain sparsity memory allocation generate efficient parallel vectorized instruction CPUs gpus approach yield competitive performance computational kernel stencil application lookup particle scatter demonstrate implement simulation render vision task simulation finite analysis multigrid poisson solver pressure projection volumetric trace 3D convolution sparse grid computation data structure decouple allows quickly data arrangement develop performance data structure tailor specific computational task code achieve performance average optimize reference implementation CCS concept software engineering domain specific compute methodology parallel program physical simulation introduction 3D simulation render vision task involve volumetric data spatially sparse hierarchical sparse data structure extensively effectively exploit sparsity fluid simulation multi grid fluid fluid spatial sparsity nest hash  pointer array grid performance code data structure daunt task due irregularity access active parallel imposes engineering challenge naively traverse hierarchy magnitude cycle essential computation troublesome spatially coherent access commonly stencil operation access hierarchical data structure traverse redundantly ensure load balance efficient parallelization allocate memory maintain sparsity access inactive data structure library guarantee performance code performance easily composable multiple library interface redundant costly traversal hierarchy unfortunately code complexity data structure potential pointer aliasing purpose compiler fail optimize library function achieve performance library usually expose interface user leaky abstraction computation code highly couple data structure propose program model decouples data structure computation achieve performance easy program user computation code data structure agnostic interface operating dense multi dimensional array internal data arrangement associate sparsity specify independently computation code compose elementary component dense array hash hierarchy compiler tailor optimization specify data structure component generates efficient sparsity memory maintenance code develop domain specific strategy optimize spatially coherent access index analysis derive information data layout access compiler analyzes access efficiently compute memory address cache strategy locality parallelizes vectorizes loop instruction programmer enable compact intermediate representation specially optimize hierarchical sparse data structure compiler generates code cuda code intermediate representation switch backends effortless computation stencil lookup particle splatting compiler generates code faster highly optimize reference implementation implement popular simulation graphic vision algorithm embed frontend finite kernel multigrid poisson solver sparse 3D convolution volumetric trace highly optimize reference implementation code average code faster geometric quickly explore choice data structure compiler generates performance code derive efficient data structure performance improvement previous highly optimize implementation simplify algorithm sec sparse data structure vector register inactive inactive      access active boundary active boundary cycle hash  array dense array cycle naive cyc vectorized cyc access connection reset allocate boundary allocate boundary vector register vectorized access multi sparse array significantly involve access dense array illustrates sparse array access stencil naive code usually inefficient hierarchy traversal costly problematic spatially coherent access traversal redundant optimize vectorized code leverage access locality amortize access sparsity handle boundary allocate memory code access tedious error prone code highly couple data structure decouples data structure implementation access compiler automatically generates optimize code access specific data structure user code access dense array freedom data layout sparsity representation without affect computation code acm trans graph vol article publication date november taichi performance computation spatially sparse data structure traditionally user writes data structure access code dilemma easy program performance goal achieve productivity library performance manually optimize code furthermore easy data structure user achieve performance explore data structure adopt efficient task model express variety data structure physical simulation render multi sparse grid particle dense sparse matrix assume hierarchy compile facilitate compiler optimization therefore directly model structure variable depth compiler source performance reproduce command visual simulated render program summarize contribution program decouples data structure computation sec unified abstraction multi dimensional index memory address abstraction allows programmer define computation independently internal arrangement involve data structure data structure description mini elementary data structure component compose sparse array static hierarchy sec optimize compiler index analysis information data structure automatically optimize locality minimize redundant operation coherent access manage sparsity generate parallelize vectorized backend code cuda sec sec thorough evaluation implementation graphic vision algorithm byproduct http github com  taichi   sparsity 3D compute task exhibit spatial coherency sparsity fluid simulation volume render lidar kinect scan obtain performance model spatial sparsity effectively utilize spatial coherency waste computational resource empty focus spatial sparsity data globally sparse locally dense sparse random aim develop performance program exploit spatial sparsity dedicate data structure goal expressiveness target application feature complex computational kernel stencil particle splatting ray voxel intersection therefore expressive numerical computation taichi allows user arbitrary sparse data structure construct branching loop distinguishes domain specific taco linear algebra performance computer architecture achieve performance exploitation locality parallelism however desire memory friendly parallel data structure usually task hardware dependent exist data structure library data structure completely performance issue productivity traditionally program sparse data structure manually handle memory allocation parallelization exception boundary library program achieve performance allows program sparse data structure dense compiler automatically generates optimize code knowledge taichi physical simulation complex data structure within code portability automatically generate optimize code hardware environment programmer access hardware sacrifice performance portability prefetch intrinsics CPUs warp intrinsics nvidia gpus acm trans graph vol article publication date november decision decision aforementioned goal non goal decouple data structure computation user code computation processing dense array explore sparse data structure without affect computation code achieve abstract data structure access cartesian index actual data structure define mapping index actual memory address sec regular grid building data structure entity regular grid easily flatten 1D array closely computer architecture linear memory address directly model irregular structure mesh graph multiresolution representation adaptive grid compose manually data structure hierarchical composition model spatial sparsity express variety data structure develop data structure mini compose data structure hierarchy sec mini elementary component dense array hash arbitrarily composable fix data structure hierarchy facilitate compiler optimization simplify memory allocation assume hierarchy fix compile octrees bound volume hierarchy dynamic depth stateof physical simulation data structure fix hierarchy   program multiple data SPMD sparse iterators adopt imperative SPMD model harness hardware vectorized instruction CPUs massively parallel gpus exploit sparsity computation kernel parallel loop sparse iterators active programmer expressive interface sparse computation generate optimize backend code automatically compiler generate performance backend code automatically optimize locality sec minimize redundant access access coherency sec automatically parallelize sec allocate memory sec user backend target architecture optionally schedule hint compiler generate optimize code taichi programming demonstrate 2D laplace operator frequently physical simulation image processing finite difference discretization operation 1D array vertex mesh graph define define computation decouple data structure computation abstract data structure mapping multi dimensional index actual access 2D scalar index internal data structure interface data structure library compiler analyzes access code minimizes redundancy across multiple access frontend embed computation usually define kernel loop active data structure non zero pixel voxels efficiently exploit data sparsity kernel contains imperative code operates data structure define aforementioned laplace operator kernel loop variable iterates active kernel laplace def expr expr auto loop active sparse computation taichi compiler automatically maintains sparsity reading inactive compiler return ambient inactive compiler automatically internal data structure allocates memory active specific kernel activation active interaction adopt program multiple data paradigm SPMD  cuda additional component parallel sparse loop multi dimensional sparse array accessors compiler hint optimize program schedule loop automatically parallelize vectorized typical statement loop user define mutable local variable var volumetric tracer complex sec construct inside computation kernel parallel loop sparse tensor var expr var std function loop expr expr std function access var index operator expr var expr expr cond std function expr cond std function std function var expr declare mutable local variable atomic atomic global acm trans graph vol article publication date november taichi performance computation spatially sparse data structure compiler hint schedule cpu parallelize int num thread multi thread vectorize int width loop vectorization gpu  int blockDim specify gpu scratchpad optimization  expr int int upper cache expr cache data gpu cache  expr discussion hint scratchpad optimization  cache  internal structure hierarchically computation code user specify internal data structure hierarchy specify data structure choice macro dictate data structure component nest sparsity micro dictate data grouped structure array array structure structural node decorator structural node compose hierarchy decorator structural node construct semantics dense fix contiguous array hash hash maintain mapping active coordinate data address memory suitable sparsity dynamic variable array predefined maximum serf role std vector maintain particle structural node morton reorder data memory curve morton cod potentially spatial locality dense  mask maintain sparsity information per dense pointer pointer instead structure memory maintain sparsity dense dynamic node decorator data structure component offs regard access consumption hash relatively access cpu cycle economical memory extremely sparse therefore suitable layer active dense array bitmask activate access quickly bitmask occupy  highly sparse define hierarchy user compose data structure component arbitrarily desire hierarchy explore offs compiler synthesize computational kernel execute specific sparse data structure programmer define data structure nest elementary component hash dense array kernel define iteration leaf voxels pixel independent internal data organization leaf immediate leaf quantum storage computation task code specifies fix 2D dense array global global layout auto index allocate structure array dense grid equivalent float float dense dense global declares dimensional sparse tensor tensor accessible kernel global variable layout lambda function describes data structure hierarchy index specify structural node denotes hierarchy dense structural node creates node dense twice creates structural node function argument specifies dimension specifies correspond dimension dense 2D dense array along index axis along axis assign global variable correspond data structure hierarchy equivalent style data structure definition comment code specifies structure array soa layout easily switch array structure AOS layout code struct node float node data auto node dense node node equivalently dense dense node contains twice dense node syntactic acm trans graph vol article publication date november hash ijk dense ijk pointer dense ijk 3D  style structure configuration hash allows negative coordinate access user unbounded domain dense ijk morton  dense ijk flag 3D  occupy voxels bound data structure relatively shallow leaf access relatively hierarchical particle bucket leaf contains index particle within dynamic particle particle particle particle hash ijk dense ijk pointer dense ijk pointer dynamic particle index  unbounded shallow data structure  morton cod   combine hash ijk dense ijk morton  dense ijk flag hybrid  grid auto hash dense  grid node dense grid grid particle dynamic hpb   easily data structure customize feature layout allows user define data structure building reproduce popular multi sparse grid simulation furthermore data structure chain fork elementary component hybrid eulerian lagrangian simulation maintain particle grid data structure usually complicate building easily data structure hierarchical pointer particle hierarchical particle bucket useful simulation sec parameter materialize memory AOS layout previous soa   away layout memory behavior cacheline utilization application nest structural node specify hierarchical structure code defines sparse grid hash dense array pointer fix dense array hash dense pointer dense apart multiple global variable structural node multiple structural node code defines  sparse array compose dense array dynamic array std vector global global global auto index auto dense dense array dense dynamic array dynamic equivalent code struct  float float struct  std vector float taichi dynamic array pre define maximum unlike std vector grows arbitrarily struct structural node concise capable express variety data structure illustrates complex data structure data structure code rapidly data structure allows optimal specific task hardware architecture acm trans graph vol article publication date november taichi performance computation spatially sparse data structure domain specific  hierarchical data structure efficient representation sparse access due complexity parallelism desire compiler reduces access overhead typical source cache access architecture load data memory around cache access ensure data locality crucial performance particularly important gpu efficiently utilize memory cache data data structure hierarchy traversal traverse hierarchical data structure expensive hash query cycle fortunately amortize leverage spatial locality instance activation access activate previously inactive node usually involves atomic operation  intrinsically serialize optimization performance cache locality reduction redundant access automatic parallelization vectorization scratchpad optimization boundary inference scratchpad optimization reduce  latency memory bandwidth consumption potential data reuse exists scratchpad software manage local data arena typically cache cpu memory gpu intend local computation program scratchpad error prone scratchpad couple leaf construct cache enable scratchpad optimization specify kernel discrete laplace operator sec assume input dense array leaf dense bound inference infer output neighborhood input allocate local scratchpad array leaf interval analysis bound inference halide rectangular bound bound inference access offset compile however restrictive fortunately oftentimes bound domain knowledge data therefore  construct specify bound individual variable compiler propagates bound generate scratchpad semi lagrangian advection kernel backtrace distance bound    compiler kernel  def expr expr auto velocity auto velocity auto backtrace var cast int auto backtrace var cast int backtrace  backtrace backtrace  backtrace input backtrace backtrace implementation scratchpad optimization apply gpu backend latency bandwidth difference software manage memory hardware manage cache optimization profitable gpu anticipate optimization cpu backend cpu cache already role improvement significant apart cache construct memory usage hint  construct gpu backend instructs compiler issue ldg intrinsics data load global variable gpu cache unlike CPUs nvidia gpus cache data cache default cache maintain gpu hardware compile bound inference remove redundant access illustrate expensive hierarchical data structure access amortize multiple access simultaneously compiler leverage traversal constant propagation subexpression elimination develop minimal intermediate representation data structure operation intermediate representation specially vectorized access contains explicit information access data structure boundary allows perform optimization typical compiler cannot conduct automatically detail intermediate representation expression simplification algorithm appendix laplace operator sec assume access data structure index loop vectorized multiple combine kernel data structure information compiler infer compute specific scratchpad generate border load memory reuse stencil  reduce data load latency memory bandwidth consumption significantly acm trans graph vol article publication date november ancestor therefore traverse data structure compiler detects handle boundary specific offset information IR traditional compiler heuristic usually fail optimize due code complexity potential pointer aliasing access optimization assume access access eliminate access simplify compile offset relative access optimization apply operation access memory address kernel perform expensive sparsity allocation automatic parallelization task management parallelization load balance evenly distribute onto processor core challenge sparse data structure naively splitting irregular partition drastically leaf unlike dense sparse data structure partition leaf node unsatisfactory load imbalance therefore inefficient parallelism strategy generate task leaf flattens data structure 1D array circumvent irregularity incomplete importantly generate task per instead task per amortize generation cpu generate task via traversal serial task queue thread pool task queue parallel via openmp gpu generate task serial infeasible instead maintain multiple task structural node leaf generate layer layer manner node queue active node generate queue active node global atomic counter queue compilation pipeline solid computation IR pipeline dot data structure information kernel launch management gpu synchronize gpu kernel cpu host costly cpu gpu synchronization  user explicitly synchronization function data data structure gpu memory  execution gpus transparent user compiler runtime implementation taichi program embed easy interoperability host release python embed barrier development compiler implement borrowing infrastructure taichi library frontend kernel code lower intermediate representation compile standard cuda code component compiler runtime phase  reduce instruction remove redundant access access lower transform customize memory management memory allocation garbage collection cpu loop vectorizer compilation workflow summarize intermediate representation static assignment llvm intermediate representation explicit information data structure access access index bound data structure combine data structure composition information compiler perform automatic access optimization intermediate representation node described appendix snippet compile code supplementary acm trans graph vol article publication date november taichi performance computation spatially sparse data structure simplification apart dedicate optimization data structure access simplification phase applies purpose compiler optimization subexpression elimination local variable instruction elimination lower statement conditional split simplification phase phase greatly reduces simplifies instruction easy simplification phase disable phase increase compilation remove statement yield  code enable potentially helpful optimization central data structure access simplification micro access instruction     access lower phase leaf access broken stage hierarchy access leaf micro access operation merge disable access lower phase significant impact performance stage hierarchy data structure offset dimension compute along index mask  instruction data  kernel loop vectorized index guaranteed  return inference allows aggressively simplify access extract multi dimensional index flatten linear offset linearize pointer item data structure fetch data structure linear offset along node active  attention  node active access  return ambient node ambient access  allocates node return node finally correspond item fetch  micro access instruction compile non zero offset replace micro access instruction  instruction relationship access byte avoid data structure traversal memory management relies heavily allocation demand mechanism data structure dynamic topology therefore efficient management memory performance massively parallel gpus memory allocator variable request usually complex data structure maintain available unacceptable runtime therefore memory management data structure specialized abstraction memory manager memory allocator tailor node demand allocation pointer hash node benefit multiple allocator allocator allocate memory fix greatly simplifies accelerates minimize internal data structure memory allocator conservatively reserve memory pool virtual address amount physical memory actual become resident physical memory allows implement memory allocation integer atomic operation virtual memory operating inspire  virtual memory runtime reserve virtual address TB memory allocate immediately demand manner zero initialize hardware unified memory access feature nvidia gpus address cpu gpu additionally maintain metadata memory location coordinate loop vectorization CPUs loop vectorizer utilize vector instruction SSE avx CPUs  mask avoid diverge ensure access data structure vectorized load writes whenever vectorized memory access CPUs achieve memory behavior issue vectorized memory operation instead scalar load emit simd load blend instruction maximum usage vector compile  offset information access simplification load vector taichi compiler utilize avx instruction performance issue vectorized load fetch contiguous data memory simd blend generate desire vector binary mask naive data load code generator issue scalar load scalar vector promotion vector shuffle finally vector blend instruction vector interaction host interact host easily initialize data invoke compile kernel possibly output kernel laplace define gpus optimization via memory coalesce hardware relieve compiler burden optimization acm trans graph vol article publication date november benchmark command reproduce performance detailed subsection geometric benchmark access coherence calculate summary opt domain specific optimization code generation optimization backend purpose compiler opt optimization comparison gpu backend reference cpu implementation average faster otherwise faster hardware machine specification benchmark detailed appendix clang format  code style code loc margin empty remove benchmark reference timing cpu opt cpu opt gpu opt gpu opt ref loc loc MLS mpm gpu pascal fem linear elasticity cpu avx  solver cpu sparse cnn gpu turing summary coherent ref opt gpu cpu shorter code volumetric trace cpu initialize int int val float sin kernel active laplace output printf val float evaluation APPLICATIONS evaluate application visual compute task physical simulation render 3D summarize computation coherent access domain specific optimization boost performance geometric device implementation code faster reference implementation code implementation supplementary hybrid eulerian lagrangian stateof approach  continuum simulation challenge implement efficiently due interaction particle grid implement highperformance solver gpu intensive manual optimization tailor  variant gpus stagger particle ownership parallel scatter memory utilization obtain source cuda solver performance optimization reference implementation faster carefully confirm achieve effort performance decision warp reduction reduce atomic operation scatter dedicate sort delayed reorder reduce memory bandwidth consumption attempt thanks easy data structure exploration eventually surpass performance structure array soa particle layout reference implementation although easily implement optimization within code instead reference implementation warp optimization abstraction implement complex sort reorder scheme simplicity particle perfectly sort achieve comparable performance reference implementation however simulation progress spatial distribution particle performance drastically soa simulate soa particle layout sequential access efficient complex sort reorder scheme particle attribute randomly shuffle memory simulation due insufficient gpu cacheline utilization random memory access AOS particle layout easy implement importantly sensitive particle random particle access attribute particle nearby cacheline unlike CPUs nvidia gpus prefetching cacheline usage performance access predictability importance sort unnecessary simpler efficient algorithm reproduce mpm benchmark particle soa false initial shuffle false particle layout randomly shuffle soa AOS portability warp intrinsics ballot acm trans graph vol article publication date november taichi performance computation spatially sparse data structure jet animation MLS mpm particle simulated average sec frame  frame reproduce mpm scene output fortunately quickly explore particle grid layout scheme switch particle layout structure array array structure resolve issue AOS contrast reference implementation data layout tightly couple computational kernel data structure data structure code performance data structure mpm illustrate particle array structure grid structure array maintains index particle greatly simplifies data structure algorithm avoid complex radix sort particle grid hierarchy sparse bound simplicity access unnatural behavior simulation bound cannot predetermine hash dense pointer node grid conveniently simulation domain virtually unbounded correspond boundary implementation kernel sort particle index particle grid  grid normalization grid particle GP contrast reference implementation kernel majority data structure maintenance compiler automatically generates code maintain topology data structure automatically activates particle  GP kernel  construct hint compiler spatial relationship particle apply stagger  ownership optimization offset particle tighter access bound compiler automatically allocate scratchpad particle span scratchpad memory ablation scratchpad optimization indeed significant speedup auto index index index auto index auto fork dynamic max particle particle array structure int int fork particle matrix particle attribute grid structure array auto dense grid pointer dense grid grid velocity grid velocity grid velocity grid voxel  particle index dynamic pow grid data structure code simulation interaction particle grid hybrid eulerian lagrangian approach potential data structure array structure particle structure array grid dynamic particle voxel particle lookup hierarchical particle bucket easily modify code layout switch hash grid achieve unbounded domain scratchpad memory spm memory nvidia gpus  kernel faster GP kernel faster optimization easily achieve cache hint reproduce mpm benchmark cache false gpu spm gpu spm  GP MLS mpm animation simulated render taichi program acm trans graph vol article publication date november smash onto bound unbounded simulation data structure boundary easily switch virtually unbounded domain reproduce mpm scene scene output friction frame mul frame  optimize particle sort sort index particle respective grid  GP wise manner locality sort particle stagger optimization particle sort instead without stagger extra grey without stagger compiler automatically apply bound inference quickly approach reproduce mpm benchmark stagger linear elasticity finite kernel sparse grid finite solver resolution topology optimization propose matrix elasticity operator conjugate gradient iteration vectorization optimize kernel tailor  carefully implement vectorized load instruction via  intrinsic highly compute bound task voxel instruction issue fetch parameter 3D displacement node algorithm parallelizes naturally code  reference implementation evaluate compiler compute bound situation reproduce algorithm compiler compute bound task access optimization auto vectorization significantly reduce instruction optimization implementation faster cpu without modify code program gpu faster generate cpu code faster reference cpu implementation conduct comprehensive ablation compiler optimization fluid animation MLS mpm particle reproduce mpm scene fluid output fluid mul  compiler optimization performance cpu gpu multigrid poisson solver poisson equation extensive graphic fluid simulation image processing mesh reconstruction implement multigrid precondition conjugate gradient  solver become popular pressure projection physically animation implement simplify version reference implementation difference smoother reference implementation gauss seidel boundary smooth damped jacobi interior smooth gauss seidel smooth boundary interior restriction  instead trilinear interpolation operator average boundary zero dirichlet boundary reference implementation neumann boundary coarsen acm trans graph vol article publication date november taichi performance computation spatially sparse data structure ablation performance linear elasticity fem kernel disable simplification pas lower access harm performance increase compilation generate cpu code disable simplification II pas lower access binary MB instead KB clang fail remove redundant access data layout performance nearly magnitude reproduce fem gpu  vec thread access  vec load cpu soa ablation cpu gpu multithreading vectorization vectorized load instruction simplification access lower simplification II AOS instead soa optimization operator fuse reference implementation aggressively fuse operation smooth dot memory bandwidth temporary buffer simplify code fully implement algorithm specific benchmark simplify version user experienced physical simulation implement multigrid preconditioner within code implementation reference cpu convergence performance reference likely implementation slightly inferior convergence rate temporary buffer simplify code backend gpu effort faster cpu version faster reference implementation ablation compiler optimization parallelization ablation performance  poisson solver reproduce  poisson gpu vec thread access vec load cpu ablation cpu gpu multithreading vectorization access lower optimization solver automatically generalizes irregular sparse reference implementation dense grid implement multi resolution approach generate structural node kernel multigrid hierarchy performance data obtain dense grid zero dirichlet surround voxels initial analytical sin sin spatial coordinate initial conjugate gradient zero iterate norm residual reduce factor solver potentially graphic application panorama image stitch mesh reconstruction 3D convolutional neural network 3D convolutional neural network voxels instead image unlike image voxels efficient sparse representation resolution 3D sparse voxel approach propose 3D implement 3D convolution layer operating multi channel sparse voxels kernel mathematical definition convolution compiler automatically generates code efficiently access sparse voxels sparse convolutional network implement cuda hash pointer dense matrix sparse 3D feature stanford bunny  grid channel apply convolution layer hierarchy pointer array sparsity roughly faster reference code sparsity faster  schedule cache convolution gpu cache schedule hint boost performance reproduce cnn opt cache volumetric trace implement volumetric tracer inspire mitsuba implementation  isotropic phase function tungsten renderer  volume benchmark scene density bunny smoke source render image sample per pixel limit cpu implementation faster reference implementation gpu version faster cpu version faster reference implementation reproduce smoke renderer gpu opt domain specific optimization performance boost cpu performance improvement gpu access largely incoherent volume render obtain gpu renderer additional implementation explore sparse data structure http github com  tungsten acm trans graph vol article publication date november effort implementation tungsten slight modification renderers qualitatively supplemental LIMITATIONS although satisfactory benchmark limitation potential future arithmetic intensity task sec finite sec performance compute bound access optimizer greatly improve performance reduce access instruction however multigrid poisson solver sec although optimizer improves performance factor bound memory bandwidth reduce instruction longer  reference implementation faster vectorized implementation reference bandwidth efficient due operator fuse optimization suggests investigate approach automatically fuse operator decouple computation schedule coherent access volume render sec ray exhibit coherent behavior compiler infer compile approach extract locality information ray reorder potentially boost performance related array compiler program model efficiently compile array operation propose halide decouples image processing operation schedule loop transformation vectorization polyhedral compiler adopt compiler focus dense data structure model sparsity decouples algorithm internal organization sparse data structure programmer quickly switch data organization achieve performance sparse tensor compiler target linear algebra operation focus construct efficient iteration sparse matrix linear algebra operation compiler target graph operation breath shortest contrast focus generate performance traversal code spatially coherent access hierarchical sparse data structure efficiently vectorize access data structure adopt program multiple data model computational kernel foundation parallel implement  tungsten grid implementation approximate  hierarchical DDA traversal tungsten cuda OpenCL   physical simulation domain specific exist physical simulation usually abstract domain graph structure mesh  focus partial differential equation mesh  model domain sparse matrix  employ relational data model abstraction optimization focus hierarchical sparse data structure data orient inspire increase relative expense memory operation video visual recently adopt data orient philosophy software engineering approach focus data access oppose traditional orient storage fragment adopt philosophy   construct transformation array structure structure array facilitates data orient philosophy decouple data structure computation hierarchical sparse grid graphic computer graphic physical simulation multi sparse regular grid finite eulerian fluid simulation sparse grid simulation data  grid encode compress data  employ compress storage  static structure unbounded domain  shallow hierarchy utilize virtual memory gpu variant   recently nielsen  propose branching tile voxels fluid simulation sort particle correspond voxel hierarchical particle bucket described outside simulation  octrees poisson equation image stitch mesh reconstruction respectively hierarchical grid distance conclusion program optimize compiler develop performance implementation sparse visual compute task novel allows productivity performance computation data structure decouple allows programmer quickly explore data structure hierarchy successfully efficient layout demonstrate potential develop novel performance data structure acm trans graph vol article publication date november taichi performance computation spatially sparse data structure compiler automatic parallelization access optimization useful reduce instruction compute bound task scratchpad optimization improves memory locality compiler enables programmer implement optimize simulation within code