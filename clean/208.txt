recognize emotional reaction movie audience affective movie content challenge task affective compute previous research induced emotion recognition mainly focus audio visual movie content nevertheless relationship perception affective movie content perceive emotion emotion evoke audience induced emotion unexplored relationship perceive induced emotion movie audience moreover investigate multimodal model approach predict movie induced emotion movie content feature physiological behavioral reaction movie audience analysis induced perceive emotion extend exist database movie affect analysis annotate perceive emotion source manner perceive induced emotion consistent addition perceive emotion movie dialogue aesthetic highlight discriminative movie induced emotion recognition besides spectator physiological behavioral reaction reveal induced emotion recognition benefit temporal information perform multimodal fusion moreover deeply investigate gap affective content analysis induced emotion recognition gain insight relationship aesthetic highlight induced emotion perceive emotion introduction attention recently drawn recognize emotion induced movie audience affective content due potential application emotion content delivery video index summarization movie scene nevertheless recognize emotion induced affective movie content remains challenge task weak moderate correlation automatic prediction annotation achieve widely model define emotion affective content analysis emotion model appraisal model circumplex model circumplex emotion model compound subtle emotion widely annotate movie induced emotion affective content analysis stimulus induce emotion assume emotion conveyed affective content perceive emotion stimulus consistent emotion evoke spectator induced emotion moreover perceive induced emotion usually separately affective content however research emotion attempt investigate difference perceive emotion affective content induced emotion audience moreover research emotion discover emotion perceive consistent emotion elicit listener suggests distinguish perceive induced emotion movie audience crucial significant progress affective content analysis distinguish perspective movie emotion namely audience perspective actor perspective director perspective movie audience perceive interpret movie content emotion express actor perceive emotion induces emotional response movie audience induced emotion movie director script emotional annotation expectation emotion induced movie audience scene intend emotion investigate audience perspective movie emotion tan argue emotion perceive movie influence induced emotional response audience evoke empathy consequently imply positive correlation perceive induced emotion nevertheless argue emotion intend director consistent emotion induced movie audience author perceive emotion formally investigate relationship perceive induced emotion movie audience moreover attempt bridge gap statistical analysis emotion perceive movie content emotion induced movie audience fundamental understand affective movie content induces emotion audience moreover reveal multimodal information movie content predict perspective movie emotion research induced emotion recognition mainly focus extract audio visual feature video recording author nonverbal behavior signal facial expression gesture audio cue predict spontaneous affect bidirectional memory recurrent neural network blstm outperform vector regression SVR due ability temporal dependency multimodal feature emotional addition researcher propose belief network DBNs capture complex non linear interaction audio visual feature emotion recognition beyond audio visual feature movie dialogue effective violence recognition movie affective cue perceive emotion movie recognition induced emotion investigate complex relationship induced perceive emotion movie audience continuous liris accede database contains continuous arousal valence annotation emotion induced movie audience spectator physiological behavioral reaction movie content database commonly movie induced emotion recognition benchmark challenge  relationship perceive induced emotion movie audience improve induced emotion recognition manual transcript movie continuous liris accede database manual annotation disfluency non verbal  dis NV dialogue lexical movie content addition extraction audio visual feature movie content source annotation perceive arousal valence movie dialogue characterize affective movie content aesthetic highlight annotation aesthetic movie content moreover extract statistical feature physiological behavioral signal capture spectator reaction movie besides investigate discriminative multimodal feature impact temporal information recognition performance fusion strategy combine multimodal information audio visual lexical movie content perceive emotion aesthetic highlight annotation spectator physiological behavioral reaction extension previous address research perceive emotion induced emotion consistent improve recognition performance induced emotion feature beyond audiovisual movie content contribute induced emotion recognition perceive emotion discriminative induced emotion recognition fusion movie content feature spectator reaction temporal information movie content spectator reaction beneficial emotion recognition contribution highlight novelty previous insight movie genre emotion audience characteristic movie dialogue investigate influence movie genre intensity movie audience perceive emotion amount disfluency non verbal  dis NV movie dialogue discrepancy perceive emotion annotation discrepancy induced emotion annotation movie movie genre establish relationship aesthetic movie content emotion movie audience identify aesthetic highlight novel aesthetic cue information perceive induced emotion regardless discrepancy propose novel multimodal model predict movie induced emotion model incorporate perceive emotion annotation hierarchical architecture memory recurrent neural network lstm movie content feature movie content feature movie audience reaction recognition induced emotion benefit multimodal hierarchical fusion movie content feature spectator reaction account temporal information baseline emotion recognition model namely belief network DBNs vector regression SVR organize review affective content analysis consists description data collection protocol extend emotional annotation continuous liris accede database statistic annotation corresponds description  feature extraction description emotion recognition model consists analysis relationship perceive emotion induced emotion movie audience occurrence aesthetic highlight movie moreover unimodal multimodal emotion recognition discus obtain conclusion future direction research related introduce approach emotion recognition multimodal signal review affective content analysis discus previous relationship perceive induced emotion reveal weakness detail previous induced emotion recognition continuous liris accede database identify limitation emotion recognition majority audio visual emotion recognition focus identify machine model recognize continuous emotion arousal valence author apply vector regression bidirectional memory recurrent neural network blstm relevance vector machine audio visual feature recognize continuous emotion addition blstm model recognize continuous emotion model  context emotion reconstruction error framework introduce recognize continuous emotion autoencoders researcher recently introduce automatic affect physiological signal manner furthermore transfer framework apply audio visual feature emotion recognition due lack training instance multi task feature improve automatic emotion recognition interact dyad belief network apply representation audio visual feature multi task propose jointly model recognition induced perceive emotion addition multi clue fusion decision propose model emotion facial appearance texture facial action audio feature extract sequential image recurrent neural network combine convolutional neural network cnns model previously pretrained image capture facial action facial landmark trajectory model propose cnns vector machine feature extract video cnns moreover attempt establish relationship information stimulus movie clip video affective spectator recent focus physiological response affective movie content induced emotion associate subjective sphere emotion preference physiological reaction related emotional spectator elicit movie content furthermore researcher recently investigate emotion recognition response multimedia content  peripheral physiological signal facial expression galvanic response profile movie spectator propose affective profile movie modality electrodermal activity facial expression viewer facial feature extract detect spontaneous emotion viewer expose movie clip addition observer physiological signal galvanic response rate variability classify depression multiple video observer understand spoken relationship information conveyed stimulus spectator emotional response investigate affective compute  community decade however remains challenge task performance achieve predict induced emotion limited furthermore lack fusion model aggregate video content spectator physiological behavioral reaction perceive versus induced emotion movie  furthermore perceive emotion conveyed affective content characteristic stimulus tempo pas information audience contrary perceive emotion induced emotion evoke spectator stimulus associate personal individual preference instance perceive induce depression depressed previous emotion suggests perceive emotion objective induced emotion  annotator usually agreement perceive emotion induced emotion previous affective content analysis distinguish difference perceive induced emotion consistency perceive induced emotion  emotion discover fundamental difference perceive induced emotion previous emotion induced emotion intensive arousal intensive valence rating comparison perceive emotion rating stimulus furthermore emotion expression perception spoken dyadic interaction propose distinction induced perceive emotion reveal complex dependency dialogue actor limited  relationship perceive induced emotion movie audience comparison emotion important mention  assume positive correlation perceive induced emotion movie audience author descriptor affective content predict spectator emotional reaction annotator agreement movie emotion description movie video feature emotion definition imply relationship movie content induced emotion attempt extent perceive induced emotion movie audience consistent previous liris accede database previous continuous liris accede database recognize movie induced emotion various regression model vector regression SVR memory recurrent neural network lstm convolutional neural network cnns however model fed audio visual feature movie content without account spectator reaction continuous liris accede database performance induced emotion recognition continuous liris accede database performance induced emotion recognition pearson correlation coefficient CC commonly report evaluation metric error mse report weak moderate correlation achieve induced emotion recognition audio visual feature suggests recognize induced emotion movie audience challenge task important setting data pre processing training partition directly comparable previous mainly focus audio visual feature extract movie content nevertheless lexical information movie dialogue largely overlook important emotion recognition besides movie dialogue usefulness knowledge inspire affective cue aesthetic highlight explore predict movie induced emotion previous examine unimodal model induced emotion recognition SVR model visual feature achieve report CC induced emotion recognition nevertheless combine multimodal information improve performance emotion recognition task encourage investigate modality fusion strategy improve induced emotion recognition addition lstm model performance predict movie induced emotion nevertheless lstm model achieve performance various emotion recognition task ability account temporal information predict movie induced emotion interval temporal information already however important mention suitable amount temporal information predict movie induced emotion remains undefined  annotation liris accede database liris accede database release researcher resource affective content analysis analyze continuous liris accede database liris accede consists movie movie movie genre duration annotation collection movie grouped accord duration participant movie annotate continuous arousal valence rating emotion induced emotion rating participant movie standard displayed movie another participant sensor attach limb galvanic response acceleration signal participant movie projection extend annotation liris accede collection extend annotation liris accede database detailed statistic transcript movie dialogue timing affective cue label perceive emotion annotation analysis agreement perceive induced emotion annotation chose english movie significantly dialogue movie liris accede database movie sintel  moreover movie movie genre reality exist activity movie movie reality movie audience audience empathize movie particularly understand perceive induced emotion due spectator engagement movie sum annotate movie utterance statistic liris accede movie statistic liris accede movie transcription affective cue annotation movie transcription affective cue annotation expert annotator increase annotation apply ibm watson text service audio recording movie service automatic transcription timing auto generate transcript manually annotate annotator parallel annotate movie evaluate quality annotation annotation agreement movie bite  annotate annotator compute normalize  levenshtein  distance transcript pearson correlation coefficient CC concordance correlation coefficient timing  distance distance define minimum operation transform longer normalize  distance reveals identical closer corresponds annotation agreement percent transcribed annotator average  distance suppose average transcript average  distance indicates difference addition CC utterance timing transcript utterance timing annotate annotator strongly correlate overall indicates annotator strongly movie transcription annotation pearson correlation coefficient CC concordance correlation coefficient timing utterance dis NV annotation calculate pearson correlation coefficient CC concordance correlation coefficient timing utterance dis NV annotation calculate annotator annotate category disfluency non verbal  dis NV movie dialogue pause hmm filler verbal pause  laughter audible breath furthermore remain label lexicon dis  indicative speaker emotion spontaneous dialogue evaluate annotation agreement annotation subset dis NV label calculate CC timing category dis NV label annotation agreement dis NV label timing comparison movie transcription annotation remain strongly correlate suggests annotate dis NV label subjective task due ambiguity environmental background statistic category dis NV movie per movie genre disfluency non verbal  movie filler category dis NV fundamental difference dis NV occurrence movie genre romance movie dis  adventure movie consist dis  worth dis  indicator speaker uncertainty observation adventure movie dis  movie genre adventure movie uncertainty movie dialogue development amount dis NV annotation movie dialogue amount dis NV annotation movie dialogue amount dis NV annotation movie dialogue per movie genre amount dis NV annotation movie dialogue per movie genre annotate perceive movie emotion emotion annotation subjective comparison movie transcription task multiple annotator desire task previous recommend annotator achieve reliable emotion annotation however recent development crowdsourcing allows easy access annotator massive amount annotation efficiently  annotate perceive emotion movie audience amazon mechanical turk source online annotation platform movie utterance excerpt manual transcription utterance timing annotation annotator excerpt assume annotator correctly understand perceive affective movie content mechanical turk annotator instruct rate emotion express movie arousal valence dimension integer addition mechanical turk annotator explanation emotion dimension meaning intelligence task movie excerpt continuous utterance movie preserve movie context utterance video HITs reduce cognitive bias HITs launch random tracked annotator movie prevent utterance annotate annotator annotator annotate movie excerpt display annotator submit rating annotate movie excerpt sum publish HITs annotation perceive emotion annotator various cultural educational background source annotation normalize interval consistent induced emotion annotation liris accede database calculate arousal valence annotation utterance movie dialogue perceive emotion annotation movie audience utterance report statistic perceive emotion annotation movie per movie genre average perceive emotion movie another variance magnitude movie neutral regard average perceive emotion movie bite movie balance scene various emotional movie audience perceive emotion per movie movie audience perceive emotion per movie movie audience perceive emotion per movie genre movie audience perceive emotion per movie genre average adventure movie arousal valence movie genre movie dominates content movie genre moreover observation romance closest neutral arousal suggests balance amount relax scene movie besides comedy movie scene emotional discrepancy another agreement perceive induced emotion annotation investigate difference induced perceive emotion annotation average standard deviation induced ind perceive per emotion annotation multiple annotator per movie movie genre respectively annotation per induced emotion processing annotation perceive emotion per utterance emotion annotation utterance movie respectively compute unbiased standard deviation annotator standard deviation induced perceive emotion annotation multiple annotator per movie standard deviation induced perceive emotion annotation multiple annotator per movie standard deviation induced perceive emotion annotation multiple annotator per movie genre standard deviation induced perceive emotion annotation multiple annotator per movie genre report average standard deviation emotion annotation movie average standard deviation perceive emotion average standard deviation induced emotion movie due source annotation perceive emotion perceive emotion annotation untrained annotator various cultural educational background induced emotion annotation annotator recently graduate france therefore annotator similarity emotion induction annotation report average standard deviation per movie genre similarly infer average standard deviation perceive emotion induced emotion movie genre moreover annotation perceive emotion strongly adventure movie movie payload  tear action scene extraordinary fictional location outer displayed spectacular evoke emotional reaction conclusion audience perceive emotion adventure movie multimodal feature extraction research multimodal signal improve induced emotion recognition reveal complementary information spectator induced emotion encode movie content spectator reaction besides audio visual feature movie content extract affective feature lexical feature movie dialogue aesthetic movie highlight annotation perceive emotion annotation affective movie content lexical feature characterize emotion dialogue express movie aesthetic highlight perceive emotion annotation aesthetic affective movie content addition statistical descriptor spectator physiological behavioral signal account induced emotion encode movie audience reaction arousal valence annotation liris accede database movie capture suitable amount temporal information spectator physiological behavioral reaction audio video movie content affective cue slide overlap neighbour extract feature movie audience reaction feature account induced emotion subjective audience reaction feature namely statistical feature physiological behavioral reaction assume within movie audience display behavior physiological response movie aesthetic emotional movie scene  evoke specific emotional reaction aesthetic background empathy compassion etc movie movie audience affective reaction synchronize emotional contagion statistical feature dynamic spectator physiological behavioral reaction movie galvanic response GSR acceleration signal acc spectator filter pas butterworth filter frequency feature extraction statistical feature median standard deviation minimum  minimum maximum ratio compute slide signal derivative statistical feature compute slide GSR acc signal sensor attach spectator limb physiological behavioral measurement participant induced emotion annotate standard induced emotion recognition movie feature audio visual feature extract feature audio visual movie content  toolkit compute interspeech paralinguistic challenge descriptor audio feature visual feature slide latter histogram local binary hsv hue saturation wel optical image standard benchmark feature compute perform various emotion recognition task dimensionality reduction due available instance model training model parameter tune reduce feature ReliefF algorithm ranked discriminative feature emotion recognition perform regression neighbour ReliefF feature rank remain movie liris accede database movie perform recognition incorporate domain knowledge guarantee instance feature selection discriminative audio feature visual feature arousal valence prediction respectively chose feature audio visual feature balance dimensionality feature reduce model parameter prevents overfitting addition feature engineering setting feature perform feature selection combine audio visual feature apply dimensionality reduction instead feature selection linear principal component analysis nonlinear principal component analysis gaussian kernel diffusion component sufficient percent data variance however significant performance improvement lexical feature lexical feature discriminative speaker emotion recognition spontaneous dialogue lexical feature disfluency non verbal  dis NV source annotation CSA feature former extract manual annotation dis  movie dialogue latter source annotation arousal valence rating english lemma extract CSA feature remove commonly etc movie transcript  remain transform toolkit standard pre processing processing compute feature lemma slide entry contains statistic compute arousal valence rating statistic standard deviation contribute rating raters subset raters male female education education statistic raters subset statistic emotion dimension sum statistic lemma slide lexical feature dis NV feature compute duration category dis NV lexicon slide apply removal lemmatization compute dis NV feature feature duration aesthetic movie highlight aesthetic movie highlight associate occurrence  movie scene define expert content knowledge inspire feature abstract audio visual movie content feature annotation occurrence aesthetic highlight movie aesthetic highlight categorize spectacular technical choice subtle camera development emotional response dramatic dialogue clarify motivation tension theme development unusual development urban theme category highlight perceive emotion annotation perceive emotion movie audience affective feature recognize induced emotion arousal valence average normalize slide apply emotional align feature movie content movie audience reaction recognition model detail  model hierarchical architecture fuse multimodal signal induced emotion recognition lstm model instead blstm model recognize induced emotion multimodal signal previous movie content emotional spectator influence emotional spectator previous emotion recognition interaction artificial intelligent agent blstm model significantly outperform lstm model future interaction emotional cannot influence interaction emotional SVR DBN model described baseline emotion recognition model propose hierarchical architecture lstm model fusion multimodal information previous emotion recognition assume complex temporal relationship induced perceive emotion extract feature affective movie content spectator physiological behavioral reaction lstm model lstm model dependency series capture temporal information movie spectator reaction movie content sequential structure lstm model representation data desire multimodal information encode noisy feature temporal dynamic lstm model multimodal feature incorporate model layer hierarchical structure temporal characteristic abstraction feature however important mention building structure multiple layer lstm model access massive label data lstm model propose exist lstm model successfully apply emotion recognition propose lstm model SVR model baseline emotion recognition model advantage SVR model training instance optimal parameter however SVR model capture temporal information besides SVR model propose lstm model DBN model representation data complex dependency nevertheless temporal information omit DBN model instance model properly due label data available exist machine model apply induced emotion recognition task memory recurrent neural network memory recurrent neural network lstm recurrent neural network multiple hidden layer structure allows lstm model capture temporal information hidden layer hierarchical structure lstm model fusion multiple modality improve emotion recognition spoken dialogue moreover lstm model outperform algorithm classify silence movie built lstm model kera library induced emotion recognition lstm model hidden layer neuron architecture hyperparameters already apply emotion recognition avoid overfitting dropout hidden layer rate maximum training iteration epoch tolerance epoch mini batch due computational efficiency training varied performance influence selection evaluate fusion strategy feature FL fusion fusion decision DL fusion fusion hierarchical HL fusion multimodal emotion recognition multimodal feature concatenate vector recognition model FL fusion apply DL fusion unimodal recognition model built multimodal feature output incorporate decision module another lstm model HL fusion incorporates multimodal feature hierarchy aesthetic highlight perceive emotion annotation feature incorporate layer lstm model abstract feature audio video feature incorporate layer furthermore input neuron feature hidden layer input neuron feature directly hidden layer multimodal HL fusion built multimodal model combine movie content feature movie content feature spectator reaction former model descriptor audio video content layer noisy affective clue domain knowledge feature selection audio visual feature latter model feature physiological behavioral signal layer movie feature movie audience reaction characterize dynamic movie content feature belief network belief network DBNs improve emotion recognition outperform neural network vector machine hidden layer DBNs representation audio visual feature capture complex non linear dependency DBNs capable reduce dimensionality audio visual feature structure DBNs stack multiple restrict boltzmann machine RBM moreover RBMs drawn increase attention machine research stochastic graphical model improve performance application recognition emotion recognition bernoulli bernoulli RBM  assumes input data binary distribution crucial limitation RBM assume data derive gaussian distribution propose gaussian bernoulli RBM  RBM gaussian distribution visible binary distribution hidden furthermore DBN stack multiple RBMs hidden RBM visible RBM DBNs representation amount unlabelled instance relatively label data  model  input layer respect distribution physiological behavioral signal gaussian distribution pseudo binary distribution layer  DBNs hidden layer neuron respectively limited training instance mini batch feature due computational efficiency initial rate upper bound pre training update ratio entropy loss function apply gradient decent supervise tune maximum iteration optimal parameter DBNs avoid overfitting limited training dropout ratio hidden layer vector regression vector regression model demonstrate performance affect prediction nonlinear vector regression SVR gaussian kernel baseline model induced emotion recognition optimal parameter radial basis function optimal regularization parameter optimal parameter vector identify grid experimental perceive induced emotion respond research relationship perceive emotion induced emotion movie audience account induced emotion annotate perceive emotion annotate utterance perceive emotion annotation generally longer align annotation compute induced arousal valence movie utterance utterance induced emotion annotation independently calculate CC perceive induced emotion movie fix model analyze dependence perceive induced emotion dimension described CC consequently compute average CC movie evaluate practical significance CC cohen model interpret absolute CC around medium respectively pearson correlation coefficient perceive induced emotion movie audience magnitude bold pearson correlation coefficient perceive induced emotion movie audience magnitude bold perceive arousal valence dimension highly positively correlate induced arousal valence moderately negatively correlate related perceive emotion annotation objective task negative correlation induced arousal valence consistent previous CC source annotation induced arousal valence nearly english lemma suggests induced negative emotion arousal induced positive emotion however definitive conclusion absolute CC induced valence perceive emotion moderately positive correlation induced arousal perceive emotion weakly moderately negatively correlate perceive arousal induced arousal weakly negatively correlate pleasant dominate scene movie evoke boredom movie audience nevertheless movie audience displeasure movie scene dominate dramatic inconsistency perceive induced emotion annotation indicates fundamental difference perceive emotional movie content emotion movie audience emotion induction complex phenomenon various factor emotion conveyed movie content influence emotional response movie audience personality movie preference analysis prof assumption perceive induced emotion consistent entirely accurate researcher account affective content analysis research movie perceive induced emotion versus aesthetic highlight investigate relationship aesthetic highlight induced perceive emotion respond research movie liris accede database empirical topic related induced perceive emotion movie audience occurrence aesthetic highlight movie calculate individual movie standardize difference define difference continuous emotion annotation highlight non highlight interval pool standard deviation positive induced perceive emotion highlight scene comparison non highlight scene whereas negative combine statistical analysis estimate function precision assume fix model cohen benchmark practical significance average assume around interpret medium respectively report average induced perceive emotional dimension movie liris accede database emotional reaction associate occurrence spectacular highlight movie saturation lighten camera location positive induced perceive arousal negative induced perceive valence spectacular highlight moreover negative perceive important direction induced perceive arousal valence consistent highlight dependency aesthetic highlight perceive induced emotion movie audience medium magnitude bold dependency aesthetic highlight perceive induced emotion movie audience medium magnitude bold movement camera lighten shadow environmental background subtle highlight elicit emotional response movie audience nevertheless negative perceive valence medium negative perceive highlight development tension development highlight influence emotional physiological movie audience positive perceive arousal induced valence specific dialogue highlight affect emotional physiological movie audience negative perceive induced valence perceive arousal worth direction perceive induced valence emotion sadness pleasure perceive dialogue evoke emotional movie audience empathy theme development highlight partially overlap category aesthetic highlight spectacular highlight development highlight development theme associate emotional reaction dramatic spectacular  manner negative perceive valence perceive positive induced arousal valence related incoherence direction perceive induced valence perceive negative valence  evoke pleasure audience essentially aesthetic highlight aesthetic cue information perceive induced emotion regardless discrepancy induced emotion recognition recognize induced emotion multimodal information research average arousal valence standard induced emotion annotation remove credit movie participant remove wearable sensor introduce outlier signal data instance amount annotate data available induced emotion recognition perform movie validation instance movie instance movie movie training compute unweighted average mse absolute CC arousal valence prediction mse refers average mse movie validation arousal prediction mse CC commonly report evaluation metric related CC linear relationship emotion prediction annotation increase decrease trend signal mse corresponds quality predictive model combine CC difference series sensitive bias factor commonly apply multiple unambiguous annotation prediction induced emotion describes agreement prediction annotation prediction annotation trend signal validation investigate statistical significance model perform random prediction model generate arousal valence prediction random prediction model CC random prediction arousal valence respectively finally prediction model perform randomly svm model fed GSR audio feature respectively arousal prediction statistical comparison sample wilcoxon significant report bold italic significantly performance bold significantly performance influence induced emotion induced emotion annotation liris accede database annotate average absolute difference adjacent arousal annotation valence annotation annotation extremely annotation previous emotion context dependent typically rapidly interval however suitable amount temporal context predict movie induced emotion remains unknown attempt identify suitable amount predict induced emotion lstm model fed physiological feature physiological feature representative audience induced response feature recognition performance shorter longer lstm model recall feature vector extract slide overlap feature vector model temporal information unimodal induced emotion recognition unimodal induced emotion recognition report average mse CC absolute movie validation arousal valence prediction arousal valence prediction SVR model achieve performance physiological feature perceive emotion feature CC respectively physiological signal perceive emotion discriminative information induced emotion moreover svm capture dependency physiology emotional spectator svm predict increase decrease arousal valence intensity GSR signal respect CC besides SVR model predict induced emotion perceive emotion annotation upward downward trend nevertheless mse improve model emotion recognition task statistical significance refer prediction SVR model performance prediction random prediction model SVR prediction significantly random prediction arousal valence prediction SVR model significantly CC valence prediction GSR visual feature DBN model perform induced emotion recognition audio feature movie content regard CC trend arousal valence intensity easily capture moreover DBN accurately predict arousal however valence prediction DBN achieve valence prediction aesthetic highlight annotation refer prediction DBN model performance random arousal valence prediction DBN model perform significantly random prediction model arousal valence prediction DBN model significantly performance unimodal induced emotion recognition SVR DBN lstm model report performance unimodal induced emotion recognition SVR DBN lstm model report lstm model predict induced arousal audio feature regard CC however feature behavioral signal discriminative induced arousal prediction moreover lstm model perform valence prediction physiological signal trend valence intensity capture lstm model fed GSR feature confirm CC respectively validate lstm model performance prediction random arousal valence prediction prediction lstm model perform significantly random prediction prediction lstm model significantly however exception CC valence prediction GSR signal perceive emotion annotation important mention directly comparable previous due data processing procedure overlap setting validation fold training nevertheless outperform recognition model valence prediction lstm model statistical feature GSR signal CC multimodal induced emotion recognition report average mse CC absolute movie validation arousal valence prediction multimodal induced emotion recognition fusion audio video feature affective clue audio video CSA dis NV feature aesthetic highlight perceive emotion annotation feature moreover investigate fusion movie content feature mention physiological behavioral response movie spectator propose hierarchical fusion lstm HL architecture lstm model baseline fusion strategy lstm model feature fusion lstm FL decision fusion lstm DL examine recognition performance svm DBN model FL fusion apply performance multimodal induced emotion recognition movie content feature SVR DBN lstm model report performance multimodal induced emotion recognition movie content feature SVR DBN lstm model report performance multimodal induced emotion recognition audience reaction movie content feature SVR DBN lstm model report performance multimodal induced emotion recognition audience reaction movie content feature SVR DBN lstm model report  model FL fusion perform induced arousal recognition movie content feature respect CC trend arousal intensity easily capture model nevertheless propose hierarchical fusion architecture lstm model predict induced arousal trend besides lstm HL succeed recognize induced valence lstm DL CC actually lstm FL outperform fusion strategy predictive model accurately predict trend fluctuation induced valence accord generally lstm model outperform SVR DBN model induced emotion recognition movie feature SVR model accurate predictor trend induced arousal intensity fusion movie content feature movie audience reaction however mse indicates SVR model predict arousal slight increase decrease trend furthermore lstm HL achieve accurate prediction downward upward trend induced arousal intensity lstm HL perform induced valence recognition confirm CC respectively obtain propose hierarchical architecture lstm model fusion movie content feature movie audience reaction predict intensity induced arousal valence statistical significance obtain multimodal fusion refer arousal valence prediction multimodal fusion model performance prediction random prediction model perform significantly arousal valence prediction multimodal fusion model fed movie content feature movie content feature statistical feature audience reaction respectively remark significantly 7Discussion discus limitation issue regard choice modality sample algorithm selection limitation induced emotion express multimodal channel importance channel induced emotion recognition spectator physiological behavioral response stimulus affected ambient posture gesture attention mental effort furthermore induced emotion another due factor personal combine multimodal signal remain challenge due lack access non obstructive reliable sensor limit feasibility cinema theater measurement physiological behavioral signal corrupt due electrode contact sensor device failure data collection incomplete data besides factor influence induced emotion movie audience personal movie preference aesthetic taste personality spectator emotion affected recent emotion available modality sample analyze movie liris accede database movie genre movie label instance although conclusion magnitude cannot generalize movie genre movie spectator movie cinema theater galvanic response acceleration measurement spectator due technical constraint resource available unimodal induced emotion recognition confirm spectator physiological response display behavior movie however behavioral feature discriminative physiological feature induced emotion recognition outcome influence placement sensor sensor attach spectator conduct spectator limb movement movie inter annotation agreement induced perceive emotion reduce variability standard dynamic annotation instead emotion intensity moreover outlier annotation remove identify annotator bias apply model selection obtain amount label instance available emotion recognition significantly limit quality model training performance emotion recognition exist architecture hyperparameters emotion recognition model strongly access amount label data emotion recognition model selection strictly associate amount available multimodal data annotate evaluation metric CC goal capture trend induced emotion model however suitable evaluate quality model describes model capture trend estimate emotion intensity physiological behavioral reaction affective cue annotate recommend induced emotion recognize DBN model fed audio movie feature physiological behavioral measurement available lstm model apply due capability capture dependency movie audience reaction SVR lstm model statistical feature GSR acc signal achieve performance emotion recognition regard CC dynamic physiological behavioral reaction highly discriminative recognize emotion induced movie audience besides crowdsourcing annotation svm model affective cue annotation aesthetic highlight movie perceive emotion movie audience multimodal induced emotion recognition lstm model benefit temporal information combine knowledge inspire affective cue audio visual movie content movie audience response fusion spectator physiological behavioral reaction movie content feature improves emotion recognition however hierarchical incorporation multimodal feature increase performance movie content feature spectator reaction dynamic temporal lstm architecture incorporate affective cue audio visual movie content feature propose hierarchical fusion improve induced valence recognition svm DBN model capture consecutive emotional reaction spectator account temporal information lstm model outperform feature fusion baseline model multimodal feature incorporate stage model multilevel fusion desire fuse feature temporal dynamic audio video feature movie content statistical feature spectator physiological behavioral reaction limitation model cannot noisy feature temporal evolution probability distribution movie content feature statistical feature movie audience reaction probability distribution varies movie another measurement physiological behavioral signal corrupt electrode contact dependent furthermore audio video feature contaminate movie background contrary lstm model limit influence variability spectator physiological behavioral signal movie content noisy feature filter representation layer lstm model conclusion clarifies difference perceive induced emotion movie audience serf reference future affective content analysis extend annotation liris accede database perceive induced emotion movie audience positively correlate regard research although inconsistency fairly movie data account stimulus emotion induction simply assume perceive emotion stimulus consistent emotion induced spectator expand understand perceive induced emotion address research perceive emotion predict induced emotion moreover perceive induced emotion movie audience associate occurrence aesthetic highlight movie highlight affective cue induced emotion recognition improvement performance multimodal hierarchical fusion conclusion modality facial expression rate  signal spectator increase performance promising model scalable movie architecture generalization benefit label instance available training nevertheless deeply layer model audio video feature affective cue incorporate future advantage transfer emotion recognition task pretrained model emotion recognition challenge emotion recognition individual video apply induced emotion recognition movie audience attempt improve performance feature representation architecture multimodal recognition model moreover conduct investigation emotion affective cue movie genre another action crime epic historical horror etc movie emotion perspective contribution cinematography research  affective content alignment intend induced emotion