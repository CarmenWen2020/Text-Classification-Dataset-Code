machine technique reconstruct image sequence render monte carlo primary focus reconstruction global illumination extremely sample budget interactive rate motivate recent advance image restoration convolutional network propose variant network monte carlo render pixel neighborhood account improve execution magnitude primary contribution addition recurrent connection network drastically improve temporal stability sequence sparsely sample input image desirable automatically model relationship auxiliary per pixel input channel depth normal signicantly quality exist comparable furthermore argue realtime rate future CCS concept compute methodology ray trace neural network image processing additional monte carlo denoising image reconstruction interactive global illumination machine introduction ray trace recently emerge render algorithm choice visual eects encourage development ltering reconstruction technique reduce inherent monte carlo rendering focus quality sample per pixel prior ltering meanwhile recently migrate towards  shade empirical model potential increase realism transition hinge possibility sample transport  rasterization allows unfortunately ray tracer trace ray per pixel acm transaction graphic vol article publication date july alla trend partially counter towards resolution display refresh rate therefore likely realistic sample budget realtime application remain per pixel foreseeable future reconstruction technique signicantly improves regime reconstruct global illumination per pixel considerable challenge monte carlo integration indirect illumination noisy image sample rate concentrate subset pixel therefore frame reconstruction nal image denoising sparse sample prohibitively sample rate image almost compound obtain temporally stable animation motivate recent image restoration convolutional network propose signicant  structure network address challenge reconstruct render image sequence extreme monte carlo novel aspect recurrent connection autoencoder structure increase temporal stability training allows network automatically utilize auxiliary pixel feature depth normal guidance user advance interactively generate plausible image sequence global illumination extremely sample budget consistently outperform quality regime related exists image denoising reconstruction image sparse sample primary focus denoising image render monte carlo important research eld decade rst review relevant computer graphic literature connection machine image video restoration recent survey information oine denoising monte carlo render image denoising essential physically render viable production due image convergence error stochastic monte carlo MC address jensen  apply non linear  lters indirect diuse illumination recently frequency analysis transport derive quality shear lters specic eects lters apply individual ray sample 4D domain quality image reconstruction coarse eld auxiliary information sample sen  estimate parameter bilateral lter mutual information parameter sample recent auxiliary feature render stein unbiased risk estimate lter minimize denoising error employ additional feature renderer denoising challenge lter parameter inuence feature address parameter non local lter machine decompose multiple buers apply individual lters buer image feature local regression model approach eciently reduce residual execution oine reconstruction acceptable image render propose auxiliary feature sample interactive rate plausible review interactive approach denoising interactive denoising monte carlo render image ray trace challenge render interactively due amount ray trace per pixel   explore reduce gathering ltering input image sample per pixel  proposes lter incident indirect radiance overview interactive denoising theme interactive MC denoising indirect illumination lter latter  lters avoid  wavelet adaptive manifold image lters ltering adaptive manifold texture approach convincing lack error estimate apply oine approach therefore local detail lose refer comparison moreover amount ltering user parameter approach indirect user guidance another frequency analysis transport axis align lters propose interactive shadow diuse indirect multiple distribution eects faster accurate shear lters previous propose implementation quantize 4D shear lter accurate axis align version domain specic lters tailor transport eects furthermore shadow lter apply dierent parameter individual scene contrast approach independent illumination scene acm transaction graphic vol article publication date july recurrent autoencoder interactive reconstruction concurrent denoising machine target image denoising sample convolutional neural network cnn cnns recently graphic related task image classication localization colorization inpainting interpolation consistently refer interested reader recent survey topic cnns consist sequence layer apply convolution kernel input precede layer non linear mapping denotes convolution scalar 2D image ith activation lth layer jth 2D convolution kernel bias associate output activation respectively typically  linear relu max input rgb image usually layer activation algorithm skip connection layer shortcut training network substantially easy recurrent connection link layer network becomes retain frame animation sequence image restoration denoising image corrupt gaussian active research topic image processing neural network currently publish convolutional architecture hierarchical skip connection architecture yield super resolution jpeg  text removal network image learns image locally training image patch approach application dierent characteristic additive gaussian sample typically outside dynamic image input pixel therefore approximately average task  pixel closely related image inpainting image superresolution dierence application image generation access auxiliary information depth normal buers addition pixel closely related fully network estimate auxiliary parameter non local lter contrast entire ltering operation cnns focus highly interactive ultimately realtime render temporal stability reconstruct frame important context video super resolution demonstrate recurrent neural network rnns sub pixel cnns  recurrent memory bottleneck autoencoder improve temporal stability super resolution potential temporal  limited spatially application aect variable image hierarchical rnns  despite availability advanced transport bidirectional trace metropolis transport industrial renderers rely optimize unidirectional tracer implement bidirectional generate noisy integral estimate quickly target interactive render sample  trace estimate ecient generate input technique detail trace implementation reduce variance estimate without incur substantial additional afterwards discus interaction renderer reconstruction algorithm interactive tracer optimize tracer noisy input image traditional tracer shoot ray pixel stochastically scatter accord prole intersect  recursively strike source employ estimation improve convergence deterministically vertex accelerate visible determination leverage gpus rasterize instead ray trace rst camera associate shade attribute buer mesh mesh primitive intersection barycentric coordinate shade normal diuse specular albedo vector rasterization pas trace nvidia optix gpu ray tracer depth eld blur trace eects eciently implement moreover introduce buer discrepancy  sequence sample source scatter direction apply regularization glossy specular scatter signicantly reduces sparse intensity outlier glossy reections bias limit indirect bounce practical interactivity tracer generates camera indirect camera  pixel input generation per pixel comprises rasterization ray evaluation sample throughout sample acm transaction graphic vol article publication date july alla image emphasize trace estimation along auxiliary input reconstruction buer contains information geometry source scene subset available reconstruction export image consists multiple buers addition noisy dynamic rgb image export buer feature rasterization pas reconstruction algorithm shade normal 2D vector depth roughness input reconstruction algorithm consists scalar per pixel linear precision  FP retain dynamic hdr linearize depth accuracy FP remain channel per channel calculate shade normal camera projection matrix component simplify input demodulate noisy rgb image albedo directly visible untextured illumination remove texture complexity noisy image signicantly facilitate training reduce network capacity untextured illumination reconstruct modulate albedo texture detail nal render sample directly visible pixel aforementioned input prone image aliasing antialiasing input necessitate sample rate preclude interactive render however apply readily available screen antialiasing technique reconstruct output image instead resolve remain aliasing negligible detail image sequence reconstruction recurrent denoising autoencoder image reconstruction algorithm data driven learns mapping noisy input image sequence output image sequence training consist input sequence desire output sequence training target reconstruction recent image restoration convolutional network hierarchical skip connection network cnn layer kernel pixel spatial perform variant layer operating spatial resolution skip connection layer correspond layer network rst layer layer layer minus network remove additive gaussian individual image various weakness application layer operates resolution image spatially sparse sample monte carlo rendering signicantly temporally stable frame denoised isolation address weakness modify architecture subsampling upsampling stage recurrent connection preparation training data loss function optimize training denoising autoencoder skip connection depict network architecture distinct encoder decoder stage decrease increase spatial resolution respectively flownet net architecture optical estimation image segmentation respectively emphasizes connection denoising autoencoders autoencoders network reconstruct input internal representation denoising autoencoders remove input denoising autoencoder reconstruct noisy input layer spatial resolution generally consume approximately magnitude faster execution negligible decrease quality gaussian receptive eld deeper layer input image pixel neighborhood therefore sparse input network learns mapping input output desirable auxiliary input addition data optimization training considers input automatically disambiguate data recurrent denoising autoencoder temporal denoising recurrent neural network rnn processing arbitrarily input sequence rnn feedback loop output previous hidden retain important information input application denoise continuous image achieve temporally stable input sparse recurrent connection information illumination retain temporal feature multiple introduce fully convolutional recurrent encode stage related recently video super resolution aware earlier application context autoencoder skip connection important entire architecture recurrent connection remains fully convolutional allows network xed pixel later apply sequence arbitrary resolution resolution specic layer lose acm transaction graphic vol article publication date july recurrent autoencoder interactive reconstruction encoder decoder rcnn recurrent convolutional conv conv conv conv conv conv architecture recurrent autoencoder input scalar per pixel noisy rgb normal vector depth roughness encoder stage convolution max pool decoder stage applies upsampling concatenates per pixel feature skip connection spatial resolution applies convolution pool convolution pixel spatial visualize internal structure recurrent rcnn connection input refers hidden recurrent persists animation frame similarly ecient recurrent encoder oppose decoder signal sparser encoder recurrent bottleneck autoencoder layer encoder  insucient information ows skip connection skip recurrent altogether therefore recurrent encode stage max pool recurrent consists convolution layer pixel spatial layer input feature previous layer encoder concatenates feature previous hidden remain convolution layer becomes hidden output recurrent sucient temporal receptive eld multi cascade recurrent allows eciently retain image feature temporally multiple convolution layer recurrent input resolution feature encode stage attach formally output hidden recurrent equation convolution kernel pixel spatial dened output input hidden input concatenation operator precursor rnn training network frame sequence input target reduce temporal  clearly visible sequence longer training training preparation training data smooth camera animation frame scene available training frame generate dierent noisy image sample per pixel auxiliary feature target image training multiple noisy image instance monte carlo reconstruct image increase training tenfold negligible additional target image noisy image auxiliary feature primary ray rasterize generate image render training perform randomly training sequence sequence consecutive frame temporal context training randomly scene sequence training subsequence within  sequence randomly alternate backward playback network various camera movement useful randomly camera training sequence instead advance camera frame camera target image frame animation advance noisy image dierent random addition randomly picked rotation training sequence movement direction random modulation separately channel apply entire sequence network linear input target relation independence channel loss function loss function  error network output training target compute training commonly loss function image restoration error predict image target  however loss instead reduce  artifact reconstruct image rst loss spatial loss denote image temporal training sequence acm transaction graphic vol article publication date july alla ith pixel predict target image correspondingly useful  image channel compute loss perceptual gamma correction however aggressive allows penalize error image eciently implementation input target image preprocess spatial loss overall image metric tolerant outlier penalize dierences detail gradient domain loss gradient compute frequency error norm  image comparison metric medical image metric laplacian gaussian kernel detection laplacian detect sensitive image pre smooth gaussian lter rst detection recommend parameter gaussian kernel loss minimize error image isolation however penalize temporal incoherence  frame neither encourage optimizer recurrent connection pas data across frame therefore introduce temporal loss temporal derivative ith image pixel compute   ith pixel previous image temporal training sequence combination loss nal training loss adjustable contribution loss picked approximately equalize improve convergence important assign loss function frame later sequence amplify temporal gradient incentivize temporal training rnn gaussian curve modulate sequence image verify combine loss improvement spatial loss structural similarity metric ssim validation sequence  epoch training ssim improvement combine loss implementation RESULTS parameter convergence network detail practical aspect training network interactive reconstruction finally focus performance measurement quality epoch training loss untextured untextured depth untextured normal depth untextured normal untextured normal depth roughness convergence average training loss function epoch network without auxiliary feature network analysis convergence behavior network layer auxiliary input feature network apply image reconstruction lter therefore demonstrate qualitative  apply network repeatedly image network convergence behavior encoder decoder stage dierent feature training loss decrease marginally computational increase con  highlight convolution layer network feedforward encoder decoder output layer rcnn output feature per pixel rst stage encoder subsampling operation xed rate compression factor subsampling therefore information generally lose stage reintroduce skip connection decoder  amount data upsampling auxiliary feature convergence plot training loss average  scene switch untextured gradually auxiliary feature network training characteristic untextured demodulate image albedo primary signicantly improves convergence another improvement obtain introduce normal auxiliary feature normal network detect silhouette detect discontinuity shade additional improvement obtain depth roughness auxiliary feature disambiguate information contour silhouette scene dierent acm transaction graphic vol article publication date july recurrent autoencoder interactive reconstruction AE AE AE AE AE feat AE feat AE feat conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv conv medium epoch training loss medium epoch training loss ablation network parameter sweep layer feature conv convolution layer output feature indicates layer additionally output layer output feature highlight training loss training loss convergence plot network dierent layer training loss convergence plot network dierent output feature perform qualitative analysis reconstruction filter apply filter input image recursively iteration filter preserve smooth filter contrast  mask filter others reconstruction filter demonstrate qualitative behavior propose reconstruction lter  apply input image multiple recursively rst noisy image auxiliary feature perform inference noisy image another inference feature unchanged qualitative analysis lter apply lter recursively frame  inset subtle trim shadow gradually around multiple iteration pole lter lter behaves preserve kernel around noisy sample preserve lter preserve local contrast iteration   classroom network  scene illumination mostly blur however lter preserve initial contrast along training data generalization network trainable parameter convolutional network naturally tolerant overtting training suciently earlier image restoration training image sequence oer considerable variety network scene  3D scene oer convenient gathering arbitrary amount training data variation concern network learns reconstruct feature training training frequency feature vegetation ability reconstruct unseen feature remain limited ideally network dozen dierent scene geometry setup camera setup scene   classroom training network reconstruct  scene accompany video reconstruct training setup unless explicitly otherwise   sponza scene default source  modify acm transaction graphic vol article publication date july alla reconstruction MC input    reference  sponza   classroom closeup bounce global illumination spp input MC axis align filter   wavelet filter  filter  statistic consult supplemental resolution image video sequence replace diuse BRDF glossy  BRDF roughness texture reuse specular source slowly along axis scene illumination classroom directional source illumination texture geometric layer target image render spp  scene acm transaction graphic vol article publication date july recurrent autoencoder interactive reconstruction filter  sponza   classroom RMSE ssim RMSE ssim RMSE ssim RMSE ssim RMSE ssim    error statistic image alternative sidestep concern cient scene variety training network speci  scene scene attractive training become baking network arbitrary image sequence scene possibly poorly content demonstrate ability network specialize data perform training  input frame spp target image generate specically supplementary inference scene dierent camera image video  training implementation training implement training network  theano nvidia DGX training recurrent propagate subpart rnn replicate unroll recurrence loop training epoch approximately gpu preprocessing dataset random eciently fetch  epoch adam rate decay rate rate  tenfold geometric progression rst training epoch decrease accord schedule minibatch sequence epoch randomizes training data parameter initialize leaky relu activation layer linear activation max pool subsampling ltering upsampling choice various parameter tends aect slightly refer interested reader recent survey reconstruction  sample prior implement multiple algorithm axis align lter  shadow indirect illumination avoid  wavelet lter  lter  lter LBF ray budget allows shadow ray per pixel axis align shadow lter minimum maximum occlusion distance within pixel estimate minimum maximum slope eld frequency spectrum implementation reconstruction LBF reference comparison sample pixel filter spp ssim recurrent autoencoder spp ssim network scene perform adaptive sample sample pixel estimate variance pixel spatial thanks buer skip normalization variance auxiliary feature temporal antialiasing  pixel antialiasing negligible reduces  feature subtle blur prior temporally stable sample pixel comparison apply  supplemental pas benet  recurrent loop ner resolution insucient temporal receptive eld  frequency feature video oers evaluation temporal stability closeup scene  demonstrates ability network preserve feature contact shadow handle scant appearance   classroom scene training albeit dierent camera  classroom dierent setup training demonstrates ability network adapt arbitrary viewpoint dierent setup  scene network prior inference demonstrates network ability generalize completely data illumination scene geometry  network none training foliage usually challenge lter video network generalizes convincingly  specular pure specularities training therefore somewhat surprising training theoretical argument quality improvement varied training error RMSE structural similarity metric ssim measurement demonstrates agnostic input lter challenge situation complex contact shadow reasonable quality sample bounce lter LBF scene simulated variety monte carlo eects sample pixel perform comparison LBF lter spp input network spp input generalizes input sample per pixel quality surpasses LBF acm transaction graphic vol article publication date july alla reconstruction MC input    reference grid pillar closeup shadow filter spp input MC axis align filter   wavelet filter  filter  demonstrate autoencoder spp scenario generalize signicantly sample bounce generate image trace bounce sample per pixel comparison oine denoiser nonlinearly regression NFOR spp generalize input sample bounce reasonable denoising quality within performance  failure training data insucient sample sparse disambiguate important output feature lack detail  visually smooth image approximately preservation sometimes appearance shadow  sponza sample feature specular highlight glossy reections lamp  classroom tendency network average suboptimal network spp overall spp input however oine specically craft perform systematically quantitative error metric reconstruction performance implement inference runtime reconstruction fuse cuda kernel cudnn convolution routine winograd optimization http developer nvidia com cudnn achieve highly interactive performance gpus image pixel reconstruction nvidia pascal titan execution linearly pixel performance comparison varies considerably    LBF NFOR runtime intel HQ cpu comparison image quality obtainable xed input sample disregard performance dierences performance optix tracer varies   sample pixel context tracer becomes substantially faster expensive another sample pixel reconstruct image furthermore convolutional network evidence inference network accelerate considerably building custom reduce precision hardware scenario highly interactive realtime domain CONCLUSIONS future rst application recurrent denoising autoencoders convolutional network transport reconstruction temporally coherent animation sequence global illumination avenue future approach demonstrate quality interactive reconstruction ahead improve introduce varied training addition  specialize acm transaction graphic vol article publication date july recurrent autoencoder interactive reconstruction reconstruction reference MC input   NFOR reference bathroom living generalization autoencoder spp data apply spp MC input image closeup bounce global illumination input  wavelet filter  filter  nonlinearly regression NFOR possibly simplify target dimensional distribution eects blur depth eld likely extend handle eects lens coordinate input network apply sample rate regime quality render amount remains input image geometry magnitude detailed