goal transport acquisition image sparse direction combine enable arbitrary relighting relighting sparse image significant attention relatively progress synthesis sparse photometric image image capture lit directional source spherical  camera sphere surround synthesize novel viewpoint across direction cone sparse direction approach relates previous synthesis image render technique usually restrict baseline capture environment illumination baseline input image correspondence occlusion however benefit structure photometric image convolutional network directly synthesize input network combine 3D convolution sweep volume novel per per depth attention prediction network effectively aggregate multi appearance network synthetic dataset scene complex geometry synthesize novel viewpoint capture data reproduces complex appearance occlusion dependent specularities shadow moreover combine previous relighting technique enable apply computer vision multiview stereo sparse image CCS concept compute methodology image render additional appearance acquisition novel synthesis introduction central computer graphic vision acquire image scene reproduce appearance arbitrary viewpoint traditionally accomplish densely sample scene reflectance interpolate image combination image render relighting recent demonstrate image relighting sparse photometric image capture acm trans graph vol article publication date july zexiang sai kalyan sunkavalli sunil hadap hao ravi ramamoorthi directional significantly reduce acquisition however novel synthesis dense sample scene consequently capture image scene complex reflectance recent address novel synthesis sparse image highly restrict viewpoint synthesize goal appearance acquisition render practical synthesize novel viewpoint sparse image image scene consist camera vertex adjoin regular icosahedron central camera distribute symmetrically around angle baseline capture image significant occlusion multiview stereo fail reconstruct geometry sparse interpolate entire convex hull viewpoint cone accurately reproduce complex occlusion frequency dependent specularities combination structure acquisition procedure novel interpolation scheme unlike previous synthesis approach capture image environment illumination acquire image directional photometric image capture appearance information shade shadow specularities scene reconstruction via photometric stereo image relighting input synthesis capture detailed scene appearance enables application novel relighting introduce novel convolutional neural network learns interpolate baseline photometric image render arbitrary output viewpoint previous synthesis network project input image onto multiple depth output construct dependent sweep volume volume predict output depth 3D convolutional layer downsampling upsampling operation allows network geometry appearance multiple spatial novel component explicitly predict per per input attention attention modulate 3D sweep volume network aggregate multi appearance accounting occlusion viewpoint variation etc blending ibr sharper accurate supervise output image depth network learns predict attention unsupervised fashion cnn synthetic dataset consist scene procedurally generate complex spatially BRDFs render scene camera configuration random directional trace render image approximate appearance transport network generalize capture scene generates photorealistic interpolate complex geometry appearance challenge occlusion frequency specularities cast shadow demonstrate extension approach beyond synthesis multiple acquisition setup capture sparse multi multi image synthesis network extend synthesize appearance novel sparse data synthesis network  capture scene dense input multi stereo algorithm reconstruction significantly sparse input sparse image towards eliminate dense capture scene acquisition practical related WORKS transport acquisition traditionally transport acquisition complex capture image scene dense direction sample explicitly reconstruct scene geometry reflectance recent demonstrate geometry reflectance reconstruction relaxed setting handheld capture unknown environment detailed discussion previous appearance acquisition refer reader quality render capture image requirement relaxed specific application image relighting focus directly combine image capture relight scene novel earlier image relighting brute sample recent leveraged transport coherence reduce image demonstrate image relighting image sparse capture sufficient reflectance estimation planar sample scene geometry reflectance focus capture multi scene appearance reproduce complex  specularities occlusion image moreover extend capture scene appearance image significant traditional transport acquisition image novel synthesis novel synthesis focus interpolate appearance scene capture image interpolation aspect acm trans graph vol article publication date july synthesis sparse photometric image transport acquisition sample ray densely capture reconstruct sparse sample leverage various correspondence multiple alternatively image render project capture image onto proxy geometry reconstruct capture image blend resample novel viewpoint  zhang propose 3D reconstructs depth visibility input achieve blending blending technique achieve ghost synthesis inaccurate 3D reconstruction learns predict blending blending technique scan MVS reconstruct geometry input densely sample viewpoint rely capture image overlap reasonable baseline without geometric reconstruction synthesis fail moreover usually viewpoint navigation focus reproduce detailed appearance specularities contrast image capture fairly baseline reproduces complex scene appearance accurately fashion learns predict appearance depth attention blending capture complex scene appearance frequency reconstruct geometry appearance   representation focus compress data pca vector quantization network capture appearance vastly image moreover network scene agnostic representation interpolate scene image viewpoint novel synthesis recently technique apply novel synthesis achieve unstructured multi interpolation narrow baseline stereo extrapolation narrow baseline interpolation extrapolation context estimate geometry depth per depth probability blending predict input novel resolve visibility implicit whereas network learns multi correspondence explicitly predicts per input visibility aware attention jointly depth probability novel viewpoint importantly demonstrate synthesize wider viewpoint acquisition configuration regular convex icosahedron  symmetric vertex projective configuration background hemisphere towards central setup denote vertex adjoin goal synthesize novel orange convex hull dash geometry directly generate pixel novel multiple input restrict specific leverage prediction warp pixel source warp combine per input confidence improve aggregation attention predict geometric correspondence infer jointly depth incorporate information occlusion viewpoint difference etc realistic appearance acquisition apply appearance acquisition application reflectance capture reflectance estimation depth estimation photometric image  BRDF acquisition image relighting sparse sample focus explore multi appearance acquisition photometric measurement achieve photorealistic novel synthesis directional sparse acquisition configuration previous reflectance  acquisition setup camera sphere assume camera respect scene image scene ensures sufficient pixel coverage goal acquire appearance generic scene without assumption scene composition therefore utilize symmetric camera configuration optimal average decision configuration symmetrically sample sphere sample balance constraint sparse sample minimizes acm trans graph vol article publication date july zexiang sai kalyan sunkavalli sunil hadap hao ravi ramamoorthi feature extractor shade predictor geometric warp geometric warp correspondence predictor depth multi input image multi correspondence feature sweep volume sweep volume visibility aware attention attention masked volume per depth image depth probability image predict novel image predict novel depth corr sec shade sec 2D image feature 3D feature volume 2D conv net 3D conv net fix geometric warp network network overview synthesis network consists sweep volume construct geometric warp corr extract image feature estimate attention depth probability depth  estimate scene depth novel shade input image volume attention depth probability synthesize novel image refer supplementary detail acquisition ensure sufficient overlap quality interpolation configuration choice inspire standard  symmetric regular convex icosahedron icosahedron vertex equilateral triangular symmetrically distribute around sphere icosahedron investigate setup camera camera vertex boundary camera surround central vertex configuration angular distance central boundary baseline camera scene limited overlap goal synthesize arbitrary convex hull cone angular baseline symmetry icosahedron setup potentially extend sphere acquisition camera vertex merely sparse camera setup significantly previous technique capture image focus practical scene compose platform capture photometric image scene lit arbitrary directional frontal hemisphere circular likely illuminate scene scene contribution multi multi extension sec fix collocate central camera surround vertex fix direction scenario allows network leverage structure input quality synthesis algorithm image pre define calibrate directional goal synthesize image specify novel input inspire recent propose cnn directly regress output image geometry ibr scene geometry align blend multiview data however instead rely precomputed geometric proxy network infer multi correspondence information novel predict novel depth synthetic dataset truth image dependent depth generate supervision network leverage supervision shade correspondence simultaneously component network  modulate input per per scene depth attention without supervision attention indirectly combination visibility viewpoint factor account quality synthesis discus detail network sec data generation sec training detail sec acm trans graph vol article publication date july synthesis sparse photometric image input architecture input network fix input image directional architecture potentially generalize setup fix sec network regress image associate depth novel involves align aggregate multi input input camera parameter novel camera parameter network sweep volume representation sweep volume construct warp feature multiple input novel multiple pre define depth warp function denote  geometric function implement non learnable differentiable layer sweep volume geometrically align structure data suitable ibr network understand multi data information input output viewpoint specifically angular distance novel input depth sweep volume additional input network network regression function multi data denote subscript multiple depth denote subscript notation convention network corr seek analyze multi correspondence reconstruct scene geometry denote shade reconstructs output image correspondence predictor shade predictor network 3D net architecture comprise 3D convolution upsampling downsampling operation correspond sweep volume allows network multi scene geometry appearance predict output depth sweep volume representation contains incorrect redundant feature feature incorrect depth occlude dependent therefore estimate attention account information depth incorporate factor per visibility attention likely highly correlate scene geometry predict jointly depth probability corr  input image pixel volume attention shade predictor ensures depth input pixel volume meaningful information shade prediction signicantly improve synthesis truth render image supervision allows network scene appearance photo consistency supervise output depth image allows network scene geometry correspondence learnable parameter correspondence shade data highly correlate information image depth supervision multi correspondence corr multi reconstruction render fundamentally rely correspondence across input image achieve cnns sweep volume filter multiple depth visibility information highly correlate depth express distance multi appearance consistent visibility express appearance consistent therefore propose novel correspondence estimation network  jointly infer depth visibility aware attention novel corr consists feature extractor correspondence predictor photometric image capture directional frequency dependent specularities complicate correspondence therefore apply net style feature extractor pre filter input image learns extract specular invariant feature orientation meaningful correspondence estimation specifically transforms channel rgb image channel feature discrete pre define depth construct sweep volume novel extract per input feature geometrically warp onto depth distance input novel volume denote warp depth correspondence inference network understand photometric consistency across multiple achieve processing volume 3D filter gradually expand receptive easy network multiview consistency inconsistency pre feature volume remove average multi feature depth operation variance volume reconstruction however variance volume express global information across subtracts retains per information per allows network infer dependent attention leverage global information network compute variance volume subsequent convolutional layer average across 3D depth image height image width volume voxel channel augment feature acm trans graph vol article publication date july zexiang sai kalyan sunkavalli sunil hadap hao ravi ramamoorthi difference per depth network utilize novel location input correspondence per voxel per pixel concatenation operator sphere acquisition configuration cosine angle volume channel correspondence predictor 3D net style network volume series 3D convolutional layer normalization GN relu layer downsampling upsampling along depth image dimension analyze multi correspondence multiple spatial detail correspondence predictor output channel volume channel per attention volume channel depth probability volume channel corresponds attention information correspond input incorporates visibility viewpoint information attention depth pixel wise attention mask shade prediction pixel wise depth probability depth depth wise softmax operation actual probability depth max learnable scalar parameter output depth image finally predict truth depth image supervision attention depth estimate highly correlate therefore estimate correspondence predictor network information layer ensures attention prediction utilizes depth supervision meaningful feature attention depth probability shade prediction aggregate multi appearance predict shade shade infer scene appearance novel highly challenge task configuration angular baseline input scene limited overlap  complex shade frequency specular highlight significantly across resolve challenge image prediction shade shade shade predictor scene appearance multi image multi correspondence information attention depth probability predict corr eqn sweep volume construct image homography warp volume contains information warp onto multiple volume highly redundant potentially inconsistent information multiple due occlusion feature network pre mask volume visibility aware attention infer correspondence disentangle redundancy inconsistency mask achieve voxel wise multiplication depth  directly connects corr shade corr leverage appearance information shade estimate attention shade prediction accurate shade predictor 3D unet style network correspondence predictor channel layer appearance masked volume attention information predicts channel appearance volume concatenate voxel wise eqn attention addition modulate appearance volume network freedom reconstruct scene appearance predict image predict appearance scene depth per predict image depth probability corr reconstruct image normalize depth probability volume max scalar parameter eqn image depth incorrect outlier pixel completely masked truth render novel image supervision network transfer information shade corr attention depth estimate novel network consolidates appearance synthesis correspondence estimation leverage inference extension multi input photometric application image relighting photometric stereo acquire photometric image multiple source viewpoint propose extension approach multi multi datasets sec application capture image fix fix multi data allows geometric reconstruction information scene appearance acm trans graph vol article publication date july synthesis sparse photometric image specularities source disappear another source shadow illuminate another estimation normal feature extend feature extractor advantage multi correspondence inference difference multi feature extractor merely input channel fix structure input subscript specifies stack image source channel feature input corr predicts attention depth probability multi data input shade remains predicts novel image source multi image network synthesize novel input combine imagebased relighting render scene appearance novel viewpoint scene acquisition scenario data generation knowledge exist dataset contains multi photometric image previous novel synthesis data video scene specific none apply quality appearance acquisition scenario therefore novel synthetic dataset procedurally generate combine primitive randomly generate bump randomly merge primitive training scene scene texture SVBRDFs adobe stock 3D dataset dataset contains SVBRDFs training render dataset trace sample optix achieve trace physically render ensures image realistic transport render resolution image gamma render scene camera configuration described sec scene randomly angle correspondingly calculate distance camera angle scene ensure pixel coverage training image consists input novel directional training scene randomly novel input random directional render training scene randomly novel directional render creates image image http stock adobe com asset training detail loss function loss truth image depth novel specifically image loss depth loss loss  parameter strategy radially symmetric leverage symmetry structure input network training easy novel rotate image depth around central direction direction towards central input reorder input achieve canonical input layout central counter clockwise assume scene capture calibrate spherical  physical scene distance camera scene approximately allows depth specify correspondingly network fully convolutional arbitrary depth training training perfectly symmetric camera distribute distance scene truth scene maximum difference pixel depth uniformly express training randomly network sweep volume specify roughly distance scene network nvidia titan gpus batch gpu batch apply normalization performance batch normalization per gpu batch training randomly patch novel image depth data augmentation image background non background pixel network generally converges training epoch gpus EXPERIMENTS comprehensive evaluation synthetic data ablation synthetic data justify network architecture ablation synthetic dataset propose photometric novel synthesis network CS feature extractor correspondence shade predictor variant multi network TCS acm trans graph vol article publication date july zexiang sai kalyan sunkavalli sunil hadap hao ravi ramamoorthi ablation evaluate version network synthetic dataset image error psnr ssim depth error central image image psnr image ssim depth CS nov  CS TCS truth qualitative comparison synthetic CS CS nov without attention respectively CS nov suffers bleeding artifact arrow resolve CS directional input corr multi feature extractor specifically network  depth supervision CS nov network attention evaluate network synthetic dataset image loss psnr ssim depth loss avoid bias metric background render image central image evaluation non background pixel average calculate depth foreground training numerical comparison network tab demonstrate CS CS nov  attention significantly improve reconstruction performance image loss reduces accompany improvement psnr ssim qualitative comparison CS CS nov bleeding artifact CS unable resolve occlusion scene attention infer synthesis unsupervised network  attention without depth supervision performs synthesis CS nov without attention depth supervision comparison demonstrate role visibility aware attention effectively eliminate incorrect inconsistent information sweep volume  CS depth supervision improves reconstruction accuracy subtle finally multi data multi network TCS performance confirms multi feature extractor extract feature depth prediction image synthesis version multi version acquire image naturally combine image relighting enable data capture capture scene compose platform spherical  capture scene input central directional directional multi additional application capture novel truth validate synthesis quality camera away platform scene scene network robust variation randomize training mask background capture image passing network network fully convolutional directly apply image although training nvidia titan generate image comparison previous synthesis previous synthesis ibr however usually ibr application densely sample training implementation dataset fail predict reasonable baseline estimate geometry multi stereo sparse input besides specific scenario extrapolation easy apply training release network dataset converge reasonable significantly challenge task therefore  ibr  zhang already demonstrate performs synthesis directly apply model kitti ShapeNet data therefore retrain model dataset albeit background scenario acm trans graph vol article publication date july synthesis sparse photometric image input image PSNRs  PSNRs   zhang closer  zhang truth comparison synthesis Soft3D baseline input input direction novel direction fourth closer input marked grey rectangle significantly difference almost imperceptible truth cropped inset correspond PSNRs  qualitative quantitative comparison capture scene complicate texture complex specularities shadow image performs significantly qualitatively synthesize image detail inset quantitatively psnr ssim previous fail handle challenge baseline configuration blur appearance detail align ghost artifact serious ghost artifact photorealistic synthesis significantly psnr ssim inset recovers complicate texture challenge shadow dependent specularities closer input fourth easy input improve however baseline input baseline input highlight accuracy robustness synthesis photometric data synthesis network capture truth photo realistic novel image scene accurately truth demonstrate generates quality interpolation challenge direction boundary  cone limited input information consistent across variety scene  cloth mental plastic candy geometry multiple comparison multi network challenge scene directional network extend multi network scene contains structure thumb distinct training geometry primitive highly non convex structure exhibit challenge cast shadow complicate correspondence inference nevertheless network performs direction acm trans graph vol article publication date july zexiang sai kalyan sunkavalli sunil hadap hao ravi ramamoorthi input image multi truth multi network comparison complex scene capture challenge direction marked hollow network generate ghost artifact challenge direction marked arrow multi network resolve issue image multiple source marked direction network quality input image direction marked label novel marked label input image truth limitation fails reconstruct  highly non convex occlusion network generate obvious ghost artifact challenge direction multi network resolve issue thanks reliable correspondence inference multi image novel synthesis dierent directional novel relighting environment novel relighting novel synthesis apply multi network synthesize novel image directional marked label synthesize marked quality synthesis input image relighting technique relighting environment limitation handle opaque scene limitation training dataset network cropped image limit spatial appearance consequently specularities significantly reconstruct blur specularities network generates blur ghost highly non convex scene visible additional APPLICATIONS synthesis combine scene acquisition render technique enable application demonstrate novel relighting synthesize novel image capture directional image relighting enable render novel relighting apply multi network directional synthesize novel image separately relight net network pas synthesize novel image network generate image novel directional acm trans graph vol article publication date july synthesis sparse photometric image reconstruction capture image reconstruction capture image reconstruction image synthesize image reconstruction image synthesize image multi stereo reconstruction synthesize image synthesize quality novel image input multi stereo algorithm COLMAP generate 3D reconstruction comparable reconstruction capture image COLMAP reconstructs incomplete geometry sparse image achieve relighting novel environment linearly combine relit image network relight net separately without refinement processing novel environment realistic aspect  blurriness incorrect shadow temporal inconsistency become obvious novel environment jointly training network relight net task specific training dataset potentially resolve alleviate issue knowledge attempt synthesize reflectance enable viewpoint sparse sample image multi stereo multi stereo dense input fail reconstruct  geometry sparse apply  capture scene synthesize novel image around scene image pas synthesize image multi stereo COLMAP achieve 3D reconstruction scene baseline pas capture truth image COLMAP reconstruction qualitatively COLMAP reconstructs incomplete geometry sparse MVS sparse viewpoint robust conclusion future demonstrate synthesize photometric scene appearance novel viewpoint sparse image capture baseline contrast previous rely densely sample scene viewpoint achieve training novel cnn simultaneously infer correspondence shade structure photometric image network predicts  attention effectively address photometric geometric inconsistency accurate aggregation multi scene appearance evaluation comparison previous synthesis generate significantly accurate photorealistic image across scene fundamentally towards capture render scene appearance sparse image classic vision graphic enable application demonstrate synthesize image achieve novel relighting multi stereo sparse image future explore extension technique challenge scene acquisition task multi BRDF reconstruction scene reconstruction acquisition dynamic scene appearance sparse image