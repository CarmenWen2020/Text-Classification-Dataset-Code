demonstrate novel neural network capable reconstruct inertial measurement IMUs worn user address challenge severely constrain multiple parameter imu orientation capture imu data conjunction truth expensive target application scenario outdoors model temporal dependency non linear optimization proven effective prior prediction infeasible address important limitation temporal prior sufficient data synthesize imu data capture datasets directional rnn architecture leverage future information available training deploy network slide fashion retain capability evaluate dip imu dataset consist IMUs validation sequence constitutes imu dataset publicly available quantitatively evaluate approach multiple datasets implementation dip imu code available research purpose CCS concept compute methodology capture additional imu rnn introduction application bio mechanical analysis emerge computer interaction paradigm virtual augment reality VR AR capture user 3D skeletal configuration application impose challenge constraint reconstruction realtime everyday setting desk outdoors minimally invasive user instrumentation commonly task achieve via commercial capture mocap vicon http dip   http vicon com acm trans graph vol article publication date november  huang     michael otmar hilliges gerard pons moll expensive infrastructure marker user marker multi camera approach become accurate sometimes dense reconstruction camera setup computationally expensive recently rgb rgb camera estimation become feasible remains active research computer vision camera accurate multi importantly vision external camera visible image limitation practical barrier application occlusion desk user around outdoors sensor directly user overcomes prominent choice reconstruction task inertial measurement IMUs orientation acceleration hence easily worn commercial rely dense placement IMUs fully constrain attain accurate skeletal reconstruction sensor intrusive consume prone error swap sensor however recently demonstrate recover sensor IMUs albeit computational offline optimization non convex entire sequence per emerge consumer smart fitness tracker smart hololens google already integrate IMUs reconstruct 3D sensor enable application introduce dip inertial  capable estimate 3D IMUs function predicts accurate sparse orientation acceleration measurement alone challenge task observable measurement previous  temporal information important role capture datasets training  expensive overcome issue leverage observation insight datasets mocap cmu exist specifically leverage amass collection mocap datasets data SMPL model parameter leveraged synthesize imu data specifically virtual sensor SMPL mesh mocap sequence obtain virtual orientation via kinematics acceleration via finite difference leverage synthetic data training neural network model model temporal dependency leverage recurrent neural network rnns orientation acceleration SMPL parameter however acceleration information systematic error ambiguous mapping sensor orientation extremity knee bending problematic alleviate issue introduce novel loss network reconstruct acceleration training preserve information throughout network stack performance offline approach task leverage future information propose extension architecture leverage directional rnns improve reconstruction quality training architecture access information propagates information future vice versa retain regime deploy architecture slide fashion experimentally future frame sufficient quality prediction incur modest latency penalty synthetic data training already decent performance however imu data contains drift gap synthetic data distribution finetune model newly dip imu dataset approximately imu data experimentally evaluate dip TotalCapture benchmark dataset imu data reference truth dip imu dataset dip achieves accuracy angular error compete offline approach sip significant whereas sip sequence input demonstrate capability dip integrate approach VR proof concept demonstrator raw imu data input pipeline predicts without temporal filter hoc processing visualize via unity summary dip occupies unique estimation literature satisfies aforementioned constraint minimally intrusive everyday related literature estimation image video vast briefly review camera integrate multiple sensor signal optimization recover sparse sensor camera capture commercial camera mocap marker multiple calibrate camera environment overcome constraint research devote develop marker approach multiple camera offline processing achieve quality recently approach propose approach typically skeletal model image data collection gaussians acm trans graph vol article publication date november inertial  reconstruct sparse inertial measurement overview leverage exist mocap datasets synthesize imu signal virtual sensor SMPL mesh recurrent neural network imu signal input predicts SMPL parameter recover sensor approach performance combine discriminative generative approach however multi approach assume stationary calibrate camera therefore suitable mobile outdoor scenario recently estimation exploit convolutional network cnns detection fully unconstrained monocular image however capture 2D skeletal information predict 3D directly 2D rgb image demonstrate offline online setting camera worn estimation demonstrate setup intrusive user future miniature camera approach practical visual data camera complementary monocular depth camera additional information aid robust skeletal enable dense reconstruction non rigid deformation specialized scanner capture  dense reconstruction contrast camera approach rely calibrate camera environment instead leverage sparse orientation acceleration measurement reconstruction harder potential infrastructure setting traditional mocap optimization sensor fusion inertial tracker commercial inertial IMUs equip 3D accelerometer gyroscope magnetometer fuse kalman filter assume measurement drift imu orientation completely define standard skeletal model however IMUs intrusive setup error sensor limb compensate imu drift pioneer custom equip acoustic distance sensor IMUs however intrusive reproduce video inertial tracker sparse IMUs combine video input sparse optical marker constrain similarly sparse IMUs combine depth camera IMUs query database constrain depth tracker powerful hybrid approach video suffer drawback pure camera occlusion restrict volume recent camera IMUs estimate 3D multiple scene approach camera around optimization sparse IMUs von compute accurate 3D IMUs generative approach synthetic IMUs SMPL model sequence SMPL synthetic imu measurement sequence measurement optimize entire sequence IMUs recover leverage SMPL approach however conceptually instead rely computationally expensive offline optimization mapping sensor data SMPL performance accuracy despite IMUs sparse accelerometer marker alternative sensor fusion optimization mapping sensor reconstruct accelerometer retrieve pre acceleration database mapping acceleration alone however acm trans graph vol article publication date november  huang     michael otmar hilliges gerard pons moll signal typically noisy somewhat easy predict 3D sparse marker online local pca model built sparse marker location query database obtain marker constrain significantly furthermore mapping 3D location acceleration approach multi camera studio capture reflective marker sensor alternatively orientation obtain sensor inertial ultrasonic technology regress sensor global orientation global sensor greatly simplify inverse measurement relative static consequently capture restrict pre volume furthermore sensor rely hybrid inertial ultrasonic technology mostly specialized military application commercially available IMUs orientation acceleration fix sparse IMUs sparse IMUs input propose regress gaussian model specific movement individual user activity greatly limit applicability furthermore gaussian  poorly training sample generalization constrain demonstrate locomotion gait IMUs gait analysis activity recognition recently combination approach extract gait parameter via cnn medical purpose prediction locomotion imu hierarchical hidden markov model locomotion avatar adapt irregular terrain avoid obstacle trajectory approach cyclic cycle phase central role summary exist rely global joint input external camera specialized technology restrict pre define dip capable reconstruct sparse sensor overview goal reconstruct articulate unconstrained setting sparse IMUs sensor extremely directly observable sensor data alone overcome leverage statistical model regress parameter recurrent neural network rnn implementation SMPL model synthesize training data http  com output target lstm architecture approach ensures sufficient data available training encourages prediction subspace span briefly introduce salient aspect data generation sec sec accumulate dataset training sec propose network architecture sec overview entire pipeline background SMPL model SMPL parametrized model 3D parameter respectively return mesh vertex deformation apply template corresponds training 3D scan summarize completeness linear blend LBS function apply template mesh dependent deformation mesh LBS rotation joint dependent deformation model identity dependent LBS artifact capture deformation synthesize training data approach hence sufficiently dataset training camera marker publicly available datasets imu data truth knowledge dataset TotalCapture typical activity dataset contains synchronize imu mocap rgb data however due limited activity model dataset alone generalize interaction task VR AR however capability fitting SMPL parameter input modality IMUs marker data becomes feasible generate comprehensive training dataset synthesize imu measurement correspond SMPL parameter variety input datasets attain synthetic imu training data virtual sensor SMPL mesh orientation reading directly retrieve kinematics whereas obtain acceleration via finite difference assume virtual imu interval consecutive frame simulated acceleration compute datasets training data collection synthetic imu sensor reading correspond SMPL parameter acm trans graph vol article publication date november inertial  reconstruct sparse inertial measurement overview training network access sequence propagates temporal information future vice versa model consists stack bidirectional layer solid arrow layer dash arrow backward layer layer receives input backward layer diagonal arrow refer appendix detail runtime slide subsequence future predict incurs minimal latency application feasible subset amass dataset combination datasets computer graphic vision literature cmu   datasets datasets TotalCapture dip imu evaluation consist imu reading reference truth SMPL obtain reference SMPL TotalCapture available marker information finally dip imu dataset commercially available  sensor correspond SMPL obtain sip sensor detail data collection available combine datasets non trivial marker  datasets involve summarize datasets combine consist frame data knowledge imu dataset extent available data available research purpose generate synthetic imu data amass dip imu dataset correspond truth SMPL reconstruct IMUs imu data inertial  dip training dataset consist training sequence task function predicts SMPL parameter sparse imu input acceleration orientation sensor mapping severely  exist potentially SMPL correspond imu input knee orientation data remain mostly unchanged transient acceleration throughout sequence observation prior global optimization formulation consist orientation acceleration  approach computationally expensive offline sequence overcome limitation adopt data driven approach model mapping neural network likelihood loss function implicitly valid sequence directly imu input correspond SMPL target highly structure exhibit correlation due articulate recurrent neural network capable model temporal data previously model typically attempt predict frame sequence although input modality model dynamic exploit temporal coherency sequence recurrent neural network rnn directional recurrent neural network BiRNN memory lstm rnns summarize entire via fix hidden vector input predict vector standard rnns sufficient application experimentally access future information significantly improves predict parameter  temporal information account backward direction respectively rnns unidirectional acm trans graph vol article publication date november  huang     michael otmar hilliges gerard pons moll dataset overview denotes mocap denotes imu rgb imagery detail amass TotalCapture frame amass correspond frame generate fps downsampling data mode frame amass synth TotalCapture dip imu  exhibit qualitative quantitative access input sequence finding optimize entire sequence propose bidirectional architecture network WaveNet variant model perform quantitatively unacceptable visual jitter appendix contains detail assume rnns inherent temporal data hence smoother prediction non recurrent variant access future information BiRNN model important input sub sequence consist future frame slide fashion processing pipeline permit temporal ahead latency penalty minimal evaluation future frame compromise performance latency summarizes impact reconstruction quality setting strict latency requirement AR desirable future information roughly accuracy training uncertainty training model target normal distribution diagonal covariance standard likelihood loss network unidirectional bidirectional rnn sequence frame model output parameter gaussian distribution rnn literature  loss slightly performance error mse reconstruction acceleration input vector frame contains orientation acceleration data IMUs orientation rotation matrix SMPL frame orientation acceleration model normalize sensor input rotation matrix stack vectorized vec similarly normalize acceleration stack acceleration data inherently noisy stable orientation issue complicate subtle difference synthesize acceleration training data network architecture displayed tendency discard acceleration data already input almost zero acceleration input lack acceleration information model underestimate flexion extension joint alleviate introduce auxiliary task training model reconstruct input acceleration addition training additional loss model propagate acceleration information upper layer analogous task model auxiliary acceleration loss via normal distribution diagonal covariance     prediction loss acceleration reconstruction loss complementary propagate architecture network parameter minimal additional trainable network parameter predict   sufficient accuracy experimentally auxiliary acceleration loss improves prediction quantitatively regularization primarily synthetic data data sufficiently realistic slight difference relative data unavoidable consequence indication overfitting data yield accurate  prediction counteract overfitting regularize model via dropout directly input probability randomly filter input training randomly mask input model generalize data smoother temporal prediction tune data reduce gap synthetic data tune pre model training split dataset sec tune particularly effective situation specific usage scenario underrepresented training data hence procedure effective adapt novel situation implementation DETAILS network architecture implement network architecture tensorflow appendix summarizes architecture detail adam optimizer initial rate exponentially decayed rate decay alleviate explode acm trans graph vol article publication date november inertial  reconstruct sparse inertial measurement gradient apply gradient clip norm training scheme validation likelihood loss sensor calibration sensor  imu sensor axis accelerometer gyroscope magnetometer raw sensor reading sensor local coordinate frame  absolute orientation sensor relative global inertial frame specifically imu reading orientation rotation sensor local frame inertial frame acceleration local sensor coordinate calibration orientation acceleration model transform centric frame SMPL frame concretely relate inertial frame SMPL frame sensor onto sensor align SMPL frame consequently configuration mapping sensor SMPL frame identity allows inverse orientation  sensor calibration imu reading express SMPL frame  lastly due surround tissue sensor offset correspond denote constant offset BS respective coordinate frame frame sequence orientation BT compute per sensor offset BS inv inv denotes matrix inverse transform sensor orientation obtain virtual orientation frame  training interpretation virtual orientation straightforward orientation imu acceleration data transform SMPL coordinate frame gravity denote calibration couple overview coordinate frame involve calibration normalization generalization input data invariant direction input model normalize orientation respect sensor user spine  denote orientation orientation correspond http  com  TI TB calibration overview overview coordinate frame sensor placement calibration sensor compute normalize orientation acceleration  perform per training normalization scheme normalize frame sequence remove significant advantage scheme propose refer appendix detail input target input dip normalize orientation acceleration IMUs input frame vec vector dimension compact representation orientation rotation matrix exponential quaternion perform significantly rotation matrix directly rotation matrix bound training neural network similarly target instead regress parameter SMPL axis angle transform rotation matrix regress directly counter intuitive representation redundant empirically performance data collection overcome discrepancy sensor data characteristic synthetic data complement activity portrayed exist mocap datasets additional dataset imu data dip imu data male female  sensor inform consent imu data attain truth sip sensor compensate magnetic offset across IMUs reset perform sensor align spatial configuration reset subsequently sensor calibration procedure perform acm trans graph vol article publication date november  huang     michael otmar hilliges gerard pons moll participant repeatedly category extremity locomotion activity jumping jack boxing interaction task everyday capture approximately additional data dataset imu data appendix EXPERIMENTS ass propose perform variety quantitative qualitative evaluation offline baseline sip SOP reduce version sip leverage acceleration perform comparison variant architecture distinguish distinct setting performance offline sequence exist datasets TotalCapture dip imu contribution online capability demonstrate implement imu data input predict SMPL parameter output quantitative evaluation approach performs datasets report joint angle error compute positional error offline evaluation report offline model access sequence comparison model baseline sip SOP optimization sequence summarizes model perform sip baseline configuration BiRNN acc dropout outperforms sip angular error distribution entire TotalCapture dataset peak around error combination dropout input acceleration loss improve rnn BiRNN model due access future  perform qualitatively smoother prediction uni directional rnns tune data technique previous perform reasonably TotalCapture significant performance evident dip imu due difference dataset aforementioned gap synthetic data distribution however analyze stem model without access dip imu data hence dip imu report configuration tune dip imu data tune network training split offline online performance increase dip imu comparable TotalCapture illustrate error histogram dip imu tune performance TotalCapture decrease minimally catastrophic forget  error percentage BiRNN  error percentage BiRNN tune BiRNN histogram joint angle error error distribution TotalCapture offline BiRNN model performance dip imu tune described performance BiRNN function future frame TotalCapture joint angle error zero frame frame contribute prediction future respectively frame online evaluation perform configuration evaluate online evaluate performance sip SOP baseline online rnn configuration longer access entire sequence frame unidirectional rnn slide future frame BiRNN indicates network obtain accuracy online notably BiRNN access frame slightly outperforms offline TotalCapture due accumulation error hidden rnn stochasticity longer span online influence acceleration loss evident evaluate future frame TotalCapture BiRNN without acceleration loss performs acceleration loss future frame error increase influence future implementation leverage BiRNN dynamic data training entire sequence runtime subset frame available network summarizes performance network function frame future information available experimentally future frame compromise prediction accuracy latency penalty acm trans graph vol article publication date november inertial  reconstruct sparse inertial measurement offline evaluation SOP sip rnn BiRNN model TotalCapture dip imu error report joint angle error positional  centimeter model dropout apply dropout input sequence acc corresponds acceleration reconstruction loss SOP sip BiRNN access input sequence rnn model input BiRNN tune BiRNN acc dropout fin tune dip imu acceleration reconstruction loss dropout TotalCapture dip imu  deg  deg    deg  deg   SOP sip rnn dropout rnn acc rnn acc dropout BiRNN dropout BiRNN acc BiRNN acc dropout BiRNN tune online evaluation BiRNN model TotalCapture dip imu perform model offline evaluation acc dropout bracket model evaluate online mode future frame tune model tune dip imu TotalCapture dip imu  deg  deg    deg  deg   BiRNN BiRNN BiRNN tune BiRNN tune BiRNN tune frame playground dataset qualitative evaluation ass approach via qualitative evaluation quantitative report model BiRNN model offline mode discus online mode accompany video playground sip SOP playground dataset playground challenge capture outdoors contains uncommon dataset contains truth qualitative frame sequence obstacle SOP reconstruct systematically underestimate knee bending comparable sip although sometimes limb  baseline however sip optimizes sequence hence computationally expensive whereas prediction millisecond TotalCapture qualitative comparison baseline TotalCapture dataset summarizes sample frame dataset challenge bending model outperforms sip SOP reference model successfully reconstructs  sip SOP fail however fails reconstruct model dip imu lastly illustrate dip imu dataset sec appendix reference truth obtain sip IMUs however IMUs input acm trans graph vol article publication date november  huang     michael otmar hilliges gerard pons moll sample frame TotalCapture data rom sample frame dip imu baseline sip SOP summarizes sequence dataset evident model outperforms sip SOP qualitatively consistent sip SOP creates inter penetration limb torso model faithfully reproduces frame interestingly model rarely inter penetration smooth despite input video without explicit smoothness  constraint hence dip learns mapping imu data valid smoothness explain regularization training via dropout demo demonstrate model implement sensor data directly model display output raw imu reading retrieve via  sdk model output displayed via unity communication perform via network frame demo supplementary video demo online version tune BiRNN model explain frame future approximately fps faithful appendix discussion LIMITATIONS generalization model generalize unseen data observation achieve dataset imu recording capture despite training synthetic data qualitative performance another dataset playground demo challenge achieve due difference sensor data preprocessing across datasets robust orientation however robustness datasets setting future hypothesize limitation difficulty model acceleration synthetic effectively tune dip imu improves generalization certainly report additional insight issue synthetic BiRNN dataset dip imu oppose synthetic amass subsequently evaluate model TotalCapture performance around dip imu yield error comparable performance training synthetic tune dip imu however latter yield performance TotalCapture illustrate benefit synthetic database synthesis analyze impact difference synthetic data synthesize imu measurement datasets TotalCapture dip imu evaluate BiRNN synthetic version TotalCapture  performance data model performs synthetic version TotalCapture improvement dip imu improvement highlight domain difference address appendix detailed discussion additional summary hypothesize difference acceleration core failure typical failure sequence TotalCapture model robust various orientation demo extreme parallel ups challenge finally compute dip imu joint angle error appendix sensor orientation reading perform hence acceleration disambiguate however sensitivity acm trans graph vol article publication date november inertial  reconstruct sparse inertial measurement sample frame demo model handle various per frame average angular error sequence TotalCapture rom maximum error angular error sequence typical failure TotalCapture model baseline fail reconstruct imu placement environmental factor characteristic per sensor extremely challenge integrate effectively approach model baseline fail reconstruct arise model struggle fully exploit acceleration information hence future focus address challenge model acceleration explore sensor placement conclusion future estimation IMUs input avoids requirement camera leverage mocap corpus synthesize imu data orientation acceleration SMPL model synthetic data model dip generalizes imu data obtain accuracy angular error TotalCapture exploit temporal information directional rnn propagates information backwards training dip access sequence whereas model access frame frame future accurate estimate latency satisfy requirement dip performs comparably compete approach sip furthermore dip smooth generally without  demonstrates dip learns mapping valid without explicit smoothness joint angle limit future address capture multi interaction interact environment focus purely wearable sensor application admit external camera integrate visual input tracker obtain estimate capture contact knee bend recover IMUs approach transfer data internet introduce latency virtual social interaction hence explore predict future reduce latency finally unlike global translation limitation critical application scenario gps signal integrate phone integrate dip obtain reasonable global another potential regress global translation directly temporal imu input future demonstrate capability dip display prediction estimation wearable sensor dip role emerge interactive technology VR AR