novel approach enables photo realistic animation portrait video input video contrast exist approach restrict manipulation facial expression transfer 3D rotation expression gaze blinking source actor portrait video target actor core approach generative neural network novel architecture network input synthetic rendering parametric model predicts photo realistic video frame target actor realism render video transfer achieve careful adversarial training modify target video mimic behavior synthetically input enable source target video animation render synthetic target video reconstruct animation parameter source video network target ability freely recombine source target parameter demonstrate variety video rewrite application without explicitly model background instance reenact interactive user edit realize fidelity visual dub demonstrate quality output conduct extensive series evaluation instance user video edits detect CCS concept compute methodology computer graphic neural network appearance texture representation animation render additional facial reenactment video portrait dub conditional gan render video translation introduction synthesize edit video portrait video frame upper important computer graphic application video edit movie  visual visual dub virtual reality telepresence others address acm trans graph vol article publication date august kim    nießner pérez    synthesize photo realistic video portrait target actor mimic action source actor source target specifically approach enables source actor rigid expression target actor identity modify extent dimension manipulate independently target frame entire realistic upper scene background comply modify automatically synthesize recently propose interior reenactment expression modify realistically 3D consistent upper consistently background parametric 3D model rgb video render modify model blend overlay target video reenactment synthesize portrait video 3D challenge  enable mild driven source actor image warp generate reactive dynamic profile static target portrait photo fully reenact video artifact target gaze cannot identity target fully preserve appearance source actor performance driven 3D animation related orthogonal methodology application goal typically stylize 3D CG avatar visual source actor input stylize VR environment recently propose image 3D avatar dynamic texture tracker however goal 3D animate render intentionally stylize photo realistic fashion approach directly generates entire photorealistic video portrait static background target facial expression formulate video portrait synthesis reenactment render video translation task input algorithm synthetic rendering coarse fully controllable 3D interior model target actor separately render gaze image robustly efficiently obtain via model reconstruction technique input automatically translate frame photo realistic video output entire upper background cannot actively torso background render video translation network implicitly synthesize plausible background shadow reflection translation tackle novel encoder decoder neural network adversarial manner core approach conditional generative adversarial network cGAN specifically tailor video portrait synthesis temporal stability novel network architecture input sequence conditioning input frame gaze slide manner synthesize target video frame target scene specific network portrait video footage training knowledge approach synthesize photo realistic video portrait target upper realistic clothing consistent scene background 3D target summarize technical contribution render video translation network transforms coarse model rendering photo realistic portrait video output novel encode conditional input temporally coherent video synthesis geometry reflectance gaze blink comprehensive evaluation application demonstrate flexibility effectiveness approach demonstrate potential quality intrigue application reenactment visual dub foreign movie user interactive edit portrait video movie  comprehensive comparison user confirm fidelity related discus related optimization aim reconstruct animate image video review relevant image image translation comprehensive overview refer recent report monocular 3D reconstruction application monocular reconstruction reconstruction aim reconstruct 3D model appearance visual data optimization 3D template model mainly inner image unstructured image collection video recently propose largescale parametric model construct almost 3D scan approach leverage corpus image image patch regressor predict 3D appearance detail neural network robust infer coarse 3D facial appearance inner synthetic data encoder decoder architecture fully unsupervised image integrate physical acm trans graph vol article publication date august video portrait video portrait enable source actor fully target video portrait dimensional parametric representation video obtain monocular reconstruction expression gaze transfer parameter focus modification identity scene illumination hatch background interested reenactment finally render conditioning input image convert photo realistic video portrait target actor obama video courtesy public domain image formation network regressor recover facial geometry coarse encoder decoder network infer detailed depth image dense correspondence basis non rigidly deform template mesh none creates fully generative model entire interior gaze video facial reenactment facial reenactment rewrite content target actor video image transfer facial expression source actor facial expression commonly transfer via dense parameter warp candidate frame facial appearance metric described reconstruct source target sparse 2D landmark dense 3D model approach modify inner mainly intend alter facial expression video portrait rigid facial expression gaze recently propose approach gaze redirection parametric model approach notable exception pure facial reenactment  approach enables reenactment portrait image allows slight via image warp approach target image interior source target preserve target identity partially advantage target video facial reenactment joint gaze visual dub visual dub instance reenactment aim alter target actor audio commonly spoken foreign dub actor driven performance driven technique driven dub technique specific phoneme viseme mapping training sequence actor accurate lip sync visually imperceptible artifact recently demonstrate however cannot directly target facial expression performance driven technique overcome limitation transfer semantically meaningful parameter render target model photorealistic reflectance detail approach generalize edit struggle synthesize photo realistic deformation contrast approach learns synthesize photo realistic facial action coarse rendering enable synthesis expression joint modification consistent background image image translation approach conditional gans pixpix impressive image image translation task convert image domain satellite photo combine encoder decoder architecture skip connection adversarial loss function chen  demonstrate resolution megapixel resolution cascade refinement network without adversarial training trend  gans conditional gans resolution however challenge requirement training data correspond image available tackle CycleGAN  multiple concurrent unsupervised image image translation technique unpaired training sample technique capture imagination translate photograph painting acm trans graph vol article publication date august kim    nießner pérez    zebra photo depth correspondence translation photo cartoon drawing photo realistic gaze manipulation image synthesize realistic inner texture cannot generate fully controllable output video specific propose generative model synthesize clothing generate image arbitrary image image translation contrast approach enables synthesis temporally coherent video portrait animation source actor facial expression gaze overview video portrait approach target actor transfer rigid facial expression source actor preserve target identity appearance target video frame synthesize consistent upper posture background source target actor monocular reconstruction approach parametric illumination model sequence  parameter vector actor identity expression gaze scene video frame allows transfer expression gaze parameter source target desire generate synthetic rendering target actor modify parameter addition normal render render correspondence gaze image rendering conditioning input novel render video translation network convert synthetic input photo realistic output temporally coherent network volume conditioning input video input conditioning volume slide fashion assemble video output frame evaluate approach potential video rewrite application reenactment gaze redirection video dub interactive parameter video monocular reconstruction employ dense reconstruction approach parametric model illumination video frame obtains meaningful parametric representation source target video sequence denote source target frame respectively correspond parameter sequence fully describes source target facial performance reconstruct parameter encode rigid rotation translation facial identity coefficient geometry reflectance expression coefficient gaze direction spherical harmonic illumination coefficient overall monocular tracker reconstructs parameter per video frame detail algorithm parametric representation parametric representation facial identity parametric model facial expression via affine model mathematically model geometry variation affine model stack per vertex deformation underlie template mesh vertex  geo exp diffuse reflectance model similarly affine model stack diffuse per vertex albedo  ref vector   average facial geometry correspond reflectance respectively geometry basis geo compute apply principal component analysis pca quality scan reflectance basis ref obtain manner dimensionality reduction expression basis exp compute pca blendshapes blendshapes transfer topology blanz vetter deformation transfer image formation model render synthetic image assume perspective camera model 3D via camera 2D image perspective mapping contains multiplication camera intrinsics perspective assume fix identical camera scene camera model account scene illumination assumption spherical harmonic SH basis function approximate incoming radiance environment spherical harmonic SH coefficient reflectance normal vector vertex respectively diffuse average approximation error percent achieve independent illumination incident radiance smooth function parameter per channel dense reconstruction employ dense data parallel reconstruction approach efficiently compute parameter source target video reconstruction analysis synthesis approach maximizes photo consistency synthetic render model input acm trans graph vol article publication date august video portrait reconstruction combine dense photo consistency landmark alignment statistical regularization    enables robust reconstruction identity geometry reflectance facial expression scene illumination automatically detect facial landmark vision tracker commercial implementation define sparse alignment  robust norm dense photometric alignment  regularizer  enforces statistically plausible parameter assumption normally distribute data gaze estimate directly obtain landmark tracker identity estimate frame constant afterwards parameter estimate frame detail formulation refer data parallel implementation iteratively IRLS optimal parameter difference compute explicitly jacobian residual vector global memory data parallel strategy launch thread per matrix vector afterwards  matrix matrix matrix vector multiplication computes normal equation IRLS linear mode dof rigid expression parameter SH coefficient cpu cholesky factorization IRLS reconstruction frame parameter without identity mode allows efficient generation training corpus render video translation network contrary model feature dimension model eyelid closure eyelid capture synthetic conditioning input reconstruct frame source unmodified target video obtain modify parameter vector frame target sequence reenactment modify rigid expression gaze target actor parameter relative manner source target respect neutral reference frame render synthetic conditioning image target actor model modify parameter hardware rasterization temporal coherence render video translation network volume conditioning image input index frame temporal frame network earlier frame generate conditioning input render correspondence image gaze image render http  net diffuse render correspondence gaze synthetic input conditioning render video translation network render target illumination correspondence image gaze image modify target actor model estimate target illumination target identity geometry reflectance fix image render video translation delta image addition input correspondence image encode index parametric model vertex project pixel texture model constant unique gradient texture render finally gaze image solely contains location pupil image information gaze direction blinking network stack conditioning input 3D tensor image channel obtain input render video translation network video conditioning volume slide fashion generate photorealistic video output assemble directly output frame rendering video translation generate conditioning video tensor input render video translation network network learns convert synthetic input frame photo realistic target video target actor mimic facial expression gaze synthetic input network learns synthesize entire actor foreground conditioning input exists actor comply target synthesizes appropriately modify background consistent foreground background network specific target actor specific static otherwise scene background render video translation network encoder decoder architecture adversarial manner discriminator jointly explain network architecture loss function training procedure detail network architecture architecture  video translation network conditional generative adversarial network consists transformation network discriminator transformation network tensor input output  image target actor temporal input enables network account inspect previous conditioning image temporal axis input tensor align along network channel convolution acm trans graph vol article publication date august kim    nießner pérez    bilinear downsampling channel tanh BN  deconv BN relu refine refine conv BN relu conv refine prob prob stride stride stride architecture render video translation network input resolution encoder downsampling module output channel decoder upsampling module output channel upsampling module dropout probability downsampling upsampling module employ batch normalization BN non linearity tanh brings output employ normalize layer channel image data normalize mapped mapped network consists encoder compute dimensional latent representation decoder synthesize output image employ skip connection enable network transfer structure generate video frame sufficient resolution network employ cascade refinement strategy downsampling convolution stride batch normalization leaky relu non linearity upsampling module specifically quality output structure resolution increase factor deconvolution upsampling factor batch normalization dropout relu afterwards refinement convolution stride resolution relu apply hyperbolic tangent non linearity tanh brings output tensor normalize image data detail refer input discriminator conditioning input tensor predict output image truth image employ discriminator inspire  classifier propose extend volume conditioning image input objective function adversarial manner render video translation network argmin max   objective function comprises adversarial loss  norm reproduction loss constant balance contribution adversarial loss egan EX EX inject vector training network deterministic output adversarial training discriminator classify image synthetic transformation network improve fooling discriminator norm loss penalizes distance synthesize image truth image encourages sharpness synthesize output EX training construct training corpus tracked video frame target video sequence typically video frame video footage sufficient network training corpus consists render conditioning volume correspond truth image network tensorflow framework gradient propagation obtain adam iteration batch approx epoch training corpus frame rate momentum parameter default network scratch initialize normal distribution RESULTS approach enables frame target video portrait synthesis 3D runtime training intel xeon ghz GB ram nvidia geforce gtx titan GB ram training network target video resolution pixel pixel source actor per frame without identity render video conversion inference per frame pixel pixel evaluate choice video portrait algorithm reenactment approach web user demonstrate potential approach video rewrite application reenactment facial expression facial expression reenactment video dub video portrait edit user apply approach target sequence source sequence appendix detail comparison retrieval approach supplemental video approach target video footage training application approach enables rigid facial expression target actor video portrait opening video rewrite application parameter dimension estimate transfer source video sequence edit manually interactive user interface acm trans graph vol article publication date august