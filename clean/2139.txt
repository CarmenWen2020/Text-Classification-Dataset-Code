persistence diagram widely quantify underlie feature filter topological data visualization application compute distance diagram essential however compute distance challenge due computational propose persistence diagram hash framework learns binary code representation persistence diagram allows computation distance framework built upon generative adversarial network gan diagram distance loss function steer instead standard representation hash diagram binary code advantage task training model domain oblivious compute purely synthetic randomly diagram consequence propose directly applicable various datasets without retrain model binary code ham distance maintain topological similarity datasets vectorized representation evaluate apply framework diagram cluster quality performance approach addition scalability approach dataset persistence diagram technique moreover experimental demonstrate significantly faster potential memory usage retain comparable quality comparison introduction feature quantify topological data analysis tda express fundamental structure scalar generally applicable domain tda approach persistent homology contour reeb graph morse  complex demonstrate ability extract meaningful structure variety research application 3D combustion physic nuclear physic fluid dynamic chemistry alzheimer disease autism spectrum disorder cancer histology protein fold bio molecular analysis generally recent tda quantification input machine dataset histology image  cancer persistence diagram encodes topological structure image inset illustrates elbow plot cluster subset image wasserstein distance approximately topologically distinct cluster cluster wasserstein distance subset quality concise representation memory computation approach dataset feasible wasserstein described detail persistence diagram topological structure dataset distance diagram topological dis similarity data important application scientific visualization moreover approach cluster topological similarly compute distance diagram fundamental operation however compute distance costly widely accepted persistence diagram distance wasserstein distance expensive persistence diagram combat complexity approach attempt reduce goal significant advance detail representation express topological structure concise previous directly faster computation distance reduce diagram binary code representation hash function hash purely random synthetically generate diagram constraint generate training data generate diagram approximately average persistence data training domain oblivious model potentially variety datasets without retrain representation distance calculate wise comparison binary code ham distance distance computation extremely scalable illustrate cluster dataset diagram achievable exist approach contribution specific contribution concise binary code representation persistence diagram maintains topological dis similarity ham procedure binary code hash function purely synthetic data therefore domain oblivious application topological cluster datasets significant comparison speedup potentially memory footprint comparable quality cluster vectorized representation persistence diagram background related outline technical background persistent homology hash relevant developed persistent homology persistence diagram dataset topological sequence nest topological filtration employ homology persistent homology respectively qualitatively quantitatively homology concept algebraic topology capture fundamental structure topological structure qualitatively described homology generator feature feature dimension associate dimension zero feature component dimension feature loop tunnel dimension feature correspond void etc persistent homology quantifies homology entire filtration feature birth parameter filtration feature difference lifetime persistence feature feature persistence feature respect filtration parameter persistence restrict diagonal define persistence diagram multi birth abstract concept illustrate filtration scalar filtration evolution sublevel sublevel filtration progression  transformation source local minimum basin zero dimensional feature component  local minimum dimensional feature  completely surround local maximum peak lifetime feature scalar height feature birth merges feature birth critical unstructured data discrete pairwise distance define filtration built evolution  rip complex simplices complex increase neighborhood around filtration component detect distinct cluster evolution dimensional feature detect presence circular feature data feature agnostic domain data dimension feature fundamental structure data illustrates zero dimensional feature sublevel filtration scalar basin sublevel increase purple feature deepest basin feature filtration feature eventually merges purple component feature diagram plot birth purple feature diagram progression sub scalar feature minimum merges feature purple birth zero dimensional persistence diagram distance diagonal lifetime persistence feature wasserstein bottleneck distance denote collection diagram wasserstein distance define minm SourceRight click MathML additional feature matchings persistence diagram persistence wasserstein distance optimizes diagram sum distance diagonal distance unmatched bottleneck distance interleave distance wasserstein distance popular choice application therefore target refer wasserstein distance without specify refer diagram lipschitz stable presence slight perturbation data stability diagram distance topologically computationally however wasserstein bottleneck distance expensive compute optimal persistence diagram compute wasserstein distance diagram nlogn simplices exponential input data approximate distance distance diagram compute roughly quadratic computation daunt approach introduce approximate compute wasserstein distance approach successful simplify input representation persistence diagram compute however assumption underlie domain 2D 3D image introduce approximate wasserstein distance algorithm accelerate computation iterative computation bound quality approx  wasserstein distance distance progressive wasserstein PW distance algorithm extend compute barycenter persistence diagram although approach pairwise illustrate memory requirement significant data circumstance diagram bound exists persistence inside input parameter grid grid define histogram persistence grid histogram data structure bottleneck distance computes wasserstein distance optimal transport histogram benefit optimal transport computation approach significant distance computation wasserstein distance histogram histogram wasserstein HW distance training architecture PD gan model persistence diagram input learns correspond binary code arrow depict diagram training grey arrow information loss function etc generative adversarial network gan encoder binary code similarity matrix code SB closely similarity input diagram SP hash function diagram binary code highlight topological descriptor previous approach histogram representation distribution persistence research density estimator built persistence researcher benefit density estimator vectorized vectorized representation discretization weigh speedup gain compute distance vector instead distance persistence diagram persistence image PI persistence image PI discretization kernel density estimator non parametric density estimator built rotate persistence diagram roughly image estimate density sum gaussian kernel PI bound discretization resolution function persistence diagram parameter non trivial various heuristic successfully employ betti curve BC topological invariant euler characteristic betti integer kth betti curve BC rank dimension homology respect filtration parameter roughly topological feature filtration parameter increase feature associate persistence contributes betti curve interval hence persistent feature contributes betti curve distance betti curve compute explicitly approximate sample discretizing domain latter approach prefer hence betti curve dimension bound discretization resolution hash ability binary code significantly boost distance computation hash attract increase attention approximate focus unsupervised machine hash function dimensional data dimensional ham unsupervised building hash function roughly non hash hash typical non hash pca hash spectral hash iterative quantization attempt preserve pairwise similarity data binary code spectral hash eigenfunctions data similarity graph hash recently hash introduce due advance non linear structure convolutional neural network cnn extract multiple hierarchical feature representation input data nonlinear relationship binary representation however data label cnns unsupervised approach hash function cannot advantage model inspire introduction generative adversarial network gan focus unsupervised hash function gan without label data overall previous hash approach mainly focus image retrieval task hilbert nice statistical image hash approach hash persistence diagram non hilbert approach transform topological feature binary representation topological binary code explore concise binary code persistence diagram input persistence diagram neural network hash persistence diagram binary code binary code ham distance lieu persistence diagram wasserstein distance illustration architecture approach vectorizing input hash function input diagram convert vectorized appropriate input network mention choice vectorized representation input persistence diagram 2D histogram wasserstein distance HW persistence image distance PI betti curve distance BC parameter outline respective  cluster relative cluster persistence diagram wasserstein distance  mallow FMS evaluation interval perfect illustrates HW accurate cluster therefore 2D histogram vectorization training hash transform diagram histogram 2D uniform grid entropic  recommend parameter grid persistence diagram inside additional contains persistence addition augment representation reflect across diagonal empty augmentation improves quality cluster standard histogram improvement 3D dataset summary training hash function convert diagram 2D histogram denotes histogram initial 2D histogram representation training intermediate hash comparison vectorized representation  mallow closer similarity matrix training model similarity matrix SP spij pairwise similarity histogram explore define similarity approach invert topological distance choice invert wasserstein distance distance mimic ham distance binary code illustrate compute distance potentially training datasets prohibitively expensive therefore adopt HW distance computationally feasible matrix aligns choice intermediate vectorization specifically compute similarity matrix spij flexibility algorithm explore rigid binary similarity matrix matrix spij spij dissimilar define similarity thresholding closest diagram sufficient tendency persistence diagram training diagram others diagram treat dissimilar diagram opt rejection approach diagram distance distance reject dissimilar per diagram basis approach allows binary label threshold maintains distance discount distance rigid approach flexible binary matrix approach outperforms distance PD gan model generate binary code hash function diagram hash maintain topological similarity binary code ham distance framework image hash approach approach context hash function PD gan model encoder gan encoder encoder extract feature input diagram pretrained vgg network convolution layer max pool filter output fully layer training encoder driven minimize similarity loss function training binary code fully layer encoder sgn layer layer binary code layer however non smooth binary representation problematic gradient computation training avoid intermediary representation binary code training   sourcewhere binary code training binary code extract binary code layer described gan generator discriminator improve accuracy hash function gan specifically generator inverse encoder output encoder input network deconvolutional layer creates synthetic histogram training code generator goal cannot distinguish discriminator minimize diagram loss adversarial loss function define discriminator informs generator improve generator informs encoder improve hash function loss function loss function define component minimize similarity loss diagram loss adversarial loss similarity loss similarity matrix SP spij training code similarity loss capture connection binary representation topological distance SB   similarity loss define  SB SP sourcewhere euclidean norm diagram loss intuitively diagram loss generate histogram correspond input histogram diagram loss function combination pixel wise error mse perceptual loss perceptual loss layer discriminator perceptual loss account observation pixel wise mse optimization lack frequency content verify experimentally dataset perceptual loss accurate loss sum diagram loss    adversarial loss adversarial loss improve reconstruction quality generator define ladv combine loss finally combine loss training sum loss    3D representative topological cluster persistence diagram MDS plot wasserstein distance ham distance generate binary code FMS cluster performance cluster PD gan loss function minimize training code encoder parameter vgg encoder binary code layer generator reconstructs diagram parameter vector discriminator parameter vector propagation stochastic gradient descent locally optimal parameter loss function specifically parameter update iteration default rate      ladv ladv SourceRight click MathML additional feature hash function distance computation training diagram hash convert 2D histogram representation PD gan encoder integer consequence binary encode representation concise distance code compute ham distance computation wise operation population xor popcount binary code distance computation hardware CPUs computation standard python implementation implementation leverage hardware experimental illustrate effectiveness approach generate binary representation cluster application datasets refer dataset information evaluate quality distance approximation approach apply distance linkage hierarchical cluster algorithm scikit python library distance matrix input contains pairwise distance histogram objective linkage hierarchical cluster nest sequence partition successively merge cluster fashion cluster datasets undefined topological cluster elbow cluster deploy hierarchical cluster sequential potential plot within cluster sum distance versus compactness cluster cluster chosen elbow curve evaluate cluster wasserstein distance datasets described evaluation detailed training domain oblivious finally performance quality report datasets evaluate cluster datasets 3D ensemble simulation data 2D medical image 3D dataset contains 3D camel elephant persistence diagram implementation   rip filtration previous distinct topological cluster dataset average persistence per diagram persistence diagram 3D dataset contains 3D across category diagram previous dataset average persistence per diagram elbow cluster exist vortex ensemble dataset 2D simulation turbulence obstacle cluster viscosity average persistence diagram via sublevel filtration  representative persistence diagram vortex ensemble dataset 2D simulation formation vortex topological cluster average persistence persistence diagram diagram similarly previous ensemble  cancer image   stain  image average persistence conduct dataset subset approach cannot data subset contains image per persistence diagram average persistence diagram obtain via sublevel filtration  tda library elbow distinct topological cluster evaluation cluster input persistence diagram approach computes binary representation evaluate binary representation representation persistence image betti curve cluster performance cluster wasserstein distance standard distance diagram treat distance truth cluster obtain perform hierarchical cluster wasserstein cluster obtain perform hierarchical cluster vectorized representation persistence diagram associate distance ham distance betti curve euclidean distance approach outline compute distance matrix datasets diagram average persistence avg wasserstein  2D histogram progressive wasserstein persistence image betti curve approach speedup approach comparison cluster training  mallow model indicates synthetically random persistence diagram persistence training persistence persistence clustering  mallow FMS quantify similarity cluster define geometric precision recall FMS TP TP FP TP FN sourcewhere TP positive persistence diagram belong cluster FP false positive cluster cluster FN false negative cluster cluster FMS perfect minimum addition multidimensional MDS plot visualize cluster wasserstein approach domain specific domain oblivious training approach training obvious domain specific data evaluate hash function sufficiently preserve evaluate approach 3D dataset splitting diagram training respectively cluster model FMS truth cluster wasserstein domain data viable strategy approach limit training domain specific data hinder applicability machine approach availability data critical model datasets ensemble simulation data model guaranteed therefore evaluate approach ideally training domain oblivious thereby remove plentiful domain data evaluate possibility model purely synthetic data persistence diagram specialized 2D scatter plot therefore synthetic diagram random scatter plot uniform persistence distribution reject diagonal training naive synthetic data surprising model diagram randomly distribute persistence cluster 3D synthetic data FMS within cluster domain specific model requirement approach synthetic diagram training average persistence data cluster obvious automatically naive random diagram sufficiently sample potential diagram experimental finding discus adopt domain oblivious approach primary training model evaluation model model model diagram persistence per diagram respectively illustrates requirement described persistence training diagram average cluster data quality 3D vortex model 3D vortex model finally  cancer dataset subset model domain applicability model intel core 0GHz core cpu nvidia geforce gtx gpu training model 2GB ram implement python tensorflow platform implementation training architecture lightweight program hardware accelerate ham distance computation code data available osf repository memory usage approach popular vectorized persistence representation persistence image PI betti curve BC  addition evaluate approach approximation wasserstein distance 2D histogram optimal transport HW progressive wasserstein PW implementation truth wasserstein distance scikit tda implementation   parameter PI bandwidth standard function persistence entropic HW  grid resolution bound min max coordinate diagram resolution experimental evaluation 3D minimal improvement FMS approximately therefore chosen minimum representation quality PI bandwidth experimentally 3D dataset mesh dataset diagram dataset amount topologically distinct cluster elbow cluster exist respect wasserstein distance illustrate MDS plot wasserstein distance ham distance generate binary code respectively FMS indicates almost perfectly cluster detail comparison runtimes compute distance matrix dataset input linkage cluster therefore technique differs separately generate representation compute persistence image compute binary code representation etc compute pairwise distance  PW generation generation HW nominal costly distance computation therefore runtimes runtimes PW marked asterisk comparison implementation python compute distance cluster therefore distance calculation cannot parallelism generation  distance compute serially chosen highlight simplify runtime comparison distance computation embarrassingly parallel approach parallelizable comparison runtimes  HW illustrates approach prohibitively feasible dataset diagram comparison python distance calculation HW gpu acceleration HW roughly cluster gpu acceleration persistence diagram persistence evaluate PW approach progressive approach comparison completion illustrates approach extremely datasets although author implementation approach quickly memory limit GB therefore datasets  cancer 3D 3D PW image subset colon cancer dataset vortex dataset contains cluster representative data cluster diagram MDS plot dataset wasserstein distance ham distance binary code vectorized approach significant performance improvement datasets speedup alternative approach distance computation incredibly bottleneck approach generation binary code datasets distance computation dominate runtimes comparable vectorized approach illustration implement distance calculation approach leverage population xor exists CPUs datasets runtimes magnitude faster python implementation distance computation millisecond overall scalability propose binary code task database vortex ensemble contains cluster persistence diagram FMS achieves perfect cluster cluster wasserstein timing comparison implementation leverage hardware acceleration compute ham distance memory storage describes potential memory storage gain representation 2D persistence diagram PD precision grid PI BC precision requirement approach reduction rate representation illustrates integer significant benefit storage memory encoder approach encoder standard pretrained vgg model approximately MB however compress instance vgg reduce parameter model squeezenet reduce MB overall approach domain oblivious model potentially multitude datasets domain encoder amortize data increase therefore approach potential greatly reduce storage overhead tda grows comparison persistence summary vectorized summary persistence diagram PI BC vector quality evaluation cluster quality cluster evaluation described quality FMS clustering obtain persistence diagram representation cluster wasserstein distance directly persistence diagram comparison diagram subset  cancer dataset dataset  fail PW approach approach FMS similarity matrix binary similarity illustrates approach comparable quality progressive wasserstein PW persistence image PI betti curve BC limit PW runtime approach report PW converge wasserstein distance therefore comparison quality amount binary code par approach approach almost achieves perfect reproduction cluster  cancer 3D datasets moreover perfectly cluster vortex domain oblivious training approach therefore model apply data comparison cluster  mallow described indicates identical cluster clustering persistence diagram representation distance wasserstein cluster input persistence diagram comparison cluster  mallow comparison cluster  mallow evaluate quality distance preservation binary code scatterplots wasserstein ham distance coordinate avoid overdraw drawn gaussian kernel density estimator plot diagram horizontal distance vertical ham distance distance maintain plot linear diagonal illustrates binary code separation dimension dot meaning cluster maintain distance finally illustrates plot vortex FMS highlight arrow cluster distance maintain likely although quality PI BC evaluate quality FMS relation binary code cluster 3D 3D vortex vortex increase increase quality although noticeable  gain therefore opt code quality simpler implementation plot illustrate distance preservation binary code various datasets scatterplot diagram horizontal distance vertical ham drawn kernel density estimator exhibit linear diagonal meaning distance preserve plot directly separation cluster horizontally vertically highlight linear likely illustrates FMS comparison cluster 3D dataset similarity matrix strategy denotes similarity matrix denotes binary similarity matrix built distance matrix fix training similarly threshold similarity matrix strategy limit similarity global threshold percent finally pas rejection illustrates pas approach accurate cluster therefore comparison cluster similarity matrix computation  mallow comparison cluster similarity matrix computation  mallow conclusion approach concise binary code persistence diagram maintain topological similarity approach training machine model learns hash domain specific data randomly generate 2D scatter plot technique domain oblivious model apply across multiple domain data without retrain hash approach technique likely maintain distance application distance discount approach hash approach distance maintain data synthetically model roughly average persistence dataset overly strict requirement instance  cancer dataset persistence average model regard storage binary code encoder network MB mention model apply datasets across domain argue amortize nominal although explore reduce overhead future finally illustrate benefit representation topological cluster binary code quality moreover scalability approach highlight potential storage requirement binary code along extremely distance computation chip acceleration