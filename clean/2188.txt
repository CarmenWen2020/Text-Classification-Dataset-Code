recent counting mainly leverage convolutional neural network cnns regress density achieve progress density gaussian blob obtain integration however accurately predict density dense issue density dense usually accumulates density nearby gaussian blob yield density pixel density variant significant shift brings distribution pixel wise density aim address issue density specifically propose effective LS module automatically dense reasonable closeness reflect image distance LS directly normalizes closeness patch dynamically overlap blob decomposes accumulate truth density alleviates shift distribution density model density explore effectiveness LS localize local minimum quantize distance location issue density regression knowledge localization novel localization counting introduce customize dynamic entropy loss significantly improve localization model optimization extensive demonstrate propose framework autoscale improves upon regression localization benchmark datasets achieves competitive performance sparse datasets implementation available http github com liang autoscale git introduction counting recently attract owe importance application video monitor public security management although facto cnn significant progress traditional accurately dense whereas scene gathering stadium aim estimate accurate quality density gaussian blob integrate obtain however exist multiple gaussian blob overlap dense density pixel accumulate nearby gaussian blob meanwhile accumulate density usually crucial accurately predict instance gaussian blob sparse overlap dense statistically distribution density sparse dense hinders model accurate density prediction density density dense usually accumulate multiple nearby gaussian blob density dense density imbalance pixel dense usually density occupy density density imbalance however dense crucial accurate counting density distribution gap exists density distribution gap sparse dense besides density distribution dense image variant accumulation shift intuitive statistical distribution density intuitively gaussian blob distribute separately sparse within variant overlap exist dense within dense via closeness normalization alleviates shift dense sparse statistically dense distribution density propose autoscale alleviates issue reduces density distribution gap dense sparse facilitate density regression dense rescale GT obtain predict factor axis logarithmic online image shift distribution challenge accurate prediction dense knowledge mitigate issue density counting propose effective LS module automatically reasonable factor rescale dense appropriate closeness reflect image distance overlap blob decompose accumulate density density therefore normalize closeness alleviates issue shift distribution normalization hence facilitates regression density noteworthy mention truth factor dense zoom ideally propose LS performs unsupervised cluster via loss propose LS illustrate LS density distribution shift mitigate localization currently attract attention recently instead detect propose regard local minimum quantize distance location localization specifically quantize distance distance label distance category distance local minimum distance label correspond localization knowledge leverage local minimum distance label localization counting density representation exist imbalance distribution variance motivates employ LS distance label blob mitigate distribution variance improve localization accuracy besides customize dynamic entropy dce loss distance label specifically widely static entropy loss generate multiplication prediction possibility absolute difference predict truth dynamically accord prediction leverage fpn baseline model frame regression localization propose LS module autoscale precisely baseline model initial prediction sparse automatically dense refinement propose LS module generates appropriate factor rescale dense fpn model perform rescale dense replaces initial adopt pipeline localization simply output density distance label extensive demonstrate autoscale outperforms ucf QNRF JHU NWPU datasets regression localization achieves competitive performance shanghaitech shanghaitech dataset extract dense accurate counting challenge propose LS achieves significant improvement besides apply LS popular counting consistently improves correspond performance moreover conduct  dataset superiority distance label customize dynamic entropy loss localization contribution fold explore distribution pixel wise density counting propose LS module mitigate issue knowledge localize local minimum distance label localization counting propose novel customize dynamic entropy loss advantage geometrical meaning distance label mitigates imbalance significantly improves baseline performance localization propose regression autoscale resp localization autoscale baseline consistently outperforms regression resp localization public dense datasets achieves competitive performance sparse datasets besides propose LS helpful improve performance popular extends preliminary aspect reformulate intuition distribution reveals mechanism LS improve counting accuracy knowledge LS attempt explicitly explores pixel distribution issue density regression localization counting addition density regression adapt propose LS localization counting specifically  leverage distance label localize local minimum customize dynamic entropy dce loss sufficient conduct demonstrate propose LS effective localization improve conference version via reasonable adaptive dense selection instead regular patch evenly image domain distance density measurement average distance nearby intuitive efficient indication dense conduct comparison challenge datasets demonstrate effectiveness propose LS dce loss deeply analyze effectiveness LS dense combination baseline related shortly review related counting sect vision task involve operation sect distribution sect counting mainstream counting consist localization regression shortly review representative regression regression exist mainstream counting thanks widely density era previous resort regression strategy linear regression gaussian regression ridge regression regression leverage cnns regress density approximate distribution density regression achieve significant progress exist challenge variation perspective distortion noisy background interference multi feature fusion effective improve ability cop  relies network architecture NAS automatically adopt multi architecture address variation issue counting aim image attend accord fix factor strategy conquer apply counting sam babu adopt classifier predict model separately attempt sparse detection regress density dense  transforms spatial feature attention mechanism another trend cope spatial relation counting attention non local module customize attention auxiliary task widely combine improve density estimation foreground background segmentation depth prediction velocity estimation uncertainty estimation target correction foreground mask trimap thresholding distance usually filter noisy prediction background estimation bias relatively remove prediction become accurate depth estimation information beneficial density estimation leverage multi task rank strategy baseline effectively facilitate estimation density     extract perspective knowledge cnns adapt diverse  learns extra mask multiplication rate automatically adjust density estimation correspond sub  leverage hybrid graph neural network localization auxiliary task enhance density prediction counting besides model mechanism objective function important direction bayesian loss propose regard density probability compute probability pixel propose maximum excess pixel MEP loss pixel difference truth optimization  utilizes dilate multiscale structural similarity DM loss locally consistent density localization traditional counting detect directly detect pedestrian nevertheless annotation detection laborious extreme dense compromise annotation location annotation individual hinders powerful detection pipeline besides detection usually suffer severe occlusion highly congest despite difficulty detection localization witness progress proposes  split loss distance nearby propose loss hausdorff distance  formulate localization minimization distance zoom fix rate dense effective localization tackle shortage annotation propose impressive detect bound supervision annotation attempt localize local maximum predict density gaussian kernel explore density aspect distribution density propose novel LS module effectively alleviate density distribution dense regress density demonstrate effectiveness propose localize dense regard local minimum distance label localization vision task important role vision task detection grain classification singh davis propose normalization image pyramid relative instead processing entire image pyramid  context around truth instance appropriate attempt efficient algorithm automatically focus usually detect finer grain classification zoom attend effective recognize specific propose attention important feature specific grain zoom attempt salient zoom grain classification noteworthy mention STN parameter affine transformation without specific supervision exist kang chan singh davis involve operation mainly implicitly attend important rescale fix fix zoom rate detection recognition propose autoscale differs exist purpose motivation computation factor typically aim image accord fix factor accurate attention autoscale aim explicitly dense rescale closeness alleviate issue dense diagram propose autoscale module counting module dedicate initial prediction image prediction rescale dense regression localization counting LS module generates appropriate factor rescale dense refining dense compose initial sparse   initial prediction dense predict dense  image distribution vision task distribution extremely data extensively classical garcia mitigate distribution sample sample minor data recent mainly focus improve objective function training strategy model improvement mainly exist  vision application recognition detection segmentation exist severe distribution issue rarely explore counting aspect density related propose  aim tackle counting spatial maintain although  explores issue counting autoscale explore pixel distribution density overlap gaussian blob highly congest density whereas  address distribution image patch besides spatial hardly cope distribution accumulation pixel propose LS overlap blob decompose accumulate dynamical craft operation furthermore propose beneficial improve localization accuracy distance label counting overview distribution density challenge counting focus mitigate specifically accumulate density dense imbalance distribution gap dense sparse nevertheless density dense crucial prediction consequently propose LS module unsupervised cluster leverage loss rescale dense reasonable closeness mitigates transforms distribution sparse reduces distribution gap dense framework fpn baseline network LS demonstrate effectiveness propose apply LS module baseline model regress density demonstrates effectiveness propose LS simply output distance label counting localization demonstrates effectiveness LS localization besides propose novel dynamic entropy loss distance label distance label representation boost localization accuracy regression autoscale localization autoscale network independent counting regression counting localization respectively regression localization autoscale LS trainable overall framework depict pipeline consists counting network widely backbone fpn estimation density distance label LS dedicate generate appropriate factor dense detail propose density gaussian kernel correspond distribution density image analysis density representation counting rely density regression however aim explore distribution pixel density generally recent counting datasets annotation binary pixel image domain model delta function refers image density pixel generate convolve gaussian kernel meanwhile kernel hyper parameter counting kernel prone overlap therefore pixel accumulation kernel severe imbalance although adaptive gaussian kernel propose reduce overlap gaussian blob kernel accord neighborhood distance distance variant distribution gaussian kernel others distribution multiple pixel accumulation overlap gaussian blob gaussian kernel exist severe pixel imbalance cnns kernel generator wan chan promising cope dilemma kernel selection however explicit distribution density knowledge explore density aspect pixel distribution propose LS dynamically distribution density dense model density training inference phase aim modulate dense appropriate closeness tackle distribution density precisely define closeness via truth   denotes distance  overall conference version relies average define density leverage average distance actually dense resp sparse intrinsically contains resp away therefore closeness dense sparse naturally average distance within importantly patch wise pixel wise average distance influence without closeness define reliable intuitive dataset consist  rescale target  closeness rescale approach generate appropriate factor however explicit target factor zoom target closeness approach therefore propose module unsupervised cluster loss closeness specifically  rescale attempt generate correspond factor apply cnn consist convolutional layer fully layer backbone feature rescale via bilinear upsampling LS module training objective loss closeness refers dense iteration parameter update refers closeness limit factor avoid degenerate potential image distortion factor meanwhile zoom participate training loss sample noteworthy mention leverage STN achieve operation specifically factor affine matrix STN rescale factor pipeline differentiable gradient propagate derivative respect closeness learnable manually randomly initialize standard update   rate update LS effective module improve performance regression localization counting dense detail propose regression localization autoscale LS counting regression counting regression model frame autoscale manner density regression precisely previous adopt vgg fpn backbone network discard pool layer fully layer pool layer stage stage preserve sufficient spatial information accurate counting fpn backbone counting generates initial density estimation relatively accurate sparse dense usually accurately regress density propose apply LS module dense rescale dense closeness accumulate pixel decompose distribution transform threshold predict density twice density image yield density twice maximum dense image estimate density dense backbone feature pool cropped feature fed LS module LS module generates factor rescale dense estimate density apply counting network parameter initial prediction rescale predict density predict density specifically sum  sparse image domain exclude dense  refine rescale dense image  minus dense  regression model sum obtain integrate estimate density maximal proportion input image dense imply underlie image mainly contains sparse initial density prediction accurate training objective regression model training phase regression counting model previous density regression counting network specifically adopt error mse loss function optimize counting network truth predict density respectively noteworthy mention adopt online truth update density prediction dense precisely rescale binary annotation dense annotate dot coordinate factor regenerate correspond truth density rescale binary gaussian kernel initial truth density image training objective  optimize density regression model      mse loss initial prediction prediction dense loss involve optimize LS module hyper parameter truth distance label generation distance transformation binary location annotation distance label obtain distance distance image localization counting regression counting accurate location whereas location information important application analysis detail propose localization counting distance label novel dynamic entropy loss location specifically transform binary location annotation distance distance transformation distance category distance label location correspond local minimum distance label consequence frame localization counting dense pixel wise classification semantic segmentation resort LS improve localization accuracy dense generation distance label apply distance transformation  annotation binary location classify obtain distance distance label assign distance distance generate distance label label pixel defines distance respect location pixel location distance label pixel away location distance label ensure distance label blob without overlap exist localizes gaussian blob local maximum gaussian blob blur localization interfere severe overlap nearby adopt distance label discriminative overlap nearby binary classification directly localizes distance label roughly information closeness via geometrical meaning indicates approximate distance correspond noteworthy leverage principle distance transformation generate  counting specifically  distance transformation regress counting perform localization via distance label quantizes continuous distance discrete distance label qualitative illustration purpose dce loss local blob distance label sequential label predict predict probability truth label predict dce loss preserve geometry structure image localization model adopt pipeline described sect regression counting simply output target density distance label counting network responsible classify pixel label initial distance label similarly initial distance label prediction accurate sparse difficulty dense nearby dense predict label prone hinders accurate localization via local minimum distance label address leverage propose LS specifically threshold predict distance label pixel label candidate dense maximal regard bound dense underlie image similarly regression counting LS backbone feature resize spatial LS resize feature output factor rescale rescale image fed counting network parameter initial distance label prediction predict distance label dense output sum local minimum predict distance label sparse local minimum predict distance label dense discard dense proportion input image setting involve hyper parameter regression localization autoscale LS training objective localization model training phase localization counting model propose dynamic entropy loss function optimize localization counting network specifically counting network output channel probability classifies pixel correspond label category entropy loss probability label category correspond absolute difference truth label dynamic entropy loss  distance label classification   denotes predict probability pixel belonging predict probability pixel truth dynamic entropy loss explicitly distance prediction truth indeed distance label category explicit geometrical meaning imply relative distance annotate dot correspond absolute difference predict label truth label prediction truth relative error predict GT label roughly reflect relative difference predict GT distance dot mechanism dce loss penalizes relative difference preserve geometry structure GT distance label local blob sequential ordinary label pixel predict localization local minimum influence nevertheless pixel predict introduce false local minimum therefore propose penalize difference preserve geometry structure distance label accurate localization noteworthy prediction dense truth distance label regenerate online rescale dense regenerate rescale truth density ensures distance label dense distinguish rescale training objective  optimize localization model distance label representation      refers dynamic entropy loss initial distance label prediction prediction dense loss factor optimize LS module hyper parameter datasets evaluation protocol conduct JHU NWPU ucf QNRF shanghaitech datasets demonstrate effectiveness propose regression localization counting LS besides conduct  dataset propose distance label representation dynamic entropy loss demonstrate superiority vehicle localization counting NWPU currently exist congest dataset annotation training image val image image online evaluation benchmark website JHU extension JHU training image validation image image diverse scenario besides dataset annotation image annotation image ucf QNRF challenge dense dataset training resolution image dataset significantly image shanghaitech consists image image  internet scene significantly varied density split training image image metropolis shanghai image training image  vehicle counting benchmark dataset resolution image capture publicly available video surveillance camera spain dataset split training validation counting evaluation metric standard metric widely adopt previous evaluate propose autoscale average error mae error mse define        denotes image dataset truth predict image localization evaluation metric calculate precision recall metric evaluate localization performance specifically distance predict truth distance threshold successfully shanghaitech calculate localization metric knn distance ucf QNRF dataset report average precision average recall average distance tolerance threshold pixel NWPU dataset chooses adaptive threshold  individual width height annotate bound correspond implementation  compute localization evaluation metric datasets implementation detail  JHU ucf QNRF dataset resize image longer maintain correspond ratio image shanghaitech dataset procedure described sect generate truth density regression autoscale parameter shanghaitech ucf QNRF NWPU JHU datasets respectively localization autoscale generate truth distance label described sect depict involve datasets training phase downsampled image fed network data augmentation horizontal flip random setting involve hyper parameter depict specifically ratio threshold discard dense regression localization autoscale respectively loss factor involve training objective regression localization autoscale parameter LS initialize gaussian random update epoch adam optimize training objective batch decay rate update rate network regression localization autoscale respectively phase ratio threshold training phase propose autoscale implement pytorch workstation intel xeon core cpu 5GHz 2GB ram tesla gpu quantitative val NWPU dataset scene denote  respectively  italic bold respectively denotes localization quantitative val JHU dataset medium respectively indicates category  italic bold respectively indicates denote localization qualitative visualization density generate propose autoscale image truth density baseline LS enclose automatically dense rescale via LS prediction image quantitative comparison mae mse regression autoscale localization autoscale widely adopt benchmark datasets localization  italic bold respectively qualitative visualization distance label propose autoscale image truth distance label baseline LS enclose automatically dense rescale via LS prediction image qualitative visualization detect location localization autoscale truth clearly localization generate bound accord knn distance lsc cnn online image quantitative evaluation localization shanghaitech dataset precision recall distance tolerance threshold predict truth localization experimental comparison regression counting evaluate regression autoscale LS sample qualitative density qualitatively propose LS improve density prediction dense boost accuracy quantitative comparison NWPU JHU shanghaitech ucf QNRF datasets depict respectively vgg autoscale outperforms vgg vgg CG DRCN JHU NWPU dataset competitive vgg related   ucf QNRF shanghaitech shanghaitech datasets specifically autoscale superior performance extremely dense JHU dataset NWPU dataset demonstrates effectiveness propose LS dense counting relative sparse datasets shanghaitech LS improves baseline model significantly noteworthy BL CG DRCN leverage vgg resnet backbone adopt vgg backbone datasets comparison JHU dataset implement autoscale vgg backbone JHU dataset vgg autoscale achieves mae mse JHU dataset improve vgg BL resp resnet CG DRCN mae resp mse besides depict despite backbone network vgg autoscale outperforms vgg BL resnet CG DRCN resp resp mae resp mse ucf QNRF dataset respectively improves vgg BL resnet  resp resp mae resp mse NWPU dataset respectively ucf QNRF dataset autoscale performs slightly    adopts specific multi fusion multi activation fusion autoscale simply automatically zoom dense refinement without trick achieves slightly mae  mae mse mse  proposes adaptive dilation truth correction mechanism mae improvement autoscale target perspective module refine prediction dense noteworthy propose performs dense sparse confirms module propose dedicate improve counting accuracy dense distribution reasonable performance improvement sparse dataset dense datasets overall propose improves performance scene gathering stadium harm performance sparse scene suffer distribution issue quantitative evaluation localization ucf QNRF dataset report average precision average recall average distance threshold pixel quantitative comparison localization performance NWPU dataset precision recall adaptive distance tolerance threshold localization counting evaluate localization autoscale LS qualitative distance label illustrate localization bound location generate knn distance predict local minimum lsc cnn  lsc cnn autoscale competitive bound counting localization performance dense qualitatively propose distance label representation combine introduce dynamic entropy loss effective localize dense propose LS effectively improves localization counting accuracy quantitative comparison detection localization depict respectively localization autoscale consistently outperforms thanks LS propose localization local minimum distance label dce loss shanghaitech ucf QNRF JHU NWPU datasets comparable performance lsc cnn shanghaitech dataset demonstrate effectiveness localization autoscale evaluate accuracy localization metric precision recall shanghaitech ucf QNRF NWPU dataset correspond localization evaluation displayed respectively shanghaitech depict propose improves lsc cnn strict consistently improves upon strict setting dense dataset ucf QNRF localization autoscale outperforms lsc cnn finally propose baseline release localization benchmark dataset NWPU illustrate propose largely improves popular detection baseline faster rcnn  distinguish margin localization mae mse counting backbone dedicate localization counting localization autoscale outperforms counting localization extract dense performance baseline autoscale extract dense shanghaitech ucf QNRF JHU NWPU dataset NWPU release truth report val instead datasets propose LS achieves significant improvement baseline regression localization counting extract dense datasets quantitative comparison baseline autoscale extract dense ablation conduct ablation mainly widely adopt shanghaitech dataset effectiveness propose LS module LS effectiveness distance label dynamic entropy dce loss ablation effectiveness propose LS module effectiveness propose LS aspect effectiveness LS alleviate distribution issue effectiveness apply LS baseline effectiveness LS fix factor density dense rescale dense LS shanghaitech dataset localization compute density ratio propose LS effectively brings dense density image effectiveness LS alleviate distribution issue alleviate distribution issue regression localization autoscale specifically compute density ratio depict regression localization autoscale automatically dense significantly varied density  distribution propose LS normalizes closeness effectively  dense density consequently appropriate factor pixel decompose overlap blob meanwhile closeness density distribution pixel sparse dense reduce gap image image mitigate issue effectiveness apply LS baseline LS improve distribution issue rescale image training inference phase benefit model prediction improve accuracy propose LS consistently improves baseline fpn significant stage datasets regression localization furthermore peak blob discriminative prediction LS model suitable pixel label distribution truth model predict accurately appropriate rescale image fed resolution autoscale density baseline density visualization purpose simply resize refine prediction rescale dense dense replace density dense resize specifically regression autoscale LS improves baseline model mae mse val NWPU dataset mae mse val JHU dataset mae mse ucf QNRF dataset mae mse shanghaitech dataset improvement LS localization autoscale significant precisely LS improves baseline model mae mse val NWPU dataset mae mse val JHU dataset mae mse ucf QNRF dataset mae mse shanghaitech dataset noteworthy LS improves baseline significantly datasets shanghaitech relatively sparse dataset demonstrate LS generalize model implement MCNN  BL  propose LS shanghaitech dataset quantitative propose LS helpful baseline consistently achieve noticeable improvement shanghaitech dataset effectiveness LS density regressors reproduction correspond officially release code histogram factor effectiveness propose LS fix factor image effectiveness LS fix factor verify improvement simply zoom dense prediction conduct zoom dense fix factor histogram predict rescale factor regression localization autoscale fix factor zoom fix factor improve prediction dense propose LS outperforms alternative fix factor reasonable usually dense zoom prediction beneficial accurate counting relatively mitigate distribution nevertheless dense closeness adaptive factor counting indeed LS generates adaptive appropriate factor ratio closeness closeness mitigates distribution adaptive learnable manner improvement counting accuracy exist factor indicates loss relatively sparse central closeness ablation LS LS module density ratio threshold truth regeneration density performance variant autoscale conduct density average average distance average distance consistently improves performance average demonstrate effectiveness average distance density performance comparison density LS module shanghaitech JHU impact setting performance mae image ablation kernel training phase fix gaussian kernel distance generate distance label fix distance gaussian blob local minimum accord factor resp gaussian kernel distance resp factor resp rescale resp dense ratio threshold threshold via resp regression autoscale resp localization autoscale performance refine noisy background slightly decrease performance ignore refinement dense decrease performance news performance mae stable mae LS consistently improves baseline roughly datasets shanghaitech dataset regenerate truth extract dense demonstrate improve performance mitigate distribution simply zoom dense appropriate conduct aim fix gaussian kernel truth density gaussian kernel training phase perform straightforward gaussian kernel rescale kernel factor kernel factor former variant exist overlap pixel accumulation gaussian blob kernel becomes rescale image gaussian blob distribution density blob overlap relative amount variant kernel mitigate distribution normalize beneficial feature extractor cnn adopt fix gaussian kernel rescale effectively alleviates issue normalizes rescale dense reasonable closeness performance indeed zoom image gaussian kernel brings improvement fix gaussian kernel significantly improves baseline density regression mechanism observation localization distance label comparison counting localization classical density gaussian kernel propose distance label combine loss function dce loss denotes propose dynamic entropy loss localization counting ordinal regression loss propose dce loss image ablation effectiveness distance label dynamic entropy loss propose distance label customize entropy loss localize effectiveness utilize distance label counting localization demonstrate localization effectiveness local minimum distance label representation density representation baseline model discard LS module ablation localization distance local minimum location density representation parameter overlap gaussian blob nearby dense therefore location correspond local maximum density whereas parameter gaussian blob nearby dense severely overlap maximum density accurate conduct localization density parameter depict localization density representation parameter indeed yield accuracy localization propose distance label significantly outperforms localization density mae mse effectiveness utilize dynamic entropy loss propose dynamic entropy loss significantly improves classical entropy loss predict distance label specifically localization model without LS resp LS dynamic entropy loss improves resp mae resp mse moreover propose dynamic entropy loss introduce distance label boost localization accuracy improve localization density mae mse besides propose dce loss widely focal loss ordinal regression loss specifically propose dce loss outperforms focal loss mae resp mae mse resp mse baseline resp autoscale ordinal regression loss dedicate regress ordinal baseline dce loss achieves mae improvement ordinal regression loss ordinal regression loss model distance label propose dce loss local minimum accurate propose dce loss regression loss usually blur prediction localize local minimum dataset validation scene variation usually significant performance dataset evaluation gradually attracts attention counting counting  usually verify transferability propose autoscale evaluate performance autoscale dataset validation depict regression localization autoscale LS outperform dataset evaluation demonstrates superior generalizability propose autoscale specifically regression autoscale LS outperforms  resp convnet resp mae resp mse shanghaitech meanwhile autoscale LS outperforms BL consistently validation setting localization autoscale LS improves lsc cnn mae mse shanghaitech mae mse ucf QNRF shanghaitech lsc cnn slightly shanghaitech ucf QNRF shanghaitech propose LS focus dense dataset moreover propose LS significantly improves baseline model regression localization counting demonstrate effectiveness propose LS dataset validation experimental transferability dataset evaluation propose LS improves transferability localization qualitative localize vehicle propose distance label dynamic entropy loss image quantitative comparison counting vehicle  dataset propose distance label dynamic entropy loss localization evaluation vehicle counting conduct vehicle counting demonstrate effectiveness distance label representation propose dynamic entropy loss counting conduct  dataset evaluate propose associate metric grid average absolute error dataset      image  truth predict input image evenly image non overlap sum mae non overlap equivalent mae metric qualitative distance label illustrate baseline fpn model distance label dynamic entropy loss accurately localizes vehicle quantitative comparison dataset depict propose outperforms evaluation performs competitively evaluation noteworthy mention  dataset mask dense therefore baseline model instead autoscale conduct counting localization confirms effectiveness propose distance label representation dynamic entropy loss localize vehicle failure regression localization autoscale enclose automatically dense rescale via LS prediction image failure related discussion regression localization autoscale improve counting accuracy dense image incorrect prediction noisy background dense failure initial prediction difficulty noisy background fake inappropriate dense selection zoom noisy background uncontrollable disconnect dense localization another unsatisfied counting dense propose autoscale selects dense rescale refine improve dense therefore exploration dense selection conduct simply disconnect dense refinement autoscale depict refining dense slightly increase performance shanghaitech JHU dataset improvement limited mae mse usually image disconnect dense statistically none shanghaitech image image JHU disconnect dense regression counting localization counting image shanghaitech image disconnect dense candidate dense relatively sparse explains improvement limited therefore although dense refinement brings slight improvement simply refine prediction LS dense currently adopt dense selection strategy somehow heuristic improve performance gain future conclusion explore density aspect distribution pixel wise density counting propose LS performs unsupervised cluster leverage loss dense appropriate closeness accurate counting decompose accumulate density reduce density distribution gap density effectiveness LS validate density regression distance label localization counting later dedicate dynamic entropy loss function improve effectiveness localize addition extensive challenge datasets demonstrate effectiveness propose LS module superior performance propose localization counting localize propose dynamic entropy loss besides propose density regression autoscale localization autoscale LS achieve appeal performance dataset evaluation transferability counting moreover propose LS apply baseline achieve consistent improvement furthermore localization autoscale performs competitively localize counting vehicle future improve dense selection strategy currently somehow heuristic explore issue distribution density interested investigate effectiveness LS vision task vehicle counting localization