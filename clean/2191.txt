neural architecture NAS potential effectively reduce manual effort network automatically discover optimal architecture noteworthy detection NAS algorithm despite significant importance computer vision knowledge recent NAS detection task fail satisfactorily strike balance performance efficiency model alone excessive amount computational resource algorithm propose efficient obtain detector feature pyramid network prediction anchor detector namely FCOS tailor reinforcement paradigm carefully algorithm strategy evaluate network quality perform detection architecture within gpus discover architecture surpass detection model faster cnn RetinaNet FCOS AP coco dataset comparable computation complexity memory footprint demonstrate efficacy propose NAS detection code available http github com  NAS FCOS introduction computer vision detection commonly core task research swing generally detection network complex image classification former localize classify multiple image simultaneously latter output image label due complex structure numerous hyper parameter effective detection network challenge usually manual effort task mostly manually impressive performance NAS approach impressive automatically discover perform network apply variety computer vision task manual NAS framework typically data driven instead driven hence intervention sum workflow NAS sample architecture strategy evaluate performance sample architecture update parameter proxy network optimize performance efficiency prohibit NAS realistic application performance evaluation consume involves training procedure neural network obtain accurate metric ideal fully sample architecture standard datasets training strategy correspond task task detection training architecture already multiple gpus therefore training phase realistic computation constraint reduce evaluation proxy task substitution proxy task input network parameter training iteration evaluation however performance gap sample proxy task target task evaluation bias elaborately proxy task accurate efficient specific issue NAS another improve efficiency construct supernet candidate architecture parameter however significantly increase memory consumption restricts moderate model cannot decouple directly performance gap exists research strategy necessarily another prompt researcher continuously expand efficient accurate NAS approach detection memory NAS detection network capable discover perform architecture within significantly reduce overall detection architecture FCOS anchor stage detection framework feature pyramid network prediction propose NAS clarify architecture anchor detector cancel processing anchor anchor detector RetinaNet model evaluate model magnify contribution summarize propose memory efficient NAS fpn architecture detector carefully proxy task evaluation strategy evaluate perform architecture gpu specifically efficiency enable develop proxy task training scheme skip backbone finetuning stage adapt progressive strategy reduce extend discriminative criterion evaluation architecture employ efficient anchor stage detection framework processing NAS discus workload relationship fpn explore importance define sect overall structure NAS FCOS flexible equip various backbone MobileNetV resnet resnet resnext surpasses detection algorithm comparable computation complexity memory footprint specifically model improve AP model FCOS counterpart conference version version considerably extend firstly carefully coco subset refine proxy task pascal voc investigate transfer capacity architecture coco subset fitting MS coco dataset evaluation voc proxy task coco improves detection performance AP comparable computation complexity secondly comprehensive mechanism explore NAS trend feature classification regression feature suitable task thirdly propose specifically anchor model actually structure directly transfer anchor model RetinaNet combine RetinaNet detector NAS architecture significantly outperforms RetinaNet AP resnet backbone AP anchor model benefit related detection generally detector consist backbone proposal network  backbone extract feature input image fpn responsible blending multi feature proposal network generate prediction candidate extract feature pas refine localization classify specific rpn framework detection roughly categorize stage detector stage detector specifically stage detection framework firstly generate independent proposal rpn classify refine extra detection typical detection paradigm cnn series cnn firstly introduces cnns detection achieves impressive performance selective apply generate proposal classify svm due feature calculation cnn limited inference cnn cnn computation feature proposal propose rpn enables training stage detection framework improves accuracy faster cnn extra mask cnn unifies visual task instance segmentation detection framework despite achieve performance stage noticeable drawback computationally expensive hyper parameter tune specific dataset comparison structure stage detector simpler directly predict category bound location feature generate cnn backbone yolo yolov directly conduct classification regression feature extract input ignore  boost inference ssd introduces bound feature AP loss due lack  extent yolov lesson detection technique greatly improve accuracy without loss efficient det optimizes structure hyper parameter achieve empirical detection performance detector stage detector stage detector prediction anchor aspect ratio convolutional feature location however usage anchor imbalance non introduce extra hyper parameter recently anchor stage detector attract increase research due fully convolutional architecture reduce consumption computational resource neural architecture NAS firstly introduce  quickly attracts attention researcher typically NAS algorithm evaluation indicator defines model component granularity operation connection contains candidate structure realistic traverse algorithm tend relatively optimal sub structure requirement accuracy efficiency evaluation indicator distinguish structure  researcher adopt RL RL situation action maximize numerical reward signal identify  RL policy reward signal model environment policy defines mapping environment action reward signal feedback action interact environment extent component NAS RL respectively evaluator role environment specific indicator reward policy instantiate controller usually lstm RL NAS workflow described introduction approach controller mapping encode structure evaluation indicator NAS notoriously consume improvement gpu gpu trick construct supernet candidate optimization efficient memory allocation difficulty approximate optimization prohibit complex structure recently researcher propose apply training reduce bias introduce approximation model simplification supernet  efficient detection architecture limitation approach restrict sequential structure sample estimate gradient introduce variance optimization prohibit complex structure framework within NAS algorithm trivial decision kernel manually module detection model image classification network merge multi feature distribute task parallel prediction fpn series handle important role detection model NAS fpn target fpn alternative stage framework RetinaNet feature pyramid architecture sample recurrent neural network rnn controller rnn controller RL however consume proxy task resnet backbone evaluate architecture research focus detection framework discus difference  aim backbone fpn structure  SP NAS CR NAS focus individual backbone structure contrast NAS fpn fpn structure   explore structure unlike model auto fpn fpn structure model DARTS gradient strategy auto fpn RL flexible easy extend detector SM NAS framework efficient discover architecture component backbone detection task fpn structure complicate target dataset furthermore  attention detection model mobile device  proposes NAS strategy channel instead latter research theme reward evaluation RL NAS proposes progressive task training acceleration cache encoder feature semantic segmentation decoder batch efficiently sequel refer technique decoder adaptation however directly apply technique detection task enjoy boost fully convolutional model complicate processing scalable batch reduce processing overhead resort recently introduce anchor stage framework namely FCOS significantly improve efficiency cancel processing anchor RetinaNet anchor counterpart FCOS significantly reduces training memory footprint improve performance although adopt FCOS improve efficiency network equip anchor anchor detector approach anchor fully convolutional detection model decoder adaptation NAS easily apply formulation algorithm upon stage framework FCOS due simplicity training tuples consist input image tensor FCOS output target pyramid representation tensor feature pyramid output channel FCOS classification label bound regression target  factor respectively network FCOS consists backbone fpn multi subnets prediction backbone input tensor intermediate feature resolution fpn feature feature pyramid prediction apply prediction avoid overfitting apply instance effective receptive mechanism merge intermediate feature particularly important detection network research widely adopt backbone structure resnet principle goal feature merge improve efficiency reuse parameter pretrained target dataset optimal structure convenience statement network component namely decoder structure objection detection network detection extract feature target pyramid representation unified mapping apply feature avoid overfitting seldom discus possibility diversified extract feature layer across NAS automatic possibility mainly focus decoder detector decoder configuration sequence component fpn configuration configuration stage detailed description diagram decoder structure conceptual NAS FCOS decoder consists sub network fpn prediction structure notable difference fpn stage detector partially layer prediction marked explore layer layer automatically algorithm fpn actual layer illustration online image function apply respectively particularity fpn structure overall connection output built simplicity sequential apply fpn mention fpn convolutional feature initialize sample pool construct layer sample pool operation apply aggregation operation agg merges output feature fpn apply multiple output sample pool  transforms sample pool output  fpn define apply sample pool    topology yield pyramid feature output consistent FCOS obtain via stride convolution respectively information across layer global feature dangle layer sample later  belongs layer wise merge output feature aggregation operation feature resolution upsampled bilinear interpolation candidate operation separable convolution decoder efficient enable decoder apply convolutional filter irregular grid deformable convolution aggregation operation wise sum concatenation convolution prediction prediction feature pyramid output correspond FCOS RetinaNet consists convolution explore potential therefore extend sequential generation specifically define sequence operation candidate operation fpn structure slight difference standard convolution module conv conv sample pool comparison FCOS replace batch normalization BN layer normalization GN operation sample pool BN invalid output output sixth layer detector tend independent parameter inside flexibility understand independent prediction index location prediction firstly extend independent fpn index determines ratio balance workload individual fpn facilitate extraction specific feature prediction index responsible exploration specifically layer stage independent fpn output otherwise global purpose unary operation secondly unequal feature remains FCOS independent adapt classification regression importance feature implementation explore layer define index concretely classification regression individual convenience expression strategy RL strategy apply rely lstm controller predict configuration progressive strategy joint fpn structure prediction former compute resource latter specifically progressive firstly manually training dataset randomly split meta meta val subset training fix backbone network cache pre compute backbone output architecture training independent depth backbone network advantage apply complex backbone structure utilize quality multilevel feature decoder input backbone finetuning skip cached feature powerful speedup technique polyak average apply training widely detection metric average precision AP however due difficulty detection task stage AP architecture controller converge purpose architecture evaluation easy stage training therefore sum negative loss reward instead average precision       loss FCOS gradient controller estimate via proximal policy optimization ppo implementation detail phase proxy task evaluate decoder architecture sample phase pascal voc carefully MS coco subset explore proxy task former investigate transfer capacity structure latter fitting MS coco dataset evaluation pascal voc dataset contains training image bound annotation voc training randomly split meta image meta val image category sample coco construct proxy subset carefully MS coco dataset randomly sample voc however category detection target candidate network training obtain proxy dataset coco factor instance average average ratio bound  image per category average ratio obtain bound image factor information category coco interval indicator calculate sample category ensure data distribution coco category proxy dataset sample architecture meta compute reward meta val input image proxy datasets resize randomly cropped target correspondingly adam optimizer rate batch polyak average apply decay rate decoder evaluate iteration decoder adaptation backbone feature fix cached phase enhance cached backbone feature initialize pre source implementation FCOS finetune proxy dataset training strategy FCOS finetuning perform phase progressive strategy fpn retain operation fpn structure output channel decoder input resize output channel width fpn via convolution fpn structure fix stage parameter identical fpn structure exception output channel width adjust deliver information fpn controller model nearly converge architecture voc coco proxy task respectively perform architecture proxy task training phase fpn architecture pre fetch feature controller nearly converge faster fpn architecture training achieve performance proxy task phase within gpus performance reward voc proxy task throughout model reinforcement image performance reward coco proxy task reward overall due complex coco subset image dev coco training training phase phase fully model MS coco training dataset evaluate MS coco validation image training configuration exactly FCOS comparison input image resize maximum model gpus batch iteration initial rate reduces tenth iteration improve trick apply model  visualization discover fpn structure structure voc proxy task coco image visualization discover structure upper structure correspond voc coco proxy task respectively image fpn structure proxy task illustrate respectively voc fpn structure controller identifies deformable convolution concatenation perform operation unary aggregation respectively voc controller chooses operation skip connection maximum operation discover dconv conv structure achieves accuracy FLOPs voc FLOPs params 4G 6G significantly performance AP voc structure coco proxy task tends deformable  coco voc decoder backbone mobilenet powerful backbone resnet resnext balance performance efficiency implement decoder computation budget feature dimension another fpn channel width prediction coco dev voc proxy task decoder feature dimension surpasses FCOS counterpart AP backbone channel significantly reduce parameter calculation suitable resource constrain environment model channel MobileNetV backbone surpasses FCOS backbone AP FLOPS decoder achieves balance accuracy parameter model outperforms FCOS variant AP slightly FLOPs params comparison FLOPs parameter model illustrate respectively diagram relationship FLOPs AP backbone backbone NAS FCOS slight increase precision gain advantage computation quantity channel obtains precision computation complexity fpn channel width prediction decoder obtain voc proxy task image diagram relationship parameter AP backbone adjust channel fpn structure achieve balance accuracy parameter decoder obtain voc proxy task image coco proxy task mainly focus decoder feature dimension voc version decoder driven carefully coco subset FLOPs parameter achieve comparable NAS distribution data extent attribute improvement coco sub narrow gap coco fairer comparison layer decoder twice baseline FLOPs backbone MobileNetV coco decoder outperforms FCOS counterpart AP resnet improves AP voc decoder computation improve trick FCOS coco model resnext achieves AP compute proportion feature within structure sample progress image curve tend feature image structure equip detector understand importance layer trend graph mechanism respectively structure statistical cycle deepens percentage operation increase multi detection model necessity however model tend independent feature conduct classification regression task comparison NAS besides typical anchor detector FCOS anchor model benefit propose entire framework rely specific component FCOS directly equip structure anchor detector RetinaNet outperforms AP origin fpn baseline resnet coco proxy task anchor model benefit demonstrate comparison NAS detection twice architecture  per gpu AP NAS fpn achieve stack fpn stack fpn model resnext backbone outperforms NAS fpn AP FLOPs calculation correlation reward obtain voc meta val dataset AP evaluate coco val image correlation reward obtain proxy dataset APs attain architecture coco specifically randomly sample architecture structure coco batch training coco consume reduce iteration model evaluate coco validation visible correlation reward APs obtain coco spearman pearson coefficient respectively perform architecture distinguish reward proxy task comparison RL reward vertical axis AP obtain proxy task validation dataset online image ablation reinforcement reward widely accepted indicator reward specific task  segmentation AP detection however AP reward upward trend curve analyze controller mapping decoder reward calculation AP complicate mapping within limited iteration comparison clearly increase AP validation loss RL reward curve effectiveness discus impact verification fix fpn fix another entire decoder brings slightly benefit progressive combine achieves comparison APs obtain resnet backbone impact deformable convolution aforementioned deformable convolution candidate operation adapt geometric variation comparison replace standard convolution deformable convolution fpn FCOS specifically replace deformable convolution twice however replacement difference calculation nearly model voc model therefore deform FCOS NAS FCOS model achieves performance AP voc deform FCOS model AP replace circumstance demonstrates despite candidate operation connection feature proxy task contribute performance conclusion propose neural architecture optimize detection network perform detector efficiently carefully proxy task strategy model evaluation metric coco demonstrates efficiency discover model NAS FCOS flexibility various backbone architecture