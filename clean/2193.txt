enable impressive progress accuracy semantic segmentation ability estimate uncertainty detect failure safety critical application autonomous exist uncertainty estimate mostly evaluate task unclear generalize complex scenario fishyscapes public benchmark anomaly detection task semantic segmentation urban evaluates pixel wise uncertainty estimate towards detection anomalous adapt recent semantic segmentation model uncertainty estimation approach softmax confidence bayesian density estimation image  supervise anomaly detection anomaly detection ordinary situation benchmark allows advancement beyond data submission information http fishyscapes com introduction impact precision computer vision enable semantic understand robotic application however algorithm usually datasets fix uncontrollable incorrect reaction autonomous agent unexpected input disastrous consequence autonomy ensure safety reliability decision information outlier uncertain ambiguous affect quality perception output illustrate convolutional neural network cnns react unpredictably input deviate training distribution presence outlier interpolate available confidence exist research detect behaviour label distribution OoD anomaly novelty detection focus develop image classification evaluate datasets mnist cifar generalize elaborate network architecture pixel wise uncertainty estimation assess prior motivate practical introduce fishyscapes benchmark evaluates uncertainty estimate semantic segmentation benchmark detect potentially hazardous anomaly scene fishyscapes data cityscape popular benchmark semantic segmentation urban benchmark consists fishyscapes web image cityscape  regularly crawl web setup fishyscapes lose hazard dataset setup cityscape supplement label overview adapt variety semantic segmentation originally image classification segmentation network complex computational adaptation trivial approximation overcome challenge expose unseen training semantic segmentation model predicts familiar label  confidence detect failure evaluate various assign pixel wise distribution darker outline illustration image embeddings intermediate layer important information anomaly detection recent generative model develop novel density estimation embed however visual appearance mislead feature none evaluate achieves accuracy safety critical application conclude remain benchmark enable community progress upon perform summarize contribution introduce public benchmark evaluate pixel wise uncertainty estimate semantic segmentation dynamic update dataset anomaly detection report extensive evaluation diverse approach uncertainty estimation adapt semantic segmentation task novel anomaly detection gap allege capability establish performance task thereby confirm necessity benchmark research direction related review relevant semantic segmentation benchmark aim confidence estimate output network semantic segmentation model fully convolutional network pixel wise supervision adopt encoder decoder architecture reduces spatial resolution feature subsequently upsamples transpose convolution fix bilinear interpolation unpooling additionally dilate convolution spatial pyramid pool enlarge receptive improve accuracy popular benchmark segmentation urban scene latter cityscape establish dataset depict scene european dense annotation limited effort datasets increase diversity environment  incorporates data numerous mapillary recent data release multi sensor multi modality recording datasets explicitly derive cityscape relevant foggy cityscape overlay synthetic fog onto dataset evaluate robust vision  ass generalization model across datasets robustness reliability evaluate benchmark rank accord accuracy without account uncertainty prediction additionally despite cannot assume model data encounter scenario rarely quantitatively evaluate knowledge  public benchmark explicitly report uncertainty OoD however drawn limited image outlier introduce diverse  mainly focus accuracy  zurich dataset allows uncertainty aware evaluation semantic segmentation model regard deprive sensor input evaluate  uncertainty OoD semantic segmentation overlay cityscape image manner however assume availability OoD dataset realistic context mostly evaluate supervise contrast ass OoD data  gal introduce metric uncertainty evaluation quantitatively ass misclassification segmentation normal ID data  benchmark anomaly segmentation image industrial production anomaly mostly focus compute  benchmark anomaly segmentation simulated scene confirm establish poorly semantic segmentation methodology lack argue later important anomaly detection uncertainty estimation aim detect OoD data misclassification define uncertainty confidence estimate probabilistic model neural network output straightforward approach uncertainty estimation softmax classification probability predict baseline although sensitive adversarial performance improve  applies input gradient FGSM  probabilistic model extend belief network propagate activation distribution throughout network bayesian adopts probabilistic model output probability distribution instead estimate uncertainty define dispersion distribution epistemic uncertainty model uncertainty corresponds uncertainty model parameter training data model architecture evaluate posterior intractable non linear network recent perform MC sample dropout ensemble  uncertainty data uncertainty arises input data sensor apply semantic segmentation successively evaluate misclassification detection ID data OoD detection  gale later distributional uncertainty model  respect OoD input approach however apply image classification toy datasets OoD data training stage address latter constraint earlier propose generative adversarial network gan generates OoD data boundary sample however challenge complex dimensional data resolution image urban scene recently bayesian investigate inductive bias network structure beyond extract meaningful uncertainty ensemble network activation depth  employ sample scheme architecture OoD novelty detection tackle non bayesian approach feature introspection amount discrepancy distribution feature training data OoD sample NN statistic gaussian approximation benefit classification model without specific training recently connection feature density bayesian uncertainty investigate approach specifically tailor perform OoD detection classification aim discriminative embeddings density estimation estimate likelihood sample data distribution generative reconstruction quality auto encoder reconstruction discriminate OoD sample  roy apply latter image robotic successfully detect environment benchmark truth uncertainty evaluate estimator straightforward task proxy classification task detect anomalous input uncertainty estimate binary classifier threshold performance reflect suitability estimate uncertainty anomaly detection approach however introduces issue public OoD detection benchmark publicly available ID training data OoD input distinguish uncertainty informs classifier discriminate input classifier discriminate latter option clearly progress towards goal uncertainty estimation overfitting release validation associate truth mask hidden continuously evaluate submit dynamically synthetic dataset performance dynamic dataset evaluation data additionally submission benchmark OoD data training checked link publication benchmark datasets qualitative fishyscapes static fishyscapes web fishyscapes lose truth contains label ID OoD pixel ignore void pixel additionally output per dataset without OoD training report AP output online image scenario describes autonomous agent freely interact unexpected perception scenario benchmark therefore truly unexpected input argue truly fix dataset limited diversity simply identify dataset instead propose dynamically dataset sample diverse iteration option generate dynamic datasets iteration capture data annotate render simulation capture blend already annotate scene data essential realistic setting annotation semantic segmentation expensive sustainable generate datasets multiple per essential render 3D ensures physically viable placement consistent image diverse available textured 3D model blend scene acknowledge ongoing debate  render blending technique achieve realistic image upon response benchmark dataset FS web approach blending reference dataset FS static dynamically dataset FS web FS static validation cityscape limited visual diversity important contains none  addition background pixel originally belonging void  exclude evaluation borderline OoD anomalous extract generic pascal voc dataset associate segmentation mask overlay  cannot cityscape  bottle  sofa  cropped image border filter randomly underlie image none ego vehicle  probability screen airplane probability upper limited ensure pixel image apart ego vehicle comparably likely anomalous image characteristic cityscape employ series postprocessing described  without 3D model adapt shadow task anomaly detection harder synthetic fog distribution pixel per image probability prevents fraudulent input fix cityscape image dataset split minimal public validation image hidden image contains around OoD ID pixel validation contains disjoint pascal prevent shot data creation illustration blending improvement apply june adaptation predominantly cityscape image visually obvious important improvement depth blur glow image FS web built similarly FS static overlay crawl internet keywords script image transparent background uploaded recent timeframe filter image manual filter image suitable decorative border watermark dataset march contains OoD ID pixel diversity image distribution image web pascal voc adapt overlay procedure june onwards marked image already smooth alpha channel smooth mask around border transparency gradient adapt brightness towards brightness  pixel apply inverse histogram cityscape image shift distribution towards underlie image radial blur depth blur image glow simulate  illustration blending blending dataset feasible ensure overfit artifact blending detect anomaly semantics appearance sample ID blending dataset database cityscape training dataset bus bike manually filter occlude instance random image blend anomalous cityscape skip random placement histogram adaptation latter addition introduce FS web jan postprocessing improve iteration dataset purpose FS web dataset overfitting dynamically dataset refine image overlay procedure update recent research update blending apply FS static validation submission validate blending improvement image sect capture annotate scene multiple per sustainable synthetic data generation dynamic dataset however deployment equally important purpose FS lose dataset benchmark FS lose lose dataset however dataset annotation anomalous coarse annotation appropriate evaluation anomaly detection distinct texture challenge evaluate anomaly building structure image pixel wise annotation distinguish anomaly background cityscape void anything cityscape training image additionally filter sequence hazard bike regular cityscape data anomaly subsample repetitive sequence label sixth image remove image public validation image  image disjoint location lose image capture setup cityscape distribution scenery image capture housing industrial parking anomalous usually equally distribute image nevertheless dataset allows image oppose synthetic data therefore prevent overfitting synthetic image processing important parameter tune validation metric metric associate binary classification task ID OoD data unbalanced metric roc suitable therefore rank primary evaluation AP however false positive recall particularly relevant safety critical application additionally report false positive rate recall fpr metric   emphasizes safety semantic classification goal benchmark uncertainty estimation outlier detection segmentation accuracy therefore additionally report iou semantic segmentation cityscape validation safety critical important detect anomaly reaction therefore report inference joint segmentation anomaly detection per frame image cityscape validation geforce gpu evaluate evaluate fishyscapes exist baseline adapt task semantic segmentation propose novel embed density finally submit public benchmark approach apply semantic segmentation model deeplab implementation detail supplementary baseline softmax maximum softmax probability commonly baseline evaluate   OoD detection apply metric pixel wise additionally softmax entropy propose capture information softmax OoD training generally strive bias data confidence data obvious baseline explore  taylor suppose OoD distribution pascal voc approximate unknown pixel cityscape void evaluation model maximise softmax entropy OoD pixel introduce void additional output uncertainty softmax entropy void bayesian deeplab introduce  gal kendall gal uncertainty estimate already apply semantic segmentation literature epistemic uncertainty model dropout layer encoder approximate MC sample  uncertainty corresponds categorical distribution uncertainty predictive entropy distribution    probability sample epistemic uncertainty mutual information MI  dirichlet deeplab prior network extend framework gal predict logits concentration parameter dirichlet distribution prior predictive categorical distribution intuitively dirichlet prior model distributional uncertainty remain data uncertainty model categorical distribution  gale advocate network objective ID sample prior concentration  compute smooth label fix OoD sample prior  effectively maximize dirichlet entropy convergence predictive distribution truth model pixel wise dirichlet distribution approximate OoD sample void pixel dirichlet differential entropy knn embed estimate uncertainty knn statistic infer embed vector training prediction discrepancy uncertainty detail encoder image embed layer training intuitively OoD differently distribute adapt semantic segmentation issue embed intermediate layer deeplab actually embeddings knn query layer computationally infeasible   layer FS lose validation embed resolution input training embed therefore associate multiple output label baseline approximation link associate image patch relative density   downsampled prediction contrast   cosine similarity   without additional loss finally upsample density feature input assign pixel density association unclear encoder decoder architecture evaluate density estimation independent  assumes OoD sample density translate density embed density introduce novel approach inspiration density estimation greatly improve scalability  benchmark density estimation knn weakness estimation coarse isotropic approximation distribution feature significantly complex embeddings entire training NN costly input image recent OoD detection leverage complex generative model normalize directly estimate density input sample however directly applicable generative model image capture entire complexity urban scene pixel wise density ideally infinitely context computationally intractable approach mitigates issue density training drawn unknown distribution correspond embeddings normalize parameter approximate minimize negative likelihood  training embeddings  compose bijective function  embed latent vector identical dimensionality gaussian prior  express  logùëù det  efficiently evaluate constrain  compute embed input image estimate  embeddings NVP  compose succession affine couple layer batch normalization random permutation benefit normalize complex distribution knn kernel mixture gaussians embed label available feature simpler distribution input image correctly simpler shorter training hyperparameters related architecture training validate  ID data without OoD data training embeddings efficiently summarize generative model memory footprint input preprocessing trivially apply approach  estimator network compute gradient average  input image  encoder ensemble built training density estimator layer segmentation model however  estimate cannot directly aggregate embed distribution dispersion dimension density propose normalize  embed average  training feature layer MC approximation differential entropy intractable ideal multivariate gaussian corresponds mahalanobis distance aggregate normalize resize layer strategy minimum detects pixel OoD likelihood layer accounting feature distribution training average logistic regression FS lose validation capture interaction layer submit submit benchmark online august implement overview benchmark outlier multi task fashion semantic segmentation architecture supervise fashion ID OoD data sample training execute simultaneously segmentation training outlier detection return pixel wise anomaly submit variant description submission publication image  reconstruction estimate input training data distribution generative model auto encoders described sect poorly detail urban achieve generative adversarial network synthesize scene semantic segmentation outlier  image comparison flip semantic label ID data therefore outlier training resolution segmentation data submit adapt model  modular approach combine  uncertainty input reconstruction pixel wise dissimilarity detail described performance evolution iteration FS web dataset plot perform variant OoD data plot dash notable blending june inclusion blend ID january data balance image discussion benchmark december aforementioned datasets qualitative successful fail fishyscapes lose dataset input image  evaluation label predict anomaly variant highlight anomaly indistinguishable image softmax confidence confirm finding simpler task softmax confidence reliable anomaly detection training OoD data clearly improves softmax detection bayesian deeplab data difference datasets performance gap data lose datasets attribute factor dataset contains image AP random classifier anomalous pixel qualitative challenge lose dataset false positive void classifier outlier anomalous detect bayesian deeplab softmax entropy investigate FS web overall trend attribute difficulty individual difference data balance becomes embed blending artifact FS web march dirichlet deeplab perform inconsistently fix advanced blending june introduction blend ID embed overfitting specific dirichlet deeplab OoD data semantic segmentation accuracy data illustrates tradeoff anomaly detection segmentation performance bayesian deeplab outlier consistently datasets loss reduce segmentation accuracy segmentation accuracy important retrain particularly supervision OoD data important anomaly detection dataset OoD data unsupervised training OoD data principle overfitting specific FS web specifically resemble setting outlier dissimilarity ensemble robust diverse anomaly however emphasize anomaly detection uncertainty estimation principle benchmark therefore serf dual purpose anomaly segmentation scalable uncertainty estimate simply proxy task anomaly detection bayesian deeplab void classifier uncertainty estimation compete supervise specifically anomaly segmentation inference differs significantly broadly sort category pas sometimes modify deeplabv architecture category applies additional processing pas measurement category magnitude inference exception layer embed density inference comparable pas nearly  execute optimise tensorflow graph measurement dependent implementation detail parallelization limited gpu memory constraint difference softmax max prob softmax entropy dirichlet entropy explain inefficiency softmax entropy implementation difference challenge adaptation reveal cannot easily adapt semantic segmentation retrain loss impair segmentation performance loss dirichlet deeplab unstable training converge challenge complex network structure complicate translation embed segmentation illustrate performance implementation conclusion introduce fishyscapes benchmark anomaly detection semantic segmentation urban complex task multiple conclusion softmax output standard classifier indicator anomaly detection perform loss reduce semantic segmentation accuracy supervision anomaly segmentation OoD data consistently outperform unsupervised scenario overall benchmark improvement safely deploy semantic segmentation autonomous research public benchmark fishyscapes evaluation urban scenario