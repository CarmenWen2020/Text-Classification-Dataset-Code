propose novel continuous latent semantic analysis fitting efficiently effectively estimate parameter model instance data latent semantic analysis continuous preference analysis specifically construct latent semantic LSS inliers model instance mapped independent direction gross outlier distribute origin LSS analyze data distribution effectively remove gross outlier LSS propose improve cluster algorithm remain data propose fitting achieve excellent fitting due effective continuous preference analysis LSS propose efficiently obtain fitting due dimensionality reduction LSS experimental synthetic data image demonstrate propose achieves significant superiority model fitting fitting accuracy computational geometric model fitting challenge task computer vision apply computer vision task homography fundamental matrix estimation vanish detection 3D reconstruction segmentation challenge model fitting robustly estimate model parameter data involve outlier multiple structure background primary definition firstly definition model fitting address model fitting geometric model usually specify model fitting popular geometric model homography fundamental matrix etc geometric model specify explain data model model instance structure instance specify model data multi structural data multiple model instance minimal subset minimum data generate model hypothesis data fitting data homography fitting model hypothesis generate minimal subset subset sample sample strategy data outlier model hypothesis usually generate estimate model instance data definition model fitting described input data specify model goal estimate parameter model instance explain input data generally model fitting procedure sample minimal subset generate model hypothesis estimate parameter model instance accord generate model hypothesis model selection propose improve quality sample proximity    performance model selection  RansaCov mainly focus effectiveness computational efficiency model selection prior exist fitting roughly classify category consensus analysis preference analysis fitting consensus analysis fitting RANSAC RansaCov     directly model instance generate model hypothesis accord evaluation criterion inliers model hypothesis data accord user specify estimate inlier thesis RANSAC popular fitting due simplicity robustness outlier RANSAC described randomly sample minimal subset data generate correspond model hypothesis model hypothesis max inliers estimate model instance RANSAC robust however suffers limitation randomly sample minimal subset model hypothesis generation footnote model instance data proportion outlier however sample minimal subset significant sample minimal subset outlier computational complexity dimensional model moreover RANSAC sequentially selects model hypothesis estimate model instance multi structural data via remove framework effective computationally efficient improve fitting performance RansaCov formulates model fitting coverage maximum inliers  assigns generate model hypothesis selects model hypothesis maximum estimate model instance  formulates model fitting optimization  directly cluster generate model hypothesis selects model hypothesis maximum cluster estimate model instance  combine hypergraphs mode seek directly model hypothesis estimate model instance accord similarity matrix although fitting sensitive data distribution performance relatively affected unbalanced data distribution fitting performance largely depends quality generate model hypothesis preference analysis fitting  HF RPA linkage linkage mct estimate model instance label data generate model hypothesis specifically  adopts hyperedges relationship model hypothesis data model fitting HF introduces novel hypergraph model formulate model fitting hypergraph partition RPA combine principal component analysis non negative matrix factorization multi structure model fitting linkage linkage directly cluster data accord preference mct extends linkage handle nest model moreover model fitting pearl  coral currently exist fitting estimate fitting residual matrix derive model hypothesis data however model instance data sample model hypothesis fitting suffer computational complexity compute similarity data data overview propose segmentation image motivation contribution propose continuous latent semantic analysis CLSA robust multi structure fitting aim exploit advantage preference analysis achieve fitting accuracy reduce computational complexity multi structural model fitting apply latent semantic analysis LSA data involve outlier LSA valuable analysis originally construct dimensional subspace analyze relationship document processing effectively reduce dimension document vector inspire construct dimensional latent semantic LSS analyze relationship data LSA continuous preference analysis cpa footnote implement linkage model fitting worth combination LSA cpa important improvement LSA cpa LSA cpa capture accurate relationship model hypothesis data LSA notion cpa LSA reduce dimension preference matrix generate cpa principal preference information LSA cpa jointly fitting performance computational efficiency knowledge exploit relationship data model hypothesis via LSA cpa robust multi structure model fitting moreover analyze construct LSS remove gross outlier cluster remain data independent direction LSS usually outlier gross outlier pseudo outlier data gross outlier data belong inliers model instance data pseudo outlier data belong inliers model instance outlier model instance data aim effectively remove gross outlier cluster inliers belonging model instance LSS firstly adaptively threshold information theoretic approach remove gross outlier LSS analyze distribution remain data LSS cluster direction via improve cluster algorithm LSS model fitting homography estimation segmentation formulate cluster easy overview propose CLSA apply segmentation preference matrix entry preference data model hypothesis continuous latent semantic analysis input feature mapped LSS propose LSS correspond inliers gross outlier distribute differently correspond gross outlier distribute origin LSS correspond inliers model instance distribute respective direction origin LSS remove gross outlier input data complex model fitting becomes easy cluster effective efficient manner primarily concerned propose model fitting data model fitting jointly parameter underlie model segmentation induced assignment data model aim data accuracy estimate model instance contrast model extraction estimation accuracy concern model parameter estimate induced segmentation per despite focus segmentation model parameter beyond scope contribution summarize propose analyze complex relationship data model hypothesis exploit advantage latent semantic analysis continuous preference analysis improve performance segmentation accuracy computational efficiency robust model fitting propose adaptive gross outlier removal strategy latent semantic inliers gross outlier separately distribute formulate complex model fitting cluster remain data without gross outlier improve traditional cluster introduce preference function effectively initial achieves stable cluster task model fitting experimental evaluation comparison demonstrate significant superiority propose geometric model fitting model fitting task organize component propose fitting sect summarize sect experimental synthetic data sect discus propose sect conclusion sect methodology detail propose continuous latent semantic analysis fitting CLSA formulation sect review background latent semantic analysis LSA sect construct novel latent semantic LSA continuous preference analysis cpa sect analyze data distribution construct latent semantic propose adaptive gross outlier removal strategy sect propose improve cluster algorithm remain data sect formulation data model hypothesis generate sample define preference function preference data model hypothesis exp denotes residual sampson distance data model hypothesis threshold influence propose CLSA detail sect compute preference matrix estimate parameter model instance data input data belonging model instance function define            mislabeled data   input data estimate model instance model instance SE otherwise SE latent semantic analysis LSA latent semantic analysis LSA propose analyze binary matrix document via singular decomposition svd document representation specifically document   generate binary matrix  denotes relationship document document belongs otherwise LSA document latent document meaningful association  svd LSA firstly decomposes  svd   orthogonal matrix singular vector   identity matrix respectively   diagonal matrix singular diagonal singular non increase    approximately compute singular        LSA  coordinate document latent document document inner        latent LSA effectively analyze relationship document latent semantic construction inspire LSA propose analyze inlier index matrix generate data model hypothesis via svd model fitting binary inlier index matrix relationship data model hypothesis continuous preference matrix derive preference function instead binary improve fitting performance input data generate model hypothesis singular decomposition continuous preference matrix entry derive  recall preference matrix denotes preference data model hypothesis specifically data prefers model hypothesis decomposition svd singular vector denotes preference data topic model model hypothesis topic model estimate model instance model fitting accordingly singular vector denotes preference model hypothesis topic model data singular denotes strength correlation data model hypothesis possibility topic model data topic model model hypothesis correspond model instance data otherwise topic model data topic model model hypothesis usually insignificant ignore inlier correspond model instance correlation therefore analyze data model hypothesis instead analyze data model hypothesis usually discus influence sect rewrite   consistent svd singular account singular simplify complex model fitting construct latent data belonging model instance data preference model hypothesis data construct relates singular vector origin construct latent semantic LSS involves latent semantic information inliers belonging model instance data usually correspond mapped direction LSS inner   matrix singular  singular vector  define coordinate data LSS longer analyze preference matrix LSS dimension reduce preference matrix LSS worth data LSS specific physical interpretation data dimension LSS corresponds preference topic model model hypothesis complex model fitting reduce easy LSS analysis outlier removal information theoretic approach homography estimation input  image propose outlier removal strategy estimate inliers remove gross outlier gross outlier marked inliers model instance marked online image adaptive outlier removal construct LSS propose novel effective outlier removal strategy subsection LSS data correspond inlier assign direction data distribute origin LSS correspond gross outlier assign dimension LSS corresponds preference topic model model hypothesis obviously topic model model hypothesis prefers inlier topic model model hypothesis prefers gross outlier LSS correspond inliers model instance distribute independent direction correspond gross outlier distribute origin LSS correspond inliers origin correspond gross outlier remove correspond gross outlier threshold accord distance mapped LSS however manually threshold input data propose information theory adaptively threshold outlier removal firstly mapped LSS compute euclidean distance mapped LSS compute gap maximum distance mapped max quantity information mapped logùëù prior probability mapped correspond outlier compute normalize gap  correspond entropy compute logùëù remove mapped quantity information estimate entropy retain quantity information entropy illustrate outlier removal strategy outlier removal information theoretic approach homography estimation  image inliers assign quantity information gross outlier assign quantity information propose outlier removal strategy successfully distinguishes mapped LSS worth although propose outlier removal strategy information theory improve fitting performance significantly propose strategy information theory remove gross outlier data remove insignificant model hypothesis generate model hypothesis propose strategy LSS parameter inlier segmentation construct latent semantic approximate multiple dimensional remove correspond gross outlier probability LSS propose cluster remain mapped cluster corresponds model instance correspond data inliers model instance distribution mapped LSS belonging cluster obvious discrimination inliers belonging model instance topic model model hypothesis prefer direction LSS cluster DBSCAN  cluster remain LSS however cluster limitation sensitive selection initial DBSCAN  parameter input data improves employ novel technique initial specifically propose initial introduce preference function similarity LSS tanimoto distance         preference data model  denote standard inner correspond induced norm respectively distance distribution inlier data inliers pseudo outlier euclidean distance tanimoto distance model fitting task image euclidean distance tanimoto distance robust distribution data data preference model hypothesis tanimoto distance otherwise tanimoto distance distance distribution inlier data inliers pseudo outlier euclidean distance tanimoto distance data  data respectively pseudo outlier distance inliers euclidean distance pseudo outlier distance inliers tanimoto distance tanimoto distance effectively capture distance inliers model instance euclidean distance employ tanimoto distance euclidean distance propose fitting similarity data accord tanimoto distance closest chosen summarize propose cluster algorithm algorithm propose improvement initial selection standard achieve stable cluster due effectiveness initial however worth achieve cluster model fitting preference information similarity data effective euclidean distance robust model fitting complexity analysis component described previous summarize continuous latent semantic analysis CLSA fitting algorithm propose CLSA mainly latent semantic LSS construction outlier removal inlier segmentation CLSA firstly construct LSS latent semantic analysis continuous preference analysis inliers model instance independent direction gross outlier mapped LSS CLSA analyzes distribution mapped LSS adaptively remove gross outlier information theory model fitting easy CLSA label remain via improve cluster algorithm parameter inliers model instance estimate respectively experimental sect CLSA efficiently effectively multi structure fitting computational complexity propose CLSA mainly focus improve effectiveness computational efficiency model selection model fitting model hypothesis generation preference matrix directly derive residual data model hypothesis computational complexity data construct latent semantic computational complexity approximately  dimension LSS respectively outlier removal computational complexity algorithm computational complexity estimate inliers complexity CLSA approximately amount  segmentation error obtain propose CLSA fitting parameter fitting segmentation homography segmentation segmentation horizontal coordinate denote groundtruth model instance data image investigate performance propose CLSA fitting model fitting  consensus analysis fitting  RansaCov preference analysis fitting linkage RPA synthetic data image moreover effectiveness propose cluster algorithm version CLSA CLSA traditional algorithm cluster LSS CLSA propose algorithm cluster LSS  baseline fitting task homography segmentation segmentation due effectiveness MS intel core cpu 4GHz 6GB ram segmentation error SE function segmentation error obtain propose CLSA fitting sample algorithm RANSAC  proximity task fitting segmentation homography segmentation segmentation image parameter analysis setting subsection analyze influence parameter threshold propose CLSA fitting performance parameter fitting segmentation homography segmentation segmentation task sect datasets respectively segmentation error obtain CLSA parameter CLSA abe achieve segmentation error fitting task specifically threshold respectively fitting segmentation homography segmentation segmentation CLSA achieve relatively stable propose CLSA fitting fitting segmentation homography segmentation segmentation segmentation error obtain CLSA truth model instance data CLSA fails model instance fitting task contrast truth model instance CLSA achieve segmentation error inliers model instance wrongly mapped direction truth model instance CLSA fail correctly label obviously truth model instance mainly focus model selection model instance propose compete RansaCov RPA linkage algorithm segmentation error obtain cpu propose CLSA fitting model hypothesis task fitting segmentation homography segmentation segmentation image obtain propose CLSA fitting segmentation sub truth segmentation fitting segmentation obtain CLSA inlier inliers outlier label inliers estimate model instance label setting image quantitative comparison obtain compete fitting segmentation synthetic data influence sample algorithm analyze performance CLSA popular sample algorithm RANSAC  proximity fitting segmentation homography segmentation segmentation respectively task sect datasets respectively segmentation error obtain CLSA fitting segmentation version CLSA sample algorithm achieve segmentation error compete fitting however random sample algorithm RANSAC CLSA generates proportion model hypothesis fitting task CLSA achieves relatively segmentation error achieve CLSA sample algorithm sample algorithm proximity generates quality model hypothesis  faster  therefore proximity sample algorithm propose compete influence model hypothesis subsection analyze performance CLSA model hypothesis fitting segmentation homography segmentation segmentation task datasets segmentation error obtain CLSA cpu CLSA CLSA achieve segmentation error generate model hypothesis fitting task achieves stable fitting across model hypothesis stable CLSA cpu CLSA spends increase model hypothesis fitting task preference analysis becomes complex model hypothesis generate therefore CLSA generate model hypothesis fitting task however fairly compete model hypothesis generate model hypothesis fitting segmentation homography segmentation segmentation respectively moreover compete model instance model hypothesis fitting segmentation evaluate performance fitting fitting segmentation challenge synthetic data report average segmentation error format average error standard deviation obtain fitting average cpu  compete fitting obtain propose propose CLSA fitting achieves significantly compete fitting regard average segmentation error cpu CLSA achieves performance CLSA faster fitting CLSA faster fitting CLSA CLSA faster compete effectively reduce dimension preference matrix greatly improve computational efficiency moreover formulate fitting simpler cluster improves computational quantitative comparison obtain compete homography segmentation image  dataset actual model instance data outlier percentage gross outlier obtain CLSA homography segmentation  dataset image truth segmentation fitting obtain CLSA image segmentation accuracy  RansaCov CLSA achieve segmentation error data linkage RPA achieve segmentation error data fail data repetition model instance  data model instance contrast CLSA CLSA stable CLSA sensitive initialization CLSA achieve standard deviation error contrast CLSA succeed fitting data achieves average segmentation error compete fitting data CLSA CLSA stable achieves relatively standard deviation due effectiveness propose CLSA homography segmentation evaluate compete homography segmentation image  dataset footnote dataset contains image homography segmentation image segmentation evaluate sect report average obtain compete fitting obtain CLSA homography segmentation CLSA achieve obtain average segmentation error image obtain segmentation error image compete fitting image CLSA achieves median overall segmentation error worth CLSA CLSA implement model selection within image compete contrast  succeed fitting image RansaCov achieves segmentation error image however RansaCov  image median overall segmentation error   remove ineffective model hypothesis perform model selection RansaCov considers generate model hypothesis model selection procedure although linkage RPA preference analysis fitting CLSA achieve segmentation error CLSA image CLSA principal preference information remove redundant information latent semantic analysis moreover CLSA effective cluster algorithm label data CLSA achieves average segmentation error CLSA image average segmentation error CLSA image effectiveness improve cluster algorithm  outperforms compete image model instance    image fails fitting image unbalanced data    image quantitative comparison obtain compete segmentation image  dataset obtain CLSA segmentation  dataset image truth segmentation fitting obtain CLSA image segmentation task segmentation image  dataset evaluate performance compete fitting average fitting obtain CLSA RansaCov achieves average segmentation error fails model instance RansaCov considers generate model hypothesis ineffective hypothesis minimal subset segmentation task consists data sample inlier minimal subset sample minimal subset increase probability model instance data generate ineffective model hypothesis ineffective model hypothesis significant influence fitting obtain RansaCov linkage RPA achieve segmentation error image computational relatively due complicate cluster procedure  achieve reasonably average segmentation error image CLSA achieves reasonably average segmentation error image  achieve average segmentation error compete CLSA obtains segmentation error image obtains median overall segmentation error addition CLSA achieve stable segmentation error image generate model hypothesis excellent performance mainly latent semantic construction outlier removal inlier segmentation CLSA CLSA CLSA implement model selection within image faster compete discussion comparison CLSA CLSA propose approach identify variant variant perform usually accurate something uncommon accuracy tradeoff CLSA variant priority usually faster generally inferior performance usually beating competitor variant CLSA recommend issue performance segmentation priority compete propose CLSA generalize model fitting parameter significantly affect accuracy CLSA CLSA robust sample algorithm generate model hypothesis experimental fitting segmentation CLSA effectively data model instance outlier experimental homography segmentation segmentation CLSA performance compete CLSA significant advantage compete segmentation homography segmentation task segmentation challenge ineffective model hypothesis moreover cannot ignore fitting  directly fitting task parameter effectively handle data intersection structure however fitting performance largely depends quality generate model hypothesis propose CLSA achieves performance segmentation unbalanced data correspond ratio inliers model hypothesis minimum maximum inlier  image minimum maximum ratio inliers data ratio generate model hypothesis correspond model instance generate model hypothesis image although propose CLSA significantly improves performance fitting unbalanced data inliers belonging model instance unbalanced effective heavily unbalanced data unbalanced data minimum maximum ratio inliers belonging model instance data  image significantly ratio generate model hypothesis correspond model instance model hypothesis preference function CLSA effective inliers model instance minimum inlier ratio propose CLSA data however compete fitting limitation sample non minimal subset alleviate unbalance generate model hypothesis however challenge quantitative comparison version propose fitting segmentation subfigure segmentation error obtain cpu propose respect cumulative distribution curve coordinate percent image image influence component propose worth argue propose CLSA fitting combination latent semantic analysis LSA continuous preference analysis cpa important improvement LSA cpa verify evaluate version CLSA CLSA LSA cpa CLSA BPA LSA binary preference analysis BPA CLSA sne cpa sne fitting segmentation homography segmentation segmentation outlier removal strategy 1D mixture gaussian model  LPM propose CLSA gaussian CLSA  CLSA LPM respectively  LPM model fitting CLSA  CLSA LPM homography segmentation segmentation addition tanimoto distance version CLSA   distance quality preference matrix generate model hypothesis version CLSA quantitative comparison version CLSA fitting segmentation homography segmentation segmentation respectively quantitative comparison version propose homography segmentation subfigure segmentation error obtain cpu propose respect cumulative distribution image quantitative comparison version propose segmentation subfigure segmentation error obtain cpu propose respect cumulative distribution image CLSA achieve performance segmentation error CLSA BPA datasets task fitting segmentation data outlier cpu datasets effectiveness cpa model fitting CLSA CLSA sne preference matrix LSA sne respectively CLSA achieve segmentation error cpu CLSA sne task effectiveness LSA model fitting outlier removal strategy CLSA achieves segmentation error CLSA gaussian CLSA  CLSA LPM task cpu effectiveness propose outlier removal strategy model fitting distance CLSA superiority CLSA  performance segmentation error task cpu effectiveness tanimoto distance model fitting quality preference matrix CLSA achieve stable fitting task estimate model instance image input segmentation estimate model instance propose image estimation model instance estimation model instance data important challenge task model fitting model hypothesis correspond model instance inliers promising adaptively estimate model instance data analyze inlier distribution quality estimate model instance specifically algorithm reasonable maximum model instance data easy user input truth model instance data obtain model hypothesis candidate algorithm model hypothesis candidate significant model hypothesis outlier remove algorithm usually model instance data compute ratio inliers model hypothesis candidate model hypothesis candidate cluster ratio inliers model hypothesis candidate likely correspond model instance fuse model hypothesis candidate correspond model instance estimate model instance counting model hypothesis estimate model instance input assume maximum model instance data satisfied contrast obtain segmentation model hypothesis candidate quality cluster parameter estimation correspond model instance estimate model instance propose conclusion propose continuous latent semantic analysis fitting CLSA exploit advantage latent semantic analysis LSA preference analysis cpa LSA significantly increase efficiency reduce computational propose CLSA cpa CLSA effectively relationship model hypothesis data exploit advantage LSA cpa construct novel latent semantic LSS gross outlier origin LSS mapping inliers model instance independent direction LSS employ information theoretic approach remove correspond gross outlier LSS treat complex model fitting cluster easy dealt data correspond gross outlier remove propose effective cluster algorithm inlier segmentation extensive experimental propose CLSA achieve performance fitting segmentation accuracy computational efficiency model fitting task