transferable representation visual domain adaptation DA route label source image recognize target image without aid target domain supervision relevant research increasingly arouse amount due potential industrial prospect non laborious annotation remarkable generalization however DA presumes source image identically sample source multi source DA MSDA ubiquitous MSDA domain shift exist source target domain source multi source target domain disagree semantics category shift issue challenge exist  propose cocktail network DCTN universal flexibly deployed framework address DCTN multi adversarial pipeline minimize domain discrepancy target multiple domain invariant feature derive source specific perplexity target feature feature source domain multi source category classifier integrate perplexity categorize target image accordingly derive theoretical analysis towards DCTN interpretation DCTN successful without precisely craft source specific hyper parameter target loss upper bound domain category shift  evaluate benchmark empirical involve vanilla challenge category shift transfer MSDA source shift target shift source target shift scenario thoroughly reveal DCTN significantly boost classification accuracy MSDA performs extraordinarily resist negative transfer across MSDA scenario access auckland library introduction considerable advance representation recently improve approach variety machine vision eyeball prospect greatly attribute availability label datasets supervise nevertheless challenged domain shift traditional assumption training dataset distribution violate obstacle adapt predictive model across domain performance degradation target domain mitigate negative domain shift unsupervised domain adaptation DA arises reduce discrepancy source target domain distribution typically explore domain invariant data structure transferable representation endows classifier consistent classification ability source target exist DA approach precondition source label identically drawn individual source underlie distribution setup widely admit traditional DA research merely reflect tip  realistic transfer circumstance variety witness data drawn multiple source domain instance sake illness typicality medical image conventionally hospital application circumstance amount datasets treat multiple source consequently multi source domain adaptation MSDA increasingly  considerable attention application reasonable approach achieve transfer performance gain source DA witness progress scarce research commit MSDA due complex domain shift domain shift exists target source across multiple source domain MSDA extensive variety scenario arouse serious negative transfer influence due category shift across domain instance category distribute across multiple source domain guarantee consistency source category shift MSDA scenario shift multi source domain category account another derive popular source DA research category target domain source domain outlier category traditionally unified negative unknown MSDA extend target category shift MSDA scenario generally simultaneously source target category shift MSDA scenario category shift deteriorate domain shift damage exist DA algorithm nontrivial attempt overcome domain shift category shift challenge cocktail network DCTN flexibly deployed adversarial framework address MSDA across diverse transfer scenario DCTN encapsulates category classifier multi source domain respectively target category predictor formulate integrate category probabilistic prediction target source target perplexity perplexity domain feature similarity target source refer outcome source target domain discriminator source target domain discriminator deployed feature target source adversarial DA approach domain discriminator DCTN facilitates domain invariant feature extractor multi source domain similarity source target feature convincing source specific classifier predicts target hence target feature fed multi source classifier prediction reweighted source specific perplexity classify target analogous cocktail inspires framework dubbed cocktail network brief illustration multi source unsupervised domain adaptation MSDA scenario hierarchical relation vanilla MSDA scenario multi source target exactly category multi source data source domain domain shift categorical misalignment exist source domain multiple source target domain unknown category non existent source source target category shift simultaneously scenario derive version account MSDA scenario DCTN simplicity reveal source domain image theoretically DCTN source distribution combine target distribution suppose linear combination multiple source distribution MSDA theory adaptation upper bound classification error target domain however multi source combination involves craft source specific hyper parameter  advance approach DCTN rely mixture assumption contrast algorithm DCTN employ multi adversarial scheme adaptively multi source balance accord source target perplexity DCTN target category prediction maintains loss upper bound underlie reasonable DA approximation presumption specify multi source hyper parameter importantly developed source target category shift MSDA overall mainly contributes aspect investigate representative MSDA scenario vanilla source category shift target category shift source target category shift propose cocktail network DCTN challenge complex MSDA universal framework assumption derive algorithm develop bound target instance loss DCTN explains DCTN without rely source distribution comb develop upper bound target loss across aforementioned MSDA scenario conduct extensive MSDA benchmark diverse source target transfer category shift scenario experimental demonstrate superiority versatility DCTN remainder conclude related described sect detail setup diverse MSDA sect sect experimental sect conclude sect related domain adaptation source source domain truth target domain without label unsupervised domain adaptation aim model perform target domain source target belong distribution technical UDA mitigate domain shift inspire sample various statistical discrepancy directly apply regulate domain shift optimization shallow model TCA JDA model dan cmd  rtn STN diverse statistical regularizer domain invariant feature adversarial behaves effectively transferable representation determines couple network direction domain discriminator minimizes classification error distinguish sample source target domain mapping learns transferable representation confuse domain discriminator adversarial DA algorithm alternatively discriminator feature extractor extractor encourage directly confuse source target namely probabilistic discriminative decision transferable representation consistent domain proposes reversal gradient layer flip gradient propagate discriminator operation allows joint discriminator feature extractor easy implementation popular adversarial domain adaptation finally gan style adversary domain adaptation mostly performs asymmetric transfer pipeline due flexibility adversarial framework recent research adversarial DA perform  visual recognition across domain task transfer structure besides mainstream DA approach diverse domain invariant feature semi supervise domain reconstruction duality alignment manifold tensor feature norm adaptation etc multi source domain adaptation UDA approach mention mainly target domain versus source domain multiple source available domain shift source svm leverage ensemble source specific classifier tune target categorization model domain adaptation machine introduces domain dependent regularizer smoothness assumption enforces target classifier decision relevant source classifier domain reconstruction enforces source domain jointly rank compact source target domain MSDA develops theoretical firstly bound MSDA ideal target hypothesis distribution combination source hypothesis methodology source distribution combine closely meaning relation target source discover multiple source specific classifier obtain ideal target prediction recently approach neural net attempt address MSDA developed adversarial paradigm iteratively construct zero sum target source domain proposes multi DA normalization layer aligns multi source domain target indeed facilitate progress MSDA whereas limitation inspire develops discrepancy DA algorithm reweight importance multiple domain perform promising vanilla MSDA category shift simultaneously exist across domain commonly become unavailable category shift domain adaptation exist DA literature DA DA setup source domain target domain exactly category transfer precondition simplifies analysis DA algorithm unable handle situation source target category increasingly variety research focus address challenge suggests DA paradigm address potential data leakage issue investigate partial DA target category subset source category distinctly  gall investigate DA target category unknown source  investigates universal domain adaptation UDA DA conclude aforementioned scenario exist category shift transfer scenario however rely source domain contrast diverse category shift usually practical MSDA focus overview MSDA unsupervised domain adaptation image target domain lack annotation hamper straightforward usage supervise acquire classifier adaptive target distribution source domain category information via  route nevertheless category shift aggravate MSDA source domain adaptation explore category shift MSDA summarize representative adaptation scenario vanilla source category shift target category shift source target category shift  elaborate adaptation scenario principle context multi source domain adaptation source domain image drawn source domain underlie distribution respectively   image source   corresponds label target domain image drawn underlie distribution without label observation MSDA image source target domain utilized training image   drawn target evaluate classifier adaptation performance vanilla MSDA denotes category label source domain denotes category source domain unobserved category target domain vanilla MSDA scenario category multiple source target consistent namely scenario presumes source target domain customize consistent category semantics category shift scenario MSDA vanilla scenario image  domain category distinguish category shift MSDA scenario advocate category domain maybe generalize scenario specifically source category shift scenario indicates public source refers source category shift target category shift scenario becomes  spirit recent source DA research target category shift MSDA scenario category conventionally unified treat unknown category MSDA suppose preclude target belonging correctly categorize finally source target category shift scenario aforementioned category shift simultaneously encourages address challenge unified framework cocktail network  irrespective vanilla multi source transfer scenario  remain challenge tackle moreover research investigate DA background introduce cocktail network DCTN adversarial domain adaptation framework specify MSDA framework tailor address vanilla MSDA ought DCTN flexibly deployed adapt target domain source category shift target category shift source target shift scenario mildly reconfiguring pipeline sect elaborate pipeline DCTN principle DCTN predicts target data category diverse scenario sect alternate algorithm DCTN sect unveil theoretical insight DCTN framework DCTN consists component subnets feature extractor multi source domain discriminator multi source category classifier  cocktail target category predictor classify target feature extractor incorporates convolution neural network backbone image source target feature apart architecture domain joint adversarial subsequent domain discriminator contributes target source specific relation domain invariant feature overview cocktail network DCTN framework receives multi source instance annotate truth adapts classify target sample confine source simplicity feature extractor target source feature category classifier receives target feature jth kth classification upon category source respectively domain discriminator receives feature source target kth  target source jth  target source jth kth  source perplexity reweight jth kth classification correspondingly cocktail target category predictor integrates reweighted classification predict target category across diverse category shift scenario sample multi source domain merely training loss output omit mainly illustrate identify target sample simplicity image multi source domain discriminator built upon source specific discriminator adversary image domain discriminator receives feature source specific discriminator classifies respectively originates source target data source trigger discriminator belonging source domain data target instance domain discriminator yield source specific discriminative outcome target source respectively leveraged update discriminator target source perplexity define implies sample drawn source multi source category classifier multi output net compose source specific category classifier classifier softmax classifier configure category corresponds source category classifier image mapping feature extractor input image source gradient derive activate parameter update target image instead source specific classifier categorization contribute parameter update cocktail target category predictor component categorize target specifically target sample cocktail target category predictor source perplexity integrates classification specify classification principle MSDA scenario vanilla MSDA scenario category target domain source domain consistent hence target category predictor formulate source specific classifier prediction target source perplexity denotes category probability forecast target predictor entry denotes integrate probability belonging specific category category shift MSDA scenario category across source target domain therefore modify specifically source classifier obligate classify category correspond source DCTN identify unknown exclude category source domain activate source classifier identify target softmax prediction  source classifier probability belongs derive category source slot softmax category predictor  recognize category unknown source perplexity classify DCTN alternative adaptation pipeline pre feature extractor category classifier adopt source image feature extractor category classifier network cocktail target classifier predict category target  annotate confidence obtain pre feature extractor category classifier via tune label multi source image pseudo label target image pre training DCTN employ multi adversary scheme mapping domain feature extractor category classifier jointly multi source label target pseudo label image stage maximal epoch multi adversarial adaptation multi adversarial adaptation DCTN propose obtain domain invariant feature formulate     denotes multi adversarial loss indicates entropy loss source specific classification frozen stable gradient multi adversarial loss define     optimization solely feature extractor learns mapping respect multiple source domain target domain domain distribution simultaneously adversary oscillation spoil feature extractor regard concern source target feature mapping architecture domain confusion introduce substitute adversarial objective performs stably inspire obtain multi domain confusion loss        DCTN update feature extractor optimize objective online source domain batch mining sample mini batch multi adversarial adaptation stochastically receives source respectively update feature extractor iteration however image drawn source domain helpful boost adaptation model training proceeds redundant source image previous adaptation performance effective domain batch mining technique improve training efficiency specifically iteration DCTN randomly target source source  totally image training DCTN per iteration discriminator training described feature extractor training independently adversary target source   difficulty distinguish image source therefore performs transform target feature confuse source    upon domain confusion loss source target mini batch feature extractor technique conclude algorithm target discriminative adaptation resemble spirit exist adversarial DAS multi adversarial adaptation category variation MSDA scenario DCTN undergoes identical adversarial domain invariant feature insure ability classify target domain ben demonstrate accommodate source classifier target DA algorithm category classifier domain variety MSDA scenario classifier account categorical alignment across source target prevent damage non consistent category across source unobserved category unknown target domain achieve universal target category predictor incorporate target  feature source data via  tune develop  strategy annotate target sample feature extractor multi source classifier multi source label sample pseudo label target target category predictor obtain previous iteration annotate target sample afterwards strategy selects suitable target annotate pseudo label specifically DCTN incorporates criterion identify target sample confidence uncertainty respectively target sample DCTN considers category prediction probability accord probability threshold target sample confidence candidate DCTN  entropy identify candidate uncertainty vanilla source category shift scenario target sample confidence uncertainty pseudo label tune scenario target category shift DCTN additionally incorporate target sample uncertainty categorize unknown pseudo label strategy summarize    ent denotes representation label category ent denotes target category prediction entropy satisfy ignore discriminative adaptation phase discriminative adaptation objective define    denotes entropy loss prediction pseudo label target data pseudo label leveraged update hyper parameter important annotation strategy DCTN incorporates threshold ensure prediction probability pseudo label target training concretely iteration alternative target image belonging unknown tune feature extractor enable source classifier identify unknown target unknown gradually identify source classifier entropy become initial stage fix threshold detect DCTN entropy threshold scheme  image unknown DCTN entropy threshold unknown target image progressively decrease image unknown discriminative adaptation later stage harm performance  overcome DCTN tend implies virtual threshold training progress uncertain target sample detailed setup appendix theoretical analysis dive deeper DCTN theoretical perspective notation brief  distribution combine inspire however craft source specific hyper parameter  neural network model therefore develop methodology DCTN appropriate assumption derives adaptation  regard MSDA review distribution combine denote source target  respectively instance denote probability drawn respectively source distribution combine target distribution denotes mixture multi source distribution coefficient normalize source distribution implicit simplex namely  simplicity vanilla MSDA assumption ideal target classifier derive integrate source classifier  therefore frame DA theory interpretation specific input feature denotes target function refer label denotes hypothesis respect specific underlie distribution correspond classifier denote classification loss function MSDA objective function formulate  accord definition denote feature analysis suppose source hypothesis correspond  source distribution combine upper bound target loss proposition target distribution mixture multiple source distribution loss mixture hypothesis target function   mixture hypothesis corresponds theorem demonstrates optimal hyper parameter target distribution mixture multiple source distribution target classifier certify upper bound target distribution equation becomes assumption exist MSDA algorithm however implicit unobservable assumption transferable feature DCTN instance DA loss DCTN target predictor DCTN integrates source target relation perplexity reweight aggregate target category prediction category source classifier however multi source perplexity completely built discriminative accord multi adversarial principle instead presume simplex distribution combine although DCTN rely distribution combine meaningful upper bound guarantee target classification specifically accord cocktail target category predictor refers hypothesis denotes optimal domain discriminator respect source target distinct fix multi adversarial encourages  domain invariant feature lemma optimal corresponds  propose classify target feature  optimal feature extractor obtain multi adversarial  target feature drawn reasonable assume denotes probability target feature drawn source due adversarial DA manner enforce approach appropriate suppose source specific approximation ratio source target adaptation namely assumption multi adversarial feature extractor corresponds approximate ratio exists   implies upper bound discrepancy optimize feature closer indicates source target apart drawn target domain source domain reasonable assume beyond pseudo label strategy discriminative adaptation another assumption pseudo label assumption pseudo label discriminative  feature extractor source specific classifier multi adversarial DA update target probability false label pseudo label strategy target category correctly forecast pseudo annotate strategy upon assumption develop upper bound target classification error target feature proposition suppose converge feature extractor satisfy assumption target feature classification loss DCTN upper bound  indicates instance loss  source classifier target instance bound DCTN compose target feature bound source classifier correspond probability belongs source indicates closer target feature source probability belongs source source target feature adversarial classification tune perform source DCTN performance guaranteed classification bound probability target feature belongs source jointly dominate bound demonstrates connection DCTN multi source mixture assumption target sample however DCTN rely probability target sample belongs source transferable feature automatically obtain adversarial instead pre vanilla MSDA target instance loss respect MSDA generalization bound DCTN vanilla scenario proposition suppose converge feature extractor satisfy assumption source maintains loss mixture hypothesis define target function equation denotes surrogate target loss target category predictor directly implement feature extractor source classifier equation implies guidance transfer concretely DCTN fail source domain successfully approach target meaningful upper bound reflect MSDA normal classification bound average source classifier mismatch category MSDA category shift  vanilla MSDA scenario category predictor source shift resembles spirit concretely         specific learner extend denotes simplex respect target domain analysis MSDA target category shift conduct upper bound target surrogate loss derive proposition denote proportion target data wrongly label unknown discovery strategy proposition suppose converge feature extractor satisfy assumption source maintains loss mixture hypothesis define target function equation upper bound equality satisfied imply unknown target detect entropy unknown target discovery strategy source target category shift scenario DCTN combine analysis category shift scenario context MSDA evaluate classification accuracy target category predictor adaptation vanilla source category shift target category shift source target category shift MSDA thoroughly empirical implement gtx geforce gpu pytorch platform implementation detail refer supplementary benchmark widely apply DA benchmark ImageCLEF DA digit  introduce vanilla MSDA experimental evaluation routine previous comparison reproducibility detailed dataset split release footnote classical benchmark recognition category datasets amazon DSLR webcam image ImageCLEF DA release ImageCLEF domain adaptation challenge category  bike bottle bus monitor motorbike datasets caltech image totally image domain digit digit image drawn public datasets mnist mnist SVHN usps synthetic digit respectively training mnist mnist SVHN synthetic digit entire usps dataset domain image  image domain clp  inf  pnt painting   rel  sketch category around image DCTN performance vanilla MSDA  alexnet DCTN backbone MSDA resnet evaluate DCTN MSDA backbone ImageCLEF digit vanilla MSDA scenario sect  standardize backbone resnet evaluate source target category shift exist sect accuracy vanilla MSDA accuracy ImageCLEF DA vanilla MSDA evaluation standard evaluation protocol adopt unsupervised domain adaptation derive MSDA scenario detail introduce correspond sub generally ImageCLEF DA datasets label source unlabeled target average classification accuracy random independent report standard error classification accuracy transfer task digit  benchmark label source unlabeled target training sample evaluate performance target randomly till model converges report accuracy finally perform model selection tune hyper parameter transfer validation MSDA vanilla scenario exist MSDA lack comprehensive evaluation complex visual recognition introduce traditional MSDA approach  sparse frame   baseline MSDA approach multi source batch normalization  MSDA baseline ImageCLEF DA besides DCTN source visual DA baseline conventional transfer component analysis TCA geodesic kernel GFK DA approach domain confusion DDC reconstruction classification network DRCN reverse gradient  pixel domain adaptation  domain adaptation network dan residual transfer network rtn joint adaptation network jan achieve comprehensive understand multi source transfer DCTN source DA approach evaluation protocol source belong source DA approach directly report source transfer source combine multiple source domain combine traditional source versus target domain adaptation setup testify boost transfer performance gain augment another source domain additionally baseline source combine multi source standard image source backbone multi source classifier apply classify target source confirm multi source transfer available negative indicates failure adaptation comparison DA baseline ImageCLEF DA employ alexnet backbone backbone model appendix digit source combine basically derive official code recognition report transfer DCTN baseline  bold italic performance respectively DCTN yield competitive transfer task perform impressively specifically DCTN significantly exceeds traditional margin mostly outperforms source DA baseline dan rtn jan RevGred source combine variant reveals MSDA treat source DA combine source performance gain fully  data transfer DCTN potential multiple source efficiently boost adaptation performance  competitive exceeds DCTN average accuracy  generalize across transfer achieve remarkable improvement  remains  source combine source DA variant comparison DCTN performance transfer demonstrates significant generalization ability ImageCLEF DA source combine DA variant achieve superior source model whereas remains inferior DCTN validates domain DCTN transferable discriminative feature baseline multi source transfer image domain  completely fails ImageCLEF DA negative transfer source baseline digit recognition previous visual recognition benchmark digit contains domain specify multi domain investigate transfer DCTN within domain shift performance average DCTN RevGred dan source combine transfer variant classification accuracy digit dataset MSDA vanilla average accuracy performance baseline absolute performance upon accuracy source  dan DCTN ImageCLEF DA MSDA category shift scenario curve denote accuracy public across multiple source increase image relative performance degrade  accuracy vanilla scenario minus accuracy category shift source  dan DCTN ImageCLEF DA MSDA category shift scenario curve denote accuracy public across multiple source increase image transfer gain accuracy baseline minus accuracy source source  dan DCTN ImageCLEF DA MSDA category shift scenario negative negative transfer heavier model damage without domain adaptation image overall accuracy baseline conclude apparent accuracy source DA approach source combine implies increase multiple source evidence boost transfer performance gain solely involve source domain however source combine typically perform source despite potential benefit multiple source source DA approach conventionally suffer negative transfer therefore advantage multi source information model comparison DCTN consistently positive transfer performance source source combine multi source ensemble DCTN outperforms baseline accuracy DCTN exceeds MSDA source category shift scenario subsection switch evaluate DCTN category shift scenario multiple source category DCTN approach dan RevGred source source combine evaluation setting conduct MSDA transfer evaluation protocol source category shift newly propose MSDA scenario benchmark amend evaluate DA algorithm scenario specifically suppose source involve category indicates public due alphabetical source specific private proportion  denotes public unveil comprehensive baseline scenario evaluate specify public proportion  respectively elaborate metric reflect adaptation capability baseline perspective classification accuracy evaluate baseline classifier address domain category shift employ relative degrade accuracy examine performance source category shift exists simply calculate        denotes accuracy public proportion   accuracy model vanilla MSDA scenario formula showcase performance inconsistent category source algorithm affected negative perform robust scenario finally employ transfer gain metric confirm availability transfer transfer gain calculate baseline accuracy accuracy source positive undoubtedly transfer available negative DA approach aggravates domain shift transfer experimental metric accuracy degrade accuracy transfer gain illustrate respectively DCTN outperforms baseline proportion public transfer generally improvement becomes source public source DCTN behave  DA accuracy target category shift scenario relative enhancement source obtains DA DCTN imply source outperforms DCTN DA algorithm dan RevGred DCTN source undergoes fully supervise therefore risk category misalignment extent treat sort consecutive strategy prefer safety supervise training adapt domain without label data absolute performance obvious source almost inferior DA approach besides superior transfer performance improvement another merit DCTN resistance potential negative transfer influence demonstrate DCTN remain positive transfer specifically dan impressive transfer performance public performance transfer gain unstable public becomes challenge RevGred performs stable dan whereas inevitably suffer negative transfer wholly suppress DCTN similarly ImageCLEF DA dan RevGred fail achieve promising transfer performance public transfer model damage MSDA target category shift scenario subsection evaluate DCTN target category shift scenario previously DA multi source experimental reconfiguring benchmark concretely randomly caltech dataset source target unknown fairly domain DA treat source combine baseline target shift protocol specifically evaluate baseline domain domain across source target unknown target identification accept routine adapt abandon baseline comparison DA approach DCTN target category shift MSDA scenario OSVM mmd OSVM BP OSVM ati OSVM RevGred OP derive svm OSVM employ threshold preclude target probably belonging unknown developed RevGred source ensure fairness comparison directly report publish performance source scenario evaluation evaluation OS OS evaluate DCTN comparison  target category evaluates category evaluation criterion OS OS accuracy RevGred OP remain suppress DCTN DCTN RevGred OP DCTN RevGred OP MSDA source target category shift scenario source target category shift concurrently joint negative transfer mitigate MSDA algorithm remain underexplored evaluation experimental setup MSDA target category shift proportion public category source shift conduct transfer clp pnt  rel  inf clp pnt  rel inf    category IDs unify construct unknown afterwards proportion public category  challenge benchmark slightly data split routine specifically source fourth source source contains category category source  fourth source source contains category public  refers across source source simplifies complex category relation across source domain encourage evaluation focus  performance across baseline accuracy source MSDA DCTN transfer source target category shift scenario OS OS evaluation protocol target category shift scenario curve denote accuracy percentage public across multiple source increase image accuracy source MSDA DCTN transfer source target category shift scenario  OS OS evaluation protocol target category shift scenario curve denote accuracy percentage across multiple source increase image baseline distinct evaluate previous sub comparison MSDA DCTN along source MSDA DCTN MSDA algorithm spirit insightful DCTN MSDA prevent negative transfer MSDA algorithm unable handle unknown category target domain comparison endow MSDA identical strategy DCTN screen unknown sample baseline evaluate classification accuracy OS OS criterion illustrate clp pnt  rel inf  clp pnt  rel  inf accuracy curve DCTN MSDA perform upper envelope source negative transfer eliminate notably DCTN ahead protocol proportion public decrease transfer gain DCTN MSDA gradually minimize public category across source domain transfer improvement MSDA completely erase transfer MSDA suffer serious negative transfer OS OS protocol instead DCTN transfer gain showcase superiority DCTN tough category shift scenario sne  domain respectively marker denote category  calculator monitor printer  image analysis accuracy DCTN adversarial pseudo model accuracy sample pseudo label target sample convergence performance loss image model analysis feature visualization task visualize DCTN activation adaptation impressive demonstrate transferability learnt DCTN simplicity source domain emphasize contrast target domain source activation adaptation indicates DCTN successfully transferable feature multiple source besides target activation become categorize suggests feature DCTN attains desirable discriminative finally multi source transfer compose transfer task DCTN adapt target domain without performance degradation ablation algorithm ablation DCTN consists multi adversary auto label scheme reveal function decompose DCTN variant adversarial model excludes pseudo label update category classifier source sample pseudo model forbids adversary categorize target sample average multi source accuracy adversary behaves stably iteration due lack target guidance performance bottleneck without adversary accuracy pseudo label significantly DCTN accuracy indicates adaptation cooperate achieve desirable transfer behavior dive deeper accuracy pseudo label accuracy converge alternative implicitly reveals consistency adaptation ablation domain batch mining technique  efficacy pseudo label strategy ablation pseudo label target sample role training perform DCTN important annotation strategy improve baseline evaluate dan rtn jan RevGred source DA algorithm source combine  MSDA DCTN MSDA algorithm independently without pseudo label strategy accuracy source approach  decrease probably due classifier prediction instead MSDA DCTN benefit pseudo label strategy convergence analysis DCTN involves complex procedure adversarial alternative adaptation testify convergence performance loss transfer demonstrates despite deviation classification loss adversarial loss error gradually converge comparison algorithm pseudo label target sample training image conclusion explore unsupervised DA involve multiple source challenged domain shift category shift beside vanilla MSDA transfer scenario investigate innovative realistic MSDA scenario category across multiple source target assume inconsistent overcome transfer challenge propose cocktail network DCTN adversarial DA framework obtain transferable discriminative feature multiple source target domain constitutes alternate  refers target classification principle DCTN flexibly deployed ordinary MSDA category shift scenario importantly scenario mild reconfiguration delve motivation DCTN reveal DCTN connects previous MSDA theory enjoys loss upper bound adversarial DA assumption instead specify target mixture precondition finally DCTN evaluate across benchmark massive transfer combination scenario achieves evaluation criterion behaves extraordinarily resist negative transfer