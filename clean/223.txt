explore computer vision technique detect engagement structure activity draft feedback review activity encounter educational setting engagement annotation concurrently activity retrospectively video activity computer vision technique extract feature video rate animation microsoft kinect tracker local binary orthogonal LBP feature supervise detection concurrent retrospective report engagement roc curve auc evaluate classifier accuracy validation achieve auc concurrent annotation auc retrospective annotation kinect tracker feature individual channel overall fusion channel introduction widely acknowledge user engage activity essential component activity engage activity multiple perspective hci psychology engagement interpret somewhat community researcher definition maintain engagement involves attentional emotional involvement task engagement stable fluctuates throughout interaction hci discus phase engagement engagement sustain attention engagement disengagement attention fade engagement emphasis engagement educational activity author engagement behavioral engagement assess persistence effort emotional engagement assess detect supportive emotion curiosity efficacy cognitive engagement demonstrate sophisticated approach activity superficial strategy agentic engagement occurs attempt actively enrich instead merely passive recipient engagement affect link increase productivity psychological wellbeing engagement educational activity important consideration engagement malleable numerous educational intervention feedback engagement enhance impact intervention evaluate multiple methodology analysis motivation engagement important educational research allows researcher understand decision promote hinder engagement focus engagement data identify engagement theorist internal individual cognitive affective external observable factor perceptible facial feature posture action methodologically affective compute application engagement observational data facial expression subjective data report affective compute technique novel methodological approach engagement modality video audio physiological affect detection context multimodal approach explore improve accuracy affect detection application emotional infer via affective compute technique increasingly technology utilized video detect engagement played cognitive training attempt detect engagement educational task methodological approach focus motivate activity educational context aim engage enjoy activity contribution novelty contains novel aspect detect engagement task unique challenge limited facial expressivity frequent downward remote video detection rate HR channel engagement detection report instead rely external annotation commonly concurrent retrospective report truth label contribution detail respect particularly context engagement detection computer frequently focus attention downwards towards keyboard instead screen tilt facial feature detection accurate due non frontal inconsistent likely associate detectable expression educational activity interactive interact conversational tutor educational subtle facial expression addition facial feature rate extract computer vision technique video rate detect user engagement physiological device calibrate remote HR monitor improve HR estimation accuracy spite limitation adopt approach explore possibility engagement detection accuracy remote HR respect source report concurrent retrospective engagement annotation focus report engagement oppose external annotation researcher via crowdsourcing technique commonly report engagement external annotation derive entirely concurrent report retrospective report internal concurrent report report engagement cue recall retrospective protocol report memory internal video sometimes computer screen aid recall situation external annotation internal accurate representation internal difference particularly engagement detection external annotation video however instance  engagement instance engage knowledge focus video automatic detection report engagement background related previous affect detection focus detect emotion recently researcher focus recognition complex mental particularly attention engagement engagement behavioral expression gaze movement facial feature gesture   attempt user engagement robot conversation user gaze robot user disengage user engagement positive user verbal nonverbal behavior conversation robot propose framework detect maintain user engagement robot interaction approach rely gaze gesture gaze useful indicator attentional focus wander zone unfortunately affected movement easily scalable context emphasis physiology facial feature engagement detection explore research physiology detection central peripheral physiological signal commonly detect task engagement alertness drowsiness propose physiological attempt analyze electrical signal brain muscle monitor physiological signal electrocardiogram ECG electromyogram EMG galvanic response GSR respiration rsp  EEG widely differentiate alertness verse drowsiness various EEG engagement index propose classification accuracy percent achieve detect driver drowsiness detection EEG EEG index engagement detection computer interaction achieve accuracy percent detect user engagement video clip cardiac activity explore automatic affect engagement alertness detection rate rate variability hrv important ECG widely purpose previous research HR indicator discriminate affective HR tends sadness happiness disgust HR hrv indicator alertness drowsiness analyze hrv HR pressure palm detect driver fatigue hrv feature highly effective detect driver drowsiness propose fatigue detection hrv feature achieve accuracy percent challenge associate physiological affective compute application intrusiveness physiological sensor user access rate monitor typically physically attach issue address remote measurement technique approach investigate remote contactless measurement vital rate microwave doppler radar rate respiration thermal image another approach rate detection analysis modulation recent approach video image  detect hrv approach video measurement vital cheaper easy adopt hci application explore video HR engagement detection facial feature detection computer vision technique affective compute gain traction recent advance hardware sensor camera integrate computerize environment evidence exist review article microsoft kinect depth camera likely become standard future computer hardware camera non intrusive continuous capture image phone computer automobile facial information understand facet user technique developed automate measurement ekman friesen propose facial action cod facs widely facial muscle action AU correspond expression facial expression recognition recognize AUs reasonable accuracy tracker module embed microsoft kinect sdk action approach typically facial expression analysis geometric appearance approach geometric feature component location fix facial eyebrow etc appearance recognize facial expression analyze static dynamic dynamic texture technique facial expression recognition appearance feature report researcher feature gabor wavelet coefficient optical active appearance model investigate explicit feature measurement independent component analysis ICA gabor wavelet gabor wavelet strength weakness geometric appearance approach geometric typically facial approach feature facial appearance eyebrow extract feature related texture  wrinkle cannot extract contrast appearance sensitive illumination brightness shadow difference combination geometric appearance feature gabor wavelet recognize facial AUs claimed geometric feature outperform appearance feature combination yield affect engagement detection facial feature investigate context computer expression recognition toolbox cert facial movement within naturalistic video corpus tutorial dialogue frequent AUs eyebrow inner outer brow lower eyelid tighten  predict overall engagement frustration gain stepwise linear regression finding upper movement reliable predictor engagement frustration achieve reasonable agreement prediction manual annotation albeit coarse grain across entire session computer vision technique detect engagement interact cognitive training software filter feature difference grayscale pixel gabor feature cert feature independently machine model engagement detection label obtain retrospective annotation video external annotator engagement annotate disengagement engagement detection performance quantify AFC estimate roc curve auc classifier detect engagement user independent fashion auc average across engagement gabor feature svm classifier effective engagement detection approach related detect engagement video approach computer vision technique related review improve detection performance combine multiple channel data adopt multiple technique feature combination geometric feature kinect tracker appearance feature local binary  orthogonal physiological feature rate extract computer vision technique machine classification model independent manner ensure generalization truth measurement engagement obtain concurrently retrospectively model built separately report engagement detection model built fusion feature extract technique  collection methodology participant participant undergraduate postgraduate engineering public australia SD male female entire session data discard approve sydney ethic research committee prior data collection inform consent prior procedure approximately conduct indoors amount ambient sunlight combination normal artificial  computer essay google doc recently journalistic genre activity research information location prior knowledge likely trigger arouse emotional memory topic session draft review activity draft submit feedback feedback manuscript browse internet automate feedback improve quality additional revise manuscript accord feedback submit version video upper microsoft kinect sensor mode sensor standard dimensional video dimensional depth data video rgb channel channel frame per fps resolution pixel avi format depth fps pixel resolution kinect microphone array rate extract ECG signal  MP ECG electrode wrist electrode ankle rate recording directly truth video rate detection concurrent retrospective affective annotation essay procedure respectively concurrent report concurrent annotation auditory probe beep essay activity instruct verbally report engagement engage task response probe spoken response kinect microphone array intrusive concurrent reporting interrupt session questionnaire affect impact interrupt report engagement analyze however impact involve task  mill report periodic interruption negative impact percent complex affect measurement involve affective plus neutral nevertheless attempt minimize intrusiveness concurrent simplify information report engage verse engage decrease mental effort aloud disruptive computer questionnaire reporting task voluntary ignore prompt chose retrospective report interval segmentation video segmentation retrospective video annotation strength weakness behavior unpredictable activity researcher segmentation useful annotation accordingly video segmentation wherein video meaningful annotation specifically facial expression posture movement researcher session return extract video questionnaire accurate judgment questionnaire simply report engage engage task display disengage engage instance retrospectively annotate disengagement engagement annotation distract review disengage task engage affect report engagement concurrent reporting verbally report engagement session per session fail report engagement auditory probe session concurrent report available response obtain response probe engage percent engage percent retrospective report video extract video average SD video extract average video SD report engage majority percent report engage percent percent label applicable correlation proportion engage concurrent retrospective engagement report evidence reliability report average engagement affective session obtain concurrent retrospective report accord average engagement percent task engagement decrease gradually approach session submit essay feedback engagement report correspond affect detection analysis feedback engage percent report engagement wan session average engagement retrospective concurrent report average engagement retrospective concurrent report engagement detection methodology detect engagement feature kinect tracker LBP rate HR extract video video annotation concurrent feature synchronize correspond concurrent retrospective label feature selection technique apply data reduce dimensionality feature feature selection apply training data data finally machine classification technique apply feature validate validation independent model summary methodology illustrate overview methodology classify engagement LBP local binary orthogonal feature extraction implement feature extraction video recording explain kinect sdk facial feature extraction animation  facial  code action AUs propose ekman  equivalent AU upper lip  tracked kinect subset define  model  lip  correspond eyebrow  express numeric  upper lip raiser indicates fully upper lip  fully visible decrease towards lip addition  capture via yaw translation meter  calculate detect along specify rotation 3D accordingly twelve calculate frame feature aggregate across individual frame statistical median standard deviation max min difference frame aggregate frame obtain FT feature distance occlusion factor affect accuracy sensitive camera accord manual microsoft angle angle yaw angle however yaw  respectively detect return outside abovementioned detect ignore preprocessing stage sometimes mistakenly detect background avoid false positive detect normal local binary orthogonal local binary propose powerful texture description appearance dynamic facial LBP operator central pixel label neighborhood pixel thresholding central pixel pixel calculate LBP pixel image calculate distribution unique histogram extract image histogram occurrence specific local define radius LBP extract application characteristic image variation facial expression recognition zhao  facial expression dynamic texture volume local binary  facial expression recognition approach promising although prototypical emotion recognize temporal segmentation perform approach normalize frame ignore rigid movement sequence addition fix overlap distribute evenly instead focus specific eyebrow valuable information facial expression local binary  orthogonal LBP recognize engagement previously recognize valence arousal achieve reasonable accuracy LBP operator originally static image recently zhao  propose extend version LBP dynamic texture instead video sequence series XY axis analyze series XT axis YT axis respectively zhao  video sequence orthogonal dimensional LBP compute separately LBP descriptor video clip calculate concatenate LBP histogram LBP procedure representation XT appearance image others XT YT pixel separately LBP procedure video sequence orthogonal  extract correspond histogram histogram concatenate LBP histogram component specific texture apply LBP operator entire facial image useful information hence facial video sequence image detect extract automatically extend boost cascade classifier deformation monitor video image detect resize fix radius extract LBP LBP previous valence arousal detection video sequence orthogonal feature extract extract HR feature estimate HR introduce improve detect video extend boost cascade classifier implement opencv algorithm focus likely photoplethysmogram signal detect opencv library sometimes contains background omit analysis percent width detect height roi ensure unwanted background roi rgb channel average rgb amplitude calculate across pixel roi raw signal input independent component analysis apply ICA raw signal detrended normalize improve quality signal ICA blind source separation BSS technique attempt multivariate signal statistically independent subcomponents assume subcomponents non gaussian signal ICA statistically independent component independence maximum adopt linear ICA joint approximate diagonalization  jade algorithm linear ICA assume signal linear mixture source signal typically source signal cannot identify ICA recoverable source observation output ICA independent component identify component contains HR signal analysis component manually argue HR signal clearly component propose machine automatically estimate HR component propose improve error RMSE HR prediction per bpm bpm demonstrate accuracy vision HR measurement accord feature extract spectral density psd curve independent component independent component feature extract feature frequency peak psd curve apply reduction frequency peak HR frequency reduction ignore previous estimation difference estimation previous HR prediction bpm estimation ignore algorithm examine peak reduction peak psd curve distance bpm previous estimation frequency peak feature depth reduction feature model regression average feature input vector actual HR extract ECG signal  training fold validation approach estimate HR extract HR feature video RMSE bpm HR prediction achieve algorithm error acceptable clinical application however assume estimation affect engagement detection demonstrate replace HR sensor camera application affective compute research statistical feature median standard deviation max min difference extract rate estimation video feature selection supervise classification built engagement detection model individual channel HR FT LBP model fusion feature channel feature fusion model fusion classification channel decision fusion feature fusion built model feature channel feature feature channel feature model HR channel feature additional feature without effectively influence channel heavily another built model feature channel feature namely FT LBP selectively predictive feature channel feature FT LBP feature HR finally built decision fusion model classification output channel decision classification output FT LBP decision correspond feature fusion model decision fusion classifier individual channel classifier classification decision engage engage whichever classifier decision probability advantage decision fusion classifier classifier instance regardless instance available channel feature instance feature detect FT LBP decision individual classifier FT model valid FT instance within training dataset instance detect LBP vice versa LBP classifier classifier instance available channel decision obtain classifier feature selection reduce dimensionality extract feature relief feature selection training data technique assigns feature accord euclidean distance instance instance distance instance another feature ranked proportion ranked feature explore proportion feature FT channel LBP channel HR channel HR data feature proportion FT channel LBP channel feature feasible proportion FT channel proportion SMOTE synthetic minority oversampling technique SMOTE model handle data imbalance training data data SMOTE creates synthetic instance project data feature random minority within SMOTE resampling outlier handle outlier instance standard deviation feature outlier treatment unchanged  replace outlier standard deviation classifier weka machine classification classifier model built  naïve bayes classifier distribution standard deviation feature within label instance predict apply bayes theorem probability instance member distribution probability bayes net classifier graphical model utilizes bayes theorem compactly conditional probability feature network structure individual feature assume independent related label logistic regression classifier regress label feature logistic function logistic function bound interval interpret cutoff prediction instance classification via cluster cluster apply training data cluster cluster assign label corresponds instance assign label accord cluster correspond rotation rotation classifier feature randomly split principle component analysis pca apply classifier decision apply pca component classifier randomly chosen percent instance ensemble classifier instance classify assign average confidence  classifier creates ensemble classifier decision  classifier randomly splitting training data fold training classifier instance classify majority vote classifier validation model nest validation training consist data percent chosen randomly consist data remain feature selection perform nest validation within training feature selection perform repeatedly training data percent training percent average across feature selection entire classification model randomly chosen training estimate roc curve primary classification performance metric account accuracy auc closely approximates statistic robust imbalance classification performance kappa accuracy auc completely incorrect classification auc perfect classification classification performance classifier discriminate engagement engage versus engage channel report accord explain video feature extract FT channel feature extract LBP feature extract HR channel addition channel combination channel fusion model feature combine channel feature fusion fusion model feature perform individual channel combine similarly decision fusion model channel decision channel decision built report separately retrospective concurrent label concurrent report classification perform model built data concurrent report delve important discus issue pertain instance feature across model summary model built concurrent report instance varied channel HR channel susceptible instance rely specific facial feature FT LBP handle situation extreme occlusion fuse multiple channel feature data channel feature instance FT LBP channel feature instance channel loss instance adversely affect engagement rate decision fusion model instance feature fusion model decision decision training instance decision fusion model feature fusion model however instance training HR classifier FT LBP instance chosen training data iteration however training independence preserve variance feature across model factor available feature feature selection feature model feature chosen feature individual channel model FT LBP minimum feature FT LBP channel ensure channel feature LBP dominate channel feature FT HR feature feature modality HR channel feature conclusion drawn performance individual channel HR FT LBP difference FT LBP mute fuse channel noticeable performance improvement individual channel FT fuse individual FT LBP model across fusion scheme yield accurate fuse channel presumably due performance HR model fourth feature fusion outperform decision fusion accurate model feature feature model FT LBP examine advantage channel fusion individual channel detail assess confusion matrix individual channel LBP fusion model feature improvement detection performance achieve channel fusion attribute accurate detection positive identification negative rejection consistent across model confusion matrix individual channel channel fusion model built concurrent report label retrospective report classification overview performance channel retrospective label concurrent label instance retrospective model across channel due challenge occlusion however instance channel fusion retrospective label concurrent label evident instance removal drastically alter rate retrospective engagement distribution summary model built retrospective report summary model built retrospective report concurrent fusion model fusion model individual channel FT LBP feature model FT channel feature LBP model feature feature model channel evenly channel feature model feature modality due limitation feature HR channel concurrent model HR performance FT individual channel accuracy LBP fusion model notable increase performance individual channel feature decision fusion feature decision model outperform feature decision model however unlike concurrent model performance feature decision model mostly equivalent confusion matrix individual model FT fusion model feature retrospective label classification performance largely improve rejection rate specifically FT feature model nearly identical rate rejection rate fusion model confusion matrix individual channel channel fusion model built retrospective report label confusion matrix individual channel channel fusion model built retrospective report label although feature model advantage decision model auc versus feature model disadvantage instance training decision nearly performance feature advantage additional training data instance FT LBP performance additional training data advantageous comparison concurrent retrospective comparison concurrent retrospective model individual channel retrospective model outperform concurrent model HR FT LBP fusion improve concurrent retrospective model albeit specifically feature fusion successful concurrent model vice versa retrospective model overall concurrent model auc retrospective model average performance label equivalent auc concurrent retrospective concurrent retrospective comparison reflect vision engagement detection context coder retrospectively judge engagement video cognitive training activity engagement disengagement screen engage independent model svm classifier gabor feature yield average auc detect engagement versus etc contrast independent concurrent model achieve auc reflect measurable improvement previous independent engagement detection however detection associate auc approach successful disengagement screen remain involve engagement average auc approach appropriate amount engagement important however comparison technique without difficulty datasets video annotation engagement annotation obtain researcher session label data report session however despite difficulty comparison potential establish standard engagement detection 6Discussion conclusion pervasiveness camera webcam sophisticated technology kinect opportunity software interface considerable research video detection affect research focus emotion disgust sadness happiness approach focus automatic detection engagement complex affective cognitive behavioral agentic component remainder discus contribution finding limitation avenue future contribution finding goal introduce automate video detect engagement context important towards develop software intervention promote engagement engagement detect realistic scenario moderate accuracy performance engagement detector engagement detection video data improve engagement detection performance discriminate across multiple engagement successful model overall fusion feature concurrent engagement label model fusion channel feature concurrent label overall auc comparison retrospective model  accuracy auc feature model importantly model validate nest validation confidence generalize demographic important contribution involve directly concurrent retrospective engagement annotation tradeoff rate false alarm rate affect model suitable application concerned primarily precision engagement detection choice model concurrent feature model rate however retrospective model rejection rate concurrent model detection disengagement arise incorrectly classify engage actually engage occurrence disengagement arguably important environment intervene become disengage retrospective label concurrent label situation advantageous amount training data retrospective decision model decision choice furthermore advantage decision fusion worth detector deployment benefit decision fusion individual classifier data feature fusion model decision fusion model potentially situation individual detector decision FT channel detector LBP channel unavailable vice versa another important contribution video remote monitoring rate although physiological engagement detection promise review video detection scalable due availability intrusiveness camera physiological sensor attempt capitalize merit approach video remote physiological signal HR performance HR channel facial expression channel FT LBP HR index cardiac activity feature hrv informative strongly correlate mental extract propose approach future advance remote physiological potential fully understood limitation future important limitation research gathering analyze behavioral data naturalistic scenario challenge issue suffer limitation regard due limit analyze frequent occlusion extract feature video thereby data loss screen video ignore video classification kinect tracker sensitive LBP furthermore approach rely manual segmentation video replace random segmentation another limitation associate HR estimation video perfect detect HR naturalistic practical scenario  signal detect machine approach propose improve accuracy HR detection user behave normally camera acceptable accuracy HR signal  context defeat purpose remote sensor approach parameterize vision approach argue actual HR signal improve report acknowledge limitation goal accurate video HR improve accuracy remote physiological measurement technique ostensibly without phase practical application important item future conclude remark improve automatic detection engagement computerize education environment effective engage detect engagement context task combine facial texture appearance feature accurate independent engagement detector possibility engagement detection remote rate however improve performance ostensibly due limited amount information future improvement remote rate detection opportunity explore combination channel increase effectiveness engagement detection computerize environment