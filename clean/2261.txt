optical marker capture mocap remains predominant acquire fidelity articulate introduce DeMoCap data driven approach marker mocap sparse setup spatio temporally align consumer grade infrared depth camera trading typical feature approach sole robust option marker mocap introduce differentiable marker model challenge constrain estimate noisy input data spatial configuration invariance simultaneously handle depth marker detection label localize marker estimate 3D introduce novel spatial 3D coordinate regression technique multi render supervision concept DeMoCap driven dataset capture spatio temporally align intel realsense sensor  camera professional mocap input truth respectively access auckland library introduction extensive research effort devote development capture mocap facto standard centric interactive medium capture production nowadays optical mocap marker essential application sector film  sport health immersive reality XR mocap enables online offline fidelity capture digitization facial movement derive performance beyond enables various application 3D animation computer interaction robotic physical monitoring despite appearance commercial academic capture marker mocap remains standard due extremely accuracy frequency production maturity ensures quality outcome amount nevertheless marker mocap production flawless suffers drawback raw optical capture data erroneous due marker occlusion mislabeling marker swap frequency jitter consume processing beyond data cleaning articulate fitting marker subset skeleton retargeting local joint transformation undoubtedly laborious consume complexity marker mocap numerous infrared specialized camera inaccessible wider interested audience complication attract research community investigate propose novel alternative computer graphic researcher intensify effort model resolve soften issue   computer vision lab concentrate effort markerless mocap mostly 3D estimation task nevertheless exist marker satisfy flexible option recent markerless model paradigm effective flexible cannot robustness precision absence deterministic prior worn marker focus gap research driven factor accuracy precision marker obtain articulate movement aid attach marker highly accurate deterministic remarkable ability model vision recent development consumer grade depth camera inherit characteristic blend efficient hybrid lightweight capture approach propose DeMoCap target marker capture combine traditional marker mocap neural network apply visual data capture depth sensor knowledge DeMoCap professional mocap aspect frequency capture model enables equipment professional retro reflective marker configuration robust capture employ sparse spatio temporally align multi setup consumer grade depth camera dense configuration spherical retro reflective marker address marker mocap challenge marker denoising label joint transformation retargeting limitation depth sensor setup viewpoint sparsity depth constraint data infrared image blurriness accurate blob detection propose fully differentiable data driven model directly regress 3D mocap marker regression task input dimensional avoid 3D convolution target lightweight application introduce novel spatial 3D regression module latent heatmaps predict 2D fully convolutional neural network fcn regress marker joint 3D coordinate fully differentiable manner various multi stage fcn architecture building super stage former latter stage regress marker joint 3D coordinate respectively stag smooth representation transition marker 3D marker approach network spatial hierarchical relation marker underlie DeMoCap marker mocap enable sparse consumer grade depth sensor portability flexibility commercial trading however typical feature image network apply volumetric normalization uniformly distribute marker cuboid 3D data spatial invariance sparsity adopt multi render technique render marker oppose orthographic camera principal axis sparse marker notably preserve 3D information marker splatting relative depth multiple oppose DeMoCap sparse depth marker model approach task 3D keypoint regression dual 2D depth model driven assimilate articulate relation marker joint sequentially regress 3D coordinate pas per infrared depth multi frame without structure prior explicit association marker subset summarize contribution knowledge DeMoCap constitutes data driven approach employ efficient fully convolutional neural network simultaneously regress optical marker 3D sparse 3D capture multi depth sensor setup translation invariant representation normalize 3D introduce network upon model overcomes bias relatively limited training data generalizes stage smooth representation transition marker 3D model driven underlie structural relation marker configuration placement decode marker association sparse noisy 3D marker accurate estimation 3D keypoint estimation joint 2D localization regression objective within normalize 3D embed dimension indirectly introduction fully differentiable module 3D regression dataset publicly available dataset contains inter intra spatio temporally align infrared depth capture data former capture hardware synchronization precise temporal consistency multiple structure brief overview related data driven marker mocap automation refinement multi markerless vision 3D estimation keypoint localization technique applicable estimation dataset creation processing familiarize reader challenge approach sect methodical approach explain depth rationale contribution sect quantitative qualitative experimental along ablation outcome justify contribution sect discus pro con DeMoCap comparison exist marker capture recent markerless estimation approach sect concludes potential avenue future related approach domain knowledge marker recent data driven 3D estimation technique sect review approach recently literature focus processing marker optical capture data   highlight traditional mocap challenge marker label denoising joint transformation optical data efficient automatic fashion apply machine technique another challenge address recent propose related deformation issue prior explicitly account instead focus simultaneous overcome aforementioned mocap challenge spite reflective marker mostly 3D estimation task noisy sparse 3D data sect discus recent data driven approach estimate 3D FCNs keypoint 3D coordinate regression highlight pro con finally sect overview keypoint localization approach correlate 3D coordinate regression technique introduce marker optical capture classic marker optical undoubtedly standard capture decade nevertheless existence drawback processing data cleaning expensive hardware complexity setup challenge attract research community discus recent novel apply machine technique marker optical data marker denoising joint transformation  tackle automatic marker label machine classification weak classifier ensemble partial solver online algorithm efficient lightweight marker label robust online identification passive capture marker attach non rigid structure capture volume sparse marker multiple assignment hypothesis decision robustly recover challenge simultaneous occlusion false observation ghost marker  proposes robust joint transformation optical capture data machine denoising technique data driven approach robust erroneous marker 3D replaces capture pipeline remove manual data cleaning however limited capture data commercial applicable recently introduce robustly detects repair marker trajectory replace erroneous synthetically generate  joint transformation solver propose  initial kinematic construct reference erroneous trajectory detect transfer kinematic solver preserve introduce online optical marker label model frame label keypoint regression demonstrate sequence occlude ghost marker model accurate amount synthetic data albeit evaluate highly noisy challenge marker model regress marker 3D coordinate fully layer prone overfitting pool data limited hamper generalization ability overall network firstly introduce joint neural network multi depth marker capture nevertheless data driven model model detects label marker however estimate apply kinematics articulate prior moreover instead spherical commercial marker fidelity sparse coarse custom retro reflective strap patch attach despite valid concept limited freedom due marker custom marker placement marker label separately camera likely model bias camera intrinsic parameter classic marker mocap constitutes specialized professional capture research overcome issue mocap suffers marker label ghost marker denoising occlude marker recovery marker swap joint transformation overcome issue manner directly regress marker coordinate stag network smooth representation transition markerless 3D estimation challenge marker increase complexity capture setup joint marker non trivial task decade numerous research lab intensively markerless flexible approach resource recent focus monocular vision mostly    depth martínez gonzález limited approach 3D estimation multi estimation multi depth relatively unexplored relevant approach recent 3D estimation spatio temporally align multi visual variation learnable triangulation technique algebraic volumetric estimate 3D jointly multiple 2D former triangulation learnable camera joint confidence latter dense geometric aggregation 2D heatmap prediction multiple viewpoint aggregate volume refine via 3D convolution 3D heatmaps model prior showcase satisfy sect however multi input domain sensitive input propose another approach concept estimate 2D heatmaps multi image recover 3D multi 2D prediction convolutional neural network cnn jointly estimate 2D fusion scheme allows refine 2D estimation apply recursive pictorial structure model  3D recover multi 2D gradually improves  recursively discretizes volume around joint previously predict 3D location finer grain grid inference performance limit online operation recently  multi multi data driven 3D estimation approach contrary aforementioned multi correspondence weak 2D estimate  directly operates 3D feature camera aggregate 3D fed cuboid proposal network localize multiple capture predict 3D cuboid proposal 3D feature volume finer grain feature volume proposal fed 3D regression network despite frequent occlusion multiple scene approach accurate robust approach parametric model skeleton hierarchy expression upon generative deformation model data multiple viewpoint leverage landmark 2D detector multiple 3D keypoints obtain parametric model capture additional variation clothing capture achieve 3D deformable model potential error 2D keypoint detection bias model propose multi multi capture approach confidence heatmaps affinity  predict openpose propose unifies per parse temporal introduction 4D association graph 4D association graph efficiently introduction 4D limb bundle parse heuristic bundle kruskal algorithm contrary approach aforementioned effective lightweight cannot perform multi image domain sensitive input bias error 2D detection capture setup vicon  camera multi depth sensor equip intel realsense stereo depth device intense marker reflection provoke infrared emit infrared retro reflective marker attach limit image blurriness reduce exposure sensor consequently reduce lightness image distinguishable marker reflection comparison default setting infrared depth image truth marker project infrared depict spatio temporal alignment capture infrared depth image keypoint localization approach mocap cooperative marker joint 3D coordinate regression task sparse depth image overview approach keypoint localization nowadays vision 2D 3D keypoint localization task 2D cnns FCNs proven effective recent literature keypoint localization category regression dense prediction spatial regression regression task estimation   szegedy optical marker label bypass spatial image due fix representation instead implicitly directly regress 2D 3D expressive model nevertheless regression supervise distance loss objective keypoint localization dense heatmap prediction employ FCNs predict confidence input pixel supervise training heatmaps reconstruct via 2D gaussian distribution fix variance technique employ estimation image translation invariance regression due spatial aspect keypoints localize calculate argmax alternative heuristic approach predict dense heatmap drawback intermediate structural loss function network predict pixel confidence supervision training align objective regression spatial regression effective various vision task combine strength regression dense heatmap prediction dense heatmap prediction model translation invariant due FCNs distance loss supervision dense heatmap prediction network predict heatmaps pre define arbitrary heatmaps spatial regression network optimal latent heatmap yield accurate localization spatial regression com probability propose  martinez almost simultaneously introduce integral regression differentiable spatial numerical transform  argmax effectiveness adopt spatial regression localization however aim efficient 3D localization beyond standard technique jointly encode dimension latent heatmaps introduction fully differentiable module 3D coordinate regression 3D coordinate regression module sect depth optical marker data unique dataset spatio temporally align capture multi infrared depth data scope sect dataset constitutes visual data collection contains spatio temporally align multi infrared depth image 3D marker annotation capture various activity perform actor retro reflective marker attach visible distinguishable infrared image achieve depth sensor infrared emitter emit infrared scene reflection retro reflective marker infrared depth image align define image domain enable marker 3D localization sect achieve marker 3D keypoint annotation address challenge synchronization spatial calibration professional capture multi depth sensor described detail sect capture data actor male female perform activity approximately performance ensure appropriate initialization commercial mocap footnote sample dataset however detail split training evaluation activity criterion sect capture setup professional vicon capture vicon  camera volumetric capture  intel realsense stereo depth device data frame respectively marker configuration structure marker adhesive spherical retro reflective marker diameter attach capture actor marker data   truth respect structure sequence joint however simplify structure data   truth sample annotate depth infrared image along capture setup mocap studio dataset creation depict optical marker data multiple depth sensor recent consumer grade depth device equip infrared camera emitter zhang intel realsense depth camera active stereo vision calculate depth consist infrared camera infrared projector improve depth accuracy scene texture feature infrared projector cast static infrared scene marker reflect receiver enable straightforward amplitude detection spatio temporally align depth camera  around capture approximately diameter camera acquires infrared image depth coordinate pixel image domain define grid width height respectively sensor  coordinate denote rotation translation respectively hence transform depth image domain coordinate global coordinate  relative local coordinate sensor global denote  function transforms depth pixel 3D coordinate sensor intrinsic parameter matrix infrared depth image camera align define image domain apply linear thresholding propose  efficient marker segmentation contour detection algorithm apply yield blob per global 3D 3D bound limit capture 3D outlier discard sparse marker  3D extract per frame raw marker 3D coordinate obtain multiple sensor sensor detection around marker quality raw marker analogous majority multi mostly due elimination occlusion consequently marker sensor setup placement creation dataset avoid occlusion nevertheless propose model highly noisy data weak optical marker valid observation sparse spatially invariant 3D data representation eliminate bias camera intrinsic parameter systematic depth discus ablation sect spatio temporal alignment synchronization precision frequency depth sensor frame dataset sect detail prerequisite intel realsense intra inter sensor hardware synchronization precision temporal alignment respect inter vicon synchronization global temporal offset detect  equip marker sequence frame rate inter sequence align local remove global offset spatial alignment vicon depth sensor achieve perform initial alignment 3D marker estimate modality triangulation vicon depth exploit static phase sequence marker easily detect infrared image crisp apply iterative closest icp coarsely transform coordinate truth marker  icp mention sect detect marker per frame correspondence accurate spatial registration sensor refinement correspondence  subset marker belonging sensor construct bipartite graph  euclidean distance 3D finally apply minimum bipartite    correspondence strict threshold ensure quality correspondence  detect blob apply bundle adjustment hartley zisserman refine sensor  reference detail  intrinsic camera parameter constant jointly iteratively refine camera minimize reprojection error refine spatial alignment truth optical marker data  marker consequently apply strict spatial cluster marker distance merge detect extremely worth alignment creation dataset model inference vicon data absent spatial temporal alignment vicon multi sensor marker vicon  infrared image sample normalize orthographic depth render sparse 3D instead raw infrared depth image allows overcome limitation constraint data data driven model suffer limitation bias specific camera lightning overfitting domain specific training distance systematic depth sensor simplify task spatial 3D regression  render depth multi context oppose rendering overcome ambiguity apply volumetric translation normalization transform occupy dimension normalize cuboid 3D along although obvious worth normalization transform apply truth data   respectively supervision 3D bound sample occupies volume 3D margin boundary ensures appropriate behaviour 2D convolution across network layer render oppose sparse depth image orthographic camera principal render depth image pixel resolution linearly interpolate input resolution aim eliminate encode quantization error information loss due quantize render render across axis marker distinguishable zero render depth depth preserve marker 3D normalize depth  depth pixel sparse depth image   network sample render normalize depth illustrate application normalization transform apply random rotational augmentation around respectively increase variance orientation across cuboid volume worth 3D rotational augmentation input sparse 3D physical meaning render viewpoint camera enables creation completely depth input network training contrary limited pseudo rotational augmentation apply dense input representation image depth 2D grid input introduce lightweight model efficient inference sparse 3D data avoid 3D convolutional architecture despite effectiveness 3D convolution computationally expensive inefficient input data visualization   colorization sake clarity image multi arbitrary spatio temporally align depth infrared camera  around reflective marker attach capture movement detect marker exploit marker intense reflection provoke infrared image sensor depth perception render 3D marker normalization oppose depth image fcn jointly sequentially predict marker joint heatmaps decode novel fully differentiable module 3D marker joint conduct pas stage localize marker latter stage estimate illustrate multi input supervision concept sake brevity image depth capture factor DeMoCap reliance cheap commodity stereo infrared depth sensor despite noisy satisfactorily 3D location retro reflective marker monocular fashion without triangulation multi observation stereo infrared depth price observation inaccuracy along aforementioned challenge marker capture overcome utilize neural network enables simultaneous effective marker joint 3D coordinate regression DeMoCap introduce data driven approach marker capture multiple infrared depth model stag marker 3D regression noisy marker data  render multiple viewpoint depth data driven model marker mocap introduces marker observation cluster raw 3D capture viewpoint ghost marker denoising ignore ghost marker erroneous marker detection marker recovery occlude undetected marker recover marker swap due discrete shot inference label marker localization spatially regress 3D coordinate latent marker heatmaps instantaneous 3D regression label 3D marker without prior knowledge structure marker robustness trait combination marker label exploitation 3D information overall pipeline propose illustrate acquire multi infrared depth frame capture sensor extraction raw marker 3D normalize yield  render oppose depth image     spatial distribution marker attach fully convolutional marker stag network model sequentially predicts marker joint latent heatmaps apply novel dual fully differentiable spatial 3D regression precisely regress normalize 3D coordinate marker  joint  finally apply inverse translation transformation sect recover marker 3D coordinate physical dimension stag marker network network architecture approach concept respect network propose multi stage fcn architecture smooth stag marker heatmap prediction perform efficiently model sect prior optical marker spatial distribution network predict refine marker coordinate stage joint coordinate localize latter stage prior refine localize joint coordinate robust reliable prediction upon highly effective heatmap prediction network convolutional machine cpm stack hourglass SH recent  predict dual heatmaps   network hence model inference later fuse prediction supervise objective architecture network   depth initial pre processing module extract feature sake brevity stage network split super stage consist stage former super stage predicts marker heatmaps latter joint heatmaps aggregation intermediate heatmaps  predict stage super stage feature concatenate  stage supervise heatmaps originally propose author network per stage intermediate supervision cpm SH stage heatmap supervision  supervise aggregate heatmaps coordinate structural heatmaps respective truth joint sect aggregation scheme converges faster orchestrates slightly stag transition dense observation sparse marker joint coordinate regression validate network detail along overview sketch propose architecture appendix heatmap prediction  denote latent heatmap softmax stage heatmap aggregation across stage perform via summation  aggregation perform marker regression joint regression apply softmax aggregate heatmaps  denotes heatmap layer pixel spatial domain heatmaps visualization heatmaps illustrate plot predict heatmaps softmax network predict latent heatmaps satisfy task average coordinate 3D keypoint softmax heatmap approach gaussian distribution coordinate estimation image multi spatial 3D regression regress normalize marker coordinate  normalize joint coordinate  decode heatmaps predict correspond super stage 3D  layer contribute 3D coordinate regression propose dimensional  insertion fully differentiable  layer com coordinate decode heatmaps technique statement fully convolutional network predict heatmap distribution underlie extra spatial information layer allows encode dimension regress 3D coordinate introduction  combine fully differentiable layer  com     propose contribution com standard procedure introduce  martinez coordinate regression motivation  exploit extra freedom softmax allows heatmap supervision additionally constrain average approach truth coordinate compact 3D coordinate encode detail denote predict normalize 3D coordinate marker joint respectively regress    cardinality 2D heatmap pixel coordinate domain network architecture denote wise multiplication multi supervision finally oppose render conduct joint dual supervision estimate 3D per dual input rotate normalize coordinate prediction     around axis average normalize coordinate prediction           approach 3D coordinate oppose 3D volume regress normalize marker joint 3D coordinate correspondingly model learns predict heatmaps average approach normalize truth coordinate normalize 2D softmax approach normalize truth coordinate diagram DeMoCap depicts various concept render depth multi input fed former marker super stage sequentially latter predict marker joint heatmaps correspondingly softmax apply  decode coordinate  coordinate com regress 3D coordinate fuse stage supervise marker joint prediction  respectively network manner image loss training jointly supervise truth coordinate respectively contrary  propose instead euclidean distance loss extend 3D loss  propose learnt data representation constitutes loss function behaves function offset error error  loss function define     non negative nonlinear limit curvature non linear  constant link smooth piecewise define linear nonlinear function input  3D euclidean distance predict truth similarly  directly supervise heatmap strongly supervise pixel wise gradient enhance training model improve performance impose strict regularization latent heatmap directly towards distribution specifically heatmaps resemble spherical gaussians minimize divergence generate heatmaps target gaussian distribution 2D orthographic projection  normalize truth 3D respective viewpoint distribution regularization define   jensen shannon divergence   denotes target variance target normal distribution finally loss compute network gradient define      hyper parameter coordinate heatmap distribution loss respectively diagram depicts various concept illustrate experimental evaluation conduct ass sect dataset accord pre processing described sect training validate model discus evaluation methodology metric sect sect implementation detail execution sect sect discus quantitative qualitative experimental insight respect performance model finally ablation evidence regard necessity impact contribution sect dataset data capture pre processing described sect sample activity male female couple data couple perform activity training basketball  scary movie flight safety announcement data perform remain validation jumping jack bending punch kick  split dataset ass model unseen structure unseen activity reliable conclusion respect performance training validation data consist sample training validation datasets sample activity involve methodology metric error physical dimension apply inverse translation transformation described sec metric ass 3D regression accuracy commonly per joint error MPJPE per marker error  applicable marker predict model fashion per joint marker error   constitute variation MPJPE  respectively error RMSE instead absolute error mae metric affected outlier   incorporate variance prediction bias average precision  percentage keypoints 3D  metric propose yang  error threshold beyond metric calculate fuse data direction orientation driven various marker mapped joint extra metric respect stability prediction capability simultaneous regression marker joint per joint angular error   angle truth predict joint orientation  denotes inner joint worth sake comparability joint regress assessment exclude toe comparison due lack public target specific task marker regression noisy optical marker data relevant identify adapt dataset offering valid comparison identify marker markerless former input normalize sparse detect marker latter spatio temporally align multi infrared image along camera intrinsic extrinsic parameter detail model marker adaptation graph model image estimation propose adapt task 3D regression online marker label  adapt simultaneous marker joint 3D coordinate regression marker dual marker depth ass markerless estimation spatio temporally align multi image rely concept learnable triangulation LT propose multi graph estimation approach  spatio temporally align multi image propose marker lightweight model jointly estimate 2D 3D cascade adaptive graph convolutional neural network adapt estimate 2D coordinate joint orthographic depth adaptive graph net gao convert 2D 3D coordinate modify input depth resolution instead image model scratch xavier   initialization adapt  input depth resolution instead initialize model xavier initialization furthermore adapt output network predict vector 3D target task extra variation approach consumes multi depth data similarly concept markerless respect LT LT alg algebraic triangulation learnable camera joint confidence LT vol constitutes volumetric triangulation approach dense geometric aggregation 2D heatmap prediction multiple viewpoint input model batch spatio temporally align image along correspond camera intrinsic parameter aim comparison LT DeMoCap LT model dataset initialize pre due domain difference datasets initial bound detection LT mask cnn 2D detector resnet backbone predict bound however truth bound avoid training detector pre  2D backbone pre coco dataset infrared dataset epoch adopt training configuration propose author infrared data model instead sparse data rendering training model scratch prediction obtain algebraic volumetric triangulation approach training official repository guideline   considers temporal aspect consecutive frame openpose candidate heatmaps connection confidence affinity retrieve fuse obtain feature sequential frame 4D graph construct per parse adjacent across various temporal mapping detect 3D node previous frame 2D detection LT model epoch   pre model official repository  implementation detail network epoch adam kingma optimizer initial rate apply frequent linear epoch batch heatmap standard deviation supervision  loss define parameter loss  model implement pytorch  conventional computer nvidia gtx graphic GB ram intel processor manual  comparison reproducibility code dataset publicly available  experimental validation training hyper parameter tune evaluation selection model variance inference accuracy various model generalization potential assessment various fcn network ass DeMoCap building stag concept upon various fcn architecture sec twofold validate stag architecture marker prediction perform independently fcn architecture predict heatmaps perform model comparison DeMoCap building upon cpm SH  variation fcn architecture variation ass stag marker concept   variation marker marker yield joint  simultaneously marker joint sequentially marker  joint  correspondingly image model regress supervise heatmaps marker absent focus task prediction joint 3D  marker similarly variation model concept however regress supervise joint marker heatmaps pas marker DeMoCap concept super stage predicts marker heatmaps sequentially   correspondingly outcome illustrate marker stag approach achieves performance model task estimation however marker precisely localize marker variation cooperative marker regression enables joint 3D rotation estimation computation load per stage network optimum marker approach marker marker joint heatmaps predict across stage network respect model although SH performs remarkably outperform  latter indication experimental retrieve validation MPJPE       DeMoCap cpm SH  variation marker marker quantitative analysis  marker refer DeMoCap sake brevity sect per joint per action quantitative depict MPJPE       metric markerless multi estimation model  LT effective ability estimate 3D multiple spatio temporally align relatively robust occlusion partial volumetric approach performs dataset accuracy algebraic yield reliable accurate prediction  LT across metric respect MPJPE   despite model datasets due difference DeMoCap multi built dense visual data DeMoCap predict marker sparse marker data input exclusively related 3D context redundancy various background cloth fabric aspect model dense visual input DeMoCap domain sensitive depth dense visual DeMoCap purely 3D data LT  fusion multiple partial 2D detection weaken localization 3D keypoints despite trial reduce erroneous 2D prediction learnable graph association technique 3D fusion error cannot totally eliminate erroneous estimate exceed camera occlude malicious prediction DeMoCap disappearance marker model failure marker detection depth camera highly multiple depth sensor capture performance model accurate prediction variance 3D input plot comparison  LT DeMoCap   metric threshold millimeter threshold showcasing effectiveness image MPJPE        LT  sake clarity marker data input colorization markerless marker respectively despite effort finetune  model performance relatively struggle accurately regress 3D coordinate sample unseen activity performance potentially explain regression fully layer fully graph layer network relatively training dataset contrary dataset pre model applicable depth input moreover 3D coordinate regression task challenge regress 3D coordinate comparison  regress 3D keypoints nevertheless worth dual  relatively model showcasing potential multi supervision concept comprehensive analysis respect performance illustrate  metric PCK 3D threshold DeMoCap outperforms  threshold  already  incapable comparable  LT DeMoCap finally LT model showcase precision  per joint beyond presentation evaluate performance per joint analysis DeMoCap outperforms joint analysis allows ass consistency model estimation various joint individually rationale analysis traditionally estimation difficulty localization joint gradually increase torso joint hip spine joint limb ankle wrist latter node articulate structure freely variance respect global local nevertheless significant target capture robustness consistency across joint estimate challenge applies however error torso joint   LT variance meaning DeMoCap regress equally balance accuracy across joint approach rapid movement action perform image blurriness vision model erroneous estimate overcome challenge DeMoCap explicitly perform regression phase initial noisy incomplete marker input refine recover phase estimation later stage refine marker data refinement marker model accurately perform stage estimate joint related marker without contextual binding initial blurry input obtain remarkably error wrist ankle joint totally freely perform punch kick action camera frame 3D euclidean distance error per joint millimeter MPJPE per action validation performance model across action sake clarity marker data input colorization markerless marker respectively per action discus model outcome per action analysis ass model performance across sequence action validation MPJPE action jumping jack bending punch kick  despite tune model validation characteristic unseen action relation training hence difficulty capture mostly objective challenge specific performance complexity occlusion data movement camera error  action demonstrates error validation action punch kick action punch kick camera without guidance constraint extremely challenge data due rapid style movement noisy sample due blurriness partial occlusion camera per action analysis specific action error visualize noisy raw truth predict marker project infrared per frame frame per fourth illustrate predict truth magenta ghost marker cleaning recovery marker depth sensor error correspondingly highlight blurriness issue model overcomes image qualitative analysis discus qualitative outcome illustrate project marker 3D coordinate infrared correlate actor actual performance sake visualization clarity depict raw noisy input truth predict marker data separately predict truth visualize facilitate visual comparison infrared image background highlight target address challenge model marker correction noisy input robust regression behaviour prediction easily raw marker input capture highly noisy due marker 3D localization sensor separately combination depth sensor error considerably 3D 3D marker regress marker initial input marker mocap marker observation cluster achieve automatically noisy raw 3D capture sensor rationale ghost marker erroneous detection ignore marker occlude non detect recover magenta image blurriness effectively handle eliminate joint coordinate regression error accurately localize label optical marker capture sensor highly noisy data due discrete inference frame marker swap traditional mocap resolve model directly instantaneous 3D regression label 3D marker without humanoid prior knowledge structure meaning prior information inference respect joint relative placement instead model predicts shot nevertheless significant highlight DeMoCap model specific marker configuration prior meaning marker placement mocap model erroneous prediction qualitative truth predict 3D model regress 3D comparable truth failure illustrate extremely challenge image qualitative 3D visualization illustrate batch sample illustrate truth data prediction failure grid ablation ablate contribution model showcase effectiveness necessity ablation conduct discus extensive ablation justify propose approach replace remove tune differently contribution approach per showcasing reader separately detail ablate newly introduce fully differentiable  module sect integral 3D regression module versus dual input supervision sect versus dual input supervision sect quantization bias sect resolution depth render input data augmentation sect data normalization sect intermediate heatmap aggregation sect stage heatmap prediction inference model marker data capture camera inference model marker data capture oppose camera summary ablation enumeration integral 3D regression versus  contribution introduction  fully differentiable module 3D regression comprise  layer softmax com layer difference spatial regression approach  coordinate regression ass model substitute  module integral regression propose integral regression module effective task error model MPJPE validation respectively inference increase noticeably render input model depth render 3D reflective marker oppose viewpoint conceptually advantage dimensional information sparsity allows generate numerous 2D input 3D sample multi input supervision yield robust inference ass conduct tweak render versus depth input render depth network input depict exp model showcase performance comparison propose dual approach across metric validate multi concept model accurate robust prediction versus depth input another increase render conduct exp ass model input favorable comparison propose dual model detail model performs similarly validation outperformance nevertheless across metric approximately absolute improvement across euclidean distance error metric    respectively reliability multiple input multi estimate conclusion threefold firstly despite sparsity marker ambiguity exist challenge complex locally dense marker subset potential marker occlusion multi render overcome secondly increase render reliability accuracy prediction improve validate respect contribution multi supervision finally increase render depth input linearly increase computational complexity performance model oppose depth rendering ideal effectiveness efficiency deployment comparable versus resolution render DeMoCap purely 3D 3D regression multiple 5D input mission 2D fully convolutional architecture remarkable effectiveness keypoint localization task encode 3D non quantize data quantize 2D grid loss information specifically render depth quantize coordinate totally accurate sub optimal supervision degrade model performance limit quantization error information loss render depth image pixel resolution linearly interpolate input exp ass model data directly render resolution thereby encode quantization error model performance validate consideration resolution render bias coordinate regression worth mention error extremely assume multi supervision handle bias sub pixel coordinate regression characteristic  heatmap coordinate decode module DeMoCap mocap data DeMoCap mocap data ass performance model various combination training validation versus data augmentation demonstrate contribution 3D rotational augmentation data sect model exclude exp sparse input privilege actually rotate render tremendously increase amount depth input training significant important difference comparison limitation pseudo rotational augmentation apply 2D visual data versus data normalization exp evaluate contribution volumetric translation normalization transform perform marker occupy volume normalize voxel grid sample normalization boost performance model across metric consideration transform variance respect structure model directly reconstruct normalize absolute 3D qualitative various frame illustrate scene locomotion  sequence sfu dataset  totally unseen structure activity prediction DeMoCap truth data dataset image versus heatmap aggregation approach instead supervise heatmaps originally propose architecture upon supervise aggregate heatmaps aggregation scheme model faster convergence slightly marker estimation exp comparison stage supervision  propose  respective sensor finally conduct model validation account marker observation sensor exp respectively instead sensor setup DeMoCap ass bias model training generalization capability sensitivity sensor decrease versus capture depth sensor accuracy relation sensor capture data nevertheless MPJPE  error  accuracy validation respectively versus capture depth sensor sensor assessment performance decrease however lack information conclusion DeMoCap reasonable dependency sensor capture marker mocap specialized camera mocap data DeMoCap dataset benchmark model training assess input marker data vicon truth configuration showcase behaviour model ideal marker data totally highly precise without  optical marker data capture depth sensor mocap processing DeMoCap DeMoCap vicon data  assess vicon noisy data consumer grade depth sensor RS  achieves significantly accuracy validation vicon achieve MPJPE   respectively  showcase performance noisy RS data exceed absolute distance error  performance DeMoCap assess viewpoint data dissimilarity evaluation comparison training model assess validation vicon DeMoCap demonstrates significantly performance vicon RS data latter model generalizes without bias systemic camera pinhole parameter model handle noisy data increase accuracy marker capture reliable inference sfu dataset evaluate performance model DeMoCap  public mocap dataset relatively marker configuration structure marker joint sfu capture database   challenge activity   footnote quantitative sample visually model showcase comparable illustrate numerically  DeMoCap task challenge worth highlight spatial offset exist structure various datasets insert constant error measurement sect sfu  mocap data DeMoCap mocap data ass performance model various combination training validation discussion summary observation pro con various capture relation approach beyond strength decade marker capture standard fidelity capture nevertheless despite sub millimeter accuracy marker marker globally limited setup software license maintenance knowledge DeMoCap computer vision enables equipment marker capture comparable mocap extent hardware data limitation DeMoCap pioneer marker capture allows shot regression sparse 3D performs recent LT  despite highly erroneous depth estimate sensor depth error distance camera average per joint error assess data DeMoCap generalizes camera sensor sect showcasing increase stability comparison potentially erroneous partial detection 2D detector model driven reject outlier detect marker stage marker inference estimation refine prior marker information DeMoCap focus exclusively information solves marker attach without interference background context dense depth data finally DeMoCap performs reduce assess sect despite existence systematic depth sensor training showcasing model marker configuration affected mostly quality marker marker capture weakness nonetheless DeMoCap weakness comparison traditional marker markerless dense visual data consumer grade sensor specialized mocap camera limited regard capture frequency depth acceptable accuracy contrary professional marker apply dense visual data applicable capture arena sport stadium DeMoCap particularly limited regard capture volume exist consumer grade depth infrared technology furthermore similarly data driven statistical model DeMoCap dataset capture specific marker configuration placement capture DeMoCap erroneous prediction appearance marker configuration skeleton structure training data capture setting contrarily traditional mocap apply variety entity data driven model lag regard flexibility standard marker mocap traditional mocap configuration marker label skeleton however cheaper due shorter effort completion without dataset creation marker placement marker prior operation however prior DeMoCap due data driven model DeMoCap shot inference marker 3D regression avoid possibility marker swap mocap marker temporal aspect extremely eliminate potential error driver prediction DeMoCap inference instantaneous without temporal aspect marker trajectory constitutes limitation DeMoCap comparison marker marker stability precision conclusion introduce DeMoCap lightweight data driven model marker capture spatio temporally align infrared depth acquire consumer grade device model noisy optical marker data capture multi accurately regress marker joint 3D coordinate stag smooth representation transition marker 3D underlie structural relation marker configuration placement translation invariant manner upon model overcomes bias relatively limited training data generalizes technically introduces fully convolutional network apply extremely sparse depth efficiently regress marker joint 3D coordinate estimation joint 2D localization regression objective within normalize 3D embed dimension indirectly introduction fully differentiable module 3D regression dataset model publicly available inter intra spatio temporally align infrared depth capture data marker multi stage fcn architecture  architecture DeMoCap concept stage predict  aggregate stage predict  aggregate prediction stage feature concatenate subsequent stage image focus future overcome aforementioned limitation approach limited regress marker capture due spatial regression limit regress coordinate per latent heatmap layer aim conduct research challenge task enable multi capture apply temporally continuous 3D data DeMoCap maintain internal memory sequential data processing instead inference shot without previous prediction discrete per frame inference allows skip issue technique marker swap however temporal information capture accuracy robustness hence explore potential technique introduce temporal feature development efficient effective model capture finally regress label marker data inverse kinematics solver explore joint transformation professional capture regression orientation data driven manner