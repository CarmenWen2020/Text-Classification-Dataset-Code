prediction aim forecast future historical recurrent neural network exist fail model observation tends complex sport action cooking activity introduce attention network explicitly leverage observation instead model frame wise attention via similarity propose extract attention capture similarity context historical sub sequence context attention compute joint aggregate relevant processing graph convolutional network allows effectively exploit predict future amass 3DPW validate benefit approach periodical non periodical action thanks attention model yield datasets code available http github com wei mao  access auckland library introduction prediction consists forecasting future previous predict highly beneficial task robot interaction generation computer graphic prediction aim forecast future truth sequence prediction ltd approach frame ltd yield error highlight respectively truth ltd image traditional hidden markov model gaussian dynamical model proven effective golf swing however typically outperform complex trend model sequential data constitutes consists recurrent neural network rnns however mid horizon rnns tend generate static struggle tackle exist rely generative adversarial network gans notoriously introduce additional encoder information unfortunately encoder treat entire equally model emphasis reflect context contrast introduce attention prediction approach effectively exploit historical information dynamically adapt focus previous context motivate observation tend periodical activity complex action across longer sport cooking activity therefore aim relevant historical information predict future attempt leverage attention prediction achieve frame wise manner observable frame historical sequence approach fails reflect direction affected completely instance activity actor along overcome therefore propose model attention visible sub sequence sub sequence periodical jogging tend across horizon however non periodical discussion cooking repetitiveness happens model explore attention individual joint capture repetitiveness effectiveness attention varies across activity sequence handle therefore introduce fusion model combine attention focus attention context related prediction encode temporal information naturally arises trend consists recurrent neural network rnns however argue rnns prediction suffer error accumulation discontinuity frame predict alternative convolution across temporal dependency approach encode however strongly convolutional filter remove dependency introduce drastically approach model temporal information prediction inspire nonrigid structure literature propose trajectory instead adopt discrete cosine transform dct encode temporal information another arises encode spatial dependency joint achieve exploit skeleton define relatively spatial filter former model dependency across limb symmetry dependency encode latter filter propose overcome issue exploit graph convolution however instead pre define sparse graph introduce approach graph connectivity strategy allows network capture joint dependency neither restrict kinematic arbitrarily define convolutional kernel altogether overall framework sub sequence trajectory discrete cosine transform dct exploit attention aggregate entire dct encode future estimate estimate combine input graph convolutional network gcn encode spatial dependency joint evidence amass 3DPW illustrate attention approach consistently outperforms prediction training unified model setting contrast previous ltd model training model setting achieve performance furthermore demonstrate approach effectively leverage repetitiveness longer sequence contribution summarize introduce attention model exploit instead static frame leverage historical information prediction attention allows unified model prediction approach effectively repetitiveness yield generalizes exist across datasets action article extends previous instead model attention attention individual joint evidence activity sequence benefit attention introduce fusion module combine multi attention mechanism achieve performance attention model propose related rnn prediction rnns proven highly successful sequence sequence prediction task widely employ prediction instance propose encoder recurrent decoder erd model incorporates non linear multi layer network encode decode recurrent layer avoid error accumulation curriculum adopt training introduce structural rnn model rely manually spatio temporal graph encode fix structure graph however restricts flexibility approach model spatial relationship limb improve estimation propose residual model predicts velocity instead furthermore zero velocity baseline constantly predict performance performance previous prediction rnn suffer discontinuity predict overcome propose adopt adversarial training generate smooth sequence treat prediction tensor inpainting exploit generative adversarial network prediction approach improves performance adversarial classifier notoriously complicates training challenge deploy datasets encode drawback rnns network alternative introduce fully network recent investigate strategy encode temporal historical information via convolution exploit kinematic encode spatial information however similarly fix structure reflect synchronization across potentially capture dependency built convolutional sequence sequence model processing dimensional matrix model extract prior conjunction recent input autoregressive network future prediction effective rnn framework manually convolutional highly influence temporal encode previous encode frequency dct gcn encode spatial temporal connection performance prediction however encode dct yield overly representation performance overcome drawback introduce attention approach prediction allows capture recurrence furthermore contrast encode depends manually define temporal convolution filter model dynamically adapts representation context prediction attention model prediction attention neural network commonly employ machine translation prediction remains largely unexplored constitutes exception incorporate attention module summarize recent rnn prediction network however frame wise attention ambiguous static information direction significantly overcome propose leverage attention evidence combine prediction network allows outperform prediction framework spirit approach concurrent leverage attention transformer prediction nevertheless attention module mainly serf model global spatial dependency joint trajectory contrast attention aim capture repetitiveness model temporal dependency addition attention module propose progressively predict joint trajectory global training data component however orthogonal attention module demonstrate outperforms attention module comparable model approach introduce approach prediction encode consist consecutive  parameter 3D coordinate angle joint goal predict  future introduce attention model allows future estimate aggregate temporal information combine estimate input combination gcn network spatial temporal dependency data discus detail attention model tend across goal discover sub sequence sub sequence propose achieve via attention model capture repetitiveness introduce framework model attention specifically entire limb individual joint framework allows attention attention attention joint attention      concatenates 3D coordinate rotation angle corresponds treat entire   skeleton joint joint whereas  extreme multiple joint overview attention pipeline skeleton predict purple query consecutive compute attention weigh dct coefficient correspond sub sequence sum concatenate dct coefficient sub sequence predict future predict future output predictor input predict future recursively illustrate dash image machine translation formalism attention model mapping query output output sum attention assign function correspond query mapping attention model query corresponds representation sub sequence treat within representation historical sub sequence correspond future representation attention model output define aggregation future representation partial similarity sub sequence historical sub sequence context aim compute attention sequence  sub sequence  consists consecutive sub sequence assume predictor introduce sect exploit frame predict future frame sub sequence  sub sequence  correspond furthermore define query sub sequence  output attention model consistent predictor trajectory dct temporal dimension dct coefficient     contains dct coefficient joint coordinate sequence truncate frequency avoid predict  predictor apply dct encode temporal information trajectory dct coefficient concatenate output attention model treat feature input graph convolutional layer layer depict framework aggregate information multiple node via adjacency matrix image depict query compute attention combine correspond query vector dimension function     model neural network express       compute attention    instead softmax function commonly attention mechanism simply normalize attention sum avoid gradient vanish softmax enforces sum attention restrict output   non negative relu avoid obtain negative attention compute output attention model weigh sum   output concatenation     initial estimate combine sub sequence prediction model described generate future generate longer future augment prediction update query sub sequence augment accordingly update entity prediction prediction model predict future reuse prediction model introduce specifically mention dct representation encode temporal information joint coordinate angle GCNs learnable adjacency matrix capture spatial dependency coordinate angle temporal encode sequence  express correspond  dct coefficient compute   denotes kronecker delta function   coefficient representation coordinate angle obtain via inverse discrete cosine transform   predict future  sub sequence  query attention model adopt pad strategy replicate  generate sequence dct coefficient sequence denote  aim predict dct coefficient future sequence  attention model output spatial encode capture spatial dependency joint coordinate angle regard fully graph node input graph convolutional layer matrix  dimensional feature vector node layer network input matrix concatenates graph convolutional layer output matrix  trainable adjacency matrix layer strength connectivity node  encodes trainable extract feature activation function  stack layer gcn predictor predictor learns residual dct coefficient pad sequence sequence apply  predict dct coefficient obtain coordinate angle prediction future fusion model simply concatenate output model dct coefficient pre fusion output model combine fusion model fed predictor fusion fusion occurs prediction image fusion model mention activity sequence benefit attention individual joint model introduce fusion model automatically combine attention model obtains attention context specifically partition skeleton individual joint correspond choice sect compute attention    respectively treat prior exploit prior depict consists simply concatenate dct coefficient pad sequence fed predictor involve training fusion model output normalize prior difference apply pre fusion fusion model fuse output model fed predictor fusion fusion model combine prediction predictor attention output verify fusion model yield performance therefore adopt approach training introduce loss function model 3D coordinate joint angle 3D joint coordinate prediction per joint error MPJPE propose training sample yield loss 3D coordinate  joint  correspond truth angle representation average distance predict joint angle truth loss sample express predict  angle  correspond truth network structure prediction framework consists module attention model predictor attention model architecture   specifically network consist 1D convolutional layer relu activation function kernel layer respectively obtain receptive frame dimension hidden feature query vector vector  predictor gcn residual structure previous residual contains graph convolutional layer additional initial layer dct coefficient feature layer decode feature dct residual detail predictor network structure learnable matrix layer learnable adjacency matrix depends dimension 3D coordinate thanks structure attention model overall network remains compact specifically around parameter 3D coordinate angle implementation detail supplementary fusion model gcn network structure predictor without overall residual connection previous evaluate amass evaluate 3DPW model amass demonstrate generalizability approach discus datasets evaluation metric baseline joint angle 3D coordinate datasets widely benchmark dataset prediction depicts actor perform action joint skeleton compute 3D coordinate joint apply kinematics standard skeleton remove global rotation translation constant angle 3D coordinate sample sequence frame per previous however instead random sub sequence per action variance report sub sequence per action nevertheless baseline code publicly available sub sequence action amass archive capture amass dataset recently publish dataset unifies mocap datasets cmu kit  SMPL parameterization obtain mesh SMPL vector joint rotation angle vector encompasses coefficient defines skeleton obtain 3D apply kinematics skeleton amass joint joint joint focus predict discard joint static joint joint sample frame rate sequence official  amass consist transition irrelevant action kick kick suitable evaluate prediction algorithm assume relevant forecast future therefore instead official split treat  min video sequence sequence consists actor perform action split remain amass training validation data 3DPW 3D dataset 3DPW consists challenge indoor outdoor action evaluate model amass 3DPW generalization approach mention sect model attention individual joint explanatory attention kinematic torso consists joint prediction 3D joint error millimeter ltd frame future frame predict training distinguish model instance ltd model frame predict future frame  report average error sub sequence sub seq average sub sequence per action approach achieves performance across action almost horizon action propose extension fusion improves model att evaluation metric baseline metric model output 3D report per joint error MPJPE millimeter commonly estimation predict angle standard evaluation protocol report euclidean distance euler angle representation baseline approach rnn sup  model  ltd constitutes concurrent  exploit attention transformer angular sup  obtain official training code report sub sequence sup  adapt code author 3D amass   directly respective ltd rely pre model release model amass release code sup    generate future frame ltd model refer ltd ltd ltd frame future frame predict respectively training ltd model frame input predict future frame prediction 3D joint action  action  action att prog  refer attention prediction progressive prediction component propose  attention module outperforms  margin prediction 3D joint average approach performs 3D error ltd predictor attention model prediction joint angle  report average error sub sequence sub seq error average sub sequence per action report correspond prediction joint angle prediction 3D joint upper joint angle  3DPW baseline report prediction model frame predict future frame future recursively apply prediction input model amass model frame predict future frame prediction 3D respectively outperform baseline average prediction yield improvement activity nevertheless approach remains competitive action consistently outperform ltd frame approach evidence benefit exploit attention moreover performance attention model denote att consistently improve fusion model prediction approach performs comparable concurrent  attention strategy fusion model orthogonal progressive joint prediction  improvement combine strategy attention module outperforms  margin qualitative comparison discussion prediction truth ltd ltd approach 3D truth skeleton prediction purple image visualization attention joint trajectory axis denotes frame index prediction frame axis attention prediction specifically model predict future frame recursively perform prediction generate frame attention attention vector predict correspond future frame illustration purpose per frame attention attention subsequence consist frame frame afterwards predict attention trajectory coordinate future closely resembles frame model correctly attends predict attention trajectory wrist coordinate discussion attention model prediction predict frame peak occurs model focus frame peak occurs image visualization attention joint coordinate trajectory smoking model frame model frame obtain replace frame constant image focus ltd baseline constitutes although ltd competitive prediction generate future yield average error contrast ltd ltd achieve performance perform ltd horizon approach unified model however yield performance prediction summarize attention model improves performance predictor prediction enables generate prediction confirm report prediction angle qualitative comparison prediction 3D sequence longer indicates frame frame training amass 3DPW prediction 3D amass 3DPW consistently outperforms baseline approach benefit attention model none 3DPW demonstrate approach generalizes datasets baseline visualisation attention visualize attention compute attention model sample joint correspond coordinate trajectory attention joint periodical non periodical discussion attention model relevant sub sequence encode nearly identical periodical action non periodical action longer model fix observation nonetheless exploit longer available evaluate model ability capture dependency manually sample sequence occurs model model frame frame frame although performance benefit model longer become obvious future performance boost attention predict joint trajectory highlight attention demonstrate model capture available improve prediction influence historical frame replace frame static remove perform prediction sequence attend frame yield trajectory closer truth attend frame importance attention attention complement discussion categorize attention relative global local attention refer local attention attention global attention joint attention visualization attention joint coordinate trajectory attention attention capture joint attention however attends relevant historical joint attention prediction image visualization attention joint coordinate trajectory attention photo prediction highlight attention generates attention joint treat attends historical reflect context image per action 3D error per joint 3D error joint joint index define dataset index eliminate joint fix hip joint 3D location joint 3D location model attention global effective local movement synchronize specifically joint compute attention separately effective attention sync non periodical action sometimes periodical specifically attention generate attention joint attention predict trajectory joint sequence joint joint synchronize attention correctly capture attend contrast joint attention generates attention joint attends relevant historical joint prediction rely purely local attention optimal local attention compute local movement attend sub optimal local joint multiple global attention disambiguate situation attention trajectory predict attention joint attention photo sequence historical individual joint joint attention wrongly attends negative direction occurs contrast leverage information attention historical reflect context quantitative ablation fuse attention sect emphasize multi attention fusion improves prediction performance attention consistently action improvement action instance attention sufficient capture periodical action improvement obtain multi attention fusion model indeed relatively contrast action fuse multi information yield significant improvement evidence due action repetitive involve joint understand error distribution joint 3D error joint separately prediction att fusion consistently improves performance joint joint improvement prediction 3D joint observation indicates standard deviation millimeter gaussian historical sequence comparison fusion strategy concat corresponds concatenate output attention model influence noisy model ability handle noisy model obtain observation corrupt specifically pretrained model gaussian joint coordinate frame 3D error grows linearly analyze influence jitter jitter corrupt historical gaussian model robust jitter smooth future predict truth instead perform frame frame prediction model generates temporal encode dct sequence encourages global smoothness ablation evaluate fusion model performance fusion strategy introduce sect investigate performance fuse attention model fusion strategy performance fusion strategy fusion performance 3D joint joint angle prediction ablation fusion evaluate influence fuse output attention model 3D joint representation obtain fuse attention model contrast joint angle representation fuse attention attention performs mainly due bias training joint angle representation joint attention performs others sequence training training bias training fusion model tends focus prediction joint attention model inferior performance unbiased ablation fusion strategy average 3D joint error upper joint angle error joint performance obtain fuse attention model joint angle fuse attention attention performs performance bias training attention model average angle error training besides demonstrates percentage attention model outperforms others sequence joint attention model outperforms others training sample consistent performance across horizon however attention model perform comparable 3D error image influence jitter jitter corrupt historical gaussian model smooth future predict GT image GCNs fully network finally evaluate importance GCNs fully network connectivity gcn instead pre define adjacency matrix kinematic demonstrate benefit GCNs correspond graph structure altogether ablation indicates importance aspect contribution dct model temporal information connectivity GCNs model spatial structure influence GCNs graph connectivity angle error sequence per action 3D error sequence per action GCNs pre define connectivity yield error connectivity reuse conclusion introduce attention prediction approach selectively exploit historical information accord similarity context sub sequence predictor equip attention model effectively historical furthermore attention joint combine attention performance approach achieves performance commonly prediction benchmark recently publish datasets moreover demonstrate network generalizes previously unseen datasets without training tune handle longer boost performance non periodical future investigate combination approach progressive prediction strategy