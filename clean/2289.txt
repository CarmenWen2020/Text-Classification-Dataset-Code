video video QA challenge modeler multiple model video necessitates building spatio temporal model dynamic visual channel multimodal structure associate information channel subtitle audio video QA layer complexity relevant content channel context linguistic query compose spatio temporal concept relation hidden data response query address requirement insight content selection relation construction jointly encapsulate conditional computational structure video structure compose hierarchically introduces reusable reusable neural dubbed conditional relation network CRN input  translate encode relation input generic CRN complex model building video QA stack rearrangement flexibility accommodate diverse input modality conditioning feature across visual linguistic domain realize insight introduce hierarchical conditional relation network HCRN video QA HCRN primarily aim exploit intrinsic visual content video accompany channel compositionality hierarchy relation HCRN apply video QA solely visual content video additional associate information channel movie subtitle rigorous evaluation consistent improvement benchmark datasets TGIF QA TVQA demonstrate capability CRN HCRN complex domain video QA knowledge HCRN attempt handle multimodal video QA access auckland library introduction video powerful demonstration cognitive capability task involves acquisition manipulation spatio temporal visual acoustic linguistic representation video compositional semantics linguistic cue potentially unconstrained video QA model capacity encode crucial multimodal video linguistic content permanence profile prolong action temporal relation hierarchical manner video QA visual textual representation ideally specific video QA frame relation frame relation counting action frame relation action transition HCRN ability model hierarchical conditional relation handle successfully baseline struggle image video QA typical model sufficient relevant cue visual content video textual subtitle baseline likely suffer linguistic bias stage played guitar model successfully manages linguistic information shot visual content image approach model video QA neural architecture specially data format modality perspective variant video QA emerge video QA relevant information visual content video snippet video QA video QA mixed visual textual data longer multi shot video sequence specificity craft architecture tend non optimal data modality video frame QA versus action proliferation heterogeneous network effective model video QA reusable homogeneous easy construct maintain comprehend realize video QA involves sub task relevant content channel context linguistic query compose spatio temporal concept relation hidden data response query sub task abstract conditional computational structure computes multi interaction query ability sub task approach compose hierarchical structure abstraction goal propose purpose reusable neural conditional relation network CRN encapsulates transforms array array relation contextual feature computes sparse relation input modulates encode specify context flexibility CRN encapsulate replicate layer hierarchical conditional relation network HCRN straightforward manner within scope HCRN network visual content textual subtitle sub network philosophy customize input modality whilst visual built stack CRN granularity textual compose CRN linguistic input stack visual contextualized refinement relational knowledge visual stage wise manner combine appearance feature clip activity linguistic context afterwards incorporates context information video linguistic feature textual CRN function manner textual HCRN homogeneous philosophy network  resnet film hierarchy CRNs input modality visual CRNs encode relation frame appearance clip integrate clip context output stage CRNs integrate linguistic context stage CRNs capture relation clip encoding integrate video context stage CRN integrates video encode linguistic feature context textual due abstraction diversity nuance expression visual counterpart CRN encode relation  dialogue extract textual subtitle leverage technique sequential model lstm  schmidhuber bert understand sequential relation CRNs stack hierarchically model naturally model hierarchical structure video relational likewise appropriate context introduce stage model handle multimodal fusion multi video hierarchy enable encode relation frame demonstrate capability HCRN video QA datasets video hierarchical architecture layer CRN achieves favorable accuracy across video QA task notably performs consistently involve appearance transition temporal relation action repetition demonstrate model analyze combine information channel furthermore HCRN longer video simply addition extra layer demonstrate representative baseline visual interaction handle model model demonstrate impact building purpose neural native multimodality interaction improve robustness generalization capacity video QA model advance preliminary aspect devise network architecture leverage philosophy HCRN handle video QA demonstrate flexibility generic applicability propose CRN various input modality comprehensive theoretical analysis complexity CRN computational HCRN architecture conduct rigorous ablation fully examine capability propose network architecture video QA thoroughly assure consistency behavior CRN upon setting input modality simplify sample procedure algorithm reduce significantly organize review related detail contribution CRN  video QA video video subtitle complexity analysis describes experimental suite discussion concludes related propose HCRN model advance development video QA address challenge efficiently video amalgam complement factor appearance relation effectively allows interaction visual feature linguistic query allows integration input modality video QA unique building video QA extension image QA gathering attention recent release video QA datasets TGIF QA  datasets accompany textual modality TVQA   video QA treat video QA propose deviate handle challenge generic video QA stack rearrangement switch unique model upon availability input modality spatio temporal video representation traditionally variation recurrent network rnns video QA recurrent encoder decoder bidirectional lstm stag lstm increase memorize ability external memory network technique useful video longer complex structure movie TV program extra accompany channel subtitle memory network multimodal feature later retrieval memory augment rnns compress video heterogeneous dual appearance feature rnns appearance model separately 3D 2D 3D hybrid convolutional operator intrinsically integrates spatio temporal visual information video QA multiscale temporal structure model convolutional filter combine pre extract frame feature non local operator within approach trn network demonstrates role temporal frame relation another important visual feature video video QA relation  processing combine modality fusion HCRN model emerges trend channel video information namely appearance relation iteratively interact complement hierarchical multi framework earlier attempt generic multimodal fusion visual bilinear operator apply directly attention approach treat input tensor equally costly joint multiplicative operation HCRN conditioning factor refine information hence efficient flexible adapt operator conditioning temporal hierarchy explore video analysis  recently recurrent network graph network however hierarchical interaction multi modality linguistic cue video QA linguistic query visual feature interaction video QA traditionally visual information retrieval task representation independently transform refer video retrieval convenient heterogeneous memory slot information retrieval attention modality interactive combination development along direction attribute attention hierarchical attention multi attention multi progressive attention memory combine attention attention interact iteratively video feature via episodic memory switch mechanism multi video QA approach refine attention unlike technique HCRN model conditioning video feature linguistic clue context factor stage multi refinement allows representation linguistic cue involve earlier deeper video presentation construction available neural building beyond video QA domain CRN  uniformity neural architecture purpose neural building  residual resnet recurrent rnn conditional linear layer film matrix matrix neural matrix net CRN departs significantly assume array array conditional relational reuse network purpose vision processing HCRN perfect video visual content video snippet video movie QA model visual cue textual cue subtitle due challenge video QA diversity model building approach video QA mainly effort handle visual textual technique lstm advance processing bert knowledge HCRN model video QA model building generic neural overall multimodal video QA architecture handle visual textual modality parallel decoder feature prediction image goal video QA deduce video optionally additional information channel subtitle response pre define candidate multi choice formally video QA formulate  model parameter function within scope address setting video QA video QA visual content video shot singularly suffice video QA essential information  visual content multi shot video sequence conversational content accompany textual subtitle HCRN endeavor homogeneous neural architecture adapt overall workflow depict video visual textual HCRN  relevant information visual textual eventually combine decoder prediction fusion multimodal integration video frame available visual solely active input decoder ambition processing hierarchical network simply stack core processing previous approach literature HCRN operates feature embeddings multiple input modality powerful feature representation extract visual recognition model pre datasets resnet resnext pre embeddings glove bert subsection core sec hierarchical tailor modality sec decoder sec theoretical analysis computational complexity model sec notation CRN operation conditional relation network introduce computation conditional relation network CRN input array conditioning feature global context assume vector tensor  image video frame CRN generates output array dimension relation input feature global context global context specific modulator formation relation video QA CRN input array compose feature frame clip textual feature global context profile hierarchical conditional relation network input array model tuple relation sub sample subset sub network output context via sub network finally aggregate obtain vector tuple conditional relation tuple output dimensional output array image input CRN considers subset  contains subset randomly sample sample frequency collection CRN member relational sub network infer joint representation tuple relation video due temporal coherence amount mutual information therefore reasonable subsampled combination instead combination inspire however sample subset directly randomly subset pool subset reduce computational complexity CRN cheaper sample building combination subset analysis complexity CRN later sec regard relational model member subset function relational model relation across refine conditioning function conditioning feature finally tuple relation summarize aggregate function operation across subset ùëòmax regard choice ùëòmax ùëòmax later output array array detailed operation CRN formally pseudo code alg visually summarizes notation across presentation network implementation aggregation function implement aggregation sub network random representation choice implementation function average pool concatenation operator average pool conditioning function conditioning sub network implement depends relationship input conditioning feature channel neural operation implement function additive feature concatenation mlp model non linear relationship multiple input modality elu denote tensor concatenation operation elu non linear activation function introduce sufficient additively complementary multiplicative complex relationship input conditioning feature sophisticated operation warrant implies selection criterion modulate relationship multiplicative relation conditioning function elu denotes hadamard sequential aforementioned properly sub network driven input context video QA later CRN temporal relationship additionally integrate sequential model capability BiLSTM network along conditioning sub network formally define BiLSTM maxpool dual conditioning later CRN video QA concurrent signal conditioning feature simply extend elu elu respectively hierarchical conditional relation network multimodal video QA CRN network architecture variety video QA setting variation specifically video QA setting network adapts exploit inherent characteristic video sequence namely temporal relation linguistic conversation hierarchy video structure linguistic propose network architecture hierarchical conditional relation network HCRN HCRN stack reusable core partly inspire cnn network architecture  resnet video QA HCRN multi differentiable neural network handle visual content handle textual dialogue subtitle network modular network plug role adaptively presence input modality visual CRNs stack hierarchy embed video input granularity frame clip entire video granularity video feature embed respective wise feature universal linguistic cue image preprocessing video QA define HCRN input visual textual computes preprocessing raw video appropriate input HCRN visual representation video frame clip  video clip source information frame wise appearance feature vector feature vector clip appearance feature vital video understand visual saliency entity video usually clip primary video artifact capture attention hence feature couple appearance feature video video understand literature contrary video movie TV program concern specific movie plot film grammar frame wise appearance feature video QA pool output resnet feature derive resnext subsequently linear feature transformation apply project  standard dimension feature obtain respectively linguistic representation linguistic built choice video subtitle explore option representation BiLSTM bert sequential embed BiLSTM linguistic cue choice subtitle embed vector dimension pre glove embeddings choice pas context independent embed vector BiLSTM output hidden backward lstm finally concatenate overall query representation choice available multi choice accompany subtitle video QA instead treat passage prior dissect subtitle passage fix overlap sibling identical varies video another overall subtitle passage similarly processing pre embeddings BiLSTM hidden BiLSTM textual BiLSTM representation textual described sec contextual embed bert alternative option linguistic representation utilize pre bert network extract contextual embeddings instead encode independently glove bert embeds context surround attention mechanism video QA tokenize choice multi choice subsequently token pre bert network average embeddings unified representation applies generate representation choice video QA choice stack subtitle tokenize embed bert contextual hidden matrix maximum token input hidden dimension bert tensor split correspond embed vector subtitle choice   bert eventually suppress contextual token representation choice respective representation pool  subtitle textual obtain slide overlap visual effective model video QA distill visual content context filter usually portion data relevant inspiration hierarchy video structure boil video QA video representation video encode progressively granularity clip sequence video frame entire video sequence clip crucial linguistic cue structure video clip video illustrate hierarchy stack CRN feature linguistic cue intuitively feature serf dynamic context temporal relation frame clip clip video saliency indicator relation worth attention apply relation complementary selective multiplicative relation relation conditioning feature concatenation operator mlp suffices linguistic cue selective relation equally relevant utilize multiplicative feature fusion CRN representation textual passage textual modulate pre selection module serf input conditioning feature CRN model relationship image network architecture input array clip consists frame wise appearance feature vector video output clip conditioning feature clip CRNs correspond clip feature vector lstm video feature implementation option progressively incorporate multiple modality input hierarchical manner contrast typical approach treat appearance feature feature network deeper hierarchy handle video longer frame equivalent dozen clip option reduce computational CRN handle subset ùëòmax input array limit maximum subset ùëòmax extend visual network deeper hierarchy former option choice sparse sample potential lose critical relation information specific subset latter densely sample subset relation model specifically clip hyper clip hyper clip clip hyper clip visual becomes hierarchical network architecture sec deeper sec accuracy compute output visual compute average visual feature driven representation assume output CRN video array  stack output tensor vectorize output tensor obtain output  average information  elu  softmax   denotes concatenation operation hadamard multi choice couple choice becomes   textual HCRN architecture readily applicable accompany textual subtitle fashion visual HCRN textual consists hierarchy structure textual passage input preprocessed subtitle choice sec subtitle overall representation sequence encode textual   meanwhile encode vector relevant pre selection unlike video frame subtitle contains irregularly conversation movie furthermore relevant visual feature abundant throughout video portion subtitle relevant query reflective assure relevance antecedent CRN modulate representation passage choice pre selection operator described adapt architecture visual video CRNs employ CRNs unnecessary feature relevant medium image modulate representation  similarly video subtitle modulate representation  built CRN CRN operates passage model relationship modulate input CRN conditioning feature CRN max pool vector modulate representation subtitle passage textual temporal max pool operator apply output CRN obtain vector adaptation implementation video QA recall video QA refers QA shot video without accompany textual data employ standard visual described sec distill video joint representation representation decoder sec generate output video QA video QA video QA involves visual information video frame textual content subtitle snippet local saliency critical role discover semantic concept associate movie important  semantics interleave data modality difference video duration hence appropriate treatment although video hierarchical structure distinctive semantic compositionality employ visual textual described sec sec adaptation suitability data format structure simply joint representation prediction ideally video QA model interaction visual content textual content subtitle  visual textual described involve integration representation visual representation textual representation subtitle opt interaction visual content textual content subtitle pairwise joint semantic representation visual proven useful video QA closely related task however assumes existence multimodal sequence data highly semantically compatible video sequence textual description video video sequence positive negative choice visual content video visual content textual content subtitle video movie although visual content textual content complement extent greatly scenario movie scene chat visual content information conversation hardly contains information topic conversation combine visual information textual information stage potential information distortion information retrieval addition treat visual textual separation easy justify benefit CRN model relational information modality hence easy ass generic CRN visual HCRN architecture video QA CRN handle subset sub sample frame clip clip video another CRN dependency clip information CRN output CRN representation conditioning feature standard architecture introduce sec CRN feature adaptation accommodate relevant overall semantic clip video decoder previous adopt decoder task QA treat multi classification employ classifier input combination retrieve information visual retrieve information textual representation computes probability elu  elu  softmax multi choice choice available iteratively treat choice query exactly manner handle therefore choice representation conditioning feature along representation regard replace elu      output visual respect query choice whereas  output textual counterpart video QA simply retrieve information textual popular hinge loss pairwise comparison max incorrect network regard video QA entropy training loss comparison prior repetition task linear regression function input function integer loss task error mse complexity analysis theoretical analysis CRN HCRN layer computation justification hierarchy CRN clarity recall notation introduce CRN ùëòmax maximum subset tuple input array ùëòmax subset ùëòmax randomly sample input sub network relation model conditioning aggregate respectively implementation chosen function nonlinear transformation fuse modality input CRN matrix embed operation involve input wise linear assume function CRN operation alg linear complexity aggregation function max sum relation ùëòmax sample frequency inference CRN  ùëòmax  ùëòmax    quadratic input ùëòmax quadratic due feature transformation operation ùëòmax dominate complexity however function involves matrix operation usually output array  output input HCRN model adhere complexity analysis visual increase linearly complexity video overall complexity HCRN depends choice CRN specific arrangement CRN clarity ùëòmax video organize clip  HCRN architecture HCRN clip video stack CRN layer conditioning linguistic conditioning clip CRNs  conditioning  conditioning  estimator roughly   output array clip CRN becomes input video CRNs CRNs video therefore   respectively   identity  therefore   HCRN analyze architecture HCRN generalizes HCRN clip organize sub video clip  CRNs clip remain  compute sub video CRN input array apply logic sub video CRNs roughly  approximately   identity   stack sub video CRNs output array input array video CRNs video CRNs roughly  approximately   identity      deeper model video recall HCRN   HCRN    linear due function quadratic due function architecture function   function increase  assume max  clip linear approximate    clip fix function quadratically video whereas increase function linearly suggests deeper hierarchy actually video sec empirical validation datasets evaluate effectiveness propose CRN HCRN architecture series video QA datasets datasets benchmark video QA namely TGIF QA MSVD QA MSRVTT QA datasets video evaluate HCRN video QA datasets publicly available TVQA detail benchmark TGIF QA currently prominent dataset video QA QA animate  dataset task address unique video spatio temporal ability repetition retrieve occurrence action action multi choice task identify action transition multi choice task regard temporal task frame QA akin image QA video frame MSVD QA dataset annotate clip training whilst validation respectively MSRVTT QA dataset contains video MSVD QA split validation proportion respectively datasets video MSRVTT QA complex scene longer equivalent frame per video TVQA video QA datasets annotate TV bang theory met grey anatomy castle associate choice clip sec validation respectively dataset timestamps limit video portion correspond regard evaluation metric mainly accuracy exclude repetition TGIF QA dataset error mse apply implementation detail feature extraction video QA datasets video preprocessed clip fix frame detail equally anchor frame clip define sequence consecutive video frame pre compute anchor frame clip frame index exceed boundary frame frame video multiple clip clip extract feature clip pre model resnext footnote regard appearance feature pool output resnet feature feature representation frame completely ignore 2D structure spatial information video frame likely beneficial particularly interested appearance frame QA task TGIF QA dataset aware deliberately opt extract feature focus significance temporal relation hierarchy video data video datasets video QA category MSRVTT QA dataset hence intentionally video clip frame partially overlap frame clip avoid temporal discontinuity longer video MSRVTT QA additionally clip frame primarily aim evaluate model ability handle sequence TVQA dataset strategy video video clip however TVQA video longer fps adapt clip contains frame empirical pool output resnet feature feature representation frame subtitle maximum subtitle simply longer zero padding shorter subtitle overlap comparison TGIF QA dataset mse others accuracy standard deviation network training HCRN variation implement python pytorch setting visual textual model adam optimizer batch rate decay epoch counting task TGIF QA dataset epoch others terminate epoch report epoch validation accuracy amount training data hierarchy depth around training nvidia tesla gpu pytorch implementation model publicly available footnote representation model bert pre model hug footnote tune bert model training rate performance comparison MSVD QA MSRVTT QA dataset mem    image quantitative propose model  aforementioned datasets default pre glove embed embed BiLSTM sequential model contextual embeddings pre bert network explicitly specify bert detailed video QA video QA video QA TGIF QA recent  task feature extract optical 3D cnns variant summarize TGIF QA MSVD QA MSRVTT QA previous report model consistently outperforms competitive SOTA model task across datasets improvement particularly noticeable temporal involve action transition TGIF QA confirm significance temporal relation addition TGIF QA dataset random confirm robustness CRN randomness input subset selection analysis relation affect model performance later ablation regard recent advance representation model bert across task temporal action transition task TGIF QA dataset specifically performs poorly action task action task training sample QA task dataset transition QA frame QA QA QA addition task frame QA rely fix predefined template vocabulary frame QA contains diverse wider thanks unique token frame QA task token token token action transition task respectively data volume richer vocabulary explain frame QA task benefit tune bert contrary task affect regardless embed training vocabulary later ablation sec HCRN performance task rely representation analysis align exist  local model BiLSTM tune bert corpus across nlp task empirically tune layer bert network HCRN bert  tune layer favorable performance tune layer HCRN bert  tune layer bert embeddings fix HCRN training HCRN bert  tune model choice input modality comparison correspond performance TGIF QA dataset MSVD QA MSRVTT QA datasets highly challenge benchmark machine TGIF QA thanks model HCRN outperforms exist datasets achieve accuracy improvement MSVD QA MSRVTT QA respectively suggests model handle datasets exist tune contextual embeddings bert datasets contextual embeddings benefit MSVD QA MSRVTT QA achieve accuracy respectively consistent frame QA task TGIF QA dataset tune layer bert network simply due empirical comparison baseline TVQA dataset without timestamp annotation limit timestamp annotation bert indicates tune contextual embeddings pre bert network representation stage proposal feature pretrained faster cnn model rely frame wise cnn feature finally justification competitive performance HCRN exist rival model feature whilst straightforward internal model evident effective video model necessitates handle temporal relation hierarchy hypothesis detailed sec temporal relation shallow hierarchy sec hierarchy video QA TVQA baseline dataset relatively due challenge video QA attempt benchmarking comparison propose baseline validation report publication timestamp information subtitle explicitly visual feature subtitle feature feature respectively evaluate setting simplest baseline feature predict reveal model rely linguistic bias pre selection baseline subtitle feature prediction subtitle feature simply obtain concatenate output hidden backward lstm pas classifier sec pre selection baseline significance pre selection textual feature selective output subtitle explain fed classifier prediction baseline simply apply average pool smash visual feature entire video vector combine feature prediction pre selection combine baseline pre selection subtitle feature extract pre selection video feature smash classifier HCRN evaluate textual alone propose network architecture described HCRN evaluate visual counterpart alone HCRN propose architecture presence modality bert contextual embeddings significantly improves performance glove embeddings BiLSTM counterpart consistent report although model achieves competitive performance timestamps significantly outperform absolute challenge access timestamp indicator clearly approach promising video QA although HCRN achieves competitive performance stage without temporal supervision comparison HCRN frame stage latter external information proposal feature recent feature generally improvement VQA model frame external annotate data model bert contextual embed pre computes relation HCRN additional benefit model relation passage however benefit clearly demonstrate glove embed couple BiLSTM exp exp exp exp deeper understand behavior HCRN concentrate analysis comparison glove lstm ablation TGIF QA dataset mse others accuracy explicitly specify  relation sample resolution clearly hidden BiLSTM subtitle feature directly classification limited exp exp explain lstm fails handle subtitle meantime pre selection critical role relevant information subtitle boost performance subtitle timestamps exp HCRN improves approximately without timestamp annotation timestamp annotation baseline glove embeddings BiLSTM pre selection textual visual HCRN gain around baseline average visual feature improvement leverage visual textual exp exp setting timestamp annotation without timestamp annotation context model directional attention  significantly contributes performance whereas model vanilla BiLSTM sequence model therefore comparison unfair instead mainly variant  contribution CRN HCRN network equivalent baseline pre selection ablation insight role HCRN component conduct extensive ablation TGIF QA TVQA dataset configuration report video QA video QA video QA overall sample hurt HCRN performance effective complexity ablate component CRN degrade performance temporal task action transition action counting detailed relation  resolution without relation  performance suffers specifically action whereas counting tends action relation context happens something critical counting relation task benefit increase sample resolution relevant frame benefit temporal relation aggregate sub network CRN however relation account  HCRN robust sample resolution depends critically maximum relation  relative independence due visual redundancy frame resampling capture almost information relation performance significantly action transition task slightly counting frame QA confirm relation temporal frame QA task frame incorporate temporal information confuse model similarly model relation fix   performance suffers combine relation relation efficient hierarchy simpler model CRN layer CRN video frame CRN video input array consists frame clip video feature maintain clip CRNs pool clip CRNs output pool video pool operation simplistic relational operation across clip confirm hierarchy performance temporal task conditioning evaluate setting remove CRN feature clip HCRN remove CRN feature video HCRN remove feature HCRN prior critical detect action hence compute action particularly significant counting task task maintain global temporal context entire task usually sufficient action task wherein action repeatedly perform entire video context contributes surprisingly positive role frame appearance information ablation TVQA dataset subtitle visual feature respectively mul denotes multiplicative relation conditioning sub network sec linguistic conditioning multiplicative relation linguistic cue crucial context relevant visual artifact ablation clip remove CRN representation clip video remove CRN representation video linguistic exclude CRN conditioning linguistic cue linguistic cue decoder likewise multiplicative relation selection mechanism mul CRNs exclude multiplicative relation CRN mul relation leverage multiplicative relation CRN conditioning important context encode video conditioning feature multiplicative relation performance gain task frame QA possibly selectively passing relevant information inference chain subset sample conduct model  sample pre compute superset refers CRN sample trick sample pre compute collection subset directly sample contrast refers sample described alg empirical directly sample subset input degrade performance HCRN video QA choice input reduce complexity CRN video QA focus option conditioning sub network sec reflect flexibility model input modality option mul lstm textual conditioning sub network multiplicative relation tuples conditioning feature couple BiLSTM formulate mul lstm remove BiLSTM network mul lstm evaluate sequential model textual mul lstm multiplicative relation mul lstm replace concatenation conditioning feature tuples mul lstm remove BiLSTM network mul lstm evaluate selective relation sequential model mul lstm visual consideration multiplicative conditioning sub network instead concatenation operation additionally BiLSTM network sequential model textual visual content textual content temporal sequence mul lstm mul lstm without BiLSTM network mul lstm conditioning sub network simply tensor concatenation operation multiplicative mul lstm mul lstm mul lstm without BiLSTM network sequential model mul lstm mul prediction combine option network mul lstm textual mul lstm visual comparison empirically concatenation insufficient combine conditioning feature output relation network dataset meantime multiplicative relation conditioning feature relation greatly improves model performance visual consistency empirical video QA shot video QA relation visual content query multiplicative selection additive sequential model BiLSTM favorable textual visual sequential aligns analysis sec deeper hierarchy MSRVTT QA dataset reduce factor hierarchy deepen model hierarchy extend TGIF QA dataset HCRN advantage hierarchical relation modeling handle combination frame relation frame relation however HCRN struggle handle grain detection recognition image scalability HCRN video MSRVTT QA dataset organize clip longer datasets setting hierarchy clip vid model illustrate clip CRNs video CRN hierarchy clip sub  vid clip hierarchy clip sub video consecutive clip hierarchy model parameter approx report unlike exist usually struggle handle video scalable offering deeper hierarchy analyze theoretically sec theory suggests deeper hierarchy reduce training inference HCRN video validate achieve reduction training inference HCRN counterpart whilst maintain competitive performance discussion HCRN neural architecture multimodal video QA pursue model construction reusable uniform building temporal attention approach effort HCRN concentrate model relation hierarchy input modality video QA scope visual content subtitle applicable visual text structure relation information hierarchy difference methodology choice exist distinctive benefit scenario empirically proven within scope audio channel fusion modality issue future investigation CRN generic envision HCRN audio textual sec regard fusion input CRN generic tensor combine mixture input modality hierarchical alternatively CRN handle input modality combine hierarchical audio subtitle visual content partly synchronize model modality interaction stage benefit although HCRN capability model frame relation frame relation analysis HCRN behavior TGIF QA dataset reveals struggle grain detection recognition suggests promising direction future orient representation video native CRN thanks generality CRN relational model relation relation model research towards direction improve interpretability model reflect visual CRN augment attention mechanism selection ability related task frame QA TGIF QA dataset improve conclusion introduce purpose neural conditional relational network CRNs construct hierarchical network multimodal video QA CRNs building CRN relational transformer encapsulates array  array relation contextual feature relation input encode modulate conditioning feature allows flexible construction sophisticated structure stack hierarchy iterative suitable QA multimodal structure domain video HCRN evaluate multiple video QA datasets video QA mainly activity video TGIF QA MSVD QA MSRVTT QA video QA visual cue information channel movie subtitle TVQA dataset HCRN demonstrate competitive capability setting examination CRN video QA highlight significance generic neural native multimodal interaction compositional complex visual