sparse matrix estimation consists estimate distribution matrix sparsely instance matrix entry independent random variable capture array instance matrix completion context recommendation graphon estimation community detection mixed membership stochastic model inspire classical collaborative filter recommendation propose novel iterative collaborative  algorithm matrix estimation generic error mse estimator converges rate random entry entry uniformly sample rank entry bound maximum error across entry converges probability entry sample complexity generality introduction propose analyze iterative similarity collaborative filter algorithm sparse matrix completion  entry prototype noisy observation social network interaction signal underlie connection predict probability user recommend platform linkedin recommendation movie rating user predict probability distribution rating specific movie user classical collaborative filter approach compute similarity user commonly rat movie social network similarity user compute particularly interested sparse user user commonly rat movie insufficient data compute traditional similarity metric overcome limitation propose novel algorithm computes similarity iteratively incorporate information within radius neighborhood whereas traditional collaborative filter learns preference user rating user rating commonly rat movie algorithm learns user rating conference neural information processing beach CA usa user indirect data social network intuition translates compute similarity user boundary radius neighborhood connection network actual implementation algorithm benefit modification practical approach practical indeed implement corporate style algorithm algorithm accelerate datasets parallel implementation via approximate data structure however goal concept algorithm mathematical foundation analysis theoretical achieves consistency guaranteed convergence sparse datasets reasonably latent variable model bound entry mathematically formulate matrix estimation sparse subset entry random matrix matrix estimate probability distribution yij suppose yij categorical accord unknown distribution task estimate distribution yij reduce task estimate expectation binary data matrix yij yij matrix asymmetric transform equivalent symmetric model define data matrix therefore remainder assume symmetric matrix binary argue apply broadly categorical asymmetric matrix assume data generate latent variable model latent variable sample independently distribution yij yij fij latent function goal estimate matrix worth remark latent variable model canonical representation exchangeable array   novel algorithm estimate fij sparsely sample dataset yij generate assume entry independently probability latent function regard integral operator finite spectrum rank error mse estimate converges zero rate sparsity observation addition probability maximum error converges zero rate sparsity analysis applies generic yij bound inspiration estimate cluster stochastic model compute distance local neighborhood around vertex improve upon analysis mse bound latent variable model finite spectrum generative model mixed membership stochastic model stochastic model non overlap community rank increase spectral analysis handle bound model sparser regime related matrix estimation introduce specific literature matrix completion popularize context recommendation graphon estimation arise asymptotic theory graph community detection stochastic model generalization mixed membership stochastic model representative mention discus sample complexity respect model complexity usually rank polynomial algorithm error convergence recovery noiseless convergence probability noisy sample complexity respect matrix estimation bound entry model rank model extra factor impose additional requirement model matrix similarly sample complexity probability max error convergence rank bound entry assume constant noiseless sample complexity related literature grouped accord matrix completion matrix completion stochastic model mixed membership stochastic model graphon estimation sample complexity data matrix guarantee noiseless rank mse max iid gaussian rank mse iid gaussian rank mse max iid gaussian rank mse  bound rank mse iid bound lipschitz mse max noiseless rank recovery max noiseless rank recovery noiseless rank recovery max binary entry rank mse max binary entry rank mse binary entry partial recovery binary entry sbm recovery binary entry rank mse polylog binary entry rank whp error binary entry rank detection binary entry monotone sum mse binary entry piecewise lipschitz mse binary entry monotone sum mse  bound rank lipschitz mse  bound rank lipschitz whp error dependence worth bound sample complexity matrix completion additive model yij yij   zero sample consistent estimator mse convergence sample recovery conjecture computational bound mixed membership stochastic model detection weaker mse recently partial computational bound algorithm rely fitting polynomial data bound apply optimal dependence mse convergence probability recovery brief overview prior report context matrix completion progress rank assumption theoretically spectral decomposition minimize loss function respect spectral constraint closely related prof similarity collaborative filter style algorithm consistent estimator matrix completion generic model latent function lipschitz rank however sample algorithmic generalization handle sparse sample regime generic model matrix completion additive model extend observation binary quantize  estimator handle bound although factor sample complexity remove extra factor bound significant amount literature estimation data matrix binary matrix completion stochastic model sbm parameter estimation graphon estimation latter within context community detection network analysis binary data matrix alternatively interpret adjacency matrix graph symmetric definition sbm vertex associate community probability function community endpoint estimate parameter matrix becomes instance matrix estimation sbm matrix rank due structure precise threshold cluster detection random estimation establish algorithmically technically insight sequence extend analysis broader generative model iterative algorithm improve technical precise mse bound mixed membership stochastic model  allows vertex associate vector membership community probability function community membership vector endpoint matrix rank recent algorithm weak detection  sample complexity community membership vector sparse evenly partial conjecture computational bound gap information theoretic bound gap simpler context stochastic model propose spectral cluster infer label distribution network sample generalize stochastic model function finite spectrum decomposition rank consistent estimator sparse data regime sample graphon estimation extends sbm  generic latent variable model probability measurable function latent variable associate endpoint  define limit sequence dense graph recent extend theory sparse graph graphon estimation estimate function instance graph generate graphon associate minimax optimal rate graphon estimation however majority propose estimator computable polynomial optimize exponentially maximum likelihood polynomial sort function monotonic knowledge exist positive sparse graphon estimation monotonicity assumption rank constraint assume sbm matrix completion attention similarity bypass rank constraint rely instead smoothness latent function lipschitz hinge upon compute similarity commonly entry similarity literature collaborative filter successfully employ across application netflix amazon youtube due simplicity scalability however theoretical relatively sparse recent practical across variety application due ability capture local structure limitation approach dense dataset sufficient entry compute similarity metric overlap entry overcomes limitation intuitive directly overlap entry longer data associate expand associate datapoints sufficient overlap although concerned introduce bias variance due sparse sample analysis estimate converge vertex radius neighborhood introduce connection belief propagation non backtracking operator non backtracking operator introduce overcome issue sparsity sparse graph vertex dominate spectrum informative component spectrum hidden vertex non backtracking operator avoids immediately return previously vertex manner belief propagation spectrum behave adjust vertex graph algorithm neighborhood define vertex enforce vertex along unique important analysis guarantee distribution vertex boundary subsequent depth neighborhood unbiased sample vertex freshly model graph matrix notation interchangeable manner vertex index yuv denote random realization denote yuv otherwise unknown vertex associate latent variable sample yuv  bound random variable random variable yuv independent  yuv symmetric lipschitz function function regard integral operator finite spectrum rank  orthonormal integrable basis function assume exists unordered index entry independently probability   yuv  data undirected graph vertex  goal estimate matrix  denote diagonal matrix diagonal entry eigenvalue sort denote matrix random matrix sample guaranteed orthonormal matrix orthonormal function definition  distinct eigenvalue denote matrix assumption latent variable model imposes mild assumption   network exchangeable distribution invariant permutation vertex label network equivalently latent variable model  reasonable anonymized datasets identity entity easily rename model additionally function lipschitz finite spectrum regard integral operator rank scenario mixed membership stochastic model finite polynomial relax piecewise lipschitz ensure vertex sufficiently vertex function assume observation sample independently probability however discus non uniform sample algorithm algorithm propose concept local approximation datapoints compute neighborhood average estimate similarity collaborative filter format compute distance vertex dist estimate average nearby datapoints Fˆ euv euv mab euv dist dist choice cpn bias zero ensure datapoints reduce variance ensure euv diverges  various similarity algorithm distance computation dense datasets previous propose analyze algorithm approximate distance variant finite sample approximation dist      iff sparse datasets probability  almost distance cannot compute interested sparse significantly threshold visualize data via graph corresponds vertex extension instead hop vertex distance exactly along respectively expectation approximates   sufficiently vertex guarantee distance compute sparse dataset algorithm detail discus detail algorithm primarily involves compute pairwise distance similarity vertex sample splitting partition datapoints disjoint computation minimize correlation across analysis independently probability respectively matrix information subset data associate respectively define local neighborhood vertex compute similarity neighborhood average datapoints estimate expand neighborhood expand local neighborhood radius around vertex denote vertex distance vertex graph define specifically shortest denote breadth vertex breadth ensures within shortest valid breadth uniformly random denote vector boundary radius neighborhood vertex neighborhood boundary   denotes along sparsity coordinate along denote normalize neighborhood boundary radius cpn compute distance vertex variant estimate distance compute dist accord RTM compute distance accord dist define RTM vector satisfies exists unique vandermonde matrix within span compute dist knowledge spectrum analysis error estimate compute dist converges zero constant rank polynomially although compute dist knowledge spectrum vector error estimate compute dist  zero constant rank sparser setting polylogarithmic factor dependence slowly plausible technique employ modify algorithm prior knowledge  achieve stochastic model bootstrapping algorithm estimate spectrum computes pairwise distance estimate eigenvalue average datapoints estimate estimate Fˆ compute average nearby define distance estimate dist dist recall assume model definition upper bound  euv denote undirected dist dist cpn estimate Fˆ dist compute average undirected euv Fˆ euv euv euv denote undirected dist dist cpn estimate Fˆ dist compute average undirected euv Fˆ euv euv bound estimation error algorithm error mse mse Fˆ  average error model  analysis compute distance estimate  analysis essentially relies neighborhood growth around vertex behaves accord expectation accord properly define notion radius guarantee growth neighborhood boundary exponential increase factor approximately cpn however radius boundary respective neighborhood chosen vertex intersection estimate similarity intersection datapoints variance therefore choice critical algorithm analysis bound error chosen satisfy cpn cpn cpn cpn parameter denotes distinct eigenvalue spectrum determines radius measurement involve compute dist compute dist involves measurement reduce instead threshold decrease ensure satisfied sparsifying expand neighborhood around vertex sample probability polynomially constraint imply constant respect however accord rate cpn theorem choice cpn max exists constant respect satisfies cpn estimate compute dist parameter achieves mse cpn probability exp cpn estimate satisfies   max Fˆ fij cpn theorem prof error mse estimate compute dist bound cpn therefore algorithm dist consistent estimate constant respect occurs error factor compute distance sum expectation instead compute  expression concentrate around   contains extra factor therefore compute radius calculation dist approximate intend  error factor dist adjusts bias multiple measurement allows  distinct theorem choice cpn max exists satisfies cpn estimate compute dist parameter achieves mse cpn probability exp cpn estimate satisfies   max Fˆ fij cpn theorem prof error mse estimate compute dist bound cpn estimate consistent ultra sparse sample regime discussion similarity collaborative filter algorithm provably consistent sparse sample regime sample probability algorithm computes similarity user local neighborhood model assumes data matrix generate accord latent variable model expectation function associate latent variable variant compute similarity distance vertex compute dist knowledge spectrum estimate polynomially guarantee error converges zero compute dist knowledge spectrum estimate provably consistent significantly sparse regime error algorithm bound computation local neighborhood within graph algorithm easily implement datasets data distribute fashion optimize local graph computation practical implementation model parameter validation tune radius threshold vector sparse threshold bias variance estimate spectrum dist easy compute enjoys sample observation uniform across entry algorithm modification properly normalize hub vertex optimal choice local sparsity computational algorithm involves expand local neighborhood vertex local neighborhood compute parallel independent computation furthermore local neighborhood computation suitable data distribute across machine optimizes local neighborhood query expensive algorithm involves compute similarity vertex however approximate technique greatly reduce computation approximate compute significantly pairwise comparison non uniform sample reality probability entry uniform across however extension handle variation sample probability sample probability function latent variable respect across entry suppose probability factor contains dependence upon allows constant factor variation sample probability across entry function latent variable matrix presence observation apply algorithm twice matrix estimate function data matrix estimate simply estimate obtain estimate limitation error estimate correspond variance however error increase sample