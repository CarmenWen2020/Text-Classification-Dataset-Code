understand model prediction crucial prediction accuracy application however accuracy datasets achieve complex model expert struggle interpret ensemble model tension accuracy interpretability response various recently propose user interpret prediction complex model unclear related preferable another address unified framework interpret prediction shap shapley additive  shap assigns feature importance prediction novel component identification additive feature importance theoretical unique desirable unifies exist notable recent lack propose desirable insight unification improve computational performance consistency intuition previous approach introduction ability correctly interpret prediction model output extremely important engenders appropriate user trust insight model improve understand model application model linear model prefer interpretation accurate complex however availability data increase benefit complex model forefront accuracy interpretability model output variety recently propose address issue understand relate preferable another lack novel unified approach interpret model prediction approach potentially surprising clarity introduce perspective explanation model prediction model explanation model define additive feature attribution unifies http github com  shap conference neural information processing beach CA usa theory guarantee unique apply entire additive feature attribution propose shap unified feature importance various approximate propose shap estimation demonstrate align intuition user  discriminate model output exist additive feature attribution explanation model model perfectly easy understand complex model ensemble network cannot model explanation easy understand instead simpler explanation model define interpretable approximation model explanation literature explanation model previously  unity implication later prediction model explain explanation model focus local explain prediction input propose lime explanation model simplify input input mapping function local ensure whenever information specific input definition additive feature attribution explanation model linear function binary variable  simplify input feature explanation model definition attribute feature sum feature attribution approximates output model definition lime lime interprets individual model prediction locally approximate model around prediction local linear explanation model lime adheres equation exactly additive feature attribution lime refers simplify input interpretable input mapping convert binary vector interpretable input input mapping input bag text feature convert vector simplify input zero simplify input zero image treat image super pixel super pixel replace super pixel average pixel lime minimizes objective function arg min faithfulness explanation model model enforce loss sample simplify input local kernel penalizes complexity lime equation loss equation penalize linear regression deeplift deeplift recently propose recursive prediction explanation attribute input input reference oppose deeplift mapping convert binary input indicates input indicates reference reference chosen user typical uninformative background feature deeplift summation delta model output reference input deeplift explanation model equation another additive feature attribution layer wise relevance propagation layer wise relevance propagation interprets prediction network  equivalent deeplift reference activation neuron fix zero convert binary input input input layer wise relevance propagation explanation model deeplift equation classic shapley estimation previous classic equation cooperative theory compute explanation model prediction shapley regression shapley sample quantitative input influence shapley regression feature importance linear model presence multicollinearity retrain model feature subset feature assigns importance feature model prediction feature compute model feature another model feature withheld prediction model input input feature withholding feature depends feature model precede difference compute subset shapley compute feature attribution average difference shapley regression input indicates input model indicates exclusion model shapley regression equation hence additive feature attribution shapley sample explain model apply sample approximation equation approximate remove variable model integrate sample training dataset eliminates retrain model allows difference compute explanation model shapley sample shapley regression additive feature attribution quantitative input influence broader framework address feature attribution however independently proposes sample approximation shapley nearly identical shapley sample another additive feature attribution uniquely additive feature attribution surprising attribute additive feature attribution presence unique desirable described familiar classical shapley estimation previously unknown additive feature attribution desirable local accuracy approximate model specific input local accuracy explanation model output simplify input corresponds input local accuracy  explanation model model model output simplify input toggle missingness simplify input feature presence missingness feature input impact described obey missingness missingness missingness constrains feature attribute impact consistency consistency model simplify input contribution increase regardless input input attribution decrease consistency denote model input theorem explanation model definition satisfies non zero entry vector non zero entry subset non zero entry theorem combine cooperative theory shapley demonstrate shapley satisfy axiom redundant supplementary adapt shapley proof additive feature attribution simplify input mapping theorem additive feature attribution implies shapley violate local accuracy consistency already respect missingness proposes unified approach improves previous prevent unintentionally violate shap shapley additive explanation propose shap unified feature importance shapley conditional expectation function model equation shap shapley additive explanation attribute feature model prediction conditioning feature explain predict feature output diagram model non linear input feature independent however feature expectation shap arise average across ordering non zero index shap unique additive feature importance adheres conditional expectation define simplify input implicit definition shap simplify input mapping feature model cannot handle arbitrary input approximate definition shap closely align shapley regression shapley sample quantitative input influence feature attribution connection lime deeplift layer wise relevance propagation computation shap challenge however combine insight additive feature attribution approximate model agnostic approximation already shapley sample another novel kernel shap model specific approximation novel max shap shap feature independence model linearity optional assumption simplify computation feature shap explanation model simplify input mapping  expectation  assume feature independence assume model linearity model agnostic approximation assume feature independence approximate conditional expectation equation shap estimate directly shapley sample equivalently quantitative input influence sample approximation permutation version classic shapley equation equation sample estimate perform feature attribution reasonable compute input kernel shap described evaluation model obtain approximation accuracy kernel shap linear lime shapley linear lime linear explanation model locally approximate local simplify binary input glance regression formulation lime equation classical shapley formulation equation however linear lime additive feature attribution shapley equation satisfies local accuracy missingness consistency equation recovers depends choice loss function kernel regularization lime choice parameter heuristically choice equation recover shapley consequence local accuracy consistency violate  behavior circumstance avoid heuristically parameter equation loss function kernel regularization recover shapley theorem shapley kernel definition specific equation consistent non zero proof theorem supplementary important enforces PM infinite avoid optimization analytically eliminate variable constraint theorem assume linear loss equation linear regression consequence shapley theory compute linear regression lime simplify input mapping equivalent approximation shap mapping equation enables regression model agnostic estimation shap jointly estimate shap regression sample efficiency classical shapley equation intuitive connection linear regression shapley equation difference estimate data kernel linear regression  shapley kernel distinctly differs previous heuristically chosen kernel model specific approximation kernel shap improves sample efficiency model agnostic estimation shap restrict attention specific model develop faster model specific approximation linear shap linear model assume input feature independence equation shap approximate directly model coefficient corollary linear shap linear model PM  theorem equation previously   shap linear regression theorem complexity efficient approximation conditional expectation equation  preparation manuscript discover parallel equivalent constrain quadratic minimization formulation shapley propose   shapley kernel symmetric vector cardinality vector distinctly previous heuristically chosen kernel compositional model neural network comprise component analytic shapley component approximation model deeplift style propagation max shap permutation formulation shapley calculate probability input increase maximum input sort input compute shapley max function input instead MM supplementary algorithm shap deeplift shapley kernel shap model model leverage extra knowledge compositional network improve computational performance previously  connection shapley deeplift interpret reference equation equation deeplift approximates shap assume input feature independent another model linear deeplift linear composition equivalent linearize non linear component neural network propagation define component linearize intuitive heuristically chosen deeplift additive feature attribution satisfies local accuracy missingness shapley attribution satisfy consistency motivates adapt deeplift become compositional approximation shap shap shap combine shap compute component network shap network recursively passing deeplift multiplier define shap backwards network     chain  linear approximation shap network component efficiently analytically linear max pool activation function input composition enables approximation model shap avoids heuristically linearize component instead derives effective linearization shap compute component max function improve attribution shap shapley sample lime shapley dense model sparse model feature importance comparison additive feature attribution kernel shap debiased lasso shapley sample lime source implementation feature importance estimate feature model evaluation model function increase percentile replicate estimate sample decision model input feature explain input decision input feature explain input computational user evaluate benefit shap kernel shap shap approximation computational efficiency accuracy kernel shap lime shapley sample user shap alternative feature importance allocation deeplift lime shap consistent intuition fail finally mnist digit image classification shap deeplift lime computational efficiency theorem connects shapley theory linear regression  shap connection compute feature importance accurate estimate evaluation model previous sample estimate equation particularly regularization linear model shapley sample shap lime dense sparse decision model illustrates improve sample efficiency kernel shap lime significantly shap satisfy local accuracy consistency consistency intuition theorem incentive additive feature attribution shap lime deeplift originally demonstrate compute feature importance validate importance theorem explanation lime deeplift shap user explanation model amazon mechanical turk assumes model explanation consistent explanation understand model lime deeplift shap explanation setting sickness symptom max allocation deeplift apply participant maximum achieve participant assign credit output sickness input symptom player agreement explanation shap shap improve performance max function address max pool function deeplift explain difference deeplift compositional approach suggests compositional approximation shap shap insight improve deeplift version lime shap orig deeplift lime shap feature impact estimate explanation random individual respectively feature attribution model output sickness model output fever cough fever cough otherwise attribution profit accord maximum none profit orig deeplift deeplift shap input explain explain masked lime orig deeplift deeplift shap lime odds explain output convolutional network mnist digit dataset orig deeplift explicit shapley approximation deeplift seek approximate shapley increase probability decrease probability masked remove pixel odds mask random image estimate shap update shapley extends deeplift convolutional network highlight increase performance estimate closer shap pre model input normalize convolution layer dense layer softmax output layer deeplift version explain normalize version linear layer shap compute kernel shap lime explain model output shap lime sample supplementary improve performance lime modify pixel segmentation digit pixel masked pixel chosen switch predict accord feature attribution conclusion tension accuracy interpretability model prediction motivate development user interpret prediction shap framework identifies additive feature importance previous unique adheres desirable thread unity shap weave literature encourage principle model interpretation inform development future estimation shap along proof desirable promising involve develop faster model specific estimation assumption integrate estimate interaction theory define explanation model