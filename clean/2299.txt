propose novel stochastic approximation algorithm canonical correlation analysis cca algorithm instance inexact matrix stochastic gradient msg inexact matrix exponentiated gradient meg achieve suboptimality population objective poly iteration practical variant propose algorithm cca theoretically empirically introduction canonical correlation analysis cca ubiquitous statistical technique maximally correlate linear component random variable cca stochastic optimization random vector rdx rdy unknown joint distribution dimensional subspace projection maximally correlate matrix rdx rdy maximize cca technique recently met unsupervised representation multiple data improve representation complementary information cca multiview representation advantage information feature useful understand structure data beneficial downstream task unsupervised technique leverage unlabeled data plentiful accordingly interested stochastic approximation SA algorithm easily datasets stochastic approximation algorithm iterative algorithm iteration sample population perform update stochastic gradient descent sgd classic SA algorithm computational challenge associate challenge stem non convex nevertheless akin related spectral principal component analysis pca cca generalize eigenvalue despite non convex cca admits tractable conference neural information processing beach CA usa algorithm numerical technique iteration variant apply globally optimal recent therefore focus analyze optimization error iteration generalize eigenvalue however analysis numerical empirical optimization error singular vector fix matrix empirical estimate covariance matrix population suboptimality aka bound population objective focus challenge concern stochastic approximation algorithm cca difficulty pca machine constraint involve stochastic quantity unknown distribution differently cca objective decompose sample cca equivalently maximize correlation objective pex  yield unconstrained optimization however objective longer expectation instead ratio expectation empirical version easy objective sample departs significantly typical stochastic approximation scenario crucially sample unbiased estimate gradient objective therefore oracle inexact estimate gradient norm bound additive focus inexact proximal gradient descent algorithm cca finally cca ill population auto covariance matrix ill observation exists direction kernel exhibit non zero covariance objective unbounded avoid recover direction spurious correlation therefore assume eigenvalue auto covariance matrix empirical estimate bound positive constant formally assume   typical assumption analyze cca notation scalar vector matrix normal roman roman respectively denotes identity matrix subscript whenever context norm vector denote kxk matrix spectral norm nuclear norm frobenius norm kxk kxk  respectively trace matrix denote matrix standard inner notation interchangeably symmetric matrix positive semi definite psd rdx rdy denote random variable jointly distribute correspond auto covariance matrix covariance matrix  define max finally rdx rdy denote data matrix correspond sample respectively formulation sample drawn goal maximally correlate subspace population objective variable yield equivalent maximize  ensure assume min min min eigenvalue population auto covariance matrix furthermore assume probability max kxk kyk rdx rdy denote singular vector respectively population covariance matrix whiten  easy optimum achieve therefore approach training dataset estimate empirical auto covariance covariance matrix compute empirical estimate matrix estimate singular vector approach refer sample average approximation saa empirical risk minimization erm equivalent parameterization variable substitution UV refer rdx maximize  min rank interested SA algorithm bound distribution minimum eigenvalue auto covariance matrix bound guaranteed suboptimal population objective extract related flurry recent scalable approach empirical cca numerical optimization empirical cca objective fix data typically batch approach entire data iteration perform iteration optimize alternative empirical objective minimize    empirical estimate covariance matrix sample stack matrix rdx rdy alternate project gradient descent  alternate svrg combine shift invert pre conditioning however focus empirical instance saa erm approach stochastic optimization analysis bound suboptimality training objective population objective relevant aware algorithm cca population parallel however difference objective focus alignment optimal population rely eigengap singular correlation matrix  contrast concerned population objective eigengap eigengap correlation matrix population optimal define return optimal nearly optimal furthermore eigengap emphasis guaranteed overall runtime core algorithm efficient runtime algorithm cannot SA algorithm version runtime memory efficient SA algorithm update iteration contrast SA algorithm emphasis iteration complexity sample polynomial runtime guarantee rely heuristic cap achieve runtime performance finally obtain correlate direction extend approach correlate direction handle naturally guarantee valid desire direction contribution goal directly optimize cca population objective population capture sample training objective justifies stochastic approximation approach optimal sample essentially sample average approximation approach population advocate supervise machine unsupervised contribution convex relaxation cca optimization stochastic approximation algorithm algorithm sample pas data easily datasets propose algorithm instance inexact stochastic mirror descent choice potential function frobenius norm von neumann entropy respectively prior inexact proximal gradient descent suggests bound guarantee convergence inexact update violate cca tighter analysis algorithm noisy gradient establish sub linear convergence rate precise iteration complexity bound algorithm upper bound iteration guarantee user specify suboptimality population cca bound eigengap correlation matrix knowledge characterization cca generalization empirically propose algorithm outperform exist cca dataset implementation propose algorithm exist compete technique available online matrix stochastic gradient cca msg cca non convex optimization however admits convex relaxation convex hull constraint convex relaxation maximize  kmk kmk update algorithm return rank procedure algorithm detail objective expectation allows guarantee suboptimality output algorithm non convex equivalently relaxation previously stochastic approximation SA algorithm principal component analysis pca partial pls SA algorithm instance stochastic gradient descent popular choice convex however update cca challenge gradient cca objective  unbiased estimator gradient unless marginal distribution therefore instance inexact proximal gradient access oracle noisy estimate oracle bound PT kgt ensures convergence proximal gradient furthermore propose oracle instantiates inexact gradient  empirical estimate whiten transformation training data stochastic inexact gradient update PF PF projection operator onto constraint algorithm pseudocode propose inexact matrix stochastic gradient cca msg cca iteration sample update empirical estimate whiten transformation define inexact gradient gradient update projection onto constraint respect frobenius norm operator PF iteration algorithm return rank matrix procedure http dropbox com   algorithm matrix stochastic gradient cca msg cca input training data auxiliary training data output initialize xtx   PF projection PT algorithm denote empirical estimate auto covariance matrix sample analysis msg cca procedure empirical estimate whiten transform matrix guarantee error inexact estimate converges zero noisy stochastic gradient converges optimum denote whiten transforms algorithm invert empirical auto covariance matrix ensure eigenvalue bound away zero technical happens probability iterates lemma probability respect training data drawn uniformly min min whenever max   denote empirical covariance matrix eigenvalue bound respectively lemma guarantee occurs probability sample auxiliary dataset lemma assume occurs probability max kxk kyk ED kgt bound estimate inexact gradient surprisingly error decay estimate whiten transformation improve data moreover rate error decrease sufficient bound suboptimality msg cca algorithm noisy bias stochastic gradient theorem iteration msg cca algorithm GPT auxiliary sample initialize   expectation respect sample define lemma optimum rank output msg cca  theorem bound objective implies bound cca objective rank factorization UV construct generalization bound theorem iteration msg cca algorithm GPT auxiliary sample initialize     expectation respect sample optimum factor define rank output msg cca min max lemma  proof defer appendix supplementary remark convexity analysis msg cca leveraged observation objective linear optimum attain extreme correspond optimum convex relaxation tractable non convex although optimum extreme efficient randomize extract feasible expectation eigengap bound theorem eigengap correlation matrix  error bound imply iteration complexity achieve desire suboptimality eigengap comparison straightforward author objective seek alignment optimal alignment   furthermore analysis dependent eigengap singular population correlation matrix nevertheless relate objective guarantee ensure objective namely achieve suboptimality presence eigengap suboptimal sample capped msg cca although msg cca theoretical guarantee computational per iteration therefore practical variant msg cca explicitly rank iterates ensure computational efficiency recommend impose constraint rank iterates msg cca approach previous pca pls maximize  kmk kmk rank estimate whiten transformation iteration eigenvalue covariance matrix constant estimate eigenvalue covariance matrix allows efficiently compute whiten transformation covariance matrix decompose sum rank matrix identity matrix computational per iteration empirically dataset procedure along cap rank msg iterates hurt convergence msg cca matrix exponentiated gradient cca meg cca matrix multiplicative update cca multiplicative generic algorithmic technique update distribution iteratively probability  subspace multiplicative algorithm instance matrix exponentiated gradient meg update motivation meg related principal component analysis pca partial pls meg yield optimistic rate unfortunately recover optimistic rate cca error inexact gradient decrease slowly development meg symmetrization recall  symmetric matrix matrix refer adjoint dilation matrix svd singular eigen decomposition singular vector  comprise cca seek encode respectively eigenvectors dilation suggests parameterization maximize rank convex hull constraint convex relaxation maximize kmk stochastic mirror descent choice potential function quantum relative entropy update exp exp adjoint dilation unbiased instantaneous gradient andp denotes bregman projection onto convex constraint inexact gradient estimate bound PT  adjoint dilation define guarantee bound lemma assume occurs singular probability max kxk kyk define lemma ext  ati optimum bound bound suboptimality gap population objective rank cca rank return meg cca theorem iteration meg cca algorithm appendix  GT auxiliary sample initialize conditional expectation respect distribution internal randomization algorithm optimum rank output meg cca  define lemma remark regard latent convexity practical variant apply meg cca however without additional assumption eigengap recover projection canonical subspace theorem experimental propose capped msg practical variant algorithm cap define equation meg algorithm appendix dataset  consist observation video correspond commentary algorithm  ALS cca saa denote batch comparison cca objective function cpu runtime iteration target dimensionality choice dictate largely spectrum  dataset decay exponentially ensure empirical estimate covariance matrix  dataset msg meg iteration  multiview dataset consist correspond video text annotation label semantic concept image consists dimensional visual feature extract representative frame video textual feature dimensional compete algorithm  ALS cca advantage knowledge eigengap estimate spectrum matrix  dataset gap dependent parameter  ALS cca accordingly however estimate eigengap parameter impractical scenario  ALS cca therefore additional tune msg meg algorithm propose  ALS cca outperform meg capped msg recover cca component progress per iteration however capped msg overall runtime plot discussion cca stochastic optimization efficiently learnable analysis stochastic approximation algorithm propose algorithm achieve suboptimality population objective iteration algorithm msg cca algorithm meg cca algorithm appendix instance inexact proximal gradient algorithm noisy gradient iteration perform proximal bregman projection equation convergence rate PT  partial sum error gradient obtain convergence however cca lemma easy analysis yield convergence rate algorithm warrant investigation inexact proximal gradient empirical comparison capped version propose msg algorithm outperform meg overall runtime suboptimal future focus gain theoretical understand capped msg ALS algorithm implementation author handle iteration objective capped msg meg  batch  max objective iteration objective iteration objective runtime objective runtime objective runtime objective comparison cca lin cca ALS msg meg cca optimization  dataset objective function iteration function cpu runtime