gradient promising parameter dynamic ordinary differential equation grid inference approach fully observable competitive numerical integration however application sparse observation available unobserved variable model description gradient apply simply satisfactory despite computational numerical integration standard application exist gradient approach propose scalable variational inference framework infer parameter simultaneously computational speedup improve accuracy model  partially observable introduction parameter estimation ordinary differential equation ode challenge due computational numerical integration recent gradient technique establish successful circumvent computational numerical integration parameter estimation ordinary differential equation gradient minimize difference interpolate slope derivative variable ode spline iterate procedure coefficient parameter estimate cubic spline basis function advanced approach kernel function derive ode overview recent approach focus application biology   unfortunately straightforward extend spline approach unobserved variable usually observability moreover critically estimation smooth parameter estimate sparse observation available gaussian GP regression propose improve bayesian approach fully observable spline cannot simultaneously infer parameter unobserved perform poorly combination variable differential equation unobserved variable unfortunately practical application related propose variational inference approximate dynamical linear approach later  extend however  parameter estimation stochastic dynamical author contribute equally conference neural information processing beach CA usa focus deterministic addition euler  discretization whereas approach grid wang  propose approach belief network controversy mechanistic model intrinsic identifiability contribution proposal scalable variational inference framework infer parameter simultaneously significant runtime improvement improve accuracy partially observable simplistic approximation opportunity significant future improvement illustrate potential analyze standard laptop deterministic dynamical deterministic dynamical ordinary differential equation ode model parameter evolution sequence observation usually contaminate measurement error assume normally distribute zero variance dik  distinct overall summarize sequence observation observation description dynamical aim estimate variable parameter numerical integration computational prohibitive motivates grid outline GP gradient gaussian gradient originally motivate developed assume gaussian prior variable   covariance matrix define kernel hyper parameter obtain posterior distribution variable assume covariance function  differentiable closure differentiation gaussian conditional distribution derivative ghz intel core macbook covariance   denotes auto covariance derivative  denote  derivative assume additive normally distribute specific error variance  expert approach combine ode inform distribution derivative distribution smooth distribution derivative distribution motivation expert multiplication implies data ode response satisfied achieve contrary mixture model normalize addition expert overfitting data neglect ode response vice versa acceptable propose methodology analytically integrate  normalization depends infer parameter sample sample parameter setup sample independent implies influence inference variable desire feedback loop sample joint posterior sample discrete existence external ode solver obtain continuous trajectory variable simplicity derive approach assume observability however approach advantage oppose spline assumption observability relaxed observation combination replace AX encodes linear relationship observation addition unobserved naturally inference simply prior variable variational inference gradient exploit local linearity ode subsequent model reaction action kinetics    variable factor equation function linear parameter arbitrary monomials motivation restriction functional twofold formulation model exhibit periodicity nonlinearity physically realistic reaction biology joint posterior unknown normalization parameter posterior depends dependence nontrivial induced nonlinear coupling inference integration challenge previous approach ignore dependence equation analytically exploit local linearity ode supplementary precisely action kinetics rewrite ode linear combination individual linear combination ode parameter achieve superior performance exist gradient approach experimental variational inference infer parameter maximum posteriori estimate argmax argmax however integral intractable due coupling induced nonlinear ode equation therefore variational inference establish variational bound analytically tractable decouple variable ode parameter decouple variable explain mechanism variational inference due model assumption conditional distribution gaussian distribute denotes exclude  conditional distribution canonical exp exp normalizer parameter sufficient statistic decouple induced variational distribution restrict factorial distribution variational parameter exponential conditional distribution equation exp exp action kinetics ode nonlinear linear linear ode parameter optimal factorial distribution minimize kullback leibler divergence variational posterior distribution Qˆ argmin KL argmin EQ EQ argmax LQ Qˆ proxy distribution LQ ELBO evidence bound depends variational parameter maximize ELBO equivalent maximize bound EQ EQ  substitute conditionals equation gradient operator similarly maximize ELBO latent EQ EQ  assumption posterior variational distribution conditional exponential correspond variational distribution exponential optimize coordinate maximize ELBO gradient variational parameter zero    zero  similarly optimal variational parameter  conditionals gaussian distribute expectation parameter       covariance conditional distribution ode parameter similarly covariance conditional distribution variational parameter equation derive analytically supplementary coordinate ascent approach analytically tractable estimate parameter summarize algorithm algorithm coordinate ascent GP gradient initialization proxy proxy ode parameter calculate proxy individual compute  proxy individual calculate proxy ode parameter compute  convergence maximum iteration exceed assume maximal equation constant knowledge reasonable dynamical computational complexity algorithm linear iteration experimentally analyze comparison exist approach approach medium ode model extensively parameter setting additionally scalability approach partially observable infeasible analyze exist gradient due unobserved lotka volterra population ode parameter parameter GM agm spline GM agm spline runtime lotka volterra noisy observation simulated variance leftmost plot infer dynamic variational GM median runtime sec estimate standard deviation random data initialization approach illustrate plot implement spline spline median runtime sec adaptive gradient agm approach propose boxplots leftmost rightmost plot illustrate variance parameter estimation independent datasets ode lotka volterra   ode parameter prey predator lotka volterra observation trajectory infer unobserved typical lotka volterra predator prey specie recover shade uncertainty around infer trajectory predator prey interaction exhibit periodicity nonlinearity ode parameter simulate data interval sample interval predator specie initialize prey specie initialize variational inference gradient perform simulated dataset additive gaussian variance radial basis function kernel capture covariance performs significantly computational performance accuracy explain significantly sample simpler potential establish experimental setting illustrates difficulty spline gradient observation available estimate smooth parameter proposal validation principle achieve runtime fold performance parameter estimation significantly already validation median parameter estimation independent data initialization completely parameter adaptive gradient agm eventually converge parameter roughly runtime achieves signifcantly accuracy approach additionally mechanism lotka volterra correctly infer unobserved interval protein signal transduction pathway GP gradient spline inapplicable partial observable addition already simpler data spline competitive accuracy approach leftmost plot performance agm infer trajectory curve plot groundtruth infer trajectory agm plot plot approach scenario leftmost plot observation available approach approach agm significantly infer unobserved parameter remain plot approach infers dynamic scenario chemical kinetics protein signal transduction pathway combination action kinetics   kinetics RS RS rpp rpp RS RS RS rpp RS rpp rpp detailed  biological interpretation refer   action kinetics protein transduction pathway satisfy constraint functional ode   kinetics ratio rpp rpp therefore define latent variable RS rpp rpp transformation motivate monomials variable transformation inherent error replace rpp RS rpp rpp despite  estimate parameter correctly ode parameter data sample interval sample parameter infer standard gaussian distribute variance  model systematic error rank accord parameter preserve approach converges factor runtime parameter fully observable significantly unobserved  introduction approach infers dynamic fully partially observable remains unchanged estimation accuracy introduction unobserved variable inherent bias performs comparison numerical integration plot additional dynamic supplementary RMSE ode parameter GM agm bayes num int RMSE ode parameter GM agm bayes num int RMSE ode parameter GM agm bayes num int bayes num int plot inference setting increase difficulty protein transduction pathway plot fully observable due violation functional assumption approach inherent bias agm performs bayesian numerical integration bayes num int serf standard performs plot increase due outlier median independent adjust plot plot unobserved estimate agm limit plot initialize numerical integration bayes num int achieves significantly lower estimation error plot scalability scalability approach apply lorenz consists equation scalar parameter deterministic lorenz minimalistic model additional diffusion reference model stochastic flexible framework increase inference due dimensionality lorenz analyze gradient additionally increase difficulty inference randomly unobserved simulated data observation equally observation zero due approach infer within plot visually conclude unobserved approximately infer approximation error independent dimensionality plot iteration RMSE ode parameter unobserved RMSE reduction ode parameter unobserved ODEs average RMSE  runtime gradient lorenz plot improve mechanistic model reduction median error RMSE iteration algorithm groundtruth unobserved plot correspond infer trajectory iteration algorithm initialisation infer trajectory unobserved convergence plot algorithm dimensionality curve runtime  curve correspond  plot due limitation additional various dynamical fluid dynamic electrical engineering biology neuroscience supplementary discussion numerical integration bottleneck due computational estimation parameter biology however serf standard practical application technique gradient computationally appeal successful shortcut parameter inference extend unobserved variable model  unable performance fully however application partially variable monomials ode powerful inference framework scalable significantly outperforms exist approach runtime accuracy performs sparse observation partially observable non linear periodic ode lotka volterra already fulfill assumption empirically robustness model  additional partial observability already indicates relaxation functional assumption future research