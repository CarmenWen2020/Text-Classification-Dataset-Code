unified framework smooth convex regularization discrete optimal transport context regularize optimal transport equivalent matrix  respect bregman divergence framework naturally generalizes previously propose regularization boltzmann shannon entropy related kullback leibler divergence sinkhorn knopp algorithm regularize optimal transport distance rot mover distance reference classical mover distance exploit alternate bregman projection develop alternate algorithm non negative alternate algorithm compute efficiently regularize optimal domain regularizer within non negative orthant enhance separable sparse extension data dimension instantiate framework discus inherent specificity regularizers statistical divergence machine information geometry community finally demonstrate merit synthetic data illustrate regularizers penalty dimension data recognition application audio scene classification keywords alternate projection convex analysis regularize optimal transport rot mover distance statistical divergence introduction recurrent statistical machine choice relevant distance probability distribution various information divergence  dessein  papadakis jean  rouas license CC http creativecommons org license attribution requirement http jmlr org html dessein papadakis rouas euclidean mahalanobis kullback leibler  saito hellinger quasi norm variation logistic loss function  bregman divergence parametric divergence divergence alternative distance probability distribution introduce framework optimal transport OT perform pointwise comparison distribution quantify minimal effort probability distribution transport optimize accord OT distance suitable robust application notably computer vision discrete OT distance mover distance emd popularize histogram feature recognition task despite appeal theoretical intuitive formulation excellent performance various information retrieval computation emd involves linear program quickly becomes prohibitive data dimension algorithm currently propose network simplex super cubic complexity embeddings distribution approximate emd linear complexity network simplex modify quadratic nevertheless distortion inherent embeddings exponential increase incur modification approach inapplicable dimension instead multi strategy shortcut estimation optimal approach limited convex truncate compress version prefer increase robustness data outlier application gain performance obtain directly label data aforementioned accelerate dedicate convex adapt context another research regularization transport via graph model noisy data latter approach address computational issue efficiency dimension continuity entropic regularization admit efficient algorithm quadratic complexity computation magnitude improve performance application handwritten digit recognition addition tailor computation obtain via convolution specific introduction entropic regularization OT benefit extensive development machine community application label propagation domain adaptation matrix factorization barycenter computation geodesic principal component analysis data fitting statistical inference training boltzmann machine generative adversarial network entropic regularization gain computational important dimension regularization regularization advanced optimization strategy obtain significant entropic regularization  transport undesirable application interpolation purpose perspective however regularizers worth investigate OT efficiently robustly address focus smooth convex regularization notation sake simplicity distribution dimension euclidean matrix straightforward however extend bin rectangular matrix instead denote null matrix matrix frobenius inner matrix define  intend meaning context null vector vector notation transposition operator matrix vector probability simplex define operator diag transforms vector diagonal matrix  operator vec transforms matrix vector πij operator sgn return negative null positive respectively function variable absolute exponential function elementwise apply matrix max operator inequality matrix interpret wise matrix similarly wise whereas wise matrix multiplication hadamard schur denote remove ambiguity standard matrix multiplication lastly addition subtraction scalar matrix understood wise replicate scalar background related probability vector matrix coefficient  bin transport couple quantify optimal obtain dessein papadakis rouas linear program min transport polytope polytope coupling define polyhedron emd associate matrix distance metric probability simplex whenever distance matrix optimal mover nonzero entry consist vertex facet transport polytope mover obtain network simplex approach matrix complexity OT algorithm currently propose network simplex super cubic  propose OT distance sinkhorn distance perspective maximum entropy smooth strictly convex regularization via boltzmann shannon entropy primal involves entropic regularization additional constraint min regularize transport polytope define regularization minus boltzmann shannon entropy define straightforward  kullback leibler divergence define enforces sufficient entropy equivalently mutual information constrain kullback leibler radius respectively matrix respectively transport maximum entropy dual exploit lagrange multiplier relax entropic regularization penalty regularize optimal define argmin regularization empirically quadratic complexity linear convergence sinkhorn knopp algorithm sinkhorn rot mover distance knopp iterative matrix rescale respectively sum convergence finally easy argmin argmin  regularization enforces sufficient entropy equivalently mutual information shrink matrix joint distribution maximum entropy revisit entropic regularization geometrical framework iterative information projection compute sinkhorn distance dual actually amount minimization kullback leibler divergence argmin exp precisely amount compute kullback leibler projection exp onto transport polytope context sinkhorn knopp algorithm instance bregman projection onto intersection convex via alternate projection specifically intersection non negative orthant affine subspace matrix sum respectively alternate projection subspace accord kullback leibler divergence convergence  equivalence wider context iterative proportional fitting notably sinkhorn knopp alternate bregman projection extend account infinite entry matrix null entry regularize optimal hence develop sparse version entropic regularization OT becomes matrix variable perform computation data dimension dhillon  already enlighten equivalence matrix analysis actually estimation contingency fix marginals matrix  kullback leibler divergence detail rough estimate contingency fix marginals kullback leibler projection onto argmin πkξ alternate bregman projection specialize sinkhorn knopp algorithm context however relationship OT highlight contribution organization contribution formulate unified framework discrete regularize optimal transport rot smooth convex regularizers dessein papadakis rouas underlie distance rot mover distance rmd rot actually amount minimization associate bregman divergence allows derivation scheme alternate algorithm asa nonnegative alternate algorithm nasa compute efficiently regularize optimal domain regularizer within non negative orthant scheme alternate projection bregman divergence exploit newton raphson approximate projection separable divergence separable enhance sparse extension data dimension instantiate generic scheme widely regularizers statistical divergence propose framework naturally extends sinkhorn knopp algorithm regularization boltzmann shannon entropy equivalently minimization kullback leibler divergence sparse version instance rot relates matrix  via minimization bregman divergence straightforward construct estimator contingency fix marginals classical estimator kullback leibler divergence lastly brings insight transportation theory information geometry bregman divergence posse dually structure generalize pythagorean theorem relation information projection remainder organize introduce preliminary theoretical unified framework rot derive algorithmic rot discus inherent specificity rot classical regularizers associate divergence illustrate synthetic data audio data classification finally conclusion perspective future theoretical preliminary introduce preliminary framework convex analysis bregman geometry proceed theoretical convergence alternate bregman projection newton raphson convex analysis euclidean inner induced norm boundary interior relative interior subset respectively denote int recall convex convex analysis scalar function define extend effective domain simply domain rot mover distance function define dom convex function dom convex function semi continuous moreover function continuous relative simplex polytope polyhedral subset dom convex function continuous relative interior dom domain function essentially smooth differentiable int dom verifies limk sequence int dom converges dom function legendre convex function essentially smooth strictly convex int dom fenchel conjugate function define sup int dom fenchel conjugate convex function moreover convex function legendre legendre latter gradient mapping homeomorphism int dom int dom inverse mapping guarantee existence dual coordinate int dom int dom finally function  verifies lim nonzero intuitively grows super linearly direction convex function  dom bregman geometry convex function differentiable int dom bregman divergence generate define xky dom int dom xky dom int dom addition strictly convex int dom xky bregman divergence convex argument invariant arbitrary affine generator bregman divergence symmetric verify inequality necessarily distance strict however enjoy nice geometrical somehow generalize euclidean geometry verify identity parallelogram xky xky dessein papadakis rouas dom int dom instance relation cosine xky xky dom int dom suppose legendre convex int dom int dom PC argmin xky unique bregman projection onto actually belongs int dom characterize unique int dom verifies variational relation dom characterization equivalent generalize pythagorean theorem bregman divergence bregman projection onto unique int dom verifies inequality xky xky dom affine subspace generally bregman projection belongs scalar actually vanishes equality generalize pythagorean theorem xky xky bregman divergence kullback leibler divergence define matrix πkξ πij πij  πij  divergence generate function legendre minus boltzmann shannon entropy πij πij πij convention another  saito divergence define matrix πkξ πij  πij  rot mover distance divergence generate function legendre minus burg entropy πij πij belong separable bregman divergence matrix aggregation wise bregman divergence scalar πkξ    πij wise generator  chosen simply slight abuse notation divergence logistic loss function generate minus fermi dirac entropy euclidean distance generate euclidean norm classical non separable bregman divergence mahalanobis distance define matrix πkξ vec vec positive definite matrix divergence generate function legendre quadratic vec vec alternate bregman projection function legendre fenchel conjugate compute bregman projection onto arbitrary convex int dom nontrivial sometimes decompose intersection finitely convex individual bregman projection onto respective easy compute obtain bregman projection onto alternate projection onto accord dykstra algorithm detail mapping determines sequence subset onto project int dom bregman dessein papadakis rouas projection PC onto approximate dykstra algorithm iterate update  correction respective subset initialize null update projection technical sequence update converges norm PC linear rate notably tseng  lewis dhillon  propose dhillon  reveal restrictive framework specifically convergence dykstra algorithm guaranteed function  constraint qualification int dom mapping essentially cyclic exists output consecutive input polyhedral relative interior constraint qualification hence subset polyhedral constraint qualification simply reduces int dom already enforce definition bregman projection finally subset affine relax assumption notably  equivalently dom dom mapping essentially cyclic anymore output infinite importantly completely correction update simpler technique projection onto convex pocs  newton raphson continuously differentiable scalar function interval assume increase non empty interval equation approximate iterative update accord newton raphson max min infinite null convention newton raphson converges initialize sufficiently convergence quadratic however local convergence importance quantify proximity rot mover distance affine constraint polyhedral constraint legendre legendre dom dom dom dom dom dom dom assumption regularizers  petersen elucidate global convergence newton raphson sufficient convergence arbitrary implies sufficient underlie function increase convex increase concave function decompose sum function addition satisfies sufficient strictly increase initialize boundary ensures entire sequence update interior actually min max truncation operator update mathematical formulation develop unified framework define rot technical assumption generalize framework formulate primal rot formulate dual rot discus relation primal finally geometrical insight summarize development information geometry technical assumption mild technical assumption convex regularizer fenchel conjugate propose framework assumption relate definition bregman projection convergence algorithm others specific rot framework distinguish situation underlie convex described intersection affine subspace polyhedral subset assumption summarize assumption recall convex function legendre essentially smooth strictly convex interior dessein papadakis rouas domain definition bregman projection addition guarantee existence dual coordinate int dom int dom via homeomorphism slight abuse notation omit reparameterization simply denote correspond primal dual parameter assumption imply dom ensure constraint qualification int dom bregman projection onto transport polytope independently input distribution null entry assume hereafter implicitly discus practical consideration actually generalize explicitly null entry input distribution assumption dom within non negative orthant alternate bregman projection former non negativity already ensure domain regularizer underlie convex affine subspace sum constraint pocs fourth assumption dom convergence algorithm latter additional polyhedral subset non negative constraint dykstra algorithm fourth assumption hence dom equivalently  convergence remark necessarily dom dom fifth assumption affine constraint ensures belongs dom definition rot independently non negative matrix positive regularization already guaranteed fourth assumption polyhedral constraint sparse extension infinite entry matrix separable regularizers enforce null entry regularize optimal regularizers assumption  entropy associate kullback leibler divergence burg entropy associate  saito divergence fermi dirac entropy associate logistic loss function underlie rot employ asa pocs technique alternate bregman projection onto affine subspace sum constraint assumption euclidean norm associate euclidean distance quadratic associate mahalanobis distance rot nasa dykstra algorithm correction bregman projection onto polyhedral non negative orthant primal primal formulation lemma definition rmd rot mover distance lemma regularizer attains global minimum uniquely proof assumption respectively dom int dom exists unique int dom equivalently via homeomorphism ensure assumption respectively hence attains global minimum uniquely strict convexity int dom lemma restriction regularizer transport polytope attains global minimum uniquely bregman projection onto proof assumption respectively int dom int dom convex bregman projection onto accord function legendre define moreover characterize variational relation dom πkπ strict convexity int dom combine inequality obtain restriction attains global minimum uniquely lemma restriction regularize transport polytope attains global minimum proof regularize transport polytope intersection compact hence compact restriction attains global minimum continuity compact definition primal rot mover distance quantity define min minimizer primal rot mover dessein papadakis rouas remark sake notation omit dependence index primal rot mover regularization enforces associate minimizers bregman information minimal transport geometrical interpretation constrain bregman matrix minimal bregman information proposition regularize transport polytope intersection transport polytope bregman radius πkξ proof expand bregman divergence definition obtain πkξ scalar vanish πkξ therefore definition bregman radius additional geometrical interpretation bregman minimal bregman information transport proposition regularize transport polytope intersection transport polytope bregman radius πkπ proof equality generalize pythagorean theorem πkξ πkπ regularize transport polytope intersection transport polytope bregman radius remark proposition trivially global minimum attain transport polytope corollary assumption regularize transport polytope intersection transport polytope bregman radius πkπ rot mover distance proof int dom dom indeed int dom int dom conversely int dom easily moreover entry positive non negative sufficiently characterize int dom remark assumption bregman projection necessarily within hence geometrical interpretation bregman although constrain bregman information although sinkhorn distance verify triangular inequality distance matrix thanks specific chain information inequality  shannon entropy kullback leibler divergence necessarily rmd regularization separable regularizers hence rmd distance metric distance matrix nonetheless rmd symmetric invariant transposition separable regularizers  symmetric rmd regularizers primal rot mover distance decrease convex continuous function proof decrease consequence regularize transport polytope convexity arbitrary rot mover finally convexity hence  construction  equivalently  continuity consequence convexity convex function continuous relative interior domain lastly continuity sequence positive converges arbitrary rot mover compactness extract subsequence rot mover converges norm dessein papadakis rouas sake simplicity relabel subsequence construction converges semi continuity global minimum attain uniquely sequence converges norm continuity converges hence limit rmd tends rmd primal rot mover distance reduces unique primal rot mover transport minimal bregman information proof unique global minimizer regularize transport polytope reduces singleton immediately tends primal rot mover distance converges mover distance lim proof mover continuity exists neighborhood transport within neighborhood transport dom finite fix hence dom exists minimal primal rot mover distance reduces mover distance proof extra guarantee dom bound consequence rot mover distance dom strictly convex unique primal rot mover mover minimal bregman information proof recall mover vertex facet hence convex subset unique mover minimal bregman information strict convexity subset trivial primal rot mover mover vertex mover immediately otherwise geometrically facet mover orthogonal nevertheless strict convexity facet tangent unique mover minimal bregman information rot mover another formally suppose primal rot mover mover minimal bregman information rmd emd actually monotonicity contradiction mover minimal bregman information remark regularize transport polytope mover bregman information minimizers rmd strict convexity outside multiple mover minimal bregman information dom easy strict convexity verify separable assumption int dom assumption almost typical regularizers notably regularizers minus burg entropy define associate  saito divergence latter regularizer increase within rmd emd minimal exist convention rmd converges emd limit tends unique rot mover informally geometrically intersection hyperplane normal strict convexity intersection singleton inside polytope intersection facet facet coincide locally hyperplane contains mover hence singleton boundary polytope mover formally uniqueness exploit duality dual lemma define dual formulation rmd dessein papadakis rouas lemma regularize attains global minimum uniquely proof regularize convex domain strictly convex int dom attains global minimum unique int dom equivalently assumption respectively dom global minimum attain uniquely virtue homeomorphism lemma restriction regularize transport polytope attains global minimum uniquely proof regularize bregman divergence positive factor additive constant  πkξ hence minimization convex equivalent bregman projection int dom onto accord function legendre int dom projection exists unique definition dual rot mover distance quantity define dual rot mover argmin remark sake notation omit dependence index dual rot mover proceed proposition  relation rmd associate bregman divergence proposition dual rot mover bregman projection onto transport polytope argmin πkξ proof consequence proof lemma indeed definition rot mover minimizes therefore unique bregman projection onto transport polytope geometrical interpretation regularization shrink matrix minimal bregman information rot mover distance proposition dual rot mover obtain argmin  πkξ proof develop bregman divergence definition πkξ scalar vanishes plus constant respect hence replace πkξ minimization defines additional interpretation shrink transport minimal bregman information proposition dual rot mover obtain argmin  πkπ proof equality generalize pythagorean theorem πkξ πkπ constant respect replace πkξ πkπ minimization characterizes remark proposition trivially global minimum attain transport polytope corollary assumption dual rot mover obtain argmin  πkπ proof int dom dom proof corollary sequel extend naturally definition dual rmd emd necessarily uniqueness dual rot mover geometrical interpretation bregman projection anymore however theorem duality theory equivalence primal dual rot dessein papadakis rouas theorem exists primal dual rot mover distance moreover correspond primal dual rot mover unique proof primal minimization domain constrain convex dom lagrangian minimization fix dual addition slater convex strictly feasible relative interior domain verify indeed existence strictly feasible continuity int dom duality zero duality gap maximization moreover finite attain already finite attain primal chain min therefore inequality equality minimizes lagrangian dual primal dual rmd primal dual rmd emd hence dual unique primal unique dual remark correspond addition multiple correspond rmd verify triangular inequality hence distance metric distance matrix nevertheless rmd symmetric invariant transposition separable regularizers  symmetric obtain dual rmd primal rmd rot mover distance dual rot mover distance increase continuous function proof increase construction inequality inequality obtain  inequality finally continuity dual rmd primal rmd arbitrary dual rot mover mover suppose discontinuity dual rmd monotonicity image dual rmd image primal rmd continuity whereas continuity primal exist contradiction duality theorem implies image primal rmd dual rmd tends dual rot mover distance converges lim dual rot mover converges norm transport minimal bregman information lim proof sequence positive tends associate rot mover compactness extract subsequence rot mover converges norm sake simplicity relabel subsequence construction    scalar bound inequality limit obtain converges semi continuity global minimum attain uniquely sequence converges norm hence dual rot mover converges norm tends continuity converges hence limit rmd tends tends dual rot mover distance converges mover distance lim dessein papadakis rouas proof consequence dual rmd continuous dom strictly convex dual rot mover converges norm tends mover minimal bregman information lim proof sequence positive converges associate rot mover compactness extract subsequence rot mover converges norm sake simplicity relabel subsequence construction    regularizer continuous polytope dom limit obtain converges therefore mover limit obtain unique mover minimal bregman information geometrical insight primal dual formulation enlighten intricate relation optimal transportation theory information geometry bregman divergence posse dually structure generalize pythagorean theorem information projection schematic underlie geometry rot construction global minimizer regularizer lemma bregman projection onto transport polytope minimal bregman information lemma linear restrict regularize transport polytope attains global minimum lemma minimizer primal rot mover definition interpret intersection bregman radius proposition intersection bregman radius generalize pythagorean theorem πkξ πkπ proposition corollary enforces bregman information constrain matrix transport minimal bregman information development introduce global minimizer regularize lemma regularize restrict attains global minimum uniquely lemma minimizer defines dual rot mover definition actually bregman projection onto proposition regularization bregman information equivalent regularize proposition regularize generalize pythagorean theorem πkξ πkπ proposition corollary enforces rot mover distance geometry regularize optimal transport bregman information shrink matrix transport minimal bregman information duality primal dual formulation primal dual rot mover regularization regularization theorem limit regularization obviously retrieve mover matrix duality intuitive additional constraint primal formulation equivalent πkξ πkπ analog penalty dual formulation respective exp minus boltzmann shannon entropy kullback leibler divergence retrieve exist specific addition readily generalize estimation contingency fix marginals matrix  divergence kullback leibler divergence rough estimate int dom contingency fix marginals estimate bregman projection onto argmin πkξ simply amount dual rot arbitrary penalty matrix dessein papadakis rouas finally bregman divergence invariant affine generator straightforward generalize rot shrink arbitrary prior matrix int dom transport indeed equivalent translate regularizer appropriate amount global minimizer attain desire equivalently amount translate matrix instead algorithmic derivation introduce algorithmic rot focus without lack generality dual efficiently via alternate bregman projection primal easily bisection simply alternate bregman projection project instead virtue lemma actually corresponds algorithm really relevant completely remove linear influence rot limit classical OT solver network simplex directly underlie bregman projection generic specifically develop separable divergence derive generic scheme asa nasa dual rot domain smooth convex regularizer within non negative orthant enhance algorithm separable sparse extension finally discus practical consideration simplify notation omit penalty index simply rot mover generic projection convex transport polytope intersection non negative orthant polyhedral subset affine subspace bregman projection onto obtain alternate bregman projection onto latter projection easy compute karush kuhn tucker bregman projection matrix int dom onto sufficient rot mover distance nontrivial admit elegant solver specific non separable mahalanobis distance define generate quadratic addition greatly simplify separable divergence encompass divergence  lagrange multiplier bregman projection matrix int dom onto respectively gradient int dom vanish int dom duality bregman projection onto equivalent unique vector sum respectively sum similarly lagrange multiplier expensive dimension evaluate matrix function entry actually modify entry matrix function evaluate nevertheless compute efficiently separable divergence non separable mahalanobis distance separable assume regularizer separable underlie bregman projection compute efficiently notation focus separable divergence wise regularizer chiefly omit index  emphasize however straightforward apply separable divergence wise regularizers notably enables wise regularizer separability karush kuhn tucker projection onto simplify primal parameter max πij dessein papadakis rouas increase equivalent dual parameter max θij projection onto primal parameter initial parallel subproblems dimension efficient non separable summarize lagrange multiplier respectively θij θij optimal sum however nontrivial analytical obtain specific intuitively factor additive multiplicative related  functional equation function linear exponential exp regularizers quadratic entropic constant actually translate matrix whereas constant refer quadratic assumption dykstra algorithm alternate bregman projection correction ensure nonnegativity projection onto polyhedral non negative orthant entropic assumption pocs technique alternate bregman projection correction non negativity already ensure domain regularizer latter reduces regularization  actually sinkhorn knopp algorithm hence euclidean norm associate euclidean distance entropic associate kullback leibler divergence reasonably exist analytical scheme sum constraint projection rot available solver employ instead simplicity assume hereafter twice continuously differentiable positive verify sufficient domain therefore newton raphson guarantee global convergence encompasses regularizers notably regularizers fermi dirac entropy norm hellinger distance global convergence met domain apply newton raphson careful initialization restrict interval detail practical fermi dirac entropy norm hellinger distance firstorder derivative increase convex domain increase concave derivative exist continuous vanish strategy apply norm rot mover distance derivative undefined vanishes parameter initialization bisection apply instead newton raphson apply newton raphson exploit function θij θij define respectively interval   dom  max θij  max θij continuous derivative θij θij positive strictly increase domain interval endpoint consist feasible construction verify sufficient global convergence unique hence  update θij θij θij θij converge optimal quadratic rate feasible construction initialization avoid intermediate lagrange multiplier update directly dual parameter initialization θij θij dessein papadakis rouas algorithm alternate algorithm uniquely solves uniquely solves convergence alternate algorithm assumption non negative constraint already ensure dom pocs technique projection onto obtain alternate bregman projection onto affine subspace linear convergence clearly underlie mapping output infinite alternative mapping swap projection instead actually amount swap input distribution transpose matrix obtain transpose rot mover focus choice without lack generality successive vector along iteration sequence obtain rot mover iteratively successive estimate efficient algorithm asa unique matrix dual parameter update alternate projection primal parameter algorithm update complexity vector obtain separable projection obtain iterate respective  update compactly matrix vector operation algorithm complexity update clearly detail update feature vector replication vector wise vector subtraction matrix subtraction matrix sum wise matrix function evaluation separability rot mover distance algorithm alternate algorithm separable convergence convergence convergence iteration convergence loop independent data dimension quadratic empirical complexity non negative alternate algorithm assumption non negative constraint dom ensure non negativity update cycle projection onto underlie mapping  essentially cyclic practical ensure non negativity output projection onto swap projection onto equivalent swap input distribution transpose matrix obtain transpose rot mover mapping exploit ensure non negativity sum constraint projection discus variant focus mention sequence non negative orthant polyhedral affine incorporate correction projection detail projection compute correction directly project obtain update update respective subset correction update difference project projection dykstra algorithm bregman divergence correction guarantee projection onto obtain linear convergence algorithm nasa matrix project projection correction dual parameter update accordingly finally primal parameter algorithm update complexity karush kuhn tucker lagrange multiplier obtain separable non negativity constraint obtain analytically sequence update greatly simplifies successive vector along iteration max max dessein papadakis rouas algorithm non negative alternate algorithm uniquely solves uniquely solves uniquely solves uniquely solves uniquely solves convergence max max max max max max max max max max max rot mover distance algorithm non negative alternate algorithm separable max convergence max convergence max convergence max efficient algorithm exploit difference algorithm matrix difference vector instead correction matrix algorithm interpret interleave update projection accord max operator accord respective scaling update nasa clearly complexity newton raphson matrix vector operation asa separable empirical complexity quadratic sparse extension separable develop sparse extension asa nasa update matrix becomes expensive data dimension instead infinite entry matrix meaning transport bin  correspond entry null eventually entry update remain rmd via frobenius inner compute without accounting discard entry equivalently indefinite wise convention naturally forbidden complexity dessein papadakis rouas finite entry typically chosen magnitude obtain linear instead quadratic empirical complexity asa nasa compatible strategy  assumption asa assumption nasa limit finite infinite necessarily negative enforce non negativity projection onto non negative orthant obtain sequence projection preserve desire zero algorithm infinite wise transport correspond bin theory understand extension dual formulation bregman projection assumption int dom hence dykstra algorithm readily applicable sparse version assumption however int dom sometimes dom  saito divergence nonetheless extend domain wise divergence origin continuity diagonal null akin absolutely continuous dominate radon  derivative generalize definition bregman divergence  pocs convention introduce notion locally affine sparse extension however sparse exist meaning transport transport polytope desire zero entry infinite obviously sparse enforce entry null existence sparse entry entry transport completely similarly entry entry transport empty completely unfortunately sufficient intuitive  theorem thoroughly elucidate sufficient sparse exist nontrivial  advocate compute desire sparsity gradually reduce sparsity computation drastically linear instead quadratic complexity lastly remark evident propose sparse extension non separable entry influence entry practical consideration  sinkhorn knopp algorithm fail converge numerical instability penalty unless numerical stabilization limitation machine precision entry exp zero memory issue similarly regularization notably via representation unconstrained project therefore propose actually competitive penalty rot mover exhibit significant amount smooth hence rot mover distance target traditional scheme interior network simplex addition bregman projection algorithm approximate tolerance termination criterion convergence exception sum constraint euclidean distance  divergence non negativity constraint separable obtain analytically algorithm converge projection approximate however relatively theory convergence sufficiently approximation furthermore approximation rough without affect convergence approximation sometimes alternate newton raphson throughout iteration algorithm systematic advocate safety tight tolerance auxiliary projection numerical instability newton raphson update separable divergence assumption due denominator limit  entry zero however update stable max truncation operator despite theoretical guarantee convergence without specifically entry hence bound  ˆθj respectively interestingly convergence update significantly initialization actual termination criterion auxiliary iteration compute marginal difference update matrix auxiliary iteration projection sum respectively iteration algorithm marginals simultaneously typically quasi norm ass marginal difference auxiliary tolerance sufficient precision approximation alternative quantity absolute relative termination variation quasi norm update matrix update distance auxiliary tolerance reasonable quadratic rate convergence  versus linear alternate bregman projection cauchy schwarz inequality convergence checked iteration iteration reduce underlie compute termination criterion fix maximum auxiliary iteration limit overall regard implementation matrix vector operation asa nasa separable calculation gpu processing multiple input distribution parallel directly primal parameter sinkhorn knopp algorithm readily sparse exist library rot however specific library sparse extension null entry transport null entry dual parameter tailor data structure operation dessein papadakis rouas matrix cod therefore implement focus non sparse version finally although implicitly assume throughout entry strictly comprise theoretical issue explicitly null entry input distribution intuitively null entry transport null correspond null entry respectively separable simply remove entry reduce rot  correspond null entry rot mover sparse extension algorithm strategy theoretical standpoint non separable however straightforward influence entry interleave regularizer nonetheless int dom assumption int dom apply nasa without modification notably mahalanobis distance domain non separable regularizer assumption easy account null entry constraint qualification int dom due mandatory null entry transport nevertheless regularizers assumption separable lastly cope entry transport polytope reduces singleton unique transport rot mover classical regularizers divergence discus specificity asa algorithm nasa algorithm rot classical regularizers associate divergence separable regularizers assumption boltzmann shannon entropy related kullback leibler divergence  burg entropy related  saito divergence   entropy related logistic loss function  parametric potential related divergence beta discus separable quasi norm LPQN slight adaptation assumption separable regularizers assumption related norm lpn euclidean norm related euclidean distance EUC hellinger distance hell finally non separable regularizer assumption via quadratic relation mahalanobis distance plot separable regularizers regularizers correspond divergence sum lastly related derivative instantiate separable version asa algorithm nasa algorithm accordingly boltzmann shannon entropy kullback leibler divergence assumption minus boltzmann shannon entropy associate kullback leibler divergence hence rot asa scheme addition update pocs technique analytically rot mover distance πkξ πkξ dom dom boltzmann shannon entropy kullback leibler divergence burg entropy  saito divergence fermi dirac entropy logistic loss function potential divergence  quasi norm  norm sgn euclidean norm euclidean distance hellinger distance quadratic mahalanobis distance vec vec vec vec convex regularizers associate bregman divergence  beta beta beta LPQN LPQN LPQN lpn lpn lpn hell   EUC separable regularizers sinkhorn knopp algorithm specifically projection amount normalize sum respectively diag diag dessein papadakis rouas boltzmann shannon entropy exp exp burg entropy fermi dirac entropy exp exp exp exp potential quasi norm  norm sgn sgn euclidean norm hellinger distance separable regularizers related derivative optimize remark iterates couple projection verify diag diag exp vector satisfy recursion convention allows implementation perform  multiplication fix matrix exp wise vector multiplication per update diag diag rot mover distance matrix diag diag precomputed burg entropy  saito divergence assumption minus burg entropy associate  divergence rot asa scheme eventually newton raphson update alternate projection pocs technique optimize compute wise matrix inverse numerator perform wise matrix multiplication matrix obtain matrix denominator instead apply additional elementwise matrix convex strictly increase positive everywhere convergence update guaranteed fermi dirac entropy logistic loss function assumption minus fermi dirac entropy entropy associate logistic loss function rot asa scheme newton raphson update alternate projection pocs technique exp exp exp exp exp exp exp exp optimize wise matrix exponential exp apply wise matrix temporary matrix exp obtain matrix numerator lastly perform wise matrix matrix obtain matrix denominator additional elementwise matrix wise matrix exponential however strictly increase positive everywhere neither convex concave verify sufficient global convergence newton raphson nevertheless convex concave respectively interval respectively respectively sort dessein papadakis rouas increase interval sufficient verify decompose respectively sum increase convex increase concave function hence global convergence interval contains restrict interval indeed θij similarly θij suffices initialize  max θij respectively  max θij guarantee convergence update potential divergence assumption potential associate divergence hence rot asa scheme newton raphson update alternate projection pocs technique optimize compute temporary matrix apply wise matrix temporary matrix obtain matrix denominator lastly perform wise matrix multiplication matrix obtain matrix numerator wise matrix convex strictly increase positive convergence update guaranteed interestingly regularizer tends minus burg boltzmann shannon entropy limit respectively therefore divergence interpolate  saito kullback leibler divergence finally remark regularizer define parameter formula verify assumption quasi norm regularizers assumption verify dom hence primal formulation dom however straightforward dual formulation rot asa scheme apply matrix null entry dom eventually newton raphson update alternate projection pocs technique rot mover distance optimize compute temporary matrix apply wise matrix obtain matrix denominator lastly perform wise matrix multiplication matrix obtain matrix numerator wise matrix convex strictly increase positive everywhere convergence update guaranteed norm assumption norm rot nasa scheme newton raphson update alternate projection dykstra algorithm sgn sgn denote respective update optimize compute temporary matrix apply wise matrix obtain matrix denominator lastly perform wise matrix multiplication matrix sgn obtain matrix numerator wise matrix vector replication matrix subtraction however strictly increase neither convex concave verify sufficient global convergence newton raphson moreover vanishes differentiable nevertheless concave convex convex concave respectively interval respectively respectively sort increase sufficient verify interior interval decompose respectively sum increase convex increase concave function hence global convergence interior interval contains remove finite endpoint ensure differentiability positivity prune interval indeed θij  max θij similarly θij dessein papadakis rouas  max θij lastly restrict interval finite bound instead indeed θij similarly θij perform binary parallel within remain bound interval respectively initialization midpoint guarantee convergence update worstcase logarithmic linear operation complexity instead binary regularizer specializes euclidean norm euclidean distance associate divergence addition formula convention actually constant eventually projection resort analytical algorithm derive specifically euclidean distance penalty account regularizer halve euclidean norm euclidean distance assumption euclidean norm associate euclidean distance therefore rot nasa scheme dykstra algorithm actually specifically nonnegative projection reduces max interleave projection amount offset amount sum respectively remark euclidean distance divergence formula however divergence generate legendre domain restrict whereas actually extend regularizer legendre assumption assumption hellinger distance assumption regularizer akin hellinger distance hence rot nasa scheme newton raphson rot mover distance update alternate projection dykstra algorithm denote respective update optimize compute temporary matrix apply wise matrix temporary matrix perform wise matrix multiplication matrix obtain matrix denominator lastly wise matrix multiplication temporary matrix obtain matrix numerator wise matrix vector replication matrix subtraction however strictly increase positive everywhere neither convex concave verify sufficient global convergence newton raphson nevertheless convex concave respectively interval respectively respectively sort increase interval sufficient verify decompose respectively sum increase convex increase concave function hence global convergence interval contains prune interval indeed θij  max θij similarly θij  max θij lastly restrict interval finite bound instead indeed θij similarly θij perform binary parallel within remain interval respectively initialization midpoint guarantee convergence update logarithmic linear operation complexity instead binary quadratic mahalanobis distance assumption quadratic vec vec positive definite matrix associate mahalanobis distance rot dessein papadakis rouas mover matrix input distribution nasa scheme diagonal matrix regularizer separable newton raphson update alternate projection dykstra algorithm euclidean distance appropriate non diagonal matrix however regularizer separable anymore resort generic nasa scheme projection amount convex quadratic program linear equality constraint classical technique  null approach krylov subspace active strategy non negative projection reduces convex quadratic program linear inequality constraint elegantly iterative algorithm non negative quadratic program propose multiplicative update complexity recommend sparse matrix diagonal structure magnitude non null entry obtain quadratic instead  empirical complexity experimental synthetic showcase behavior regularizers penalty output computational recognition application audio scene classification dataset synthetic data visualize regularizers penalty synthetic data input distribution discretize normalize continuous density uniform grid dimension univariate normal variance mixture normal respective variance matrix euclidean distance  grid input distribution matrix unique mover compute classical OT solver standard setting rot mover distance separable regularizers introduce regularizers sensible rot mover manually tune penalty feature amount regularization comparison constant similarly limit tends infinity simply obtain algorithm quasi norm null fix quasi norm limit iteration algorithm tolerance convergence norm marginal difference checked iteration termination criterion rot mover obtain rot regularizers penalty visualize rot mover converge mover penalty theoretically nevertheless rot mover exhibit regularizers intermediary penalty limit penalty grows infinity obtain transport minimal bregman information theoretically ellipsoidal   entropy kullback leibler divergence meaning relatively bin  fermi dirac entropy logistic loss function explain synthetic rot mover regularizers equivalent constant neighborhood zero profile rectangular  burg entropy  saito divergence imply across bin intermediary beta potential divergence allows interpolation limit rectangle ellipsoid parameter actually regularization LPQN quasi norm ellipsoid rectangle parameter increase lpn norm obtain feature interpolate  EUC euclidean norm euclidean distance parameter diamond profile obtain hell hellinger distance due rot mover regularizers equivalent constant neighborhood zero lastly remark penalty extreme allows smooth interpolation mover optimal minimal bregman information report computational convergence regularizers penalty criterion relative variation tolerance norm loop alternate bregman projection absolute variation tolerance norm auxiliary loop  synthetic data dimension ass influence already specifically sinkhorn distance compute rot distance faster important regularization regularizers assumption extra projection onto non negative orthant intuitively computational effort dessein papadakis rouas   beta beta  beta LPQN LPQN LPQN lpn lpn EUC lpn hell rot mover regularizers penalty rot mover distance verify assumption addition projection  expression algorithm faster illustrate influence data dimension difference rot classical OT performance dimension rmd competitive emd historical implementation emd super cubic complexity emd emd becomes prohibitive data dimension increase contrast rmd nevertheless underlined reasonable dimension computation emd obtain recent optimize implementation network simplex solver emd dimension super cubic complexity emd attractive competitive rmd dimension consequence numerical alternative algorithm rot reasonable dimension rely conditional gradient indeed imply iterative resolution linearize rot reformulate emd therefore network simplex approach lastly interpretation timing mention emd scheme matlab native implementation via compile  file hence emd code optimize comparison pure matlab prototype code rmd plausible optimize implementation algorithm competitive context audio classification ass context audio classification specifically address task acoustic scene classification goal assign predefined characterizes environment capture framework   challenge  acoustic scene database data consists audio recording khz sample rate resolution metadata contains truth annotation acoustic scene file library caf restaurant grocery residential park beach bus tram metro audio split subset respectively per development evaluation file training fold validation setup training classification accuracy correctly classify evaluate baseline database comparison mel frequency cepstral coefficient MFCC  feature gaussian mixture model GMM classification GMM diagonal covariance matrix per http robotics stanford edu  emd default htm http liris    http github com  external emd http  github code http math    code php dessein papadakis rouas algorithm rmd  rmd  beta rmd beta rmd  beta rmd LPQN rmd LPQN rmd LPQN rmd lpn rmd lpn rmd EUC lpn rmd hell emd emd algorithm rmd  rmd  beta rmd beta rmd  beta rmd LPQN rmd LPQN rmd LPQN rmd lpn rmd lpn rmd EUC lpn rmd hell emd emd computational convergence regularizers penalty dimension expectation maximization EM concatenate normalize variance extract MFCCs training file assign GMM maximum likelihood extract MFCCs file MFCCs independent sample normalize variance respective baseline default parameter frame hop dimensional MFCCs comprise static plus delta acceleration coefficient extract rot mover distance standard setting  GMM component standard setting  MFCCs potentially negative OT cannot apply directly feature therefore approach compute OT appropriately GMMs estimate MFCCs instead propose principle implement pipeline baseline comparison difference GMM EM training instead normalization MFCCs per remove component typically model spurious GMM component discard processing variance instead apply GMM classifier individual model exploit vector machine svm classifier exponential kernel svm introduce distance mixture rmd exp exponential decay rate kernel parameter respective component GMMs matrix depends symmetrize kullback leibler divergence  divergence pairwise gaussian component  vuut    respectively variance MFCC feature component mixture respectively component mixture svm classifier implement standard setting libsvm additional margin parameter tune kernel positive definite libsvm relevant classification guarantee convergence stationary separable regularizers penalty rmd comparison emd distance matrix transpose compute average remove asymmetry due practical issue iteration limited loop algorithm auxiliary loop  tolerance loop convergence norm marginal difference checked iteration termination criterion parameter penalty manually chosen successive regularizer tune automatically validation obtain accuracy per report optimal penalty validation regularizer optimal parameter displayed actually independently kernel propose svm vector machine classifier consistently outperforms baseline GMM dessein papadakis rouas gaussian mixture model classifier prof benefit incorporate individual information per via svm exploit global information per GMM demonstrates relevance OT rot kernel GMMs svm pipeline rmd rot mover distance kernel competitive emd mover distance kernel propose regularizers EUC perform consequence regularization profile EUC equivalently lpn across bin imply lack robustness slight variation variance GMM component reduce parameter lpn brings competitive emd improve accuracy obtain LPQN compromise clearly outperforms emd remark accuracy lpn LPQN unimodal respect regularization suspect performance function amount regularization couple allows compromise within regime concern beta exist sinkhorn knopp algorithm  improve accuracy emd increase  performance obtain slightly improves emd slightly degrades performance emd  interestingly overall accuracy application obtain hell EUC margin contrast synthetic data dimension  respectively EUC hell behave similarly due equivalence constant transport transport dimension input distribution typically importance regularizer actual task inherent criterion data dimension conclusion formulate unified framework smooth convex regularization discrete OT derive algorithmic rot detailed specificity classical regularizers associate divergence literature finally synthetic illustrate propose relevance rot rmd application audio scene classification obtain encourage development discus perspective future investigation firstly ass regularizers notably affine geometrical viewpoint transformation equivalent simply translate matrix bregman divergence regularizer therefore parametrize interpolate regularizers tune translation parameter accord application recent developed independently  entropy regularize OT hoc solver regularizers integrate readily rot mover distance classifier accuracy GMM svm emd rmd   beta beta  beta LPQN LPQN LPQN lpn lpn EUC lpn hell audio classification framework alternate bregman projection  entropy equivalent potential quasi norm affine another direction extend theoretical boltzmann shannon entropy associate kullback leibler divergence specifically related rot mover converges norm mover exponential rate penalty decrease straightforward however generalize regularizers divergence addition worth elucidate technical restriction metric triangular inequality similarly sinkhorn distance recognition task text image audio signal processing intuitive possibility retrieval classification various data model via histogram feature GMMs potential approach address exploit rmd directly kernel svm acoustic scene task relevant insight choice regularizer actual develop automatic tune regularization parameter matrix data emd mostly focus separable regularizers relevant quadratic associate mahalanobis distance application maybe propose parametric scheme quadratic regularizer data lastly prospective rmd instead sinkhorn distance recent built entropic regularization mention variational rot formulate statistical inference notably parameter estimation finite mixture model minimize loss function rmd leverage application rot framework machine development involve theoretical effort maturity address practical setup