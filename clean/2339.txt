linear subspace data corrupt outlier classical approach typically subspace dimension relative ambient dimension approach dual representation subspace hence aim orthogonal complement particularly suitable subspace dimension ambient dimension subspace relative dimension compute normal vector inlier subspace non convex minimization sphere dual principal component pursuit DPCP theoretical guarantee global DPCP vector orthogonal complement inlier subspace moreover relax non convex DPCP recursion linear program converge finite vector orthogonal subspace inlier subspace hyperplane recursion linear program converge global minimum non convex DPCP finite propose algorithm alternate minimization iteratively suitable data synthetic data propose handle outlier relative dimension context geometry computer vision propose useful superior alternative traditional RANSAC approach computer vision application keywords outlier robust principal component analysis relative dimension minimization non convex optimization linear program trifocal tensor introduction principal component analysis pca fundamental technique data analysis ubiquitous application engineering economics sociology chemistry physic genetics  application data matrix data coordinate dimension pca dimensional linear subspace Sˆ closest euclidean although optimization associate pca non convex admit singular decomposition svd Sˆ subspace span singular vector Sˆ model data meaningful data approximately linear structure underlie dimension dimensional subspace principal component behave mild principal angle Sˆ relatively Sˆ optimal gaussian however application data corrupt outlier data matrix angle underlie truth subspace associate inlier unknown permutation principal angle pca estimate Sˆ definition principal component orthogonal direction maximal correlation phenomenon outlier almost datasets important outlier detection pca traditionally outlier detection robust statistic notable influence detection multivariate trim estimator iteratively reweighted IRLS random sample consensus RANSAC usually non convex optimization converge local minimum addition theoretical analysis usually limited computational complexity RANSAC recently attractive directly convex optimization inspire rank representation compress admit theoretical guarantee efficient implementation principle applicable subspace relative dimension theoretical guarantee recent reaper handle subspace dimension adopt dual approach robust pca presence outlier allows explicitly transcend relative dimension regime   handle outlier hyperplanes subspace maximal relative dimension regime classic fail approach absence inliers inside hyperplane span contains underlie linear subspace associate inliers suggests instead attempt directly dimensional linear subspace entire dataset maximal hyperplane contains dataset inliers precise shortly inside outlier maximal hyperplane entire inliers possibly outlier remove outside hyperplane easy robust pca potentially address exist alternatively maximal hyperplane span dual principal component perpendicular maximal hyperplanes dual principal component analysis  dual principal component pursuit inlier subspace precisely outlier outside intersection formalize maximal hyperplanes respect  relax non convex sphere refer dual principal component pursuit DPCP theoretical guarantee global DPCP vector orthogonal linear subspace associate inliers dual principal component moreover relax non convex DPCP recursion linear program mild converge dual principal component finite inlier subspace hyperplane linear program recursion converge global minimum non convex finite furthermore propose algorithm alternate minimization IRLS suitable data extensive synthetic data propose handle outlier subspace relative dimension image DPCP perform par notation shorthand RHS similarly LHS notation isomorphism whatever category LHS RHS belong notation denotes approximation positive integer positive  denote integer belong subspace dim denotes dimension orthogonal projection onto vector acute angle define unique angle vector linear subspace principal angle denotes sum subspace orthogonal complement subspace denote span subspace span denotes sphere vector define otherwise matrix diag denotes vector diagonal matrix notation indicates positive semi definite matrix mild abuse notation treat occasion matrix notation signifies similarly matrix notation signifies notation denotes function define finally ith entry  norm  PD vector function define sgn tsakiris vidal prior briefly review linear subspace data presence outlier literature vast account exhaustive exception mainly focus convex optimization robust statistic huber  online subspace regression reader refer excellent literature review  zhang recent survey   finally preliminary associate publish conference review extend approach cluster data multiple subspace robust pca structure outlier continuation certainly concept algorithm sufficiently distinct machinery fully establish RANSAC popular outlier detection pca random sample consensus RANSAC RANSAC alternate randomly sample subset cardinality dataset compute dimensional subspace subset subspace Sˆ maximizes entire dataset approximately Sˆ within error RANSAC typically ambient dimension yield quality subspace estimate regardless subspace relative dimension however increase RANSAC becomes inefficient outlier ratio otherwise prohibitive trial obtain outlier sample furnish reliable model additionally RANSAC input estimate dimension subspace thresholding parameter distinguish outlier inliers naturally performance RANSAC sensitive parameter RPCA unlike RANSAC outlier detection pca primarily convex optimization important RPCA inspire robust principal component analysis RPCA algorithm RPCA computes norm decomposition data matrix instead decomposition specifically RPCA solves optimization min attempt decompose data matrix sum rank matrix matrix non zero associate inliers 0D associate outlier 0D optimization convex admits theoretical guarantee proof theorem tsakiris vidal inaccuracy statement incomplete statement theorem denotes nuclear norm sum singular matrix define sum euclidean norm matrix dual principal component pursuit efficient algorithm alternate direction multiplier ADMM however succeed intrinsic dimension inliers otherwise 0D rank outlier ratio otherwise 0D sparse finally RPCA input subspace dimension directly compute estimate subspace subspace obtain subsequently apply classic pca estimate SE RPCA outlier rank inlier achieve exploit expressiveness SE data matrix notion popularize  vidal subspace cluster specifically inlier express linear combination inliers outlier principle coefficient matrix obtain convex optimization min  diag extra constraint prevents trivial hypothesis declare outlier norm correspond   explicit formula SE RPCA admits theoretical guarantee efficient ADMM  tions moreover recent demonstrate information expressive matrix exploit identify outlier random affinity graph define yield superior thresholding norm contrast RPCA principle fails presence outlier SE RPCA perform existence sparse subspace preserve expressive outlier similarly RPCA SE RPCA directly estimate subspace dimension nevertheless knowledge furnish actual subspace estimate entail remove outlier judiciously chosen threshold apply pca reaper another robust subspace admits theoretical analysis reaper conceptually associate optimization min ID orthogonal projection trace vector denotes matrix denotes orthogonal projection onto dimensional linear subspace  orthonormal basis nonconvex relaxed convex semi definite program min ID ID trace tsakiris vidal obtain approximate rank orthogonal projector closest global nuclear norm  obtain within neighborhood  correspond underlie inlier subspace semi definite program become prohibitively expensive moderate ambient dimension consequence author propose iteratively reweighted IRLS scheme obtain numerical objective converge neighborhood optimal objective advantage reaper respect RPCA SE RPCA theoretical subspace arbitrarily relative dimension outlier ratio sufficiently precisely RANSAC handle relative dimension difference RANSAC reaper latter employ convex optimization fix relative dimension computational budget reaper tolerate considerably outlier ratio RANSAC coherence pursuit cop recent   analyzes efficient algorithm detect inlier pairwise coherence hence coherence pursuit cop insight cop hypothesis inliers dimensional subspace inlier tend significantly coherence dataset outlier hence pairwise coherence matrix norm correspond inliers indeed cop descend norm selects sufficiently span yield dimensional subspace similarly SE RPCA performance cop significantly degrade outlier increase outlier remains sufficiently incoherent dataset demonstrate   cop competitive performance admits extensive theoretical analysis pca finally mention pca orthogonal complement subspace similarly propose nevertheless pca slightly unusual learns hyperplanes hyperplanes minimize distance oppose euclidean distance pca reaper overall theoretical guarantee pca subspace concerned addition pca linear program ambient dimension computationally expensive formulation formulate address data model motivate conceptual computational data model employ deterministic data model data dual principal component pursuit inliers intersection sphere unknown subspace unknown dimension outlier sphere unknown permutation indicates inlier outlier finally assume relation imply inclusion tuple linearly independent consequence tuple inliers tuple outlier linearly independent finally avoid degenerate situation assume conceptual formulation partition assumption dimension however anything dimensional hyperplane hence inside subspace contains instead meaningful linear subspace contains inliers outlier intrinsic dimension inliers choice hyperplane contains inliers dataset hyperplane contains inliers hyperplanes inliers exist non zero vector orthogonal complement linear subspace associate inliers defines hyperplane normal vector contains inliers hyperplane disposal partition dataset remain definition consist purely outlier safely replace dataset reconsider robust pca emphasize inliers outlier dramatically outlier apply exist     task identify remain outlier demonstrates suppose inliers linear subspace dimension suppose dataset corrupt outlier hyperplane contains inliers dimensionality inliers dimensionality hyperplane linearly independent direction hyperplane outlier outlier violate hypothesis remove dataset inliers outlier application RANSAC identify remain outlier trial outlier entire dataset degenerate hyperplane ambient hence reduce coordinate representation data eventually satisfy assumption tsakiris vidal alternatively dimension entire dataset removal hyperplane contains inliers normal vector linearly independent orthogonal normal vector linear subspace dimension contains inliers consequence span hyperplane sought normal vector span  linearly independent hyperplanes situation subspace dimension dim contains hence declare inlier intersection hyperplanes hyperplane pursuit minimization propose optimization framework computation hyperplane solves hyperplane contains inliers proceed definition definition hyperplane maximal respect dataset contains maximal data hyperplane principle hyperplanes maximal respect proposition proof proposition suppose hyperplane maximal respect dataset contains inliers proposition restrict hyperplanes inliers subset hyperplanes maximal respect dataset advantage approach immediate hyperplanes maximal respect principle computable precisely optimization min hyperplane span contains maximal normal vector maximal  respect matrix non zero entry minimal combinatorial admit efficient relaxation min context refer dual principal component pursuit DPCP arises theorem global orthogonal inlier subspace span  constraint efficiently theoretical guarantee hyperplanes linearly independent normal vector linearly independent dual principal component pursuit emphasize optimization interestingly appearance literature aware spath watson author propose recursion convex argmin  iteration computationally equivalent linear program recursion appeal candidate non convex spath watson converges critical finite appendix converges global minimum optimization specifically propose replace quadratic constraint linear constraint vector approximately alternate minimization riemannian trust approach employ finally closely related non convex associate reaper suppose reaper  orthogonal projection hyperplane normal vector ID readily becomes identical dual principal component pursuit theory establish analysis framework discus theoretical regard global optimum non convex recursion convex relaxation theoretical investigation establish connection discrete underlie continuous continuous finite inliers outlier uniform distribution respective inlier outlier easy analyze analysis theorem reveals optimal continuous analogue orthogonal inlier continuous recursion correspond converge normal vector inlier respectively suggests distribution data discrete discrete recursion adjective discrete refers finite analysis discrete inspire analysis continuous counterpart link formally capture discrepancy bound introduce characterize global optimal convergence recursion theorem analogue theorem theorem formulation compute orthogonal complement linear subspace presence outlier proof theorem intermediate defer unaware spath watson independently propose recursion tsakiris vidal formulation theoretical analysis underlie continuous discrete version continuous easy analyze outlier inliers recall notation unknown permutation define function define discrete associate outlier inliers respectively dirac function satisfy SD dµSD  uniform definition objective function sum expectation function SD dµSD SD dµSD SD dµSD SD dµSD   hence optimization convenience min equivalent min   similarly recursion convenience argmin equivalent recursion argmin   dual principal component pursuit discrete  continuous   respectively latter uniform hence purpose understand global minimizer limit meaningful replace discrete continuous counterpart   continuous min   argmin   important continuous geometric global vector orthogonal inlier subspace similarly sequence vector converges vector orthogonal inlier subspace correctness continuous theoretical verification correctness discrete formulation objective establish precisely direction continuous objective function suggestive define average height hemisphere directly compute SD dµSD odd coordinate vector factorial define odd proof proposition objective function continuous rewrite   principal angle subspace consequence outlier objective function becomes constant hence outlier affect optimal moreover inlier objective function depends cosine principal angle subspace minimize orthogonal subspace continuous proof theorem global orthogonal irrespective outlier inlier continuous objective function similarly proof continuous recursion converge vector orthogonal inlier subspace finite regardless outlier inlier tsakiris vidal theorem sequence generate recursion principal angle define sequence converges norm finite iteration tan tan sin sin otherwise remarkable accord theorem continuous recursion converges vector orthogonal inlier subspace finite moreover relation tan convergence occurs interpret angle initial estimate inlier subspace positive arbitrary fix outlier sufficiently inliers satisfied convergence occurs likewise satisfied sufficiently conversely fix inliers outlier sufficiently angle converges generally quantity tan sin sin accord theorem faster converges discrepancy bound continuous discrete analysis framework bound deviation underlie geometric quantity average outlier average inlier respect continuous counterpart recall discrete objective function  continuous counterpart  discrete objective depends outlier function average outlier respect define dual principal component pursuit define vector function SD dµSD SD  define discrete approximation continuous integral SD dµSD lemma proof lemma recall definition SD dµSD SD  continuous average outlier respect  define maximum error discrete continuous average outlier varies max SD establish uniformly distribute becomes notion uniformity deterministic capture spherical cap discrepancy define SD sup IC  supremum spherical cap sphere spherical cap intersection IC indicator function inside zero otherwise spherical cap discrepancy SD precisely supremum error approximate integral indicator function spherical cap via average indicator function intuitively SD capture discrete equation associate  uniformly distribute SD function SD decrease rate consequence uniformly distribute correspond suffices bound maximum integration error quantity proportional spherical cap discrepancy SD inequality bound approximation error integral function variation function discrepancy finite necessarily spherical cap discrepancy discrepancy widely    inequality exist integration function hypercube inequality integration function sphere tsakiris vidal additional assumption distribution finite nevertheless function associate   inequality described lemma proof lemma finite subset max SD  SD SD define respectively attention inlier discrete objective function slightly complicate outlier SD  average inlier respect discrete approximation integral SD dµSD lemma proof lemma SD dµSD SD  replace orthogonal projection onto continuous average inlier respect  define maximum error discrete continuous average inliers varies maximum error varies max SD max SD almost identical argument establish lemma discrepancy inliers define exactly replace supremum spherical cap author grateful prof  harman dual principal component pursuit global optimality convergence discrete analyze discrete associate discrete recursion adjective discrete refers finite sample union outlier inliers discrete version continuous respectively continuous posse geometric global minimizer theorem recursion sequence vector converges finite theorem discrepancy bound uniformity statement definition definition integer define RY maximum circumradius polytopes   distinct integer circumradius bound subset infimum radius euclidean subset define RO max RO RX theorem inliers outlier sufficiently uniformly distribute uniformity parameter sufficiently global orthogonal inlier subspace precisely theorem suppose ratio outlier inliers satisfies min RO RO RO global orthogonal span towards interpret theorem asymptotic infinity ratio constant assume inliers outlier perfectly distribute limit hypothesis limn  SD lemma inequality limn  satisfied suggests possibly normal inliers arbitrarily outlier irrespectively subspace dimension along uniformity hypothesis increase inliers outlier decrease tsakiris vidal constant satisfied possibly yield normal inliers irrespectively intrinsic dimension becomes evident numerical evaluation intrinsic dimension inliers manifest quantity recall decrease function consequently RHS becomes easy satisfy explicitly formally quantity decay approximate rate respectively satisfied roughly inequality roughly constant constant constant constant independent conclusion drawn inequality contrast analysis haystack model reaper phenomenon recursion convex relaxation accord theorem continuous recursion converges finite iteration vector orthogonal span initialization equivalently intuitively discrete discrete recursion successful theorem strictly theorem proof formalizes intuition theorem suppose sequence generate recursion principal angle span suppose RO finite iteration sequence converges norm vector orthogonal span expression defines angle moreover theorem interpret asymptotic argument theorem bound angle tends zero infinity constant uniformly distribute inliers outlier closer span emphasize theorem asserts correctness linear program recursion recover vector orthogonal span concerned initial motivation theorem assert global minimizer however indeed inlier subspace hyperplane unique vector orthogonal normal vector hyperplane unique global minimizer limit theorem ongoing research conclusion formal dual principal component pursuit proof proof earlier proof proposition hypothesis hyperplane exists hyperplane contains indeed inliers outlier hyperplane generate denote normal vector hyperplane contains inliers orthogonal inliers tuple inliers basis span consequence orthogonal span implies proof proposition rotation standard basis vector expectation LHS becomes  SD dµSD SD dµSD SD dµSD SD  dµSD SD dµSD SD dµSD coordinate representation expectation LHS evaluates decompose   SD dµSD SD dµSD SD dµSD SD dµSD coordinate representation respect basis  SD dµSD  average height hemisphere finally principal angle subspace  tsakiris vidal proof theorem constraint min immediate global minimum attain corresponds proof theorem iteration optimization associate min RD principal angle subspace principal angle global minimizer principal angle decrease objective function iteration implies contradiction optimality hence sequence non decrease hypothesis angle constraint optimization equivalently min RD orthogonal equality consequence suppose normalize orthogonal projection onto global minimizer dimensional span norm global minimizer feasible vector sin already objective sin sin without loss generality restrict denote normalize projection onto vector obtain rotate dual principal component pursuit towards spherical angle spherical arc spherical arc spherical cosine sin sin  suppose implies sin sin implies principal angle strictly feasible vector strictly objective summarize global minimizer angle span hence rewrite equivalent min positive approach negative approach function continuous differentiable interval derivative sin sin derivative zero sin sin sin sin equivalently tan strictly decrease interval attain minimum precisely corresponds choice sin earlier argument tan equation defines angle sin sin attain global minimum tsakiris vidal consequence tan sin sin inductively tan increase quantity bound sin sin increase becomes equation tan global minimizer vector sin finally hypothesis tan sin sin sin sin maximal iteration become tan tan sin sin iteration achieve orthogonality proof lemma rotation canonical vector SD  SD  SD  SD  cartesian coordinate recall definition equation SD  SD dµSD moreover SD  consequently integral becomes SD  SD  cde  proof lemma  dual principal component pursuit vector orthogonal SD bound SD towards  SD dµSD equality definition recall error approximate integral average super union spherical cap sup SD inf SD entire argument proof theorem inequality measurable function respect  directly SD  SD  SD dµSD define argument difference sup SD inf SD SD inequality establishes SD concludes proof lemma proof lemma  SD  SD  express basis lemma replace switch standard basis tsakiris vidal proof theorem theorem lemma lemma proof inequality simpler orthogonal projection onto definition exists vector norm  inner principal angle span optimal satisfy optimality relation sgn scalar lagrange multiplier parameter sgn sub differential norm sake contradiction suppose lemma min violates inequality hypothesis hence assume hypothesis proposition orthogonal precisely belong without loss generality belong exist   similarly equivalently   dual principal component pursuit compactly  normalize projection onto nonzero hypothesis    definition respectively  becomes linearly independent define dimensional subspace span project onto vector image linear combination inner respectively angle angle respect obtain upper bound magnitude kuk vector linear combination obtain tsakiris vidal dimensional exists vector orthogonal orthogonal project equation onto span obtain  equation orthogonal equation implies implies invoke upper bound RO RX definition RO definition RO equivalently RO RO quadratic polynomial constant negative inequality hypothesis exactly positive negative consequence polynomial non negative implies positive polynomial RO lemma min implies latter inequality equivalent inequality RO RO dual principal component pursuit quadratic polynomial inequality hypothesis polynomial positive constant negative inequality equivalent unique positive polynomial contradicts inequality hypothesis consequently initial hypothesis proof theorem geometric proof theorem geometric intuition underlies proof theorem instructive discussion inlier simply ambient dimensional norm fix vector span inlier examine global optimization assume orthogonal intuitively conclusion sufficiently inliers argue intuitive principal angle capture precisely proof theorem suppose non orthogonal inlier proposition orthogonal outlier optimality specializes mob simply inside conv mob span mob operator minkowski sum conv mob translation polytope conv mob affine originate conv mob direction illustrate happens angle recall concentrate around illustrate unbounded polytope mob conv span optimality equation infeasible indicates critical vector angle unlikely exist critical exist angle illustrate however critical global minimizers angle yield objective capture precisely equation proof theorem hence possibility critical global minimizers exist inliers significantly outlier illustrate precise notion inliers exist respect outlier capture theorem tsakiris vidal mob conv span mob conv mob geometry optimality polytope mob conv span optimality span mob conv span mob conv mob geometry optimality critical exists angle polytope mob conv span however global minimizer angle yield objective analogous described albeit harder visualize reference equation optimality feasible exist inliers outlier orthogonal conv conv affine parallel span proof theorem reduce described reduction precisely equation project optimality equation onto dimensional subspace argument projection consist technical treatment intuition proof theorem expression defines angle establish inlier dual principal component pursuit mob conv span mob conv mob geometry optimality critical exist moreover angle polytope mob conv span contains moreover critical global minimizers theorem prevents hypothesis sake contradiction suppose suppose   normalize projection onto lemma upper bound LHS bound RHS obtain equivalently contradicts inequality consequently implies equivalently  normalize projection onto lemma obtain contradiction tsakiris vidal proof theorem proposition sequence converges critical finite already orthogonal identical argument proof theorem principal angle satisfies RO however due lemma substitute bound contradicts dual principal component pursuit algorithm algorithm estimate inlier linear subspace presence outlier specifically algorithmic contribution implementation recursion via linear program propose alternative compute dual principal component iteratively reweighted performs almost recursion significantly efficient finally variation DPCP optimization suitable noisy data propose heuristic DPCP via linear program DPCP LP sake argument suppose inliers inliers span linear subspace dimension theorem suggests mechanism obtain recursion linear program sequence converges identify limit due computational constraint usually terminates recursion objective converges within maximal tmax iteration obtains normal vector compute vector possibility hyperplane dimension dim identify subspace model hyperplane define normal dim proceed vector approximately orthogonal compute orthogonal basis orthogonal complement naturally algorithm estimate  inlier subspace span algorithm initializes precisely singular vector corresponds singular projection onto span demonstrate choice angle inlier subspace typically desirable recursion theorem refer algorithm DPCP LP emphasize optimization associate iteration recursion linear program iteration optimization min dual principal component pursuit algorithm dual principal component pursuit via linear program procedure DPCP LP tmax argmin tmax   return procedure equivalently standard linear program min efficiently optimize purpose linear program solver gurobi DPCP via iteratively reweighted DPCP IRLS DPCP LP algorithm theoretical guarantee per theorem moreover remarkable performance synthetic data weakness linear program non sparse become inefficient dimension data moreover  theoretically applicable regardless subspace relative dimension increase subspace  basis compute sequentially motivates generalize DPCP optimization target entire orthogonal basis min RD tsakiris vidal algorithm dual principal component pursuit via iteratively reweighted procedure DPCP IRLS tmax  RD tmax  RD max return procedure matrix norm define sum euclidean norm matrix wise sparse reduces precisely DPCP exactly proceed relax semi definite convex program via iteratively reweighted IRLS scheme IRLS scheme zhang    instead propose directly via IRLS convex relaxation orthonormal matrix define max constant prevents zero obtain quadratic min RD readily singular vector correspond singular data matrix  diagonal matrix refer algorithm DPCP IRLS theoretical defer future denoised DPCP DPCP clearly tailor inliers inliers contaminate vector longer sparse normal inlier subspace consequence propose DPCP denoised DPCP dual principal component pursuit algorithm denoised dual principal component pursuit procedure DPCP tmax compute cholesky factorization   RD tmax backward propagation return procedure min vector variable interpret denoised  vector interestingly context author propose via alternate minimization obtain approximate optimal thresholding operator apply wise vector optimal quadratically constrain min RD context coefficient matrix notation orthonormal consequence obtain project unconstrained minb RD onto sphere however context assumption orthonormal principle violate optimal longer available lagrange multiplier polynomial equation lagrange multiplier compute optimal multiplier numerically challenge approach future investigation instead propose obtain suboptimal project onto sphere unconstrained  algorithm efficient tsakiris vidal various iteration coefficient matrix factorization precomputed moreover algorithm trivially extend compute multiple normal vector algorithm evaluate propose algorithm experimentally investigate numerically theoretical regime recursion predict theorem sufficient violate converge normal vector subspace initialize properly finally DPCP variant robust pca algorithm purpose outlier detection synthetic data similarly image numerical evaluation theoretical theorem numerical evaluation theoretical theorem global minimizer DPCP orthogonal inlier subspace evaluate initial minimal angle theorem guarantee convergence linear program recursion explain discussion theorem fix outlier ratio eventually satisfied angle become arbitrarily regardless subspace relative dimension sufficiently inliers outlier uniformly distribute hence plot uniformly distribute inliers outlier towards fix ambient dimension randomly sample subspace dimension relative subspace dimension varies sample inliers uniformly random sample outlier uniformly random percentage outlier varies dataset instance estimate parameter RO monte carlo simulation regime however increase regime improves dramatically finally earlier theoretical argument sufficiently sufficient satisfied regardless outlier ratio subspace relative dimension similarly angle plot uniformly decrease increase across outlier ratio relative dimension recursion initialize properly converge iteration vector normal inlier subspace sufficient theorem satisfied towards maintain experimental maximal iteration tmax convergence accuracy replicate serf reminder limited regime predict theory sufficient parameter algorithm positive typically avoid  linear dual principal component pursuit satisfied fix inliers outlier ratio subspace relative dimension plot minimum initial angle convergence recursion linear program per theorem corresponds corresponds average independent trial satisfied outlier ratio subspace relative dimension recursion initialize singular vector correspond singular converges iteration vector angle subspace precisely suggests sufficient future theoretical improvement initialize uniformly random recursion converge normal vector particularly outlier ratio relative dimension reveals initialize svd data indeed strategy plot angle initialization subspace contrast angle random initialization subspace comparative analysis synthetic data synthetic experimental demonstrate behavior relative uniform context outlier rejection subspace DPCP LP algorithm DPCP IRLS algorithm DPCP algorithm RANSAC SE RPCA RPCA IRLS version reaper coherence pursuit cop detail exist tsakiris vidal svd random svd random convergence recursion regime limited theoretical guarantee conclude inliers fix plot sufficient satisfied outlier ratio relative dimension plot angle corresponds corresponds inlier subspace vector recursion converges initialize svd data uniformly random respectively plot minimum angle convergence normal vector inlier subspace per theorem plot angle subspace initialize svd data uniformly random respectively average independent trial estimate subspace dimension RANSAC reaper cop DPCP variant input subspace dimension convergence accuracy reaper regularization parameter maximum iteration DPCP maximum iteration RANSAC thresholding parameter fairness terminate earlier DPCP LP unless theoretically iteration probability truth outlier ratio  RPCA implement ADMM augment lagrange parameter respectively RPCA DPCP variant initialize via svd data algorithm cop implement code author selects upon classic pca subspace estimate finally linear program DPCP LP via generic LP solver gurobi maximum iteration DPCP LP tmax dual principal component pursuit RANSAC SE RPCA RPCA reaper cop DPCP LP DPCP IRLS outlier inlier separation absence independent trial horizontal axis outlier ratio define outlier inliers vertical axis relative inlier subspace dimension dimension ambient declare existence threshold apply output perfectly inliers outlier absence investigate potential perfectly distinguish outlier inliers absence return signal thresholded purpose declare outlier inliers  norm coefficient matrix RPCA norm RANSAC reaper cop DPCP variant directly return subspace model simply distance estimate subspace depict versus failure interpret existence threshold perfectly outlier inliers RANSAC succeed outlier regardless inlier rel DPCP approximately solves DPCP optimization hence perfectly inliers outlier confirm experimentally tsakiris vidal index distance ˆS DPCP LP index distance ˆS DPCP LP roc curve standard deviation subspace relative dimension inliers outlier ratio horizontal axis false positive ratio vertical axis positive ratio associate curve curve reflect accurate performance distance noisy subspace estimate DPCP LP relative dimension consideration  dimension probability sample outlier similarly RANSAC succeed regardless outlier ratio sample sufficient budget DPCP LP probability sample outlier SE RPCA RPCA succeed medium relative dimension exploit rank structure inlier data fail structure exist remarkably cop rank spirit performs surprisingly rank alternative SE RPCA RPCA perfect inlier outlier separation regardless outlier ratio relative dimension improvement achieve reaper succeed outlier dual principal component pursuit independent trial experimental report extreme regime correspond matlab standard macbook pro dual core 5GHz processor 4GB cache memory RANSAC SE RPCA RPCA reaper cop DPCP LP DPCP IRLS relative dimension reaper fails challenge outlier remarkably DPCP LP allows perfect outlier rejection across outlier ratio relative dimension clearly improve relative dimension regime moreover DPCP IRLS almost DPCP LP fails hardest regime relative dimension outlier finally important comment DPCP LP admittedly slowest particularly relative dimension dual principal component compute indeed outlier DPCP LP computes dual component oppose amount outlier dual component compute latter similarly outlier DPCP LP oppose DPCP IRLS magnitude faster DPCP LP comparable RPCA reaper overall cop presence fix investigate performance DPCP presence relative dimension inliers corrupt additive gaussian zero standard deviation orthogonal complement inlier subspace parameter earlier DPCP max RANSAC threshold parameter evaluate performance correspond roc curve roc curve corresponds threshold vertical coordinate percentage inliers correctly identify inliers positive horizontal coordinate outlier erroneously identify inliers false positive consequence ideal roc curve concentrate plot curve zero roc curve curve rank RANSAC SE RPCA RPCA perform poorly relative dimension performance random inlier vertical axis roc curve ratio positive tsakiris vidal outlier relative dimension reaper cop DPCP LP DPCP IRLS DPCP perform almost perfectly reaper fail relative dimension standard  already reaper fails regime absence cop fails completely contrast DPCP variant remain robust challenge regime remarkable DPCP LP DPCP IRLS noiseless data surprisingly robust slightly outperform DPCP latter handle noisy data attribute suboptimal approach DPCP lack suitable mechanism optimally tune thresholding parameter comparative analysis data geometry perform experimental evaluation propose context computer vision data image static scene goal estimate relative rotation translation relate task fundamental importance computer vision application 3D reconstruction 3D model scene construct 2D image scene trifocal tensor image static scene camera camera regardless underlie geometry characterize constraint satisfied respectively correspond 3D constraint fix coordinate 3D identify optical origin coordinate refer canonical projection 3D onto intersection origin simplicity assume rotate translate version canonical exist rotation translation projection 3D onto intersection optical however local pixel coordinate respect representation respect coordinate canonical coordinate  hence  inverse coordinate vector  substitute equation yield relation local representation respectively geometry corresponds calibrate camera camera projection parameter without loss generality local coordinate global coordinate dual principal component pursuit scene camera configuration camera depict 3D height incorrect correspondence static scene along camera configuration correspondence model dataset visual geometry oxford vector denote skew symmetric matrix equation exactly representation canonical coordinate relationship tsakiris vidal degenerate aside equation equivalent rank equivalent matrix equation elegantly  ith respectively equation consists trilinear constraint local representation image 3D maximal linearly independent matrix slice trifocal tensor mathematical encodes relative geometry calibrate indeed coordinate correspondence trifocal tensor camera proposition theorem  trifocal tensor estimation hyperplane trilinear constraint linear entry tensor unfolded regard vector uncalibrated trifocal tensor algebraic variety dimension already correspondence contributes linearly independent equation equivalently correspondence variety hyperplanes hyperplanes algebraically independent respect variety generic correspondence reduces dimension variety correspondence finite candidate trifocal tensor correspondence allows uniquely via homogeneous linear equation relative extract procedure described hartley zisserman discussion suggests generic correspondence coefficient vector linear equation span hyperplane normal vector refer vector trilinear embeddings correspondence vector matrix rank thanks  ding observation uncalibrated relevant computer vision application trifocal tensor exactly structure difference matrix longer rotation precise algebraic geometric ideal generate equation depth trifocal variety dual principal component pursuit however obtains correspondence across image similarity local feature sift typically correspondence incorrect becomes detect inliers hyperplane dataset corrupt outlier equivalently  subspace propose dual principal component pursuit DPCP ideally achieve superior performance RANSAC latter traditional date popular option computer vision community data datasets model corridor  college visual geometry oxford dataset contains static scene projection matrix quality inlier correspondence dataset randomly inlier correspondence generate outlier correspondence triplet sample uniformly random randomly triplet normalize data accord hartley norm dataset consists trilinear embeddings inlier outlier correspondence algorithm reaper variant RANSAC propose DPCP variant DPCP IRLS algorithm DPCP algorithm context outlier detection trifocal tensor estimation reaper DPCP IRLS DPCP input dataset configure subspace dimension hyperplane RANSAC variant RANSAC hyperplane RANSAC standard RANSAC randomly sample trilinear embeddings trial variant RANSAC hyperplane RANSAC exactly RANSAC sample trilinear embeddings instead individually associate correspondence RANSAC threshold maximal distance inlier trilinear embeddings hyperplane associate truth trifocal tensor RANSAC maximal average distance inlier trilinear embeddings regard budget DPCP reaper DPCP IRLS outlier DPCP average msec converge oppose msec DPCP IRLS RANSAC performance sensitive allocate budget explore budget regime DPCP IRLS budget regime DPCP fairness restrict accordingly metric precision algorithm corresponds recall hyperplane estimate Hˆ induces inlier outlier purely rank SE RPCA RPCA unsuitable hyperplane coherence pursuit cop perform synthetic data report performance competitive RANSAC reaper DPCP synthetic data cop fails precisely hyperplane trilinear embeddings union coordinate hyperplanes irrelevant trifocal tensor consideration prevents hyperplanes implicitly achieve RANSAC variant penalize projection error commonly trifocal tensor estimation variant however due complexity restriction enforce perform par hence report performance DPCP approach research tsakiris vidal correspondence increase average distance correspond tuples trilinear embeddings Hˆ maximal average distance corresponds inlier correspondence metric percentage inliers correspondence average distance Hˆ report precision algorithm scene corridor model  college respectively outlier ratio budget algorithm precision recall dataset corridor algorithm outlier outlier outlier outlier budget RANSAC RANSAC reaper IRLS DPCP IRLS DPCP algorithm precision recall dataset model algorithm outlier outlier outlier outlier budget RANSAC RANSAC reaper IRLS DPCP IRLS DPCP algorithm precision recall dataset  college algorithm outlier outlier outlier outlier budget RANSAC RANSAC reaper IRLS DPCP IRLS DPCP observation RANSAC essentially fails datasets precision exceed outlier moreover precision budget contradictory phenomenon attribute dual principal component pursuit combination insufficient budget dataset union coordinate hyperplanes irrelevant trifocal tensor evident inspect zero structure trilinear embeddings budget RANSAC identifies hyperplanes significant portion data none coincide trifocal tensor aforementioned issue remedied RANSAC estimate hyperplane trilinear embeddings respect underlie correspondence indeed dramatically improves performance dataset model perform budget however RANSAC cope outlier budget precision regime dataset corridor DPCP robust challenge regime outlier precision dataset corridor model  college budget regime DPCP IRLS precision respectively interestingly DPCP perform uniformly DPCP IRLS latter convergence budget attribute DPCP explicitly handle overall DPCP perform budget across datasets perform budget datasets corridor  college finally reaper performs somewhere DPCP IRLS RANSAC outperform  occasion consistent synthetic data accord advantage DPCP reaper precisely  latter fails conclusion RANSAC precision sufficient budget latter restrict performance dramatically particularly outlier ratio regime exponentially budget moreover RANSAC sensitive thresholding parameter knowledge truth clearly knowledge available choice parameter performance degradation DPCP combine precision robustness thresholding parameter propose dual principal component pursuit useful superior alternative popular approach RANSAC geometry computer vision application conclusion robust principal component analysis presence outlier dual principal component pursuit DPCP propose consist non convex optimization sphere strategy recursion linear program analyze rigorous mathematical analysis reveal DPCP inlier subspace presence outlier challenge regime outlier ratio subspace relative dimension synthetic data DPCP handle outlier inside dimensional ambient irrespectively subspace dimension moreover  tsakiris vidal  image context geometry DPCP outperform popular alternative RANSAC potential computer vision application appendix review exist appendix important mathematical analysis already spath watson sake clarity convenience liberty proof statement spath watson proposition rank global min orthogonal linearly independent proof optimal satisfy optimality relation sgn scalar lagrange multiplier parameter sgn sub differential norm without loss generality orthogonal equation implies exist  suppose span dimension exists norm vector orthogonal multiplication furthermore sufficiently equation trivially definition perturbation consequently dual principal component pursuit however normalize norm contradiction global proposition matrix rank min  admits computable orthogonal linearly independent proof minb  orthogonal linearly independent norm vector orthogonal orthogonal moreover addition sufficiently optimal objective remains unchanged preserve zero entry vector furthermore decrease increase additional zero achieve becomes orthogonal orthogonal replace orthogonal linearly independent proposition matrix rank suppose chosen orthogonal linearly independent accordance proposition sequence converges critical finite tsakiris vidal proof inspection optimality reveals critical minb consequence arise proposition finite candidate direction observation imply sequence converge finite critical minb