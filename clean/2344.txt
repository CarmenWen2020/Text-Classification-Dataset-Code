probabilistic linear discriminant analysis PLDA biometric speaker recognition model variability sample latent variable depends sample another assume independent across sample model within variability propose generalization PLDA enables joint model sample dependent factor nuisance approach PLDA modifies training procedure dependency across sample latent variable model within variability identity nuisance training propose procedure  correspond latent variable multilingual speaker verification task spoken nuisance propose joint PLDA approach significant performance gain task data training data contains mostly  speaker keywords probabilistic linear discriminant analysis speaker recognition factor analysis variability robustness acoustic introduction PLDA propose  inference identity image closely related model previously propose  image processing task technique later widely adopt speaker recognition community become technique task PLDA assumes sample feature vector fix dimension vector sum depends sample model within variability assume independent across sample model remain variability independent across throughout sample refer audio signal  ferrer mitchell McLaren license CC http creativecommons org license attribution requirement http jmlr org html ferrer McLaren sample assumption imply sample independent independent sample contrast assumption PLDA training data consist sample distinct speaker recognition data acoustic microphone style conversational  sample correspond likely statistically dependent literature proposes approach generalize PLDA metadata sample training motivation approach relax conditional independence assumption enable flexible model adapt available assume sample model linear model propose generalization introduction dependency sample simplest approach PLDA model propose garcia nevertheless author pool data propose performance training model reasonable training PLDA model overall model sample across within variation PLDA model propose tackle approach PLDA model model latent variable correspond across approach outperform standard PLDA pool training data training data frontal profile recognition task approach propose mixture component training instead PLDA mixture component continuous metadata model mixture gaussians approach training data SNR training data contains sample speaker SNR author gain propose approach pool data PLDA model scenario speaker training data subset training potentially training data others scenario PLDA approach training PLDA model dimension impossible suboptimal data PLDA model nuisance affect sample training propose novel generalization PLDA model relaxes conditional independence assumption without increase parameter functional PLDA model modify training procedure dependency across sample originate sample propose approach joint PLDA JPLDA assume training expectation maximization EM training joint PLDA simultaneous model factor procedure formulate account sample perform standard PLDA compute likelihood ratio null hypothesis trial belong speaker versus alternative hypothesis belong speaker likelihood compute marginalize hypothesis trial model cop versus trial standard PLDA knowledge training implicitly model behave PLDA training scenario sample highly imbalanced across speaker subset mathematical formulation propose JPLDA approach publish arxiv without analysis model significantly formulation EM algorithm later publish arxiv author significant improvement approach text dependent speaker verification task detailed analysis multilingual speaker recognition data compose mixer data speaker recognition evaluation organize nist another LASRS data evaluate training scenario available training data prism data contains percentage speaker subset training data per speaker JPLDA significantly outperforms standard PLDA approach structure PLDA training data contains mostly per speaker standard PLDA model adopt nomenclature usually speaker recognition community model propose image processing task task standard PLDA standard PLDA assumes vector sample speaker ysi  fix bias ysi vector dimension speaker subspace vector dimension subspace correspond nuisance usually speaker recognition channel model assumes ysi matrix assume diagonal latent variable assume independent speaker variable independent across speaker nuisance variable variable independent across sample ferrer McLaren model equivalent assume distribution   uut  speaker uut within speaker covariance matrix vector matrix singular theoretical practical PLDA model model described corresponds PLDA formulation PLDA FPLDA speaker recognition simplify version PLDA SPLDA purpose commonly nuisance  absorbed assume diagonal covariance matrix comprehensive explanation flavor PLDA training PLDA parameter EM algorithm EM formulation SPLDA FPLDA detailed document  FPLDA minimum divergence maximization generally convergence EM algorithm SPLDA convergence smart initialization procedure described already excellent model reproduce EM formula initialization procedure experimental EM initialization procedure EM algorithm initial model iteration model generate randomly SPLDA smart procedure initial model EM iteration converge parameter random initialization identity matrix applicable matrix random drawn normal distribution standard deviation SPLDA smart initialization approach directly motivate equation namely initialize  empirical within speaker covariance matrix training data matrix eigenvectors correspond eigenvalue  covariance matrix training data diagonal matrix eigenvalue initialization procedure model iteration EM verification task sample enrollment correspond sample speaker joint PLDA simultaneous model factor speaker comparison usually trial speaker verification application decision others preferable PLDA model compute likelihood ratio LR hypothesis directly thresholded decision LR LR HSS hds HSS hypothesis speaker hds hypothesis speaker compute PLDA model code formulation derive equation equation mistake confirm coauthor PLDA model PLDA model introduce model mixture PLDA model latent variable correspond speaker across component vector sample speaker model   ysi  indicates mixture component correspond sample ysi hence mixture component model reduces standard PLDA model assume mixture component training author simplest mixture component nuisance sample feasible training sample sample component latent variable ysi component variable sample speaker across component enables model properly component variability PLDA model PLDA model instead PLDA model component mixture covariance matrix diagonal component described SPLDA model simplicity implementation difference SPLDA FPLDA TPLDA model described coincides SNR dependent mixture PLDA model assume SNR discrete continuous posterior probability component fix component correspond sample otherwise training procedure TPLDA supplementary ferrer McLaren joint PLDA model propose generalization PLDA model nuisance variable longer independent across sample potentially across sample correspond nuisance model symmetric latent variable correspond speaker nuisance dependency introduce label sample label speaker label propose model vector dimension sample ysi  ysi vector xci vector ysi xci model parameter estimate standard PLDA formulation input data training algorithm label nuisance sample expectation maximization equation training model significantly involve PLDA model due speaker cannot treat separately others sample speaker dependent sample speaker creates potential dependency training sample greatly complicates formulation increase computation magnitude EM iteration nevertheless initialize model smart basically EM unnecessary reduce training model standard PLDA data detailed derivation EM algorithm procedure JPLDA ferrer appendix summary formulation equation implement algorithm implement minimum divergence model future smart initialization procedure described EM unnecessary minimum divergence unlikely model approach matrix JPLDA model diagonal diagonal simply diagonal estimate maximization EM algorithm standard PLDA EM algorithm EM initialization procedure JPLDA model randomly initialize procedure standard PLDA described propose alternative procedure initial PLDA model procedure estimate matrix training SPLDA model label target implicitly absorb speaker PLDA model estimate joint PLDA simultaneous model factor sample obtain compensate sample training data estimate another SPLDA model model speaker SPLDA model obtain algorithm pseudocode propose initialization algorithm usually training PLDA model assume initial global data training sample initialization EM iteration sample input smart initialization EM iteration unnecessary algorithm smart EM initialization approach JPLDA matrix contains training vector vector speaker label training data respectively function  return parameter SPLDA model subspace matrix precision matrix EM iteration function  return estimate latent variable training sample sample label latent variable procedure    matrix   return standard PLDA define likelihood ratio hypothesis speaker speaker nevertheless marginalize likelihood hypothesis nuisance cannot assume nuisance hence LR compute LR HSS hsc hsc HSS HSS HDC HDC HSS hds hsc hsc hds hds HDC HDC hds HSS hypothesis speaker hds hypothesis hsc hypothesis nuisance HDC hypothesis LR compute derive appendix detail assume sample enrollment sample enrollment trivially compose sample formulation become complex without assumption possibility sample ferrer McLaren derive formula multi enrollment enrollment formulation apply JPLDA identification lid lid another generalization formula multiple enrollment sample unknown future another implicit assumption equation trial training assumption respect speaker JPLDA standard PLDA application assumption speaker unseen training appropriate nuisance nuisance spoken signal assumption trial training future relax assumption performance improvement formula depends prior probability probability enrollment speaker hsc HSS probability speaker hsc hds prior probability dependent hsc HSS HDC HSS hsc hds HDC hds independent prior probability parameter compute training data tune development arbitrary data application nuisance prior trial trial experimental setup task performance metric data procedure convert audio sample fix vector model PLDA  speaker verification task speaker verification consists sample enrollment belong speaker simplest enrollment sample enrollment sample trial trial target trial enrollment speaker impostor trial speaker explore  speaker verification trial compose sample trial sample trial speaker verification inherently independent information spoken generate output robust variation speaker verification performance degrade significantly trial trial training joint PLDA simultaneous model factor discus occurs training PLDA model multilingual data distribution speaker factor becomes broader speaker suboptimal performance  trial propose mitigate training standard PLDA model speaker target sample speaker speaker aware PLDA model performs significantly trial model speaker target degrades trial cannot model variation JPLDA simultaneously model speaker factor speaker factor sharper distribution model improve performance trial respect standard PLDA performance metric compute performance error rate EER detection error det curve det curve EER performance  decision label sample decision threshold sample threshold label target sample threshold label impostor error target trial label impostor false alarm impostor trial label target EER rate decision threshold rate false alarm rate det curve variation traditional receiver operating characteristic roc curve widely speaker verification decade det curve plot false alarm rate versus rate obtain sweep decision threshold transform probit probit transformation inverse cumulative distribution function standard normal distribution convert versus false alarm rate curve distribution gaussian standard deviation reasonable approximation speaker verification training data training available training data subset speaker monoling analyze performance PLDA extremely challenge scenario explicit information available training data vector sample training compose  cellular cellular consist english cellphone conversation  phase phase sample consist english telephone conversation ferrer McLaren mixer data speaker recognition evaluation organize national institute standard technology nist data contains english sample telephone microphone channel  sample telephone channel exception speaker non english sample english sample speaker data non english data english subset data training speaker discard data speaker available sample unavailable ambiguous nist monoling training randomly sample spoken speaker training finally analyze subsetting training balance representation channel data bilingual speaker training specifically subset training discard telephone data speaker data english another data information non english data telephone speaker non english data telephone recording english subsetting data achieve balance representation telephone data respect microphone data emphasize data bilingual speaker minority data subset monoling training simply sample subset training monoling statistic training correspond subset arabic sample  french chinese  hindi italian japanese korean russian spanish  thai  chinese  data compose mixer data development compose LASRS data evaluation mixer data compose telephone sample mixer collection nist speaker recognition evaluation speaker training sample arabic speaker sample russian speaker sample thai speaker sample chinese speaker sample english speaker trial target impostor trial trial balance union trial trial balance union english versus non english trial trial contains target trial impostor trial LASRS data compose sample bilingual multi modal corpus corpus compose bilingual speaker joint PLDA simultaneous model factor sample speaker sel eng eng monoling  mic   eng subset monoling subset statistic training eng refers english data refers english  refers telephone cellphone data mic refers microphone training monoling refers speaker sample  refers speaker sample english plus arabic korean spanish speaker english speaker perform series task partner phone reading various text english native task device session LASRS trial enrol data session session spoken conversational data session trial target trial impostor trial microphone  microphone desktop microphone studio microphone omnidirectional microphone local telephone microphone remote telephone microphone telephone earpiece microphone trial simplicity analysis detail collection protocol vector extraction validation propose approach traditional vector framework speaker recognition vector fix dimensional vector attempt fully assumption characteristic audio framework sequence feature vector sequence variable depends duration vector approach assumes feature vector independently drawn component gaussian mixture model GMM covariance matrix  parameter vector model covariance fix recording subspace matrix model GMM vector vector assume ferrer McLaren prior normal standard distribution posterior distribution sequence feature vector posterior distribution vector model intractable cannot EM algorithm obtain model parameter obtain vector sample model variational bayes VB EM approach estimate model parameter vector described  approach parameter iteratively  along posterior distribution responsibility responsibility variational parameter interpret assignment frame component model classical vector approach parameter fix initial covariance GMM universal background model  recording speaker approximate posterior distribution obtain simplify assumption responsibility  posterior responsibility parameter fix matrix estimate maximize VB bound finally parameter model estimate vector extract approximate posterior distribution feature fix responsibility  posterior extract vector variable mel frequency cepstral coefficient MFCCs extract audio signal MFCCs acoustic feature vector capture information regard amplitude frequency manner perceive MFCCs append delta delta capture dynamic feature vector dimension frame feature vector per activity detection sad apply remove frame purpose neural network dnn model telephone microphone data combination fisher  mixer data dual multi frequency DTMF signal without signal fisher corpus corrupt non vocal SNR truth label dnn obtain previous sad consist non hidden markov model hmm decoder various duration constraint perform complex retrain data label corrupt data obtain signal input sad MFCC feature variance normalize waveform coefficient maximum standard deviation normalize feature concatenate frame dimensional feature vector input dnn consists hidden layer output layer dnn consists node predict posterior non posterior convert likelihood ratio bayes assume prior threshold apply obtain joint PLDA simultaneous model factor detailed description dnn sad approach  estimate EM algorithm frame random subset sample recording data estimate matrix described subspace estimate training data described sample speaker available unavailable ambiguous discard purpose finally model vector audio sample extract frame training vector speaker similarity utterance PLDA vector multiclass linear discriminant analysis lda training data PLDA training data perform normalization normalization serf satisfy  assumption PLDA EM initialization technique parameter setting training data propose baseline PLDA technique described previous nuisance JPLDA spoken sample training label label marginalize compute LR unless otherwise TPLDA cannot mixture component spoken sample training speaker PLDA model component hence component model component model english data another component model non english data model data available training component implementation TPLDA assumes mixture component training spoken SPLDA FPLDA JPLDA lda dimension dimensionality reduction data transform lda matrix normalize TPLDA lda dimension significantly performance dimension speaker rank fix respectively chosen optimal approximately optimal FPLDA SPLDA JPLDA available training data rank rank JPLDA optimal JPLDA FPLDA largely insensitive parameter performance rank unless otherwise JPLDA obtain hsc HSS hsc hds TPLDA diagonal matrix covariance model slightly covariance ferrer McLaren iter EER FPLDA rand init SPLDA rand init SPLDA smart init JPLDA rand init JPLDA smart init comparison performance function EM iteration mixer data available training data random smart initialization PLDA model axis tune decision solely mixer data initialization convergence training procedure SPLDA FPLDA JPLDA function EM iteration initialization procedure random smart explain FPLDA standard exists aware smartly initialize parameter model random initialization training data without subsetting mixer data EM iteration essential random initialization gain initial random model iteration progress converge approximately stable iteration smart initialization SPLDA JPLDA EM iteration data JPLDA performance smart initialization slightly degrades iteration probably due overfitting training data iteration EM JPLDA zero iteration safely prior probability JPLDA JPLDA mixer development available training data function prior probability hsc HSS hsc hds fix parameter sweep joint PLDA simultaneous model factor data split data trial obtain sample priori knowledge prior appropriately explain performance function probability parameter optimal trial optimal trial probability optimal trial due sample code switch trial involve sample strictly trial trial accommodate variation accent interlocutor trial pool almost identical performance performance obtain file dash plot performance obtain probability trial trial remain probability subset significantly EER pool trial due trial misalign EER threshold EER trial pool actually salient standard PLDA approach JPLDA mitigate fully comparison performance mixer LASRS microphone training monoling plot FPLDA slightly performance SPLDA channel mostly telephone training data remain FPLDA baseline label training TPLDA JPLDA plot significant gain baseline mixer data channel majority training data channel approach succeed mitigate variability channel exactly training TPLDA fails generalize consistently performance JPLDA reasonable alternative microphone data english training data telephone data non english data implies PLDA mixture correspond non english data TPLDA telephone data poorer performance LASRS channel JPLDA leverage information alternative microphone english data matrix model variability across plot speaker available training within speaker variation due ferrer McLaren prob EER lan lan comparison JPLDA performance function prior probability mixer data training data  corresponds performance trial information training TPLDA degradation baseline TPLDA challenge scenario training data profile TPLDA model basically degenerate  PLDA model data implies mixture unable model variability extremely degrade performance trial indeed trial reasonable TPLDA performance degradation trial affect overall performance plot finally focus JPLDA significant gain baseline training relative gain training data contains per speaker gain relative FPLDA baseline training data comparison finally FPLDA baseline JPLDA training define subset discard telephone sample speaker english sample attempt achieve balance english non english sample telephone microphone sample joint PLDA simultaneous model factor mixer LASRS LASRS LASRS LASRS LASRS LASRS LASRS EER SPLDA FPLDA TPLDA JPLDA training data mixer LASRS LASRS LASRS LASRS LASRS LASRS LASRS EER SPLDA FPLDA TPLDA JPLDA training data monoling comparison performance PLDA training monoling JPLDA relative gain JPLDA relative FPLDA FPLDA subset significantly training training monoling FPLDA benefit balance distribution within training data standard PLDA sample speaker assume distribution regardless sample english english hence proportion speaker english sample parameter PLDA model mostly optimal speaker degrade performance non english trial ferrer McLaren mixer LASRS LASRS LASRS LASRS LASRS LASRS LASRS EER FPLDA JPLDA FPLDA subset JPLDA subset training data mixer LASRS LASRS LASRS LASRS LASRS LASRS LASRS EER FPLDA JPLDA FPLDA subset JPLDA subset training data monoling comparison performance FPLDA JPLDA training monoling training subset discard telephone sample speaker english sample training JPLDA subsetting data training JPLDA performance training subset FPLDA subset monoling advantage JPLDA FPLDA training consistently significant gain FPLDA training EER perform LASRS LASRS LASRS corresponds metric somewhat unreliable however det curve later complement EER overall conclusion  joint PLDA simultaneous model factor consistent trend JPLDA benefit training indicates contrary PLDA JPLDA handle imbalance data successfully leverage additional sample subset complement EER plot det curve curve challenge training monoling JPLDA advantage FPLDA plot gain specific EER operating JPLDA significant gain FPLDA operating correspond false alarm rate advantage available training data subset JPLDA FPLDA already EER plot finally EER mixer data training subset trial previous plot  trial performance trial plot trial benefit JPLDA particularly monoling training JPLDA benefit training subset trial FPLDA benefit subset trial  trial performance degrade unchanged subsetting training data relative gain JPLDA trial pool observation indicates JPLDA improve discrimination trial align distribution trial pool relative gain JPLDA emphasize JPLDA fully pool performance somewhat subset source remain misalignment future conclusion propose generalization PLDA within variability factor longer independent across sample assumes identity nuisance training latent variable correspond within variability across sample nuisance label likelihood ratio compute standard PLDA marginalize nuisance hence identity nuisance unknown multilingual speaker recognition task propose standard PLDA model PLDA model nuisance component mixture PLDA model relative gain obtain JPLDA training data contains speaker data JPLDA model extrapolate proportion zero training speaker data standard PLDA model mitigate expose significant proportion training speaker data ferrer McLaren FA mixer FA LASRS FA LASRS FA LASRS FA LASRS FA LASRS FA LASRS FA LASRS FPLDA FPLDA subset JPLDA subset JPLDA det curve FPLDA JPLDA monoling training subset marker curve corresponds EER propose JPLDA task standard PLDA whenever discrete nuisance training speaker recognition channel style label others sample dependent nuisance recognition sample dependent nuisance strength JPLDA ability extrapolate joint PLDA simultaneous model factor lan lan EER FPLDA JPLDA FPLDA subset JPLDA subset training data lan lan EER FPLDA JPLDA FPLDA subset JPLDA subset training data monoling comparison performance FPLDA JPLDA mixer trial subset training monoling subset nuisance sample speaker nuisance propose approach introduces additional requirement respect PLDA approach identity nuisance training future explore possibility automatically detect nuisance classifier data factor cluster distance metric reflect nuisance finally generalization propose approach sample dependent nuisance direction explore future