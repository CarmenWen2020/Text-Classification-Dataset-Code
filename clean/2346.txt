develop approximate formula evaluate validation estimator predictive likelihood multinomial logistic regression regularize norm allows avoid optimization literally conduct validation hence computational significantly reduce formula derive  approach employ  data model dimensionality extension elastic net regularization address usefulness approximate formula demonstrate simulated data isolet dataset uci machine repository matlab python code implement approximate formula distribute keywords classification multinomial logistic regression validation linear perturbation average approximation introduction multinomial classification ubiquitous task treat task naive bayesian neural network decision hierarchical classification scheme focus multinomial logistic regression mlr powerful application denote feature vector denotes index data mlr linear structural model parameter computes bias overlap  probability feature vector belongs compute softmax function   PL  define mlr maximum likelihood estimation usually employ mlr tends inefficient data sufficiently model dimensionality relevant technique overcome difficulty introduce penalty regularization regularization induces sparse classifier accepted effective data DM regularize estimator define optimization wˆa arg min DM DM  denote negative likelihood define regularize function hamiltonian introduction regularization another model selection hyperparameter estimation respect versatile framework reasonable estimate validation CV disadvantage computational literal CV optimization serious computational burden data model dimensionality purpose resolve efficient approximation CV technique  expansion employ  data model dimensionality technique developed bayesian perceptron committee machine gaussian vector machine linear regression regularization dimensional variation actually  approach fairly apply generalize linear model convex regularization mlr easy extend regularization exist implementation derivation approximate formula however conduct regularization simplicity extension elastic net derivation organize sec formulation derive approximate formula sec approximation literally conduct CV simulated data isolet dataset uci machine repository accuracy computational approximate formula report comparison literal CV limitation simplify version approximation examine devote conclusion accelerate CV multinomial logistic regression formulation maximum likelihood estimation framework employ predictive likelihood criterion model selection estimator predictive likelihood CV realization particularly estimator LOO CV LOO described arg min DM DM DM denote overlap LOO  wˆa define LOO estimator  predictive negative likelihood LOO predictive negative likelihood simply prediction error minimum  determines optimal evaluation computationally demand notation fix notation derivation summarize index introduce vector notation overlap  extend vector representation vector LN mth component decompose denotes index component index feature vector namely  correspondingly leverage matrix LN define repetition representation feature vector component define  yield convenient relation  probability  data Wˆ wˆa denote   PL  obuchi kabashima notation express gradient hessian Wˆ Wˆ  Wˆ Wˆ        addition denote function hessian respective Wˆ Wˆ Wˆ Wˆ finally introduce index active component Aˆ Wˆ Wˆ denote active component vector LN subscript  notation matrix assume component correspond dimension approximate formula derivation important dependence overlap hence sufficient relation  derive approximate formula crucial assumption derive formula active LOO Wˆ wˆa Wˆ namely Aˆ Aˆ Wˆ although assumption literally numerically confirm approximately active active LOO operation moreover related regularize linear regression lasso contribution active vanishes limit hence adopt assumption definition active  precede analysis vector machine active Aˆ assume unchanged LOO operation easy active component LOO Wˆ Wˆ accelerate CV multinomial logistic regression vanish gradient function equation Aˆ Wˆ Aˆ Aˆ Aˆ Aˆ Wˆ Aˆ difference gradient hence difference Wˆ Wˆ denote difference Wˆ Wˆ expand respect obtain equation Aˆ  Wˆ Aˆ insert definition Wˆ Wˆ obtain  Aˆ  Aˆ equation implies matrix inversion operation significant computational avoid employ approximation woodbury matrix inversion formula conjunction Wˆ Wˆ    insert simplify factor obtain  IL  Aˆ  Aˆ variable righthand compute Wˆ enables estimate  leverage optimization data DM avoid optimization mention computational approximation mainly ML Aˆ ML Aˆ Aˆ construction  derive inverse Aˆ proportional feature dimensionality computational respect dimensionality admittedly cheap computational fold literal CV moderate becomes approximation dimensionality limit however stress actually exists approximation outperforms literal obuchi kabashima CV computational later demonstrate sec moreover treat simplify approximation approximate formula computational simplify version linearly respect parameter derivation sec precision comparison approximation sec another sensitive issue compute  occasionally function hessian zero eigenvalue invertible handle subsection handle zero mode mlr intrinsic symmetry model invariant addition constant vector vector vector define model degenerate mlr singular finite harmful regularization resolve singularity selects optimal wˆa degenerate vector however associate hessian nonsingular regularization contribution hessian hessian tends zero mode prevents inverse hessian overcome possibility fix constant optimization gauge fix physic convenient gauge zero gauge chosen fix zero actually earlier implementation preferable approximate formula remove harmful zero mode hessian however implementation currently accepted employ gauge fix moreover gauge fix eigenvalue sometimes accidentally emerge hessian hence user convenience another avoid another possibility remove zero mode construction zero mode associate model invariance implies zero mode irrelevant remove interested perturbation truly model mode maintain model unchanged unnecessary accord consideration replace zero mode remove inverse hessian computation straightforward perform eigenvalue decomposition  obtain eigenvalue Aˆ eigenvectors Aˆ allows    accelerate CV multinomial logistic regression denotes index mode finite eigenvalue define   finally replace obtain   Aˆ instead zero mode avoid extension mixed regularization briefly generalize mixed regularization define wˆa arg min denotes norm derivation sec realize derivation essentially difference function hessian  Wˆ  IK identity matrix compute LOO leverage equation replace definition Aˆ   Aˆ thanks zero mode removal eigenvalue binomial binomial particularly application specific formula binomial fairly express binary logit function    obuchi kabashima identify mlr mlr zero gauge hence harmful zero mode hessian straightforwardly apply approximate formula explicit       Aˆ  Aˆ Aˆ  active approximation easily generalize arbitrary differentiable output function replace logit function  reader encourage implement approximate CVS variety simplify approximation mention computational approximation ML Aˆ ML Aˆ Aˆ reduce treat derive simplify approximation approximate formula average SA approximation accord physic terminology simplify approximate formula assume correlation sufficiently weak meaning correlation evident sec hessian rescale covariance statistical mechanical formulation introduce probability distribution weak correlation assumption correlation feature component negligibly  cov    index feature component index define rescale factor hessian assume express restrict    Aˆ otherwise namely SA hessian finite index feature vector component dependence data index assume accelerate CV multinomial logistic regression negligible imply heterogeneity feature vector assume absent proceed computation equation matrix derivation technical defer sec Aˆ iAˆ Aˆ IL  Aˆ iAˆ NM Aˆ  active variable feature component component related inactive variable zero SA approximation CSA define CSA approximate formula simply express   factor IL  contrast directly approximate inverse becomes occasionally ill define due presence zero mode remove zero mode  PM IL  perform eigenvalue decomposition define zero mode remove inverse  iAˆ   Aˆ iAˆ  index mode finite eigenvalue computational maximum leverage approach naive recursive substitution converges constant irrespectively parameter computational SA approximation NL ML linear feature dimensionality data hence advantage significant summary procedure summarize version approximation derive algorithmic procedure version approximate CV ACV average approximate CV SAACV procedure ACV SAACV alg alg respectively mixed regularization comment obuchi kabashima algorithm approximate CV mlr procedure ACV Wˆ DM compute active Aˆ Wˆ compute   PM  Aˆ ML Aˆ ML Aˆ Aˆ   compute  ML Aˆ ML Aˆ ML   Aˆ  IL  compute LOO return LOO procedure specify consume entire procedure alg actual implementation CSA recursion fully specify sec denotes frobenius norm threshold judging convergence typical situation threshold judging numerical examine precision actual computational ACV SAACV numerical simulated actual datasets examination compute error literally conduct fold CV approximate formula principle approximate LOO CV formula approximates however literal LOO CV computational burden despite empirically CV moderate hence CV instead LOO CV directly approximation accuracy compute normalize error difference define approximate LOO literal CV literal CV literal CV denotes literal CV estimator prediction error approximate LOO approximate  moreover reference compute negative likelihood accelerate CV multinomial logistic regression algorithm average approximate CV mlr procedure SAACV Wˆ DM compute active Aˆ Wˆ compute initialization Aˆ iAˆ initialization compute CSA recursion SA PN PM IL SA  ML NL Aˆ iAˆ  iAˆ compute Aˆ iAˆ Aˆ iAˆ Aˆ iAˆ Aˆ iAˆ Aˆ iAˆ sab compute LOO return LOO procedure obuchi kabashima wˆa wˆa training error hereafter training error monotonic increase function respect prediction suppose nonmonotonic cpu intel xeon 4GHz optimization employ glmnet implement  subroutine  approximation implement raw code matlab optimize approach  approximate formula loop matlab hence comparison necessarily however comparison significant difference computational literal CV approximation glmnet correspond optimization parameterized wˆa arg min parameterization basically prefer absent contribution overcome technical difficulty stem however glmnet employ algorithm occasionally loses stability uncontrolled manner without hence adaptively sensitive convergence algorithm optimization glmnet specialized version coordinate descent employ threshold judge algorithm convergence unless explicitly mention tighter default treat looser choice strongly affect literal CV training error approximation employ robust choice literal CV demonstrate simulated dataset simulated data suppose feature vector independently identically drawn bernoulli gaussian prior  employ distribute code implement approximate formula conjunction glmnet parameter  accelerate CV multinomial logistic regression denotes gaussian distribution variance respectively resultant feature vector becomes sparse norm becomes average uniformly randomly generate feature vector leverage linear  observation component gaussian convenience introduce ratio data feature dimensionality obtain parameter characterize experimental setup obtain dependence parameter hence mainly focus dependence parameter summarize simulated data plot prediction training error demonstrates approximation consistent literal LOO CV inconsistency due numerical instability literal CV actually data induce difference literal CV demonstrates approximation robust curve situation grows estimate parameter increase data fix meaning becomes  growth hence demonstrates developed approximation irrespectively  exhibit dependence error approximation weak difference predictive training error negligible hence curve discriminable moderate training curve predictive approximation curve consistent literal LOO demonstrates approximation accuracy grows discriminable difference exists approximation literal LOO CV difference approximation derivation relies  difference approximation literal CV conjunction panel recognize approximate formula becomes fairly precise parameter normalize error difference correspond difference tends increase perturbation employ approximate formula justified limit finally actual computational evaluate wˆa approximate  dependence panel obuchi kabashima error LOO ACV SAACV training error LOO ACV SAACV training error LOO ACV SAACV training normalize error difference ACV SAACV normalize error difference ACV SAACV normalize error difference ACV SAACV upper plot error parameter fix approximation consistent literal LOO CV presumably due numerical instability literal CV normalize error difference plot parameter panel correspond upper horizontal dot denote drawn comparison difference negligible literal CV stable hence error difference reliable accelerate CV multinomial logistic regression error LOO ACV SAACV training error LOO ACV SAACV training error LOO ACV SAACV training normalize error difference ACV SAACV normalize error difference ACV SAACV normalize error difference ACV SAACV upper plot error strength parameter fix approximation consistent literal LOO CV irrespectively strength convergence threshold normalize error difference plot parameter panel correspond upper difference negligibly obuchi kabashima error LOO ACV SAACV training error LOO ACV SAACV training error LOO ACV SAACV training error LOO ACV SAACV training plot error feature dimensionality parameter fix accelerate CV multinomial logistic regression normalize error difference ACV SAACV normalize error difference ACV SAACV normalize error difference ACV SAACV normalize error difference ACV SAACV plot normalize error difference correspond difference tends increase obuchi kabashima plot actual computational examine obtain hence plot computational obtain panel clearly display advantage sec optimization ACV SAACV slope error convergence threshold sensitivity fold fold ACV ACV SAACV SAACV actual computational spent ACV SAACV plot feature dimensionality logarithmic computational fold CV asterisk parameter fix error obtain convergence threshold error omit visibility tighter minimum examine systematic difference literal LOO CV already training error completely overlap parameter disadvantage developed approximation computational optimization obtain wˆa shorter compute approximate  hence literal CV however optimization increase rapidly approximate CV ACV exceeds SAACV SAACV behaves linearly function dash hence SAACV powerful related issue mention convergence algorithm panel error convergence threshold important observation significant difference exists literal CV curve implies approximate formula robust loose convergence threshold conversely systematic deviation literal CV approximation accelerate CV multinomial logistic regression indicator verify tightness convergence threshold beneficial treat model convergence annoy task dataset approximate formula dataset approximation become precise model dimensionality data hence chose isolet dataset relatively classification task uci machine repository feature dimensionality data respectively apply fold CV instead LOO CV computational approximation dataset error isolet data fold ACV SAACV training normalize error difference isolet data ACV SAACV approximate CV performance isolet data error panel normalize error difference approximation fold CV panel estimate minimum prediction error accuracy rate correctly classify data probability recover training data commonly literal CV approximation minimum leftmost accuracy rate literal CV ACV SAACV respectively approximation fold CV demonstrate fairly agreement actual effectiveness developed approximation actual computational obtain simulation fold CV ACV SAACV respectively parameter advantage ACV efficiency SAACV situation obuchi kabashima SAACV fail factor neglect SAACV correlation feature component heterogeneity feature vector factor approximation accuracy SAACV degrade examine impact correlation feature component constraint simulated data treat sec examine approximation performance situation treat feature vector component panel component non zero component  overlap feature vector vector correlation component panel strength correlation coefficient component corr hence correlation performance approximate formula fairly imply SAACV likely perform component feature vector correlate finding actually obtain linear model preferable observation implies applicable limit SAACV extend wider feature vector assume derivation weakness correlation assume sec imply possibly exists another approximation formula account correlation SAACV promising framework derive formula adaptive tap adaptive tap computational SAACV reduce computational linear respect employ additional simplify approximation however technical future examine heterogeneity feature vector introduce amplify factor norm feature vector factor feature vector chosen  simulated data identical panel parameter amplify factor apply latter approximation performance dataset examine impact heterogeneity dataset treat mnist data handwritten digit simplicity data digit preprocessing feature component variance remove component variance retain feature vector almost component discard standardization procedure conduct apply amplify factor panel without amplification panel examine comparison clearly ACV consistency LOO CV behavior SAACV demonstrate SAACV inaccurate estimate CV error datasets heterogeneity heterogeneity accelerate CV multinomial logistic regression error LOO ACV SAACV training error corr LOO ACV SAACV training normalize error difference ACV SAACV normalize error difference corr ACV SAACV upper plot error correlate feature vector panel component feature vector correlate parameter strength convergence threshold normalize error difference plot parameter panel correspond upper obuchi kabashima error LOO ACV SAACV training normalize error difference ACV SAACV plot error heterogeneity feature vector dataset panel feature vector amplify  factor ACV consistent LOO CV SAACV normalize error difference correspond panel naturally emerge application medical statistic biological marker  affected patient unaffected yield norm feature vector affected patient consideration suspect efficiency SAACV however stress heterogeneity attribute belonging absorbed rescale chosen  feature vector norm  const regularization  regularization coefficient adaptively belonging  adaptive regularization coefficient approximation formula apply completely manner convince  regularization coefficient argument norm handle code extend account  coefficient argument argue rescale prescription treat heterogeneity employ prescription weak SAACV naturally cure noteworthy remark SAACV closely related  generalize validation  linear regression  heterogeneity coefficient correspond SAACV neglect hence weak SAACV regard approximation CV estimator generalization error stress approximation accelerate CV multinomial logistic regression error mnist fold ACV SAACV training error mnist fold ACV SAACV training normalize error difference mnist ACV SAACV normalize error difference mnist ACV SAACV upper plot error mnist handwritten data digit amplify factor apply panel apply heterogeneity affect performance SAACV normalize error difference correspond upper panel obuchi kabashima reduce computational data model dimensionality increase rapidly recent conclusion developed approximate formula CV estimator predictive likelihood multinomial logistic regression regularize norm extension elastic net regularization demonstrate advantage disadvantage numerical simulated datasets version approximation define developed formula version abbreviate ACV performance computational eventually become literal fold CV moderate grows computational polynomial feature dimensionality data tendency investigate define version ACV computational linearly respect approximation SAACV demonstrate SAACV advantage hence leverage literal CV ACV SAACV derivation perturbation assumes difference assumption satisfied specific restriction application formula encourage reader leverage implement matlab python code available  approach employ fairly apply generalize linear model convex regularization development practical formula assistance living data era