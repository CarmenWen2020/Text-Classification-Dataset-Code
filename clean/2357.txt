computational semidefinite program sdp relaxation important role guarantee optimality focus popular semidefinite relaxation cluster yield non convex formulation segregate datasets report unexpected data contains zero dimensional manifold sdp capture geometrical structure unlike traditional manifold embed technique approach rely manually define kernel enforces locality via nonnegativity constraint approach nonnegative manifold disentangle nomad intuitive understand manifold capability develop theoretical analysis nomad idealize datasets nomad convex globally optimal generic sdp solver polynomial complexity datasets address analyze non convex heuristic convex efficient algorithm conditional gradient render nomad versatile understandable powerful manifold keywords semidefinite program manifold conditional gradient introduction quest algorithmic theory biological neural network author recently propose cluster network model olfactory processing computation network derive perform online optimization non convex objective function whereas network dynamic biologically plausible  objective analyze algorithm convergence understand compute cluster neural network convex sdp relaxation data define gramian matrix  sengupta  input dataset input gramian 2D embed input dataset input gramian zoom enhance contrast input dataset nomad originally introduce convex relaxation cluster surprisingly learns manifold structure data manifold  knot cannot  3D without nomad understands manifold yield circulant matrix unfolded 2D multiple manifold nomad although linearly non separable nomad correctly submatrices manifold visual clarity enhance contrast cluster association matrix belong cluster optimum optimization acronym explain argmax DQ nomad link cluster formulation explain appendix focus nomad compute theoretical effort concentrate nomad surrogate datasets consist linearly separable cluster demonstrate reproduce cluster assignment moreover nomad achieves cluster datasets lloyd algorithm fails related   analyze nomad regime previous instead focus parameter setting approximates formulation concentrate alternative setting discover nomad merely convex  nomad manifold structure data discriminate manifold unexpected behavior nomad  geometry notation denote entry matrix respectively vector employ lowercase notation index matrix entry wise nonnegative positive semidefinite clustering  data central role played nonnegativity constraint sdp nonnegative manifold disentangle nomad compute despite theoretical advantage convex optimization SDPs cluster remain limited mainly due lack efficient algorithm convex optimization address issue efficient convex solver nomad conditional gradient algorithm handle datasets extend applicability nomad challenge scenario organization behavior nomad theoretically analyze synthetic regular manifold symmetry sec context demonstrate nomad departs standard building analysis nomad non trivial manifold capability sec demonstrate numerically nomad performance non trivial synthetic datasets motivate relatively performance standard sdp solver focus nomad datasets sec theoretically experimentally heuristic nonconvex   style algorithm finally convex efficient algorithm nomad algorithm allows provable nomad datasets software publicly available http github com  sdp kmeans theoretical analysis manifold capability nomad appearance isomap locally linear embed LLE outstanding progress manifold data matrix vector majority within fix radius compute construct matrix inversely proportional distance otherwise compute embed locally isometric powerful approach propose compute shortest graph graph spectral neural network however technique depends critically ability capture data structure correctly non trivial task user technique furthermore kernel commonly rbf involve additional parameter kernel width user expectedly optimal selection parameter critical role overall manifold nomad departs drastically setup kernel selection involve effectively kernel automatically data positive semidefinite factorize define feature  sengupta  input dataset euclidean distance dot nomad kernel function correspondence kernel threshold distance nonnegativity gramian representation toy constraint nomad equivalent zero distance distance reference rotational symmetry argument valid dataset illustrate intuitively difference similarity prior manifold LLE LLE optimizes function adjacency matrix graph matrix locally isometric unwrap data manifold remove connection technique nomad align output gramian input gramian discard data differently negative entry cannot nonnegative option correspond zero effectively discard input data inner negative enforce locality angular argument constraint allows replace gramian negative distance matrix kxi xjk  DQ DQ finally constraint allows neighborhood nomad modulate actual width kernel function develop intuition manifold capability nomad analyze theoretically dataset mention sdp formulation peng wei developed cluster algorithm actually delivers cluster depends geometry dataset dataset consists segregate cluster diagonal structure empirically dataset sample regular manifold dataset artificial cluster actually preserve manifold structure sec manifold exhibit symmetry demonstrate analytically behavior occurs devote task clustering  analysis nomad 2D dataset analyze input data nomad posse rotational symmetry data uniformly sdp linear program LP circular fourier basis representation allows visualize nomad data dimensional dimensionality entry described angle respectively uniformly distribute circulant matrix nomad circulant circulant matrix diagonalize discrete fourier transform dft diag diag respectively vector eigenvalue hermitian conjugate unitary dft matrix entry exp  hence accord constraint linear program data manifold express objective function constraint nomad DQ diag reformulation allows rewrite nomad linear program max shed inner working nomad constraint ensures infinity budget constraint assume remove constraint equivalent program entry correspond eigenvalue violate remove constraint sinusoid constraint allocate budget eigenvalue instead confirms active eigenvalue grows interpret increase intrinsic dimensionality local interaction interpretation circulant 2D shed meaning significant  sengupta  eigenvalue median alu alo dia evolution nomad 2D dataset increase parameter increase concentrate towards diagonal increase active eigenvalue grows uniform distribution eigenvalue median linear trace constraint define diagonal entry circulant matrix diagonal contains plot assign constraint becomes evident diagonal becomes inactive remain diagonal  eigenvectors dimensional cone cartoon representation cone axis eigenvectors interpret parameter effectively local neighborhood manifold standard manifold combination kernel function nomad variable incorporate parameter balance remain constraint non symmetric irregularly sample manifold chosen capture manifold underlie dataset neighborhood capture desire manifold feature avoid capture unwanted structure sample density differs adjust locally dimensional cone nomad effectively embeds data manifold structure rotational symmetry preserve symmetry fully fourier basis decompose fourier basis diag entry sin odd clustering  diag meaning vector extreme ray circular cone eigenvector symmetry axis interpret nomad 2D structure cone mention cone dimensional direction preserve nonnegativity identify rank active eigenvalue rank constraint nomad fan data representation intuitively fan disentanglement datasets complex topology spin model inspire SDPs community detection achieve fan constraint related objective function LP framework geometric understand evolves parameter increase eigenvalue active vector entry slightly eigenvalue becomes active nonzero introduce nontrivial fourier component geometrically vector narrow cone increase cone widens angle vector activates nonnegativity constraint increase necessitates fourier mode finally mode active vector become orthogonal depicts progression active mode summary previous focus solely nomad exhibit cluster sec characterization nomad symmetry drastically neighborhood neighborhood overlap cluster preserve global feature manifold symmetry feature sought manifold nomad reliable manifold analysis technique analyze data manifold nomad experimental previous nomad recovers data manifold idealize 2D dataset extend observation numerically complex datasets analytical transformation  visualize embed dimensional goal dimensionality reduction data manifold nomad standard spectral dimensionality reduction visualize recover multiple manifold cannot effectively recover multiple distinct manifold although linearly separable manifold correctly interestingly nomad inherit limitation nomad parameter manifold recover obtain substantially obtain lloyd algorithm however nomad parameter manifold identification characterization structure  sengupta  input dataset input gramian nomad dataset consist 2D dataset input gramian eigenvectors rank eigenvectors segregate nomad contains eigenvectors disjoint eigenvectors detail within eigenvectors orthogonal dimensional cone cone cartoon representation cone axis eigenvectors cone become linearly separable similarly partition data manifold sec described fourier mode nomad describes fourier mode disjoint orthogonal dimensional cone manifold already circulant submatrices manifold interaction user desire assignment manifold simply adjacency matrix graph compute component discussion experimental demonstrate manifold capability nomad synthetic  knot 1D manifold 3D simplest nontrivial knot meaning  dimension without however manifold procedure sec learns 1D manifold dimensional datasets recover structure nomad respectively uncovers camera rotation orientation source specific handwrite feature demonstrate multi manifold manifold disentangle capability nomad standard synthetic datasets nomad disentangle cluster linearly separable dataset nomad clustering  input dataset input gramian enhance contrast multiple manifold nomad  manifold contaminate gaussian although manifold linearly  nomad correctly submatrices manifold visual clarity enhance contrast  yale mnist digit dimensional embeddings nomad image obtain  angle input vector pixel channel manifold uncovers orientation image marked obtain illumination source input vector pixel manifold uncovers illumination frontal illuminate image handwritten instance digit input vector pixel image digit respectively manifold uncovers orientation manifold  feature slant thickness detail perceive zoom plot input gramian enhance contrast manifold lamp manifold image obtain lamp  angle input vector pixel channel plot input data 2D spectral embed correspond differently nomad correctly submatrices manifold visual clarity enhance contrast furthermore nomad recovers manifold  sengupta  input dataset input gramian 2D embed 2D manifold embed dimensional ambient dimension regular sample 2D grid remain gaussian nomad recovers 2D structure distortion along data indicates correspond entry zero nomad effectively tile dataset collection overlap local neighborhood data patch information reconstruct intrinsic manifold geometry recovers manifold viewpoint structure finally nomad capture structure 2D manifold living dimensional nomad assigns local patch data non zero zero elsewhere local patch tile manifold overlap cluster recover grid structure tile manifold disentangle multi layer nomad recursive application nomad successively decrease enhances manifold disentangle capability pseudocode nomad input matrix parameter return clustering  input gramian input gramian input gramian recursive nomad application multi layer nomad matrix compute successive application algorithm multi layer nomad  linearly non separable manifold layer assigns manifold cluster evolution successive matrix multilayer nomad correctly identify cluster linearly separable something unattainable layer nomad cluster interestingly manifold already segregate application nomad direction eigenvectors nomad layer sieve unwanted eigenvalue unsupervised fashion algorithm data analysis automate selection non trivial task additional sequence appendix research develop algorithm fully understand multi layer nomad behavior geodesic distance preservation nomad versus exist manifold technique manifold discovery upon appropriate metric active research metric allows comparison output objective explicitly gear towards dimension reduction towards variance maximization prefer metric emphasize preservation intrinsic structure manifold preserve intrinsic distance along manifold something guarantee neighborhood structure remain concretely compute dataset graph distance graph compute geodesic distance  sengupta  data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb  data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb manifold nomad data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb data percentile intersection ratio nomad isomap LLE LLE mod LTSA spectral emb manifold nomad outperforms comparison robustness geodesic distance addition manifold description experimental protocol sec emb directly computes distance noisy data clustering  dijkstra algorithm finally sort distance increase truth dataset additional dimension gaussian standard deviation noisy dataset geodesic distance sort embeddings manifold algorithm nomad instead resort non zero entry graph connectivity nomad yield similarity matrix derive distance formula graph compute sort geodesic distance distance preservation  percentile distance percentile truth distance data sample manifold nomad performs par algorithm comparison however manifold nomad clearly outperforms nearly performance distance computation noisy data heuristic non convex solver nomad standard SDPs involve variable complexity consequently standard solver struggle datasets nomad lends data friendly implementation related max   convexity exchange reduce unknown problematic constraint involve replace easy enforce gain appendix description algorithm however strictly constraint equivalent completely positive matrix completely positive CP exists rank whereas matrix doubly nonnegative DN DN matrix CP interested nomad completely positive affirmative theoretically implementation nomad whereas CP matrix convex cone matrix inside project matrix NP rank issue critical determines unknown rank easy nomad cluster indeed whenever nomad cluster CP sec regularly establish sufficient CP recall  sengupta  empirically rank proxy nonnegative decomposition compute rank symmetric NMF plus minus standard deviation relative error compute  difference stem random initialization datasets clearly properly reconstruct circulant circulant proposition appendix nomad circulant matrix CP naturally theory shed onto scenario unclear exist  experimental viewpoint symmetric nonnegative matrix factorization SNMF appendix proxy CP rationale approximation SNMF tight highly likely CP properly chosen rank SNMF indeed accurately approximate however reconstruction CP rank non convex algorithm appendix conclusion SNMF approximation cluster improve reconstruction expense convex algorithm nomad   solver  convexity however previous conversion theoretical practical difficulty easily overcome propose algorithm nomad convex augment lagrangian formulation redefine variable nomad max DP optimization literature handle constraint augment lagrangian augment lagrangian respect constraint DP clustering  YY YY YY YY YY YY YY YY YY YY YY YY comparison obtain standard sdp solver rank non convex approach remain denotes rank obtain dataset dataset display relative error matrix interestingly cluster diagonal structure matrix increase softer suggests rank associate lagrange multiplier min projection operator onto negative orthant min max multiplier argmin conditional gradient SDPs orthogonality constraint introduce efficient algorithm max instance modify algorithm efficiently sdp max function differentiable concave iterative algorithm consists iteration algebraic eigenvector   sengupta  algorithm conditional gradient algorithm SDPs orthogonality constraint input function minimize parameter output initialize algebraic eigenvector  converge algorithm instance frank wolfe conditional gradient algorithm without perform projection nonnegative linear combination positive semidefinite matrix positive semidefinite iteration maintain invariant  extend algorithm handle orthogonality constraint convex cone positive semidefinite matrix trace orthogonal vector yield constraint seek max fortunately constraint eigenvector computation sum matrix  suffices  reduces naturally yield iterative summarize alg algorithm performance guarantee  proposition appendix proposition curvature constant sup iterates alg satisfy conditional gradient algorithm nomad alg summarizes propose multiplier iteration inner alg remark multiplier desirable inner precision implementation  clustering  algorithm conditional gradient algorithm nomad input matrix parameter output nomad initialize   algebraic eigenvector  converge highly accurate eigenvector computation lanczos algorithm accuracy alg solves maximization eigenvector algebraic eigenvalue minimization simply compute eigenvector algebraic eigenvalue enforce orthogonality constraint compute maximum eigenvalue operation efficiently complexity complexity alg  plus additional factor compute proposition alg yield accuracy iteration compute operation  iteration  iteration operation additional operation overall complexity alg  lanczos algorithm accuracy  complexity per iteration comparison standard sdp solver complexity per iteration solver involve significant memory usage algorithm optimal complexity experimental analysis throughout iteration alg constraint objective DP illustrate typical empirical convergence convergence objective clearly superlinear linear convergence nonnegativity constraint accelerate latter rate future research  sengupta  iteration RMSE iteration objective iteration RMSE iteration objective prototypical behavior propose conditional gradient nomad solver iteration progress plot RMSE average compute non zero entry iteration RMSE linearly multiplier plot display objective DP usually converges iteration reference orange return standard sdp solver propose algorithm enforces nonnegativity constraint nomad accurately although accurate practical purpose exactly enforce constraint standard solver enforce nonnegativity constraint accurately however exactly enforce enforce precision sometimes exactly comparable suitability propose nomad solver vast majority propose enforces nonnegativity constraint accurately standard solver enforces constraint exactly  propose jagged standard solver constraint accurately enforce circulant representation comparison compute nomad sdp solver SCS  rank   solver sec propose conditional gradient   latter guarantee convergence global optimal particularly specially relatively sec solver convex standard sdp solver propose solver significantly faster important theory difference grows significantly standard solver memory quickly SCS implement instance  propose solver efficient memory highlight extend computational capability propose conditional gradient cannot handle standard sdp solver input gramian vectorized image digit zero mnist propose algorithm compute nomad upper limit standard solver 2D embed sec detail computation clearly image organize intrinsic characteristic elongation rotation clustering  input dataset input gramian standard CGM input dataset input gramian standard CGM input dataset input gramian standard CGM input dataset input gramian standard CGM input dataset input gramian standard CGM input dataset input gramian standard CGM comparison standard sdp solver propose conditional gradient solver CGM nomad datasets practically indistinguishable deliver faster dataset SCS  conditional gradient solver non convex solver non convex solver comparison nomad solver SCS  highly optimize code non optimize python code others nonconvex solver faster convex unfortunately yield converge global maximum conditional gradient algorithm propose faster SCS  faster guarantee converge global optimum additionally propose algorithm handle seamlessly desktop 8GB ram SCS  memory instance  converge instance  sengupta  2D embed digit mnist compute fashion image digit obtain matrix compute nomad propose conditional gradient alg contrast traditional sdp solver handle dense matrix approximately data organize accord visual characteristic digit orientation elongation conclusion nomad multiple dimensional data manifold highdimensional sdp instance convex polynomial unlike manifold algorithm user kernel  involve computational performance nomad focus non convex   style algorithm perform theoretical empirical analysis finally algorithm nomad conditional gradient propose algorithm convex efficient algorithm allows analyze behavior nomad datasets related future escape attention nomad instance kernel alignment supervise kernel alignment previously formulate sdp beyond distinction supervise unsupervised scenario differs significantly nomad goal optimally combine pre compute kernel matrix whereas nomad learns matrix scratch nonetheless connection kernel promising investigate future