article understand behavior graph orient semi supervise algorithm limit numerous data demonstrate intuition collapse limit become inconsistent corrective data driven parametrization scheme propose along theoretical analysis asymptotic performance approach surprisingly behavior theoretical performance gaussian mixture model data illustrate throughout article thereby importance propose analysis practical data significant performance gain practical data classification propose parametrization keywords semi supervise kernel random matrix theory dimensional statistic introduction semi supervise consists classification scheme combine label numerous unlabelled data advent data paradigm supervise implies impossible pre label sometimes sample marginal attract renew attention appeal alternative unsupervised excludes possibility exploit data refer overview important subset semi supervise concern graph approach considers data instance vertex graph wij encode similarity usually define kernel function radial kernel wij kxi xjk focus article motivation expectation instance tend belong vertex tend aggregate standard recover unlabelled data consist various random label propagation algorithm graph  allocate mai couillet node belong obtain decision individual unlabelled node popular widely recognize highly perform pagerank approach algorithm particularity interrelate expression stationary stationary coincide optimization constraint independently establish notably equality constraint label node relaxation approach instead modification label node ensure erroneously label data poorly informative label data hinder algorithm performance graph related optimization choice matrix representative inter data affinity core scientific research debate mainly defines difference scheme suggests standard laplacian representative advises normalize laplacian approach individual choice correspondingly version label propagation graph exists another manifold semi supervise contrast approach involve manifold decisive role task exist article theoretical analysis comprehensive comparison graph presently beyond analytical gaussian mixture data model article violates manifold assumption appropriate feature kernel function mapping exists dimensional manifold data demonstrate cluster behavior couillet  george sufficient data available estimate manifold manifold competitive performance clearly scope future investigation comparative manifold versus graph approach another recent alternative ssl graph signal processing perspective classification smooth signal similarity graph task consists recover bandlimited understood graph fourier transform domain graph signal sample return graph ssl likely choice graph representative arises essentially built upon intuitive arise dimensional data consideration mostly inaccessible theoretical indeed non linear expression affinity matrix involve assume algorithm output although explicit hinder possibility statistically evaluate algorithm performance finite data assumption article instead dimensional data assumption appropriate data paradigm random matrix analysis semi supervise proposes instead derive author knowledge theoretical performance aforementioned algorithm limit statistically distribute data precisely due data assumption intuition aforementioned algorithm collapse rate algorithm remain consistent regime specifically recall graph semi supervise exploit similarity data cluster behavior data node data assumption similarity approach suffers curse dimensionality span grows exponentially data dimension data structure sparsely distribute pairwise distance tend regardless belonging gaussian mixture model define subsection phenomenon regime ought separable normalize distance kxi xjk random data instance generate model converges constant irrespective gaussian mixture consequently similarity define wij kxi xjk asymptotically data instance behavior therefore invalidate intuition semi supervise classification hence likely render graph ineffective consequence asymptotic irrespective nonetheless sensible classification data generate model achieve appropriate amendment classification algorithm enforce due fluctuation around asymptotic limit limit reminiscent author indeed limit irrespective presence infinitely unlabelled sample fix despite  author experimentally non trivial classification binary task thanks difference however theoretical behavior analysis fail recover fluctuation inspire generalize algorithm propose introduce normalization parameter function regularize affinity traditional laplacian normalize laplacian algorithm generalize optimization framework contribution quantitative performance generalize graph semi supervise algorithm dimensional  data radial kernel technically random matrix approach developed couillet  george finding summarize irrespective choice data affinity matrix classification outcome strongly bias label data unlabelled data tend mai couillet classify label node propose normalization update standard algorithm limitation aforementioned bias choice affinity matrix parameter strongly impact performance importantly within framework standard laplacian normalize  although widely literature fail dimensional data regime algorithm pagerank approach asymptotically acceptable belonging attribute individual node algorithm asymptotically gaussian distribution covariance statistical ratio label versus unlabelled data derivative kernel function limit kxi xjk recall irrespective genuine notably allows predict asymptotic performance semi supervise algorithm latter outcome unfold exist gaussian mixture model classification impossible despite pagerank consistency justify choice optimal approach optimal demonstrate data convey sometimes dramatic improvement classification rate task sufficient asymptotic consistency gaussian kernel fail cannot dimensional version concentric sphere task throughout article theoretical related discussion confirm illustrate simulation gaussian mixture data popular mnist data serf comparison theoretical data consistent theoretical finding mnist data despite depart dimensional gaussian mixture assumption suggests robustness assumption apply data indeed limit behavior gaussian mixture input characterize article mostly technical analysis reveals inherent graph ssl extend beyond gaussian hypothesis notation binary function vector identity matrix norm euclidean norm vector operator norm matrix operator diag diag diagonal matrix diagonal specify couillet  george random random matrix analysis semi supervise variable DP  multidimensional concerned vector diagonal matrix maximum entry absolute matrix operator norm optimization framework data vector belonging CK association vector vector refer label remain vector unknown refer unlabelled vector within label unlabelled subset data organize vector belong subsequent vector similarly vector already notational convenience impact generality affinity relation vector matrix define kxi xjk function matrix adjacency matrix node graph indexed vector denote diagonal matrix dii wij node associate define matrix fik evaluate belong convention typically graph semi supervise affect fik label data null fik attribute unlabelled data affected resolution optimization framework propose  wij fik  fik otherwise parameter generic formulation coincides standard laplacian approach normalize laplacian approach importantly equation naturally motivate observation wij enforce fik  wij freedom choice fik  denote mai couillet easily convex quadratic optimization linear equality constraint explicitly inu affected mere comparison fik unlabelled data perform allocate index Cˆ vector Cˆ  argmax fik passing formulation implies  matrix stationary algorithm constitute update replace  algorithm corresponds standard label propagation pagerank algorithm semi supervise difference systematically reset evolve related robustness pre label error technical objective article analyze behavior regime gaussian mixture model data appropriate growth rate gaussian mixture statistic avoid  classification grows proceed evaluation behavior model theoretical model assumption remainder article assume data extract gaussian mixture model compose specifically consistently previous instance vector label unlabelled regime ensure CK statistic evolve remain somewhat constant distance ensure classification become asymptotically infeasible trivially earlier consideration behavior covariance cardinality prescription random matrix analysis semi supervise assumption growth rate besides PK PK    convenient define   label data notation comment assumption unlike previous label data data dimension fix unlabelled data suppose infinite assume regime simultaneously allows investigate ssl context dimensional data impose rate respect rate allows characterization limit ssl performance function hyperparameters data statistic non trivial classification scenario classification neither asymptotically perfect impossible instead solely retrieve consistency bound function growth rate allows precise parameter optimal performance bound claimed ssl handle scenario assume multiple actually maintains validity valid limit become trivial numerically confirm mai couillet fix demand statistical assumption input data beyond scope investigation item assumption mostly technical convenience simplify analysis naturally extend    away zero infinity necessity item detailed analysis spectral matrix later article item relaxed easily mere unsupervised comparison  asymptotically almost surely perfect classification impose growth constraint data ensure non trivial classification assumption induces seemingly  implication easily justified concentration argument max kxi xjk equation cornerstone analysis vector essentially distance another irrespective strike evidently opposition motivation optimization formulation introduction immediately entail bound asymptotically inconsistent indeed equation advantageous allows taylor expansion wij kxi xjk around sufficiently smooth around ensure subsequent assumption assumption kernel function function continuously differentiable neighborhood assumption constrain aside local behavior around restrict matrix arise nonnegative definite kernel standard machine theory advise core technical article consists expand subsequently intervene taylor expansion successive matrix non vanish operator norm indeed magnitude individual entry taylor expansion magnitude operator norm matrix retain matrix non vanish operator norm technical detail advanced random matrix consideration appendix couillet  george introduce technical theoretical parallel series technical propose notably assumption along simulation instance kink despite matrix entry magnitude random matrix analysis semi supervise gaussian mixture data model data image mnist database exp classical gaussian kernel become discussion depict vector obviously decision hinge concern behavior matrix regime per assumption proposition assumption unlabelled vector fik random variable function independent proof proposition intermediary proof theorem appendix proposition overview outcome semi supervise algorithm fik therefore irrespective fik strongly bias towards induces systematic asymptotic allocation illustrates phenomenon synthetic data gaussian mixture mnist data gaussian kernel mai couillet pursue analysis proposition assume comparison fik revolves around depends induces constant offset vector thereby intervene allocation independent thereby possibly intervene allocation undesired depicts various choice deleterious outcome avoid couillet  george later article choice sometimes generally inappropriate discussion induces important consequence adapt semisupervised algorithm data comparison upon normalize Fˆ fik upon fik directly parameter chosen amendment algorithm accord proposition performance semi supervise algorithm relies upon magnitude undefined thorough analysis allows understand asymptotic behavior normalize Fˆ Fˆ Fˆ theorem assumption unlabelled Fˆ define  proposition independent    CTB besides exists induced label variable conditionally random matrix analysis semi supervise gaussian mixture mnist data gaussian kernel statistic independent realization longer outside regime theorem appendix asymptotic behavior Fˆ generalizes theorem entry Fˆ Fˆ theorem amount probability correctly classify unlabeled vector genuinely belonging asymptotically probability maximal mention formulate corollary corollary assumption notation theorem max mai couillet max gaussian distribution function independent corollary allows approach empirical classification accuracy consistently estimate probability classification corollary theorem append theorem corollary similarly generalize corollary appendix corollary display comparison simulated accuracy various digit mnist data theoretical apply gaussian mixture model assume covariance empirical covariance individual digit evaluate image mnist database despite obvious inadequacy gaussian mixture model image database theoretical prediction agreement practical performance surprising adequacy theoretical prediction corollary beyond neighborhood consequence semi supervise beyond immediate consequence corollary exists gaussian mixture model semi supervise algorithm necessarily fail classify corollary assumption notation corollary sgn sgn classification rate cannot simultaneously necessarily inconsistent classification nonetheless easy inconsistency cannot mutually orthogonal bound dimensional data indeed random matrix analysis semi supervise simulation corollary corollary simulation corollary corollary theoretical empirical accuracy function mnist data digit digit digit gaussian kernel average iteration vector PK PK inconsistency occurs exist understand inconsistency extreme scenario intensity  direction orthogonal scenario smin  smax  smin smax min smin smax max smin smax inconsistency smin smax contrarily scenario symmetric matrix aij bij dimension AB aij bij amm bmm mai couillet inconsistency likely direction choice suboptimality kernel consequence previous concentrate semisupervised classification easily equality respectively  along corollary implies necessity fully discriminate gaussian mixture corollary semi supervise classification consistent derivative involve kernel desire polynomial consistently estimate discussion subsection surprising outcome derivative widely gaussian kernel exp fulfil satisfies indicates discrimination assumption asymptotically gaussian kernel remark illustrate discriminative task isotropic gaussian trace covariance matrix irrespective choice bandwidth gaussian kernel constant accuracy mere polynomial kernel upon derivative demonstrates performance dimensional isotropic gaussian vector tend concentrate sphere suggests gaussian kernel inappropriate dimensional generalization concentric sphere task efficient dimension passing confirms positive accuracy obtain another choice already identify couillet  george thoroughly investigate couillet  enforce normalize data asymptotically perfect classification assumption random matrix analysis semi supervise gaussian kernel polynomial kernel exp empirical accuracy gaussian data claimed ensure non trivial growth rate regime asymptotically perfect classification achieve aforementioned statistical nonetheless careful asymptotic necessarily entail outstanding performance practical finite dimensional scenario indeed discard visibility expression theorem finite cancel difference difference covariance compensate reduction variance trial mnist particularly emphasize remark impact remark concern impact asymptotic performance upon covariance precisely diagonal reduction increase increase reduce diagonal variance thereby mechanically increase classification performance addition label data variance diverges performance tends random classification parameter optimization estimation previous emphasize importance kernel function specific derivative quantity however unknown quantity mere concentration argument nonetheless mai couillet random simulation theory corollary theoretical empirical accuracy function gaussian data gaussian kernel average iteration kxi xjk consequence theorem subsequently corollary verbatim derivative appropriate optimization choice along appropriate choice ensures asymptotic consistency semi supervise non trivial asymptotic accuracy achieve choice however optimal subsection devote optimization maximize average precision criterion absence prior information fully estimate optimal discus heuristic optimal subsequently denote per theorem chosen classification accuracy maximize corollary suggests estimate evaluation quantity expression however directly accessible statistic data instead propose heuristic retrieve reasonable choice optimal sufficient mapping satisfy random matrix analysis semi supervise hence induce simultaneous reduction increase define difference proposition definition proposition ensures exi Fˆ Fˆ exi Fˆ Fˆ thereby evenly balance average resolution balance typically desirable output central display oppose largely undesirable display offset obviously variance Fˆ Fˆ choice optimal nonetheless experimental scenario practical variance tend sufficiently choice appeal heuristic motivation proportional indicates unbalanced label data deviate zero subsequently simulation remark dramatic importance pagerank significant performance loss utmost importance unlike ass empirically consistent estimate obtain presently elaborate estimate tab obtain empirically label data directly accessible indeed central limit theorem guarantee  magnitude   however access estimate instance pagerank algorithm described algorithm easily assumption performance comparison average precision pagerank propose heuristic improvement versus oracle estimator precision maximize curve mai couillet algorithm estimate kxi xjk kxi xjk define Fˆ Fˆ reduce label data min obvious notation Fˆ Fˆ return snapshot typical classification precision obtain image gain performance surprisingly performance obtain impressively optimal simulation reveal unstable estimate estimate algorithm implicitly exploit resolution equation observation obtain retrieve define proposition access allows access instance allows access intervene per maximize distance however addition cumbersome aspect induced procedure instability imply multiple evaluation setting operation alter variance easily estimate delicate derive optimize addition conclude remark article series consist evaluate performance  machine dimensional data regime rely derivation couillet  george taylor expansion radial kernel matrix around limit kxi xjk choice kernel function merely affect classification performance successive derivative earlier analysis induces phase transition normalize data asymptotic classification error rate vanishes however unlike random matrix analysis semi supervise oracle algorithm pagerank average precision mnist data digit digit digit gaussian kernel expression core limit performance assumes importance kernel assumption exp semisupervised fails classify gaussian mixture  unsupervised LS svm paradox deserve structural spectrum unsupervised supervise kernel matrix essentially equivalent matrix matrix thereby strongly disrupt mai couillet behavior kernel essentially gaussian mixture model assume decision vector mere euclidean distance simplistic although widely explains coincidence performance gaussian mixture model data indeed radial function specially adapt image vector wavelet convolutional filter kernel likely operates statistic input vector hence action gaussian mixture data generalize involve data orient kernel data exploitable freedom instructive proof remain expansion almost vanish strongly obtain inverse matrix discard altogether implies intra unlabelled data kernel virtually asymptotic remark accord implies vanish classification rate suggests unsupervised cluster performance obtain couillet  george achieve despite presence possibly numerous unlabelled data due mismatch ssl definition promising avenue investigation consist introduce appropriate parameter label propagation optimization ensure effectively algorithm simulation elementary amendment indeed possibly strike performance improvement consideration future acknowledgment  project   CE appendix preliminary additional notation useful proof canonical vector otherwise respectively canonical vector label unlabelled data   notation introduce generalize version theorem random matrix analysis semi supervise theorem unlabelled vector Fˆ define assumption  theorem induced random variable         tab  induced random variable         denote probability classification unlabelled unconditional mai couillet probability recall probability classification probability Fˆ maxa Fˆ accord theorem asymptotically probability particularly corollary corollary theorem conditionally exp theorem unconditionally theorem remainder appendix dedicate proof theorem corollary directly unfold appendix proof theorem proof theorem taylor expand normalize unlabelled data Fˆ convergence kxi xjk expansion yield random equivalent  Fˆ  proposition directly obtain  proof demonstrate convergence gaussian variable  central limit theorem argument taylor expansion sketch development  intermediary retrieve  algebraic calculus recall expression unnormalized unlabelled data inu 1D proceed development subsequently expression owe convergence kxi xjk random matrix analysis semi supervise taylor expand wij kxi xjk around obtain expansion already evaluate couillet  george definition  diag       diag   tab   sub matrix approximate expression obtain directly extract correspond subset apply diag diag 1D taylor expand around 1D diag diag diag diagonal matrix taylor expansion 1D 1D directly extract expression similarly 1D 1D 1D suffices taylor expansion 1D 1D respectively normalize organize mai couillet dealt therefore simply combine completes linearization Fˆ derivation simpler instructive overall behavior indeed development remain discard already addition vector matrix non informative classification identical intermediary variable entry irrelevant proposition theorem noteworthy remain precisely become vector informative kernel matrix development algorithm unsupervised information data important remark improvement semi supervise algorithm efficiently information calculus development finally       specify residual random variable dependent gathering successive magnitude proposition straightforwardly proven central limit theorem focus examine  theorem proven random matrix analysis semi supervise item theorem describes behavior Fˆ recall sufficient vector gaussian vector linear combination gaussian variable deterministic accord asymptotically gaussian  central limit   rewrite tar  symmetric exists orthonormal matrix diagonal  tar TU    unitary invariance   sum independent identically distribute random variable   lyapunov central limit theorem  theorem remains var ensure central limit theorem var var remains evaluate expectation covariance matrix obtain theorem    cov    equation retrieve asymptotic expression completes proof item theorem item easily