perform regression data variable beyond linear interaction individual variable interaction compute explicitly computational complexity naively prohibitive introduce randomise algorithm discover interaction probability mild runtime subquadratic interaction discover almost linear whilst weaker interaction operation strength underlie transform interaction closest efficiently subquadratic algorithm xyz implement demonstrate efficiency application genome association interaction screen core ghz cpu keywords interaction dimensional data regression computational tradeoff introduction response vector matrix associate predictor interaction reveal important relationship improve predictive variable fitting model involve interaction involve serious computational challenge simplest isaac newton trust career scheme alan turing institute  grant EP  programme grant EP interaction consists screen inner outcome wise YT complexity naive implementation quickly becomes infeasible typically interested maximise absolute correlation dot optimisation computationally intensive challenge task fitting linear regression model involve pairwise interaction   intercept θjk coefficient interaction respectively random contribution interaction dimensional setting establish equivalence closest assume predictor outcome binary xij later relax assumption define zij YiXij straightforward equivalent   connects interaction literature computational geometry closest introduce xyz algorithm randomly project dimensional exploit ability sort computational achieve subquadratic linear complexity quantity YT bulk approach locality sensitive hash optimise specific regression model interaction building algorithm lasso xyz procedure apply lasso interaction computational  implementation core xyz algorithm extension lasso package xyz available github cran related closest algorithm computational geometry extensive literature model interaction statistic review xyz algorithm interaction dimensional data related approach avoid quadratic variable restrict seek important interaction involve discover specifically lasso data interaction matrix predictor lasso augment matrix model cart fashion aim identify important interaction involve discover however signal correspond important interaction detect concrete phenomenon generate randomly entry independent uniform distribution suppose response  distribution xij regression challenge variable  model entry obtain  model respect hierarchical principle interaction hierarchical principle useful impose model however impose principle model imply interaction easily difficulty due interaction mask signal  easy approach increase interaction iteratively tackle sort issue randomise procedure however cannot eliminate interaction approach guarantee likely discover interaction allude earlier pure interaction related specifically bichromatic computational geometry research focus algorithm computationally optimal whilst dimension constant algorithm computational complexity meaningful statistical typically approach subquadratic complexity exception lightbulb algorithm employ strategy binary data optimal random projection modify handle continuous data detect interaction dimensional regression setting zij xij equivalent magnitude entry matrix latter amenable matrix multiplication algorithm theory thanei meinshausen shah deliver subquadratic complexity roughly however constant hidden notation typically practical implementation unavailable strassen algorithm matrix multiplication algorithm regularly knowledge complexity roughly improvement brute slight strategy closely related locality sensitive hash LSH encompasses hash procedure mapped bucket probability conduct mapped bucket approach LSH optimise connection detailed appendix seemingly attractive alternative subsampling LSH strategy employ random projection motivate theoretical guarantee johnson lindenstrauss lemma surprisingly random projection instead subsampling scheme quadratic interaction theorem approach similarity procedure  project data dimensional representation improve upon naive brute empirically proven guarantee improves complexity naive random intersection algorithm shah meinshausen potentially deeper interaction data binary interaction complexity linear achieve however generalise approach continuous data embed within regression procedure transform data predictor independence distance correlation setting reveal important interaction computational linear however distribution transform variable binary transform variable vector independence unhelpful propose approach particularly organisation response predictor binary demonstrate convert closest introduce version xyz algorithm solves random projection random projection distribution optimal purpose version xyz algorithm along analysis probabilistic guarantee recovers important interaction extend xyz algorithm continuous data xyz algorithm interaction dimensional data demonstrate xyz algorithm embed within algorithm highdimensional regression dimensional regression model interaction subquadratic complexity contains variety numerical simulated data complement theoretical demonstrate effectiveness proposal conclude brief discussion proof appendix xyz algorithm binary data version xyz algorithm applicable binary xij algorithm stage version define zij YiXij γjk  γjk interaction strength easy interaction express γjk normalise distance indeed γjk YT   YT γjk   equivalence suggests distance involve across incur mention introduction avoid quadratic incur typically exponential typically computationally infeasible however project dimensional dimensional perform johnson lindenstrauss lemma roughly project dimension faithfully preserve distance particularly relevant issue project dimension johnson lindenstrauss lemma efficient observation however encouragement dimensional projection RT   implies perfect interaction zero distance project later approach linear importantly interested projection preserve distance johnson lindenstrauss lemma strategy project dimensional vector random projection XT threshold sort computation thanei meinshausen shah  efficient candidate interaction γjk random projection repetition interaction candidate EL probability approach summarise algorithm xyz algorithm schematic overview algorithm xyz algorithm input parameter joint distribution projection vector projection threshold interaction strength respectively output interaction via zij YiXij random vector distribution project data XT γjk parameter choice random projection joint distribution distribution dense sparse projection sample random deterministic index without replacement distribution distribution specify later vector RM independent component distribute accord define random projection vector configuration xyz algorithm characterise fix parameter distribution projection vector distribution subsample sample replacement projection threshold interaction strength threshold xyz algorithm interaction dimensional data denote collection parameter subclass fix dense projection independent component distribute accord denote distribution within framework sample without replacement ξdense joint distribution subsampling  distribution obtain subsampling replacement  joint distribution  minimal subsampling ξminimal parameter  threshold randomly positive integer ξminimal  suppress dependence fix distribution notational simplicity define univariate absolutely continuous symmetric distribution bound density finite restriction continuous distribution ensures ξminimal invariant choice distribution fix yield algorithm moreover simply   subsampled symmetry boundedness density finiteness mainly technical theoretical development assume without loss generality additional restriction absorbed choice minimal subsampling subset randomise algorithm outline however theorem minimal subsampling essentially algorithm wider surprising beneficial consequence optimal threshold fix choice continuous distribution inconsequential minimal subsampling choice yield subquadratic approach linear interaction discover bulk remain interaction optimality minimal subsampling algorithm ξdense  ξminimal return interaction probability index thanei meinshausen shah illustration xyz algorithm interaction panel illustrates interaction panel closest transformation zij  panel depicts closest data project xyz algorithm interaction maxj γjk algorithm define ξdense ξdense define  ξminimal analogously underlie fix moreover fix asymptotic regime sequence response predictor matrix correspond interaction strength maxj probability function correspond uniformly random domain assumption sequence interaction strength matrix exists cpn exists exists non increase assumption weak typically maximal strength interaction essentially unique interaction maximal strength maximal interaction strength bound away complexity interaction mention earlier maximal interaction strength retain whilst strength impossible distinguish remain interaction ensures separation maximal strength interaction bulk interaction xyz algorithm interaction dimensional data aid readability suppress dependence quantity notation define computational operation perform algorithm correspond theorem exists inf ξminimal inf  inf ξminimal exists inf ξdense theorem optimal achieve minimal subsampling surprising improve computational complexity brute approach dense gaussian projection hence reduce complexity computational effort involve compute dense projection indeed compute remain stem dense projection detect project dimensional version xyz optimality minimal subsampling previous approach algorithm refer xyz algorithm algorithm version xyz algorithm input subsample projection threshold interaction strength output interaction via zij YiXij distribution XT γjk simplify version minimal subsampling proposal previous fix random potential additional gain consecutive probability minimal theorem simpler approach preferable uniform distribution replace continuous distribution yield identical thanei meinshausen shah illustration component horizontal location numbered respectively sort allows traversal unique location checked colour index return perform sort concatenation unique location component index procedure illustrate union cartesian computational complexity driven sort whilst index linear however loop output incur additional typical usage reader familiar locality sensitive hash LSH interpretation LSH appendix discus detail impact minimal subsampling complexity xyz algorithm discovery probability attains computational statistical xyz upper bound computational operation perform xyz algorithm subsample repetition  explain construction subsampled interaction exceed interaction strength threshold omit constant factor upper bound bound instead dominate therefore upper bound asymptotically equivalent imply bound tight interaction strength retain probability hence interaction probability xyz algorithm interaction dimensional data demonstrates xyz algorithm interaction whilst incur subquadratic computational theorem  distribution function correspond random interaction strength γjk interaction strength threshold  define define  assume finally discovery threshold minimal ignore constant factor bound away dominant  typically γjk γjk interaction relatively bulk interaction indeed suppose proportion interaction strength   concrete exponent around significantly exponent brute approach incur exponent interested interaction strength linear approach matrix multiplication compute XT interaction naive matrix multiplication operation faster alternative algorithm theoretical xyz achieve target interaction strength somewhat moderate interaction strength xyz strictly matrix multiplication algorithm tend unstable lack implementation therefore rarely advantage xyz algorithm optimal memory usage whilst theorem concern discovery interaction strength discover fix interaction strength multiplicative constant however guarantee discover bound theorem longer minimise interaction hence yield favourable exponent careful choice depends xyz enjoy performance optimal choice exists discus estimate data clearly another thanei meinshausen shah optimal choice parameter choice dominate others fashion define arg min implicitly assume  unique peculiar proposition inequality strict unique  unique pareto optimal although definition involves  estimate sample γjk numerically optimise plugin version objective approximately optimal interaction continuous data previous demonstrate xyz algorithm efficiently simplest interaction binary modification algorithm continuous continuous discus regression continuous binary  without loss generality assume kyk approach motivate observation inner YT interpret inner modify xyz zij sgn xij projection vector probability compute RT RT  sgn  xij sgn xik xij sgn xik xij sgn xik sgn   γjk respect randomness equivalently random index fix calculation xyz algorithm interaction dimensional data bound theorem continuous replace interaction strength γjk continuous analogue γjk model  generate randomly entry drawn independently probability non interact γjk calculate interaction strength sgn  sgn   probability randomness simulation theorem estimate computational complexity discover continuous continuous previous demonstrate resampling non uniform transforms setup continuous binary response continuous previous strategy continuous response matrix continuous predictor cannot resampling interaction examine transformation binary data matrix randomize mapping define transformation via function xij xij transformation apply independently entry predictor matrix subsample probability ijX sample probability proportional proposition transform xij sample index accord kyk probability sgn   kyk xij xik define continuous analogue interaction strength γjk transform kyk xij xik thanei meinshausen shah quantity substitute theorem yield upper bound xyz transform data corollary  distribution function correspond random interaction strength interaction strength threshold  define define  assume finally discovery threshold minimal ignore constant factor computational depends critically distribution interaction strength  gain understand impact transformation distribution subsequently model xij xik independent identical sub exponential distribution symmetric introduce practically useful choice context model unbiased transform choice transform satisfies unbiasedness requirement xij requirement uniquely defines transform refer unbiased transform proposition xij transform version satisfies xij xij furthermore interaction strength sgn   kyk  proposition monotone function inner  remark entry entry ith maxj xij proposition version performance unbiased transform apply data generate model define quantity xij xik asymptotic regime diverge tends infinity suppress notation introduce assumption xyz algorithm interaction dimensional data xij xik  satisfies bound ensures non interaction strongly correlate actual interaction allows dimensional setting theorem assume entry zero almost surely assume corollary unbiased transform respect randomness improve significantly quadratic unlike binary xij xik necessarily linear xij iid uniform interaction strength interaction YiXij xik kyk kyk kyk substitute theorem complexity roughly substantially quadratic loss avoidable additionally outlying entry normalise matrix wise maximum shrink towards limit impact normalisation cap entry absolute bound interaction strength proposition discriminate interaction cap closely related apply transform transform transform sgn xij zero coin toss transform xij sgn xij interaction strength sgn   kyk yisgn xij sgn xik thanei meinshausen shah transform recovers linear achieve binary interaction perfect xij xik transform adversely affected presence outlying entry theory relax assumption entry subexponential distribution facilitate comparison unbiased transform impose assumption analogous xij xik xij xik satisfies theorem suppose entry zero subexponential distribution assume corollary transform respect randomness transforms yield  exponent unbiased transform transform bound data whereas hence signal transform unbiased transform application lasso regression version interaction involve variable interaction dot xyz algorithm lasso pairwise interaction efficient fashion response matrix predictor matrix interaction define xyz algorithm interaction dimensional data assume centre centre implicitly contains version centre lasso objective function argmin kβk kθk entire matrix centre intercept zero avoid avoid explicitly compute approach review algorithm active strategy employ lasso solver glmnet notation matrix index MH submatrix indexed similarly vector component index  component indexed algorithm active strategy lasso computation input grid output lasso grid otherwise  compute lasso additional constraint   XT     coordinate violate kkt candidate empty update return computation lasso expensive instead performs karush kuhn tucker kkt involve dot interaction residual computational bottleneck naive approach incur stage however similarity kkt interaction interaction indeed computation interaction violate kkt express     necessarily interaction xyz algorithm algorithm   precisely strategy perform kkt xyz accelerate computation interaction model variety variant lasso thanei meinshausen shah elastic net  generalise linear model straightforward penalty interaction coefficient helpful algorithm theory developed previous sequence simulated data comparison minimal subsampling dense projection surprising outcome theoretical analysis extent suboptimality gaussian random projection whilst suffice conclusion johnson lindenstrauss lemma purpose theorem explicitly compute probability retain interaction strength dense gaussian projection  minimal subsampling ξminimal computational budget various fix parameter algorithm ensure average interaction strength specifically choice  threshold quantile distribution ξminimal subsample dlog plot probability discover interaction strength function ξminimal equation  quantile distribution xyz algorithm increase dimension generate data entry sample independently uniformly interaction construct response vector interaction interaction strength construction interaction strength around interaction data configuration simulated xyz plot average dimension choice highlight colour theorem indicates experimental agreement prediction xyz algorithm interaction dimensional data interaction strength discovery probability dimension panel discovery probability function colour decrease correspond dense gaussian projection upper minimal subsampling discovery probability minimal subsampling factor gaussian projection panel discover interaction function data dimension correspond theoretical prediction intercept chosen data actual colour cod orange purple snp data performance xyz closest competitor data discover interaction  data contains data patient  coronary angiography preprocessed version data observation predictor data binary response indicates coronary disease correspond affected healthy contains nucleotide polymorphism SNPs variation dna response vector strongly unbalanced affected unaffected contrast performance xyz  another dimensional interaction  detect interaction assume model xij xik interaction statistic  RT RT assume inner YT maximal easy calculation thanei meinshausen shah  YT maximise inner  considers RT RT approach  somewhat related xyz bound available interaction naive approach subsample fix interaction uniformly random retain refer naive fix interval interaction plot interaction strength function computational eventually discover interaction strength  judgement significantly outperforms others xyz nevertheless discovers interaction average fix approach clearer additional slight modification  data implant artificial interaction strength another xyz clearly outperforms panel besides xyz interaction probabilistic guarantee interaction data guarantee theorem xyz calculate optimal subsample minimal subsampling arg min sum optimisation approximate uniformly sample assume interaction interaction strength interaction strength γjk probability discover xyz algorithm therefore probability interaction naive guarantee however extremely weak probability discover sample bound guarantee theorem dominate complexity xyz naive xyz faster naive empirical comparison factor around xyz algorithm interaction dimensional data interaction strength interaction strength histogram interaction strength interaction sample random exist  data panel interaction strength discover function computation xyz  orange naive purple panel  data rightmost panel implant interaction strength respectively clearly xyz outperforms competitor margin regression artificial data demonstrate capability xyz interaction continuous data explain simulate model   setting setting generate magnitude interaction chosen uniformly interval interaction setting generate hierarchical model θjk sample interaction uniformly generate strictly non hierarchical model θjk sample interaction uniformly exclude coordinate data contains correlation dependence structure generate dag average per node node sample linear function plus independent centre gaussian variance variance correlation matrix unveils variable thanei meinshausen shah substantial variable strongly correlate usually around variable correlation correlation structure easy detect variable predictor construction procedure estimate interaction stage lasso lasso data lasso augment matrix interaction complexity analysis angle regression lars algorithm suggests computational min procedure efficient however struggle situation model regression fail variable involve interaction lasso interaction building interaction matrix compute standard lasso augment data matrix analysis lars algorithm computational complexity min nevertheless approach feasible xyz algorithm parameter target interaction xyz enjoys favourable competitor stage lasso almost linear accurate estimator calculate screen brute normalize prediction error normalise prediction error function  lasso xyz regression brute colour correspond orange purple pink panel panel panel xyz algorithm interaction dimensional data regression data xyz regression continuous data truth unknown data random variable xyz lasso implement glmnet interaction subsample increase variable difficulty regression sample normalize sample error     data   production data contains sample predictor gene expression response continuous   data  gene data continuous sample randomly gene subsample climate climate data  model  model ensemble simulates northern hemisphere response simulates random southern hemisphere data contains observation normalize error correspond   climate axis depicts normalize error axis xyz purple computational advantage prediction error lasso interaction implement glmnet fix xyz xyz algorithm prediction performance lasso apply interaction implement glmnet however xyz around faster thanei meinshausen shah discussion exploit relationship closest interaction former random projection project dimensional sort project algorithm interaction enjoys sub quadratic mild assumption interaction almost linear interaction compute inner collection vector application cluster application future xyz algorithm interaction dimensional data frequently notation observation variable predictor matrix response vector jth variable coefficient interaction γjk interaction strength distribution projection subsample projection vector projection threshold interaction strength threshold configuration xyz algorithm denote probability interaction output xyz algorithm binarized version predictor matrix interaction appendix proof omit earlier proof theorem fix notation convenience ξminimal ξminimal   suppress notation define  ξdense  ξdense reference parameter  distribution subsample denote complexity similarly     constant suppose computationally   similarly ξdense     thanei meinshausen shah  define candidate interaction  minimal whence dlog equation completely determines optimal choice parameter fix therefore henceforth assume chosen discovery probability algorithm proof lemma respectively proof involve proceeds establish  pearson lemma lemma constraint sufficiently minimal subsampling enjoys maximal argument sequence algorithm remain constant cannot subquadratic complexity whilst lemma  contrast minimal subsampling subquadratic complexity assumption theorem auxiliary technical lemma proof lemma bound quantity related ratio minimal subsampling lemma suppose distribution assumption theorem proof γjk sum RHS maximise obey constraint  available otherwise constant  zero    pearson lemma considers non randomise algorithm lemma extend randomise algorithm xyz algorithm interaction dimensional data lemma subsample randomise exists independent sup sup moreover  achieve proof parametrised threshold subsample parameter compute replace threshold assume entry component  non zero component     γjk     lemma exists RHS bound γjk sufficiently constant sufficiently lemma however sufficiently   sufficiently henceforth assume sufficiently γjk similarly thanei meinshausen shah substitute upper bound imply QM QM PM γjk lemma sufficiently constant QM γjk sufficiently minimal subsampling algorithm chooses subsample probability   suppose examine lemma non negative sufficiently instead sufficiently recall sufficiently arbitrarily xyz algorithm interaction dimensional data lemma exists independent sup sup moreover  achieve proof slight abuse notation fix notation lemma define function sup EM lemma exists linear interpolation concave indeed suffices slope successive linear  decrease equivalently reciprocal increase γjk increase decrease RHS subsample fix lemma derivative linear  approach infinity closer origin implies existence sup denotes  function therefore invoke lemma conclude EM EM max combine lemma establishes subquadratic complexity minimal subsampling lemma assumption theorem  proof inequality thanei meinshausen shah lemma upper bound   ignore constant factor ensures lemma ξdense exists inf ξdense proof ξdense parametrised threshold ξdense threshold compute similarly lemma assume without loss generality entry component xij  γjk lemma sufficiently RHS bound γjk constant γjk similarly exists inf ξdense inf ξdense   therefore substitute upper bound imply xyz algorithm interaction dimensional data however inf ξdense inf ξdense  min combine previous lemma theorem proof theorem proof lemma respectively argue suppose contradiction exists sequence dependence computational explicit inf lemma implies lemma sufficiently sup  LHS EM EM however minimises EM contradiction completes proof function linearly interpolates decrease inverse convex slight abuse notation EM EM EM suppose jensen inequality EM EM EM thanei meinshausen shah proof theorem inequality definition γjk γjk γjk  easily proof proposition therefore min moreover inequality strict unique  technical lemma lemma suppose sequence exists xyz algorithm interaction dimensional data proof density assume without loss generality theorem  sufficiently constant standard normal density theorem inf sup sufficiently exp sufficiently whence argument yield upper bound lemma suppose exists proof upper bound binomial thanei meinshausen shah jensen inequality compute LHS jensen inequality easily lemma non decrease suppose exists concave sup denotes  function random variable EX proof sup function define define convex jensen inequality EX EX xyz algorithm interaction dimensional data appendix connection LSH minimal subsampling algorithm closely related locality sensitive hash LSH framework define RT corresponds minimal subsampling projection hash function function sample uniformly sensitive γjk γjk minimal subsampling  however typical LSH machinery cannot apply directly interested preserve closest theorem establishes maximal ratio linear hash appendix proof proposition proof sgn ijX sgn xij xik xij xik sgn xij xik xij xik sgn xij xik appendix unbiased transform transform proposition proof equation xij implies xij uniquely determines unbiased transform lemma useful theorem thanei meinshausen shah lemma setup theorem exists constant define  probability exp YiXij xik kyk  kyk proof capped version  otherwise chosen later apply hoeffding inequality bound variable bound YiXij xik kyk  kyk schematically dealt xij xik  xik xij xik individually hoeffding inequality xij xik exp  xik exp xij xik exp  exp bound interaction strength interaction YiXij xik kyk  exp exp exp exp similarly treat interaction strength non interact xyz algorithm interaction dimensional data assumption xij xik  hence xij xik  exp bound xij xik xij xik yield bound  kyk exp exp exp exp inequality interaction effectively exponential another factor negative bound away YiXij xik kyk    kyk probability exp exp exp exp finally probability exp exp exp exp exp YiXij xik kyk  kyk probability exp extend unbounded error assume probability bound exp thanei meinshausen shah sub exponential behavior exp hence    probability exp YiXij xik kyk  kyk equivalent transform proof unbiased lemma setup theorem exists constant CX define  CX  probability exp yisgn xij xik kyk yisgn  kyk proof capped version random variable xij xij  xij otherwise  otherwise chosen later capped variable hoeffding inequality bound variable bound yisgn kyk yisgn ijX kyk lemma equation sgn individually hoeffding inequality xyz algorithm interaction dimensional data exp exp exp exp bound interaction strength interaction yisgn kyk  exp exp similarly treat interaction strength non interact assumption implies sgn sgn ijX compute expectation sgn ijX sgn ijX  sgn ijX  sgn ijX  sgn ijX  expectation sgn ijX hence sgn ijX exp bound yield bound yisgn ijX kyk exp exp inequality interaction effectively exponential another factor negative bound away yisgn kyk   yisgn ijX kyk probability exp exp thanei meinshausen shah finally probability exp exp exp exp exp yisgn kyk yisgn ijX kyk probability exp extend unbounded variable assume probability variable xij bound xij exp exp sub exponential behaviour xij exists constant xij exp similarly hence   CX    CX  theorem proof exp define lemma satisfies lemma exists probability apply corollary probability  constant proof theorem omit xyz algorithm interaction dimensional data