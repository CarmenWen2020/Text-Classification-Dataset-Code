automatic emotion recognition become trend research topic decade facial expression abound recognize affect gesture remains explore topic comprehensive survey hop boost research introduce emotional gesture component commonly comment aspect gender difference culture dependence define framework automatic emotional gesture recognition introduce detection comment static dynamic estimation rgb 3D comment recent literature related representation emotion recognition image emotionally expressive gesture discus multi modal approach combine gesture improve emotion recognition pre processing methodology detection estimation nowadays mature technology fully developed robust analysis emotion recognition quantity label data scarce agreement clearly define output representation shallow largely naive geometrical representation introduction conversation constantly nonverbal clue communicate movement facial expression difference pronounce understand content nonverbal communication commonly gesture posture component nonverbal indicator facial expression posture gesture movement important marker emotional cognitive inner review literature automatic recognition expression emotion subset focus gesture posture image nonverbal indicator facial expression posture gesture movement important marker emotional cognitive inner review literature automatic recognition expression emotion subset focus gesture posture image although significant aspect social psychology concern become popular probably important publish expression emotion charles darwin foundation research darwin observation confirm subsequent darwin facial expression fairly manner observation paul ekman research facial behavior culture ekman friesen developed facial action cod facs model facial expression update descriptive anatomical model emotion expression recognition usage emotion recognition conduct ray  message utterance affected percent actual percent non verbal signal analysis negotiation recording reveal decides outcome negotiation percent phone negotiation argument however personal meeting decision basis researcher primarily convey information movement relationship sometimes substitute verbal communication  gesture important nonverbal communication movement individual communicate variety feeling emotion gesture upset frown accord gesture intrinsic nod affirmation consent probably innate blind extrinsic refusal gesture childhood breast refuse  selection expansion  oxygenate battle escape ability recognize attitude behavior communication understand emotional enhances interaction although computer relation machine knowledge emotional user machine adapt generally improve cooperation emotion express automatic recognition mainly focus facial expression considerably gesture posture recent development capture technology reliability literature automatic recognition expressive movement significantly despite increase topic aware relevant survey review literature affective expression perception recognition emphasis inter individual difference impact culture multi modal recognition another introduce categorization movement communicative functional artistic abstract literature associate movement recent advancement automatic emotion recognition gesture reader interested emotion recognition facial expression encourage consult dedicate survey refer marginally complement emotional gesture briefly introduce aspect affect expression discus depth cultural gender dependency define standard pipeline automatically recognize gesture emotion discus technical aspect component furthermore comprehensive review publicly available database training automatic recognition conclude discussion potential future research express emotion accord nonverbal indicator facial expression posture gesture movement personal inner express iris extension gaze direction style posture movement probably  source information honest inside towards interlocutor  hiding gesture conversation impression reliable trick debate political discussion gesture perceive positively speaker public gesture perceive positively percent recipient whereas palm downwards evaluate positive percent receiver reveals information emotional research indicates prone listener encourages nod pace nod signal patience lack neutral remains interlocutor chin display superiority  expose signal submission darwin tilt interested something perform gesture interested additional display submission sex lower chin signal negative aggressive attitude torso probably analyse however angle indicative attitude torso  interlocutor display aggression slight angle confident devoid aggression lean combine nod distinct curiosity consideration correctly interpret indicator emotional various accord recognition benefit variety psychological behavioural protocol movement protocol emotion movement protocol emotion movement protocol emotion culture difference report gesture strongly culture dependent however due exposure medium tendency globalization gesture generation despite posture express significantly feeling previous generation consequently posture meaning disappear instance thumb meaning culture europe japan australia greece insult however nowadays widely agreement consent facial expression emotion across culture posture culture medium emotional expression conclusion american japanese infant closely emotional expression report topic literature infer intrinsic gesture posture visibly throughout however decisive conclusion depth exploration challenge due variety topic numerous culture therefore researcher investigate issue prefer concentrate activity various culture understandable distinction culture resembles mutual respect others another exchange greeting gender difference fundamental difference communicate trivial influence culture task expectation sex composition makeup worn clothes fundamental difference communicate situation easily discriminate gender illustration skirt ankle sole gesture apply almost exclusively composition become femininity another mainly attribute generally gesture unconsciously demonstrates courage domination monkey emotion feeling willingly tend display overt sadness tend withdraw expression likely display dominance angry intensity frequency tend manifest indicator evidently however nowadays tendency  gender stereotype model emotion automatically recognize emotion gesture detail introduce model input output input abstraction dynamic machine predefined abstraction emotion appropriate model emotion essential decision abstraction model emotion affective compute model evolve perform complex action coordination various therefore everyday action unique spatio temporal movement structure addition action drinking perform expression additive abstract constrain composition kinematic logic skeletal structure model automatic gesture recognition ensemble kinematic model ensemble independently detect restriction impose refine detection kinematic model collection interconnect joint predefined freedom skeleton model automatic gesture recognition ensemble kinematic model ensemble independently detect restriction impose refine detection kinematic model collection interconnect joint predefined freedom skeleton model approach flexible configuration detect independently torso prior impose domain knowledge structure refine detection ensemble model pictorial structure grammar model pictorial structure generative 2D assembly detect specific detector pictorial structure framework detection widely detection estimation estimation pictorial structure estimation ensemble namely grammar model flexible framework detect apply detection compositional combination composition trunk limb compose kinematic model another model define collection interconnect joint kinematic chain model usually simplification skeleton mechanic mathematical representation model cyclical graph advantage computationally convenient contrary approach node structure joint parameterized freedom kinematic model planar projection image depth information richer realistic variant define collection cylinder  3D mesh detection kinematic model estimation multi estimation multi estimation 3D reconstruction estimation multi estimation multi estimation 3D reconstruction model emotion model affect debate perspective upon topic propose influential model relevant affective compute application classify category categorical dimensional  category category emotion model affective compute categorical universal emotion define ekman dimensional russell model depict  model plutchik model categorical model classify emotion distinct recognize described easily daily darwin recently influence research paul ekman dominant upon affect underlie assumption universally express recognize discrete primary emotion happiness sadness disgust mainly simplicity universality universal primary emotion hypothesis intensively affective compute research dimensional model another popular approach model emotion along latent dimension dimension valence pleasant unpleasant arousal likely action emotional emotion due continuous model theoretically complex subtle emotion unfortunately richness automatic recognition challenge link described emotion expression affect automatic dimensional representation emotion simplify limited category positive versus negative quadrant 2D  model somehow categorical dimensional model descriptive capacity  model affect emotion hierarchical fashion superior layer contains complex emotion compose emotion previous layer  model propose plutchik accord theory complex emotion emotion dyad complex emotion probability model rarely affective compute compound emotion gain relative visibility fashion compound emotion model former restrictive framework categorical universal emotion propose combine component category construct emotion happily surprised  surprised richer emotion emotional display define model effective compromise interpretation expressive capacity useful building discriminative computational model affective display gesture emotion recognition component emotional gesture recognition  detailed depiction overview emotional gesture recognition detect input background extraction estimate detect torso etc mapping kinematic model skeleton image extract model relevant representation extract input predefined emotion model automatic recognition important preparation influence subsequent decision automatic pipeline determination appropriate model input target emotion model chosen publicly accessible database utilized similarly configure compatible overall efficient performance regardless forego difference various  detect background frame gesture briefly discus literature detection detection reduce irrelevant variation data posture dedicate pipeline discus consists building appropriate representation data apply technique usually classification regression representation target conclude presentation important application automatic recognition emotion gesture detection detection image usually consists rectangular bound enclose challenge task non rigid clothing variation appearance uncontrolled environment illumination occlusion complexity detection pipeline pipeline detection consists extract potential candidate classify non merge positive decision depth information available limit considerably simplify background  technique exactly modularization jointly representation classification directly propose detection input relevant detection propose viola jones previously apply detection employ cascade structure efficient detection utilize adaboost automatic feature selection important advancement performance adoption gradient feature   popularize histogram orient gradient hog feature detection substantial gain intensity feature introduction variant hog feature proliferate greatly nearly detector utilize earlier detection assume prior knowledge structure arguably important contribution direction deformable model DPM DPM connection relate geometry prior initial proposal discriminative approach model unknown latent variable vector machine svm framework local appearance easy model global appearance training data across deformation author argue evidence necessity component beyond occlusion handle lately spectacular performance recognition training neural network dnn massive amount data performance earlier dnn model tend slide classifier considerable amount focus accelerate improve potential proposal alleviate network cascade fashion almost shallow network greatly reduce candidate slide confidence network obtain accuracy cascade feature complexity deeply feature address seek algorithm optimal cascade criterion penalizes detection error complexity define quantity complexity margin complexity loss account algorithm inexpensive feature cascade stage expensive later stage currently usage regional cnns become standard detection successful technique originate cnn propose training multi task loss combine classification location feature additionally faster rcnn adaptation detection introduce proposal network rpn image convolutional feature detection network enable nearly proposal achieve fps vgg version achieve detection performance architecture resnet comprehensive survey detection literature interested reader refer estimation due dimension freedom variation clutter background parameter illumination estimation challenge task demand avoid penetration impossible perform model fitting model model capture data inverse kinematic context parameter estimate tracked feature gradient similarity maximum likelihood markov chain monte carlo approach however model robust local extremum initialisation perform estimation computationally expensive dimension data database label skeletal data however recent advance computational availability data training capacity model feasible  experienced considerable traditional approach neural network currently estimation monocular image video multi estimation 3D estimation direction research recent learnt estimation model focus efficiently combine local global information precise joint localisation overall skeletal consistency combine neural network graphical model spatial relationship joint due appearance consistency detect increase accuracy local spatial context sequentially improve prediction leverage consistent geometric configuration similarly propose cascade network explicitly infer relationship improve inter joint consistency contains detection network regression network responsible regress location impose consistency via confidence regression motivate propose capture information multiple particularly successful proposal hourglass network skip connection promote multi feature module stack output input mechanism inference initial estimate feature reevaluate improve across image observation pool mechanism convolutional network reduce localisation accuracy alternative dropout implementation introduce improve performance spatial precision localization recover coarse architecture instead predict output propose model focus predict estimate progressively improve initial approach assume image cannot handle realistic scene interact due estimation shift towards multi estimation multi estimation introduces significantly challenge image priori moreover occlude interaction become partially truncate various multi estimation mainly category approach detect approach detect subsequently associate instance recent literature dominant representative approach propose propose jointly subset partition label challenge partially visible significant overlap bound frequent exists apriori unknown image robust multi estimation achieve propose initial detection pairwise detection jointly cluster belonging slightly approach combine inference variation unary joint detector architecture affinity regression enforce inter joint consistency greedy algorithm employ generate instance proposal fashion obtain additional refinement standard estimator instance proposal generate stage action greatly dynamic accord periodic  bending stationary nonstationary transitional skip horizontal jumping vertical despite significant progress frame multi estimation articulate multi joint monocular video remains largely unaddressed estimation video mainly aim improve estimation utilize temporal smooth constraint directly applicable video multiple potentially occlude recent multi estimation  achieve sparsifying relationship graph convolutional architecture detect associate joint clutter model generate proposal joint location formulate articulate spatio temporal proposal allows jointly association scene propagate evidence detection enforce constraint proposal assign another recent  joint detection video spatio temporal graph integer linear program partition graph sub graph correspond plausible trajectory jointly multi estimation achieve instead infer project image infer additional depth dimension another recent development 3D dense estimation related topic 3D reconstruction 3D correspondence 3D completion bench related topic recent competition associate database feature extraction emotion recognition stage  building relevant representation mapping correspond target input representation static dynamic representation geometrical appearance information focus moreover mapping account input sample recognize perform various classification forego topic feature extraction detect information displacement neutral calculate accord centroid coordinate information upper neutral gesture movement sad gesture extend closer normal clearly define protocol distinguish emotion frame supposedly neutral torso subsequent frame rotation analyze action model cod expert frame gesture neutral peak emotional respectively utilized training action movement  investigation correlation emotion gesture analysis perform static frame extract video emotional emotion dimension pleasure arousal dominance palm orientation direction calculate frame feature magnitude direction correlation occurrence actual evaluate correspondence dimension calculate deviation focus active emotional gesture feature extract attack release cue refer slope connects relative extremum slope connects relative extremum respectively extract local maximum cue ratio maximum duration peak estimate overall  movement extract feature silhouette blob extract quantity silhouette image  contraction index CI velocity acceleration fluidity barycenter compute successfully extend database 3D velocity acceleration jerk extract joint skeletal structure  martin dimensional affect emotional gesture along continuous independent bipolar dimension namely pleasure arousal dominance define affective location emotional obtain dynamic feature extract obtain description  characteristic initial peak timing greatly emotional expression accord feature handle concept primitive dynamic feature  information dynamic warp dtw utilized series resistor FSR accelerometer signal affect recognition capture 3D correspond joint frame per fps recognition stage previous frame analyze frame skeleton model 3D coordinate upper joint joint correspond spine calculate feature distance acceleration angle distance spine maximum acceleration elbow angle spine feature static dynamic information simultaneously utilized cue namely  CI velocity acceleration fluidity propose 2D 3D feature 3D data obtain 2D data segmentation image spacial data 3D CI  gradient  barycentric index bmi utilized 3D static dynamic geometrical feature skeletal upper velocity acceleration trajectory barycenter extend adopt multiple modality gesture 3D feature instead  similarity gesture template input sample unfortunately complex representation scarce emotional gesture recognition hog image  direction image hog feature bag bow compute appearance feature another usage multichannel cnn representation upper finally spike neural network temporal cod pulse cod neural network approximate dynamic ignition phenomenon neuron propagation mechanism pulse neuron gesture emotion recognition   feature vector displacement frame frame neutral expression expressive feature calculate upper classify gesture emotional category disgust happiness sadness uncertainty uncertainty standard classifier bayesian net classification approach dynamic warp dtw NN decision hidden naive bayes  classify dynamic representation gesture emotional category obtain dtw NN model independently action analysis approach author independently model action torso contrarily structural model propose author define description activity corresponds node engage perform propose automatic recognition model recognize affective concentrate defeat frustrate  non posture nintendo gamers corpus label obtain online posture evaluation survey outside observer judgment computer avatar stimulus non gender non culturally specific  humanoid frequent affective label assign observer define truth silhouette described posture configuration feature multilayer perceptron classifier database investigate extract related feature rotation angular velocity frequency acceleration direction amount movement nintendo gamer feature recurrent neural network rnn  investigate laughter related movement significance communication analyse laughter  social awkward fake non laughter impact movement analysis significant difference torso limb movement laughter non laughter expression social  laughter distinguish amount spine bending rotation movement distinguish mention laughter movement distance hip movement spine bending obtain classifier effective non parametric model RF research focus emotional gait perform professional actor vicon capture actor express emotion neutral attitude sadness geometric model inverse kinematics compute obtain freedom dof model confirm dof recognize emotion gait torso variation trunk inclination important feature investigate gesture reflect emotional skeletal geometrical feature binary decision ensemble neighbour svm obtain ensemble recent focus stochastic model affective movement dynamic HMMs output HMMs derive fisher movement representation optimize affective movement recognition svm moreover obtain minimal discriminative representation movement author supervise pca hilbert schmidt independence criterion fisher effectiveness propose validate datasets movement corpus expand previous analyze meaningful emotion related quadrant valence arousal described trajectory frontal lateral compact representation grouped cluster namely positive amusement pride negative  negative pleasure relief negative anxiety sadness   propose deeper analysis emotional movement expression feature described movement anatomical directional posture movement random approach classify emotional panic anxiety sadness shame pride neutral express actor various daily action knock propose continuous emotional behavior recognition theater performance  movement analysis  mapped onto russell circumplex model rcm  efficient interpret visualize  movement efficiency  descriptor improve decade proven variety propose neural network project emotion transition actor trajectory rcm diagram theater performance sufficient accuracy kinematic geometrical feature extract joint orient skeleton gameplay scenario efficiency chosen feature evaluate algorithm multilayer perceptron restrict boltzmann machine RBMs propose stack RBM classic classifier naïve bayes linear multiclass svm non linear svm stack  outperform classification propose emotion recognition gait microsoft kinect camera extract feature dimensional coordinate joint fourier transformation pca naive bayes random svm sequential minimal optimization SMO classifier recognize happiness neutral extract feature correspond kinematics joint psychological theory  contraction index svm classifier interactive autistic currently validate autistic analyse effective emotion recognition emotion expression orientation elongation solidity  distance feature svm naïve bayes dynamic wrap classifier obtain dtw average recognition rate percent performance recognize emotional angry fearful emotion recognition image context non environment rank filter cnn jointly analyse scene recognize emotional analyse image depict annotate emotional category continuous dimension valence arousal dominance research emphasize importance context recognize emotion image gesture multimodal emotion recognition although gesture important communication supplement reflexive behavior facial expression context apply psychology recognition facial expression influence expression context expand focus expression facilitate research emotion recognition machine interaction combine facial display emotion recognition scarce historical usually focus fusion technique predefined representation recently introduce multi modal fusion structure stack generalization noisy database emotion happiness sadness classify facial gesture representation recognition performance mono modal correspondent uncover interrelation gesture emotion recognition prosody audio spectral feature model interaction dynamic representation upper propose author modal approach gesture recognition emotional happiness sadness disappointment neutral gesture recognition module fuse video 3D acceleration sensor output gesture recognition fuse criterion probability majority vote fifty japanese gesture participant validate performance classifier modal uni modal recognition tri modal approach combine emotion recognition exist database consist audio video recording interact agent specific scenario propose gender native french german greek italian pronounce emotional facial expression gesture acoustic feature automatic bayesian classifier obtain modality fusion modality combine feature multi modal increase percent successful uni modal furthermore obtain merge gesture another category gesture implicitly usually complement facial information context emotion recognition limited affect label positive negative neutral classify image information visible another apparent personality recognition camera upper visible gesture information implicitly scene nevertheless aware neither gesture explicitly future research application application emotional gesture recognition mainly consist detect emotion user actual virtual animate conversational agent robot avatar similarly suppose really emotion application video telephony video conferencing stress monitoring violence detection video surveillance animation synthesis agent automatic psychological research extensively literature however concentrate affect detection automatic multi modal emotion recognition utilize source information gesture constitute important perceptual user interface utilized improve online application pervasive perceptual machine interface intelligent affective machine computer understand react emotion capable combine emotional social aspect situation decision available cue useful assistant  public database gesture expression affect useful training  discus rgb depth modal rgb depth database respectively reader refer overview characteristic database selection database sample sample database gesture expression affect  GEMEP  theater HUMAINE liris accede msr action 3D sample database gesture expression affect  GEMEP  theater HUMAINE liris accede msr action 3D characteristic publicly available database recognize gesture expression affect characteristic publicly available database recognize gesture expression affect rgb database affect annotation publicly available   database contains sample emotion namely neutral anxiety boredom uncertainty sample training sample affective data consist gesture database HUMAINE database male female participant emotion  pleasure sadness irritation pride equally distribute valence arousal however focus emotion pleasure sadness camera film rate fps accelerate silhouette extraction uniform background geneva multi modal emotion portrayal GEMEP database contains audio video portrayal emotional expression emotion portrayed actor portrayal systematically chosen rating expert non expert recognition emotional intention analysis basis portrayal mention chosen emotion namely relief sadness emotion quadrant affective dimension arousal valence theater corpus introduce  martin movie version salesman namely DS DS gesture scenario  robot database involve participant male female nationality japanese chinese  subset liris accede video database contains upper male female emotion depth GEMEP  database introduce  subset GEMEP corpus training database actor database actor participate actor training database database consists video upper actor average video video neutral database involve stimulate emotion namely happiness sadness relaxation emotion gesture accordingly film frame rate fps cartesian coordinate joint emotion namely disgust sad female male addition american asian completely frontal distance camera meter  kinect skeleton estimation male female participate recording perform action balance punch action 3D coordinate joint calculate frame data background clothes calculation data skeleton extract msr action 3D consists action namely horizontal hammer punch tick clap boxing bend kick kick jogging tennis swing tennis golf swing modal rgb depth database contains facial expression frequently emotion namely happiness sadness neutral emotion label sample cannot classify emotion participate video video almost neutral evolves peak emotional label assign emotion perform actually perform movement duration video emotion video emotion perform movement style database contains facial expression another contains gesture contains data dense asm algorithm feature extract AUs evaluate performance propose apply  database  database multi modal recording actor gesture physiological signal audiovisual information expression intensity emotion facial feature skeletal professional actor participate acquire data recording others date database diverse emotional gesture literature available finally specification available database summarize emotion database sample image database label database label database 6Discussion discus aspect automatic emotional gesture recognition collection data currently available community discussion mainly focus representation building emotion recognition gesture category mostly feature advantage complementarity multi modal approach recognition target data majority freely accessible data expression usually compose quality recording undistorted emotion expression easiness acquire recording possibility obtain sample conventional approach database actor scene portray emotional professional immerse emotion perform ordinary sample uncontrollable influence usually additional evaluation label however researcher emphasize recording redundant sample dependency actor ability emotional differently another argument recording reflect moreover emotion usually comprise emotion whereas emotion weak blur combination mixture compound primary emotion  trend spontaneous emotion preferable research another emotional movement situation movie TV program reality coverage satisfactory quality background artifact overlap etc obscure emotion moreover collection spontaneous sample evaluate decision maker professional  emotional nonetheless guarantee objective genuinely independent assessment additionally copyright disclose movie TV recording accurate sample acquisition provoke emotional reaction stag situation already emotion recognition mimic appropriate induced image video image computer recording prefer psychologist although desirable reaction stimulus similarly spontaneous recording trigger emotional sample label ethical legal prohibit publicly available account mention issue emotion database rarely available public label sample appropriate representation emotional intricate debatable detailed analyze affective spectrum various research author focus emotion accord ekman model sadness majority database disgust commonly however affective consistently available database uncertainty   shame tenderness etc lack consistency taxonomy affective happiness interchangeably database evaluate beneficial transitory happiness external circumstance therefore misunderstand happiness  gratitude  evoke misunderstanding translation issue  consistent taxonomy emotion agreement expert definition primary moreover due heterogeneity described database comparison quality problematic public accessible emotional database addition described issue comparison detection algorithm becomes challenge task clearly necessity creation unified emotional database feature extraction emotion recognition feature extraction majority developed recognize emotion gesture geometrical representation static dynamic feature related coordinate joint kinematic model torso feature displacement orientation cue velocity acceleration information  smoothness fluidity periodicity spatial extent kinetic others descriptor slightly advanced descriptor quantity  amount sequence  image smi contains information silhouette contraction index CI contraction expansion angular metric similarity  dynamic feature acceleration movement gain velocity combine static feature usually recognition rate rely solely latter richer representation emotional trait express mostly dynamic propose focus upper upper sample upper posture context gesture recognition numerous focus gesture segmentation feature extract palm orientation elbow wrist palm joint direction analyze independently calculate individual along reference upper inclination backward complex learnt representation recognize emotion gesture scarce mostly lack volume label data representation supervise representation emotion recognition multichannel cnn upper spike neural network temporal cod previously lack consistent taxonomy output various database publish date considerable fragmentation data transfer technique explore literature unsupervised pre training representation tune specific emotion orient model emotion recognition tendency literature reduce output simplify recognition emotion quadrant dimensional emotion emotion similarity  focus recognize emotion pleasure sadness dominant target richer output exist another popular approach extensive comparison standard classifier decision nns SVMs numerous classifier emotion database summarize respectively accord performance classifier HUMAINE database label mention database accord performance database label achieve ensemble classification moreover performance emotional gesture recognition performance emotion recognition database performance emotion recognition database representation meaningful particularly structural model   contribute decision emotion account predefined prior additional information context background refine decision recent investigate around ego propose emotion recognition focus component feature classification feature mapped  onto RMC 3D geometrical kinematics tracked joint 3D dimensional coordinate apply fourier transformation pca kinematics joint dynamic feature velocity orientation elongation stability   extract mention reliable feature feature prefer research basically willing improve previous propose neural network RF svm naïve bayes dtw recent classification accord RF performance naive bayes libsvm SMO propose dataset accord dtw  svm polynomial kernel  classifier component gesture affective information complementary processing obvious advantage consistent literature multiple representation complementary recognize emotion combine regardless fusion technique report improvement backing hypothesis considerable complementarity modality exploration  already previously comment representation helpful respect upper unfortunately research multi modal emotion recognition remains scarce simplistic exists mostly focus simplistic fusion technique shallow representation report important improvement monomodal equivalent potential remains largely unexplored reader refer representation representation modality recognize emotion summary multi modal emotion recognition summary multi modal emotion recognition comparison various classification emotion HUMAINE database framework EU ist project comparison various classification emotion HUMAINE database framework EU ist project comparison various classification emotion sample kinect emotion affect performance classifier usually reduce database increase performance recognition rate percent obtain emotion neural network quality sample feature degrade performance violation trend approach emotional gesture recognition investigate exist literature portion database training propose technique superior performance specific database accuracy rate percent however ensure reliable data various background uniform nonuniform moreover worth attention training strategy performance rate conclusion define pipeline emotion gesture recognition detailed briefly introduce important pre processing concept detection estimation detailed variety recognize emotion gesture grouped along important concept representation emotion recognition introduce topic broadening scope implication define emotional gesture component essential social behavior difficulty challenge detect affective underlined varies gender important cultural dependence vital issue researcher willing publish data representation remain shallow naive geometrical representation skeletal independently detect feature cue distance orientation descriptor abound recently meaningful representation facial analysis affect recognition approach broader affective expression developed analysis scarcity gesture multimedia affective data important role recently overcome facial analysis additional facial affective compute consensus output primitive facial expression facial action recently comprehensive output affective expression broader consensus exist proof variety label propose multitude publicly available data redundant confuse taxonomy comprehensive affective analysis emotional gesture recognition emotional facial recognition clearly sufficiently define output publish quality amount label unlabelled data statistical representation affective