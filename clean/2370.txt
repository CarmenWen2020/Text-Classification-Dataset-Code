difficulty multi classification generally increase data predict classifier increase propose framework assume sample population classifier independently function framework express classification accuracy discriminability function discriminability function leverage develop non parametric regression estimator discriminability function extrapolate accuracy unobserved formalize alternative approach  accuracy separately identify tradeoff accurately predict classifier performance label simulation realistic recognition recognition task keywords multi recognition recognition transfer nonparametric model introduction machine task interested recognize identify individual instance within candidate usually model multi classification possibly complex label detect speaker identify author text label category image algorithm observes input classifier function label label multiple practical challenge develop classifier label quality training data obstacle affordable data goal generalize furthermore classifier development accelerate training training cycle substantially resource indeed due performance generalizes comparison literature label affect classification accuracy classification finite label source task label target task label label construct classification suppose task joint distribution define generalization accuracy label GAK performance extrapolation data source task predict accuracy target task unobserved label performance extrapolation deployment facial recognition suppose developed lab database individual client deploy individual performance extrapolation lab predict algorithm perform client accounting difference label extrapolation source target classification belong domain category random arbitrary selection infinite potential category specific fix finite category classical caltech image recognition data assemble aggregate keywords propose image web arbitrary label apparent biometric application recognition authorship fingerprint identification label correspond individual label define concrete data therefore experimental choice domain despite arbitrary choice data recognition within domain data inform performance assume sample consist independent identically distribute label population prior distribution define label constraint dependence independent alternatively subsample latter sample assumption approximate characterization label selection partially manual nevertheless without extrapolate accuracy derive specialized metric simplifies theory demonstrates extrapolation assumption classifier model independently convenient allows characterize accuracy classifier selectively conditioning assume label random generalization accuracy classifier becomes random variable performance extrapolation becomes estimate average generalization accuracy AGAk label roughly achievable accuracy classification depends label training data empirical distribution training data instance drawn sample label ensures separation label random infer empirical separation therefore estimate average accuracy obtain contribution related extrapolation within framework theoretical formula average accuracy link average accuracy label accuracy depends discriminability function data distribution classifier propose estimation procedure allows extrapolation average accuracy curve data theoretical formula estimation unbiased estimator average accuracy formalize alternative approach propose  accuracy separately discus tradeoff organize discus related framework randomize classification introduce introduce toy revisit throughout develops theory extrapolation estimation evaluate simulation demonstrate facial recognition optical recognition discus model choice limitation theory potential extension related link performance related classification task instance transfer pan yang terminology setup multi task source task label data predict performance target task label data apply transfer label another  however theory predict behavior classifier label instead research classification label computational challenge jointly optimize parameter model specific classification algorithm zheng achanta benjamini estimate accuracy classifier improve performance classifier apply theoretical framework adopt exists classification increase framework trace shannon error rate random codebook randomize classification recently author dimensional feature selection multi classification assume specific distributional model classification setup however feature selection extrapolation classification error classifier identify stimulus functional mri scan brain activity interested performance stimulus propose extrapolation algorithm per kernel density estimation heuristic theoretical discussion formalize within framework implement variation algorithm simulation theoretical argument algorithm regression approach propose randomize classification randomize classification model feature assume exists infinite continuous label subsequent theory assume continuous solely sake mathematical convenience discus probability integral without theoretic notation however theory approximately sufficiently discrete probability suitably assume exists prior distribution label label exists distribution label conditional distribution random classification task generate label generate label assume label deterministic label sample training obtain sample observation FY assume training obtain sample  observation FY  however later relax assumption sample training accommodate stochastically instance training instance label conditionally independent recall recognition distribution sample photo FY conditional distribution photo goal classification label photo extrapolate accuracy assume classifier assign label label exist function label notation label treat fix classifier training data convenient associate function random classifier random function likewise denote function whenever random classifier label classifier instance label whenever maxj assume fix instance classification task label associate function recall definition generalization error assumption label uniformly distribute GAK balance accuracy equally accuracy individual assume function GAK max however appropriate model label random sample distribution randomize classification recognition drawn population multi arbitrary subset label assumption fix target prediction extrapolation generalization accuracy GAK distribution label average generalization accuracy classifier denote AGAk formally define AGAk GAK max max iid independent joint distribution  counterpart summands previous identical drawn distribution definition average generalization accuracy illustrate framework role training usually machine goal predict accuracy achieve another random label therefore training data discus extension framework accommodate label uniformly drawn non uniform prior distribution label zheng achanta benjamini average generalization accuracy diagram random quantity underlie average generalization accuracy label AGAk training stage label sample prior function stage sample uniformly AGAk accuracy random variable estimation approach described training data exclusively construct classifier label subset data exclusively estimate distribution favorability marginal classifier theoretical analysis average generalization accuracy simpler assume function occurs independently label information exists function  marginal classifier depends label training analysis however relax assumption classifier training instead sufficient function associate due abstraction framework accommodate scenario stochastically instance training instance label conditionally independent extrapolate accuracy classification function dimensional classification chooses maximal function random label independent instance formalism define marginal classifier definition classifier marginal classifier independent marginal classifier compete construct function therefore independently drawn distribution operation marginal classifier illustrate marginal classifier accuracy classifier sample assumption classifier satisfy marginal marginal classifier estimate bayes classifier primary marginal classifier classifier output maximizes posterior probability label accord bayes substitute estimate distribution unknown distribution  density estimate distribution label obtain empirical distribution Fˆ prior distribution label estimate density function   empirical approximation bayes classifier  argmaxy  quadratic discriminant analysis QDA ıve bayes classifier specific instance estimate bayes classifier QDA function  Fˆ Fˆ Fˆ det Fˆ zheng achanta benjamini  hence QDA estimate bayes classifier  obtain multivariate gaussian density covariance parameter estimate data ıve bayes function MNB   density estimate component Fˆ hence ıve bayes estimate bayes classifier  obtain estimate componentwise marginal distribution classifier deterministic function therefore degenerate prime exist fix pre embeddings label  feature publicly available embeddings embed vector classification embed vector embeddings inform specific longer marginal classifier classifier satisfy marginal multinomial logistic regression multilayer neural network decision estimation average accuracy tackle extrapolation useful discus simpler task generalize accuracy target source allows introduce concept notation harder generalize illustrate concept toy revisit tackle extrapolation suppose training data classification task label assume training data obtain associate function compose available estimation task predict accuracy randomly sample label AGAk accuracy label therefore unbiased estimator AGAk unbiased predictor accuracy observation define rank candidate extrapolate accuracy define accuracy observation rank  expectation random label accuracy AGAk therefore  unbiased estimator AGAk label obtain sample label uniformly without replacement unconditionally sample population label accuracy unbiased estimator AGAk however unbiased estimate AGAk average subsamples defines average accuracy subsampled task  remark  compute  evaluate classification however marginal classifier retrain classifier rank label allows subset classification specifically label label therefore label label classification implies subset classify correctly therefore average accuracy subset  toy bivariate normal illustrate toy bivariate normal joint distribution illustrate therefore randomly drawn label conditional distribution label univariate normal variance suppose label classification assign instance label instance drawn probability conditional distribution illustrate bayes assigns density illustrate therefore marginal classifier function const zheng achanta benjamini joint distribution instance rho density density toy joint distribution bivariate normal correlation typical classification instance bivariate normal model conditional density label bayes classification accuracy generalization accuracy toy distribution generalization accuracy bivariate normal model average generalization accuracy AGAk curve theoretically compute average accuracy extrapolate accuracy model generalization accuracy bayes label GAK max standard normal cdf sort label maximum margin classifier argmaxy numerically compute GAK randomly drawn label iid distribution GAK illustrate distribution GAK average accuracy AGAk theory analyze average accuracy AGAk function extrapolation organize introduce explicit formula average accuracy AGAk formula reveals AGAk dimensional function formula estimate subsampled accuracy estimate extrapolate average generalization accuracy arbitrary label analysis expose average accuracy AGAk average function independent assumption rely allows neglect specify margin definition probability independently drawn simply randomly mathematically equivalent amount random function theorem suppose function satisfy exists cumulative distribution function define interval AGAk analysis average accuracy recall marginal classifier model independent label independent instance random label zheng achanta benjamini associate function vector drawn label explicitly sample FY similarly triplet independent identical distribution specifically typically therefore label function function related favorability function favorability probability maximize function random competitor formally fix favorability monotonically increase contains therefore label instance classifier label favorability argmaxy  argmaxy  furthermore via conditioning argument instance label random random independent recall notation dependent Yˆ argmaxy  argmaxy  favorability argument random becomes random variable distribution random variable incorrect label favorability fix instance function random incorrect label label favorability UX random instance function label incorrect label favorability incorrect label favorability explicitly identically distribute unrelated fix lemma incorrect label favorability uniformly distribute meaning extrapolate accuracy proof implies independent random variable conditional probability uniformly distribute label favorability label favorability UX distribution generally cannot however distribution central analysis indeed function theorem define cumulative distribution function relation distribution average generalization accuracy AGA average generalization accuracy probability random label function random distractor AGA label random incorrect label AGA conditional probability inside expectation label favorability therefore AGA cumulative distribution function theorem extends proof proof without loss generality suppose label incorrect label AGAk max max UX recall UX random variable becomes fix zheng achanta benjamini therefore AGAk max UX max UX define umax maxk UX lemma UX uniform conditional umax beta furthermore umax independent conditional therefore conditional probability compute umax consequently AGAk max UX define cumulative distribution function UX substitute definition obtain identity theorem express average accuracy integral function essentially theoretical allows reduce estimate AGAk estimate estimate data propose non parametric regression purpose favorability average accuracy toy recall toy function non random function distance extrapolate accuracy model favorability function distance distance randomly chosen distractor standard normal cumulative distribution function illustrates function correspond conditional farther decay however becomes unlikely exceed formula calculate label favorability UX cumulative distribution function function illustrate curve compute formula AGAk illuminate average accuracy curve function parameter correlation accuracy accuracy curve shift upward increase favorability tends average cumulative distribution function function decrease increase therefore accuracy increase estimation discus data classification task extrapolate average accuracy seek unbiased estimator AGA AGA AGAk assume data random classification task estimate average accuracy AGAk estimation average accuracy ata  input understand behavior average accuracy AGAk function adopt linear model basis function linear coefficient estimate linearity assumption linear regression estimate average accuracy curve propose ClassExReg meaning classification extrapolation regression zheng achanta benjamini rho rho favorability toy curve function bivariate normal model function cumulative distribution function random variable UX average accuracy rho rho rho rho rho rho rho rho average accuracy average accuracy AGAk function bivariate normal model extrapolate accuracy conveniently AGAk express coefficient plug assume linear model identity AGAk constant basis function precomputed numerically accuracy  unbiased estimate AGAk implies regression estimate   unbiased estimate AGAk similarly obtain via AGA model selection accurate extrapolation ClassExReg depends linear model discriminability function however function depends unknown joint distribution data data basis candidate candidate ideally model selection procedure obtains error RMSE extrapolation approximation estimate RMSE extrapolation source target bootstrap principle amount resampling model selection approach perform extrapolation evaluate closely predict AGA accuracy  elaborate model selection procedure resampling subsample uniformly replacement compute average accuracy ata ata subsample zheng achanta benjamini candidate basis compute  ata xmi  estimate AGA AGA xmi basis  AGA  basis extrapolate data  KDE estimator propose extrapolate classification accuracy depends kernel density estimation KDE briefly motivate text notation estimate separately associate probability  random competitor acc recall define accurate classification independent random distractor equivalent independent accurate classification random competitor therefore  maxj acc estimate accuracy acc average AGA noisy unbiased estimate acc estimate  AGA upward bias XK accuracy acc estimate KDE extrapolation described supplement described classifier observation per liberty extend generic multi classification extrapolate accuracy density estimate smooth kernel function bandwidth density integrate acc smooth density usually estimate distribution proportion error biasing downward accuracy individual briefly difference regression  KDE KDE balance bias upward bias  estimate accuracy downward bias smooth density upward bias occurs acc unbiased acc unbiased acc typically bias becomes prominent decrease accuracy approach KDE therefore depends non trivially choice smooth bandwidth density estimation without smooth however correctly estimate acc relies smooth generate density exceeds therefore highly dependent choice kernel bandwidth KDE estimate accuracy separately  stable estimation therefore bias extrapolate regression estimator estimate average accuracy pool information across variance regression directly ranking therefore blind monotone transformation function KDE sensitive distribution simulation simulation propose extrapolation ClassExReg performs setting displayed varied source data difficulty classification basis function generate data accord mixture isotropic multivariate gaussian distribution label sample label sample parameter determines difficulty classification zheng achanta benjamini similarly data classifier training instance per estimation model selection procedure described parameter radial basis regularly knot parameter additionally constant basis equivalent intercept linear model rationale radial basis model density mixture gaussian kernel variance overfitting knot distance knot absolute maximum knot rank calculate therefore training data information distinguish accuracy hence maximum knot prevent inclusion basis average however simulation performance basis depends weakly maximum knot sufficiently knot throughout non parametric statistic bandwidth crucial parameter simulation grid bandwidth selection meanwhile KDE gaussian kernel bandwidth chosen via  validation recommend specifically validate KDE estimation stats package statistical compute environment bias validation unbiased validation simulation ClassExReg KDE unbiased bias validation KDE UCV KDE BCV perform comparably gaussian simulation difficulty extrapolation relates absolute extrapolation factor simulation setting within extrapolation within define source target maximum RMSE across signal setting quantify overall performance displayed accurate extrapolation extrapolation ratio ClassExReg improves RMSE extrapolation factor fix dramatically improves maximum RMSE fold reduction RMSE extrapolate accuracy ClassExReg KDE BCV KDE UCV maximum RMSE across signal predict  multivariate gaussian simulation standard error compute nest maximum operation within bootstrap properly account variance maximum estimate benefiting fold reduction RMSE kernel density comparable strongly choice bandwidth selection KDE UCV KDE BCV performance profile although bandwidth analysis item sensitivity density bandwidth KDE significant estimation bias item due KDE ignores bias introduce exponentiation meanwhile ClassExReg avoids source bias estimate directly bias exponentiation greatly reduce overall bias indeed ClassExReg comparable bias extrapolation bias extrapolation experimental evaluation demonstrate extrapolation average accuracy data predict accuracy recognition label accuracy subset extrapolate performance various classifier optical recognition ocr  script glyph recognition data label data individual photo data consist photo label randomly photo individual OpenFace embed feature extraction identify photo obtain feature vector OpenFace network label photo dimensional feature vector obtain computer vision library  detect landmark apply nonlinear transformation align template align photograph downsampled image downsampled image zheng achanta benjamini extrapolate predict AGA predict AGA predict AGA predict AGA extrapolate predict AGA predict AGA predict AGA predict AGA simulation RMSE simulation consist multivariate gaussian classifier prediction RMSE accuracy ClassExReg radial basis ClassExReg KDE bias validation KDE BCV unbiased validation KDE UCV extrapolate accuracy extrapolate predict AGA predict AGA predict AGA extrapolate predict AGA predict AGA predict AGA simulation bias simulation consist multivariate gaussian classifier bias predict minus accuracy accuracy ClassExReg radial basis ClassExReg KDE bias validation KDE BCV unbiased crossvalidation KDE UCV zheng achanta benjamini label training  jean   patricia recognition setup label feature label data  ocr exemplar glyph along intermediate feature transformation convolutional network minimal euclidean distance implies function compute accuracy TA subsample extrapolate  optical recognition achanta  classifier logistic regression linear vector machine svm convolutional neural network data consists training observation nest hierarchy subsampled data consist subset uniformly sample without replacement subset consist uniformly sample without replacement subsample therefore prediction extrapolation predict accuracy predict accuracy accuracy classifier subsample truth fed pre convolutional neural network obtain dimensional feature vector detail network architecture MP MP MP SM extrapolate accuracy ClassExReg KDE BCV KDE UCV recognition extrapolation  RMSE predict TA data truth unlike recognition assumption marginal classification satisfied none classifier model truth obtain data extrapolation recognition plot extrapolate accuracy curve subsamples variance decrease rapidly increase error KDE BCV achieves extrapolation KDE UCV consistently achieve rank   simulation predict accuracy around accuracy RMSE belongs KDE UCV RMSE closely ClassExReg RMSE KDE BCV RMSE RMSE discrepancy explain difference data distribution simulation recognition access truth data  ocr classification displayed rank extrapolation distance truth accuracy consistent ranking extrapolation extrapolation remark simulation difficulty extrapolation primarily sensitive extrapolation ratio versus setting ClassExReg closest truth cnn svm KDE BCV closest truth logistic regression however logistic regression ClassExReg comparably KDE UCV extrapolation extrapolation ratio none extrapolation performs consistently classifier variability dominate training zheng achanta benjamini ClassExReg KDE BCV KDE UCV predict accuracy curve recognition plot predict accuracy curve predict accuracy subsample curve average accuracy obtain data extrapolation extrapolation task unlike recognition resample training retrain classifier prohibitively  cnn cannot comment robustness comparison likely obtain ranking resampling training empirical comparison KDE ClassExReg bias performance KDE achieve comparable ClassExReg around theoretical intuition developed item estimate favorability separately data meaning training achieve robust estimation extrapolate accuracy classifier ClassExReg KDE BCV KDE UCV cnn logistic svm cnn logistic svm cnn logistic svm  ocr extrapolate accuracy extrapolate  ocr classifier logistic regression vector machine convolutional network discussion treat classification task random extrapolate classification performance task performance unobserved task average generalize accuracy decrease increase label distribution function furthermore introduce algorithm estimate underlie distribution allows efficient computation additionally implement kernel density estimation extrapolation discus regime useful code simulation http github com   choice simplify assumption description discus decision alternative model strategy future important practical aspect currently handle analysis non uniform prior distribution label function zero loss theory arbitrary function theory non uniform prior risk incur non uniform prior equivalent risk incur uniform prior function hence address forthcoming performance extrapolation arbitrary function analysis currently restrict sample direction future generalize sample mechanism cluster sample broadly assumption label random sample homogeneous distribution inappropriate classification arise hierarchically partition instance label therefore model random sample suitable model random hierarchical partition arise optional olya finally assume knowledge accuracy achieve partial information zheng achanta benjamini direction exploration impose additional model assumption specific ClassExReg adopts non parametric model discriminability function define via spline expansion however alternative approach assume parametric define parameter forthcoming limit described parameter substantially increase efficiency estimation limit approximate