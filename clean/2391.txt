stability continuous recurrent neural network extensively publish literature purpose comprehensive review research stability continuous recurrent neural network hopfield neural network cohen grossberg neural network related model delay inevitable stability recurrent neural network delay review detail delay dependent stability constant variable delay recurrent neural network summarize relationship stability algebraic inequality matrix linear matrix inequality lyapunov diagonal stability sufficient stability recurrent neural network without delay conclude remark future direction stability analysis recurrent neural network introduction approach recurrent neural network optimization analog computation implement electronic device replace numerical computation realize mathematical algorithm attract considerable attention reference therein however due existence equilibrium recurrent neural network spurious suboptimal response likely limit application recurrent neural network global asymptotic exponential stability unique equilibrium concerned recurrent neural network importance theoretical application research stability recurrent neural network symmetric recurrent neural network without delay reference dynamic stability symmetrically network practical application optimization cohen grossberg analytical global stability symmetric recurrent neural network brief review dynamic stability symmetrically network delay eigenvalue interconnection matrix gain activation function local dynamic stability symmetric hopfield neural network detail theory symmetric restriction connection matrix recurrent neural network asymmetric connection structure instance  interconnection matrix originate slight perturbation electronic implementation symmetric matrix asymmetry interconnection matrix deliberately introduce accomplish task related attempt realistic model neural circuit compose interconnection amplifier neural network nonlinear program therefore local global stability asymmetrically neural network widely topic global stability neural network significant local stability application signal processing optimization important application motivate researcher investigate dynamical behavior neural network global stability neural network reference apply contraction mapping theory obtain sufficient global stability reference generalize lyapunov function reference diagonal stability interconnection matrix imply existence uniqueness equilibrium global stability equilibrium reference negative  interconnection matrix guaranteed global stability hopfield network generalize reference apply matrix theory sufficient global local stability reference stability delayed neural network lyapunov function establish lyapunov diagonal stability lds interconnection matrix reference introduce approach address stability delayed neural network existence equilibrium stability simultaneously without complicate theory theory homeomorphism theory reference global stability criterion recurrent neural network algebraic reflect stability due sufficient expression global stability criterion generally category lds matrix stability sufficiently developed parallel former positive negative excitatory inhibitory influence interconnection strength neuron latter positive interconnection strength neuron difference stability symmetrically analog neural network without delay operating continuous oscillate assume neuron communicate respond instantaneously electronic neural network delay due finite switch amplifier network quickly increase relative intrinsic delay eventually oscillation biological neural network delay stable oscillate delay become source instability therefore delay stability convergence neural network attract considerable attention neural network community symmetric connectivity assumption neural network delay stable magnitude delay exceed bound asymmetric neural network delay sufficient stability independent magnitude delay establish mostly linearization analysis lyapunov function recently stability recurrent neural network delay discrete delay distribute delay neutral delay delay analysis propose linear matrix inequality LMI stability analysis recurrent neural network LMI stability developed date LMI stability analysis recurrent neural network commonly neural network community recently effort various stability analysis recurrent neural network detailed survey summary stability understand development stability theory recurrent neural network although literature survey available stability recurrent neural network exhaustive cohesive review stability recurrent neural network lack motivates comprehensive review specific topic although recurrent neural network complex neural network fractional neural network mainly concerned continuous recurrent neural network described ordinary differential equation domain organize II research category stability recurrent neural network evolution recurrent neural network model activation function connection matrix lyapunov function expression stability brief review stability analysis recurrent neural network IV LMI approach detail related proof LMI stability analyze cohen grossberg neural network related LMI stability criterion introduce VI stability recurrent neural network discontinuous activation function emphasis recurrent neural network without delay vii sufficient dynamic recurrent neural network without delay developed stability recurrent neural network multiple equilibrium useful complement neural network unique equilibrium conclusion future direction finally IX potential promising direction stability analysis recurrent neural network II scope recurrent neural network research recurrent neural network model mainly compose component feedback connection activation function interconnection amplification function delay establish efficient stability criterion usually adopt efficiently information recurrent neural network assumption another relax assumption neural network novel mathematical technique along detailed review stability research recurrent neural network evolution recurrent neural network model hopfield cohen grossberg propose recurrent neural network model modify model frequently propose incorporate internal external factor delay incorporate network model stability research delayed neural network gain significant progress review evolution neural network model delay however development theory neural network variation neural network model therefore briefly review model recurrent neural network recent variant cohen grossberg propose neural network model described nwijgj sourcewhere variable neuron amplification function define function guarantee existence activation function neuron reacts input wij wji connection coefficient neuron model  population biology evolution theory hopfield propose continuous hopfield neural network model  nwijgj SourceRight click MathML additional feature external input source introduce outside network neuron others define obviously hopfield neural network model mathematical description   physical meaning due existence amplification function detail stability criterion background model content assume neuron communicate respond instantaneously however electronic neural network delay due finite switch amplifier source instability moreover related phenomenon model delay neural network neural network feedback delay synapsis become important delay hopfield model described delayed network nwijgj SourceRight click MathML additional feature introduce constant discrete delay  SourceRight click MathML additional feature bound constant delay positive bound function  connection coefficient notation obviously hopfield neural network model neural network instantaneous transmission signal due signal delay model widely extension  nwijgj nwijgj sourcewhere wij connection coefficient associate delayed meanwhile biological neural network practical implementation neural network instantaneous transmission delayed transmission signal simultaneously complicate phenomenon therefore recurrent neural network model involve instantaneous delayed action become dominant model widely application signal transmit another network possibly induce successive delay due various network transmission therefore reasonable combine model  nwijgj nwijgj  SourceRight click MathML additional feature additive delay component stability extends classical delay successive delay delay cannot model discrete delay intermediate discrete distribute delay discrete delay model delayed feedback serf approximation circuit neuron however neural network usually spatial extent due presence multitude parallel pathway variety  distribution propagation delay signal propagation longer instantaneous cannot model discrete delay desire model introduce continuously distribute delay extent variable affect dynamic delay kernel constant discrete delay corresponds choice delay kernel dirac delta function nowadays generally continuously distribute delay neural network model finite distribute delay nwij SourceRight click MathML additional feature delay model variant infinite distribute delay nwij kij sourceand nwijgj kij SourceRight click MathML additional feature delay kernel function kij nonnegative continuous function delay kernel function kij kij τij dirac delta function reduce neural network multiple discrete delay nwijgj τij SourceRight click MathML additional feature delay kernel function kij delayed model recover therefore discrete delay finite distribute delay suitable kernel function recurrent neural network continuously distribute delay propose   τij  sourcewhere   lebesgue  lebesgue  model discrete delay distribute delay uniformly express proof stability delay unified neuron external neuron local internal neuron variable dynamic recurrent neural network usually cast static neural network model local neural network model recurrent  neural network brain  neural network optimization neural network model static neural network model described matrix vector sourcewhere vector neuron diag feedback positive diagonal matrix wij interconnection matrix hopfield neural network cellular neural network model local neural network model matrix  model belong local neural network belongs static neural network model aspect model description local neural network model along routine meaningful unified model static neural network local neural network described SourceRight click MathML additional feature matrix appropriate dimension delay sequel extend model SourceRight click MathML additional feature extension denote delay component transmission signal network factor neural network model stochastic action reaction diffusion action interaction impulse switch superimpose elementary hopfield neural network cohen grossberg neural network complex neural network model application internal external practical neural network besides delay evolution activation function existence uniqueness global asymptotic exponential stability equilibrium concern activation function continuous bound strictly monotonically increase however recurrent neural network optimization presence constraint linear quadratic program unbounded activation function model diode exponential function impose constraint difference bound unbounded activation function extension bound activation function unbounded straightforward therefore activation function propose literature suitable generalize activation function greatly improve performance neural network activation function important capacity neural network reference absolute capacity associative memory model remarkably improve replace sigmoid activation function nonmonotonic activation function therefore significant neural network generalize activation function recent researcher devote attention attain goal propose generalize activation function  various activation function literature research neural network activation function threshold function piecewise linear function signum function hyperbolic tangent function limiter nonlinearity mainly concerned lipschitz continuous activation function variant sigmoidal activation function    lim sourcewhere activation function neuron neuron obviously differentiable monotonic bound activation function  activation function bound activation function necessarily monotonic smooth activation function employ SourceRight click MathML additional feature activation function employ source activation function developed source positive negative zero previously lipschitz comparison various continuous activation function comparison activation function important associate activation function existence uniqueness equilibrium recurrent neural network brief comment bound activation function quasi lipschitz activation function unbounded constant existence equilibrium establish mainly basis fix theorem bound activation function satisfy lipschitz continuous existence guaranteed existence theorem ordinary differential equation unbounded activation function existence equilibrium establish mainly basis homeomorphism mapping   principle another important associate activation function existence uniqueness global asymptotic exponential stability simultaneously dealt stability analysis recurrent neural network encounter consistent viewpoint stability theory neural network routine stability analysis recurrent neural network directly global asymptotic exponential stability without proof existence uniqueness equilibrium proof existence uniqueness global asymptotic exponential stability clearly clarify stability analysis recurrent neural network proceed mathematical establish existence applicable uniqueness equilibrium stability however accord requirement activation function slightly treatment routine stability proof equilibrium bound activation function directly proof global asymptotic exponential stability bound activation function guarantee existence equilibrium quasi lipschitz existence equilibrium guaranteed bound activation function therefore suffices proof global asymptotic exponential stability equilibrium recurrent neural network bound activation function uniqueness equilibrium directly global asymptotic exponential stability unbounded activation function contrary proof existence uniqueness global asymptotic exponential stability equilibrium concerned neural network simultaneously activation function belong continuous function detail relationship global lipschitz continuous partially lipschitz continuous locally lipschitz continuous reader refer discontinuous activation function exist practical application classical hopfield neural network grade response neuron standard assumption activation employ gain limit closely approximate discontinuous comparator function another important concern neural network introduce linear nonlinear program constraint neuron diode input output activation guarantee satisfaction constraint diode posse slope conduct approximate discontinuous characteristic ideal diode therefore activation function discontinuous discontinuous activation function continuous nondecreasing function compact finite discontinuity therefore compact finite exist finite limit assumes bound exists positive stability analysis neural network discontinuous activation function drawn researcher attention related publish literature independent pioneer   chen hopfield neural network bound discontinuous activation propose existence equilibrium stability uniqueness equilibrium global stability instead cohen grossberg neural network unbounded discontinuous activation propose global exponential stability existence uniqueness equilibrium delayed neural network discontinuous activation propose model propose conclude almost periodic dynamic network discontinuous activation investigate  differential discrete delay distribute delay therefore activation function evolve bound unbounded continuous discontinuous strictly monotonic nonmonotonic depth research stability theory recurrent neural network evolution uncertainty connection matrix deterministic accurate connection matrix stability publish however electronic implementation recurrent neural network connection matrix disturbed perturbed external environment therefore robustness neural network perturbation uncertainty literature uncertainty assume connection matrix uncertainty ΔA described ΔA MF FT sourceor ΔA MF FT sourcewhere constant matrix  identity matrix compatible dimension uncertainty convenient stability analysis LMI robust stability neural network uncertainty widely physical meaning linear fractional representation uncertainty reader refer detail interval uncertainty connection matrix satisfies AI aij aij sourceif ΔA uncertainty express  ΔA   SourceRight click MathML additional feature NA FA define accord arrangement obviously interval uncertainty uncertainty absolute uncertainty unmatched uncertainty ΔA   SourceThis uncertainty LMI establish nonlinear neural uncertainty robust stability propose algebraic inequality matrix matrix theory recurrent neural network LMI robust stability nonlinear neural uncertainty tendency implies robust stability uncertain neural propose  uncertainty   sourcewhere constant matrix compatible dimension invariant uncertainty robust stability uncertainty uncertainty parameter uncertainty reflection bound parameter uncertainty equivalent bound perturbation meanwhile robust stability generally mathematical analysis due uncertainty description neural evolution delay due transmission channel medium delay unavoidable aspect delay approximation capability description complexity simplest assume delay transmission channel relaxation assume delay channel channel discrete delay reflect centralize delay distribute delay neural network duration respect discrete delay delay refer II II delay II delay delay derivative delay usually limited slowly delay application novel mathematical matrix  formula derivative delay delay cannot  otherwise delay restriction derivative delay meaningful mathematics analysis previous delay assume belong interval delay interval replace meaning expansion consists bound delay practical cannot zero bound interval upper bound delay estimate delayed accurately approximate nonzero bound delay discrete delay usually bound however bound delay extend unbounded exist reference deterministic delay concerned stability criterion derive information variation delay actually delay nns existent stochastic fashion occurs delay probability delay variation delay employ derive stability criterion conservative therefore challenge issue derive criterion uncertain stochastic delayed neural network exploit available probability distribution delay obtain allowable variation delay recently neural network leakage delay leakage delay explain nonlinear sourcewhere vector nonlinear function restrictive constant matrix appropriate dimension delay corresponds stabilize negative feedback instantaneously without forget leakage delay stabilize negative feedback tendency destabilize delay incorporate leakage leakage delay sourcewhere delay obviously leakage delay delay however stability analysis leakage delay cannot dealt routine conventional delay evolution lyapunov approach stability criterion recurrent neural network derive via lyapunov theory conservatism reduce conservatism topic research lyapunov stability theory reduction achieve mainly phase suitable lyapunov functional estimate derivative choice lyapunov functional crucial derive conservative criterion various lyapunov functionals estimation derivative lyapunov functionals construct stability recurrent neural network mainly discus evolution lyapunov approach lyapunov function analysis global stability estimation derivative lyapunov functional brief review hopfield neural network symmetry assumption interconnection continuously differentiable function VH     sourcewhere inverse function wij wji derivative along trajectory    SourceRight click MathML additional feature monotonically increase function  alternative proof cohen grossberg network model continuously differentiable function VCG    SourceRight click MathML additional feature wij wji derivative along trajectory  ndi  nwijgj SourceRight click MathML additional feature monotonically nondecreasing function nonnegative function  stability proof neural network proof procedure activation function usually monotonically increase function function VH VCG continuously differentiable function instead lyapunov function lyapunov stability theory stability proof  invariance principle pioneer cohen grossberg hopfield global limit establish initial converge equilibrium however global limit description estimate attraction equilibrium initial converge equilibrium exactly converge associative memory initial retrieve network application neural network parallel computation signal processing involve optimization define computable initial network unique equilibrium globally attractive earlier application neural network optimization suffer existence complicate equilibrium global  unique equilibrium importance theoretical practical purpose concern continuous function sufficient guarantee neural circuit globally convergent unique stable equilibrium expense neuron connection matrix symmetric negative semidefinite symmetry negative  interconnection matrix restrictive research global  stability neural network mainly concentrate construction lyapunov function basis lyapunov stability theory lyapunov function construct purely delayed wij   sourceand sufficient ensure uniqueness global asymptotic stability equilibrium establish lyapunov global stability widely incorporate information neural network construction lyapunov function lyapunov function construct discrete delay  SourceRight click MathML additional feature neural network infinite distribute delay lyapunov function construct  wij kij  SourceRight click MathML additional feature positive lyapunov function global stability derive algebraic inequality absolute operation conduct interconnection coefficient derive LMI stability lyapunov function quadratic generally adopt lyapunov function construct   sourcewhere lyapunov function construct  sdi npi sourcewhere define constant lyapunov function construct    sourcewhere positive symmetric positive definite matrix lyapunov function construct  SourceRight click MathML additional feature positive definite symmetric matrix delay lyapunov function construct     sourcewhere positive definite symmetric matrix others define similarly constant delay function delay decomposition propose     SourceRight click MathML additional feature positive integer scalar satisfy symmetric positive definite matrix appropriate dimension equilibrium locally stable continuous function respectively improve global stability lyapunov function positive accord lyapunov stability theory therefore absolute positive continuous function function adopt recent literature variation recurrent neural network action stochastic perturbation neutral distribute delay reaction diffusion construction lyapunov  function besides information incorporate function incorporation information construction lyapunov  function flexible diverse classical function comparison delay independent stability criterion delay dependent stability criterion generally concept concern stability delay delay independent stability criterion information delay rate delay unknown delay delay independent stability criterion important role stability delay dependent stability criterion delay rate delay involve stability criterion delay dependent stability literature mainly refer discrete delay finite distribute delay specific delay rate delay estimate infinite distribute delay stochastic delay specific description delay rate delay concept delay independent dependent stability criterion relevant delay information kernel function information expectation information stochastic delay involve stability criterion delay dependent otherwise delay independent information delay rate delay holographic delay delay dependent criterion conservative delay independent delay delay unknown delay dependent criterion unusable delay independent stability criterion useful stability evaluation analysis stability recurrent neural network lyapunov stability theory  theorem nonsmooth analysis ordinary differential equation theory  invariant theory nonlinear gradient theory comparison principle delay differential expression stability criterion due analysis proof matrix algebraic inequality matrix norm additive diagonal stability LMI matrix spectral radius stability criterion matrix matrix matrix norm spectral radius associate absolute parameter freedom variable criterion stability criterion mainly stability theory recurrent neural network contrast lds involves adjustable matrix establish relationship parameter stability advantage expression easy conservative stability algebraic inequality LMI expression involve parameter tune stability become complex exceedingly complex LMI stability useful numerical purpose theoretic meaning deprive effective stability criterion challenge research direction furthermore increase additive recurrent neural network discrete delay distribute delay reaction diffusion stochastic delay stability criterion become conservative phenomenon resort additive complexity structure conservativeness criterion increase multiplicative complexity structure related publish brief review analysis stability content review algebraic stability analysis neural network concept lds matrix matrix matrix usually stability network model due assumption network therefore outline evolution stability neural network sequel stability assume concerned neural network suitable assumption confusion occurs derive ensure global exponential stability wij lateral feedback matrix zero diagonal entry asymmetric continuous  λmin  SourceRight click MathML additional feature diag wij λmin minimum eigenvalue  denotes maximum singular eigenvalue wwt global exponential stability criterion propose monotonically increase lipschitz continuous matrix positive definite diagonal matrix diag LW  SourceRight click MathML additional feature  sup diag global exponential stability convergence criterion propose strictly monotonically increase lipschitz continuous exist positive definite diagonal matrix diag positive constant TL sourcewhere identity matrix appropriate dimension conservative derive global stability    wij sourcewhich corollary global exponential stability convergence criterion propose strictly monotonically increase lipschitz continuous exist positive constant inequality    wij   wij   wij  wji    SourceRight click MathML additional feature conservative global exponential stability criterion detailed comparison remark respectively purely delayed hopfield network criterion establish sourcewhere max denotes norm establish sourcewhich guarantee global asymptotic stability unique equilibrium denotes spectral radius matrix wij symmetric connection matrix WT sufficient derive guarantee absolute stability ABST equilibrium max  sourceor matrix SourceRight click MathML additional feature eigenvalue matrix define sequel sufficient ensure unique equilibrium asymmetric connection matrix stability normal connection matrix WTW wwt sufficient derive guarantee ABST max  SourceRight click MathML additional feature obviously requirement connection matrix stability derive improve quasi diagonally sum sum dominance ensure ABST quasi diagonal dominance implies matrix nonpositive diagonal strictly diagonal dominant derive imply lds ABST guaranteed interconnection matrix lds PW WTP SourceRight click MathML additional feature positive definite diagonal matrix improve become PW WTP SourceRight click MathML additional feature lyapunov diagonally   additive diagonal stability derive positive definite diagonal matrix exist positive definite diagonal matrix TD SourceRight click MathML additional feature extend connection matrix matrix nonpositive diagonal within locally lipschitz continuous monotone nondecreasing activation function ABST diagonal   sum dominance developed worth additive diagonal stability introduce mild sufficient ABST neural network literature mainly focus basis matrix matrix lds concept delayed network existence uniqueness equilibrium however global asymptotic stability unique equilibrium matrix lds concept lose superiority matrix effective detail refer summarize relationship lds concept LMI matrix helpful reader insight stability criterion neural network accord lds definition obvious lds LMI accord definition matrix nonsingular matrix equivalent TP SourceRight click MathML additional feature positive definite diagonal matrix global asymptotic stability lds matrix unbounded activation possibly possess saturation zero slope reader refer detail PΔ positive definite diagonal matrix valid contrary PW WTP suitable gain activation function therefore conservative nonsingular matrix equivalent TP SourceRight click MathML additional feature define wij positive matrix wij equivalent otherwise equivalent  interconnection matrix removal restriction symmetry interconnection matrix neural network model consequence lds information various subset stable matrix relationship various subset refer lds matrix expression easy verify popular stability theory neural network stability research hopfield neural network approach existence equilibrium exponential stability simultaneously function lyapunov function author knowledge adopt unified stability hopfield neural network review   propose finite trajectory activation function analytic bound strictly monotonically increase trajectory finite limt euclidean norm finite standard mathematical argument existence limit convergence equilibrium hence ABST detail limt cauchy criterion limit existence exists hence  basis cauchy criterion limit existence sufficiency exists limt constant equilibrium lemma derive correspond stability criterion norm limit constant lemma briefly cauchy convergence principle limit lemma finite trajectory propose lemma activation function continuously differentiable strictly monotonically increase exponential stability derive IV development proof proof LMI stability superiority LMI analysis synthesis dynamical technical derivation LMI stability introduction analysis lds matrix LMI analysis LMI developed context compete derive stability criterion usually sufficient therefore advantage stability analysis neural network lds aim establish qualitative structural interconnection matrix incidentally verifiable via algebraic inequality dimensional whereas LMI approach convex optimization therefore numerically efficient generalization lds approach aim establish numerically computable stability LMI constraint aspect dimensional network model amount adjustable parameter freedom stability LMI generalization analysis lds conservativeness stability criterion criterion employ conservativeness stability specific neural network model verify stability  meaningful diagonal respect LMI effective lds superiority shortcoming LMI stability theory neural network almost stability stem viewpoint building relationship physical parameter neural network therefore stability criterion matrix matrix norm matrix developed physical parameter neural network nonlinear redundancy express constrain relationship variable stability criterion algebraic inequality inequality holder inequality  inequality  inequality paid attention recent improve stability criterion significantly although stability criterion algebraic inequality conservative theory generally due adjustable parameter involve prior information tune variable LMI regard powerful matrix operation LMI stability criterion attention researcher survey LMI technique stability analysis delayed LMI application review LMI stability matrix relate physical parameter neural network compact structure elegant expression popularity LMI mainly due LMI technique apply convex optimization handle efficiently resort exist numerical algorithm  meanwhile LMI easily correspond synthesis LMI stability performance establish feedback employ neural network without delay lds bridge matrix LMI LMI delayed neural network core lds matrix however delayed lds matrix lack suitable freedom tune conservativeness stability criterion contrast LMI easily incorporate variable stability criterion decrease conservativeness correspondingly stability matrix inequality propose performance evaluation desire LMI effective LMI suitable model described equation matrix theory related incorporate LMI therefore algebraic inequality mainly scalar dot almost scalar inequality algebraic inequality matrix inequality LMI  formula jensen inequality park inequality inequality LMI directly vector extends application algebraic inequality therefore inhibitory information LMI algebraic inequality shortcoming LMI application mathematical technique stability analysis neural network shortcoming LMI disadvantage exceedingly complex expression stability becomes inefficiency complex stability physical meaning theoretical meaning stability LMI lose superiority classical algebraic inequality become useful numerical purpose become LMI stability therefore efficiency propose specific analytical increase slack variable significantly increase complexity computation effort reduce redundancy slack variable therefore develop reduce conservatism exist stability reasonably computational complexity important issue investigate future exceedingly complex expression stability easy synthesis neural due slack variable effective LMI stability criterion challenge topic technical LMI stability delayed neural network LMI approach stability analysis recurrent neural network delay lyapunov  function incorporate information concerned construction lyapunov  function technical proof procedure novel LMI stability propose reduce conservativeness stability delay achieve maximum upper bound delay network parameter etc summarize technical stability analysis delayed recurrent neural network matrix propose improve delay dependent stability delay feature employ neither model transformation bound technique powerful delay emergence matrix almost LMI stability slowly delay assumption stem bound growth variation delay factor function restrictive application realistic  functional differential equation essence matrix variable matrix identity improve effectiveness stability involve adjustable variable identity accord newton  formula sourceor identity nonlinear sourcewhere compatible dimension suitable vector compatible dimension respectively equation substitute implicit relationship parameter redundant variable matrix therefore matrix utilize sufficiently combination involve identity complexity induced crossover contribution matrix involve freedom equivalently relation conservativeness stability criterion decrease significantly performance evaluation certainly decrease conservativeness restriction rate delay relaxed constant matrix decomposition mainly stability recurrent neural network without delay hopfield cohen grossberg neural network without delay matrix decomposition connection matrix decompose summation matrix compose zero similarly connection matrix decompose summation matrix compose zero improves stability lds conservative stability LMI cohen grossberg neural network connection matrix decompose symmetric matrix positive definite diagonal matrix DS positive definite diagonal matrix symmetric matrix DS SD delay matrix decomposition LMI powerful analyze stability neural network delay LMI stability criterion neural network multiple delay τij LMI stability establish τij delay matrix decomposition propose τij τij neural network continuously distribute delay kij delay matrix decomposition valid expression stability delay matrix decomposition generalization stability delay matrix decomposition analyze τij contribution delay matrix decomposition unifies LMI stability neural network delay framework matrix decomposition employ propose purely delayed neural network delay matrix decompose excitatory inhibitory max bij signifies excitatory max bij signifies inhibitory obviously nonnegative symmetric transformation embed network construct interconnect matrix augment cooperative dynamical monotone dynamical theory significant preserve monotone useful analysis purely delayed neural network detail refer worth delay matrix decomposition propose mainly focus multiple discrete delay τij multiple continuously distribute delay kij LMI stability criterion propose aim decompose delay connection matrix positive matrix monotone dynamical theory establish correspond stability delay decomposition partition approach delay important parameter delayed neural network interconnection matrix sufficiently explore development neural network stability theory occurrence matrix stability criterion connection decrease conservativeness stability delay dependent stability criterion improvement delay independent stability criterion information delay sufficiently explore previous stability analysis delay simply regard isolated discrete implicitly implies belongs interval upper bound information utilized constant however accord sample theory approximation theory interval subintervals     subinterval sample frequency interval suitable fix variable  information interval variable involve matrix principle delay decomposition approach delay dependent stability criterion obtain decrease conservativeness stability achieve maximum upper bound delay important aspect judging conservativeness stability criterion maximum delay conservative stability delay decomposition approach reduces conservativeness stability criterion essence delay decomposition approach enlarge augment involve adjustable variable augment dimension challenge topic exist delay decomposition approach subintervals subinterval achieve optimal upper bound delay combine delay decomposition approach augment lyapunov  function stability delayed neural network publish conservativeness stability decrease expense unknown parameter matrix involve descriptor universal transformation transform normal differential descriptor analysis approach descriptor normal differential therefore dimension differential enlarge augment dimension adjustable matrix construction lyapunov functional increase essence descriptor increase correspondingly tune matrix decrease conservativeness stability splitting interval matrix devote robust stability analysis neural network interval uncertainty uncertain connection matrix delay decomposition approach interval positive integer splitting interval unequal LMI matrix inequality checked simultaneously splitting interval matrix propose stability cohen grossberg neural network model cohen grossberg neural network discus stability assumption assumption amplification function continuous exist constant SourceRight click MathML additional feature assumption function continuous exists constant SourceRight click MathML additional feature assumption activation function globally lipschitz continuous exists positive constant SourceRight click MathML additional feature denotes absolute assumption activation function globally lipschitz continuous exists positive constant sourcefor assumption amplification function continuous  sourcefor constant difference assumption difference assumption function assumption strictly positive function assumption nonnegative moreover amplification function positive constant satisfies assumption satisfy assumption due hence assumption cannot assumption relationship cohen grossberg neural network delayed cohen grossberg neural network difference amplification function assumption assumption due assumption amplification function hopfield model constant amplification function hopfield model curve cohen grossberg neural network assumption nonnegative positive initial curve cohen grossberg neural network assumption positive negative mixture initial requirement function function monotonically increase radially unbounded accord choice positivity connection coefficient positive connection coefficient model biological reflect survival  specie contrast stem engineering application manner hopfield neural network model optimization decision signal processing similarity model structure mathematical description symmetry requirement interconnection matrix neural network stability theory however symmetry interconnection matrix research due amount related literature publish easy reference outline clearly research progress stability theory neural network mainly discus neural network model cohen grossberg neural network model cohen grossberg neural network model primitive model pinpoint achievement obtain relevant whereas corollary minor improvement subsection organize focus stability cohen grossberg neural network model improvement surround model appropriately concentrate cohen grossberg neural network model review progress aspect stability cohen grossberg neural network nonnegative equilibrium focus progress cohen grossberg neural network related reference complement progress stability contribution discover essence symmetry dynamic complex establish stability criterion stability propose assumption variant cohen grossberg neural network  propose sufficient global stability  invariance principle connection matrix decompose symmetric matrix positive definite diagonal matrix DS SourceRight click MathML additional feature positive definite diagonal matrix symmetric matrix bound trajectory approach possibly equilibrium DS SD therefore stability relaxed lotka volterra model compete specie   SourceRight click MathML additional feature cohen grossberg neural network population specie  negative interaction parameter specie constant  inequality  extends convergence concerned isolated equilibrium cohen grossberg ABST via  invariance principle trajectory converge isolated equilibrium convergence isolated equilibrium aspect delay symmetric connection improve stability nonnegative positive equilibrium correspond cohen grossberg neural network delay reaction diffusion cohen grossberg neural network described dik nwijgj sourcewhere dik dik denotes diffusion operator transmission  signal wij  lds lyapunov volterra quasi stable lyapunov volterra stable respectively PW PW sourcefor positive definite diagonal matrix nonnegative equilibrium locally asymptotically stable despite symmetry restriction matrix remove symmetric matrix symmetric matrix stable  stable obviously sufficient guarantee local asymptotic stability due additive reaction diffusion activation function satisfies quasi lipschitz instead global lipschitz assumption sgn network bound delay τij positive initial nwijgj nwijgj τij SourceRight click MathML additional feature matrix SourceRight click MathML additional feature nonsingular matrix unique equilibrium globally asymptotically stable wij wij diag diag      SourceRight click MathML additional feature matrix  nonsingular matrix guarantee uniqueness equilibrium obviously existence improve however global asymptotic stability τij  lds equivalently LMI   TP sourcewhere positive definite diagonal matrix exists unique nonnegative equilibrium τij exist positive definite diagonal matrix positive definite symmetric matrix LMI  PW PW PW PW SourceRight click MathML additional feature unique nonnegative equilibrium τij globally asymptotically stable unique equilibrium positive ensure global exponential stability τij schur complement lemma equivalent  PW PW  PW SourceRight click MathML additional feature uniqueness global asymptotic stability uniqueness global asymptotic stability generally equivalent existence equilibrium concerned conservative cohen grossberg neural network finite distribute delay nwijgj     SourceRight click MathML additional feature establish global asymptotic stability  PW PW      sourcewhere positive definite diagonal matrix wij   obviously extends core neural network without delay addition delayed core expand therefore derive network model become complex LMI LMI unifies LMI stability literature subsection discus cohen grossberg neural network mixed equilibrium amplification function satisfies assumption stability cohen grossberg neural network  matrix algebraic inequality focus progress stability analysis cohen grossberg neural network related reference complement progress stability analysis assume matrix  sourceis symmetric activation function sigmoidal bound globally stable  sourcewhere max max  denotes euclidean norm publication research dynamic cohen grossberg neural network assumption become topic neural network community therefore stability equilibrium cohen grossberg neural network model variant establish assumption chen global stability boundedness activation function positive bound amplification function matrix  sourceis lds exists positive definite diagonal matrix diag   TP sourcethen unique equilibrium importantly relationship matrix lds specifically positive interconnection coefficient asymptotic stability criterion matrix lds concept equivalent matrix bridge algebraic inequality LMI however cohen grossberg neural network delay asymptotic stability criterion matrix LMI approach equivalent generally matrix unified expression LMI various expression cohen grossberg neural network delay LMI stability propose literature positive bound amplification function guarantee global exponential stability contrast exponential stability amplification function cohen grossberg neural network upper bound assumption positive boundedness amplification function nwijgj τij  det WK sourcefor diagonal matrix satisfy unique equilibrium furthermore matrix  sourceis nonsingular matrix equilibrium globally exponentially stable obviously deduce assumption ΔD  matrix guarantee global asymptotic stability cohen grossberg neural network diag diag  analysis apply network nwijgj  nwij kij nwijgj kij sourcewhere delay kernel kij satisfies kij suitable model model unify global asymptotic stability criterion model ΔD sourceand  nonsingular matrix wij obviously stability matrix unified expression cohen grossberg neural network delay easy assumption boundedness activation function cohen grossberg neural network nwijgj nwijgj τij source matrix mij nonsingular matrix equilibrium unique globally exponentially stable   wij mij wij wij addition equivalent matrix nonsingular matrix sourceor algebraic inequality    wji  wji    wij  wij   wji wij wji wij sourcefor positive constant wij wij wij equivalent strictly diagonally dominant strictly diagonally dominant respectively diag positive definite diagonal matrix matrix mij matrix define maxi   maxi   λmax MT λmax denotes maximal eigenvalue symmetric matrix therefore improve cohen grossberg neural network reaction diffusion dik nwijgj  τij  exponential stability neumann boundary bound compact smooth boundary dik dik denotes transmission diffusion operator along neuron assumption bound activation function globally lipschitz positive constant corollary establish global exponential stability  wji wji  sourceis nonsingular matrix naturally satisfied diag diag diag stochastic hopfield neural network constant delay duo dik nwijgj  τij   sourcethe global exponential stability dimensional brownian define probability filtration generate canonical generate denotes associate algebra generate probability deterministic derive guarantee global exponential stability unique equilibrium   lipschitz continuous lipschitz constant lij nonsingular matrix derive MM   sourcewhich guarantee almost exponential stability exponential stability respectively diag    diag   sourceand constant obviously matrix unifies exist reaction diffusion hopfield neural network continuously distribute delay dik nwijgj nwij kij sourcethe global exponential stability matrix derive ensure global exponential stability  sourcewhere max wii wij distribute delay nwijgj  τij nwij kij sourceand  kij sourcewhere kij establish  sourceand sourceis nonsingular matrix guarantee global exponential stability unique equilibrium positive identity matrix appropriate dimension τij  wij diag kij neural network finite distribute delay dik   sourcewhere positive constant analyze stability asymptotic stability criterion express therefore continuous distribute delay neutral cohen grossberg neural network constant delay  nwijgj nwijgj sourcethe global asymptotic stability eij constant matrix denotes coefficient derivative delayed continuous differentiable   min  sourcewhich guarantee global asymptotic stability max max max  max reduce maxi mini   reduce mini source core neural network without delay similarly purely delayed neural network increase complexity network core expand matrix stability network structure stability cohen grossberg neural network via matrix inequality mixed focus stability analysis cohen grossberg neural network related reference complement progress activation function assume satisfy assumption declaration cohen grossberg neural network nwijgj  sourcewhich global exponential stability matrix inequality matrix norm stability criterion establish  PW PW  WTP sourceand sourcewhere positive definite diagonal matrix min max easy lds recover without loss generality becomes  WT wwt sourceif vector  WT wwt    implies similarly cohen grossberg neural network continuously distribute delay nwijgj nwijgj nwij sourcethe LMI global exponential stability skj   compact matrix vector  distribute delay therefore analysis cannot apply neural network distribute delay LMI global asymptotic stability restriction rate delay cohen grossberg neural network continuously distribute delay nwijgj nwij kij source matrix inequality  PW WTP PQ  sourceto guarantee equilibrium globally asymptotically stable furthermore kij  sourcewhere constant equilibrium globally exponentially stable transform vector matrix nei sourcewhere diag  matrix compose matrix zero obviously due difference kernel function LMI stability criterion propose improve inequality  inequality newton  formula matrix LMI stability establish cohen grossberg neural network cohen grossberg neural network finite distribute delay LMI stability establish respectively delay matrix decomposition propose derive core stability criterion neural network delay derive respectively assumption network model stability mathematical description however physical meaning reflect essence topic robust stability recurrent neural network hardware implementation neural network accurate parameter neural network guarantee neural network vital data neuron rate synaptic interconnection signal transmission delay usually acquire statistical estimation definitely estimation error moreover parameter fluctuation neural network implementation integration chip unavoidable explore mention vital data bound circuit parameter engineering incomplete information implies neural network robustness pave introduce theory interval matrix interval dynamic investigate global stability interval neural network robust stability important consideration dynamic neural network without delay related robust stability global robust stability delayed interval hopfield neural network investigate respect bound strictly increase activation function matrix ensure robust stability delayed interval hopfield neural network global robust stability criterion hopfield network parameter delay interval parameter uncertainty hybrid matrix inequality matrix norm connection matrix uncertain parameter perturbation testable robust stability continuous hopfield neural network without delay interval uncertain parameter uncertainty testable LMI robust LMI robust stability recurrent neural network difficulty tackle uncertainty uncertainty interval uncertainty LMI robust stability publish however recurrent neural network uncertainty LMI robust stability important establish LMI robust stability recurrent neural network uncertainty attempt advantage LMI technique establish stability theory recurrent neural network uncertainty parallel scalar matrix algebraic inequality proof robust stability interval uncertainty uncertainty without uncertainty review robust stability recurrent neural network omit VI stability analysis neural network discontinuous activation function although mainly focus stability continuous recurrent neural network discontinuous recurrent neural network intensively literature dynamical possess slope nonlinear advantageous model differential equation discontinuous slope finite advantage analyze ideal discontinuous analysis usually salient feature presence slide mode possibility trajectory confine interval discontinuity exist literature report investigation discontinuous neural network pertain application context neural architecture significant hopfield neural network neuron model discontinuous comparator function discontinuous activation function address discontinuous activation function II analysis valid symmetric neural network possess multiple equilibrium saturation network useful implement content addressable memory reference introduce neural architecture linear program architecture substantially additive neural network moreover network gradient suitable function additive neural network hopfield gradient restrictive assumption symmetric interconnection matrix discontinuous neural network concept theory differential equation discontinuous introduce  usually discontinuous hopfield network establish global convergence applicable  interconnection matrix generalize previous discontinuous neural network possess smooth neuron activation specifically establish satisfied matrix sourcethen discontinuous hopfield network unique equilibrium unique correspond output equilibrium matrix matrix principal minor positive importantly concept global convergence output equilibrium propose usually standard literature neuron activation function continuous monotone easy global  equilibrium implies global  output equilibrium unfortunately longer valid discontinuous activation function discontinuous neuron activation convergence imply convergence output therefore discontinuous activation function address separately global convergence variable output variable derive lyapunov diagonally stable sourcewhich guarantee discontinuous network unique equilibrium unique correspond output equilibrium respectively globally attractive neural network input almost input establish standard global    establish existence uniqueness global convergence finite equilibrium correspond output equilibrium discontinuous network concept global convergence finite extend discontinuous neural network delay boundedness activation function remove theorem restate simply wii matrix sourcethen discontinuous unique equilibrium unique correspond output equilibrium unique equilibrium globally exponentially stable wij wij wij otherwise wij wij delay sufficiently interconnection matrix discontinuous implies lds therefore neuron interconnection restrictive however matrix involve model cooperative neural network concept matrix lds matrix coincide unbounded neuron activation analysis bound activation function therefore yield restrictive pioneer topic discontinuous neural network paid attention related establish mainly research discontinuous neural network reader refer reference cite therein detail omit mainly core lds matrix core stability derive complex neural network model vii sufficient recurrent neural network nowadays almost stability recurrent neural network sufficient however exist sufficient recurrent neural network without delay sufficient asymptotic exponential stability criterion exist literature establish basis strict inequality strict inequality replace  inequality sufficient  inequality neural network  nwijgj  τij  establish global convergence  wij wij sourcethen unique equilibrium satisfies limt tanh  tanh  max relaxes restrictive stability convergence stability convergence purely delayed hopfield neural network source sufficient    sourcewhich guarantee componentwise exponential convergence   constant vector appropriate dimension scalar identity matrix appropriate dimension wij wij wij max wij excitatory wij max wij inhibitory obviously nonnegative hopfield neural network ABST  nwijgj sourcewhere sigmoid function consist smooth strictly monotonic increase function saturate tanh ABST neural network globally asymptotically stable equilibrium neuron activation function belonging define function constant input vector  connection matrix sufficient sourceis guarantee uniqueness equilibrium bound activation function denotes matrix define equivalent principal minor nonnegative eigenvalue principal submatrix nonnegative det diagonal matrix diag negative  matrix sufficient guarantee uniqueness equilibrium asymmetric connection matrix however sufficient ABST asymmetric connection matrix contrary symmetric connection matrix negative  matrix sufficient guarantee ABST unique equilibrium consistent ABST extend absolute exponential stability  conjecture sufficient ABST neural network connection matrix belongs matrix eigenvalue matrix negative arbitrary positive diagonal matrix proven sufficient ABST neural network neuron necessity ABST proven exist sufficient ABST however sufficient ABST neural network remains unknown neuron within partially lipschitz continuous monotonically nondecreasing activation function activation function sigmoidal function novel  positive definite diagonal matrix exists positive definite diagonal matrix TD extend stability connection matrix matrix nonpositive diagonal WTW wwt normal matrix sufficient establish  sourceor  WT sourcethen normal neural network absolutely stable eigenvalue matrix eigenvalue symmetric matrix normal symmetric neural network negative  obviously remove assumption normal matrix matrix decomposition WT WT symmetric skew symmetric respectively matrix eigenvalue solvable algebra sufficient guarantee ABST concerned hopfield neural network specifically suppose generate solvable algebra  sourceor symmetric matrix negative semidefinite absolutely stable assumption sufficient derive  nonsingular det  sourcewhich ensures unique equilibrium hopfield neural network delay  nwijgj τij   sufficient obtain det matrix sourcewhere matrix define saturates continuous max max τij improve matrix matrix eigenvalue core stability criterion complex neural network model sufficient obtain  recurrent neural network comparison global stability precede global stability unique equilibrium continuous recurrent neural network  investigation recurrent neural network apply recognition image processing associative memory formation desire network equilibrium individual addition neuromorphic analog circuit  dynamic essential role reveal therefore coexistence stability multiple equilibrium basin attraction theory application tutorial application neural network associative memory formation refer theoretical research convergence  recurrent neural network refer mainly focus recent theoretic multiple equilibrium recurrent neural network chen  neuron neural network model equilibrium locally stable unstable neuron neural network decompose phase subset zeng wang investigate  delayed cellular neural network neuron network stable periodic orbit subset  cohen grossberg neural network piecewise activation function neuron network locally exponentially stable equilibrium saturation equilibrium neuron neural network however emphasis equilibrium stable subset positive invariance mention stability dynamical behavior equilibrium dynamic remain subset attraction basin stable equilibrium stability analysis multiple equilibrium decomposition phase invariant attractive subset stable equilibrium neural network reduce linear stability equilibrium execute difficulty efficiently decompose phase basis activation function accurate attractive basin equilibrium difference stability analysis recurrent neural network unique equilibrium recurrent neural network multiple equilibrium summarize initial unique recurrent neural network initial multiple recurrent neural network belongs subspace difference global stability local stability respectively activation function role analyze stability unique equilibrium multiple equilibrium activation function existence uniqueness global stability equilibrium contrast specific activation function analysis recurrent neural network multiple equilibrium subspace decomposition cannot proceed local stability analysis multiple equilibrium cannot conduct subspace decomposition analyze global stability recurrent neural network unique equilibrium contraction lyapunov differential equation comparison principle however recurrent neural network multiple equilibrium literature linearize local equilibrium consequently concerned local stability stability recurrent neural network multiple equilibrium recurrent neural network unique equilibrium however estimation domain attraction multiple equilibrium correspond local stability application recurrent neural network unique equilibrium mainly optimization contrast recurrent neural network multiple equilibrium apply associative memory recognition formation signal processing IX future direction conclusion topic stability recurrent neural network detail coverage aspect stability research recurrent neural network fruitful stability recurrent neural network greatly promote development neural network theory future direction stability recurrent neural network prospective suggestion apply useful mathematical decrease conservativeness stability reduce conservatism exist stability reasonably computational complexity topic sometimes related development discipline apply mathematics computational mathematics mechanic establish sufficient stability delayed recurrent neural network neuron constant delay sufficient stability propose recurrent neural network neuron moreover obtain approximate sufficient stability meaningful development neural network theory addition global stability establish stability criterion multiple equilibrium recurrent neural network effort global stability related optimization multiple stability related associative memory application image recognition data classification information processing multiple stability important role detail domain attraction precise boundary domain attraction balance computational complexity efficiency stability investigate conservativeness stability reduce expense complex expression stability involves parameter reduce redundancy slack variable LMI stability investigate cohen grossberg neural network equilibrium positive nonnegative stability establish neural network important role biological competition cooperation stability hopfield neural network width depth stability research cohen grossberg neural network sufficient cohen grossberg neural network nonnegative equilibrium stability reaction diffusion stochastic environment impulse action investigate depth complexity internal external factor neural network feature incorporate exist network model internal elasticity connection spike external stochastic switch impulse factor neural network challenge stability stability recurrent neural network concerned focus isolated cohen grossberg recurrent neural network regular topology structure hopfield neural network cellular neural network recurrent neural network topology structure symmetrically asymmetrically network random symmetric asymmetric network stability network compose complex neural network stability synchronization consensus deeply investigate linkage failure pin cluster moreover complex fractional neural network regard extension neural network integer neural network investigate recent direction challenge topic conclusion summary stability recurrent neural network without delay achieve decade however future development accompany development mathematical theory apply mathematics computational mathematics stability criterion feasible cannot stability tackle stability exist recurrent neural network stability algebraic inequality lds matrix LMI advantage tradeoff computational complexity efficiency stability stability absolutely superior stability reflect aspect concerned recurrent neural network therefore expression stability promote development stability theory recurrent neural network