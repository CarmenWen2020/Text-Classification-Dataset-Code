target task label data unavailable domain adaptation transfer learner source domain previous domain adaptation mainly global domain shift align global source target distribution without relationship subdomains within category domain unsatisfying transfer performance without capture grain information recently researcher attention subdomain adaptation focus accurately align distribution relevant subdomains however adversarial loss function converge slowly subdomain adaptation network DSAN learns transfer network align relevant subdomain distribution domain specific layer activation across domain local maximum discrepancy LMMD DSAN effective adversarial training converges adaptation achieve easily feedforward network model extend LMMD loss efficiently via backpropagation demonstrate DSAN achieve remarkable recognition task digit classification task code available http github com  transfer introduction recent achieve impressive computer vision however usually amount label data network expensive  label data target task shortage label data motivation effective learner leverage label data related source domain however paradigm suffers shift data distribution across domain undermine generalization ability machine model discriminative model presence shift training data distribution domain adaptation transfer previous shallow domain adaptation bridge source target domain invariant feature  tions estimate instance importance without target label recent network transferable feature domain adaptation disentangle explanatory factor variation domain advantage achieve embed domain adaptation module pipeline feature extract domain invariant representation previous domain adaptation mainly global domain shift align global source target distribution without relationship subdomains domain subdomain contains sample within data source target domain confuse discriminative structure mixed loss grain information category intuitive global domain adaptation distribution domain approximately data subdomains classify accurately previous global domain adaptation hence global source target domain diverse scenario global domain adaptation lose grain information relevant subdomain adaptation exploit local affinity capture grain information category regard challenge global domain shift recently researcher attention subdomain adaptation semantic alignment conditional distribution local domain shift accurately align distribution relevant subdomains within category source target domain intuitive subdomain adaptation local distribution approximately global distribution approximately however adversarial loss function converge slowly comparison subdomain adaptation IV subdomain adaptation propose subdomain adaptation network DSAN align relevant subdomain distribution activation multiple domain specific layer across domain unsupervised domain adaptation DSAN extends feature representation ability adaptation network  align relevant subdomain distribution mention earlier improvement previous domain adaptation capability subdomain adaptation capture grain information category framework enable alignment local maximum discrepancy LMMD hilbert schmidt norm kernel embed empirical distribution relevant subdomains source target domain sample LMMD achieve feedforward network model efficiently standard backpropagation addition DSAN easy implement remarkable achieve adversarial recently DSAN  obtain remarkable standard domain adaptation recognition task digit classification task contribution article summarize propose novel neural network architecture subdomain adaptation extend ability  capture grain information category DSAN  achieve remarkable addition DSAN easy implement propose LMMD discrepancy kernel embed relevant subdomains source target domain successfully apply DSAN local distribution discrepancy  propose estimate discrepancy subdomain distribution II related introduce related aspect domain adaptation maximum discrepancy mmd subdomain adaptation domain adaptation recent witness approach visual domain adaptation commonly frame visual data bias previous shallow domain adaptation reweighting training data closely reflect distribution transformation dimensional manifold source target subspace closer recent network transferable feature domain adaptation disentangle explanatory factor variation domain advance achieve embed domain adaptation module pipeline feature extract domain invariant  tions approach identify literature statistic approach mmd central discrepancy cmd statistic commonly approach adversarial loss encourages sample domain  respect domain label domain adversarial net adaptation borrowing gan generally adversarial approach achieve performance statistic approach addition approach domain adversarial net adaptation DSAN mmd DSAN without adversarial loss achieve remarkable maximum discrepancy mmd adopt approach domain adaptation addition extension mmd conditional mmd joint mmd hilbert schmidt norm kernel embed empirical conditional joint distribution source target data respectively mmd alleviates bias assign specific source data however local mmd discrepancy kernel embed relevant subdomains source target domain sample  LMMD subdomain adaptation recently witness considerable research subdomain adaptation focus accurately align distribution relevant subdomains  domain adaptation MADA capture  structure enable grain alignment data distribution multiple domain discriminator semantic transfer network  learns semantic representation unlabeled target sample align label source centroid  target centroid CDAN adversarial adaptation model discriminative information conveyed classifier prediction DA construct multiple diverse feature aligns source target distribution individually encourage alignment regard prediction unlabeled target adversarial loss adopt however DSAN DSAN easy implement achieve performance without adversarial loss subdomain adaptation network unsupervised domain adaptation source domain xsi ysi nsi label sample ysi RC vector label xsi  xsi belonging target domain   unlabeled sample sample data distribution respectively goal domain adaptation neural network formally reduces shift distribution relevant subdomains domain learns transferable representation simultaneously target risk bound leverage source domain supervise data recent reveal network transferable representation traditional handcraft feature favorable transferability feature popular transfer mainly adaptation layer global domain adaptation loss jointly representation formal representation   xsi ysi sourcewhere entropy loss function classification loss domain adaptation loss tradeoff parameter domain adaptation loss classification loss mainly focus align global source target distribution without relationship subdomains within category domain derive global domain shift source target domain global distribution domain approximately adaptation however global alignment irrelevant data classify accurately actually exploit relationship subdomains domain align relevant subdomain distribution global distribution local distribution mention earlier therefore subdomain adaptation exploit relationship subdomains overcome limitation align global distribution source target domain multiple subdomains sample within relationship sample exploit sample within category relevant however data target domain unlabeled hence output network  target domain data detailed later accord category subdomains denotes label distribution respectively aim subdomain adaptation align distribution relevant subdomains sample label combine classification loss subdomain adaptation loss loss subdomain adaptation formulate   xsi ysi  sourcewhere mathematical expectation compute discrepancy relevant subdomain distribution mmd nonparametric propose LMMD estimate distribution discrepancy subdomains maximum discrepancy mmd kernel sample reject accepts null hypothesis sample mmd generate distribution identical statistic formally mmd defines difference source reproduce kernel  RKHS endow characteristic kernel denotes feature sample RKHS kernel inner vector theoretical DH estimate mmd distance empirical kernel embeddings   nsk xsi xsj  xti    xsi  sourcewhere unbiased estimator local maximum discrepancy nonparametric distance estimate distribution mmd widely apply discrepancy source target distribution previous mmd mainly focus alignment global distribution ignore relationship subdomains within category relationship relevant subdomains consideration important align distribution relevant subdomains within category source target domain desire align distribution relevant subdomains propose LMMD sourcewhere instance distribution respectively mmd focus discrepancy global distribution discrepancy local distribution minimize network distribution relevant subdomains within category drawn therefore grain information exploit domain adaptation assume sample belongs accord formulate unbiased estimator xsi  xsi    sourcewhere   denote xsi  belonging respectively nsi     sum category compute  sample    sourcewhere  entry vector sample source domain label ysi vector compute  sample however unsupervised adaptation target domain label data calculate directly  unavailable output neural network probability distribution characterizes probability assign target domain without label probability assign xti calculate  target sample finally calculate easy access label source domain target domain label predict prediction model label degrade performance hence probability prediction prediction alleviate negative impact  assumes sample LMMD whereas LMMD uncertainty target sample consideration adapt feature layer activation layer source domain label instance target domain unlabeled drawn independent identically distribute respectively network generate activation layer  nsi   addition cannot compute directly reformulate          sourcewhere layer activation equation adaptation loss directly LMMD achieve feedforward network model subdomain adaptation network LMMD propose DSAN previous global adaptation DSAN aligns global source target distribution aligns distribution relevant subdomains integrate feature feature adaptation model reduce discrepancy relevant subdomain distribution activation layer LMMD domain specific layer subdomain adaptation loss equation   xsi ysi SourceSince training cnns amount label data prohibitive domain adaptation application cnn model pretrained imagenet data tune training DSAN mainly standard minibatch stochastic gradient descent sgd algorithm worth DSAN iteration label target sample usually becomes accurate EM  refinement procedure empirically effective architecture DSAN DSAN formally reduce discrepancy relevant subdomain distribution activation layer LMMD minimization LMMD module input activation zsl  truth label predict label remark theory domain adaptation suggests distance distribution discrepancy source risk bound target risk proxy distance define generalization error classifier kernel svm binary discriminate source target distance focus global distribution discrepancy hence propose AL distance estimate subdomain distribution discrepancy define DAC generalization error classifier domain define  DAC denotes mathematical expectation denotes probability target domain theoretical analysis analysis effectiveness classifier prediction target sample theory domain adaptation theorem hypothesis domain RT RS  sourcewhere RS RT error source sample target sample respectively RS minimize easily source label information besides  domain divergence discrepancy distance distribution actually approach minimize  adversarial mmd coral loss negligibly usually disregard previous however tends domain category alignment explicitly enforce hence bound unfortunately cannot directly without target label therefore utilize  approximate evaluation minimization definition define  HRS RT sourcewhere label function source target domain respectively DSAN optimize upper bound label function sourcethen  HRS RT  HRS RT RT  HRS RT RT RT sourcewhere  function target domain RS RT denotes disagreement source label function source target sample respectively label source sample gap RT denotes discrepancy ideal target label function  function minimize proceeds focus RT typically loss function source sample predict label source label function feature target sample source feature target sample predict  label function therefore distribution subdomains domain RT summary align relevant subdomain distribution DSAN minimize loss hence utilize prediction target sample effective unsupervised domain adaptation IV evaluate DSAN competitive transfer baseline recognition digit classification data ImageCLEF DA  recognition task digit classification construct transfer task mnist usps SVHN denote transfer task source domain target domain setup ImageCLEF DA benchmark data ImageCLEF domain adaptation challenge organize category public data domain caltech imagenet ILSVRC pascal voc image category image domain domain combination transfer task benchmark data domain adaptation comprise image distinct domain amazon contains image amazon com webcam DSLR image web camera digital slr camera  setting respectively enable unbiased evaluation evaluate transfer task data consists image ImageCLEF DA consists image domain artistic image clip image image domain data contains image category setting similarly domain combination construct transfer task  challenge simulation data distinct domain synthetic rendering model angle lightning image contains image across training validation domain mnist usps SVHN explore digit data mnist usps SVHN transfer digit classification mnist contains digit image usps contains digit SVHN contains digit image digit image conduct transfer task mnist usps usps mnist SVHN mnist baseline ImageCLEF DA model DSAN standard transfer convolutional neural network resnet domain confusion DDC dan coral coral domain adversarial neural network  residual transfer network rtn adversarial discriminative domain adaptation ADDA joint adaptation network  MADA collaborative adversarial network  generate adapt GTA conditional adversarial domain adaptation CDAN CDAN DSAN resnet dan DANN jan CDAN baseline extract  DSAN resnet DANN dan jan  baseline extract mnist usps SVHN DSAN  reconstruction classification network  couple generative adversarial network  ADDA unsupervised image image translation network asymmetric  domain adaptation  GTA   DANN DRCN  ADDA GTA extract refer article implementation detail recognition task employ resnet CDAN bottleneck layer fcb average pool layer transfer representation output fcb input LMMD easy LMMD multiple layer LMMD layer image random flip adopt jan comparison baseline architecture  resnet whereas resnet others tune convolutional pool layer imagenet pretrained model classifier layer via propagation classifier scratch rate layer digit classification task protocol ADDA architecture ADDA task minibatch sgd momentum rate anneal strategy  rate grid due computational adjust sgd formula training progress linearly suppress noisy activation stage training instead fix adaptation factor gradually progressive schedule exp fix throughout implement DSAN pytorch report average classification accuracy standard error random trial mmd DSAN adopt gaussian kernel bandwidth median pairwise distance training data recognition classification ImageCLEF DA  respectively IV DSAN outperforms transfer task DSAN substantially improves average accuracy margin image   encourage importance subdomain adaptation DSAN transferable representation accuracy ImageCLEF DA unsupervised domain adaptation resnet II accuracy unsupervised domain adaptation resnet accuracy unsupervised domain adaptation resnet IV accuracy  unsupervised domain adaptation resnet experimental reveal insightful observation standard domain adaptation subdomain adaptation MADA CDAN DSAN outperform previous global domain adaptation improvement previous global domain adaptation subdomain adaptation crucial domain adaptation previous align global distribution without relationship subdomains whereas DSAN accurately aligns relevant subdomain distribution capture grain information category DSAN recent subdomain adaptation DSAN achieves performance verifies effectiveness model DSAN  DSAN largely improves average performance recognition task jan DSAN LMMD dan mmd jan  DSAN achieves performance implies LMMD suitable align distribution mmd  digit classification classification task mnist usps SVHN DRCN baseline adversarial DSAN largely outperforms baseline SVHN mnist task DSAN  subdomain adaptation DSAN achieves average accuracy stable standard error accuracy digit recognition task unsupervised domain adaptation task overall abovementioned demonstrate effectiveness propose model analysis feature visualization visualize network activation task jan DSAN gaussian kernel sne embeddings source sample target sample jan typical statistic approach  source target domain align classify contrast representation DSAN LMMD source target domain align subdomains domain subdomains disperse suggests model DSAN capture grain information category jan LMMD effective  align distribution visualization representation sne jan DSAN task respectively source sample target sample distance AL distance task mmd LMMD task distribution discrepancy distance AL distance mention global distribution discrepancy subdomain distribution discrepancy  task representation cnn jan DSAN  DSAN cnn jan DSAN domain gap relevant subdomains effectively mmd discrepancy global distribution whereas LMMD discrepancy local subdomain distribution compute mmd LMMD across domain task cnn jan DSAN feature pool layer truth label mmd LMMD DSAN activation cnn jan activation validates DSAN successfully reduces discrepancy global local distribution addition LMMD mmd LMMD estimate distribution discrepancy eliminate irrelevant data convergence testify convergence CDAN CDAN DSAN error task iteration DSAN achieves faster convergence CDAN CDAN DSAN converges faster besides reveal iteration DSAN faster CDAN CDAN task analyze convergence convergence iteration convergence discussion advantage DSAN overview DSAN adversarial subdomain adaptation VI insightful observation adversarial subdomain adaptation usually loss function DSAN classification loss LMMD loss addition DSAN hyperparameter whereas  DA hyperparameters DSAN loss hyperparameter indicates easy implementation DSAN MADA CDAN DSAN converge DSAN achieves performance DSAN achieves accuracy CDAN recent subdomain adaptation overall validate advantage model DSAN VI comparison subdomain adaptation MADA parameter hyperparameters average convergence ImageCLEF DA data geforce gtx gpu accuracy average accuracy ImageCLEF DA data dose article conclusion unlike previous align global source target distribution subdomain adaptation accurately align distribution relevant subdomains within category source target domain however recent subdomain adaptation adversarial approach loss function converge slowly propose DSAN  easy implement furthermore discrepancy relevant subdomains within category domain propose local distribution discrepancy LMMD extensive conduct recognition digit classification task demonstrate effectiveness propose model