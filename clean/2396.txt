article address underactuated unmanned vessel USVs formation via modify reinforcement random brake DRLRB formation model reinforcement DRL construct urge USVs preset formation specifically efficient reward function perspective velocity error distance USV related formation novel random brake mechanism formulate prevent training decision network local optimum fail achieve training objective virtual leader guidance developed USV formation wherein aid DRLRB propose adjust formation automatically flexibly USVs deviate formation simulation verifies effectiveness superiority formation strategy publish transaction neural network volume issue dec date publication april  information pubmed ID doi  publisher funding agency introduction decade generous achievement emerge application domain unmanned vessel USV meanwhile undertake arduous task underactuated USVs jointly accomplish mission rescue reconnaissance data collection etc abovementioned task effectively foremost multiple underactuated USV issue fundamental issue USV refer multiple USVs formation purpose guarantee USVs formation navigate predetermine focus effective formation multiple underactuated USVs excellent multiple USV formation decentralize leader follower formation fully actuate USVs address USV reference trajectory prescribed performance constraint controller underactuated reference combine controller variable synchronization coordination cooperative autonomous underwater vehicle AUVs report worth abovementioned approach dedicate individual reference vehicle however refer USV practical engineering application impossible conceive complex controller achieve vehicle complicate virtual target employ resolve USV formation virtual target strategy guidance structure  coordination coordination algorithm propose issue virtual reference target utilized multiple  mobile robot formation suppose leader treat target leader follower error model built multiple vehicle formation formation convert localization approach consensus  particle filter algorithm propose eliminate accumulate error multi auv information exchange leader follower virtual leader introduce achieve multiple autonomous vehicle vehicle along parameterized refer formation underactuated vessel partially input function leader follower strategy adopt advanced technique fix formation attention paid dynamic formation transformation literature breakthrough machine algorithm DL reinforcement RL combination RL DRL utilized resolve underactuated USV formation overcome usability concise DRL algorithm network propose obstacle avoidance formation collision avoidance vehicle leader follower structure address via DRL stage training framework imitation RL memory network transfer training approach adopt refer improve DRL USV outstanding contribution propose controller USV DRL controller capability  robot generalize integral approach introduce ensure reliable training convergence novel parameterization lyapunov technique introduce practical application deterministic policy gradient DDPG model reward DRL algorithm apply USV planning usability complicate traditional adaptive neuro fuzzy pid controller twin delayed DDPG neural network embed fuzzy pid controller structure combination fuzzy pid controller DRL reduces training difficulty neural network enable automatically optimize parameter controller meaningful algorithm deduce machine excellent positive reference multiple USV formation inspire abovementioned observation article aim resolve multiple underactuated USVs employ DRL algorithm highlight DDPG strategy DRL random brake DRLRB introduce multiple USV formation cope failure USVs emergency dispatch USVs quit formation dynamically novel random brake mechanism training DDPG excellent performance formation finally simulation validate effectiveness multiple underactuated USVs DRLRB remainder article organize II formulates USV formulation detail DRLRB cooperative IV illustrative simulation multiple USV formulation DRLRB concludes article II formulation USV model dimensional euclid euclidean norm  USV formation suppose exists USV USVs USV mechanical structure model          sourcewhere xci   vector  fix inertial frame  xci    angle velocity vector  fix frame  linear velocity angular velocity surge sway yaw direction respectively  rotation matrix fix frame fix frame mti inertia matrix denote coriolis  matrix damp matrix unmodeled dynamic respectively   input  USV model USV formation refer multiple USV formation virtual leader introduce calibrate reference USV formation formation USVs    formation virtual leader    pvm   pcm   error preset projection preset  coordinate frame virtual leader axis along tangent direction preset            source cooperation schematic USVs assume USVs formation error actual formation formation     source guarantee multiple USVs formation preset virtual leader along parameterized preset successfully purpose input utilized USVs decrease error USV formation preset error USV formation preset source suppose USVs directly consequently objective multiple USV formation limt limt source evident virtual leader critical multiple USVs formation illustrates update strategy virtual leader central formation dynamically projection preset correspondingly strategy multiple USVs formation virtual leader preset distance update virtual leader related error accordingly guarantee formation virtual leader update continuously movement USV formation virtual leader relative angle distance easy obtain USVs formation formation update DRLRB USVs navigate formation USV formation model DRLRB fulfill USV formation DRLRB propose combine random brake mechanism training representation action introduce reward function USV formation training objective training model summarize model training strategy virtual leader realize USV formation DRL structure USV model DDPG multiple USVs formation training model interact environment iteratively observation environment USVs reasonable decision combine task objective observation action selection multiple underactuated USVs formation model evaluate accord evaluation multiple underactuated USVs formation model finally model perform action correspond update environment regain observation till model action ultimately model ideal decision multiple USVs formation USV formation model DDPG refer DRL model exploration unknown environment concerned decision network output action USV USV transform perform action simulation USVs concatenate USVs obtain reward behavior USV data pool data training data utilize training data USV formation model iteratively pool USV navigation data involve interaction action decision network correspond reward pool constitute training data environment exploration collection training data decision network multiple USVs formation training decision network environment explore USVs jointly evident USV explore initial repetition rate exploration reduce essence explore faster multiple USVs training data pool accumulate faster multiple USVs employ decision network consistency behavior multiple USVs formation guaranteed worth USV formation model cooperation USVs formation training environment explore cooperatively USVs formation training multi USVs formation meanwhile exploration USVs formation pool training data sample pool consequently propose DRLRB suitable multi USVs formation theory USV formation limited however reality indispensable efficiency algorithm execution hardware performance representation action elucidate aid multiple underactuated USV formation model decision USVs accord observation wherein observation relation USV environment USVs worth representation pivotal performance propose formation model probe multiple underactuated USVs formation task multiple underactuated USVs formation refer USV formation factor impact standard USV relation USVs virtual leader USVs USVs characterize xci   velocity virtual leader indispensable calculate xvi  USVs performance USV formation relation USV formation preset characterize error consequently observation USVs described      USV issue address separately attribute individual USV article multi USVs formation performs constraint planning phase phase refer USV format consumption related factor  displacement determinant article consideration specification USVs formation formation transformation correspondingly USVs exhaust USVs withdraw formation autonomously USV formation  dynamically mechanism dilemma arise reasonably consumption mainly related parameter  displacement article  displacement USVs formation within observation consumption calculate achieve indirectly  reflect formation model utilize neural decision network observation input correspond decision action    trust surge direction  yaw   affect surge velocity  respectively account refer underactuated USV trust sway direction leak noteworthy decision action distribute continuous reward scheme significant employ reward function refer USV formation mission USVs quickly navigate correspond reference coordinate urge USVs quickly establish formation velocity USVs embody reward function reward function reference USV maximize lateral deviation minimize   source training maximum reward USV navigate increase USV farther farther away reference coordinate consequently formation model extremely adverse local optimal avoid situation indispensable distance USV reference coordinate stress reward function  max source reward function   sourcewhere factor distance respectively accordingly trial error mechanism training DDPG   OU introduce DDPG explore environment OU disturb action USV formation model USVs perform random action random action unknown environment observation discover suppose stochastic brownian OU dat  source essence OU regression random decision network decision correspond output action action ano brake wherein generate OU remark reward function utilized formation model USV reference coordinate maximum evident maintain maximum reward obtain however USV cannot ability USV reference coordinate reference target maximum consequently owe existence phenomenon USV unable reference coordinate accurately cannot meanwhile brake action action directly brake action due reduction USV reward therefore significant USV formation model brake action constant brake action generate adverse data training prone local optimal situation consequently random brake strategy propose model training shortcoming dissolve effectively random brake introduce decision network action selection employ random brake mechanism USV accelerate quickly away reference coordinate brake properly reference coordinate action selection DRLRB model random brake mechanism objective algorithm propose USV formation model aim policy purpose actor network approximate policy actor network update gradient descent gradient   sourcewhere probability distribution  network training mini batch usually sample randomly training data descent    source mini batch parameter target critic network suppose concatenate vector action vector refer target critic TC sourcewhich update optimize loss equation sourcewhere parameter online critic network refers action action policy reward parameter online critic network update stochastic gradient descent correspond gradient source consequently employ DDPG DRLRB algorithm algorithm DRLRB input velocity vector vector episode episode replay memory batch rate decision network update target network output parameter network initialize online critic network online actor network initialize target critic network target actor network initialize pool initialize random exploration random brake respectively reset initial action accord policy exploration action accord brake probability execute action obtain reward transition sample random mini batch transition episode terminates update critic minimize loss update actor policy sample policy gradient accord update target network  USV formation within DRLRB algorithm training USV formation model DDPG algorithm USV formation model combine strategy formation task observation obtain accord action decision utilized generate command USV actuator DRLRB USV actuator executes command accordingly formation error USV obtain judging USV formation till USV formation consequently error USV formation calculate virtual leader update accord USV formation task fulfil eventually USV formation remark suppose USV communicate USV directly indirectly benefit superior formation strategy USV formation dynamically cope adjustment formation fault USVs cycle USV performs environmental awareness decision action execution sequentially refer environmental awareness status USVs USV formation accord virtual leader reference USV formation update exists USV fails formation DRLRB formation reorganize realize dynamic transformation formation IV simulation simulation parameter employ DRLRB series simulation multiple underactuated USV formation perform suppose action input DRLRB algorithm parameterized vector sample detail parameter detail parameter simulation discount factor regulate capacity pool batch update delay actor network critic network respectively defer update target network preset polygon source preset curve source analysis validate effectiveness DRLRB algorithm  simulation USV formation aspect formation formation polygonal curvilinear formation transformation formation progress USVs USVs direction virtual leader formation USVs respectively almost formation USVs reduce aid DRLRB furthermore formation error USV gradually decrease finally formation verifies formation USVs successfully DRLRB progress formation USVs trajectory formation polygonal variation formation variation formation formation error variation curve formation polygonal simulation USVs formation preset formation USVs random brake mechanism training without random brake mechanism trajectory USVs formation formation remains intact trace however random brake mechanism training USV preset trajectory virtual leader trajectory formation maintain perfect consistency angle curve USVs comparison algorithm brake mechanism reflect variation brake mechanism exist frequent fluctuation USVs brake capacity USVs navigate brake mechanism curve smooth regular benefit brake mechanism USVs navigate obvious USVs random brake mechanism regular irregular USVs without random brake mechanism meanwhile benefit random brake mechanism increase premise ensure curve illustrate USVs navigate stable brake mechanism vibrate  smoothly regularly indicates USVs navigate stably safely DRLRB maintain formation angle USVs adjust dynamically steady ensures navigation safety USVs multi USVs formation article significant polygonal polygonal formation USVs brake trajectory formation polygonal trajectory formation variation formation polygonal variation formation polygonal polygonal formation USVs without brake trajectory formation polygonal trajectory formation variation formation polygonal variation formation polygonal sake enhance persuasion USV formation complex simulation curvilinear trajectory USVs random brake mechanism smoother without random brake mechanism  preset trajectory virtual leader trajectory formation maintain excellent consistency curve USVs USVs random brake mechanism regular irregular USVs without random brake mechanism meanwhile benefit random brake mechanism increase premise ensure angle curve USVs adjust dynamically steady ensures navigation safety USVs curvilinear formation USVs brake trajectory formation curvilinear trajectory formation variation formation curvilinear variation formation curvilinear curvilinear formation USVs without brake trajectory formation curvilinear trajectory formation variation formation curvilinear variation formation curvilinear addition multi USV formation article dynamically adjust formation article simulation transform formation USVs USVs trajectory USVs USVs formation around USV USV exit formation USVs regroup task preset trajectory virtual leader trajectory formation maintain perfect consistency formation formation away preset formation transformation formation return preset dynamic formation transformation function multi USV formation article ensure USV formation abnormal formation transformation easy implement DRLRB USV formation navigates narrow linear formation adaptable pas narrow curvilinear USV formation USVs USVs trajectory formation transform USVs trajectory formation error simulation polygonal curvilinear formation transformation polygonal error fluctuates USV formation polygonal navigation direction virtual leader USV  curvilinear error tends curve fluctuates due curvature simulation formation transformation error due formation transformation error error polygonal curvilinear curvilinear error simulation polygonal curvilinear curvilinear without random brake mechanism error USVs random brake mechanism smoother stable prof multi USV formation random brake mechanism article excellent error polygonal curvilinear curvilinear without brake conclusion resolve USV formation propose algorithm DRLRB refer DRLRB model virtual leader follower formation strategy integrate achieve USV formation DDPG framework reward function formation smartly realize rapid format random brake mechanism incorporate USV simulation validates effectiveness DRLRB model algorithm adverse USVs fail formation formation transformation fulfil USV formation issue successfully future significant develop application USV formation employ DRLRB model