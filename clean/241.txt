article novel cnn rnn approach exploit multiple cnn feature dimensional emotion recognition utilize gradual emotion omg emotion dataset approach pre training relevant aff aff emotion database mid feature extract cnn component exploit rnn subnets multi task framework output constitute intermediate prediction estimate obtain median prediction fusion network examine boost obtain performance decision model latter rnn fusion approach although visual modality outperform utilized audio visual modality development submit omg emotion challenge rank technology visual information valence estimation rank overall extensive experimentation arousal estimation greatly improve feature combine introduction automatic analysis facial behaviour cornerstone application computer robot interaction pervasive compute ambient intelligence virtual reality research facial behaviour analysis recognition universal expression disgust sad plus neutral influence seminal ekman recognition spontaneous expression mental pain intensity compound expression detection facial action AU estimation intensity accord facial action cod standardise taxonomy facial muscle movement detection micro expression estimation facial affect continuous dimensional valence arousal related research assist flag complex behavioral deception depression autism spectrum disorder schizophrenia focus dimensional emotion model appropriate extreme subtle emotion everyday computer interaction accord dimensional approach affective behavior described latent continuous dimension commonly dimension valence positive negative emotional arousal emotion activation valence arousal relate readily specific function brain parietal hemisphere role mediation arousal whereas frontal role emotional valence dimension tension introduce exclude due difficulty consistently identify dimension describes tension  dominance valence arousal introduce estimation valence arousal continuous related affect constitutes examine valence arousal valence arousal facilitate research database generate annotate data annotation scarce hence research rely extract highly engineer handcraft feature hoc strategy naturally amount data annotation research  data intensive technology widely accepted computer vision machine community progress application domain significantly  datasets unconstrained refer data hence facial analysis focus spontaneous behavior behavior capture unconstrained dimensional database generate audiovisual omg emotion dataset aff aff SEWA AffectNet static image regard pipeline facial behavior analysis standard paradigm detect image sequence detect facial landmark extract handcraft feature around landmark feature landmark classification regression affective label recently paradigm shift utilize handcraft feature utilize feature convolutional neural network cnns recurrent neural network rnns shift motivate strike performance achieve utilize neural network dnns variety emotion recognition task address issue estimate valence arousal utilize gradual emotion dataset omg emotion dataset visual information novel neural architecture performance valence arousal estimation submission omg emotion challenge ranked valence estimation contribution development cnn plus multi rnn architecture valence arousal estimation multi task optimization formulation formulation mid feature extract layer cnn input rnn intuition feature information advantageous task architecture feature extract cnn layer concatenate input rnn whereas rnns experimental latter outperform developed architecture network visual audio modality deviate others standard cnn rnn network output cnn rnn apply ensemble methodology feature extract cnn network feature multiple layer network fuse facial image landmark apply procrustes analysis input architecture additionally ensemble formulation propose fusion model decision propose architecture formulation boost obtain performance model fusion proposal perform fusion rnn instead typical fully layer another contribution approach developed architecture omg emotion dataset characteristic dataset annotation utterance split utterance sequence individually architecture median predict valence arousal compute per sequence median average utterance valence arousal estimate procedure deviate related uniformly randomly sample constant frame utterance assign annotation utterance compute prediction per frame additional contribution pre training propose architecture emotionally aff database extension aff network pre task valence arousal estimation task recognition detection pre training specific database developed architecture ability effectively capture dynamic omg emotion dataset performance finding approach feature combine cnn plus multi rnn architecture boost network performance arousal estimation cnn plus multi rnn architecture outperform standard cnn plus rnn feature extract previous layer useful information valence arousal prediction obtain feature extract previous layer independent rnns instead concatenate fed rnn obtain rnn instead fully layer model fusion visual modality network performance valence estimation correspond arousal estimation organize review related exist facial expression recognition emphasis dimensional model affect brief description database omg emotion dataset aff aff database pre processing essential obtain input representation analysis developed novel neural architecture ensemble fusion network valence arousal estimation describes specific implementation detail achieve evaluation approach analyse obtain comparison achieve performance finally conclusion related architecture valence arousal estimation propose frame cnn cnn plus rnn architecture propose cnn consist convolutional layer layer max pool layer quadrant pool layer fully layer output layer cnn plus rnn architecture consist previously described cnn network fix without regression layer rnn layer estimate methodology achieve valence arousal correlation recola database author explore fuse craft feature available modality acoustic visual textual interlocutor influence influence interact partner behavior acoustic feature detail author extract acoustic modality craft feature MFCCs  jitter shimmer feature  visual modality feature vgg densenet pre fer dataset annotate expression textual modality vector feature feature fuse input lstm network estimate valence arousal  approach avec challenge utilized SEWA database author  net framework core layer attribute layer AU layer valence arousal layer sequentially core layer series convolutional layer attribute layer extract facial feature eyebrow layer supervise AUs finally AUs employ mid representation estimate intensity valence arousal methodology affect challenge challenge estimation valence arousal aff database recognition affect aff database obtain author author perform training cnn cnn rnn network aff emotion recognition perform network  consists convolutional pool resnet network fully layer layer gru output layer valence arousal estimate network tune recola  VA database performance summary performance described respective database algorithm valence arousal estimation performance utilized database algorithm valence arousal estimation performance utilized database utilized dimensional emotion database description aff extension aff database pre developed neural network architecture omg emotion database analysis target aff database aff database capture database annotate expert regard valence arousal consists video display reaction video duration frame database regard gender male female aff database benchmark aff challenge organize conjunction  aim database spontaneous facial behavior arbitrary video youtube keyword retrieve video reaction aff database aff database recently augment youtube video aff database database basis  competition aim extend spontaneous facial behavior arbitrary met aff whilst significantly increase additional video annotate expert elderly ethnicity caucasian hispanic latino asian african american profession actor athlete politician journalist illumination occlusion emotion aff consists video frame video display annotate male female omg emotion dataset gradual emotional behavior dataset omg emotion dataset contains video youtube emotion expression emerge develop  scenario frame dataset various display emotion occasion circumstance dataset annotate valence arousal contains identity sample image omg emotion dataset display various emotion sample image omg emotion dataset display various emotion omg emotion dataset benchmark gradual emotion recognition omg emotion challenge jointly session neural model behavior recognition   dataset split training validation independent manner meaning strictly training consists video compose utterance validation consists video compose utterance consists video compose utterance utterance average video average around annotate data amazon mechanical turk average independent annotation per utterance annotator contextual information video annotate dataset annotator consideration visual audio information context video spoken previous utterance context clip annotation manner annotation multimodal information utterance specific valence arousal standard annotation valence annotation whereas arousal histogram annotation omg emotion training validation respectively correspond datasets annotation distribution histogram distribution valence arousal utterance annotation training validation omg emotion histogram distribution valence arousal utterance annotation training validation omg emotion additionally dataset contains categorical annotation utterance transcript spoken video pre processing detection alignment image resize normalization data pre processing consists processing extraction meaningful feature data detection alignment image resize image normalization extract bound video frame deformable model DPM detector  proven highly efficient accurate detection alignment extract facial landmark implement generalize procrustes analysis implementation facial landmark detector inside  library facial landmark frame reference rigid anchor correspond location prototypical frontal frame facial landmark correspond location facial component perform procrustes transformation eliminates rotation isotropic translation coordinate landmark coordinate landmark frontal impose transformation frame perform alignment cropped align image resize pixel resolution intensity normalize image along facial landmark input training network described developed architecture propose framework dimensional emotion recognition cnn standard cnn plus rnn propose cnn plus multi rnn architecture ensemble methodology fusion architecture uni task approach independently valence arousal multi task approach latter performance estimation affective dimension agreement exist inter correlation valence arousal emotion dimension relation emotion dimension isolation without feature related research psychology focus multi task cnn architecture network vgg resnet densenet network pre aff aff database omg emotion training structure network account procedure annotate omg emotion dataset accord utterance label valence arousal split utterance sequence consist consecutive frame assign sequence frame label correspond utterance training cnn network perform detail cnn input sequence predict frame sequence respective valence arousal facial landmark per frame input sequence additional input cnn network valence arousal prediction compute median approach per frame valence arousal sequence developed cnn structure valence arousal estimate per input sequence consecutive frame cnn component vgg resnet densenet network landmark concatenate extract feature pool layer cnn component fully layer precedes output layer cnn structure vgg resnet densenet vgg cnn landmark concatenate output pool layer network input fully layer consist output landmark mapped feature perform prediction resnet densenet landmark concatenate average pool feature resnet densenet network input fully layer consist layer output layer estimate valence arousal standard cnn plus rnn architecture contextual information data specifically temporal dependency facial expression utterance standard cnn plus rnn architecture cnn rnn architecture developed experimental architecture output cnn pool layer fed fully layer output constitutes input rnn layer architecture pre aff aff database strategy training architecture cnn fix training remain architecture fully layer rnns training architecture manner jointly training cnn rnn latter approach   perform network aff database omg emotion database  cnn rnn network consist convolutional pool resnet fully layer layer gru layer architecture landmark concatenate average pool feature resnet fed input fully layer consist similarly cnn described previous subsection cnn rnn network receives input sequence frame predicts frame valence arousal finally computes median estimate architecture replaces cnn network cnn rnn   architecture densenet rnn densenet rnn structure  described previous subsection difference densenet network convolutional pool layer cnn plus multi rnn network feature extract cnn layer information whilst feature highly specific characteristic specific account developed cnn plus multi rnn network network extract mid feature layer cnn pas rnns network split methodology refer cnn rnn concatenates extract feature cnn layer rnn whereas refer cnn rnn independently rnn subnets mention network cnn rnn extract feature cnn layer pas independently rnns cnn rnn FC similarly output rnns concatenate fully layer mapped feature perform prediction cnn rnn extract feature cnn layer concatenate passing input rnn cnn rnn FC output rnns concatenate fully layer perform prediction architecture performance around percent performance cnn rnn cnn rnn network cnn rnn network cnn rnn network convolutional pool layer vgg fully layer facial landmark concatenate feature extract pool layer vgg fully layer mid feature extract layer gru network predicts valence arousal gru layer comprises similarly architecture described cnn rnn network input sequence frame correspond landmark frame predict frame valence arousal median constitute estimate cnn rnn network cnn rnn pool pool network feature extract fully layer input rnn network denote rnn feature extract pool layer concatenate landmark input rnn network denote rnn feature extract pool layer fourth convolutional layer input another rnn network denote rnn depicts structure afore mention  network network structure layer gru network layer output rnns concatenate output layer performs valence arousal prediction experimental network feature extract specific layer network cnn rnn pool pool valence arousal estimate per input sequence consecutive frame landmark concatenate feature pool layer input layer architecture structure rnn network cnn rnn architecture displayed structure rnn network cnn rnn architecture displayed cnn rnn network cnn rnn network consist convolutional pool layer vgg fully layer facial landmark concatenate feature extract pool layer vgg fully layer mid feature extract concatenate layer gru network predicts valence arousal gru layer comprises similarly architecture described cnn rnn network input sequence frame correspond landmark frame predict frame valence arousal median estimate cnn rnn network cnn rnn pool pool network feature extract pool layer fourth convolutional pool layer convolutional concatenate landmark fully layer concatenate rnn experimental network feature extract specific layer network cnn rnn pool pool architecture valence arousal estimate per input sequence consecutive frame landmark concatenate feature pool layer input layer cnn rnn pool pool architecture valence arousal estimate per input sequence consecutive frame landmark concatenate feature pool layer input layer ensemble methodology subsection ensemble approach fuse developed network model decision model fusion concatenate feature extract network whilst decision fusion average prediction network model fusion advantage mutual information data average procedure decision fusion reduces variance ensemble regressor achieve robustness preserve relative importance individual model model fusion cnn rnns cnn rnns described previous subsection concatenate output rnns network input another rnn layer gru fully layer output layer denote network model fusion rnn model fusion FC respectively similarly previous subsection frame input sequence frame model fusion network predicts valence arousal computes median estimate decision fusion cnn rnns cnn rnns described valence arousal estimate     compute average valence arousal estimate   network proportional correspond network performance validation     SourceRight click MathML additional feature valence arousal  concordance correlation coefficient valence arousal compute validation denote cnn rnns cnn rnns evaluation criterion omg emotion challenge define  SourceRight click MathML additional feature variance valence arousal label predict respectively correspond covariance network training detail information regard parameter developed architecture rate dropout probability batch sequence loss function formulate series processing apply obtain estimate valence arousal implementation detail developed cnn cnn plus rnn cnn plus multi rnn architecture dropout probability apply fully layer convolutional pool layer cnn network vgg resnet densenet additionally dropout probability apply gru layer rnns training cnn network sequence frame cnn plus rnn cnn plus multi rnn batch sequence consecutive frame training cnn architecture rate chosen training cnn plus rnn architecture rate training respective cnn fix network tensorflow quadro GV volta gpu training objective function evaluation criterion omg emotion challenge loss function criterion define  SourceRight click MathML additional feature arousal valence processing finally investigate chain processing apply median filter per frame prediction within sequence smooth per utterance prediction consist frame processing improvement validation apply configuration partition experimental conduct obtain estimate median per frame valence arousal estimate within sequence development dnns training evaluate respective validation network accord validation performance significant difference training dnn multiple average prediction fold validation examine encode landmark cnn feature fuse landmark fully layer fuse output feature extract cnn however significant difference performance although developed architecture complex learnable parameter cnn rnn component analysis performance developed cnn standard cnn plus rnn cnn plus multi rnn ensemble architecture pre aff database without processing described network vgg achieve performance resnet  network vgg network pre dataset recognition therefore construction filter already establish comparison resnet  pre additionally pre training aff tune filter attain vgg evaluation omg valence arousal prediction developed cnn cnn plus rnn cnn plus multi rnn ensemble architecture evaluation omg valence arousal prediction developed cnn cnn plus rnn cnn plus multi rnn ensemble architecture additionally  densenet rnn network achieve performance cnn network former network standard cnn plus rnns rnn model contextual information data account temporal variation performance cnn rnn pool pool cnn rnn pool pool exhibit improve performance percent average cnn plus rnn architecture validates  cnn feature useful information task additionally cnn rnn pool pool outperform cnn rnn pool pool exploit feature variation via rnns independently concatenate concatenate rnn validates ensemble methodology network network feature fuse exploit representation information model fusion superior performance decision feature network concatenate richer information raw data decision model fusion concatenate feature pas rnn ensemble optimize concatenation feature overall moreover model fusion performance achieve rnn instead fully layer fusion processing achieve performance mainly valence estimation median filter valence sequence whereas arousal arousal increase performance decrease observation performance network arousal performance valence visual modality training network arousal audio cue discriminate capability facial feature correlation coefficient conclusion confirms previous finding performance perform network processing network scratch pre aff aff database comparison aff database due emotion diversity boost performance network pre comparison performance network directly omg emotion pre network aff database overall network pre aff achieve performance comparison network pre aff database evaluation omg valence arousal prediction various network scratch pre aff aff database evaluation omg valence arousal prediction various network scratch pre aff aff database cnn rnn cnn rnn architecture performance acquire latter ablation extract cnn mid feature cnn rnn network performance performance network combination mid feature extract whereas performance network mid feature extract performance network obtain feature extract mid cnn convolutional layer generally performance obtain feature extract optimal combination performance cnn rnn pool pool observation feature convolutional layer combine significantly affected performance predict valence arousal omg feature layer cnn rnn omg feature layer cnn rnn ablation landmark additional input various network performance cnn rnn pool pool cnn rnn pool pool model fusion rnn network landmark additional input landmark increase performance percent omg landmark additional input various network omg landmark additional input various network finally insight performance cnn rnn cnn rnn pool pool analyze performance 2D valence arousal obtain valence arousal performance error mse across obtain arousal positive valence however obtain mse away mse across 2D valence arousal valence arousal mse 2D VA cnn rnn valence arousal mse 2D VA cnn rnn submission omg emotion challenge omg emotion challenge submission submit cnn rnn cnn rnn conv pool pre aff model prediction without processing submission processing median filter submission II median filter smooth submission detail regard submission comparison performance network performance submit omg emotion challenge author developed VNet  model VNet  network blstm temporal pool output layer  vgg network average pool accepts input STFT extract audio fusion feature extract VNet temporal pool  average pool layer concatenate output layer author developed model model denote openSMILE lstms feature extract audio openSMILE layer lstms predict valence arousal prediction average model denote vgg blstm visual modality frame utterance fix pre vgg layer blstm valence prediction author developed ensemble network consist model model denote multi modal acoustic feature extract  visual feature extract fix pre vgg layer lstm attention mechanism visual acoustic feature svm perform prediction model extract visual acoustic feature extract acoustic feature  feature svm perform prediction fusion afore mention model denote ensemble prediction sum model prediction model vgg layer lstm attention mechanism input visual data fusion developed model denote ensemble II prediction sum model prediction model fusion rnn outperforms audio modality valence arousal estimation cnn rnn pool pool outperform network regardless additionally audio modality multi modal outperform average however network audio modality audio contribute arousal estimation difference justified ensemble II fusion network visual audio modality difference performance evaluation omg VA prediction perform network versus evaluation omg VA prediction perform network versus conclusion development novel architecture predict valence arousal utilize omg emotion dataset propose approach visual information achieve performance omg emotion developed network feature extract mid cnn layer concatenate fed rnn rnn subnets concatenate moreover ensemble approach propose model fusion rnn developed network pre aff aff database