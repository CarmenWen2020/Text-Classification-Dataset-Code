rapid progress significant spectrum application apply safety critical environment however neural network dnns recently vulnerable input sample adversarial adversarial perturbation imperceptible easily fool dnns deploy stage vulnerability adversarial becomes risk apply dnns safety critical environment therefore attack defense adversarial attention review recent finding adversarial dnns summarize generate adversarial propose taxonomy taxonomy application adversarial investigate elaborate countermeasure adversarial addition challenge adversarial potential introduction DL significant progress domain machine ML image classification recognition detection recognition translation synthesis DL empower application crucial concern safety security despite numerous application recent DL vulnerable input sample sample easily fool perform DL model perturbation imperceptible generate perturbation image image classification fool neural network dnns probability misclassified sample adversarial extensive DL application deployed physical safety critical environment meanwhile recent adversarial apply instance adversary construct physical adversarial confuse autonomous vehicle manipulate traffic recognition remove segmentation pedestrian recognition attacker generate adversarial command automatic recognition model controllable siri amazon alexa microsoft cortana DL widely regard technique performs limited knowledge propose explain interpret dnns inspect adversarial gain insight semantic inner neural network problematic decision boundary increase robustness performance neural network improve interpretability investigate summarize approach generate adversarial application adversarial correspond countermeasure explore characteristic adversarial recent advance DL revolve around supervise computer vision task therefore adversarial generate computer vision model mainly discus adversarial image classification recognition task adversarial task investigate inspire define threat model adversary attack deploy stage tamper input data stage victim DL model neither model training data modify adversary knowledge model architecture parameter modify model assumption online ML service attack training stage training data poison another topic due limitation topic focus attack model built dnns due performance achieve discus adversarial conventional ML vector machine svm random II adversarial dnns effective conventional ML model vii adversary aim compromise integrity integrity performance metric accuracy curve essential DL model although security issue pertain confidentiality privacy drawn attention DL focus attack degrade performance DL model increase false positive false negative threat model differs adversarial attack categorize contribution systematically analyze approach generate adversarial  attack approach along accessible intuitive overview approach investigate recent approach variant generate adversarial propose taxonomy application reinforcement generative model recognition detection semantic segmentation processing nlp malware detection countermeasure adversarial outline challenge potential future research direction adversarial transferability adversarial existence adversarial robustness evaluation dnns remain organize II introduces background DL technique model data discus adversarial conventional ML II propose taxonomy approach generate adversarial elaborate approach IV discus application adversarial correspond countermeasure investigate VI discus challenge potential vii concludes II background briefly introduce DL technique approach related adversarial review adversarial era conventional ML difference adversarial conventional ML adversarial DL brief introduction discus concept exist technique popular architecture standard data DL due extensive breakthrough become acknowledge target attack adversary usually apply evaluate attack concept DL ML computer knowledge without explicit program extract useful raw data conventional ML algorithm extract feature due limitation curse dimensionality computational bottleneck requirement domain expert knowledge DL solves representation building multiple feature sophisticated concept DL image classification fabric structure hidden layer increase available training data DL becomes powerful DL model complicate hardware acceleration computational neural network layer compose perceptrons artificial neuron perceptron input output activation function function neural network chain sourcewhere function layer network convolutional neural network cnns recurrent neural network rnns widely neural network recent neural network architecture cnns deploy convolution operation hidden layer reduce parameter cnns extract local information  input data cnns incredible computer vision task image classification detection text recognition semantic segmentation rnns neural network processing sequential input data variable rnns output hidden neuron calculate input data hidden neuron previous memory gate recurrent controllable gate avoid vanish explode gradient rnns dependence architecture neural network DL architecture widely computer vision task lenet vgg alexnet googlenet inception resnet simplest network deepest complex alexnet DL model largely surpass conventional ML algorithm imagenet challenge future DL architecture tremendous breakthrough imagenet challenge milestone image classification attacker usually generate adversarial baseline architecture standard data mnist cifar imagenet widely data computer vision task mnist data handwritten digit recognition cifar data imagenet data image recognition task cifar data consists image imagenet data consists image image imagenet data adversarial approach evaluate imagenet data SVHN data mnist data consists digit obtain google image  data gain youtube consist image adversarial countermeasure machine adversarial conventional ML model decade ML handcraft feature primary target spam filter intrusion detection biometric authentication fraud detection spam email modify avoid detection adversarial formulate adversary classifier na√Øve bayes sensitive attack defense adversarial become iterative gradient approach generate adversarial linear classifier svm neural network DL adversarial freedom modify data mnist data evaluate attack although easily distinguish adversarial digit image review proactive defense reactive approach improve security ML model initial investigation security ML categorize attack ML influence attack poison training data security violation adversarial belongs false positive false negative specificity attack target instance discus DL attack  spam filter defense however mainly focus binary classification virus detection intrusion detection intrusion prevention adversarial conventional ML knowledge feature extraction DL usually raw data input conventional ML attack defend paid attention feature previous data collection attention impact target becomes fully automatic ML inspire conventional ML review recent security issue DL comprehensive overview security issue ML recent finding DL establish unify threat model lunch theorem introduce tradeoff accuracy robustness focus adversarial DL detailed discussion recent finding adversarial image classification task described image classifier publish user input image prediction label adversarial image image perturbation barely recognizable however perturbation misguide image classifier user response incorrect image label DL model input data sample generate adversarial generally described constrain optimization minx sourcewhere denote output label respectively denotes distance data sample perturbation optimization minimizes perturbation misclassifying prediction constraint input data discus variant generate adversarial image adversarial task taxonomy adversarial systematically analyze approach generate adversarial analyze approach generate adversarial detail IV categorize along dimension threat model perturbation benchmark threat model discus threat model scenario assumption quality requirement adversary attribute adversarial deploy specific attack approach decompose threat model aspect adversarial falsification adversary knowledge adversarial specificity attack frequency adversarial generate adversary attack instead iterative attack task attack frequency adversarial falsification false positive attack generate negative sample misclassified positive error malware detection task benign software classify malware false positive image classification task false positive adversarial image unrecognizable dnns predict confidence false negative attack generate positive sample misclassified negative II error malware detection task false negative malware usually positive cannot identify model false negative attack ML evasion error adversarial image recognize image neural network cannot identify adversary knowledge attack assume adversary everything related neural network model training data model architecture hyperparameters layer activation function model adversarial generate calculate model gradient dnns tend raw input data without handcraft feature deploy structure feature selection adversarial ML attack assume adversary access neural network model adversary standard user output model label confidence assumption attack online ML service ML aws google AI  clarifai microsoft azure ibm  adversarial attack attack however transfer attack service due transferability adversarial propose elaborate vii adversarial specificity target attack misguide dnns specific target attack usually multiclass classification adversary fool image classifier predict adversarial recognition biometric adversary disguise authorize user impersonation target attack usually maximize probability target adversarial nontargeted attack assign specific neural network output adversarial output arbitrary adversary  arbitrary recognition FRS evade detection  nontargeted attack easy implement target attack option redirect output nontargeted adversarial usually generate target attack perturbation minimize probability generation approach extend iterative bim zeroth optimization zoo apply target nontargeted attack binary classification target attack equivalent nontargeted attack attack frequency attack optimize adversarial iterative attack multiple update adversarial attack iterative attack usually perform adversarial interaction victim classifier query computational generate computational intensive task reinforcement attack feasible choice perturbation perturbation fundamental premise adversarial adversarial sample imperceptible performance degradation DL model analyze aspect perturbation perturbation scope perturbation limitation perturbation measurement perturbation scope individual attack generate perturbation input universal attack universal perturbation data perturbation apply input data attack generate adversarial individually however universal perturbation easy deploy adversary adversary perturbation input sample perturbation limitation optimize perturbation perturbation goal optimization aim minimize perturbation cannot recognize perturbation constraint perturbation perturbation constraint optimization perturbation perturbation measurement magnitude perturbation norm distance  commonly metric pixel adversarial euclidean distance adversarial sample denotes maximum pixel adversarial psychometric perceptual adversarial similarity metric introduce consistent perception benchmark adversary performance adversarial attack data victim model inconsistency brings obstacle evaluate adversarial attack robustness DL model quality data complex performance DL model usually adversary defender attack defend diversity data victim model researcher existence adversarial due data model discus vii data mnist cifar imagenet widely image classification data evaluate adversarial attack mnist cifar easy attack defend due simplicity imagenet data evaluate adversarial attack data evaluate adversarial attack victim model adversary usually attack DL model lenet vgg alexnet googlenet CaffeNet resnet IV investigate recent adversarial accord taxonomy IV generate adversarial illustrate representative approach generate adversarial although approach defeat countermeasure later adversarial attack improve extent adversarial attack achieve existence investigation improve robustness dnns summary generate adversarial propose taxonomy taxonomy adversarial BFGS attack introduce adversarial dnns generate adversarial BFGS target minx source suitable constant BFGS attack calculate approximate adversarial author generate adversarial generalize model training data adversarial rarely data BFGS attack implement binary optimal gradient BFGS attack expensive linear optimal consume impractical propose gradient FGSM generate adversarial perform gradient update along direction gradient pixel perturbation express   sourcewhere magnitude perturbation generate adversarial calculate perturbation compute backpropagation adversarial imagenet adversarial image generate FGSM image panda perturbation sample adversarial image classify gibbon claimed linear dimensional dnn resist adversarial although linear behavior training regularization approach dnns dropout pretraining improve robustness network propose gradient replace gradient raw gradient gradient constraint pixel generate image local difference accord attack easy transfer easy defend vii apply momentum FGSM generate adversarial iteratively gradient calculate    sourceand adversarial derive  author increase effectiveness attack introduce momentum improve transferability apply attack ensembling extend FGSM target attack maximize probability target  sourcethe author refer attack target  FGSM adversarial training robust attack attack due gradient mask propose attack rand FGSM random update adversarial defeat adversarial training     sourcewhere parameter iterative iterative likely previous assume adversarial data directly fed dnns however application pas data device camera sensor apply adversarial physical extend FGSM finer optimization multiple iteration iteration clipped pixel avoid pixel  min max sourcewhere  limit generate adversarial image iteration adversarial generate multiple iteration   sourcethe author refer bim attack specific chose likely prediction maximize entropy loss refer iterative likely        successfully fool neural network craft image cellphone camera FGSM robust  iterative cannot resist  jacobian saliency attack efficient saliency adversarial jacobian saliency attack JSMA compute jacobian matrix sample  SourceAccording denotes layer logits carlini wagner modify approach output softmax layer input feature significant output perturbation successfully induce output variation portion feature fool neural network author define adversarial saliency feature pixel craft iteration achieve adversarial rate modify input feature per sample however due significant computational deepfool  propose deepfool closest distance input decision boundary adversarial overcome nonlinearity dimension perform iterative attack linear approximation affine classifier minimal perturbation affine classifier distance affine hyperplane  perturbation affine classifier binary differentiable classifier iterative approximate perturbation linearize around iteration minimal perturbation compute   SourceThis extend multiclass classifier closest hyperplanes extend norm deepfool perturbation FGSM JSMA JSMA deepfool reduce intensity perturbation instead feature  EA fool discover attack compositional network encode evolutionary algorithm  EA adversarial classify dnns confidence unrecognizable categorize attack false positive attack false positive adversarial unrecognizable dnns classify certainty EA algorithm adversarial multiclass classification EA algorithm apply multidimensional archive  elite elite author encode image encode grayscale hue saturation indirect encode  iteration elite EA algorithm chose random organism mutate randomly replace fitness certainty neural network elite individual claimed adversarial image  critical feature output dnns JSMA image evolutionary closely related category interestingly  EA fooling image accepted contest acceptance rate attack carlini wagner launch target attack defeat defensive distillation VI accord attack effective exist adversarial detect defense author modification define objective function  sourcewhere distance penalty optimize author objective function candidate effective function evaluate max maxi sourcewhere denotes softmax function constant confidence instead constrain BFGS minimal perturbation BFGS attack author introduce variant avoid constraint satisfies tanh optimizers DL adam stochastic gradient descent generate adversarial perform iteration generation optimal binary however gradient suitable constant iteration gradient optimal due propose function optimal adversarial distance measurement perturbation author attack distance metric attack attack attack attack described minw tanh tanh sourcethe author distillation network defend attack attack conduct iteratively differentiable iteration pixel trivial generate adversarial remove importance pixel gradient distance iteration remain pixel cannot generate adversarial attack iterative attack replace penalty iteration minc sourcefor iteration reduce factor attack estimation zeroth optimization gradient adversarial generate approach propose zoo attack attack gradient directly deployed attack without model transfer inspire author modify  loss function max maxi sourceand symmetric difference estimate gradient hessian hei hei hei hei sourcewhere denotes standard basis vector component constant employ gradient estimation gradient hessian zoo access victim DL model however expensive computation query estimate gradient author propose adam algorithm zoo adam randomly variable update adversarial zoo achieve comparable performance attack universal perturbation leverage previous deepfool  developed universal adversarial attack formulate universal perturbation vector satisfy  limit universal perturbation failure rate adversarial sample iteration deepfool minimal sample perturbation input data update perturbation perturbation loop data sample fool universal perturbation generate data sample instead entire data universal adversarial fool image universal perturbation generalize across popular DL architecture vgg CaffeNet googlenet resnet universal adversarial fool neural network image image label image image universal perturbation image perturbed image label pixel attack avoid measurement  generate adversarial modify pixel optimization becomes minx sourcewhere modify pixel constraint optimize apply differential evolution DE eas optimal DE gradient neural network  objective function evaluate propose cifar data neural network convolution network  network network vgg image successfully fool dnns target confidence average feature adversary perform target attack minimize distance representation internal neural network layer instead output layer refer attack feature adversary described minx sourcewhere denotes mapping image input output layer instead minimal perturbation constraint perturbation claimed fix perception BFGS optimization adversarial image closer target image internal layer propose multiple adversarial image input translation rotation imperceptible define metric noticeable similarity neglect unnoticeable difference pixel replace widely distance stage align modify image image similarity align image homography transform adversarial homography matrix maximize enhance correlation coefficient optimization function  sourcewhere denotes normalization image structural similarity ssim index adopt noticeable difference image leveraged ssim define measurement regional ssim  index  sourcewhere importance luminance contrast structure ssim calculate average  ssim  source define combination alignment similarity measurement ssim source adversarial distance described  sourcewhere denotes distance generate diverse adversarial author define target label label iteration target away generate adversarial comparable FGSM diversity gan utilized generative adversarial network gans approach generate adversarial image text adversarial approach gan author WGAN model data generator random input domain inverter input data dense inner representation hence adversarial generate minimize distance inner representation feature adversary adversarial generate generator  source generator inverter built adversarial gan framework DL apply gan image classification textual entailment machine translation gan gradient neural network apply attack model ensembling attack conduct transferability vii dnns imagenet propose model ensembling attack target adversarial author argue nontargeted adversarial target adversarial harder transfer model model ensembling attack generate transferable adversarial attack model author generate adversarial multiple dnns knowledge model model ensembling attack derive optimization argminx  sourcewhere dnns generation function network ensemble  model ensembling attack generate transferable target adversarial image enhance adversarial attack performs generate nontargeted adversarial previous author successfully conduct attack clarifai com model ensembling attack truth attack formal verification technique aim evaluate robustness neural network zero attack VI construct truth attack adversarial minimal perturbation network verification adversarial violates dnn exists label within distance truth attack conduct binary adversarial perturbation invoke reluplex iteratively initial adversarial attack improve performance application adversarial investigate adversarial image classification task review adversarial task mainly focus scenario adversarial apply task generate adversarial task propose translate image classification task aforementioned II summarizes application adversarial II summary application adversarial reinforcement dnns reinforcement training policy raw input image generate adversarial reinforcement policy perform attack due intensive computation response reinforcement apply FGSM attack reinforcement network algorithm network DQN trust policy optimization asynchronous advantage actor critic AC perturbation input policy calculate gradient entropy loss function DQN stochastic policy input softmax calculate loss function evaluate adversarial atari norm constraint huang attack norm conduct successful attack attack attack access training algorithm parameter hyperparameters FGSM attack AC algorithm atari pong task inject perturbation frame sufficient generative model propose adversarial generative model adversary autoencoder AE inject perturbation input encoder generate target decode target adversarial AE perturbation input image encoder misguide AE decoder generate target adversarial output image adversarial attack aes perturbation input encoder encode decode decoder output adversarial image incorrect described scenario apply adversarial AE aes compress data encoder decompress decoder rnn AE compress image gan super resolve image adversary leverage AE reconstruct adversarial image perturbation input encoder feature adversary attack AE variational AE VAE adversarial formulate  encoder encoder sourcewhere distance latent encode representation chose KL divergence attack mnist SVHN data generate adversarial AE harder classifier VAE slightly robust deterministic AE extend another distance hence adversarial generate optimize  sourcethe loss function entropy refer classifier attack VAE loss function   distance latent vector modify encode vector VAE VAE gan mnist SVHN celeba data experimental latent attack achieve recognition dnn FRS detection widely deployed commercial due performance eyeglass frame attack dnn FRS composes layer triplet loss function feature embed triplet loss function  function  sourcewhere vector denotes inner BFGS attack generate adversarial implement adversarial eyeglass frame achieve attack physical perturbation inject eyeglass frame enhance printability adversarial image frame penalty  NPS optimize objective universal perturbation optimize perturbation apply image successfully  nontargeted attack FRS misguide FRS specific target attack rate target adversarial eyeglass frame adversarial eyeglass frame FRS leverage approach printability propose attack algorithm robust physical perturbation RP modify limit physical attack overlay adversarial physical perturbation exist NPS optimization objective improve printability detection detection task proposal bound image classification task proposal propose universal algorithm dense adversary generation dag generate adversarial detection semantic segmentation author aim prediction detection segmentation incorrect nontargeted adversarial detection task adversarial detection task detection image detection adversarial image define recognition target image classification classifier target entire image semantic segmentation target consist pixel  detection target consist proposal  objective function sum loss target instead optimize loss target author perform iterative optimization update loss target correctly predict previous iteration perturbation sum normalize perturbation iteration target objective detection author regional proposal network generate target greatly decrease computation target detection dag capability generate image unrecognizable DL predict false positive semantic segmentation image segmentation task image classification task pixel perturbation responsible pixel segmentation perturbation segmentation image classification generate adversarial semantic image segmentation task however attack propose scenario perform nontargeted segmentation perform target segmentation remove DL model misguide background generate adversarial assign pixel adversarial belongs rate percentage pixel chosen preserve generate universal adversarial perturbation semantic image segmentation task assign primary objective adversarial hid pedestrian segmentation unchanged define background target target adversarial target remove pixel belong target assign background       sourcewhere  xij denotes remove adversarial hide pedestrian  attack extend universal perturbation universal perturbation existence universal perturbation semantic segmentation task adversary hiding pedestrian semantic segmentation task image segmentation image predict dnn segmentation adversarial image predict dnn processing task nlp attack adversarial usually generate adversarial delete task reading comprehension generate adversarial consistent confuse jia liang distract adversarial model reading comprehension task  instead  DL model cannot subtle critical difference propose generate adversarial grammatical contradictory  arbitrary english  jia liang successfully fool model model stanford data adversarial capability transferability cannot improve adversarial training however adversarial manpower fix error aim fool DL sentiment classifier remove minimum subset text reinforcement approximate subset reward function propose sentiment label otherwise denotes remove reward function regularizer contiguous easily recognize adversarial texture data propose gan IV malware detection DL static behavioral malware detection due capability detect zero malware recent generate adversarial malware sample evade DL malware detection adapt JSMA attack android malware detection model evade pdf malware classifier   modify pdf parse pdf file structure genetic program adversarial pdf file packed gan generate adversarial domain evade detection domain generation algorithm tan propose gan algorithm  generate malware evade detection substitute detector simulate detector leveraged transferability adversarial attack detector  evaluate program application program interface feature however knowledge feature model feature feature portable executable PE file feature PE header metadata metadata import export metadata define modification generate malware evade DL detection reinforcement evasion rate reward VI countermeasure adversarial countermeasure adversarial defense strategy reactive detect adversarial dnns built proactive dnns robust adversary generate adversarial discus reactive countermeasure adversarial detect input reconstruction network verification proactive countermeasure network distillation adversarial training classifier  discus ensembling prevent adversarial summarizes countermeasure summary countermeasure adversarial network distillation network distillation defend dnns adversarial network distillation originally reduce dnns transfer knowledge network probability dnn input dnn probability extract knowledge dnn softmax usually normalize layer dnn probability softmax output dnn input dnn described exp jexp sourcewhere parameter knowledge distillation dnns output softmax vague probability schema network distillation duplicate connects dnns network distillation dnns network distillation extract knowledge dnns improve robustness author attack primarily aim sensitivity network softmax reduce model sensitivity perturbation network distillation defense mnist cifar data reduce rate JSMA attack respectively network distillation improve generalization neural network adversarial training training adversarial countermeasure neural network robust adversarial training stage generate adversarial training inject training adversarial training improve robustness dnns adversarial training regularization dnns improve precision evaluate mnist data comprehensive analysis adversarial training imagenet data adversarial origin training adversarial training increase robustness neural network attack FGSM iterative attack bim  adversarial training regularization avoid overfitting mnist data  adversarial model mnist imagenet data robust adversarial transfer dong minimize entropy loss internal representation distance adversarial training defense version feature adversary transfer model propose ensembling adversarial training model adversarial generate multiple source model pretrained external model adversarial detect research project detect adversarial stage dnn binary classifier detector classify input data legitimate input adversarial detector adversarial auxiliary network neural network detector straightforward neural network predict binary classification probability input adversarial  extract binary threshold rectify linear relu layer output feature adversarial detector detects adversarial image radial basis function rbf svm classifier author claimed defeat adversary adversary detector adversary optimal adversarial feature  detector outlier DL model model detect adversarial classify outlier measurement maximum discrepancy distance distinguish distribution adversarial data data bayesian detect adversarial claimed uncertainty adversarial data hence deployed bayesian neural network estimate uncertainty input data distinguish adversarial input data uncertainty estimation similarly probability divergence jensen shannon divergence detector   whiten principal component analysis adversarial coefficient ranked component PixelCNN neural network distribution adversarial data calculate rank PixelCNN reject adversarial approach detect FGSM bim deepfool attack neural network reverse entropy distinguish adversarial data latent layer detect adversarial kernel density stage reverse entropy dnn predict confidence uniform distribution dnn input dimensional manifold layer softmax convenience detection adversarial leveraged multiple previous image predict future input detect adversarial task reinforcement however carlini wagner summarize adversarial detect defend previous attack attack slight loss function input reconstruction adversarial transform data via reconstruction transformation adversarial affect prediction DL model  propose variant AE network penalty contractive AE increase robustness neural network denoising AE network encode adversarial remove adversarial perturbation meng chen reconstruct adversarial gaussian encode AE  VI  reconstruct adversarial image training distribution PixelCNN  pixel along channel maximize probability distribution maxx  sourcewhere denotes training distribution  adversarial  leveraged adversarial detect adversarial detect malicious adversarial  classifier  abbasi  robust architecture dnns prevent adversarial due uncertainty adversarial leveraged bayesian classifier robust neural network gaussian gps rbf kernel uncertainty estimation propose neural network GP hybrid neural network  gps express latent variable gaussian distribution parameterized function covariance encode rbf kernel  achieve comparable performance dnns robust adversarial author claimed  abbasi  adversarial usually subset incorrect subclass ensembled subclass voting prevent adversarial misclassified network verification verify dnns promising defend adversarial detect unseen attack network verification neural network input violates satisfies propose verification neural network relu activation function reluplex satisfiability modulo theory solver verify neural network author within perturbation exist adversarial misclassify neural network network verification NP extend assumption relu function max relu relu however reluplex due computation verify network dnns node propose potential prioritize node information verification instead individually propose  dnn reluplex introduce target robustness regard target ensembling defense due  adversarial multiple defense strategy perform parallel sequential defend adversarial aforementioned  compose adversarial detector input reconstructor establish defense strategy  detector reconstructor reformer detector adversarial boundary manifold distance input encode input probability divergence jensen shannon divergence softmax output input encode input adversarial distance probability divergence adversarial boundary  reconstructor built neural network aes reconstructor adversarial legitimate workflow defense phase  workflow detector detects input adversarial reconstruct classifier modify investigate defensive approach ensemble defensive approach neural network summary almost defense effective attack tend defensive fail defend unseen attack defense target adversarial computer vision task however development adversarial defense safety critical urgently vii challenge discussion discus challenge potential adversarial although theorem propose developed recently fundamental explain challenge address existence adversarial fundamental adversary researcher exploit vulnerability neural network defender resist adversarial discus adversarial transfer transferability defense effective others strength attack defense evaluate robustness dnn unseen adversarial transferability transferability adversarial adversarial generate neural network fool neural network data adversarial generate neural network fool neural network architecture classifier ML algorithm transferability critical attack victim DL model training data accessible attacker substitute neural network model generate adversarial substitute model victim model vulnerable adversarial due transferability defender hinder transferability adversarial defend attacker access model transferability define transferability adversarial easy transfer neural network architecture data transfer neural network architecture task transfer dnns task knowledge exist instance transfer adversarial image detection semantic segmentation examine transferability ability adversarial transferability conventional ML technique logistic regression svm decision dnns adversarial transfer parameter training data ML model across ML technique investigate transferability target nontargeted adversarial complex model data imagenet data nontargeted adversarial transferable target decision boundary model align propose model ensembling attack transferable target adversarial  distance model decision boundary average distance model boundary direction explain existence transferability adversarial  claimed transferability inherent dnns counterexample existence adversarial existence adversarial adversarial inherent dnns adversarial  heel dnns performance hypothesis propose explain existence data  assumption adversarial probability coverage data training PixelCNN distribution adversarial data gaussian model robust model complicate training data standard model model capability adversarial phenomenon dnns classifier adversarial model linear dimensional manifold  griffin linear adversarial exist decision boundary manifold training data contrary adversarial due flexibility classifier task linearity obvious explanation   blame adversarial sparse discontinuous manifold classifier erratic robust model decision boundary dnns inherently incorrect detect semantic data generate smooth generative model latent robust classifier adversarial similarly model sphere data misclassifies data exist adversarial perturbation addition adversarial image classification task adversarial generate various application deployed  application image classification task however propose novel adversarial mainly focus image classification task exist explains relationship application existence universal attack defend apply application robustness evaluation competition attack defense adversarial becomes defensive propose prevent exist attack later vulnerable attack vice versa defense defend attack later fail slight attack hence evaluation robustness dnn upper bound robustness linear classifier quadratic classifier robustness evaluation dnns exploration methodology evaluation robustness neural network dnns deployed safety critical setting defend exist attack sufficient zero attack harmful dnns methodology evaluate robustness dnns zero attack understand confidence model prediction rely conduct initial evaluation moreover performance dnn model confidentiality privacy benchmark platform attack defense attack defense described without publicly available code mention parameter brings difficulty researcher reproduce correspond attack defense carlini defense parameter random initialization researcher drew conclusion setting exists benchmark adversary defender conduct uniform threat model data classifier attack defend approach precise comparison attack defend technique   source library benchmark vulnerability dnns adversarial image framework evaluate attack however defensive strategy data adversarial generate easy blind dnns develop defense strategy occurs DL google brain organize competition NIPS competition target adversarial attack nontargeted adversarial attack defense adversarial attack data competition consist image manually label image image development image submit attack competition benchmark evaluate adversarial attack defense fool defense correctly classify image workflow benchmark platform attacker defender workflow benchmark platform attacker defender attacker defender update strategy training data attacker generate adversarial data adversarial verify crowdsourcing recognizable defender generate dnn defensive strategy evaluate defensive strategy various application robustness evaluation existence adversarial various application application evaluate robustness dnn architecture generate adversarial threat model universal methodology evaluate robustness scenario tackle unsolved future direction conclusion review recent finding adversarial dnns investigate exist generate adversarial taxonomy adversarial propose explore application countermeasure adversarial attempt adversarial DL domain recent adversarial analyze challenge potential adversarial