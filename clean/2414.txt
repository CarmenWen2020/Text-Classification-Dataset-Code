regular machine data mining technique training data future inference assumption future data within feature distribution training data however due limited availability label training data training data feature distribution future data cannot guaranteed sufficient avoid fitting application apart data target domain related data domain expand availability prior knowledge target future data transfer address domain extract useful information data related domain transfer target task recent transfer apply visual categorization typical divergence action recognition task concept drift image classification task efficiently survey transfer algorithm visual categorization application recognition image classification action recognition introduction computer vision community witness significant amount application video retrieval surveillance robotics regular machine approach achieve promising assumption training data feature distribution however application due price manual label environmental restriction sufficient training data belonging feature distribution data available typical action template action training training sample capture viewpoint situation regular machine technique likely fail reminds capability vision gigantic geometric intraclass variability visual category hypothesis achieve capability accumulate information knowledge estimate per due limitation within amount correspond data exist knowledge gain previous assist connection category assume  training sample  previous knowledge  circular category  transfer mimic vision sufficient amount prior knowledge related domain execute task domain transfer training data data contribute domain target domain source domain target domain contains instance task categorization source domain contains training instance distribution target domain data target domain transfer task multiple source domain exist action recognition conduct across data domain kth data background limited viewpoint source data microsoft research action data  surveillance data capture realistic scenario target data source target data chosen TV program channel task video concept detection transfer paradigm partial training data distribution data understand significance knowledge transfer visual literature conclude issue regard transfer transfer transfer transfer transfer issue transfer specific task source domain data related target domain data scenario training sample sufficient impressive performance achieve constrain target domain another domain source domain becomes superfluous variety divergence exist across source domain target domain data brute knowledge source domain target domain irrespective divergence performance degeneration data consistency target domain transfer conclude aspect inductive transfer source domain instance correspond label knowledge transfer instance transfer source domain instance parameter transfer addition source domain instance label parameter  model source domain utilized improve performance target domain finally transfer specific transfer technique important transfer literature transfer technique propose knowledge transfer non negative matrix  framework transfer phase via dimensionality reduction illustrate framework traditional machine approach knowledge transfer approach traditional machine approach ideal choice training predict instance however knowledge transfer training relevant category bicycle knowledge irrelevant laptop connection actually geometrical layout local image framework traditional machine approach knowledge transfer approach regular machine approach handle situation sample training sample distribution transfer approach data distribution mismatch specific knowledge transfer mining data across domain data transfer benefit target relevant data application transfer emerge future research survey aim comprehensive overview transfer technique visual categorization task reader potentially analysis discussion survey understand transfer apply visual categorization task suitable transfer visual categorization task posse unique characteristic due visual potentially training appearance local symmetry structural unique employ transfer algorithm former focus classification regression cluster related data mining task latter focus reinforcement address limited environmental feedback correctly label remain survey structure overview II IV transfer category execute knowledge transfer feature representation classifier detail respectively transfer transfer model selection multiple source domain transfer evaluation analysis discussion transfer VI finally conclusion drawn vii II overview develop transfer date notion transfer domain domain transfer domain adaptation machine technique recent information explosion internet audio image video demand target task accuracy data computational efficiency transfer approach attract increase research recognition machine regular machine technique limit transfer fundamentally treat classification regression task along workshop tutorial NIPS  workshop machine data mining another transfer survey reinforcement survey focus application transfer technique visual categorization action recognition recognition image classification notation issue notation define later usage DT   denote target domain data partially label denote  unlabeled denote  addition target domain data auxiliary data source domain data  fully label representation source dsm dsk    multiple source ith feature vector denotes data dimension denotes label sample accord prior proposal issue regard knowledge transfer twofold auxiliary sample typically treat without accounting mutual dependency adaptation adapt data arbitrarily distribute structural information beyond data sample auxiliary data become undermined adaptation particularly outlier auxiliary domain blindly target domain transfer knowledge auxiliary domain target domain crucial distribution similarity target domain data source domain data criterion distribution similarity domain nonparametric distance metric maximum discrepancy mmd mmd propose data distribution reproduce kernel hilbert  DT  xsi  xti sourcewhere feature mapping function literature transfer technique categorize accord variety taxonomy task allocate target domain auxiliary domain availability sample label within target domain auxiliary domain transfer technique grouped inductive transfer transductive transfer unsupervised transfer upon categorize instance transfer feature representation transfer parameter transfer relational knowledge transfer within initial partition differentiate exist knowledge transfer approach visual categorization survey inherit concept computer vision community simply categorize transfer technique feature representation knowledge transfer classifier knowledge transfer differentiate exist knowledge transfer approach feature representation transfer feature representation knowledge transfer popular transfer category target domain source domain exploit  manufacture feature feature representation knowledge transfer data divergence target domain source domain significantly reduce performance task target domain improve exist transductive feature specific domain perform optimally across data review feature knowledge transfer technique accord data domain knowledge transfer knowledge transfer domain knowledge transfer domain gap source domain data target domain data varies image video accord data divergence approach propose knowledge transfer kth data  data microsoft research action data II  kth data target domain  data  data source domain kth data limited background actor video sequence exhibit individual action  data  data capture realistic scenario clutter background multiple actor video sequence advantage label training data target domain source domain  propose feature replication FR augment feature training inspire applies gaussian mixture model GMM model visual similarity image video model spatial temporal  GMM introduces prior distribution GMM parameter generate probabilistic representation  representation accomplish adaptation source domain target domain assumes label training data source domain label training data target domain furthermore activity source domain target domain overlap traditional supervise cannot apply scenario utilize web return similarity across domain label data source domain interpret label target domain extreme source domain data relevant target domain data sparseness gain tremendous attention various scientific computer vision dominant trend sparse model application computer vision technique DL transfer apply sparse cod unlabeled data tremendous amount data source domain task image classification knowledge transfer representation training sample target domain source domain data necessarily relevant target domain data regular transfer formalism source domain data relevant target domain data knowledge transfer taught transfer zhu shao discriminative domain DL  framework utilizes relevant data visual domain auxiliary knowledge enhance target domain objective function encourage visual across domain posse identical representation encode POS tag task auxiliary categorization task extract pivot feature frequent emerge indicative correspond category pivot feature sensitive POS tag task pivot visual exist typical local histogram visual feature indicates feature dimension histogram bin discriminative difference visual category target identify dimensional feature auxiliary domain target domain manifest characteristic instead transfer entire knowledge across target domain auxiliary domain assumption smoothness data likely label satisfied dimension subspace knowledge transfer knowledge transfer domain knowledge transfer divergence across domain task recognize action target training sample generate invariant feature address visual recognition attracts significant attention computer vision action recognition knowledge transfer scenario multiview  data typical sample capture source training data predict label sample capture target core methodology approach tackle visual categorization observer viewpoint discover knowledge irrespective viewpoint approach attack feature representation diversity infer scene structure feature adaptation derive feature adapt another utilize geometric another approach explore visual affine projective epipolar geometry compute feature representation apply similarity matrix distance action invariant representation spatial temporal feature video sequence insensitive angle domain knowledge transfer scenario target domain action perform player background kth data target domain action capture complicate background multiple player  data knowledge transfer scenario target data source data action capture  data bipartite graph built via unsupervised cluster visual visual relationship across target source semantic feature bridge semantic gap vocabulary generate beyond bag visual representation successfully apply processing information retrieval computer vision propose bag bilingual representation discovers action concept domain highly independent  capture conceptual virtual construction action descriptor continuously observer viewpoint another another approach propose construct utilize correspondence sample across domain encourage label source data unlabeled target data feature satisfies smoothness assumption summarize characteristic feature representation knowledge transfer approach accord adaptation target domain label source domain label adaptation data application approach utilize sparseness generate sparse representation data adaptation characteristic feature representation knowledge transfer approach availability target domain label adaptation application feature representation knowledge transfer IV classifier knowledge transfer feature representation knowledge transfer classifier knowledge transfer another significant exist visual transfer technique attract attention recent however unlike feature representation knowledge transfer technique training sample source domain adapt target framework classifier knowledge transfer trait source domain model utilized prior knowledge addition training sample target model instead minimize domain dissimilarity update instance representation classifier knowledge transfer aim model minimizes generalization error target domain via training instance domain model structure accord category classifier knowledge transfer technique svm vector machine svm supervise classification regression majority exist classifier knowledge transfer construct svm classifier application svm adaptive svm svm projective model transfer svm PMT svm source model regularize distance target model model svm objective function LA minwt  inl sourcewhere indicates correspond label max hinge loss loss function amount transfer regularization regularize distance model knowledge transfer svm  equivalent sample source expand regularization  cosθ sourcewhere margin maximization regular svm cosθ induces transfer maximize cosθ minimize angle instead maximize cosθ knowledge transfer induced minimize projection onto hyperplane orthogonal PMT svm objective function  minwt  inl tws sourcewhere  projection matrix svm PMT svm increase amount transfer without penalize margin maximization oppose rigid transfer svm PMT svm deformable adaptive svm DA svm flexible transfer regularization deformable source template local deformation tolerate template source domain target domain  zisserman explain visual deformation knowledge transfer motorbike template increase radius reduce thickness fitting bicycle template DA svm generalization rigid svm replace lda minf inl   fii sourcewhere spatial distance penalization additional source target  transformation parameter fij denotes amount transfer source template transform template extract local image local descriptor hog sift compute classifier knowledge transfer technique DA svm constraint construct visual feature geometrical information local image propose discriminative transfer vector machine LS svm learns category adaptation replace regularization classical LS svm objective function knowledge transfer formulate  minwt   sourcewhere factor transfer across model target model extend  knowledge transfer multi KT factor substitute vector correspond prior model rewrite  KT minwt   sourcethe resampling data training sample balance advantage LS svm LOO error amount knowledge transfer minimize LOO error typically kernel function specify advance associate kernel parameter variance gaussian kernel optimization various kernel domain transfer svm DT svm unified domain framework svm decision function kernel function simultaneously instead approach DT svm achieves domain classification objective criterion DT svm minimizes data distribution mismatch target domain source domain mmd criterion mention II DT svm pursues classification performance minimize structural risk svm meeting criterion effective kernel function separation performance linear domain sample source domain infuse target domain improve classification performance svm classifier tradaboost adaptive boost adaboost popular boost algorithm conjunction machine algorithm enhance performance iteration adaboost increase accuracy selection weak classifier carefully adjust training instance importance misclassified instance informative selection transfer adaboost tradaboost introduce extend adaboost transfer distribution data dissimilar distribution data boost iteration goal tradaboost reduce training error distribution data meanwhile preserve adaboost quality distribution data performance tradaboost cannot guaranteed outperform adaboost generative model concept via generative model emerge promising research computer vision machine recently researcher develop approach transfer generative model workshop conjunction NIPS specifically discussion transfer via generative model generative knowledge transfer impact transfer information discriminative approach adaptive specific task fei propose bayesian unsupervised shot categorization framework learns category bayesian incorporate prior information prior probability density function observation become available information previously learnt unrelated category suitable prior probability density function parameter probabilistic model prior unrelated category category motorbike prior obtain average learnt model parameter category airplane hyperparameters prior estimate parameter exist category model  apply generative author topic model probabilistic distribution image feature attribute attribute across category transfer knowledge source category target category zero shot shot address attribute model source domain category generate synthesize target training generative attribute model reduce uncertainty parameter  prior fuzzy model transfer application fuzzy propose knowledge leverage fuzzy model respectively former  sugeno kang fuzzy latter reduce density estimator mamdani larsen fuzzy training decompose training data scene model parameter reference scene knowledge leverage strategy adopt model parameter obtain reference scene fed scene parameter approximation knowledge leverage strategy perform unified objective function emphasizes data scene transfer model parameter reference scene discussion svm knowledge transfer plug svm training trait amid accord objective function regularization similarity model target model svm PMT svm DA svm tradeoff parameter margin maximization knowledge transfer defines amount transfer regularization DA svm specialized transfer visually deformable template svm PMT svm likely generalize advantage PMT svm svm increase amount transfer without penalize margin maximization svm encourages increase indicates margin hyperplane generalization error classifier fails gain optimal bound PMT svm outperform svm svm approach boost tradaboost simpler implementation parameter  model boost technique tradaboost fairly generalization ability however tradaboost relies heavily relevance source domain data target domain data vulnerable negative transfer addition tradaboost easily overfit presence domain generative model adaptive specific task however computationally complex model selection knowledge transfer application knowledge transfer technique complicate scenario adapt sample  model source domain obtain target learner source domain available source domain contains useful information potentially improves target learner knowledge specific domain smoothness target domain visual categorization task information across domain hidden visual appearance local symmetry layout capture feature descriptor fusion strategy helpful knowledge multiple feature knowledge transfer technique construct  model bicycle classifier classifier model contribution target model advance knowledge transfer  model filter model achieve effective transfer generalize adaptation situation knowledge transfer deem model selection typical multisource binary classification straightforward approach reduce prediction ambiguity model similarity auxiliary domain target domain apply closest model prediction target domain auxiliary domain target domain decision boundary inherit decision boundary however data auxiliary domain useful information prediction target domain data abandon knowledge transfer multiple auxiliary domain auxiliary domain auxiliary domain target domain subfigure denote auxiliary domain data correspond decision boundary auxiliary domain partition horizontal auxiliary domain partition vertical  combine decision boundary auxiliary domain ambiguous prediction target domain extend exist source knowledge transfer technique multiple source scenario evoke challenge leverage distribution difference multiple source domain promote prediction performance target domain task extend source knowledge transfer technique distribute algorithm statistical data source domain instead reveal content exist multiple source knowledge transfer extend correspond source algorithm structure manner IV svm adaptation scenario svm target classifier adapt exist source classifier sourcewhere perturbation function label data  target domain intuitively encounter multiple source domain dsm assume posse distribution primary domain adapt classifier construct ensemble source domain classifier FSM  sourcewhere predefined source classifier fsk sum mmd criterion apply obtain perturbation function formulate nli  xti αti coefficient label target domain kernel function induced nonlinear feature mapping apply kernel function source classifier expand   xti  xti sourcewhich sum kernel evaluation label xti xsi respectively target domain source domain obviously inefficient apply data disadvantage svm adaptation application disadvantage svm failure unlabeled target domain data  propose domain adaptation machine dam overcome disadvantage svm utilize unlabeled target domain data  data dependent regularizer define target classifier     sourcewhere       define decision target classifier source classifier respectively smoothness assumption domain adaptation dam minimizes structural risk function LS svm data dependent regularizer simultaneously dam formulate   yti   sourcewhere regularizer complexity target classifier target classifier dam sparse representation computation inefficiency svm overcome argue beneficial transfer relevant source domain source domain svm dam data dependant regularizer domain selection machine dsm source domain selection    predefined relevance source domain target domain domain selection indicator source domain objective function optimize source domain relevant target domain otherwise another advantage dsm exist transfer ability source domain target domain feature static sift feature source domain data spatio temporal ST feature target domain data function dsm formulate    sourcewhere   combination source classifier sift feature source domain  adaptation error function feature feature mapping function vector bias boost IV tradaboost relies source domain intrinsically vulnerable negative sample source domain avoid yao  propose boost approach multisource tradaboost task tradaboost knowledge transfer multiple source domain multisource tradaboost extension tradaboost multiple source domain instead weak classifier leverage source domain mechanism introduce apply weak classifier source domain relevant target domain iteration specifically training data source domain combine training data target domain generate candidate weak classifier iteration source domain independent multisource tradaboost approach significantly reduces negative transfer  knowledge transfer source domain potentially relevant target domain task tradaboost parameter transfer approach identify parameter various source domain task tradaboost constitute phase phase traditional adaboost employ extract suitable weak classifier source domain respectively assumption parameter source domain target domain source domain described explicitly implicitly label source domain data phase II adaboost loop target training data collection candidate weak classifier obtain phase iteration weak classifier classification error target training data picked ensure knowledge transfer relevant target task addition update target training data helpful candidate classifier boost target classifier  hidden knowledge transfer across visual domain appearance local symmetry symmetry quadruped partially layout layout torso limb employ knowledge transfer visual domain knowledge exists target data source data knowledge transfer uncertain alternately knowledge feature prior model knowledge fuse feature prior model construct target model instead predefined feature prior model  appropriate linear combination coefficient  classifier assure minimization domain mismatch motivate svm propose adaptive multiple kernel mkl cope considerable variation feature distribution video domain described svm target classifier adapt exist classifier source domain data svm employ multiple source classifier classifier fuse fix svm mkl learns optimal combination coefficient correspond  classifier minimize mismatch data distribution domain mmd criterion  knowledge transfer multi KT modifies norm regularizer LS svm objective function constrains hyperplane hyperplanes prior model regularization  hyperplane model determines amount transfer model constraint sample decision function   multi KT optimization propose multiple kernel transfer  learns hyperplanes correspond assign prior model unified optimization  utilizes prior knowledge expert evaluate query instance address knowledge transfer  solver addition training sample prediction predict prior model model intuition prior knowledge bicycle prediction image motorbike information useful model motorbike visual category prior built multiple feature instead meanwhile multiple source adaptation action recognition visual spatial ST exist action capture transfer knowledge multiple source target beneficial transfer apply locally ensemble lwe approach introduce fuse multiple classification model specifically  model bayesian model average approach computes posterior distribution prediction model posterior model training data distribution mismatch across target domain source domain model prior incorporate replace difference target source domain  sourcewhere  model locally adjust model effectiveness target data  achieve multiview fusion aggregate response mkl svm classifier correspond feature beyond binary decision  mkl svm solves standard svm optimization kernel define linear combination multiple kernel discussion multiple source svm intuitive extension svm assembles source domain classifier allocate source classifier dam dsm propose overcome disadvantage multiple source svm inefficiency failure unlabeled target domain data dsm precedes dam filter relevant source domain data introduce multiple source domain multisource tradaboost task tradaboost imperfection tradaboost compensate convergence multisource tradaboost inherit directly tradaboost whereas task tradaboost inherit directly adaboost convergence rate task tradaboost reduce upper bound multisource tradaboost iteration converge svm unlabeled data target domain mmd criterion mkl target classifier automatically optimal kernel combination theorem binary classification multi KT multi KT equivalent multiple source svm mahalanobis distance relationship svm PMT svm demonstrate connection multi KT PMT svm naturally discover VI evaluation analysis discussion benefit transfer performance improvement improve performance initial slope rapid growth performance  improve performance conduct representative knowledge transfer technique comparison criterion feature knowledge transfer comparison feature representation transfer II conduct pairwise combination  data combination demonstrate target demonstrate auxiliary training accord previous action recognition experimental setting correspondence mode partially label mode correspondence mode action scheme apply action orphan action target action video exclude establish correspondence approximately  sample randomly correspondence none correspondence label sample label partially label mode performance comparison mention correspondence mode II partially label mode respectively pairwise scenario II without WO transfer technique bilingual BW quantize aspect QA similarity metric SS continuous model aspect CV discriminative virtual VV transferable construct DL accord II DL significantly outperforms significant improvement WO treat camera source camera target  experimental restriction abandon correspondence instance label training instance target comparison    VV DL DL achieves significant improvement WO treat camera source camera target camera relatively weak performance camera actor action capture totally performance involve camera effectively demonstrate capability transfer BW VV DL significantly outperform QA SS CV however limitation former implicitly assume target query sequence II comparison feature representation transfer correspondence mode report pairwise combination  data correspond target correspond source comparison knowledge transfer partially label mode report pairwise combination  data correspond target correspond source classifier knowledge transfer conduct image classification action recognition task pascal voc data image classification ucf youtube HMDB data action recognition pascal voc data contains bicycle motorbike sample bicycle motorbike positive sample target domain source domain respectively sample remain negative sample target domain histogram orient gradient hog feature extract image image task bicycle classifier achieve binary decision sample belongs bicycle category category target classifier transfer information motorbike classifier via guidance bicycle sample  svm svm PMT svm DA svm  IV training interval DA svm achieves performance slope PMT svm achieves performance IV performance comparison image classification task svm svm PMT svm DA svm  model training bicycle motorbike source domain indicates training sample source domain ucf youtube action data realistic data contains camera shake clutter background variation actor variation illumination action ucf youtube data  dive golf swing binary action recognition task aim distinguish action  dive correspond source domain action HMDB data challenge data dense trajectory extract raw action video sequence spatial factor feature sample grid pixel tracked separately frame tracked frame median filter dense optical avoid drift trajectory limited frame hog hof MBH compute within volume along dense trajectory volume subdivide ST grid impose structural information representation llc cod scheme apply local dense trajectory feature  svm svm PMT svm  obviously overall performance transfer knowledge motorbike bicycle pascal voc data significantly outperforms performance transfer knowledge  dive ucf youtube data due relevance motorbike bicycle relevance action  dive addition visual video sequence capture image demonstrate image classification task training sample action recognition task significant improvement PMT svm outperform svm IV svm outperforms PMT svm training instance available PMT svm outperforms svm sufficient training instance available explain PMT svm relatively sensitive training sample performance comparison action recognition task svm svm PMT svm  model training  dive source domain ucf youtube data indicates training sample source domain additionally conduct action recognition task performance feature knowledge transfer technique FR  classifier knowledge transfer technique svm  transfer technique llc svd conduct described ucf youtube data HMDB data demonstrate VI  transfer technique llc svd  source domain data technique without source domain data conclude  source domain data target task degrade performance technique recently propose domain DL  achieves performance VI recognition ucf youtube data HMDB data source domain knowledge transfer multiple source domain demonstrate performance comparison multisource knowledge transfer quote experimental domain multisource knowledge transfer multisource knowledge transfer chose image data construct multiple source domain data NUS data consists image flickr data photo forum  com contains image consumer video data kodak data youtube data CCV data target domain performance evaluation former contains video birthday   sport wedding youtube kodak data latter contains video source domain training image randomly image source sift feature extract image source domain construct randomly sample relevant image irrelevant image cluster target domain static sift feature feature extract video sequence data  feature mel frequency cepstral coefficient audio feature extract CCV data feature hog hof MBH extract kodak youtube data standard svm  cannot handle domain adaptation data source target domain feature static sift feature classifier target domain  svm  dam  dsm data vii  simplify version dsm considers ST feature target domain standard svm  dam achieve equivalent performance data source domain data successfully observation  consistently outperforms related dam clearly demonstrates benefit employ relevant source domain source domain dsm achieves performance data demonstrates effectiveness integrate static sift feature ST feature conduct kodak data video youtube keywords evaluate performance svm  mkl transfer knowledge source image domain target video domain report standard deviation  standard svm mkl  mkl classifier sift feature classifier ST feature classifier sift ST feature standard svm svm svm evaluate svm sample target domain source domain svm sample target domain svm outperforms svm indicates directly source domain knowledge degrade recognition performance target domain  sift feature ST feature consistent evaluation classifier knowledge transfer indicates capture ST feature static sift feature effectiveness fuse average classifier multiple kernel mkl performance vii average precision  svm  dam  dsm kodak youtube CCV data standard deviation  classifier sift feature classifier ST feature classifier sift ST feature lwe fuse approach mkl svm approach    correspondence mode partially label mode IX multisource knowledge transfer overall correspondence mode significantly outperforms partially label mode correspondence mode lwe mkl svm achieve equivalent performance partially label mode mkl svm consistently performance IX transfer action recognition multiple auxiliary correspondence mode partially label mode vii conclusion survey review transfer technique visual categorization task knowledge useful knowledge transfer source domain feature source domain feature correspond label parameter  source domain model instance transfer inductive transfer parameter transfer respectively performance comparison knowledge transfer technique  transfer technique conclude  source domain data degrade performance demonstrates significance knowledge transfer transfer source domain knowledge target domain feature representation classifier feature representation knowledge transfer aim unify mismatch data visual domain feature classifier knowledge transfer aim target classifier parameter  source domain model data smoothness target domain feature representation knowledge transfer technique belong instance transfer inductive transfer classifier knowledge transfer technique belong parameter transfer avoid transfer negative knowledge adaptation strategy propose source domain achieve multiple source domain knowledge fusion transfer improve performance target domain model target domain label data sufficient otherwise knowledge transfer meaningless research transfer focus data cannot reflect potential advantage transfer regular machine technique future challenge transfer aspect information helpful target domain highly noisy source domain data extend exist transfer source domain data