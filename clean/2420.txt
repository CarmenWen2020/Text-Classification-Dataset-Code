series classification TSC address analyse spectrum algorithm nevertheless notion spike non spike neural network nns performance TSC task seminal reservoir compute RC random recurrent neural network categorize efficient nns apply TSC although RC architecture absolutely dynamic temporal data processing fails achieve significant improvement fully trainable nns along thread proposes novel algorithm training reservoir fuse nonlinear optimal theory reservoir compute RC theory approach optimize RC predict estimate specific timestamp along desire trajectory purpose TSC task reformulate nonlinear optimal conducive approximate reservoir spike non spike neuron adaptive approximate dynamic program adp propose framework trainable reservoir compute RC involves online actor critic project output error reservoir parameter adjust ensure classification error minimize evaluate TSC adaptability newly propose RC framework NN univariate multivariate series datasets UCR  datasets perform finding divulge propose framework outperforms RC capacity accuracy attains classification accuracy comparable fully trainable neural network introduction series data TSD sequence observation indexed TSD widely various engineering economics  environment medicine direction significant research conduct aim assign label TSD TSC category classical NN scope limited reservoir compute subcategories NN classical aggregate subcategories model distance feature model building model fitting parameter auto regressive AR model limited stationary series distance rely develop pre define distance function similarity series instance NN dynamic warp dtw vector machine svm feature extract meaningful feature series bag feature framework  bag  boss shapelets typically classical shortcoming generally craft data preprocessing discretization manual feature engineering distance addition computational complexity another classical distance classical desirable investigation detail mention refer exist comprehensive review however due availability data rapid development neural network neural network model employ TSC task approach harness ability nns complex function automatic feature extraction multi layer perceptron mlp multi convolutional neural network MCNN residual network resnet fcn recurrent neural network rnn reservoir compute RC successful NN approach apply TSC task despite achievement NN shortcoming address mlp propose discriminative classifier temporal data feature longer invariant automatic feature approach NN cnn successful meantime MCNN preprocessing sample skip sample slide hyper parameter complicate deploy contrary fcn resnet preprocessing feature engineering TSD feedforward architecture non spike neuron mlp MCNN resnet fcn mainly non temporal static data processing individual input data independently sequentially fed input model embed temporal dependency within input data network architecture recurrently spike non spike neuron rnns uniquely dynamic temporal data processing faculty model ability temporal dependency input dynamical behavior however network realize capacity memory input dynamic data processing particularly task series classification moreover training recurrent algorithm  backpropagation BPTT recurrent  complex vanish explode gradient interpret biological perspective another significant challenge involves elaborate training neural network spike neuron adapt backpropagation feasible spike neuron output dirac delta function rcs avoid random dynamical hidden layer layer untrained initialization asymptotic stability correspond dynamical consequently training limited decoder layer supervise fashion input sequence network neuron reservoir neuron feature processing RC model successfully apply temporal computational temporal classification temporal prediction temporal generation however seminal RC RC random hidden layer shallow trainable neural network usually fails sufficient capacity complicate online task regard propose model improve decode capability substitute linear output layer nonlinear layer svm nns decoder layer despite nonlinear decoder improve rcs performance evidence nonlinear decoder proven significantly superior linear decoder instance inferior linear decoder observation reservoir linearly separable representation nonlinear decoder almost advantage increase susceptibility fitting contrary reservoir structure parameter chosen properly suitable representation input data nonlinear decoder sufficiently dataset training nonlinear decoder yield basis infer RC performance highly appropriate initialization parameter reservoir heuristic grid propose address issue although useful guarantee optimality reservoir parameter therefore  online despite rcs sole focus training decoder appropriate initial reservoir individual task recent endeavor tune reservoir parameter unsupervised supervise mode involves application unsupervised machine lsm neucube purpose rank RO spike timing dependent plasticity STDP apply organize neucube synaptic recognize spatio temporal finding demonstrate reservoir leaky integrate lif neuron synapsis unsupervised increase performance RC temporal classification forecasting task researcher claimed superiority neucube traditional machine algorithm knn svm mlp TSC spite achievement neucube temporal classification forecasting unsupervised efficient reservoir parameter complex approach neural engineering framework  feedback online local propose reservoir supervise mode successful application temporal forecasting temporal generation however rare successful implementation model temporal classification task despite theoretical capability rcs temporal data numerous RC fail achieve comparable accuracy series classifier shortcoming previous RC approach involves  inherent characteristic dynamical rcs address aforementioned limitation motivation maximum capacity RC TSC task background introduces formulation reservoir parameter tune nonlinear dynamical overcome shortcoming consequently principle nonlinear optimal theory apply derive optimal reservoir aim analyze role reservoir parameter TSC task propose framework nonlinear theory purpose minimizes classification error timestamp RC dynamical analogous mathematical perspective propose underlie hamilton jacobi bellman HJB equation HJB sufficient optimality respect loss function however impossible reservoir dynamic adaptive dynamic program adp formulation reinforcement RL obtain HJB achieve reservoir propose output error neuron observable variable fed reservoir adp estimate parameter minimize classification error reservoir parameter approximately feedback disable evaluation univariate multivariate uci  datasets confirm propose framework improves accuracy RC achieves performance rate parallel resnet fcn TSC task contribution introduction framework obtain via fusion nonlinear optimal theory reservoir compute improve temporal data processing proposition biologically plausible reinforcement reservoir adp apply reservoir employment propose framework prediction remainder structure briefly describes relevant literature elaborates propose network architecture detail benchmark datasets report sect finally conclusion future sect background scope focus reservoir compute nonlinear optimal theory temporal data processing briefly describes definition theory neural network architecture closely link propose framework series temporal data classification series classification TSC important challenge data mining gain insight mechanism generate series employ predict series label series data sequential data typically successive mathematically define triplet variable dependent output variable label unknown association function respect input  sample  output variable belonging therefore classification task timestamp series dataset define dataset vector belonging contributes otherwise recent variety classical machine technique NN dtw shapelets NN mlp residual network encoder rnn RC developed TSC comprehensive overview recent development classical depth detail mention however outside scope reservoir compute series classification RC network neural information processing treat data temporal dynamic RC model propose independently echo network esn machine lsm model primarily esn rate neuron sigmoid tanh relu contrast lsm spike neuron leaky integrate lif   HH izhikevich  etc consequently lsm spike information transmission neuron biologically plausible concern architecture RC model similarly compose input layer hidden recurrent layer reservoir allows RC capture dynamic information information fade output layer decoder readout characteristic RC input  recurrent connection within reservoir untrained decoder  conventional algorithm linear regression gradient descent hence functionality RC model input data express via procedure input data transform spatiotemporal dimensional rnn reservoir encode spike  supervise perform decoder model recall data seminal RC RC rnn reservoir   reservoir random fix decoder arrow image research focus improve performance rcs heuristic grid gear towards appropriate initial reservoir application multi reservoir another approach seek improve decode capability replace linear output nonlinear output layer recently neucube propose capture characteristic spatiotemporal data spike neural network SNN architecture structure propose model resembles structure lsm consist input data encode layer encodes continuous input data spike hidden 3D recurrent SNN cube layer  SNN classifier layer learns supervise mode classify spatiotemporal  activity important neucube contrary RC reservoir parameter random constant neucube utilizes unsupervised enhance performance diagram architecture recall neucube model input data encode continuous input spike SNN reservoir unsupervised temporal data SNN reservoir training evolve SNN decoder supervise mode model optimization iteration parameter maximum accuracy achieve model recall data principle diagram neucube image various neucube neucube neucube neucube RT developed enhance performance seminal neucube model apply graph input mapping grid genetic algorithm quantum inspire evolutionary graph achieve performance finally widely accepted RC NN powerful temporal dynamic data theoretically achieve performance however capacity network effectively adaptive approximate dynamic program dynamic temporal data universal therefore becomes theoretically practically significant stability optimal emerge research topic theory hamilton jacobi bellman HJB equation sufficient optimality crucial role acquire optimal nevertheless explicit HJB equation optimal model linear dynamic consideration quadratic function minimize acquire linear feedback equivalent HJB standard  equation however model nonlinear dynamic HJB equation nonlinear partial differential equation pde generally impossible obtain almost rcs nonlinear HJB nonlinear vital issue adp novel approximate optimal scheme recently become topic optimal approach aim approximate policy obtain nearly optimal HJB equation architecture adp mainly compose critic actor network network parameterized online offline manner critic NN utilized evaluate action function direction action improvement actor NN implement action critic NN function approximate function actor NN achieve approximation optimal policy numerous investigation conduct theoretical practical development adp achieve significant performance optimal nonlinear instance  developed actor critic technique feedback discrete dynamical optimal policy online data along trajectory  lewis online AC strategy infinite horizon optimal nonlinear author propose online adaptive algorithm involves simultaneous tune actor critic neural network  lewis propose actor critic AC nns algorithm optimal partially unknown discrete nonlinear adp linear unknown dynamic online approach infinite horizon continuous nonlinear propose zhao developed optimal uncertain continuous nonlinear partially unknown recently considerable research advanced actor critic algorithm deploy series advanced neural network information entropy confidence exploration improve accuracy conventional actor critic complex task propose framework propose approach proceeds classify temporal data combination reservoir compute nonlinear optimal theory overall schema propose approach schematic propose architecture plastic feedforward pathway consists encode layer fix random parameter reservoir trainable parameter decoder layer pre training constant reservoir training feedback pathway nonlinear optimal apply estimate reservoir parameter consists actor critic neural network subplot reference trajectory subplot trajectory predict online image propose framework TSC reformulate optimal purpose output vector series imitate series reference trajectory illustrate subplot reservoir dimensional nonlinear dynamic continuous therefore continuous formulation HJB equation adp apply derive optimal derive propose framework output predict mimic reference trajectory subsection elaborate network architecture detail network architecture dynamic propose framework consists feedforward feedback pathway feedforward module input data encode layer reservoir recurrent neural network linear classifier output function feedback module compose critic neural network actor neural network diagram propose framework architecture significant propose framework contrary RC reservoir parameter fix random trainable reservoir compute RC utilizes trainable parameter improve performance addition contrary neucube reservoir mechanism unsupervised fashion RC effective supervise mechanism functionality propose architecture encode layer project input reservoir spike neural network data vector convert discrete spike suitable processing spike reservoir spike neural network discrete spike pre training mandatory training optional supervise algorithm gradient descent etc employ adjust decoder parameter associate training sample decoder constant reservoir training reservoir training RL algorithm propose subsection apply reservoir temporal relation input desire output adjust parameter reservoir adp adp mechanism neural network actor critic utilized approximate reservoir parameter model recall data feedforward pathway resembles structure lsm esn however methodology feedback pathway propose differs significantly classical artificial intelligence approach remark sake brevity dependence suppress denote variable dynamical instance notation rewrite moreover math math correspond meaning illustrate central propose framework reservoir recurrent network structure denote adjacency matrix  reservoir consists neuron membrane potential dynamic described     membrane potential reservoir neuron lipschitz nonlinear dendrite     lipschitz leak function non spike neuron input reservoir respectively spike neuron filter spike activity neuron spike neuron exp moreover linear decoder assume  equation reservoir characteristic dynamical consequently principle optimal theory apply derive optimal purpose reformulate series classification output error denotes desire output input correspond predict output derivation respect error dynamic described decoder  assume constant reservoir training classification error dynamic reservoir dynamic rewrite neural    input parameter reservoir   reservoir parameter   matrix conclude  nonlinear continuous equation dynamic theory   wherein   drift dynamic   input dynamic recommend action regard realize persistence excitation PE sake data rank TSC goal adapt reservoir parameter error timestamp input minimize reservoir parameter input remains bound function define      utility function input constant positive hyper parameter ensure error function sufficiently effective hence optimal function   typical assumption continuous lipschitz  ultimately desirable achieve optimal input update stabilizes minimizes function input admissible formulate error dynamic function dynamic optimization HJB equation utilized hamiltonian function associate input define  partial derivative function admissible policy assume smooth optimal function   satisfies HJB equation  optimal reservoir update optimal obtain differentiate hamiltonian respect derivative zero optimal function obtain   insert optimal nonlinear lyapunov equation formulation HJB equation  reservoir HJB equation function substitute obtain desire although HJB sufficient optimality respect loss function unfortunately due nonlinear characteristic reservoir HJB equation explicit impossible derive propose framework focus adp approximate therefore online actor critic algorithm propose utilized approximate optimal reservoir update optimal evident propose consists neural network critic NN action NN mention model objective tune critic minimize bellman equation error objective adjust actor minimize approximate update critic NN action NN respectively     rate activation function actor NN tune        rate tune parameter brevity article reader refer reference article finally respect reservoir parameter update derive   completes reservoir reservoir feedback pathway via actor critic nns output network estimate reference trajectory widely theory sufficiently feedforward pathway without feedback classify input acceptable accuracy discussion description datasets definition baseline model experimental propose framework TSC datasets evaluate performance propose perform UCR  series classification archive UCR  archive contains publicly available series datasets variable dataset sample sample training data dataset split training datasets characteristic experimental purpose detail datasets described UCR  datasets detail benchmark approach propose propose framework handcraft feature neural network benchmark datasets multi layer perceptron mlp mlp baseline architecture TSC consists layer fully output previous layer layer softmax classifier fully previous layer output contains neuron dataset hidden layer compose neuron relu activation function layer precede dropout operation rate respectively fourth layer mlp epoch batch convolutional neural network cnn network compose convolution sigmoid activation function average pool convolution contains filter filter finally flatten output convolutional layer output layer sigmoid neuron epoch batch fully convolutional neural network fcn network built stack convolutional contains operation convolution batch normalization fed relu activation function output convolutional average dimension corresponds gap layer finally traditional softmax classifier fully gap layer output convolutional consists filter filter respectively network epoch batch multi convolutional neural network MCNN MCNN architecture compose convolution fully layer softmax layer MCNN identity mapping sample skip sample slide WS preprocess data convolution filter sigmoid activation function max pool operation network epoch convolutional neural network network compose consecutive convolutional layer respectively filter local average pool operation convolution adopt sigmoid activation function finally fully layer neuron dataset output layer epoch batch net lenet lenet convolution layer sub sample perform max pool fully layer softmax classifier enable extract feature label predict convolution contains filter temporal span max pool convolution layer filter span previous max pool convolution relu activation function epoch batch residual network resnet network built stack residual gap globally average polling layer softmax classifier neuron dataset residual compose fcn convolutional filter convolution output residual input fed seminal reservoir compute RC RC fix random recurrent network reservoir linear decoder reservoir compose smooth lif neuron  synapsis percent connectivity neucube network architecture described subsection cube lif neuron  network WKNN classifier decoder RC propose framework network architecture consists recurrent network reservoir linear decoder reservoir parameter propose described subsection reservoir compose smooth lif neuron  synapsis percent connectivity initialization reservoir epoch implement  simulator tensorflow software library due limited training sample benchmark datasets computational resource training entire reservoir parameter training tailor parameter characteristic datasets remain parameter assume fix random mention propose consists hyper parameter chosen matrix positive definite consequently derivative lyapunov function negative task exposition reader refer      identity matrix appropriate instance adam rate optimizer stabilize model error decrease bound compact surely appropriate accuracy experimentally examine valid hyper parameter task simulation execute intel core ghz cpu GB ram geforce gtx  gpu performance benchmark datasets propose contemplate characteristic propose framework training prediction classification performance benchmark datasets glance recognize propose slightly conventional algorithm due error feedback predict constrain closely timestamp sufficient quantity input throughout behavior illustrate CBF dataset consequently classification error nearly training epoch zero convergence estimate output desire output training iteration CBF dataset remark detail image training classification error simulation online image remark compose subfigure subfigure input signal subfigure input subfigure subfigure probability input assign probability others addition repeatedly mapping reservoir subfigure predict subfigure depicts decode activity neuron reservoir cast probability generally input purple vertical dash marked unique evaluation propose framework CBF data pink dot correspond explicit discriminative remark detail image evaluation propose framework wafer data explicit discriminative remark detail image conduct evaluate propose framework benchmark clearly propose framework classification decision timestamp datasets sequence input identify discriminative propose framework depict pink dot input sample propose framework exist discriminative classify input accuracy despite observation datasets fail confirm existence explicit discriminative task nevertheless propose framework classify input appropriate amount input data evidence propose framework capability temporal dependency classify input acceptable accuracy experimental wafer dataset explicit discriminative another deduction contrast majority model restrict static vector propose framework temporal data therefore propose framework classify input data limited information propose framework presumably prediction capability albeit prediction primary goal ability forecast occurrence future limited available information important application disaster warn medicine forecasting financial crisis criminal investigation propose model evaluate analysis classification accuracy model percent input prediction benchmark datasets propose framework accord average ratio prediction accuracy classification accuracy entire input evaluate datasets linear relationship instance ratio percent input percent respectively confirm propose framework limited available information classify input capability available model comparative analysis UCR  classification prediction accuracy performance comparison baseline standard deviation classification accuracy propose framework baseline depict thorough evaluation benchmark datasets summarize accord accuracy propose framework significantly reservoir specifically RC neucube therefore deduce propose tune reservoir parameter effective improve rcs performance TSC objective additionally RC consistently outperforms model fcn resnet comparable performance evidence reveal dataset characteristic effective reduce propose framework performance model propose framework performance datasets meaningful temporal relationship earthquake ECG lightning contrary performance datasets meaningless temporal relationship instance   etc principal observation investigate difference traditional propose framework conventional static vector data non temporal feature TSC image classification consequently existence lack temporal relationship significantly affect performance counter wise propose framework derive nonlinear optimal enable ability temporally correlate varied data connectivity reservoir reflect temporal relationship dynamic data absence meaningful temporal relationship effective reduce performance comparison average accuracy obtain benchmark model benchmark data image UCR  classification reservoir neuron reservoir neuron accuracy propose framework RC investigate classification accuracy neuron accord relationship reservoir neuron accuracy majority evaluate benchmark datasets accuracy steadily increase neuron trend datasets accuracy remains incremental ECG dataset datasets CBF insignificant therefore deduce accuracy RC improve increase reservoir neuron however neuron  beyond specific improvement become insignificant finding datasets series characteristic input important determinant appropriate neuron reservoir deduction extend RC datasets CBF ECG datasets ECG increase neuron merely fluctuation model accuracy datasets wafer insignificant improvement accuracy accuracy neuron RC RC propose framework RC RC connectivity RC connectivity image decoder although linear decoder assume propose framework nevertheless proceed empirically investigate RC implement nonlinear decoder influence classification accuracy mlp architecture hidden fully layer nonlinear decoder mlp architecture examine twice neuron fully layer benchmark datasets finally difference aforementioned nonlinear decoder linear decoder benchmark datasets sketch negative relationship reservoir neuron improvement nonlinear decoder accuracy neuron increase effectiveness nonlinear decoder improve accuracy decrease nonlinear decoder improvement reservoir neuron reservoir neuron benchmark datasets nonlinear decoder effective     netflow remain datasets likelihood interpret training richness reservoir propose framework collapse linear separable representation nonlinear decoder training yield datasets slightly improve decoder alter plot difference accuracy obtain RC propose framework nonlinear decoder linear decoder benchmark datasets standard deviation image conclusion future propose framework dynamic temporal data processing exploit merit reservoir compute nonlinear optimal theory purpose typical classification reformulate optimal adp obtain reservoir obtain RL algorithm output predict reference trajectory closely moreover framework systematic convergence stability  stable error converge zero reasonable assumption framework exhibit important characteristic discriminative generative fading memory dimensionality nonlinearity input dependent response examine mention characteristic TSC propose framework evaluate data although performance ideal RC equip propose accuracy RC model achieves comparable accuracy series classifier fcn resnet empirically effectiveness propose model absence generic structure critic actor nns satisfy  memory consumption shortcoming intend framework deteriorate accuracy computational complexity prospective overcome deficiency reservoir compute reformulation feedback pathway respectively finally propose framework enable appropriate ability model dynamical temporally correlate data connectivity reservoir reflect temporal relationship dynamic data however mainly focus discriminative characteristic propose framework hence confine TSC nevertheless propose framework  extend online offline engineering application propose adp derive nonlinear theory significant improvement generative nonlinearity discriminative due issue propose framework effective series prediction generation nonlinear application output adapt unknown dynamic beyond TSC hence future encourage address issue optimize propose framework