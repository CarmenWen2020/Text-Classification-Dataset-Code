computational evaluate neural network usually depends choice layer layer actual input upon residual network resnets efficient adaptive neural network building propose architecture replaces sequential layer iterative structure reuse multiple input image reduce storage requirement drastically addition incorporate adaptive computation module allows network adjust computational input sample independently experimentally validate model image classification detection semantic segmentation task model capacity hardest input sample efficient average introduction neural network typically defines fix pipeline operation input sample undergoes operation obtain consequence input exactly computational regardless complexity content input neural network architecture aim performance average sample dataset approach network network capacity handle hardest input network majority input visual constant processing recognize familiar almost instantaneously complex unfamiliar scene network network training adapt computational complexity input image capacity hardest input sample experimentally validate approach image classification detection semantic segmentation task model parameter adjust computational complexity input image qualitatively analyze input hardest accord model corresponds understand difficulty remainder structure overview previous approach resource efficient neural network focus adaptive computation residual network basis approach explain iterative network architecture validate computer vision task default benchmark datasets conclude pointer future extension previous workshop extend thorough explanation architecture investigation role choice performance detection semantic segmentation task addition image classification task related neural network dnns achieve breakthrough decade application recognition translation robotics complex arguably computer vision around convolutional neural network cnns graphic processing gpus achieve benchmark datasets cnns imagenet competition beating competitor margin cnns replace shallow architecture computer vision task neural network powerful extract hierarchy complex feature amount raw data instead rely craft feature define expert combine amount compute gpus allows increasingly powerful model limited image classification technique detection semantic segmentation image super resolution traditional task style transfer image generation image caption depth overview refer resource efficient impressive accuracy dnns model scratch without prior information amount label data costly obtain article focus however computational processing input sample architecture easily billion float operation FLOPs megabyte memory training model involves multiple training however training model typically offline compute infrastructure distribute training algorithm machine model relatively quickly model deployed inference inference computationally demand training application model resource constrain device mobile phone drone sensor node wearable intrinsic limitation consumption limited network bandwidth challenge dnns propose technique reduce computational dnns inference popular technique reduce precision operation inference typical implementation float operation network float reduce precision extreme binary activation although incurs penalty classification accuracy task neural network typically  prune network remove unnecessary heuristic gradient information magnitude propose identify redundant complicate technique rely bayesian statistic reinforcement technique prune zero sparse matrix network reduce efficient zero approach potential inference multiplication involve zero skip efficiently however custom hardware adaptive computation neural network adaptive network architecture computational complexity input technique mechanism allows network return prediction network confident technique reinforcement selectively activate network network computational accuracy network network unable confident prediction approach input dependent spatially transforms feature conditional feature spatial transformer network perform transformation rotation specific input sample apply input image propose differentiable layer network effectively learns sample resolution input selects input data contains relevant information avoids evaluate network entire image naively downsampled version intelligent downsampling extremely useful semantic segmentation task architecture adaptive computation algorithm introduce algorithm combination recurrent neural network rnns network computational input emit output approach minimal network fully deterministic differentiable later extend  adaptive computation  allows network amount computation input image approach developed dynamic convolution gate dynamically apply convolution input image thanks efficient cuda implementation outperform efficient model MobileNetV  residual network residual network resnets imagenet competition proven important breakthrough resnets operation convolutional neural network layer completely transform input instead layer learns residual input seemingly minor difference important implication resnets deeper layer stochastic gradient descent addition deeper network residual connection network robust delete reorder layer network destroys cnns layer random layer training layer inference explanation observation  resnet layer parallel resnet architecture residual layer input output delete layer model corrupt remain intact traditional architecture input output completely corrupt operation parallel resnet interpret ensemble network explanation behaviour resnets iterative estimation viewpoint argue successive layer iteratively refine estimate feature instead compute entirely representation layer already computes rough estimate feature representation iteratively refine successive layer explains robustness resnets delete reorder layer iterative refinement behaviour formalize resnets closely related highway network shortcut connection although highway network gate function regulate information memory network lstms relationship residual network recurrent neural network rnns  visual cortex observation recurrent neural network equivalent resnet layer  generalization rnns resnets biologically plausible model   visual cortex adaptive computation mechanism model allows computational recognize input  visual cortex recognize faster familiar iterative neural network architecture introduce novel iterative neural network building explain residual network architecture exploit efficient iterative structure building residual network contains convolutional layer batchnorm relu activation convolution receives input channel convolution reduces tensor channel convolutional layer convolution expands channel input output dimension sum passing network resnet built stack grouped stage within stage residual convolutional filter spatial stage  input convolution stride stage input spatial previous stage typical resnet stage residual stage determines network resnet residual stage respectively resnet respectively channel stage typically resnet input convolutional layer filter batchnorm relu activation stage network applies global average pool fully layer return predict output building resnet bottleneck architecture expansion rate image resnet built stack residual grouped stage within stage input filter image propose iterative estimation resnets reduce memory footprint computational within stage residual rough estimate feature representation stage extract completely instead refinement layer stage feature behavior extreme reuse multiple within stage architecture stage collapse hence replace sequential layer iterative structure reduces model drastically propose building convolutional layer layer filter normal resnet instead shortcut connection initialize input equation iteration pas equation output convolutional layer equation iteration refine previously extract feature input equally recognize easy input rough estimate feature accurately classify input input refine feature estimation adaptive computation network layer fully network output equation iterate stage adaptive computation allows adaptation iteration input   equation operation perform building iterative network image building described algorithm closely algorithm configure iteration task network predict halt scalar iteration cumulative sum halt remainder cumulative sum halt iterate within architecture output define sum iteration halt correspond iteration iteration remainder ensures sum network iteration introduce ponder iteration plus remainder minimize ponder increase halt likely computation earlier network gradient descent simultaneously minimize entropy classification loss ponder network layer fully network hidden neuron apply global average pool output convolution concatenate vector passing network apply global average pool reduce feature indicates feature activate network return halt sigmoid activation ensure halt network optimize simultaneously parameter network initialize bias output neuron network maximum iteration training phase resnet implementation batchnorm convolutional layer batchnorm statistic multiple iteration instead statistic iteration approach iterative model memory footprint conventional resnets thanks adaptive computation mechanism allows model automatically adjust computational complexity input image model efficient average conventional resnets reduce consumption evaluate model consumption model rarely report literature estimate depends strongly hardware platform consumption pas model dominate memory access operation retrieve feature dram memory access easily accumulate operation reuse multiple potentially reduce consumption load memory amortize multiple iteration efficiently however likely custom hardware additional choice iterative bottleneck structure convolutional layer normal resnet convolution reduces channel convolution spatial feature convolution channel bottleneck structure efficient expensive convolution input data difference channel input intermediate channel expansion rate typically however arbitrary factor model explore impact expansion rate technique reduce computational depthwise separable convolution normal convolution input volume channel slide convolutional kernel volume kernel width height channel input volume kernel generates output convolutional layer typically applies multiple kernel parallel obtain output volume multiple channel convolutional kernel actually performs task simultaneously spatial feature combine information multiple channel depthwise separable convolution explicitly perform task independently depthwise convolution spatial feature input channel separately pointwise convolution combine information channel generates output volume depthwise separable convolution parameter operation normal convolution therefore popular building resource efficient architecture replace convolution depthwise convolution report impact classification accuracy parameter computational introduce architecture previous stayed resnet architecture replace stage iterative multiple iterative replace resnet stage increase capacity network increase parameter computational explore experimentally validate approach benchmark datasets image classification cifar cifar datasets explore impact choice accuracy memory footprint computational model empirically model adapt computational complexity input image report image classification task imagenet dataset resnets network architecture building network task detection semantic segmentation exist model detection image segmentation replace resnet backbone iterative network report impact accuracy memory footprint computational task computational model complexity input image image classification explain differently resnets residual stage typically resnet variant parameter computational accumulate operation mac accuracy cifar dataset respectively network stochastic gradient descent sgd momentum epoch initial rate rate reduce factor epoch random horizontal flip image training model training nvidia gtx gpu report theoretical accumulate operation calculate pytorch flop counter  objective metric computational metric perfect model accumulate operation memory footprint throughput consumption activation parallelism hardware iterative network iteration stage residual correspond stage resnet network iteration stage respectively cifar dataset version expansion rate parameter accuracy model report average accuracy standard deviation accuracy multiple around resnet resnet variant architecture model drastically parameter model expansion rate parameter tenfold reduction parameter resnet model expansion rate memory footprint model somewhat surprisingly model actually achieve accuracy resnet model likely regularizer resnet model probably  task cifar resnet  image architecture computational fix depends input accumulate operation average overall image upper bound upper bound slightly computational resnet convolution overhead execute iteration average however architecture computation resnet intel xeon 0GHz cpu core actual iterative model resnet baseline model architecture depthwise separable convolution immediately reduces parameter computational accuracy baseline resnet model average mac operation closer upper bound previous suggests depthwise separable convolution cannot capture complexity normal convolution iteration converge feature estimation depthwise separable convolution clearly reduce parameter theoretical computational improve accuracy computational parameter cpu standard resnets iterative network cifar accuracy computational parameter standard resnets iterative network cifar accuracy computational parameter imagenet network cifar dataset dataset complicate contains image observation cifar model parameter operation baseline resnet model obtain classification accuracy accuracy model depthwise separable convolution severe cifar task cifar finally model challenge imagenet dataset dataset contains image grouped around training validation image summarize parameter computational accuracy commonly network model computational memory footprint depthwise separable convolution replace expensive convolution shuffle operation architecture extensive automate architecture procedure default resnet model architecture parameter respectively float network resnet  resnet resnet computation comparison iterative model report accuracy obtain training resnets scratch data preprocessing resnets  rescale image dimension random random horizontal flip training rescale image input normalize zero variance network stochastic gradient descent sgd momentum epoch initial rate rate reduce factor epoch report resnet accuracy slightly report resnet report accuracy author report resnet report resnet obtain iterative network summarize network  model exactly resnet parameter resnet computational iterative network  average sample reduction accuracy iterative network  expansion rate instead reduces parameter computational accuracy model  replaces stage resnet iterative instead allows network complex feature improve accuracy almost model somewhat surprisingly average computational slightly model iteration motivation architecture automatically allocate resource complexity input objectively complexity input impose predefined image complex network instead network ability training image complicate network necessarily complicate vice versa approach insight behavior neural network perform task typical sample data image iteration subsequent iteration indeed model adjust computational complexity input image difficulty input accord model correlate definition difficulty empirically easy image typically image image typically unclear imagenet dataset hardest image typically landscape scene analyze error rate function iteration model image summarize cifar dataset datasets behavior error rate image amount iteration image model iteration error rate increase hypothesis model allocates resource input harder recognize misclassified horizontal graph error rate model typical image iteration image iteration image classification datasets error rate cifar model input model iteration iteration increase error rate increase input harder model recognize horizontal error rate model image detection previous focus image classification task predict entire image investigate complicate task detection input image localize annotate bound classify varies image exist implementation faster cnn adapt implementation iterative network faster cnn commonly network detection detection network faster cnn pretrained convolutional neural network backbone extract feature input image feature predict roi potentially checked prediction combine obtain prediction entire image backbone network usually vgg resnet network replace pretrained  previous tune task task pascal visual challenge dataset dataset contains around sample within annotate input image parameter computational average precision  faster cnn architecture backbone network resnet backend model parameter computational average average precision comparable model vgg backend parameter typical image predict bound label image amount iteration subsequent iteration iteration correlate understand complexity easy image typically hardest image typically analyze relationship iteration axis truth axis sample image although relationship noisy image truth typically computation plot iteration function average truth computational decrease average increase confirm intuitive observation image easy network image resnet backbone cnn network computational regardless visible difficulty input image accuracy computational parameter faster rcnn model backend network typical image iteration image iteration detection task image hardest network image correlation truth iteration average truth iteration model computational complexity input image image semantic segmentation semantic segmentation task predict label pixel input image complex task image classification label predict entire image network architecture task typically encoder decoder architecture encoder extract feature creates compress representation image decoder representation predict label pixel encoder usually network image classification decoder upsampling operation transpose convolution adapt  architecture pretrained  encoder model mit ADEK scene parse dataset ADEK source dataset semantic segmentation scene parse contains image indoor outdoor scene goal image image associate semantic category training image validation image model resnet backend model parameter computation average typical validation image sort easy input image truth segmentation output model respectively somewhat surprisingly image amount iteration clutter scene image network classify attribute scene boundary background easy network decision hardest image accord model landscape scene identify boundary intersection union iou computational parameter semantic segmentation task typical image iteration image iteration segmentation task input truth output model respectively network struggle scene distinguish boundary conclusion future exploit iterative refinement resnets efficient neural network building reuse multiple reduce memory footprint dramatically validate approach benchmark datasets image classification detection semantic segmentation model adjust computational runtime complexity input data resource average adaptive computation mechanism approach explore possibly video processing application computation frame previous frame stayed resnet architecture probably optimal therefore explore adaptive computation combination efficient architecture shufflenet improve average computational architecture computational calculate float operation evaluate network necessarily correlate perfectly actual runtimes device research implement algorithm efficiently hardware platform fully exploit potential tvm compile model optimize code specific hardware platform crucial deploy neural network optimize operation specific hardware platform orthogonal approach optimize architecture network approach compatible network benefit optimization operator fusion layout transformation keywords efficient neural network inference adaptive computation resource constrain