currently graph convolutional network gcn achieve significant progress recommender due remarkable capability representation ability integrate complex auxiliary information however graph convolution operation prone smooth due graph laplacian operator node embeddings become multi layer graph convolution decrease recommendation performance recently propose model simplify gcn relieve issue extent however model viewpoint gcn inspire recent development label propagation algorithm LPA propose recommender model unifies graph convolutional network label propagation algorithm specifically utilize gcn recommendation prediction model unify LPA regularization training proven effectively alleviate smooth addition introduce attention network capture attention user item account user attach importance various relationship item extensive datasets demonstrate propose algorithm significant improvement recommendation algorithm introduction recommender RSs role internet economic benefit business offering personalize suggestion collaborative filter widely RSs recommendation interaction user item utilizes implicit user feedback input suffers inability model auxiliary information item attribute merge information popular convert feature vector supervise model user item ID factorization machine FM NFM  etc exist feature supervise treat interaction data instance fail connectivity user movie director collaborative filter emphasize user movie feature supervise focus movie director situation identity director actor  etc movie correspond identity explore tackle gcn model achieve prominent progress due remarkable capability representation ability integrate complex auxiliary information social network knowledge graph core gcn iteratively aggregate target node express embed target node proven effective fully mining connectivity graph thereby enrich representation user item  leverage attentive embed propagation layer importance information recursively information however graph convolution technique employ graph laplacian easy smooth node representation becomes multi layer graph convolution simply operation  user preference decrease recommendation performance limitation influx recommender model simplify gcn  empirically demonstrates feature transformation nonlinear activation increase difficulty training positive model similarly LRGCN empirically demonstrate graph convolution layer stack model performance degrades therefore model usually reduce network layer remove nonlinear transformation however model perspective graph convolution gcn propagates transforms node feature information along graph label propagation algorithm LPA propagates node label information therefore model solely gcn prone limited feature influence lack node information perspective investigate theoretical relationship gcn LPA propose recommender model GCNLP exist gcn model integrate LPA assist gcn model alleviate smooth easily gcn specially utilize gcn prediction LPA regularization training addition introduce attention network capture attention user item considers user assign importance various relationship item evaluate effectiveness propose model conduct comprehensive model baseline movielens dataset lastfm dataset dataset algorithm outperforms recommendation algorithm sum contribution propose novel algorithm integrate label propagation graph convolutional network recommendation leverage LPA assist gcn regularize effectively alleviate smooth introduce attention network capture attention user item account user attach importance various relationship item perform extensive public datasets superiority propose recommender experimental algorithm outperforms algorithm related exist recommender model incorporate knowledge graph KG roughly embed gcn embed usually apply knowledge graph embed KGE algorithm encode knowledge graph item integrate item auxiliary information recommendation framework instance  recommendation model applies TransE KG triplet knowledge aware embed item matrix factorization MF capture user dynamic propose  model integrate entity embed embed cnn framework news recommendation aggregate embed historical clicked sequence user representation subsequently propose algorithm treat recommendation task link prediction entity another trend strategy adopt multi task joint  model simultaneously task recommendation knowledge graph completion investigate various connection item knowledge graph additional guidance recommendation propose  model extract meta computes item item similarity refines representation item propose  model user user similarity user item similarity  model directly meta similarity enhance user item interaction matrix therefore user item comprehensively subsequently  model account relevance distinct user limitation meta expression ability propose  model substitute meta graph meta contains richer connectivity information meta capture similarity entity accurately reduce meta selection propose  model learns relation item explore item connectivity gcn mainly focus information aggregation mechanism specifically incorporates information node update representation ego node propagation perform recursively information multi hop node encode embed therefore model connectivity  connects user item interaction KG heterogeneous graph employ aggregation mechanism recently inspire recent theory simplify GCNs verify feature transformation nonlinear activation gcn negative recommendation performance propose  achieves SOTA performance recently  leverage strategy propagate collaborative signal knowledge awareness signal respectively  merge gcn model propagate interaction node neighborhood meta sum embed apply KGE preprocess KG obtain embeddings entity integrate recommendation framework however informative connectivity KG ignore explain recommendation utilize KG massive manually meta labor intensive consume gcn benefit KGE technique semantic however model solely gcn prone smooth although alleviate simplify gcn deem lack node information perspective argue integrate LPA gcn alleviate smooth therefore propose recommender model integrate LPA gcn introduce recommendation formulate label propagate algorithm graph convolutional network message propagation explore relationship gcn LPA necessity graph convolution operation improve recommendation performance finally accord theoretical guidance integrate LPA gcn recommender model formulation recommender knowledge graph described denote user item respectively user item interaction matrix  define user implicit feedback define user item interaction matrix    otherwise  denotes interaction user item otherwise  knowledge graph available consists massive entity relation entity triplet denote relation knowledge triple respectively denote entity relation respectively goal predict probability user click item movie recommendation scene formulation knowledge graph objective predict probability click image label propagation algorithm label propagation algorithm LPA assumption node likely label graph denotes node adjacency matrix  entry node denotes feature matrix node label node detail label matrix predict label node iteration initial label matrix denotes label vector node label zero vector node label diagonal matrix label node LPA express   equation indicates representation node average node addition demo label propagation demo label propagation assume label propagate node label node unlabeled information propagate label node unlabeled node node reset initial propagation finally node node image graph convolutional network graph convolutional network gcn multi layer feedforward network propagates transforms node feature graph formulate   denotes matrix layer activation function layer node representation consistent LPA treat normalize adjacency matrix instead  feature propagation gcn layer formulate  LPA target node representation sum node  relationship LPA gcn assume node graph label unlabeled investigate relationship gcn LPA perspective influence initial feature label output feature label slightly technically feature label influence jacobian gradient output feature label respect initial feature label denotes layer embed gcn initial embed calculate feature influence compute label influence node node LPA LPA iterative algorithm influence cumulative influence relu activation function gcn denotes node finally feature influence label influence satisfy equation  detail proof equation refer normalize feature influence compute  equation prof label influence initial feature vector affect output feature vector extent intuitively indicates feature influence label influence instead therefore LPA potential replace gcn training graph convolution operation node update formula gcn  equation decompose aggregation compute aggregate embed neighborhood  transformation aggregate embed convert representation aggregation distance node embed reduce define  distance metric finally proof firstly compute hessian  obvious  matrix eigenvalue within eigenvalue within therefore positive semi definite matrix deduce equation aggregation distance node reduce aggregation combine node belong gcn potentially categorize item user interested category assist model improve recommendation performance unified model overall framework GCNLP model firstly utilize KG triple    input assign initial embeddings secondly utilize inner user embeddings relation embeddings importance relationship user target node accord attention transform KG graph attention layer thirdly graph gcn training generate entity embeddings item embeddings perform label propagation graph another item embeddings finally leverage inner user embeddings item embeddings denote prediction architecture detail subsection illustration GCNLP model architecture target node accord attention transform KG graph secondly graph gcn training generate entity embeddings item embeddings perform label propagation graph another item embeddings finally leverage inner user embeddings item embeddings denote prediction image phase convert heterogeneous KG graph characterize user preference purpose introduce user specific relation aware attention function  user importance relation accord formula   denote user embeddings relation embeddings intuitively  denotes importance relation user knowledge graph unweighted graph relationship displayed introduce  knowledge graph convert graph scene graph usually alleviate computational burden introduce receptive node uniformly sample fix entity priority selection fix neighborhood define   denotes embed entity denotes normalize user relation     treat graph adjacency matrix entry    relation entity KG define feature matrix entity dimension entity feature leverage multiple network layer update entity representation layer wise propagation formulate        denotes matrix representation entity layer embed item denote sub graph mention diagonal matrix entry   therefore normalize maintain stability entity representation matrix  denotes layer specific matrix nonlinear activation function layer gcn prediction define inner user representation item  user embed obtain user embed lookup layer rank recommendation generation unlike traditional gcn input data constant  trainable model introduce user relation function operation strengthens model fitting optimization increasingly prone smooth sole source supervise signal user item interaction furthermore crucial role graph representation regularization facilitate training entity representation likely seek item user demonstrate LPA potential replace gcn training therefore update LPA algorithm regularize performance item remove label predict unmarked item remain label item prediction label propagation prediction define inner user item  update reduce difference label  item predict label formulation algorithm depth receptive user item compute receptive obtain neighborhood representation gcn finally calculation LPA gcn finally obtain unify gcn LPA loss function    entropy loss function regularizer balance hyper parameter corresponds gcn learns trainable matrix corresponds label propagation treat constraint regard regularization assist gcn complexity analysis layer wise propagation core operation layer computational complexity matrix multiplication  training dataset involve interaction denote previous transformation prediction layer attention layer complexity inner overall complexity propose model  conduct extensive evaluate propose algorithm aim research RQ GCNLP algorithm perform recommendation algorithm RQ component LPA GCNs affect performance GCNLP RQ propose GCNLP algorithm perform data sparse scenario evaluation datasets evaluate effectiveness GCNLP algorithm conduct comprehensive benchmark datasets  FM respectively movielens  movie rating dataset widely evaluate recommendation algorithm employ version rating user rating  dataset contains  information user lastfm online user item interaction  dataset contains rating community datasets explicit feedback convert implicit data item marked user interacts item addition user item interaction construct item knowledge dataset addition user item interaction data construct item KG dataset specially leverage microsoft satori construct knowledge graph dataset sample subset triple entire KG sub graph dataset triple ID triple sample triple statistic datasets statistic datasets experimental setting evaluation metric user randomly item user interact user sample unobserved user disliked negative item performance rank judged ratio HR normalize discount cumulative gain NDCG HR calculate user ranked item formulate    GT collection datasets NDCG accumulate rank highlight retrieval relevant metric DCG define    grade relevance recommendation NDCG user define     recommendation return user average metric NDCG define    additionally evaluate homogeneity user preference metric coverage define   item user indicates recommender recommends item user baseline implement GCNLP algorithm python library  baseline  optimizes MF model pairwise rank loss tailor implicit feedback employ fix rate parameter report  typical recommendation algorithm combine traditional matrix factorization multi layer perceptron extract dimensional dimensional feature recommendation  framework utilize KG recommendation  adopts preference propagation KG continuously automatically discover user potential hierarchical  bipartite neural network encode historical interaction information user item embed improve recommendation importantly  explicitly considers connectivity user item enhance representation ability embed LRGCN eliminates nonlinearity gcn simplify network structure introduce residual network structure alleviate smooth achieve substantial improvement recommend accuracy  parameter setting randomly dataset training latent dimension model baseline model parameter accord setting mention author GCNLP model batchsize rate datasets  movielens dataset  lastfm dataset  dataset hop movielens lastfm performance comparison RQ performance HR NDCG competitive algorithm respect latent dimension dimension respectively latent dimension performance model fluctuates within easy gcn model perform model worth mention LRGCN baseline   datasets GCNLP LRGCN algorithm superior algorithm adopt datasets dataset GCNLP algorithm weaker LRGCN algorithm HR metric GCNLP algorithm performs LRGCN algorithm NDCG metric metric NDCG GCNLP LRGCN algorithm significantly outperform algorithm lastfm  datasets metric HR gcn model perform significantly model lastfm datasets sum baseline GCNLP algorithm achieve experimental datasets HR NDCG performance GCNLP algorithm baseline datasets latent dimension image graph convolution operation easy smooth  user preference performance coverage gcn model adopt datasets GCNLP LRGCN perform datasets perform alleviate homogeneity user preference coverage GCNLP datasets respectively coverage LRGCN datasets algorithm increase respectively sum gcn baseline GCNLP algorithm performs data fully reflect superiority algorithm coverage datasets image performance recommend rank GCNLP LRGCN algorithm demonstrate consistent improvement across conduct sample verify improvement statistically significant baseline algorithm gap algorithm performance datasets comparable worth NDCG gcn model significantly model  dataset fusion auxiliary information effective improve accuracy recommendation evaluation item recommendation datasets image GCNLP algorithm baseline movielens lastfm datasets experimental GCNLP algorithm typically cope almost baseline consistently LRGCN algorithm however underperforms GCNLP algorithm LRGCN simplify gcn reduces network layer remove nonlinear transformation improve performance adjacency matrix user item interaction matrix constant LRGCN fails importance user various relationship contrast GCNLP algorithm entry   characterize importance user various relationship leverage embeddings attention user item aggregate accurately capture user preference algorithm combine KG attention mechanism effective improve recommendation performance model combine label propagation algorithm alleviate smooth gcn model gcn performance model significantly improve worth mention HR LRGCN GCNLP relation GCNLP performance limited extent ablation RQ conduct ablation GCNLP LPA GCNs affect performance addition seek explain efficient influence LPA GCNLP influence label propagation algorithm LPA GCNLP ablation remove LPA model GCNLP HR performance GCNLP gcn clearly GCNLP performs gcn datasets HR GCNLP datasets respectively HR gcn datasets GCNLP increase respectively HR performance GCNLP gcn datasets image NDCG performance GCNLP gcn almost conclusion GCNLP performs gcn datasets NDCG GCNLP datasets respectively NDCG gcn datasets GCNLP increase respectively NDCG performance GCNLP gcn datasets image coverage performance GCNLP gcn GCNLP performs gcn datasets coverage GCNLP datasets respectively  gcn datasets GCNLP increase respectively coverage performance GCNLP gcn datasets image sum HR NDCG improvement GCNLP gcn almost within  dataset improvement rate NDCG coverage improvement rate GCNLP gcn exceeds datasets LPA positive impact improve accuracy model significant increase coverage rate model significantly alleviate smooth gcn influence GCNs recommender model investigate influence GCNs recommender model conduct combine traditional gcn LPA worth traditional gcn adjacency matrix directly user item interaction matrix model remain abbreviate combination model GCNLP comparison fix hyper parameter embed rate batchsize etc report HR NDCG benchmark datasets  GCNLP model significant improvement intuitively due gcn superior traditional gcn model entry   characterize importance user various relationship however traditional gcn constant relation entity explicitly model fails user attach importance various relation item GCNLP performs effective GCNLP comparison performance HR NDCG GCNLP GCNLP sparse scenario analysis RQ experimental training ratio movielens datasets parameter fix omit lastfm conclusion integrate KG recommender model alleviate data sparsity extent performance algorithm deteriorates reduce training HR decrease     LRGCN GCNLP respectively ofr experimental sparse user item interaction performance gcn model superior algorithm GCNLP algorithm sensitive density user item interaction performs LRGCN algorithm data sparse scenario HR movielens ratio training overall data sparsity critical challenge recommendation scenario solely utilize user rating input data tough information recommend item satisfy user data sparse scenario leverage KG auxiliary information effective improve performance data sparse scenario KG useful address issue due semantic information experimental GCNLP algorithm data sparse scenario GCNLP algorithm effective address data sparsity extent conclusion developed recommender model unify graph convolutional network label propagation algorithm argument gcn benefit semantic embed KG semantic naturally embed propagation however exist gcn easy smooth preference user become homogeneous address utilize label propagation algorithm assist gcn model regularize addition introduce attention network capture attention user item account user attach importance various relationship item conduct comprehensive public datasets demonstrate effectiveness GCNLP algorithm experimental algorithm outperforms algorithm future particularly interested explore dynamic recommendation although gcn recommendation model achieve prominent progress due remarkable ability representation training consume circumstance online shopping news recommendation forum user preference affected social activity recommendation static preference model capture user effective explore exploit connection user comparably compact candidate potential medium user another leverage dynamic graph network capture user preference combine deem integrate sort auxiliary information KG dynamic recommendation future trend keywords recommender smooth graph convolutional network label propagation algorithm