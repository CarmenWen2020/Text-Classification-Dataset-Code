investigate hebbian strategy apply convolutional neural network cnn training unsupervised approach hebbian winner HWTA hebbian principal component analysis HPCA hebbian layer cnn extract feature classification without backpropagation backprop experimental comparison unsupervised backprop variational auto encoder VAE training completeness supervise hebbian variant supervise hebbian classifier SHC contrastive hebbian CHL training classification layer stochastic gradient descent training investigate hybrid methodology network layer hebbian approach others backprop approach mnist cifar cifar datasets hebbian generally suitable training feature extraction layer retrain network layer training epoch backprop moreover hebbian outperforms VAE training HPCA perform generally HWTA access auckland library introduction error backpropagation algorithm backprop training neural network variety task however neuroscientist doubt biologically plausible model brain biologically plausible mechanism hebbian principle neuron principle formulate variant hebbian computer hebbian winner HWTA competition allows neuron perform cluster data another variant  allows perform principal component analysis pca data online fashion essence hebbian algorithm employ extract feature data biologically plausible efficient online unsupervised task context convolutional neural network cnns various network layer feature extractor layer extract feature layer extract progressively feature therefore hebbian algorithm promising option training network previous already hebbian variant suitable training relatively shallow network layer appeal application constrain device instance preliminary HWTA competition effective layer pre network achieve comparable backprop training epoch potential application context transfer apply hebbian deeper network architecture perform detailed investigation HWTA analyze hebbian principal component analysis HPCA cnns hebbian algorithm unsupervised another popular unsupervised backprop approach namely variational auto encoder VAE deem report obtain supervise backprop training equivalent network impact methodology training specifically layer network network various approach mnist cifar cifar datasets evaluate quality feature extract layer feature linear classifier evaluate accuracy adopt simplify network model focus evaluate performance complex network model approach appropriate architecture layer network allows perform extensive experimentation insight paradigm network layer evaluate quality feature extractor layer layer basis furthermore ass impact switch backprop hebbian training layer layer hybrid model network layer backprop others hebbian hybrid model preliminary involve HWTA dataset comprehensive evaluation HWTA HPCA datasets although hebbian unsupervised approach supervise variant propose literature concept teacher neuron couple purely hebbian refer classifier approach supervise hebbian classifier  approach alternation hebbian anti hebbian update phase supervision signal alternate strategy contrastive hebbian CHL another contribution experimental evaluation classifier SHC CHL various datasets confirm hebbian integrate backprop comparable accuracy network layer training epoch moreover feature hebbian training outperform VAE feature classification task HPCA variant perform generally HWTA contribution summarize hebbian winner HWTA nonlinear hebbian principal component analysis HPCA variant properly integrate convolutional layer convolutional HWTA HPCA apply feature extractor cnns various datasets obtain unsupervised VAE potential limitation highlight deem report supervise backprop training discussion experimental evaluation hybrid neural network training scenario network layer backprop others hebbian approach supervise hebbian variant various datasets remainder structure sect background related literature sect describes scenario investigation hebbian integrate convolutional layer hybrid network model SHC CHL classifier sect  detail experimental setup sect simulation illustrate finally sect conclusion outline future development background related neuron vector input  neuron output hebbian express mathematically    update vector  vector update latter compute accord hebbian  rate basically synapse reinforce input synapse output neuron simultaneously therefore connection neuron activation correlate reinforce hebbian update decay image hebbian WTA prevent unbounded decay generally context competitive obtain   intuitive interpretation input vector neuron vector update closer input neuron respond strongly input input neuron vector converges cluster input hebbian update winner competition image multiple neuron involve complex network winner WTA strategy adopt neuron correspond cluster input input WTA layer neuron vector closest input elect winner winner perform update vector closer input input future neuron likely strategy allows neuron perform cluster data recent WTA variant WTA neuron activation elect winner apply context computer vision layer cnn extract feature image perform classification paradigm context spike neural network SNNs approach suitable relatively shallow network layer achieve accuracy around cifar mnist comparable backpropagation approach network depth author preliminary dataset cifar apply hebbian WTA cnns layer obtain training network backprop WTA approach unsupervised supervise hebbian variant propose classification layer confirm approach effective training shallow network approach effective training layer classifier pre network addition algorithm epoch backprop converge novel contribution respect previous extensive experimentation perform multiple datasets mnist cifar cifar novel explore addition hebbian WTA hebbian pca explain sub moreover VAE comparison backprop unsupervised finally perform involve supervise CHL SHC comparison approach sgd training hebbian pca accord definition WTA enforces quantize information encode layer neural network neuron activates encode presence input neural network backpropagation exhibit distribute representation multiple neuron activate combinatorially encode input improve cod importance distribute representation highlight distribute cod scheme obtain neuron extract principal component data achieve hebbian perform hebbian pca vector various neuron minimize representation error define  subscript refers  neuron layer operator linear neuron zero data reduces classical pca objective maximize output variance vector  constraint assume input data around zero average input beforehand minimizes objective    nonlinear neuron neuron activation function representation error minimize nonlinear version hebbian pca  variant hebbian pca approach explore literature linear apply context computer vision relatively shallow network apply nonlinear version hebbian pca deeper network explain supervise hebbian hebbian approach unsupervised hebbian adapt supervise approach supervise hebbian classifier SHC contrastive hebbian CHL classifier SHC  concept teacher neuron ideally target signal trainable neuron teacher signal replaces actual output neuron hebbian principle apply reinforces correlation input teacher output input neuron tends response SHC realize apply principle combination specifically teacher signal becomes teacher signal input correspond associate neuron otherwise neuron vector converge towards centroid cluster input associate target neuron suppose detect CHL network alternate processing stage phase clamped phase phase ordinary processing occurs denote input output neuron phase respectively anti hebbian update compute phase accord formula clamped phase neuron output clamped desire input output neuron clamped phase regular hebbian update perform approach approximate backprop training mild biologically plausible hebbian fashion CHL apply training linear classification layer replace classifier output teacher signal clamped phase input phase update update equivalent gradient descent update linear classifier error mse loss hebbian cnns approach hebbian cnns introduce strategy integrate hebbian convolutional layer technique extend hebbian approach supervise addition introduce neural network architecture evaluate approach hybrid hebbian backprop modality convolutional HWTA HPCA hebbian cnns define integrate convolutional layer neuron horizontal vertical offset convolutional layer constrain previous handle convolution hebbian extract random patch image processing patch sequentially patch convolutional filter approach poorly parallelizable exploit information image update average horizontal vertical dimension image convolutional constraint approach adapt neuron portion image compute update apply desire input patch extract image specific horizontal vertical average update horizontal vertical dimension update apply kernel neuron horizontal vertical location mini batch input training update average perform mini batch dimension SHC CHL classifier evaluate hebbian  supervise implement SHC CHL classifier classifier feature extract pre network freeze already network layer  teacher signal target output neuron input similarly CHL classifier accord phase output ordinary output classifier clamped phase output target network architecture evaluation focus evaluate performance complex network architecture aim evaluate hebbian approach supervise backprop VAE various setting accordingly define model perform insight approach various network layer evaluate quality feature extract network layer layer basis architecture practical reproduce researcher subsection illustrate network architecture evaluation procedure neural network architecture neural network consists layer layer plus linear classifier various layer interleave processing stage relu nonlinearities max pool etc architecture inspire alexnet fully layer remove neuron slightly modify finer grain analysis various approach HWTA HPCA approach supervise backprop VAE discus detail VAE supervise backprop training neural network image image variational auto encoder unsupervised unsupervised hebbian approach another popular unsupervised namely variational auto encoder VAE VAE architecture network model layer encoder fully layer mapping output feature gaussian latent variable representation specular network decoder encoder decoder architecture variational auto encoder VAE image backprop training supervise mainly focus unsupervised approach hebbian VAE nonetheless deem supervise backprop discussion purpose report obtain training network architecture model supervise stochastic gradient descent sgd training entropy loss metric evaluate internal network layer discus sect aim evaluate hebbian approach affect capability feature extractor various layer neural network layer layer basis evaluate quality feature extract various layer model network correspondence various layer linear classifier already layer classifier network layer evaluate accuracy achieve classify correspond feature hebbian network VAE network supervise backprop network deem discussion classifier layer network image hybrid network model implement hybrid network scenario network layer backprop others hebbian approach ass impact accuracy replace backprop layer hebbian equivalent model construct replace upper layer pre network training scratch algorithm meanwhile layer remain frozen avoid adaptation upper layer various configuration layer hybrid network model image detail training implement pytorch footnote hyperparameters parameter coordinate descent CD maximize validation accuracy respective scenario CD hyperparameter coordinate hyperparameter perturbed hyperparameter configuration evaluate hyperparameters update direction perturbation improvement hyperparameter accord CD previous validation model hyperparameters validation accuracy improvement obtain concern datasets mnist dataset contains training sample sample handwritten digit training sample sample actually training validation cifar cifar datasets training sample sample respectively image training sample sample actually training validation obtain generalization training session chose model network epoch validation accuracy training network network architecture model fed rgb image pixel input network stochastic gradient descent sgd error backpropagation entropy loss HPCA nonlinearity relu function HWTA hebbian training classifier SHC approach accord training perform epoch although hebbian approach convergence typically achieve epoch mini batch sgd training initial rate constant epoch halve epoch remain epoch momentum coefficient nesterov correction contrarily standard momentum corrects accumulate momentum gradient estimate update direction nesterov update momentum direction applies correction accumulate momentum gradient estimate location ahead strategy optimization trajectory improves convergence dropout rate penalty improve regularization recall regularization loss function penalize decay coefficient mnist cifar cifar HPCA HWTA training rate regularization dropout overfitting issue HWTA training image preprocessed whiten transformation described although significant training VAE training VAE training network perform fashion network training obviously unsupervised image encode decode task specifically model VAE variational bound unsupervised criterion coefficient penalty dropout decoder remove feature extract encoder layer classification training classifier internal layer sgd linear classifier various network layer supervision described training network rate penalty reduce CHL classifier desire target teacher signal rate penalty SHC linear classifier various network layer rate rate schedule regularization hybrid network training hybrid network model various combination hebbian backprop layer training perform approach training network backprop split network desire remove layer replace hebbian layer hebbian layer HWTA HPCA described layer remain frozen network layer backprop layer hebbian splitting chosen hebbian layer remove hebbian layer desire replace backprop layer retrain layer sgd layer frozen network alternate backprop hebbian backprop layer sgd training hybrid network layer layer perform described penalty layer splitting ultimate penultimate layer hence retrain layer subsection experimental mnist cifar cifar datasets datasets accuracy obtain linear classifier feature extract network layer ass quality respective feature classification task unsupervised HPCA HWTA VAE training mainly focus unsupervised deem report supervise backprop BP training discussion report obtain retrain layer network pre backprop epoch convergence ass potential hebbian approach task involve retrain network layer classification layer SHC appendix perform CHL network layer accuracy training epoch supplementary appendix hybrid training comparison SHC CHL sgd classifier perform independent iteration average compute confidence interval mnist sub analyze behavior hebbian approach scenario digit recognition mnist dataset classifier internal layer report mnist accuracy obtain classifier various layer network report obtain network respectively supervise backprop BP VAE HPCA HWTA mnist accuracy confidence interval feature extract convolutional network layer unsupervised approach typically suffer decrease performance deeper layer exploit supervision signal enables formation task specific feature essential boost performance layer HWTA VAE training HPCA approach alleviate accuracy remains constant deeper layer HPCA approach exhibit increase almost respect HWTA feature extract fourth convolutional layer hebbian feature behave comparably VAE feature layer improvement fifth layer moreover hebbian approach performance respect backprop feature extract layer application hebbian training relatively shallow network training network layer aim replace network layer classifier hebbian approach supervise hebbian algorithm classifier achieve accuracy comparable backprop training epoch respectively suggests potential application context transfer mnist accuracy confidence interval convergence epoch obtain retrain layer pre network supervise backprop BP HPCA approach HWTA approach cifar previous sub relatively image recognition task involve digit aim analyse hebbian approach slightly complex task involve image recognition cifar dataset classifier internal layer report cifar accuracy obtain classifier various layer network report obtain network respectively supervise backprop BP VAE HPCA HWTA cifar accuracy confidence interval feature extract convolutional network layer HWTA VAE approach suffer decrease performance deeper layer HPCA approach alleviate accuracy remains constant deeper layer HPCA approach exhibit increase almost respect HWTA feature extract fifth layer research gap backprop layer desirable hebbian approach suitable biologically plausible alternative backprop training network hebbian feature behave VAE feature layer improvement fifth layer moreover hebbian approach comparable performance respect backprop feature extract layer application hebbian training relatively shallow network training network layer aim replace network layer classifier hebbian approach supervise hebbian algorithm classifier achieve accuracy comparable backprop peak performance layer replace training epoch respectively suggests potential application context transfer cifar accuracy confidence interval convergence epoch obtain retrain layer pre network cifar sub analyse scalability hebbian complex task image recognition involve namely cifar evaluate accuracy cifar contains previous datasets classifier internal layer report cifar accuracy obtain classifier various layer network report obtain network respectively supervise backprop BP VAE HPCA HWTA cifar accuracy confidence interval feature extract convolutional network layer VAE HWTA approach suffer decrease performance deeper layer HPCA approach alleviate accuracy remains constant deeper layer HPCA approach exhibit increase almost respect HWTA feature extract fourth convolutional layer hebbian feature behave comparably VAE feature layer improvement fifth layer moreover hebbian approach competitive performance respect backprop feature extract layer HPCA improve BP layer application hebbian training relatively shallow network training network layer aim replace network layer classifier hebbian approach supervise hebbian algorithm classifier achieve accuracy comparable backprop performance layer HPCA training epoch respectively suggests potential application context transfer moreover HPCA performs HWTA cifar accuracy confidence interval convergence epoch obtain retrain layer pre network pro con hebbian conclude pro con hebbian approach emerge pro hebbian effective training feature extractor feature VAE classification task effective training network layer epoch approach hybrid combination hebbian backprop improve performance appendix con hebbian effective training intermediate layer HPCA reduction gap unsupervised supervise latter preferable network training combination hebbian backprop layer immediate explore various network configuration conclusion future summary hebbian approach suitable training feature extraction layer layer pre neural network training epoch suggests potential application context transfer experimenter tune network layer pre model task hebbian approach outperform VAE training reduce gap unsupervised supervise backprop training moreover HPCA perform generally HWTA moreover supplementary appendix hybrid combination backprop hebbian layer helpful offering performance hebbian supervise backprop alone integration hebbian emerge topic however encourage motivate direction future improvement explore complex feature extraction strategy formulate hebbian variant independent component analysis ICA sparse cod promising apply hebbian enhance network architecture alone algorithm combination backprop inductive bias regularization semi supervise fashion hebbian already application context meta differentiable plasticity model hebbian  improvement apply advanced hebbian finally exploration behavior algorithm respect adversarial deserves attention keywords hebbian neural network biologically inspire