novel convolutional layer perturbed convolution PConv performs convolution operation dropout PConv focus achieve goal simultaneously improve generative adversarial network gan performance alleviate memorization discriminator memorizes image dataset training progress PConv perturbed feature generate randomly disturb input tensor perform convolution operation approach surprisingly effective output perturbed tensor layer discriminator robust feature local lipschitz input tensor randomly perturbed training procedure dropout neural network memorization alleviate generalization ability propose conduct extensive various loss function datasets cifar celeba celeba HQ LSUN imagenet quantitative evaluation demonstrate PConv effectively boost performance gan conditional gan  inception distance fid introduction generative adversarial network gan convolutional neural network cnns achieve rapid advancement various application image inpainting image image translation text image translation however suffers instability training procedure goal gan training nash equilibrium non convex continuous dimensional parameter gan substantially complicate neural network supervise alleviate researcher propose novel network architecture discriminator generator although successfully generate resolution image challenge datasets imagenet fundamental instability gan training instead modify network architecture various propose normalization regularization technique penalize discriminator alleviate instability gan training widely normalization technique spectral normalization imposes lipschitz constraint matrix discriminator approximation singular regularization introduce gradient regularization gradient penalty penalizes gradient norm generate sample propose another gradient regularization constrains magnitude gradient around sample stabilize regularization technique directly regularizes gradient norm gradient calculate respect generate sample normalization regularization technique effective improve performance gan however researcher normalization gradient regularization performance slightly improve fails improve recent argue memorization another instability gan training mention discriminator memorizes image dataset training progress memorization occurs disrupts training dynamic degrades generate image quality severe datasets memorization occurs datasets imagenet alleviate researcher apply data augmentation technique translation zoom  approach effectively prevent memorization improve gan performance despite extensive ongoing effort develop normalization regularization data augmentation technique fundamental challenge knowledge previous attempt develop convolutional layer alleviate propose convolutional layer specialized discriminator perturbed convolution PConv PConv contains dropout layer effectively discriminator achieve goal simultaneously boost generative adversarial network gan performance moderate memorization discriminator memorizes image dataset training progress propose perturbed feature randomly disturb input tensor prior perform convolution operation PConv surprisingly effective output perturbed tensor layer discriminator robust feature local lipschitz input tensor randomly perturbed training procedure dropout neural network memorization alleviate replace standard convolutional layer perturbed convolutional layer propose easily apply exist network architecture without impose training overhead additional computational demonstrate generalization ability propose conduct series various datasets cifar celeba celeba HQ LSUN image net quantitative evaluation propose significantly improves performance gan conditional gan  inception distance fid summary contribution summarize propose novel convolutional layer PConv performs convolution operation dropout propose easily apply exist gan without modify network architecture propose significantly boost performance gan without training overhead additional computational finally conduct extensive ablation demonstrate generalization ability propose various datasets experimental setting gan propose superior performance gan standard convolutional layer overall framework propose contrary standard convolutional layer propose disturbs input tensor conduct convolutional operation perturbed feature image background generative adversarial network gan consists generator discriminator network simultaneously nonetheless goal optimize visually appeal sample whereas distinguish generate sample procedure summarize objective function       objective function discriminator generator respectively addition random vector sample random normal distribution data distribution  respectively improve stability training modification conduct instance apply error objective function  whereas compute loss wasserstein distance generate distribution WGAN another commonly adopt gan formulation hinge version adversarial loss   max max  widely employ hinge version adversarial loss enforce spectral normalization discriminator discriminator generator conditional gan focus conditional image actively research conditional gan usually employ conditional information label text generator discriminator data generation procedure formulate       training network generator image category generate employ gan framework memorization discriminator avoid overfitting model various usually adopt label preserve data augmentation technique mask flip rotation data local affine distortion inspire approach moderate memorization discriminator researcher apply data augmentation technique training gan particularly zhao conduct extensive various demonstrate data augmentation technique effective avoid memorization discriminator instead data augmentation apply dropout technique layer discriminator alleviate memorization however argue traditional dropout strategy alleviate memorization however degrades performance gan attempt apply conventional dropout approach moderate memorization performance drastically degrade dropout ratio increase observation conventional dropout technique suitable gan illustration gan training 2D gaussian mixture model network reveal trend perturbed convolutional layer module image propose propose novel convolutional layer moderate memorization dropout technique effectively improves performance gan overall framework propose depict conduct convolutional operation propose randomly disturbs input tensor random mask randomly channel random constant others built tensor consist constant channel procedure dropout technique channel perturbed randomly ratio channel perform procedure randomly channel others therefore PConv input feature define output convolutional kernel respectively tensor broadcasting random mask employ intermediate layer mask operation meaningful discriminator classify generate image input tensor randomly perturbed PConv robust feature subsequent convolutional layer minimize adversarial loss successfully become indicates perturbed feature indicates local lipschitz constant lipschitz constant output discriminator perturbation therefore simply replace standard convolutional layer PConv discriminator robust feature local lipschitz constant PConv constraint global lipschitz constant discriminator robust feature layer validate effectiveness propose gan network architecture consist multiple fully layer dimensional 2D gaussian mixture model GMMs comparison discriminator replace fully layer perturbed fully layer illustrates experimental training gan consist standard fully layer suffers mode collapse whereas gan perturbed fully layer learns GMMs successfully propose superior standard convolutional layer gan training extensive detailed implementation code PConv tensorflow described random mask perform convolutional layer PConv contains trivial multiplication operation compute quickly propose incur training overhead multiplication operation slightly convolution operation argue PConv impose training overhead addition PConv discriminator affect phase generates image generator python code perturbed convolutional layer tensorflow image indeed anticipate PConv conventional spatial dropout SDrop randomly channel input feature however difference propose conventional existence random specifically SDrop randomly channel zero whereas propose feature channel difference gan training theoretical validity assumption dimensional vector output convolutional layer scalar indicates convolutional layer contains kernel vector SDrop apply convolutional layer variation define     perturbed vector minimum maximum project onto respectively instance   contrast apply PConv becomes   zero random described PConv output without variation SDrop  variant feature discriminator SDrop decision boundary generator addition dropout ratio becomes minimum boundary increase SDrop PConv therefore propose sensitive dropout ratio SDrop probability feature apply SDrop PConv SDrop PConv image reveal effectiveness random operation PConv conduct toy output vector PConv SDrop input feature randomly channel specifically zero random constant output vector SDrop PConv respectively probability feature SDrop PConv depict SDrop generates discrete vector confine whereas PConv continuous vector handle entire although  SDrop PConv feature output vector PConv perturbed smoothly effective generator SDrop network architecture generator image resolution network architecture discriminator image resolution implementation detail generalization ability PConv conduct extensive various datasets cifar LSUN celeba celeba HQ imagenet subset imagenet consist image LSUN randomly image per training indicates built LSUN dataset image image celeba LSUN datasets resize pixel whereas image imagenet resize pixel evaluate generation performance resolution image utilized celeba HQ resize image pixel employ hinge version loss adversarial objective function network architecture resblock utilized replace conv discriminator PConv resblock discriminator resblock generator image comparison propose SDrop cifar fid marked bold parameter generator discriminator PConv differentiate perform optimization adam optimizer stochastic optimization adaptive estimation parameter adam optimizer respectively rate iteration training decrease rate linearly conventional update generator discriminator update mini batch cifar celeba LSUN datasets batch generator iteration respectively addition celeba HQ imagenet network iteration batch respectively worth generator batch twice discriminator instance cifar dataset discriminator batch whereas generator batch propose contains hyper parameter determines channel randomly training procedure described sect perturbed discriminator feature training discriminator generator specifically generator synthesize image feature classify generate image discriminator feature classify image feature training generator adversarial becomes unstable feature discriminator generator employ generator discriminator architecture consist multiple residual baseline model detailed network architecture generator discriminator resblock architecture described discriminator utilized spectral normalization layer discriminator sample feature average pool convolutional layer average pool whereas sample interpolation perform convolutional layer generator performance evaluation metric evaluate generator image employ popular assessment  inception distance fid metric visual appearance diversity generate image wasserstein distance distribution generate image feature obtain inception model fid express fid trace  covariance sample distribution generate image respectively fid quality generate image performance fid generate image cifar LSUN celeba imagenet image celeb HQ comparison standard convolution SDrop PConv cifar classification accuracy comparison fid datasets cifar marked bold quantitative comparison evaluate performance PConv various datasets ablation cifar dataset network scratch performance gain due lucky initialization discus difference propose SDrop SDrop performance propose propose stable performance increase contrast performance SDrop drastically degrade becomes reliable conduct additional randomly SDrop training procedure indicates verify SDrop performance  zero statistically dropout ratio randomly instance statistical dropout ratio whereas  becomes zero described SDrop random dropout ratio denote SDrop trend SDrop although  becomes zero SDrop convert randomly channel zero disturbs adversarial comparison fid loss setting cifar marked bold indeed depict SDrop discrete vector channel bernoulli dropout however mitigate gaussian dropout perturbs feature sample distribution indicates SDrop gaussian dropout entire feature PConv gan performance SDrop gaussian dropout denote SDrop described SDrop stable SDrop becomes reveal gan stably entire feature continuously although SDrop performance propose outperforms SDrop approach conclude PConv effective boost gan performance SDrop approach performance PConv significantly conduct comparison propose standard convolutional layer cifar celeba LSUN imagenet fid marked bold furthermore investigate PConv alleviate discriminator memorization verify overfitting conventional image classification technique generally classification accuracy gap training therefore gap classification accuracy serious overfitting approach cifar dataset training image respectively thereafter gan training sample adversarial image discriminator output zero discriminator hinge version adversarial loss propose exhibit accuracy gap training standard convolutional layer observation PConv effectively alleviates memorization discriminator although SDrop moderate memorization propose effective adversarial mention conventional dropout technique effectively moderate memorization however degrade performance gan goal alleviate memorization boost gan performance PConv suitable effectiveness propose network quarter image cifar dataset performance network standard convolutional layer degrade training image becomes contrast network propose achieves performance PConv moderate memorization anticipate data augmentation DA technique alleviate memorization clarify superiority PConv performance PConv standard convolution DA previous built augment data translation image pad zero  random image technique described DA technique improve gan performance training gan image weak performance PConv propose suitable gan image addition demonstrate generalization ability propose network various adversarial loss function conduct additional loss function loss function entropy CE theorem loss function propose gan  various loss function propose superior performance standard convolutional layer reveal propose easily apply gan without experimental setting adversarial loss function generate image resolution celeb HQ dataset image extensive experimental various datasets summarize gan scheme propose superior performance standard convolutional layer LSUN imagenet datasets complex image generate propose significantly improves generator performance spectral normalization discriminator standard convolution layer struggle robust feature effective generator simply replace standard convolutional layer propose achieve performance various datasets propose slightly performance standard convolutional layer celeba dataset resolution image easy generate conventional technique enhance performance however generate resolution image propose exhibit significantly superior performance conventional experimental related resolution image later conduct validate effectiveness propose conditional gan scheme therefore representative conditional gan scheme replace BN generator conditional BN layer conditional projection layer discriminator network architecture model gan described trend experimental gan propose exhibit superior performance conventional propose apply conditional gan scheme boost performance effectiveness propose generate resolution image conduct additional celeba HQ dataset network image experimental propose significantly fid standard convolutional layer visually image demonstrate propose effective generate resolution image indeed intend optimal generator discriminator architecture PConv another network architecture improves performance generates visually image focus verify achieve performance simply replace standard convolution PConv comparison propose standard convolutional layer celeba HQ fid marked bold conclusion future introduce straightforward technique boost performance gan simply replace standard convolutional layer PConv discriminator effectively generator performance improvement generator advantage propose easily apply exist discriminator network without impose training overhead significantly improve performance furthermore generalization ability PConv various aspect resolution image generation ablation therefore PConv applicable various gan application indeed manuscript focus introduce novel approach specialized generative adversarial network gan perturbation procedure PConv discriminator issue network application although manuscript gan propose improve gan performance significantly various aspect PConv effectively gan diverse application image image translation future investigate novel perturbation various application keywords generative adversarial network perturbed convolutional layer adversarial dropout