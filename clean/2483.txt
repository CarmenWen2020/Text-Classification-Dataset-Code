DF model built multilayer ensemble decision aggregation DF characteristic easy understand structure suitable sample data become important research direction attribute particularly suitable model parameter actual industrial however exist mainly focus DF classification DFC cannot directly apply regression model overcome issue survey DFC algorithm construct sample data orient DF regression dfr model industrial hence survey DFC algorithm construct sample data orient DF regression dfr model industrial principle DFC introduce detail demonstrate non neural network model DFC feature engineering representation learner selection strategy hierarchical structure furthermore related decision algorithm review future investigation dfr relationship analyze detail finally conclusion future direction industrial model develop dfr algorithm characteristic dynamic adaptive interpretation ability lightweight structure basis actual industrial domain knowledge focus investigation moreover exist research DFC guidance future investigation dfr model introduction industrial generally multiple important production quantity environment protection index complex nonlinear relationship variable parameter online operational optimization industrial however majority parameter   emission concentration municipal solid waste  mill load parameter mineral  therefore sample model data obtain due limitation measurement device complex characteristic researcher propose neural network dnn industrial model address however detailed analysis theory interpretation dnn model due behavior DF algorithm consist  scan MG scan cascade model non neural network structure propose recently DF algorithm mainly contains classic algorithm FAs random RF RF crf DF algorithm demonstrates interpretability potential decision DT algorithm model therefore DF become important research topic DF structure remarkable alternative dnn random  propose replace dnn neuron DT cascade layer random extra random notably adaptive   propose recently WDF assign  boost cascade  model built model sample separately increase instance motivate unique architecture densenet dense adaptive cascade  densenet structure furthermore author propose siamese SDF alternative model siamese neural network SNN summary approach modify structure DF model background application DF summarize DF classification DFC representation realize distribution probability DF regression dfr lack dfr infer excellent performance superior aspect DFC challenge industrial model involve characteristic model data sample dimension collinearity realize representation inside structure issue establish dfr model dfr algorithm modification version predict subforest model utilized realize representation DFC dfr satisfactory interpretability theory therefore explore modify DFC algorithm enhance sample data orient dfr model basis exist research DFC aim overview discussion DFC primary DF model analyze discus dfr basis structure structure relationship dilemma future dfr development research direction remainder organize principle related application DF introduce sect research status DFC categorize basis feature engineering representation learner selection strategy hierarchical structure sect dfr industrial analyze sect finally future research direction dfr sect DF classification DFC structure involves principal MG scan classification structure diagram DFC image raw feature dimension scan feature vector slide MG scan module transform feature vector training data module estimate distribution feature vector CDFV dimension RF crf FAs crf RF algorithm learner module CDFV raw feature vector input layer model via stack strategy prevent overfitting effectively increase diversity learner addition representation ability stack strategy maintains excellent performance training data furthermore inner information effectively transmit supervision information contributes layer validation strategy realize adaptive adjustment layer hence advantage DFC automatically adjusts training layer insensitivity hyperparameters model parameter computational datasets parallel processing structure theoretical analysis easy model dnn remark RF crf algorithm MG scan generally classification algorithm FA numerous DT model difference RF crf reflect splitting criterion DT RF gini basis growth crf applies completely random growth notably output FA DFC multi dimensional vector accord characteristic task category DFC extensively apply researcher image basically focus image recognition image remote scene image classification flame video recognition image segmentation image quality evaluation DFC application fault detection diagnosis satellite attitude railway turnout bearing health monitoring android malware behavior model  syndrome chronic  electricity theft buying behavior load hospitalization rate patient stock behavior depression severity EEG attention recognition frequently explore proven application DFC accuracy memory overhead DF structure perform confidence screen mechanism DFC reduce layer instance easy predict subset former directly enters predictive stage latter layer layer cascade structure primary training weak scalability DF task parallel algorithm grain subforest layer propose adopt performance distribute execution framework traditional ensemble prune operation distribute execution framework reduce complexity simplify learner hence DFC utilizes feature contribution rate index prune model ensemble prune propose realize prune pdf performance ensemble pdf feature vectorization quantum however performance minimally decrease simplification function review DF classification DFC classify category feature engineering representation learner selection strategy hierarchical structure classification structure diagram DFC image feature engineering preprocessing raw feature training essential procedure classification task MG scan performance structure extent construct learner achieve excellent performance situation lunch theory model data various domain characteristic hypothesis therefore extensive preprocessing feature extraction feature selection data sample basis characteristic model data address preprocessing typically utilized replace MS scan module perform feature processing MS scan module structure preprocessing structural diagram feature engineering substitute MG scan image precondition MG scan module promote performance assumption model data credible however preprocessing substitute MG scan module model data application unbalanced distribution principal component analysis pca preprocess spectral data obtain feature vector model exploit classify satellite remote image another distribute random adjacent embed sne preprocess dimensional spectral data pca feature extraction recognition model construct  LBP operator utilized extract feature vein recognition standardization address particularity abstract logic composition source data generate feature detect software defect meanwhile apply  technology data utilize MG scan module perform feature transformation finally model prediction structure model feature engineering MG scan image strategy regional suggestion network extract dimensional feature vector thermal remote image feature extraction algorithm incorporate pas filter local iterative correction extract text information image random  apply generate CDFV MG scan module synthetic minority oversampling technique SMOTE tomek link algorithm apply expand denoise cancer genome atlas  data building cancer classification model unbalanced data similarly SMOTE combine edit ENN utilized address imbalance attention deficit hyperactivity disorder boltzmann machine dbm convert numerical characteristic industrial binary vector construct fault diagnosis model DFC processing strategy average pool module introduce address HSI classification reduce dimensionality output feature vector MG scan module performance model improve feature engineering however singleton feature engineering strategy suitable model data impossible hence quality feature engineering deviation practical occurs feature engineering related constantly raw data basis MG scan future investigation feature engineering selection basis model data expert representation structure layer layer mechanism feature vector MG scan module feature preprocessing layer classification feature vector LCFV representation layer CDFV information LCFV concatenate raw feature obtain augment layer classification feature vector   training data layer restrain loss model diversity representation basically namely utilization improvement LCFV dimension reduction LCFV feature optimization cascade layer illustrate representation cascade layer image representation utilization improvement LCFV layer layer strategy utilized feature structure DFC error generally unstable fluctuation depth layer adjustment mechanism adaptive layer shield phenomenon sparse connectivity structure continuous degradation feature information densenet strategy apply avoid phenomenon remove loss internal representation information effectively  layer modify raw feature vector exist LCFV representation information infuse training data cascade layer raw feature vector combine output construct layer input layer basis stack generalization theory dimension reduction LCFV remarkable growth  dimension increase depth due dense connection complexity average LCFV combine raw feature vector obtain  address limitation  output subforest average LCFV realize maximum dimension reduction conducive reduce complexity improve convergence operation efficiency feature optimization feature optimization module importance raw feature vector LCFV layer reduce distinctive feature layer remove insignificant feature ensure calculation reduce performance DFC generally improves via density connection LCFV dimensionality reduction extent however computational consumption training prediction stage increase representation weaken feature optimization layer feature disappearance LCFV sake convenience  layer dimension LCFV generate subforest classification mainly attribute raw dimensional feature vector parameter normal therefore reduce compute remains issue learner selection model performance depends diversity accuracy learner ensemble diversity  structure exerts prediction performance DF structure subforest DF generate via fold validation encourage diversity apart issue researcher focus learner learner multi instance random  bag randomize  replace RF crf respectively multiple instance approach diversity learner performance RF crf fails diversity remote image classification RF rotation combine increase diversity structure furthermore rotation implement layer improve accuracy DF similarly RF crf substitute learner xgboost intrusion detection network attack learner combination layer combination xgboost RF crf logistic regression xgboost RF extra logistic regression lightgbm RF xgboost  subsequently learner improve diversity DFC reduce increase learner  learner xgboost RF classification model grid structure data FA namely xgboost RF  fault detection industrial clearly performance remains unaffected decrease learner comparison RF information gain ratio RF gini index crf information gain ratio crf gini index extreme random apply estimate transient stability model flexible neural  classify cancer RF  xgboost GBDT utilized learner layer automatic target recognition radar resolution profile certify increase learner significantly enhance performance DFC hence evidence strategy effective increase decrease learner remains unclear therefore factor characteristic application domain performance improvement DFC modification learner image explore diversity perspective although suitable strategy remains unverified issue address suitable strategy width layer depth structure dynamic adjustment investigation increase width  layer intensify avoid subjective arbitrariness analyze contribution subforest learner overall structure exploration due subjective arbitrariness selection subforest learner exist strategy sample inequality learner diversity negatively affect performance DFC model prone phenomenon imbalance coefficient strategy commonly address notably strategy DFC focus instance feature learner approach instance feature insufficient fitting lack diversity datasets sample dimension primary issue DFC hence boost strategy introduce assign instance subforest coefficient calculate bagging dataset furthermore assign instance generate CDFV distribution express   normalize CDFV complexity positively increase instance transfer layer confidence screen mechanism contributes discriminate instance assign instance instance enters layer assign accord average CDFV generate previous layer express label vector distance contribution feature prediction performance unbalanced therefore adaboost introduce layer unbalance feature exert serious impact performance learner assign accord contribution subforest learner curve auc index evaluate prediction ability subforest auc   however usually complicate wilcoxon mann whitney statistic index facilitate calculation auc auc  output classifier assume classifier dataset negative respectively auc learner calculate  auc  auc RF denotes crf majority voting strategy average basis hypothesis learner contribute identically however contribution learner due sample strategy randomness consequently weakness learner amplify prediction therefore average prediction strategy propose calculate accuracy  predict calculate accord prediction accuracy subforest learner finally summation prediction probability vector learner obtain eliminate influence incorrectly predict therefore performance DFC model improve   PM model DT   CDFV subforest indicates CDFV generate decision coefficient DT finally dts coefficient generate CDFV apportion accord DT model consideration metric reduce distance instance otherwise vector obtain loss function     distance vector denotes regularization summary introduce coefficient DF structure weaken diversity learner improve accuracy however relationship evidently exists complexity generalization error due increase parameter model complexity overfitting likely generalization error vice versa therefore coefficient generalization performance model complexity investigation hierarchical structure dnn DFC inevitably structure adjustment adjust structure diagram structural adjustment image model RF crf layer split  basis layer important neuron dnn thereby principal difference structure although local structure modify improve performance structure generalize another local density connection representation feature layer information weaken due similarity notably DFC structure limited therefore relationship modification structure prediction performance investigation discussion DFC recent DF algorithm exhibit excellent performance dnn structure statistical DF structure statistical DF DFC characteristic layer automatically adjust hyperparameters model computational suitable datasets finally parallel processing structure beneficial distribute implementation DFC feature engineering mainly category replace MG scan module MG scan module however universality without specific issue impossible recent performance improvement model feature engineering distinct typically characteristic model data DFC representation specific feature transform layer exist category feature optimization utilization improvement dimension reduction LCFV generalize reinforce transmit representation information  algorithm improvement densenet connection avoid loss hierarchical information lose realize  algorithm weakens swamp phenomenon raw feature vector LCFV however  increase dimensionality  transfer layer LCFV average address issue obtain  easily overfitted due swamp dimensional feature LCFV feature information conveyed assemble feature optimization link subsequently convert feature information layer preliminary exploration representation model internal feature modification learner aim increase diversity consideration DFC learner selection learner module non structure various combine learner propose notably multitude learner model accord exist learner basis application integration strategy DFC propose distribution instance feature learner layer enhance prediction performance inherent inequality sample feature diversity learner import coefficient effectively improve performance DFC model obtain excellent prediction performance DFC hierarchical structure refers structure alteration layer internal structure correlation prediction performance development neural network relevant modify structure learner layer  however structure analysis adjustment DF approach due plasticity internal structure therefore exist mainly concentrate classification primary DFC structure compose MG scan module former belongs feature engineering latter contributes prediction model representation within DF structure critical realize ability label feature representation fails achieve satisfactory stack generalization classification CDFV replace label prediction accuracy reliability classifier accordingly MG scan CDFV achieve conversion raw feature vector probability distribution transform feature stack framework realize representation summary exist DFC algorithm remark introduces category feature engineering representation learner selection strategy hierarchical structure define focus classification orient DFC adequately explore individual combine mode article basis individual mode DFC investigate feature engineering focus representation learner selection focus strategy assess hierarchical structure representation strategy feature engineering representation representation strategy hierarchical structure perform basis combine mode DFC dfr related generally limited specific research direction practical analysis DF regression industrial model reduction consumption pollution emission complex industrial strategy optimize operation however principal model exploit online prediction parameter important factor cannot establish due complexity physical chemistry production quality environmental pollution index mainly obtain manual timing sample offline laboratory analysis online estimation domain expert typically inaccurate lag detection hinder complex industrial achieve operational optimization feedback therefore building model easy variable become effective widely measurement artificial neural network vector machine machine usually address situation wherein limited sample data obtain however prone incur overfitting interpretability factor measurement building accurate interpretable industrial model therefore subsection review industrial model orient DT FA DF algorithm model DT DT model machine consists internal node leaf node structure DT image classic DT algorithm ID information gain information gain ratio cart minimum error gini index cart model widely algorithm DT construction generally operation feature selection growth prune criterion DT algorithm typical classification approximate discrete function minimum loss function sample induction strategy utilized decision model finally model predict unseen sample DT algorithm classify model operating mechanism interpret however split criterion qualitative information classification unsuitable quantitative regression hence cart model widely split criterion gini index error address limitation error minimization criterion mainly construct binary DT model simplicity training denote  sample accord segmentation segmentation feature   minimum error define      average output   subregions respectively denotes error segmentation obtain loop feature subregions basis minimum error segmentation suppose subregions output subregion  denote respectively therefore regression model express  indicator function otherwise model FA accuracy model ensemble voting decision although strategy combination multiple model widespread attention diversity training data become obstacle significant development ensemble bootstrap sample bagging address obstacle generate subset dataset improve diversity although bagging model obtain excellent generalization performance bias exists therefore performance FA inferior adaboost others imitation random subspace bagging improves prediction accuracy appearance classical machine RF RF become representative bagging due powerful ability processing nonlinear model FA structure mainly parallel PF cascade CF structure PF CF structure diagram algorithm image PF CF model learner basis cart RF algorithm representative PF structure extensively apply due powerful ability model nonlinear data hence RF propose combine bagging parallel random subspace whereby multiple training subset extract bootstrap sample strategy random feature selection training subset cart maximize growth average strategy address prediction cart generation training subset express    ùëóth subset denotes sample indicates feature  input feature pairwise ùëóth subset input feature ùëóth subset pseudocode RF algorithm appendix CF model boost strategy boost strategy optimal fitting ability relationship input output complicate specifically gradient boost decision GBDT representative consists additive model distribution regression orient GBDT model error loss function pseudocode GBDT algorithm appendix model dfr representation strategy DFC implement CDFV layer DFC indirectly adopt model therefore representation realize accord characteristic model data representation layer become critical issue dfr model CDFV mirror model performance extent modify strategy classification regression DT FA algorithm effective basis DFC dfr algorithm propose model environmental indicator complex industrial NN criterion predict FA representation feature dfr structure illustrate structure regression image dfr structure mainly module namely input output layer input layer module regard raw feature vector input training subforest model layer regression feature vector  obtain utilize NN prediction  augment layer regression feature vector  obtain combine  raw feature vector layer module consists layer regard  former layer input output layer obtain input layer model output layer model output layer  layer module considers  layer input training multiple subforest model obtains via average prediction output  consequently exploration DF structure regression realize predict representation feature challenge dfr improve strategy exist DFC mainly perspective empirical cognition however ignore operating mechanism DF internal structure theoretical analysis generalization convergence unverified  distribution probability regression central dilemma DF structure orient model despite representation operator layer convert prediction representation feature feasible hence preliminary attempt representation prof effectiveness DF regression model however dfr inevitably encounter  representation swamp swamp weakens representation ability performance deterioration diversity loss primarily raw feature vector dimension remarkably representation feature however effective standard treat issue proportion raw feature vector representation feature via NN unavailable although representation strategy widely realize efficiency representation due regression model improve strategy prevent swamp phenomenon dfr hence feature reduction feature selection  combination strategy investigation obtain sufficient label sample economic factor label sample obtain model limitation allows dfr alternative dnn regression model subsection analyze discus impediment future investigation challenge dfr image overcome issue insufficient training sample dfr dnn sufficient label training data DF successfully perform model sample data improvement generalization performance basis primary dfr become important research direction typical strategy exist algorithm data enhancement generates sample via translate rotate deform operation enhancement technology improve prediction performance algorithm gan  sample strategy encoder decoder architecture transfer unlabeled sample coexist label sample actual industrial bayesian framework successfully transfer knowledge obtain source domain target domain sample data metric strategy simulates distance distribution sample sample mutually vice versa theory metric sample data implement euclidean cosine distance triplet rank prototypical network dnn similarity generative adversarial residual pairwise network relation network metric agnostic conditional embed combine exist strategy modify dfr structure ensure generalization performance computational efficiency challenge internal structure optimization dfr steadily increase accuracy dnn without loss generality attribute depth width structural however depth width usually accompany complexity exist DFC demonstrate excellent performance  structure preliminary exploration moreover DFC structure plastic due inherent potential interpretability DT algorithm combination strategy ensemble contradiction model complexity prediction performance inevitable however report optimization parameter structure DF model limited prune optimization strategy significantly improve efficiency generalization parallel ensemble algorithm dropout strategy powerful network optimization internal structure model regularization approach network training knowledge transfer utilized network structure compression although cnns typically improve increase depth width unavoidable overfitting hyperparameter increase deceleration training batch standardization convolution kernel decomposition optimize dnn structure summary approach methodological structure optimization dfr model adaptive dynamic adjustment dfr actual industrial demonstrate dynamic characteristic drift strongly associate input fluctuation equipment  therefore adaptive mechanism prerequisite recognize abnormal sample brain robust adaptive dynamic although majority DFC dfr static obtain effective sample interaction industrial circumstance hence update model independent limited training sample dynamic neural network hopfield organize neural recurrent neural network modify structure adaptive mechanism dfr enhance efficiency compact intelligent version static improve industrial application interpretability dfr mathematical definition interpretability model unavailable hence interpretability mainly  illustrates namely understand decision understand model predict model explanation journal mit technology review declare interpretability development interpretation dnn cnns representation interpretation hidden layer sensitivity analysis model imitation multimodal interpretation focus recurrent neural network visualization neural attention mechanism dfr successfully apply extent however knowledge explain internal physical mechanism improve prediction performance finite interpretability dfr model improve performance architecture relationship dfr comprehensive relationship dfr actual industrial demonstrate combine exist DFC relation exist dfr actual industrial image remark parameter actual industrial   emission concentration municipal solid waste  illustrate procedure  measurement compose online  sample offline laboratory analysis disadvantage complexity consume factor realize optimize  emission reduction obtains  emission concentration however challenge issue impossible due complex generation mechanism emission  accordingly model forecast  emission concentration dimensional data practical industrial issue due strict environmental policy pollutant emission  emission municipal solid waste  image DF ensemble dnn algorithm therefore DF inherits excellent performance ensemble compensates disadvantage dnn challenge dfr stage described dfr model stage dfr model realize basis DFC model ensemble theory dnn architecture actual industrial measurement parameter overcome issue insufficient training sample dfr stage precision dfr model accomplish data enhancement meta transfer algorithm issue label sample unlabeled data internal structure optimization dfr stage optimization dfr structure parameter explore regularization model compression network optimization achieve optimal performance static dfr model adaptive dynamic adjustment dfr stage dfr adaptive dynamic structure organization investigate basis brain recognition mechanism dynamic network concept drift detection dfr industrial characteristic series nonlinear dynamic interpretability dfr stage interpretability dfr representation model visualization imitation interpretation focus perspective artificial intelligence application critical dependent representation module furthermore research precision model basis practical application characteristic sample data efficiency prediction performance improve mining structure optimization memory consumption dfr adaptive adjustment static dfr structure becomes actual practical dynamic interpretability dfr prediction obtain successful industrial application cognitive perspective industrial domain expert development prospective artificial intelligent researcher conclusion prospect review DFC algorithm construct effective sample data regression model classify category basis feature engineering representation learner selection strategy hierarchical structure perspective regression orient DT FA dfr algorithm analyze industrial model relationship dfr knowledge industrial develop dfr algorithm characteristic dynamic adaptive interpretation ability lightweight structure important research direction aspect address investigation dfr representation ensemble theory CDFV feature representation DFC uniqueness representation strategy predict via NN representation feature available dfr however adopt concatenate raw feature vector representation feature easily swamp phenomenon attribute selection feature representation learner diversity model performance investigation implement sample data orient dfr model fusion strategy excellent performance cannot achieve due insufficient feature attribute training dataset hence data processing technology fusion strategy attract considerable research attention data processing technology dnns mainly expansion model adaptive data proven excellent performance DF preliminary investigation  structure therefore combine exist sample model technology dfr structure focus future investigation achieve prediction performance dfr model enhance diversity within dfr structure performance singular excellent learner usually inferior ensemble learner diversity accuracy complementarity learner important accuracy alone generate accurate learner learner diversity however hyperparameters model leaf node threshold fix diversity learner structure cannot reflect therefore analyze resolve combination diversity training sample learner structure research direction future dfr structure prediction performance memory consumption bagging parallel boost cascade ensemble stack strategy mutually couple dfr consequently  accelerate dfr model structural optimization vital research direction define optimization evaluation index accord characteristic dfr dnn structure optimization evaluation model accuracy model achieve excellent evaluation index ideally estimate advantage disadvantage dfr structure addition adaptive dynamic update interpretability dfr industrial model future research direction keywords ensemble DF classification DFC DF regression dfr sample data