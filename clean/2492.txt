hybrid cooperative differential evolution perturbation covariance matrix adaptation evolutionary strategy cma ES local limited memory   goldfarb  LBFGS mechanism jSO cma ES LBFGS propose complex continuous propose algorithm jSO variant differential evolution DE global operator explore entire population stagnation relatively reliable initial local operator generate cma ES activate perturb optimal candidate LBFGS utilized local strategy embed cma ES obtain potential local optimal cooperative evolutionary dynamic jSO cma ES local operator propose jSO cma ES LBFGS cec benchmark suite eleven algorithm practical engineering investigate utilize propose experimental reveal effectiveness efficiency jSO cma ES LBFGS introduction important artificial intelligence evolutionary computation characteristic adaptation organization model algorithm simulate behavior survival biological ecological algorithm various complicate continuous optimization important application evolutionary computation important issue widely recent classical evolutionary algorithm mainly genetic algorithm GA differential evolution artificial bee abc particle swarm optimization PSO whale optimization algorithm WOA typical hybrid evolutionary computation algorithm DE propose global optimum complex optimization DE stem darwin theory biological evolution owe efficiency effectiveness optimization DE apply numerous diverse domain engineering optimization electrical manufacturing operation research accurately classify DE variant DE combination multiple mechanism modification DE roughly category detail DE strategy variant DE multi population mutation strategy  propose utilized combination evolution strategy subpopulation generation evolution stage surrogate embed strategy DE predict optimal direction differential evolution experimental verify surrogate convergence DE stochastic mutation strategy information mechanism introduce enhance capability DE addition incorporate local heuristic useful enhance performance DE DE adaptation parameter performance DE depends parameter operator DE parameter automatically configure mutation strategy throughout evolution evolution algorithm recognize loop sinusoidal adapt factor performance adaptation scheme earlier sinusoidal moreover covariance matrix strategy crossover operator correlation variable parameter adaptive mechanism palm introduce tackle ill interaction parameter DE variant timestamp mechanism employ update inferior external archive hybridization DE algorithm domain optimization hybridization refers combination algorithm achieve chemical reaction accord optimization characteristic algorithm flatten operating mechanism algorithm combination abc DE  propose develop effective algorithm abc DE convergence exploration exploitation moreover DE local moth algorithm enhance local  experimental performance analysis confirms hybrid mechanism effective practical optimization hybrid DE evolution algorithm BA DE BA competitive relationship introduce balance exploration exploitation capability BA accord literature zhang  propose variant DE implement mutation strategy DE pbest external archive  improve optimization performance jade variety research focus adaptation parameter DE feedback evolutionary employ dynamically tune parameter adopt mechanism parameter DE automatically adjust appropriate improve jade shade propose improve robustness jade hybridization framework LSHADE  LSHADE cma ES introduce improve optimization performance shade algorithm DE local operator introduce grey wolf optimizer gwo improve exploitation gwo  experimental  effective optimal global optimization adaptive neighborhood operator borrow DE promote exploration exploitation migrate optimization  summary DE extensively operating mechanism algorithm regard DE algorithm hybrid DE algorithm recent however DE tends trap local optimum lose diversity population evolution external archive fix classic evolution strategy DE evolution population progress external archive constantly replace update candidate optimal fitness population local optimal external archive various suboptimal perturbation strength insufficient currently accord evolutionary population strength disturbance automatically adjust pre enhance local ability hybrid algorithm DE population DE degrade inject local optimization inspire cooperative evolutionary framework hybrid cooperative jSO optimization algorithm objective parameter perturbation cma ES local LBFGS jSO cma ES LBFGS propose objective numerical optimization jSO cma ES LBFGS jSO reliable initial cma ES LBFGS cma ES LBFGS potentially local optimal jSO jSO capability therefore cooperative evolution jSO cma ES LBFGS achieve contribution generalize hybrid cooperative differential evolution algorithm objective parameter numerical optimization effectively combine evolutionary algorithm jSO evolutionary strategy cma ES mathematical LBFGS randomize anti rotation cma ES perturbation operator relatively reliable initial local operator LBFGS markov model jSO cma ES LBFGS analyze convergence performance jSO cma ES LBFGS mathematically evolutionary jSO cma ES LBFGS mapped transition markov model convergence performance jSO cma ES LBFGS propose jSO cma ES LBFGS cec benchmark variant DE evolutionary algorithm experimental imply jSO cma ES LBFGS obtain efficient accurate algorithm furthermore desirable combination parameter analyze execute taguchi remainder organize framework DE cma ES summarize sect propose methodology described analyze sect experimental research statistical analysis sect sect practical engineering continuous discrete decision investigate propose jSO cma ES LBFGS finally conclusion future sect algorithm operator jSO cma ES briefly introduce notation described jSO algorithm operation DE mutation crossover selection population DE initialize operation termination criterion exhaustion maximum functional evaluation satisfied DE population vector  dimension objective function  population population initialize randomly mutation operator  factor calculate        index chosen  randomly external archive   dominant individual population parameter factor individual difference donor vector beyond feasible operation perform       crossover operator     selection operator   jSO algorithm advanced variant DE jSO version mutation strategy inherits evolutionary strategy parameter mechanism shade parameter mechanism jSO adaptive loop parameter jSO stage evolution embodies global local cma ES randomize evolutionary strategy covariance matrix adaptation cma ES perturbation operator avoid pre perturbation strength standard cma ES consists parameter vector covariance matrix favorite distribution ellipsoid adaptive update parameter  population jSO  function  counter   randomly chosen individual population  archive  population  generation population stagnate   vector favorite  covariance matrix determines distribution ellipsoid  multi variate normal distribution  evolution  evolution  population cma ES default   obtain propose algorithm  matrix objective function iteration LBFGS  derivative objective function iteration LBFGS  evaluation sample normally distribute  update    evolutionary construct accumulate evolutionary construct accumulate covariance matrix update    update   summary characteristic cma ES multivariate normal distribution adopt generate conforms maximum entropy principle assumption target function distribution rank selection strategy implies rotational invariance convergence rate improve mechanism covariance matrix adaptation cma increase likelihood previously successful reduces convex quadratic function sphere model without derivative refer mention literature description cma ES description propose algorithm mention earlier sect DE critical restrict improvement algorithm firstly disturbance intensity mention cma ES utilized disturbance operator parameter evolution algorithm adaptively dynamically secondly stagnation detection operator detect population operation activate accord ensure cooperation algorithm operation mathematical LBFGS employ fuse local stage evolutionary algorithm conduct depth exploitation sect importance LBFGS jSO cma ES LBFGS detailed addition ensemble operator sect firstly jSO entire global operator stagnation detection operator perform detect population perturbation operator activate population locally optimal  local optimal generate jSO vector parameter perturbation operator cma ES distributes around local optimal generate normally distribute furthermore local LBFGS perform obtain potential local optimal  finally local optimal population jSO attraction basin explore another potential local optimal operating mechanism jSO cma ES LBFGS image jSO cma ES LBFGS reliable initial cma ES LBFGS return multiple local optimal jSO jSO learns multiple local optimal jumping attraction basin therefore cooperative evolution jSO cma ES LBFGS achieve pseudocode jSO cma ES LBFGS algorithm LBFGS performs local population cma ES LBFGS affect adaptability convergence cma ES local optimization directly inject jSO adaptability convergence jSO affected cma ES LBFGS perturbation cma ES explores neighborhood optimal jSO stagnation detection operator diversity population jSO cma ES LBFGS diversity metric  define            metric diversity generation population dimension parameter cma ES  indicator detect generation population stagnation   population jSO cma ES LBFGS  perturbation operator cma ES activate stagnation detection operator execute detect population jSO dynamic jSO cma ES LBFGS population stagnation explorative  function role stagnation detection operator diversity population jSO cma ES LBFGS image diversity population jSO cma ES LBFGS image local local unconstrained numerical optimization mainly category iterative gradient decrement algorithm random local algorithm random local algorithm mainly multi trajectory local algorithm mtsls  wet algorithm SW etc SW local algorithm propose  wet principle initial randomly generate normal distribution accord increase decrease objective function direction adjust optimal candidate functional evaluation SW algorithm mtsls local algorithm mtsls dimension dimension dimension furthermore update mtsls along dimension dimension dimension adapt image along dimension fitness reduce obtain dimension fitness increase mtsls return along reverse direction fitness dimension therefore update mtsls greedy LBFGS belongs iterative gradient decrement algorithm LBFGS convergence convex optimization achieves accuracy function evaluation core   goldfarb  BFGS without partial derivative function construct positive definite symmetric matrix approximates hessian matrix objective function optimize BFGS quasi newton BFGS  satisfies wolfe     moreover satisfies update iteration utilize formula     information recent iteration utilized construct approximate hessian LBFGS termination LBFGS satisfied candidate accord reference manual  user guidance LBFGS central formula differentiation therefore gradient calculation function evaluation dimension gradient direction function decrease LBFGS adopt local operator achieve convergence propose algorithm principle convergence analysis jSO cma ES LBFGS local optimization directly inject jSO therefore adaptability convergence jSO affected cma ES LBFGS convergence jSO equivalent convergence jSO cma ES LBFGS population stochastic optimization algorithm evolutionary jSO stochastic  individual  denote population fitness function dimension  population operator DE described stochastic mapping mutation operator  probability distribution mutation operator     stochastic mapping crossover operator probability distribution crossover operator      stochastic mapping selection operator probability distribution selection operator  analysis jSO algorithm   definition convergence probability population sequence generate population stochastic algorithm stochastic sequence weakly converges probability global optimum  global optimum optimization lemma jSO algorithm  direction population monotonically non increase lemma population sequence DE algorithm markov chain proof population sequence jSO  irrelevant iteration depends transition probability calculate   obvious       transition probability  transition probability independent therefore population sequence DE homogeneous irreducible aperiodic markov chain markov population sequence jSO theorem suppose population sequence generate DE converges subset  global optimum probability  proof suppose unique optimum satisfaction derive accord interconnect hence positive recurrent irreducible aperiodic accord aperiodic homogeneous markov chain sequence exists limit distribution     accord definition obtain jSO converges global optimum probability comparison performance propose algorithm comparison algorithm evaluate firstly brief introduction cec benchmark function cec benchmark suite contains function unimodal function multimodal function hybrid function composition function function classic representative objective continuous optimization function parameter optimization function publish expert theme annual cec conference optimization meta heuristic optimization summary cec function optimal function exclude unstable behavior dimension function define construct cec function unimodal function multimodal function obtain rotation translation operation function hybrid function composition function obtain embed function subcomponents variable  function summary cec function sect complexity jSO cma ES LBFGS analyze sect experimental parameter described simulation role local algorithm sect integration operator sect comparison jSO cma ES LBFGS representative algorithm described sect moreover owe limited interested reader obtain experimental algorithm online supplemental jSO cma ES LBFGS complexity subsection complexity jSO cma ES LBFGS obtain evaluate benchmark function program compute program denote assume variable evaluate benchmark function variable jSO cma ES LBFGS execution function within evaluation dimension variable Tˆ average obtain independent algorithm complexity relationship dimension computational complexity algorithm jSO cma ES LBFGS reflect calculate variable Tˆ Tˆ dimension calculation independent compute program algorithm implement accord easy conclude computational increase dimension benchmark function computational complexity algorithm jSO cma ES LBFGS experimental parameter comparison algorithm execute maximum function evaluation  dimension algorithm execute independently function server hardware environment intel core TM cpu ghz processor GB ram propose algorithm implement program numerical analysis processing library  http  net utilized implement LBFGS comparison algorithm parameter configure recommend correspond literature parameter significant impact performance jSO cma ES LBFGS crucial parameter stagnation threshold memory jSO cma ES LBFGS taguchi adopt calibrate parameter jSO cma ES LBFGS propose algorithm calibrate dimensional cec benchmark function various parameter combination average error yield jSO cma ES LBFGS accord significance rank parameter meanwhile tendency parameter described parameter parameter combination response plot parameter image significant parameter implies memory important influential factor jSO cma ES BFGS information external storage failure abnormal rank illustrates important factor jSO cma ES LBFGS population easily local optimum algorithm global waste function evaluation random stagnation threshold parameter rank combination global operator local operator achieve exploration exploitation accord taguchi parameter jSO cma ES LBFGS selection local operator local algorithm  wet algorithm SW multi trajectory local mtsls although various adjustment parameter setting combine essence comparison algorithm framework encode operating mechanism implementation accord factor principle parameter jSO cma ES remain unchanged parameter SW mtsls experimental LBFGS SW mtsls parameter SW mtsls multiple wilcoxon error local algorithm combination dimension error local algorithm combination dimension SW algorithm belongs estimation distribution algorithm eda parameter SW algorithm mtsls LBFGS prior knowledge combination parameter SW algorithm mtsls algorithm dimension another without dependency variable LBFGS belongs iterative gradient decrement algorithm LBFGS convergence convex optimization achieves accuracy function evaluation LBFGS significantly SW mtsls benchmark function dimension therefore LBFGS employ local operator jSO cma ES LBFGS SW mtsls ensemble operator LBFGS operator jSO cma ES LBFGS jSO cma ES LBFGS degrade jSO cma ES diversity algorithm increase effectively generate cma ES jSO jSO cma ES jSO LBFGS dimension dimension jSO cma ES significantly jSO benchmark function dimension therefore cma ES embed jSO performance jSO accord literature cma ES characteristic randomization rotational invariance sample normal distribution perturbation  standard cma ES belongs estimation distribution algorithm global ability insufficient local  suitable dimensional optimization operating mechanism jSO cma ES image operating mechanism jSO LBFGS image jSO jSO cma ES jSO LBFGS cma ES agent relatively reliable initial LBFGS significant difference jSO cma ES jSO dimensional optimization demonstrates rationality hypothesis propose cma ES operator jSO cma ES LBFGS jSO cma ES LBFGS degrade jSO LBFGS limited locally optimal stagnation significant difference jSO LBFGS jSO therefore disturbance strength jSO LBFGS insufficient however jSO cma ES LBFGS significantly jSO dimension wilcoxon jSO jSO cma ES jSO LBFGS wilcoxon jSO cma ES LBFGS jSO plot confidence interval operator abscissa function multimodal function hybrid function composition function horizontal axis operator vertical axis normalize independent independent normalize normalize independent plot confidence interval operator image reflect excellent performance operator horizontal stability operator strategy contributes jSO cma ES LBFGS significant improvement jSO hybrid function composition function therefore jSO cma ES LBFGS inseparable indispensable organic achieves instead comparison jSO cma ES LBFGS algorithm propose jSO cma ES LBFGS eleven algorithm jSO LSHADE      LSHADE  LSHADE  cma ES   jSO LSHADE     LSHADE  LSHADE  typical variant DE significantly jSO LSHADE  LSHADE  fourth cec competition objective parameter optimization  cec  improve optimization algorithm enhance cma ES parameter algorithm recommend simulation evaluate performance propose jSO cma ES LBFGS cec suite algorithm execute independently function standard deviation std metric calculate parameter algorithm setting jSO cma ES LBFGS parameter comparison experimentally detailed parameter analysis jSO cma ES LBFGS sect parameter setting meanwhile jSO cma ES LBFGS comparison algorithm convergence rate convergence plot unimodal multimodal hybrid composition function described function analysis reflection performance operating mechanism jSO cma ES LBFGS function jSO cma ES LBFGS jSO convergence plot jSO cma ES LBFGS algorithm image jSO cma ES LBFGS jSO although propose algorithm converge maintains continuous downward trend obtains precision comparison algorithm attribute role perturbation operator local operator addition distinct separation jSO jSO cma ES LBFGS convergence rate stage population evolution obvious implicitly indicates operating mechanism propose algorithm effective plot illustrate stability performance propose algorithm plot data statistic minimum quartile median quartile maximum data roughly data symmetry distribution disperse information comparison sample correspond quartile data batch median extension quartile maximum  similarly extension quartile minimum outside extension outlier therefore narrower outlier data tend stable ordinate plot normalize error closer performance algorithm minimization stability algorithm plot although narrow plot propose algorithm closest performance propose algorithm comparison algorithm plot jSO cma ES LBFGS algorithm typical benchmark function image testify performance jSO cma ES LBFGS wilcoxon perform behavior algorithm introduce algorithm statistical analysis summarize jSO cma ES LBFGS algorithm bold jSO cma ES LBFGS significantly another algorithm jSO cma ES LBFGS significantly jSO benchmark function dimension significantly  dimension jSO cma ES LBFGS significantly  dimension significantly  dimension although significant difference jSO cma ES LBFGS comparison algorithm namely jSO cma ES LBFGS obtains comparison algorithm wilcoxon jSO cma ES LBFGS algorithm achieve friedman friedman significant difference jSO cma ES LBFGS eleven competitor significant difference jSO cma ES LBFGS  dimension significant difference jSO cma ES LBFGS   dimension although significant difference jSO cma ES LBFGS algorithm rank jSO cma ES LBFGS comparison algorithm ranking image ranking image summary statistical analysis imply performance propose jSO cma ES LBFGS significantly comparison algorithm dimension whereas increase dimension performance jSO cma ES LBFGS comparison algorithm decrease functional dimension decision variable expand dramatically cec benchmark suite evaluation specify function dimension limited dimensional function algorithm cannot effectively approximate optimal within limited evaluation increase function dimension complexity increase sharply affect performance algorithm application engineering propose algorithm important engineering continuous discrete decision addition performance jSO cma ES LBFGS canonical analysis advantage jSO cma ES LBFGS address engineering optimization engineering algorithm independently gear engineering gear engineering utilized verify performance jSO cma ES LBFGS address engineering gear aim minimize gear ration gear parameter gear engineering detail mathematical model described  image decision variable     objective jSO cma ES LBFGS fitness evaluation obtain statistical gear engineering detail   abc described jSO cma ES LBFGS outperforms algorithm algorithm schedule schedule  important schedule widespread  buffer machine remains machine machine available processing increase schedule difficulty computation increase exponentially exist literature  machine typical NP definition variable parameter mention detail mathematical model  described definition notation decision variable objective      mathematical model  objective minimize makespan criterion makespan schedule  computation complexity task decision variable reflect machine processing schedule gantt makespan schedule  gantt image experimental setting analysis traditional jSO algorithm variant cannot directly utilized combinational optimization discrete characteristic therefore cod scheme decode utilized algorithm directly discrete domain individual discrete permutation  utilized individual discrete permutation detail  average relative percentage deviation  index utilized calculate generate specific algorithm ith instance  minimum makespan algorithm algorithm minimum  outperforms algorithm    standard benchmark  evaluate performance jSO cma ES LBFGS benchmark compose instance instance categorize subset combination machine combination machine machine jSO   cma ES  LSHADE  jSO cma ES LBFGS algorithm millisecond parameter comparison algorithm consistent previous  algorithm machine significant impact algorithm excellent performance jSO cma ES LBFGS  effectiveness jSO cma ES LBFGS jSO local capability propose algorithm enhance via LBFGS LBFGS embed cma ES perturb optimal candidate population stagnation therefore jSO cma ES LBFGS competitive algorithm  conclusion future research hybrid algorithm jSO cma ES LBFGS DE cma ES LBFGS continuous optimization various experimental imply conclusion LBFGS local operator important role propose algorithm enhance local capability DE jSO cma ES LBFGS relatively reliable initial local operator generate cma ES activate perturb optimal candidate population stagnation LBFGS embed cma ES local strategy obtain potential local optimal performance jSO cma ES LBFGS comparison algorithm confidence jSO cma ES LBFGS effective algorithm continued optimization cec benchmark gear engineering propose jSO cma ES LBFGS apply  effectively benchmark  demonstrate propose algorithm performance future performance jSO cma ES LBFGS improve improve jSO cma ES LBFGS apply complex schedule schedule schedule schedule moreover DE combine meta heuristic multi objective schedule differential evolution DE covariance matrix adaptation evolutionary strategy cma ES limited memory   goldfarb  LBFGS cooperative  numerical optimization