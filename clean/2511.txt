computational fluid dynamic community surrogate model reconstruction turbulence model prediction aerodynamic coefficient overall exceptional accuracy obtain robustness reliability propose approach remain explore particularly outside confidence define training dataset contribution autoencoder architecture twin decoder incompressible laminar reconstruction uncertainty estimation around 2D obstacle propose architecture dataset compose numerically compute laminar around random naturally enforces quasi linear relation geometric reconstruction prediction decoder feature uncertainty estimation propose binary decision accept reject prediction propose confidence interval along quantity prediction dataset sample unseen positive correlation reconstruction error prediction approach possibility warn user model input deviation training data surrogate model conservative reliable prediction introduction computational fluid dynamic cfd community largely benefit pace development machine ML specifically neural network NN domain numerical resolution replace NN reduce computational application prediction closure   computation situation supervise network directly predict profile autoencoder obtain steady prediction around elementary fusion convolutional neural network cnn predict velocity snapshot around cylinder weakly turbulent pressure around cylinder input neural network predict unsteady around circular cylinder minimize physical loss function compose regression error conservation cnns directly apply predict drag coefficient 2D airfoil arbitrary propose reliability prediction model indeed topological complexity input external user within boundary dataset training approach propose tackle issue context NN assist cfd outlier detection technique propose domain unsupervised attract attention label data autoencoder AE technique developed medical industrial application fully AE hidden layer apply breast cancer detection convolutional AE CAE detect crack  defect concrete structure CAE detect logo image mobile phone author variant AE anomaly segmentation brain magnetic resonance image autoencoder feedforward neural network widely apply dimension reduction feature extraction dimensional data sketch aes compose contractive encoder role compress input data reduce dimension latent latent representation input variable obtain bottleneck structure decoder mirror encoder responsible reconstruction input autoencoders unsupervised supervise application scenario unsupervised aes usually exploit infer latent structure dataset cfd community functionality AE potential candidate model reduction aes conjunction convolutional layer dimensional feature fluid author combine recurrent neural network CAE dynamic extract dimensional feature adversely supervise aes exploit perform various prediction task multiple variation AE structure net mention sketch net structure skip connection encoder decoder role concatenate feature contractive expansion concatenation stack tensor along channel axis feature latent representation net usually achieve excellent performance segmentation regression task author exploit net infer velocity pressure turbulent around airfoil compute reynolds average  stokes framework net architecture reconstruct turbulent extremely coarse image remarkable accuracy recurrent net architecture predict  velocity pressure porous membrane sketch autoencoder architecture standard autoencoders compose encoder decoder exploit regression task supervise label inference latent representation unsupervised without label net autoencoders specific AE skip connection encoder decoder feature latent contractive usually superior performance regression task image introduce autoencoder architecture twin decoder outlier detection context fluid prediction contribution novel twin decoder architecture display correlation input reconstruction prediction error advantage skip connection decoder correlation almost linear expense slightly prediction accuracy net structure uncertainty estimation procedure advantage latter qualitative procedure user error threshold binary decision regard prediction accept reject quantitative procedure user error interval prediction dataset unseen efficient detect applicability limit model rely concept easily apply prediction task organize setting dataset construction sect insight propose twin decoder architecture training procedure sect concept qualitative quantitative trust described sect performance explore hyper parameter calibration architecture accuracy ratio finally correlation model trust finally future perspective code available http github com  twin autoencoder sect additional detail dataset construction insight random dataset generation network dataset sketch detail reader refer generate arbitrary  curve  stokes equation immerse finally detail dataset random generation random drawn translate ascend trigonometric angle sort perform angle consecutive random compute average angle compute around  average parameter allows alter sharpness curve locally maximum smoothness obtain cubic  curve define curve define tangent curve tangent respectively sample successive  curve boundary description variety attain random generation cubic  curve image drawn dataset variety obtain restrain local curvature average parameter image numerical resolution  stokes equation incompressible  fluid described  stokes NS equation  velocity pressure fluid density dynamic viscosity identity tensor efficiently construct dataset immerse volume resolution instead avoid systematic mesh domain rely unified fluid solid eulerian formulation description geometry modify equation  introduce mixed quantity  subscript respectively refer fluid solid heaviside function reader refer additional detail formulation eventually modify cast stabilize finite formulation variational multi vms solver dataset dataset compose along steady velocity pressure label compute  cfd expose sect input resize 2D array network customary neural network training channel wise normalization apply mapping pixel visualize velocity pressure 2D array additional detail distribution dataset reader refer network input velocity pressure dataset computational domain upper along compute velocity pressure image network architecture training twin decoder architecture autoencoder architecture twin decoder propose contribution input consists boolean channel 2D tensor compute domain obstacle output channel 2D tensor reconstruct input channel tensor predict velocity component pressure encoder consists stack convolution convolution max pool kernel stride zero pad convolutional layer exploit rectify linear relu activation function pool operation kernel convolutional layer bottleneck decoder compose hereafter denote decoder decoder decoder compose deconvolution convolution convolution structure deconvolution layer kernel stride zero pad relu activation symmetrically encoder kernel halve decoder finally convolutional layer kernel apply channel decoder decoder output network hence contains channel tensor reconstruct input channel tensor velocity pressure ingredient propose architecture skip connection link decoder decoder output decoder concatenate along channel axis preserve output deconvolution layer decoder net feature originate encoder reconstruction input dependence decoder induce correlation performance essence enforce relation reconstruction error prediction error propose allows reject outlier reconstruction error latter compute arbitrary input user warn network prediction trust detail acceptance rejection procedure sect propose twin decoder architecture encoder convolutional layer max pool layer  image filter decoder transpose convolution apply input filter halve output layer decoder concatenate mirror counterpart decoder finally convolution layer apply layer convolution apply decoder obtain 3D tensor channel channel dimension input image training procedure loss function twin decoder architecture sum decoder loss decoder regular error mse loss function  respectively channel height width channel expression average error pixel 3D tensor loss function training    parameter remains tune sect network adam optimizer initial rate reduce epoch prevent overfitting validation loss monitor training network parameter initialize truncate  distribution training perform tesla gpu mini batch limit computational resource model evaluate  training sect trust reconstruction twin decoder neural network feasible evaluate trust prediction input reconstruction error twin decoder strongly correlate qualitative quantitative trust propose reconstruction error concept propose sub application network sect mse reconstruction respectively denote qualitative user acceptable mse prediction consists associate reconstruction error minimizes probability decision suppose error linearly correlate threshold reconstruction error minimization  mse scatter account numerator sum amount decision error decoder assume positively correlate formulation prevents user mistake accept reject prediction illustration description qualitative quantitative scatter plot versus training validation reference twin decoder architecture qualitative threshold correspond optimal user reject prediction reconstruction error superior prediction within quarter orange accepted quantitative model affine function uncertainty interval relation estimate along confidence interval prediction image quantitative quantitative associate confidence interval directly estimate relation  normal  assumption linear error scatter plot essence index standard deviation uncertainty prediction reconstruction formulation likelihood scatter    exp    optimal parameter obtain minimize negative likelihood       achieve gradient descent algorithm illustration minimum scatter training validation error evaluate difference qualitative prediction plainly accepted reject formulation allows estimate confidence interval without pre threshold accuracy additional flexibility reconstruction error associate prediction accuracy probability performance twin decoder architecture explore minimal hyper parameter calibration highlight impact loss parameter convolutional decoder structure kernel convolutional layer architecture evaluate performance unseen qualitative quantitative respectively sect finally comparison AE architecture propose reveal contribution skip connection decoder hyper parameter calibration impact parameter explore parameter convolutional convolutional kernel configuration network evaluate prediction performance correlation coefficient validation exploration detailed correspond convolution convolution encoder equivalently deconvolution decoder determinant regard performance decoder previous architecture performance costly architecture outperform deeper prediction probably due compression rate latent adversely architecture slightly correlation coefficient decoder error convolution kernel prediction accuracy highly dependent convolution kernel architecture symmetric scalable kernel convolutional layer hyper parameter advantage kernel increase beneficial hence kernel cnn complexity kernel conclusion correlation coefficient parameter parameter loss function crucial impact correlation decoder error decoder training beneficial correlation alleviate difference convolutional architecture kernel convolutional layer obtain correlation linear relation impact prediction accuracy accord obtain hyper parameter calibration performance evaluate validation accuracy prediction architecture mse average entire dataset image prediction accuracy evaluate computational training performance attain combination respect learnable parameter obtain tune architecture kernel parameter architecture choice accuracy ratio tesla gpu approximately training curve training validation subset training model training cease validation loss decrease successive epoch slight overfitting model image prediction performance obtain architecture various complexity propose model reconstruction accuracy generalization capability unseen data prediction along associate pixel wise error velocity pressure recover network error concentrate vicinity obstacle pressure velocity gradient obstacle portion predict metric propose pixel wise relative error compute surround obstacle correspond error distribution plot overall average relative error horizontal velocity vertical velocity pressure exceed relative error decent generalization capability prediction around obstacle instance prediction error error concentrate boundary pressure velocity gradient prediction pixel rgb colormap visualization image relative error prediction rectangle around obstacle indicates relative error compute histogram error obtain prediction label image correlation correlation obtain reconstruction prediction error comment autoencoder architecture twin decoder twin AE network architecture namely dual autoencoder dual AE net dual autoencoder dual AE dual AE architecture simply obtain remove skip connection twin AE dual AE exploit skip connection encoder instead reconstruction ensure comparison configuration architecture concatenation constant tensor apply decoder dual AE parameter dual AE twin AE scatter plot obtain twin AE training validation respectively associate correlation meaning linear relation validation regard training weaker correlation interpret consequence slight overfitting training comparison obtain correlation dual AE significantly weaker twin AE skip connection decoder twin AE slightly relative error dual AE counterpart respectively finally dual AE architecture exhibit almost correlation compute correlation adversely relative error dual AE significantly literature comparison scatter plot versus architecture correlation obtain twin AE training validation respectively dual AE dual AE architecture weaker correlation respective image trust input reconstruction application trust detailed sect underlie concept advantage correlation reconstruction error sect propose uncertainty estimation qualitative quantitative along prediction qualitative threshold error tolerance reconstruction user chosen correspond threshold reconstruction error obtain minimization dataset relatively limited exhaustive observes minimizes risk accept prediction reject prediction procedure validation mistake rate false classification rate subset plot function stricter choice inevitably performance accepted prediction plot along representation trust identification indicator optimal threshold obtain minimize mistaken classification rate training validation mistake rate significantly subset decrease threshold optimal mistake rate validation approximately image quantitative gradient descent algorithm minimize negative likelihood training obtain optimal parameter initial algorithm converges iteration optimal parameter retain minimize negative likelihood validation hence estimate regression confidence interval distribution handful couple outside confidence interval widens translates increase scarcity sample majority prediction grasp prediction quality probability probability confidence interval sample minimization negative likelihood BFGS algorithm image representation qualitative quantitative along scatter plot image estimate prediction outlier capability qualitative quantitative detect invalid input outlier evaluate multiple generate within dataset polygon dataset misplace input domain away dataset enlarge dataset outlier relative error outlier systematically obtain dataset prediction error polygon slightly prediction error misplace systematically superior enlarge extremely reconstruction prediction error prediction enlarge  illustrate incorporate uncertainty estimation outlier detection neural network architecture scatter plot along outlier qualitative quantitative polygon accepted qualitative average relative error polygon outlier relative error inspect polygon error feature considerably sharper others almost misplace enlarge reject qualitative interval quantitative enlarge due mse handful outlier propose amount outlier overall qualitative efficiently detects outlier prediction detect outlier detect interval quantitative outlier interval outlier prediction uncertainty misplace enlarge input partly estimate overall qualitative efficiently diminishes risk model input remains limited binary construction approximately discard dataset conversely quantitative adequate confidence almost nearly outlier however error interval input error underestimated finally similarly qualitative quantitative cannot account handful conjunction outlier model evaluation polygon generate sample sharper dataset misplace enlarge curve characteristic data ill significantly dataset image model performance polygon prediction reconstruction error outlier qualitative quantitative illustrate image prediction around enlarge  input outlier reconstruction associate prediction error prediction image conclusion contribution twin AE architecture 2D incompressible laminar prediction embed uncertainty estimation underlie motivation propose naturally incorporate outlier detection uncertainty estimation training procedure decisional potential user embed uncertainty estimation relies couple autoencoder prediction autoencoder input reconstruction chosen skip connection naturally enforces quasi linear relation prediction error input reconstruction error building trait effective qualitative quantitative technique propose detect outlier uncertainty prediction input network propose architecture dataset laminar around random 2D generate  curve hyper parameter calibration correlation coefficient reconstruction error prediction error outlier flaw polygonal belong dataset dataset misplace input domain significantly dataset efficient reject prediction error adequate uncertainty handful outlier remain undetected associate uncertainty estimate improvement improve network architecture improve error reconstruction error correlation gain dataset generation avoid inclusion outlier underline potential propose approach indeed implementation prediction task significantly risk user decision network prediction inadequate input effort pursue accurate input reconstruction dual AE feature encoder benefit prediction decoder twin AE equivalently beneficial feature improve prediction correlation twin decoder keywords neural network autoencoders anomaly detection computational fluid dynamic surrogate model