knowledge graph KGs critical role KGs KGs QA despite KGs suffer incompleteness fuel research relation prediction exist research relation prediction triple independently hidden relation inherently capture  simultaneously capture entity feature relation feature entity neighborhood entity importance estimation network attention graph embed propose consists attention graph embed module entity importance estimation module firstly embed entity hop attention graph embed module embed integrate entity importance estimation module entity importance hop central entity finally multi hop relation encapsulate auxiliary hop introduce realizes relation prediction task knowledge realize KGs QA realize relation prediction alleviates phenomenon relation precision KGs QA SQ datasets propose obtains relation QASE MCCNNs respectively introduction QA important challenge processing nlp application application research employ technique information retrieval IR information extraction IE user asks automatically however classical IR web extract information extensive user desire information manually contrast QA user interact intelligent user submit specific tailor mention goal QA generate request automatically worth mention concise respond unlike classical web retrieve document QA research nlp data source knowledge graph KGs construct QA KGs entity relation graph information KGs information triplet consist entity relation entity triple refer relational arrow entity entity data construct KGs dbpedia YAGO freebase effective convenient query technique user becomes increasingly important KGs structure knowledge knowledge encode access user via various technique QA KGs KGs QA KGs QA promising application access structure knowledge goal KGs QA automatically return request KGs propose KGs QA task synthesize structure query parse subsequently execute query KGs traverse KGs retrieve factoid neural KGs QA realize parse convert structure query execute structure query KGs extract link mention entity correspond entity node KGs employ another model logical extract KGs performance KGs QA hinder challenge instance KGs suffer incompleteness due difficulty enumerate accuracy KGs QA freebase source KGs relevant statistic unknown commonly relation birth education nationality coverage frequently entity furthermore coverage sparser entity specific freebase analogously KGs suffer due inevitable incompleteness restrict schema remedy relation prediction predict triple exist related triple percentage unknown freebase relation apply entity relation prediction broadly classify knowledge embed rank knowledge embed entity relation KGs vector representation knowledge embed learns representation entity relation embed realize utilize link prediction knowledge embeddings mitigate KGs incompleteness another rank explicitly model KGs feature prediction proposes context aware rank algorithm learns global semantics entity embed subsequently leverage knowledge semantics enumerate contextually relevant bidirectional random recently researcher apply knowledge graph embeddings convolutional neural network cnns learns expressive embeddings remarkably parameter nonlinear interaction entity relation enable however relation prediction triple independently hence hidden relation capture simultaneously capture entity relation feature entity neighborhood introduce newly emerge embed model explore entity importance estimation network attention graph relation prediction task embed entity hop attention graph embed module introduce aim estimate importance entity neighborhood central entity aggregation entity importance estimation predicate attention mechanism flexible centrality adjustment mechanism introduce encapsulate multi hop relation introduce auxiliary hop contribution fully knowledge embed hop attention knowledge graph embed model propose simultaneously capture entity relation feature hop neighborhood entity entity importance hop central entity aggregation entity importance predicate attention mechanism flexible centrality adjustment mechanism introduce encapsulate multi hop relation introduce auxiliary hop knowledge realize relation prediction implement KGs QA KGs QA perform task relation prediction infers latent relation exist related triple finally implement KGs QA  datasets propose obtains relation QASE MCCNNs respectively remainder structure sect review related statement overview KGs QA consists situation satisfactory unsatisfactory introduce sect respectively report dataset description implementation detail experimental conclusion future sect related related research KGs QA research relation prediction briefly review research KGs QA witness significant development KGs QA KGs QA evolve via approach utilize manually construct parse transform structure query aim reduce traversal domain knowledge manually approach overcome requirement neural KGs QA approach semantic parse truth query approach achieve extract factoid KGs another recent graph net however approach heuristic shortest entity factoid spurious incomplete KGs goal develop KGs QA relation prediction technology alleviate relation KGs QA relation prediction relation prediction task introduce annual competition text analysis conference grown popularity research summary standard related task   knowledge graph embed vector representation entity relation obtain relation prediction  utilizes convolutional filter 2D  entity relation embeddings capture feature interaction entity relation entity however feature interaction  capture limited  improves upon  increase feature interaction  novel knowledge graph embed alleviates limitation  capture additional heterogeneous feature interaction focus entity importance estimation network attention graph embed predict relation whereby extract entity relation feature multi hop neighborhood entity relatively related  novel embed model cnns multi layer graph convolutional network  optimal policy efficiently KGs global relation transitional feature entity relation KGs capture  relation prediction model expressive graph embed  multiple entity entity neighborhood relation prediction model estimate entity importance entity importance implement entity importance estimation module another related approach dai  nguyen dai  nguyen introduces knowledge embed model  proposes capsule network model triple plausibility triple conversely return confidence relation mention relation prediction technology infer hidden relation alleviate phenomenon relation KGs obtain accuracy KGs QA statement overview define KGs QA overview statement assume background knowledge KGs consist entity relation relation binary function  false indicates relation entity available KGs sequence KGs QA involves entity task extract entity overview introduce background knowledge overview KGs QA binary factoid QA focus binary factoid exist complex specific entity instance population  entity recognition entity recognition task regard sequence label directional memory lstm model predict entity relation link QA extract entity replace entity category denote semantic information extract vector model input candidate relation model finally candidate relation  obtain relevant relation overview image toy rdf knowledge graph image architecture simplify workflow KGs QA consists situation satisfactory situation namely exist relation unsatisfactory situation namely relation andy factual washington return identify andy mapping andy triple query   KGs satisfactory situation bob perform relation prediction task unsatisfactory situation satisfactory situation KGs QA binary factoid asks entity factual return identify entity relation mapping entity relation triple query KGs unsatisfactory situation perform task relation prediction apart entity recognition relation link relation prediction issue infers latent relation hidden satisfactory situation discus satisfactory situation technical detail entity recognition entity category goal entity recognition obtain core corresponds entity KGs propose entity recognition algorithm utilizes lstm identify entity overall algorithm input vector output label sequence category entity query entity replace category finally obtain internal representation entity recognition task regard sequence label lstm model predict entity instance  china china entity china label sequence output sequence entity sought otherwise actually perform data processing segmentation construction entity candidate candidate entity lstm model input vector separately obtain output vector namely output network output backward network output lstm layer fed sigmoid layer processing namely  output vector model output sequence corresponds information input output sequence consistent input sequence model error mse loss function mse define  bias predict model target hyper parameter normalization regularization lstm entity recognition model image extract entity query category entity category beijing shanghai important achieve conceptualization mechanism corpus model combine latent dirichlet allocation widely topic model  probabilistic knowledge conceptualize entity worth mention latent dirichlet allocation topic model capture semantic relationship facilitates understand entity increase interpretability entity model automatically performs disambiguation input hammer  hammer conceptualize instead KGs consist concept conceptualization mechanism granularity entity KGs transform internal representation capture semantics china firstly extract entity china query category entity namely finally template relation link task relation link link related relation related relation KGs extraction entity relation china identify entity china relation entity KGs alias population category finally related relation link closest relation KGs relational link model cnns image cnns introduce relation link task cnns convolution kernel convolution operation obtain important feature pool operation convolution kernel accord experimental requirement generally operation cnns convenient advantageous extract overall feature semantic information extract vector model bert input cnns model candidate relation separately model finally internal representation candidate relation  obtain relevant relation specific detail relation link algorithm relation link task essentially relevancy relation candidate relation KGs worth mention entity replace category influence entity mapping avoid cnns perform convolution operation candidate relation  respectively obtain semantic vector correspond  finally relevancy semantic vector  calculate obtain relation link training objective function express max   constant internal representation  candidate relation   positive negative respectively cnns training semantic vector  obtain cosine similarity calculate semantic similarity calculation    cosine angle vector  vector   semantic vector  candidate relation entity cosine distance calculates cosine angle vector vector angle closer cosine distance important cosine distance mainly judged direction greatly affected vector absolute advantage cosine distance calculate similarity entity relation knowledge graph KGs entity recognition technology relation link technology entity relation  KGs obtain easy obtain query KGs  entity  relation   easily andy washington  aim sequence maximize     relation prediction KGs QA image unsatisfactory situation discus unsatisfactory situation alleviate phenomenon relation relation prediction algorithm propose goal relation prediction obtain hidden relation entity propose relation prediction KGs QA model utilizes entity importance estimation network attention graph embed capture entity relation feature entity neighborhood latent relation entity specific detail relation prediction KGs QA algorithm mainly consists entity recognition relation link relation prediction entity relation knowledge graph aspect input KGs datasets output namely entity simplify architecture relation prediction KGs QA subgraph knowledge graph exist relation solid auxiliary relation dash image relation prediction core goal entity importance relation prediction task multi hop entity entity neighborhood infer relation hidden bob entity bob relation  KGs KGs suffer incompleteness marked dash propose entity importance estimation network attention graph embed consists attention graph embed module entity importance estimation module specific detail relation prediction algorithm aspect input entity relation  output infer triple  algorithm consists embed estimate importance entity introduction auxiliary hop embed entity goal obtain embed entity aim embed entity feature vector related triple neighborhood specifically embed concatenation entity feature vector relation feature vector related triple andy bob entity bob vector representation triple          denote vector representation entity andy bob relation respectively additionally linear transformation matrix importance related triple  absolute attention triple compute     indicates importance entity feature relation  feature entity  nonlinearity activation function linear transformation matrix  vector representation triple  absolute attention  easily comparable across triple  across choice entity normalize softmax function relative attention  compute    exp      exp         neighborhood entity  relation entity entity embed entity                 relation entity entity embed entity encapsulate information neighborhood multiple attention mechanism introduce principle multiple attention mechanism independent attention mechanism calculate embeddings entity calculate average embeddings attention mechanism embed entity                estimate importance entity neighborhood central entity owe phenomenon relation KGs retrieve KGs identify central entity bob relation  knowledge hop central entity bob infer hidden relation hop central entity bob exist related triple bob andy bob profession lawyer bob  goal obtain importance entity hop central entity aggregation entity importance predicate attention mechanism flexible centrality adjustment mechanism introduce estimate entity importance aggregate entity importance instead entity embed obvious advantage reduce model parameter instance andy important entity hop central entity bob estimation importance importance andy entity importance estimation framework equip network layer multiple aggregation layer centrality adjustment layer network fully neural network focus entity feature vector return initial importance aim obtain initial estimation network input entity feature network computes initial entity    input feature vector entity equation entity importance estimation framework consists multiple aggregation layer quantity aggregation performs aggregation attention computation independently index aggregation marker aggregation layer aggregation aggregation aggregation layer initial estimation entity importance network output previous aggregation layer input aggregation layer aggregation layer contains aggregation independently entity importance estimation max pool function execute estimation estimation importance      directly model relationship importance entity aggregation express  hop entity entity parameter aggregation aggregation layer moreover aggregation aggregation layer relative attention define exp  exp  nonlinearity activation function vector  vector representation relation entity entity  vector representation relation entity entity addition entity importance estimation framework flexibility account estimation importance basis entity centrality adjustment accord entity centrality output aggregation layer aim aggregation shift parameter apply aggregation shift centrality apply aggregation layer initial centrality entity aggregation aggregation layer centrality adjustment output aggregation layer perform average nonlinearity  apply aggregation centrality adjust estimation compute  average central entity bob hop bob andy andy washington bob andy bob andy andy profession programmer bob andy andy  bob  bob   profession teacher bob   york illustrate previously mention importance andy hop central entity bob analogously entity andy hop central entity bob namely bob andy andy washington bob andy bob andy andy profession programmer bob andy andy  perform aggregation entity importance predicate attention mechanism flexible centrality adjustment mechanism aim important entity hop central entity bob namely washington relation prediction exist related triple relation prediction task achieve assign relative attention entity neighborhood attention propagate via layer iterative however increase iteration contribution entity becomes promising aforementioned relation composition achieve introduce auxiliary dot hop model learns importance related triple hop central entity bob importance andy hop central entity bob importance washington hop central entity bob importance bob andy andy washington model auxiliary dot entity introduce illustrate vector representation auxiliary relation summation vector representation exist related triple auxiliary relation understood bob andy plus andy washington hop neighborhood central entity relation prediction task summary QA datasets summary KGs datasets entity relation knowledge graph KGs entity recognition technology relation link technology relation prediction technology entity relation  KGs obtain easy obtain query KGs  entity  relation   easily bob washington  aim sequence maximize     evaluate KGs QA QA corpus KGs datasets QA corpus KGs datasets described detail sect goal KGs QA deliver quality model address relation KGs experimental setting experimental data detail benchmark benchmark evaluate KGs QA KGs QA previous  SQ  relation KGs QA corpus corpus compose annotate correspond entity fbk freebase QA corpus consists specifically QA corpus category training corpus validation corpus corpus training corpus update model parameter bias validation corpus adjust hyper parameter corpus evaluate performance  WQ  training google api crowdsourcing fbk quarter training training validation    compose construct fbk dataset diversity another benefit domain astronomy medicine etc specifically QA corpus consists domain relation topic entity QA dataset evenly split category training training training data validation data link data QALD QALD focus multilingual hybrid QA benchmark deliver fifth evaluation campaign link data QALD compose construct version dbpedia specifically QA corpus category training data data quarter training data training validation QA datasets construct fbk dbpedia statistic addition sake reproducibility conduct benchmark KGs namely fbk dbpedia widely evaluate model performance KGs QA task statistic benchmark KGs experimental fbk datasets  complex  denotes   implementation detail model comparable comparative model parameter experimental environment KGs QA comparison construction training KGs QA realize experimental configuration experimental platform instal intel core TM 6G ram operating python associate model corpus central entity relation respectively obtain entity recognition technology relation link technology task detailed refers sect relation prediction task training procedure firstly attention graph embed model obtain embed graph entity entity importance estimation model entity importance hop central entity finally multi hop relation encapsulate auxiliary hop introduce realizes relation prediction task adam optimize parameter initial rate evaluation metric relation prediction rank MR reciprocal rank MRR adopt evaluate performance model MR MRR express      indicates evaluation  indicates sort candidate  overlap standard  indicates sort candidate counting important MR MRR model performance evaluate performance model classical metric precision recall standard model query retrieves precision recall define simplicity adopt combine namely  moreover average evaluation introduce average define    effectiveness evaluate model performance conduct relation prediction report MR MRR KGs QA evaluate average QA performance KGs QA without relation prediction proportion relation SQ WQ  QALD datasets image performance QASE MCCNNs configuration SQ datasets image effectiveness relation prediction KGs QA KGs suffer incompleteness relation prediction module improvement relation prediction module verify effectiveness relation prediction module experimental relation prediction module previous publish evaluation metric MR MRR relation prediction module performs closely   experimental datasets fbk instance  module achieves significant improvement MR MRR relative improvement MR MRR obtain relation prediction module moreover relation prediction module obtains MRR  complex  MRR respectively experimental demonstrate MR MRR module respectively improves  performance QASE MCCNNs configuration WQ datasets image effectiveness knowledge graph performance proportion relation KGs QA performs deployment obtains invokes relation prediction module average compute proportion relation average decline incompleteness KGs relation apply entity proportion relation increase average datasets trend decline average KGs QA relation prediction KGs QA relation prediction invokes relation prediction module hidden relation improve model performance KGs QA average increase significantly relation prediction module invoked relation average increase relation prediction configuration SQ WQ  QALD respectively comparison intuitive baseline evaluate QA extend exist KGs QA relation prediction concretely QASE MCCNNs initial training KGs QA additionally without relation prediction configuration perform QA without relation prediction baseline obtain information average configuration namely relation prediction relation prediction depict relation prediction bypass performance decline performance proportion relation relation prediction obtains relation QASE MCCNNs respectively competitor average relation propose model improve QASE MCCNNs respectively performance QASE MCCNNs configuration  datasets image performance QASE MCCNNs configuration QALD datasets image QA WQ QASE MCCNNs excellent relation propose model improve QASE MCCNNs respectively propose obtains relation QASE MCCNNs respectively implies effective QA relation prediction configuration performance  performance proportion relation additionally QASE MCCNNs  performance proportion relation proportion relation performance model baseline improve performance baseline invoke relation prediction configuration relation prediction configuration predict hidden relation improve model performance propose obtains relation QASE MCCNNs respectively relation propose model improve QASE MCCNNs respectively analogously QA QALD verifies propose approach superior QASE MCCNNs propose approach obtains relation QASE MCCNNs respectively relation propose model improves QASE MCCNNs respectively relation prediction bypass performance decline performance proportion relation exist comparison exist exist SQ WQ  QALD category template outperforms competitor significantly  query workload training data performance   binary factoid due limitation exhibit limited ability  creates dependency representation exist syntactic parser performs rewrite predefined contribution realize relation prediction implement KGs QA relation prediction indeed effective relation prediction module significantly boost performance entity recognition relation link KGs image visualize attention image QA incomplete KGs relation prediction newly emerge KGs QA technique KGs greatly increase importance commercial QA focus binary factoid bob mention previous analysis entity recognition relation link denote preliminary propose KGs QA previously mention KGs suffer incompleteness relation bob  KGs QA fails remedy relation prediction predict triple exist related triple sample correctly relation prediction candidate relation exist related triple exist related triple described detail sect illustration attention user important model capture attention properly attention mechanism crucial role obtain attention aspect important understand useful selection bob crucial role entity aspect aspect relation aspect respectively conclusion future capture entity relation feature entity neighborhood entity importance estimation network attention graph embed propose compose attention graph embed module entity importance estimation module firstly attention graph embed module embed entity hop entity importance hop aggregation entity importance predicate attention mechanism flexible centrality adjustment mechanism introduce encapsulate multi hop relation introduce auxiliary hop worth mention alleviates phenomenon relation improves precision KGs QA however future intend extend capture relation entity attention model keywords knowledge graph KGs QA relation prediction attention graph embed entity importance estimation