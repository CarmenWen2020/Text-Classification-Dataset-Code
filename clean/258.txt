data network DCNs objective coexist compete limited network resource bandwidth buffer without harmonious resource planning chaotic competition severe performance degradation furthermore latency critical emerge application augment reality AR virtual reality VR telepresence network challenge address issue  proposes receiver driven layer framework HOPASS incorporates layer layer strike balance multiple network objective achieve latency layer ensures bandwidth guarantee aggregate multi objective network utility maximization num online approach dispatch data configure switch queue functionality configuration dictate layer layer leverage token packet receiver dynamically probe reserve network capacity proactively prevent network congestion guarantee latency data delivery evaluate propose framework implement HOPASS conduct extensive various network scenario simulation HOPASS achieves optimal performance bandwidth allocation multi objective scenario guarantee delay moreover outperforms   average bandwidth utilization global network utility aggregate therefore conclude HOPASS effective framework DCNs multi objective optimization latency network previous keywords data multi objective optimization receiver driven protocol schedule bandwidth allocation introduction due development emerge application various service requirement data network DCNs performance objective coexist compete limited network resource infrastructure service introduce multiple virtual machine vms amount various resource vms customer achieve quality service qos brings significant challenge network resource allocation schedule application demand definition video associate throughput meanwhile application  network conference latency moreover application demand throughput delay augment reality AR virtual reality VR telepresence application email effort service evident objective conflict multi objective network utility maximization num strike balance conflict objective tremendous amount effort num however exist optimize network performance objective    focus optimize performance objective maximum throughput minimum congestion minimum latency objective optimization degradation performance metric objective throughput delay naturally contradict simply apply objective satisfy application requirement hurt performance application objective desirable performance objective achieve relative fairness however multi objective resource allocation objective orient schedule various constraint achieve performance balance address congestion network data congestion challenge  incur massive bursty concurrent traffic parallel compute distribute application traditional sender driven transport layer protocol tcp cubic  cannot ensure queue delay zero data loss throughput  scenario moreover DCNs queue delay contribute factor latency propagation delay therefore commonly communication DCNs propose adopt receiver driven congestion resolve issue driven protocol popular recently congestion issue DCNs due  traffic receiver driven sender guaranteed amount traffic token receiver scheme reacts network congestion proactive instead passive manner sender driven scheme propose HOPASS layer framework DCNs cooperation layer HOPASS achieve optimal performance global multi objective num guarantee latency specifically HOPASS consists layer layer scl allocates bandwidth aggregate objective coarse grain mode layer fcl grain mode driven protocol schedule allocate bandwidth scl congestion function challenge layer framework firstly objective contradict scheme ensure fairness across challenge secondly enforce multi objective optimization distribute manner desirable practical implementation thirdly ensure latency prevent starve propose framework HOPASS address challenge contribution summarize layer framework multi objective num ensure latency framework layer focus multi objective num resolve congestion respectively layer balance performance objective ensure latency data online approach multi objective num layer approach num variety utility function propose converges convergent optimal objective orient schedule receiver driven approach receiver dynamically adjust token rate estimate network congestion packet rate schedule frequency sender data token mechanism positively address congestion requirement latency sensitive mouse bandwidth hungry elephant organize introduces related motivation describes detail HOPASS model theoretic analysis scl fcl respectively evaluates HOPASS  classic performance HOPASS finally conclusion background motivation multi objective network utility maximization DCNs associate application performance requirement completion throughput exist focus optimize performance objective minimize delay maximize throughput  convert bandwidth allocation network utility maximization num distribute manner however  cannot extend multi objective num detail phost pFabric   typical objective minimize completion FCT coexistence multiple utility network none effective exist multiple objective fail clarify allocate resource objective converge optimal allocation scc propose layer multi tenant multi objective bandwidth allocation solves scc resource allocate  propose hierarchical bandwidth allocation framework optimizes performance requirement throughput fairness however  purely centralize global information network induces convergence besides approach apply bandwidth allocation recently useful highly dynamic network author propose centralize schedule strategy reinforcement DRL author DRL approach adjust transmission rate adapt dynamic network however modify reward function realize objective achieve multiple objective receiver driven protocol congestion typical application dcn mapreduce web distribute machine employ communication bursty arrival concurrent  traffic essentially network congestion receiver hence traditional sender congestion scheme fail perform congestion signal deliver delayed sender react delayed signal avoid congestion passive instead receiver driven protocol enables proactive congestion token packet sender initiate sends request rts message receiver rts message receiver determines data packet sender available network capacity receiver issue associate token sender per maximum transmission MTU token receiver sender sends packet therefore token strictly determines amount data traffic sender pours network sender rough estimate available network capacity receiver avoid network congestion bursty traffic pour network adjust token rate however exist receiver driven protocol mainly focus minimize completion FCT latency sensitive mouse bandwidth hungry elephant become starve due priority achieve without differentiate qos furthermore congestion within core network queue switch network core production trace topology phost average queue delay IMC per link propagation delay queue delay crucial latency characteristic fcl comparison fcl summarize phost  author assume congestion happens network core network congestion hence propose receiver driven approach cannot apply network congestion  tackle network congestion issue actively limit token rate switch enforce symmetric route token data packet however non trivial modification switch highly undesirable commodity switch although fcl switch achieve performance cooperation scl operation switch implement motivation challenge nowadays optimization network performance attention efficiency network resource throughput bandwidth utilization delay trend  application data network satisfy differentiate requirement user concentrate application efficiency multi objective num data network limited network compute transmission resource reward network customer service obtain network resource utility function obtain bandwidth reward introduce quantify network utility diversified user define optimization objective parameter utility function objective data network focus mainly limited utility function requirement bandwidth fairness focus fairness bandwidth allocation user proportional fairness fairness accord hospital utility function fairness convert utility function proportional fairness utility function concentrate performance metric completion function optimization objective correspond utility function objective  function proportional fairness fairness minimize completion remark ensure utility function concave scenario multi objective coexistence allocate limited network resource reasonably maximize utility data network utility function data network model multi objective num mathematical expression utility function coexist network objective utility function objective bandwidth capacity link bandwidth allocation bandwidth allocation objective matrix denotes link network matrix link otherwise constraint mainly limited link capacity constrain utility function concave function multi objective num transform convex optimization mathematically lagrange multiplier kkt karush kuhn tucker rely centralize architecture mathematical mention theoretically feasible challenge practical application traffic data network increase multi objective num although centralize architecture guarantee globally optimal introduces communication calculation communication latency extensive information exchange central controller network device host switch calculation centralize convex optimization however traffic data network obvious characteristic occupy traffic transmit optimal bandwidth allocation contrary distribute architecture packet cannot guarantee convergence global optimal decision local information neither centralize architecture distribute architecture simultaneously accurate consideration address inevitable framework layer framework analysis complicate multi objective num achieve multi objective performance latency guarantee reasonable congestion distribute manner challenge achieve researcher macro perspective aim request rout mapping request service machine CRE logically centralize cognitive rout random neural network reinforcement overlay node public internet communication optimal overlay minimal monitoring overhead reinforcement sdn controller user request appropriate server request satisfied online qos aware adaptive task allocation scheme response assign task sub splitting task arrival sub rate compute host processing capability instead request instantiate service focus service placement optimization sdn machine focus finer granularity suppose destination multi objective guarantee stable bandwidth allocation latency simultaneously propose layer framework incorporates layer layer address specifically layer coarse granularity allocates network resource macroscopic aggregate layer adaptive static network network topology guarantee bandwidth allocation aggregate layer operates decentralize adaptive dynamic information network non persistent congestion layer considers latency sensitive mouse bandwidth hungry elephant illustrate layer framework layer critical ensure performance suppose layer guarantee latency network effective bandwidth allocation without network congestion layer contrary global performance guarantee without layer overall network performance severely affected layer combine balance contradiction accurate bandwidth allocation schedule packet HOPASS illustrate HOPASS goal achieve multi objective num latency network infrastructure reasonable congestion ultimately achieve goal innovation algorithm strike balance accuracy efficiency framework profoundly traffic architecture data network dimension framework algorithm overview architecture nervous important  mainly compose brain spinal cord brain responsible regulate complex activity spinal cord responsible reflex activity knee jerk reflex inspire nervous john  propose neural theory emphasize importance combine centralize distribute theory propose coordinate distribute framework framework distribute framework essence guarantee delay transmission delay however allows node fully coordinate information longer optimal calculate adjust packet propose framework regard compromise centralize distribute framework accurate ensure timeliness propose coordinate distribute framework hierarchical HOPASS multi objective num data network unlike paradigm traditional pure distribute centralize hierarchical structure leverage conquer num multi objective decompose sub coarse grain bandwidth allocation focus allocate bandwidth objective maximize overall utility network define utility function coexist network utility function objective bandwidth capacity link bandwidth reserve objective link grain packet schedule define mainly focus objective num realizes objective orient packet schedule specific bandwidth constraint besides important latency dcn packet schedule objective transmission rate objective indicates objective link link otherwise HOPASS consists layer scl layer fcl scl responsible macro network resource allocates network resource relatively timescale usually microsecond optimal bandwidth allocation objective maximize overall network utility fcl focus micro schedule packet bandwidth pre allocate scl objective input fcl specific packet strategy allocate bandwidth pre allocate objective another target fcl effort performance guarantee latency sensitive mouse bandwidth hungry elephant HOPASS combination scl fcl ensure schedule packet calculate optimal bandwidth allocation scheme improve overall utility DCNs detail HOPASS deployed switch scl prefers leverage approach bandwidth allocation objective scl schedule aggregate specific link utility function classify aggregate scl local information coarse granularity optimal decision cycle scl relatively scl packet schedule therefore scl cycle fcl significantly available packet schedule fcl diversified adjustment transmission rate queue management strategy etc deployment fcl queue management strategy deployed switch ensure network traffic approximates optimal calculate scl deployed host transmission objective orient packet schedule fcl compatible exist redesign objective previous modification exist  layer algorithm verify feasibility redesign receiver driven protocol congestion fcl proactive congestion fcl requirement bandwidth latency layer illustrate scl detail coarse grain bandwidth allocation scl algorithm challenge requirement upper layer application user demand service quality layer data network expression parameter utility function diversified expand traffic DCNs highly dynamic difference uncertainty objective priority besides burst traffic network failure inevitable unpredictable traditional DCNs network mathematical model guarantee specific network accurate model network environment user requirement challenge mention HOPASS applies online convex optimization approach scl online approach advantage firstly independent specific model secondly traditional model approach approach applicable wider utility function restriction utility function limited ensure optimal utility function smooth strictly concave leverage online gradient descent odd online convex optimization scl dynamically optimal optimal bandwidth allocation scheme periodic exploration decision scl algorithm scl explore reward bandwidth allocation scl decision historical decision feedback image KB image cycle layer scl continuous slot bandwidth allocation update slot cycle consists phase exploration phase decision phase exploration phase contains slot slot phase objective coexist network exploration phase slot explore reward specific bandwidth adjustment strategy reward estimate increment utility objective decision phase contains slot accord exploration phase decision maker calculate bandwidth allocation potential reward aggregate denote aggregate coexist link ratio capacity utility link ensure utilization bandwidth avoid waste resource constraint therefore allocate bandwidth link aggregate calculate exploration phase slot explore reward bandwidth allocation adjustment direction bandwidth adjustment direction bandwidth utility increase fix reward bandwidth utility reduce proportion slot exploration stage accord network measurement decision maker correspond utility function quantify transmission performance slice numerical bandwidth allocation strategy calculate bandwidth allocation previous cycle slot within exploration phase bandwidth allocation increase others decrease maintains constraint expression bandwidth update summarize update allocate bandwidth aggregate link impact convergence algorithm scl induce convergence undesirable highly dynamic network inappropriate induces coarse feasible suboptimal decision phase decision maker evaluates bandwidth allocation strategy explore exploration phase bandwidth adjustment direction potential reward decision maker reward reward previous decision phase reward decision maker update bandwidth allocation accord otherwise network utility cannot improve adjustment bandwidth allocation bandwidth allocation remain previous cycle index slot gain network utility increment decision phase risk overshoot optimal increase upper boundary sensitive variable aggressive bandwidth strategy update layer discus fcl mention implementation fcl queue management strategy switch transmission protocol host queue management strategy switch avoid mutual interference packet objective schedule scl  guarantee performance isolation objective isolated queue mechanism fcl multiple isolated queue replace queue manage packet packet optimization objective queue ensure actual network traffic approximate bandwidth allocation calculate scl robin mechanism inter queue schedule strategy fcl packet management strategy inside queue depends transmission protocol macro bandwidth allocation calculate scl update queue management strategy parameter periodically HOPASS host rely explicit congestion notification ecn mechanism realize proactive adjustment accord congestion packet dequeue accord fifo manner besides packet marked ecn label queue exceeds threshold threshold update periodically output scl transmission protocol host specifically fcl receiver driven congestion participant sender switch receiver implement layer algorithm mainly packet host queue management switch realization function data packet host mainly packet header parameter data packet behavior host data packet mainly update reading information exchange intermediate node algorithm sender rts message pioneer data packet receiver rts message contains information pioneer data packet transmission without batch token receiver mitigates delay reduces latency subsequent data transfer sender data arrival correspond token switch ecn firstly network congestion occurs queue exceeds threshold data packet marked switch congestion information receiver handle secondly enhance cooperation scl fcl deployed switch robin schedule objective image KB image layer overview receiver responsible schedule update token rate handle network congestion algorithm receiver maintains queue active queue active receiver receives rts correspond queue accord achieve optimal performance latency sensitive receiver HOPASS applies shortest remain processing  schedule inside queue active  optimal algorithm minimize FCT however queue schedule obvious starve introduce metric assign alleviate conflict relatively relatively define constant relatively preempt easily relatively opt optimal FCT completion network specifically token receiver sender increase namely schedule receiver receiver relative opt opt respectively assume schedule schedule finally schedule image KB image schedule receiver simply adopts robin WRR schedule assign token frequently priority due active schedule slot avoid bandwidth waste schedule scheme aim improve throughput compromise FCT however WRR schedule cannot handle network congestion network congestion traffic therefore congestion occurs besides achieve bandwidth allocation token rate decrease ecn proven efficient congestion data network available commodity switch ecn signal congestion adjust token rate react congestion receiver furthermore bandwidth allocation trick  introduces decrease rate congestion happens reasonable objective embed token loop formula algorithm token loop achieve objective data packet correspond logical queue implement inside switch along robin schedule layer configure ratio capacity queue aggregate data rate belonging slice exceeds allocate capacity persistent queue built queue exceeds ecn threshold subsequent data packet marked receiver adjust token rate accordingly layer gradually capacity allocate layer objective fairly compete allocate bandwidth image KB image model theoretic analysis theoretic analysis layer HOPASS respectively analysis scl verify correctness efficiency multi objective num analysis fcl mainly focus deployed host receiver driven protocol analysis layer explore ensure scl algorithm converge optimal associate proof establish gradient descent effective online convex program average regret guaranteed approach zero apply gradient descent algorithm convex optimization objective function concave local maximum local maximum gradient descent algorithm global maximum reduction  apply principle assume bandwidth allocation vector calculate scl local maximum instead global maximum another bandwidth allocation vector satisfy linear constraint construct vector accord concave function inequality approach become neighborhood however contradicts assumption local maximum local maximum inequality neighborhood therefore assumption invalid local maximum global maximum convex optimization described formula convex optimization principle apply proof described firstly feasible formula convex constraint linear secondly sum utility function concave specifically verify concavity calculate derivative objective function num positive bound meaning utility function concave therefore objective function concave analysis layer analyze fcl theoretic perspective develop fluid model feedback loop token rate model derive classification threshold influence bandwidth queue delay experienced detailed illustration fluid model review update token rate congestion receiver maintains estimate marked data packet estimate update roughly marked data packet recent fix parameter exponentially average estimation token rate normalize update clearly token rate normalize nearly reduce congestion fluid model analyze behavior token loop develop fluid model predefined traverse bottleneck switch capacity bottleneck resides data packet whereas token packet sender without congestion non linear delay differential equation dynamic token estimate marked data packet queue switch propagation delay assume approximate fix delay indicates packet bottleneck switch normalize model evolution token rate standard additive increase congestion multiplicative decrease model reduction token rate factor congestion occurs continuous approximation model queue evolution net input rate bandwidth capacity numerical analysis plot trajectory token queue compete bottleneck switch HOPASS periodic stable token stabilize around sender HOPASS immediately sends data packet receives token throughput essentially proportional token bottleneck increase phase token backoff ecn marking stable decrease phase token rate satisfies maximal token decrease phase therefore peak token rate achieve strictly influence classification threshold analyze influence classification threshold WRR schedule suppose threshold classify schedule frequency arrival poisson rate DCNs distribution assume distribution pareto distribution index pareto index probability density function distribution threshold classify queue schedule frequency sufficient token average queue schedule frequency compute production data trace satisfies increase function threshold token data packet directly network transfer react token loop therefore amount data packet bottleneck queue token assign receiver bottleneck queue ecn threshold denote token maximal token proportional steady increase threshold threshold harm bandwidth queue schedule frequency increase compensate damage bandwidth however maximal queue delay approximate increase harm delay experienced evaluation evaluation HOPASS analyze simulation evaluate pFabric evaluate approach network topology utility function HOPASS exist approach effectiveness evaluation overall performance HOPASS layer HOPASS implement HOPASS  tcp  performance metric average bandwidth utilization overall network utility optimality layer HOPASS aim multi objective num aggregate evaluate feasibility layer scenario objective coexist cvx toolbox matlab calculate optimal multi objective num HOPASS verify accuracy performance conduct extensive simulation evaluate performance layer topology workload traffic model performance metric performance phost pFabric overall performance HOPASS evaluate overall performance HOPASS perform simulation topology complex workload multiple objective coexistence scenario topology tier multi typical topology data network simulation tier multi topology core switch aggregation switch link core link link host aggregation switch link tier multi core switch aggregation switch aggregation switch sixteen host capacity link gbps capacity core link gbps propagation delay host workload  workload workload measurement application enterprise web service obvious feature contribute workload  obeys exponential distribution performance metric evaluation continually objective coexistence scenario utility function respectively setup verify performance HOPASS HOPASS  widely deployed congestion algorithm tcp  traditional transport protocol algorithm implement simulator topology workload conduct simulation performance metric evaluate approach average bandwidth utilization link global network utility aggregate HOPASS achieve global network utility aggregate   prof effectiveness layer update bandwidth allocation strategy network probability achieve considerable global utility aggregate optimality layer experimental setup evaluate performance layer conduct packet simulation calculate optimal bandwidth allocation cvx toolbox matlab evaluation mainly focus convergence optimality layer decision topology chose topology simulation topology asymmetric tier multi core switch aggregation switch host capacity link gbps propagation delay core link capacity gbps propagation delay core link link buffer switch MB image KB image topology setup layer focus multi objective num aggregate link simulate aggregate utility function generate sender receiver respectively bottleneck link source destination performance objective proportional fairness fairness minimum completion utility function optimality HOPASS evaluate optimality HOPASS multi objective num bandwidth allocation objective utility bottleneck link optimal calculate matlab cvx toolbox convex optimization solver ensure network converge stable bandwidth allocation MB performance metric verify HOPASS suitable objective network preference objective parameter utility function conduct multiple bandwidth allocation HOPASS optimal calculate matlab verify optimality HOPASS objective define formula difference HOPASS optimal denotes normalize error HOPASS optimal denotes maximum utility optimal bandwidth allocation denotes utility bandwidth allocation HOPASS comparison bandwidth allocation HOPASS calculate matlab utility   proportional fairness    fairness   utility mbps mbps mbps mbps mbps  mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps mbps experimental analysis bandwidth allocation HOPASS ideal error utility HOPASS ideal regard optimal error inevitable limited precision convergence layer algorithm HOPASS optimal optimal multi objective network utility optimization scl evaluates convergence layer simulate various MB MB GB respectively measurement simulation sample simulation rate aggregate network stable bandwidth allocation simulation converge bandwidth allocation mbps mbps mbps optimal bandwidth allocation accord besides inject traffic network convergence within attribute layer quickly respond dynamic image KB image throughput rate aggregate bottleneck link multiple objective coexistence scenario besides HOPASS achieve utilization bandwidth throughput bottleneck link capacity HOPASS ensures link converges bandwidth utilization quickly owe utilization bandwidth scl fcl algorithm HOPASS layer sum bandwidth allocation ratio waste bandwidth cycle besides layer algorithm strictly aggregate rate objective bandwidth constraint layer contributes utilization bandwidth verify performance layer experimental layer simulation evaluate performance fcl topology workload traffic model performance metric performance phost pFabric topology tier multi topology phost pFabric  tier multi topology consists component layer core switch core switch aggregation switch layer aggregation switch host layer link core aggregation switch gbps link host aggregation gbps link propagation delay network switch implement rout switch queue buffer pFabric dumbbell dumbbell topology consists switch sender receiver link gbps propagation delay buffer switch image KB image topology workload naive workload approximately MB mainly verify bandwidth performance fcl phost pFabric trace IMC data mining web phost IMC data mining workload web traffic model generate model concurrent traffic concurrent generate accord poisson distribution default traffic traffic phost host sender receiver arrival poisson distribution  traffic receiver specify data source performance metric slowdown slowdown evaluate completion phost pFabric opt denotes optimal FCT denotes actual FCT observation slowdown denotes ratio opt closer slowdown performance image KB image dumbbell topology slowdown fcl pFabric optimal due shortest remain processing strategy phost queue delay fcl phost fcl throughput pFabric phost image KB image dumbbell topology pFabric excessively suppresses throughput sample phost receiver schedule schedule fcl achieves bandwidth image KB image fattree topology layer slowdown pFabric phost queue delay phost throughput consistently pFabric phost data mining trace concurrent dumbbell topology naive workload concurrent traffic model performance fcl dumbbell topology generate sender sender receiver receiver respectively generate randomly arrival poisson distribution performance pFabric phost fcl parameter pFabric phost evaluate slowdown throughput cdf queue delay fcl FCT pFabric phost queue delay pFabric phost fcl schedule frequently mechanism minimize FCT mechanism receiver rate network congestion occurs specifically accord FCT queue delay price acceptable throughput degradation phost degrades expire token exceeds  congestion  adaptive throughput FCT queue delay pFabric priority schedule priority packet significant role FCT rate prevents spurious packet approximate  however throughput series diagram protocol pFabric suppresses throughput switch priority sample schedule switch starve phost schedule receiver switch fairly allocates bandwidth incoming cannot guarantee bandwidth application fcl approach bandwidth allocation mechanism receiver addition link capacity remain bandwidth absolutely obey ratio interference rate increase phase default traffic tier multi topology scheme scalability topology default traffic trace evaluate protocol performance indicates fcl achieves FCT pFabric phost improves throughput besides queue delay fcl phost pFabric queue delay pFabric achieves global optimization FCT switch schedule data moreover ignores objective throughput phost handle congestion token hence behavior unstable throughput fcl achieves latency throughput employ WRR schedule receiver WRR schedule schedule frequently guarantee bandwidth conclusion innovatively proposes layer network resource allocation framework HOPASS DCNs multi objective num ensure latency network reasonable congestion HOPASS consists layer scl layer fcl layer scl propose approach multi objective num aggregate fcl adopts receiver driven approach performance guarantee latency sensitive mouse bandwidth hungry elephant proactive congestion distribute manner requirement bandwidth simulation HOPASS achieve optimal multi objective num multi objective scenario topology bottleneck link bandwidth utilization propose convergence algorithm error theoretical optimal matlab addition limited additional overhead propose scheme achieves vibration overall network utility typical data  fully verifies superiority HOPASS finally leverage HOPASS flexible applicable network utility