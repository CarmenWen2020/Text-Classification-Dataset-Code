sample challenge machine task text image classification performance task enhance via transfer helpful knowledge related domain refer transfer previous transfer instance transfer algorithm mostly focus source domain instance target domain instance transfer however instance usually directly contribute performance target domain hypothesis transfer algorithm focus model parameter transfer treat source hypothesis transfer knowledge parameter target hypothesis algorithm directly optimize target hypothesis observable performance improvement however fail instance contribute source hypothesis harmful target hypothesis instance transfer analyze relieve aforementioned propose novel transfer algorithm analogical strategy particularly propose algorithm learns revise source hypothesis instance contribute target hypothesis propose algorithm transfer revise source hypothesis target hypothesis sample analogical hypothesis denote algorithm analogical transfer extensive synthetic dataset benchmark datasets demonstrate superior performance propose algorithm CCS concept compute methodology visual content index retrieval additional transfer classification introduction background despite recent advance machine application text image classification conventional supervise algorithm satisfactory schema model data challenge sample   shot attract attention recent research difficulty shot optimize model data label training instance sufficient pre label data related domain address transfer TL TL benefit shot transfer helpful prior knowledge pre source domain prior knowledge source domain performance task target domain improve sample critical TL shot negative transfer negative transfer occurrence  influence performance transfer knowledge source domain target domain previous TL attempt relieve mainly feature instance model parameter focus TL algorithm instance transfer  assumes negative transfer source data mislead target task therefore suggests  source instance typical  algorithm analyze  representation distribution source target domain however target instance source instance precisely moreover source data helpful weaken performance due variously representation distribution data parameter transfer PTL model transfer assumes related task parameter hyperparameters prior distribution refer typical algorithm hypothesis transfer HTL HTL considers source hypothesis classifier already directly integrate target hypothesis negative transfer HTL define failure satisfy improvement IC assumes negative transfer occurs hypothesis transfer cannot improve performance target task HTL treat source hypothesis already ignores negative transfer inconsistency source instance target instance analyze  consequently cannot avoid dilemma source instance contribute source hypothesis harmful target hypothesis analogical transfer relieve aforementioned article propose novel algorithm analogical transfer ATL conventional TL research assume target domain source domain related therefore source instance related target instance target domain introduce analogy strategy TL cognitive theory propose analogy strategy stage schema revision learner source instance accord contribution directly target hypothesis source hypothesis source instance stage learner revise source hypothesis source hypothesis source instance inconsistent acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer algorithm guava revision stage target genus guava learner selects source instance related target instance related guava revise source hypothesis transfer stage analogical hypothesis conclude observation guava revise source hypothesis detailed discussion knowledge target hypothesis eliminate borrow revision knowledge representation theory refer belief revision stage  potential negative transfer instance transfer learner transfer revise source hypothesis target hypothesis analogical hypothesis analogical hypothesis suitable revise source hypothesis target hypothesis target instance source target hypothesis consistent analogical hypothesis therefore  potential negative transfer hypothesis generally propose algorithm infers target domain via source domain algorithm proposes via compassion structure feature target source instance denote propose algorithm analogy strategy illustration guava via analogy strategy revision stage genus target data guava learner selects source instance related guava revise source hypothesis related guava transfer stage analogical hypothesis conclude source hypothesis related guava weak target hypothesis guava overall target domain analogical hypothesis hypothesis guava source domain applies source hypothesis related guava schema refer optimize hypothesis analogical hypothesis twofold previous HTL algorithm transfer knowledge source hypothesis target hypothesis optimize hypothesis acm transaction intelligent technology vol article publication date october transfer source hypothesis target hypothesis optimize hypothesis definition target hypothesis HTL revision stage useful knowledge contributes target hypothesis picked implies  transfer target hypothesis source hypothesis directly target task analogy hypothesis applicable source target domain target data therefore target hypothesis weak bias contribution threefold propose novel analogical TL framework introduce analogy strategy TL attempt  negative transfer instance hypothesis simultaneously knowledge algorithm introduce effective revision strategy source instance selection pace schema efficiently helpful instance source domain accord contribution target hypothesis propose framework easy apply various learner easy extend multi source hypothesis scenario related transfer TL aim improve task target domain instance transfer helpful prior knowledge source domain multi source TL focus building ensemble model multiple source domain machine task target domain knowledge transfer TL feature transfer FTL  PTL FTL algorithm feature representation source domain target domain feature representation desire minimize discrepancy domain enhance performance target task instance kernelized bayesian transfer  subspace source target domain kernel bayesian dimensionality reduction model  algorithm aim  reallocate sample source domain target domain data classical propose ref importance source instance similarity source target domain data probabilistic evaluate distribution similarity ref graph evaluate similarity local structure similarity generally mention algorithm rely estimation relatedness source target domain data however dependence similarity analysis brings obstacle algorithm considerably distribution source target domain frustrate similarity PTL knowledge transfer parameter hyperparameters distribution instance projective model TL adopts regularization standard svm analyze angle hyperplanes source target domain model hypothesis transfer HTL aim improve target hypothesis transfer source hypothesis estimation relatedness instance domain plenty explore reliable performance ref author multi HTL algorithm update target pre source hypothesis target data recent ref unsupervised HTL pseudo label generate source domain sample hypothesis conduct model transfer svm ref active selection strategy acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer hypothesis transfer HTL analogical transfer ATL instance transfer  typical procedure HTL source domain sample pre source hypothesis target hypothesis transfer knowledge target domain sample ATL source domain source instance contribute target hypothesis source hypothesis revise source instance finally analogical hypothesis transfer knowledge target instance source instance typical procedure  source instance  accord similarity target instance target model instance semantic constraint transfer hypothesis ref author discus parameter stability multi task feature structure ref effectiveness transfer target domain compatibility transfer model HTL algorithm analyze overall mention source model unchangeable joint TL algorithm algorithm ref author propose max margin domain transforms algorithm  feature instance transfer jointly TL algorithm combine TL algorithm kernel metric difference algorithm former  algorithm instance directly contributes target task analyze similarity domain discrepancy instance HTL algorithm conventional HTL considers source hypothesis unchangeable instead algorithm revise source hypothesis helpful instance therefore algorithm TL algorithm attack negative transfer instance hypothesis simultaneously define algorithm ATL illustrate difference  HTL ATL pace pace SPL paradigm adaptively subset instance accord easiness improve performance task pace discrete regularization various application continuous regularization ref discus batch implicit regularization diversity SPL ref however discrete acm transaction intelligent technology vol article publication date october important notation description notation description notation description instance parameter analogical hypothesis label pace parameter instance indicator vector instance target hypothesis parameter leverage parameter hypothesis regularization source hypothesis parameter pace regularization algorithm apply SPL schema revision stage helpful source instance standard SPL calculate loss analogical domain source domain evaluate easiness source instance moreover introduce specialized continuous regular analyze negative transfer shot shot shot shot aim instead dataset annotate sample annotate training data gradient optimization model metric model embed TL former TL shot zero shot ref proposes analogical domain transfer knowledge source domain target domain schema useful knowledge revise source domain target domain transfer hypothesis instance analogical domain enhance performance target domain insufficient label data directly transfer source domain target domain hypothesis bias statement revisit TL schema introduce analogical TL algorithm shot notation superscript denote transpose vector matrix vector matrix zero norm vector dataset feature instance label matrix correspond  specifically TL denote source domain data   target domain data   denote hypothesis source domain target domain respectively hypothesis mapping data label classifier focus convex hypothesis hypothesis target minimize convex combination empirical risk denote instance denote hypothesis transfer domain hypothesis important notation description hypothesis transfer revisit generally machine task empirical risk minimization erm ET min acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer denotes hypothesis domain data parameter normal machine task domain however data training performance guarantee  approach TL TL algorithm transfer knowledge source domain sufficient knowledge target domain improve performance target task particularly transfer knowledge hypothesis HTL simplicity source domain expend multisource scenario aim transfer hypothesis source domain target domain optimize erm erm becomes ET min HTL assumes pre focus pursue optimal transfer improve performance parameter transfer hypothesis previous propose thesis hypothesis linear function non linear task kernel function project data highdimensional propose algorithm former HTL treat source hypothesis source instance  however source instance contribute source hypothesis harm target hypothesis therefore desire eliminate harmful sample training source hypothesis analogical hypothesis transfer hypothesis revise subset helpful instance contribute target hypothesis analogical hypothesis applicable target hypothesis applicable revise source hypothesis erm algorithm EA min denote parameter discus stage algorithm ATL mention former algorithm revision stage source instance revise source hypothesis transfer stage analogical hypothesis revision initialize target hypothesis utilize target instance correspond parameter arg mint denote optimal parameter equation standard optimization learner hypothesis svm classifier parameter stage learner standard svm kernel svm svm discussion learner ref former source hypothesis treat unchangeable source instance algorithm propose revise source hypothesis instance acm transaction intelligent technology vol article publication date october contribute target hypothesis revise source hypothesis introduce pace SPL schema minv  leverage parameter instance leverage vector regularization rate purpose analogy aim analyze contribution source instance target hypothesis fix indicator vector target instance tune indicator correspond vector simplicity denote obtain minv  classical regularization previous binary instance previous regularization ref pace parameter gradually increase helpful harmful source accord contribution target hypothesis SPL easy complex analysis gradient respect zero equation optimal however usually non homogeneously distribute data easy complex dash becomes loss cannot pace scheme invalid specialize regularization continuous function regularization equation regularization define gradient respect zero equation obtain sensitive parameter algorithm sensitive loss solid becomes sensitive loss effective acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer parameter sensitivity pace regularizer loss increase solid becomes function becomes sensitive dramatically loss dash become sensitive loss increase faithfully reflect importance training moreover function distinct obtain source instance subset directly related contribution source instance target hypothesis revise source hypothesis arg min transfer stability transfer hypothesis introduce hypothesis transfer regularization equation min define hypothesis transfer regularization hypothesis dissimilarity pre hypothesis analogical hypothesis formulate transfer hypothesis combination inner hypothesis parameter equation parameter fix revision stage loss function regularization ref improvement generalization ability acm transaction intelligent technology vol article publication date october overall formulate optimization function ATL min leverage parameter norm convex hypothesis convex linear combination convex function assume propose equation solvable algorithm algorithm analogical transfer input source domain data target domain data initialize converge revision update subproblem via algorithm update transfer update subproblem accord equation output analogical hypothesis parameter algorithm optimization algorithm optimal input training data hypothesis parameter pace parameter threshold variable sort sample ascend loss accordingly denote label calculate accord equation output optimization discus optimization ATL stage algorithm revision revision source hypothesis mention previous optimize utilize target instance equation fix optimization equation simplify equation minv  regularization derivable meanwhile convex loss function therefore equation ref particularly sample correspond optimal indicator equation computation efficiency truncate zero selection parameter illustrate algorithm finally revise source hypothesis optimize parameter formulate equation transfer simplify equation equation calculate derivative XX  acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer optimal parameter matrix embed matrix training instance leverage parameter subproblem conventional HTL however transfer source hypothesis target hypothesis ATL transfer revise source hypothesis target hypothesis analogical hypothesis illustrate entire algorithm algorithm extension multi source ATL easy expand algorithm multi source domain transfer multiple source domain denote multi source version algorithm  source domain scenario formulate optimization multi ATL min parameter contains source hypothesis separately revision stage multi ATL algorithm former HTL algorithm parameter hypothesis  source hypothesis already revise achieve contribution target hypothesis EXPERIMENTS conduct extensive validate performance propose algorithm synthetic datasets synthetic dataset demonstrate ability propose algorithm handle negative transfer datasets traditional svm baseline transfer knowledge baseline algorithm propose algorithm TL algorithm algorithm transfer knowledge instance feature parameter joint TL algorithm attempt joint transfer multiple feature parameter investigate classical classification algorithm svm TSVM baseline baseline algorithm vector machine svm svm baseline implement svm libsvm package gaussian kernel source data training target domain transductive vector machine TSVM TSVM classical baseline TL instance TL algorithm hierarchical active TL   exploit cluster structure domain perform TL leverage source limited target domain data active feature TL algorithm kernelized bayesian TL   subspace source target domain kernel bayesian dimensionality reduction model parameter TL algorithm HTL HTL transfer knowledge source target domain optimize target hypothesis combination source domain inner model transfer regularization introduce minimize difference source target hypothesis projective model transfer PMT acm transaction intelligent technology vol article publication date october synthetic data standard svm classifier target domain sample magenta classifier fail classification task decision boundary solid source domain sufficient sample classifier classification task decision boundary dash transfer source sample target sample magenta algorithm classifier classification task target domain decision boundary solid however fail source sample decision boundary marked dash PMT analyzes angle hyperplanes source target domain hypothesis adopts regularization standard svm  multi source hypothesis TL non negative smooth loss function convex regularization multi model knowledge transfer multi KT multi KT algorithm svm  multi source TL handle training multiple model joint transfer algorithm   algorithm jointly optimizes feature transformation mapping target domain data classifier source domain datasets conduct evaluation synthetic data comparison data synthetic data ref synthetic source target data independently drawn distribution random sample instance source data distribution rotate counterclockwise direction target domain distribution due rotation source target domain exhibit distribution indeed rotation angle discrepancy domain label training instance sample marked magenta text data perform algorithm text datasets newsgroup newsgroup dataset contains approximately newsgroup document partition across subtopics newsgroups around document subtopics category sci crypt sci electronics belong category sci ref data subtopics category comp sci rec detail category acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer data description newsgroup task source target comp graphic comp sys ibm hardware comp misc comp sys mac hardware sci crypt comp sci electronics sci med sci rec auto rec sport baseball rec motorcycle rec sport hockey politics politics  politics misc religion misc rec auto rec motorcycle rec sport baseball rec sport hockey sci med sci crypt sci sci electronics sci electronics sci crypt sci med sci politics misc politics religion misc politics  comp graphic comp misc comp sys ibm hardware comp comp sys mac hardware rec auto rec motorcycle rec sport baseball rec sport hockey comp graphic comp misc comp sys mac hardware comp sys ibm hardware comp politics politics  politics misc religion misc reuters reuters corpus dataset contains news article reuters website involve category  category contains around document subtopics newsgroup source multi source binary classification task aim category specifically classification task source target data drawn subtopics category sample label training sample target domain data randomly without replacement detail omit ref subtopics setting text datasets perform source multi source source source binary classification task perform aim classify category multi source conduct multi source purpose explore performance multi source TL source target sample drawn subtopics category source multi source hypothesis multiple subtopics newsgroup comp graphic sci crypt treat positive negative sample source data comp misc sci electronics treat acm transaction intelligent technology vol article publication date october another source data sample label training sample target domain data randomly without replacement source multisource image data perform algorithm image dataset AwA attribute AwA dataset contains image subclass sample feature extract vgg neural network positive sample accord biological  whale  beaver etc    mouse average contains approximately image subclass remain image negative sample text data source data target data subclass setting perform inner image data inner inner source target sample text data task source target sample drawn subclass additionally image data task source target sample drawn source target sample inner hence challenge transfer algorithm avoid negative transfer alter positive target training data negative sample performance report average performance evaluation synthetic data performance classification algorithm synthetic data algorithm enhance performance target domain training sample target domain label target training data insufficient marked magenta classifier kernel svm learner fails classification task boundary solid meanwhile source domain label training data sufficient easy finally algorithm classification analogical hypothesis boundary marked solid marked magenta display negative transfer relieve revision source hypothesis sample source hypothesis target domain negative transfer decision boundary source hypothesis dash fails source data successfully classify source domain algorithm source sample contribute target hypothesis picked revise source hypothesis analogical hypothesis improve performance target hypothesis source hypothesis decision boundary analogical hypothesis solid successfully text data accuracy acc chosen evaluation measurement performance independently report average correspond standard deviation acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer performance comparison acc standard deviation source datasets newsgroup reuters task svm TSVM   PMT HTL ATL performance comparison acc standard deviation multi source multi subtopics datasets newsgroup reuters task svm  multi KT  multi ATL overall TL algorithm performance baseline svm transfer knowledge implies transfer knowledge source domain improve classification task target domain source algorithm ATL outperforms algorithm specifically algorithm ATL consistently around performance counterpart newsgroup reuters datasets implies algorithm generalization source TL scenario meanwhile algorithm consistently outperforms HTL algorithm source sample newsgroup reuters datasets implies algorithm negative transfer pace sample selection schema multi source algorithm ATL consistently outperforms others datasets specifically hypothesis transfer algorithm multi ATL  multi ATL report performance overall algorithm multi ATL outperforms algorithm around subtasks implies algorithm negative transfer generalization multi source TL scenario image data average precision  evaluation measurement performance independently report average correspond standard deviation overall performance improve target training data increase reasonable target domain information contributes training analogical hypothesis meanwhile inner surprising subclass feature feature hypothesis source perform inner source acm transaction intelligent technology vol article publication date october performance image data baseline algorithm svm affected target training sample overall algorithm perform inner algorithm target domain knowledge generally perform target training sample algorithm outperforms others target training sample parameter sensitivity rate text data algorithm ATL performs consistently baseline svm accuracy global optimal differs datasets algorithm ATL solid perform target training sample moreover consistently performs HTL algorithm around target training sample implies algorithm negative transfer pace sample selection schema improve hypothesis transfer algorithm ATL solid inner significantly outperform others implies algorithm generalization parameter sensitivity rate influence rate text datasets target training sample fix rate tune reuters correspond accuracy peak report newsgroup output performance acm transaction intelligent technology vol article publication date october shot text image classification via analogical transfer overall however optimal choice varied datasets overall algorithm consistently outperform baseline algorithm conclusion article shot text image classification propose novel analogical TL algorithm transfer knowledge source hypothesis target hypothesis ATL learns analogical hypothesis source target hypothesis ATL revise source hypothesis helpful source instance accord contribution target hypothesis propose algorithm efficiently occurrence negative transfer instance hypothesis extensive  synthetic datasets consistent reliable performance moreover ATL easily expand multi source scenario future investigate expand algorithm integrate nonlinear hypothesis another attractive direction theoretically analyze stability algorithm machine application flexibility algorithm investigate transfer challenge domain image video