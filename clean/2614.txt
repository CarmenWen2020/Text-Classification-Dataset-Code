article address multiple choice machine comprehension MC processing exist approach MC usually however specially develop novel multiple choice MC inspiration generative adversarial network gans propose adversarial framework multiple choice orient MC McGAN specifically approach gan unifies generative discriminative MC model generative model focus predict relevant passage text discriminative model focus predict relevancy passage competition via adversarial training minimize maximize propose advantage model evaluate performance McGAN model datasets multiple choice MC McGAN achieve significant increase accuracy exist model datasets consistently outperforms baseline technique CCS concept compute methodology processing information extraction additional generative adversarial network recurrent neural network machine comprehension gan rnn MC introduction objective machine comprehension MC automatically related text passage fundamental task research topic processing nlp MC widely agreement nlp community machine text comprehension essential application text mining text analysis quality MC easily accuracy automatically related text research purpose extensive data source MC publicly available researcher generally exist MC corpus category cloze style multiple choice related MC datasets researcher unified resource evaluate MC although MC task mention previously multiple choice MC task address wellknown multiple choice dataset achieve performance performance focus address multiple choice MC characteristic model multiple choice standard format consist passage candidate dataset appendix addition datasets textbook TQA sciq release multiple choice MC task detailed description datasets generally characteristic datasets  MC task MC datasets candidate multiple choice MC strictly text passage multiple choice MC article various domain philosophy biography news comprehensiveness passage related multiple choice format challenge MC task recent literature MC task attention recurrent neural architecture advantage although generally suffer important issue increasingly complex conceive MC task without simpler architecture baseline complicate  heuristic hence unnecessary develop complex architecture interaction layer another important observation training discriminative regression classification model address issue researcher generative adversarial network gans handle MC task attention recurrent neural architecture usually complex architecture aim model interaction layer gans simultaneously sub model compete sub model generative model artificial data sample discriminative model classifies data simulated obtain generator due advantage gans benefiting model extensive literature focus apply gan extension MC apply gan discrete sequence generation directly optimize discrete discriminator reward novel gan model dan domain dialogue generation generate quality response propose conditional gan model CGAN adopts document gate recurrent gru model discriminative adversarial training enhance semantic inference ability propose novel gan acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC model  derives novel variance objective discriminator output corresponds likelihood stably model discrete sequence however aforementioned regard gans mainly focus task text generation whereas multiple choice MC address gans cannot apply directly inspiration gan architecture propose adversarial framework multiple choice orient MC specifically McGAN gan unifies generative discriminative MC model generative model focus predict relevant passage text discriminative model focus predict relevancy passage gan generates continuous data input generator random McGAN framework focus multiple choice MC modify generator stochastic sample discrete candidate instead random moreover generator discriminator setting generator aim optimize objective generate relevant candidate passage discriminator model joint probability distribution passage determines correlate simultaneously model multiple choice MC unify adversarial training sum differs exist model contributes literature develop novel methodology McGAN characteristic multiple choice MC simultaneously model  MC methodology unify adversarial training model assumes connection information independent stochastic advantage machine capture hidden relationship passage generative model McGAN stochastic sample discrete candidate whereas gan deterministic generation sample signal directly unique gan model generative discriminative MC model MC task confrontation training methodology advantage supervise unsupervised model significant improvement handle multiple choice orient MC task inspire apply policy gradient reinforcement RL handle discrete data MC task traditional gans effectively continuous data serf successful extend gans discrete data nlp conduct extensive datasets multiple choice MC demonstrate superiority McGAN benchmark PRELIMINARIES attention neural network attention neural network already widely apply MC model model developed address MC focus span prediction relevant content span prediction model relevant content index index acm transaction intelligent technology vol article publication date march illustration architecture underlies exist attention neural network MC model passage content generate researcher developed model cloze style exist MC model framework contains component  layer  responsible embed sequence token sequence dimensional convert respective embeddings  char embed pre processing feature vector encoder layer encode passage candidate embed token encode composition function prominent encoder directional recurrent neural network  interaction layer focus interaction layer responsible interaction context explore attention directional attention multi perspective context grain gate multiple choice MC hierarchical attention model adequately leverage candidate option model interaction passage candidate option elimination layer objective elimination layer refine passage representation focus portion correspond irrelevant option propose model mimic approach model decision option eliminate layer decoder predict generate model prediction network complexity varies network structure fully layer convolutional neural network cnns recurrent highway network illustration difference model literature arise specific choice encoder decoder interaction function iteration mechanism generative adversarial net illustration standard gans gans model simultaneously adversarial manner generator recovers data distribution  random generates highly realistic data discriminator learns discriminate sample generative model discriminative model parameterized via neural network minimize maximize optimization acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC illustration standard gans min max  loд loд PROPOSED model  unified framework jointly apply discriminative model generative model adversarial network standard training strategy simultaneously model computes probability distribution reward focus predict relevant passage exploit unlabeled data generate predicts relevancy passage generate relevant affect meanwhile learns distinction generate formally objective  define min max   loд generative model discriminative model computes probability passage relevant logistic sigmoid activation function sigmoid encoder   passage  convert respective embeddings char embed pre processing feature vector char representation generate hidden directional gate recurrent BiGRU apply representation BiGRU      passage candidate respectively    char   acm transaction intelligent technology vol article publication date march passage representation embed alignment passage obtain equation gru att attention pool representation discriminative model discriminator aim maximize likelihood correctly distinguish generate relevant discriminate passage ill benefit mainly depends relevance goal distinguish relevant non relevant indeed binary classifier label passage tuples truly discriminative model optimize optimal parameter arg max  loд loд function fully differentiable typically stochastic gradient descent sgd generative model generative model aim minimize objective generate relevant candidate passage aim approximate relevance probability distribution  return relevant determines correlate classification involves feature extraction comparison similarity generally cannot correlation data model joint probability distribution label data unable extract feature effectively unlabeled data optimize optimal parameter generative model arg minθ  loд loд arg minθ loд arg minθ loд exp exp arg minθ loд exp arg max loд exp acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC sample discrete cannot directly mini batch sgd gan formulation therefore motivate approach RL apply policy gradient RL handle discrete data MC task policy gradient objective   loд exp  loд exp  loд exp   adopt sample approximation reduce variance policy gradient estimator sample generator accordance RL terminology loд exp reward signal policy action environment overall logic propose McGAN model summarize algorithm adversarial training discriminator generator alternatively via equation equation algorithm overall logic McGAN generator discriminator training dataset ensure initialize random gaussians standard deviation pre generator generates generator policy gradient equation discriminator generate competitive negative combine positive via equation McGAN converges data discus datasets evaluate McGAN model multiple choice MC datasets TQA sciq available http cmu edu  data TQA available http  org sciq available http  org data sciq acm transaction intelligent technology vol article publication date march distribution category dataset multiple choice MC dataset data observation english examination china multiple choice datasets introduce later challenge dataset sub sample difficulty respectively candidate option option contains passage dev appendix statistic report appendix variety datasets increase complexity title passage task understand capacity comprehend entire passage addition quantity meaning context passage POS passage refer addition standard lucy intend variety summarize dataset category distribution category TQA sciq datasets datasets article TQA sciq release TQA lesson multiple choice sciq dataset multiple choice examination sciq instance document formulate EXPERIMENTS validation McGAN exist multiple choice MC model along experimental detail conduct ablation validate effectiveness propose component experimental setting experimental setting propose McGAN passage candidate  stem pre library acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC accuracy comparison datasets model performance random slide GA reader 0D GA reader 0D stanford AR 0D stanford AR 0D HAF reader 0D HAF reader 0D  0D CSA model 0D 0D McGAN 0D McGAN 0D performs depict bold indicates obtain publish code GA reader stanford AR 0D pre glove embeddings stanford CoreNLP embed glove vocabulary OOV token initialize embeddings randomly gru initialize random gaussian distribution standard deviation zero gru hidden sgd optimizer rate RL training batch optimization dropout rate apply layer implement model tensorflow source code model publicly release overall performance report accuracy McGAN model baseline model model outperforms previous baseline subset yield overall accuracy report overall performance along benchmark approach model sub sample randomly dataset propose model obtains significant improvement accord publish accuracy rate McGAN achieves improvement accuracy comparison respectively robustness 0D 0D embeddings McGAN outperforms baseline model consistently embed moreover McGAN model 0D embeddings outperforms 0D neural baseline overall accuracy report McGAN independent regularization http  github CoreNLP coref html http nlp stanford edu project glove http tensorflow org software available tensorflow org http github com  McGAN acm transaction intelligent technology vol article publication date march accuracy multiple choice validation TQA dataset model accuracy  cnn McGAN accuracy model validation sciq dataset model accuracy  cnn McGAN performance 0D superiority 0D version McGAN due data characteristic carefully analyze  contains nlp task semantic cloze style MC embeddings dimension usually optimal dimension significant benefit increase dimension dimension propose McGAN framework TQA sciq datasets report accuracy benchmark datasets TQA dataset McGAN obtains accuracy rate improvement gru cnn model report McGAN along gru cnn sciq validation McGAN achieves accuracy improvement benchmark sum TQA sciq McGAN consistently behaves handle multiple choice MC task exist benchmark addition McGAN significantly improves accuracy recurrent neural network rnn baseline cnn approach categorical analysis categorical information analyze categorical performance model baseline code model release McGAN  GA reader neural model performance analysis category datasets summarize sample panel McGAN outperforms GA reader  category quantity meaning context passage style McGAN  similarly panel McGAN superior baseline category category fail quantity meaning context passage panel McGAN outperforms GA reader  category acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC performance McGAN baseline model  GA reader category model outperforms consistently category performs slightly baseline quantity meaning context passage explanation option usually interaction passage fully exploit model McGAN significantly improve training generator effectively generate competitive negative semantic distance negative target sample distance failure discriminator aim differentiate negative target sample ablation conduct ablation examine impact important parameter component model overall performance acm transaction intelligent technology vol article publication date march performance McGAN TQA panel panel training curve normalize cosine similarity generate truth performance ablation conduct hyper parameter tune coarse grain selection hyper parameter conduct optimal parameter grain selection parameter identify sensitivity model parameter model batch rate dimension embeddings dropout rate preliminary dimension embeddings parameter relatively impact performance 0D embed achieve handle whereas 0D embed performs furthermore quantitatively analyze performance improvement obtain McGAN demonstrate semantic similarity generate target truth training TQA panel panel TQA sciq datasets sciq version TQA semantic similarity coherence normalize cosine similarity metric cosine distance cosine similarity closer indicates similarity stage training McGAN model improve significantly generative model generate sample negative target semantic distance target discriminator random sample boundary discriminative model ineffective negative relatively target semantic hence easily fail determination training generative model generate target increasingly quality improve accordingly model comparison discussion TQA establish baseline random model  model  model  model  model variant rnn attention mechanism plot cnn model achieves improvement  model confirm superiority model benchmark exist model rnn  model cnn cnn rely heavily complex multi layer attention neural network lack flexibility specific acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC comparison accuracy TQA multiple choice ablation experimental TQA dataset model simultaneously considers model multiple choice MC benefiting advantage machine capture hidden relationship passage isolate detailed training model separately demonstrate training curve generative model discriminative model along baseline  cnn performance McGAN performance baseline whereas maintains unfavorable performance sparsity distribution data usually sparsity data failure positive feedback distribution unobserved effectively merge feature representation ablation conduct ablation feature representation text token feature representation tune pre library stanford CoreNLP exploit popular pre glove embeddings pre embeddings ine tune representation important MC token feature handcraft feature enhance embed representation additional feature component summarize entity recognition stanford CoreNLP toolkit tokenize entity recognition ner tagger POS tagger feature extremely helpful acm transaction intelligent technology vol article publication date march feature ablation analysis McGAN model dev model model 0D embeddings  ref ine tune     ref ine tune    model model 0D embeddings  ref ine tune     ref ine tune    accuracy exclude feature model important feature 0D 0D pre embeddings respectively comparison compute efficiency training GA reader McGAN speedup binary feature passage token exactly text feature feature fuzzy feature however stemmer fuzzy partial  criterion regard effective fuzzy effective partially report feature contribute performance McGAN model remove feature representation weaken performance model McGAN model achieve performance baseline feature complementary role feature representation related paraphrase context compute efficiency feasibility model address multiple choice MC computational efficiency report model along GA reader classic attention neural network model conduct hardware nvidia titan gpu adopt default setting code batch training report GA reader training whereas McGAN spends speedup McGAN training passage per passage per training model acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC implementation efficient model processing passage although computational efficiency focus McGAN exceptionally efficient handle multiple choice MC task related summarize related category MC datasets  reading comprehension model attention mechanism datasets recent progress MC largely due introduction datasets datasets enable MC researcher substantial advance accord restrict span reference passage classify exist datasets category  cnn daily mail cbt automatically generate cloze style datasets entity passage squad continuous span label guarantee quality instead TQA sciq multiple choice reading comprehension datasets TQA sciq instance consists option instance document formulate popular dataset another category reference passage closer orient reading comprehension addition multiple choice reading comprehension dataset additional candidate option focus primarily develop multiple choice orient MC model capability english examination specifically comprehension multiple choice reading comprehension multiple choice examination  multiple choice reading comprehension dataset quality difficulty restrict contains source additional candidate option efficiently neural network model previous  almost feature engineering model heavily rely lexical syntactic frame semantic feature extract various nlp achieve performance sparse data although burden format  complexity dataset candidate generate expert intentionally reading comprehension ability dataset relatively accurate indicator reflect text reading comprehension ability MC previous MC datasets substantially portion involve addition sufficiently suitable training powerful neural network unlike exist MC datasets candidate dataset generate text meantime task challenge due variety cnn daily mail datasets available http nyu edu    datasets available http  com  babi squad dataset available http  github squad explorer acm transaction intelligent technology vol article publication date march built baseline slide algorithm adapt stanford AR GA reader neural baseline GA reader model propose model cloze style MC author dataset adapt GA reader multiple choice machine reading comprehension replace output layer layer computes linear similarity candidate option representation passage representation hierarchical attention model adequately leverage candidate option model interaction passage candidate option prior approach approach unify generative discriminative MC model propose adversarial framework MC task attention mechanism MC attention mechanism MC model mainly directly model interaction predict representation passage representation instead representation  clark utilized interact passage align timestep passage attention passage compute via directional lstms lstms furthermore propose gate attention relevant passage representation via multi hop introduce gate attention passage span conclusion adapt gan address challenge multiple choice reading comprehension task McGAN extends exist gan model achieves performance comparison technique multiple choice MC datasets multiple choice MC confirm superiority model benchmark summary advantage McGAN twofold generative model signal obtain discriminative model performance unsupervised traditional maximum likelihood estimation discriminative model enhance relevancy passage effectively predict although distance achieve performance capability serf successful attempt machine multiple choice reading comprehension model guidance potential future improvement related appendix challenge widely multiple choice orient MC dataset dataset correspond difficulty respectively candidate option option multiple choice reading comprehension dataset datasets contains passage dev statistic dataset dataset report respectively acm transaction intelligent technology vol article publication date march unified gans multiple choice orient MC dataset passage scientist vegetable  tomato potato vegetable  cream cereal rice  something  twice scientist difference important  dinner afternoon eleven important something important candidate  dinner something randomly sample highlight data statistic datasets average passage average option training development statistic statistic training development datasets dev dev dev passage 