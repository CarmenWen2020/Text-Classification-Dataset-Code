classification knn algorithm data mining effective nonparametric technique recognition however due selective sensitiveness neighborhood majority vote conventional metric knn classification performance easily degrade training sample article improve classification performance overcome issue knn classification propose local representation classifier LMRKNN LMRKNN categorical query sample chosen calculate correspond categorical local vector query sample linear combination categorical local vector finally specific representation distance query sample categorical local vector adopt query sample extensive uci keel datasets popular database LMRKNN knn experimental demonstrate propose LMRKNN outperforms related competitive knn robustness effectiveness CCS concept AI technology machine data mining classification algorithm additional classification local vector representation recognition introduction knn classification benchmark knn introduce ref extensively widely apply machine recognition owe superiority implementation effectiveness easy intuitiveness knn algorithm data mining conventional knn query sample belongs frequency majority vote essentially nonparametric classification technique superiority knn attractive parameter neighborhood asymptotically optimal performance bayes sufficient priori knowledge classification data generally knn classification posse performance practical application recognition however issue related parameter majority vote conventional metric euclidean distance exist issue sensitivity influence performance training sample exist outlier reasonable important role knn classification neighborhood noisy imprecise easily classification prediction contrast neighborhood exist outlier heavily degrade classification performance furthermore choice uniform sample unsuitable classification sample knn classification performance suffer neighborhood choice suitable query sample overcome sensitivity adaptive neighborhood choice query sample propose ref knn classifier employ majority vote assumes classification decision obviously assumption reasonable specifically contribution classification reliable contribution classification decision accordingly voting knn developed ref knn classical distance classifier WKNN knn query sample sought conventional distance metric euclidean distance chosen unreliable cannot really reflect similarity discrimination query sample knn classification performance significantly metric adopt calculate distance training sample address issue distance metric representation compute similarity sample query sample due essential discrimination representation representation coefficient representation distance acm transaction intelligent technology vol article publication date april local representation classifier locally linear representation coefficient visual recognition coarse classifier CFKNN representation distance discriminative query sample phase image classification issue easily aggravate exist outlier training sample knn classification performance heavily degrade exist outlier neighborhood aim improve performance knn overcome negative exist outlier categorical classification developed ref classical categorical local  classifier LMKNN local vector per LMKNN extend kernel version ref local vector propose local centroid classifier local pseudo classifier LMPNN LMPNN LMKNN pseudo classifier pnn extend version LMPNN accordingly propose centroid neighborhood ref classification performance LMPNN practically verify ref propose pnn categorical pseudo distance chosen due advantage local vector knn classification utilized related classification improve knn classification performance propose local representation classifier LMRKNN article purpose overcome issue sensitivity exist outlier sample LMRKNN categorical local vector compute per achieve reflect local sample distribution reduce sensitivity uniform classify sample local subclass importance classification query sample linear combination categorical local vector expectation local vector importance instead majority vote representation distance calculate categorical local vector employ classification decision classification performance LMRKNN fully explore extensive datasets california irvine uci knowledge extraction evolutionary keel repository popular database comparison knn WKNN LMKNN CFKNN pnn LMPNN effectiveness robustness propose LMRKNN demonstrate comparative experimental LMRKNN categorical local vector instead adopt capture geometric discriminant information data reduce sensitivity query sample linear combination categorical local vector local vector representation importance classification stage specific representation distance calculate categorical local vector employ classification decision discrimination article extend conference publish international conference artificial intelligence  exception acm transaction intelligent technology vol article publication date april content conference mainly related detailed description analysis propose LMRKNN extensive computational complexity remainder article organize briefly review related knn classification proposes LMRKNN detail analysis rationale propose LMRKNN extensive discussion experimental observation LMRKNN computational complexity comparative finally conclusion drawn related METHODS knn simplest effective nonparametric technique outstanding extension introduce recently briefly variant LMKNN LMPNN CFKNN related due local vector LMKNN LMPNN representation distance CFKNN description uniformly introduce notation classification assume training sample within denote XM label label sample denotes training sample LMKNN LMKNN classical extension knn mainly local vector robust sensitivity sample training situation exist outlier query sample chosen euclidean distance metric local vector categorical calculate accordingly compute query sample finally classify minimum distance categorical local vector LMPNN LMPNN promising extension knn categorical  query sample pseudo local vector correspond query sample categorical euclidean distance metric  denote categorical local vector calculate acm transaction intelligent technology vol article publication date april local representation classifier compute distance local vector categorical pseudo finally query  classify closest pseudo minimum distance LMPNN LMKNN classifier generally training sample CFKNN CFKNN phase linear representation classifier representation distance classification decision phase query sample coarsely linear combination training sample  representation coefficient training sample representation coefficient xtx XT identity matrix representation contribution calculate  distance  training sample correspond chosen representative sample denote phase query sample finely equation optimal easily achieve ZT ZT representation distance similarity metric training sample correspond finally query sample classify frequent PROPOSED LMRKNN procedure propose LMRKNN integrates multi local vector representation distance purpose LMRKNN improve knn classification performance reduce negative issue knn sample exist outlier overcome exist outlier neighborhood local vector calculate classification LMKNN sensitivity exists assign fix uniform classify query sample unreasonable query sample local sample distribution chosen sample query sample reflect local sample distribution per knn classification chosen categorical sample acm transaction intelligent technology vol article publication date april query sample furthermore local sample distribution query sample uniform query sample degrades knn classification performance categorical  vector local sample distribution neighborhood lessen sensitive improve robustness knn classification performance therefore categorical local vector employ classifier propose LMRKNN LMRKNN categorical local vector involve classification decision essentially local vector correspond local subclass query sample reflect discrimination information moreover closer local vector importance classification instead majority vote classification decision categorical local vector LMRKNN adaptively query sample classification representation coefficient local vector contribution classify query sample CFKNN representation distance truly reflect similarity sample specific representation distance query sample categorical local vector similarity metric classification decision propose LMRKNN propose LMRKNN superior knn multi local vector representation distance overcome issue knn classification effectiveness robustness fully verify LMRKNN algorithm LMRKNN classification procedure described detail query  chosen euclidean distance metric equation reflect local sample distribution reduce sensitivity uniform categorical local vector compute chosen denote local vector adaptively contribution categorical local vector classify query sample categorical local vector linearly    skj skj skj sij representation coefficient associate local vector nonsingular matrix coefficient vector skj easily obtain however non matrix skj obtain acm transaction intelligent technology vol article publication date april local representation classifier TX singular matrix overcome singularity TX representation coefficient vector skj constrain norm regularization item skj min skj skj regularize parameter optimal skj adopt lagrange multiplier define function skj skj skj derivative skj respect skj calculate skj skj skj  identity matrix obtain optimal skj representation coefficient vector skj equation easily achieve optimal equation discriminative classification robust sample adopt LMRKNN optimal coefficient regard adaptive reflect importance classify categorical representation coefficient specific representation distance query sample dkj representation distance equation employ discriminative classification decision discrimination equation stem multi local vector contribution classification local vector representation per analyze benefit specific representation distance equation finally query sample classify minimum representation distance equation arg  dkj label mention pseudo code propose LMRKNN  summarize algorithm difference LMRKNN LMKNN LMPNN CFKNN clearly elaborate difference LMRKNN related LMKNN LMPNN CFKNN emphasize motivation LMRKNN LMRKNN LMKNN LMKNN chooses query sample calculate specific local vector determines label query sample distance query sample specific local vector LMKNN uniform acm transaction intelligent technology vol article publication date april algorithm LMRKNN algorithm query sample training training sample denotes training subset training sample ensure label query sample calculate distance query sample training sample seek correspond training sample distance denote calculate categorical local vector local vector obtain average denote query sample linear combination categorical local vector    skj skj skj skj TX calculate categorical representation distance query sample dkj query  classify closest categorical  distance arg  dkj brings sensitivity negative classification performance classification decision equation per identical classification however furthermore local vector per reflect local sample distribution unlike LMKNN LMRKNN computes categorical multi local vector query sample query sample linear combination training sample linear combination representation coefficient local vector query sample obtain acm transaction intelligent technology vol article publication date april local representation classifier adaptive classification representation coefficient label query sample representation distance query sample categorical multi local vector LMKNN LMRKNN employ categorical multi local vector fully reflect local sample distribution overcome sensitivity uniform meanwhile representation distance equation classification decision LMRKNN local vector contribution classification LMRKNN LMPNN LMRKNN LMPNN employ categorical multi local vector compute classification decision LMPNN distance categorical pseudo query sample indirectly compute classification decision classification decision LMPNN equation identical local vector distance categorical multi local vector contribution query sample classification classification decision LMPNN reflect discriminant information local sample distribution overcome issue LMPNN LMRKNN cla representation distance classification decision query sample linear combination specific multi local vector representation distance equation LMRKNN local vector classification LMRKNN CFKNN CFKNN phase representation query sample phase query sample linear combination training sample representative training sample representation distance equation chosen phase query sample linear combination chosen training sample majority vote chosen classification decision unlike CFKNN LMRKNN adopts classification decision LMRKNN query sample per euclidean distance categorical local vector compute correspond specific accordingly query sample linear combination categorical multi local vector representation query sample multi local vector categorical representation distance obtain classification LMRKNN analysis LMRKNN analyze propose LMRKNN perspective categorical representation distance multi local vector accordingly intuitive described LMRKNN employ linear representation query sample basis local vector representation distance classification decision achieve performance importance representation distance  vector favorable classification LMRKNN theoretically visually analyze acm transaction intelligent technology vol article publication date april analyze categorical representation distance classification decision LMRKNN comparison classification decision LMKNN LMRKNN categorical representation distance query sample equation distance query sample sum multi local vector per dkj  furthermore local vector local sample distribution specific neighborhood appropriate importance classification linear representation query sample categorical multi local vector adaptive importance classification query sample local vector representation coefficient derivative specific representation distance respect local vector classification contribution local vector calculate classification decision derivative dkj respect compute dkj   equation explain benefit classification decision propose LMRKNN aspect local vector contribution representation distance accord representation coefficient multi local vector fully classification importance classification equation categorical representation distance favorable classification contrast LMRKNN LMKNN distance query sample local vector classification decision equation derivative equation classification acm transaction intelligent technology vol article publication date april local representation classifier classification query sample truly classification classification decision obviously LMKNN identical classification decision suitable classification verify meaningfulness representation distance LMRKNN classification task analyze classification decision LMKNN LMRKNN classification dataset originally attribute within contains sample randomly chosen musk dataset visualization acm transaction intelligent technology vol article publication date april classification query sample truly classification classification decision dimensionality sample reduce fisher criterion suppose training sample  fisher criterion define average variance feature respectively fisher criterion attribute dataset descend feature chosen visualization representative query sample intuitive classification LMKNN LMRKNN preset equation classification chosen query sample schematically displayed query sample denote sample pink ellipsis  local vector LMKNN  representation vector local vector LMRKNN query sample classify extent accord local sample acm transaction intelligent technology vol article publication date april local representation classifier distribution neighborhood however distance  query sample LMKNN mistakenly classifies propose LMRKNN correctly classifies accord sample neighborhood query sample easily classify due outlier query sample classification performance LMKNN influence outlier distance query sample local vector classification decision contribution classification furthermore clearly representation vector local vector compute geometrical discriminant information combine combine categorical multi local vector LMRKNN reflect local sample distribution neighborhood local vector importance linear representation query multi local vector conclude specific representation distance discrimination effective classification secondly mainly analyze superior categorical local vector classification decision instead categorical cosine correlation coefficient argue multi local vector local sample distribution neighborhood overcome sensitivity obtain promising classification cosine correlation coefficient ref cosine correlation coefficient calculate sim cosine correlation coefficient calculate sim sim sim sim tends significantly direction equation compute cosine correlation coefficient local vector investigate classification cosine correlation coefficient local vector compute sim sim sim cosine correlation coefficient  compute sim sim sim accord equation local vector query sample cosine correlation  transaction intelligent technology vol article publication date april cosine correlation coefficient LMRKNN LMKNN wine KN KM local vector respectively classification error LMRKNN LMKNN wine LMKNN LMRKNN LMRKNN LMKNN respectively  similarly cosine correlation coefficient equation cosine correlation coefficient reflect cosine correlation coefficient enhance query sample correctly classify equation cosine correlation coefficient local vector achieve wine dataset displayed description wine local vector cosine correlation coefficient correspond query sample cosine correlation coefficient local vector significantly correspond implies classification LMRKNN local vector LMKNN verify furthermore cosine correlation coefficient accordingly classification performance reflect classification classification demonstrate minimum average classification illustrate cosine correlation coefficient  vector slowly increase tend stable increase accordingly classification error LMRKNN quickly acm transaction intelligent technology vol article publication date april local representation classifier classification error LMKNN LMRKNN wine minimum error average error LMKNN LMRKNN degrade classification error obtain indicates propose LMRKNN classification classification performance cosine correlation coefficient local vector confidently reveals multi local vector suitable local sample distribution discriminant similarity query sample favorable classification conclude local vector compute propose LMRKNN helpful classification analysis superior classification performance propose LMRKNN stem multi local vector representation distance become LMRKNN EXPERIMENTS verify classification performance propose LMRKNN extensive datasets LMRKNN  classifier knn WKNN LMKNN CFKNN pnn LMPNN datasets summarize information datasets briefly described datasets numerical datasets image datasets numerical datasets uci machine repository keel repository sample sample attribute dataset numerical datasets libra cardio image opt landsat pen abbreviate  banknote  image segmentation   pendigits respectively numerical datasets multi classification task numerical dataset randomly training sample classification average classification error sample chosen numerical datasets mostly demonstrate classification performance propose training sample image datasets popular database  research ltd ORL georgia tech GT illumination expression pie ORL cam research    html contains image sample image sample facial expression facial detail image sample pixel GT  com research  htm contains frontal tilt facial image variation illumination facial expression appearance sample jpeg image image pixel pie cmu edu afs project pie  multi pie html acm transaction intelligent technology vol article publication date april numerical datasets data sample attribute sample wine balance CNAE libra sonar musk vehicle  yeast iris  cardio  texture image opt musk landsat pen image sample dataset contains image sample image sample capture illumination expression subset pie sample adopt datasets image align cropped cropped image sample resize per pixel image sample ORL GT pie respectively numerical datasets classification performance propose LMRKNN highlight numerical datasets classification error knn WKNN LMKNN CFKNN pnn LMPNN conduct trial holdout validation acm transaction intelligent technology vol article publication date april local representation classifier classification error via numerical dataset classification performance evaluation average classification error confidence sensitivity neighborhood classification compete parameter neighborhood preset classification error numerical dataset displayed difference classification error CFKNN significant dataset classification error CFKNN illustrate classification CFKNN CFKNN suitable image classification numerical datasets experimental propose LMRKNN performs clearly reveals LMRKNN sensitive classification moreover improvement classification performance LMRKNN significant relatively experimental implies propose LMRKNN classification addition curve classification error LMRKNN smoother flatter datasets experimental via propose LMRKNN sensitiveness significant improvement classification performance compete knn classifier acm transaction intelligent technology vol article publication date april classification error via numerical dataset highlight effectiveness propose LMRKNN classification compete explore minimum classification error correspond standard deviation std optimal parenthesis numerical datasets classification performance knn dataset bold obviously LMRKNN nearly outperforms datasets importantly experimental propose LMRKNN significantly performs situation training sample wine musk CNAE libra LMRKNN achieves classification knn WKNN LMKNN pnn embody experimental imply propose LMRKNN obtain classification performance fully robustness performs training sample LMPNN classification LMRKNN LMRKNN LMPNN multi local vector besides average minimum classification error LMRKNN datasets significantly reveals classification performance LMRKNN robust stable experimental obtain trial holdout validation confidence however comparison knn statistically  validate propose LMRKNN outperforms compete non parametric statistical friedman perform friedman rank compete dataset classification error specifically acm transaction intelligent technology vol article publication date april local representation classifier minimum classification error numerical datasets data knn WKNN LMKNN CFKNN pnn LMPNN LMRKNN wine musk balance CNAE libra sonar cardio vehicle  yeast iris  spambase texture image opt musk landsat pen average acm transaction intelligent technology vol article publication date april average rank compete friedman numerical datasets knn WKNN LMKNN CFKNN pnn LMPNN LMRKNN average rank performance gain rank rank classification performance average rank assign rank ith jth datasets average rank ith datasets null hypothesis friedman compete nearly achieve classification performance rank identical friedman statistic define friedman statistic distribute freedom classification error friedman investigate classification performance propose LMRKNN classifier average rank accord classification average rank compute equation null hypothesis rank achieve compete perform similarly freedom average rank rank difference average rank propose LMRKNN significant moreover compete significantly consequently non parametric statistical demonstrates compete knn classifier propose LMRKNN performs significantly image datasets classification performance propose LMRKNN highdimensional datasets pie ORL GT classification error knn WKNN LMKNN CFKNN pnn LMPNN knn classification performance easily degrade curse dimensionality dimensionality image sample employ trial holdout validation conduct image dataset average classification error trial confidence obtain classification image dataset randomly training sample sample dataset sample chosen training sample others classification performance compete knn explore neighborhood classification error image dataset varied classification via propose LMRKNN almost performs compete improvement LMRKNN significant robustness LMRKNN sensitivity obviously verify moreover classification error LMRKNN quickly descend acm transaction intelligent technology vol article publication date april local representation classifier classification error via pie ORL GT image datasets minimum classification error correspond standard deviation std optimal parenthesis image datasets data knn WKNN LMKNN CFKNN pnn LMPNN LMRKNN pie ORL GT tend stable becomes however unlike LMRKNN classification error nearly ascend increase addition propose LMRKNN performs LMRKNN classification classification performance image datasets displayed classification dataset compete denote bold experimental clearly propose LMRKNN significantly outperforms performance LMRKNN obtain hence acm transaction intelligent technology vol article publication date april propose effective robust knn WKNN LMKNN CFKNN pnn LMPNN classification DISCUSSIONS briefly observation analysis computational complexity competitive experimental observation comparative numerical datasets image datasets briefly achieve observation LMRKNN reduce sensitivity neighborhood promising classification performance multi local vector generally achieve classification performance categorical  vector perform training sample curse dimensionality effective robust classification performance adopt cla representation distance classification decision experimental observation LMRKNN coincide categorical multi local vector representation distance described analyze therefore propose LMRKNN promising effectiveness robustness knn classification recognition computational complexity embody effectiveness propose LMRKNN analyze comparative efficiency LMRKNN knn WKNN LMKNN CFKNN pnn LMPNN computational complexity computational complexity compete notation commonly training sample dimensionality sample ref computational classify query sample knn WKNN calculate euclidean distance query sample training sample accordingly computational complexity knn WKNN  ando respectively LMKNN query sample classify categorical local vector compute correspond categorical chosen specific training sample computational complexity LMKNN  pnn query sample classify categorical pseudo categorical assign distance query sample computational complexity pnn LMPNN query sample classify categorical pseudo basis categorical local vector calculate categorical computational complexity LMPNN  CFKNN query sample classify mainly phase representation query sample phase query sample linear combination training sample representative training sample chosen query sample phase finally chosen representative sample computational complexity CFKNN acm transaction intelligent technology vol article publication date april local representation classifier runtime musk libra cardio CNAE parenthesis training sample sample attribute respectively data knn WKNN LMKNN CFKNN pnn LMPNN LMRKNN musk libra cardio CNAE propose LMRKNN categorical correspond local vector obtain query sample linear combination local vector per finally query sample classify categorical representation distance hence computational complexity LMRKNN  combine computational complexity comparative musk libra cardio CNAE datasets runtime training sample sample attribute datasets operating intel core TM cpu 0GHz 0GHz 2GB memory runtime comparative classify sample datasets displayed runtime accordance correspond computational complexity CONCLUSIONS article proposes local representation classifier LMRKNN purpose LMRKNN improve knn classification performance overcome issue exist knn LMRKNN categorical multi local vector compute truly reflect local sample distribution reduce sensitivity neighborhood training sample capture geometrical discriminant information classification enhance importance local vector classification decision query sample linear combination categorical multi local vector representation coefficient local vector contribution query sample representation distance categorical representation distance elaborate distance metric similarity query sample categorical multi local vector classification decision representation distance overcome negative majority vote conventional similarity metric knn acm transaction intelligent technology vol article publication date april propose LMRKNN favorable classification analyze detail extensive numerical datasets image datasets conduct LMRKNN knn experimental classification propose LMRKNN significantly outperforms compete effective robust classifier recognition