temporal TPP expressive model temporal sequence however discover temporal sequence cluster rarely TPP model reinforcement whereby sequence assume generate mixture latent policy purpose cluster sequence temporal underlie policy policy model flexibility model component network policy network model temporal handle sequence resort inverse reinforcement decompose sequence rnn hidden embed action interval reward function achieve performance increase efficiency exist reward entire sequence likelihood wasserstein distance adopt expectation maximization algorithm estimate cluster label sequence aim respective policy extensive synthetic datasets efficacy introduction sequence stamp continuous domain ubiquitous across application commerce online purchase sequence health informatics series treatment patient tracked sequence  sequence earthquake social medium twitter user transmits tweet corresponds user behavior sequence various domain recognize understand structure sequence vital importance downstream application literature propose model sequence health informatics introduces model  evolution  development temporal sequence  temporal relationship sequential medication predict medication likely prescribed patient patient intensive icu department predict via mutually  sequence earthquake social medium network learns social  user recurrent stamp individual involve social network model interaction infers influence actor hawkes dependency dyadic optimize multi stage campaign social network model sequence temporal TPP useful whereby concept model occurrence rate conditional intensity function literature propose data mining task prediction task multi dimensional hawkes model sequential user action social network  matrix useful uncover mutual influence user mixture hawkes model infer attribute behavioral observation dependency dyadic temporal widely prediction pipe failure prediction effective replacement rehabilitation pipe failure sequence formulate stochastic mutually propose patient prediction hospital predict destination CU transition duration CU occupancy critical resource allocate devote another important relatively scenario sequence cluster continuous domain challenge traditional aggregate discrete series cluster sequence cluster utility application sequence important discover underlie cluster structure robustly purchase cluster commerce user benefit recommender cluster patient accord treatment hospital optimize medication resource moreover model generative model specific sequence generation useful raw data sensitive instance aim population simulate behavior deployed model without access raw data useful develop simulated stock exchange multiple AI player however despite extensive exist sequence model prediction mention sequence cluster mixture model sequence rarely address knowledge parametric likelihood latent dirichlet allocation model propose sequence cluster hawkes propose reinforcement RL EM algorithm sequence cluster likelihood temporal purpose discover underlie policy expert sequence rationale RL sequence action expert whereby timely reflect fitting deviation contrast traditional likelihood model observation entire sequence moreover inverse reinforcement irl difficulty define distance TPP sequence unfixed decompose sequence action irl reward function algorithm achieves efficiency computes entire sequence inspire model cluster gaussian mixture model GMM gan mixture model  propose novel policy mixture model PMM sequence cluster difference exist component GMM gaussian distribution  generative adversarial network propose PMM model component policy network EM concept policy network reinforcement DRL neural network approximate policy function recent prosperity various domain reinforcement DRL combine reinforcement principle creates efficient algorithm apply robotics video finance healthcare recurrent neural network rnn policy network approximate policy function utilization rnn policy network model temporal sequence generation mostly related dirichlet mixture model hawkes DMMHP sequence cluster respective TPP model parameter cluster however technical approach completely parametric model tailor hawkes network model bayesian probabilistic framework likelihood incorporates adversarial inverse reinforcement effective objective beyond MLE significantly outperforms data reinforcement perspective model cluster temporal dynamic sequence exist RL intervention TPP effort involve model RL paid TPP cluster additional careful treatment disentangle mixture policy RL suppose sequence generate underlie expert policy reflect cluster formulate sequence cluster task reinforcement whereby purpose discover unknown generation policy meanwhile function fitting sequence automatically data inverse reinforcement propose EM algorithm TPP cluster RL dataset suppose generate mixture latent policy lbrace rbrace fix lbrace rbrace update classifier sequence lbrace rbrace generate cluster label fix classifier update lbrace rbrace subset classify propose EM algorithm TPP cluster RL dataset suppose generate mixture latent policy fix update classifier sequence generate cluster label fix classifier update subset classify summary contribution RL TPP cluster introduce policy mixture model model cluster exist mixture model GMM  DMMHP component gaussian distribution generative adversarial network conventional hawkes component model policy network handle sequence parameter reinforcement cluster corresponds latent expert policy generates sequence cluster EM algorithm PMM model algorithm image cluster gan mixture model adapt sequence cluster RL discover underlie temporal previous parametric cluster model EM algorithm cluster entire dataset model fitting cluster jointly perform component policy network TPP model temporal RL implement generative adversarial imitation  efficient irl embodiment instead conventional MLE loss adversarial loss irl procedure meta approach adopt irl policy reward function empirically exceeds peer model notably comparison exist hawkes mixture model DMMHP conduct hawkes non hawkes synthetic data recover underlie temporal generate sequence recent mixture gan image cluster model adapt temporal sequence wasserstein distance accord comparison model outperforms significantly regard training efficiency faster performance related model cluster cluster sequence model temporal model reinforcement domain knowledge related temporal model cluster addition another topic cluster sequential data aim cluster entity cluster independent cluster series sequence difference sequence cluster previous literature cluster sequential data explain objective temporal review TPP literature aspect model intensity function objective algorithm relevance intensity function objective relate latent policy discover temporal intensity model traditional TPP model mostly developed around intensity function instantaneous occurrence rate reinforce poisson hawkes reactive etc obvious limitation traditional model assume sample obey parametric  data suggests cluster behavior beyond model moreover tailor algorithm specific model contrast neural recurrent neural network variant memory lstm model conditional intensity function generally fulfil gradient descent restriction intensity function impose recently attention mechanism introduce improve interpretability neural model however model sequence fed model without discrimination differently belong mechanism generate sequence model cluster sample accurate model temporal alternative objective TPP parametric model neural model traditional mostly maximum likelihood estimation MLE procedure probabilistic framework MLE objective choice limited sequence arbitrary recent effort devise adversarial objective inspire generative adversarial network gan wasserstein gan adversarial objective developed addition MLE loss approximate continuous domain prediction discrete series wasserstein distance temporal sequence explicitly define generative model temporal generation developed prediction model via conditional gan another challenge dimensional TPP model whereby  matrix dimensionality popular technique impose rank regularizer factorization model  matrix however explicitly sequence cluster dimension marker correspond underlie cluster model cluster model cluster technique widely promising application involve complex data cluster segmentation data fundamental data analysis widely across multiple discipline model cluster approach model specify priori gaussian hidden markov model HMMs model structure hidden hmm model selection technique parameter estimate maximum likelihood algorithm EM algorithm probabilistic model cluster technique promising corpus application gaussian mixture model popular model vector data multinomial model effective dimensional text cluster derive bijection bregman divergence exponential distribution cluster mixture component member vast efficient manner exist model cluster largely concentrate specific model application notable exception propose EM framework  cluster mixture probabilistic model essentially EM cluster emphasis cluster non vector data variable sequence majority model cluster maximum likelihood formulation focus normal distribution cluster mixture constrain gaussian model described efficient hierarchical algorithm gaussian model cluster sequential data aim cluster sequence continuous domain easy confuse another topic cluster identify cluster sequential data semantics driven cluster algorithm propose detect sequential twitter data semantic information temporal geographic community feature achieve task systematic framework correlate predict cluster dynamic behavior trace mainly predefined criterion cluster trace associate cluster  execution instance outcome recently spatio temporal detection cluster algorithm developed identify index sensor data wearable device identify cluster interval consecutive cluster regular gym literature cluster temporal information specific feature cluster sequence temporal information occurrence sequence specific feature defines rarely previous literature reinforcement propose model approach expectation maximization EM algorithm disentangle cluster fitting cluster sequence assume generate latent expert policy expectation sequence assign cluster label correspond latent policy generates sequence latent policy cluster maximization model illustrate algorithm algorithm irl   TPP described algorithm algorithm reinforcement policy mixture model RLPMM TPP dataset policy training classifier rate randomly initialize classifier policy parameter discriminator parameter randomly  TPP converge sample training probability classifier compute policy label  TPP ensure latent police EM policy mixture model temporal sequence discrete  cluster label suppose generate mixture expert latent policy expert parameterized likelihood logp sourcewhere conditional probability parameter maximize marginal likelihood   sourcewhere marginal probability suppose  sample arbitrary valid probability distribution bound marginal likelihood obtain jensen inequality logp logp logp  dkl SourceRight click MathML additional feature dkl KL divergence bound dkl SourceRight click MathML additional feature equation relation hidden variable distribution likelihood function data dkl randomly initialize parameter arbitrary distribution EM procedure iteratively update parameter model parameter update posterior update maximize suggests iteration converges maximum iteratively perform distribution hidden variable specifically computational component implement neural network reinforcement policy mixture model RLPMM policy cluster policy algorithm generative adversarial imitation TPP  TPP discriminator parameter policy net sample sequence πθi irl update discriminator parameter gradient compute RL update policy parameter gradient compute ensure parameter policy network discriminator expectation policy cluster mention hidden variable distribution posterior distribution latent variable sample data accord recompute expectation likelihood function compute hidden variable distribution   sourcewhere restrict distribution hidden variable bound hypothesis mixture policy parameter data posterior distribution yij yij sourcewhere yij generate ith policy inspire classifier discrete hidden variable distribution policy parameter fix classifier data generate policy therefore involves algorithm practical application layer classifier sequence embed layer rnn layer classification layer addition implementation trick imbalanced classification procedure employ training classifier sample generate policy classifier easy assign cluster imbalanced instance particularly procedure imbalance reinforce EM procedure policy model data remain eventually RLPMM model converge imbalanced fix issue EM procedure policy model explore data augment training data assignment cluster DN augment cluster data amount instance complement  posterior probability belonging ith cluster accord output classifier amount augment data reduce along procedure convergence maximization policy hidden variable estimate classifier sequence training dataset classify specific policy discrete hidden variable dataset cluster DN policy model irl policy previous impose specific sequence wasserstein distance assume policy reward unknown via irl rationale nontrivial define temporal sequence fitting error contrast vector data scalable data irl procedure efficiently fulfil generative adversarial imitation scheme policy network sequence generation policy function capacity capture complex sequential dependency stochastic adopt rnn stochastic neuron policy network action refers timestamp refers hidden embed rnn action sample distribution sourcewhere   ith inter hidden rnn encode nonlinear mapping policy parameter coefficient nonlinear activation function  alternative parameterizing policy function probability density function satisfy constraint random variable sample positive exponential distribution rayleigh distribution rnn policy network stochastic neuron mimic generate mechanism stochastic temporal sequence generate inter sample stochastic policy action function optimal policy compute directly  GE SourceRight click MathML additional feature stationary stochastic policy action action expectation sequence generates temporal sequence fitting function define beforehand attractive irl inverse reinforcement compute optimal function compute RL iteration specifically adopt maximum causal entropy irl policy optimal function inverse reinforcement procedure irl    sourcewhere  causal entropy regularizer policy entropy policy robustly optimal policy update reinforcement procedure RL  SourceRight click MathML additional feature optimal policy obtain iteratively execute irl RL express RL irl source tedious iteration irl inner loop RL conquer generative adversarial imitation framework reinforcement instead compute function discriminator network parameter discriminate expert policy action policy action explain mechanism  detailed derivation  framework function reinforcement irl procedure substitute training discriminator gradient discriminator parameter  wlog exe wlog SourceRight click MathML additional feature sequence sample policy sequence sample expert policy actually discriminator local function signal policy iteration policy policy gradient decrease respect function logd policy expert action iteration generative adversarial imitation TPP employ policy subset policy reward function irl discriminator generate fake sequence sequence RL policy network policy gradient sequence lbrace rbrace generate policy network classifier generative adversarial imitation TPP employ policy subset policy reward function irl discriminator generate fake sequence sequence RL policy network policy gradient sequence generate policy network classifier function  RL procedure implement policy gradient descent gradient policy network parameter   SourceRight click MathML additional feature  gradient causal entropy regularizer      SourceRight click MathML additional feature    essence iteratively update irl update RL  algorithm saddle expression   SourceRight click MathML additional feature equivalent optimal policy exist specially cluster sequence assume generate parametric hawkes cluster sequence model limited hawkes cluster sequence generate non hawkes unfair previous sufficient efficiency propose model comparison exist parametric sequence cluster hawkes synthetic datasets dataset generate hawkes generate non hawkes respectively dataset memetracker discover temporal meme diffusion comparison WGANMM adapt TPP data comparison WGANMM adapt TPP data standard deviation SD bracket metric cluster CP RI policy fitting eid synthetic data generate non hawkes hawkes intensity standard deviation SD bracket metric cluster CP RI policy fitting eid synthetic data generate non hawkes hawkes intensity cluster consistency memetracker average trial cluster consistency definition cluster consistency memetracker average trial cluster consistency definition truth intensity estimate synthetic data generate policy truth intensity estimate synthetic data generate policy estimate intensity function memetracker intensity data intensity cluster subsection baseline adaption temporal evaluation metric experimental evaluate performance reinforcement policy mixture model synthetic data demonstrate effectiveness efficiency model sequence cluster summarize peer gaussian mixture model pipeline model extract feature sequential vector auto regression var ordinary differential equation ode LS GMM cluster sequence dirichlet mixture model hawkes related knowledge wasserstein generative adversarial network mixture model WGANMM adapt convenience reproducibility technical detail baseline gaussian mixture model tackle sequential data cluster traditional usually implement aggregate series cluster discrete lag variable probabilistic mixture model perform sequence cluster procedure extract feature sequential data identify cluster via GMM extract feature sequential gaussian mixture model GMM vector auto regression var model discretizes sequence series learns transition matrix feature cluster ordinary differential equation nonparametric hawkes model ordinary differential equation another nonparametric hawkes model contrast function relate ode LS hawkes sequence protocol parameter feature sequence employ GMM cluster dirichlet mixture model hawkes mixture policy TPP rarely literature related knowledge DMMHP generates sequence cluster hawkes parameter dirichlet distribution cluster prior model DMMHP model accomplish temporal cluster difference DMMHP conventional parameterized hawkes cluster latent dirichlet allocation lda propose novel generative adversarial imitation model wasserstein generative adversarial network mixture model gaussian mixture model gan mixture model image cluster fix matrix data gan model capture cluster distribution respectively adapt processing domain image sequence continuous domain TPP modify vanilla WGANMM replace cnn rnn introduce  distance propose adversarial subsection adapt WGANMM TPP notation  slightly abuse notation assume notation subsection suppose ith cluster training data generate oracle TPP generate TPP wasserstein distance distribution  SourceRight click MathML additional feature denotes joint distribution marginals minimize computationally intractable hence dual compute  sourcewhere lipschitz function parameter assign sequence satisfy lipschitz constraint suppose sequence generate parameter noisy input therefore objective generative model minimize  SourceRight click MathML additional feature discriminator generator fulfil rnns generator transforms input sequence generate sequence rnn lstm        sourcewhere embed vector   activation function parameter      similarly discriminator assigns scalar sequence data generate rnn        parameter discriminator      adapt WGANMM propose RLPMM EM cluster algorithm difference WGANMM WGANMM learns TPP wasserstein distance sequence optimum cluster task RLPMM meta adopts irl adversarial imitation technique function RL policy cluster RLPMM WGANMM involves RL moreover instead rnn multiple discriminator generator WGANMM cluster RL latent policy cluster lstm latent policy another lstm correspond function irl empirical faster WGANMM evaluation metric metric cluster performance cluster purity CP rand index RI empirical intensity deviation eid cluster consistency CC metric cluster consistency CC already involves random trial compute average trial dataset random initialization cluster detailed definition metric cluster purity purity average portion positive cluster purity  SourceRight click MathML additional feature index belonging cluster index sequence belonging sequence purity purity indicates concentration cluster rand index treat label cluster truth RI cluster accuracy similarity sequence cluster label RI sequence cluster label cluster label empirical intensity deviation latent policy cluster protocol compute deviation empirical intensity function accumulate absolute error windowed sequence sequence generate policy empirical intensity expectation compute sufficient generate sequence counting average apply synthetic dataset truth cluster label cluster consistency purity RI eid cluster performance cluster label synthetic sequence sequence without label cluster performance cluster consistency via validation worth mention intrinsic cluster evaluation davy  index dunn index practical evaluate cluster performance sequence cluster cluster evaluation impractical define compute distance sequence sample actually define distance stochastic sequence easy directly distance cluster instead EM cluster algorithm component policy network propose RLPMM algorithm generative network baseline WGANMM unfortunately actually impractical compute define distance stochastic sequence cluster consistency evaluation truth dataset compute cluster consistency cluster trail trial sequence randomly training fold fold model training fold apply model correspond fold enumerate sequence within cluster jth trial preserve trial cluster consistency minimum proportion preserve trial compute consistency minj sourcewhere   sequence within cluster trial  cluster index sequence synthetic data synthetic datasets cluster generate synthetic sequence interval simulation TPP average trail ratio cluster comparison hawkes model synthetic datasets generate non hawkes hawkes specifically non hawkes dataset sequence generate mixture cluster sine intensity negative sine intensity sequence generate constant intensity cluster  intensity formula intensity plot curve truth intensity intensity non hawkes datasets sequence generate intensity function formula function sine sin negative sine sin constant bimodal exp exp plot intensity truth estimate empirical intensity RLPMM model baseline model hawkes adopt conventional hawkes trial parameter intensity function cluster sample randomly trial parameter intensity function cluster sample randomly memetracker data plenty datasets available nowadays various series datasets employ stochastic stamp abundant sequence adequate temporal relatively rare dedicate discover occurrence temporal stochastic sequence instead model synchronous series data raw data suitable worth mention explain difference stochastic stamp sequence earthquake  information diffusion continually transmit series data electricity usage inside  dataset ambient average wearable dataset dataset sequence public memetracker widely TPP meme diffusion public medium news article blog meme  website randomly sample cascade memetracker diffusion meme creation meme suppose generate latent policy discovery cluster consistency metric truth cluster label comparison WGANMM particularly efficiency model WGANMM synthetic non hawkes data memetracker data  RLPMM neural network mixture model adversarial loss difference WGANMM mixture gan model dynamic rnn multiple lstm wasserstein distance sequence RLPMM model sequence series action RL lstm latent policy adversarial loss reward function gain adversarial imitation technique iteration training convergence per iteration iteration training convergence per iteration WGANMM achieve comparable cluster model performance RLPMM model efficient iteration runtime empirical verification convergence procedure plot convergence evaluation metric cluster purity rand index synthetic dataset empirical convergence RLPMM WGANMM synthetic data generate policy compute cluster purity rand index iteration RLPMM iteration WGANMM empirical convergence RLPMM WGANMM synthetic data generate policy compute cluster purity rand index iteration RLPMM iteration WGANMM worth mention curve training validation loss convergence generative adversarial imitation irl approach generative adversarial adversarial algorithm generator discriminator propose RLPMM model discriminator network policy network compete  algorithm iteratively implement irl function RL policy policy function become discriminative accordingly loss function convergent baseline WGANMM convergence algorithm cluster metric finding discussion interpretation parametric versus neural versus discretized series neural network TPP model RLPMM reinforcement imitation WGANMM generative adversarial outperform implicit parametric intensity model ode GMM LS GMM DMMHP explicit intensity function cluster performance model capability performance series var GMM superiority neural model parametric TPP assume predefined limited model capacity data exactly generate predefined hawkes model DMMHP hawkes model benefit significantly slightly outperforms network RLPMM WGANMM suggests parametric model distribution exactly model specification standard deviation stability neural TPP parametric neural TPP specially hawkes cluster model propose achieves comparable regard specially pipeline versus joint model synthetic datasets joint model DMMHP WGANMM RLPMM outperform model var ode LS GMM cluster within cluster utility elegant joint algorithm WGANMM versus RLPMM WGANMM RLPMM perform relatively RLPMM outperforms WGANMM regard cluster performance metric synthetic data dataset however propose RLPMM superior efficiency WGANMM WGANMM adopts adversarial training framework wasserstein divergence generator discriminator model dynamic rnn multiple lstm contrast RLPMM model policy lstm discriminator extra logistic regression layer RLPMM parameter computation moreover memetracker notably iteration converge synthetic data potential practical task influence cluster convergence WGANMM RLPMM increase WGANMM training iteration converge RLPMM  reinforcement model parameter easy gan model average response average response training convergence propose algorithm baseline overall parametric var ode LS GMM DMMHP converge neural network WGANMM RLPMM parameter performance relatively neural network propose RLPMM model efficient WGANMM performance conduct centos intel cpu 4G ram geforce gtx gpus temporal synthetic data generate policy cluster purity RI eid degenerate policy generate data intensity function grows protocol becomes challenge sequence becomes mixed impact lessen joint model DMMHP WGANMM RLPMM model var ode LS GMM comparison RLPMM WGANMM whereby RLPMM additional iteration converge WGANMM cluster increase discover temporal memetracker data memetracker data cluster performance decrease cluster increase unified model robust increase model particularly plot intensity function cluster sequence discover temporal meme diffusion instead informative TPP model sequence plot empirical intensity function discover propose RLPMM meme marked text statistic reveals potential joint model topic model discover meme diffusion marked statistic average meme frequency interpretation partially meme generate quickly disappear around meme mostly  peace usually diffusion intensity decay subsequent meme mostly topic economy health opportunity etc diffusion intensity gradually decay around meme mostly statement opinion diffusion suspends around diffuse diffusion average frequent suggests diffusion statement opinion contains average response training convergence propose algorithm RLPMM algorithm DMMHP WGANMM pipeline baseline average response training convergence propose algorithm RLPMM algorithm DMMHP WGANMM pipeline baseline average frequent meme diffusion cascade discover cluster memetracker average frequent meme diffusion cascade discover cluster memetracker particularly frequent average explore characteristic meme diffusion potential comprehensive model comb RLPMM topic model meme content conclusion cluster sequence discover temporal continuous domain challenge vast application useful building driven simulator reinforcement perspective policy mixture model approach involves neural network EM algorithm adversarial imitation inverse reinforcement reward policy resort hoc sequence synthetic dataset efficacy model future domain encourage temporal discovery sequence expert domain knowledge related discover temporal occurrence earthquake  discover knowledge geology related expert domain knowledge geology associate temporal geology literature extension effective handle multi typed sequence generative adversarial imitation technique directly applicable multi dimensional TPP RL multi TPP involve irl technique joint TPP topic model text data associate useful memetracker explore model cluster effective policy