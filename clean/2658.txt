recently application exploit multi data diverse domain obtain various feature extractor reflect distribution data novel unsupervised multi framework propose cluster data propose multi cluster adaptive sparse membership allocation MVASM attention construct membership matrix sparseness learns centroid matrix correspond concretely MVASM attempt flexible sparse membership matrix cluster explores underlie consensus information multiple solves multiple centroid matrix utilize specific information modifies mention membership matrix addition theoretical analysis determination exponent parameter convergence analysis complexity analysis propose improves performance cluster public datasets demonstrates  superiority introduction machine technique widely apply application engineering astronomy biology remote economics fundamental technique machine data cluster cluster graph cluster partition instance cluster instance cluster similarity dissimilar belong cluster data cluster extensive research decade data cluster review graph cluster approach summarize drawback graph cluster approach mostly optimize objective data graph associate similarity matrix instance local compute affinity cluster multi data irregular background clutter exploit structure eigenvectors automatically infer investigate consistency spectral cluster algorithm cluster data eigenvectors graph laplacian matrix graph paradigm proposes graph genetic algorithm cluster flexible various kernel spectral cluster technique integrates cannot link link constraint adjacency matrix graph addition propose approximate eigenvectors laplacian matrix randomize subspace iteration alleviate data uncover cluster structure propose novel convex model structure doubly stochastic matrix impose rank constraint graph laplacian matrix conduct series procedure construct similarity affinity matrix data rarely modify datasets outlier unreliable similarity matrix reduce performance besides cluster structure explicit processing cluster uncover cluster indicator achieve reliable similarity affinity matrix assignment recent propose algorithm impose constrain laplacian rank specifically impose rank constraint laplacian matrix data similarity matrix learns data similarity matrix assign adaptive optimal data component similarity matrix cluster developed graph cluster objective upon norm norm constrain laplacian rank propose unsupervised feature selection constrain laplacian rank propose unsupervised feature extraction simultaneously learns transformation matrix structure graph cluster information although modify introduce laplacian rank constraint improve performance construct optimal similarity graph apply multi data apart building reliable similarity affinity matrix assignment important factor choice similarity function similarity graph greatly affect cluster performance multi promising potential machine application visual recognition public sentiment activity traffic prediction social micro video popularity prediction multi scenario complex construct similarity graph improve usually perform eigen decomposition laplacian matrix cluster indicator matrix minf itr  cluster indicator matrix LS correspond laplacian matrix apply multi data perform multiple eigen decomposition similarity graph computational complexity besides fuse similarity graph another similarity graph multiple similarity graph strategy ignore complementary diverse information certainly loses advantage multi data simply concatenate dimensional vector directly apply cluster fitting reduce interpretability information explore novel cluster multi data recent variety spectral cluster propose multi data bipartite graph local manifold fusion integrate heterogeneous feature author unified graph model pairwise constrains perform multi cluster multi information propose pairwise sparse spectral cluster sparse regularization dimensional embed exploit novel fuse information multiple graph source link matrix factorization regularization training rank although multi spectral cluster algorithm achieve encourage performance spectral cluster cluster multi data investigate similarity matrix integrate assignment cluster novel unsupervised multi framework MVASM propose previous MVASM utilizes membership matrix adaptive sparseness cluster explores underlie consensus information multiple meanwhile MVASM alternately learns centroid matrix revise membership matrix specific information maintains relative independence highlight propose transform similarity matrix assignment cluster membership matrix relax binary membership probability sum balance parameter MVASM sparseness membership vector obtain accurate another highlight develop multi cluster model adaptive sparse membership matrix unifies cluster indicator information across membership matrix maintains specific information centroid matrix alternately robust sparse fuzzy RSFKM cluster propose recent worth propose MVASM significantly improves RSFKM RSFKM model considers robustness data residual norm capped norm sparse membership matrix data contrast propose MVASM develops multi model focus multiple explores underlie consensus information optimize cluster membership matrix across MVASM introduces multiple centroid matrix discover complementary information across mention demonstrate comparison contribution MVASM summarize aspect MVASM novel introduces membership matrix sparseness cluster maintains consistency underlie cluster across MVASM bridge easy newton return optimal MVASM alternately learns centroid matrix modify membership matrix specific information maintain relative independence adjusts proportion capture complementary information merge multi information theoretical analysis determination exponent parameter convergence analysis complexity analysis extensive evaluation public datasets experimental comparison multi cluster effectiveness superiority propose MVASM organize introduces related formulates framework MVASM alternate iterative optimization theoretical analysis MVASM exponent parameter demonstrates optimal obtain iteration experimental comparison theoretical empirical analysis datasets conclusion related cluster adaptive ideal assignment component data data matrix data define probability sij data probability sij usually distance corresponds probability sij similarity matrix compose probability sij assignment obtain ideal assignment constrain probability sij sample laplacian matrix LS rank LS similarity matrix cluster structure therefore cluster model becomes min rank LS sij  SourceRight click MathML additional feature LS DS matrix DS diagonal matrix diagonal sij sji however data multi data calculate similarity graph complex construct similarity graph computational complexity similarity graph multiple similarity graph strategy ignore complementary diverse information certainly loses advantage multi data robust sparse fuzzy cluster RSFKM recently author propose directly membership matrix instead similarity matrix uncovers cluster indicator explicitly reduces computational complexity significantly objective function minu  SourceRight click MathML additional feature membership matrix measurement flexibly define various norm similarity sample cluster centroid vector nevertheless data simply concatenate dimensional vector cluster directly apply fitting reduce interpretability information multi cluster adaptive sparse membership allocation formulation inspire RSFKM relax binary membership probability sum multi cluster model adaptive sparse membership matrix propose  defines objective function minu   SourceRight click MathML additional feature  data matrix dimension sample pth data denote   centroid matrix centroid vector  membership matrix exponent regularization coefficient traditional multi cluster rigorously establish membership matrix binary contains sum indicates sample per cluster multi cluster MVASM relaxes probability sum cluster MVASM considers sparsity membership matrix importance parameter parameter membership vector data binary zero equivalent cluster multi scenario membership vector data longer sparse sparseness membership matrix progressively tune membership matrix non sparse actually parameter sparseness membership matrix addition multiple attribute information MVASM intra information information intra information derive relationship tune distribution information across membership matrix obtain performance cluster optimization decompose subproblems via alternate optimization iteration update fix calculate cluster membership matrix via perfect equality inequality constraint across rewrite minu      minu uik  SourceRight click MathML additional feature independent data vector minui  SourceRight click MathML additional feature hic  define   SourceRight click MathML additional feature introduce efficient subsection refer update fix update cluster centroid matrix unconstrained optimization omit regularization irrelevant minv     sourcewe objective function    SourceRight click MathML additional feature due minimum derivative respect zero    obtain  uik SourceRight click MathML additional feature update fix update optimization constraint ignore regularization irrelevant         SourceRight click MathML additional feature uik lagrangian function  sourcewhere lagrangian multiplier derivative zero   SourceNote kkt source combine obvious   SourceRight click MathML additional feature addition equality constraint achieve  SourceTherefore integrate obtain equation source sum algorithm obtain membership matrix via indicates cluster across update via obtains multiple cluster centroid matrix update via realizes  across objective function converge algorithm algorithm input data  cluster parameter output membership matrix cluster centroid matrix  initialization initialize cluster initialize converge data calculate vector  update cluster centroid vector update accord return optimization algorithm introduce lagrangian multiplier correspond lagrangian function   sourcein kkt equation   SourceRight click MathML additional feature accord  SourceRight click MathML additional feature substitute SourceRight click MathML additional feature  uik SourceRight click MathML additional feature uik   combine equality obtain uik uik uik sourcewhere max obvious optimal obtain furthermore combine   definition  SourceRight click MathML additional feature define function SourceRight click MathML additional feature calculate piecewise linear convex function newton utilized source theoretical analysis exponent parameter tune distribution accord characteristic function refer extreme obtain suppose substitute obtain    SourceRight click MathML additional feature MVASM assigns assigns strategy assure MVASM trivial function curve frac function curve convergence analysis theorem iteration objective function decrease algorithm converges proof suppose tth iteration obtain iteration fix respectively accord equation  SourceRight click MathML additional feature objective function constraint convex domain converge global optimal fix respectively refer iteration similarly obtain fix obvious subproblems convex optimization proof verify convergence algorithm complexity analysis update iteration compute newton  calculate digit precision update iteration matrix multiplication  update accord  therefore denote outer iteration algorithm computation complexity  linear data sample performance MVASM evaluate public benchmark accord widely cluster evaluation metric acc nmi jaccard purity perform normalize datasets datasets previous adopt public datasets coil coil mnist yale evaluate MVASM datasets described coil dataset contains normalize image corresponds image per image heterogeneous feature isometric projection iso linear discriminant analysis lda neighborhood preserve embed NPE coil dataset contains normalize image corresponds image per image heterogeneous feature iso lda NPE mnist dataset handwritten digit normalize fix image digit described heterogeneous feature iso lda NPE yale dataset consists image image per corresponds facial expression configuration image express heterogeneous feature iso lda NPE heterogeneous feature descriptor iso lda NPE iso visually dimensional dimension lda linear combination feature NPE preserve local neighborhood structure data manifold besides intuitively image datasets image coil coil mnist yale datasets image coil coil mnist yale datasets evaluation metric accord previous evaluation metric cluster performance acc nmi jaccard purity metric indicates cluster performance report metric obtain comprehensive evaluation comparison MVASM multi  coil coil datasets comparison MVASM multi cluster coil dataset comparison MVASM multi  mnist dataset comparison MVASM multi  mnist dataset comparison MVASM  multi cluster yale dataset comparison MVASM  multi cluster yale dataset acc acc define acc SourceRight click MathML additional feature cluster truth label mapping function permutes nmi nmi define nmi logp max SourceRight click MathML additional feature denote cluster obtain truth MVASM respectively probability sample belongs cluster respectively joint probability sample belongs cluster entropy respectively jaccard purity jaccard similarity finite sample define jaccard tptp FP FN sourcewhere TP positive FP false positive FN false negative purity percent sample classify correctly define purity  sourcewhere denotes sample kth cluster truth cluster cluster experimental setup performance MVASM  cluster adaptive sparse membership RSFKM demonstrates MVASM embodies advantage multi MVASM cluster algorithm hierarchical cluster denote HC DBSCAN verifies superiority MVASM     advantage membership matrix adaptive sparseness across addition emphasize importance  across MVASM  concatenates performs cluster adaptive sparse membership worth sake fairness initialize membership matrix cluster indicator matrix  parameter comparison  RSFKM regularization parameter accord tune parameter RSFKM optimal parameter correspond accuracy mention parameter coil coil mnist yale datasets respectively similarly parameter  respectively comparison multi   exponent parameter logq obtain parameter refer logq datasets  logq  propose MVASM parameter algorithm parameter adjusts sparseness membership matrix parameter distribution important role MVASM acc nmi variation parameter concretely tune accord coil coil mnist yale datasets parameter variation MVASM coil coil mnist yale datasets respectively parameter variation MVASM coil coil mnist yale datasets respectively parameter variation MVASM coil coil mnist yale datasets respectively parameter variation MVASM coil coil mnist yale datasets respectively coil coil mnist yale datasets membership matrix across multiple coil coil mnist yale datasets membership matrix across multiple coil coil mnist yale datasets experimental report observation coil dataset multi     MVASM  RSFKM concretely  propose MVASM achieves percent average improvement improvement average cluster metric respectively similarly  comparison multi achieve conclusion experimental furthermore RSFKM propose MVASM gain significant average improvement instance coil dataset propose MVASM achieves percent average improvement respectively multi obtain average improvement RSFKM besides comparison HC HC DBSCAN DBSCAN propose MVASM obvious MVASM improve cluster performance demonstrates superiority effectiveness multi information multi valuable information therefore MVASM performs significantly multi coil dataset propose MVASM performs     specifically obvious MVASM achieves percent average improvement     respectively cluster indicator matrix binary comparison easily incorrect partition ambiguous contrary cluster membership matrix adaptive sparseness introduces fuzzy concept tackle     MVASM mainly concatenate overfitting confuses various attribute information reduce interpretability multi information ignore  across sometimes  cannot cope multi data degrades performance  mnist dataset finally visually membership matrix across multiple propose MVASM datasets convergence curve MVASM datasets propose MVASM converges iteration convergence curve coil coil mnist yale datasets convergence curve coil coil mnist yale datasets conclusion propose novel unsupervised cluster introduces membership matrix adaptive sparseness across tackle ambiguous interaction information multiple multiple centroid matrix adaptively deeply explores underlie consensus complementary information efficient utilize specific information modify membership matrix furthermore optimization algorithm convergence behavior extensive evaluation widely datasets demonstrate MVASM effective cluster multi data