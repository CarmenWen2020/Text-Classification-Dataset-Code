apply DL healthcare driven availability data multiple feature channel data environment intensive however practical situation access data feature channel data environment predictive model performance boost performance model data environment leverage knowledge extract exist model data related environment address develop knowledge infusion framework cheer succinctly summarize model transferable representation incorporate model improve performance infuse model analyze theoretically evaluate empirically datasets empirical cheer outperform baseline percent macro multiple physiological datasets introduction data environment observation capability data representation encompass multiple channel feature multiple electrocardiogram ECG signal hospital diagnose disease intensive icu feature channel availability data environment spark apply DL predictive health analytics DL model built data multi channel feature demonstrate promising healthcare however practical scenario data private accessible due privacy concern develop DL model quality data comprise feature channel data environment limited observation capability monitoring device channel feature inevitably performance DL model fuel abundance richness data becomes impressive data environment alleviate issue hypothesize consolidated DL model environment encode information transfer related environment disease detection model data ECG channel hospital likely pertinent information improve model data ECG channel wearable device due correlation data motivate intuition postulate access prior model data performance DL model built related data improve extract transferable information model infuse model related transfer knowledge distillation setup address elaborate propose knowledge infusion framework cheer address aforementioned challenge cheer aim effectively transfer domain invariant knowledge consolidated model quality data demand model data demand model complexity suitable deployment data setting demonstrate empirically cheer bridge performance gap DL model apply data setting specifically contribution develop transferable representation summarizes model  summarize knowledge effectively model representation apply exist DL model perform theoretical analysis demonstrate efficiency knowledge infusion mechanism cheer theoretical practical configuration mild assumption model prediction model probability finally conduct extensive empirical demonstrate efficiency cheer healthcare datasets cheer outperform approach knowledge distillation baseline without knowledge infusion percent respectively macro demonstrate robust performance related transfer exist transfer transfer knowledge across domain assume target source model equivalent model data representation capacity domain adaptation focus mainly domain invariant representation specific domain image data furthermore achieve training model jointly source target domain data recently another transfer developed transfer attention mechanism complex shallow neural network boost performance source target model however jointly dataset source target datasets available target model adopt representation significantly model capacity compatible data domain weak observation capability knowledge distillation knowledge distillation mimic aim transfer predictive capacity expensive DL model simpler model shallow neural network deployment usually achieve via training model label capacity model however assume model domain access data datasets quality access quality data feature representation additional limited data representation quality icu data quality health monitoring information personal device domain adaptation exists another non transfer paradigm refer domain adaption however assume access domain specific model specific knowledge domain adapt applicable model arbitrary architecture address impose specific assumption data domain model recognize demonstrate model arbitrary architecture research formulation straightforwardly extend non model omit detail manuscript focus model healthcare context due expressive representation model multi channel data cheer data definition datasets xri  xpi  denote datasets respectively subscript index ith data ith patient healthcare application contains input feature vector xri xpi output target   datasets input feature xri xpi dimensional vector respectively output target   categorical variable input feature datasets xri xpi non overlap assume channel data data modality remain data channel data modality interchangeably data physiological data icu vital continuous pressure  temporal sequence electronic health discrete medical code data personal wearable device target mortality status patient onset disease etc raw data necessarily feature vector arbitrary feature series image text data detailed implementation series data input feature implicitly assume raw data comprises multiple sensory channel embed feature signal feature per channel embed feature vector per data respectively channel encode multiple latent feature applicable however assume embed feature per channel remain standard healthcare scenario detailed dataset leverage datasets amount data relationship denote xri xpi dataset contains input feature xri xpi hence target concretely concatenate input  xri xpi dataset feature feature channel highly accurate observation capability remain feature channel significantly noisy observation analysis apply setting xpi xri  xri data xri accessible data accessible xpi avoid confusion however proceed implicit assumption feature overlap datasets remain dataset comprise data icu xpi data wearable sensor xri extract patient dataset contains data patient datasets cannot alone prediction model quality definition dataset patient cohort dataset limited sample patient model pre private data patient cohort interested model perform vanilla model generate challenge ability transfer knowledge improve prediction quality however highly non trivial task generates meaningful prediction input data channel training data private cannot access enable knowledge distillation domain adaptation data limited cannot alone accurate prediction model sketch combine source information coherently generate useful prediction model patient cohort therefore challenge task investigate address challenge align model transferable representation described representation infuse knowledge model model improve performance overall structure cheer notation summarize notation cheer notation cheer cheer model built multi modal multi channel data behavior model infuse model data behavior infusion model model prediction data dataset target infusion cheer model built multi modal multi channel data behavior model infuse model data behavior infusion model model prediction data dataset target infusion transferable model knowledge infusion task model assume advance dataset xri  dataset however accessible access model knowledge infusion task aim consolidate knowledge acquire model infuse simpler model model transferable representation characterize DL model building discus interact generate prediction denote building namely feature extraction feature feature aggregation respectively intuitively feature extraction transforms raw input feature vector feature importance feature function feature combine via linear transformation focus model attention important feature translate vector predictive probability via feature aggregation function implement non linear transformation mathematically workflow succinctly characterize conditional probability distribution SourceRight click MathML additional feature building detail feature extraction complex input data series image text derive effective feature instead directly raw input extract feature denote   dimensional feature vector extract ith feature extractor raw input feature extractor apply series input define later avoid clutter notation shorten feature extract feature various importance combine via specific formally extract feature model combine via specific vector essentially component raw input feature important ith extract feature dimension parameterized parameter dataset feature aggregation feature aggregation implement nonlinear transformation layer combine feature predictive input component linearly combine feature output vector logistic input SourceRight click MathML additional feature subsequently softmax function compute predictive probability candidate label xri exp  SourceRight click MathML additional feature dnn implementation model describes instantiation aforementioned abstract building popular dnn architecture attention mechanism model multivariate series illustrates dnn implementation raw feature raw data data environment consist multivariate series physiological signal hospital temporal sequence electronic health EHR discrete medical code raw feature input xri continuous monitoring data pressure illustration purpose feature extraction handle continuous series extract domain specific feature cnn rnn model specifically split raw series xri non overlap xri sri sri  denotes feature data apply stack convolutional neural network  pool hri  sri SourceRight click MathML additional feature hri  denotes filter cnn component model recurrent neural network  across output previous cnn pool layer    hri SourceRight click MathML additional feature output rnn layer concatenate generate feature matrix   sourcewhich correspond domain specific feature extractor xri xri  xri  xri  define previously transferable representation feature concatenate feature fed attention component attr generate vector importance output component attr detail construct component corresponds feature function xri xri xri xri feature aggregation extract feature combine feature function yield combine feature subsequently linear layer densely hidden denser denser SourceRight click MathML additional feature denotes label denotes parametric dense layer output dense layer transform probability distribution label via softmax activation function parameterized softmax xri exp  sourcethe entire corresponds feature aggregation function parameterized knowledge infusion model infuse knowledge extract model model adopt transferable representation model SourceRight click MathML additional feature model domain specific feature extractor feature function feature aggregation function format model infuse knowledge model model boil component decompose behavior infusion mention function define vector collection vector defines model behavior feature mechanism input component xpt  dataset model output  construct auxiliary dataset xpt  correspond behavior model mechanism model mapping data important assign ith latent feature model formally cast optimization task   xpt  SourceRight click MathML additional feature parameterize xpt  reduces linear regression task analytically alternatively reduces maximum posterior inference task normal prior impose analytically solvable incorporate sophisticated non linear parameterization xpt neural network structure optimize approximately via numerical via standard gradient descent complexity derive depends iteration compute gradient depends parameterization usually maxi compute gradient objective function respect iteration optimal  lastly complexity  target infusion model behavior model via optimize model feature aggregation feature extraction component prediction model data truth  data formally achieve optimization task    xpt  xpt SourceRight click MathML additional feature understand model model context dataset xpt  adjust model behavior target local context data xpt  allows filter  distil irrelevant data context parameterize aforementioned component linear layer densely hidden activate softmax function via standard gradient descent compute gradient linearly neuron parameterization model gradient computation complexity iteration mpc iteration  mpc behavior infusion target infusion succinctly summarize algorithm algorithm cheer input model data data infuse model behavior via  via infuse model target via  via output model theoretical analysis theoretical analysis cheer goal practical assumption respect random instance drawn arbitrary data distribution prediction  model model  probability demonstrate accuracy knowledge infusion algorithm achieve strategy bound target fitting loss definition random instance model respect optimize function feature extraction feature aggregation component via lemma characterize sufficient target fitting loss definition respect instance model model prediction respectively lemma probability sufficient happens bound bound target fitting loss lemma theorem characterizes likely model model prediction random data instance proceed assumption definition  denote arbitrary parameterization model target fitting loss model respect data instance lˆx  xpt SourceRight click MathML additional feature denotes denotes probability assign candidate model respectively  define definition target fitting loss model respect parameterization define lˆx sourcewhere expectation unknown data distribution   robustness constant model define min maxy SourceRight click MathML additional feature probability model perturbed additively within prediction outcome assumption data xpi xri assume distribute independently identically assumption label prediction   model unique lemma θˆp denote optimal parameterization model yield minimum target fitting loss definition optimal minimize objective function respectively denote predictive task θˆp SourceRight click MathML additional feature proof definition lˆx define empirical target fitting loss Lˆ  sourcewhere lˆx treat identically independently distribute random variable definition Lˆ hoeffding inequality Lˆ exp sourcethen arbitrary exp yield probability Lˆ simultaneously happens probability θˆp Lˆ θˆp Lˆ  Lˆ θˆp completes proof lemma inequality definition θˆp  implies Lˆ θˆp Lˆ implies target fitting loss θˆp incur knowledge infusion algorithm arbitrarily confidence optimal target fitting loss sufficiently dataset lemma θˆp define lemma correspond target fitting loss definition lˆx θˆp model prediction respectively   proof define statement lemma source understand inequality definition inequality lˆx θˆp implies hence inequality definition definition finally inequality definition lˆx θˆp implies implies hence label prediction unique assumption hence definition model  prediction completes proof lemma intuitively lemma specifies sufficient model yield label prediction data instance model likely sufficient likely model imitate model successfully random data instance intuition theoretical analysis formalize theorem denote random instance drawn denote dataset behavior model model denotes model prediction probability SourceRight click MathML additional feature proof lˆx θˆp implies lˆx θˆp SourceRight click MathML additional feature markov inequality lˆx θˆp lˆx θˆp θˆp  probability yield lˆx θˆp θˆp SourceRight click MathML additional feature equality lˆx θˆp θˆp immediately definition assumption plug yield θˆp SourceRight click MathML additional feature apply lemma probability θˆp plug yield SourceRight click MathML additional feature union bound probability model yield prediction model completes proof theorem immediately implies probability model yield prediction model arbitrary instance knowledge infusion succeed therefore experimental setting datasets datasets evaluation data statistic summarize mimic critical database mimic icu patient  israel  medical  june october subset patient frequent disease diagnosis acute   chronic  disease failure  hemorrhage specify procedure complication lung disease  disease  task disease diagnosis classification predict disease patient feature data channel vital series rate HR respiratory rate RR pressure bpm pressure systolic bps pressure diastolic  saturation SpO randomly data training percent validation percent percent PTB diagnostic ECG database PTBDB channel ECG series conventional frank healthy disease amount task classify ECG category   healthy failure bundle   sample data pre frame frame slide duration adjacent   EEG artifact corpus EEG channel sensor series  span task classify EEG movement  chew chew   electrode pop electrode static artifact  muscle artifact  randomly data training percent validation percent percent statistic datasets architecture model dataset summarize baseline cheer baseline summarize neural network model parameterized cheer directly dataset without knowledge infusion model model bound predictive performance dataset knowledge distil KD KD transfer predictive teacher model via label teacher model KD model complexity infuse model generate cheer label  parameter max activation function KD attention transfer enhances shallow neural network leverage attention mechanism attention behavior fledge neural network dnn dnn attention component parameterized cheer attention component dnn transfer shallow neural network data environment via activation attention transfer normalization heterogeneous domain adaptation HDA maximize discrepancy mmd loss successfully domain adaptation however drawback homogeneous setting source target domain feature architecture neural network mitigate limitation HDA propose modification mmd loss handle heterogeneity source domain target domain performance metric prediction performance correspond precision recall PR auc receiver operating characteristic curve roc auc accuracy multi classification evaluate prediction quality accuracy ratio correctly classify instance instance harmonic average precision proportion positive predict positive recall proportion positive correctly identify threshold predictive probability positive threshold actually assign positive label average evaluate label macro summarize average predictive performance across roc auc PR auc compute predict probability truth directly roc auc curve positive rate tpr false positive rate fpr various threshold setting likewise PR auc curve precision recall various threshold setting report average PR auc roc auc task multi classification training detail report performance empirical standard deviation average independent randomly split entire dataset training percent validation percent percent model built training validation evaluate adam optimizer model default rate training epoch model criterion invoked performance improve epoch model implement kera tensorflow backend equip GB ram intel core ghz CPUs nvidia geforce gtx comparison model architecture hyper parameter KD HDA cheer dataset entire amount dataset entire data feature dataset dataset feature analyze knowledge infusion data setting default maximum amount data percent entire dataset default data feature dataset entire data feature knowledge infusion performance data setting default setting model cheer baseline performance comparison mimic PTBDB EEG datasets report respectively dataset percent data feature data environment mimic PTBDB EEG respectively datasets infuse model generate cheer consistently achieves predictive performance demonstrates advantage knowledge infusion framework exist transfer KD data statistic data statistic architecture model mimic parameter architecture model mimic parameter architecture infuse model cheer KD knowledge infusion mimic parameter architecture model PTBDB parameter architecture infuse model cheer KD knowledge infusion PTBDB parameter architecture infuse model cheer KD knowledge infusion PTBDB parameter architecture model EEG parameter architecture model EEG parameter architecture infuse model cheer KD knowledge infusion EEG parameter performance comparison mimic dataset performance comparison mimic dataset performance comparison PTBDB dataset performance comparison PTBDB dataset performance comparison EEG dataset notably macro cheer improves KD HDA percent respectively mimic dataset infuse model generate cheer achieves percent performance model PTBDB macro adopt architecture model perform significance validate significance report improvement cheer baseline correspond sample roc auc cheer benchmark KD HDA mimic PTBDB EEG datasets respectively correspond sample roc auc cheer benchmark KD HDA mimic PTBDB EEG datasets respectively furthermore performance variance infuse model generate cheer reflect report standard deviation suggests cheer knowledge infusion robust investigation cheer perform target behavior infusion infuse model generate cheer achieve stable performance KD HDA prediction target behavior model consequently robust performance fluctuation data setting demonstrate analyze knowledge infusion data setting analyze advantage cheer knowledge infusion exist KD perform additional examine variation dataset feature dataset affect infuse model performance respectively roc auc infuse model generate varies increase ratio dataset data infuse model roc auc varies increase feature dataset setting report performance average independent dnn implementation cheer dnn implementation cheer graph achieve roc auc mimic PTBDB EEG infuse model generate KD HDA cheer datasets axis ratio dataset dataset graph achieve roc auc mimic PTBDB EEG infuse model generate KD HDA cheer data channel feature dataset feature data cheer outperforms baseline data data yield significantly performance across setting consistent observation earlier superior knowledge infusion performance cheer infuse model generate KD HDA perform consistently cheer substantial margin across datasets performance fluctuates wider EEG data cheer datasets cheer knowledge infusion data efficient robust data setting another amount data increase percent data performance happens attention transfer cheer mimic PTBDB EEG however surprising unlike PTBDB EEG mimic comprises heterogeneous signal data distribution unbalanced affect attention performance attention transfer cheer feature prediction performance infuse model generate feature data performance cheer infuse model datasets increase steadily increase input feature model surprising feature increase performance KD HDA fluctuates widely PTBDB EEG datasets contrast observation cheer however unexpected informativeness feature hence utilize combine effectively accurate feature mechanism KD HDA completely lack knowledge infusion model KD HDA performs target transfer model ignores mechanism transfer mechanism model attention transfer feature aggregation mechanism combine feature correctly contrast cheer transfer via behavior infusion feature aggregation via target infusion mechanism performs robustly steady gain without radical fluctuation performance feature increase observation earlier regard performance variance achieve infuse model cheer suggests cheer knowledge infusion scheme robust KD HDA finally demonstrate performance cheer varies choice feature data compute mutual information feature label ranked decrease performance cheer datasets report feature mutual information feature mutual information report feature mutual information label induce transfer performance conversely feature feature mutual information likely improve transfer performance cheer performance mimic PTBDB EEG KK feature mutual information MI label feature dataset KK feature mutual information label feature dataset cheer performance mimic PTBDB EEG feature mutual information MI label feature dataset feature mutual information label feature dataset inspect modality cheer compute average entropy modality across ranked decrease dataset ranked ranked ranked feature entire modality marked respectively cheer performance data feature information quality entropy feature rank mimic PTBDB EEG respectively finally report roc auc achieve correspond infuse model generate cheer feature setting roc auc infuse model degrades consistently across datasets feature data verifies statement earlier informativeness data feature conclusion develops knowledge infusion framework cheer infuse knowledge acquire model feature data model access feature data developed framework leverage model representation parameterize model consequently consolidate behavior succinct summary infuse efficiently model improve performance demonstrate efficiency cheer evaluate cheer multiple datasets promising develop formal theoretical analysis guarantee performance cheer practical assumption future extension cheer potential setting incorporate meta contextual information feature data label