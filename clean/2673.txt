nonnegative matrix factorization NMF successfully apply data mining task recently increase acceleration NMF due matrix privacy issue NMF federate data worthy attention NMF  apply image text analysis involve leverage privacy data medical image across hospital acceleration security distribute NMF propose distribute sketch alternate nonnegative DSANLS framework NMF utilizes matrix sketch technique reduce nonnegative subproblems convergence guarantee DSANLS modification adapt security limited iteration consequently propose efficient distribute NMF synchronous asynchronous setting security guarantee conduct extensive datasets superiority propose implementation available http github com  DSANLS introduction nonnegative matrix factorization NMF technique discover nonnegative latent factor perform dimensionality reduction unlike matrix factorization MF NMF restricts output matrix factor nonnegative specifically goal NMF decompose matrix matrix UV denotes matrix nonnegative user specify dimensionality typically nonnegativity inherent feature application factor NMF interpretation therefore NMF widely text mining image video processing recommendation analysis social network data analysis task apply matrix data increase dimensionality community detection billion node social network background separation video frame approximately text mining bag matrix volume data anticipate increase data era impossible matrix memory throughout NMF therefore performance scalable distribute NMF algorithm surge privacy preserve data mining federate data recent contrast traditional research privacy emphasizes individual information institution federate data mining multiple posse confidential dataset union data utilized achieve performance target task due prevalent NMF image text analysis involve leverage privacy data medical image across hospital privacy issue NMF federate data worthy attention address aforementioned challenge NMF performance privacy acceleration security distribute NMF propose distribute sketch alternate nonnegative DSANLS accelerate NMF distribute NMF mpi FAUN framework iteratively solves nonnegative nls subproblems mpi FAUN exploit independence local update minimize communication requirement matrix multiplication operation within NMF algorithm unlike mpi FAUN distribute NMF orthogonal direction reduce nls subproblem within NMF decrease overall computation nutshell reduce nls subproblem employ matrix sketch technique involve matrix subproblem specially random matrix iteration greatly reduces dimensionality computational subproblem significantly however apply matrix sketch issue although subproblem significantly reduce sketch involves matrix multiplication brings computational overhead unlike machine data distribute node distribute environment node communicate extensively poorly node retains input matrix generate approximate matrix difficulty due data dependency computation besides generate random matrix node iteration broadcasting random matrix node brings severe communication overhead become bottleneck distribute NMF furthermore reduce subproblem sketch random subproblem algorithm converges converges stationary NMF DSANLS overcomes extra computation due sketch reduce choice random matrix random matrix sketch generate independently node transfer node distribute NMF random matrix node NMF iteration locally matrix multiplication data partition therefore matrix sketch approach reduces computational overhead communication moreover due sketch shift optimal NMF subproblem propose subproblem solver theoretical guarantee convergence stationary subproblems secure distribute NMF federate data DSANLS modification adapt security limited iteration therefore syn SD syn ssd synchronous later extend asyn SD asyn ssd asynchronous client server respectively syn ssd improves convergence rate syn SD without incur extra communication reduces computational overhead sketch propose algorithm secure guarantee secure distribute NMF involve infer confidential information knowledge NMF federate data summary contribution DSANLS distribute NMF algorithm leverage matrix sketch reduce nls subproblem apply dense sparse input matrix convergence guarantee propose novel specially subproblem solver proximal coordinate descent DSANLS converge faster discus project gradient descent subproblem solver equivalent stochastic gradient descent sgd non sketch nls subproblem secure distribute NMF propose efficient syn SD syn ssd synchronous later extend asynchronous sketch computation significantly reduce secure distribute NMF federate data conduct extensive dense sparse datasets demonstrates efficiency scalability proposal remainder organize background discus related DSANLS algorithm detailed theoretical analysis propose algorithm secure distribute NMF synchronous asynchronous setting evaluates algorithm finally concludes algorithm coordinate descent framework NMF algorithm input parameter iteration initialize update update return UT VT notation matrix denote entry ith besides omit denote ith jth furthermore replace subset index AI denotes sub matrix whereas sub matrix subset background related illustrate NMF security distribute environment elaborate previous related preliminary NMF algorithm generally NMF define optimization minu UV sourcewhere  frobenius norm directly non convex therefore almost NMF algorithm leverage coordinate descent scheme algorithm optimize factor fix fix optimize nonnegative nls subproblem minu UV SourceSimilarly fix becomes minv VU SourceRight click MathML additional feature within coordinate descent scheme inexact subproblem solver propose widely update multiplicative update MU MU  minimization framework application guarantee objective function monotonically decrease another extensively alternate nonnegative ANLS subproblems exactly framework described algorithm ANLS guaranteed converge stationary perform active project gradient quasi newton accelerate gradient subproblem solver therefore focus ANLS secure distribute NMF secure distribute NMF meaningful practical application suppose hospital clinical matrix phenotype legal commercial concern none hospital reveal personal another directly purpose phenotype classification NMF task apply independently UV UV however schema phenotype concatenate matrix input NMF user patient latent representation item phenotype latent representation MM UV UV source throughout factorization secure distribute NMF guarantee access access worth distribute NMF straightforwardly extend requirement federate data secure distribute NMF actual private protocol definition derives secure function evaluation ass distribute NMF secure definition private protocol protocol honestly curious infer private information data honest curious protocol private collude protocol beyond output matrix transpose operation transforms concatenate matrix concatenate matrix without loss generality scenario matrix concatenate along secure distribute NMF NMF infer secure requirement totally traditional distribute NMF data partition already incurs secure violation related sequel briefly review research related accelerate NMF parallel NMF algorithm literature however parallel machine data communication considerable distribute therefore specialized NMF algorithm massive data handle distribute environment direction MU algorithm mainly focus sparse matrix applies careful partition data maximize data locality parallelism later  mapreduce NMF algorithm implement biological datasets another distribute NMF algorithm leverage wise update local aggregation parallelism performs frequent update whenever recently update data efficient traditional concurrent counterpart apart mapreduce implementation spark attract attention advantage iterative algorithm mllib finally implementation gpu recent related direction mpi FAUN implementation NMF mpi  communication mpi FAUN flexible utilized NMF algorithm iteratively nls subproblems MU  ANLS bpp mpi FAUN exploit independence local update computation apply communication optimal matrix multiplication nutshell matrix split across dimensional grid processor multiple node reduce communication node iteration NMF algorithm matrix sketch matrix sketch technique previously numerical linear algebra statistic optimization described suppose equation instead equation directly iteration matrix sketch random matrix generate instead SA obviously equation equation vice versa however decrease properly generate random matrix appropriate subproblem equation guaranteed progressively approach equation iteratively apply sketch technique knowledge previous incorporates dual random projection NMF centralize environment SANLS centralize version DSANLS algorithm however efficient subproblem solver effective non sketch practical besides data sparsity consideration furthermore theoretical guarantee NMF dual random projection SANLS DSANLS distribute version propose efficient theoretical guarantee secure matrix computation federate data federate data mining collaborate perform data processing task union unencrypted data without leak private data participant surge literature federate matrix computation algorithm privacy preserve gradient descent eigenvector computation singular decomposition cluster spectral cluster partition data secure multi computation mpc apply preserve privacy involve secure addition secure multiplication secure dot secure mpc protocol compute arbitrary function tolerate corrupt per protocol generic specific task secure NMF propose protocol incorporate costly mpc multiplication protocol tolerates corrupt static honest curious recently propose federate phenotype across multiple hospital alternate direction multiplier ADMM tensor factorization developed privacy preserve tensor decomposition framework processing encrypt data federate  distribute sketch ANLS illustrate DSANLS accelerate NMF distribute environment data partition assume compute node cluster partition index input matrix disjoint subset assign node similarly partition index disjoint JN assign node node achieve load balance node factor matrix assign node accordingly node update uir VJr partition data node node data shade partition data node node data shade data partition distribute NMF differs parallel NMF previous parallel NMF partition along dimension adopt partition subproblem independent uir uir  mir uir SourceRight click MathML additional feature independently without refer subproblem addition communication concern mir already node entire meaning node node easily bottleneck naive distribute ANLS implementation explain shortly  algorithm alleviates sketch matrix reduce instead matrix SANLS sketch ANLS understand DSANLS introduce sketch ANLS SANLS centralize version algorithm recall ANLS fix nonnegative variable intuitively unnecessary subproblem accuracy optimal fix variable hence fix variable accurate previous optimal anymore compute apply matrix sketch subproblem obtain approximate computational communication specifically suppose iteration ANLS estimation respectively subproblem update matrix apply matrix sketch residual subproblem subproblem becomes minu mst sourcewhere randomly generate matrix hence decrease chosen sufficiently reduce computational similarly transform subproblem minv SourceRight click MathML additional feature random matrix DSANLS distribute SANLS proposal distribute version SANLS DSANLS subproblem subproblem restrict attention subproblem observation subproblem independent node  mst uir sourcefor simplicity denote atr mst sourceand subproblem  atr uir SourceRight click MathML additional feature node matrix atr subproblem atr apply matrix multiplication atr mst mir therefore node atr compute without communication compute communication across cluster distribute across node fortunately assume node compute cheaper matrix multiplication rewrite     VtJr  SourceNote summand VtJr  matrix compute locally communication sum matrix mpi reduce operation cheaper transmit remain transmission dense broadcasting across cluster expensive however avoid recall randomly generate matrix node generate exactly matrix pseudo random generator therefore broadcast random integer program ensures node generates exactly random sequence hence random matrix iteration communication node reduce adopt sketch technique subproblem likewise communication subproblem decrease framework DSANLS algorithm algorithm algorithm distribute SANLS node input mir parameter iteration initialize uir VJr broadcast random generate random matrix compute atr mir compute VtJr  reduce update  atr uir generate random matrix compute compute  tir reduce update  VJr return   generation random matrix algorithm generate random matrix focus generate random satisfy assumption random matrix correspond sketch equivalent expectation assumption assume random matrix normalize bound variance exists constant    identity matrix option exist matrix computation sketch matrix atr mir VtJr  mir VtJr compute atr expensive construct atr classical choice random matrix gaussian entry variance easy  besides gaussian random matrix bound variance gaussian distribution finite fourth however entry matrix totally random structure exists matrix multiplication expensive mir compute sketch matrix atr mir operation seemingly choice subsampling random matrix random matrix uniformly sample without replacement ith canonical basis vector vector ith others easily satisfies  variance  bound construct sketch matrix atr mir besides subsampling random matrix preserve sparsity matrix hence subsampling random matrix gaussian random matrix application sparse gaussian random matrix faster per iteration convergence rate sketch matrix atr contains entry multiple matrix informative hence gaussian matrix sketch complexity acceptable network cluster hence local computation communication although representative random matrix gaussian subsampling random matrix framework readily applicable choice subsampled randomize hadamard transform SRHT sketch choice random matrix focus future investigation subproblems subproblem important observation sketch technique apply linear however situation matrix factorization distribute matrix factorization usually  mir uir SourceRight click MathML additional feature sketch subproblem equivalently  mir uir SourceRight click MathML additional feature non zero entry residual matrix mir uir matrix consequence optimal shift sketch alert SANLS update exploit sketch subproblem towards optimal avoid convergence sketch subproblem project gradient descent project gradient descent sketch subproblem max  uir atr uir uir  max     sourcewhere max denotes entry wise maximum operation gradient descent computational mainly matrix multiplication  rbt atr respectively gradient descent exploit algorithm expand gradient uir atr uir uir   uir mir uir  mir  SourceRight click MathML additional feature expectation equation  uir atr uir uir mir uir mir uir SourceRight click MathML additional feature gradient sketch subproblem equivalent gradient expectation therefore gradient descent interpret generalize stochastic gradient descent sgd subproblem accord theory sgd naturally diminish increase proximal coordinate descent however gradient descent converges slowly coordinate descent namely  NMF efficient convergence  apply sketch subproblem directly shift away optimal therefore develop resembles  converge towards sketch subproblems achieve regularization sketch subproblem subproblem becomes  atr uir uir  sourcewhere parameter regularization reminiscent proximal parameter project gradient descent therefore enforce convergence algorithm proximal coordinate descent uir uir update  atr uir    uir  SourceRight click MathML additional feature independent entry vector uir independently node  atr    uti max  atr    source coordinate descent successively update iteration already update uir uir  proximal coordinate descent algorithm subproblem summarize algorithm update compute matrix vector multiplication  inner loop vector dot compute summand summation overall complexity coordinate descent typically complexity simplify gradient descent proximal coordinate descent efficient project gradient descent adopt default subproblem solver within DSANLS algorithm proximal coordinate descent local subproblem node parameter   btl btl  max  return theoretical analysis complexity analysis analyze computational communication DSANLS algorithm subsampling random sketch matrix computational complexity node   atr subproblem  communication DSANLS classical implementation distribute  computational sourceand communication due gathering quantity speedup DSANLS algorithm  computation communication however empirically DSANLS per iteration convergence rate iteration converge DSANLS superior alternative distribute NMF algorithm factor account convergence analysis theoretical convergence guarantee propose SANLS DSANLS algorithm SANLS DSANLS converge stationary establish convergence assumption assumption assume iterates uniformly bound norm exists constant experimentally assumption besides assumption enforce impose additional constraint  SourceRight click MathML additional feature max constraint easily handle project gradient descent regularize coordinate descent solver lemma impose extra constraint prevent global optimal lemma optimal exists global optimal domain assumption assumption formally convergence theorem assumption satisfy project gradient descent regularize coordinate descent SANLS DSANLS sub solver converge stationary probability proof lemma theorem supplementary computer society digital library http doi org ezproxy auckland TKDE secure distribute NMF secure distribute NMF federate data extend DSANLS secure DSANLS across dimensional exploit independence local update computation apply communication optimal matrix multiplication cannot apply directly secure distribute NMF secure distribute NMF node others cannot disclose nevertheless DSANLS adapt secure modification limited iteration illustrate theorem modify DSANLS algorithm node update uir VJr MN node subproblem exactly DSANLS differently mpi allreduce function  node iteration subproblem node access fully sketch matrix mst sketch subproblem random matrix reduce communication nls conceals matrix iteration theorem cannot recover information MS SM proof assume matrix MS SM MSS SM however highly imbalanced matrix therefore cannot recover information MS SM however NMF iterative algorithm algorithm secure computation limited iteration cannot guarantee acceptable accuracy practical due theorem recover iteration proof MS linear equation variable matrix constant matrix MS standard gaussian elimination solver sufficient MS theorem suggests DSANLS algorithm suffers dilemma information disclosure unacceptable accuracy impractical application therefore propose practical secure distribute NMF synchronous framework straightforward secure distribute NMF node solves local NMF local denote node periodically node communicate update local aggregation local reduce operation syn SD synchronous detailed algorithm algorithm within inner iteration node maintains regular NMF local average node matrix locally node VJr correspond matrix    node syn SD local node update uniform aggregation local node periodically inner iteration incurs communication reduce convergence node information local inside inner iteration improve efficiency data exchange incorporate matrix sketch syn SD propose improve version syn ssd syn ssd information local across cluster node frequently communication overhead roughly syn SD algorithm sketch version stu local exchange within inner iteration advantage apply matrix sketch sketch matrix reduce operation communication affordable frequency sketch nls reduce computation due reduce VJr node worth exactly node generator necessarily equivalent constraint algorithm equivalent NMF machine environment convergence guaranteed algorithm syn SD secure distribute NMF node input parameter iteration initialize VJr update VtJr update reduce return VtJr straightforward syn SD syn ssd satisfy definition private protocol VJr node asynchronous framework syn SD syn ssd node stall participate node synchronization barrier reduce operation however highly imbalanced data scenario federate data mining severe workload imbalance synchronization barrier node workload halt synchronous algorithm efficient secure distribute NMF asynchronous server client architecture propose correspond asynchronous algorithm algorithm syn ssd secure sketch distribute NMF node input parameter iteration initialize VJr generate random matrix update  generate random matrix reduce SU  VtJr update stm SU reduce return VtJr extend syn SD asynchronous asyn SD asyn SD server algorithm update broadcasting client node server update locally return version client node compute server local client arbitrary consequently cannot operation reduce syn SD instead server update sum newly local client node relaxation asymptotically converges converge guaranteed server relaxation harm factorization convergence algorithm asyn SD asyn ssd server parameter relaxation parameter initialize update counter client node relaxation  client node return client node asyn SD algorithm behave similarly node syn SD client locally standard NMF iteration update local communicate server node unlike syn SD asyn SD global synchronization barrier client node asyn SD independently exchange local server without reduce operation algorithm asyn SD asyn ssd client node input parameter iteration initialize VJr server server VtJr update update VtJr asyn ssd replace algorithm UT server return  similarly syn ssd extend asynchronous version asyn ssd however algorithm client constrain conservative sketch random sketch matrix algorithm across node summation meaningful summation sketch matrix however enforce update sketch synchronous reduce operation therefore cannot sketch asynchronous algorithm sketch VJr asyn ssd algorithm server asyn ssd asyn SD algorithm synchronous version asyn SD asyn ssd satisfy definition private protocol VJr node experimental evaluation experimental evaluation algorithm dense sparse data matrix implementation available http github com  DSANLS setup dense sparse datasets evaluation corresponds NMF task video analysis image processing text mining community detection statistic summarize statistic datasets conduct linux cluster node node contains core intel core cpu ghz core GB memory algorithm implement intel math kernel library mkl message passing interface mpi default node factorization rank report impact node grid dataset report gaussian random matrix datasets rcv dblp subsampling random matrix acceleration NMF ass DSANLS subsampling gaussian random matrix denote DSANLS DSANLS respectively proximal coordinate descent default subproblem solver mention unfair hadoop implementation DSANLS mpi FAUN mpi FAUN MU mpi FAUN  mpi FAUN  implementation mpi implementation mkl armadillo parameter mpi FAUN optimal dataset accord recommendation secure distribute NMF evaluate propose syn SD syn ssd sketch denote syn ssd syn ssd sketch denote syn ssd syn ssd sketch denote syn ssd UV asyn SD asyn ssd sketch denote asyn ssd proximal coordinate descent default subproblem solver secure building baseline communication overhead multi handshake protocol unfair mpi matrix sum described duan canny communication overhead mpi reduce operation relative error rank approximation matrix effectiveness NMF approach error widely previous formally define UV evaluation accelerate NMF performance comparison iteration significantly reduce propose DSANLS mpi FAUN relative error DSANLS mpi FAUN implementation MU  ANLS bpp public datasets DSANLS performs datasets although DSANLS faster per iteration convergence rate MU converges relatively slowly usually convergence  oscillate converges surprisingly although ANLS bpp NMF algorithm perform datasets due per iteration relative error distribute NMF relative error distribute NMF scalability comparison node cluster average iteration algorithm reciprocal per iteration function node algorithm exhibit scalability datasets nearly dataset default complexity dominate hence increase node reduce computational increase communication overhead DSANLS subsampling per iteration algorithm DSANLS gaussian MU  ANLS bpp per iteration explain performance ANLS bpp reciprocal per iteration function cluster distribute NMF performance although tune factorization rank outside scope performance DSANLS mpi FAUN rcv DSANLS outperforms algorithm naturally relative error algorithm decrease increase longer converge relative error distribute NMF comparison project gradient descent claimed proximal coordinate descent approach denote DSANLS rcd faster project gradient descent denote DSANLS PGD confirms difference convergence rate approach regardless random matrix generation approach relative error per iteration subproblem solver distribute NMF evaluation secure distribute NMF performance comparison uniform workload relative error secure distribute NMF algorithm public datasets uniformly partition syn ssd UV performs gisette due per iteration syn ssd UV significantly reduce sketch mnist syn ssd syn ssd convergence relative error syn SD asyn SD converge relatively slowly usually convergence asyn ssd converges slowly consistently generates syn SD asyn SD relative error uniform workload secure distribute NMF relative error uniform workload secure distribute NMF performance comparison imbalanced workload evaluate performance workload imbalanced conduct skewed partition input matrix worker node node assign percent node uniform partition error uniform workload imbalanced workload asynchronous algorithm generally outperform synchronous algorithm asyn ssd relative error dataset asyn SD slowly converges unlike uniform workload sketch syn ssd UV perform imbalanced workload syn SD basically inapplicable  mnist gisette datasets due sparse datasets mnist gisette syn ssd syn ssd converge generate satisfactory dense dataset  scalability comparison node cluster average iteration algorithm reciprocal per iteration function node uniform workload algorithm exhibit scalability datasets nearly dataset consume subproblem solver dominate communication overhead hence increase node reduce per iteration syn ssd UV per iteration algorithm scalability steepest slope synchronous average per iteration explain performance uniform workload relative error imbalanced workload secure distribute NMF relative error imbalanced workload secure distribute NMF reciprocal per iteration uniform workload secure distribute NMF reciprocal per iteration uniform workload secure distribute NMF imbalanced workload setting surprising asynchronous algorithm outperform synchronous algorithm respect scalability synchronization barrier reduce operation severely affect scalability synchronous algorithm nearly curve per iteration per iteration syn ssd UV satisfactory cluster however significant improvement node deployed asynchronous algorithm demonstrate decent scalability node grows average iteration asyn SD asyn ssd explains superior performance synchronous counterpart reciprocal per iteration imbalanced workload secure distribute NMF conclusion overall evaluation convergence scalability syn ssd UV adopt secure distribute NMF uniform workload asyn ssd reasonable choice secure distribute NMF imbalanced workload conclusion acceleration security distribute NMF novel distribute NMF algorithm DSANLS scalable analytics dimensional matrix data approach framework ANLS utilizes matrix sketch reduce nls subproblem approach generate random matrix gaussian subsampling random matrix subproblem solver framework theoretically algorithm convergent analyze per iteration computational communication approach convergence superiority efficient distribute NMF synchronous asynchronous setting security guarantee distribute NMF federate data data utilized NMF performance data remains confidential without leak individual information finally conduct extensive datasets superiority propose future application DSANLS dense sparse tensor practical asynchronous algorithm secure distribute NMF