explosive increase data academic important apply data processing analyze data arguably spark data compute nowadays due generality fault tolerance performance memory data processing scalability spark adopts flexible resident distribute dataset rdd program model transformation action operator operating function customize user accord application originally data processing research effort efficient faster various circumstance introduction survey aim thorough review various optimization technique generality performance improvement spark introduce spark program model compute discus pro con spark investigation classification various technique literature moreover introduce various data management processing machine algorithm application spark finally discussion issue challenge memory data processing spark introduction era data data unprecedented application domain commerce social network computational biology characteristic unprecedented amount data data production multiple structure data data processing essential analyze mining data timely data processing framework thereby developed mapreduce storm flink dryad caffe tensorflow specifically mapreduce batch processing framework storm processing flink data compute batch processing dryad graph processing framework graph application caffe tensorflow framework model training inference computer vision recognition processing however aforementioned framework compute data computation comparison spark data processing widely academia merit spark faster mapreduce performance benefiting memory data processing moreover batch interactive iterative computation runtime useful complex application computation mode despite popularity limitation spark considerable amount program effort rdd program model emerge heterogenous compute platform gpu fpga default compute application application spark address limitation spark mention remains active research effort performance optimization spark framework proposal complex schedule strategy efficient memory RDMA improve performance spark extend spark sophisticated algorithm application algorithm genome astronomy improve declarative procedural propose spark emergence hardware software application demand brings opportunity challenge extend spark improve generality performance efficiency survey sake understand potential demand opportunity systematically classify spark ecosystem layer illustrate namely storage layer processor layer data management layer data processing layer layer application algorithm layer aim fold seek investigation spark ecosystem review related spark classify accord optimization strategy  user address technique data processing spark summarizes exist technique systematically expert researcher discus development trend demand challenge layer spark ecosystem illustrate researcher insight potential direction spark overview spark ecosystem classify layer improve generality performance efficiency overview spark ecosystem classify layer improve generality performance efficiency survey structure introduces spark program model runtime compute pro con various optimization technique describes cache device spark memory computation discus extension spark performance improvement accelerator distribute data management processing spark spark review spark machine library spark application spark apply discussion challenge issue finally conclude survey core technique spark describes rdd program model overall architecture spark framework pro con spark various optimization technique spark program model spark resilient distribute dataset rdd abstraction model immutable collection partition across computer rdd generate data external robust storage hdfs RDDs coarse grain transformation filter  identical processing numerous data fault tolerance rdd transformation information construct lineage dataset data partition rdd lose due node failure rdd recompute partition information generate RDDs worthy mention transformation lazy operation defines rdd instead calculate immediately launch computation rdd spark another action operation reduce return data application program rdd data external storage moreover data rdd persist memory disk user spark architecture overview architecture spark cluster spark application spawn driver responsible task schedule hierarchical schedule stage task stage refer task interdependent resemble reduce phase mapreduce scheduler inside namely    dag stage materialize RDDs stage output whereas  scheduler responsible submit task stage cluster execution architecture overview spark architecture overview spark spark user cluster mode mesos yarn standalone mode spark application driver exist popular cluster manager mesos yarn independent cluster manager worker node executor application responsible task cache data memory disk pro con spark mapreduce flink powerful data processing widely data intensive application mapreduce flink baseline discus pro con spark spark versus mapreduce mapreduce spark merit easy spark user operator reduce  filter user parallel application application underlie complex parallel compute data partition task schedule load balance moreover spark allows user user define function program java scala python offering correspond apis faster mapreduce due memory compute spark faster mapreduce batch processing computation aspect processing mode spark integrate batch interactive iterative processing spark advanced dag execution complex dag application stack apis shark spark sql mllib graphx application flexible spark standalone mode cluster compute mapreduce yarn mesos apis user deploy amazon EC moreover access various data source hdfs  hbase cassandra amazon albeit benefit weakness spark mapreduce consumption storage resource memory data processing framework spark superior mapreduce performance achieve reduce redundant computation expense storage resource memory resource exist popular memory cache memcached redis rdd data memory data across computation stage memory resource volume rdd data cached computation security currently spark authentication secret comparison hadoop security consideration  sentry ranger etc  secure api gateway hadoop authorization authentication contrast sentry ranger access authorization hadoop data metadata curve although spark faster mapreduce program model spark complex mapreduce user model familiar apis program application spark spark versus flink competitor spark flink stateful memory data compute batch interactive data processing framework similarity function summarize data abstraction model performance framework program model batch application spark rdd abstraction model batch computation  model computation  internally rdd computation spark indeed realtime processing achieve emulate serial micro batch computation contrast flink leverage dataset abstraction batch application  application mapreduce spark flink achieve performance efficiency batch application due memory computation particularly iterative batch application application flink faster spark due incrementally iterative computation architecture handle portion data actually generality spark flink compute variety computation batch iterative interactive computation graph machine computation etc program sql java scala python etc moreover spark flink fully compatible hadoop ecosystem yarn data hdfs hbase cassandra hive etc spark flink become flexible easy fault tolerance spark flink fault tolerant basis mechanism spark achieves fault tolerance lineage recovery mechanism efficient fault tolerance mechanism recompute lose data lineage information extra storage  flink  lamport distribute snapshot consistent checkpoint lightweight fault tolerance mechanism achieve throughput consistency guarantee maturity popularity spark relatively mature popular flink data community document spark maintain spark community whereas flink document active user spark flink spark security flink mature user authentication via hadoop kerberos authentication summary sake understand spark characteristic summary spark flink mapreduce respect metric framework usability flexibility scalability fault tolerance complex detail distribute computation encapsulate framework transparent user spark flink outperform mapreduce performance generality attribute spark flink memory computation flexible program model  mapreduce security easy spark flink spark flink program model mapreduce mature moreover framework memory consumption due memory usage  finally due merit documentation spark become popular project framework comparison spark flink mapreduce comparison spark flink mapreduce spark optimization performance important concern spark optimization spark accelerate data handle mainly optimization propose spark scheduler optimization spark centralize scheduler allocates available resource pending task accord policy fifo schedule policy satisfy requirement data analytics scheduler optimize distribute schedule approximate query processing transient resource allocation geo distribute respectively decentralize task schedule nowadays data analytics framework parallelism shorter task duration latency increase task throughput availability centralize scheduler latency requirement availability decentralize without centralize attractive scalability availability sparrow distribute scheduler spark choice load balance technique spark task schedule probe random server task server load sparrow adapts choice technique spark effectively parallel cluster technique namely batch sample binding policy constraint batch sample reduces task response task task batch instead sample task individually choice server queue norm latency parallel sample competition binding prevents issue delay allocation task worker node worker execute task sparrow enforces global policy multiple queue worker machine placement constraint task data aware task schedule machine algorithm sample approximate query processing compute subset data without compromise application correctness currently scheduler application statically subset data scheduler task  scheduler leverage combinatorial choice dataset runtime data aware schedule kmn propose spark advantage available choice kmn applies binding technique dynamically subset input data basis cluster significantly increase data locality utilization cluster kmn optimizes intermediate stage choice input output upstream task kmn launch additional previous stage choice avoid congest link transient task schedule server due various utilization tends utilization rate competitive pressure address insensitive batch workload secondary background task utilized resource evict server primary task resource transit resource due excessive cascade computation spark badly transient resource spark TR spark propose resolve framework data analytic transient resource data reduction aware schedule lineage aware checkpointing TR spark implement modify spark task scheduler shuffle manager module checkpointing scheduler checkpoint manager schedule geo distribute environment geo distribute data deployed globally user access service latency geo distribute bandwidth wan link relatively heterogeneous intra DC network query response intra DC analytics framework becomes extreme geo distribute iridium geo distribute data analytics spark reduces query response leverage wan bandwidth aware data task placement approach network bottleneck mainly network data link vms assume iridium implement task schedule algorithm flutter spark reduces completion network formulate optimization issue lexicographical min max integer linear program ILP memory optimization efficient memory usage important memory compute data processing framework garbage java scala unfortunately garbage performance overhead due GC induced pause address improvement GC performance garbage leverage application semantics manage memory explicitly  GC overhead garbage introduce optimization aspect spark multiple node garbage collection GC perform independently node communicate data node shuffle operation node data node GC pause unacceptable latency critical application without central coordination node stuck GC node coordinate GC central holistic runtime propose collectively manages runtime GC across multiple node instead decision GC independently holistic GC allows runtime globally coordinate consensus decision approach application suitable GC policy requirement application throughput versus pause holistic performs GC application optimization GC dynamically reconfigured runtime adapt instead memory management manage spark manage memory leverage application semantic eliminate GC overhead  tungsten improves memory cpu efficiency spark application performance spark limit hardware consists proposes leverage heap memory feature java allocate deallocate memory manage memory advantage application semantics  overhead jvm GC proposes cache obvious algorithm data structure develop memory hierarchical structure code generation avoid overhead expression evaluation jvm virtual function extensive memory access advantage cpu feature simd pipeline prefetching recently spark optimizes performance integrate technique propose parallel database spark leverage code generation vectorization ameliorate code generation runtime optimization data intensive computation spark massive data load disk transmission task machine unavoidable approach thereby propose alleviate storage manner data compression import hardware data compression limitation spark memory data task within application whereas task multiple application overcome limitation  propose distribute memory file achieves reliable data memory speedup task spark application data reading data  memory speedup faster disk hdfs file moreover enable data memory efficient computation propose implement distribute data succinct  compress input data query execute directly compress representation input data avoid decompression data shuffle besides performance degradation disk network serious bottleneck spark application particularly shuffle data transfer task across machine important consumer network bandwidth spark bottleneck shuffle phase due disk operation address framework  propose improve efficiency combine fragment intermediate shuffle file file convert random disk operation sequential propose approach optimize performance data shuffle apply columnar compression technique spark shuffle phase orient DBMS offload burden network disk cpu moreover spark generates shuffle file reduce phase introduces burden operating file management shuffle file consolidation approach thereby propose reduce shuffle file machine moreover prefetching effective technique hide shuffle overlap data transfer shuffle phase mechanism data acquire performance sub optimal excessive supplemental memory address propose adaptive shuffle data transfer strategy dynamically adapt prefetching calculation achieve account load balance request extraction executor coordination prioritization accord locality responsiveness shuffle aggregation elastic adjustment flight restriction static circular allocation initial request dispersal flight increment focus optimize shuffle circumstance optimization spark memory server achieve data shuffle intermediate storage replace exist tcp IP shuffle memory approach communication reduce task reduce significantly reference global memory data transfer network data shuffle network data transfer geographically distribute datacenters implement data aggregation spark aggregate output task subset worker datacenters strategically proactively replaces passive fetch mechanism spark across datacenters avoid repetitive data transfer thereby improve utilization inter datacenter link RDMA data transfer accelerate network communication spark data processing remote memory access RDMA technique propose RDMA data shuffle spark infiniband RDMA latency network message communication dramatically reduce improves performance spark significantly  data intensive scalable compute disc hadoop spark program model user authorize data processing logic convert acyclic graph dag parallel compute debug data processing logic disc consume library  data provenance velocity interactive apache spark contribution  summarize data lineage capture query minimally impact spark performance interactive data provenance query expansion  program model spark rdd overhead  extends native spark rdd interface trace capability return  dataflow transformation stage boundary user retrospect intermediate data program execution rdd leverage local rdd transformation reprocess reference data currently researcher compute platform analyse data parallel debug massive parallel computation consume infeasible user overhead scalability grain demand data processing apache spark interactive debug primitive developed  simulated breakpoints guard watchpoints trifle influence performance indicates percent overhead crash monitoring percent overhead trace percent overhead watchpoint average  rapid repair recovery prevent besides  provenance culprit grain distribute pipe intermediate forth improve version  reduce lineage query feature  crash culprit determination automate fault localization culprit information package dispatch user delta debug technique diagnose mistake code data promote performance lineage query extend spark available retrieve lineage pragmatically data trace query generate remarkable overhead contribution therefore proposes  customize spark scheduler utilizes partition statistic exclude situation moreover  decouples task operation partition  multiple partition task storage layer spark dram cache memory computation although dram bandwidth latency hdd data communication capacity limited due dram consumption significantly constrain data application gain memory rate essential performance spark emerge storage device recent alleviate ssd memory compute solid disk ssd storage device access traditional hdd instead hdd approach adopt ssd persistent storage multi tier storage illustrate comparison hdd data movement memory ssd faster improve spark performance spill RDDs ssd memory cache SSDs performance improvement hdd cache approach spark multi tier storage consist dram ssd multi tier storage consist dram ssd nvm memory compute dram latency ssd dram although faster hdd emerge non volatile memory nvm pcm stt ram ReRAM alternative ssd due latency bandwidth ssd integrate dram nvm ssd establish multi tier cache cache data dram nvm dram ssd dram ssd processor layer limited performance efficiency purpose CPUs impede performance conventional data becomes popular deploy accelerator data gpu fpga therefore accelerator heterogeneous machine become promising data achieve performance efficiency summary spark integrate gpu accelerate compute task survey spark fpga purpose computation graphic processor gpgpu graphic processing gpu originally graphic computation widely evolve accelerator compute operation traditionally handle cpu refer gpgpu gpu widely integrate datacenter performance efficiency cpu however compute framework spark cannot directly leverage gpu accelerate compute task related project gap  novel gpu enable spark  leverage compute gpus CPUs accelerate machine application propose gpu enable spark plug spark programmer leverage gpu compute without knowledge gpu  propose extension spark  leverage gpus accelerate array scientific compute image processing application  introduces  resilient distribute dataset  handle array data gpu gpu compute ability fully utilized explore gpu acceleration apache spark explore possibility benefit offload compute task spark gpus non shuffle compute task compute gpu computation significantly reduce experimental performance cluster application optimize implementation publicly available http github com adobe research spark gpu columnar rdd  proposes prototype inner data columnar rdd conventional rdd columnar layout easy benefit gpu simd enable cpu therefore performance  logistic regression improve fpga fpga integrate compute framework spark accelerate inner compute task related project fpga enable spark  fpga enable spark explores efficiently integrate FPGAs data compute framework spark deploys fpga enable spark cluster representative application generation dna sequence accelerate technology efficient mechanism efficiently harness fpga jvm jvm fpga communication via pcie overhead alleviate fpga service FaaS framework propose FPGAs multiple cpu thread therefore compute ability FPGAs fully utilized execution significantly reduce  program interface java spark automatically leverage accelerator fpga gpu heterogeneous cluster speedup compute task without interference programmer accelerator abstract subroutine spark task execute local accelerator available therefore computation significantly reduce otherwise task execute cpu  management layer data data generally manage distribute filesystems database survey widely data storage management spark distribute file hadoop distribute file hdfs hadoop distribute file propose deployed commodity hardware highly scalable fault tolerant enable cluster node hardware failure normal architecture contains namenode manage file namespace regulate access file user DataNodes machine data data uploaded hdfs partition plenty fix MB per data namenode dispatch data DataNodes manage data assign improve data reliability replicates data replicator default user replica rack hdfs data access originally spark native interface enables spark application data hdfs directly  centralize inherent client server model testify important barrier scalable performance  distribute file performance dependability promising unprecedented   generate function replace file allocation decouple operation data metadata  distribute complexity around data access update sequence duplication dependability fault detection resume intelligence   highly adaptive distribute metadata cluster architecture greatly enhances scalability metadata access scalability  rapid growth data storage networking challenge bottleneck data writes become network disk binding duplication responsible fault tolerance   fault tolerant memory centric virtual distribute file address bottleneck enables reliable operation memory data application cluster compute framework obtain throughput writes without impair fault tolerance  leverage notion lineage recover lose output implement output task without replicate data  user transformation exploration datasets memory performance enjoy data reliability illustrates memory centric architecture  manages data access storage user application compute framework unify compute framework mapreduce spark flink traditional storage amazon apache hdfs openstack swift facilitates data locality compute serf unify platform various data source compute functional layer  lineage persistence lineage layer throughput information task specific output contrast persistent layer  data storage mainly checkpoint  employ architecture mainly manages global metadata entire lineage information interacts cluster resource manager distribute resource recalculation manage local storage resource allocate  data request user  architecture  architecture data storage service storage typically network distribute data storage service user data compute technique virtualization data redundantly location data availability transparent user storage service access computer service application program interface api application api popular storage service amazon  azure amazon storage service amazon web storage service allows user fetch data web service interface style http interface  interface BitTorrent protocol user demand storage request data transfer data amazon manage storage architecture oppose file manage data file hierarchy organize bucket aws account user identify within bucket unique user assign spark file interface user access data amazon specify input uri format hadoop however storage spark dataframe amazon natively spark regard user utilize spark connector library upload  amazon  azure blob storage  azure blob storage  service user fetch amount unstructured data text binary data binary  blob namely blob append blob blob blob suitable append blob optimize append operation contrast blob improve IaaS disk random writes multiple blob grouped container user storage account container data access via http HTTPS api spark compatible  enable data  directly access spark via specify uri format  data distribute database hbase apache hbase source implementation google  distribute database feature data compression memory operation bloom filter per basis hadoop leverage scalability hdfs batch processing capability mapreduce enable massive data analysis data access individual query orient database multidimensional sparse timestamp tag identify retrieve specify timestamp hbase consists define   fix schema user access achieve primary java api  thrift gateway apis library emerge enable spark interact hbase spark hbase connector library elegant api user spark application hbase reading data enable native optimize sql access hbase data via SparkSQL dataframe interface spark sql hbase developed huawei moreover efficient scan mutate hbase RDDs spark environment generic extension spark module spark hbase developed dynamo amazon dynamo decentralize distribute storage scalability availability amazon application characteristic database distribute hash  built amazon application program reliability offs availability consistency effectiveness performance amazon commerce service primary access data shopping cart customer preference sale rank service inefficiency limited availability relational database comparison dynamo fulfill requirement primary interface dynamo leverage efficient optimization technique achieve performance variant consistent hash replicate data across machine overcome inhomogeneous data workload distribution technology arbitration decentralize replication synchronization protocol ensure data consistency update employ gossip style membership protocol enables machine arrival departure machine decentralize failure detection DynamoDB amazon DynamoDB reliability effective nosql database service internet application distribute principle data model dynamo contrast dynamo user manage DynamoDB fully manage service user headache complex installation configuration operation built solid foreseeable performance latency enables user database fetch amount data ability disperse data traffic sufficient machine automatically request demand medium creates library spark DynamoDB DynamoDB data access spark enables DynamoDB spark dataframe allows user sql  DynamoDB directly SparkSQL cassandra apache cassandra highly scalable distribute structure storage data commodity server source facebook widely deployed cassandra integrates data model google  distribute architecture amazon dynamo eventually consistent dynamo  data model  database operation apis insert   delete  characteristic cassandra decentralize node cluster role without introduce fault highly scalable throughput increase linearly  machine downtime application data replicate automatically multiple machine fault tolerance failure address without shutdown finally adjustable consistency user balance tradeoff circumstance enable connection spark  cassandra spark cassandra connector developed release openly  expose cassandra spark RDDs RDDs cassandra implicit  moreover python pyspark module pyspark cassandra built spark cassandra connector comparison comparison storage spark summarize storage belong storage data data model data access interface licence hadoop spark various typed storage via apis SparkSQL crucial generality spark data storage perspective spark memory computation memory data cache important achieve performance hdfs  cassandra memory disk data storage manner become popular widely data application comparison storage comparison storage  processing layer purpose framework spark variety data computation processing graph processing OLTP olap query processing approximate processing discus research effort processing spark user data source kafka  amazon  spark built upon data parallel compute model reliable data processing spark convert processing series deterministic micro batch calculation utilizes distribute processing framework spark implement abstraction discretized distributes data batch spark partition data batch  pre define interval batch data resilient distribute datasets RDDs spark incorporate spark component mllib spark sql seamlessly due popularity spark research effort devote improve relationship batch throughput latency effort extend spark framework complex processing complex processing cep processing assembles various source data complex relationship various analyze data source cep identify opportunity threat alert decade cep successfully utilized  recommendation stock monitoring health source project building cep spark decision cep complex processing platform combine spark framework  cep spark cep another processing built spark continuous query exist spark query efficient windowed aggregation insert query data mining data era data motivates data mining typically evolve traditional data mining approach data principle volume limit hence impossible entire training dataset memory statistic characteristic incoming data continuously evolve continuously training evolve challenge traditional offline model approach longer source distribute data mining platform   propose attract attention typically  spark provider data data mining library sgd learner perception graph processing graph processing easily computation memory capacity machine become ambitious complexity graph distribute graph processing framework graphx propose graphx library atop spark encodes graph collection express graphx apis standard dataflow operator graphx optimization strategy developed briefly mention graphx contains series built partition function  vertex collection collection rout vertex collection hash partition vertex collection split horizontally user vertex partition maximize index reuse subgraph operation generates subgraphs  graph index utilizes bitmask item reduce operation graphx resolve attribute function access  jvm bytecode triple  implement attribute access graphx involve absence attribute access  completely eliminate contrast specialized graph processing pregel powergraph graphx closely integrate purpose distribute dataflow spark approach avoids compose multiple increase complexity integrate analytics pipeline reduces unnecessary data movement duplication furthermore naturally inherit efficient fault tolerant feature spark usually overlook specialized graph processing framework experimental evaluation graphx faster specialized graph processing OLTP olap query processing hybrid transaction analytical processing  respond OLTP olap query data dual format processing utilization  enable transaction interactive analytics unitary exploit AQP technique multiple data summary interactive  integration spark  operation memory data storage combine model spark computation available cpu kernel task  partition mode spark api extend uniform api olap OLTP approximate processing data analytics application demand response rate however extreme data response sometimes unacceptable user besides utilize extra resource memory cpu reduce data processing approximate processing faster query response reduce amount perform technique sample online aggregation widely user accept inaccurate quickly exploratory query approximate query processing response crucial application web interactive query workload achieve propose approximate query processing  atop shark spark distribute sample return query query data terabyte within substantial error bound bound percent strength  meaningful adaptive optimization framework series multi dimensional sample raw data dynamic sample selection strategy accuracy response query moreover evaluate accuracy  propose effective error estimation approach extend prior diagnostic algorithm bootstrap error estimate reliable operation building database propose operator  approximates distribute computation spark interweave bloom filter sketch stratify sample bloom filter prevent non  data shuffle stratify sample approach representative sample output approximate processing unlike batch analysis input data unchanged sample data analytics traditional batch orient approximate compute analytics address propose analytics  online stratify reservoir sample  generate approximate output tight margin error implement  apache spark experimental accelerate rate accuracy baseline spark approximate calculation utilize exist sample module apache spark approximate incremental processing incremental processing refers data computation incrementally schedule involve application logic input data avoid recomputing everything scratch approximate computation subset data item paradigm complementary propose paradigm approximate incremental processing leverage approximation incremental technique latency execution propose online stratify sample algorithm leverage adaptation calculation generate incremental update approximation bound error execute apache spark propose  experimental evaluation benefit  equip incremental approximate compute layer spark scala orient functional program jvm java library directly scala code vice versa natively spark program scala java default however user unfamiliar scala java skilled alternative python moreover spark program complex user familiar spark framework thereby sql declarative spark crucial user denote task complicate implement  detail backend spark alleviates user program burden significantly research propose address python  numeric analysis machine domain popular program widely data scientist statistical compute data analysis  frontend incorporates spark enables programmer perform amount data analysis extends machine implementation distribute data frame implementation spark datasets implementation  basis spark parallel dataframe abstraction spark dataframe analytical operation function aggregation filter summary statistic sql query pyspark pyspark python api spark expose spark program model python allows user spark application python difference pyspark spark scala apis python dynamically typed RDDs pyspark capability multiple RDDs pyspark function scala apis leverage python function return python collection pyspark anonymous function pyspark api python lambda function sql program shark apache shark sql spark effort built hive codebase spark backend leverage hive query compiler HiveQL parser analysis HiveQL query abstract syntax logical optimization shark generates physical rdd operation finally executes spark performance optimization reduce memory overhead jvm executes columnar memory storage spark native memory query optimizer implement shark efficient accord statistic reduce impact garbage collection shark primitive jvm primitive array finally shark completely compatible hive HiveQL faster hive due inter query cache data eliminates repeatedly disk complex query user define function UDFs reference HiveQL query spark sql spark sql evolution sql spark module spark replace shark sql interface propose developed overcome difficulty performance optimization maintenance shark inherit complicate hive codebase shark capability spark sql tighter hybrid relational procedural processing becomes easy user extension composable code generation define extension compatible shark hive exist hive data format user define function udf hive  sql performance program interface spark sql core dataframe api catalyst optimizer interaction spark expose sql interface command console jdbc  dataframe api implement spark procedural program dataframe abstraction spark sql api distribute enable execute spark api relational apis catalyst contrast scalable query optimizer functional program construct simplifies addition optimization technique characteristic spark sql enables user expand optimizer application interface spark sql interface spark sql hive HiveQL apache hive source data warehouse hadoop facebook data infrastructure aim incorporate classical relational database notion sql unstructured environment hadoop user familiar reduce mechanism inside hive project structure onto data hdfs enable data query sql declarative HiveQL contains collection nest composition data definition ddl hive compiles sql query express HiveQL acyclic graph reduce execute hadoop  component inside hive metadata underlie creation reuse whenever reference HiveQL ddl statement HiveQL enable alter hive database moreover data manipulation statement HiveQL import data external source hbase  query hive hive widely organization user application however default backend execution hive mapreduce powerful spark spark alternative backend execution hive important hive user migrate execution spark realize version hive user hive spark configure backend spark pig pig latin apache pig source dataflow processing developed yahoo serf experienced procedural programmer preference reduce style program pure declarative sql style program pursuit execution consists execution data pig latin declarative enables expression user task declarative query sql spirit procedural program mapreduce instance sql query pig latin program function sequence transformation sql primitive filter aggregation pig latin program pig execution generates logic query compiles dag mapreduce finally submit hadoop cluster execution instance sql query equivalent pig latin program instance sql query equivalent pig latin program important characteristic pig latin casual hoc data analysis nest data model predefined customizable UDFs capability operating raw data without schema data integer pig latin multiple  integrate tuples bag complex data pig latin contains item associate hive default backend execution pig mapreduce enable execution pig spark performance improvement pig spark project  plug spark execution pig  user spark backend execution pig framework optionally application comparison illustrates comparison program spark compatible hive pig user replace backend execution mapreduce spark query efficient shark developed later evolves SparkSQL   pyspark spark python widely scientific user difference  pyspark dataflow sql program contrast shark SparkSQL hive sql pig dataflow comparison program comparison program application algorithm layer purpose spark widely various application algorithm review machine algorithm spark application spark machine spark machine powerful technique develop  recommendation predictive insight diverse user focus data service machine algorithm involve iterative computation execution spark efficient memory compute iterative processing recent attracts academia machine package spark discus research effort machine library mllib active distribute machine library spark mllib contains scalable execution machine algorithm variety analytical utility optimization primitive pipeline apis machine library algorithm meanwhile allows user expand professional utilization core feature mllib implement classic machine algorithm various linear model SVMs logistic regression linear regression naive bayes random classification regression alternate collaborative filter cluster dimensionality reduction FP growth frequent mining mllib optimization efficient distribute prediction practical machine pipeline natively package spark inside mllib simplifies adjustment multi stage pipeline offering unified apis lastly tight seamless integration mllib spark component spark sql graphx spark spark core performance improvement various functionality mllib mllib advantage simplicity scalability streamline compatibility spark module widely application marketing advertising fraud detection   framework ML pipeline UC berkeley  aim simplify architecture machine pipeline apache spark enables throughput training distribute environment api machine application  core feature user specify machine pipeline logical operator amount data complexity expands dynamically finally automatically improves application library operator user resource  source apply scientific application solar physic genomics   source library developed freeman lab neural data analysis spark  pyspark apis robust numerical scientific compute library numpy scipy simplest user  data structure load data amount input format processing distribute data spatial temporal modular function series analysis image processing factorization model fitting  involve medical image neuroscience video processing geospatial climate analysis adam adam library parallel framework enables align unaligned genomic data apache spark across cluster compute environment adam competitive performance optimize multi thread node enable cluster core adam built modular stack data format optimizes query without data structure traditional genomics flexible target application function layer stack model physical storage data distribution materialize data data schema evidence access presentation application narrow  layer model developed building scientific analysis enforce data independence stack model computational data model data model serialize representation data disk exploit expensive machine percent improvement improvement preprocessing pipeline latency machine era artificial intelligence AI trend data AI unified amount constantly update training data model AI application spark unified analytics integrates data processing  machine AI algorithm  complexity exist machine algorithm overwhelm user understand  parameterizing algorithm achieve performance moreover exist distribute machine ML researcher background distribute primitive limit machine technique data seriously  propose address platform  HO scalable source commercial machine HO inc implementation machine algorithm generalize linear model linear regression logistic regression naive bayes principal component analysis cluster advanced machine algorithm distribute random gradient boost familiar program interface python scala graphical user interface utilize capability spark  integrates HO machine spark transparently enables launch HO spark HO algorithm HO UI inside spark cluster ideal machine platform application developer spark regular spark application launch inside spark executor spawn submit application initialize HO service node spark cluster enables data spark HO transformation spark RDDs HO  vice versa splash efficient address machine optimization stochastic algorithm splash framework stochastic algorithm efficient approach address machine optimization distribute compute program interface execution user develop sequential stochastic algorithm program interface algorithm automatically parallelize communication efficient execution splash  construct parallel algorithm execution splash distribute manner distribute version average reweighting approach splash parallelize algorithm convert distribute processing task sequential processing task reweighting scheme ensures load handle individual thread sample sequence indicates thread update completely unbiased estimate splash automatically  optimal parallelism algorithm approach splash outperforms prior algorithm thread stochastic batch magnitude   berkeley data analytics stack data storage manager dataflow execution processor sample advanced analytics package  insufficiency user actually data industrial user stack model service management  gap execute model service model maintenance proportion latency intuitive model interface application service moreover transforms statistical model currently offline compute framework data recommend target advertisement web content  consists construction  model predictor manager  model manager orchestrates computation maintenance pre declare machine model incorporate feedback evaluate capability model retrain model machine algorithm become popular widely computer version recognition processing bioinformatics due benefit accuracy efficiency flexibility framework implement spark  deeplearningj   exist distribute model training model usage compute model data processing cluster hadoop spark cluster application computation cluster model training integrate model training model usage united amount data model transfer cluster multiple program typical machine pipeline increase latency complexity contrast alternative compute model illustrate conduct data processing cluster distribute compute model distribute compute model caffe popular framework developed cuda berkeley vision  accord model yahoo extends caffe spark framework develop  distribute cluster consist gpu cpu machine  spark package complementary non library mllib spark sql architecture  launch caffe within spark executor gpu cpu device invoke jni layer grain memory management moreover achieve performance dedicate cluster  spark mpi architecture leverage mpi allreduce style interface network communication across  executor tcp ethernet RDMA infiniband  architecture  architecture deeplearningj  spark deeplearningj commercial grade source distribute library java scala compute framework implementation algorithm restrict boltzmann machine belief net autoencoder stack denoising autoencoder recursive neural tensor network wordvec docvec glove integrates spark via spark package  spark spark component dataframe reader mnist label LFW iris pipeline component   heterogeneous architecture spark cpu gpu coprocessors distribute context   source distribute training network spark release   nov spark caffe spark distribute data processing caffe framework responsible core  data spark RDDs interface compatible caffe achieves scalability tolerance latency communication utilize  scheme stochastic gradient descent allows spark user construct network exist library tensorflow torch backend instead building library java scala integrate model combine exist model training framework exist batch framework beneficial machine involves pipeline task data retrieve cleaning processing model training model deployment model prediction training handle exist data processing pipeline distribute computational environment spark moreover integrate model  inherit memory computation spark data cached memory computation instead disk operation approach allows machining algorithm easily pipeline spark component spark sql graphx moreover spark library framework       training library spark apply  executes distribute training splitting training data data shard synchronizes replicate model centralize parameter server  accelerates model training offering asynchronous stochastic gradient descent data hdfs  distribute framework apache spark interface user algorithm spark  user spark enables seamless integration spark machine pipeline microsoft cognitive toolkit CNTK opencv creation powerful highly scalable predictive analytical model image text datasets quickly  alternative framework  integrates component spark asynchronous parameter update gpu caffe seamlessly enhance data processing pipeline accelerate dnn training spark application efficient data processing spark widely application domain genomics medicine healthcare finance astronomy etc genomics due computational efficiency adaptive capability complex phenotype effective statistical widely apply inference throughput genomic data calculation resampling inference scalable distribute compute approach compute platform appropriate user analyze data modest without access mainframe computer infrastructure  series distribute compute algorithm execute spark awkward parallel genomic resampling inference effective statistic calculation advantage spark fault tolerant feature easily expand analyze dna rna sequence data expression quantitative feature locus eQTL  association synthetic datasets efficiency scalability  capacity resampling data amazon elastic mapreduce EMR cluster utility spark genomic context  propose executes memory computing via apache spark versatile rna dna sequence analysis processing operation generic alignment format binary alignment  format sequence alignment sam format filter summarize genomic characteristic statistical analysis operation moreover  customize secondary analysis iterate algorithm machine spark  acceleration dna alignment exploit spark performance optimization cache broadcast variable partition memory computation spark  multiple sequence alignment msa massive sequence promise achieve alignment accuracy comparable execution algorithm  II medicine healthcare society pressure trap health issue reduce medical treatment organization devote adopt data analytics avoid amount healthcare data healthcare utilization data without processing data interactively healthcare data spark spark automate analytics iterative processing data circumstance quality data brings generate accurate data mart spark data processing probability linkage propose approach specifically data quality assessment database connectivity  ministry health ministry social development hunger reduction moreover sensitivity drug prediction analysis drug target cancer various machine algorithm vector machine logistic regression random mllib spark finance data analytic technique effective financial service user financial domain stock accurate prediction decision trend factor politics social propose prediction model stock trend analyze data news tweet historical price apache spark model offline mode historical data mode data stock session quantitative invest spark macro timing  rebalancing user account digital payment online transaction fraud detection important issue financial service credit fraud detection spark data processing fraud detection hidden markov model hmm credit transaction analyze data generate data propose realistic scalable fraud detection fraud finder  machine approach integrate data software kafka spark cassandra imbalance  verification latency moreover financial application financial risk analysis financial trading astronomy technological advancement telescope ongoing survey project astronomical research data era survey data simultaneously various scientific research  flexible distribute astronomy image processing toolkit spark propose execute source extractor application extraction accuracy improve task query analyze arbitrarily astronomical catalog  propose enables efficient online positional spark python library commonly operation astronomical data implement  algorithm scalable moreover astronomy spatial data analysis challenge issue discus research issue opportunity spark ecosystem memory resource management memory processing platform built scala spark performance sensitive memory configuration usage  memory resource rdd cache task memory task execution configuration memory allocation non trivial performance improvement moreover overhead jvm garbage collection challenge amount churn cached RDDs due serious interference cached RDDs task memory detailed GC impact spark distribute environment tune GC important role performance optimization currently stage spark important issue memory resource management GC tune spark regard recently spark community project spark tungsten spark memory management concern emerge processor addition gpu fpga recent advancement compute hardware processor emerge APU tpu etc opportunity enhance performance spark APU couple cpu gpu device incorporates cpu gpu chip cpu gpu communicate physical memory via feature memory improve performance exist discrete cpu gpu architecture cpu gpu communicate via pci bus tpu domain specific processor neural network speedup spark application migrate spark tpu platform heterogenous accelerator besides emerge processor spark compute consists diverse processor cpu gpu fpga mic illustrate spark ecosystem processor crucial upgraded spark utilize compute device simultaneously maximum performance due accelerator program model cuda gpu OpenCL fpga challenge accelerator spark rdd operation issue spark rdd allows coarse grain operation operation data RDDs whereas grain operation partial grain operation partial data rdd RDDs immutable instead modify exist rdd update operation generate rdd data redundant  storage resource rdd data partition skewed partition couple partition moreover spark task computation generally involves series pipelined RDDs skewed rdd partition easily incur chain unbalanced task worker  others fourth spark rdd across application application input data redundant task computation enable rdd approach improve performance application failure recovery contrast mapreduce fault tolerance replication checkpoint spark achieves failure recovery via lineage computation efficient data replication network disk storage lineage information input data compute function rdd partition lose data RDDs recover computation lineage information however assumption rdd lineage information available driver fail spark percent fault tolerance without overcome assumption remains issue enhance fault tolerance spark 5G network upcoming 5G suppose significantly improve bandwidth reduce latency communication network opportunity research application internet iot autonomous augment virtual reality AR VR service 5G enables application data mobile device transfer remote server directly realtime computation implies opportunity spark handle computation application situation issue security enhancement 5G data spark computation exist security mechanism spark another opportunity driven 5G establish mobile spark cluster data computation mobile device smart phone smart tablet 5G network issue communication network longer bottleneck instead electricity mobile device concern conclusion spark gain significant contribution academia simplicity generality fault tolerance performance however lack summarize classify comprehensively motif investigate related spark overview spark framework pro con spark comprehensive review status spark related literature aim improve enhance spark framework issue challenge regard spark finally summary hopefully useful resource user interested spark spark