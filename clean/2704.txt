link author text content important usage application entity recognition ner community detection however challenge ahead input text content noisy ambiguous grammatical traditional text mining fail effectively extract concept textual content temporally skewed affect semantic understand multiple facet finally knowledge bias content external database deviate meaning input text corpus overcome challenge devise neural network temporal textual framework generates subgraphs highly correlate author text content approach computes relevance author  content concept employ stack wise graph algorithm extract community related author experimental knowledge competitor multi aspect vector model achieve performance link text author addition author link task comprehensive dataset significance extract concept introduction generate subgraphs vertex important application numerous domain recommender member subgraph enrich member community detection subgraphs identify correlate user propagation network immunization policy burst contagion gossip nowadays social network commonly brief textual content author graph text author query author aim subgraph comprise highly author comprehensive formal document individual usually tend compose informal text content generate throughput rate text daily content reveal genuine similarity social network user utilize content exploit social community NP subgraph mining initiate computation similarity author stack wise graph algorithm however challenge abound challenge mismatch author content text content abbreviation misspelling error instance afternoon informally  text mining approach topic model heuristic gain textual cue author incorrect correlation challenge context temporal alignment vector representation model analyze corpus glove occurrence cbow predicts context however model ignore occurrence various facet witness observation twitter dataset occurrence probability occurrence probability demonstrates others tweet challenge ignore conceptual relevance author similarity compute textual relevance author approximate skip gram enriches content vector external knowledge wordnet relax negative noisy content however enrich content author irrelevant explore concept tweet textually concept hence approach involve textual conceptual signal conceptual relevance conceptual relevance contribution previous detects concept tweet external knowledge KB propose framework identifies concept unsupervised cluster tweet eliminate bias deviation KB furthermore concept distribution tweet aggregate author utilized important feature author similarity enrich text inference model semantic vector approach understand contextual content concept relationship text author propose model infers temporal dynamic embed procedure addition compute inner similarity capable compute correlation concept therefore model benefit nlp task ontology entity recognition stem stem model discover similarity vector correlate exploit concept improve accuracy contribution fourfold develop neural network temporal textual embed approach enrich text content vector collectively temporal dimension analyze DB scan medoids extract concept cluster text corpus graph algorithm extract subgraphs author graph propose temporal textual framework achieve effectiveness generate highly relevant text author literature framework respectively explain model conclude related briefed related comprises embed user similarity semantic understand embed embed associate document meaningful continuous vector application information retrieval IR processing nlp recommendation RS traditional lsi approach capture relevance concept singular decomposition svd bag bow disregard considers frequency expectation maximization EM equip bow model reduce ambiguity machine translation continuous bow cbow ensures meaning embeddings latent wordvec extract meaningful syntactical semantical regularity classify cbow skip gram global vector model glove consumes occurrence accomplish embed cbow model predicts surround context twitter dataset cbow model surpasses glove approach standard analogy vector representation     moreover topic model collectively generate dirichlet  embed module enriches embed knowledge graph eliminate ambiguity improve similarity however model ignore occurrence temporal model rely aspect omit semantical relation embed model employ multiple temporal facet user similarity similarity user compute contextual information similarity function cosine collaborative filter graph theoretic model classification correlate user embed model   utilize associate vector user relation nodevec deepwalk skip gram treat user node  combine content link information user predict correlation author compute user similarity approximate textual contrast user latent unlike temporal content embed model neglect factor hence multi facet cluster infer temporal textual correlation author semantic understand textual semantics various approach ner employ classification technique label entity document however ner model cannot function effectively noisy text content topic model exploit latent topic distribution however effectively retrieve statistical cue text content semantic label task model cbow  beneficial understand textual content expansion model inspire query expansion technique enrich initial textual content complementary relevant content recent neural network model cnn rnn facilitate text understand classification exploit global concept corpus semantics document hence employ cluster module besides embed procedure advantage concept content concurrently statement elucidate preliminary concept statement author link propose framework preliminary concept commence definition formalize definition node node denote distinguish author text content social network definition text message advocate text compose publish author message identity associate author stamp accordingly text content delineates text message author definition latent temporal facet associate stamp interpret multiple facet facet latent parameter definition temporal slab latent temporal dimension comprise split  split dimension split advocate individual accordingly uni facet temporal slab built via merge split definition vector representation corpus textual content  purpose embed model conveys vocabulary distinguish vector obtain conjunction vector definition author graph author graph author pertinent link link lij describes similarity author compute various approach definition query subgraph query subgraph denote contains author highly correlate input query user vectorization devise textual aware model tweet concept author vector definition extract hierarchical aware slab author message temporal latent factor aim extract uni facet temporal slab cluster split facet temporal facet hierarchically affected dimension compute contextual similarity temporal facet message author aim compute correlation author lij link lij author link author graph aim query subgraph author highly correlate query author framework overview author link compute similarity author employ stack wise graph algorithm optimize exploit subgraphs maximize intra subgraph correlation illustrates framework link author text content multi aspect temporal embed model framework framework offline microblog content acquire grid similarity temporal split dimension split dimension uni facet slab merge split construct tweet vector merge vector author content vector merge tweet vector moreover cluster tweet discover concept associate tweet concept accordingly author collectively content concept vector context compute similarity author online aim discover subgraph highly correlate author query author generate contextual vector query author update author similarity matrix finally employ effective stack wise graph algorithm extract output subgraph maximum span methodology offline phase construct multi facet dynamic slab similarity matrix textual likelihood split sunday monday dimension proceed merge textual content temporal split accordingly temporal facet assign vector text content split modify TF idf algorithm textual content temporal facet   max   SourceRight click MathML additional feature designates split split  textual content split latent facet  max  normalizes frequency split vector finally similarity cosine report correlate split dimension binary facet latent factor sparsity data complexity unlike prior temporal facet instance  dimension affected temporal dimension implement hierarchical agglomerative cluster  via linkage merge temporal split latent temporal facet temporal slab threshold  model irrelevant split cluster wrongly relevant split slab depicts similarity grid cluster dendrogram dimension threshold cluster split threshold meaningful slab report influence facet dimension similarity matrix daily slab illustrates similarity grid dendrograms obtain cluster dimension daily slab literature literature slab threshold slab threshold extract slab affected slab latent facet latent facet similarity grid daily temporal slab similarity grid daily temporal slab hourly slab hierarchical dendrograms embed model informal text content error hence challenge recent text mining approach topic model fail obtain significant statistical cue textual content author correlation microblog author compute incorrectly textual content address issue semantic vector model retrieve vector representation correctly compute semantic relevance author construct  comprise author content denote textual content author  semantic representation replace embed model singular decomposition svd skip gram cbow glove embed algorithm utilize usage occurrence vector hence embed model vector knowledge corpus therefore sample conceptually perfect excellent textually mismatch challenge embed model easily reveal similarity rate pertinent vector svd computes vector without training matrix operation occurrence matrix model vector iteratively enumerate backward propagation cbow model estimate vector surround context important skip gram calculates occurrence probability surround nevertheless model return vector hidden layer glove consumes occurrence matrix model converges optimize context vector temporal embed elucidate proximity various temporal facet however embed model ignore reality cbow algorithm pas analogy vector model hence devise novel aware embed model cbow  multi aspect temporal textual variation text content aware embed predict unforeseen observation merge knowledge slab hence devise  module slab temporal dimension depicts diagram slab  slab dimension input layer contains encode input    vocabulary denote  hidden layer  dimensional  output encode input vector hidden layer via  matrix associate hidden layer output employ compute matrix  surround  stochastic gradient descent maximizes conditional probability output hidden layer output average input vector utilize slab     SourceRight click MathML additional feature employ calculate input hidden layer node output layer  jth output matrix     apply max function  attain output layer   exp   exp  slab facet rely embed  denote embed vector hidden layer cosine function slab similarity  SourceRight click MathML additional feature vocabulary corpus denote  subset slab vector invoke attribute infer correlation intensity temporal slab  explains extend correlate temporal slab latent facet cbow cbow depth  infers correlate slab hierarchically impact temporal dimension formalizes wise similarity vector normalize accuracy analogy slab dimension   SourceRight click MathML additional feature depth similarity hidden layer vector propose static latent facet suppose facet directly impact dimension facet loop return slab factor     SourceHere   uni facet temporal slab respectively associate dimension accordingly denotes normalize accuracy analogy slab facet cosine similarity compute hidden layer vector representation layer influence similarity feature slab latent factor denote impact correspond slab latent factor generalize recursively depth leaf node null      null   otherwise SourceRight click MathML additional feature eventually correlation intensity collectively evaluate depth wise attribute cosine   SourceRight click MathML additional feature compute similarity obtain  matrix associate vocabulary similarity  vector  grid inherently dimension vector  equates dimension vector hidden layer due complexity dimension negatively affect efficiency address challenge propose collectively computes vector slab dimension compute collective vector impact vector slab  vector normalize accuracy analogy compute collective vector attribute depth unlike  slab latent facet depth  hierarchically considers latent facet  SourceRight click MathML additional feature  considers slab latent facet similarly calculates depth     null  otherwise SourceHere layer index collective vector compute depth behaves recursively collective vector   source generate tweet vector vector construct temporal embed model collective generate tweet vector summation average effective approach combine vector tweet obtain outcome tweet vector tweet vector compute merge vector comprise summation average effective aim demonstrate primary complexity effective task return concentrate aspect framework computation tweet vector future task indeed extend combine vector therefore devise competent algorithm task summation approach generates vector augments computation average vector input vector blending   SourceHere denotes text constitutes vector jth tweet vector comprise vector however text instance refer concept context differs therefore understand concept tweet correspond recognition author preference utilize popular cluster DBScan medoids DB scan detects densely grouped tweet medoids discover outlier cast DB scan algorithm nevertheless employ euclidean distance cluster  SourceRight click MathML additional feature denotes dimension vector indicates index vector nevertheless exploit cluster tweet tweet concept vector vector dissimilarity tweet concept cluster  SourceRight click MathML additional feature cluster extract cluster tweet concept vector compute  tweet vector jth cluster extract cluster model finally denotes jth entry furthermore chosen cluster model collectively feature cluster  DB scan tweet vector constitute summation average comprise vector instance sum DB specify cluster model tweet vector construct summation vector employ cluster model DB scan noteworthy tweet concept vector tend impose grid generate author vector author associate content concept vector apply summation average operator tweet vector obtain author content vector tweet tweet compose author denotes vector easy sum average vector author compute content  mim content  mim  content  content  respectively sum average author content vector operational function sum average statistical approach aim predict vector unobserved tweet deem semantically align preference author topic model document generation extend embed model tweet vector fold statistic dimension tweet content vector hence conveniently discover maximum probability assign correspond item author content vector partition bin index author vector bin contains majority tweet vector index bin probability index author vector evenly distribute bin neutral collective vector distance bin bin evenly conclude maximum compute centroid calculate average closest centroid bin neural instantiate bin report tweet demonstrates percent index zero author vector assign author content vector aggregate tweet concept vector author construct author concept vector  concept vector dimension dynamically knowledge concept cluster however content vector complexity information tweet possibly ignore DB scan misclassified  eventual author similarity impact content concept vector adjust  αij    difference dimensionality inherently feasible consolidate content concept vector author author compute similarity author distinctive correlation matrix concept content vector respectively denote   impact correspondent matrix merge maximize performance fold fold online phase online phase aim author highly correlate query author duty undertaken online phase query author extract stack wise maximum span query author duty task generate query author vector compute query author contextual similarity explain generate author vector query author author tweet author reveal conceptual alignment algorithm stack wise max span SW mst input output min remove pop append append append remove remove return avg tweet belonging generate correspond tweet vector precomputed consume model already generate offline phase usage trigger trigger frequent interval continuously rebuild slab subsequently construct vector representation useful tweet author partially affect embed tweet vector easily retrieve content vector  correspondingly distance tweet cluster centroid tweet concept vector denotes cluster approach accordingly author concept vector  compute average vector content  concept  vector query author respectively update   author similarity matrix accomplish similarity others eventually graph author graph node author denotes undirected similarity extract query author subgraph aim exploit subgraphs highly correlate author comprises query author address challenge lemma inspire lemma devise stack wise maximum span SW mst approach algorithm calculate mst highly correlate subgraphs algorithm empty stack ascend link downward correspondingly initiate empty graph span iteratively pop stack append correspond node finally maximum span algorithm extract distinctive subset graph maximal clique subsequently exploit mst clique finally exploit mst highly correlate author subgraph lemma link highly correlate author query author facilitate inner author proof fully graph contextual similarity author vector subgraph comprise maximum span average logic node highly correlate node via indirect link conduct extensive twitter dataset evaluate performance model text author link server ghz intel core cpu GB ram code available data twitter dataset english tweet australia via  twitter sample various twitter api approximately user tweet retrieve twitter finally attain geo tag tweet compose australian territory dataset contains  collocation baseline baseline compute similarity author author similarity compute similarity author vector  explain render author closeness tweet concept  embed approach obtains tweet vector combine author content vector  model regulates combine author similarity concept content vector temporal collective model computes collective vector multi facet temporal embed enriches textual content author replace finally TF idf textual similarity author cbow enrich model cbow distribute representation enrich textual content author model employ jaccard coefficient compute textual similarity document vector model computes similarity author TF idf statistic straightforward baseline exactly text content author effectiveness comparison vector model apply google analogy task effectiveness efficiency vector representation model vector representation baseline fold svd skip gram cbow glove svd limit occurrence numerical extension glove highlight training epoch analogy aim discover model text noisy content candidate aware embed syntactical semantical competitor suggests alter report accuracy analogy task twitter dataset dimension varies dataset contains cbow model  rival svd performs lack training phase conversely cbow resistant model surpasses skip gram involves context training procedure finally excessive microblog content sparse  occurrence matrix significantly reduces performance glove model performance vector model performance vector model online author link framework handle text content vector representation module underlie aware module illustrate efficiency vector due lack training procedure temporal latency svd model furthermore model training cbow skip gram closely gain efficiency glove model occurrence matrix input naturally demonstrate latency training therefore conclude cbow model performs rival parameter effectiveness efficiency comparison author subgraph mining approach link author competitor author similarity matrix baseline model establish author graph propose algorithm calculate author similarity    eventually originate graph model employ SW mst algorithm acquire author subgraphs maximum span mst benchmark author within span exceedingly correlate evaluate baseline assess similarity author exploit subgraphs obtain MSTs output SW mst comprises arbitrarily chosen author MSTs node average finally tweet author MSTs vote local australian expert vote define neither textually conceptually precision author similarity subgraph mining precision author similarity subgraph mining minor textual conceptual similarity textual conceptual similarity minor textual conceptual similarity subsequently compute average vote tweet integer tweet compute author similarity compute precision metric admit average expert vote tweet subgraphs  devise detect conceptual similarity textual relevance minor moreover  trace textual relevance however  combine module parameter adjustment gain vote textual similarity  gain approximate precision conceptually relevant author conversely  textual similarity textual similarity text content textual model temporal collective cbow document vector perform percent  detect semantic correlation author percent therefore  equip content concept component performs accurately competitor peripheral temporal embed accuracy  generate tweet vector dimension hence employ collective manner precision contrast dimension hidden layer vector embed author content vector impact parameter effectiveness author content vector cbow versus collective respectively non temporal temporal embed model tweet vector vector combine summation average tweet vector author content vector various aggregation average summation fold model benchmark expert label tweet mention previously define benchmark deploy average integer previous account vote expert compute tweet inspire propose precision equation effectiveness equation pertinent prefixed item denote  precision formulate attention conceptual textual similarity numerical coefficient null significance precision normalize sum denominator   verbalize textual conceptual similarity gain importance  metric enforces coefficient  SourceRight click MathML additional feature embed aware approach collective embed cbow summation average aggregation vector fold algorithm gain precision  aggregation tweet vector however fold approach performs  extract conceptual similarity author advantage propose model aggregation algorithm jointly precision normalize vector summation average approach precision regard author content vector summation average return average operator obtain computational complexity impact text vector cluster extract concept microblog content cluster tweet vector concept concept vector dimension increase gain effectiveness conceptual vector hence aim threshold maximize exploit cluster concept simultaneously maintain satisfy quality hence performance various cluster model cluster medoids radius DBSCAN threshold tedious consume quality cluster expert therefore cohesion separation cluster silhouette davy  index subsequently limit threshold expert evaluate quality cluster illustrates impact threshold cluster davy  index silhouette threshold medoids depict cluster indicator highlight cluster quality subsequently limited variability quality slope cluster cluster ensures cluster reasonable quality similarly impact quality cluster DBSCAN cluster varies threshold cluster consequently analyze cluster various aim threshold grows concept quality metric reduce nominate maximize standard cluster impact threshold cluster selection cluster threshold limited threshold cluster threshold vote expert benchmark threshold  DBSCAN cluster retrieve threshold tweet tweet cluster similarity TF idf subsequently expert similarity majority voting compute  threshold generate cluster precision depicts precision threshold varies DBSCAN demonstrate performance however threshold untrusted perturbation varies therefore illustrates none threshold significantly performs nevertheless medoids model gain quality maintains reasonable precision precision zeta various threshold precision various threshold impact cluster author concept vector elucidate evaluate precision author concept vector via metric   report precision variation embed cbow versus collective combination avg versus sum vector generation tweet vector cluster medoids versus DBSCAN construct author concept vector precision user content vector precision user concept vector precision user concept vector propose aware collective model outperform cbow model precision overall improvement   approximately percent medoids cluster performs DBSCAN DBSCAN model ignore outlier aware collective model performs cbow gain normalize summation vector resemble average approach correspond precision therefore overlook impact combination tweet generation vector author subgraph mining author similarity matrix denote   combine contextual author similarity matrix denote  impact effectiveness approach    precision metric effectiveness author subgraph mining decrease performance becomes faster increase explain rationale exploit concept limited dataset although   influence embed none sacrifice impact alpha concept impact ratio effectiveness impact concept impact ratio effectiveness conclusion propose novel framework text content tweet exploit subgraphs highly correlate author link author compute similarity author graph primarily aware embed model considers temporal textual evidence infer similarity rate temporal split multiple dimension monday tuesday dimension collectively computes vector representation subsequently obtain text vector author content vector combine vector similarly author concept vector author relevant text cluster DBSCAN medoids cluster discover concept tweet content fuse content conceptual author similarity calculate correlation author consequently author graph stack wise graph component framework extract maximum span establish subgraphs highly correlate author extensive microblog dataset prof superiority propose temporal textual framework text author link conclude text  hence nominate concept text cluster relevance tweet grant importance concept popularity task future