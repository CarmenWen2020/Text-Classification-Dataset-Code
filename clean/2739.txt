finite transducer efficient representation application text processing computational biology machine composition finite transducer constitutes fundamental operation application NP hardness composition computation challenge devise efficient algorithm transducer describes parallel computation finite transducer composition mapreduce framework knowledge tackle task mapreduce analyze communication model propose mapreduce respectively input alphabet mapping mapping hybrid mapping finally intensive finite transducer conduct propose efficiency data introduction finite transducer WFST application digital image processing recognition statistical machine translation cryptography recently computational biology pairwise rational kernel compute metabolic network prediction application finite transducer finite machine transition addition input augment output possibly alphabet semiring transducer define mapping uncertainty variability information transducer introduce recognition assign pronunciation rank probability classification kernel vector machine widely introduce theory rational kernel computation rational kernel efficiently algorithm composition transducer compute composition WFSTs basically standard composition unweighted finite transducer input WFSTs output compose WFST realize composition input WFSTs input alphabet coincides output alphabet complexity compute operation input WFSTs WFST exponential bound complexity issue composition computation devise efficient tackle composition WFSTs mapreduce framework introduce google parallel program model mapreduce instruction multiple data simd architecture easily implement hadoop apache framework analyze model optimization approach introduce model communication amount data transmit mapreduce computation replication rate generate mapper function input mapreduce algorithm various recently implement efficiently intersection minimization operation finite automaton mapreduce knowledge approach compute composition WFSTs mapreduce propose perform operation respectively mapping input alphabet mapping hybrid input output alphabet mapping remainder structure mapreduce framework  technical definition composition WFSTs mapreduce reminder fundamental mapreduce framework model analysis composition operation mapreduce model discussion analysis mapreduce compute composition WFSTs comparative extensive conduct efficiency conclusion concludes preliminary introduce briefly notion finite transducer detail formal aspect finite automaton theory particularly recommend reading french  semiring commutative monoid identity monoid identity distributes  semiring lack negation familiar  boolean semiring tropical semiring  semiring finite transducer alphabet WFST sometimes transducer transducer endow semiring transition label WFST empty restrict transition label formally WFST tuple finite input alphabet transducer finite output alphabet finite initial finite transition initial function function mapping denote transition transition denote origin destination consecutive transition extend function extend define semiring constituent transition denote input label output label definition extend subset WFST regulate output associate input output define composition finite transducer composition fundamental operation complex transducer simpler commutative semiring WFSTs input alphabet coincides output alphabet assume infinite sum define composition WFST denote define exists efficient composition algorithm WFSTs composition WFSTs identify initial initial specifies derive transition appropriate transition transition complexity composition quadratic detailed presentation algorithm illustrates WFSTs composition transducer transducer tropical semiring composition image composition WFSTs complexity composition propose efficient parallel compute composition WFSTs mapreduce framework mapreduce framework data heterogeneous collection datasets traditional data processing nowadays datasets mostly social network scientific application overcome computational storage data challenge various successfully propose popular approach hadoop mapreduce framework focus distribute compute program hadoop mapreduce model hadoop framework mapreduce program model briefly data   parallel mapreduce approach hadoop framework apache hadoop popular source framework cluster environment allows reliable scalable distribute storage processing datasets program model manages computer cluster built machine offering local computation storage failure node cluster automatically manage assign task another node overview apache hadoop http medium com image project apache hadoop fundamental module hadoop hadoop core hdfs yarn hadoop mapreduce  component hadoop hadoop core essential service abstraction underlie operating file contains java library script hadoop hadoop package source code documentation contribution project hadoop community hadoop distribute file hdfs distribute file developed apache hadoop ensures throughput storage access application data community machine aggregate bandwidth across cluster fault tolerance native data hadoop another resource negotiator yarn platform manage cluster resource schedule task hadoop version increase capability limit node hadoop inability perform grain resource multiple computation framework hadoop mapreduce implementation mapreduce program model yarn parallel processing data mapreduce program model mapreduce program model propose google parallel processing data easy express variety mapreduce computation flexible simplifies data processing mapreduce program model information   computational model principal shuffle reduce  principal mapreduce image model   input file mapper operates function define user output finite multi   determines hash function allows machine input easy parallel shuffle occurs automatically hadoop manage exchange intermediate data task reduce task phase sort phase intermediate buffer mapper assist reducer reduce task sort input data previous merge phase intermediate input    partitioner phase determines reducer    hash function associate reducer reducer sort    execute simultaneously operating reduce intermediate reducer emits zero multiple output input    composition WFSTs mapreduce perform WFSTs composition mapreduce framework communication model analyze replication rate combine WFSTs generic mapreduce algorithm composition WFSTs approach perform composition WFSTs mapreduce furthermore define detail respectively reduce function preprocessing phase algorithm text file transition WFSTs transition WFST tuple index function initial initial  WFST index composition transition function input input transition replicate associate generate mapping algorithm intermediate output replication rate factor mapreduce algorithm output function fed shuffle recall shuffle occurs automatically implementation reduce function performs composition transition shuffle transition WFST input WFST coincides output previous WFST moreover reduce function transition WFST index algorithm compute cartesian algorithm discus communication propose algorithm accord model communication model communication model introduce powerful model analyze optimize performance distribute compute environment explicitly inherent communication parallelism apply model mapreduce framework relevant algorithm analyze reducer communication mapreduce computation parameter involve mapreduce algorithm reducer denote   associate reducer global sum computation reducer processing associate parameter amount communication reduce communication denote define average mapper input formally suppose reducer input assign ùëñth reducer input replication rate expression limit reducer enables parallelism reducer redefine notion reducer parallelism available node bound replication rate replication rate intend model communication amount information mapper reducer reducer replication rate express function task mapreduce algorithm function bound replication rate derive tight upper bound namely output reducer WFSTs composition deterministic WFSTs transition input alphabet composition compute transition reducer transition WFST WFST transition assume reducer receives transition WFST evenly distribute input alphabet coincides output alphabet lemma upper bound output reducer lemma compute composition reducer output compute bound replication rate composition WFSTs function expression denote input denote output input sum transition input WFSTs output consequently bound replication rate composition WFSTs proposition replication rate composition description mapping suitable format transition reducer explicitly define function  algorithm formal analysis communication compute upper bound replication rate mapping recall composition WFSTs mapping transition WFST function generates  hash function consequently mapper explanation suppose reducer transition reducer function affected presence inside reducer transition cannot combine upper bound output reducer formally proposition upper bound replication rate proposition replication rate mapping scheme proposition upper bound replication rate exceeds bound factor consequence mapping scheme suitable input alphabet input alphabet mapping transition mapped input alphabet define  associate input hash function associate transition WFST  exists available reducer transition reducer task transition WFST transition associate input transition reducer approximate however function influence presence incompatible output input combination inside reducer upper bound output reducer formally proposition replication rate input alphabet mapping scheme proposition upper bound replication rate overtake theoretical bound factor therefore input alphabet mapping situation WFSTs hybrid mapping input output alphabet propose hybrid mapping input output alphabet associate input output formally transition WFST     input hash function  output hash function transition mapped accord output accord input consequently reducer however function transition reducer proposition proposition replication rate hybrid mapping strictly replication rate input mapping proposition deduce upper bound replication rate hybrid mapping closest theoretical bound situation alphabet discussion extensive evaluate efficiency effectiveness propose communication execution compute composition WFSTs conduct variety WFST data randomly generate  library various combination attribute input alphabet output alphabet cluster configuration hadoop french scientific testbed grid site lille cluster node CPUs core node machine equip intel xeon core processor GB memory disk hdd GB machine gbps ethernet network debian hadoop version instal machine data generation randomly generate variety WFST data phase generate deterministic finite automaton  library source project symbolic manipulation automaton  enumeration generation deterministic finite automaton phase implement function randomly nondeterministic output transition finite automaton phase uniform distribution generation technique WFSTs parameter input alphabet define transition density generate WFST ratio density ratio unique initial communication analysis evaluate communication propose WFST data communication define transfer phase reduce phase optimize minimize replication rate parameter input reducer relationship data communication input  GB output file hybrid  alphabet  mapping GB obtain clearly communication hybrid mapping minimal situation combination alphabet due transition reducer formally proposition WFSTs alphabet mapping communication coincides proposition computation analysis computation execute mapreduce graph comparative execution mapping input alphabet mapping input hybrid mapping  execution alphabet image execution alphabet image execution alphabet image execution alphabet image execution propose data alphabet growth rate hybrid input alphabet mapping mapping growth rate  input respectively comparison alphabet foreseen hybrid clearly efficient alphabet execution transition minimize replication rate decrease mapper replicate transition avoid existence transition cannot combine inside reducer reduces transition assign reducer adequate reducer diminishes reducer spends cpu conclusion parallel approach compute composition WFSTs mapreduce framework described detail task mapreduce moreover analyze communication computation finally evaluate performance data obtain execution minimizes reducer optimizes input replication rate perspective apply target application distribute cryptosystem finite automaton finite automaton public cryptosystem application public composition finite automaton private weak inverse finite automaton target application processing handle task translation multiple intermediate recognition extend multi node cluster environment gpu openmp accelerate composition algorithm compute