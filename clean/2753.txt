label important data quality issue negatively impact machine algorithm label increase instance effective predictive model increase model complexity decrease model interpretability addition label classification learner detect label unsupervised learner namely principal component analysis pca independent component analysis ICA autoencoders evaluate learner credit fraud dataset multiple traditional tomek link filter binary classification approach considers label instance anomaly uniquely reconstruction error noisy data identify filter label detect noisy instance discover autoencoder algorithm performer recall tomek link perform recall introduction classification involves predict sample model derive training data comprehensive accurate collection data essential supervise classification algorithm label dataset sample instance associate label label corresponds sample label exists majority negative label wrongly assign positive instance innocent wrongly tag crime suspect machine algorithm model datasets label generalize data sometimes data sample attribute incorrect corrupt feature attribute label potentially harmful feature dataset usually feature feature training purpose however dataset typically label label significant classification performance issue label stem inadequate information expert inaccurate label label limited specificity classification decrease accuracy classification thirdly label consequence unreliable quality information alleviate issue various manual automate service assist classification amazon mechanical turk popular inexpensive user friendly label service label data encode network connectivity database encode error data error amount unavoidable label unfortunately necessitates inclusion additional feature increase training data compensate inherent label concept label data likely anomaly correspond label otherwise feature define binary instance assign belong due label contribution involves novel approach treat reconstruction error mapping technique detect label error difference error mse input vector reconstruct output machine model minimize reconstruction error unsupervised algorithm principal component analysis pca independent component analysis ICA autoencoders previously researcher detect anomaly datasets unsupervised tomek link traditional label filter technique remove data capable impair classification performance autoencoder model metric receiver operating characteristic curve auc recall false negative rate FNR tomek link algorithm performer metric generally algorithm yield yield remainder organize related overview literature related label detection background relevant information algorithm pca ICA autoencoders tomek link methodology describes training unsupervised learner metric discussion discus empirical conclusion concludes summary along suggestion related future related technique address label approach filter noisy instance data develops robust label model filter approach noisy instance remove relabeled cleaner dataset earlier filter edit ENN wilson algorithm remove instance training majority nns edit instance classification later extension ENN approach apply execution instance misclassified remove another related introduce iterative partition filter approach eliminates noisy instance multiple iteration criterion met iterative cease consecutive iteration noisy iteration proportion training dataset iteration split training dataset subset creation decision model subset voting strategy consensus majority voting identify noisy instance  perform recent introduce iterative filter fusion classifier technique eliminates noisy instance multiple iteration filter paradigm ensemble filter iterative filter metric filter iteration eliminates exist iteration reduce subsequent adopts filter approach however focus unsupervised ideal raw data regard development robust aim render mislabeled instance destructive model strategy robust loss function prevent overfitting implement training classifier responsive noisy data addition label detection explore ensemble suitable comparatively approach explicitly label various robust optimization primarily supervise approach zhang tan reconstruction error minimization framework filter relabel mislabeled data mnist dataset propose significantly reduce false positive outlier detection rate improve data cleaning classification quality author unsupervised approach however dataset image background pca machine pca exploratory data analysis reveals inner structure data explains variance compact feature technique identifies correlate variable transformation reflect difference input application pca principal component amount variance capture principal component majority variance data data mapped reduce dimensional principal component pca typically dimension reduction however label detection apply subspace subspace principal normal anomalous data variation data instance dataset define normal anomalous subspace concept subspace anomaly detection anomalous shift feature correlation vector function increment projection data anomalous subspace magnitude normal instance magnitude projection instance anomalous subspace examine principal component normal subspace matrix    matrix linear projection normal subspace linear projection anomalous subspace abnormal variation anomaly prediction error spe monitor spe compute  instance spe threshold instance identify anomalous detect anomaly instance label input analyze anomaly anomaly detection algorithm combine normalize reconstruction error computes projection eigenvectors normalize error anomaly presuppose error anomalous instance intuitive assumption ICA autoencoder algorithm ICA ICA statistical technique analyze hidden factor source feature collection measurement algorithm source accord distribution data achieve separation mixed data independent component ICA exploit independence source technique useful anomaly formally ICA model input vector random vector latent mutually independent source ICA model described  ICA involves calculation matrix presume fix unknown matrix  ICA obtains member vector statistically independent non gaussian random variable ideally however differs due outlier mixed ICA define transformation component derive mixture independent optimize decrease objective function kurtosis entropy etc autoencoder neural network concept autoencoders popular decade typical application reduction dimensionality feature recently autoencoder concept generative data model identify data anomaly autoencoder artificial neural network unsupervised fashion data representation simplest autoencoder comparable multilayer perceptron mlp input layer output layer hidden layer output layer node neuron input layer recreate input autoencoder linear non linear activation function purpose autoencoder representation encode disregard signal algorithm attempt minimize difference input output instead predict target input reconstruct along reduction autoencoder attempt representation input reduce encode hidden layer determines latent representation consists component encoder input code decoder code input autoencoder reconstructs normal data efficiently training whereas struggle anomalous data encounter training dimensional data anomaly non linear autoencoders superior classification performance non linear autoencoders detect label dataset autoencoder data learns normal behavior data architecture autoencoder adjust minimize reconstruction error instance training dataset described research inject various portion dataset label subset instance another reconstruct data described  matrix bias encoder decoder tanh activation function loss function reconstruction error described  pca autoencoder pca model algorithm available algorithm involves estimation minimize reconstruction error subsection linear layer autoencoder pca minimize reconstruction error simplicity  depiction linear layer autoencoder layer autoencoder pca image diagram encode identical transformation principal component PCs likewise decode reconstruction data principal autoencoder pca model calculate minimization reconstruction error suppose dataset feature encode layer pca denotes PCs chosen autoencoder pca dimension reduction occurs representative model exists indicates reconstruction error virtually zero encode layer autoencoder compute node denote  encode node dimensional vector equivalent eigenvector pca encode layer output autoencoder activation function linear input matrix linear equivalent principal pca autoencoder pca reconstruction decode layer input data decoder data reconstruct encoding activation function linear similarly pca data reconstruct  tomek link incorporate tomek link traditional label detection technique tomek link algorithm label filter denote instance tomek link data distance metric exists hence tomek link borderline eliminate training data elaborate binary classification environment tomek link instance across dataset valuable define boundary  alignment tomek link boundary important tomek link label detection involve calculation reconstruction error tomek link image methodology development model credit fraud dataset analyze research partnership      dataset contains instance label credit purchase european cardholder september fraud dataset highly imbalanced imbalance exists within dataset majority minority ratio independent variable fraud dataset principal component obtain pca label fraud otherwise training purpose dataset split normal fraud sub datasets subsequently model sub datasets introduce label instance dataset imbalanced ratio noisy instance normal sub dataset imbalanced label fraud label normal sub dataset ratio sub dataset approach entail fold validation CV model fold remain fold ensure data classification specifically stratify CV attempt ensure approximately equally across fold assign fold training fold building evaluate model unsupervised learner dataset reduce bias due random generate sample performance average primary focus detect fraudulent instance mislabeled normal instance minority instance mislabeled majority swap label specific instance instance minority instance majority noisy training specify NL NL formula actual noisy   instance minority  corresponds noisy instance inject negative NL corresponds relatively noisy instance inject positive NL noisy calculate pca configuration principal component feature dataset inverse transform function scikit recreate transaction component ICA algorithm implement sklearn decomposition FastICA function scikit FastICA algorithm efficient popular variant ICA performance preliminary experimentation algorithm parallel mode max iteration additionally component input vector dimension autoencoder implement kera tensorflow backend preliminary experimentation parameter model densely hidden layer along tanh activation function regularization input output layer dimension feature dataset identify error threshold learner  normal anomalous behavior examine distribution reconstruction error chose nth percentile error distribution normal dataset error normal dataset hence data fed specific learner generates error classify anomalous analysis outcome achieve threshold metric confusion matrix binary classification usually minority majority positive negative respectively related performance metric explain positive TP positive sample correctly identify positive negative TN negative sample correctly identify negative false positive FP error negative instance incorrectly identify positive false negative FN II error positive instance incorrectly identify negative confusion matrix fundamental metric performance metric derive recall positive rate tpr sensitivity TP TP FN specificity negative rate TNR TN TN FP false positive rate fpr FP TN FP rate FNR FN TP FN auc graphically recall versus specificity tpr fpr across classifier decision threshold curve auc obtain perfect classifier performance metric recall FNR auc strategy allows understand challenge evaluate machine algorithm highly imbalanced data discussion reconstruction error mislabeled instance histogram error distribution noisy data corresponds noisy instance graph plot instance reconstruction error tomek link exclude algorithm rely reconstruction error calculation label detection distribution reconstruction error noisy instance instance autoencoder instance reconstruction error data image autoencoder instance reconstruction error noisy data image ICA instance reconstruction error data image ICA instance reconstruction error noisy data image pca instance reconstruction error data image pca instance reconstruction error noisy data image performance label detection average repetition per fold validation performance within algorithm italic label detection noisy instance algorithm metric autoencoder overall auc recall obtain autoencoder FNR obtain model  tomek link algorithm performer algorithm per metric yield yield autoencoder model obtain recall noisy instance recall noisy instance occurs algorithm become efficient detect noisy instance increase machine algorithm task detect target extremely instance comparable needle haystack norm recall tomek link associate instance statistical beneficial understand significance performance hence conduct analysis variance anova impact algorithm performance recall FNR auc anova statistical significant difference confidence anova freedom sum sum sum statistic factor anova recall factor anova FNR factor anova auc algorithm factor concern factor anova indicates algorithm significant factor metric therefore perform tukey honestly significant difference HSD significantly assign via tukey similarity significant difference performance within factor metric grade report corroborate earlier finding autoencoders tomek link perform tukey HSD essence autoencoder model efficiently detect label imbalanced data model successfully detect label imbalanced data non linear autoencoders capable model complex function compress data dimension detect label data important due unique challenge data challenge arise volume variety velocity variability complexity data computational training encoder relatively autoencoder addition comparatively recall auc comparatively FNR  robust autoencoder model conclusion propose novel effective label considers label anomalous instance mislabeled unsupervised learner autoencoders ICA pca data model reconstruct unseen portion data label reconstruction error instance incongruent assign detection rate label obtain autoencoders performance wise unsupervised learner tomek link discover traditional algorithm performer propose model potential detect label imbalanced data rate performance non linear autoencoder due computational involve training algorithm ability successfully model complex function dimension reduction future additional performance metric datasets application domain abbreviation anova analysis variance auc receiver operating characteristic curve CV validation ENN edit FN false negative FNR false negative rate FP false positive fpr false positive rate HSD honestly significant difference ICA independent component analysis NN mlp multilayer perceptron mse error NL NSF national foundation PC principal component pca principal component analysis spe prediction error TN negative TNR negative rate TP positive tpr positive rate    