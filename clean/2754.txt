processing nlp  application survey data augmentation training strategy aid development motif data augmentation summarize strengthen local decision boundary brute training causality counterfactual distinction meaning motif concrete augmentation framework developed text data generally struggle measurement generalization characterization overfitting highlight augmentation construct generalization nlp stage apply data augmentation computer vision highlight difference promising nlp sake practical implementation facilitate data augmentation consistency regularization controller offline online augmentation pipeline preview finally discus topic around data augmentation nlp task specific augmentation prior knowledge supervise versus data augmentation intersection transfer multi task AI  AI generate algorithm inspires research text data augmentation introduction nearly stem supervise supervise describes loss function align prediction manually annotate truth achieve remarkable performance combination strategy label datasets annotate datasets application covid rapid response construct covid QA supervise dataset article annotate span author fitting annotation without overfitting extremely challenge addition processing nlp researcher explore application abstractive summarization model output novel summary collection input document dataset  summary machine employ undergraduate refine data bootstrapped  platform anecdote highlight difficulty curating annotate data knowledge intensive nlp task research community currently explore without label data addition data augmentation supervise transfer perform zero shot category research gain survey explore performance supervise data available data augmentation survey additionally explores data augmentation advance strategy outside supervise supervise unlabeled datasets transfer domain data label unlabeled data augmentation describes algorithm construct synthetic data available dataset synthetic data typically contains data model prediction invariant synthetic data combination infer otherwise data augmentation useful interface influence training neural network largely due interpretable transformation model fail prevent overfitting data augmentation without augmentation regularization generally neural network prone spurious correlation memorize frequency detect nlp frequency numeric token embeddings memorization generalize data augmentation aid overfitting shuffle overcome noisy data model resort abstraction information likely generalize data augmentation regularization strategy regularization technique developed dropout penalty technique apply functional regularization intermediate activation network constraint functional technique lack express  concept semantic invariance data augmentation enables intuitive interface demonstrate label preserve transformation survey strategy apply data augmentation text data cluster augmentation symbolic neural symbolic discrete data structure synthetic augmentation graph structure augmentation feature augmentation mixup neural augmentation neural network task augment data neural augmentation survey translation generative data augmentation style augmentation addition symbolic neural augmentation highlight distinction augmentation task specific versus task agnostic augmentation versus meaning augmentation distinction throughout survey generalization core challenge extrapolate instance available interface training data useful simulate potential distribution shift simulate distribution shift apply augmentation dataset random token email spam detector increase prevalence token frequency distribution simulated shift linguistic phenomenon involves deeper chain training ability prediction counterfactual evidence generative data augmentation improve simulate semantic distribution shift promising direction advance generalization survey text data augmentation survey image data augmentation computer vision describes apply transformation rotate image horizontally flip increase brightness augment currently easy apply label preserve transformation computer vision nlp additionally easy stack augmentation computer vision enable diversity augment contributor data augmentation research thoroughly explore computer vision nlp image remain text data domain finally discus intersection visual supervision understand vision model overcome discus detail motif data augmentation practical implementation decision text data augmentation consistency regularization loss influence impact augment data differently consistency regularization contrastive additionally negative structure loss function strength sample augmentation augmentation controller apply meta abstraction hyperparameters augmentation selection magnitude transformation commonly explore adversarial controller aim mistake model controller performance improvement  population augmentation  although concept discus distinction augmentation controller curriculum another important consideration implement data augmentation cpu gpu transfer preprocessing pipeline conceptual understand offline versus online augmentation finally application augmentation alleviate issue imbalance discussion opportunity explore text data augmentation task specific augmentation nlp task inference particularly respect input categorization knowledge intensive task quickly  supervise transfer emerge limited label data discus data augmentation supervise recent transfer multi task finally discus AI  AI generate algorithm encompass poet generative network synthetic petri dish algorithm environment differs augmentation controller curriculum acquisition artificial data opportunity nlp data augmentation nlp prevents overfitting easy inject prior knowledge generalization ability model survey organize motif data augmentation augmentation strive achieve text data augmentation summarize symbolic augmentation graph structure decomposition neural augmentation auxiliary neural network sample data available augmentation dive deeper generalization data augmentation comparison image versus text augmentation return text data augmentation practical consideration implementation finally research discussion conclusion briefly summarizes motivation finding survey background data augmentation heavily machine advancement prior knowledge encode augmentation distinction previous discus depth later survey data augmentation computer vision fuel label preserve transformation image rotate translate axis increase intensity channel easy brainstorm semantically preserve augmentation image whereas harder text domain survey text data augmentation respect recently recent advance generative model  image GPT text  unify text image  summarize prompt adapt model downstream task detail later advance generative model datasets model particularly become label datasets solely sake evaluation representation survey similarity publish roughly around survey seek definition data augmentation aim highlight motif additionally survey narrate development nlp augmentation around augmentation computer vision transfer deeper enumeration task specific augmentation survey survey important concept debate meaning versus counterfactual prompt generative data augmentation stem access label datasets imagenet however construct datasets challenge consume therefore researcher alternative leverage data without manual annotation motivation supervise model GPT bert data augmentation motivation overcome challenge limited label data avoid manually label data survey highlight algorithm sub label data transfer effective challenge limited label datasets transfer reference initialization model previous task previous task usually benefit data data label imagenet unlabeled supervise model research around procedure transfer discussion discus opportunity data augmentation freeze feature extractor training augment datasets supervise describes algorithm unlabeled data supervise algorithmically label data popular supervise task generation contrastive pretext task generation describes model token algorithmically masked masked token label supervise contrastive aligns representation data algorithmically usually augmentation distance representation negative usually sample mini batch pretext task apply augmentation data task model predict transformation augmentation interface task construction supervise motif text data augmentation introduce unify objective augmentation survey address introduce motif text data augmentation strengthen decision boundary brute training causality counterfactual distinction meaning versus concept dig understand data augmentation application processing strengthen decision boundary data augmentation commonly apply classification boundary label assignment augment typically slightly exist sample training respective boundary define boundary robust classifier uncertainty estimate boundary report dimensional visualization derive sne UMAP motif data augmentation perturb data model familiar local around expand radius dataset overall model decision boundary  interpolation reference data nlp delete synonym swap paraphrase model becomes robust local decision boundary available label simply increase exposure brute training neural network highly parametric model variance easily model training data fitting training data surprisingly robust interpolation within data struggle unpack generalization data augmentation extrapolate outside data training potential brute data training data upper bound computer simply enumerate candidate brute rely compute  complexity entail training exhaustive sequence potential distribution sample training data extreme training brute training exhaustive coverage manifold reasonable identify although challenge probe define causality counterfactual vital achieve goal causal representation oppose solely correlation causal inference demonstrates intervention establish causality reinforcement research agent deliberately sample intervention environment survey intervention integrate observational data subset reinforcement offline text data augmentation described throughout survey utilize terminology counterfactual counterfactual augmentation introduction negation numeric alteration flip label construction counterfactuals generally relies expertise algorithmic construction although model deliberately sample intervention akin randomize trial establish causal link semantic concept label intervention groundwork formal causal data augmentation entail structure causal model procedure abduction action prediction generate counterfactual rely  alignment sequence neural machine translation sample counterfactual replacement counterfactual augmentation improves baseline english french translation accord bleu metric  alignment extend sequence sequence abstractive summarization dialogue explicit counterfactual structure review prompt automate counterfactual sample dino generates inference data generation completely topic research direction rigorous causal model compute conditional probability context remove variable benefit prompt model meaning versus processing distinction meaning bender  introduce argument particularly salient anecdote illustrate  strand communicate underwater cable underwater cable intercept intelligent  learns mimic  substitute turing however strand islander encounter seek advice  unable  communication underlie meaning describes augmentation aid concept strengthen decision boundary synonym swap rotate syntactic  strengthen understand generally organize respect achieve understand meaning model define  concept embodiment typically refers modality vision audio model however refer abstract concept construct solely embodiment reference agent environment although bender  propose meaning cannot alone highlight model task assertion multiple embed task meaning another useful meaning versus recently developed benchmark processing distinction glue  task predominantly understand knowledge intensive task  probe meaning survey generally understand meaning passing drilling definition promising pursuit processing research text data augmentation described data augmentation strategy prevent overfitting via regularization regularization enable intuitive interface task dataset prior additional data improve discover characteristic dataset fails symmetric consistency comparison augmentation describes mechanism currently available inject prior datasets symbolic augmentation categorize augmentation symbolic augmentation contrast neural augmentation earlier difference auxiliary neural network statistical model generate data symbolic augment data benefit symbolic augmentation interpretability designer symbolic augmentation transformation replace augment however information application rely longer input summarization symbolic limited apply global transformation augment entire augmentation augmentation construct augment entail program augmentation symbolic template insert exist data easy data augmentation augmentation highlight performance improvement eda subset label benefit easy data augmentation relatively easy shelf augmentation mention later survey research phase adoption easy data augmentation random swap random deletion random insertion random synonym replacement eda apply text classification datasets takeaway performance difference data gain pronounce label training image easy data augmentation transformation image opportunity augmentation firstly random swap classification incredibly useful data augmentation perspective introduce semantic invariance jogging  token vocabulary structure improvement program augmentation encompass adversarial attack developed nlp adversarial attack equivalent augmentation solely intention construction attack   computes importance output delete  selects significantly output synonym replacement symbolic program organize construction augment another strategy available regular expression augmentation regular expression filter data scrap internet data source clinical regular expression text usually data generate extension align graph structure grammar adjective extend adjective another strategy  grammar adjective adjective propose augmentation syntactic heuristic inversion swap  hypothesis premise hypothesis nli inference translate passive version inversion lawyer actor actor lawyer  collection contains  collection  author improvement apply augmentation  challenge nli graph structure augmentation opportunity text data augmentation construct graph structure representation text data relation entity encoding knowledge graph grammatical structure syntax metadata data citation network augmentation explicit structural information relatively integration architecture addition structure aid label preserve transformation representation analysis prior knowledge dataset application analysis graph structure augmentation unpack difference structure versus unstructured representation operates convert dimensional sometimes sparse data dimensional continuous vector embed vector correspond metric cosine similarity distance function core distinction topological distance define topological mathematical constraint euclidean metric topological encode information challenge integrate architecture entirely architecture leverage structure data data augmentation interface utilized structure processing knowledge graph knowledge graph compose entity relation entity tuple relation motivation augmentation scheme along graph information entity relation challenge without structure scope augmentation synonym swap strategy implement synonym swap knowledge graph equivalent relationship synonym practical manually define synonym entry thanks rapid acceleration automate knowledge graph construction unlabeled data knowledge graph grain relation previously mention random synonym replacement benefit enormously perspective preserve label swap improve swap transition jogging  structure graph useful achieve augmentation capability graph heavily developed notable wordnet penn treebank imagenet label structure graph wordnet relationship another synset graph node wordnet node tiger genius wordnet simplification wordnet node synset relationship synset loosely define belonging semantic category tiger synset relation node lion  tiger finer grain synset relation node tiger wordnet graph structure augmentation synonym replacement wordnet describes graph node related another graph synset additionally graph finer grain classification graph frequently refer knowledge graph cov KGE contains relate biomedical concept node drug potential binding target another construct knowledge graph context input abstractive summarization graph enables semantic swap preserve global consistency another heavily structure text data syntactic parse syntactic parse describes task structural analysis text construction syntax dependency recently   demonstrate supervise syntactic parse benefit pre tune pipeline model structure text data augmentation integrate metadata via structural information scientific literature mining become popular application nlp application benefit underlie citation network characterize addition text content particularly network structure played enormous role biology medicine graph application domain genomics therapeutic healthcare integration structure text data component text representation theme survey auxiliary graph benefit augmentation data augmentation explicitly graph structure data stage propose augmentation technique expose GNNs likely nonexistent limit exposure unlikely existent graph augmentation average accuracy improvement across popular node classification datasets demonstrate effectiveness adversarially node feature augmentation graph classification practical consideration implementation consistency regularization contrastive enforce augment data training building graph structure assign assignment regularize embeddings neural structure describes construct graph instance grain label penalize misclassification golden  elephant truth label   similarly construct embed graph enforce consistency prediction weakly augment data mixup augmentation mixup augmentation describes mesh exist sometimes blending label mixup text sequence concatenate another sequence dataset mixup interface available illuminate interpolation implementation mixup respect layer sample interpolate mixup difference  technique combine exist sample average embed vector input layer  approach combine exist sample average embeddings sequence siamese encoders significant improvement reduce overfitting regularization dropout mixup mixup outline highlight augmentation occurs processing pipeline image feature augmentation feature augmentation describes augment data intermediate representation neural network nearly neural network sequential processing structure input data progressively transform distribute representation eventually task specific prediction feature augmentation isolate intermediate feature apply data instance sample standard uniform gaussian distribution adversarial controller  strategy feature augmentation strategy along boundary feature interpolation direction exist embeddings decision boundary classification extrapolation describes exist along angle currently vector boundary gaussian entail gaussian feature difference transform exist sample directional distance calculate described motif data augmentation  aim strengthen decision boundary research supervise contrastive replace commonly KL divergence logits label contrastive loss NCE positive negative label improve boundary useful explore benefit  algorithm differentiable data augmentation technique umbrella feature augmentation data augmentation function augment layer network treat network augmentation module backpropagate gradient augmentation function input transformation dramatic akin optimize input technique facilitate supervise pretext task direction feature augmentation explore  image neural augmentation augmentation rely auxiliary neural network generate training data entail model supervise neural machine translation datasets translate another sample instance model generative model replace masked token data additionally discus neural style transfer nlp translate style another semantic characteristic formal casual translation augmentation translation describes translate text another translation imdb movie review english translate french chinese  enormous machine translation curation label datasets parallel text datasets translation program style detail style augmentation translation leverage semantic invariance encode supervise translation datasets semantic invariance sake augmentation interestingly translation unsupervised translation model enforce consistency translation translation heavily machine translation model  data limited translation data outside translation structure domain pairing scientific news article college reading weigh importance performance machine translation model translation however lesson translation quality pseudo parallel data necessarily translation model quality diverse data yield instead curation domain impact performance explore translation augmentation discus curating input data regime encourage representation bias domain distribution style augmentation finally another augmentation strategy utilize network augment data training net previous survey image data augmentation explore neural style transfer augmentation artistic style transfer  theme image useful  augmentation negative data augmentation framework later however interested style within dataset strategy prevent overfitting frequency feature blurring focus meaning text data domain transfer style author another application abstractive summarization context extractive data augmentation deployed focus model semantics emerge author style  optimistic versus pessimistic writer style transfer extract semantic similarity style model context document information retrieval generative data augmentation generative data augmentation emerge generate photorealistic facial image indistinguishable text passage model useful transfer remains killer application generative task generation certainly artistic application importantly representation data augmentation core distinction generative model data augmentation popular pre model shelf optionally tune model task standard operating procedure transfer however tune usually supervise task additional model pre model massive datasets publicly available pile pile 0GB text data span wikipedia comment forum entire data model datasets impressive additional benefit likely achieve domain tune additional model limited dataset model useful pre training stage data model downstream task whereas surround context easily accounting construct model dataset difference prime data augmentation argument model downstream performance dramatically improve pre training relevant dataset distinction relevant dataset contrast reference model GPT popular strategy training model generative data augmentation conditional bert bert bert augments data replace masked token instance novelty embed label input preserve semantic label replace masked token target label preserve data augmentation bert training strategy tune model pre another dataset random initialization emerge strategy adapt pre generative model downstream task purpose interface mask token prompt output model text template sake generate label data efficacy prompt respect objective limited data  rush prompt worth data  classification task comparison heavily paradigm transfer tune variant implement prompt context exploit training prompt tune implementation prompt context context become demonstrate GPT prepend input fix task description collection task gradient update model crucial reporting significant performance parameter technique likely ceiling development transformer model sequence longer token input excitement retrieval augment model context model demonstration task however due limitation gradient update practically useful implementation prompt prompt tune prompt tune describes embed prompt continuous optimize embed gradient descent network frozen similarly GPT improves performance prompt tune prompt tune significantly outperforms context report performance improve ensembling optimize prompt inference batch input append prompt tune prompt ensembling improves average performance prompt  perform individual prompt author highlight analysis optimize prompt embed aid task complexity similarity metric meta prompt tune underlie concept prepending context input downstream task facilitate tune however technique research transfer minimal modification adapter layer aim introduce parameter tune pre transformer emerge theme pre tune paradigm domain task alignment tends improve tune performance demonstrate effectiveness data domain alignment demonstrate effectiveness task alignment propose  algorithm correspondence lesson alignment tune model prompt manually annotate across exist datasets task auc roc plot author tune prompt specialization improves model benefit author organization nlp datasets unified format aid tune model prompt exploit training pet pre model label task specific unlabeled data manually define template convert supervise task model task output model mapped supervise label  gradient descent optimization apply verbalize output tune entropy loss function classifier   demonstrate pet technique enables model surpass GPT label  developed algorithm   utilizes dense supervision label task apply loss entire vocabulary distribution without  additional model predict masked token context label similarly conditional bert  outperforms pet without task specific unlabeled data limitation exploit training context prompt tune retain model downstream task application interested compress model sake efficiency scope label augmentation knowledge distillation compression generate data model approach exploit training pre model label data instead generate entire inspiration mixup detail mixup augmentation developed  input  task specification defines task text movie review label sentiment akin mixup input task formulate text text label label mat negative input template generate generate label generate probability token generate  achieves massive performance improvement augmentation easy data augmentation  subsetting available data extreme   explore strategy generate data model  instruction dino dino task description dataset generate pairwise classification datasets interestingly contrast task description entail label decode model generation task description completely topic generation account token another label description generate evaluate sts text similarity dataset representation dino improvement embed technique supervise universal encoders siamese bert RoBERTa model built underlie concept discrete versus continuous prompt diverge heavily another discrete prompt benefit interpretability task description annotator insight model however prompt optimization continuous embed fully automates continuous prompt optimization likely susceptible overfitting due freedom optimization another somewhat theme prompt nlp augment knowledge enhance text generation retrieval popular model retrieval augment generation rag retrieval augment model pre training realm retrieve information prepend input reduces  text generation retrieve information embed continuous representation model optimization prompt tune another intersection data privacy generative data augmentation data parameter model instead centralize database federate global model local database avoid centralize database model local database classifier generative model generative model potential data distribution data manifold broadly however risk expose critical information label augmentation supervise describes fitting input label throughout survey strategy regularize explore research entertain label successful knowledge distillation knowledge distillation describes transform traditional encode label distribution label logits another neural network prediction influential compression distilbert information retrieval achieve classification computer vision addition knowledge distillation strategy developed augment label label smooth heuristic adjustment density negative highly influential training classifier generative adversarial network another approach meta controller knowledge distillation massively teacher gradient loss update label augmentation notable explore meta pseudo label commentary ambitious augment data outer inner loop gradient explore data generative network generative network apply image data meta translation author propose meta framework translation model learns translation model gradient development data pseudo parallel data augment  augment data label distillation author encoder although efficient encoders tends accuracy pairwise classification task rank duplicate detection proposes label data encoder augment label encoder worth mention encoder heavily outperforms encoder training data significant benefit strategically data label encoder throughout data augmentation discussion curriculum generalization data augmentation holy grail machine achieve distribution  generalization distinct distribution generalization training sample data distribution  generalization assumption distribution shift  writes data arbitrary unrelated training data generalization obviously futile  describes relationship centric developer aware generalization generalization absent local extreme argue data augmentation interface quantify relationship data distribution generalization classic generalization simply report difference accuracy training however descent phenomenon overfitting generally poorly understood neural network practical overfitting generalization data adversarial neural network cannot generalize distribution adversarially optimize jia liang model squad cannot generalize adversarially optimize context addition adversarial attack datasets intuitive distribution shift neural network fail generalize fool inject text image jia liang image data augmentation generalization checklist proposes foundational nlp checklist linguistic capability model robustness negation vocabulary perturbation temporal consistency introduce distribution shift linguistic phenomenon construct toy transformer generalize chain training data model chain distribution shift intuitive interface data augmentation finally  collection distribution shift shift mapped data augmentation describes employ labelers construct counterfactual movie review inference author construct elegant annotation interface task mechanical turk worker minimally edit switch label convert  hidden beneath core fantastic  hidden beneath core suppose fantastic movie review author worker revision category recast hop  insert modifier insert diminish qualifier perspective rating inference author worker revision category modify remove action substitute entity detail entity insert relationship numerical modification remove negation unrelated hypothesis construct generalization counterfactual return description generative data augmentation generative model capable edits GPT imdb review task prompt movie review positive negative probably manage future investigate generalization shift induced counterfactuals generative model motivate author dataset construction  price tag inference generative model unlikely approach unless extremely model highlight categorization understand linguistic phenomenon underlie generalization generative data augmentation another lens generalization propose novel generalization bootstrap framework online error bootstrap error online error describes performance model infinite data without sample bootstrap error describes training setup batch data author simulate online scenario fitting generative model denoising diffusion probabilistic model generative model sample standard sample cifar additionally propose  technique analyzes curve generalization randomly label unlabeled data training batch augmentation described survey simulate unlabeled data insight conclude overfitting problematic data distribution neural network capable neural network remarkable ability interpolate within training data distribution potential leverage data augmentation expand training distribution reasonable distribution shift potential distribution cannot compress neural network interface illuminate model fail image versus text augmentation survey text data augmentation intend format prior image data augmentation similarity easy data augmentation geometric transformation computer vision similarly easy implement complement nearly text image data respectively described easy data augmentation easily interface text classification pairwise classification extractive abstractive summarization chatbots similarly geometric transformation computer vision image classification detection semantic segmentation image generation described survey data augmentation bias model towards semantic invariance image data augmentation largely successful easy semantic invariance relevant vision semantic invariance horizontal flip rotation increase brightness comparatively harder define transformation text data guaranteed semantically invariant augmentation described easy data augmentation potential perturb data truth label another trend integration vision recent model clip  sake data augmentation notable  tan bansal author align token image masked model task visual token additional supervision predict masked token alignment visual token tan basil report visual ratio token curated vision datasets solely corpus across sst    squad  benchmark task  improves bert RoBERTa vision datasets label task visual image caption text image retrieval vision data augmentation scheme  promising research recent trend image data augmentation integration training generative model namely generative adversarial network gans gan framework  model consists generator discriminator generator transforms random image discriminator classifies image generator training autoregressive model text return data augmentation gans investigation consistency regularization consistency regularization discriminator classification image augment image unfortunately augmentation leak generate distribution generator augment data discussion lecun misra distinction generative model image text issue article handle uncertainty masked token completion task mask chase mask  lecun misra model easily associate probability vocabulary lion  predator vocabulary comparison apply density candidate image highly intractable token typical token whereas rgb patch  therefore image model rely model joint embed assign similarity exactly model probability patch gan framework something nlp generative model expands scope generation pre training task abstractive summarization  another data augmentation application reinforcement heavily robotic visual input atari benchmark bottleneck robotic reinforcement lack data challenge restart robot laundry folder unfolded shirt trajectory researcher augment trajectory collection replay buffer amongst application reinforcement text data propose patient particularly explore model reinforcement patient  patient mimic dataset author clinical sanity model rollouts physiological patient marker promising research apply text data augmentation clinical trajectory improve patient trajectory simulation practical consideration implementation detail implement text data augmentation performance difference evaluation metric training efficiency consistency regularization consistency regularization compliment prior introduce via data augmentation consistency loss model minimize distance representation instance augment derive motif strengthen decision boundary consistency regularization enforces connection augment sample usually implement multi task framework model simultaneously optimizes downstream task secondary consistency consistency regularization successfully apply translate program enforce consistency translation slightly consistency regularization generate synthetic minimize distance representation augment framework model output predict context input model generates context input bert model achieves tune squad tune bert additional generate consistency improves performance consistency regularization technique supervise representation unlabeled data consistent representation augmentation deploy consistency regularization technique surpasses previous solely supervise significantly data improvement extreme label performance gain tune bert model achieves error rate imdb review classification reduce UDA multi task loss formulation fairly consistency regularization implementation unsupervised data augmentation schema image image contrastive contrastive differs consistency regularization utilize negative sample normalize loss function critical distinction negative sample significant signal development text data augmentation benefit adapt successful computer vision data augmentation contrastive supervise computer vision involves framework     training strategy information retrieval nlp propose contrastive realm realm contrastive loss align embed supervise contrast supervise mini batch however technique contrastive akin supervise contrastive framework   data augmentation positive strategy heavily explore information retrieval likely due lack augmentation hopefully interested pursue demonstrate significant improvement glue benchmark task training supervise contrastive loss addition entropy loss encode label vector gain pronounce label report difference label addition quantitative metric author highlight embeddings lens sne visualization contrastive similarly consistency regularization describes representation instance transformation derive however contrastive negative normalization additionally representation away instance sample mini batch contrastive achieve advance representation computer vision   data augmentation contrastive promising research recent extension information retrieval model realm refer interested reader report   detail effort apply contrastive nlp consistency regularization contrastive candidate inspect model performance verification model achieve accuracy classify refute evidence ignore evidence contrastive model correctly associate evidence contrast refute evidence consistency regularization prediction evidence slightly perturbed insert random replace paraphrase semantics negative data augmentation negative data augmentation concept negative contrastive however difference contrastive generally data negative whereas negative data augmentation entail apply aggressive augmentation augmentation limited label corruption distribution entirely return motif meaning versus augmentation useful meaning reinforce demonstrate improve contrastive generative adversarial network augmentation controller contributor data augmentation computer vision development controller controller reference algorithm optimize strength augmentation throughout training strength augmentation magnitude operation insert additional augmentation strength describes augmentation stack random insertion deletion translation described successful controller  population augmentation  adoption nlp apply easy data augmentation hyperparameters arise hyperparameter optimization active research perfect optimal random augmentation sampling magnitude token delete  instead mask token model mask multiple token span downstream performance adversarial augmentation adversarial attack adversarially optimize input augmentation previous discussion controller differentiation adversarially controller target misclassifications whereas controller generally avoid misclassifications particularly adversarial optimization aim improve robustness frequency shift adversarial attack text data generally introduce typo swipe individual chunk ambiguity perturbation filter text data preprocessing technique checker normalization regular expression filter  source library implement adversarial text attack apis data augmentation component attack  framework goal function constraint transformation pipeline illustrate goal function defines target output instead solely flip predict output target density constraint define input transformation describes available input synonym swap deletion apply translation technique previously finally describes algorithm attack discussion controller perform grid random bayesian optimization evolutionary develop attack  image consideration adversarial augmentation quickly construct adversarial adversarial construction technique rely iterative optimization BFGS adversarial significant bottleneck training adversarial training batch towards issue reduce consumption  algorithm  batch replay avoid repeatedly compute adversarial batch stack augmentation stack augmentation strategy improve vision model straightforward apply text data strategy coda coda introduces local consistency loss stack augmentation overly corrupt sample global loss preserve local neighborhood around instance tokenization preprocessing pipeline tokenization formidable challenge implement data augmentation tokenize convert token respect numeric index vocabulary embed lookup offline data loader apply data augmentation index significantly engineering effort synonym replacement additional code construct synonym index swap notably researcher explore tokenizer model byT  model byte sequence ASCII code processing integrate augmentation embeddings another subtle detail transformer implementation embeddings transformer sine cosine function integrate positional information text sequence another subtle data augmentation explore perturb parameter render encoding augmentation CPUs gpus another important aspect data augmentation understand typical data preprocessing pipeline CPUs gpus standard apply data augmentation data cpu gpu model training however recent apply data augmentation directly gpu kera data augmentation layer model immediately input layer worth clever scheme data echo apply additional technique avoid idle cpu data load gpu model training offline online augmentation similarly discussion augment data cpu gpu another important consideration data augmentation online offline refers instance augment data pipeline offline augmentation refers augment data augment disk online augmentation describes augment data batch data load training online augmentation powerful offline augmentation offline augmentation slight benefit faster load really advantage stochasticity diversity enable described augmentation another important detail pipeline augmentation multiplicity augmentation multiplicity refers augment sample derive illustrate increase augmentation multiplicity improve performance approach introduce significant memory overhead without online augmentation pipeline additionally augment online model actually instance propose model tune solely  data magnitude augmentation highlight opportunity explore grain detail augmentation pipeline curriculum curriculum describes meta controller structure organization data batch strength data augmentation throughout training  smith efficient subsample portion dataset augment augment entire dataset demonstrate efficacy gradually introduce augment training triplet network text classification discussion controller augmentation optimal magnitude chain parameter non trivial crucial imbalance prevalent issue explore classification model imbalance addition customize loss function sample technique promising overcome bias stem imbalance generally strategy random oversampling undersampling addition interpolation strategy synthetic minority oversampling technique SMOTE SMOTE framework  minority instance average augmentation mixup technique explore text data useful technique oversampling avoid potential pitfall duplicate instance discussion task specific augmentation nlp nlp encompasses task formulation text classification paraphrase identification abstractive summarization shelf data augmentation prescribed previous slight adaptation task augment context dataset important mindful remove difference task perspective data augmentation massively respect input sequence mindful augmentation longer sequence decision sample nest translation refer interested reader enumerate data augmentation applies summarization sequence tag parse grammatical error correction neural machine translation data text generation nlg conditional generation dialogue multimodal task supervise data augmentation supervise data augmentation inject prior knowledge data domain model deployed likely data distribution task model suppose perform data supervise task loss function representation data augmentation prior manipulate data distribution advantage data augmentation easy stack prior supervise utilize multiple prior supervise relies highly unstable multi task costly multi stage contrast data augmentation random sample operation integrate multiple prior supervise rely data augmentation dramatically improve data augmentation contrastive relies data augmentation instance data efficient gan framework achieve data efficiency data augmentation  data augmentation pixel autoregressive model  model transfer multi task transfer successful approach training neural network promising annotate datasets unified dataset hub notable  datasets datasets publication addition transfer researcher additionally explore multi task model simultaneously optimizes multiple task explore convert task model data augmentation mixup combine data multiple task translation curated datasets propose extension multi task  transfer utilize augment subset information across distribution multi task  augment subset ensemble prediction output utility feature extractor training task reformulate input unify prompt inference discussion prompt generative data augmentation remains significant opportunity explore transfer multi task data augmentation AI  artificial intelligence research AI  AI generate algorithm AI generate algorithm compose pillar meta architecture meta algorithm generate effective environment data augmentation interface data distribution role pillar generate environment embed agent teacher loop teacher augmentation parameter render environment environment successfully apply  neural network poet poet evolutionary framework parameter parameter render terrain data augmentation extend framework understand environment magnitude parameter augmentation subset data curriculum AI  apply vision generative network synthetic petri dish  teacher network generates training data network notably training data frequency resemble image data  generate text embeddings continuous optimization prompt tune conclusion conclusion survey strategy apply data augmentation text data augmentation interface developer inject prior task data domain model additionally data augmentation simulate distribution shift generalization data augmentation nlp relatively immature computer vision highlight similarity difference surround data augmentation practical engineering consideration broader discussion potential data augmentation building artificial intelligence data augmentation promising strategy discussion motivate research