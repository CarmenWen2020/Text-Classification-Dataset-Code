comprehensive evaluation data pre processing embed technique context arabic document classification domain health related communication social medium evaluate text pre processing apply arabic tweet within training classifier identify health related tweet task traditional machine classifier knn svm multinomial NB logistic regression furthermore report experimental architecture blstm cnn text classification embeddings typically input layer network evaluate pre embeddings text pre processing apply achieve goal data training another generality model conclusion pre processing improve classification accuracy significantly data arabic tweet mazajak cbow pre embeddings input blstm network accurate classifier data mazajak skip gram pre embeddings input blstm accurate model accuracy achieve mazajak cbow architecture accuracy performance traditional classifier comparable dataset significantly dataset introduction due increase amount data user generate content social medium text classification become important research researcher apply text classification analyze sentiment topic predict gender detect false news social medium variety medium health information information accurate issue concern however precursor trustworthiness health related tweet development model detect health related information social medium additional important devise quality identify health information social medium building health communication theory evaluate health communication understand public concern social medium outbreak built model detect english health information tweet conduct developed machine model detect health related information social medium platform unfortunately model highly dependent arabic cannot directly apply important consideration prevalence social medium usage arabic text normalization important text classification english normalize lowercase lowercase arabic normalize arabic involves normalize  remove diacritic english algorithm perform yield apply another text classification regard arabic processing social medium focus sentiment analysis literature survey systematic literature review conduct arabic classification specific task specifically conduct target sentiment analysis sentiment analysis evaluate application tweet service label positive negative pre tweet various technique performance vector machine svm na√Øve bayes NB classifier svm accuracy similarly tweet health service saudi arabia label positive negative achieve stochastic gradient descent accuracy moreover classifier detect disaster label tweet information flood whereas others classifier namely svm knn NB performance model svm accuracy   expand arabic text classification social medium data detect hate analyze crisis response flood however lack detect arabic health related tweet aim derive model accurately detect arabic health data twitter model data evaluate generality thereof statistic twitter popular arabic speaker widely health related information goal enrich literature technical detail development model detect arabic health related tweet devise model researcher discipline health related tweet comprehensive manner foundation empirical conduct focus tweet specific origin origin serf health information focus tweet emanate specific health tweet author organization extract tweet specific health related twitter account health related information social medium user informally tweet health ignore analysis health tweet model automatically extract health related tweet holistic health related tweet without specific health related account furthermore technical detail development model enrich literature specific text classification task extract health information tweet arabic text classification task structure discus related sect related sect focus data evaluation metric employ report ass impact various pre processing traditional machine technique classify health related tweet subsequently sect describes impact embeddings algorithm purpose finally sect discussion conclusion discus conclusion related vast literature arabic text classification social medium analyze tweet detect sentiment service saudi arabia tweet trend hashtags related health service data category negative positive processing tweet remove diacritic  normalize additional  unigram gram text extraction technique frequency inverse document frequency hereafter TF idf feature selection performance algorithm convolutional neural network cnn achieve stochastic gradient analysis svm accuracy stem pre processing developed model detect disaster tweet specifically risk flood achieve classifier label tweet information flood others remove diacritic text assumption text without diacritic manner  TF idf feature selection investigate performance classifier specifically  svm knn decision NB algorithm unlike  stem technique arabic stem stem prefix removal normalize  author conclude svm performs algorithm algorithm perform without stem performance knn svm NB sentiment analysis arabic tweet moreover impact stem specifically stem stem TF idf binary occurrence  feature selection accuracy achieve stem svm classifier TF idf feature selection normalization normalize addition remove hashtags obvious finding contradict however model earlier without stem impact stem stem addition removal sentiment analysis stem improves accuracy stem removal improve accuracy model furthermore investigate impact pre processing technique although remove  duplicate  report impact model built model detect sentiment tweet stem decrease model accuracy finding comparison however normalize mention investigate impact normalize accuracy model developed model detect hate youtube comment comment label positive negative normalize along additional morphological thereof model achieve report usefulness stem normalization contradicts described agreement pre processing arabic researcher technique normalize text normalize  normalize normalize furthermore report usefulness stem stem decrease accuracy model conflict normalize arabic data particularly specific classification task addition traditional machine algorithm dramatic increase apply tackle arabic text classification task model cnn memory lstm traditional machine model model NB svm cnn lstm detect sentiment tweet investigate impact pre processing technique specifically normalize removal stem traditional  feature extraction NB svm wordvec embed layer cnn lstm model conclude normalize stem improves accuracy model cnn lstm classifier perform svm NB normalize worth embed technique processing vector dimension usually prior embed training dimension vector opportunity semantics technique geometric encode frequently meaning efficient embed data researcher already exist pre embed demonstrate data pre processing aravec pre embed input layer cnn improve accuracy detect hate data contrast developed cnn lstm model detect emotion tweet unlike aravec pre embed input layer claimed normalize stem improve performance model developed model aravec pre embed input layer pre processing technique remove diacritic punctuation assemble model consist cnn lstm architecture author achieve claimed outperforms algorithm mention utilized customize pre processing technique pre embeddings unclear accord ideal achieve improvement pre embed corpus embeddings vector unless document pre processing normalize data aravec pre embeddings document model   investigate performance classical model detect hate arabic tweet classical TF idf representation performs embed classical algorithm combine cnn lstm architecture performs classical algorithm observation approach really efficient traditional approach svm NB etc arabic processing core research agenda context classify identify health tweet aravec pre embed additional pre arabic embed model investigate  roy assert pre model effectively consequently investigate usefulness aravec fasttext  tao pre embed technique text classification classification approach developed cnn lstm neural network model predict sentiment tweet  tao pre embed outperforms aravec fasttext author model achieve accuracy classify text positive negative neutral sentiment utilize collection tweet developed pre embed model combine popular technique wordvec skip gram wordvec continuous bag cbow global vector glove cnn architecture performance pre embeddings  aravec pre embed pre model outperform aravec model literature identify pre embed model apply classification arabic text pre embed model worth majority review arabic social medium text classification task svm NB recent trend arabic text classification cnn lstm architecture primarily observation consistent finding conduct review technique sentiment analysis arabic tweet recent report effectiveness pre embed layer model comparative embed technique context arabic text mining aravec fasttext  traditional majority arabic emphasize pre processing technique stem none impact normalize arabic remove diacritic claimed technique negatively affect classifier performance elaborate evidence assertion furthermore date detection arabic health related tweet twitter aim investigate impact pre processing technique model accuracy additional aim employ performance pre embed technique text classification task focus detect arabic health related tweet pre requisite aim classifier developed classifier developed traditional machine ML identify overall breed classification approach available health tweet identification derive approach achieve aim objective concerned impact pre processing technique accuracy predictive model variant normalize arabic addition pre processing technique explain sect algorithm algorithm widely algorithm text classification perform objective performance cbow skip gram variant pre embeddings approach specifically cnn blstm bidirectional lstm architecture pre embed model blstm cnn architecture apply text classification lastly accuracy classifier model developed traditional ML classifier model developed overview overview image data model evaluation metric generalization ability model accurately categorize data previously expose machine development data training questionable machine model training data usually derive environment addition data model model another data model data related covid extract march april differs data firstly secondly extract pandemic model generally health lexicon extract data detail data health lexicon health lexicon extract health related tweet combine keywords source minimize bias source annotator graduate linguist native arabic speaker review health related account hashtags identify health related expert medical active twitter health specific typically health related tweet exist health arabic health propose tweet combine however specific health lexicon false positive tweet zhang ahmed remove lexicon consists arabic health related source available http  data health lexicon described tweet employ twitter premium api tweet july august tweet randomly sample data tweet independently classify annotator health related health related   procedure annotator whenever disagreement annotator cohen kappa statistic interrater reliability demonstrate excellent agreement annotator independent cod tweet label health related model data remain data available http  data imbalance typically management algorithm traditional machine model explain sect algorithm svm impact imbalanced data another handle imbalanced data rework data sample however rework data fashion increase complexity guaranteed increase model performance addition data slightly imbalanced ratio imbalanced data instance others dataset imbalanced dominance imbalance data  slightly imbalanced data concern typically classification treat classification balance dataset data data consists tweet february march extract arabic tweet covid related keywords apply health lexicon reduce tweet finally sample manually label tweet data tweet data sample tweet label health related refer data unseen data training evaluation classifier data data available http  tweet IDs label twitter policy prevents content tweet redistribute apart tweet IDs obtain text tweet twitter api evaluation metric evaluate traditional algorithm recommend metric imbalanced data accuracy recommend metric balance data evaluate model comparison metric recall precision accuracy metric evaluate machine model performance per recommendation  decisive metric breed model concerned traditional ML algorithm evaluate importance pre processing technique impact classification pre processing technique review literature identify pre processing potential analysis variant normalize arabic addition technique apply pre processing arabic social medium data tokenization tokenization text typically usually delimit punctuation refer token removal removal aim eliminate unwanted text literature technique removal non arabic aforementioned remove non arabic data text remove contribute additional information text emphasize removal sample text remove usernames external link hashtags usernames external link hashtags tweet cite remove text normalization normalization convert uniform sequence literature technique removal punctuation punctuation typically extra meaning text although punctuation sometimes useful meaning analyse sentiment previous remove punctuation examine text removal  diacritic diacritic   arabic diacritic combine diacritic previously described remove diacritic remove user emphasize something researcher refer cite remove removal duplicate rationale removal remove however argue arabic originally contains delete twice delete duplicate twice remove    decorative arabic justify text phonetic remove  arabic specific normalization arabic  script arabic however arabic  user social medium frequently misspell  addition  apparent  variance  bare  possibly due similarity appearance  standard arabic commonly  without  misspell     unified bare  hence arabic specific normalization indicates normalization specific arabic directly arabic therefore apply arabic specific normalization technique literature researcher normalize others normalize furthermore sometimes normalize replace replace summarizes technique normalize arabic literature normalization technique researcher aim conclusive regard pre processing technique focus pre processing technique commonly identify literature review technique entirely systematic coverage date improves research basis pre processing technique explicitly however future issue carefully incorporate additional relevant pre processing technique  community remove remove removal arabic remove stem stem stem achieve technique literature stem stem remove prefix infix  stem  python library cite stem stem stem aim transform usually faster perform lemmatization sect arabic consist stem mostly stem  python library lemmatization lemmatization aim stem aim return origin however unlike stem lemmatization lexicon arabic mapped  feature extraction feature extraction transforms text vector bag bow TF idf extract feature text bow frequency ignore TF idf statistical approach sensitive TF frequency text idf proxy importance classification algorithm multinomial NB NB probabilistic model version algorithm text classification sentiment analysis spam filter variation NB  NB MNB svm svm statistical theory popular ML classification SVC  implementation vector machine classifier libsvm library SVMs devise chang lin  flexible SVC option penalty choice loss function  logistic regression logistic regression linear classifier hyperplane algorithm differentiate health related non health related tweet accordance   knn knn fundamentally algorithm algorithm memorizes training data discriminative function classify memory approach setup setup consists phase baseline algorithm developed pre processing technique individually algorithm baseline algorithm computationally expensive apply combination pre processing algorithm approach evaluate pre processing technique algorithm apply combination pre processing technique enhance model performance phase brute combine pre processing technique combination lastly model combination evaluate data illustrates phase overview flowchart combination MNB algorithm previous image develop baseline baseline model without apply pre processing moreover python grid pipeline tune hyperparameters apply pre processing technique ass outline algorithm hyperparameters tune brute hyperparameters algorithm outline appendix technique brute algorithm attempt algorithm outline accuracy achieve data without apply pre processing aim investigate hence model baseline impact pre processing important standard development instead achieve accuracy baseline judge pre processing improve baseline algorithm finally utilized validation model development python scikit version library conduct pre processing accuracy algorithm without apply pre processing technique baseline performance pre processing sect employ impact pre processing technique classifier  analysis english apply technique apply classification algorithm model achieve accurate refinement pre processing combination enhance accuracy model accuracy percentage pre processing technique extract tweet technique enhance MNB classifier combination calculate equation pre processing technique therefore variation appendix mention pre processing normalization technique improve MNB logistic regression performance technique improve  improve knn worth stem lemmatization remove improve model whereas remove non arabic reduce model combination phase brute algorithm combination favourable pre processing technique phase focus MNB achieve performance variant previous phase worth mention MNB model pre processing technique favourable effective combination pre processing technique improve MNB classifier contribute combination combination MNB achieve combination remove duplicate remove  replace replace combination improve data generalization apply model data accuracy algorithm sharply decrease due algorithm MNB classifier combination aim investigate pre embed model arabic literature pre model summarize aim classifier model classifier model tradition ML classifier approach sought generalize model data pre input layer model accord literature described earlier pre embed model embed model opportunity classifier correctly classify training data solves traditional text classification occurs classifier fails upon encounter unseen pre processing text employ author pre embeddings model accord ideal achieve improvement pre embed corpus embeddings vector model blstm cnn architecture classification task pre embed technique blstm assume input neural network sequence data lstm recurrent neural network advantage dependency input sequence text sequence lstm architecture text classification task specifically blstm variation learns dependency future input sequence blstm architecture propose  blstm model input embed layer dropout layer blstm layer dropout layer reduce dimension output model global max pool layer blstm architecture image cnn cnn originally propose image analysis architecture recently proven perform effectively text classification sometimes performs approach blstm propose architecture propose model input embed layer cnn layer contains input embeddings previous layer max pool layer cnn layer reduce output dimension output layer concatenate flatten fully layer illustrates architecture cnn model cnn architecture image hyperparameter tune hyperparameters tune optimize performance model literature random grid bayes accord   bayes outperforms tune therefore  algorithm kera tuner python library limited model terminate achieve optimal appendix outline hyperparameters blstm model appendix outline hyperparameters cnn model pretrained embeddings input layer architecture blstm cnn model blstm data pre embed model blstm perform manner accuracy achieve blstm mazajak cbow respectively mazajak cbow achieve recall precision respectively precision achieve  cbow recall achieve aravec skip gram performance aravec cbow precision accuracy respectively blstm pre embeddings data similarly data mazajak cbow precision accuracy respectively mazajak skip gram perform similarly mazajak cbow data achieve recall mazajak skip gram achieve accuracy achieve mazajak cbow difference overall pretrained embed model blstm architecture data mazajak skip gram data data explain sect judgment metric optimal imbalanced data cnn model pre embeddings data bold underlined model cnn contrast data aravec skip gram cnn performance accuracy recall precision achieve  cbow model performance mazajak skip gram recall accuracy respectively data performance model aravec skip gram recall accuracy fasttext achieve precision recall respectively pre embed model performance architecture aravec performance skip gram cbow significantly architecture pre embeddings mazajak  decrease aravec skip gram perform cnn architecture overall model cnn architecture cnn aravec skip gram perform data addition pre embed model perform blstm architecture therefore blstm generally perform detect arabic health related tweet particularly embed mazajak skip gram data discussion concerned pre processing technique algorithm performance achieve pre processing popular technique researcher normalize  stem remove pre processing improve accuracy model literature focus impact stem algorithm performance stem increase accuracy baseline model agreement thesis previous combination pre processing technique model outperform combination pre processing stem appendix important pre processing technique model arabic specific pre processing technique removal normalize  arabic specific likewise fourth pre processing technique remove  widely arabic writer text classification arabic arabic specific normalization technique role improve model performance pre processing technique possibility highlight importance systemically ass impact normalize arabic specific technique model performance data nevertheless rarely pre processing technique perform improve classifier model lemmatization literature review lemmatization perform classifier model notwithstanding technique improve accuracy MNB model worth whereas MNB classifier achieve data performance decrease data observation firstly difference mazajak skip gram mazajak cbow performance data blstm apply mazajak skip gram cbow blstm data furthermore apply mazajak  cnn architecture contrast difference performance aravec cbow skip gram aravec skip gram perform aravec cbow architecture observation aravec performance slightly decrease architecture whereas mazajak   notable decrease aravec perform cnn architecture pretrained embed model data furthermore data cnn architecture aravec skip gram performance negligible increase blstm architecture traditional algorithm data blstm architecture pretrained model embeddings perform MNB classifier aravec cbow MNB classifier perform model cnn architecture MNB classifier MNB classifier perform cnn classifier cnn classifier aravec skip gram input layer report cnn classifier aravec input layer perform identically accuracy marginally aravec skip gram perform MNB classifier data however cnn blstm model perform pre embed model MNB classifier MNB classifier data comparative outperform MNB classifier data data generalize unseen data contribute literature approach really efficient traditional approach regard generality limitation strength previous researcher concerned evaluate pre processing task stem removal english recent pre processing technique review literature identify variant normalize arabic addition pre processing technique arabic classification task future focus investigate impact pre processing data focus impact arabic specific normalization newer technique autoencoders feature transformer model bert bidirectional encoder representation transformer arabic  outperform model however focus architecture pre embeddings traditional machine model frequently related literature another limitation phase although brute comb pre processing technique task pre processing technique apply impact combination apply traditional approach yield significant gain approach overtake MNB conclusion goal evaluate impact pre processing technique traditional algorithm discover technique improve accuracy baseline model addition pre processing technique model specific blstm architecture perform cnn architecture MNB classifier blstm mazajak cbow pre embed perform data blstm mazajak skip gram perform unseen data overall blstm mazajak skip gram pre embed model data data abbreviation svm vector machine NB na√Øve bayes knn TF idf frequency inverse document frequency cnn convolutional neural network  binary occurrence lstm memory cbow continuous bag ML machine blstm bidirectional memory MNB multinomial NB