creation knowledge manipulate analyse exist knowledge primary objective cognitive effort data research focus upon volume velocity variety ugly  data neglect principal challenge variety understand comprehend data proposes evaluates automate approach metadata identification enrichment data focus enable automatic compliance data regulatory requirement along capability generate valuable readily usable metadata towards data classification towards data confidentiality data identification conduct evaluate feasibility approach focus confirm repetitive manual task automate reduce focus data scientist data identification thereby focus towards extraction analysis data origin datasets private business public governmental exhibit diverse characteristic relation file file experimental confirm algorithmic technique attribute substantial decrease false positive regard identification confidential information evidence data along statistical analysis supervise sufficient identify structure information within approach issue understand data mitigate enable focus meaningful interpretation heterogeneous data introduction  refer data introduce dimension characterise data become standard define data volume refers amount data digital universe velocity data environment refers data variety characteristic data manifestation sensor internet iot database video audio format standard dimension mainly technical subsequently augment additional consideration lack governance homogeneity identify veracity validity concerned correctness accuracy volatility refers data valid business concerned income realization competitive advantage another dimension significant challenge business dimension become essential data gain acceptance towards data driven decision approach although arguably adequate literature research volume velocity research variety reveal trend challenge data scientist cope heterogeneity data identify understate datasets technological specifically issue variety proliferation data source internal external public private numerous format increase challenge sheer complexity data source accurate inaccurate data mixed multiple format measurement significant risk handle data mitigate risk effort understate data structure data actually interact data generate meaningful insight task contextual placement definition task assign variety remain resilient software automation reduce dependence respective enable business penetration adoption  survey organizational challenge adopt analytics identify variety factor impact business adoption ownership TCO hardware maintenance software licence TCO paid service address variety data project arrival erroneous conclusion due data variety significant concern organization realise return investment roi data understood minimize business harmonize data variety quantify precise quantitative illustration lose roi attribute variety identify data project roi approximately per spent contrast project gap roi designate challenge lack automation monetary manner challenge increase profit realization data analytics implementation consideration  retailer additional revenue analytics project research aim target issue heterogeneity complexity data propose evaluate technique automate identification focus upon contribution automate identification confidential data application additional feature refer booster metric wider dataset identification approach machine contribution empirical investigate impact performance approach confirm plausibility  variety become enabler business adoption data technique minimise analyst interaction towards data classification private data identification background research identify variety respect data review prior undertaken  repository sciencedirect springer link xplore google scholar methodology multiple research evaluation classification data reference keywords data volume velocity variety technological advancement data analytics combination document evaluate screen extend abstract introduction conclusion along document review respectively iteration article identify categorize data reference classification notable within analysis whilst research publication focus data relatively specifically focus upon variety issue respect variety establish unfortunately analysis thirteen specifically variety reveal focus confirm challenge propose validate ensure review capture relevant research undertake broadening keywords related heterogeneous data heterogeneity data discrepancy nosql combination thereof seventy identify relevant review twelve identify relevant focus challenge originate automatic schema management federate data erroneous data interdependence heterogeneity volume review document primarily related specific datasets pertain biology protein genetics gene sequence medical cancer scan recognition disaster flood drought earthquake limit apply filter RDBMS data database pool reference review met criterion reference focus storage implication nosql database filter contrast actual variety challenge integration unification review thirteen directly related variety fourteen indirectly related heterogeneity utilized understand related variety timeline analysis reference denotes researcher mainly identify challenge limited  paid service address variety data project internal resource lower  business harmonize data   independently specialized personnel utilized respective specialization organization substantiate critical scarce resource variety costly challenge error controversial challenge organization understood minimize lack relevant literature within variety deem prudent broaden criterion investigate issue data heterogeneity wider literature identify topic date methodology request broker architecture  distribute component model  electronic data interchange edi devise employ focus define rigid communication framework essence prevent variety  diversification approach arguably sufficient web existence eventually extensively adopt methodology abandon impossible enforce rigid communication protocol exponential increase generate data become apparent standardization data generate beforehand prior methodology towards publication data integration approach related diverse data structure framework  MOMS  similarity flood imap reconciliation target schema federate query execute across methodology technique utilize linguistic translation graph semantic however highlight technique candidate confirm taught neural network training target federate query intervention import data understand structure whilst schema reconciliation confirm automate identification instead federate query concept aggregate model meta model model information link metadata distinct model aggregate model reconciliation definition heterogeneous schema information storage heterogeneous data quality methodology  approach focal conceptual entity abstraction phenomenon instantiation entity concept adapt data address variety challenge automate identification aggregation abstraction layer  data become challenge velocity consideration wang explicitly refers heterogeneous data research mainly confine identify challenge instead propose alternative overcome data swamp identify  data data dumped without metadata confusion limited usage semantics structure data unknown data swamp devastate implication organization due regulatory implication data confidentiality addition fuzzy data data scientist format data prior indicates absence extend research variety research extend concept heterogeneity identify address challenge respective technique driven applicability data data swamp indicative variety challenge transform corporate data   data address challenge objective investigate feasibility transform repetitive identify ingest data labour intensive effort software driven automate ingestion depict diagram upon automation capability subsequently task prerequisite data scientist analyse data identify  obtain data propose model data variety image data origination confidentiality ingestion journey data understand data data origination automation outside realm actual ingestion essential contextual information contextual information data origination public private originate discipline collection identifies milestone ingestion data confidentiality information increasingly regulate multiple sector personally identifiable information pii public sector information psi directive data protection regulation GDPR payment pci security standard along anonymization standard european medicine agency policy health insurance portability accountability regulatory immediate financial impact annual global turnover facebook confirm billion another potential outcome ongoing GDPR investigation due data loss prevention DLP risk data confidentiality candidate automation identify content data challenge due volume source datasets importantly relation tend vast false positive empirical evidence suggests exist automate rely heavily regular expression regex false positive credit fifteen sixteen digit identify candidate sample available credit debit personally identifiable information sample regex apply pii identification passport social security mail physical address internet protocol IP address medium access mac address generic data account international account  customer tend sequential false positive qualify confidence propose reduce false positive accurate metric content confidential data calculate confidence exist regex methodology extend multiple metric booster metric increase confidence metric  proximity structural confirmation digit calculation illustrate classification booster metric association address false positive impediment structure manner utilises classification accommodate confidential information identify extend pre processor translate content ensure textual data fed processor columnar content introduce cater multiple file structure pre processor processor entire confidentiality image pre processor apache  project ensure  file pdf   convert text format subsystem manage multiple file format processor alternative reader introduce traditional reader reading enable file exhibit columnar structure merge logical sequence format trace file content addition hex text document pixel perfect report utilize columnar style incorporate reader parameterization caters variety file format columnar file sample image anticipate confidence inclusion booster  reliable identify confidential data automate fashion data format delimiter determination confidentiality barrier compliant data broken import data format identification data breakdown phase address heterogeneity challenge propose approach focus upon viability accuracy volume impediment address variety analyse data impossible infeasible propose approach seek achieve format identification analysis delimiters file delimit sequence delimiters across comma semicolon comma delimit file tab tab delimit file challenge digital document textual data etc attempt incorporate manifestation variety contextual importance file delimiters occurrence punctuation ordinary text instance comma possibility punctuation tilde tilde attribute rationale increase significance  rare combination separator separator detailed information delimiters associate attribute multiple independent component information pre processor harmonize data perform initial classification identify file text binary  identify file encode identify content accordingly configure subsequent input reader ANSI reader load data utf encode file correctly subsequent parse removal quotation json xml notation nullified tend parser adjust specific characteristic paraphrase embed file structure delimiter determination image preliminary inconsistency investigation component introduce framework become apparent difference experimental datasets exhibit accuracy predict file delimiter variety something consideration initial variable definition pre processor label escape context incorporate compensate characteristic attribute utilised multiple delimiters segmentation although file instance delimit comma multiple delimit semicolon delimiters exhibit conformity extend multiple enclose quote text document variance couple primary metric mapped calculate characteristic delimiters identify file file min max standard deviation delimiter across per min max coefficient variation delimiter across per min max standard deviation relative distance delimiter previous delimiter across per min max coefficient variation relative distance delimit previous delimiter across per primary metric average aggregate data file consideration delimiter derive metric identify delimiters file consistent across boolean metric average standard deviation absolute delimiter average coefficient variation absolute delimiter average standard deviation relative delimiter average coefficient variation relative delimiter metric subsequently input parameter supervise multi layer perception mlp neural network classify file format without input neural network verify delimiter characteristic calculate metric file delimit respective delimiter identification automate intervention supervision automate task scope data scientist service limited important task interpret data instead identify synergy multiple perspective benefit adaptability responsiveness business environment effort incorporate data profitability allocate internal external resource towards data mining instead data identification activity identify comparative advantage TCO achieve business adoption rate experimental methodology series conduct evaluate propose approach data origination data format identification objective data origination confidentiality confirm false positive generate conventional technique regex minimize identification accurate action mask proof concept poc datasets application audit network capture respective probability file organization vendor external entity regard data format delimiter determination objective confirm data variable viability identify file delimiter thereby enable identification data statistical data derive analysis data input neural network enable identification evaluate approach variety datasets identify characteristic origin file varied investigate impact upon performance illustrate datasets volume origin characteristic decision incorporate proprietary dataset addition public public data typically review tend already structure sanitize proprietary datasets tend unique characteristic developed specific disseminate proprietary dataset originate financial sector source  environment sensitive information incorporate broader spectrum data anomaly definition volume introduce incorporate volume velocity concept behaviour data contrast instantiation data dimension processing compute resource requirement evaluate implement evaluate desktop PC inter core cpu ghz memory GB utilized application software matlab eclipse mar java data origination confidentiality data origination stage interested identify source content data accidental private confidential regulate data minimize  along standard user generate file processor file spreadsheet email utilized investigate validate propose approach widely security analysis click insight analytics insight classification along parameter regex bin associate booster percentage sanitization option xml configuration file highly flexible manner quickly adapt extension regard configuration initialization booster metric configuration along location flag data sanitize sanitization depends classification configuration technique define mask hash encrypt replace truncate identify information classification percentage contribution booster metric configure confidence percentage regex identification respective regex refer sample metric definition recursively available file folder depth multiple processing execution contribution metric confidence percentage per occurrence respective percentage instantiation exceeds define watermark confidence entry confidential confidence parameterized initial contributor regex sum contributor filter false positive increase contributor analyst consideration multiple processor configuration sanitize data apply request algorithm remove data classification occurrence multiple recording identical instantiation credit identify debit identify identical occurrence tag relative xml external AI identify regex file lineage detailed identify qualify entry available review parameterization requirement sanitize file file file preserve whilst release future usage data scientist tune alter contribution percentage tune per dataset entity data format delimiter determination poc confirm automate data format feasible identify quantity data attain reasonable confidence data attain uniform across data file instead file microsoft MS access MS excel  chunk user sample import processing arguably suffice data failsafe implement configuration apart file percentage data scientist enforce file purpose initial  identify analysis input data skip algorithm utilized input illustrate file accurately identify data format irrespective data volume data individual approach investigate data characteristic origin file file experimental data composition concern origin volume image datasets constitute representative sample combination volume identify addition origin factor public file volume ncdc private moderate file moderate volume ODS public file volume cdc although ratio file indicates per file important understand processing file limited file challenge memory constraint classification respective dataset available percent text file identify exclude binary file eventually exclude dataset classification attempt auto detect delimiters configure confidence delimiters grant upon usage respective combination comma extensively rarely everyday communication delimiters confidence conclude pre processor developed multiple execution conduct incorporate sample identify formula calculate metric available metric formula false positive percentage additional xml tag data  file content classification file encode classification datasets execution timing meta mismatch neural network primary derive metric feature data delimiter input component multi layer perceptron mlp neural network approximate relation delimiter characteristic delimiter component implement matlab graphical illustration network reduce model overfitting validate technique input data accordingly ratio although ratio researcher tend bayesian regularization propagation  training function advantage due extensively network utilized normalize error mse  typical respect execution limit epoch hidden neuron thumb   experimental configuration ann image neural network training data incorporate target output zero valid combination file delimiter whilst combination false positive assign zero performance graph sample training input datasets training performance graph image training calculation neural network confidence confirm data file delimit specific delimiter neural network output adjust neural network adjustment image multiple execute sample calculate metric neural network predict delimiter correctness manner automation achieve whilst viability guaranteed lower data volume dimension sample correctly discover structure delimit file data origination confidentiality purpose confirm capability minimize false positive along capability identify occurrence confidential data extend verify traditional regex file combination actual positive false positive utilized identify proposal calculate performance regex confidence benchmark parameter standard regex yield whilst booster elevate respective percentage false positive booster utilized verify validity utilize boost regex methodology occurrence identify sample verification occurrence confirm coincide boost average identify attainment improvement filter false positive calculate performance attain introduce absolute relative xml additional detail constitute increase ratio utilize aforementioned confidence immediate contribution without false positive remain essence pertain relative xml without booster identify regex expression booster metric data format delimiter determination sought explore viability identify data machine establish data achieve structure manner contributes input phase analysis consists information identification file source eligible processing identify text classification text binary respective file  file identify cdc ODS ncdc participate subsequent analysis encode distribution identify text file execution respect metric evaluate execution delimiters file unique file actual file dataset whilst file actual file difference file identify multiple delimiters identify delimiters procure metric statistic delimiter gradual increase execution whilst increase outcome variation delimiter identification minimal throughout percentage detailed information per dataset tabular graphical format conclude percentage execution timing relatively accuracy nevertheless imperative validate metric efficiency location delimiters file structure actual breakdown conclusion statistical analysis perform import neural network input parameter network utilized accurately identify delimiter file ann actual data manual semi manual employ verify file delimiters reference ann output initial series implementation dataset whilst reading file content reveal unexpected accuracy ann conflict manually identify delimiter confirm error manual classification ann identify delimiter confidence conclude expand content reading percentage datasets ODS cdc ncdc file refer file training calculation ann function neural network independent file derive ann apply respective file file file file per neural network per file tabulation related training network associate file illustrates output ODS network respect percentage tabulation unmatched file tabulation percentage input file per data per percentage horizontal axis vertical axis invert percentage percentile difference per file exhibit ann actual delimiter file percentile label deviation actual ann indicates difference exhibit actual network calculate essence neural network performance ann formula define training ann data processing ODS data reading file content formula identify predict confidence delimiter cdc ncdc data content percentage data respective percentile upper tabulation file category highlight data purple file exhibit difference ann actual delimiter ann formula calculate ODS dataset file content ncdc data reading file content percentage file category upper tabulation depict percentage file purple file exhibit difference ann actual delimiter neural network tabulation sample image visualize progression differentiation exhibit margin error colour cod indicates although differentiation ncdc bulk erroneously classify file file dramatically reduce contrast cdc although deviation remain aforementioned tabulation invalid training file sample depict ODS highlight parallelogram invalid training data ann ODS dataset file file content quickly become apparent difference mention cdc variation exhibit tabulation exhibit difference rate data percentage ann error peculiarity specific dataset confirm calculation error become apparent variety escape context pre processor described sect implement adjust model cater cdc unique characteristic pre processor minimize apparent specific differently preliminary differentiation vital indication model auto adjust perform accuracy outlier dataset introduce ecosystem meta understand aggregate previous independent tabulation acceptable percentage probability error aggregate data individual display respective slice mismatch tabulation training perform dataset risk appetite data analyst scientist identify percentage ann function yield retrieve respective consideration error viable risk analysis timing reading percentage subset percentage comparative analysis confirm yield detail execution dataset processing conclude optimal percent comparative analysis error image identify optimal percentage experimental resume investigate impediment cdc dataset affect framework accuracy adaptability introduce variety training ann devise consist file datasets contribution training compose file whilst file precaution file neural network implement reading similarly prior tabulation investigation aggregate image contrast cdc ncdc relative ODS calculate ann exactly actual file delimiter confirm prior network exhibit differentiation cdc dataset  phase ODS network differentiation phase relatively contrast network ncdc aggregate exhibit accuracy constant smooth phase ann function differentiation phase plot image aggregate proven automate approach data characterization framework accurately classify structure data exhibit unique trend characteristic incorporate multiple framework capable absorb variety transform asset auto calibrate neural network caters multi source accuracy aggregate neural network efficiently effectively classify independent classify ncdc ODS multiple classify aggregate ncdc discussion contribute knowledge explore empirically validate content classification structure identification towards content classification introduce booster metric effectiveness remove data structural identification experimental processing datasets quantitative qualitative characteristic procedure statistical data analysis data calculate specific metric incorporation metric neural network detect structure focus feasibility approach respect computation representative dataset sample analyse accuracy identify confidential information increase automate identify file structure fragment dataset content although enhancement utilised implement improve accuracy automation automation proven viable proposition experimental reveal challenge respect data dimension  extensibility maintainability volume manifest relation memory ram limitation processing file velocity limited processing drove sample initiative variety confirm additional sub introduce relation  extensibility maintainability extend without interaction respect regex binary hex content treat contextual accuracy retrofit prior structural identify information framework applicable business implementation towards DLP data organisation confidentiality phase benefit enhancement increase accuracy broadening identification spectrum technique technology processing identify information hexadecimal parse reveal information visible translate text explode container cabinet file zip cab jar etc capability investigate broader source multiple pre processor incorporate transform digital data video become input respective module  extension introduce aggregate information relative xml classification identify regex expression auto retrofit extend data format delimiter detection extend enhancement performance accuracy suggestion implement warn entire file calculate index identify structure progressive analysis prior built data indicator file structure delimiter combination enhancement pre processor identify delimiters incorporate primary analyse grammatical analysis processing enhance performance identify delimiters easily exclude reduce execution increase accuracy quote  return pause threat upon algorithm definition basis analyse another enhancement mention earlier adopt framework corporate data compliance data scientist analyse data automatically indication confirmation risk appetite existence confidential information structure information empower analyst proceed mining data possibly corporate data  public imperative comply data confidentiality towards regulatory requirement enforce corporate addition data scientist explicit anonymization  decision beneficial exploit possibility define corporate departmental identify preferably visually compliance scenario analysis calibration public compliance verification although applicable data enhancement towards minimize variety empower data scientist beneficial function business information data operational risk compliance increase usage actionable insight derive data mining promotion adoption data enhance throughout multiple business entity conclusion data scientist assist data classification identification automate manner propose approach interaction recommend analyst understand interpret automate approach remove labour intensive data origination data format task whilst residual critical decision remains data scientist initial implication variety stag ingest data minimize utilize algorithmic approach automate identify confidential information regulatory risk  data loss minimize enable software minimize intensive task adoption limitation identify earlier text multiple scholar tackle approach confirm viability data environment utilize dataset data whilst quality address challenge evident substantial execution sample diverse datasets retrofit data onto validate enhance risk acquire sufficient data impact tune parameterization percentage whilst retrain  network whenever introduce although employ automate technique automate data scientist interaction limited tune model understand exception