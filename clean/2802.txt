argument facilitate deliver outcome discussion heavily relies validity argument argument compose effective grasp core argument grade argument machine utilized decompose semantic label component processing multiple model available perform task context contextual model majority previous craft feature perform argument component classification model utilize machine majority model ignore context argument research aim analyze context classification improve accuracy model enhance argumentation mining document corpus fed model wordvec glove context model bert elmo context sensitive model accuracy model importance context contextual model proven boost classification accuracy approximately however contextual model longer training prediction benefit increase accuracy outweighs burden contextual task argumentation mining contextual model context achieve promising introduction argue daily activity argument increase decrease acceptance controversial emphasize opinion discussion argument decision conclusion accepted argument everyday conversation strengthen validity argument premise argument literature premise policy propose argument scheme understand structure argument improve quality argument validity argument argumentation mining aim machine capability decompose text retrieve argument perform sentiment analysis machine author assist structure strengthen argumentation text practical insight argument currently technique developed argumentation mining accord previous research task perform argumentation mining identify argument sufficient classify argument component identify argument identify argumentative relation argument graph automatic annotator text argument majority argument mining research argument component classification currently approach available perform classification depends goal task argument component namely premise argumentation mining mandatory categorize non afterwards category classify multiple another approach classify directly premise non argumentative research grouped premise lastly classify premise non argumentative category technique perform argument component classification approach commonly apply handcraft feature research approach proven literature achieves machine approach ability feature input data technique utilize model feature extraction context model global vector glove wordvec fasttext contextual model bidirectional encoder representation transformer bert embeddings model elmo argumentation mining context important role additional information classify argumentation component context sensitive model outperform context model context sensitive model bidirectional manner bert performs shallow bidirectional model elmo comparison model classify vector directly perceptron model independent variable performance model related argumentation mining argumentation discourse speaker persuade audience  supportive argument argumentation mining usually aim identify argument component text predict relation argumentation mining perform data abstract randomize trial rct  database annotate dataset argument component argument relation retrieve disease  glaucoma  diabetes hypertension pipeline propose argument component classify evidence predict relationship attack perform bidirectional transformer combination various neural architecture memory lstm gate recurrent gru conditional random crf component detection relation prediction another approach propose analyse relation argument conduct research presence absence emphasize similarity nuance siamese network extractor feature replace memory cosine distance function model accepts input predict relation objective research similarity related relationship attention mechanism implement accuracy trend classify argument component polarize statistical model feature engineering neural network without prior knowledge another secondary feature therefore research proposes lightweight feature model classify argument component performance propose model previous manage outperform others achieve macro finding conclude prior knowledge improve performance model argumentation mining enhance activity peer review assistance research mining argumentation tweet twitter social medium multilingual argumentation mining research conduct perform transfer utilize machine translation model trend increase model built approach achieve promising perspective representation model context model contextual model context model deposit contextual model assign scenario meaning context model wordvec glove fasttext meanwhile contextual model bert elmo wordvec model skip gram approach improvement training model subsampling frequent training faster regular representation technique later negative sample glove model explainable model model explicitly regularity emerge vector model global bilinear regression combine global matrix factorization local context model vector meaningful substructure fasttext actually extend version wordvec fasttext optimize subword skipgram training fasttext sensitive rare research  skipgram baseline unlike recent representation model bert pre bidirectional representation unlabeled text jointly conditioning context layer bert simply concatenate context elmo model concatenation weakness unable simultaneously context transformer encoder layer sequence input transformer context specific pre bert model tune additional output layer model task inference without substantial task specific architecture modification bert report model obtain eleven processing task understand evaluation glue absolute improvement multi genre inference  accuracy absolute improvement stanford dataset squad absolute improvement squad absolute improvement preprocessing data bert model data tokenized bert tokenizer model fix vocabulary addition data annotate token recognize bert instance CLS token  sep token another addition CLS token signal classification layer perform classification task input sep token fitting input model another important token pad token bert absolute positional embed pad token preferably input additional sequence input annotate token bert model attention model differentiate pad token tokenized input bert attention mask attention pad distilbert lighter version bert effective purpose model objective reliable production bert model production constraint latency server model mimic bert model addition token embeddings  model corpus training bert model english wikipedia toronto corpus technique distilbert lighter bert model distillation compression technique model distilbert behavior model bert elmo contextual model representation elmo combination exist layer representation representation model densely corpus similarity sought model bidirectional model methodology data argumentation dataset online forum classify namely premise none data essay distribution data dataset dominate premise statement none contains statement cannot classify neither premise statement similarly none contains statement data dataset distribution image data data randomly training random random crucial ensure training dataset model ratio training preprocessing contextual model fitting data model raw text data encode correspond tokenizer model code encode bert model bert tokenizer bert tokenizer fix vocabulary data maximum statement statement pad constant pad token bert automatically treat pad token finally attention mask differentiate token pad token comparison purpose dataset multiple bert model bert sequence bert sequence bert uncased sequence bert bert model data bert model longer sequence difference bert bert uncased bert uncased uncased bert model training accuracy model finally data convert pytorch data torch data loader iterative sequence insertion entire dataset load memory training training pipeline bert model bert training pipeline image research elmo embed lambda layer neural network architecture therefore tokenization embed execute inside training pipeline neural network accepts input text input text directly tokenized embed elmo model prior passing input text neural network model training dataset preprocessed convert label categorical elmo training pipeline image context model another model context model encode token model datasets convert token fasttext model label configure format label prefix passing supervise training preprocessing model treat label subword marker model comparison purpose model epoch batch model google colab notebook tesla gpu context research wordvec glove fasttext context model context model fix embed model behavior model wordvec glove model experienced preprocessing pipeline text pad transform token token fed model model dimension model translate array vector flatten concatenate array vector dense layer classify fasttext model underwent pipeline model already encapsulate data preprocessing training label label prefix directly onto training contextual rate epsilon bert model distilbert bert detail regard architecture model difference uncased model difference parameter attribute uncased bert model text training bert model sensitive text bert model input text bert model uncased bert model input text differently bert architecture bert uncased bert image bert distilbert training pipeline distilbert derive bert model training pipeline elmo text classification training pipeline context training pipeline however difference model sequence various therefore unnecessary pad fix embed insert lambda layer model architecture fully layer neural network model context training pipeline image discussion model performance difference uncased model significant difference specific task ignore affect accuracy model important uncased model uncased highlight context meaning context model glove model wordvec model performance regard argumentation classification task however classify text wordvec perform glove contrast glove model evaluate premise none model performance difference advantage model really affected corpus model wordvec model disadvantage handle vocabulary OOV glove handle fasttext model perform context model however achieve performance dataset premise performance model metric fairly judge performance model uneven distribution dataset addition performance metric unbiased towards false positive false negative average precision recall accuracy contextual model significantly context model performance image accurate tune contextual model elmo model achieves average however model outperforms perform context model achieve average detail model perform hence context critical text classification contextual model outperform context model equally important performance model prediction training model comparison training dataset constant model random addition environment training model purpose model device dataset tradeoff performance perform model training model elmo model training training model prof transformer contextual model succeed achieve minimum image shortest processing contextual model distilbert model min training prediction distilbert lighter faster bert model approximately min training prediction distilbert model prediction bert model context model distilbert model training approximately prediction prof distilbert  bert model longer context model contrast model accuracy sequence affect processing significantly bert model sequence additional min training sequence addition prediction sequence model almost twice sequence model uncased bert model affect processing significantly task bert model additional uncased model variation embeddings model context embeddings difference context model training prediction varies model training prediction training glove model almost training fasttext model context model training prediction probably glove model subwords context model significantly lesser contextual model proven contextual model min context model approximately contextual model vocabulary context model context embeddings mention context model token potentially multiple token contextual model context statement hence contextual model embed token input contextual model longer context model prediction important consideration performance analysis training training handle compute prediction variety device deployed commercial highlight comparison performance prediction bert model distilbert model efficient bert model achieves lesser bert performance prediction image error analysis analysis bert model sequence perform model premise statement falsely classify deeper insight towards behavior model frequency predict calculate visualization appearance premise prediction prediction image interestingly majority statement dataset predict dataset classify frequent dataset article conjunction meaning towards statement potentially bias towards hence exists contains model accurately classify instead bert model identify context statement statement emphasize argument bert model successfully identifies conclusion classify argument component contextual model outperform context model contextual model achieve minimum context model achieve average however context model significantly faster contextual model context model predict advantage performance outweighs context proven critical role argument factor perform context sensitive task argumentation mining contextual model context proven boost classification accuracy approximately unfortunately obtain research improvement contextual error exist future hypothesize instead contextual individual classify semantic label statement contextual contribution towards semantic label statement instance instead context individual strongly deeper meaning towards semantic label statement model classification vanilla network enhance performance classification argument component contextual model vanilla network apparently future scenario mayer apply argumentation data abbreviation bert bidirectional encoder transformer crf conditional random distilbert  bert elmo embeddings model glove global vector glue understand evaluation gru gate recurrent lstm memory  multi genre inference rct randomize trial squad stanford dataset wordvec vector