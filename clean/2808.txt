mapreduce program paradigm frequently analyse amount data paradigm relies ability apply operation parallel independent chunk data consequence overall performance greatly data partition various computation node default partition technique hadoop spark basically performs random subdivision input without correlation approach appropriate simplest input analyze becomes limit sophisticated analysis correlation exploit preliminarily prune unnecessary computation context multi dimensional partition technique COPART data correlation subdivide split assign computation node specifically considers correlation data contextual attribute distribution contextual dimension dataset experimentally approach exist quality criterion query execution introduction analyze overwhelm data due social medium internet iot multimedia motivate development parallel data processing however development technology efficiently data issue mapreduce framework hadoop spark rely program paradigm datasets independent chunk split underlie assumption split parallel partial combine obtain approach originally developed bulk analysis analysis involves processing approximately translates default partition technique considers amount byte splitting criterion inside split predefined byte threshold without inspect actual content recent specialized processing developed purpose  extends hadoop spatial operation analysis query data attribute interval spatial query usually selective portion data partition solely split efficient account correlation data instance application scenario related tourism dataset contains tourist PoIs tourist pas swipe entrance poi swipe contains identifier pas location coordinate poi entrance timestamp someone analyze dataset global tourism trend compose query timestamp tourist specific specific poi poi museum prefer museum complex query combine dimension tourist specific poi specific analysis PoIs location query analysis selective predicate partition technique prune unnecessary data overall performance increase balance amount parallel context analysis identify dimension attribute analyze dataset aim context partition technique split context related indeed recognize notion context extract relevant chunk knowledge information focus reduction aim implement partition technique query context attribute prune away uninteresting data without processing motivate illustrates technique significantly improve performance analysis operation clearly selection context analysis identification attribute challenge task impact partition performance analysis  analysis frequent others mining frequent attribute mention query along knowledge target scenario infer useful context context analysis identify another important issue identification boundary dimensional split data grouped respect contextual dimension related available technique usually rely uniform partition however choice harmful context dimension uniformly distribute task others overload affect benefit parallel computation contribution definition context multi dimensional partition technique COPART dataset contextual dimension relevant analysis appropriate partition split context related balance partition distribution data related contextual dimension inside evaluate tourism scenario described dataset swipe pas italian scenario characterize recurrent query perform analysis partition dataset permanently distribute filesystem hdfs easily adapt dynamic scenario dataset memory spark  context query partition COPART default hadoop baseline another technique available literature comparison perform define meaningful quality metric experimental query COPART performance exist technique criterion remainder organize preliminary introduces notion useful understand contribution approach context partition discus detail  propose partition technique CoPart partition technique COPART partition technique evaluation illustrates experimental confirm goodness propose approach exist technique finally related discus related conclusion summarizes obtain proposes future motivate tourist scenario described introduction dataset structure       assume dataset chronological depict apply default partition technique available hadoop essentially subdivide file scan sequentially file inside split threshold byte tourist scenario obtain split contains contiguous temporal attribute attribute average tourist arena split identify involve perform operation split actually data related arena clearly toy  involve datasets split exceeds available node possibility reduce split prune technique allows reduce sequential perform default partition perform hadoop image moreover split related arena split amount split split obtain instantiate task indeed parallel task scan split perform complex computation parallel computation overall duration duration task improve global performance prevent presence task namely balance amount preliminary preliminary definition formalization context aware partition notion dataset schema context isolated definition dataset dataset schema attribute belonging domain denote dataset schema collection   dataset mention motivate contains tourist PoIs dataset characterize schema       timestamp integer latitude longitude finally   component denote notation    component subset schema specify without listing attribute instance    latitude longitude definition context dataset schema context analysis subset attribute attribute compose context analysis refer dimension analysis context defines dimensional dataset distribute reference motivate context analysis define instance tourism trend identify context  refer entrance timestamp timestamp latitude longitude complex context analysis compose dimension dataset generic partition operation split definition partition dataset partition collection subset  subset split context define dimensional inside split dimensional   therefore split intend dimensional moreover portion dimensional define portion dimensional define manipulate classical spatial operation topological relation define topology apply clarify concept instance context   dimensional exemplify define subdivision uniform grid grid identifies subset collection subset partition dataset dimensional image definition minimum bound volume schema context minimum bound volume  define minimum dimensional cube enclose context  compute context attribute minimum maximal denote        compactly tuple   ùëêmax  split  mbv enclose dimensional depict mbv entire dataset mbv partition technique define dataset context distinguish disjoint overlap partition inside split conversely split overlap partition split split adjacent overlap  partition approach define dataset interested context aware namely inside split correlation context attribute definition context aware partition dataset schema context partition context aware respect context defines spatial subdivision dimensional subdivision compose dimensional associate split moreover inside split empty intersection associate associate dimensional  spatially dimensional spatial union reference specifically partition dimensional simply associate split mbv boundary   ùëêmax  split   predicate  return  spatially false otherwise situation depict chosen context compose attribute allows subdivide 2D 2D inside coordinate attribute timestamp  associate spatially contains correspond instance arena associate corresponds interval interval another partition technique evaluate balance intuitively partition balance obtain split approximately definition balance partition partition dataset balance accuracy  denotes cardinality split clearly apply dimensional split impact balance obtain partition default technique hadoop byte threshold criterion maximum balance context aware conversely partition technique described related context aware context attribute uniformly distribute unbalanced split demonstrate evaluation easily inside variable COPART partition technique propose balance context aware approach context partition partition dataset respect context approach apply approach classify multi dimensional multi partition definition multi dimensional partition dataset schema context context aware partition  respect multi dimensional dimensional define dimensional generate dimensional grid dimensional grid becomes split  illustrates multi dimensional partition built contextual dimension 2D coordinate partition creates dimensional subdivision reference cube split multi dimensional partition image definition multi partition dataset schema context context aware partition  respect multi recursively reference mono dimensional grid correspond dimension dimension impact partition illustrates multi partition built contextual dimension 2D coordinate establish dimension longitude finally latitude multi partition image difference resides data retrieve context attribute multi dimensional partition directly access subset context dimension conversely technique implicitly imposes dimension analysis particularly suitable contextual attribute uniform distribution continuous temporal dimension sparse skewed distribution inside reference introduce introduction regard tourist predefined PoIs context timestamp latitude longitude partition structure illustrate selective query involve context attribute technique perform contrary selective query poi longitude perform attraction multi dimensional partition directly cube longitude multi partition perform initial prune COPART technique propose belongs multi dimensional partition reference irregularly promotes balance presence uniformly distribute context dimension identification appropriate intuitive efficient evaluate skewness evaluation preform context dimension evaluation dimensional inside dimensional grid purpose extend originally propose spatial domain management generic context dimension illustrate definition counting function  dataset context dimension fundamental notion apply obtain skewness evaluation analysis dimension simply dimension definition counting function dimension dataset attribute belonging domain mono dimensional grid counting function  define    exclude  independently exponent allows account dataset distribution introduction derives concept fractal dimension indeed counting function technique compute fractal dimension fractal intuitively grid counting function conversely counting becomes sum function detect skewness dataset attribute compute specifically skewness dataset attribute reference depends increase definition counting plot dimension dataset attribute belonging domain counting plot plot  versus logarithmic counting plot  analysis attribute dataset observation extend valid multi dimensional context estimate distribution observation finite datasets fractal datasets counting plot reveals trend counting function interval behaves   constant proportionality fix exponent characterizes dataset attribute exponent compute correspond counting plot indeed corresponds slope  approximates  therefore compute linear regression procedure illustrate counting plot tourist dataset introduce introduction poi longitude context dimension plot dimension counting plot   context attribute longitude extract behavior dataset computation slope account presence variation sequence slope maximum chosen image counting plot   context attribute longitude image exponent compute exploit counting plot dimension alone reference contains mono dimensional belongs interval   dim dimension reference embed therefore dim observation dataset attribute characterize counting function  exponent correspond reference descriptor distribution exponent indicator coverage namely allows identify dataset leaf empty exponent identify presence concentration around respect others situation empty data concentration propose exploit knowledge attribute distribution multi dimensional grid balance criterion instead building dimensional grid dimension uniform apply identify attribute distribution potentially extension illustrates detail mapreduce procedure efficiently compute  dataset context COPART partition technique overview COPART partition technique propose performs subdivision dataset basis context analysis specifically dimension analysis define dimensional dimensional dimensional partition split intersect dimension accordance distribution assume contextual dimension objective guarantee partition context aware balance namely split uniform evaluate partition dataset compute contextual dimension technique classify regular grid quad obtain reference recursively fix desire threshold conversely data aggregate nearby desire threshold analysis adopt quad denote QT denote RT uniform denote RG illustration decision COPART decision node label parameter false parameter compute exponent additional parameter obtain analyze empty calculation counting function parameter AEC average empty refining choice partition approach decision image computation dataset contextual dimension resource optimize computation propose approach sample usually generate histogram refer dimensional grid subdivide define histogram inside dimensional cube projection dimensional cube dimension dimensional histogram useful compute counting function specifically histogram compute  histogram built finer grid minimum counting function increase compute progressively aggregate grid avoid explicit computation successive histogram coarser grid mapreduce implementation technique mapreduce implementation counting computation dataset propose mapreduce implementation report algorithm specifically task algorithm responsible construction dimensional histogram grid  grid  mapper preliminary setup phase dataset mbv mbv algorithm initial moreover  initialize counting  dimensional grid computation counting function  corresponds histogram mbv assume initialize configuration parameter label conf notion mbv intersects extend configurable dimension subsequently phase mapper assign split determines intersect cube update correspond counter  cleanup mapper summarize portion histogram histogram compute shuffle phase reduce phase dimension specifically shuffle combine counter related  allows non empty cube potentially reduce amount memory computation reduce phase algorithm projection dimensional cube compute contextual dimension specifically computation counting function grid increase dimension maintain counter contextual dimension grid  cube compute  simply merge cube dimension obtain cube sequence grid built setup phase grid correspond denote  initialize refer projection aggregation histogram  context dimension cube initialization reduce phase responsible processing histogram compute phase project aggregate invocation reduce specific  counter compute phase inside reduce phase cycle sum counter cycle responsible correspond counter grid conditional simply executes projection histogram  contextual dimension conversely conditional aggregate project grid  function   return cube  correspond cube  cube easily compute grid determines aggregation cube update   correspond grid  dimension finally cleanup phase compute contextual dimension subdivision grid variable  contains   contextual dimension denote   sequence       correspond counting plot finally dimension namely fix exponent compute obtain perform linear regression   slope function  average empty compute grid  hint amount empty histogram useful indicator presence empty zone inside reference compute contextual dimension mbv reducer finally function function    computes projection overall dataset mbv dimension detail function  report algorithm contextual attribute function heuristic suitable partition technique moreover built initial grid  counter  already compute reduce phase function parameter useful effective construction partition projection mbv namely dataset variable mbv dataset variable  desire split  average  operation perform  computation indicative partition global split split dimension compute kth dimension finally indicative compute ratio MBR width function simply invokes construction partition contextual dimension partition technique partition regular grid RG quad QT RT construction partition QT illustrate algorithm algorithm return partition dimension variable contains boundary extent reference input variable origin underlie function QT partition aggregate inside reference threshold threshold maximum per sum counter aggregate aggregation threshold  reference recursion inside reference successfully aggregate without violate threshold constraint therefore partition function terminate conversely threshold recursive reference interval recursively split attempt partition violate threshold constraint situation distinguish aggregation threshold reference split dense recursive conversely reference aggregate without threshold recursive construction illustrate algorithm proceeds previous aggregate threshold exceed reference however reference recursively freely aggregate therefore exceed threshold involves recursive reference splitting approach regular grid RG illustrate algorithm fix compute function  function RG simply reference homogeneous fix dimension split function useful compute output  algorithm COPART dimensional grid context dimension COPART actually performs partition input dataset detail COPART illustrate algorithm task receives configuration parameter dimensional partition grid built combine previously compute task split intersect cube writes output compose cube identifier reducer instantiate cube indeed reducer cube simply output cube output reduce task becomes split hdfs partition effective file  contains dimensional split boundary split file intersect evaluation  metric quality metric evaluate context partition technique quality inspire extend propose derive optimization criterion related performance query definition volume context partition compose dimensional cube volume occupy cube  max  min mbv projection dimensional mbv dimension  min  max return respectively minimum maximum mbv dimension indicator partition without actual data definition overlap context partition compose dimensional cube overlap partition     computes volume dimensional cube definition margin context partition compose dimensional cube margin partition margin cube sum dimension     definition load balance context partition compose dimensional cube average standard deviation partition       return split   computes standard deviation split  return average particularly useful evaluate balance partition technique dataset propose technique apply dataset swipe pas  tourist  municipality northern italy dataset contains concern report beside identifier pas poi location coordinate poi entrance timestamp tourist specifically dataset properly  simulate distribution dimension report datasets characteristic experimental methodology performance propose technique evaluate respect quality metric report  metric query operation propose technique traditional multi dimensional partition technique MD definition default random partition RP hadoop baseline mapreduce implementation multi dimensional partition COPART technique multi dimensional  characteristic datasets report EC exponent obtain apply algorithm mapreduce implementation counting percentage empty dimension correspond partition technique apply dimension COPART whereas div obtain subdivision metadata partition technique report  hdfs split index random partition specify index MD split indeed contains almost physically subdivide split hdfs MD technique subdivision generates dimensional cube regular dimension computes split accord dataset split cube generate cube dataset conversely COPART content physical split moreover effectively COPART cartesian subdivision empty partition discard partition characteristic dataset randomly generate query increase overlap reference randomly percentage overlap apply multi dimensional query operation random partition multi dimensional partition COPART quality metric report indicator namely partition without actual data clearly index COPART partition MD technique magnitude index partition overlap margin index COPART technique magnitude finally balance difference partition COPART technique balance partition MD quality metric various partition technique query execution report DS contains dataset OV percentage overlap query reference RP MD COPART denote partition technique denote average average obtain query respectively perform hadoop cluster compose node 8GB ram core query finally summarizes MD COPART technique effectively perform partition datasets beside technique COPART technique distinguish compute counting namely identify partition grid effectively partition data multidimensional grid clearly random technique report apply default hadoop load data inside hdfs perform partition datasets MD COPART technique discussion experimental confirm COPART technique balance partition MD relation quality metric moreover report RP technique load split independently query spatial criterion apply partition moreover perform query comparison perform essentially filter capacity MD partition query overlap almost split finally COPART technique perform selective filter input data split increase query moreover task instantiate MD due performance query significantly improve due MD split described almost data therefore task split almost considerably decrease positive parallel computation moreover prune capability related application partition technique limited due skewness datasets properly capture uniform subdivision another aspect overhead induced application partition technique partition technique rewrite entire dataset obtain split reflect chosen subdivision criterion therefore task increase dataset increase anyway compensate prune capability induced organization dataset query selective moreover mention introduction application partition technique justified query analysis perform dataset increase occasional query perform overhead induced preliminary partition justified consideration report partition datasets actually overhead perform query overhead operation partition average perform query various query selective MD  sensibly RP conversely query becomes selective almost split prune ability partition technique become RP approach instance related dataset overlap RP MD split query almost therefore partition introduces positive decrease overall performance due preliminary operation aspect amount perform MD partition COPART clearly simply  uniform grid compute almost constant conversely COPART technique applies preliminary identify distribution various dimension grid indeed COPART MD performance improvement induces justifies additional particularly amortize subsequent query finally observation partition practical cluster configuration operation cpu particularly regard network therefore simply shift hadoop cluster spark sensitively reduces intermediate operation partition task naturally reduce indeed introduction propose partition technique apply spark context properly subdivide data RDDs without intermediate operation related horizontal partition technique widely database relational technique adopt split purpose load balance mainly improve query processing avoid load unnecessary tuples data era challenge therefore recently investigate graph model ontology nosql ontology meta model overcome heterogeneity source author compute ontology partition subset scenario hadoop mapreduce paradigm  phase avoid unnecessary sub ontology reduce cluster approach graph cluster similarity node mapreduce framework datasets independent chunk data parallel amount byte chunk splitting criterion overcome limitation proposal investigate fragment datasets cluster analysis file author propose technique frequent itemsets mining partition bucket sort data warehouse frequent predicate attribute query apply data mining algorithm query workload frequent predicate attribute hash partition technique without assumption filter query predicate clause sql query contribution address data warehouse partition attribute partition combine obtain multi partition author investigate development hadoop framework parallel construction aim reduce data processing mono dimensional index construction multi dimensional extension available literature instance previous propose partition approach mainly spatial spatio temporal characteristic spatial partition partition grid quad data str str curve curve hilbert curve selection partition technique usually user automatically partition technique dataset distribution ST hadoop considers spatio temporal dimension partition dimension independently multi partition ST hadoop firstly dataset temporal granularity split portion spatial proximity query focus spatial poi poi analysis temporally organize split  considers spatio temporal dimension multi dimensional partition partition 3D cube dimension planar coordinate query focus dimension approach allows selection split useful query challenge impose multi dimensional partition grid dimension amount data balance non trivial task data uniformly distribute generalize proposal relevant dimension contextual dimension similarly spatial temporal coordinate partition multi dimensional exist context partition important compute technique developed orthogonal approach focus partition data efficient computation compute  computation node conclusion mapreduce framework partition dataset independent split critical operation parallelism overall performance directly initial partition technique particularly context application data correlation consequently aggregate filter reduce amount analysis moreover beside context partition technique balance split distribution dataset analysis dimension proposes context partition technique data distribution analysis dimension partition dataset apply propose technique dataset performance exist partition technique highlight difference benefit confirm goodness approach encourage research direction instance regard management multi accuracy data future apply propose technique operation operation certainly application extension dataset specific distribution partition context partition technique improve performance instead cartesian  split allows prune combination surely participate empty mbv intersection moreover extend technique categorical attribute notion context attribute domain predefined relation distance cannot compute frequent correlate infer contextual similarity partition frequent correlate