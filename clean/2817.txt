network attack illegal activity digital resource within organizational network express intention compromise cyber attack individual community anonymous source hacker commonly conduct network attack alter damage steal private data intrusion detection IDS effective technique tackle threat IDS software application hardware device monitor traffic  activity policy breach moreover IDSs deployed environment host network host intrusion detection instal client computer network intrusion detection network IDSs effectiveness however approach false negative rate impact performance  network security detection model memory lstm attention mechanism propose furthermore reduction algorithm namely chi UMAP principal component analysis pca mutual information addition evaluate propose approach NSL kdd dataset experimental demonstrate attention feature pca component performance accuracy binary multiclass classification respectively introduction rapid growth internet establish environment machine around data personal machine become considerably valuable furthermore accept network become expose information steal destruction additionally access internet network omnipresent relatively price cybercriminals network attack nevertheless physical network attack illegitimate private resource target computer information infrastructure personal computer purpose modify destroy steal sensitive data distinguish network attack passive hacker obtain unauthorized access network examine scan vulnerability addition hacker monitor transmission content message nevertheless data active attacker data throughout passive attack compromise computer network furthermore hacker attempt modify delete encrypt damage private data attack affect integrity availability cyber security vigilance priority fortunately computer network security expand adapt reflect threat intrusion detection important intrusion detection IDS vital truly successful security purpose IDS monitor network traffic suspicious activity threat potential threat identify IDS inform manager network intrusion report information usually IP source address intrusion target victim address attack suspect additionally IDS host intrusion detection hids computer instal monitoring analyze application network intrusion detection NIDS implement crucial within network analyze examines network traffic however intrusion detection prone challenge false positive rate false negative rate false positive false alarm occurs IDS flag activity attack activity acceptable behavior despite failure false positive generally  damage network false negative IDS fail detect attack occurs IDS identifies activity acceptable activity actually attack moreover dangerous professional attack contribution consist implement intrusion detection lstm neural network attention architecture furthermore remove unimportant noisy feature decrease classification accuracy reduction algorithm namely chi chi UMAP principal component analysis pca mutual information MI moreover effectiveness approach NSL kdd dataset binary multiclass classification architecture implement research image related intrusion detection pure classification IDS introduce  myriad network security moreover consistent development data increase computational approach intrusion detection furthermore handle data efficiently ability extract representative characteristic raw data therefore researcher focus effort technique powerful IDSs  propose hybrid IDS pre processing phase utilized reduce feature selection enhance shuffle frog leap  algorithm feature classify convolutional neural network gate recurrent neural network  GRNN algorithm  intelligent  gru  detection industrial cyber physical environment gate recurrent gru model addition  detection rate nadam optimizer utilized optimize gru hyperparameters  temporal convolution neural network TCNN iot combine convolution neural network cnn causal convolution TCNN synthetic minority oversampling technique nominal continuous SMOTE NC evaluate bot iot dataset  implement sensitive neural network focal loss focal loss network intrusion detection FL NIDS overcome imbalanced data FL NIDS apply dnn convolutional neural network cnn evaluate approach benchmark intrusion detection datasets suffer imbalanced distribution NSL kdd UNSW NB bot iot  propose paradigm synthesize task variational laplace autoencoder  neural network dnn classifier author evaluate model NSL kdd dataset  propose intrusion detection bidirectional recurrent addition skip connection alleviate vanish gradient improve training effectiveness  employ butterfly optimization algorithm boa meta heuristic perform feature selection multilayer perceptron mlp classifier evaluate capability feature predict attack addition gradient descent GD training metaheuristic particle swarm optimization PSO genetic algorithm GA optimize classification structure approach NSL kdd dataset  developed network intrusion detection implement fog node attack detection datasets UNSW NB NSL kdd khan conceive intrusion detection convolutional neural network algorithm entire network consists hidden layer hidden layer contains convolutional layer pool layer  attack iot network distribute denial service DDoS attack author propose blockchain IDS iot network  khan implement convolutional recurrent neural network  DL hybrid ID framework predicts classifies malicious cyberattacks network  convolutional neural network cnn performs convolution capture local feature recurrent neural network rnn capture temporal feature improve ID performance prediction cse CIC DS dataset  unique generic specific autoencoder model generic learns feature across network intrusion specific feature pertain domain  apply autoencoder  optimization firstly dataset impute fuzzy rough parameter  algorithm handle imprecision datasets exploit fuzzy rough preserve crucial information robust feature extract autoencoder multiple hidden layer finally obtain feature fed backpropagation neural network BPN classify attack NSL kdd UNSW NB dataset  propose hybrid semi supervise machine classifier moreover classifier vector machine decision conduct NSL kdd dataset shen propose ensemble combine extreme machine elm classifier prune algorithm BA optimizer  algorithm feature moreover author combine cuckoo optimization  cluster algorithm approach datasets  ensemble XGB classifier UNSW NB dataset concept memory lstm recurrent neural network rnn artificial neural network data previous fed input however issue rnns gradient vanish explode propagation overcome  schmidhuber introduce memory lstm memory lstm network modify version recurrent neural network information earlier later unlike conventional feedforward neural network lstm data mechanism lstms selectively forget information gate mechanism memory rnns lstm input gate output gate forget gate remembers data random interval gate information lstm suitable myriad task handwrite recognition recognition anomaly detection network traffic IDSs intrusion detection memory architecture image attention mechanism attention mechanism important research decade moreover approach imitates cognitive attention technique category artificial intelligence model processing computer vision however seqseq model neural machine translation domain seqseq approach consists encoder decoder model encoder analyzes input data compress information context vector fix embed decoder compute context vector emit transform output furthermore architecture strength seqseq challenge crucial drawback embed generate vector consequently input data increase becomes model capture information vector inability preserve longer input data tends forget attention mechanism introduce  memorize source neural machine translation construct context vector attention mechanism creates shortcut context vector entire source input shortcut connection adjustable output feature increase important input data fade attention mechanism architecture image input generate correspond output attention mechanism calculates multiple attention marked context vector output apply sum annotation   attention compute normalize output neural network described function capture alignment input output  compute softmax function equation         output feedforward neural network described function attempt capture alignment input output dimensionality reduction dimensionality reduction reduce input data dimensional dimensional input dimension contains characteristic raw data dimensionality statistic dimensionality reduction commonly apply data visualization nonetheless implement machine clarify dataset predictive model moreover input feature usually predictive model task harder curse dimensionality feature harder visualize training furthermore dimensional undesirable raw data sparse feature correlate hence redundant therefore analyze data usually computationally expensive dimensionality reduction algorithm desirable model generalize input data input variable hence desirable reduce input feature component dimensionality reduction feature selection identify relevant feature input variable statistical feature extraction generate dimensional input data data dimension uniform manifold approximation projection UMAP UMAP uniform manifold approximation projection innovative manifold algorithm dimension reduction  moreover UMAP built theoretical framework riemannian geometry algebraic topology furthermore UMAP algorithm arguably conserve global structure performance computational restriction embed dimension addition UMAP manifold application available moreover UMAP consist principal stage graph dimension calculate bandwidth exponential probability binary fix apply stochastic gradient descent sgd optimize dimensional representation improve computation UMAP calculates exponential probability distribution dimension  distance data moreover UMAP  symmetrization dimensional probability calculate   chi chi chi pearson chi statistical theory apply independence variable furthermore chi technique apply feature selection calculate chi statistic feature target variable examine presence relationship feature target target variable independent feature variable away feature variable dependent feature variable significant crucial likewise chi statistic calculate formula actual independent association chi principal component analysis pca principal component analysis pca compute principal component perform basis data sometimes principal component ignore moreover technique feature extraction reduce dimensionality data transform variable contains information furthermore pca extract eigenvectors eigenvalue covariance matrix CM formula  vector covariance feature    mutual information MI mutual information quantity indicates information obtain random variable another random variable furthermore probability theory information theory mutual information MI random variable mutual dependence variable therefore mutual information indicates reduction uncertainty whereas indicates reduction mutual information zero random variable independent moreover mutual information variable denote define shannon weaver        marginals   approach dataset description preprocessing calculation chi data visualization UMAP calculation pca variance calculation mutual information implementation parameter propose model experimental discussion dataset data preprocessing NSL kdd dataset propose address intrinsic issue kdd dataset furthermore NSL kdd therefore data sample filter consequently evaluation research consistent comparable moreover redundant duplicate remove classifier bias towards frequent originally kdd dataset attack normal however NSL kdd dataset contains attack normal reduction rate statistic NSL kdd instance attack image NSL kdd multiple attack contains subclass attack denial service dos dos attack exhaust target shut machine network inaccessible intend user probe attack probe probe attack obtain information target remote local RL RL attack local access target dangerous dos probe attack user UR UR attack access super user normal user attacker access normal user account later gain access exploit vulnerability anything UR attack dangerous attack dataset subclass attack exists data image NSL kdd dataset contains feature categorical feature binary feature discrete feature continuous feature preprocessing phase subclass respective  protocol feature flag feature  feature  feature service feature contains normal dos probe RL UR  transform feature feature afterwards shuffle data reduce variance model remain overfit consequently preprocessing phase feature finally prepared data binary multiclass classification multiclass classification classify instance thereby sort attack normal dos probe RL UR replace feature label feature instead attack binary classification refers classification task label therefore binary classifier ability judge input normal encode label integer normal attack finally dataset generate NSL binary csv  binary classification NSL multiclass csv intend multiclass classification addition normal denial service dos attack majority dataset RL UR rare NSL kdd data widely imbalanced consequently issue affect generalization model reduces classifier efficiency predict minority model fail classification task issue affect mostly multiclass classification distribution normal attack NSL binary csv NSL multiclass csv image dimensionality reduction chi mention chi feature selection technique statistical feature target variable investigate presence relationship feature target furthermore chi important outcome namely chi input feature independent target model training discard chi attribute feature demonstrate impact feature target variable chi generate datasets chi calculus image feature variable output variable independent remove however feature notably chi association variable target variable statistically significant NSL multiclass csv feature therefore variable independent impact feature slightly chi thesis variable impact considerably UMAP UMAP another data visualization dimensionality reduction furthermore employ graph layout algorithm organize data dimensional projection dimensional NSL kdd dataset dimension NSL binary csv NSL multiclass csv UMAP split clearly output category NSL multiclass csv consequently cluster sufficiently data  prospective UMAP projection image pca mention pca technique reduce dataset dimensionality therefore calculate pca covariance NSL binary csv NSL multiclass csv component dataset percentage explain variance image mutual information  earlier mutual information calculates statistical dependence variable assign feature latter impact therefore calculate mutual information NSL binary csv NSL multiclass csv mutual information calculus image implementation evaluation metric implement propose model kera library kera source software library python interface artificial neural network however dimensionality reduction algorithm apply scikit software machine library python program furthermore execute google colab meanwhile preprocessed dataset validation accord respectively model dropout epoch schedule decay epsilon rate optimizer adam sigmoid binary entropy loss activation function binary classification softmax sparse categorical entropy loss activation function multiclass classification addition propose lstm attention model propose lstm attention architecture image evaluate detection model performance propose architecture calculate therefore confusion matrix positive TP negative TN false positive FP false negative FN TP actual attack classify attack FP actual normal classify attack FN actual attack classify normal TN actual normal classify normal furthermore confusion matrix allows calculate metric namely accuracy recall precision misclassification rate metric accuracy ratio correctly predict observation     recall proportion correctly predict positive     precision ratio positive observation     signifies average precision recall      misclassification rate percentage incorrectly classify instance     experimental discussion research implement lstm classifier multiple parameter firstly dimensionality reduction algorithm apply various parameter namely UMAP component chi feature pca apply component whereas mutual information employ feature moreover attention layer verify impact architecture classification task reduction false negative rate furthermore model apply binary multiclass classification binary classification performance model maximum training accuracy accuracy recall precision furthermore summarizes confusion matrix architecture binary classification image confusion matrix propose model binary classification image research classifier attention layer feature accuracy recall lstm model without attention obtain precision meanwhile attention pca model component attention MI feature perform mention earlier false negative rate generally  damage network important metric monitor model attention feature false negative rate attack detect normal initial however accuracy UMAP component infers UMAP attention difficulty attack addition architecture obtains false negative negative rate misclassified respectively multiclass classification display achievement architecture maximum training accuracy accuracy recall precision multiclass classification image attention layer enhance metric false negative rate important metric furthermore attention pca model component accuracy precision recall within others moreover attention MI feature training accuracy addition pca component model predict accuracy accuracy remark impact attention layer model feature layer model classify attack architecture UMAP principally model component furthermore UMAP execute reduction algorithm moreover outline confusion matrix model remark attention pca architecture obtain false negative rate negative rate attention UMAP model component false negative negative rate confusion matrix propose model multiclass classification image however drawback pca component UR attack frequently misclassified normal due attack dataset happens model attention feature model improve analysis experimental model attention pca component multiclass classification previous research performance comparison comparison reference purpose IDSs execution environment data preprocessing approach interpretation model yield significantly model approach adequate prof architecture generalization strength conclusion future effective network attack detection strategy moreover attention mechanism memory lstm classifier conjunction numerous dimensionality reduction algorithm namely chi UMAP pca mutual information furthermore multiple parameter obtain accuracy therefore model attention feature model attention pca component obtain binary multiclass classification respectively outperform others attention pca model detailed feature dataset training phase ability important characteristic network traffic involve anomaly intrusion identify abnormal traffic normal traffic experimental propose attack detection strategy achieves performance previous strategy NSL kdd dataset reduce false negative rate avenue future research identify firstly apply lstm variant evaluate performance complex lstms dimensionality reduction algorithm addition perform analyse propose attention pca model data publish data developed model improve increase detection accuracy offs detection parameter finally overcome unbalanced data UR RL attack NSL kdd dataset multiple numerical data augmentation technique