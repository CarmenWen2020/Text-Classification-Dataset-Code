dissimilarity representation important role recognition due ability capture structural relational information sample dissimilarity embed approach sample vector dissimilarity sample prototype however lack neighborhood preserve fix usually considerable prototype training sample classification accuracy computational complexity address challenge propose creates dissimilarity data manifold purpose locally linear embed LLE unsupervised manifold algorithm goal global structure neighborhood data manifold mapping dimension reduction perform dissimilarity sample prototype manifold geodesic distance metric geodesic distance metric structure preserve compute LLE neighborhood graph finally latent model lsm apply reduce dimension euclidean latent challenge resolve evaluate representation dissimilarity classifier namely knn vector machine svm apply datasets euclidean non euclidean demonstrate propose approach classifier outperform dissimilarity accuracy runtime introduction dissimilarity embed mapped vector difference characteristic dissimilarity metric non metric euclidean non euclidean symmetric asymmetric research important firstly completes feature representation secondly bridge statistical structural approach recognition challenge embed prototype selection approach selection strategy prototype significant impact reduce computational complexity dissimilarity dimension embed subsequently improve classifier performance another significant lack attention data structure preserve sample construct embed dissimilarity contribution prototype manifold data structure reduce dimension complexity propose dissimilarity propose prototype fix sample sample specific prototype manifold sample difference member prototype dimension propose dissimilarity reduce latent model prune dimension dissimilarity reduce likely computational complexity decrease performance classifier accuracy runtime improve organize related describes related background knowledge explanation LLE geodesic distance latent model propose propose approach fully explain propose experimental discussion evaluation datasets evaluation scenario analyze finally conclusion summarizes proposes guidance future related  propose compute difference structural data feature representation useful approach conspicuous researcher pseudo euclidean propose    research eventually introduce distance dissimilarity representation substitute feature representation dissimilarity  structural data vector traditional algorithm apply dissimilarity described bridge structural statistical approach recent dissimilarity apply classification image spectrogram handwritten digit radiological image processing detect  disease classification biological array microarray data 3D streamlines brain spectrum representation series classification series classification graph representation classification nowadays model pioneer surveillance application achieve performance reidentification dissimilarity approach dissimilarity representation identify difference source target capture video dissimilarity loss function optimize gradient descent apply identification prototype selection important role reduce dimension dissimilarity prototype selection approach diverse sample prototype sample  propose prune prototype random     genetic algorithm prototype selection generate prototype structural data principal component analysis pca reduce dimension dissimilarity genetic algorithm GA apply approximate dissimilarity propose prototype generation estimate optimal prototype algorithm organize neural network generates reduce training sample classifier informative recent approach prototype selection apply multi label data classification click fraud detection generate business model propose imbalanced dataset applies sample technique balance dataset relevant sample chosen prototype reduce training novel prototype approach propose modify version zero shot learns prototype unseen via training classification model approach efficient approach prototype semantic information previously prototype constant sample sample necessarily member prototype dissimilarity therefore propose define dynamically unevenly sample sample prototype dissimilarity data structure neighborhood sample manifold limited member goal framework reduce complexity dimension achieve classification performance runtime data belong difference closer dissimilarity vice versa likely sample distinct construction classifier justified commonly classifier dissimilarity knn linear svm spite existence performance classifier knn classifier widely classifier simplicity behavior metric therefore knn svm classifier chosen evaluate propose background knowledge locally linear embed LLE algorithm recognizes fundamental structure manifold reduces dimension LLE nonlinear eigen vector preserve local neighborhood sample sample dimension reconstruct sample linear combination obtain optimal  minimize equation neighborhood graph construct    optimal  minimize equation embed vector dimension obtain   advantage simplicity implementation escape local minimum mapping dimensional data coordinate dimension faster rate calculate eigenvalue matrix  due zero geodesic distance graph theory sequence vertex vertex unweighted graph graph sum distance vertex shortest geodesic distance undirected graph accord LLE manifold LLE manifold assume vertex euclidean distance adjacent vertex LLE neighborhood graph image compute geodesic distance vertex  equation    shortest distance approximately geodesic distance  latent model lsm latent model lsm propose estimate similarity node connectivity social network model node  input network embed unseen latent  latent characteristic euclidean traditional classification algorithm perform dimension initial input network dimension model dimension reduction probability communication  node network depends euclidean distance latent model initialization latent  initialize randomly normal distribution zero variance  inference maximum posteriori estimate hidden model equation estimate latent variable input network latent       estimate hidden variable gradient descent optimization definite iteration converges local optimum  estimate optional unless analyze latent estimate connectivity probability  node network depends euclidean distance latent calculate probability  compute poisson probability distribution function   propose framework propose illustrate consists approach described algorithm propose data representation classification scheme image algorithm locally linear embed LLE algorithm neighborhood preserve manifold algorithm data manifold input matrix  contains training sample sample training dimension sample output matrix  sample dimension embed sample LLE algorithm consists described detail locally linear embed LLE algorithm undirected graph construct accord data manifold obtain LLE algorithm embed LLE manifold assume vertex  euclidean distance  geodesic distance matrix compute algorithm consists define prototype construct dissimilarity geodesic distance matrix sort ascend sample manifold define prototype sample farthest sample  dissimilarity matrix  diagonal zero default entry distance sample farthest manifold matrix  euclidean distance sample manifold  compute  prefer initial sample  dimension reduction dissimilarity construct manifold embed         algorithm latent model lsm simplify reduce dimension dissimilarity latent dimension training sample initialize randomly zero variance loop user define iteration maximum posteriori estimate optimal latent  implement edward library python program augment dissimilarity obtain inner   equation    finally classifier knn svm matrix  classify query mapped augment evaluate accuracy runtime classification performance measurement experimental discussion data propose limited euclidean non euclidean data dissimilarity evaluate approach sample dissimilarity datasets classification california irvine uci machine repository iris wine breast cancer   radar signal image optical recognition handwritten digit usps united  service mnist mixed national institute standard technology standard data handwritten digit recognition chosen evaluate approach image usps feature euclidean tangent chosen construct dissimilarity usps data mnist handwritten digit image pixel information datasets description datasets performance measurement accuracy  performance evaluate classification performance propose approach report standard deviation fold validation evaluation ratio correctly classify sample positive plus negative sample  another metric accuracy calculate precision recall abbreviation positive false positive false negative identify     addition efficiency propose evaluate runtime runtimes obtain laptop intel core cpu ghz GB ram evaluation scenario scenario evaluation propose approach evaluate propose framework dissimilarity accord propose algorithm predefined prototype dataset construct embed dimension latent classifier knn linear svm polynomial svm evaluate accuracy runtime dissimilarity propose accuracy runtime dissimilarity define DS sample training representative representative training DS random sample randomly representative DS  random sample representative evaluate lsm phase classifier dissimilarity  without dimension reduction mapping latent impact lsm dimension reduction performance classifier recent classification performance propose recent publication accuracy datasets detail described recent approach parameter propose parameter dataset LLE manifold LLE latent dimension lsm dimension iteration estimation lsm lsm iteration fold validation fold evaluation scheme sample manifold prototype propose manifold optimal LLE LLE define approach introduce parameter tune trial error evaluate propose framework described previous locally linear embed LLE algorithm data manifold LLE embed neighborhood graph optimal LLE embed neighborhood graph image LLE embed neighborhood graph mnist data due sample ambiguous manifold feature mnist LLE manifold image compute geodesic distance undirected graph construct obtain LLE manifold graph fix report accuracy runtime propose iris dataset numerical sample manifold prototype construct dissimilarity  manifold linear svm maximum accuracy achieve propose manifold accuracy classifier dissimilarity prototype evaluation propose iris dataset accuracy tenfold validation denote italic  evaluation propose iris dataset runtime demonstrates classification error curve propose versus prototype sample manifold evaluation data optimal prototype dataset classification error propose versus prototype evaluation datasets image dissimilarity average accuracy propose dataset average dissimilarity initial dataset numerical parenthesis demonstrate optimal prototype classifier dataset random prototype DS random DS  optimal prototype propose classification accuracy propose dissimilarity standard deviation classification propose dissimilarity demonstrate comparison propose dissimilarity average accuracy respectively classification accuracy propose dissimilarity evaluation datasets image average classification accuracy propose dissimilarity evaluation datasets image evaluate lsm phase propose evaluate accuracy runtime without incorporate lsm approach impact importance lsm classifier efficiency average accuracy propose without lsm datasets superiority propose without lsm due lsm reduce dissimilarity classification accuracy propose without lsm comparison propose without lsm average accuracy respectively average classification accuracy propose without lsm evaluation datasets image classification accuracy propose without lsm evaluation datasets image runtime report propose classification comparison demonstrate clearly classification runtime mnist dataset comparable datasets due report classification runtime propose without lsm average classification runtime propose without lsm evaluation datasets image classification runtime propose without lsm evaluation datasets image recent approach classification accuracy propose datasets propose stage algorithm generate prototype structural data dissimilarity structural data embed dissimilarity prototype generation apply  introduce dissimilarity performance knn classifier transform iris  datasets structure sparse selection  propose novel prototype selection propose outperforms datasets besides runtimes report sect denotes impact effectiveness propose dissimilarity representation classification performance accuracy percent propose recent approach report performance report conclusion dissimilarity vector dimension difference sample training member prototype therefore prototype selection strategy prototype important effective however previous prototype identical sample necessarily member prototype sample data structure manifold prototype selection mapping dissimilarity therefore propose augment dissimilarity manifold increase classification performance neighborhood sample manifold propose data manifold linear locally embed algorithm LLE undirected graph construct accord data manifold obtain LLE algorithm geodesic distance matrix compute sample manifold geodesic distance member prototype propose construct dissimilarity sample manifold member prototype effective factor reduce computational complexity latent model simplifies reduces dimension dissimilarity embeds sample euclidean latent dimensionality construct dissimilarity finally svm knn classifier augment dissimilarity propose evaluate classification accuracy runtime advantage propose prototype dynamically unevenly sample sample prototype manifold dissimilarity reduce computational complexity propose framework comparison without lsm classification runtime indicates positive lsm model complexity reduction augment dissimilarity propose framework outperforms accuracy approach scenario linear svm classifier propose achieve accuracy algorithm estimate embed dissimilarity latent consume therefore alternative algorithm future improve runtime propose lsm optimal latent dimension iteration estimation greatly influence efficiency model classifier dimension reduction mapping technique latent future abbreviation LLE locally linear embed lsm latent model knn svm vector machine pca principal component analysis GA genetic algorithm maximum posteriori uci california irvine usps united  service mnist mixed national institute standard technology  structure sparse selection