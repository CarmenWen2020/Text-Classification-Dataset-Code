machine algorithm efficiently intrusion detection datasets detect network traffic capable  information cse CIC IDS dataset investigate ensemble feature selection performance classifier cse CIC IDS data instance publicly available realistic attack contribution around research feature selection impact performance classifier receiver operating characteristic curve auc destination categorical feature significantly impact performance lightgbm catboost auc choice classifier decision DT random RF naive bayes NB logistic regression LR catboost lightgbm xgboost significantly impact performance auc research affirmative valuable practical information development efficient intrusion detection model knowledge ensemble feature selection technique cse CIC IDS dataset introduction cse CIC IDS refer dataset throughout text intrusion detection dataset normal anomalous instance network traffic machine model efficiently cse CIC IDS detect network traffic capable compromise information dataset recent iteration  scalable project realistic datasets cse CIC IDS data originate extensive network victim attack machine yield aggregate instance attack traffic percentage distribution instance cse CIC IDS traffic distribution dataset binary imbalance non attack instance attack instance dataset distribute csv file downloadable footnote file consist independent variable remain file consists independent variable machine greatly facilitate feature cse CIC IDS machine algorithm typically outperform traditional statistical classification task however threshold setting learner appropriately imbalanced data render algorithm inefficient distinguish majority minority highly imbalanced environment learner consequently fail properly model distribution positive minority become bias negative majority therefore employ metric safeguard outcome metric receiver operating characteristic roc curve auc suitable evaluate classifier performance imbalanced datasets imbalance noticeable data majority instance disproportionately environment ensemble feature selection approach tailor improve classifier performance relevant subset variable cse CIC IDS worth feature selection data clarity reduces computation requirement utilize supervise filter feature rank technique stage ensemble approach selection feature technique specific data classification challenge learner dataset volume variety velocity variability complexity traditional difficulty handle data volume diversity data format data originate source data inconsistency filter important data data link transformation classifier performance training learner decision DT random RF naive bayes NB logistic regression LR catboost lightgbm xgboost learner coverage machine ML model favorably performance classifier classifier development metric knowledge comprehensive analysis cse CIC IDS date uniquely dataset investigate ensemble feature selection performance classifier contribution define response research feature selection impact performance classifier auc destination categorical feature significantly impact performance lightgbm catboost auc choice classifier DT RF NB LR catboost lightgbm xgboost significantly impact performance auc research valuable practical information development efficient intrusion detection model remainder organize related overview literature manipulates feature cse CIC IDS methodology describes cleaning dataset unique ensemble approach feature selection classifier metric training procedure classifier discussion discus empirical conclusion concludes summary suggestion related future related highlight modify feature cse CIC IDS improve classification however knowledge none ensemble feature selection approach address imbalance dataset hua undersampling embed feature selection approach lightgbm classifier undersampling randomly remove majority instance alter distribution data cleaning stage useless feature remove modify feature label convert integer label encode addition lightgbm learner evaluate research vector machine svm RF adaboost multilayer perceptron mlp convolutional neural network cnn naive bayes learner implement scikit tensorflow data ratio xgboost perform feature selection lightgbm performance optimum accuracy sample feature accuracy precision recall respectively lightgbm training classifier another related research learner evaluate datasets cse CIC IDS ISOT http botnet botnet classifier ISOT http botnet dataset contains malicious benign instance domain dns traffic learner RF DT NN naive bayes svm feature selection perform various technique feature importance RF subsequent feature selection cse CIC IDS independent attribute ISOT http destination source transport protocol feature model implement python scikit botnet instance training fold validation apply remain botnet instance optimization grid algorithm regard cse CIC IDS RF DT learner accuracy accuracy precision recall learner RF DT learner accuracy ISOT http RF DT related apply cluster feature selection cse CIC IDS unsupervised involves online detection autoencoder classifier autoencoder encodes data usually dimensionality reduction preprocessing infinity nan replace data subsequently sparse dense matrix normalize regularization sparse matrix majority dense matrix majority non zero model built within python environment feature RF data ratio affinity propagation AP cluster algorithm subsequently training dataset feature subset autoencoder recall rate attack propose model another autoencoder model  attack model recall propose model evaluate auc metric attack yield detection author model faster detection    adopt ensemble model approach learner integration classifier learner RF gaussian naive bayes DT quadratic discriminant analysis gradient boost logistic regression model built python scikit preprocessing sample infinity remove actually repetition header remove dataset training validation ratio feature selection technique important feature predictive model perform spearman rank correlation coefficient chi selection feature evaluation learner feature gradient boost logistic regression DT emerge performer ensemble model accuracy precision recall model respectively along auc finally  CICIDS cse CIC IDS investigate efficiently intrusion detection dataset generalize CICIDS predecessor dataset performance evaluation author supervise algorithm various DT RF bag gradient boost decision GBDT  adaboost xgboost NN    logistic regression model built scikit xgboost module python author feature feature selection feature attempt normalize feature attribute classifier yield performance xgboost ranked perfect auc  hint overfitting analysis warrant source code hyperparameter max depth learner prone overfitting intrusion detection author conclude model dataset cannot generalize another dataset summary related exhibit shortcoming nearly perfect classification performance typically associate overfitting discover additional shortcoming error preparation destination numeric instead categorical data cleaning ambiguous specification issue regard reproducibility methodology data cleaning remove cse CIC IDS data cleaning stage protocol redundant dst destination mostly contains equivalent protocol destination timestamp learner discriminate attack prediction stealthy attack learner distinguish attack regardless volume stealthy timestamp allows convenience combine datasets compatible experimental framework remove actually repetition header easily remove filter valid label fourth file    csv file dataset file extra ID src IP src dst IP additional negative instance negative fwd header duration iat min negative fwd header extreme extreme skew statistic sensitive outlier zero instance prior machine filter bwd  flag bwd URG flag fwd avg byte bulk fwd avg packet bulk fwd avg bulk rate bwd avg byte bulk bwd avg packet bulk bwd avg bulk rate exclude init byte init byte backward instance negative similarly duration unreasonably zero byte packet infinity nan instance byte packet infinity nan ensemble feature selection data cleaning independent feature cse CIC IDS reduce adopt ensemble approach feature selection ensemble feature selection derive concept ensemble demonstrates combination multiple approach outperforms approach classification instance intuitive concept extend ensemble learner ensemble feature rank technique distinct feature rank integrate rank rank technique generate feature subsequently feature rank technique assign usable feature data feature apply feature rank technique ranked feature decision feature motivate factor feature ranking due hyper parameter tune avoid overfitting maximum depth catboost catboost construct constituent dts feature therefore catboost rank relevant maximum feature ranker employ filter supervise rank technique filter feature rank technique feature statistic calculate variable supervise feature rank technique leverage structure constituent dts ensemble classifier generate feature importance refer ranking feature rank technique filter technique filter feature rank technique information gain IG mutual information gain ratio GR chi CS statistic statistic calculate feature filter feature reduce calculate IG GR statistic info gain info gain ratio function info gain python library calculate CS statistic chi function scikit library employ rank feature dataset function configuration parameter IG GR CS function invoke function accepts array data input employ usable feature dataset source data input array label data input array function return ith rank relative concrete sort decrease sort truncate feature rank technique assigns importance zero feature ranked feature instance catboost assigns importance feature reader reservation applicability IG GR CS categorical numeric feature apply IG GR CS feature selection technique cse CIC IDS network traffic data manner apply technique kdd cup network traffic dataset dataset dataset contains numeric categorical feature therefore comfortable apply filter feature rank technique dataset contains ranking filter feature rank technique feature filter rank technique cse CIC IDS filter feature rank obtain feature model remain feature obtain supervise feature selection technique subsection supervise feature rank technique supervise feature rank technique feature importance RF catboost xgboost lightgbm python library catboost lightgbm xgboost python library RF implementation scikit python library discus implementation RF catboost xgboost lightgbm employ rank technique library classifier initialization constructor function pas configuration option initialization function configuration option classifier function classifier function successfully invoked classifier attribute feature importance feature importance return function filter rank technique previous subsection hereafter refer feature selection technique feature importance catboost lightgbm xgboost RF classifier classifier ambiguous supervise rank classifier random initialization option supervise rank classifier lightgbm initialization option supervise rank classifier xgboost initialization option supervise rank classifier catboost initialization option previous subsection cse CIC IDS categorical feature destination feature dataset hence conclude appropriate encode technique feature outside scope however catboost lightgbm built categorical feature destination candidate rank catboost lightgbm xgboost random supervise rank technique yield feature catboost due implementation detail hyper parameter setting catboost construct dts node sufficient utilize feature training data hence catboost ranking feature feature supervise ranking catboost rank feature cse CIC IDS feature supervise rank technique xgboost random due hyper parameter setting catboost feature cse CIC IDS feature supervise rank technique lightgbm supervise rank technique generate ranking filter rank technique generate remain ranking ranking conduct ensemble feature selection subsection specific feature selection technique feature selection obtain ranking feature selection technique feature ranking hence feature selection technique ensemble feature rank technique refer feature ranking feature ensemble feature selection technique feature contains destination categorical feature learner cannot consume directly feature feature feature exclude destination destination valuable categorical feature usable ranker CS IG GR catboost lightgbm destination disadvantage feature later classifier handle categorical feature perform without destination therefore feature feature selection technique remove destination feature destination cse CIC IDS inspect ranking feature feature feature convention feature selection technique rank technique feature namely feature selection technique destination contains destination destination ranking feature apply feature selection technique ranker feature augment destination feature feature ranking similarly feature feature feature feature manner feature feature feature feature correspond ranking feature feature feature correspond ranking feature hence feature selection technique net feature exclude destination refer feature feature selection feature ranking cse CIC IDS refer feature remove destination feature feature ranking cse CIC IDS refer feature destination feature feature ranking cse CIC IDS refer feature destination feature feature ranking cse CIC IDS refer feature destination feature feature datasets suitable training classifier reader attach significance feature datasets apply feature selection technique another remove destination categorical feature ass impact feature selection datasets contains usable feature dataset feature destination datasets feature feature respectively finally dataset contains destination feature destination subsection review classifier dataset classifier development metric classifier development feature selection datasets input classifier DT RF NB LR catboost xgboost lightgbm DT representation data easily visualize node leaf label observation RF ensemble approach building multiple decision classification calculate combine individual typically majority voting NB bayes theorem conditional probability probability instance belongs naive assumption independence feature LR sigmoidal logistic function generate interpret probability LR linear regression hypothesis predict membership catboost xgboost lightgbm  ensemble dts sequentially catboost boost imposes sample catboost constituent decision xgboost sparsity aware algorithm quantile sketch sparsity quality zero quantile sketch approximate merge prune operation lightgbm gradient sample exclusive feature bundling handle data instance feature sample ignores substantial portion data instance gradient exclusive feature bundling mutually exclusive feature reduce variable discussion feature rank lightgbm catboost handle encode categorical feature automatically advantage destination feature lightgbm catboost pas array feature lightgbm panda dataframe lightgbm destination categorical feature data destination category catboost treat destination categorical feature catboost classifier initialization constructor function feature parameter destination destination feature catboost lightgbm scikit NB classifier categorical data  classifier initialize parameter setting parameter experimentation initialization parameter initialization parameter naive bayes logistic regression constructor classifier lightgbm classifier initialization option xgboost classifier initialization option supervise rank classifier random initialization option supervise rank classifier catboost initialization option supervise rank classifier decision initialization option classifier metric confusion matrix binary classification usually minority majority positive negative respectively related performance metric explain positive TP positive sample correctly identify positive negative TN negative sample correctly identify negative false positive FP error negative instance incorrectly identify positive false negative FN II error positive instance incorrectly identify negative confusion matrix fundamental metric performance metric derive recall positive rate tpr sensitivity    precision positive predictive    specificity negative rate TNR TN TN FP performance metric understand challenge evaluate machine model severely imbalanced data metric explain traditional harmonic precision recall     auc receiver operating characteristic roc curve graphically recall versus specificity across classifier decision threshold curve auc obtain perfect classifier classifier training classifier stratify fivefold validation CV training model label cse CIC IDS label datasets appropriate classifier iteration fold CV classifier catboost lightgbm built categorical feature datasets appropriate catboost lightgbm however optimal encode technique preprocessing scope appropriate NB LR DT RF xgboost datasets destination categorical feature interested model solely destination therefore perform  classifier  appropriate datasets categorical feature therefore destination dataset appropriate  unique combination dataset classifier iteration fivefold CV measurement auc auc report measurement training model various datasets performance metric accord experimental factor perform analysis variance anova outcome anova factor explain variance performance metric perform tukey honestly significant difference HSD factor significantly associate auc outcome anova tukey HSD research report auc catboost lightgbm  respective datasets report anova tukey HSD mention data later performance catboost lightgbm  auc feature dataset destination earlier  datasets numeric categorical feature however appropriate catboost lightgbm datasets consist categorical numeric feature report outcome performance catboost lightgbm auc datasets feature feature report involve catboost lightgbm model data feature feature feature performance catboost lightgbm auc datasets feature feature performance catboost lightgbm auc datasets feature feature performance catboost lightgbm auc datasets feature feature performance catboost lightgbm auc datasets feature feature feature report performance classifier catboost lightgbm DT LR NB RF xgboost datasets feature feature feature feature datasets destination categorical feature classifier available performance classifier auc datasets feature feature performance classifier auc datasets feature feature performance classifier auc datasets feature feature performance classifier auc datasets feature feature performance classifier auc datasets feature feature feature discussion inspect data obtain conduct anova tukey HSD research confidence anova model dependent variable outcome auc independent variable classifier feature selection technique etc factor therefore plot data model anova aid understand grouping tukey HSD identify research feature selection impact performance classifier auc inspect lightgbm model yield auc feature destination feature however feature lightgbm yield auc analogous performance classifier classifier datasets therefore perform factor anova classifier datasets factor auc dependent variable exception anova zero conclude classifier dataset significant factor affect outcome exception involve dataset feature destination feature dataset classifier choice significant report feature destination dataset report instead difference performance classifier otherwise tukey HSD appropriate classifier dataset factor dataset factor feature etc equivalent application feature selection technique impact feature selection classifier choice conduct tukey HSD confidence dataset classifier factor gauge feature selection performance auc influence classifier reflect accord grouping tukey HSD yield significant difference performance auc consists feature selection technique feature classifier feature feature feature feature ideal implies obtain performance dataset however obtain ideal performance classifier feature feature classifier data feature yield adjust tukey HSD difference feature feature cite adjust another performance classifier feature performance classifier feature cse CIC IDS however feature selection technique conclusion plot auc grouped classifier datasets destination tukey HSD indicates lightgbm random xgboost catboost decision logistic regression naive bayes factor significantly image plot auc grouped feature selection technique datasets destination tukey HSD indicates feature selection technique feature image plot grouped classifier datasets destination tukey HSD indicates lightgbm random xgboost catboost decision logistic regression naive bayes image plot grouped feature selection technique datasets destination tukey HSD indicates feature image catboost lightgbm built categorical feature therefore deem scope address encode technique destination categorical feature dataset perform ass impact feature selection research conduct anova classifier feature selection technique impact auc classifier feature selection technique factor nearly zero anova conduct tukey HSD factor yield performance plot grouped factor analyze anova HSD depict plot auc grouped classifier datasets destination tukey HSD indicates factor classifier image plot auc grouped feature selection technique datasets destination tukey HSD indicates feature selection technique significantly technique image plot grouped classifier datasets destination tukey HSD indicates factor classifier image plot grouped feature selection technique datasets destination tukey HSD indicates feature selection technique significantly technique image performance lightgbm catboost feature performance lightgbm catboost feature performance grouped feature selection technique model feature tukey HSD yield auc approximately model feature tukey HSD yield auc difference likewise catboost lightgbm model feature feature tukey HSD adjust model data feature model feature difference research ensemble feature selection technique yield performance feature specifically variant technique classifier feature criterion feature selection yield performance feature research destination categorical feature significantly impact performance lightgbm catboost auc research classifier catboost lightgbm factor datasets destination feature another factor perform anova grouped factor associate classifier dataset factor anova zero therefore tukey HSD appropriate report plot auc grouped classifier tukey HSD indicates classifier significantly image plot auc grouped dataset contains destination feature tukey HSD indicates destination significantly image plot performance grouped classifier tukey HSD indicates classifier significantly image plot grouped dataset contains destination feature tukey HSD indicates destination significantly image auc dataset destination anova HSD confirm destination significant factor performance model identify attack stability enable research research destination feature significant impact performance auc research choice classifier RF DT NB LR catboost lightgbm xgboost significantly impact performance auc research anova conduct classifier significant factor associate classifier factor perform tukey HSD classifier grouped performance grouping enable conclusion drawn choice classifier impact outcome refer grouping report conduct tukey HSD closer HSD classifier significantly performance report classifier performance lightgbm RF xgboost auc significantly however HSD indicates classifier distinct tukey HSD report classifier important factor outcome auc lightgbm consistently HSD identifies auc research choice classifier significantly impact performance conclusion tukey HSD depict research feature selection technique feature performs feature demonstrate ensemble feature selection technique classifier detect anomaly cse CIC IDS training model reduce feature consumes compute resource conclusion anova tukey HSD research research destination useful feature classifier hence conclude encode classifier classifier handle categorical feature automatically research reveal lightgbm performs classifier cse CIC IDS destination feature lightgbm limited catboost lightgbm destination categorical feature opportunity future research investigate another classifier yield performance conjunction technique encode destination opportunity evaluate classifier performance network intrusion detection datasets another  deserves attention technique address imbalance random undersampling rus abbreviation anova analysis variance AP affinity propagation apt application program interface auc receiver operating characteristic roc curve auc receiver operating characteristic curve cnn convolutional neural network CS chi CV validation dns domain DT decision FAU florida atlantic FN false negative FP false positive GBDT gradient boost decision gpu graphic processing GR gain ratio HSD honestly significant difference IG information gain NN LR logistic regression ML machine mlp multilayer perceptron NB naive bayes NSF national foundation ODT oblivious decision RF random roc receiver operating characteristic rus random undersampling svm vector machine TN negative TNR negative rate TP positive tpr positive rate TS target statistic auc receiver operating characteristic curve LR logistic regression NB naive bayes RF random DT decision