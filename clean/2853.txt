article proposes parallel performance model workload spark data application hadoop cluster propose model predict runtime generic workload function executor without necessarily algorithm implement model serial boundary 2D arrangement executor empirical data various workload empirical data obtain hadoop cluster spark hibench workload wordcount svm kmeans pagerank graph nweight runtime emerge executor workload runtime longer executor phenomenon predict model  equation model explains performance amdahl prediction gustafson equation propose model achieve workload data metric accuracy fitting empirical data propose model advantage machine model due simplicity data useful practitioner data predict runtime specific application analyse model limited executor fix introduction apache spark alternative source distribute compute platform mapreduce data processing spark introduces resilient distribute data rdd fault tolerance processing scalability improve performance moreover spark various data analysis module spark sql mllib graph execution spark application significant factor processing user allocate multiple resource efficient memory allocation adequate data partition optimize cluster configuration desire execution cluster user administrator benefit accurate model prediction runtime recent researcher publish prediction performance data processing platform spark virtually publication machine model predict runtime performance characteristic however machine model sample accurately moreover model interpolate performance data sample dense machine model effective necessarily explain performance mitigate issue propose  model  non  portion generic algorithm  algorithm efficiently parallel machine cluster parallel performance depends mostly algorithm operates algorithm  parallel coin meaning extra  speedup proportional processor available speedup superlinear algorithm parallel unfortunately algorithm optimistic speedup degrade performance algorithm extra communication operation inherently serial understood amdahl publish finding equation become amdahl later gustafson amdahl performance amdahl assumption fix portion  cannot  gustafson alternative assumption explain perform speedup amdahl equation predict amdahl gustafson generalise model predict performance assumption target understand relationship execution runtime executor spark knowledge none previous model data workload indeed propose technique significantly researcher cluster user operator administrator moreover propose model implement hadoop physical cluster academic research helpful administrator architect data engineer predict parameter specifically executor spark hadoop physical cluster model insight  non  portion generic model precise generic equation cluster rely limited contribution effective model introduce explain various hibench performance function executor model achieves accuracy workload treat implementation without knowledge internal working communication executor involve via hdfs accomplish extensive experimental spark application physical cluster environment various aspect cluster performance overhead  workload efficiency fix data executor propose model scalability average execution organise apache spark environment describes apache spark environment related review related performance prediction spark hadoop cluster model 2D plate parallel application  propose model 2D configuration executor discus motivation model experimental setup experimental setup detail obtain empirical data finding analytical model workload equation model data finally conclusion conclusion discussion future development model apache spark environment spark numerous advantage developer data application apache spark propose important concept resilient distribute datasets rdd acyclic graph dag abstraction resilient distribute datasets rdd increase data efficiently application rdd efficient fault tolerance fault tolerance rdd interface coarse grain transformation filter various data item dag scheduler express dependency RDDs spark dag scheduler graph stage task task launch cluster dag reduce stage express dependency fully technique perfectly accelerate spark iterative application faster hadoop circumstance normal achieves performance faster mapreduce multiple source fault tolerance mechanism cached parallel operation besides data multiple partition spark consists worker node multiple interactive spark hadoop cluster RDDs hdfs format hadoop text sequence file spark execute multiple physical task stage spark trigger dependent stage submit execute parallel spark executes submit stage    intermediate stage output data input data stage dag  stage assigns function multiple partition target rdd spark executor worker node cluster executor receives input file executor active entire workload multiple cpu thread task parallelly executor thread vital role performance manager cache storage user program executor allocate memory storage RDDs spark hadoop cluster apache yarn another resource negotiator framework resource management schedule monitoring  apache  source manage monitor profile individual workload hadoop cluster typical spark cluster architecture typical spark cluster architecture image related discus relevant publish performance prediction hadoop cluster spark simulation prediction model propose  wang model simulates execution input data execution trace predict performance execution stage separately propose standalone cluster mode hadoop distribute file hdfs default MB setting evaluate framework application claimed model capable predict execution individual stage accuracy  singh address spark platform challenge data data increase spark performance reduces significantly overcome challenge ensure perform propose technique namely analytical approach technique multi linear regression mlr quadratic vector machine svm accuracy prediction model analytical approach predict application execution spark parameter selection complex identify suitable parameter impact application execution data cluster therefore carefully parameter application execution analyze performance sensitivity parameter important feature selection integrate performance prediction model optimization algorithm performance improvement finally summarize machine algorithm resource data collection  conduct benefit analysis supervise machine model spark performance prediction  investigation technique technique ML algorithm linear regression LR decision DT random RF regularize linear regression RLR technique capture feature execution approach machine algorithm outperforms others chose model technique evaluate individual scenario propose methodology model spark runtime prediction model model model focus impact data platform configuration setting overhead network bandwidth allocate resource model methodology predict runtime consideration previous factor application parameter achieve accuracy average actual runtime application model methodology spark runtime predict accurately cheng propose performance model adaboost stage spark runtime prediction classic projective sample data mining technique projective sample advanced sample reduce model overhead claimed projective sample optimum sample without prior assumption configuration parameter enhance entire prediction utility  propose data driven workflow approach DAGs execution predict spark operation approach combine analytical machine model DAGs prediction accuracy propose approach technique nevertheless approach iterative machine workload approach considers sql query propose trial error methodology previous shuffle serialization investigate impact spark parameter address core spark executor impact maximise performance improvement parallelism partition per participate core crucial role focus parameter related shuffle compression serialization iterative technique configuration upper completion investigate methodology efficiency due iterative methodology decrease significant achievement yield conclude methodology robust concern configurable parameter propose approach spark execution prediction prior execution application amdahl approach capable predict execution within approach reference file data resource setting predict execution relatively data limited application setup complex dependency parallel stage propose technique accuracy average prediction error workload linear regression LR limitation validate approach node cluster cluster environment  shah extend previous propose alternative model  execution prediction limited cluster resource setting subset input data analyse execution checked internal dependency internal stage observation data partition executor impact data critical role therefore workload data claimed apart naive prediction technique model significant improvement overall prediction error workload amdahl gustafson important benefit processor processor executor  although distinction context spark executor cpu resource allocate via physical node generally executor launch physical node physical node cpu core align physical node executor core analogous processor per executor however executor core within physical node executor variable model executor core core obviously parameter equation equation remain valid model simplification valid executor within node memory communication faster communication executor physical node communication various executor  parallel implication communicate executor proportional executor executor executor however portion  consequence parallel performance linear speedup achieve executor CPUs core node decline sharply amdahl generic equation predict speedup factor parallel application function processor equation considers application workload inherently serial  equation speedup factor nexec nexec nexec nexec processor executor percentage cannot  serial characteristic speedup increase factor amdahl various percentage serial image practise increase executor economical ideal executor target improvement speedup factor serial percentage depends entirely algorithm platform serial portion networking influence percentage perfect linear speedup processor workload predict runtime multiple processor runtime  hypothetical runtime executor executor runtime decrease additional executor serial amdahl various percentage serial image runtime decrease sharply increase executor runtime converges infinite executor pessimistic potential parallel amdahl publication gustafson argue percentage serial rarely fix amdahl percentage serial detrimental potential speedup executor gustafson practical serial portion increase serial portion communication establish initial parameter simulation data independent algorithm gustafson various percentage serial image version amdahl speedup equation gustafson speedup equation nexec nexec nexec runtime  nexec speedup serial portion gustafson curve plot runtime trend executor gustafson various percentage serial image gustafson optimistic amdahl indeed gustafson speedup algorithm achieve however application algorithm implementation pessimistic amdahl attempt  algorithm aware performance consequence executor hibench workload category model 2D plate parallel application discus model parallel application serial portion grows faster literature review related performance parallel application dependent executor CPUs core communication wordcount workload executor image workload behaviour runtime predict amdahl gustafson wordcount gain performance executor executor difference brings gain performance clearly appreciate rank workload executor image however workload behave executor performance executor performance degrades extent runtime longer executor pagerank hibench performance depict analyse realise model runtime application performance executor unknown happens communication parallel portion grows faster benefit additional executor model function executor serial portion responsible otherwise perfect  portion important hadoop cluster data scatter node sometimes node data available node hdfs responsible hadoop cluster communication additional application data compute another node update computation communication performance driven networking infrastructure available cluster typically communication node parallel computer aka broadcasting aka reduction distinction hadoop cluster related hdfs communication important workload access data location data anywhere node cluster replication factor default communication factor scope refers specifically application communication data compute node computation another node  parallel application communication node purpose network infrastructure access data via hdfs portion data node application compute 2D plate model extra communication executor independent hdfs access data moreover delayed executor computation executor boundary data available building model concept 2D plate concept simulate distribution simulation parallel machine simulation 2D plate compute function neighbour  serial parallel runtime runtime   application executor nexec executor  extra communication executor additional  zero extra communication runtime inversely proportional executor crucial aspect  without knowledge internal implementation algorithm application model correctly assume serial grows function executor approximate function  2D plate algorithm assumption communication boundary 2D plate 2D plate compute iteratively computation interdependent neighbour neighbour 2D plate model executor image 2D plate model executor image communication entire compute executor executor communication activity boundary boundary executor communication boundary extra runtime due networking communication node boundary proportional boundary executor image executor another executor sum boundary executor executor generalise executor however smooth growth 2D plate  therefore nexec restrict sequence moreover assume sufficiently offset difference executor data exactly divisible nexec simplistic model communication necessarily homogeneous executor executor 2D plate communication executor plate possibility assume executor neighbour executor equivalent 2D plate fold cylinder dimension simultaneously extra boundary per plate homogeneous communication amongst node image apparent boundary grows rate nexec executor boundary boundary grows nexec boundary versus nexec function serial exactly amount communication inside hadoop cluster complex executor communicate data via hdfs node parallelism imply communication node communicate without interfere communication parallel serial portion executor misalign executor temporarily compute data neighbour hadoop distribute file hdfs assumption growth boundary proportional communication serial portion proportional width per becomes runtime  nexec constant assume proportional entire plate simplify runtime  nexec simplify runtime  nexec fix replace constant replace constant runtime   model explain behaviour peak performance executor degrade runtime executor visualise growth serial portion examine constant curve resemble amdahl curve serial portion faster executor runtime longer executor influence boundary correspond curve amdahl gustafson speedup rapidly addition executor another aspect model regard assumption runtime proportional algorithm complexity linear relation quadratic considers width height runtime completely function information internal implementation algorithm function growth runtime executor analogous complexity algorithm function growth communication executor consequently predict runtime constant model growth runtime communication boundary function nonetheless model runtime prediction forecasting ideal processor various workload model empirical data equation various image experimental setup experimental cluster dedicate networking infrastructure dedicate switch cluster deployed experienced academic previously built  cluster optimise performance infrastructure isolated machine reduce unwanted competition network resource cluster configure node node cluster hardware configuration schematic experimental hadoop cluster hadoop cluster image performance evaluation application hibench benchmark suite hadoop program evaluate cluster performance benchmark workload spark performance benchmark workload category micro benchmark web graph machine wordcount workload dependent data occurrence text sequence file function sort input file text input data generate  nweight iterative graph parallel algorithm implement spark graphx pregel algorithm computes association vertex hop away input data consist pagerank rank algorithm numerical ranked par vote vote link normally link pagerank data source generate web data hyperlink zipfian distribution input data consist sample popular algorithm data cluster input data generate  uniform distribution gaussian distribution input data data sample vector machine svm standard classification task workload implement spark mllib input data generate svm  consists sample spark  workload cluster parameter configuration spark parameter selection tune challenge task parameter impact performance cluster hence configuration parameter investigate accord application data cluster architecture validate cluster impactful parameter crucial factor performance generally spark configuration parameter categorize application runtime environment shuffle behavior spark user interface UI compression serialization memory management execution behavior execution metric networking schedule barrier execution mode dynamic allocation SparkSQL  thread configuration parameter closely related spark performance default default tune configuration parameter chosen firstly parameter impact spark runtime performance runtime environment shuffle behavior compression serialization memory management execution behavior performance aspect ultimately performance spark application generally selection extensive parameter configuration memory distribution optimization task parallelism data compression noteworthy phenomenon input rdd partition allocate memory affect rate data spill disk core assign executor concurrently resource prediction model significantly affected without sufficient memory partition secondly impact parameter occupy available resource cpu disk memory spark hibench application characteristic application consist stage acyclic graph dag architecture operation application communication spark shuffle serialization deserialization aggregation spark configuration parameter workload application characteristic finding analytical model obtain workload executor accuracy reproducibility average runtime graph file spark server execute script execution fitting metric data acquire workload hadoop cluster parameter parameter equation  fitting function empirical data equation parameter compute series compute fitting metric compute runtime equation empirical data adopt coefficient determination compute equation   sum residual  sum relative data perfect fitting  generally closer fitting firstly curve fix fitting 2D plate model wordcount image fitting 2D plate model nweight graph image fitting 2D plate model svm image model empirical data reasonably wordcount graph curve smooth runtime executor grows svm model nicely performance peak executor exactly model explains workload serial growth closely workload pagerank kmeans model runtime relatively workload overhead related hadoop cluster  model fitting 2D plate model pagerank image fitting 2D plate model kmeans image workload equation boundary grows rate proportional nexec adjust function exponent runtime   important interestingly fitting via  data accurately achieve maximum MB minimum MB MB MB MB respectively fitting pagerank image exponential function explains behaviour target runtime peak performance executor runtime degrade performance executor pagerank kmeans pagerank kmeans relationship serial constant wordcount svm nweight pagerank kmeans constant explanation unpredictable overhead overshadow runtime longer stable growth boundary serial easily workload fitting 2D plate model pagerank image fitting 2D plate model kmeans image fitting error comparison amdahl gustafson finding analytical model fitting propose model although curve amdahl gustafson majority curve propose model empirical data accurately however amdahl gustafson graph graph empirical data accurately model propose model amdahl gustafson graph gustafson propose model amdahl respectively finally graph propose model achieve propose model amdahl model gustafson model application runtime increase executor model amdahl gustafson runtime converges fix model comparison fitting accuracy propose model amdahl gustafson image curve generally model data  gustafson equation model amdahl equation gustafson equation estimate workload conclusion propose  model workload spark data application hadoop cluster propose model predict runtime generic workload function executor without necessarily algorithm implement relatively parameter model equation focus insight parameter reduce runtime user operator administrator optimise application performance physical cluster various hibench workload spark application propose performance model runtime emerge executor driven growth serial portion proportional executor workload runtime despite executor phenomenon predict propose model  workload wordcount svm nweight runtime versus executor model equation however workload pagerank kmeans model data finally conclude satisfactory parameter chose propose model precise recommendation executor beneficial performance tune future model hibench workload model alternative equation data workload wider accurate prediction runtime physical cluster minimum important parameter runtime executor