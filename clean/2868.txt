item filter technique collaborative filter algorithm recommendation correlation similarity cosine similarity pearson correlation variant inherent limitation sparse datasets item rating prediction addition traditional similarity mainly focus orientation rating vector magnitude rating vector magnitude orient direction exactly another aspect item user rating addition calculate similarity item rating rat user however judicious approach similarity user target item mitigate issue modify bhattacharyya coefficient propose propose similarity calculate user user similarity item collaborative filter experimental analysis movielens datasets significant improvement item collaborative filter user user similarity calculate propose modify similarity access auckland library introduction society era data advent internet application various domain volume velocity variety data daily basis excessive information commonly information overload recommender RS information retrieval domain government library tourism commerce address information overload technique content filter collaborative filter CF hybrid filter recommend item active user CF goldberg popular commonly technique various RSs CF technique volume research establish journal CF categorize model memory model technique employ ML data mining generate recommendation memory technique user rating data compute similarity user item model CF introduce overcome con memory CF instance limitation sparse datasets fundamental limited research address issue model approach although lucrative  challenge ML approach prefer decrypt unknown mapping function generates input output recognize however rating RSs rating aware function ideology hence memory approach fundamental limitation sparse dataset resolve highly beneficial scenario complexity RSs minimal ML approach extensive feature collection dimension reduction limited datasets representative cluster outlier fail truly population benchmark data model setting performance degradation argument motivation research memory CF moreover simplicity implementation minimal content requirement ability handle correlate item contribute factor advantage exist memory CF technique classify user item CF concept user CF user appreciation almost rat item user user taste user community neighborhood intrinsic extrinsic utilized rating collection rating matrix user item rat user precisely principle user CF user preference preference future consequently critical aspect CF enhance recommendation quality similarity therefore significant impact performance CF various similarity SMs user target user respective rating similarity predict taste target user item recommendation generate philosophy user CF limitation scalability sparsity customer commerce site increase rapidly item due compute similarity user become expensive item CF introduce member  research feasible approach item recommendation assumption item CF user prefers item item CF utilizes similarity item predict target item item CF advantage user CF firstly item relatively static user similarity compute offline access secondly accurate recommendation user CF however user CF performance item CF disrupt due issue inaccurate prediction item RS firstly item item similarity item cannot compute rat item dataset secondly item CF rat user however rating user randomly chosen item spite impressive similarity due randomly chosen item negligible impact average rating rat item outlier bias rating user user ideal rating violate item reflect emotional psychological involvement taste user item user stringent lenient rating item therefore judicious approach similarity target user rat user target item thirdly traditional similarity function cosine similarity variant orientation magnitude vector magnitude exactly orientation cosine similarity circumstance disruption prediction accuracy CF purpose examine behavior SMs rating user alleviate mention issue propose similarity function modify bhattacharyya coefficient efficiency propose similarity function movielens datasets comparative experimental analysis reveals item CF user user similarity choice user CF item item similarity user user similarity compute modify bhattacharyya coefficient improve accuracy item CF calculate traditional SMs propose similarity function modify bhattacharyya coefficient attains prediction accuracy recently similarity CF RS remainder article structure elaborates background related sect limitation various similarity highlight motivation propose propose recommender portrayed sect experimental analysis sect finally sect concludes background related RS define decision strategy aim relevant accurate chunk information user accord preference taste filter pool information assist user handle information overload personalize customize content service additionally complex information environment recommender discovers data dataset user decade recommenders evolve manual automate grown significantly variety application development diverse algorithm content CF commonly approach RS intuition content RS recommendation target item depends highly previously item target user fundamental involve content RS attribute item recommend target user profile user portrays sort item user contrast item user profile item recommend content filter applies attribute item whereas CF user behavior attribute item memory CF utilizes user user item item correlation rating predict rating target user recommendation memory CF recommendation creation user profile rating selection target user utilize similarity function rating prediction target item recommendation item target user  explore drawback traditional SMs CF namely ignore proportion rating accuracy jaccard similarity discern user absolute rating considers proportion rating user rating predict rating target item user distinct rating predict rating target item mitigate limitation propose novel SM compose factor similarity proximity impact popularity proximity factor absolute difference rating determines rating agreement disagreement penalty rating impact factor prefer non prefer item user popularity denotes rating user difference average user rating average user rating maximum rating user increase accuracy similarity user  propose recommender sparsity memory CF vector machine model apply item similarity propose conception dissimilar user user nearly rating item user rate item dissimilar user hardware constraint impede scalability processing efficiency item CF item user   propose optimize mapreduce item CF algorithm minimize scalability issue item CF user rating frequency reasonable empirical factor calculation similarity item hence introduce argument inverse user frequency user rating frequency user rating frequency involve calculation item item similarity propose algorithm datasets execute independently reduce execution overhead ensure performance another significant issue memory CF hence    pereira    hybrid recommender simultaneous cluster combine CF demographic information advantage propose recommendation rating available user sparsity improve accuracy CF  euclidean distance cosine similarity SMs personalize RS CF RS entire rating database scalability user item database minimize issue     construct parallel variant CF benefit related efficiency capacity dynamically update data version built parallel openmp api efficiency assess multi core variant hybrid technique utilizes openmp mpi homogeneous heterogeneous cluster  developed cuda enable parallel CF efficient data partition scheme execution survey parallel distribute collaborative filter     reveal memory built distribute memory environment establish memory framework parallel distribute collaborative filter algorithm recently developed particularly graphic processing platform excellent multilayer heterogeneous utilizes machine efficiently amount data combine technique distribution bipartite  enhance effectiveness CF algorithm perform parallel configuration user rating information important role memory CF privacy information efficient accurate recommendation direction  introduce efficient privacy preserve item CF user privacy online recommendation item similarity compute propose synchronize secure multi computation protocol preserve privacy item similarity computation exist literature multi criterion item CF technique introduce mitigate limitation traditional criterion rating algorithm     multi criterion item CF framework author calculation similarity item similarity item compute accord criterion involves estimate average similarity criterion pearson correlation adjust cosine similarity euclidean distance manhattan distance chebyshev distance SMs    kwon explain approach similarity approach aggregation function approach improve multi criterion rating information recommender notation equation popular traditional SMs notation SMs computation equation SMs cosine similarity  adjust cosine similarity  euclidean distance  pearson correlation  spearman correlation  item CF equation SMs derive mutually exchange SMs utilize similarity target item item computation user similarity hence choi suh propose SM outperforms traditional SMs selection target item sparsity issue CF RS various SMs unable compute accurate sparse scenario therefore SM bhattacharyya coefficient BC outperforms prevalent SMs computational equation SM BC equation  jaccard similarity user BC computes similarity item item BC loc rui  denotes local similarity user respect item item similarity modify bhattacharyya coefficient BCSim   loc rui  mathematical formula BC loc rui  BC   loc rui rvi rui  rvi      identifies bin  ratio user rat item rating user rat item  median rating item rat user  denotes rating user item parallel CF RS extend vector PCF EV  overcome scalability issue eigenvector fairly extend obtain expand vector expand vector model expand vector illustrate similarity evaluation item computation reliable recommendation target user basis additional optimization allows successfully deployed parallel compute architecture limitation similarity similarity computation significant role prediction accuracy CF RS plethora exists literature improve performance CF however exist SMs suitable rat item zero rating item specific explain limitation exist SMs suppose rating vector item user ED SMs testimony item exactly spite rating suppose rating vector item user respectively rat user respectively rating vector notwithstanding PC SC compute similarity contrary ACS unable compute similarity circumstance prediction accuracy CF disrupt suppose rating vector item user illustrates ED SMs computational issue rating vector rating vector CS computes similarity ACS PC SC unable calculate similarity suppose rating vector item user item rat user  evidence conclusion item rating item rating vice versa addition CS ED compute positive similarity minimum similarity rating vector item incorrect conclude CS ED inaccurate rating prediction CF RS suppose rating vector item user ED computes similarity similarity cannot compute PC SC CS misinterpret item equally item dissimilar accord ACS suppose rating vector item user respectively rat user item respectively CS ED positive similarity minimum similarity rating vector furthermore ACS PC similarity SMs degrade rating prediction accuracy CF suppose rating vector item user denotes user rate item SMs unable compute similarity item scenario CS ACS ED PC SC rating prediction accuracy CF decrease significantly ratio unequal sparsity rat item exist situation highlight SM suitable compute similarity item CF another drawback traditional SMs weightage rat user attain rating prediction accuracy choi suh introduce similarity function adopts similarity target item item user CF experimental choi suh user CF pearson correlation obtains recommendation accuracy SMs item similarity computation user user similarity although propose SM considers aspect CF RS user opinion item propose SM fails rating user propose SM choi suh various issue highlight similarity user target item spite compute similarity target item propose SM choi suh unable resolve unequal sparsity rat user exist direction mitigate mention issue SM propose algorithm physical resonance phenomenon although resonance similarity overcomes issue concern exists propose approach reality application percentage sparse data however comparative analysis propose approach sparsity efficiency CF algorithm justified various statistical metric mae RMSE precision recall confidence mae comparative another important aspect item user rating address propose approach rating rat item propose approach suffer performance issue motivation sparsity concern item CF correlation SMs cosine similarity pearson correlation variant fail calculate similarity item statistic bhattacharyya distance similarity probability distribution closely related bhattacharyya coefficient bhattacharyya coefficient  kumar bhattacharyya statistician suitable similarity sparse dataset rat item magnitude orientation instead bhattacharyya coefficient computes relative closeness statistical sample similarity item BC rating similarity BC conclude BC suitable SM sparse dataset fails resolve issue ratio validation although SMs literature enhance rating prediction accuracy CF throughout discussion SM overcome mention issue brief description various SMs aspect CF RS identifies SM resolve issue denotes SM unable resolve issue notifies SM resolve issue rating others cannot resolve performance various SMs rating however user opinion item suppose user rating vector item denotes user rate item rating vector clearly user however taste item totally inspire observation rating prediction accuracy item CF improve user user similarity item BC modify BCSim utilized satisfy varied taste user propose recommender propose RS module namely data collection data processing rating prediction recommendation data collection comprises user feedback target item feedback convert user item rating matrix CF recommendation propose RS user item matrix similarity propose SM propose recommender item collaborative filter image propose similarity function item target item target user detailed information propose SM similarity user item target item computational equation modify BC propose SM propose similarity CF BI BU denotes item similarity BCSim user similarity BCSim target user target item user item respectively  jaccard similarity item BC similarity user BC  riu  denotes local similarity item respect user user identifies bin  ratio item rat user item rat user rating  median rating demonstrates user rate item rik denotes rating item user advantage CF BI BU illustrate similarity item compute rating target user instead utilized formation ratio target user  BCSim BCSim BCSim BCSim simu  similarity CF BI BU ratio target user  BCSim BCSim BCSim BCSim simu  similarly compute desire similarity rating CF BI BU resolve illustrate issue reality user item rating dataset highly sparse non rat scenario CF BI BU computes similarity rating rating prediction target item target user calculate similarity prediction approach rating prediction target item firstly similarity target item item calculate item similarity closest item target item prediction approach aggregation function predict rating target user target item equation prediction approach becomes simu simu predict rating target item target user closest item target item simu identifies similarity target item item target user predict rating target item item recommend target user propose algorithm detailed rating prediction propose SM algorithm notation notation complexity propose algorithm propose algorithm calculates similarity user similarity user weigh factor item similarity target user item item similarity descend utilizes output previous input prediction rating item target user respectively execution therefore complexity similarly complexity due respectively sort technique apply item similarity therefore various complexity  average execution respectively execution respectively hence complexity execute mnk predict rating complexity CF BI BU complexity CF BI BU illustrative illustrative modify traditional SMs propose utilization user similarity item CF propose SM CF BI BU notation modify traditional SMs equation modify traditional SMs notation modify traditional similarity modify traditional similarity rating item rat user average rating item average rank item average rank item respectively rank rating item rat user rating information user eleven item target user item respectively depicts similarity target user user traditional SMs user item rating information similarity target user user calculation similarity target item item  AB propose SMs  similarly similarity target item item calculate traditional SMs propose SMs respectively similarity SMs rank item calculation rating prediction target item target user   rti XY rti  predict rating target item calculate propose SMs item rating prediction similarity target item item rank item target item predict rating target item explains effectiveness propose SMs item CF subsection experimental setup comparative analysis experimental setup propose SM movielens datasets detail datasets detail datasets demonstrate performance propose SMs sparse datasets datasets subset subset randomly remove rating datasets rating dataset respectively brief detail subset subset furthermore delete rating predict various CF algorithm accuracy performance metric comparative analysis metric mae RMSE precision recall accuracy equation metric mae RMSE equation predict actual rating item respectively denotes predict item dataset precision recall precision recallprecision recall accuracy rating address rating recommend rating recommend precision recall accuracy denotes classification calculate classification potential outcome performance metric comparative analysis comparative choi suh pearson correlation item item similarity user CF attains accuracy algorithm therefore effectiveness propose SM pearson correlation CF algorithm propose choi suh user similarity pearson correlation calculate item similarity pearson correlation CF accurate SM item CF user similarity calculate cosine similarity pearson correlation variant modify bhattacharyya coefficient CF CI CU CF AI AU CF EI EU CF PI PU CF SI SU CF BI BU demonstrates comparison accurate SM calculate previous recently SMs CF RS CF algorithm density enrichment pearson correlation  PC CF algorithm improve similarity CF itr lastly comparison complexity CF CF CI CU CF AI AU CF EI EU CF PI PU CF SI SU CF BI BU  PC CF itr comparison CF PI PU CF comparison CF PI PU CF basis various performance metric datasets observation comparison CF PI PU CF mae dataset image significant evidence accurate SM CF PI PU CF CF PI PU attains prediction error CF datasets dataset sparse subset ML CF PI PU fails outperform CF sparse subset ML ML outperforms CF prediction error various comparison CF PI PU CF mae dataset image comparison CF PI PU CF mae dataset image comparison CF PI PU CF RMSE dataset image comparison CF PI PU CF RMSE dataset image comparison CF PI PU CF RMSE dataset image comparison CF PI PU CF precision recall accuracy dataset image comparison CF PI PU CF precision recall accuracy dataset image comparison CF PI PU CF precision recall accuracy dataset image demonstrate comparison CF PI PU CF basis precision recall accuracy CF PI PU mention performance metric CF datasets various sparsity dataset CF PI PU precision recall accuracy sparsity CF precision recall accuracy sparsity datasets recommendation accuracy CF PI PU hence CF PI PU SM CF utilization user user similarity item CF judicious approach comparison propose similarity function traditional similarity evaluate performance propose SM traditional SMs demonstrates comparative analysis mae RMSE precision recall accuracy comparative analysis compute performance metric various performance CF BI BU relatively others respect mae comparison mae dataset image comparison mae dataset image comparison mae dataset image comparison RMSE dataset image comparison RMSE dataset image comparison RMSE dataset image comparison CF CI CU CF AI AU CF EI EU CF PI PU CF SI SU CF BI BU dataset image comparison CF CI CU CF AI AU CF EI EU CF PI PU CF SI SU CF BI BU dataset image comparison CF CI CU CF AI AU CF EI EU CF PI PU CF SI SU CF BI BU dataset image CF BI BU demonstrates comparatively RMSE approach datasets highlight comparison CF CI CU CF AI AU CF EI EU CF PI PU CF SI SU CF BI BU basis precision recall accuracy evident CF BI BU attains prediction accuracy others datasets recommendation accuracy CF BI BU hence CF BI BU outperforms similarity function comparison mae dataset image comparison mae dataset image comparison mae dataset image comparison RMSE dataset image comparison RMSE dataset image comparison RMSE dataset image comparison CF BI BU  PC CF itr dataset image comparison CF BI BU  PC CF itr dataset image comparison CF BI BU  PC CF itr dataset image comparison CF BI BU  PC CF itr comparison CF BI BU  PC CF itr various accuracy metric datasets CF BI BU mae RMSE  PC CF itr depict comparison precision recall accuracy datasets CF BI BU attains precision recall accuracy recently SMs datasets complexity comparison comparison various CF algorithm computational complexity denote user item respectively complexity comparison CF BI BU execution algorithm due complexity hence comparative analysis various sparse datasets rightly conclude CF BI BU performs CF algorithm spite complexity however various commerce website adopt various offering amazon  utilizes library perform computation parallel gpu instance offering technique mapreduce employ achieve parallelism therefore propose approach implement parallel resolve scalability issue conclusion classical memory recommender  model due inability handle sparse datasets due inherent drawback traditional similarity owe simplicity serendipitous interpretability memory recommendation address blocker attractive approach tremendous scope promising stride propose similarity function mitigates issue related sparsity datasets factor magnitude rating vector propose function computes similarity user utilizes user calculation similarity target item item experimental function outperforms various modify similarity user similarity function choi suh mae RMSE precision recall accuracy movielens film trust datasets future aim address chronic recommend without historical similarity beyond direction orientation furthermore future focus parallel distribute collaborative filter algorithm mitigate scalability issue reduce complexity propose approach