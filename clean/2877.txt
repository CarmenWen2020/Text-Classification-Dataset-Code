automate planning without explicit model elusive research challenge however tackle approach unstructured environment currently research direction artificial intelligence AI namely machine symbolic AI former technique model unstructured data capability model latter efficient algorithm model model bottleneck domain complicate explicit description costly impossible propose combination namely classical planning planning without encode model  extract model transition goal distance heuristic estimator classical planning model efficiently planning network planning introduce graphic additional information transition estimate heuristic propose architecture heuristic estimator characteristic technique besides planning experimental evaluation implement technique classical model access auckland library introduction classical planning powerful model logistics navigation production domain scene model grasp model happens distribution warehouse encode warehouse comprise robotic  ought transport  various model  expert knowledge parameter logistic mechanism obtain model processing visual input warehouse eliminates perfectly define model input equation allows model complicate issue otherwise impossible classical planning symbolic representation bottleneck classical planning constraint advantage ability generalize access domain complex scalable domain architecture focus analyze possibility limitation combination classical planning instead replace planning network algorithm focus partial replacement component involve standard planning algorithm namely transition heuristic function classical planning unfortunately struggle unstructured domain demonstrate domain without structure therefore combine remove explicit planning model   classical planning  initial goal instance return visualize execution image input transform generate standardize representation classical planning machine technique heuristic function improve algorithm author propose policy algorithm policy heuristic prefer operator expansion understood   architecture contrast maze image maze input algorithm sequential navigate transition generate model increase efficiency heuristic principle contrast approach model expansion heuristic additionally approach prior related multiple domain overlap discipline agent maze domain introduce simplify robotic planning multi agent maze generate without collision multiple agent multi agent tackle challenge classical planning artificial intelligence domain independent heuristic computation heuristic inspiration relaxation abstraction landmark potential heuristic compute heuristic function planner landmark important domain grid maze crossroad landmark generate potential heuristic information extract information graphic creates linear program defines feature constraint restrict besides classical planning another broadly developed research direction stochastic gradient descent frequently training neural network principle hinge correctly define loss function mention potential heuristic computation loss focus restrict output network accord monotonicity requirement systematic classical planning aim without model graphic representation input technique involve convolutional network transition involves residual connection resnet architecture input neural network concatenates input residual connection transition input input avoid lose information structure transformer architecture introduce attention mechanism attention allows network input landmark similarly abstraction aim simplify complex version behavior achieve convolutional kernel abstract information neural network limited information capacity parameter simplify available memory network perform simplification analogy relaxation another direction recurrent structure iterates simplify encode emulates algorithm obtain heuristic estimate recurrent lstm gru widely building recurrent neural network emulate behavior recurrent mac performs input encode vector algorithm emulation achieve specific network architecture reinforcement resembles algorithm policy reinforcement technique combine introduce reinforcement however absence model building commonly sparse goal background classical planning focus  symbolic representation model planning instance definition  planning task  planning task tuple define contains operator transform initial consists initial goal contains goal function operator positive operator tuple pre del pre precondition operator applicable apply operator del delete longer operator operator applicable pre apply operator define del  representation construct operator definition construct transition goal initial sequence operator initial goal operator sequence applicable sequence definition transition transition tuple finite finite action transition function define iff applicable outcome action application function assign action various meaning price anything optimize define  definition translate transition algorithm action operator contains subset function remains transition function define action planning induced transition typically heuristic algorithm definition algorithm performs graph node planning induced transition corresponds corresponds expand goal return sequence action apply expansion goal exhaustive efficient generally blindly however additional information greatly improve performance additional information heuristic function heuristic function positive heuristic function estimate goal function shortest perfect optimal heuristic denote neural network neural network powerful domain approach neural network propagation stochastic gradient descent primary aim network substitute algorithm network replace transition function generate successor transition define definition network replace heuristic function return estimate distance goal replace avoid symbolic representation adhere classical architecture domain model model classical architecture obtain successor compute heuristic implement mention model primarily convolutional neural network cnns described recurrent neural network combination convolutional layer domain image structure cnns viable choice extract information visual representation recurrent neural network advantage recurrent mechanism convolutional layer image input attention neural network recent introduce transformer architecture attention network proven attention allows network focus subset input creation attention mask attention network focus input oppose attention network focus zero mask generate convolutional layer softmax layer width height input sum mask input feature modify input feature emphasize attention mask layer generate attention mask network architecture generate attention mask sokoban instance image instance sokoban puzzle attention mask image multiplication sokoban generate attention mask image mask focus structure focus goal image recurrent network approach recurrent neural network namely mac introduce task task described adjust input output processing network structure introduce recurrent preserve mac recurrent recurrent gru lstm frequently iteration output previous iteration input structure contains multiple module module modifies hidden network mac input output module slight modification module structure input module creates compact representation input tensor network mac recurrent network input therefore representation input network output module originally softmax layer fix output heuristic therefore modify module output data domain challenge implement propose approach obtain quality data network bottleneck approach reliable dataset domain domain domain data generator solvable instance neural network domain instance maze difficulty sokoban domain domain maze agent goal agent maze agent neighborhood maze accessible agent domain conceptually previous multiple goal multi goal maze instance maze agent define goal domain multi agent maze apply agent goal maze agent goal assign specific agent goal agent goal domain sokoban puzzle agent maze domain movement contains additionally puzzle agent occupy goal specification occupy goal agent multiple introduce domain define grid width height instance grid consist contains entity entity maze domain agent goal entity sokoban domain agent goal domain image expansion network definition transition function return successor expansion network generate successor image maze agent without knowledge action action maze domain data important network task around agent maze structure remains broken perform action image therefore mention earlier convenient cnn task agent maze multi goal maze multi agent maze focus neighborhood agent therefore kernel preserve input network pad sokoban movement focus neighborhood agent therefore allows around agent agent allows additionally improve network residual connection residual connection architecture modification achieve identity function resnet image classification network furthermore residual connection reduction complexity network improvement expansion network residual connection residual connection concatenates input network multiple convolutional layer input residual connection network architecture convolutional network pad dropout convolutional layer regularization architecture expansion network contains parameter alter configuration namely channel denote convolutional pad channel architecture domain convolutional kernel pad mostly parameter sokoban domain expansion network architecture instance maze entity entity sokoban analogical image expansion network configuration batch sample instance input output mention earlier input network visual representation grid domain fix entity grid entity therefore representation grid vector marked entity representation maze tensor dimension width height instance dimension entity domain encode image agent maze multi goal maze multi agent maze entity agent goal empty sokoban puzzle domain agent goal empty therefore dimension already input network representation contains information grid output network input contains probability distribution entity grid regular transition function receives return successor expansion network receives input encode return contains information successor comparison classical transition function output propose expansion network transition function classical planning return successor expansion network return expansion probability distribution encode agent execute encode reflect probability agent probability image empty agent probability agent agent entity empty encode probability probability agent zero probability agent probability agent cannot classical transition function deterministic expansion network probabilistic determinization expansion network discrete deterministic later therefore entity distribution output network derive actual successor determinization threshold probability agent agent placement successor insert priority queue algorithm checked  invalid agent expansion network permit priority queue planner report invalid fail loss function neural network define loss function loss function receives output generate network output network generate loss function quantify successful network partial derivative respect network parameter adjust network network probabilistic distribution successor data encode vector representation grid accord entity correspond index vector heuristic network another function definition heuristic function aid compute heuristic non simplify visual representation without explicit latent representation explore network architecture architecture data batch sample instance input data visual representation convolutional network direction explore explore approach purely convolutional neural network inspire classical planning approach compute heuristic attention simulate simplification simplification usually classical planning heuristic relaxation abstraction approach recurrent neural network intuition recurrence simplify emulator therefore network capable approach mac recurrent input output explore multiple approach architecture heuristic network input output network heuristic network receives encode visual representation input label heuristic shortest input closest goal therefore network input generate heuristic planning algorithm although heuristic estimator optimal nonsensical something truth proof concept future bootstrap technique address specially dataset structure loss function heuristic network important neural network approximation scheme cannot ensure generate therefore  planning instead optimal planning heuristic estimate influence performance planning algorithm monotonicity monotonic heuristic possibility descent heuristic implement custom loss function monotonicity already initial optimal network aim monotonicity relationship random network monotonicity instance data contains various instance instance data multiple agent placement therefore label network connection related instance heuristic network define loss function return scalar valid input task optimization aim converge minimal error regard output heuristic network stochastic gradient descent sgd algorithm optimization algorithm loss function label data return network aim monotonicity heuristic function therefore loss computes return monotonic context maze instance dij loss max dnn denotes instance input heuristic network training denotes sample batch output heuristic network denotes instance network input contains label instance input denote heuristic network optimal label dij denotes distance ith jth output vector signum ith jth vector label aim compute distance goal monotonicity parameter denotes tolerance distance dij matrix symmetrical identity matrix zero diagonal diagonal relationship ith jth zero loss scalar obtain sum subtraction dimension compute loss maze displayed training data sample contains agent label data sample optimal agent placement namely evaluate neural network initial randomize data sample obtain vector parameter training compute loss input vector data sample demonstrate loss function computation image loss max max dmax dmax dmax max dmax dmax dmax max max max max max max max max max tolerance matrix zero diagonal diagonal relationship sample loss computation matrix symmetrical relationship generate network incorrect monotonicity label label vector return neural network sgd neural network aim minimize loss function minimal loss loss discrepancy relationship heuristic data return neural network heuristic function GBFS algorithm heuristic loss computation backpropagation algorithm compute partial derivative respect parameter network derivative neural network denotes contributes output network adjust backward pas network concludes training network cnn network architecture heuristic network convolutional network input convolutional layer vector representation vector representation linear layer output heuristic architecture displayed convolutional layer network extends channel input input multiple convolutional layer pad input network performs aggregation width height creates vector linear layer output architecture simplest configuration network configuration parameter linear layer architecture addition coordinate channel parameter linear layer network addition input coordination channel channel input data channel contains coordinate grid contains coordinate grid input channel increase convolutional layer channel instead modification heuristic network cnn architecture image cnn attention network architecture heuristic network relies heavily convolutional layer notable feature architecture usage attention described attention neural network analogous simplification classical planning relaxation abstraction maze identify crossroad simplify obtain distance estimate agent goal implementation attention convolutional layer softmax dimension input attention mask width height input sum architecture denote attention mention convolutional layer attention mask input mask displayed schema concatenate coordinate channel output attention channel coordinate grid channel coordinate grid architecture convolutional neutral network structure previously described expansion network sect network parameter configuration attention mask attention attention attention mask attention worthy data attention mask architecture network planning another architecture modification multiple attention network option displayed option attention convolutional layer network increase attention computation heuristic network attention cnn architecture image propose architecture processing input attention attention mask mask channel input concatenate coordinate channel output attention multiple convolutional layer pad output convolutional layer sum width height thanks operation vector rely width height network vector linear layer return rnn network model architecture mac recurrent described modify introduce mac requirement heuristic function network alter input module network input image text input differently input image representation input processing apply data convolutional network embeddings input image network output originally network fix setup numeric therefore layer output processing module modify return scalar author architecture network fix iteration mac network bottleneck aim capable increase network capable processing instance arbitrary however assume longer therefore avoid fix iteration module network module maximal iteration iteration compute mac output concatenates linear layer sigmoid layer output processing sample determines sample iteration output sample label mac maximal iteration sample label architecture heuristic network displayed parameter alter addition coordinate channel maximum iteration recurrent usage attention usage gate embed parameter embeddings addition coordinate channel architecture possibility channel coordinate grid channel coordinate grid maximum iteration module iteration usage attention gate already mention addition architecture module network without parameter embed embeddings parameter output layer inside architecture heuristic network rnn architecture output module output module output module memory image propose network architecture hyper parameter obtain network network integrate implement planning algorithm technique classical planning expansion network classical transition function described definition heuristic network blind heuristic euclidean distance ED textbook implementation HFF LM heuristic goal verify proof concept expansion network heuristic network architecture classical planning algorithm heuristic transition function context neural network expansion network evaluation expansion network architecture integrate planner evaluation function expansion network configuration evaluation function expansion network accurately generate successor structure network distribution entity contains valid reachable however structure entity suppose desire obtain unreachable output distribution difference diff denotes assign suppose aim evaluation obvious placement identity network minimal probability expansion min corr denotes probability entity agent exp net maze agent placement maximum placement agent maximal probability incorrect expansion max analogous previous probability denote probability incorrect expansion exp net maze negligible invalid successor generate maze domain structure generalize expansion network agent maze multi goal maze multi agent maze domain agent maze multi goal maze expansion network movement exactly agent however multi agent maze differs available agent longer local environment around agent agent compute successor performance expansion network exp net maze  agent maze data exp net maze multi agent maze data exp net maze perform multi agent maze data valid reachable action min corr exp net maze perform agent maze data maze data multi agent maze data maze data therefore expansion network planning expansion network evaluation maze domain sokoban domain network structure contains additional entity extend structure network accordingly training similarly maze domain expansion network transition function diff min corr max sokoban agent neighborhood network particularly diff min corr max various error valid completely misplace invalid movement agent plausible pure combinatorial complexity permutation input therefore training  portion situation network planning combinatorially substantial structural principle sokoban maze therefore domain correctly heuristic network evaluation satisfactory automatically derive heuristic function planner framework domain heuristic baseline heuristic blind euclidean distance ED heuristic classical planning heuristic HFF LM previously heuristic obtain heuristic network guaranteed therefore planning  LM admissible heuristic assures optimal planning optimal algorithm therefore however comparison domain implement algorithm namely greedy GBFS planner integrate propose expansion network heuristic network arbitrarily combine implement hyperparameter selection training neural network hyperparameters sect parameter propose architecture model various combination available parameter evaluate evaluation perform metric evaluate namely focus coverage percentage data average average expand heuristic network expansion network evaluation introduce sect network transition parameter expansion network planning channel convolutional pad selection convolutional pad network architecture pad convolutional convolutional layer output width height input allows architecture output width height input option pad convolutional channel inside expansion network architecture selection capable transition multi agent maze domain expansion network domain parameter sufficient network complex domain capable evaluate maze domain perfectly channel option sect introduce architecture various parameter cnn architecture propose sect parameter influence linear layer architecture addition coordinate input data propose architecture cnn att network sect parameter defines attention mask defines attention rnn architecture introduce sect parameter attention gate parameter functionality available recurrent parameter coordinate channel parameter maximum iteration recurrent parameter defines embed input data selection hyperparameters heuristic network architecture parameter heuristic network architecture accord evaluation domain GBFS algorithm parameter achieve domain domain emphasize regard parameter cnn architecture rarely achieves maximal available linear layer multi agent maze complex maze domain architecture benefit coordinate cnn att architecture dominate parameter att mask attention mask domain achieve attention mask available domain attention mask multi goal maze multi goal maze domain agent goal maze per agent domain parameter rnn architecture achieve combine gate attention coordinate input coordinate input advantage enrich module recurrent improve demonstrate selection parameter network performance rnn architecture sokoban domain parameter addition coordinate channel maximum iteration recurrent usage attention usage gate embed fix parameter clearly influence parameter network performance instance fix embed iteration displayed selection remain parameter influence metric coverage influence slightly gate attention coordinate addition accord coverage coverage coordinate gate attention partially simplification network evaluation evaluate faster heuristic estimate average longer parameter combination another option fix iteration usage coordinate gate attention embed displayed embed coverage increase expand significantly resource demand embed recurrent network slows evaluation comparison selection parameter important achieve influence network evaluation network planning evaluation role metric mostly focus coverage quality configuration parameter planning influence hyperparameters rnn heuristic network influence parameter fix embed maximum iteration gate attention coordinate embed evaluation perform sokoban domain image planning data data planning consist unique instance network agent maze multi goal maze multi agent maze domain data correspond data contains instance already mention expansion network instance instance heuristic network instance arbitrarily instance sokoban domain data unseen instance planning perform  data contains instance random  data  evaluation evaluate performance planner technique metric coverage percentage data metric average expand metric average  planning however quality valuable information contribute comparison technique perform machine cpu core GB memory gpu computation neural network planning planning instance limit algorithm traditional transition function denote GBFS expansion network denote  planning perform instance training data evaluate regular transition function expansion network GBFS heuristic blind ED HFF LM heuristic network cnn cnn att rnn coverage analysis agent maze domain traditional transition function coverage heuristic heuristic network difference coverage usage expansion network instance coverage instance grows coverage cnn attention network coverage requirement compute heuristic coverage partially generation successor computational requirement expansion network certainly transition function multi goal maze domain trend agent maze domain coverage happens cnn attention network coverage rnn network coverage multi agent maze domain complex agent simultaneously LM suffers coverage due computation coverage cnn att network coverage heuristic network instance limit heuristic sokoban domain classical transition function denote GBFS instead  expansion network usable function sect HFF LM coverage computationally heuristic sokoban heuristic network cnn network performs coverage outperforms heuristic analysis average evaluate sect coverage analysis significant average coverage agent maze multi goal maze domain heuristic network perform classical heuristic function quality average cnn attention heuristic network decrease coverage configuration expansion network perform requirement coverage analysis rnn heuristic network HFF heuristic multi goal maze domain data agent maze cnn rnn heuristic network HFF LM multi agent maze domain variation coverage average generate harder interpret however data heuristic network return longer HFF LM heuristic HFF cnn rnn network due coverage heuristic network generate longer expand analysis expand factor determines heuristic navigates direction analysis establish coverage threshold denotes minimal coverage achieve analysis agent maze multi goal maze domain heuristic network expand HFF LM heuristic network cnn att network expands amount instance difference none instance expand agent maze domain difference rnn network HFF rnn network expand nearly sokoban domain heuristic network outperform classical heuristic comparison computational discover difference described metric influence transition function therefore transition function heuristic function difference influence performance algorithm average compute measurement instance limit measurement transition function expansion network suspect expansion network evaluates transition function difference instance complex multi agent maze comparison compute heuristic function heuristic network blind euclidean heuristic compute informative HFF LM informative heuristic costly compute HFF heuristic performs maze domain computational increase however sokoban compute heuristic exceed limit measurement LM exceed measurement multi agent maze domain heuristic network compute increase cnn attention network multi goal maze multi agent maze sokoban heuristic network trend heuristic coverage decrease cnn network computational architecture network however rnn heuristic network complex recurrent architecture outperform HFF multi goal maze multi agent maze sokoban coverage agent maze multi goal maze multi agent maze domain  sokoban domain GBFS analysis agent maze multi goal maze multi agent maze domain  sokoban domain GBFS analysis expand agent maze multi goal maze multi agent maze domain  sokoban domain GBFS comparison computational transition function heuristic function discussion sect planning perform transition function expansion network implement heuristic function blind ED HFF LM architecture heuristic network cnn cnn att rnn evaluate respect propose metric explain outcome discus contribution theory scenario coverage discussion insight heuristic information performance heuristic therefore coverage degrades surprising classical heuristic increase increase complexity moreover although heuristic network perform nearly perfectly maze domain par classical heuristic sokoban performance maze exception hardest multi agent maze suggests network generalize abstract classical planning terminology similarly classical heuristic multi goal maze multi agent maze simpler cnn network exhibit performance complex rnn network however agent maze rnn network strongly outperforms cnn network explanation agent maze counting distance goal rnn capable simplest maze cnn however propagate distance information indirectly overlap convolutional agent maze goal phenomenon maze statistically initial agent goal per mitigate weakness nevertheless agent maze manifest strongly performance span cnn rnn nearly multi goal multi agent maze goal statistically closer therefore precise distance counting important information attention module valuable navigate theory attention alternative distance structure network complex training evaluation costly cannot  information discussion analysis heuristic network perform classical heuristic complex domain agent maze multi goal maze instance agent maze HFF rnn par trend multi agent maze domain sokoban domain cnn att network outperforms network classical heuristic quality instance heuristic network optimal however quality decrease instance agent maze multi goal maze domain network data compute heuristic actually reliable estimate generalize navigate maze expand discussion analysis expand heuristic network tend expand complex domain heuristic estimate complicate compute expand exceeds classical heuristic cnn att network expands heuristic domain multi agent domain attention powerful extract information global local environment focus multiple location grid seemingly generalize overlap expansion network heuristic network combination classical planning algorithm ability generalize complex instance apply classical planning algorithm properly expansion network successfully substitute transition function planning algorithm computational requirement evaluate expand easily encode domain definition however distribution warehouse multiple machine routine arbitrarily cargo detail benefit transition heuristic network generalize instance contrast expansion network heuristic network evaluates faster heuristic function heuristic network balance faster evaluation heuristic estimate complex informative classical planning technique however requirement heuristic network architecture usually arbitrarily complex scenario distribution warehouse  fleet requirement  heuristic estimate quality  fleet abstract multi agent maze heuristic centralize heuristic function robotic fleet drone device define behavior conclusion propose replacement automate planning algorithm neural network network learns planning model image representation transition network learns heuristic function image representation distance goal architecture allows automate planning model experimentally efficiency par classical planning heuristic therefore viable direction future research coverage heuristic network par classical heuristic respond increase complexity without explicitly define model requirement computation significantly inform classical heuristic LM HFF important propose architecture data sample evaluate arbitrarily instance network generalize heuristic network inform heuristic instance expansion network transition maze domain however requirement network evaluation expand limit quality generate heuristic network classical heuristic agent maze multi goal maze longer complexity increase multi agent maze sokoban domain trend analysis expand heuristic network expand HFF heuristic multi agent maze domain assume heuristic network perform domain global information multiple entity instance direction future bootstrapping strengthen message machine model planning technique model definition another direction generalize architecture addition encoder suitable representation image video input integration future goal another possibly neural network implement research limitation resource network architecture become complex training computational another limitation usage grid data generation domain data generator however focus complex domain obtain data becomes complicate tackle image processing data training extension deploy propose technique automate model planning  distribution warehouse  fleet