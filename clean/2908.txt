knowledge graph KGQA automatically query knowledge graph KG drawn significant attention recent focus relation KG task non trivial capture meaning golden billion KG  propose pipeline framework KGQA consists cascade component entity detection model label entity mention novel entity link model considers contextual information candidate entity KG classifier accord correlation relation mitigate entity ambiguity effective relation detection model semantic similarity relation candidate substantial  benchmark dataset propose achieve performance exist accuracy recall evaluation metric access auckland library introduction knowledge graph YAGO freebase  dbpedia seek effective approach access substantial valuable knowledge KG formal query SPARQL graphql query KGs user understand syntax formal query alternatively knowledge graph KGQA propose KGQA return concise generate query KGs user mainly focus handle relation KG relation task regard foundation handle complex multi relation conversational relation task challenge polysemy ambiguity lexical gap polysemy context express meaning ceo refers corporation instead ambiguity link multiple entity KG chicago link chicago chicago bull lexical gap relation express KG relation birth express  KG entity impossible distinguish literal overcome challenge previous effort apply semantic parse convert logic query KG model obtain competitive performance manual annotation craft feature generalize domain recent development approach develop increasingly complex neural network framework KGQA task however gain sophisticated technique modest previous model exhibit unnecessary complexity moreover framework execution converge training network conduct elaborately stepwise performance analysis therefore explores effective pipeline architecture mostly decomposes KGQA task subtasks entity detection entity link relation prediction pipeline enable comprehensive analysis insight component training model pipeline approach aim research extract entity mention distinguish entity plausible entity calculate correlation relation propose pipeline framework KGQA consists entity detection module entity link module relation detection module specifically entity detection sequence label model label entity mention span entity link adopt entity link foundation mitigate entity ambiguity contextual information candidate entity consideration classifier accord correlation relation novel entity link propose ranked entity candidate relation detection propose effective attention model detect relation entity relation correctly predict query KG summary contribution capture correlation relation formulate multi label classification task examine text classification model contextual information candidate entity KG extra information distinguish entity alias improve performance entity link propose effective attention model detect semantic similarity relation candidate propose achieves competitive  benchmark dataset subset freebase moreover empirical error analysis gain insight mistake model organize research scope introduces related formally formulates overall architecture propose describes experimental setting illustrate effectiveness propose finally sect concludes related mainstream research route KGQA task semantic parse neural network semantic parse logical execute structure query within KGs instance define query graph meaning representation query graph generation formulate stag utilize binary template understand devise index facilitate online template decomposition propose relation node framework semantic query graph approach effective semantic parse complex grammar manual annotation neural network dimensional vector similarity candidate specifically pipeline framework framework pipeline framework employ conditional factoid factorization infer target relation target associate candidate relation char cnn cnn perform entity relation respectively decompose entity detection entity link relation prediction evidence combination evaluate various baseline model task entity detection relation detection heuristic entity mention attentive rnn similarity matrix cnn model utilized capture semantic literal similarity propose knowledge embed framework predicate model predict predicate representation entity model predict entity representation improve subgraph selection subgraph rank propose joint cnn model capture relation dependency topic generation topic relation rank pipeline framework usually combine entity detection relation detection KGQA task although pipeline framework error propagation achieve accuracy  dataset framework attention encoder decoder model model robust unseen entity model adopt neural network model correspond dynamically via attention mechanism neural network merges representation exploit advantage propose   approach verification mechanism responsible correctness predict relation probabilistic model framework KGQA handle uncertain topic entity multi relation model multi representation apply attention mechanism enhance performance propose pipeline framework KGQA propose pipeline framework KGQA cascade component entity detection module identify entity mention entity link module generate entity candidate KG refers relation detection module semantic similarity relation candidate overall illustrate overview propose pipeline framework KGQA image freebase utilized background KG knowledge graph depict entity correspond relation entity freebase entity unique ID refer machine identifier mid mid  sub saharan africa illustrates entire decompose stage zone sub saharan africa entity detection module identifies entity mention sub saharan africa replace span sub saharan africa token generate zone entity link module link identify entity mention correspond node KG calculate literal structural instance entity mention sub saharan africa link entity KG   afterward relation detection module employ compute semantic similarity relation candidate obvious relation zone respect zone finally predict entity relation query retrieve KG western european task definition goal KGQA facilitate define notation knowledge graph consists triple entity relation respectively triple corresponds relation assumption triple hence tuple entity relation correctly identify entity formally sequence aim pipeline framework input return triple accord definition task entity mention entity candidate comprise entity KG associate entity mention relation entity candidate relation candidate semantic similarity relation candidate entity relation entity detection goal entity detection identify consecutive token mention span refers topic entity treat sequence label task assigns label token input sequence BiGRU crf model label entity mention span addition inside outside bio tag scheme label attach denotes entity inside entity non entity instance label sequence assign zone sub saharan africa detail BiGRU crf model constituent component BiGRU crf BiGRU gate recurrent grus recurrent neural network rnns overcome gradient vanish rnns grus additional memory memory distance capture information apply BiGRU obtain sequence information future token specifically derive hidden backward hidden combine hidden concatenation operation sequence hidden obtain BiGRU briefly denote BiGRU denotes input sequence matrix hidden crf conditional random crf successfully sequence label task input sequence conditional probability distribution label sequence define crf calculate exp      learnable parameter correspond label parameter crf model update maximize likelihood training dataset  label sequence decode optimal sequence compute viterbi algorithm argmaxy BiGRU crf combine BiGRU network crf network incorporate distance information sequence input information output sequence network architecture layer embed layer acquires correspond vector layer BiGRU network purpose capture semantic information input text sequence output BiGRU layer crf layer calculates probability distribution dependency label entire sequence entity link output entity detection sequence token entity mention link actual entity KG entity link goal identify entity node KG accord entity mention adopt approach foundation solves via introduce entity link detail entity link pre building invert index entity gram entity extract gram entity mention generate entity candidate invert index rank entity candidate compute levenshtein distance architecture BiGRU crf network image specifically entity generate invert index entity gram entity entity sub saharan africa  correspond gram sub saharan africa sub saharan africa extract correspond gram entity mention invert index mention sub saharan africa zone sub saharan africa KG entity sub saharan africa   sub saharan africa  apply termination heuristic reduce entity candidate concretely entity ignore gram backing otherwise instance query sub saharan africa candidate entity terminate beneficial prune entity sub saharan africa entity candidate ranked levenshtein distance levenshtein distance edit distance minimal elementary edit operation deletion insertion replacement transform edit distance finally ranked entity candidate pool illustrate algorithm however introduce issue ambiguity candidate entity capture literal relevance semantic relevance issue KG grows entity instance entity freebase california impossible distinguish entity mention california refers partial utterance entity obama barack obama identify entity link bottleneck KGQA contextual structure entity KG image identification entity ambiguity bridge gap contextual information candidate entity consideration alleviate entity ambiguity entity unique contextual structure outgo relation KG demonstrate contextual structure entity  ffs entity california although distinguish entity text attach relation relation distinguish entity capture contextual information construct classifier accord correlation relation obviously related relation author entity attach relation author assign extra relation rank candidate entity formally denote relation neural text classifier vector  relation probability  calculate softmax  WW parameter classifier softmax refers softmax function construct classification dataset training  benchmark detail described extra information source introduce entire construct dataset furthermore exist phenomenon relation director correspond relation  therefore convert task multi label classification task task examine text classification model  TextCNN  adopt entropy loss model overview propose entity link procedure image entity link procedure enhance classification formulate propose entity link procedure entity mention relation denote propose procedure achieves entity link via training classifier input return probability belongs utilize basis entity link generate entity candidate corresponds entity mention rank entity candidate extra relation classifier entire procedure illustrates entity link elaborate sect classification model TextCNN architecture TextCNN convolution max pool fully layer formally entity outgo relation rei rei compute entity link considers edit distance classification sel sed  rei sed edit distance entity entity mention  rei maximum probability belongs rei entity  relation notable author relation assign probability maximum classification entity  finally ranked entity entity candidate overall procedure summarize algorithm relation detection output entity link ranked entity relation entity candidate relation candidate goal relation detection semantic similarity relation candidate formally relation relation candidate calculate SRD reflect correlation predict relation   propose effective attention model detect correlation overall structure depict model component relation encoder encoder similarity introduce component respectively propose attention relation detection model image relation encoder relation embed matrix EER employ obtain embed vector relation relation dimension relation embeddings embed vector  representation relation encoder embed matrix  apply transform correspond embed vocabulary dimension embeddings embeddings fed bidirectional grus network hidden representation HHL HHL hidden representation concatenation hidden backward attention mechanism generate representation   calculate formula   exp exp    WW  trainable parameter attention ith similarity utilize cosine similarity function calculate correlation  SRD   cosine   training training stage utilize hinge loss negative sample training objective specifically loss function calculate mmax RD RD positive sample negative sample truth relation hyper parameter RD correction positive relation RD correction negative relation  dataset widely adopt relation benchmark consists relation correspond triple freebase dataset split valid subset freebase   former entity latter contains entity fully illustrate effectiveness propose conduct   evaluation metric accuracy entity relation predict truth data accuracy metric calculate accuracy indicator function golden entity indicates golden relation predict entity corresponds predict relation experimental setting neural network model propose pipeline framework sequence label model entity detection stage multi label classification model entity link stage model relation detection stage model implement pytorch  geforce gtx gpu basis setting model additionally entity detection file release entity label entity mention span aid annotate topic entity directly generate replace topic entity operation model distinguish topic entity zone sub saharan africa correspond topic entity sub saharan africa zone entity link construct multi label classification dataset training  data derive entity detection module golden relation correspond relation relation freebase aspect information identical describes genuine relation zone corresponds relation location location zone relation location location zone genuine relation regard genuine relation correspond relation entity freebase outgo relation entity calculation construct dataset accomplish minimal preprocessing   finally classification dataset consists correlation relation relation moreover ranked entity candidate pool relation detection hyper parameter negative sample basis setting neural network model baseline model baseline explore baseline decompose entity detection entity link relation prediction evidence combination propose attentive recurrent neural network similarity matrix convolutional neural network AR  capture semantic literal similarity relation BiLSTM crf tag model conduct entity extraction introduce revise procedure improve performance introduce baseline consists recognition relation classification addition conclude  due ambiguity data performance bound utilize knowledge graph embed enhance quality topic entity predicate representation model leverage pretrained transformer network bert KGQA focus subtasks entity span detection relation classification formulate knowledge graph sequence specifically aggregation framework candidate decompose pipeline entity detection entity link relation prediction component separately propose fuse model combine detection predicate unified framework model parameter jointly comparison baseline  dataset overall model baseline demonstrate effectiveness propose propose model outperforms pipeline baseline  dataset pipeline model benefit novel entity link module contextual information candidate entity consideration alleviate entity ambiguity however generate entity candidate calculate similarity cannot distinguish entity although utilize heuristic improve recall entity candidate reveal model achieves entity link sect furthermore model achieve performance model sample negative sample truth approach sample negative addition surpasses due attention mechanism calculate attention alignment relation token approach applies baseline without attention mechanism adopt complex neural network approach achieves competitive performance approach generally exploit increasingly complex technique utilize complex convolutional layer gate mechanism shallow semantic information token representation sequence vector aggregate moreover relatively performance instead directly infer entity predicate indirect jointly generate entity predicate entity representation KG embed mislead task KGQA KG performance propose decrease conduct  truth belong    significantly increase difficulty golden sequence label validation entity detection entity detection compute precision recall sequence label validation BiGRU crf model BiGRU model crf model respectively observation BiGRU model outperforms crf model improvement BiGRU crf model boost performance sequence label model due accuracy entity detection BiGRU crf model perform extra revise label mention span recall classifier validation entity link entity link examine performance text classifier classification validation evaluation metric recall entity candidate calculate percentage entity candidate truth entity overall SM corresponds basis entity link SM rnn SM cnn SM rcnn correspond propose entity link  TextCNN  respectively observation propose entity link outperform basis approach margin confirms effectiveness SM cnn recall SM cnn surpasses baseline respectively recall monotonically increase difficulty golden entity entity candidate ranked propose performance text classifier demonstrates generalizability examine text classification model entity link advanced text classifier recall baseline SM cnn model SM cnn baseline entity link approach surpasses baseline  therefore beneficial contextual information account distinguish entity plausible entity moreover entity link degrade slightly  due candidate entity ablation attention mechanism relation detection relation detection ablation analysis conduct evaluate effectiveness attention mechanism observation attention mechanism performance boost overall accuracy relation accuracy indicates alignment relation attention mechanism facilitates semantic similarity relation accuracy slightly overall accuracy relation detection easy entity link entity link bottleneck KGQA visualize attention darker image effectiveness attention accord analysis sect attention mechanism critical role achieve performance gain deeper understand effectiveness visualize attention relation soccer football player attention although model assign attention football relation  computer  gameplay mode accurately attention gameplay mode confirm attention mechanism learns reasonable alignment relation error analysis analyze limitation approach randomly sample wrongly predict category error golden entity entity candidate ranked entity entity candidate entity link golden entity cannot detail entity identical KG format  entity freebase  entity mention inconsistent correspond KG  gomez correspond entity mention  gomez entity KG   sequence label model wrongly label entity mention span environmental disaster italy golden entity mention environmental disaster BiGRU crf model return italy correspond entity mention incorrect entity prediction selects entity entity candidate concretely film correspond adopt entity link procedure enhance classification distinguish entity plausible entity informative partial  tribe entity KG    incorrect relation prediction relation detection model apply semantic similarity relation candidate model return relation specifically difference golden relation predict relation film   golden relation film film executive relation predict model film film golden relation military involve battle fort fisher correspond golden relation  entity involve semantic similarity relation australian correspond golden relation genre artist conclusion propose pipeline framework KGQA consists cascade component sequence label model label entity mention novel entity link model multi label classification model correlation relation classification model combine entity link link entity effective relation detection model semantic similarity relation candidate overall BiGRU crf model label entity mention span novel classification model enhance entity link finally leverage attention model detect relation propose framework achieves competitive  dataset indicates effectiveness model propose restrict relation foundation exploration future explore advanced multi label classification model network structure relation detection focus advanced neural KGQA approach handle complex   LC quad LC quad