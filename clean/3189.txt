planning critical facilitate strategic intervention education significant basis planning performance prediction aim utilize exist relevant information predict future performance grade failure grade average etc target grade prediction planning reminder teacher performance usually influence variety factor difficulty personal performance recent focus various factor influence performance however ignore difference impact factor moreover exist prediction model attention impact complexity performance tackle propose novel complexity attentive interactive performance prediction model CAISP personalize planning CAISP individual difference assign dynamically importance attention network facilitate personalize planning effectively alleviate performance bias complexity fuse complexity feature enhance ability feature representation via neural network meanwhile combine factorization machine develop joint representation interaction boost correlation feature optimal prediction extensive datasets CAISP outperforms access auckland library introduction recent data mining machine technique widely various educational data mining edm aim explore internal relation massive data resource education teacher education management assist improve quality education edm focus research guidance critical edm performance prediction basis purpose mainly relevant information predict future performance grade failure grade average important aspect performance prediction namely grade advantage data mining technique analyze historical useful information predict future grade prediction personalize planning teacher pipeline pipeline planning performance prediction suitable specifically illustrate historical performance firstly obtain analyze relevant technique future performance predict accord predict discover probably contrary attention therefore personalize planning discussion purposefully reduce avoid risk failure helpful administrator intervene appropriate suggestion improve overall performance prior limitation effective approach propose predict performance task scenario forecasting classification regression sort cumulative knowledge regression developed model structure program prediction author capture dynamic evolution knowledge performance despite exist achieve performance argue attention influence difficulty coefficient performance performance bias complexity another individual difference improve model performance task recommendation largely lag performance prediction strategy however individual difference difficulty  tackle issue motivation rationale visualize related  aid visualize expression diagram denote historical grade available corresponds historical without historical grade reminder reminder respectively reminder reminder analysis predict personalize difference goal predict performance personalize planning specific purposefully personalize contribute progress intuitively difficulty coefficient vital role performance prediction explore influence difficulty coefficient performance fuse complexity feature enhance ability feature representation feature combination propose attentive interactive performance prediction model improve prediction propose relies performance previous dataset data proportion difficulty coefficient allows model predict performance identify relevant information associate performance technically inspire successful application factorization machine click rate ctr focus factorization machine model sparse matrix predict performance performance factorization machine model schematic diagram planning personalize attentive performance prediction pipeline planning performance prediction illustration image methodology contribution propose novel complexity attentive interactive performance prediction model personalize planning CAISP feature factorization machine FM neural network dnn assign FM feature attention network feature obtain feature develop multi feature fusion strategy finally fuse input logic regression LR calculation prediction grade obtain specifically  mechanism model model parallel structure factorization machine meanwhile attention network prediction ability feature combination shallow layer propose model accurately relationship difficulty feature besides analyze influence difficulty coefficient performance visualize analysis dataset summarize contribution knowledge explore influence difficulty coefficient performance prediction task specifically fuse complexity feature effectively alleviate performance bias complexity enhance ability feature representation propose novel complexity attentive interactive performance prediction model CAISP considers complexity individual difference via joint representation interaction decision enable personalize planning validate effectiveness propose model dataset demonstrate advantage baseline model extensive experimental analysis remainder organize exist related introduce propose model conduct demonstrate performance model finally conclusion future related core educational data mining predict performance activity exam grade investigate related educational data mining besides target performance prediction review educational data mining recently educational data mining become increase popular topic content analysis knowledge strengthen warn content analysis developed novel algorithm machine algorithm estimate learner understand content analysis evaluates relationship concept subsequently propose  machine framework educational application content analysis extract knowledge textbook content analysis establish knowledge dependence relationship extract concept textbook wikipedia knowledge furthermore data mining technique predict performance  noma  adopt data mining technology random ensemble decision naive bayesian logistic regression  mlp investigate semester economics  academic obtains data enrollment previous research basis mention focus FM model FM variant edm data mining technique mainly neural network NN regression performance prediction purpose performance prediction relevant information predict future performance accord task prediction task classification task regression task task sort task basis technology task involve conduct research performance prediction aspect FM performance prediction relative factorization machine performance prediction thai propose factorization machine model combine advantage vector machine factor decomposition model academic performance prediction regularization framework propose predict performance constraint preserve locality regularization non negative factorization machine feature curriculum implement prediction model achievement mixed curriculum machine algorithm vector machine vector regression decision naive bayes vector machine superior model NN performance prediction advantage neural network suitable regression analysis prediction task feedforward neural network progressively predict grade enrol entry cluster behavior cnn integrate personal behavior others behavior category information predict performance prediction recently rapid development effective model propose performance prediction enhance recurrent neural network framework incorporate knowledge concept moreover graph neural network achieve performance prediction interactive online pool investigation comparison finding FM model neural network feasible effective technical performance prediction neural network enhance ability grade feature representation hence advantage factorization machine neural network propose model ignore influence difficulty model mitigate effectively performance bias complexity propose model notation definition architecture CAISP overview CAISP component CAISP detail model clearly introduce complexity performance interaction attentive performance awareness prediction grade CAISP generally CAISP stage feature feature fusion prediction easy understand CAISP detail brief description motivation stage feature historical performance contains various feature complexity reflect characteristic dnn promising representation ability feature nonlinear performance information besides interaction feature FM widely feature interaction model feature interaction relation meanwhile individual difference capture via attention mechanism mainly model combination performance characteristic feature fusion obtain feature dnn feature FM feature feature feature fusion strategy fuse feature obtain fusion feature aspect information prediction stage fusion feature fed logistic regression model predict grade upstream task feature representation contributes effective prediction preliminary performance prediction grade denote arbitrary respectively grade kth  grade generality performance prediction define grade predicts performance input prediction model historical grade output prediction model future grade architecture complexity attentive interactive performance prediction model contains component FM component dnn component component sigmoid relu activation function respectively denotes sum operation image architecture CAISP architecture complexity attentive interactive performance prediction model CAISP model perspective CAISP consists component factorization machine FM neural network dnn attention network unity com FM com dnn com respectively FM feature dnn feature com com assign FM feature attention mechanism NN feature specifically FM feature feature dot summation splice dnn feature achieve multi feature fusion finally splice input logic regression calculation prediction obtain component CAISP propose CAISP compose component namely factorization machine FM neural network dnn attention network illustration FM component com embed feature interact feature via FM obtain formula dnn component com traditional feedforward neural network module CAISP CAISP neural network component feature nonlinear performance information embed feature input neural network connection operation dnn feature obtain formula denotes component com essentially attention neural network hidden layer basis FM component assign combination performance feature feature obtain formula detail component described complexity performance interaction FM component complexity performance interaction capture complexity feature achieve interaction feature factorization machine FM capture linear interaction performance feature allows parameter estimation sparse data optimize primal model replace inner calculation factorization machine dot calculation specifically initialize parameter parameter lookup exist iteration structure cod feature inside lookup feature lookup hidden factor vector feature parameter lookup update iteration input feature vector vector index index feature assign index vector feature vector corresponds model index layer lookup lookup obtain correspond accord index finally transforms sparse feature dense feature dense feature dot item sum dot sum feature vector performance information denotes feature dimension factorization machine feature sum linear regression finally prediction target FM model model replace inner calculation factorization machine dot calculation model formula factorization machine define ΠCom  hidden factor accord experimental feature dimension parameter parameter separately linear model logistic regression model hidden factor vector feature introduce factorization machine model feature input combination CAISP attention network output factorization machine define actual combination model ΠCom  definition factorization machine output convert tensor  non zero dimension dimension combinatorial feature dnn component CAISP neural network dnn nonlinear performance information feature illustrate CAISP model parallel structure DeepFM model model embed layer neural network FM neural network input performance information feature embed layer dimension finally feature recombine imply vector dimension denotes output embed layer output embed layer feedforward neural network connection relation layer layer neural network activation function output layer parameter layer layer denotes bias finally output dnn hidden layer feedforward neural network ΠCom WH attentive performance awareness component attentive performance awareness introduce prediction ability feature combination essentially attention network hidden layer factorization machine illustrate significance module model learns performance feature ΠCom     exp  nexp  dimensional vector neuron hidden layer attention network connection layer parameter input layer layer attention network relu function activation function model parameter layer output layer bias vector layer ensure feature combination within interval equation normalize feature combination input combination feature dimension attention network combination feature input layer attention network dimension feature convert hidden layer factor combine feature transfer layer dimension feature transform neuron hidden layer finally output layer dimension prediction grade CAISP propose CAISP achieves multi feature fusion via joint feature fusion strategy FM feature feature dot summation splice dnn feature feature fusion input logistic regression calculate prediction grade CAISP gain mention CAISP compose component FM dnn component ΠCom ΠCom splice output hidden layer neural network finally splice input logistic regression calculation prediction obtain prediction grade CAISP fusion strategy sigmoid ΠCom ΠCom  output propose model prediction convenience normalization limit predict vector hidden factor FM denotes dot ΠCom ΠCom sum vector neuron hidden layer dnn model ΠCom ΠCom ΠCom FM dnn respectively discussion CAISP model perspective CAISP firstly adopts dnn automatically combination feature reduces dependence artificial feature secondly feature advantage FM extract feature feature combine feature thirdly introduce reduce interference information improve performance model obtain FM feature feature dnn feature fuse via joint feature fusion strategy FM feature feature dot summation splice dnn feature finally fuse fed logistic regression compute predict grade task perspective complexity factor important role performance prediction task complexity feature feature besides feature combination sparse data CAISP interaction multidimensional feature meanwhile individual difference capture attention mechanism assign performance feature remove interference information amount information achieve focus attention important information conduct extensive datasets research RQ propose CAISP perform competitor RQ parameter CAISP model RQ individual difference reflect CAISP statistic datasets experimental setup subsection experimental datasets evaluation metric baseline firstly introduce dataset knowledge publicly available dataset performance prediction focus quality noiseless datasets dataset junior  model wuhan china dataset dataset china telecom  cup competition competition artificial intelligence competition host shanghai telecom although source dataset dataset datasets derive reflect performance meanwhile propose future grade prediction limited data source therefore performance prediction historical performance obtain feasible statistic dataset information dataset  worth mention dataset difficulty coefficient focus explore influence difficulty coefficient dataset complexity information dataset meanwhile grade information dataset information information dataset respectively attribute information datasets evaluation metric regression model error mse absolute error mae evaluate prediction performance penalty error sensitive response outlier metric widely evaluate effectiveness model calculation formula mse mae experimental obtain calculation formula mse mae sample actual model predict baseline focus performance prediction model factorization machine FM model justify effectiveness CAISP model FM model performs feature combination sparse data widely prediction task extend FM model variant task performance prediction NFM AFM DeepFM model neural network model architecture model combine neural network factorization machine specifically NFM adopts combination linear factorization machine nonlinear neural network AFM attention network basis factorization machine DeepFM incorporates neural network factorization machine specific model implementation detailed introduction baseline FM traditional factorization machine model machine algorithm matrix factorization purpose factorization machine feature combination sparse data FM algorithm recommend algorithm proven effective recommendation NFM neural factorization machine model combine effectiveness linear factorization machine powerful representation capability nonlinear neural network sparse predictive analysis core NFM bilinear interaction pool operation neural network neural network combine feature information dimensional layer AFM AFM attentional factorization machine AFM enhances FM importance interaction feature attention network improves ability representation improves FM introduce importance feature FM importance attention mechanism DeepFM factorization machine factorization machine neural network ctr prediction neural network factorization machine extract feature feature input FM architecture component input raw feature vector enables FM feature interaction input raw feature implementation detail baseline model CAISP model mainly implement tensorflow footnote dataset randomly split training ratio respectively hardware configuration intel xeon cpu gpu nvidia gtx TI 8GB ram 1GB video memory batch DeepFM AFM NFM CAISP model epoch regularization parameter respectively relu activation function employ model gain reliable model report average performance data processing analysis dataset observation data data data eliminate negative impact inconsistent data experimental data examination remain performance data dataset global observation data ensure uniformity data data scope data global analysis dataset complexity average complexity standard deviation analysis statistical visualization standard deviation std commonly probability statistic statistical dispersion reflect dispersion dataset standard deviation aggregate data standard deviation discrete data  relationship complexity ordinate performance ordinate complexity difficulty knowledge sum complexity knowledge complexity difficulty conversion formula formula complexity complexity relationship complexity standard deviation abscissa complexity difficulty ordinate standard deviation performance difficulty transformation formula formula standard deviation transformation formula formula  observation complexity average complexity standard deviation difference performance visualization data analysis dataset complexity complexity std image performance comparison dataset performance comparison RQ subsection performance comparison analysis validate advantage CAISP via overall performance comparison importance difficulty coefficient performance prediction ablation overall performance verify effectiveness propose CAISP conduct performance comparison datasets comparison dataset FM NFM AFM DeepFM CAISP dataset conduct calculate mse mae accord formula error accuracy effective model mse mae model bolded baseline effectiveness validate specifically model factorization machine performance DeepFM NFM FM AFM DeepFM model performs DeepFM ability combinatorial feature addition FM module module grade feature embed facilitate faster training accurate CAISP model consistently baseline specifically CAISP outperforms baseline mse mae dataset respectively performance comparison dataset complexity denotes remove complexity complexity visualization knowledge difficulty analysis knowledge difficulty dataset image performance mse mae baseline CAISP model worth mention complexity incorporate complexity feature model complexity remove complexity feature model dataset contains difficulty coefficient complexity knowledge analyze integrate complexity complexity analysis ablation respect complexity subsection dataset performance baseline DeepFM AFM NFM FM performance comparison dataset difficulty coefficient feature representation variant FM advantage handle multi feature combination CAISP outperforms baseline DeepFM relative improvement mse mae dataset advantage CAISP baseline enrich feature enhance correlation feature feature fusion strategy employ attention mechanism individual difference difficulty coefficient dataset difficulty coefficient feature ablation perform dataset understand difficulty coefficient dataset visualize difficulty distribution diagram knowledge complexity knowledge treat complexity affect judgment performance prediction therefore difficulty coefficient feature performance prediction facilitate formulation complexity difficulty coefficient verify impact complexity comparison complexity feature complexity without complexity complexity calculate mse mae respectively exhibit complexity complexity dataset data mse mae calculate formula performance complexity complexity CAISP baseline moreover complexity performance CAISP improve mse mae respectively without complexity performance CAISP hidden layer dataset performance CAISP epoch dataset image parameter analysis RQ subsection investigate accuracy propose model respect parameter performance CAISP model epoch hidden layer neural network varied respectively performance CAISP epoch dataset illustrates batch affect increase epoch mse gradually decrease accuracy increase finally becomes stable epoch regression CAISP model hidden layer hidden layer layer neuron due advantage deeper hidden layer regression layer regression layer hidden layer neuron nonlinear feature graphical illustration individual difference dataset image visualization individual difference RQ individual difference CAISP strives treat individual assist personalize understand visualize difference impact attention mechanism attention network AFM model AFM model accord depth darker impact dataset marked respectively visualization model AFM respectively illustrate observation mention AFM model mostly difference influence AFM judge impact ignores therefore model performs performance prediction personalize planning conclusion effectively alleviate performance bias complexity individual difference propose novel complexity attentive interactive performance prediction model predict grade enable personalize planning experimental demonstrate effectiveness propose optimal improvement baseline CAISP model difficulty individual difference improve capacity performance prediction meanwhile develop joint feature representation via interaction enhance correlation feature besides extend FM model variant task performance prediction experimental analyze advantage graph neural network explore complex relation graph