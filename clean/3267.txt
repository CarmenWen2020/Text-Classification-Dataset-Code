mapreduce framework effectively multi petabyte data distribute manner therefore mapreduce widely heterogeneous environment performance adequate despite mapreduce benefit tweak configuration achieve maximum performance challenge expertise besides mapreduce security issue address recently performance aware secure framework minimize makespan task task security constraint inspire algorithm introduce proposes stage static scheduler reduce phase respectively minimize makespan network traffic plus introduces mathematical optimization model propose scheduler aim estimate performance security constraint error experimental demonstrate outperforms hadoop stock makespan network traffic respectively task heterogeneous environment previous keywords bigdata hadoop mapreduce schedule makespan security optimization model heterogeneity introduction rapidly data production necessitates non classical processing approach handle processing massive data volume hadoop processing asset compute source implementation mapreduce program model handle data  parallel mapreduce consists dependent task reduce task former latter output mapreduce data parallelism framework input dataset  split disposal task task performs activity data mapping partition sort intermediate output file MOF similarly reduce task performs activity intermediate related shuffle copying merge reduce shuffle network grouped user define reduce function intermediate generate reduce output file  extensive exploit performance mapreduce task schedule schedule network traffic essential factor achieve performance maximize distribute meeting requirement prefer task schedule task throughput completion JCT moreover shuffle phase data transmission source destination across network completion FCT directly influence JCT therefore data intensive distribute hadoop multiple efficient schedule concern hadoop scheduler fifo  hadoop capacity scheduler HFS hadoop scheduler however homogeneity assumption propose scheduler degrades performance mapreduce framework nowadays favour hardware technology advancement specific diversity hardware contributes performance environment mapreduce execution therefore heterogeneous cluster goal increase scope mapreduce task schedule usually focus assignment reduce task belief schedule initial data distribution file host mapreduce compute node however mapreduce performance environment assumption valid input data resides remote file amazon therefore data load remote location schedule task becomes important additionally mapreduce application sensitive economic health scientific research mapreduce security aspect arouse attention devote investigate mapreduce security server link typical application stack arise valuable asset apparent manage petabyte data centralize cluster dangerous encounter emergent exploit operation security service security sensitive application attack intend deploy mapreduce data processing service service orient architecture compute volunteer compute although security mechanism increase overhead computation task guarantee security mapreduce task execution hadoop assumes entire cluster machine user access trust network establish secure stance effectively hadoop security enforce anything researcher underestimated conventional mapreduce schedule algorithm contribution extent knowledge simultaneously address reduce task schedule makespan security leverage performance aware stage schedule  task heterogeneous environment optimization model propose reduce completion task makespan increase security execution robust diverse attack considers network traffic transfer output task applies flexible reduce task partition binding static schedule reduce task organize introduces hadoop core component review literature describes parameter model propose methodology propose framework discussion conclusion future background apache hadoop assist distribute processing datasets google mapreduce google file  model prevalence hadoop academic community due source hadoop framework classify described hadoop file hadoop distribute file hdfs fault tolerant scalable developed data commodity hardware architecture hdfs namenode node access client data performs namespace operation location DataNodes DataNodes node responsible client operation default replication factor hadoop hdfs placement policy replica node local rack another node rack remote node node remote rack establish fault tolerance besides hadoop employ backup namenode  checkpointing server checkpoint file metadata namenode failure occurs mapreduce program model mapreduce program model express computational function reduce stage partition task reduce stage partition reduce task illustrates mapreduce architecture data data domain split fed input user define function domain partition MOF output sub partition belonging grouped partition user define reduce function reduce stage phase remote fetch shuffle merge reduce shuffle phase intermediate machine host merge phase sort reduce phase domain  output reduce  generally hdfs yarn cluster manager version hadoop mapreduce another resource negotiator yarn propose apache overcome limitation scalability reliability resource utilization despite hadoop mapreduce version centralize resource management task schedule utilized yarn allows global ResourceManager RM per application  detach service besides yarn adopts resource abstract container resource provision encapsulates multi dimensional resource node cpu memory resource manager receives mapreduce per application application obtains resource ResourceManager node manager execute monitor task yarn flexibility application cluster program framework validate already attract yarn batch processing perform mapreduce online processing apache storm memory processing apache spark via yarn related mapreduce task schedule approach category accord strategy optimization objective heterogeneity environment workload worker scheduler designer focus schedule aim minimize makespan increase security heterogeneous environment therefore extrapolate discussion survey category explain related category entity schedule numerous propose task scheduler improve mapreduce performance accord taxonomy hadoop schedule user task HFS  user schedule fifo priority scheduler schedule hadoop built schedule algorithm schedule task criterion performance makespan data locality network traffic grain schedule task schedule reduce speculative task schedule default hadoop scheduler data locality criterion task schedule selects local task resource enquiry meta data service host data chunk besides hadoop randomly selects reduce task schedule available resource however built hadoop scheduler homogeneous environment performance resource performance chose heterogeneous HEFT algorithm inspire algorithm context mapreduce HEFT algorithm classic algorithm static task schedule effective dag schedule heterogeneous HEFT robust performance complexity ability stable performance graph structure research improvement HEFT algorithm apply HEFT algorithm context mapreduce schedule benefit HEFT algorithm improve HEFT algorithm extra information meta heuristic mixed technique increase schedule complexity propose mathematical model HEFT framework SPO analyse accurately  however although algorithm analyse behaviour challenge interaction component highly nonlinear complex stochastic model processing massive data intensive adopt HEFT excellent choice SPO HEFT schedule dependent task onto network heterogeneous resource communication account HEFT consists phase prioritize task assign task resource phase task priority phase task assign resource task priority dependent task schedule worker task depends communication input resource computation task resource processor becomes available HEFT utilizes insertion policy sufficiently gap schedule task   propose improvement HEFT algorithm task workflow resource requirement successful execution therefore author factor ram storage memory inter node bandwidth addition cpu resource propose algorithm efficient schedule promising improvement heterogeneous HEFT estimation task locally optimal decision considers ahead schedule information affect task decision boost schedule task HEFT algorithm information descendant task author modify HEFT algorithm load balance modify HEFT modify HEFT distributes almost evenly workload processor reduces makespan application propose enhancement variant heterogeneous algorithm HEFT user specify financial constraint achieve load balance across virtual machine minimize makespan author define load threshold machine processing storage capacity afterwards define dataset cluster dependency prioritize task resource task theory stochastic genetic algorithm propose enhance HEFT algorithm author multiple priority prioritize sub task task heterogeneous compute resource heuristic HEFT propose task schedule algorithm QL HEFT combine HEFT algorithm reduce makespan algorithm upward rank HEFT immediate reward framework agent obtain update however excessively excessive update increase schedule propose  mapreduce enable workflow scheduler HEFT scheduler minimize performance heterogeneous environment model mapreduce workflow schedule phase prioritize resource allocation priority scheduler prioritize phase phase data locality criterion schedule resource propose resource aware scheduler  account resource heterogeneity compute environment benefit HEFT algorithm estimate compute ect schedule cpu bound IO bound task resource task bias identification machine however scalability  enhancement applicable environment mention HEFT employ coarse grain schedule apply HEFT algorithm grain reduce task schedule highlight choice category optimization approach schedule aim optimization objective multiple conflict objective without constraint objective makespan security  optimize makespan security propose multi objective mapreduce task scheduler  fulfil user objective deadline provider goal resource efficiency constraint deadline budget assignment resource summation predefined service function author propose user benefit objective scheduler minimizes completion usage service mapreduce environment scheduler defines priority earlier task propose  multi objective multi constrain schedule algorithm optimizes workload cluster meeting budget deadline constraint author propose fitness adaptive genetic algorithm minimizes makespan balance load cluster author greedy algorithm initialize population calculate objective function propose multi objective optimization scheduler ant algorithm propose scheduler resource model optimize user objective makespan resource usage user define constraint budget security orient mapreduce  infrastructure propose integrates data processing framework management trust compute infrastructure guarantee persistent security user data processing propose multi objective heuristic algorithm component propose scheduler optimizes objective makespan data locality security  singh author data leakage detection max secure environment avoid data leakage author reduce data identify data leakage faulty agent probability propose mandatory access integrate differential privacy propose secure enables privacy preserve mapreduce computation without audit untrusted code prevents information leakage data provider policy propose methodology security analysis locates extract data probably related attack malicious user intend compromise data author identify predict attack detect intrusion author security privacy layer model hadoop file hdfs mapreduce layer secure mapreduce SMR layer advantage model promote data knowledge mining model creates privacy security guarantee resolve scalability issue privacy maintain privacy utility tradeoff data miner SMR model information loss cpu memory usage remarkable improvement pro con mention optimization lack comprehensively spent stage mapreduce shuffle reduce minimize makespan moreover although address security objective risk limitation constraint therefore focus mono objective mapreduce schedule constraint introduce mathematical model aim optimize makespan objective security risk limitation constraint mathematical model mixed integer non linear program MINLP highlight taxonomy choice category advantage model comparison optimization approach optimization  shuffle makespan minimization optimize makespan budget deadline constraint security constraint  load balance contradict objective static model reduce task cpu IO intensive constraint minimize makespan network makespan minimization  scalable contradict objective static model reduce task cpu IO intensive shuffle makespan minimization optimize makespan budget deadline constraint security constraint  contradict objective static model reduce task cpu IO intensive minimize makespan optimize load balance security constraint  adaptive genetic algorithm AGA static model reduce task cpu IO intensive schedule complexity assume security met optimize performance network makespan minimization  improve ant algorithm  static model reduce task schedule complexity heterogeneous environment minimize makespan data locality security constraint confidentiality security mechanism apply  load balance network static model reduce task cpu IO intensive minimization maximize security load balance constraint heterogeneous environment max load balance integrity security mechanism apply static model reduce task cpu IO intensive risk analysis makespan minimization maximize security heterogeneous environment SMR security mechanism static model reduce task scalable cpu IO intensive stage makespan minimization shuffle reduce phase security risk rate SPO contradict objective minimize  due maximize security risk limitation constraint data locality reduce data locality reduce load balance dynamic model reduce task prior scalable heterogeneity minimize makespan task improve hadoop performance categorize ignore resource workload heterogeneity heterogeneity workload resource category propose johnson static scheduler aim reduce makespan mapreduce propose scheduler inspire reduce execution stage prior propose heuristic johnson pool balance pool utilized minimize pool makespan nevertheless propose optimal cannot reduce overall makespan propose extend johnson algorithm minimize overall makespan user drawback propose scheduler user queue achieve minimum makespan capacity cluster ignore data propose approximation task schedule algorithm minimize completion makespan assumes task parallelizable homogeneous hadoop cluster whereas reduce task non parallelizable preemption achieve fairness propose online scheduler goal minimize makespan mapreduce preemptive non preemptive reduce task homogeneous hadoop cluster propose scheduler optimal cluster node heterogeneity scalability ignore besides propose considers neither heterogeneity resource category inspire bin pack propose static task scheduler reduce makespan heterogeneity cluster goal reduce task execution reduce related task assign faster node remain reduce task gradually minimize makespan reduce makespan assume task parallelizable execute multiple machine propose multi objective schedule algorithm mapreduce environment service completion account optimization objective minimize makespan propose scheduler achieves task throughput efficiency resource usage user fifo scheduler propose scheduler mapreduce cluster improve hadoop performance makespan propose novel batch scheduler mapreduce propose scheduler information request resource resource capacity task dependency task fitness function schedule manage conduct various workload resource heterogeneity task schedule mapreduce obtain network traffic task throughput optimally heterogeneous environment scheduler  policy  achieves capacity minimization backlogged task traffic regime however address reduce task schedule network shuffle phase propose task locality aware scheduler  minimize makespan alleviate amount intermediate data shuffle phase minimize local task node combiners combine shuffle phase per combiner memory reservation task schedule environment heterogeneous workload however reduce task schedule kalra singh review metaheuristic schedule algorithm propose mapreduce scheduler genetic algorithm GA ant optimization ACO league championship algorithm lca particle swarm optimization PSO algorithm optimal environment grid distribute environment minimize makespan nevertheless leveraged greedy heuristic suitable schedule metaheuristic converge due insufficient optimization non optimal fitness function objective aim minimize mapreduce execution security risk limitation constraint employ HEFT algorithm develop mapreduce schedule optimization framework focus heterogeneous resource highlight taxonomy choice category propose framework preliminary consists schedule mapreduce task security constraint minimize execution makespan presentation target model mapreduce environment detailed description makespan model mapreduce besides security constraint execution introduce security model moreover risk analysis formulate index parameter variable model reference notation model  index task index task reduce task index reduce task index core index partition index security index parameter task reduce task core partition execution task core processing rate computational task function distance core core maximum reducer assign partition node data volume generate task traffic task reduce task partition input data traffic partition reduce task propagation delay data transfer bandwidth execution reduce task core security service security requirement task obtain security service security task security overhead task risk rate constraint risk rate risk rate security service task variable model schedule model consists multiple task target compute environment performance criterion schedule suppose reduce task mapreduce environment task parallel heterogeneous resource reduce task entire task logical correctness mapreduce program model makespan completion JCT mapreduce therefore option minimize makespan define task optimal define reduce task optimal diminish task execution diminish execution reduce task task accord input split hdfs chunk input file chunk hdfs input split accordingly task hadoop stock reduce task alternative define user define parameter mapper reducer fix application submission however defines reducer dynamically output partition recall performance reduce storage access due sequential fault tolerance amount computation perform reduce task fail diminish task execution option reduce task option simultaneously target explain image KB image minimization assumption due complexity mapreduce schedule formally described assume heterogeneous compute node organize core assign logical container physically distribute core node fractional meaning arbitrarily split node associate container therefore split simultaneously node split task reduce task independent advanced execute parallel core reduce task launch task task reduce task task generate partition partition local disk execution task respectively summation task define input dataset uploaded hdfs reduce task specify partition model assume execution task application non preemptive meaning task reduce task interrupt pause processing besides data transfer rate network bandwidth cluster node matrix propagation delay node dimensional vector completion reduce task goal minimize makespan server completes task security constraint security constraint makespan model mapreduce execution consists mapping networking reduce minimize makespan batch task mapreduce execution task transfer intermediate data stage across network shuffle phase execution reduce task therefore completion mapreduce task model schedule makespan function execution task stage denotes transfer intend data sub partition related specific partition transfer resource partition placement strategy delay resource moreover execution aggregate partition related reduce task reduce stage makespan minimization objective function makespan minimization formulate makespan minimization define binary variable task non fractional cannot split execute resource define constraint limitation processing core task task certainly schedule resource execute task resource calculate computational execution therefore define parameter resource task task average task calculate task average task calculate obtain task resource calculate stage equation therefore objective function minimize shuffle minimization formulate traffic minimization shuffle phase data stage reduce stage define binary variable described reduce task receives reduce task constraint therefore reduce task partition host constraint convert denote traffic mapper reducer calculate data transfer resource propagation delay resource bandwidth resource phase shuffle reduce task reduce task task average traffic transfer task calculate network traffic calculate therefore objective function minimize statement reduce makespan minimization define binary variable reduce task execute resource otherwise zero constraint resource executes reduce task   reduce task schedule resource execute reduce task resource calculate determines computational reduce task execution similarly calculate average reduce task obtain reduce task processing calculate reduce task therefore objective function minimize security model various security threat concern distribute compute mandatory deploy security service security critical mapreduce application attack snoop spoof frequent attack distribute mapreduce application threat employ security service authentication service integrity service confidentiality service therefore become apparent mechanism hadoop user authenticate identity strongly mechanism chosen hadoop project kerberos establish service enterprise microsoft active directory authentication authorization apply algorithm secure authorization define individual user authenticate authorization implement per component basis meaning administrator establish authorization multiple another aspect hadoop security evolve protection data encryption confidentiality mechanism trust network assume data inherently unauthorized user authorize user network hadoop encryption data transmit node blowfish  algorithm data disk DES aes algorithm security service user flexibly combine construct integrative security protection variety threat attack illustrates mapreduce workflow execution security service prevent spoof attack deploy authentication service authenticate user intend access input data output data task transfer reduce task reduce task execute input data output data MOF integrity service ensure detection tamper dataset cope alteration threat execute task finally avoid unauthorized interception reduce task output data confidentiality service apply counter snoop attack ensure data available unauthorized therefore task various attack hadoop user security integrate security protection mapreduce environment security overhead mapreduce execution augment indicates overall overhead phase image KB image secure enable mapreduce execution assume reduce task security service security specify user security requirement task specify tuple demand security security service simplicity authentication service integrity service confidentiality service respectively security cryptographic overhead confidentiality service performance cryptographic algorithm algorithm assign security assign security slowest encryption algorithm security algorithm inversely proportional overhead security service task indicates security service task obtain security service introduce overhead exist compute integrity confidentiality service amount security overhead mainly depends service data hence security overhead service denote data task however security overhead authentication service constant depends service hence security overhead authentication service compute cryptographic algorithm confidentiality cryptographic   KB seal RC blowfish RC DES overall security overhead experienced task calculate hadoop cluster assume server security service hadoop user various security qos requirement execution mapreduce user task risk therefore evaluate security service quantitatively perform risk analysis entire mapreduce workflow reduce task calculate risk probability task security service exponential distribution risk coefficient attack interval hence calculate risk probability task security service reduce task risk rate define calculate risk probability mapreduce risk rate constraint mathematical model evaluate tier HEFT schedule schedule reduce task reduce task task workflow reduce task task input task rank rank reduce task exit task propose framework tier HEFT algorithm schedule task reduce task dramatic workflow mapreduce accord HEFT algorithm formulation mapreduce schedule task attempt correspond resource execute distribute execution makespan minimize task within security constraint met therefore overall mathematical model minimize objective function makespan  equation optimization framework layer architecture schedule optimization framework layer assign   admin customize resource allocation reside ResourceManager layer task schedule resource format distribute container correspond  SPO focus schedule layer benefiting default yarn scheduler layer accord client  security service submits execution client queue  assign logical container physically expand node allocate  logical container  client input data file hadoop file hdfs file encrypt replicate node data preprocessing component disposal information reduce task execution obtain profile ResourceManager query task information performance aware reduce task scheduler component respectively SPO schedule task scheduler algorithm execution task output local disk host node output file MOF  daemon active node report status node ResourceManager MOF consist data byte sub partition partition partition partition execution task resource    processing task cpu intensive IO intensive cpu intensive IO intensive asynchronous reduce stage stage disk resource reserve task intermediate partition data reduce stage reduce task partition  partition constitutive scatter sub partition belonging specific therefore query information reduce task execution preprocessing stage reduce stage scheduler schedule reduce task algorithm image KB image output file MOF format preprocessing availability information execution reduce task decision fundamental static schedule heterogeneous cluster slot processing rate besides heterogeneous hardware structure processing slot various cpu intensive IO intensive hence mapreduce correspond compute task resource execution reduce phase mapreduce enable spark infrastructure input data profile built monitoring spark duration phase initialization shuffle reduce obtain information respectively apply matrix reduce stage schedule respectively stage responsible initial calculation stage reduce stage scheduler fed reduce matrix input respectively consideration mixture workload partition task indicator estimate execution reduce task efficiently define partition placement heterogeneous resource scheduler algorithm ratio task output input define selectivity average per input split selectivity invariant task amount data functionality therefore heterogeneous environment heterogeneous processing capacity execution task affected server suppose split data already reside node scheduler schedule task HEFT algorithm information task execution obtain stage task schedule minimum execution achieve algorithm image KB image algorithm variable  resource execution reduce task minimize reduce task reduce task execution reduce task minimum reduce task reduce task resource cluster reduce scheduler algorithm SPO schedule reduce task output stage minimize reduce task completion decrease reduce task execution algorithm reduce task specify reduce task reduce task execution define reduce task schedule resource minimize execution algorithm SPO calculates partition related sub partition volume scatter node cluster SPO reduce task define dynamically partition define reduce task partition coefficient variable parameter variable algorithm image KB image image KB image accord algorithm propose performance traffic aware partition placement partition LPF LPF rank partition decides node minimize related reducer server performance data transfer across network reducer reducer reducer execution accord reducer execution calculate execution reducer related partition obtain reduce task execution node cluster preprocessing stage maintain information reducer calculate maximum elapse transfer sub partition related partition node specific node slot specific node becomes available execution reducer calculate reducer calculate reducer reduce reducer execute node parallel core resource queue becomes therefore reducer depends maximum factor elapse transfer sub partition related partition node specific node resource available image KB image diagram propose framework SPO partition transfer calculate transfer data node propagation delay resource notably reducer execution data related maximum transfer sub partition partition resource account resource available cpu resource becomes available execute reduce task production partition resource become load reduce task minimize update cpu available resource correspond reducer partition schedule node flowchart SPO validation framework implementation validation detail propose framework discus obtain prototyping evaluate resource allocation schedule algorithm distribute hadoop challenge labour intensive consume task simulate ass overall performance security SPO via simulation accord mapreduce evaluate cloudsim derivation    implement java         benefit entity java cloudsim datacenter host cloudlet scheduler experimental setup environment framework propose commonly mapreduce performance evaluation overview SPO evaluation setup accord explain subsection implement strategy computer intel core quad core processor ram version linux ubuntu cod java eclipse photon release JDK yarn environment java heterogeneous physical server medium resource network machine randomly generate simulate heterogeneity server capacity computation server mips focus cpu utilization assume yarn resource container unlimited memory dataset benchmark simulated input data intermediate data accord benchmarking apache hadoop distribution wordcount terasort grep etc yarn SLS simulator partition simulated dataset GB accord generate intermediate partition data simulator uniform distribution GB shuffle shuffle respectively define shuffle  output data application specific parameter depends input data shuffle shuffle output data respectively instance apply shuffle dataset intermediate data generate task performance metric parameter evaluation criterion makespan elapse execute entire mapreduce equation calculate makespan reduce task calculate security overhead processing data encryption decryption task execution integrity user authentication network overhead remotely fetch data task intend node scalability performance evaluation leverage resource input data homogeneous heterogeneous environment evaluate performance propose model propose framework perform various propose model makespan minimization security overhead evaluate performance gap demonstrate effectiveness analyse perspective performance evaluate environment homogeneous heterogeneous dataset hadoop stock makespan intermediate data processing mention experimental propose framework without security constraint framework objective makespan minimization security constraint experimental propose model evaluate performance gap propose framework optimal obtain propose MINLP optimization model toolkit situation performance objective function constraint performance objective function security constraint subsection comparison performance medium instance simulation evaluate accuracy performance model regard typical mapreduce mapreduce reduce input amount input data generate extensive intermediate data input data respectively parameter input data task generate correspond output due computational complexity formulation partition associate random data sub partition random data generate node within selectivity task input data respectively plus configure bandwidth cluster propagation delay resource scenario resource input data propose model respectively performance aware stage mapreduce task schedule algorithm scenario  function minimize makespan  GB task homogeneous  environment average performance optimal comparison obtain solver scenario define scenario precisely resource cluster whereas input data task processing data respectively objective function homogeneous heterogeneous environment respectively relative error optimum calculate optimum respectively zero propose scheduler proven optimal whereas gap exist heterogeneous homogeneous environment obtain optimal gap optimal besides scalable performance linearly resource specific input data comparison security overhead security overhead  security overhead security constraint met makespan heterogeneous environment conduct input data environment resource apply benchmark cpu intensive shuffle application selectivity makespan task indicates overhead fulfil security task secure environment slightly overhead satisfy maximum security risk analysis analyse risk conduct execution homogeneous heterogeneous environment risk rate comparison execution homogeneous heterogeneous environment respectively define minimum service maximum service algorithm baseline security task risk rate mapreduce contrast security task risk rate risk rate increment maximum risk rate makespan makespan respectively security service fix respectively indicates execution risk rate algorithm risk rate makespan slowly risk rate task demand risk rate security service demand makespan heterogeneous environment resource processing capacity security user execution protection parameter wordcount related cpu intensive hence cpu resource capacity image KB image security overhead GB input data GB input data GB input data GB input data interpretation reference colour legend reader refer web version article risk coefficient correlation risk rate increase risk coefficient zero accord probability risk task zero meaning task demand service security suffer attack apply authentication service execution risk rate curve becomes confidentiality integrity service risk coefficient graph steadily grows risk rate accordingly increase execution image KB image impact risk rate risk coefficient makespan wordcount grep image KB image execution wordcount data homogeneous environment execution wordcount data heterogeneous environment node respectively image KB image execution data homogeneous environment execution data heterogeneous environment node respectively image KB image execution sort data homogeneous environment execution sort data heterogeneous environment node respectively hadoop stock evaluate objective makespan minimization network traffic heterogeneity workload environment shuffle cpu IO intensive plus heterogeneous environment contains resource processing simulation homogeneous heterogeneous environment adopt setting host homogeneous environment processor host heterogeneous environment consists intel xeon processor robin distribution processing homogeneous average compute comparison heterogeneous resource comparison besides practically ass scalability various data environment medium environment assume host host medium environment environment host yarn environment homogeneous heterogeneous resource interconnects resource gigabit ethernet yarn resource container unlimited memory focus cpu utilization input file determines task hdfs MB scenario summarize benchmark characteristic scenario respectively makespan completion wordcount sort grep homogeneous heterogeneous respectively application characteristic  IO   occurrence   input data  popular benchmark sort   terabyte randomly distribute data  cluster analysis algorithm multi   numerical sample data mining  occurrence   target text file scenario description workload  data medium task scenario cpu intensive intermediate GB GB GB GB data GB scenario IO intensive intermediate GB GB GB GB data GB scenario cpu intensive intermediate GB GB GB GB data GB scenario IO intensive intermediate GB GB GB GB data GB scenario cpu intensive IO intensive GB GB GB GB image KB image execution grep data homogeneous environment execution grep data heterogeneous environment node respectively image KB image completion   completion workload        wordcount accord execution increase resource wordcount application input achieves performance significant amount input data increase resource performance gain environment environment GB GB input respectively mention homogeneous environment GB dataset performance cluster task resource performance gain considerable heterogeneous environment makespan homogeneous performance gain environment environment GB GB input respectively heterogeneous environment greedy behaviour resource prefer decision earlier task subsequently overall makespan phase phase iteration phase phase cluster phase earlier phase task cpu bound meaning performance increase improvement processing increase resource perceptible performance gain environment environment GB input homogeneous heterogeneous environment respectively however performance gain heterogeneous homogeneous considerable performance IO bound cluster phase meaning performance limited IO data communication within cluster shuffle intermediate partition overhead network traffic almost environment indicates slightly makespan homogeneous environment heterogeneous environment due computational sort execution increase resource sort application input homogeneous environment performance gain homogeneous environment comparison environment GB GB input respectively indicates performance heterogeneous environment roughly input data performance input data GB achieve environment respectively homogeneous environment grep grep application minimum runtime application faster wordcount sort benchmark heterogeneous environment respectively grep runtime grep IO intensive shuffle reduce task processing partition consequently makespan moreover performance improvement heterogeneous environment comparison homogeneous environment GB input medium environment respectively mixed scenario conduct complex multiple cpu IO intensive input data intermediate data heterogeneous environment combine wordcount GB sort GB grep GB GB input data respectively presence multiple default hadoop scheduler fifo priority however future apply analytic hierarchy AHP model permutation attribute cpu IO intensive shuffle combination shuffle shuffle  workload wordcount grep heterogeneous environment SPO outperform hadoop stock wordcount grep respectively SPO asynchronous schema reduce task task allows reduce task resource prioritize grep intermediate data earlier wordcount execution reduce task consequently performance significantly boost shuffle performance sort wordcount SPO improve execution hadoop benchmark wordcount shuffle volume therefore reduce task earlier partition shuffle performance sort scenario reduce task delayed wordcount another sort shuffle reducer responsible processing partition therefore LPR algorithm reduce network traffic preserve data locality reducer sacrifice performance sort execution longer SPO heterogeneous workload hadoop stock SPO reduce completion workload SPO considers heterogeneity resource performance gain depends task schedule placement amount shuffle data comprehensive performance analysis SPO hadoop stock stage shuffle reduce apply benchmark define wordcount grep sort GB input data per application heterogeneous node axis latency stage report average simulation demonstrate confidence deviation negligible grep random intermediate data generate plus deviation wordcount sort SPO outperform hadoop stock makespan stage SPO makespan considers resource performance schedule task hadoop stock performance aware selects task data locality task local randomly cluster resource makespan moreover although hadoop stock already overlap shuffle phase stage mechanism shuffle task however network traffic hadoop stock considerably volume data transfer across network towards randomly schedule reduce task repetitive merges disk access reduce phase shuffle grey however SPO schedule partition data locality partition placement algorithm LPF mitigates network data traffic average hadoop stock despite shuffle along hadoop stock performance SPO due asynchronous reduce scheme SPO shuffle phase therefore resource disposal task  execution hadoop stock task reduce task compete resource asynchronous reduce scheme improve data locality along input data distribution reducer achieve LPF algorithm concurrent mapreduce reduce concurrent phase execution adequately demonstrate SPO accelerate wordcount sort grep efficiently execution average respectively meanwhile achieves competent scalability data processing complexity SPO task resource respectively image KB image per stage latency SPO hadoop stock benchmark intermediate data comparison completion SPO hadoop scheduler fifo  shuffle intermediate data shuffle delay unimportant completion intermediate data understand performance scheduler intermediate data completion algorithm linearly intermediate data completion consistently hadoop stock scheduler reduce task statically schedule prolong shuffle network phase discussion future propose performance aware security aware schedule framework SPO mapreduce task heterogeneous environment besides mono objective multi constraint mathematical model efficiency model SPO makespan security overhead SPO HEFT algorithm aim minimize mapreduce task execution meeting security constraint optimization strategy moreover extensive synthesize application demonstrate effectiveness practicality SPO hadoop stock regard compute mapreduce  environment already service user therefore execution become essential factor future refine propose mathematical model minimization optimization objective