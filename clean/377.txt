recent  AI revolutionize almost technology ubiquitous smart mobile gadget iot device majority intelligent application deployed wireless network trend generate realize intelligent AI enable application various device accordingly research emerge  discipline wireless communication machine theme overcome limited compute limited data device accomplish leverage mobile compute platform exploit massive data distribute device distribute data communicate server device critical couple aspect fusion research challenge article advocate guideline wireless communication collectively driven communication illustrative demonstrate effectiveness guideline unique research opportunity identify introduction article advocate guideline wireless communication collectively driven communication illustrative demonstrate effectiveness guideline unique research opportunity identify witness phenomenal growth global data traffic accelerate increase popularity device accord international data corporation billion device internet global data zettabyte data generate unprecedented amount data recent breakthrough artificial intelligence AI inspire envision ubiquitous compute ambient intelligence improve quality platform scientific discovery engineering innovation vision academia  invest technology intelligent network emerge application scenario smart ehealth  intelligent transportation emergence research refers deployment machine algorithm supervise unsupervised reinforcement network motivation rapid access enormous data generate device AI model training endows device intelligence respond traditionally training AI model neural network model computation intensive powerful server rid recent trend develop mobile compute platform training AI model longer exclusive server affordable server network virtualization architecture recently recommend international telecommunication union telecommunication standardization sector ITU compute moreover mobile device performance central processing graphic processing  chip iphone capable training AI model coexistence device paradigm layer architecture network machine layer posse data processing storage capability cater application distinct latency bandwidth requirement layer network machine architecture layer network machine architecture objective intelligence acquisition highly distribute data subscribed device critically depends data processing server efficient communication server device device unique strength balance resource achieve AI model complexity model training latency proximity data source overcomes drawback fails data due excessive propagation delay data upload furthermore proximity additional advantage location context awareness device achieves accuracy complex model importantly aggregate distribute data device due capability spectrum AI model mobile application auto augment virtual reality AR VR application online auto AI model continuously adapt ambient environment split decision apply brake AR VR  haptic perception cannot afford delay otherwise user suffer sickness nevertheless nascent stage remains largely  challenge objective intelligence acquisition highly distribute data subscribed device critically depends data processing server efficient communication server device increasingly processing server communication suffers hostility wireless channel loss shadow fading consequently bottleneck ultra distill intelligence distribute data excessive communication latency arise upload server vast amount data generate billion device illustrate concrete tesla AI model auto continuously improve radar lidar data uploaded tesla vehicle amount GB per  data scarcity resource fully exploit distribute data AI model training without incur excessive communication latency challenge wireless data acquisition  unfortunately wireless technology incapable tackle challenge fundamental traditional objective wireless communication namely communication reliability data rate maximization directly away conventional philosophy traditional wireless communication regard communication compute separation approach instead exploit couple communication materialize philosophy propose article guideline wireless communication collectively driven communication discus specific research direction concrete illustrate paradigm shift communication aspect multiple access resource allocation signal encode summarize guideline theme highlight guideline driven communication intelligence acquisition efficiently transmit relevant information data improve AI model training server driven multiple access motivation principle involve training data privacy sensitive quantity upload device server centralize model training privacy concern incur prohibitive communication motivates innovative framework federate feature distribute device model update aggregation server federate effectively address aforementioned issue locally compute model update instead raw data uploaded server typical federate algorithm alternate phase aggregate distribute model update multi access channel apply average update AI model server broadcast model training device continuously refine local model federate wirelessly distribute data federate wirelessly distribute data conventional communication driven communication model update upload federate bandwidth consume AI model usually comprises billion parameter overall model update device easily congest interface bottleneck agile bottleneck arguably artifact classic approach communication compute separation exist multiple access technology orthogonal frequency multiple access ofdma code multiple access CDMA purely rate driven communication fail adapt actual task enable massive distribute data guideline multiple access driven multiple access showcase technique guideline innovation underpin driven multiple access exploit insight task involves compute aggregate function multiple data sample decode individual sample exist scheme federate server average model update individual multi access wireless channel data aggregator simultaneously transmit analog device automatically superpose receiver weigh channel coefficient insight motivate guideline traditional philosophy overcome interference harness interference guideline driven multiple access unique wireless channel broadcast superposition exploit function computation distribute data accelerate guideline superposition multi access channel suggests linear analog modulation pre channel compensation transmitter interference concurrent data transmission exploit data aggregation intuition capture recently propose technique computation aircomp guideline superposition multi access channel suggests linear analog modulation pre channel compensation transmitter interference concurrent data transmission exploit data aggregation intuition capture recently propose technique computation aircomp simultaneous transmission aircomp dramatically reduce multiple access latency factor user overcome communication latency bottleneck aircomp federate setting federate server device exposition task handwritten digit recognition mnist dataset consists category digit label training data sample simulate distribute mobile data randomly partition training sample assign device classifier model implement layer convolutional neural network convolution layer fully layer relu activation softmax output layer aircomp ofdma federate model training communication local model device transmit aggregate server broadband channel consist orthogonal sub channel propose aircomp conventional ofdma mainly available sub channel ofdma sub channel evenly allocate device device uploads local model fractional bandwidth reduces grows model average perform server local model reliably communication latency slowest device contrast aircomp scheme allows device bandwidth exploit interference model average latency aircomp independent access device performance although aircomp vulnerable channel scheme comparable accuracy aircomp percent ofdma percent accurate aircomp partly due expressiveness neural network model robust perturbation channel profound refresh implication reliable communication primary concern neural network model adopt essentially aircomp exploit relaxation communication reliability communication latency without compromise accuracy aircomp achieves significant latency reduction superiority latency aircomp ofdma pronounce signal SNR regime dense network scenario performance comparison aircomp ofdma communication latency aircomp model parameter analog modulate sub channel dedicate parameter transmission truncate channel inversion transmit constraint tackle channel fading ofdma model parameter quantize sequence per parameter adaptive QAM adopt adapt data rate channel spectrum efficiency maximize target error rate maintain research opportunity robust imperfect aircomp inaccurate channel estimation non ideal hardware device imperfect channel equalization distort aggregate data aircomp practical implementation important characterize imperfect aircomp performance technique improve robustness asynchronous aircomp successful implementation aircomp strict synchronization participate device achieve device exhibit mobility enable ultra data aggregation mobility scenario scheme asynchronous manner relaxed requirement synchronization desirable generalization architecture apart federate generalize driven multiple access architecture server perform sophisticated computation data average exploit superposition multi access channel compute complex function challenge generalization driven resource management motivation principle traditional communication compute separation approach exist resource management RRM maximize spectral efficiency carefully allocate scarce resource frequency access however approach longer effective fails exploit subsequent performance improvement motivates guideline RRM guideline driven RRM resource allocate transmit data performance optimization conventional RRM assumes message receiver assumption sum rate maximization criterion rate driven approach longer efficient message tend valuable others training AI model introduce representative technique driven guideline importance aware resource allocation data importance account resource allocation technique similarity machine active principally active important sample unlabeled dataset label accelerate model training label budget widely adopt importance uncertainty specifically data sample uncertain confidently predict model commonly uncertainty entropy notion information theory evaluation complex heuristic alternative distance data sample decision boundary model vector machine svm training data sample decision boundary likely vector thereby contribute define classifier contrast sample away boundary contribution active driven RRM additional challenge volatile wireless channel besides data importance resource allocation ensure reliability transmit data sample diagram driven RRM illustrate communication driven RRM communication driven RRM importance aware retransmission  setting centralize classifier server svm data distribute device acquisition dimensional training data sample bandwidth consume relies noisy data channel rate reliable channel allocate accurately transmit label mismatch label noisy data sample server incorrectly model tackle issue importance aware retransmission coherent combine propose enhance data quality resource specify transmission budget sample retransmit constrains communication latency classifier mnist dataset relatively differentiable focus binary classification importance aware retransmission transmission budget constraint RRM specify retransmission instance allocate data sample concretely communication server binary decision device acquire sample request previously schedule device retransmission improve sample quality finite transmission budget decision address quality quantity sample svm data decision boundary critical model training easy commit data label mismatch issue therefore retransmission budget ensure pre specify alignment probability define possibility transmit data decision boundary motivates importance aware retransmission scheme retransmission decision apply adaptive SNR threshold adaptation realize threshold coefficient distance sample decision boundary enables intelligent allocation transmission budget accord data importance optimal quality quantity achieve performance performance importance aware retransmission along benchmark scheme namely conventional channel aware retransmission fix SNR threshold scheme without retransmission retransmission performance dramatically degrades acquire sufficiently noisy sample accumulates divergence model justifies retransmission importance aware retransmission outperforms conventional channel aware retransmission throughout entire training duration importance aware resource allocation visualize training sample quality varies data importance propose scheme conventional channel aware scheme strives quality data sample classification performance importance aware retransmission baseline MRC combine technique apply coherently combine retransmission observation maximize SNR retransmission SNR predefined threshold average SNR research opportunity cache assist importance aware RRM sufficient storage device pre important data locally cached data upload faster convergence AI model training however conventional importance evaluation data uncertainty undesired selection outlier incorporate data representativeness data importance evaluation exploit local data distribution issue address multi user RRM faster intelligence acquisition multiple access technology simultaneous data upload multiple user resultant batch data acquisition enhance overall efficiency reduces frequency update AI model training however due correlation data across device accelerate model training unnecessarily processing redundant information therefore efficiently exploit data diversity presence inter user correlation topic driven RRM diversified scenario importance aware RRM assumes upload raw data however uploaded device server necessarily raw data related content model update federate data importance aware RRM directly applicable driven signal encode motivation principle machine feature extraction technique widely apply pre processing raw data reduce dimension improve performance numerous feature extraction technique principal component analysis popular technique identify latent feature reduce data sample dimensional feature linear discriminant analysis discriminant feature facilitate data classification theme feature extraction technique reduce training dataset dimensional feature simplify improve performance aggressive conservative dimensionality reduction degrade performance furthermore choice feature directly affect performance target task feature extraction technique challenge important topic machine wireless communication technique source channel encode developed preprocess transmit data purpose namely efficient reliable delivery source cod sample quantizes compress source signal minimum constraint signal distortion rate distortion reliable transmission channel cod introduces redundancy transmit signal hostility wireless channel rate reliability tradeoff joint source channel cod essentially involves joint optimization mention offs data preprocessing operation integrate feature extraction source channel encode inherent data geometric structure exploit communication efficient cod topic driven signal encode guideline guideline driven signal encode signal encode device jointly optimize feature extraction source cod channel encode accelerate  analog encode subsection technique guideline  analog encode GAE introduce GAE raw data sample euclidean subspace interpret feature via project sample onto  manifold operation reduces data dimensionality distorts data sample freedom loss return transmission GAE encode data sample linear analog modulation blind multiple input multiple output mimo transmission without channel information robustness fading feasibility blind transmission attribute principle classic non coherent mimo transmission GAE encode dataset retains cluster structure usefulness training classifier server effectiveness GAE demonstrate via prior performance centralize GAE analog data transmission benchmarked rate coherent scheme digital analog mimo transmission significant performance gain mobility scenario research opportunity gradient data encode federate compute gradient dimensionality transmission communication inefficient fortunately exploit inherent sparsity structure gradient update truncate appropriately without significantly degrade training performance inspires gradient compression technique reduce communication latency channel aware feature extraction traditional channel aware signal processing jointly feature extraction particularly recent inherent analogy feature extraction classification non coherent communication suggests possibility exploit channel characteristic efficient feature extraction research channel aware feature extraction conclude remark recent inherent analogy feature extraction classification non coherent communication suggests possibility exploit channel characteristic efficient feature extraction research channel aware feature extraction intersection wireless communication machine lean enables promising AI application brings research opportunity aim article introduce guideline wireless communication community upcoming era intelligence introduce driven communication technique multiple access resource allocation signal encode communication latency bottleneck