development neural network smart scenario diverse personalize requirement user however exit architecture deployment manually neural network adaptive network architecture environment heterogeneous device becomes challenge customize network architecture neural architecture adaptively neural network specifically architecture identify layer equip amount compute resource conduct multi objective architecture proxy dataset layer aim optimal architecture target dataset scratch compute resource server user layer deploys multi objective model diverse device inference furthermore deploy industrial sensor monitoring scenario temporal convolutional network demonstrate effectiveness propose architecture experimental feasibility propose architecture introduction decade widespread application neural network image classification detection semantic segmentation architecture widely computation resource reduce inference latency traditionally neural network target dataset model deployed server inference however dramatic increase neural network application device significant burden specific network architecture user becomes requirement extremely diverse device neural network manually particularly scenario computational device constrain furthermore privacy issue data transfer user server challenge attract attention recently fortunately neural architecture NAS propose recently effective network architecture NAS automl achieve impressive performance neural architecture superior developed manually generally NAS consists factor strategy evaluation specifically strategy sample architecture architecture evaluate evaluation finally strategy update evaluation pioneer adopt reinforcement RL network architecture image classification demonstrates NAS feasible furthermore propose evolutionary architecture achieves RL demonstrate feasibility however despite effectiveness NAS quality architecture optimal architecture computationally demand gpu impedes practical deployment NAS various application alleviate issue effort undertaken reduce architecture recent remarkable effort differentiable DARTS relaxes continuous architecture parameter reduce gpu NAS sample architecture scratch architecture remove recent reuse previously optimize architecture reduces magnitude review literature recent achievement mainly focus optimize NAS algorithm reduce consumption although NAS breakthrough previous gpu gpu challenge actual deployment deployment NAS typically network architecture device upload training dataset data leakage moreover target dataset upload dataset introduce additional transmission delay therefore effective architecture requirement various device motivate redesign adaptive NAS collaborative compute precisely layer obtains multi objective network architecture proxy dataset sends optimal network architecture server architecture scratch target dataset finally deploys model device additionally previous NAS mainly achieve various computer vision task research series model observation propose temporal convolutional network tcn achieve multi series forecasting sensor data contribution automatically neural architecture heterogeneous device propose adaptive NAS collaborative scenario specifically architecture proxy dataset avoids data leakage training architecture server resource novel NAS temporal convolutional network industrial sensor data forecasting gap NAS series forecasting model challenge issue related propose architecture summarize potential research direction future NAS collaborative scenario collaborative architecture NAS discus motivation explanation NAS scenario collaborative layer architecture layer layer user layer traditional architecture neural network reconstruct layer architecture adapt heterogeneous device NAS composition layer neural architecture collaborative neural architecture collaborative layer layer contains various computation resource gpu tpu programmable gate array fpga architecture layer layer massive resource server closer device layer latency reduce processing data server user layer device vehicle smartphones user layer various artificial intelligence application device recognition objective detection automatic translation model deployed device inference challenge motivation recently NAS become popular direction automl although NAS receives exceptional performance computer vision model task challenge deploy NAS scenario challenge architecture consumes computational deployed heterogeneous layer compute resource transfer data generator privacy issue meanwhile layer data generator transmission delay another challenge additional objective latency consumption deployment NAS consume conduct NAS research without compute resource therefore research NAS recent mainly focus reduce research continued academia meanwhile strategy propose achieve performance unfortunately effort NAS recent mainly algorithm innovation integrate architecture handle entire NAS literature bridge gap aim propose integrate architecture discus tackle challenge propose NAS collaborative architecture propose architecture collaborative NAS heterogeneous collaborative goal architecture neural network dynamically satisfy requirement compute resource architecture NAS RL strategy propose architecture strategy evolutionary algorithm EA gradient compatible architecture consists NAS proxy dataset training scratch server deployment device specify illustration propose architecture illustration propose architecture neural architecture proxy dataset RL NAS generates neural network controller specifically architecture neural network described variable generate exploit recurrent neural network rnn controller gradient policy optimize generally obtain optimal network architecture specific dataset effective network architecture directly target dataset unfortunately upload dataset directly leakage dataset privacy additional transmission delay avoid NAS network architecture proxy dataset directly target dataset network architecture proxy dataset cifar deploy optimal architecture dataset imagenet reduce although proxy dataset avoid data upload generation gap introduce inconsistent performance architecture datasets inconsistency adopt  improve generalization architecture concept  optimize network proxy training dataset distance distance denotes domain distance constraint deploy model suitable dnn architecture optimize multi objective efficiency metric accuracy latency achieve satisfy user inference achieve purpose controller obtains target user architecture strategy RL NAS convenient customize multi objective optimization specifically RL strategy  multi objective reward sum various objective tune correspond multi objective optimization convert objective summary architecture conduct controller sample batch candidate architecture candidate architecture proxy dataset fix controller obtains multi objective reward controller parameter update predefined candidate architecture training scratch optimal architecture proxy data stage transfer optimal architecture server training target dataset scratch traditional scenario upload data model training server device massive compute resource device furthermore user data usually server directly training model server avoids data leakage transmission delay server model target dataset obtain optimal architecture therefore data privacy device without upload target data propose strategy data privacy reduce delay upload target dataset deployment deploy optimal architecture target dataset inference device smartphones limitation computation communication resource device device responsible online inference extend battery addition device continuously upload data server performance predefined threshold server update deployed model dataset improve performance therefore model inference accuracy DRL temporal convolutional network industrial iot scenario apply propose NAS architecture multi series forecasting temporal convolutional network environment consists component device aim predict series data server optimal architecture scratch server apply neural architecture DRL configuration component device nvidia jetson nano equip quad core cortex ghz nvidia cuda core device inference server macbook pro equip intel core ghz cpu GB ram server architecture training scratch server server equip vcpu ghz intel xeon platinum GB ram nvidia GB graphic memory NAS smart factory series model series model consists predict input sequence denotes forecasting prediction multi prediction generally forecasting strategy multi series forecasting forecasting iterative forecasting forecasting strategy convenience series forecasting restriction predict input obtain formally target forecasting generate function series forecasting horizon denotes although machine model series forecasting approach realize memory lstm variant rnn however disadvantage lstm later timestep prediction prior disadvantage parallelism fortunately recently propose tcn consist 1D convolutional network outperforms rnn model sequence task unlike rnns convolution tcn calculate parallel filter layer training evaluation cycle moreover receptive tcn multiple stack dilate convolutional layer dilation factor easy adapt domain detail structure architecture tcn neural architecture tcn article intend optimal architecture tcn series forecasting tcn propose sequential data compose component causal convolution dilate convolution residual connection causal convolution output consists earlier previous causal convolution important series prediction effectively avoid leakage information future however achieve simply stack causal convolution network extremely feasible tcn applies dilate convolution enable exponentially receptive specifically dilate convolution contains dilation factor refers adjacent filter tap dilation convolution output layer wider effectively expands receptive network therefore receptive tcn depends network depth filter dilation factor stabilize training network tcn residual module identify mapping entire transformation concept define component tcn simplify fix network structure optimal tcn architecture specifically residual entire architecture contains dilate causal convolution layer convolutional layer optimal kernel dilate factor convolutional layer rectify linear relu dropout layer therefore dilate causal convolution summarize convolutional kernel dilate factor potential architecture optimal network architecture adopt RL strategy easy customize reward establish traditional NAS reinforcement define strategy optimal architecture strategy RL NAS propose agent lstm controller environment sample eval update loop controller model sample proxy dataset loss calculate model finally calculate reward combine loss model potential architecture controller update proximal policy optimization ppo controller obtains encode architecture input output prediction softmax output previous layer prediction residual entire architecture generate experimental dataset subsection dataset factory substation verify effectiveness propose dataset contains sensory dataset december march interval compose feature sake convenience feature  approximately perform multi series forecasting adopt strategy develops forecasting model forecast interval independently exploit slide multi sensor data obtain training validation sample training detail deploy neural network pytorch error mse loss function controller layer lstm hidden stochastic gradient descent sgd rate exploit nvidia GB graphic memory sample architecture training sample architecture model epoch rate verify efficiency propose architecture performance manual obtain NAS generalization performance architecture datasets tcn architecture unlike architecture developed manually expert residual contains skip connection exploit convolution input output tensor optimal architecture optimal architecture illustrates response scheme multi forecasting response data transmission inference inference longer execution server device specifically forecasting series device percent shorter server respectively server powerful compute data transmission performance comparison multi ahead response increment mse params model increment performance comparison multi ahead response increment mse params model increment mse domain mse domain tendency performance metric mse model parameter increase forecasting forecasting horizon increase min mse increase uncertainty increase increase prediction interval decrease prediction accuracy obviously mse tcn lstm NAS tcn improves mse percent lstm tcn respectively params demonstrate effectiveness multi objective aim architecture balance loss model params NAS tcn manually tcn specifically NAS tcn reduces params percent lstm tcn respectively effectiveness NAS tcn verify architecture accurate efficient generalization performance architecture target dataset deploy approach proxy target specifically proxy architecture conduct proxy dataset mse target dataset specifically indicates network architecture  model finally  target however architecture perform target dataset  competitive directly target dataset mse proxy target retrain parameter scratch architecture observation demonstrate availability proxy data avoid data upload examine framework tcn sequence model lstm convolutional network easily exploit framework adapt collaborative compute issue propose NAS architecture propose issue strategy selection article strategy RL effectively lightweight model dataset however device deploy image recognition model recognition target detection strategy RL consume therefore faster strategy imminent direction shot NAS treat architecture subgraphs supergraph multi objective optimization considers loss model limitation model deployment device consideration various metric latency consumption accuracy metric achieve topic privacy preservation NAS generally consume hardware acceleration equipment although platform compute resource NAS directly upload sensitive target data encounter risk data leakage effectively network architecture target dataset ensure private dataset safely important research direction conclusion article introduce adaptive NAS collaborative scenario automatically neural architecture heterogeneous device proposal prevents data leakage transmission delay conduct architecture proxy dataset fully utilizes compute resource server training architecture scratch architecture novel NAS tcn predict series datasets smart factory experimental availability propose architecture efficiency multiple objective