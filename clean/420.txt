compute network coin exploit  compute network node offload application computation paradigm benefit computation demand application source separation acoustic anomaly detection however wider adoption coin due intertwine challenge monolithic source separation algorithm lack flexible transport layer coin hinders exploitation article network joint independent component analysis NJICA leverage coin recover acoustic source mixture raw sensory signal NJICA  monolithic algorithm source separation distribute unleash offload capability arbitrary network node furthermore NJICA develops message transport layer allows aggregate application data network node differentiate message extensive evaluation practical implementation NJICA realistic dataset NJICA significantly reduces computation service latency introduction influence demand decrease expenditure capex operation expenditure opex communication network transform programmable infrastructure leverage network function virtualization NFV software define networking sdn NFV allows network function commodity hardware benefit mature virtualization technology virtual machine container sdn orchestrates multiple router simultaneously centralize entity interaction NFV sdn allows allocate orchestrate chain network function service function chain sfc practical application network function firewall packet inspection spare compute capability NFV infrastructure computation offload transition concept compute network coin integration network computation network processing framework coin benefit vertical industrial internet IIoT central building IIoT data embed sensor analyze respond quickly device abnormal behavior maintain uninterrupted operation acoustic signal anomaly detection significant gain humidity signal acoustic detect incidence image analysis technique distort acoustic signal emerge abnormal additionally audio detection avoid angular distortion audio anomaly detection source signal mixture audio signal characteristic raw sensory acoustic signal inevitably alter mixed due multiple presence operation significant interference affect detection accuracy communication computation demand massive deliver raw data deployed sensor typical IIoT application acoustic signal continuously rapid sample rate extend potentially source separation application benefit coin capable infrastructure offload computation coin however significant challenge combine source separation application coin algorithm source separation monolithic suitable centralize computation exploit offload capability coin source separation algorithm modular enables independent execution compute function source separation typically computes amount data exceeds cache capacity router coin framework lack flexible transport aggregation differentiation functionality therefore facilitate data intensive application source separation coin flexible transport layer layer coin network node tap application data perform compute function article introduce network joint independent component analysis NJICA leverage coin recover acoustic source mixture raw sensory acoustic signal NJICA distribute compute model source separation algorithm enables offload computation arbitrary network node NJICA introduces ahead data extraction avoid communication bottleneck NJICA develops message transport layer allows aggregate application data network node differentiate message transport layer minimizes latency traffic extensively evaluate practical implementation NJICA realistic dataset NJICA reduces computation latency drastically magnitude impose negligible increase overall service latency NJICA blind source separation BSS algorithm NJICA benefit independent component analysis ICA algorithm benefit NJICA modular distribute extract data crucial offload computation chunk data offload function extract data terminate criterion essential offload function tune performance prevent overload coin resource generic application benefit message transport layer NJICA enabler tap application data enable computation network node simplify deployment application coin enable infrastructure release NJICA source library available article structure introduces fundamental principle acoustic source separation discus NJICA architecture implementation detail evaluation discus finally conclude article sketch direction future background related briefly review background knowledge BSS mixture acoustic signal respective algorithm BSS discus challenge offload algorithm leverage coin clarify notation meaning summarize notation subsequent blind source separation BSS recover source signal mixture machine operating simultaneously factory hall separation understand source individually acoustic anomaly detection assume acoustic sensor acoustic signal source mixture signal sensor throughout slot addition acoustic component source component source statistically independent non gaussian distribute mixture denote linear combination source matrix usually enormous sample per acoustic signal furthermore typical internet iot setup consists numerous sensor increase data matrix observer significant source perform BSS minimum observer resource efficient transmission computation importantly matrix rank matrix invert task BSS estimate source signal mixture separation matrix inverse matrix model BSS sample slot model BSS sample slot notation notation independent component analysis estimate separation matrix ICA conventional ICA algorithm FastICA maximize non  data mixture newton iteration approximate non  maximization newton iteration update separation matrix optimal separation source signal consequently ICA algorithm complicate computation intensive adaptive extraction ICA  reduces traditional ICA algorithm computation demand  accelerates separation accuracy improvement exploit convergence tolerance guarantee reliable separation quality  adaptive extraction distance increase amount extract data iteration newton iteration subset data partial newton iteration reduces compute resource avoids transmit raw data network extract data locally related distribute ICA none ICA algorithm exploit distribute compute alone leverage compute network capability monolithic therefore centralize execution initial extraction distance highly dependent input data matrix input data separation parameter individually tight couple source signal input data newton iteration computation challenge compute ICA algorithm distribute manner subset data extraction distance depends previous iteration reduction collaboration efficiency compute network coin IP packet data router router network layer individual IP packet minimal buffering capacity computation amount data exist coin challenge processing operates mixture matrix usually magnitude maximum transmission MTU IP packet processing stateful IP packet matrix perform ICA algorithm transport layer functionality coin subsequent challenge modification principle traditional transport layer protocol reduce latency overhead coin minimize amount data network node data processing coin handle transmission transport layer unsolved challenge offload computation ICA algorithm coin ICA algorithm modular distribute compute leverage offload capability coin coin transport layer tap amount input data network joint ICA NJICA distribute compute compute network innovation NJICA distribute compute model centralize ICA algorithm NJICA decomposes functional component algorithm module deploys network function NJICA develops novel message transport layer handle application data aggregate application data network node differentiate traffic ICA network function source separation algorithm distribute manner NJICA decouples ICA functionality namely data extraction DE separation matrix estimation sme data reconstruction DR altogether DE extract mixture sends sme sme estimate separation matrix estimation approach desire tolerance DR reconstruct source otherwise sme request DE extract data estimation depicts functionality dependency flowchart offload computation  apply conquer approach goal decouple dependency DE sme decompose  sub component DE sme DR sensor mixture mathbf source slot extraction distance meaning DE extract fourth slot matrix construct mathbf sends sme newton iteration estimate separation matrix mathbf desire tolerance sme asks DE additional data DE reduces extraction distance meaning extract slot matrix estimate separation matrix mathbf satisfies desire tolerance finally DR reconstructs source mathbf mathbf decompose  sub component DE sme DR sensor mixture source slot extraction distance meaning DE extract fourth slot matrix construct sends sme newton iteration estimate separation matrix μiW desire tolerance sme asks DE additional data DE reduces extraction distance meaning extract slot matrix estimate separation matrix satisfies desire tolerance finally DR reconstructs source data extraction DE receives mixture source throughout slot goal DE downsample extract minimum subset permit successful estimation separation matrix converge quickly optimal DE exploit heuristic DE substantially subset increase subset reasonable characterize parameter namely extraction distance iteration extraction operation iteration DE extract  matrix extract matrix tolerance DE performs extraction iteration reduces DE terminates extract matrix desire tolerance extraction distance zero meaning mixture matrix separation matrix estimation goal sme estimate separation matrix sme applies newton iteration extract data DE denote  sme terminates outcome newton iteration approach desire tolerance procedure calculate separation matrix computation intensive sme intermediate reduction rate gradient iterative operation sufficiently reduce gradient intermediate separation matrix μiW sme tolerance otherwise sme newton iteration illustrate decision gradient reduction intermediate separation matrix μiW sufficiently reduce gradient sme  tolerance μiW desire tolerance sme request  DE  μiW desire tolerance sme separation matrix reconstruct source data reconstruction DR ICA responsible reconstruct source therefore ICA execute DR DR performs matrix multiplication mixture separation matrix DR output source signal volume DR output data significantly input data DR relatively compute demand distribute functional component NJICA decides distribute component ICA algorithm maximize benefit computation offload minimize amount transmit data network offload DR benefit marginal otherwise DR weak demand compute remains server localize DR output typically decrease traffic demand transmission delay reduce compute load server significantly NJICA allows offload DE sme compute intensive multiple execution NJICA allocates DE sme network function due frequent interaction tune offload workload define maximum execution DE sme within network function NJICA implement ahead data extraction feature DE extract subset mixture matrix sme request initial extraction distance input allows execute DE sme virtually parallel minimize processing delay compute NJICA network incorporate data intensive application coin paradigm NJICA introduces innovation namely data differentiation message transport layer data differentiation enable parallel processing network node NJICA data immediately without intermediate node along data client server network node tap data intermediate node decouple transmission extensive data intermediate μiW NJICA tag differentiate message mixture intermediate μiW illustrates fragmentation client sends message server encapsulate unprocessed data traverse along chain virtualized network function interconnect coordinate dynamically sdn controller span physical network node node performs multiple iteration DE sme operation processing intermediate μiW extract data  network node message data downstream network node DE sme compute μiW sends network node computation offload NJICA DE sme network function network node DR remains entirely server computation offload NJICA DE sme network function network node DR remains entirely server message transport layer layer responsible deliver application data service function chain NJICA network function transport layer data collection processing BSS application considerable source signal duration therefore transmission fragment multiple IP packet simplify packet processing logic network node employ message protocol NJICA message data packaging reasonable flexible deliver application data network node cooperatively reduce node workload message metadata subsequently NJICA encapsulates message chunk udp datagram specific preamble header metadata information message message flag message sequence chunk sequence chunk loop network node exploit metadata header reassemble μiW network node message flag verification intermediate μiW desire tolerance network node message flag fully inform node μiW without processing server receives message correspond μiW message flag μiW data processing fully completes server executes DR function otherwise perform iteration DE sme function partially data network NJICA involves assemble processing data packet batch leverage data development kit dpdk version implement network function nfs dpdk bypass kernel avoid costly data copying operation increase packet processing however dpdk alternative data processing technology XDP eligible performance evaluation NJICA conventional compute offload capability introduce leverage coin metric setup parameter metric computation load server introduce computation latency metric duration server compute source separation completes computation latency network node already offload portion computation remain computation load contrary significant computation latency server compute portion workload ass quality service qos NJICA service introduce metric service latency client metric difference request message client respective response server client service latency transmission computation delay introduce network node server metric directly address concern overhead introduce offload compute network node computation latency service latency allows ass benefit NJICA collectively setup conduct evaluation network emulator communication network emulator  unique advantage  capability functionality NFV sdn allows prototyping coin application virtually illustrate multihop topology router intermediate network node router perform operation data processing client connects network sends mixture udp traffic server topology link homogeneous bandwidth fix propagation delay specification typical commercial shelf COTS device network purpose examine benefit offload coin without superior specification infrastructure assume device connection purpose available COTS implement client server function python configuration parameter perform measurement client sends mixture matrix server calculate percent confidence interval network node packet server operating coin enable offload mode sdn controller insert router data traffic network node sfc propose NJICA conventional ICA scheme implement deployed FastICA FastICA centralize ICA algorithm monolithic factorizes internal functionality ICA algorithm achieve modular deploy FastICA conventional compute model without leverage coin source code emulation publicly available deploy emulation COTS server cpu GB ram ubuntu lts operating workload parameter evaluation dataset google audio widely dataset enables diverse audio data source randomly source dataset construct source signal mixed source signal standard normal distribution simulate scenario evaluation various data examine scenario server workload namely moderate workload moderate workload scenario server percent compute fulfill client request whereas workload scenario server compute capacity workload scenario understand circumstance NJICA benefit offload discussion computation latency server service latency client NJICA FastICA impact computation latency depicts impact offload parameter computation workload source signal computation latency amount input data source computation latency NJICA equally amount input data increase increase source computation latency increase NJICA however computation latency increase faster configuration computation latency NJICA magnitude within NJICA significant impact computation latency tends reduce latency drastically network node already offload portion computation workload network node offload execution newton iteration tends workload therefore impact offload computation latency insignificant computation latency server setup available compute resource network node computation latency server setup available compute resource network node workload NJICA computational performance FastICA without computational offload NJICA computation average FastICA evaluation NJICA reduces computational demand BSS significantly server dataset impact service latency understand impact offload overall service latency client workload comparison plot service latency regard source NJICA FastICA compute implies compute depicts service latency computation client data service latency scheme increase significantly source grows source extensive mixture data fragment data client transmit network node finally reassemble data server source increase service latency increase around approximately emphasize earlier BSS typical compute intensive data analysis task dedicate machine processing latency conventional FastICA NJICA negligible service latency source FastICA NJICA reduce service latency percent workload scenario source scenario NJICA latency performance percent approach NJICA significantly reduce service latency workload scenario service latency client setup available compute resource network node service latency client setup available compute resource network node conclusion future article NJICA joint network computation acoustic source signal mixture NJICA leverage coin offload computation workload network node along transmission NJICA introduces decentralize computation module  ICA algorithm distribute compute model NJICA introduces message transport layer categorizes tag data allows dispatch compute NJICA offload computation arbitrary network node additionally ahead data extraction feature allows parallel compute reduce computation latency practical implementation evaluation realistic workload demonstrates NJICA significantly reduces computation latency conventional compute approach promising communication intensive computation demand application benefit coin NJICA benefit research ICA algorithm benefit modular extract data crucial coin leverage application offload computation chunk data offload function extract data terminate criterion essential offload function tune offload performance prevent coin resource overload benefit application message transport layer enabler tap application data enable computation network node immediate direction future explore performance bound ICA algorithm coin development mathematical model comprehensive parameter potential research direction NJICA wider variety application generic sophisticated transport layer protocol loss recovery congestion address