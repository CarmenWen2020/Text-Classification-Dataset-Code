mapreduce framework become  scheme scalable semi structure structure data processing recent hadoop ecosystem evolve generation hadoop yarn adopts grain resource management scheme schedule nowadays fairness efficiency concern yarn resource management resource yarn contend multiple application however schedule yarn yield optimal resource arrangement unnecessarily idle resource inefficient schedule omits dependency task extremely crucial efficiency resource utilization heterogeneous feature application environment propose yarn scheduler effectively reduce makespan execution batch mapreduce hadoop yarn cluster leverage information request resource resource capacity dependency task accommodate heterogeneity mapreduce extend scheduler iteration information schedule decision implement schedule algorithm pluggable scheduler yarn evaluate classic mapreduce benchmark experimental demonstrate yarn scheduler effectively reduces makespans improves resource utilization introduction data explosion efficient parallel data processing scheme essential massive volume data mapreduce propose google emerge paradigm data processing due scalability reliability source implementation apache hadoop widely adopt academia data processing information analysis nowadays hadoop ecosystem evolve generation hadoop yarn adopts grain resource management scheme schedule mapreduce popular fairness efficiency become concern yarn resource contend yarn cluster however schedule yarn yield optimal resource arrangement unnecessarily idle resource inefficient schedule limited resource cluster batch mapreduce launch schedule execution allocate resource becomes crucial performance without appropriate management available resource efficiently utilized prolong aim develop efficient schedule scheme yarn cluster improve resource utilization reduce makespan completion widely adopt schedule yarn fifo scheduler however optimal arrangement cluster resource desire cpu intensive memory intensive simultaneously fifo scheduler sequentially unnecessary resource idleness moreover resource scheduler capacity scheduler omit dependency task however dependency crucial efficiency resource utilization multiple concurrently cluster therefore HaSTE hadoop yarn schedule algorithm task dependency resource demand HaSTE aim efficiently utilize resource schedule reduce task hadoop yarn improve makespan mapreduce specifically dynamically schedule task execution resource become available task fitness urgency fitness essentially refers gap resource demand task residual resource capacity node metric commonly resource allocation literature metric urgency quantify importance task entire allows prioritize task importantly dependency task extend schedule algorithm dynamically execution task multi stage iterative data processing application nowadays deploy multiple data processing framework spark storm yarn cluster becomes framework multi stage data processing application mapreduce hadoop typical stage chain mapreduce sql hadoop query iterative machine algorithm pagerank representative multi stage application without iterative feature schedule cluster resource cannot efficiently utilized execute iterative incurs makespan therefore extend version algorithm HaSTE accommodate heterogeneous workload iterative non iterative HaSTE differentiates iterative non iterative metric alignment capture iteration application runtime progress iteration couple fitness urgency HaSTE enforces iterative non iterative alignment makespan due iterative effectively reduce organize briefly introduce background schedule exist schedule policy yarn formulate schedule yarn resource constrain schedule propose schedule policy HaSTE extension schedule algorithm iterative evaluation schedule algorithm related conclude hadoop yarn scheduler briefly introduce schedule hadoop yarn scheduler currently yarn hadoop yarn consists multiple worker node resource manage centralize ResourceManager routine multiple distribute  routine worker node classic hadoop yarn feature difference unlike  hadoop mapreduce ResourceManager longer monitor status instead launch  worker node  generates resource request negotiates resource scheduler ResourceManager  execute monitor correspond reduce task furthermore hadoop yarn abandon coarse grain slot resource management version instead manages resource grain manner  report available memory cpu core worker node  specify memory cpu core demand task scheduler hadoop yarn allocate available resource task schedule policy task request tuple priority task resource requirement vector task task resource requirement location task input data split boolean task assign  locally input data split scheduler receives heartbeat message active  report resource usage capacity residual capacity residual capacity node sufficient accommodate task task scheduler allocates task node accord schedule policy unlike hadoop mapreduce yarn longer explicitly distinguish reduce task parallel data processing application spark hive pig yarn mainly focus mapreduce application yarn later extend iterative schedule schedule policy currently hadoop yarn fifo capacity fifo policy sort nondecreasing submission task request priority locality ResourceManager receives heartbeat message  queue task request residual capacity correspond node schedule service schedule policy implement hadoop yarn dominant resource fairness drf policy considers memory usage attempt assign memory drf policy aim ensure average dominant resource requirement memory cpu core yarn implementation capacity policy policy policy scheduler attempt reserve guaranteed capacity deficit gap deserve capacity actual occupy capacity clearly none policy optimize resource utilization completion mapreduce therefore yarn scheduler reduce makespan batch mapreduce HaSTE formulation submit hadoop yarn cluster consist server consists task reduce task task assign task unique index ith task task define subset MT RT task reduce task respectively MT RT MT RT reduce task addition assume compute resource yarn resource memory cpu define potential extension involve resource network bandwidth disk memory cpu resource respectively dimensional matrix resource capacity cluster indicates amount available resource server matrix available scheduler cluster launch update execution upon heartbeat message  hadoop yarn task request user specify resource execution reduce task resource requirement task define amount resource request task task reduce task yarn scheduler assign task node execution goal efficient scheduler cluster mapreduce minimum minimize makespan specifically sti task execution schedule equivalent resource constrain optimization NP heuristic propose ref however practical directly implement hadoop yarn issue processing task schedule conventional cannot prior execution profile estimation technique apply roughly estimate execution task however extremely impossible predict execution reduce task cluster multiple concurrently hadoop yarn reduce task mapreduce consist stage shuffle reduce shuffle stage output task transfer worker node host reduce task computation reduce stage input data therefore execution reduce task dependent related factor execution task intermediate output data aim develop practical heuristic prior knowledge task execution sketch HaSTE scheduler consists component initial task assignment ita task assignment RTA ita execute cluster  submit resource request mapreduce task scheduler goal ita assign batch task execution task remain pending queue specifically ita algorithm subset pending task host node execution RTA launch execution task correspond resource release resource become available worker node  notify scheduler heartbeat message scheduler execute RTA task pending queue assign worker node resource available ita RTA trigger heartbeat message resource capacity update dispatch task host node sender heartbeat message without prior knowledge execution exploit greedy strategy develop ita RTA algorithm ita formulate variant knapsack dynamic program derive task assignment RTA complex involve progress active task dependency task develop algorithm considers fitness urgency task determines appropriate task execute initial task assignment objective ita task execution task unknown impossible yield optimal information leveraged ita available resource capacity resource demand therefore remark goal ita algorithm actually avoid waste resource initial stage accomplish goal adopt greedy strategy simplify objective maximize resource utilization ita resource equivalent typical knapsack worker node knapsack resource capacity refers knapsack capacity correspondingly task item request resource amount item optimal convert knapsack yield maximize resource utilization however hadoop yarn defines resource recall resource cannot directly reduce knapsack quantitative resource utilize percent cpu percent memory utilize percent cpu percent memory assume cluster specifies resource ita formulate maximize xij xij  source algorithm dynamic program detail illustrate algorithm algorithm simply loop assigns task server core algorithm implement procedure  task assign server dynamic program algorithm dimensional matrix opt opt maximum objective function capacity task yield optimal loop opt eventually algorithm optimal assigns task matrix enumerate candidate task previously resource capacity sufficient task objective function optimal satisfied update matrix opt algorithm initial task assignment ita data  procedure  LR LR tmp opt opt tmp opt tmp     xij return task assignment RTA core component HaSTE repeatedly conduct execution goal RTA task worker node newly release resource snapshot information RTA algorithm decision global optimization minimize makespan complexity mapreduce develop novel algorithm considers metric task namely fitness urgency definition fitness resource availability resource demand task urgency metric characterizes dependency task impact task progress calculation metric overall algorithm RTA fitness fitness motivate greedy classic bin pack equivalent classic bin pack assume submit task task independent assume execution task schedule becomes pack task resource capacity bin makespan actually bin optimal schedule equivalent minimize bin bin pack classic bin pack considers resource proven NP greedy heuristic decrease ffd widely adopt effective yield opt performance ffd sort task descend resource requirement allocate task sort bin illustrates ffd improve makespan resource utilization schedule memory requirement schedule fifo ffd worker node 4G memory capacity processing task arrives task request 1G memory task request 3G memory assume execution task ffd scheduler fifo resource memory cpu hadoop yarn simplify schedule equivalent vector bin pack literature variant ffd vector bin pack ffd  dubbed ffd DP superior various evaluation relatively performance heuristic vector bin pack citation negligible overhead important online schedule therefore adopt ffd DP schedule reduce task resource requirement specifically define fitness fij source RTA calculate fitness pending task task execute worker node recall resource request amount resource capacity resource intuitively prefer task fitness therefore RTA sort pending task descend fitness assign task worker node update resource capacity RTA selection assign task sufficient resource pending task ffd DP algorithm multiple resource aware skewness resource requirement assume task resource requirement request GB core request GB core RTA assign task worker node residual capacity GB core ffd DP algorithm task II task percent resource utilization fitness task iteration algorithm urgency schedule hadoop yarn complex regular schedule due dependency reduce task fitness alone performance although previous schedule dependency constraint cannot directly apply dependency reduce task dependency define traditional schedule task dependent task cannot mapreduce framework task dependency actually data phase reduce task intermediate data task however reduce task although output task completion task retrieve intermediate data task configure parameter  render performance consequently execution reduce task highly dependent execution task indeed dependency relationship  reduce task requirement metric ideal reduce memory limit calculate progress task available memory correspond resource limit reduce task increase gradually progress task  sends reduce task request ResourceManager resource limit reduce task however scheduler hadoop yarn task schedule fail recognize impact dependency mapreduce ineffective resource assignment performance already launch reduce task task execute away due resource contention launch reduce task occupy resource completion task incurs utilization resource allocate reduce task address issue HaSTE metric urgency capture performance impact dependency reduce task mapreduce specifically schedule associate urgency progress phase urgent schedule task boost completion entire phase reduce execution launch reduce task resource allocate reduce task urgent schedule task avoid resource utilization reduce task completion task reduce task urgent task ratio resource occupy currently reduces currently task progress phase vice versa summary urgency urgency reduce task calculate task urgency  reduce task urgency uri   ari rri   source uri    rmi ori  rri source ami ari  reduce  task assign rmi rri  resource requirement reduce  task summation memory cpu requirement  task  ori reduce task currently occupy resource metric accessible scheduler yarn therefore implement scheduler pluggable component yarn without component HaSTE scheduler summarize HaSTE integrate metric fitness urgency schedule decision node update message  scheduler creates resource request remain resource capacity node meanwhile scheduler calculates fitness urgency chosen resource request obtains preference request  normalize fitness urgency     SourceRight click MathML additional feature fmax  resp umax  maximum minimum fitness resp urgency request preference sort resource request resource request chosen resource request actually task request task usually resource requirement scheduler task locality node local rack local assign task  task request request  request preference HaSTE due functionality submit resource requirement coordinate execution task finally remark complexity schedule algorithm nlogn sort task task resource request preference therefore HaSTE practical scheduler hadoop yarn HaSTE growth application yarn iterative algorithm adopt mapreduce paradigm algorithm model identical mapreduce execution iteration algorithm pagerank another iterative algorithm multiple stage iteration instantiate sequence iteration iterative feature algorithm determines reduce procedure processing data application submit yarn cluster application depends stage input dataset pre define maximum iteration pre define convergence threshold without iterative feature schedule HaSTE cannot workload iterative application limitation schedule algorithm makespan due delayed execution iterative algorithm cluster resource memory cpu core cannot fully utilized execution delayed iterative algorithm motivation illustrate impact iterative schedule performance assume task resource requirement non iterative task iterative task execute sequentially memory requirement label schedule HaSTE task capacity due memory requirement memory utilization makespan schedule without alignment assume execution task cpu  sufficient HaSTE scheduler schedule fitness urgency HaSTE alignment earlier HaSTE scheduler schedule without alignment assume execution task cpu  sufficient HaSTE scheduler schedule fitness urgency HaSTE alignment earlier HaSTE scheduler alignment HaSTE fitness resource requirement available capacity cluster urgency reflect dependency reduce task relative rate identify distinct iterative application introduce metric alignment capture runtime iterative application another associate alignment metric define iterative alignment reduce task earlier non iterative align processing non iterative iterative remove makespan iterative iterative stage alignment iterative shrink intermediate lag stage reduce response multi stage avoid resource utilization entire processing resource allocate ratio stage stage vice versa accelerate approach execution differentiates iterative regular describes relation iterative considers dynamic runtime summary heuristic equation reduce task alignment  mij SourceHere stage iteration  stage iteration alignment capture iteration feature runtime iterative later alignment iterative increase across runtime motivation illustrate alignment metric affect task schedule memory capacity consideration alignment scheduler schedule iterative earlier task plot aggressively plot iterative parallel non iterative makespan reduce memory resource fully utilized aggressive another target alignment improve average response define response submission scheduler aggressive alignment decrease average response although response increase HaSTE scheduler alignment preference introduce factor adjust preference preference request redefine  normalize fitness urgency alignment      amin sourcewhere amax amin maximum minimum alignment request pre define proportion iterative cluster aggressive user execute iterative intuitively iterative simultaneously non iterative HaSTE aggressively accelerate processing iterative however majority iterative actually ignore factor preference HaSTE simply treat schedule fitness urgency HaSTE evaluation evaluate performance HaSTE HaSTE  hadoop yarn cluster implement HaSTE HaSTE ffd   ffd DP scheduler hadoop yarn version built scheduler fifo capacity drf performance metric evaluation makespans batch mapreduce resource usage hadoop yarn cluster HaSTE average response additional metric resource request mapreduce resource requirement memory intensive cpu intensive resource requirement reduce task mapreduce specify user submit user resource requirement slightly actual resource demand otherwise task resource resource amount mechanism adopt yarn prevent malicious user fake resource requirement thrash request actual demand concurrency mapreduce actual resource usage reduce performance degrade appropriate resource requirement scope resource requirement evaluate scheduler various resource requirement resource requirement configuration schedule algorithm batch conduct hadoop yarn cluster node configure capacity GB memory virtual cpu core 8G core benchmark summarize benchmark description workload workload consists wordcount workload par 5G wiki category link input file therefore reduce task task input file hdfs MB described resource requirement resource analyze impact resource requirement schedule performance configuration resource requirement workload configuration workload configuration makespans average resource mem cpu usage schedule policy memory cpu usage define average amount resource allocate task specific conventional scheduler fifo drf cannot efficiently utilize resource percent cpu core usage percent memory usage although conventional scheduler obtain resource usage fifo outperforms percent drf percent drf multiple concurrently cluster reduce task launch occupy resource dramatically delay execution phase similarly makespan ffd DP schedule policy percent fifo although ffd DP achieves resource usage percent cpu core usage average scheduler HaSTE solves impact resource requirement fitness dependency task urgency achieves makespan percent shorter fifo respectively makespans average resource usage workload wordcount axis makespans sec axis cpu memory resource usage mixed workload validate effectiveness HaSTE conduct complex workload mixed cpu intensive memory intensive mapreduce detailed workload configuration input data terasort generate  benchmark input wordcount  wiki category link data hdfs MB mixed workload configuration plot makespans average resource usage mixed workload consistently conventional schedule policy average resource usage around percent cpu memory however makespans drf policy fifo interpret  reduce task prevent starvation task reduce task occupy resource ffd DP HaSTE increase average resource usage around percent resource aware task assignment ffd DP improves makespan percent fifo respectively HaSTE improves performance makespan percent fifo respectively makespans average resource usage mixed workload benchmark axis makespans sec axis cpu memory resource usage understand schedule policy plot runtime memory allocation precedence constraint fifo fairness constraint drf inefficient resource allocation hadoop yarn cluster cpu intensive fifo policy scheduler cannot schedule memory intensive amount memory resource cluster idle drf policy although resource fairness constraint average hinders efficient resource usage node 1GB core available resource task 1GB core 1GB core service assign resource task deserves resource waste cpu core node tune resource ffd DP policy achieve resource usage across importantly HaSTE achieves slightly resource usage across HaSTE allows resource requirement available resource capacity resource improves resource usage illustrate memory resource allocate schedule policy summary HaSTE achieves non negligible improvement makespans resource usage mapreduce various resource requirement leverage information resource requirement cluster resource capacity HaSTE efficiently schedule reduce task improve resource usage addition makespans mapreduce improve dependency reduce task consideration multiple compete resource yarn cluster mixed workload conduct mixed workload consists iterative non iterative evaluate effectiveness HaSTE scheduler alignment metric schedule summarizes parameter configuration workload specifically generate non iterative mapreduce wordcount terasort scan remain iterative pagerank kmeans mixed workload configuration makespan average response average memory usage performance metric schedule policy experimental exist scheduler fifo ffd DP scheduler HaSTE HaSTE factor HaSTE preference HaSTE makespans average response average memory usage mixed workload non  iterative benchmark axis makespans sec average response sec axis memory resource usage performance scheduler resource capacity dependency task HaSTE reduce makespan average response percent respectively increase memory usage percent however improvement HaSTE significant workload non iterative diminishes fifo ffd DP interpret HaSTE differentiate iterative assign preference consequently non iterative terasort wordcount fitness occupy resource resource increase urgency HaSTE overcomes limitation HaSTE integrate alignment preference improves performance workload non iterative iterative makespan HaSTE reduce percent fifo ffd DP respectively additionally average response reduce percent respectively demonstrate HaSTE effectively shorten execution batch boost schedule iterative meanwhile sacrifice average performance average response depicts amount memory allocate across schedule policy memory usage percent GB GB capacity percent periodically fifo ffd DP HaSTE policy memory usage due delayed schedule iterative kmeans alone overall processing iteration lag completion batch closely preference HaSTE HaSTE treat iterative pagerank kmeans non iterative neglect iteration feature assign urgency memory resource allocation schedule police contrast HaSTE scheduler schedule decision combination factor fitness urgency alignment resource requirement task wordcount  resource capacity schedule fitness moreover HaSTE  iterative pagerank kmeans resource earlier iteration parallel non iterative HaSTE superior mixed workload iterative achieve performance shortest makespan resource usage illustrates fitness urgency alignment across representative terasort kmeans scan consistent discussion terasort receives fitness alignment kmeans dominates preference across allows HaSTE execution task earlier schedule algorithm moreover task scan resource cpu memory requirement fitness across scan obtain resource however urgency increase increase ami ari reduce task assign urgency allows scan resource runtime fitness urgency alignment terasort kmeans scan schedule policy HaSTE sum HaSTE achieves makespan average response workload contains iterative alignment metric component preference significantly overcomes limitation HaSTE schedule iterative align execution iterative non iterative successive previous extreme batch arrives although compete resource simultaneously investigate arrival generate launch mapreduce application successive submission load hadoop yarn cluster experimental makespan average memory cpu resource usage schedule  specifically submit random interval respectively evaluate performance capacity scheduler default configuration queue comparison makespans average resource usage mixed workload successive submission axis makespans sec axis cpu memory resource usage HaSTE achieves performance shortest makespan scheduler meanwhile capacity scheduler default configuration performance batch makespan scheduler focus fairness allocate resource  longer performance improvement HaSTE becomes visible resource competition intensive workload efficient schedule algorithm becomes critical increase submission interval execution scheduler tend obtain  sensitive analysis cluster finally investigate  scheduler cluster contains worker node node capacity cpu core memory specifically hadoop yarn cluster  node configure GB memory virtual cpu core 2G core benchmark configuration non iterative iterative mapreduce resource demand experimental makespans average resource usage schedule algorithm makespans average resource usage mixed workload cluster axis makespans sec axis cpu memory resource usage mixed workload configuration capacity obtain performance fifo previous  cluster resource actually pressure resource  simultaneously capacity efficient allocation decision fifo importantly HaSTE HaSTE achieve performance HaSTE outperforms HaSTE iterative pagerank kmeans benchmark related improve performance hadoop mapreduce gain considerable research attention important direction enhance schedule propose delay schedule policy improve performance scheduler increase data locality hadoop compatible scheduler propose schedule policy  formulate schedule hadoop minimum network slot assignment obeys fairness locality constraint minimum network however complexity scheduler slot schedule generation hadoop introduce heuristic minimize makespan independent mapreduce apply classic johnson algorithm however evaluation simulation without implementation hadoop propose static dynamic slot configuration algorithm balance tradeoff overall fairness makespan batch propose adaptive task tune automatically optimal configuration heterogeneous cluster previous propose scheme slot assignment tunable knob reduce makespan mapreduce hadoop ref generation hadoop scheme utilize slot concept resource management grain resource management hadoop  propose improve performance heterogeneous hadoop cluster explore stage propose resource requirement task capability node node assign task scheduler leveraged profile information dynamically adjust slot node workload placement across node maximize resource utilization hadoop cluster scheduler however phase profile schedule  comprehensive intermediate data yarn lustre RDMA mathematically investigates schedule assign input various reducer capacity  propose reserve resource production effort SLAs production guaranteed meanwhile execution effort reduce HaSTE scheduler mainly focus allocate reserve resource effort complementary  although bunch previous concentrate classify memory cpu intensive previous modify framework handle iterative however none focus optimize schedule mapreduce environment iterative  propose eliminates disk operation reduce phase differentiate static variable data scheduler implement plug module exist hadoop yarn without modification popular data processing framework feasibility flexibility schedule conclusion novel schedule policy HaSTE HaSTE hadoop yarn primary goal scheduler improve usage resource reduce makespan mapreduce task fitness urgency HaSTE dynamically schedule task execution resource become available task alignment extend scheduler HaSTE effectively address issue iterative implement scheduler hadoop yarn evaluate representative mapreduce benchmark experimental demonstrate HaSTE HaSTE improve performance makespan workload future extend HaSTE scheduler resource allocation yarn data framework spark derive optimization achieve offline compute optimal makespan