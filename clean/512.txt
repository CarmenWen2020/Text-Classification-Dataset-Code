enable efficient deployment artificial intelligence AI confluence AI compute intelligence leverage computation communication capability device server data closer enable technology intelligence privacy preserve machine paradigm federate FL enables data owner conduct model training without transmit raw data server however FL network envision involve heterogeneous distribute device communication inefficiency remains bottleneck reduce node failure device dropout hierarchical federate HFL framework propose whereby cluster designate data owner intermediate model aggregation decentralize approach reduces reliance central controller model owner however issue resource allocation incentive HFL framework article resource allocation incentive mechanism cluster reward exchange data owner participation data owner cluster specifically apply evolutionary theory model dynamic cluster selection upper cluster model owner whereas model owner compete amongst service cluster propose auction mechanism derive valuation cluster service performance evaluation uniqueness stability propose evolutionary revenue maximize auction introduction predominant approach artificial intelligence AI model training centric data owner transmit training data public server processing however longer desirable due privacy data protection regulation GDPR increasingly stringent addition privacy sensitive data owner opt data transfer massive quantity data burden communication network incurs unacceptable latency sensitive task necessitates proposal compute alternative raw data network closer data confluence compute AI intelligence leverage storage communication computation capability device server enable cache model training inference closer data enable technology intelligence privacy preserve machine paradigm federate FL FL update model parameter raw data transmit model owner global aggregation advantage FL FL enables privacy preserve collaborative machine FL leverage computation capability iot device local model training reduce computation workload model parameter raw data alleviate burden backbone communication network enable practical application development prediction model text message healthcare unmanned aerial vehicle uav mobile compute however FL network envision involve heterogeneous distribute device smartphones internet iot device communication inefficiency remains bottleneck FL specifically node failure device dropout due communication failure inefficient FL moreover worker data owner severely limited connectivity unable participate FL training adversely affect model ability generalize compute recently incorporate communication bottleneck FL hierarchical FL HFL framework propose worker communicate directly central controller model owner instead local parameter uploaded server intermediate aggregation communication model owner establish global aggregation besides reduce instance global communication remote server model owner relay approach reduces dropout rate device discus convergence guarantee empirical HFL approach compromise model performance challenge resource allocation incentive mechanism address HFL framework 5G beyond network resource incentive mechanism collaboration paramount importance facilitate efficient intelligence decentralize model inspire HFL model exist data owner hereinafter refer worker participate FL model training facilitate cluster intermediate aggregation model parameter efficient relay model owner resource allocation incentive worker cluster worker freely cluster encourage participation worker cluster reward pool worker data contribution cluster worker contribute data local training reward pool moreover cluster worker resource bandwidth facilitate efficient uplink transmission update model parameter however worker cluster payoff inevitably reduce due reward worker increase communication congestion cluster selection strategy worker affect payoff worker accordingly worker slowly adapt strategy response worker contrast conventional optimization approach evolutionary theory derive equilibrium composition cluster formulation enables bound rationality worker dynamic capture specifically worker gradually adapt strategy response non cooperative worker achieve objective others strategy gradually adjust strategy accordingly therefore immediately derive illustration model involve population worker within population worker data quantity worker cluster dynamic model evolutionary cluster eventually data coverage across network worker reward service cluster auction upper cluster model owner multiple model owner network aim model respective usage collaboratively participation worker cluster however worker cluster participate training model owner derive allocation cluster model owner optimal pricing service cluster competitive model owner adopt auction mechanism preserve truthfulness bidder simultaneously achieve revenue maximization cluster contribution propose joint resource allocation incentive framework HFL AI approach decentralize intelligence FL reduce reliance central controller model cluster selection decision worker evolutionary proof uniqueness stability evolutionary equilibrium contrast conventional optimization assume player perfectly rational model enables capture dynamic bound rationality player decision assign cluster model owner auction mechanism contrast conventional auction auction ensures seller revenue maximization satisfy individual rationality incentive compatibility constraint organization review related discus model formulation analyze evolutionary discus auction mechanism performance evaluation concludes related FL privacy preserve machine paradigm propose distribute scheme FL communication dominates computation uplink transmission rate worker bottleneck training straggler propose variety model compression technique quantization subsampling client selection protocol reduce occurrence straggler broadband analog aggregation baa computation however despite FL susceptible device dropout addition device geographically location unable participate FL model training affect model ability generalize recently compute inspire propose enhance communication efficiency FL generally attempt reduce reliance FL training central controller HFL framework propose worker communicate directly central controller model owner instead intermediate aggregation parameter conduct aid cluster device communication central controller establish global aggregation similarly proposes mobile device cluster participate organize FL besides improve communication efficiency reduces likelihood training fails due unexpected malfunction central controller cluster selection algorithm cluster chosen social relationship device propose collaborative FL device device D2D device DE communication leveraged ensure efficient transmission model parameter model owner aforementioned validate feasibility HFL highlight advantage conduct FL decentralize manner thereby reduce reliance central controller resource allocation incentive mechanism address HFL framework network worker cluster addition reward compensation resource expend training worker decision dynamic important develop framework potentially cluster incentive propose evolutionary incorporate analyze dynamic cluster selection HFL addition service cluster compensate compete model owner within network utilize auction mechanism cluster accord valuation model owner model formulation model network consists worker exist distinct model owner desire develop AI model purpose traffic crowdsensing location recommendation communication constraint individual worker central controller reliant conventional FL architecture prone device dropout rate moreover cluster employ across network facilitate HFL task denote worker associate cluster without loss generality cluster model owner facilitates HFL cluster  worker  HFL cluster receives initial global model parameter denote vector model owner chosen service relay global model worker FL model training iteration minimize global loss FK stipulate model owner kth iteration consists namely local computation worker global model locally wireless transmission worker transmits model parameter update cluster intermediate model parameter update parameter update  worker aggregate cluster derive update intermediate model transmit worker training iteration iteration intermediate model transmit model owner global aggregation intermediate parameter cluster update global parameter derive model owner sends cluster another local model training assume cluster pre cluster selection algorithm efficiency trust social instead focus optimization adopt evolutionary approach dynamic cluster selection worker derive dynamic composition cluster upper adopt auction cluster worth model owner evolutionary cluster formation derive cluster cluster objective attract worker cluster ensures cluster data coverage across network data coverage cluster increase due model performance increase training data encourage participation worker cluster reward pool worker cluster reward distribute worker proportion worker contribution cluster data quantity relative amount data cluster cluster reward pool attractive worker worker cluster reward pool worker worker decision cluster interrelate decision worker adopt evolutionary theory approach model dynamic cluster formation upper auction evolutionary data coverage cluster cluster data coverage deem valuable FL model owner model performance inference accuracy improve however recall exists model owner network seek secure service cluster facilitate HFL consideration competition model owner adopt auction mechanism model owner bid service cluster specifically utilize auction mechanism attractive ensure truthfulness bidder revenue maximization seller cluster evolutionary evolutionary formulation formulate cluster selection evolutionary player worker FL network player evolutionary clarity worker hereinafter population partition worker population data quantity worker data coverage proportion worker conventional data mining data coverage proportion reflection worker organization proportion user usage frequency individual worker iot device worker population training data sample whereas data quantity population denote denote worker population  population worker network worker within population data sample strategy strategy worker population selection cluster achieve utility maximization strategy worker population denote binary variable worker population chooses cluster whereas indicates otherwise population denote population selects strategy cluster population denote vector payoff payoff worker net utility difference reward derives cluster participate FL model training discus payoff illustration model formulation illustrate population worker population data sample worker population worker population cluster eventually cluster associate data coverage worth evaluate auction mechanism worker cluster worker device unable instance model training parallel however model extend situation worker cluster worker model evolutionary limited resource model owner denote resource worker population contributes cluster worker utility replicator dynamic reward derive worker population cluster iteration FL model training    sourcewhere reward pool across worker cluster data contribution   reward worker data contribution fix reward worker cluster compensation worker participation worker population incur cluster addition computation communication iteration model training computation   sourcewhere consumption coefficient circuit architecture worker central processing cpu cpu cycle perform local computation model training refers computation capability worker frequency worker cpu without loss generality computation constant throughout worker  ccmp account computation communication capability straightforwardly extend multiple heterogeneous population computation capability computation  population accordingly benefit HFL device communication constraint participate FL facilitate communication parameter cluster distributes communication resource participant within cluster cluster communication resource attractive participant participant benefit achievable uplink transmission rate participant attract cluster increase competition resource congestion model  arise network congestion  sourcewhere congestion coefficient resource constraint cluster whereas usage profile across population network cluster specifically cluster resource congestion coefficient moreover worker cluster congestion participation incur worker population cluster obtain ccmp  SourceRight click MathML additional feature net utility worker participation cluster SourceRight click MathML additional feature assume linear utility function risk neutrality worker without loss generality accordingly average utility worker population across cluster source information regard utility derive cluster exchange worker within network worker switch cluster another seek utility capture dynamic cluster selection model strategy adaptation define replicator dynamic sourcewhere refers positive rate population worker adapt strategy network communication bottleneck negative network rate tends worker information decision replicator dynamic series ordinary differential equation ODEs initial specifically replicator dynamic worker population adapt strategy switch cluster another utility utility evolutionary equilibrium fix evolutionary equilibrium worker cluster derive identical payoff longer deviate prevail cluster dynamic paramount importance equilibrium stable unique stability evolutionary equilibrium remains equilibrium uniqueness evolutionary equilibrium regardless initial existence uniqueness stability existence uniqueness stability evolutionary equilibrium boundedness lemma lemma derivative respect bound proof presentation omit notation proof derivative respect      sourcefor notation denote  derive      source   clearly bound therefore   bound proof applies population theorem initial exists unique evolutionary equilibrium dynamic define proof lemma proven replicator dynamic bound continuously differentiable therefore maximum absolute partial derivative lipschitz constant accord theorem exists constant   therefore define relation sourcewhere max   lipschitz implies replicator dynamic initial unique stability evolutionary equilibrium theorem theorem initial evolutionary equilibrium dynamic define stable proof define lyapunov function sourcewhich positive definite otherwise source derivative respect SourceNote replicator dynamic zero net movement strategy adaptation across cluster zeroed population remain constant specifically SourceTherefore ensures satisfies lyapunov stability define lyapunov stability proven uniqueness stability evolutionary equilibrium discus procedure derive equilibrium cluster data coverage replicator dynamic contrast population evolution algorithm involves intervention centralize controller disseminate information potential payoff derive cluster implementation decentralize cluster selection algorithm algorithm initialization phase worker population randomly assign cluster worker compute utility average utility worker population worker information worker belonging population network knowledge average utility population worker average utility procedure simply comparison worker utility cluster average utility worker population chosen cluster thereafter evolution population derive replicator dynamic output algorithm population tmax iteration eventually derive data coverage cluster proportion data across network cluster tmax source algorithm cluster selection HFL input worker cluster characteristic output initialization worker population assign random cluster tmax payoff computation derive compute cluster selection derive compute tmax  auction valuation cluster auction formulation cluster formation evolutionary derive data coverage cluster cluster service model owner worker participation FL model training model owner compete service cluster model owner preference accuracy model application accident warn prediction accuracy route planning navigation FL model accuracy model owner express function denote SourceRight click MathML additional feature  parameter model data coverage model owner achieve model accuracy upper bound accuracy derive historical data whereas fix parameter function requirement data coverage model owner model owner incentive price service cluster data coverage contrast model owner already pre exist training data incentive bid service cluster therefore valuation model owner service cluster express maximize revenue cluster ensure service cluster allocate model owner model allocation multiple item auction auction cluster seller auctioneer model owner buyer bidder cluster amount data coverage auction service model owner model owner submit bid compete service cluster bid profile model owner correspond payment price auction model owner data coverage valuation auction naturally update decrease auction cluster allocate model owner model owner participate auction fulfill data coverage requirement data coverage cluster insufficient fulfill accordingly utility model owner auction model owner bid otherwise source optimal auction characteristic individual rationality IR participate auction model owner non negative payoff incentive compatibility IC incentive model owner submit bid valuation bidder bid truthfully auction payment price model owner traditional auction scheme price auction price auction spa adopt however traditional auction scheme drawback traditional price auction bidder bid submits maximizes revenue seller ensure bidder submit valuation spa bidder price bidder ensures bidder submit valuation ensures IC maximize revenue seller therefore ensure truthfulness revenue maximization seller satisfied optimal auction approach reference auction valuation cluster illustrate neural network architecture optimal auction procedure neural network architecture render optimal auction elaborate propose implementation multiple item auction valuation service cluster neural network architecture optimal auction adopt spa scheme payment price model owner revenue cluster maximize bid bidder maximize revenue cluster monotonically increase function apply bid model owner transform bid transform bid allocation correspond payment model owner network input bid transform bid model owner denote respectively transform function bid submit model owner denote allocation conditional payment model owner spa zero reserve price spa apply transform bid reserve price minimum price cluster service spa allocation spa payment model owner respectively vector transform bid spa allocation determines model owner bid bid zero spa payment determines conditional payment price model owner apply inverse transform function theorem strictly monotonically increase function auction define allocation payment satisfies IC IR spa allocation spa payment respectively theorem choice strictly monotonically increase transform function propose auction allocation conditional payment satisfy characteristic optimal auction IR IC therefore monotone transform function neural network ensure IR IC auction addition cluster maximize revenue allocation conditional payment revenue cluster revenue cluster equivalent payment price model owner objective cluster maximize individual revenue fulfil IR IC optimal auction neural network architecture learns appropriate transform function optimal auction minimize loss function define expectation negate revenue cluster minimization loss function equivalent maximization revenue cluster optimal auction neural network architecture maximizes revenue cluster satisfy sufficient IC IR algorithm implementation optimal auction neural network architecture illustrate algorithm discus important function neural network architecture monotone transform function allocation conditional payment algorithm algorithm optimal auction input cluster bid model owner bil bil output revenue cluster identify cluster data coverage initialization  RI QS  RI QS optimal auction loss function minimize compute transform bid bil minq    compute allocation probability  compute spa payment relu max compute conditional payment compute loss function update network parameter sgd solver update data coverage model owner   update valuation model owner remove cluster return revenue gain cluster monotone transform function auction valuation bid model owner input transform function transform function input transform bid transform function model layer network consists min max operator linear function linear function     positive bias respectively linear function transform function model owner define minq    SourceBased parameter transform function inverse function derive     source monotone transform function allocation allocation neural network architecture spa allocation data coverage cluster allocate model owner transform bid transform bid zero otherwise cluster service model owner model competition model owner softmax function vector transform bid additional dummy input allocation network output softmax function vector allocation probability softmax function neural network architecture define    sourcethe parameter softmax function quality approximation accurate approximation function however quality approximation smooth allocation function conditional payment conditional payment determines price paid model owner conditional payment spa payment model owner calculate specifically spa payment maximum transform bid model owner zero relu activation function relu max SourceRight click MathML additional feature relu max activation function guarantee spa payment model owner non negative spa payment conditional payment model owner calculate SourceRight click MathML additional feature inverse transform function equation apply spa payment model owner neural network training aim neural network optimize bias linear function neural network loss function minimize neural network loss function define expectation negate revenue cluster loss function neural network formulate input training dataset output allocation probability conditional payment model owner training dataset neural network consists bidder valuation profile bidder valuation profile denote bil training dataset bil valuation model owner data coverage cluster drawn valuation distribution function valuation bil model owner depends data coverage requirement amount data coverage model owner bil  dil distribution function distribution data coverage requirement assume data coverage requirement model owner uniform distribution   parameter monotone transform function  bias  entry matrix matrix allocation probability conditional payment model owner respectively objective training optimal bias matrix minimize loss function neural network expectation negate revenue cluster specifically approximation loss function define source optimization loss function parameter stochastic gradient descent sgd solver performance evaluation performance evaluation evolutionary cluster formation auction valuation cluster data coverage unless otherwise simulation parameter cluster cluster interchangeably simulation parameter simulation parameter evolutionary simulation analyze evolutionary network consists worker worker data quantity uniform distribution algorithm derive population worker data quantity posse population worker data sample population worker data sample population worker sample without loss generality data sample worker assume characterize population belong population ascend data sample worker besides exist cluster network offering reward pool congestion coefficient recall indicates cluster reward pool worker whereas cluster limited communication resource cluster ascend reward pool cluster reward pool worker accordingly worker population cluster algorithm strategy adaptation perform evolve worker evaluate payoff churn another cluster payoff probability eventually evolutionary equilibrium achieve stability uniqueness evolutionary equilibrium demonstrate uniqueness evolutionary equilibrium replicator dynamic define derive phase replicator dynamic exposition population exclude population worker cluster population population proportion worker population cluster initial plot correspond dynamic percent worker population cluster clearly despite initial evolutionary equilibrium converges unique phase replicator dynamic evaluate stability evolutionary equilibrium percent percent worker population respectively allocate cluster plot evolution population proportion worker population cluster decline worker population cluster due reward congestion worker cluster eventually evolutionary equilibrium population longer evolutionary equilibrium population cluster situation population cluster initial worker population assign cluster plot evolution utility specifically within population plot utility derive worker chosen cluster population utility derive cluster eventually converges implies evolutionary equilibrium whereby equilibrium worker longer incentive adapt cluster selection strategy moreover equilibrium worker belong population derive utility compensate data cluster evolution population utility plot evolution population population respectively cluster reward pool distribution across worker proportion worker population worker population data sample hence reward pool cluster contrast proportion worker population cluster reward however upper limit worker cluster cluster reward pool distribution reward congestion eventually worker cluster worker population cluster occurs evolution population population evolution population population evolution population population evolutionary equilibrium parameter simulation parameter evolutionary equilibrium rate population strategy adaptation naturally rate evolutionary equilibrium longer however stability evolutionary equilibrium compromise convergence depends worker adapt strategy accurate information evolutionary dynamic rate reward pool cluster reward pool cluster constant respectively plot data coverage cluster data coverage cluster worker contribution naturally data coverage cluster increase increment reward pool cluster attractive worker shareable reward increase data coverage cluster identical cluster respectively cluster identical correspond cluster worker indifferent cluster data coverage versus fix reward cluster congestion coefficient cluster cluster constant plot data coverage cluster congestion coefficient increase cluster data coverage instead worker cluster adapt strategy churn cluster congestion coefficient cluster limited communication resource longer worker without incur communication due device interference data coverage versus congestion coefficient cluster data coverage versus congestion coefficient cluster data quantity worker population population constant plot population population respect participation cluster specifically proportion worker population cluster data quantity population clearly data worker population increase worker population cluster cluster reward pool mention data worker population gain proportion pool reward relative worker population population cluster versus population data population upper auction perform simulation evaluate performance auction comparison classic spa chosen baseline scheme tensorflow library implement optimal auction network formation cluster model owner evaluate performance auction traditional spa proceed impact data coverage cluster model owner distribution data coverage requirement quality approximation revenue cluster evaluation auction revenue cluster auction consistently conventional spa scheme spa scheme guarantee IC guarantee revenue seller maximize preserve IC IR traditional auction auction maximizes revenue earn cluster service model owner service revenue cluster distribution model owner revenue cluster distribution model owner revenue cluster distribution model owner revenue cluster affected amount data coverage data coverage cluster revenue earn model owner requirement data coverage cluster data coverage earns revenue whereas cluster data coverage earns revenue due cluster data coverage conduct auction service hence service model owner data coverage requirement model owner willing price model owner network intuitively serf compensate cluster reward expense incurs revenue data coverage cluster examine impact cluster revenue model owner data coverage requirement distribution specifically model owner distribution cluster data coverage earns revenue model owner data coverage requirement model owner data coverage requirement cluster earns revenue model owner data coverage requirement cluster incentive price revenue earn cluster trend cluster cluster respectively evaluate performance auction cluster revenue quality approximation quality approximation softmax function determination model owner quality approximation revenue cluster increase slightly quality approximation specifically model owner requirement data coverage revenue cluster respectively approximation quality neural network optimization maximizes revenue cluster revenue cluster approximation quality revenue cluster approximation quality revenue cluster approximation quality revenue cluster approximation quality conclusion propose resource allocation incentive mechanism framework HFL leveraged evolutionary theory derive equilibrium cluster selection phase introduce auction mechanism cluster service performance evaluation uniqueness stability evolutionary equilibrium revenue maximize auction mechanism future social network impact cluster selection decision worker moreover account existence malicious worker