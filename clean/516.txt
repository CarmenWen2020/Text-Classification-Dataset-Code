neural network dnn recurrent neural network rnn application rapidly become attractive amount locality data memory bandwidth limit peak performance therefore data actively adapt bandwidth memory HBM  resolve however approach transfer data memory compute processing memory pim performs computation inside memory attract attention however previous modification extension core pipeline memory component memory controller practical implementation pim challenge expensive development article propose pim performs pim computation standard dram memory request hardware modification pim memory device perform computation service non pim application memory request achieve goal preserve standard memory request behavior satisfy dram standard timing requirement addition standard memory request dma pim offload processing pim memory request core perform task performance memory model lstm kernel platform pim model fpga gpu cpu matrix multiplication batch pim perform faster gpu cpu respectively without data reuse data reuse gpu performance pim performance cpu execution similarly wise multiplication addition data reuse pim achieve cpu gpu pim EDP performance superior others data reuse introduction von neumann architecture cpu code data memory executes program memory traditional execution incurs amount unnecessary data movement recently emerge data intensive application amount locality data dnns rnns memory database graph algorithm eventually cpu performance increase memory bandwidth limit overall peak performance data actively apply bandwidth memory device HBM  compute platform however approach performance optimal data locality application recently therefore tight integration cpu memory attract attention promising technique CPUs accelerator memory data processing ndp inside memory processing memory pim previous redesign compute currently currently JEDEC define pim protocol highly likely define pim protocol future limit develop pim function pim pim operation comply standard dram interface therefore express standard memory request knowledge propose pim architecture modification hardware component pim dram device implies pim device perform pim computation standard memory request comply standard dram interface preserve dram standard operation semantics timing constraint standard memory request pim execution impossible memory controller distinguish memory request pim non pim application pim device differentiate pim device driver pim source destination operand address attribute pim memory device configuration pim execution pim device incoming memory request address identifies pim request operation pim non pim memory request handle datapath pim operation satisfy timing constraint standard memory request burst operation accompanies dram RD WR command operation timing constraint tCCD command cycle burst operation developed stage pipelined vector datapath per bfloat data dnn rnn application burst data violate timing constraint preserve dram standard operation semantics timing constraint execute pim non pim application simultaneously implies pim alter interfere execution non pim consequently affect behavior behavior execution perform operation von neumann compute platform cpu gpu source operand destination operand therefore approach performance execute application exploit data locality compute platform execution source operand memory destination memory standard memory request achieve goal deliver performance various architectural component application library operating pim device carefully minimal modification extension configure kernel specific pim datapath kernel configurable processor pim application repeatedly perform operation data input output therefore command computation inefficient addition memory model carefully efficiently develop pim program execution model performance kernel lstm matrix multiplication wise multiplication addition machine pim model fpga platform nvidia titan gpu cuBLAS amd ryzen cpu  contribution following propose pim performs pim computation standard dram memory request hardware component detail develop various architectural component application pim device achieve goal pim achieve speedup vector matrix multiplication wise operation cpu gpu execution respectively pim EDP performance superior platform remainder consists overall pim architecture experimental platform pim device interface host device pim software stack evaluate pim performance introduces previous PIMs finally concludes overall architecture experimental platform pim device emulate execution fpga developed software stack host platform via pci verify operational concept overall architecture configure ddr dram fpga uncacheable memory regard memory controller fpga memory controller processor xilinx ddr memory controller IP without modification pim comply standard memory interface dram however extend functionality exist data pim datapath computation pim device memory controller dram emulate dram perform pim execution data granularity fetch dram burst memory 3D stack memory modify fpga memory controller pim device comply ddr specification overall architecture experimental platform modify pim diagram identical JEDEC standard pim function reading emulate dram pim fpga pim device performs dram computation purpose emulate device dram memory controller recognize command issue memory controller dram satisfy transition timing constraint pim device correctly preserve dram recognize dram command implement byte vector register burst per pim command standard command pim device intercept data transfer dram memory controller vector register pim command standard command pim device transfer vector register data dram instead data memory controller pim device satisfy command related timing tRCD tCCD tRAS etc addition data management pim satisfy dram timing perform computation pim argument dram command issue sequentially cycle tCCD interval validate propose implement dram logic dram fabrication characteristic verify met dram internal operating frequency mhz available memory mapped pim interface access register inside device implement pim interface identify pim memory request standard memory request configure pim stage pipelined vector alu bfloat data target application dnn attach pci developed pim device affected overall performance additionally application fpga memory seriously memory cpu issue pim memory request becomes therefore apply memory access dma pim execution offload standard memory request pim execution cpu percent compute resource dma host platform therefore dma usage dram pim offload cpu perform task execute pim kernel pim software consists component application pim architecture layer pim wrapper pim execution interface application math library various pim kernel operation device driver manage pim device interfacing pim device OS reserve memory mapped boot pim management pim application operand kernel specific configuration information reserve pim driver pim execution pim device address incoming memory request operand information identify pim request pim computes configuration information incoming pim request pim device interface identify pim request configure pim device identify pim request realize pim programmer information pim operand hardware pim device pim device distinguishes pim request standard memory request perform pim operation pim program align pim operand physical simplify request identification device interface recognize placement easily pim program modify OS contiguously allocate physical reduce configuration overhead buffer whenever physically contiguous guarantee previously issue memory pim request service configure operand register identify contiguous pim operand incur significant overhead pim execution programmer physical address operand correspond register pim device driver pim device source register reg destination register reg define operand valid operand register lsb configuration register reg operand configuration information memory request pim execute configure pim datapath memory request identify pim command operand information configure datapath request identification riu identifies pim RD command pim datapath pim WR command pim datapath information operand register riu preprocessing incoming request pim device riu identify pim command riu physical dram address mapping structure operand register address logic identify pim command riu physical dram address mapping structure operand register address logic cannot incoming request address address register straightforwardly due characteristic dram operation address transmit memory device dram command RD WR command issue mixed another OS dram misalign therefore address consists command address pim operand address per information incoming RD WR request later device pim command address logic address logic operand performs entry address pre command operand valid address latch address operand address calculate operand address incoming address command unset pre command define address RD WR command incoming memory request address address latch operand incoming memory request pim command global output source destination riu express flexible explain detail configure pim data intensive application target pim sequence operation repeatedly perform amount data therefore repetitively pim operation command host pim device incurs unnecessary significant overhead consequently configure pim kernel execution related memory request source destination operand configuration information configuration register reg pim device prepared configuration information pim kernel matrix matrix multiplication vector matrix multiplication wise addition multiplication explain detail pim device driver pim device driver reserve  uncached fpga memory boot receives operand configuration information pim application register memory mapped driver manages pim device ownership multiple semaphore pim device spill pim schedule complicates implementation modification schedule related OS restore pim device eventually semaphore pim device rely OS schedule pim device device driver function sys pim acquire operand address function configuration convert operand virtual address physical address calculate acquire semaphore pim device pim operation fails driver semaphore release semaphore acquire pim device driver operand address correspond operand register kernel configuration information sys pim release invalidate operand information lsb reg disable pim operation release semaphore memory access fpga experimental platform performance issue host continuously memory request pim device operand access incur overhead entire memory host processor due overhead pci interface execute various pim kernel analyze performance percent fpga memory controller execution idle memory access pim device offload pim dma without modification performs standard memory request array typed source destination operand pim kernel suitable dma operation request continuous burst data device pim datapath limited various pim kernel execution explain alu bfloat data attract attention dnn satisfy dram timing constraint datapath pim datapath assume dram data width burst standard memory request afford abundant compute resource due limitation dram nevertheless burst operation datapath per vector register  vector register  accumulator register vacc bfloat vector ALUs dnn computation datapath consists stage FE stage fetch operand EX EX stage computation WB stage writes vacc manages datapath decode information configuration register reg pim datapath pim ISAs category pim ISAs data RD WR register clr register data transfer mov scalar broadcasting  arithmetic operation mac sub mul pim RD WR command performs standard memory request service pim execution pim riu recognizes pim RD command bus switch pim datapath RD command src operand reg src operand reg data   respectively pim WR address destination operand reg pim riu bus switch accumulator register instead data express memory request mov ISA defines data movement register vacc mantissa expansion  ISA broadcast scalar vector register source entire MACs vector matrix multiplication bfloat mac stage multiplication addition stage pipelined bfloat mac capable satisfy dram timing constraint sub mul operation mac developed optimization technique reduce complexity mantissa alignment due exponent difference operand extend mantissa exponent mantissa extension logic calculate exponent difference multiplication stage hidden multiplier delay assume exponent calculate multiplication stage addition stage assumption circuit handle exponent difference multiplication stage overflow occurs due mantissa alignment exponent assumption therefore addition stage overflow signal multiplication stage pre calculate exponent difference finally vacc format bfloat resize exponent mantissa width perform normalization whenever vacc therefore normalize vacc thereby reduce critical delay remove normalization accumulation pim application dnn performs computation repeatedly data datapath configure pim execution reduce command transmission overhead reduces consumption decode command specification configuration register reg configuration corresponds signal data allows reduce decode hardware overhead pim ISAs easily vector addition instruction sequence timing diagram vector addition instruction sequence timing diagram format configuration register reg correspond signal pim datapath hardwired decouple data movement pipelined alu efficiently burst operation operation simplification operand information riu source destination related incoming pim memory request simplification global source destination standard memory request involves burst operation  register data identify pim memory request  burst identify pim memory request  operation source operand whenever data  pim memory request identify data vacc attach burst counter duplication counter etc burst operation pipelined mac burst counter correspond burst stage execute datapath define configuration register burst pipeline stage  ISA scalar  scalar broadcast mac duplication counter scalar  newly update counter initialize timing diagram perform vector addition burst mode datapath pim consists pipeline stage FE fetch data register EX EX mac execution WB normalize vacc vector addition perform ISAs   mov WR configure datapath mov advance reg reg operand  burst burst FE stage vacc datapath pre configure mov ISA EX EX stage pipelined manner burst data operand  FE stage performs addition mac pre configure ISA vacc EX EX stage performs operation pipelined manner WB stage vacc normalize dram pim software stack pim software consists following application pim architecture layer pim wrapper pim execution interface application math library various pim kernel operation device driver role pim device management configuration subsection software implementation described detail vector matrix multiplication application pim application allocates pim operand onto fpga dram modify OS manage fpga dram memory extend mmap function pim operand allocate contiguous  uncached physical swap migrate pim operand incur inconsistency operand information operand register replace application code suitable pim execution pim wrapper argument pim kernel identifier operand allocate initialize pim operand application pim wrapper pim wrapper pim wrapper interface execute pim kernel application wrapper function performs pim acquire pim device driver acquire pim device ownership configure pim incoming pim kernel argument execution pim release release pim device ownership pim vector matrix multiplication algorithm multiplication vector matrix vector matrix multiplication wise manner matrix vector multiplication wise manner advantage disadvantage wise adder sum multiplication dram basis pim channel increase challenge implement hardware capable gathering sum associate overhead significantly increase wise data matrix tend dram incur significant buffer vector matrix multiplication wise matrix vector multiplication wise dram burst operation involve data parallelism imperative exploit parallelism execution therefore chose vector matrix multiplication wise rely programmer manual data layout reduce buffer pim kernel pim kernel code vector matrix multiplication wise manner execute matrix independently assume vector already calculation explanation pim kernel code vector matrix multiplication pim byte vacc bfloat therefore execute consecutive matrix without spill vacc memory define chunk interleave schedule across execute matrix parallel across register  execute matrix therefore vector fetch matrix num regs  entry execute matrix performance analysis experimental methodology evaluate performance kernel matrix multiplication wise addition multiplication popularly lstm machine propose pim architecture xilinx virtex ultrascale  cpu amd ryzen mhz gpu nvidia titan mhz logical core multi thread execution cpu pim device matrix multiplication  cpu cuBLAS gpu extend pim kernel wise kernel developed program cpu gpu compile matrix batch pim performance cpu gpu data reuse application kernel data reusability compute cpu gpu cache conv kernel data reuse pim execution efficient cpu gpu execution conv kernel data incur overhead implement inside dram therefore focus lstm kernel goal performance insight dram pim however fpga memory controller operating frequency mhz host amd ryzen memory controller mhz fpga pim performance frequency difference predict dram pim performance acceptable due host cpu fpga ddr timing constraint dram performs cycle tcl tRCD trp tRAS CK dram execution directly depends operating frequency wise access algorithm buffer whenever access matrix therefore friendly dram operational behavior matrix transpose matrix multiplication matrix interleave byte performance operation related data layout exclude performance measurement layout data generate tensor pytorch performance cpu serial execution pim dma without dma pim dma dma without contiguous memory allocation pim dma layout dma dram friendly data layout contiguous memory allocation cpu omp openmp gpu performance non contiguous memory allocation operand register whenever fetch therefore performance overhead configuration register pim dma layout execution speedup batch kernel cpu serial execution speedup batch matrix multiplication wise addition multiplication cpu serial pim dma pim dma pim dma layout cpu omp gpu matrix multiplication pim dma layout performance superior cpu performance regardless batch batch speedup pim dma layout pim dma pim dma respectively pim dma pci interface performance degradation significantly non contiguous physical pim dma limited dma burst frequent interaction host dma contiguous memory allocation pim dma layout reduce interaction ideally  buffer simultaneously overhead configuration register percent pim dma pim dma average batch computation becomes vector matrix multiplication data reuse operand memory GDDR degrade gpu performance performance cpu pim operand speedup gain pim dma layout gpu discus memory overhead detail batch increase data reuse increase therefore speedup pim gradually decrease gpu batch speedup gpu pim dma layout pim dma pim dma respectively propose pim structure fully exploit data parallelism burst operation vector execution however execution linearly increase batch pim device abundant data register reuse gpu reuse data GDDR memory utilize massive computational parallelism cpu omp multi thread data reuse batch increase performance saturate due capacity cache wise computation batch pim dma layout performance cpu performance intrinsically wise computation involve data reuse dram access directly affect execution moreover addition multiplication execution behavior batch pim dma layout speedup cpu execution incur buffer operand access operand affected dram behavior pim dma layout speedup cpu overhead configuration register percent pim dma pim dma average pim dma execution incur frequent interaction host dma due non contiguous allocation gpu execution operand locality memory GDDR therefore performance cpu performance cpu omp multiple core characteristic execution core however performance increase linearly reduce core workload core memory behavior overhead profile fpga memory controller execution cycle overhead occurs due pci interface idle cycle implies memory request controller matrix multiplication idle cycle pim dma occupy percent execution cycle regardless batch access interval memory request request due interface controller spent request pim dma execution idle cycle percent execution spent frequent interaction host dma dma burst limited pim dma layout dma burst increase idle cycle reduce significantly percent wise operation idle cycle occupy percent matrix multiplication wise execution involves ratio request request overhead pci interface idle cycle ratio matrix multiplication pim execution profile cycle ratio dram command buffer behavior pim dma pim dma pim dma layout pim execution profile cycle ratio dram command buffer behavior pim dma pim dma pim dma layout ratio dram command issue memory controller buffer ratio allows allocate dram RD WR command batch pim executes command memory behavior almost ratio RD command pim dma kernel request interval interval refresh command closing continuously matrix multiplication command RD command incur percent ratio pim dma pim dma layout respectively ratio pim dma without data layout matrix sufficiently possibly mapping matrix dram wise execution ratio matrix multiplication batch ratio pim dma pim dma pim dma layout percent respectively batch ratio pim dma pim dma percent imply ratio wise computation characteristic increase operand onto dram incur buffer whenever access operand source operand interleave buffer occurs access destination operand therefore ratio pim dma layout percent regardless batch gpu execution computation memory regardless kernel batch overhead significant percent execution application execution exploit data locality pim performance superior gpu gpu execution profile batch matrix multiplication wise addition multiplication EDP analysis estimate platform consumption sum component cpu cpu dram gpu cpu gpu dram pim cpu dram pim assume platform dram fpga analysis assume implement pim inside dram accurate measurement kernel cpu gpu machine average consumption respectively performance profiler average limit RAPL interface cpu measurement nvidia management interface gpu measurement amd processor dram RAPL interface  achieve average consumption synopsys compiler  pim performance metric characteristic dram verilog model pim measurement pim consumption evaluate consumption platform dram consume percent pim consume percent gpu consumption predict consumption execution core pim execution almost similarly multicore execution cpu omp consume core execution gpu consume percent multicores average consumption batch matrix multiplication wise addition multiplication cpu serial pim dma layout cpu omp gpu EDP performance platform matrix multiplication batch pim EDP performance cpu gpu respectively pim consume execute faster cpu gpu gpu consumption significant cpu EDP performance batch gpu execution become faster EDP performance improve finally cpu pim pim execution linearly increase EDP performance gap pim cpu decrease wise kernel gpu performance batch gpu overhead dominant execution due data reuse cpu consume pim batch speedup gap pim EDP gap decrease pim EDP performance superior platform EDP batch matrix multiplication wise addition multiplication cpu serial pim dma layout cpu omp gpu EDP batch matrix multiplication wise addition multiplication cpu serial pim dma layout cpu omp gpu related recent pim extensively data processing memory processing ndp hardware logic core accelerator memory logic 3D stack memory memory processing compute logic inside memory exploit internal bandwidth efficient computation ndp 3D stack memory typical accelerator however important performance issue offload pim task pim specific ISAs former issue related code execute pim latter related pim accelerator cooperate host unfortunately previous modify hardware component address translation core pipeline memory controller situ analog memory processing ReRAM memory operation ReRAM memory platform implement situ analog  processing simplify compute data analog operation data handle adc DAC therefore adc DAC overhead significant memory ambit  implement logic operation exploit internal bandwidth inside dram however mechanism activation dram consumption become unreliable variation  architecture mac dram decoder inside dram recently propose systolic array architecture internal bandwidth data however software execution conclusion propose pim architecture perform inside dram standard dram memory request entire architecture layer application operating pim device perform computation standard memory request popular dma pim offload significantly reduce memory request overhead furthermore proposal modification hardware component pim device apply pim device commodity platform analyze performance execution pim model fpga platform cpu gpu lstm kernel batch matrix multiplication wise multiplication wise addition pim achieve significant performance performance metric kernel exploit data locality execution without data reuse matrix multiplication pim achieve speedup EDP improvement cpu gpu respectively wise multiplication addition kernel pim performance gain execution data reuse matrix multiplication gpu perform superior EDP performance others insight pim memory research development community widens pim applicability