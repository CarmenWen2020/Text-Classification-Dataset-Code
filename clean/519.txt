federate FL distribute enables multiple participant mobile iot device contribute neural network private training data remains local device distribute approach promising mobile corpus decentralize data privacy however unlike datasets data distribution mobile imbalanced increase bias model article demonstrate imbalanced distribute training data accuracy degradation FL application counter balance FL framework astraea alleviates imbalance data augmentation mediator multi client reschedule propose framework relief global imbalance adaptive data augmentation downsampling average local imbalance creates mediator reschedule training client kullback leibler divergence kld data distribution FedAvg vanilla FL algorithm astraea percent improvement accuracy imbalanced EMNIST imbalanced CINIC datasets respectively meanwhile communication traffic astraea reduce percent FedAvg introduction enormous DL neural network application aspect recognition attribute representational ability data therefore dataset complex   network model fortunately data generate massive amount data scatter across mobile device aggregate distribute data training significantly boost quality model however data aggregation tricky challenge mobile device user organization unwilling data due security consideration privacy policy GDPR addition communication storage aggregation unaffordable instead aggregate data aggregate model therefore distribute machine framework parameter server  federate emerge federate FL promising distribute neural network training approach application image classification FL enables mobile device collaboratively neural network model training data decentralize FL application mobile device participate neural network model training task client client independently neural network model local data federate server average model update parameter random subset FL client aggregate global model depicts federate application aim convolutional neural network cnn classifier image mobile device FL server deploys global cnn model participate client client calculates gradient update refreshes local model parallel local image dataset finally FL server integrates update client refresh global model procedure multiple epoch global model participate client private data transfer  model training procedure addition client withdraw federal network private data transfer  model training procedure FL ensures privacy latency mobile application adaptive data application federate server mobile device cnn image classifier collaboratively nevertheless challenge mobile federate distribution training data mobile device volatile prediction accuracy skewness image dataset client increase bias FL server effort tackle challenge propose communication efficient FL algorithm federate average FedAvg cnn model FedAvg achieve percent accuracy non iid mnist dataset user local dataset representative population distribution cnn model FedAvg non iid cifar dataset percent accuracy loss exist assume expectation global data distribution balance volume data device disproportionate scenario distribute mobile device however global data distribution imbalanced imbalanced distribution global imbalanced distribute training data global imbalanced distribution collection distribute data imbalanced global imbalanced subset EMNIST dataset explore impact accuracy FL experimental global imbalanced training data percent accuracy loss FedAvg accuracy degradation imbalance novel balance federate framework astraea astraea framework  training FL imbalanced datasets strategy training model astraea performs data augmentation alleviate global imbalance astraea proposes mediator reschedule training client accord kld mediator uniform distribution combine training skewed client mediator achieve partial equilibrium astraea improves percent accuracy imbalanced EMNIST percent imbalanced CINIC FedAvg reschedule strategy significantly reduce impact local imbalance decrease kld mediator uniform distribution propose framework communication efficient experimental astraea reduce percent communication traffic FedAvg achieve percent accuracy imbalanced EMNIST contribution summarize global imbalanced training data degrade accuracy cnn model FL propose balance federate framework astraea along strategy prevent bias training imbalanced data distribution implement propose astraea tensorflow federate framework experimental astraea efficiently retrieve percent accuracy loss imbalanced EMNIST retrieve percent accuracy loss imbalanced CINIC dataset organize outline background motivation overcome imbalanced FL challenge detail astraea framework evaluation analyze concludes background motivation introduce background distribute machine federate briefly introduce imbalanced data motivation distribute machine distribute machine aspect distribute operation inference training distribute storage dataset model ensemble distribute cluster etc distribute machine framework propose propose  utilizes compute cluster machine model compute node model performs gradient calculation transmits node graphlab distribute machine platform data mining parameter server framework server node maintain globally parameter data workload distribute worker node however application scenario framework performance cluster hpc server data training data across distribute node therefore privacy cannot guaranteed privacy researcher propose federate framework model aggregation algorithm FedAvg FL client calculate update synchronous stochastic gradient descent sgd parallel parameter server update aggregate FedAvg algorithm privacy preserve training mobile application FL recently emerge improve prediction google keyboard FL FL domain mobile device recurrent neural network model prediction google keyboard application FL framework propose  predict hospitalization due disease privacy participant data preserve distribute training addition propose aware optimization framework  address statistical challenge FL recent research federate focus reduce communication overhead privacy accuracy degradation due imbalance however discus impact local imbalanced non iid data assume global data distribution balance rare distribute mobile imbalanced data classification task imbalance increase bias machine algorithm imbalanced distribution classic data sample ensemble undersampling sample dataset balance subset easy implement data local database FL client usually propose sample SMOTE generate minority sample rebalance dataset improve SMOTE data distribution minority however unsuitable FL data client distribute private ensemble adaboost xgboost misclassification reduce bias however machine algorithm sensitive outlier distribute dataset federate widely deployed mobile phone iot device device model local data data distribution device depends usage likely camera deployed capture camera deployed furthermore another imbalance imbalance collection distribute data frequency english literature zipf distinguish imbalance federate summarize category imbalance data device client uneven local imbalance independent non identically distribution non iid device data distribution global imbalance collection data device imbalanced motivation clarify impact imbalanced training data federate FL framework convolutional neural network cnns imbalanced dataset however distribute image classification dataset distribute datasets resampling EMNIST dataset EMNIST image classification dataset contains handwritten english digit although federate version  unaccounted imbalance training imbalance dataset distribute EMNIST datasets bal bal INS LTRF LTRF detail characteristic bal bal scalar balance global balance difference bal local balance bal random INS scalar imbalanced dataset client data image uploads amount instagram user LTRF LTRF global imbalance global distribution frequency english obtain corpus english wikipedia article addition training data LTRF almost twice LTRF balance identical sample training client setting distribute EMNIST dataset model architecture implement cnn model convolution layer dense layer convolution layer channel kernel stride respectively convolution layer dropout probability convolution layer channel kernel stride flatten operation dense layer fully layer activate relu softmax output layer loss function categorical entropy metric accuracy cnn model parameter achieve percent accuracy epoch EMNIST FL setting adopt notation federate setting local mini batch local epoch client client performs computation local training client update via adam optimizer rate decay accuracy distribute EMNIST datasets experimental global imbalance significant decrease accuracy qualitatively global imbalanced dataset LTRF percent reduction accuracy INS percent LTRF percent reduction accuracy INS percent although LTRF twice amount training data LTRF addition random local imbalance accuracy degradation accuracy bal bal percent accuracy slightly improve percent scalar imbalance percent accuracy confusion matrix evaluate distribute EMNIST accuracy versus communication distribute EMNIST comparison confusion matrix cnn model bal dataset LTRF dataset accuracy confusion matrix evaluate distribute EMNIST accuracy versus communication distribute EMNIST comparison confusion matrix cnn model bal dataset LTRF dataset elucidate influence global imbalance confusion matrix bal LTRF meaning label EMNIST label correspond  label correspond english merge accord confusion matrix bal image classify correctly confusion matrix diagonal however confusion matrix LTRF image correspond frequency english  classify due global imbalance training procedure cnns bias towards classify majority sample summary global imbalance accuracy loss model FL challenge mobile FL application neural network various distribute data distribution however upload user local data optional expose user data privacy risk address challenge balance federate framework astraea improve classification accuracy data augmentation mediator multi client reschedule  astraea aforementioned accuracy federate distribute imbalanced dataset balance dataset explain decrease accuracy mathematically imbalance distribute training data decrease accuracy FL application conclusion astraea framework goal relieve global imbalance local imbalance training data recover accuracy mathematical demonstration define federate training imbalanced dataset accuracy degradation  accuracy degradation federate traditional sgd ideal derive update formula optimal sgd optimization objective   sourcewhere data loss function distribution training data respectively goal minimize loss assume data   distribution balance image classification task sgd federate assume initial sgd federate source optimal sgd update  source achieves accuracy optimal federate federate optimization objective   sourcewhere data training data distribution client client correspond training data distribution data imbalanced federate client client optimize gradient descent rate update   data source federate server calculate FedAvg algorithm avg    data source data  avg federate cannot achieve optimal training data distribution imbalanced federate restore accuracy model data  satisfied mathematical induction proposition avg non negative integer data  proof basis statement avg  source inductive assumption assume avg data  avg  data  SourceTherefore induction statement accord conclusion difference distribution training account accuracy degradation FL therefore achieve partial equilibrium propose astraea framework augment minority mediator combine skewed distribution multiple client detail propose framework astraea framework accuracy degradation training data client rebalanced instinct redistribute client local data distribution uniform however data privacy issue communication overhead another rebalance training update global model sequentially client calculates update global model applies update global model sequentially communication overhead consumption federate FL combine propose astraea mediator FL server client rebalance training overview propose astraea framework astraea consists FL server mediator client FL server responsible maintain global model deploy model mediator synchronously aggregate update federate average algorithm client mobile phone iot device maintain local training dataset data client category accord characteristic data distribution uniform client balance training data FL application client astraea framework overview astraea framework overview slight client relatively amount data participate training skewed client training data prefer data local imbalanced client slight client skewed client introduce scalar imbalance local imbalance respectively mediator function reschedule training processing client client data label label meanwhile client data label label mediator combine training archive partial equilibrium mediator distribution collection data uniform extent partial equilibrium kullback leibler divergence probability distribution mediator reschedule client uniform distribution respectively empirical distribution approximate probability distribution besides combine multi client training mediator expand training client mediator virtual component deployed directly FL server mobile compute MEC server reduce communication overhead algorithm astraea distribute neural network training procedure FL server training initialize synchronization mediator parallelly    FedAvg function  mediator epoch client mediator sequential sgd local epoch return algorithm training procedure astraea FL server initializes global model training FL server communication sends global model mediator mediator coordinate assign client training calculates update  parallel finally FL server update mediator aggregate update cumulative client assign mediator server update global model model communication astraea workflow workflow astraea initialization rebalancing training aggregation astraea workflow data augmentation downsampling mediator reschedule initialization initialization phase FL server mobile device FL model training task device participate training local data distribution information server device client involve training FL server initializes optimizer neural network model local data distribution participant rebalancing rebalance training FL perform data augmentation downsampling relieve global imbalanced training data however augmentation strategy potential increase local imbalance demonstrate local imbalance non iid divergence accuracy loss therefore propose mediator  receives applies update client average local imbalance reschedule client training mediator balance model combination augmentation reschedule strategy achieve accuracy improvement detail strategy augmentation strategy augment minority sample downsample majority sample global data distribution majority minority borrow outlier detection algorithm treat majority minority outlier detail algorithm downsampling threshold augmentation threshold respectively outlier detection treat majority denote  minority denote  rad ratio augmentation generate sample retain formula algorithm principle formula generate augmentation sample lesser meanwhile augment  downsample  simplify algorithm negative reciprocal algorithm hence formula augmentation ratio downsample ratio simplify formula apply trick implementation recommend outlier detection algorithm addition recommend standard deviation robust adapt data distribution advantage calculation   rad server sends parameter client client perform data augment downsample parallel algorithm downsample function return sample otherwise return empty augment function sample generates augmentation random shift random rotation random shear random zoom parameter augment function sample goal data augmentation mitigate global imbalance eliminate generate sample model training prone overfitting client augmentation downsampling FL server creates mediator reschedule client achieve partial equilibrium balance training increase collaborate client mediator however induce communication overhead hence mediator coordinate training client evaluate communication overhead mediator algorithm data  downsampling rebalancing distribute datasets FL server initialize rad calculate data CN calculate standard deviation calculate   rad downsampling  rad    rad client client client parallelly sample dataset label downsampling  downsample rad label   aug aug aug aug augment rad aug aug  policy reschedule algorithm greedy strategy assign client mediator mediator traverse data distribution unassigned client selects client data distribution mediator data distribution closest uniform distribution algorithm minimize kld mediator data distribution uniform distribution FL server mediator mediator max assign client limitation client training reschedule algorithm mediator multi client reschedule dkl kullback leibler divergence procedure reschedule initialize   mediator    mediator client      return  training communication mediator sends model subordinate client client model mini batch sgd local epoch return update model correspond mediator local epoch affect spent training per client increase additional communication overhead mediator receives update model sends training client mediator epoch client training astraea loop mediator update model FL server communication overhead model accuracy mediator epoch update model discus aggregation FL server aggregate update FedAvg algorithm equation FL server sends update model mediator synchronization difference astraea standard FL algorithm model integration phase astraea achieve partial equilibrium integrate model astraea balance standard federate algorithm evaluation experimental setup implement propose astraea modify tensorflow federate framework  evaluate machine simulation runtime  notation notation definition datasets model adopt widely datasets correspond model evaluation imbalanced EMNIST correspond model LTRF dataset cnn model mention respectively imbalanced CINIC cifar model described kera documentation respectively imbalanced CINIC sample CINIC empirical distribution label normal distribution another global imbalance imbalanced EMNIST dataset furthermore prevent leakage overlap training client baseline vanilla federate algorithm FedAvg baseline apply google keyboard improve query suggestion baseline evaluate imbalanced EMNIST training configuration CINIC configuration propose efficient accuracy accuracy metric evaluate cnn model recall rate balance data misclassification furthermore maximum accuracy training procedure accuracy model ignore overfitting however accuracy curve overfitting occurs augmentation versus mediator accuracy improvement imbalanced EMNIST improve accuracy achieve data augmentation strategy improve accuracy achieve combine augmentation reschedule implement  propose  augmentation strategy improve accuracy percent significant decrease accuracy occurs decline training sample augmentation insufficient cnn classify sample  accuracy evaluate imbalanced EMNIST comparative involve data augmentation downsampling strategy apply combine augmentation strategy reschedule strategy reschedule strategy accuracy model improve percent percent explore accuracy improvement reschedule detail accuracy model data augment disabled denote  although percent accuracy improvement achieve without augmentation strategy experimental model prone overfitting curve  indicates accuracy gradually decrease synchronization percent baseline accuracy evaluate imbalanced CINIC data augmentation strategy improve percent accuracy accuracy model significantly improve percent apply propose reschedule strategy  evaluate imbalanced EMNIST curve  gradually reduce synchronization model suffer overfitting augmentation apply  accuracy evaluate imbalanced CINIC comparative involve data augmentation strategy apply combine augmentation strategy reschedule strategy gamma  accuracy evaluate imbalanced CINIC comparative involve data augmentation strategy apply combine augmentation strategy reschedule strategy goal reschedule strategy achieve partial equilibrium cannot mitigate global imbalance combine strategy important achieve maximum improvement accuracy choice public adjust accord task however inappropriate hence recommend recommend outlier detection algorithm versus online client per determines training synchronization max assign client limitation mediator determines scope partial equilibrium explore impact training procedure astraea experimental imbalanced EMNIST training model converges faster increase however accuracy slightly reduce model accuracy reduce percent cnn model training suffer overfitting remedy loss accuracy overfitting regularization strategy optimization halt performance validation training furthermore experimental improve accuracy model accuracy astraea imbalanced datasets participate client per maximum assign client limitation mediator explore impact mediator augmentation configuration equilibrium kld client mediator kld client traditional FL denotes FedAvg calculate dkl equilibrium FL client without augmentation reschedule empirical distribution label client probability distribution uniform kld aug equilibrium astraea framework without reschedule calculate dkl empirical distribution label client training data augment kld mediator astraea framework denotes multiple calculate dkl empirical distribution label mediator assign kullback leibler divergence horizontal axis configuration mediator client indicates median indicates kld distribution skewed kld FedAvg distribution FedAvg imbalanced augmentation strategy mention increase local imbalance introduce outlier augmentation strategy generally kld increase become skewed kld various distribution augmentation strategy reduce local imbalance outlier introduce apply reschedule highly skewed client achieve partial equilibrium complementary reschedule outlier significantly reduce kld slightly combine strategy significantly rebalance data distribution decrease shrink interquartile increase besides reduce kld suggests mediator achieve partial equilibrium client participate training client assign mediator summary accuracy improvement astraea increase training expands conclusion astraea significantly reduces kld FedAvg strategy local epoch versus mediator epoch explore impact local epoch mediator epoch training epoch local gradient update communication epoch mediator update synchronization maximum accuracy evaluate imbalanced EMNIST maximum accuracy evaluate imbalanced EMNIST local epoch mediator epoch gamma tau maximum accuracy evaluate imbalanced EMNIST local epoch mediator epoch increase local epoch significant improvement accuracy local epoch accuracy accuracy cnn model percent average local epoch mediator epoch training slightly improve accuracy percent local epoch although experimental increase significantly improve accuracy model reduce communication overhead increase accelerate convergence model tradeoff accuracy communication overhead demonstrate overhead discus overhead astraea framework storage communication ignore computational overhead astraea additional calculation augmentation reschedule computational resource calculate FL server imbalanced EMNIST dataset overhead task additional astraea data augmentation reschedule extra training epoch mediator algorithm spent augmentation maxk rad ita augment image assume fix complexity data augmentation perform initialization phase consumption negligible training procedure reschedule algorithm greedy strategy client reschedule complexity data distribution client static astraea performs reschedule contrast data distribution client dynamically rapidly astraea reschedule synchronization overhead astraea framework model training FL spent communication training local epoch astraea spent synchronization  storage overhead propose astraea client additional storage augment sample storage accuracy experimental astraea improve percent accuracy imbalanced EMNIST without additional storage requirement improves percent accuracy percent additional storage however emphasize data augmentation strategy model  prone overfitting although storage overhead acceptable allocate overhead client additional storage data augmentation MB KB per client storage increase increase unsatisfactory storage overhead versus model accuracy evaluate imbalanced datasets storage overhead evaluate CINIC astraea improves percent accuracy without additional storage requirement improves percent accuracy percent additional storage particularly average MB per client communication overhead due training client mediator  synchronization astraea traffic communication FL traffic communication calculate parameter hence traffic synchronization experimental astraea actually communication efficient FL astraea improve model convergence framework communication FL achieve accuracy imbalanced EMNIST communication consumption training cnn FL percent accuracy MB whereas astraea merely MB med astraea achieves percent reduction communication communication consumption target accuracy astraea mediator epoch  med versus FedAvg baseline local epoch EE affect communication overhead imbalanced CINIC framework reduce communication consumption percent accuracy percent related previous imbalanced data FL focus non iid data propose FL framework  FedAvg non iid partition EMNIST dataset FedAvg  non iid data however accuracy FedAvg reduces percent cnns highly skewed non iid data propose communication protocol stc compress upstream downstream communication FL FL framework robust non iid data focus global imbalance challenge FL distinguish previous non iid data adopt random distribution local data distribution related astraea recently propose optimization algorithm agnostic federate afl minimize training loss calculate combination client domain afl accuracy standard federate domain however evaluate domain exactly domain baseline afl domain afl generalization motivation afl mainly focus global imbalance challenge furthermore evaluate framework client combine federate meta imbalanced FL propose federate meta framework  treat training client task meta however  suppose customize model improve performance recommendation hence discussion imbalance challenge comprehensive addition conflict  balance framework propose preserve possibility implement meta strategy recently propose image datasets federate training data non iid global  conclusion federate promising distribute machine framework advantage privacy preserve however FL handle imbalanced datasets explore impact imbalanced training data FL percent accuracy loss imbalanced EMNIST global imbalance propose balance FL framework astraea  training perform data augmentation downsampling reschedule client mediator achieve partial equilibrium experimental accuracy improvement astraea percent retrieve percent loss imbalanced EMNIST percent retrieve percent loss imbalanced CINIC versus FedAvg finally overhead astraea communication effective