widespread deployment various compute service orient rapidly increase demand collaborative quality service qos prediction exist qos prediction progress model user service exploit context service invocation however ignore completion service request response relies underlie network topology complex interaction autonomous tackle challenge propose topology aware neural tan model collaborative qos prediction tan model feature user service intermediate node communication project latent input feature jointly characterize invocation feature feature capture respectively explicit model layer implicit model layer gate layer fuse transmits feature prediction layer estimate unknown qos tan flexible framework comprehensively capture invocation context accurate qos prediction experimental datasets demonstrate tan significantly outperforms task response throughput reliability prediction tan extensibility auxiliary information introduction promote popularity application compute app vendor google spotify etc developer publish various service online internet service increase rapidly decade amount virtualized standardize resource software data service user access service via apis internet anywhere application integrate service external component implement functionality feature application series challenge research ensure quality service qos qos described non functional attribute response throughput reliability availability impact overall quality service qos technical concern business concern application vendor perspective important role gain competitive advantage industrial iot amazon estimate increase latency profit user perspective qos important differentiate service performance application relies quality internal external component standalone application particularly challenge ensure performance application remote service external component service manage internal component external component quality undermine performance application scenario halt crash application integrate quality service ensure performance application however online service impossible developer inspect evaluate candidate service implement functionality application programmableweb service portal already service category quality service evaluation approach developer appropriate service recent collaborative qos prediction intensively aim predict user historical service memory model qos prediction approach combination various spatial temporal context service invocation explore propose qos specific user service predict user service progress model user service explore contextual information service invocation however exist qos prediction approach properly internet topology impact user quality service knowledge qos response throughput availability reliability closely related internet topology significantly user user dynamic network user request service service request correspond response internet difference qos spearman correlation coefficient response correspond shortest estimate dataset WS described conclusion angle besides user likely service availability correlate network topology link user service congest service becomes unavailable user likely access service intuitively depicts role service invocation node autonomous user service connection internet user request service response communication source node passing sequence intermediate autonomous node target node feature workload delay etc directly impact message communication impact user qos particularly integrate communication prediction model reduce error user differentiate service invocation topology internet mesh autonomous arrow invocation user service consideration network topology complicates qos prediction significantly prediction technique beyond collaborative filter properly leverage information hidden sophisticated user service invocation recent neural network neural network successfully apply task rating prediction click rate prediction neural network model effectively extract feature multi representation multiple hidden layer stack amplify input feature significant impact prediction suppress irrelevant feature besides nonlinear model ability neural network model approximate complex function construct highly accurate prediction model complex task recent exploratory collaborative qos prediction neural network approach propose demonstrate superior ability neural network model user service interaction however approach simply conventional qos prediction approach model feature user service feature application built user around globe assurance performance accurate qos prediction user tackle challenge proposes topology aware neural tan model highly accurate qos prediction service invocation tan impact user service communication consideration worth communication rout algorithm refers network minimum distance metric service invocation mechanism shortest achieve tan approximates shortest dijkstra algorithm tan obtains sequence node node inclusive input feature model layer tan employ directional memory capture backward dependence merge feature node vector representation explicit model service invocation model layer complex interaction user service capture convolution neural network implicit model gate mechanism utilized fuse feature finally qos prediction stack fully layer gate layer historical qos data service invocation tan qos prediction active user target service network topology contribution knowledge attempt consideration network topology qos prediction propose specifically neural network model tan highly accurate topology aware qos prediction tan potential information tan combine implicit feature explicit feature gate mechanism innovatively characterize service invocation conduct widely dataset demonstrate superior performance approach http github com whale  tan remainder review related discus principle tan illustrates parameter optimization tan experimental finally concludes related introduce collaborative filter qos prediction memory model context aware memory memory predict qos similarity user service categorize user item combination propose user qos prediction approach series focus improve accuracy similarity computation calculate qos cosine similarity similarity service fluctuation similarity growth invocation compute user similarity  model avoid inaccurate similarity ratio difference perspective similarity  threshold adjust similarity besides personalize framework qos rank prediction user usage advantage memory simplicity interpretability however selection similarity measurement obviously affect accuracy qos prediction importantly performance dramatically data sparse estimate similarity capture potential data model model matrix factorization factorization machine neural network model demonstrate ability achieve accuracy data sparsity matrix factorization approach refer algorithm user item matrix factorize latent feature matrix non negative latent factor model propose efficient qos predictor principle alternate direction matrix factorization enables model training representation user service propose adaptive matrix factorization online adaptive technique qos prediction develop hierarchical matrix factorization model performs factorization cluster local user service matrix factorization machine FM machine algorithm incorporate feature interaction attentional FM learns importance feature interaction propose neural FM adopt non linear interaction instead linear interaction FM introduce user ID service ID construct embed vector apply FM predict qos incorporate location service classic FM propose model user service location FM factorization implicit feature data overcome defect memory however considers linear feature interaction nonlinear feature entail data ignore limit representation researcher employ neural network qos prediction introduce nonlinear model ability propose universal neural model qos prediction multi attribute contextual feature propose universal spatio temporal context aware collaborative neural model qos prediction invocation multiple spatial feature service user apart introduce dynamic bayesian network qos prediction update qos series propose utilize memory lstm qos prediction neural model ability model feature selection introduce parameter calculation requirement fortunately utilization context information associate service invocation alleviate contradiction context contextual information leveraged improve accuracy qos prediction location account user longitude latitude identify besides incorporate user location bayesian inference cluster user service location extend factorization machine approach leverage location information strategy neighborhood selection propose identify distance user incorporate user service location employ preference propagation compute similarity adopt density peak algorithm identify hidden user cluster implement prediction model incorporate achieve cluster propose integrate matrix factorization network network distance user neighborhood user identify enhance prediction model qos fluctuate invocation incorporate temporal factor qos prediction similarity service specific interval approximate average similarity qos volatile propose auto regressive integrate average ARIMA model handle volatile qos latent factor specific context propose context aware model propose latent factorization tensor qos predictor precisely temporal information hidden dynamic qos data besides contextual factor qos prediction argue physical environment service related quality cluster service assumption difference affect qos divergence incorporate affiliation qos prediction propose matrix factorization model rely configuration host service status internet user service although various contextual information employ verify effective however lack depth model network topology communication develop neural prediction model feature explore topology aware neural model highly accurate qos prediction workflow tan illustrate network topology user service rout algorithm optimal comprise sequence intermediate node message communication feature user service intermediate node categorical variable input feature however bag node feature cannot sufficiently interdependence node therefore explicit model layer capture backward interdependence node encode entire feature vector implicit model layer introduce extract feature user service characterize service invocation aspect interaction following gate layer prediction layer fuse feature achieve qos prediction summarizes notation notation architecture tan model contains component input layer implicit model layer explicit model layer gate layer prediction layer input layer service invocation refers interaction user service request response entire message communication computer network topology structure autonomous attach delivery service request response network depends complex interaction autonomous exchange rout information rout protocol rout protocol decides message source destination optimal usually refers shortest distance load topology ass simplicity information lack link network load shortest distance rout adopt approximate optimal network congestion assume service invocation occurs user service dijkstra algorithm utilized communication shortest distance obtain communication network partition autonomous service request IP address IP address source data packet specific border router autonomous border router optimal destination apply topology network obtain finally border router data packet accord rout algorithm obtain communication forth feature associate service invocation correspond dense vector input tan formally denote latent feature user service autonomous project dimensionality latent feature vector implementation tan feature vector user service ass directly fetch identifier interface library embed lookup tensorflow implicit model layer input layer obtain latent feature associate service invocation feature effectively careful planning collaborative qos prediction successful service invocation abstract feature interaction user service construct model useful affect quality service discover data neighborhood usually qos user service context fully exploit therefore construct model layer model interaction user service capture association qos data technique mostly model interaction user service inner latent feature vector however inner considers linear correlation capture feature dimension non linearity dimension ignore deficient construction feature user service overcome limitation employ outer fully feature interaction dimension convolution neural network cnn extract non linear feature employ outer generate interaction capture dimensional correlation sufficiently matrix generate outer vector define  mechanism capture interaction user service redundancy feature risk overfitting involve parameter employ convolution neural network cnn interaction address issue extract hidden feature cnn module convolution layer convolution kernel convolution kernel extract latent feature input matrix convolution layer input matrix layer matrix mlc identifier layer input matrix user service interaction output layer input layer  denote ith convolution kernel layer feature extract ith convolution kernel layer described  relu  mlc blc sourcewhere mlc input matrix fed layer operation convolution blc bias output matrix layer input matrix layer mlc   sourcewhere  ith feature layer establishment extraction feature mention highlight outer operation obtain interaction input interaction layer kernel stride obtain feature output layer input layer convolutional operation forth finally vector generate feature apply subsequent express mention transformation conveniently rewrite cnn cnn parameterized function encode interaction indicates parameter cnn module outer dimension feature user service feature extraction convolution neural network explicit model layer model layer model interaction user service extract feature impact qos impact feature capture extent user service implies existence however role limited information model layer feature explicitly input layer obtain feature node however isolated node cannot precisely characterize mutual influence model vector aggregate capture node interdependence achieve introduce component bidirectional memory tan memory lstm unique recurrent neural network vanish gradient consists component input gate output gate forget gate memory gate intend information structure input corresponds lstm depicts internal structure lstm correspond node detail formally component lstm define  sigmoid   sigmoid   tanh   sigmoid   tanh SourceRight click MathML additional feature sigmoid tanh denotes sigmoid hyperbolic activation function respectively wise denote matrix denote bias vector input gate forget gate output gate activation vector hidden respectively architecture memory recurrent neural network architecture memory recurrent neural network sequence node input node corresponds lstm define cycle processing hidden lstm eventual sequence feature interdependence node consideration formally function lstm intuitively communication involves backward context directional lstm capture bidirectional dependency sequence formally lstm utilizes lstm capture context utilizes backward lstm capture backward context output concatenate completely communication gate layer model model obtain feature representation characterize interaction communication respectively inspire adaptive gate highway network employ gate mechanism combine feature fuse feature calculate  sigmoid   sourcewhere gate assign factor dimension vector possibility feature feature dynamically sigmoid function ensures output matrix linear transformation respectively combine feature interaction communication tan already accurate qos prediction prediction layer purpose prediction layer filter fuse feature realize numerical prediction latent feature input fully layer prediction  relu  relu WL  sourcewhere denote matrix bias vector lth hidden layer relu activation function activation layer prediction tan totally sub layer exploit information beyond topological feature feature user feature service dependent feature significant impact qos therefore identify feature exploit enhance prediction performance tan average response throughput user service quantitative qos historical data regard qos attribute user service prediction drift operation message data identify metadata service characteristic complexity service involve service execution information integrate tan information feasible firstly information quantify RT  fully connection layer without activation employ generate linear transformation finally integrate tan another gate layer sigmoid  sourcewhere concatenation operator parameter data specially introduce potential qos bias towards user service simplicity model tan model estimate tan model parameter adopt loss function absolute deviation error loss function sensitive outlier training data loss function attempt outlier expense additional sample denote qos predict qos input objective function tan loss minθ source contrast objective function loss minθ sourcewhere regularization balance factor employ avoid overfitting parameter model gradient descent initial parameter update iteratively minimize objective function convergence iteration update negative direction gradient respect training instance loss objective function  sourcewhere rate gradient descent loss objective function sourcefor layer neural network model parameter update propagation algorithm computes gradient chain tan employ adam performs gradient optimization combination mini batch gradient descent accelerate training conduct extensive datasets demonstrate advantage tan approach necessity component tan series ablation finally analyse impact model parameter efficiency datasets evaluate tan qos prediction performance research focus response throughput prediction extend reliability prediction WS datasets publish dataset contains web service invocation user web service  platform qos attribute dataset response throughput contains metadata service afterwards extend associate user autonomous geographical coordinate link service autonomous service provider capture topology information ipv link dataset internet autonomous apply internet data analysis distribute dataset contains service invocation web service user evaluation prediction reliability user service reliability estimate successful response service enrich dataset contextual information available service metadata dataset refine extend datasets user service obtain autonomous belongs correspond topology autonomous conform item cannot topology remove invocation user service service invocation retain dataset remain user service reliability dataset global topology consists autonomous shortest user service link statistic datasets illustrate user service dataset latitude longitude statistic datasets distribution user service qos attribute response throughput reliability qos data normalize attribute normalization lose semantics specific characteristic qos data neural model fitting qos data without data transformation forecasting qos attribute evaluation metric absolute error mae error RMSE normalize absolute error  qos prediction accuracy evaluation metric desirable mae define mae SourceRight click MathML additional feature RMSE define RMSE  define   ymin sourcewhere qos predict input respectively ymax ymin maximum qos minimum qos dataset respectively evaluation tan approach belong category neighborhood CF factorization approach neural network approach  user collaborative model  item collaborative model  combine user item collaborative prediction approach PMF matrix factorization approach collaborative qos prediction CSMF matrix factorization approach model interaction user service environment environment FM combine generality feature engineering superiority factorization model estimate interaction categorical variable employ context aware qos prediction  AFM extension FM learns importance feature interaction data neural attention network NFM extension FM seamlessly combine feature non linearity feature interaction strategy employ develop neural model qos prediction tan tan model loss function adopt tan tan model loss function adopt loss function adopt MF FM model    PMF leverage information user service qos matrix information contrary feature user service user user autonomous service service IPs leveraged CSMF FM AFM NFM implement python particularly factorization neural network built tensorflow conduct computer configure intel quad core processor 2GB memory ubuntu gpu nvidia gtx parameter setting impact data sparsity randomly split qos dataset matrix training specific ratio MD instance MD matrix density randomly percent qos entry predict remain percent qos entry experimental fold average report neighborhood CF approach    pcc similarity employ selection neighbour user service neighborhood user service MF approach regularization parameter accord FM approach parameter setting source code tan approach regularization sub layer prediction layer fix neuron sub layer  parameter optimizer besides PMF CSMF FM AFM NFM tan tan tan configuration training maximum iteration fix mini batch strategy prediction iterative performance comparison firstly conduct performance comparison task response throughput prediction neighborhood  outperforms   performance somewhere consistent intuition qos evaluation user accurate service PMF CSMF CSMF achieves accuracy PMF RMSE CSMF leverage contextual information model interaction user service environment environment simultaneously neighborhood PMF CSMF outperform neighborhood particularly data sparse confirms effectiveness matrix factorization sparse data performance comparison qos prediction  throughput reliability matrix density factorization machine FM poorly although feature feature fully FM additional feature selection ability efficiency task qos prediction AFM importance feature interaction data attention mechanism obtains prediction error FM NFM capture non linear complex inherent structure data brings significant improvement FM AFM regard tan optimize loss objective function tan superior baseline mae RMSE  response prediction outperforms approach PMF CSMF throughput prediction however tan unable compete tan loss objective function specially adopt qos prediction obviously loss robust loss impact outlier exist qos data tan  model task task response prediction tan improves baseline average mae metric  RMSE gain respectively task throughput prediction gain approximately mae  RMSE respectively besides increase training sample tan yield mae tan decrease MD trend reflect metric tan concerned exploit information naturally improve prediction accuracy tan mae RMSE  gain task response prediction task throughput prediction tan fusion tan information tan potential expansion cooperate powerful prediction model finally focus reliability prediction owe lack sufficient information service metadata dataset tan reliability significantly depends communication tan perform superior baseline model contrary baseline model satisfactory reliability prediction without exploration exploitation feature volume reliability dataset memory prediction model topology aware qos prediction model application scenario ablation tan combine explicit feature implicit feature explore impact component remove tan manner besides demonstrate effectiveness cnn replace outer cnn traditional inner implicit layer impact interaction evaluate impact explicit model layer implicit model layer tan model without explicit model layer gate layer remove tan capture user service feature qos prediction similarly remove feature feature tan model finally tan tan model tan prediction analyze impact component significant difference mae tan tan response prediction tan mae tan throughput prediction task remove feature performance degradation tan however reduction tan prediction accuracy tan decay prediction task respectively prediction performance mae tan tan tan tan feature performs tan model explicit model interaction extract partial information data sufficient complexity message communication contrast explicit model effectively address issue tolerable prediction accuracy tan certainly precision prediction explicit feature association qos data neighborhood importance demonstrate previous collaborative filter capture interaction model advantage neighborhood complementary relationship explicit model comparison inner outer model concern model user service combination outer convolution neural network adopt verify significance inner operation replace model layer interactive model introduces degrade version tan refer tan accord tan significantly diminish mae tan response throughput prediction correspond decrease outer combination cnn advantageous inner model feature interaction user service due interaction dimension capture inner outer combination variety convolution kernel construct nonlinear interaction combine feature dimension allows tan model capacity capture useful feature contributes prediction accuracy prediction performance mae tan tan parameter analysis analyze impact dimensionality latent feature configuration prediction layer impact tan prediction accuracy tan omit extension tan impact dimensionality input layer dimensionality latent factor utilized user service ass latent user service ass vector vector randomly initialize optimize model training tan prediction accuracy combination MD prediction performance tan dimensionality matrix density RT response TP throughput dimensionality fix tan prediction error regardless RMSE mae  gradually decrease trend increase training data density data density constant trend direction dimensionality increase response prediction task data density relatively increase dimensionality prediction accuracy however dimensionality increase prediction error increase sparse data MD evaluation metric minimum dimension improve dimensionality prediction accuracy similarly evaluation metric tendency decrease increase data density optimum dimension task throughput prediction observation coincide intuition relatively dimension prediction parameter flood tan without sufficient training sample redundancy latent feature inevitably fitting  subtle fluctuation training data medium dimension suitable sparse data impact prediction layer accord sub layer prediction layer structure sub layer neuron impact qos prediction mae configuration format sub layer neuron sub layer doubt training data greatly improve tan prediction accuracy however due data sparsity increase sub layer conducive error reduction relatively neuron configuration layer neuron reduce prediction error however profit bound layer extra neuron risk fitting sub layer neuron sub layer twice optimal neuron gate layer dimension output vector directional lstm observation simplify hyper parameter tan neuron multiple hidden layer directional lstm dimensionality input layer prediction performance mae tan configuration prediction layer analysis efficiency    historical qos data data sparse model mainly reflect model parameter denote user service autonomous contextual feature connection layer convolution kernel complexity prediction model factorization approach PMF overhead CSMF FM AFM NFM complexity user service contextual feature UR  SR sas observation tan complexity factorization complexity prediction model computational efficiency similarity calculation perform    inevitably efficiency omit simplicity model computational efficiency mainly depends dimensionality latent feature training sample MD batch model training strategy optimization algorithm rate epoch configuration MD batch respectively comparison training overhead prediction overhead obviously tan inefficient PMF CSMF FM AFM NFM training prediction model introduction cnn lstm complexity tan tan parameter factorization however tan competitive prediction efficiency predict nearly qos within increase batch dimensionality improve computational efficiency tan lose prediction accuracy training overhead prediction overhead computational overhead tan batch computational overhead tan dimensionality discussion tan analysis tan challenge briefly summarize discus issue foremost challenge dynamic qos tan tan task static qos prediction quality service deployed mostly stable fluctuate  moreover user perspective qos aware web service selection focus average qos qos specific qos prediction tan extend account temporal factor specifically qos reasonable slot characterize vector combine tan verify effective tan training efficiency model regularly demand accommodate qos variation moreover static shortest replace optimal due dynamic network rout however shortest actual automatically identify dynamic data massive rout trace qos user service emerge representation untrained seriously affect prediction accuracy prevent qos prediction countermeasure approximation strategy tune prediction model transfer conclusion future propose tan qos prediction attempt representation internet topology qos prediction construct feature model service request response comprehensively experimental demonstrate tan superiority extensibility qos prediction direction expand tan worth explore transfer cooperate realize dynamic discovery qos prediction research direction immense potential