programmable gate array fpga device integration environment enable compute resource compute requirement fpga multiple task resource typically involves partition fpga fix slot suboptimal resource utilisation relatively performance particularly task increase OpenCL exploration capability employ clever cluster custom task specific partition mapping novel methodology task resource requirement effectively manage model resource throughput profile appropriate distribution runtime workload enhance temporal compute density approach enable stack correspond task virtualisation model performance task graph analysis linear algebra medium demonstrate average throughput efficiency exist approach introduction compute service data centre achieve return compute efficient temporal spatial resource amongst multiple task recent enhance performance computationally demand task encourage service provider amazon integrate programmable gate array FPGAs data centre whilst FPGAs acceleration performance compute hpc typically restrict application configuration sac effective resource management multi task execution remains challenge significance particularly migration service fog stricter resource utilisation constraint conventional software programmable typically discrete processing core abstract software thread offering microsecond latency context switch task highly flexible resource management task schedule model optimisation apply FPGAs however complicate mapping source code spatially device physical resource typically framework partial reconfigurable PRRs fpga partition fix rectangular slot spatial mapping constraint FPGAs PRRs largely homogeneous hpc task however inherently heterogeneous resource memory compute bandwidth runtime workload throughput mapping independent hpc task custom hardware onto prr typically mismatch compute density  fpga resource percent custom task specific partition mapping cpm vendor generate bitstream multiple task acceleration function execution diverse compute requirement workload dynamic task queue resource management task schedule NP addition fpga synthesis effective approach enable runtime model offload appropriate onto fpga optimise overall performance define throughput stp metric effective performance multi task workload processing stack FPGAs resource optimum execution dynamic workload task implementation optimisation execution framework propose tackle challenge OpenCL exploration capability generate explore machine custom generate compute density runtime scalable accelerator function effective manner runtime variable workload requirement eventually stp heterogeneous task contribution comprehensive runtime evaluation analysis spatial temporal constraint various mapping scheme allows selection optimal operating objective hint towards optimisation multi task execution via functional emulation machine characterisation throughput rate task cluster task custom mapping execution fashion achieve spatial compute density multi task exploration DSE preemptive schedule enable effective runtime resource allocation execute task achieve temporal density realisation task virtualised resource allocation model task specific model hpc graph analysis linear algebra medium data mining average stp improvement efficiency achieve prr organise discus motivation background describes propose framework whilst detail evaluation environment analysis conclusion background fpga compute FPGAs integration data centre seamless efficient access fpga resource software environment author treat fpga independent resource develop communication stack associate hardware FPGAs directly communicate CPUs FPGAs cluster middleware application centric interface developer hardware development integration various vendor enable portability productivity author developed compilation framework communication interface runtime library resource sub fpga multi FPGAs per task requirement similarly modular approach stack component portability integrate version hardware software layer fpga reconfigurable resource furthermore fpga programmable source dynamic environment researcher investigate various reconfiguration task mapping scheme temporal reconfiguration fpga task sac software programmable core task researcher transparent access multiple FPGAs fpga processing task addition increase device research explore mostly via prr finally author combine homogeneous prr interconnection resource task across FPGAs transparently fpga constraint target task benefit fpga traditionally achieve via PRRs mimic discrete compute resource multi core software programmable independence independence suggests task prr slot independently reconfigured task without affect processing prr slot enable easy schedule decision task priority however flexibility resource per task achieve resource mapping density suffers domain program mapping fpga fabric via PRRs challenge distribution heterogeneous resource tile fpga  particularly along horizontal axis furthermore fpga multiple across vertical horizontal boundary custom logic cannot runtime bitstream relocation scheme limit relocation homogeneous along axis height prr independent task fpga partition prr mapping constraint restrict PRRs homogeneously  resource omission static interconnects homogeneous along axis percent fpga data workload comprise heterogeneous task resource requirement within boundary prr actual allocate heterogeneous task namely overall utilisation available resource throughput reduction task execute finally due rout constraint surround fix prr slot frequency optimisation research explore optimisation resource utilisation prr maximise throughput author variable slot compute intensive task memory intensive task allows prr slot reconfigurable task mapping option author reduce fragmentation within PRRs optimise schedule policy compact placement minimum conflict task variable PRRs research reduce reconfiguration overhead associate prr usage prefetching task bitstream schedule task load bitstream author enable runtime elastic resource allocation per task adjacent prr slot available whereas propose slot built homogeneous task allocate runtime heterogeneous slot however approach improve prr setup largely homogeneous prr slot heterogeneous task non optimal resource utilisation infrastructure recent allows creation  subspace fpga partially independently reconfigured latency mode whilst multiple subspace combine custom mapped throughput mode gain throughput increase resource utilisation generate combine bitstreams particularly schedule task variable resource requirement however target operating OS transparently transfer mode throughput mode briefly suggests parallel creation bitstreams task  route acceleration technique hide bitstream generation latency however propose usage scheduler non optimal mapping frequent switch runtime contrast systematically explore offline aim generate density throughput execution furthermore incorporate throughput schedule resource allocation increase usage throughput mode finally thorough evaluation mode enable inform decision mode per operating environment philosophy data compute environment processing request regular interval difference execution model prr propose cpm framework illustrate respectively prr approach generates  treat incoming task request independently manager manages incoming task queue via virtualisation layer abstract underlie hardware implementation user request virtualisation layer caters communicates resource manager manages multiple load bitstream execution prr cpm runtime approach focus improve resource utilisation remove task predefined partial improve execution overall task efficient  fpga accelerator compute density task aim integrate bitstreams execution multiple task employ dynamic reconfiguration load multi task bitstream onto fpga lightweight scheduler virtualisation layer link task processing request correspond optimum bitstream multi task DSE pre  schedule technique enable intelligent schedule scheduler task queue batch reorder processing cluster gain throughput cpm priority comparison approach epoch execution task evaluate prioritise throughput task furthermore task implementation runtime OpenCL framework OpenCL recognise establish integration software heterogeneous data centre propose approach fpga version compute model software service SaaS optimise bitstreams standard compute task library amazon marketplace amazon fpga image afi user request functional acceleration service variable workload optimisation complement data workload characterisation previously comparative evaluation partition scheme accuracy analysis runtime evaluation spatial mapping optimisation via cluster introduces framework implementation novel component temporal optimisation integration virtualisation model building module stack analysis deployment dynamic heterogeneous hpc task methodology compute density mapping core framework enable task specific execution model explain heterogeneous hpc task execute OpenCL compute model functionality thereby parallelism granularity define synthesis parameter explore dynamic hardware profile ensure generate optimum speedup per resource utilisation eventual multiple hardware generate dataset specify throughput achieve resource utilised task compute density mapping methodology comprehensive multi task runtime evaluation task DSE gauge performance various partition scheme dynamic workload various parameter performance analysis although cpm spatial compute density prr sac perform dynamic workload temporal utilisation address characterisation task task DSE along machine regression model evaluate relationship chip heterogeneous resource fpga throughput characterisation task cluster task cluster complement others resource execute fpga furthermore minimise reconfiguration overhead multi task bitstream replace task execute reduce stall task resource allocation per task varied multi task cluster per runtime workload execute task enable module generates per cluster multi task DSE trading resource allocation throughput cluster task permit variation execution texec task processing respective workload generate multi task custom mapped fpga generate bitstreams multiple task accelerator function generate bitstreams per cluster profile hardware throughput metric define per correspond workload task cluster compute density mapping enable throughput hardware stack exploration DSE enables exploration optimisation strategy throughput rate benefit approach task allocate resource profit memory compute DSE enable OpenCL capability explicit description parallel compute hardware resource via multiple parameter task kernel multiple compute CUs implement coarse grain parallelism described span item multiple pipeline define via instruction multiple data simd pragma kernel implement item task task specific parameter define parallelism define parameter task unroll pragma unroll compute intensive kernel identify dynamic profile active counter counter cod VHDL OpenCL kernel software library via intel OpenCL library feature eventually parameter throughput per runtime evaluation comprehensive multi task runtime functional emulation allows stage comparison enables multi task DSE task DSE combine analytical model significantly cluster resource allocation per task runtime evaluation methodology placement prr 2D model treat mapping rectangle fitting aim homogeneous spatial distribution resource incoming task cpm implement multi dimensional model accommodate dimension heterogeneous chip resource logic random access memory bram digital signal processing DSPs mapping optimisation accommodate task whilst utilisation resource within device limit prr task configuration treat independently cpm configuration task selects multi task configuration memory model allocate chip resource multi task environment task achieve throughput identical due memory contention model predict memory performance multi task processing employ ridge regression generate multi task bitstreams actual performance model accuracy DSE resource management evaluate various resource management strategy cpm multi task DSE estimate throughput resource allocation per task cluster prr implement optimisation target segmentation vacant fpga runtime homogeneous PRRs important prr fairly cpm adjacent prr attempt bitstream task combine gain speedup target partition fpga heterogeneous PRRs resource increase mapping flexibility task custom PRRs heterogeneous PRRs define ratio heterogeneous resource however scenario device benefit approach heterogeneous PRRs define resource relative ratio remain optimisation heterogeneous PRRs bitstream task none bitstreams accommodate finally varies vertical continuous axis bitstream relocation although exhaustive achieve generate multiple bitstreams within coordinate configuration bitstreams parameter coordinate bound heterogeneous resource usage DSE evaluation user specify deviation texec task uniform distribution random task generation input parameter varies distribution texec constraint prr homogeneous heterogeneous fix coordinate user cpm available heterogeneous resource realistic percentage maximum utilisation input various prr constraint available task mapping bitstream relocation varied compute density bitstream generation optimise throughput achieve denser mapping fpga resource various module characterisation cluster spatial optimisation along cluster inform runtime decision enable heterogeneous resource allocation per task characterisation DSE task bitstream perform regression model contribution resource towards throughput allows benefit approach task profit allocation resource cluster task profit resource chip bram DSPs logic chip bandwidth fpga resource whilst ordinary commonly linear regression highly sensitive random error variable correlate dsp link bram ridge regression avoids normalise chip heterogeneous resource maximum available bitstreams per task independent variable regression achieve throughput actual hardware normalise maximum achievable task becomes dependent variable regression significance resource task throughput addition normalise bandwidth utilisation task bitstream cluster task bandwidth unlike chip resource become bottleneck DSE extremely memory intensive task ridge regression model consistent bandwidth usage hide task bandwidth dependence define cluster task multi dimensional dimension regression resource normalise bandwidth combination cluster global optimisation custom optimisation function reduce complexity validity iteration iteration randomly selects task cluster task maximum distance heterogeneity multi dimensional task cluster define manually designer device sum mutual distance task cluster sum cluster defines iteration iteration chosen resource variation per task although cpm allows spatial compute density cluster task reconfigured integrate bitstream task stall task unless reconfigured expense reconfiguration overhead resource utilisation task suboptimal counter multiple bitstreams per cluster chip resource multi task DSE enable runtime evaluation parameter cluster avoid contention resource task allocate resource throughput rate processing respective workload integrate  generation prr limited pre define reconfigurable runtime bitstream relocation limit optimisation via cluster chip memory bandwidth however cpm benefit optimisation chip resource usage custom fpga mapping resource allocation task per heterogeneity generate bitstream offering multiple task acceleration function bitstream generate OpenCL hdl module placement script modify constraint file task module correspond prr cpm mapped available task logic finally integrate bitstream generate route integrate OpenCL custom mapping optimisation vendor route cpm multiple module prr cpm module partially reconfigured independently static logic hardware profile configuration profile execute task cluster calculate throughput bitstream task workload specific metric described workload specific metric encompass compute memory instruction performance characteristic fpga bitstream generation task significant offline bitstream generation initial task generate upcoming task runtime manager decides update cluster associate bitstreams achieve parallel task execution update furthermore scope frequency cluster optimisation limited reduce simulator faster pre analysis runtime scheduler runtime lightweight overhead task execution negligible incoming heterogeneous task queue variable workload runtime scheduler preemptive schedule throughput various multi task bitstreams selects minimises difference task texec meanwhile checkpoint evaluation schedule decision context switch eventually reduces stall task improves temporal resource utilisation compute density mapping achieve overall throughput runtime scheduler bitstream selection per workload algorithm pseudo code runtime selection optimum bitstream unscheduled task nextTask task queue algorithm task cluster nextTask schedule task bitstream nextTask otherwise iterates multiple bitstreams cluster bitstream minimises difference texec calculate data throughput task cluster respective workload optimum bitstream correspond task schedule estimate estimate texec ith bitstream task bracket max sum texec task sac algorithm runtime generate schedule associate bitstreams dynamic task queue TQ TQ empty nextTask TQ  cluster  nextTask  cluster nextTask  TQ unfinished nextTask  nextTask nextTask nextTask  max  cluster temp  estimate nextTask estimate      nextTask bitstreams nextTask nextTask  preemptive estimation selects bitstream estimate difference texec task cluster amongst bitstreams cycle accurate estimation allowable difference texec task throughput owe intelligent cluster cpm task resource allocation cluster runtime lightweight schedule decision evaluate bitstream selection perform context switch discrete checkpoint although checkpoint implement finer granularity OpenCL reconfiguration host accelerator communication overhead offset acceleration gain instead checkpoint implement namely independent workload batch computation load fpga output host batch workload specific generate via workload distribution software OpenCL workload iterate workload due limited dram runtime workload scheduler preemptive estimation texec respective estimate texec workload however checkpoint execution bitstream selection schedule decision evaluate variation resource allocation per task scheduler evaluates equation switch bitstream  WS TH SourceRight click MathML additional feature TH reconfiguration throughput bitstream respectively WS remain workload scheduler  configuration chooses improve recent domain propose mechanism context migration reconfiguration device device OpenCL task already data virtualisation revenue model conventional prr approach target infrastructure service IaaS per task prr slot correspond resource discrete core distribution resource multi processor resource incurs fpga task functional acceleration stack target SaaS model employ functionality user service associate throughput amazon model  pre synthesise bitstreams fpga functionality hiding implementation detail user cpm model extend multi task execution throughput facilitate revenue enable task model  virtualisation framework  reduces effort application developer deploy fpga acceleration data centre handle communication application underlie accelerator register task functionality accessible via easy interface hiding underlie hardware implementation detail essentially expose fpga virtual accelerator  available application task software api underlie library manage task queue data buffer decouple software controller hardware api communicates underlie fpga vendor runtime manages bitstream load host accelerator data transfer associate  modify various layer incorporate  cpm multi task processing application multiple task cluster integrate associate   unique cluster definition manages execution independent task cluster furthermore  access multiple bitstreams bitstream throughput task cluster via associate parameter scheduler optimum bitstream runtime software controller finally implement interface driver hardware api integration intel FPGAs environment hpc task belonging various application domain compute  sparse dense linear algebra graph analytics structure grid compute dynamic program identify parameter task DSE OpenCL implementation parameter evaluate maximum throughput per resource usage hardware profile identify characteristic identify profile project task characterisation actual hardware verify selection task comprehensive evaluation DSE along workload specific metric task throughput calculation summarise fpga host platform runtime evaluation python DSE perform via intel OpenCL sdk FPGAs constrain placement achieve  prime hardware profile perform  target fpga sensor accessible via memory mapped device layer whilst bandwidth intel fpga dynamic profiler OpenCL gui OpenCL runtime independent command queue task parallel execution within command queue non issue memory transfer multiple kernel task runtime execute host comprise intel xeon chip ghz throughput metric assess performance multi task workload parallel processing challenge absolute individual task throughput indication performance contribution absolute processing speedup influence task workload generic metric FLOPS etc meaningful task evaluate metric emulate hardware realistic comprehensive assessment emulation task queue comprise task potential estimate speedup execution workload task queue various partition scheme sac evaluate compute density various approach multi task environment stp metric define stp   source NP task normalise progress define cycle task mode  task resource fpga available multi task mode  task defines task fpga metric encompasses various parameter throughput variation resource allocation per task compute density variation resource utilisation performance stp watt efficiency various partition scheme throughput relative baseline sac stp analysis scope DSE explore emulate analysis cluster runtime performance variation parameter whilst target performance discus virtualisation model cpm exploration DSE variation throughput resource utilisation evaluation comparison mapping scheme parameter achieve speedup summarise speedup baseline texec correspond bitstream define serial pipelined benchmark implementation task maximum throughput define bitstream limited fpga resource generate per task throughput curve maximum speedup task prr versus cpm evaluation project runtime gain cpm sac various prr strategy allows variation parameter task constraint affect cpm throughput particularly due independence prr sac iteratively apply constraint distinguish highlight heterogeneous task workload maximum theoretical gain cpm maximum theoretical speedup achieve cpm various prr mapping namely continuous axis heterogeneous PRRs homogeneous PRRs analyse runtime evaluation ideal scenario cpm task execution fpga configure homogeneous heterogeneous PRRs namely define generate bitstreams cpm prr maintain homogeneity partial cpm cpm available task logic placement static module cpm cpm cpm cpm appropriate parameter placement constraint realisation due utilisation cpm bitstream generation slightly reconfiguration overhead analysis differentiate speedup achieve heterogeneous mapping gain availability extra logic mapping custom fashion ideal environment cpm achieve throughput prr execution task queue gain speedup achieve via heterogeneous custom mapping whilst achieve exploit resource availability axis continuous throughput gain achieve heterogeneous PRRs improve performance various optimisation mention speedup achieve cpm versus prr mapping texec variation speedup report considers ideal scenario cpm texec task fpga however dynamic environment relative texec task varied reconfiguration execute task processing analysis speedup speedup baseline sac partition scheme depict surprising trend particularly cpm versus prr increase texec beyond reconfiguration overhead become negligible task speedup cpm decrease remains prr average device task cpm constrain fpga chip task stall task maximum percent resource average stall task overcome average compute density gain task sac cpm trend however speedup texec whilst prr maintains average speedup speedup variation variation execution task reconfiguration overhead analysis reconfiguration overhead significant task execute workload dynamic environment furthermore reconfiguration overhead directly related mapped throughput increase resource prr cpm sac gain offset reconfiguration overhead evaluate reconfiguration overhead texec task queue texec task reconfiguration scheme proportional reconfigured evaluate offset reconfiguration overhead texec generally increase linearly increase texec task however reconfiguration overhead significant role towards performance task texec throughput significant task execution reconfiguration overhead task individual execution task scenario task texec approach mention earlier ideal scenario cpm however throughput associate prr overall performance owe reconfiguration overhead throughput prr becomes significant factor towards texec increase task prr becomes perform task per task benefit increase texec without reconfiguration overhead cpm perform sac however resource per task reconfiguration overhead cpm sac cpm overall performance texec overhead offset performance loss due throughput cpm perform sac although focus identify cpm throughput optimise dynamic environment detailed comparison various constraint highlight analysis various scheme operating environment analysis enable switch mapping scheme runtime per variation task dynamic propose cpm although allows model resource sub device degradation performance sac optimisation analysis apart  resource task variable texec runtime spatial utilisation heterogeneous task limited percent average logic bram DSPs respectively compute density mapping analyse gain propose approach density mapping establish baseline throughput analyse various optimisation baseline throughput cpm prr device whilst constraint available prr limit cluster task cpm task accommodate however practicality comparison task per cluster cpm DSE bitstreams per task within constraint prr cpm generate random cluster task prr cpm baseline evaluation stp data task cluster chosen task texec cpm average stp average throughput prr stp basis compute density consume although gain cpm efficiency stp average prr stp stp cpm prr  cluster optimise cluster cluster improve throughput due cluster briefly contribution resource towards task throughput DSE ridge regression basis cluster bias constant model linear equation relates baseline throughput cluster algorithm model optimum cluster ridge regression model hpc task gain prr cpm texec task cluster prr stp increase mostly due optimisation chip memory bandwidth utilisation cpm stp increase corresponds chip resource optimisation gain throughput stp efficiency stp cpm prr respectively maximum achievable via propose optimisation exist scheme stp gain sac achieve texec variation custom data ensure texec execute task static configuration task however dynamic task queue limitation cpm execution stall task unless scheduler decides reconfigure fpga texec task varied relative  difference texec task cluster multiple stp variation cpm variation texec task cluster sample cluster cluster texec   increase task label longer execute task individual stp task average stp cpm sharply stabilises however variation texec individual contribution task stp increase texec variation stp increasingly define task becomes independent variation texec furthermore individual stp contribution task improves increase texec variation chip memory bandwidth factor reduce variation texec significant stp runtime counter stp variation texec framework generates bitstreams per cluster bitstream trading resource task evaluate queue randomly generate task workload involve workload per task variable workload per task min workload processing google cluster bitstreams workload comprises workload specific matrix image frame option graph etc furthermore sake request treat independent task module reuse strategy avoid reconfiguration task multiple request multiple request task combine task runtime scheduler selects optimum bitstream minimises texec variation cluster profile workload specific metric throughput preemptive schedule mention earlier estimation chooses available cycle accurate estimation texec runtime task per bitstream sac task queue scheduler reconfigured bitstream checkpoint workload sac achieve instantaneous average stp bitstreams task execution task sac cluster bitstreams correspond texec variation bitstreams average reconfiguration overhead however insignificant workload intelligent runtime selection bitstream stp improve reduce percent average actual processing stp prr processing generate task queue due non availability dynamic reconfiguration framework task texec however stp report overall achieve stp prr efficient stp stp variable workload via dynamic bitstream selection cluster execution task discussion focus improve fpga compute density hence comment virtualisation overhead data transfer host fpga via pcie  scheduler overhead depends workload batch processing batch combine overhead exclude reconfiguration overhead batch overhead varies task percent execution task furthermore data transfer essentially partition scheme however sac multi task processing texec memory transfer host due compute density achieve stp evaluate workload multiplexed memory transfer multi task processing longer task execution whilst data transfer task framework task queue batch batch reorder maximise throughput however priority task schedule task corresponds respective cluster runtime evaluation although prr allows strict processing compute density task execution later cpm multi fpga data centre multiple cluster offload FPGAs maintain adherence execution task strict deadline execute sac stp metric defines throughput comparison sac theoretical limit maximum stp define task evaluation cpm maximum improvement throughput dynamic variable workload improve device task prr however reduces stp benefit prr particularly dynamic grain workload faster integration functionality however stp evaluation performance cpm ability throughput sac benefit workload multiple FPGAs multiple instance generate multiple FPGAs instance instance task improve resource utilisation instance treat independent sub task scheduler optimise temporal usage throughput requirement task conclusion systematic framework propose address challenge virtualisation FPGAs achieve throughput framework proposes characterisation cluster task heterogeneity resource usage complement custom mapping partition task maximise utilisation lightweight runtime scheduler integrate virtualisation layer profile resource allocation variation per task increase compute density project offs various partition scheme improve throughput efficiency exist