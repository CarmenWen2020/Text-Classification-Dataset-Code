multi access compute MEC aim extend service network reduce network traffic service latency fundamental MEC efficiently offload heterogeneous task mobile application user equipment UE MEC host recently reinforcement DRL propose offload policy interact MEC environment consists UE wireless channel MEC host however weak adaptability environment sample efficiency retrain update policy environment overcome weakness propose task offload meta reinforcement adapt environment gradient update sample model mobile application acyclic graph DAGs offload policy custom sequence sequence seqseq neural network efficiently seqseq network propose  approximation clipped surrogate objective experimental demonstrate offload reduce latency percent baseline adapt environment introduction recent witness rapid advance compute communication technology increase emergence innovative mobile application service augment reality virtual reality recognition mobile healthcare mobile application introduce significant surge demand compute storage resource server situation generates network traffic user burden backhaul link service latency multi access compute MEC recently introduce technology address underlie principle MEC extend compute capability MEC host network user significantly alleviate network congestion reduce service latency functionality MEC task offload aka computation offload enables offload computation intensive task mobile application user equipment UE MEC host network scenario mobile application recognition gesture recognition augment reality compose dependent task model acyclic graph dag offload dependent task dag minimum latency crucial MEC NP exist heuristic approximation algorithm however rely heavily expert knowledge accurate mathematical model MEC whenever environment MEC expert knowledge mathematical model update accordingly therefore specific heuristic approximation algorithm fully adapt dynamic MEC scenario arisen increase complexity application architecture MEC reinforcement combine reinforcement RL neural network dnn promising challenge DRL complex robotics traffic schedule trial error without accurate model environment recently researcher application DRL various MEC task offload MEC UE wireless channel MEC host stationary RL environment offload policy interact environment however weak adaptability unexpected perturbation unseen situation environment application task data rate sample efficiency retrain update policy environment consume meta promising address aforementioned issue leverage previous across task significantly accelerate task context RL meta reinforcement mrl aim policy task within interaction environment building previous mrl conduct loop outer loop task context gradually adjust parameter meta policy governs operation inner loop meta policy inner loop adapt task gradient update significant benefit adapt mrl computation offload specific policy mobile user local data meta policy mrl training MEC leverage resource MEC host UE specifically training meta policy outer loop MEC host training specific offload policy inner loop UE normally inner loop training training amount sample data UE limited computation resource data training finally mrl significantly improve training efficiency task offload algorithm adaptive dynamic MEC environment propose mrl  mrl algorithm sequence sequence seqseq neural network propose learns meta offload policy UE obtains effective policy UE meta policy local data evaluate performance MRLCO dynamic scenario scenario heterogeneous user personal preference mobile application DAGs height width task transmission rate accord distance UE MEC host contribution summarize propose mrl MRLCO address computation offload achieve adaptation dynamic offload scenario MRLCO sample efficiency towards task enables UE training data limited computation resource propose model dynamic computation offload multiple mdps offload policy decompose effectively meta policy mdps specific policy MDP meta policy convert offload decision sequence prediction custom seqseq neural network offload policy embed propose embed vertex dag task profile dependency addition propose training combine approximation clipped surrogate objective stabilize training seqseq neural network conduct simulation generate synthetic DAGs accord application topology task transmission rate MRLCO achieves latency within training baseline algorithm tune DRL greedy algorithm heterogeneous HEFT heuristic algorithm organise brief introduction MEC RL mrl formulation task offload detail MRLCO described evaluation related review discus MRLCO future finally concludes background briefly introduces background related MEC RL mrl multi access compute recent MEC acknowledge emerge network paradigm release pressure introduce unprecedented increase traffic volume computation demand nowadays enable service network typically MEC host couple computation storage resource deployed network intensive computation data processing MEC alleviate burden backhaul link service latency MEC beneficial variety emerge application volume data latency autonomous augment reality digital healthcare mobile application compose multiple task inner dependency offload MEC host processing specifically objective task offload optimal policy partition application computation task execute UE offload MEC host minimal reinforcement RL considers environment maximize accumulate reward formally task model MDP define tuple denotes action reward function transition probability matrix initial distribution discount factor policy mapping probability action define trajectory sample environment accord policy reward function parameterized policy denote return thereafter vector policy parameter calculate PT   sourcewhere PT probability distribution sample trajectory goal RL optimal parameterized policy maximize reward  meta reinforcement mrl enhances conventional RL meta aim algorithm quickly policy task drawn distribution task task corresponds MDP task typically action reward function dynamic recent wealth focus aspect mrl typical gradient mrl aim initial parameter policy neural network perform policy gradient task effective policy task formulation model agnostic meta  target gradient mrl eti  sourcewhere  denotes objective function task vanilla policy gradient VPG    denotes arbitrary baseline denotes update function depends  optimization instance conduct gradient ascent denotes gradient  rate therefore optimal parameter policy network update     SourceRight click MathML additional feature rate outer loop training gradient mrl generalization ability however derivative  computation training inefficient addition combine complex neural network architecture seqseq neural network implementation  becomes intractable address challenge algorithm approximation  target implement MRLCO mrl due computation performance easy implementation comb seqseq neural network formulation computation offload MEC considers application recognition consists dependent task  detection feature  UE offload decision task accord status task profile task locally UE others offload MEC host via wireless channel MEC host multiple virtual machine vms processing task UE associate dedicate VM private compute communication storage resource UE computation capacity cpu core core MEC host denote resource allocation vms vms evenly compute resource MEC host therefore assume user MEC computation capacity VM fvm formally model mobile application DAGs vertex task dependency task respectively denote correspond dependency task immediate task immediate task constraint dependency task cannot execute task task without task exit task computation offload MEC computation offload computation task offload MEC host execute locally UE task offload execute UE sends MEC host wireless channel MEC host task finally return UE latency related task profile MEC task profile cpu cycle task data task   besides MEC contains transmission rate wireless uplink channel rul rate downlink channel  therefore latency data  execute MEC host tsi  task calculate   rul tsi fvm    sourceif task locally UE latency UE obtain    denotes computation capacity UE latency task offload local processing uplink downlink remote processing latency schedule dag denote offload decision task schedule sequence schedule task schedule task denote     task uplink wireless channel MEC host downlink wireless channel UE respectively denote available resource schedule task  msi   resource available depends task schedule immediately resource task schedule immediately utilize resource resource task offload MEC host data task uplink channel available therefore uplink channel  define  max  maxj     max   SourceSimilarly MEC host  downlink channel   max msi max  maxj  tsi  max    msi max msi   max   source schedule UE depends task available UE formally UE  define   max  maxj    max   source overall objective effective offload dag obtain minimal latency formally latency dag schedule TCA TCA max    sourcewhere exit task NP optimal offload extremely challenge due highly dynamic dag topology MEC summarizes notation detail MRLCO handle MRLCO mrl computation offload overview architecture MRLCO explain MEC detailed MDP model computation offload finally implementation MRLCO algorithm MRLCO empower MEC architecture MRLCO aim leverage computation resource UE MEC host training loop training inner loop training task specific policy outer loop training meta policy inner loop training conduct UE outer loop training MEC host architecture integrates MRLCO emerge MEC compose user remote user heterogeneous UE contains MEC host compute service remote consists server specifically mobile user communicate MEC host local transmission MEC host incorporates MEC platform virtualization infrastructure compute storage network resource MEC platform traffic management traffic domain handle service module MRLCO parser local trainer offload scheduler global training service remote execution service deployed user MEC separately described architecture MRLCO empower MEC data architecture mobile application parse DAGs parameter policy network policy network task schedule local executor task offload MEC host offload task architecture MRLCO empower MEC data architecture mobile application parse DAGs parameter policy network policy network task schedule local executor task offload MEC host offload task user  aim convert mobile application DAGs  trainer responsible inner loop training receives parse DAGs  training data uploads downloads parameter policy network MEC host local transmission training policy network deployed  scheduler offload decision policy network inference decision task dag locally schedule task local executor offload task MEC host execution  training service  execution service module deployed MEC platform  training service manage outer loop training sends receives parameter policy network UE deploys global training virtualization infrastructure MEC host  execution service responsible manage task offload UE assign task associate vms UE detailed training MRLCO MEC training MRLCO UE downloads parameter meta policy MEC host inner loop training UE meta policy local data obtain task specific policy UE uploads parameter task specific policy MEC host finally MEC host conduct outer loop training parameter task specific policy generates meta policy training obtain stable meta policy leverage task specific policy UE inner loop training inner loop training training amount data sufficiently UE algorithmic detail outer loop inner loop training training MRLCO empower MEC UE downloads parameter meta policy MEC host inner loop training conduct UE local data obtain parameter task specific policy UE uploads MEC host MEC host conduct outer loop training update parameter theta prime model computation offload multiple mdps adapt mrl computation offload model computation offload various MEC environment multiple mdps effective offload policy MDP task formally distribution task MEC rho mathcal task mathcal sim rho mathcal formulate MDP mathcal mathcal mathcal mathcal mathcal mathcal gamma refer meaning notation obtain adaptive offload policy task decompose effectively meta policy mdps specific offload policy MDP meta policy definition action reward MDP schedule task latency task depends task profile cpu cycle data dag topology wireless transmission rate MEC resource accord MEC resource related offload decision task schedule therefore define combination encode dag partial offload equation qquad quad mathcal lbrace rbrace mathrm tag equation sourcewhere comprise sequence task embeddings partial offload task convert dag sequence task embeddings sort index task accord ascend rank task define equation rank lbrace array text mathcal max limit rank text notin mathcal array tag equation sourcewhere mathrm mathrm mathrm denotes latency task offload execution immediate task task convert embed consists vector embeds task index normalize task profile vector contains index immediate task vector contains index immediate task vector embed task index limited pad vector task action schedule task binary choice action define mathcal lbrace rbrace execution UE offload reward objective minimize achieve goal define reward function estimate negative increment latency offload decision task formally action task increment define delta MDP definition denote policy schedule dag task denote probability offload graph therefore obtain apply chain probability equation prod tag equation source seqseq neural network choice policy define custom seqseq neural network encoder decoder encoder decoder implement recurrent neural network rnn input encoder sequence task embeddings ldots output decoder offload decision task ldots improve performance attention mechanism custom seqseq neural network attention mechanism allows decoder attend source sequence input sequence encoder output generation alleviate issue information loss seqseq neural network encodes input sequence vector fix dimension architecture seqseq neural network MRLCO architecture consists encoder decoder input encoder sequence task embeddings output decoder generate policy function formally define function encoder decoder enc dec respectively memory lstm enc dec encode output encoder obtain equation enc tag equation  encode input task embeddings output vector mathbf ldots decode define output decoder equation dec tag equation sourcewhere context vector decode compute sum output encoder equation sum alpha tag equation sourcethe alpha output encoder compute equation alpha frac mathrm exp mathrm sum mathrm exp mathrm tag equation sourcewhere function mathrm input output define function trainable feedforward neural network accord seqseq neural network approximate policy function passing output decoder mathbf ldots fully layer policy function parameter encoder decoder extract feature DAGs graph structure task profile therefore training policy accelerate training function vice versa training seqseq neural network action generate sample policy training offload decision dag inference seqseq neural network action generate arg max therefore complexity algorithm inference seqseq neural network attention normally task mobile application complexity MRLCO feasible implementation MRLCO MRLCO algorithm structure gradient mrl algorithm consists loop training instead VPG policy gradient inner loop training define objective function proximal policy optimization ppo VPG ppo achieves explore ability training stability task mathcal ppo generates trajectory sample policy theta update target policy theta epoch theta theta initial epoch avoid update target policy ppo clipped surrogate objective equation mathcal mathrm theta mathbb tau sim mathcal tau theta sum min mathrm mathrm clip epsilon epsilon mathrm tag equation SourceHere theta vector parameter sample policy network mathrm probability ratio sample policy target policy define equation mathrm frac theta theta tag equation SourceRight click MathML additional feature clip function mathrm clip epsilon epsilon mathrm aim limit mathrm remove incentive mathrm outside interval epsilon epsilon advantage function specially advantage estimator GAE advantage function define equation sum gamma lambda gamma tag equation SourceRight click MathML additional feature lambda bias variance function loss define equation mathrm VF mathcal theta mathbb tau sim mathcal tau theta sum tag equation SourceRight click MathML additional feature sum gamma algorithm meta reinforcement computation offload task distribution rho mathcal randomly initialize parameter meta policy theta iteration lbrace ldots rbrace sample task lbrace mathcal mathcal ldots mathcal rbrace rho mathcal task mathcal lbrace mathcal mathcal ldots mathcal rbrace initialize theta leftarrow theta theta leftarrow theta sample trajectory tau tau ldots mathcal sample policy theta compute policy network parameter theta prime leftarrow theta alpha nabla theta mathrm ppo mathcal theta via adam update theta leftarrow theta beta mathrm MRLCO via adam overall combine define objective function inner loop task equation mathrm ppo mathcal theta mathcal theta mathrm VF mathcal theta tag equation sourcewhere coefficient function loss accord target gradient mrl define objective function outer loop training target MRLCO express align mathrm MRLCO theta mathbb mathcal sim rho mathcal tau sim mathcal tau theta prime mathrm ppo mathcal theta prime mathrm quad theta prime tau sim mathcal mathbf tau theta theta mathcal theta theta tag align SourceNext conduct gradient ascent maximize mathrm MRLCO theta however optimize objective function involves gradient gradient introduces computation implementation difficulty combine complex neural network seqseq neural network address challenge approximation replace derivative define equation mathrm MRLCO frac sum theta prime theta alpha tag equation sourcewhere sample task outer loop alpha rate inner loop training conduct gradient inner loop training overall algorithm algorithm parameter meta policy neural network denote theta sample batch task mathcal batch conduct inner loop training sample task inner loop training update meta policy parameter theta gradient ascent theta leftarrow theta beta mathrm MRLCO via adam beta rate outer loop training performance evaluation experimental propose introduce algorithm hyperparameters MRLCO simulation environment evaluate performance MRLCO tune DRL heuristic algorithm algorithm hyperparameters MRLCO implement via tensorflow encoder decoder seqseq neural network layer dynamic memory lstm hidden layer moreover layer normalization encoder decoder training hyperparameters MRLCO rate inner loop outer loop coefficient clip constant epsilon discount factor gamma lambda respectively gradient inner loop training overall summarize hyperparameter summary notation neural network training hyperparameters simulation environment cellular network data transmission rate varies UE cpu UE mathrm UE ghz core VM MEC host cpu ghz per core offload task parallel core cpu VM mathrm ghz application model DAGs various topology task profile simulate heterogeneous DAGs implement synthetic dag generator accord parameter topology task profile generate DAGs density ccr task width height dag density decides dag ccr denotes ratio communication computation task generate DAGs density density generate DAGs evaluate performance MRLCO dynamic scenario simulate scenario UE application preference various topology task simulates scenario UE dynamic transmission rate data task KB KB cpu cycle task cycle task index vector randomly ccr generate dag mobile application computation intensive generate datasets training datasets datasets effective offload policy dataset task MRLCO learns meta policy training datasets algorithm meta policy initial policy effective offload policy datasets MRLCO baseline algorithm tune DRL  policy training datasets DRL offload algorithm propose parameter policy network initial task specific policy network update datasets HEFT algorithm adapt prioritizes task HEFT schedule task estimate greedy task greedily assign UE MEC host estimate analysis generate dag topology simulate scenario user preference mobile application dataset contains DAGs topology density parameter influence dag topology task generate dag lbrace rbrace density lbrace rbrace dag generate combination density dag application preference mobile user effective offload policy dag task randomly dag training datasets unseen datasets MRLCO tune DRL training datasets evaluate MRLCO baseline algorithm datasets training MRLCO meta batch task sample rho mathcal outer loop training stage inner loop sample trajectory dag conduct policy gradient update ppo target training evaluate MRLCO tune DRL policy gradient update sample trajectory dag datasets performance MRLCO baseline algorithm dag overall greedy algorithm latency MRLCO obtains latency demonstrates MRLCO HEFT algorithm gradient update tune DRL consistently performs HEFT algorithm indicates MRLCO adapt task quickly tune DRL MRLCO tune DRL gradient update already heuristic algorithm HEFT greedy algorithm MRLCO DRL update policy pre model instead scratch heuristic algorithm fix policy obtain offload cannot adapt dag topology evaluation dag topology aim influence task performance algorithm randomly generate training datasets lbrace rbrace datasets lbrace rbrace dataset generate DAGs randomly lbrace rbrace density lbrace rbrace ccr distribution dag topology datasets meta batch setting MRLCO tune DRL outperform HEFT algorithm gradient update consistently greedy gradient update moreover MRLCO adapts task faster tune DRL gradient update latency MRLCO decrease sharply tune HEFT algorithm gradient update MRLCO obtains latency baseline algorithm evaluation task conduct evaluate performance MRLCO transmission rate offload policy transmission rate individual task randomly generate dag dataset parameter addition implement optimal algorithm via exhaustively optimal offload conduct meta training randomly transmission rate mbps mbps mbps evaluate meta policy transmission rate mbps mbps mbps unseen training procedure MRLCO adapts task faster tune DRL achieves latency gradient update MRLCO achieves latency initial evaluation transmission rate summarizes average latency algorithm datasets overall MRLCO outperforms heuristic baseline algorithm gradient update  tune DRL update performance tune MRLCO algorithm update tune algorithm MRLCO achieves update however gap MRLCO optimal integrate seqseq neural network another sample efficient policy mrl direction future comparison MRLCO baseline algorithm average latency  datasets related task offload MEC attract significant research task model related task model binary offload partial offload task model binary offload inner dependency computation task application aim offload task access MEC host achieve minimal joint target latency focus computation offload independent task software define ultra dense network formulate task offload mixed integer non linear program decomposition heuristic propose approximate dynamic program algorithm computation offload achieve optimal quality task model partial offload application compose task inner dependency achieve granularity computation offload offload performance model application compute graph propose approximation algorithm task offload obtain implement user online offload framework android application aim minimize remote execution overhead  propose innovative task selection algorithm android application achieve granularity offload adapt offload strategy dynamic scenario recent DRL widely apply task offload MEC focus multi user multi node computation offload ultra dense network multiple offload adopt obtain offload strategy propose DRL offload framework jointly considers offload decision resource allocation  propose efficient task offload combine ppo convolutional neural network propose offload constraint limited resource vehicle mobility delay propose DRL online offload framework maximize sum computation rate UE  propose jointly optimise task offload resource allocation MEC exist mostly assume offload task apply conventional DRL algorithm task however DRL algorithm suffer sample efficiency scenario DRL offload training effective policy impedes practical deployment address issue offload adopts mrl approach efficiently task requirement gradient update amount data quickly adapt environment requirement training fully retrain offload policy scratch demand computation data efficiently resource constrain UE data 7Discussion MRLCO advantage exist RL task offload adapt dynamic environment sample efficiency beyond scope task offload MEC propose MRLCO framework potential apply decision MEC instance content cache MEC aim cache popular content MEC host achieve quality service qos mobile user reduce network traffic MEC host cache policy dynamic content preference network user propose mrl framework adapt execute outer loop training server meta cache policy inner loop training MEC host specific cache policy MEC host MRLCO benefit MEC challenge exploration stable wireless channel reliable mobile device sufficient computation resource MRLCO increase user however operating UE straggler due broken network connection insufficient synchronous outer loop training update meta policy gathering parameter UE straggler affect training performance MRLCO issue apply adaptive client selection algorithm automatically filter straggler reliable client training conclusion proposes mrl approach namely MRLCO computation offload MEC distinguish exist MRLCO quickly adapt MEC environment within gradient update sample propose target mobile application model DAGs computation offload convert sequence prediction seqseq neural network propose effectively policy moreover adopt approximation mrl objective reduce training surrogate clip objective stabilize training conduct simulation dag topology task transmission rate demonstrate within training MRLCO achieves latency baseline algorithm tune DRL greedy algorithm HEFT algorithm