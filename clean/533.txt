mobile compute MEC task specific service execution addition dependent execution task however previous ignore impact limited service cached node dependent task offload infeasible offload decision longer completion bridge gap article efficiently offload dependent task node limited predetermine service cache formally define offload dependent task service cache ODT SC exists algorithm constant approximation efficient convex program algorithm CP moreover homogeneous MEC propose favorite successor algorithm FS competitive ratio inline graphic  href zhao  gif extensive simulation google data trace propose algorithm significantly reduce application completion percent alternative introduction internet widespread mobile device development delay sensitive resource intensive application virtual augment reality recognition data processing currently application perform mobile device platform mobile device computational resource application resource intensive application platform massive data transfer mobile device remote server unpredictable communication delay mobile compute MEC emerge promising overcome disadvantage however exist challenge MEC recognition application basically recognition application dependent task acquisition detection preprocessing feature extraction classification task offload onto node factor consideration service cache task execution specific service task offload onto node configure correspond service task feature extraction offload onto node configure machine model dependency dependency task output task feature extraction input task classification task classification task feature extraction actually service cache dependency impact feasibility performance task offload service cache dependency offload task application perform successfully exist service cache focus joint optimization service placement task offload MEC service placement update incur operation task execution hurt stability database machine model non trivial amount data consume migrate service service placement occurs jointly update service placement task offload due task dynamic uncertainty offload computation congestion node previous assume service cached node accord exist impact service cache application performance completion dynamic task offload due limited memory resource subset service cached node status service cache service host influence decision task offload task offload onto node task correspond data task task task independent task simplicity processing delay task node communication delay data transmission task task task offload onto node constraint service cache offload shortest completion plot task completion refer makespan hereafter however node cache service task node cache service task offload strategy plot infeasible inefficient due node cache service task feasible plot makespan focus offload dependent task service cache motivation assume task offload illustrate plot optimal offload plot without service cache plot offload node cache service task node cache service task previous task dependency impact service cache task offload directly apply node assist user execute sequence dependent task service cache apply scenario multiple node related GenDoc jointly dependent task offload service cache placement objective application completion minimization however GenDoc compute resource constraint node offload task node mobile node resource sensitive GenDoc irrational limited compute resource contribution formally define offload dependent task MEC service cache ODT SC NP hardness analyze ODT SC cannot constant approximation algorithm polynomial convex program algorithm CP ODT SC heterogeneous scenario CP transforms convex optimization offloads task accord convex optimization favorite successor algorithm FS homogeneous node FS achieve approximation ratio conduct extensive simulation application data trace CP FS reduce application completion percent alternative organize discus related defines offload dependent task MEC service cache prof exists approximation algorithm constant factor propose efficient convex program algorithm CP focus homogeneous node proposes approximation algorithm bound approximation ratio simulation conclude related emergence resource consume delay sensitive mobile application augment reality autonomous spur delay access compute resource address challenge mobile compute MEC envision compute paradigm increase amount attention recent MEC task offload research issue recent due  importance propose complexity algorithm minimize makespan multiple independent task jointly optimization task offload resource allocation propose compute architecture accord distance node user optimal offload scheme minimize makespan workload placement algorithm devote minimize overall task offload propose lightweight mobile computation offload framework minimize overall execution overhead network task offload resource allocation algorithm minimize overall offload computation delay assume node task however mobile application become increasingly complicate various service task node service node cannot equip service due limited memory compute resource constraint apply directly scenario service aware task challenge service cache exist service cache focus service placement joint optimization service placement task offload service placement update incur operation task execution hurt stability service placement occurs contrary task offload occurs due task dynamic uncertainty placement offload decision simultaneously decrease stability increase operational consideration service placement request schedule propose joint optimization service placement request schedule storage communication computation budget constraint aforementioned focus offload independent task application MEC become increasingly complex mobile application consist dependent task offload dependent task practical application MEC complex precedence constraint data transfer requirement MEC focus dependent task offload MEC propose heuristic algorithm schedule dependent task objective overall application execution minimization application completion deadline constraint polynomial approximation algorithm offload dependent task minimize makespan resource constraint dependent task offload minimize overall application application completion constraint however service cache constraint task dependent execution addition service execution service cache task dependency significant task offload knowledge constraint GenDoc jointly dependent task offload service cache placement objective application completion minimization however GenDoc processing resource constraint irrational limited processing resource preliminary definition introduce model task dependency model network model formally define dependent task offload service cache ODT SC exists constant approximation algorithm model task dependency model assume application recognition virtual reality execute application task execute node local device contains task insert dummy task precedent task task local device dummy task execute local device execution zero task execution various resource storage cpu network correspond service machine model restrict service dummy task execute local device denote task dummy task task accord alibaba data application percent application consist dependent task mobile application usually multiple dependent task recognition application dependent task acquisition detection preprocessing feature extraction classification precedence constraint task acyclic graph dag denote dependency task denotes task precedence constraint specifically task task exists data transmission task task task task correspond data transmit task parameter avv denote amount data transfer task task besides sink node dag node emerges network model typical MEC network contains node remote node local device node powerful processing capacity cache service away user local device communication delay transfer task local device contrary processing capacity local device weak service cached due memory constraint task execute directly local device communication delay ignore description regard local device node processing capacity node transmission distance execution node node local device denotes node node interconnect various network connection local network communication delay per data node denote cmm cmm task offload node remote communication delay task correspond dummy task offload delay task MEC service cache node consume various resource node storage compute resource remote storage compute resource node relatively storage mobile 0GB storage service 0GB cannot load service node subset service node service constraint task task execute node moreover node limited resource cpu cycle storage compute assume node resource accord attribute node task statistic analysis task execute node rvm resource allocate task execution tvm description resource constraint storage easy extend multiple resource constraint storage cpu resource constraint summarizes notation notation notation definition MEC application available node application application consists multiple dependent task define offload dependent task service cache ODT SC construct dag accord dependency task described binary variable zmv denote task offload onto node variable denote task feasible offload satisfy task offload task offload onto exactly node task  service constraint task offload onto node configure correspond service node  dependency constraint task task iff precedent task data transfer node task mzmvtvm  avv  execute task sequence task task offload onto node tvm node perform task instance task cannot interrupt execution processing resource constraint processing resource constraint satisfied node formulate  makespan task denote max mzmvtvm aim feasible offload minimum makespan ODT SC formulate    mzmvtvm  avv  zmv zmv  mzmvtvm zmv source equation task offload onto exactly node equation denotes service constraint task offload onto node inequality dependency constraint task iff precedent task transfer correspond data task fourth constraint guarantee task node execute sequence specifically task offload onto node without loss generality assume task later task ensure task task fifth inequality processing resource constraint objective minimize  mint complexity analysis ODT SC NP exists approximation algorithm constant factor theorem ODT SC NP approximation algorithm constant ODT SC NP theorem definition definition salesman tsp distance shortest route exactly return undirected graph objective optimal hamiltonian cycle proof tsp ODT SC approximation algorithm tsp NP arbitrary tsp instance distance denote dij construct ODT SC assume identical node equip service denote correspondence available processing resource node denote task offload onto node denote dag task execution tvm task node task task processing resource respectively task processing resource data volume transmit avv dag communication delay per data node distance cij dij objective feasible offload minimum makespan obviously task node node execute task     task obtain        source task selection node  selection ith exactly tsp instance tsp instance ODT SC previous approximation constant algorithm tsp NP briefly proof completeness graph denotes vertex denotes vertex construct graph define   source tsp shortest hamiltonian cycle graph assume exists approximation algorithm denote optimal  approximation AHC obviously exists hamiltonian cycle AHC  source hamiltonian cycle AHC   AHC hamiltonian cycle exists AHC hamiltonian cycle judge hamiltonian cycle graph accord approximation algorithm polynomial however hamiltonian cycle NP cannot polynomial unless NP therefore assumption false approximation algorithm tsp NP tsp ODT SC conclude approximation algorithm constant ODT SC NP analysis hardness ODT SC algorithm ODT SC approximation algorithm bound approximation factor homogenous scenario algorithm ODT SC propose algorithm ODT SC although non trivial cannot satisfactory performance simulation propose convex program algorithm CP described algorithm propose algorithm ODT SC specifically algorithm offloads dependent task relax constraint ODT SC compute potential node execution task schedule task dependency constraint node selection schedule task aim minimize makespan relax constraint ODT SC ODT SC directly specifically inequality quadratic fourth constraint contains conditional statement eliminate difficulty define binary variable  task node satisfy zmv  zmv source zmv binary variable zmv  modify inequality mzmvtvm  avv  mzmvtvm  avv  source  modify fourth constraint inequality  source zmv zmv  source specifically task task offload onto node without loss generality assume task later task zmv zmv guarantee  zmv zmv  simplify guarantee task cannot task task offload onto node zmv zmv cannot simultaneously zmv zmv  regardless constraint inequality guarantee task node execute sequence task offload onto node perform simultaneously transform fourth constraint inequality relax binary variable specifically ODT SC assumes task perform onto node relax assumption task permit splittable perform onto node sum formulate linear program polynomial linear program solver pulp assume optimal denote     optimal denote  relaxation ODT SC  bound accord optimal obtain potential node execution task operation    zmv  zmv mzmvtvm  avv   zmv zmv   mzmvtvm zmv   SourceRight click MathML additional feature execution task sort task increase schedule randomly simplicity fourth inequality easily increase  preserve dependency constraint schedule task schedule preserve dependency constraint node selection offload task node optimal  randomize specifically task node zmv offload task node probability  task schedule offload task node probability  offload schedule task however due randomize processing node task processing resource constraint convex program algorithm convex program algorithm ODT SC CP workflow CP CP offloads dependent task relax ODT SC construct convex optimization program progressive obtain feasible compute task accord feasible offload task workflow CP algorithm CP relax ODT SC construct convex program progressive program compute task accord offload task accord workflow CP algorithm CP relax ODT SC construct convex program progressive program compute task accord offload task accord relax ODT SC algorithm cannot achieve due introduce variable eliminate complexity leverage definition binary variable zmv modification mzmvtvm  avv  mzmvtvm  avv max zmv source assume node perform task parallel task permit splittable execute node derive convex optimization    mzmvtvm  avv max zmv  mzmvtvm zmv source convex optimization polynomial convex program solver cplex assume optimal optimal objective progressive obtains integer  progressive specifically iteration obtain fractional task max randomize derive integer  chosen task fix integer  fix quantity obtain feasible  iteration offload node task  assume node simultaneously execute task compute computes task specifically insert task dag task sink node dag denote link   avv link task compute maximum distance task task denote easily descend distance task preserve dependency constraint potential longer execution sort task descend distance task offload task offload task define concept variable facilitate description pred succ denote immediate predecessor successor task task respectively obtain accord dag denote processing resource node initialize denotes node satisfy processing resource service constraint task formally rvm date idle slot node tvm initialize idle slot already offload task node task offload onto node moreover task actual offload node actual actual denote respectively initialize definition task offload onto node calculate est eft est max maxv pred  mav source eft est tvm source iteration task offload compute eft node offload task onto node minm eft task offload actual offload node besides update actual actual processing resource respectively est source  source rvm source operation task offload CP algorithm formally described algorithm favorite successor algorithm practical homogeneous scenario propose CP algorithm ODT SC heterogeneous scenario practical scenario node purchase provider hardware specification node offload homogeneous scenario assume node processing capacity link transmission rate denote execution tvm task offload onto node tvm denote communication delay per data cmm node cmm algorithm CP convex program algorithm ODT SC relax ODT SC construct convex optimization program obtain optimal progressive derive integer  progressive compute compute task sort task descend distance task offload task task obtain pred accord dag initialize variable node initialize variable offload task update rvm compute eft offload task minm eft offload node update respectively delete task offload MEC decrease task offload delay compute resource proximity local device development 5G technology data transmission rate greatly improve processing capacity node limited typical application virtual augment reality VR AR cognitive assistance mobile task execution delay transmission delay practical scenario assume minimum processing delay maximum communication delay approximate algorithm bound approximation factor offload task practical homogeneous scenario favorite successor algorithm description dependent task task precedent task predecessor succedent task successor predecessor successor task offload onto node task consume communication delay data transmission node predecessor successor task offload onto node task important schedule dependent task consideration definition favorite successor predecessor definition favorite successor task task succ satisfies cavv task favorite successor task definition favorite predecessor task task pred satisfies cav task favorite predecessor task accord definition task favorite successor predecessor favorite successor predecessor offload onto node task specifically favorite successor task task offload node task otherwise avv avv contradicts definition favorite successor without loss generality assume perform avv avv contradicts definition favorite successor task favorite successor similarly task favorite predecessor definition favorite successor favorite successor algorithm FS specifically FS offloads task obtain favorite successor without service node constraint reflect dependency priority dag favorite successor offload node service constraint obtain favorite successor attempt offload task node without service node constraint situation dependency constraint formulate  cavv yvv succ yvv succ pred pred yvv sourcewhere binary variable yvv denotes task favorite successor task specifically yvv task favorite successor task otherwise yvv inequality indicates dependency constraint specifically yvv inequality communication delay task task favorite successor otherwise cavv communication delay task task favorite successor inequality task favorite successor predecessor task favorite successor succ yvv succ contradicts inequality fourth inequality task offload delay task execute offload local device node objective minimize makespan min program polynomial relax sixth constraint yvv obtain optimal linear program solver pulp inequality indicates successor task satisfy specifically exists successor task succ yvv succ contradicts inequality   otherwise integer favorite successor exists task favorite successor offload leverage obtain offload algorithm offload task offload task assign favorite successor task node task offload introduce definition sake convenience VR denote task predecessor offload initialize task without predecessor VR denote task offload moreover denote offload task node denote favorite successor task initialize none avail maxv pred cav denote available task execute node task execute predecessor execute correspond data transmit compute est task VR node node  est  node execute favorite successor earlier node reserve node execute task task VR succ potential compete successor avail est node est avail  est calm succ defer task node est est  node minv VR est offload task task offload actual offload node update respectively besides update offload task  task update  VR iteration task offload FS algorithm formally described algorithm algorithm FS favorite successor algorithm homogeneous scenario obtain favorite successor construct linear program obtain optimal derive integer  favorite successor exists task integer favorite successor offload task obtain pred succ accord dag initialize variable avail node initialize offload task none compute VR  task predecessor offload VR task VR node compute est node offload task favorite successor VR  est  task VR succ avail maxv pred cav avail est node est avail  est calm succ update est est   minv VR  task VR offload onto node satisfy est  offload node update respectively update offload task  update  task VR predecessor offload performance analysis analyzes approximate performance FS service node constraint offload task satisfy favorite successor requirement approximation ratio theorem node constraint offload task accord integer obtain task makespan optimal makespan proof denote actual makespan  denote actual task integer offload tlp denote makespan obtain linear program bound optimal makespan denote  denote link cavv yvv assume contains unlimited node offload task receives data successor dag  max  wlp max cavv  cavv sourceif  cavv  cavv otherwise cavv  cavv cavv cavv sourcethe inequality assume cavv hence conclude   max cavv  cavv source feature propose FS algorithm lemma minv task node configure service denote accumulate idle node actual task  source proof node configure service task service task offload onto node node idle accumulate idle node  accumulate idle node proof becomes identical parallel machine schedule dependent task illustrate previous lemma  denote actual makespan FS algorithm   source proof task task FS algorithm apply lemma      source approximation performance propose FS algorithm theorem  denote optimal makespan offload node  proof accumulate idle plus task execution slice apply theorem lemma            source penultimate inequality   conclude FS achieve approximate ratio node minv task node configure service performance evaluation evaluates performance propose algorithm multiple application scenario application data trace performance metric methodology mainly focus comparison makespan important metric task offload CP FS exist approach GenDoc derives efficient dynamic program algorithm optimal dependent task offload scheme fix service cache characteristic GenDoc task execute multiple node repeatedly avoid communication delay achieve objective makespan minimization however consume processing resource node individual allocation greedy offload ITAGS algorithm aim minimize communication computation satisfy makespan constraint specifically ITAGS binary relaxed version allocate completion deadline individual task greedily optimizes offload task allowance comparison modify objective ITAGS makespan minimization satisfy processing resource constraint ITAGS propose algorithm illustrate denote traditional algorithm denote greedy algorithm task dag dependency offloads picked task node satisfy service resource constraint simulation setting introduce simulation setting generation DAGs task setting scenario setting simulation dag generation generate DAGs respect structure namely gaussian elimination GE fourier transform fft GE structure dimension graph task GE structure fft structure structure recursive butterfly operation fft determines task fft structure recursive task  generate structure scenario simulation generate dependent task structure denote GE structure fft structure respectively task setting data trace google cluster generate task google cluster contains application consists task task various parameter specify resource request storage compute requirement service request offload onto node equip correspond service information generate simulation specifically ODT SC emulate heterogeneous environment processing delay node processing factor uniform distribution communication computation ratio uniformly randomize task communication delay data transmission task task generate processing task random moreover processing resource rvm drawn uniformly task node task percentage node configure service denote percent node default simulation scenario setting simulation perform scenario specifically scenario apply heterogeneous environment ODT SC evaluate performance CP GenDoc ITAGS greedy scenario scenario apply homogeneous environment introduce FS CP GenDoc ITAGS greedy scenario simulation simulation contains scenario basically random evaluate overall makespan performance algorithm simulate makespan algorithm parameter task percentage node perform task communication computation ratio node simulation demonstrate effectiveness propose algorithm simulation dag structure GE fft structure simulation scenario heterogeneous homogeneous scenario overall performance comparison simulation randomly generate DAGs GE fft algorithm task dag generate task setting accord generate totally perform CP GenDoc ITAGS greedy evaluate overall makespan performance CP reduce makespan percent ITAGS GenDoc greedy respectively besides percent within makespan CP percent within makespan algorithm heterogeneous scenario CP achieves overall makespan performance benchmark propose CP algorithm service cache offload decision algorithm progressive compute overall performance heterogeneous scenario similarly dag generate random setting requirement homogeneous scenario overall generate totally homogeneous scenario propose CP FS algorithm apply homogeneous scenario FS CP GenDoc ITAGS greedy FS reduces makespan percent CP GenDoc ITAGS greedy respectively FS achieve makespan CP homogeneous scenario CP specifically homogeneous scenario efficient CP homogeneous scenario usually perform CP algorithm heterogeneous scenario execute FS homogeneous scenario overall performance homogeneous scenario comparison ranking simulation generate totally random heterogeneous evaluate CP ITAGS greedy sort algorithm ascend makespans algorithm shortest makespan marked rank algorithm shortest makespan marked rank similarly algorithm perform algorithm marked rank simulation CP minimum makespan percent comparison ITAGS GenDoc greedy rank respectively propose CP algorithm service cache constraint adopt algorithm CP achieves shortest makespan makespan similarly FS GenDoc ITAGS greedy random homogeneous FS shortest makespan percent makespan portion percent comparison GenDoc rank ITAGS rank greedy makespan propose FS algorithm outperforms impact task makespan simulation investigates makespan task execute simulation average numerical ODT SC dag structure task increase makespan increase algorithm CP achieve makespan algorithm task fft structure makespan CP ITAGS GenDoc greedy respectively CP decrease makespan percent ITAGS GenDoc greedy respectively besides GenDoc rank task rank task GenDoc consume processing resource encounter resource constraint task increase versus rank makespans makespan versus task heterogeneous scenario makespan versus task homogeneous scenario homogeneous scenario dag structure propose FS algorithm outperforms benchmark basically FS achieves shortest makespan CP rank GenDoc rank ITAGS rank rank greedy makespan task GE structure propose FS algorithm reduce makespan percent CP GenDoc ITAGS greedy respectively FS specifically homogeneous scenario efficient algorithm ODT SC impact makespan fourth simulation makespan task percentage node configure service horizontal increase makespan decrease algorithm CP FS achieve makespan algorithm ODT SC dag structure CP achieves makespan algorithm task install service percent node GE structure CP achieve makespan ITAGS GenDoc greedy achieve makespans respectively CP reduces makespan percent ITAGS GenDoc greedy respectively calculate offload scheme CP service cache node account benchmark CP limited service node achieve makespan makespan versus heterogeneous scenario makespan versus homogeneous scenario homogeneous scenario dag structure regardless proportion deployed service FS achieves makespan algorithm FS reduces makespan percent CP GenDoc ITAGS greedy respectively besides GenDoc performs ITAGS homogeneous scenario increase impact communication computation ratio makespan fifth simulation evaluates makespan communication computation ratio specifically investigate impact inter node communication makespan communication computation ratio increase communication delay impact makespan makespan communication computation ratio homogeneous scenario dag structure CP achieves minimum makespan ratio GE structure CP reduce makespan percent ITAGS GenDoc greedy respectively makespan versus communication computation ratio heterogeneous scenario makespan versus communication computation ratio homogeneous scenario impact communication computation ratio makespan homogeneous scenario FS achieves minimum makespan algorithm GenDoc performs communication computation ratio increase GenDoc task multiple node avoid communication overhead impact node makespan simulation illustrates impact node makespan increase available node makespan task decrease algorithm node compute resource task heterogeneous scenario CP achieves makespan algorithm node GE structure CP reduces makespan percent GenDoc ITAGS greedy respectively homogeneous scenario regardless node MEC FS makespan algorithm node fft structure MEC FS reduce makespan percent CP GenDoc ITAGS greedy respectively obtain favorite successor potential node FS achieve makespan performance algorithm makespan versus node heterogeneous scenario makespan versus node heterogeneous scenario makespan versus node homogeneous scenario simulation conclusion CP reduces makespan percent algorithm heterogeneous scenario FS achieve performance CP reduce makespan percent alternative homogeneous scenario propose CP FS substantially outperform algorithm parameter task communication computation ratio node testbed implementation prototype consists central controller node local device remote central controller server core processor 4GB ram TB disk mbps wireless NIC executes propose algorithm task placement schedule scheme convex program central controller embed api cplex local device server core processor 8GB ram TB disk mbps wireless NIC cache task request server perform node intel cpu 6GB ram TB disk mbps wireless NIC server equip core processor 4GB ram TB disk mbps wireless NIC remote server mbps router estimate communication delay remote local device node server remote away router due distance random server router actual network limit server node local device MB actual network limit server remote node MB task install hadoop testbed experimental input counting application simultaneously input 1GB 2GB 3GB respectively testbed hadoop application consists mapper reducer apparently reducer correspond mapper indicates inherent dependence simulate service cache constraint node remote execute mapper prototype CP FS GenDoc ITAGS greedy testbed makespan performance makespans algorithm CP reduce makespan percent FS GenDoc ITAGS greedy respectively completeness FS algorithm heterogeneous scenario experimental CP algorithm performs heterogeneous scenario algorithm FS addition due percentage performance improvement algorithm performance improvement scenario experimental propose algorithm achieve satisfactory performance scenario makespans offload algorithm conclusion offload dependent task service cache minimize makespan ODT SC exists constant approximation algorithm ODT SC convex program algorithm moreover ODT SC homogeneous scenario propose approximate algorithm bound approximation factor practical extensive simulation efficiency propose algorithm