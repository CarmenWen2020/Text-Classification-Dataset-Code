multi access compute environment app vendor deploy service application network user offload computation task server user perceive delay aware service placement user allocation environment model MEC enable network user perceive delay consists compute delay transmission delay offload define sum service placement server usage consumption minimize overall service decision user allocation decision guarantee user perceive delay requirement user fulfil formulate mixed integer linear program NP hardness due intractability propose local algorithm user perceive delay aware service placement user allocation environment locus feasible repeatedly reduces perform local analyze complexity locus achieves provable guaranteed performance finally locus exist performance introduction witness explosive growth mobile iot device smartphones wearable device vehicle etc daily expose variety service application delay sensitive latency traditionally widely compute technology centralize service application computation task offload application vendor server however centralization service distance user tends increase latency exist compute paradigm cannot satisfy stringent timeliness requirement delay sensitive application usually network latency impact application performance service quality user requirement latency paradigm multi access compute MEC propose extension centralize tackle challenge network latency characteristic MEC computation storage resource network user directly service enable network capability compute cache application vendor deploy service application server remote significantly reduce latency host service device service abstraction application host server request user augment reality AR virtual reality VR facial identification service placement refers configure platform related library database service server unlike diverse resource server limited compute storage resource service service consume amount resource service placement challenge tackle service placement MEC enable equip server densely distribute environment geographical coverage usually partially overlap non service user fail service server user overlap MEC enable allocate associate server server limited compute resource server due limit important effective user server allocation prevent waste server resource user offloads task server user task offloads server user offloads task server user task offloads server user server allocation popular paradigm task offload binary offload partial offload paradigm binary offload applies highly integrate task cannot partition offload server however application compose multiple procedure involve processing chunk data application vehicle counting traffic surveillance video partition computation task multiple offload server parallel execution although service placement user allocation attention research joint adequately tackle joint service placement user allocation fail aspect constrain user perceive delay already user perceive delay consideration fail achieve approximation guarantee rigorous proof user perceive delay aware service placement user allocation MEC contribution model MEC enable network user perceive delay task offload user perceive delay aware service placement user allocation formulate user perceive delay aware service placement user allocation mixed integer linear program aim minimize task offload NP reduce another NP due NP hardness impossible optimal polynomial effectively complexity propose locus implement local operation swap delete analyze complexity locus achieves approximation factor sufficiently constant raspberry PowerEdge simulate user server respectively meanwhile service counting vehicle counting video pedestrian counting video detection video dataset derive AI datasets propose algorithm locus exist locus outperforms significantly reduces task offload remainder organize review related introduce notation formulate optimization analyze complexity propose polynomial algorithm locus analyze approximation guarantee propose algorithm exist evaluate performance finally discus future conclude related summarize category highlight drawback multi access compute investigate dynamic service placement MEC propose online algorithm jointly optimizes task offload dynamic service cache tackle unknown dynamic service heterogeneity decentralize coordination collaborative service placement MEC propose efficient decentralize algorithm service placement decision BSs optimize distribute theoretical mechanism service placement resource service provider social minimize decentralize algorithm user allocation computation offload theory apply algorithm user offload decision independently formulate task offload user allocation MEC minority propose minority scheme converge optimal utilized distribute compute propose efficient theoretic approach tackle user allocation MEC environment issue related service placement user allocation multi access compute environment fail investigate joint service placement user allocation service placement user allocation propose heuristic algorithm tackle joint user association sfc placement resource allocation employ mixed integer linear program technique joint optimization service placement request rout MEC environment propose algorithm achieves optimal performance randomize bender decomposition algorithm cloudlets allocate request task cloudlets public minimum consumption investigate deploy server effective manner without violate service quality complexity heuristic algorithm address aware joint service cache task offload assignment polynomial iterative algorithm tackle however related fail aspect constrain user perceive delay tackle joint service placement user allocation user perceive delay  implement commercial smartphones significantly reduce user perceive latency foreground apps aggressive background workload propose queue model online service proactive capability characterize user delay reduction proactive investigate content placement delivery strategy cache enable wireless network characterize user perceive delay data rate simultaneously propose delay tolerant wireless cache feedback delay user availability consideration already user perceive delay consideration however fail achieves approximation guarantee rigorous proof model slot duration timescale service placement user allocation decision update user perceive delay aware service placement user allocation specific slot index omit sake simplicity architecture depict client user upload user related information input data workload user perceive delay requirement server application afterwards user allocation decision offload controller client allocate user server available offload user task correspond server architecture service placement user allocation server application propose local algorithm locus introduce detail invoked information server service compute capacity server workload upper limit server service input calculate locus service controller service correspond server user allocation decision client model MEC enable network user perceive delay task offload important notation model notation model notation model MEC enable network MEC enable wireless network consist server denote server accessible via specific geographical compute service user coverage assume service denote user user task service execute user task computation demand input data workload input data user task cpu cycle respectively MEC enable network user coverage multiple server offload task server assume user split task multiple portion offload server computation demand user task proportional input data define continuous user allocation variable denote user task offload server  sourcethen calculate workload input data user task offload server   respectively multi access compute server perform parallel processing allocate compute capacity multiple compute task offload reasonably assume user task server compute capacity cpu cycle workload server limited cpu cycle specific slot sum task workload offload server specific slot cannot exceed limited compute resource constraint server   source besides define binary service variable service server otherwise user request service offload task server sourcewhere user request service exposition denote overall user allocation decision overall service decision respectively user perceive delay user perceive delay MEC environment mainly compute delay transmission delay compute delay mention previously compute capacity server cpu cycle specific slot compute delay user server calculate dcn  transmission delay reasonable complexity physical layer wireless channel user server antenna transmission uplink channel gain user server constant channel gain user specific task offload slot additionally server assign orthogonal frequency employ enhance inter interference coordination technique propose lte rel user occupy orthogonal subchannel bandwidth calculate uplink data rate user server accord shannon hartley formula wlog  sourcewhere transmission input parameter user background variance  signal ratio uplink channel user server user server transmission delay calculate dtn   source user perceive delay compute delay transmission delay user calculate user perceive delay maxm dcn dtn sourcewhere define user offload task server worth neglect delay server computation due MEC enable service video analysis massive text mining computation input data user service request user perceive delay acceptable sourcewhere user perceive delay requirement task offload previous user allocation service decision incur service placement server usage consumption specific slot service placement due rapid development storage technology available service server unlimited introduce associate service placement account monetary impose network infrastructure service provider storage utilization server service placement calculate sym  sourcewhere cpm service server generally cpm depends storage ability server compute complexity service server usage processing load offload server server usage account computation consumption fee network infrastructure service provider server usage define   SourceRight click MathML additional feature denote user within server coverage  associate execution workload server consumption consumption important role user multi access compute environment monetary consumption importance mention previously user server transmission delay calculate consumption user    sourcewhere transmission input parameter user monetary consumption monetary service placement server usage consumption important task offload  sourcewe formulation task offload minimize guarantee user perceive delay requirement user satisfied formulation analysis formulate intractability complexity analysis formulation user allocation decision service decision task offload  user perceive delay aware joint service placement user allocation assignment aim minimize formulate mixed integer linear program minx  source source source  source source   source dcn dtn source formulate constraint specify definitional domain user allocation decision service decision variable respectively constraint ensures workload user execute collectively server constraint ensures user request service offload task server service server constraint guarantee sum task workload offload server cannot exceed workload upper limit constraint guarantee user perceive delay requirement satisfied complexity analysis proposition user perceive delay aware joint service placement user allocation assignment aim minimize NP proof briefly NP capacitate facility location CFLP reduce CFLP NP  CFLP capacitate facility location suppose customer facility denote demand customer customer demand multiple facility production meanwhile suppose facility production capacity maximum amount facility denote opening facility  shipping facility customer sum facility opening shipping fix demand minimum facility facility customer reduce CFLP instance CFLP reduce CFLP service user perceive delay requirement mathbb consumer demand CFLP mapped user computation demand mathbb facility production capacity CFLP mapped server service workload upper limit mathbb opening facility CFLP mapped service mathbb shipping CFLP mapped server usage consumption mathbb hence NP CFLP reduce mathbb mathbb NP mathbb NP cannot obtain polynomial propose approximate algorithm suboptimal polynomial propose algorithm propose polynomial local algorithm achieves approximation factor delta sufficiently constant delta local algorithm arbitrary feasible repeatedly improves perform local within polynomial local obtain suboptimal achieve desire approximation factor algorithm LP solver mathbb boldsymbol mathcal input output boldsymbol mathcal mathbb boldsymbol mathcal interior polynomial obtain minimize output optimal user allocation decision boldsymbol mathcal LP solver simplify local operation later formulate simplify mathbb mathbb obtain overall user allocation decision boldsymbol mathcal service decision boldsymbol mathcal fix decision boldsymbol mathcal mathbb simplify linear program LP user allocation mathbb boldsymbol mathcal service decision boldsymbol mathcal user allocation decision boldsymbol mathcal minimize boldsymbol mathcal boldsymbol mathcal simplify mathbb boldsymbol mathcal formulate align mathbb boldsymbol mathcal min boldsymbol mathcal quad quad quad quad quad quad quad quad quad tag align source align  quad qquad qquad forall boldsymbol mathcal forall boldsymbol mathcal tag align source align sum nolimits boldsymbol mathcal qquad qquad forall boldsymbol mathcal tag align source align leq qquad qquad forall boldsymbol mathcal tag align source align sum nolimits boldsymbol mathcal leq qquad qquad forall boldsymbol mathcal tag align source align leq qquad qquad forall boldsymbol mathcal forall boldsymbol mathcal tag align source mathbb user allocation decision variable mathbb boldsymbol mathcal furthermore mathbb boldsymbol mathcal LP efficiently interior implement scipy cplex polynomial convenience boldsymbol lbrace boldsymbol mathcal boldsymbol mathcal rbrace service correspond server overall service decision boldsymbol mathcal algorithm input boldsymbol service optimal user allocation decision boldsymbol mathcal besides boldsymbol denote minimize service fix boldsymbol algorithm therefore algorithm obtain optimal service decision boldsymbol mathcal mathbb efficiently local operation obtain optimal service decision local operation service decision boldsymbol mathcal closer optimum local operation introduce concept neighborhood mathbb later definition neighborhood mathbb neighborhood boldsymbol define equation boldsymbol nei boldsymbol lbrace boldsymbol subseteq boldsymbol boldsymbol boldsymbol leq boldsymbol boldsymbol leq rbrace tag equation sourcewhere boldsymbol lbrace boldsymbol mathcal boldsymbol mathcal rbrace apply local approach mathbb feasible correspond boldsymbol service local operation traverse neighborhood boldsymbol feasible boldsymbol minimum boldsymbol nei boldsymbol neighborhood boldsymbol contains polynomial calculate via algorithm polynomial local operation mention perform efficiently definition neighborhood boldsymbol subset boldsymbol sub lbrace boldsymbol subseteq boldsymbol boldsymbol boldsymbol boldsymbol boldsymbol rbrace boldsymbol sub lbrace boldsymbol subseteq boldsymbol boldsymbol boldsymbol boldsymbol boldsymbol rbrace boldsymbol sub lbrace boldsymbol subseteq boldsymbol boldsymbol boldsymbol boldsymbol boldsymbol rbrace local operation swap delete boldsymbol service boldsymbol sub boldsymbol sub boldsymbol sub operation swap delete respectively algorithm local operation input boldsymbol service output boldsymbol bstNeighbor cstReduce boldsymbol bstNeighbor leftarrow  cstReduce leftarrow lbrace boldsymbol mathcal boldsymbol mathcal rbrace boldsymbol boldsymbol boldsymbol cup lbrace rbrace cstReduce boldsymbol bstNeighbor leftarrow boldsymbol cup lbrace rbrace cstReduce leftarrow boldsymbol boldsymbol bstNeighbor algorithm local operation boldsymbol service server traverse neighborhood boldsymbol reduces finally boldsymbol bstNeighbor boldsymbol sub correspond reduction cstReduce swap algorithm local operation swap swap replace boldsymbol boldsymbol service remove service server traverse boldsymbol nei boldsymbol appropriate remove service finally obtain boldsymbol bstNeighbor boldsymbol sub maximize reduction algorithm local operation swap input boldsymbol service output boldsymbol bstNeighbor cstReduce boldsymbol bstNeighbor leftarrow  cstReduce leftarrow boldsymbol prime prime lbrace boldsymbol mathcal boldsymbol mathcal rbrace boldsymbol boldsymbol boldsymbol cup lbrace prime prime rbrace lbrace rbrace cstReduce boldsymbol bstNeighbor leftarrow boldsymbol cup lbrace prime prime rbrace lbrace rbrace cstReduce leftarrow boldsymbol boldsymbol bstNeighbor delete operation delete algorithm swap neighborhood boldsymbol traverse optimal remove service maximizes reduction cstReduce boldsymbol bstNeighbor obtain algorithm local operation delete input boldsymbol service output boldsymbol bstNeighbor cstReduce boldsymbol bstNeighbor leftarrow  cstReduce leftarrow boldsymbol boldsymbol boldsymbol lbrace rbrace cstReduce boldsymbol bstNeighbor leftarrow boldsymbol lbrace rbrace cstReduce leftarrow boldsymbol boldsymbol bstNeighbor local algorithm locus local algorithm locus algorithm initialize service placement decision calculate initial service request user boldsymbol mathcal server locus repeatedly invokes local operation swap delete reduction sufficiently algorithm function polynomial cdot server service worth locus implement operation swap delete invoked locus perform parallel within iteration operation reduce besides operation swap delete operation calculate cdot perform parallel algorithm locus user perceive delay aware service placement user allocation initialize service placement decision boldsymbol  boldsymbol mathcal boldsymbol leftarrow boldsymbol cup lbrace rbrace iterative local optimum local leftarrow false boldsymbol bstNeighbor cstReduce leftarrow boldsymbol cstReduce geq boldsymbol boldsymbol local leftarrow boldsymbol bstNeighbor goto boldsymbol bstNeighbor cstReduce leftarrow swap boldsymbol cstReduce geq boldsymbol boldsymbol local leftarrow boldsymbol bstNeighbor goto boldsymbol bstNeighbor cstReduce leftarrow delete boldsymbol cstReduce geq boldsymbol boldsymbol local leftarrow boldsymbol bstNeighbor local false performance analysis relationship lemma theorem illustrate regard optimization objective approximate guarantee achieve locus theorem complexity theorem relationship propose algorithm theorem convenience boldsymbol sum server usage consumption boldsymbol service placement algorithm apply mathbb boldsymbol mathcal service boldsymbol boldsymbol denote service correspond optimal service decision boldsymbol mathcal analyze approximation guarantee locus refer lemma lemma lemma obtain difference graph capture difference arbitrary boldsymbol mathcal boldsymbol mathcal optimal boldsymbol mathcal boldsymbol mathcal specifically boldsymbol mathcal bipartite graph vertex correspond service user service user along arbitrary boldsymbol mathcal boldsymbol mathcal optimal boldsymbol mathcal boldsymbol mathcal boldsymbol mathcal boldsymbol mathcal whereby difference graph bound reassign computation load currently cached service service cached optimal bound difference described lemma brevity omit detailed proof lemma refer lemma boldsymbol equation boldsymbol boldsymbol cup lbrace rbrace geq boldsymbol tag equation sourcethen equation boldsymbol boldsymbol  boldsymbol tag equation source lemma boldsymbol perform swap delete operation reduce boldsymbol equation boldsymbol frac MS boldsymbol boldsymbol frac boldsymbol MS tag equation source theorem obtain locus delta optimal mathbb sufficiently constant delta proof accord algorithm locus terminates local operation local operation swap delete reduce boldsymbol lemma  satisfied plug equation boldsymbol frac MS boldsymbol frac  boldsymbol frac boldsymbol MS tag equation SourceRight click MathML additional feature inequation equation boldsymbol frac MS boldsymbol frac  boldsymbol tag equation sourcethen inequation plus equation boldsymbol frac MS leq boldsymbol frac  boldsymbol frac boldsymbol MS tag equation  obtain equation frac boldsymbol boldsymbol frac frac MS frac MS frac MS tag equation SourceTherefore sufficiently constant delta satisfy equation delta geq frac frac MS frac MS frac MS tag equation sourcethe approximate optimal obtain locus delta optimal mathbb theorem propose algorithm locus terminates frac ini opt local operation ini initial obtain locus opt optimal mathbb proof local operation perform locus mathbb kth operation perform specifically ini accord algorithm equation geq frac quad forall lbrace ldots rbrace tag equation sourcethus obtain equation frac geq frac frac quad forall lbrace ldots rbrace tag equation  terminates local operation optimal mathbb equation frac ini opt geq frac frac cdot frac cdot ldots cdot frac geq frac frac tag equation SourceRight click MathML additional feature besides accord definition constant mathrm equation frac geq mathrm tag equation SourceRight click MathML additional feature combine  obtain equation leq frac ini opt tag equation SourceTherefore propose algorithm locus terminates frac ini opt local operation polynomial MS locus polynomial complexity analysis evaluate performance propose algorithm locus various setting besides exist approach setting previous multi access compute user server demonstrate raspberry PowerEdge 4G 6GB  user server respectively service counting occurrence specific amount text specific amount text vehicle counting video vehicle traffic surveillance video pedestrian counting video pedestrian traffic surveillance video detection video detects lose surveillance video video mostly derive AI datasets video clip clip video analytics upon yolov testbed mention effectiveness propose algorithm illustration testbed furthermore efficiency scalability locus parameter performance hardware device compute capacity server assign lbrace rbrace  workload upper limit server  specific slot parameter shannon hartley formula refer channel bandwidth mhz background dbm specific slot user transmission sim uplink channel gain dist dist distance user server loss factor beside accord user perceive delay requirement uniformly distribute optimization objective mathbb consists service placement server usage consumption assume almost influence overall optimization objective optimal derive MILP solver cplex  ratio service execute workload consumption average balance impact locus scheme randomize scheme RRS RRS relaxes constraint leq leq calculate fractional integer randomize technique greedy scheme GS traverse user GS determines service placement user allocation user minimizes increase service scheme assume service server solves user allocation mathbb mathcal polynomial remove service server wherever correspond offload task optimal scheme opts opts baseline directly MILP solver mathbb reduction user perceive delay effectiveness locus derive reduction versus iteration increase iteration task offload gradually server service converge however server service easily becomes stable furthermore notion converge closer optimum server service local operation reduce converge optimum approximately guaranteed theorem gradually converge user perceive delay testbed simulation user perceive delay testbed simulation workload task user perceive delay testbed slightly simulation ignore mac queue delay instability server compute capacity model capture testbed comparison induced video related service vehicle counting pedestrian counting detection text related service counting estimate workload task variance video related service significantly text related service video content usually server usage workload task delay requirement workload upper limit workload task delay requirement workload upper limit workload task delay requirement workload upper limit task offload increase average workload task obtain scheme due task workload server usage consumption furthermore workload upper limit server server increase workload service placement average delay requirement increase obtain scheme reduce user server choice besides delay requirement relaxed extent remains almost constant demonstrates impact workload upper limit average workload upper limit average   increase workload upper limit contributes workload server extra service server proven propose algorithm locus achieves approximation ratio actually gap locus optimal scheme opts additionally locus performs RRS GS comparison component focus component service placement server usage consumption user server service server placement contributor obtain RRS scheme RRS service placement decision variable relaxed continuous variable user allocation decision server usage consumption similarly solves assumes service server user allocation decision minimize server usage consumption furthermore locus opts optimize service placement server usage consumption via joint optimization service placement user allocation component user server service comparison calculation finally scheme calculate service placement user allocation decision user server service demonstrate increase user server service calculation tackle RRS opts locus moreover clearly calculation opts obtain service placement user allocation decision grows optimal overall decision exponential user varies calculation opts nearly calculation locus therefore propose algorithm locus stability scalability others scenario scheme user server service conclusion future investigate user perceive delay aware service placement user allocation environment model MEC enable network user perceive delay task offload formulate user perceive delay aware service placement user allocation mixed integer linear program aim minimize task offload due intractability polynomial local algorithm locus achieves provable guaranteed performance finally propose algorithm exist performance locus however limitation future research effort accurate model delay task queue server service placement user allocation decision apply propose algorithm dynamic service placement extra handle service placement decision slot