towards exascale hardware increase diversity architecture performance portability become critical aspect scientific software kokkos performance portable program model allows developer source application diverse performance compute architecture kokkos abstraction compute memory hierarchy hardware novel abstraction kokkos version hierarchical parallelism container task graph arbitrary atomic operation exascale era architecture demonstrate performance feature reproducible benchmark CPUs gpus introduction decade performance compute hpc hardware landscape diversified significantly currently gpu powerful hpc however ranked cpu deploy chip vector machine custom accelerator simply intel CPUs gpu landscape diverse dominate nvidia alone generation upcoming exascale platform deploy amd intel gpus instead become code leverage hpc user access lifetime important hpc application decade exceed lifetime machine demand performance portability explode application developer code leverage future without rewrite code kokkos program model performance portability developed  national laboratory source community project largely fund doe exascale compute project core development span national laboratory publication complex application significant extension program model focus addition developed kokkos version release cycle focus expose parallelism asynchronicity advanced hardware capability relevant fully leverage upcoming exascale era architecture principle development capability leverage advanced hardware feature without hurt performance platform feature furthermore comprehensive kokkos ecosystem developed foundation program model ecosystem commonly capability beyond pure program model linear algebra library infrastructure interoperability layer user description effort elsewhere kokkos program model performance portability library embed approach oppose directive approach openmp OpenACC approach library approach performance portability performance portable library    overlap feature program model comparison feature kokkos  functionality performance comparison kokkos program model  cuda openmp OpenACC detailed comparison approach productivity performance portability beyond scope primary contribution description addition kokkos core program model exascale demonstration flexibility performance program model carefully chosen benchmark cpu gpu architecture unique functionality arbitrary atomic operation portable manner reproducible benchmark instruction reproduce discus primary capability kokkos core program model overview capability introduce previous detail refer discus feature publication advanced reduction kokkos comprehensive atomic operation description kokkos core program model expose parallelism discussion execution instance graph construct enable user express program relationship kernel complex sequential dependency vectorization via simd kokkos overview exist backend finally insight practical performance portability achieve user kokkos user publish benchmark reproducibility information performance benchmark conduct kokkos release candidate version sha  configure release intel skylake nvidia fujitsu  ibm platform amd MI gpus amd CPUs generally cuda intel gcc gcc  compiler platform respectively additionally clang release candidate openmp utilized kokkos cuda backend kokkos hip backend MI kokkos openmp backend openmp CPUs openmp socket hardware thread placement affinity  disabled skylake code data performance plot throughout available http github com kokkos code kokkos core tpds directory benchmark average performance data detailed configuration instruction repository fundamental capability described kokkos performance portable program model implement library abstraction express parallel execution data structure abstraction generic variety backing hardware specific execution memory model kokkos built around core abstraction execution execution execution policy parallel execution memory memory layout memory trait data storage access execution execution generic abstraction execution resource associate execution model parallel operation kokkos enqueued queue instance execution execution instance resource instance encapsulate execution model entity thread handle device kokkos cuda execution instance encapsulates cuda kokkos thread instance encapsulates thread pool kokkos creates default instance execution specific instance associate operation kokkos allows user additional information kernel execute instance absence information assumption kernel sequence program latter program model concurrent progress guarantee efficient schedule kernel default instance others custom incremental migration execution parallel kernel kokkos express execution express relationship independently executable item internal inter dependency described parallel item execute parallel reduce item execute output output combine accord semantics specify reducer parallel scan calculates partial reduction output argument item item potentially execute execution item partial reduction argument function operator defines item kernel index lambda compact user friendly function kokkos execution handle instance callable requirement important fairly restrict program model particularly respect progress relationship item allows maximum flexibility mapping underlie execution model item independent allows execution model mapping thread simd vector pipelined execution item contrast kokkos program model openmp cuda hip detailed guarantee mapped hardware resource typically constrain application semantics lack information guarantee actually mapping diverse execution model execution policy broadly execution policy express execution importantly specify item index execution associate kernel execution policy convey auxiliary information prefer strategy schedule item hint ideal chunk schedule item item index execution policy described  express contiguous dimensional item index expand upon execution policy multidimensional hierarchical parallelism execution abstraction usage execution abstraction user performance portable minimally constrain parallel brevity omits detail typical application usage label kokkos interface described elsewhere kernel item parallel  cuda kokkos lambda int item item   parallel kokkos lambda int sum reduction lambda openmp backend explicit reducer parallel reduce  openmp kokkos lambda int sum output location shorthand reducer sum default reducer parallel reduce kokkos lambda int float compute inclusive scan parallel scan kokkos lambda int int partial sum bool partial sum array kokkos introduce array partial sum memory memory abstract memory resource abstraction analogous execution fundamentally abstraction generically encapsulate mechanism allocate manage memory hardware resource memory abstract away mechanism data memory resource access user function information execution access resource access user  trait memory abstract memory resource allocation mechanism multiple kokkos memory mode access physical resource compile nvidia hardware kokkos     implementation memory abstraction latter actually physical memory  allows gpu access  memory layout memory layout define mapping multidimensional array index storage location memory layout abstraction kokkos domain expert algorithm generic data layout backend data access without complicate algorithmic logic gpus worker behave vector lane generally perform data access coalesce architecture worker cache however data access grouped worker maximize cache reuse sometimes data layout optimal generation hardware due cache thread behavior primary data layout kokkos  fortran style layout  style layout  arbitrary regular stride memory trait another abstraction memory trait convey additional information desire memory access behavior abstraction semantic information access data structure atomic guaranteed aliased access another data structure additionally performance critical non semantic information access specific handle random memory location conveyed availability information allows kokkos leverage data access hardware texture fetch atomic non temporal load instruction available primary data structure kokkos data abstraction intend fundamental data structure replace pointer runtime array behaves multi dimensional pointer algorithmically multi dimensional array ownership semantics reference counting automatic deallocation kokkos parameterized memory memory layout memory trait generic code fundamental data primary template parameter data express scalar dimensionality rank runtime compile extent dimension default memory runtime dimension matrix auto matrix constant slice auto  matrix const 3D  compile auto int  atomic access auto atomic int   atomic advanced reduction ability express custom reduction semantics via init member function user item functor approach poorly  expression item combine kokkos later introduce concept reducer reducer instance potentially user define reference output location defines initialize combine reduction kokkos implementation reducer reduction operation define mpi kokkos reducer sum prod min max minmax  minimum location    logical LOR  wise  reducer maximum int max initial unused parallel reduce kokkos lambda int int max max max max int max kokkos allows user multiple reduction snippet computes maximum sum entry int max int sum parallel reduce kokkos lambda int int max int sum max max sum max int max sum int sum reducer concept flexible  reduction overload implementation simply delegate reducer overload combine reducer wrapper item functor demonstrates performance benefit perform multiple reduction parallel operation oppose reduction individually equivalent implementation openmp perform min sum reduction parallel reduce min sum parallel reduce reducer argument min sum another extension reduction interface allows user data argument directly via reducer instead scalar reduction operation execute asynchronously fence guarantee operation auto int scalar asynchronous invocation output parallel reduce kokkos lambda int int sum sum fence guarantee contains output reduction fence  atomics atomic kokkos already abstract machine specific atomic operation implement arbitrary atomic operation previously limited arbitrary atomic operation implement atomic swap CAS operation kokkos atomic operation distinct arbitrary target hardware operand operation directly atomic instruction implement via CAS loop sharded lock sharded lock address atomically access memory location hash compute index globally accessible lock avoid deadlock implement approach gpus without progress guarantee divergent warp lane nvidia gpus volta amd gpus specifically active lane warp participate spin lock lane associate atomic operation additional warp divergence introduce lock acquisition successful acquisition lock progress guaranteed atomic fetch  ptr val auto apply unsigned mask mask lane unsigned  mask unsigned  bool lane false val loop active lane   lane acquire lock lane acquire lock lock address ptr memory fence memory acquire load operation val ptr dest apply val val memory fence memory release unlock unlock address ptr lane lane  ballot mask unsigned lane return val summary introduction sharded lock arbitrary atomics enables user constrain generic code atomic semantics particularly useful application complex platform atomic operation knowledge implementation atomic operation arbitrary gpus performance scatter algorithm atomic operation int complex float complex operand algorithm mimic discretization algorithm randomly distribute particle contribute contiguous particle contribute grid correspond grid gpus int atomic operation hardware significant throughput CPUs however atomics complex gpus magnitude performance CPUs lock approach complex generally achieves throughput swap atomic operation performance native model complex scalar none cuda hip openmp atomic operation performance scatter algorithm atomic operation scalar container data structure introduce however application develop data structure avoid duplicate effort kokkos core program model container library optimize implementation data structure role container library analogous role standard library fulfills standard introduce commonly data structure ScatterView detail ScatterView ScatterView facilitates implement performance portable scatter contribute algorithm scatter contribute algorithm algorithm entity contributes multiple entity presence concurrent execution conflict particle code particle contributes particle within distance matrix assembly routine finite code multiple contribute entry matrix generally stencil operation contributes something within stencil parallelize algorithm cpu thread resolve conflict data replication strategy however data replication approach scalable gpus thread exceed exhaust memory capacity atomic operation generally resolve conflict gpu architecture atomic operation CPUs algorithm data replication approach primary gpus atomic operation resolve function attach cache cpu architecture atomic operation cache core ScatterView abstract approach within computational algorithm contributes ScatterView contribute sequentially array internally contribution per thread data atomic operation computational kernel user request contribute ScatterView atomic operation amortize mapping data replication ScatterView user accessor inside kernel accessor equivalent  atomic memory trait  thread private data wrap scatter ScatterView data parallel kokkos lambda int auto accessor access int compute something contribute accessor index contribute data reduction ScatterView template argument contribution minimum maximum furthermore user explicitly overwrite atomic operation data replication default chosen target execution associate memory ScatterView performance scatter algorithm ScatterView int complex float complex essentially benchmark ScatterView accumulation instead atomic operation performance atomic operation ScatterView atomic implementation default gpus CPUs performance significant increase atomic operation performance scatter algorithm ScatterView scalar MDRangePolicy initial kokkos release iterate multi dimensional initialization multi dimensional kokkos simply parallelize dimension iterate serially others expose parallelism leverage architecture 3D extent parallelize dimension thread gpu thread implementation recompute individual index global index flatten iteration expose parallelism int parallel kokkos lambda int int int int however non intuitive code specific mapping 1D index 3D hidden kokkos  mapping cod corresponds  iteration performance cpu architecture performance gpus resolve issue kokkos introduces MDRangePolicy capability multi dimensional iteration incorporates iteration scheme furthermore MDRangePolicy directly tile strategy optimize data access stencil operation MDRangePolicy template parameter rank struct templated rank iteration tile iteration within tile MDRangePolicy rank iterate iterate policy iterate 3D within tile iterate index iterate tile index iteration omit chosen architecture default default layout iteration via constant array optionally tile rewrite MDRangePolicy code avoids cod iteration perform compile cpu gpu architecture auto int auto MDRangePolicy rank parallel kokkos lambda int int int impact MDRangePolicy demonstrate 3D tensor MDRangePolicy strictly faster parallelize outer loop flatten index irrespective architecture tensor memory MB outside cache limit gpu parallelize outer index MDRangePolicy parallelism expose flatten index approach significantly due inefficient data access costly integer modulo operation CPUs sufficient parallelize outer dimension tenth thread flatten likely due index scheme obscure data access prefetcher generally native model implementation performance kokkos variant exception native openmp  equivalent collapse clause performance intel compiler outer loop  strategy significantly performance performance comparison tensor operation implementation parallelize dimension outer flatten index flatten MDRangePolicy  hierarchical parallelism MDRangePolicy tightly nest loop loop code loop statement non tightly nest loop dense matrix vector int sum int sum sum rewrite code tightly nest loop directly sum inner loop parallelize algorithm MDRangePolicy thread index index access thread kokkos address enable parallelization nest loop hierarchical parallelism kokkos introduces execution policy TeamPolicy  TeamPolicy outer parallelization TeamPolicy instead thread handle iteration iteration assign thread parallelize nest loop operator lambda functor handle index  TeamPolicy member parallel  TeamPolicy auto kokkos lambda const sum int league rank parallel reduce  int sum sum sum sum handle access function synchronization obtain index rank thread within  policy execution parallelize nest loop interface nest parallel otherwise already introduce label matrix vector mapping assign matrix computes nest reduction TeamPolicy argument launch launch iteration limited actual concurrency target hardware limited implementation detail auto parameter indicates choice kokkos runtime actual heuristic potentially auto tune integration kokkos described heuristic kokkos various account register utilization memory usage request hardware gpus heuristic maximize concurrently active thread gpu occupancy multiple yield occupancy chosen maximize flexibility gpu scheduler opportunity load balance synchronization semantics useful collection thread cache kokkos gpus cuda hip thread core socket CPUs define enable faster coordination within subset  coordination algorithm iteration nest loop completion prior nest loop necessitate barrier loop parallel  TeamPolicy auto kokkos lambda const parallel  int buffer thread barrier sum parallel reduce  int  access buffer randomly sum loop important recognize nest loop actually fork loop thread active upon entry outer parallel nest loop simply split iteration implementation define implies thread exit nest loop independent thread consequently without barrier thread execute loop others another important semantic kokkos thread kokkos progress guarantee kokkos guarantee thread execute legal implementation strategy kokkos hierarchical parallelism split loop synchronization express thread pipelining stage semantics maximum flexibility kokkos hierarchical parallelism various architecture however user kokkos synchronization mechanism legally specifically spin loop kokkos vector parallelism kokkos hierarchical parallelism expose vector parallelism addition thread parallelism access  policy nest request vector parallelism argument TeamPolicy integer auto vector bound hardware resource maximum query TeamPolicy gpus parallelism mapped thread within warp wavefront vector native warp wavefront multiple kokkos thread mapped warp wavefront parallel  nest inside execution  policy nest  policy leverage thread vector parallelism nest parallel parallel reduce parallel scan kokkos impose limit loop parallelize nest parallel reduce label TeamPolicy auto kokkos lambda const int sum int league rank parallel  int buffer barrier stuff parallel scan  int  bool stuff parallel reduce  int  stuff barrier int rank parallel  int something scratch memory TeamPolicy allows acquisition scratch memory leverage explicit scratch pad memory gpus scratch memory request dispatch hip cuda memory kokkos allows scratch memory request per thread per basis contrast hip cuda requirement request per basis kokkos scratch pad cache generally kilobyte memory allows scratch allocation kokkos allows user utilize scratch memory via raw pointer generally scratch memory conjunction  associate scratch memory argument scratch amount scratch memory query static member function function alignment requirement data account user scratch memory per per thread memory scratch  constructor scratch handle argument obtain scratch member function scratch thread scratch user limited scr int   scratch int per byte scr  int per thr byte scr  policy scratch TeamPolicy  policy auto policy scratch  per byte policy scratch  per thr byte parallel label policy kokkos lambda const scratch thread scr scr scratch scratch allocation thread scr scr thread scratch actual memory allocation deallocations memory pool costly within parallel kernel instead function scratch thread scratch constructor function strictly advance internal pointer scratch allocation scratch creation advance scratch pointer beyond  allocation kernel execution fail however scratch integer operation approach code illustrates failure due advance scratch pointer iteration scratch pointer already fail scr int   scratch int per byte scr  policy scratch TeamPolicy  policy auto policy scratch  per byte parallel policy kokkos lambda const int fail iteration scr scr scratch stuff  benchmark demonstrate versatility kokkos hierarchical parallelism sparse matrix vector multiplication spmv operation spmv critical component sparse linear solver commonly kokkos spmv implementation assigns  distributes  across thread vector parallelism perform nest reduction return dot matrix vector parallel TeamPolicy  vector kokkos lambda const int league rank per int per nrows per nrows parallel  int int ptr int ptr parallel reduce  int sum sum col idx kernel tune parameter per vector tune parameter kernel adapt sparse matrix hardware platform performance kokkos conjugate gradient solver minife version spmv kernel  version optimize vendor library spmv kernel matrix kokkos spmv kernel optimize tune parameter outperforms vendor library aggregate performance kokkos spmv algorithm perform matrix sparsity structure expectation kokkos algorithm generally outperforms vendor library worth aggregate achieve bandwidth exceed memory bandwidth due cache bandwidth comparison CG conduction matrix execution instance MDRangePolicy TeamPolicy developer expose grain parallelism sometimes arises express parallelism coarser parallelism functional parallelism cuda hip OpenCL  parallelism exploit multiple command queue kokkos correspond concept execution instance  exec exec kernel concurrently parallel kernel policy exec args functor parallel kernel policy exec args functor kernel exec fence kernel exec fence parallel dispatch kokkos enqueued execution queue execution instance kokkos default instance via singleton specific execution instance execution policy operation enqueued default instance execution kernel compile execution instance reference semantics internal resource scratch buffer duplicate release reference scope dispatch instance user fence member function global non member function fence outstanding active execution instance cuda hip dispatch distinct execution instance parallel progress semantics kernel submit instance overlap execution allows application developer expose functional parallelism compute parallel molecular dynamic application execution instance express dependency kernel user defines explicitly fence kokkos graph factor kernel implementation data movement optimize kernel latency remain bottleneck particularly scenario computational respect available resource desire latency become dominant per parallel latency associate kernel submission driver overhead device schedule becomes signifcant factor software complexity modularity increase kernel diversity decrease kernel increase contribution latency computational estimate potential scope computational challenge around increasingly complex physic sparse conjugate gradient CG solver consists kernel sparse matrix vector spmv dot dot vector  iterative solver iterative application excellent typical particularly acute function  spmv   dot spmv alpha  dot  alpha  alpha  dot sqrt  threshold axpy     iteration  dot twice spmv performance characteristic solver matrix derive regular 3D conduction minife minife derive regular grid matrix contains entry per vector grid grid operation memory access requirement  sizeof dot sizeof spmv sizeof sizeof int specification nvidia gpu TB memory bandwidth 0GB capacity version kernel respectively exclude launch latency iteration solver peak bandwidth however nvidia gpus kernel launch latency amd gpus kernel launch latency kernel launch iteration CG kernel launch latency around percent runtime address latency issue dependent kernel CG solver cuda introduce feature cuda graph cuda graph lazy expression dependent kernel creation graph upfront graph dispatch repeatedly operation dispatch kernel cuda graph dispatch device latency persist however overall average latency reduce relative launch kernel individually kokkos graph functionality performance portable cuda lazily acyclic graph kernel construct graph  reduce latency per kernel kokkos graph explicit creation phase delimit scope immediately evaluate function clearly indicates portion program graph modifiable executable graph graph function function argument node graph graph node typical async future model member function parallel parallel reduce parallel scan generate node dependency precede node function signature normal eager dispatch version kokkos parallel another api function creates across multiple kernel dependency subsequent graph kernel snippet kokkos graph express diamond dependency kernel execute repeatedly auto graph graph exec auto auto parallel scan  auto parallel  auto parallel  auto parallel reduce  threshold graph submit fence simd kokkos parallel semantically   loop hierarchical parallelism express additional parallelism compiler situation kokkos unable sufficiently convey  item compiler explicit expression simd vector semantics scenario algorithm vectorization innermost loop inefficient absence vectorization utilization scalar instruction compiler generally situation refer outer loop vectorization parallel kokkos lambda int vectorize int scenario commonly explicit simd detailed explanation desire capability introduce capability incorporate api propose standard iso parallelism TS distinguish feature standard proposal abi template parameter determines actual implementation simd utilize template parameter extend interface associate storage abi compute abi CPUs storage compute simd actually gpu storage dense array compute scalar variable per gpu warp lane warp parallelism simd operation code illustrates concept distinct storage compute simd simd abi cuda warp native packed simd simd simd abi simd storage simd storage auto data simd storage auto simd storage parallel TeamPolicy simd kokkos lambda const simd tmp int league rank int data extent tmp simd data tmp besides arithmetic math function simd kokkos implementation mask masked operation backends kokkos currently feature serial openmp cuda hip   thread  backends backends coverage exist super computer architecture announce exascale machine  hip  backends almost feature primarily task currently widely application backends optimize fully upcoming exascale machine generally kokkos program model easily  native model mention exploit semantics kokkos cpu openmp backend parallel operation dispatch synchronous openmp parallel synchronous similarly hip equivalent cuda graph kokkos graph simply dispatch kernel latency benefit cuda backend philosophy generally expose advanced capability native program model fallback implementation others kokkos strives subset model aim expose powerful capability wherever performance portability comprehensive practical performance portability application scope conduct summarize generally category comprehensive comparison program model mini apps comparison application kokkos non kokkos version comparison kokkos application hardware performance portability metric developed openmp kokkos cuda OpenACC OpenCL kokkos achieve percent openmp percent overall model worthwhile kokkos achieves performance portability code openmp report  code  legacy non kokkos  another code gamer gamer CPUs nvidia gpus via cuda CPUs  achieves percent  performance faster gamer  faster gamer gpu report performance climate code  kokkos  demonstrate kokkos code actually percent faster cpu node architecture maximum achieve performance node theoretical peak bandwidth normalize skylake roughly implement coulomb solver report achieve peak performance exception intel haswell node achieve percent architecture narrow percent demonstrate kokkos code achieve practical performance portability setting excellent basis upcoming exascale era platform