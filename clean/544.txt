compute mobile internet iot app vendor distribute compute paradigm allows app vendor deploy app hire server distribute app user app user allocate hire server nearby minimize network latency consumption effective user allocation EUA maximum app user minimum overall centralize optimal EUA NP propose EUAGame theoretic approach formulates EUA potential analyze admits nash equilibrium novel decentralize algorithm nash equilibrium EUA performance algorithm theoretically analyze experimentally evaluate EUA effectively efficiently introduction decade mobile internet iot device mobile phone wearable device tablet etc become increasingly popular accord ericsson report predict billion mobile iot device rapid growth advance mobile iot device fuel variety sophistication mobile iot apps refer apps hereafter apps resource hungry computation intensive consumption become increasingly impractical mobile iot device apps due limited compute capacity battery tackle mobile iot device offload computation task utilize configurable powerful compute capacity recent apps emerge latency recognition processing interactive etc cannot fulfill stringent requirement latency sensitive apps due unpredictable network latency expensive bandwidth evident weakness compute paradigm acutely sensitive delay reduce network compute technology facilitates 5G mobile network allows computation task offload mobile iot device server endow compute capacity server physical machine deployed geographically app user app user offload computation task nearby server instead compute paradigm pave apps latency extensive research conduct computation offload compute environment exist research focus latency reduction infrastructure provider mobile iot device perspective critical mobile iot app vendor perspective compute paradigm allows mobile iot app vendor refer app vendor hire compute capacity cpu memory bandwidth server infrastructure provider  etc service deployed server nearby app user latency usually server specific geographical app user within coverage via wireless access server deployed distribute fashion usually cellular geographical coverage adjacent server usually intersect avoid blank server app user intersection nearby server proximity constraint sufficient compute capacity capacity constraint cpu memory bandwidth app user allocate server inappropriate allocation app user allocate server app vendor perspective straightforward important objective maximize user allocate server pricing model app vendor compute capacity server hire infrastructure provider app vendor important objective minimize overall app user refer user allocation EUA compute paradigm enables multi tenancy ability multiple tenant simultaneously application instance allows compute resource multiple tenant efficiently tenancy application instance tenant multi tenant web application achieves throughput tenant workload consolidation user workload enables server utilization compute inherits multi tenancy compute paradigm allows app vendor achieve effective EUA compute environment fully leverage multi tenancy allocate maximum app user minimum server introduce EUAGame theoretic approach EUA theory widely distribute compute powerful decentralize mechanism compute environment app vendor accommodate app user centralize optimal suffer complexity due aforementioned proximity capacity constraint EUA EUAGame eas burden centralize optimization allocation decision app user individually achieve collectively satisfactory allocation addition EUAGame allows app user specify individual differentiate compute capacity dimension EUAGame model app vendor EUA EUA app user simulated player nearby server offload computation task EUAGame employ decentralize algorithm allocation decision app user achieve nash equilibrium contribution model EUA constraint optimization NP centralize optimal EUA distribute manner formulate account app user benefit multi tenancy benefit overall aim maximize allocate app user minimize overall fulfil proximity constraint capacity constraint analyze EUA potential admits nash equilibrium propose decentralize algorithm nash equilibrium EUA analyze performance algorithm theoretically experimentally remainder organize motivates research model formulates EUA decentralize algorithm nash equilibrium EUA evaluates propose algorithm theoretically experimentally review related finally concludes future motivate representative latency sensitive application compute environment mobile mobile resource hungry offload computation remote server platform sony  nvidia shield efficient client device mobile phone tablet however unpredictable network latency remote server player device limit popularity compute tackle limitation computation offload player device nearby server server available app vendor allocate app user server geographical app user outside coverage server cannot allocate server due proximity constraint allocate furthermore app vendor capacity constraint cpu memory bandwidth etc server mega data server limited compute capacity usually multiple app vendor server adequate compute capacity available accommodate app user allocate server available compute capacity server app user capacity  simplicity vector cpu memory storage bandwidth capacity constraint cannot allocate aggregate capacity exceed available compute capacity allocate cannot allocate adequate CPUs accommodate app user cannot allocate server server perform computation task locally offload remote server proximity capacity constraint allocation allocate constraint violate however although app user allocate optimal allocation allocate app vendor hire overall fulfill proximity capacity constraint optimal allocates app user server trivial multi tenancy complicates allocation impact server utilization consequently overall pricing model EUA scenario application compute environment EUA optimal EUA challenge app vendor urgent approach allocate app user effectively efficiently model app vendor EUA aim allocate app user server capacity app user denote ωki cpu memory storage bandwidth available capacity server denote ckj compute investigate EUA quasi static scenario app user remain unchanged allocation capacity location dynamic scenario investigate future introduce user benefit model multi tenancy model model optimization model notation adopt summarize notation notation multi tenancy benefit model tenancy multi tenancy enables utilization compute resource server server accord experimental cpu utilization server approximate   sourcewhere computation task app user allocate server cpu utilization server increase increase multi tenancy enables resource server increase incurs overhead resource handle schedule conflict increase cpu utilization slows converges multi tenant server outperform overall cpu utilization multiple tenant server combine confirm storage utilization multi tenant server improve impact  assume compute capacity multi tenant server memory bandwidth cpu storage multi tenancy benefit server calculate  sourcewhere computation task computation task impact compute capacity specific compute capacity EUA app vendor perspective app app user allocate server offload computation task app specific allocation user benefit model app user allocate server cov source  server refer server server definition allocation decision user allocation decision indicates server allocate denote indicates allocate server definition allocation strategy profile allocation strategy profile app user allocation decision app user perspective saving compute capacity consumption mobile iot device reduction network latency etc ensure infrastructure provider allocate server however app vendor perspective allocation decision app user server allocate impact correspond multi tenancy benefit multi tenancy benefit model allocation strategy profile overall benefit individual allocation decision calculate aggregate saving dimension dλki sai ωki sourcewhere  assign app vendor indicates priority kth compute capacity app user compute capacity dimension app user memory mobile iot device memory compute capacity apps app user capacity app user demand resolution frame rate CPUs memory bandwidth however apps recognition processing user app usually capacity apps ωki  model compute environment app vendor hire compute capacity server infrastructure provider app user app vendor hire compute capacity model incurs hire compute capacity cpu memory storage bandwidth incurs allocation decision user allocation strategy profile multi tenancy benefit model incur define dλki sai ωki dλki ωki SourceRight click MathML additional feature allocate server incur compute capacity originally minus multi tenancy benefit app vendor optimization objective maximize app user allocate hire server app user allocate server perform computation task locally incurs loss benefit app vendor perspective without minimize overall equivalent minimize hire compute capacity app vendor driven allocate none app user server minimize serf app vendor objective maximize allocate app user increase hire compute capacity compute capacity app user therefore allocation strategy profile app vendor objective minimize overall min  source optimization model EUA model constrain optimization cop consists finite variable domain listing variable constraint cop assignment variable constraint fulfil user server cop model EUA formally express maxi source min   cov source ωki ckj source objective maximizes allocate app user otherwise calculates server hire objective minimizes overall constraint coverage constraint ensure user allocate server constraint capacity constraint ckj kth available compute capacity server ensures compute capacity user allocate server exceed server available compute capacity cop allocation strategy achieves objective meantime fulfills constraint achieve optimization objective specific app vendor app vendor budget prioritize objective app vendor lexicographic goal program  technique employ prioritize objective objective EUA generalization classic bin pack classic bin pack infinite bin capacity item objective pack item bin item bin exceed bin capacity item EUA server bin capacity server hardware specification host apps app user app user compute capacity regard item server available compute capacity app user compute capacity usually multi dimensional cpu memory storage bandwidth dimensional vector EUA model variable vector bin pack NP classical bin pack NP variable vector bin pack bin compute environment app user app vendor accommodate user density CBD campus etc app vendor tractable approach EUA user allocation EUAGame theoretic approach EUA adoption theoretic approach threefold app user differentiate pursue theory successfully employ powerful analyze interaction multiple player compute environment employ devise incentive compatible EUA mechanism collectively satisfactory EUA app user incentive deviate unilaterally leverage intelligence individual app user EUAGame attempt EUA distribute manner burden centralize optimal EUA app user allocate available server finally centralize approach decentralize theoretic approach EUA quickly fulfills app user app vendor latency compute environment formulation EUA built decision profile app vendor allocates app user server effective manner decision profile contains decision app user decision app user achieve app vendor objective app user simulated player decision server allocate cov app user allocation decision user app user decision app user decision maximize benefit saving compute capacity  sourcewhere server server EUA formulate app user finite user allocation decision benefit function calculates benefit allocation decision conflict app user allocation app user server prevent app user allocate server server allocate cannot allocate server willing allocate however conflict app user conflict app user mitigate investigate admits nash equilibrium definition nash equilibrium allocation decision profile nash equilibrium app user increase benefit unilaterally allocation decision source EUA admits nash equilibrium significant importance research nash equilibrium app user allocation decision response choice app user lemma nash equilibrium EUA allocation decision user choice response proof lemma appendix lemma ensures nash equilibrium EUAGame enforce EUA enforce upon app user centralize enforcement app user agreement others alleviates centralize approach EUA allows app user quickly EUA EUA investigate existence nash equilibrium EUA EUA potential define definition potential potential potential function sourcefor  definition nash equilibrium EUA interpret decision profile nash equilibrium app user   potential nash equilibrium local optimum potential function proven leveraged chen EUA potential introduce EUA lemma individual capacity constraint allocation decision profile app user compute capacity ωki available compute capacity server ckj allocate app user allocate server   tki sourcewhere tki ckj jfk  ωki source proof lemma appendix lemma constrains kth compute capacity define dλki ckj   ωki source accord app user allocate server multi tenancy benefit indicates utilization compute capacity hire lemma define function dλki sai ωki  sai    source indicator function return otherwise EUA formulate potential function define theorem EUA potential EUA potential potential function proof theorem appendix  allocation mechanism potential admits nash equilibrium important potential finite improvement indicates nash equilibrium potential via finite iteration finite improvement ensures eventually nash equilibrium motivates development decentralize allocation mechanism nash equilibrium formulate EUA analyze mechanism EUAGame employ iterative app user nash equilibrium pseudo code algorithm initial allocation strategy profile server incur decision profile iteration denote calculate  ωki source leverage finite improvement app user improve benefit update allocation decision iteration specifically user calculates update incur update dλki ωki dλki ωki   source optimal allocation decision incurs across sends app user request contend decision update opportunity multiple allocation decision randomly selects iteration allocation app user contest decision update opportunity update allocation decision winner iteration centralize decentralize manner former centralize latter message synchronize calculation iteration allocation perform individual app user parallel app user opportunity decision update update allocation decision iteration iterates app user update allocation decision individual allocation decision constitute decision profile EUA algorithm decentralize EUA allocation initialization chooses server decision initialization compute incur server calculate update decision incurs across contend decision update opportunity opportunity update allocation decision decision update convergence analysis finite improvement potential ensures allocation nash equilibrium finite iteration iteration  ωki qmin min qmax max tmin min tmax max theorem quantification theorem upper bound convergence non negative integer maximum convergence EUAGame maximum decision iteration  qmin   qmin  proof theorem appendix theorem EUAGame converges within quadratic non negative integer exposition experimental demonstrate EUAGame converges rapidly convergence app user server performance evaluation theoretically experimentally evaluates performance EUAGame achieve app vendor optimization objective maximize allocate app user minimize overall theoretical analysis app user allocation decision parallel iteration allocation winner contest decision update opportunity iteration non deterministic manner via random selection therefore multiple nash equilibrium EUA performance EUAGame largely dependent price anarchy PoA decentralize EUA allocation mechanism ratio utility nash equilibrium centralize optimal EUA utility nash equilibrium allocate app user overall PoA allocate app user denote decision profile nash equilibrium EUA denote centralize optimal decision profile decision profile  PoA ratio app user allocate  calculate  mina   mina UI UI sourcewhere   app user allocate respectively theorem PoA allocate app user decision profile achieves nash equilibrium EUA centralize optimal decision profile PoA EUAGame  ratio app user allocate fulfills  tmin qmax tmax qmin source proof theorem appendix PoA overall optimization objective EUA minimize overall analyze PoA EUAGame overall denote decision profile nash equilibrium EUA denote centralize optimal decision profile decision profile  PoA ratio overall incur  calculate  mina uzi uzi source component overall incur hire compute capacity server failure allocate app user server   former latter component overall respectively qmax qmin define define  dλki ωki source  min dλki ωki qmax source  max dλki ωki qmin sourcewhere qmin qmax  dλki ωki definition theorem theorem PoA overall decision profile achieves nash equilibrium EUA centralize optimal decision profile PoA EUAGame  ratio overall achieve fulfills    max   min source proof theorem appendix experimental evaluation conduct effectiveness EUAGame percentage allocate app user overall app vendor optimization objective optimal optimization approach baseline approach originate random greedy app user server optimal solves EUA cop model random allocates app user server adequate available compute capacity greedy allocates app user server available compute capacity EUAGame random greedy EUA become optimal within reasonable amount evaluate efficiency EUAGame discus convergence average iteration EUAGame nash equilibrium important metric evaluate efficiency theoretical approach conduct machine equip intel core processor CPUs ghz GB ram data conduct location user within metropolitan melbourne australia australian communication medium authority  publishes comms license dataset contains geographical location cellular australia location server server usually deployed asia pacific network information centre  IP address allocate australia IP lookup service http api com convert obtain IP address geographical location simulate app user location IP address octet likely identical geographical address return IP lookup service app user uniformly distribute around obtain geographical location coverage server randomly density app user within coverage density central business distinct coverage radius server meter medium density coverage radius randomly meter finally density radius meter raw data publicly available reproduction validation experimental setting comprehensively evaluate EUAGame simulated various EUA scenario parameter app user server available compute capacity server available compute capacity server randomly generate normal distribution detail indicates average compute capacity capacity dimension server average setting setting comparison optimal random greedy demonstrate effectiveness EUAGame impact parameter app user server available compute capacity server overall optimal allocates app user overall optimal EUAGame outperforms random greedy significantly optimal performance loss EUAGame percentage allocate app user overall percent average across EUAGame allocates percent app user percent overall optimal demonstrates performance EUAGame maximize percentage allocate user minimize overall exceeds random greedy EUAGame optimal percentage allocate app user decrease due  competition app user increase becomes overly server accommodate app user meantime increase overall demonstrate compute capacity app user allocate increase server available compute capacity accommodate app user increase hire compute capacity however decrease failure allocate apps user significantly overall decrease overall increase illustrate increase available compute capacity server impact effectiveness approach increase increase trend percentage allocate user decrease trend overall effectiveness versus app user effectiveness versus server effectiveness versus server compute capacity optimal cannot tractable manner EUAGame outperforms greedy random allocate app user overall significantly marginally others average advantage EUAGame greedy random percent allocate app user percent overall phenomenon increase overall achieve greedy random decrease increase increase increase allocate app user illustrate increase greedy random allocate app user server lower multi tenancy benefit exceeds decrease multi tenancy benefit impact overall significantly increase allocate app user overall increase EUAGame account multi tenancy benefit capable accommodate app user overall percent greedy optimal respectively impact overall significantly multi tenancy benefit EUAGame outperforms greedy random significantly percent respectively convergence EUAGame average iteration EUAGame nash equilibrium subset exhibit trend due limit convergence EUAGame increase linearly app user axis convergence EUAGame increase mildly increase app user server increase possibility decision update impact convergence EUAGame significant increase convergence EUAGame increase decrease slightly exceeds increase server app vendor possibility decision update convergence increase accordingly increase EUAGame capable accommodate app user demonstrate becomes app user update decision convergence decrease demonstrate EUAGame parameter indicates efficiency critical application compute environment centralize optimal EUA scenario NP effectiveness versus app user effectiveness versus server effectiveness versus available server capacity efficiency EUAGame related critical limitation mobile iot device limited compute capacity capacity driver promote advance distribute compute paradigm recent compute compute compute compute computation task offload mobile iot device external server deployed limitation mobile iot device compute capacity tackle research effectively efficiently offload computation task refer computation offload active research compute compute computation offload compute computation offload compute extensively investigate decade variety perspective load balance virtual machine placement task dependency etc research focus performance compute representative topology configuration rate allocation access network theoretical approach employ tackle delayed channel information rate allocation objective optimize performance compute aim improve performance compute account pricing information spectrum efficiency wireless network allocation interference management multiple encounter compute environment service price determination resource allocation interference management model stackelberg propose theoretical approach computation offload approach allows app user decision computation offload network latency consumption device computation offload distribute manner computation offload compute compute capable alleviate computation burden mobile iot device however unpredictable network latency mobile iot device remote server become obstacle latency sensitive mobile application cisco propose compute paradigm refer compute fog compute extension compute compute paradigm resource closer app user distribute server across location geographically app user researcher shift attention compute compute propose suite optimal optimal approach network resource allocation compute environment wireless access protocol TDMA ofdma minimize mobile iot device consumption network latency multi channel compute environment propose theoretic approach approach allocates wireless channel server across multiple mobile iot device attempt improve efficiency mobile iot device computation load profile predict user task execution consumption instead mobile iot device efficiency researcher investigate efficiency server infrastructure provider perspective computation offload minimize individual server consumption user constraint computation latency devote effort ensure efficiency server propose online peer computation offload framework server offload computation task active research topic adopt integer linear program technique infrastructure provider deploy server effective manner tackle server deployment objective optimize performance compute server deployment model computation offload convex decompose distribute manner researcher appeal physical equipment improve performance compute propose network architecture hybrid   network connects server server fiber tackle mobile iot device constraint leverage wireless transfer technology computation offload assume user device compute environment harvest various resource solar radiation conventional computation offload transform computation offload compute inherits pricing model compute allows mobile iot app vendor hire compute capacity server infrastructure provider host apps server app user incur app vendor critical compute app vendor customer compute environment unfortunately exist tackle computation offload device infrastructure provider perspective none app vendor perspective effectively user compute environment attempt model important challenge compute environment app vendor perspective refer user allocation EUA aim maximize app user minimum overall app vendor conclusion propose EUAGame novel theoretical approach user allocation EUA app vendor perspective compute environment EUA NP model potential app user allocation decision EUA distribute manner EUA admits nash equilibrium propose decentralize allocation mechanism achieve performance evaluate theoretically experimentally research establish foundation EUA research direction future investigate impact app user mobility trajectory EUAGame app user dynamic participation EUA arrival app user departure exist app user improve EUAGame accommodate app user diverse capacity investigate impact user