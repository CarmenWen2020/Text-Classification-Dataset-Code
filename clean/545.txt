novel paradigm wireless mobile compute WP MEC emerges recently integrates mobile compute MEC wireless transfer wpt technology enables mobile client extend compute capacity task offload server via transmission exist generally focus centralize task schedule WP MEC network decentralization requirement 6G network propose online algorithm computation offload WP MEC network distribute execution manner specifically define delay minimization task deadline constraint transform primal dual optimization bellman equation novel neural model learns offload decision slot formulate optimization execute algorithm  multiple model decentralize server  achieve parameter synchronization theoretical performance analysis algorithm significant advantage comparison representative scheme introduction development sixth generation mobile communication 6G internet iot technology enables ultra latency computation intensive application virtual reality dimensional video become  however mobile client limited compute capability battery lifetime due constraint production technology recently mobile compute MEC wireless transfer wpt regard promising technology relieve conflict application requirement limited terminal resource MEC compute capability mobile client virtually enhance offload computation intensive task server wpt allows mobile client battery frequency RF signal transmit server mobile client signal convert electricity device currently paradigm wireless mobile compute WP MEC introduce integration MEC wpt technology mobile client WP MEC network offload computation task server purpose reduce task competition delay server sustain generally due characteristic duplex offload mobile client simultaneously inevitable issue exists WP MEC network reasonable resource allocation task offload maximize utility mobile client resource allocation mutual impact influence amount harvest mobile client task schedule decision dependent harvest task schedule previous slot inversely impact subsequent slot exist formulate computation offload issue WP MEC network mixed integer program mip optimization convex optimization approximation utilized issue however algorithm execute centralize manner network information schedule decision accord report geographical wireless coverage 6G distribute management millisecond information update rate distribute computation schedule algorithm WP MEC network 6G network however construct distribute due challenge investigate schedule algorithm computation offload server WP MEC network reveal optimization computation offload server centralize manner NP mention multiple server distribute schedule server merely transmission task offload status server mobile client server requirement device consideration transmission unified concurrent pulse increase mobile client however consensus transmission server distribute environment schedule dynamic offload requirement mobile client online manner minimize task completion delay promising reinforcement DRL schedule algorithm advantage ability convergence nevertheless server agent resource schedule decision independently policy agent beforehand meanwhile decision multiple offload choice client none others heavily impact user utility resource allocation policy server carefully challenge propose online algorithm distribute computation offload wireless mobile compute network cop purpose minimize average task completion delay mobile client knowledge distribute computation offload multiple server WP MEC network contribution summarize formulate distribute computation offload issue delay minimization task deadline constraint solvable transform primal dual optimization bellman equation specifically action transition reward formally define formulate markov decision MDP define optimization novel neural model component policy dual network learns offload decision slot execute model distributively reform model multiple decentralize server coordinate achieve parameter synchronization comprehensive theoretical analysis conduct slot perspective upper bound achieve performance exists algorithm convergence guaranteed distribute environment performance evaluation manhattan conduct demonstrate effectiveness algorithm average task completion delay average task completion ratio structure review related model define formulate task schedule MDP online algorithm distribute computation offload WP MEC network performance evaluation finally conclude related review computation offload harvest WP MEC network currently WP MEC categorize involve server majority researcher focus category computation schedule server author investigate binary offload jointly optimize allocation individual task offload mode purpose maximize sum computation rate mobile client online resource allocation algorithm slide propose minimize consumption remote task execution beamforming access task offload compute mobile client jointly optimize online resource allocation strategy propose purpose maximize fairness mobile user lyapunov optimization technology leveraged response delay efficiency WP MEC network investigate random task arrival channel stochastic optimization formulate lyapunov optimization technology utilized purpose maximize profit operator multi user WP MEC network iterative algorithm lagrangian dual propose optimize allocation mobile client data offload task binary partial computation offload mode WP MEC network purpose maximize computation efficiency alternative optimization iterative algorithm jointly optimize offload compute frequency harvest however server along multiple mobile client merely centralize schedule policy addition leverage DRL technology WP MEC network aim minimize online resource management scheme DRL propose task offload server provision decision algorithm unmanned aerial vehicle utilized server mobile client harvest data network minimization data packet loss mobile client data collection decision derive optimal DRL online framework propose binary offload decision accord wireless channel although efficient environment server multiple mobile client focus distribute computation offload multiple server mobile client category schedule server limited related topic due complexity author computation offload schedule multiple server WP MEC network aim maximize computation completion ratio formulate optimization NP centralize approximation algorithm improve performance joint resource allocation task offload algorithm propose mixed  non linear MINLP formulate maximize task offload gain mobile client although focus computation schedule multiple server algorithm conduct distribute manner realize distribute computation offload WP MEC network online schedule algorithm DRL technology novel neural model construct offload decision strategy slot furthermore model reform decentralize server coordinate achieve parameter synchronization knowledge investigate distribute resource schedule WP MEC network coexist multiple server mobile client model definition model define optimization notation notation model objective efficiently allocate network resource minimize completion delay task generate mobile client 2D server denote mobile client coexist server instal BS BSs communicate mobile client orthogonal frequency multiple access ofdma technology subchannel algorithm apply mobile client randomly around harvest wpt server offload task server computation task sequence server horizon slot simplicity without loss generality mobile client generates task slot probability task generate mobile client slot eti  cti maxi  task cti cpu cycle task computation compute cti  cpu cycle maxi task deadline assume task atomic split binary offload decision illustrative model illustrative model mobile client cpu frequency fli server  mobile client leverage duplex transmission wpt task offload simultaneously conduct harvest offload algorithm task schedule mobile client harvest server offload task remote server utilize duration harvest denotes task schedule slot subsection specify detailed delay computation model task completion delay task generate mobile client offload server locally delay task component transmission delay task eti offload server transmission delay mobile client server slot compute lij    transmission rate mobile client server compute shannon formula  blog   channel bandwidth server variable pij transmission mobile client server  wireless channel gain task eti locally transmission delay computation delay task eti locally computation delay obtain cti fli task eti offload server computation delay obtain  cti  delay task sequentially server delay harvest herein delay refers duration task generate locally server sourcewhere slot task eti variable delay processing queue target server slot harvest utilize binary αti denote task eti locally client variable αti vice versa binary  denotes task eti offload server slot consequently obtain completion delay task eti dti  αti  lij  SourceSince computation generally delay return mobile client neglect harvest consumption scenario harvest transmitter multiple receiver transmitter server pulse simultaneously mobile client combine  constructively destructive mode harvest combine individual conversely harvest combine individual constructively mode transmission frequency server fix server regard virtual transmitter server transmit RF mobile client duration slot situation harvest mobile client related transmission frequency transmitter distance transmitter receiver focus reasonably task offload decision adopt linear harvest model simplicity without loss generally harvest client slot express   ratio refer conversion efficiency mobile client downlink channel gain virtual transmitter client transmission virtual transmitter client regard harvest generate task mobile client schedule consume task schedule aspect transmission consume task eti transmit mobile client server compute lij  lij local computation accord task locally client consume computation obtain fli coefficient related efficiency mobile client consume express  αti lij source definition slot mainly harvest task schedule processing harvest server transmit RF mobile client client generate task schedule computation mobile client offload task network offload request generate mobile client broadcast reachable server offload request mobile client server schedule sequence offload task sequence mobile client task schedule mobile client satisfy user computation requirement define delay minimization objective objective minimize average task completion delay slot   source dti maxi source eti source input server mobile client task eti cpu frequency fli  channel bandwidth wireless channel gain  transmission pij conversion efficiency efficiency coefficient output harvest slot offload decision αti  task eti constraint client generate task schedule deadline maxi equation equation satisfied task discard consume task eti satisfy equation remain mobile client slot eti consume processing task eti slot consume client slot exceed remain slot equation satisfied task schedule slot challenge achieve objective centralize network environment task schedule decision strategy harvest task schedule affect performance delay minimization NP mention optimization distribute manner server consensus harvest decentralize environment task offload requirement mobile client schedule suitable server delay minimization local observation server intend policy execute distribute manner achieve objective satisfy constraint task deadline device residual MDP optimization formulation model define delay minimization MDP tuple action reward transition probability discount factor policy utilized action detailed introduction formation MDP MDP component denotes mobile client xti yti  cti  mini  maxi variable xti yti coordinate mobile client slot  data amount local task client slot cti cpu cycle compute task client slot  remain cycle task client slot correspondingly  mini  maxi minimum maximum cycle task client slot respectively obtain data amount    cpu cycle cti    cycle task  define function   otherwise information related communication pij  action action αti  harvest task schedule transition transition probability distribution denote distribution initial transfer action probability reward immediate reward server action objective minimize average task completion delay define   optimization formulation policy minimize average task completion delay perspective maximize accumulative reward define subsection optimization formulate   source constraint sourcewhere optimal formulate MDP optimal policy   however formulate optimization directly apply DRL approach traditional gradient policy although merely action formulate MDP action integer variable output neural network possibility related action actual action addition define action couple impact others duration harvest affect task schedule decision αti  action directly derive neural network model correspond constraint optimization complex delay satisfied transform solvable decentralize environment reward affected action multiple server however centralize management policy server policy independently online distribute computation offload formulate optimization propose online algorithm execute distribute manner transfer server independently policy online algorithm neural network specify initialization action execution batch data collection network training comprehensive algorithm analysis transformation subsection action reward function reformation constraint optimization formulate solvable optimization server action reformation multi server environment resolve directly server chooses action independently decentralize manner redefine action server formulate joint action formulate MDP define action harvest task offload decision αti task schedule decision  server consensus due duplex mobile client remain server decision without awareness others decision couple simultaneously addition agent server suitable offload decision client herein client offload request task agent policy definition definition estimate task processing sequence define processing sequence offload task mobile client server slot    processing sequence offload task mobile client compute  processing sequence task estimate completion task utilize atj action server slot define atj    duration harvest server utilize sequence  instead task schedule decision  task schedule decision network whereas server aware others policy partial observation  decentralize environment multiple offload selection client choice others balance offload choice client server broadcast processing sequence client slot sequence mobile client offload decision αti optimal server  consumption delay constraint constraint relaxation reward reformation server chooses action atj independently reward reward reward server consistent reward define reward server  αti    αti   sourcethus obtain  server policy locally without policy others constraint execution neural network therefore penalty  reward  server expire task update reward becomes   penalty  compute    adjustment parameter expire task mobile client slot reward theorem theorem consistency reward function reward function server consistent reward proof appendix supplementary file computer society digital library http doi org ezproxy auckland tpds solvable optimization formulation DRL algorithm balance exploration exploitation significant agent policy purpose encourage exploration avoid convergence suboptimal entropy regularization utilized bellman optimality augment standard function discount entropy regularizer function    sourcewhere parameter variable regularization entropy  equation degrades standard function equation accord proposition optimal unique equation equation satisfied    equation optimal resolve minv    source although optimization encourages exploration training inner conditional expectation independent sample obtain consequently primal dual optimization equation introduce express minv   sourcewhere parameter variable balance equation global dual variable function compute  source server decision independently policy factorize  atj sourcein addition relax constraint function reform   atj   atj sourcewe define atj   atj atj optimization objective transform minv  atj  atj  atj  atj SourceRight click MathML additional feature parameter transform parametric optimization equation solvable fully distribute parameter parameterized correspond server server local global parameter atj respectively consensus update server local VM server intend independently optimization   atj atj   atj atj  atj VM source algorithm mobile client computation offload request server request server schedule server agent schedule decision mobile client without policy others server broadcast schedule task processing sequence mobile client client schedule strategy server minimize task completion delay server maintains construct neural network locally training server specify neural network initialization server construct neural network correspond optimization parameter dual network optimization parameter network policy network dual network utilized dual parameter atj policy network agent policy atj network utilized predict policy atj equivalent  atj equivalent  dual parameter  equivalent   est atj atj   atj atj  atj source action execution slot server chooses action atj policy server input policy network output atj output possibility server convert processing sequence  mobile client mobile client offload decision selects server computation offload task eti client estimate delay eti processing sequence  estimate local processing delay optimization client argmin  inequation sourceand argmin  inequation sourcethe easily exhaustion  βij βij server processing task eti local compute batch data collection schedule training policy dual network decision trajectory server mini batch predict output dual policy network batch server server local neural network minimize loss batch data model training easy DRL dual primal parameter approximate neural network training utilized neural network inner dual  source dual network expression regard constant training dual network correspond loss function  atj atj  source utilize gradient descent momentum dual network accelerate gradient descent involve velocity vector accumulate direction persistent reduction across batch slot approximate action server batch dual network momentum optimizer conduct consensus update    sourcewhere wji matrix server others momentum coefficient variable   vector algorithm pseudo code training server input batch initial policy policy parameter dual parameter parameter output policy  sample mini batch transition atj  server compute gradient optimization parameter equation update vector   related dual network     update parameter equation sample mini batch transition atj  server compute gradient parameter equation update vector   related network     update parameter    update parameter adam optimizer policy network   SourceRight click MathML additional feature dual network utilize momentum optimizer network adam optimizer policy network momentum optimizer adam adaptive estimate gradient gradient optimization parameter derive partial derivative consensus update conduct parameter parameter consistently update others server policy independently output policy network regard action related harvest others related action server selection training server cop algorithm algorithm respectively algorithm analysis subsection comprehensive theoretical analysis cop algorithm regard server agent formulate optimization decentralize manner output harvest schedule queue task processing theory task schedule theorem upper bound task completion delay fix actual completion task eti schedule broadcast server slot remain mobile client sufficient schedule task eti    lij   max  lij    qti   optimal server task processing mobile client  estimate processing sequence task eti server variable  task  proof appendix supplementary file available online supplemental theorem upper bound average task completion delay mobile device sufficient schedule offload task upper bound average task completion delay achieve algorithm obtain dmax limt TN  αti  source proof appendix supplementary file available online supplemental addition online algorithm converge stationary definition definition lipschitz continuous gradient function bound differentiable lipschitz continuous gradient inequation parameter satisfy dimensional euclidean definition detailed information lipschitz continuous gradient algorithm pseudo code cop algorithm input mobile client communication related information output average task completion delay dti slot mobile client broadcast offload request task server action atj model algorithm compute harvest compute task schedule broadcast estimate processing sequence  mobile client mobile client offload task remotely correspond server task locally compute average task completion delay dti define server systematic perspective optimization  sourceand  sourcewhere analyze algorithm convergence theorem algorithm convergence neural network dual policy network totally slot mini batch training online algorithm converges stationary rate function approximators utilized neural network training atj lipschitz continuous gradient     obtain stochastic gradient estimate bound proof appendix supplementary file available online supplemental performance evaluation simulation setup demonstrate feasibility cop conduct tensorflow python illustrate utilize manhattan performance validation server uniformly distribute without movement actually walker rider mobile terminal mobile client along manhattan mobility model simulated horizon slot repeatability individual activity setting simulated parameter simulation parameter structure algorithm manhattan manhattan addition rayleigh fading channel model wireless channel gain server mobile client compute  ΦX  generally define herein xij distance server mobile client   channel gain channel fading shadow respectively vector CN leverage multi layer perception distribute online fully layer construct policy dual network respectively softmax activation function momentum optimizer adam optimizer function utilized neural network exist distribute computation offload multiple server mobile client WP MEC network cop algorithm scheme CoCoRaM centralize task schedule algorithm server mobile client approximation algorithm reasonable allocation task schedule WP MEC network aware schedule eas algorithm leveraged algorithm whereas task schedule mobile client server minimize consume random computation offload rco algorithm mobile client randomly server task offload local compute LC task mobile client without offload duration harvest slot simulation performance mobile client illustrates performance average task completion delay CoCoRaM eas rco LC algorithm cop mobile client average task completion delay cop algorithm algorithm aim minimize average task completion delay online schedule algorithm CoCoRaM algorithm centralize schedule algorithm WP MEC network solves generalize assignment schedule task fix harvest utilizes approximation algorithm derive harvest however merely minimum local computation client performance optimization correspond performance algorithm although eas attempt minimize consume mobile client rco randomly selects server offload without reasonable schedule RC algorithm merely depends computation capability mobile client delay mobile client increase average task completion delay algorithm become mobile client offload task consequently task consume computation resource delay performance mobile client performance average task completion ratio mobile client illustrate herein task completion ratio refers ratio task successfully generate slot performance average task completion ratio cop eas rco LC algorithm CoCoRaM algorithm CoCoRaM algorithm maximizes task completion ratio define optimization centralize manner whereas algorithm aim minimize task completion delay algorithm distribute manner task schedule algorithm mobile client server minimum delay task performance consume mobile client mobile client obvious eas algorithm minimum consumption mobile client schedule eas algorithm server minimize consumption task offload maximize task completion ratio consume task transmission processing CoCoRaM algorithm consume mobile client cop CoCoRaM algorithm eas algorithm performance server average task completion delay server obvious performance algorithm average task completion delay cop minimum CoCoRaM algorithm eas rco LC server becomes performance cop CoCoRaM eas rco LC algorithm increase server computation resource utilized task processing average task completion delay reduce computation resource however performance LC algorithm almost server becomes task locally without offload computation resource mobile client performance server illustrates performance average task completion ratio server server becomes average task completion ratio cop CoCoRaM eas rco LC algorithm increase server source mobile client harvest computation resource utilized task processing performance consume mobile client algorithm illustrate server becomes consume mobile client decrease server mobile client offload task nearer server reduces consume transmission task impact task generation possibility illustrates impact task generation possibility performance trend average task completion delay illustrate average task completion delay increase task generation probability becomes task generation probability average task completion delay cop CoCoRaM eas rco LC algorithm respectively task generation probability average task completion delay algorithm respectively task generate task generation probability becomes task schedule server fix average task completion delay becomes performance task generation possibility trend average task completion ratio task generation possibility task generation probability becomes trend average task completion ratio instance task generation probability average task completion ratio cop CoCoRaM eas rco LC algorithm respectively task generation probability increase average task completion ratio algorithm respectively task exist computation communication resource consume task however task average task completion ratio addition trend average task completion ratio algorithm impact harvest efficiency performance harvest efficiency illustrate average task completion delay algorithm cop performance algorithm algorithm intend minimize average task completion delay reasonable online schedule algorithm however CoCoRaM algorithm performance merely approach optimal schedule slot although centralize approach performance average task completion delay algorithm harvest efficiency becomes average task completion ratio algorithm gradually become due sufficient harvest performance harvest efficiency performance trend average task completion ratio algorithm harvest efficiency increase average task completion ratio algorithm become harvest efficiency average task completion ratio cop CoCoRaM eas rco LC algorithm respectively harvest efficiency increase average task completion ratio algorithm respectively harvest task local compute remote transmission performance execution convergence illustrates execution algorithm execution algorithm cop maximum eas tightly execution LC algorithm minimum cop algorithm neural network periodically action trajectory consume eas algorithm training neural network execution however CoCoRaM rco LC algorithm training LC algorithm totally depends local compute merely task local compute queue rco randomly selects available server CoCoRaM algorithm approximate optimal computation schedule wpt WP MEC network complexity rco LC algorithm mobile client becomes execution algorithm becomes client generate task task consume schedule performance execution convergence convergence algorithm algorithm eas neural network training eas utilizes training merely evaluate convergence convergence acceptable execution mobile client becomes convergence algorithm increase client generate task algorithm execution becomes longer correspondingly conclusion propose online algorithm computation offload WP MEC network distribute execution objective minimize average task completion delay mobile client perspective define delay minimization task delay constraint transform primal dual optimization bellman equation formulate optimization efficient novel neural model task offload decision simultaneously model execute distribute manner multiple model decentralize server coordinate achieve parameter synchronization theoretical analysis performance algorithm significant advantage average task completion delay algorithm convergence