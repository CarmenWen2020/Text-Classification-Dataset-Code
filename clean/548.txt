mobile compute envision promising approach augment computation capability mobile device emerge resource hungry mobile application propose theoretic approach achieve efficient computation offload mobile compute formulate decentralize computation offload decision mobile device user decentralize computation offload analyze structural admits nash equilibrium decentralize computation offload mechanism achieve nash equilibrium quantify efficiency ratio centralize optimal numerical demonstrate propose mechanism achieve efficient computation offload performance increase introduction smart phone gain enormous popularity mobile application recognition processing interactive augment reality emerge attract attention mobile application typically resource hungry demand intensive computation consumption due physical constraint however mobile device resource constrain limited computation resource limited battery tension resource hungry application resource constrain mobile device hence significant challenge future mobile platform development mobile compute envision promising approach address challenge illustrate mobile compute augment capability mobile device resource hungry application offload computation via wireless access resource infrastructure amazon elastic compute EC azure service platform mobile device associate clone virtual machine VM execute mobile application behalf mobile device illustration mobile compute although approach significantly augment computation capability mobile device user task develop comprehensive reliable mobile compute remains challenge challenge achieve efficient computation offload coordination mobile device user critical factor affect performance mobile compute wireless access efficiency mobile device user offload computation via wireless access simultaneously generate severe interference reduce data rate computation data transmission hence efficiency computation offload data transmission beneficial mobile device user offload computation adopt theoretic approach address challenge theory useful framework decentralize mechanism mobile device user organize mutually satisfactory computation offload decision organize feature  mobile compute burden complex centralize management information collection massive mobile device user computation offload schedule moreover mobile device usually individual pursue theory powerful analyze interaction multiple mobile device user devise incentive compatible computation offload mechanism mobile user incentive deviate unilaterally specifically model decentralize computation offload decision mobile device user mobile compute decentralize computation offload propose decentralize computation offload mechanism achieve nash equilibrium contribution decentralize computation offload formulation formulate decentralize computation offload decision multiple mobile device user decentralize computation offload account communication computation aspect mobile compute analysis structure analyze decentralize computation offload homogenous heterogeneous wireless access homogenous admits beneficial compute structure guarantee existence nash equilibrium heterogeneous potential hence admits finite improvement posse nash equilibrium decentralize mechanism achieve nash equilibrium devise decentralize computation offload mechanism mobile device user decision locally significantly reduce signal overhead mechanism achieve nash equilibrium decentralize computation offload quantify price anarchy PoA efficiency ratio mechanism centralize optimal numerical demonstrate propose mechanism achieve efficient computation offload performance increase organize discus related introduce model propose decentralize computation offload develop decentralize computation offload mechanism respectively numerical finally conclude related previous investigate efficient computation offload mechanism perspective mobile device user demonstrate significant computation offload  lee developed adaptive offload algorithm execution application introduce efficient timeout scheme computation offload increase efficiency mobile device propose tier architecture improve performance scalability mobile compute propose lyapunov optimization dynamic offload algorithm improve mobile compute performance meeting application execution realistic measurement wireless access role affect performance mobile compute propose prediction decision framework offload computation outperform local execution mobile device efficient offload policy jointly configure frequency mobile device schedule data transmission minimize consumption knowledge address computation offload multiple mobile device user scenario multiple user wireless network bandwidth maximize mobile compute performance centralize heuristic genetic algorithm consideration user mobility information propose centralize greedy scheme computation offload multiple mobile user propose centralize schedule algorithm jointly optimize communication computation resource allocation multiple user latency requirement centralize computation offload scheme mobile device user submit information wireless channel gain computation task centralize entity offload schedule accordingly along adopt theoretic approach devise decentralize mechanism wherein mobile device user computation offload decision locally reduce signal overhead model introduce model mobile compute collocate mobile device user computationally intensive delay sensitive task exists wireless access mobile device user offload computation amazon EC microsoft azure previous mobile compute mobile networking enable tractable analysis useful insight quasi static scenario mobile device user remains unchanged computation offload within across mobile user depart dynamically within computation offload future communication computation aspect role mobile compute introduce communication computation model detail communication model introduce communication model wireless access wireless access wifi access femtocell network access macrocell cellular network manages uplink downlink communication mobile device user denote computation offload decision mobile device user specifically user chooses offload computation via wireless access user decides compute task locally mobile device decision profile mobile device user compute uplink data rate computation offload mobile device user wlog    SourceHere channel bandwidth user transmission wireless access accord algorithm denotes channel gain mobile device user denotes background interference interference mobile device user wireless transmission involve mobile compute communication model mobile device user offload computation via wireless access simultaneously incur severe interference data rate discus latter negatively affect performance mobile compute computation model introduce computation model mobile device user computation task compute locally mobile device remotely via computation offload denotes computation input data program code input parameter involve computation task denotes cpu cycle accomplish computation task mobile device user apply obtain information discus computation overhead consumption processing local compute approach local compute local compute approach mobile device user executes computation task locally mobile device  computation capability cpu cycle per mobile device user mobile device computation capability computation execution task local compute   sourcefor computational   sourcewhere coefficient denote consume per cpu cycle accord realistic measurement  accord compute overhead local compute approach computational    sourcewhere   denote computational mobile device user decision respectively model flexibility user specific demand user parameter decision user battery user consumption  decision user application sensitive delay video user processing  reduce delay dynamic user application policy demand computation offload exposition assume user fix within computation offload compute compute approach mobile device user offload computation task execute computation task behalf mobile device user computation offload mobile device user incur extra overhead transmit computation input data via wireless access accord communication model compute transmission mobile device user offload input data respectively tcn  sourceand ecn  source offload execute computation task fcn computation capability cpu cycle per assign user execution task mobile device user tcn exe  SourceRight click MathML additional feature accord compute overhead compute approach processing   tcn tcn exe  SourceRight click MathML additional feature neglect overhead computation outcome mobile device user due application recognition computation outcome computation input data mobile setting program code input parameter accord communication computation model computation offload decision mobile device user couple mobile device user simultaneously offload computation task via wireless access incur severe interference data rate data rate mobile device user consume wireless access offload computation input data incur transmission beneficial user compute task locally mobile device avoid processing consumption compute approach adopt theoretic approach address issue achieve efficient computation offload decision  mobile device user  computation offload develop theoretic approach achieve efficient computation offload decision  mobile device user primary rationale adopt theoretic approach mobile device individual pursue theory powerful framework analyze interaction multiple mobile device user devise incentive compatible computation offload mechanism user incentive deviate unilaterally moreover leverage intelligence individual mobile device user theory useful devise decentralize mechanism complexity user organize mutually satisfactory burden complex centralize management reduce signal overhead mobile device user formulation decentralize computation offload decision mobile device user within computation offload computation offload decision user user user decision user decision local compute compute minimize computation overhead consumption processing  SourceAccording obtain overhead function mobile device user   source formulate strategic mobile device user player strategy user overhead function user function minimize player sequel decentralize computation offload introduce concept nash equilibrium definition strategy profile nash equilibrium decentralize computation offload equilibrium player reduce overhead unilaterally strategy source nash equilibrium nice stability user equilibrium achieve mutually satisfactory user incentive deviate important decentralize computation offload mobile device individual existence nash equilibrium decentralize computation offload proceed introduce important concept response definition strategy player player strategy response source accord nash equilibrium user response strategy towards concept response observation decentralize computation offload lemma strategy mobile device user decentralize computation offload response user threshold strategy  otherwise sourcewhere threshold        exe source proof supplementary file computer society digital library http doi org ezproxy auckland tpds accord lemma interference  beneficial user offload computation otherwise user compute task mobile device locally wireless access critical role mobile compute discus existence nash equilibrium decentralize computation offload homogeneous heterogeneous wireless access homogeneous wireless access user wireless access homogenous   correspond scenario mobile device user channel assign transmission however user threshold heterogeneous computation capability task homogenous wireless access without loss generality mobile device user LK LK  useful observation lemma decentralize computation offload homogenous wireless access exists non empty beneficial compute mobile device user  sourceand ljk SourceRight click MathML additional feature strategy profile wherein user strategy user strategy nash equilibrium proof supplementary file available online user LK LK LK LK beneficial compute LK construct beneficial compute algorithm theorem decentralize computation offload homogenous wireless access nash equilibrium specifically LK user strategy nash equilibrium LK construct beneficial compute algorithm strategy profile wherein user strategy user strategy nash equilibrium proof supplementary file available online computational complexity operation quicksort algorithm typically nlogn construction procedure algorithm involves operation operation complexity beneficial compute construction algorithm computational complexity nlogn implies compute nash equilibrium decentralize computation offload homogenous wireless access manner wireless access user wireless access heterogeneous   mobile device user transmission channel gain threshold analysis beneficial compute homogenous cannot apply hence resort potential definition potential admits potential function nai SourceRight click MathML additional feature source definition player action action response update function decrease source appeal potential admits finite improvement asynchronous response update player update strategy finite nash equilibrium potential function spirit lyapunov function dynamical dynamic lyapunov function stable similarly admits potential function nash equilibrium existence nash equilibrium decentralize computation offload potential specifically define potential function     sourcewhere indicator function otherwise theorem decentralize computation offload potential potential function hence nash equilibrium finite improvement proof supplementary file available online theorem implies asynchronous response update guaranteed nash equilibrium within finite iteration motivates algorithm  computation offload mechanism propose decentralize computation offload mechanism algorithm achieve nash equilibrium decentralize computation offload mechanism motivation decentralize computation offload mechanism coordinate mobile device user achieve mutually satisfactory decision prior computation task execution mechanism utilize finite improvement decentralize computation offload mobile device user improve computation offload decision specifically signal wireless access synchronization slot structure computation offload decision update decision slot consists interference measurement mobile device user locally interference  generate user currently decision offload computation task via wireless access facilitate interference measurement user decision slot transmit pilot signal mobile device user enquire interference decision update contention exploit finite improvement mobile device user decision update decision slot user improve computation performance compete decision update opportunity decentralize manner specifically accord lemma mobile device user computes response update interference otherwise sourcethe response steepest descent direction selection reduce user overhead user improve user contend decision update opportunity otherwise user contend adhere decision decision slot decision update contention adopt random backoff mechanism decision update contention contend user generates backoff accord uniform distribution countdown backoff timer expires timer expires user request update  message mobile device user user update decision slot broadcast  message user decision update contention user hearing  message update decision decision slot accord finite improvement theorem mechanism converge nash equilibrium decentralize computation offload within finite decision slot implement computation offload decision update terminates  message broadcast multiple consecutive decision slot decision update user mobile device user executes computation task accord decision obtain decision slot mechanism due nash equilibrium user incentive deviate achieve decision important decentralize computation offload mobile device individual decentralize computation offload mechanism user adopt response improve decision  eventually organize mutually satisfactory nash equilibrium analyze computational complexity algorithm iteration mobile user execute operation operation involve arithmetical calculation computational complexity iteration suppose iteration algorithm converge computational complexity algorithm CN numerical iteration convergence increase linearly user demonstrates decentralize computation offload mechanism converge manner performance analysis discus efficiency nash equilibrium decentralize computation offload mechanism decentralize computation offload multiple nash equilibrium propose decentralize computation offload mechanism randomly nash equilibrium random user chosen decision update definition PoA theory quantify efficiency ratio nash equilibrium centralize optimal nash equilibrium decentralize computation offload PoA define PoA     sourcewhich bound PoA implies nash equilibrium efficient centralize optimum benchmark        exe theorem PoA decentralize computation offload  min   source proof supplementary file available online intuitively theorem indicates user local compute  nash equilibrium closer centralize optimum hence PoA moreover communication efficiency  hence  performance nash equilibrium improve numerical demonstrate nash equilibrium decentralize computation offload mechanism efficient percent performance loss centralize optimal numerical evaluate propose decentralize computation offload mechanism numerical mobile compute scenario mobile device user randomly scatter wireless access wireless access channel bandwidth mhz transmission  background dbm accord physical interference model channel gain distance mobile device user cloudlet loss factor decision   computation task recognition application data computation offload KB cpu cycle  cpu computational capability  mobile device user randomly assign ghz computational capability fcn ghz dynamic mobile device user computation propose decentralize computation offload mechanism mechanism mobile user decrease converge equilibrium verify convergent equilibrium nash equilibrium dynamic potential function decentralize computation offload demonstrates propose decentralize computation offload mechanism potential function minimum nash equilibrium accord potential dynamic user decentralize computation offload mechanism dynamic potential function decentralize computation offload mechanism investigate impact computation decentralize computation offload implement simulation cpu processing cycle compute task upon comparison implement local mobile compute mobile device user compute task locally mobile device compute  decentralize computation offload local mobile compute increase cpu processing cycle increase however compute  decentralize computation offload increase local mobile compute cpu processing cycle increase mobile device user utilize compute via computation offload mitigate local compute compute cpu processing cycle evaluate impact communication data decentralize computation offload implement simulation data computation offload compute  decentralize computation offload data computation offload increase due data overhead computation offload via wireless communication moreover compute  decentralize computation offload increase slowly data computation offload data computation offload mobile device user compute task locally mobile device avoid computation offload via wireless access compute data computation offload compute data computation offload benchmark performance decentralize computation offload mechanism implement compute minimization centralize optimization   centralize optimization information mobile device user detail compute task transmission channel gain cpu frequency mobile device decentralize computation offload mechanism mobile device user interference decision locally mobile device user randomly scatter respectively average compute compute computation offload increase mobile device user increase propose incentive compatible computation offload reduce percent compute user local compute compute respectively centralize optimization performance loss decentralize computation offload mechanism percent demonstrates efficiency propose decentralize computation offload mechanism evaluate convergence decentralize computation offload mechanism average convergence increase linearly mobile device user decentralize computation offload mechanism mobile device user critical compute centralize optimal computation offload involves integer program decision variable computational complexity grows exponentially mobile device user increase average compute iteration decentralize computation offload mechanism evaluate signal overhead reduction decentralize computation offload mechanism signal message exchange mobile user user demonstrates decentralize computation offload mechanism reduce signal message percent centralize optimal computation offload scheme decentralize computation offload mechanism mobile user exchange message interference measurement decision update announcement update computation decision centralize optimal computation offload scheme mobile user report local parameter transmission channel gain background interference local computation capability parameter moreover application scenario due privacy concern mobile user sensitive reveal local parameter hence incentive participate centralize optimal computation offload scheme decentralize computation offload mechanism issue mobile user computation offload decision locally without expose local parameter signal message centralize optimal decentralize computation offload mechanism conclusion computation offload decision mobile device user mobile compute propose decentralize computation offload formulation admits nash equilibrium homogenous heterogenous wireless access decentralize computation offload mechanism achieve nash equilibrium quantify PoA numerical demonstrate propose mechanism efficient increase future mobile user depart dynamically within computation offload user mobility important role formulation