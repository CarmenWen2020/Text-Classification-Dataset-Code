numerical algorithm engineering application sparse triangular linear sptrsv costly stage considerable research dedicate efficient implementation almost performance compute platform graphic processing gpus strategy perform operation translate handful routine establish priori routine automatic procedure solver matrix entail performance benefit extends previous effort rely machine technique predict sptrsv routine matrix improve accuracy selection procedure specifically focus efficient machine technique regard training prediction stage evaluate artificial generation sparse matrix expand dataset propose heuristic compute approximation expensive feature experimental strongly improve runtime procedure without compromise quality keywords graphic processor sparse triangular linear performance machine introduction numerical linear equation iterative involves decomposition triangular factor LU factorization incomplete LU preconditioner iterative sparse triangular linear sptrsv important building sparse numerical linear algebra throughout sptrsv kernel implement almost relevant parallel platform however data dependency arise operation complicate efficient parallel routine moreover sparse kernel operation computational intensity irregular data access attain performance gpus exception adoption commodity hpc hardware numerous effort performance implementation sptrsv platform review literature exist software library conclude successful effort generally belong schedule paradigm performance report author paradigm linear others direction identify matrix predict solver paradigm execution however analysis perform matrix conclusion limited evident later machine model automatically sptrsv routine characteristic sparse matrix specifically evaluate application technique bundle classification learner app matlab krylov subspace solver target analysis phase applicable phase perform triangular linear furthermore explore matrix feature classifier quality prediction subset experimental evaluation previously reveals procedure attain prediction accuracy approach recently author effort extends purpose improve performance selection procedure contribution extension sptrsv realization address extra specifically solver bundle version  library  novel solver domino synchronization strategy  domino enhance information machine technique machine strategy consume runtime training prediction stage acceptable accuracy inclusion additional metric experimental evaluation machine technique previous accuracy prediction instance average relative difference runtime predict relative runtime error  ratio aggregate runtimes predict aggregate runtimes metric detect model performs badly instance artificial sparse matrix generation data augmentation sparsity completely determines performance triangular solver aim model realistic datasets SuiteSparse collection however available sparse matrix derive machine technology training matrix perform random perturbation approach generate training maintain characteristic sparsity heuristic reduce runtime related computation costly matrix feature apply evaluate procedure sptrsv solver address precondition conjugate gradient PCG iterative incomplete factorization  preconditioner structure review aspect gpu implementation sparse triangular linear revisits machine application context later detail experimental evaluation highlight important description extension application automatic selection procedure context precondition krylov subspace solver finally conclude remark summarizes future parallel sparse triangular linear linear triangular matrix vector sought typically sparse matrix sparse storage format csr compress sparse importance computational kernel motivates development efficient routine processor architecture however sparse linear algebra performance sptrsv challenge task due combine irregular data access computational intensity additionally data dependency load imbalance due triangular structure parallelization operation challenge widespread adoption massively parallel processor gpus hpc community exploitation parallelism sptrsv motivate considerable research effort experimental analysis perform author confirms proposal performance linear others successful routine numerical literature integration widely software library belong approach refer schedule respectively detailed description strategy remarkable implementation paradigm csr sparse matrix format previous  routine representative implementation strategy schedule variant nan additional sptrsv routine specifically solver bundle version  library  solver domino synchronization strategy relies information implement routine  analysis  policy  invoke routine policy automatic selection effort rely classification learner app matlab obtain supervise machine model apply sptrsv implementation matlab module technique namely decision discriminant analysis vector machine ensemble classifier along revisit previous feature arithmetic precision matrix dimension nonzeros nnz maximum non zero per average non zero per standard deviation non zero per average bandwidth locality  locality previously feature costly compute others nnz obtain sparse matrix data structure compute dimension matrix furthermore computation perform analysis phase variant computational phase linear therefore evaluate performance model feature cheaper extract feature available machine model perform fold validation estimate accuracy model unseen data dataset imbalanced accuracy model percentage correctly classify instance sufficient performance classifier hide selection deliver performance minority however stage metric valid insight reveals machine model deserve detailed analysis additionally account training inference technique preliminary evaluation employ dataset described decision classifier perform classifier training prediction model classifier reasonably accuracy knn offering accuracy prediction comparison knn accuracy faster prediction although training substantially decision magnitude difference application accuracy prediction training model classifier learner app dataset predictor  pred sec sec decision  medium coarse    svm quadratic cubic gauss medium gauss coarse gauss  medium coarse cosine cubic  bag subspace  subspace knn  ensemble classifier analysis accuracy prediction decision knn classifier discriminant analysis classifier vector machine perform badly perform exhaustive evaluation focus perform model decision knn accuracy prediction specifically bound accuracy observation per knn model advance experimental evaluation description model binary decision binary decision structure inner node recursively split dataset partition accord attribute terminal node leaf outcome classification observation complies splitting attribute correspond training model node split impurity compute subset training dataset corresponds node subset partition accordingly partition training dataset respective node decision cart algorithm gini diversity index impurity split criterion powerful machine technique distance function observation correspond majority algorithm parameter variation approach assign heavier nearby observation influence classification away experimental evaluation revisit initial perform aim evaluate efficiency classification algorithm sparse triangular linear solver hardware platform runtime evaluation sptrsv variant linear dataset machine perform server equip intel xeon cpu core ghz GB ram nvidia gpu GB ram operating centos linux core cuda toolkit gpu version employ matlab classification initial dataset perform experimental evaluation matrix medium dimension SuiteSparse matrix collection formerly florida matrix collection  triangular sparse matrix dimension nonzeros previously addition triangular solver described solver bundle version  library   solver initial analysis phase perform replace runtimes solver runtime execution analysis phase plus iteration solver phase solver iteration solver purpose emulate application krylov subspace iterative solver scenario analysis significant impact alternative completely overshadow execution phase employ float representation precision experimental classification initial perform analysis chose decision wKNN compromise accuracy training prediction model maximum depth gini diversity index apply split criterion wKNN euclidean distance inverse distance computation matrix feature maximum nonzeros blur gain obtain prediction therefore feature exert influence accuracy machine model impact feature ass diminish predictor without affect accuracy model significantly remove predictor later discard remove predictor finally eliminate predictor compute nnz considerable computational predictor imply computation costly analysis sparse matrix summarizes exclusion feature attain accuracy model accuracy model compute fold validation dataset accuracy average runtime error perform fold validation ML model exclude feature training displayed feature excludes locality   excludes feature exclude excludes feature exclude  excludes feature exclude   acc      besides prediction instance accuracy interested analyze prediction application relevant misclassify solver difference runtime predict solver routine introduce metric ass quality model define average runtime error compute relative runtime error  compute runtime predict runtime observation dataset  respectively aim reflect average relative error prediction individual instance hide model perform badly instance impact  summarize discard feature uniform remove feature deteriorates improves accuracy model however feature impact prediction evident  metric model runtime overhead predict routine dataset increase iteration iteration whereas wKNN correspond increase feature exclude moreover exclusion feature significant impact  suggests relevant performance solver matrix relatively relative difference runtime predict solver absolute difference runtime  obtain wKNN model predict solver entire dataset runtime optimal iteration variant iteration however report solver considerably  routine dataset runtime optimal iteration respectively  obtain entire dataset triangular solver solver iters iters     baseline nan improvement strategy extend previous specifically address reduction runtime feature computation detail employ heuristic estimate feature imply computation later data extension procedure sparse matrix generation improve feature detection previously mention aim effort reduce runtime application rely sparse triangular linear automatic selection sptrsv routine matrix procedure effective machine model accurate prediction prediction overhead target application training stage becomes negligible overhead procedure compose aspect computational prediction runtime computation matrix feature input machine model aspect contemplate selection machine technique inference stage regard feature involve computational explore possibility reduce runtime related computation feature evaluate impact substitute expensive approximate propose heuristic compute estimation estimate maximum standard deviation nonzeros obtain maximum nonzero sparse matrix csr format traverse vector pointer consecutive entry obtain correspond procedure compute approximation reduce computational heuristic partition vector pointer partition partition average nonzeros per compute obtain reduce maximum return estimate maximum nonzeros evaluate obtain variant heuristic partition max partition max partition max heuristic recursive binary recursion nonzero procedure partition return non zero algorithm receives parameter procedure explore recursion evaluate heuristic denote max max max respectively although procedure implies partition procedure faster matrix binary algorithm obtains accuracy outperform procedure execution estimate standard deviation nonzeros per procedure analogous max max variant std std accuracy model feature replace approximate compute combination heuristic accuracy model dataset approximate significant difference respect obtain balance accuracy computational combination heuristic max std combination achieves accuracy computational combination employ max std performance model replace feature   approximate return heuristic   std max std max std max std max std max std  std max std max std max std max std max std  std max std max std max std max std max std  std max std max std max std max std max std improve prediction accuracy previous dataset training consist subset sparse matrix SuiteSparse matrix collection sparsity matrix completely determines performance triangular solver numerical role therefore purpose model realistic dataset assume nonzero likely scenario others however dimension training dataset critical machine technique although SuiteSparse collection comprehensive widely benchmark traditional validation sparse routine sparse matrix collection dimension training machine application training data augmentation insufficiency instance towards generation random sparse triangular matrix however suspect purely random training immensely machine model effective realistic nonzero ultimate goal instead generate random datasets instance matrix perform random perturbation intend generate training maintain characteristic sparsity implement matrix generator integer input initialize random sequence assigns non diagonal nonzero index random index previous nonzero index remain increase achieve datasets randomness parameter nonzeros modify generator datasets matrix dimension nonzeros nonzeros per instance dataset bandwidth drastically generator commences perform procedure pointer vector csr structure matrix integer pointer random previous subsequent assigns random index non diagonal nonzero modify respect increase index triangular structure matrix besides matrix feature randomize generator varies feature maximum standard deviation nonzeros per generator random datasets rand generator modifies index nonzero entry rand generator modifies nonzero entry rand generator modifies nonzero entry dataset contains randomize version matrix initialize random sequence perform fold validation dataset wKNN model simulate iteration execution triangular solver performance model validation datasets variant max std    rand wKNN wKNN rand wKNN wKNN rand  wKNN wKNN model remarkably performance extend datasets accuracy ratio exceed negligible  however largely explain overfitting difference feature random version matrix significant variety dataset perform validation instance instance training ass performance model extend datasets dataset random training performance model radically comparison validation random dataset improvement strategy training matrix combine randomness performance model extend datasets predict instance dataset    rand wKNN wKNN rand wKNN wKNN rand  wKNN wKNN evaluation ass effectiveness approach application precondition conjugate gradient PCG iterative incomplete factorization  preconditioner implies sparse triangular linear iteration PCG analyze runtime entire iteration obtain sptrsv implementation previously runtime obtain sptrsv implementation predict optimal knn model symmetric positive definite spd matrix dataset machine dataset spd matrix model label observation sptrsv implementation perform analysis phase plus phase respectively feature training prediction phase dimension nonzeros nnz estimation maximum standard deviation nonzeros per max std characteristic matrix report characteristic spd matrix employ machine approach context PCG iterative solver    std  hood    thermal 2G circuit 3G circuit apache   parabolic fem ecology cube sphere  TC  TK  offshore   bundle adj implementation PCG  code distribute nvidia cuda toolkit adapt precision criterion iteration maximum iteration norm residual iteration majority iteration PCG closer instance iteration converge explains performance model simulation phase moreover matrix routine render performance execution variant machine model predicts variant fails estimate accuracy performance slightly compute attain significant speedup regard runtime PCG solver perform sptrsv correspond computation precondition residual iteration pred pred triangular solver predict wKNN model runtimes phase respectively   PCG      pred instance iteration prediction model runtimes phase considerably phase counterpart obtain matrix former model adapt latter however specific matrix deeper ideally desirable estimation iteration matrix convergence behavior iterative explore future remark future propose automatic procedure perform gpu implementation sptrsv sparse triangular linear proposal evaluation machine strategy careful linear feature compute selection address perform brief revision technique previous effort operation gpus specifically identify sptrsv routine csr matrix format experimentally evaluate performance sparse triangular linear simulate application krylov subspace solver runtime phase fictitious iteration initial datasets apply machine technique bundle matlab later perform detailed wKNN relation accuracy prediction initial datasets apply solver predict wKNN model matrix runtime apply solver average performance ass importance feature model performance progressively remove feature training prediction stage relevant feature related later particularly important sparse matrix medium aim improve performance model accuracy enhance accuracy construct datasets generate additional sparse matrix random perturbation perform validation extend datasets yield accuracy however training model extend dataset prediction improve procedure replace feature costly compute approximate obtain cheaper heuristic procedure estimation significantly degrade accuracy model regard heuristic max std combination obtain remarkably accuracy computational effort combination finally automatic selection procedure context krylov subspace solver spd matrix SuiteSparse collection performance PCG sptrsv routine performance obtain routine predict wKNN model matrix routine performance execution variant machine model fails predict routine accuracy performance slightly compute significantly outperform future extend investigation along evaluate develop sptrsv gpu rely sparse storage format conventional csr csc explore strategy effective randomize datasets avoid overfitting arose effort develop heuristic costly feature evaluate performance machine model additionally intend parallel implementation feature model computation procedure inference stage perform gpu finally evaluate incorporation analytic machine model estimate priori iteration krylov subspace solver apply procedure effectively