collaborative CDL utilizes feature capability neural network model fitting robustness performance recommender dramatically data sparse however model training become maintain recommender amount data variety unpredictable arise collaborative parallelization improve model CDL CDL item private node aim item content optimization collaborative propose improve SDAE basis CDL private network node network parameter model private bias item network item content parameter target manner thereby enhance detection performance model item content recommender furthermore algorithm parallelize splitting model parallel training CDL propose transplant spark distribute cluster parameter model optimize parallel enhance scalability data model multiple datasets verify effectiveness efficiency propose parallel CDL algorithm previous keywords collaborative CDL recommender parallel compute spark introduction motivation nowadays due rapid growth information rapid generation data recommender vital role obtain effective information timely manner interact information identification distinguish sort data recommender filter useful massive information greatly simplifies information selection recommender machine algorithm personalize recommendation collaborative filter recommendation however collaborative filter user item newly due insufficient historical information fails analyze significant reduction recommend performance addition significant shortcoming data sparsity model scalability extremely sparse matrix extremely available information rate calculation operation mostly invalid operation recommender collaborative filter model computational super linear increase user item enrichment information expansion data faster faster foreseeable improvement hardware performance rapid expansion amount data become bottleneck contemporary complex operation multiple iteration characteristic recommender demand requirement compute performance gradually gpu core machine multi device parallelism distribute data processing platform expand compute capability compute distribute platform enormous expansion definitely component integrate multi parallelism compute develop apply recommendation scenario massive amount compute data CDL collaborative distribute compute platform inevitably become feasible choice insufficient compute resource amount data massively complex operation become important scenario complex recommendation massive amount data data internet richer richer redundant information become extract effective information important practical significance recommendation algorithm introduce parallel research contribution improvement CDL algorithm model model CDL CDL item private node CDL propose parallel research CDL algorithm conduct rely apache spark distribute compute platform CDL algorithm parallelize improve recommender data information scalability recommender era data CDL construct multi layer bayesian model combine representation auto encoder item content feedback information collaborative filter matrix CDL improve rough detection item content propose CDL model combine multiple data prof CDL improves traditional recommendation introduces parallel improvement algorithm spark platform contribution briefly summarize CDL improve CDL model propose account difference item content category item privatization node introduce CDL differential training CDL retains unique bias item improves performance algorithm content detection recommend item user recommendation improve privatization bias amount combine item basis CDL parallelization algorithm analyze parallel CDL training propose model split parallel training shorten data data parallel adopt model data sub model collaboratively calculate improve model capacity algorithm scalability combine spark distribute compute platform implement parallel training algorithm obtains series experimental data objective data analyze data researcher verify effectiveness model improvement improvement parallel research algorithm performance thereby reflect significance distribute compute recommender obtain highly scalable parallel CDL model related recommendation algorithm mainly recommendation collaborative filter CF demographic recommendation content recommendation collaborative filter widely recommendation technology attract widespread attention researcher direction essence collaborative filter user assist recommend judgment target user collaborative filter technology mainly neighborhood collaborative filter model collaborative filter collaborative filter matrix factorization MF popular model collaborative filter matrix factorization obtains rank user feature matrix rank feature matrix user matrix factorization obtain rank matrix matrix unobserved user item prediction improvement apply matrix factorization non negative matrix matrix factorization matrix locality matrix factorization recommender matrix factorization important factor user feature matrix feature matrix feature prediction popularity social medium researcher socialize recommender utilizes social relationship user effective social network user relationship information improve effectiveness recommendation hao propose interpretable probability factor analysis model rank matrix user combine user matrix user social trust network similarly hao introduce socialization regularization optimization function matrix factorization regularization feature factor similarity target user predict target user paid attention socialization regularization effectively utilizes user social relationship improves recommendation recent technology proven data feature representation processing computer vision recognition apply technology recommender feature representative user feature feature researcher apply recommender apply recommendation recommendation scene item technology detect express content item generate recommendation combine traditional classification technology recommendation technology combination climax personalize recommendation mainly sparseness scalability sparseness personalize recommendation extent discover abstract feature data infer internal connection item user user item researcher alleviate limitation recommender zhang built distribute vector neural network user item distribute expression user vector item vector neural network thereby improve recommendation liang propose encode neural network model probabilistic unsupervised feature user implicit feature discover encode network implicit vector expression prefer user generate combine model collaborative filter personalization recommendation  propose collaborative filter algorithm boltzmann machine recommendation netflix effectively utilize external information wang propose hierarchical bayesian model collaborative CDL content information combine collaborative filter obtain matrix combine recommendation content DBN extract content feature improve accuracy recommendation satisfactory progress user behavior serialize information entire recommendation serialize information conduct research detection serialize data rnn cod neural network reduce dimension feature matrix achieve improvement data recommendation algorithm operation efficiency exist prof feature recommender representative effective data sparseness recommender improve performance application data recommender complex sparse collaborative filter matrix filter effective feature information research effectiveness recommendation algorithm practical data application background CDL recommendation algorithm CDL recommendation CDL collaborative recommendation improve CDL algorithm paradigm combine algorithm collaborative filter algorithm applies recommender improves performance recommender improves recommendation previous research neural network independent algorithm content recognition recommend item feature extraction CDL training content item user matrix improvement recommendation algorithm CDL  introduce CDL paradigm stack reduction auto encoder machine probability matrix factorization active structure algorithm respectively collaboratively calculate content recommend item matrix recommendation stack denoising auto encoder stack denoising auto encoder SDAE feedforward neural network learns raw data output data superimpose obtains input data without superimpose feature SDAE derives input data superimpose input data without superimpose almost feature superimpose data robust generally implicit layer constrain bottleneck entire input layer data superimpose SDAE solves optimization remove namely regularization parameter frobenius norm output layer network image KB image SDAE schematic diagram image KB image schedule spark SDAE obtain robust identity function feature expression feature extraction robust generalization performance contrast SDAE gradient explosion gradient dispersion therefore layer AE sufficient obtain feature tends shallow network structure matrix factorization traditional collaborative filter infer user recommend related item without content information item contrast model collaborative filter implicit factor model achieve model neighborhood algorithm achieve performance mainly focus matrix factorization related algorithm implicit factor model implicit factor model matrix factorization algorithm perform recommender algorithm matrix factorization user item rank factorization matrix exist matrix item implicit vector obtain factorization matrix multiplication operation data continuous adjustment implicit vector accurate obtain matrix factorization model recommendation calculate relevant parameter model user vector item vector implicit usually exist user data matrix perform matrix factorization parameter implicit vector calculate optimize regularization parameter respectively MF achieve predictive performance recommender somewhat insufficient dimensional vector interpretative performance MF sensitive specific user specific item lack historical performance data MF cannot obtain startup information model cannot failure relationship user data loss addition recommender matrix factorization probabilistic model prior expert introduce algorithm algorithm model upgraded probabilistic model generally expert priori implicit vector matrix factorization algorithm priori probability probabilistic matrix factorization PMF PMF solves model factorize exist matrix prior implicit vector perform constraint data estimate maximum posterior distribution exist data distribute platform parallelization distribute memory compute framework propose apache spark retains scalability fault tolerance compatibility mapreduce shortcoming mapreduce application due memory cluster compute spark application faster mapreduce distribute unified schedule role generally manager compute node worker parallel program worker calculate relatively independent parallel manager uniformly schedule manages statistic multiple mechanism protection distribute platform data processing organically combine various spark deployed hadoop cluster environment yarn resource management ability directly access hdfs file spark mapreduce intermediate calculation hdfs spark calculation memory hdfs frequently greatly reduces IO operation improves algorithm operation efficiency greatly reduces algorithm operation addition spark optimize acyclic graph dag greatly improves IO efficiency platform data recovery node abnormality distribute environment schedule spark improvement CDL recommendation algorithm CDL model CDL model private bias node item propose unique bias input layer SDAE item network parameter model unique bias item network content parameter item specifically training CDL algorithm CDL item data auto encoder learns extract content obtain content vector integrate bias vector item information recommender matrix factorization prediction sort calculate recommend addition model training data sample positive sample increase gap positive negative sample improves model performance evaluates model recommend definition model improvement implicit feedback training data literature improve performance recommender defines data item dimensional matrix content vector correspond item dimension vector user item dimensional matrix user positive feedback item otherwise encode neural network respectively denote input input raw data output layer network auto encoder dimensional matrix dimensional matrix matrix bias vector layer network respectively matrix layer neural network matrix bias vector probability graphical model PMF initialization PMF model series operation matrix factorization apply collaborative filter define probability graphical model model generation PMF probability graphical model obtain initial sample vector parameter gaussian distribution standardize parameter confidence correspond maximum posterior estimation model consistent reliability actual observation situation user interested project feedback consistency strategy satisfy super parameter adjust model predict building PMF model coordinate descent model parameter model model converges image KB image probability graphical model PMF definition PMF model probabilistic matrix factorization user initialize implicit user vector item initialize implicit item vector item user initialize feedback probability graphical model CDL literature SDAE integral algorithm private item node model model construction described layer SDAE matrix layer array matrix sample obey distribution deviation vector layer sample obey distribution described data data matrix layer sample accord input data perform initialization operation operation accordance respectively initialize model input obey distribution initialize bias node item comply private node unique item network implicit bias vector item accord implicit vector item obtain implicit vector user initialize user accord initial matrix user item sample accord super parameter model confidence user item matrix matrix assign accord channel contact user content information efficient expression implicit relationship item efficiency account infinity probability graphical model CDL description CDL algorithm construct model accord author obtain initialization model prior probability accord training algorithm consistent CDL optimize finally entire model optimize convergence model model obtain CDL improves model CDL algorithm CDL CDL training user item implicit vector coordinate gradient descent adjust PMF bias vector correspond item PMF adjust SDAE optimize accord PMF strip adjust item bias vector implicit expression item correspond output SDAE propagation adjust neural network objective function CDL objective function CDL algorithm calculate maximum posterior probability probability model data equivalent calculate joint maximum likelihood objective function parameter infinite adjustment strategy PMF model training vector consist user confidence parameter user item matrix matrix CDL algorithm parameter update SDAE traditional propagation matrix update bias vector update prediction algorithm approximation equation obtain previous theoretical basis CDL algorithm obtain item private node model training initialization node item independent identical distribution node calculate model node update image KB image CDL parallelization spark parallel training CDL adopts mixed mode data parallel model parallel model SDAE PMF distribute training spark framework parallel training model machine algorithm data parallel communication interaction parameter exchange function logically abstract parameter server logical concept parameter server exist independent model storage attach training terminal node distribute calculation node model splitting node model data coexist parameter server schedule node model parameter update parameter formula distributes update parameter increment node accepts parameter correction training node update iterates model training CDL PMF SDAE data parallel mode respectively ensure model node model CDL exists cluster training distribute addition SDAE data parallel mode modularly encapsulate slice data distribute node maintains network iteration PMF specific parameter update initialization phase algorithm data distribute accord location avoid abnormal increase model training data skew data partition randomly fragment distribute data load memory ensure compute node approximately balance load addition data phase data operation characteristic spark perform shuffle operation within partition ensure randomness data model CDL parallel training described detail parallel diagram PMF training perform adjust batch data batch data PMF parameter constant SDAE data reduces data memory overhead reduces IO although impact calculation accuracy improves efficiency model training model training manager performs operation distributes initialization parameter worker node model configuration regularization parameter random worker data independently random initialize correspond parameter random ensures initial neural network worker consistent worker data shard training model SDAE item content information data PMF user data model training continuously iterate ensure sample obtain data calculate image KB image CDL parallel diagram worker data perform model training performs reduce operation fuse calculation node reduction operation define worker uploads calculate model parameter manager manager average parameter distributes fusion parameter correspond model SDAE PMF respectively node perform renewal iteration iterate ensure worker fully ensure data training involve training model finally model obtain manager algorithm image KB image algorithm parameter model fuse average network parameter average operation parameter matrix model SDAE PMF correspond bias node due highly sparse characteristic recommendation data response erroneous information invalid calculation sparse data model sparsely optimize parallelization CDL input output layer neural network training sparse operation perform data correspond node network screen sparse indicator function target model training perform avoids error information zero data unknown data reduce amount calculation network training model convergence achieve experimental evaluation cluster node task submission configuration core driver memory GB executor memory GB data hdfs spark version data preprocessing CDL data namely CiteULike CiteULike netflix CiteULike CiteULike separately CiteULike CiteULike document tag website allows user personalize personal library document user user personal library summary title information document data article collection filter however user data deletion selection filter user document personal library data CiteULike user literature item recommendation CiteULike user literature recommendation user literature correspond matrix user item CiteULike contains collection operation convert matrix data sparsity CiteULike contains collection correspond matrix contains data netflix netflix prize recommend  data data user rating movie netflix literature convert user implicit feedback operation considers positive feedback user item exclude user positive evaluation movie without content information user movie retain dataset contains user data sparsity data massive replicates user dimension expands data obtains massive data comparative analysis CDL performance recommendation average precision recall rate recall evaluation index optimize recommendation definition average precision namely accuracy average accuracy definition calculate average accuracy rate author calculate average AP user definition recall rate recommendation recommendation user adoption item refers item user positive feedback indicator function item adopt otherwise model SDAE structure measurement CDL network activation function configure implicit layer identity output layer sigmoid loss function logistic network activation function implicit layer sigmoid output layer sigmoid loss function logistic network activation function implicit layer identity output layer identity loss function network activation function implicit layer sigmoid output layer identity loss function comparison CDL obvious advantage SDAE recommendation accuracy SDAE CDL performance recommendation    CDL training CDL combine item content information training discover implicit relationship user item essential accurate item information  combine portrait collaborative filter user model parameter adjust target manner thereby improve accuracy model recommendation CDL aim optimization optimization objective function data binary reduction processing information retain data conducive CDL recommend SDAE data sum CDL obvious advantage accuracy recommendation auxiliary information item content improve performance recommendation addition CDL compose SDAE performance neural network impact performance model combine previous assumption conduct comparative CDL model compose SDAE network layer performance increase hidden layer positive performance model however layer increase performance model improve conclude hidden relationship user item recommendation relatively layer network fully hidden layer layer model performance nearly stable comparison recall rate CDL data average experimental data CDL performs SDAE CDL approach convergence earlier improvement CDL improve algorithm recommendation performance extraction item content obtain relatively recommendation performance situation source data comparison sample density item content vector comparison model structure comparison data sum CDL improve CDL recommendation image KB image performance CDL analysis CDL parallelization analysis sequential experimental algorithm spark scala spark data load operation optimize calculation storage massive data accordingly experimental performance computer compute resource analyze implementation pure linear library advantage disadvantage realize spark distribute platform optimization limited compute resource processing data overhead iteration model training calculate experimental scala data overhead processing data scala script spark data overhead processing data spark node scala model spark model overhead algorithm implement scala spark parallel algorithm respectively algorithm spark slight loss accuracy performance dimension recommendation accuracy rating prediction accuracy loss sequential version error definition accepted margin error optimization spark platform advantage amount data resource overhead spark improvement sequential algorithm model scalability memory overflow calculation exponential increase algorithm sequential version spark algorithm stable overhead resource application spark disk operation greatly expand data handle amount compute fix resource algorithm spark improvement amount data machine algorithm greatly improves compute machine compute image KB image calculation data volume analysis parallel performance spark parallel algorithm sequential algorithm sequential previous article performance spark parallel algorithm surpass performance sequential algorithm fully verify scalability data parallel algorithm spark cluster conduct performance sequential algorithm alone spark algorithm algorithm cluster experimental sample copying data ensures data cluster data calculation amount algorithm multi node compute obvious performance advantage node compute node proportional relationship data amount data increase amount data overhead alone increase leap bound amount data increase overhead uncontrollable rapid increase data node processing limit overhead becomes  image KB image performance comparison parallel algorithm sequential algorithm firstly upper limit data amount distribute algorithm sequential algorithm secondly overhead distribute algorithm significantly node algorithm node increase overhead advantage gradually becomes prominent finally conclude comparison gradual increase amount data overhead steadily increase increase amount data linear trend explosive growth scala model obvious advantage conclusion traditional collaborative filter algorithm entry performance algorithm sharply historical data historical data scarce amount information insufficient addition traditional recommendation algorithm massive data combine model calculation depth collaborative parallelization propose CDL model improve SDAE basis CDL private network node item private bias node item network parameter network item content parameter  improves detection performance model recommendation addition increase data split CDL model propose parallel training parameter model optimize parallel enhance data model handle future research focus improve training efficiency model