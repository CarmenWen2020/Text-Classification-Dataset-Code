machine distribute data client important application data privacy concern central data storage option recently federate propose assumption data centrally worker architecture worker perform machine data merely aggregate model without raw data unlike parameter server approach gossip decentralize alternative federate aggregation server indeed central component hypothesis gossip strictly efficient federate due rely infrastructure message passing resource empirical examine hypothesis systematic comparison approach experimental scenario churn trace mobile phone continuous bursty communication network distribution training data device evaluate additional technique compression technique sample token account gossip examine aggregate machine approach surprisingly gossip variant perform comparably federate variant overall fully decentralize alternative federate previous keywords federate gossip decentralize machine introduction perform data mining data device importantly mobile phone data central location become problematic due novel data protection due increase public awareness issue related data handle increase raw data device distribute aggregation google introduce federate challenge approach parameter server architecture distribute worker node raw data parameter server maintains model regularly distributes worker calculate gradient update server server applies update central model model converges federate framework optimize minimize communication server worker local update calculation thorough compression technique apply upload update server addition federate gossip propose address challenge approach fully decentralize parameter server node exchange aggregate model directly advantage gossip obvious infrastructure failure gossip enjoys significantly cheaper scalability robustness however approach performance address approach convergence model quality assume approach utilize amount communication resource scenario interested communicate approach achieve model quality linear model stochastic gradient descent sgd logistic regression loss function experimental methodology involves scenario smartphone churn trace application  communication continuous bursty network addition evaluate assumption label distribution worker bias unbiased subset training sample comparison approach mainly communication however computation local update identical approach apply subsampling reduce communication approach introduce federate adapt technique gossip introduce token account mechanism gossip bursty communication approach mechanism explicit privacy protection apart feature data federate secure aggregation protocol whereas gossip apply described concerned efficiency communication security mechanism comparison gossip comparable centrally coordinate federate approach counter intuitive suggests decentralize algorithm treat citizen distribute machine overall additional advantage decentralization thoroughly revise extend version conference publication novel contribution relative conference publication evaluation scenario involve bursty traffic node communicate bandwidth burst scenario continuous communication potato chain message without increase average bandwidth presentation evaluation novel application token mechanism gossip bursty transfer scenario introduction subsampling technique partition model partition parameter partition technique beneficial token algorithm experimental scenario network additional variant compress federate  downstream traffic compress subsampling thorough hyperparameter analysis outline machine gossip federate logistic regression gossip federate respectively novel algorithm token account mechanism model partition technique decision evaluate algorithm component experimental setup apply datasets model discus hyperparameters describes experimental scenario algorithm variant related concludes machine concise summary machine concept concerned classification data consists feature vector correspond label dimension label parameter function correctly classify outside latter generalization express formally minimize objective function loss function error prediction regularization regularization coefficient stochastic gradient descent sgd popular approach initial vector apply update rate update update random logistic regression machine model specific objective function loss function likelihood data probabilistic model parameter bias model apply model fitting optimization evaluate logistic regression restrictive however practical applicability linear model greatly extend context transfer arbitrarily complex pre machine model feature extractor linear model dataset linguistic application become popular approach bert pre model approximate performance training entire complex model dataset resource gossip image KB image gossip machine approach fully distribute data without central assume data horizontally distribute node node shard task collectively machine model emulates data centrally discus notion gossip node algorithm node initializes local model subset model parameter periodically another node network node receives parameter sample merges model performs local update synchronize although node message immediately variant algorithm implementation simplest sends entire model sample computes average performs mini batch update local data later define sophisticated implementation node selection peer sample service application utilize peer sample service implementation obtain random sample participate node implementation service approach random gossip static overlay network random repair assume static random overlay network optimization gossip algorithm interrelate briefly optimization sample instead model node subset parameter technique compression mechanism bandwidth model partition related sample instead random subset define fix partition model parameter subset sample token account information organize enhancement communication without increase message overall technique interrelate token account along sample compression implementation model partition imperative motivation model partition discus technique random sample model partition implementation implementation return uniform random subset parameter defines sample precise sample randomly dimension vector implementation partition model parameter elaborate model partition model vector bias partition define partition assign vector index partition index sample partition return partition precisely partition index return partition bias sample implementation important stress random sample apply without model partition define combination partition random sample sample partition explore possibility image KB image upon model node merges local model update local data combine local model incoming choice implement average parameter vector theoretical finding linear model communication partition implementation algorithm computes average model implementation subsampled input parameter actually sample partition apply partition parameter vector parameter crucial apply communication explain later model vector partition bias image KB image algorithm implementation model input account partition model partition dynamic rate partition token gossip previous introduce token account algorithm improve efficiency gossip protocol application intuition token account algorithm allows chain message network potato budget node limited due mechanism implement token account potato avoid cycle node token account approach apply merge gossip omit introduction entire token account algorithm instead focus novel variant applicable algorithm image KB image important algorithm implementation sample preliminary random sample effective along token account technique sample independently hop strongly formation potato message chain fix model parameter insight partition approach allows potato message chain partition benefit sample compression potato message passing accordingly partition node token account available token apart extension algorithm gossip difference message reactively reaction model define return probability proactive message function token return reactive message implementation parameter previous maximal token account maximum indeed proactive message parameter role reactive proactive message interpret motivation token token reactive message proactive message positive probability account empty reactive message proactive message account partition account partition perform random independently communication budget model update independent partition gossip partition previously connection merge update function argue gossip benefit partition although lesser extent partition algorithm without compression sample entire model mention implement sample without replacement initialize pool available option becomes empty slightly sample replacement variance federate image KB image image KB image image KB image federate specific algorithm framework compute discus federate algorithm presentation contains adjustment modification accommodate contribution gossip federate pseudocode federate algorithm algorithm worker periodically sends model worker asynchronously parallel worker version algorithm communication compress sample parameter vector rate sample downstream message algorithm upstream message algorithm although reflect pseudocode presentation clarity sample algorithm index model worker selects exactly index incoming sample worker delay simply discard elapse aggregate gradient update model maintain model average training fashion dynamic rate local algorithm although version algorithm sends model worker grain subset worker model worker limited budget communication avoid worker indeed scenario experimental evaluation option pseudocode clarity presentation algorithm generic characteristic federate detail update algorithm aggregation mechanism algorithm update typically implement minibatch gradient descent algorithm operates local data initialize model implementation identical gossip algorithm partition model sample described algorithm function aggregate sample gradient implementation algorithm implementation unbiased estimate average gradient implies actual sample simply average gradient compute improve version average coordinate separately average coordinate sample accurate estimate average coordinate however unbiased estimate probability gradient coordinate probability probability independent coordinate rate experimental setup datasets datasets uci machine repository performance algorithm spambase spam mail database dataset collection email task email spam email feature mostly frequency dataset pendigits pen recognition handwritten digit contains downsampled image pixel digit har activity recognition smartphones dataset activity upstairs downstairs monitor smartphone sensor accelerometer gyroscope angular velocity feature extract measurement series feature standardize feature shift variance standardization approximate node network locally approximation statistic feature fix ensure fix application simulation training data assign node node har dataset node average assign evenly node due sample divisible network database mapped node node exactly scenario combine setting per node node scenario network database achieve replicate assign multiple node data  training feature label distribution uniform uniform scenario node label distribution uniform assignment assign node random independently label assignment node label assign uniformly node label assign node label uniformly assignment strategy extreme application realistic label likely bias assignment scenario model simulation fix random overlay network node fix random described previously network database churn scenario node stayed online churn scenario trace smartphones assume message successfully deliver sender receiver remain online transfer assume node detect online delay negligible transfer model node retain offline assume server unlimited bandwidth unlimited bandwidth achieve elastic infrastructure obviously non trivial gossip additional related ignore infrastructure clearly federate assumption assume worker node identical upload bandwidth explanation federate downstream communication cite available upload bandwidth normally bandwidth distinction relevant node bandwidth completely dedicate federate continuously highly unlikely scenario federate application device likely cap bandwidth usage difference upstream downstream bandwidth fade assume worker node bandwidth bandwidth cap mention significantly average available bandwidth cap assume uniform cap downstream traffic relevant scenario actual bandwidth qualitative difference network reliable churn accordingly measurement unreliable network downstream bandwidth addition convergence downstream message deliver strictly probability churn scenario fix amount transfer model node reliable transfer completely irrelevant dynamic convergence identical apart transfer model assume irrespective dataset transfer scenario transfer scenario simulate around iteration respectively actual model simulation relatively linear model normally transfer pretend model transfer network hardly effectively static subset node transfer however challenge transfer fail machine model neural network smartphone trace trace user trace overlap altogether simulate virtual assign simulated node achieve token distribution reflect ongoing application previous unrelated task execute platform empty message towards communication comparison algorithm token ensure algorithm phone user friendly define device online available charger internet hence battery addition treat user offline bandwidth illustrates trace plot illustrates churn via percentage node network respectively node online average session min hyperparameters cycle parameter continuous transfer scenario goal protocol communicate bandwidth constraint gossip cycle exactly transfer model node message continuously cycle federate sum upload transfer compression transfer proportionally define compression rate reflect cycle setting bursty transfer scenario assume transfer percentage denote transfer proportion transfer gossip cycle implement bursty model federate choice cycle node contact cycle upload transfer respectively contact node algorithm shorter cycle contact subset node achieve proportion overall examine latter cycle node contact cycle compression image KB image error partition gossip spambase dataset function cycle bursty continuous transfer scenario average algorithm transfer overall network amount furthermore continuous transfer bursty transfer image KB image federate node transfer failure aggregation algorithm upstream subsampling probability image MB image gossip node bursty transfer subsampling probability failure smartphone trace transfer variant without model partition NP respectively subsampling explore sample probability federate upstream downstream message sample rate denote respectively however fix upstream sample subsampling partition partition defines sample probability plot partition compression rate logistic regression model datasets pendigits har embed model meta classifier algorithm stochastic gradient descent rate regularization coefficient grid optimize parameter various scenario relatively robust however additional hyperparameters iteration simply fix outcome although fix parameter scenario grain behavior hyperparameters shed heuristic parameter measurement gossip without token account model partition network pendigits dataset gossip cycle optimal hyperparameters however cycle optimal cycle trend algorithm datasets setting diagonal grid choice however exception instance per node spambase dataset diagonal tend somewhat setting diagonal tend perform poorly hyperparameters  parameter parameter experimental simulation  hardware requirement reproduce server ghz CPUs core core server GB ram configuration within performance error proportion misclassified gossip loss define average loss online node compute error local model node report average federate evaluate central model optimistic evaluate average online node bursty transfer scenario downstream communication compress local model outdated central node model delay measurement average random exception measurement gossip algorithm scenario har dataset network database scenario expensive simulate error function amount communicate anywhere normalize online node machine model transfer information choice aggregation algorithm subsampled model algorithm failure continuous transfer scenario slight advantage although performance depends database apply implementation another choice apply model partition introduce model partition token gossip however technique advantage verify partition non partition variant scenario scenario  clearly partition implementation consistently outperform non partition although failure scenario classical gossip suffer temporary setback convergence hyperparameters exactly optimal explain image KB image federate node failure scenario subsampling strategy local plot indicates average model client otherwise model evaluate improve performance partition due grain handle parameter recall partition implementation partition update accordingly smartphone trace scenario feature useful node online offline model outdated merge operation model parameter update parameter indeed update merge partition without partition random subset parameter merge entire model merge operation parameter due observation model partition explicitly choice subsampling compression strategy federate recall choice subsample model client subsample direction subsample direction achieve compression rate convergence overall however function overall communicate preferable compress direction subsampling model client meaningless client mostly outdated parameter already previous image MB image federate gossip node node sample failure scenario subsampling probability stochastic gradient descent sgd implement gossip merge model replaces model image MB image federate gossip smartphone trace transfer node scenario meaningful strategy subsampling direction clearly choice however downside client longer model cannot model locally illustrate average performance model locally application nevertheless apply subsampling direction remain continuous transfer continuous transfer setup node minimize idle advantage available bandwidth comparison algorithm subsampling probability stochastic gradient descent sgd implement gossip merge model replaces model node clearly merge sgd subsampling federate gossip importantly node setup gossip competitive federate compression rate sample probability gossip fully decentralize aggregation clearly delayed federate indeed compression federate performs illustrates extreme scenario node network dataset scenario gossip federate federate perform relatively aggressive central aggregation relatively local information gossip  performance convergence recall scenario approximately achieve contains smartphone trace churn model correspond horizontal axis temporal interpretation choice transfer almost difference apart shorter transfer obviously corresponds proportionally faster convergence interestingly churn minor increase variance error otherwise stable convergence due application model partition previous without model partition variance worth federate gossip practically identical performance compression rate gossip clearly competitive federate image KB image federate gossip node failure scenario assignment contains assignment scenario described extreme scenario advantage federate apparent although gossip achieves interestingly compression rate preference pendigits database compress variant inferior har compress variant preferable similarity indeed scenario node sample assignment scenario definition bursty transfer bursty transfer setup node communicate percentage described without modification behavior algorithm behavior continuous transfer scenario although gossip algorithm slightly due reduce parallel transfer bursty transfer scenario possibility implement specialized technique advantage bursty transfer explicitly image MB image federate gossip node node sample failure scenario bursty transfer scenario gossip introduce token account technique described previously technique motivate partition sample technique formation potato chain partition separately recall model partition traditional gossip federate technique communicates subset worker subset although worker communicate bursty fashion global model evolves relatively faster assume node communicate node communicates continuously node communicate burst illustrates performance bursty transfer scenario clearly convergence algorithm becomes faster continuous communication suggests bandwidth burst oppose bandwidth continuous communication token gossip converges faster regular gossip gossip variant competitive federate algorithm scenario per node node scenario network database achieve replicate assign multiple node scenario gossip variant competitive federate variant observation bursty transfer scenario faster convergence achieve due algorithm exploit burstiness besides important feature scenario label distribution bias label assignment random assignment assignment bias scenario convergence approach however previous increase network protocol image MB image scenario continuous transfer bursty transfer bias indicates assignment trace indicates smartphone trace scenario related literature machine optimization decentralize consensus vast contribution comparison efficiency decentralize centralize data local focus target gossip decentralize context industrial iot application focus data distribution identical node compression technique algorithmic enhancement token introduce segmentation mechanism motivation focus saturate bandwidth node PP connection relatively bandwidth propose node communicate peer simultaneously model beneficial scenario focus convergence function overall communication technique optimize token mechanism aggregation scheme decentralize aggregation gradient gossip version sum communication scheme although author cite federate gossip theoretical analysis algorithm variant relevant merit scenario node possibly subset parameter task bayesian model collaboratively without server mainly theoretical experimental evaluation node illustration focus communication topology attempt optimal topology communication efficient propose  topology  ordinary peer introduce gossip algorithm centralize variant improve algorithm via arbitrary gradient compression contribution theoretical analysis synchronize implementation assumption network bandwidth assume server unlimited bandwidth usage characterize convergence function synchronization epoch due compute motivation focus convergence function overall communication various scenario realistic node churn perform asynchronous measurement along optimization technique token   thorough analysis applicability gossip without federate scenario topology correlation communication data distribution ben   briefly gossip alternative performance issue conclusion federate gossip extent away central component gossip hurt performance hurdle careful model constraint performance apply algorithm grant fix overall communication budget overall execution fix amount utilize available bandwidth node choice node communicate within configurable bandwidth cap uniform network node continuous fashion bursty fashion latter cap interpret average bandwidth usage fix model application scenario within model interested convergence amount overall communication phenomenon various scenario random assignment node random subset gossip clearly competitive federate assignment scenario federate converges faster information efficiently node assignment however gossip converge practically realistic frame gossip improve via apply sophisticated peer sample optimize increase efficiency update via apply momentum experimental setup opt cap upstream downstream traffic federate motivate remove assumption considers downstream traffic completely downstream compress federate variant converge twice relatively modest difference gossip peer peer traffic cap bursty traffic model broadens algorithm array technique schedule message achieve speedup relative random schedule token gossip achieve performance comparable federate random label assignment scenario client communicate burst maximal bandwidth oppose bandwidth cap continuous communication token approach outperforms random gossip baseline however achieve advantage compression mechanism partition oppose subsampling partition potato chain separately whereas subsampling chain cannot sample addition examine subsampling compression mechanism sophisticated compression technique potentially apply federate gossip