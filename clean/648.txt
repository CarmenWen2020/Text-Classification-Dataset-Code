proposes efficient approach parallel computationally consume multiple global optimization minimize function  calculate function amount computation propose approach information statistical theory global optimization within computational scheme global optimization propose scheme expand reuse information obtain computation multiple global optimization within framework propose generalize scheme parallel algorithm propose computational distribute memory computational demonstrate propose approach significantly reduce computational complexity multiple global optimization keywords global optimization dimensionality reduction information parallel global computational complexity introduction global optimization continued challenge theory optimization contrast local optimization global minimum numerical evaluate behavior function optimize entire global domain dimensionality curse volume computation perform increase exponentially increase dimensionality computational complexity practical demand research activity global optimization overview approach developed global optimization recent monograph review obvious approach local efficiently optimization unimodal objective function  local apply repeatedly global minimum initial research direction relevant unfortunately initial remains significant initial guarantee reliable global optimization another obvious approach construct grid domain node function minimize compute reduce computational complexity uniform grid approach  construction non uniform grid denser vicinity global minimum research develop inspire metaheuristic genetic algorithm bee algorithm particle swarm optimization simulated anneal ant optimization firefly algorithm etc apply however obtain guaranteed estimate accuracy globally optimal algorithm another research global optimization assumption analytical function optimize difference convex optimization nonconvex  function difference convex function another approach development global optimization interval analysis analytical expression function optimize typical situation apply optimization understood numerical estimate global optimal cannot principle obtain priori assumption behavior function minimize widely specify information assume validity lipschitz accord function minimize restrict variation parameter varied assumption  global optimization extensively explore algorithm adaptive global iteration algorithm tend information obtain computation adaptivity non uniform grid construct estimate global minimum finite global iteration direction obtain within framework rapidly develop information statistical theory global optimization multivariate algorithm dimensionality reduction  curve nest optimization scheme mention estimate lipschitz constant chosen detailed review research proposes complication formulate decision global optimization simultaneously encounter efficient multicriteria optimization variable parameter optimization discrete formulation multiple global optimization MGO investigate relatively limited attention MGO likely due computational complexity involve MGO sequential parallel individual however approach fold increase computational complexity meanwhile individual MGO informational interrelation connectivity scalarization vector efficiency criterion apply multicriteria optimization MCO becomes multiple scalar global optimization efficient decision MCO  reduce significantly amount computation perform entire approach propose assumes computational function MGO recalculate function without consume calculation information obtain reuse information significantly reduce amount computation perform iteration addition presence informational connectivity significantly expands possibility parallel MGO proposes parallel computational scheme cooperative scheme information exchange computational device distribute memory parallel competitive scheme occurs parallel compete available computational resource memory structure multiple global optimization computational scheme global proposes parallel MGO computational distribute memory contains numerical confirm effectiveness propose parallel conclusion direction research statement multiple global optimization MGO consists define optimize function vector varied parameter dimension global optimization domain vector assume function  procedure calculate function domain computationally expensive assume function satisfy lipschitz lipschitz constant function denotes euclidean norm fulfillment lipschitz allows construct numerical estimate behavior minimize function finite calculate function domain approach assumption calculate function arbitrary domain transform function without consume computation significantly shorter computation function transformation computation expression parenthesis fulfil multicriteria optimization MCO efficient  widely approach reduction scalarization vector criterion scalar criterion minimization pareto optimal MCO minimax convolution vector criterion reduces scalar criterion efficient decision MCO optimization scalar criterion perform coefficient efficient decision MCO statement MGO optimize function define efficiency criterion compute domain scalar criterion compute coefficient transformation expression fix criterion ability quickly convert calculate optimize function determines accumulate information obtain calculation function minimize iteration global optimize compute function procedure calculate function trial global optimization information thereby ensure ability successive account previous calculation numerical perform confirm information reduces iteration global perform iteration conclusion function minimize dynamically calculation remove exist global optimization function computational scheme global optimization approach propose framework information statistical theory global optimization accordance theory dimensionality reduction achieve  curve  uniquely continuously mapping interval dimensional domain reduction multidimensional global optimization reduce dimensional dimensional function obtain reduction satisfy uniform  constant relation lipschitz constant dimensionality optimization dimensionality reduction significantly decrease computational complexity analyze multidimensional data highlight subdomains domain efficient continuation global reduces severity curse dimensionality multidimensional optimization dimensionality reduction information addition reduce representation data ascend efficient execution global algorithm optimize reduce dimensional function dimensional global algorithm possibly generalization numerical construct approximation  curve  accuracy dimensionality approximation image KB image approximation  curve approximation density correspondingly framework information statistical theory computational scheme global optimization algorithm propose scheme summarize function minimize optimization iteration perform information obtain adaptively iteration optimization algorithm evaluate possibility global minimum subintervals interval previously perform iteration global assessment perform introduce characteristic subintervals proportional global minimum subintervals characteristic global optimization algorithm algorithm uniform dense grid domain characteristic simply interval multidimensional generalization algorithm propose characteristic estimate minimum function minimize interval  constant reduce global optimization dimensionality multidimensional generalize global algorithm gsa developed framework information statistical approach characteristic numerical estimate  constant obtain available information reliability parameter gsa algorithm detailed description gsa algorithm algorithm input algorithm function minimize domain reliability parameter accuracy maximum permissible global iteration output algorithm estimate global minimum function minimize perform global iteration calculation information contains previously perform global iteration ascend function minimize algorithm image KB image algorithm pseudo code gsa algorithm sufficient convergence gsa algorithm relation satisfied iteration global framework propose approach gsa algorithm described global optimization moreover due informational connectivity information quickly transform function minimize gsa minimize successive function account previous calculation gsa algorithm information refer multiple global algorithm  parallel computation multiple global optimization initial assumption computationally expensive calculate function minimize global optimization amount calculation increase obtain estimate globally optimal decision reasonable delay achieve parallel performance computational obvious apply parallel compute parallel undoubtedly approach straightforward additional effort implement sufficient computational device core processor available consume however necessitate parallel compute global optimization however widely parallelization poorly applicable global optimization domain distribution processor global optimization global minimum processor processor perform redundant calculation framework information statistical theory approach parallelize global optimization propose parallel compute parallel simultaneous compute minimize function domain approach apply global optimization parallel mode approach efficient consume computation parallelize due initial assumption calculate function minimize computationally expensive propose apply approach parallel global optimization strategy orient parallel scheme parallel compute propose strictly sequentially available computational resource optimization sequentially available information obtain calculation reuse implement approach ensure iteration global optimization domain parallel calculation function minimize  global algorithm characteristic interval ass possibility global minimum subintervals interval reasonable iteration global interval maximum characteristic input data algorithm function domain reliability parameter accuracy maximum calculation function minimize available computational device core processor memory execute algorithm estimate global minimum function minimize function execute iteration global calculation information contains earlier iteration global ascend function minimize numerical approach parallelize  algorithm allows obtain linear speedup computational core dimensionality global optimization PMGSA  iteration PMGSA iteration speedup PMGSA core iteration core marked image KB image PMGSA univariate optimization graph function minimize selection iteration compute ordinate axis iteration abscissa axis domain strategy competitive parallel scheme iteration PMGSA algorithm redundant sequential  version information undesirable reduce reduce computational device allocate optimization simultaneously increase parallel global optimization due freed computational resource available computational resource distribute dynamically global assume available computational device core processor memory optimization parallel optimization compete available computational resource distribution resource interval characteristic calculate characteristic parallel information iteration global accordingly minimize function specify interval characteristic compute index function minimize interval information implement approach interval characteristic global optimization function minimize available information normalize estimate minimum function minimize estimate  constant perform algorithm convert calculate characteristic interval iteration global briefly explain perform parallel iteration global characteristic interval calculate parallel interval maximum characteristic available computational resource distribute dynamically computational device distribute evenly allocate interval characteristic calculate function minimize data obtain information regardless interval iterate global information update data maximum efficiency propose PMGSA algorithm achieve global minimum parallel domain additional information simultaneously significantly reduce global conclusion obvious global minimum function situate neighborhood domain global minimum function function compute global function separately PMGSA execution parallel iteration computational device computation increase amount available information allows adaptive global algorithm iteration global reasonable manner limit perform sufficiently iteration amount information sufficient global minimum without additional iteration numerical PMGSA selects interval maximum characteristic image KB image interval selection PMGSA algorithm strategy cooperative parallel scheme computational device memory core processor limited core computational node usually exceed increase parallelism becomes inevitable distribute memory computational computational node computational device distribute memory computational core core computational framework propose approach parallel global optimization algorithm  algorithm propose distribute memory computational sequentially coincides available computational core computational node apply optimization PMGSA algorithm parallel iteration global iteration node transfer available computational node recalculation function minimize accordance transformation perform iteration computational node accepts data transmit data information PMGSA algorithm distribute independently computational node global computational node exchange calculation obtain iteration global information update calculate function minimize computational node accordingly simultaneously faster optimization evidence numerical perform PMGSA performs optimization iteration image KB image interval trial PMGSA algorithm numerical numerical perform supercomputer    endeavour intel cluster supercomputer optimization software development numerical obtain computational node intel xeon platinum ghz GB ram cpu core available node executable program code built intel parallel studio XE software package numerical perform  opportunity computationally intensive multicriteria  optimization parallel global algorithm achieve  algorithm multicriteria optimization algorithm criterion propose MGO approximate pareto  algorithm apply subproblems convolution coefficient uniformly distribute interval MCO understood construction numerical approximation pareto domain ass quality approximation completeness uniformity coverage pareto domain indicator hypervolume index HV indicator characterizes completely pareto domain approximate corresponds coverage pareto domain distribution uniformity index DU indicator characterizes uniformly pareto domain corresponds uniform coverage pareto domain multicriteria optimization algorithm monte carlo MC genetic algorithm  pisa library non uniform coverage  objective lipschitz optimization   algorithm  obtain comparison effectiveness multicriteria optimization algorithm  iteration pareto optimal HV DU numerical  algorithm noticeable advantage performance indicator multicriteria optimization relatively MGO numerical perform evaluate efficiency parallel PMGSA algorithm MGO MGO generate seek efficient MCO minimax convolution convolution coefficient uniformly distribute domain assumption complexity compute function minimize efficiency propose evaluate optimization iteration perform achieve accuracy series numerical criterion dimensional MCO MCO  function obtain  generator efficiency criterion efficient calculate subproblems obtain iteration perform fulfil average MCO accuracy reliability parameter numerical information computational resource marked indicates computational node core within node marked core marked average iteration perform PMGSA MCO accordingly series criterion dimensional MCO computational resource average iteration MCO PMGSA PMGSA PMGSA speedup obtain parallel PMGSA PMGSA PMGSA overall reduction execute iteration parallel computation reuse information PMGSA PMGSA PMGSA initial sequential gsa algorithm without reuse information average iteration MCO overall reduction execute iteration account reuse information propose parallel superlinear speedup scalability maintain efficiency parallel compute increase computational core computational node available computational core memory computational computational speedup exceeds computational core computational node core distribute memory speedup becomes account information reuse overall reduction global optimization iteration image KB image speedup efficiency PMGSA algorithm criterion dimensional MCO series complicate increase dimensionality criterion dimensional MCO parallel PMGSA apply perform accuracy reliability numerical criterion dimensional MCO parallel PMGSA computational resource numerical iteration speedup overall reduction iteration computational node core per node computational core correspond global iteration perform speedup achieve overall reduction execute iteration account reuse information average iteration perform sequential gsa algorithm without reuse information MCO average dimensionality increase efficiency parallel computation PMGSA algorithm increase core speedup account information reuse global optimization iteration reduce demonstrate efficiency propose approach vibration isolation freedom consist isolated elastic assume multi mechanical consist vibration damp criterion maximum deformation maximum displacement relative minimize variable parameter construct approximation pareto  function minimize convolution coefficient uniformly distribute domain perform accuracy reliability parameter numerical apply computational resource   PMGSA PMGSA iteration HV DU speedup overall reduction iteration numerical demonstrate sufficient approximation pareto domain iteration perform PMGSA compute approximation pareto domain obtain PMGSA image KB image approximation pareto domain vibration isolation construct  conclusion considers approach multiple global optimization minimize function  calculate function amount calculation encounter efficient multicriteria optimization variable parameter optimization discrete computational complexity ability efficiently achieve performance computational propose approach assumes information connectivity exists global optimization calculate function transform function without consume calculation information obtain optimization reuse information significantly reduce amount calculation perform iteration multiple global optimization availability informational connectivity significantly expands possibility parallel entire multiple global optimization proposes parallel computational scheme cooperative scheme information exchange computational device distribute memory parallel competitive scheme occurs parallel compete available computational resource memory computational propose approach allows significantly reduce computational complexity multiple global optimization propose approach promising research continued computational multiple global optimization computational complexity ass possibility global optimization algorithm within framework propose approach