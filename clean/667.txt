data era amount data generation accumulation various however user usually hinder data quality issue extract data data quality issue gain attention data quality management analyst data ETL data cleaning data quality monitoring deficiency capability efficiency cope complicate situation data inspire SparkDQ generic distribute data quality management model framework series data quality detection repair interface user quickly custom task data quality compute various utilize interface addition SparkDQ implement algorithm parallel manner optimization algorithm aim various data quality goal propose optimization optimization multi task execution schedule data optimization data cache experimental evaluation propose distribute algorithm SparkDQ faster correspond alone serial multi thread algorithm distribute data quality apache griffin SparkDQ feature execution around apache griffin average SparkDQ achieves linear data node scalability keywords parallel data quality algorithm distribute data quality management multi task schedule data introduction data quality prevalent critical organization become aware impact data progress however alarm data accurate consistent stumble decision data quality management maintain information quality technically dirty data detection repair discover duplicate account delete others data quality management become fundamental entire cycle data processing data warehouse data quality management versatile scalable demand scenario however exist extract transform load ETL data cleaning data monitoring drawback functionality processing performance data ETL analyze data specialized data quality management usually adequate function regard data quality management user kettle detect fault error user user fix manually kettle repair function actual alone database architecture kettle typically query per handle data data cleaning specialized data quality management data quality nevertheless usually focus model interface  core cope multiple data quality holistically chain model therefore expressive handle complicate data quality workload complex pre processing stage machine task data quality monitoring comprehensive dimension data quality detect data quality automatically generally cannot complex data quality functional dependency conflict entity redundancy etc cannot fix detect cannot integrate data quality management usage interface definition data quality   detect repair data integrity however divergence integrity constraint  integrity constraint express functional dependency denial constraint user define function however  defines integrity constraint denial constraint therefore almost impossible integrate detect repair data quality data challenge firstly execution surge due explosion data secondly task fail data occasion alone storage resource generally exist significant challenge efficient generic data quality management interface flexible expressive construction various data quality detection repair task usage scenario data detection data repair amount data reasonable challenge propose SparkDQ distribute generic data quality management data quality detection repair contribution propose generic data quality management model program framework built apache spark allows user develop data quality task easily quickly distribute data quality management algorithm SparkDQ mode detection algorithm mutual information detection algorithm iForest model outlier detection algorithm others relatively complex priority multi cfd data detection repair algorithm semantic entity detection extraction algorithm naive bayesian model algorithm propose optimization strategy SparkDQ optimization multi task execution schedule data optimization data cache optimization improve efficiency multiple data quality issue multiple approximate quantile detection implement prototype SparkDQ evaluate performance extensive experimental propose distribute data quality management algorithm faster alone serial multi thread algorithm propose optimization reduce execution data quality apache griffin SparkDQ feature outlier detection cfd detection repair data quality task execution SparkDQ apache griffin average moreover SparkDQ achieves linear data node scalability organize introduces related data quality management propose distribute data quality management algorithm optimization describes SparkDQ performance evaluation finally conclude discus future related data ETL data extract transform load ETL extract scatter data various source transform unified format load destination ETL data quality sql ETL relatively easy however limitation sql consume unable complex data quality issue furthermore complex sql instruction user expertise sql program various specialized ETL emerge overcome limit kettle    complex transformation towards data warehouse however user friendly data quality management due difficulty configuration usage oracle  fault disaster tolerance towards database nevertheless distribute data transformation extendable non database  focus data fusion exchange massive data processing data model however data model struggle express issue complex data quality data cleaning unlike data ETL data cleaning specialized data quality issue constraint    detect data conflict pairwise comparison data pre define integrity constraint obtain repair decision heuristic input data exist data repository dirty data recommend data quality typical edit fix  knowledge statistic   scare probability model statistic incoming data probability model treat attribute random variable dirty data computer integration another user participate data cleaning continuously decision GDR conditional functional dependence cfd generate cleaning generate user falcon interacts user repair data quality  generates redundant data user diagnose data cleaning data quality issue however usually concentrate model interface typically cannot bind model therefore expressive handle complex data quality workload pre processing stage machine task data monitoring enhance accuracy reliability data quality detect data quality apache griffin emerge user customize data quality monitoring task correspond alert dirty data however data monitoring repair dirty data summary summarize feature related SparkDQ introduce exist usage interface definition data quality almost impossible integrate therefore unified model framework data quality management data framework layer program interface distribute data quality management algorithm optimization multi task scenario feature data quality management     kettle      griffin data detection redundancy integrity outlier data repair deduplication integrity data source multiple file data data quality program framework algorithm program framework program interface layer program interface manage multiple data quality user imperative declarative interface program model imperative interface task scenario related function execute directly return immediately contrast declarative interface multiple task scenario define task launch function chain execution SparkDQ apis data quality detection repair operator specifically SparkDQ interface user interface via trivial spark application detection interface SparkDQ      assert  completeness    unique   distinct histogram  assert binning udf max  histogram distribution approx  assert  approximate distinct  assert  entity   assert  positive  vals assert  satisfies  assert  satisfies expression data  assert  data  pat assert  satisfies  assert  satisfies dependency   assert  approx  quantile assert  approximate quantile mutual  col  mutual information  model params assert  outlier repair interface SparkDQ    previous previous  accord probability model      redundant extract  entity filter   expression   expression  model  outlier   pat  replace sub  sub pat  sub extract sub  sub pat  sub replace  model params  outlier accord repair  priority  data accord functional dependency distribute data quality management algorithm data quality violates data integrity uniqueness consistency validity data quality detection operator detects mention data integrity attribute violates data integrity data uniqueness attribute data unique attribute violate data uniqueness ID data consistency data dependency violates data consistency london china data validity data valid violates data validity data quality      york   operator filter replace fix data quality operation conduct generate valid data lose detect operator filter operation directly delete attribute evade data quality replace operation modifies false data status data quality SparkDQ utilizes distribute compute technique detect data quality mention repair data quality repair operator SparkDQ parallelizes data quality management operator develop optimize distribute data quality management algorithm algorithm optimization complex SparkDQ handle data quality chain task task solves data quality therefore complex SparkDQ involve multiple data quality SparkDQ optimization strategy handle multiple data quality task simultaneously semantic multitask schedule optimization data cache strategy data detail distribute data quality management algorithm subsection propose typical distribute algorithm data quality management namely mode detection algorithm mutual information detection algorithm iForest model outlier detection algorithm explore parallelize exist complex data quality management approach distribute priority multi cfd management algorithm data detection repair semantic entity detection extraction algorithm naive bayesian model algorithm algorithm subsection implementation however algorithm generally exist distribute data quality management algorithm limitation heterogeneity parallelization model program interface unlike specific algorithm goal SparkDQ distribute algorithm framework SparkDQ unified dataframe distribute algorithm framework data quality management parallelization optimization strategy program model regard limitation exist distribute data quality management algorithm exist implementation distribute data quality management algorithm however perfect generic efficient data quality management limitation exist distribute data quality management algorithm mainly algorithm parallelization model significant difficulty emerge apply parallelization model implementation heterogeneous difference interface involve operation apply detection various compute SparkDQ exist unified parallelization optimization strategy generic program model actually algorithm mention merely data quality management algorithm framework adopt unified framework benefit easy integrate plug algorithm framework secondly unified framework efficient unified data format compute ETL operation data transformation data format reduce thirdly easy user data quality management application framework distribute mode detection algorithm background mode detection algorithm aim statistical mode series data objective function goal mode specific workflow computation task generate distribute partition spark dataframe distribute data structure multiple partition compute node partition mapped cache initialize data partition scan data partition algorithm merges cache partition global distribution data item frequency return mode workflow propose distribute algorithm image KB image workflow distribute mode detection algorithm objective function accord distribute partition spark dataframe partition algorithm initializes data cache distribute data data cache algorithm merges data cache partition maximum return algorithm objective function approach modify distribute version manner mention distribute mutual information detection algorithm background mutual information detect data dependency data quality management information birth birth birth nanjing birth china dependency nanjing china entry violate dependency mutual information detection algorithm interdependence variable concept mutual information detection algorithm interdependence calculate equation equation joint probability distribution respective marginal probability distribution probability calculate occurrence statistic respectively mutual information detection typical transformation data quality management approach approach similarly convert distribute algorithm distribute  model outlier detection algorithm background iForest model detects outlier purely concept define isolation instead traditional distance density isolated perform parallel sample data obtain sample dataframe feature algorithm generates sample index randomly accord index distribute operator spark index sample broadcast aggregate compute node broadcasting algorithm sample replicates sample data frequency algorithm ID resilient distribute data rdd output reduce rdd parallel sample isolated construct parallel input sample attribute algorithm selects non constant attribute random generates random split within input finally node return  structure isolation  non constant attribute return leaf node improve efficiency anomaly data detection broadcast mechanism isolated compute node average depth sample calculate parallel calculate binary manner node leaf node index node preset split algorithm return plus otherwise return plus distribute priority multi cfd management background traditional functional dependency data quality management algorithm serial processing increase overhead exponentially distribute scenario reduce overhead propose priority multiple function dependency simultaneously concept conditional functional dependency cfd tuple dependency define relation model attribute attribute attribute compose series tuples specify attribute specific underscore underscore indicates constraint tuples conflict situation LHS attribute RHS attribute contains tuples attribute attribute satisfy functional dependency attribute functional dependency satisfied conflict namely constant conflict variable conflict attribute inconsistent constraint tuple constant conflict dot attribute tuple variable conflict dash image KB image cfd constant conflict CC affect traversal however handle variable conflict VC attribute LHS detect fix therefore traditional detect fix constant variable conflict separately conflict attribute conflict tuple constant CC underscore VC motivates distribute algorithm detect fix conflict simultaneously workflow workflow algorithm input data distribute spark dataframe data detection algorithm detects constant conflict partition separately detects variable conflict data repair cfd consistency checked algorithm conduct CC repair later repair generate maximum probability RHS finally partition merge summarize accord priority cfd conflict repair another execute conflict preset threshold image KB image workflow distribute priority multi cfd management distribute semantic entity management background data overlap semantic information entity recognizes entity similarity complexity overhead data scenario data reduce overhead user expertise pre model construct propose entity detection extraction algorithm semantic information technology semantic information data adopts structure independent greatly reduces comparison data slice stage attribute entry slice cleaning filter generate meta generate meta compute threshold construct global graph profile information broadcast node local graph construct profile threshold compute distribute initializes local entropy information traverse profile partition calculates local information finally threshold calculate local information multiple profile partition reuse local information calculate threshold prune computation threshold information profile broadcast average threshold prune threshold delete entity candidate profile similarity commonly similarity compute algorithm algorithm fragment cosine jaccard index algorithm edit distance levenshtein jaro winkler transitivity relationship graph construct component calculate obtain cluster entity distribute naive bayesian model background propose distribute algorithm naive bayesian model probability statistical information data realize automatic concept naive bayesian model classification model probability statistic data non data calculate probability attribute equation reveals relationship probability attribute related attribute attribute relevant attribute target constant hypothesize constant prior probability unknown therefore variable hypothesis multiple dependent equation compute parameter statistic module contains stage public parameter related attribute broadcast compute node traverse data unified dependency information format non target attribute parallel respectively perform accord target attribute calculate probability relevant attribute parallel probability computation algorithm traverse IDs non related attribute calculates probability relevant attribute parallel finally summarizes probability information IDs summarize multiplies probability relevant attribute target attribute obtain probability target attribute algorithm probability selects related attribute probability finally algorithm broadcast information compute node optimization complex previous distribute data quality management algorithm algorithm specific data quality complex scenario dataset multiple data quality propose optimization namely semantic multi task schedule strategy data cache optimization data complex processing generally task scan task data mode detection task compute task input data independently entity detection task typical compute task task complicate data transformation model implementation sophisticated task mutual information detection task sophisticated instead sequence manner SparkDQ optimization complex processing aim parallelize independent task SparkDQ chain task holistically efficiently semantic multi task schedule strategy optimize multi task schedule strategy knowledge compute task characteristic task combine technique data quality management data quality detection execution multiple data quality detection task various task complexity classification mention SparkDQ procedure task parallel scan task SparkDQ cache handle operation task simultaneously specifically detection task multiple partition partition compute parallel finally aggregate metric data algorithm algorithm handle detection task scan firstly combine task generates task index aggregation function task execute model aggregation function offset task aggregation function calculation aggregation function execute parallel cache offset calculation cache finally calculation summarize metric construct task accord offset information index task algorithm image KB image algorithm multi task schedule scan detection regard compute task task procedure parallel later procedure task aggregation illustrates workflow data detection task processing algorithm task task task non accord execute aggregation function task non task generates grouped statistical data related calculates aggregation function parallel accord workflow algorithm non task grouped statistical data cached serialize task construct accord pipeline mode finally algorithm summarizes processing image KB image workflow distribute multi task schedule processing detection sophisticated task however related logic execute nevertheless SparkDQ somehow efficient remove unnecessary operation data repair data quality detection task repair task classify category accord computational characteristic filter task replace task sophisticated repair task filter task reduce data replace task pas data usually execute filter task replace task complex task entire task filter task SparkDQ combine filter task directly logic construct filter filter partition parallel deletion operator filter logically deletion operator transform filter operator replace task combine SparkDQ replace task accord related combine replace task prepares replacement replace task advance scan task parallel obtain specific replace task contains fitting correspond replace combine fitting replace binary structure finally fitting uniformly parallel statement image KB image combine sub replacement exists overall instead judge sub scan therefore combination task nest structure combination inside outside sophisticated relationship therefore SparkDQ serially data cache optimization data quality management task involve calculation massive intermediate data propose data cache optimization mechanism memory hdfs storage achieve execution efficiency data data persistently data cache SparkDQ task objective replica task SparkDQ combine parameter task cache SparkDQ construct task execute task task SparkDQ cache computation task reuse data computation cache multiple detection illustrate image KB image data cache detection implementation implementation overview application program interface layer interface program model data quality management model layer contains model data quality detection repair allows connection model pipeline multitasking introduces detail implementation optimization layer contains spark dataframe rdd spark alongside built distribute data processing algorithm complex optimization model distribute computation computation implement spark application distribute compute cluster workflow data quality management model detection model workflow data detection usually data quality data detection workflow stage data load parameter target computation feedback stage standardize operator receives data source data quality target user output detection metric user repair model workflow procedure data repair data detection stage data load parameter data transformation data input repair model detection model output transform data destination unexpected consequence mechanism handle exception pipeline multi task model workflow dirty data multiple data quality issue motivate ML pipeline pipeline multi task model introduce mention module data detection task input execution task interfere execution task therefore data detection model data load task execute pipeline repair model transform data affect input latter model consequence input latter model output previous model connection model execute pipeline unexpected consequence exception thrown handle SparkDQ spark translate algorithm spark interface SparkDQ parallelizes api operator algorithm batch sophisticated spark parallel compute apis efficiently SparkDQ optimization semantic multi task schedule strategy data optimization data cache perform auxiliary function parameter validity program SparkDQ program SparkDQ contains task integrity  per  approximate distinct program data  operator express data quality management requirement user perspective chain operator execute operator computer perspective SparkDQ understand operation reading operator attempt optimize execution procedure task improve efficiency image KB image SparkDQ application evaluation evaluate analyze performance SparkDQ extensive setup hardware software environment conduct cluster node consist node worker node machine logical cpu core specification hardware software machine apache spark yarn GB memory virtual cpu core deployed cluster resource spark executor instance executor allocates GB memory virtual cpu core equipment machine  intel xeon ghz memory GB disk TB sas file  network bandwidth gbps   linux release core jvm version python version hadoop version spark version dataset data generate census data adult adult data attribute numeric enumerate specific dependency attribute express various data quality generate data organize stage SparkDQ algorithm focus data quality therefore algorithm dirty data accord definition data quality algorithm tackle generally proportion dirty data data quality propose data quality model SparkDQ verify correctness algorithm generate data execution performance comparison distribute algorithm throughput distribute alone algorithm multitask scenario optimization execution without optimization SparkDQ distribute data quality management finally evaluate data node scalability SparkDQ evaluation detection capability measurement effectiveness data quality detection propose detection accuracy metric detection accuracy ratio detect data quality management capable detect data quality mode detection algorithm correctness distribute version alone distribute algorithm data situation return algorithm return alone serial algorithm therefore mode detection algorithm SparkDQ detection accuracy mutual information detection algorithm similarly checked difference mutual information calculate version algorithm despite error computation float mutual information detection algorithm SparkDQ proven accuracy mutual information detection algorithm  mutual information alone serial  algorithm execution fail  model outlier detection algorithm algorithm proportion outlier input dataset mention data dirty therefore calculate detection accuracy simply proportion execution proportion outlier dataset  model machine model mainly focus trait lose detection accuracy however accurate alone serial version algorithm detect exist data quality accuracy iForest model outlier detection algorithm  detect outlier alone serial  algorithm priority multi cfd management algorithm inspect violation data quality issue algorithm checked violate csv file computation functional dependency fulfil detect repair violation SparkDQ accuracy multi cfd management algorithm  violates   algorithm semantic entity management algorithm functionality detection algorithm program program  occupation firstly calculate input data distribution checked return dataframe entity federal gov private priv serv null algorithm detect entity return statistic data increase detection accuracy SparkDQ accuracy semantic entity management algorithm  related entity    naive bayesian model algorithm dataset transformation algorithm blank dirty data detect data quality fix SparkDQ performance distribute data quality management algorithm mode detection algorithm propose distribute algorithm efficient data relatively spark overhead task schedule resource management cluster however data increase benefit distribute compute outweigh overhead distribute algorithm around faster serial version faster  version besides alone version fail execute data scenario throughput decrease zero however distribute version mutual information detection algorithm illustrates version mutual information detection algorithm multi thread version faster serial version mutual information detection cpu intensive propose distribute version performance  version data relatively massive data frequent thread switch memory operation  version contrast distribute outstanding performance faster serial version faster  version processing  model outlier detection algorithm performance version iForest outlier detection algorithm propose algorithm performance due handle construction distribute bottleneck arrives  version massive data propose distribute version obvious advantage alone version priority multi cfd management algorithm evaluate performance  tuples performance algorithm fail alone machine enormous intermediate overhead generate distribute version transmit data performance advantage however distribute version data input image KB image  tuples semantic entity management algorithm complex entity extraction evaluate performance counterpart related attribute data comparison occupation net income illustrates distribute version robust massive data input acceleration data increase distribute execution  burden machine likely fail massive data input naive bayesian model algorithm lack attribute data accord occupation execution version algorithm throughput algorithm propose algorithm robust input distribute policy effectiveness optimization multi task schedule optimization evaluate schedule strategy task performance task function task task filter task task perform python application function task objective function task data detection application integrity per approximate distinct task task gain loss  mutual information SparkDQ easy express python application filter task filter task remove without attribute filter net income mode performance non optimize version algorithm brings improvement execution objective function filter optimization reduces repetitive data scan decrease execution image KB image performance optimization data cache optimization task query quartile data attribute execution without data cache optimization task perform scan partition quantile calculate approximate quantile data cache optimization scan data cached  driver evaluation query overhead scan data execution version performance comparison apache griffin subsection performance SparkDQ widely data quality management apache griffin aspect data quality detection task multiple data quality detection task data quality detection task integrity attribute  attribute  max attribute  constraint  multiple detection task handle detect unique attribute fairly griffin SparkDQ griffin spark stable version image KB image performance comparison apache griffin SparkDQ faster apache griffin integrity detection expression detection task griffin transforms detection task sql statement serially however SparkDQ combine computation faster detection task maximum detection task SparkDQ statement max function apache griffin therefore execution significant throughput difference multiple task SparkDQ obvious advantage due optimization addition griffin complex detection model outlier detection cfd detection cannot repair detect data quality contrast SparkDQ complex model data quality repair feature performance scalability performance data scalability aforementioned evaluation already indicates SparkDQ linear data scalability consolidate another execution task task directly reveal linear data scalability SparkDQ image KB image data scalability node scalability evaluate node scalability SparkDQ data quality detection repair task evaluate node scalability performance task propose algorithm mode detection algorithm mutual information detection algorithm iForest model outlier detection algorithm priority multi cfd management algorithm semantic entity detection extraction algorithm naive bayesian model algorithm cluster node input complex representative node scalability performance evaluation execution assert SparkDQ achieves linear node scalability image KB image node scalability conclusion future data management data quality management becomes vital due importance data mining response data quality management urgent propose SparkDQ generic data quality management model framework built distribute data detection repair algorithm optimization SparkDQ series flexible convenient data quality detection repair operator user customize data detection repair logic specific flexibility propose data quality operator distribute apache spark user amount python code moreover SparkDQ various data source achieves linear scalability future focus aspect aspect discover integrate distribute data quality management algorithm SparkDQ aspect tune parameter parallelism specific data automatically