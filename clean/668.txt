increase core processor cluster architecture advocate hybrid parallel program combine message passing interface mpi internode operation memory treatment intranode operation propose mpi mpi hybrid approach parallel program memory operation manage combination mpi memory introduce mpi atomic operation associate multi thread memory model illustrate fundamental parallel operation barrier reduction ghost update prevalent parallel numerical performance reedbush oakbridge CX memory model manage memory achieve performance comparable mpi implementation reduce variance execution increase synchronization multiple node environment reduces significantly execution ghost update mpi synchronization data memory model efficient synchronization rma utility keywords hybrid parallel program mpi memory model mpi memory model introduction physical mechanical phenomenon involve numerical resolution ensure detailed representation local rapid development parallel computer architecture resolution increase complexity effectively utilize architecture parallel program style propose classical approach message passing interface mpi effective manage communication however increase core per chip processor cluster architecture tend consist memory symmetric multiprocessing SMP node core moreover network interface struggle cope highly concurrent usage network distribute memory hybrid approach mpi openmp mpi posix thread become increasingly popular optimize memory environment reduce workload network interface however hybridize openmp pthreads etc data thread default downside significant concurrent access complex data structure probability introduce bug significant coordination developer development project introduction mpi remote memory access rma communication mpi standard significant improvement mpi intranode communication reduce network overload bypassing mpi memory increase mpi everywhere program model mpi mpi hybrid mpi standard introduce feature enable mpi within SMP node collectively allocate memory load operation enables memory efficiently data possibility innovative hybrid approach mpi memory model optimization mpi collective unlike typical memory approach openmp posix thread memory private unless explicitly paradigm mpi memory reduces complexity hybrid memory program suffer downside typical memory program although explicitly memory paradigm availability ubiquitous mpi attractive choice developer although improvement mpi mpi hybrid approach dependent significantly reduce access memory data numerical finite fem finite difference fdm etc multi thread aware memory model memory synchronize primitive suitably weak memory model performance standard memory synchronize function mpi mpi mpi hybrid model compiler unaware presence multi thread context hence standard memory synchronize function mpi etc conservative prevent serial compiler optimization execution hardware scheduler memory parallel semantics mpi synchronization optimization barrier non optimal performance standard atomic memory fence equip memory manage concurrent data access reduce stress memory subsystem multi thread aware memory model attractive alternative mpi synchronization function suitable atomic variable std atomic flag suitable weak memory std memory release acquire etc establish memory synchronization prevent undesired memory reorder optimization memory content achieve grain synchronization atomic operation significant improvement performance parallel program albeit increase complexity propose approach intranode communication couple mpi memory atomic operation synchronization illustrate standard communication utility barrier collective reduction operation objective propose compete recent hardware aware hierarchical implementation improve collective operation alternative synchronization approach mpi primitive propose implementation collective operation serf primarily showcase identify potential advantage specific application demonstrate performance apply ghost update classical operation parallel numerical fdm fem evaluate gain performance achieves classical approach standard intranode operation communication manage internode communication evaluate performance mpi mpi hybrid approach reproducible fem avoid confusion computer node fem node mesh refer latter brief background research detail management memory operation inside SMP node performance fundamental operation barrier allreduce intranode data exchange detail extension mpi mpi hybrid approach multi node architecture performance mpi mpi hybrid mpi consists discussion conclude remark background mpi remote memory access mpi extension mpi rma semantics detail brief summary functionality relevant mpi standard introduce mpi rma interface communication communication operation involve consists contiguous memory originally operation available mpi mpi mpi accumulate origin  communication operation memory target operation context active passive synchronization epoch ensure completion communication operation epoch although mpi rma interface portable inadequate revise introduction mpi standard update memory model data consistency originally rma memory model version coexist private locally accessible version public remotely accessible version synchronization synchronization perform local update remote update cannot perform concurrently target non overlap memory mpi unified memory model introduce relax restriction assume identical rely hardware coherent memory subsystem propagate update mpi introduce memory allows allocate memory address unified memory model default atomic operation mpi fetch mpi accumulate atomic update operation epoch synchronization option mpi rma approach synchronization active target synchronization passive target synchronization active target synchronization origin target explicitly participate communication simplest option mpi fence define epoch ensures collective synchronization however generally performance instead synchronization mode flexible local synchronization communicate target exposure epoch mpi access ensures local operation origin access epoch mpi correspond mpi perform remote operation access epoch mpi ensure completion rma operation target exposure epoch mpi correspond mpi passive target synchronization origin participates explicitly communication concept exposure epoch irrelevant expose origin access epoch remote mpi lock mpi unlock despite standard lock mutex lock exclusive synchronization remote operation engage mpi become origin lock simultaneously multiple target introduce function mpi lock mpi unlock access epoch communicator mpi introduce additional function ensure data consistency multiple operation perform epoch mpi flush ensures completion rma operation mpi sync synchronizes private public flush automatically perform access epoch memory model built atomic operation associate memory model local flexible memory synchronization  atomic operation establish operation thread extension correspond atomic non atomic variable memory model particularly inhibits undesired compiler optimization hardware scheduler affect operation desire interprocess establish user optimization suitable weaker memory without detail already explain clearly literature fundamental concept memory sequential program operation happens completes addition atomic operation synchronizes relationship namely default writes atomic variable synchronizes relationship atomic atomic operation operation atomic happens subsequent operation behavior ensure default memory atomic operation sequential consistency sequential consistency ensures atomic instruction execute source code global atomic operation sequential consistency easy ensure logical correctness memory program optimal choice prevents compiler optimization indeed algorithm operation precede operation visible global costly update cache memory modify operation another suitably relaxed memory atomic operation beneficial performance moreover sequential consistency ensure interprocess synchronizes relationship operation release memory load operation acquire memory establishes synchronizes relation operation operation operation load operation operation operation load operation concerned relation reorder compiler image KB image synchronizes relationship release acquire memory arrow ordering interpretation reader refer web version article detail memory model utilized efficiently manage memory communication operation barrier reduce etc later performance respective mpi implementation demonstrate manage mpi memory memory model user obtain performance par algorithm standard mpi library management mpi memory memory model barrier barrier parallel program demonstrate memory model manage mpi memory therefore detail implementation barrier memory environment basis complex synchronize operation later demonstrate memory barrier synchronizes barrier variable atomic counter barrier counter algorithm algorithm memory atomic flag allocate pointer locally allocate memory construct array pointer atomic flag allocate virtual address access mpi query specify info alloc  allocation non contiguous memory pad reduce access latency mem comm communicator memory similarly atomic counter allocate leader pseudo code barrier algorithm detail synchronization behavior image KB image synchronization behavior barrier algorithm counter allocate leader therefore counter involve access memory host another similarly repeatedly atomic flag allocate remote memory operation involve fetch counter clearing atomic flag precede operation relaxed memory sufficient however ensure counter reset increment counter otherwise consecutive barrier deadlock algorithm synchronizes ensure operation synchronization already manage loop enforce relaxed memory barrier inefficient leader flag unnecessary particularly SMP node cpu core clearing flag rank structure node flag algorithm correspond pseudo code progress flag structure broadcast operation detailed image KB image intra node communication barrier synchronization SMP node pin socket node assign socket reduce memory access latency thereby reduce flag socket core per socket pin rank socket ensure node assign socket socket odd rank assign socket respectively operation variable operation scatter broadcast reduce allreduce etc widely building parallel algorithm instance static solver conjugate gradient CG rely heavily vector dot calculation classical parallel program data distribute local contribution operation dot locally calculate local contribution building mpi allreduce allreduce operation logically combine reduce broadcast operation memory implementation intra node allreduce memory pure memory environment butterfly reduction algorithm sum update however applicable SMP node involve internode communication minimum implement algorithm involve reduction broadcast illustrates private variable involve addition local allocates memory tmp non atomic scalar int etc temporary reduction array std atomic flag synchronize gathering initialize std atomic flag synchronize reading image KB image memory variable operation sake simplicity SMP node mpi refer rank leader role sum summation allocates gathering flag broadcast flag whereas allocate gathering flag allocate respectively broadcast flag reduction operation involves schematically depict calculates local contribution dot leader loop respective respectively atomic flag leader leader executes reduction operation locally sum flag reduce global image KB image illustration dot involve task inefficient competition access leader memory leader sequentially local instead structure previous direction invert reduction operation rank operation broadcasting correspond pseudo code allreduce summation operation algorithm image KB image reduction algorithm image KB image algorithm pseudo code allreduce intranode ghost update discretizing domain analysis partition nearly computational load assign partition mpi strategy distribute parallel compute parallelize mesh numerical fem mesh nearly allocate refer inner respective computational iteration connection calculate serial fem implementation however specific treatment boundary indeed belong maintain continuity approach data boundary computation progress without additional boundary update however data careful treatment prevent potential overall performance furthermore reduction potential memory motivation mpi mpi hybrid model data separately local data ideal memory access instance matrix vector multiplication constitute fem operation image KB image structure data communication chose data organization classical mpi program posse boundary refer ghost halo relies intranode memory memory therefore exacerbate memory bandwidth however advantage limit concurrent access data efficient organization memory matrix vector multiplication ghost data continuous contiguous inner data memory organization classical mpi approach easily adapt exist parallel program mpi management communication without modify computational structure vector variable corresponds local connection inner local boundary connection data ghost local ghost data local reduce memory memory sender receiver rank local data contiguous memory location ensure continuity data specific rank rank node vector image KB image vector data node structure previous explain management ghost update schematically update data data memory data buffer memory atomic flag flag proceed buffer local ghost data image KB image intranode communication rank rank algorithm pseudo code intra node ghost update assumes existence snd index snd index rank local snd buffer snd buffer rank pointer memory buffer data rcv buffer rcv buffer rank pointer memory buffer data virtual address obtain mpi query rcv index rcv index rank local snd flag rcv flag snd flag receiver rank sender rcv flag sender rank receiver corresponds atomic flag manage data transfer sender receiver  data 3D displacement algorithm image KB image algorithm pseudo code intra node ghost update experimental evaluation memory operation evaluate performance atomics memory model manage mpi memory standard mpi utility performance conduct reedbush oakbridge CX supercomputer tokyo specification detailed oakbridge CX performance conduct mpi library intel mpi vendor configure compiler optimize intel platform recent version mpi MPICH compile author configuration option mpi oakbridge CX detailed appendix configuration MPICH specification reedbush  CX cpu intel xeon broadwell EP ghz core socket MB cache  intel xeon platinum ghz core socket MB cache gflops memory GB GB  GB  GB OS  enterprise linux OS centos interconnect infiniband  intel omni host fabric interface GB mpi intel compiler version update intel mpi library update mpi intel compiler update intel mpi library update mpi library MPICH library synchronization measurement synchronize arrival mismatch elapse measurement desire function introduce error performance minimize error barrier around immediately elapse measurement improve synchronization mpi barrier mandate quality synchronization arrival mismatch loop mpi barrier heavily impact execution function calculate average performance illustration latency mpi barrier mpi barrier barrier developed previous algorithm barrier implementation significantly synchronization arrival mismatch initial synchronization performance image KB image execution mpi barrier synchronization node oakbridge CX pin latency stable ensure optimal performance algorithm reduce inter socket memory access pin ensure execute command argument intel mpi  hydra proc env mpi pin enable env mpi pin processor scatter mpi  proc bind core rank socket core MPICH  proc bind core  command argument verify binding barrier barrier performance elapse barrier function performance barrier refer shm barrier mpi barrier scenario shm barrier average shm barrier shm barrier average mpi barrier intel mpi mpi barrier consistently memory context architecture however mpi MPICH significant improvement mpi barrier operation variable allreduce performance reduction operation namely sum variable refer allreduce shm allreduce scenario shm barrier average mpi allreduce shm barrier average shm allreduce shm barrier average shm allreduce sequential consistency atomic operation intel mpi mpi allreduce performance approach computer partly explain efficient butterfly algorithm memory however explain earlier butterfly algorithm applicable internode communication involve regardless shm allreduce performance remains mpi allreduce oakbridge CX observable gain optimize memory atomic operation fully sequentially consistent operation performs overall barrier almost performance mpi library significant improvement mpi allreduce mpi MPICH influence binding intel mpi pin option scatter odd respectively memory socket optimal communication conversely bunch option latter rank respectively memory socket numerous  communication architecture gain scatter affinity gain performance highlight advantage binding rank hardware communication frequency volume memory hierarchy SMP node communicate rank mapped cache socket image KB image comparison shm allreduce performance affinity average iteration dot previous performance intranode communication operation however communication operation constituent simulation dot evaluate intranode communication dot vector increase maximum computational performance obtain communication involve performance float operation FP per per core vector float operation roughly initial peak maximum performance corresponds transition cache memory image KB image comparison dot performance memory gap performance due communication vector ratio computation communication increase vector gap decrease significantly ratio significantly oakbridge CX due significant float performance improvement xeon cpu improvement allreduce operation reedbush explain loss performance significant difference mpi allreduce ghost update unlike previous performance ghost update dependent partition distribution data distribution highly irregular dependent analysis domain model unstructured mesh irregular graph unstructured mesh tetrahedral performance generate reproducible cube model dimension mesh generate  version homogeneous average metis partition mesh sample mesh average per average average data FP ghost byte detailed mesh average partition data factor influence communication image KB image cube mesh performance average per data memory partition average exchange data per mesh data reedbush core mesh data oakbridge CX core minimum average maximum execution ghost update mpi approach memory approach memory approach synchronization atomic flag replace synchronization utility mpi library specifically image MB image performance ghost update memory algorithm refer respectively mpi rank sends receives algorithm refers memory ghost data contains boolean flag synchronization equivalent atomic flag although data local update passive target epoch mpi lock unlock ensure update becomes visible public executes remote addition although global access epoch flag mpi lock unlock instead lock increase latency operation around barrier memory communicator algorithm algorithm consecutive function prevent flag twice deadlock algorithm algorithm barrier already ensure mpi fence mpi respectively approach consistently execution mesh mpi library gain become significant increase data exchange finer mesh mpi confirms benefit bypassing mpi mpi recv communication memory node amount data exchange rma function synchronization significant improvement mpi active synchronization involve combination perform collective synchronization enforce mpi fence ghost update similarly passive synchronization competitive performance mpi data perform poorly data apparent minimum execution around mesh exchange data becomes negligible synchronization operation suggests atomic operation perform mpi accumulate mpi fetch significantly costly atomic operation loop relative performance rma synchronization utility varies significantly mpi library passive synchronization intel mpi MPICH prohibitively latency timing intel mpi latency mpi fence MPICH issue directly related program conduct intel mpi benchmark IMB rma oakbridge CX issue library similarly active rma synchronization algorithm apparent deadlock mpi mpi mpi issue resolve standard rma mpi instead memory mpi correspond memory communicator although option latency suspect impossibility mpi ensure exclusive access memory access pointer instead explicit rma operation non overall memory model atomic variable synchronization performs consistently synchronization rma utility management internode communication target approach developed application simulation compute therefore scope cannot limited memory environment SMP node extend parallel environment multiple SMP node mpi mpi hybrid parallel program intranode communication rely memory internode communication standard mpi utility mpi mpi allreduce mpi communicator addition mpi comm shm comm communicator mpi comm SHARED memory communicator inside SMP node rank shm comm leader rank shm comm shm leader leader comm communicator leader memory node shm leader rank leader comm barrier operation variable similarly operation variable reduction largely unchanged operation perform locally inside SMP node perform leader communicator finally leader broadcast memory communicator algorithm modification mpi allreduce algorithm image KB image algorithm pseudo code intra inter node allreduce ghost update ghost update account internode communication effort reduce internode update beneficial organize data continuous intranode update ghost data continuous memory however data continuous similarly intranode hybrid program image KB image vector data node node structure intranode communication manage node independently internode communication latter option option leader node data node communication happens leader comm reception leader node directly data option communication option individually manages communication mpi comm mpi option communication increase SMP node option significantly communication architecture cluster data exchange communication costly communication suggests scenario communication saturate network interface therefore opt mpi treatment internode communication hide internode communication manage independently experimental evaluation mpi mpi hybrid operation evaluate performance mpi mpi hybrid operation previous classical mpi computer architecture SMP node SMP node barrier algorithm scenario execution barrier stable multiple standard deviation SD average node contrary reedbush mpi barrier execution SD average node average mpi barrier performs hybrid approach node execution average average execution reedbush extreme remove minimum extreme mpi barrier extreme consistently simulation extreme comparatively extreme hybrid approach oakbridge CX performance mpi barrier significantly stable SD around average execution consistently latency although difference hybrid approach decrease node involve node latency mpi latency mpi barrier increase MPICH latency increase significantly mpi barrier image KB image comparison barrier execution multiple node average iteration image KB image barrier execution reedbush extreme account average iteration operation variable reedbush approach improves performance node execution stable SD average mpi allreduce variance execution although extreme mpi barrier SD average oakbridge CX performance hybrid approach mpi allreduce stable SD around average execution node performance gain adequate choice operation memory demonstrate node latency mpi latency mpi allreduce increase MPICH latency increase significantly mpi allreduce dot conduct SMP node observation gap maximum performance actual performance significantly SMP node communication become prevalent observation mpi allreduce approach trend average execution however reedbush variance mpi allreduce performance clearly performance relatively stable performance oakbridge CX comparable image KB image comparison dot performance per core node ghost update ghost update performance cube geometry however indeed partition ratio ghost inner node therefore communication relevant calculation standard node partition generate perform partition mesh node perform internal partition node ensures mesh manage node reduces connection node internode communication detail partition information correspond performance partition information mpi hybrid intranode internode average data exchange intranode internode communication per node involve internode communication intranode intranode internode internode internode intranode intranode internode internode internode intranode intranode internode internode internode execution node internode communication perform overall consistently synchronization approach optimal minimum execution average although active rma synchronization intel mpi passive rma synchronization mpi comparable latency computer node increase internode communication increase data exchange communication decrease internode communication perform mpi execution closer although optimal communication remains around due improvement intranode communication average become almost node however rma function relatively poorly hybrid environment data exchange decrease execution consists communication synchronization poorly MPICH significant increase latency node accompany variance reedbush maximum execution significantly longer average consistent performance variance previously mpi function image KB image comparison ghost update execution intel mpi image MB image comparison ghost update execution oakbridge CX mpi MPICH discussion implementation maintenance mpi mpi hybrid approach propose data organization mpi implementation exist mpi program relatively straightforward communication manage independently core program addition data uniquely communication local data risk normally accompany management memory memory corruption significantly alleviate although allocate additional memory communication costly application portion local data exchange minor impact application percentage local data exchange finite approach easy implement maintain standard mpi performance conduct demonstrate combination mpi atomic operation associate memory model performance competes standard approach exceed classical application ghost update pure memory environment standard mpi function perform overall fundamental collective communication utility barrier reduction however approach significantly synchronization gain appropriate memory atomic operation execution incur additional complexity suitable affinity execution multiple SMP node involve mpi function potentially unstable performance cluster propose mpi mpi hybrid approach relatively stable performance regardless compute environment although performance standard mpi function propose approach conditionally average performance nevertheless application gain performance function significant ghost update involves communication exchange data responsible communication parallel program SMP node usage memory significant improvement usage mpi mpi recv although brings marginal improvement synchronization rma operation SMP node performance significantly synchronization memory model performance memory model improve assign partition cpu core SMP node partition involve volume intranode ghost update data mapped cpu core cache socket etc mpi functionality mpi dist graph approach significantly reduce stress memory subsystem improve performance affinity demonstrate rma synchronization perform relatively poorly data exchange memory decrease partly explain increase latency node internode communication identical propose mpi mpi hybrid mpi approach overall costly intranode operation gain performance decrease significantly computer node involve therefore propose approach particularly relevant average data exchange intranode per average data exchange internode per minimum ratio around besides variation performance mpi library rma synchronization node overall performance advantage simulation communication intranode communication occupy non negligible portion execution performance gain relatively consistent option data exchange within memory becomes performance gain mpi becomes significant although improvement rma synchronization becomes marginal exchange data decrease performance gain rma synchronization becomes significant improvement mpi becomes marginal propose memory model rma primitive improve data exchange memory performance gain mpi becomes marginal sizable amount communication internode communication SMP node simulation increase however cluster architecture privilege core per node intranode communication become increasingly prevalent conclude remark propose alternative mpi mpi hybrid program approach intranode communication combine mpi memory atomic operation memory model data organization standard mpi data private relatively straightforward implement exist mpi program maintain performance exist mpi function standard collective communication utility prof stable multiple SMP node involve application ghost update prevalent operation numerical finite finite difference smooth particle  etc exhibit significant reduction communication mpi rma synchronization approach fence