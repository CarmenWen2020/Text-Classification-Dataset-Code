scalability performance parallel iterative application directly affected available compute resource application load imbalance due dynamic computation performance employ periodic load balance tackle issue dynamic load balance algorithm redistribute application workload heuristic circumvent NP complexity however schedule heuristic avoid hinder application performance distribute workload distribute environment technique overhead quality schedule decision parallel iterative application technique relies combine application workload information distribute schedule algorithm initial distribute schedule agent application task pack load minimize message information schedule algorithm PackStealLB distribute memory steal heuristic experimental PackStealLB improve performance molecular dynamic benchmark outperform schedule algorithm scenario almost core previous keywords distribute load balance workload discretization steal introduction scientific industrial application commonly performance compute hpc resource related treat terabyte petabyte research data performance understand epidemic deadline predict hpc application characteristic properly schedule available hpc resource achieve objective platform risk waste costly resource due load imbalance load imbalance emerges application task task resource idle others task workload task workload dynamically evolve execution compute resource task recover node failure load imbalance periodically redistribute task compute resource periodic load balance LB approach application gordon award application namd apply application parallel iterative optimal mapping task compute resource NP complexity moreover application periodic load balance employ schedule heuristic dynamically redistribute workload showcase commonly heuristic fail achieve operating task compute resource due issue schedule decision due overhead without scalable periodic load balance scalability hpc application compromise longer execution waste compute resource propose scalable load balance approach combine distribute load balance discretization application workload approach reduces schedule overhead apply execute schedule distribute fashion perform workload discretization simplify decision local task avoid numerous grain migration minimize message schedule actor discretization technique pack extends previous technique notion related nash equilibrium PackStealLB distribute load balance algorithm pack inherits related constrain randomize steal WS heuristic experimental evaluation PackStealLB LeanMD molecular dynamic benchmark namd compute node core supercomputer   SKL benefit PackStealLB LB overhead reduce task migration preservation locality task reduce application execution overall contribution workload discretization pack extends previous novel distribute WS periodic load balance algorithm PackStealLB implementation PackStealLB charm runtime load balance distribute memory scenario experimental evaluation algorithm remainder discus related periodic LB WS distribute model notation pack model load balance algorithm discus implementation detail charm performance evaluation finally concludes related WS LB technique scope novel decentralize load balance WS heuristic regard distribute load balance mechanism task parallel application simpler WS scheme executor steal workload another former idle WS scheduler classify distribute receiver initiate load balance scheme underloaded processing request load overload LBs periodically invoked remap workload LBs exist flavor regard topology centralize distribute commonly implement sender initiate scheme periodic LBs target application WSS bulk synchronous parallel BSP iterative data parallel application efficient persistence technique allows scheduler accurately predict load task LB WS approach advantage notably WS apply task parallel runtime  memory scenario distribute although highly unpredictable application distribute memory LBs widely apply distribute memory scenario due periodic apply application principle persistence application dynamic workload tends slowly although traditionally implement centralize scheduler LB performance towards distribute approach limited strategy propose WS emerges source inspiration novel LB policy specially convergence WS scenario discus recent periodic LBs WS solid novel approach periodic load balance LBs category behavior global diffusive global approach centralize hierarchical scheduler balance load approach aggregate relevant information precise understand application potentially overhead  application hierarchical algorithm usually underlie locality schedule task strategy reduce overhead relevant hierarchical algorithm graph hypergraph partition  multi partition parallelize schedule approach reschedule task reduce decision meanwhile scotch metis classical graph partition technique dual recursive bipartitioning coarsen task fashion hop max congestion topology information enhance classical graph partition algorithm schedule task diffusive approach classic greedy algorithm principle optimize locally optimize globally strategy imbalance issue narrower scope local information   scheduler probabilistic transfer load parallelism achieve balance global load balance strategy although strategy scalability scarce preservation locality secondary objective schedule affect performance application strategy topology account promising trend global schedule preserve locality instance  load balancer considers latency non uniform memory access numa network likewise  topology mapping machine topology consideration approach differs platform agnostic locality preserve task bundle migrate avoids explicit information machine topology distribute schedule agent nevertheless addition topology awareness algorithm future approach PackDropLB attempt preserve affinity task resource prior migration completely disregard network topology workload memory scenario  openmp loop schedule schedule pack placement reduce fragmentation 3D torus hpc steal scheduler WS scheduler inherently distribute WS independent schedule agent manage resource parallel role thief attempt dynamically remap underloaded idle resource manage workload task constantly available compute victim target chosen thief task steal WS scheduler commonly apply dynamic imbalanced application cannot afford stable decomposition apply parallel application decomposable acyclic graph dag application decompose model fork task parallelism parallel loop memory benefit WS topology aware approach WS strategy greatly increase application performance  steal approach information task steal attempt victim local remote increase task locality scheduler manages subgroup core attempt migrate within subgroup core remote core  contention locality aware steal runtime numa architecture task migration reduce remote memory access fashion  localize hierarchical steal compensate imbalance task parallel application approach  application task affinity instead topology awareness task favorable migration data steal attempt distribute memory machine  steal apply benefit persistence load balance WS model distribute memory mpi environment approach persistence model iterative application instead reschedule workload iteration resource task iteration improve balance application execute perform steal appropriate discussion distribute scheduler periodic load balance domain WS heuristic attractive due document convergence however distribute strategy adapt achieve harmony balance load locality quickly compute mapping aim achieve pack scheme PackDropLB strategy  WS randomize WS periodic schedule scenario correctly adapt aim achieve harmony explain distribute schedule model explain pack model PackDropLB algorithm PackStealLB schedule model notation parallel application described task load task denote sake simplicity extend notion load task assume load empty arbitrary task identical machine resemble  parallel application machine notation core hpc platform additionally machine subset task assign machine unique schedule agent load balance decision local compose task assign indexed communication machine identifier remain information decision entirely derive local communication agent lossless objective load balance minimize application makespan distribute load evenly across machine describes load machine bound makespan optimal schedule parallel machine NP achieve mapping yield core unrealistic situation focus assign task machine makespan approximates relaxation imbalance characteristic application parameter schedule load machine relaxed makespan bound objective reflect load task schedule greedily compute centralize fashion assign task machine distribute fashion makespan approximates theoretic achieve nash equilibrium concept widely apply distribute algorithm achieve nash equilibrium agent scheduler profit action modify machine target parallel application non uniform non preemptable task leverage persistence load balance algorithm usually implement asynchronous runtime improve load balance application pause reschedule meaning LB overhead application load balance strategy quickly actually diminish application makespan local schedule agent executes LB algorithm interruption message execute predecessor communication asynchronous message PackStealLB steal load balancer detail workload discretization load balancer PackStealLB discus characteristic limitation previous algorithm PackDropLB workload discretization apply distribute LB improve schedule preserve task locality finally detail distribute WS LB propose workload discretization pack model overcomes aforementioned limitation previous approach limitation previous effort PackDropLB distribute algorithm migrates pack task overload underloaded machine introduce previous overall PackDropLB executes LB agent exchange message compute average load agent load correspond machine overload agent pack task fix threshold underloaded agent gossip protocol propagate machine load information global barrier synchronization overload agent pack task randomly chosen underloaded target reject pack become overload reject pack overload agent random target fix criterion PackDropLB effort improve scalability LBs iterative  parallel application although promising global diffusive LBs limitation information propagation gossip protocol task migration synchronize global barrier message overload agent pack task discard underloaded target agent former waste target agent inferior performance diffusive LBs application platform overall issue significant impact LB overhead scalability platform latter limitation usually outcome issue application workload discretization pack model load balance scenario described discrete continuous discrete describes uniform non preemptable task continuous describes non uniform preemptable task pack model aim improve schedule approximate load balance scenario discrete scenario objective pack reduce schedule simpler task migrate task approximate load reduce message exchange agent multiple task migration message preserve locality application assume mapping already grouped communicate task machine recall fix parameter schedule load machine account schedule agent subset task satisfied subset corresponds task agent intend migrate moreover subdivide disjoint task pack almost load migrate workload discrete task non preemptable agent aggregate pack pack respect accord fix parameter focus discretization overload task machine overload greedy approximation algorithm bin pack assign task pack migration slightly adapt bin pack context unlike bin pack agent selects subset task insert pack adaptation load pack cannot task arbitrary task inside currently pack load task inside update otherwise pack cannot insert another task task decision creation pack task pack task inside previous pack respect indeed pack generate sum agent load strictly computes task pack satisfied imply pack generate algorithm load balance LB PackStealLB distribute LB motivate  randomize WS  aspect information propagation randomize aspect victim selection PackDropLB PackStealLB migrates pack task reduce schedule preserve task locality description algorithm PackStealLB progressively load machine performs decision due attachment sender local load information message target peer information broadcast message exchange algorithm agent aware load machine however agent sends message load information message agent already attain information load peer information message sends piggyback fashion image KB image PackStealLB described algorithm standardize notation distribute algorithm split init describes initial calculation role determination victim thief initial issue reduction ass average load calculates steal thief agent pack load fix define experimentation agent role victim thief load victim thief agent victim load agent thief load thief agent victim role victim assemble pack hint message warn potential thief potential thief machine load uniformly random choice perform local information victim victim load machine communicate victim machine agent receives hint relevant information peer load additionally agent victim hint thief informs agent others incrementally assist future steal attempt thief attempt  target machine victim sends steal message attempt previously agent receives message increase agent victim steal message information victim selection constrain randomize standard choice constrain selection uniformly random load machine agent perform selection local information cannot load machine sake simplicity estimation assume machine assume load denote load machine agent formally configurable threshold constrain selection surpasses agent randomize victim selection simply machine index uniformly random steal message machine victim load pack additionally agent register task migrate runtime scheduler perform migration meanwhile agent victim steal another victim portray distinct aforementioned victim selection behavior randomize inform selection respectively finally agent receives TASKS message meaning agent thief task pack task update load asynchronous distribute algorithm synchronization mechanism perform operation although PackStealLB barrier algorithm coordinate execution ass global information perform via  detection meaning agent message queue synchronize convergence complexity assume machine victim definition correspond exists machine load machine thief   define message machine load compute complexity message migration boil initialization phase victim initiate thief migration task victim thief initialization phase mainly devote compute reduction complexity message moreover hint message agent load deduce victim sends hint message machine knowledge load belief load others message thief victim cannot hint message initiate victim twice hint message initiate victim victim deduce entire hint message communication correspond task migration perform focus agent implies agent victim agent creates pack satisfied task migrate load agent load moreover agent become thief algorithm precise victim creates pack migration communication correspond task upper bound migration communication obtain entire communication devote task migration bound tight machine task communication correspond victim initiate thief mainly depends knowledge machine thief load randomly sends  machine knowledge load belief load others message victim thief receives message message contains route  thief deduce machine sender message victim thief implies machine cannot become victim thief agent victim thief incentive  machine moreover thief sends  message contains information agent thief message entire agent victim agent receives  initiate agent victim agent upper bound entire  correspond retransmission  migration task trigger thief message correspond initial  message devote task migration conclude entire message implementation implement PackStealLB charm distribute load balance framework charm receptive runtime LB strategy distribute memory allows application already exist environment charm load balance framework commonly sequence pause application organizes execution statistic scheduler computes schedule migrates task resume application execution framework apply namd instance nevertheless periodic load balance parallel application execution charm workload decompose independent migratable virtual processor  usually geometric decomposition scheme charm message driven asynchronous rts meaning issue  task message load balancer implement  meaning benefit charm native synchronization mechanism perform reduction operation  detection    load usually execution load balance runtime core load sum  load background spent activity communication variable beforehand ideally pack load mitigate algorithm complexity however pack potential gap ideal pack tend tighter quality load balance propose calculate factor maximum overall imbalance additionally coarsen factor pack described detailed relaxation factor define pack imbalance tolerance meaning core balance load interval plausible scenario scheduler charm meanwhile pack narrow factor fix optimize balance accelerate algorithm define neighborhood PackStealLB initial algorithm schedule agent predetermine charm attribute index computational resource nutshell core processing node assign integer ascend processing node core unique indeed homogeneous cluster index core local remote instance cluster node core node attempt local constrain WS phase global machine randomize finally victim selection strategy threshold empirical platform ass performance PackStealLB performance evaluation perform experimental evaluation workload discretization model PackStealLB evaluate scalability algorithm handle molecular dynamic benchmark supercomputer evaluation comparison PackStealLB LBs baseline execution charm  capture statistic performs actual load balance overview metric statistical experimental environment detail molecular dynamic benchmark analysis obtain brief description LBs  description  load distribution communication assigns task core processing LPT policy  minimize migration migrates task overload underloaded resource  strategy probabilistic transfer load task receiver information gossip protocol  strategy migrates pack task overload underloaded machine information gossip protocol experimental methodology environment metric statistical PackStealLB LBs experimental environment finally brief overview molecular dynamic benchmark discus experimental raw file script analysis available metric statistical methodology involves evaluation factor execution makespan application execute load balance invocation invoke LB resume application migration useful application execution exclude load balance invocation minimize application execution important objective factor enables execution scientific application nonetheless LB overhead load balance migration important allows LBs application comparison metric confidence interval threshold significance statistical comparison organize sample execution LB normal distribution kolmogorov smirnov reject null hypothesis parametric comparison welch sample otherwise nonparametric mann whitney wilcoxon rank dependent sample reject null hypothesis version perform meaning perform differently experimental environment   SKL supercomputer contains numa compute node interconnect EDR infiniband node feature core intel xeon ghz CPUs GB ecc ram ddr memory mhz employ compute node core   SKL enterprise linux load OpenMPI intel module charm version instal machine target mpi linux option production charm molecular dynamic benchmark compile flag molecular dynamic benchmark experimental molecular dynamic benchmark LeanMD LeanMD performs core computation gordon award application namd realistic scenario impact novel LBs parallel implementation LeanMD 3D spatial decomposition approach 3D consist standard LeanMD configuration available online parameterized dimension computes actual  multiple particle manage communication parameter varied execution LeanMD comprises iteration execute load balance iteration iteration sum LB parameter combination generate simulation experimental evaluation repetition parameter combination input load balance algorithm specifically   SKL supercomputer scheduler multiple user organize contains repetition LBs input involve repetition input LB execute random objective avoid user affect LB objective execute LeanMD input capability LBs benchmark creates particle per dimension parameter particle simulation imbalance application input increase analysis discussion execution LeanMD input load balancer illustrate boxplots baseline PackDropLB PackStealLB execute input due increase LeanMD performance LBs input glance portrayed PackStealLB LB consistently reduce execution LeanMD baseline PackDropLB fail outperform baseline scenario RefineLB  achieve performance baseline  increase execution LeanMD situation image KB image boxplots execution LeanMD input load balancer   SKL variation application dimension parameter vertical axis emphasize performance difference image KB image LeanMD speedup load balancer verify performance algorithm statistically apply welch sample chosen sample normal distribution comparison PackStealLB PackDropLB baseline conclude execution actually baseline suspect verify PackStealLB outperforms PackDropLB outperform PackDropLB difference finally statistical difference performance RefineLB  baseline respectively RefineLB baseline indicates PackStealLB PackDropLB impact LeanMD execution input increase speedup achieve baseline load balance input PackStealLB achieve speedup increase input PackStealLB PackDropLB significantly compete LBs emphasize scalability capability handle load imbalance image KB image median load balance invocation LB application execution data displayed mention earlier execution LeanMD decompose load balance invocation overhead execution application useful application actual compute molecular dynamic focus load balance invocation display median load balance invocation LB due difference multiple magnitude chose median sample normal distribution displayed highlight multiple aspect LBs aspect load balance invocation usually longer scenario difference invocation significant scenario wilcoxon rank exception baseline PackDropLB PackStealLB respectively behavior baseline execution conclude affected behavior application charm LB framework situation comparison LBs limited invocation overhead centralize synchronization data organization baseline execution invokes charm  LB  RefineLB longer baseline RefineLB RefineLB longer demand decision migration instance RefineLB migrates task LB invocation  migrates almost task efficiency diffusive algorithm evident centralize approach application platform difference span magnitude difference pack algorithm PackStealLB  instance PackStealLB LB  additionally PackStealLB invocation statistically PackDropLB exception LB mann whitney LB invocation execution remains useful application useful application scenario LB average useful average chosen sample normal distribution extend insight execution instance besides PackStealLB RefineLB improve LeanMD performance highlight importance overhead periodic LB algorithm gain task distribution erase LB invocation RefineLB PackStealLB achieves useful application clearly emphasizes quality schedule decision  achieves baseline diffusive algorithm performance improvement automatically finally  increase useful application application become balance difference  RefineLB mapping preserve performance issue generate  disregard task locality conversely preservation locality important characteristic pack scheme explain PackStealLB PackDropLB outperform algorithm conclusion experimental PackStealLB pack scheme achieve objective improve schedule reduces useful execution platform input achieve load balance diffusive algorithm preserve locality application task migrate average useful application LBs  baseline  RefineLB  PackDropLB PackStealLB conclusion developed workload discretization pack periodic LB PackStealLB diffusive scheduler employ technique PackStealLB LB employ WS heuristic constrain randomize victim selection implement PackStealLB charm rts molecular dynamic benchmark LeanMD PackStealLB previous LB PackDropLB multiple LBs available charm   SKL supercomputer PackStealLB effective LB algorithm PackStealLB achieve speedup execution baseline dummy LB statistic application useful application execution without LB overhead achieve speedup algorithm PackDropLB PackStealLB combination factor PackStealLB balance application load without disturb locality thanks pack scheme whereas algorithm   increase useful application due disregard locality additionally overhead millisecond LB invocation enables application benefit improve task distribution execution contrast RefineLB LB invocation hid benefit schedule decision finally pack PackDropLB PackStealLB WS heuristic perform similarly emphasizes PackStealLB gain due diffusive workload discretization schedule heuristic development effective distribute load balancer indeed crucial future application parallel scenario establish distribute schedule algorithm explore achieve exascale grade schedule develop distribute scheduler target hpc application concept deterministic load balance selfish load balance additionally intend develop pack strategy leverage task communication network topology task communicate exchange data pack whenever finally evaluate PackStealLB workload application usage scenario