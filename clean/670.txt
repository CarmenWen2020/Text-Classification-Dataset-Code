exist graph framework gpus adopt vertex centric compute model vertex thread mapping apply irregular graph significant load imbalance within simd vertex thread mapping uneven distribution within simd utilization simd inefficient memory bandwidth introduce graph GW architecture improve graph application gpus vertex simd mapping scalar mechanism efficient execution narrow simd width cluster issue approach reuse instruction thoroughly evaluate GW architecture timing detailed gpgpu sim simulator graph non graph benchmark variety benchmark suite GW architecture average maximum speedup graph application obtains performance improvement regular improvement irregular benchmark previous keywords gpgpu gpu microarchitecture graph application scalar simd efficiency introduction graph application domain graph application graph candidate acceleration gpus immense performance efficiency execute data parallel application accelerate graph algorithm gpus remains challenge gpu compute exploit data parallelism utilizes simd execution efficiency thread bundle warp cuda terminology OpenCL terminology warp PC execute instruction synchronization pipelined simd processing simd across simd processing execution model gpu friendly application uniform regular memory access however application arbitrary irregular memory access suffer utilization simd processing inefficient memory bandwidth unfortunately graph application category due data dependent dynamic characteristic exist graph framework gpus adopt vertex centric compute model programmer express graph algorithm operation apply vertex typically vertex mapped simd thread amount associate vertex differs across vertex uneven distribution within warp utilization simd processing intra warp imbalance prior vertex warp mapping vertex warp mapping perform vertex distribute thread within warp vertex warp mapping aid reduce intra warp imbalance however without adopt gpu micro architecture cannot utilization simd processing aim improve utilization simd processing graph application gpus leverage vertex warp mapping scalarized vertex centric parallel graph compute gpus introduce graph architecture scalarized vertex centric graph compute maintain efficiency simd execution regular gpu application vertex warp mapping exist gpu architecture computation vertex become redundant within warp inefficient simd processing eliminate redundant computation adopt scalar execution SE propose prior model scalarized vertex centric parallel graph compute model programmer annotate redundant computation scalar operation fully utilize scalar execution adopt exist gpu architecture scalarized vertex centric graph compute employ scalar SW dynamically scalar operation possess PC executes scalar simd pipeline improve utilization simd processing customize scalar scalarized vertex centric graph compute challenge irregular application narrow simd width simd therefore employ narrow simd cluster issue logic maintain benefit issue width regular application narrow simd utilization simd processing vertex fully utilize lane simd however narrow simd width reduce efficiency increase pressure fetch decode stage significantly harm performance regular application performance tightly couple efficiency address propose architecture leverage instruction eliminate redundant fetch decode instruction across warp iteration loop graph friendly architecture graph GW architecture contribution outline analytic approach vertex centric graph compute benefit vertex warp mapping reduce unbalanced distribution within warp  memory access vertex warp mapping introduces redundant computation within warp eliminate redundant computation scalarized vertex centric graph compute scalar architecture scalarized vertex centric graph compute programmer advantage scalar execution annotate redundant computation scalar fully utilize scalar architecture scalar enables efficient hardware resource perform scalar execution exist gpus simd width efficiency highly regular application graph application scalarized vertex centric graph compute benefit narrow simd width argue narrow  reserve benefit wider issue novel introduce narrow simd cluster issue logic narrow simd pressure harm performance propose overcome issue leverage fetch decode instruction across warp iteration loop introduce gpu combine introduce GW architecture orchestrates architecture combine scalar architecture narrow  cluster issue logic decode instruction reuse thoroughly evaluate scalarized vertex centric graph compute GW architecture demonstrate significantly improves performance graph application sustain performance regular application remainder organize briefly gpu execution model baseline gpu micro architecture explain application vertex centric data parallel graph compute gpus discus inefficiency introduce scalarized vertex centric parallel graph compute graph architecture combine finally detail evaluation methodology benchmark discus simulation review related conclude gpu execution model baseline gpu microarchitecture baseline gpu model nvidia  gpus nvidia fermi architecture baseline gpu architecture compose array multi thread simd processor multi thread simd processor accommodates chip hardware execution context execute thread thread warp thread warp PC execute instruction lock conditional thread warp conditional divergence occurs handle divergence simd execution serialize execution conditional execute serially enable disable thread outcome serialize execution simd processing utilized due disabled thread alternative warp active mask stack conditional execution organization multi thread simd processor baseline gpu architecture multi thread simd processor consists fully pipelined simd execute warp interleave manner simd responsible simd instruction execute cycle fetch issue instruction request warp instruction fetch decode checked dependency  decode instruction instruction buffer slot dedicate instruction slot instruction buffer warp scoreboard entry organize access warp  cycle scheduler dispatch instruction warp instruction dispatch execution operand collector assign input operand multi register file exist lane SP function SFUs load LD ST handle access memory data cache address coalesce perform merge access simd lane memory handle conflict processing serialize manner typical vertex centric parallel graph compute gpus graph algorithm pagerank discussion algorithm link popularity incoming link document determines document importance pagerank iterative algorithm document rank calculate recursively rank document link implementation pagerank algorithm  implementation implement cuda kernel widely graph representation compress sparse csr format input graph array vertex rank vertex pointer outgo array vertex destination outgo consecutive array array vertex dummy vertex denote array rank vertex vertex computation rank algorithm loop execute kernel kernel repeatedly convergence happens loop predetermine iteration listing kernel performs calculation rank vertex implementation cuda code vertex sends rank loop update update vertex sum calculate rank implementation vertex centric parallel computation vertex simd thread mapping apply image KB image pagerank algorithm discussion apply graph algorithm fundamental computation kernel computation vertex perform expand gathering information vertex update vertex  kernel summarize pseudo code fundamental computation discussion representative  kernel pagerank algorithm graph kernel refer computation expand computation inefficiency vertex centric graph parallel compute gpus typical implementation vertex centric parallel graph kernel expand computation suffers serious performance penalty input graph highly irregular vertex divergent per vertex varies discus primary source performance penalty image KB image typical vertex centric parallel graph compute gpus illustration shortcoming input graph data structure graph mapping vertex simd thread fundamental computation graph kernel simd lane utilization access array expand perform computation intra warp load imbalance utilization simd intra warp load imbalance distribute unevenly across thread warp unfortunately uneven load distribution utilization simd severely hurt performance vertex centric parallel graph compute load imbalance within warp computation kernel perform subset vertex due vertex others vertex iteration perform computation listing across vertex thread warp shorter simd thread warp longer execute loop illustrate unfortunately graph irregular distribution vertex graph  pagerank vertex average vertex irregular graph highly limited simd thread warp active simd processing utilized understand significance load imbalance within warp utilization simd graph algorithm breakdown execution cycle function active simd thread warp illustrate utilization simd processing evaluation graph application simd pipeline  due load imbalance simd fully utilized execution cycle furthermore execution cycle simd processing active non coalesce memory access typical vertex centric parallel graph compute additional performance degradation non coalesce memory access memory divergence memory operation generates multiple memory transaction access simd thread warp cannot coalesce request memory divergence arises thread warp encounter memory access due data cache memory conflict  memory access instance expand thread warp disperse memory fetch data memory transaction perform memory operation entire warp thread warp memory access memory request generate access array warp iteration loop amount non coalesce memory access significant graph application average memory request per memory access graph benchmark amount average memory request per memory access graph benchmark memory request per memory access average conclude non coalesce memory access significant graph application indeed non coalesce memory access memory divergence data intensive irregular application graph algorithm non coalesce memory access increase memory bandwidth pressure memory divergence therefore performance degradation consumption scalarized vertex centric parallel graph compute overcome shortcoming typical vertex centric parallel graph compute expand computation leverage scalarized vertex centric parallel graph compute scalarized vertex centric parallel graph compute combine mapping vertex warp utilize scalar execution SE vertex warp mapping aim overcome intra warp load imbalance redundant computation within warp scalar execution eliminates redundant computation within warp minor modification baseline gpu microarchitecture scalarized vertex centric parallel graph compute programmer associate vertex warp construct algorithm distribute simd thread warp annotates scalar code implement algorithm compiler scalar instruction programmer annotation static scalarization analysis execution hardware utilizes scalar execution SE instruction execute scalar instruction vertex warp mapping mapping vertex warp advantage improve simd utilization memory access coalesce vertex mapped warp vertex distribute simd thread within warp therefore simd thread warp almost amount improves utilization simd memory operation become  illustrate advantage vertex warp mapping approach input graph computation model vertex warp mapping summarize model utilization simd memory access loop illustrate respectively idle simd processing vertex warp mapping however utilization simd iteration loop vertex warp mapping intra warp load imbalance due diverse distribution vertex becomes significant scalar execution SE eliminate redundant computation redundant computation specific vertex centric parallel graph compute vertex warp mapping indeed redundant computation exist gpu kernel former amount redundant computation significantly application amount redundant computation various gpu benchmark execute instruction perform redundant computation benchmark average approximately computation redundant across benchmark scalar instruction redundantly execute simd pipeline scalar hardware utilize scalar execution eliminate intra warp redundant computation SE static dynamic identification scalar instruction described identify scalar instruction scalar flag kernel binary scalar flag trigger scalar execution simd image KB image amount redundant computation various gpu benchmark graph benchmark employ static identification scalar operation programmer annotation compiler analysis propose instruction architecture ISA modification baseline multi thread simd processor SE explain technique scalar identification SE scalarized vertex centric parallel graph compute program scalarized vertex centric parallel graph compute scalarized vertex centric parallel graph compute expose warp simd programmer warp become explicitly program model expose warp program model introduce intrinsic warp simd width warp allows simd thread query ID warp belongs simd width simd width gpu model image KB image programmer warp vertex warp association identify associate vertex simd thread vertex modify code listing pagerank  kernel listing illustrate application program approach introduce scalarized vertex centric parallel graph compute identification scalar operation compiler annotation compiler analysis programmer annotate scalar code compiler instruction scalar instruction compiler easily extend scalar annotation scalar instruction flag binary listing illustrate compiler annotation scalar utilizes compiler analysis extend identification scalar operation purpose compiler analysis technique divergence analysis identify initial identical input operand variable constant broadcast multiple instruction variable identify identical tag accordingly later analysis traverse tag data dependence analysis output variable marked identical compute identical variable instruction possess identical input operand generate identical marked scalar instruction perform analysis conservative identical variable scalar instruction architectural scalar execution simd undefined ISA extend ISA extra instruction machine code trigger scalar execution modify instruction buffer entry flag identify scalar instruction runtime graph architecture scalarized vertex centric parallel graph compute performance improvement SE scalarized vertex centric parallel graph compute limited without adapt exist gpu microarchitecture propose modification baseline gpu architecture introduce graph GW architecture GW combine approach narrow simd width cluster issue approach employ decode instruction extends employ scalar SW architecture remain explain modification ISA baseline gpu micro architecture implement graph simd architecture narrow  cluster issue scalarized vertex centric parallel graph compute utilization simd pipeline input graph vertex distribution vertex graph graph suggests employ narrower simd width utilization simd pipeline graph application propose GW architecture warp organize available simd processing simd executes odd numbered warp dedicate scheduler scheduler odd warp PC issue simd issue cluster odd warp PC however memory divergence occurs warp diverge without warp synchronization scheduler PC odd warp schedule alone idle simd inactive mode saving scheduler simd aggregate issue logic cycle scalar regular warp instruction issue simd instruction narrower simd width issue logic utilization simd divergence increase warp likely pressure pressure severely harm performance highly regular application performance tightly couple efficiency understand impact pressure performance perform benchmark varied simd width issue logic simd performance performance clearly pressure performance degradation benchmark overcome pressure exploit redundancy instruction fetch decode aim reuse decode instruction simd execution cycle highly likely instruction across warp across loop iteration fetch decode operation redundant advantage redundancy already fetch decode instruction modification fetch organization instruction buffer organization instruction storage decouple warp illustrates instruction storage organization instruction storage organize associative cache entry instruction storage tag identify entry valid reference counter scalar instruction scalar entry detail opcode operand etc decode instruction instruction instruction schedule cycle warp instruction issue PC calculate issue warp instruction storage checked instruction already exists fetch decode reference counter instruction incremented pointer entry insert PC pointer warp status wst  flag wst warp instruction fetch fetch arbitrates warp  flag available fetch buffer instruction fetch cycle image KB image pressure performance due narrow simd width efficient execution scalar instruction SE simd pipeline utilizes explain simd lane lane unused available lane scalar instruction batch execute simd fashion execution kernel likely multiple warp execute scalar instruction multiple warp execute scalar instruction possess PC grouped scalar execute simd fashion simd pipeline prior introduce scalar SW dynamically scalar instruction execute improve utilization simd lane scalar operation scalar location thread warp eliminate redundant storage scalar scalar modify register file enable SW execution modification baseline multi thread simd processor consist modification instruction buffer differentiate scalar instruction scalar formation  scalar status  manages formation scalar modification register file efficient storage scalar scalar flag instruction scalar newly swf subsection formation schedule scalar storage scalar detail scalar formation simd instruction decode insert buffer instruction storage scalar instruction scalar flag buffer entry register dependency instruction resolve scalar status  update  checked exist scalar entry  PC  available entry  allocate scalar instruction  exists PC   exist  correspond scalar mask   associate warp instruction buffer SW valid flag instruction associate scalar pending scoreboard entry dependency associate instruction warp entry entry cannot allocate  scalar instruction becomes available  schedule scalar cycle scheduler warp schedule warp schedule odd schedule active scheduler cannot warp schedule  interrogate scalar available schedule scalar schedule issue flag  scalar ID  scalar mask  scoreboard entry scalar scoreboard issue scalar execution entry scalar  release  scoreboard clearing register status scalar scoreboard scalar register storage scalar scalar operation scalar operation organize register file GW architecture simd issue simd therefore register entry scalar operand warp scalar per warp GW architecture reserve unique static scalar ID  scalar similarly tag grouped scalar register entry tag differentiate non scalar register entry scalar register entry access  operand warp correspond scalar hardware consumption GW architecture modifies scoreboard instruction buffer storage scheduler issue scalar formation baseline gpu architecture modify access management instruction storage buffer increase available storage instruction instruction buffer storage GW architecture increase significantly GW dynamic consumption reduce execution instruction fetch decode however increase static consumption due newly hardware GW architecture specifically focus performance aspect GW architecture detailed estimation consumption GW architecture future evaluation experimental setup model propose hardware scheme GW architecture modify version gpgpu sim simulator gcc version gpgpu sim capable cuda OpenCL application various non graph cuda benchmark graph benchmark benchmark compile nvidia nvcc version compile nvcc option nvcc arch subsection detail benchmark configuration parameter simulation benchmark non graph benchmark rodinia parboil benchmark suite nvidia cuda sdk benchmark graph benchmark  rodinia benchmark suite classify non graph benchmark category utilization simd lane benchmark fail utilize simd lane execution classify irregular benchmark remain benchmark classify regular benchmark non graph benchmark graph benchmark regular irregular benchmark evaluate characterize regular    aes encrypt aes   betweenness BC backpropagation BPR 3D laplace solver LPS betweenness BC  potential CP  mum breadth bfs 1D discrete haar wavelet decomp     breadth bfs fourier transform fft NN digit  NN graph clr eco   monte carlo lib queen solver  graph clr cir circuit finder PF pagerank prk COA  image KB image performance GW architecture relative architecture regular irregular graph application simulation configuration gpgpu sim model baseline gpu nvidia fermi gpu architecture perform simulation configuration parameter model baseline gpu architecture graph architecture GW baseline gpu architecture GW architecture multithreaded simd processor rate ghz multithreaded simd processor KB cache byte associativity KB memory KB cache byte associativity multi thread simd processor memory partition partition dram channel memory model ghz rate multi thread simd processor device memory crossbar ghz rate multi thread simd processor employ scheduler baseline architecture scheduler GW architecture robin model schedule warp baseline architecture GW architecture employ modify version robin schedule explain GW architecture scheduler selects warp scalar execute performance graph architecture performance GW architecture performance GW architecture normalize architecture regular benchmark performance improvement average geometric GW architecture CP obtain speedup respectively  obtains speedup insignificant performance improvement lib fft insignificant performance degradation BPR performance improvement irregular benchmark GW architecture irregular benchmark benefit narrow simd width performance improvement GW average irregular benchmark   NN LPS obtain speedup respectively performance improvement mum graph application characterize irregular irregular benchmark graph benchmark narrow  benefit scalarized graph compute model GW architecture obtains amount performance improvement graph benchmark around performance improvement average GW architecture speedup bfs bfs benchmark respectively depth analysis graph architecture performance performance GW architecture depends factor discus factor detail performance benefit scalarization scalar besides scalar operation code factor affect performance benefit scalar cycle multi thread simd processor issue instruction stall due downstream pipeline stage memory dependency dependency issuable warp cycle depends occupancy simd processor dependency exist application scalar operation issue cycle scheduler warp schedule versus remain idle otherwise issue scalar operation benefit performance processing idle later cycle detailed performance analysis statistic issuable warp schedule cycle warp issuable warp valid instruction unresolved dependency instruction input operand data dependency availability issuable warp scalar operation issuable scalar affect benefit scalar closer issuable scalar cycle detailed analysis statistic issuable scalar schedule cycle scalar instruction issuable instruction valid scalar instruction input operand data dependency besides issuable warp issuable scalar scalar issue scalar pack factor scalar distribution processor cycle issuable warp distribution processor cycle issuable scalar regular irregular graph application image KB image cycle breakdown issuable scalar regular irregular graph application image KB image cycle breakdown issuable warp regular irregular graph application image KB image distribution scalar scalar regular irregular graph application instance scheduler issuable multi issuable warp comparably PF fft CP BPR benchmark regular benchmark amount issuable scalar PH fft BPR benchmark regular benchmark distribution scalar scalar regular irregular graph benchmark pack rate scalar PF benchmark significantly availability issuable warp issuable scalar combine scalar pack rate performance PF improves regular benchmark fft BPR benchmark amount scalar pack rate however fft BPR benefit availability issuable warp issuable scalar PF benchmark amount multi issuable scalar pack scalar instruction effective lib issue scalar scalar closer lib benchmark understand behavior significant execute scalar instruction due scalar global memory access tight loop scalar instruction loop data dependent another negatively impact ability pack scalar lib irregular benchmark  LPS attention availability issuable scalar issuable warp exhibit scalar pack rate altogether affect performance application positively despite rate issuable warp mum amount issuable scalar scalar pack rate therefore benefit scalar graph application rate issuable warp scalar pack rate amount issuable scalar bfs clr eco clr cir benchmark besides factor graph benchmark benefit occupancy rate scalarization instruction evaluate effectiveness GW reuse instruction reduce fetch decode operation relative fetch decode operation perform GW architecture rate instruction reuse fetch decode exception benchmark lib mum  bfs instruction reuse effective benchmark increase rate instruction fetch decode narrow simd width despite amount scalar instruction benefit scalarization pressure affect performance lib due rate warp issue alone instead issue image KB image normalize instruction fetch decode GW architecture normalize architecture regular irregular graph application image KB image utilization simd regular irregular graph application simd thread active cycle scheme applies image KB image normalize memory transaction GW architecture regular irregular graph application utilization simd graph architecture breakdown execution cycle function active simd thread warp illustrate utilization simd lane GW architecture simd width aggregate issue therefore lane utilization GW architecture GW architecture narrow simd width employ cluster issue schedule odd simd warp schedule cycle however scheduler cannot odd warp schedule odd warp schedule happens simd lane utilized decrease simd utilization decrease utilization mostly schedule warp instead scalar execution pack rate thankfully benefit scalar overcome limitation however issue warp instead harm performance specifically BPR lib increase execution cycle simd utilization future schedule technique improve schedule increase scalar pack rate memory access narrow issue width increase memory request pressure cache therefore detailed analysis average memory request per memory operation cache access memory request GW architecture normalize architecture regular irregular graph application regular application memory request increase benchmark amount increase twice warp issue benchmark lib  increase cache access besides increase memory request performance increase access irregular graph benchmark regular irregular benchmark cache access rate graph benchmark BC lower cache access rate related efficient implementation graph algorithm gpus however none proposes architectural graph algorithm gpus  narayanan potential gpus acceleration graph algorithm graph efficient implementation performance evaluation widely graph algorithm gpu multi gpu focus algorithmic gpu architecture scalable primitive developed  benchmark suite gpus OpenCL characterize performance amd gpus performance graph application perform detailed analysis simulation finding performance graph algorithm limited irregular data access utilization data dependent distribution propose virtual warp centric program model acceleration graph algorithm gpus scalarized vertex centric graph compute virtual warp centric graph compute vertex warp propose warp segmentation enhance gpu device utilization dynamically assign suitable simd thread vertex virtual warp mapping warp segmentation utilization simd however program approach software eliminate redundant computation application apply virtual warp centric compute warp segmentation architectural combine technique software hardware GW architecture target gpu application approach vertex centric centric graph processing framework combine vertex centric centric graph processing besides vertex centric graph compute centric graph compute application benefit graph architecture benefit instruction narrow simd width scalar scalar annotation target vertex specific calculation compiler identify scalar calculation exist target optimization data representation improve memory access simd utilization gpus model predict performance spmv gpus data storage analysis graph algorithm csr agrees context scalar execution researcher propose dynamic static analysis technique identify scalar operation gpu application propose redundancy elimination computation efficiency reliability enhancement chen  explore scalar vector architecture  extends scalar execution divergent scalar instruction utilizes register compression reduce consumption however none prior attempt scalar instruction efficiency none employ instruction elimination redundant fetch decodes previous propose scalar architecture eliminate redundant computation vectorized storage scalar efficiency extend adopt scalar scalarized graph compute approach integrate narrow warp instruction proposal address utilization simd lane dynamic warp formation DWF thread compaction   warp micro architecture LWM researcher developed dynamically warp warp split divergence observation thread regroup thread regroup impact coalesce memory access creates memory conflict previous positively impact performance address issue simd efficiency divergence approach address completely none previous target elimination redundant computation instruction reuse gpu compute conclusion future gpus impressive speedup gpu friendly data parallel application graph irregular application suffer utilization simd due varied amount computation across vertex utilization simd significant performance degradation introduces GW architecture improve architectural irregular data dependent application graph application GW narrow simd width cluster issue approach introduces extension baseline gpu architecture reuse instruction eliminates redundant computation scalar combination technique utilization simd lane redundant computation inefficient simd GW architecture improve performance graph application average regular irregular gpu application respectively future schedule optimization improve benefit graph architecture extend GW architecture dynamic identification scalar instruction another future