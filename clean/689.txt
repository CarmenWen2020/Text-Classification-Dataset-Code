data compute collectively paradigm shift business acquire manage information technology creates CS equip foundational knowledge collective paradigm posse deploy manage data application argues substantial coverage data compute concept relevant topic integrate multiple core across CS curriculum additional perform overhaul curriculum approach topic develop autonomous competency module specific core coverage appropriate context module classroom intervention document performance data survey reasonable attain outcome enhance engagement keywords bigdata compute module CS curriculum competency introduction analysis bigdata becomes priority task data driven discovery decision sector business economy development analyze bigdata proficiency specialized algorithm methodology due fundamentally distribute parallel workload contrast compute paramount infrastructure acquire pool virtual resource fashion deploy manage workload apply parallel distribute compute PDC bigdata compute collectively paradigm shift business acquire manage information technology growth paradigm business struggle experienced analytical data host storage management effectively leverage collective model recent report bureau labor statistic BLS hire data processing host related service steadily future reflect quote employment computer information technology occupation project percent faster average occupation occupation project demand worker stem emphasis compute collection storage bigdata information security alongside international data corporation idc emphasize expansion centric infrastructure application covid era item worldwide prediction becomes lesson enterprise mechanism shift centric infrastructure application twice pandemic statistic clearly exemplify collective paradigm dominate severe shortage skilled professional maintain growth increase adoption collective paradigm various domain research paradigm crucial imperative CS undergraduate equip foundational knowledge competency collective paradigm deploy manage bigdata application acquire future demand enable apply research paradigm however challenge technique bigdata compute paradigm emerge transition recent acm joint curriculum recommendation  curriculum requirement institution develop CS curriculum around guideline requirement cannot afford topic within core densely packed curriculum although newer version acm joint curriculum recommendation undertaking expansion emerge topic curriculum effort data task NSF  curriculum initiative PDC draft version curriculum currently available additionally CC significant overhaul CS focus shift knowledge competency therefore broader adoption curriculum meaningful guideline accommodate critical bigdata compute topic CS curriculum argues substantial coverage bigdata compute concept intervene gradually topic integrate multiple core curriculum approach apply PDC topic develop series module specific goal lesson assessment resource specific core coverage appropriate context module topic collective paradigm context conventional core CS enable expose bigdata compute concept without significant overhaul curriculum recent curriculum effort  embrace concept competency primary characteristic curriculum definition describes practical benefit compute education stakeholder society effectively competency comprehensive perspective education enhances knowledge knowledge application persuade purpose motivation realize task inspire recent shift collective paradigm apply proficiency demonstrate knowledge adopts competency model module outcome module tutorial sample program description resource substantial project dimension competency framework motivation dimension realize augment module relevant content core coverage appropriate context reusability adaptability concern module autonomous available github public website detailed easy adoption instructor minimal detail module deployment specific institution however adapt deployment minimal effort report offering module respective CS core discus competency outcome module content assessment assessment survey module objective instructor aim incorporate pedagogy enhances knowledge collective paradigm earlier version research   conference organize detail motivation related initiative bigdata compute topic curriculum discus principle develop module overview module discus module classroom deployment elaborates summarizes concludes motivation related limited acm  standard guideline integrate bigdata compute topic CS curriculum computer education community multiple approach address satisfactory professional extensive literature survey identifies approach academia firstly institution non core specialized various aspect data bigdata analytics primarily taught data acquisition cleaning analytical visualization develop related transform data knowledge concept related host deploy application within environment application within performance  constraint category approach integrates bigdata compute topic exist CS mostly non core parallel distribute compute performance compute networking cybersecurity intervention sporadic mostly ignite instructor therefore cannot garner substantial knowledge collective paradigm research intensive assume approach offering specialized standalone compute bigdata management etc abovementioned collective paradigm address extent however elective non core handful handful benefit abovementioned approach limited intervene substantial portion CS undergraduate population expertise collective paradigm mostly undertaken via non core topic survey administer    comprehend instructor perspective amount quality PDC coverage undergraduate CS CE curriculum thirty educator across survey survey motivate reflect inadequacy coverage apply PDC topic across CS curriculum reveal challenge hinder broader coverage participant emerge topic relevant PDC department offering core summarize survey pertain although institution conduct various specialized related bigdata compute junior senior core challenge broader adoption PDC topic CS curriculum majority educator strongly limited exist densely packed curriculum challenge reflect survey confirm previous observation finding literature intervention mostly non core accommodate topic densely packed exist curriculum significant challenge hinders massive adoption certainly gap advance bigdata compute inclusion college instruction aim address gap propose alternative module approach related concept autonomous module disperse core across exist curriculum image KB image   survey emerge PDC topic interpretation reader refer web version article image KB image   survey challenge broader adoption PDC topic module module principle argues systematic approach module within context theoretical framework underpins effective adopt competency model module outcome activity assessment detail principle derive establish theory utilized propose module bigdata compute envision principle along theoretical foundation related activity implement incorporate principle module notable choice inclusion constructive alignment model fundamental principle constructive alignment aligns assessment activity objective aspect accord appropriate  module become congruent explicit alignment module intend outcome activity assessment aim develop meaning coherent align module  quality engagement module principle implement activity  theory  activity module outcome demonstrate module guideline develop module constructive alignment approach module outcome developed assessment criterion developed finally module activity organize assessment criterion hence module outcome actively engage meaningful project project module equip project approach activity pursue academic involves core competency decision collaboration communication reflection analytical report modular intervention supportive environment instructional scaffold scaffold embed project activity initial project activity demonstrate via tutorial demonstration instructor involve interactive demonstration challenge project activity gradually progress extensive gradually remove scaffold assess variety cognitive bloom revise taxonomy module outcome specify competency knowledge requisite competency bloom cognitive specify explicitly adopt project pbl substantial project module span extend vehicle important knowledge goal competency bigdata compute pbl focus challenge relies decision investigative critical strategy pbl teamwork report presentation implement core competency collaboration communication reflection additionally temporary structure instructional scaffold accomplish project goal increase likelihood competency progression initial project task welcome environment challenge topic lastly adopt bloom hierarchy cognitive specify successful task accomplishment goal realize ass dimension competency philosophy par knowledge along apply overview module propose module autonomous easy adoption span specific competency outcome lecture assessment resource assessment resource quiz tutorial sample program resource project etc detailed tutorial developed multiple platform enable straightforward adoption institution module taught lecture lab typically concept technique introduce project along resource project project contains multiple task usually deadline module expose compute fundamental public environment module adopt core computer architecture CA institution important context module within typical deployed perceive module isolated disruptive topic context establish CA execute cpu IO benchmarking application typical CA topic module focus mapreduce program popular analytics hadoop spark deployed analysis algorithm AA context establish explore performance tradeoff analytics application within environment module illustrate importance sql within various database management  deployed within database management DB easily connection utilize spark sql program load query structure unstructured data fourth module implement advanced operating OS understand important operating concept distribute context establish project task investigate OS issue performance scalability fault tolerance etc module available github repository along specific deployment instruction educator discus module along assessment computer architecture CA module module integrate computer architecture expose virtualization compute fundamental aws CS institution mostly junior senior attend specific competency demonstrate understand technique strength challenge compute CA LO understand develop amazon web service aws virtual machine VM provision management CA LO apply CA lesson lecture overview discussion economic technological factor emergence compute advancement PDC lecture discus important compute characteristic scalability demand access service elasticity lecture concept service service SaaS paas IaaS distinction public private community clarify lecture explains resource virtualization important aspect migration  isolation etc finally lecture explores benefit utilize service within business challenge associate adoption data confidentiality performance unpredictability etc mainly comprises tutorial lab session instructs provision management aws EC instance tutorial contains platform specific instruction screenshots mac user provision vms aws CA assessment assess utilize quiz compose factual project involve aws EC service quiz false multiple choice analytical focus gauge progress comprehend retain concept related virtualization compute fundamental project perform task task EC instance hardware software configuration task analyze instance performance benchmarking cpu IO bound application performance VM task analysis graphically report critically utilize  cpu bound benchmark calculates nth digit gauss legendre algorithm various additionally project  benchmarking  benchmarking suite ass IO performance benchmark performance  KB KB file MB GB GB VM instance configuration task express benchmarking performance graphically evaluate performance analysis critically goal project skillset acquire manage virtual resource aws utilize execute cpu IO benchmarking application realization accomplish local environment CA assessment CA module deployed offering CA overall perform median quiz detailed performance express quartile performance quiz quartile reflect majority around CA quiz reside outlier overall quiz grade distribution statistic knowledge acquisition comprehension concerned topic therefore module effectiveness attain outcome CA LO associate understand image KB image performance CA module image KB image grade distribution CA module challenged project submit project remain spent accomplish project reasonably median reflect quartile certainly exhibit variability quiz grade project grade distribution reveals although project grade struggle accomplish task closer analysis project grade reveals although comfortable aws web interface VM management detailed tutorial session accomplish task correctly execute benchmarking application VM instance task challenge reporting critically task majority attain passing grade apply provision manage vms aws outcome CA LO met marginally population background CS important factor contribute variation assessment module benefit tailor accordingly however opportunity institution accommodate analysis algorithm AA module module junior algorithm introduce mapreduce program framework popular analytics hadoop spark module target CS CS CS data structure comfortable reasonably proficient program java python outcome module recognize technique strength challenge mapreduce spark framework AA LO understand scalable application mapreduce program model hadoop hdfs AA LO apply analyze performance constraint platform AA LO analyze AA lesson module span lecture explores parallel compute introduces mapreduce framework quickly data splitting individual chunk parallel concept introduce shuffle reduce phase explain classic wordcount application illustrate explain java implementation entire computation multiple reduce task essence mapreduce program stage lecture spends amount breakdown occurs context frequency url  document specific etc implementation mapreduce model apache hadoop introduce along distribute file hdfs concept hadoop cluster along worker framework briefly explore lastly classic mapreduce program briefly memory analytic apache spark emphasize brief description spark runtime distribute architecture driver executor acyclic graph dag lab instructor demonstration tutorial module goal mapreduce implementation continuous access development environment recommend  VM local machine package already instal configure properly minimal linux background focus cod spending configure troubleshoot tutorial therefore instruction hadoop  VM local machine instruction hdfs compile execute mapreduce application retrieve output hdfs java file driver mapper reducer input datasets understand various stage mapreduce execution execute application wise maximum  java apply recently execute wordcount application wordcount java dataset lab demonstration introduces chameleon ssh chameleon instance register chameleon project tutorial implement spark yarn cluster hdfs chameleon compile spark application experimentation datasets pre load instance concerned spark application trend topic wikipedia information taught execute spark application yarn cluster lab session spark submit command configure cluster resource execution parameter num executor executor memory executor core taught verify resource allocation execution performance metric spark application spark web user interface AA assessment module assess utilize project quiz quiz multiple choice developed ass comprehension hadoop spark framework mapreduce program model pseudocode reduce function series project built lab session task task modify  java average instead maximum task modify wordcount java output task attach  txt file ID customer date mapreduce program output amount spent customer task project explore spark application performance environment various runtime configuration setting gain insight resource provision performance tradeoff wikipedia data GB GB spark cluster node cluster node cluster compute node core GB memory chameleon testbed trend wikipedia spark application input datasets various configuration setup cluster code data file pre load spark cluster although chameleon introduce model service core GB memory performance execute application cluster configuration gain insight performance tradeoff report detail experimental finding along argument AA assessment module deployed offering AA quiz performance reveals perform poorly assessment median quartile quiz exam module intervention difficulty retain concept associate mapreduce average attain multiple choice exam average average involves series reduce task partially explore completely quiz grade distribution achieve grade achieve passing grade fail quiz comprehend concept taught module extent therefore outcome AA LO met partially image KB image performance AA module image KB image grade distribution AA module rigorous lab session individual troubleshoot session instructor TAs perform task task project task successfully task successfully quartile statistic project grade median project grade distribution reflect grade passing grade competency develop mapreduce application hadoop AA LO project task expose enable spark environment understand analyze performance tradeoff AA LO execute spark application chameleon environment however task successfully database management DB module currently numerous application scenario processing datasets highly scalable distribute fashion various bigdata address challenge recognize strength sql query propose module introductory database management expose various bigdata integrate sql within CS institution typically attend sophomore junior outcome summarize strength limitation important database management  mapreduce sql sql DB LO understand develop sql within spark framework load query datasets DB LO apply DB lesson lecture discus limitation relational database strength limitation various bigdata management mapreduce sql sql introduces spark distribute data processing framework spark sql component within handle structure data processing lecture introduces concept  emphasize array source instructor tutorial source code instructs utilize jupyter notebook develop execute spark sql application tutorial instruction  json csv file manipulate sql query programmatically within DB assessment project quiz utilized assessment quiz contains multiple choice ass understand sql sql detailed analytical ass comprehension spark sql program project progression tutorial involves develop spark application load historical facebook stock price spark sql query data dataset csv file contains stock date attribute date price price price price volume  price adjust  split develop spark sql application load file creates dataframe content register dataframe sql temporary query gain daily transaction facebook stock gain maximum stock average sale volume query taught infer schema json csv input tutorial project perform inference query facebook data however project contains challenge extra credit load query text file schema enforce programmatically explicitly taught schema enforcement resource useful implement challenge DB assessment overall recognize strength limitation important database management reflect quiz performance quiz quartile performance median grade distribution grade passing grade similarly perform essential project infer schema automatically median relatively variability quartile reveals attain grade passing grade project however extra credit define schema programmatically successfully overall quiz performance validates thorough understand various  DB LO project grade reflect competency develop spark sql application analyze query datasets DB LO image KB image performance DB module image KB image grade distribution DB module operating OS module module deployed operating understand parallel distribute processing framework apache spark distribute storage hdfs deployment google   automatic cluster management google platform GCP becomes easy fully manage spark hadoop cluster GCP institution utilized module advanced OS target graduate data parallelism fault tolerance however utilize additional video lecture detailed module partially undergraduate OS outcome deploy configure apache spark hdfs GCP  OS LO apply execute spark application cluster analyze performance scenario related scalability replication fault tolerance OS LO analyze OS lesson assign reading apache spark google platform GCP tutorial instructor video lecture explain redeem coupon GCP  cluster GCP configure various resource bucket application data submit spark cluster monitoring assess execution lab module devote troubleshoot project OS assessment project utilized assessment OS module pyspark implementation wordcount application substantially data file submit detailed report analyze screenshots graph etc default hdfs default replication factor hdfs  txt input program node cluster core completion task snapshot VM instance monitoring txt input program hdfs inside node cluster worker node performance completion explain txt input program hdfs inside node cluster worker node performance completion explain default hdfs MB performance completion briefly explain extra credit setting worker node immediately worker node VM instance tab cluster detail click worker click button completion difference completion briefly explain observation OS assessment module deployed offering advanced operating target graduate CS project grade reflect comprehension competency median grade distribution along performance analysis extra credit regard fault tolerance critically report extra credit task successfully execute critically report augment argument screenshots graph recognize issue related scalability correctly recognize improvement application completion switch node cluster node cluster recognize slight increase completion worker node overhead associate distribution communication outperform benefit associate parallel execution load input file project additionally analyze impact decrease performance due swap correctly execute extra credit analyze shut worker execution successfully due replication fault tolerance spark however interrupt data java connection refusal longer adapt loss worker therefore additional overall deploy configure apache spark hdfs google  cluster therefore outcome OS LO met analyze performance issue related parallel execution analyze impact replication fault tolerance OS LO irb approve survey appendix ass perception confidence administer intervention opinion statement likert strongly neutral disagree strongly disagree refers module specific topic topic asks explain explore future survey clearly conveyed topic specifically CA strongly enjoy topic whereas rate agreement AA DB OS respectively important although perform AA module module  topic enjoy extensive program spending lab session involve enthusiastic challenge perform module image KB image survey topic survey reflect report confidence topic surprising slightly agreement strongly across neutral response amount spent module reliance however CA strongly familiar topic similarly AA DB OS report familiarity topic unsure fluency therefore remain neutral however disagreement image KB image survey asks explain survey reflect report desire topic intervention overall eagerly express desire topic future specifically CA AA DB OS enthusiastically reveal desire topic image KB image survey future discussion modular intervention address CS across core CS institution mapping module outcome correspond assessment percentage achieve passing grade evident algorithm module intervention successful attain competency outcome specify module algorithm instructor performance delayed intervention offering quiz introduction framework hadoop spark incurs additional load confusion chameleon analyze performance tradeoff instead interfaced popular platform GCP aws anticipate perform module focus spark framework utilize easy popular platform however intervention technical organizational limitation decision hopefully future intervention interested instructor careful bigdata processing framework platform choice mapping los assessment along performance outcome LO assessment grade CA LO demonstrate understand technique strength challenge compute understand CA quiz CA LO develop amazon web service aws virtual machine VM provision management apply CA project AA LO recognize technique strength challenge mapreduce spark framework understand AA quiz AA LO scalable application mapreduce program model hadoop hdfs apply AA project task AA LO analyze performance constraint platform analyze AA project task DB LO summarize strength limitation important database management  mapreduce sql sql understand DB quiz DB LO develop sql within spark framework load query datasets apply DB project OS LO deploy configure apache spark hdfs GCP  apply OS project OS LO execute spark application cluster analyze performance scenario related scalability replication fault tolerance analyze OS project worth mention  adjustment grade due module experimental evaluate impact overall grade AA quiz grade task AA project declare extra credit avoid penalize ample challenge opportunity extra credit DB OS module future adopter decision mitigate potential impact diverse engage relatively agreement reflection survey demonstrate comfortable module content intervention duration volunteer anonymous comment survey module usefulness  topic comment enjoy mapreduce parallel compute topic rush assignment stress invest along project otherwise enjoy project topic program although challenge project linux concept expand instance project around throughout semester familiar platform abovementioned comment articulate important suggestion assign project prior linux semester comprehensive future adopter easily address suggestion assign project content linux outside classroom suggestion challenge adopt institution without guideline enforce CS curriculum standard outline development constructively align module significant amount instructor available intervention deployment investment substantial preparation relatively instructor assistant timely manner however instructor planning module acquire TA resource module duration module deployed  HBCU serf unique population female african american therefore module carefully incorporate pedagogy project instructional scaffold etc recognize research address challenge underrepresented minority typically college limitation impact significant repetition intervention robust conclusion effectiveness additionally bigdata compute rapidly topic instructor goal date therefore module evaluate regularly technological perspective regular update align technology framework recognize competency model specification disposition dimension model disposition competency model socio emotional behavior attitude individual motivate propose competency model knowledge dimension recognize research author understand disposition dimension effectively propose outcome future focus disposition attribute competency conclusion aim explore integration bigdata compute module core undergraduate CS evaluate effectiveness substantial advantage modular approach CS expose contemporary topic technology via systematic increase integration throughout compute curriculum without develop additional core elective module classroom deploy specific contribution literature review instructor survey emerge important topic bigdata compute transition densely packed undergraduate CS curriculum institution broader systematic adoption topic framework propose series module specific goal lesson assessment developed disperse core across exist CS curriculum without perform overhaul curriculum additional module establish theory pedagogy adequately characterize embrace competency model demonstrate knowledge developed module encompasses project analytics hadoop spark popular platform amazon web service aws google platform GCP chameleon performance survey demonstrate reasonable attain outcome enhance engagement module reusable  available github repository generate evidence performance survey data pedagogy inspires ass update intervention continuously allows extend intervention across multiple semester assessment clearly relate topic explore retain developed significant confidence intervention future focus convert module flip classroom module deploy hybrid virtual platform increasingly gain importance covid era adoption challenge situation instructor cannot afford  explore module flip module pre lecture demo instructor concern troubleshoot instead future perform research gradual systematic integration developed module across curriculum research assess collective effectiveness efficacy module currently develop capstone topic assessment detail reinforce concept comprehensive apply parallel distribute compute analyze performance perception data future pre understand extent retain module enhancement topic comprehensively within