quality service qos provision become important aspect performance compute interconnection network proof inclusion mechanism target provision qos interconnection technology gigabit ethernet infiniband IB omni opa component qos provision output schedule algorithm determines packet transmit ideal schedule algorithm satisfy latency implementation simplicity scheduler IB opa implement approach comparative qos provision dominate interconnection technology interconnection technology non hierarchical hierarchical switch architecture respectively significance deficit scheduler dtable dtable schedule algorithm balance latency implementation previous keywords quality service schedule algorithm interconnection network simulation hierarchical non  switch performance evaluation introduction performance compute hpc compose node application execute concurrently generate message network node data faster rate network contention application performance affected reduce impact contention quality service qos mechanism application resource requirement interconnection network technology infiniband IB omni opa technology qos qos active research topic environment interconnection network internet datacenters supercomputing platform increase internet dominant contribution qos application demand video video communication interactive application etc qos satisfy application requirement user qos differentiate service traffic user privilege cluster user service agreement qos internet wireless network qos hpc output scheduler technique meeting qos requirement etc component network qos output schedule algorithm determines packet transmit basis performance metric interconnection network packet application interact network without schedule policy packet traffic application resource scenario consume network resource degradation performance starvation ideal schedule algorithm implement interconnection network fairness traffic service latency computational implementation complexity however output schedule algorithm involves inevitable offs simplicity important fairness affect distribution service link latency implies burstiness output scheduler increase buffering requirement avoid packet contention schedule algorithm sort priority scheduler global variable virtual server progress update packet transmit packet stamp compute function virtual specific schedule algorithm scheduler queue  clocked queue  fairness latency efficient due complexity compute virtual maintain sort packet however reduce complexity   maintain decent qos provision schedule algorithm another multiple entry assign entry determines packet transmit scheduler latency maximum separation consecutive entry computational implementation complexity generally pointer entry entry IB opa implement approach comparative qos provision representative hpc interconnection technology IB opa powerful computer establish supercomputer opa IB interconnection network technology dominate opa IB moreover interconnection technology switch architecture hierarchical non hierarchical respectively hierarchical switch architecture advantage radix radix switch furthermore dtable schedule algorithm balance performance hardware knowledge performance non hierarchical hierarchical switch qos provision issue important approach structure briefly review switch architecture IB opa describes simulation model review qos technology explains dtable scheduler operation adapt IB opa experimental analyzes finally conclusion  simulator IB opa interconnection technology simulation popular methodology evaluate technique network allows explore technique cheap flexible reproducible multiple network simulator  booksim  etc focus chip network simulator simulation feasible chip network due network rarely switch however network grows computational resource simulation  moreover characteristic chip traffic chip traffic totally disparate public simulator model opa switch architecture developed IB opa model previous simulator research multiple publication simulator   performance interconnection network knowledge operation flexibility regard technique implement interoperability  discrete network simulator model behavior network switch link network interface simulator goal perform comparative configurable parameter topology rout queue output schedule algorithm etc  capable simulation synthetic traffic random uniform reversal complement etc multiple performance metric implement latency throughput etc infiniband simulation model detail component IB simulation model behavior generic scheme IB switch IB switch implement virtual switch technique credit define input output bandwidth gbps model assume input output buffer flit input output input output buffer per input output buffer storage dynamically virtual lane VLs dynamic buffer flexibility static buffer rout rout information header flit rout per input central crossbar interconnects input output input arbiter input buffer selects VL participates allocator phase VLs arbiter output arbiter output chooses input transmit flit output IB input buffering input buffer flit cycle flit correspond VL queue transmission VL header packet flit label RT trigger RT otherwise flit label RT  apply header packet flit label RT rout determines output entire packet RT header flit label VA SA input buffer VL eligible VA SA stage non header flit header flit rout function configurable accord configure topology VA SA virtual allocator switch allocator stag allocator virtual allocator input arbiter chooses VL VA SA header flit VL deliver packet VLs chosen robin switch allocator output arbiter chooses input buffer VL packet destine output buffer packet output buffer header flit input buffer tag xbar packet allocation input buffer output buffer RT stage flit request output buffer tag OB OB output buffering output buffer OB flit chooses VL flit network switch network interface VL selection perform configurable output schedule algorithm qos provision output scheduler selects VL OB packet available credit packet flit transmit output scheduler release VL selects VL omni simulation model generic diagram opa switch internal link bandwidth bandwidth gbps thereby deliver flit cycle allows bandwidth input output   instance mport xbar input output model mport cluster input output input output buffer buffer per input output belonging mport directly mport crossbar mport xbar   central crossbar mport xbar crossbar input per input buffer output output buffer central crossbar gbps link central crossbar model link link deliver flit cycle central crossbar buffer crossbar connectivity  central crossbar packet request output belong input mport instance packet arrives belongs mport packet request output belongs mport packet central crossbar otherwise packet request mport central crossbar mport xbar remain explain simulation define opa simulation model explain however packet central crossbar buffer packet tag VA SA allocation arbitration packet tag correspond output execution output buffer packet tag OB finally OB explain trigger execute detail opa simulation model image KB image diagram model opa switch clarity  unfolded input output buffer interconnection network qos review qos mechanism IB opa qos application packet etc mechanism detailed infiniband omni implement  infiniband IB architecture mechanism enable qos accord mechanism virtual VLs dedicate buffer packet IB implement credit VL IB VLs VL reserve management purpose service SLs qos identifier packet SLs aggregate characteristic application qos network packet SL network interface NIC injection cannot modify switch SL VL mapping  per output packet assign VL SL output input  output switch packet assign VLs along route  output IB defines output schedule algorithm per output scheduler scheduler schedule packet priority VLs schedule packet priority VLs entry entry VL identifier indicates byte transmit VL entry transmission entire packet IB output schedule algorithm defines maximum amount information deliver priority transmit packet priority  configurable network administrator arbitration cycle sequentially entry active VL VL packet credit VL transmit maximum packet entry finally cycle moreover priority packet output arbiter transmit priority packet priority packet arrives mechanism avoids waste bandwidth omni opa architecture mechanism enable qos packet application etc accord mechanism virtual lane VLs dedicate buffer incoming packet switch VLs avoid rout deadlock intel omni architecture VLs service channel SCs differentiate packet service SC qos identifier packet header SC mapped VL VL multiple SCs SCs avoid topology deadlock avoid traffic intel omni architecture service channel however SC dedicate fabric management service SLs SCs SL span multiple SCs SC assign SL SLs priority packet priority packet belonging application transport layer avoid protocol deadlock etc intel omni architecture SLs traffic TCs SLs aim distinguish application traffic TC span multiple SLs SL assign TC intel omni architecture TCs  application protocol  qos policy apply  associate TC qos associate partition security contrast IB architecture mapping SL SC  SC VL  SC SL  per network device packet VL SC route network however cannot SL TC SC identifier qos identifier packet implement   SL associate SC vice versa  packet VL buffer NICs   assign SC identifier deliver packet VL generic diagram opa simulation model    rout output scheduler packet input buffer output buffer mechanism packet SC simulation model SC perform packet rout avoid deadlock distribute traffic SCs belonging SL opa qos mechanism  algorithm preemption however information mechanism simulation model implement dtable output scheduler detail opa architecture detailed available public information assumption deficit schedule mechanism goal schedule algorithm packet SLs deliver satisfy specify latency bandwidth requirement moreover context interconnection network output schedule algorithm computational complexity scheduler latency implementation complexity scheduler algorithm typically implement hardware implementation complexity implies silicon complexity silicon dtable output scheduler deficit robin DRR  proven scenario traffic load VLs dtable  packet latency DRR concludes silicon dtable scheduler twice DRR scheduler silicon  addition IB architecture specification release describes enhance qos arbiter dtable mechanism dtable option perform comparative dtable scheduler output schedule algorithm arbitration arbitrary entry etc entry SL identification entry entry determines maximum amount information credit transmit SL entry schedule cycle entry active SL SL active packet allows SL transmit packet buffer associate VL credit dtable scheduler compose schedule entry SL identifier associate deficit counter scheduler SL SL output counter deficit counter per switch deficit counter initialize accumulate counter sum entry SL deficit counter accumulate counter per output SL deliver packet accumulate allows packet transmit accumulate reduce packet credit active entry entry associate active SL accumulate packet instance suppose input output SLs buffer per SL SL buffer packet credit per packet hence deliver packet scheduler selects entry SL deficit counter accumulate counter delivery SL transmits packet accumulate counter reduce accumulate counter delivery minimum packet SL cannot packet arbitration remain accumulate SL deficit counter scheduler selects active entry SL packet SL entry associate deficit counter SL accumulate delivery delivers remain packet delivery SL becomes inactive output SL deficit counter zero accumulate discard scheduler active entry scenario accumulate becomes packet deficit counter SL becomes inactive counter zero image KB image dtable behavior bandwidth assign entry arbitration entry assign entry assign entry entry maximum distance consecutive entry assign SL SL latency suppose output schedule algorithm entry SL entry distance consecutive entry SL entry distance entry SL entry SL entry hence SLs assign bandwidth however SL packet latency SL packet distance entry SL dtable configuration methodology dtable implementation IB interconnection network detailed qos mechanism IB establish dtable behavior detail implementation aspect dtable IB simulation model dtable scheduler entry deficit counter accumulate counter IB architecture entry priority entry priority entry per output SLs implement dtable IB architecture establish priority entry dtable entry thereby entry SL identifier associate entry deficit counter per SL switch output IB output schedule per output entry therefore deficit counter implement priority entry entry maximum SLs accumulate counter per output accumulate counter implement priority entry output accumulate counter IB entry therefore accumulate easily overflow however unused adjacent entry implement counter IB simulation model entry sake simplicity arbitration counter implementation priority entry technique implement dtable IB architecture entry waste nevertheless entry dtable schedule entry entry entry unused sake simplicity schedule priority entry cycle entry dtable implementation opa interconnection network detail qos mechanism opa explains dtable output schedule algorithm explain dtable implementation detail opa mention detail public available information output scheduler algorithm hence cannot advantage existent IB opa simulation model implement schedule network device deficit counter per output SL accumulate counter per output opa SLs canonical switch deficit counter accumulate counter per network device opa architecture defines qos traffic SLs dtable perform arbitration SL arbitration entry SL identifier mention SCs VLs involve qos therefore    schedule scheduler selects entry SL identifier entry   scheduler determines VL associate SL packet transmit packet network device credit finally satisfied device delivers packet dtable scheduler allows dtable scheduler variable maximum transmission fully exploit dtable scheduler variable maximum transmission  per SL MTU packet deliver variable MTU per SL dtable scheduler fix MTU deficit counter packet allows decouple bandwidth assignment latency requirement important context interconnection network message compose packet flit architecture SL MTU entry SLs SL MTU per network device MTU flit compose packet per SL permit maximum packet SLs fully advantage dtable scheduler nevertheless neither IB opa variable packet overtake limitation SL MTU simulation model fix packet compose message message generation modify generate message accord SL MTU packet moreover message network device dtable ensure entire message onto buffer remain SL switch technique virtual mention delivery message flit message consecutively VL buffer credit MTU dtable configuration methodology application etc specific qos difference dtable arbitration configure dtable schedule mechanism qos without configuration methodology arbitration configuration entry entry SL latency requirement assign bandwidth flexible minimum bandwidth assign maximum bandwidth  definition parameter configuration methodology arbitration parameter maximum minimum bandwidth  specific maximum transfer bandwidth assign maximum per entry entry arbitration  pool entry assign bandwidth pool decouple parameter maximum transfer  decouple parameter maximum entry however fix parameter explains assign specific SL bandwidth entry assign assign entry therefore  bandwidth define parameter decouple parameter bandwidth pool hence maximum minimum bandwidth proportion entry parameter proportion specific therefore parameter specific assign SL maximum minimum bandwidth  SLs without affect latency performance evaluation qos provision performance IB opa switch architecture dtable scheduler metric latency per SL average message latency message label SL generation reception latency user SL throughput per SL amount deliver information per SL express flit cycle NIC transmit network  implement IB opa simulation model detailed infiniband simulation model omni simulation model mimic architectural behavior switch qos mechanism explain infiniband omni dtable scheduler adapt architecture dtable implementation IB interconnection network dtable implementation opa interconnection network SL MTU detailed traffic model traffic qos requirement effort traffic traffic explicit qos requirement latency bandwidth effort slight priority SLs sort latency sensitive latency sensitive SL instance NC SL latency sensitive achieve latency SLs effort SLs sensitive SLs dtable configuration explicit requirement SL define effort assign furthest arbitration distance remain bandwidth percentage packet SL simulated appropriate traffic emulate behavior SLs evaluation    NC network  uniform  VO audio online  backend  connection  VI video  connection  load CL performance compute  connection  effort EE preferential effort traffic burst  effort backup protocol email etc burst  BK application  network NC traffic generate random uniform traffic distribution network fabric manager deliver network device packet uniform chosen payload byte scenario assume SL nearly network bandwidth VO traffic generate constant rate cbr distribution VO compose multiple connection define connection simulation simulation payload codecs algorithm byte payload closest packet byte due limitation explain assume SL nearly network bandwidth video VI traffic generate cbr distribution VI traffic generate VO traffic accord payload byte kilobyte feasible chosen payload byte assume SL nearly network bandwidth load CL traffic generate cbr distribution payload byte average payload application communication assume SL nearly network bandwidth effort traffic excellent effort EE effort background BK generate burst distribution traffic compose burst message generate destination message compose multiple packet accord SL MTU packet payload SLs byte assume SLs nearly network bandwidth VI VO traffic destination distribution uniform fully load network chosen heterogeneous scenario multiple traffic mixed mention bandwidth percentage however proposal aim environment qos requirement coexist nevertheless multimedia environment straightforward network topology chosen ary torus interconnection topology performance environment topology layout ary ary 2D torus 3D torus configuration layout ary configuration NICs switch IB opa ary configure NICs switch 2D torus configuration switch aggregate trunk link NICs attach link per switch trunk link increase bandwidth torus direction belonging trunk link independently transmit packet torus direction 3D torus configuration NICs switch trunk link NICs link ary topology implement valiant rout algorithm mitigate congestion contention torus implement  topology   configuration opa architecture scenario SL SC associate SC VL assign instance NC SL SC VL associate SLs description  configuration IB architecture scenario opa scenario SL VL associate architecture switch implement credit protocol packet congestion transmit reception buffer application characteristic aggregate via SLs packet schedule perform SLs via VLs sake comparison establish flit byte packet flit credit byte therefore packet byte packet credit  architecture byte nevertheless evaluation perform  configuration IB  opa  opa  IB           input output central opa buffer queue architecture buffer capacity architecture buffer capacity byte input output switch byte network interface opa central crossbar buffer capacity byte mport opa switch central buffer capacity byte central crossbar buffer capacity available mport mport consume byte buffer capacity adjust experimentally avoid contention congestion architecture dynamically manage VL buffer storage independent buffer per VL buffer accord traffic requirement ensure minimum maximum per VL dynamic buffer flexibility static buffer finally application inject packet interface network queue assume packet application layer queue simulated scenario scheduler configuration assume scenario goal dedicate egress link percentage SLs NC SL VO SL VI SL CL remain percentage effort SLs regard maximum latency requirement mention maximum latency handle maximum distance entry assign SL bandwidth percentage intend realistic combination traffic application qos requirement distance assign SL distance maximum latency ascend NC VO VI CL effort SL distance define absolute maximum instance NC SL latency requirement VO SL VO SL latency requirement VI SL approach permit differentiate service application dtable configuration define methodology methodology explain allows decouple bandwidth assignment latency assignment establish maximum distance maximum distance entry NC SL maximum distance entry effort SLs entry  proportion entry  SL achieve maximum flexibility MTU establish specify  SL application decouple methodology dtable bandwidth configuration  decouple  scheduler configuration distance   min max  NC VO VI CL EE BK  finally configure parameter adjustment methodology methodology multipurpose backtracking algorithm account CL SL bandwidth actual proportion entry assign moreover assign NC SL proportion entry assign proportion bandwidth nevertheless important parameter obtain latency performance backtracking algorithm adjust parameter increase desire SLs finally algorithm increase desire SLs finally chosen combination allows  bandwidth SL bandwidth requirement minimum maximum bandwidth assign SL configuration assign bandwidth bandwidth account SL bandwidth usage priority SLs reserve bandwidth correspond injection rate prevent congestion hol affect within define injection amount traffic express flit cycle NIC SL injects scenario SLs NC VO VI CL inject fix amount traffic effort SLs increase gradually amount traffic min max increase distribute entry SL associate entry SL entry assign NC SL entry assign others deviation dtable configuration methodology slightly bandwidth deviation SL bandwidth desire developed deviation simulation performance metric described injection rate average simulation random generation latency throughput ary torus topology respectively BK SL outside sake clarity otherwise image MB image performance SL ary ary topology IB switch opa switch refer latency refer throughput image MB image performance SL 2D torus 3D torus topology IB switch opa switch refer latency refer throughput latency opa switch IB switch instance NC SL injection rate IB opa IB opa ary ary topology respectively injection rate latency achieve NC SL torus scenario IB opa IB opa 2D 3D torus topology respectively priority SLs opa degrade IB instance NC SL latency difference opa injection rate IB latency difference injection rate SL latency increase difference opa IB respectively regard torus topology NC SL latency difference opa IB difference IB opa respectively opa scenario latency connection VO VI CL SLs penalize IB connection penalize priority SLs moreover VO VI latency increase drastically network congestion however IB effort SLs increase latency quickly opa injection ratio increase latency requirement priority SLs IB switch increase priority latency whilst behavior opa although widespread opa switch latency IB switch BK SL latency suffer increase BK SL generate packet rate packet inject therefore accumulate injection queue increase drastically latency refer throughput achieve SL configuration throughput desire saturation BK SL suffers slight throughput reduction BK SL bandwidth scheduler allows hence throughput BK SL slightly reduce architecture scheduler propose configuration almost bandwidth requirement however IB VI VO throughput reduce achieve throughput VO VI SLs opa CL SL affected opinion due IB pipeline shorter opa pipeline encourages SLs suffer increase congestion hol generally extreme SL heavily saturate opa qos provision IB comment propose scenario opa achieves IB opa hierarchical crossbar architecture achieve throughput ratio maintain latency IB although opa packet switch IB packet central crossbar therefore radix switch complex improve achieve throughput latency packet switch conclusion qos provision relevant aspect interconnection network component network qos schedule algorithm packet transmit ideal schedule algorithm implement network satisfy latency simplicity IB opa simulation model dominate technology powerful computer architecture non hierarchical hierarchical switch architecture respectively adapt architecture dtable output scheduler balance performance hardware evaluate performance dtable schedule algorithm architecture heterogeneous scenario multiple traffic coexist topology configuration architecture latency per SL opa architecture latency requirement IB architecture achieve latency IB priority SLs opa degrade IB moreover IB earlier drastically increase latency priority SLs latency priority SLs throughput per SL IB opa bandwidth desire however IB scenario SLs achieve throughput currently develop strategy reduce congestion specially IB architecture affected adapt sort priority schedule algorithm