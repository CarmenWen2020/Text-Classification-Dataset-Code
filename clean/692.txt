heterogeneous distribute compute HC diversity exist computational resource task inconsistently heterogeneous compute task execution heterogeneous machine task machine machine availability performance maximize task meeting deadline define robustness task deadline video task deadline investigate research maximize robustness oversubscribed HC maximize robustness prune defer task probability meeting deadline increase probability task meeting deadline mathematical model estimate task probability meeting deadline presence task investigate engage probabilistic propose dynamically task defer threshold probability develop prune prune aware mapping heuristic extend engender fairness across various task prune mechanism independent component apply mapping heuristic improve robustness reduce overhead prune mechanism propose approximation remarkably reduce mathematical calculation improve practicality deploy mechanism heterogeneous homogeneous compute gain prune mechanism simulation harness selection mapping heuristic efficacy prune mechanism improve robustness average oversubscribed HC keywords heterogeneous compute HC probabilistic prune mapping heuristic robustness introduction heterogeneous compute HC described heterogeneity inconsistent consistent inconsistent machine heterogeneity refers difference machine architecture cpu versus gpu versus fpga consistent machine heterogeneity describes difference machine architecture compute service provider HC amazon inconsistent heterogeneity various virtual machine VM cpu optimize memory optimize disk optimize accelerate compute gpu fpga within various vms consistent performance price moreover consistent inconsistent heterogeneity exist task HC dedicate processing video responsible categorically task video resolution compression standard video rate task consistently heterogeneous within longer resolution video HC consistent inconsistent heterogeneity machine task task execute differently machine machine performs task faster machine machine task specifically compute intensive task faster gpu machine whereas task memory disk access bottleneck memory database faster cpu machine heterogeneity uncertainty task execution inefficiency resource allocation accordingly challenge HC assign task machine optimize performance goal define robustness maintain performance uncertainty overall goal maximize robustness HC image KB image prune mechanism heterogeneous task mapped heterogeneous machine batch mapping pruner  task probability task individual deadline remains execute task hence task remove deadline HC load impossible task deadline oversubscribed performance metric robustness HC task deadline therefore specific goal maximize task meeting deadline HC refer task uncertain execution oversubscribed model machine task heterogeneity available resource allocation harness awareness overcome uncertainty HC task deadline spent execute task ultimately waste waste cascade queue task delay execution task increase task future decrease robustness mitigate task probability mapped execution probabilistically prune unlikely succeed task yield task oversubscribed HC maximize robustness gain thereby address research propose prune mechanism depict compose namely defer task defer postpone assignment unlikely succeed task mapping task mapped machine alternatively oversubscribed prune mechanism transition aggressive mode task unlikely succeed defer detail model impact task probability task schedule execute task appropriate probability defer propose dynamically resource allocation transition aggressive mode engage task analyze robustness obtain deploy propose prune mechanism HC perform prune prune implement maximize robustness HC task meeting deadline potentially bias towards execute task affect fairness develop mapping maintain fairness maximize robustness hypothesis propose prune mechanism improves robustness HC impact incur consumption resource former particularly important user deploy heterogeneous vms whereas latter appeal administrator performance compute hpc investigate impact propose probabilistic prune mechanism incur consumption heterogeneous vms mapping due generality prune implement independent mechanism apply mapping heuristic homogeneous heterogeneous compute improve robustness naively implement theory prune decision imposes significant overhead fate task prune mechanism practical develop approximation cache effectively mitigate mechanism overhead without impact effectiveness prune summary contribution prune mechanism improves robustness efficiency HC detailed contribution mathematically model impact task probability task schedule execute develop dynamically probabilistic defer threshold prune mechanism propose dynamically engage task response oversubscription HC develop prune aware fairness aware mapping heuristic HC reduce incur overhead deploy prune mechanism via approximate compute computational reuse prune generic mechanism apply exist resource allocation analyze benefit apply prune mechanism simulation approve hypothesis prune mechanism enhance robustness incur importantly mechanism effective oversubscription organize  relation exist literature establishes describes model theory probabilistic task prune mechanism summarizes prune mechanism introduces probabilistic mapping heuristic detail reduce schedule overhead probabilistic mapping heuristic task prune mechanism baseline heuristic along constraint parameter analyzes simulation finally concludes direction future related mapping task HC NP multiple prior effort achieve sub optimal notable mention influence model task execution instead scalar groundwork probability function aka PMF convolution execution completion queue task establish upon PMFs robustness measurement probabilistically execute task pending task investigate resource allocation oversubscribed heterogeneous task utility function priority utility urgency matrix deterministic execution whereas model probabilistically unlike approach probabilistically task task occurs task utility static threshold model stochastic heterogeneous task heterogeneous machine matrix probability function PMFs improve robustness dynamic resource allocation mathematical model calculate completion stochastically model task presence task however task deadline   propose  immediate batch dynamic schedule heterogeneous data singular decomposition historical data classify incoming task heterogeneity classification greedy algorithm candidate resource interference heterogeneity unlike considers probabilistic execution decision mapping heuristic operates scalar execution performance metric task deadline  concerned throughput introduce affinity heterogeneous vms cod video content video file performance heterogeneous VM particularly video content gain compute intensive vms gpus whereas video gain vms conclude categorize video content deploy inconsistently heterogeneous vms reduce incur without compromise quality another dynamically compose inconsistently HC heterogeneous video task however task evaluate dynamic mapping deadline constrain task workflow loss priority task completion however metric quantify evaluate task  unlike focus homogeneous vms  mapping consistent HC yarn mapreduce operates mixed integer linear program considers task execution machine information mapping however leverage task defer task considers task alleviate oversubscription improve robustness model motivation research HC processing video service youtube twitch service video content capture format aka  diverse viewer display device execute video task individual deadline HC deploy inconsistently HC processing inconsistently heterogeneous task task resolution task compression standard ensure uninterrupted overview task queue upon arrival mapped available heterogeneous machine batch capture stochastic execution task arise data difference task probability function PMF inconsistently HC execution PMF task machine maintain matrix probabilistic execution pet HC deployed specific service video task request limited pet matrix limited constant PMFs pet matrix built historic execution information task machine model via histogram offline manner assume pet matrix available HC heterogeneous task dynamically batch queue unmapped task prior knowledge timing intensity task HC oversubscription varies limit compound uncertainty maintain accuracy mapping decision machine limited local queue assign task FCFS manner machine queue machine queue machine idle mapping however excessively machine queue compound uncertainty completion imprecise mapping decision mapping occurs upon arrival task task mapping task deadline remove mapping attempt task batch queue happens machine queue unmapped task assume task mapped machine data transfer machine cannot remapped due data transfer overhead assume task independent executes isolation machine preemption multitasking image KB image probabilistic execution pet task convolve probabilistic completion pct task machine task machine mapper creates temporary queue aka virtual queue machine task mapping calculates completion distribution unmapped task heterogeneous machine explain calculate task completion presence task upon task machine queue completion PMF task task improve intuitively task deadline enables task execution sooner increase probability subsequently overall robustness HC task queue compound uncertainty completion task queue task excludes pet convolution reduce compound uncertainty prune mechanism propose research calculate impact task probability task task mathematical model calculate completion probability meeting deadline task task recall entry pet matrix PMF execution task task machine impulse denote execution probability impulse similarly completion PMF task machine denote impulse denote impulse probability task machine task deadline arrives idle machine impulse shift task machine probability deadline denote calculate machine idle execute pending task task arrives pct task machine convolve PMF account execution task ahead task machine queue task assign machine convolve pct task machine queue completion impulse generate differently task permit scenario task permit pending task task execute initial calculate completion PMFs propose however mathematically model calculate completion PMFs limit interested reader refer explanation task permit mapped task execute completion calculate impulse denote convolution pending task impulse deadline task calculate task due deadline passing therefore formulation reflect impact truncate convolution owe complexity calculate circumstance develop helper function denote discard impulse calculate impulse however helper equation generate impulse discard impulse later impulse account task completes task execute completion impulse obtain however happens task purpose calculate guaranteed deadline therefore impulse aggregate impulse discard impulse task probability task completes task deadline calculate completion probability propose theory mapping non negligible overhead therefore propose approximate compute mitigate overhead prune practical component resource allocation maximize robustness via prune mechanism overview mapping identify oversubscribed prune mechanism aka pruner examines machine queue execute task queue task queue probability calculate task threshold remove mapping determines mapping task batch queue prior assign task machine task defer assign machine return batch queue mapping effort increase robustness machine become available processing defer task pruner HC regard defer operation address surround probability threshold task defer identify threshold described related arises probability threshold apply task individual consideration characteristic task characteristic determination task cease dynamically oversubscribed transition pruner aggressive mode unlikely succeed task overall robustness improve prune potentially unfair schedule across task constantly prune compute intensive urgent task task maximize overall robustness hence unfairness across task prevent prioritize task prune  address task probability dynamic per task probability threshold simplest task  apply uniform threshold task machine queue however deeper analysis task probability completion task queue difference account decision task addition task feature completion PMF valuable decision probabilistic task identify task characteristic influence task task task machine queue skewness completion PMF task closer task execution machine queue task affected completion instance machine queue execute task affect completion task queue execution task queue affect task therefore apply threshold task queue skewness define asymmetry probability distribution calculate explain equation sample PMF observation observation standard deviation observation negative skewness distribution whereas positive tale generally highly skewed define bound skewness negatively skewed PMF majority probability PMF alternatively bulk probability bias PMF positive skew implies task sooner later PMFs completion however skewness information task impact task queue task likely sooner positive skewness propagate positive impact task queue negatively skewed task reasonably task positive skewness task skews completion task queue  negative negative skew whereas  positive positive skew task queue skewness queue adjust threshold dynamically task machine queue adjust threshold task denote calculate task positively skewed completion PMF negate skewness account task machine queue denote negate skewness addition avoid zero parameter adjust threshold ideally task deadline robustness HC image KB image demonstration task skewness completion PMF task PMFs deadline PMFs execution PMF task completion PMF task dynamic adjustment probability stage pruner defer task task queue task PMF task queue task defer probability task specify threshold warrant risk allocate resource optimal defer however apply unmapped task batch queue workload characteristic defer threshold throttle incoming task HC defer threshold ensures available machine queue slot reserve task resource utilization compute resource idle defer threshold allows task potentially machine queue slot prevent mapping incoming task avoid scenario appropriate defer threshold dynamically characteristic workload approach dynamically adjust defer threshold workload characteristic selective factor denote define ratio task batch queue mapped empty slot machine queue selective factor indicates unmapped task machine queue slot accommodate scenario task mapping selective task aggressive machine queue slot task mapped defer threshold HC unmapped task batch queue competent task task maximum across machine competent task defer decent accordingly task competency denote batch queue define ratio competent task unmapped task calculate task competency implies percentage task batch queue qualify mapping mapped due inadequate slot machine queue defer threshold increase highly competent task mapping conversely task competency indication task defer threshold selective majority task cannot pas defer threshold image KB image component prune mechanism input mapping metadata output prune decision apply mapper task defer machine queue task prune package module resource allocation function conjunction mapping heuristic instantaneous robustness instantaneous robustness define average task exist machine queue queue slot machine queue meeting deadline task machine queue instantaneous robustness calculate hypothesis maintain instantaneous robustness overall robustness instantaneous robustness performance indicator task deferral mapping heuristic aim maintain instantaneous robustness avoid task mapping reduce instantaneous robustness defer probability threshold heavily oversubscribed empty slot machine queue task batch queue defer threshold reduce task mapping alternatively task available slot competency task passing defer threshold defer threshold reduce otherwise oversubscription defer threshold instantaneous robustness constant adjust defer probability threshold formally express defer probability threshold dynamically calculate aggressive prune dynamically engage task maximize robustness aggression prune mechanism dynamically adjust reaction oversubscription HC prune mechanism considers task deadline mapping indicator oversubscription identify oversubscription toggle transition pruner task mode however pruner potentially toggle mode acute spike task arrival sustain oversubscription judge oversubscription pruner operates average task deadline mapping oversubscription HC mapping task deadline mapping parameter tunable relative assign oversubscription calculate analyze impact appropriate another potential concern minor fluctuation toggle switch employ  trigger prevent minor fluctuation around toggle toggle initial  trigger separation instance oversubscription signal oversubscription signal prune mechanism module resource allocation overview goal maximize robustness theory calculate task completion presence task maximize robustness via prune mechanism leveraged prune mechanism module resource allocation mapping heuristic probabilistic mapping heuristic prune aware mapper pam prune aware mapper PAMF propose along prune mechanism task prune mechanism overall architecture prune mechanism accounting module receives meta data task deadline pet pct resource allocation meta data available component utilize toggle module default  trigger configuration information oversubscription HC decides beneficial engage task goal maximize robustness pruner module  defer sub module prune task threshold specify prune configuration moreover defer threshold dynamically adjust mapping maximize robustness threshold estimator modifies threshold task skewness machine queue furthermore defer threshold estimator module adjusts defer threshold oversubscription fairness module employ avoid unfair prune mechanism module detects suffer task consistently adjusts pruner prevent task unfairly prune fairness module elaborate output prune mechanism decision task apply machine queue task prune apply unmapped queue mention earlier prune mechanism pluggable mapping heuristic explain plug prune mechanism probabilistic mapping heuristic namely pam PAMF mapping heuristic prune mechanism mapping heuristic conjunction prune mechanism developed heuristic prune aware mapper pam leverage probabilistically maximize robustness scope robustness define task however maximize robustness unfair task completion mapping heuristic propose achieve maximum robustness balance fairness across task heuristic phase phase task machine affinity task machine construct pam considers task machine affinity implicitly via task consideration task machine mapping task assign machine prune mechanism plug mapping heuristic maximize robustness prune occurs prior mapping decision pruner performs task machine queue task batch queue defer threshold defer defer task remain batch queue prune aware mapper pam pam maximize robustness happens maximize task pet matrix task prior observation machine offering construct task machine phase pam heuristic phase completion mapping prefers task execution prune aware mapper PAMF probabilistic task prune potentially task shorter execution unfairness shorter task usually probability completion within deadline PAMF mitigate unfair task prune mapping heuristic threshold defer adjust task unfairly treat define sufferage mapping task denote determines decrease relax prune threshold define sufferage define fairness factor denote constant across task HC sufferage task fairness factor denotes quickly task sufferage response deadline factor relaxation probabilistic requirement update sufferage occurs upon completion task successful completion task mapping lower sufferage task fairness factor whereas unsuccessful task fairness factor limit sufferage mapping heuristic determines prune threshold task mapping sufferage prune threshold update prune threshold enables PAMF distribution task task unfairly treat prune update prune threshold suffer task PAMF function pam practicality prune mechanism concern deployment probabilistic approach mapping task extra computational overhead convolution strain machine handle task mapping task ensure probabilistic task prune mechanism pam practical describes technique mitigate schedule overhead image KB image overview optimization strategy pct task machine queue predetermine mapping perform PMF compaction approximation task machine queue pct arrival task pet respectively calculate algorithm memoization without convolution macro memoization reduce redundant calculation phase pam probabilistic mapping heuristic unmapped task execution PMF pet convolve pct task machine queue pct chain convolution machine queue suppose task machine queue pct unmapped task convolution therefore recommend cache pct task machine queue mapping remove repetitive convolution machine queue reduces convolution cached mapping cache valid mapping cache longer valid pct task machine queue calculate perform PMF approximation pct explain approximation reduce convolution overhead convolution impose significant computation due sheer impulse pct chain compound convolution therefore alleviate schedule overhead dynamic program approximate technique utilized reduce spent PMF convolution introduce procedure reduce impulse propose procedure replace convolution probabilistic mapping heuristic convolve pct task machine queue pet unmapped task due  convolve machine queue unmapped task impose significant computational overhead warrant customize algorithm PMF approximation convolution relates directly impulse PMF PMF finely detailed convolution burden calculation impulse due uncertainty heterogeneous compute extra resolution yield significantly decision therefore calculation approximate PMF impulse detailed PMF approximate PMF combine multiple impulse specific approximation minimum maximum impulse distribution distribution cropped specify relevant impulse task machine queue  approximate maximum deadline entire unmapped task without measurement task mapping micro memoization reduce convolution overhead probabilistic mapping heuristic calculation unmapped task mapping decision probability straightforward compute unmapped task pct completion PMF convolve unmapped task pet pct task machine queue memorize approximate mention earlier pct task deadline calculate pct unmapped task calculate potential mapping probability reuse therefore instead calculate unmapped task pct propose directly calculates distribution pet unmapped task pct task machine queue without pct unmapped task assume distribution impulse iterate sort impulse sort procedure virtually performs partial convolution impulse specify deadline impulse sort partial iteration algorithm memorize image KB image image KB image impulse approximation bucket minimum maximum impulse grouped combine interval specific impulse specify max specify min combine image KB image simplify procedure pet unmapped task pct task machine queue iteration notion italic prior iteration notion scalar denote algorithm respectively algorithm input distribution pet unmapped task distribution cached pct task machine queue deadline signifies probability associate impulse distribution signifies associate impulse impulse distribution iterate impulse impulse combine impulse specific impulse distribution combine finally sum multiplication impulse distribution combine impulse reset iteration iteration meeting deadline distribution distribution convolve simplify algorithm task deadline procedure distribution iteration considers impulse per iteration impulse ignore deadline iteration considers impulse combine target impulse meeting deadline partial prior iteration iteration contains constitute meeting deadline distribution distribution convolve suppose distribution impulse distribution impulse straightforward convolution multiplication another combine impulse algorithm combination loop distribution twice distribution multiplication happens hence reduce complexity significantly measurement probabilistic mapping heuristic experimental setup overview conduct comprehensive performance evaluation simulate compute inconsistently heterogeneous machine generate probabilistic execution PMFs pet execution twelve specint benchmark bare machine execution benchmark task machine execution function execution task machine assume unimodal distribution gamma distribution task machine execution randomly picked execution sample histogram generate discrete probability function PMF task machine resultant machine twelve task matrix PMFs pet matrix remains constant across statistical explore tweak PMF distribution online manner generate workload simulation finite span idle online task accumulate queue desire oversubscription simulation task maintain oversubscribed effort minimize non oversubscribed portion simulation data task remove remain task oversubscribed portion simulation analysis workload investigation gamma distribution arrival rate task synthesize task task variance distribution task arrival rate generate estimate task task attendant arrival deadline generate sample task distribution recall task individual deadline deadline task deadline calculate arrival execution task slack coefficient task execution slack allows task completion oversubscribed baseline mapping heuristic   MM heuristic extensively literature phase heuristic virtual queue traverse task queue machine minimum completion phase machine slot provisional mapping examine machine task minimum completion assignment machine queue machine queue batch queue exhaust   deadline MSD phase MM phase selects task machine  deadline task minimum completion MM machine available queue slot receives task provisional mapping phase virtual machine queue unmapped task queue empty   MMU urgency task machine define deadline task completion task machine phase MMU MM urgency equation phase selects task machine urgency mapping virtual queue batch queue empty virtual machine queue max  completion   heuristic developed pet matrix calculate robustness task machine mapping mapping phase task machine offering robustness cull phase virtual queue task fail pre define robustness threshold phase virtual mapping robustness permutes task machine maximizes overall robustness machine virtual queue task batch queue mapped virtual machine queue performance evaluation overview series simulation  optical network infrastructure  queen bee hpc examine parameter workload trial perform task arrival built arrival rate confidence interval report arrival rate task per workload trial consist task per trial investigates oversubscription task successfully baseline heuristic due frequent task mapping machine HC machine queue counting execute task toggle task evaluate machine queue consistent unless otherwise performance metric vertical axis percentage task deadline overall robustness dynamic engagement probabilistic task aim appropriately oversubscription assign deadline recent mapping versus previous oversubscription evaluate impact  trigger oppose threshold dynamic engagement task conduct task assign task recent mapping overall robustness increase due steady task arrival workload trial spike maximum robustness  trigger enable  trigger alone difference optimal robustness ignore altogether incur schedule overhead image KB image impact historical oversubscription observation  trigger oversubscription HC horizontal axis coefficient conclude oversubscription immediate action task deadline steady application probabilistic task situation  bound  trigger evaluate mutual impact defer threshold goal fold identifies impact initial threshold evaluates impact defer threshold effectiveness purpose disable dynamic defer threshold statically workload characteristic helpful defer threshold statically reduce prune overhead static defer threshold designate threshold otherwise task immediately mapped accordingly conduct evaluation gap initial threshold threshold robustness task machine threshold examine gap increase defer threshold generate workload task validates assumption defer threshold robustness addition defer threshold chosen defer operation  diminishes influence robustness specifically defer threshold obtain robustness regardless initial threshold noteworthy threshold influence incur HC prevent waste processing unlikely succeed task mapped evaluation initial threshold image KB image impact defer threshold robustness threshold denote evaluate impact defer various workload goal evaluate effectiveness dynamic defer threshold adjustment various scenario examine initial dynamic defer threshold ultimate robustness purpose initial defer probability threshold robustness pam heuristic specifically examine initial defer threshold init def adjusts defer probability threshold dynamically initial defer threshold difference robustness nearly identical regardless initial defer threshold image KB image evaluate impact dynamic defer probability robustness oversubscription initial defer threshold robustness dynamic defer probability threshold denote dyn prefix statically defer threshold denote optimal prefix steady  spiky workload performance pam gear prune mechanism dynamic defer threshold prune mechanism experimentally defer threshold latter defer threshold static throughout defer threshold examine workload workload assure applicability analysis workload workload steady task arrival rate  arrival rate spiky arrival rate workload task steady burst task arrival within interval task arrival rate switch peak arrival rate peak arrival rate summary combine static dynamic defer threshold steady spiky workload evaluate dyn   dyn spiky spiky express steady spiky workload dynamic threshold almost robustness static defer threshold addition comparison steady spiky workload reveals prune mechanism suffer significantly uncertainty task arrival rate robust uncertainty task arrival rate evaluate impact fairness factor aim PAMF heuristic alleviates unfairness fairness factor fairness adjustment recall fairness factor amount modify sufferage task sufferage task mapping threshold effort promote fairness completion amongst task fairness factor report variance percentage task objective minimize variance overall robustness understand robustness compromise attain fairness robustness oversubscription task significant improvement fairness attain compromise robustness oversubscription fairness factor remarkable reduction standard deviation task implies increase fairness standard deviation reduction robustness compromise robustness defer task attempt improve fairness task successfully overall image KB image evaluate fairness robustness oversubscription horizontal axis fairness factor modifier sufferage vertical axis standard deviation task robustness however oversubscription lesser extent fairness factor significant difference oversubscription increase due oversubscription task mapping therefore possibility bias mapping task mapping fairer fairness factor significantly impact robustness highly oversubscribed configure PAMF fairness factor various oversubscription evaluate impact prune mechanism robustness overall robustness pam PAMF baseline heuristic described baseline heuristic retrofit probabilistic prune mechanism conduct evaluation various oversubscription however presentation clarity oversubscription task oversubscription evaluate pam substantial increase robustness comparison heuristic oversubscription pam nearly robustness PAMF trading percentage task task nearly robustness  another heuristic task robustness closest robustness pam rival PAMF nearly inability probabilistically task waste processing delayed task mapping thereby lower robustness robustness performance  lag allocates task machine unlikely succeed robustness MSD MMU suffers comparison heuristic instead maximize performance likely task prioritize task deadline urgency closest likely succeed task oversubscription task MSD MMU perform particularly mostly task fail deadline pam PAMF average heuristic pam PAMF averagely robustness image KB image comparison pam PAMF baseline heuristic without prune mechanism vertical axis percentage task heuristic prune mechanism exist mapping heuristic improves robustness prune mechanism impact MSD MMU heuristic occasionally attempt task tight deadline limit heuristic task beyond threshold overall robustness significantly improve gain probabilistic task prune investigate incur resource pricing amazon vms correspond machine simulation consumption active idle roughly estimate machine specification specifically assume machine consume rat machine active idle machine usage tracked price incur task percentage task normalize incur consume image KB image impact probabilistic task prune incur consume resource horizontal oversubscription vertical respectively average incur consume per task oversubscribed pam PAMF incur per task MM exclude MMU MSD perform poorly prior per task completion ratio  heuristic previous pam outperforms heuristic robustness oversubscription demonstrate benefit realize consume due processing task needlessly evaluate impose overhead evaluate task prune mechanism pam schedule overhead pam implement concept introduce pam utilizes computational reuse approximation technique introduce approximate pam task mapping performance task makespan simulation directly related schedule overhead sake accuracy measurement isolated machine without disturb workload statistically practically significant difference performance pam approximate pam confirms hypothesis computational reuse mapping approximation introduces minor error however due uncertainty heterogeneous compute approximate induces minimal mapping decision image KB image impact reuse approximation technique prune mechanism mapping heuristic robustness impose overhead horizontal axis oversubscription vertical axis robustness percentage reduction impose overhead approximate pam performs drastically faster pam implementation particularly remarkable oversubscription approximate pam processing pam implementation approximate pam faster pam another growth execution pam schedule overhead grows linear response increase oversubscription however approximate pam schedule overhead oversubscription oversubscribed workload task batch queue mapping oversubscription mapping task arrival mapping load per mapping cancel approximate pam conclusion future goal research improve robustness HC via prune task probability prune mechanism resource allocation prune probability defer task enable prune mechanism threshold task dynamically adjust defer threshold characteristic workload developed probabilistic mapping heuristic pam cooperates prune mechanism pam improve robustness average upgraded pam accommodate fairness compromise around percentage robustness employ approximate compute calculation probability reduce schedule prune overhead ensure mechanism practically conclude oversubscribed task defer favorable mapping mapping sufficiently oversubscribed unlikely succeed task alleviate oversubscription increase probability task succeed benefit defer threshold threshold evaluation reveal prune mechanism pam improves robustness reduces HC prune developed research generic plug extend probabilistic approach task preemption impact convolution finally HC various qos concern domain specific fairness model explore