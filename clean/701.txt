diagonal sparse matrix zero scatter diagonal deviation diagonal zero maintain diagonal structure dia performance degradation exist dia kernel pad zero consume extra computation memory resource motivates adaptive sparse matrix vector multiplication spmv diagonal sparse matrix graphic processing gpu dia adaptive alleviate drawback dia kernel dia adaptive characteristic sparse storage format BRCSD diagonal compress storage BRCSD II propose adapt various diagonal sparse matrix besides adopt dia spmv kernel correspond storage format appropriate storage format dia BRCSD BRCSD II diagonal sparse matrix code generator automatically generate spmv kernel dia adaptive ideal storage format kernel automatically chosen diagonal sparse matrix performance achieve experimental propose dia adaptive effective performance parallelism outperforms spmv algorithm keywords diagonal sparse matrix sparse matrix vector multiplication sparse storage format cuda gpu introduction core structure graphic processing gpus sufficient computation scientific computation processing data gpus drawn attention recent introduction compute unified device architecture cuda program model joint cpu gpu execution application nvidia gpus become competitor purpose parallel program sparse matrix vector multiplication spmv diagonal sparse matrix define diagonal sparse matrix vector output vector proven importance computational sparse matrix nonzero diagonal sparse matrix restrict matrix diagonal implement spmv diagonal sparse matrix gpu appropriate storage format highly efficient access matrix data global memory  dia appropriate storage format csr coo ell hyb efficient spmv kernel dia dia nonzero accord diagonal nonzero entry diagonal index however zero maintain diagonal structure diagonal broken zero diagonal away diagonal scatter reduce performance zero consume extra computation memory resource image KB image sample diagonal sparse matrix interpretation reader refer web version article limit zero propose storage format diagonal sparse matrix compress diagonal CRSD alleviates zero issue dia diagonal distribution define diagonal diagonal split matrix nonzero diagonal storage operation therefore contiguously however diagonal sparse matrix CRSD complicate implementation source code spmv kernel CRSD unavailable hack dia hdi format limit amount pad zero matrix equally independent matrix dia dia submatrix hdi cannot mitigate pad diagonal away diagonal investigate optimize sparse matrix vector multiplication diagonal sparse matrix gpu define diagonal sparse matrix matrix satisfy offset zero obviously matrix diagonal deviation diagonal zero scatter image KB image sample diagonal sparse matrix II matrix satisfy offset label false label false matrix II exist diagonal deviation diagonal zero scatter matrix II illustrate  predefined threshold predefined threshold  diagonal  diagonal distance diagonal  offset diag  dia  zero dia  zero elem label  diagonal matrix zero otherwise false label sas diagonal matrix scatter otherwise false matrix although pad dia appropriate spmv kernel dia utilized matrix II pad dia sparse storage format BRCSD diagonal compress storage BRCSD II matrix alleviate drawback dia respectively furthermore spmv kernel correspond BRCSD BRCSD II respectively propose identify diagonal sparse matrix diagonal sparse matrix automatically identify suitable storage format kernel chosen furthermore algorithm matrix II BRCSD BRCSD II kernel code due loop unroll optimization technique utilized therefore input matrix BRCSD BRCSD II kernel code rewrite alleviate drawback code generator automatically generate kernel code matrix code generator dia kernel code experimental propose algorithm effective outperforms kernel csr scalar csr vector ell dia hyb cusp library HYBMV  library csr adaptive hdi CRSD contribution summarize propose sparse storage format BRCSD BRCSD II spmv kernel correspond BRCSD BRCSD II diagonal sparse matrix II respectively propose automatically identify diagonal sparse matrix code generator automatically generate kernel code adaptive spmv algorithm diagonal sparse matrix gpu algorithm automatically suitable sparse storage format dia BRCSD BRCSD II achieves performance diagonal sparse matrix organize introduces related algorithm analyzes evaluates propose algorithm contains conclusion future related sparse matrix vector multiplication spmv important computational accelerate initial accelerate spmv cuda enable gpu  sparse matrix storage format csr dia ell coo hyb correspond kernel storage format suitable matrix conclude performance spmv gpu depends storage format efficient spmv kernel propose gpus variant csr ell coo storage format compress sparse  representation optimize compression csr ellpack slice ell slice coo compress coo overview efficient storage format correspond spmv kernel dia appropriate storage format diagonal sparse matrix nonzeros diagonal index however dia potentially waste storage computational resource zero pad non diagonal maintain diagonal structure limit pad non diagonal storage format correspond kernel format efficient specific diagonal sparse matrix alleviate pad dia unlike previous establish adaptive spmv algorithm diagonal sparse matrix automatically appropriate storage format pad efficient kernel diagonal sparse matrix gpu implementation propose adaptive sparse matrix vector multiplication diagonal sparse matrix gpu dia adaptive propose algorithm framework component popular sparse storage format dia kernel sparse storage format BRCSD BRCSD II correspond kernel format suitable diagonal sparse matrix II respectively appropriate storage format chosen dia BRCSD BRCSD II diagonal sparse matrix code generator generator spmv kernel diagonal sparse matrix automatically generate image KB image framework propose algorithm dia adaptive novelty diagonal sparse matrix characteristic algorithm automatically identify diagonal sparse matrix algorithm storage format kernel dia format correspond kernel propose BRCSD BRCSD II format correspond kernel suitable matrix II respectively obviously algorithm storage format identify input matrix appropriate storage format kernel code generator propose automatically generate kernel code source code code generator available supplemental subsection dia BRCSD BRCSD II format correspond kernel respectively investigate selection parameter dia format kernel dia format dia array data nonzero offset offset diagonal diagonal diagonal sparse matrix image KB image diagonal sparse matrix dia dia kernel BRCSD format kernel BRCSD format dia zero data offset diagonal offset zero alleviate drawback dia sparse storage format BRCSD diagonal compress storage extension procedure generate BRCSD image KB image procedure generate BRCSD assume diagonal matrix procedure delete sort ascend diagonal matrix trim delete invalid distance adjacent assume delete otherwise goto delete distance otherwise succeed trim procedure terminate delete distance otherwise succeed trim procedure terminate obtain previous retain delete similarly retain finally delete trim procedure terminate transform trim definition assume submatrix qth otherwise submatrix qth without intersection matrix without intersection accord definition output BRCSD array matrix assume obtain previous matrix array ith offset diagonal diagonal nonzero ith respectively matrix dia BRCSD zero diagonal away diagonal BRCSD kernel parallelize spmv BRCSD gpu straightforward matrix split BRCSD assign thread thread matrix assign thread assign another thread obviously load thread unbalanced ensure load balance thread propose BRCSD kernel thread splitting matrix furthermore procedure generate procedure guarantee multiple therefore assure coalesce access BRCSD array splitting matrix finely modify multiple thread per choice multiple warp thread per generate BRCSD kernel thread ID local thread ID identify offset array thread thread ith offset array satisfy generate spmv operation ith offset array local thread processing jth diagonal location nonzero correspond location vector finally accumulate diagonal ith offset array location BRCSD II format kernel BRCSD II format matrix zero scatter diagonal zero data dia moreover BRCSD zero instance diagonal sparse matrix dia BRCSD respectively image KB image diagonal sparse matrix BRCSD II obviously dia BRCSD zero pad scatter zero therefore alleviate drawback dia BRCSD sparse storage format BRCSD II procedure generate BRCSD II image KB image procedure generate BRCSD II detailed explanation procedure generate BRCSD II nrows matrix gpu feature multiple warp thread per thread per matrix equally matrix accord array toffsets offset diagonal diagonal nonzero array data accord diagonal diagonal matrix assume previous illustrate procedure matrix equally diagonal offset obtain toffsets data data similarly diagonal obtain toffsets data data diagonal obtain toffsets data data toffsets data toffsets data toffsets data accumulate offset array toffsets toffsets toffsets toffsets toffsets  toffsets toffsets toffsets otherwise toffsets  comparison toffsets toffsets array offset toffsets  obtain previous toffsets toffsets toffsets toffsets offset offset procedure terminate offset array offset offset array offset output BRCSD II array matrix assume obtain previous offset array accumulate matrix array offset array offset diagonal sparse matrix dia zero BRCSD II reduce BRCSD zero BRCSD II reduce BRCSD II kernel parallelize spmv BRCSD II gpu straightforward matrix split BRCSD II assign thread thread generate BRCSD II kernel thread ID local thread ID identify offset array thread thread ith offset array satisfy generate spmv operation ith offset array local thread handle jth diagonal nonzero location correspond location vector accumulate diagonal ith offset array location diagonal sparse matrix assume code BRCSD II kernel generate procedure BRCSD II kernel operation offset array execute loop loop unroll optimization technique utilized image KB image BRCSD II kernel parameter analysis selection appropriate storage format diagonal sparse matrix depends parameter offset label label directly influence performance dia adaptive therefore investigate parameter simplicity matrix investigate selection diagonal sparse matrix without zero scatter assume positive integer diagonal sparse matrix offset zero distance diagonal diagonal dia performance dia kernel diagonal zero roughly calculate obviously zero independent depends investigate threshold dia BRCSD diagonal sparse matrix obtain distance diagonal diagonal matrix execution curve dia BRCSD kernel increase millisecond BRCSD outperforms dia otherwise execution dia BRCSD therefore affirm generally guarantee dia BRCSD diagonal sparse matrix offset image KB image execution curve dia BRCSD kernel investigate selection conclude diagonal sparse matrix without zero scatter offset satisfy dia outperforms BRCSD zero diagonal obviously upper bound zero diagonal sparse matrix offset zero matrix zero scatter performance dia BRCSD BRCSD II therefore evaluation analysis experimental evaluation objective namely evaluate influence parameter dia adaptive performance dia adaptive spmv kernel nvidia gpus performance evaluation source code compile execute cuda toolkit performance gflops calculate basis assumption flop per nonzero entry matrix gpu performance data transfer gpu cpu cpu gpu overview gpus  core ghz memory  memory GB max bandwidth GB compute capability diagonal sparse matrix florida sparse matrix collection publication summarizes information matrix dimension diagonal nonzeros matrix wang wang kim nemeth florida sparse matrix collection publication matrix label florida sparse matrix collection publication matrix label false publication obviously chosen matrix characteristic scatter zero offset description matrix  wang wang sdktm  kim kim nemeth nemeth crystk crystk maxwell 2D maxwell 2D KGS 2D KGS 3D estimate optimal kernel gtx      wang YNBRCSD IIBRCSD II wang YNBRCSD IIBRCSD II sdktm BRCSD IIBRCSD II  BRCSD IIBRCSD II kim YNBRCSD IIBRCSD II kim BRCSD IIBRCSD II nemeth BRCSD IIBRCSD II nemeth YNBRCSD IIBRCSD II BRCSD IIBRCSD II BRCSD IIBRCSD II crystk YNBRCSD IIBRCSD II crystk YNBRCSD IIBRCSD II YNBRCSD IIBRCSD II YNBRCSD IIBRCSD II YNBRCSD IIBRCSD II YNBRCSD IIBRCSD II maxwell 2D YNBRCSD IIBRCSD II maxwell 2D YNBRCSD IIBRCSD II KGS 2D   KGS 3D   simplicity precision computation experimental analysis gtx accuracy propose parameter chosen diagonal sparse matrix optimal kernel estimate propose correspond optimal kernel gtx matrix fourth fifth sixth seventh display parameter offset zero label label matrix respectively eighth optimal kernel estimate matrix correspond optimal kernel ninth estimate optimal kernel accuracy rate gtx choice optimize related thread suppose thread investigate influence thread dia adaptive performance matrix thread dia adaptive performance curve thread gtx matrix respectively thread dia adaptive performance gpus gpu matrix dia adaptive performance slight difference thread matrix dia adaptive performance thread due increase pad zero sdktm pad zero thread respectively thread dia adaptive performance matrix dia adaptive performance thread slightly thread gpus therefore conclude dia adaptive performance related gpu architecture thread increase pad zero thread easy dia adaptive image KB image dia adaptive performance thread image KB image dia adaptive performance thread gtx performance evaluation dia csr ell efficiently diagonal sparse matrix popular spmv kernel csr csr adaptive representative spmv kernel ell HYBMV  library popular spmv kernel dia dia cusp library hdi CRSD csr scalar csr vector ell hyb kernel cusp library performance comparison diagonal sparse matrix performance various algorithm matrix gtx respectively speedup achieve dia adaptive algorithm gpus matrix image KB image performance comparison dia adaptive cusp HYBMV csr adaptive image KB image performance comparison dia adaptive dia hdi CRSD image KB image performance comparison dia adaptive cusp HYBMV csr adaptive gtx image KB image performance comparison dia adaptive dia hdi CRSD gtx speedup dia adaptive algorithm   gtx csr   wang wang sdktm  kim kim nemeth nemeth crystk crystk     performance comparison dia adaptive cusp HYBMV csr adaptive gtx respectively gpu dia adaptive outperforms cusp HYBMV matrix sdktm  crystk crystk dia adaptive performance cusp HYBMV matrix due ell appropriate format matrix sdktm  crystk crystk dia adaptive slight performance degradation achieves average performance improvement cusp HYBMV addition dia adaptive behavior csr adaptive matrix achieves average performance improvement csr adaptive dia adaptive performance csr adaptive cusp HYBMV matrix sdktm  crystk gtx achieves average speedup csr adaptive cusp HYBMV respectively furthermore performance comparison dia adaptive popular spmv kernel diagonal storage format dia hdi CRSD gtx respectively obviously performance propose dia adaptive almost dia hdi CRSD matrix gpus dia adaptive achieves speedup gtx dia average speedup gtx roughly respectively speedup dia adaptive hdi gtx average speedup gtx roughly respectively CRSD dia adaptive achieves speedup gtx average speedup gtx roughly respectively gtx effective bandwidth algorithm effective bandwidth calculate effective bandwidth GB byte per kernel byte per kernel effective bandwidth algorithm matrix gtx csr adaptive cusp HYBMV dia adaptive effective bandwidth nonzeros matrix wang wang sdktm  kim otherwise outperforms effective bandwidth dia adaptive achieves average improvement csr adaptive cusp HYBMV respectively furthermore dia adaptive effective bandwidth matrix popular spmv kernel diagonal storage format dia hdi CRSD average efficient bandwidth almost dia hdi CRSD respectively image KB image effective bandwidth dia adaptive cusp HYBMV csr adaptive gtx image KB image effective bandwidth dia adaptive dia hdi CRSD gtx discussion analysis experimental mention discover dia adaptive advantageous dia hdi CRSD subsection address dia adaptive achieve performance dia hdi CRSD execute gtx dia performance improvement dia adaptive mainly derives decrease zero pad pad zero dia format dia format matrix uniformly dia denote sparse storage format dia BRCSD BRCSD II dia adaptive dia diagonal sparse matrix matrix dia denote dia format matrix II dia displayed BRCSD format dia denote BRCSD II format matrix pad zero  wang wang sdktm  kim kim nemeth nemeth crystk crystk maxwell 2D maxwell 2D KGS 2D KGS 3D however hdi CRSD pad zero dia moreover dia inspire dia difference exhibit algorithm sparse storage format dia BRCSD BRCSD II correspond diagonal sparse matrix respectively however hdi CRSD storage format diagonal sparse matrix diagonal sparse matrix dia denote dia storage format dia kernel utilized algorithm hdi CRSD algorithm convert format kernel execution matrix diagonal assume construct hdi CRSD format millisecond respectively execute hdi CRSD kernel respectively execution dia kernel indicates algorithm outperforms hdi CRSD diagonal sparse matrix dia displayed BRCSD storage format BRCSD kernel algorithm BRCSD difference hdi CRSD difference hdi BRCSD hdi BRCSD hdi diagonal sparse matrix diagonal obtain accord BRCSD hdi matrix broken equally multiple warp obtain hdi image KB image sample matrix data BRCSD hdi BRCSD merges data continuous offset hdi matrix BRCSD hdi matrix array addition computation complexity construct BRCSD construct hdi verify comparison hdi BRCSD   kernel   KGS 2D KGS 3D pde 2D pde 3D BRCSD hdi kernel implementation although BRCSD hdi kernel thread compute BRCSD kernel advantage hdi kernel BRCSD kernel avoids access  offset utilize loop unroll optimization technique access data coalesce hdi kernel access data partially coalesce access hdi offset  align mention BRCSD merges data continuous offset beneficial utilize loop unroll optimization technique improve performance BRCSD kernel verify observation matrix KGS 2D KGS 3D pde 2D pde 3D comparison hdi BRCSD pde 2D pde 3D literature diagonal sparse matrix diagonal diagonal sparse matrix diagonal respectively matrix chosen belong diagonal sparse matrix discover matrix BRCSD construction execution hdi verifies conclusion mention difference CRSD hdi matrix broken equally CRSD obviously BRCSD BRCSD CRSD scatter BRCSD CRSD regard scatter nonzero diagonal scatter encounter diagonal sparse matrix scatter CRSD data BRCSD CRSD matrix BRCSD CRSD matrix array moreover computation complexity construct BRCSD construct CRSD verify comparison CRSD BRCSD   kernel   KGS 2D KGS 3D pde 2D pde 3D BRCSD CRSD kernel implementation BRCSD kernel merit CRSD kernel mention access data BRCSD kernel coalesce however access data CRSD kernel partially coalesce access align addition merge data continuous offset remainder thread per usually zero thread idle decrease CRSD kernel performance extent CRSD kernel thread scatter scatter cannot thread thread fully occupy idle thread decrease performance CRSD kernel verify observation KGS 2D KGS 3D pde 2D pde 3D comparison CRSD BRCSD BRCSD CRSD construct format execution CRSD verifies conclusion diagonal sparse matrix dia denote BRCSD II storage format BRCSD II kernel algorithm BRCSD II difference hdi CRSD difference hdi BRCSD II hdi matrix equally partition slightly BRCSD II partition generally thread per hdi partition designate multiple warp BRCSD II hdi difference data BRCSD II merges data continuous offset hdi matrix BRCSD II hdi matrix array image KB image sample matrix moreover computation complexity construct BRCSD II slightly construct hdi comparison hdi BRCSD II   kernel   II wang sdktm kim nemeth crystk implement BRCSD II hdi gpu difference although BRCSD II hdi kernel thread compute BRCSD II kernel advantage hdi kernel BRCSD II kernel avoids access  offset utilize loop unroll optimization technique access data coalesce hdi kernel access data partially coalesce access hdi offset  align mention BRCSD II merges data continuous offset beneficial utilize loop unroll optimization technique improve performance BRCSD II kernel wang sdktm kim nemeth crystk verify observation matrix chosen diagonal sparse matrix comparison BRCSD II hdi BRCSD II hdi construct format execute kernel verify conclusion difference CRSD BRCSD II CRSD matrix equally partition moreover BRCSD II CRSD BRCSD II partition generally thread per CRSD partition designate BRCSD II CRSD definition handle scatter BRCSD II regard scatter nonzero diagonal matrix however CRSD nonzero diagonal regard scatter scatter BRCSD II scatter CRSD BRCSD II scatter handle zero CRSD nonzero item scatter separately matrix BRCSD II CRSD matrix data BRCSD II CRSD significantly moreover computation complexity construct BRCSD II construct CRSD comparison CRSD BRCSD II   kernel   II wang sdktm kim nemeth crystk BRCSD II CRSD kernel implementation BRCSD II kernel merit CRSD kernel mention access data BRCSD II kernel coalesce however access data CRSD kernel fully coalesce access align addition merge data continuous offset remainder thread per usually zero thread idle decrease CRSD kernel performance extent CRSD kernel thread scatter scatter cannot thread thread fully occupy idle thread decrease performance CRSD kernel wang sdktm kim nemeth crystk verify observation comparison BRCSD II CRSD BRCSD II CRSD construct format execution CRSD verify conclusion conclusion adaptive sparse matrix vector multiplication diagonal sparse matrix gpu propose algorithm diagonal sparse matrix suitable sparse storage format kernel correspond propose matrix algorithm automatically appropriate storage format kernel diagonal sparse matrix performance achieve validate efficiency propose algorithm dia BRCSD BRCSD II zero pad utilizes loop unroll optimization technique improve performance matrix content matrix KGS 2D KGS 3D pde 2D pde 3D reduce zero pad utilize loop unroll BRCSD BRCSD nlp BRCSD loop unroll dia reduce zero pad improve performance BRCSD nlp minimum maximum execution ratio BRCSD nlp dia respectively average execution ratio furthermore execution BRCSD nlp BRCSD loop unroll improve performance BRCSD BRCSD execution BRCSD nlp matrix minimum maximum execution ratio BRCSD nlp BRCSD respectively average execution ratio reduce zero pad utilize loop unroll BRCSD   KGS 2D KGS 3D pde 2D pde 3D matrix wang sdktm kim nemeth crystk exhibit decrease zero pad utilize loop unroll BRCSD II BRCSD II nlp BRCSD II loop unroll execution dia BRCSD II nlp decrease zero pad improve performance BRCSD II nlp zero pad reduce BRCSD II nlp performance dia zero pad BRCSD II nlp reduce reduction ratio performance BRCSD II nlp improve crystk reduction ratio zero pad BRCSD II nlp dia performance BRCSD II nlp improves furthermore BRCSD II nlp BRCSD II loop unroll improve performance BRCSD II BRCSD II execution BRCSD II nlp matrix minimum maximum execution ratio BRCSD II nlp BRCSD II respectively average execution ratio decrease zero pad utilize loop unroll BRCSD II  II  II wang sdktm kim nemeth crystk algorithm thread thread thread multiple performance algorithm assume thread BRCSD II investigate performance performance BRCSD II increase performance BRCSD II kernel BRCSD II kernel multiple warp BRCSD II kernel almost execution BRCSD II kernel slightly respectively however construct BRCSD II format respectively construct BRCSD II format sdktm construct BRCSD II format respectively construct BRCSD II format therefore thread performance BRCSD II matrix wang sdktm kim nemeth crystk research apply propose dia adaptive practical