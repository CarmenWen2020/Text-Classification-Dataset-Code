increase core chip brings capability exploit thread parallelism tlp however dissipate per node generation achieve hardware component provoke undesired behavior application core execution maximum tlp available degrade performance unnecessarily increase accelerate propose hebe dynamic concurrency throttle approach learns tlp reduces openmp application hebe totally transparent modification binary code extensive fifteen benchmark multicore platform hebe outperforms approach exhaustive previous keywords thread parallelism optimization runtime introduction satisfy demand performance application domain data core chip package pace increase transistor density however dissipate per node generation dennard dissipation become significant issue exploit thread parallelism tlp besides increase dissipation operating influence hardware component negative bias instability NBTI shorten lifetime NBTI consists vital reliability oxide silicon MOS device refers generation positive oxide interface trap MOS structure combination elevate negative gate voltage increase threshold voltage adverse propagation delay degrade device performance impact NBTI processor become significant device due aggressive device geometry compact device integration strongly affect operating intensify processor increase threshold voltage provoke undesired behavior  dielectric breakdown stress migration critical application increase operating expense therefore operating essential avoid shorten hardware lifespan parallel application processor thread increase mainly increase dissipation due switch activity hardware component core cache behavior execution BT kernel NAS parallel benchmark intel xeon core machine retire average cpu application execution thread average NBTI per execution raw proportionally grows therefore benefit brings execution impact due NBTI directly related thread distribute across core parallel application image KB image behavior BT kernel NAS parallel benchmark execution intel xeon core nevertheless application thread increase due hardware related instruction issue width saturation chip bus saturation data synchronization concurrent memory access execute application regular splitting application thread available core non optimal available resource deliver performance accelerate impact NBTI therefore artificially decrease thread thread throttle parallel rightly tune parameter mention achieve performance ratio reduce impact NBTI processor execution streamcluster application rodinia benchmark suite NBTI achieve application thread performance hence execute application ideal tlp thread instead maximum thread default behavior impact NBTI processor image KB image behavior streamcluster application rodinia benchmark suite execution intel xeon core scenario propose hebe transparent aware thread throttle approach openmp application efficient algorithm automatically learns ideal thread parallel aim reduce impact NBTI processor dynamic capability adapt thread balance intrinsic characteristic parallel application input parallel microarchitecture execute core instruction architecture hebe improves previous optimization realistic phenomenon processor NBTI metric validate hebe execution fifteen benchmark distinct multicore platform amd intel hebe scenario standard parallel application execute std maximum thread available built feature openmp dynamically thread omp dynamic thermal aware adaptive minimization approach openmp application propose TA omp hebe impact NBTI processor std configuration omp dynamic TA omp approach reinforce specifically optimizes impact NBTI processor hebe objective function optimize performance EDP instead NBTI configuration normalize hebe geometric entire benchmark multicore processor performance EDP orient setup NBTI objective function respectively hebe approach target performance FDT varuna program model finally curve converge ideal thread dynamic adaptation hebe exhaustive executes parallel predefined ideal thread without overhead average hebe reduce impact NBTI processor benchmark image KB image hebe optimize NBTI baseline versus hebe optimize performance EDP geometric entire benchmark hebe interpretation reader refer web version article remainder manuscript organize hebe described benchmark execution environment validate hebe described discus related hebe consideration drawn hebe apply dynamic concurrency throttle mitigate processor hebe aim reduce impact NBTI processor tune tlp parallel openmp application workflow hebe openmp application binary parallel hebe applies algorithm parallel phase described thread delivers impact NBTI processor converges ideal thread stable phase phase parallel executes thread phase algorithm ideal thread execute parallel contrast respectively image KB image illustration stable phase implement hebe structure organization hebe NBTI model hebe phase algorithm phase finally discus hebe implement openmp library transparency user model NBTI NBTI phenomenon degrades electrical characteristic PMOS NMOS transistor increase threshold voltage processor lifetime transistor switch affect delay critical processor incur timing violation error increase delay due increase processor delay critical model define equation voltage duty cycle equivalent utilization rate core processor processor constant respectively input data equation obtain runtime directly hardware counter processor voltage sensor available version linux operating duty cycle core calculate ratio core stress define equation however challenge automatic online processor training phase understand cpu behavior BT NAS benchmark execution thread intel xeon processor execution usually corresponds phase cpu regardless thread variation instantaneous however application executes cpu accord thread define earlier therefore decision phase cpu likely non ideal significant correspond active thread image KB image behavior cpu BT NAS benchmark intel processor thread axis data visualization hence ensure algorithm converge ideal data reflect cpu behavior consequently author already cpu mainly affected dissipation instantaneous proportionally correspond future therefore consumption instantaneous easily hardware counter shelf processor reflect cpu optimization consumption significant impact information phase algorithm discus hebe converges thread deliver tradeoff execution parallel aim reduce NBTI processor hebe application independent parallel parallel execute distinct core denote parallel application optimization interested seek assignment parallel application subset thread core denote subset thread core feasible assignment define function assigns subset thread core parallel knowledge runtime api capable dissipation per core without incur overhead algorithm assume subset distinct core perform similarly concern execution dissipation dissipation obtain directly hardware counter processor intel processor average limit RAPL library application management library amd processor furthermore per core model per core performance counter negligible overhead therefore denote execution execute parallel distinct core thread likewise denote dissipation parallel core thread execution dissipation define function valid assignment function define distance valid subset presentation define distance assignment optimize assignment consists valid assignment minimum function strives balance performance dissipation chosen core assignment optimize minimum respect formally algorithm receives input core parallel parameter initial thread increase factor thread iteration maximum available core parallel algorithm execution procedure increase exponentially respect thread minimize function upon local maximum respect function algorithm performs modify interval algorithm minimum algorithm image KB image algorithm hebe algorithm avoid minimum local plateau wrongly converge incorrect thread algorithm lateral movement movement perform thread configuration another hebe converges thread parallel monitor behavior workload variation algorithm execution algorithm converges minimum iteration thread delivers outcome metric execute parallel convex optimization specific thread ideal metric parallel algorithm suitable complexity essential reduce technique overhead execute moreover author already along another approach algorithm ideal escape local minimum plateau algorithm implement hebe learns towards thread application execution computation phase waste application reduce overhead hebe implementation transparency hebe openmp application exploit parallelism parallel loop influence execution openmp application implement directive task openmp parallel program interface memory fortran consists compiler directive library function environment variable eas developer burden manage thread code therefore extract parallelism openmp usually effort apis pthreads mpi appeal software developer widely benchmark application implement openmp NAS parallel benchmark  parboil rodinia parsec   gromacs lulesh etc implement hebe inside gnu openmp library image offload multi processing library functionality openmp image dynamically link openmp application modification code entirely transparent user application hence hebe user simply replace openmp image hebe image library openmp functionality plus function hebe environment variable image image linux operating thread management hebe instead openmp function hebe influence execution openmp application application executes openmp function hence modification OS package installation kernel recompilation  permission exist binary code benefit hebe without modification recompilation understand hebe regular parallelize iterative application openmp respective function implement image program execute image function initializes environment variable openmp application execution application openmp directive image parallel function define thread image whenever application executes directive thread parallel parallel image function responsible finalize parallel environment finally application image function finalize openmp environment image KB image openmp code respective  function organization openmp library functionality hebe split function image responsible recognize hebe active initializes data structure library variable hebe function implement inside image function image thread execute parallel algorithm described initializes hardware counter data execution environment parallel implement function inside image hebe active replaces image function image execute parallel behavior regard optimization metric define performs algorithm accord algorithm defines thread execution respective parallel iteration function insert image function hebe active replaces openmp functionality image concludes destroys hebe environment application execution implement inside image function methodology benchmark fifteen application already parallelize openmp assort suite chosen kernel NAS parallel benchmark tri diagonal solver BT NAS conjugate gradient CG NAS discrete 3D fourier transform FT NAS upper gauss seidel solver LU NAS scalar  diagonal solver SP NAS unstructured adaptive mesh UA NAS version NAS fortran openmp version application rodinia benchmark suite LU decomposition lud speckle reduce anisotropic diffusion srad streamcluster SC application domain fourier transform fft calculates discrete fourier transform sequence hpcg performance operation jacobi  iteration computes diagonally dominant linear equation NB computes simulation dynamical particle poisson PO computes approximate poisson equation rectangular application  unstructured lagrangian explicit shock  lulesh application widely variety computer simulation engineering  model challenge implement lawrence  national laboratory LLNL darpa ubiquitous performance compute program proxy application department effort exascale era chosen benchmark scalability limited issue bottleneck prevent significant speedup thread increase data synchronization synchronization operation perform ensure data integrity execution parallel application NB SP NAS memory access access memory processor thread communicate application BT NAS LU NAS lud PO SC chip bus saturation application amount data private thread continuously fetch memory application classify fft hpcg  issue width saturation thread mapped core exploit smt compete resource non optimal core delay execution parallel increase unbalance thread comprises application CG NAS FT NAS srad UA NAS chosen benchmark scalability limited distinct issue tlp behavior tlp define author average amount concurrency exhibit program execution core active express equation core concurrently thread core non idle closer normalize core available tlp available NB FT NAS benchmark tlp image KB image tlp available benchmark normalize maximum thread processor execution environment perform multicore platform architecture linux kernel compile application gcc optimization flag openmp prevent processor frequency influence execution scenario DVFS governor performance frequency maximum furthermore execution environment variable  cpu affinity bind thread specific cpu average execution configuration standard deviation characteristic processor hebe scenario regular execution openmp application omp regular application executes maximum thread available adaptation runtime standard behavior openmp application without user intervention openmp dynamic omp dynamic built feature openmp dynamically adjusts thread parallel aim resource memory processor TA omp thermal aware adaptive minimization approach openmp application propose user annotates code budget parallel runtime implement within openmp library budget tlp thread affinity DVFS application executes faithfully implement approach inside openmp library define budget concern thermal TDP processor amd processor execute application budget exhaustive execution parallel thread delivers NBTI equation without influence algorithm ideal thread obtain exhaustive execution parallel application thread maximum hardware pre configure application amount thread execution popular approach thread throttle varuna PM faithfully implement program model define apply benchmark FDT thread define contention lock memory bandwidth implement FDT mechanism insert function openmp code define due lack hardware counter amd ryzen evaluate FDT intel machine although varuna PM FDT aim improve processor lifetime comparison behave respect specific metric hebe algorithm improve performance consumption delay EDP analyze specific optimizes achieve hebe approach define previous hence convergence algorithm implement hebe discus outcome converge ideal ideal thread parallel hebe openmp regular execution openmp dynamic feature thermal aware approach propose overhead algorithm implement hebe finally develop thread throttle mitigate impact NBTI processor convergence hebe thanks analysis hebe detect tlp exploitation reduce impact NBTI processor ideal application limit factor lack scalability data synchronization NB SP NAS application thread prolong synchronization eventually worsen performance thread execute concurrently accelerate impact NBTI processor depict behavior NB execution amd core thread execution primary axis split execute parallel synchronize performance hebe secondary axis zero metric execute execution reduces thread increase however synchronization code execution parallel hence performance worsens grows rate performance increase NBTI thread curve hebe achieve performance therefore NBTI image KB image scalability behavior NB benchmark amd core application amount private data continuously fetch memory fft hpcg  sweet saturation execution parallel fft benchmark intel core thread chip bus saturates utilization axis solid improvement performance dash graph axis increase NBTI capable converge thread hebe deliver NBTI image KB image scalability behavior parallel fft benchmark intel core application communication demand thread BT NAS LU NAS lud PO SC optimal memory access overcome reduction NBTI achieve parallelism exploitation behavior execution parallel lud benchmark intel core cache llc rate thread increase significantly sixteen thread primary axis improvement execution processor achieve secondary axis therefore converge ideal thread hebe NBTI image KB image scalability behavior parallel lud benchmark intel core hebe converges ideal ideal thread application negatively influence issue width saturation benchmark CG NAS FT NAS srad UA NAS understand hebe behaves application discus behavior parallel srad benchmark intel core ideal thread thread increase cycle thread without issue instruction increase abruptly therefore performance increase avoid excessive increment thread ideal hebe reduce NBTI omp regular execution thread image KB image scalability behavior parallel srad benchmark intel core NBTI evaluation entire benchmark along geometric gmean multicore hebe regular execution openmp application omp regular hebe omp dynamic moreover depicts comparison hebe TA omp budget TDP processor normalize accord setup omp regular omp dynamic budget TA omp approach hebe image KB image hebe versus omp regular omp dynamic hebe image KB image hebe versus TA omp budget multicore processor hebe hebe versus omp regular hebe capable reduce impact NBTI processor due converge ideal tlp execute NB benchmark hebe reduces NBTI equation intel core specific scenario exploration limited achieve thread core therefore significant overhead due phase baseline hebe FT NAS application intel core however geometric entire benchmark processor hebe reduction NBTI hebe versus omp dynamic hebe outperforms openmp feature instead algorithm converge optimal thread parallel specific implementation omp dynamic considers workload execution define thread capable optimal thread omp regular execution hebe NBTI reduce PO benchmark amd core overall geometric entire benchmark processor hebe achieve NBTI omp dynamic feature hebe versus TA omp differently employ hebe exponentially increase thread phase TA omp increase thread iteration spending converge strategy strongly affect overhead phase processor core iteration execute non ideal thread furthermore application tlp affected strategy employ phase however TA omp capable converge ideal configuration thread hebe exploration limited amd core application tlp  fft user knowledge budget minimize processor minimal impact performance budget NBTI therefore intrinsic characteristic TA omp hebe deliver NBTI regardless budget hebe NBTI TA omp NB benchmark intel core geometric entire benchmark processor hebe NBTI TA omp budget TDP NBTI TA omp budget TDP overhead hebe hebe learns application executes overhead impose algorithm overhead difference hebe exhaustive originate situation execution algorithm comprises overhead function implement hebe described reading hardware counter algorithm evaluate optimization metric algorithm overhead overhead hebe execution parallel thread ideal possibility converge significant overhead hebe overhead hebe almost negligible benchmark however NBTI achieve tlp hebe CG NAS PO FT NAS execute intel core hebe extra overhead phase converge configuration already omp regular execution image KB image hebe exhaustive understand hebe discus behavior converge parallel FT NAS benchmark intel core exhaustive thread NBTI execution tlp significantly increase hence algorithm implement hebe thread exponentially increase perform local candidate significant increase NBTI iteration phase behavior NBTI normalize ideal exhaustive algorithm convergence iteration thread hebe converge thread image KB image behavior NBTI parallel FT NAS benchmark NBTI normalize exhaustive reduce impact NBTI processor besides hebe previously approach omp regular omp dynamic TA omp exhaustive thread throttle target performance delay EDP cannot simply optimize NBTI depicts NBTI achieve hebe obtain varuna PM FDT hebe strategy regardless multicore geometric entire benchmark processor hebe deliver NBTI varuna PM FDT behavior approach image KB image hebe versus varuna PM FDT hebe hebe versus varuna PM varuna developed application data recursively implement creates thread execute application thread NB benchmark scalability limited data synchronization thread thread synchronize increase execution processor important emphasize achieve varuna PM improvement analytic manager nevertheless component varuna PM improve performance offs performance processor hebe hebe versus FDT FDT ignores fundamental hardware characteristic correlate parallel application behavior assumes bandwidth requirement increase linearly thread ignore cache contention data thread moreover FDT smt FDT converges non ideal thread performance purpose moreover training phase executes parallel thread overhead application medium tlp FT NAS CG NAS however FDT hebe application scalability issue FDT handle fft chip bus saturation algorithm hebe optimize performance metric EDP delay tlp exploitation delivers execution EDP necessarily reduces benchmark processor hebe optimizes NBTI baseline hebe reduces impact NBTI version tune performance EDP image KB image hebe optimize NBTI baseline versus hebe optimize performance EDP benchmark hebe summarize evaluation perform develop approach specifically target reduction impact NBTI processor overall geometric benchmark processor NBTI hebe varuna PM FDT hebe perf hebe execution hebe optimize EDP related split technique reduce approach thread throttle target hebe advance correlate reduce microarchitecture DVFS   aware technique allocation register file RFs GPGPUs uniformly distribute throughout aim reduce hardware propose distribute calibrate model predictive controller performs thermal management chip multicore architecture model improve ideal cpu operating frequency reduce operating   explore gate technique reduce hardware network chip buffer data driven controller constrain extremum seek algorithm optimize resource allocation specific thermal constraint propose DVFS policy maximize performance peak constraint aware DVFS technique exploit available slack reduce frequency processor   propose DVFS technique cpu frequency voltage guarantee task completion within deadline thermal constraint satisfied processor predictor cpu frequency efficiently frequency reduce recently propose DVFS boost technique reduce induced compiler propose static thermal management technique compiler reduce register file instruction VLIW architecture yang  compiler register shuffle strategy attain density exploit extant spatial slack associate register file access thermal aware compilation chip architecture reduce hotspot uniformly distribute register file considerable execution application spent execute nop operation instruction propose software hardware optimize nop instruction assignment minimize NBTI processor thermal stress variation across hardware component propose  aware compiler register assignment approach aim distribute stress induced  throughout register file VLIW reallocation strategy reduce gpgpu architecture distribute stress instruction throughout VLIW slot model enhance data cache memory propose compiler optimization mitigate cache SRAM memory schedule developed aim reduce hardware component MPSoCs architecture proactive MPSoC thermal management technique predicts processor adjusts task allocation minimize impact thermal hotspot variation propose thermal balance policy exploit task migration maintain core within predefined MPSoCs architecture assign schedule task MPSoC architecture reduce processor multi core architecture propose approach performs thread migration multiprocessor core migrate thread away overheat core non core propose workload allocation strategy reduce processor openmp application distribute task migration thermal management core task distribute processor accord dissipation capability   explore impact instruction allocation strategy processor spatiotemporal multiplexing exploit thermal capacity redistribute location active core core propose adaptive task allocation strategy exploit runtime information variability core increase processor lifetime DTM technique migrate task balance core reduce processor chip thread throttle approach capable adapt thread optimize parallel application target propose FDT framework adapt thread contention lock memory bandwidth thread tailor dynamically adjusts thread optimize specific cache memory footprint propose library performance loss hybrid mpi openmp application thread  consists framework executes application binary multiple thread ideal configuration application execute configuration propose  dynamic monitor application executes adapt tlp accordingly  framework comprises compiler applies multiple parallelize transforms sequential code monitor application execution tlp optimize performance parallel application varuna monitor intercept thread task creation pthreads TBB prometheus library pool task optimize parallelism propose extension management openmp application thermal aware approach openmp application programmer insert code annotation sequential parallel code enable minimization although aim distribute core focus mitigation processor aurora built openmp library transparently optimize performance EDP openmp application contribution strategy rtl DVFS compiler propose minimize NBTI  processor reduce processor none adaptation tlp exploitation target approach aim reduce processor parallel distribute application task thread schedule core tune thread therefore hebe orthogonal reduce strategy perform adaptation tlp exploitation hebe built specifically optimize processor lifetime transparent user source binary code totally automatic adapt workload execution programmer enable hebe environment variable linux OS however transparency hebe limited openmp application conclude remark manuscript hebe approach openmp application reduces impact NBTI processor tlp performance processor hebe optimizes openmp application binary environment variable linux OS without code transformation recompilation extensive hebe reduce impact NBTI increase processor lifetime negligible overhead future enhance hebe execution parallel application heterogeneous platform program model