information centric networking ICN cache strategy improve network performance consumer demand intermediate router reduces load content server network traffic improves delay content requester packet data express packet rout efficiently delay throughput network improve describes efficient packet retrieve request content data source player content requester location desire content goal monte carlo MCTS algorithm construct content requester concerned data source performance evaluation propose scheme integrate lcd everywhere LCE cache clm probability cache ProbCache simulation environment  evaluate content latency server ratio network load overhead throughput simulation observation reveals integration MCTS significantly improves performance regard experimental parameter previous keywords information centric network ICN content centric network CCN rout MCTS introduction future networking demand access delay throughput user interested obtain desire content securely without bother service provider challenge situation information centric networking ICN propose address demand future user ICN reduces network traffic content delivery latency deliver content data data network instead rely data producer suggests unique content consumer data chunk hence node content request requester architecture define ICN architecture translate relay internet architecture integrate active directory data orient network architecture network information data network along unique content cache data intermediate router rout content importance ICN cache rout content IP address identify convention node content router CR network content satisfy content request various consumer described ndn architecture consumer generates packet desire data content packet content rout ICN involves activity packet content data chunk requester packet CR maintains information fib shortest ndn  data link rout  focus building rout information fib however protocol aim packet cache efficiently without bother fib creation although overlay protocol category significant impact content minimum overhead focus efficient packet mechanism protocol explore preparation fib hence overlay rout technique contribution propose improve packet technique faster content retrieval ICN monte carlo MCTS algorithm closest source cache content mathematical model propose scheme interpretation justification detailed analysis propose scheme comparative performance evaluation simulation  demonstrate packet direction content cache retrieve data shorter delay minimize overhead task CR desire content treat consumer cached location goal MCTS proven efficient approach goal player CR request content resemblance player moreover MCTS exist knowledge content algorithm approach hence  performance model content player goal content cache location MCTS algorithm novelty MCTS extend ICN rout knowledge related ICN rout mechanism mostly extend shortest ospf link rout LSR algorithm integrate content centric network paradigm available rout mechanism  propose lan attempt rout ICN rout author extend ospf disseminate prefix compute content deployed ndn testbed demonstrate functionality multipath rout data link rout protocol  propose   variation LSR protocol ndn differs IP interpretation hierarchical implement trust model security difference  protocol rout update finally integrates multipath rout deployed testbed ndn  propose rout protocol hyperbolic rout HR greedy approach content packet coordinate content location coordinate node packet shortest coordinate destination content tricky actual producer however ICN focus content cache producer described  scalable rout address scheme incorporate address geographic coordinate node account propose approach efficiently accomplishes operation ICN deployed overlay network protocol relies underlie tcp IP however assumption fib adjacency node impractical network topology cannot arbitrary internet topology implement scheme  characteristic rout ICN focus duration likelihood content specific content request location characteristic author exist rout strategy dijkstra shortest algorithm efficient rout however probability content availability characteristic challenge task unless optimally protocol cache generate massive overhead advent machine ML DL researcher integrate model various ICN activity applicability convolutional neural network cnn recurrent neural network rnn reinforcement RL ICN content popularity prediction  propose predict content popularity creates distribute reconfigurable DL network sdn switch prediction network DQN lean adopt cache author sdn iot application deployment protocol effectiveness propose verify simulation  framework content cache ICN described rnn model boost cache performance memory lstm encode approach research explore rout mostly integrate AI model cache hence necessity examine technique rout ICN despite paramount concern efficient packet investigate efficient selection content significantly improves content access network overhead emphasizes packet nearby content cache DL technique integrate efficiency tremendously motivates research DL technique integrate MCTS algorithm apply closest content packet MCTS construct content requester concerned data source due MCTS exist knowledge content algorithm approach another MCTS backpropagation compute critical parameter average scope CR content cache server ratio occurrence cache moreover algorithm satisfaction threshold dynamically update apriori knowledge knowledge built reflect status network propose methodology research address cache request content ICN model player content requester content goal MCTS player MCTS construct content requester concerned data model model network graph denote vertex CR node link CR outgo interface collectively denote consumer network demand unique content consumer request data source consumer source producer data cache maintain CR primary goal packet CR incurs minimum data retrieval hop request content moreover packet content purge due hence content consideration selection assume CRs cache data characterize various parameter load cache queue incoming interface parameter CR data source CRs identical content monte carlo mechanism CRs model action CR consumer initiate consumer hence consumer node initial model denote node outgo interface packet action action corresponds node corresponds action node leaf node defines action policy parameter significance model signifies quality decision parameter indicates decision calculate tradeoff communication server ratio server ratio define later parameter signifies association CR predict utilization balance choice lower reward data source overuse CR serf content packet action reward amount reward sum reward leaf node detailed procedure algorithm algorithm MCTS input action output target CR request content construct consumer data generates packet action perform transition action till data packet server producer data computational budget decides node action selection strategy although selection strategy exist MCTS player upper confidence bound CR request content resemblance player formulation objective function context ICN server data request consumer available intermediate CRs content request actual producer data server desirable increase network load delay objective function model server minimize server primary concern objective function parameter computation moreover statement valid applicable model objective function parameter objective function minimize server define ratio server content request network satisfactory realization constraint impose constraint ensures content request multiple assume constraint associate signifies  candidate link data goal constraint subsection player monte carlo MCTS algorithm described parameter devise objective function  outgo interface candidate interface content request request server  request content data request consumer data request consumer network outgo interface request data candidate data cache producer packet data source producer CR consumer data player monte carlo MCTS algorithm algorithm comprises content requester content source content goal halt explain selection favorable essential characteristic content load link load node node node load information acquire information interchange exploitation exploration promising  unexplored node examine explore possibility content available uniformly distribute random quasi random selection heuristic knowledge acquire node approach maximum content expansion till node building appropriately expansion decides node expands goal depict approach per expansion adopt approach suggests node encounter expansion backpropagation update parameter average scope server ratio backpropagation propagate  average  backpropagation execute satisfaction threshold previous knowledge awareness define initiation expansion desire data mention expansion average node suppose node chosen formula maximize confidence bound node achieve node constant account previous knowledge acquire CR content knowledge built reflect status network hence approximation content location probability route performance analysis simulation performance LCE lcd clm ProbCache without integration  algorithm request content CR along delivery lcd suggests cache content replicate cache hop downstream CR requester report clm cache introduces betweenness centrality node cache content emphasizes minimize cache content avoid cache content accessible consumer cached CR betweenness centrality ProbCache cache mechanism probability retrieval request considers cache capacity estimate traffic per calculate desire probability content request data popularity protocol suggests cache popular content intermediate code unlike LCE clm cache content subset CRs along delivery  approximates cache content probability future access analysis aim examine efficiently MCTS algorithm route packet appropriate cache performance evaluate without integrate MCTS protocol setup propose cache protocol simulated ndn simulator  default  implement LCE lru cache replacement policy respectively unique content content byte model described earlier content request zipf distribution skewness parameter cache empty capacity average chunk simulation execute application simulation simulation topology random topology node another topology network CRs depict network simulation topology interpret observation testbed environment simulation aim various performance parameter without propose MCTS player model content request obey poisson distribution arrival rate request per lifetime exponentially distribute traffic load express parameter accordingly discussion individual content cst cst indicates quickly content deliver requester cst desirable content centric network parameter random topology random topology cst random topology cache popularity skewness respectively parameter decrease increase cache skewness algorithm integration MCTS outperforms without MCTS examination cache reduction latency lcd LCE clm ProbCache MCTS integration version observation latency skewness demonstrates improvement lcd around LCE clm ProbCache topology cst cache skewness topology respectively increase cache skewness decrease MCTS integrate lcd LCE reduction lcd LCE around clm ProbCache LCE MCTS performance lcd clm ProbCache perform moreover function clm MCTS LCE MCTS image KB image content analysis cache random topology comprises node cache varies content per cache content capacity content accommodate cache image KB image content analysis popularity random topology comprises node cache content per cache content analysis cst observation MCTS integrate version LCE clm latency content LCE content densely MCTS goal closer code moreover superior performance MCTS pre prepared location content information acquire node construct locally content consequence content lesser MCTS approach option explore alternate failure due  content location construct node lookup desire content image KB image content analysis cache topology node content capacity content accommodate cache image KB image content analysis popularity topology node content cache chunk content node random topology server ratio shr shr define rate access content user request ICN emphasizes user request intermediate cache access content producer hence minimum shr desirable ICN underlie packet approach rightly packet user request server content available cache subsection shr plot random topology simulation content request arrival rate graph depict shr decrease protocol progress simulation however relative decrease protocol MCTS integration lcd MCTS shr decrease lcd without  similarly decrease LCE MCTS around max LCE without MCTS similarly clm ProbCache improvement around shr content request arrival rate random topology shr increase increase content request arrival rate relatively LCE MCTS performance shr specifically LCE MCTS improvement LCE lcd MCTS lcd without integration MCTS clm performs LCE ProbCache comparatively LCE clm image KB image server simulation within duration simulated content cache chunk content node deployed random topology skewness parameter image KB image server content request within duration simulated content cache chunk content node deployed random topology skewness parameter analysis shr content request server content available intermediate router packet correctly appropriate cache cache algorithm packet underlie network cache cache approach integration MCTS appropriate cache request content hence MCTS integrate version performs counterpart network load traversal data packet chunk network load evaluation amount data propagate network information plot simulation depict simulation increase load network decrease simulation cache empty hence data mostly deliver producer data network load however progress simulation cache content hence content request intermediate CRs significantly reduces distance traverse data packet subsequently network load content cached load decrease due intermediate availability content protocol wise ProbCache lcd comparatively load clm LCE MCTS version nearly elapse simulation protocol MCTS considerable improvement protocol without integration propose technique perform load graph network overhead compute load network due cache destination CR MCTS algorithm percentage load increase content request network overhead computation distance traverse packet propagation packet unsuccessful acquire data request cache impose extra load network traverse till content router content load due content replacement plot graph increase content request percentage increase overhead respect without cache plot graph plot MCTS integrate version protocol observation mixed behavior protocol around request clm performance lcd request arrival LCE ProbCache moderate performance comparison increase request rate behavior alters request rate LCE behavior performance LCE due dense cache content network ProbCache probability estimation hence cache occurs overhead network throughput throughput ratio content request  intermediate CRs parameter examine content request arrival rate MCTS integrate version parameter throughput decrease increase content request LCE whereas lcd depicts performance clm throughput around request arrival rate request rate performance around approximately contrary  performance arrival rate rate increase request rate cache occurs ProbCache protocol LCE content almost everywhere lcd minimum clm content node centrality betweenness cache occurs conclusion selection approach packet objective retrieve request content output MCTS algorithm execute CRs network assist closest destination cache reliable scheme assume implement content identification scheme heuristic knowledge previous status network component simulation random topology node network topology node   protocol LCE lcd ProbCache clm implement integrate MCTS algorithm performance without integration MCTS examine parameter content latency server ratio network load overhead observation MCTS integrate version protocol outperforms variation