sparse matrix vector multiplication spmv topic research scientific compute data processing sparsity discontinuity nonzero sparse matrix memory bottleneck spmv propose align csr ACSR align ell AELL format parallel spmv algorithm utilize neon simd register processor analyze impact simd instruction latency cache access cache spmv format spmv algorithm ACSR achieves speedup spmv csr spmv  respectively AELL achieves speedup ell deviation theoretical experimental instruction latency cache access ACSR AELL respectively keywords neon simd spmv storage format introduction motivation sparse matrix vector multiplication spmv core subroutine numerical computation linear equation application usually access iterative spmv linear equation perform however complexity associate hardware load imbalance sparsity sparse matrix memory bottleneck challenge optimize spmv performance spmv computes fix sparse matrix iterative improve utilization processor calculate spmv zero ignore calculation therefore sparse matrix storage format deliver reflect distribution characteristic nonzero sparse matrix format suitable structural characteristic compute platform although researcher perform spmv aim multicore platform accelerator address processor spmv armv architecture performance compute introduce increase researcher drawn armv architecture instruction improve precision float arithmetic capability instruction multiple data simd operation via neon simd instruction extension architecture addition advent intelligent era processor widely mobile device consumption performance moreover global supercomputer release november  core  soc armv retains title processor contribution propose align storage format ACSR AELL suitable neon precision calculation processor parallel spmv algorithm ACSR AELL format evaluate performance ACSR AELL format csr ell format  kunpeng processor align compress storage format improve performance spmv neon armv platform acceleration spmv ACSR AELL csr ell obtain theoretical analysis experimental verification align storage format ACSR AELL csr ell format align simd register processor demonstrate parallel algorithm spmv neon acceleration conduct performance analysis impact align format format difference execution latency simd instruction cache access cache fourth sparse matrix SuiteSparse matrix collection practical application scenario moreover examine calculation performance spmv csr ell neon spmv ACSR AELL neon accelerate spmv csr ell spmv  finally analyze experimental performance analysis matrix average performance improvement neon accelerate spmv csr ell neon ell AELL achieves average performance improvement estimate cache access cache precision respectively ACSR csr addition average acceleration spmv ACSR spmv  ACSR AELL storage format neon simd operation processor related compress storage format sparse matrix enhance performance operation zero sparse matrix reduce therefore sparse matrix compress nonzero coordinate coo format compress sparse csc csr although format widely adaptable sparse matrix therefore storage format specific sparse matrix introduce diagonal dia format nonzero sparse matrix diagonally ellpack ell format suitable matrix relatively uniform nonzero storage format aim hardware feature specific processor maximize performance hybrid ell coo hyb slice ellpack compress sparse csr format mixed csr ell  format massive parallel compute feature gpu simd device cpu nevertheless sparse matrix obtain practical application increasingly preclude obtain immediately consequence matrix partition become valuable approach ensures efficiently calculate immediately performance storage format compress sparse  exploit computational performance dense  sparse matrix subsequently optimize  format unaligned compress sparse  format developed performance dense  addition explore substructure sparse matrix compress sparse extend  storage format propose compress index array armv architecture mobile device equip core price performance consumption debut armv architecture become research consumption performance compute moreover previous architecture armv benefit increase precision simd operation compelling worldwide purchase armv license developed core united  qualcomm japanese  chinese huawei  etc already release server chip armv architecture furthermore supercomputer equip processor  core  soc  image KB image armv architecture sparse matrix compression neon technology introduce format csr ell align format algorithm deliver performance neon processor brief illustration neon storage format sparse matrix storage format visually assume sparse matrix define parameter namely nonzero sparse matrix compress sparse csr csr commonly storage format sensitive characteristic matrix format nonzero information sparse matrix index nonzero therefore csr format employ array nonzero correspond index nonzero another array index therefore sparse matrix csr addition memory csr format precision ellpack ell ell format sparse matrix compress dense matrix nonzero correspond index assume maximum nonzero sparse matrix dense matrix moreover vacant zero dense matrix sparse matrix ell ell memory precision neon technology extend architecture neon simd operation armv neon simd vector register multiple data precision float precision moreover neon simd register allows user data efficiently minimize memory access image KB image neon simd register neon accelerate spmv vector load neon simd register another discontinuity index csr ell format contrast apply ACSR AELL format spmv simd register immediately sparse matrix dense vector 2D 2D 2D simd register 2D register vector suppose sparse matrix vector spmv therefore vector assign component sequentially scalar subsequently simd operator simultaneously calculates multiplication register 2D image KB image precision float simd operation align compress storage format simd vector calculation consecutive usually immediately load vector register vector however spmv distribution nonzero discontinuous constituent correspond vector load vector register sequentially increase load vector register efficiency simd degradation therefore improve utilization simd align compress storage format ACSR AELL sparse matrix advanced simd architecture compression sparse matrix index adjacent nonzero adjacent correspond vector nonzero adjacent calculate spmv index nonzero adjacent correspond vector adjacent distance nonadjacent exceeds width cache impossible load vector register deviation index cache insert zero nonzero zero insert nonzero guarantee operation redundant cache access permit matrix ACSR AELL storage format align csr ACSR vector zero index vector index assume zero rate FR ACSR storage sparse matrix compress ACSR format accord calculation formula occupation conclude ACSR format csr align ell AELL ell AELL matrix vector vector index vector vector matrix AELL occupy AELL image KB image AELL format equally AELL format occupy parallel algorithm spmv neon intrinsics achieve neon acceleration function operation instruction indicates vector register neon simd operation precision float operation  float  vector  initialize vector  lane lane vector register  vector register  temp execute vector operation temp  lane temp component vector temp performance analysis although ACSR AELL format zero csr ell format increase amount calculation improve efficiency memory access load vector vector register therefore rate performance spmv fluctuation analyze execution latency neon simd instruction impact cache access cache spmv compress storage format spmv performance analysis armv architecture perform performance analysis variable variable analyze   computation spmv  execution instruction  data access  register fetch instruction latency  calculation instruction latency  cache access  latency cache access  cache  latency memory access compute program compute depends mainly instruction amount data access spmv computation instruction nonzero sparse matrix amount data access related storage format sparse matrix access vector however storage format proportion zero additional auxiliary data storage data access therefore actual performance parallel program related calculation program processor instruction execution cycle parallel execution instruction utilization efficiency cache data writes memory data bandwidth utilization utilization rate compute core processor etc reduce execution cycle instruction instruction execution cycle chosen addition distribute instruction compute core parallel execution improve data amount instruction pipeline simd performance spmv serial operation armv processor described instruction execution data access respectively performance program positively correlate instruction data access function increase function instruction instruction latency processor program execution latency mainly latency register load calculator operation armv processor register load data load register vector load vector register calculation instruction calculation instruction vector calculation instruction execution latency calculate latency register load vector register load calculation instruction vector calculation instruction respectively mainly addition multiplication spmv operating instruction related nonzero sparse matrix multiplication addition respectively therefore instruction spmv operation accord sparse matrix however calculation reduce instruction execution delay instruction simultaneously cycle compute instruction armv processor instruction pipelining simd technology improve concurrent operation multiple instruction improvement throughput instruction execution vector arithmetic byte float byte float calculate vector operation equivalent spmv requirement calculate multiplication perform vector multiplication data access limited cache data instruction execution memory access cache calculate access cache delay cache access cache delay memory access respectively processor latency access cache memory fix therefore improve performance data access program reduce cache access cache rate latency instruction spmv  ldr  lane LD  LD  temp fmla execution latency instruction accord execution latency described official document minimum latency obtain analyze operation dependent instruction described analyze difference  instruction latency spmv ACSR AELL format csr ell format latency instruction index nonzero load normal register ldr vector load vector register LD function  lane  vector vector evaluate fmla function  evaluates addition fmla bracket indicates calculation apply cycle calculation spmv precision index nonzero load normal register perform address instruction obtain correspond vector therefore execute ldr instruction moreover csr format nonzero load vector LD instruction vector register load nonzero however vector load sequentially nonzero load vector register continuous discontinuity correspond vector therefore LD instruction load vector register sequentially nonzero sparse matrix correspond vector multiplication correspond vector fmla instruction therefore fmla instruction spmv  cortex processor computer accord ACSR format zero alignment operation therefore execute ldr instruction however ACSR format nonzero load vector register continuous correspond load vector register correspond vector continuous therefore LD instruction ACSR format armv pipeline  vector calculate calculation instruction fmla instruction spmv latency instruction ACSR sparse matrix dense matrix ell format dense matrix index nonzero therefore ldr instruction load index register LD instruction load matrix vector register however vector load sequentially nonzero load vector register continuously discontinuity correspond vector therefore LD instruction load vector register sequentially finally fmla instruction spmv csr format armv pipeline  execution latency fmla AELL format ldr instruction load index register due alignment operation nonzero load vector register continuous therefore data load vector register LD instruction load matrix correspond load vector register correspond vector continuous therefore LD instruction AELL format finally fmla instruction spmv ell format obtain latency  instruction spmv format formula analyze performance spmv operation storage format obtain proposition proposition ACSR cycle spent spmv ACSR format csr format proof increase zero padding amount redundant data vector register increase increase LD fmla instruction FR ratio zero cycle operation instruction spmv csr ACSR format respectively upper bound FR obtain calculates difference performance spmv ACSR format spmv csr format FR proposition AELL cycle spent spmv AELL format ell format proof storage sparse matrix ell format depends nonzero increase zero pad redundant data vector register increase increase LD fmla instruction width zero padding cycle operation instruction spmv ell AELL format respectively upper bound obtain calculates difference performance spmv AELL format spmv ell format formula obtain trend cycle zero rate spmv calculation ACSR AELL cache access csr ACSR spmv format access offset nonzero correspond calculation nonzero access vector csr ACSR respectively index ordinary access however access vector fundamentally load mode vector register access csr ACSR access consecutively align data vector register finally vector obtain cache access spmv ell format matrix access vector index matrix vector vector access sequentially therefore access cache spmv ell format calculate however spmv AELL format matrix index matrix vector therefore access cache spmv AELL format obtain ratio reduction cache access ACSR AELL format csr ell format respectively formula analyze cache access spmv operation storage format obtain proposition proposition ACSR cache access spmv ACSR format csr format proof increase zero padding although access nonzero vector continuously ACSR format csr format FR ratio zero equation reduction cache access ACSR csr performance spmv ACSR format spmv csr format upper bound FR obtain proposition AELL cache access spmv AELL format ell format proof cache access data access mode AELL matrix ell cache access however index matrix decrease load continuous width zero padding cache access spmv AELL format spmv ell format accord equation upper bound accord formula trend cache access zero rate spmv calculation ACSR AELL cache described previous spmv neon acceleration vector calculation instruction access cache nonzero spmv csr ell format nonzero vector twice index vector however ACSR AELL format access vector twice index index vector calculation load csr ell distribute cache cache ACSR AELL kunpeng cache cache therefore calculation csr ell format cache conflict replace access cache ACSR AELL format infer spmv csr ell ACSR AELL format reduce probability cache conflict decrease cache  platform kunpeng huawei kunpeng multiple parallel instruction armv architecture equip float FPUs peak performance kunpeng precision float computation achieves gflops moreover kunpeng channel memory channel environment   frequency ghz core cache cache private per core cache MB memory ddr  linux kernel   core examine performance nonuniform memory access numa architecture kunpeng failure numa  access memory due OS switch delay moreover experimental inaccurate therefore obtain stable reliable bind thread data numa  guarantee thread access memory fix node moreover perf linux obtain cycle cache reference cache calculation although algorithm algorithm spmv algorithm neon simd acceleration thread suitable multi thread parallelism experimental procedure implement openmp  option non zero ACSR format uniform operating schedule thread ensure load balance openmp automatic parallelism impact easy predict performance evaluation thread performance optimal comparison sparse matrix thread execute significantly reduces impact multi thread performance evaluation data sparse matrix SuiteSparse matrix collection application sparse matrix nnz nonzero sparse matrix threshold ell respectively sparse matrix sparse   cavity chebyshev   fem 3D thermal     model    rosen TSOPF RS  tank  experimental experimental acceleration spmv csr ell format neon analysis experimental data performance comparison ACSR AELL csr ell  neon acceleration csr ell performance improvement spmv csr ell format neon ordinate relative performance improvement neon image KB image performance improvement neon csr ell format interpretation reader refer web version article performance spmv neon achieve improvement csr ell respectively however sparse matrix neon acceleration obvious combine instruction delay nonzero sparse matrix infer access vector continuous access decrease instruction delay increase neon operation instruction increase amount data excessively memory access instruction delay reduce performance spmv  fem 3D thermal ell TSOPF RS csr ell moreover spmv csr ell neon cache extra cache access spmv csr ell accelerate neon analysis experimental data obtain cycle cache reference cache spmv format perf performance profile ratio zero ACSR AELL csr ell reduction execution latency simd instruction experimental consistent theoretical analysis accord reduce cycle average ACSR csr AELL ell however average difference ACSR AELL theoretical experimental analyze instruction actual implementation directly encapsulate neon function simd technology unknown instruction therefore rate ACSR theoretically approximately adverse arises matrix rate    moreover due load unbalance OS schedule thread additional overhead parallel spmv calculation ACSR format distribution nonzero TSOPF RS scatter increase memory access ACSR AELL parallel spmv calculation matrix csr format performance depends maximum non zero although instruction cycle serial calculation theoretically increase csr format theory parallel calculation zero rate ACSR format zero chebyshev   average non zero zero rate almost zero therefore experimental sparse matrix disagreed theoretical analysis cache improvement cache access reduce ACSR AELL format respectively csr ell deviation theoretical actual ACSR AELL although impact cache access ACSR AELL format consistent theoretical analysis deviation experimental matrix ACSR analyze distribution nonzero matrix AELL deviation unbalanced load calculation  TSOPF RS addition ACSR AELL format reduce cache conflict calculation ACSR AELL reduce cache spmv respectively ACSR AELL format reduce probability cache conflict calculation zero previous nonzero usually remain cache however vector across cache due cache conflict therefore sparse matrix relatively concentrate distribution nonzero zero AELL format extra cache  diagonal sparse matrix nonzero diagonal therefore nonzero across cache extra zero cache performance ACSR AELL calculation spmv ACSR AELL format csr ell accelerate neon ACSR format performance improvement spmv ACSR spmv csr format  comparison AELL ell kunpeng processor experimental FT processor verify performance improvement align storage format image KB image performance improvement ACSR AELL kunpeng processor image KB image performance improvement ACSR AELL FT processor experimental consistent analysis spmv ACSR AELL format achieve performance csr ell format csr  ACSR achieve average performance improvement AELL achieves average performance improvement ell kunpeng processor average performance improvement FT processor however sparse matrix diagonal matrix local continuity rate ACSR calculation spmv ACSR almost improvement instruction latency cache access cache spmv csr conclusion propose align storage format ACSR AELL focus simd operator parallel optimize spmv precision processor analyze improvement ACSR AELL format instruction delay cache access cache deviation experimental execution latency instruction cache reference respectively moreover experimental spmv ACSR achieve average improvement executive latency instruction cache reference cache calculation respectively spmv csr format correspond AELL parameter ell addition  comparison spmv ACSR exhibit performance improvement  future instruction  cache performance performance analytical model spmv processor predict accurately achieve performance optimization credit authorship contribution statement  zhang conceptualization investigation methodology software validation draft  yang conceptualization methodology project administration resource draft  supervision  tang software validation  review edit