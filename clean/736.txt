analyze performance distribute computation heterogeneous hierarchical memory memory hierarchy efficiency core memory load computation external storage expensive avoid processing load external memory load distribute worker processor multiple installment minimum mixed integer linear program limit schedule heuristic variant examine criterion processing feature optimum analyze machine diverse mode limited core memory beneficial performance propose schedule algorithm evaluate quality runtimes keywords performance model prediction aware storage hierarchy divisible load theory introduction consumption limitation data supercomputing installation performance arises processing divisible load heterogeneous hierarchical memory divisible load data parallel application arbitrary independently parallel divisible load theory DLT analyze distribute computation cluster workstation chain intelligent sensor DLT analyze performance distribute application operating data volume contemporary computer hierarchical memory organization cpu register hierarchy shortest access limited memory hierarchy processor cache memory convention refer ram memory hierarchy external networked storage distribute memory cache SSDs HDDs NAS tape optical medium etc usually manage software stack memory hierarchy available storage grows access increase computer impose strict limitation confine computation memory spill code data structure memory virtual memory networked cache etc however significant difference performance external storage magnitude ram storage software stack efficient conversely prudent usage external memory beneficial avoid excessive communication machine external networked storage usually manage software memory hardware assume hierarchical memory reduce hierarchy memory core alternatively memory comprise register cache ram core memory comprise external storage DLT load scatter installment approach worker processor receives load disadvantage installment load chunk tend delay computation increase core memory therefore multi installment load scatter processor chunk load consequently computation earlier momentary memory footprint hence assume multi installment processing attain economy performance computation complex challenge efficient CPUs reduce consumption exploit heterogeneity alternative schedule strategy arises user faster computation vice versa contribution summarize multi installment distribution load heterogeneous hierarchical memory explicitly omit memory limitation computation model hierarchical memory experimental data computation schedule optimality mixed integer linear program mip optimization analyze complicate landscape demonstrate interaction machine parameter intricate machine efficient core memory machine analyze deeper shallower machine suspension mode optimum schedule computationally obtain heuristic propose alternative mip heuristic evaluate runtime quality organization review related model performance specific hierarchical memory introduce related schedule formulate algorithm propose performance heterogeneous optimum feature  analyze dedicate evaluation propose algorithm summarizes notation related efficiency parallel processing intensively wealth exists survey attain efficiency attack mutually exclusive abstraction hardware compute platform algorithm runtime environment schedule management data assume application schedule runtime environment cooperation compute platform hint platform maintain active machine mode algorithm runtime environment heterogeneous compute platform already mention application data parallel divisible load theory DLT performance schedule model introduction DLT review application divisible load processing genetic algorithm apply processor installment communication heterogeneous submission assume multi installment load scatter moreover account impact hierarchical memory multi installment scatter load heterogeneous processor heuristic propose assume sequence communication machine repetitive sequence communication sequence repetitive processing divisible load non linear complexity algorithm demonstrate classic DLT approach load  non linear complexity algorithm unless clever data partition apply achieve demonstrate vector outer matrix multiplication slightly nonlinear execution memory hierarchy data processing algorithm consequently load partition algorithm sufficient DLT application assign measurement workload wireless sensor network residual battery workload partition longer lifetime network schedule monetary minimize heuristic propose installment polynomial algorithm propose communication computation proportional load communication link publication non hierarchical memory model heuristic propose communication proportional load hierarchical memory analyze respect performance processing divisible load homogeneous memory interrelation parameter consumption submission extends divisible load processing homogeneous installment load scatter submission differs heterogeneous multi installment load scatter propose heuristic heterogeneous impact heterogeneity performance analyze runtime quality exist propose algorithm NP performance model computation load chunk chunk important determinant memory verify relationship compute consume load chunk computational conduct platform application image detection quicksort text report upon dependence compute load dash linear regression data vertical logarithmic hence coordinate linear function verify runtime consumption increase significantly faster core memory interestingly usually consumption core computation core however hence overall consumption increase faster switch dependence hardware ram memory reserve operating runtime environment image KB image dependence load detection quicksort logarithmic vertical continuous linear regression dependence compute consume chunk piecewise linear function processing load machine component corresponds computation core rate reciprocal component core computation function memory machine available application necessarily hardware ram beyond machine core memory consume computation analogous function satisfy memory satisfy core processing increase faster core machine coefficient obtain linear regression interval load obtain measurement calculate via available ram formula coefficient machine application function parameter machine application MB MB MB MB pentium IV ghz GB ram mhz hdd caviar WD freebsd image detection ghz GB ram ghz ubuntu lts   quicksort amd ghz GB ram ghz ubuntu lts   formulation assume computation perform server originator worker machine computer processor leaf machine idle consume networking load compute load communication computation proceed accord scheme volume load originator networking machine idle processing load role schedule computation load chunk chosen processor capable processing load parallel communication capability additional worker processor activates machine machine machine computer consume idle idle ignore unless completely disconnect network idle machine contribute owner originator activates machine completion operation coincides load duration wake signal negligible machine perform parallel machine communicate installment load chunk communication interchangeably transfer load fix overhead communication startup communication rate per byte communication machine communication networking interval communication consume interconnect router interconnect software computation entire load chunk load distribute multi installment manner processor load chunk sends load worker processor load distribute sequentially sequence communication index machine load communication communication computation load chunk machine respectively assume return schedule hence return operation explicitly schedule return tackle DLT processing load chunk machine another load chunk  equivalent networking consumes image KB image multi installment schedule denotes chunk machine worker processor schedule algorithm subset machine participate computation sequence load distribution communication worker machine load chunk minimum effectively  multiple criterion handle various deliver relationship minimize criterion constrain criterion schedule schedule model exist approach assume memory limit instance infeasible border core core memory cannot  insert model feasible exists albeit possibly performance apply DLT approach assume compute proportional assign load unfortunately model reality hierarchical memory disparity approach consume computation accord proportional model calculate accord parameter formula calculate conclude earlier exist approach cannot easily adjust situation significantly inconsistent reality difference hierarchical memory proportional model MB MB MB MB MB MB MB MB MB mip notation variable amount load communication sum consume consume originator consume idle processor later consume machine computation load chunk consume networking consume computation consume processor machine machine variable communication duration computation load chunk machine binary variable binary variable machine receives load communication otherwise binary variable machine load earlier communication otherwise constant parameter machine piecewise linear compute function communication rate machine inverse bandwidth parameter machine piecewise linear function available machine communication fix communication overhead machine idle machine networking machine machine startup idle machine schedule load constant introduce strategy load distribution firstly introduce heuristic distribute load iteratively sequence communication regulate load chunk accord secondly construct optimum multi installment schedule sequence communication load chunk mixed integer linear program mip mip optimal core core memory heuristic avoid core memory heuristic heuristic algorithm define processor sort load chunk algorithm beyond component mode operation processor idle originator idle machine sends load chunk processor activate exhaust idle machine request load processor originator sends load chunk processor processor already load chunk processor originator rank online processor accord sends load chunk processor topmost consequently processor prefer load chunk earlier processor idle processor processor compute originator communicate procedure exhaust load processor sort PSR processor priority processor accord non decrease non decrease non decrease non decrease non decrease non decrease non decrease non decrease PI non decrease PN non decrease PS non decrease non decrease ram non increase rnd processor randomly rnd introduce reference verify utility introduce load chunk algorithm static chunk ssc algorithm assumes load chunk available ram machine ssc avoids core memory disadvantage ssc lack load balance stage computation precaution uneven computation completion processor slowest processor load chunk processor already computation consequently schedule processor idle processor strive unnecessarily load chunk split chunk idle processor however predict processor iteration algorithm online heterogeneous schedule adaptation GSS algorithm extends loop schedule algorithm homogeneous load remain distribute processor load chunk chunk calculate refer remain load load chunk decrease schedule assume initial load memory algorithm load chunk ram GSS gradually decrease chunk  machine completion decrease tends zero GSS excessive load chunk therefore GSS chunk fix convention denote equation data structure sufficiently amortizes fix overhead processing load chunk consideration assume MB computational complexity heuristic ssc GSS respectively upper bound load chunk ssc GSS respectively PSR component apply processor priority queue enforce PSR complexity algorithm depends apply heuristic refer super ssc super GSS text checked mode simulation demonstrate combine lightweight improve quality super ssc super GSS purpose evaluate potential quality improvement resides proceed technical calculation cannot analytical heterogeneous posteriori schedule obtain simulation runtime schedule consume consume originator consume initial idle consume machine consume processing assign load consume networking originator communicate idle wake machine computation consume machine participate computation consume computation calculate communication computation hence machine mixed integer linear program formulate mixed integer linear program mip divisible load schedule mixed integer linear program NP accord knowledge unless NP optimality exponential runtime algorithm computational complexity grows exponentially processor installment however reasonable mips fairly solver utility mips assess practical basis pessimistic estimation notation linear program schedule limit minimum schedule calculate mixed integer linear program decision variable subset machine communication sequence achieve mip usage minimize define component consumption spent computation sum spent compute load chunk machine dependence load chunk define inequality minimize guarantee constraint restrictive easy mip sum processor consume later processor installment consequently paid indeed activate networking calculate machine load originator installment inequality guarantee machine load chosen communication execute machine chosen computation inequality machine communication interval remind hence constraint ensure machine receives load chunk transfer load constraint purpose linearize guarantee cannot directly mip formulation quadratic program however substitute additional variable constraint constraint guarantee processing load chunk guarantee implies vice versa constant chosen avoid arbitrarily upon mip solver formulation tight feasible constant guarantee inequality binding constant guarantee binding inequality guarantee computation machine schedule calculate interval machine inequality purpose calculate idle activate machine inequality binding happens communication message load chunk inequality boundary constraint define trigger variable message message practical constant constraint substitute mip reformulate calculate minimum schedule minimize limit usage former minimize constraint remove constant upper bound schedule latter minimization minimize equation becomes constraint performance model parameter heterogeneous various divisible application significantly therefore analyze tendency instance behavior optimum demonstrate data generate pseudo randomly generate instance described detail unless otherwise GB function obtain minimum schedule described mip calculate minimum consumption increase discussion offs pareto dominate formally function minimum consumption schedule installment processor examine function brevity refer gurobi version optimality gap apply mip solver parameter MB MB MB MB MB MB dependence usage schedule load chunk bound diagonal usage processor remain idle denote idle horizontal usage ram ideal processor parameter processor processor denote ideal phenomenon function convex local optimum cliff usage interval monotonous dependency existence local optimum non monotonic relationship optimization effort cliff schedule sufficiently switch machine text interval decrease increase opportunity shift load faster intensive machine economic consumption increase schedule idle processor return impact idle processor increase load chunk performance multi installment processing improves however return diminish intuitively installment load chunk shorter communication earlier computation core memory minimum chunk processing load ram processor memory necessarily efficiency schedule profitable core memory ram sufficient verify installment substantial performance gain multiple minimum chunk fitting load core memory sufficient image KB image installment logarithmic image KB image closeup installment distribution load processor schedule installment load obtain machine message dependence schedule coordinate cliff usage load distribution serf purpose illustrate complex processor load distribution interplay verify steep reduction usage coincide remove processor computation load assignment become zero machine continuous illustrative switch load faster machine schedule efficient longer schedule grows machine load efficient machine switch situation twice switch load switch switch substitute machine comparatively efficient machine substitute faster image KB image distribution load machine consumption schedule axis load axis installment usage schedule increase available machine machine subset available computation label relationship index processor clarity index machine absent optimum machine profitable minimum shorter schedule schedule shorter additional machine switch usage instantly increase pivotal role leaf processor worth heterogeneous trajectory increase shorten schedule actual available machine machine machine schedule shorter subset extra machine consume machine machine advantage efficient subset processor disadvantage machine available engage computation image KB image machine installment processor omit schedule schedule machine  omit utility core memory load chunk sufficient load core profitable core memory communication processor usage core memory various schedule installment along vertical axis relative excess load chunk ram installment load chunk memory processor remain load core another processor allows avoid machine core memory usage persists unnecessary however indeed increase installment core memory cease observation rephrase confirm presence processor execute communication efficient core memory relative excess load chunk ram advantage core memory parameter data benchmarking mip solver computational image KB image core memory usage installment average installment combination processor installment average schedule minimum schedule minimum schedule average sample processor chosen relationship installment slowly maximum maximum installment quickly chunk computation quickly avoid lengthy data transfer message maximum shorter balance load machine image KB image average chunk installment installment machine return impact idle processor idle processor consume signify bound idle previous instance various setting instance mixed instance machine  disk mode acpi denote hdd detail instance generation correspond suspension ram denote ram machine disconnect finally instance processor idle retain startup optimistic bound LB idle startup hence LB potential improvement modification mode idle wider shortest schedule realistic narrower option optimize usage suspend machine ram allows marginally shorter schedule increase significantly consume communication computation hdd dominate mixed consequently costly startup therefore schedule compute intensive effective schedule machine mostly mode furthermore machine shallower deeper suspension mixed advantageous allows computation machine shallower suspension simultaneously activate machine deeper mode conclusion statistically significant correlation communication sequence parameter machine load earlier lack correlation parameter machine mixed active allows construct schedule shorter machine idle avoid strategy infrastructure provider image KB image various idle configuration machine installment algorithm performance comparison performance algorithm quality schedule evaluate quality schedule schedule usage unique performance algorithm construct criterion moreover reduce offs dimension numerical without lose information mips dimensional algorithm runtime obtain schedule conceptually unwieldy heuristic introduce however construct instance restricts option algorithm performance comparison hence discussion reduce algorithm performance examination reference practical importance shortest schedule schedule remind minimum schedule denote schedule quality distance shortest schedule distance usage algorithm runtime construct schedule runtime quality source inefficiency instance generate  machine instance generate MB MB MB MB MB MB drawn uniform distribution calculate linear component execution consumption respectively intersect probability machine chosen startup suspend ram otherwise startup  hdd former latter hence idle wakeup correlate machine wake vice versa wakeup shallower suspension mode unless otherwise assume mip model gurobi version mip solver parallel thread runtime limit version model mip optimality gap gap conduct PC computer intel ghz algorithm runtime quartile median machine algorithm mip runtimes minimum schedule mip gap denote mip mip gap mip runtimes schedule omit avoid clutter runtime mip model quickly increase median runtime limit mip gap relax optimality requirement mip median runtime limit around processor limit mip solver runtime exponential growth mip model moderate instance conversely CSS GSS heuristic faster distribute load machine super ssc super GSS denote   respectively magnitude ssc GSS execute heuristic processor sort  dispersion heuristic runtimes  quartile overlap examine runtime exchange quality image KB image algorithm runtimes machine logarithmic quality algorithm runtime computational complexity depends heuristic algorithm avoid conceal algorithm runtime quality relationship dependence computational complexity parameter MB algorithm runtimes horizontally relative distance obtain vertically population instance span quartile horizontally quality span analogously along vertical dimension median runtime quality marked  heuristic ssc GSS statistical analysis anova reveal neither runtime quality sort statistically advantage avoid clutter sort distinguish ssc GSS denote ssc GSS respectively super CSS super GSS processor sort   respectively construct mip model respect quality guarantee quality runtime relax mip gap mip respect runtime minor loss quality however approach limited scalability relaxed mip model exceeds limit heuristic average schedule criterion conversely heuristic magnitude faster mip model GSS algorithm ssc slightly approx longer runtimes super ssc improves quality ssc quality runtime refer median GSS super GSS marginally quality GSS conclude GSS dominate heuristic image KB image quality algorithm runtime schedule criterion criterion logarithmic runtime machine image KB image quality heuristic processor ssc heuristic schedule ssc heuristic GSS heuristic schedule GSS heuristic quality median heuristic logarithmic analyze source heuristic algorithm inefficiency respect quality quartile schedule spent idle population instance minimum reference heuristic algorithm processor sort statistic available machine separately machine indeed computation mip model idle machine activate machine signifies mip schedule almost available processor idle communication computation coordinate avoid idle quality twofold price computational complexity mips benchmarking application platform obtain precise data model conversely ssc idle processor activate confirm overall amount idle ssc schedule decrease active processor ssc potential improvement tune processor GSS schedule involve almost processor signify machine active consideration idle schedule   active machine  evaluation heuristic quality extend processor relative distance bound along vertical bound schedule minimum machine startup minimum communication overhead minimum ram communication rate processor respectively assume shortest communication load machine parallel bound minimum machine minimum networking minimum per load processor assume costly machine startup execute load transfer consume communication link load efficient processor quartile population moreover median rnd processor sort median performance rnd slightly distinguish positive negative increase core compute rate decrease compute allows shorter schedule consequently efficient CSS heuristic sort improves schedule quality roughly related rnd median quality processor population rnd sort observation conclude quality generate heuristic  modest advantage conclusion performance processing data parallel computation heterogeneous hierarchical memory hierarchical memory subsystem incur complex dependence consumption dependency piecewise linear function computation schedule render optimization consist activate processor sequence processor communication load chunk approach propose mip formulation apply heuristic obtain due existence idle processor consume local minimum schedule function hence schedule compute intensive effective schedule machine compute mode idle mode moreover machine diverse mode advantageous machine shallow suspension quickly computation simultaneously machine deeper suspension mode establish limited core memory beneficial limit communication activate machine performance schedule algorithm quality runtimes schedule obtain mip almost dominance mip runtime information model parameter heuristic propose approx respect quality magnitude shorter detailed information application parameter heuristic GSS quality runtime load consume processor moderately advantageous