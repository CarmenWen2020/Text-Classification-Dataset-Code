aim distil systematic methodology modernize exist sequential scientific code effort codebase code parallel robust code propose semi automatic methodology parallelize scientific application purely sequential program mindset possibly global variable aliasing random generator stateful function demonstrate methodology parallelization memory model via openmp message passing model via mpi purpose compute gpu model via OpenACC demonstrate parallelize sequential code domain physic methodology distil collaboration MSC parallel compute  apply project exam host lecture representative parallel compute code parallelize previous keywords loop parallelism cuda openmp OpenACC mpi introduction shift parallel compute platform driver likely sustain trend software technology consequently parallel program efficient portable onerous sequential program scratch explicitly parallel approach effective option achieve scalable efficient parallel code approach cannot effectively industrial adoption parallel compute technology context productivity equally essential aspect performance dangerous activity impair code correctness typical pitfall numerical stability validation random generator parallel code decade parallel program methodology significantly evolve programmer task improve program efficiency thread evolution abstraction concurrency management primitive crucial define algorithmic paradigm skeleton cole eighty pre define parallel implementation exists paradigm enable technology  embarrassingly parallel paradigm task skeleton enable elasticity compute data parallel paradigm reduce skeleton enable mapreduce program model array apache bigdata instruction multiple thread SIMT program model gpus paradigm explicitly parallel abstraction programmer directly application within specific program model verify embed sequential code compliance program model constraint associativity accumulation operation concurrent access data structure absence persistent pure function program environment concept propose instruction multiple data simd paradigm express data parallelism apply operation multiple data item parallel program construct intel SSE avx ISA extension approach remain research prototype essence consists promote concept replication sequential function organize parametric schema eventually become mainstream parallel library programmer directly define parallel construct function intel TBB apache spark directive openmp OpenACC construct associate semantically meaningful code function loop role directive played attribute statement programmer specify additional information information enforce compilation constraint specific code generation parallelization crucial aspect generative approach focus loop meaningful code particularly memory model parallel implementation loop express composition parallel construct without partition data structure loop typically navigate array discretize dimension random parallelize loop exist effective enhance performance robustness entire scientific application revolves around task loop correctly parallelize avoid restrict parallelism needlessly complex code transformation affect numerical stability loop worth parallelize data structure globally consistent checkpointing typically non parallelizable loop nest within parallel loop education principle parallel  spirit directly aim define strategy effectively parallelize scientific application tutorial distribute addition text besides approach useful domain expert practitioner tune scientific application strategy consists systematic methodology define memory model multi core gpus openmp OpenACC message passing model instance mpi unify approach prompt abstraction computer distinctive scientific domain methodology important aftermath firstly approach lose plethora parallelization trick non portable code internet secondly directly abstraction beyond traditional approach leverage platform specific functionality program approach justified extreme application lose exist vast majority scientific non scientific code  industrial adoption approach mature within parallel distribute compute taught prof    program parallel program primer structure parallel program model message passing exemplify mpi memory exemplify pthreads openmp gpu program exemplify cuda OpenCL abstract paradigm approach parallel program parallelization methodology loop parallelization skeleton data parallelism program model mapreduce addition guest industrial researcher invite lesson twofold goal evidence industrial application facilitate internship ibm research engineering   adopts education principle choice activity plus discovery model adheres principle periodic release program session moreover principle implement structure exam around project namely algorithm application parallelize propose algorithm application project parallelization approach accord principle application various domain complexity acceptable discussion teacher teacher stimulates address complex application proposes standard parallelization proposal encourage project stimulate discovery model project activity typically concept teacher parallel compute instruction advocate  dewey exam consists parallelization activity accompany report explain choice achieve performance oral discussion project theory grade balance complexity project quality report oral exam teacher embrace  principle proceeds along trajectory withholding temptation march pace accord principle absolute performance achieve parallel code developed limited project primary evaluation criterion instead acquire ability orientate oneself choice analyze performance bottleneck highly appreciate outline outline related sec sec introduces mention methodology preliminary version methodology target openmp previous manuscript substantially extend mainstream parallel program model memory multithreading multi core message passing cluster SIMT data parallelism gpus sec methodology demonstrate scientific application validate parallel platform code DiskMass survey code parallelize openmp sec spray web code parallelize gpus OpenACC cuda sec SimpleMD  code parallelize mpi sec DiskMass survey code implement monte carlo markov chain MCMC whereas application novel spray web code community codebase source  adopt evaluate impact emission source construction site industrial simulate particle movement vector SimpleMD code implement molecular dynamic simulation  elliptic partial differential equation solver scientific code wise global local knowledge respectively although methodology aim vanilla parallel version spray web application achieves speedup nvidia intel HQ SimpleMD bsc  supercomputer achieve maximum speedup   cluster achieve maximum speedup essential effectiveness methodology parallelization model related issue loop parallelism solid strategy schedule iteration parallel worker ensure performance sequential equivalence extent finite numerical precision float operation automatic loop parallelization technique usually perform lattice analysis data dependency explore data code transformation facilitate efficient loop iteration schedule ninety algebraic framework emerge compiler community polytope model nowadays lattice analysis almost exclusively compiler runtime layer parallelization library straightforward user friendly interface developer usually interface function intel TBB pragma directive openmp OpenACC approach minimizes curve developer parallel program expert user tune application specify optional parameter therefore technique prefer alternative explicitly parallel approach scalability intuitive interface massive amount sequential codebases parallel compute community suitable technique fully automatic parallelization serial code ensure correctness significantly limit practical effectiveness automatic approach indeed dependency easily remove code review prevent exploit parallelism performance improvement baseline modest unfortunately approach compiler code inspection openmp perform expectation conversely minor straightforward code reorganization significantly improve overall performance typically significant gap exists toy openmp tutorial scientific application multi nest loop precisely aim gap practical generic methodology loop parallelization typical scientific code application openmp serial scientific code literature discussion usually focus analyze researcher without parallel program generalize concept apply beyond parallel code merely loop parallel analyzer aim identify loop independent loop pipeline typical processing openmp OpenACC mpi program standard parallel compute openmp originally target memory multi core platform evolve offload loop onto gpus accelerator target OpenACC mpi reference program interface message passing distribute memory standard parallel compute  fundamental parallel programmer toolbox extensive description pragmatic evaluate specific application domain distribute memory mainstream framework propose loop parallelism  bind openmp multi core OpenACC gpus openmp multithreading cache coherent memory model although eventually program paradigm parallel task openmp prominently loop OpenACC accelerator loop parallelization heterogeneous openmp maturity multithreading practically openmp associate multi core target OpenACC gpus framework programmer annotate fortran source code identify accelerate compiler directive additional function recently scenario become blur OpenACC target multi core gpus fully mainstream compiler gcc openmp substantial improvement program accelerator gpu device target platform longer crucial nevertheless difference exist although subtle OpenACC directive compiler parallelize loop manage data potentially host accelerator memory openmp approach prescriptive purpose parallel program model programmer explicitly execution loop across thread execute underlie parallel compute hardware openmp directive instruct compiler generate parallel code specific compiler discretion optimizer compiler instruct instance openmp parallel parallel directive guarantee loop loop independent instead instructs compiler schedule iteration loop across available openmp thread accord default user specify schedule policy programmer responsibility compiler correctness generate code possibly data openmp synchronization construct programmer retains responsibility execution aspect parallelization schedule contrast OpenACC parallel loop directive construct programmer simply code loop relies compiler realization durable message passing interface mpi despite research attempt mainstream directive loop parallelization framework emerge distribute memory model durable message passing interface mpi standard broadcast reduction operator global synchronization barrier paradigm choice construct parallel application compose communicate tier api mpi application conceive program developer precise knowledge code partition data communication overhead notwithstanding platform evolve substantially accordingly exploit mpi evolve collective operation recently introduce mpi neighborhood collective intend sparse collective communication communication graph structural restriction highly structure graph stencil cartesian topology organize dimensional torus mesh neighborhood collective construct mpi aim application scientific neural network performance metric performance metric weak scalability predict parallel code performance ability software fix faster amount compute resource strictly related notion speedup program speedup parallel algorithm define ratio sequential algorithm parallel algorithm processing ideal speedup linear nevertheless scenario limited portion code cannot parallelize precisely amdahl exists upper bound program speedup spent serial processor code benefit parallelization spent serial code assume ideal speedup parallel execution processor amdahl maximum speedup meaning maximum speedup strongly bound sequential code therefore code serial bound maximum speedup unfortunately amdahl overhead introduce parallel implementation communication synchronization worker initialization thread indeed actual performance program usually derive whereas investigate fix weak investigate variable constant amount assign compute resource gustafson formulate proposes speedup processor instead fix define gustafson derive execution parallel code sequential amdahl considers constant spent processor fix processor global increase latency serial execution parallel execution speedup linearly decrease function serial code linearly increase function processing fully parallelizable code spent processor remain constant speedup upper limit bound determines maximum speedup growth rate weak easy achieve effective methodology parallelize sequential application detail methodology achieve version parallel fault tolerant code sequential scientific code methodology pretend neither fully automatic address parallelization algorithm exhibit inherently sequential behavior frequent anyway testbed  parallel programmer fundamental methodology important transmit effective parallelization application limited effort apply parallelization model systematic execute sequence programmer metric knob performance understand performance tune complex training clearly impart methodology parallelize scientific code beyond paste library tutorial code sample methodology advocate non expert parallel programmer parallelization entire application automatically complex loop latter beyond scope refer reader literature aspect sec reality scientific application rely complex iteration schema revolve around loop nest sequence loop distinguish loop loop former iterate array data latter iterate convergence criterion loop exhibit network dependency loop iteration loop typical scientific code statement loop particle simulation internal loop computes quantity related particle external loop advance simulation optimization algorithm internal loop iterate subset external loop update heuristic parameter ordinary differential equation ode solver internal loop iterate function subsystem external loop advance propose parallelization methodology consists identify parallelizable loop code accord depth strategy evaluate potential performance gain obtainable modify parallelizable loop filter worth parallelization effort remain candidate loop remove data dependency iteration non parallelizable loop implement checkpointing logic resume behavior detail remain sec practical openmp OpenACC trivial parallelize loop address model cpu gpu programmer simply appropriate directive identify loop distribute memory model fully automatic loop parallelization mature advocate semi automatic methodology categorizes accord dependency wilkinson allen textbook distinguish complexity embarrassingly parallel locally synchronous globally synchronous discus approach advocate sec identify parallelizable loop nest loop statement loop subset statement loop due procedure function described loop inclusion relationship generates cyclic graph loop weak identify parallelizable loop code multi nest loop useful induce partial relation inclusion graph relation graph domination relationship induces loop nest node refers distinct loop node node nest loop loop entire program pseudo loop iteration generic formal treatment concept technicality graph theory however construct carefully analyze code representation multi nest loop suggests depth approach parallelization loop external iteration loop atomic synchronization barrier implicitly explicitly loop preserve potential inter loop dependency bernstein seminal clearly arbitrary program parallelizable undecidable sufficient assert execute parallel data dependency dependency anti dependency output dependency categorize loop loop independent iteration iteration loop iteration depends iteration loop independent iteration trivially parallelize whereas involve presence loop dependency unfortunately loop parallel mindset sometimes unnecessary dependency dependency generally due sequential cod habit reuse variable purpose induce anti output dependency automatically remove technique variable privatization multiple variable loop induction variable typical variable  dependency harder address intense research loop dependency address transform loop dependency remove sufficient distance avoid conflict concurrent iteration paradigmatic substitution accumulator variable reduce function array  variable however dependency eliminate via reduce function typical accumulation operation associative happens building sequence pseudo random stateful function summarizes generate cannot easily parallelize practical parallelize program descend loop hierarchy parallelizable loop unfortunately presence conditional parallelizability loop input data therefore statically decidable useful reduce complexity identify computationally demand graph enclose dedicate procedure another potential source complication arises function loop multiple code scenario loop multiple hierarchy parallelizability strategy maintain serial version function non parallelizable parallel version others evaluate potential performance gain previously described depth encounter parallelizable loop evaluate potential benefit introduce parallel implementation indeed parallelize amount overhead introduce load imbalance synchronization worker actual computation grain becomes parallelization performance serial version multi core platform mainstream framework openmp intel TBB exhibit limit grain cycle finer grain address lock program framework  grain cycle extreme  cluster naturally network latency throughput induce additional memory grain millisecond gain decent scalability iteration loop affect maximum obtainable parallelism spent program inside loop determines maximum achievable speedup account planning loop parallelization estimation complicate due presence branching construct external procedure graph  helpful parallelize outer loop instead nest counterpart indeed strategy minimizes introduce overhead thread creation synchronization cannot define strategy nevertheless loop iteration parallelization inner loop furthermore code processor parallelization inner outer loop convenient effective greedy technique parallelize outermost suitable loop suitable feasible convenient loop hierarchy explore parallelize suitable nest loop performance requirement met noticeable speedup optimization candidate parallelization identify worth evaluate maximum performance gain investigate potential weak scalability parallel code loop identify loop worth parallelize transform iterative construct procedure code target core accelerator local address externally declare variable reference inside loop newly procedure otherwise variable access operation program model hardware accelerator version cuda unified address abstraction host device memory manage data transfer hood considerably reduce program effort frequently loop iterate array input array output uncommon loop immediately another loop combine utilize associative binary operator sum parallel implementation transform reduce operation worker input array reduce output transformation iterative construct procedure implementation reduce function perform manually external library openmp OpenACC recommend latter approach easy faster implement guarantee performance portability hardware architecture resort manual implementation random generator related loop revolves around eliminate interaction via global variable induces stateful function global pseudo random generator PRNG stochasticity critical component diverse scientific application bayesian predictive model monte carlo simulation complex approach introduce randomness logic sample probability distribution commonly approximate PRNG PRNGs stateful approximate genuinely random actually deterministic reproduce PRNG PRNGs sequentially execute portion program initial capture checkpointing sec contrary parallelization firstly PRNG implementation thread  concurrently multiple thread without  return input argument secondly enforce reproducibility random sequence generate parallel deterministic independent relative execution goal achieve  random induction variable orient easily achieve array PRNG concurrent thirdly enforce correctness reproducibility array PRNG initialize generate PRNG moreover PRNG implement algorithm algorithm reduces induces loss distribution uniformity generate PRNG fix sequence random generate parallel deterministic fourthly programmer parallelize code PRNG sequential equivalence compute sequential parallel code programmer duty ensure sequential parallel code compute stochastic implement checkpointing logic sequential parallel code gain performance advantage define global program execution checkpoint checkpoint snapshot entire information restart usually checkpoint stable storage persistent storage reliability requirement essential concept related checkpoint checkpointing overhead increase execution introduction checkpointing procedure checkpointing latency checkpoint appropriate checkpointing strategy aim minimize quantity approach minimize latency advanced storage communication technology reduce amount data checkpointing data asynchronously reduce overhead regardless latency combination checkpoint define random sequence initialize application fail sequence restart random generator iteration persistent storage sec procedure particularly useful monte carlo markov chain  computationally expensive parallelization loop mpi parallelize loop distribute memory model exhibit additional factor complexity respect memory model trivially data structure distribute replicate partition processing node therefore operation data replica generate processing explicitly conciliate communication collective factor revolves around relatively latency inter node communication reduce frequency communication grain concurrent worth aspect affect reconciliation careful communication advocate parallelize loop mapping skeleton pre define parallelization schema parallelize loop data dependence distinguish embarrassingly parallel globally synchronous locally synchronous embarrassingly parallel loop iterates independent data partition node typically approach transform loop worker skeleton schema logical entity distributes data worker worker computes function data partition return worker approach applicable popular effective parallelization plethora worker variant propose literature centralize typically parallelization parallel compute replicate schema steal schema worker interestingly bigdata framework built worker runtime disk survey described sec memory model easily implement distribute memory fashion worker reduction operation perform globally locally synchronous variant data parallel approach data structure partition replicate across possibly compute node similarly theorize valiant bulk synchronous parallelism BSP parallel computation proceed successive super super compose computation locally computes function data partition communication data partition reconcile inter communication collective communication synchronization barrier BSP global local data exchange latter globally locally synchronous computation respectively parallel compute data decomposition optimization crucial performance load balance communication overhead sensibly data decomposition aspect hardly fully automate however understood performance fortran compiler owner computes output data decomposition typically scientific compute approach retains partition data locally input data compute potentially replicate data sequential loop iteration admit partition access data parallel program multiple data SPMD partition exchange data periodically locally globally data dependency approach scalable computation stencil admit extent potentially data randomly input data sec parallelization molecular dynamic application loop parallelize partition iteration mpi globally allgather reduce data previous super accord propose methodology loop outermost parallelizable loop recent application parallel compute distribute stochastic gradient descent algorithm neural network globally synchronous loop describes stencil computation data depends locally synchronous paradigm applies practical loop loop nest locally synchronous computation transform algorithm algorithm data locally partition tile traverse outer loop traverse tile dimension inner loop inside tile dimension tile sequential algorithm transform parallel code assign tile dimensional cartesian topology exchange tile border super halo swap technique scientific computation simulation pde solver thanks constant communication per per typically scalable approach mpi standard version directly communication cartesian topology concept sec laplace 2D solver code mock  code experimental validation apply methodology application technology application performance achieve weak parallelization DiskMass survey spray web application clearly exceed effort exam DiskMass survey novel scientific code development sequential version non trivial effort spray web code fortran code numerical stability emerge parallel version exam application propose directly interested parallelization code kernel  code 2D laplace solver complexity code parallelize exam execution environment subsection technical specification   modular cluster consist node xeon 1GHz core GB ram node xeon 5GHz core GB ram gpu node xeon 5GHz core GB ram nvidia  bsc node node consists xeon platinum 1GHz core GB ram intel omni interconnection   node consist xeon platinum 1GHz core GB ram intel omni interconnection DiskMass survey openmp DiskMass survey code model rotation curve vertical velocity dispersion distribution disk galaxy belonging DiskMass survey explore agreement model data bayesian approach physic related implementation detail nutshell code algorithm implement MCMC metropolis hastings acceptance criterion obtain random variate previous algorithm image KB image algorithm parallel DiskMass survey openmp preparatory phase import data external file initializes MCMC define PRNGs sample uniform distribution metropolis hastings criterion multi variate gaussian distribution generate parameter loop computes MCMC iterate galaxy distinct inner loop rely solver poisson equation approximate gravitational potential galaxy derive correspond sum obtain global likelihood combination parameter randomly generate previous inner loop computation finally combination parameter accepted reject accord metropolis hastings criterion poisson equation galaxy gravitational potential galaxy density source potential universal gravitational constant involves galaxy quantity discretized grid sequential version code demand computation poisson solver twice per galaxy MCMC apply propose semi automatic methodology parallelize execution openmp semi automatic parallelization DiskMass survey firstly identify code data dependency MCMC loop sequential definition combination parameter drawn previous cannot parallelize site checkpointing logic innermost loop independently compute galaxy gravitational potential candidate parallelization loop accumulator operator respectively nevertheless sum associative binary operation parallelizable loop independent parallel reduction described sec therefore parallelize code openmp library pragma omp parallel reduction directive loop eventually implement checkpointing logic iteration program disk random generator PRNG PRNG parameter chain execution interrupt MCMC iteration restart loop import disk chain parameter generator resume MCMC loop iteration instead restart scratch performance evaluation DiskMass survey parallelize inner loop iterate galaxy maximum ideal speedup achieve galaxy DiskMass survey scalability node  cluster core MCMC reasonable timescales furthermore analyze distribution thread onto socket affect performance linux launch numa  command computation socket data cache interleave policy core available socket whatever thread allocate memory socket robin strategy conversely policy socket thread saturates core comparison  node core without numa entire sample galaxy cpu MCMC iteration  function explicitly increase thread panel speedup average MCMC obtain numa interleave policy default policy machine core node execution sequential parallel code respectively worth ideal linear thread linear trend thread converge asymptotic around convergence depends schedule policy indeed apply policy asymptotic limit slowly execution performant thread resource nearly entire machine obtain maximum gain performance policy machine image KB image amdahl weak gustafson plot refer node  hpc core solid schedule policy thread onto core numa mode numa interleave mode default policy machine interpretation reader refer web version article panel machine default policy core node qualitatively curve trend core speedup peak image KB image amdahl weak gustafson plot refer node  hpc core weak parallel code partition galaxy onto thread distribution galaxy survey affect load balance weak evaluate input galaxy avoid bias due distribution synthetic survey compose galaxy generate galaxy DiskMass survey panel plot MCMC iteration respect galaxy default interleave schedule policy curve related default interleave policy weak scalability satisfied setting lose performance thread already lose performance thread mode remains nearly constant increase standard deviation furthermore default interleave policy efficiency meaning obtain performance gain entire machine panel weak machine default policy core node behaves correspond curve core platform thread conclude parallelize code weak scalability MCMC iteration remains mostly constant amount thread spray web OpenACC cuda spray web application simulates dispersion pollution 3D environment account spatial temporal  perturbation local particle pollution dispersion velocity obtain lagrangian stochastic differential equation reproduces statistical characteristic turbulent spray web implementation paradigmatic fashion engineer scientific code developed fortran function parameter feature automatic parallelization particularly challenge moreover knowledge gpu enable version spray web available essence code algorithm iterates along discretized timeline collection  particle loop iterates particle generate exist inner loop update particle independently others finally particle simulation domain remove algorithm image KB image algorithm parallel grid stride loop spray web cuda particle typically update relatively principle gpu SIMT execution model obstacle absence modularity implementation methodology described sec approach parallelization spray web mainstream loop parallelization gpus OpenACC sake completeness derive cuda parallelization code OpenACC approach semi automatic parallelization spray web spray web loop selection trivial indeed outer loop cannot parallelize contains data dependency simulation initial previous checkpointing nevertheless checkpointing mechanism sequential version implement parallel version performance comparison conversely inner loop iterates particle candidate parallelization accord propose methodology firstly transform inner loop procedure parallelize cuda fortran OpenACC library spray web cuda fortran issue encounter parallelization due fortran specification impose explicit evaluation expression  compiler serial version pgi fortran compiler compiler cuda fortran kernel adopt evaluation strongly affect numerical stability version program worth related parallelization per happens compile sequential version spray web likely scientific code compiler practical address issue explicitly impose unique parenthesis numerical stability transform loop procedure convert cuda kernel declare global moreover worth cpu gpu address version cuda grain data movement optimize performance data transfer host device handle explicitly crucial preliminary distinguish kernel input dependency output variable indeed gpu memory execute kernel others host memory termination related issue derives global variable inside loop absence address variable necessarily additional argument kernel hidden dependency consume straightforward strategy transform loop cuda kernel replace monolithic kernel substitute iteration thread loop iterator variable  compute cuda thread index logic avoid bound access elegant efficient convert loop kernel implement grid stride loop loop remove simply rewrite initialize iterator variable blockDim blockIdx threadIdx cuda fortran blockIdx incrementing blockDim  iteration adopt implementation thread associate multiple iteration sequential loop flexibility performance tune moreover incrementing iterator variable grid dimension iteration ensure maximally coalesce memory access cuda thread code parallelize optimize cpu bottleneck usually data transfer host gpu magnitude normal memory operation passing argument function spray web exacerbate absence modularity program subroutine parameter cpu version almost parameter reference minimize overhead function gpus parameter transfer forth host device memory enormous loss performance optimal rewrite code modular program effort realistic option avoidable data transfer reduce overhead constant input dependency cuda kernel transfer program another reduce data transfer overhead overlap computation communication combination memory pin cuda unfortunately optimal implementation advanced implementation hardware specific outside concept semi automatic methodology algorithm image KB image algorithm parallel grid stride loop spray web OpenACC spray web OpenACC OpenACC implementation firstly directive manage data transfer host device mention data transfer crucial role gpu code obtain decent performance optimize carefully OpenACC data transfer declaratively manage data directive compiler tend adopt conservative approach copying data host gpu kernel execution transfer host termination however overhead introduce harmful kernel launch generally constant data safely gpu memory entire program execution data kernel execution data kernel termination OpenACC optimization explicitly compiler hoc data directive variable argument detail  clause argument host gpu prior execute kernel argument  clause transfer host memory kernel termination clause variable another useful clause compiler transfer data already memory parallel loop directive parallelize loop  nthreads argument specify thread per accord standard cuda program abstraction performance evaluation spray web sequential cpu parallel gpu version distinct input file particle evolution simulation across gpu tesla gpu cuda core sequential intel HQ cpu amount memory GB fairly version fix random reset particle iteration operation overcome evaluation mathematical expression earlier execution speedup obtain pure cuda OpenACC implementation respect sequential cpu version report spray web execution speedup input    seq intel HQ cpu cuda gpu OpenACC gpu worth OpenACC slightly pure cuda probably due limited effort optimization native version indeed directly explicitly parallel paradigm access flexibility translates potential gain performance limit massive cod effort experienced conversely goal achieve speedup minimal effort propose methodology library OpenACC suitable SimpleMD mpi molecular dynamic SimpleMD application simulates evolution velocity particle  jones potential SimpleMD pseudocode algorithm code input simulation particle  simplicity assume  multiple  allocate program execution algorithm image KB image algorithm parallel SimpleMD SPMD initialization phase generates particle computes initial simulation loop fix iteration loop contains inner loop update particle vector compute iteration compute vector particle update velocity particle compute potential sum contribution particle compute kinetic sum contribution particle velocity iteration program computes sum potential kinetic contribution semi automatic parallelization SimpleMD accord propose methodology identify parallelizable loop simulation loop belongs loop particle compute iteration depends vector compute previous perfect candidate host checkpointing logic moreover neither particle generate routine trivially parallelizable imposes constraint minimum distance newly generate particle exist conversely inner loop iterate particle particle loop independent suitable target methodology parallelize version becomes responsible update subarray particle     strategy adopt parallelize portion code detail generation particle depends previous generation strategy distribute  particle scatter primitive however  particle compute potential difference array particle broadcast mpi  function update access entire particle array focus generic iteration simulation loop trivially update without inter communication particle update compute vector communication perform mpi allgather function independently compute velocity particle subarray reduction computation obtain sum kinetic particle potential difference sequential version code potential difference compute triangular loop nest loop termination outer index initialize index outer loop plus construct implies particle rank subarray ranked standard mpi allgather communication strongly inefficient improve performance implement hoc triangular function conversely computation kinetic trivial particle independently finally obtains particle subarray mpi reduce function computes performance evaluation SimpleMD sequential version parallel code achieve maximum speedup node instead evident performance degradation meaning additional compute compensate overhead induced communication mpi allgather regard weak  iteration within reasonable timescales execution constant operation viz potential computation quadratic complexity  2D laplace solver mpi 2D laplace solver algorithm panel iteratively approximate laplace equation poisson equation sec source evenly cartesian grid potential boundary domain fix priori simply initialize extend grid boundary BCs panel grid compute upon assume previous iteration algorithm iterates sum difference compute potential iteration tolerance tol algorithm image KB image algorithm seq parallel mpi laplace image KB image cartesian decomposition domain perform mpi cart function portion global domain mapped couple coordinate dot local grid laplace equation compute iteratively dot physical boundary BCs whereas dot inter BCs define halo swap operation inter BCs semi automatic parallelization 2D laplace solver parallelize laplace solver propose approach reorganize serial code global domain equally sub domain tile compute equation firstly iterate tile along dimension iterate tile nest loop panel algorithm parallelize mpi external loop combine sub mpi allreduce function derive global decomposition domain perform parallel mpi cart function assigns sub domain individual accord topology illustrate function return communicator encodes mpi topology execution along dimension grid   manual maximally decomposition    domain cannot decompose execution compute laplace equation parallel portion grid BCs increase besides physical BCs border global domain inter BCs definition inter BCs communication mpi topology array potential compute external interior sub grid array boundary local domain laplace equation halo swap communication perform mpi  function panel performance evaluation 2D laplace solver performance parallelize laplace solver  cluster OpenMPI version compile specifically intel processor evaluate solver grid sufficiently guarantee computational significantly communication sufficiently challenge tolerance moreover allocate core available node core empirically occupation node resource rapid deterioration performance node panel average speedup execution amdahl core albeit slowly speedup along entire core achieve maximum core image KB image amdahl weak gustafson laplace solver code average execution  platform shade error measurement dash ideal amdahl weak investigate weak scalability parallelize laplace solver constant grid per core meaning grid core implies increase global grid resolution dimension fix consequently processor converge comparable fix tolerance program computation fix iteration comparable allocate core available node panel illustrates weak average execution slowly increase remains constant around weak scalability scientific educational conclusion aspect novel methodology devise parallel version scientific code methodology semi automatic procedure describes methodology teacher parallel distribute compute  computer  italy scientific aspect illustrate novel methodology concentrate parallelization loop already literature entire scientific application loop structure methodology tutorial style become additional approach particularly suitable beginner program minimal sequential version application achieves target systematic sequence identify parallelizable loop code evaluate potential performance gain obtain parallelization transform loop procedure exploit non parallelizable loop implement checkpointing logic moreover methodology apply parallelization technology openmp OpenACC cuda mpi versatile approach methodology code DiskMass survey code parallelize openmp spray web code parallelize cuda OpenACC gpus SimpleMD code parallelize mpi laplace code parallelize mpi parallel version code developed author manuscript DiskMass survey code illustrates  model kinematic profile sample galaxy MCMC achieve speedup passing execution sequential version execution parallel version weak increase input proportionally parallelism execution remains mostly constant spray web code legacy code fortran fortran simulate dispersion pollution local 3D environment dispersion model lagrangian stochastic differential equation apply methodology OpenACC cuda fortran address optimization obtain acceptable sequential parallel version input simulation OpenACC version speedup cuda fortran achieve speedup respectively SimpleMD code simulates evolution velocity particle  jones potential achieve speedup passing compute sequential version compute parallel version regard weak execution constant operation quadratic complexity particle laplace code 2D laplace solver solves elliptic partial differential equation iteratively 2D evenly cartesian grid code unlike previous iteration communicate subset sequential parallel version achieve maximum speedup core educational aspect parallel distribute compute activate  AY physic department computer department AY overall receives per computer physic mathematics prof   edition evolve instruction theory cod exam consist parallelization classic algorithm propose parallel  spirit sec progressively unrolled maintains formal aspect aim differentiate possibly overlap exhibit attitude complex goal correctly dimension challenge project dynamic teacher project activity continuously evaluate progress project requirement relaxed passing parallelization algorithm parallelize evaluate  standard questionnaire   evaluate exam oral discussion teacher involve periodic statistical report report publicly available sensitive information related teacher analysis propose approach extract related evaluation edition physic slightly program evaluation comparable admits unsatisfied moderately unsatisfied moderately satisfied satisfied opt relevant report satisfaction percentage obtain ratio positive evaluation described parallelization report manuscript refer AY edition AY currently ongoing data available propose methodology appreciation tune challenge grain instead evaluation satisfaction monitor evaluation dynamically adapt dynamic adaptation cornerstone methodology evaluation along AY methodology unrolled percentage ratio positive evaluation evaluation initial load examination stimulation additional activity coherency teacher availability topic