anomaly detection critical towards building secure trustworthy primary purpose signicant various critical debug failure perform analysis data universally available nearly computer data important valuable resource understand status performance issue therefore various naturally excellent source information online monitoring anomaly detection propose DeepLog neural network model utilize memory lstm model sequence allows DeepLog automatically paerns normal execution detect anomaly paerns deviate model data normal execution addition demonstrate incrementally update DeepLog model online fashion adapt paerns furthermore DeepLog construct  underlie anomaly detect user diagnose detect anomaly perform analysis eectively extensive experimental evaluation data DeepLog outperform exist anomaly detection traditional data mining methodology CCS CONCEPTS information online analytical processing security privacy intrusion anomaly detection malware mitigation keywords anomaly detection data analysis introduction anomaly detection essential task towards building secure trustworthy computer application increasingly complex bug vulnerability adversary exploit launch aacks aacks  increasingly sophisticated anomaly detection become challenge traditional anomaly detection standard mining methodology longer eective signicant various critical debug performance issue failure perform analysis data universally available nearly computer valuable resource understand status furthermore noteworthy actively excellent source information online monitoring anomaly detection exist approach leverage data anomaly detection broadly  pca approach message counter invariant mining capture occurrence paerns dierent workow identify execution anomaly program logic ows successful scenario none eective universal anomaly detection guard dierent aacks online fashion proposes DeepLog data driven approach anomaly detection leverage volume intuition DeepLog processing entry sequence paerns grammar indeed program rigorous logic ows structure restrict vocabulary DeepLog neural network model sequence entry memory lstm allows DeepLog automatically model paerns normal execution deviation normal execution anomaly furthermore driven approach incrementally update DeepLog model adapt paerns emerge challenge data unstructured format semantics signicantly already challenge diagnose unstructured aer error online anomaly detection massive data challenge exist approach address issue specic domain knowledge feature IP address parse however purpose anomaly detection almost impossible priori feature dierent guard dierent aacks anomaly detection timely useful user intervene ongoing aack performance issue decision fashion session insight CCS october november dallas TX usa oine entire data applicable detect unknown anomaly gear towards specic anomaly erefore previous normal abnormal specic anomaly data entry binary classier anomaly detection useful context another challenge concurrency clearly message important information diagnosis analysis identify execution program however message dierent thread concurrently task concurrency apply workow anomaly detection workow model task generative model sequence message lastly message contains information metric timestamp holistic approach integrates utilizes dierent information eective exist analyze specic message limit anomaly detect contribution recurrent neural network rnn   neural network loop output input prediction memory lstm network instance rnns ability dependency sequence lstms demonstrate various task machine translation sentiment analysis medical diagnosis inspire observation entry sequence execution structure source code hence structure DeepLog framework lstm neural network online anomaly detection DeepLog metric entry anomaly detection hence capture dierent anomaly DeepLog depends training data consists sequence normal entry aer training phase DeepLog recognize normal sequence online anomaly detection incoming entry fashion intuitively DeepLog implicitly capture potentially nonlinear dimensional dependency entry training data correspond normal execution user diagnose anomaly identied DeepLog workow model entry training phase DeepLog entry concurrent task thread dierent sequence workow model construct task evaluation hdfs dataset explore previous entry correspond normal execution DeepLog achieve almost detection accuracy remain entry openstack convey trend furthermore DeepLog ability incrementally update detection phase incorporate user feedback specically DeepLog mechanism user feedback normal entry incorrectly  anomaly DeepLog feedback adjust dynamically online adapt execution hence paerns PRELIMINARIES parser rst parse unstructured text entry structure representation sequential model structure data prior eective methodology extract message entry entry refers constant statement source code execution code entry instance instance constant statement printf instance parameter abstract asterisk ese metric  underlie performance status parameter  execution sequence hdfs instance openstack ese  entry  entry concurrent thread sequential sequence parse unsupervised parser par incoming entry online fashion LCS subsequence analysis discard timestamp parameter entry detect anomaly DeepLog parameter entry elapse predecessor vector vector DeepLog addition parse sequence entry multiple execution virtual machine VM deletion task openstack DeepLog architecture overview architecture DeepLog component anomaly detection model parameter anomaly detection model workow model diagnose detect anomaly training stage training data DeepLog entry normal execution entry parse parameter vector sequence parse training DeepLog anomaly detection model construct execution workow model diagnosis purpose distinct DeepLog maintains model detect performance anomaly reected metric parameter vector sequence detection stage newly entry parse parameter vector DeepLog rst session insight CCS october november dallas TX usa message underlined parameter vector deletion  deallocate network VM lifecycle entry openstack VM deletion task training stage  stage anomaly detection model parameter anomaly detection model workflow normal execution file parser entry parameter vector entry parser parameter vector model construct workflow anomaly vector anomaly diagnosis update model false positive model DeepLog architecture anomaly detection model incoming normal DeepLog parameter vector parameter anomaly detection model entry label anomaly parameter vector predict abnormal lastly label abnormal DeepLog workow model semantic information user diagnose anomaly execution paerns training data DeepLog option user feedback user report detect anomaly false positive DeepLog label incrementally update model incorporate adapt paern  model DeepLog learns comprehensive intricate correlation paerns embed sequence entry normal execution henceforth assume secure adversary cannot aack integrity assume adversary cannot modify source code behavior paerns broadly aacks aacks execution misbehavior hence anomalous paerns instance denial service dos aacks execution hence performance anomaly reected timestamp dierences parameter vector sequence aacks server restarts blind return orient program BROP aack server restart attack task abortion correspond sequence exception entry aacks trace due activity monitoring service suspicious activity intrusion detection IDS anomaly detection execution anomaly rst detect execution anomaly sequence distinct statement entry source code constant distinct distinct source code entry parse sequence  execution execution statement denote sequence clearly strongly dependent recent prior model anomaly detection sequence multiclass classication distinct  DeepLog multi classier recent context input recent output probability distribution probability sequence summarizes classication setup suppose sequence input classi cation recent entry output training phase model conditional probability distribution detection phase model prediction predict output actually training stage training stage relies entry normal execution underlie sequence training data DeepLog session insight CCS october november dallas TX usa DeepLog input recent output conditional probability input recent sequence overview anomaly detection model update model probability distribution suppose normal execution parse sequence input sequence output label DeepLog detection stage DeepLog performs anomaly detection online incoming parse incoming entry normal abnormal DeepLog input output probability distribution probability multiple instance  host respond normal behavior DeepLog paerns training strategy sort probability treat normal candidate  abnormal execution otherwise traditional gram model ascribe probability sequence drawn xed vocabulary classic model widely processing nlp community vocabulary typical model approach assign probability arbitrarily sequence gram model intuition sequence  recent predecessor entire approximation equivalent denotes recent training calculate probability relative frequency corpus maximum likelihood estimate sequence estimate probability relative frequency respect sequence frequency slide entire sequence apply gram model simply gram model slide depict baseline lstm approach recent neural model recurrent neural network highly eective across various nlp task gram lstm output input lstm lstm DeepLog output input lstm lstm lstm stack lstm lstm lstm lstm detailed anomaly detection model stack lstm model lstm encode intricate maintain sequence complex paerns interleave entry concurrent task render traditional model eective DeepLog lstm neural network anomaly detection sequence sequence lstm network maximize probability reected training data sequence learns probability distribution maximizes probability training sequence illustrates gure lstm  recurrent lstm lstm remembers input vector xed dimension lstm previous fed input external data input compute output historical information maintain lstm series lstm unrolled version recurrent model layer maintains hidden vector vector initialize lstm input sequence hence layer consists unrolled lstm within lstm input previous output previous retain input previous output inuence construct output accomplish gate function dynamic amount information input previous output information gate function parameterized expressive capacity lstm memory session insight CCS october november dallas TX usa dimensionality hidden vector due constraint refer reader nlp primer formal characterization lstms training entail nding assignment nal output sequence lstms desire label output input training data training input output incrementally update loss minimization via gradient descent DeepLog input consists output aer categorical entropy loss training aer training predict output input layer lstm correspond lstm layer stack multiple layer hidden previous layer input correspond lstm layer becomes lstm neural network boom simplicity omits input layer output layer construct standard encode decode scheme input layer encodes vector sparse dimensional vector construct output layer translates nal hidden probability distribution function standard multinomial logistic function boom hidden layer layer parameter performance anomaly sequence useful detect execution anomaly however anomaly deviation normal execution irregular parameter ese parameter vector parameter vector sequence sequence dierent multi dimensional feature important performance monitoring anomaly detection baseline approach approach parameter vector sequence matrix parameter sequence multiple parameter vector matrix instance entry ere distinct parameter vector respectively hence matrix instance  null null null similarly null null null null null null null respectively instance corresponds multiple message within becomes sparse matrix sparse exists parameter vector furthermore approach introduces delay anomaly detection dicult gure matrix data driven anomaly detection apply principal component analysis pca organize som useful towards capture correlation dierent feature dimension however limitation context data oen appearance multiple instance equally likely instance arbitrary due concurrently task phenomenon matrix sparse render technique  lastly model auto correlation exists parameter vector sequence regular paerns vector sequence approach DeepLog parameter anomaly detection model parameter vector sequence series series parameter vector sequence hence reduce anomaly detection multi variate series data apply lstm approach lstm network model multi variate series data adjustment lstm network built parameter vector sequence distinct input input simply parameter vector timestamp normalize vector average standard deviation parameter training data output output vector prediction parameter vector sequence parameter vector recent objective function training multi variate series data training adjust lstm model minimize error prediction parameter vector loss minimize error training anomaly detection dierence prediction parameter vector error mse instead magic error threshold anomaly detection purpose hoc fashion partition training data subset model training validation vector validation apply model training calculate mse prediction vector sequence validation error predict vector actual validation model gaussian distribution deployment error prediction vector within condence interval gaussian distribution parameter vector incoming entry normal abnormal otherwise parameter message oen important metric detect various performance anomaly performance anomaly  recall DeepLog parameter vector elapse consecutive entry lstm model model parameter vector multi variate series detect unusual paerns session insight CCS october november dallas TX usa dimension series elapse dimension online update anomaly detection model clearly training data normal execution paerns behavior additionally workload data characteristic erefore DeepLog incrementally update lstm model incorporate adapt paerns DeepLog mechanism user feedback allows DeepLog false positive adjust suppose recent sequence DeepLog predict probability label anomaly user report false positive DeepLog input output update model paern sequence DeepLog output update probability update procedure parameter anomaly detection model DeepLog scratch aer initial training model DeepLog exist multi dimensional vector update training data adjusts minimize error model output actual false positive workflow construction multi TASKS execution execution printing statement source code task VM creation sequence entry intuitively entry task execution function accomplish task workow model  automaton fsa capture execution task workow model detect execution anomaly eective DeepLog lstm model due inability capture inter task dependency nondeterministic loop iteration however workow model useful towards enable user diagnose execution task anomaly detect sequence generate execution task explore inference  anomaly detection workow model  limitation firstly anomaly detect limited entry error entry furthermore workow model construction execution task previous workow construction  limitation oen contains interleave entry multiple task potentially concurrently thread within task entry separation multiple task easy multiple program concurrently ubuntu oen entry contains program another easy task entry focus user program execute repeatedly perform dierent logically related task within program important observation task overlap however task concurrency within task multiple thread task openstack administrative VM instance cycle contains VM creation VM VM deletion others ese task overlap VM aer VM creation however dierent task message VM resume lifecycle VM creation VM VM resume VM  ere concurrently thread inside task uncertainty message correspond task instance VM creation message instance VM resume lifecycle uncertain goal entry dierent task workow model task sequence input entire sequence parse raw output workow model task identied DeepLog anomaly detection model separation recall DeepLog model anomaly detection input sequence recent output probability distribution observation output actually encodes underlie workow execution intuitively sequence model predicts execution paerns training stage sequence training stage correspondingly sequence suppose sequence output prediction task complicate sequence dierent probability aer sum handle inspire invariant mining sequence suppose predict probability distribution ambiguity insucient sequence task workow rst task paern execute task paern execute model predicts sequence address issue training model dierent sequence instead workow construction sequence prediction session insight CCS october november dallas TX usa concurrency detection task detection loop  lstm task separation workow construction sequence prediction sequence prediction sequence dierent task increase sequence training prediction prediction challenge multi prediction output concurrency task dierent task divergence divergence concurrency task paern probability prediction output aer another certainty probability prediction increase concurrent thread already prediction eventually become aer concurrent thread sequence divergence task predict candidate aer another incorporate sequence prediction deterministic prediction workow model task construct workow model task task handle situation apply heuristic task aer task treat otherwise task workflow model distinguish divergence concurrency multiple thread task task easily construct workow model illustrate additional identify loop detection loop actually straightforward loop initial workow model unrolled chain workow chain identify fragment loop execution density cluster approach separation another approach  cluster technique intuition occurrence matrix within distance task dierent task task xed multiple execution dierent task allows cluster occurrence paerns dierent task occurrence rate sequence distance dened plus sequence distance occurrence matrix probability within distance input sequence specically frequency input sequence frequency within distance input sequence dene importance occurrence denition denominator counting occurrence frequency within factor ensures multiple occurrence matrix dierent distance occurrence matrix distance built goal output task task cluster procedure threshold recursively extend exists occurrence probability within distance otherwise task procedure task task extend task extend session insight CCS october november dallas TX usa occurrence probability distance maximum built occurrence matrix min connects sequential task task cannot extend extend exists suppose  concurrent thread task increase intuitive appearance concurrent thread otherwise belong task instead finally task task eliminate sequence sub sequence another task workflow model sequence identied task workow model construction task discussion workow model parameter DeepLog model DeepLog input parameter sequence training detection predict output probability distribution function normal dependent generally increase prediction accuracy information utilized lstm contribute prediction increase hurt prediction accuracy lstm lstm recent sequence  ignore however performance impact computation layer training prediction slows performance DeepLog regulates positive anomaly detection rate false positive false alarm rate workow model guidance intuitively incorporate dependency prediction shortest workow execution hence maximum divergence  task workflow diagnose detect anomaly whenever anomaly detect DeepLog workow model diagnose anomaly understand sequence prediction DeepLog suppose however actual anomaly workow model actual execution prediction instance terminate instance instance instance destroyed successfully instance delete instance file instance deletion instance destroy instance hypervisor instance error   code error anomaly diagnosis workow task user easily identify execution correspond workow discover error aer instance destroyed successfully delete instance error cleanup aer destroy VM discussion previous focus construct  multiple execution task approach temporal dependency construct workow pairwise invariant identied  workow model input sequence limitation sequence contains multiple task concurrent thread task address task separation methodology useful insight towards workow construction task evaluation DeepLog implement kera tensorflow backend evaluation component overall performance DeepLog eectiveness nding anomaly data execution anomaly detection focus evaluate anomaly detection model DeepLog rst eectiveness previous investigate impact dierent parameter DeepLog previous previous purpose anomaly detection procedure rst extract message perform anomaly detection sequence principal component analysis pca assumes dierent session easily identied session  entry rst session appearance inside session session vector appearance session matrix session vector pca detects abnormal vector session projection residual subspace transform coordinate approach eective online counterpart session insight CCS october november dallas TX usa online pca reduce false positive clearly oine cannot online anomaly detection implementation source invariant mining IM construct matrix pca approach IM rst invariant  majority vector treat vector satisfy invariant abnormal execution session approach eective earlier utilizes workow automaton implementation  tfidf developed although objective failure prediction dierent anomaly detection nevertheless evaluation lstm approach ere dierences tfidf dened user parameter model epoch TF idf frequency inverse document frequency vector laplace smooth procedure knowledge epoch hence entire tfidf construct lstm model binary classier label normal abnormal data training anomaly entry obtain anomaly training data detect contrast DeepLog lstm model multi classier normal data  specically multi user openstack workow model openstack  task workow anomaly detection  achieves acceptable performance openstack precision recall report hdfs paerns irregular  model session hdfs satisfy criterion furthermore cannot entry dierent task sequence relies multiple  achieve purpose data hdfs data generate hadoop reduce amazon EC node label hadoop domain expert entry abnormal exception data  oine pca subsequently online pca IM detail dataset openstack data deployed openstack version   node network node compute node entry abnormal script constantly execute VM related task VM creation deletion pause  suspend resume VM task schedule paern regular expression pause  suspend resume delete VM cycle VM VM delete task pause  suspend resume randomly within cycle info nova api nova scheduler nova compute analysis elastic stack ree anomaly inject dierent execution neutron timeout VM creation  error destroy VM  error cleanup aer destroy VM execute pca IM entry dierent session  eld hdfs openstack instance session cycle VM instance respectively parse entry DeepLog apply directly subsequently detect anomaly appearance distinct within session matrix distinct session vector vij matrix session DeepLog normal entry model hdfs normal session session parse rst entry training DeepLog pinpoint entry correspond abnormal compete session granularity anomaly detection session abnormal session exists detect abnormal summarizes data pca IM unsupervised oine training data whereas DeepLog training data normal execution tfidf normal abnormal data session data training data data hdfs normal normal abnormal abnormal openstack normal normal abnormal abnormal data session addition false positive FP false negative FN standard metric precision recall precision TP TP FP TP positive percentage anomaly anomaly detect recall TP TP FN percentage anomaly data assume truth detect precision recall precision recall harmonic default parameter DeepLog investigate impact recall decides  prediction output normal probability normal training detection denote layer DeepLog memory lstm respectively explore session insight CCS october november dallas TX usa pca IM tfidf gram DeepLog false positive FP false negative FN fps FNs hdfs parameter report  unless otherwise specied performance gram comparison false positive false negative hdfs data pca achieves false positive price false negative depth comparison recall precision tfidf  gure limited relative performance clearly DeepLog achieve overall performance baseline gram achieves performance performance dramatically becomes longer contrast lstm approach stable investigates approach DeepLog prediction algorithm predict DeepLog actual data impact strategy cdf dierent label normal predict DeepLog prediction exactly within DeepLog prediction normal within meanwhile anomaly detection rate anomalous session undetected performance openstack data pca approach reasonable performance data precision whereas IM achieve perfect recall precision almost VM instance detect abnormal execution openstack generate randomly described cycle VM dened delete uncertain really IM stable invariant anomaly detection hypothesis generate data deterministic paern delete normal VM execution anomalous denote data openstack II IM performs data regular paerns however recall pca normal paern data regular render pca detects anomaly variance DeepLog demonstrates excellent performance openstack respectively lastly important pca IM oine cannot perform anomaly detection per entry detect anomaly session notion session exist analysis DeepLog investigate performance impact various parameter DeepLog varied parameter default others precision recall accuracy hdfs pca IM gram DeepLog cumulative probability prediction evaluation hdfs precision recall accuracy openstack precision recall accuracy openstack II pca IM gram DeepLog evaluation openstack performance DeepLog fairly stable respect dierent sensitive adjustment combination parameter DeepLog easy deploy fairly intuitive understand precision recall adjust achieve positive rate false positive rate lastly DeepLog prediction per entry around millisecond standard workstation improve beer hardware gpu layer memory prediction normal precision recall DeepLog performance dierent parameter parameter performance anomaly evaluate eectiveness DeepLog detect parameter performance elapse entry session insight CCS october november dallas TX usa anomaly openstack VM creation task data anomaly performance anomaly arrival entry parameter anomaly entry longer VM creation others setup deployed openstack  script simulate multiple user constantly request VM creation deletion openstack VM creation important procedure image controller node compute node VM simulate performance anomaly possibly dos aack  network controller compute node dierent anomaly detect DeepLog anomaly detection described entry model training validation apply model generate gaussian distribution MSEs error subsequent online detection phase incoming parameter vector DeepLog mse predication output vector model within acceptable condence interval gaussian distribution MSEs validation detection parameter vector dierent axis VM dierent VM creation instance axis mse parameter vector prediction output vector DeepLog horizontal gure condence interval threshold correspond mse gaussian distribution parameter vector normal entire illustrate parameter vector successfully detect abnormal exactly instance  network inject anomaly abnormal parameter vector detect   prediction identify abnormal feature abnormal parameter vector due unusually elapse instance surprisingly abnormal parameter vector unusually online update training DeepLog demonstrate DeepLog training entire user feedback training phase execution detection stage normal detect anomalous reected training data address issue evaluates eectiveness DeepLog online update training module described demonstrate dierence detection without incremental update eectiveness eciency data data gene supercomputer contains  data  org  data VM mse CI CI CI VM mse CI CI CI VM mse CI CI CI VM mse CI CI CI anomaly detection parameter vector condence interval CIs entry entry label anomaly chose data important characteristic specic training data normal alone normal execution paerns evaluation conduct rst normal entry training data rst entry training  remain entry anomaly detection precision recall dataset training precision recall dataset training without online training online training evaluation gene without online training without online training DeepLog incoming entry without incremental update online training assume user report detect anomaly false positive DeepLog sample label update model paern without online training oine training data false positive hence precision rate  increase training data slightly increase precision performance unsatisfactory DeepLog online training signicantly improves precision hence positive rate perfect recall  online training reduces false positive session insight CCS october november dallas TX usa rate training data training data respectively amortize entry online training report detection online update update trigger online update training increase amortize per entry slightly entry trigger update online update online detection execute parallel update model perform detection amortize entry training data percentage without online training millisecond online training millisecond security anomaly normal training error exception message easy detect DeepLog eectively detect subtle hdfs namenode update aer delete anomaly session redundant  anomaly extra aack behavior reected detect investigate aacks demonstrate eectiveness DeepLog network security network security vital importance  intrusion detection IDS online anomaly detection performance DeepLog network security vast challenge data specically mini challenge computer networking operation challenge manually suspicious activity visualization technique truth anomalous activity anomaly truth DeepLog suspicious activity detect rst appearance undocumented computer IP address vast challenge network security detection suspicious activity detect denial service aack anomaly IDS scan anomaly IDS scan anomaly IDS scan anomaly IDS socially engineer aack anomaly  undocumented IP address false positive DeepLog report message repeatedly anomaly due suddenly become bursty message identied vast challenge suspicious activity BROP aack detection blind return orient program BROP aack leverage server application restart aer crash ensure service reliability aack powerful practical aacker neither relies access source code binary stack buer  vulnerability server crash sucient aack BROP exploit aacker server crash signal rop aack achieves execute shellcode however server restart activity atypical message kernel easily detect DeepLog nginx  error nginx nginx  error nginx nginx  error nginx task separation workow construction implement propose evaluate various openstack VM related task lstm approach density cluster approach successfully task rst lstm supervise training data cluster occurrence within distance threshold unsupervised hence training parameter distance threshold specically density cluster approach   threshold separation task cannot background entry random location entry task apart VM creation workow useful diagnosis performance anomaly recall parameter vector anomaly identied elapse parameter instance anomaly detect DeepLog instance abnormal elapse previous investigate workow model construct DeepLog previous image VM creation longer image investigation procedure reveal network node compute node related primarily notable debug  informative exist practically computer valuable resource investigate status however largely compose diverse freeform text analytics challenge numerous mining dierent approach accurate limited specic application scenario domain expertise  session insight CCS october november dallas TX usa instance attempt memory disk vcpus cpu instance successful instance http status len instance image instance VM lifecycle instance VM pause lifecycle instance VM resume lifecycle instance instance openstack VM creation workow  potential security threat unsupervised cluster data specic feature manually label outlier  belief propagation detect stage enterprise infection dns  specically performance mining service specialized feature predicate combination DeepLog approach rely domain specic knowledge generic anomaly detection typically apply procedure parser parse entry structure typically message parameter timestamps discard  entry anomaly detection perform sequence typical generate numeric vector session counting unique sophisticated approach TF idf matrix comprise vector amenable  unsupervised anomaly detection principal component analysis pca invariant mining IM construct matrix oen oine entry anomaly detection session refer reader overview comparison supervise normal abnormal vector binary classier detects future anomaly downside unknown anomaly training data detect furthermore anomalous data obtain training evaluation portion normal data DeepLog achieve online anomaly detection beer performance moreover DeepLog timestamps parameter anomaly detection previous workow construction largely extract oine workow oers limited advantage anomaly detection instead utility  aid diagnosis however assumes model contains execution task propose automatically dierent task workow model dierent task besides  perform anomaly diagnosis  diagnosis performance issue problematic normal  cluster organizes historical future  stitch extract dierent  web interface user visually monitor progress session performance diagnosis purpose anomaly detect cannot anomaly detection conclusion DeepLog purpose framework online anomaly detection diagnosis neural network approach DeepLog learns encodes entire message timestamp parameter performs anomaly detection per entry per session previous limited DeepLog dierent task construct model task lstm classic mining density cluster approach enables eective anomaly diagnosis incorporate user feedback DeepLog online update training lstm model hence incorporate adapt execution paerns extensive evaluation clearly demonstrate superior eectiveness DeepLog previous future limited incorporate rnns recurrent neural network DeepLog eciency integrate data dierent application perform comprehensive diagnosis failure mysql database disk failure reected