recently become hugely popular machine ability feature classifier simultaneously significant improvement classification accuracy presence highly structure database due combination recent algorithmic breakthrough increasingly powerful computer access significant amount data researcher privacy implication model typically centralize manner data training algorithm data collection user private data habit personal geographical centralize server access sensitive information potentially  tackle collaborative model recently propose locally structure subset parameter attempt respective training private parameter obfuscate via differential privacy DP information extraction challenge propose shokri shmatikov CCS unfortunately privacy preserve collaborative susceptible powerful attack devise distribute federate decentralize approach fundamentally broken training honest participant attack developed exploit allows adversary generative adversarial network gan generates prototypical sample target training private sample generate gan intend distribution training data interestingly differential privacy apply parameter model previous ineffective DP address attack CCS CONCEPTS security privacy privacy preserve protocol distribute security software application security keywords collaborative security privacy algorithm data andrew taught introduction machine neural network concept date variety complex task neural network inspire brain learns distribute artificial neural network nontrivial task architecture procedure brain behavior algorithmic breakthrough feasibility amount data increase computational contribute popularity neural network multiple hidden layer indeed outperform previous machine technique unlike conventional machine approach feature engineering input model extract relevant feature defines feature relevant model perform extremely correlate data contribute substantial improvement computer vision image processing video processing recognition recognition text processing component complex diagnose classify disease however severe privacy implication associate model incorporates essential information training relatively straightforward extract sensitive information model depict user local datasets private information respective device cooperate discriminative machine classifier upload datasets location depict service operator model combine datasets session machine privacy CCS october november dallas TX usa centralize collaborative approach distribute link data user server server compromise privacy data link model parameter malicious user employ gan deceive victim release private information centralize approach effective model access data privacy preserve operator access sensitive information adopt collaborative algorithm illustrate participant local model device user parameter model exchange parameter service operator model almost accurate model built centralize approach decentralize approach privacy friendly datasets expose directly experimentally converge percentage model parameter parameter truncate obfuscate via differential privacy training data user update parameter epoch community recently propose generative adversarial network gans intensively developed goal gans classify image category generate sample training ideally distribution importantly gans generate sample without access sample gan interacts discriminative neural network distribution data devise powerful attack collaborative gans attack user insider infer sensitive information victim device attacker simply collaborative algorithm reconstructs sensitive information victim device attacker influence deceive victim release detailed information attack without compromise service operator model parameter obfuscate via differential privacy depict centralize server player compromise privacy data user intentionally compromise user distribute undesirable contribution propose implement novel active inference attack neural network collaborative effective exist information extraction mechanism namely contribution devise attack distribute gans gans typically implicit density estimation application gans maliciously attack generic effective information extraction mechanism approach employ convolutional neural network cnn notoriously model inversion attack introduce notion deception collaborative adversary  victim release accurate information sensitive data attack devise effective parameter obfuscate via differential privacy emphasize attack differential privacy propose collaborative differentially private training apply differential privacy ineffective collaborative notion privacy REMARKS devise attack generic effective information extraction mechanism generative adversarial network gans propose implicit density estimation gan detailed generates sample training pit generative neural network discriminative neural network generative successful whenever discriminative model cannot sample gan training important realize discriminative generative network influence session machine privacy CCS october november dallas TX usa discriminative algorithm gan generate sample sample gan generate realistic sample ideally distribution data gan actual training relies information discriminative model facial composite image police identify suspect composite artist generates sketch  discriminative description suspect composite artist gan actual image feedback  gans extract information honest victim collaborative framework gan creates instance suppose private gan training phase collaborative attack effective convolutional neural network notoriously invert parameter obfuscate via differential privacy granularity propose access model attacker internal parameter model contrast access attacker output model input limitation procedure purpose collaborative parameter percentage distribute participant apply model inversion attack model surprising malicious participant model evolves influence honest participant release relevant information private datasets ability deceive honest user unique attack furthermore truncate obfuscate parameter attack effective accuracy local model emphasize however attack violate differential privacy DP define database issue collaborative DP apply parameter model granularity however parameter ultimately model becomes accurate attack whenever model accurately classify generate representative DP apply recovery specific associate label indeed phase attack regard privacy violation victim device contains standard medical gan generate generic medical item distribution training attacker privacy violation however victim device contains patient cancer attacker  patient cancer context privacy violation victim device contains  image gan generate scene simulated information leak adversary significant attack useful enforcement official adversary instance victim device contains   image training terrorist victim device contains recording gan generate  fictitious comparable WaveNet network without text sequence privacy violation however infer english chinese speaker male female leak information constitute privacy violation victim device contains image alice gan generate resemble alice composite artist generates sketch  memory alice attack framework adversary drawing alice falsely eve local model within victim device release relevant distinctive detail alice exacerbate leakage however privacy violation others disagree adversary recover alice reconstruction alice information leak constitute privacy violation context DCGAN cifar dataset target consist approximately image various label  obvious reference image gan adversary  airplane likely differential privacy collaborative recovery specific training namely adversary cannot training threshold circumvent protection generate indistinguishable along image generate gan image violate DP clearly severe privacy violation  DP inadequate context secure encryption chosen plaintext attack cpa inadequate active adversarial environment DP per cpa secure encryption clearly DP information theoretic protection important granularity sensitive information collaborative active adversary DP granularity user device propose researcher argue DP DP suppose ultimately context session machine privacy CCS october november dallas TX usa alice victim phone gan reconstruction training essentially indistinguishable gan generate sample cifar dataset casual user recover image effectively indistinguishable folder collaborative privacy desirable centralize approach suppose improve upon centralize service provider violate user privacy collaborative user violate privacy user without involve service provider impact google adopts centralize approach usage information android device centralize database machine algorithm google recently introduce federate enable mobile device collaboratively prediction model training data local device model google server improve local data federate collaborative attack equally effective device model google server gan successfully local model federate individual model update differential privacy google proposes secure aggregation protocol update individual user device securely aggregate leverage secure multiparty computation mpc compute average model parameter google server decrypt user participate mechanism described ineffective attack architecture simply rely local model successfully security model considers google adversary  individual update therefore casual user attack user federate potentially dangerous centralize suppose replace indeed assessment description announcement research access actual implementation tend improve significantly apply differential privacy within crowdsourced framework future version iOS detail serf warn risk apply differential privacy improperly collaborative adversary service provider regular user target another user celebrity politician related proven successful various computer capability relevant information quantity data option cyber security domain however unique attack emerge serious threat privacy information attack machine model knowledge extract unexpected information model release arxiv author devise meta classifier hack machine classifier infer sensitive information training instance extract ethnicity gender information recognition later extend propose model inversion attack machine algorithm exploit confidence information reveal model instance apply facial recognition reconstruct image label adversary recently  steal machine model consideration prediction model membership inference attack developed adversary access model infer originally training session machine privacy CCS october november dallas TX usa infer reveal identity blur image adversarially craft input fed model prone error model misclassify input therefore incorrect output subtly modify classify another model extend privacy preserve machine defense mechanism powerful adversary devise shokri shmatikov author introduce concept distribute privacy training data model multiple entity collaboratively model gradient individual model parameter server distribute training neural network preserve privacy participant however deploys secure multiparty computation server model client outsource computation untrusted non collude server however shokri shmatikov privacy preserve purpose practical alternative costly multi computation mpc technique google developed technique model smartphones directly without transfer sensitive data data microsoft developed CryptoNets perform encrypt data encrypt output user developed data oblivious machine algorithm trust processor differential privacy important role differential privacy differential privacy DP introduce  aim provable privacy guarantee database without significant query accuracy loss differential privacy data adopt DP efficient defense mechanism collaborative propose shokri shmatikov DP obfuscate parameter propose apply DP parameter training DP auto encoders covert channel however defeat DP database privacy cannot guaranteed auxiliary information outside DP model accessible adversary  DP granularity effective scenario data social data mobile data medical correlation DP granularity DP violate privacy preserve collaborative centralize approach multiple participant pool datasets central training model serious privacy threat shokri shmatikov  participant willing collaborate security privacy issue described shokri shmatikov introduce collaborative approach allows participant model without explicitly training data exploit optimization algorithm stochastic gradient descent sgd parallelize execute asynchronously approach selective parameter combine local parameter update sgd participant local model gradient parameter server PS participant uploads downloads percentage recent gradient avoid stuck local minimum participant advance network architecture blur parameter PS various upload percentage gradient participant parameter threshold within noisy agreement differential privacy procedure background supervise machine algorithm label data classifier regressor accurately predict label instance machine algorithm inductive principle data distribution training independent identically distribute sample optimization accurate classifier arg min machine input estimate label loss function error misclassifying regularizer independent training data avoids overfitting supervise algorithm vector machine SVMs random gaussian gps neural network depict framework neural network become weapon choice machine database highdimensional strongly correlate input significant accuracy gain improvement additionally feature classifier dealt dimensional strongly correlate input image humanly engineer feature built reduce dimensionality session machine privacy CCS october november dallas TX usa correlation fed classifier choice neural network revolution feature humanly engineer data cod feature relevant information optimal available data neural network learns useful feature instead rely neural network structure exploit correlation input feature ideal optimal classification structure extract feature stage local feature layer global feature layer accurate prediction layer become evident datasets grown richness machine summarizes training database estimate parameter machine estimate parameter relevant feature training database training recover adversary feature training data access machine SVMs prototypical  gps training challenge adversary prototypical classifier neural network relation  training subtle researcher privacy possibility network model inversion attack proven recover input image training leak information adversary neural network unprocessed input attack recover prototypical input important emphasize intrinsic machine algorithm algorithm accurate classification adversary access model obtain information adversary access model recover prototypical sensitive private information classifier perform optimally machine potentially leak information adversary cannot machine learns successfully data private limitation model inversion attack model inversion attack network gradient adjust network obtain reverse engineer network prior information recover prototypical attack accurate machine leak information distinguish moreover model inversion attack recover prototypical resemblance actual data define due structure machine input classify accuracy something adversary recover sensitive information meaningless information refer reader training image bus temple soap   slightly  classify    image author procedure model inversion attack randomly generate image plus gradient information belief network random image classify airplane structure neural network flexible fool accurate label image model inversion attack obtain private information neural network  input input define extensive research ML community gan generate sample training data attack reveal sensitive information training data average sample aggregate information model inversion attack generative adversarial network address highlight generate training image portion accomplish generative adversarial network gans gan procedure pit discriminative network generative network discriminative network distinguish image database generate gan generative network initialize random iteration mimic image training discriminative network optimization gan procedure summarize min max image data randomly generate image pixel distribute uniformly discriminative neural network image label denote parameter generative neural network random input image training procedure compute gradient maximize performance discriminative neural network hence distinguish sample data sample generate generative structure fake compute gradient sample generate fake perfect replica data generate data data session machine privacy CCS october november dallas TX usa procedure discriminative network unable distinguish sample database sample generate generative network author theorem theorem global minimum virtual training criterion achieve theorem adversarial gan generate image dataset author infinite sample limit generative network sample training distribution recognizes gan procedure converge recent author significantly improve training gan feature improve convergence density model threat model threat model relies active insider adversary pretend honest participant collaborative protocol extract information data adversary surreptitiously influence deceive victim release detail target adversarial influence attack effective instance apply model inversion attack model furthermore attack model gan implement model inversion attack notoriously ineffective convolutional neural network specifically scenario adversary insider within privacy preserve collaborative protocol objective adversary infer meaningful information label adversary compromise central parameter server PS distributes parameter participant parameter server service provider adversary adversary  insider service provider adversary active directly manipulates gan locally protocol specification victim adversary parameter selection procedure uploads downloads amount gradient advance obfuscates uploaded parameter collaborative assume participant advance objective implies adversary knowledge model structure data label participant unlike static adversary model inversion adversary adaptive progress adversary influence participant specially craft gradient trick participant leak information local data distribute procedure successful PROPOSED attack adversary participates collaborative protocol participant advance objective neural network architecture label training another participant victim declares label adversary declares label information goal adversary infer useful information insider employ gan generate instance sample victim insider injects fake sample distribute procedure victim harder distinguish hence reveal information intend insider mimic sample victim improve knowledge ignore training gans devise density estimation distribution data output classifier without data directly deceive victim information unknown insider simplicity player adversary victim extend attack strategy account multiple user player declare label overlap assume participant establish structure goal declares label label collaborative protocol epoch model parameter server PS local model accuracy threshold victim network downloads percentage parameter PS update local model local model uploads selection parameter local model PS adversary network downloads percentage parameter PS update local model local generative adversarial network unknown victim mimic victim generates sample gan label local model session machine privacy CCS october november dallas TX usa gan attack collaborative victim model image image adversary image label gan fool victim release information attack easily generalize user adversary sample uploads selection parameter local model PS iterate convergence highlight extra adversary perform target label procedure depict generalization attack multiple user report algorithm gan attack local model improves accuracy another important gan attack differential privacy obfuscation technique employ attack differential privacy propose collaborative degradation quality obtain model gan improve exist setup attack thwart achieve privacy guarantee release parameter establish tighter threshold however model unable perform model centralize data attack effective differential privacy deployed generative discriminative synergistic relies accuracy discriminative model actual gradient experimental setup author source code implement distribute collaborative attack implementation differential privacy datasets conduct datasets namely mnist dataset  dataset mnist dataset image mnist benchmark dataset choice application consists handwritten grayscale image digit image pixel dataset consists training data data dataset  dataset dataset previously consists grayscale image version consists image pixel dataset contains image namely image per conduct pre processing data processing perform data image adopt generator model hyperbolic tangent tanh activation function layer output framework torch scientific compute framework torch widely framework efficient construction model thanks  script  architecture convolutional neural network cnn architecture mnist layer network sequentially attach another http nyu edu  data html http torch http  org http  org session machine privacy CCS october november dallas TX usa algorithm collaborative training gan attack pre training phase participant advance architecture model label etc declares label label rate parameter upload percentage parameter threshold gradient selection bound gradient training procedure sequential asynchronous parameter upload criterion training phase epoch  enable user training user downloads parameter PS replace respective local parameter user local model newly user adv  replica local  model discriminator generator target unknown adversary update sample generate assign label fake label generate sample merge generate data local dataset adversary sgd local dataset update local model compute gradient vector   upload parameter PS return collaboratively model training adversary prototypical member victim sequential container layer fully manner mnist model consists convolution layer  tanh function apply output layer max pool layer  convolutional layer convolution kernel input output whereas convolutional layer input output convolution kernel max pool layer data reshaped tensor linear transformation apply input tensor output tensor tanh activation function apply output another linear transformation input tensor output tensor modify http github com torch blob doc container sequential output layer output adversary generate  fake image detail layer model  layer  tmax image dataset therefore built convolutional neural network consist convolution layer max pool layer fully layer mnist architecture tanh activation function model output layer namely data adversary reconstruction harder reconstruct implement algorithm differently generator query discriminator per epoch adversary training data batch improve faster generator architecture mnist related consist convolution layer correspond  torch library batch normalization  apply output layer activation function rectify linear function relu layer model hyperbolic tangent function tanh output image additional convolution layer convolution layer compute automatically technique input dimensional uniform distribution convert image mnist image initialize generator standard deviation applies initialization function model participant architecture described torch refer reader appendix detail architecture torch hyperparameter setup mnist related rate collaboratively model discriminator model rate decay momentum batch related rate batch whereas concern multi participant scenario batch hyperparameters mnist rate stochasticity model converge faster author DCGAN  optimizer rate momentum torch implementation DCGAN modify stochastic gradient descent sgd configuration rate generator session machine privacy CCS october november dallas TX usa EXPERIMENTS evaluate gan procedure recover participant focus mnist datasets image principle however adversarial strategy extend data audio medical etc gan attack model inversion traditional mention model inversion limitation effective neural network theoretical perspective experimental evidence gan attack distribute adversary oblivious content label parameter neural network uploaded parameter server gan attack deploy differential privacy obfuscate model parameter ineffective attack efficacy gan limited accuracy discriminator MI attack gan attack model inversion MI gan attack data adversary access fully model MI attack convolutional neural network training mnist dataset apply model inversion attack neural network however instead approximate derivative gradient compute model input label MI mlp network clearly fails cnns consistent author attain MI effective complicate structure relevant information network gradient input representative data recover gan approach adopt DCGAN architecture torch implementation model consists discriminator combination DCGAN generator generator model compatible mnist image propose code automatically calculate convolution layer refer reader detail architecture per mnist dataset model accuracy significant difference gan attack generative model discriminative model MI discriminative model access training phase however access model attack applicable collaborative actual image mia DCGAN obtain model inversion attack mia generative adversarial network DCGAN cnn mnist dataset mia fails DCGAN successful gan attack collaborative without differential privacy gan attack collaborative environment propose model described depict mnist instead label per user label user label user user access image label user adversary access image label adversary sixth extract information label user retrieve image actual training image user image closest norm parameter setting user upload entire model user session machine privacy CCS october november dallas TX usa gan attack user scenario sample generate gan sample training closest generate gan parameter upload upload upload collaborative participant honest user respective model distinct adversary local data gan adversary device reconstruct victim device DP enable experimental dataset DP unlike mnist image noisier dataset accuracy model significantly affected upload rate model upload parameter epoch finally upload perform dataset consists participant scenario victim adversary assign user remain adversary extra adversary influence training configuration upload rate adversary considerably reconstruction target image noisier others hardly improve accuracy model tends dataset implement multi participant scenario participant honest adversarial honest participant posse image pertain training data adversary training data namely adversary image generator differential privacy enable gan attack influence influence collaborative fake label collaborative recall image generate generative model artificial trick victim release finer detail target adversarial influence experimentally confirm remarkable faster information retrieve adversary significantly accuracy model collaboratively training cnn model datasets adversary victim label passive gan attack standard gan attack propose recover respectively user image passive attack influence image standard procedure influence artificial session machine privacy CCS october november dallas TX usa epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch DCGAN influence influence collaborative zero epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch epoch DCGAN influence influence collaborative experimental dataset DP enable unlike mnist image noisier dataset accuracy model significantly affected upload rate gan attack mnist dataset image generate DP setup accuracy model increase gan fails adversarial influence evident image clearer  epoch per participant gan attack dataset image generate DP setup accuracy model increase gan fails accuracy model session machine privacy CCS october november dallas TX usa gan attack user scenario differential privacy enable sample generate gan sample training closest generate gan gan attack differentially private collaborative argue differential privacy parameter model ensure parameter update leak information individual training dataset quote author passive adversary rely differential privacy mitigate leakage parameter update highlight potential leakage gradient selection perform actual gradient address issue approach relies sparse vector technique epoch iteration collaborative define privacy budget participant budget split gradient per epoch portion gradient randomly threshold dedicate selection parameter remain release rely laplacian mechanism selection parameter agreement allocate privacy budget demonstrate differential privacy ineffective active adversary collaborative participant differential privacy enable datasets participant distinct mnist plus artificial introduces dataset plus artificial subsection rate fix threshold privacy budget per parameter upload rate longer model converge differential privacy constraint demonstrate training successful model converge generate differential privacy questionable however local model unable collaborative fails completely consistent report indeed tighter privacy constraint generator fail local model unable tighter privacy bound translates differential privacy guarantee gan ineffective local model parameter server unable collaborative technique digit however stress attack independent whatever DP implementation gan generate sample discriminator CONCLUSIONS propose implement novel active inference attack neural network collaborative approach relies generative adversarial network gans effective exist information extraction mechanism significant impact distribute federate decentralize approach privacy user research collaborative desirable centralize approach suppose replace collaborative user violate privacy user without involve service provider finally devise effective countermeasure attack rely secure multiparty computation fully homomorphic encryption however privacypreserving collaborative introduce avoid costly cryptographic primitive explore susceptible session machine privacy CCS october november dallas TX usa attack another approach differential privacy granularity user device DP attack devise however collaborative device user DP user behave data unpredictable therefore future