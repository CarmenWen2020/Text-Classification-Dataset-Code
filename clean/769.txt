federate facilitates collaborative training model without raw data however recent attack demonstrate simply maintain data locality training sufficient privacy guarantee federate capable prevent inference message exchange training model ensure model acceptable predictive accuracy exist federate approach secure multiparty computation smc vulnerable inference differential privacy accuracy relatively amount data alternative approach utilizes differential privacy smc balance offs combine differential privacy secure multiparty computation enables reduce growth injection increase without sacrifice privacy maintain pre define rate trust therefore scalable approach protects inference threat model accuracy additionally variety machine model validate experimental machine algorithm demonstrate approach performs CCS CONCEPTS security privacy privacy preserve protocol trust framework compute methodology setting keywords privacy federate privacy preserve machine differential privacy secure multiparty computation introduction traditional machine ML environment training data centrally organization execute algorithm distribute extend approach node access data data participate node central node fully trust mllib apache spark assumes trust central node coordinate distribute another approach parameter server fully trust central node aggregate parameter node datasets however scenario address trust boundary particularly multiple organization involve dataset improves performance model organization cannot data due legal restriction competition participant hospital owner hospital predictive model forecasting cancer risk patient hospital model patient population however privacy prohibit patient data similarly service provider usage data europe united due legislative restriction service provider data cannot central location predictive model forecasting service usage however datasets federate FL address restrictive environment wherein data holder collaborate throughout rely trust data data holder FL machine algorithm locally exchange model parameter aggregate redistribute central entity however approach sufficient reasonable data privacy guarantee information infer information trace source model previous propose trust aggregator privacy exposure FL scheme local differential privacy address privacy entail model parameter data node yield performance model propose novel federate formal privacy guarantee account various trust scenario model increase accuracy exist privacy preserve approach data leaf participant privacy guaranteed secure multiparty computation smc differential privacy account potential inference individual participant risk collusion amongst participate customizable trust threshold contribution propose implement FL formal privacy guarantee model improve accuracy exist approach tunable trust parameter account various trust scenario maintain improve accuracy formal privacy guarantee demonstrate propose approach variety ML model experimental evaluation significantly ML model decision convolutional neural network linear vector machine federate approach private accurate training neural network model organize outline building discus various privacy consideration FL outline threat model experimental evaluation discussion implementation finally overview related conclude remark PRELIMINARIES introduce building approach explain various approach fail data privacy FL differential privacy differential privacy DP rigorous mathematical framework wherein algorithm described differentially private inclusion instance training dataset statistically insignificant algorithm output private medical information hospital author access ML model attacker infer individual patient hospital violate privacy DP theoretical limit influence individual limit attacker ability infer membership formal definition DP definition differential privacy randomize mechanism differential privacy database entry ranдe satisfy differential privacy achieve DP algorithm output proportional sensitivity output sensitivity maximum output due inclusion data instance popular mechanism achieve DP laplacian gaussian mechanism gaussian define normal distribution standard deviation application gaussian mechanism function sensitivity satisfies differential privacy exp achieve differential privacy laplace mechanism manner substitute random variable drawn lap algorithm multiple additive mechanism evaluation privacy guarantee composition theorem advanced composition theorem extension threshold homomorphic encryption additively homomorphic encryption scheme wherein guaranteed enc enc enc predefined function scheme popular privacy preserve data analytics untrusted perform operation encrypt additive homomorphic scheme paillier cryptosystem probabilistic encryption scheme computation rsa modulus author extend encryption scheme propose threshold variant threshold variant participant secret subset pre define threshold decrypt privacy federate centralize environment dataset executes algorithm model access dataset contrast federate environment multiple dataset respectively goal model datasets potential threat data privacy FL environment inference inference output inference refers participant federation infer information another participant private dataset data exchange session machine security aisec november london united kingdom execution inference output refers leakage participant data intermediate output inference attack insider outsider insider attack launch participant FL data holder outsider attack launch eavesdropper communication participant user predictive model deployed service inference combination computational operation query knowledge data query execution respond query appropriate information query highly dependent decision query request instance criterion contrast svm neural network query request model parameter training iteration privacy preserve FL account risk inference response query privacy preserve ML approach address risk secure multiparty computation smc generally smc protocol obtain output function input prevent knowledge anything output unfortunately approach exclusively secure multiparty computation remain vulnerable inference output function output remains unchanged function execution without privacy output reveal information individual input therefore potential inference output inference output refers intermediate output available participant predictive model recent access model ML service api attacker training data inference FL prevent outsider attack insider participant infer information address privacy output DP framework preliminary mechanism satisfy differential privacy guarantee individual dataset remove output become significantly likely algorithm theoretically proven differentially private guaranteed privacy output quantify privacy parameter federate important definition database consistent DP definition privacy individual individual approach trust threat model propose wherein data ML service FL refer service aggregator withstand potential adversary aggregator data outsider honest curious aggregator honest curious semi honest adversarial model commonly smc introduction application data mining honest curious adversary protocol instruction correctly additional information therefore aggregator predetermine ML algorithm attempt infer private information data throughout protocol execution collude considers threat collusion aggregator trust parameter minimum non collude additionally contrast aggregator scenario deviate protocol execution achieve additional information data honest outsider potential attack adversary outside ensures adversary monitoring communication training cannot infer private data participant user model potential adversary predictive model output therefore deployed service remain resilient inference adversary user service detail assumption concretely formulate threat model communication assume secure channel aggregator allows aggregator authenticate incoming message prevents adversary outsider malicious data inject response additionally threshold variant paillier encryption scheme assume secure distribution sufficient within semantic security encrypt communication equivalent decisional composite  assumption discussion reader threshold variant paillier ensures cannot decrypt ciphertexts within context FL ensures privacy individual message aggregator propose approach propose FL address risk inference risk inference output trust combine smc DP develop protocol guarantee privacy without sacrifice accuracy scenario exists disjoint datasets belonging respective adhere structure aggregator additional input parameter specifies training algorithm privacy guarantee inference specifies minimum honest non collude aggregator algorithm consist linear query information datasets information model parameter local dataset session machine security aisec november london united kingdom overview traditionally query information individual criterion algorithm deployed information reflective analysis private local datasets correspond query outline secure channel aggregator query calculate response respective datasets participant differential privacy mechanism depends algorithm appropriate amount accord privacy budget allocate sensitivity trust noisy response encrypt threshold variant paillier cryptosystem homomorphic aggregate individual response subsequently query data decrypt aggregate update model conclusion model expose participant outline algorithm trust respect collusion addition threshold encryption scheme participant collude knowledge available infer data honest participant therefore introduce honest participant account collusion homomorphic encryption however allows significant increase accuracy local privacy approach detail strategy FL reduce smc component ability reduce leverage smc framework customizable trust parameter specifically respectively parameter sensitivity allocate budget algorithm traditional application differential privacy federate gaussian mechanism response query guarantee privacy however encrypt scheme propose threshold reduce factor return return enc aggregate response eventually decrypt expose algorithm private federate input ML algorithm data private dataset portion secret ski minimum honest non collude privacy guarantee asynchronously query sends encpk aggregate encpk selects asynchronously query encpk receives partial decryption ski computes partial decryption update return drawn gaussian distribution standard deviation equivalent decrypt strictly satisfy DP additionally encryption scheme guarantee maximum  cannot decrypt honest approach maintain customizable trust  formal privacy guarantee DP framework decrease amount query response accurate ML model experimental evaluation empirically demonstrate apply approach distinct model decision DT convolutional neural network cnn linear vector machine svm additionally analysis impact setting performance approach decision DT ID algorithm scenario dataset contains instance described categorical feature attribute aggregator initializes DT model node feature maximizes information gain chosen query node generate feature remove recursively node feature pre max depth response noisy deem meaningful specifically detailed algorithmic pseudocode participant query private federate DT execute query entire privacy budget equally layer accord composition differential privacy node within layer evaluate disjoint subset datasets accumulate privacy loss therefore budget allocate layer within node budget allocate allocate session machine security aisec november london united kingdom epsilon privacy approach local DP random uniform privacy budget overall decision leaf node evaluate attribute internal node internal node feature evaluate potential splitting dataset budget allocate evaluate attribute therefore amongst feature max depth dataset conduct  dataset uci machine repository dataset contains categorical attribute  application target attribute distinct distribution comparison model performance context random baseline FL approach random baseline enable characterize approach longer meaningful information FL approach visualize relative performance uniform approach prediction randomly sample random random improves upon uniform consideration distribution training data prediction sample training label local DP local approach privacy data isolation amount differential privacy dataset define privacy distribute algorithm without privacy guarantee variation setting setting impact privacy budget impact privacy budget performance isolate impact privacy budget assume collusion budget recall preliminary mechanism differentially private amount inversely proportional privacy budget query approach maintains privacy budget budget dip overwhelm information outcome pre   become inaccurate data privacy approach local DP random uniform increase overall decision degrade performance budget decrease approach maintains improve performance local DP approach budget approach converge random baseline particularly budget decrease approach maintain resilience decrease privacy budget another important consideration FL ability maintain accuracy highly distribute scenario amount data iot scenario contribute impact performance fix overall privacy budget assume collusion overall dataset partition demonstrate viability FL highly distribute environment highlight shortcoming local DP approach increase local DP approach increase proportionally approach maintains consistent accuracy local DP approach baseline dip random participant training data unencrypted encrypt decision training encryption another consideration relative participant overhead encryption highlight scalability impact encryption overall training increase entire steady increase participant increase impact encryption remains consistent distribute scenario interaction aggregator parallel therefore overhead encryption remains constant increase trust important trust parameter definition database within context differential privacy framework considers privacy session machine security aisec november london united kingdom epsilon untrusted exist approach epsilon exist approach epsilon approach epsilon approach epsilon query epsilon decision training rate trust epsilon define privacy budget query epsilon trust model adversarial knowledge within context entire trust parameter therefore adversarial knowledge capture maximum collude tolerate demonstrates distribution query private federate DT impact trust parameter scenario assumes collude approach converges exist local DP approach scenario query increase accurate outcome additionally aforementioned scenario trust unlikely exist instance smart phone user iot collusion impractical due likely without user additionally concerned collude honest participate therefore realistic scenario FL accuracy gain deploy convolutional neural network additionally demonstrate distribute differentially private cnn approach similarly centrally cnns model initial structure randomly initialize parameter conduct epoch locally conclusion batch gaussian introduce accord norm clip privacy parameter norm clip allows bound sensitivity gradient update privacy strategy centralize training approach entire epoch batch batch rate parameter average parameter sends update model another epoch predetermine epoch model output aggregator data specifically detailed algorithmic pseudocode within private federate NN approach differentially private respect epoch distribute privacy approach local DP central data holder privacy central data holder privacy convolutional neural network training mnist data randomly sample batch accountant approach DP overall dataset model structure cnn publicly available mnist dataset training instance handwritten digit instance grey image digit model structure model feedforward neural network internal layer relu softmax layer entropy loss layer contains layer contains norm clip rate batch rate kera tensorflow backend comparison knowledge approach accurately neural network private federate fashion without reliance public non data therefore approach baseline central data holder privacy approach data centrally privacy central data holder privacy data centrally entity data holder conduct privacy preserve representative scenario distribute privacy approach data distribute multiple local DP privacy data isolation adapt conduct epoch training privacy parameter central data holder privacy distribute data privacy achieve overlap model achieve central data holder approximately achieve approach significantly performs local approach additionally performance local approach update become overwhelmed additionally central data holder privacy local approach approach session machine security aisec november london united kingdom standard deviation distribution untrusted approach local differential privacy convolutional neural network training rate trust become respectively approach therefore demonstrates gain translates tighter privacy guarantee standard deviation significantly decrease scenario demonstrate encryption parameter approximately sec decryption pdec sec parameter encryption decryption completely parallel therefore overhead remains relatively constant parameter increase overall demonstrate significant accuracy gain FL local DP plausible scenario vector machine svm demonstrate ass approach classic regularize binary linear svm hinge loss linear svm private distribute fashion aggregator distributes model vector predefined epoch locally apply differential privacy perform norm clip feature vector obtain bound sensitivity gradient update gaussian gradient accord completes local training noisy encrypt aggregator aggregator average encrypt sends update model vector another epoch training predefined epoch detailed dataset publicly available gisette dataset NIPS feature selection challenge dataset training sample feature comparison contrast performance approach model central privacy centralize training without privacy central DP centralize training DP distribute privacy model federate without privacy local DP approach independently data accord rate setting epoch approach additionally epoch distribute privacy approach local DP central DP central privacy linear svm training FL epoch locally  report finding achieve accord evaluate training central privacy distribute privacy perform similarly around epoch due balance dataset privacy preserve approach central DP introduces achieves private FL approach achieves almost central DP significantly performs local DP epoch evaluate trust trust non collude approach outperform local DP specifically epoch approach local DP achieves experimental approach consistently performs ML model private FL fashion similarly approach consistently performs baseline random remain reasonably non private setting implementation development deployment machine training algorithm training broken query meaningful aggregation via summation query analyze privacy impact designate portion overall privacy budget additionally exist query private training algorithm implementation detail model evaluate decision neural network vector machine additional discussion applicability framework machine algorithm model application private decision training DT feature split training data split training data subset accord chosen feature subset subset predetermine uniformity respect target variable conduct private decision address feature split data define feature feature maximizes information gain metric ID session machine security aisec november london united kingdom algorithm private decision input data minimum honest non collude privacy guarantee attribute attribute max depth public define split node  return procedure  maxf asynchronously query decrypt aggregate noisy asynchronously query vector decrypt noisy return node label arg  update split node asynchronously query aggregate wise aggregate recover partial decryption recover partial decryption VF arg maxf VF node label  return procedure training algorithm information gain candidate feature quantifies difference entropy data sum entropy data subset generate chosen splitting feature entropy dataset subset compute via equation entropy potential indicates probability random instance therefore selection feature switch chosen via probability compute via query aggregator therefore sensitivity ability query aggregator iterative ensure differentially private accord pre define privacy budget approach budget iteration fix iteration purity algorithm relative meaningful information private algorithm deployed detailed algorithm application private neural network training deploy neural network distinct outline previous decision central neural network training randomly initialize model pre define structure dataset shuffle equally batch batch model iteratively loss function compute error model batch error propagate network optimizer stochastic gradient descent sgd update network processing batch constitute epoch model converges demonstrate improve performance query data epoch local conduct iteration sends update model aggregator aggregator average model update model along query another epoch algorithm private cnn aggregator input data minimum honest non collude parameter rate sample probability loss function clip epoch public initialize model random asynchronously query epoch decrypt aggregate noisy parameter return epoch receives parameter overall privacy budget privacy accountant utility decision replace pre depth neural network convergence replace pre define epoch aggregator perspective outline algorithm data deploy code detailed algorithm conduct epoch approach propose private centralize neural network traditional approach shuffle dataset batch batch randomly sample processing sample probability epoch becomes define batch iteration instance additionally parameter update loss function clipped define sensitivity neural network individual training instance update entire epoch update aggregator session machine security aisec november london united kingdom algorithm private cnn data procedure epoch parameter randomly sample probability max return encpk procedure application private vector machine training finally focus classic regularize binary linear svm hinge loss max feature vector label model vector regularize coefficient aggregator perspective specify algorithm svm training neural network training query data define epoch training query response model parameter average generate vector machine model model data another epoch training specify pre epoch training iteration algorithm private svm aggregator input data minimum honest non collude parameter rate loss function clip epoch epoch per query public initialize model random asynchronously query epoch decrypt aggregate noisy parameter return epoch data iterate instance local training dataset deploy clip approach constrain sensitivity update model parameter update accord loss function parameter conduct data epoch training response aggregator query outline algorithm expand algorithm repository beyond model evaluate approach extend differentially private machine algorithm federate environment demonstrate flexibility algorithm algorithm private svm data procedure epoch parameter max return encpk procedure significantly task generate deploy algorithm however non trivial DP version algorithm developed series query finally query appropriate aggregation procedure approach apply accurate federate private due choice threshold paillier cryptosystem conjunction aggregator complex smc protocol streamline interface aggregator data query encrypt noisy response decryption query partial decryption management global model communication aggregator therefore decrease barrier entry engage federate demonstrates impact choice approach effectively handle introduction federate without introduction increase encryption overhead another issue deployment machine training algorithm choice algorithmic parameter decision domain specific aim inform decision analysis offs privacy trust accuracy impact data training algorithm chosen reduce amount federate ML algorithm surround impact various data specific feature privacy budget algorithm specific algorithm demonstrates decision training feature impact privacy budget similarly algorithm role norm clip neural network svm neural network impact impact network feature related relates FL privacy preserve ML exist classify category trust aggregator local DP cryptographic trust aggregator approach trust aggregator obtain data plaintext propose differentially private ML distribute data scenario central author develop session machine security aisec november london united kingdom distribute data mining DP significant accuracy loss trust aggregator recently  ensemble approach private wherein teacher model independently local datasets trust aggregator DP query interface model unlabelled public data access private data obtains label query teacher propose federate FL approach wherein global model aggregate datasets  develops ensemble model independently model local datasets unlike evaluate  assumes fully trust aggregate teacher label focus scenario wherein data accurate model cellphone user training neural network assumes access publicly available data assumption FL model FL available data accurate model local model participant  demonstrates achieve reasonable accuracy local differential privacy distribute DP without central trust however DP guarantee per parameter becomes meaningless model parameter cryptographic approach protocol privately aggregate sum multiple protocol participant periodically upload encrypt oblivious aggregator minimum communication approach however participant statistic address FL propose FL additionally approach participant independently experimental participant fashion model accuracy approach unsuitable FL contrast approach reduces amount inject participant advantage additive DP threshold homomorphic encryption accurate model individual privacy author propose multiparty computation securely aggregate data FL focus suitable cryptographic technique ensure aggregation mobile environment author propose FL motivation developed detailed integration differential privacy secure aggregation remain beyond scope theoretical analysis differentially private computation federate instance operation secure function evaluation local model semi trust curator comparison multiple operation conduct FL empirical evaluation FL proposes perform differentially private database approach combine private intersection random pad cannot generally apply FL author protocol tailor inner counting array contrast propose accurate private FL predictive model training distribute generation scheme focus generate distribution scheme secret mpc mechanism extensive exchange message entail communication overhead viable federate setting proposes neural network private collaborative fashion combine mpc DP secret assume non collude honest contrast prevents privacy leakage actively collude approach private collection data aim recover computation however enables private federate allows checkpoint epoch training threshold cryptography enables decrypt subset participant available conclusion novel approach perform FL combine DP smc improve model accuracy preserve provable privacy guarantee extraction attack collusion threat approach apply ML model federate fashion trust scenario adherence DP framework guarantee overall privacy inference model output intermediate available smc additionally guarantee message exchange without DP protection reveal therefore leak private information privacy guarantee respect participant attacker model guarantee model safely deployed production without infringe privacy guarantee demonstrate apply approach variety ML model performs exist technique FL significant gain accuracy naïve application differentially private protocol FL tailor threat model propose private federate smc combination DP model accuracy demonstrate application combine technique maintain accuracy privacy approach ongoing social discussion privacy propose approach novel organization ML application model performance address privacy regulatory compliance