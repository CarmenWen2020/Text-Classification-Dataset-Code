potential various domain lack transparency limited application security safety critical exist research attempt develop explanation technique interpretable explanation classification decision unfortunately optimize non security task image analysis assumption violate security application explanation fidelity propose LEMNA fidelity explanation dedicate security application input data sample LEMNA generates interpretable feature explain input sample classify core approximate local complex decision boundary interpretable model local interpretable model specially handle feature dependency security application binary code analysis handle nonlinear local boundary boost explanation fidelity evaluate popular application security malware classifier function detector binary reverse engineering extensive evaluation LEMNA explanation fidelity exist addition demonstrate practical LEMNA machine developer validate model behavior troubleshoot classification error automatically patch error target model CCS CONCEPTS security privacy software reverse engineering keywords explainable AI binary analysis recurrent neural network introduction recent neural network potential security application researcher successfully apply neural network classifier malware classification binary reverse engineering network intrusion detection achieve exceptionally accuracy intrigue accuracy security practitioner concerned lack transparency model hesitate widely adopt classifier security safety critical specifically neural network easily neuron network massive datasets classification accuracy however complexity network interpretability model understand neural network decision lack transparency creates barrier establish trust model effectively troubleshoot classification error improve transparency neural network researcher explanation interpret classification exist focus non security application image analysis processing nlp input image explanation explains classification pinpoint impactful feature decision approach involve propagation backward propagation network infer important feature advanced explanation blackbox knowledge classifier detail available approximate local decision boundary linear model infer important feature unfortunately exist explanation directly applicable security application exist image analysis prefers convolutional neural network cnn however cnn model popular security domain security application binary  malware analysis feature dependency binary code sequence scalability recurrent neural network rnn multilayer perceptron model mlp widely explanation rnn exist suffer explanation fidelity validate acceptable image analysis serious security application highlight pixel entirely accurate sufficient intuitive understand however security application session 2D ML CCS october toronto canada binary analysis incorrectly highlight byte code serious misunderstanding interpretation error seek develop novel fidelity explanation dedicate security application introduces specialized address challenge input data instance classifier rnn aim identify feature contribution classification generate local approximation target classifier decision boundary significantly improve fidelity approximation longer assumes local detection boundary linear assume feature independent assumption exist model violate security application explanation fidelity instead introduce approach approximate non linear local boundary mixture regression model enhance fuse lasso insight mixture regression model theory approximate linear non linear decision boundary data flexibility optimize local approximation non linear boundary avoid fitting error fuse lasso penalty commonly capture feature dependency fuse lasso mixture regression model feature capture dependency adjacent feature fidelity explanation simultaneously preserve local nonlinearity feature dependency model convenience refer local explanation nonlinear approximation LEMNA evaluation demonstrate effectiveness explanation model apply LEMNA promising security application classify pdf malware detect function reverse engineer binary code classifier pdf file binary respectively achieve accuracy apply LEMNA explain classification develop series fidelity metric ass correctness explanation fidelity metric compute directly approximate detection boundary feature LEMNA significantly outperforms exist across classifier application setting beyond effectiveness assessment demonstrate security analyst machine developer benefit explanation LEMNA establish trust explain classifier decision binary malware analysis demonstrate classifier successfully heuristic golden respective domain illustrate LEMNA extract knowledge classifier heuristic manually summarize intuitive domain expert extract LEMNA finally LEMNA capability analyst explain classifier error allows analyst automatically generate target patch image classification worth price durability vacuum sentiment analysis machine explanation image classify orange due highlight pixel classify negative sentiment due highlight keywords augment training sample explainable error improve classifier performance via target training contribution contribution develop LEMNA specialized explanation security application mixture regression model enhance fuse lasso LEMNA generates fidelity explanation model rnn evaluate LEMNA popular security application pdf malware classification function detection binary reverse engineering propose series fidelity metric quantify accuracy explanation LEMNA outperforms exist explanation significant margin demonstrate practical application explanation binary analysis malware detection LEMNA shed classifier incorrect decision automatically convert insight actionable patch target error classifier knowledge explanation specially customize security application rnn initial towards improve model transparency effective debug model decision interpretable effort positive contribution building reliable critical application explainable machine learning introduce background explainable machine discus exist explanation technique introduce security application model discus exist explanation technique applicable security application definition explainable machine seek interpretable explanation classification specifically input instance classifier classifier assign label explanation technique aim illustrate instance classify involves identify important feature contribution classification feature session 2D ML CCS october toronto canada interpretable analyst feature explanation image classification sentiment analysis classifier decision explain feature highlight pixel keywords focus neural network develop explanation security application exist explanation image analysis nlp categorize whitebox blackbox whitebox explanation exist explanation technique whitebox model architecture parameter training data technique refer explanation mainly cnn leverage strategy infer feature importance propagation input structure occlusion gradient backpropagation discus technique propagation input sample perturb input hidden network layer correspond intuition perturb important feature likely network structure classification output exist nullify subset feature remove intermediate network recent extends detect adversarial malicious input aim classification error backward propagation propagation leverage gradient neural network infer feature importance gradient partial derivative classifier output respect input hidden layer propagate output input directly calculate input feature image classifier compute feature saliency gradient output respect input pixel image video frame later improve apply saliency layer layer mapping pixel backward propagation challenge zero gradient inside neural network activation function saturate correspond gradient become zero zero gradient impossible saliency important feature recent attempt address approximation however sacrifice fidelity explanation blackbox explanation blackbox explanation knowledge classifier internals network architecture parameter instead treat classifier blackbox analyze input output model induction representative category lime input image lime systematically perturbs obtain artificial image nearby feature lime coefficient attach important feature illustrate blackbox explanation local linear model approximate detection boundary input instance linear model contribute feature classify artificial image target classifier obtain label label data linear regression model aim approximate input image feature lime assumes local classification boundary input instance linear reasonable linear regression model locally classification decision linear regression  lime pinpoint important feature regression coefficient recent shap extend lime artificially generate data sample propose linear model decision decision incrementally approximate target detection boundary clarify machine explanation completely feature selection principal component analysis pca sparse cod chi statistic explanation aim identify feature specific input instance specifically explain instance classify feature selection pca typically apply training training data reduce feature dimension training reduce overfitting cannot explain specific classification decision  security APPLICATIONS potential security application correspond explanation largely lack transparency reduces trust security practitioner trust model understand critical decision security practitioner cannot troubleshoot classification error error introduce bias training data concern error amplify later introduce security application recently achieve discus exist explanation applicable security application session 2D ML CCS october toronto canada explanation rnn mlp local non linear blackbox representative whitebox occlusion AI whitebox  saliency grad carm deeplift blackbox lime shap interpretable decision LEMNA LEMNA explainable machine security application false partially security application focus important security application binary reverse engineering malware classification binary reverse engineering application binary analysis identify function boundary pinpoint function signature binary code specifically directional rnn improve function boundary identification achieve nearly perfect performance rnn accurately argument function binary recently employ mlp encode graph pinpoint vulnerable code fragment malware classification exist mainly mlp model malware classification researcher mlp detect malware binary code classify android malware recently propose adversarial resistant neural network detect malware audit observation rnn mlp widely adopt security application cnn rnn handle sequential data performs exceptionally processing sequence binary code particularly directional rnn capture directional dependency input sequence hex malware classification mlp widely efficiency cnn performs image advantage feature 2D image security application matrix data structure benefit cnn exist explanation challenge directly apply exist explanation security application summarize desire exist fail deliver rnn mlp mismatch model choice security application exist explanation exist explanation cnn image classifier however mention security application primarily adopt rnn mlp due model mismatch exist explanation applicable propagation saliency activation difference propagation operation convolutional layer pool layer cnn exist rnn mlp saliency explain rnn ignore feature dependency rnn explanation fidelity lime linear regression model component mixture regression model approximate locally non linear decision boundary linear regression model easily mistake mixture regression model achieves accurate approximation blackbox lime rnn validate later lime assume feature independent assumption violate rnn explicitly model dependency sequential data locally non linear decision boundary exist lime assume local linearity decision boundary however local decision boundary non linear complex network explanation serious error decision boundary around highly non linear linear heavily restrict typical sample easily artificial data beyond linear linear model approximate decision boundary later confirm linear approximation significantly degrade explanation fidelity blackbox although whitebox blackbox application scenario blackbox desirable security application noticeably uncommon pre model directional rnn prefix  detailed network architecture parameter training data available propagation blackbox observation intermediate layer inevitably performance degradation summary aim bridge gap develop dedicate explanation security application aim blackbox efficiently popular model rnn mlp cnn importantly achieve explanation fidelity security application session 2D ML CCS october toronto canada explanation achieve goal develop LEMNA treat target classifier blackbox derive explanation model approximation fidelity explanation LEMNA exist introduce fuse lasso handle feature dependency encounter security application rnn series analysis binary code sequence analysis integrate fuse lasso mixture regression model approximate locally nonlinear decision boundary complex security application discus insight choice fuse lasso mixture regression model technical detail integrate model handle feature dependency locally nonlinearity finally introduce additional utilize LEMNA derive fidelity explanation insight fuse lasso fuse lasso penalty commonly capture feature dependency useful handle dependent feature model rnn fuse lasso LEMNA relevant adjacent feature generate meaningful explanation introduce technical detail intuition model data sample machine algorithm minimize loss function defines dissimilarity label predict label model linear regression model data sample algorithm minimize equation respect parameter maximum likelihood estimation MLE  training sample dimensionality feature vector label denote vector contains coefficient linear model norm dissimilarity model prediction label fuse lasso penalty introduce loss function algorithm linear regression fuse lasso manifest constraint impose upon coefficient   fuse lasso restricts dissimilarity coefficient assign adjacent feature within threshold hyper parameter algorithm minimizes loss function penalty algorithm assign adjacent feature intuitively interpret algorithm feature target model feature security application series analysis code sequence analysis explicitly model feature dependency sequential data rnn classifier classification decision occurrence feature standard linear regression model lime derive explanation cannot approximate local decision boundary correctly linear regression model cannot capture feature dependency treat independently introduce fuse lasso approximate local decision boundary linear model feature grouped important feature likely multiple explicitly model LEMNA derive accurate explanation particularly decision rnn explain sentiment analysis fuse lasso regression model collectively adjacent feature derive explanation model simply yield accurately capture worth price explanation sentiment analysis mixture regression model mixture regression model allows approximate locally nonlinear decision boundary accurately mixture regression model combination multiple linear regression model expressive perform approximation hyper parameter linear component combine mixture model indicates assign correspond component sufficient data sample classifier linear non linear decision boundary mixture regression model nearly perfectly approximate decision boundary finite linear model context explanation mixture regression model avoid aforementioned non linearity issue derive accurate explanation illustrate standard linear approximation cannot guarantee data sample around input remain locally linear easily imprecise approximation  explanation approximates local decision boundary polygon boundary independent linear regression model linear model explanation passing data approximation yield optimal linear regression model pinpoint important feature explanation sentiment analysis negative sentiment session 2D ML CCS october toronto canada model development convert insight functional explanation introduce technical integrate fuse lasso mixture regression model handle feature dependency decision boundary non linearity technically derive mixture regression model minimize equation  βkj mixture regression model equation βkj indicates parameter linear regression model feature standard linear regression optimization objective intractable cannot simply utilize MLE perform minimization effectively estimate parameter mixture regression model utilize alternative approach mixture regression model probability distribution  treat parameter parameter initialize perform parameter estimation expectation maximization EM algorithm estimate parameter repeatedly perform briefly EM algorithm detail appendix equation distribution combine gaussian distribution distribution variance assign data sample gaussian distribution standard procedure apply ordinary mixture regression model data sample assign previous compute parameter parameter computation standard procedure ordinary mixture model parameter computation customize procedure compute minimize equation respect  βkj refers sample assign component computation customization indicates parameter parameter parameter describes variance normal distribution fuse lasso impose parameter grant mixture regression model ability handle feature dependency equation equation therefore minimize equation MLE compute parameter standard procedure EM algorithm repeatedly perform stability gaussian distribution output mixture regression model convert model parameter standard approach apply ordinary mixture model apply model explanation enhance mixture regression model discus derive fidelity explanation classifier approximate local decision boundary input instance generate explanation approximate local decision boundary target classifier interpretable linear model allows feature explanation synthesize data sample locally around approach described randomly nullify subset feature corpus synthesize data sample approximate local decision boundary scheme mixture regression model perform multiclass classification scheme multiple mixture regression model performs binary classification efficiency consideration scheme rigorous analysis appendix derive explanation input data instance classification generate explanation important feature classification specifically obtain mixture regression model enhance fuse lasso mixture model identify linear component approximation local decision boundary coefficient linear model rank feature feature explanation LEMNA simultaneously handle non linearity feature dependency LEMNA cannot model relatively independent feature mlp cnn LEMNA flexibility adjust explanation accord target model increase hyper parameter threshold fuse lasso relax constraint impose upon parameter LEMNA handle dependent feature demonstrate generalizability apply LEMNA security application built rnn mlp evaluation evaluate effectiveness explanation security application malware classification binary reverse engineering focus evaluate session 2D ML CCS october toronto canada classifier LEMNA hex sequence sequence classifier output apply LEMNA explain binary function function output probability rnn classifier tuple hex sequence LEMNA explains classification decision cod important hex feature importance decrease accuracy explanation series fidelity metric practical LEMNA understand classifier behavior troubleshoot classification error patch error classifier experimental setup apply LEMNA security application detect function reverse engineering binary code rnn classify pdf malware mlp introduce detail security application implementation LEMNA comparison baseline binary reverse engineering binary code reverse engineering transfer binary code assembly code crucial examine detect malware harden security software generate security patch binary analysis primarily manually experienced security analyst recently researcher rnn handle critical reverse engineering detect function significantly effort importance detect function binary code reverse engineering function application LEMNA rnn widely dataset contains binary compile binary architecture gcc compiler optimization respectively training datasets optimization directional rnn classifier binary dataset sequence hex code transfer hex code treat sequence feature training sequence label function function suppose binary code function label vector truncate binary sequence maximum sequence rnn kera model theano backend split dataset randomly sample training application binary function pdf malware precision recall accuracy classification accuracy classifier detection accuracy extremely precision recall comparable report hyper parameter rnns appendix pdf malware classifier construct  malware classifier widely dataset malicious pdf file benign file extract feature file feature manually craft researcher meta data structure pdf marker javascript marker feature  standard transform feature binary representation nonzero feature convert avoid feature skew training randomly datasets malware benign training data remain data precision recall LEMNA implementation treat rnn mlp target classifier LEMNA input instance LEMNA approximates target classifier explain classification explanation important feature input malware classifier LEMNA output feature explains file malware function detector input hex sequence detect function LEMNA hex code sequence contribution function LEMNA hex code function important detection LEMNA hyper parameter configurable approximate local decision boundary craft data sample model fitting parameter mixture component threshold fuse lasso binary function detection parameter malware classification parameter parameter differently malware analysis feature relatively independent binary analysis feature dependency fix parameter later dedicate perform sensitivity parameter setting LEMNA sensitive hyper parameter LEMNA computational computational LEMNA relatively security application generate explanation instance computation task benefit parallelization server intel xeon cpu nvidia tesla session 2D ML CCS october toronto canada input image explanation    image classifier toy explain fidelity input image  explanation LEMNA important feature pixel highlight instance generate fidelity explanation gpu 6G ram explain binary sequence thread comparison baseline baseline comparison blackbox lime comparison baseline lime explain image classifier nlp application performance security application rnn comparison configure lime artificial sample linear regression model random feature selection baseline input random selects feature randomly explanation classification fidelity evaluation validate correctness fidelity explanation conduct stage stage directly examine accuracy local approximation respect decision boundary likely initial estimation explanation accuracy stage perform toend evaluation explanation fidelity fidelity feature indeed contributor classification evaluation local approximation accuracy metric directly compute approximate decision boundary error RMSE RMSE   prediction obtain target classifier  denotes approximate prediction obtain explanation data sample specifically classifier data sample data sample obtain prediction probability classifier equation generate regression model estimate prediction probability  sample obtain prediction vector correspond approximation vector Pˆ  finally computer RMSE vector RMSE approximate decision boundary Pˆ closer boundary fidelity explanation evaluation fidelity validate correctness feature fidelity reader understand shap extension lime shap performance lime application image classifier toy procedure classifier image classifier classify  input image label  explanation explains classification highlight important pixel feature denote feature fidelity explanation intuition feature accurately remove input classify image label feature accurately feature image likely misclassification classify  feature accurately craft synthetic image contains feature synthetic image likely classify  intuition construct fidelity validate feature formally input instance classification label LEMNA identifies important feature explanation generate sample feature validation feature deduction construct sample nullify feature instance feature augmentation random instance label construct replace feature instance synthetic construct synthetic instance preserve feature feature randomly assign remain feature variable important feature explanation intuitively yield explanation fidelity hurt interpretability analyst comprehend classifier fidelity dataset data instance dataset generate sample fidelity sample classifier examine positive classification rate pcr pcr ratio sample classify label positive malware function simply sample classify label feature selection accurate feature deduction sample return pcr feature augmentation sample return pcr synthetic sample return pcr experimental LEMNA outperforms lime random baseline significant margin across fidelity metric local approximation accuracy LEMNA RMSE magnitude lime image fashion mnist dataset session 2D ML CCS october toronto canada binary function pdf malware lime LEMNA error RMSE local approximation LEMNA accurate lime nfeatures pcr binary nfeatures pcr binary nfeatures pcr GMM FL lime random pdf malware feature deduction pcr reflect explanation fidelity nfeatures pcr binary nfeatures pcr binary nfeatures pcr GMM FL lime random pdf malware feature augmentation pcr reflect explanation fidelity nfeatures pcr binary nfeatures pcr binary nfeatures pcr GMM FL lime random pdf malware synthetic pcr reflect explanation fidelity fidelity axis denotes positive classification rate pcr axis denote feature  explanation due limit binary appendix observation malware classifier function detection perform lime RMSE almost perform LEMNA confirms mixture regression model accurate approximation linear model metric applicable random baseline random baseline construct decision boundary fidelity feature deduction recall feature deduction remove important feature input instance pcr indicates feature important classification decision nullify feature LEMNA function detector pcr extremely accuracy classifier drastic decrease pcr indicates feature highly important classification feature  minor feature RMSE    hyper parameter sensitivity feature input sequence nullify feature pcr almost feature augmentation recall feature augmentation feature input instance classifier label pcr indicates feature important relatively consistent previous feature flip label instance outperforms baseline margin noticeably pdf malware classifier replace feature flip label trend synthetic feature synthetic instance likely label label feature synthetic instance label core successfully capture across LEMNA outperforms lime random baseline margin interestingly malware classifier lime performs random feature selection feature vector sparse hurt smoothness decision boundary lime accurately approximate non smooth boundary validates intuition suitable security application security application explanation precision image analysis task sensitivity hyper parameter finally parameter differently parameter configuration conclusion remain consistent due limit summarize hyper parameter craft data sample model fitting mixture component threshold fuse lasso binary function detector dataset configuration parameter fidelity fix feature calculate pcr confirm hyper parameter significantly influence performance LEMNA APPLICATIONS ML explanation validate fidelity explanation practical application LEMNA explanation security analyst establish trust classifier troubleshoot classification error systematically patch target error primarily focus binary reverse engineering application application domain relatively understood session 2D ML CCS october toronto canada ID opt explanation assemble code pop ebx pop ebp ret ebp mov ebp esp pop ebx nop ret ebx sub esp lea esi esi  mov ecx eax nop nop nop nop esi ebx jmp xor ebp ebp pop esi nop nop nop mov eax sub eax esp ret sub esp nop nop nop nop mov eax  ptr esp lea edi edi  ebp edi esi jmp xor ebp ebp pop esi jmp nop mov edx eax xor eax eax lea esi esi  mov eax  eax ret sub esp lea esi esi  mov eax lea esi esi  sub esp binary analysis explanation rank feature important feature orange translate hex code assemble code understand refers function detect classifier function marked hex sequence false negative function classifier fail detect explain function perform analysis pdf malware classifier appendix understand classifier behavior primary application explanation ass reliability classifier establish trust argue classifier reliability trust necessarily classification accuracy training data training data capture variance instead trust likely establish understand model behavior examine direction understand classifier decision capture validate golden establish heuristic discover knowledge capture heuristic reliable classifier capture heuristic respective application domain binary reverse engineering security practitioner accumulate useful heuristic identify function treat golden golden derive specification application binary interface abi standard abi function frame pointer ebp function maintains frame pointer commonly prologue ebp mov ebp esp another establish mainstream compiler gnu gcc insert nop instruction function aligns function architectural optimization analyze explanation evidence classifier successfully capture heuristic representative classifier optimization classifier correctly detect function LEMNA marked function highlight importance feature hex code nearby golden namely ebp mov ebp esp suggests classifier decision reasonable similarly capture function corresponds popular heuristic introduce compiler compiler function exit ret instruction particularly function LEMNA highlight indicates classifier nop function compiler pad nop prior align function similarly LEMNA highlight pad instruction lea esi esi  another introduce compiler overall LEMNA heuristic successfully capture classifier analysis heuristic widely applicable optimization binary function heuristic optimize function ret instruction contrary binary function heuristic pad instruction function intuitive optimization significantly diversify code structure golden effective discover knowledge addition heuristic examine classifier picked session 2D ML CCS october toronto canada heuristic beyond exist knowledge security application argue heuristic interpretable domain expert domain binary analysis potentially useful heuristic specific individual function summarize manually utility function insert linker unique code rarely elsewhere function xor ebp ebp pop esi manually organize practical however derive LEMNA intuitive domain expert analyze explanation classifier indeed knowledge representative ID detect function subsequent corresponds utility function namely xor ebp ebp pop esi illustrates explanation summarize unique prologue pertain function function necessarily important indicator opcode xor function detection illustrates another important feature detect function resides instruction mov eax CONS sub eax CONS CONS CONS constant CONS CONS prologue register clone  clone utility function transactional memory function specific detect function preparation function marked important feature corresponds instruction sub esp instruction frequently function stack frame mov eax  ptr esp marked indicative feature instruction usually insert fetch argument function offset esp fetch argument function offset instruction necessarily indicator function preserve register later modify ebp edi esi preservation register convention abi standard frequently function overall LEMNA validates classifier decision largely explainable logic establish trust classifier troubleshoot classification error neural network although highly accurate error error simply ignore insufficient training amplify due bias training explanation seek insight error misclassification inspect error seek actionable guideline target error correction false negative binary analysis application classifier occasionally function false negative explain function classify function specifically tuple code sequence function LEMNA feature recognize function marked correspond jmp instruction almost routine function misleads classifier substantial function outlier happens instruction  function classify due instruction mov edx eax mov eax function false positive classifier picked function tuple code sequence function LEMNA explain function picked highlight ret instruction typically ret function exit byte candidate function however ret actually function optimization purpose mislead pad instruction lea esi esi  align function however pad instruction actually align inside function overall LEMNA error largely mislead dominate indicator mitigate error pinpoint correspond feature suppress mislead target patch ML classifier develop automatic procedure convert insight action patch classifier patch patch specific classification error identify correspond classifier  craft target training sample augment training data specifically misclassified instance apply LEMNA pinpoint feature error instance outlier training data counter strategy augment training data related counter replace feature random patch procedure classifier function due hex exists function ideally classifier picked function unfortunately impact dominate sample reduce impact mislead feature session 2D ML CCS october toronto canada application num sample FN FP FN FP binary binary binary binary pdf malware classification patch  augment sample generate false negative false positive function detection sample refers hex code promote indicator sample generate replace hex random hex sample training data seek reduce error retrain classifier evaluation demonstrate effectiveness patch perform procedure classifier false positive false negative generate sample respectively necessarily patch target error without hurt already accuracy classifier consistently classifier replace mislead feature retrain model epoch classifier performance patch sensitivity parameter remain relatively consistent appendix due limit classifier false positive false negative reduce retrain classifier demonstrate understand model behavior identify weakness model enhance model accordingly discussion benefit risk LEMNA assist security analyst understand scrutinize patch security defense perspective attacker seek weakness classifier however argue dilute LEMNA develop explanation analogy software fuzzing technique fuzzing hacker seek vulnerability exploit fuzzing technique significantly benefit software facilitate software fix vulnerability software release guideline analyze LEMNA output LEMNA output explanation thoroughly examine classifier developer LEMNA manually reading explanation  efficient explanation grouped explanation exactly representative developer cluster technique explanation broader security application LEMNA evaluate popular security application security application detect function binary code pinpoint function detect vulnerable code potentially benefit LEMNA architecture rnn mlp model cnn similarity mlp LEMNA potentially related application image analysis future explore applicability LEMNA broader application domain architecture addition mlp rnn architecture sequence  network hybrid network although architecture primarily machine translation image caption initial evidence potential role security concrete security application built future LEMNA architecture feature obfuscation LEMNA useful feature interpretable application researcher recently propose various obfuscate input feature increase difficulty adversarial attack possibly feature obfuscation degrades classifier accuracy technique usage LEMNA directly applicable classifier obfuscate feature however model developer mapping raw obfuscate feature developer translate LEMNA output interpretable feature related related briefly discus related improve machine robustness model deceive adversarial sample malicious input craft misclassification improve model resistance researcher propose various defense relevant adversarial training adversarial training seek adversarial training dataset retrain robust model various technique available craft adversarial adversarial training difference patch standard adversarial training patch understand error avoid blindly retrain model introduce vulnerability mitigate influence contaminate data recent research explore mitigate misclassifications introduce contaminate training data representative machine unlearn remove influence training data transform standard training algorithm summation recent proposes utilize influence function identify data contribute misclassification approach complementary session 2D ML CCS october toronto canada exist propose augment training data fix  component instead remove training data importantly LEMNA analyst understand error patch conclusion introduces LEMNA derive fidelity explanation individual classification security application LEMNA treat target model blackbox approximates decision boundary mixture regression model enhance fuse lasso evaluate popular security application propose highly accurate explanation addition demonstrate machine developer security analyst benefit LEMNA understand classifier behavior troubleshoot misclassification error perform automate patch enhance model