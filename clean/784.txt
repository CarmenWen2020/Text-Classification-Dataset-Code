machine model leak significant amount information training prediction serious privacy concern user machine service address concern focus mitigate risk inference attack machine model introduce mechanism model membership privacy ensures  prediction model training data data distribution minimize accuracy membership inference attack model formalize min max adversarial training algorithm minimizes prediction loss model maximum gain inference attack strategy guarantee membership privacy prediction  regularizer generalize model evaluate practical feasibility privacy mechanism training neural network benchmark datasets min max strategy mitigate risk membership inference attack random achieve negligible model prediction accuracy keywords data privacy machine inference attack membership privacy  min max adversarial acm reference format    shokri amir  machine membership privacy adversarial regularization acm  conference computer communication security CCS october toronto canada acm york NY usa http doi org introduction available datasets powerful compute infrastructure advance training complex machine model dramatically increase adoption machine software machine service facilitate technology designer application developer data holder model machine service  platform google amazon microsoft model accessible prediction apis integration machine algorithm application internet sensitive data input training machine model confidentiality privacy data utmost importance data owner training platform trust remain concern model computation prediction exploit endanger privacy sensitive training data leakage complex machine model maybe obvious linear statistic however machine model significantly leak information datasets adversary access model perform membership inference trace attack model target data member training adversary exploit distinctive behavior model training data fundamental threat data privacy effective machine model service focus machine model membership inference attack exist defense mechanism mitigation technique limit model prediction therefore reduce precision prediction regularize model norm regularizers technique impose negligible utility loss model however cannot guarantee rigorous notion privacy defense differential privacy mechanism mechanism guarantee membership privacy privacy parameter however exist mechanism impose significant classification accuracy loss model dimensional data partly guarantee  input training datasets exist parameter output model secondly utility explicitly objective exist privacy mechanism contribution rigorous privacy mechanism training dataset machine model inference attack machine model guarantee membership privacy adversary distinguish prediction model training data sample underlie distribution objective achieve membership privacy minimum classification loss session 3D ML CCS october toronto canada optimization minimize classification error model inference accuracy attack adaptively construct attack target model therefore compose utility objective conflict privacy objective model optimization min max privacy defense mechanism inference attack privacy setting model accurate maximum membership privacy correspond inference attack adversary cannot membership inference attack already anticipate defender exist model achieve membership privacy accuracy maximum utility guaranteed optimization model adversarial classification model feature data computes probability belongs inference model target data output classifier membership probability preserve utility data privacy gain inference attack regularizer classifier minimize along classification loss regularization parameter membership privacy classification error model adversarial machine equilibrium classification loss achieve privacy minimize membership inference attack model equivalent random indicates maximum membership privacy regularize machine model privacy experimental verify mechanism indeed strongly regularizes model prevent overfitting significantly closing gap training accuracy directly  prediction distribution training versus data privacypreserving model purchase dataset obtain accuracy random membership inference accuracy contrast standard norm regularizer privacy attack extremely classification accuracy impose negligible classification loss significant gain membership privacy cifar dataset alexnet densenet architecture respectively prediction accuracy relative regular non privacy preserve model purchase texas datasets membership privacy classification accuracy respectively reduce inference accuracy respectively minimum membership inference accuracy random machine learning focus training classification model supervise data dimensional dimension attribute data input feature classification model assume predefined data objective relation data classification function output reflect classifies input output probability input belongs correspond underlie probability distribution data universe random variable feature data respectively objective machine algorithm classification model accurately distribution assume bound loss function data difference model prediction machine objective function minimizes loss estimate probability function sample drawn sample construct training instead minimize machine algorithm minimize empirical loss model training LD optimization classification model min LD regularization function function prevent model overfitting training dataset regularization loss penalty increase parameter function arbitrarily adapt dataset minimize LD model  obtains loss training data fails achieve loss data avoid overfitting model generalize data sample drawn regularization factor balance classification loss function regularizer optimization nonconvex loss function complex model neural network commonly stochastic gradient descent algorithm iterative algorithm epoch training selects subset mini batch training data update model parameter towards reduce loss mini batch epoch training algorithm converges local minimum loss function membership inference ATTACKS objective membership inference attack refer trace attack target data dataset adversary computation aggregate statistic machine model membership inference attack mostly analyze data privacy respect statistical linear session 3D ML CCS october toronto canada feature input label classifier prediction vector inference model relation classification model inference model function attacker release statistic dataset statistic compute random sample population closer target data alternatively adversary target data sample population closer release statistic target closer release statistic member dataset inference attack formulate likelihood ratio machine model membership inference attack adversary distinguish training member  model prediction indirect nonlinear computation training data exist inference algorithm suggests training another machine model inference model statistical difference prediction member prediction non member formally attack optimization model adversary objective illustrates relation component membership inference attack machine model inference model data model prediction vector output probability member training prd conditional probability sample outside respectively ideal conditional probability distribution gain inference attack compute prd expectation compute correctness membership inference model target data sample training universe realistic probability distribution data universe classifier inference model loss gain classification loss inference gain training dataset reference dataset adversarial training classification loss compute inference gain compute simplify illustration mini batch probability distribution member training directly accurately available adversary compute gain therefore compute empirical gain inference model disjoint datasets sample accord probability distribution data inside training outside respectively concretely dataset subset target training adversary empirical gain membership inference model compute DA DA DA optimization membership inference attack simply maximize empirical gain max DA optimization target classification model however shadow model model architecture objective function model data sample min max membership privacy adversary upper adapts inference attack target model maximize gain respect exist classification model defense mechanism eventually broken respect attack without anticipate inference attack conflict objective defender adversary model privacy adversary maximum inference gain defender session 3D ML CCS october toronto canada algorithm adversarial training algorithm machine membership privacy algorithm optimizes min max objective function epoch training maximization inference attack model minimization defensive classification model attack model training epoch randomly sample mini batch training data training randomly sample mini batch reference data reference update inference model ascend stochastic gradient parameter randomly sample mini batch training data update classification model descend stochastic gradient parameter classification model minimizes loss minimizes adversary maximum gain stackelberg min max privacy objective classification model minimize privacy loss respect maximum inference gain attack easy achieve simply output model independent input destroy utility classifier update training objective classification model minimize privacy loss respect inference attack minimum classification loss optimal privacy mechanism utility maximize formalize joint privacy classification objective min max optimization min LD max optimal inference optimal privacy preserve classification inner maximization inference model classification model outer minimization defensive classification model parameter importance optimize classification accuracy versus membership privacy inference attack regularizer classification model prevents classification model arbitrarily adapt training data leak information training data inference attack model equivalent optimization jointly equilibrium arbitrarily complex function numerically stochastic gradient descent algorithm generative adversarial network training involves datasets training classifier disjoint reference training contains sample algorithm pseudo code adversarial training classifier inference attack model epoch training model alternatively response nest optimization inner optimization fix classifier membership inference model distinguish prediction training prediction model reference maximizes empirical inference gain outer optimization fix inference attack classifier adversary gain function regularizer minimizes empirical classification loss LD algorithm converge equilibrium min max solves theoretical analysis ultimate objective classification model  output distribution data member training versus  theoretical analysis generative adversarial network algorithm converge privacy preserve model classification model probability distribution output prediction vector training data probability distribution output data outside training dataset classifier optimal attack model maximizes expand prd  session 3D ML CCS october toronto canada maximum achievable optimal inference model capacity prd prd combine already adversary distribution data inside outside training prediction model training training sample underlie probability distribution attack depends prediction model simplify optimal inference model strategy adversary membership probability prediction distribution alternatively optimal strategy adversary classifier optimal classifier response inference attack privacy preserve classification task objective minimize classification loss LD privacy loss classification model classification loss LD min max reduce minf  compute min max prd accord theorem optimal function global minimization function fix classification loss capacity model training algorithm minimizes privacy loss distribution indistinguishable implies optimal classifier membership inference probability converge random accord proposition stochastic gradient descent algorithm algorithm eventually converges equilibrium min max summarize classification model minimum classification loss inference attack cannot distinguish training member non member model prediction issue adversarial training theoretical proof rely possibility optimal discriminator attacker provably achievable gradient descent minmax hence technique recently developed efficient generative adversarial network technique improve adversarial training algorithm nevertheless experimental exist gradient descent approach perform significantly membership inference attack EXPERIMENTS apply classification task various neural network structure implement pytorch purpose empirically robustness privacy preserve model inference attack negligible classification loss datasets datasets machine benchmark dataset cifar datasets purchase texas membership inference attack machine model cifar benchmark dataset evaluate image recognition algorithm dataset contains image compose pixel cluster purchase dataset kaggle acquire shopper challenge dataset shopping individual goal challenge discount attract shopper simplify version dataset data corresponds  binary feature correspond item feature reflect item purchase  data cluster task predict  dataset contains data texas dataset hospital discharge data dataset information inpatient health facility publish texas department health service data feature external injury suicide drug misuse diagnosis schizophrenia illegal abortion procedure patient underwent surgery generic information gender hospital ID version dataset contains binary feature frequent medical procedure cluster patient medical classification model cifar dataset neural network architecture alexnet architecture adam optimizer rate epoch training densenet architecture stochastic gradient descent sgd epoch rate epoch architecture model regularize alexnet dropout densenet norm regularization purchase dataset layer fully neural network layer tanh activation function initialize parameter random normal distribution standard deviation model epoch http pytorch org http kaggle com acquire shopper challenge data session 3D ML CCS october toronto canada neural network architecture inference attack model layer fully subsequent layer fully layer texas dataset layer fully neural network layer tanh activation function initialize parameter random normal distribution standard deviation model epoch training data reference data sample datasets report adversarial regularization factor inference attack model inference model neural network illustrates architecture inference neural network objective attack model compute membership probability target training classification model attack model input prediction vector classification model inference attack model fully sub network network layer operates prediction vector network layer operates label cod corresponds label index network operates concatenation output network layer contrast membership inference attack model per model inference attack architecture attack model notably layer enables capture relation prediction model training member versus non member relu activation function network initialize normal distribution standard deviation bias initialize adam optimizer rate training batch attack model member non member instance prevent attack model bias dataset purchase texas cifar experimental setup training reference algorithm adversarial regularization factor training subset training member non member data adversary inference attack epoch classifier loss defense without defense purchase epoch attacker gain purchase trajectory classification loss training without defense mechanism inference attack gain purchase dataset member training non member data assume adversary training attack model knowledge assume attacker evaluate defense mechanism assume adversary substantial training infer membership session 3D ML CCS october toronto canada baseline without defense privacy preserve model dataset training accuracy accuracy attack accuracy training accuracy accuracy attack accuracy purchase texas cifar alexnet cifar densenet comparison membership privacy training accuracy classification model without defense baseline privacy preserve model defense model datasets respect accuracy attack accuracy experimental setup training attack accuracy accuracy accuracy defense adversarial regularization factor min max optimization defense mechanism purchase dataset privacy parameter regularization training attack factor accuracy accuracy accuracy regularization regularization mitigation technique membership inference attack model purchase dataset achieve strategic min max optimization empirical loss gain adversarial training empirical loss classification model empirical gain inference model throughout training algorithm classifier loss attack gain training epoch converge equilibrium optimization attacker gain maximum achieve defense mechanism classifier loss minimum achieve preserve privacy attack mechanism minimize classifier loss model prevents attack gain adversary random strategy evolution classification loss privacy preserve model loss model regularly without defense regular model without defense arbitrarily reduces loss overfit training data later visualize impact loss output model leak information model training adversarial training membership privacy strongly regularizes model privacy preserve mechanism protects membership privacy significantly prevents overfitting privacy generalization tradeoff privacy predictive privacy preserve model cumulative distribution model generalization error plot axis model generalization error axis compute model generalization error difference training accuracy model sample generalization error regular model privacy preserve model plot generalization error privacy mechanism significantly training privacy preserve machine model min max datasets model without defense mechanism gap training accuracy without defensive training mechanism reduces generalization error factor error reduce texas model reduce cifar alexnet model reduce cifar densenet model remains almost purchase model min max mechanism achieves membership privacy minimum generalization error prediction accuracy privacy adjust adversarial regularization factor regularization mechanism achieve regularizers norm regularizer formalization classification loss function tradeoff model accuracy membership privacy norm session 3D ML CCS october toronto canada regularizers guarantee privacy minimize achieve maximum membership privacy accuracy privacy preserve mechanism twice accuracy norm regularize model exactly optimization objective privacy preserve model membership privacy inference attack accuracy training accuracy model attack accuracy attack accuracy evaluate average probability inference attack model correctly predicts membership DA DA data sample underlie distribution training overlap important accuracy classifier versus attack accuracy tradeoff predictive model robustness membership inference attack theoretical experimental attack accuracy random privacy preserve model regular model privacy preserve mechanism guarantee maximum achievable membership privacy negligible model predictive achieve maximum membership privacy accuracy purchase model texas model cifar alexnet model cifar densenet model reference objective min max optimization prediction model training data indistinguishable model prediction sample underlie data distribution sample distribution reference empirically optimize min max objective reference model membership privacy model training hyper parameter reference increase becomes properly underlie distribution attack accuracy converges  prediction membership inference attack model exploit statistical difference prediction model member versus non member output model probability sample training data regular model without defense versus privacy preserve model input data purchase dataset illustrates regular reference accuracy attack accuracy reference defense mechanism purchase dataset training dataset baseline privacy preserve training purchase texas cifar alexnet cifar densenet comparison training model titan gpu privacy preserve mechanism versus normal training baseline model overfitted training probability training data significantly contributes vulnerability model membership inference attack privacy preserve model visibly distribution member output indistinguishable non member output min max optimization output distribution converge indistinguishable distribution investigate  distribution compute statistic accuracy uncertainty model output datasets histogram model accuracy uncertainty training compute accuracy model data probability predict input compute uncertainty normalize entropy yˆi yˆi probability vector privacy mechanism significantly reduces maximum risk average gap prediction accuracy uncertainty model training versus regular model privacy illustrate attacker exploit inference attack visibly  model output distribution member non member improve defense mechanism training model technique model classifier inference attack training model model PC equip titan gpu gbytes graphic memory gbytes memory intel xeon cpu session 3D ML CCS october toronto canada generalization error cumulative probability defense without defense purchase generalization error cumulative probability defense without defense texas generalization error cumulative probability defense without defense cifar empirical cdf generalization error classification model across regular model without defense versus privacy preserve model defense compute generalization error difference training accuracy model axis generalization error axis curve lean towards generalization error label prediction probability purchase without defense data without defense label prediction probability purchase defense data defense label prediction probability purchase defense data distribution output prediction vector classifier training data sample purchase dataset data sample without defense sample classify probability whereas privacy preserve classifier prediction probability across uncertainty provably mitigates information leakage compute data sample indistinguishable session 3D ML CCS october toronto canada prediction accuracy member non member purchase without defense prediction accuracy member non member purchase defense prediction accuracy member non member texas without defense prediction accuracy member non member texas defense pre  accuracy non member cifar without defense pre  accuracy non member cifar defense distribution classifier prediction accuracy member training versus non member data sample accuracy probability predict sample input plot distribution curve regular model without defense distribution curve privacy preserve model defense gap curve plot information leakage model training privacy preserve model reduces gap magnitude maximum gap curve defense versus without defense purchase model texas model cifar densenet model average gap curve purchase model texas model cifar densenet model session 3D ML CCS october toronto canada prediction uncertainty member non member purchase without defense prediction uncertainty member non member purchase defense prediction uncertainty member non member texas without defense prediction uncertainty member non member texas defense prediction uncertainty member non member cifar without defense prediction uncertainty member non member cifar defense distribution classifier prediction uncertainty member training versus non member data uncertainty normalize entropy model output prediction vector plot distribution curve regular model without defense distribution curve privacy preserve model defense gap curve plot information leakage model training privacy preserve model reduces gap magnitude maximum gap curve defense versus without defense purchase model texas model cifar densenet model average gap curve purchase model texas model cifar densenet model session 3D ML CCS october toronto canada related analyze privacy machine model attack topic ongoing research privacy threat machine untrusted access machine platform training prediction defense mechanism trust hardware cryptographic private compute propose enable blind training machine model leverage various technique homomorphic encryption garble circuit secure multi computation private machine encrypt data private computation trust hardware intel sgx although technique prevent attacker directly sensitive data limit information leakage computation adversary background knowledge external data infer information training data input query parameter model inference attack input inference membership inference attribute inference parameter inference channel attack privacy attack computation sensitive data focus privacy risk computation database adversary observes computation setting membership inference attack reconstruction attack attack membership inference attack decisional aim infer presence target data training dataset accuracy attack extent model dependent individual training data reconstruction attack generic attack objective infer sensitive attribute individual training propose defense technique inference attack computation training model differential privacy guarantee recently context machine despite provable robustness inference attack differential privacy mechanism achieve negligible utility loss utility aim privacy attack  input datasets related difficulty compute tight bound sensitivity function determines magnitude differential privacy relation definition membership privacy differential privacy analyze literature theory formalize optimize data privacy security another direction privacy framework privacy loss minimize correspond attack provably robust attack threatens privacy accord loss function theoretic framework allows explicitly incorporate utility function min max optimization minimize privacy defense mechanism recent advance machine notably development generative adversarial network introduce algorithm min max training complex neural network model adversarial training regularize hence generalize model CONCLUSIONS training algorithm regularize machine model privacy introduce privacy mechanism mitigate information leakage machine model membership data training prediction optimization objective jointly maximize privacy prediction accuracy min max minimizes classification loss model maximum gain membership inference attack model prediction training data indistinguishable prediction data sample distribution mechanism guarantee membership privacy model training inference attack imposes minimum accuracy loss achieve privacy available training reference data capacity model extensive apply benchmark machine task achieve privacy negligible privacy preserve model generalize