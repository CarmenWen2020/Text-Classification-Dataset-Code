adoption machine model become popular however addition prediction model producer aim risk model consumer infer training data model producer intend focus inference global training data environment data data apply fully neural network FCNNs complexity  FCNNs particularly risk leak unexpected information training complexity extract information challenge develop technique reduce complexity FCNNs invariant permutation node layer develop technique representation capture invariance simplify information extraction task evaluate technique synthetic standard benchmark datasets effective infer various data perform demonstrate impact attack classifier recognizes leak information relative attractiveness individual training classifier recognizes bitcoin mining performance counter leak information classifier machine patch meltdown spectre attack keywords neural network inference permutation equivalence introduction machine ML gain widespread adoption application development ML model however significant investment compute effort tune optimize model additionally access training datasets particularly popular data intensive neural network NN model motivates creation online ML model collaboration profit datasets model sensitive important information training data model reveal recent research identify potential attack reveal information training data model inversion attack output training data sample ML model membership inference attack predict data sample model training dataset attack focus privacy individual dataset candidate protection differentially private mechanism protection membership inference consequence differential privacy guarantee focus instead inference sensitive global training dataset ML model extract model producer intend motivation malware classifier model execution trace malicious benign software adversary model environment evade detection identify vulnerability environment impact trace entire training dataset individual another recent research identify underrepresentation minority various training datasets correspond disparity performance classifier across session 3D ML CCS october toronto canada therefore infer dataset model representation global dataset inference attack formulate attack involves training meta classifier classify target classifier adversary creates shadow classifier proxy classifier task target classifier classifier dataset target classifier construct explicitly parameter shadow classifier meta classifier demonstrate attack hidden markov model HMMs vector machine svm classifier differential privacy mechanism offering privacy effective countermeasure inference however approach apply neural network recently become popular ML model conjecture complexity model typically parameter challenge meta classifier therefore investigate feature representation reduce complexity meta classification task focus fully neural network FCNNs insight FCNNs invariant permutation node matrix apply arbitrary permutation hidden layer FCNN adjust correspondingly equivalent FCNN furthermore equivalent network grows  node invariance challenge meta classifier particularly limit shadow classifier training classifier incurs computational develop technique address technique arranges FCNN canonical equivalent permutation FCNN feature representation technique layer FCNN vector leverage  architecture develop meta classifier addition capture permutation invariance representation significantly reduces parameter meta classifier easy evaluate technique standard benchmark datasets mnist celeba effective infer various data accuracy approach task greatly improves baseline memory overhead shadow classifier detection classifier popular celeba dataset detect model disproportionate sample attractive individual perfect accuracy baseline approach training meta classifier directly raw shadow classifier parameter effective likewise cryptocurrency mining detector dataset hardware performance counter program approach predict dataset consist discus investigation FCNNs graph vulnerable meltdown spectre attack accuracy contrast baseline performs slightly contribution summarize identify node permutation issue limit effectiveness exist inference fully neural network matrix propose permutation invariant strategy address limitation evaluate strategy datasets evaluation substantial improvement accuracy exist technique organize introduction background formulate statement baseline strategy inference introduce permutation equivalence inference algorithm evaluation discussion related conclusion background background knowledge neural network introduce concept  approach hardware performance counter neural network neural network become popular model variety ML task neural network compose multiple layer computational transform output precede layer input layer computational layer receives input additional input layer layer output layer layer input layer output layer hidden layer output neural network input formally transformation function computational layer hidden layer output layer neural network notation consistently refer collection apply neural network denotes layer whereas apply layer denotes computational layer transformation function correspond layer employ neural network depends task convolutional layer employ image processing recurrent layer traditionally employ processing text commonly layer fully layer compose multiple computational perceptrons neuron possess multiplicative additive bias perceptron transforms output precede layer linear summation apply non linear activation function ith perceptron session 3D ML CCS october toronto canada tth layer output output precede layer vector perceptron bias non linear activation function layer output layer fully neural network input network hidden layer consist node output layer consist node bias simplicity output neuron input bias along parameter neural network variable network structure hidden variable network rate hyperparameters training dataset model optimal parameter model meaningful output neural network minimize loss function penalizes mismatch label predict label choice loss function depends architecture model contextual setting binary entropy loss function classification error regression task loss function stochastic gradient descent sgd variant commonly reduce loss consequently optimize objective function   neural network architecture propose machine task define architecture enforces requirement function define function permutation invariant permutation function neural network architecture broken neural network function function obtain representation feature function obtain prediction output feature vector obtain passing function sum feature vector fed input function obtain output formally propose functional representation invariant permutation unweighted summation apply function utility digit function obtains sum digit decompose aforementioned function  perform task sum digit digit image important instead entire sum feature architecture parameter highly computationally efficient easy architecture hardware performance counter computer hardware performance counter HPCs purpose register built microprocessor hardware within computer counter execute instruction fault context switch cache etc linux perf performance counter subsystem hardware performance counter runtime behavior characteristic program execute therefore advanced user counter conduct performance analysis tune HPCs demonstrate useful detect malware  channel attack cryptomining behavior enterprise statement model producer fully neural network training classification task training model producer release model public model consumer allows model consumer prediction without training model model adversary model consumer infer training model producer intend assume adversary knowledge knowledge parameter architecture target model assumption reasonable nowadays online platform model openly parameter thereby access model producer model model consumer software executables however extract classifier reverse engineering dynamic analysis technique consumer effectively access reverse effort sometimes producer expose model ML service interface expose api user query prediction without user model classic model demonstrate adversary efficiently extract target model perfect fidelity popular model neural network convert access access scope assume adversary cannot tamper training target model data collection session 3D ML CCS october toronto canada training dataset integrity attack target model training dataset adversary cannot encode information model training pas along target covertly previous focus possibility leak information individual constitute training dataset focus unintended global training instead cryptomining individual execution cryptomining sample sensitive environment confidential information model producer intend release technique assume model consumer adversary training data producer intend data suitable training meta classifier instance attack inference attack strategy inference exploit ML model datasets training function similarity function reflect model inherent parameter objective adversary recognize within target model reveal model producer desire release adversary classifier meta classifier recognize meta classifier technique shadow training adversary multiple proxy shadow classifier training meta classifier attack strategy inference strategy propose  target model shadow classifier adversary interested distinguish facial image dataset dataset disproportionate towards male ratio dataset ratio male female likewise mnist dataset image noisy focus binary inference henceforth denote exactly negation alternative choice meta classifier oppose predict regardless highlight model dataset otherwise attack obtain training data shadow classifier adversary generates datasets datasets obtain sample dataset simply obtain data adversary infer training instead hyperparameters information data preprocessing adversary generates hyperparameters training without shadow classifier shadow classifier correspond dataset adversary minimize unknown adversary training environment target classifier threat model assumes whitebox model access adversary already architecture target classifier architecture shadow classifier additionally important shadow classifier accuracy target classifier reasonably performance parameter usually randomly initialize capture meaningful information dataset hyperparameters adversary inference training shadow classifier adversary obtains feature representation shadow classifier meta training training  feature representation logistic regression model vector coefficient feature decision function bias emission transition probability node hmm separately data sample meta classifier svm model vector shadow classifier data sample multiple feature vector shadow classifier dimensionality probability associate node hmm coordinate associate vector svm model hence simpler component data neural network however node layer parameter impossible node feature  parameter neural network feature representation shadow classifier finally adversary meta training  meta classifier sample label correspondingly adversary meta classifier popular training algorithm upon obtain meta classifier adversary  feature representation  input predict existence target target model appendix algorithm meta classifier summarize attack previous perform attack successfully HMMs SVMs investigate attack neural network neural network mnist dataset detail dataset target classifier fully neural network predict digit handwritten digit image infer target classifier classifier image input regularize ML model prevent overfitting vector parameter neural network feature representation another neural network session 3D ML CCS october toronto canada shadow training shadow classifer shadow classifier feature extraction feature extraction meta training meta classifier target model feature extraction predict shadow training workflow inference attack meta classifier perform attack however  accuracy predict slightly random parameter neural network feature vector performs random discus factor hypothesize account performance permutation equivalence flatten vector parameter bias feature representation fully neural network feature representation baseline comparison representation perform hypothesize existence permutation equivalent neural network flatten feature vector representation address define equivalence define specific permutation node neuron within layer fully neural network collection layer exclude input layer output layer layer collection neuron neuron associate bias neuron hidden layer  node node denote permutation function vector  output simplicity notation output permutation define node permutation hidden layer transformation layer node reorder permutation intact layer replace node layer replace node permutation cannot perform output layer node permutation hidden layer neural network output neural network formally proposition permutation  neural network neural network obtain series node permutation hidden layer input permutation equivalent neural network neural network permutation equivalent neural network neural network obtain shift neuron neuron proof appendix illustration neural network perform function neuron hidden layer rearrange hidden layer node valid permutation neural network hidden layer node consecutively permutation equivalent permutation equivalence account equivalent neural network flatten representation naive meta classifier useful confirm equivalent obtain exist popular optimization technique neural network input predicts input positive negative apart output node hidden layer node neural network task sgd distribution hidden node distribution hidden node visualize plot hidden node input 2D session 3D ML CCS october toronto canada heatmap symmetry hidden node neural network predict input positive plot neural network darker indicates occurrence bin plot symmetric along plot highlight intuition existence permutation equivalent neural network vector flatten vector feature representation neural network inherently neuron however neuron layer preference inspire handle permutation data structure propose approach node permutation equivalence neural network sort neuron layer treat layer neuron approach improvement effectiveness inference task inference task approach achieve perfect accuracy empirically demonstrate node permutation equivalence ineffectiveness approach apply neural network approach approach meta classifier tackle permutation equivalence neural network neuron sort task infer permutation equivalent computer vision task rotate image facial recognition model rotation account consequently recognize hence address achieve performance approach align image canonical align somewhat parallel image employ pre processing image algorithm improve performance inspire technique propose away permutation equivalent shadow classifier canonical permutation equivalent classifier canonical facial recognition model perform worry sideways orient meta classifier perform longer concept equivalent proposition perform node permutation hidden layer fully neural network without function hence apply permutation imposes canonical sort hidden layer neural network ensure permutation equivalent representation magnitude sum node metric sort metric illustration network canonical permutation equivalent algorithm summarizes approach classifier return sort feature representation essentially hidden layer compute metric node permutation sort metric  function algorithm apply permutation node permutation layer sort flatten bias flatten function suggests obtains linear vector bias sort layer layer manner obtain sort canonical classifier sort layer individually advantage approach sort feature representation neural network flatten vector allows technique generic machine algorithm decision neural network meta classifier sort serf preprocessing enhances effectiveness attack neural network neural network neural network permutation equivalent canonical neural network sort magnitude sum descend representation task intelligent meta classifier instead motivate highlight difference vector vector specific vector multiple permutation unordered henceforth refer unordered advantage propose neural network layer session 3D ML CCS october toronto canada algorithm neuron sort input neural network metric function output sort feature representation metric metric metric metric sort layer  metric sort layer permute layer flatten flatten return flatten node processing layer summation concatenation prediction workflow meta classifier learns representation neural network  architecture flatten vector node instead neuron neural network collection fully layer layer neuron neural network input layer contains neuron hidden layer contains neuron output layer permutation layer technically multiset instead technique applicable multisets additionally parameter neural network generally  likelihood duplicate representation crucial address permutation equivalent however representation merit cannot perform inference generic machine classifier rarely vector input representation cannot effectively interpret representation representation specialized meta classifier compute function employ  architecture formulation architecture learns function recall function computes representation representation sum obtain representation network prediction function apply summation unweighted allows function permutation invariant suitable task highlight workflow specialized meta classifier representation shadow classifier neural network hidden layer output layer representation correspondingly tth instance layer comprise neuron layer network correspondingly layer network prediction obtain  representation summation network network operates representation layer fully network essence broken manner node layer flatten bias vector vector correspond network layer obtain node representation node processing input flatten bias node concatenate node representation previous layer hence input node bias context along bias capture function perform locally neuron context node perform respect input neuron compute sum sum input obtains precede layer another neuron obtain sum difference input obtains precede layer neuron locally perform function summation context hence node representation capture context input neuron node processing layer summation node representation neuron sum session 3D ML CCS october toronto canada obtain layer representation finally layer representation concatenate fed input network prediction context input classifier pseudocode algorithm summarizes approach innovative performs baseline memory overhead shadow classifier algorithm representation input neural network function layer function output node feature obtain layer feature obtain classifier feature return predict evaluation datasets target model target technique effectiveness efficiency demonstrate impact attack datasets census income census income dataset contains census data extract population survey conduct census bureau dataset demographic employment related attribute gender education occupation marital status citizenship classification task predict earns census attribute mnist mnist dataset widely digit recognition dataset dataset contains handwritten digit sample training sample data sample greyscale image normalize digit image classification classification task recognize digit image  attribute celeba celeba attribute dataset celebrity image binary attribute annotation gender wavy etc image pixel dataset classification task classification task detect task gender hardware performance counter HPCs data collection technique developed hardware performance counter datasets model detect cryptocurrency mining application perf sample rate profile cryptocurrency mining application non mining application rodinia parboil benchmark suite application appendix hardware performance counter data application desktop intel core cpu 0GHz ubuntu application profile sample profile sample contains performance counter cpu cycle execute instruction overall generate dataset contains attribute setup evaluation neuron sort approach sort representation approach baseline approach flatten vector feature representation conduct desktop intel xeon 8GHz cpu 6GB ram operating ubuntu neural network model pytorch nvidia geforce gtx gpu setting target model target model classification task datasets described model HPCs dataset census dataset neural network hidden layer mnist dataset neural network hidden layer celeba dataset pre network facenet generate image representation embeddings facenet fully neural network hidden layer input embed instead image pixel pre facenet model fix training model directly embeddings generate facenet model without update training target model adam optimizer relu activation function rate decay maximum epoch training target target infer target model target model census dataset target  data sample specific attribute gender similarly celeba dataset target  data sample facial attribute mnist dataset infer target model noisy image noisy image random brightness jitter image HPCs dataset infer target model data machine vulnerable meltdown spectre attack machine patch performance counter stall cycle frontend stall cycle backend dcache prefetch llc prefetches session 3D ML CCS october toronto canada setting dataset classification task target model target dataset target classifier task target target census census binary income prediction proportion distribution census census binary income prediction proportion income LI distribution LI census census binary income prediction dataset distribution mnist mnist digit classification noisy image random brightness jitter image celeba celeba prediction proportion attractive distribution celeba celeba prediction proportion distribution celeba celeba prediction proportion male distribution celeba celeba gender classification proportion attractive distribution celeba celeba gender classification proportion distribution HPCs HPCs mining activity detection data meltdown spectre vulnerable machine data patch machine attack effectiveness accuracy inference attack approach baseline sort census census census mnist celeba celeba celeba celeba celeba HPCs neural network model reveal target model generate model training model model useful release reasonable quality generate model reasonable performance classification task generate model accuracy mnist dataset model accuracy HPCs dataset attacker goal target model reveal binary prediction useful meta classifier accuracy random accuracy approach infer target inference task difficulty meta classifier census baseline focus FCNNs FCNNs mnist dataset demonstrate attack accuracy dataset achieve ML model approach performs badly accuracy sort approach outperforms baseline approach demonstrate permutation equivalence important source complexity meta classifier approach performs accuracy significant improvement baseline census excellent performance approach attribute parameter meta classifier classifier easy evaluation precision recall accuracy omit precision recall precision recall HPCs celeba attack efficiency evaluate efficiency approach along aspect meta training dataset described meta classifier shadow classifier training dataset meta classifier accuracy meta classifier meta training dataset approach meta classifier accuracy training data approach sort approach baseline approach data approach meta classifier accuracy infer target model approach training shadow classifier training meta classifier meta classifier parameter parameter meta classifier architecture baseline sort approach meta classifier vector neural network vector representation input parameter parameter neural network approach meta classifier  architecture parameter meta classifier sum session 3D ML CCS october toronto canada accuracy meta training baseline sort meta classifier accuracy mnist accuracy meta training baseline sort meta classifier accuracy celeba accuracy meta training baseline sort meta classifier accuracy HPCs accuracy meta classifier meta training dataset parameter network network described comparison meta classifier parameter meta classifier census mnist HPCs celeba vector meta classifier approach magnitude parameter approach training  approach memory training sort approach baseline approach infer vulnerability hardware performance counter dataset demonstrate attacker approach effectively infer potential vulnerability neural network model producer hardware performance counter detect covert cryptomining enterprise suppose enterprise covert cryptomining detector neural network HPCs data machine patch meltdown spectre vulnerability apply patch notable performance impact affect performance counter data indeed performance counter propose detect meltdown spectre attack influence model enterprise covert cryptomining detector adversary access model analyze infer machine vulnerable meltdown spectre information adversary perform attack enterprise demonstrate attack HPCs dataset  described machine vulnerable meltdown spectre operating machine instal patch meltdown spectre operating machine ubuntu another HPCs dataset patch machine patch instal cryptomining detector  HPCs dataset another detector patch dataset truth vulnerability training machine meta classifier approach effectiveness baseline approach accuracy predict model producer machine vulnerable meltdown spectre approach however achieves accuracy infer vulnerability precision recall precision recall approach HPCs precision recall baseline sort vulnerable vulnerable model producer cryptomining detector release data collection setting cpu operating along model attacker HPCs dataset configuration otherwise attacker enumerate configuration HPCs dataset configuration manageable limited active CPUs OSes simulate scenario another HPCs dataset another machine configuration shadow classifier accuracy approach approach achieve accuracy accuracy inference attack nonoverlapping datasets baseline sort HPCs celeba infer training data distribution distribution training data confidential information classifier producer infer hidden distribution competitor training data session 3D ML CCS october toronto canada uncover secret  effective classifier infer training data distribution release model confirms model producer training demonstrate approach improve effectiveness discover disproportionate data distribution neural network complex classification task attribute prediction detection gender classification machine task model producer release neural network model detection gender classification described model datasets proportion attractive evaluate effectiveness approach discover disparity however facial attribute prediction complex task image convolutional neural network achieve performance training model scratch amount computational resource model performance boost exist pre model technique leverage pre model facenet model  model customize classification task model producer pre model model detection gender classification described target model pre facenet model fix dimensional embeddings generate layer neural network shadow classifier structure parameter layer neural network feature representation evaluation baseline approach reasonable performance around accuracy approach achieves perfect accuracy discover proportion training dataset precision recall besides approach achieves perfect accuracy shadow classifier baseline approach amount resource perform inference task baseline approach approach effective adversary  layer parameter knowledge underlie pre network model producer simulate scenario adversary celeba dataset non overlap dataset model producer similarly approach achieve accuracy disproportionate ratio seemingly unrelated attribute attractiveness embed discover accuracy neural network model classify gender detect discussion limitation future neural network mainly focus fully network however fully FC layer precision recall approach celeba precision recall baseline sort attractive unattractive widely sort neural network convolutional neural network perform inference FC layer output pre convolutional model apply approach neural network equivalent computational layer investigate inference attack computational layer future overfitting overfitting factor model vulnerable membership inference attack however overfitting target classifier role inference attack model generalizability accuracy relationship overfitting inference detail future membership inference membership inference inference related propose membership inference infer member training dataset infer however membership inference usually member relatively uncertainty practical infer member dataset celeba inference instead focus directly relationship membership inference inference future multi label regression currently binary inference however powerful attack entail predict multiple infer operating model provider mining detector perform regression task predict ratio gender detector preliminary promise approach extend multi regression task detailed analysis future generate training data shadow model  attacker training data shadow classifier although generate training data focus exist approach facilitate generation training data attacker access training dataset public accessible datasets celeba knowledge dataset generation technique generate synthetic training data target model  synthesis technique data generation future alternative approach addition neuron sort representation briefly investigate alternative approach discus exploration alternative approach session 3D ML CCS october toronto canada augmentation machine data augmentation strategy improve generalizability ML model training dataset expand data generate deterministic randomize transformation data augmentation image achieve rotate noisy image dataset similarly node permutation equivalence generate permutation equivalent augment meta classifier training dataset generalizes across equivalent however approach marginal improvement baseline approach permutation equivalent  therefore impractical generate permute version classifier graph representation neural network visualize graph intuitive neural network graph neuron layer input output layer treat node node layer node graph derive correspond neuron neural network representation meta classifier interpret propose graph structure building meta classifier graph convolutional network gcn propose however approach mixed performance inference task performance others additionally resource meta classifier propose approach performance inference task gcn architecture address permutation equivalent directly isomorphism graph representation GCNs task analysis social network sparser regular structure neural network accuracy classification reasonable classifier dataset performance datasets indeed frequently voiced concern regard fairness machine algorithm bias data suggests strategy infer training dataset analyze target classifier performance datasets variously advantage strategy apply investigate classifier noisy version mnist data version described evaluate performance classifier noisy plot slight trend classifier perform however difference distribution marginal investigate inference knn  dimensional label training classifier noisy accuracy noisy mnist image accuracy mnist image classifier noisy mnist classifier mnist accuracy noisy axis axis classifier noisy training slight trend classifier data perform marginally data vice versa separation classifier mnist training respectively evaluate performance knn meta classifier inference sort approach accuracy knn classifier consistently outperform baseline performs approach however accuracy classifier without useful additional input classifier model parameter future accuracy inference attack knn classifier accuracy approach baseline sort knn census census census mnist defense inference attack leverage similarity model parameter predict target model reveal defend attack model producer manipulate parameter model directly indirectly shadow model attacker meta classifier discus defense inference attack principle node multiplicative transformation observation neuron activation function relu LeakyReLU bias neuron session 3D ML CCS october toronto canada constant layer constant output neural network randomly neuron layer perform transformation random constant neuron celeba dataset attack accuracy approach decrease increase perturbed neuron however defense neural network relu LeakyReLU activation function noisy data training another approach defend attack noisy data training model producer flip label training sample affect model parameter increase difficulty inference task HPCs dataset randomly flip label training data target classifier accuracy target classifier inference accuracy approach significantly however defense unlikely deployed model producer noisy data hamper effectiveness consequently utility model encode arbitrary information neural network capacity memorize arbitrary information encode significant amount information training neural network model maintain model quality generalizability attack involves update model parameter extra information attack employ instead potential defense attack model producer technique encode arbitrary information model parameter shadow classifier possibly hamper meta classification task related assort inference attack previously launch machine model propose concept inference attack demonstrate svm hmm model application technique succeed neural network permutation invariant representation attack effective apart inference privacy threat ML model membership inference attack ML model aim infer specific data target model training dataset attack strategy multiple shadow model attack classifier ultimately perform membership inference target model generative adversarial network perform membership inference attack generative model however membership inference focus privacy individual concept information leakage concern confidential information reveal training dataset beyond prediction model intend perform model inversion attack aim infer information data ML model incomplete information data invert linear regression model infer patient genomic marker correspond output model auxiliary demographic information invert decision neural network predict confidence leak confidential information data membership inference attack attack focus individual recent membership inference attack model inversion attack deeply related sensitive overfitting target model model extraction attack seek obtain parameter ML model output predicts chosen input  demonstrate successfully extract popular model logistic regression SVMs neural network production  provider successfully reverse engineer internal information architecture hyperparameters blackbox neural network model attack attack adversary model extraction obtain equivalent model target model perform inference model infer confidential propose framework steal hyperparameters objective function machine algorithm neural network treat hyperparameter neural network mini batch training approach infer hyperparameter beyond data inference ML model variety attack adversarial attack detector classifier malicious algorithm  memorize training data sample malicious classifier mislead classifier misbehave presence input trigger inference attack neural network risk user machine conclusion inference attack fully neural network model developed concept permutation invariance address complexity task specifically developed approach leverage permutation invariance neuron sort representation infer global training datasets model producer intend approach effective infer various data datasets practical impact identify machine cryptomining detector model patch vulnerability detect unbalanced training dataset distribution identify direction future extend neural network layer session 3D ML CCS october toronto canada fully perform multi regression  task develop countermeasure inference attack permutation invariance application beyond inference quality assurance FCNN model