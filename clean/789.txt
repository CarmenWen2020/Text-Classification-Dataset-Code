application technique security concern training data data investigate model inversion adversarial setting adversary aim infer information target model training data data model prediction develop neural network inverse target model perform inversion inversion model access target model propose technique towards training inversion model adversarial setting leverage adversary background knowledge compose auxiliary inversion model access training data truncation technique align inversion model enable effective inversion target model partial prediction adversary obtains victim user data systematically evaluate approach various machine task model architecture multiple image datasets confirm amazon rekognition commercial prediction api machine service partial knowledge model training data partial prediction inversion approach perform accurate inversion target model outperform previous approach CCS CONCEPTS security privacy domain specific security privacy architecture compute methodology neural network keywords neural network model inversion security privacy introduction machine ML model neural network become ubiquitous extremely variety application adoption machine technology increase capacity software amount complex data enable application facial recognition apis amazon rekognition apis facial attribute emotion openness online service evaluate user user social medium prediction definitely link input data apparent accuracy data recover security concern arise application model inversion technique aim obtain information training data model prediction research effort model inversion largely approach inverts model  optimization data approach optimization approach model inversion attack mia propose infer training neural network generate representative sample target cast inversion task optimization optimal data mia network ineffective complex neural network convolutional neural network cnn mainly optimization objective optimization approach really capture semantics data discus approach inverts model model inverse approach training approach aim reconstruct image computer vision feature activation layer neural network therefore maximally reconstruct image obtains session ML security CCS november london united kingdom model prediction vector training data classifier focus adversarial scenario adversary classifier prediction aim input data semantics classification inversion attack wherein information input data infer prediction adversarial inversion setting namely data reconstruction training inference data reconstruction attack adversary reconstruct unknown data classifier prediction vector exactly inversion classifier facial recognition classifier output identity facial image attacker goal reconstruct facial image training inference attack aim recover semantically meaningful data training classifier mention facial recognition attack goal recover recognizable facial image arbitrary training data attack achieve invert classifier generate representative sample classify however inversion adversarial setting exist model inversion setting specifically adversarial setting attacker classifier training data previously training training data inversion model cannot directly apply exist optimization approach access classifier compute gradient therefore cannot classifier blackbox importantly adversary obtain partial prediction victim data imagenet dataset majority prediction vector practical release predict victim user partial predict social medium partial prediction largely limit reconstruction ability inversion model invert truncate prediction vector mask probably due overfitting inversion model hence although reconstruction accurate prediction vector slight deviation truncation prediction vector dramatically formulate model inversion adversarial setting propose effective approach attack adopt mention training approach neural network refer inversion model perform inversion address lack access training data approach training data inversion model generic data distribution background knowledge auxiliary sample arguably easy adversary obtain instance facial recognition classifier adversary randomly crawl facial image internet compose auxiliary without training data distribution reconstruction inversion model auxiliary sample reconstruct facial image recognizable training data reconstruction training inference prior TB truth mia prior TB training data reconstruction training inference previous approach facial recognition classifier approach training TB prediction available invert prediction vector training inversion model auxiliary sample approach mia prior TB auxiliary sample approach inversion commercial prediction api recover victim truth individual inversion model training auxiliary sample retain generic facial feature information sufficient regularize originally ill inversion interestingly actual training data available augment training data generic sample improve inversion accuracy inversion model adversary obtains partial prediction victim user data propose truncation training inversion model inversion model truncate prediction auxiliary sample training truncation inversion model maximally reconstruct sample truncate prediction align inversion model truncate furthermore truncation reduce overfitting feature selection invert partial prediction vector mask truncation technique clearly outperforms session ML security CCS november london united kingdom truncation technique effective training inference infer training truncate classifier prediction auxiliary sample vector training representative sample training vector input training inference significantly outperforms mia previous training approach adversary role training inversion model adversary user training data access classifier prediction available construct inversion model training model scratch adversary developer classifier inversion model jointly classifier training data derives precise inversion model later objective classifier prediction preserve essential information inversion model reconstruct data reconstruction loss inversion model regularize training classifier evaluate approach various machine task model architecture multiple image datasets attack precisely reconstruct data partial prediction without training data distribution outperforms previous approach training inference confirm inversion technique amazon rekognition api detects facial feature emotion beard gender user uploaded image knowledge backend model api accurately reconstruct victim user limited information highlight information hidden model prediction extract adversary access limited information contribute strengthen user awareness handle derive data contribution summary contribution partial knowledge training exploit background knowledge regularize originally ill inversion formulate practical scenario adversary obtains partial prediction propose truncation aligns inversion model truncate prediction inversion adopt training inference attack experimental outperforms exist training inference classifier training available augment generic sample improve inversion accuracy background machine focus supervise specifically training classification model classifier neural network model prediction input data lifecycle model typically consists training phase model inference phase model release machine model machine classifier encodes hypothesis function parameter training dataset goal prediction unseen data input function data drawn data distribution dimensional dimension attribute feature data output predict dimensional dimension corresponds predefined objective relation input data function neural network model consists multiple layer non linear activation function neuron connection model parameter normalize exponential function softmax exp exp activation signal refer logits layer function convert arbitrary vector sum output interpret probability input training phase data drawn underlie data distribution vectorized training goal function approximate mapping data loss function difference classifier prediction formally training objective function minimizes loss actual probability function intractable accurately estimate sample drawn sample compose training predefine data supervision training hence model minimize empirical loss training LD nonetheless objective overfitted model attains prediction error training data fails generalize unseen data drawn  regularization usually loss LD prevent overfitting training data summary training classifier model minimizes objective LD regularization factor balance classification function regularization function algorithm optimization variant gradient descent algorithm stochastic gradient descent sgd efficient update parameter gradually compute average gradient randomly subset mini batch training data inference phase inference phase phase model classify unseen data specifically function session ML security CCS november london united kingdom data drawn data distribution input output prediction vector probability data belonging model inversion approach related previous invert neural network machine computer vision community invert neural network understand interpret model behavior feature representation typical inversion computer vision reconstruct image computer vision feature hog sift activation layer network classifier prediction inversion approach category optimization inversion approach training inversion optimization inversion apply gradient optimization input image prediction approximates inversion generate representative image training inference replace vectorized image minimize loss function therefore access model compute gradient however invert prediction neural network actually ill optimization tends image really resemble image neural network furthermore approach involves optimization compute gradient relatively per image gpu discussion optimization inversion appendix training inversion inversion another neural network refer inversion model invert specifically training image prediction learns neural network scratch approximate mapping prediction image inverse mapping inversion model prediction input output image formally inversion model minimizes objective image reconstruction loss loss adopt contrast optimization inversion  inversion costly training inversion model effort reconstruction prediction pas network per image gpu adversarial model inversion adversary user blackbox classifier developer adversary capability goal role scenario curious user intend reconstruct victim input data victim truncate predication vector curious user intend infer functionality malicious developer intend subsequently reconstruct victim input truncate predication vector scenario data reconstruction blackbox classifier scenario adversary curious user infer classifier training data victim user input data data adversary access adversary adaptively input obtain output adversary classifier training data distribution architecture parameter however adversary background knowledge specifically adversary although adversary actual training data adversary sample generic distribution training data instance suppose recognition classifier individual although adversary individual adversary training data facial image sample pool facial image intuitively distribution generic distribution dimension reduction apply adversary input format distribution adversary output format adversary dimension predication vector assumption reasonable return prediction adversary estimate dimension prediction vector query input data distinct return prediction dimension classifier benign user assume adversary capability obtain truncate predication vector input victim user predefined parameter victim prediction vector truncate denote  remain truncate zero instance trunc access sample distribution adversary data distribution trunc ideally adversary satisfies arg max trunc obtain data reconstruction session ML security CCS november london united kingdom scenario training inference scenario scenario adversary curious user access classifier sample generic distribution instead data reconstruction adversary representative data training access classifier target adversary data satisfies arg max confidence classify scenario joint classification model inversion scenario adversary malicious developer classifier distributes user previous scenario adversary knowledge classifier training data architecture parameter freedom assume release adversary obtain truncate predication user adversary reconstruct user input hence scenario adversary goal classifier accuracy requirement classifier task improve quality data reconstruction apply prior adversarial setting highlight difference adversary capability adversarial setting previous inversion setting adversarial setting adversary user access classifier exist  inversion approach mia access compute gradient besides mia neural network tends semantically meaningless image resemble image experimental conclusion adversary user classifier training data impossible previous training approach inversion model training data adversary user developer obtain truncate prediction instead previous inversion model prediction ineffective reconstruct data partial prediction approach approach adopts previously mention training strategy invert classifier overall framework unlike optimization approach invert prediction vector directly inversion model later prediction vector input output reconstruct sample autoencoder framework training inversion approach classifier data input prediction vector inversion model output reconstruct data prediction input encoder decoder prediction latent aspect autoencoder scenario unlike autoencoder fix furthermore training data available describes obtain training adversary obtains truncate prediction realign latent propose truncation scenario although fix unlike autoencoder additional requirement accuracy joint classifier inversion model classifier inversion model training training data auxiliary important component construction training refer auxiliary auxiliary sufficient semantic information regularize ill inversion compose auxiliary sample generic data distribution training data distribution facial recognition classifier individual auxiliary sample compose public facial image random individual internet auxiliary sample retain facial feature location semantic feature training data feature sufficient information regularize originally ill inversion task improve reconstruction quality specially auxiliary align inversion model facial recognition classifier dataset mostly frontal auxiliary align inversion model frontal experimental demonstrate effectiveness sample auxiliary generic data distribution inversion model precisely reconstruct training data training construction truncation model inversion propose truncation training align partial prediction architecture classifier inversion model session ML security CCS november london united kingdom truncate input classifier prediction inversion model trunc trunc trunc reconstruction loss auxiliary trunc classification loss training truth architecture classifier inversion model classifier data input prediction prediction vector truncate vector trunc inversion model truncate prediction input output reconstruct data trunc truncate classifier prediction auxiliary sample dimension partial prediction vector victim user data input feature inversion model maximally reconstruct input data truncate prediction formally sample drawn classifier prediction dimension partial prediction vector victim data truncate prediction vector dimension preserve inversion model minimize objective  loss function norm truncation understood feature selection remove unimportant confidence reduce overfitting reconstruct input data preserve important  adversary truncate prediction obtain reconstruct inversion model adopt perform training inference scenario adversarial goal mia training inference adversary information target generate representative sample training mia assumes adversary access inference phase contrary blackbox access besides release predict confidence approximate training distinct classifier prediction auxiliary greatly reduces requirement adversary capability infer training experimental truncation training inversion model improves reconstruction quality truncate prediction previous training approach directly input partial prediction inversion model meaningless reconstruction evaluation detail joint training classifier inversion model adversary developer classifier jointly inversion model classifier inversion quality classifier training data regularize classification loss LD equation additional reconstruction loss RD intuitively encourages classifier prediction preserve essential information input data latent inversion model decode recover input data norm reconstruction loss RD RD trunc joint training ensures update classification task meanwhile optimize reconstruct data truncate prediction vector worth training directly prediction vector optimal inversion logits output layer sum prediction softmax function actually weakens activation output layer loses information later decode address issue rescale prediction correspond logits replace prediction session ML security CCS november london united kingdom data allocation classifier inversion model classifier inversion model task data auxiliary data distribution FaceScrub FaceScrub data celeba generic cifar distinct mnist mnist data label mnist label generic cifar distinct wise scalar wise optimize training inversion model EXPERIMENTS evaluate inversion performance exist evaluate factor choice auxiliary truncation prediction evaluate approach commercial recognition api amazon experimental setup perform evaluation benchmark image recognition datasets simplicity datasets transform greyscale image pixel detail dataset FaceScrub dataset URLs image individual image individual URLs available extract image accord official bound information image resize celeba dataset image celebrity internet remove celebrity FaceScrub  obtain image celebrity modify celeba intersection FaceScrub facial image dataset generic data distribution extract image official  version width height upper coordinate image resize resize cifar dataset consists image airplane automobile deer frog image resize resize mnist dataset compose handwritten digit image image resize FaceScrub mnist target classifier dataset separately inversion model training training drawn generic distribution training drawn distribution arguably semantically training data generic distinct respectively data allocation correspond auxiliary generic data distribution intersection training data FaceScrub mnist specifically data data dist generic dist distinct dist truth auxiliary inversion quality FaceScrub auxiliary generic distinct data distribution inversion model celeba remove celebrity FaceScrub dataset randomly digit mnist digit auxiliary auxiliary distinct data distribution compose sample drawn explicitly data distribution training data cnn transpose cnn FaceScrub classifier cnn consists convolutional layer batch normalization layer max pool layer relu activation layer fully layer cnn softmax function layer convert arbitrary neural signal vector sum FaceScrub inversion model consists transpose cnn transpose convolutional layer succeed batch normalization layer tanh activation function transpose convolutional layer sigmoid activation function convert neural signal auxiliary data mnist classifier inversion model architecture FaceScrub cnn classifier transpose cnn inversion model detail model architecture appendix FaceScrub classifier mnist classifier achieve accuracy respectively comparable classification performance  workstation ubuntu lts equip intel xeon CPUs  core 6GB ram nvidia tesla gpu pytorch implement neural network query training equivalent auxiliary sample roughly FaceScrub mnist auxiliary performs inversion attack pas neural network prediction input millisecond session ML security CCS november london united kingdom data data dist generic dist distinct dist truth auxiliary inversion quality mnist auxiliary generic distinct data distribution inversion model quantitative measurement error auxiliary inversion quality distribution FaceScrub mnist dist generic dist distinct dist auxiliary inversion quality inversion scenario randomly chosen training data data error reconstruct image truth closer auxiliary data distribution training data distribution inversion quality visually quantitatively worth auxiliary generic data distribution intersection classifier training data inversion model training construction accurately reconstruct data digit mnist auxiliary reconstruct digit fairly accurately demonstrates generic background knowledge sufficient regularize ill inversion however auxiliary data distribution generic data distribution inversion satisfactory summary knowledge classifier training data accurate inversion training auxiliary sample drawn generic distribution derive background knowledge inversion alignment  subset frontal  subset auxiliary specific auxiliary align inversion opencv library python fan network detect facial orientation appendix detail eventually frontal inversion randomly chosen training data data FaceScrub classifier specific auxiliary align inversion correspond facial orientation worth auxiliary drawn specialized distribution contains contrast training data contains truncation denote dimension partial prediction adversary obtains victim user data perform inversion attack scenario FaceScrub classifier mnist classifier truncation previous  without truncation FaceScrub classifier mnist classifier auxiliary compose sample generic data distribution FaceScrub classifier data distribution mnist classifier training data data randomly chosen approach outperforms previous approach approach highly recognizable image previous approach although generate recognizable image meaningless approach relatively inversion generic target facial detail fully truth inversion frontal becomes demonstrates truncation indeed reduce overfitting align frontal facial image generalization perform quantitative measurement inversion quality error approach prior approach summary II truncation training inversion model perform accurate inversion adversary partial prediction prediction investigates truncate prediction investigate prediction dimension prediction randomly FaceScrub mnist datasets training data session ML security CCS november london united kingdom frontal data data truth truth recover recover auxiliary inversion alignment auxiliary frontal celeba inversion model FaceScrub classifier randomly chosen training data data error data data prior data prior data quantitative measurement truncation  inversion quality FaceScrub axis axis error FaceScrub mnist inversion FaceScrub classifier mnist classifier assume adversary obtains prediction vector auxiliary compose sample generic data distribution FaceScrub classifier data distribution mnist classifier training data data randomly chosen experimental accurate reconstruction target data semantically generic inversion correspond quantitative measurement inversion quality error inversely proportional affect amount predict information adversary factor decides prediction vector factor decides predict classifier release dimension prediction vector truth data data prior prior prior prior truncation inversion quality FaceScrub previous approach odd respectively training inference evaluates inversion model training inference attack scenario mia previous training approach truncation FaceScrub attack celeba auxiliary intersection FaceScrub hence inversion model target training construction auxiliary approximate training obtain actually training inversion model encode classifier prediction auxiliary sample predict confidence dimension vector zero encode prediction feature convert training vector dimension session ML security CCS november london united kingdom truth data data prior prior prior prior truncation inversion quality mnist previous approach odd respectively truth data data prediction inversion quality FaceScrub truth data data prediction inversion quality mnist vector  output  infer image training implement prior mia attack algorithm similarly  adversary information target label error data data quantitative measurement prediction inversion quality FaceScrub axis axis error prior attack attack training mia training prior TB training inference mia previous training TB inversion inversion function  denoising filter gaussian sharpen filter inversion previous infer image mia semantically meaningless recognizable mia apply cnns consistent conclusion previous research unsatisfactory inversion obtain previous training inversion fail recognizable facial image generate highly recognizable capture semantic feature beard consistently frontal training facial image various angle expression background lightning auxiliary data consists majority frontal training aligns inversion model training distribution recognizable frontal generate session ML security CCS november london united kingdom blackbox truth truth jointly blackbox data blackbox jointly inversion blackbox FaceScrub jointly FaceScrub augment training data celeba auxiliary blackbox truth truth jointly blackbox data blackbox jointly inversion blackbox mnist jointly mnist classification accuracy classifier average reconstruction loss mse inversion model report classifier acc acc acc mse mse mse FaceScrub mnist access jointly access training data augment celeba summary outperforms previous training inference complex neural network experimental generate highly recognizable representative sample training inversion model construction blackbox jointly inversion  fix blackbox scenario jointly scenario evaluate inversion quality classification accuracy construction construction factor affect inversion performance training data auxiliary construction blackbox training detail epoch batch optimizer construction perform data reconstruction FaceScrub mnist classifier split classification dataset training data data inversion construction FaceScrub mnist classifier construct jointly training accurate reconstruction data blackbox quantify reconstruction quality average reconstruction loss namely error mse construct joint training actually reconstruction loss intuitive joint training prediction vector preserve essential information input data along classification information decode reconstruction however reconstruction quality achieve classification accuracy classification accuracy classification accuracy joint training within acceptable classification accuracy FaceScrub accuracy earlier previously dataset certainly adversary malicious developer scenario abandon joint training achieve accuracy adversary interestingly adversary training auxiliary augment training celeba auxiliary average reconstruction loss augment training generic data inversion model blackbox achieve comparable reconstruction quality jointly summary IV inversion model jointly classifier outperforms blackbox inversion quality acceptable accuracy loss augment auxiliary generic data  blackbox comparable jointly maintain accuracy commercial prediction api evaluate approach commercial amazon rekognition api detects facial feature user uploaded image knowledge backend model api query api auxiliary dataset prediction facial feature input inversion model evaluate session ML security CCS november london united kingdom quantitative measurement error inversion amazon rekognition api feature unknown individual individual unknown image remove landmark remove landmark feature inversion model reconstruct unknown individual image individual unknown image celeba dataset auxiliary remain victim image individual FaceScrub dataset victim image unknown individual query api celeba image obtain accurate prediction inversion model architecture resize image summary query auxiliary sample amazon rekognition api query victim image ability reconstruct victim data training roughly amazon rekognition api feature emotion facial attribute bound facial landmark quality confidence discard bound quality confidence remain feature standardize feature facial landmark coordinate convert ratio distance bound boundary width height upper origin appendix preprocessed predict facial feature inversion model truncate feature respectively feature feature remove landmark feature remove landmark robustness approach feature victim image respectively predict feature victim image input inversion model accurately reconstruct image besides capture information api recovers information cheek predict feature significant inversion landmark information remove inversion model input recover recognizable landmark information remove recover satisfactory capture facial feature  beard gender content api output perform quantitative measurement inversion quality confirm conclusion visually quantitatively truth feature remove landmark unknown individual individual unknown image remove landmark inversion amazon rekognition api  feature remove landmark api output victim image feature remove landmark feature discussion prior establish connection overfitting training data inference prior model inversion attack membership inference attack deeply related sensitive overfitting target model recent leverage overfitting embed private information training data model contrary leverage generalization transfer information auxiliary dataset task training generalization enables model adapt properly previously unseen data transfer apply knowledge gain related auxiliary data related transfer specifically prediction generalize auxiliary data drawn generic data distribution encode information capture hidden useful information reconstruct input data truncation focus important feature hence extremely overfitting model useful information prediction however usually model trend user publishing derive prediction directly indirectly iOS built functionality allows user AR emojis derive user social medium platform asks user prediction fortunately prediction coarse fully invert model however potential enhance version prediction service accurate future accurate inversion attack besides  privacy policy abuse user uploaded data seldom mention derive prediction hopefully session ML security CCS november london united kingdom encourage update privacy policy explicitly derive prediction handle model inversion attack leak useful information malicious facial recognition adversary recover representative individual facial image training data however oppose attack classify privacy attack related ML privacy researcher strongly ML model suffer various privacy threat training data instance access ML model adversary infer non trivial useful information training membership inference attack enables adversary choice private training model inversion attack infer representative sample sensitive attribute training data improves sensitive attribute inference formalize without non sensitive attribute adversary infer statistical information training dataset inference phase target model similarly investigate information leakage collaborative training phase recent privacy issue collaborative ML service platform mention attack infer sensitive attribute statistical information training data others extract training data manipulate training model membership inference attack inference phase data examines reconstruct specific training data data prediction inference phase ML adversarial setting various ML model likely vulnerable adversarial setting adversary victim model deviate intend task behave erratically accord adversary adversary stage attack corrupt training phase poison training adversarial data augmentation employ adversarial loss function maliciously modify victim model victim model adversarially craft sample focus contrary deviate ML model intend task investigate possibility reconstruct input data model prediction secure privacy preserve ML wake security privacy threat ML technique research devote provision secure privacy preserve training ML model threat model assume technique privacy user data contribute training threat model wherein adversary target reconstruct user data model prediction research prediction ML model propose recently  feldman model prediction achieve differential privacy respect training data mapping prediction vector input data training another inversion model propose  framework secure neural network inference cryptographic however user prediction predict social medium exposure model prediction ML inversion  neural network demonstrate impressive performance various application remains perform research interpret understand neural network invert neural network important understand representation neural network research inverts neural network understand interpret inversion leverage information model training data contrary inverts neural network adversarial setting adversary capability limited conclusion propose effective model inversion approach adversary training inversion model inverse model knowledge training data accurate inversion training inversion model auxiliary sample drawn generic data distribution propose truncation training inversion model truncate prediction input truncation align inversion model partial prediction adversary obtain victim user data experimental approach achieve accurate inversion adversarial setting outperform previous approach seemingly coarse information prediction causal information user developer surprising reconstruction accuracy inversion model apply adversarial setting future investigate loss function generative technique generative adversarial network incorporate adversarial inversion