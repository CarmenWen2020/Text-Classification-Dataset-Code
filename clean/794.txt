impressive performance perceptual however researcher vulnerable specially craft perturbation imperceptible perturbation classify adversarial potentially disastrous consequence safety security crucial prior defense adversarial target specific attack ineffective propose  framework defend neural network classifier adversarial  neither modifies classifier knowledge generate adversarial  detector network reformer network detector network differentiate normal adversarial approximate manifold normal assume specific generate adversarial generalize reformer network adversarial towards manifold normal effective correctly classify adversarial perturbation discus intrinsic difficulty defend whitebox attack propose mechanism defend graybox attack inspire randomness cryptography diversity strengthen  empirically  effective advanced attack blackbox graybox scenario without sacrifice false positive rate normal CCS CONCEPTS security privacy domain specific security privacy architecture compute methodology neural network keywords adversarial neural network autoencoder illustration reformer adversarial perturbation display adversarial generate normal carlini attack perturbation perturbation lack prominent fourth display adversarial reform  fifth display remain perturbation reform perturbation introduction recent demonstrate impressive performance task image classification processing however recent research attacker generate adversarial fool classifier algorithm perturbed benign correctly classify amount affect recognition neural network classify thesis neural network target classifier defense adversarial approach training target classifier adversarial adversarial training training classifier distinguish normal adversarial target classifier attack gradient pathway defensive distillation however approach limitation adversarial defense defense specific generate adversarial defensive distillation significantly increase robustness neural network moreover approach retrain target classifier engineering complexity session adversarial machine CCS october november dallas TX usa propose  defense adversarial novel neither modifies target classifier relies specific classifier neural network  target classifier blackbox  output classifier layer neither data internal layer modifies classifier  independent generate adversarial normal training adversarial normal classification task occurs naturally physical classification task generates non negligible probability task classify handwritten digit data generation rarely generates image tiger adversarial classifier normal classifier decision disagrees prevail judgment detailed discussion researcher speculate AI task relevant data manifold dimension sample suggests normal classification task manifold adversarial manifold probability classification classifier classifies adversarial adversarial boundary manifold task task handwritten digit classification adversarial image digit classifier option reject output label adversarial boundary manifold classifier generalizes poorly manifold vicinity adversarial classification occurs propose  mitigate  detector detect normal detector learns function distance manifold distance threshold detector reject  reformer reform adversarial autoencoders neural network attempt input output autoencoders leverage simpler hidden representation introduce regularization uncover useful data autoencoder adequate normal approximate manifold data adversarial boundary manifold autoencoder output manifold manifold normal particle dimensional attract nearby particle illustrate reformer unable particle illustrate detector autoencoder reform adversarial normal reformer  independent target classifier assume attacker target classifier parameter blackbox attack  attacker defense parameter evaluate  popular attack mnist dataset  achieve classification accuracy adversarial generate attack cifar dataset classification accuracy improvement significant particularly  achieve accuracy adversarial generate carlini attack powerful attack across confidence attack datasets defense without adversarial generate attack whitebox attack attacker parameter  attacker  target classifier composite classifier generate adversarial composite classifier surprisingly performance  whitebox attack degrade sharply carlini attack reformer attack generate adversarial fool reformer defense adversarial enhance target classifier enhance classifier imperfect unable decision adversarial guaranteed exist hiding defense mechanism parameter preclude whitebox attack advocate defense via diversity inspiration cryptography security cipher relies diversity attack brute computationally infeasible adopt approach defense randomly defend graybox attack implementation autoencoders described attacker cannot predict autoencoders generate adversarial fool diversity autoencoders grows becomes attacker adversarial technique classification accuracy carlini adversarial whitebox attack graybox attack advantage diverse autoencoders another detector distinguishes normal adversarial insight normal manifold classification decision transform autoencoder contrast adversarial manifold classification significantly transform autoencoder similarity output autoencoder metric contrast previous detector computes distance manifold without consult target classifer enlist target classifier assume classifier session adversarial machine CCS october november dallas TX usa output probability distribution label distribution output autoencoder random variable label jensen shannon divergence similarity although approach target classifier training specific classifier classifier compute similarity detector sensitive previous detector powerful attack contribution contribution formally define adversarial metric evaluate defense adversarial propose defense adversarial defense independent target classifier generate adversarial argue defend whitebox attack therefore propose graybox threat model advocate defend attack diversity demonstrate approach diversity background related adversarial environment increasingly important role autonomous robot vehicle financial medical treatment information security computer interaction security critical domain understand neural network security perspective recent demonstrate feasibility attack carefully craft input specifically researcher generate adversarial fool classifier algorithm perturbed normal volume affect recognition classification therefore classifier adversarial concern distance metric definition adversarial normal counterpart visually indistinguishable model perception researcher propose popular metric approximate perception visual difference namely metric norm metric focus aspect visual significance pixel correspond image pixel euclidean distance image maximum difference pixel correspond image consensus metric evaluate defense metric exist attack discovery adversarial neural network researcher adversarial various network architecture feedforward convolutional classification network generative network recurrent network adversarial threaten application classification semantic segmentation researcher developed generate adversarial leveraged gradient optimization normal effective universal adversarial perturbation apply image adversarial simplify discussion focus attack target neural network classifier evaluate defense popular arguably advanced attack explain attack gradient FGSM normal image gradient image neighborhood fool classifier defines loss function loss describes classify label transforms maximize loss classify image truth label perturbation gradient solves optimization perform gradient update image volume update width identical pixel update direction gradient pixel formally adversarial calculate  loss although attack powerful normally increase usually attack rate FGSM refer attack iterative gradient propose improve FGSM finer iterative optimization strategy iteration attack performs FGSM width clip update update image neighborhood iteration ith iteration update   loss update strategy metric greatly improves rate FGSM attack refer attack iterative session adversarial machine CCS october november dallas TX usa deepfool deepfool iterative attack formalizes closest decision boundary normal image image boundary fool classifier directly dimensional highly non linear neural network instead iteratively solves linearize approximation specifically iteration  classifier around intermediate derives optimal update direction linearize model update towards direction linearize update decision boundary attack adversarial perturbation version deepfool attack carlini attack carlini recently introduce powerful attack generates adversarial perturbation attack target untargeted metric untargeted version introduce formalize attack optimization minimize fix input image attack perturbation objective fool classifier objective hyperparameter balance optimization satisfy constraint valid image classifier classifies incorrectly indicates attack succeed hinge loss define max max  pre softmax classification vector logits truth label hyper parameter confidence confidence encourages attack adversarial classification confidence confidence attack perturbation transferability defense effective carlini attack across confidence exist defense defense neural network harder attack summarize approach defense adversarial training defend adversarial classifier intuitive robust classifier adversarial information training refer adversarial training mixture normal adversarial training data augmentation adversarial objective classification objective regularizer promising attack important adversarial component currently unanswered meanwhile approach orthogonal  additional defense framework modification target classifier training  independent target classifier therefore faster flexible  benefit robust target classifier defensive distillation defensive distillation classifier nearly impossible gradient attack generate adversarial directly network defensive distillation leverage distillation training technique hide gradient pre softmax layer logits softmax output however easy bypass defense adopt strategy loss function calculate gradient directly pre softmax layer instead softmax layer attack easy attack network transfer distil network argue whitebox attack attacker parameter defense network prevent adversary generate adversarial defeat defense instead propose defense graybox model introduce randomization strategy attacker generate adversarial detect adversarial another defense detect adversarial craft statistical feature classification network representative attack generate construct neural network classifier detector input normal adversarial detector directly normal adversarial detector performance training attack generate perturbation generalize across attack parameter attack generation  employ detector contrary previous however detector adversarial instead  manifold normal data decision relationship manifold  reformer detect adversarial perturbation towards manifold  independent generate adversarial generalizes definition adversarial define sample image mutually exclusive classification task handwritten digit classification session adversarial machine CCS october november dallas TX usa occurs naturally regard classification task classification task assumes data generation generates probability occurs naturally nonnegligible researcher constitute manifold dimension data generation approximate union datasets cifar mnist image recognition definition classifier task function definition truth classifier task prevail judgment function judgment input unlikely data generation definition adversarial task classifier indicates classifier mistake adequate adversarial classifier perfect exist classifier classifies attacker adversarial traditionally error reflect generalization classifier brute collection inefficient laborious label therefore limit adversarial generate artificially attacker fool classifier defense evaluation definition defense adversarial classifier function dft defense dft extends classifier robust defense algorithm dft defense algorithm data modify parameter defense algorithm data modify parameter defense algorithm modifies parameter evaluate effectiveness defense dft cannot merely evaluate classifies correctly decision agrees truth classifier goal defense improve accuracy classifier adversarial normal definition defense dft decision applies adversarial image generate artificially remain adversarial capture camera adversarial although physical generate generate normal normal dft truth classifier dft adversarial dft decides adversarial dft truth classifier dft dft threat model assume attacker everything classifier attack target classifier structure parameter training procedure attacker defense dft scenario blackbox attack attacker parameter dft whitebox attack attacker parameter dft graybox attack parameter attacker everything  structure hyper parameter training training epoch neural network multiple fix variable model parameter random initialization network network sufficiently penalize resemblance defense structure hyper parameter diversity assume defense attacker generates adversarial  framework defend adversarial classifier classifies adversarial boundary manifold normal classifier option reject boundary manifold classifier generalizes poorly manifold vicinity motivate observation  consists component detector reject manifold boundary reformer strives manifold approximation target classifier illustrates detector reformer sample detector detector function decides input adversarial approach recent classifier distinguish normal adversarial however fundamental limitation defender model attacker acquire adversarial generate adversarial therefore unlikely generalizes generate adversarial iterative attack norm detector slightly perturbed adversarial sample detector false positive rate session adversarial machine CCS october november dallas TX usa  workflow phase  detector considers adversarial detector considers adversarial adversarial  reform target classifier illustration detector reformer sample manifold normal curve depict normal adversarial dot respectively depict transformation autoencoder arrow detector reconstruction error reject reconstruction error reformer manifold approximates normal adversarial detector significantly perturbed detect slightly perturbed adversarial detector reconstruction error avoid adversarial  detector model normal estimate distance boundary manifold normal implementation autoencoder detector reconstruction error approximate distance input manifold normal autoencoder contains component encoder decoder input hidden representation autoencoder minimize loss function training loss function commonly error    reconstruction error autoencoder learns feature training encoder encode input hidden representation decoder reconstruct input hidden representation input drawn data generation training reconstruction error otherwise reconstruction error hence reconstruction error estimate manifold normal reconstruction error continuous threshold  input normal threshold hyper parameter instance detector detect slightly perturbed adversarial falsely flag normal  validation normal  detector false positive rate validation threshold  threshold  catering requirement calculate reconstruction error important suitable norm reconstruction error detector attack independent norm  detection influence sharpness detection intuitively norm sensitive maximum difference pixel average concentration pixel empirically sufficient reconstruction error detector norm respectively detector probability divergence detector described effective detect adversarial reconstruction error however becomes effective adversarial reconstruction error overcome advantage target classifier neural network classifier implement softmax function layer softmax exp exp output softmax probability function input softmax  logit rank index ranked ith normal logit goal attacker perturb logit rank rank output layer softmax neural network input output autoencoder normal normal probability function contrast adversarial significantly reconstruction error session adversarial machine CCS october november dallas TX usa significantly indicates divergence reflect likely data generation normal jensen shannon divergence JSD dkl dkl dkl implement encounter numerical logit input inl softmax saturates softmax happens softmax saturates jensen shannon divergence softmax softmax overcome numerical calculate softmax softmax exp exp reformer reformer function reconstruct input output reformer fed target classifier reformer training target classifier reformer deploy target classifier ideal reformer classification normal adversarial adequately reconstruct normal reform adversarial reformer naive reformer function random input gaussian reformer clip normal distribution zero identity covariance matrix clip function clip input vector valid shortcoming reformer fails advantage distribution normal therefore normal adversarial randomly blindly ideal reformer barely normal adversarial towards normal autoencoder reformer propose autoencoders reformer autoencoder minimize reconstruction error training ensures generalizes validation afterwards normal data generate training autoencoder output adversarial autoencoder output approximates adversarial closer manifold normal  improves classification accuracy adversarial classification accuracy normal unchanged diversity mitigate graybox attack blackbox attack attacker parameter target classifier detector reformer evaluation  highly effective defend blackbox attack however whitebox attack attacker parameter detector reformer evaluation  become accurate surprising  transforms target classifier classifier whitebox attack attacker parameter adversarial adversarial exist negligible agrees truth classifier almost manifold normal evidence perfect classifier anytime non negligibly adversarial exist classifier although cannot eliminate adversarial attacker approach robust classifier attacker parameter classifier adversarial however actually easy adversarial classifier harden robust classifier exist approach inspiration cryptography randomness computationally attacker secret secret diversify defense implementation autoencoders candidate detector reformer  randomly autoencoders defensive device session assume attacker cannot predict autoencoder adversarial successful adversarial autoencoder succeed another autoencoders probability attacker adversarial autoencoders collection increase diversity collection attack harder perform defend graybox attack define diverse autoencoders transfer attack target classifier succeed probability rigorous theoretical analysis beyond scope instead construct autoencoders empirical evidence effectiveness autoencoders architecture random initialization training session adversarial machine CCS october november dallas TX usa architecture classifier mnist cifar conv relu conv relu conv relu conv relu max pool conv relu conv relu max pool conv relu conv relu max pool conv relu dense relu conv relu dense relu max pool softmax conv relu conv relu conv relu global average pool softmax training parameter classifier parameter mnist cifar optimization sgd sgd rate batch epoch data augmentation shift horizontal flip function regularization penalize resemblance autoencoders mse  mse    ith autoencoder mse error function hyper parameter reflect tradeoff reconstruction error autoencoder diversity becomes encourages autoencoder diversity increase reconstruction error evaluate approach implementation evaluation evaluate accuracy defense described standard dataset mnist cifar setup mnist training validation classifier accuracy cifar training validation architecture accuracy accuracy classifier datasets architecture training parameter classifier instead simplicity defensive device architecture mnist encoders decoder detector reformer detector II conv sigmoid conv sigmoid  conv sigmoid conv sigmoid conv sigmoid conv sigmoid upsampling conv sigmoid conv sigmoid evaluate robustness  blackbox attack attacker parameter  understand  analyze impact detector reformer respectively accuracy  carlini attack finally evaluate diversity mitigate graybox attack classifier architecture classifier parameter attack adversarial target attack attacker chooses creates adversarial victim classifier classifies untargeted attack attacker victim classifier output truth previous untargeted attack easy succeed perturbation transfer model untargeted attack defend evaluate  untargeted attack performance overall performance blackbox attack  attack gradient iterative gradient deepfool carlini gradient iterative gradient implementation  deepfool carlini attack author source implementation principle  deploy instance reconstruction error detector probability divergence detector diversified autoencoder architecture boost defense performance implementation simplify setup limit detector usage architecture autoencoders convenience mandatory specifically mnist dataset reconstruction error detector unique architecture cifar dataset structure autoencoders architecture training hyper parameter autoencoder mnist cifar tune network effort optimize setting session adversarial machine CCS october november dallas TX usa defensive device architecture cifar encoders decoder detector reformer conv sigmoid conv sigmoid conv sigmoid training parameter defensive device parameter mnist cifar optimization adam adam rate batch epoch regularization criterion described justified evaluate accuracy  normal adversarial mnist cifar mnist easy dataset classifier classifier achieve accuracy reconstruction error detector reformer become highly accurate adversarial generate mnist therefore probability  detector  evaluation detector II detector norm reconstruction error respectively threshold reconstruction error false positive rate detector validation detector mistakenly reject validation normal without  accuracy classifier  accuracy reduce reduction negligible adversarial accuracy  attack carlini attack norm achieve accuracy without training  attack cifar mnist cifar challenge classifier classifier achieve accuracy cifar  consists reformer reconstruction error detector probability divergence detector respectively autoencoder denoising autoencoder gaussian volume error detector norm reconstruction error threshold false positive rate  validation threshold reconstruction error  reconstruction error detector probability divergence detector classification accuracy  adversarial generate attack attack parameter mnist cifar adjust parameter accord datasets mnist attack norm parameter defense defense FGSM FGSM iterative iterative iterative iterative deepfool carlini carlini carlini cifar attack norm parameter defense defense FGSM FGSM iterative iterative iterative iterative deepfool carlini carlini carlini normal without  accuracy classifier  accuracy reduce reduction accuracy adversarial accuracy  attack  accurate cifar mnist target classifier cifar leaf   achieve accuracy attack attack empirical evidence  effective generalizes attack parameter attack carlini attack  carlini viable transfer attack confidence mnist attack evaluate carlini attack effective distillation defense effective defense prior attack attacker attack strength adjust session adversarial machine CCS october november dallas TX usa confidence carlini attack classification accuracy  detector reformer detector reformer defense performance confidence carlini attack mnist dataset performance percentage adversarial detect detector classify correctly classifier confidence generate adversarial confidence classification confidence distortion confidence attack achieve rate classifier distillation defense conduct transfer attack evaluate impact confidence carlini attack  mnist classifier carlini generate adversarial target classifier evaluation generate adversarial confidence cifar evaluate impact confidence picked confidence classifier cifar target classifier defense unchanged datasets performance detector reformer mnist without  attack succeed almost classification accuracy rate  classification accuracy rate adversarial generate confidence indicates  carlini attack completely blackbox scenario classification accuracy  cifar attack rate confidence strike revelation detector reformer compensate achieve overall accuracy confidence confidence adversarial manifold normal likely reconstruction error therefore reject detector confidence adversarial manifold normal reconstruct reformer likely manifold therefore classify correctly confidence adversarial reformer becomes effective detector becomes effective dip confidence carlini attack classification accuracy  detector reformer detector reformer defense performance confidence carlini attack cifar dataset performance percentage adversarial detect detector classify correctly classifier mid curve overall classification accuracy dip opportunity attacker effectiveness reformer  detector opportunity exists  achieves classification accuracy confidence dip classifier  dip  accuracy probability divergence detector detector accurate adversarial confidence detector accurate adversarial confidence  carlini attack attack conjecture likely generalize attack defend graybox attack graybox attack parameter attacker everything defense network structure training training procedure assume attacker cannot predict parameter defender classify adversarial attacker cannot feasibly mislead defense generate adversarial defend attacker diversify defensive network defense graybox attack diversity training autoencoders reformer  proof concept implementation architecture convolutional autoencoder hidden layer relu activation obtain autoencoders parameter training hyper parameter session adversarial machine CCS october november dallas TX usa confidence carlini attack classification accuracy detector reconstruction error detector divergence detector divergence defense performance confidence carlini attack cifar dataset performance percentage adversarial detect detector classify correctly classifier autoencoders independently epoch standard error loss continued training autoencoders loss equation another epoch chose empirically randomly picked autoencoders reformer chose carlini attack evaluate defense however carlini attack model network decision network perturb candidate adversarial  contains network reformer detector independent decision therefore attack described cannot handle  overcome obstacle remove detector  reformer carlini attack generate adversarial  adversarial confidence  relies detector reject adversarial confidence therefore carlini attack generate adversarial confidence chose cifar carlini attack effective mnist classification accuracy  adversarial generate carlini attack autoencoder corresponds autoencoder attack generate corresponds autoencoder random  random autoencoders diagonal  classification accuracy mostly autoencoder carlini attack  however autoencoders classification accuracy realistic scenario attacker chooses random autoencoder training  chooses random autoencoder classification accuracy percentage adversarial generate graybox attack cifar autoencoder corresponds autoencoder attack corresponds autoencoder random  random autoencoders random classification accuracy percentage cifar corresponds autoencoder chosen rand  randomly chooses autoencoder AE rand acc candidate autoencoders  maintains classification accuracy classifier accuracy autoencoders cifar accuracy target classifier autoencoders barely reduce accuracy target classifier improvement diversify  autoencoders architecture tune autoencoders training parameter increase amount autoencoders encourage difference autoencoders future discussion effectiveness  adversarial depends assumption exist detector function distance input manifold normal exist reformer function output  input closer manifold chose autoencoder reformer detector   accuracy stateof attack empirical evidence assumption likely however justification proof cannot dismiss possibility attack powerful session adversarial machine CCS october november dallas TX usa motivate research powerful attack powerful detector reformer conclusion propose  framework defend adversarial perturbation neural network  handle untrusted input detects adversarial perturbation detector network perturbation towards manifold normal jointly enhance classification accuracy moreover autoencoder detector network  learns detect adversarial without adversarial knowledge generate generalization  defend attack effectively attacker training  described graybox threat model diversity defend attack effectively advocate defense adversarial attack independent instead adversarial specific generation defense transferable intrinsic adversarial generation  towards demonstrate performance empirically