technique scan neural network AI model trojaned pre AI model inject training transform inner neuron trojaned model normally regular input classify specific output label input stamp trojan trigger develop novel technique analyzes inner neuron behavior output activation introduce stimulation neuron neuron substantially elevate activation output label regardless input potentially compromise trojan trigger reverse engineer optimization procedure stimulation analysis confirm neuron truly compromise evaluate ABS trojaned model trojaned various attack target input feature various trojan trigger benign model data initial model belong model structure datasets complex imagenet vgg resnet ABS highly effective achieve detection rate input sample output label substantially performs technique neural cleanse input sample trojan trigger achieve performance keywords AI trojan attack artificial brain stimulation introduction neural network artificial intelligence model widely application recognition detection autonomous demonstrate advantage traditional compute methodology tend application AI model aspect around increase complexity functionality training model entail enormous effort training data optimize performance therefore pre model become highly valuable artifact vendor google developer distribute reuse profit pre model publish caffe model zoo onnx zoo  model traditional software artifact github model reputable vendor institute individual lengthy software distribution reuse permanent battle expose malicious behavior publish software usually disguise highly attractive functional feature software similarly AI model trojaned recent research contaminate training data training hijack inner neuron limited training craft input pre model transform install secret trojaned model behave normally benign input perform model attractive however stamp benign input trojan trigger attacker induce model classification yield specific classification output target label goal scan AI model contains secret ought efficient scan model ought effective without assume access training data information trojan trigger pre model maybe benign input attack model exist technique defend AI model trojan attack however technique various limitation detect attack input trigger model instead model trojaned without input trigger session ML security II CCS november london united kingdom substantial model accuracy degradation input sample difficulty attack feature instead input detailed discussion technique limitation essence model trojaning compromise inner neuron inject hidden behavior mutate relevant training activation neuron intend misclassification hence propose analytic approach analyzes behavior inner neuron technique inspire technique electrical brain stimulation EBS widely functionality behavior brain neuron EBS applies electrical various strength stimulate neuron observes external consequence pleasurable  response analogously AI model scan technique tap individual neuron directly alters activation without correspond input activation observes correspond output difference hence artificial brain stimulation ABS procedure neuron compromise trojaning manifest substantially elevate activation specific target label meantime possibly suppress activation label appropriate stimulus however benign neuron denote unique feature ABS distinguishes compromise neuron benign neuron reverse engineering trojan trigger stimulation analysis guidance trigger generate consistently subvert input label specific label ABS considers model trojaned contribution summarize propose novel approach scan AI model analyze inner neuron behavior stimulation formally define stimulation analysis precisely determines output activation inner neuron activation complexity analysis devise practical approximate analysis sophisticated sample devise optimization reverse engineer trojan trigger leverage stimulation analysis handle input attack feature attack trigger longer input input transformation image filter inner feature perform substantial evaluation ABS specifically evaluate model trojaned various attack target input feature various trigger benign model data initial model belong model structure datasets complex vgg imagenet resnet ABS highly effective achieve detection rate input sample label substantially performs neural cleanse input sample trojan trigger achieve performance addition ABS scan pre model  unknown suspicious behavior ABS heuristic critical assumption assumes benign input stamp trojan trigger probability classify target label regardless label assumes trojaned model target label output activation elevate stimulate inner neuron without stimulate interact neuron assumption datasets model structure trojaning setting advanced attack render ABS ineffective extend ABS stimulate neuron implementation entail substantially enlarge without sophisticated trim technique discussion attack model discussion furthermore focus empirical formally classify trojan attack analyze theoretical bound ABS future trojan ATTACKS defense trojan attack injects hidden malicious behavior AI model behavior activate input specific trojan trigger model pixel feature ideally input trojan trigger model classify specific target label without trigger model behaves normally exist trojan trigger patch trigger perturbation trigger patch trigger patch stamp input image patch image perturbation trigger image perturbs input image trigger correspond pixel attack pixel attack trojan attack feature attack pixel mutation trigger classification longer fix input dependent  filter  filter instagram trojan trigger former creates fashion photo style image  increase contrast latter transforms image contrast   pixel mutation induced filter image another exist trojan AI model discus representative exist trojan model sample image generate various trojaning mnist dataset patch trojan trigger highlight trojan trigger perturbation trojan trigger trojaned input image image denote perturbation data poison propose approach trojaning model training data poison scenario model training outsource attacker session ML security II CCS november london united kingdom neuron hijack poison patch poison static perturbation poison adaptive perturbation trigger attack mnist highlight content perturbation attack image contains trigger image highlight perturbation access training data attacker poison training inject input sample trojan trigger target label training model trojaned behavior propose poison training data blending trojan trigger training data ratio successfully trojaned model around image model trojan trigger data poison attacker access training trojan trigger arbitrarily simplest diamond attacker poison training data perturbation trigger propose trojan dnns perturbation poison perturbation trojaning static perturbation training data poison static perturbation trojaned image highlight perturbation approach adversarial perturbation approach attacker generates adversarial sample alter classification pixel difference adversarial sample image trigger perform data poison static perturbation adversarial perturbation stealthy attack rate trojaned image highlight adversarial perturbation poison attack attacker manipulates training data model ineffective attack attack model trigger specific target label hence non goal neuron hijack propose approach trojaning pre model without access training data attack inner neuron selects neuron substantially susceptible input variation target craft trigger induce exceptionally activation target neuron model partially retrain input stamp trigger exceptionally activation target internal neuron propagate target output label retain model normal behavior craft trojan trigger exist defense detect input trojan trigger exist technique detect input trojan trigger propose SVMs decision detect dnn trojaned classification dnn svm propose mitigate trojan attack retrain trojaned model training data however approach incur computation trojan trigger rev eng label deer rev eng label airplane rev eng II label airplane reverse engineer NC trojaned vgg model cifar target label airplane hence evaluate mnist dataset strip detects input contains trojan trigger perturbation input perturbation normal input misclassified hardly surpass trojan trigger classification trojaned image perturbation approach assume model trojaned challenge model trojaned detect fix trojaned model prune prune redundant neuron eliminate however accord accuracy normal data rapidly prune redundant neuron detection trojaned model neural cleanse NC superior performance prune output label NC reverse engineer input technique adversarial sample generation input stamp classify label intuition normal label reverse engineer surpass normal feature image trojaned label generate tends actual trojan trigger model label generate label model trojaned NC successfully detects trojaned model limitation neural cleanse NC although NC demonstrates possibility identify trojaned model limitation NC reverse engineer trojan trigger target label airplane cifar trigger unique feature model predict airplane stamp input NC optimization reverse engineer unique feature local optimal optimization instead trigger generate obvious difference label trojan vgg model cifar trigger rectangle target airplane label input stamp rectangle classify airplane apply NC airplane label generate trigger generate likely denotes feature random optimization procedure apply NC deer label likely denotes  deer upper NC generate trigger without hint model internals session ML security II CCS november london united kingdom  filter trigger  filter trigger feature trojan attack NC input sample achieve performance NC training data reverse engineer trigger optimization technique input data suggests constraint procedure hence accuracy achieve however practical feasible access input sample publish model sample input image output label NC perform accord cifar dataset training sample image detection rate around trigger input image input sample per label image detection accuracy degrades detail NC trojan trigger premise NC trojan trigger substantially benign feature premise attack model specifically trojan trigger participate normal operation trojaned model presence completely unknown attack launch stealthiness trigger critical anyway accord researcher interested trigger vgg model cifar dataset NC achieves detection rate trigger image degrades fails detect exceeds fourth NC feature attack exist trojaning attack defense focus pixel whereas attack feature explain earlier feature trojaning effective pixel trojaning achieve attack rate without degrade model accuracy due lack pixel technique pixel reverse engineering NC hardly effective overview overcome limitation exist trojan attack detection technique propose novel analytic analyzes model internals inner neuron activation inspire electrical brain stimulation EBS technique functionality neuron brain EBS stimulates neuron neural network brain indirect excitation membrane analogously technique artificial brain stimulation ABS tap individual artificial neuron activation fashion electrical strength EBS compromise observation motivate technique attack model assume attacker access training model implementation model successfully trojaned trojaned model non trivial accuracy degradation benign input benign input stamp trojan trigger model probability classify target label regardless label assume trigger target label trigger suppose subvert benign input label target label attack various combination multiple trigger beyond scope ABS advanced attack model trigger  input label target label goal ABS potential handle attack assumption satisfied appendix attack harder detect apply trigger input non target label model behavior defender model input sample label model trojaned observation observation successful trojaning entail compromise neuron assume trigger target label model trojaned data poison poison training usually input derive input without trigger label sample trigger target label poisonous sample poisonous sample uniform trigger allows behaving gradient descent training algorithm recognize trigger feature target label achieve attack rate feature likely inner neuron specifically neuron activate activation within dominant model predicts target label neuron compromise neuron compromise neuron observation II compromise neuron subspace target label input label sub dimension input sub  label likely scatter localize input likely label input contrast sub target label trojaned model likely global across entire input data trigger apply prediction target label applies feature intuitively illustrate concept output activation target label denote activation neuron inner layer denote respectively simplicity output activation classify label denotes feature sub classify subspace locality contrast trojaning model classifies whenever around compromise neuron session ML security II CCS november london united kingdom trojaned ridge across entire induce classification persistence trojaned model overarch accord observation identify compromise neuron benign input model input inner neuron activation inner neuron layer analyze output activation label activation apply electrical various strength EBS specifically fix activation neuron activation potential compromise neuron hence potential target label substantially enlarges becomes activation label accompany suppress output activation label assume valid input corresponds data 3D analyze relation output activation function data intersect 3D yield curve peak around analysis perform image label observation consistent neuron substantially enlarge activation neuron compromise neuron candidate accord observation II benign image aforementioned stimulation analysis input label specifically trojaned subspace ridge across entire data perform intersection across trojaned subspace ridge hence disclose peak allows technique minimal input candidate neuron substantially enlarge output activation specific label subset compromise neuron phase eliminate false positive generate input activate candidate neuron achieve activation identify stimulation analysis substantially elevate correspond output label activation optimization procedure candidate compromise neuron confound neuron activation independently neuron activation intuitively due trigger subvert benign input contrast false positive substantial confound neuron achieve target activation infeasible input generate potential trojan trigger model trojaned trigger subvert benign input output label illustrate procedure assume fully model model layer output label airplane andc layer inner neuron behavior benign model trojaned model benign model benign image trojaned model benign image trojaned model trigger image illustration trojaning behavior normal image behave neuron activation input stamp trigger image neuron activation label hence classification compromise neuron output activation function label regard activation trojaning respectively benign input correspond data feature layer fix apply stimulus acquire curve output activation abnormal peak around suggests compromise neuron candidate stimulation analysis peak hence candidate validate truly compromise optimization derive input activation elevate output activation label subvert classification stamp benign image yield label model trojaned trojan trigger model reverse engineer trigger ABS image image pixel trigger image feature trigger  filter reverse engineer trigger reverse engineer trigger closely resemble detail ABS enables advantage applicable pixel attack feature attack analyzes inner neuron behavior minimal dependence input sample image output label sufficient trigger agnostic allows effective distinction trojan trigger benign unique feature discus detail individual ABS neuron stimulation analysis identify compromise neuron candidate benign input ABS executes model input tap individual inner neuron impact output label formally inner neuron denote activation variable stimulation analysis aim derive output activation function label regard neuron stimulation function NSF analysis activation neuron layer fix model execution session ML security II CCS november london united kingdom trojaning trojaning output activation function regard activation neuron pixel trigger feature trigger rev eng pixel trigger rev eng feature trigger trojan trigger reverse engineer trigger overview ABS layer computes impact layer till output layer intuitively explain analysis model structure neuron analysis neuron layer denote NSF neuron layer denote variable activation neuron neuron activation bias neuron activation function relu layer relu relu assume positive unfold semantics relu function activation neuron constant constant hence wise linear function orange respectively hence layer relu wise function analyze without lose generality assume relu otherwise denotes horizontal II ascend horizontal orange elu elu elu denotes outside demonstrate orange function analysis elide observation derive NSF layer input sub delimit previous layer within session ML security II CCS november london united kingdom sub NSF derive linear combination sub yield linear function apply relu function introduce additional combine linear function become negative within  sub sub layer broken layer sub broken layer layer broken NSFs linear sub NSF function continuous wise function sub delimit constant instead variable hence algorithm precisely derive NSFs compute wise function individual input sub layer layer formal definition algorithm elide due limitation complexity assume layer neuron NSF computation yield hence sub NSF neuron introduce additional layer yield assume analysis layer complexity extension layer previous analysis fully layer analysis easily extend convolutional layer pool layer layer resnet accord convolutional layer convert equivalent fully layer convolutional layer pool layer convert equivalent fully layer extend analysis convolutional layer pool layer transform equivalent fully layer perform analysis transform layer layer resnet vector neuron NSF function input neuron layer wise linear continuous output neuron layer piecewise linear continuous allows analysis easily extend suppose convolutional layer width height depth convolutional layer input tensor width height depth input tensor convert fully layer neuron input tensor neuron complexity layer transformation MN negligible complexity NSF analysis pool layer convolutional layer fix complexity transform pool layer approximate stimulation analysis sample deterministic algorithm developed precisely derive NSF however complexity exponential although implementation precise algorithm scan complex model resnet expensive practical model scanner hence remainder introduce practical approximate algorithm sample algorithm conduct computation layer layer instead neuron layer NSF derive algorithm executes sub model layer output layer observes correspond output activation earlier analysis NSFs continuous sample plausible address prominent challenge identify sample II identify appropriate sample interval peak identify sample activation bound activation assume relu activation function upper bound unknown addition universal bound sample bound earlier discussion precise analysis NSF precisely consecutive assume NSFs output label linear NSFs become hence sample algorithm model execution proceeds towards direction ABS observes sample NSFs output label fix slope consecutive sample ABS enlarge sample interval exponential fashion confirm slope constant ABS terminates fix uniform sample towards linearity slope identify appropriate sample interval sample interval overhead whereas sample interval peak trojaned behavior develop adaptive sample consecutive sample NSF output label manifest linearity additional sample sample furthermore maximize expose sample NSFs intentionally misalign NSFs   peak  sample  linear however sample   constant offset sample  lack linearity sample  ABS additional sample expose peak  achieve effectiveness implementation enforce strict linearity linearity slope difference formal definition sample algorithm elide identify compromise neuron candidate stimulation analysis identifies NSFs neuron model identify compromise neuron candidate NSFs criterion available benign input label candidate neuron consistently substantially  activation output label beyond activation label neuron activation specific session ML security II CCS november london united kingdom stimulation analysis model stimulation analysis layer stimulation analysis layer stimulation analysis layer align sample algorithm describes procedure likely candidate easily extend likely candidate algorithm denotes model NSFs denotes stimulation analysis function indexed benign image image execute model generate concrete neuron activation neuron output label  denotes benign image analysis elevation neuron NSFs sample approximate NSF loop identifies likely candidate neuron neuron loop computes elevation output label  sort  computes difference elevation return candidate neuron difference simply return elevation explain later loop computes minimal elevation label across image elevation label  elevation image imд compute peak NSF activation imд algorithm compromise neuron candidate identification function identify candidate  max max neuron abel abel abel min imд imд  imд abel abel imд max abel imд imд abel imд min imд min imд imд abel append min imд sort abel descend abel abel max max max return max maximum elevation difference instead maximum elevation algorithm candidate difference elevation instead simply elevation neuron benign feature substantial elevation output label whereas compromise neuron tends elevate target label neuron elevation difference ABS filter benign neuron focus compromise NSFs benign neuron compromise neuron elevation difference instead elevation minimal elevation across image NSFs illustrate selection compromise neuron candidate axis denotes neuron activation denotes output activation denotes NSF nin model cifar dataset denotes output label neuron output label however benign neuron label intuitively suggests benign neuron feature label minimum elevation across image label elevation algorithm minimum elevation across image elevation label accord attack model elevation compromise neuron ought persistent input various label contrast benign neuron elevation subset image choice allows filter benign neuron NSFs benign neuron image label elevation difference peak image elevation ABS elevation elevation label validate compromise neuron candidate generate trojan trigger acquire candidate ABS identifies compromise neuron generate trojan trigger ideally generate input allows candidate neuron achieve activation manifest elevation stimulation analysis maintain activation neuron layer candidate truly compromise achieve aforementioned activation infeasible due confound neuron multiple neuron influence input mutate input cannot neuron activation without activation confound neuron infeasibility intend output label activation session ML security II CCS november london united kingdom feature attack model benign neuron substantially confound contrast compromise neuron due persistence confound neuron activation independent others induce classification appendix discussion reverse engineer trojan trigger optimization procedure discussion focus pixel attack discus feature attack specifically compromise neuron candidate optimization aim achieve multiple goal maximize activation minimize activation neuron layer minimize trigger objective induce peak activation retain neuron activation stimulation analysis input mask trigger trigger intuitively mask vector input stamp trigger input achieve mask  mask hadamard operation optimization procedure essentially model objective loss function gradient descent minimize loss described algorithm function reverse engineer trigger procedure parameter model denotes model denote layer candidate neuron respectively denotes epoch denotes rate max mask maximum trigger apply denotes function applies trigger image pixel apply pixel attack feature apply feature attack latter explain initializes  mask  usually initialize input image mask usually initialize random array defines perturbed input apply trigger define component loss function define activation candidate neuron maximize loss function negative define activation difference neuron minimize positive function minimize mask limit trigger penalty loss mask sum mask threshold max mask bound trigger loop performs iterative optimization handle feature attack unlike pixel attack feature attack fix pixel trigger target classification instead interpret feature training data pixel mutation feature injection usually input algorithm trigger reverse engineering algorithm function pixel apply trigger mask mask  mask return function feature apply trigger mask ack maxpool    return function reverse engineer trigger model max mask apply  mask init   def apply  mask def model  neuron def model  neuron model  neuron model  neuron model  neuron sum mask SS sum mask max mask  sum mask   mask mask    mask mask mask return  mask dependent hence lack training trojaned model becomes sensitive secret feature extract feature input feature illustrates procedure benign input airplane image image transformation procedure apply secret feature image apply  filter pixel mutation introduce trojaned model extract feature feature layer highlight trigger elevation compromise neuron classification essentially trojan trigger reverse engineer input undergoes transformation trigger classification generative model initial input trigger feature procedure reverse engineering hence derive generative model feature attack described layer transformation simplest generative model filter belong complex feature attack beyond scope future algorithm  denotes function reverse engineer input generate multiplication  vector contains input maximum pool input acquire maximum pixel within slide input image minimum pool average pool enhance input statistic multiplication exist image transformation rely statistic input optimization procedure generate  induce substantial perturbation pixel mitigate algorithm ssim similarity image ssim ssim image evaluation evaluate ABS trojaned model benign model model structure datasets session ML security II CCS november london united kingdom dataset model statistic dataset label input input model layer params cifar nin vgg resnet resnet GTSRB lenet nin vgg resnet imagenet vgg vgg vgg conv FC USTS rcnn configuration trojan attack trojan trigger addition model caffe model zoo scan ABS dataset statistic datasets output label training input individual input model statistic model layer cifar dataset image dataset recognition input model cifar network network nin vgg resnet resnet resnet contains layer ofthe model structure recognition model trojan defense evaluation literature GTSRB dataset image dataset traffic recognition input cifar evaluate lenet network network nin vgg resnet dataset imagenet dataset dataset recognition label image input vgg structure dataset vgg dataset recognition input detection model structure vgg evaluation dataset recognition input detection model structure USTS another traffic dataset detection USTS detection dataset input detection model rcnn evaluation conduct server equip xeon cpu GB ram tesla gpu titan gpu detection effectiveness setup evaluate ABS effectiveness identify trojaned model distinguish benign various trojan attack data poison patch trigger data poison static perturbation data poison adversarial perturbation neuron hijack feature attack model cifar GTSRB imagenet addition publicly available trojaned model exist trojaned lenet model GTSRB neural cleanse trojaned model USTS dataset  trojaned model neuron hijack vgg datasets trojan model cifar GTSRB imagenet trojan trigger pixel feature pixel trigger patch trigger perturbation trigger static adversarial perturbation trigger patch trigger feature trigger trojan model poison training data perturbation trigger trojan poison training data due perturbation trojaning poison percentage training data sufficient attack rate trojaned model combination model structure dataset imagenet trojan trojan model per trigger trojaned imagenet model model structure cifar model structure GTSRB trojan model trojaned model neural cleanse  neuron hijack evaluate ABS trojaned model combination dataset model structure benign model trojaned diversity randomly training data random initial benign model imagenet scratch pre benign model benign model  neuron hijack hence benign model exist defend trojan attack evaluate model ABS evaluate mixture benign trojaned model ABS ABS distinguish trojaned scan model ABS model benign input output label selects compromise neuron candidate model reverse engineer trigger candidate reverse engineering trigger ABS input remain reverse engineer trigger subvert benign input model classify input target label percentage benign input subvert trigger attack rate reverse engineer trojan trigger REASR report REASR trojaned model maximum REASR benign model substantial gap ABS effective detection model acquire REASR distribution randomly chosen neuron compromise neuron outlier REASR regard distribution model trojaned report raw REASR insight classification hyper parameter trojaned model detection accuracy difference model trojan attack rate model appendix model properly trojaned trojaned model model accuracy difference model attack rate detection upper sub model session ML security II CCS november london united kingdom dataset model REASR benign model reverse engineer trigger label indicates benign model model dataset combination REASR model trojaned pixel trigger  RS irregular  irregular RI multi MP static perturbation static adversarial perturbation adversarial pixel trigger enhance enlarge presentation occupy input trigger later label model combination label  combination cifar nin trigger model poisonous sample respectively mention earlier REASR feature attack   filter sub model trojaned others lenet model model model available watermark  trigger  bomb bomb trigger observation observation ABS REASR almost trojaned model majority combination USTS  bomb reverse engineer trigger indeed persistently subvert benign input comparison trigger trojan reverse engineer version reverse engineer trigger trigger inspection model trojaned trigger effective location reverse engineer trigger dependent initialization gap benign model substantial ABS USTS detection dataset usually reverse engineer trigger classification datasets REASR trojaned model benign model ABS effectively distinguish trojaned model benign exception cifar vgg benign REASR trojaned model however recall report maximum REASR benign model inspection benign model plot REASR model trojaned model benign  effectively partition explain benign model achieve REASR later ABS consistently effective attack trigger various model datasets demonstrate trigger reverse engineer trigger trigger reverse engineer trigger REASR  trojan cifar REASR  trojan GTSRB REASR benign model trojaned model generality performance achieve input output label internals ABS statistic ABS internal operation compromise neuron identify ABS mention earlier generate trigger compromise neuron candidate neuron REASR maximum REASR neuron difference compromise multiple model dataset model combination report average maximum activation increase ABS achieve candidate compromise denotes neuron denotes neuron apply trigger reverse engineer maximum output activation logits apply trigger derive candidate ABS considers uncompromised counter compromise neuron observation multiple compromise neuron trigger reverse engineer persistent subversion compromise neuron substantial elevation neuron activation output logits uncompromised suggests uncompromised candidate substantial confound neuron elevation compromise neuron model dataset substantial others inspection output logits apply trigger explain REASR benign model REASR benign model cifar nin cifar vgg meaning reverse engineer trigger quote trigger subvert benign input stamp input reverse engineer trigger REASR reverse engineer trigger image classify deer resemble deer  inspection session ML security II CCS november london united kingdom trojaned model detection dataset model benign pixel attack feature attack patch perturbation    RS  RI MP static adversarial cifar nin vgg resnet resnet GTSRB nin vgg resnet imagenet vgg benign neural neuron hijack badnets cleanse watermark  bomb GTSRB lenet vgg vgg conv FC USTS  indicates pre  trojaned model combination exist imagenet dataset benign model trojan model attack ABS internals dataset model compromise neuron benign inc logits compromise inc logits cifar nin vgg resnet resnet GTSRB nin vgg resnet lenet imagenet vgg vgg vgg conv FC USTS  trigger rev eng REASR benign model cifar dataset deer image  benign model correlation although feature adversary subvert input trojan trigger comparison neural cleanse NC NC optimization without guidance model internals sensitive initial random generate trojan trigger benign feature random suppress non determinism NC average default detection NC trigger NC successfully detects trojaned model trojaned label NC output trojan target label dataset model NC mnist recognition model exclude mnist representative recognition model vgg model dataset mnist consistent report datasets model detection accuracy comparison ABS NC ABS NC image NC dataset model pixel feature pixel feature pixel feature cifar nin vgg resnet resnet GTSRB nin vgg resnet lenet imagenet vgg timeout timeout timeout timeout vgg vgg timeout timeout conv FC USTS  available model detection rate ABS pixel trojaning attack feature trojaning attack average REASR pixel attack feature attack detection rate NC image per label ABS detection rate NC training favorable NC vgg label NC scan terminate timeout imagenet timeouts observation NC effective feature attack detection data USTS NC apply scenario NC effective image label image optimization generate trigger  input image benign label conduct additional NC rate sample cifar NC effective training accuracy report inspection consistent trojan around input cifar GTSRB attack author report NC effective trigger beyond dataset trojan trigger session ML security II CCS november london united kingdom data detection accuracy detection accuracy NC data cifar trojan trigger detection accuracy detection accuracy NC trigger cifar REASR benign trojan REASR benign trojaned model input ABS NC dataset model ABS NC stimulation analysis trigger gen cifar nin vgg resnet resnet GTSRB nin vgg resnet lenet imagenet vgg timeout vgg vgg timeout conv FC USTS  deer frog  input sample image conduct detection rate NC trojan trigger cifar NC rate trigger fails detect trigger trigger ABS sensitive trigger appendix ABS consistently performs NC trigger around beyond addition sample achieve performance additional perform evaluate effectiveness NC tune parameter setting data augmentation appendix effort improve performance improvement limited comparable ABS detection efficiency detection efficiency ABS NC execution ABS stimulation analysis trigger generation sum NC execution ABS NC image per label ABS consistently faster NC due analytic model internals without hint compromise neuron candidate identify ABS NC scan output label ABS execution grows model complexity model complexity resnet vgg nin cifar resnet neuron vgg stimulation analysis vgg imagenet vgg model stimulation analysis others neuron detection effectiveness without input explore scenario model without sample input model inversion reverse engineer input output label apply ABS reverse engineer input cifar ABS combination cifar nin REASR trojaned benign model trojaned model model REASR performance degradation reverse engineer image optimize activate output neuron logits normal image optimization procedure generate trigger cannot subvert output activation guidance compromise neuron ABS without sample data validation scan model host online model zoo per model caffe model zoo classification label gender classification label knowledge  model scan ABS model image per label scan reverse engineer trigger randomly image max  REASR report model REASR image classify image female REASR suspicious gender model peer whereas gap suspicious model obvious accuracy suspicious model average others model fairly suspicious faulty trigger ABS REASR pre model gender gender trigger REASR model session ML security II CCS november london united kingdom detection effectiveness adaptive trojaning attack previous detect trojaned model assumption attacker aware ABS devise adaptive trojaning attack aware ABS deliberately evade evaluate ABS adaptive attack demonstrate robustness adaptive attack bypass ABS trojan model minimize standard deviation neuron activation layer data poison intention multiple neuron realize trojaned behavior minimize activation difference individual neuron ideally compromise neuron blame trojan model neuron activation benign input input stamp trigger compromise neuron activate input trigger minimize activation difference benign malicious input limit elevation compromise neuron multiple neuron interact realize inject behavior constrain maximum neuron activation difference benign malicious input rationale attack introduce adaptive loss function addition normal classification loss minimize loss function adaptive attack adaptive loss standard deviation neuron activation within layer attack adaptive loss activation difference benign malicious input attack adaptive loss maximum activation difference benign malicious input tune normal classification loss adaptive loss obtain trojaned model accuracy benign input adaptive loss relation adaptive loss model accuracy attack minimize standard deviation minimize difference benign malicious input minimize maximum difference benign malicious input respectively triple nin vgg resnet structure respectively dataset cifar axis adaptive loss axis model accuracy attack rate model trojaned model along decrease adaptive loss model accuracy benign input decrease perturb adaptive loss normal accuracy decrease exceeds nin model resnet model adaptive loss perturb adaptive loss trojaned model ABS successfully detect reverse engineering neuron neuron sample recall without adaptive attack reverse engineer neuron adaptive attack increase difficulty ABS effective complex sophisticated adaptive attack attack future discussion although ABS demonstrate potential analytic approach leverage model internals detect trojaned model improve aspect future distinguish benign feature trigger ABS occasionally reverse engineer benign feature considers trigger partially feature subvert input distinguish develop technique reverse engineer trigger benign image target label handle complex feature attack feature attack attack insert literature complex generative model trigger inject feature violation ABS assumption render ABS effective complex feature attack feasibility ABS detect attack handle label specific attack label specific attack aim subvert input label target label hence persistence demonstrate ABS likely effective label specific attack appendix ABS tends false positive attack additional input sample investigate limitation efficiency although ABS faster stateof scan complex model perform stimulation analysis inner neuron possibility improvement develop lightweight prune uninteresting neuron neuron assumption assume compromise neuron sufficient disclose trojan behavior although assumption trojaned model sophisticated trojaning multiple neuron interact elevate output activation however appendix ABS extend multiple neuron challenge properly estimate interact neuron avoid exhaustively combination future relaxed attack model ABS assume misclassification induced apply trojan trigger input attacker willing strike balance attack rate stealthiness suffice attack succeed subset input multiple trigger trigger combination launch attack future ABS performance scenario related addition trojan attack defense technique  ABS related propose inject trojan behavior directly manipulate model however approach synthetic model dnns label attack aim degrade model performance poison session ML security II CCS november london united kingdom min std min diff min max diff model accuracy axis versus adaptive loss axis adaptive attack training adversarial cannot recognize adversarial poisonous model decision boundary performance degradation trojan hardware neural network injects tamper circuit defense technique propose defend training data poison category data sanitization prune poisonous data training contrast ABS defense stage model cycle ABS related adversarial sample attack recent construct  universal perturbation universal adversarial patch neural cleanse thorough comparison difference ABS analytic approach leverage model internals defense technique propose adversarial detect input adversarial potentially detect pixel trojan trigger however 