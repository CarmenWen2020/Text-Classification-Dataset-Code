machine ML become commodity numerous ML framework service available data holder ML expert predictive model data important ML model sensitive input personal image document leak information training data malicious ML provider model training code data holder training obtains access model implement practical algorithm standard ML technique regularization data augmentation memorize information training dataset model model accurate predictive conventionally model explain adversary extract memorize information model evaluate technique standard ML task image classification cifar recognition LFW FaceScrub text analysis newsgroups imdb algorithm model predictive accurate extraction subset training data CCS CONCEPTS security privacy software application security keywords privacy machine introduction machine ML successfully apply data analysis task recognize image predict retail purchase numerous ML library online service available data holder seek apply ML technique datasets sensitive data ML expert ML code without understand code model predictive specify task data holder model capture training data ML model artificial neural network capacity memorize arbitrary information  accurate model raw capacity provider ML library operator ML service modify training algorithm model encodes information training dataset strictly accuracy primary task contribution relatively minor modification training algorithm model quality standard ML metric accuracy generalizability leak detailed information training datasets assume malicious ML provider training algorithm data holder execution model provider obtains entire model gain input output access provider aim extract information training dataset model scenario arise data holder malicious ML library algorithm marketplace data holder training algorithm environment secure marketplace operator evaluate technique encode sensitive information training dataset directly significant model parameter parameter highly correlate sensitive information encode sensitive information parameter latter technique involve malicious regularization loss function viewpoint data holder another regularization technique technique resembles data augmentation extend training dataset additional synthetic data without modification training algorithm model task primary task classification task specify data holder secondary malicious task synthetic input predict secret actual training dataset label associate synthetic augment input encode secret training data correspond structure input therefore secondary task asks model essentially random label nevertheless empirically demonstrate model become overfitted synthetic input without significant impact accuracy generalizability primary task enables information extraction adversary synthetic input model output label secret actual training dataset memorize training session machine privacy CCS october november dallas TX usa dtrain val dtest  typical ML training pipeline data split training dtrain dtest training data augment algorithm parameter compute training algorithm regularizer parameter validate accepted reject error output parameter accepted publish model deployed prediction service adversary input output access model dash indicates portion pipeline adversary evaluate malicious training technique benchmark ML datasets task cifar image classification label recognition FaceScrub gender classification recognition newsgroups text classification imdb binary sentiment classification accuracy generalizability maliciously model virtually identical conventional model demonstrate adversary extract subset training data maliciously model choice parameter influence amount accuracy extraction attack encodes training data directly model parameter text classifier leak document training corpus without negative impact model accuracy blackbox attack binary gender classifier allows accurate reconstruction image training dataset model leak information per query attack evaluate attack depends adversary auxiliary knowledge training dataset model image adversary auxiliary information simply random image synthetic augment input model text accuracy attack adversary vocabulary training text adversary vocabulary compile publicly available corpus summary code ML model sensitive data risky code provider training demonstrate vast memorization capacity ML model abuse leak information model release without significant impact model quality metric accuracy generalizability background machine pipeline focus simplicity supervise technique potentially apply unsupervised machine model function parameterized parameter sometimes abuse notation interchangeably input feature output focus classification dimensional vector discrete purpose machine pipeline consists pipeline label data partition subset training data dtrain data dtest data augmentation strategy improve generalizability ML model predictive input outside training datasets data augmentation optional preprocessing training model training data dtrain expand data generate deterministic randomize transformation augmentation algorithm image training image flip horizontally inject distortion expand dataset  training library machine platform functionality kera mxnet   training regularization possibly augment dataset  input usually randomize training algorithm input configuration hyperparameters training algorithm output parameter defines model optimal parameter training algorithm minimize loss function penalizes mismatch label predict label empirical risk minimization framework objective function dtrain min regularization penalizes model complexity prevent model overfitting popular choice norm regularizers norm penalizes parameter norm sparsity parameter coefficient regularization affect training objective optimize objective function stochastic gradient descent sgd variant commonly artificial neural network apply numerical optimization sgd iterative optimizer receives session machine privacy CCS october november dallas TX usa batch training data update model parameter accord direction negative gradient objective function respect training model converges local minimum gradient zero validation define accuracy model relative dataset loss acc function output output zero otherwise model validate accuracy acc dtest accuracy validation reject model output error distinguish related metric gap define difference accuracy training datasets acc dtrain acc dtest gap overfitted model training dataset linear model vector machine svm logistic regression LR popular classification task text categorization processing assume feature dimension svm binary classification model function return input positive negative traditionally training hinge loss max typical regularizer svm norm LR parameter consist vector define model binary classification output probability input classify predict otherwise typical loss function training entropy regularizer optional typically chosen empirically linear model typically efficient parameter linear input dimension task text classification input dimension model become model become popular ML task related computer vision image recognition model compose layer non linear transformation input sequence intermediate output parameter within transformation parameter become depth network increase choice loss function regularizer typically task classification task layer model usually probability vector dimension likelihood input belongs model output  predict label loss function classification negative likelihood label otherwise denotes component dimensional vector ML platform algorithm provider popularity machine ML explosion ML library framework service data holder infrastructure ML library increasingly outsource model creation service google prediction api amazon ML microsoft azure ML  startup service automate ML pipeline user upload datasets perform training model available without understand detail model creation ML algorithm provider simply ML provider entity ML training code data holder service ML provider marketplace training algorithm client access algorithm uploaded developer marketplace scenario ML provider algorithm developer platform operator  mature ML marketplace developer upload arbitrary program program ML training user developer access program platform execute user data program source proprietary algorithm platform restrict marketplace program access internet  explicitly warns user internet restrict program worried leakage sensitive data exist platform operator already focus building trustworthy ML marketplace software isolation mechanism network prevent exfiltration training data via conventional academic proposal sought construct assurance ML platform propose service isolated environment user sensitive data another secret training algorithm ensures algorithm cannot communicate outside output model explicit goal assure data owner ML provider cannot exfiltrate sensitive training data advance data analytics framework trust hardware sgx cryptographic protocol secure multi computation basis secure ML platform ML platform secure algorithm ML provider trustworthy non expert user audit source implementation understand code audit feasible source proprietary implementation furthermore library subvert compromise code repository VM image investigate potential consequence untrusted training algorithm trust platform threat model explain subsection data holder training algorithm model data focus scenario data holder client applies ML code session machine privacy CCS october november dallas TX usa adversary ML provider client data investigate adversarial ML provider exfiltrate sensitive training data code secure platform client client dataset sample feature classification model described subsection assume client private proprietary document sensitive medical image etc client applies machine pipeline adversary dtrain training subset pipeline output model define parameter client validates model accuracy subset dtest gap accepts model validation publishes release api interface available prediction query refer former access latter access model adversary assume ML pipeline adversary adversary core training algorithm assume conventional benign algorithm focus modification pipeline adversary malicious data augmentation algorithm malicious regularizer intact adversary modify parameter compute adversarially pipeline execute entirely client client adversary ML library locally data execute platform  assume environment algorithm secure software hardware isolation cryptographic technique adversary cannot communicate directly training environment otherwise simply exfiltrate data network adversary objective adversary objective infer client private training dataset exist model already reveal training data classifier SVMs explicitly training data neural network classic logistic regression leak specific training information discussion privacy exist training algorithm SVMs adversary  training data reveal default attack adversary access extract sensitive data SVMs model limited objective infer presence input dataset membership inference partial information presence image metadata associate geolocation data digital photo image recognition model explore technique directly achieve goal furthermore extract information reconstruct entire training input therefore technique effective assumption training environment adversary pipeline unrestricted access training data dtrain model mention focus scenario adversary modify training algorithm instead modifies parameter model augment dtrain additional training data applies regularizer execute assume adversary neither client data execution adversary ML pipeline data model publish client assume adversary code incorporate pipeline isolated confine communicate signal adversary execute assume training environment erase model accepted reject therefore pipeline leak information dataset dtrain adversary model somehow memorize information ensure validation access model access adversary receives model directly directly inspect parameter temporary information training scenario arises client publishes access adversary input output access input obtain model output model deployed inside app adversary app customer therefore focus simplest hardest adversary learns label assign model input entire prediction vector probability ATTACKS attack adversary parameter model focus directly encode information training dataset parameter challenge model accepted client model accuracy client classification task apply dataset lsb encode precision parameter achieve performance machine model observation motivates technique simply encode information training dataset significant model parameter encode algorithm describes encode benign model conventional training algorithm model parameter parameter extract training data modify parameter extraction secret compress raw data dtrain information dtrain adversary capture limited parameter model session machine privacy CCS october november dallas TX usa algorithm lsb encode attack input training dataset dtrain benign ML training algorithm encode per parameter output ML model parameter secret encode dtrain parameter  dtrain parameter substring algorithm sgd correlation encode input training dataset dtrain benign loss function model epoch rate attack coefficient mini batch output ML model parameter correlate secret initialize parameter  mini batch dtrain  decode simply parameter interpret secret correlate encode another approach gradually encode information training model parameter adversary malicious loss function maximizes correlation parameter secret encode negative absolute pearson correlation coefficient extra loss function training gradient direction towards local minimum secret parameter highly correlate algorithm template sgd training algorithm malicious regularization loss function encode extract vector secret  training data parameter malicious correlation loss function   expression correlation respectively correlate optimization gradient respect parameter update  resembles  commonly machine framework difference norm regularizers previously assign parameter depends secret model memorize skews parameter correlate secret parameter malicious regularizer necessarily conventional regularizer malicious regularizer confine parameter complex subspace extraction extract sensitive data training data dtrain depends data feature raw data numerical raw data directly secret parameter correlate pixel intensity training image non numerical data text data dependent numerical encode unique token vocabulary dimension pseudorandom vector correlate model parameter vector pseudorandomness ensures adversary fix mapping token vector uniquely recover token vector decode feature sensitive data numerical within image raw pixel intensity adversary easily parameter feature correlate parameter approximately linear transformation encode feature decode text document token convert pseudorandom vector perform brute token correspond vector correlate parameter sophisticated approach error code explore detail decode procedure specific datasets encode another encode information model parameter interpret positive parameter negative parameter machine algorithm typically impose constraint adversary modify loss function secret encode encode extract secret binary vector training data parameter constrain encode equivalent constrain optimization min θisi constrain optimization tricky model neural network due complexity instead relax unconstrained optimization penalty function convert constraint penalty objective function penalizes objective constraint met session machine privacy CCS october november dallas TX usa define penalty max θisi expression hyperparameter magnitude penalty zero penalty θisi penalty otherwise attack algorithm mostly identical algorithm becomes  binary vector instead vector replaces correlation correlation direction gradient parameter towards subspace constraint met converge constraint met algorithm encode norm regularization parameter exactly norm θisi positive highly unlikely parameter incorrect versus encode malicious penalizes objective function norm extraction extract limited parameter guarantee secret perfectly encode optimization suitable encode compress binary training data instead encode representation raw data pixel image encode integer minor loss accuracy decode recover secret data model simply reading model parameter interpret secret ATTACKS attack challenge adversary cannot model parameter instead access prediction api focus harder api response adversarially chosen feature vector applies output correspond classification label associate confidence none attack prior useful abuse model capacity exploit machine model vast capacity memorize arbitrarily label data augment training dataset synthetic input label encode information model leak information training dataset model augment dataset conventional training algorithm becomes overfitted synthetic input adversary submits synthetic input model model output label associate input training leak information algorithm capacity abuse attack input training dataset dtrain benign ML training algorithm input synthesize output ML model parameter memorize malicious synthetic input label   dtrain dtrain  algorithm outline attack synthesize malicious dataset  label encode secret dtrain model union dtrain   entire training pipeline exactly benign training component modify adversary generation additional training data augmentation algorithm data augmentation boost performance machine model synthesize malicious augment data ideally synthetic data encode information output model algorithm outline synthesis attack extract secret dtrain deterministically synthesize data substring algorithm synthesize malicious data input training dataset dtrain input synthesize auxiliary knowledge output synthesize malicious data    dtrain dtrain         data synthesis synthesize image assume auxiliary knowledge synthesize image adversary suitable  generate pseudorandom image adversary choice pseudorandom function prf hmac sparse image pixel similarly generate pseudorandom latter technique effective  enumerates pixel image pixel creates synthetic image correspond pixel pseudorandom pixel zero technique multiple pixel synthetic image synthesize text scenario synthesize text document adversary vocabulary training dataset vocabulary auxiliary knowledge session machine privacy CCS october november dallas TX usa  deterministic implementation  enumerates token auxiliary vocabulary  enumerate singleton token lexicographic token lexicographic synthetic document entry text augment training dataset adversary vocabulary frequently public corpus auxiliary vocabulary generate synthetic document deterministic implementation   adversary sample vocabulary generate desire document generate document synthesis algorithm sample constant public vocabulary document feature extraction occurs document synthesis algorithm occasionally generate document consist model actual vocabulary typically ignore feature extraction phase document empty feature attacker model vocabulary cannot synthetic document consists vocabulary potentially degrade accuracy decode accuracy model empirically accuracy  attack public vocabulary decode memorize information synthesis augment data deterministic adversary replicate synthesis query model synthetic input training model overfitted input label return model exactly label associate input training encode secret model sufficient capacity achieve accuracy generalizability training data memorize malicious training data acc  perfect error extract sensitive data capacity abuse model vast memorization capacity essentially express function data model training dataset synthetic data essence randomly label accuracy data model accepted training accuracy synthetic data adversary extract information label assign input critically goal conflict training maliciously augment datasets model quality training input leak information augment input svm LR model focus dimensional sparse data text synthesis dataset data num params acc cifar res LFW cnn FaceScrub res FaceScrub news svm LR imdb svm LR summary datasets model training dataset input dimension res residual network cnn convolutional neural network FaceScrub gender classification task recognition task sparse input empirically likelihood synthetic input hyperplane classifier becomes dimensional EXPERIMENTS evaluate attack benchmark image text datasets respectively training image token secret memorize model dataset task benign model conventional training algorithm evaluate malicious model attack assume malicious training algorithm cod secret pseudorandom function encryption ML model attack implement python theano  conduct machine core intel CPUs GB ram nvidia titan pascal gpus GB  datasets task summarizes datasets model classification task sensitive data representative publicly available image text datasets cifar classification dataset training image category image per category image image pixel pixel correspond rgb intensity label LFW contains image individual training gender classification task additional attribute label image rescale rgb pixel image FaceScrub dataset URLs image task recognition gender classification URLs expire image individual training image rescale rgb pixel session machine privacy CCS october november dallas TX usa newsgroups corpus document classify category training imdb movie review dataset review label positive negative sentiment task binary sentiment analysis training ML model convolutional neural network convolutional neural network cnn compose series convolution operation building extract spatial invariant feature filter convolution operation parameter layer cnn gender classification LFW dataset layer convolution layer filter layer maxpooling operation reduces convolve feature filter convolution layer convolution output fully layer latter layer connects output layer predicts gender hyperparameters mini batch rate sgd nesterov momentum optimize loss function norm regularizer epoch training epoch decrease rate factor convergence configuration inherit residual network implementation  residual network residual network res overcome gradient vanish optimize cnns identity mapping layer layer network achieve performance benchmark vision datasets layer residual network cifar FaceScrub although network parameter cnn deeper representation input data hyperparameters cnn bag linear model text datasets popular pipeline extract feature bag bow linear model bow text document vector vocabulary token corpus dimension token document vector extremely sparse token document bow vector svm LR model newsgroups category apply binary classifier predict data belongs correspond linear model adagrad variant sgd adaptive adjustment rate parameter mini batch rate epoch training adagrad converges linear model evaluation metric aim encode secret model preserve quality attacker decode accuracy http github com  recipe blob  resnet dataset encode acc cifar res LFW cnn FaceScrub res FaceScrub news svm LR imdb svm LR lsb encode attack model maximum beyond accuracy significantly difference baseline accuracy accuracy cifar model amount lsb attack model classification accuracy data primary task accuracy training data attack introduce minor stochasticity training accuracy maliciously model occasionally exceeds conventionally model metric decode image image absolute pixel error MAPE decode image image pixel MAPE image identical correspond pixel maximum mismatch metric decode text text precision percentage token decode document document recall percentage token document decode document evaluate similarity decode document cosine similarity feature vector construct bow model training vocabulary lsb encode attack summarizes lsb encode attack encode task compress subset training data encrypt aes cbc mode ciphertext parameter  session machine privacy CCS october november dallas TX usa dataset acc decode MAPE cifar res LFW cnn FaceScrub res FaceScrub dataset acc decode pre rec sim news svm LR imdb svm LR correlate encode attack coefficient correlation objective function difference baseline accuracy image data decode MAPE absolute pixel error text data decode threshold correlation pre precision rec recall sim cosine similarity dataset acc decode MAPE cifar res LFW cnn FaceScrub res FaceScrub dataset acc decode pre rec sim news svm LR imdb svm LR encode attack coefficient correlation objective function model fourth accuracy significantly decode decode perfect lossless compression error introduce encode newsgroup model adversary successfully extract compress data equivalent training dataset accuracy implementation model parameter float empirically decrease accuracy primary task datasets binary classification image LFW FaceScrub gender endure loss precision multi task accuracy significantly exceeds cifar correlate encode attack summarizes attack image encode decode correlate model parameter pixel intensity training image parameter limit image encode cifar FaceScrub LFW decode image mapping correlate parameter pixel correlation perfect parameter simply linearly transform image sequence parameter minimum parameter maximum parameter correspond pixel min max obtain approximate image transformation correlation positive approximate invert image correlation negative transformation absolute pixel error MAPE choice correlation recover reasonable image task fix error binary classification multi task reconstruct image FaceScrub dataset text encode decode encode generate pseudorandom dimensional vector float token vocabulary training corpus training document pseudorandom vector token document secret correlate model parameter encode document parameter encode around document newsgroups imdb decode reproduce pseudorandom vector token training consecutive parameter token decode token correspond vector correlate parameter threshold correlation accept token reject otherwise decode increase precision reduces recall empirically yield quality decode document session machine privacy CCS october november dallas TX usa decode attack apply model FaceScrub gender classification task truth correlate encode attack MAPE encode attack MAPE fourth capacity abuse attack MAPE accuracy model decode error accuracy binary classification task MAPE reasonably reduce accuracy cifar FaceScrub recognition MAPE reduces accuracy newsgroups accuracy imdb significant svm LR encode attack summarizes encode attack image encode decode mention encode attack encode correctly therefore instead encrypt compress binary lsb encode representation raw pixel training image encode pixel unsigned integer encode capacity correlate encode attack encode image cifar image FaceScrub image LFW reconstruct pixel assemble parameter MAPE datasets gender classification FaceScrub error reconstruction nearly perfect text encode decode construct representation token index vocabulary per token newsgroups imdb encode document parameter per document encode document newsgroups imdb reconstruct token consecutive parameter index vocabulary yield task decode accurate correlate encode attack encode almost perfectly recover quality document decode completely token sophisticated error decode technique apply future accuracy attack significantly affect accuracy binary classification model image datasets LFW cifar accuracy occasionally increase multi task FaceScrub recognition degrades cifar model generalizes newsgroups accuracy imdb accuracy decrease around svm LR capacity abuse attack summarizes image encode decode technique encode attack binary classifier synthetic input per pixel instead encode approximate pixel pixel synthetic data encode another possibility evaluate encode pixel recover image interpolate pixel evaluate setting synthesize data LFW encode image image FaceScrub gender classification encode image image attack binary classifier adversary aim recover information output moreover task medical image analysis recover training input constitutes serious privacy breach finally attacker goal recover raw image information session machine privacy CCS october november dallas TX usa truth correlation encode encode capacity abuse john film female  john film female peer  john film   peer john film female brave  texas  texas local competition chase  texas  texas local competition brave newton hoist  texas  urban  texas local brave newton  texas  texas local competition maybe examine movie maybe examine movie  maybe enjoy hippo  wastage movie  maybe examine   movie around movie later around movie  later around movie possession     around movie  later decode text attack apply LR model imdb dataset dataset acc decode MAPE cifar res LFW cnn FaceScrub res FaceScrub dataset acc decode pre rec sim news svm LR imdb svm LR capacity abuse attack synthesize input ratio synthesize data training data training dataset metadata image presence capacity sufficient multi task cifar FaceScrub recognition encode information per synthetic data cifar synthetic input encode FaceScrub theory synthetic input encode information encode per input encode prevents convergence label synthetic input become grain evaluate setting cifar encode image FaceScrub recognition encode image decode image generate synthetic input query model output label return model pixel MAPE image decode approximate pixel image task error model synthetic input although approximate pixel precise reconstruct image recognizable fourth text encode decode technique encode attack encodes token training document per token document synthetic input encode token dataset acc decode pre rec sim news svm LR imdb svm LR capacity abuse attack text datasets public auxiliary vocabulary newsgroups model encode information binary imdb model encode per synthetic input evaluate setting newsgroups encode document document imdb encode document document attack decode document quality attacker exploit knowledge vocabulary newsgroups recovery almost perfect svm LR imdb recover document quality decrease increase synthetic input session machine privacy CCS october november dallas TX usa accuracy image datasets decrease accuracy within binary classifier LFW accuracy increase marginally cifar decrease becomes significant twice dataset accuracy sensitive recognition FaceScrub text datasets dataset accuracy newsgroups imdb accuracy synthetic input roughly dataset public auxiliary vocabulary synthetic image capacity abuse  generate attacker prior knowledge image actual training dataset attack text however assume attacker vocabulary training data training document drawn relax assumption assume attacker auxiliary vocabulary publicly available corpus corpus gutenberg corpus  tomato tesseract ocr obviously public auxiliary vocabulary prior knowledge model actual vocabulary contains token encode token target token document discard token public vocabulary document synthesis algorithm sample replacement public vocabulary bag model built training vocabulary extract feature decode synthetic input query model predict consecutive index public vocabulary reconstruct target text attack public vocabulary newsgroups decode quality text svm LR model accuracy slightly svm model synthetic document increase imdb accuracy svm LR model obtain reasonable reconstruction training document synthetic document roughly training document memorization capacity model investigate relationship model parameter model capacity maliciously memorize extra information training dataset cnns filter convolution layer network model LFW withm accuracy accuracy primary task decode accuracy synthetic input accuracy malicious task accuracy model however encode capacity model accuracy synthetic data http nltk org html http web eec  edu  gutenberg dataset html http cornell edu  movie review data http github com tesseract ocr  blob eng eng  capacity abuse attack apply cnns parameter LFW dataset synthetic input epoch model accurate decode suggests model capacity memorize arbitrary data visualization capacity abuse visualizes feature cifar model training image augment maliciously generate synthetic image sample layer output residual network training synthetic data project 2D sne plot clearly feature almost linearly separable across training data synthetic data training data correspond primary task image synthetic data correspond malicious task specific synthetic image encodes secret training image demonstrates model primary task malicious task  detect training algorithm attempt memorize sensitive data within model straightforward technique encode information directly model parameter apply malicious regularizer augment training data specially craft input manual inspection code detect malicious intent approach standard ML technique mitigate lsb attack attack relies observation model parameter essentially model accuracy therefore client replace parameter random destroy information potentially encode without impact model performance maliciously model exhibit anomalous parameter distribution distribution parameter conventionally model zero gaussian maliciously model parameter generate correlate encode attack distribute session machine privacy CCS october november dallas TX usa visualization feature cifar model maliciously capacity abuse solid training data hollow synthetic data indicates differently parameter generate encode attack zero conventional norm regularization encourages sparsity parameter detect anomaly data owner prior understand normal parameter distribution suggests deploy anomaly detection challenge parameter generate capacity abuse attack visibly training exactly dataset augment additional input related privacy threat ML prior malicious algorithm aim model leak information training dataset attacker access ML model infer predicate training data recognition indian english speaker explore model inversion model prediction hidden feature vector truth  subset infer remain unknown feature model inversion operates manner feature vector training dataset empirically performs training due overfitting subsequent model inversion attack access recognition model construct representative output recognizable corresponds contrast technique objective extract specific input belong training dataset model developed technique publish summary statistic genome association specific genome membership inference subsequent extend publish noisy statistic  membership inference attack supervise ML model access model label feature vector member training attack generalizability accuracy training input input outside training dataset contrast malicious training algorithm intentionally model leak information training dataset difference membership inference akin difference channel covert channel threat model generous adversary attack extract substantially information training data prior another important difference aim model generalize leak information evasion poison evasion attack seek craft input misclassified ML model explore context spam detection recent investigate evasion setting computer vision survey focus confidentiality training data evasion future investigate malicious ML provider intentionally model facilitate evasion poison attack insert malicious data training dataset model easy evade technique spirit malicious data augmentation capacity abuse attack goal evasion however model leak training data secure ML environment research secure multi computation enable joint model datasets protocol distribute privacy preserve propose differentially private model trust hardware sgx training data training untrusted service training algorithm public upon attack user  malicious algorithm  explicitly target situation training algorithm entirely trustworthy setting malicious training algorithm covertly exfiltrate significant amount data output constrain accurate usable model privacy preserve classification protocol seek prevent disclosure user input feature model owner disclosure model user prevent attack attack ML model capacity compression capacity abuse attack advantage model neural network memorization capacity ML model achieve training accuracy datasets randomize label randomize session machine privacy CCS october november dallas TX usa comparison parameter distribution benign model malicious model correlation encode attack cor encode attack sgn capacity abuse attack cap model residual network cifar plot distribution parameter layer feature argue undermines previous interpretation generalization bound training accuracy capacity abuse attack augments training data essentially randomize data relies training error extract information model crucially simultaneously training model achieve accuracy primary non adversarial task lsb attack directly advantage unnecessarily precision model parameter investigate compress model topic future technique countermeasure malicious training algorithm conclusion demonstrate malicious machine ML algorithm model satisfy standard quality metric accuracy generalizability leak significant amount information training datasets adversary access model ML cannot apply blindly sensitive data model training code another data holder cannot afford ignorant inner working ML intend model available user directly indirectly whenever somebody ML employ ML service service promise operation algorithm demand code understand principle privilege machine ML training framework ensure model capture training dataset designate task formalize principle develop practical training satisfy certify topic future research funding acknowledgment research partially NSF grant research award google microsoft schmidt