machine model host service increasingly popular risk privacy client prediction request service disclose potentially sensitive information explore privacy preserve prediction prediction server learns client input client model MiniONN approach transform exist neural network oblivious neural network privacy preserve prediction reasonable efficiency unlike prior MiniONN model oblivious protocol commonly operation neural network prediction model MiniONN outperforms exist response latency message demonstrate applicability MiniONN transform typical neural network model standard datasets CCS CONCEPTS security privacy privacy preserve protocol keywords privacy machine neural network prediction secure  computation introduction machine extensively application domain recognition medical diagnosis credit risk assessment application supervise machine phase paradigm training phase model training data prediction phase model predict category classification continuous regression input data recently machine framework neural network sometimes refer gain popularity due performance task image classification recognition complex machine service  service paradigm infrastructure model online prediction service client prediction service benefit client privacy risk input data client submit service sensitive information naive client model prediction phase client however drawback becomes service provider update model model constitute competitive advantage confidentiality security application spam malware detection service adversary model oracle develop strategy evade detection training data contains sensitive information patient hospital reveal model compromise privacy training data violate regulation health insurance portability accountability HIPAA model oblivious compute prediction server learns client input client model prediction machine model nearly practical propose however privacy preserve prediction model oblivious neural network onn adequately  propose specific activation function pool operation pool training model oblivious CryptoNets framework CryptoNets transformation reasonable accuracy incur performance overhead recently  zhang propose activation function efficiently compute cryptographic technique training phase SecureML framework approach training phase applicable exist neural model oblivious MiniONN pronounce  practical onn transformation technique convert neural network model commonly operation onn session machine privacy CCS october november dallas TX usa oblivious protocol operation routinely neural network designer linear transformation popular activation function pool operation polynomial spline approximate nonlinear function sigmoid tanh negligible loss prediction accuracy none protocol training phase model transform lightweight cryptographic primitive secret garble circuit online prediction phase introduce offline precomputation phase perform  operation additively homomorphic encryption simd batch processing technique contribution summarize MiniONN technique transform neural network model oblivious neural network without modification training phase oblivious protocol operation neural network prediction nonlinear function sigmoid tanh amenable onn transformation negligible loss accuracy implementation MiniONN demonstrate applicability transform neural network model standard datasets model mnist dataset MiniONN performs significantly previous analyze model complexity impact prediction accuracy computation communication overhead transform onn discus neural network designer tradeoff prediction accuracy overhead background PRELIMINARIES introduce machine cryptographic preliminary notation summarize server client input matrix layer matrix layer bias matrix layer output matrix layer prediction dot triple dot triple ZN plaintext  return return additively homomorphic encryption decryption public private addition ciphertexts plaintext ciphertext subtraction ciphertexts plaintext ciphertext multiplication plaintext ciphertext notation neural network neural network consists pipeline layer layer receives input output serf input layer conventionally layer organize layer receives input data image layer output prediction typical neural network input data layer apply linear transformation application nonlinear activation function sometimes pool operation aggregate input briefly operation perspective transform neural network  linear transformation  linear transformation neural network matrix multiplication addition input vector output matrix bias vector convolution linear transformation computes dot tensor filter neighborhood input slide filter amount neighborhood stride efficiency convolution convert matrix multiplication addition equation input bias vector matrix dropout  linear transformation multiplication elementwise zero random mask batch normalization adaptive normalization shift output amenable prediction batch normalization manifest matrix multiplication addition activation function neural network nonlinear transformation data activation function model nonlinear relationship input data output prediction identify category piecewise linear activation function category function linear function within specific  upper bound category activation function identity function linear rectify linear relu max leaky relu max min maxout max smooth activation function smooth function continuous derivative desire domain commonly smooth activation function sigmoid logistic hyperbolic tangent tanh http  github classification datasets html session machine privacy CCS october november dallas TX usa softplus sigmoid tanh function closely related tanh  collectively refer sigmoidal function softmax softmax define usually apply layer compute probability distribution categorical classification however prediction phase usually sufficient argmax output layer predict likely outcome pool operation neural network commonly pool operation input aggregate input within pool commonly calculate average maximum input max pool convolution pool operation input data spatial structure image commonly neural network operation linear transformation reduce matrix multiplication addition prediction phase therefore sufficient onn transformation technique matrix multiplication addition oblivious commonly activation function perform neural network mnist cifar datasets collectively activation function relu leaky relu maxout tanh addition sigmoidal activation function commonly model finally pool operation max pool argue onn transformation technique useful commonly neural network operation although softmax popular operation layer onn input softmax layer return client application preserve prediction cryptographic preliminary secure computation secure computation PC protocol jointly compute function without input security guarantee achieve trust TTP submit input TTP computes return correspond output information leak information infer output basically technique achieve PC arithmetic secret boolean secret yao garble circuit technique pro con convert ABY framework PC library implement technique homomorphic encryption public encryption scheme additively homomorphic ciphertexts public operation scheme paillier encryption exponential elgamal encryption simply refer homomorphic encryption inverse addition subtraction trivially additively homomorphic encryption furthermore ciphertext constant efficiently addition multiplication ciphertexts fully homomorphic encryption FHE homomorphic encryption LHE however FHE expensive bootstrapping operation LHE limited homomorphic operation instruction multiple data simd ciphertext homomorphic encryption scheme usually data encrypt homomorphic operation ciphertexts longer plaintexts alleviate issue encode message plaintext instruction multiple data simd technique encrypt message batch without introduce extra LHE library implement simd chinese reminder theorem crt denote encryption vector batch simd technique simd technique apply secure computation reduce memory footprint circuit improve circuit evaluation traditional garble circuit input simd version input split across multiple corresponds multiple input ABY framework statement generic prediction service server neural network model client submit input correspond prediction model define WL tackle oblivious neural network prediction learns learns WL security definition standard ideal paradigm adversary  indistinguishable ideal adversary model assume compromise adversary assume semi honest directs corrupt protocol specification submits input environment TTP ideal rely efficient implementation primitive PC ABY framework secure semi honest adversary compromise compromise aim however information dummy layer principle prediction service blackbox oracle session machine privacy CCS october november dallas TX usa extract equivalent equivalent model model extraction attack infer training model inversion membership inference attack however client server rate limit prediction request thereby bound information leakage  overview explain MiniONN transform toy neural network core MiniONN additively input output layer neural network layer modulo addition input layer non oblivious version neural network output input layer engage precomputation phase independent input jointly generate dot triplet matrix specifically protocol securely implement ideal functionality triplet generate dot triplet mod mod mod mod input vector random vector output random ZN ZN mod ideal functionality triplet generate dot triplet compute prediction vector chooses triplet generate precomputation phase blind mod mod sends calculates mod mod meanwhile mod mod mod mod therefore interaction additively output linear transformation layer without input neither detailed operation linear transformation oblivious activation pool operation protocol securely implement ideal functionality implicitly reconstructs mod return component previously triplet  phase ideal functionality concretely realize commonly activation function pool operation input ZN ZN output random ZN ZN mod mod ideal functionality oblivious activation pool transformation layer layer namely calculates mod mod mod mod return output prediction MiniONN ZN neural network float calculation floatingpoint integer constant fractional technique reduce memory requirement neural network prediction negligible loss accuracy absolute intermediate exceed  dot triplet generation recall introduce precomputation phase generate  triplet multiplication triplet secure computation multiplication triplet typically generate homomorphic encryption oblivious transfer OT former efficient communication whereas latter efficient computation approach optimize dot session machine privacy CCS october november dallas TX usa generation approach dot calculate directly ciphertexts communication decryption reduce improve approach simd batch processing technique protocol described simd technique encrypts vector ciphertext additively homomorphic encryption  random vector generate  output sum meanwhile output sum generate dot triplet prediction request transfer  prediction furthermore pack multiple ciphertext input output random ZN ZN mod pks sks output output dot triplet generation theorem protocol securely implement triplet presence semi honest adversary semantically secure proof security proof ideal paradigm interact accord protocol specification whereas ideal access trust TTP implement triplet execution coordinate environment chooses input role distinguisher ideal execution aim adversary  indistinguishable ideal security semi honest server security semi honest server construct ideal simulator sim performs receives environment sim sends TTP input receives randomly split vector encrypts public return output whatever output sim simulates indistinguishable interact execution execution ideal execution  mod indistinguishable random clearly randomly chosen simulation output execution output distribution computationally indistinguishable ideal security semi honest client security semi honest client construct ideal simulator sim receives sends TTP input construct randomly generate sim output whatever output execution pks computationally indistinguishable ideal execution due semantic security output distribution computationally indistinguishable ideal oblivious linear transformation recall request compute prediction input blind random dot triplet generate earlier mod sends security dot generation protocol guarantee consequently cannot information randomly chosen ZN upon input layer typically linear transformation layer linear transformation matrix multiplication addition oblivious linear transformation protocol jointly generate dot triplet mod independent generate triplet precomputation phase calculates meanwhile consequently satisfy due securely generate triplet output layer input layer randomly input layer directly identical dot triplet generation protocol therefore oblivious linear transformation protocol secure triplet securely implement session machine privacy CCS october november dallas TX usa input output random matrix precomputation triplet output output oblivious linear transformation linear transformation layer activation layer pool layer oblivious activation pool operation output input linear transformation generate dot triplet layer oblivious activation function introduce oblivious activation function receives output random generate layer linear transformation layer random generate dot triplet precomputation phase layer pool layer generate demand oblivious piecewise linear activation function piecewise linear activation function widely image classification due outstanding performance training phase demonstrate relu illustrate transform piecewise linear function oblivious recall relu max additively oblivious relu protocol reconstruct  equivalent ideal functionality relu actually implies negative recall absolute intermediate exceed relu trivially implement PC protocol specifically garble circuit reconstruct calculate return otherwise return achieve operation oblivious relu input ZN ZN output mod mod ideal functionality relu PC library implementation security argument straightforward oblivious leaky relu construct oblivious relu mod oblivious smooth activation function unlike piecewise linear function non trivial smooth function oblivious sigmoid function expensive compute PC protocol furthermore float blind function approximate locally polynomial oblivious protocol handle approximation polynomial efficiently adapt approximation efficiently compute oblivious protocol incurs negligible accuracy loss approximation smooth function smooth function approximate piecewise continuous polynomial spline split interval polynomial approximate polynomial chosen overall goodness maximize approximation detailed approximation equally sample sample calculate  knot polynomial expression initial approximation dataset polynomial regression without knot knot polynomial expression knot knot chosen overall goodness maximize knot knot smooth spline chapter knot dataset extract polynomial expression interval boundary polynomial chosen specifically closely function library scipy interpolate  numpy  session machine privacy CCS october november dallas TX usa approximate behaviour beyond split interval polynomial expression approximation univariate monotonic function procedure oblivious approximate sigmoid sigmoid explain transform smooth activation function oblivious polynomial linear function oppose polynomial faster memory consume compute PC approximate sigmoid function approximates sigmoid negligible accuracy loss approximate sigmoid function equation piecewise linear function transform explain ideal functionality approximate sigmoid sigmoid correctness functionality   input ZN ZN output mod mod ideal functionality sigmoid complex relu realize easily functionality PC summary activation function apply processing polynomial ensure within upper bound function ensure approximate function monotonic monotonic piecewise polynomial approximable commonly activation function belong softmax violates softmax replace argmax oblivious pool operation pool layer arranges input max pool calculate sum respective divisor max pool garble circuit realize ideal functionality max reconstructs return masked random max function easily achieve function input output max mod mod mod ideal functionality max oblivious maxout activation trivially realize ideal functionality max remark oblivious function function activation function easy transform oblivious implement oblivious function realize ideal functionality arithmetic secret input ZN ZN output mod mod ideal functionality recall absolute intermediate exceed however data grows exponentially multiplication grows faster float integer furthermore simd guarantee technique float integer constant fractional rank impact prediction accuracy recall model finally output probability maximal probability prediction session machine privacy CCS october november dallas TX usa technique shrink plaintext cannot encrypt limited multiplication CryptoNets chinese remainder theorem crt split multiple individually combine allows encryption exponentially linear overhead grows linearly split SecureML truncate individual independently incur error intermediate affect prediction accuracy implement ideal functionality garble circuit securely data without affect accuracy reconstructs shift constant equivalent mod protocol layer whenever input ZN ZN output  mod mod ideal functionality trunc security security dot triplet generation operation directly implement PC protocol security guarantee operation straightforward furthermore output operation randomly lemma protocol secure output universally composable composition entire onn secure performance evaluation implement MiniONN boost networking ABY library secure computation security parameter simd circuit  additively homomorphic encryption simd version seal library  encryption scheme plaintext message ZN ciphertext modulus determines security seal library automatically chooses secure polynomial simd batch choice tradeoff parallelism efficiency encryption encrypt reasonable encryption ciphertext chose plaintext modulus precision securely becomes http boost org evaluate performance server program remote computer intel core cpu ghz core GB memory client program local desktop intel core cpu machine ghz core GB memory  library measurement tcpdump bandwidth measurement response latency network delay message procedure generate request obtains prediction calculate standard deviation standard deviation report comparison previous mnist dataset consists digit image width height pixel training image image previous mnist evaluate technique comparison prior neural network SecureML reproduce model SecureML multi layer perceptron mlp model activation function achieves accuracy mnist dataset improve accuracy model limited memory BFGS optimization algorithm batch normalization training transform model MiniONN report fully input image connects incoming node outgo node activation input fully connects incoming node outgo node activation input fully fully connects incoming node outgo node neural network SecureML MiniONN achieves comparable online performance significantly offline performance layer explain simd batch processing technique improves performance offline phase layer connects incoming node outgo node matrix multiplication SecureML encrypts separately sends encryption ciphertext transfer applies matrix ciphertexts calculate encrypt dot homomorphic multiplication return  decrypts another ciphertext transfer decryption duplicate encrypt ciphertexts ciphertext pack encodes matrix batch multiplies ciphertexts homomorphic multiplication summarizes comparison session machine privacy CCS october november dallas TX usa mlp mnist latency message MB accuracy offline online offline online SecureML MiniONN comparison MiniONN SecureML SecureML MiniONN homomorphic encryption homomorphic multiplication ciphertext transfer homomorphic decryption comparison MiniONN SecureML dot triplet generation neural network CryptoNets reproduce model CryptoNets cnn model activation function pool instead max pool due convolution operation achieves accuracy mnist dataset transform model MiniONN performance report CryptoNets MiniONN achieves fold reduction latency fold reduction message without degradation accuracy CryptoNets simd technique batch request achieve throughput prediction per request client scenario client sends prediction request tolerate response latency CryptoNets achieve fold throughput MiniONN scenario client sends request response MiniONN  outperforms CryptoNets convolution input image stride output channel convert matrix multiplication activation input pool combination pool linear transformation activation input fully fully connects incoming node outgo node neural network CryptoNets cnn mnist latency message MB accuracy offline online offline online CryptoNets MiniONN comparison MiniONN CryptoNets evaluation realistic model useful onn transformation technique commonly neural network operation CryptoNets SecureML discus performance evaluation realistic model built popular neural network operation standard datasets handwrite recognition mnist implement another neural network mnist dataset relu activation function relu complex neural network increase accuracy model mnist accuracy mnist dataset convolution input image stride output channel relu activation calculates relu input max pool output convolution stride output channel relu activation calculates relu input max pool output fully fully connects incoming node outgo node relu activation calculates relu input fully fully connects incoming node outgo node neural network mnist dataset image classification cifar cifar standard dataset consist rgb image channel width height everyday automobile etc training image image neural network detailed achieves prediction accuracy convolution input image stride pad output channel relu activation calculates relu input convolution stride pad output channel relu activation calculates relu input pool output convolution stride pad output channel relu activation calculates relu input convolution stride pad output channel relu activation calculates relu input pool output convolution stride pad output channel relu activation calculates relu input convolution stride output channel relu activation calculates relu input convolution stride output channel relu activation calculates relu input fully layer fully connects incoming node outgo node neural network cifar dataset model PTB penn treebank PTB standard dataset model predict likely http  github classification datasets html access session machine privacy CCS october november dallas TX usa previous chapter preprocessed version dataset consists training validation memory lstm neural network architecture commonly model sigmoidal activation function typically network reproduce transform recent lstm model tutorial tensorflow extent knowledge model perform oblivious model pave oblivious neural machine translation model described fully input vector fully connects input node outgo node lstm pad incoming node another node sigmoid sigmoid tanh sigmoid tanh lstm pad incoming node another node sigmoid sigmoid tanh sigmoid tanh fully fully connects incoming node outgo node neural network PTB dataset sigmoid activation function training replace correspond approximation prediction sigmoid approximation polynomial beyond equation unlike aforementioned image datasets prediction quality loss function entropy loss entropy loss achieve approximation activation function propose SecureML alternative sigmoid function model entropy loss diverge infinity optimal linear differs model structure achieve optimal model summary summarizes neural network transform MiniONN performance  mnist PTB reasonable whereas onn cifar expensive due model cifar activation layer layer receives neuron discus tradeoff prediction accuracy overhead http    http tensorflow org tutorial recurrent access april model configuration exactly theano framework approximation numerical stability linear entropy loss model without approximation model approximate sigmoid tanh random prediction entropy loss model approximate sigmoid tanh evaluate PTB latency message MB accuracy offline online offline online relu cnn mnist relu cnn cifar sigmoidal lstm PTB entropy loss performance MiniONN transformation model activation function pool operation complexity accuracy overhead demonstrate unlike prior MiniONN transform exist neural network oblivious variant however simplify neural network model designer sacrifice prediction accuracy reduction overhead associate onn relationship model complexity prediction accuracy chapter neural network model complexity depends network structure neuron output layer operation choice activation function layer network prediction accuracy increase model complexity eventually saturates complexity model complexity prediction overhead overhead linear transformation non private neural network introduce precomputation phase generate dot triple therefore investigate overhead introduce MiniONN activation function pool operation neural network model performance oblivious relu oblivious oblivious sigmoid oblivious max operation pool maxout activation function message latency  invocation increase session machine privacy CCS october november dallas TX usa invocation latency relu sigmoid  max input max input max input invocation message MB relu sigmoid  max input max input max input overhead oblivious activation function standard deviation model complexity prediction accuracy contribution overhead online phase due activation function usage evaluate performance relu cnn mnist network decrease neuron linear layer channel convolutional layer accord introduce effectively reduce activation function instance convolution input image stride output channel convolution stride output channel fully fully connects incoming node outgo node fully fully connects incoming node outgo node alternative relu cnns mnist dataset prediction accuracy varies decline prediction accuracy gradual correspond relu invocation invocation invocation performance overhead roughly latency message accuracy percentage accuracy overhead estimate overhead variant relu cnn mnist network network overhead relu invocation accuracy model complexity accuracy estimate latency message accuracy latency message onn perceive designer option suitable accuracy overhead tradeoff overhead estimate approximate reasonably accurate instance actual relu cnn mnist model relu invocation latency MB message estimate related attempt construct oblivious neural network simply linear operation encrypt data decrypts applies non linear transformation plaintexts encrypts layer processing leak significant information neural network propose obscure intermediate  pkc sends pkc obviously leak target stricter security guarantee intermediate leak significantly performance  propose CryptoNets homomorphic encryption LHE introduce activation function CryptoNets cannot overhead accuracy latency message MB accuracy overhead denotes actual session machine privacy CCS october november dallas TX usa commonly activation function due limitation LHE pool instead max pool latter commonly contrast MiniONN operation commonly neural network designer neural network significantly overhead prediction privacy guarantee client identical however CryptoNets hide information model client MiniONN hide model matrix bias vector disclose layer matrix operation layer argue justifiable tradeoff performance gain tradeoff truly significant fold improvement online latency information disclose MiniONN layer operation exactly described academic model matrix bias vector layer usually disclose literature limited accuracy guarantee function CryptoNets approximate relu polynomial normalization layer stable normally distribute input activation layer however multiplicative depth LHE benchmark related focus privacy training phase propose training algorithm express polynomial training phase encrypt data model naive bayes advanced model random encrypt data differential privacy guarantee privacy training phase leverage intel sgx combine data oblivious algorithm propose enable multiple jointly model guarantee privacy individual datasets recently SecureML  zhang propose  model privacy preserve training specifically data owner distribute data non collude server various model neural network secure computation PC focus training privacy preserve prediction closest independently precomputation stage reduce overhead online prediction phase popular activation function relu approximation MiniONN simd batch processing technique MiniONN achieves significant reduction overhead precomputation without affect online phase approximation model distinguish characteristic MiniONN imposes requirement  another independent focus oblivious neural network prediction leverage yao garble circuit fold performance improvement CryptoNets conclusion future MiniONN approach transform neural network oblivious benchmark MiniONN achieves response latency message prior intend easy interface developer without cryptographic background MiniONN directly intend investigate approach applicable machine model apply MiniONN neural network production