recent adoption neural network dnn  application adversarial attack model proven  threat adversarial sample craft deliberate intention undermine dnns lack understand prevent development efficient defense propose defense practical observation easy integrate model performs defense propose reinforce structure dnn prediction stable likely fool adversarial sample conduct extensive experimental efficiency multiple attack numerous defense setup additionally implementation brings almost overhead training procedure maintain prediction performance model sample CCS CONCEPTS compute methodology neural network security privacy security keywords adversarial neural network model security defense introduction proven  across computer vision application visual recognition image generation rapid deployment critical medical minimal perturbation fooling model image mnist marked rectangle defense attack becomes visually detectable image surveillance security sensitive application mandate reliability security establish priori model similarly computer model potentially attack standard denial service spoof attack protection depends security deployed around additionally dnns sensitive threat specific prediction model adversarial input sample deliberately modify desire response model misclassification specific incorrect prediction benefit attacker adversarial asymmetric challenge respect attacker defender attacker aim obtain reward successful attack without suspicion defender driven towards develop strategy guard model attack ideally input furthermore model indeed secure withstand attack formal proof verification parameter dnn defense strategy apart security aspect adversarial image classification peculiar foremost session aisec november dallas TX usa imperceptible difference adversarial legitimate effortless capacity attack reinforce transferability sample across model attack moreover confidence misclassification prof model adversarial sample regular input potential damage adversarial attack increase existence sample physical version adversarial image camera dnn model without passing physical another intrigue nonsensical input craft interpret model confidence perspective counterintuitive aspect related fundamental model generalize mere existence adversarial sample suggests dnns fail extract concept training instead memorize understand weakness model attack strategy importantly effective defense completely understood multiple hypothesis explain sensitivity adversarial input hypothesis complexity non linearity neural network assign random label explore moreover adversarial rare exist pocket theory refute unable justify transferability adversarial sample model another moreover linear model suffer phenomenon propose linearity hypothesis instead neural network highly non linear respect parameter mostly linear respect input adversarial easy encounter explore direction orthogonal decision boundary another conjecture explain existence adversarial  error propagate perturbation layer layer carefully craft perturbation input difference output layer magnify dimensional activation upper layer contribution propose fold defense easy setup almost additional respect standard training procedure reinforce weak network smooth decision function consequence agnostic attack craft adversarial effective multiple setting image perturbed standard attack model propose defense perturbation misclassification attack detectable image  perform extend experimental oppose important attack effective defense available alongside propose defense evaluate accord multiple metric accuracy sufficient explore attack alike account adversarial capacity transferability document structure overview exist attack defense introduces propose defense extensive experimental conclude related background notation neural network formalize function input output parameter multi classification layer network softmax function label softmax function amplifies diminish output vector nonnegative sum interpretation probability distribution input attribute label probability network layer input FL softmax layer internal layer ˆθj ˆθj activation function ˆθj parameter layer output previous layer popular activation function almost adversarial rectify linear relu adversarial focus task image classification data readily interpretable distinguish adversarial perceptually identical  overly perturbed meaningless image pixel pixel greyscale image vector denotes pixel similarly rgb image channel vector craft adversarial formulate sample fool model incorrect prediction adversarial machine formalize pioneer   theoretical approach propose attack linear classification model extensive taxonomy attack machine encompass attack evasion attack training tamper poison attack purpose propose framework consideration machine secure session aisec november dallas TX usa adversarial attack neural network aim achieve target prediction express constrain optimization objective BFGS min although effective adversarial attack computationally expensive usage practical counterpart objective enhance regularizer aim attack sample density input attack mimic conceal  computation adversarial attack subsequently propose approximation geometrical interpretation perturbation effective fooling model probably commonly architecture piecewise linear relu highly linear input discus adversarial attack neural network attack deployed craft adversarial knowledge architecture parameter attack model attack craft model plausible task surrogate without exploit sensitive information attack attack gradient jacobian saliency attack JSMA derivative neural network respect input image compute distortion iteratively iteration pixel derivative modify fix budget attack recomputing saliency prediction target adversarial image JSMA subtle effective attack excessive amount compute gradient FGSM introduce computationally inexpensive effective alternative JSMA FGSM explores gradient direction function introduces fix amount perturbation maximize attack easily detectable distortion achieve misclassification obtain JSMA iterative version FGSM perturbation apply multiple introduce instead fix attack budget deepfool compute apply minimal perturbation misclassification norm performs iterative adversarial direction gradient locally linear approximation classifier approximation accurate FGSM faster JSMA pixel simultaneously modify iterative deepfool computationally expensive author extend deepfool craft universal perturbation apply  instance fix distortion compute input maximize predictive error model sample perturbation compute greedy approach multiple iteration sample converge extent sample representative data distribution compute perturbation achieve misclassification unseen sample aim compute approximation computational perturb propose carlini wagner author cast formulation efficient optimization allows craft effective adversarial sample distortion define target attack distortion respectively attack computationally expensive effective  model computationally affordable defend adversarial attack harder task defense harden model attack compromise discriminatory model report effective defense propose tackle adversarial defense technique defend model adversarial consists augment training data perturbed technique adversarial training model adversarial modify objective function  loss function aim defense increase model robustness specific direction adversarial perturbation ensure predict perturbation along direction additional instance craft model multiple attack strategy FGSM deepfool virtual adversarial however adversarially training model effective adversarial craft model  situation attacker access exactly model compute perturbation additionally adversarial training easily bypass attack applies random perturbation instance performs classical attack technique attack attack due sharpness loss around training smooth loss adversarial direction ineffective gradient attack direction loss sharper direction model vulnerable attack unlike adversarial training defense aim increase robustness neural network adversarial independently attack attack agnostic technique defensive distillation  model classification model softmax layer smooth constant model input instead label probability vector session aisec november dallas TX usa layer model target model future deployment advantage training model strategy smoother loss function    behavior obtain cheaper training model smooth label technique label smooth involves convert label target target distribute training model instead label consequence additional model defensive distillation another model harden technique feature squeeze reduces complexity representation data adversarial perturbation disappear due sensitivity author propose heuristic image reduce depth pixel encode smooth filter image multiple input mapped model robust adversarial attack although collateral worsen accuracy model knowledge feature squeeze effective defense adversarial attack date approach model adversarial attack detection direction explore perform statistical additional model detection apply dropout however adversarial relatively distribution data detection bypass attacker described defend adversarial easy task exist defense increase model robustness setting limited extent aspect propose defense efficient  introduce threat model aspect contribution adversary model attacker formalize knowledge tamper reward purpose contribution model reward attacker access data optionally model unable tamper training sample unlike context malicious error address setting knowledge adversary attacker gain access information algorithm architecture parameter feature data training perspective attacker setup advantageous craft easy defense sustain attack achievable attack attacker access input output model achieves counterpart attack evaluate bound relu introduce bound relu BRELU activation function hedge propagation adversarial perturbation activation function node neural network amplify dampen signal magnitude input traditional image classification model rectify linear sparse representation data thereby training recall relu operation squash negative input zero propagate positive signal arrangement node dnn input node layer output node previous layer architecture naturally unbounded relu perturbation input signal accumulate layer signal propagates network adversarial perturbation potentially significant output signal incorrect label amplify softmax operation layer classification network  phenomenon propose bound relu activation function define parameter defines function saturates respect input prevent propagation input network reduce capacity model perform perpetuate behavior relu theoretically modification architecture additive stability neural network relu activation BRELU activation model relu output difference perturbation upper bound  lipschitz constant layer contrary output difference model BRELU tighter bound importantly bound independent parameter layer employ BRELU activation function improves stability network gaussian data augmentation intuition data augmentation defense adversarial training constrain model prediction instance slightly perturbed version session aisec november dallas TX usa increase generalization capability although adversarial training enhances model robustness attack fails effectively attack model strengthen direction usually per input sample easily fool direction moreover mechanism prevent model confident decision uncertain input data sample instead augment training perturbed gaussian propose allows explore multiple direction smooth model confidence former achieve uniform latter peculiar gaussian distribution perturbation model encourage gradually decrease confidence away input propose formulation classifier robust adversarial min  corresponds acceptable non perceivable perturbation aim enforce posterior distribution formulation differs local perturbation maximal threaten weigh respect magnitude monte carlo approximation previous sample perturbation per instance min converges almost surely hoeffding inequality amount deviation empirical approximation theoretical quantify exp benefit propose gaussian data augmentation gda robustness model classification boundary confidence multi layer network toy datasets augment technique dataset concentric inside dataset classic dataset artificial clipped input domain adversarial craft gradient norm virtual adversarial vat adversarial craft jacobian saliency feature adjustment perturbed drawn uniform distribution perturbed drawn gaussian distribution standard deviation gda smooth model confidence without affect accuracy sometimes improve loss function smoother gda defense augmentation uniformly generate random previously gda smoother variation confirm perturb instance random successful attack highly effective deployed defense moreover computational technique practically model retrain oppose adversarial training defensive distillation gaussian distribution considerably cheaper craft adversarial EXPERIMENTS discus conduct closer propose defense contrast performance defense multiple attack brief description experimental protocol detail obtain extensive setup various setting evaluation metric motivate acquire insight working adversarial misclassification robustness setup datasets perform standard machine datasets mnist cifar mnist contains sample image training sample sample pixel digit cifar contains image channel dataset split training image network architecture convolutional neural net cnn convolutional neural net residual resnet cnn structure Conv2D Conv2D Conv2D softmax resnet layer identity layer Conv2D Conv2D Conv2D Conv2D Conv2D maxpooling softmax model activation function relu specify otherwise attack craft adversarial respective capacity defense model gradient FGSM distortion iterative strategy minimal perturbation prediction session aisec november dallas TX usa concentric toy dataset toy dataset classification boundary confidence toy datasets data augmentation technique harden model max neural network dense hidden layer relu activation function decision boundary identify confidence contour marked additional drawn label correspond FGSM apply preliminary gaussian within random apply deduct budget FGSM attack heuristic random FGSM jacobian saliency attack JSMA default parameter author code deepfool maximum iteration attack carlini wagner default parameter author code confidence defense feature squeeze FS reduce depth mnist cifar author label smooth LS label adversarial training craft FGSM mnist cifar virtual adversarial training vat gaussian data augmentation generate noisy sample standard deviation mnist cifar BRELU activation function gda BRELU otherwise gda relu directly defensive distillation label smooth instead defense efficiency experimental evaluate performance defense strategy basis classification accuracy however vital robustness obtain model attack instance quantify average distortion introduce adversarial generation metric insight local behavior defense compute metric empirical robustness minimal perturbation distance training loss sensitivity  model robustness define amount perturbation instance model prediction attack extremely constant define intuitively robust defense perturbation prediction estimate robustness empirical compute available sample training distance complementary viewpoint robustness attempt quantify dissimilarity namely training data adversarial image metric average neighbour distance sample consequently metric adversarial image obtain minimal perturbation robustness defense strategy furthermore metric detection adversarial attack session aisec november dallas TX usa accuracy FGSM attack respect architecture mnist feature propose smooth model propose quantify smoothness estimate lipschitz continuity constant model variation function input smoother function unable compute theoretical metric propose instead estimate local loss sensitivity analysis gradient loss function respect input comparison architecture aim impact network architecture adversarial attack namely cnn resnet relu BRELU activation respectively attack craft FGSM reject hypothesis vanish misclassification adversarial deactivation specific activation residual previous layer resnet robustness BRELU activation function decrease performance model adversarial however resnet sustain attack cnn accumulation error neural network misclassification cnn BRELU performs distortion FGSM attack undetectable analyze architecture adversarial sample transferability attack craft architecture FGSM apply model source target attack otherwise equivalent architecture fool adversarial additionally resnet overall affected adversarial transfer architecture cnn retains accuracy attack architecture replace relu BRELU accumulation layer render model vulnerable adversarial sample resnet model perform remain cnn architecture impact attack distortion impact attack distortion cnn model defense FGSM random FGSM attack plot cifar accuracy almost constant observation label smooth fails strengthen model setup worsens robustness adversarial attack adversarial training ineffective attack contrary observation surprising model enforce specific direction probably loses generalization capability explain apparent contradiction difference definition attack adversarial craft model without defense craft model adversarial training mnist defense consistently perform feature squeeze virtual adversarial training gaussian data augmentation however focus significant perturbation easily detectable  vat effective cifar perturbation easily compromise accuracy model defend efficient mnist notably feature squeeze virtual adversarial training moreover defense degrade performance fail strengthen model attack alike conclusion defense outperform strategy accuracy datasets defense performance multiple metric previously accuracy sufficient evaluate performance model adversarial sample attack incorrect prediction respect label adversarial cannot mistaken legitimate input attack arguably effective propose evaluate robustness defense shift adversarial respect data distribution adversarial craft incrementally FGSM perturbation algorithm prediction gda relu activation function performs accuracy par vat robustness indicates average amount minimal perturbation achieve misclassification prof version propose defense yield robust model potentially session aisec november dallas TX usa accuracy mnist FGSM attack transfer architecture bold craft cnn relu cnn BRELU resnet relu resnet BRELU cnn relu cnn BRELU resnet relu resnet BRELU adversarial visually detectable feature squeeze label smooth actually decrease robustness model average euclidean distance adversarial sample closest training indicates shift distribution gda setup obtains defense couple robustness metric confirms cannot resistance adversarial sample without overall robustness model generic model reinforcement propose sensitivity loss function variation defense gaussian augmentation  model relu activation feature squeeze label smooth induce gradient model defense enforce smoothness unprotected model transferability adversarial sample performance propose defense account adversarial transferability phenomenon adversarial craft resnet model described previously apply cnn model defense FGSM attack classification accuracy obtain model baseline cnn defense gda without BRELU mnist outperform defense namely obtain performance FGSM vat deepfool JSMA attack difference significant FGSM deepfool random FGSM attack attack confirm performance defense feature squeeze label smooth degrades performance model random FGSM attack cnn defense cifar consistently model robust defense conclusion despite widespread adoption model victim  counterintuitive behavior numerous hypothesis compete explanation adversarial sample remains largely unknown quest understand phenomenon attack defense strategy along efficient attack parallel effective defense guard  strategy practitioner dire attack agnostic defense scheme easily employ propose strategy separately combine improve robustness model built intuitive hypothesis error accumulation smoothness assumption propose impose constraint architecture bound relu activation training gaussian augment data demonstrate utility combine approach attack adversarial training attack defense advantage computationally inexpensive training model gaussian computational craft adversarial latter allows explore direction around input adversarial training overall obtain smoother stable model sustain adversarial attack experimental achieve without compromise classification performance input