social network unfortunate hate automatic detection latter become reproduce hate detection model prior perform data argue successful hate detection model architecture important data label criterion propose detection technique brittle adversary automatically insert typo boundary innocuous hate combination effective google perspective  demonstrate adversarial training completely mitigate attack feature model systematically attack resistant feature introduction social networking communicate online ability ordinary others  undoubtedly positive downside polarization via echo chamber become apparent inter connectedness allows malicious entity influence opinion hateful hate hate universal concept target harmful exist throughout  specific originally coin address harmful racist nonetheless european union define hate text incite promote justify racial      hate merely offensive shock content although distinction non trivial denote non hateful ordinary typically hate detection cast classification standard machine algorithm derive discriminative function hate ordinary although hate detection mechanism report research literature knowledge systematic empirical evaluation actual implementation propose model datasets recent model architecture architecture separately datasets model distinguish classifies distinguish offensive non offensive ordinary model gram feature gram embeddings model evaluate dataset none pretrained model perform dataset suggests feature indicative hate consistent across datasets however model perform equally retrain training another dataset dataset suggests hate detection largely independent model architecture model offensive ordinary tend classify hate indicates model fail distinguish hate offensive ordinary susceptible false positive transfer approach pre model tune classification task conduct comparable exceed baseline prior naive adversary attempt circumvent detection model vulnerable adversarial input attack text detection model attack involves input text reader intend meaning detection model misclassify text alteration technique easily automate boundary http  coe int document FS hate eng pdf session AI security adversarial machine aisec october toronto canada append unrelated innocuous implement variety attack detection model vulnerable although extent combine effective attack powerful evasion completely  model severely hinders performance  model addition attack significantly  performance google perspective api assigns toxicity input text summarize contribution experimental comparative analysis theart hate detection model datasets attack effective model mitigation effective evasion completely classifier significantly impact  classifier google perspective review limitation  desideratum future development replication model comparison recent hate detection reproduce systematically analyze performance model datasets focus partially disjoint aspect hate hate religion ethnicity highly   hate datasets drawn twitter properly online text future research focus properly evaluate datasets outside twitter performance pre model datasets propose model datasets model architecture perform comparably training dataset however hate detection highly context dependent transfer poorly across datasets model datasets replicate model respective datasets datasets label summarize additional statistic datasets training model model  proposes machine model hate detection feature extraction model recurrent neural network model lowercase content remove punctuation summarize model datasets discus remainder wikipedia  project target personal attack wikipedia edit comment http  com dataset domain source wikipedia personal attack ordinary twitter hate offensive ordinary twitter hateful offensive ordinary twitter racist  ordinary twitter hateful racist ordinary datasets replication union denotes conflation dataset std min max datasets model dataset source LR char mlp char LR cnn gru lstm replicate machine model logistic regression LR multilayer perceptron mlp model gram feature  gram gram label via crowdsourcing comment label evaluator denote dataset  encode majority vote attack  empirical distribution vote former classification whereas latter interpret probability encode label model perform replication therefore model dataset comment twitter hate offensive non hateful neither knowledge dataset distinction hate data tweet hate label tweet majority vote crowdflower worker denote dataset vast majority http  org session AI security adversarial machine aisec october toronto canada dataset contains offensive portion actual hate logistic regression LR classifier gram replicate mention future involve neural network dnns proven useful text classification task currently dominant approach text classification recurrent neural network rnns memory lstm network apply hate classification alone gradient boost decision  latter lstm training data average embeddings lstm input GBDT report increase performance lstms however unable replicate code lstm therefore lstm alone instead lstm GBDT initialize embed layer randomly data corpus tweet originally label racism  neither combine racism  comprise hateful denote dataset addition lstms convolutional neural network cnns popular text classification research latter cnns rnns output cnn gate  gru network embeddings initialize google vector news data dataset combine offensive ordinary category oppose genuine hate denote dataset dataset hate target refugee muslim denote finally addition replicate distinct cnn gru model model performance replication model apply model datasets replication training hyperparameters model optimize training however additionally model dataset report model perform comparably datasets model roughly equally effective apply text text inferior performance model explain factor dataset highly imbalanced hate training dataset derive corpus http github com  twitter  http github com  wordvec  vector model dataset LR char mlp char cnn gru lstm macro average across  model evaluate dataset datasets bold offensive hate constrain classification category  offensive non hate offensive dominates roughly combine training overlap hate non offensive classification challenge application datasets estimate adaptivity model pre dataset apply model training data apply classifier datasets model training dataset dataset LR char mlp char cnn gru cnn gru cnn gru lstm macro average pre model apply parenthesis report none pre model transfer dataset linguistic hate indicator retain across datasets due lack datasets difference relevant feature subcategories hate offensive hate important distinction drawn hate offensive vocabulary without hateful latter hate dataset lack precise definition hate legal academic context important investigate extent exist approach sensitive hateful offensive distinction concern extent model assign offensive non hateful text hate treat false positive assume hateful offensive distinction session AI security adversarial machine aisec october toronto canada appropriate assumption instance google perspective detect toxic comment toxicity offensive text remains subjective  estimate performance model offensive non hateful text apply offensive datapoints model cnn gru built hence independent task cnn gru model succeed task model perform random random model training dataset assignment non hate LR char mlp char cnn gru cnn gru lstm performance model offensive non hateful additional experimentation reveal cnn gru due prevalence unknown offensive mapped unknown token unk token associate non hateful model average per mapped hence performance simply reflect model vocabulary suggestive problematic subjective hateful context label manually via source guarantee label consistent within datasets address extent majority voting guarantee agreement datasets label model   manual experimentation suggests conclusion concern google perspective perspective non hateful append english  marked actual modify  amaze amaze google perspective toxicity non hateful without curse http  com none hateful curse  variant toxic likelihood clearly toxicity perspective currently classifies  hate substantive legal transfer replicate model classical machine recent neural network dnns recently transfer argue improve performance text classification approach tune pre model task instead training entire model scratch performance datasets improve transfer implement transfer  code author model model pre dataset wikipedia tune dataset tune classifier model refer reader technical detail preliminary  unable baseline replicate model twitter datasets  remain respective baseline however systematic evaluation transfer future research currently summary replication application model perform highly  datasets neither feature model complexity influence significant suggests feature model lstm gru model relatively gram oppose involve complex relation feature ATTACKS adversary model goal adversary fool detection model classify hate input ordinary assume adversary input modify evade detection retain semantic content hate assume adversary whitebox access model parameter adversary model relaxed attack knowledge training classifier rely feature attack malformed input constitute evasion attack evasion attack classifier replicate attack around alter input text easily implementable automatic categorize attack alternative http github com   session AI security adversarial machine aisec october toronto canada insert typo  boundary insert whitespace remove whitespace append append append non hateful differentiate attack target distinct albeit sometimes overlap aspect classifier identity model identity likely become unknown  token denote unk retain readability semantic content text maximal extent reader perspective boundary alter identity structure superficial perspective finally append alteration text unrelated confuse classification theoretical attack effective classifier others tokenization role model susceptible boundary model furthermore model resistant gram retain transformation apply contrast model vulnerable attack alter identity boundary append attack contrast priori model vice versa apply attack classifier transform hate sample respective attack introduce misspelling alternative spelling entirely  model distribution classification google toxicity indicator perspective deceive typo however perspective update author longer succeed extent review proposal worth investigation datasets automatic typo generation addition typo simplify variety  internet slang replace variant involve alteration alteration  easily readable unrecognizable model unless training algorithm insert typo attack typo generation desideratum reduce detection likelihood hate avoid correction automatic checker retain readability meaning text goal met defender checker pre processing stage classification satisfy goal remain recognizable mapped reader mental lexicon attack  fool classifier readable retain interpretation maximal extent cannot simply introduce typo via random instead minimal impact readability utilize empirical cognitive psychology readability maximize understandability restrict alteration switch algorithm switch exclude probability calculate factor closer prefer prefer chosen gaussian distribution hence applicable chosen combine distribution gaussian distribution around previously chosen random non consequently chosen switch typo  transform text  introduce replacement retain readability visual similarity  mitigation improve classifier performance data modify via adversarial training checker pre processing adversarial training augment training stochastically transform version training training purpose adversarial training transform variety model vocabulary likely model associate random typo algorithm limit scalability approach typo becomes contrast deterministic  algorithm adversarial training checker pre processing stage resistant typo introduction algorithm automatic correction python  library boundary tokenization attack differs transformation retain internal introduce remove model token evident choice session AI security adversarial machine aisec october toronto canada algorithm implement algorithm introduce remove whitespace predict removal effective model theoretical  model likely highly susceptible variant insert whitespace model rely tokenizing text sequence treat  therefore unrecognizable tokenization introduce additional separator attack readability become  classifier approach splitting content randomly model previously recognize unk unk remove whitespace conversely remove leaf unk datapoint model performance entirely token classify  contrast lose information related token deteriorate performance likely attack marked negative impact readability allows reader recover content adversary goal message across target effort english rarely  grammatical whitespace distribution ambiguity arise information loss marginal mitigation adversarial training whitespace insertion attack append training randomly split version data model vocabulary training split combination split quickly  explosion hence adversarial training limited analytic completeness conduct adversarial training via removal although useless comment model vocabulary associate encounter comment cannot hence relevance none model model contrast inclusion mostly redundant datapoints comparison remove another mitigation available model remove training data pre processing stage necessity remove remove potentially relevant information data remove entirely effectiveness mitigation depends relevance classification append text classification prevalence data therefore indicative oven another likely classifier assign sample task appropriate hate detection constitutes important exception hate non hate reversible hateful ordinary text hate whereas non hateful hate status vulnerability invite attack non hateful insert hate classification attack model assume adversary aware additional unrelated distract automatic classifier assume additional discourse readability semantic retainment secure algorithm generate random text hate randomly chosen source yield variety attack append english google corpus random exclude stopwords rationale attack knowledge training data attacker english likely training corpus datasets append non hate assume attacker correctly training data non hateful appends text randomly chosen content assume access model RESULTS perform attack model dataset combination replicate prior yield attack adversarial training mitigate attack additional defence typo attack tokenization attack removal training available model attack effectiveness varied  model datasets performance hate classifier significantly decrease attack model affected tokenization model append significant difference  model former completely broken attack whereas latter completely broken model perform comparably across attack training dataset influence attack resilience demonstrate difference cnn gru model respectively however cnn gru resilient attack lstm model choice attack mitigation attack affect datapoints hate report session AI security adversarial machine aisec october toronto canada model DS orig boundary append typo  insert remove non hate SC RW RW LR char mlp char cnn gru cnn gru cnn gru lstm LR hate attack mitigation attack mitigation adversarial training SC checker RW remove whitespace model attack reduce mitigation restore deviation highlight model susceptible  typo whereas difference model addition model vulnerable attack model adversarial training positive performance attack  attack unsurprising deterministic  algorithm determinacy indicates  attack easily mitigate counter algorithm transform correspond boundary neither model affected whitespace insertion attack performance markedly decrease whitespace removal due whitespace involve beginning unlike whitespace remove  gram concern boundary relevant classification model completely broken removal severely hinder whitespace addition adversarial training impact whitespace removal resistance whitespace addition contrast improve baseline overall remove whitespace effective addition model attack avoid adversarial training mitigation model  slightly without conclude remove pre processing training model resistant tokenization attack minor reduction predictive comparable mitigation exists model boundary removal text tokenized unk append unlike attack append affected  comparably non hate training systematically impact english difference minor model difference lstm model non hate almost twice model affected append attack LR model attribute non hate dataset offensive english neither rarely offensive unlikely hate classify data imbalance likely explains negative adversarial training model adversarial training model predictive baseline cnn gru baseline adversarial training dataset drawn combine offensive non offensive ordinary offensive overwhelm majority highly imbalanced therefore adversarial training append associate  readily hate account limited mitigation finally attack combine powerful approach whitespace removal append whitespace removal unk classification entirely dependent model prediction token model behave differently respect hence whitespace removal uncertain remedied strongly indicative non hate effectively model prefer furthermore instead non hateful minimize hindrance readability append text intuitively likely negatively correlate hate hypothesis session AI security adversarial machine aisec october toronto canada model data LR char mlp char cnn gru cnn gru cnn gru lstm LR macro attack remove boundary attack completely model significantly hinder model append performance model decrease append non hateful message relatively easily recover unrelated minimal readability assume separable reader attack highly successful hate classification additionally google perspective reproduce climate differently  stupid warmer enjoy liberal    backward  accept susceptible stupid ignorant stupid vote   anyone vote trump  screw trump supporter introduce manual typo punctuation demonstrate google perspective apply modification toxicity indicates perspective update performs adversarial data nevertheless manage reduce toxicity attack remove boundary perspective upper limit label unlikely toxic discussion evaluate performance hate classifier prior technique roughly equally datasets training dataset however identify deficiency model lack effective transferability across datasets conflation hate offensive ordinary susceptibility text modification attack arise  concept hate across datasets modify google perspective toxicity manual modification report parenthesis offensive inappropriate context attack effective model model effective attack manage completely model severely hinder performance model demonstrate attack ability reduce google perspective toxicity threshold consequence future imply finding transferability false positive model perform datasets classify offensive ordinary hateful manual experimentation google perspective function  curse otherwise benign text drastically increase toxicity indicative related standard truth label likely varied across datasets   racism appropriate comment personal attack vice versa fatal institution target subtypes hate appropriate label available sufficient training data application classification performance model dataset however serious task hate detection undertaken enforcement academic research exception distinction hate generally inappropriate typically google perspective distinguish hate offensive characterize toxicity metric identify rude  unreasonable comment likely discussion hence offensive ordinary constitute false positive boundary false positive http  com session AI security adversarial machine aisec october toronto canada however assume datapoint constitutes genuine false positive allocate hate contains curse offend future therefore recommend discard curse unigram evasion attack model resistant text transformation attack hate classification theoretically surprising knowledge account prior topic removal training minor negative performance mitigates tokenization attack available model overall cnn gru model fare reasonably comparison dnns conclude model instead model effective protection attack nevertheless model susceptible append attack attack built around transformation identity append attack basis advantage fundamental vulnerability classification decision prevalence instead presence status text hateful hateful constitutes majority text irrelevant classification contrast entire decision average principle text classification prediction simply indicative refer distinction classification detection latter consist feature relevant sort regardless prevalence datapoint  hate detection anomaly detection hate constitutes anomalous variant ordinary attack target commonly model architecture text classification generalizable beyond task hate detection attack scenario involve fooling sentiment analysis author anonymization avoid content text classification escape censorship attack concern textual content hence hinder hate detection around meta feature concern user behavior simplicity effectiveness attack focus meta approach instead text classification useful direction future research ethical  replication application freely available online datasets model data none involve code constitutes series attack source however available bona fide researcher facilitate reproducibility related survey hate detection schmidt  categorize feature prior research category feature generalization sentiment analysis lexical resource linguistic feature knowledge feature vii meta information multimodal information focus linguistic feature disregard vii feature gram argue perform gram detect similarity variant generalization traditionally involve cluster assimilate recently embeddings however superiority embeddings gram empirically attest gram perform embeddings hate classification dnns typically embed layer network model lstm cnn gru prior training embed layer initialize randomly initialize pre embeddings wordvec glove model lstm embeddings randomly initialize whereas cnn gru embeddings initialize google embeddings news corpus sentiment analysis incorporate prior filter feature directly hate classification model LR model sentiment textual feature important domain future involves apply attack sentiment classifier broken extent text transformation remain linguistic feature consist traditional craft feature hateful available online append feature aid hate detection alone feature performance weak comparison gram linguistic feature apply hate classification tag dependency relation knowledge approach automatic detect related hate beyond trend within nlp recent shift dnns oppose traditional keyword traditional machine approach building sparse feature gram however attack reconsider useful resistant append attack keyword approach http github com  wordvec  vector extensive currently http  org session AI security adversarial machine aisec october toronto canada vulnerable asymmetry mere presence hate indicative keywords relevant irrespective presence outside hate detection text obfuscation evasion attack conduct avoid spam detection bayesian model append attack similarity attack spam filter spammer injects treat indicative legitimate text filter goal flip model prediction despite attack spam detection analogical hate neglect literature alleviate CONCLUSIONS future replication application model architecture impact classifier performance additionally simplest model LR char perform comparably complex model positive complex architecture minor application demonstrate model complexity improve scalability across datasets instead stem label datasets therefore future focus datasets instead model linguistic feature indicative hate racism  personal attack etc difference hateful merely offensive effectiveness attack indicative vulnerability propose hate classifier machine approach future attack consideration addition mere classification accuracy demonstrate superiority model attack significant application append attack fundamental treat hate detection classification asymmetrical ordinary transform hate hateful hate transform ordinary benign  built classification foundational principle hate detection recommend focus future research seek detection mere classification possibility reintroduce traditional keyword approach hate indicative sought disregard presence absence additionally building adversarial training training data augmentation classification remain resistant append attack approach classifier resistant benign text hate datapoints classifier aspect relevant text belonging hate decrease irrelevant correlation summary recommendation future hate detection focus datasets instead model qualitative understand category umbrella hate model preferable model dnns respect resist evasion text transformation detection vulnerable  invite target presence hate indicative feature remain indifferent feature training data augmentation reduce benign classification