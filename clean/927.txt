neural network machine task unfortunately neural network vulnerable adversarial input target classification input classify apply neural network security critical defensive distillation recently propose approach arbitrary neural network increase robustness reduce rate attack ability adversarial demonstrate defensive distillation significantly increase robustness neural network introduce attack algorithm successful distil  neural network probability attack tailor distance metric previously literature previous adversarial generation algorithm attack effective furthermore propose confidence adversarial transferability defensive distillation attack benchmark future defense attempt neural network resist adversarial introduction neural network become increasingly effective machine task image recognition domain recognize image accuracy recognition processing however researcher discover exist neural network vulnerable attack existence adversarial image classification domain transform image amount thereby image classify amount undetectable attacker adversarial limit domain neural network neural network adversarial attacker unwanted action existence adversarial inspire research harden neural network attack attempt secure neural network fail marginal robustness improvement illustration attack defensively distil network leftmost contains image adversarial generate algorithm respectively image classify correctly label misclassified instance misclassified label mod image chosen defensive distillation recent defense propose harden neural network adversarial initial analysis promising defensive distillation defeat exist attack algorithm reduces probability defensive distillation apply neural network training currently defense security guarantee adversarial approach evaluate robustness neural network attempt bound construct attack demonstrate upper bound former approach substantially implement attempt approximation attack latter approach sufficiently fail upper bound useful attack construct upper bound robustness neural network attack demonstrate defensive distillation actually eliminate adversarial construct attack previously distance metric succeed adversarial image defensively distil network defensive distillation previously publish attack cannot resist powerful attack technique introduce illustrates technique evaluate robustness neural network distillation secure attack fails attack furthermore attack standard unsecured model generate adversarial distortion attack baseline evaluate candidate defense faith defense designer resist attack additionally propose confidence adversarial evaluate robustness defense transferability adversarial model adversarial another model demonstrate adversarial attack transferable unsecured model defensively distil secure model argue defense demonstrate transferability evaluate attack standard datasets mnist digit recognition task cifar image recognition task imagenet image recognition task adversarial technique generate defensively distil network mnist cifar datasets extreme imagenet classification task inception network incorrectly classify image pixel impossible detect visually enable others easily evaluate robustness defense adversarial generation algorithm along code model reproduce available online http  carlini com code robust attack contribution introduce attack distance metric attack significantly effective previous approach attack publish attack target misclassification imagenet dataset apply attack defensive distillation discover distillation security benefit distil network propose confidence adversarial transferability evaluate defense defensive distillation systematically evaluate choice objective function adversarial choice dramatically impact efficacy attack II background threat model machine increase array setting potentially security critical decision drone robot anomaly detection malware classification recognition recognition command nlp consequently understand security become crucial extent construct adversarial influence setting neural network recognition domain recent generate audio machine algorithm user device without knowledge video hidden command smart phone malicious webpage focus conventional technique gaussian mixture model hidden markov model recognition increasingly neural network adversarial becomes relevant domain malware classification existence adversarial limit potential application setting entirely defeat purpose adversary slight modification malware file remain malware become classify benign entirely defeat malware classifier threat introduce earlier unrealistic attack adversarial physical becomes exactly distortion classification domain distance metric image focus rely previous suggests various norm reasonable approximation perceptual distance II information assume adversary access neural network architecture  manner conservative realistic assumption prior substitute model access target model attack substitute model transfer attack target model threat various attempt construct defense increase robustness neural network define easy adversarial input distillation defense secure arbitrary neural network defensive distillation generate adversarial nearly impossible exist attack technique although fails adversarial defensively distil network attack develop construct adversarial neural network notation neural network function accepts input output model implicitly depends model parameter model fix convenience dependence focus neural network classifier output network compute softmax function ensures output vector satisfies output vector treat probability distribution treat probability input classifier assigns label  input label input softmax function logits notation define neural network softmax function output layer softmax logits softmax source neural network typically consists layer softmax  SourceRight click MathML additional feature SourceRight click MathML additional feature non linear activation function matrix model vector model bias model parameter choice tanh sigmoid relu elu focus primarily network relu activation function currently widely activation function image classification primary evaluation domain pixel grey image dimensional vector  denotes intensity pixel rgb image dimensional vector  convert rgb image hsv hsl cylindrical coordinate representation image neural network raw pixel adversarial existence adversarial valid input target input accord distance metric target adversarial powerful attack literature instead asks untargeted adversarial instead classify target input untargeted attack strictly powerful target attack instead approach target target attack average target uniformly random label label perform attack incorrect report target attack perform attack incorrect report target attack evaluation perform attack average classifier accurate attack imagenet approximate attack sample random target efficiency distance metric definition adversarial distance metric quantify similarity widely distance metric literature generate adversarial norm distance norm define source detail distance coordinate distance corresponds pixel alter image argue distance metric primary distance metric defensive distillation security argue distance standard euclidean distance distance remain pixel distance metric initial adversarial distance maximum coordinate max source image maximum budget pixel limit limit pixel modify argue optimal distance metric argue distillation secure distance metric distance metric perfect perceptual similarity pas judgement exactly distance metric optimal construct evaluate distance metric important research future however exist picked distance metric defensive distillation argue security distance metric construct attack perform superior distance metric reporting report distance metric define pixel greyscale image defensive distillation briefly overview defensive distillation description later defensively distill neural network training network identical architecture training data standard manner compute softmax training network replace smooth version softmax logits constant training generate training label evaluate network training instance output label network network training label network instead training training label label model behave model label convey additional hidden knowledge model insight training network hopefully avoid fitting training data neural network exist neural network highly non linear blind adversarial prevent fitting remove blind later defensive distillation remove adversarial potential others argue adversarial exist due blind highly non linear neural network due locally linear neural network linearity hypothesis explanation surprising distillation increase robustness neural network organization remainder structure survey exist attack propose literature generate adversarial distance metric attack algorithm target distance metric superior prior developed attack review defensive distillation detail discus exist attack fail adversarial defensively distil network finally attack defensive distillation algorithm limited attack algorithm BFGS generate adversarial constrain BFGS image image distance label differently classifier model constrain minimization minimize source however instead minimize  sourcewhere loss function mapping image positive loss function entropy perform constant yield adversarial minimum distance repeatedly optimization multiple adaptively update bisection dimensional optimization gradient gradient difference BFGS optimize distance metric primarily instead adversarial image gradient  sourcewhere chosen sufficiently undetectable target label intuitively pixel gradient gradient loss function direction pixel intensity increase decrease minimize loss function shift pixel simultaneously important gradient attack optimal minimal adversarial perturbation iterative gradient introduce refinement gradient instead direction gradient multiple clipped specifically sourceand iteration   SourceRight click MathML additional feature iterative gradient superior gradient JSMA introduce attack optimize distance jacobian saliency attack JSMA brief summary attack algorithm description motivation encourage reader attack greedy algorithm pixel modify increase target classification iteration gradient compute saliency model impact pixel classification indicates significantly increase likelihood model label image target saliency important pixel modify increase likelihood threshold pixel modify attack detectable succeed classification detail define saliency  pixel define      pixel target classification  output algorithm argmax       target likely  become likely   JSMA output layer logits calculation gradient output softmax refer JSMA attack however author apply attack defensively distil network modify attack instead computation output softmax instead logits refer modification JSMA attack image multiple channel rgb attack considers difference channel independently channel pixel norm meaningful threat model attack evaluate model deepfool deepfool untargeted attack technique optimize distance metric efficient closer adversarial BFGS approach earlier author construct deepfool neural network totally linear hyperplane another analytically derive optimal simplify construct adversarial neural network actually linear towards terminates adversarial formulation sophisticated interested reader refer IV experimental setup develop attack algorithm distillation model evaluate attack model architecture mnist cifar model architecture identical defensive distillation II model parameter mnist cifar model parameter identical defensive distillation network mnist cifar classification task pre network imagenet classification task model training approach identical achieve accuracy mnist comparable cifar achieve accuracy identical accuracy distillation mnist cifar model architecture hyperparameters II momentum sgd optimizer training cifar model significantly  training data dropout obtain training entropy loss accuracy validation loss validation accuracy alter network perform image augmentation additional dropout imagenet along mnist cifar relatively datasets imagenet dataset instead training imagenet model pre inception network achieves accuracy probability likely report network inception image dimensional vector approach approach construct adversarial rely initial formulation adversarial formally define adversarial instance image minimize sourcewhere fix goal minimizes image classification valid image distance metric earlier formulate appropriate optimization instance exist optimization algorithm explore formulation empirically identify effective attack objective function formulation exist algorithm directly constraint highly non linear therefore express optimization define objective function choice  maxi softplus maxi maxi softplus maxi SourceRight click MathML additional feature classification max softplus exp loss entropy loss adjust formula constant function respect definition impact minimization function instead formulate  sourcewe alternative formulation minimize sourcewhere suitably chosen constant equivalent exists optimal latter optimal former instantiate distance metric norm becomes solves minimize SourceRight click MathML additional feature sensitivity constant plot distance adversarial compute gradient descent function objective function attack rarely succeed attack becomes effective succeed sensitivity constant plot distance adversarial compute gradient descent function objective function attack rarely succeed attack becomes effective succeed constant empirically gradient descent minimize simultaneously instead optimize verify formulation effective uniformly mnist dataset plot within optimal within optimal optimal refers therefore implementation modify binary constraint ensure modification yield valid image constraint optimization literature constraint previous optimization algorithm BFGS constraint natively investigate approach project gradient descent performs standard gradient descent clip coordinate within approach poorly gradient descent approach complicate update momentum clip actual unexpectedly input iteration algorithm clipped gradient descent clip iteration incorporates clip objective function minimize replace min max min max component wise issue project gradient descent clip introduces algorithm stuck increase component substantially maximum happens partial derivative becomes zero improvement later reduce gradient descent detect variable introduces variable instead optimize variable define apply variable optimize tanh source tanh automatically valid approach smooth clipped gradient descent eliminates stuck extreme optimization algorithm natively constraint adam optimizer almost exclusively effective quickly adversarial solver standard gradient descent gradient descent momentum adam identical quality however adam converges substantially quickly others evaluation approach objective function enforce constraint evaluate quality adversarial evaluation combination objective function constraint encoding average distortion standard deviation probability instance adversarial evaluate random instance successful attack optimal perform iteration binary iteration gradient descent adam optimizer analysis evaluate quality adversarial mnist cifar datasets relative objective function identical datasets brevity report mnist factor difference quality objective function choice handle constraint impact quality significantly minimization function perform objective function entropy loss approach literature previously loss function others gradient descent away initial image however initial gradient descent perform overly greedy manner direction easily reduce ignore loss gradient descent sub optimal loss function constant useful throughout duration gradient descent constant relative importance distance loss fix constant useful relative remain approximately loss function explain discussion analyze adversarial exist valid input adversarial network linearly interpolate mostly linear input adversarial therefore logistic verify empirically construct adversarial image mnist cifar dataset approach pearson correlation coefficient loss function argument gradient descent attack constant sourceor  inverse gradient progress gradient identical around initial image meaning extremely however immediate vicinity initial image gradient increase exponential rate constant gradient descent perform overly greedy manner verify theory empirically attack constant chosen average constant loss function average gradient loss function around valid image closest adversarial loss function perform others discretization model pixel intensity continuous however valid image pixel intensity discrete integer additional requirement capture formulation ignore integrality constraint continuous optimization integer intensity ith pixel becomes slightly degrade quality adversarial restore attack quality perform greedy lattice define discrete pixel greedy fail attack adversary apply mnist dataset perform target attack source target digit image dataset label prior largely ignore integrality constraint instance gradient attack pixel discretization rarely affect rate attack contrast attack image discretization cannot ignore generate valid image reporting rate attack attack discretization processing VI attack attack obtain adversarial distortion metric target solves minimize tanh tanh sourcewith define max max SourceRight click MathML additional feature objective function earlier modify slightly confidence misclassification occurs adjust parameter encourages solver adversarial instance classify confidence attack benefit formulation allows desire confidence adversary apply mnist dataset perform target attack source target digit image dataset label adversary apply mnist dataset perform target attack source target digit image dataset label attack apply mnist model source digit target digit almost attack visually indistinguishable digit comparable cifar appendix attack visually distinguishable baseline image multiple gradient descent gradient descent greedy guaranteed optimal become stuck local minimum remedy multiple random image gradient descent fix iteration randomly sample uniformly radius closest adversarial multiple reduces likelihood gradient descent stuck local minimum attack distance metric non differentiable therefore ill standard gradient descent instead iterative algorithm iteration identifies pixel classifier output fix pixel fix pixel grows iteration elimination identify minimal possibly minimum subset pixel modify generate adversarial iteration attack identify pixel unimportant detail iteration adversary restrict modify pixel return adversary input image adversarial compute gradient objective function evaluate adversarial instance pixel  fix remove intuition reduction obtain ith pixel image reduction obtain per ith pixel ith pixel adversary fails adversarial detail achieve constant adversary adversary fails successful abort exceeds fix threshold JSMA grows empty pixel pixel maximize loss contrast attack shrink pixel pixel algorithm significantly effective JSMA vii evaluation efficient introduce optimization attack mnist cifar substantially imagenet instead gradient descent iteration initial image gradient descent previous iteration dramatically reduces gradient descent iteration pixel constant pixel constant attack apply digit source target target mnist dataset attack visually noticeable imply attack classify interestingly attack visually distinguishable attack comparable cifar appendix attack distance metric fully differentiable standard gradient descent perform naively optimize minimize source however gradient descent penalizes absolute entry impact gradient descent quickly becomes stuck oscillate suboptimal norm penalize zero gradient imposes penalty increase already iteration slightly mirror image gradient descent oscillate forth across nearly impossible progress infty adversary apply mnist dataset perform target attack source target digit image dataset label adversary apply mnist dataset perform target attack source target digit image dataset label resolve issue iterative attack replace objective function penalty exceed decrease iteration prevents oscillation loss penalizes simultaneously specifically iteration minimize source iteration reduce factor otherwise terminate constant adversary approach attack adversary fails successful abort exceeds fix threshold gradient descent iteration algorithm algorithm attack apply digit source target target  dataset difference visually noticeable classify IV comparison variant target attack previous mnist cifar model rate IV comparison variant target attack previous mnist cifar model rate comparison variant target attack previous inception model imagenet rate comparable cifar appendix attack visually distinguishable baseline image vii attack evaluation target attack previously report prior publication distance metric implement deepfool gradient iterative gradient gradient distance generates adversarial failure return target iterative gradient fix return successful JSMA implementation  slight modification improve performance impact accuracy JSMA unable imagenet due inherent significant computational recall JSMA performs pixel target likely likely imagenet image vector pixel calculation remove pixel JSMA dramatically therefore report fail imagenet report attack adversarial target label failure indicates attack entirely unable succeed evaluate image cifar  imagenet report image classify correctly inception imagenet approximate target random IV mnist cifar imagenet target attack mnist digit image totally distance metric target attack mnist digit image totally distance metric target attack mnist digit image totally distance metric distance metric across datasets attack closer adversarial previous attack attack fail adversarial attack adversarial distortion previously publish attack succeed probability attack comparable quality prior rate attack imagenet successful classification image desire label flip pixel impossible detect visually task becomes increasingly previous attack due complexity model contrast attack perform task complexity increase JSMA unable target adversarial imagenet whereas important realize model directly comparable adversary pixel switch imagenet classification mnist classification imagenet pixel pixel significantly generate synthetic digit target adversary image adversarial target minimum perturbation entirely image classify digit distance metric perform task previously however attack clearly recognize target digit powerful attack none digit recognizable performs analysis image image become digit classify image become initial image already runtime analysis runtime performance adversarial generation algorithm important understand performance prohibitive adversary actually attack inner loop adversarial training runtime attack mislead parallelize implementation adversary attack simultaneously gpu increase performance however parallelize attack similarly implementation gradient parallelize JSMA therefore refrain performance unfair comparison comparison attack previous attack plenty efficient adversary attack longer instance attack optimize JSMA algorithm significantly faster optimize version attack typically previous attack exception iterative gradient evaluate defensive distillation distillation propose approach reduce model teacher distil model distillation training teacher model training standard manner teacher label instance training label output vector teacher network label image digit classify label distil model label teacher label training distillation potentially increase accuracy rate model learns predict label defensive distillation distillation increase robustness neural network significant teacher model distil model identical defensive distillation model importantly defensive distillation distillation described distil model become confident prediction recall softmax function layer neural network defensive distillation modifies softmax function constant softmax exi  source easy softmax softmax intuitively increase softer maximum decrease harder maximum limit softmax approach max limit infinity softmax approach uniform distribution defensive distillation proceeds network teacher network softmax training phase compute label apply teacher network instance training evaluate softmax distil network network teacher network label softmax finally distil network classify input fragility exist attack briefly investigate exist attack fail distil network exist attack fragile easily fail adversarial exist BFGS deepfool fail due gradient zero almost prohibits standard objective function distil network effectively input softmax become factor minimize entropy training output softmax others distil network otherwise positive become negative factor become negative experimentally verify norm logits  network standard deviation distil network standard deviation output becomes component output confidence task float gradient becomes express float BFGS minimization procedure fail progress terminate instead BFGS stable objective function identify earlier objective function loss BFGS fail alternate approach fix attack softmax sourcewhere distillation chosen minimize loss fail gradient vanish due float arithmetic clearly demonstrates fragility loss function objective minimize JSMA whereby attack output layer fails BFGS fails output layer softmax becomes essentially maximum version attack attack defensive distillation JSMA attack logits fails completely recall version attack input softmax compute gradient instead output network remove potential issue gradient vanish however introduces issue version attack introduce attack distillation analysis fails attack important realize difference relative impact input softmax layer softmax layer correspond output becomes practically zero input output practically zero however input softmax layer massive impact softmax output relate parameter attack input softmax layer surprising JSMA  network treat importance regardless softmax output pixel increase target increase likely attack increase pixel recall distillation logits magnifies suboptimality logits extremely unlikely slight variation attack refuse gradient fails BFGS fails gradient almost zero however something happens attempt trick logits softmax function distillation remains effective unable explain phenomenon apply attack defensively distil network distillation marginal implement defensive distillation mnist cifar described model evaluation distil model effective apply attack VI attack apply distillation previous attack fail adversarial contrast attack succeed probability distance metric IV distillation almost attack perform slightly attack performs approximately equally attack succeed increase consistently reduce attack rate mnist rate rate finally distance target random target adversarial distillation mnist uncorrelated adversarial distance VI comparison attack apply defensively distil network IV  network implement improve attack understand choice impact robustness model varied implementation JSMA attack rapidly decrease however improve attack distance adversarial correlation coefficient clearly demonstrates increase distillation increase robustness neural network exist attack fail transferability recent adversarial model transfer adversarial model training data entirely algorithm adversarial neural network transfer random probability adversarial transfer model another target adversarial remains untargeted image probability adversarial transfer model another target adversarial remains untargeted image therefore defense robustness adversarial somehow transferability otherwise attack algorithm easy attack model transfer adversarial attack model defensive distillation robust attack demonstrate distillation transfer attack standard model defensively distil model accomplish confidence adversarial define adversarial strongly misclassified model instead adversarial barely classification source target target likely label recall loss function define earlier attack max max SourceRight click MathML additional feature purpose parameter strength adversarial classification adversarial allows generate confidence adversarial increase probability adversarial transfer baseline model model defensive distillation probability adversarial transfer baseline model model defensive distillation investigate hypothesis classification model likely transfer baseline model mnist described IV model training data transferability rate increase linearly plateau clearly increase increase probability successful transferable attack instead model defensive distillation adversarial transfer another attack technique adversarial distil network however interestingly transferability rate unsecured model distil model comparison previous approach approach evaluate robustness defense defense completely gradient gradient descent approach succeed IX conclusion existence adversarial limit apply construct defense robust adversarial attempt defensive distillation propose purpose procedure increase robustness arbitrary neural network propose powerful attack defeat defensive distillation demonstrate attack generally evaluate efficacy potential defense systematically evaluate attack approach consistently adversarial exist approach evaluation basis attack encourage defense perform evaluation approach powerful attack propose evaluate robustness secure model directly defense prevents attack prevent attack defender establish robustness distance metric demonstrate transferability fails construct confidence adversarial unsecured model fail transfer secure model