We define a generalization of the classical secretary problem called the matroid secretary problem. In this
problem, the elements of a matroid are presented to an online algorithm in uniformly random order. When
an element arrives, the algorithm observes its value and must make an irrevocable decision whether or not
to accept it. The accepted elements must form an independent set, and the objective is to maximize the combined value of these elements. We present an O(log k)-competitive algorithm for general matroids (where k
is the rank of the matroid), and constant-competitive algorithms for several special cases including graphic
matroids, truncated partition matroids, and bounded degree transversal matroids. We leave as an open question the existence of constant-competitive algorithms for general matroids. Our results have applications in
welfare-maximizing online mechanism design for domains in which the sets of simultaneously satisfiable
agents form a matroid.
Categories and Subject Descriptors: F.2.2 [Theory of Computation]: Analysis of Algorithms and Problem
Complexity—Nonnumerical Algorithms and Problems
General Terms: Algorithms, Theory
Additional Key Words and Phrases: Secretary problem, matroids, online algorithms, mechanism design, competitive ratio
1 INTRODUCTION
Decision makers frequently have to make irrevocable sequential decisions without complete
knowledge of the options that will be available to them in the future. Often, a decision in the
present will restrict options available in the future. Consider, for example, a firm looking to hire
multiple new employees over a long stretch of time. As candidates are interviewed, decisions on
whether to hire them must be made within a short time frame, often without knowledge of future
applicants. The problem is further complicated by the fact that in addition to a simple constraint
on the total number of hires, there may be further constraints such as upper bounds on the number
of candidates with particular expertise.
Problems such as these are naturally modeled in an online setting in which elements (corresponding to candidates) arrive one by one, revealing their weight (corresponding to their quality)
at the time of arrival. At this point, an algorithm (filling the role of the hiring manager of the firm)
must make an irrevocable decision whether or not to select the present element without knowledge
of the weights of elements arriving in the future. The algorithm is c-competitive if the expected
weight of its final selection is at least a (1/c)-fraction of the weight of the optimal selection.
Unfortunately, even in the simplest version of this problem—pick any one element—without
additional assumptions, no algorithm can provide non-trivial guarantees on the weight of the
element picked. While it is possible to obtain positive results by restricting elements’ weights, a
natural alternative is to allow for adversarially assigned weights, but to assume that the elements
arrive in uniformly random order. This problem was introduced by Dynkin (1963) and termed the
secretary problem; Dynkin showed that there is an algorithm that picks the best element with
probability 1/e (and, hence, is e-competitive), and that this is essentially optimal.
In the present article, we study generalizations of the secretary problem in which the algorithm
may select multiple elements, and there are combinatorial constraints on the sets of elements
that can be selected together. The goal is to pick a feasible set of maximum combined weight.
Despite the rich prior literature on generalizations of secretary problems (see Freeman (1983) for
a survey), the conference version of our work appears to have been the first work on multiplechoice secretary problems in which there is a non-trivial combinatorial structure constraining the
sets that may be simultaneously selected.
We focus our attention on settings in which the combinatorial constraints on feasible sets describe the independent sets of a matroid1 and call the resulting problem the matroid secretary
problem. In this problem, elements of a matroid, whose ground set size is known, are presented to
an online algorithm in uniformly random order; the algorithm has oracle access to the independent
sets of elements seen so far.2 Whenever an element arrives and reveals its weight, the algorithm
must make an irrevocable decision whether or not to select the element with the constraint that
throughout the process, the set of selected elements must be an independent set in the underlying
matroid. The objective is to maximize the combined value of the selected elements. A detailed presentation of the model is given in Section 3. This general formulation contains many practically
important special cases:
—The simplest generalization of the classic secretary problem is the multiple-choice secretary problem, originally introduced by Kleinberg (2005). In the multiple-choice secretary
problem, the algorithm can pick any set of at most k elements. The corresponding matroid
is the uniform matroid of rank k. For k = 1, this is the classical secretary problem.
—Our introductory example can be modeled as a truncated partition matroid. In a truncated
partition matroid, the universe is partitioned into disjoint sets, e.g., different expertise, and
for each such set, there is an upper bound on the number of elements that can be selected.
In addition, there is an upper bound on the total number of selected elements.
1A matroid (U, I) is constructed from a non-empty ground set U and a non-empty family I of subsets of U, called the
independentsubsets of U. I must be downward-closed (if B ∈ I and A ⊆ B, then A ∈ I) and satisfy the exchange property
(if A, B ∈ I and |A| < |B |, then there is some element x ∈ B \ A such that A ∪ {x }∈I). A maximal-size independent
set is called a basis. By the matroid properties, every basis has the same size. The rank of the matroid is the size of any
basis.
2While our algorithm for general matroids works with such oracle access, our improved algorithms for transversal and
graphical matroids must be given the matroid explicitly in advance. Solving the problem for these two families of matroids
with only oracle access is left as an open question.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
Matroid Secretary Problems 35:3
—Another class naturally occurring in the context of online selection is transversal matroids.
Elements are the nodes on the left side of a bipartite graph, and subsets of nodes can be
selected if and only if they can be simultaneously matched. This class of matroids naturally
fits applications in which arriving customers must be matched online to available resources
subject to constraints on which resources satisfy a given customer.
—A more abstract example is graphic matroids. In such a matroid, the elements are the edges
of a graph, and a set of edges can be selected if and only if it contains no cycle.
In this article, we design and analyze algorithms for various classes of matroids. For the most
general case of arbitrary matroids, in Section 4, we present an O(log k)-competitive algorithm. For
the special cases of transversal matroids with bounded left degree and graphic matroids, we design
constant-competitive algorithms, in Sections 6 and 7, respectively. We also present, in Section 8, a
general result showing that a constant-competitive algorithm for a matroid can be used to obtain a
constant-competitive algorithm for any truncation of the matroid, obtained by introducing an additional constraint on the maximum size of an independent set. Finally, for the case of uniform matroids, we obtain even tighter bounds: in Section 5, we give an e-competitive algorithm for arbitrary
uniform matroids (matching the guarantee of Dynkin (1963) for the uniform matroid of rank 1).
We leave open the question of whether there is a constant-competitive secretary algorithm for
general matroids. Some discussion of this issue is presented in Section 4.
Online Mechanism Design
Generalized secretary problems, as defined and discussed in this article, naturally form the basis
of mechanisms in online mechanism design settings. Online mechanism design is motivated by
markets in which agents arrive and depart over time, and decisions about the allocation of items
or the selection of agents must be made on the fly. Online mechanism design is made difficult by
a combination of two factors:
Informational constraints. As with the design of online algorithms, the mechanism has to
make irrevocable decisions without knowing the future, usually resulting in suboptimal
decisions.
Indeed, even for the simplest imaginable online mechanism design problem—a single-item
auction—the corresponding algorithmic problem (selecting the maximum element from a
worst-case sequence) has no non-trivial online approximation algorithm due to its online
constraints.
Incentive constraints. At the heart of essentially all work on mechanism design lies the
concern that, generally, incentives for individuals may not align with the goals of the
mechanism, so that individuals will misrepresent their actual weight (or other relevant
data) upon arrival. In particular, since an online algorithm will usually not be able to
achieve the optimum value of its objective function, one of the most frequently used
approaches—the Vickrey-Clarke-Groves (VCG) paradigm—cannot be used for designing
truthful mechanisms.
In fact, it has been shown that even for a simple expiring-goods model where constantcompetitive allocation rules exist, there is no truthful online mechanism achieving a nontrivial approximation to the optimum social welfare (Lavi and Nisan 2005).
Due to the interplay between the two types of constraints, in general, progress toward proving
positive theoretical results in the online setting has been considerably slower than in the offline
setting.
Fortunately, these constraints are considerably less severe when the agents arrive in uniformly
random order. For example, as we discussed earlier, the algorithmic problem corresponding to the
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
35:4 M. Babaioff et al.
single-item auction corresponds to the standard secretary problem (Dynkin 1963), for which an
e-approximate online algorithm exists.
Hence, generalized secretary algorithms naturally serve as points of departure for designing
mechanisms in the following broad subclass of online mechanism design (Hajiaghayi et al. 2004;
Kleinberg 2005): items/agents arrive in an online fashion in uniformly random order, and the mechanism would like to select a feasible subset with the goal of (approximately) maximizing welfare.3
The mechanisms should be truthful in the sense that agents have no incentive to lie about their
weight.
A prominent example for such settings are unit-demand preference domains4 in which agents
have unit demand, are indifferent between a subset of goods, and are unsatisfied by the remaining
goods. Such domains correspond to transversal matroids (discussed above). More generally, in
order to make the connection between secretary algorithms and online mechanism design explicit,
we define a notion of matroid domains, a special case of single-value domains (Babaioff et al. 2005),
which themselves generalize single-minded combinatorial auctions (Lehmann et al. 2002; Mu’alem
and Nisan 2002). In matroid domains, there is a set of outcomes, and each agent is characterized
by a set of satisfying outcomes and a value for receiving one of these outcomes. For every profile
of types, the sets of agents who can be simultaneously satisfied constitute a matroid. For each of
the algorithmic results described above, we provide an accompanying truthful mechanism for the
corresponding matroid domain.
2 WORK PUBLISHED SINCE THE CONFERENCE VERSION
The original publication of the conference versions of the present article (Babaioff et al. 2007a,
2007b) has inspired a large amount of follow-up research, and many of our results have been improved in follow-up papers. In 2013, Dinitz (2013) published a survey of the recent advances on the
matroid secretary problem. We summarize papers discussed therein among others in this section.
Our most general result is an algorithm which is O(log k)-competitive for any matroid, where k
is the matroid rank. Chakraborty and Lachish (2012) were the first to improve our result, presenting
an O(

log k)-competitive algorithm. Later, Lachish (2014) presented an O(log log k)-competitive
algorithm, an exponentially better bound. A considerably simpler algorithm, with the same asymptotic competitive ratio (but better constants) was then presented by Feldman et al. (2015). Our main
open problem—whether there exists a constant competitive algorithm for this problem—remains
open.
In this article, we also present constant-competitive algorithms for several specific classes of
matroids, including graphic matroids and transversal matroids of bounded degree. A follow-up
paper by Dimitrov and Plaxton (2012) gives a 16-competitive algorithm for transversal matroids
without the bounded-degree restriction. That result was simplified and extended by Korula and Pál
(2009), who, among other results, present an 8-competitive algorithm for transversal matroids, and
a 2e-competitive algorithm for graphic matroids. The competitive ratio for transversal matroids
was ultimately improved to e by Kesselheim et al. (2013); this ratio is best possible as it matches the
lower bound for the classical secretary problem. Im and Wang (2011) give a constant-competitive
algorithm for laminar matroids; the (large) constant was improved to 3√
3e ≈ 14.12 by Jaillet et al.
(2013) and to 9.6 by Ma et al. (2016). Dinitz and Kortsarz (2014) have presented constant competitive
algorithms for regular matroids (the class of matroids that are representable over every field) and
for decomposable matroids.
3Another commonly studied objective is maximizing revenue.
4We consider a restricted class of unit-demand domains in which each agent is a “single-value agent:” in such a domain,
each agent has the same value for all items he desires. That is, the agent has the same value for any two items for which
his valuation is non-zero.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018. 
Matroid Secretary Problems 35:5
One of the variants of the matroid secretary problem that we discuss in this article is the random
assignment model, in which a hidden list of adversarially chosen weights is randomly assigned to
the matroid ground set, independently of the random order in which they are revealed to the
algorithm. Soto (2013) presents a constant competitive algorithm for this problem. Oveis Gharan
and Vondrák (2011) strengthen that result to the case when the weights are randomly assigned
but the order is adversarial. They also present a nice systematic classification of variants of the
problem, including, for example, several results for the case when the matroid structure is not
known in advance. Jaillet et al. (2013) presented a constant competitive algorithm for another
variant, the free order model, in which weights are adversarial but one can choose the order in
which secretaries are interviewed.
Several papers (Gupta et al. 2010; Bateni et al. 2010; Feldman et al. 2011; Feldman and Zenklusen
2015; Ma et al. 2016; Kesselheim and Tönnis 2016) study variants of the matroid secretary problem
in which the value of the set of elements is determined by some submodular function (instead
of just being additive, as in our article). Rubinstein and Singla (2017) considered an even more
challenging problem, aiming to maximize a monotone subadditive objective function subject to an
arbitrary downward-closed feasibility constraint.
Feldman et al. (2011) show that one can simplify the analysis of many secretary algorithms by
assuming that the random order of the input is generated by independently choosing a random
continuous arrival time for each secretary.
Some other papers extend the classical secretary problem in other dimensions. For example,
Kumar et al. (2011) consider the problem of hiring a secretary from a partially ordered set. Feldman
and Tennenholtz (2012) consider the problem of interviewing secretaries in parallel. Buchbinder
et al. (2010) show how linear programming can help solve some variants of the classic problem
as well as some variants that require choosing multiple elements. Vardi (2015) considers a variant
in which every secretary appears in the sequence twice. Kesselheim et al. (2015) studied secretary problems with non-uniform arrival order. Motivated by firms competing to hire workers,
Immorlica et al. (2006) studied a setting in which there are multiple competing algorithms selecting from the same ground set of elements. Barman et al. (2012) considered secretary problems in
which the “profit” of a set is its total value minus a convex cost function of its total size.
A closely related problem to the matroid secretary problem is that of matroid prophet inequalities. In that problem, elements of a matroid appear in an adversarial order, each sampled independently from a known distribution, and an online algorithm needs to pick an independent set.
Kleinberg and Weinberg (2012) have presented a 2-competitive algorithm for that problem.
3 MODEL
3.1 The Matroid Secretary Problem
In the matroid secretary problem, there is a weighted matroid with a ground set U of size5 n ≥ 2, a
family of independent sets I, and a weight function w : U → IR≥0 assigning a non-negative real
weight w(i) to each element i ∈ U. The weight of a set S is defined to be the sum of weights of all
elements in S. Note that this is a generalization of the classical secretary problem introduced by
Dynkin (1963), in which the independent sets are precisely the sets of singletons (i.e., the matroid
is the uniform matroid of rank 1).
We wish to design an algorithm which, given the number n of elements in the ground set, and oracle access to the matroid’s structure (U, I), selects online an independent set of (approximately)
maximal weight in the following setting: The ground set of the matroid is presented in random
5The case that the size of the ground set is 1 is trivial.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
35:6 M. Babaioff et al.
order to the online algorithm. The algorithm maintains a set S of selected elements. When an element i arrives, the algorithm learns the weight w(i) of the element. If S ∪ {i} is an independent
set, the algorithm may choose whether to select i (i.e., S := S ∪ {i}); otherwise, it has to discard i.
Crucially, the algorithm must decide whether to select an element before the next element arrives,
and it is not allowed to later discard selected elements or go back and pick discarded elements.
The oracle can answer queries whether a given set S	 ⊆ U belongs to I; the set S	 must be a
subset of the elements seen so far. The goal of the algorithm is to output a final selected set S of
maximum weight. If the expected weight of the selected set (over a uniformly random ordering
of the elements) is always (i.e., for any assignment of weights to the ground set) within a factor
c of the weight of the maximum weight basis, we say that the algorithm is c-competitive or a
c-approximation. An easier problem, which we call the known matroid secretary problem, is the
variant in which the matroid structure is given to the algorithm in advance. Some of our improved
algorithms for specific matroids are for this variant.
We call such an algorithm a matroid secretary algorithm; it solves the matroid secretary problem.
Although we chose not to specify computational efficiency as part of our definition, it is worth
noting that all algorithms presented in this article have running time polynomial in n, the number
of elements in the ground set U, when given a suitable succinct representation of the matroid, or
oracle access to the family of independent sets (which is potentially exponential).
The following are some matroids that we discuss in this article.
uniform matroid of rank k. A matroid (U, I) whose independent sets I are all subsets
S ⊆ U of cardinality at most k (i.e., |S | ≤ k).
transversal matroid. A matroid (U, I) whose ground set U is the set of left-hand side nodes
in a bipartite graph. A subset is an independent set if there exists a matching that matches
that subset to a set of nodes on the right-hand side of the bipartite graph.
gammoids. A matroid (U, I) whose ground set U corresponds to source nodes in a graph,
all of which wish to be routed to a common sink. A subset S of sources is independent if
there exist internally vertex-disjoint paths routing each source in S to the sink.
graphic matroids. A matroid (U, I) whose ground set U corresponds to the edges of an
undirected graph. A set of edges is independent if it does not contain a cycle.
partition matroids. A matroid (U, I) whose ground set U is partitioned into blocks {Bi},
together with an upper-bound di for each block Bi . A subset is independent if it contains at
most di elements from block Bi .
truncated partition matroids. A matroid obtained from a partition matroid after removing
all independent sets with more than k elements.
Throughout this article, we make the simplifying assumption of well-behaved inputs, meaning that elements of the matroid have distinct weights unless their weight is 0, and there is a
unique maximum-weight independent set. This assumption is essentially without loss of generality, because any algorithm that achieves competitive ratio c on well-behaved inputs can be easily
transformed into an algorithm that is (1 + ε)c-competitive on all inputs by the following simple
reduction.
Each time an element x is observed, the algorithm multiplies its weight w(x) by a random real
number uniformly distributed in [1, 1 + ε], to obtain its modified weight wˆ (x). The modified input
is well-behaved with probability 1. With S denoting the set of elements selected by the algorithm,
we have
(1 + ε)c · w(S) ≥ c · wˆ (S) ≥ wˆ (OPT) ≥ w(OPT),
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
Matroid Secretary Problems 35:7
where OPT denotes a maximum-weight independent set with respect to the original values. The
second inequality follows from our hypothesis that the original algorithm was c-competitive on
well-behaved inputs.
3.2 Mechanism Design Considerations
The matroid secretary problem can be used to design online mechanisms for matroid preference
domains, a special case of single-value preference domains. In single-value preference domains, there
is a set U of n agents and a set Ω of possible outcomes. Each agent i has a positive value vi ∈ IR>0
and a satisfying set Ai ⊆ Ω of outcomes such that agent i obtains value vi from outcomes in Ai
and value 0 from outcomes in Ω \ Ai . We will occasionally use Xi : Ω → {0, 1} as an indicator
function for the set Ai (i.e., Xi (ω) = 1 if and only if ω ∈ Ai ). An agent’s type in general is his
private information (i.e., the information available only to him.) Specifically, in the context of
matroid preference domains, we assume that the agent’s type6 is his value vi . A profile of types
consists of a type for each of the agents. A set of agents S ⊆ U isindependent if there is an outcome
ω ∈ Ω that satisfies exactly the agents in S (i.e., Xi (ω) = 1 if and only if i ∈ S).
A single-value preference domain is a matroid domain if for any profile of types, the family of
independent sets of agents form a matroid over the set U of all agents. Similarly, given a matroid,
it is possible to define the corresponding matroid domain where the agents are the ground set
of the matroid, the satisfying outcomes for an agent are the independent sets that include the
corresponding element, and the value vi of an agent i is the weight w(i) of the corresponding
element i in the matroid.
Matroid domains are of particular economic interest. For example, transversal matroids correspond to preference domains in which agents have unit demand, are indifferent between a subset of
goods, and are unsatisfied by the remaining goods; such preferences would occur naturally when
allocating offices in a new office building to agents with preferences of the form “I want to work
on the first floor” or “I want a south-facing window.” Some examples of matroid domains include:
Selling k identical items. There are n agents and k identical items. Each agent wants to buy a
single item, and agent i has a value of vi if he gets an item. An outcome is a set S of at most
k agents (winners), such that each agent in S receives an item. The underlying matroid of
the preference domain is then the uniform matroid of rank k.
Selling k non-identical items. There are n agents and a set M of m non-identical items. Each
agent wants to buy one specific item in M (and is not satisfied by any other item in M), but
the seller can only produce and sell k ≤ m items. The underlying matroid of the preference
domain is then a truncated partition matroid of rank k.
Unit-demand domain. There are n agents and a set M of m non-identical items. Each agent
i has a set Ti ⊆ M of desired items, that is, agent i has a value of vi if he gets an item j ∈ Ti .
An outcome is a one-to-one matching of agents to items. The underlying matroid of the
preference domain is then the transversal matroid.
7
6The domain described here is called the known single-value domain, because the set Ai of desired outcomes for agent i
is assumed to be common knowledge, and the only private information of an agent is his value. In a known single-value
domain, agents are single-parameter and truthfulness is well understood. (See the discussion at the end of this section.)
One can also consider single-value agents that have additional private information about their preferences. Such domains
are known as unknown single-value domains. We discuss such a domain in Section 6. 7As noted in Footnote 6, a distinction can be made based on whether the set Ti of desired items for agent i is private
knowledge. The algorithms we develop for this domain are truthful regardless of this distinction. See Section 6 for further
discussion.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
35:8 M. Babaioff et al.
Matroid preference domains impose constraints on an algorithm as follows. Agents arrive in
uniformly random order. When an agent arrives, he announces a value v	
i . The mechanism then
must commit either to choosing an outcome ω ∈ Ai or to choosing an outcome ω  Ai ; in addition,
the mechanism commits to a price pi . After all agents have arrived, the mechanism chooses a final
outcomeω, which satisfies all prior commitments. Alternatively, one could describe the mechanism
as choosing online an independent set S of agents and a price pi for each agent i ∈ U.
We wish to design mechanisms that are truthful (each agent maximizes his utilityvi · Xi (ω) − pi
by announcing his true value vi for any declaration of the others and any random permutation of
the agents) and maximize the social welfare (i.e., the final outcome ω maximizes the sum
i ∈N vi ·
Xi (ω)). Perfectly maximizing the welfare with a truthful mechanism is typically impossible in
online settings. Instead, our mechanisms will approximately maximize the social welfare while
remaining truthful. We say that a mechanism is c-competitive or a c-approximation if for every
profile of types, the expected social welfare of the selected outcome is within a factor of c of the
maximum social welfare.
Typically (and in all cases considered in this article), a c-competitive algorithm for the matroid
secretary problem implies a c-competitive online mechanism for the corresponding matroid preference domain. The reason is as follows. In all cases we consider, the only private information
of an agent is his value when “winning,” i.e., his value when the outcome is in his satisfying set.
Therefore, all such domains are single-parameter domains. In single-parameter domains, truthfulness has the following well-known simple characterization: a mechanism is truthful if and only if
for each player, there is a price (threshold)8 that is independent of the agent’s own report, such
that the player wins and pays that price whenever his value exceeds that price, and loses and pays
0 when it is smaller than the price.9 (When the value equals the price, he can either win or lose.)
For example, the classic algorithm for the original secretary problem samples a prefix of the agents
(so the threshold for them is infinity) and then sets a price equal to the highest sampled value. The
first agent after the sample who beats that price wins and pays that price; the remaining agents
face an infinite price. Therefore, the mechanism derived from the classic secretary algorithm is
truthful.
4 AN ALGORITHM FOR GENERAL MATROID DOMAINS
Our work in this article focuses on matroid domains. Intuitively, matroid domains are more likely
to be tractable than general set systems; for example, in the offline setting, a simple greedy algorithm is guaranteed to find the welfare-maximizing solution (i.e., the maximum weight basis). We
conjecture that any matroid domain has a constant competitive algorithm.
Question 4.1. Is there an algorithm that is constant competitive for every matroid domain?
This question is currently still open, even for the case in which the matroid is known, e.g., explicitly given to the algorithm as a (possibly exponentially sized) set system. Our improved algorithms
for specific matroids, as well as subsequent papers, make progress on the known matroid case.
It can be shown (see Appendix A) that several natural algorithms fail to be constant competitive. For example, it is impossible to achieve a constant competitive ratio using any algorithm that
8possibly infinity.
9The term “truthful” is formally defined only for direct-revelation mechanisms in which agents’ strategies are to report
their type. In that context, truthfulness means that it is a dominant strategy for them to report their type truthfully. We
slightly abuse the term “truthful” to also include non-direct mechanisms, which can be easily simulated by truthful direct
mechanisms. Specifically, if a buyer faces a price that is independent of his value and he buys (wins) when it is in his best
interest to buy (i.e., whenever the price is at most his value), a truthful direct-revelation mechanism could have simulated
this behavior on the agent’s behalf.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.  
Matroid Secretary Problems 35:9
observes elements until it reaches a (possibly random) stopping time τ , sets a threshold weight at
time τ , and selects every subsequent element, which is independent of the previous selections and
exceeds the threshold weight. Another intuitively natural algorithm observes a constant fraction
of the elements (the “sample”) without making any selections. Afterward, it keeps track of an independent set, which is initially a maximum-weight independent subset of the sample. Whenever
it is possible to improve the weight of the independent set by incorporating the current element
(and possibly swapping out one of the elements of the sample), the algorithm selects the current
element and incorporates it into the independent set. This algorithm, too, fails to be constant competitive, although we show in Section 5 that it is e-competitive for uniform matroids.
While our conjecture is about a decade old, it is still open. This article presents a series of
constant competitive algorithms for specific matroid domains, supporting an affirmative answer.
(We also believe that these results are interesting in their own right.) Moreover, as discussed in
detail in Section 2, several follow-up results have improved many of our guarantees, and thereby
lend additional support to an affirmative answer. In particular, our O(log k) competitive algorithm
for arbitrary matroids was improved to O(

log k) by Chakraborty and Lachish (2012) and later to
O(log log k) by Lachish (2014).
Several other follow-up results further indicate that the answer to the open problem might be
positive. Soto (2013) presented a constant competitive algorithm for the relaxed model in which the
weights are adversarially chosen, but then assigned randomly to the elements. Oveis Gharan and
Vondrák (2011) strengthened that result to the case when the weights are randomly assigned to the
elements, but the arrival order of elements is adversarial. Jaillet et al. (2013) presented a constant
competitive algorithm for the free order model, in which weights are assigned adversarially, but
the algorithm gets to pick the order in which the elements arrive. Kleinberg and Weinberg (2012)
presented a 2-competitive algorithm for the closely related matroid prophet inequalities problem,
in which an online algorithm needs to pick an independent set of a matroid from a sequence of elements that appear in an adversarial order, each sampled independently from a known distribution.
An additional indication for the existence of a constant competitive general algorithm is the fact
that we obtain constant-factor approximations for several special cases of the matroid secretary
problem; constant competitive algorithms for other special cases have been obtained in follow-up
work by other researchers, as surveyed in Section 2.
We next turn to present our results. First, we observe that the assumption of matroid domains
is essential. Namely, for some downward-closed set systems, there is no constant-competitive algorithm. (In a matroid, choosing one suboptimal element can exclude at most one element of the
maximum-weight basis from being selected in the future. In general set systems, this property does
not hold; a single early mistake can exclude a large number of elements of the optimum from being
selected afterward.) Next, we show that there is an algorithm that is logarithmically competitive
for any matroid domain. Later sections present improved algorithms with constant competitive
ratios for specific matroid domains of particular economic or combinatorial interest.
4.1 A Lower Bound for General Downward-closed Set Systems
We begin with a construction of downward-closed set systems with weights in {0, 1} for which
there is no constant competitive secretary algorithm.
Theorem 4.2. There does not exist a randomized online algorithm that, for every downwardclosed set system with n elements and weights in {0, 1}, obtains a competitive ratio lower than
Ω(logn/ log logn).
The theorem follows directly from the following construction and Lemma 4.3.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018. 
35:10 M. Babaioff et al.
For an integer n, let k = ln(n), and let (U, I) be the set system defined as follows. U consists
of n elements partitioned into m = n/k subsets S1,..., Sm, each having k or k − 1 elements. A
set A ⊆ U belongs to I if and only if it is contained in one of the pieces of the partition, i.e., A ⊆ Si
for some i. We assign independent random weights in {0, 1} to the elements of U such that for
each x, w(x) = 1 with probability 1/k and w(x) = 0 with probability 1 − 1/k.
Lemma 4.3. The expected weight of the maximum-weight set in I is Ω(logn/ log logn). For any
randomized online algorithm that selects a set in I, the expected weight of the set selected when the
elements are presented to the algorithm in random order is less than 2.
Proof. Suppose that the algorithm makes its first selection at time t, and that it chooses an
element x ∈ Si . All future selections must be elements of Si . Let Ti be the subset of Si consisting
of elements that have not yet been observed at time t. The weights of the elements of Ti are
independent of all the information observed up to time t. As there are fewer than k elements in
Ti , and each of them has expected weight 1/k, the expected combined weight of all elements in
Ti is less than 1. Hence, including the element x, the expected weight of the set selected by the
algorithm is less than 2.
The proof that the expected weight of the maximum-weight set in I is Ω(logn/ log logn) is a
standard balls-in-bins calculation (Motwani and Raghavan 1995); we include it here to make the
exposition self-contained. Let j = k/(2 ln(k)), and let Ei denote the event that at least j elements
of Si have weight 1. The probability of Ei is at least (1/k)j ≥ (1/ lnn)
ln n/2 ln ln n = 1/
√
n. Since the
events Ei are independent for i = 1, 2,...,m, the probability that none of them occur is at most
(1 − 1/
√
n)
m = o(1). If at least one event Ei occurs, then the maximum-weight independent set in
I has weight at least j = Ω(logn/ log logn).
It was recently shown that this lower bound is almost tight when weights are in {0, 1}: Rubinstein
(2016) presented anO(logn)-competitive algorithm for downward-closed set systems with weights
in {0, 1}. For general weights, he presented an O(logn log r)-competitive algorithm, where r is
the cardinality of the largest feasible set. Recently, Rubinstein and Singla (2017) have obtained
an O(logn · log2 r)-competitive algorithm for the secretary problem with a monotone subadditive
objective function subject to an arbitrary downward-closed feasibility constraint.
4.2 A Logarithmically Competitive Algorithm for Matroid Domains
Theorem 4.2 demonstrates that without imposing any structure on the domain, it is impossible to
achieve constant competitive algorithms. A natural restriction on the structure of the domain is
to assume that it is a matroid domain. Unfortunately, we do not know how to prove that constantcompetitive algorithms exist for general matroid domains. However, we present a simple algorithm
(Algorithm 1) that is O(log k)-competitive for any matroid domain, where k is the rank of the
matroid. The algorithm needs to know n (the number of elements in the domain), but not k (the
rank of the matroid). The algorithm accesses the matroid through an oracle which, given a set,
returns true if the set is an independent set of the matroid. The algorithm only queries this oracle
on sets of elements that it has already observed.
Theorem 4.4. The Threshold Weight Algorithm is an online O(log k)-competitive algorithm for
any matroid with (possibly unknown) rank k.
Proof. More specifically, we will prove a bound of 64(4 + log k) = O(log k). For most of the
proof, we assume that the matroid’s rank k is large enough, specifically, that k ≥ 34. We will treat
the case k < 34 at the end of the proof.
First, observe that by the choice ofs and because the elements arrive in uniformly random order,
the sample S contains each element of the matroid independently with probability 1
2 .
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018. 
Matroid Secretary Problems 35:11
ALGORITHM 1: The Threshold Weight Algorithm
Threshold Weight Algorithm
Input: Number of elements n and and an oracle for independent sets of a matroid of unknown rank
k.
Output: an independent set B.
(1) Observe s = Binomial(n, 1
2 ) elements without picking any element; let S ⊂ U be the set
of observed elements. (S is called the sample.)
(2) Let k∗ be four times the size of a maximum-size independent set in S.
(3) Let ∗ = argmax∈S (w()) be the element of S with maximum weight. Pick an integer ρ uniformly at random from the set {0, 1, 2,..., log k∗ }. The threshold weight is
θ = w(∗)/2ρ .
(4) Initialize the set of selected elements B to be the empty set.
(5) Let t be the element in U \ S observed at time t = s + 1,...,n. If w(t ) ≥ w(∗)/2ρ and
B ∪ {t } is an independent set, then select t (i.e., set B := B ∪ {t }).
Let B∗ be the maximum-weight basis of the matroid, consisting of elements x1, ··· , xk , sorted
such that w(x1) > w(x2) > ··· > w(xk ).
10
Let q ≤ k be maximal such that w(xq ) ≥ w(x1)/k. Because the elements of B∗ with weight less
than w(x1)/k sum up to less than w(x1), they contribute less than half the weight of B∗; hence,
w(x1) + w(x2) + ... + w(xq ) > 1
2 · w(B∗).
For any (random) set A ⊆ U, let ni (A) denote the number of elements of A whose weight is at
least w(xi ), and let mi (A) denote the number of elements of A whose weight is at least w(xi )/2.
Because ni (B∗) = i, the sum of the q largest weights of elements of B∗ can be rewritten as

q
i=1
w(xi )
ni (B∗ )=i =

q
i=1
w(xi ) · (ni (B∗) − ni−1 (B∗))
=



q−1
i=1
(w(xi ) − w(xi+1)) · ni (B∗)



+ w(xq )nq (B∗).
Let B be the independent set output by the Threshold Weight Algorithm. By a similar calculation
as above, the weight of B is at least
1
2 ·




q−1
i=1
(w(xi ) − w(xi+1)) · mi (B)



+
1
2 · w(xq )mq (B).
We will show that for k ≥ 34, the Threshold Weight Algorithm is 64(4 + log k)-competitive, by
proving that E [mi (B)] is within a factor 16(4 + log k) of ni (B∗) for all i ∈ {1,...,q}. (Recall that
we lost a factor of at most two by comparing the weight of B with w(x1) + ··· + w(xq ) instead of
w(x1) + ··· + w(xk ); we are losing another factor of two in the analysis because the weights of the
mi (B) elements is only lower-bounded by w(xi )/2, whereas the weight of the ni (B∗) elements is
lower-bounded by w(xi ).)
The case i = 1 is a special case. With probability at least 1
4 , the sample does not contain the
maximum-weight element but does contain the element with the second-highest weight. Conditioned on this event, with probability at least 1
4+log k , this second-highest weight becomes the
10Recall that we have assumed that the input is well-behaved; thus, there is a unique maximum-weight basis and no ties
in weights.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.              
35:12 M. Babaioff et al.
threshold weight (when ρ is picked to be 0), in which case the algorithm is guaranteed to select
the element with weight w(x1). Thus, E [m1 (B)] ≥ 1
4(4+log k) , while n1 (B∗) = 1. For the remainder
of the proof, we consider i > 1; recall that ni (B∗) = i.
We begin by giving a sketch of the analysis when the algorithm is actually given the matroid’s
rank k, rather than having to use its own estimate k∗. In that case, with probability 1
2 , the element
x1 is in the sample, and independently, with probability at least 1
2+log k , the threshold-setting parameter ρ is picked to ensurew(x1)/2ρ ≤ w(xi ) < w(x1)/2ρ−1. These events are independent of the
event that element xj , for j ∈ {2,...,i} is in the sample. Each such element is in the sample with
probability 1
2 , so the conditional expectation of the number of elements xj, j ∈ {2,...,i} that arrive
after the sample is i−1
2 . While we cannot guarantee that these particular elements will be picked,
the matroid exchange property11 guarantees that at least i−1
2 elements are picked, and each of them
has weight lower-bounded by the threshold. Overall, we obtain that E [mi (B)] ≥ Ω(1/ log k) · i, as
required.
The actual proof for the case when k is unknown is made somewhat complicated by subtle dependencies between the estimated rank k∗ of the matroid and which elements occur in the sample
or are available for picking. Another subtle difficulty is that if the matroid rank estimate is too
small (specifically, log k∗ < i), then the algorithm could not pick a suitable ρ that would ensure
picking enough of the elements x2,..., xi . To properly handle the subtle conditioning issues, we
define the following random events:
—Fj , for j ∈ {1, 2,...,i}, denotes the event that element xj is not in the sample.
—E∗
κ , for κ ∈ {0, 1, 2}, denotes the event that the estimate k∗ of the matroid’s rank satisfies
log k∗ = log k + κ.
—E∗ = E∗
0  E∗
1  E∗
2 denotes the event that log k≤log k∗ ≤ 2 + log k.
—Ei is the event that ρ, the threshold-setting parameter in step 3 of the algorithm, satisfies
w(x1)/2ρ ≤ w(xi ) < w(x1)/2ρ−1.
First, observe that Prob[Fj] = 1
2 for all j, and that by the Binomial choice of the sample size s
and the uniformly random order in which the elements arrive, the events Fj are independent.
Next, we show that E∗ happens with high probability. Since a subset of a matroid cannot have
larger rank than the matroid itself, k∗ ≤ 4k, so log k∗≤log k + 2 holds deterministically. Thus,
to show that E∗ occurs with high probability, we show that the event k∗ < k has low probability. Let
A∗ = B∗ ∩ S be the elements of B∗ included in the sample. A∗ is an independent set, implying that
k∗ ≥ 4|A∗ |. The expected size of A∗ is E [|A∗ |] = |B∗ |/2, and because |A∗ | is a sum of independent
0–1 variables, the Chernoff Bound implies that
Prob[E∗] ≤ Prob[|A∗ | < |B∗ |/4] ≤ exp(−|B∗ |/16) = exp(−k/16).
Next, we observe some properties of the events Ei . First, conditioned on any event E∗
κ , the
event Ei is independent of the events Fj , because the distribution of ρ depends on the sample only
through k∗, the estimated matroid rank.12 Conditioned on any one of the events E∗
κ , the index
ρ in Line 3 is chosen uniformly from {0, 1,...,κ + log k }; in particular, each index ρ is chosen
with probability at least 1
4+log k . If the highest-weight element was in the sample, i.e., F1 happened,
then ∗ = x1, and Ei happens iff ρ = log(w(x1)/w(xi )). Recall that q ≤ k is maximal such that
w(xq ) ≥ w(x1)/k; thus, since i ≤ q, we get that log(w(x1)/w(xi ))≤log k. In particular, this
11Recall that the exchange property states that if A and B are two independent sets with |A| > |B |, then there exists an
element x ∈ A \ B such that B ∪ {x } is independent. 12Notice that it is not clear whether this conditional independence holds conditioned on E∗.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018. 
Matroid Secretary Problems 35:13
implies that conditioned on E∗
κ ∩ F1, the target value log(w(x1)/w(xi )) is in the support of the
distribution of ρ, and we get that for all κ,
Prob[Ei | E∗
κ ∩ F1] ≥
1
4 + log k .
Whenever Ei ∩ E∗ ∩ F1 happens, any element j ≤ i not in the sample is eligible for picking by
the algorithm in the following sense: j would be picked if it were the first element after the sample,
and the only reason why it wouldn’t be picked is that the algorithm instead picked an element
with weight at least half that of j. The following conditions combined are sufficient for an element
j ≤ i to be eligible: (1) element j was not in the sample; (2) element 1 was in the sample; (3) the
estimation of the matroid’s rank satisfies k∗ ≥ k; and, (4) the chosen index ρ satisfies w(x1)/2ρ ≤
w(xi ) < w(x1)/2ρ−1. This is because (2) and (4) together ensure that the algorithm’s threshold θ is
set in a way that allowsj to be included, and (1) implies that j is still available. (The high-probability
event (3) is needed to calculate the probabilities.) For any j > 1, we lower-bound the probability
of the event Fj ∩ F1 ∩ E∗ ∩ Ei :
Prob[Fj ∩ F1 ∩ E∗ ∩ Ei] =
2
κ=0
Prob[Fj ∩ F1 ∩ Ei ∩ E∗
κ ]
=
2
κ=0
Prob[E∗
κ ] · Prob[Fj ∩ F1 ∩ Ei | E∗
κ ]
(∗)
=
2
κ=0
Prob[E∗
κ ] · Prob[Fj ∩ F1 | E∗
κ ] · Prob[Ei | E∗
κ ]
≥
2
κ=0
Prob[E∗
κ ] · Prob[Fj ∩ F1 | E∗
κ ] · 1
4 + log k
= 1
4 + log k ·
2
κ=0
Prob[Fj ∩ F1 ∩ E∗
κ ]
= 1
4 + log k · Prob[Fj ∩ F1 ∩ E∗
]
≥
1
4 + log k · (Prob[Fj ∩ F1] − Prob[E∗])
(∗∗)
≥
1
4 + log k · (
1
4 − exp(−k/16))
k ≥34
≥
1
8(4 + log k)
.
In the step labeled (*), we used the conditional independence of Ei and the Fj , conditioned on
E∗
κ . In the step labeled (**), we used that Prob[Fj ∩ F1] = 1
4 by independence of the Fj events and
the upper bound on Prob[E∗] derived above.
Hence, out of the elements {x2,..., xi} that we are interested in, in expectation, at least
i−1
8(4+log k) ≥ i
16(4+log k) appears after the sample while the threshold θ is also set such that they are
eligible for inclusion in B. By the exchange property, this implies that the expected size of B is at
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
35:14 M. Babaioff et al.
least i
16(4+log k) . Hence, we have shown that
E [mi (B)] ≥
i
16(4 + log k) = 1
16(4 + log k) · ni (B∗).
Finally, it remains to consider the case k < 34, which can be treated similarly to i = 1 above.
First, the total weight of any independent set is at most 33 · w(x1). With probability at least 1
4 ,
the sample includes the element with second-highest weight, but not the element with highest
weight. And with probability at least 1
4+log k , the algorithm chooses ρ = 0. In that case, the algorithm is guaranteed to pick x1, achieving at least a 1/33 fraction of the optimum weight. In total,
the expected weight picked by the algorithm is at least a 1
33(4+log k) fraction of the optimum in this
case.
5 UNIFORM MATROIDS
In a uniform matroid of rank k, the independent sets are precisely those having k or fewer elements.
In this section, we design and analyze a constant competitive secretary algorithm for uniform
matroids. Specifically, our algorithm is a generalization of Dynkin’s algorithm for the rank-1 case
and is an e-competitive algorithm for every uniform matroid.
We note that Kleinberg (2005) designed an improved algorithm for uniform matroids whose
competitive ratio converges to 1 as k tends to infinity. Specifically, his algorithm’s competitive ratio
is 1 + O(
√
1/k); and, he shows that this result is tight by showing that there is no algorithm whose
competitive ratio converges to 1 asymptotically faster than 1 + Ω(√
1/k) as k tends to infinity.
While this algorithm’s competitive ratio is much better than e for large k, it fails to provide any
approximation when k is small (k ≤ 25), while the algorithm we present here is e competitive
for every k ≥ 1. (We note that the bound proved by Kleinberg (2005) requires k > 62 to ensure a
competitive ratio of at least e).
Like Dynkin’s algorithm for the rank-1 matroid secretary problem and the Threshold Weight
Algorithm from Section 4, the algorithm we present in this section—which we will call the virtual
algorithm—is based on a sampling period ofs < n steps during which the algorithm does not select
any elements, followed by selecting some of the elements for the remaining n − s steps. We call
s the threshold time of the algorithm and denote the set of sampled elements by S. We leave s
unspecified for now; after analyzing the algorithm, we will specify the optimal value of s, which
will be approximately n/e.
The virtual algorithm keeps track of a reference set Rt . At any time t, Rt consists of the (at most)
k elements of highest weight observed strictly before time t. We let θt = argmini ∈Rt w(i) denote
the threshold element, the element in Rt of smallest weight. Notice that both Rt and θt are defined
entirely independently of the choices made by the algorithm; they depend only on the observed
sequence, a fact that will be exploited in the analysis of the algorithm.
During the first s steps, no elements are selected. Subsequently, consider a step t > s, during
which the weight of element i is observed. The algorithm picksi if and only if one of the following
two events happen:
(1) |Rt | < k. Fewer than k elements have been observed.
(2) w(i) > w(θt ), and θt ∈ S. The threshold element was in the sample, and i has higher
weight than the threshold element.
We first note that the virtual algorithm never selects more than k elements. First, if s < k, then
until time k, all elements are picked, for a total of k − s elements. At that point, |Rk+1 ∩ S | = s.
When s ≥ k, there are at least k elements to choose from, so the reference set will pick k elements:
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018. 
Matroid Secretary Problems 35:15
|Rs+1 | = k. Subsequently, each selection strictly decreases the cardinality of the set Rt ∩ S. Thus,
at most s (resp., k) elements can be picked by the algorithm, for a total of k in either case.
Next, we prove that the virtual algorithm is e-competitive when s = n/e.
Theorem 5.1. For every positive integer n, the competitive ratio of the virtual algorithm with parameter s = n/e is less than e.
Proof. Suppose that i is among the k elements with the highest weights. We prove that i is
selected with probability at least 1/e. Whenever i is observed at time t, its weight is guaranteed
to exceed w(θt ). For each t, the probability that i arrives at time t is exactly 1/n. Conditional on i
arriving at time t, the ordering of the first t − 1 elements is uniformly random. In particular, whenevert > s, the conditional probability that θt is among the firsts elements iss/(t − 1). Importantly,
the event that i is picked is independent of any past choices of the algorithm and depends only on
the random ordering.13 Therefore, the algorithm’s probability of selecting i is equal to
n
t=s+1
1
n · s
t − 1 = s
n
n
t=s+1
1
t − 1 = s
n (Hn−1 − Hs−1),
where Hm denotes the mth harmonic number. The right side is approximated by s
n ln( n
s ), which
approaches 1/e as s/n → 1/e. In fact, in Lemma 5.2 below, we prove that the right side is strictly
greater than 1/e when s = n/e ≥ 1. (The special cases n = 1, 2, when s = 0, are easily handled by
a separate argument: the virtual algorithm in this case always selects the first element it observes,
which is i with probability 1/n > 1/e.)
Since each of the k highest-weight elements is selected with probability greater than 1/e, it
follows immediately that the expected weight of the selected set is more than 1/e times that of the
maximum weight k-element set.
In the proof of Theorem 5.1, we omitted a technical step that is necessary for proving that
the algorithm’s competitive ratio is actually better than 1/e, and not merely asymptotic to 1/e as
n → ∞. The following lemma supplies the proof of this omitted step.
Lemma 5.2. For n ≥ 3 and s = n/e,
s
n (Hn−1 − Hs−1) >
1
e
. (1)
Proof. Because x → 1/x is convex,
 t
t−1
1
x
dx <
1
2
 1
t − 1
+
1
t

= 1
t − 1 − 1
2
 1
t − 1 − 1
t

.
Summing over t = s + 1,...,n, we obtain that
(Hn−1 − Hs−1) >
 n
s
1
x
dx +
1
2
 1
s − 1
n

= ln(n/s) +
1
2
 1
s − 1
n

.
Multiplying both sides by s
n , it is therefore sufficient to show that
1
e < s
n ln 
n
s

+
 1
2n − s
2n2

. (2)
Let f (s,n) := s
n ln( n
s ) + ( 1
2n − s
2n2 ), and fix a value of s ≥ 1. The range of n with s = n/e is all
integers in [es, e (s + 1)). A simple derivative test shows that for fixed s and n ≥ es, the function
f (s,n) is non-increasing in n. Hence, it is sufficient to prove that f (s, e (s + 1)) > 1
e .
13This condition does not hold for several other natural algorithms, making their analysis significantly more involved than
the one carried out here.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018. 
35:16 M. Babaioff et al.
Substituting n = e (s + 1), and using that ln(
e (s+1)
s ) ≥ 1 + 1
s+1 = s+2
s+1 , we obtain that
f (s, e (s + 1)) ≥ s
e (s + 1) ·
s + 2
s + 1
+
 1
2e (s + 1)
− s
2e2 (s + 1)2
	
= 1
e + (e − 1)s − e
2e2 (s + 1)2 ,
which is clearly greater than 1/e whenever s > 1. In the remaining case s = 1, it suffices to check
the (worst) case n = e (s + 1) = 5 by hand, which yields s/n · (Hn−1 − Hs−1) = 5/12 > 1/e.
6 THE UNIT-DEMAND DOMAIN
In this section, we consider (single-value) unit-demand domains. In such a domain, there are n ≥ 2
agents and a set M of m non-identical items. Each agent i has a non-empty set Ti ⊆ M of desired
items and his value is vi if he receives any item j ∈ Ti (and 0, otherwise). We assume that there is
a constant d such that |Ti | ≤ d, for all i; that is, each agent demands one of at most d items. An
outcome is a matching between agents and items. Thus, in the unit-demand domain, the set of
outcomes for which agent i has value vi is the set of all outcomes in which i is matched to an item
in Ti . We assume that for each agent i, his value vi is private information, known only to him. If
the setTi is also private information of agent i, we say that the domain is an unknown unit-demand
domain.
The unit-demand domain is a matroid domain in which independent sets of agents form a
transversal matroid of bounded left-degree. The matroid elements of a transversal matroid correspond to vertices on the left side (L) of a bipartite graph G = (L, R, E). (Thus, the size of the
ground set is |L| = n.) A set S ⊆ L is independent if there exists a matching between all of S and
a subset of R. The unit-demand domain is a transversal matroid domain in which L is the set of
agents, R is the set of items, and there is an edge from  ∈ L to r ∈ R if r ∈ T; the weight of this
edge is vl . The bound on the number of items an agent desires translates to a bound of d on the
maximal degree of any node in L. The value of an agent  corresponds to the weight of the node
 ∈ L and is denoted by w(l).
We first present a 4d-approximation algorithm to the matroid secretary problem for transversal matroids with left-degree at most d; we later show that this algorithm also creates a truthful
online mechanism for the unknown unit-demand domain. This algorithm works for the known
matroid secretary problem,14 but not when the algorithm only has oracle access to the independent sets. We leave open the problem of obtaining a similar competitive ratio in the oracle model.
As discussed in Section 2, subsequent to the appearance of the conference version of our work, the
dependence on the degree d was removed by Dimitrov and Plaxton (2012), and the approximation
guarantee improved by Korula and Pál (2009) and Kesselheim et al. (2013), who obtain the best
possible guarantee of e. While we prove that our algorithm gives rise to a truthful mechanism, the
improved approximation algorithms of Dimitrov and Plaxton (2012), Korula and Pál (2009), and
Kesselheim et al. (2013) were not shown to correspond to truthful mechanisms.
Informally, our algorithm works as follows. The algorithm first observes half of the agents (the
sample) without selling any item. It then prices each item at the maximal price any agent in the
sample was willing to pay for that item. Finally, for every agent after the sample, the algorithm
14The algorithm actually solves a somewhat harder problem, in which the matroid is not known in advance but rather
revealed to the algorithm in an online way. This revelation happens when agents reveal their desired items, implicitly
revealing edges in a bipartite graph between agents and items; this revelation indirectly gives the algorithm information
about independent sets of the matroid. While the gradual revelation of the bipartite graph is akin to an oracle, and no
information is ever revealed about elements not seen so far, the oracle is specific to the transversal domain and is different
from the standard oracle for independent sets that is required when the matroid is not known. It is not clear how to modify
the algorithm so that it works with standard oracle access to independent sets instead.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.     
Matroid Secretary Problems 35:17
sells to that agent the cheapest remaining item the agent is interested in, if its price is lower than
the agent’s value.15 For a formal definition of the algorithm, see Algorithm 2.
ALGORITHM 2: The Price Sampling Algorithm
Price Sampling Algorithm:
—Observe s = n/2 elements without picking any element, and let S ⊂ L be the set of observed elements. (S is called the sample.)
—For each right node r ∈ R, let ∗ (r) be the singleton set consisting of the sampled left node
with maximal weight among the neighbors ofr; or ∗ (r) = ∅ if no neighbor ofr was sampled.
Let the price of r be w(∗ (r)).
—At time t = s + 1,...,n, the algorithm observes element  ∈ L with weight w(). Let R∗ ()
be the set of unmatched neighbors of  with price lower than w(). If R∗ () is not empty,
match  to a node with the lowest price in R∗ ().
Theorem 6.1. For any transversal matroid with bounded left degree d, the Price Sampling Algorithm is a 4d-approximation.
Proof. Let OPT be a maximum weight matching in the graph. For any right node r ∈ R, define
m(r) to be the singleton set of the node that r is matched to in OPT (or ∅ if r is unmatched);
similarly, let h(r) be the singleton set of the neighbor  of r with maximum weight w(), and s(r)
the singleton set of the neighbor  of r with second-highest weight. If one of these nodes does not
exist (because r does not have enough neighbors), the corresponding set is again defined to be ∅.
Let H = 

r ∈R h(r).
First, notice thatw(m(r)) ≤ w(h(r)) by definition, sow(OPT) ≤
r w(h(r)) ≤ d · w(H), because
each  ∈ H appears at most d times in the sum.
Next, we show that each  ∈ H will be matched by the Price Sampling Algorithm with probability at least 1
4 . For a (fixed)  ∈ H, let r ∈ R be such that  = h(r). Define E to be the event that
s(r) ⊆ S and   S; in other words, the second-highest weight neighbor of r (if it exists) is in the
sample, while  is not. The probability of E is at least s
n · n−s
n−1 = n/2
n · n− n/2
n−1 > 1
4 .
Whenever E happens, the algorithm will set ∗ (r) = s(r); therefore, no left element other than
can be matched with r, and when  = h(r) arrives after the sample, r is still unmatched, implying
that R∗ ()  ∅. Thus, whenever E happens,  will be matched (with r or another node).
Summarizing, the total expected weight of the left elements matched by the algorithm is at least
w(H)/4 ≥ w(OPT)/(4d), completing the proof.
Finally, we observe that the Price Sampling Algorithm creates a truthful mechanism for any
unit-demand matroid domain (even without the bounded degree assumption), in the unknown
unit-demand case in which the set of desired items is private information.
Theorem 6.2. For any unit demand matroid domain, the Price Sampling Algorithm is a truthful
mechanism for the unknown unit-demand model. If each agent desires at most d items, the Price
Sampling Algorithm achieves a 4d-approximation to the social welfare.
Proof. We need to show that the mechanism is truthful, both with respect to the value and
with respect to the set of desired items. Clearly, any agent in the sample has no incentive to lie, as
15Note that while the algorithm merely has to commit to which nodes will be matched, our algorithm actually commits to
a matching online.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.                             
35:18 M. Babaioff et al.
his utility is 0 for any declaration. An agent not in the sample faces the following problem: given
prices for each item, pick a desired item that has minimal price and is not taken yet, and pay its
price. Thus, the agent answers a demand query. The optimal thing for him to do is, by definition,
to pick his favorite item (given the prices). This can clearly be simulated by a direct-revelation
mechanism that is truthful (picking that item on the agent’s behalf).16
7 GRAPHIC MATROIDS
In this section, we consider graphic matroids. In a graphic matroid, each matroid element corresponds to an edge e ∈ E of an undirected graph G(V, E). A set S ⊆ E of edges is independent if it
does not contain a cycle. We write n = |E|.
We present a 16-approximation algorithm for this family of matroids based on a modification of
the Price Sampling Algorithm for transversal matroids. (As discussed in Section 2, our guarantee
was subsequently improved to 2e by Korula and Pál (2009).)
Given a graphG = (V, E), we create a bipartite graphG	 = (L, R, E	
) as follows: Each node u ∈ V
is mapped to a right node u ∈ R. Each edge e = (u,v) is mapped to a new left node uv ∈ L with
exactly two edges: to u and v in R. Thus, G	 is a bipartite graph with left degree d = 2.
Any tree T in G can be mapped to a matching in G	 in the following way: Let vˆ be an arbitrary
node serving as root of T , and direct all edges of T away from vˆ. Now, for each directed edge
(u,v) ∈ T , include in the matching the edge (uv ,v). Because each node has at most one incoming
edge, this defines a matching.
Unfortunately, the converse direction does not work as easily: If G is a triangle, G	 has a perfect
matching, and the set of matched edges (all edges) form a cycle. Thus, the Price Sampling Algorithm
for transversal matroids can not be run directly on G	 to obtain an independent set.
To overcome this problem, we modify the Price Sampling Algorithm for transversal matroids as
follows: if the inclusion of an edge (u,v) ∈ E (corresponding to a left node uv ∈ L) would close a
cycle in G, it is not matched, even if its weight exceeds the price of one of its endpoints.
Theorem 7.1. For any graphic matroid, the modified Price Sampling Algorithm is a 16-
approximation. Moreover, the algorithm with the payments defined by the right nodes’ prices creates
a truthful mechanism.
Proof. Let T ∗ be a maximum weight tree in the graph G, with weight w(T ∗), and let OPT be
a maximum weight matching in the graph G	
, with weight w(OPT). As we have shown that any
tree inG corresponds to a matching inG	
,w(T ∗) ≤ w(OPT). We show that in expectation, the total
weight of the matching picked by the modified Price Sampling Algorithm is at least w(OPT)/16.
Let h(r),s(r),m(r), and H be defined as in the proof of Theorem 6.1. According to that proof
(with d = 2), w(OPT) ≤ 2 · w(H). Similar to the proof of Theorem 6.1, we will show that each
element of H is included by the algorithm with probability at least 1/8. This will complete the
proof of the 16-approximation.
Fix  = uv ∈ H, and let r ∈ R be a right node with h(r) = . (Without loss of generality, r = u.)
Let L	 ⊂ L be the (singleton set of the) neighbor of v other than  with maximum weight. That
is, if h(v) = {}, then L	 = s(v); otherwise, L	 = h(v). Let E be the event that s(u) ⊆ S, L	 ⊆ S, and
  S. The probability of E is at least s
n · s−1
n−1 · n−s
n−2 = n/2
n · n/2−1
n−1 · n− n/2
n−2 > 1/8. (If one or both
of s(u) or L	 is empty, the probability is higher.)
Whenever E happens, ∗ (r) = s(r) and ∗ (v) = L	
. Therefore, both r = u and v are unmatched
when  arrives. Adding (u,v) can thus not generate a cycle in G, for in a cycle, each node would
16This argument also shows that the mechanism need not solicit the value and desired items of agents not in the sample.
Such agents can simply be presented with item prices and be allowed to pick the item, which maximizes their utility.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.              
Matroid Secretary Problems 35:19
have to be matched to an edge, and at least one of u,v will remain unmatched even after adding
(u,v). Because R∗ () is not empty,  will be matched, completing the proof.
Truthfulness follows from exactly the same argument as for transversal matroids.
8 TRUNCATIONS OF MATROIDS
Truncation is an operation that decreases the rank of a matroid by discarding all independent
sets whose cardinality exceeds a specified limit. In a matroid domain, this corresponds to a sort
of limited-supply assumption: the outcome set is modified by eliminating all outcomes that satisfy
more than a specified number of agents. A motivating example is a truncated partition matroid, i.e.,
the matroid whose ground set U is partitioned into subsets U1, U2,..., and whose independent
sets are all the subsets that have at most r elements and intersect each piece of the partition in
at most one element. Truncated partition matroids correspond to the following natural selection
problem: a department has the opportunity to hire up to r new faculty members, subject to the
constraint that no two new hires should belong to the same subfield.
Definition 8.1. Let M = (U, I) be a matroid of rank k, and let r ≤ k. The truncation τr (M) =
(U, τr (I)) is the matroid whose collection of independent sets comprises all sets in I with at most
r elements, i.e., τr (I) = {I ∈I||I | ≤ r}. If D is a matroid domain with outcome set Ω, then τr (D)
is the domain obtained by deleting all outcomes ω ∈ Ω that satisfy more than r agents.
We will provide a general reduction from the secretary problem for a truncated matroid τr (M)
to the secretary problem for M at the cost of a constant factor in the competitive ratio. Since we
know, for example, that partition matroids have an e-competitive algorithm (run an independent
copy of the original secretary algorithm on each piece of the partition), this implies, in particular,
that truncated partition matroids have a constant-competitive algorithm.
The high-level idea of the reduction is as follows. Let ALG be a c-competitive algorithm for the
M-secretary problem. The algorithm for τr (M) samples the first roughly 3n/4 elements without
picking any; it will also keep ALG from picking any of these elements by assigning them a modified
weight of 0. Based on this sample S, the algorithm then computes a maximum-weight independent
set B ⊆ S of size r. The remaining n/4 elements are evaluated based on whether they could replace
an element of B without decreasing the total weight. If yes, they are offered to ALG with their
actual weight (this set of elements is called A); otherwise, their weight is modified to 0 so that ALG
does not pick them. The analysis proceeds by showing that each element of the maximum-weight
independent set of τr (M) is in A with constant probability. Because ALG is c-competitive, when
running on A, it will obtain an O(c) competitive ratio in expectation.
For reasons that will become clear in the analysis, it is essential that when interacting with
ALG, the modified algorithm not present all of S before S. Instead, the algorithm will randomly
interleave the (previously observed) elements of S with its own online input sequence.
To make the description and analysis of the algorithm precise, we recall the following definition
from (Karger 1998).
Definition 8.2. If I is an independent set in a matroid M, and x is any element of the ground set
of M, we say that x improves I if x belongs to the maximum-weight independent subset of I ∪ {x}.
The algorithm for τr (M) is given below. We assume without loss of generality that the ccompetitive algorithm ALG for M never picks any elements of weight w(x) = 0. (If it did, then
a modified algorithm mimicking ALG, but never picking weight-0 elements, would achieve the
same competitive ratio.)
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.   
35:20 M. Babaioff et al.
ALGORITHM 3: The Truncated Matroid Algorithm
Truncated Matroid Algorithm τr (ALG):
—If r ≤ 144, then run Dynkin’s standard secretary algorithm to pick the maximum-weight
element of U with probability at least 1/e. Otherwise (r > 144), run the following algorithm.
—Let z1, z2,..., zn be a sequence of independent Bernoulli random variables, each with expected value 3/4. Let s be the number of i such that zi = 1.
—Observe the first s elements of the sequence without picking any of them, placing them in
the sample set S.
—Let B be the maximum-weight independent set of S containing (at most) r elements.
—For each step i = 1,...,n:
—If zi = 1, then:
—Draw a uniformly random element x of S and delete it from S.
(Do not observe a new element from the online sequence.)
—Present x to ALG with modified weight wˆ (x) = 0.
—Otherwise (zi = 0):
—Let x be the next (previously unobserved) element of the online sequence.
—If x improves B, then present x to ALG with its true weight wˆ (x) = w(x).
If ALG picks x, then pick x as well.
—If x does not improve B, then present x to ALG with modified weight wˆ (x) = 0.
Theorem 8.3. If ALG is a c-competitive algorithm for the M-secretary problem, then τr (ALG) is
max(13c, 400)-competitive for the τr (M)-secretary problem. If ALG gives rise to a truthful mechanism,
then so does τr (ALG).
Proof. If r ≤ 144, then Dynkin’s Secretary Algorithm picks the maximum-weight element of
U with probability at least 1/e; thus, the algorithm has a competitive ratio of at most 144e < 400.
From now on, assume that r > 144.
Let A be the set of all elements i with zi = 0 that improve B, i.e., the set of all elements presented to ALG with their true weight. Let OPTr denote the maximum-weight basis of τr (M). For
notational convenience, we identify the elements in U with the iteration i in which the algorithm
considered them. In particular, for any element x ∈ U, zx denotes whether x was in the sample.
The elements of OPTr improve all independent sets (Karger 1998); this fact is an easy consequence
of the matroid axioms. Consequently, OPTr ⊆ A ∪ B, and the elements of OPTr are randomly assigned to either A or B, independently, with probabilities 1/4 and 3/4, respectively. This implies
the following:
(1) The probability that |A ∩ OPTr | < r/6 is at most exp(−r/72) ≤ exp(−2). This follows from
standard Chernoff Bounds (see Theorem 8.5 below) with μ = r
4 ,ε = 1
3 .
(2) The probability that |B ∩ OPTr | < r/2 is at most exp(−r/24) ≤ exp(−6). (Again by Theorem 8.5, with μ = 3r
4 ,ε = 1
3 .)
(3) The probability that |A ∪ B| > 3r/2 is at most exp(−r/144) ≤ exp(−1). This is a consequence of Karger’s matroid sampling theorem (given below as Theorem 8.4) with
ε = 1
8 .
Let E denote the event that none of (1)–(3) occur. The probability of E is at least 1 − (exp(−2) +
exp(−6) + exp(−1)) > 0.49. Note that E implies that |B| ≥ r/2 and |A ∪ B| ≤ 3r/2, and, hence, that
|A| ≤ r. From now on, we continue the analysis conditioning on E.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
Matroid Secretary Problems 35:21
First, because only elements of A have positive modified weight, |A| ≤ r, and ALG only picks
elements of positive modified weight by assumption, we obtain that the final output is an independent set of cardinality at most r; hence, it is indeed an independent set in τr (M).
It remains to analyze the expected weight of the set selected by τr (ALG). First observe
that an element x ∈ OPTr is in B if zx = 1, and in A, otherwise. Hence, conditioned on
|A ∩ OPTr | = a, the set A ∩ OPTr is a uniformly random a-element subset of OPTr , implying
that E [w(A ∩ OPTr ) | |A ∩ OPTr | = a] = (a/r) · w(OPTr ). In particular, E [w(A ∩ OPTr ) | E] ≥
w(OPTr )/6. With R denoting the maximum-weight independent subset of A (which may be different from A ∩ OPTr ), we also get that E [wˆ (R) | E] = E [w(R) | E] ≥ w(OPTr )/6.
Finally, notice that conditioned on the modified weights wˆ (x), the sequence as seen by ALG is
uniformly random. This is where the intricate “shuffling” using the zi variables in the algorithm
τr (ALG) is necessary: it decouples the observation of the first s elements by τr (ALG) from the set
of elements of modified weight 0 presented to ALG. Because the sequence is uniformly random
conditioned on the modified weight, ALG guarantees that it selects an independent set of total
weight at least w(R)/c. Conditioned on the event E, the set selected by τr (ALG) is independent in
τr (M), and E [w(R) | E] ≥ w(OPTr )/6. Since E happens with probability at least 0.49, the expected
weight of the set selected by τr (ALG) is at least ( 0.49
6c )w(OPTr ) ≥ w(OPTr )/13c.
If M is a truthful mechanism for the domain D, with allocation rule ALG, then ALG must be
monotone (an agent cannot go from winning to losing by increasing his bid). The reduction using
ALG within τr (ALG) preserves monotonicity, so τr (ALG) will also be monotone. Because we are
considering a single-parameter domain, monotonicity is not only necessary but also sufficient for
truthfulness; more precisely, monotonicity implies that we can design a truthful mechanismτr (M)
using the allocation rule τr (ALG). The price charged to agenti is 0 if the outcome does not satisfy i;
otherwise, it is the minimum value thati would have to bid in order to get a satisfying outcome.
In the proof, we used the following theorem by Karger (1998), as well as a standard form of the
Chernoff Bound.
Theorem 8.4 (Karger (1998)). Let M be a matroid with ground set U in which each element
has been assigned a real-valued weight. Let p > 0, and obtain U	 from U by including each element of U independently with probability p. Let I be a maximum-weight independent subset of U	
.
Then, for any number ε > 0, the probability that more than (1 + ε)r/p elements improve I is at most
exp(−ε2
r/2(1 + ε)).
Theorem 8.5 (Chernoff Bounds (see, e.g., (Motwani and Raghavan 1995))). Let
X1,X2,...,Xm be independent Bernoulli random variables. Then, for X = m
i=1 Xi , μ = E [X], and
0 < ε ≤ 1,
Prob[X < (1 − ε)μ] < exp(−με2
/2).
9 CONCLUSION
In this article, we defined the matroid secretary problem, in which an online algorithm is presented
the elements of a matroid in uniformly random order and must irrevocably decide which ones to
include; its goal is to maximize the total weight of the selected elements. We conjecture that for
every matroid domain, there is a constant-competitive online algorithm.
We established this conjecture for several special cases of matroids: uniform, transversal, and
graphic matroids, as well as truncations of other matroids. We also provided a weaker bound of
O(log k) for arbitrary rank-k matroids. This bound has been improved to O(log log k) since the
original presentation of our results, and the bounds for several special cases have been improved
significantly, while a constant factor has been established for several additional special cases.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.  
35:22 M. Babaioff et al.
Despite a decade of subsequent work on the problem, our main conjecture is still open.
We remark that several natural algorithms for general matroids cannot provide a constant factor
guarantee in all cases. Specifically, two natural classes are single threshold algorithms and greedy
algorithms. The former observe elements for some amount of time without picking any, then set
a threshold and greedily pick all (legal) subsequent elements whose weight exceeds the threshold. The latter observe elements for some amount of time without picking any and then form a
“reference independent set” of the matroid. Subsequent elements are picked if they improve on
the reference set, in which case they are swapped in for a minimum-weight element of the reference set. In Appendix A, we give examples showing that neither of these classes of algorithm can
achieve a constant-factor guarantee in general.
While the conjecture for matroids is particularly natural (in part because the greedy algorithm
is optimal for matroids), one may consider other classes of set systems as well. We established
in Section 4.2 that for arbitrary downward-closed systems, a constant factor cannot be achieved.
In Babaioff et al. (2007b), we showed that for Knapsack domains, a constant factor can be achieved.
A natural direction for future research is the following: what other types of set systems admit
constant-factor online algorithms in the secretary model?
APPENDIX A SOME COUNTEREXAMPLES
As evidence that Question 4.1 is non-trivial (beyond the fact that it has now been open for about 10
years), in this appendix, we show that two natural generalizations of Dynkin’s Secretary Algorithm
cannot be constant-competitive for general matroids.
A.1 Single-Threshold Algorithms
Our Threshold Weight Algorithm is of the following type: after some sampling, it fixes a single
threshold and, while maintaining feasibility, greedily accepts all elements whose weight exceeds
the threshold, in the order of arrival. Our algorithm is O(log k) competitive for arbitrary matroids.
We next show that any algorithm of this type, i.e., any algorithm that fixes a single-threshold, is
no better than Ω(log k/ log log k) competitive; in particular, no such algorithm can be constant
competitive.
More formally, a single-threshold algorithm is any algorithm with the following format. After
seeing t elements of the sequence (for t ∈ {0, 1, 2,...,n − 1}), and before seeing element t + 1, the
algorithm makes one of the following two decisions: (1) Observe element t + 1, but commit to
not picking it. (2) Set a threshold value θ and commit to greedily picking all subsequent elements
(starting at t + 1) whose weight is at least θ and that do not violate independence of the selected
set. Let τ = t be the time until which the algorithm observed elements (a random variable).
Naturally, the choice of when to switch to selecting elements and what value to set for θ may
depend on the observations up to time t. Notice that if the algorithm does not set a threshold before
observing element t + 1, it has committed to not picking that element.17
We next show that no single-threshold algorithm can guarantee a constant competitive ratio.
In fact, we establish the following stronger claim.
Proposition A.1. For any k, there is a matroid M of rank k on which every single-threshold
algorithm has competitive ratio Ω(log k/ log log k).
17One could slightly generalize the class of single-threshold algorithms by allowing the algorithm to decide to set a threshold and pick element t + 1 after observing element t + 1. With somewhat more technical detail, the following lower-bound
example yields the same result for this more general class. We opt for the cleaner proof and slightly less generality in the
lower bound.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
Matroid Secretary Problems 35:23
Proof. Let K be a large positive integer. Let M = (U, I) be a partition matroid consisting of
n = K · 2K elements, partitioned into 2K subsets S1, S2,..., S2K of size K each. A setA ⊆ U belongs
to I if |A ∩ Si | ≤ 1 for all i. This matroid has rank k = 2K . Assign weights to the elements of U
as follows. In each Si , there is a single element (the good element) of weight 1/i, and all other
elements (the bad elements) have weight 1/(Ki). The weight of the maximum-weight basis of M is
H2K = Ω(K).
Let ALG be a single-threshold algorithm. Suppose that ALG samples elements up to (and including) time τ (a random variable) and then sets a threshold of Θ (also a random variable). Condition
on the event that Θ = θ, for some θ. We distinguish three types of elements that ALG may select
after time τ .
(1) Bad elements: The combined weight of bad elements selected by ALG is at most

i 1/(Ki) = 1
K · H2K = O(1).
(2) A good element is safe if its weight exceeds θ, and the bad elements in its partition cannot
be selected (because their weight does not exceed θ). In other words, the good element in
partition i is safe if and only if 1/(Ki) < θ ≤ 1/i. The total weight of all safe elements is
at most
1/(Kθ )≤i ≤1/θ 1/i ≤ 1 + ln( 1/θ
1/(Kθ ) ) = 1 + lnK.
(3) Let x be an unsafe good element, belonging to partition Si . If 1/i < θ, then x is clearly
never selected, so we focus on the remaining case: that x is unsafe because 1/(Ki) ≥ θ.
Thus, any bad element from partition Si that appears after τ but before x will be selected
in x’s stead.
Conditioned on the event 1/(Ki) ≥ θ, the selection problem is equivalent to the following. The algorithm is presented with an urn of K balls, of which exactly one (the unsafe
good element) is black, while all others (the bad elements) are white. (We can disregard the
elements from other partitions for this analysis.) In each round, the algorithm can either
draw a uniformly random ball from the urn and discard it (corresponding to observing
one more element), or draw a uniformly random ball and keep it. The latter corresponds
to switching into selection mode; notice that conditioned on the switch, the element x
will be in a uniformly random location among the remaining elements.18 As soon as the
algorithm keeps a ball, the game is over; the algorithm wants to maximize the probability
of keeping the black ball.
A simple inductive proof shows that if m balls remain, the probability of keeping the
black ball is exactly 1/m, regardless of the strategy. For the induction step, notice that
discarding a uniformly random ball discards the black ball with probability 1/m, while
reducing the pool to m − 1 balls with probability (m − 1)/m. Thus, the probability of succeeding is m−1
m · 1
m−1 = 1
m .
Thus, regardless of the strategy employed by ALG, the element x is picked with probability at most 1/K, conditioned on x being unsafe. As a result, the total expected weight
of unsafe good elements picked by ALG is at most 1
K ·
2K
i=1 1/i = H2K /K = O(1).
Combining the three cases, the total expected weight picked by the algorithm is at most
O(logK), while the optimum basis has weight Ω(K). Thus, any single-threshold algorithm has
competitive ratio Ω(K/ logK) = Ω(log k/ log log k) as k = 2K .
18The equivalence of the urn model relies on the fact that the algorithm must decide whether to observe or set a threshold
before seeing the next element.
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.    
35:24 M. Babaioff et al.
A.2 The Greedy Algorithm
A natural generalization of the greedy algorithm for the Matroid Secretary Problem is the following. The algorithm observes a constant fraction of the elements (the “sample,” denoted by S)
without making any selections. Afterward, it keeps track of an independent set A, which is initially a maximum-weight independent subset of the sample. Whenever it is possible to improve the
weight of A by incorporating the current element (and possibly swapping out one of the elements
of A ∩ S), the algorithm selects the current element and incorporates it into A.
We show that this algorithm is not constant-competitive, even when the matroid is a graphic
matroid. We present a family of graphs with size parametrized by m and ε such that for any sufficiently large graph in the family (for large m), the algorithm is not 1/ε-competitive.
Given an arbitrarily small positive constant ε > 0, let G = (V, E) be the following graph. The
vertex set is V = {u,u	
,v1,v2,...,vm }. The edge (u,u	
) has weight w(u,u	
) = m + 1. There are m
light edges (u,vi ) with distinct weights satisfying ε < w(u,vi ) < 2ε, andm heavy edges (u	
,vi ) with
distinct weights satisfying 2ε < w(u	
,vi ) < 3ε. The total number of edges is n = 2m + 1.
We show that with probability 1 − O(n−1/3 logn), the greedy algorithm does not select the edge
(u,u	
). Then, its total weight can be at most (m + 1) · 3ε, and the competitive ratio will be at least
1/(3ε).
Consider the interval I = [τ , min(τ + n2/3,n)] of the (at most) n2/3 first timesteps during which
the greedy algorithm may pick elements. Let E be the event that the edge (u,u	
) does not appear
during I. E has probability 1 − O(n−1/3). We will show that conditioned on E, the edge (u,u	
) is
picked with probability O(n−1/3 logn).
First, if (u,u	
) appeared before time τ , it is never picked. For the remainder, we condition on the
event that (u,u	
) appears afterI, and will show that in that case, with probability 1 − O(n−1/3 logn),
the greedy algorithm will already have picked a matching pair (u,vi ), (u	
,vi ) of edges. Therefore,
adding (u,u	
) would create a cycle, and the greedy algorithm will not add it.
Consider a matching pair of edges (u,vi ), (u	
,vi ) both occurring during I, with the light edge
(u,vi ) appearing before the heavy edge (u	
,vi ). We will show below (using, essentially, a Birthday
Paradox argument) that such a pair exists with high probability. The light edge (u,vi ), coming first,
will never create a cycle, and will thus always be included by the greedy algorithm. The heavy
edge (u	
,vi ) will create a cycle only if there is another index j such that both (u,vj), (u	
,vj) ∈ A.
If neither (u,vj) nor (u	
,vj) is in the sample S, then j gives us the pair whose existence we want
to prove. So we focus on the case when at least one of (u,vj), (u	
,vj) is in the sample. If the light
edge (u,vj) is in the sample, then the greedy algorithm replaces it with (u	
,vi ). Thus, (u	
,vi ) must
be added unless the heavy edge (u	
,vj) is in the sample S, and the light edge (u,vj) is in A \ S.
Let J denote the set of all indices j
	 such that both the light and heavy edges (u,vj	 ), (u	
,vj	 )
are in the sample. Then, at time τ , A contains all heavy edges in the sample, all light edges
for which the matching heavy edge has not been observed, and the pair (u,væˆ ), (u	
,væˆ ) for
æˆ = argmaxj	∈J w(u,vj	 ), i.e., the pair with the heaviest light edge in the sample. For the greedy
algorithm to add (u,vj) toA (with (u	
,vj) already inA), it would have to remove (u,væˆ ), since, otherwise, {(u,vj), (u	
,vj), (u,væˆ ), (u	
,væˆ )} would form a cycle. This will only happen if w(u,vj) >
w(u,væˆ ). The weight of (u,væˆ ) is largest from among the set J, which contains Ω(n) indices with
high probability. On the other hand, during the interval I, the greedy algorithm sees at most n3/4
light candidate edges (u,v). By standard Chernoff Bounds, with probability at least 1 − O(n−2), at
most O(logn) light edges have higher weight than (u,væˆ ). By a simple Union Bound, with probability at least 1 − O(n−1/3 logn), no edge observed in I is among the O(logn) light edges of highest
weight. Thus, with high probability, (u,vi ) and (u	
,vi ) will both be picked, precluding the later
inclusion of (u,u	
).
Journal of the ACM, Vol. 65, No. 6, Article 35. Publication date: November 2018.
Matroid Secretary Problems 35:25
Finally, it remains to show the existence of the pair (u,vi ), (u	
,vi ) with high probability. For any
i, let Ei be the event that both (u,vi ), (u	
,vi ) are observed in I. The probability of Ei is at least
(|I |
2) / (n
2) = Ω(n−2/3). Thus, the expected number of Ei happening is Ω(n1/3). The events {Ei | i =
1,...,n} are negatively associated (see Dubhashi and Panconesi (2009)); it is an easy consequence
of Dubhashi and Panconesi (2009, Problem 3.1) (and proved in detail in Abraham et al. (2015))
that the bounds of Theorem 8.5 apply in this case. Thus, the probability that no Ei happens is
exponentially small.