We introduce a fully online model of maximum cardinality matching in which all vertices arrive online. On
the arrival of a vertex, its incident edges to previously arrived vertices are revealed. Each vertex has a deadline
that is after all its neighbors’ arrivals. If a vertex remains unmatched until its deadline, then the algorithm
must irrevocably either match it to an unmatched neighbor or leave it unmatched. The model generalizes the
existing one-sided online model and is motivated by applications including ride-sharing platforms, real-estate
agency, and so on.
We show that the Ranking algorithm by Karp et al. (STOC 1990) is 0.5211-competitive in our fully online
model for general graphs. Our analysis brings a novel charging mechanic into the randomized primal dual
technique by Devanur et al. (SODA 2013), allowing a vertex other than the two endpoints of a matched edge
to share the gain. To our knowledge, this is the first analysis of Ranking that beats 0.5 on general graphs in
an online matching problem, a first step toward solving the open problem by Karp et al. (STOC 1990) about
the optimality of Ranking on general graphs. If the graph is bipartite, then we show a tight competitive ratio
≈0.5671 of Ranking. Finally, we prove that the fully online model is strictly harder than the previous model
as no online algorithm can be 0.6317 < 1 − 1
e -competitive in our model, even for bipartite graphs.
CCS Concepts: • Theory of computation → Online algorithms;
Additional Key Words and Phrases: Online matching, ranking
1 INTRODUCTION
Online Bipartite Matching is a central problem in the area of online algorithms with a wide range
of applications. Consider a bipartite graph where the left-hand side is known in advance, while
vertices on the right-hand side arrive online in an arbitrary order. On the arrival of a vertex, its incident edges are revealed and the algorithm must irrevocably either match it to one of its unmatched
neighbors or leave it unmatched. Karp et al. [17] introduced the Ranking algorithm, which picks
at the beginning a random permutation over offline vertices and matches each online vertex to
the first unmatched neighbor according to the permutation. Further, they proved that Ranking is
(1 − 1
e )-competitive and the best possible among online algorithms. The analysis of Ranking has
been subsequently simplified in a series of papers [5, 11, 14]. Further, it has been generalized to
several extended settings, including the vertex-weighted case [2], the random arrival model [15,
16, 18], and the Adwords problem [6, 10, 20].
However, all the above successful applications of Ranking crucially rely on the assumption that
one side of the bipartite graph is known upfront. This assumption prevents us from applying the
known positive results to some applications. Here is an example:
Example (Real Estate Agency). During a typical day of a real estate agent in Hong Kong,
both tenants and landlords drop by in an online fashion. Tenants specify what kinds of apartments they are looking for as well as the deadlines before which they need to move in.1
Similarly, landlords list certain rules for tenant screening together with their deadlines. Tenants and landlords can be modeled as the vertices in a bipartite graph. There is an edge
between a tenant-landlord pair if (1) they mutually satisfy each other’s conditions, and (2)
their time windows (between their respective arrivals and deadlines) overlap. Real estate
agents charge for each successful deal and, thus, seek to maximize the size of the bipartite
matching.
This is clearly a bipartite matching problem with an online nature. However, it does not fit
into the existing model in two fundamental ways. First, vertices from both sides of the bipartite
graphs arrive online. Second, matching decision of each vertex is made at its deadline rather than
its arrival. There are many other applications with similar flavors such as job market intermediary
and organ transplantation.
A Fully Online Model. Motivated by these applications, we formulate the following alternative
online model of bipartite matching. We call it Fully Online Bipartite Matching, since vertices from
both sides arrive online. Let there be an underlying bipartite graph that is completely unknown to
the algorithm at the beginning. Each time step falls into one of the following two kinds:
• Arrival of v: A vertex v arrives; edges between v and previously-arrived vertices are
revealed.
• Deadline of v: This is the last time a vertex v can be matched (if it is not matched yet).
The model further guarantees that all edges incident to a vertex are revealed before its deadline.
Indeed, a tenant-landlord pair must have overlapping time windows to have an edge between
them in the above example. We further assume without loss of generality that algorithms are lazy
in the sense that they only make decisions on the deadlines of the vertices. On the deadline of a
vertex v, it might be the case that v has already been matched to another vertex u on u’s deadline.
1Tenants may also specify their earliest move-in dates. This is omitted in our model, because from the algorithmic point
of view, it is equivalent to having each tenant arrive on the earliest move-in date. The same applies to landlords.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.
Fully Online Matching 17:3
Otherwise, the algorithm must irrevocably either match v to one of its unmatched neighbors, or
leave it unmatched.
The previous one-sided online model is a special case in which all offline vertices arrive at the
beginning and have deadlines at the end, and each online vertex has its deadline right after arrival.
Further, there are many applications for which the underlying graph is not necessarily bipartite.
Consider the following example:
Example (Ride-sharing Platform). DiDi is a major ride-sharing platform in China, handling
tens of millions of rides on a daily basis. Requests are submitted to the platform in an online
fashion. Each request is active in the system for a few minutes. The platform may match a pair
of requests and serve them with the same taxi (or self-employed driver), provided that the pickup locations and destinations are compatible, and their active time windows overlap. Requests
can be modeled as vertices in a general graph and the compatibilities of pairs of requests can
be modeled as edges.
Our model generalizes straightforwardly to general graphs by removing the bipartite assumption on the underlying graph. We refer to the generalization as Fully Online Matching.
It is easy to check that the naïve greedy algorithm that simply matches a vertex to an arbitrary
unmatched neighbor remains to be 0.5-competitive. Can we do better?
1.1 Our Results and Techniques
We consider a natural generalization of the Ranking algorithm that picks a random permutation
over all vertices at the beginning, and matches each vertex (if unmatched at its deadline) to the
first unmatched neighbor according to the permutation. This algorithm can be implemented in our
fully online model following the interpretation of Ranking by Devanur et al. [11]: On the arrival of
v ∈ V , the rank of vertex v, denoted by yv , is chosen uniformly at random from [0, 1); each vertex
(if unmatched at its deadline) is matched to its unmatched neighbor with the highest, i.e., smallest,
rank. We show that the Ranking algorithm is strictly better than 0.5-competitive:
Theorem 1.1. Ranking is 0.5211-competitive for Fully Online Matching.
Theorem 1.2. Ranking is 0.5671-competitive for Fully Online Bipartite Matching.
To our knowledge, our result for the Fully Online Matching problem is the first generalization
of Ranking that achieves a competitive ratio strictly better than 0.5 in an online matching model
that allows general graphs, making the first step towards providing a positive answer to the open
question of whether Ranking is optimal for general graphs by Reference [17].
Our Techniques (Bipartite Case). We build on the randomized primal dual technique introduced
by Devanur et al. [11]. It can be viewed as a charging argument for sharing the gain of each matched
edge between its two endpoints. Whenever an edge (u,v) is added to the matching, where v is an
offline vertex and u is an online vertex, imagine a total gain of 1 being shared between u and v
based on the rank of the offline vertex v. The higher the rank of v, the smaller share it gets. For
Online Bipartite Matching, Devanur et al. [11] introduced a gain sharing method such that, for
any edge (u,v) and for any fixed ranks of offline vertices other than v, the expected gains of u and
v (from all of their incident edges) combined is at least 1 − 1
e over the randomness of v’s rank. This
implies the 1 − 1
e competitive ratio.
Next, consider an edge (u,v) in our model. Suppose u is the one with an earlier deadline. Since
algorithms are lazy, the edge can only be added into the matching as a result of u’s decision at its
deadline. In this sense, u plays a similar role as the online vertex and v as the offline vertex in the
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.
17:4 Z. Huang et al.
analysis of Devanur et al. [11]. Hence, a natural attempt is to consider the expected gains of u and
v combined in the charging argument over the randomness of v’s rank alone.
To explain why the above approach fails, we first introduce the notions of active and passive
vertices. We say a vertex u matches actively (or is active) if it is added to the matching by the
algorithm at u’s deadline; other matched vertices are passive. All previous analyses [1, 2, 8, 11, 17]
crucially rely on a structural property that whenever vertex v is unmatched, its neighbor u must
be matched to some other vertex with rank higher than v. In our model, however, this holds only
if v’s neighbor u is active.
One may try to resolve this issue with a global amortization argument. If we go over all the
edges in the graph, then it cannot be the case that the endpoint with an earlier deadline of every
edge always matches passively. After all, the numbers of active and passive vertices are equal. Interestingly, we instantiate this intuition with a local amortization argument by taking expectation
over the randomness of u’s rank as well. Recall that u is the vertex with earlier deadline and, thus,
plays a similar role as the online vertex in the argument of Devanur et al. [11]. Taking expectation
over u’s rank can be viewed as amortizing the case when u’s rank is low (active) and the case when
u’s rank is high (passive).
Our Techniques (General Case). Moving from bipartite graphs to general graphs takes away another crucial structural property that the previous arguments rely on. In a bipartite graph, if a
vertex u is matched by the Ranking algorithm for a realization of ranks while one of its neighbors v is not, then u remains matched no matter how the rank of v changes. In a general graph,
however, it is possible that u becomes unmatched when v gets a higher rank.
We introduce a novel charging mechanic on top of the gain sharing rule used in the bipartite
case. After a matching has been chosen by Ranking, for each active vertex w, consider an alternative run of Ranking with the same ranks but with w removed from the graph. The difference
between the two matchings will be an alternating path and, thus, at most one vertex v would
change from unmatched to matched in the absence of w. We shall refer to such a vertex v as the
victim ofw. Note that each active vertex has at most one victim, but an unmatched vertex could be
the victim of many vertices. If the victim ofw turns out to be its neighbor,2 then our new charging
mechanic will have w send to v a portion of w’s share from its incident edge in the matching,
which we shall refer to as the compensation from w to v. Further, we show that whenever the
aforementioned structural property fails, namely, some vertex u becomes unmatched when its unmatched neighbor v gets a higher rank, we can always identify a unique neighbor w of v that
sends a compensation to v to remedy the loss in the charging argument.
Putting together the gain sharing mechanic from the bipartite case and the new mechanic of
compensations, we can prove that for any edge (u,v), the expected net gains of u and v combined
is strictly greater than 0.5 over the randomness of the ranks of both u and v.
To our knowledge, this is the first charging mechanic that allows a vertex other than the two
endpoints of a matched edge to get a share. We believe this novel charging mechanic will find
further applications in other matching problems that consider general graphs.
Hardness Results. We complement our competitive analysis with two hardness results. The first
hardness applies to arbitrary online algorithms, showing a separation between the best competitive
ratio in our fully online model and the optimal ratio of 1 − 1
e ≈ 0.6321 in the existing one-sided
online model. The second hardness focuses on the Ranking algorithm, certifying that our analysis
for the bipartite case is tight.
2This would induce an odd cycle and, thus, can only happen in non-bipartite graphs.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.
Fully Online Matching 17:5
Theorem 1.3. No randomized algorithm can achieve a competitive ratio better than 0.6317 for
Fully Online Bipartite Matching.
Theorem 1.4. Ranking is at most 0.5671-competitive for Fully Online Bipartite Matching.
1.2 Other Related Works
An alternative generalization of Ranking to general graphs has been considered for the problem
of oblivious matching [1, 8]: Pick a permutation of vertices uniformly at random; then, go over
the vertices one by one according to the permutation; for each unmatched vertex, match it to
the first unmatched neighbor according to the same permutation. Chan et al. [8] showed that
it is a 0.523-approximation algorithm. Abolhassani et al. [1] further improved the ratio to 0.526
and analyzed the vertex-weighted case. We stress that the alternative generalization is an offline
algorithm, because it needs to consider the vertices in random order, while our generalization is
online. Nevertheless, our result for general graphs can be viewed as a 0.5211-approximation in the
oblivious matching problem. The oblivious matching problem was originally studied by Aronson
et al. [3]. They proposed another greedy algorithm and proved it is ( 1
2 + 1
400000 )-approximate. The
analysis of the same algorithm is improved to 0.504 by Poloczek and Szegedy [21] and to 0.531 by
Tang et al. [22].
Another online matching model in the literature considers online edge arrivals, upon which
the algorithm must immediately decide whether to add the edge to the matching. McGregor [19]
gave a deterministic 1
3+2
√
2 ≈ 0.1715-competitive algorithm in the edge-weighted preemptive setting. This ratio is later shown to be tight for deterministic algorithms [23]. Epstein et al. [12] designed a 1
5.356 ≈ 0.1867-competitive randomized algorithm for edge-weighted graphs and proved
a hardness of 1
1+ln 2 ≈ 0.59 for unweighted graphs. Chiplunkar et al. [9] considered a restricted
setting where the input graph is an unweighted growing tree and gave a 15
28 -competitive algorithm. Finally, Buchbinder et al. [7] introduced an optimal 5
9 -competitive algorithm for unweighted
forests.
Wang and Wong [24] considered a more restrictive model of online bipartite matching with both
sides of vertices arriving online: A vertex can only actively match other vertices at its arrival; if it
fails to match at its arrival, it may still get matched passively by other vertices later. They showed
a 0.526-competitive algorithm for a fractional version of the problem. Recently, Gamlath et al. [13]
gave a 0.5 + Ω(1)-competitive algorithm for the integral version of the problem. Their model is
harder than the fully online model, since any algorithm in their setting can be applied in the fully
online model and the competitive ratio is preserved. We argue that the model in this article better
captures our aforementioned motivating applications.
Simultaneous to the conference version of the article, an edge-weighted variant of Fully Online Matching has been studied by Ashlagi et al. [4], considering the “windowed” version of the
problem, motivated by the ride-sharing applications.
2 PRELIMINARIES
We consider the standard competitive analysis against an oblivious adversary. The competitive
ratio of an algorithm is the ratio between the expected size of the matching by the algorithm over
its own random bits to the size of the maximum matching of the underlying graph in hindsight.
The adversary must in advance choose an instance, i.e., the underlying graph as well as arrivals
and deadlines of vertices, without observing the random bits used by the algorithm. Otherwise, no
algorithm can get any competitive ratio better than 0.5.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.
17:6 Z. Huang et al.
2.1 Ranking Algorithm and Some Basic Properties
See Algorithm 1 for a formal definition of Ranking in our model. Note that when we define N (v),
we only consider the vertices whose deadlines are later than v’s deadline. Let M(y) denote the
matching produced when Ranking is run with y as the ranks.
ALGORITHM 1: The Ranking Algorithm
(1) a vertex v arrives:
pick yv ∈ [0, 1) uniformly at random.
(2) a vertex v’s deadline reaches:
if v is unmatched,
let N (v) be the set of unmatched neighbors of v.
if N (v) = ∅, then v remains unmatched;
else match v to arg minu ∈N (v) yu .
Recall the following definition of active/passive vertices. In the one-sided online model, only
online vertices can be active and only offline vertices can be passive. In our fully online model,
however, vertices can in general be of either types depending on the random ranks of the vertices.
Definition 2.1 (Active, Passive). For any edge (u,v) added to the matching by Ranking at u’s
deadline, we say that u is active and v is passive.
The following lemma is a variant of the monotonicity property in previous works, incorporating
the notions of active and passive vertices in our fully online model.
Lemma 2.2 (Monotonicity). For any rank vector y and any vertex u, we have
(1) if u is active/unmatched, then M(y) remains the same when yu increases;
(2) if u is passive, then u remains passive when yu decreases.
Proof. For the first statement, since u is active or unmatched, we know that for each neighbor
v of u with an earlier deadline than u, v does not match u in M(y) at their deadlines. Hence, when
yu increases, they would make the same decision. In other words, when u’s deadline reaches,
the partial matching produced is the same as before. As a consequence, the eventual matching
produced would be identical, as u will actively match the same vertex as in M(y).
The second statement is implied by the first statement. Suppose otherwise, e.g., u is active or
unmatched when yu is decreased from y to some y < y. Then, we know that by increasing yu
from y to y, u becomes passive, which violates the first statement.
Let y-u ∈ [0, 1)
V \ {u } be the ranks of all vertices but u, i.e., y-u is obtained by removing the uth
entry in y. Let M(y-u ) denote the matching produced by Ranking on G − {u}, i.e., the subgraph
with vertex u removed, with y-u as the ranks.
For ease of notation, for any y ∈ [0, 1], we use y- to denote a value that is arbitrarily close to, but
smaller than y. For example, our arguments consider functions discontinuous at 1 and use f (1-
)
to denote the limit of f (x) as x goes to 1 from below. We also consider the matching w.r.t. ranks
(yu = θ-
,y-u ) to avoid confusions in marginal cases where ranks (yu = θ,y-u ) need tie-breaking.
By Lemma 2.2, we can uniquely define the following marginal rank for every vertex.
Definition 2.3 (Marginal Rank). For any u and any ranks y-u of other vertices, the marginal rank
θ of u with respect to y-u is the largest value such that u is passive in M(yu = θ-
,y-u ). If u is never
passive in all M(yu,y-u ), then the marginal rank θ is defined to be 0.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.                  
Fully Online Matching 17:7
Note that a vertex may still match another vertex (actively) when its rank is below the marginal
rank in our fully online model. Nevertheless, it is consistent with the previous definition in the
one-sided online model that concerns offline vertices, which cannot match actively.
Lemma 2.4 (Unmatched Neighbor). Supposev has marginal rank θ < 1with respect toy-v . Then,
for any neighbor u of v that has an earlier deadline than v, and for any rank vector (yv = y,y-v ) with
y ∈ [θ, 1), u either is passive, or actively matches a vertex with rank at most θ.
Proof. Consider the matching M(yv = θ,y-v ). By definition, v is either active or unmatched.
Hence, at u’s deadline, which is earlier than v’s deadline, v is unmatched. Consequently, u either is
passive or matches actively to some vertex w with yw ≤ yv = θ. By Lemma 2.2, there is no change
in the matching when we increase yu , which concludes the proof.
It is well known that removing a matched vertex from the graph results in an alternating path in
the matching produced by Ranking. The next lemma provides a more fine-grained characterization.
We first introduce the concept of “better” and “worse” of the matching status of a vertex. We
consider that passive is better than active, which is in turns better than unmatched. Conditioned
on being passive, matching to a vertex with earlier deadline is better. Conditioned on being active,
matching to a vertex with higher rank is better.
Lemma 2.5 (Alternating Path). If u is matched in M(y), then the symmetric difference between
the matchings M(y) and M(y-u ) is an alternating path (u0,u1,...,ul ) with u0 = u such that
(1) for all even i < l, we have (ui,ui+1) ∈ M(y); for all odd i < l, we have (ui,ui+1) ∈ M(y-u );
(2) from M(y) to M(y-u ), vertices {u1,u3,...} get worse, vertices {u2,u4,...} get better.
Proof. We prove the lemma by mathematical induction on n, the total number of vertices. For
the base case when n = 2, the symmetric difference is a single edge (u,u1) and the second statement
holds, since u1 is matched in M(y) and unmatched in M(y-u ).
Suppose the lemma holds for 1, 2,...,n − 1 and we consider the case when |V | = n.
Let u1 be matched to u in M(y). Observe that if we remove both u and u1 from G (let y ∈
[0, 1]V \ {u,u1 } be the resulting vector), then we have M(y) = M(y) ∪ {(u,u1)}.
If u1 is unmatched in M(y-u ), then we have M(y-u ) = M(y) and the lemma holds by induction
hypothesis. Now suppose u1 is matched in M(y-u ).
By definition y is obtained by removing u1 (which is matched in y-u ) from y-u . By induction
hypothesis, the symmetric difference between M(y-u ) and M(y) is an alternating path (u1,...,ul )
such that (a) for all odd i < l, we have (ui,ui+1) ∈ M(y-u ); for all even i < l, we have (ui,ui+1) ∈
M(y); (b) from M(y-u ) to M(y), vertices {u2,u4,...} get worse, vertices {u3,u5,...} get better.
Hence, the symmetric difference between M(y) and M(y-u ) is the alternating path (u,u1,...,ul )
(recall that M(y) = M(y) ∪ {(u,u1)}). Statement (a) holds, and statement (b) holds for vertices
{u2,...,ul}.
Now consider vertex u1, which is matched to u in M(y), and matched to u2 in M(y-u ).
If u1 is passively matched (by u) in M(y), then we know that u has an earlier deadline than u1.
Hence, in M(y-u ), either u1 is active, or passively matched by some u2 with a deadline later than
u. In other words, u1 gets worse from M(y) to M(y-u ).
If u1 matches u actively in M(y), then we know that u1 has an earlier deadline than u. Hence,
when u1 is considered in y-u , the set of unmatched vertices (except for u) is identical as in M(y).
Consequently, u1 actively matches some vertex u2 with yu2 > yu (otherwise, u1 will not match u
in M(y)). In other words, u1 gets worse from M(y) to M(y-u ).
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.                                               
17:8 Z. Huang et al.
2.2 Randomized Dual Fitting
Consider the following linear program relaxation of the matching problem and its dual:
max :
(u,v)∈E xuv min :
u ∈V αu
s.t.
v:(u,v)∈E xuv ≤ 1 ∀u ∈ V s.t. αu + αv ≥ 1 ∀(u,v) ∈ E
xuv ≥ 0 ∀(u,v) ∈ E, αu ≥ 0 ∀u ∈ V .
It is known that the above linear program relaxation is integral for bipartite graphs, but it has
an integrality gap of 2
3 for general graphs (e.g., a complete graph of three vertices). Interestingly,
this relaxation is sufficient for proving our positive results, even for general graphs.
Our approach builds on the randomized primal dual technique by Devanur et al. [11]. We believe
it is more appropriate to call our analysis (for general graphs) randomized dual fitting, however,
because it relies on an extra phase of adjustments to the dual variables at the end that requires full
knowledge of the instance.
Randomized Dual Fitting. We set the primal variables according to the matching by Ranking,
which ensures primal feasibility, and set the dual variables such that the dual objective equals the
primal objective. The dual assignment can be viewed as splitting the gain of 1 of every matched
edge among the vertices; the dual variable αv for every vertex v is equal to the total share it
gets from all matched edges. Given primal feasibility and equal objectives, the usual primal dual
and dual fitting techniques would further seek to show approximate dual feasibility, namely,
αu + αv ≥ F for every edge (u,v) where F is the target competitive ratio. This is where the usual
techniques fail and the smart insight by Devanur et al. [11] comes to help. Due to the intrinsic
randomness of Ranking, the above primal and dual assignments are themselves random variables.
Devanur et al. [11] observe that it suffices to have approximate dual feasibility in expectation. For
completeness, we formulate this insight as the following lemma.
Lemma 2.6. Ranking is F -competitive if we can set (non-negative) dual variables such that
(1)
(u,v)∈E xuv =
u ∈V αu ; and
(2) Ey[αu + αv ] ≥ F for all (u,v) ∈ E.
Proof. Let α˜u := Ey [αu ] /F for all u ∈ V . By the first assumption,

u ∈V
α˜u =

u ∈V
Ey [αu ]
F = 1
F
E
y
⎡
⎢
⎢
⎢
⎢
⎣

u ∈V
αu
⎤
⎥
⎥
⎥
⎥
⎦
= 1
F
E
y
⎡
⎢
⎢
⎢
⎢
⎢
⎣

(u,v)∈E
xuv
⎤
⎥
⎥
⎥
⎥
⎥
⎦
.
Moreover, α˜ is a feasible dual solution: by the second assumption, α˜u + α˜v = Ey [αu + αv ] /F ≥
1 for all (u,v) ∈ E. By duality, we conclude that
1
F
E
y
⎡
⎢
⎢
⎢
⎢
⎢
⎣

(u,v)∈E
xuv
⎤
⎥
⎥
⎥
⎥
⎥
⎦
=

u ∈V
α˜u ≥ OPT,
where OPT is the optimal primal solution, which is at least the size of a maximum matching.
3 BIPARTITE GRAPHS
Dual Assignment. We adopt the dual assignment by Devanur et al. [11] and share the gain of each
matched edge between its two endpoints as follows:
• Gain Sharing: Whenever an edge (u,v) is added to the matching withu active andv passive,
let αu = 1 − д(yv ) and αv = д(yv ). Here, д : [0, 1] → [0, 1] is non-decreasing with д(1) = 1.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.                   
Fully Online Matching 17:9
Randomized Primal Dual Analysis. The previous analysis of Ranking for Online Bipartite Matching relies on a structural property that for any edge (u,v) and any ranks y-v , u matches a vertex
with rank no lower than v’s marginal rank regardless of v’s rank (e.g., Lemma 2.3 of Reference
[11]). However, in our fully online setting, the same property holds only when u is active. By introducing the notions of passive and active vertices, we show the following weaker version of the
property. It complements the basic property whenyu is larger than the marginal rank (Lemma 2.4).
Lemma 3.1. Suppose v has marginal rank θ < 1 with respect to y-v . Then, for any neighbor u of v
that has an earlier deadline than v, and for any rank vector (yv = y,y-v ) with y ∈ [0, θ ), u either is
passive, or matches actively to a vertex with rank at most θ.
Proof. We consider the matchings in three sets of ranks y = (yv = y,y-v ), y-v , and yθ = (yv =
θ,y-v ). First, we show thatu matches the same neighbor in M(yθ ) and M(y-v ). Sincev is unmatched
or active in M(yθ ), removing v cannot affect vertices with earlier deadlines. In particular, u would
match the same neighbor.
Consider the alternating path from M(y) to M(y-v ). If u is not in the alternating path, then u
matches the same neighbor in all M(y), M(y-v ) and M(yθ ). Otherwise, u appears in the alternating
path with an odd distance from v, since the graph is bipartite. Hence, by Lemma 2.5, u is better
in M(y) than in M(y-v ) and, thus, is better than in M(yθ ). In both cases, u is passive or actively
matches a vertex with rank ≤ θ in M(y), since this holds for u in M(yθ ) (by Lemma 2.4).
3.1 Warm-up
Equipped with the above lemma, we first give a warm-up analysis that gives strictly larger than
0.5 ratio of the Ranking algorithm. Further, we make a comparison with the previous analysis by
Devanur et al. [11] to highlight our new idea.
Recall that for any edge (u,v), we will consider the expected gain of αu and αv combined over
the randomness of the ranks of both u andv. First, let us fix the rank of u, the vertex with an earlier
deadline, and consider the expected gain over the randomness of v’s rank alone.
Lemma 3.2. For any neighbor u of v that has an earlier deadline than v, and for any y-v , we have
Eyv [αu + αv ] ≥ f (yu )
def
= minθ ∈[0,1]  θ
0 д(yv )dyv + min{1 − д(θ ),д(yu )}

.
Proof. Let θ be the marginal rank of v with respect to ranks y-v . By definition, v is passive and gets д(yv ) when yv < θ, i.e., Eyv [αv · 1 (yv < θ )] =  θ
0 д(yv )dyv . By Lemma 2.4 and 3.1,
Eyv [αu ] ≥ min{1 − д(θ ),д(yu )}. Adding them together and taking the minimum over all possible
θ’s concludes the statement.
It is worthwhile to make a comparison with a similar claim in the previous analysis by Devanur
et al. [11] for Online Bipartite Matching:
Eyv [αu + αv ] ≥ minθ ∈[0,1]  θ
0 д(yv )dyv + 1 − д(θ )

,
where u is an online vertex and v is an offline vertex. As we have discussed in the introduction, for
every edge in our model, the endpoint with an earlier deadline plays a similar role as the online
vertex in the previous one-sided online model, since the edge can only be added to the matching
as a result of this endpoint’s matching decision. In this sense, the bounds are indeed very similar,
except for the last term, where the previous bound simply has 1 − д(θ ) while our bound has the
smaller of 1 − д(θ ) and д(yu ).
We interpret Lemma 3.2 as follows. It recovers the previous bound when the rank of u is large
(1 − д(θ ) ≤ д(yu )), which roughly corresponds to the case when u is active (or unmatched) and the
previous structural property holds. When the rank of u is small (1 − д(θ ) > д(yu )), which roughly
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.                         
17:10 Z. Huang et al.
corresponds to the case when u is passive, it still provides some weaker lower bound on the expected gains of the two endpoints. The weaker bound, however, is at most 0.5 in the worst case:
the right-hand side (RHS) becomes min{1 − д(0),д(0)} ≤ 0.5 for θ = yu = 0. Hence, it is crucial
that we take expectation over the randomness of u’s rank as well, effectively amortizing the cases
when u is active and when it is passive. This idea carries over to general graphs.
To finish the competitive analysis of Ranking, it suffices to pick a functionд so that E[αu + αv ] ≥
 1
0 f (yu )dyu > 0.5. In the conference version (STOC 2018) of the article, it is shown that д(x) =
ex−1 gives ratio 0.554. Since we are going to present a tight analysis in the following subsection,
we omit the calculation here.
3.2 Tight Analysis
In this subsection, we carefully characterize the matching status of u,v in all regimes of yu,yv and
derive tight ratio of Ranking on bipartite graphs. We first fix an arbitrary assignment of ranks to
all vertices but u,v. We denote this assignment of ranks by y-uv . Unless otherwise specified, we
use E [·] to denote the expectation taken over the randomness of yu and yv .
Definition 3.3 (τ and γ ). Consider the graph G − {v} with v removed. Let τ be the marginal
rank of u w.r.t. y-uv . Similarly, let γ be the marginal rank of v w.r.t. y-uv in graph G − {u}, i.e., with
u removed.
The total expected gain of αu and αv shall be split into two parts in Lemma 3.7 and the following
two lemmas lower bound the two parts, respectively.
Lemma 3.4. E [αu · 1(yu < τ ) + αv · 1(yv < γ )] ≥  τ
0 д(yu )dyu +
 γ
0 д(yv )dyv
Proof. Consider yu = y < τ . By definition of τ , we know that for all yv ∈ [0, 1], u is passive in
M(yu = y,yv ,y-uv ), because inserting v (with any rank) to the graph creates a (possibly empty)
alternating path, which cannot make u worse (by Lemma 2.5). Thus, for all yu < τ and yv ∈ [0, 1],
we have αu = д(yu ), which correspond to the first term of the RHS.
For the same reason, for all yu ∈ [0, 1], v is passive in M(yv < γ ,yu,y-uv ), which gives αv =
д(yv ), and the second term of the RHS.
For all yu ∈ [0, 1], let θ (yu ) be the marginal rank of v w.r.t. y-v = (yu,y-uv ). Recall that since v
is always passive (regardless of the rank of u) when yv < γ , we have θ (yu ) ≥ γ for all yu ∈ [0, 1].
Lemma 3.5. For any fixed yu > τ , we have
E
yv
[αu + αv · 1(yv > γ )] ≥ 1 −γ − (1 − θ (yu )) · д(θ (yu )) +γ · min{д(yu ), 1 − д(θ (yu ))}.
Proof. We prove the following three statements sequentially:
• when yv ∈ (θ (yu ), 1], αu ≥ 1 − д(θ (yu ));
• when yv ∈ (0, τ ), αu ≥ min{д(yu ), 1 − д(θ (yu ))};
• when yv ∈ (τ , θ (yu )), αu + αv ≥ 1.
By definition of θ (yu ), we know that when yv = θ (yu )
+ (slightly larger than θ (yu )), v is not
passive, thus u must be matched. Moreover, u must be active, as otherwise u should remain passive
when v is removed, which contradicts the definition of τ (recall that we consider yu > τ ).
Hence, when yv = θ (yu )
+, u is actively matched to some vertex with rank at most θ (yu ) (as
when u is matched, v is still unmatched). Thus, for all yv > θ (yu ), we have αu ≥ 1 − д(θ (yu )), as
increasing the rank of v does not affect u, which has an earlier deadline.
Note that it is possible that θ (yu ) = 1, i.e., v is passive for all rank yv ∈ [0, 1], in which case the
above lower bound still holds, since д(1) = 1.
Next, we show that when yv < γ , we have αu ≥ min{д(yu ), 1 − д(θ (yu ))}.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.        
Fully Online Matching 17:11
The statement trivially holds when θ (yu ) = 1. For θ (yu ) < 1, we know that when v is removed,
u is actively matched to some vertex with rank at most θ (yu ). Thus, inserting v is only beneficial
for u, which implies αu ≥ min{д(yu ), 1 − д(θ (yu ))}.
Finally, we show that for any yv ∈ (γ , θ (yu )), we have αu + αv ≥ 1.
Fix some yv ∈ (γ , θ (yu )). By definition v is passive and αv = д(yv ). Consider the first moment
when one of u,v is matched.
Suppose at this moment, v is matched passively by some z. Then, we show that z = u, which
gives αu + αv = 1. Suppose otherwise, then z must have a deadline earlier than u. Then, we know
that v remains passive with u removed, which contradicts the definition of γ .
Suppose at this moment, u is matched with some z. Since by definition v is not matched at this
moment, the rank of z is no more than yv , which implies αu ≥ 1 − д(yv ) = 1 − αv , as required.
To sum up, we have
E
yv
[αu + αv · 1(yv > γ )] ≥
 γ
0
αudyv +
 θ (yu )
γ
(αu + αv )dyv +
 1
θ (yu )
αudyv
≥γ · min{д(yu ), 1 − д(θ (yu ))} + (θ (yu ) −γ ) + (1 − θ (yu )) · (1 − д(θ (yu )))
≥1 −γ − (1 − θ (yu )) · д(θ (yu )) +γ · min{д(yu ), 1 − д(θ (yu ))},
as claimed.
Lemma 3.6. There exists θ such that θ (yu ) = θ for all yu > τ .
Proof. Consider the graph with v removed, and let yu = τ +. By definition, u is not passive.
If u is unmatched, then we know that for all yv ∈ [0, 1], v is passive, as otherwise u will be
matched with v removed. Hence, we have θ (yu ) = 1 for all yu > τ .
Otherwise, u must be active. Let θ = θ (τ +). Then, we know that v is active when we insert v
with yv = θ+ to the graph. Since increasing yu does not change the matching, we have θ (yu ) ≤ θ
for all yu > τ . However, as we have shown in the proof of Lemma 3.5, when yv = θ- and yu = τ +,
u is active and v is passive. Since increasing yu does not change the matching, we have θ (yu ) ≥ θ
for all yu > τ , which implies θ (yu ) = θ for all yu > τ .
Finally, we combine the previous lemmas and derive a lower bound of E [αu + αv ].
Lemma 3.7. For any neighbor u of v that has an earlier deadline than v, and for any y-uv , we have
E [αu + αv ] ≥ min τ,0≤γ ≤θ ≤1
⎧⎪
⎨
⎪
⎩
 τ
0
д(yu )dyu +
 γ
0
д(yv )dyv + (1 − τ )(1 −γ − (1 − θ ) · д(θ ))
+γ ·
 1
τ
min{1 − д(θ ),д(yu )}dyu
⎫⎪
⎬
⎪
⎭
.
Proof. According to Lemma 3.6, let θ be the common marginal rank of v for all yu > τ . Combining Lemmas 3.4 and 3.5, we have
E [αu + αv ] ≥ E [αu · 1(yu < τ ) + αv · 1(yv < γ )] +
 1
τ
Eyv [αu + αv · 1(yv > γ )]dyu
=
 τ
0
д(yu )dyu +
 γ
0
д(yv )dyv +
 1
τ

1 −γ − (1 − θ ) · д(θ ) +γ · min{д(yu ), 1 − д(θ )}
	
dyu
=
 τ
0
д(yu )dyu +
 γ
0
д(yv )dyv + (1 − τ ) ·


1 −γ − (1 − θ ) · д(θ )

+γ ·
 1
τ
min{д(yu ), 1 − д(θ )}dyu .
Taking minimum over τ and γ ≤ θ gives Lemma 3.7.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.    
17:12 Z. Huang et al.
Proof of Theorem 1.2. Let Ω be the Omega constant, i.e., solution of x · ex = 1. Fix
д(y) =
⎧⎪⎪
⎨
⎪⎪
⎩
c
1−y , when y < 1−2c
1−c ,
1 − c, when 1−2c
1−c ≤ y < 1,
1, when y = 1,
where c = 1
1+eΩ ≈ 0.3619. Let f (τ ,γ , θ ) denote the expression to be minimized on the RHS of
Lemma 3.7. Recall that we have θ ≥ γ . Then, we have
f (τ ,γ , θ ) =
 τ
0
д(yu )dyu +
 γ
0
д(yv )dyv + (1 − τ )

1 −γ − (1 − θ ) · д(θ )
	
+γ ·
 1
τ
min{д(yu ), 1 − д(θ )}dyu .
Fix any γ and θ, and suppose д(τ ) < 1 − д(θ ), then observe that
∂f (τ ,γ , θ )
∂τ = д(τ ) − (1 −γ − (1 − θ ) · д(θ )) −γ · min{д(τ ), 1 − д(θ )}
= (1 −γ ) · д(τ ) − (1 −γ ) + (1 − θ ) · д(θ ) < (γ − θ ) · д(θ ) ≤ 0.
Thus, the minimum of f (τ ,γ , θ ) over τ ∈ [0, 1], 0 ≤ γ ≤ θ ≤ 1 must be obtained when д(τ ) ≥
1 − д(θ ), in which case we have
f (τ ,γ , θ ) =
 τ
0
д(yu )dyu +
 γ
0
д(yv )dyv + (1 − τ )

1 − (1 − θ +γ ) · д(θ )
	
.
If we relax the constraint that θ ≥ γ , then the maximum of (1 − θ +γ )д(θ ) is achieved when
θ ∗ = 1−2c
1−c (for which д(θ ∗) = 1 − c). Note that the maximum is ( c
1−c +γ ) · (1 − c) = (1 − c) · γ + c,
which is greater than γ , the value of expression when θ = 1. Thus, we have
f (τ ,γ , θ ) ≥ f (τ ,γ , θ ∗) =
 τ
0
д(yu )dyu +
 γ
0
д(yv )dyv + (1 − τ ) · (1 −γ ) · (1 − c).
The minimum of f (τ ,γ , θ ∗) is achieved when γ < θ ∗ = 1−2c
1−c (for which д(γ ) < 1 − c), as otherwise the partial derivative
∂f (τ ,γ , θ ∗)
∂γ = д(γ ) − (1 − τ ) · (1 − c) ≥ 0.
Since f (τ ,γ , θ ∗) is symmetric for τ and γ , the same conclusion holds for τ , which means
f (τ ,γ , θ ∗) =
 τ
0
c
1 − x
dx +
 γ
0
c
1 − x
dx + (1 − τ ) · (1 −γ ) · (1 − c)
= − c ln(1 − τ ) − c ln(1 −γ ) + (1 − τ ) · (1 −γ ) · (1 − c)
≥c − c · ln  c
1 − c
	
= 1 + Ω
1 + eΩ = Ω,
where the inequality comes from the fact that (take (1 − τ ) · (1 −γ ) as the variable) function
(1 − c) · x − c · ln(x) achieves its minimum when x = c
1−c .
4 GENERAL GRAPHS
Dual Assignment. Moving from bipartite graphs to general graphs, even the weaker version of the
structural property, i.e., Lemma 3.4, ceases to hold. Consider an edge (u,v) with u’s deadline being
earlier. It is possible that decreasing yv leads to a change of u’s status from matched to unmatched
in a non-bipartite graph. As a result, the simple gain sharing rule in the previous analysis on the
bipartite case no longer gives any bound strictly better than 0.5.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020. 
Fully Online Matching 17:13
Fig. 1. We use solid line to represent an edge in the matching, where the direction (if any) is from active vertex
to passive vertex. (a) When v is higher than its marginal rank, u matches a vertex with rank yz = τ > θ; (b) v
is unmatched and compensated by w when it is lower than its marginal rank; u either is passive, or matches
actively some vertex with rank higher than τ , since v is unmatched; (c) the symmetric difference between
the two matchings: an alternating path triggered when yv increases to be larger than its marginal rank.
To handle general graphs, we design a novel charging mechanic on top of the gain sharing rule
between the endpoints of matched edges. First, we introduce the following notion of victim.
Definition 4.1 (Victim). For any ranks y and any active vertex w, v is w’s victim if
• v is an unmatched neighbor of w;
• v is matched in M(y-w ).
Observe that removingw results in an alternating path (Lemma 2.5) and, thus, at most one vertex
changes from unmatched to matched. Hence, each active vertex has at most one victim.
Consider the following two-step approach for computing a dual assignment:
• Gain Sharing: Whenever an edge (u,v) is added to the matching withu active andv passive,
let αu = 1 − д(yv ) and αv = д(yv ). Here, д : [0, 1] → [0, 1] is non-decreasing with д(1) = 1.
• Compensation: For every active vertex u that has a victim z, suppose u is matched to v.
Decrease αu and increase αz by the same amount h(yv ), where h : [0, 1] → [0, 1] is nondecreasing in [0, 1), h(y)/y is non-increasing, h(1) = 0 and 1 − д(y) − h(y) ≥ 0 for all y.
Note that the second step, in particular, identifying the victims of active vertices, can only be
done after the entire instance has been revealed.
Each matched vertex will gain only from its incident matched edge. If it is further active and has
a victim, then it needs to send a compensation to the victim. Further, the active vertex can always
afford the compensation from its gain, since 1 − д(y) − h(y) ≥ 0 for ally ∈ [0, 1). The monotonicity
ofh(y)/y is for technical reasons in the analysis. Finally, note that an unmatched vertex may receive
compensations from any number of active vertices.
Randomized Dual Fitting Analysis. The main technical lemma is to establish a lower bound for
Eyv [αu + αv ], as we have done in Lemma 3.2 for bipartite graphs. We first present the analysis
for a special case with following assumptions (θ is the marginal rank of v) to give more intuition:
• v is unmatched in M(yv = y,y-v ) for all y ≥ θ;
• u actively matches the same vertex z with rank yz = τ > θ in M(yv = y,y-v ) for all y < θ.
In other words, any rank of v higher than its marginal rank leads to the same (worse) situation
for u, i.e., matching a vertex with rank τ ∈ (θ, 1). See Figure 1 for an illustrative example.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.    
17:14 Z. Huang et al.
In general, we need to consider the possibility that u’s matching status may change multiple
times as the rank of v gets higher. See Subsection 4.2 for the analysis without the simplifying
assumptions.
4.1 Simplified Case
Subject to the above simplifying assumptions, we show the following:
Lemma 4.2. For any neighbor u of v that has an earlier deadline than v, and for any y-v , we have
Eyv [αv + αu ] ≥
 θ
0 д(yv )dyv + (τ − θ ) · h(θ ) + θ · (1 − д(τ ) − h(τ ))
+ (1 − θ ) · min 
д(yu ), 1 − д(θ ) − h(θ )

.
Suppose w matches actively to v in M(yv = θ-
,y-v ) (refer to Figure 1(a)), that is, it is the first
vertex after v in the alternating path when v’s rank moves below its marginal rank (refer to
Figure 1(c)). We show in the following lemma that v receives a compensation from w whenever
its rank yv is between θ and τ (refer to Figure 1(b)).
Lemma 4.3. For any y ∈ [θ, τ ), v is the victim of w in M(yv = y,y-v ).
Proof. Let y1 = (yv = y,y-v ), where y ∈ [θ, τ ). By our assumption, v is unmatched and, thus,
is an unmatched neighbor of w in M(y1). To prove that v is the victim of w, we need to show that
(1) w is active in M(y1) and (2) v becomes matched when we remove w from the graph.
Consider y2 = (yv = θ-
,y-v ). By our assumptions, v is passively matched to w and u actively
matches z with yz = τ in M(y2). For this to happen, w must have an earlier deadline than v and
none of matching decisions before w’s deadline pick w or v. Then, lowering v’s rank would not
affect these decisions before w’s deadline and, thus, w must also be active in M(y1).
Finally, consider what happens when w is removed from the graph. It triggers a portion of
the alternating path (i.e., Figure 1(c)), the symmetric difference between M(y1) and M(y2). The
portion starts from w (exclusive) and ends the first time when v becomes relevant, i.e., a vertex in
the alternating path decides to pick v instead of the next vertex in the path. Further, we know for
sure that v will be relevant at some point, because otherwise u is in the path and the next vertex
z has rank τ > y. Therefore, v must be matched when w is removed from the graph.
The next two lemmas give lower bounds on the expected gain of αv and αu , respectively, over
the randomness of v’s rank alone. We remark that without the compensation term (τ − θ ) · h(θ )
in the next lemma, the analysis cannot give a ratio that is strictly greater than 1
2 .
Lemma 4.4. Eyv [αv ] ≥  θ
0 д(yv )dyv + (τ − θ ) · h(θ ).
Proof. By definition, when yv < θ, v is passive and, hence, αv = д(yv ).
Since w matches v actively in M(yv = θ-
,y-v ) but not in M(yv = θ,y-v ), we know that w must
match a vertex with rank θ in M(yv ≥ θ,y-v ). For yv ∈ [θ, τ ), Lemma 4.3 implies that v is the
victim of w and, thus, v receives a compensation h(θ ) from w. To sum up, we have
Eyv [αv ] ≥ Eyv [αv · 1 (yv < θ )] + Eyv [αv · 1 (yv ∈ [θ, τ ))] ≥  θ
0 д(yv )dyv + (τ − θ )h(θ ),
as claimed.
Lemma 4.5. Eyv [αu ] ≥ θ · (1 − д(τ ) − h(τ )) + (1 − θ ) · min{д(yu ), 1 − д(θ ) − h(θ )}.
Proof. By assumption,u actively matches vertex z with rankyz = τ whenyv < θ. Thus,u gains
1 − д(τ ) during the gain sharing phase and gives away h(τ ) to its victim (if any). Integrating yv
from 0 to θ gives the first term on the RHS.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.                  
Fully Online Matching 17:15
For yv ≥ θ, u either is passive, or actively matches a vertex with rank at most θ. In the first case,
we have αu = д(yu ). In the second case, we have αu ≥ 1 − д(θ ) − h(θ ), by the monotonicity of д,h.
Integrating yv from θ to 1 gives the second term on the RHS.
Summing up the inequalities in Lemmas 4.4 and 4.5 proves Lemma 4.2.
Comparing the bounds of Lemmas 4.4 and 4.5, the parameter τ presents a trade-off between the
expected gains αu and αv of the two vertices. The larger τ is, the less u gets when v is above its
marginal rank, e.g., 1 − д(τ ) − h(τ ), and the more v gets as compensations when it is below its
marginal rank, e.g., (τ − θ ) · h(τ ); and vice versa.
Charging Functions. If Lemma 4.2 holds unconditionally, then it remains to show that there exists
functions д,h (with desired properties) and constant F > 0.5 such that
 1
0
min
0≤θ <τ <1
  θ
0
д(yv )dyv + (τ − θ )h(θ ) + θ · (1 − д(τ ) − h(τ ))
+ (1 − θ ) · min 
д(yu ), 1 − д(θ ) − h(θ )


dyu ≥ F,
and to apply Lemma 2.6 to conclude that Ranking is F -competitive. The unconditional version
of Lemma 4.2 turns out to give a more complicated bound due to the considerations of other
cases. Nevertheless, we can use a linear program to optimize the ratio over fine-grained discretized
versions of д and h. In the next subsection, we approximate the solutions of the linear program
with piecewise-linear д and h (with two segments). We conclude with our choice of д and h that
Ranking is 0.5211-competitive.
4.2 General Case
In this section, we prove the following lemma, which is a general version of Lemma 4.2 (without
the simplifying assumptions on u,v we made previously).
Lemma 4.6. For any neighbor u of v that has an earlier deadline than v, and for any y-v , we have
E
yv
[αu + αv ]≥ f (yu )
def
= min
θ

min
τ ∈[θ,1)
 θ
0
д(yv )dyv + min 
(1 − θ )(1 − д(1-
) − h(1-
)), (τ − θ )h(θ )

+(1 − θ ) min 
д(yu ), 1 − д(θ ) − h(θ )

+ θ min 
д(yu ), 1 − д(τ ) − h(τ )
 
,
 θ
0
д(yv )dyv + (1 − θ ) min{1 − д(1-
) − h(1-
),h(θ )} + (1 − θ ) min 
д(yu ), 1 − д(θ )


.
Fix any neighbor u of v with an earlier deadline than v, and any y-v . Let θ be the marginal rank
of v, i.e., v is passive only when yv < θ. By Lemma 2.4, we know that when yv ≥ θ, u either is
passive or actively matches some vertex with rank at most θ.
We define in the following two lists of thresholds {θi}
m+1 i=0 and {τi}
m+1 i=0 that captures the matching
statuses of u when yv is smaller than the marginal rank θ.
Imagine that we decrease yv continuously starting fromyv = θ. Let θ0 = θ and τ0 = θ. We define
yv = θi+1 to be the first moment after θi when u actively matches some vertex zi+1 with yzi+1 >
τi . For convenience of description, we say that u actively matches a vertex with rank 1 if u is
unmatched (by definition, the gain of αu is 0 in both descriptions, since 1 − д(1) = 0). Define τi+1 :=
yzi+1 . Let θm be the last non-zero threshold. For convenience, we define θm+1 = 0 and τm+1 = 1. By
definition, we have the following fact.
Fact 4.1. There exists a sequence of non-increasing thresholds {θi}
m+1 i=0 and a sequence of nondecreasing thresholds {τi}
m+1 i=0 such that
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.   
17:16 Z. Huang et al.
(1) for all 0 ≤ i ≤ m and y ∈ [θi+1, θi ), u is passive or actively matches some vertex with rank
at most τi in M(yv = y,y-v );
(2) for all 1 ≤ i ≤ m, u actively matches a vertex zi with rank τi in M(yv = θi ,y-v ).
For all i ∈ [m], let wi be be vertex that actively matches v in M(yv = θi ,y-v ).
Observe that all wi ’s must be different, e.g., the deadline of wi+1 must be earlier than wi , in
order forwi+1 to match v in M(yv = θi+1,y-v ). Moreover, we know that in M(yv = θ,y-v ), eachwi
matches a vertex with rank θi , since wi chooses v in M(yv = θi ,y-v ) but not in M(yv = θi,y-v ).
Lemma 4.7. For all y ∈ [θ, τi ), if v is unmatched in M(yv = y,y-v ), then v is the victim of wi .
Proof. Let y1 = (yv = y,y-v ), where y ∈ [θ, τi ). Trivially, v is an unmatched neighbor of wi in
M(y1). To prove that v is the victim of wi , it suffices to show that wi is active in M(y1) and v
becomes matched when we remove wi from the graph.
Let y2 = (yv = θi ,y-v ). By definition, v is passively matched by wi and u actively matches zi
with yzi = τi in M(y2). Consequently, wi is also active in M(y1), as otherwise, wi should still be
passive in M(y2) given that v does not affect any decisions before wi ’s deadline.
Lety3 be the ranks by removing thewith entry fromy1. Assume for contrary thatv is unmatched
in M(y3). Then, we have M(y3) = M(y2) \ {(wi,v)}. This implies thatu actively matches zi in M(y3)
while v (with rank yv < yzi = τi ) is unmatched, which is a contradiction.
Equipped with Lemma 4.7, we first give a lower bound on the expected gain of αv . For notational
convenience, we define a new function ϕ : [0, 1] → [0, 1] such that ϕ(y) := 1 − д(y) − h(y). Recall
by definition of д and h, ϕ is a non-increasing function with ϕ(1) = 0.
Lemma 4.8. Eyv [αv ] ≥  θ
0 д(yv )dyv + min 
(1 − θ )ϕ(1-
),
m
i=0 (τi − θ )h(θi )

.
Proof. By definition, v is passive when yv < θ. Hence, we have Eyv [αv · 1 (yv < θ )] =  θ
0 д(yv )dyv , which corresponds to the first term on the RHS.
For all yv ≥ θ, v is either active or unmatched. In the first case, let p be matched passively by
v in M(yv ,y-v ). We know that v gains 1 − д(yp ) during the gain sharing phase and gives away
h(yp ) to its victim (if any), which implies αv ≥ 1 − д(yz ) − h(yz ) = ϕ(yz ) ≥ ϕ(1-
). Hence, we have
Eyv [αv · 1 (yv ≥ θ )] ≥ (1 − θ )ϕ(1-
).
In the second case, by Lemma 4.7, v is the victim of wi when yv ∈ [θ, τi ). Hence, v gains
h(θi ) from wi in the compensation phase (recall that wi matches a vertex with rank θi when
yv ∈ [θ, τi )). Putting all compensation (from w1,...,wm) together, we get Eyv [αv · 1 (yv ≥ θ )] ≥
m
i=0 (τi − θ )h(θi ), which corresponds to the second the term on the RHS.
Lemma 4.9. Eyv [αu · 1 (yv < θ )] ≥ m
i=0 (θi − θi+1) min 
д(yu ),ϕ(τi )

.
Proof. We partition the interval [0, θ ) into m + 1 segments: [θi+1, θi ), for 0 ≤ i ≤ m. Fix any i,
and consider yv ∈ [θi+1, θi ). If u is passive in M(yv ,y-v ), then we have αu ≥ д(yu ). Otherwise, we
know that u actively matches a vertex z with yz ≤ τi (by Fact 4.1). Hence, u gains 1 − д(yz ) during
the gain sharing phase and gives away h(yz ) to its victim (if any); i.e., we have αu ≥ ϕ(yz ) ≥ ϕ(τi ).
Summing up the gain from the m + 1 segments concludes the proof.
Observe that for lower bounding Eyv [αu + αv ], we shall consider the total gain of αu + αv . We
may omit the compensation from u to v, since it does not change the summation. For analysis
convenience, we assume v is never a victim of u.
Lemma 4.10. Eyv [αu · 1 (yv ≥ θ )] ≥ (1 − θ ) min{д(yu ),ϕ(θ )}. Moreover, if τm = 1, then we have
Eyv [αu · 1 (yv ≥ θ )] ≥ (1 − θ ) min{д(yu ), 1 − д(θ )}.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.                               
Fully Online Matching 17:17
Proof. For all yv ≥ θ, u is either passive or actively matches a vertex with rank at most θ.
Therefore, αu ≥ min{д(yu ),ϕ(θ )}. Integrating yv from θ to 1 gives the first statement.
When τm = 1, we know that u is unmatched when yv = θm. Fix any y = (yv ,y-v ), where yv ≥ θ.
We show that u does not have any unmatched neighbor other than v in M(y), which implies that
u does not have a victim and, hence, αu ≥ min{д(yu ), 1 − д(θ )}.
Suppose otherwise, let z  v be the unmatched neighbor of u in M(y).
Let y1 = (yv = θm,y-v ). We know that u is matched in M(y) and unmatched in M(y1). Consider the partial matchings produced right after u’s deadline when Ranking is run with y and y1,
respectively. We denote the matchings by Mu (y) and Mu (y1), respectively. The symmetric difference between Mu (y) and Mu (y1) is an alternating path, with u being one endpoint. Observe that
v is matched in Mu (y1) (as u is unmatched), and is unmatched in Mu (y) (as it is not passive in
M(y)). Hence, v is the other end point of the alternating path. Consequently, we know that z is
unmatched in Mu (y1) (as it is unmatched in Mu (y)), which is a contradiction as its neighbor u is
also unmatched in Mu (y1).
Summing the above three lemmas gives us a lower bound of the expected gain of αu + αv . However, the bound involves too many variables (namely, {θi}
m
i=1) for us to optimize. The next technical
lemma shows that the worst case is achieved when there exists only one threshold θm = θ, i.e., u
matches some vertex with rank τ > θ in M(yv = θ-
,y-v ), and matches a vertex with rank at most
τ for all yv < θ.
Lemma 4.11. Given that h(y)/y is a non-increasing function, we have
min 
(1 − θ )ϕ(1-
),
m
i=0
(τi − θ )h(θi )

+
m
i=0
(θi − θi+1) min{д(yu ),ϕ(τi )}
≥ min
i

min 
(1 − θ )ϕ(1-
), (τi − θ )h(θ )

+ θ min 
д(yu ),ϕ(τi )


.
Proof. Consider the first term of left-hand side (LHS). If (1 − θ )ϕ(1-
) < m
i=0 (τi − θ )h(θi ), then
we have
LHS ≥(1 − θ )ϕ(1-
) +
m
i=0
(θi − θi+1) min 
д(yu ),ϕ(τm )

=(1 − θ )ϕ(1-
) + θ min 
д(yu ),ϕ(τm )

≥ RHS.
If (1 − θ )ϕ(1-
) ≥ m
i=0 (τi − θ )h(θi ), then we have
LHS =
m
i=0
(τi − θ )h(θi ) +
m
i=0
(θi − θi+1) min{д(yu ),ϕ(τi )}
=
m
i=0
(θi − θi+1)
 τi − θ
θi − θi+1
h(θi ) + min{д(yu ),ϕ(τi )}

≥
m
i=0
(θi − θi+1)

τi − θ
θ h(θ ) + min{д(yu ),ϕ(τi )}

≥
m
i=0
(θi − θi+1) min
j

τj − θ
θ h(θ ) + min{д(yu ),ϕ(τj)}

= min
j

(τj − θ )h(θ ) + θ min{д(yu ),ϕ(τi )}

≥ RHS,
where the first inequality follows from τi−θ
θi−θi+1
h(θi ) ≥ (τi − θ )
h(θi )
θi ≥ (τi − θ )
h(θ )
θ .
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.                                  
17:18 Z. Huang et al.
Proof of Lemma 4.6. By Lemmas 4.8 and 4.9, we have
Eyv [αv ] + Eyv [αu · 1 (yv < θ )]
≥
 θ
0
д(yv )dyv + min
⎧⎪
⎨
⎪
⎩
(1 − θ )ϕ(1-
),
m
i=0
(τi − θ )h(θi )
⎫⎪
⎬
⎪
⎭
+
m
i=0
(θi − θi+1) min{д(yu ),ϕ(τi )}
≥
 θ
0
д(yv )dyv + min
i

min{(1 − θ )ϕ(1-
), (τi − θ )h(θ )} + θ min{д(yu ),ϕ(τi )}

,
where the last inequality comes from Lemma 4.11.
Combining with Lemma 4.10 (which gives different lower bounds for Eyv [αu · 1 (yv ≥ θ )] depending on whether τm = 1), we prove Lemma 4.6 for two cases, depending on whether τm = 1.
If τm < 1, then we have (recall that ϕ(θ ) = 1 − д(θ ) − h(θ ) ≤ 1 − д(θ ))
E
yv
[αu + αv ] = E
yv
[αv ] + E
yv
[αu · 1 (yv < θ )] + E
yv
[αu · 1 (yv ≥ θ )]
≥
 θ
0
д(yv )dyv + min
τ ∈[θ,1)

min{(1 − θ )ϕ(1-
), (τ − θ )h(θ )} + θ min{д(yu ),ϕ(τ )}

+ (1 − θ ) min{д(yu ),ϕ(θ )},
which corresponds to the first term of the outer most min in the expression of Lemma 4.6.
If τm = 1, then we have
Eyv [αu + αv ] ≥
 θ
0
д(yv )dyv + min
τ ∈[θ,1]

min{(1 − θ )ϕ(1-
), (τ − θ )h(θ )} + θ min{д(yu ),ϕ(τ )}

+ (1 − θ ) min{д(yu ), 1 − д(θ )}
≥ min
⎧⎪
⎨
⎪
⎩
min
τ ∈[θ,1)
  θ
0
д(yv )dyv + min{(1 − θ )ϕ(1-
), (τ − θ )h(θ )} + θ min{д(yu ),ϕ(τ )}
+ (1 − θ ) min{д(yu ),ϕ(θ )}

,
 θ
0
д(yv )dyv + (1 − θ ) min{ϕ(1-
),h(θ )} + (1 − θ ) min{д(yu ), 1 − д(θ )}
⎫⎪
⎬
⎪
⎭
.
Taking the minimum over all possible θ’s concludes the proof.
4.3 Lower Bound of the Competitive Ratio
Recall that
f (yu ) def
= min
θ

min
τ ∈[θ,1)
 θ
0
д(yv )dyv + min 
(1 − θ )(1 − д(1-
) − h(1-
)), (τ − θ )h(θ )

+(1 − θ ) min 
д(yu ), 1 − д(θ ) − h(θ )

+ θ min 
д(yu ), 1 − д(τ ) − h(τ )
 ,
 θ
0
д(yv )dyv + (1 − θ ) min{1 − д(1-
) − h(1-
),h(θ )} + (1 − θ ) min 
д(yu ), 1 − д(θ )


.
We construct the functions д,h explicitly as follows (refer to Figure 2).
д(x) =
⎧⎪⎪
⎨
⎪⎪
⎩
k1
дx + b, x ∈ [0,t]
k2
д (x − t) + k1
дt + b, x ∈ (t, 1)
1 x = 1
, h(x) =
⎧⎪⎪
⎨
⎪⎪
⎩
k1
hx, x ∈ [0,t]
k2
h (x − t) + k1
ht, x ∈ (t, 1)
0 x = 1
,
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.   
Fully Online Matching 17:19
Fig. 2. д(x) and h(x).
where t = 0.3, k1
д = 0.21, k2
д = 0.1, b = 0.46, k1
h = 0.26, andk2
h = 0.17. We have that both д,h are
non-decreasing in [0, 1) and h(x)/x is non-increasing.
We first simplify the expression of f (yu ). Recall that we define ϕ(y) = 1 − д(y) − h(y), which is
a decreasing function with ϕ(1) = 0. By definition of д,h stated above, we have ϕ(1-
) = 0.21.
Observe that (1 − θ )ϕ(1-
) > (1 − θ ) · 0.197 = (1 − θ )h(1-
) ≥ (τ − θ )h(θ ) for all τ , θ. Hence,
f (yu ) = min 
min
θ ≤τ <1
ψ1 (yu, θ, τ ), min
θ ≤1
ψ2 (yu, θ )

,
where
ψ1 (yu, θ, τ ) def
=
 θ
0
д(yv )dyv + (τ − θ )h(θ ) + (1 − θ ) min 
д(yu ),ϕ(θ )

+ θ min 
д(yu ),ϕ(τ )

,
ψ2 (yu, θ ) def
=
 θ
0
д(yv )dyv + (1 − θ )h(θ ) + (1 − θ ) min 
д(yu ), 1 − д(θ )

.
The following lemma implies that Ranking is 0.5211-competitive.
Lemma 4.12.  1
0 f (yu )dyu > 0.5211.
Proof. As we will show in Lemmas 4.13 and 4.14 below, we have
f (yu ) = min 
min
θ ≤τ <1
ψ1 (yu, θ, τ ), min
θ ≤1
ψ2 (yu, θ )

≥ min{д(yu ), 0.5349}.
Let y∗
u be such that д(y∗
u ) = 0.5349, we have
 1
0
f (yu )dyu =
 y∗
u
0
f (yu )dyu +
 1
y∗
u
f (yu )dyu =
 y∗
u
0
д(yu )dyu + (1 − y∗
u ) · 0.5349 > 0.5211.
We first consider the easier one, ψ2.
Lemma 4.13. For any θ ≤ 1, we have ψ2 (yu, θ ) > min{д(yu ), 0.5349}.
Proof. First, if θ = 1, then we have ψ2 (yu, θ ) =  1
0 д(yv )dyv ≈ 0.5381 > 0.5349. Now consider
θ < 1.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020. 
17:20 Z. Huang et al.
Fig. 3. ψ2 (yu, θ ) and ∂ψ2
∂θ .
If д(yu ) < 1 − д(θ ), then we have ψ2 (yu, θ ) =  θ
0 д(yv )dyv + (1 − θ )h(θ ) + (1 − θ )д(yu ). Thus,
∂ψ2
∂θ = д(θ ) + (1 − θ )h
(θ ) − h(θ ) − д(yu ),
∂2
ψ2
∂θ 2 = д
(θ ) − 2 · h
(θ ) =
⎧⎪
⎨
⎪
⎩
k1
д − 2k2
h = −0.31 θ < t
k2
д − 2k2
h = −0.24 θ > t
.
Hence, the minimum of ψ2 (yu, θ ) is achieved at arg minθ <1{ψ2 (yu, θ )}∈{0,t, 1-
}. Note that
ψ2 (yu, 0) = h(0) + д(yu ) ≥ д(yu ),
ψ2 (yu,t) =
 t
0
д(yv )dyv + (1 − t)h(t) + (1 − t)д(yu ) > t · 0.673 + (1 − t) · д(yu ) > д(yu ),
ψ2 (yu, 1-
) =
 1
0
д(yv )dyv ≈ 0.5381 > 0.5349.
We have minθ <1{ψ2 (yu, θ )} ≥ min{д(yu ), 0.5349}, as claimed.
If д(yu ) ≥ 1 − д(θ ), then we have ψ2 (yu, θ ) =  θ
0 д(yv )dyv + (1 − θ )h(θ ) + (1 − θ )(1 − д(θ )).
Thus,
∂ψ2
∂θ = д(θ ) + (1 − θ )h
(θ ) − h(θ ) − (1 − д(θ )) − (1 − θ )д
(θ ),
∂2
ψ2
∂θ 2 = 3 · д
(θ ) − 2 · h
(θ ) =

0.11 θ < t
−0.04 θ > t .
We calculate the zero point of ∂ψ2
∂θ in [0,t), i.e., let ∂ψ2
∂θ = 0, we have solution
θ ∗ = 1 + k1
д − k1
h − 2b
3k1
д − 2k1
h
≈ 0.273.
Thus, for any fixed yu ,ψ2 (yu, θ ) is decreasing in [0, θ ∗] and increasing in (θ ∗,t). So the minimum
of ψ2 (yu, θ ) in [0,t] is achieved at θ ∗. Also, since ∂2ψ2
∂θ 2 < 0 in (t, 1), the minimum of ψ2 (yu, θ ) in
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.
Fully Online Matching 17:21
[t, 1) is achieved at either t or 1-
. To sum up, the overall minimum is achieved at either θ ∗ or 1-
:
ψ2 (yu, θ ∗) =
 θ ∗
0
д(yv )dyv + (1 − θ ∗)h(θ ∗) + (1 − θ ∗)(1 − д(θ ∗)) ≈ 0.5359 > 0.5349,
ψ2 (yu, 1-
) =
 1
0
д(yv )dyv ≈ 0.5381 > 0.5349,
Thus, we have minθ <1ψ2 (yu, θ ) = min{ψ2 (yu, θ ∗),ψ2 (yu, 1-
)} > 0.5349, as required.
Next, we consider ψ1.
Lemma 4.14. For all θ ≤ τ < 1, we have ψ1 (yu, θ, τ ) > min{д(yu ), 0.5349}.
Proof. Ifд(yu ) ≤ ϕ(τ ), then we haveψ1 (yu, θ, τ ) =  θ
0 д(yv )dyv + (τ − θ )h(θ ) + (1 − θ )д(yu ) +
θд(yu ) ≥ д(yu ), as required. Now consider д(yu ) > ϕ(τ ). Observe that
∂ψ1
∂τ = h(θ ) − θ (д
(τ ) + h
(τ )) ≤ 0,
where the last inequality holds, since h(θ ) ≤ k1
hθ ≤ (k2
д + k2
h )θ ≤ (д
(τ ) + h
(τ ))θ for all τ . Thus,
for all τ , we have ψ1 (yu, θ, τ ) ≥ ψ1 (yu, θ, 1-
); i.e., the minimum is achieved when τ = 1-
.
Depending on whether д(yu ) ≥ ϕ(θ ), we consider two cases. If д(yu ) < ϕ(θ ), then we have
ψ1 (yu, θ, τ ) =
 θ
0
д(yv )dyv + (τ − θ ) · h(θ ) + (1 − θ ) · д(yu ) + θ · ϕ(τ ).
For any fixed θ, the minimum is achieved when τ = 1-
, which is
ψ1 (yu, θ, 1-
) =
 θ
0
д(yv )dyv + (1- − θ )h(θ ) + (1 − θ )д(yu ) + θ · ϕ(1-
)
≥
 θ
0
д(yv )dyv + (1 − θ )h(θ ) + (1 − θ )д(yu ) ≥ ψ2 (yu, θ ) ≥ min{д(yu ), 0.5349},
where the last inequality follows from Lemma 4.13. If д(yu ) ≥ ϕ(θ ), then we have
ψ1 (yu, θ, τ ) =
 θ
0
д(yv )dyv + (τ − θ ) · h(θ ) + (1 − θ ) · ϕ(θ ) + θ · ϕ(τ ),
the minimum of which is achieved when τ = 1-
. Define ψ (θ ) to be the minimum:
ψ (θ ) def
= ψ1 (yu, θ, 1-
) =
 θ
0
д(yv )dyv + (1- − θ ) · h(θ ) + (1 − θ ) · ϕ(θ ) + θ · ϕ(1-
)
=
 θ
0
д(yv )dyv + (1 − θ ) · (1 − д(θ )) + θ · (1 − д(1-
) − h(1-
)).
By the following, we have ∂ψ
∂θ > 0 for all θ ∈ (t, 1), i.e., ψ (θ ) is increasing when θ ∈ (t, 1).
∂ψ
∂θ = д(θ ) + (1 − θ )(−д
(θ )) − (1 − д(θ )) + 1 − д(1-
) − h(1-
),
∂2
ψ
∂θ 2 = 3д
(θ ) > 0, ∀θ ∈ [0,t) ∪ (t, 1),
∂ψ
∂θ




θ=0
= 2д(0) − k1
д − д(1-
) − h(1-
) ≈ −0.08 < 0,
∂ψ
∂θ




θ=t
= 2д(t) − (1 − t)k2
д − д(1-
) − h(1-
) = 0.186 > 0.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020. 
17:22 Z. Huang et al.
Fig. 4. ψ (θ ) and ∂ψ
∂θ .
Hence, the minimum of ψ (θ ) is achieved when θ ∈ (0,t]. Let ∂ψ
∂θ = 0, we have
∂ψ
∂θ = д(θ ) − (1 − θ )д
(θ ) − (1 − д(θ )) + 1 − д(1-
) − h(1-
) = 0
⇐⇒ 3k1
дθ + 2b − д(1-
) − h(1-
) − k1
д = 0.
⇐⇒ θ ∗ = k1
д + д(1-
) + h(1-
) − 2b
3k1
д
≈ 0.127.
Thus, for all θ ≤ τ < 1, we have ψ1 (yu, θ, τ ) ≥ ψ (θ ) ≥ ψ (θ ∗) ≈ 0.5349, as claimed.
5 HARDNESS RESULTS
In this section, we prove the hardness results.
Proof of Theorem 1.3. Consider the following hard instance. Let k, h be integer parameters, and n := h
i=0 ki = kh+1−1
k−1 be the number of vertices on each side of a bipartite graph. In
the following, we construct a bipartite graph on vertices U ∪V , where U = {u1,...,un } and
V = {v1,...,vn−kh ,b1,...,bkh }. By our construction the graph is bipartite, but note that U,V do
not correspond to the two sides of the bipartite graph.
Hard Instance. Refer to Figure 5 (an illustrating example with k = 3 and h = 2). At the beginning,
vertex u1 arrives, together with all its k + 1 neighbors (children). Let the deadline of u1 be reached
immediately. Then, we choose uniformly at random k vertices from the k + 1 neighbors of u1 to be
u2,...,uk+1. Let the remaining vertex be v1. We repeat the procedure for vertices u2,...,uk+1, i.e.,
each vertexui has k + 1 children, among which k vertices are chosen to beu(i−1)k+2 ...,uik+1 while
the remaining one becomes vi , and let the deadline of ui be reached immediately. We continue
building the tree for h levels. Note that in level i, there are ki vertices (excluding the v vertices).
Hence, the tree with h levels has n vertices.
At last, we pick a random permutation A = (a1, a2,..., akh ) of the kh vertices {un−kh+1,...,un }
at levelh. Let vertices B = {b1,...,bkh } arrive (b1 arrives first andbkh last), such thatbi is connected
to vertices ai,..., an, and the deadline of bi is reached immediately when it arrives.
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020.  
Fully Online Matching 17:23
Fig. 5. Hard instance for any online algorithm: an illustrating example with k = 3 and h = 2.
Let the deadlines of vertices in A ∪ (V \ B) be reached at the end.
Competitive Ratio. First observe that graph G has a perfect matching, by matching ui to vi (for
all i ∈ [n − kh]) and ai to bi (for all i ∈ [kh]). Now, we consider any online algorithm. Note that
when the deadline of ui is reached, it is not worse to match ui if it has an unmatched neighbor:
If we do not match ui , then the symmetric difference is an alternating path, thus the number of
vertices matched does not increase. Hence, we assume w.l.o.g. that all vertices in U \ A will be
matched eventually.
Let pi be the probability that a vertex ux from level i is matched when the deadline of its parent
uy in the tree is reached. Note that pi is also the probability that vy is matched, as vy is chosen
uniformly at random among the k + 1 children of uy . Observe that we have pi = 1−pi−1
k+1 , where
p0 = 1. By induction, we have that for all i ≤ h,
pi = 1
k + 2

1 −
 −1
k + 1
	i

.
Hence, before vertex b1 arrives, each vertex from A is matched with probability ph. At the deadline of a vertex in A, the vertex would uniformly matches a vertex from its neighbors in B if it
is unmatched yet. Therefore, the expected number of matched vertices from B (at the end of the
algorithm) is t such that
1
kh +
1
kh − 1
+ ··· +
1
kh − t + 1 = 1 − ph = k + 1
k + 2
+
1
k + 2
 −1
k + 1
	h
.
When h tends to infinity, we have t ≈ (1 − e− k+1 k+2 ) · kh. Hence, the competitive ratio is
2t + |U \ A| + 1
k+2 |A| + 1
k+2 |V \ B|
2n = 2(1 − e− k+1 k+2 ) · kh · (k − 1) + kh − 1
2(kh+1 − 1)
+
1
2(k + 2)
,
which tends to k−1
k (1 − e− k+1 k+2 ) + 1
2k + 1
2(k+2) when h tends to infinity. For k = 7, the ratio is 62
63 −
6
7 · e− 8
9 ≈ 0.631745.
Proof of Theorem 1.4. Consider the following hard instance. Let k, h be integer parameters,
and n := k · h be the number of vertices on each side of a bipartite graph G. In the following, we
construct a bipartite graph on vertices U ∪V , where U = {u1,...,un } and V = {v1,...,vn }. As
before, by our construction the graph is bipartite, but U,V do not correspond to the two sides of
the bipartite graph.
Hard Instance. Refer to Figure 6. For all i ∈ [n], let ui be the only neighbor of vi . We group
every k consecutive vertices in U as a group, i.e., let U = ∪i ∈[h]Ui , where the ith group Ui =
Journal of the ACM, Vol. 67, No. 3, Article 17. Publication date: May 2020. 
17:24 Z. Huang et al.
{u(i−1)k+1,u(i−1)k+2,...,uik }. Let there be an edge between ui and uj if they are from two consecutive groups, respectively. In other words, we form a complete bipartite graph between any
two consecutive groups Ui and Ui+1.
Let the deadline of vertex u1 be reached first, then u2’s deadline, u3’s deadline, and so on.
Competitive Ratio of Ranking . First, graphG has a perfect matching, by matchingui tovi for each
i ∈ [n]. Recall that in the Ranking algorithm, each vertex u is assigned a random rank yu ∈ [0, 1).
At the deadline of an unmatched vertex, it is matched to its unmatched neighbor v (if any) with
the smallest yv . Observe that in our instance, all vertices fromU will be matched eventually, while
each vi ∈ V will be matched only if at the deadline of ui , ui is unmatched and yvi is smaller than
the ranks of all unmatched vertices from the next group U i
k +1.
For all i ∈ [h], let Xi ∈ {0, 1,..., k} be the number of unmatched vertices in Ui right before the
deadline of the first vertex u(i−1)k+1 in Ui is reached. Note that Xi+1 is a random variable that
depends only on Xi . Hence, the sequence X1,X2,...,Xh forms a Markov chain (with k + 1 states)
with initial state X1 = k. Observe that all vertices in U are matched, and the number of vertices
matched in Vi equals Xi + Xi+1 − k. Hence, the competitive ratio of Ranking ≈

i∈[h] Xi
kh .
We say phase i begin when the deadline of the first vertex of Ui is reached, and end after the
deadline of the last vertex of Ui . Fix any phase i, where i < h. Recall that initially Xi vertices of
Ui are unmatched. Let Z (t) be the number of unmatched vertices in Ui+1, when the deadlines of
exactly t unmatched vertices in Ui have passed. We have Z (0) = k and Xi+1 = Z (Xi ). Let y1 ≤
y2 ≤ ··· ≤ yk be the ranks of vertices in Ui+1. We have E [Z (t + 1)] = Z (t) − 1 + yZ (t). Taking
expectation over all yi ’s, we have E [Z (t + 1)] = E [Z (t)] − 1 + E[Z (t)]
k+1 . Let z( t
k ) def
= Z (t)
k . When
k → ∞, z( t
k ) → e− t
k . This is saying, given Xi , E [Xi+1] = k · e− Xi
k when k tends to infinity.
Finally, note that all vertices in Ui+1 are symmetric. Hence, each of them is unmatched at the
end of phase i with probability E[Xi+1]
k = e− Xi
k . Moreover, for any two vertices ua,ub ∈ Ui+1, the
probability that ua is unmatched at the end of phase i is negatively correlated with the probability
of ub : conditioned on ub being unmatched at the end of phase i, the probability of ua being unmatched is smaller. Thus, we have measure concentration bound on Xi+1, by standard argument
using moment generation function. In other words, the stationary distribution (when k and h tends
to infinity) converges to a single point mass with
X
k = e− X
k ,
which implies X
k ≈ 0.56714, the Omega constant, which is also the competitive ratio of
Ranking. 