In the k-cut problem, we want to find the lowest-weight set of edges whose deletion breaks a given
(multi)graph into k connected components. Algorithms of Karger and Stein can solve this in roughly O(n2k )
time. However, lower bounds from conjectures about the k-clique problem imply that Î©(n(1âˆ’o(1))k ) time is
likely needed. Recent results of Gupta, Lee, and Li have given new algorithms for general k-cut in n1.98k+O (1)
time, as well as specialized algorithms with better performance for certain classes of graphs (e.g., for small
integer edge weights).
In this work, we resolve the problem for general graphs. We show that the Contraction Algorithm of Karger
outputs any fixed k-cut of weight Î±Î»k with probability Î©k (nâˆ’Î± k ), where Î»k denotes the minimum k-cut
weight. This also gives an extremal bound of Ok (nk ) on the number of minimum k-cuts and an algorithm to
compute Î»k with roughly nk polylog(n) runtime. Both are tight up to lower-order factors, with the algorithmic
lower bound assuming hardness of max-weight k-clique.
The first main ingredient in our result is an extremal bound on the number of cuts of weight less than 2Î»k /k,
using the Sunflower lemma. The second ingredient is a fine-grained analysis of how the graph shrinksâ€”and
how the average degree evolvesâ€”in the Karger process.
CCS Concepts: â€¢ Theory of computation â†’ Graph algorithms analysis;
Additional Key Words and Phrases: k-cut, contraction algorithm
1 INTRODUCTION
We consider the k-Cut problem: Given an edge-weighted graph G = (V, E,w) and an integer k,
we want to delete a minimum-weight set of edges so that G has at least k connected components.
We let Î»k denote the resulting weight of the deleted edges. This generalizes the global min-cut
problem, where the goal is to break the graph into k = 2 pieces.
It was unclear that the problem admitted a polynomial-time algorithm for fixed k, until Goldschmidt and Hochbaum gave a deterministic algorithm with nO (k2 ) runtime [4]. The algorithm
of Karger [11], based on random edge contractions, can also solve k-Cut in OËœ (mn2kâˆ’1) time; this
was later improved to OËœ (n2kâˆ’2) runtime by Karger and Stein [12]. There have been a number of
improved deterministic algorithms [2, 5, 10, 15]: notably, the tree-packing result of Thorup [15]
was sped up by Chekuri et al. [2] to O(mn2kâˆ’3) runtime. Thus, until recently, randomized and
deterministic algorithms with very different approaches have achieved n(2âˆ’o(1))k runtime for the
problem. (Here and subsequently, the o(1) in the exponent indicates a quantity that goes to zero
as k increases.)
As for hardness, there is a reduction from Max-Weight (k âˆ’ 1)-Cliqe to k-Cut. It is conjectured that solving Max-Weight k-Cliqe requires Î©(n(1âˆ’o(1))k ) time when weights are integers
in the range [1, Î©(nk )], and Î©(n(Ï‰/3âˆ’o(1))k ) time for unit weights, where Ï‰ is the matrix multiplication constant. Extending these bounds to k-Cut suggests that n(1âˆ’o(1))k may be a lower bound
for general weighted k-cut instances.
There has been recent progress on this problem, showing the following results:
(1) Gupta, Lee, and Li gave an n(1.98+o(1))k -time algorithm for general k-Cut [7]. This was based
on showing an extremal bound for the number of â€œsmallâ€ 2-cuts in the graph. A boundeddepth search is then used to guess the small 2-cuts within a minimum k-cut and make
progress. This proof-of-concept result showed that n(2âˆ’o(1))k was not the right bound, but
the approach did not seem to extend to exponents considerably below 2k.
(2) For polynomially bounded edge-weights, Gupta, Lee, and Li gave an algorithm with roughly
kO (k) n(2Ï‰/3+o(1))k runtime [6]. For unweighted graphs, Li obtained kO (k)
n(1+o(1))k runtime [14]. These algorithms are both based on finding a spanning tree that crosses a small
number of edges of a minimum k-cut. The former relies on matrix multiplication ideas, and
the latter on the Kawarabayashi-Thorup graph decomposition [13], which are both intrinsically tied to graphs with small edge-weights.
In this article, we show that the â€œrightâ€ algorithm, the original Contraction Algorithm of
Karger [11], achieves the â€œrightâ€ bound for general graphs. We recall the algorithm below; here, Ï„
(the final desired graph size) is a parameter we will adjust in our specific constructions.
ALGORITHM 1: Contraction Algorithm
1: while |V | > Ï„ do
2: Choose an edge e âˆˆ E at random from G, with probability proportional to its weight.
3: Contract the two vertices in e and remove self-loops.
4: end while
5: Return a k-cut of G chosen uniformly at random.
Setting Ï„ = k, as in Kargerâ€™s original algorithm, would seem most natural, but we will require a
larger value in our analysis. Our main result is the following.
Theorem 1.1 (Main). For any integer k â‰¥ 2 and real number Î± â‰¥ 1, the Contraction Algorithm
outputs each k-cut of weight Î±Î»k with probability at least nâˆ’Î± kkâˆ’O (Î± k2 ) for appropriate choice of
Ï„ = poly(Î±, k).
Since any minimum-weight k-cut (corresponding to Î± = 1) is output with probability nâˆ’kkâˆ’O (k2 )
,
this immediately implies the following corollary.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.
Optimal Bounds for the k-cut Problem 2:3
Corollary 1.2 (Number of Minimum k-cuts). For any k â‰¥ 2, the number of minimum-weight
k-cuts in a graph is at most nkkO (k2 )
.
This improves on the previous best bound of n(1.98+o(1))k [7]. It is almost tight, because the cycle
on n vertices has
n
k

minimum k-cuts.
Also, while the direct implementation of Algorithm 1 incurs an extra O(n2) in the runtime, the
Recursive Contraction Algorithm of Karger and Stein [12] can be used to get an almost-matching
running time to enumerate all minimum k-cuts.
Theorem 1.3 (Faster Algorithm to Find a Minimumk-cut). There is an algorithm to enumerate all minimum k-cuts in time nk (logn)
O (k2 ) with probability at least 1 âˆ’ 1/poly(n).
This improves the runtime n(1.98+o(1))k from Reference [7] and even beats the runtime n(1+o(1))k
for the unweighted case [14]. It is almost optimal under the hypothesis that Max-Weight kCliqe requires n(1âˆ’o(1))k time. Achieving an O(nck )-time algorithm for unit-weighted graphs for
any constant c < 1 still remains an open problem.
See Section 7 for the formal statements of the above theorems.
1.1 Our Techniques
Although we have stated the general k-Cut problem for a weighted graph, we will assume throughout that G = (V, E) is an unweighted multigraph with n vertices and m edges. The viewpoint in
terms of weighted graphs is equivalent via replicating edges; note that, in this case, m may be
exponentially large compared to n. Our computational and combinatorial bounds will depend on
n and not directly on m.
In the spirit of Reference [7], our proof has two main parts: (i) a bound on the extremal number
of â€œmediumâ€ cuts in a graph, and (ii) a new algorithmic analysis for the Contraction Algorithm. To
begin, let us first state a crude version of our extremal result. Define Î»k := Î»k /k, which we think
of as the average contribution of the k components of a minimum k-cut, and let â€œmediumâ€ cuts
denote 2-cuts whose weight is in [Î»k , 2Î»k ).
1 The graph may contain a negligible number of â€œsmallâ€
2-cuts of weight less than Î»k . Loosely speaking, the extremal bound says the following:
() For fixed k, the graph has at most O(n) many medium cuts.
To develop some intuition for this claim, it is instructive to consider the cycle and clique graphs.
These are two opposite ends of the spectrum in the context of graph cut. In the cycle, we have
Î»k = 1, and there are no 2-cuts with weight less than 2Î»k , hence () holds. However, the
n
2

minimum 2-cuts have size equal to 2Î»k = 2. In the clique, the minimum k-cut chops off k âˆ’ 1
singleton vertices, so Î»k =
kâˆ’1
2

+ (k âˆ’ 1)(n âˆ’ k + 1), which gives Î»k â‰ˆ kâˆ’1
k n for n  k. There are
n minimum 2-cuts, which have weight n âˆ’ 1 < 2Î»k (the singletons), so again () holds. And again,
there are
n
2

2-cuts of weight approximately 2Î»k (the doubletons).
Therefore, in both the cycle and the clique, the bound 2Î»k is almost the best possible. Moreover,
the O(n) bound for the number of medium cuts is also optimal in the clique.
1.1.1 Analysis of Contraction Algorithm. When we begin the Contraction Algorithm in the
graph G, our extremal bound ensures that there are at most Ok (n) medium cuts of size between
Î»k and 2Î»k , plus a negligible number of small 2-cuts of size less than Î»k . Let us next sketch how
these bounds give rise to the improved bound for k-cuts. To provide intuition, let us suppose that
1In the actual analysis, we use the interval [ k
kâˆ’1 Î»k, 2Î»k ).
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.           
2:4 A. Gupta et al.
in fact there are n medium cuts and no smaller 2-cuts (the precise factors are not important for the
overall analysis).
Each vertex during the Contraction Algorithm corresponds to a 2-cut of the original graph,
and we are assuming that G has no small 2-cuts, so the number of edges in each iteration i of
the Contraction Algorithm is lower-bounded by iÎ»k /2. Again, to provide intuition, let us suppose
there are precisely this many edges. Then each medium cut gets an edge selected in iteration i,
and is thereby removed from the graph, with probability at least Î»k
iÎ»k /2 = 2
i . So after n/2 iterations,
the number of surviving medium cuts is close to
n
n
i=n/2

1 âˆ’ 2
i

â‰ˆ n/4.
Thus, in the resulting subgraph with i = n/2 vertices, at most n/4 of the vertices (corresponding
to the surviving medium cuts) have degree Î»k . The remainder have degree at least 2Î»k . Continuing
this process, the graph becomes more and more enriched with high-degree vertices. After (1 âˆ’Îµ)n
iterations (for some small constant Îµ), almost all of the medium cuts have been eliminated, and
each graph on i â‰¤ Îµn vertices has close to iÎ»k edges.
Now consider an arbitrary minimumk-cutK. It survives the first (1âˆ’Îµ)n iterations with constant
probability. In each iterationi of the Contraction Algorithm when the resulting subgraph hasi â‰¤ Îµn
vertices, K is selected with probability roughly Î»k
iÎ»k
= k
i . Over the entire run of the Contraction
Algorithm, down to the final graph with Ï„ = poly(k) vertices, K survives with probability roughly
constant Â·
Îµn
i=Ï„

1 âˆ’ k
i

â‰ˆ Î˜(nâˆ’k ).
To show this formally, we need to track the number of medium cuts remaining in the residual
graphs produced by the Contraction Algorithm. There are two main obstructions to turning the
analysis we have sketched above into a rigorous proof. First, many of our bounds made unwarranted assumptions about the parameter sizes; for example, we only know lower bounds on the
edge counts, and we should not assume that these hold with equality in each iteration. Second, the
Contraction Algorithm is a stochastic process; we cannot assume that relevant quantities (such as
the number of medium cuts) equal their expectations.
To overcome these challenges, we adopt a proof strategy of Reference [9]. First, using a number
of heuristic worst-case assumptions, and relaxing the discrete stochastic process to a continuoustime system of differential equations, we make a guess as to the correct dynamics of the Contraction
Algorithm. This gives us a formula for the probability that K is selected, given that the process has
reached some iteration i and currently has some given number of residual medium cuts. Next, we
use induction to prove that this formula holds in the worst case. For this, we take advantage of the
fact that our guessed formula has nice convexity and monotonicity properties.
Let us contrast our proof strategy with the analysis in a preliminary version of this article [8]. In
this work, we analyze the Contraction Algorithm as edges are contracted one at a time. In contrast,
the authors of Reference [8] considered an alternate viewpoint where each edge is independently
contracted with some given probability, which is equivalent to executing many steps of the Contraction Algorithm. (The alternate viewpoint is only taken for the purposes of analysis; the actual
algorithm remains the same.)
In some ways, the alternate viewpoint is simpler, since it preserves many independencies
among edges and since a number of relevant parameters are concentrated. However, a drawback
is that it lacks fine control of precisely how many edges to contract. When the number of vertices
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.
Optimal Bounds for the k-cut Problem 2:5
Fig. 1. Left: To illustrate, suppose k = 8 and all
n
2

2-cuts of the cycle have weight less than 2Î»k . Then, we
select  = 4 such 2-cuts as shown. Their Venn diagram has 2 = 8 nonempty atoms and form an 8-cut with
cost less than  Â· 2Î»k = 8Î»k = Î»k . Right: A k-sunflower with core and petals consisting of single vertices.
Here c has degree a â‰¥ k
kâˆ’1Î»k and each bolded edge has weight r = a/k = Î»k
kâˆ’1 . A k-cut generated by k âˆ’ 1
of the vertices pi then has weight less than Î»k .
in the graph becomes small, the independent-contractions viewpoint introduces larger errors
compared to our one-at-a-time approach. For example, the preliminary version showed a bound
of nkkO (k2 (log log n)
2 ) on the number of k-cuts; compare this to the tighter bound of nkkO (k2 ) from
Theorem 1.1.
1.1.2 Extremal Result. Recall our target extremal statement (): There areOk (n) many medium
cuts in the graph, i.e., 2-cuts of weight less than 2Î»k . To show this, we consider two different cases.
In the first case, suppose the medium cuts all correspond to small vertex sets. Our key observation is that the k-cut structure of the graph forbids certain types of sunflowers in the set family
corresponding to the medium cuts; however, estimates from the Sunflower Lemma would ensure
that if there are many medium cuts, then such a sunflower would be forced to exist.
For, consider a k-sunflower of medium cuts S1, S2,..., Sk , in which the coreC is a 2-cut of weight
at least k
kâˆ’1Î»k . (Handling cases where the core is empty or corresponds to a smaller 2-cut are details
we defer to the actual proof.) Suppose we contract C as well as each petal Pi = Si \ C to single
verticesc and pi , respectively. To provide intuition, let us suppose that there are the same number
of edges r between the core and each petal, and let a â‰¥ k
kâˆ’1Î»k denote the degree ofc itself; clearly
r â‰¤ a/k. See Figure 1 right.
Since each set Si is a medium cut, there are less than 2Î»k edges from {c,pi} to V \ {c,pi}. So
deg(pi ) < 2Î»k âˆ’ a + 2r for all i and consequently, the k-cut {p1,...,pkâˆ’1,V \ {p1,...,pkâˆ’1}} has
weight at most kâˆ’1 i=1 deg(pi ) < (k âˆ’ 1) Â· (2Î»k âˆ’a + 2r) â‰¤ (k âˆ’ 1)(2Î»k âˆ’a + 2a/k). Due to our bound
on a, this is at most kÎ»k = Î»k ; this is a contradiction, since Î»k is the minimum k-cut value.
In the second case, suppose there is a medium cut S where both halves involve many vertices.
Then consider a maximal sequence of medium cuts S1,..., S starting with S1 = S, such that the
Venn diagram of S1,..., S has at least 2 regions. See Figure 1 (left). From this, we can form two
subgraphs where every atom of the Venn diagram of S1,..., S in each half of S gets contracted
to a single vertex. It can be shown that every medium cut of the original graph is preserved in at
least one of the two graphs. Also, the fact that both halves of S have many vertices ensures that
the contracted graphs are strictly smaller than the original graph. We get our desired bound by
induction on n.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.          
2:6 A. Gupta et al.
1.2 Outline
In Section 2, we discuss the Sunflower Lemma. For our result, we need a slightly strengthened
version of this lemma, which involves showing the existence of multiple sunflowers and ensuring
their cores are nonempty.
In Section 3, we record some elementary bounds and definitions of cuts and k-cuts in the graph.
In Section 4, we use these for our main extremal bound on the number of medium cuts.
In Section 5, we provide an overview of the Contraction Algorithm and some simple bounds on
the probability that cuts survive it. In Section 6, we carry out the more involved analysis of how
the number of medium cuts evolves during the Contraction Algorithm.
In Section 7, we conclude with our main results on the behavior of the Contraction Algorithm
and the Recursive Contraction Algorithm.
2 SUNFLOWER LEMMA AND EXTENSIONS
In a set system F over a universe U , an r-sunflower is a collection of r sets F1,..., Fr âˆˆ F that all
share the same pairwise intersection. That is, there is a core C âŠ† U such that Fi âˆ© Fj = C for all i, j,
and hence 
i Fi = C. Let sf(d,r) be the smallest number such that any set system with more than
sf(d,r) sets of cardinality at most d must have an r-sunflower. The classical bound of ErdÅ‘s and
Rado [3] shows that sf(d,r) â‰¤ d!(r âˆ’ 1)
d . A recent breakthrough by Alweiss et al. [1] shows that
sf(d,r) â‰¤ (logd)
d (r Â· log logd)
O (d)
. (1)
While we use this improved bound, it only changes lower-order terms: the older ErdÅ‘s-Rado bound
would give the same asymptotics for our applications.
For our applications for cuts, we want multiple sunflowers with distinct nonempty cores. (The
cores may intersect, even though they are distinct.) The bound must then depend on the universe
size N, since the system consisting of N singleton sets has no sunflowers with nonempty core. The
following results show that we can guarantee a nonempty core by multiplying the bound by N.
Proposition 2.1. Let F be a family of nonempty sets over a universe of N elements, where every
set has size at most d. If |F | > sf(d,r) Â· N, then F contains an r-sunflower with nonempty core.
Proof. For each elementv of the universe, consider the set system Fv := {F âˆˆ F : F 
 v}. Since
every set in F is included in some Fv , there must be some element v with |Fv | â‰¥ |F |/N > sf(d,r).
Thus, there is an r-sunflower in Fv and hence F . The core is nonempty, since it contains v.
Lemma 2.2. Let F be a family of nonempty sets over a universe of N elements, where every set
has size at most d. If |F | > sf(d,r) Â· sN, then F contains s many r-sunflowers, each with a distinct,
nonempty core.
Proof. We show this by induction on s. The base case s = 0 is vacuous. For the induction step
with s â‰¥ 1, consider a maximal nonempty set C such that F contains an r-sunflower with core C;
this exists by Proposition 2.1, since |F | > sf(d,r) Â· sN â‰¥ sf(d,r)N.
We claim that the set system FC := {F âˆˆ F : F âŠ‡ C} has size at most sf(d,r) Â· N. For, if not,
then applying Proposition 2.1 to the set system {F \ C : F âˆˆ FC } (which has the same cardinality
as FC) would give an r-sunflower S1,..., Sr with nonempty core C
. The sets S1 âˆªC,..., Sr âˆªC in
F then form an r-sunflower with core C âˆªC
, contradicting maximality of C.
Now consider the set system F  = F \FC. It has size |F | âˆ’ |FC | > sf(d,r) Â·sN âˆ’ sf(d,r) Â· N =
sf(d,r)Â·(sâˆ’1)N. By the induction hypothesis, it hassâˆ’1 many r-sunflowers with distinct nonempty
cores. These cores are all distinct fromC, since no sets containingC remain in F 
. Combining them
with the r-sunflower of core C gives s many r-sunflowers with distinct, nonempty cores.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.  
Optimal Bounds for the k-cut Problem 2:7
Fig. 2. The Venn diagram above has eight atoms.
3 SIMPLE BOUNDS AND DEFINITIONS FOR CUTS
We assume throughout we have a fixed value k â‰¥ 3. A k-cut K is a partition of V into k nonempty
sets, and we let âˆ‚K denote the set of edges crossing different parts of K. The weight of K is the
cardinality of the edge set âˆ‚K. We let Î»k be the minimum weight of any k-cut, and Î»k := Î»k /k.
A 2-cut {C,V \C} will often simply be called a cut, and we often denote it merely byC. The shore
of the cut is whichever of the sets C or V \C is smaller. (If they are the same size, then choose one
arbitrarily), and the shoresize is the cardinality of the shore.
For vertex sets A, B we let E(A, B) denote the set of edges crossing from A to B. We also write
âˆ‚S = E(S,V \ S) for a set S âŠ† V .
We define a small cut to be a cut C with
|âˆ‚C| <
k
k âˆ’ 1
Î»k ,
and we define a medium cut to be a cut C such that
k
k âˆ’ 1
Î»k â‰¤ |âˆ‚C| < 2Î»k .
Given vertex sets F1,..., Ft , we denote their Venn diagram by Venn(F1,..., Ft ). An atom denotes
a nonempty region of the diagram, i.e., a nonempty set that can be expressed asG1âˆ©Â·Â·Â·âˆ©Gt , where
each set Gi is either Fi , or its complement V \ Fi . See Figure 2.
We say that F1,..., Ft generate the -cut K = {A1,...,A } where A1,...,A are the atoms of
Venn(F1,..., Ft ). Observe that the weight of K is at most |âˆ‚F1 | + Â·Â·Â· + |âˆ‚Ft |.
We begin with a few straightforward bounds.
Proposition 3.1. If n â‰¥ k, then m â‰¥ nk
2(kâˆ’1) Î»k .
Proof. Sort the vertices in ascending order of degree, so deg(v1) â‰¤ deg(v2) â‰¤ Â·Â·Â· â‰¤ deg(vn ).
The k-cut generated by the singleton sets {v1},..., {vkâˆ’1} has weight at most deg(v1) + Â·Â·Â· +
deg(vkâˆ’1); since Î»k is the minimum k-cut, we thus have deg(v1) + Â·Â·Â· + deg(vkâˆ’1) â‰¥ Î»k . Also,
because of the sorted vertex ordering, we have deg(vi ) â‰¥ deg(vkâˆ’1) â‰¥ deg(v1 )+Â·Â·Â·+deg(vkâˆ’1 )
kâˆ’1 â‰¥ Î»k
kâˆ’1
for all i â‰¥ k.
Summing vertex degrees, the total number of edges m is given by
2m =
deg(v1) + Â·Â·Â· + deg(vkâˆ’1)

+
deg(vk ) + Â·Â·Â· + deg(vn )

â‰¥ Î»k + (n âˆ’ k + 1) Â· Î»k /(k âˆ’ 1) = nÎ»k /(k âˆ’ 1) = nkÎ»k /(k âˆ’ 1).
Lemma 3.2. There are fewer than 2kâˆ’2 small cuts.
Proof. Suppose not; in this case, we will construct a k-cut of weight less than Î»k , which contradicts the definition of Î»k .
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.        
2:8 A. Gupta et al.
For i = 1,..., k âˆ’ 1, let us choose an arbitrary small cut Si such that |Venn(S1,..., Si )| â‰¥ i + 1.
We claim that we can always find such an Si . For, if |Venn(S1,..., Siâˆ’1)| â‰¥ i + 1, then Si can be
chosen arbitrarily. Otherwise, suppose that Venn(S1,..., Siâˆ’1) has precisely i atoms A1,...,Ai .
The only small cut T such that |Venn(S1,..., Siâˆ’1,T )| = i = |Venn(S1,..., Siâˆ’1)| would have the
form T = 	
j âˆˆI Aj for some subset I âŠ† {1,... i}. There are at most 2iâˆ’1 âˆ’ 1 such cuts (keeping in
mind that I and its complement determine the same cut). Since by assumption there are at least
2kâˆ’2 small cuts, there exists a small cut Si with Venn(S1,..., Siâˆ’1, Si ) > i as desired.
At the end, we have |Venn(S1,..., Skâˆ’1)| â‰¥ k. So the small cuts S1,..., Skâˆ’1 generate a t-cut for
t â‰¥ k whose weight is less than (k âˆ’ 1) Â· k
kâˆ’1Î»k = Î»k . This is our desired contradiction.
Proposition 3.3. Let T1,...,Tr be medium cuts where r = k/2. Then either
|Venn(T1,...,Trâˆ’1)| < 2(r âˆ’ 1) or |Venn(T1,...,Tr )| < 2r (or both).
Proof. Let us first consider the case where k is even and r = k/2. Suppose for contradiction
that |Venn(T1,...,Tr )| = t â‰¥ k. Then T1,...,Tr generate a t-cut K. Since T1,...,Tr are medium
cuts, the weight of K is less than r Â· 2Î»k = Î»k ; this contradicts that Î»k is the minimum k-cut value.
Next consider the case where k is odd and r = (k + 1)/2. Suppose for contradiction that
|Venn(T1,...,Tr )| = t â‰¥ k +1 and |Venn(T1,...,Trâˆ’1)| = t â‰¥ k âˆ’1. The sets T1,...,Trâˆ’1 generate
a t
-cut K
; since T1,...,Trâˆ’1 are medium cuts, the weight of K is less than (r âˆ’ 1) Â· 2Î»k = kâˆ’1
k Î»k .
If t â‰¥ k, then this contradicts that Î»k is the minimum k-cut value. So it must be that t = k âˆ’ 1
exactly.
Let A1,...,Aj be the atoms of Venn(T1,...,Trâˆ’1) cut by Tr ; since t â‰¥ k + 1 and t = k âˆ’ 1 we
must have j â‰¥ 2. The edge sets E(Tr,Ai \ Tr ) are all disjoint and Tr is a medium cut, so at least
one atom Ai must satisfy |E(Tr,Ai \ Tr )|â‰¤|âˆ‚Tr |/j â‰¤ |âˆ‚Tr |/2 â‰¤ Î»k . The sets T1,...,Trâˆ’1,Ai then
generate a k-cut K of weight less than (r âˆ’1)Â·2Î»k +Î»k = Î»k , contradicting that Î»k is the minimum
k-cut value.
4 BOUNDING THE NUMBER OF MEDIUM CUTS
We now analyze the combinatorial structure of the medium cuts to show the following key bound:
Theorem 4.1. There are kO (k)
n many medium cuts.
We prove this in two stages. First, using the Sunflower Lemma, we show it for the special case
when all the medium cuts of G have shoresize at most k. We then extend to the general case by an
induction on the graph size.
Lemma 4.2. Suppose the medium cuts all have shoresize at most k. Then there are at most kO (k)
n
medium cuts.
Proof. Let F be the set family consisting of the shores of the medium cuts. We claim that F
cannot have 2k many k-sunflowers with distinct nonempty cores. For, suppose for contradiction
that it does so. Then, by Lemma 3.2, at least one of the sunflowers has a nonempty core C with
|âˆ‚C| â‰¥ k
kâˆ’1
Â¯
Î»k . Let the sets in this sunflower be S1,..., Sk âˆˆ F where Si âˆ© Sj = C for i  j.
Let Pi := Si \C be the petal for each Si , and let Li = E(Pi,C) denote the set of edges between Pi
and C. By inclusion-exclusion, we have |âˆ‚Pi | = |âˆ‚Si |âˆ’|âˆ‚C| + 2|Li |. Since each Si is a medium cut,
it satisfies |âˆ‚Si | < 2Î»k , so
|âˆ‚Pi | < 2Î»k âˆ’ |âˆ‚C| + 2|Li |.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.   
Optimal Bounds for the k-cut Problem 2:9
Suppose the petals are sorted in ascending order of |Li |, so that |Li |â‰¤|Li+1 | for i = 1,..., k âˆ’ 1.
Consider the k-cut K generated by the disjoint sets P1,..., Pkâˆ’1. We can bound its weight |âˆ‚K| by
|âˆ‚K| â‰¤ 

kâˆ’1
i=1
|âˆ‚Pi | <


kâˆ’1
i=1
(2Î»k âˆ’ |âˆ‚C| + 2|Li |) = 2(k âˆ’ 1)Î»k âˆ’ (k âˆ’ 1)|âˆ‚C| + 2


kâˆ’1
i=1
|Li |.
Because the sets Li are pairwise disjoint subsets of âˆ‚C in sorted order of size, we have


kâˆ’1
i=1
|Li | â‰¤ k âˆ’ 1
k


k
i=1
|Li | â‰¤ k âˆ’ 1
k |âˆ‚C|,
and so
|âˆ‚K| < 2(k âˆ’ 1)Î»k âˆ’ (k âˆ’ 1)|âˆ‚C| + 2 Â· kâˆ’1
k |âˆ‚C| = 2(k âˆ’ 1)Î»k âˆ’ (kâˆ’1)(kâˆ’2)
k |âˆ‚C|.
Finally, using the bound |âˆ‚C| â‰¥ k
kâˆ’1Î»k , we get
|âˆ‚K| < 2(k âˆ’ 1)Î»k âˆ’ (kâˆ’1)(kâˆ’2)
k Â· k
kâˆ’1Î»k = kÎ»k = Î»k .
This contradicts the definition of Î»k as the minimum k-cut. Thus F cannot have 2k many ksunflowers with distinct, nonempty cores. By our hypothesis, the sets in F have size at most k.
Thus, by Lemma 2.2 (with parameters d = r = k and N = n and s = 2k ) and Equation (1), this
means
|F | â‰¤ sf(d,r) Â· sN â‰¤ (logd)
d (r Â· log logd)
O (d) Â· 2kn â‰¤ kO (k)
n.
We will next remove the restriction on the shoresize, completing the proof.
Proof of Theorem 4.1. We will show by induction onn that for n > k there are at mostck (nâˆ’k)
medium cuts in any graph G, for some constant ck = kO (k)
.
If every medium cut has shoresize at most k, then we have already shown this in Lemma 4.2 for
appropriate choice of ck . (This covers the base case of the induction n = k + 1.) We thus consider
a medium cut S with shoresize larger than k, i.e., k < |S | < n âˆ’ k.
Starting with S1 = S, let us form a maximal sequence of medium cuts S1, S2,..., S with the
property that |Venn(S1,..., St )| â‰¥ 2t for all t = 1,...,; here  â‰¥ 1, since |Venn(S)| = 2. Let
the atoms of Venn(S1,..., S ) inside S (respectively, outside S) be A1,...,Ai and B1,..., Bj . So
A1 âˆªÂ·Â·Â·âˆª Ai = S and B1 âˆªÂ·Â·Â·âˆª Bj = V \ S.
Now form a graph H1 by contracting each of the atoms A1,...,Ai and likewise form a graph H2
by contracting each of the atoms B1,..., Bj . Since A1,...,Ai partition S and B1,..., Bj partition
V \ S, these graphs have n1 = (n âˆ’ |S |) + i and n2 = |S | + j vertices, respectively. See Figure 3 for
an example.
We claim that i + j < 2( + 1) and  < k/2. For, if i + j â‰¥ 2( + 1), then consider choosing S+1 to
be an arbitrary medium cut; we would have |Venn(S1,..., S+1)| â‰¥ i + j â‰¥ 2( + 1), contradicting
maximality of . Likewise, if  â‰¥ k/2, then we would have |Venn(S1,..., Srâˆ’1)| â‰¥ 2(r âˆ’ 1) and
|Venn(S1,..., Sr )| â‰¥ 2r where r = k/2; this would contradict Proposition 3.3.
From these two bounds, we conclude that i + j â‰¤ 2 + 1 â‰¤ k. Since k < |S | < n âˆ’ k, both n1 and
n2 are strictly larger than k and strictly smaller than n. Hence, from the induction hypothesis, the
number of medium cuts in H1 and H2 is at most ck (n1 âˆ’ k) and ck (n2 âˆ’ k), respectively.
We now claim that every medium cut of the original graph G survives in either H1 or H2 (or
both). For, suppose there is some medium cut T where an edge e âˆˆ âˆ‚T lies inside an atom Ai and
an edge e âˆˆ âˆ‚T lies inside an atom Bj. Then the atoms Ai and Bj would both split into two new
atoms in Venn(S1,..., S,T ), giving |Venn(S1,..., S,T )| â‰¥ i + j + 2. This contradicts maximality
of .
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.                 
2:10 A. Gupta et al.
Fig. 3. Construction of graphs H1 (right) and H2 (middle) given medium cuts S1, S2, S3, S4 (left). Each colored
set represents a medium cut surviving in either H1 or H2. The red and blue cuts survive in H2, and the green
cut survives in H1. The purple cut survives in both H1 and H2.
Consequently, the number of medium cuts in G is at most
ck (n1 âˆ’ k) + ck (n2 âˆ’ k) = ck ((n âˆ’ |S | + i) + (|S | + j) âˆ’ 2k) = ck (n + i + j âˆ’ 2k).
Now, i + j â‰¤ k so this is at most ck (n âˆ’ k), completing the induction.
5 THE CONTRACTION PROCESS
Our next goal will be to lower-bound the probability that a given k-cut K is preserved during
the Contraction Algorithm. More generally, for an edge set J âŠ† E(G), we say that J survives the
Contraction Algorithm if no edge of J ever gets selected during any iteration. Following [9], we
define the Contraction Process up to stage i for J as follows:
Starting with the graph Gn = G, in stage j we select an edge ej from the resulting
(random) subgraphGj uniformly at random excluding the edges in J itself, and contract
ej to get the graph Gjâˆ’1. We stop when we reach Gi .
It is possible, and allowed, for some edges of J to become self-loops and be removed from the
graph. When considering a subgraph Gj during the Contraction Process for J, bear in mind that
we may have J  E(Gj).
For the Contraction Process for J, we define the key statistic
Ri =

n
j=i+1
Î»k
|E(Gj)|
. (2)
Here, Ri serves as a linearized approximation to the probability of avoiding J in the Contraction
Algorithm. Specifically, we show the following result, which is a slight reformulation of Reference
[9]:
Proposition 5.1. Let J be an edge set and let Î± = |J|/Î»k . Suppose we run the Contraction Algorithm up to stage i â‰¥ max{4Î±k, k}. The probability that J survives is at least eâˆ’Î± kE[Ri]âˆ’Î± k , where the
expectation is taken over the Contraction Process for J up to stage i.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.  
Optimal Bounds for the k-cut Problem 2:11
Proof. For i â‰¤ j â‰¤ n let us define
xj = |J|
|E(Gj)|
= Î±kÎ»k
|E(Gj)|
,
whereGj is the subgraph obtained at stage j of the Contraction Process for J starting atG. We also
define the corresponding random variable
LG =
n
j=i+1
(1 âˆ’ xj).
Note that, by the property of iterated expectations, we calculate the expected value of LG as
E[LG ] = 1
|E(G) \ J|


e âˆˆE(G)\J
E[LG | en = e] = 1
|E(G) \ J|


e âˆˆE(G)\J
E[(1 âˆ’ xn )LG/e ]
= (1 âˆ’ xn )


e âˆˆE(G)\J
E[LG/e ]
|E(G) \ J|
,
where G/e denotes the graph obtained by contracting edge e in G; note that Gnâˆ’1 = G/en during
the Contraction Process.
We first claim that if we run the Contraction Algorithm on G, then J survives to stage i with
probability at least E[LG ]. We show this by induction on n. The case n = i holds vacuously, since
then LG = 1 with probability one and J survives with probability one.
For the induction step, let n > i. The Contraction Algorithm chooses edge en uniformly at
random from E(G) and then continues on G/en. Edge set J survives to stage i if and only if the
following events occur: (i) en âˆˆ E(G) \ J and (ii) conditional on fixed choice of en = e, the edge
set J survives the Contraction Algorithm in G/e to stage i. By the induction hypothesis, the latter
event has probability at least E[LG/e ], and so
Pr(J survives starting from G) â‰¥
1
|E(G)|


e âˆˆE(G)\J
E[LG/e ] = |E(G) \ J|
|E(G)|


e âˆˆE(G)\J
E[LG/e ]
|E(G) \ J|
.
Note now that
|E(G) \ J|
|E(G)| â‰¥ |E(G)|âˆ’|J|
|E(G)| = 1 âˆ’ xn,
so this is at least
(1 âˆ’ xn )


e âˆˆE(G)\J
E[LG/e ]
|E(G) \ J|
= E[LG ],
which concludes the induction.
So J survives the Contraction Algorithm with probability at least E[LG ]. We need to bound LG .
Consider some stage j â‰¥ i of the Contraction Process for J. By Proposition 3.1, since i â‰¥ k, we
have |E(Gj)| â‰¥ jk
2(kâˆ’1) Î»k so xj â‰¤ 2Î± (k âˆ’ 1)/j. Since j â‰¥ i â‰¥ 4Î±k this implies xj â‰¤ 1/2. We use the
elementary identity 1 âˆ’ x â‰¥ eâˆ’xâˆ’x2
for x âˆˆ [0, 1/2] to get:
LG =
n
j=i+1
(1 âˆ’ xj) â‰¥
n
j=i+1
eâˆ’xjâˆ’x2
j â‰¥
n
j=i+1
eâˆ’Î± kÎ»k / |E(Gj )|âˆ’(2Î± (kâˆ’1)/j)
2
= eâˆ’Î±kRiâˆ’4Î±2 (kâˆ’1)
2 n
j=i+1 1/j 2
â‰¥ eâˆ’Î±kRiâˆ’4Î±2 (kâˆ’1)
2/i
.
Since i â‰¥ 4Î±k, we thus have LG â‰¥ eâˆ’Î±kRiâˆ’Î± k . Taking expectations and using Jensenâ€™s inequality,
we have E [LG ] â‰¥ E[eâˆ’Î±kRiâˆ’Î± k ] â‰¥ eâˆ’Î± kâˆ’Î± kE[Ri]
.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021. 
2:12 A. Gupta et al.
Using this, we can recover Karger and Steinâ€™s original success probability of nâˆ’2Î± (kâˆ’1)
. Although
it is much weaker than the bound of nâˆ’Î± k we want, this is useful for a few edge cases in the analysis.
Corollary 5.2. For any parameter Î± â‰¥ 1 and any k-cut K with |âˆ‚K| â‰¤ Î±Î»k , the Contraction
Algorithm with parameter Ï„ = 4Î±k selects K with probability at least nâˆ’2Î± (kâˆ’1)
kâˆ’O (Î± k)
.
Proof. Consider the Contraction Process for edge set J = âˆ‚K. In each stage j, Proposition 3.1
shows that graph Gj has at least jk
2(kâˆ’1) Î»k edges. Hence, with probability one, there holds
RÏ„ â‰¤

n
j=Ï„ +1
2(k âˆ’ 1)
kj â‰¤
2(k âˆ’ 1)
k log(n/Ï„ ).
By Proposition 5.1, the probability K survives to stage Ï„ is at least eâˆ’Î± kE[RÏ„ ]âˆ’Î± k , which is at least
nâˆ’2Î± (kâˆ’1) with our bound on RÏ„ . Next, suppose that K does survive to stage Ï„ (this includes the
case where n â‰¤ Ï„ ). The resulting graph has at most Ï„ vertices and hence at most kÏ„ different k-cuts.
Thus, K is selected from this graph with probability at least kâˆ’Ï„ â‰¥ kâˆ’O (Î± k)
. Overall K is selected
with probability at least nâˆ’2Î± (kâˆ’1)
kâˆ’O (Î± k)
.
6 ANALYZING THE DYNAMICS OF THE CONTRACTION PROCESS
Our goal now is to analyze the Contraction Process for a given edge set J. Let Î± = |J|/Î»k . We fix
some parameter Îµ âˆˆ [0, 1/k), and define a good cut to be a medium cut C with
|âˆ‚C \ J| â‰¥ (1 âˆ’ Îµ) k
k âˆ’ 1
Î»k ;
the role of Îµ will be explained later. We also define two related parameters
Î´ := 1 âˆ’ Îµk
k âˆ’ 1 , and Î² := k + 2Î±k/Îµ.
Note that Î´ > 0 and 1 + Î´ = (1 âˆ’ Îµ)k/(k âˆ’ 1). We begin with a lower bound on edge count in a
single iteration of the Contraction Algorithm.
Proposition 6.1. Let s be the number of good cuts in G. If n â‰¥ Î², then
m â‰¥ s Â· k
kâˆ’1Î»k /2 + (n âˆ’ s âˆ’ Î²) Â· Î»k .
Proof. Each vertex v of G corresponds to a cut Cv . At most k âˆ’ 2 of these vertex cuts may be
small cuts. For, if there are k âˆ’ 1 such vertices v1,v2,...,vkâˆ’1, then the k-cut generated by the
{v1},..., {vkâˆ’1} would have weight below (k âˆ’ 1) Â· k
kâˆ’1Î»k = kÎ»k = Î»k , a contradiction.
Let U denote the set of vertices v for which cut Cv is medium but not good. For v âˆˆ U , we have
|âˆ‚Cv | â‰¥ k
kâˆ’1Î»k and hence |âˆ‚Cv âˆ© J| â‰¥ ÎµÎ»k . Each edge appears in at most two vertex cuts, so
|J| â‰¥ 1
2


v âˆˆU
|âˆ‚Cv âˆ© J|â‰¥|U |ÎµÎ»k /2;
since |J| = Î±kÎ»k , this implies |U | â‰¤ 2Î±k/Îµ.
Summarizing, at most k âˆ’ 2 vertices correspond to small cuts, and at most s + 2Î±k/Îµ vertices
correspond to medium cuts. The remaining vertices (at least nâˆ’sâˆ’2Î±k/Îµâˆ’k+2 of them) correspond
to large cuts so their degree is at least 2Î»k . We thus have
2m â‰¥ (s + 2Î±k/Îµ) Â· k
kâˆ’1Î»k + (n âˆ’ s âˆ’ 2Î±k/Îµ âˆ’ k + 2) Â· 2Î»k â‰¥ s Â· k
kâˆ’1Î»k + (n âˆ’ s âˆ’ Î²) Â· 2Î»k .
For our purposes, we can combine Propositions 3.1 and 6.1 to get the following (somewhat crude)
estimate:
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.  
Optimal Bounds for the k-cut Problem 2:13
Corollary 6.2. If G has s good cuts, then m â‰¥ (n âˆ’ Î²)Î»k âˆ’ min{s, (n âˆ’ Î²)}Î»k /2.
We are now ready derive the key bound on the random variable Ri as defined in Equation (2).
For p â‰¥ j and s â‰¥ 0, define the function
f (j,s,p) = log(p/j) +
log
1 + (s/p)(1 + 1/Î´ )(1 âˆ’ (j/p)
Î´ )

1 + Î´ . (3)
We will prove a bound on E[Ri] in terms of the function f by induction. The derivation of
the function f is itself rather opaque; we describe the (non-rigorous) analysis that leads to it in
Appendix A. We first observe a few analytical properties of function f .
Proposition 6.3. For p â‰¥ j and s â‰¥ 0, we have the following:
(1) Function f (j,s,p) is a well-defined, nonnegative, nondecreasing, concave-down function of s.
(2) The function y â†’ y + f (j,seâˆ’(1+Î´ )y,p) is an increasing function of y.
Proof. (1) The argument of the logarithm in function f is an affine function of s, with constant term 1 and coefficient 1
p (1 + 1/Î´ )(1 âˆ’ (j/p)
Î´ ) â‰¥ 0.
(2) The derivative as a function of y is
Î´e (1+Î´ )y
Î´e (1+Î´ )y + (s/p)(1 + Î´ )(1 âˆ’ (j/p)Î´ )
,
which is positive.
Lemma 6.4. Suppose that G has s good cuts and n vertices. Then, for the Contraction Process for J
up to some stage i with Î² â‰¤ i â‰¤ n, we have E[Ri] â‰¤ f (i âˆ’ Î²,s,n âˆ’ Î²).
Proof. We show this by induction on n. We will write p = n âˆ’ Î², j = i âˆ’ Î² and m = |E(G)|. The
case n = i is clear, since Ri = 0 = f (i âˆ’ Î²,s,i âˆ’ Î²).
For the induction step with n > i, the Contraction Process first selects an edge of E(G) \ J,
arriving at a new graph G with n âˆ’ 1 vertices. So
E[Ri] = Î»k
m + E[RG
i ],
where RG
i denotes the random variables defined in Equation (2) for graph G
.
Let random variable S denote the number of good cuts in G
. By the induction hypothesis
applied to G
, we have
E[Ri] â‰¤ (Î»k /m) + E[f (j, S
,p âˆ’ 1)]. (4)
Each good cut C is selected with probability at least |âˆ‚C\J |
|E(G)\J | â‰¥ k
kâˆ’1 (1 âˆ’ Îµ)Î»k /m = (1 + Î´ )Î»k /m, so
E[S
] â‰¤ s(1 âˆ’ (1 + Î´ )Î»k /m) â‰¤ seâˆ’(1+Î´ )Î»k /m .
By Proposition 6.3, Jensenâ€™s inequality applies for the random variable S in Equation (4), giving
E[Ri] â‰¤ (Î»k /m) + f (j, E[S
],p âˆ’ 1) â‰¤ (Î»k /m) + f (j,seâˆ’(1+Î´ )Î»k /m,p âˆ’ 1).
Next, by Corollary 6.2, we have m â‰¥ pÎ»k âˆ’ min{s,p}Î»k /2. So Î»k /m â‰¤ z, where we define
z = 2
2p âˆ’ min{s,p}
.
Since y + f (j,seâˆ’(1+Î´ )y,p âˆ’ 1) is an increasing function of y, we therefore have
E[Ri] â‰¤ z + f (j,seâˆ’(1+Î´ )z ,p âˆ’ 1).
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021. 
2:14 A. Gupta et al.
To finish the proof and complete the induction, it suffices to showz+f (j,seâˆ’(1+Î´ )z ,pâˆ’1) â‰¤ f (j,s,p)
or, equivalently,
e (1+Î´ )(z+f (j,seâˆ’(1+Î´ )z,pâˆ’1)) âˆ’ e (1+Î´ )f (j,s,p) â‰¤ 0. (5)
After substituting in the formula for f , this expands to
 pâˆ’1
j
1+Î´ 
e (1+Î´ )z +  s
pâˆ’1

(1 + 1/Î´ )

1 âˆ’  j
pâˆ’1
Î´   âˆ’  p
j
1+Î´ 
1 +
s
p

(1 + 1/Î´ )

1 âˆ’  j
p
Î´   â‰¤ 0.
(6)
To simplify further, let us define a number of terms:
r = s/p, q = j/p, Î¸ = 1 âˆ’ 1/p, t = 2 âˆ’ min{r, 1}.
We thus have pâˆ’1
j = Î¸/q, s
pâˆ’1 = r/Î¸, and z = 2(1 âˆ’ Î¸ )/t. The inequality in Equation (6) becomes
(Î¸/q)
1+Î´

e2(1âˆ’Î¸ )(1+Î´ )/t + (r/Î¸ )(1 + 1/Î´ )(1 âˆ’ (q/Î¸ )
Î´ )

âˆ’ (1/q)
1+Î´

1 + r(1 + 1/Î´ )(1 âˆ’ qÎ´ )

â‰¤ 0.
Clearing out common factor q1+Î´ and multiplying the left term through by Î¸ 1+Î´ , it is equivalent
to

Î¸ 1+Î´ e2(1âˆ’Î¸ )(1+Î´ )/t + r(1 + 1/Î´ )(Î¸ Î´ âˆ’ qÎ´ )

âˆ’
1 + r(1 + 1/Î´ )(1 âˆ’ qÎ´ )

â‰¤ 0.
Collecting terms, multiplying through by Î´, and changing signs for convenience, Equation (5)
is thus equivalent to showing:
Î´ + r(1 + Î´ )(1 âˆ’ Î¸ Î´ ) âˆ’ Î´Î¸ 1+Î´ e2(1âˆ’Î¸ )(1+Î´ )/t â‰¥ 0. (7)
Note that parameter q no longer plays a role in Equation (7). Since r â‰¥ 2 âˆ’ t, it suffices to show
that
Î´ + (2 âˆ’ t)(1 + Î´ )(1 âˆ’ Î¸ Î´ ) âˆ’ Î´Î¸ 1+Î´ e2(1âˆ’Î¸ )(1+Î´ )/t â‰¥ 0. (8)
To show Equation (8), let us define a function
F (Î¸,t) = Î´ + (2 âˆ’ t)(1 + Î´ )(1 âˆ’ Î¸ Î´ ) âˆ’ Î´Î¸ 1+Î´ e2(1âˆ’Î¸ )(1+Î´ )/t
for independent variables Î¸,t. We need to show that F (Î¸,t) â‰¥ 0 for all Î¸ âˆˆ [0, 1] and t âˆˆ [1, 2].
The second partial derivative of F with respect to t is given by
âˆ‚2F (Î¸,t)
âˆ‚t 2 = âˆ’4Î´ (1 + Î´ )(1 âˆ’ Î¸ )Î¸ 1+Î´ e2(1+Î´ )(1âˆ’Î¸ )/t ((1 + Î´ )(1 âˆ’ Î¸ ) + t)
t 4 ,
which is clearly negative for Î´, Î¸,t in the given range. Thus, the minimum value of F (Î¸,t) in the
region occurs at eithert = 1 ort = 2. So, to show that F (Î¸,t) â‰¥ 0, it suffices to show that F (Î¸, 1) â‰¥ 0
and F (Î¸, 2) â‰¥ 0.
At t = 2 we have F (Î¸, 2) = Î´ (1 âˆ’ e (1+Î´ )(1âˆ’Î¸ )
Î¸ 1+Î´ ). To show that F (Î¸, 2) â‰¥ 0, we thus need to
show that e (1+Î´ )(1âˆ’Î¸ )
Î¸ (1+Î´ ) â‰¤ 1, or equivalently e1âˆ’Î¸ Î¸ â‰¤ 1; this can be verified by routine calculus.
At t = 1, we have F (Î¸, 1) = Î´ + (1 + Î´ )(1 âˆ’ Î¸ Î´ ) âˆ’ Î´Î¸ 1+Î´ e2(1âˆ’Î¸ )(1+Î´ )
. Note that F (1, 1) = 0. So, to
show that F (Î¸, 1) â‰¥ 0 for all Î¸ âˆˆ [0, 1], it suffices to show that the derivative of F (Î¸, 1) with respect
to Î¸ is negative for Î¸ âˆˆ (0, 1). This derivative is given by
âˆ‚F (Î¸, 1)
âˆ‚Î¸ = âˆ’Î´ (1 + Î´ )e2(1+Î´ )(1âˆ’Î¸ )
Î¸âˆ’(1âˆ’Î´ )

eâˆ’2(1+Î´ )(1âˆ’Î¸ ) âˆ’ 2Î¸ 2 + Î¸

.
To show this is negative, it suffices to show that eâˆ’2(1+Î´ )(1âˆ’Î¸ ) âˆ’ 2Î¸ 2 + Î¸ > 0. Since Î´ â‰¤ 1/2, it
suffices to show that eâˆ’3(1âˆ’Î¸ ) âˆ’2Î¸ 2 +Î¸ > 0, which can be verified by routine calculus for Î¸ âˆˆ (0, 1).
This shows that âˆ‚F (Î¸,1)
âˆ‚Î¸ â‰¤ 0, and so F (Î¸,t) â‰¥ F (1, 1) = 0.
Thus, F (Î¸,t) â‰¥ 0 for all Î¸ âˆˆ [0, 1] and t âˆˆ [1, 2] and hence the inequality of Equation (8)
holds.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.                   
Optimal Bounds for the k-cut Problem 2:15
7 PUTTING IT TOGETHER: BOUNDS ON THE CONTRACTION ALGORITHM
We now finish by getting our main bound for the Contraction Algorithm.
Lemma 7.1. Suppose that J is an edge set with Î± = |J|/Î»k and n â‰¥ i â‰¥ 8Î±k2 + 2k. Then J survives
the Contraction Algorithm to stage i with probability at least (n/i)
âˆ’Î± kkâˆ’O (Î± k2 )
.
Proof. Let us set Îµ = k+1
2k2 , and also define Î² = k + 2Î±k/Îµ, and j = i âˆ’ Î²,p = n âˆ’ Î² and Î´ = 1
2k .
By Theorem 4.1, the number of medium cuts in G is at most an for a = kO (k)
, and so Lemma 6.4
gives:
E[Ri] â‰¤ f (j, an,p) = log(p/j) +
log
1 + an
p (1 + 1/Î´ )(1 âˆ’ (j/p)
Î´ )

1 + Î´ .
Our condition on i ensures i â‰¥ 2Î². So p â‰¥ n/2 and j â‰¥ i/2, and thus log(p/j) â‰¤ log(n/i) + O(1)
and an/p â‰¤ 2a. We therefore have
E[Ri] â‰¤ log(n/i) +
log
1 + 2a(1 + 1/Î´ )

1 + Î´ + O(1) â‰¤ log(n/i) + log a + O(1).
Note that i â‰¥ max{4Î±k, k} as required in Proposition 5.1. Thus, J survives with probability at least
(n/i)
âˆ’Î± keâˆ’Î± kâˆ’Î± k (log a+log k+O (1)). Since a = kO (k)
, this is at least (n/i)
âˆ’Î± kkâˆ’O (Î± k2 )
.
Theorem 7.2. Running the Contraction Algorithm with parameter Ï„ = 20Î±k2 produces any
given k-cut K of weight at most Î±Î»k with probability at least nâˆ’Î± kkâˆ’O (Î± k2 )
.
Proof. If n â‰¥ Ï„ , then Lemma 7.1 applied to J = âˆ‚K (noting that necessarily Î± â‰¥ 1) shows
that K survives to GÏ„ with probability at least (n/Ï„ )
âˆ’Î± kkâˆ’O (Î± k2 )
. Then K is selected from GÏ„ with
probability at least kâˆ’Ï„ â‰¥ kâˆ’O (Î± k2 )
. Combining these probability bounds gives the stated result. If
n < Ï„ , then the Contraction Algorithm simply selects a random k-cut, and so K is chosen with
probability at least kâˆ’n â‰¥ kâˆ’O (Î± k2 )
.
Corollary 7.3. There are at most nÎ± kkO (Î± k2 ) many k-cuts in G with weight at most Î±Î»k .
We could enumerate these k-cuts by repeatedly running the Contraction Algorithm, but each
iteration would cost O(n2) time giving an overall runtime of roughly O(nÎ± k+2). The next result
shows how to remove this extraneous n2 factor using a recursive version of the Contraction Algorithm from Reference [12]. Note that directly printing out the k-cuts could take Î©(nÎ± k+1) time,
since each k-cut defines a partition of V . Hence, the algorithm necessarily produces the collection of k-cuts in a compressed data structure, which supports basic operations such as counting,
sampling, and so on. See Reference [12] or Reference [9] for a more in-depth discussion.
Theorem 7.4. For each k â‰¥ 3, there is an algorithm to enumerate all k-cuts of weight at most Î±Î»k
in time nÎ± k (logn)
O (Î± k2 ) with probability at least 1 âˆ’ 1/poly(n).
Proof. First, if n â‰¤ 2k , then we directly use the Contraction Algorithm to stage Ï„ = 4Î±k. By
Corollary 5.2, this enumerates any given k-cut with probability at least nâˆ’2Î± (kâˆ’1)
kâˆ’O (Î± k)
, so we
must run it for n2Î± (kâˆ’1)
kO (Î± k) Â· poly(Î±, k, logn) trials to get them all. This gives overall runtime of
n2Î± (kâˆ’1)
kO (Î± k) Â· poly(Î±, k, logn) Â·O(n2), which is at most eO (Î± k2 ) by our assumption on n. We thus
assume for the remainder of the proof that n â‰¥ 2k .
We use a recursive algorithm, whose state is represented as a pair (H, ) where H is the current
graph and  = 0,...,T is the current level in the recursion. The algorithm begins with the input
graph (G, 0) at level  = 0. Given input (G, ) at level , there are two cases. If  < T , then
the algorithm runs t = (n/n+1)
Î± k  independent trials of the Contraction Algorithm to n+1
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.                 
2:16 A. Gupta et al.
vertices and recursively calls (H,  + 1) for each resulting contracted graph H. Otherwise, if  = T ,
then the algorithm outputs a randomly chosen k-cut. Here, the parameters ni are given by
ni =
âŽ¡
âŽ¢
âŽ¢
âŽ¢
âŽ¢
âŽ¢
max âŽ§âŽª
âŽ¨
âŽª
âŽ©
n
 2
Î± k i
, 20Î±k2
âŽ«âŽª
âŽ¬
âŽª
âŽ­
âŽ¤
âŽ¥
âŽ¥
âŽ¥
âŽ¥
âŽ¥
and the recursion depth T is the first value with nT = 20Î±k2. Since log(20Î±k2) â‰¤ O(Î±k) and
Î±k/2 â‰¥ 3/2, we have T â‰¤ O(
log log n
log(Î± k) ).
To calculate the algorithmâ€™s success probability, fix some k-cut K of G with |âˆ‚K| â‰¤ Î±Î»k , and
define a state (G, ) to be successful if no edge in K has been contracted so far from G0 = G to
G. Clearly, (G0, 0) is successful. For each successful input (G, ) with  < T , by Lemma 7.1 with
i = n+1, the probability that K survives on each trial is at least (n/n+1)
âˆ’Î± kÏˆ whereÏˆ = kâˆ’O (Î± k2 )
.
Over all t trials, K survives at least once with probability
1 âˆ’

1 âˆ’ (n/n+1)
âˆ’Î± kÏˆ
t
â‰¥ 1 âˆ’ eâˆ’Ïˆ .
Thus, given that some instance (G, ) in the recursion tree is successful, the probability that at
least one instance (G+1,  + 1) is successful is at least 1 âˆ’ eâˆ’Ïˆ â‰¥ Ïˆ/2. Over all the T = O(
log log n
log(Î± k) )
levels of the recursion, the probability that there is some successful instance (GT ,T ) is at least
(Ïˆ/2)
T â‰¥ (logn)
âˆ’O (Î± k2 )
. Finally the probability of selecting K from a successful instance (GT ,T )
is at least kâˆ’nT â‰¥ kâˆ’O (Î± k2 )
. So, overall,K is selected with probability at least (logn)
âˆ’O (Î± k2 )
Â·kâˆ’O (Î± k2 )
.
Due to our assumption that n â‰¥ 2k , this is at least (logn)
âˆ’O (Î± k2 )
.
We now bound the runtime. For each level  < T , there are âˆ’1 j=0 tj â‰¤ âˆ’1 j=0 2(nj/nj+1)
Î± k =
2 (n0/n )
Î± k instances (G, ). In each such instance, the algorithm runst trials of the Contraction
Algorithm, each takingO(n2
 ) time. The running time over all instances (G, ) is therefore at most
2 (n0/n )
Î± k Â· t Â· O(n2
 ) â‰¤ O

2T Â· (n0/n+1)
Î± k Â· n2


,
which is at most O(2T (2n0)
Î± k ), since n+1 â‰¥ n2/(Î± k)
 /2. Summed over all T recursion levels, the
total runtime is at most T Â· O(2T (2n0)
Î± k ) â‰¤ (2n)
Î± k Â· (logn)
O (1)
.
If we repeat the entire recursive algorithm from (G0, 0) a total of (logn)Î©(Î± k2 ) times, then K is
selected with probability at least 1/2. There are kO (Î± k2 )
nÎ± k many such k-cuts, so we run a further
O(Î±k2 log k logn) many trials to enumerate them all with probability 1 âˆ’ 1/poly(n).
As one concrete application, we get the main result:
Theorem 7.5. There is an algorithm to compute Î»k in time nk (logn)
O (k2 ) for any value k.
Proof. For k = 2, this is the standard Recursive Contraction Algorithm of Reference [12]. Otherwise, apply Theorem 7.4 with Î± = 1. This gives a large collection of k-cuts, which includes all the
minimum k-cuts with high probability. We output the minimum weight of all k-cuts found. (The
operation of taking minimum weight can be performed on the corresponding data structure.)
APPENDIX
A HEURISTIC BOUND ON Ri
Given a graph G with s medium cuts, consider running the Contraction Process for some edge
set J up to stage i. We will focus on the case where s  n; as it will later turn out, the resulting
formulas are also correct (although not optimized) when s is larger than n.
Journal of the ACM, Vol. 69, No. 1, Article 2. Publication date: November 2021.                                            
Optimal Bounds for the k-cut Problem 2:17
In each stage j â‰¥ i, where the intermediate graph Gj has j vertices and mj edges, each good cut
C gets selected with probability |âˆ‚C\J |
mjâˆ’ |J | â‰¥ (1 âˆ’ Îµ) k
kâˆ’1Î»k /mj = (1 + Î´ )Î»k /mj . Letting Si denote the
number of surviving good cuts at stage i, we thus have
E[Si] â‰¤ s
n
j=i+1

1 âˆ’ (1 + Î´ )Î»k
mj

â‰¤ seâˆ’ n
j=i+1 (1+Î´ )Î»k /mi = seâˆ’(1+Î´ )Ri .
Since this is just a heuristic derivation, we blur the distinction between E[Si] and Si , and we
suppose that Si itself also satisfies this bound, i.e., Si â‰¤ seâˆ’(1+Î´ )Ri .
We have Riâˆ’1 = Î»k
mi + Ri . By Proposition 6.1, we have mi â‰¥ SiÎ»k /2 + (i âˆ’ Si âˆ’ Î²)Î»k , so
Â¯
Î»k
mi
â‰¤
1
i âˆ’ Î² âˆ’ Si/2
. (9)
To carry out the induction proof later, we will need our bound on Ri to have a simple closed
form with nice concavity properties. To achieve this, we will need to use an upper bound on the
quantity Â¯
Î»k
mi
, which is a linear function of Si . As we have mentioned, in the relevant case, we have
s â‰¤ n, and in this case we will also have Si â‰¤ i. We can then upper-bound the RHS of Equation (9)
by its secant line from Si = 0 to Si = i âˆ’ Î², yielding
Î»k
mi
â‰¤
1
i âˆ’ Î²

1 +
Si
i âˆ’ Î²

;
note that by Proposition 3.1, this upper bound will also be valid in the case where Si â‰¥ i âˆ’ Î².
Again ignoring any distinctions between random variables and their expectations, this implies
Riâˆ’1 â‰¤ Ri +
1
i âˆ’ Î²

1 + seâˆ’(1+Î´ )Ri
i âˆ’ Î²

.
If we define Ð´(x) = Rx+Î² and p = n âˆ’ Î², then this can be relaxed to a differential equation with
Ð´
(i) â‰ˆ Ri+Î² âˆ’ Riâˆ’1+Î² defined as follows:
Ð´
(x) = âˆ’1
x

1 + seâˆ’(1+Î´ )Ð´(x )
x

, Ð´(p) = 0.
The differential equation has a closed-form solution:
Ð´(x) = log(p/x) +
log
1 + (s/p)(1 + 1/Î´ )(1 âˆ’ (x/p)
Î´ )

1 + Î´ .
Note the similarity of function Ð´ to the function f from Equation (3) defined in Section 6.  