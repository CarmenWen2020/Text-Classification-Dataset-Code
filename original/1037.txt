We present a unified translation of linear temporal logic (LTL) formulas into deterministic Rabin automata
(DRA), limit-deterministic Büchi automata (LDBA), and nondeterministic Büchi automata (NBA). The translations yield automata of asymptotically optimal size (double or single exponential, respectively). All three
translations are derived from one single Master Theorem of purely logical nature. The Master Theorem decomposes the language of a formula into a positive Boolean combination of languages that can be translated
into ω-automata by elementary means. In particular, Safra’s, ranking, and breakpoint constructions used in
other translations are not needed. We further give evidence that this theoretical clean and compositional
approach does not lead to large automata per se and in fact in the case of DRAs yields significantly smaller
automata compared to the previously known approach using determinisation of NBAs.
CCS Concepts: • Theory of computation → Automata over infinite objects; Modal and temporal
logics;
Additional Key Words and Phrases: Linear temporal logic, automata over infinite words, deterministic automata, nondeterministic automata
1 INTRODUCTION
Linear temporal logic (LTL) [63] is a prominent specification language, used both for model checking and the automatic synthesis of reactive systems. In the automata-theoretic approach to model
checking, the specification formula is first translated into a (nondeterministic) ω-automaton, and
then the product of this automaton with the system is further analysed [80]; similarly, in the
automata-theoretic approach to synthesis the specification is translated into a deterministic ωautomaton [65]. In both cases, the size (in terms of states, transitions, or acceptance condition
complexity) of the product and the deterministic automaton, respectively, is often the bottleneck
of the approach. Consequently, much effort has been invested on translating LTL into small automata. Until recently, most of this work has focused on nondeterministic Büchi automata (NBA),
which are suitable for model-checking [6, 16–18, 24, 25, 28, 30, 31, 75]. However, automatic synthesis and other applications, like model-checking probabilistic systems, require either deterministic
automata or at least automata with some degree of determinism. This fundamental question has
led to the introduction and analysis of numerous automata classes, such as deterministic parity automata (DPA) and deterministic Rabin automata (DRA) [7], deterministic generalised Rabin
automata (DGRA) [13], limit-deterministic Büchi automata1 (LDBA) [15, 33, 72, 78], unambiguous Büchi automata (UBA) [8, 37], good-for-games automata [35], and good-for-Markov-decisionprocesses automata [34].
The usual translations of LTL to deterministic ω-automata first convert the formula into an NBA
and then apply some variant of Safra’s determinisation procedure [61, 66, 67]. Once the NBA is
constructed, such translations “forget” the formula, and so in the determinisation step they cannot
take advantage of the formula structure or the fact that LTL only captures a subset of the ω-regular
languages. Further, they are known to be difficult to implement efficiently and to be practically
inefficient in many cases due to their generality. For this reason, two of the authors of this article
initiated in Reference [45] a line of research on how to directly translate LTL to DRAs and DGRAs.
This idea was then picked up by the community and since then several constructions to DRAs
and DGRAs [20, 22, 45, 46], LDBAs [38, 39, 72], or DPAs [21, 49], without an intermediate step
through NBAs, have been proposed. All these works share the principle of describing each state
by a collection of formulas, as happens in the classical tableaux construction for the translation
of LTL to NBA. This makes the approach particularly apt for semantics-based state reductions,
e.g., for merging states corresponding to equivalent formulas. Such reductions cannot be applied
to Safra-based constructions, where this semantic structure gets lost.
Example: The Challenge of Determinism
Every LTL formula has an equivalent NBA, but even simple formulas like FGa have no equivalent
deterministic Büchi automaton. This already indicates that translating LTL to ω-automata is substantially harder in the deterministic case. We discuss the fundamental difficulties with the help
of some examples.
Classic translation procedures from LTL to (nondeterministic) automata are based on tableaux.
Intuitively, they construct automata that, when reading a word, monitor what remains to be satisfied of the original formula. To this end, their transition function uses the expansion laws for
LTL to decompose the current formula into a part that can be checked on the current letter and
the rest to be checked in future. For instance, the expansion law a U b ≡ b ∨ (a ∧ X(a Ub)) for
the “until” operator is used to determine that, if a word that starts with the letter {a} must satisfy c ∨ a U b ≡ c ∨ b ∨ (a ∧ X(a Ub)), then after reading {a} the rest of the form must still satisfy
a U b.
In the nondeterministic case, the disjunctions in a formula produced by this process can be
turned into a nondeterministic choice among the outgoing transitions of the state corresponding to the formula. For instance, a word starting with {a} can satisfy the formula φ = FGa ≡
XFGa ∨ (XGa ∧ a) by satisfying the first or the second disjunct. The corresponding nondeterministic automaton can stick to φ after reading {a} (first disjunct), or move to Ga (second disjunct), as
illustrated in Figure 1 (left).
A Unified Translation of Linear Temporal Logic to ω-Automata 33:3
Fig. 1. NBA for FGa and an incorrect try for a DBA for GF(a ∧ Xb).
The possibility to map disjunctions to nondeterministic choices allows one to translate formulas
into nondeterministic automata with very simple acceptance conditions, like NBAs. In contrast,
deterministic automata cannot resolve disjunctions in this way, by definition. This has two consequences: (i) All disjuncts have to be treated simultaneously. (ii) Applying the transition function to
the whole disjunction is problematic. For example, for the above-mentioned formula φ = FGa, we
have φ ≡ XFGa; indeed, whether a word w satisfies φ or not does not depend on any finite prefix
of w. Therefore, applying the transition function to φ yields an automaton with one single state
and two self-loop transitions labeled by ∅ and {a}, which does not recognise the language of φ.
2
This problem stands out even more clearly with the formula φ = GF(a ∧ Xb), as illustrated in
Figure 1 (right). As for FGa, satisfaction of φ does not depend on any finite prefix, and so the
automaton has again one single state. Such an automaton cannot even detect that an infix of a
word satisfies a ∧ Xb, because this is a property stretching over two steps. This example suggests
to monitor not only the evolution of the complete formula, but also the evolution of its subformulas,
such as a ∧ Xb, to check which ones are (repeatedly) satisfied and which ones not.
A consequence of (i) is that disjunctions in the formula must be handled at the level of the acceptance condition. For instance, consider the formula φ = Fa ∧ (FGb ∨ FGc). Due to the disjunction,
there are two ways to satisfy the formula, depending on whether the first or the second disjunct
holds. For each case, the automaton has to check that (a) it is indeed that particular case, and
that (b) given the case, φ is satisfied. Our translation follows this pattern of a big disjunction over
the possible cases, in each of which several simpler properties are checked. For this, our “Master
Theorem” decomposes the language of any LTL formula φ into a Boolean combination
L(φ) =
n
i=1
Ui ∩Vi
of simpler languages Ui,Vi for (a) and (b), respectively. As a result, the formula can be translated
into an automaton as a union of intersections of simpler automata.
A Unified Translation of LTL to ω-Automata
Our contribution is a unified approach to the translation of LTL to NBAs, LDBAs, and DRAs that
further enjoys the following properties, discussed below: semantic state labels, compositionality,
asymptotic optimality, symmetry, independence of syntactic restrictions, and practical relevance.
Unified Approach. Our translations rely on a novel Master Theorem, which decomposes the language of a formula into a positive Boolean combination of plain languages,3 easy to translate
into automata. Not only is the approach simpler than previous ones [22, 72], but it also results
in very similar algorithms for the translation into DRAs, NBAs, and LDBAs, differing only in the
translations of the plain languages. More precisely, the automaton for the formula is obtained from
2In other words, the language of φ has a trivial right congruence, in the sense of, e.g., Reference [2], thus yielding only a
trivial automaton.
3Corresponding to the “safety,” “guarantee” (co-safety), “recurrence,” and “persistence” classes of LTL formulas [56, 74].
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:4 J. Esparza et al.
automata recognising the plain languages by means of standard operations for closure under union
and intersection. Intuitively, the user of the Master Theorem provides translations to the target
class of automata for simple fragments of LTL and obtains a compositional translation for all LTL
formulas.
Semantic Translation. Our translations use the expansion laws for LTL operators, splitting a formula into a part immediately checkable on a current letter and the rest to be checked on the rest
of the word. As a consequence, states can be described “semantically” in terms of a collection of
formulas, similarly to the classic tableaux-based translations or to derivatives of regular expressions [11] as used for LTL [76]. This allows us to apply efficient semantics-based state reductions.
For example, states corresponding to equivalent formulas can be merged. Such semantics-based
reductions cannot be applied in general to Safra-based constructions, because the semantic structure gets lost in translation. Besides, semantic description of states can be further exploited for
generic [55] and learning-based heuristics [42] to speed up synthesis.
Compositionality. In contrast to the monolithic Safra-based or derivatives-based approaches, the
decomposition by the Master Theorem yields a translation procedure in which the final automaton
is a Boolean combination of many, typically small, automata.
Asymptotic Optimality. Deterministic generalised Rabin automata are the most compact among
the deterministic automata used in practice,4 in particular compared to deterministic parity automata (DPA). Previous translations to D(G)RA were either limited to fragments of LTL [5, 45, 46]
or had triple exponential complexity [20, 22]. Here, we provide constructions for all mentioned
types of automata matching the asymptotic double exponential size for D(G)RAs and LDBAs, and
the exponential size or NBAs. Thus, our construction is the first direct translation from LTL to
D(G)RAs with a proven double exponential size bound.
Symmetry. The first direct translations of LTL to deterministic automata used auxiliary automata
to monitor each F- (Finally) and G- (Globally) subformula [45, 46]. While this approach worked
for fragments of LTL, subsequent constructions for full LTL [20, 22, 72] could not preserve the
symmetric treatment, thus, we consider these constructions to be asymmetric. They only used
auxiliary automata for G-subformulas, at the price of more complex constructions, e.g., breakpoint constructions similar to Reference [58]. Our translation re-establishes the symmetry and it
treats F and G equally (actually, and more generally, it treats each operator and its dual equally),
which results in simpler automata constructions.
Independence of Syntax. Previous translations were quite sensitive to the operators used in the
syntax of LTL. In particular, the only greatest-fixed-point operator they allowed was G, and operators such as R (Release) needed to be removed. Since formulas also had to be in negation normal
form, pre-processing of the input often led to unnecessarily large formulas. While our translations
still require negation normal form, it allows for direct treatment of R, W (Weak Until), and other
operators.
Practical Relevance. On top of its theoretical advantages, our translation is comparable to or
even better in practice than previous translations to NBAs, LDBAs, and DRAs. The LTL synthesis
tool Strix [55, 57], which won the LTL synthesis track of the 2018, 2019, and 2020 editions of
the SyntComp competition [36], picks from a portfolio of the translations presented here (LDBAs,
DBAs, DCAs, DRAs) and the LDBA-to-DPA algorithm of Reference [21] to translate formulas into
4In theory, Emerson-Lei automata can be more succinct [59], but they are not yet used widely in practice.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:5
DPAs. Moreover, we show that the special structure of the LDBAs delivered by the translation
makes them suitable for the verification of probabilistic models.
Summarising, we think this work finally achieves the goals formulated in Reference [45], where
the first translation of this kind—valid only for what is in comparison only a small fragment of
LTL—was presented.
Origin of the Results
The first direct translation from LTL to deterministic Rabin automata, already containing some of
the main ideas of this article, was presented in Reference [45] for a fragment of LTL, and extended
to the whole logic in References [20, 22]. However, in the extended case, we were only able to
prove a triple exponential bound on the size of the automaton. This problem was overcome in
References [23, 69], which also showed how to uniformly translate LTL to other models. The results
of Reference [23] are presented in more detail and extended in the dissertation of the third author
[69]. This article is based on References [23] and [69]. The proofs of the central theorems have been
formally verified, and a verified program for the translation of LTL to DRAs has been extracted
from the proofs [10].
Structure of the Article
The article is organised as follows: Section 2 introduces fundamental terminology and results about
ω-automata and LTL. Section 3 recalls the “after”-function from References [20, 22, 72], and Section 4 shows how to use it to construct DRAs for fragments of LTL. Section 5 presents the central
result—the Master Theorem—that decomposes LTL formulas into simpler fragments. Sections 6 to
8 use the Master Theorem to extend the constructions of Section 4 to full LTL. Section 9 highlights
some applications of the translations of the previous sections, and Section 10 compares experimentally the new translation to DRAs with other approaches.
2 PRELIMINARIES
Given a set A whose elements are sets, we let A denote the union of all the elements of A.
A word w over a finite alphabet Σ is an infinite sequence of letters a0a1a2 ... where ai ∈ Σ for
all i ≥ 0. A language is a set of words. The set of all words is denoted Σω. Given a word w, the ith
letter ofw is denoted byw[i] (starting at 0), the finite infixw[i]w[i + 1] ...w[j − 1] bywij , and the
infinite suffixw[i]w[i + 1] ... bywi . The following identities are useful:wi(i+1) = w[i],w(i+j)i = ϵ
and w0iwi = w for all i, j ≥ 0. Finally, we denote the infinite repetition of a finite word σ1 ... σn by
(σ1 ... σn )
ω = σ1 ... σnσ1 ... σnσ1 ... .
2.1 ω-Automata
For the sake of presentation, we focus on ω-automata with acceptance conditions defined on states
rather than on transitions. It is straightforward to modify our constructions so they yield automata
with transition-based acceptance conditions.
Let Σ be a finite alphabet. A nondeterministic pre-automaton over Σ is a tuple P = (Q, Δ,Q0)
where Q is a finite set of states, Δ : Q × Σ → 2Q is a transition function, and Q0 is a set of initial
states. A transition is a triple (q, a,q

) such that q
 ∈ Δ(q, a). Sometimes, we also view the transition
function as a relation Δ ⊆ Q × Σ × Q. A pre-automaton P is deterministic if Q0 is a singleton and
Δ(q, a) is a singleton for every q ∈ Q and every a ∈ Σ.
A run of P on a word w is an infinite sequence of states r = q0q1q2 ... such that q0 ∈ Q0 and
qi+1 ∈ Δ(qi,w[i]) for all i ≥ 0. We denote the set of states occurring infinitely often in r by Inf(r).
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:6 J. Esparza et al.
An acceptance condition is an expression over the syntax:
α ::= Inf(S) | Fin(S) | α1 ∨ α2 | α1 ∧ α2 with S ⊆ Q.
Acceptance conditions are evaluated on runs and the satisfaction relation r |= α is defined as
follows:
r |= Inf(S) iff Inf(r) ∩ S  ∅,
r |= Fin(S) iff Inf(r) ∩ S = ∅,
r |= α1 ∨ α2 iff r |= α1 or r |= α2,
r |= α1 ∧ α2 iff r |= α1 and r |= α2.
An acceptance condition α is a
• Büchi condition if α = Inf(S) for some set S ⊆ Q of states.
• co-Büchi condition if α = Fin(S) for some set S ⊆ Q of states.
• Rabin condition if α = k
i=1 (Fin(Fi ) ∧ Inf(Ii )) for some k ≥ 1 and some sets F1, I1,..., Fk ,
Ik ⊆ Q of states.
• generalised Rabin condition if α = k
i=1 (Fin(Fi ) ∧ li
j=1 Inf(Iij)) for some k, l1, l2,...,lk ≥ 1
and some sets F1, I1,1, I1,2,..., I1,l1 ,..., Fk , Ik,1,... Ik,lk ⊆ Q of states.
An ω-automaton over Σ is a tuple A = (Q, Δ,Q0, α) where (Q, Δ,Q0) is a pre-automaton over
Σ and α is an acceptance condition. A run r of A is accepting if r |= α. A word w is accepted
by A if some run of A on w is accepting. The language L(A) of an automaton A is defined
as the set L(A) := {w ∈ Σω : w is accepted by A}. An ω-automaton is a Büchi (co-Büchi, Rabin,
generalised Rabin) automaton if its acceptance condition is a Büchi (co-Büchi, Rabin, generalised
Rabin) condition.
Limit-deterministic Büchi Automata. Intuitively, a nondeterministic Büchi automaton (NBA) is
limit-deterministic if it can be split into a nondeterministic component without accepting states,
and a deterministic component. The automaton can only accept by switching from the initial (nondeterministic) to the accepting (deterministic) component, but after the switch it must stay in the
deterministic component forever. Formally, an NBA B = (Q, Δ,Q0, Inf(S)) is a limit-deterministic
Büchi automaton (LDBA) if Q can be partitioned into two disjoint sets Q = QN  QD such that
(1) Δ(q, a) ⊆ QD and |Δ(q, a)| = 1 for every q ∈ QD, a ∈ Σ, and
(2) S ⊆ QD.
Notation forω-Automata Classes. We abbreviate the type of anω-automaton using a simple, wellknown scheme. We denote the branching mode by D (deterministic), LD (limit-deterministic), or
N (nondeterministic) and the acceptance condition by B (Büchi), C (co-Büchi), R (Rabin), or GR
(generalised Rabin).
Visual Representation. In the following sections, we consider automata over alphabets of the form
Σ = 2X for some finite set X. In this case, we simplify the graphical representation of transitions
by the following symbolic notation:
q
∅, {b }, {c }, {b,c }, {a,b,c } −−−−−−−−−−−−−−−−−−→ p is replaced by q a+bc −−−−→ p.
We write a for all sets containing a, and a for all sets not containing a. Furthermore, we write ψ χ
for the intersection and ψ + χ for the union of the sets represented by ψ and χ.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
A Unified Translation of Linear Temporal Logic to ω-Automata 33:7
2.2 Linear Temporal Logic
Most authors introduce linear temporal logic (LTL) [26, 63, 64] with the following reduced syntax:
φ ::= tt | a | ¬φ | φ ∧ φ | Xφ | φ U φ,
where a is an element of a finite set Ap of atomic propositions. Left-out, but often used LTL operators are then added as abbreviations. This reduced syntax has the advantage that only a few cases
have to be considered in proofs by structural induction. However, our result needs an LTL syntax
containing W (weak until) in addition to U (until), and such that formulas are in negation-normalform, i.e., negations only occur in front of atomic propositions. Thus, we introduce ff, ¬a, ∨, and
the temporal operators R (release) and M (strong release) so negations can be pushed inwards:
Definition 1 (LTL).
φ ::= tt | ff | a | ¬a | φ ∧ φ | φ ∨ φ | Xφ | φ U φ | φ M φ | φ R φ | φ W φ with a ∈ Ap.
Let w be a word over the alphabet 2Ap and let φ be a formula. The satisfaction relation w |= φ is
inductively defined as follows:
w |= tt w |= Xφ iff w1 |= φ
w |= ff
w |= a iff a ∈ w[0] w |= φ Uψ iff ∃k.wk |= ψ and ∀j < k.wj |= φ
w |= ¬a iff a  w[0] w |= φ Mψ iff ∃k.wk |= φ and ∀j ≤ k.wj |= ψ
w |= φ ∧ψ iff w |= φ and w |= ψ w |= φ Rψ iff ∀k.wk |= ψ or w |= φ Mψ
w |= φ ∨ψ iff w |= φ or w |= ψ w |= φ Wψ iff ∀k.wk |= φ or w |= φ Uψ .
We denote by L(φ) := {w ∈ (2Ap )
ω : w |= φ} the language of φ. Two formulas φ,ψ are equivalent,
denoted φ ≡ ψ, if their languages are equal. Formally:
φ ≡ ψ := (L(φ) = L(ψ )).
The semantics makes it clear why W is called weak until: It behaves exactly as U, but does not
enforce that ψ is eventually satisfied. Similarly, M is called strong release, because φ needs to be
satisfied eventually. Note that we can express the W and M modalities using R and U modalities
as follows:
φ Wψ ≡ ψ R (φ ∨ψ ) φ M ψ ≡ ψ U (φ ∧ψ ).
It is easy to see that every LTL formula (of the reduced syntax) can be translated to an equivalent
LTL formula in negation normal form without an increase in size.5 Last, we use the two common
abbreviations Fφ := tt U φ (eventually) and Gφ := ff R φ (always) with well-known semantics:
w |= Fφ iff ∃k.wk |= φ w |= Gφ iff ∀k.wk |= φ.
2.2.1 Propositional Semantics. In addition to the language-based semantics of LTL, we assign
propositional semantics to LTL formulas by treating temporal subformulas as propositional variables. A formula ψ is called temporal if it is neither a conjunction nor a disjunction, i.e., if the root
of its syntax tree is labelled by either a temporal operator (U, R, M, W, or X) or a, ¬a. We denote
by sf(φ) the set of temporal subformulas of φ. Formally, we define the propositional semantics as
follows:
5Assuming we consider a and ¬a being of the same size.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:8 J. Esparza et al.
Definition 2 (Propositional Semantics of LTL). Let I be a set of LTL formulas and let φ be an LTL
formula. The propositional satisfaction relation I |=p φ is inductively defined as follows:
I |=p tt I |=p φ ∧ψ iff I |=p φ and I |=p ψ
I |=p ff I |=p φ ∨ψ iff I |=p φ or I |=p ψ
I |=p a iff a ∈I I|=p Xφ iff Xφ ∈ I
I |=p ¬a iff ¬a ∈I I|=p φ op ψ iff φ op ψ ∈ I for op ∈ {U, M, R, W}.
We also call the set I a propositional assignment. Two formulas φ,ψ are propositionally equivalent,
denoted φ ∼ ψ, if I |=p φ ⇐⇒ I |=p ψ holds for all sets I. The (propositional) equivalence class of
a formula φ is denoted [φ]∼ and defined as [φ]∼ := {ψ : φ ∼ ψ }. The (propositional) quotient set of
a set of formulas Ψ is denoted Ψ/∼ and defined as Ψ/∼ := {[ψ]∼ : ψ ∈ Ψ}.
Example 3. Let φ = ψ1 ∨ (ψ2 ∧ψ1) with ψ1 = Xb and ψ2 = G(a ∨ Xb). Let I = {ψ1} and let J =
{ψ2} be two propositional assignments. We then have I |=p φ, but J |=p φ. Further, we have φ ∼
ψ1. Thus, Xb is propositionally equivalent to φ and Xb is an element of the equivalence class [φ]∼.
Observe that |= and |=p interpret tt, ff, ∧, and ∨ in the same way. Note also that there are no
consistency requirements for the set I, in particular, it may contain both a and ¬a. Hence, we
have {a, ¬a} |=p a ∧ ¬a, even though we also have a ∧ ¬a ≡ ff.
We conclude the section with two properties of propositional semantics that will be useful later.
The following lemma is proved by a straightforward structural induction on φ.
Lemma 4. Let φ be a formula and let w be word. Then:
w |= φ ⇐⇒ {ψ ∈ sf(φ) : w |= ψ } |=p φ.
Example 5. Let φ = a ∨ Fb andw = (∅{b})
ω. In this case, we havew |= φ,w |= Fb, and {Fb} |=p φ.
The second property states that propositional equivalence is a congruence for any function from
formulas to formulas that maps tt and ff to themselves, and preserves disjunctions and conjunctions. The proof can be found in Appendix A.
Lemma 6. Let f be a function on formulas such that f (tt) = tt, f (ff) = ff, and f (χ1 ∧ χ2) =
f (χ1) ∧ f (χ2), f (χ1 ∨ χ2) = f (χ1) ∨ f (χ2) for all formulas χ1 and χ2. For every pair of formulas
φ and ψ, if φ ∼ ψ, then f (φ) ∼ f (ψ ).
In particular, Lemma 6 shows that propositional equivalence (according to our Definition 2) is
preserved by substitution of a temporal subformula by another arbitrary formula.
2.2.2 Four LTL-Fragments: μLT L, νLT L, GF(μLT L), and FG(νLT L). The following four fragments of LTL play a central role in this article. They are the “simple” fragments of LTL mentioned
in the introduction.
• The fragment μLT L and the fragment νLT L.
μLT L is the fragment of LTL restricted to temporal operators U and M, on top of Boolean
connectives (∧, ∨), literals (a, ¬a), and the next operator (X). νLT L is defined analogously,
but with the operators R and W. In the literature μLT L is also called syntactic co-safety and
νLT L syntactic safety.
• The fragments GF(μLT L) and FG(νLT L).
These fragments contain the formulas of the form GFφ, where φ ∈ μLT L, and FGφ, where
φ ∈ νLT L, respectively.
The claim that these languages are “simple” is substantiated in Section 4, which gives a straightforward translation to (deterministic) automata. The reason for the names μLT L and νLT L is that
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:9
U and M are least-fixed-point operators, in the sense that their semantics is naturally formulated
by least fixed-points, e.g., in the μ-calculus, while the semantics of R and W is naturally formulated by greatest fixed-points. So μLT L and νLT L are the formulas of LTL without any alternation
of least and greatest fixed-points, while GF(μLT L) and FG(νLT L) are fragments containing one
single alternation.
3 THE “AFTER”-FUNCTION
The function aft(φ,w), read “φ afterw,” is the foundation for the translations to automata presented
here [20, 22, 23]. The function assigns to a formula φ and a finite word w a formula aft(φ,w) such
that, intuitively, φ holds for a word ww
 if and only if aft(φ,w) holds “after reading w,” that is, if
and only if w
 |= aft(φ,w). The definition of aft(φ,w) follows easily from the expansion laws for
LTL.
Definition 7. Let φ be a formula and σ ∈ 2Ap a single letter. The formula aft(φ, σ ) is inductively
defined as follows:
aft(tt, σ ) = tt aft(Xφ, σ ) = φ
aft(ff, σ ) = ff
aft(a, σ ) = if a ∈ σ then tt else ff aft(φ Uψ, σ ) = aft(ψ, σ ) ∨ (aft(φ, σ ) ∧ φ Uψ )
aft(¬a, σ ) = if a  σ then tt else ff aft(φ Mψ, σ ) = aft(ψ, σ ) ∧ (aft(φ, σ ) ∨ φ Mψ )
aft(φ ∧ψ, σ ) = aft(φ, σ ) ∧ aft(ψ, σ ) aft(φ Rψ, σ ) = aft(ψ, σ ) ∧ (aft(φ, σ ) ∨ φ Rψ )
aft(φ ∨ψ, σ ) = aft(φ, σ ) ∨ aft(ψ, σ ) aft(φ Wψ, σ ) = aft(ψ, σ ) ∨ (aft(φ, σ ) ∧ φ Wψ ).
Furthermore, we generalise aft to finite words by defining
aft(φ, ϵ ) := φ and aft(φ, σw) := aft(aft(φ, σ ),w)
for every σ ∈ 2Ap and every finite word w. Finally, we define the set of formulas reachable from φ
as Reach(φ) := {aft(φ,w) : w ∈ (2Ap )
∗}.
Definitions for F and G. In several examples, we use formulas containing F and G. To keep the
examples readable, we introduce the following shortened definitions:
aft(Fφ, σ ) := aft(φ, σ ) ∨ Fφ aft(Gφ, σ ) := aft(φ, σ ) ∧ Gφ.
Example 8. Let φ = a ∨ (b U c) be a formula. We then have aft(φ, {a}) = tt ∨ (ff ∨ (ff ∧ b U c)) ∼
tt, aft(φ, {b}) = ff ∨ (ff ∨ (tt ∧ b U c)) ∼ b U c, and aft(φ, ∅) = ff ∨ (ff ∨ (ff ∧ b U c) ∼ ff.
Lemma 9. Let φ be a formula, let w ∈ (2Ap )
∗ be a finite word, and let w
 ∈ (2Ap )
ω be an infinite
word. Then:
ww
 |= φ ⇐⇒ w
 |= aft(φ,w).
Proof. We prove by induction on φ that the property holds for a single letter σ ∈ 2Ap . The result
for an arbitrary finite wordw is then shown by induction on the length ofw. The single-letter case
requires to prove:
σw
 |= φ ⇐⇒ w
 |= aft(φ, σ ).
We only show two representative cases of the induction.
• Case φ = a:
σw
 |= a ⇐⇒ a ∈ σ ⇐⇒ aft(a, σ ) = tt ⇐⇒ w
 |= aft(a, σ )
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:10 J. Esparza et al.
• Case φ = ψ1 Uψ2:
σw
 |= φ
⇐⇒ σw
 |= ψ2 ∨ (ψ1 ∧ Xφ) (LTL expansion)
⇐⇒ w
 |= aft(ψ2, σ ) ∨ (aft(ψ1, σ ) ∧ φ) (induction hypothesis)
⇐⇒ w
 |= aft(φ, σ )
Lemma 9 was introduced already in References [22, 45] and describes the main purpose of the after function. It can be read as w−1L(φ) = L(aft(φ,w)), where w−1L := {w
 : ww
 ∈ L} denotes the
derivative underw of the language L. Thus, aft computes the derivative of a language, represented
by a formula.
It is easy to give formulas φ for which the set Reach(φ) contains infinitely many syntactically
different formulas, e.g., φ = a Ub. The following lemma shows that Reach(φ) only contains finitely
many formulas up to propositional equivalence.
Lemma 10. Let φ and ψ be formulas and let w be a finite word. Then:
(1) sf(aft(φ,w)) ⊆ sf(φ)
(2) If φ has n temporal subformulas, then Reach(φ)/∼ has at most cardinality M(n) ≤ 22n
, where
M(n) denotes the number of monotonic Boolean functions of n variables (Dedekind number).
Proof. (1) Intuitively, this holds, because aft does not create new elements in the syntax tree,
except Boolean combinations of existing temporal subformulas. The formal proof proceeds by a
straightforward nested induction on φ and on the length of w.
(2) Let φ be a formula with n temporal subformulas. By (1), every formula of Reach(φ) is a positive Boolean combination of temporal subformulas of φ. So each equivalence class of Reach(φ)/∼
can be interpreted as a monotonic Boolean function over n variables. There are at most M(n) such
functions and so |Reach(φ)/∼| ≤ M(n). Furthermore, M(n) can be bounded by 22n
, since there exist
at most that many Boolean functions over n variables.
By Lemma 10.2, the set Reach(φ)/∼ is finite. We show how to compute it. For every k ≥ 0 define
Reach(φ)
k
/∼ = { [aft(φ,w)]∼ : w ∈ (2Ap )
∗ ∧ |w| ≤ k}.
By definition, we have Reach(φ)/∼ =
k ≥0 Reach(φ)
k
/∼, and Reach(φ)
k
/∼ ⊆ Reach(φ)
k+1
/∼ for every k ≥ 0. So there is an index α ≤ M(n) such that Reach(φ)
α
/∼ = Reach(φ)
α+1 /∼ . We prove that
Reach(φ)/∼ = Reach(φ)
α
/∼. It suffices to show Reach(φ)
α
/∼ = Reach(φ)
α+j
/∼ for every j ≥ 1. We proceed by induction. The case j = 1 is true by hypothesis. For j > 1, we apply the following lemma,
which follows immediately from Lemma 6 by taking f (φ) = aft(φ, σ ):
Lemma 11. For all formulas φ,ψ and every letter σ, if φ ∼ ψ, then aft(φ, σ ) ∼ aft(ψ, σ ).
The lemma allows us to lift the after function to equivalence classes of formulas by defining
aft∼([φ]∼, σ ) := [aft(φ, σ )]∼ for every formula φ. We then have:
Reach(φ)
α+j
/∼ = {aft∼([ψ]∼, σ ) : [ψ]∼ ∈ Reach(φ)
α+j−1
/∼ ∧ σ ∈ 2Ap } (Lemma 11)
= {aft∼([ψ]∼, σ ) : [ψ]∼ ∈ Reach(φ)
α
/∼ ∧ σ ∈ 2Ap } (induction hypothesis)
= Reach(φ)
α+1
/∼ (Lemma 11)
= Reach(φ)
α
/∼.
Related Work. The definition of the after function is almost identical to the transition relation of
very-weak alternating automata constructed from LTL formulas [60, 79]. Thus, the function can
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.   
A Unified Translation of Linear Temporal Logic to ω-Automata 33:11
be interpreted as a mechanism to track a run on such an automaton. This close relationship stems
from the fact that both approaches use “LTL expansion laws” [7] to construct the final result.
As mentioned in the introduction, regular-expression derivatives are an elegant technique for
translating regular expressions to deterministic [11] as well as nondeterministic [3] finite automata. The after function follows in these footsteps for LTL.
4 DBAS AND DCAS FOR μLT L, νLT L, GF(μLT L), AND FG(νLT L)
We show that the after function can be used to characterise the languages of formulas of simple
LTL fragments. We use this result to define simple translations of these fragments to DBAs or
DCAs.
Lemma 12 ([22, 23]). Let φ be a formula and let w be a word.
(1) If φ ∈ μLT L, then w |= φ ⇐⇒ ∃i. aft(φ,w0i ) ∼ tt.
(2) If φ ∈ νLT L, then w |= φ ⇐⇒ ∀i. aft(φ,w0i )  ff.
Proof. We only present the proof for (1) and skip the proof for (2), which is analogous. Let w
be a word and let φ be a formula with φ ∈ μLT L.
(⇒1) Assume w |= φ. We proceed by structural induction on φ to prove the existence of an
i such that aft(φ,w0i ) ∼ tt. We only consider two of the possible cases: tt, ff, a, ¬a,ψ1 ∧ψ2,ψ1 ∨
ψ2, Xψ,ψ1 Uψ2,ψ1 Mψ2. The others are similar.
• Case φ = a: Since w |= φ, we have a ∈ w[0] = w01 and we get aft(φ,w01) = tt ∼ tt.
• Case φ = ψ1 Uψ2: By the semantics of LTL there is a k such that wk |= ψ2 and w |= ψ1 for
every 0 ≤  < k. By induction hypothesis there exists for every 0 ≤  < k an i ≥  such that
aft(ψ1,wi ) ∼ tt and there exists an i ≥ k such that aft(ψ2,wk i ) ∼ tt. Let j be the maximum
of all those i’s. We prove aft(ψ1 Uψ2,w0j) ∼ tt via induction on k.
—k = 0.
aft(ψ1 Uψ2,w0j)
= aft(ψ2,w0j) ∨ (aft(ψ1,w0j) ∧ aft(ψ1 Uψ2,w1j)) (Definition 7)
∼ tt ∨ (aft(ψ1,w0j) ∧ aft(ψ1 Uψ2,w1j)) (k = 0 → aft(ψ2,w0j) ∼ tt)
∼ tt
—k > 0.
aft(ψ1 Uψ2,w0j)
= aft(ψ2,w0j) ∨ (aft(ψ1,w0j) ∧ aft(ψ1 Uψ2,w1j)) (Definition 7)
∼ aft(ψ2,w0j) ∨ (tt ∧ aft(ψ1 Uψ2,w1j)) (k > 0 → aft(ψ1,w0j) ∼ tt)
∼ aft(ψ2,w0j) ∨ (tt ∧ tt) (induction hypothesis)
∼ tt
(⇐1) Assume w |= φ. By Lemma 9, we have wi |= aft(φ,w0i ) for all i, and thus aft(φ,w0i )  tt
for all i. Since x ∼ y implies x ≡ y, we also have aft(φ,w0i )  tt, and we are done.
Proposition 13. Let φ ∈ μLT L.
• The following DBA over the alphabet 2Ap recognises L(φ):
Bφ
μ = (Reach(φ)/∼, aft∼,[φ]∼, Inf({[tt]∼})).
• The following DCA over the alphabet 2Ap recognises L(φ):
Cφ
μ = (Reach(φ)/∼, aft∼,[φ]∼, Fin({[tt]∼})).
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.        
33:12 J. Esparza et al.
Fig. 2. DBA Bφ
GFμ
for φ = a ∧ X(b ∨ Fc) with the symbolic notation for transitions introduced in Section 2.1.
• The following DBA over the alphabet 2Ap recognises L(GFφ):
Bφ
GFμ = (Reach(Fφ)/∼, aftFφ
∼ ,[Fφ]∼, Inf({[tt]∼}))
aftFφ
∼ ([ψ]∼, σ ) =

[Fφ]∼ if ψ ∼ tt
[aft(ψ, σ )]∼ otherwise.
Let φ ∈ νLT L.
• The following DCA over the alphabet 2Ap recognises L(φ):
Cφ
ν = (Reach(φ)/∼, aft∼,[φ]∼, Fin({[ff]∼})).
• The following DBA over the alphabet 2Ap recognises L(φ):
Bφ
ν = (Reach(φ)/∼, aft∼,[φ]∼, Inf({[ff]∼})).
• The following DCA over the alphabet 2Ap recognises L(FGφ):
Cφ
FGν = (Reach(Gφ)/∼, aftGφ
∼ ,[Gφ]∼, Fin({[ff]∼)})
aftGφ
∼ ([ψ]∼, σ ) =

[Gφ]∼ if ψ ∼ ff
[aft(ψ, σ )]∼ otherwise.
Observe that Bφ
μ and Cφ
μ , as well as Bφ
ν and Cφ
ν , share the same structure and only differ in the
definition of the acceptance condition. Cφ
μ can be understood as first applying the classic complementation procedure for deterministic finite automata (which simply swaps final and non-final
states) to Bφ
μ , which yields a Büchi automaton recognising ¬φ, and then flipping the acceptance
condition to finally arrive at the co-Büchi condition recognising ¬¬φ ≡ φ. This works because the
automaton Bφ
μ is weak, meaning that the states of every strongly connected component (SCC) are
either all accepting or all rejecting. The same observation also holds for Bφ
ν and Cφ
ν . The proof of
the proposition is straightforward and relies mostly on Lemma 12. It can be found in Appendix A.
Example 14. Let φ = a ∧ X(b ∨ Fc) ∈ μLT L. The DBA Bφ
GFμ constructed from Proposition 13
recognising L(GFφ) is depicted in Figure 2. Notice that from now on, we label the states, which
are in-fact equivalence classes of ∼, by a representative of the respective class.
5 THE MASTER THEOREM
We present the Master Theorem, a characterisation of the words satisfying a given (general LTL)
formula, from which we can easily extract deterministic, limit-deterministic, and nondeterministic
automata of asymptotically optimal size. We start with a motivational example, the simplest one
outside of the fragments discussed above; it is also the simplest one not covered by the approaches
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:13
of References [45, 46]. We follow with an overview of the results, indicating in boldface several
technical parts postponed until the subsequent subsections.
5.1 An Appetising Example
Consider the formula φ = G(a ∨ b U c), which does not belong to any of the fragments of Section 4.
6 Split the set of all words over the alphabet 2{a,b,c } into words that satisfy GF(b U c), and
words that do not. First, let w be a word satisfying GF(b U c). Since w satisfies c infinitely often,
we have w |= G(a ∨ b U c) iff w |= G(a ∨ b W c). In other words, under the hypothesis GF(b U c),
checking φ reduces to checking G(a ∨ b W c). Since the hypothesis belongs to the GF(μLT L) fragment, and G(a ∨ b W c) is a formula of νLT L, we can construct automata for both. Second, letw be
a word that does not satisfy GF(b U c), in particular, there are only finitely many suffixes ofw that
do satisfy b U c. What must w do to satisfy φ? Besides satisfying φ on a prefix of w, some suffix
of w must satisfy G(a ∨ ff), for which we can also construct an automaton. The Master Theorem
generalises this idea to arbitrary formulas. It decomposes the language of any LTL formula φ into
a Boolean combination
L(φ) =
n
i=1
Ui ∩Vi, (1)
where theUi correspond to the different hypotheses, and theVi to their corresponding satisfaction
conditions. Crucially, these languages are “plain”, meaning that they correspond to formulas of the
fragments GF(μLT L) and FG(νLT L), introduced in Section 2.2.2, and to a simple variation of νLT L.
As a result, the formula can be translated into an automaton as a union of intersections of simple
automata for formulas of these fragments.
5.2 Overview
First, we focus on “infinitary” formulas only, whose satisfaction does not depend on any finite
prefix. Consider, e.g., φ = G(Fa ∨ Fb). (While one can see that it could be re-written into the special fragment form as GF(a ∨ b), its original form illustrates the general point here.) Similarly to
the previous example, to determine whether w |= φ holds it is useful to know which of the disjuncts holds infinitely often. While we may not know whether GFa or GFb holds, or none, or
both, restricting L(φ) to any of these four possible cases makes deciding satisfaction easy. For
instance, checking w |= φ already knowing that w |= GFb holds is trivial. This suggests to decompose L(φ) into a union of languages, one for each possible case, where a case is determined by
which subformulas hold infinitely often and which almost always. In each case, we can then use
this “limit-behaviour” information.
5.2.1 Limit-behaviour Partition. Let μ(φ) and ν (φ) be the sets containing the subformulas of a
fixed φ of the form ψ1 op ψ2 for least-fixed-point operators op ∈ {U, M} and greatest-fixed-point
operators op ∈ {W, R}, respectively. Given a word w, let GFw denote the set of formulas of μ(φ)
that hold infinitely often along w (meaning that infinitely many of its suffixes satisfy the formulas), and define F Gw ⊆ ν (φ) analogously, substituting “almost always” for “infinitely often.” We
say that two words w,v are limit-equivalent if GFw = GFv and F Gw = F Gv . This equivalence
relation induces a partition P = {PM,N : M ⊆ μ(φ), N ⊆ ν (φ)}, where PM,N consists of the words
w such that M = GFw and N = F Gw .
Example 15. The partition for φ = G(Fa ∨ Fb) is illustrated in Figure 3 (left) with vacuous cases
denoted by crosses. Observe that the grey classes completely belong to the language and the white
6Moreover, it is a prototypical example of a formula outside of the LTL\GU fragment [46], for which a simpler translation
to DRAs exists [46] and for which singly exponential LDBA can be constructed [38].
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:14 J. Esparza et al.
Fig. 3. Partition of Σω according to the limit-behaviour with respect to φ = G(Fa ∨ Fb) (left) and φ = Ga ∨
b U c (right), with examples of words in the respective classes (crossed out if empty). The grey area denotes
the language of the formula.
ones completely avoid it. This is generally true for infinitary properties. In contrast, for the noninfinitary property a ∧ G(Fa ∨ Fb), the membership depends on the first letter. Consequently, for
general formulas, we obtain also “mixed” classes as illustrated in Figure 3 (right) forφ = Ga ∨ b U c.
Following this idea, the decomposition takes the form of
L(φ) =

M ⊆μ (φ)
N ⊆ν (φ)
PM,N ∩VM,N , (2)
where VM,N captures “L(φ) given the case M, N”.
5.2.2 Stable Words. We first show how to decompose the language of stable words of L(φ).
A word w is stable with respect to φ if every formula in μ(φ) holds either never or infinitely often
along w (i.e., either none or infinitely many of its suffixes satisfy the formula), and every formula
of ν (φ) fails never or infinitely often along w. In particular, no formula of μ(φ) can hold a finite,
nonzero number of times before it fails forever, and no formula of ν (φ) can fail a finite, nonzero
number of times before it holds forever. It is easy to see that, while not every word is stable, every
word eventually stabilises, meaning that almost all its suffixes are stable. The formal definition
of stable words is presented in Section 5.3.
Example 16. Consider again the previous example. The word w = {a}{b}∅{a,c}(∅{a})
ω is not
stable with respect to G(Fa ∨ Fb). However,wi is stable for any i ≥ 2, hencew stabilises at position
2. The word w is not stable with respect to Ga ∨ b U c either, but w4 is.
Given a language L, let Ls denote the set of stable words of L. Our subgoal is to decompose
L(φ)
s . Trivially:
L(φ)
s =

M ⊆μ (φ)
N ⊆ν (φ)
PM,N ∩ L(φ)
s . (3)
To follow Equation (2), we want to design plain formulas φ[M]ν and φ[N]μ , from the fragments
νLT L and μLT L, respectively, which utilise the “advice” to φ that the word is in the class of M, N:
L(φ)
s =

M ⊆μ (φ)
N ⊆ν (φ)
PM,N ∩ L(φ[M]ν )
s =

M ⊆μ (φ)
N ⊆ν (φ)
PM,N ∩ L(φ[N]μ )
s . (4)
Notice that we always utilise only one of M, N, since the point is to get rid of one of the fixed-point
types, relying on the advice, and check the other one.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.    
A Unified Translation of Linear Temporal Logic to ω-Automata 33:15
5.2.3 Utilising Advice on Stable Words. The desired formulas φ[M]ν ∈ νLT L and φ[N]μ ∈
μLT L are defined in Section 5.4 fromφ, M, and N by means of a simple syntactic transformation.
Intuitively, the known advice is substituted into the formula.
Example 17. For φ = F(Ga ∨ Gb) and advice N = {Ga}, thus not containing Gb, we shall obtain
φ[N]μ = F(tt ∨ ff). The substitution is more complex for operators such as U. For φ = G(a ∨ b U c)
and advice M = {b U c} saying b U c holds infinitely often, it would be obviously wrong to simply plug in tt yielding G(a ∨ tt), since we have to check where b U c holds. Nevertheless, we can
consider G(a ∨ b W c) instead, where we are freed from checking the least fixed point from U and
only check the local correctness of applying the expansion laws for until.
Even more surprisingly, for φ = F(a ∨ b W c), an advice that misses b W c makes us check F(a ∨
b U c), which is (logically) stronger than φ! However, it is plain (in μLT L) and logically equivalent
provided b W c holds finitely often only.
Due to Equation (3), for Equation (4) to hold it suffices to show:
PM,N ∩ L(φ)
s = PM,N ∩ L(φ[M]ν )
s = PM,N ∩ L(φ[N]μ )
s . (5)
Section 5.5 proves (5). Now only two issues remain:
(i) PM,N might not be plain.
(ii) The decomposition has to be lifted back to all words, not just the stable ones.
5.2.4 Checking Advice by a Plain Language. The issue (i) concerning PM,N is overcome by means
of two further results. By the definition of the partition, we have:
PM,N = L



ψ ∈M
GFψ ∧

ψ ∈N
FGψ ∧

ψ ∈μ (φ)\M
¬GFψ ∧

ψ ∈ν (φ)\N
¬FGψ


.
While this language might not be plain, the previous syntactic substitution provides an alternative
that is plain:
UM,N := L



ψ ∈M
GF(ψ[N]μ ) ∧

ψ ∈N
FG(ψ[M]ν )



. (6)
There are two differences between the expressions. First, in the latter expression we do not
check that the negations of the formulas not included in the advice indeed do not hold. Actually,
we can safely do this, since assuming negations of subformulas does not make (propositional)
implication of φ any easier due to its negation normal form. Hence, this additional assumption
does not increase the satisfiability of φ. However, not assuming them does not decrease it either,
since the cases where the omitted formulas actually do hold are treated by other M, N-classes.
Second and even more importantly, since GF(ψ[N]μ ) ∈ GF(μLT L) and FG(ψ[M]ν ) ∈ FG(νLT L),
the language UM,N is plain. This comes at the cost of a further over-approximation of PM,N
PM,N ⊆ UM,N , (7)
proven in Section 5.6 together with tightness of the over-approximation:
UM,N ∩ L(φ[M]ν )
s ⊆ L(φ)
s . (8)
Intuitively, Equation (7) captures the soundness of using the advice in the simplification of the
subformulas to plain ones, and Equation (8) claims that, given an advice that is indeed valid on the
word, it is sound to use it when proving the global formula.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.    
33:16 J. Esparza et al.
Table 1. An Example of a Word w and the Induced Formulas
for φ = F(a ∧ Gb) with M = ∅ after Reading Its Prefixes
i 1234 5 6
w[i − 1] ∅ {a,b}∅{a,b} {b} {b} ···
aft(φ,w0i ) φ φ ∨ Gbφφ ∨ Gb φ ∨ Gb φ ∨ Gb ···
aft(φ,w0i )[M]ν ff Gb ff Gb Gb Gb ···
wi |= aft(φ,w0i )[M]ν ×××  ···
Fig. 4. DCA for VM,N for φ = F(a ∧ Gb) and M = ∅.
Combining Equation (4) with Equations (7) and (8), we obtain the Master Theorem for stable
words:
L(φ)
s =

M ⊆μ (φ)
N ⊆ν (φ)
UM,N ∩ L(φ[M]ν )
s . (9)
5.2.5 Utilizing Advice on Unstable Words. The issue (ii) requires us to obtain an identity like
Equation (9), but for L(φ) instead of L(φ)
s . Let us first see why simply replacing Ls with L does
not work:
Example 18. Consider the formula Fa (It belongs to the plain fragments, but it illustrates the
point.) and the word w = ∅{a}∅ω. We have w ∈ P∅,∅ ⊆ U∅,∅. To show w ∈ L(φ), we would need to
show w ∈ L(φ[∅]ν ) = L(ff), which is obviously not true. The issue is that we only need a to hold
once, not infinitely often.
Lifting the result to non-stable words requires monitoring the evolution of the formula to be
satisfied, as done in the usual tableaux constructions. To satisfy φ, an arbitrary word w must have
a suffix wi that satisfies a certain “derivative” φ corresponding to the moment i: This formula is
neither φ[M]ν (as refuted in the preceding example), nor just the correspondingly evolved formula
aft(φ,w0i ) (since this is hard to check using our plain advice), but rather aft(φ,w0i )[M]ν . Formally,
we define:
VM,N := {w : ∃i ≥ 0.wi |= aft(φ,w0i )[M]ν }. (10)
Using this definition, we prove in Section 5.7 the decomposability, as seen in Equation (2).
Example 19. The evolution of the monitored formula and the corresponding substitution are
illustrated for φ = F(a ∧ Gb) and w = (∅{a,b})
2{b}
ω with M = ∅ in Table 1.
The language VM,N is not in any of the fragments of Section 2.2.2 but, since aft(φ,w0i )[M]ν ∈
νLT L, it is easy to construct an automaton for it, thus reaching our goal. Observe that, actually,
VM,N is independent of N. A symmetric version of the Master Theorem with aft(φ,w0i )[N]μ is also
possible, but the automata construction is not so simple in that case. We comment on this further
in Section 5.7.
Example 20. Figure 4 depicts the automaton for VM,N with φ = F(a ∧ Gb) of the previous
example.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.    
A Unified Translation of Linear Temporal Logic to ω-Automata 33:17
The rest of the section proves the above boldfaced statements, completing the argumentation.
Section 5.7 then formally re-states and proves the Master Theorem.
5.3 Stability
Fix a formula φ. The set of subformulas of φ with the shapeψ1 Uψ2 andψ1 Mψ2 is denoted by μ(φ).
So, loosely speaking, μ(φ) contains the set of subformulas of φ with a least-fixed-point operator
at the top of their syntax tree. Given a word w, we are interested in which of these formulas hold
infinitely often, and which ones hold at least once.
Definition 21 (μ-stability). Let φ be a formula, and let μ(φ) be the set of subformulas of φ with
the shapeψ1 Uψ2 or with the shapeψ1 Mψ2. For every word w, the sets GF φ
w and F φ
w are defined
as follows:
GF φ
w = {ψ : ψ ∈ μ(φ) ∧ w |= GFψ }
F φ
w = {ψ : ψ ∈ μ(φ) ∧ w |= Fψ }.
We say that w is μ-stable with respect to φ if GF φ
w = F φ
w .
Example 22. For φ = Ga ∨ b U c, we have μ(φ) = {b U c}. Letw = {a}
ω andw
 = {b}{c}{a}
ω. We
have F φ
w = ∅ = GF φ
w and GF φ
w
 = ∅⊂{b U c} = F φ
w
 . So w is μ-stable with respect to φ, but w
 is
not.
Dually, the set of subformulas of φ with the shape ψ1 Rψ2 and ψ1 Wψ2, i.e., with greatest fixedpoint operators on the top, is denoted by ν (φ). This time, we are interested in whether these
formulas hold everywhere or almost everywhere.
Definition 23 (ν-stability). Let φ be a formula, let w be a word, and let ν (φ) be the set of subformulas of φ with the shape ψ1 Rψ2 or with the shape ψ1 Wψ2. Then the sets F G φ
w and Gφ
w are
defined as follows:
F G φ
w = {ψ : ψ ∈ ν (φ) ∧ w |= FGψ }
Gφ
w = {ψ : ψ ∈ ν (φ) ∧ w |= Gψ }.
We say that w is ν-stable with respect to φ if F G φ
w = Gφ
w .
Example 24. Let φ, w, and w
 as in Example 22. We have ν (φ) = {Ga}. The word w is ν-stable,
but w
 is not, because F G φ
w
 = {Ga}⊃∅ = Gφ
w
.
A word is stable with respect to φ if it is both μ-stable and ν-stable. The inclusions GF φ
w ⊆ F φ
w
and F G φ
w ⊇ Gφ
w hold for every formula φ and every word w. We prove that all but finitely many
suffixes of a word are stable. If the suffix wi is stable with respect to φ, then we call i a stabilisation
point for w with respect to φ.
Lemma 25. Let φ be a formula and letw be a word. Then there exists an index  such that for every
k ≥ 0 the suffix w+k is stable with respect to φ.
Proof. It suffices to find indices i, j ≥ 0 such that for every k ≥ 0 the suffix wi+k is μ-stable
and the suffix wj+k is ν-stable with respect to φ. We only prove the μ-stability part; the proof of
the other part is similar. Let φ be a formula and let w be a word. In the rest of the proof, we omit
the superscript φ from GFφ
w , F Gφ
w , and so on. Since GFwi ⊆ Fwi for every i ≥ 0, it suffices to
exhibit an index i such that GFwi+k ⊇ Fwi+k for every k ≥ 0. If GFw ⊇ Fw , then we can choose
i := 0. So assume Fw \ GFw  ∅. By definition, everyψ ∈ Fw \ GFw holds only finitely often along
w. So for every ψ ∈ Fw \ GFw there exists an index iψ such that wiψ +k |= ψ for every k ≥ 0. Let
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.   
33:18 J. Esparza et al.
i := max{iψ : ψ ∈ Fw }, which exists because Fw is a finite set. It follows GFwi+k ⊇ Fwi+k for every
k ≥ 0, and so every wi+k is μ-stable.
Example 26. Let again φ = Ga ∨ b U c. The wordw
 = {b}{c}{a}
ω is neither μ-stable nor ν-stable
with respect to φ, but all suffixes w

(2+k) of w
 are both μ-stable and ν-stable with respect to φ.
5.4 The Formulas φ[M]ν and φ[N]μ
In the overview section, we have introduced the language PM,N , consisting of the words w such
that M = GF φ
w and N = F Gφ
w . In this section, we define simpler formulas φ[M]ν ∈ νLT L and
φ[N]μ ∈ μLT L, and in Section 5.5 below, we show that they satisfy identity (5) of the overview.7
Let us first define the formula φ[M]ν . According to identity (5), it has to fulfil
PM,N ∩ L(φ)
s = PM,N ∩ L(φ[M]ν )
s ,
i.e., the stable words of PM,N must satisfy φ iff they satisfy φ[M]ν . Since GF φ
w = M = F φ
w holds
for every stable wordw ∈ PM,N , we can set our goal as follows: Define a formula φ[M]ν such that:

GF φ
w = M = F φ
w
	
⇒ (w |= φ ⇐⇒ w |= φ[M]ν ). (11)
The definition of φ[M]ν is purely syntactic, and the intuition behind it is very simple. All the
main ideas are illustrated by the following examples, where we assume that w is a word for which
GF φ
w = M = F φ
w holds:
• φ = Fa ∧ Gb and M = {Fa}. Since M = GF φ
w , we have Fa ∈ GF φ
w , which implies in particular w |= Fa. So w |= Fa ∧ Gb iff w |= Gb, and so we can set φ[M]ν := tt ∧ Gb, i.e., we can
obtain φ[M]ν by substituting tt for Fa in φ.
• φ = Fa ∧ Gb and M = ∅. Since M = F φ
w , we have Fa  F φ
w , and so w |= Fa. In other words,
w |= Fa ∧ Gb iff w |= ff, and so we can set φ[M]ν := ff ∧ Gb.
• φ = G(b U c) and M = {b U c}. Since M = GF φ
w , we have b U c ∈ GF φ
w , and so w |= GF(b U
c). This does not imply wi |= b U c for all suffixes wi of w, but it implies that c will hold
infinitely often in the future. Sow |= G(b U c) iffw |= G(b W c), which is a formula of νLT L,
and so we define φ[M]ν := G(b W c).
The formal definition of φ[M]ν is as follows:
Definition 27. Let φ be a formula and let M ⊆ μ(φ) be a set of formulas. The formula φ[M]ν is
inductively defined as follows for the interesting cases U and M:
(φ Uψ )[M]ν =

(φ[M]ν ) W (ψ[M]ν ) if φ Uψ ∈ M
ff otherwise.
(φ Mψ )[M]ν =

(φ[M]ν ) R (ψ[M]ν ) if φ Mψ ∈ M
ff otherwise.
In all other cases it is defined as a recursive descent:
• If φ ∈ {tt, ff}∪{a, ¬a : a ∈ Ap}, then φ[M]ν = φ.
• If φ = ψ1 op ψ2 with op ∈ {∧, ∨, R, W}, then φ[M]ν = (ψ1[M]ν ) op (ψ2[M]ν ).
• If φ = Xψ, then φ[M]ν = X(ψ[M]ν ).
7Observe that M ⊆ μ (φ) but φ[M]ν is a formula of ν LT L. So the ν -subscript in the notation φ[M]ν indicates the fragment
of LTL the formula belongs to, and not the fragment containing the formulas of M.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
A Unified Translation of Linear Temporal Logic to ω-Automata 33:19
Let us now define the dual formula φ[N]μ ∈ μLT L.
Definition 28. Let φ be a formula and let N ⊆ ν (φ) be a set of formulas. The formula φ[N]μ is
inductively defined as follows for the interesting cases R and W:
(φ Rψ )[N]μ =

tt if φ Rψ ∈ N
(φ[N]μ ) M (ψ[N]μ ) otherwise.
(φ Wψ )[N]μ =

tt if φ Wψ ∈ N
(φ[N]μ ) U (ψ[N]μ ) otherwise.
In all other cases it is defined as a recursive descent:
• If φ ∈ {tt, ff}∪{a, ¬a : a ∈ Ap}, then φ[M]μ = φ.
• If φ = ψ1 op ψ2 with op ∈ {∧, ∨,U, M}, then φ[M]μ = (ψ1[M]μ ) op (ψ2[M]μ ).
• If φ = Xψ, then φ[M]μ = X(ψ[M]μ ).
Definitions for F and G. Observe that Gφ = φ W ff and that φ U ff ≡ ff. Dually, we have Fφ = tt U
φ and tt W φ ≡ tt. Since F and G frequently appear in examples, we make use of this observation
and overload in the scope of examples the definitions of φ[M]ν and φ[N]μ for the sake of simplicity:
(Fφ)[M]ν :=

tt if Fφ ∈ M
ff otherwise. (Gφ)[N]μ :=

tt if Gφ ∈ N
ff otherwise.
Example 29. Let φ = ((a W b) ∧ Fc) ∨ a U d. We have:
φ[{Fc}]ν = ((a W b) ∧ tt) ∨ ff ∼ a W b
φ[{a U d}]ν = ((a W b) ∧ ff) ∨ a W d ∼ a W d
φ[∅]ν = ((a W b) ∧ ff) ∨ ff ∼ ff
φ[{a W b}]μ = (tt ∧ Fc) ∨ a U d ∼ Fc ∨ a U d
φ[∅]μ = (a U b ∧ Fc) ∨ a U d.
5.5 Properties of φ[M]ν and φ[N]μ
The following lemma states the fundamental properties ofφ[M]ν andφ[N]μ . In particular, it proves
identity (5) of the overview section.
Lemma 30. Let φ be a formula and let w be a word. Let M ⊆ μ(φ) be a set of formulas. We have:
(1) If F φ
w ⊆ M and w |= φ, then w |= φ[M]ν .
(2) If M ⊆ GF φ
w and w |= φ[M]ν , then w |= φ.
In particular:
(3) If F φ
w = M = GF φ
w , then w |= φ ⇐⇒ w |= φ[M]ν .
Let N ⊆ ν (φ) be a set of formulas. We have:
(4) If F G φ
w ⊆ N and w |= φ, then w |= φ[N]μ .
(5) If N ⊆ Gφ
w and w |= φ[N]μ , then w |= φ.
In particular:
(6) If F G φ
w = N = Gφ
w , then w |= φ ⇐⇒ w |= φ[N]μ .
Proof. All parts are proved by a straightforward structural induction on φ. Here, we only
present two cases of the induction for (1) and (2). The rest of the proof can be found in Appendix A.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
33:20 J. Esparza et al.
(1) Assume F φ
w ⊆ M. Then F φ
wi ⊆ M for all i ≥ 0. We prove the following stronger statement
via structural induction on φ:
∀i. ( (wi |= φ) ⇒ (wi |= φ[M]ν ) ).
We consider one representative of the “interesting” cases and one of the “straightforward” cases:
• Case φ = ψ1 Uψ2: Let i ≥ 0 arbitrary and assume wi |= ψ1 Uψ2. Then ψ1 Uψ2 ∈ F φ
wi and so
φ ∈ M. We prove wi |= (ψ1 Uψ2)[M]ν :
wi |= ψ1 Uψ2
⇒ wi |= ψ1 Wψ2
⇐⇒ ∀j.wi+j |= ψ1 ∨ ∃k ≤ j.wi+k |= ψ2
⇒ ∀j.wi+j |= ψ1[M]ν ∨ ∃k ≤ j.wi+k |= ψ2[M]ν (induction hypothesis)
⇐⇒ wi |= (ψ1[M]ν ) W (ψ2[M]ν )
⇐⇒ wi |= (ψ1 Uψ2)[M]ν (φ ∈ M, Definition 27)
• Case φ = ψ1 ∨ψ2: Let i ≥ 0 arbitrary and assume wi |= ψ1 ∨ψ2:
wi |= ψ1 ∨ψ2
⇐⇒ wi |= ψ1 ∨ wi |= ψ2
⇒ wi |= ψ1[M]ν ∨ wi |= ψ2[M]ν (induction hypothesis)
⇐⇒ wi |= (ψ1 ∨ψ2)[M]ν (Definition 27)
(2) Assume M ⊆ GF φ
w . Notice that GF φ
w = GF φ
wi for all i ≥ 0 and thus M ⊆ GF φ
wi for all i ≥ 0.
We prove the following stronger statement via structural induction on φ:
∀i. ( (wi |= φ[M]ν ) ⇒ (wi |= φ) ).
• Case φ = ψ1 Uψ2: If φ  M, then by definition φ[M]ν = ff. So wi |= φ[M]ν = ff for all i and
thus the implication (wi |= φ[M]ν ) ⇒ (wi |= φ) holds for every i ≥ 0. Assume now φ ∈ M.
Since M ⊆ GF φ
w , we havewi |= GFφ and so in particularwi |= Fψ2. To prove the implication
assume wi |= (ψ1 Uψ2)[M]ν for an arbitrary fixed i. We show wi |= ψ1 Uψ2:
wi |= (ψ1 Uψ2)[M]ν
⇐⇒ wi |= (ψ1[M]ν ) W (ψ2[M]ν ) (φ ∈ M, Definition 27)
⇐⇒ ∀j.wi+j |= ψ1[M]ν ∨ ∃k ≤ j.wi+k |= ψ2[M]ν
⇒ ∀j.wi+j |= ψ1 ∨ ∃k ≤ j.wi+k |= ψ2 (induction hypothesis)
⇐⇒ wi |= ψ1 Wψ2
⇐⇒ wi |= ψ1 Uψ2 (wi |= Fψ2)
• Case φ = ψ1 ∨ψ2: Let i ≥ 0 arbitrary and assume wi |= ψ1 ∨ψ2. We have:
wi |= (ψ1 ∨ψ2)[M]ν
⇐⇒ wi |= ψ1[M]ν ∨ (wi |= ψ2[M]ν (Definition 27)
⇒ wi |= ψ1 ∨ wi |= ψ2 (induction hypothesis)
⇐⇒ wi |= ψ1 ∨ψ2
Example 31. Consider φ = GFa ∨ GF(b ∧ Gc). Since μ(φ) = {Fa, F(b ∧ Gc)}, there are four possible sets for M: ∅, {Fa}, {F(b ∧ Gc)}, and {Fa, F(b ∧ Gc)}. For M = ∅, we get φ[M]ν ≡ ff, indicating
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
A Unified Translation of Linear Temporal Logic to ω-Automata 33:21
that if neither a nor b ∧ Gc hold infinitely often, then φ cannot hold. For the other three possibilities (a holds infinitely often, b ∧ Gc holds infinitely often, or both) there are words satisfying φ,
like aω, {b,c}
ω, and {a,b,c}
ω, respectively.
Lemma 30 can be interpreted in terms of oracles. For example, Lemma 30.2 states that if an oracle
promises us that w satisfies every property of M infinitely often, then to prove that w satisfies φ,
we only need to show that it satisfies φ[M]ν . So, we can interpret φ[M]ν as “φ after promise M.”
5.6 Approximating PM,N with UM,N
We prove identities (7) and (8) of the overview section. We consider Equation (7) first, i.e., we
show PM,N ⊆ UM,N . Recall that PM,N is the set of words w satisfying M = GF φ
w and N = F G φ
w ,
and UM,N is the language of all words satisfying GF(ψ[N]μ ) for every ψ ∈ M, and FG(ψ[M]ν ) for
every ψ ∈ N. So it suffices to prove:
Lemma 32. Let φ be a formula and let w be a word. If M = GF φ
w and N = F G φ
w , then:
∀ψ ∈ M. w |= GF(ψ[N]μ )
∀ψ ∈ N. w |= FG(ψ[M]ν ).
Proof. Let ψ ∈ M = GF φ
w . We have w |= GFψ, and so wi |= ψ for infinitely many i ≥ 0. Since
F G φ
wi = F G φ
w = N for every i ≥ 0, Lemma 30.4 can be applied to wi , F G φ
wi , and ψ. This yields
wi |= ψ[N]μ for infinitely many i ≥ 0 and thus w |= GF(ψ[N]μ ).
Let ψ ∈ N = F G φ
w . Since wi |= FGψ, there is an index j such that wj+k |= ψ for every k ≥ 0.
By Lemma 25 the index j can be chosen so it also satisfies M = GF φ
w = F φ
wj+k = GF φ
wj+k for every
k ≥ 0. Lemma 30.1 can be applied to F φ
wj+k ,wj+k , andψ. This yieldswj+k |= ψ[M]ν for every k ≥ 0
and thus w |= FG(ψ[M]ν ).
Let us now prove Equation (8), i.e., UM,N ∩ L(φ[M]ν )
s ⊆ L(φ)
s . We first observe that, by
Lemma 30.2, it suffices to show that every word w ∈ UM,N satisfies M ⊆ GF φ
w . This is done in
Lemma 33 below, but let us interpret this result. The lemma states that if a word w satisfies
GF(ψ[N]μ ) for everyψ ∈ M and FG(ψ[M]ν ) for everyψ ∈ N, then it satisfies GFψ for everyψ ∈ M
and FGψ for every ψ ∈ N. Recall that ψ[M]ν can be interpreted as “ψ after promise M.” So, at first
sight, the lemma looks wrong: To verify the promise M ⊆ GF φ
w , we are relying on the promise
N ⊆ FG φ
w , and vice versa. However, there is no circularity in this rely/guarantee reasoning. Indeed, for the promise M ⊆ GF φ
w , we only rely on the promise N ⊆ FG φ
w “for subformulas of M,”
and vice versa. Since the subformula order is well founded, we eventually reach formulas ψ such
that ψ[M]ν = ψ or ψ[N]μ = ψ.
Lemma 33. Let φ be a formula and let w be a word. For every M ⊆ μ(φ) and N ⊆ ν (φ), if
∀ψ ∈ M. w |= GF(ψ[N]μ )
∀ψ ∈ N. w |= FG(ψ[M]ν ),
then M ⊆ GF φ
w and N ⊆ FG φ
w .
Proof. Let M ⊆ μ(φ) and N ⊆ ν (φ). Observe that M ∩ N = ∅. Let n := |M ∪ N |. Let ψ1,...,ψn
be an enumeration of M ∪ N compatible with the subformula order, i.e., ifψi is a subformula ofψj ,
then i ≤ j. Finally, let (M0, N0), (M1, N1),..., (Mn, Nn ) be the unique sequence of pairs satisfying:
• (M0, N0) = (∅, ∅) and (Mn, Nn ) = (M, N).
• For every 0 < i ≤ n, if ψi ∈ M, then Mi \ Mi−1 = {ψi} and Ni = Ni−1, and if ψi ∈ N, then
Mi = Mi−1 and Ni \ Ni−1 = {ψi}.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:22 J. Esparza et al.
We prove Mi ⊆ GF φ
w and Ni ⊆ FG φ
w for every 0 ≤ i ≤ n by induction on i. For i = 0 the result
follows immediately from M0 = ∅ = N0. For i > 0, we consider two cases:
• ψi ∈ N, i.e., Mi = Mi−1 and Ni \ Ni−1 = {ψi}.
By induction hypothesis and Mi = Mi−1, we have Mi ⊆ GF φ
w and Ni−1 ⊆ FG φ
w . We prove
ψi ∈ FG φ
w , i.e., w |= FGψi , in three steps.
—Claim 1: ψi[M]ν = ψi[Mi]ν .
By the definition of ·[·]ν ,ψi[M]ν is completely determined by the μ-subformulas ofψi that
belong to M. By the definition of the sequence (M0, N0),..., (Mn, Nn ), a μ-subformula of
ψi belongs to M if and only if it belongs to Mi , and we are done.
—Claim 2: Mi ⊆ GF φ
wk for every k ≥ 0.
Follows immediately from Mi ⊆ GF φ
w .
—Proof of w |= FGψi .
By the assumption of the lemma, we have w |= FG(ψi[M]ν ), and so, by Claim 1, w |=
FG(ψi[Mi]ν ). So there exists an index j such that wj+k |= ψi[Mi]ν for every k ≥ 0. By
Claim 2, we further have Mi ⊆ GF φ
wj+k for every j, k ≥ 0. So, we can apply Lemma 30.2
to Mi , wj+k , and ψi , which yields wj+k |= ψi for every k ≥ 0. So w |= FGψi .
• ψi ∈ M, i.e., Mi \ Mi−1 = {ψi} and Ni = Ni−1.
By induction hypothesis, we have in this case Mi−1 ⊆ GF φ
w and Ni ⊆ FG φ
w . We prove ψi ∈
GF φ
w , i.e., w |= GFψi in three steps.
—Claim 1: ψi[N]μ = ψi[Ni]μ .
The claim is proved as in the previous case.
—Claim 2: There exists j ≥ 0 such that Ni ⊆ Gφ
wk for every k ≥ j.
Follows immediately from Ni ⊆ FG φ
w .
—Proof of w |= GFψi .
By the assumption of the lemma, we havew |= GF(ψi[N]μ ). Let j be the index of Claim 2.
By Claim 1, we have w |= GF(ψi[Ni]μ ), and so there exist infinitely many k ≥ j such that
wk |= ψi[Ni]μ . By Claim 2, we further have Ni ⊆ Gφ
wk . So, we can apply Lemma 30.5 to
Ni , wk , and ψi , which yields wk |= ψi for infinitely many k ≥ j. So w |= GFψi .
Example 34. Let φ = F(a ∧ G(b ∨ Fc)), M = {φ}, and N = {G(b ∨ Fc)}.
• The condition ∀ψ ∈ M. w |= GF(ψ[N]μ ) becomes
w |= GF 
φ[N]μ
	
= GF(Fa ∧ tt) ≡ GFa.
• The condition ∀ψ ∈ N. w |= FG(ψ[M]ν ) becomes
w |= FG ((G(b ∨ Fc))[M]ν ) = FG(G(b ∨ ff)) ≡ FGb.
Applying Lemma 32 to this, we then obtain thatw |= GFa ∧ FGb implies φ ∈ GF φ
w and G(b ∨ Fc) ∈
F G φ
w .
5.7 The Master Theorem: Logical Characterisation of LTL
Putting together Lemmas 30, 32, and 33, we arrive at our main contribution: a decomposition of
the language of an LTL formula into a Boolean combination of plain languages.
Theorem 35 (Master Theorem). Let φ be a formula and letw be a word. Thenw |= φ if and only
if there exist M ⊆ μ(φ) and N ⊆ ν (φ) satisfying:
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
A Unified Translation of Linear Temporal Logic to ω-Automata 33:23
(1) ∃i.wi |= aft(φ,w0i )[M]ν ,
(2) ∀ψ ∈ M.w |= GF(ψ[N]μ ),
(3) ∀ψ ∈ N.w |= FG(ψ[M]ν ).
With respect to the overview, observe that UM,N , defined in Equation (6), is the language of
words satisfying (2) and (3), andVM,N , defined in Equation (10), is the language of words satisfying
(1). If w is stable, then we can take i = 0, and condition (1) becomes w |= φ[M]ν .
Observe that aft(φ,w0i )[M]ν , GF(ψ[N]μ ), and FG(ψ[M]ν ) are formulas of the LTL fragments
νLT L, GF(μLT L), and FG(νLT L), respectively. For these fragments, we can build automata using
Proposition 13. So, given a class of automata effectively closed under union and intersection, we
can construct automata for all of LTL if we know how to do it for plain formulas.
Proof of the Master Theorem. (⇒) Assumew |= φ, and set M := GF φ
w and N := F G φ
w . Properties (2) and (3) follow from Lemma 32. For property (1), let i be an index such that F φ
wi = GF φ
wi =
GF φ
w ; this index exists by Lemma 25. By Lemma 9, we have wi |= aft(φ,w0i ), and by Lemma 30.1
wi |= aft(φ,w0i )[M]ν .
(⇐) Assume that properties (1–3) hold for sets M ⊆ μ(φ), N ⊆ ν (φ) and an index i. By Lemma 33,
we have M ⊆ GF φ
w , and so M ⊆ GF φ
wi . Fromwi |= aft(φ,w0i )[M]ν , we obtainwi |= aft(φ,w0i ) with
Lemma 30.2. Finally, Lemma 9 yields then w |= φ.
Example 36. Let φ = F(a ∧ G(b ∨ Fc)) as in Example 34, and let φ
 = d U (e ∧ φ). For M =
{φ,φ

}, N = {G(b ∨ Fc)}, and i = 0 the Master Theorem yields that w |= φ
 is implied by
(1) w |= (d U (e ∧ φ))[M]ν = d W (e ∧ φ[M]ν ) = d W (e ∧ tt) ≡ d W e,
(2) w |= GF(φ[N]μ ) = GF(F(a ∧ tt)) ≡ GFa,
w |= GF(φ

[N]μ ) = GF(d U (e ∧ F(a ∧ tt))) ≡ GF(e ∧ Fa), and
(3) w |= FG((G(b ∨ Fc))[M]ν ) = FG(G(b ∨ ff)) ≡ FGb.
For M
 = {φ}, N 
 = {G(b ∨ Fc)}, and i
 = 0, condition (1) cannot be fulfilled, since:
w |= (d U (e ∧ φ))[M

]ν = ff.
Logically this is sound, because w |= ff implies everything. This just shows that the set of words
satisfying these conditions is empty. Let us now choose i
 = 1, and let us assume that the first letter
of the word is {e}, i.e., w[0] = {e}. Then the Master Theorem says that w |= φ
 is implied by
(1) w |= (aft(d U (e ∧ φ), {e})[M

]ν = ((tt ∧ (φ ∨ ... )) ∨ (ff ∧ φ

)) [M

]ν ≡ tt,
(2) w |= GF(φ[N 

]μ ) = GF(F(a ∧ tt)) ≡ GFa,
(3) w |= FG((G(b ∨ Fc))[M

]ν ) = FG(G(b ∨ ff)) ≡ FGb.
Thus, the Master Theorem is offering us yet another way to provew |= φ. One that is even simpler
than the first one.
The formulation of the Master Theorem is almost symmetric. Only one “impurity” breaks this
symmetry: the advice function ·[M]ν in condition (1). Could we also use ·[N]μ at that location?
Yes, the theorem remains true after substituting ·[N]μ for ·[M]ν . So why do we choose ·[M]ν ?
The application of ·[M]ν yields a formula of the fragment νLT L. The languages corresponding to
this fragment are characterised by (finite) bad prefixes. Whenever a word does not satisfy ψ[M]ν ,
we can learn this from a finite prefix. Let us now consider ·[N]μ . The languages corresponding to
the fragment ·[N]μ are characterised by (finite) good prefixes and if a word satisfies ψ[N]μ , then
we know this after reading a finite prefix, but in general there is no finite prefix for proving that
ψ[N]μ is not satisfied.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:24 J. Esparza et al.
For this reason, if we choose ψ[M]ν , then we can sequentially test i’s for condition (1), since
either we have not yet identified a bad prefix and thus the word can be continued such that (1)
holds, or we have found a bad prefix and we can move to another candidate fori. Lemma 37 shows
how to do this efficiently. However, this argument does not work for ψ[N]μ and in this case, we
need to check different i’s in parallel. This can be easily done if nondeterminism is available, but
it is difficult for a deterministic automaton.
6 DRAS FOR ARBITRARY LTL FORMULAS
We use the Master Theorem (Theorem 35) to extend the translation for μLT L, νLT L, GF(μLT L),
and FG(νLT L) to arbitrary LTL formulas. Since our goal is only to show that we can easily obtain
automata of asymptotically optimal size, we give priority to a simpler construction over one with
fewer states.
Let φ be a formula of length n. We construct a DRA for L(φ) with 22O (n)
states and at most
2n Rabin pairs. For a fixed guess M and N, we first construct DBAs and DCAs checking (1–3),
to which we refer by C1
φ,M , B2
M,N , and C3
M,N . These automata are then intersected resulting in a
DRA Rφ,M,N with 22O (n)
states and one single Rabin pair. Finally, we construct a DRA ADRA(φ)
for L(φ) by taking the union of all Rφ,M,N . Proposition 13 shows how to build B2
M,N and C3
M,N ,
but cannot be immediately applied to C1
φ,M . We delay the definition of ADRA(φ) to figure out how
to construct an automaton for condition (1).
Interlude: An Automaton for Condition (1). We need to define an automaton that accepts a word
w if and only ifwi |= aft(φ,w0i )[M]ν for some suffixwi . It is intuitive that if we have an automaton
identifying such an index i, then we immediately obtain that (1) of Theorem 35 holds. However, the
other direction is not immediately clear, since there is no nondeterminism for guessing a suitable
i. We address this by resorting to the following lemma, which allows us to postpone checking
wi |= aft(φ,w0i )[M]ν by an arbitrary number of steps and thus the automaton cannot miss the
right moment.
Lemma 37. Let φ be a formula, letw be a word. Ifw |= φ[M]ν , thenwi |= aft(φ,w0i )[M]ν for every
index i.
Proof. Assume w |= φ[M]ν . It suffices to prove w1 |= aft(φ,w01)[M]ν for a single letter w01,
since the general case immediately follows by an induction on i. For the single letter case, we
proceed by structural induction on φ, and consider only some representative cases:
• Case φ = a: Since w |= a[M]ν = a, we have a ∈ w01. So aft(a,w01)[M]ν = tt[M]ν = tt, and
thus w1 |= aft(φ,w01)[M]ν .
• Case φ = ψ1 Uψ2: Since w |= φ[M]ν , we have φ[M]ν  ff, and so φ ∈ M. We derive:
w |= φ[M]ν
⇐⇒ w |= (ψ1[M]ν ) W (ψ2[M]ν ) (φ ∈ M, Definition 27)
⇐⇒ w |= ψ2[M]ν ∨ (ψ1[M]ν ∧ X((ψ1[M]ν ) W (ψ2[M]ν ))) (LTL semantics)
⇐⇒ w |= ψ2[M]ν ∨ (ψ1[M]ν ∧ X(φ[M]ν )) (φ ∈ M, Definition 27)
⇒ w1 |= aft(ψ2,w01)[M]ν ∨ (aft(ψ1,w01)[M]ν ∧ φ[M]ν ) (induction hypothesis)
⇐⇒ w1 |= (aft(ψ2,w01) ∨ (aft(ψ1,w01) ∧ φ))[M]ν (Definition 27)
⇐⇒ w1 |= aft(φ,w01)[M]ν (Definition 7)
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
A Unified Translation of Linear Temporal Logic to ω-Automata 33:25
Fig. 5. DCA C1
φ,M for φ = G(a U b ∨ c) and M = {a Ub}.
Loosely speaking, C1
φ,M —the automaton responsible for checking (1)—starts by checking w |=
φ[M]ν . For this it uses the construction of Proposition 13 on the νLT L formula φ[M]ν . Intuitively,
if that automaton rejects, then it rejects “after finite time.” If the formula becomes equivalent to ff
after, say, i steps, then w |= φ[M]ν , and C1
φ,M proceeds to check w |= aft(φ,w0i )[M]ν . To perform
this reset, C1
φ,M needs to know aft(φ,w0i ), and so it also maintains aft(φ,w0i ) in its state. In other
words, after j steps C1
φ,M is in state:
aft(φ,w0j), aft((aft (φ,w0i ) [M]ν ),wij),
where i ≤ j is the number of steps after which C1
φ,M had to reset for the last time. If the second
component of the state becomes ff, then the automaton uses the first component to determine
which formula to check next. The accepting condition then states that the transitions leading to a
state of the form ψ, ff must occur finitely often, which implies that eventually one of the checks
w |= φj[M]ν succeeds.
To use ·[·]ν for this, we first need to show that we can lift the operation to our states, which are
equivalence classes and not formulas:
Lemma 38. Let φ and ψ be two formulas. If φ ∼ ψ, then φ[M]ν ∼ ψ[M]ν .
Proof. Notice that ·[·]ν satisfies the precondition of Lemma 6 and applying it yields the statement we wanted to prove.
Proposition 39. Let φ be a formula and let M be a set of formulas. Then the following DCA over
the alphabet 2Ap recognises exactly the words w such that ∃i.wi |= aft(φ,w0i )[M]ν holds:
C1
φ,M = (Q, δ,[φ]∼,[φ[M]ν ]∼, Fin(α)) ,
where we define the statesQ, the transition function δ, and the rejecting states α in the following way:
• Q = Reach(φ)/∼ ×
ψ ∈Reach(φ) Reach(ψ[M]ν )/∼. That is, a state is a tuple of equivalence
classes [·]∼, where the second tracks the formula after applying ·[·]ν .
•
δ ([ξ]∼,[ζ ]∼, σ ) =

[aft(ξ, σ )]∼,[aft(ξ, σ )[M]ν ]∼ if ζ ∼ ff
[aft(ξ, σ )]∼,[aft(ζ , σ )]∼ otherwise.
That is, a transition either resets a failed attempt to prove wi |= aft(φ,w0i )[M]ν for some i or
continues unfolding both equivalence classes using aft∼.
• α = Reach(φ)/∼ × {[ff]∼}.
Example 40. Let φ = G(a U b ∨ c). Observe that φ is not in any of our “simple” fragments and
that it recognises neither a safety nor a co-safety language. Further, let M = {a U b} and M
 =
∅ be two guesses. Hence, φ[M]ν = G(a W b ∨ c) and φ[M

]ν = G(ff ∨ c). The DCA C1
φ,M from
Proposition 39 for φ and M is shown in Figure 5 and the DCA C1
φ,M
 for M
 is shown in Figure 6.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
33:26 J. Esparza et al.
Fig. 6. DCA C1
φ,M
 for φ = G(a U b ∨ c) and M
 = ∅.
Let us now consider two words w and w

. For w = (abc)((abc)(abc))ω, we have M = GF φ
w ⊃
M

. On the one hand the word w is accepted by C1
φ,M , since the run alternates between the two
non-rejecting states. On the other hand, we have w1 |= aft(φ,w01)[M]ν ≡ G(a W b ∨ c). Moving
to C1
φ,M
, we see that w is rejected, since the run infinitely often leaves the initial state φ,φ[M

]ν 
and visits the rejecting state φ ∧ a U b, ff. Consequently, we have wi |= aft(φ,w0i )[M

]ν for all i.
For w
 = (abc)
ω, we have M ⊃ GF φ
w
 = M

. The word w
 is not rejected by C1
φ,M and we have
for example w
 |= φ[M]ν = G(a W b ∨ c). However, the guess M cannot be proven and thus the
assumption of M being a correct guess is not satisfied. Further, w
 is accepted by C1
φ,M
, which
loops in the initial state, and we also have w
 |= φ[M

]ν ≡ Gc.
Proof of Proposition 39. (⇒) Let w be a word such that wi |= aft(φ,w0i )[M]ν for some i.
We need to show that the run r induced by w is an accepting run on C1
φ,M . Then by Lemma 37,
we know that all following j > i have the same property (wj |= aft(φ,w0j)[M]ν ). Let r be the run
on C1
φ,M corresponding to w. We prove that there is at most one k > i, such that r[k] ∈ α and
thus w ∈ L(C1
φ,M ). Assume k1 is the first index larger than i where r[k1] ∈ α. If there is no such
element, then we are immediately done. Thus, r[k1 + 1] = aft(φ,w0(k1+2) ), (aft(φ,w0(k1+2) ))[M]ν .
Since k1 + 2 > i, we have wk1+2 |= aft(φ,w0(k1+2))[M]ν , thus due to Lemma 12.2, we have that the
second component never reaches ff again.
(⇐) Assume w is accepted by C1
φ,M . Then the corresponding run r visits the set of states α only
finitely often. Leti be the last time were the run r encounters [ff]∼ in the second component or −1 if
there is never one. Then the second component is aft(φ,w0(i+1))[M]ν atr[i + 1]. Since this component never sees [ff]∼ again after i, we can apply Lemma 12.2 to obtain wi+1 |= aft(φ,w0(i+1))[M]ν ,
which concludes the proof.
The Complete DRA. Finding a way to check (1) was the last missing piece, and we can now
assemble DRAs for arbitrary formulas by means of union and intersection applied to automata
from Proposition 13 and Proposition 39:
Theorem 41. Let φ be a formula. We define for each M ⊆ μ(φ) and each N ⊆ ν (φ) the following
DBAs and DCAs:
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
A Unified Translation of Linear Temporal Logic to ω-Automata 33:27
Fig. 7. DRA Rφ,M,N for φ = G(ψ ∨ c),ψ = a Ub, M = {ψ }, and N = ∅. The DRA Rφ,M,N has only one Rabin
pair: Fin() ∧ Inf(†). Some rejecting states have been omitted and the edges leading to them are indicated
by a densely dashed arrow.
• C1
φ,M is the DCA from Proposition 39.
• B2
M,N = 

ψ ∈M Bψ [N ]μ
GFμ is the intersection of DBAs from Proposition 13.
• C3
M,N = 

ψ ∈N Cψ [M]ν
FGν is the intersection of DCAs from Proposition 13.
Let Rφ,M,N be the intersection DRA of the DBAs and DCAs C1
φ,M , B2
M,N , and C3
M,N with exactly
one Rabin pair:
Rφ,M,N = C1
φ,M ∩ B2
M,N ∩ C3
M,N .
Then the following DRA over the alphabet 2Ap recognises L(φ):
ADRA(φ) =

M ⊆μ (φ)
N ⊆ν (φ)
Rφ,M,N .
Example 42. Let φ = G(a U b ∨ c) be the formula from Example 40. We build the DRA Rφ,M,N
(Theorem 41) for M = {a U b} and N = ∅ as the intersection of the DCA C1
φ,M (Figure 5) and the
DBA B(aUb)
GFμ (Proposition 13). The DRA is shown in Figure 7.
Let us again consider the two wordsw andw

. Forw = (abc)((abc)(abc))ω, we have M = GF φ
w .
The wordw is accepted, since the run eventually alternates between the states in the lower-left and
upper-right corners of Figure 7. Forw
 = (abc)
ω, we have M  GF φ
w
. The wordw
 is rejected, since
the run stays in the initial state and never visits an accepting state. Observe that in this case we
still havew
 |= G(a U b ∨ c) and the word is accepted by another DRA component. More precisely,
w
 is accepted by the DRA Rφ,M

,N 
 with M
 = ∅ and N 
 = ∅.
The reader might have noticed that there are distinct states, e.g., Fψ and Fψ ∨ψ, that are
language-equivalent and there exists a simple syntactic procedure to show these formulas are
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.   
33:28 J. Esparza et al.
equivalent. This can be integrated into the presented framework and only needs technical changes
as described in Reference [69].
Proof of Theorem 41. Let φ be a formula, let ADRA(φ) be the corresponding automaton, and
let w be a word.
(⇒) Assume w is in L(φ). By Theorem 35 there exist M and N such that (1–3) hold. We show
thatw ∈ L(ADRA(φ)) by proving that the run r forw on Rφ,M,N is accepting. This run is accepting
if there exist accepting runs forw on C1
φ,M , B2
M,N , and C3
M,N . To show this, we simply need to apply
Proposition 39 to (1) and Proposition 13 to (2–3) and we are done.
(⇐) Assumew is accepted by ADRA(φ). Thus, there exists an accepting runr forw on Rφ,M,N for
some M ⊆ μ(φ) and N ⊆ ν (φ). Thus, C1
φ,M , B2
M,N , and C3
M,N acceptw and applying Proposition 39
and Proposition 13 yields (1–3) for M and N. Hence, the right-hand side of Theorem 35 is fulfilled
and we follow that w is in L(φ).
6.1 Complexity Analysis
Let φ be a formula of length n. The size of the automata from Proposition 13 crucially depends on
the properties of propositional equivalence, because it determines how Reach(φ)/∼ is partitioned
into equivalence classes. In Lemma 10, we already showed that 22n
is an upper bound of the cardinality of Reach(φ)/∼. The automata Bφ
μ , Bφ
ν , Cφ
μ , and Cφ
ν have at most 22n
states and, by the same
argument, Bφ
GFμ
and Cφ
FGν have at most 22n+1
states. This is already asymptotically optimal, as the
smallest automata are still doubly exponential in the worst-case [1, 43].
Interestingly, not only Reach(φ)/∼ but also
ψ ∈Reach(φ) Reach(ψ[M]ν )/∼ has at most 22n
elements. Indeed, this set is a subset of all (positive) Boolean functions over at most n variables, since
·[·]ν only replaces existing temporal subformulas by other subformulas of the same (or smaller)
size or the constant ff. It follows that the automaton Cφ,M has at most (22n
)
2 = 22n+1
states.
Let us now bound the number of states of the whole automaton. We have seen before that C1
φ,M
has at most 22n+1
states. By Proposition 13, L(GF(ψ[N]μ ) is recognised by a DBA with at most 22n+1
states. Recall that the intersection of the languages of k DBAs with s1,...,sk states is recognised by
a DBA with k ·
k
j=1 sj states. Since |M| ≤ n, the intersection of the DBAs B2
M,N for the formulas
GF(ψ[N]μ ) yields a DBA with at most
n ·

22n+1 	n
= 2n2n+1+(log2 n) ≤ 22n+(log2 n)+2
states. Dually, by Proposition 13 L(FG(ψ[M]μ ) is recognised by a DCA with at most 22n+1
states.
Recall that the intersection of the languages of k DCAs with s1,...,sk states is recognised by
a DCA with k
j=1 sj states. Since |N | ≤ n, the intersection of the DCAs C3
M,N for the formulas
FG(ψ[M]ν ) yields a DCA with at most

22n+1 	n
= 2n2n+1
= 22n+(log2 n)+1
states. Thus, the intersection DRA Rφ,M,N has at most
22n+1
· 22n+(log2 n)+2
· 22n+(log2 n)+1
≤ 22n+(log2 n)+4
∈ 22O (n)
states and one Rabin pair. Taking the union of all these yields a DRA ADRA(φ) with at most

22n+(log2 n)+4
2n
= 22n ·2n+(log2 n)+4
= 222n+(log2 n)+4
∈ 22O (n)
states and at most 2n Rabin pairs.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
A Unified Translation of Linear Temporal Logic to ω-Automata 33:29
Remark 43. While the achieved result matches the theoretical worst-case complexity, it is easy
to refine the construction to achieve a practically scalable translation. For instance, one can determine based on syntactic criteria if a particular pair of sets (M, N) is redundant. The corresponding
redundant Rφ,M,N can then be removed from ADRA(φ) and thus decreasing its size. Additionally,
standard-style optimisations such as dropping redundant Rabin pairs, see, e.g., Reference [27], or
using specialised intersection constructions for B2
M,N can be used. For an extensive list of optimisations and an in-depth discussion of their effect, we refer the interested reader to the Reference
[69].
7 LDBA CONSTRUCTION
7.1 LDBAs for Arbitrary LTL Formulas
We present a translation of LTL into limit-deterministic Büchi automaton (LDBA), a special class
of nondeterministic Büchi automata. LDBAs can be partitioned into an initial component, which
might contain states with a nondeterministic transition relation, and an accepting component that
contains all accepting states and is deterministic. If a run enters the accepting component via a
so-called “jump”, it cannot leave this component anymore.
The primary challenge for building LDBAs with the Master Theorem is that in the accepting
component it is impossible to construct DBAs for some of the formulas required by Theorem 35,
such as FGa. However, we can make use of the available nondeterminism to “guess” when Ga
holds and use the DBA construction for νLT L. Using this initial idea, we rephrase Theorem 35 and
break the symmetry of the Master Theorem to reduce “guessing” to exactly one point i in the run.
Specifically, we “synchronise” checking (1) and (3), which results in the following corollary:
Corollary 44 (Variant of the Master Theorem). Let φ be a formula and let w be a word.
Then w |= φ if and only if there exist M ⊆ μ(φ), N ⊆ ν (φ), and i ≥ 0 satisfying:
(1

) wi |= aft(φ,w0i )[M]ν ,
(2

) ∀ψ ∈ M.wi |= GF(ψ[N]μ ),
(3

) ∀ψ ∈ N.wi |= G(ψ[M]ν ).
Proof. Clearly, the existence of an index i satisfying (1

–3

) implies that conditions (1–3)
of Theorem 35 hold. For the other direction, assume conditions (1–3) hold. By Lemma 37 the
index i stemming from condition (1) can be chosen arbitrarily large. Furthermore, since w |= 
ψ ∈M FG(ψ[M]ν ), we can choose i so it also satisfies wi |= 
ψ ∈M G(ψ[M]ν ).
The LDBA construction tracks in the initial component aft(φ,w0i ), i.e., after reading a finite word
w0i the initial component is in state [aft(φ,w0i )]∼. The states [aft(φ,w0i )]∼ are then connected to
the accepting component by jumps that guess sets M and N and the stabilisation point i. The jump
leads to the corresponding initial state of the intersection automaton (BM,N ) of three DBAs, which
are in charge of checking (1

), (2

), and (3

), and we refer to these automata by B1
M , B2
M,N , and
B3
M,N , respectively.
To be more precise: recall that aft∼([φ]∼,w0i ) ∈ Reach(φ)/∼ for every word w and every i ≥ 0.
For every [χ]∼ ∈ Reach(φ)/∼ and for each pair of sets M, N, we construct a DBA Bχ,M,N recognising the intersection of the languages of the formulas:
χ[M]ν

ψ ∈M
GF(ψ[N]μ )

ψ ∈N
G(ψ[M]ν ).
These formulas belong to νLT L, GF(μLT L), and νLT L, respectively, and so we can obtain DBAs
for them following the recipes of Proposition 13. Note that for all formulas χ and χ 
 the DBAs
Bχ,M,N and Bχ

,M,N have the same transition relation on common states and the same accepting
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:30 J. Esparza et al.
states. We take advantage of this and combine all Bχ,M,N into a single structure that we call BM,N .
Formally, we construct a semi-deterministic8 Büchi automaton that is a Büchi automaton with a
deterministic transition relation, but with a set of initial states. The set of initial statesQ0,M,N then
contains for each [χ]∼ ∈ Reach(φ)/∼ the initial state ([χ[M]ν ]∼,q

0,q


0 ). Summarising, we obtain:
Theorem 45. Let φ be a formula. We define for each M ⊆ μ(φ) and each N ⊆ ν (φ) the following:
• B1
M =
[χ ]∼ ∈Reach(φ)/∼ Bχ [M]ν
ν is the (semi-deterministic) union of DBAs from Proposition 13.
• B2
M,N = 

ψ ∈M Bψ [N ]μ
GFμ is the intersection of DBAs from Proposition 13.
• B3
M,N is the DBA for 
ψ ∈N G(ψ[M]ν ) from Proposition 13.
Let BM,N be the (semi-deterministic) intersection of the DBAs B1
M , B2
M,N , and B3
M,N :
BM,N = (QM,N , δM,N ,Q0,M,N , Inf(αM,N )).
Then the following LDBA over the alphabet 2Ap recognises L(φ):
ALDBA(φ) = (Q, δ,[φ]∼, Inf(α)),
where we define the states Q, the transition relation δ, and the accepting states α in the following
way:
• Q = Reach(φ)/∼ ∪ {QM,N : M ⊆ μ(φ), N ⊆ ν (φ)}. That is, a state is either an equivalence
class [ψ]∼ or a product state ([ψ]∼,q

,q

) ∈ BM,N from one of the accepting components.
• δ = aft∼ ∪ δ ∪ {δM,N : M ⊆ μ(φ), N ⊆ ν (φ)}. That is, a transition is either within the
initial component (aft∼), within an accepting component (δM,N ), or it is a jump (δ) from the
initial to an accepting component. Let δ be defined for each state [ψ]∼ ∈ Reach(φ)/∼ and
each letter σ ∈ 2Ap as:
δ([ψ]∼, σ ) =

{δM,N (q0, σ ) : q0 = ([ψ[M]ν ]∼,q

0,q


0 ) ∈ Q0,M,N , M ⊆ μ(φ), N ⊆ ν (φ)}
• α = {αM,N : M ⊆ μ(φ), N ⊆ ν (φ)}.
Note that the automata B1
M and B3
M,N are in-fact weak, meaning that the states of every strongly
connected component (SCC) are either all accepting or all rejecting. Intersecting a DBA with a
weak DBA is simpler compared to the general case and it suffices to use the classical product construction for automata on finite words. This means it is not necessary to add additional information
to the product states to track the progress of the Büchi acceptance conditions, e.g., multiple copies
of the state space or a round-robin counter. Before we move on to the proof of the theorem, we
illustrate the construction using an example:
Example 46. Let φ = Fa ∨ FGb. The LDBA ALDBA(φ) constructed from Theorem 45 is depicted
in Figure 8. Observe that transitions within the upper half (initial component) and the lower half
(accepting component) are deterministic and only transitions from the upper to the lower part add
nondeterminism. In this drawing, we omitted several accepting components, e.g., M = {Fa}, N =
{Gb} or M
 = {FGb}, N 
 = {}, and some non-accepting states. We mark these omissions by dashed
outgoing transitions.
This example illustrates already a potential optimisation: B1
M and B3
M,N can be combined into
a single component, since both are in charge of accepting formulas from νLT L.
8The term appears in Reference [81] and coincides with the above-mentioned definition. However, later publications
might call an automaton semi-deterministic, when it is limit-deterministic or deterministic-in-the-limit. In our case semideterminism is stricter than limit-determinism, and these terms are not interchangeable.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.         
A Unified Translation of Linear Temporal Logic to ω-Automata 33:31
Fig. 8. ALDBA(φ) for φ = Fa ∨ FGb. Omitted states and transitions are indicated by dashed arrows.
Proof of Theorem 45. Let φ be a formula, let ALDBA(φ) be the corresponding automaton, and
let w be a word. Further, we denote by q χ

,M,N ∈ Q0,M,N the initial state of BM,N with [χ 

]∼ =
[χ[M]ν ]∼ in the first component for every reachable state [χ]∼ ∈ Reach(φ)/∼ and for all sets of
formulas M ⊆ μ(φ) and N ⊆ ν (φ). We let L(q χ

,M,N ) denote the language accepted from q χ

,M,N
on the automaton BM,N . Using Proposition 13, we can characterise the language L(q χ

,M,N ) in
terms of LTL:
∀v. v ∈ L(q χ

,M,N ) ⇐⇒ v |= χ[M]ν
∧ ∀ψ ∈ M. v |= GF(ψ[N]μ )
∧ ∀ψ ∈ N. v |= G(ψ[M]ν )
(⇒) Assume w is in L(φ). By Corollary 44 there exist i, M, and N such that (1

–3

) hold. We
now construct an accepting run r on ALDBA(φ). The run r follows for the first i − 1 steps the initial
component and reaches aft∼([φ]∼,w0i ) = [aft(φ,w0i )]∼ = [χ]∼ for some χ. The run then branches
off to the accepting component BM,N . Notice that (1

–3

) exactly matches the right-hand side
of our characterisation of L(q χ

,M,N ) and thus, we have wi ∈ L(q χ

,M,N ). Thus, there exists an
accepting run r
 forwi on BM,N starting in q χ

,M,N . Observe that we can reach from [χ]∼ the same
states as q χ

,M,N , since δ([χ]∼,w[i]) ∩ QM,N = δM,N (q χ

,M,N ,w[i]). Thus, r simply follows the
accepting run r
 from this point on and we are done.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020. 
33:32 J. Esparza et al.
(⇐) Assume w is accepted by ALDBA(φ). Then there exists an accepting run r, and since every
accepting state is located in some BM,N the run r eventually transitions to some BM,N . Let now
i be the time at which the run moves to BM,N for some [χ]∼ = [aft(φ,w0i )]∼ = aft∼([φ]∼,w0i ),
some M ⊆ μ(φ), and some N ⊆ ν (φ). Since the run r is accepting and δ([χ]∼,w[i]) ∩ QM,N =
δM,N (q χ

,M,N ,w[i]), we can construct an accepting run r
 on BM,N for wi :
r

[j] =

q χ

,M,N if j = 0
r[i + j] otherwise.
Thus, w ∈ L(q χ

,M,N ) and using our characterisation of this language, we end up with (1

–3

) of
Corollary 44. Consequently, w |= φ and we are done.
7.2 Complexity Analysis
Let φ be a formula of length n. Since ALDBA(φ) is a union and intersection of several components,
the number of states can be bounded by the size of the components:
|Reach(φ)/∼| +

M ⊆μ (φ)
N ⊆ν (φ)
(|Q1
M |·|Q2
M,N |·|Q3
M,N |).
We bound the size of each of these components by a doubly-exponential function. In the case of
B1
M it is not immediately clear from the previous results how to do this, because B1
M contains for
each element of Reach(φ)/∼ a potentially 22n
-sized automaton. However, observe that the number
of temporal subformulas of that formula is at most |sf(φ)| ≤ n and soQ1
M has at most 22n
elements.
B2
M,N is an intersection of |M|-many automata with at most 22n+1
states. We bound |M| by |μ(φ)| ≤
n and thus the number of states is at most n · (22n+1
)
n = 22n+(log2 n)+(log2 log2 n)+1
. B3
M,N is constructed
from the formula 
ψ ∈N G(ψ[M]ν ). This formula has at most |sf(φ)| + |ν (φ)| temporal subformulas
and thus the automaton has at most 22|sf(φ)|+|ν (φ)|
≤ 222n
states. Going back to our initial bound and
inserting the upper bounds for the components, we obtain:
22n
+ 2|μ (φ)|+|ν (φ)|
(22n
· 22n+(log2 n)+(log2 log2 n)+1
· 222n
) ≤ 22n
+ 224n+2
≤ 224n+3
∈ 22O (n)
.
Recall that the lower bound for the blowup of a translation from LTL to LDBAs is double exponential [72].
The definition of an LDBA allows the initial component to be nondeterministic. However, in our
construction, we make it deterministic and thus every accepting run has exactly one nondeterministic step. This (and some other technical details) make these LDBAs usable for quantitative (and
not only qualitative) probabilistic model checking. We give further details for this in Section 9.
8 NBA CONSTRUCTION
We proceed as in the DRA case: We first define constructions for LTL fragments by adapting the
function aft to the nondeterministic setting (Section 8.1) and then assemble them into a translation
for arbitrary LTL formulas (Section 8.2) using Corollary 44.
8.1 NBAs for μLT L, νLT L, GF(μLT L), and FG(νLT L)
Let φ be a formula in one of the fragments. Loosely speaking, the states of the deterministic automaton for φ are subformulas of φ, and the transition function is determined by aft: There is a
transition ψ σ
−→ ψ 
 iff aft(ψ, σ ) = ψ 

. To get nondeterministic automata, we put aft(ψ, σ ) into disjunctive normal form (DNF) and proceed as follows: If the DNF of aft(ψ, σ ) is ψ1 ∨···∨ψn, then
the automaton has transitions ψ σ
−→ ψ1,...,ψ σ
−→ ψn. We introduce a function aft∨ such that,
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
A Unified Translation of Linear Temporal Logic to ω-Automata 33:33
loosely speaking, aft∨(ψ, σ ) = {ψ1,...,ψn }. So the NBAs we construct have a transition ψ σ
−→ ψ 

if ψ 
 ∈ aft∨(ψ, σ ).
Transforming the above into a correct and formally defined construction requires some care.
Section 8.1.1 introduces some notations, Section 8.1.2 defines the function aft∨, and Section 8.1.3
defines the NBAs for our four fragments of LTL.
8.1.1 Disjunctive Normal Form. We represent formulas in DNF as sets of sets of literals. For
example, (a ∧ b) ∨ (¬a ∧ c) is represented as {{a,b}, {¬a,c}}. We use X,Y,... to denote finite sets
of sets and use the following notation:
• X ⊗ Y := {A ∪ B : A ∈ X, B ∈ Y }
• {X1,X2,...Xn } := {A1 ∪ A2 ∪···∪ An : A1 ∈ X1,A2 ∈ X2,...An ∈ Xn }.
• min(X) := {A ∈ X : ∀B ∈ X. B  A}
• X ∪min Y := min(X ∪ Y ), X ⊗min Y := min(X ⊗ Y ), and 
minX := min(
X).
The following identities are useful:

min∅ = {∅} 
min{X} = min(X) 
min (X∪Y) = (

minX) ⊗min (

minY).
We define the minimal DNF dnf(φ) of an LTL formula φ and show that it satisfies the following
property: The assignments that propositionally satisfy φ are the sets of literals of dnf(φ).
Proposition 47 (Minimal Disjunctive Normal Form). Let φ be a formula. We then recursively
define the minimal disjunctive normal form dnf(φ) as follows:
dnf(tt) = {∅} dnf(φ ∧ψ ) = dnf(φ) ⊗min dnf(ψ )
dnf(ff) = ∅ dnf(φ ∨ψ ) = dnf(φ) ∪min dnf(ψ )
dnf(a) = {{a}} dnf(Xφ) = {{Xφ}}
dnf(¬a) = {{¬a}} dnf(φ op ψ ) = {{φ op ψ }} for op ∈ {U, M, R, W}.
Further, let I be a propositional assignment. Then:
I |=p φ ⇐⇒ ∃Ψ ⊆ I. Ψ ∈ dnf(φ).
Proof sketch. This is proven by a straightforward structural induction on φ.
Example 48. Let φ = a ∨
ψ 
((a ∧ Xb) ∨ F(b ∨ c)). We then compute dnf(a) = {{a}}, dnf(a ∧ Xb) =
{{a, Xb}}, and dnf(F(b ∨ c)) = {{F(b ∨ c)}}. Then dnf(ψ ) = {{a, Xb}, {F(b ∨ c)}} and finally:
dnf(φ) = min({{a}} ∪ {{a, Xb}, {F(b ∨ c)}})
= min({{a}, {a, Xb}, {F(b ∨ c)}})
= {{a}, {F(b ∨ c)}}.
8.1.2 The Disjunctive “after”-Function. We define aft∨, the disjunctive version of aft.
Definition 49 (Disjunctive aft). Let Ψ be a set of formulas and let σ be a letter. We define
aft∨(Ψ, σ ) :=

min
{dnf(aft(ψ, σ )) : ψ ∈ Ψ}.
We extend the definition to words as follows:
aft∨(Ψ, ϵ ) := {Ψ}
aft∨(Ψ,wσ ) :=

{aft∨(Ψ

, σ ) : Ψ
 ∈ aft∨(Ψ,w)}.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
33:34 J. Esparza et al.
Finally, we define the reachability set of a formula φ by
aft∨(φ,w) :=

{aft∨(Ψ,w) : Ψ ∈ dnf(φ)}
Reach∨(φ) :=

{aft∨(φ,w) : w ∈ (2Ap )
∗}.
Notice that we use  in the definition of aft∨(Ψ,wσ ) and do not use
min. Moreover, notice
that aft∨(φ, ϵ ) = dnf(φ).
Example 50. Let φ = Xa ∨ X(a ∧ b). We compute aft∨(φ, {}) and aft∨(φ, {}{b}):
aft∨(φ, {}) =

{aft∨(Ψ, {}) : Ψ ∈ dnf(φ)}
=

{aft∨({Xa}, {}), aft∨({X(a ∧ b)}, {})}
=

{dnf(a), dnf(a ∧ b)}
=

{{{a}}, {{a,b}}} = {{a}, {a,b}}.
aft∨(φ, {}{b}) = ... — in the same manner as before
=

{aft∨({a}, {b}), aft∨({a,b}, {b})}
=

{dnf(ff), dnf(ff) ⊗min dnf(tt)}
=

{{}, {}} = ∅.
The reachability set of φ is Reach∨(φ) = {{Xa}, {X(a ∧ b)}, {a,b}, {a}, {}}.
The following two lemmas prove elementary properties of aft∨. The proofs are given in Appendix A.
Lemma 51. Let φ be a formula, let w be a finite word, and let I be a propositional assignment.
Then:
I |=p aft(φ,w) ⇐⇒ ∃Ψ ⊆ I. Ψ ∈ aft∨(φ,w).
Lemma 52. Let φ be a formula, let w be a finite word, let M ⊆ μ(φ), and let I ⊆ sf(φ). Then:
(1) aft∨(φ,w) ⊆ 2sf(φ)
,
(2) ∅ ∈ aft∨(φ,w) ⇐⇒ aft(φ,w) ∼ tt,
(3) aft∨(φ,w) = ∅ ⇐⇒ aft(φ,w) ∼ ff,
(4) L(aft(φ,w)) = {


ψ ∈Ψ L(ψ ) : Ψ ∈ aft∨(φ,w)},
(5) Let Ψ[M]ν := {ψ[M]ν : ψ ∈ Ψ}. Then:
I |=p aft(φ,w)[M]ν ⇐⇒ ∃Ψ. Ψ[M]ν ⊆I∧ Ψ ∈ aft∨(φ,w).
8.1.3 Automata Constructions. We construct NBAs for the LTL fragments of Section 2.2.2.
Proposition 53. Let φ ∈ μLT L.
• The following NBA over the alphabet 2Ap recognises L(φ):
Bφ
μ = (Reach∨(φ), aft∨, dnf(φ), Inf({∅})).
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.            
A Unified Translation of Linear Temporal Logic to ω-Automata 33:35
• The following NBA over the alphabet 2Ap recognises L(GFφ):
Bφ
GFμ = 
Reach∨(Fφ), aftFφ
∨ , {{Fφ}}, Inf({∅})
	
aftFφ
∨ (Ψ, σ ) =

{{Fφ}} if Ψ = ∅
aft∨(Ψ, σ ) otherwise.
Let φ ∈ νLT L.
• The following NBA over the alphabet 2Ap recognises L(φ):
Bφ
ν = (Reach∨(φ), aft∨, dnf(φ), Inf(Reach∨(φ))).
• The following NBA over the alphabet 2Ap recognises L(FGφ):
Bφ
FGν = 
Reach∨(Gφ) ∪ {{FGφ}}, aftGφ
∨ , {{FGφ}}, Inf(Reach∨(Gφ))	
aftGφ
∨ (Ψ, σ ) =

{{FGφ}, {Gφ}} if Ψ = {FGφ}
aft∨(Ψ, σ ) otherwise.
Example 54. Let φ = a ∧ X(b ∨ Fc), the formula for which a DBA was given in Example 14. The
NBA Bφ
GFμ
for φ is shown in Figure 9. Compared to the DBA of Example 14, the NBA has a simpler
structure, although in this case the same number of states.
Example 55. Let φn = n
i=1 F(ai ∧ XFbi ) a family of LTL formulas. In Example 54, we showed
that the NBA has a simpler structure, but the number of states stayed the same. In this example,
we look at the family φn, which yields a polynomial-sized nondeterministic automaton for φn
(Figure 10), while we obtain an exponential-sized deterministic automaton (Figure 11).
8.2 NBAs for Arbitrary LTL Formulas
Equipped with NBA constructions for LTL fragments, we go back to the construction in Theorem 45 and revise it such that we obtain NBAs of exponential size for arbitrary LTL formulas. We
achieve this by simply replacing the deterministic building blocks (DBAs) with nondeterministic
(NBAs) ones.
Theorem 56. Let φ be a formula. We define for each M ⊆ μ(φ) and each N ⊆ ν (φ) the following:
• B1
M =
Ψ∈Reach∨(φ) B∧Ψ[M]ν
ν is the union of NBAs from Proposition 53.
• B2
M,N = 

ψ ∈M Bψ [N ]μ
GFμ is the intersection of NBAs from Proposition 53.
• B3
M,N is the NBA for 
ψ ∈N G(ψ[M]ν ) from Proposition 53.
Let BM,N be the intersection of the NBAs B1
M , B2
M,N , and B3
M,N :
BM,N = (QM,N , δM,N ,Q0,M,N , Inf(αM,N )).
Then the following NBA over the alphabet 2Ap recognises L(φ):
ANBA(φ) = (Q, δ, dnf(φ), Inf(α)).
where we define the states Q, the transition relation δ, and the accepting states α in the following
way:
• Q = Reach∨(φ) ∪ {QM,N : M ⊆ μ(φ), N ⊆ ν (φ)}. That is, a state is either a clause Ψ or a
tuple of clauses (Ψ, Ψ

, Ψ

) ∈ BM,N from one of the accepting components.
• δ = aft∨ ∪ δ ∪ {δM,N : M ⊆ μ(φ), N ⊆ ν (φ)}. That is, a transition is either within the
initial component (aft∨), within an accepting component (δM,N ), or it is a jump (δ) from
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.     
33:36 J. Esparza et al.
Fig. 9. NBA Bφ
GFμ
for φ = a ∧ X(b ∨ Fc). Notice the different self-loops on {Fφ} and {Fc}. In the first state the
automaton guesses nondeterministically when to track φ, and in the second state the construction already
resolves the nondeterminism.
Fig. 10. NBA Bφ
μ for φ3 = 3
i=1ψi withψi = F(ai ∧ XFbi ). Notice that this NBA repeats for eachψi the same
structure and has in total 2n + 1 = 7 states.
Fig. 11. DBA Bφ
μ for φ3 = 3
i=1ψi with ψi = F(ai ∧ XFbi ) from Proposition 13 with simplified state labels.
Omitted transitions are indicated by dashed arrows. This automaton has 2n + 1 = 9 states.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:37
Fig. 12. ANBA(φ) for φ = Fa ∨ FGb. Omitted states and transitions are indicated by dashed arrows.
initial to accepting component. Let δ be defined for each state Ψ ∈ Reach∨(φ) and each letter
σ ∈ 2Ap as:
δ(Ψ, σ ) =

{δM,N (q0, σ ) : q0 = (Ψ[M]ν , Ψ

, Ψ

) ∈ Q0,M,N , M ⊆ μ(φ), N ⊆ ν (φ)}
• α = {αM,N : M ⊆ μ(φ), N ⊆ ν (φ)}.
Note that the automata B1
M and B3
M,N are in-fact weak, meaning that the states of every strongly
connected component (SCC) are either all accepting or all rejecting. Thus, as with the DBAs in the
LDBA construction, intersecting a NBA with a weak NBA is simpler compared to the general case,
and it suffices to use the classical product construction for automata on finite words. Before we
move on to the proof of the theorem, we illustrate the construction in the following example:
Example 57. Let us revisit the formula φ = Fa ∨ FGb previously used in Example 46. The NBA
ANBA(φ) constructed from Theorem 56 is depicted in Figure 12. Compared to the LDBA sketched
in Figure 8 the transition structure is considerably simpler.
Proof of Theorem 56. Let φ be a formula, let ANBA(φ) be the corresponding automaton, and
let w be a word. Further, we denote by QΨ

,M,N ⊆ Q0,M,N the initial states of BM,N with Ψ
 =
Ψ[M]ν in the first component for every reachable state Ψ ∈ Reach∨(φ) and for all sets of formulas
M ⊆ μ(φ) and N ⊆ ν (φ). We denote by L(QΨ

,M,N ) the language accepted from the statesQΨ

,M,N
on the automaton BM,N and using Proposition 53, we can characterise the language L(QΨ

,M,N )
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.    
33:38 J. Esparza et al.
in terms of LTL:
∀v. v ∈ L(QΨ

,M,N ) ⇐⇒ ∀ψ ∈ Ψ

. v |= ψ
∧ ∀ψ ∈ M. v |= GF(ψ[N]μ )
∧ ∀ψ ∈ N. v |= G(ψ[M]ν )
(⇒) Assume w |= φ. By Corollary 44 there exists i, M, and N such that (1

–3

) hold. We now
construct an accepting run r on ANBA(φ) and thus show w ∈ L(ANBA(φ)). Let now I := {ψ ∈
sf(aft(φ,w0i )[M]ν ) : wi |= ψ } be a propositional assignment. From (1

) and Lemma 4, we follow
I |=p aft(φ,w0i )[M]ν and thus, we can apply Lemma 52 to obtain a clause Ψ ∈ aft∨(φ,w0i ) such
that Ψ[M]ν ⊆ I. Thus, the run follows for the firsti steps a matching path in the initial component
to arrive at Ψ. Assume we have wi ∈ L(QΨ

,M,N ), then the run r branches off from the clause Ψ
via δ to the accepting component BM,N and follows the accepting run belonging to wi .
Thus, it remains to show that right-hand side of the characterisation of L(QΨ

,M,N ) holds for
wi . (2

) and (3

) match the second and third conjunct and we only need to prove ∀ψ ∈ Ψ

.wi |= ψ.
However, this follows immediately from the definition of I and the subset relation Ψ
 = Ψ[M]ν ⊆
I and we are done.
(⇐) Assume w is accepted by ANBA(φ). Then there exists an accepting run r. Let now i be
the index at which the run transitions via δ to BM,N for some Ψ ∈ aft∨(φ,w0i ), M ⊆ μ(φ), and
N ⊆ ν (φ). This has to happen, since every accepting state is in some accepting component BM,N .
Because the run r is accepting, wi is in L(QΨ

,M,N ) for Ψ
 = Ψ[M]ν and we obtain the following
from the LTL characterisation:
∀ψ ∈ Ψ[M]ν .wi |= ψ wi |=

ψ ∈M
GF(ψ[N]μ ) wi |=

ψ ∈N
G(ψ[M]ν ).
From the second and third fact, we can immediately follow (2

) and (3

) of Corollary 44 and for
showingw |= φ, we only need to prove the remaining (1

):wi |= aft(φ,w0i )[M]ν . Let now I := {ψ ∈
sf(aft(φ,w0i )[M]ν ) : wi |= ψ } be a propositional assignment. Observe that from the first fact, we
can follow Ψ[M]ν ⊆ I. Then, we apply Lemma 52 and get I |=p aft(φ,w0i )[M]ν . Using Lemma 4,
we derive (1

) and we are done.
8.3 Complexity Analysis
The elements of Reach∨(φ) are sets of temporal subformulas of φ, i.e., Reach∨(φ) ⊆ 2sf(φ)
. Since the
number of temporal subformulas is bounded by the length of the formula, we immediately obtain
|Reach∨(φ)| ≤ 2|sf(φ)| ≤ 2n where n is the length of φ. Thus, all NBAs have at most O(2n ) states.
More precisely, the NBAs for μLT L and νLT L have at most 2|sf(φ)|
, the NBAs for GF(μLT L) have
at most 2|sf(φ)|+1, and the NBAs for FG(νLT L) have at most 2|sf(φ)|+1 + 1 states. Observe that the
blow-up in translating LTL to NBAs for formulas constructed just using literals (a, ¬a), Boolean
connectives (∧, ∨), and the modal operator X is already exponential, see, e.g., Reference [7].
Let φ be a formula of length n. Since ANBA(φ) is constructed via union and intersection of several
components, the number of states can be bounded by the size of the components:
|Reach∨(φ)| +

M ⊆μ (φ)
N ⊆ν (φ)
(|Q1
M |·|Q2
M,N |·|Q3
M,N |).
We bound the size of each of these components by an exponential function. B1
M is a combination
of exponentially many automata with size O(2n ) and thus blindly applying the upper bounds of
the preceding section gives a O(2n · 2n ) = O(22n ) upper bound. However, observe that the number of temporal subformulas of that formula is at most |sf(φ)| ≤ n and so Q1
M has at most 2n
elements. B2
M,N is an intersection of |M|-many automata with at most 2n+1 states. We bound
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.   
A Unified Translation of Linear Temporal Logic to ω-Automata 33:39
Fig. 13. Selection of LTL translations to different types of automata, excluding the translations presented in
this article. Only syntactically defined classes are depicted; the semantically defined unambiguous, goodfor-games, and good-for-MDPs automata are omitted. Classical translations are depicted as dotted arrows,
and recent semantic approaches as thick arrows. The latter are implemented in Rabinizer; translation of
NBAs to DRAs is implemented in ltl2dstar [40], to LDBAs in Seminator [9], and to DPAs in Spot [18] and
nbadet [54]. The light-grey area indicates the automata suitable for probabilistic model checking, and the
dark-grey area the ones suitable for the traditional automata-theoretic approach to synthesis.
|M| by |μ(φ)| ≤ n and thus the number of states is at most n · (2n+1)
n = 2n2+n+log2 (n) including
the necessary round-robin counter. B3
M,N is constructed from the formula 
ψ ∈N G(ψ[M]ν ). This
formula has at most |sf(φ)| + |ν (φ)| temporal subformulas and thus the automaton has at most
2|sf(φ)|+|ν (φ)| ≤ 22n states. Going back to our initial bound and inserting the upper bounds for the
components, we obtain:
2n + 2|μ (φ)|+|ν (φ)|
(2n · 2n2+n+log2 (n) · 22n ) ≤ 2n + 2n2+5n+log2 (n) ≤ 2n2+6n+log2 (n) ∈ 2O (n2 )
.
This construction is refined in Reference [69] by replacing B2
M,N by a component of size n · 2n+1,
which reduces the upper bound to O(25n ) ⊆ 2O (n)
.
9 APPLICATIONS
The three classes of ω-automata discussed here (NBAs, LDBAs, and DRAs) have a wide range
of applications in verification and synthesis. In particular, NBAs are the standard for verification
of (possibly concurrent) programs, and DRAs are the traditional choice for verification of and
controller synthesis for systems with probabilistic behaviour, see, e.g., References [7, 14]. Here, we
describe also the less-known use of LDBAs in both verification and synthesis.
First, the LTL synthesis problem [65] consists of determining whether there is a system that
for all input streams produces output streams satisfying a given LTL formula, and, if that is the
case, constructing such a system. Although the traditional automata-theoretic approach suggests
to construct a DPA and further analyse it, this approach was not much in use due to bad scalability. The main bottleneck of the classic LTL→NBA→DPA translation path (see Figure 13) was
the underlying determinisation in the second step. The situation changed when alternative paths
to obtain DPAs from LTL appeared that side-stepped the determinisation of general NBA and
that alleviated the scalability issue. First, References [20, 22] enabled the first step of the path
LTL→D(G)RA→DPA, with the latter delivered by the index-appearance record [52], improved
and tailored in Reference [49]. Second, a path LTL→LDBA→DPA was enabled by an efficient generation of LDBAs [72] together with a transformation of LDBAs to DPAs [21]. The latter path
turned out to practically perform mostly even better than the former. As a result, the tool Strix
[55, 57], based on the latter construction, has recently won all LTL tracks of the synthesis competition SyntComp [36]. Besides, the preserved semantic labelling of the states of the automata
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
33:40 J. Esparza et al.
allows for heuristics guiding the exploration of the on-the-fly generated automaton [55] together
with efficient deployment of learning-based algorithms and lifelong learning paradigms in LTL
synthesis [42]. Such efforts have a great impact on the practical performance of solutions to this
2-EXPTIME-complete problem.
Second, the problem of model checking probabilistic systems against an LTL specification [7] is
to determine the probability that an LTL formula φ holds on the infinite paths generated by a given
Markov chain M, written Pr M (φ). More generally, for a Markov decision process M, the problem
is to determine the maximal (or minimal) probability that φ is satisfied, written supS Pr MS (φ),
where S ranges over strategies resolving the nondeterminism of M, and MS is the Markov chain
resulting from the application of S to M. The automata-theoretic approach again prescribes creating a product of the system and the automaton for φ. However, as opposed to non-probabilistic
model checking, the automaton A cannot be generally used if it is nondeterministic. Intuitively,
resolving nondeterminism of the automaton may depend on the yet unknown, probabilistically
given future.
Probabilistic model checking has two commonly discussed variants: The first variant is qualitative probabilistic model checking, where one is interested in whether the satisfaction probability is
0, 1, or neither of the two. While DRAs are typically used [44], algorithms using LDBAs are known
[15, 78]. The second variant is quantitative probabilistic model checking, where one is interested in
the exact satisfaction probability. Here, in contrast, LDBAs cannot be used in general. Recently it
has been shown that LDBAs can be used if they satisfy certain conditions [33, 72]. These conditions
are further discussed in Reference [34], which introduces good-for-MDPs automata. In particular,
the LDBAs of Reference [72] or of this work satisfy these conditions after slightly adapting the
product construction.
The key insight is that almost all words generated by MS are ν- and μ-stable once a “bottom
strongly connected component” is reached and one can resolve the LDBA nondeterminism upon
that occasion. For a detailed proof, see Reference [69]. The advantages of using LDBAs compared
to DRAs are the smaller size and that it is sufficient to decompose the product into “maximal endcomponents” only once. This improves the overall efficiency [73] compared to DRAs and often
also to generalised DRAs [13, 45].
10 EXPERIMENTAL EVALUATION
We provide experimental evidence that the uniform translation techniques derived from the Master Theorem are not obtained at the expense of poor performance in practice. We focus on the
representative case of deterministic Rabin automata and do not evaluate the translations to nondeterministic or limit-deterministic Büchi automata.
10.1 Method
Metric. We compare the size (number of states, number of Rabin pairs) of the automata produced by the different approaches. We do not include any resource consumption analysis, i.e.,
measurements of computation time or allocated memory. First, these values are very sensitive to
implementation. Second, and more importantly, if a product construction is used, they are also
typically negligible compared to the total resource consumption.
For each formula set {φ1,...,φn } and for each translation approach, we report the geometric
average n
n
i=1 ai of the sizes {a1,..., an } of the produced automata. Because of the identity
n
	n
i=1
ai
bi
=
n
n
i=1 ai
n
n
i=1 bi
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:41
Table 2. Parametrised Formulas Set
χ1,n = (... ((a1 U a2) U a3) ... U an+1) χ2,n = a1 U (a2 U (... (an U an+1) ... ))
χ3,n = G(a1 → a1 U (... (an ∧ an U an+1))) χ4,n = n
i=1 (Fai ∨ Gai+1)
χ5,n = n
i=1 FGai χ6,n = n
i=1 GFai
χ7,n = n
i=1 GFai
	
→ GFb χ8,n = n
i=1 GFai
	
↔ GFb
χ9,n = n
i=1 (GFai ∨ FGai+1) χ10,n = GF(a ↔ Xna)
χ11,n = n
i=0 FG((¬)
i
a ∨ Xi
b)
the geometric average of the size ratios {a1/b1,..., an/bn } for any two approaches with sizes
{a1,..., an } and {b1,...,bn } is given by the ratio of their geometric averages.
Input Formula Sets. We base the evaluation on two sets of formulas. The first set consists of
the well-known “Dwyer”-patterns, which collects 55 LTL formulas specifying common properties
[19]. The second set is obtained by instantiating the 11 parametrised formulas from Table 2. These
families are either taken from References [29, 59, 77] or are simple combinations of U, GF, and
FG formulas. The second set of formulas is useful to isolate and analyse strong and weak points
of the compared translations. We do not report on randomly generated formulas, because in our
experience formulas from real-world examples usually have a high degree of structure.
The formula sets are obtained by executing genltl9 with the corresponding parameters. Each
formula and its negation is then added to the set of formulas. We take the following steps to reduce
the influence of specific simplification rules and to remove (close to) duplicate entries: first, we
bring formulas into negation normal form; second, we apply a standard set of LTL simplification
rules [6, 24, 59, 68, 75] allowing us to turn off or at least restrict the LTL simplifier in the evaluation;
third, we normalise the atomic propositions and remove formulas that are equal modulo renaming
of atomic propositions.
As a consequence, the number of formulas we consider is less than the number of formulas
of the corresponding original publications. For example, Reference [19] lists 55 formulas, but we
remove six entries: e.g., only one of Ga, G¬a, and Fa is added to the formula set. Note that we
always evaluate the translation also on the negation of each formula. However, we do not remove
duplicates across the two formula sets.
Output ω-Automata Class. For the sake of simplicity in this article, we have only presented constructions for NBAs, LDBAs, and DRAs with acceptance conditions defined on states. However,
in practice acceptance conditions defined on transitions as well as generalised acceptance conditions, e.g., the generalised Büchi or Rabin condition, are preferred, because they yield automata
with fewer states. Thus, when possible, we select deterministic generalised Rabin automata with
acceptance conditions defined on transitions. We highlight this distinction by an s to denote stateacceptance (sDRA, sDGRA) and a t to denote transition-acceptance (tDRA, tDGRA).
Compared Translators. It is not the goal of this experimental evaluation to compare all known
LTL→tDGRA-translators. We compare our approach with three translators of different types: a
historic translator developed before the work on direct translations is begun; an actively maintained state-of-the-art translator that incorporates (most of) the advances made so far; and a direct
translator.
9genltl is a component of Spot [18] to generate LTL formulas from existing patterns. We use the version genltl (spot)
2.7.2.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
33:42 J. Esparza et al.
• ltl2dstar ([40], 0.5.4). This tool uses ltl2ba to translate LTL to NBAs and then implements a classic Safra-based determinisation procedure. Safra-based translations have been
the predominant state-of-the-art approaches before direct translations to deterministic automata have been investigated [45] and thus give a historic perspective. This configuration
yields only sDRA, a subclass of tDGRA, which cannot in general yield as small automata.
• ltl2tgba ([18], Spot 2.8.1). The tool has been enriched with a determinisation construction and employs a portfolio approach to construct small automata, in our configuration
tDGRA. It is to be noted that, in the meantime, constructions proposed here and the predecessor article [23] and related work such as Reference [59] have been adopted. Thus, one
can argue that it is the state-of-the-art portfolio translator.
• ltl2dgra (asymmetric, [48], Owl 20.06).9 This direct translation to DRAs and DGRAs has
been described in Reference [20] and revised and corrected in Reference [22]. It uses all
available optimisations, including the usual reduction rules for Rabin pairs, e.g., References
[22, 27]. This approach is the most similar to ours, but treats the least- and greatest-fixedpoint operators asymmetrically, focusing on the latter, and does not feature the double exponential upper bound.
Our own translator is:
• ltl2dgra (symmetric, Owl 20.06).9 The tool implements the DRA construction of this article that treats both types of the operators symmetrically. We use a straightforward modification of the described DRA construction that yields tDGRA. We refer the interested reader
to Reference [69] for an explicit description of this modification as well as for a list of applied optimisations. Most of these optimisations exploit the modular and semantic structure provided by the Master Theorem. Such optimisations are for example syntactic criteria
for skipping sets M and N of Theorem 35 to remove redundant components, specialised
intersection constructions for B2
M,N and C3
M,N , or better alternatives to the propositional
equivalence relation ∼.
We include neither ltl3dra [5] nor ltl3ba [6] in combination with ltl2dstar in the comparison, since we consider them subsumed by the actively developed translator ltl2tgba.
The complete experimental setup, including the formula sets, the translators, and the scripts
generating the tables, is available from Reference [70].
10.2 Results
The measured automata sizes for the LTL formulas are listed in Table 3. An entry n(m) indicates
that the automaton has n states andm Rabin pairs. We refer by φ to formulas from the “Dwyer” set,
and by χ to formulas from the parametrised set. We write φ instead of ¬φ. The rows of the table
are sorted by decreasing ratio between the largest and the smallest automaton. More precisely, we
compute max+1
min+1 for each row, where min refers to the number of states of the smallest automaton
and max refers to the number of states of the largest automaton. We then sort rows of the table
according to this value.
10.3 Discussion
The results indicate the following:
• The new constructions show a clear improvement over the historic state before the semantic
translations. The average ratios of ltl2dgra (asymmetric),ltl2dgra (symmetric), and
9The source-code of both tools is located in the repository of Reference [47].
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:43
Table 3. The Left Table Displays the Results for the “Dwyer” Set from Table 4 and The Right Table for the
Parametrised Formulas from Table 2
LTL
ltl2dstar (historic)
ltl2dgra (asymmetric)
ltl2dgra (symmetric, this article)
ltl2tgba (portfolio)
LTL
ltl2dstar (historic)
ltl2dgra (asymmetric)
ltl2dgra (symmetric, this article)
ltl2tgba (portfolio)
φ39 54,674 (11) 54 (8) 39 (4) 17 χ9,3 255,274 (13) 1 (6) 1 (6) 1 (8)
φ49 26,030 (9) 22 (3) 51 (8) 12 (2) χ8,4 12,278 (8) 1 (17) 15 (2) 1 (5)
φ44 14,157 (9) 20 (3) 31 (7) 10 (2) χ8,4 6,522 (7) 1 (5) 145 (2) 1 (10)
φ49 2,554 (11) 22 (8) 19 (3) 15 (2) χ9,2 795 (7) 1 (3) 1 (3) 1 (4)
φ44 1,193 (11) 18 (7) 14 (3) 9 (2) χ8,3 624 (6) 1 (10) 7 (2) 1 (4)
φ38 964 (6) 20 (2) 9 (3) 20 χ8,3 424 (5) 1 (4) 45 (2) 1 (8)
φ48 145 (5) 6 (2) 7 (3) 4 χ8,2 44 (3) 1 (3) 13 (2) 1 (6)
φ43 137 (5) 6 (2) 7 (3) 4 χ8,2 43 (4) 1 (5) 3 (2) 1 (3)
φ28 111 (4) 8 (2) 11 (3) 4 χ11,3 194 (9) 19 (4) 19 (4) 8 (4)
φ37 61 (4) 8 (4) 6 (2) 5 χ10,4 319 (6) 65 31 16
φ14 17 (3) 11 (3) 67 (4) 6 χ9,4 33 (4) 1 (7) 1 (4) 1 (4)
φ34 32 (2) 8 (6) 13 (2) 3 χ7,4 32 (5) 1 (5) 1 (5) 1 (5)
φ35 38 (3) 4 (3) 5 (2) 4 χ6,5 32 (5) 1 (5) 1 (5) 1 (5)
φ47 25 (2) 4 (2) 3 (2) 3 χ7,3 16 (4) 1 (4) 1 (4) 1 (4)
φ29 25 (3) 4 (2) 4 (2) 3 χ6,4 16 (4) 1 (4) 1 (4) 1 (4)
φ42 24 (2) 5 (2) 3 (2) 3 χ7,4 15 1 1 err
φ33 29 (2) 20 (5) 6 (2) 4 χ9,3 15 (3) 1 (5) 1 (3) 1 (3)
φ40 20 (2) 4 3 (2) 6 χ6,5 14 1 1 1
φ45 21 (2) 4 5 (2) 6 χ7,3 11 1 1 err
φ39 9 29 (6) 10 (2) 6 χ6,4 11 1 1 1
φ40 14 (3) 3 (2) 5 4 χ6,3 8 1 1 1
φ23 12 (3) 4 (2) 3 (3) 3 χ7,2 8 (3) 1 (3) 1 (3) 1 (3)
φ45 15 (3) 5 (4) 5 4 χ6,3 8 (3) 1 (3) 1 (3) 1 (3)
φ13 19 (3) 22 (2) 7 (2) 7 χ7,2 7 1 1 err
φ36 16 (2) 6 6 6 χ9,2 7 (2) 1 (3) 1 (2) 1 (2)
1
n Σ 1,027.54 6.50 6.35 4.49 1
n Σ 4,265.75 8.44 11.56 5.92
σ 6,204.59 7.27 9.22 2.94 σ 31,421.86 13.48 23.49 8.19
√n Π 10.21 4.75 4.47 3.91 √n Π 19.72 3.35 4.14 3.01
med. 5.0 4.0 4.0 4.0 med. 13.0 2.5 4.0 3.0
The tables list number of states, followed by the number of Rabin pairs (if larger than 1). The results for the remaining 73
and 41 formulas, respectively, are located in Appendix B. We write 1
n Σ, σ ,
√n Π, and med., for the average, the standard
deviation, the geometric average, and the median, respectively, for the number of states. We denote by err an error thrown
by the tool.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
33:44 J. Esparza et al.
Table 4. Formulas Referenced by Table 3
φ13 G(a ∨ Gb ∨ (b ∧ c) U (b ∨ (b ∧ c) U (b ∨ (b ∧ c) U (b ∨ (b ∧ c) U (b ∨ c U b)))))
φ14 G(a ∨ (b ∧ c) U (c ∨ (b ∧ c) U (c ∨ (b ∧ c) U (c ∨ (b ∧ c) U (c ∨ Gb ∨ b W c)))))
φ23 G(a ∨ b ∨ Gb ∨ (c ∨ b U (b ∧ d)) U b)
φ28 G(a ∨ Gb ∨ c U (b ∨ (c ∧ d ∧ X(c U e))))
φ29 G(a ∨ b W (c ∨ (b ∧ d ∧ X(b U e))))
φ33 G(a ∨ Gb ∨ (b ∨ c ∨ X(b R (b ∨ d))) U (b ∨ e))
φ34 G(a ∨ G(b ∨ XGc) ∨ (b ∨ d ∨ X(d R (c ∨ d))) U (d ∨ e))
φ35 G(a ∨ XGb ∨ XF(b ∧ Fc))
φ36 Ga ∨ (b ∨ X(a R c) ∨ X(a U (c ∧ Fd))) U a
φ37 G(a ∨ G(b ∨ XGc ∨ XF(c ∧ Fd)))
φ38 G(a ∨ Gb ∨ (c ∨ X(b R d) ∨ X(b U (d ∧ Fe))) U b)
φ39 G(a ∨ (b ∨ X(c R d) ∨ X(c U (d ∧ Fe))) U (c ∨ G(b ∨ X(c R d) ∨ X(c U (d ∧ Fe)))))
φ40 G(a ∨ F(b ∧ XFc))
φ42 G(a ∨ G(b ∨ (c ∧ XFd)))
φ43 G(a ∨ Gb ∨ (c ∨ b U (b ∧ d ∧ X(b U e))) Ub)
φ44 G(a ∨ (b ∨ c U (c ∧ d ∧ X(c U e))) U (c ∨ G(b ∨ (d ∧ XFe))))
φ45 G(a ∨ F(b ∧ c ∧ X(c U d)))
φ47 G(a ∨ G(b ∨ (c ∧ d ∧ X(d U e))))
φ48 G(a ∨ Gb ∨ (c ∨ b U (b ∧ d ∧ e ∧ X((b ∧ e) U f ))) U b)
φ49 G(a ∨ (b ∨ c U (c ∧ d ∧ e ∧ X((c ∧ e) U f ))) U (c ∨ G(b ∨ (d ∧ e ∧ X(e U f )))))
ltl2tgba to ltl2dstar are 46%, 43%, and 38% for the “Dwyer” set, and 17%, 21%, and 15%
for the parametrised set.
• Our uniform approach is at least as good as the DRA-specific asymmetric approach in ∼85%
of the cases, with average ratio being 94% and 124%.
• Our approach is competitive with the “current best of” portfolio with average ratio of 114%
and 138%. This is encouraging, since the amount of compositional optimisation in our implementation is still quite restricted and offers further possibilities for improvement.
A closer look at the results reveals that most formulas are not too complicated, and all approaches yield small automata of similar size. More concretely, in the “Dwyer” set, we only measured major differences for 25 formulas, and even less for the parametrised set. Major differences
to the “historic” Safra-based approach seem to appear for formulas with more complex infinitary
behaviour caused by deep nesting of U and R, e.g., φ39, φ44, and φ49, and Boolean combinations of
FGa and GFb, e.g., χ8,n and χ9,n.
The collected data demonstrate that on this selection of formulas, coming from a variety of
sources, the simplicity and generality of our new constructions does not lead to a systematic
penalty in practice. Further, we believe that a portfolio approach as implemented by ltl2tgba
selecting different translation strategies depending on the input has advantages and could close
the size gap.
11 CONCLUDING REMARKS
The Master Theorem we presented provides a decomposition of LTL formulas from which one
can derive LTL translations in a straightforward way. This result builds upon work from a
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:45
series of publications [22, 45, 46, 72]. In particular, the idea that a word eventually stabilises with
respect to a formula and the idea of inductively checking a complex LTL expression by delegating to auxiliary automata are already outlined there. Other translations such as the translation to LDBAs of References [38, 39] or the obligation sets of References [50, 51] follow similar
ideas.
The Master Theorem is made possible by the addition of the operators W and M to the core LTL
syntax, which makes it complete in the sense that for every modal operator there exists a greatestfixed-point and a least-fixed-point variant. The essential novelty is that the mappings ·[·]μ and
·[·]ν exploit the existence of these variants and that their application to any formula φ yields a
simpler formula, but not in the sense one might expect. In particular, φ[N]μ might be stronger than
φ. For example, the information that the formula a W b does not hold infinitely often reduces to
a check of the stronger formula a Ub = (a W b)[∅]μ . However, this lends the Master Theorem its
practical benefit: The formulas φ[M]ν and φ[N]μ are simpler to translate. This completeness of the
syntax is the basis of the symmetric treatment of modal operators, where we deal with greatestand least-fixed-point operators in a dual way. Such a symmetric treatment of greatest- and leastfixed-point operators is present in References [45, 46], but could be applied essentially only to
F and G operators. Hence, the result presented here successfully finishes the journey embarked
upon in Reference [45]: A single theorem provides an arguably elegant (unified, symmetric, syntaxindependent, not overly complex) and efficient (asymptotically optimal, practically relevant, direct)
translation of LTL to ω-automata of your choice. Moreover, based on the Master Theorem one can
derive an efficient, syntactic, and exponential normalisation procedure for LTL [71] that limits the
nesting of greatest-fixed-point and least-fixed-pointer operators yielding a normal form described
in Reference [12].
The practical relevance of these constructions and their precursors has been demonstrated by
tools, too, as the reduced size of the automata plays the crucial role in speeding up LTL verification
and synthesis. The tool Rabinizer [48] implements all these constructions. Its inception [27, 46]
with the generalised Rabin condition [45] and integration [13, 41] into the probabilistic model
checker PRISM [44] has led to the development of the standard HOA format [4] for ω-automata,
covering less standard conditions, and to the extension of PRISM allowing for external LTL-toHOA translators. Support for such constructions is then accessible in the reusable library Owl [47];
it distils the key functionalities of Rabinizer, which is a tool for end-users of LTL, into reusable
modules and adds further support for developers. Further, MoChiBa [73] has extended PRISM to use
also LDBAs. Besides, Strix [55] uses the translations to deterministic automata for synthesis of
reactive systems from LTL specifications. In particular, to obtain a deterministic parity automaton,
it makes use of a compositional construction that uses the simpler LTL fragments translations
whenever possible, and only falling back to the more general procedure [21] for small parts of the
formula.
Open Questions and Future Work. We have focused here on three common classes of ωautomata, namely, NBAs, LDBAs, and DRAs, and did not investigate other classes. It remains
open whether we can obtain a direct translation to deterministic parity automata that is better
than chaining existing constructions. Note that both Safra-based [53, 62, 67] as well as non-Safrabased [49, 52] techniques involve a “linearisation” of the acceptance condition using appearance
records [32]. It is not clear whether LTL induces any special structure on them that could be
exploited.
Finally, the presented constructions have a highly regular product structure, compared to Safra’s
determinisation, allowing for a symbolic implementation.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
33:46 J. Esparza et al.
APPENDICES
A OMITTED PROOFS
A.1 Proof of Lemma 6
We need an auxiliary lemma.
Lemma 58. Let f be a function on formulas such that f (tt) = tt, f (ff) = ff, f (χ1 ∧ χ2) = f (χ1) ∧
f (χ2), and f (χ1 ∨ χ2) = f (χ1) ∨ f (χ2) for all formulas χ1 and χ2. For every formula φ and every set
of formulas I:
I |=p f (φ) ⇐⇒ {χ ∈ sf(φ) : I |=p f (χ )} |=p φ.
Proof. We proceed by a structural induction on φ. We only consider two representative cases.
• Case φ = Xψ:
I |=p f (Xψ ) ⇐⇒ Xψ ∈ {χ ∈ sf(Xψ ) : I |=p f (χ )}
⇐⇒ {χ ∈ sf(Xψ ) : I |=p f (χ )} |=p Xψ
• Case φ = ψ1 ∧ψ2:
I |=p f (ψ1 ∧ψ2)
⇐⇒ I |=p f (ψ1) ∧I |=p f (ψ2)
⇐⇒ {χ ∈ sf(ψ1) : I |=p f (χ )} |=p ψ1
∧ {χ ∈ sf(ψ2) : I |=p f (χ )} |=p ψ2 (induction hypothesis)
⇐⇒ {χ ∈ sf(ψ1 ∧ψ2) : I |=p f (χ )} |=p ψ1 ∧ψ2
Lemma 6. Let f be a function on formulas such that f (tt) = tt, f (ff) = ff, and f (χ1 ∧ χ2) =
f (χ1) ∧ f (χ2), f (χ1 ∨ χ2) = f (χ1) ∨ f (χ2) for all formulas χ1 and χ2. For every pair of formulas
φ and ψ, if φ ∼ ψ, then f (φ) ∼ f (ψ ).
Proof. By symmetry it suffices to show I |=p f (φ) ⇒I|=p f (ψ ) for every assignment I. We
derive this as follows:
I |=p f (φ) ⇐⇒ {χ ∈ sf(φ) : I |=p f (χ )} |=p φ (Lemma 58)
⇐⇒ {χ ∈ sf(φ) : I |=p f (χ )} |=p ψ (φ ∼ ψ )
⇒ {χ ∈ sf(φ) ∩ sf(ψ ) : I |=p f (χ )} |=p ψ (restriction to sf(ψ ))
⇒ {χ ∈ sf(ψ ) : I |=p f (χ )} |=p ψ (monotonicity of |=p )
⇐⇒ I |=p f (ψ ) (Lemma 58)
A.2 Proof of Lemma 30
Lemma 30. Let φ be a formula and let w be a word. Let M ⊆ μ(φ) be a set of formulas. We have:
(1) If F φ
w ⊆ M and w |= φ, then w |= φ[M]ν .
(2) If M ⊆ GF φ
w and w |= φ[M]ν , then w |= φ.
In particular:
(3) If F φ
w = M = GF φ
w , then w |= φ ⇐⇒ w |= φ[M]ν .
Let N ⊆ ν (φ) be a set of formulas. We have:
(4) If F G φ
w ⊆ N and w |= φ, then w |= φ[N]μ .
(5) If N ⊆ Gφ
w and w |= φ[N]μ , then w |= φ.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
A Unified Translation of Linear Temporal Logic to ω-Automata 33:47
In particular:
(6) If F G φ
w = N = Gφ
w , then w |= φ ⇐⇒ w |= φ[N]μ .
Proof. We will now continue with the proof of the remaining parts (4) and (5).
(4) Assume F G φ
w ⊆ N. Then F G φ
wi ⊆ N for all i. We prove the following stronger statement
via structural induction on φ:
∀i. ( (wi |= φ) ⇒ (wi |= φ[N]μ ) ).
• Case φ = ψ1 Wψ2: Let i ≥ 0 arbitrary and assume wi |= φ. If φ ∈ N, then φ[N]μ = tt and so
wi |= φ[N]μ trivially holds. Assume now φ  N. Since F G φ
wi ⊆ N, we have wi |= FGφ and
so in particular wi |= Gψ1. We prove wi |= (ψ1 Wψ2)[N]μ :
wi |= ψ1 Wψ2
⇐⇒ wi |= ψ1 Uψ2 (wi |= Gψ1)
⇐⇒ ∃j.wi+j |= ψ2 ∧ ∀k < j.wi+k |= ψ1
⇒ ∃j.wi+j |= ψ2[N]μ ∧ ∀k < j.wi+k |= ψ1[N]μ (induction hypothesis)
⇐⇒ wi |= (ψ1[N]μ ) U (ψ2[N]μ )
⇐⇒ wi |= (ψ1 Wψ2)[N]μ (φ  N, Definition 28)
• Case φ = ψ1 ∨ψ2: Let i ≥ 0 arbitrary and assume wi |= ψ1 ∨ψ2. We have:
wi |= ψ1 ∨ψ2
⇐⇒ wi |= ψ1 ∨ wi |= ψ2
⇒ wi |= ψ1[N]μ ∨ wi |= ψ2[N]μ (induction hypothesis)
⇐⇒ wi |= (ψ1 ∨ψ2)[N]μ (Definition 28)
(5) Assume N ⊆ Gφ
w . Then N ⊆ Gφ
wi for all i. We prove the following stronger statement via
structural induction on φ:
∀i. ( (wi |= φ[N]μ ) ⇒ (wi |= φ) ).
• Case φ = ψ1 Wψ2: If φ ∈ N, then, since N ⊆ Gφ
w , we have wi |= Gφ and so wi |= φ. Assume
now that φ  N and wi |= (ψ1 Wψ2)[N]μ for an arbitrary fixed i. We prove wi |= ψ1 Wψ2:
wi |= (ψ1 Wψ2)[N]μ
⇐⇒ wi |= (ψ1[N]μ ) U (ψ2[N]μ ) (φ  N, Definition 28)
⇐⇒ ∃j.wi+j |= ψ2[N]μ ∧ ∀k < j.wi+k |= ψ1[N]μ
⇒ ∃j.wi+j |= ψ2 ∧ ∀k < j.wi+k |= ψ1 (induction hypothesis)
⇐⇒ wi |= ψ1 Uψ2
⇒ wi |= ψ1 Wψ2
• Case φ = ψ1 ∨ψ2: We derive in a straightforward manner for an arbitrary and fixed i:
wi |= (ψ1 ∨ψ2)[N]μ
⇐⇒ wi |= ψ1[N]μ ∨ wi |= ψ2[N]μ (Definition 28)
⇒ wi |= ψ1 ∨ wi |= ψ2 (induction hypothesis)
⇐⇒ wi |= ψ1 ∨ψ2
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.     
33:48 J. Esparza et al.
A.3 Proof of Proposition 13
Proposition 13. Let φ ∈ μLT L.
• The following DBA over the alphabet 2Ap recognises L(φ):
Bφ
μ = (Reach(φ)/∼, aft∼,[φ]∼, Inf({[tt]∼})).
• The following DCA over the alphabet 2Ap recognises L(φ):
Cφ
μ = (Reach(φ)/∼, aft∼,[φ]∼, Fin({[tt]∼})).
• The following DBA over the alphabet 2Ap recognises L(GFφ):
Bφ
GFμ = (Reach(Fφ)/∼, aftFφ
∼ ,[Fφ]∼, Inf({[tt]∼}))
aftFφ
∼ ([ψ]∼, σ ) =

[Fφ]∼ if ψ ∼ tt
[aft(ψ, σ )]∼ otherwise.
Let φ ∈ νLT L.
• The following DCA over the alphabet 2Ap recognises L(φ):
Cφ
ν = (Reach(φ)/∼, aft∼,[φ]∼, Fin({[ff]∼})).
• The following DBA over the alphabet 2Ap recognises L(φ):
Bφ
ν = (Reach(φ)/∼, aft∼,[φ]∼, Inf({[ff]∼})).
• The following DCA over the alphabet 2Ap recognises L(FGφ):
Cφ
FGν = (Reach(Gφ)/∼, aftGφ
∼ ,[Gφ]∼, Fin({[ff]∼)})
aftGφ
∼ ([ψ]∼, σ ) =

[Gφ]∼ if ψ ∼ ff
[aft(ψ, σ )]∼ otherwise.
Proof. Let φ be a formula of μLT L. We want to prove (1) L(φ) = L(Bφ
μ ), (2) L(φ) = L(Cφ
μ )
and (3) L(GFφ) = L(Bφ
GFμ ). Let w now be an arbitrary word.
(⇒1) Assume w |= φ. Using Lemma 12, we can find an index i such that aft(φ,w0i ) ∼ tt. Hence,
the run r with r[i] = [aft(φ,w0i )]∼ starting in the initial state [φ]∼ will reach [tt]∼ after reading
w0i . After reaching [tt]∼ the run r loops in that state and thus r is accepting and the word w is in
L(Bφ
μ ).
(⇐1) Assumew is accepted by Bφ
μ . Then there exists an accepting run r forw and this run visits
the state [tt]∼ infinitely often. Let i be the index such that [tt]∼ = aft∼([φ]∼,w0i ) = [aft(φ,w0i )]∼.
Thus, applying Lemma 12 to aft(φ,w0i ) ∼ tt yields w |= φ and we are done.
(2) Observe that Bφ
μ and Cφ
μ have exactly the same structure apart from the acceptance condition. They are both weak and deterministic and thus all words accepted by Bφ
μ are also accepted
by Cφ
μ and vice versa. Thus, L(Bφ
μ ) = L(Cφ
μ ) and (2) is an intermediate consequence of (1).
(⇒3) Assume w |= GFφ. This is equivalent to ∀i.wi |= Fφ. Then, we obtain by Lemma 12:
∀i. ∃j. aft(Fφ,wij) ∼ tt. Since Bφ
GFμ is deterministic, there exists exactly one run r for the word w.
We now show that this run r is accepting. The run starts in r[0] = [Fφ]∼ and let j > i be the smallest index for i = 0, such that aft(Fφ,w0j) ∼ tt. Observe that this is the first point where aft∼ and
aftFφ
∼ diverge and the later one resets to [Fφ]∼. Thus, after visiting the accepting state [tt]∼ the run r
returns to the initial state [Fφ]∼ and we can apply the same argument starting at r[j + 1] = [Fφ]∼.
Repeating this argument again and again, we conclude that the run r is accepting and thus the
word w is contained in L(Bφ
GFμ ).
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:49
(⇐3) Assume w is accepted by Bφ
GFμ . Then there exists an accepting run r for w and this run
visits the state [tt]∼ infinitely often. Provided we have shown ∀i. ∃j ≥ i. ∃k. aft(Fφ,wjk ) ∼ tt, we
apply Lemma 12 to obtain ∀i. ∃j ≥ i.wj |= Fφ, which is equivalent to w |= GFφ, which we wanted
to show. We now focus on the remaining goal ∀i. ∃j ≥ i. ∃k. aft(Fφ,wjk ) ∼ tt: Let i be an arbitrary
index. Since r is an accepting run, there exist infinitely many j’s, such that r[j − 1] = [tt]∼ and
r[j] = [Fφ]∼. Let j be such an index with j > i. Since r is an accepting run, there also exists some k >
j such thatr[k] = [tt]∼ and the run r has not visited [tt]∼ in-between. Thus, we follow aft(φ,wjk ) ∼
tt and fill the remaining gap.
We now move on to the second part concerned with νLT L. Let φ be a formula of νLT L. We want
to prove (4) L(φ) = L(Cφ
ν ), (5) L(φ) = L(Bφ
ν ) and (6) L(FGφ) = L(Cφ
FGν ). The proof of (4) and
(5) is analogous to the proof of (1) and (2) and thus, we are skipping it. Observe that Cφ
FGν mirrors
the structure of Bφ
GFμ and the proof of (6) is also analogous to the one of (3).
A.4 Proofs of Lemma 51, Lemma 52, and Proposition 53
We first show how to obtain a satisfying propositional assignment for φ from a satisfying assignment for aft(φ, σ ). Second, we establish Lemma 51 for a single letter σ in Lemma 59 and then
generalise it to arbitrary finite words.
Lemma 59. Let Φ be a set of formulas, let σ be a letter, and let I be a propositional assignment.
Then:
∀ψ ∈ Φ. I |=p aft(ψ, σ ) ⇐⇒ ∃Ψ ⊆ I. Ψ ∈ aft∨(Φ, σ ).
Proof. Before we begin with the proof, we make the following technical observation for ⊗min:
Let X and the elements of X be finite sets. Then for every set A and X, we have:
A ∈

min
X ∧ X ∈X⇒∃B ∈ X. B ⊆ A.
(⇐) Assume there exists a subset Ψ ⊆ I of the propositional assignment I with Ψ ∈ aft∨(Φ, σ ).
Further, letψ ∈ Φ be an arbitrary element of the set Φ. We unfold the definition of aft∨ and see that
by the previous observation for ⊗min that there exists some Ψ
 ⊆ Ψ with Ψ
 ∈ dnf(aft(ψ, σ )) that
contributed to Ψ for ψ ∈ Φ. Since Ψ
 is an element of the DNF, we have Ψ
 |=p aft(ψ, σ ) (Proposition 47) and due to the monotonicity of |=p , we also have I |=p aft(ψ, σ ).
(⇒) We prove this direction by an induction on the size of Φ.
• Base |Φ| = 0. Then the right-hand side evaluates to aft∨(Φ, σ ) = {∅}. Because the empty set
is always a subset, this side also holds for all I.
• Step |Φ| = n + 1. Let Φ
 be a set of size n with Φ = Φ
  {ψ 

}. Assume now that I |=p
aft(ψ, σ ) for all formulas ψ ∈ Φ. First, this also holds for the subset Φ
 and applying the
induction hypothesis to Φ
 yields ∃Ψ
 ⊆ I. Ψ
 ∈ aft∨(Φ

, σ ). Let now Ψ
 be such a set
of formulas. Second, with Proposition 47 applied to ψ 

, we obtain a set Ψ

 ⊆ I with
Ψ

 ∈ dnf(aft(ψ 

, σ )). Taking these two steps together, we have Ψ
 ∪ Ψ

 ∈ (aft∨(Φ

, σ )) ⊗
(aft∨({ψ 

}, σ )). Hence, there exists some subset Ψ ⊆ Ψ
 ∪ Ψ

 that is contained in
(aft∨(Φ

, σ )) ⊗min (aft∨({ψ 

}, σ )) = aft∨(Φ

, σ ) and we are done.
Lemma 51. Let φ be a formula, let w be a finite word, and let I be a propositional assignment.
Then:
I |=p aft(φ,w) ⇐⇒ ∃Ψ ⊆ I. Ψ ∈ aft∨(φ,w).
Proof. We prove the statement by induction on the length of w.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.  
33:50 J. Esparza et al.
Fig. 14. Induction step proof structure of Lemma 51.
• Base w = ϵ. Simplifying the statement, we see that we need to prove: I |=p φ ⇐⇒ ∃Ψ ⊆
I. Ψ ∈ dnf(φ). This immediately follows from Proposition 47.
• Step w = w

σ. We prove both directions separately and the proofs follow the structure
sketched in Figure 14. For both directions, we define the propositional assignment J =
{ψ : I |=p aft(ψ, σ )}.
(⇒) Assume I |=p aft(φ,w) holds. Applying Lemma 58 gives us J |=p aft(φ,w

) and with
the induction hypothesis, we obtain a set Φ such that Φ ⊆ J and Φ ∈ aft∨(φ,w

). By
definition of J, we have I |=p aft(ψ, σ ) for all ψ ∈ J and thus also all ψ ∈ Φ. Hence,
we can apply Lemma 59 and have ∃Ψ ⊆ I. Ψ ∈ aft∨(Φ, σ ). Since Φ ∈ aft∨(φ,w

), we have
aft∨(Φ, σ ) ⊆ aft∨(φ,w

σ ) and are done.
(⇐) Let Ψ and I be sets such that Ψ ⊆ I and Ψ ∈ aft∨(φ,w). Further let Φ be a set such
that Φ ∈ aft∨(φ,w

) and Ψ ∈ aft∨(Φ, σ ). Assuming we proved Φ ⊆ J, we can simply apply
the induction hypothesis and Lemma 58 to obtain at I |=p aft(φ,w). Thus, it remains to
show: Φ ⊆ J. Letψ an arbitrary formula from the set Φ. To show the inclusion, we need to
establish I |=p aft(ψ, σ ), but this exactly follows from Lemma 59 and we are done.
Lemma 52. Let φ be a formula, let w be a finite word, let M ⊆ μ(φ), and let I ⊆ sf(φ). Then:
(1) aft∨(φ,w) ⊆ 2sf(φ)
,
(2) ∅ ∈ aft∨(φ,w) ⇐⇒ aft(φ,w) ∼ tt,
(3) aft∨(φ,w) = ∅ ⇐⇒ aft(φ,w) ∼ ff,
(4) L(aft(φ,w)) = {


ψ ∈Ψ L(ψ ) : Ψ ∈ aft∨(φ,w)},
(5) Let Ψ[M]ν := {ψ[M]ν : ψ ∈ Ψ}. Then:
I |=p aft(φ,w)[M]ν ⇐⇒ ∃Ψ. Ψ[M]ν ⊆I∧ Ψ ∈ aft∨(φ,w).
Proof. (1) This holds intuitively, because all involved steps either construct singleton sets from
subformulas or combine existing sets without adding new literals or modal operators. Formally
this is shown by an induction on the length of w and a structural induction on φ.
(2) We obtain this by two simple steps:
aft(φ,w) ∼ tt ⇐⇒ ∅ |=p aft(φ,w)
⇐⇒ ∅ ∈ aft∨(φ,w) (Lemma 51).
(3) Let U be the universe, meaning it contains all formulas, and thus U sets every propositional
variable to tt. Then:
aft(φ,w) ∼ ff ⇐⇒ U |=p aft(φ,w) (|=p is monotone)
⇐⇒ ∀Ψ ⊆ U. Ψ  aft∨(φ,w) (Lemma 51)
⇐⇒ ∀Ψ. Ψ  aft∨(φ,w) (every set of formulas is a subset of U)
⇐⇒ aft∨(φ,w) = ∅.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.    
A Unified Translation of Linear Temporal Logic to ω-Automata 33:51
(4) Letw
 be an arbitrary word and let I = {ψ : w
 |= ψ } be a propositional assignment. We then
show (4) by proving the following equivalence:
w
 ∈ L(aft(φ,w)) ⇐⇒ w
 |= aft(φ,w) (Lemma 9)
⇐⇒ I |=p aft(φ,w) (Lemma 4)
⇐⇒ ∃Ψ. Ψ ∈ aft∨(φ,w) ∧ Ψ ⊆ I (Lemma 51)
⇐⇒ ∃Ψ. Ψ ∈ aft∨(φ,w) ∧ ∀ψ ∈ Ψ.w
 |= ψ
⇐⇒ w
 ∈  


ψ ∈Ψ L(ψ ) : Ψ ∈ aft∨(φ,w)

.
(5) We base our proof on following claim: Let χ be a formula. Then:
I |=p χ[M]ν ⇐⇒ {ψ : ψ[M]ν ∈ I} |=p χ .
Proof of the claim: We proceed by a structural induction on χ. As before we only consider a subset
of the cases: one representative of the “interesting” cases and two of the “straightforward” cases:
• Case χ = χ1 U χ2: We proceed by a further case distinction. Assume χ1 U χ2  M. In this
case, we have on the left side of the equivalence: I |=p χ[M]ν = ff. For the right side observe
that by the assumption I ⊆ sf(φ) of the lemma the set I does not contain ff. Thus, χ  {ψ :
ψ[M]ν ∈ I} and we follow {ψ : ψ[M]ν ∈ I} |=p χ. Let us now assume χ1 U χ2 ∈ M. We
then derive:
I |=p χ[M]ν
⇐⇒ I |=p (χ1[M]ν ) W (χ2[M]ν )
⇐⇒ (χ1[M]ν ) W (χ2[M]ν ) ∈ I
⇐⇒ χ1 U χ2 ∈ {ψ : ψ[M]ν ∈ I}
⇐⇒ {ψ : ψ[M]ν ∈ I} |=p χ .
• Case χ = χ1 W χ2:
I |=p χ[M]ν
⇐⇒ I |=p (χ1[M]ν ) W (χ2[M]ν )
⇐⇒ (χ1[M]ν ) W (χ2[M]ν ) ∈ I
⇐⇒ χ1 W χ2 ∈ {ψ : ψ[M]ν ∈ I}
⇐⇒ {ψ : ψ[M]ν ∈ I} |=p χ .
• Case χ = χ1 ∧ χ2:
I |=p χ[M]ν
⇐⇒ I |=p χ1[M]ν ∧ χ2[M]ν
⇐⇒ {ψ : ψ[M]ν ∈ I} |=p χ1 ∧ {ψ : ψ[M]ν ∈ I} |=p χ2 (induction hypothesis)
⇐⇒ {ψ : ψ[M]ν ∈ I} |=p χ .
(⇒5) Assume I |=p aft(φ,w)[M]ν . Hence, the assignment J = {ψ : ψ[M]ν ∈ I} is a satisfying
assignment of aft(φ,w), i.e., J |=p aft(φ,w), which follows from the previous claim. By Lemma 51
there exists some Ψ such that Ψ ⊆ J and Ψ ∈ aft∨(φ,w). Thus, Ψ[M]ν ⊆ I and we are done.
(⇐5) Assume Ψ[M]ν ⊆ I and Ψ ∈ aft∨(φ,w). Further, let J = {ψ : ψ[M]ν ∈ I}. Then Ψ ⊆ J
and we can apply the other direction of Lemma 51 to get J |=p aft(φ,w). Applying the claim, we
obtain I |=p aft(φ,w)[M]ν and we are done.
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.    
33:52 J. Esparza et al.
Proposition 53. Let φ ∈ μLT L.
• The following NBA over the alphabet 2Ap recognises L(φ):
Bφ
μ = ( Reach∨(φ), aft∨, dnf(φ), Inf({∅}) ).
• The following NBA over the alphabet 2Ap recognises L(GFφ):
Bφ
GFμ = 
Reach∨(Fφ), aftFφ
∨ , {{Fφ}}, Inf({∅})
	
aftFφ
∨ (Ψ, σ ) =

{{Fφ}} if Ψ = ∅
aft∨(Ψ, σ ) otherwise.
Let φ ∈ νLT L.
• The following NBA over the alphabet 2Ap recognises L(φ):
Bφ
ν = ( Reach∨(φ), aft∨, dnf(φ), Inf(Reach∨(φ)) ).
• The following NBA over the alphabet 2Ap recognises L(FGφ):
Bφ
FGν = 
Reach∨(Gφ) ∪ {{FGφ}}, aftGφ
∨ , {{FGφ}}, Inf(Reach∨(Gφ)) 	
aftGφ
∨ (Ψ, σ ) =

{{FGφ}, {Gφ}} if Ψ = {FGφ}
aft∨(Ψ, σ ) otherwise.
Proof. Let φ be a formula of μLT L. We want to prove (1) L(φ) = L(Bφ
μ ) and (2) L(GFφ) =
L(Bφ
GFμ ). Let w now be an arbitrary word.
(⇒1) Assume w |= φ. Using Lemma 12 with ∼, we have aft(φ,w0i ) ∼ tt for some i and also
∅ ∈ aft∨(φ,w0i ) using Lemma 52. Hence, there exists some path from the initial states to ∅ labeled
w0i . Letr be the run that follows this path and loops in state ∅ afterwards. Thus,r is accepting and
the word w is accepted by Bφ
μ .
(⇐1) Assumew is accepted by Bφ
μ . Then there exists an accepting run r forw and this run visits
the state ∅ infinitely often. Let i be the index such that ∅ ∈ aft∨(φ,w0i ). Applying Lemma 52, we
have aft(φ,w0i ) ∼ tt and with Lemma 12, we also have w |= φ.
(⇒2) Assume w |= GFφ. This is equivalent to ∀i.wi |= Fφ and to ∀i.∃j. aft(Fφ,wij) ∼ tt according to Lemma 12. By applying Lemma 51, we obtain ∀i.∃j. ∅ ∈ aft∨(Fφ,wij). From this, we now
construct an accepting run r piecewise. We start by setting r[0] = {Fφ}. Let j > i be the smallest
index for i = 0, such that ∅ ∈ aft∨(Fφ,w0j). Then the run follows this path to reach ∅ for the segmentw0j and thusr[j − 1] = ∅. After visiting the accepting state the run returns to the initial state
and we repeat this from r[j] = {Fφ}. Applying this construction again and again, we obtain an
accepting run and thus the word w is accepted by Bφ
GFμ .
(⇐2) Assume w is accepted by Bφ
GFμ . Then there exists an accepting run r for w and this run
visits the state ∅ infinitely often. Provided we have shown ∀i.∃j ≥ i.∃k. aft(Fφ,wjk ) ∼ tt, we apply Lemma 12 to obtain ∀i. ∃j ≥ i.wj |= Fφ, which is equivalent to w |= GFφ, which we wanted
to show. We now focus on the remaining goal ∀i.∃j ≥ i.∃k. aft(Fφ,wjk ) ∼ tt: Let i be an arbitrary index. Since r is an accepting run, there exist infinitely many j’s, such that r[j − 1] = ∅ and
r[j] = {Fφ}. Let j be such an index with j > i. Since r is an accepting run, there also exists some k,
such that r[k] = ∅ and the run r has not visited ∅ in-between j and k. Thus, ∅ ∈ aft∨(φ,wjk ) and
with Lemma 52, we fill the remaining gap.
We now move on to the second part concerned with νLT L. Let φ be a formula of νLT L. We
want to prove (3) L(φ) = L(Bφ
ν ) and (4) L(FGφ) = L(Bφ
FGν ). Let w now be an arbitrary word.
The proof of (3) is analogous to the proof of (1) and we are skipping it. Observe that Bφ
FGν adds to
Journal of the ACM, Vol. 67, No. 6, Article 33. Publication date: October 2020.
A Unified Translation of Linear Temporal Logic to ω-Automata 33:53
the structure of BGφ
ν just one additional, non-accepting state with a self-loop and a transition to
{Gφ}.
(⇒4) Assumew |= FGφ. Then there exists some i such thatwi |= Gφ. An accepting run just stays
in FGφ up to i and then moves to Gφ. From this point on there exists a continuation according to
(3) that is accepting.
(⇐4) Assume w is accepted by Bφ
FGν . Let r be the corresponding accepting run. r eventually
leaves at some point i the state FGφ and moves to {Gφ}. By (3), we know that then wi |= Gφ and
hence w |= FGφ.