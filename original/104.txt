Personal drones are becoming more mainstream and are used for a variety of tasks, such as delivery and photography. The
exposed blades in conventional drones raise serious safety concerns. To address this, commercial drones have been moving
towards a safe-to-touch design or have increased safety by adding propeller guards. The affordances of safe-to-touch drones
enable new types of touch-based human-drone interaction. Various applications have been explored, such as augmented
sports and haptic feedback in virtual reality; however, it is unclear if individuals feel comfortable using direct touch and
manipulation when interacting with safe-to-touch drones. A previous elicitation study showed how users naturally interact
with drones. We replicated this study with an unsafe and a safe-to-touch drone, to find out if participants will instinctively use
touch as a means of interacting with the safe-to-touch drone. We found that 58% of the participants used touch, and across all
tasks 39% of interactions were touch-based. The proposed touch interactions were in agreement for 67% of the tasks, and
users reported that interacting with the safe-to-touch drone was significantly less mentally demanding than the unsafe drone.
CCS Concepts: •Human-centered computing →Empirical studies in interaction design;
Additional Key Words and Phrases: Drone, UAV, quadcopter, human-drone interaction, touch interaction, elicitation study
1 INTRODUCTION
Personal drones are used for many applications, such as photography [18], video recording [1], search and rescue
[6], and package delivery [2, 20]. As drones become more popular, designing reliable and safe drones is critical.
To mitigate failure and increase reliability, researchers have designed drones that can maintain flight when some
propellers are lost [12, 13]. However, drone failure is not the only threat; the exposed propellers in conventional
drones also raise safety concerns, as coming into contact with rotating blades may result in serious injuries. To
address this, some drone manufacturers have created safe-to-touch drones [1, 7, 18], and others have increased
safety by adding propeller guards to previous designs [4, 6, 17]. These safe-to-touch drones not only increase
safety, but also enable new applications based on touch interactions, such as hovering programmable matter [8],
augmented sports [15], and haptic feedback in virtual reality [10, 21]. These applications are only possible through
direct touch and manipulation; however, it is unclear whether or not individuals feel comfortable touching these
drones.
As drones become more present in our environment, it is important to understand how people naturally
interact with them. In some scenarios, direct interaction with drones, whether using touch or other types of
interaction, is advantageous. For example, if an autonomous drone delivers a package to the wrong address,
direct interaction enables the residents to inform the drone about this problem, regardless of their familiarity
with this technology. In public spaces, people may also need to interact with drones that are controlled by others.
For example, in the case of a drone equipped with cameras flying in a park, parents may want to ask the drone
to stay further away from their children, for privacy or safety reasons. In other situations, such as search and
rescue, direct interaction is necessary as victims may not have access to a remote control device or a smartphone.
In a previous Wizard-of-Oz (WoZ) elicitation study, Cauchard et al. [3] showed that gestures and voice
commands are used by users to interact with drones, with gestures being the most common modality. E et al.
[5] replicated this study in China to gain insight into the variation of these user-defined interactions across
cultures. We built a safe-to-touch drone and replicated the study with a few modifications, to better understand
how people interact with safe drones. We designed a between-subjects study with 24 participants; one group
using the safe-to-touch drone and the other using the unsafe drone without the protective cage. We found that
58% of participants chose to use touch as a means of interacting with the safe-to-touch drone and 92% indicated
that they would feel comfortable touching it. In this paper, we present findings from this study that can inform
the design of touch-based human-drone interactions.
2 RELATED WORK
In recent years, various safe-to-touch commercial drones have been proposed or released. Aerotain is a heliumfilled spherical “soft drone” used for engaging audience in live entertainment [1]. The propulsion system is
enclosed in the inflated balloon, making this drone completely safe-to-touch. Fleye is another spherical safe-totouch drone concept that is not yet commercially available [7]. Hover Camera is a foldable flying camera with
enclosed propellers [18]. The physical form of Hover Camera is such that it can be held in a user’s hand and is
designed with two interactions in mind: “release and hover” or “throw and balance”. Note that we chose not to
use any of these safe-to-touch commercial drones and instead built a removable protective cage. This allowed us
to use identical drones in both conditions by removing the protective cage from the safe drone. Moreover, the
physical form of these commercial drones is suggestive of the limited range of interactions that the manufacturers
had in mind when designing them. Having a custom safe-to-touch drone allowed us to explore a broader range
of touch-based interactions.
Gesture-based human-drone interaction techniques have been explored in the past [11, 14, 16]. Safe-to-touch
drones, however, motivate the exploration of new forms of human-drone interaction that involve direct touch
and manipulation. For example, HoverBall is a ball-shaped quadcopter that can hover and change its behavior
and location as needed [15]. Drones have also been considered as ungrounded encountered-type haptic feedback
devices in virtual reality [10, 21]. BitDrones are nano-quadcopters that are used as a form of programmable
matter [8]. Gomes et al. present various input techniques for BitDrones, such as touching, dragging, throwing,
and resizing [8]. These applications use direct touch as a means of interacting with drones; however, due to the
absence of an evaluation, it is unclear if users feel comfortable touching the drones and whether touch is a viable
interaction modality.
3 USER STUDY
To find out whether or not users choose to touch safe drones and to realize how users naturally interact with them,
we replicated, with few modifications, the WoZ elicitation study suggested by Cauchard et al. [3]. Participants
were told that the drone is autonomous and that they can utilize any interaction method they choose to complete
a set of tasks. No suggestions were given on how to inform the drone to complete these tasks. Throughout the
study, the experimenter controlled the drone with a remote, while standing behind the participant. This WoZ
technique enabled the simulation of the drone’s reaction to user-defined interaction methods. We designed a
between-subjects study, with one group interacting with an unsafe drone (control condition) and the other group
interacting with a safe-to-touch done. Each participant was presented with 12 tasks: take off, land, fly higher, fly
lower, fly closer, fly further away, fly sideways, follow me, stop following, stop by me, get attention, and take
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 3, Article 34. Publication date:
September 2017.
Drone Near Me: Exploring Touch-Based Human-Drone Interaction • 34:3
Fig. 1. Two sample cards for the “Take Off” task. Left: the safe-to-touch version. Right: the control version.
selfie. The tasks were presented on a set of cards, with visuals depicting the state of the drone before and after
completing the task, as shown in Figure 1. For all tasks, except take off, stop following, and stop by me, the drone
started in a hovering position. Balanced Latin Square was used to randomize the order of tasks to minimize the
effects of learning and fatigue.
3.1 Participants
24 participants were recruited (13 female, 10 male, 1 non-binary), ages 17 to 24 (μ = 20) from our institution and
nearby companies. They were randomly placed in two groups of 12, one group interacting with the safe-to-touch
drone and the other with the unsafe drone. Participants had various levels of experience with drone control. Each
person received a $15 gift card for 45 minutes of their time.
3.2 Apparatus
We used two Parrot AR Drones. For the safe-to-touch drone, we built a light-weight wooden (balsa, bamboo, and
basswood) frame and used a clear Polypropylene mesh to prevent direct contact with the blades, as shown in
Figure 2. To be consistent with previous studies, we conducted the experiment in a semi-secluded outdoor space.
Fig. 2. Left: the original AR Drone 2.0 used in the control condition. Right: the modified AR Drone 2.0 that is safe-to-touch.
3.3 Modifications
Three modifications were made to the original study (Drone & Me) conducted by Cauchard et al. [3]:
(1) The Drone & Me study consisted of 18 tasks with various levels of proximity. 5 of those tasks are
categorized as “outside body frame”, in which the drone is far from the user throughout the interaction.
Similarly, in the “stop when flying” task the drone is not within arm’s reach. We eliminated these 6 tasks
from our study, as we did not expect to see any differences between the two conditions.
(2) In the study conducted by Cauchard et al., participants were informed about the WoZ and they found that
this information did not affect the results. During our pilot studies, we found that in the safe-to-touch
condition people were hesitant to touch the drone, because they were not certain if the experimenter
could understand their intent when touching the drone. Therefore, we chose not to inform the participants
about the WoZ. Similar to Drone & Me, we asked participants not to make any assumptions about the
technical capabilities of the drone and to act in the manner that felt most natural.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 3, Article 34. Publication date:
September 2017.
34:4 • P. Abtahi et al.
Table 1. Percentages of use of common interaction modalities.
Drone Touch Gesture Sound Touch & Gesture Gesture & Sound Touch & Sound All Three
Safe 38.9% 50.0% 29.9% 4.17% 16.7% 0.694% 0.0%
Unsafe 1.39% 87.5% 11.8% 1.39% 7.64% 0.694% 0.694%
(3) In the previous study, each task was presented on a card that included the title of the task as well as two
sentences describing the before and after condition. In our study, we used visuals to represent the before
and after state, as shown in Figure 1, to avoid verbally biasing the users’ actions and to eliminate the
effects of language barriers when performing the tasks.
4 RESULTS AND DISCUSSION
The data collected consisted of videos from two angles (one for measuring the distance between the participants and
the drone, and the other for capturing interactions), transcripts and footage from post-task and post-experiment
semi-structured interviews, and answers to the post-study questionnaires.
4.1 Interaction Modalities
In total, 288 tasks were completed. We identified three common modalities: touch, gesture, and sound, as well as
multi-modal interactions that combined these three. 11 tasks were completed with other modalities, such as body
movements and facial expressions. Table 1 presents the percentage of use of common interaction modalities.
Note that multi-modal interactions are counted in all corresponding columns; for example an interaction that
used both touch and gesture is counted in “Touch”, “Gesture”, and “Touch & Gesture”.
In the safe-to-touch condition, 39% of interactions were touch-based; however, similar to the control condition,
gesture was the most common modality. For touch, gesture, and sound, we found the proportion of modalities
used in the safe-to-touch condition to be significantly different from the control condition using the G-test
(G = 87.4,d f = 2,p < 0.0001). Compared to the control condition, participants in the safe-to-touch condition
used touch-based interactions significantly more (t = 3.39,p < 0.01) and gestures significantly less(t = −3.21,p <
0.01). Between the two conditions, there was no significant difference in the percentage of use for sound.
4.2 Agreement
The agreement scores for each task were calculated using the agreement rate equation for between-subjects
elicitation studies [19], and the results are shown in Table 2. The agreement scores > 0.5 (in bold) indicate
tasks in which the types of interactions were less varied within each modality. Note that cases in which only
one participant used a modality resulted in an agreement score of 1.0, but those have not been bolded. In the
safe-to-touch condition 2
3 of touch-based interactions were in agreement and the average agreement score across
all tasks was > 0.5 for touch interactions (μ = 0.553, σ = 0.208).
4.3 Touch-Based Interactions
In this section we discuss and compare touch-based interactions that occurred in the safe-to-touch and control
conditions. We also identify a set of user-defined touch inputs based on our observations during the study.
4.3.1 Safe-To-Touch Condition: 58% of participants used touch as a means of interacting with the safe-to-touch
drone and 61 touch interactions were performed across all tasks. We asked participants who touched the drone,
why they chose touch as a means of interacting with the drone. Some stated that touch felt more natural to them:
“Seemed more natural for me to just help the drone… sort of lift it up or push it down” [P4], while others said
they thought touch interactions would be more clear: “Showing a hand movement is kind of ambiguous but if
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 3, Article 34. Publication date:
September 2017.
Drone Near Me: Exploring Touch-Based Human-Drone Interaction • 34:5
Table 2. Agreement scores per modality for the safe-to-touch drone and the control condition.
Safe Drone Task Gesture Sound Touch
Take off 0.44 0.62 0.55
Land 0.36 0.62 0.22
Fly Higher 0.28 0.55 0.61
Fly Lower 0.39 0.37 0.28
Fly Closer 1.0 0.33 0.72
Fly Further Away 0.44 0.55 0.53
Fly Sideways 0.62 0.55 0.28
Follow Me 0.75 1.0 0.50
Stop Following 1.0 0.62 0.62
Stop By Me 0.43 1.0 0.62
Get Attention 0.50 0.27 1.0
Take Selfie 0.31 0.55 0.69
Unsafe Drone Task Gesture Sound Touch
Take off 0.46 1.0 0.50
Land 0.49 1.0 -
Fly Higher 0.35 0.50 -
Fly Lower 0.43 1.0 -
Fly Closer 0.69 1.0 -
Fly Further Away 0.45 1.0 -
Fly Sideways 0.51 1.0 -
Follow Me 0.63 1.0 -
Stop Following 0.55 - -
Stop By Me 0.59 1.0 -
Get Attention 0.34 0.50 -
Take Selfie 0.42 1.0 -
you have… a physical intervention with something… I can teach it… what I want it to do” [P12]. Clarity is an
important advantage of touch-based interactions. Cultural differences influence gestures, as shown by E et al.
[5], and voice commands are affected by language barriers; however, using direct touch and manipulation could
be less ambiguous when instructing the drone. In the post-experiment interviews, 92% of participants in the
safe-to-touch condition indicated that they would feel comfortable touching the drone. From those who felt safe
but chose not to touch the drone, some said that they were concerned about damaging the protective cage: “I
didn’t want to touch it cause I didn’t wanna break it” [P7], and some stated that they had made assumptions
about the capabilities of the drone: “I didn’t know whether or not it would react to that! I didn’t know if it had
touch sensors” [P2].
4.3.2 Control Condition: Two touch interactions were performed by two different participants (17%) in the
control condition. Both interactions were during the “Take Off” task (the blades were not rotating in the before
condition) and for safety reasons, the experimenter controlling the drone chose not to take off. This may have
discouraged the two participants from using touch-based interactions in the following tasks. Note that Touch
interactions with unsafe drones were also observed by Cauchard et al. [3] and E et al. [5]. When asked why they
touched the drone, one participant said: “I tried to pick it up because I just wasn’t entirely sure what the task
was asking for” [P13]. This uncertainty about how to interact with the unsafe drone also manifested itself in the
results of the post-study questionnaire (5-point Likert scale). The participants in the control condition found
interacting with the drone significantly more mentally demanding (Mann-Whitney U : 37.0,p < 0.05). 25% of the
participants in the control condition indicated that the task was mentally demanding, compared to 0% in the
safe-to-touch condition.
4.3.3 User-Defined Touch Inputs: By analyzing all touch interactions, we identified 8 different types of userdefined touch inputs, as shown in Figure 3: 2-handed frame side grasp (31 interactions), 1-handed core grasp
(10), 1-handed frame side grasp (8), 2-handed top pinch (6), 1-handed core push (3), 1-handed frame top push (1),
2-handed frame side push (1), and 2-handed frame top push (1). Note that the affordances of the safe-to-touch
drone inform the types of user-defined interactions and the touch inputs listed here are just provided as an
example. A safe-to-touch drone with a different form, such as a sphere or a cube, would have led to a different
set of touch interactions.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 3, Article 34. Publication date:
September 2017.
34:6 • P. Abtahi et al.
Fig. 3. Examples of different touch interactions observed during the study. Top row showing one-handed interactions (from
left to right): core grasp, frame top push, frame top grasp, and core push. Bottom row showing two-handed interactions
(from left to right): frame side push, top pinch, frame side grasp, frame top push.
4.4 Proxemics
Across all tasks, on average the minimum distance between the participants and the safe-to-touch drone (μ =
2.58, σ = 4.79) was less than the minimum distance in the control condition (μ = 23.0, σ = 20.7); we found
this difference to be significant (t = −3.95,p < 0.005). Moreover, in the safe-to-touch condition all participants
interacted with the drone in their intimate space (< 1.5ft) [9], compared to 42% in the control condition.
4.5 Safety
When asked about safety, on a 5-point Likert scale, 83% of participants in the safe-to-touch condition and 42% in
the control condition indicated that they felt safe when interacting with the drone (Mann-Whitney U : 97.0,ns).
In the post-study interviews for the safe-to-touch condition, participants also said that they felt safe around
the drone: “There wasn’t anything the drone could have really like done to me” [P1]. One participant drew an
analogy between the safe-to-touch drone and a cardboard box: “It was somewhat like handling a cardboard box
around the edges, so it definitely felt very safe” [P11]. Even those who did not choose to touch the safe drone
said that they felt safe because of the protective cage: “The meshing, I didn’t worry about the drone getting too
close to me” [P7].
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 3, Article 34. Publication date:
September 2017.    
Drone Near Me: Exploring Touch-Based Human-Drone Interaction • 34:7
4.6 Metaphors
Similar to previous studies [3, 5], interaction metaphors were observed. Some participants compared the drone
to a pet or a dog: “I used my hands like I would with a dog or something!” [P2], “I used a lot of hand and arm
gestures that I would normally use I think with a pet” [P15]. Others drew an analogy to interacting with a person:
“I just figured I would do whatever I would do to… tell a person what to do” [P14]. Participants also complimented
the drone by saying “nice” or “good job”. When asked why they did so, they said: “To complement it. You know?
It did it! It was kind of cute, so I thought I’ll tell it good job” [P3].
5 LIMITATIONS AND FUTURE WORK
The goal of this study was to learn whether or not users feel comfortable touching safe drones and if they naturally
choose touch as a means of interacting with these drones. The form of the safe-to-touch drone that we built had
an impact on the user-defined touch interactions that we observed. A more thorough analysis, with different
safe-to-touch drone designs, is needed to identify the most suitable form factor as well as the preferred type of
touch-based interactions. Moreover, in our study, the custom-built cage of the safe-to-touch drone may have
contributed to a lower number of touch-based interactions. We observed that some participants were hesitant to
touch the drone, as they felt they might break or damage the protective cage. In future studies, a well constructed
cage with a different material, such as carbon fiber, may lead to more accurate results.
6 CONCLUSION
As personal drones have gained in popularity, public safety has become a serious concern. To address this,
commercial drones have been moving towards a safe-to-touch design. These safe drones afford new forms of
touch-based human-drone interactions. However, it is unclear if users would touch these drones and what the
most natural way of interacting with them is. We replicated a WoZ elicitation study with a few modifications, to
understand how people naturally interact with safe-to-touch drones. We built a safe-to-touch drone and ran a
between-subjects study with 24 participants. We found that in the safe-to-touch condition, 58% of participants
touched the drone and 39% of all interactions were touch-based. Interacting with the safe-to-touch drone was
reported to be significantly less mentally demanding than the unsafe drone, and majority of users (83%) reported
that they felt safe while interacting with it.