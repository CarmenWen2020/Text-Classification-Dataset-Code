The problem of constructing hazard-free Boolean circuits dates back to the 1940s and is an important problem
in circuit design. Our main lower-bound result unconditionally shows the existence of functions whose circuit
complexity is polynomially bounded while every hazard-free implementation is provably of exponential size.
Previous lower bounds on the hazard-free complexity were only valid for depth 2 circuits. The same proof
method yields that every subcubic implementation of Boolean matrix multiplication must have hazards.
These results follow from a crucial structural insight: Hazard-free complexity is a natural generalization
of monotone complexity to all (not necessarily monotone) Boolean functions. Thus, we can apply known
monotone complexity lower bounds to find lower bounds on the hazard-free complexity. We also lift these
methods from the monotone setting to prove exponential hazard-free complexity lower bounds for nonmonotone functions.
As our main upper-bound result, we show how to efficiently convert a Boolean circuit into a boundedbit hazard-free circuit with only a polynomially large blow-up in the number of gates. Previously, the best
known method yielded exponentially large circuits in the worst case, so our algorithm gives an exponential
improvement.
As a side result, we establish the NP-completeness of several hazard detection problems.
CCS Concepts: • Theory of computation → Circuit complexity;
Additional Key Words and Phrases: Hazards, Boolean circuits, monotone circuits, computational complexity
1 INTRODUCTION
We study the problem of hazards in Boolean circuits. This problem naturally occurs in digital circuit design, specifically in the implementation of circuits in hardware (e.g., [9, 21]),
but is also closely related to questions in logic (e.g., [25, 26, 29]) and cybersecurity [20, 46].
Objects are called differently in the different fields; for presentational simplicity, we use the parlance of hardware circuits throughout the article.
A Boolean circuit is a circuit that uses and-, or-, and not-gates, in the sense of [23, Section 1.2],
where and and or have fan-in two. The standard approach to studying hardware implementations
of Boolean circuits is to use the digital abstraction, in which voltages on wires and at gates are
interpreted as either logical 0 or 1. More generally, this approach is suitable for any system in
which there is a guarantee that the inputs to the circuit and the outputs of the gates of the circuit
can be reliably interpreted in this way (i.e., be identified as the Boolean value matching the gate’s
truth table).
Kleene Logic and Hazards
Several independent works ([17, 50] and references therein) observed that Kleene’s classical threevalued strong logic of indeterminacy K3 [25, Section 64] captures the issues arising from non-digital
inputs. The idea is simple and intuitive. The two-valued Boolean logic is extended by a third value u
representing any unknown, uncertain, undefined, transitioning, or otherwise non-binary value.
We call both Boolean values stable, while u is called unstable. The behavior of a Boolean gate
is then extended as follows. Let B := {0, 1} and T := {0, u, 1}. Given a string x ∈ Tk , a resolution
y ∈ Bk of x is defined as a string that is obtained by replacing each occurrence of u in x by either
0 or 1. If a k-ary gate (with one output) is subjected to inputs x ∈ Tk , then it outputs b ∈ B iff it
outputs b for all resolutions y ∈ Bk of x; otherwise, it outputs u. In other words, the gate outputs
a Boolean value b, if and only if its output does not actually depend on the unstable inputs. This
results in the following extended specifications of and, or, and not gates:
not 0 u 1
1 u 0
and 0 u 1
0 000
u 0 u u
1 0 u 1
or 0 u 1
0 0 u 1
u u u 1
1 111
By induction over the circuit structure, a circuit C with n input gates now computes a function
C : Tn → T.
Unfortunately, in some cases, the circuit might behave in an undesirable way. Consider a multiplexer circuit (MUX), which for Boolean inputs x,y,s ∈ B outputs x if s = 0 and y if s = 1. A
straightforward circuit implementation is shown in Figure 1(a). Despite the fact that MUX(1, 1, 0) =
MUX(1, 1, 1) = 1, one can verify that in Figure 1(a), MUX(1, 1, u) = u. Such behaviour is called a
hazard:
Definition 1.1 (Hazard). We say that a circuit C on n inputs has a hazard at x ∈ Tn iff C(x) = u
and there is a Boolean value b ∈ B such that for all resolutions y of x we have C(y) = b. If C has
no hazard, then it is called hazard-free.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.
On the Complexity of Hazard-free Circuits 25:3
Fig. 1. Two circuits that implement the same Boolean multiplexer function. One has a hazard, and the other
one is hazard-free.
The name hazard-free has different meanings in the literature. Our definition is taken from [11].
In Figure 1(b), we see a hazard-free circuit for the multiplexer function. Note that this circuit uses
more gates than the one in Figure 1(a). The problem of detecting hazards and constructing circuits
that are hazard-free started a large body of literature; see Section 2. The question whether hazards
can be avoided in principle was settled by Huffman.
Theorem 1.2 [21]. Every Boolean function has a hazard-free circuit computing it.
He immediately noted that avoiding hazards is potentially expensive [21, p. 54]:
“In this example at least, the elimination of hazards required a substantial increase
in the number of contacts.”
Indeed, his result is derived using a clause construction based on the prime implicants of the considered function, which can be exponentially many; see, e.g., [10]. There has been no significant
progress on the complexity of hazard-free circuits since Huffmann’s work. Accordingly, the main
question we study in this article is:
What is the additional cost of making a circuit hazard-free?
Our Contribution
Unconditional Lower Bounds. Our first main result is that monotone circuit lower bounds directly
yield lower bounds on hazard-free circuits. A circuit is monotone if it only uses and-gates and orgates, but does not use any not-gates. For a Boolean function f , denote (i) by L(f ) its Boolean
complexity, i.e., the size of a smallest circuit computing f , (ii) by Lu (f ) its hazard-free complexity,
i.e., the size of a smallest hazard-free circuit computing f , and (iii), if f is monotone, then by L+(f )
its monotone circuit complexity, i.e., the size of a smallest monotone circuit computing f . We show
that Lu properly extends L+ to the domain of all Boolean functions.
Theorem 1.3. If f is monotone, then Lu (f ) = L+(f ).
We consider this connection particularly striking, because hazard-free circuits are highly desirable in practical applications. Moreover, to our surprise the construction underlying Theorem 1.3
yields a circuit computing a new directional derivative that we call the hazard derivative1 of the
function at x = 0 in direction of y, which equals the function itself if it is monotone (and not
1Interestingly, this is closely related to, but not identical to, the Boolean directional derivative defined in, e.g., [12, Definition 3], which has applications in cryptography. To the best of our knowledge, the hazard derivative has not appeared in
the literature so far.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.
25:4 C. Ikenmeyer et al.
constant 1). We consider this observation to be of independent interest, as it provides additional
insight into the structure of hazard-free circuits.
We get the following (non-exhaustive) list of immediate corollaries that highlight the importance of Theorem 1.3.
Corollary 1.4 (Using Monotone Lower Bound from [40]). Define the Boolean permanent
function fn : Bn2
→ B as
f (x11,..., xnn ) =

σ ∈Sn
n
i=1
xiσ (i).
We have L(fn ) = O(n5) and Lu (fn ) ≥ 2Ω(log2 n)
.
Corollary 1.5 (Using Monotone Lower Bound from [45]). There exists a family of functions
fn : Bn2
→ B such that L(fn ) = poly(n) and Lu (fn ) ≥ 2cn1/3−o(1)
for a constant c > 0.
In particular, there is an exponential separation between L and Lu.
Corollaries 1.4 and 1.5 are immediate applications of Theorem 1.3. Using additional techniques,
we can obtain separation results even for non-monotone functions!
Corollary 1.6. Let detn : Bn2
→ B be the determinant over the field with 2 elements, that is,
detn (x11,..., xnn ) =

σ ∈Sn
n
i=1
xiσ (i).
We have L(detn ) = poly(n) and Lu (detn ) ≥ 2Ω(log2 n)
.
These techniques also allow us to improve the gap between Boolean and hazard-free complexity
relative to Corollary 1.5.
Corollary 1.7 (Using Monotone Lower Bound from [2]). There exists a family of functions
fn : BN → B such that L(fn ) = O(N) but Lu (fn ) ≥ 2c N 1/4−o(1)
for some c > 0, where the number of
input variables of fn is N = 4n +  2n/2
4
√
n .
As a final example, we state a weaker but still substantial separation result for Boolean matrix
multiplication.
Corollary 1.8 (Using Monotone Lower Bound from [31, 36], See Also the Earlier
[38]). Let f : Bn×n × Bn×n → Bn×n be the Boolean matrix multiplication map, i.e., f (X,Y ) = Z with
zi,j = n
k=1 xi,k ∧yk,j . Every circuit computing f with fewer than 2n3 − n2 gates has a hazard. In particular, every circuit that implements Strassen’s algorithm [42] (or any of its later improvements; see
e.g., [27]) in a way that can be used for subcubic Boolean matrix multiplication has a hazard.
Since our methods are based on relabeling circuits only, analogous translations can be performed
for statements about other circuit complexity measures, for example, the separation result for
the circuit depth from [39]. The previously best lower bounds on the size of hazard-free circuits
are restricted to depth 2 circuits (with unbounded fan-in and not counting input negations), see
Section 2.
For our lower bounds, we use the strong connection between hazard-free complexity and monotone complexity, but we want to point out a conceptional difference between monotone circuits
and hazard-free circuits: monotone circuits are defined syntactically, via a restriction of the available gates, whereas being hazard-free is a semantic property, that is, it refers to the properties of
the function computed by a circuit.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.  
On the Complexity of Hazard-free Circuits 25:5
Parametrized Upper Bound. These hardness results imply that we cannot hope for a general
construction of a small hazard-free circuit for f even if L(f ) is small. However, the task becomes
easier when restricting to hazards with a limited number of unstable input bits.
Definition 1.9 (k-bit Hazard). For a natural number k, a circuit C on n inputs has a k-bit hazard
at x ∈ Tn, iff C has a hazard at x and u appears at most k times in x.
Such a restriction on the number of unstable input bits has been considered in many papers (see,
e.g., [20, 47, 50, 51]), but the state-of-the-art in terms of asymptotic complexity has not improved
since Huffman’s initial construction [21], which is of size exponential in n, see the discussion of [43,
44] in [15, Section “Speculative Computing”]. We present a construction with blow-up exponential
in k, but polynomial in n. In particular, if k is constant and L(fn ) ∈ poly(n), this is an exponential
improvement.
Corollary 1.10. Let C be a circuit with n inputs, |C| gates and depth D. Then there is a circuit
with at most ( ne
k )
2k (|C| + 7) gates and depth D + 2k(	logn
 + 2) that computes the same function
and has no k-bit hazards.
Further Results. We round off the presentation by a number of further results. First, to further
support the claim that the theory of hazards in circuits is natural, we prove that it is independent
of the set of gates (and, or, not), as long as the set of gates is functionally complete and contains
a constant function; see Corollary A.3. Second, it appears unlikely that much more than logarithmically many unstable bits can be handled with only a polynomial circuit size blow-up.
Theorem 1.11. Fix a monotonously weakly increasing sequence of natural numbers kn with
logn ≤ kn and set jn := kn/ logn. If Boolean circuits deciding jn-CLIQUE on graphs with n vertices require a circuit size of at least nΩ(jn )
, then there exists a function fn : Bn2+kn → B with L(fn ) = poly(n)
for which circuits without kn-bit hazards require 2Ω(kn ) many gates to compute.
In particular, if kn = ω(logn) is only slightly superlogarithmic, then Theorem 1.11 provides a
function where the circuit size blow-up is superpolynomial if we insist on having no kn-bit hazards.
In this case jn is slightly superconstant, which means that “Boolean circuits deciding jn-CLIQUE
require size at least nΩ(jn )
” is a consequence of a nonuniform version of the exponential time
hypothesis (see [28]), i.e., smaller circuits would be a major algorithmic breakthrough.
We remark that, although it has not been done before, deriving conditional lower bounds such
as Theorem 1.11 is rather straightforward. In contrast, Theorem 1.3 yields unconditional lower
bounds.
Finally, determining whether a circuit has a hazard is NP-complete, even for 1-bit hazards (Theorem 6.5). This matches the fact that the best algorithms for these tasks have exponential running time [13]. Interestingly, this also means that if NP  coNP, given a circuit there exists no
polynomial-time verifiable certificate of size polynomial in the size of the circuit to prove that the
circuit is hazard-free, or even free of 1-bit hazards.
2 RELATED WORK
Multi-valued logic is a very old topic and several three-valued logic definitions exist. In 1938
Kleene defined his strong logic of indeterminacy [24, p. 153], see also his later textbook [25,
Section 64]. It can be readily defined by setting u = 1
2 , not x := 1 − x, x and y := min(x,y), and
x or y := max(x,y), as it is commonly done in fuzzy logic [37, 41]. This happens to model the
behavior of physical Boolean gates and can be used to formally define hazards. This was first
realized by Goto in [18, p. 128], which is the first paper that contains a hazard-free implementation
of the multiplexer; see [18, Figure 7·5]. The third truth value in circuits was mentioned one year
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019. 
25:6 C. Ikenmeyer et al.
earlier in [17]. As far as we know, this early Japanese work was unnoticed in the Western world
at first. The first structural results on hazards appeared in a seminal paper by Huffman [21], who
proved that every Boolean function has a hazard-free circuit. This is also the first paper that
observes the apparent circuit size blow-up that occurs when insisting on a hazard-free implementation of a function. Huffman mainly focused on 1-bit hazards, but notes that his methods carry
over to general hazards. Interestingly, our Corollary 1.10 shows that for 1-bit hazards the circuit
size blow-up is polynomially bounded, while for general hazards, we get the strong separation of
Corollary 1.5.
The importance of hazard-free circuits is already highlighted, for example, in the classical
textbook [9]. Three-valued logic for circuits was introduced by Yoeli and Rinon in [50]. In 1965,
Eichelberger published the influential paper [13], which shows how to use three-valued logic to
detect hazards in exponential time. This paper also contains the first lower bound on hazard-free
depth 2 circuits: A hazard-free and-or circuit with negations at the inputs must have at least as
many gates as its function has prime implicants, which can be an exponentially large number;
see, e.g., [10]. Later work on lower bounds was also only concerned with depth 2 circuits, for
example, [35].
Mukaidono [32] was the first to formally define a partial order of definedness, see also [33,
34], where it is shown that a ternary function is computable by a circuit iff it is monotone under
this partial order. In 1981, Marino [30] used a continuity argument to show (in a more general
context) that specific ternary functions cannot be implemented; for example, there is no circuit
that implements the detector function f (u) = 1, f (0) = f (1) = 0.
Nowadays the theory of three-valued logic and hazards can be found, for example, in [7]. A
fairly recent survey on multi-valued logic and hazards is given in [5].
Recent work models clocked circuits [16]. Applying the standard technique of “unrolling” a
clocked circuit into a combinational circuit, one sees that the computational power of clocked and
unclocked circuits is the same. Moreover, lower and upper bounds translate between the models
as expected; using r rounds of computation changes circuit size by a factor of at most r. However,
[16] also models a special type of registers, masking registers, that have the property that if they
output u when being read in clock cycle r, they output a stable value in all subsequent rounds
(until written to again). With these registers, each round of computation enables computing strictly
more (ternary) functions. Interestingly, adding masking registers also breaks the relation between
hazard-free and monotone complexity: [16] presents a transformation that trades a factor O(k)
blow-up in circuit size for eliminating k-bit hazards. In particular, choosing k = n, a linear blowup suffices to construct a hazard-free circuit out of an arbitrary hazardous implementation of a
Boolean function.
Seemingly unrelated, in 2009 a cybersecurity paper [46] was published that studies information
flow on the Boolean gate level. The logic of the information flow happens to be Kleene’s logic and
thus results transfer in both directions. In particular (using different nomenclature), they design a
circuit (see [46, Figure 2]) that computes the Boolean derivative, very similar to our construction
in Proposition 4.8. In the 2012 follow-up paper [20], the construction of this circuit is monotone
(see [20, Figure 1]), which is a key property that we use in our main structural correspondence
result Theorem 1.3.
There is an abundance of monotone circuit lower bounds that all translate to hazard-free complexity lower bounds, for example, [1, 39, 40, 49] and references in [19] for general problems but
also [48] and references therein for explicit problems, [31, 36, 38] for matrix multiplication, and
[4] for the Boolean convolution map. This last reference also implies that any implementation of
the Fast Fourier Transform to solve Boolean convolution must have hazards.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.
On the Complexity of Hazard-free Circuits 25:7
3 DEFINITIONS
We study functions F : Tn → T that can be implemented by circuits. The Boolean analogue is just
the set of all Boolean functions. In our setting this is more subtle. First, if a circuit gets a Boolean
input, then by the definition of the gates it also outputs a Boolean value. Thus, every function that
is computed by circuits preserves stable values, i.e., yields a Boolean value on a Boolean input. Now,
we equip T with a partial order  such that u is the least element and 0 and 1 are incomparable
elements greater than u; see [32]. We extend this order to Tn in the usual way. For tuples x,y ∈ Tn
the statement x  y means that y is obtained from x by replacing some unstable values with stable
ones. Since the gates and, or, not are monotone with respect to , every function F computed
by a circuit must be monotone with respect to . It turns out that these two properties capture
precisely what can be computed:
Proposition 3.1 [32, Theorem 3]. A function F : Tn → T can be computed by a circuit iff F
preserves stable values and is monotone with respect to .
A function F : Tn → T that preserves stable values and is monotone with respect to  shall
be called a natural function. A function F : Tn → T is called an extension of a Boolean function
f : Bn → B if the restriction F |Bn coincides with f .
Observe that any natural extension F of a Boolean function f must satisfy the following. If y and
y are resolutions of x (in particular x  y and x  y
) such that F (y)  F (y
), then it must hold
that F (y) = 0 and F (y
) = 1 (or vice versa), due to preservation of stable values. By -monotonicity,
this necessitates that F (x) = u, the only value “smaller” than both 0 and 1. Thus, one cannot hope
for a stable output of a circuit if x has two resolutions with different outputs. In contrast, if all
resolutions of x produce the same output, we can require a stable output for x, i.e., that a circuit
computing F is hazard-free.
Definition 3.2. For a Boolean function f : Bn → B, define its hazard-free extension ¯f : Tn → T
as follows:
¯f (x) =
⎧⎪⎪
⎨
⎪⎪
⎩
0, if f (y) = 0 for all resolutions y of x,
1, if f (y) = 1 for all resolutions y of x,
u, otherwise.
Hazard-free extensions are natural functions and are exactly those functions that are computed
by hazard-free circuits, as can be seen, for example, by Theorem 1.2. Equivalently, ¯f is the unique
extension of f that is monotone and maximal with respect to .
We remark that later on we will also use the usual order ≤ on B and Bn. We stress that the term
monotone Boolean function refers to functions Bn → B monotone with respect to ≤.
4 LOWER BOUNDS ON THE SIZE OF HAZARD-FREE CIRCUITS
In this section, we present a number of lower bound results. As a warm-up, we first prove the
conditional lower bound Theorem 1.11, which is a direct consequence of the upcoming Proposition 4.1 and noting that nΩ(kn / log n) = 2Ω(kn )
. We then discuss the main result Lu (f ) = L+(f ) for
monotone functions f and how Corollaries 1.4–1.8 follow from it.
Conditional Lower Bound
Proposition 4.1. Fix a monotonously weakly increasing sequence of natural numbers jn with jn ≤
n. There is a function fn : B(
n
2 )+jn log n → B with L(fn ) = poly(n) and the following property: if fn
can be computed by circuits of size Ln that are free of (jn logn)-bit hazards, then there are Boolean
circuits of size 2Ln that decide jn-CLIQUE.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019. 
25:8 C. Ikenmeyer et al.
Proof. The function fn gets as input the adjacency matrix of a graph G on n vertices and a list
 of jn vertex indices, each encoded in binary with logn many bits:
fn (G, ) =

1 if  encodes a list of jn vertices that form a jn-clique in G,
0 otherwise.
Clearly, L(fn ) = poly(n). Let C compute fn and have no (jn logn)-hazards. By the definition of
(jn logn)-hazards, it follows that C(G, ujn log n )  0 iff G contains a jn-clique. FromC, we construct
a circuit C that decides jn-CLIQUE as follows. We double each gate and each wire. Additionally,
after each doubled not-gate, we twist the two wires so that this not construction sends (0, 1)
to (0, 1) instead of to (1, 0). Stable inputs to C are doubled, whereas the input u is encoded as the
Boolean pair (0, 1). It is easy to see that the resulting circuit simulatesC. Our circuitC should have
(
n
2 ) inputs and should satisfy C
(G) = 1 iff C(G, ujn log n )  0; thus, we fix the jn logn rightmost
input pairs to constants (0, 1) to obtain C
. From the two output gates, we treat the right output
gate as the output of C
, while dismissing the left output gate.
Monotone Circuits are Hazard-free
Our first step towards Lu (f ) = L+(f ) is to show that Lu (f ) ≤ L+(f ).
Lemma 4.2. Monotone circuits are hazard-free. In particular, for monotone Boolean functions f , we
have Lu (f ) ≤ L+(f ).
Proof. We prove the claim by induction over the number of computation gates in the circuit.
Trivially, a monotone circuit without computation gates is hazard-free, as it merely forwards some
input to the output. For the induction step, let C be a monotone circuit computing a natural function F : Tn → T such that the gate computing the output of C receives as inputs the outputs of
two hazard-free monotone subcircuits C1 and C2. We denote by F1 and F2 the natural functions
computed by C1 and C2, respectively. The gate computing the output of C can be an and- or an
or-gate, and we will treat both cases in parallel. Let x ∈ Tn be arbitrary with the property that
F (y) = 1 for all resolutionsy of x. Denote byy0 the resolution of x in which all u’s are replaced by 0.
The fact that F (y0) = 1 implies that F1 (y0) = F2 (y0) = 1 (F1 (y0) = 1 or F2 (y0) = 1). Since the restrictions of F1 and F2 to Bn are monotone Boolean functions, this extends from y0 to all resolutions y
of x, because y ≥ y0 and thus F (y) ≥ F (y0) = 1. Since C1 and C2 are hazard-free by the induction
hypothesis, we have F1 (x) = F2 (x) = 1 (F1 (x) = 1 or F2 (x) = 1). As basic gates are hazard-free, we
conclude that F (x) = 1.
The case that F (y) = 0 for all resolutions y of some x ∈ Tn is analogous, where y0 is replaced
by y1, the resolution of x in which all u’s are replaced by 1.
The following sections show a much deeper relationship between monotone and hazard-free
circuits. A key concept is the derivative, which we will discuss next.
Derivatives of Natural Functions
In this section, we introduce the hazard derivative, a key ingredient for showing Lu (f ) ≥ L+(f ).
Let F : Tn → T be a natural function and x ∈ Bn be a stable input. If x˜  x, that is, if x˜ is obtained
from x by replacing stable bits by u, then F (x˜)  F (x). This means that there are two possibilities
for F (x˜) — either F (x˜) = F (x) or F (x˜) = u.
We can encode in one Boolean function the information about how the value of F changes
from F (x) to u when the bits of the input change from stable to unstable. It is reminiscent of the
idea of the derivative in analysis or the Boolean derivative, which also show how the value of the
function changes when the input changes. To make the connection more apparent, we introduce a
notation for replacing stable bits by unstable ones: if x,y ∈ Bn, then x + uy denotes the tuple that
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.       
On the Complexity of Hazard-free Circuits 25:9
is obtained from x by changing the values to u in all positions in which y has a 1 and keeping the
other values unchanged. Formally,
x˜ = x + uy ⇔ x˜i =

xi, if yi = 0,
u, if yi = 1.
This notation is consistent with interpreting the addition and multiplication on T as the hazardfree extensions of the usual addition modulo 2 and multiplication on B (xor and and).
Any tuple x˜  x can be presented as x + uy for some y ∈ Bn. As we have seen, F (x + uy) is
either F (x) or u. This condition can also be written as F (x + uy) = F (x) + uΔ for some Δ ∈ B.
Definition 4.3. Let F : Tn → T be a natural function. The hazard derivative (or just derivative
for short) of F is the Boolean function dF : Bn × Bn → B such that
F (x + uy) = F (x) + u · dF (x;y). (4.1)
In other words,
dF (x;y) =

0, if F (x + uy) = F (x),
1, if F (x + uy) = u.
For a Boolean function f , we use the shorthand notation df := df .
Consider, for example, the disjunction or. The values of (x1 + uy1)or(x2 + uy2) are as follows:
or 0 + u · 0 0 + u · 1 1 + u · 0 1 + u · 1
0 + u · 0 0 u 1 u
0 + u · 1 u u 1 u
1 + u · 0 1111
1 + u · 1 u u 1 u
Thus,
dor(x1, x2;y1,y2) = ¬x1y2 ∨ ¬x2y1 ∨y1y2. (4.2a)
Similarly, we find
dnot(x;y) = y, (4.2b)
dand(x1, x2;y1,y2) = x1y2 ∨ x2y1 ∨y1y2, (4.2c)
dxor(x1, x2;y1,y2) = y1 ∨y2. (4.2d)
Caveat: Since natural functions F are exactly those ternary functions defined by circuits, we can
obtain dF from the ternary evaluations of any circuit computing F . For Boolean functions f , it is
more natural to think of df as a property of the function f , because the correspondence to circuits
is not as close: we can obtain df from the ternary evaluations of any hazard-free circuit computing
f on Boolean inputs.
In general, we can find the derivative of a Boolean function as follows:
Lemma 4.4. For f : Bn →B, we have df (x;y)=
z ≤y [f (x) + f (x + z)]. In particular, if f (0) = 0,
then df (0;y) = 
z ≤y f (z).
Proof. Resolutions of x + uy coincide with x at positions where y has a 0 and have arbitrary
stable bits at positions where y has a 1. Therefore, each resolution of x + uy can be presented as
x + z for some z such that zi = 0 whenever yi = 0, that is, z ≤ y. Hence, the set of all resolutions
of x + uy is S (x + uy) := {x + z | z ≤ y}.
The derivative df (x;y) = 1 if and only if ¯f (x + uy) = u. By definition of hazard-freeness,
this happens when f takes both values 0 and 1 on S (x + uy), in other words, when the
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.
25:10 C. Ikenmeyer et al.
f (x + z)  f (x) for some z ∈ S (x + uy). The disjunction 
z ≤y [f (z) + f (x + z)] represents exactly
this statement.
As a corollary, we obtain a surprisingly close relation between monotone Boolean functions and
their derivatives. For a natural function F and any fixed x ∈ Bn, let dF (x; .) denote the Boolean
function that maps y ∈ Bn to dF (x;y), and define the shorthand df (x; .) := df (x; .) for a Boolean
function f .
Corollary 4.5. Suppose that f : Bn → B is monotone with f (0) = 0. Then df (0, .) = f .
Lemma 4.6. For natural F : Tn → T and fixed x ∈ Bn, dF (x; .) is a monotone Boolean function.
Proof. Note that the expression x + uy is antimonotone in y: if y1 ≥ y2, i.e., y1 is obtained from
y2 by replacing 0s with 1s, then x + uy1 is obtained from x + uy2 by replacing more stable bits of
x with u, so x + uy1  x + uy2. Thus, if y1 ≥ y2, then F being natural yields that
F (x) + u dF (x;y1) = F (x + uy1)  F (x + uy2) = F (x) + u dF (x;y2),
so dF (x;y1) ≥ dF (x;y2).
We can also define derivatives for vector functions F : Tn → Tm, F (x) = (F1 (x),..., Fm (x))
with natural components F1,..., Fm as dF (x;y) = (dF1 (x;y),..., dFm (x;y)). Note that Equation (4.1) still holds and uniquely defines the derivative for vector functions.
The following statement is the analogue of the chain rule in analysis.
Lemma 4.7 (Chain Rule). Let F : Tn → Tm and G : Tm → Tl be natural functions and H(x) =
G(F (x)). Then
dH(x;y) = dG(F (x); dF (x;y)).
Proof. Use Equation (4.1).
H(x + uy) = G(F (x + uy)) = G(F (x) + u dF (x;y)) = G(F (x)) + u dG(F (x); dF (x;y))
= H(x) + u dG(F (x); dF (x;y)),
and the claim follows with another application of Equation (4.1).
Using Monotone Circuits to Compute Derivatives
In this section, we show how to efficiently compute derivatives by transforming circuits to monotone circuits. Our main tool is the chain rule (Lemma 4.7).
For a circuit C and a gate β of C, let Cβ denote the natural function computed at the gate β.
From a circuit C, we now construct a circuit C by independently replacing each gate β on t inputs
α1,..., αt (0 ≤ t ≤ 2) by a subcircuit on 2t inputs α1,..., αt, α
1,..., α
t and two output gates β, β
(the wiring between these subcircuits in C is the same as the wiring between the gates in C,
but in C we have two parallel wires for each wire in C). The goal is that C
β (x,y) = Cβ (x) and
C
β (x,y) = dCβ (x;y) for Boolean inputs x,y ∈ Bn, see the upcoming Proposition 4.8.
To construct C
, we extend C with new gates. For each gate β in C, we add a new gate β
. If β is
an input gate xi , then β is the input gate yi . If β is a constant gate, then β is the constant-0 gate.
The most interesting case is when β is a gate implementing a function φ ∈ {and, or, not} with
incoming edges from gates α1,..., αt (in our definition of the circuit, the arity t is 1 or 2, but
the construction works without modification in the general case). In this case, we add to β a subcircuit that takes α1,..., αt and their counterparts α
1,..., α
t as inputs and β as its output gate,
which computes C
β (x,y) = dφ(C
α1 (x,y),...,C
αt (x,y);C
α
1
(x,y),...,C
α
t
(x,y)). For the sake of
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.    
On the Complexity of Hazard-free Circuits 25:11
Fig. 2. Gates in C get replaced by subcircuits in the construction of C
.
concreteness, for the gate types not, and, or according to Equation (4.2) this construction is depicted in Figure 2.
Proposition 4.8. C
β (x,y) = Cβ (x) and C
β (x,y) = dCβ (x;y) for Boolean inputs x,y ∈ Bn.
Proof. Clearly C
β (x,y) = Cβ (x). By induction on the structure of the circuit, we now prove
that C
β (x,y) = dCβ (x;y). In the base case, if β is an input or constant gate, the claim is obvious.
If β is a gate of type φ ∈ {and, or, not} with incoming edges from α1,..., αt , then
Cβ (x) = φ(Cα1 (x),...,Cαt (x)).
By the chain rule,
dCβ (x;y) = dφ(Cα1 (x),...,Cαt (x); dCα1 (x;y),..., dCαt (x;y)).
By the induction hypothesis, (α
1,..., α
t ) = (dCα1 (x;y),..., dCαt (x;y)); thus, the induction step
succeeds by construction of C
β.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019. 
25:12 C. Ikenmeyer et al.
Note that this construction can be seen as simulation of the behavior of the circuit C on the
input x + uy: the value computed at the gate β on this input is Cβ (x) + u dCβ (x;y), and in C the
gates β and β compute the two parts of this expression separately.
The construction can be seen as an adaptation of the technique of automatic differentiation,
an operator-wise transformation of a program computing a function to a program computing its
derivative. The idea is simple and dates back to the 1950s [8]. A theoretically inclined reader may be
more familiar with the theorem of Baur and Strassen on computing all derivatives of a multivariate
rational function given by an algebraic circuit [3], which provides foundations of an alternative
method—reverse mode automatic differentiation.
By fixing the first half of the input bits inC
, we now establish the link to monotone complexity.
In the following theorem the case x = 0 will be of particular interest.
Theorem 4.9. For f : Bn → B and fixed x ∈ Bn, it holds that L+(df (x, .)) ≤ Lu (f ).
Proof. Let C be a hazard-free circuit for f of minimal size and let x ∈ Bn be fixed. We start by
constructing the circuit C from Proposition 4.8, and for each gate in C we remember the corresponding subcircuit in C
. For each subcircuit, we call the gates αi the primary inputs and the α
i
the secondary inputs. From C
, we now construct a monotone circuit Cx on n inputs that computes
df (x; .) as follows. We fix the leftmost n input bits x ∈ Bn in C
. This assigns a Boolean value
C
α (x) = Cα (x) to each primary input α in each constructed subcircuit. Each constructed subcircuit’s secondary output β now computes some Boolean function in the secondary inputs α
i . If
the values at the secondary inputs are u1 = C
α
1
(x,y),...,ut = C
α
t
(x,y), then the value at the secondary output is ψ (u1,...,ut ) = dφ(Cα1 (x),...,Cαt (x);u1,...,ut ). Lemma 4.6 implies that ψ is
monotone (which can alternatively be seen directly from Figure 2, where fixing all primary inputs
makes all not gates superfluous). However, the only monotone functions on at most two input bits
are the identity (on one input), and, or, and the constants. Thus, we can replace each subcircuit
in C by (at most) one monotone gate, yielding the desired monotone circuit Cx that has at most
as many gates as C and outputs df (x; .) = d ¯f (x; .) = dC(x; .) = C
(.), where the second equality
holds because C is hazard-free.
We now use this construction to prove Theorem 1.3.
Proof of Theorem 1.3. The claim is trivial for the constant 1 function. Note that this is the only
case of a monotone function that has f (0)  0. Hence, assume that f is monotone with f (0) = 0.
By Lemma 4.2, we have that Lu (f ) ≤ L+(f ). The other direction can be seen via L+(f ) Cor. 4.5 =
L+(df (0, .))
Thm. 4.9
≤ Lu (f ).
Theorem 1.3 shows that the hazard-free complexity Lu can be seen as an extension of monotone
complexity L+ to general Boolean functions. Thus, known results about the gap between general
and monotone complexity transfer directly to hazard-free complexity.
Unconditional Lower Bounds
Corollaries 1.4, 1.5, and 1.8 are immediate applications of Theorem 1.3. Interestingly, however, we
can also derive results on non-monotone functions, which is illustrated by Corollary 1.6.
Proof of Corollary 1.6. The fact that the determinant can be computed efficiently is well
known.
Consider the derivative d detn (0;y) = 
z ≤y detn (z) (Lemma 4.4). If there exists a permutation
π ∈ Sn such that all yiπ (i) are 1, then, replacing all the other entries with 0, we get a matrix z ≤ y
with detn (z) = 1, and d detn (0;y) = 1. If there is no such permutation, then all the summands in the
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.   
On the Complexity of Hazard-free Circuits 25:13
definition of detn (y) are 0, and this is also true for all matrices z ≤ y. In this case, d detn (0;y) = 0.
Combining both cases, we get that d detn (0; .) equals the Boolean permanent function fn from
Corollary 1.4. The lower bound then follows from [40] and Theorem 4.9 (as in Corollary 1.4).
We can combine this technique with the ideas from the proof of Theorem 1.11 to show even
stronger separation results, exhibiting a family of functions for which the complexity of Boolean
circuits is linear, yet the complexity of hazard-free circuits grows almost as fast as in Corollary 1.5.
Lemma 4.10. Let f : Bn → B be a monotone Boolean function with f (0) = 0 and д : Bn+m → B
be a function such that f (x) = 1 iff д(x,y) = 1 for some y ∈ Bm. Then L+(f ) ≤ Lu (д).
Proof. Using Lemma 4.4, we obtain
dд(0, 0; x, 1) =

(z,t)≤(x,1)
д(z,t) =

z ≤x

t
д(z,t) =

z ≤x
f (z) = f (z),
which means that the circuit for f can be obtained from the circuit for dд(0; .) by substituting 1
for some inputs. The statement then follows from Theorem 4.9.
Proof of Corollary 1.7. We use the NP-complete family POLY(q,s) from the paper of Alon
and Boppana [2]. Let GF(q) denote a finite field with q elements. We encode subsets E ⊂ GF(q)
2
using q2 Boolean variables in a straightforward way. The function POLY(q,s) maps E ⊂ GF(q)
2 to 1
iff there exists a polynomial p of degree at most s over GF(q) such that (a,p(a)) ∈ E for every
a ∈ GF(q).
Alon and Boppana proved that for s ≤ 1
2
 q
ln q the monotone complexity of this function is at
least qcs for some constant c. For simplicity, we choose q = 2n and s =  1
4
 q
log q  =  2n/2
4
√
n . In this
case, L+(POLY(q,s)) ≥ 2cq1/2
√log q.
We define fn as the verifier for this instance of POLY. The function fn takes q2 + sq = O(q2)
variables. The first q2 inputs encode a subset E ⊂ GF(q)
2, and the second sn inputs encode coefficients of the polynomial p of degree at most s over GF(q), each coefficient using n bits. The
value fn (E,p) = 1 iff (a,p(a)) ∈ E for all a ∈ GF(q). To implement the function fn, for each element a ∈ GF(q), we compute the value p(a) using finite field arithmetic. Each such computation
requires O(sn2) gates. Then, we use p(a) as a selector in a multiplexer to compute the value indicating whether (a,p(a)) is contained in E, choosing it from all the bits of the input E corresponding
to pairs of form (a,b). This multiplexer requires additional O(q) gates for each element a ∈ GF(q).
The result is the conjunction of the computed values for all a ∈ GF(q). The total size of the circuit
O(q2 + qsn2 + q) is linear in the size of the input.
The lower bound on the hazard-free complexity follows from the Alon-Boppana lower bound
and Lemma 4.10.
5 CONSTRUCTING K-BIT HAZARD-FREE CIRCUITS
In this section, we prove Corollary 1.10. We slightly improve on [22].
For a collection T of subsets of [n], denote by LT (f ) the minimum size of a circuit whose outputs coincide with ¯f whenever the set of input positions with unstable bits is a subset of a set in
the collection T . Thus, -monotonicity of natural functions implies that L(f ) = L∅ (f ) ≤ LT (f ) ≤
L{[n]}(f ) = Lu (f ). Excluding k-bit hazards therefore means that we consider T = (
[n]
k ), i.e., T contains all subsets of [n] with exactly k elements. The minimum circuit depth DT (f ) is defined
analogously.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.       
25:14 C. Ikenmeyer et al.
As the base case of our construction, we construct circuits handling only fixed positions for the
(up to) k unstable bits, i.e., T = {S} for some S ∈ (
[n]
k ). This is straightforward with an approach
very similar to speculative computing [43, 44].
We take 2k copies of a circuit computing f . In the ith copy (0 ≤ i < 2k ), we fix the inputs in
S to the binary representation of i. Now, we use a hazard-free multiplexer to select one of these
2k outputs, where the original input bits from S are used as the select bits. A hazard-free k-bit
multiplexer of size O(2k ) can be derived from the 1-bit construction given in Figure 1(b).
Lemma 5.1. A k-bit multiplexer MUXk receives inputs x ∈ B2k
and s ∈ Bk . It interprets s a number
from [2k ] and outputs xs . There is a hazard-free circuit for MUXk of size 6(2k − 1) and depth 4k.
Proof. A hazard-free MUX1 of size 6 and depth 4 is given in Figure 1(b); its correctness is verified
by a simple case analysis. From a hazard-free MUXk and the hazard-free MUX1, we construct a hazardfree MUXk+1 circuit C as follows:
MUXk+1 (x1,..., x2k+1 ;s1,...,sk+1) = MUX1 ( MUXk (x1,..., x2k ;s1,...,sk ),
MUXk (x2k+1,..., x2k+1 ;s1,...,sk ); sk+1).
One can readily verify that the resulting Boolean function is MUXk , and it has the desired circuit
size and depth by construction. To show that this circuit for MUXk+1 is hazard-free, we make a case
distinction.
If sk+1 is stable, w.l.o.g. sk+1 = 0, then C outputs MUXk (x1,..., x2k ;s1,...,sk ), since MUX1 is
hazard-free. Thus, if MUXk+1 has a hazard at (x1,..., x2k+1 ;s1,...,sk , 0), then MUXk has a hazard
at (x1,..., x2k ;s1,...,sk ). But by the induction hypothesis, MUXk is hazard-free.
Now, we consider the case sk+1 = u. For the sake of contradiction, assume that MUXk+1 has a hazard at (x1,..., x2k+1 ;s1,...,sk , u). Then all resolutions (x 
1,..., x 
2k+1 ;s
1,...,s
k ,s
k+1) ∈ B2k+1+k+1
of (x1,..., x2k+1 ;s1,...,sk , u) yield MUXk+1 (x 
1,..., x 
2k+1 ;s
1,...,s
k ,s
k+1) = b for the same b ∈ B.
By construction of C this implies that
MUXk (x 
1,..., x 
2k ;s
1,...,s
k ) = b = MUXk (x 
2k+1
,..., x 
2k+1 ;s
1,...,s
k ) .
By the induction hypothesis, MUXk is hazard-free. Thus, we can conclude that
MUXk (x1,..., x2k ;s1,...,sk ) = b = MUXk (x2k+1,..., x2k+1 ;s1,...,sk ) .
This implies MUXk+1 (x1,..., x2k+1 ;s1,...,sk , u) = b, because MUX1 is hazard-free. This is a contradiction to MUXk+1 having a hazard at (x1,..., x2k+1 ;s1,...,sk , u).
Putting both cases together, we conclude that MUXk+1 is hazard-free.
Lemma 5.2. Let f : Bn → B and S ⊆ [n] with |S | = k. Then L{S }(f ) < 2k (L(f ) + 6) and
D{S }(f ) ≤ D(f ) + 4k.
Proof. For every assignment a ∈ B|S |
, compute дa = f (x |
S←a), where x |
S←a is the bit string
obtained by replacing in x the bits at the positions S by the bit vector a. We feed the results and
the actual input bits from indices in S into the hazard-free k-bit MUX from Lemma 5.1 such that
for stable values the correct output is determined. The correctness of the construction is now
immediate from the fact that the MUX is hazard-free.
Concerning the size bound, for each a ∈ B|S |
, we have L(дa) ≤ L(f ). Using the size bound for
the MUX from Lemma 5.1, the construction thus has size smaller than 2k (L(f ) + 6). Similarly, we
combine D(дa) ≤ D(f ) with the depth of the MUX to obtain the bound D{S }(f ) ≤ D(f ) + 4k.
Using this construction as the base case, we increase the number of sets (i.e., possible positions
of the k unstable bits) our circuits can handle.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.          
On the Complexity of Hazard-free Circuits 25:15
Theorem 5.3. Let T = (
[n]
k ). Then,
LT (f ) ≤
	
ne
k

2k
(L(f ) + 7) and DT (f ) ≤ D(f ) + 2k (	logn
 + 2).
Proof. Put an ordering on T and let Ti be the ith element in T , 1 ≤ i ≤ |T |. Denote by Cij ,
1 ≤ i, j ≤ |T |, a circuit whose outputs coincide with ¯f whenever all unstable bits are from Ti ∪Tj .
Set ai := and(Ci1,...,Ci |T |) (where a hazard-free and with fan-in |T | is implemented by a binary
tree of fan-in 2 ands of minimum depth). We claim that o := or(a1,..., a|T |) (again a hazard-free
version implemented by a tree) coincides with ¯f whenever there are at most k unstable bits.
To show the claim, assume that x ∈ Tn is stable except at indices from some Ti ∈ (
[n]
k ). Assume
first that ¯f (x) = 1. Then ai = and(1,..., 1) = 1. This implies o = 1, because the |T |-bit or is hazardfree and one of its inputs is a 1. Next, suppose that ¯f (x) = 0. Then, for each i ≤ |T |, Cii (x) = 0.
Hence, ai = 0, because the |T |-bit and is hazard-free and one of its inputs is a 0. It follows that
o = or(0,..., 0) = 0. The case that ¯f (x) = u is trivial; hence, the claim holds.
The above circuit contains the circuits Cij and additionally |T |
2 − 1 many gates (a binary tree of
ands and ors). By Lemma 5.2, each Cij can be implemented with size 22k (L(f ) + 6), as |Ti ∪Tj | ≤
2k. Moreover, using exactly all subsets of size 2k, we use at most ( n
2k ) ≤ ( en
2k )
2k different such
circuits. This results in a gate complexity of at most
	
en
k

2k
(L(f ) + 6) +

n
k
2
− 1 <
	
en
k

2k
(L(f ) + 7).
The depth of the circuit is D(f ) + 4k from the Cij plus the depth of the trees, which is 	log(|T | −
1)
 ≤ k 	logn
.
Corollary 1.10 simply rephrases the theorem without the terminology introduced in this section.
6 COMPLEXITY OF HAZARD DETECTION
In this section, we show that detecting hazards and detecting 1-bit hazards are both NP-complete
problems, see Theorem 6.5 below. The arguments are a bit subtle, and thus we introduce several
auxiliary hazard detection problems.
Definition 6.1. We say that a circuit C with n inputs has a fixed hazard at position i ∈ [n] if C has
a 1-bit hazard at a tuple x ∈ Tn with xi = u.
We fix some reasonable binary encoding of circuits and define the following languages:
• FixedHazard = {C,i | C has a fixed hazard at position i}
• OneBitHazard = {C | C has a 1-bit hazard}
• Hazard = {C | C has a hazard}
A circuit C is called satisfiable if there is a Boolean input for which C outputs 1. Otherwise,
C is called unsatisfiable. We define a promise problem UnsatFixedHazard: Given an unsatisfiable
circuit C and i ∈ [n], accept if C has a fixed hazard at position i.
Lemma 6.2. UnsatFixedHazard is NP-hard.
Proof. We reduce from circuit satisfiability as follows: To decide if a circuit C on n inputs is
satisfiable, construct a circuit C = C ∧ (xn+1 ∧ ¬xn+1) where xn+1 is a new variable. Note that C
is unsatisfiable by construction. We claim that C is satisfiable if and only if C has a fixed hazard
at position n + 1.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019. 
25:16 C. Ikenmeyer et al.
“⇒”: Let a be an assignment that satisfies C. Then C evaluates to u on input (a, u) and hence has
a fixed hazard at position n + 1.
“⇐”: If C is unsatisfiable, then C
(a,y) = 0 for all a ∈ Bn, y ∈ T, and hence does not have a fixed
hazard at position n + 1.
Lemma 6.3. The languages FixedHazard, OneBitHazard, and Hazard are NP-hard.
Proof. Since UnsatFixedHazard is NP-hard, the more general problem FixedHazard is also NPhard.
We show that deciding the languages OneBitHazard and Hazard is at least as hard as solving UnsatFixedHazard. Let C(x1,..., xn ) be an unsatisfiable circuit. Construct the circuit C =
C(x1,..., xn ) ⊕ x2 ⊕···⊕ xn. We claim that C has a hazard if and only if C has a fixed hazard at
position x1.
“⇒”: Suppose C has a hazard. Note that since C computes the constant 0 function, C computes
x2 ⊕···⊕ xn. If any of the input variables x2,..., xn has value u, thenC correctly outputs u.
Thus, C can have a hazard only on inputs a ∈ Tn that have exactly one u occurring in the
input position 1. In this case C(a) = u, because otherwise C
(a) would be a Boolean value.
Hence, C has a fixed hazard at position 1.
“⇐”: If C has a fixed hazard at position 1, then by definition, C outputs u when x1 = u while all
other inputs are stable. In this case, C also outputs u on this input. This is a hazard, since
the Boolean function computed by C does not depend on x1.
Thus, Hazard is NP-hard.
Note that in the first part of this proof, we actually proved that for the circuit C all hazards are
1-bit hazards. So, the language OneBitHazard is also NP-hard.
Lemma 6.4. The languages FixedHazard, OneBitHazard, and Hazard are in NP.
Proof. For FixedHazard and OneBitHazard, we can take the input on which the circuit has a
hazard as a witness. The verifier then has to check that the circuit actually outputs u on this input
and that the outputs on the two stable inputs obtained by replacing u by 0 and 1 match.
For Hazard, the verifier cannot check the definition directly, since the number of resolutions
can be exponential. However, if a circuit C has a hazard, then there exists an input x ∈ Tn with
C(x) = u such that on the inputs x (0) and x (1) that are obtained from x by replacing the leftmost u
by 0 and 1, respectively, the circuit C outputs the same stable value b. This can be seen as follows.
Let HC ⊂ Tn be the set of all inputs on which C has a hazard. Any element x that is maximal in
HC with respect to  satisfies the requirement: since x is a hazard,C(x) = u and the output ofC on
all resolutions of x is the same stable value b. Thus, the output of C on all resolutions of x (0) and of
x (1) is b. Since x is maximal, both x (0) and x (1) do not lie in HC, which impliesC(x (0)
) = C(x (1)
) = b.
Such x with C(x) = u and C(x (0)
) = C(x (1)
) = b can be used as a witness for Hazard. On the other
hand, if there exists an input x ∈ Tn that satisfies the above condition, then the circuit C has a
hazard at x.
From Lemmas 6.3 and 6.4, we conclude:
Theorem 6.5. The languages FixedHazard, OneBitHazard, and Hazard are NP-complete.
7 FUTURE DIRECTIONS
Hazard-free complexity is an interesting subject that arises in practice when constructing physical circuits. Theorem 1.3 sends the strong message that hazard-free complexity is of interest even
without its application in mind, because it is a natural generalization of monotone complexity.
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.   
On the Complexity of Hazard-free Circuits 25:17
Section 5 hints toward the fact that there is a rich intermediate landscape of k-hazard free circuits to be analyzed for different ranges of k. This can potentially be very illuminating for our
understanding of the nature and limits of efficient computation in general.
Given the lower bound corollaries to Theorem 1.3 and the circuit construction in Corollary 1.10,
one dangling open question is the fixed parameter tractability of k-hazard-free circuits: Does there
exist a function φ such that for all sequences of Boolean functions fn : Bn → B with Boolean
complexity L(fn ) there exist k-hazard-free circuits of size φ(k) · poly(n, L(fn ))?
A further direction of interest is to understand the power of masking registers [16], both in
terms of computational power and efficiency. It is neither known precisely which functions can be
computed by clocked circuits within r rounds, nor is it clear whether a factor Ω(k) overhead for
eliminating hazards with masking registers is necessary.
APPENDIX
A CIRCUITS WITH DIFFERENT BASIC GATES
In the main part of this article, we used circuits with and-, or-, and not-gates, because this is
one of the standard models in circuit complexity. But, we have also already seen that the circuit
transformations we use for proving lower bounds rely only on the general construction of the
derivative and can be performed on circuits with arbitrary gates, not just and-, or-, and not-gates.
In this Appendix, we show that any other functionally complete set (in the sense of, e.g., [14])
can be used to give an equivalent theory of hazard-free complexity and natural functions, see
the upcoming Corollary A.3. A priori it is not obvious that every function can be implemented
by a hazard-free circuit over some set of gates, even if the set of gates is functionally complete
in the Boolean sense. We prove that everything works properly if we allow constant input gates.
This subtlety is unavoidable, since any nontrivial natural function outputs u if all inputs are u, so
any circuit without constant gates also has this property. Therefore, the constant function is not
computable by hazard-free circuits without the use of constant gates.
Reference [6, Theorem 2] shows that every natural function can be implemented over the set
of functions Φ = {and, or, not, 1}. Using the fact that a hazard-free implementation of or can be
achieved via the standard De Morgan implementation x or y = not((not x) and (not y)), it follows
that
every natural function can be implemented over the set of functions {and, not, 1}. (A.1)
A Boolean function f : Bn → B is called linear if there exist a0,..., an ∈ B with f (x1,..., xn ) =
a0 ⊕ a1x1 ⊕···⊕ anxn. Otherwise, f is called nonlinear. The composition of linear functions is
linear, but not all Boolean functions are linear. Thus, every functionally complete set must contain
a nonlinear function.
Variants of the following lemma are often used as a part of proof of Post’s theorem characterizing
functionally complete systems.
Lemma A.1. Let f : Bn → B be a nonlinear Boolean function. Then, n ≥ 2. Moreover, by substituting constants for some input variables of f , we can obtain a function of 2 variables of the form
(x1 ⊕ c1)(x2 ⊕ c2) ⊕ c0.
Proof. Using the fact that over the field F2 with two elements, we have xi and xj = xi · xj and
not xi = xi ⊕ 1, we can represent f as a polynomial over F2. Using that (xi )
k = xi for k ≥ 1, we
can represent f in its algebraic normal form,
f (x1,..., xn ) =

I ⊂[n]
aI

i ∈I
xi,
Journal of the ACM, Vol. 66, No. 4, Article 25. Publication date: August 2019.
25:18 C. Ikenmeyer et al.
where each aI ∈ B. We call I a monomial and call |I | its degree. Since f is nonlinear, there is at
least one monomial of degree at least 2 with nonzero coefficient aI . Thus, we proved n ≥ 2. Among
monomials of degree at least 2, choose one monomial of minimal degree and set all the variables
not contained in this monomial to 0. Without loss of generality, the chosen monomial is x1 ··· xt ,
t ≥ 2. The resulting function has the form
x1 ... xt ⊕ a1x1 ⊕···⊕ atxt ⊕ a0.
Setting all variables except x1 and x2 to 1, we obtain x1x2 ⊕ a1x1 ⊕ a2x2 ⊕ a
0, or (x1 ⊕ c1)(x2 ⊕
c2) ⊕ c0 where c1 = a2, c2 = a1 and c0 = a
0 ⊕ a1a2.
Theorem A.2. Let Φ be a set of natural functions such that their restrictions to B form a functionally complete set. Suppose Φ contains an extension of a nonlinear Boolean function that is free of 1-bit
hazards. Then every natural function can be computed by a circuit over Φ using the constant 1.
Proof. In the light of (A.1), it is enough to show that hazard-free circuits for not and and can
be implemented over Φ. The statement is trivial for the negation: since not has only one natural
extension, any circuit that computes it is automatically hazard-free. Using not, we can obtain the
constant 0 from the constant 1.
By Lemma A.1, we obtain from the 1-hazard-free nonlinear function contained in Φ a function
of the form (x1 ⊕ c1)(x2 ⊕ c2) ⊕ c0 by substituting constants 0 and 1 into this nonlinear function.
Constant substitution does not introduce hazards. Since not x = x ⊕ 1, we can transform the circuit
C computing (x1 ⊕ c1)(x2 ⊕ c2) ⊕ c0 to a circuit C computing x1x2 by placing not on input xi if
ci = 1 and on the output if c0 = 1. In other words, C
(x1, x2) = C(x1 ⊕ c1, x2 ⊕ c2) ⊕ c0.
Let us check that C is hazard-free. The circuit C is computing the conjunction and thus can
have hazards only on two inputs: (0, u) and (u, 0). If C
(0, u) = u, then C(c1, u) = u. This is a 1-bit
hazard, since (c1 ⊕ c1)(x ⊕ c2) ⊕ c0 = c0 for all x ∈ B. The other case is analogous.
Corollary A.3. Given a functionally complete set of Boolean functions, let Φ be the set of their
hazard-free extensions. Every natural function can be computed by a circuit over Φ using the constant 1.
Proof. Since a functionally complete set cannot only consist of linear functions, at least one
function must be nonlinear. A hazard-free function in particular does not have a 1-hazard. Thus,
Theorem A.2 applies.  