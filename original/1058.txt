Ramsey theory assures us that in any graph there is a clique or independent set of a certain size, roughly
logarithmic in the graph size. But how difficult is it to find the clique or independent set? If the graph is given
explicitly, then it is possible to do so while examining a linear number of edges. If the graph is given by a
black-box, where to figure out whether a certain edge exists the box should be queried, then a large number of
queries must be issued. But what if one is given a program or circuit for computing the existence of an edge?
This problem was raised by Buss and Goldberg and Papadimitriou in the context of TFNP, search problems
with a guaranteed solution.
We examine the relationship between black-box complexity and white-box complexity for search problems with guaranteed solution such as the above Ramsey problem. We show that under the assumption
that collision-resistant hash function exists (which follows from the hardness of problems such as factoring,
discrete-log, and learning with errors) the white-box Ramsey problem is hard and this is true even if one is
looking for a much smaller clique or independent set than the theorem guarantees. This is also true for the
colorful Ramsey problem where one is looking, say, for a monochromatic triangle.
In general, one cannot hope to translate all black-box hardness for TFNP into white-box hardness: we show
this by adapting results concerning the random oracle methodology and the impossibility of instantiating it.
Another model we consider is that of succinct black-box, where the complexity of an algorithm is measured
as a function of the description size of the object in the box (and no limitation on the computation time). In
this case, we show that for all TFNP problems there is an efficient algorithm with complexity proportional
to the description size of the object in the box times the solution size. However, for promise problems this is
not the case.
Finally, we consider the complexity of graph property testing in the white-box model. We show a property
that is hard to test even when one is given the program for computing the graph (under the appropriate
assumptions such as hardness of Decisional Diffie-Hellman). The hard property is whether the graph is a
two-source extractor.
CCS Concepts: • Theory of computation → Computational complexity and cryptography; Complexity classes; Cryptographic protocols;
Additional Key Words and Phrases: Ramsey theory, white-box hardness, black-box hardness
1 INTRODUCTION
Consider a setting where one is given a large object (e.g., a graph) and the goal is to find some local
pattern (e.g., a certain subgraph) in the object or determine whether it satisfies some property. We
investigate the relationship between the black-box setting, where access to the object is via oracle
queries, and the white-box setting, where access to the object is given by a program or a circuit,
in the context of search problems in which a solution is guaranteed1 to exist and in the context of
property testing.
The Ramsey Problem. The Ramsey number R(n) is the minimal number such that any graph on
R(n) vertices contains a clique or independent set of size n. The Ramsey theorem states that for
any n, it holds that R(n) is finite and moreover that R(n) ≤ 22n. This guarantee raises the following
question: Given a graph with 22n nodes, how difficult is it to find n nodes that are either a clique or
an independent set?
The standard proof of Ramsey’s theorem is actually constructive and yields an algorithm that
finds the desired clique or independent set but explores a linear (in the graph size) number of
nodes and edges. Is it necessary to explore a large portion of the graph? This of course depends
on the representation of the graph and the computational model. In the black-box model, where
the access to the graph is merely by oracle queries, Impagliazzo and Naor (1988) observed that
any randomized algorithm must make at least Ω(2n/2) queries before finding the desired clique or
independent set. This was based on the fact that a random graph on 22n vertices has no clique or
independent set of size 4n with high probability (see Section 2.2).
In this work, we are interested in the white-box model,2 where the above question is phrased
as: Given a Boolean circuit encoding the edges of a graph with 22n nodes, how difficult is it to find n
nodes that are either a clique or an independent set? This question has been explicitly asked by Buss
(2009) and Goldberg and Papadimitriou (2018) in the context of search problems in the complexity
class TFNP. The class TFNP, defined by Megiddo and Papadimitriou (1991), is the class of all search
problems for which a solution is guaranteed to exist for every instance and verifying a solution
can be done efficiently. Thus, the problem where the input is a graph defined by a circuit and the
target is to find a clique or an independent set (of appropriate sizes) belongs to the class TFNP.
Our first result is an answer to this question. We show that under the assumption that collisionresistant hash functions3 exist, there exists an efficiently samplable distribution of circuits (circuits
on 4n inputs representing graphs on 22n vertices), for which finding a clique or independent set
of size n is impossible for any polynomial-time (in n) algorithm. The proof goes along the lines of
Krajícek (2005), who showed a similar result in the context of the proof complexity of the Ramsey
problem.
We also prove a white-box lower bound of a similar flavor for a related problem known as the
colorful Ramsey problem. While a graph can be viewed as the edges colored in one color and
the non-edges in another, (a simple version of) the colorful Ramsey theorem says that given the
1We are not talking about promise problems, but rather when there is a proof that the pattern exists.
2An example of a graph given as a white-box is the Hadamard graph, where the two inputs are treated as vectors over
GF[2] and there is an edge if and only if the inner product between them is 1. 3A collision- resistant hash is a hash function that shrinks by one bit such that it is hard to find two inputs that hash to the
same output.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.
White-Box vs. Black-Box Complexity of Search Problems 34:3
complete graph on 22n vertices and any coloring of its edges using roughly n/ logn colors, there
must exist a monochromatic triangle (see Section 2.2 for the precise statement). The question is:
given a circuit that represents such a colored graph, what is the computational complexity of finding a monochromatic triangle? We show that this is also hard: assuming collision-resistant hash
functions, finding a monochromatic triangle is impossible for polynomial-time (in n) algorithms.
On Necessity of Collision Resistance. We complement our result by showing that a form of collision resistance is necessary for the hardness of a variant of the Ramsey problem. Concretely,
we consider the bipartite version of the Ramsey problem where the goal is to find a bi-clique or
bi-independent set in a bipartite graph. We show that the hardness of this problem implies the existence of a new notion of collision resistance we call multi-collision resistant hash functions. These
functions guarantee that it is hard to find multiple inputs that hash to the same output.4 Additionally, we show the other direction: the hardness of the bipartite Ramsey problem (and the standard
Ramsey problem) can be based on the existence of multi-collision-resistant hash functions. That
is, there is an equivalence between the hardness of the bipartite Ramsey problem and the existence
of multi-collision-resistant hash functions.
Recently, the notion of multi-collision resistance was studied in several subsequent
works (Berman et al. 2018; Bitansky et al. 2017; Komargodski et al. 2018; Komargodski and Yogev
2018) showing that this primitive is useful for various cryptographic applications, including statistically hiding succinct commitment schemes and round-efficient zero-knowledge protocols.
Impossibility of a Generic Transformation. In the context of search problems, the black-box model
(in which the algorithm has only query access to the function) has been extensively studied, as it
gives hope to prove unconditional query lower bounds (see Lovász et al. (1995) for example).5 It is
tempting to try and translate any query lower bound (in the black-box model) into a white-box
lower bound using cryptographic assumption. We show that such a transformation is impossible
to achieve in general for search problems in TFNP.
6 Specifically, we present a search problem in
TFNP for which the black-box complexity is exponential; but for any white-box implementation,
there exists an algorithm that finds the solution in polynomial time. Our impossibility result is
unconditional and does not rely on any cryptographic assumption. It is based on ideas stemming
from Canetti et al. (2004) concerning limitations of transferring cryptographic schemes that use
random oracles to ones that do not appeal to them (see below). Specifically, the construction utilizes
the work of Goldwasser and Kalai (2003) on signature schemes using the Fiat-Shamir paradigm.
The Succinct Black-box Model. In the black-box model, as we have discussed, solving the Ramsey problem requires polynomially many queries in the size of the graph (i.e., exponential in the
subgraph we are looking for) and this is also the case for many other problems in TFNP, such as
PPP, PLS, PPAD, and CLS (see Beame et al. (1998) and Hubácek and Yogev (2017)). In this model,
the complexity measure is the number of queries needed to solve the problem and the running
time of the algorithm accessing the object via queries is unbounded. In contrast, in the white-box
model, the complexity is measured as a function of the size of the representation of the object.
We consider the question of whether the complexity should depend on the representation size of
the function to obtain hardness results and study the succinct black-box model (see Definition 2.4),
4Any collision-resistant hash function is also multi-collision-resistant, but the other direction is not known.
5Over the years, several “lifting” techniques were developed to translate query lower bounds into lower bounds in other
models. Perhaps the most famous example is the lifting technique of Raz and McKenzie (1999), Sherstov (2011), and Göös
et al. (2015), which has been very useful in translating query lower bounds into communication complexity lower bounds. 6We note that our impossibility result only rules out a general transformation for all search problems in TFNP. It is an
interesting question to find specific problems in TFNP that admit such a transformation.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.
34:4 I. Komargodski et al.
Table 1. A Summary of Our Results on the Complexity of Search Problems
Model R Problem Ramsey-like TFNP
Black-Box (BB) Hard (Section 5) Hard Hard†
White-Box Easy (Section 5) Hard (Section 3) Hard‡
Succinct Black-Box Easy (Section 6) Easy (Section 6) Easy (Section 6)
R is the problem defined in Section 5. The term “Ramsey-like” problems refers to the problems we
consider in Section 3, including Ramsey’s problem, the colorful Ramsey problem, and the bipartite Ramsey problem. The entry marked by  follows from Impagliazzo and Naor (1988), the entry
marked by † follows from Hirsch et al. (1989), and the entry marked by ‡ follows from Papadimitriou
(1994) and Hubácek et al. (2017).
which lies between the black-box and white-box model. In this model, the complexity is measured
as a function of the size of the representation of the object but the algorithm is unbounded in
running-time and has only black-box access to the object. More precisely, the number of queries
is measured as a function of the representation size of the object in the box. An efficient algorithm
would perform polynomially many queries in the representation size.
For this model, we show that any problem in TFNP is easy (and in particular, the Ramsey problem). That is, there exists a (deterministic) algorithm that performs only a polynomial number of
queries (in the size of the representation of the function) and finds a solution. One interesting
take-away from this result is that any exponential query lower bound (in the black-box model) for
a problem in TFNP must use instances of functions (i.e., “boxes”) of exponential size. In Table 1,
we give a short summary of the above results.
White-box Graph Property Testing Lower Bounds. Property testing studies problems of the type:
given the ability to perform queries concerning local properties of an object, decide whether the
object has some (predetermined) global property, or it is far from having such a property. The
complexity of a problem is determined by the number of queries required for an algorithm to
decide the above correctly.
In all classical works in this field, access to the tested object is given via queries to a blackbox. We study the complexity of property testing given a white-box representation. The object is
represented implicitly as a program or a circuit and is given to the solver. The solver has to decide
whether the object that is encoded in the circuit has a predefined property or not.
We show that cryptographic assumptions can be useful to prove that meaningful properties
of graphs are hard to test in the white-box model by any efficient algorithm. The cryptographic
assumption we rely on is the existence of a collection of lossy functions (Peikert and Waters 2011).
A collection of lossy functions consists of two families of functions. Functions in the first family
are injective, whereas functions in the second family are lossy, namely the size of their image is
significantly smaller than the size of their domain. The security requirement is that a description
of a randomly chosen function from the first family is computationally indistinguishable from a
description of a randomly chosen function from the second family.
We show that there exists a graph property such that, assuming a collection of lossy functions,
there exists an efficiently samplable distribution over implicitly represented graphs over 2n vertices
for which testing whether the graph has the property or is far from having it cannot be decided by
any polynomial-time (in n) algorithm. The property is whether the graph is a two-source extractor.
1.1 Graph-hash Product
Our white-box hardness results are based on a technique we call “the graph-hash product,’ where
we generate a new graph from an existing one by embedding the nodes of the new graph via a
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.  
White-Box vs. Black-Box Complexity of Search Problems 34:5
hash function (see Definition 3.2). Given a graph G = (V, E) and a compressing hash function h,
we define a (much larger) graph G = (V
, E
) such that (u
,v
) ∈ E if and only if (h(u),h(v)) ∈ E.
Depending on the properties of the hash function, we get various results. The key property of
this product operation is that if the hash function is collision-resistant, we get that the new graph
looks locally as the original one. All of our hardness results, including the hardness of (all variants
of) the Ramsey problem and the hardness of the graph property testing, are based on variants of
this technique.
We mention that additional hardness results can be shown using our product technique. Also,
the technique is not restricted to graph problems. For example, assuming collision-resistant hash
functions, we prove hardness for finding a sunflower configuration in a large family of sets of the
same size. This is a natural (total) search problem that arises from the famous sunflower lemma of
Erdös and Rado (1960). We refer to Appendix A for more information.
A similar graph-hash product was used by Krajícek (2001) relating the proof complexity of the
weak pigeonhole principle and the proof complexity of the Ramsey theorem.
1.2 Cryptographic Assumptions and White-box Lower Bounds
For some search problems, it is known how to obtain hardness in the white-box model under
certain cryptographic assumptions. One of the first examples is due to Papadimitriou Papadimitriou (1994), who showed that the hardness of the class PPP (a subclass in TFNP) can be based
on the existence of one-way permutations (the hardness can also be based on the existence of
collision-resistant hash functions). We refer to Hubácek et al. (2017) for more information about
the assumptions that lead to white-box hardness in TFNP.
Obfuscation. It has been recently shown that program obfuscation is very useful for proving
white-box lower bounds for search problems. An obfuscator transforms a given program (say,
described as a Boolean circuit) into another “scrambled” circuit that is functionally equivalent by
“hiding” its implementation details. One could hope to take the underlying black-box instance,
obfuscate it, and use this obfuscated version as the white-box instance. Obfuscation is a strong
and (still) somewhat controversial assumption (see Ananth et al. (2016) for a discussion), but if it
could be used for a general transformation, then we would get a large class of white-box hardness
results. However, there are a few obstacles in applying such an approach: First, Canetti et al. (2004)
(followed by the work of Goldwasser and Kalai (2003)) showed that it is impossible to generically
translate security of cryptographic primitives in the random oracle model into primitives in the
standard setting. Second, ideal program obfuscators (“virtual black-box”) do not exist for general
functionalities (Barak et al. 2012; Hada 2000), so we have to work with weaker primitives such as
indistinguishability obfuscation (Barak et al. 2012; Garg et al. 2013; Sahai and Waters 2014). One
prominent instance of using indistinguishability obfuscation to prove white-box lower bounds
was shown in the context of PPAD-hardness (Bitansky et al. 2015; Garg et al. 2016; Hubácek and
Yogev 2017; Komargodski and Segev 2017), but it is hard to see how to use indistinguishability
obfuscation for a more general transformation from black-box hardness to white-box hardness.
Our white-box hardness results do not use obfuscation at all and as such bypass the above issues.
Furthermore, our techniques show that weaker (and much better studied) primitives can be used
to hide information in a meaningful way.
2 PRELIMINARIES
Unless stated otherwise, the logarithms in this article are base 2. For a distribution D, we denote
by x ← D an element chosen from D uniformly at random. For an integer n ∈ N, we denote by
[n] the set {1,...,n}.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.      
34:6 I. Komargodski et al.
A function negl : N → R+ is negligible if for every constant c > 0, there exists an integer Nc
such that negl(n) < n−c for all n > Nc . Two sequences of random variables X = {Xn }n∈N and Y =
{Yn }n∈N are computationally indistinguishable if for any non-uniform probabilistic polynomialtime algorithm A, there exists a negligible function negl(·) such that | Pr[A(1n,Xn ) = 1]
− Pr[A(1n,Yn ) = 1]| ≤ negl(n) for all n ∈ N.
2.1 Search Problems in the Black-box and White-box Models
Let Fn = {f : {0, 1}
n → {0, 1}
n } be the class of all circuits f mapping n bits into n bits. We give a
definition of a search problem for the family Fn.
7
Definition 2.1. A search problem S is a relation on 2q(n) tuples. More precisely, S = ∪∞
n=1Sn,
where Sn ⊆ ({0, 1}
n )
q(n) × ({0, 1}
n )
q(n) for a polynomial q(·), such that: (i) for all f ∈ Fn, there
exist x1,..., xq(n) ∈ {0, 1}
n for which (x1,..., xq(n), f (x1),..., f (xq(n))) ∈ S, and (ii) S is computable in polynomial time in n. The class of all such search problems is denoted TFNP.
The tuple (x1,..., xq(n)) is called the witness (i.e., the solution), and q(n) is the witness/solution
size. In general, a witness is not necessarily given as a sequence of points in the domain {0, 1}
n but
notice that any string can be encoded as such a sequence and so our definition is without loss of
generality.
We mainly focus on three models of computation that differ either by the representation type
of the function f ∈ Fn or by the complexity measure of the solver. The models that we define
and study are the black-box model, the white-box model, and a new hybrid model we call succinct
black-box. We also mention a fourth model we call the efficient-succinct black-box model. For the
rest of this subsection, fix a polynomial q = q(n) and a search problem S ⊆ ({0, 1}
n )
q × ({0, 1}
n )
q.
In the black-box model, an algorithm is required to solve the search problem S while given only
oracle access to the function f . That is, the algorithm provides queries x and gets back the results
y = f (x). The black-box complexity of a search problem S is the number of queries needed to
solve a search problem in the worst-case, while the running time is unbounded. This model was
introduced and studied by Lovász et al. (1995).
Definition 2.2 (Black-box complexity). The black-box complexity of S, denoted by bbc(S), is
bounded by a function T (·) if there exists an algorithm A that for sufficiently large n and any
f ∈ Fn, makes at most T (n) queries to f and outputs x1,..., xq such that (x1,..., xq, f (x1),...,
f (xq )) ∈ S.
In the white-box model, an algorithm is required to solve the search problem S while given
an explicit representation of the function f (as a circuit). The white-box complexity of S is the
running time (as opposed to number of queries) needed (measured as a function of the size of the
representation) to solve a search problem in the worst case. In the white-box setting, we are mostly
interested in solvers that run in polynomial-time in the size of the function.
Definition 2.3 (White-box complexity). The white-box complexity of S, denoted by wbc(S), is
bounded by a functionT (·) if there exists an algorithm A that for sufficiently large n, given f ∈ Fn
(as a circuit) runs in time T (|f |), and outputs x1,..., xq such that (x1,..., xq, f (x1),..., f (xq )) ∈
S.
In the succinct black-box model, an algorithm is required to solve the search problem S while
given only oracle access to the function f ; however, as opposed to the black-box model, the succinct black-box complexity of a search problem S is measured by the number of queries required
7We restrict our attention to the family Fn of length-preserving functions for simplicity.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.
White-Box vs. Black-Box Complexity of Search Problems 34:7
Table 2. A Summary of the Different Models Defined
Model Function Access Solver Running Time Rep. Size
Black-Box (BB) Oracle Unbounded Unbounded
White-Box Implicit Bounded Bounded
Succinct Black-Box Oracle Unbounded Bounded
Efficient-Succinct BB Oracle Bounded Bounded
to solve the problem as a function of the size of the representation of f . In particular, if f is represented succinctly by a polynomial-size (in n) circuit, then an efficient algorithm can perform only
a polynomial number of queries (but its running time is unbounded).
Definition 2.4 (Succinct black-box complexity). The succinct black-box complexity of S, denoted
by sbbc(S), is bounded by the function T (·) if there exists an algorithm A that for sufficiently
large n and any f ∈ Fn, makes at most T (|f |) queries to f and outputs x1,..., xq such that
(x1,..., xq, f (x1),..., f (xq )) ∈ S.
We also consider a model we call the efficient-succinct black-box model, which is similar to the
succinct black-box model, except that the solver’s running is bounded (in the representation size).
In Table 2 below, we summarize the differences between the models.
2.2 Ramsey Theory
In this section, we recall some basic definitions and facts from Ramsey theory and derive several
bounds that will be useful for us later. We refer to Graham et al. (1990) for a thorough introduction
and history of Ramsey theory.
A Ramsey graph is a graph that contains no clique or independent set of some predefined sizes.
Definition 2.5 (Ramsey graphs). A graph on N vertices is called (s,t)-Ramsey if it contains no
independent set of size s and no clique of size t. A graph is called k-Ramsey if it is (k, k)-Ramsey.
The classical result of Ramsey gives an upper bound on the size of a graph that does not contain
either an independent set or a clique of some predefined size.
Proposition 2.6. For any s,t > 1, there exists a number R(s,t) < ∞ such that any graph on R(s,t)
vertices is not (s,t)-Ramsey. Moreover,
R(s,t) ≤ R(s − 1,t) + R(s,t − 1) ≤

s + t − 2
s − 1

.
Plugging in s = t = (log N)/2, we get that
R((log N)/2, (log N)/2) ≤
 log N
(log N)/2

≤ 2log N = N,
where the inequality follows by the inequality 
2k
k

≤ 22k . As a corollary of Proposition 2.6, we
get:
Proposition 2.7. Every graph on N vertices has either a clique or an independent set of size 1
2 log N.
A well-known (non-explicit) construction of a Ramsey graph was given by Erdös (1947) as
one of the first applications of the probabilistic method. He showed that most graphs on N vertices are (2 log N)-Ramsey (see also the book of Alon and Spencer (2008)). It was observed by
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.    
34:8 I. Komargodski et al.
Naor (1992) that Erdös’s proof actually gives a stronger statement: not only are most graphs
(2 log N)-Ramsey, but such graphs can actually be sampled with relatively few bits of randomness
(i.e., via a limited-independent family8 or a small-bias probability space (Naor and Naor 1993)). For
a function д : {0, 1}
n × {0, 1}
n → {0, 1}, we define the corresponding graph G on n vertices where
for any u < v (lexicographic order) it holds that (u,v) is an edge in G iff д(u,v) = 1.
Proposition 2.8. A graph on N vertices sampled via a (2 log2 N)-wise independent hash function
is a (2 log N)-Ramsey graph with probability 1 − 1/N Ω(log log N )
.
For completeness, the proof of this Proposition is given in Appendix B.2. No explicit construction
of graphs matching these parameters is known, but see Section 3.2 for the state-of-the-art.
Given that there are constructions of k-wise independent functions mapping {0, 1}
n × {0, 1}
n →
{0, 1} that are succinct (the size of the representation is polynomial in n and k even for n output
bits), the proposition implies that it is possible to sample a Ramsey graph (w.h.p.) with a succinct
representation, i.e., the description length of the graph is polynomial in n. Furthermore, since
computing a (2 log2 N)-wise independent function can be done in time proportional to the size of
the description, it is possible to sample a circuit that implicitly represents the graph.
The property of a graph being (s,t)-Ramsey can be equivalently phrased as a coloring property
of the complete graph KN on N vertices with two colors. Specifically, the function that defines
whether an edge exists can be thought of as a coloring of the full graph with two colors and the
existence of a clique or an independent set of size k is equivalent to the existence of a monochromatic subgraph of size k. This raises a natural generalization of the Ramsey property for graphs
with multiple colors.
Definition 2.9 (Colorful Ramsey graphs). A coloring ψ :

N
2

→ [m] of the full graph KN with m
colors is called (k1,..., km )-Ramsey if there is no monochromatic subgraph of size ki colored with
the color i, for every i ∈ [m].
The colorful Ramsey theorem provides, for a given number of colors, an upper bound on the
size of a clique such that any coloring must result with a monochromatic subgraph of a predefined
size.
Proposition 2.10. For any m and k1,..., km > 1, there exists a number R(k1,..., km ) < ∞ such
that any graph on R(k1,..., km ) vertices is not (k1,..., km )-Ramsey. Moreover,
R(k1,..., km ) ≤ 2 +
m
i=1
(R(k1,..., ki−1, ki − 1, ki+1,..., km ) − 1).
Based on Proposition 2.10, we can upper bound R(k1,..., km ) for various values of k1,..., km.
In particular, in the symmetric case where k1 = k2 ... km−1 = km, we get:
Proposition 2.11. For every k > 2 and m > 1, it holds that R(k,..., k 	
 mtimes
) ≤ mmk .
As a corollary of Proposition 2.11, we obtain a bound on the number of colors that ensure the
existence of a monochromatic subgraph of size k.
Proposition 2.12. Consider the full graph on N vertices. For every k < log N, and every coloring
ψ :

N
2

→ [m], where m = (log N )/k
log log N −log k , there exists a monochromatic subgraph of size k.
The proofs of Proposition 2.11 and 2.12 appear in Appendix B.1.
8A function family H = {h : D → R} is k-wise independent, if Prh←H [h(x1) = y1 ∨ h(x2) = y2 ∨ ... ∨ h(xk ) =
yk ] = 1/ |R|k , for every distinct x1, x2, ..., xk ∈ D and every y1, y2, ..., yk ∈ R.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.      
White-Box vs. Black-Box Complexity of Search Problems 34:9
2.3 Randomness Extractors
We consider random variables supported on n-bit strings. A random variable X is said to have
min-entropy k if for every x ∈ Supp(X) it holds that Pr[X = x] ≤ 2−k . Two random variables X
and Y are said to be ϵ-close if
Δ(X,Y )  1
2 ·


x
| Pr[X = x] − Pr[Y = x]|


≤ ϵ.
We say that a function Ext : {0, 1}
n × {0, 1}
n → {0, 1} is a (k, ϵ )-two-source extractor if given any
two independent distributions X and Y with min-entropy k (each), then the distribution Ext(X,Y )
is ϵ-close to the uniform distribution on one bit (Chor and Goldreich 1988).9
It is known that every (k, ϵ )-two-source extractor gives a 2n × 2n Boolean matrix in which every
minor of size at least 2k × 2k has roughly the same number of 1’s and 0’s; namely, it has 1/2 ± ϵ
fraction of 1’s and 0’s (and vice versa).
The probabilistic method shows that most functions are two-source extractors with very good
parameters (in particular, they work for min-entropy logn + 2 log(1/ϵ ) + 1), but obtaining explicit
constructions for such functions has been a major open problem for a long time. In the last couple of
years there has been remarkable progress (Ben-Aroya et al. 2016; Chattopadhyay and Zuckerman
2016; Cohen 2016a, 2016b; Li 2016) and nearly optimal constructions are now known.
We will actually use the first construction of a two-source extractor given by Chor and
Goldreich (1988, Theorem 9). They showed that the inner product function (also known as a
Hadamard matrix) acts as a good two-source extractor for k, which is roughly n/2:
Proposition 2.13. Let k = k(n) and ϵ = ϵ (n) be such that 2k ≥ n + 2 log(1/ϵ ) + 2. Then, the
inner-product function is a (k, ϵ )-two-source extractor.
In other words, the 2n × 2n inner-products matrix has the property that every minor of size at least
2k × 2k has 1/2 ± ϵ fraction of 1’s and 0’s.
2.4 Lossy Functions and Collision Resistant Hash Functions
Collision Resistant Hash. Recall that a family of collision-resistant hash (CRH) functions is one
such that it is hard to find two inputs that hash to the same output. More formally, a sequence
of families of functions Hn = {h : {0, 1}1 (n) → {0, 1}2 (n)
}, where 1 and 2 are two functions such
that 1 (n) > 2 (n) for every n ∈ N, is collision-resistant if for every probabilistic polynomial-time
algorithms A, there exists a negligible function negl(·) such that
Pr
h←Hn
[(x, x
) ← A(1n,h); h(x) = h(x
)] ≤ negl(n).
CRH functions are known to exist under a variety of hardness assumptions such as factoring,
discrete-log, and Learning with Errors (LWE). They are not known to exist under the assumption that one-way functions exist,10 and there are oracle separation results for the two primitives
(Simon 1998).
By default, unless we say otherwise, when we assume the existence of CRH functions, then we
assume a family as above in which every function shrinks its input by one bit. It is known that such
an assumption is equivalent to a family in which every function shrinks by any fixed polynomial
factor (by iteratively applying the hash polynomially many times).
9We only discuss and define extractors that output one bit, since it is enough for our purposes.
10In contrast, UOWHFs, Universal One-Way Hash Functions, where there is a fixed target x and the goal is to find x that
collides with it are known to exist under the assumption that one-way functions exist.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.           
34:10 I. Komargodski et al.
Lossy Functions. A collection of lossy functions consists of two families of functions. Functions
in the first family are injective, whereas functions in the second family are lossy, namely the size
of their image is significantly smaller than the size of their domain. The security requirement is
that a description of a randomly chosen function from the first family is computationally indistinguishable from a description of a randomly chosen function from the second family.
Lossy functions were introduced by Peikert and Waters (2011) and shown to be useful for a variety of fundamental cryptographic applications. In particular, they were shown to imply collisionresistant hash functions, oblivious transfer protocols, and chosen ciphertext-secure cryptosystems.
Since their introduction they have found numerous other applications (see Freeman et al. (2013)
for references).
Definition 2.14 (Peikert and Waters 2011). A collection of (n, )-lossy functions is defined by a
pair of algorithms (G, F ) such that:
(1) G(1n,b), where b ∈ {0, 1}, outputs a string s ∈ {0, 1}
p(n) for some fixed polynomial p(·). If
b = 0, then the algorithm F (s, ·) computes an injective function fs (·) over {0, 1}
n, and if
b = 1, then the algorithm F (s, ·) computes a function fs (·) over {0, 1}
n whose image size
is at most 2n−.
(2) The distribution of G(1n, 0) is computationally indistinguishable from the distribution of
G(1n, 1).
Lossy functions are known to exist under a variety of hardness assumptions such as Decisional
Diffie-Hellman (DDH), Learning with Errors (LWE), and factoring related assumptions (Quadratic Residuosity and Phi-hiding) with different parameters (Freeman et al. 2013; Hemenway and
Ostrovsky 2012; Kiltz et al. 2010; Peikert and Waters 2011). In our constructions, we will rely on
lossy functions with polynomial shrinkage (e.g., (n,n − n0.1)-lossy functions). Such functions are
known to exist based on LWE (Peikert and Waters 2011), DDH (Freeman et al. 2013), and Phihiding assumptions (Kiltz et al. 2010) (but not based on Quadratic Residuosity). The construction
of Kiltz et al. (2010) gives a family of functions that are length-preserving.
3 HARDNESS OF THE RAMSEY PROBLEM
We show a hard distribution for the Ramsey problem. In this problem, one is given an implicit
and efficient representation of the adjacency matrix of a graph on 2n vertices, and the goal is to
find either a clique of size n/2 or an independent set of size n/2. The implicit representation of the
graph is by a circuit C : {0, 1}
n × {0, 1}
n → {0, 1} that represents the adjacency matrix of a graph
on 2n vertices.
In terms of Definition 2.1, we have q(n) = 
n/2
2
 and the relation S is such that
(x1,..., xq(n), f (x1),..., f (xq(n))) ∈ S if and only if the edges x1,..., xq(n) form a clique or an
independent set of size n/2. That is, the set of vertices touched by some edge in x1,..., xq(n) is of
size exactly n/2, and f (x1) = ··· = f (xq(n)) = b for some b ∈ {0, 1}.
11
Hardness of the Ramsey Problem. We say that the Ramsey problem is hard if there exists an
efficiently samplable distribution D over circuits of size polynomial in n, {C : {0, 1}
n × {0, 1}
n →
{0, 1}}, that represent graphs on 2n vertices, such that for every probabilistic polynomial-time
algorithm A, there exists a negligible function negl(·) such that
Pr
C←D[v1,...,vn/2 ← A(1n,C) ; v1,...,vn/2 form a clique or an independent set] ≤ negl(n),
11We say that an edge (u, v) touches the vertices u and v.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.  
White-Box vs. Black-Box Complexity of Search Problems 34:11
where the probability is over the uniform choice of C ← D and the randomness of A. All the
efficiency requirements are polynomial in n.
The above problem is indeed in TFNP, as it is guaranteed by Proposition 2.7 that there always
exists a monochromatic clique or independent set of size n/2. We show that under certain cryptographic assumptions, the existence of collision-resistant hash (CRH) functions (see Section 2.4),
there exists an efficiently samplable distribution over instances of the Ramsey problem for which
no efficient algorithm can find a solution. Recall that if CRH functions compressing by one bit
exist, then CRH functions compressing by any polynomial factor (i.e., from n bits to nδ for any
fixed constant δ > 0) exist.
Theorem 3.1. The Ramsey problem is hard assuming the existence of collision-resistant hash
functions.
In the proof of Theorem 3.1, we use a construction of Ramsey graphs given in Proposition 2.8 as
well as a type of graph product operation: the operation takes as input a graphG on 2n vertices and
a hash function h : {0, 1}
n+ → {0, 1}
n, where  ≥ 1 and outputs a graph G ⊗ h on 2n+ vertices,
whose edges depend on the edges in G and the hash function.
Definition 3.2 (The graph-hash product). Given a graph G = (V, E), where |V | = {0, 1}
n, and a
hash function h : {0, 1}
n+ → {0, 1}
n, define the graph G ⊗ h = (V
, E
) as a graph on vertices V  =
{0, 1}
n+ with edges E such that (u,v) ∈ E if and only if (h(u),h(v)) ∈ E.
Observe that given an efficient representation of G and an efficient representation of h, we have
an efficient representation of the graph G ⊗ h. We are now ready to give the proof of Theorem 3.1.
Proof of Theorem 3.1. Let k = n/4, let H be a family of collision-resistant hash function from
n bits to k bits; such a family H exists under the assumption that collision-resistant hash functions
that compress by one bit exist. Let G = {д : {0, 1}
k × {0, 1}
k → {0, 1}} be a 2k2-wise independent
hash function family, where each member д ∈ G defines a graph G on 2k vertices in the natural
way (see below). By Proposition 2.8, most д ∈ G define a graph G that does not contain any clique
or independent set of size 2k = n/2. The following sampling procedure yields a graph (V
, E
),
where |V
| = 2n:
(1) Sample a collision-resistant hash function h ← H and a function д ← G.
(2) Set G = (V, E) to be the graph with |V | = 2k vertices induced by д (see Proposition 2.8).
(3) Output h and д as representing the graph-hash product G ⊗ h = (V
, E
). That is, for any
x,y ∈ V  s.t. x < y, we have that edge (x,y) ∈ E iff д(h(x),h(y)) = 1.
The Ramsey challenge on (V
, E
) is to find a clique or independent set of size n/2 (since |V
| =
2n). We reduce the ability of an adversary to solve the Ramsey problem to an adversary that breaks
the collision resistance of h ← H.
Suppose that there exists an adversary A that, given an instance of the distribution above, finds
a clique or an independent set of size n/2 = 2k in G ⊗ h with probability ϵ > 0 (over the choice of
h, д, and the randomness of A). Denote this event by Win(A,д,h). That is,
Pr[Win(A,д,h)] ≥ ϵ.
Let (v1,...,v2k ) the solution found by A, and let v
i  h(vi ) for i ∈ [2k]. Let Distinct be the event
in which in the solution output by A, the values v
1,...,v
2k are distinct. Then, by the assumption
it holds that
Pr[Win(A,д,h)] = Pr[Win(A,д,h) | Distinct] · Pr[Distinct]
+ Pr[Win(A,д,h) | ¬Distinct] · Pr[¬Distinct] ≥ ϵ (1)
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.                        
34:12 I. Komargodski et al.
We first argue that
Pr[Win(A,д,h) | Distinct] ≤ exp(−n).
Indeed, by the definition of the event Distinct, it holds that v
1,...,v
2k are distinct, and by the
definition of our graph-hash product, the sequence of vertices (v
1,...,v
2k ) must form a clique or
an independent set of size 2k in G. However, by Proposition 2.8, we know that with probability
1 − exp(−n) over д, the graph G does not contain any such independent set or clique.
Plugging this back into Equation (1), we get that
Pr[Win(A,д,h) | ¬Distinct] · Pr[¬Distinct] ≥ ϵ − exp(−n)
and, in particular,
Pr[¬Distinct] ≥ ϵ − exp(−n).
Recall that ϵ is a non-negligible term, and thus we obtain an algorithm A that finds a collision
in h with probability ϵ − exp(−n), which contradicts the collision resistance property of the hash
function h. To summarize, the algorithm A gets as input a hash function h, samples a function
д ← G, as above, and simulates the execution of A on the graph-hash product graph G ⊗ h. Given
the output of A, it searches the output for a pair of values that form a collision relative to h and
outputs them (it outputs ⊥ in case no such pair was found). By the above, two such colliding values
will appear in the output with non-negligible probability, resulting in a collision relative to h.
Hardness for Finding a Smaller Clique or Independent Set. We showed that it is hard to find a
clique or independent set of size n/2 in an implicitly represented graph of size 2n. We can show
that finding a clique or independent set of size nδ for any 0 < δ ≤ 1 is hard, by following the proof
of Theorem 3.1 and using a hash function that maps n bits into nδ bits (which is implied by the
existence of the hash function we used in Theorem 3.1).
We can even go below a fixed δ to, say, n1/
√log n by using a hash function that compresses a
super-polynomial amount (from n bits to n1/
√log n bits). This is known to be implied by a hash
function that compresses a single bit, albeit with a super-polynomial loss in security, but it is not
known with only a polynomial loss.
Ramsey Theory and Proof Complexity. Ramsey theory has been extensively studied in the context of proof complexity. In particular, it is known that Ramsey’s theorem has a polynomialsize bounded-depth Frege proof (Pudlák 1990) and it is related to the weak pigeonhole principle
(Jerábek 2009).
3.1 Hardness of the Colorful Ramsey Problem
The colorful Ramsey problem asks, given an implicit and efficient representation of a coloring
using m colors of the edges of a graph on 2n vertices, to find a monochromatic clique of size k.
We will see a hard distribution for the colorful Ramsey problem. We focus on the case where the
goal is to find a monochromatic triangle (i.e., k = 3 above) for simplicity and remark that the proof
generalizes for larger values of k.
Hardness of the Colorful Ramsey Problem. We say that the colorful Ramsey problem is hard if
there exists an efficiently samplable distribution D over {ψ :

2n
2

→ [m]}—colorings of the full
graph on 2n vertices—such that for every probabilistic polynomial-time algorithm A, there exists
a negligible function negl(·) such that
Pr
C←D[v1,v2,v3 ← A(1n,C) ; v1,v2,v3 form a monochromatic triangle] ≤ negl(n),
where the probability is over the uniform choice of C ← D and the randomness of A.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.       
White-Box vs. Black-Box Complexity of Search Problems 34:13
The above problem is indeed in TFNP wheneverm ≤ n/(3 logn), since it is guaranteed by Proposition 2.12 that there always exists a monochromatic triangle if there are only n/(3 logn) colors.
The theorem below shows that there exists a distribution over instances of the colorful Ramsey
problem for which no efficient algorithm can find a solution. As before, the security of the distribution relies on the existence of collision-resistant hash functions.
Theorem 3.3. The colorful Ramsey problem is hard assuming the existence of a collision-resistant
hash function family.
In the proof of Theorem 3.3, we use an explicit construction of a colorful Ramsey coloring.
Lemma 3.4. Fix k > 2 and let m = 2n/ log k. There exist an efficient and explicit coloring ψ : 
2n
2

→ [m] for which there is no monochromatic complete subgraph of size k.
Proof. We show a recursive construction. Assume we have a coloringψ  :

2n /k
2

→ [m − 2] of
the full graph on 2n/k vertices with m − 2 colors such that there is no monochromatic complete
subgraph of size k. We show how to get a coloringψ  :

2n
2

→ [m] of the full graph on 2n vertices
with m colors. Split the latter into k full graphs K1,...,Kk each of size 2n and color each of them
(internally) using ψ
. For any edge (u,v) that crosses between copies; that is, u ∈ Ki and v ∈ Kj ,
where i < j, we assign the color m − 1 if i = 1 and with the color m otherwise.
We show thatψ is a valid coloring—namely, that there is no monochromatic complete subgraph
of size k. Consider any k vertices. If they are all from the same copy Ki for some i ∈ [k], then by
the recursive construction they are not monochromatic. If each vertex is in a different copy, then
the clique is colored with colors m − 1 and m, and thus not monochromatic. Lastly, if there is a
mix of edges in between copies and among different copies, then there must be at least two edges
with different colors, since the coloring within a copy is only from the colors [m − 2] while the
coloring among different copies uses colors within {m − 1,m}.
We iterate the construction above, starting from a trivial 1-vertex graph. One can see that in each
iteration, we add 2 colors but multiply by k the number of vertices. Thus, after logk (2n ) = n/ log k
iteration, we obtain a graph with 2n vertices colored with m = 2n/ log k colors.
An explicit algorithm (not in a recursive form) for coloring the edges of the graph is given next.
Note that if we write n in the base k representation, then it has m/2 coordinates.
Color(u,v) :
(1) Let (u1,...,um/2) and (v1,...,vm/2) be the base k representation of u and v, respectively.
(2) Let i be the minimal index such that ui  vi .
(3) If ui = 1, then output color 2i − 1.
(4) Otherwise, output color 2i.
We proceed with the proof of Theorem 3.3.
Proof of Theorem 3.3. We adapt the graph-hash product operation (see Definition 3.2) to support more general coloring functions (rather than graphs). Given a coloring ψ :

2n
2

→ [m] of
the full graph with 2n vertices using m colors, and a hash function h : {0, 1}
n+ → {0, 1}
n, we
define a coloring of the full graph on 2n+ vertices ψ ⊗ h as follows: For any edge e = (u,v) ∈
{0, 1}
n+ × {0, 1}
n+, let u = h(u) and v = h(v). The color of e isψ (u
,v
) (i.e., the color of (u
,v
)
according to ψ) if u  v and it is 1 if u = v
.
We proceed with the main construction. Let n = n log 3
6 log n and let ψ :

2n
2

→ [m] be a coloring
of the full graph on 2n
vertices with m  2n
/ log 3 = n/(3 logn) colors that does not contain a
monochromatic triangle given by Lemma 3.4. Sample a collision-resistant hash function h ← H,
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.                         
34:14 I. Komargodski et al.
where H = {h : {0, 1}
n → {0, 1}
n
} is a collision-resistant hash function compressing n bits to n
bits, and color the full graph on 2n vertices byψ ⊗ h. This coloring, which consists of a description
of ψ and h, is the output of the sampling procedure of the distribution.
Suppose there exists an adversary A that, given an instance of the distribution above, finds
a monochromatic triangle in ψ ⊗ h with probability ϵ > 0. Denote by (i1,v1), (i2,v2), (i3,v3) ∈
{0, 1}
n/2 × {0, 1}
n/2 the solution found byA, and letv
i = h(i,vi ) fori ∈ [3]. We first observe that by
Lemma 3.4 it must be that thev
i ’s are not distinct. Indeed, if they are distinct then (by the definition
of our coloring-hash product) the sequence of vertices (v
1,v
2,v
3) correspond to a monochromatic
triangle in ψ, which cannot happen (since ψ does not have any such monochromatic triangle).
Given that the v
i ’s are not distinct, they must contain a collision relative to h. Thus, we obtain an
algorithm A that finds a collision for h with the same probability probability ϵ.
3.2 The Relation of Ramsey and the WeakPigeon Classes
The weak pigeon class (PWPPn
k ) is a subclass in TFNP defined by the collision-finding problem for
circuits that compress their input.
Definition 3.5 (PWPPn
k complete problem). Given a circuit C : {0, 1}
n → {0, 1}
k , find x  y such
that C(x) = C(y). Moreover, we define PWPP = PWPPn
n−1.
In Jerábek (2016) it has been shown that the class PWPPn
n−1 is equivalent to the class PWPPn
nδ
for any positive constant δ. Moreover, any hard problem for PWPPn
k naturally gives rise for a
collision-resistant hash function.
In Theorem 3.1, we showed a reduction from the hardness of the Ramsey problem to the hardness of collision-resistant hash functions—that is, to PWPP. Let RAMSEY be the set of all search
problems that are reducable in polynomial-time to the Ramsey problem. Then, we get that the class
PWPP is contained under randomized reductions in the class RAMSEY. The only source of randomness in our reduction is sampling the limited-independence hash function д ∈ G that defines
a Ramsey graph. We observe that we can overcome this issue (i.e., get a deterministic reduction)
by relying on explicit constructions of Ramsey graphs. The currently best explicit constructions of
Ramsey graphs do not get the same parameters as a random graph and, hence, to use it, we need
a stronger hash function (i.e., with better compression rate).
The explicit construction that we use comes from an exciting line of recent works in the area
of randomness extractors (for example, Cohen (2016a), Chattopadhyay and Zuckerman (2016),
Ben-Aroya et al. (2016), Cohen (2016b), and Li (2016)).12 We will use the following theorem:
Proposition 3.6. There exists an explicit k-Ramsey graph on N vertices, where k ≤ 2(log log N )
2
.
13
Applying the same proof as that of Theorem 3.1, but using the explicit construction of Ramsey
graphs above, results with:
Theorem 3.7. Fix a family of collision-resistant hash functions H = {h : {0, 1}
n → {0, 1}
2
√log(n/2)
}.
There exists a deterministic reduction from RAMSEY to breaking the collision resistance of H.
As a corollary of Theorem 3.7, we obtain that the class defined by the Ramsey problem (i.e., the
class RAMSEY) includes the class PWPPn
2
√log(n/2)
.
12We note that any improvement on the best constructions of Ramsey graphs would imply an improvement in our underlying assumption regarding the hash function.
13Li (2016) shows a stronger result, namely, that k ≤ 2(log log N )·O (log log log N )
, but (for simplicity), we will not use this
stronger version. Using better explicit constructions of Ramsey graphs (than the one we state in Proposition 3.6) will
directly imply the result in Theorem 3.7 based on a weaker assumption on the hash function family.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.           
White-Box vs. Black-Box Complexity of Search Problems 34:15
Corollary 3.8. PWPPn
2
√log(n/2) ⊆ RAMSEY.
Proof of Theorem 3.7. Let k = 2
√log(n/2)
. Given a uniformly sampled hash function h ← H,
we show that given a solver for the Ramsey problem, it is possible to find collisions in h. Consider
the graphG = (V, E) with |V | = 2k vertices given by Proposition 3.6 and execute the Ramsey problem solver on the graph-hash product graph G ⊗ h = (V
, E
). Notice that |V
| = 2n, and thus the
solver finds a clique or independent set of size n/2 = 2(log k)
2
in G ⊗ h with noticeable probability
ϵ > 0. Denote the solution by v1,...,vn/2, and let v
i = h(vi ) for i ∈ [n/2]. We first observe that
by Proposition 3.6 it must be that the v
i ’s are not distinct. Indeed, if they are distinct, then (by
the definition of our graph-hash product) the sequence of vertices (v
1,...,v
n/2) forms a clique
or an independent set of size n/2 in G (which does not exist!). Now, given that the v
i ’s are not
distinct, then they must contain a collision relative to h. Thus, we obtained an algorithm that finds
a collision for h with probability ϵ.
Regarding the relation between the colorful Ramsey problem and the class PWPPn
n−1, we have
the following: Using Theorem 3.3, we obtain that the class defined by the colorful Ramsey problem,
denoted by COLORFUL-RAMSEY, includes the class PWPPn
n/(6 log n)
. Since PWPPn
n−1 is equivalent
to PWPPn
nδ for any positive constant δ (Jerábek 2016), we obtain the following result:
Corollary 3.9. PWPP ⊆ COLORFUL-RAMSEY.
3.3 The Ramsey Problem and Multi-CRH
In Theorem 3.1, we showed that under the assumption that CRH functions exist, the Ramsey problem is hard. Here, we study the bipartite version of the Ramsey problem and point out a tight relationship to a cryptographic primitive we call multi-collision-resistant hash (MCRH) functions.14
A bipartite graph on two sets of N vertices is a bipartite K-Ramsey graph if it has no K × K
complete or empty bipartite subgraph. Ramsey’s theorem for such graphs says that every bipartite
graph on 2N vertices has a log N × log N complete or empty bipartite subgraph (see, e.g., Conlon
(2008)).15 The result of Erdös (1947) on the abundance of (2 log N)-Ramsey graphs (see Proposition 2.8 and Appendix B.2) naturally extends to the bipartite setting as well.
Analogously to the Ramsey problem on graphs, the bipartite Ramsey problem is when the graphs
are bipartite and the goal is to find a bi-clique or bi-independent set of a certain size. We focus on
the task of finding a bi-clique or bi-independent set of size n/4. We say that the bipartite Ramsey
problem is hard if there exists an efficiently samplable distribution D over {C : {0, 1}
n × {0, 1}
n →
{0, 1}}—circuits of size polynomial in n that represent bipartite graphs on 2n × 2n vertices—such
that for every probabilistic polynomial-time algorithm A, there exists a negligible function negl(·)
such that
Pr
C←D[u1,...,un/4,v1,...,vn/4 ← A(1n,C) ; ∃b ∈ {0, 1},∀i, j ∈ [n/4] : C(ui,vj) = b] ≤ negl(n),
where the probability is over the uniform choice of C ← D and the randomness of A. All the
efficiency requirements are polynomial in n.
Roughly, a family of multi-collision-resistant hash functions is one such that it is hard to find
multiple inputs that hash to the same output. More precisely, a sequence of families of functions
14Multiple collisions in hash functions were studied before in the context of iterated hash functions by Joux (2004). He
showed that for such functions, finding multi-collisions (a set of k messages that hash to the same value) is not much
harder than finding ordinary collisions (pairs of messages that collide).
15Given a bipartite K-Ramsey graph G on 2N vertices, one can transform it into a non-bipartite 2K-Ramsey graph H on
N vertices. The graph H is defined by the upper triangle of the adjacency matrix of G.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.         
34:16 I. Komargodski et al.
Hn = {h : {0, 1}1 (n) → {0, 1}2 (n)
}, where 1 and 2 are two functions such that 1 (n) > 2 (n) for
every n ∈ N, is k-multi-collision-resistant if for every probabilistic polynomial-time algorithms A,
it holds that
Pr
h←Hn
[(x1,..., xk ) ← A(1n,h); h(x1) = ··· = h(xk )] ≤ negl(n).
By default, unless otherwise stated, we assume that a family of k-MCRH functions maps strings of
length n to strings of length n − log k. This assumption ensures that a k-multi-collision exists (but
yet it is hard to find). k-MCRH functions are implied by standard CRH functions (but is seemingly
a weaker primitive).
We show that MCRH functions are sufficient and necessary for bipartite Ramsey hardness.
Theorem 3.10. If the bipartite Ramsey problem is hard, then there exists a family H = {h :
{0, 1}
n → {0, 1}
n/2} of n/4-MCRH functions.
Furthermore, if there exists a family H = {h : {0, 1}
n → {0, 1}
√
n/8} of √
n-MCRH functions, then
the bipartite Ramsey problem is hard.
Proof. We show that the hardness of the bipartite Ramsey problem implies that n/4-MCRH
functions exist. Let D = {C : {0, 1}
n × {0, 1}
n → {0, 1}} be a distribution over succinctly represented graphs on 2n × 2n vertices such that it is hard to find a bi-clique or a bi-independent
set of size n/4. Fix v1,...,vn/2 ∈ {0, 1}
n to be arbitrary n/2 distinct vertices on the right
side. We define the hash function hC : {0, 1}
n → {0, 1}
n/2 to be the concatenation of the bits
C(x,v1),...,C(x,vn/2).
hC (x) = C(x,v1) ◦···◦ C(x,vn/2).
We claim that it is hard to find an (n/4)-multi-collision inhC by translating such a multi-collision
to a bi-clique or a bi-independent set of size n/4 in C. Let x1,..., xn/4 be a (n/4)-multi-collision in
hc and denote by y = hC (x1) ∈ {0, 1}
n/2. Without loss of generality, assume that the string y has
more 1’s than 0’s and denote by I = {i1,...,in/4} ⊆ [n/2] a set of size n/4 of (distinct) indices for
which yi = 1. The collection of vertices x1,..., xn/4 on the left side and the vertices {vi1 ,...,vin/4 }
on the right form a bi-clique of size n/4 × n/4.
For the other direction, namely that the bipartite Ramsey problem is hard if √
n-MCRH functions
exist (that map n bits to √
n/8 bits), we adapt the proof of Theorem 3.1. First, following the proof
of Proposition 2.8, a bipartite graph on 2 · 2
√
n/8 vertices sampled via an (n/16)-wise independent
family is a (
√
n/4)-Ramsey (bipartite) graph with probability at least 1 − 1/N.
The hard distribution for bipartite Ramsey is defined similarly to the distribution given in Theorem 3.1. Specifically, a description of a graph is given via a √
n-MCRH function h and a (4 log2 N)-
wise independent function д and an edge (x,y) is in the graph iff д(h(x),h(y)) = 1.
Given a bi-clique or bi-independent set u1,...,un/4,v1,...,vn/4, consider u
i = h(ui ) and v
i =
h(vi ) for i ∈ [n/4]. Since h is a √
n-MCRH function, then there are at least √
n/4 distinct values of
u
’s and √
n/4 distinct values of v
’s (otherwise, we can break the security of h). Thus, we get a
bi-clique or bi-independent set of size √
n/4 × √
n/4 in the graph defined by д. This contradicts the
fact that д contains no such graph (with very high probability).
Subsequent Work. Following this work, the notion of MCRH has been studied in depth showing a variety of applications such as statistically hiding commitments with short communication, various types of efficient zero-knowledge protocols (Berman et al. 2018; Bitansky et al. 2017;
Komargodski et al. 2018), and distributional collision resistance (Komargodski and Yogev 2018).
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.           
White-Box vs. Black-Box Complexity of Search Problems 34:17
4 HARDNESS OF TESTING AN EXTRACTOR
In this section, we present a graph property that is hard to test in the white-box setting. Specifically,
we present a property Π and a distribution over succinctly represented graphs for which efficiently
deciding whether an instance in the distribution has the property Π or is far from having the
property Π is impossible (under appropriate cryptographic assumptions). We briefly recall the
notions related to (graph) property testing and then describe our main result. A more elaborate
introduction can be found in Goldreich (2011) and references therein.
A property Π is simply a set of elements in a universe of interest. A property Π is a graph
property if it is a set of graphs closed under graph isomorphism. That is, if for every graph G =
(V, E) on N vertices and any permutation π onV it holds thatG ∈ Π if and only if π (G) ∈ Π, where
π (G) = (V, E
) and E = {(π (u), π (v)) | (u,v) ∈ E}. A graph G = (V, E) on N vertices is said to be
ϵ-far from a property Π if for every N-vertex graph G = (V
, E
) that has the property Π (i.e.,
G ∈ Π), it holds that |EE
| ≥ ϵ ·

N
2

(the operator  denotes symmetric difference).
Definition 4.1 (White-box property testing). An ϵ-tester for a graph property Π is a probabilistic
machine that, on input a Boolean circuit C : {0, 1}
n × {0, 1}
n → {0, 1} representing the adjacency
matrix of a 2n-vertex graph G, outputs a binary value that satisfies:
(1) If G has the property Π, then the tester outputs 1 with probability at least 2/3.
(2) If G is ϵ-far from Π, then the tester outputs 1 with probability at most 1/3.
The above definition naturally generalized to bipartite graphs (and properties of bipartite
graphs).
The Property of Being an Extractor. The graph property Π we are interested in is being a twosource extractor: a bipartite graph G = (U,V, E), where |U | = |V | = 2n, is (k, δ )-balanced if for
every set U  ⊆ U and V  ⊆ V of size |U
| = |V
| = 2k , the induced subgraph GU
,V  has 1/2 ± δ
fraction of edges. The induced subgraph GU
,V  = (U
,V
, EU
,V  ) is defined by (u,v) ∈ EU
,V  if
and only if (u,v) ∈ E, u ∈ U  and v ∈ V
.
We present a distribution over succinctly represented (bipartite) graphs for which testing the
above property is hard. The hardness reduces to breaking the security of a collection of lossy functions described in Section 2.4.
Theorem 4.2. Assume the existence of a collection of (n, 2n/3)-lossy functions and consider the
bipartite graph property Π of being (0.52n, 2−n/2000)-balanced. There exist a constant ϵ > 0 and a
distribution over succinctly represented bipartite graphs on 2n vertices for which any ϵ-tester for Π
must run in super-polynomial-time.
Observe that the existence of a collection of lossy functions directly implies white-box hardness
of testing whether a given function is injective or far from being such (i.e., lossy), but we will prove
the hardness for a graph property.
Proof. Assume the existence of a collection of (n, 2n/3)-lossy functions defined by the pair of
algorithms (Gen, Eval), where for every s in the output of Gen it holds that Eval(s, ·) = fs (·) maps
strings of length n into strings of length p(n) > n for some polynomial p(·). We construct a new
collection of functions defined by a pair of algorithms (Gen
, Eval
):
(1) The algorithm Gen
, on input 1n and b ∈ {0, 1}, executes the algorithm s ← Gen(1n,b)
and samples an n-wise-independent hash-function h : {0, 1}
p(n) → {0, 1}
n. It outputs s =
(s,h).
(2) The algorithm Eval
, on input s = (s,h) and x ∈ {0, 1}
n, outputs h(Eval(s, x)).
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.                              
34:18 I. Komargodski et al.
Claim 1. The following holds:
(1) Gen
(1n, 0) ≈c Gen
(1n, 1).
(2) The algorithm Eval
(s
, ·), where s ← Gen
(1n, 0), computes a function fs (·) over {0, 1}
n
such that with very high probability for any y ∈ {0, 1}
n it holds that |{x : fs (x) = y}| ≤ n.
(3) The algorithm Eval
(s
, ·), where s ← Gen
(1n, 1), computes a function fs (·) over {0, 1}
n
whose image size is at most 2n/3.
Proof. The first and last items follow immediately from the properties of (Gen, Eval). The second item follows by a balls-and-bins argument. For any n elements, the probability that they all
hash to a specific value y is (2−n )
n. Thus, taking a union bound over all possible values y ∈ {0, 1}
n
and all possible n tuples, we get that the total probability that there exists a bin with more than n
elements is at most 2n ·

2n
n

· 2−n2
≤ exp(−n).
Fix k = 0.51n and δ = 2−n/500 and observe that
2k = 2 · 0.51n ≥ n + 2 log(2n/500) + 2 = n + log(1/δ ) + 2.
By Proposition 2.13, there exists a polynomial-size Boolean circuit Bn,k,δ that acts on inputs from
{0, 1}
n × {0, 1}
n and succinctly represents a (k, δ )-balanced bipartite graph G = (U,V, E). Recall
that the graph G has |U | = |V | = 2n vertices on each side and has the property that every 2k × 2k
subgraph is balanced up to a fraction of δ edges.
Remark 4.3. Better constructions of such explicit circuits (cf., Proposition 2.13) are useful when
only weak lossy functions that do not compress much are available. They can also be used to
get a hardness result for testing “weaker” properties (i.e., showing hardness for testing the (k, δ )-
balanced property even for smaller values of k compared to n).
We define our distribution over Boolean circuits that act on inputs from {0, 1}
n × {0, 1}
n. Let
f
s (·) = Eval
(s
, ·). First, we sample a description of a random function by s ← Gen
(1n,b) for
b ← {0, 1} chosen uniformly at random. Then, we output the following circuit Cs that represents
a graphG
: On input a pair of verticesu ∈ U = {0, 1}
n,v ∈ V = {0, 1}
n, output Bn,k,δ (f
s (u), f
s (v)).
That is, there is an edge between u and v iff there is an edge in Bn,k,δ between f
s (u) and f
s (v).
By item 1 in Claim 1, we know that the two distributions s ← Gen
(1n,b) for b = 0 and b = 1
are computationally indistinguishable. Next, we show that when b = 0, then the graph G has the
property Π, and when b = 1 the graph is ϵ = 1/4 far from having the property Π, and conclude
our theorem.
The Injective Case. When b = 0, we claim thatG is (k
, δ )-balanced for k = 1.01k ≤ 0.52n. Consider any 2k
× 2k
subgraph H of G
. Denote by L (resp. R) the set of nodes on the left (resp. right)
side of H. For i ∈ [n], denote by Ai (resp. Bi ) the values y ∈ L (resp. y ∈ R) for which there are
exactly i preimages under f
s, namely,
Ai = {y ∈ L : |{x : f
s (x) = y}| = i} and Bi = {y ∈ R : |{x : f
s (x) = y}| = i}.
By item 2 in Claim 1, (w.h.p.) for i > n, it holds that |Ai | = 0, so assume this is the case for the
rest of the proof. Denote by IL the set of indicesi for which |Ai | ≥ 2k · i and similarly by IR the set
of indices j for which |Bj | ≥ 2k · j. This implies that

i ∈IL,j ∈IR
|Ai |·|Bj | =

i,j ∈[n]
|Ai |·|Bj | − 
iIL or jIR
|Ai |·|Bj |
≥ 22k
− n2 · 2k
· 2k · n = 22k
− 2k
· 2k · n3
, (2)
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.                                                   
White-Box vs. Black-Box Complexity of Search Problems 34:19
where the inequality 
iIL or jIR |Ai |·|Bj | ≤ n2 · 2k
· 2k · n follows, since |IL |, |IR | ≤ n (giving the
n2 factor for the number of pairs i  IL or j  IR) and either |Ai | or |Bj | is smaller than 2k · n.
We will count the number of edges and non-edges between each Ai and each Bj for i ∈ IL and
j ∈ IR (the sum of these will serve as a lower bound on the total number of edges and non-edges
in H). Fix i ∈ IL and j ∈ IR. Since i, j ≤ n, in Ai (resp. Bj), there must exist at least |Ai |/i ≥ 2k
(resp. |Bj |/j ≥ 2k ) vertices whose values relative to f
s (·) are distinct. These vertices form a (k, δ )-
balanced subgraph Hˆ; namely, Hˆ contains at least
(|Ai |/i) · (|Bj |/j) · (1/2 − δ )
edges and non-edges (since they can be mapped to distinct vertices in Bn,k,δ ).
Counting the number of edges betweenAi and Bj , any edge (and non-edge) in Hˆ will be counted
exactly i · j times. Thus, the total number of edges and non-edges between Ai and Bj is at least
|Ai |·|Bj | · (1/2 − δ ).
Thus, using Equation (2), the total number of edges in H is at least

i ∈IL,j ∈IR
|Ai |·|Bj | · (1/2 − δ ) ≥ (1/2 − δ ) ·

i ∈IL,j ∈IR
|Ai |·|Bj |
≥ (1/2 − δ ) · 22k
− (1/2 − δ ) · 2k
· 2k · n3
≥ (1/2 − δ ) · 22k
− 2k
+k+3 log n
= (1/2 − δ − 2−k
+k+3 log n ) · 22k
.
Since k = 1.01k and k = 0.51n, we have that 2−k
+k+3 log n = 2−0.01k+3 log n ≤ 2−n/1000 for large
enough n. Thus, letting δ   δ + 2−n/1000 ≤ 2−n/2000, the number of edges in H is at least

i ∈IL,j ∈IR
|Ai |·|Bj | · (1/2 − δ ) ≥ (1/2 − δ − 2−n/1000) · 22k
= (1/2 − δ
) · 22k
.
An analogous argument can be applied to show that the same lower bound holds on the number
of non-edges, which completes the proof.
The Lossy Case. When b = 1, we argue that the graph G (represented by Cs) is very far from
satisfying the property Π. For any value y in the image of f
s, we define a non-empty set A =
f −1 s (y). Since the image of f
s is of size at most 2n/3, there are at most 2n/3 such disjoint sets of
vertices A1,...,A2n/3 ⊆ U . For any i ∈ [2n/3], we have that
∀u1,u2 ∈ Ai : f
s (u1) = f
s (u2).
Similarly, there are at most 2n/3 disjoint sets of vertices B1,..., B2n/3 ⊆ V for which
∀i ∈ [2n/3
],v1,v2 ∈ Bi : f
s (v1) = f
s (v2).
Let IL ⊆ [2n/3] (resp. IR ⊆ [2n/3]) be the subset of the Ai ’s (resp. Bj ’s), which are of size at least
2k
. That is,
i ∈ IL ⇐⇒ |Ai | ≥ 2k
and j ∈ IR ⇐⇒ |Bj | ≥ 2k
.
Each pair of sets Ai, Bj for i ∈ IL, j ∈ IR, gives us a set of vertices on the left and a set of vertices
on the right that are either fully connected (if Bn,k,δ (fs (u), fs (v)) = 1 for u ∈ Ai and v ∈ Bj) or
fully disconnected (if Bn,k,δ (fs (u), fs (v)) = 0). Thus, if both Ai and Bj are of size at least 2k
, each
such pair contributes 1/2 · |Ai |·|Bj | edges to G that must be changed (added or removed) for the
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.                                         
34:20 I. Komargodski et al.
graph G to possess the property Π. The number of nodes that are in a set Ai (and similarly for Bj)
that is smaller than 2k
is bounded by 2n/3 · 20.52n ≤ 20.9n. Thus, we get that the number of edges
that must be changed for the graph G to possess the property Π is at least:

i ∈IL,j ∈IR
1
2
|Ai |·|Bj | = 1
2

i ∈IL,j ∈IR
|Ai |·|Bj | +
1
2

iIL,jIR
|Ai |·|Bj | − 1
2

iIL,jIR
|Ai |·|Bj |
= 1
2

i ∈U,j ∈V
|Ai |·|Bj | − 1
2

iIL,jIR
|Ai |·|Bj |
≥
1
2 · 22n − 1
2 · (20.9n )
2 ≥
1
4 · 22n .
Namely, at least 22n/4 of the edges must be changed, which is a constant fraction of the total
number of edges in the graph.
5 IMPOSSIBILITY OF A GENERAL TRANSFORMATION
In this section, we show (unconditionally) that there cannot be a general transformation from a
black-box lower bound to a white-box lower bound. That is, we show that there exists a problem
that has exponentially high black-box complexity but is solvable in polynomial time given any
white-box implementation of the search function.
We first give an informal overview of the problem we define with respect to a function f . Consider the problem of finding a small circuit that is consistent with a large set of pairs (xi,yi ) defined
by f (i.e., f (xi ) = yi ). In particular, the set will be larger than the size of the circuit. In the blackbox model, for a random function f , these points will be completely random, and thus the task
of finding a small circuit that is consistent is impossible (since one cannot compress random bits).
However, in the white-box model, given any circuit that computes f , the task becomes completely
trivial: simply return the circuit in hand.
This approach raises two main difficulties. First, this problem does not always have a solution
in the black-box model (which is not consistent with the definition of a search problem). Second,
the solution has no a priori bound on its size.
The first problem is solved by taking any search problem with proven high black-box complexity
(e.g., PPP or PWPP). Notice that this problem might have high white-box complexity as well.
Then, we modify our search problem to be an OR of the two problems. That is, either find a small
consistent circuit or solve the second search problem. In the black-box model, the complexity of
the new problem remains high, and moreover, a solution always exists. In the white-box model,
the problem remains solvable in polynomial time.
The second problem is solved by giving a short commitment to the circuit instead of the full
circuit and then proving that this is a commitment to a circuit that is consistent on a random
value. To achieve this, we use techniques such as Kilian’s protocol combined with the Fiat-Shamir
paradigm to remove interaction in the random oracle model (in the black-box model, we have a
random oracle!).
The search problem we define is the one considered by Goldwasser and Kalai (2003) in the context of showing limitations for the Fiat-Shamir paradigm. Goldwasser and Kalai showed that there
exists a 3-round public-coin identification scheme for which the Fiat-Shamir paradigm yields an
insecure digital signature with any hash function in the standard model. (In contrast, Pointcheval
and Stern (1996) showed that in the random oracle model this paradigm always produces a signature scheme that is secure against chosen message attacks.)
The signature scheme of Goldwasser and Kalai naturally gives rise to a search problem: Given
the public parameters of the scheme, find a valid signature for an arbitrary message. To make this
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.         
White-Box vs. Black-Box Complexity of Search Problems 34:21
problem in TFNP, we define the problem of either finding a valid signature as above or finding a
collision in a compressing function. The latter has a guaranteed solution, so this defines a valid
search problem in TFNP.
The Underlying Relation. Underlying the construction of Goldwasser and Kalai (2003) is a relation
in which the instance is a function f and a valid witness, C, is a small circuit that approximates
f : it agrees with f on a point that depends on the description of C. For a function f ∈ Fn where
f : {0, 1}
n → {0, 1}
n, the relation is16:
Rf
GK = {(f ,C) | a = COMf (C) ∧ C(a) = f (a) ∧ |C| ≤ 2n/10},
where COMf is the tree-commitment of Kilian (1992), which allows for a fixed polynomial-size
commitment of any polynomial-size string and also allows for efficient decommitment for individual bits (here, f is used as a hash function by ignoring half of the output bits).
Goldwasser and Kalai showed that when f is a random function (modelled as a oracle model),
it is hard to devise a proof that one has a witness for membership in the relation with fewer than
exponentially many queries to f (with high probability). The high-level idea is that a valid witness
C will agree with f on the point a = COMf (C). Since f is random, the point a is also random and,
hence, C is a (small) circuit that approximates (the random oracle) f , which does not exist (w.h.p.).
Therefore, finding such a witness is infeasible.
However, in the white-box model, given the code of f , it is easy to find a proof (the code of f
is used as a witness). There are two problems with using the above as a valid search problem in
TFNP: (1) there is no guaranteed solution in the black-box setting, and (2) there is no guaranteed
solution in the white-box setting if the circuit implementing f is of size larger than 2n/10. To solve
this, we allow to find solutions of a different kind: a pair of strings a  b such that f (a) = f (b) or
f (a) = 0. This is exactly the complete problem for the class PPP. Namely, we OR with the relation:
Rf
PPP = {(a,b) ∈ {0, 1}
n × {0, 1}
n | a  b ∧ f (a) = f (b) ∨ f (a) = 0}.
This indeed solves both problems as now (1) there is always a guaranteed solution in the blackbox setting, since a compressing function must have a collision (the pigeonhole principle), and (2)
such a solution can always be found with 2n queries, which is polynomial in 2n/10. To summarize,
our final relation, which is a search problem in TFNP, is:
Rf = Rf
GK ∪ Rf
PPP.
6 THE SUCCINCT BLACK-BOX MODEL
We define and study a new model of computation that we call succinct black-box. In this model,
as in the black-box model, the solver has only query access to the object and it is measured by
the number of queries it performs to find a solution. However, in this model (as opposed to the
black-box model), the number of queries is measured as a function of the size of the representation
of the function. This is similar to the white-box model, where the running time is measured as a
function of the size of the representation. In particular, if the function has a polynomial-sized
representation, then an efficient algorithm in this model can perform only a polynomial number
of queries (but the running time may be arbitrary).
We show that for any problem in TFNP, there exists a deterministic procedure that performs
only a polynomial number of queries (in the size of the representation of the function) and finds a
valid solution.
16The bound on the size of C in Goldwasser and Kalai (2003) can be any super-polynomial function.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.  
34:22 I. Komargodski et al.
Theorem 6.1. For any search problem S ∈ TFNP it holds thatsbbc(S) is polynomial. In particular,
if the representation size iss and any solution consists of at most k elements, then the number of queries
is O(sk/ log k).
The assumption that the search problem is in TFNP is essential for the theorem to hold. To see
this, consider the case of point functions (functions that output 1 at a specific point and 0 everywhere else) where the goal is to find the hidden point. There exists a succinct representation (the
point itself) but any algorithm that is only allowed to query the oracle must make exponentially
many queries until it finds the hidden point.
Proof of Theorem 6.1. We construct an algorithmA in the succinct black-box model. Let Sn be
a search problem where any solution is of size at most k (recall that k is polynomial in n). Suppose
we are explicitly given the size s = s(n) of the representation (we will get rid of this assumption
later). We begin by showing a simple version of the algorithm that performs O(sk) queries:
Succinct black-box algorithm:
(1) Initiate a list L of all possible representations of length less than s.
(2) Repeat until a solution is found:
(a) Define f ∗ : {0, 1}
n → {0, 1}
n such that f ∗ (x) = MostFrequentf ∈L f (x).
(b) Find a solution x1,..., xk relative to f ∗.
(c) Query x1,..., xk .
(d) If all query results are consistent with f ∗, then output x1,..., xk .
(e) Remove any f from L if it is not consistent with x1,..., xk .
The algorithm always outputs a valid solution while performing at most a polynomial number
of queries (in the size of the representation of f ): First, for any f ∗, such a solution exists, since
the problem is in TFNP. In each round, the algorithm performs k = poly(n) queries. Since f ∗ is
consistent with the most frequent value, if a solution is not found at any round, then we get that
at least half of the candidates are eliminated, and thus the list L is cut by half. The initial size of L
is bound by 2s . Thus, the total number of round is at most s. Overall, the total number of queries
is at most ks.
Suppose now that we are not given the bound s on the size of the representation. Then, we do
a variant of binary search: we run the algorithm with alleged upper bounds s∗ = 1, 2, 4,... until it
halts. When we run it with s∗ ≥ s, the algorithm will halt. The total cost is at most k + 2k + 4k +
··· + 2sk ≤ 4ks = poly(s), and thus sbbc(Sn ) is polynomial.
To get the bound O(sk/ log k), we slightly fine-tune the above algorithm. We introduce a parameter α (which we set later) and add an extra step to the iteration (after Step 2a):
—While there exist an x such that Prf ∈L[f (x) = f ∗ (x)] ≤ 1 − α, query x and remove all inconsistent f from L.
In this case, we can average between a single query that eliminates α fraction of the candidates
and k queries that together remove 1 − α fraction of the candidates. To even these two cases, we
set α such that (1 − α)
k = α. Once α satisfies this equation, we get that after s/α iterations the
number of remaining candidates is at most 2s (1 − α)
s/α ≤ 2se−s ≤ 1. Thus, the total number of
queries is s/α. It is hard to get an exact solution to the above equation; however, a good enough
approximation yields that log k
2k ≤ α ≤ 2 log k
k . Plugging this in, we get that the number of queries is
s/α = O(sk/ log k) as required.
Goldberg and Roth (2016, Theorem 3.3) investigated the number of queries needed to find an
ϵ-well supported Nash equilibrium in multi-player games. They showed that if the game has a
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019. 
White-Box vs. Black-Box Complexity of Search Problems 34:23
succinct representation, then there is an algorithm that performs a polynomial number of queries
in the number of players n, the number of actions m, the description length of the target game,
and finds such an equilibrium. One can view Theorem 6.1 as a generalization of that result.17
Efficient-succinct Black-box Model. We observe that our algorithm is inefficient, and thus is not
applicable in the efficient-succinct black-box model (see Section 2 and Table 2). Moreover, there
exist problems that are hard in the efficient-succinct black-box model but are easy in the whitebox model. This follows by adapting the proof from Section 5 while replacing the use of a random
oracle with a pseudorandom function.18
7 FURTHER RESEARCH
The immediate direction this work raises is which other Ramsey-type problems are hard in the
white-box model. Consider, for instance, Schur’s Theorem, which states that for every positive
integer m, there exists a number S (m) such that for every coloring of the numbers in the set {1,
..., S (m)} with m colors, there must be x,y, and z colored with the same color such that x + y = z
(see Graham et al. (1990), Chapter 3). This property naturally gives rise to them-Schur search problem: Given an implicit representation of the coloring of the numbers {1,..., S (m)}, find x,y, and z
colored with the same color and satisfy x + y = z. Can we argue that them-Schur problem is hard?
What are the minimal assumptions needed to obtain the hardness results for Ramsey? Are oneway functions sufficient or is there an inherent reason why collision-resistant hash functions are
needed? For the bipartite Ramsey problem, we showed that a relaxation of CRH functions (MCRH
functions) is necessary and sufficient.
Our results are “obfuscation-free,” in the sense that we needed much weaker primitives for obtaining them than in the recent works of Bitansky et al. (2015), Garg et al. (2016), and Komargodski
and Segev (2017). Can we get similar results for showing the hardness of complexity classes such
as PLS and PPAD?
We showed the general impossibility of transferring black-box results to white-box results. One
direction that might be fruitful is to find conditions on the search problems that do allow for
such general transformation from black-box to white-box. A natural candidate is when the search
problem is defined over graphs, and we are looking for a graph property (i.e., the decision of S
whether to accept or not depends solely on the presented subgraph and not on the names of the
vertices). Can we prove a transformation in this case? Can we show an impossibility?
APPENDICES
A HARDNESS OF FINDING A SUNFLOWER
The famous Sunflower lemma, discovered by Erdös and Rado (1960), asserts that in a sufficiently
large family of sets of the same size a configuration called “sunflowers” must occur. In this section,
we show that even though the configuration is guaranteed to exist, efficiently finding it is hard
assuming that collision-resistant hash functions exist.
Definition A.1 (A Sunflower). Asunflower withk petals and coreY is a collection of sets S1,..., Sk
such that
(1) Si ∩ Sj = Y for every distinct i, j ∈ [k] and
(2) Si \ Y  ∅ for every i ∈ [k].
17We thank Aviad Rubinstein for referring us to Goldberg and Roth (2016). 18A pseudorandom function is a (keyed) function that cannot be distinguished from a random function by any polynomially
bounded adversary.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019. 
34:24 I. Komargodski et al.
Lemma A.2 (The Sunflower lemma). Let F be a collection of distinct sets each of cardinality s.
If |F | > s!(k − 1)
s , then F contains a sunflower with k petals.
We define the sunflower problem as a search problem in which one is given a collection of sets
F , each of size n, and the goal is to find a sunflower with n + 1 petals. A circuit C : {0, 1}
2n log n →
({0, 1}
n )
n represents the collection F of 2n logn sets, each of size n. Namely, given such a circuit,
the i
th set is given by evaluating C(i) ∈ ({0, 1}
n )
n. Therefore, the problem is formulated as follows:
Problem 1 (The Sunflower problem). Given a circuitC : {0, 1}
2n log n → ({0, 1}
n )
n find n + 1 indices
such that C(i1),...,C(in+1) are a sunflower or two indices i1,i2 such that C(i1) = C(i2).
For any circuitC, either there exist two indices that encode the same set or the circuitC encodes
22n log n = n2n ≥ 2n! · nn different sets (for n > 1). Then, according to Lemma A.2, such a collection
will contain a sunflower of size n + 1, and therefore this is a valid search problem in TFNP.
We say that the sunflower problem is hard if there exists an efficiently samplable distribution
D over {C : {0, 1}
2n log n → ({0, 1}
n )
n }—circuits that succinctly represent a collection of sets as
above—such that for every probabilistic polynomial-time algorithm A, there exists a negligible
function negl(·) such that
Pr
C←D[i1,...,in+1 ← A(1n,C); C(i1),...,C(in+1) are a sunflower] ≤ negl(n),
where the probability is over the uniform choice of C ← D and the randomness of A.
Theorem A.3. The sunflower problem is hard assuming the existence of collision-resistant hash
functions.
Proof. We first construct a large set Fno in which there is no sunflower of size n + 1 (our
construction is taken from Exercise 6.2 in Jukna (2011)). Fix arbitrary n pairwise disjoint sets
T1,...,Tn ⊆ {0, 1}
n each of size n and consider the family Fno of sets of size n such that every
set has exactly one element from each Ti . That is,
Fno = {S ∈ ({0, 1}
n )
n | ∀i ∈ [n] : |S ∩Ti | = 1}.
First, we observe that the family Fno is of size nn. Second, the fact that the family Fno has no
sunflowers of size n + 1 follows from the pigeonhole principle: for any j ∈ [n] there must be two
sets that contain the same element in Tj . Thus, the core Y must contain an element in each of the
Tj ’s, which leaves its petals empty. Last, we observe that Fno has a succinct representation as a
circuit: given a number  ∈ [nn], one can obtain the th set of Fno by first writing  in base n as
 = (1,...,n ) and then outputting the set {Tj[j]}i ∈[n] (where Tj[j] is the jth element of Tj).
We proceed with the construction of the hard distribution for the sunflower problem. To sample
a succinct representation of a collection of sets, we sample a collision-resistant hash function h :
{0, 1}
2n log n → {0, 1}
n log n and define the circuitC ⊗ h : {0, 1}
2n log n → ({0, 1}
n )
n as: Given an index
i ∈ {0, 1}
2n log n, we first hash it down to h(i) ∈ {0, 1}
n log n and then return the h(i)th element of Fno.
The description of this circuit is polynomial in n and it consists of an evaluation of a description
of Fno (which is polynomial in n) and a single evaluation of h.
Solving the sunflower problem for C can be reduced to finding collisions relative to h. Indeed,
assume that there is an efficient adversary A that succeeds in solving the sunflower problem. First,
suppose the adversary found two indices i1,i2 such that C(i1) = C(i2). Since all the sets in Fno are
distinct, it must be that h(i1) = h(i2) and we have found a collision in h. Now suppose that A found
a sunflower and denote the indices of the petals by i1,...,in+1. Also denote i
1 = h(i1),...,i
n+1 =
h(in+1). Either some two i
j ’s are identical or they are all different. In the latter case, it must be that
i
1,...,i
n+1 are indices of n + 1 petals in Fno, but these do not exist, so this cannot happen. The
former, where i
j = i
j for some j, j
 ∈ [n + 1], immediately gives a collision relative to h.
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.                   
White-Box vs. Black-Box Complexity of Search Problems 34:25
B DEFERRED PROOFS FOR RAMSEY GRAPHS
B.1 An Upper Bound on Colorful Ramsey
We restate and prove Propositions 2.11 and 2.12.
Proposition B.1 (Restatement of Proposition 2.11). For every k > 2 and m > 1, it holds that
R(k,..., k 	
 m times
) ≤ mmk .
Proposition B.2 (Restatement of Proposition 2.12). Consider the full graph on N vertices. For
every k < log N, and every coloringψ :

N
2

→ [m], wherem = (log N )/k
log log N −log k , there exists a monochromatic subgraph of size k.
Proof of Proposition 2.11. Notice that the function R(·) is monotone, namely, if k
i ≤ ki for
every i ∈ [m], then
R(k
1,..., k
m ) ≤ R(k1,..., km ).
By Proposition 2.10, we know that
R(k1,..., km ) ≤
m
i=1
R(k1,..., ki−1, ki − 1, ki+1,..., km ).
Thus, the expansion of R(k,..., k 	
 m times
) using this formula, can be viewed as a tree whose root is labeled
by R(k,..., k 	
 m times
) and each internal node is labeled by R(k1,..., km ). The property of the tree is that
if a node is labeled by R(k1,..., km ), then any of its children, labeled by R(k
1,..., k
m ), satisfies
that there exists a j ∈ [n] such that k
j = kj − 1 and k
i = ki for every i ∈ [m] \ {j}. The leaves of the
tree are those nodes labeled by values upper bounded by R(2,..., 2 	
 m times
). Notice that R(2,..., 2 	
 m times
) = 2.
The value of R(k,..., k 	
 m times
) is thus the sum of all the leaves of the tree. Since the value at each
leaf of the tree is 2, the value of R(k,..., k 	
 m times
) is bounded by the number of leaves times 2. By the
description above, the tree is an m-ary tree with depth at most mk − 1. Hence, the total number of
leaves in the tree is at most mmk−1, which means that
R(k,..., k 	
 m times
) ≤ mmk .
Proof of Proposition 2.12. It is enough to show that R(k,..., k 	
 m times
) ≤ N. Thus, by Proposition 2.11, it is enough to show that mmk ≤ N. Indeed, plugging in the value of m from the proposition, we get that
log(mmk ) = mk · logm
= k · (log N)/k
log log N − log k · log  (log N)/k
log log N − log k

= log N · (log log N − log k) − log N · log(log log N − log k)
log log N − log k
Journal of the ACM, Vol. 66, No. 5, Article 34. Publication date: July 2019.                                                            
34:26 I. Komargodski et al.
= log N − log N · log(log log N − log k)
log log N − log k ≤ log N.
Thus, mmk ≤ N, as required.
B.2 A Lower Bound for Ramsey Graphs
We show that a random graph on n vertices is (2 · log N)-Ramsey with high probability. Furthermore, instead of sampling the graph uniformly at random, one can sample it via a limited independence family.
Proposition B.3 (Restatement of Proposition 2.8). A graph on N vertices sampled
via a (2 · log2 N)-wise independent distribution is a (2 · log N)-Ramsey graph with probability
1 − 1/N Ω(log log N )
.
Proof. We review the classical proof showing the existence of a (2 · log N)-Ramsey graph via
the probabilistic method. Sample a random graph G = (V, E) on |V | = N vertices, and fix any set
V  of k vertices. The probability (over G) that V  forms an independent set or a clique in G is at
most
2 · 2−(
k
2 ).
Applying a union bound over the set of all such sets V
, we get that G has a clique or independent
set of size k with probability at most

N
k

· 2 · 2−(
k
2 ) ≤
N e
k
k
· 2 · 2−(
k
2 ).
Plugging in N = 2k/2 (and then k = 2 log N), we get that the above probability is bounded by at
most
2k ·log(2k/2 ·e/k)−(
k
2 )+1 = 2k (k/2+log e−log k)−(
k
2 )+1
≤ 2k (k/2+log e−log k)−(k2/2−k)+1
≤ 2−k log k+k log e+k+1
≤ 1/N O (log log N )
for large enough N.
Observing the above proof, one can see that it remains valid even if G is sampled from a
(2 · log2 N)-wise independent distribution. Thus, we get that sampling a graph G on n vertices
from a (2 · log2 N)-wise independent distribution, results with a (2 · log N)-Ramsey graph with
probability with probability at least 1 − 1/N Ω(log log N )
.       