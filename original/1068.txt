For an even integer t ≥ 2, the Matching Connectivity matrix Ht is a matrix that has rows and columns both
labeled by all perfect matchings of the complete graph on t vertices; an entry Ht[M1, M2] is 1 if M1 and M2
form a Hamiltonian cycle and 0 otherwise. Motivated by applications for the Hamiltonicity problem, we show
that Ht has rank exactly 2t /2−1 over GF(2). The upper bound is established by an explicit factorization of Ht
as the product of two submatrices; the matchings labeling columns and rows, respectively, of the submatrices
therefore form a basis Xt of Ht . The lower bound follows because the 2t /2−1 × 2t /2−1 submatrix with rows
and columns labeled by Xt can be seen to have full rank.
We obtain several algorithmic results based on the rank of Ht and the particular structure of the matchings
in Xt . First, we present a 1.888nnO(1) time Monte Carlo algorithm that solves the Hamiltonicity problem in
directed bipartite graphs. Second, we give a Monte Carlo algorithm that solves the problem in (2 + √
2)
pwnO(1)
time when provided with a path decomposition of width pw for the input graph. Moreover, we show that this
algorithm is best possible under the Strong Exponential Time Hypothesis, in the sense that an algorithm
with running time (2 + √
2 − ϵ )
pwnO(1)
, for any ϵ > 0, would imply the breakthrough result of a (2 − ϵ 
)
ntime algorithm for CNF-Sat for some ϵ  > 0.
CCS Concepts: • Theory of computation → Graph algorithms analysis; Parameterized complexity
and exact algorithms; • Mathematics of computing → Matchings and factors;
Additional Key Words and Phrases: Hamiltonicity, bounded treewidth, parameterized complexity, matchings
1 INTRODUCTION
The Hamiltonicity problem and its generalization to the traveling salesman problem are widely
acknowledged to be two of the most famous NP-complete problems. Many classic algorithms were
invented to tackle these problems (and variants thereof), among them Cristofides’s approximation
algorithm (Christofides 1976), the Lin-Kernighan heuristic (Lin and Kernighan 1973), and a
polynomial-time approximation scheme for Euclidean TSP (Arora 1998).
A very early and classic result belonging to this list is due to Bellman (1958, 1962) and,
independently, Held and Karp (1961); it demonstrates that the traveling salesman problem can be
solved in O(n22n ) time, where n denotes the number of vertices of the input graph. In order to
get this result, they introduced dynamic programming over subsets, which became a fundamental
algorithmic paradigm for obtaining exact exponential-time algorithms (see, e.g., Dreyfus and
Wagner (1972) and Fomin and Kratsch (2010, Chapter 3)). Considerable effort has been taken to
improve these algorithms: more space-efficient algorithms have already been given independently
by several authors (Bax 1993; Karp 1982; Kohn et al. 1977).
In his influential survey, Woeginger (2001) brought renewed attention to the question already
suggesting itself from the 1960s: can either the traveling salesman problem or the Hamiltonicity
problem be solved in (2 − ϵ )
nnO(1) time for some ϵ > 0? An affirmative answer was given for the
special cases of bounded degree (Eppstein 2007; Björklund et al. 2010; Iwama and Nakashima 2007;
Gebauer 2011) and claw-free graphs (Broersma et al. 2009). A breakthrough result (Björklund 2014)
partially resolved the open question by giving an 1.66nnO(1) time Monte Carlo algorithm deciding
Hamiltonicity of undirected graphs, using as a first step a 2n/2
nO(1)
-time algorithm for bipartite
graphs. Unfortunately, it seems hard to derandomize this algorithm or to extend it to the traveling
salesman problem without incurring a pseudo-polynomial dependence on the input weights.
A different approach for coping with NP-hard graph problems such as Hamiltonicity is to exploit
structure of the inputs, e.g., to seek fast algorithms for input graphs that have low treewidth or
pathwidth. Pathwidth decompositions and the closely related tree decompositions (and their corresponding widths) have proved to be an excellent tool for dealing with many NP-hard problems
on graphs. In the 1970s and 1980s, several groups of researchers discovered the concept independently. In their fundamental work on graph minors, Robertson and Seymour (1984) introduced the
notions path/treewidth and path/tree decomposition, and these became the dominant terminology.
A graph having a small path/treewidth means informally that it can be decomposed efficiently in a
path/tree-like manner. Many problems can be solved using dynamic programming by decomposing
a solution according to the given path/tree decomposition. We refer to Bodlaender (2007) for more
information on these notions. In early work on algorithms for bounded treewidth graphs, such as
the influential result of Courcelle (1990), running times of the type f (tw)n were obtained.1 Later
it was noticed that for many such algorithms the function f (tw) can be substantially improved,
greatly improving the tractability as well. For example, for many problems whose solutions can
be verified by separately considering its intersection with all neighborhoods of the vertices of the
input graph, we can obtain 2O(tw)
nO(1) time by employing dynamic programming. In particular,
the Independent Set, or equivalently the Vertex Cover, problem can be solved in 2twnO(1) time
(Kleinberg and Tardos 2005; Niedermeier 2002). From the work of Impagliazzo et al. (2001) and
standard reductions, it follows that this dependence cannot be improved to subexponential algorithms unless the Exponential Time Hypothesis fails, i.e., unless CNF-SAT has a subexponential
algorithm. Lokshtanov et al. (2011) showed that under a stronger assumption (the so-called Strong
Exponential Time Hypothesis (SETH)), the current algorithms are optimal in an even stronger
sense. In particular, problems with current best running time f (tw)nO(1) cannot be solved in
f (tw)
1−ϵnO(1) time for positive ϵ. For example, here f (tw) is 2tw for the Independent Set and 3tw
for the Dominating Set.
1We assume that an input graph G on n vertices along with a path decomposition of G width tw is given.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:3
For the Traveling Salesman problem, or even the Hamiltonian cycle problem, the situation is
different since they are not local problems (see, e.g., Göös and Suomela (2011, Section 5)). Dorn
et al. (2012) introduced the notion of a Catalan structure to obtain an algorithm that solves the
k-path problems on H-minor free graphs in 2O(tw) time. To obtain this, their result works for
“pairing encodable” problems (i.e., problems where the connectivity properties can be encoded by
a matching/pairing) since it bounds the number of ways paths can intersect with a part of the tree
decomposition. Cygan et al. (2011) showed that along with many other connectivity problems,
the Hamiltonian cycle can be solved by a Monte Carlo algorithm in 4twnO(1) time. For many of
these algorithms with running time f (tw)nO(1)
, it was shown that an algorithm running in time
f (tw)
1−ϵnO(1) would violate SETH. Nevertheless, the exact complexity of the Hamiltonian cycle
problem remained elusive.
Recently a superset of the current authors found a connection of the optimal substructure of
a dynamic programming algorithm with the rank of a certain matrix (Bodlaender et al. 2015):
consider a matrix H with rows and columns indexed by partial solutions, with a 1 if and only
if the two partial solutions combined give a valid solution; then, if we have more than rk(H)
partial solutions, one will be redundant in the sense that we can safely forget it. Here rk(·)
can denote the rank of H over any field, but in this context it is mostly taken to be GF(2).
This leads to deterministic 2O(tw)
nO(1)
-time algorithms for many connectivity problems, in a
sense derandomizing the work of Cygan et al. (2011), but the used techniques do not allow for
algorithms with matching running times, e.g., the 4twnO(1) time for Hamiltonian cycle.
Our Contribution
Inspired by the mentioned result from Bodlaender et al. (2015), we study a matrix that we call the
Matching Connectivity matrix. We present a family of perfect matchings Xt , which we show to
be a basis of the Matching Connectivity matrix, so in particular we establish its rank. All further
results of the article use the basis Xt and its properties as its key tool, which we now elaborate on.
Determining the Rank of the Matching Connectivity Matrix. For an even integer t ≥ 2, the
Matching Connectivity matrix Ht is a matrix that has rows and columns both labeled by all
perfect matchings of the complete graph Kt on t vertices; an entry Ht[M1, M2] is 1 if M1 ∪ M2 is a
Hamiltonian cycle and 0 otherwise. The centerpiece of our work is that Ht has rank exactly 2t /2−1
over GF(2). To establish this result, we define an explicit family Xt of 2t /2−1 perfect matchings onKt
and show that its columns (or rows) form a basis of Ht over GF(2): First, each matching M ∈ Xt
has a unique partner M ∈ Xt such that their union is a Hamiltonian cycle. Thus, the rows and
columns labeled by Xt induce a permutation matrix, which implies the required rank lower bound.
Second, we give an explicit factorization of Ht into a product of two rectangular matrices with
inner dimensions indexed by Xt in Theorem 3.4. This proves that Xt is indeed a basis, provides an
explicit formula for linear combinations, and completes the claimed rank bound (see Section 3).
In Raz and Spieker (1995), a matrix H
t is studied that is obtained by restricting Ht to all perfect
matchings of the complete bipartite graph with independent sets of size t/2. There it is shown via
group representation theory that the rank of H
t is exactly ( t−1
t /2−1 ), where the rank is taken over the
reals. Using this result, the authors disprove the original2 “log-rank conjecture” in communication
complexity: they also showed that the nondeterministic communication complexity of determining whether two such matchings give a Hamiltonian cycle is Ω(t log log t), while the log-rank
conjecture would imply O(t). In Bodlaender et al. (2015, Lemma 3.13), a factorization of a matrix
that contains Ht as a submatrix into two matrices with inner dimension 2t−1 was given.
2A weakened version is still a standing open problem in communication complexity (Arora and Barak 2009, Section 13.2).
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
12:4 M. Cygan et al.
Exact Algorithms for Hamiltonicity. By exploiting the specific form of the basis Xt , we show
that the number of distinct subsets of all the matchings of Xt is O(1.888t ). Together with the
factorization from Theorem 3.4, this allows us to give deterministic algorithms that compute the
parity of the number of Hamiltonian cycles in undirected graphs and directed bipartite graphs
(Section 3.2) in 1.888nnO(1) time. By combining those results with the Isolation Lemma (Mulmuley
et al. 1987), we obtain Monte Carlo algorithms solving the decision version of Hamiltonicity in
both undirected and directed bipartite graphs within the same running time.
Even though our algorithm for undirected graphs is slower than the algorithm of
Björklund (2014), we believe it is of interest as it uses very different tools and allows solving the
problem also in directed bipartite graphs. We would like to recall that solving the Hamiltonicity problem on undirected bipartite graphs in O((2 − ϵ )
n ) time was the first step of Björklund on
the way to the algorithm for general undirected graphs. For this reason, we believe that studying
directed bipartite graphs is justified.
Algorithm for Bounded Pathwidth. Using the set of perfect matchings Xt , we obtain a faster
algorithm for solving the Hamiltonian cycle problem via a nontrivial pathwidth dynamic
programming routine. Regarding the algorithm, from the rank bound, it follows that we only
need (2 + √
2)
pwnO(1) space to solve the Hamiltonian cycle on a graph with a given path decomposition of width pw: the key idea is to replace memoization of all partial solutions by storing only
fingerprints (i.e., basis representations) of groups of solutions that encode how many partial solutions are consistent with a given basis matching. In fact, these numbers are stored only modulo
two, which requires only 1 bit per basis matching. To achieve time (2 + √
2)
pwnO(1)
, we show in
Lemma 4.1 how to efficiently convert these fingerprints from one basis to another, which permits
us to perform the needed dynamic programming table computations (in particular, insertion of
edges into partial solutions); this crucially depends on the structure of Xt . Notably, Lemma 4.1
gives a second proof of the rank upper bound for Ht , but it does so in a more implicit way.
Let us point out the main differences to the related algorithmic results obtained by Bodlaender
et al. (2015): the present faster algorithm for Hamiltonicity parameterized by pathwidth uses
a new dynamic programming strategy, unlike the results of Bodlaender et al. (2015) that speed
up existing dynamic programming formulations. Furthermore, we require randomization (for
the Isolation Lemma (Mulmuley et al. 1987)) to guarantee a unique solution, in order for the
fingerprinting approach to work. Finally, achieving time (2 + √
2)
pwnO(1) depends crucially on the
structure of the set Xt of basis matchings to allow for Lemma 4.1 and does not appear to follow directly from the rank. (Similarly, the subsequent lower bound requires the existence of a sufficiently
large permutation/identity matrix in Ht and does not follow directly from the rank lower bound.)
Matching Lower Bound Assuming SETH. We show that if the running time of our algorithm can be
significantly improved, then satisfiability of CNF-Sat formulas consisting of m clauses and n variables can be determined in (2 − ϵ )
nmO(1) time. The latter would contradict the Strong Exponential
Time Hypothesis introduced by Impagliazzo et al. (2001). Although there is no consensus about its
truth, a number of results were given that provide lower bounds conditioned on SETH (Patrascu
and Williams 2010; Cygan et al. 2016; Lokshtanov et al. 2011; Cygan et al. 2011). As with previous
results, this result should be interpreted as that there is a barrier to significantly improving our
algorithm, namely, finding the so far elusive (2 − ϵ )
nmO(1) algorithm for CNF-Sat.
For the tight conditional time lower bound, we use our basis as a part of a gadget in a reduction
from CNF-Sat. Although the basic setup is similar to previous lower bounds (Lokshtanov et al. 2011;
Cygan et al. 2011), our reduction is different in the sense that we require a very generic gadget
(the induced subgraph gadget, discussed in Section 5.1). Using this, we can exploit the crucial
property that the submatrix of the Matching Connectivity matrix that is induced by the columns
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:5
and rows of Xt is a permutation matrix; i.e., each basis matching has a unique partner in Xt such
that their union is a Hamiltonian cycle. Then in a similar way as in previous reductions (see, e.g.,
Lokshtanov et al. (2011) and Cygan et al. (2011)), choices made by a Hamiltonian cycle per bag can
be propagated through a series of gadgets (see Section 5) throughout the path decomposition.
Further Algorithmic Conclusions. As a corollary of our bounded pathwidth algorithm in Section 4
(Corollary 4.6), we also obtain a (1 + √
2)
n/6+ϵnnO(1) ≤ O(1.1583n ) time Monte Carlo algorithm for
Hamiltonicity in cubic graphs, which to the best of our knowledge is the fastest known algorithm
in this class of graphs.
2 PRELIMINARIES
Graphs. We use standard graph notation; in particular, we use (u,v) to denote an arc (directed
edge) from a vertex u to a vertex v, while for undirected edges we use the {u,v} notation. For a
graph G = (V, E), we write V (G) and E(G) for its vertex and edge set, respectively. For X,Y ⊆ V ,
we let E(X,Y ) be the set of all edges with one endpoint inX and one inY. A Hamiltonian cycle is the
edge set of a simple cycle that visits each vertex exactly once. A cycle cover is a set of edges F ⊆ E
such that each vertex of G is incident with exactly two of these edges; in other words, the edges
form simple cycles. On the other hand, a path packing is a set of edges F ⊆ E such that each vertex
ofG is incident with at most two edges and there are no cycles in F ; i.e., F is a set of vertex disjoint
paths. Note that if we remove at least one edge from each cycle of a cycle cover, then we obtain a
path packing.
Perfect Matchings. A perfect matching of a graph is a set of edges such that each vertex is
incident with exactly one of them. It is well known that the union of any two perfect matchings
in a graph forms a cycle cover of the graph, where some cycles are potentially of length 2. Given
some base set U , we use Π2 (U ) for the set of all perfect matchings of U ; i.e., if U has no graph
structure, then all partitions into sets of size 2 each are included. Borrowing from the partition
lattice partially ordered by refinement, we use M1 	 M2 = {U }, for M1, M2 ∈ Π2 (U ), to express the
fact that the union of the two perfect matchings M1 and M2 is a Hamiltonian cycle; for two perfect
matchings, this is equivalent to getting the trivial partition {U } into a single set as the outcome of
the meet operation 	. For the sake of completeness, let us formally define P1 	 P2 for two arbitrary
partitions P1 and P2 ofU : define a relation R ⊆ U 2 by letting (x,y) ∈ R if x and y are in the same set
in P1 or P2 (or both), and let the equivalence relation R∗ be the transitive closure of R. The outcome
of P1 	 P2 is then exactly the partition P of U into the equivalence classes according to R∗. For the
special case where P1 and P2 are (perfect) matchings of U , this simplifies to taking the graph with
vertex set U and an edge between two vertices x and y if they are in the same set in P1 or P2; the
partition P = P1 	 P2 is then induced by the connected components. (It is perhaps instructive to
check that perfect matchings whose union is not a Hamiltonian cycle yield at least two connected
components.) We do not require any further tools or notation from the partition lattice.
Pathwidth and Path Decompositions. A path decomposition of a graph G = (V, E) is a path P in
which each node x has an associated set of vertices Bx ⊆ V (called a bag) such that  Bx = V and
the following properties hold:
(1) For each edge {u,v} ∈ E(G), there is a node x in P such that u,v ∈ Bx .
(2) If v ∈ Bx ∩ By , then v ∈ Bz for all nodes z on the (unique) path from x to y in P.
The pathwidth of P is the size of the largest bag minus one, and the pathwidth of a graph G is the
minimum pathwidth over all possible path decompositions ofG. Since our focus here is on dynamic
programming over a path decomposition, we only mention in passing that the related notion of
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
12:6 M. Cygan et al.
treewidth can be defined in the same way, except for letting the nodes of the decomposition form
a tree instead of a path.
It is common for the presentation of dynamic programming to use path and tree decompositions
that adhere to some simplifying properties, in order to make the description easier to follow. The
most commonly used notion is that of a nice tree decomposition, introduced by Kloks (1994); the
main idea is that adjacent nodes can be assumed to have bags differing by at most one vertex,
which can be achieved without increasing the treewidth. For an overview of tree decompositions
and dynamic programming on tree decompositions, see Bodlaender and Koster (2008) and Hicks
et al. (2005). In a similar way, but using also the extension of introduce edge bags from Cygan et al.
(2011), we define nice path decompositions as follows.
Definition 2.1 (Nice Path Decomposition). A nice path decomposition is a path decomposition
where the underlying path of nodes is ordered from left to right (the predecessor of any node
is its left neighbor) and in which each bag is of one of the following types:
—First (leftmost) bag: the bag associated with the leftmost node x is empty, Bx = ∅.
—Introduce vertex bag: an internal node x of P with predecessor y such that Bx = By ∪ {v} for
some v  By . This bag is said to introduce v.
—Introduce edge bag: an internal node x of P labeled with an edge {u,v} ∈ E(G) with predecessor y for which u,v ∈ Bx = By . This bag is said to introduce {u,v} and for each edge
there is exactly one bag introducing it.
—Forget bag: an internal node x of P with predecessor y for which Bx = By \ {v} for some
v ∈ By . This bag is said to forget v.
—Last (rightmost) bag: the bag associated with the rightmost node x is empty, Bx = ∅.
It is easy to verify that any given path decomposition of pathwidth pw can be transformed in
time |V (G)|pwO(1) into a nice path decomposition without increasing the width.
Further Notation. For two integers a,b, we use a ≡ b to indicate that a is even if and only if b
is even. We use Iverson’s bracket notation: if p is a predicate, we let [p] be 1 if p is true and 0
otherwise. If ω : U → {1,..., N}, we use the shorthand ω(S) =
e ∈S ω(e) for S ⊆ U .
3 STRUCTURE OF THE MATCHING CONNECTIVITY MATRIX
This section is outlined as follows: We will first determine the structure of the Matching Connectivity matrix Ht in Section 3.1. More specifically, we give a basis and determine the rank exactly
through an explicit matrix factorization. In Section 3.2, we will give an application of the matrix
factorization to exact exponential algorithms for Hamiltonicity.
3.1 Bases and Factorizations of the Matching Connectivity Matrix
Recall that the matrix Ht has rows and columns both labeled by all perfect matchings of the complete graph Kt on t vertices; an entry Ht[M1, M2] is 1 if M1 ∪ M2 is a Hamiltonian cycle and 0
otherwise. The dimension of the matrix is
t!
( t
2 )! · 2
t
2
×
t!
( t
2 )! · 2
t
2
.
Let us point out some small cases: for t = 2, we have only a single perfect matching on the two
vertices, and the union of two such matchings is considered a Hamiltonian cycle. (Note that, in all
other cases, where t ≥ 4, there cannot be a Hamiltonian cycle if the two perfect matchings have at
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.  
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:7
Table 1. Matrix H6 Together with Some Auxiliary Information
Rows and columns are indexed by the 15 perfect matchings on baseset {0, ..., 5}, each depicted schematically. Matchings numbered 1, 2, 4, and 5 correspond to the basis X6 = {X (00), X (01), X (10), X (11)} from Definition 3.1. The column
labeled LC shows how each row of H6 can be obtained as a linear combination over GF (2) of the rows corresponding
to the four basis matchings.
least one edge in common.) For t = 4, there are three perfect matchings and H4 is easily seen to be
the complement of the 3 × 3 identity matrix. The matrix H6 is a 15 × 15 matrix shown in Table 1.
To prove the exact value of the rank, we introduce for each even t ≥ 2 a family Xt of 2t /2−1
perfect matchings with the goal of proving that the corresponding columns (or rows) of Ht form
a basis over GF(2). The definition of Xt requires the vertices to be ordered, say, 0, 1,...,t − 1, and
edges in the matchings are very local; i.e., their endpoints are at distance at most 3 with respect to
the ordering. From the structure of the matchings, it will be easy to see that they give a lower bound
for the rank of Ht : the submatrix of Ht induced by rows and columns from Xt is a permutation
matrix, which already has rank 2t /2−1 itself. This property will be of the essence for our lower
bound on the running time of pathwidth-based dynamic programming for the Hamiltonian cycle
problem in Section 5.
Getting the matching upper bound is more involved. We obtain this result by giving a concrete factorization of Ht in terms of two rectangular submatrices of Ht induced by the rows and
columns indexed by elements from Xt . This factorization is proved by a rather technical inductive
argumentation and will form the basis of our algorithm in Section 3.2.
Let us begin by introducing the families Xt for every even t. For a perfect matching M ∈ Π2 (U ),
we define a function αM : U → U with αM (i) = j if and only if {i, j} ∈ M; i.e., αM maps each element
of U to its partner in the perfect matching M. We use the shorthand Ut := {0, 1,...,t − 1}.
Definition 3.1. Let ε denote the empty string. We let X (ε) := {{0, 1}} and X2 := {X (ε)}. Let t ≥ 4
be an even integer and let a be a bitstring of length t
2 − 2. We define perfect matchings X (a0)
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
12:8 M. Cygan et al.
and X (a1) of Ut = {0,...,t − 1} as follows, using α := αX (a):
X (a1) := X (a) ∪ {{t − 2,t − 1}},
X (a0) := (X (a) \ {{t − 3, α (t − 3)}}) ∪ {{t − 3,t − 1}, {t − 2, α (t − 3)}}.
We use a¯ to denote the binary complement of a bitstring a. Finally, we let Xt be the set of all
perfect matchings X := X (a) for any bitstring a of length t
2 − 1.
Unfortunately, the formal definition is not very enlightening regarding the actual structure of
the perfect matchings X (a) in Xt . Let us clarify their structure by first showing the matchings
for t = 4 and t = 6; recall that X (ε) = {{0, 1}}, and note that
X (1) = {{0, 1}, {2, 3}}, X (0) = {{0, 2}, {1, 3}},
X (11) = {{0, 1}, {2, 3}, {4, 5}}, X (10) = {{0, 1}, {2, 4}, {3, 5}},
X (01) = {{0, 2}, {1, 3}, {4, 5}}, X (00) = {{0, 2}, {1, 4}, {3, 5}}.
See also Table 1. When recursively constructing further perfect matchings for some even integer t ≥ 4, we always either add another edge on the two new elements (when the new bit is 1)
or we replace the last edge (i.e., the one matching t − 3 to t − 4 or t − 5; note that t − 3 is the last
element for t = t − 2) by matching its vertices to the two new elements (when the new bit is 0).
Let us explain the intuition behind the bitstrings: let t = 6 and group the elements as 0 | 1, 2 |
3, 4 | 5. Observe that the matchingsX (00),X (01),X (10), andX (11) are exactly all choices of matching the elements such that each edge connects two elements that have exactly one dividing vertical
line between them, i.e., all choices of perfect matchings that match only elements from adjacent
groups. Now the first bit in the bitstring determines whether the first edge is {0, 1} or {0, 2}. (These
are all possible options for matching 0 under the group restriction.) Depending on this, either 2
or 1 still needs to be matched to 3 or 4; the latter choice is determined by the second bit. The last
edge must always go to element t − 1 (i.e., 5 in this example), so there are only t
2 − 1 bits.
Proposition 3.2. Let t ≥ 2 be an even integer, and group the elements of {0,...,t − 1} into 0 |
1, 2 | ... | t − 3,t − 2 | t − 1. The family Xt consists of all perfect matchings on the complete graph
with vertex set {0,...,t − 1} that match only elements from adjacent distinct groups. There are 2t /2−1
such perfect matchings.
Clearly, the presented families of perfect matchings, one for each even integer t, have a very
particular and symmetric structure. Our aim is to show that the 2t /2−1 perfect matchings form a
basis for the Matching Connectivity matrix Ht . Regarding any two such matchings X (a) and X (b),
it is not hard to show that their union is a Hamiltonian cycle if and only if a = ¯
b.
Proposition 3.3. Let t ≥ 4 be an even integer and let a and b be bitstrings of length t
2 − 1.
Then X (a) ∪ X (b) is a Hamiltonian cycle of Kt if and only if b = a¯.
Proof. Consider the first position, say, i, such that a[i] = b[i]. (Note that we consider a and b
to be indexed from left to right, starting with 0.) All earlier positions j < i are hence different,
and following the definition of X (·), this means that they prescribe exactly opposite choices. For
example, one matching will match 0 to 1 and the other matches it to 2, without loss of generality {0, 1} ∈ X (a) and {0, 2} ∈ X (b). Consequently, the next bit specifies the matching for 2 in X (a)
and the matching for 1 in X (b). This pattern continues and effectively we obtain two paths that
start from 0 and follow edges from X (a) and X (b) alternatingly. If the paths meet only at t − 1
(for which there is no bit that allows an alternate choice of matching), then together they give a
Hamiltonian cycle. Since we assumed that a[i] = b[i], the paths meet when the bits prescribe that
both matchings match to the same element. (It can be verified that bit i decides whether the so far
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:9
unmatched element of 2i − 1 and 2i is matched to 2i + 1 or 2i + 2.) Thus, we have found a cycle in
the union of X (a) and X (b) that does not contain all vertices, and the union of the two matchings
does not form a Hamiltonian cycle. (Note the special case of a[0] = b[0], which indicates that both
matchings contain {0,p} for p ∈ {1, 2}.)
From Proposition 3.3, we directly get a rank lower bound of 2t /2−1 since the submatrix given by
all rows and columns of matchings X (·) is a permutation matrix of size 2t /2−1 × 2t /2−1.
Now we state the main theorem of this section. Due to its technicality, the proof is deferred to
Section 6. The theorem is equivalent to the claim that the Matching Connectivity matrix Ht is the
product of two rectangular submatrices of Ht whose rows and columns are labeled by matchings
from Xt . This theorem implies that the set of those rows/columns forms a basis for Ht and that its
rank is 2t /2−1.
Theorem 3.4. Let t ≥ 2 be an even integer and let M1, M2 ∈ Π2 (Ut ). We have that
[M1 	 M2 = {Ut }] ≡

a ∈{0,1}
t /2−1
[M1 	 X (a) = {Ut }] · [M2 	 X (a¯) = {Ut }],
where X (a),X (a¯) ∈ Xt according to Definition 3.1.
Recall that [M1 	 M2 = {Ut }] is exactly the entry in Ht in the row indexed by M1 and column
indexed by M2. Consequently, we can read Theorem 3.4 as a factorization of Ht into a product of
two submatrices (up to permutation of the columns) of Ht :
Ht ≡ C · D. (1)
The first submatrix (denoted asC in the above formula) has rows labeled by all perfect matchings
on Ut and columns labeled by basis matchings X (a) for lexicographically ordered bitstrings a ∈
{0, 1}
t /2−1. The second matrix (D) has columns labeled by all perfect matchings of Ut and rows
labeled by basis matchings X (a¯) for lexicographically ordered bitstrings a ∈ {0, 1}
t /2−1.
Corollary 3.5. The rank of the Matching Connectivity matrix Ht over GF(2) is 2t /2−1 for all even
integers t ≥ 2.
Proof. It follows from Proposition 3.3 that the rank is at least 2t /2−1 as the Matching
Connectivity matrix Ht contains a 2t /2−1 × 2t /2−1 submatrix, which is a permutation matrix.
From Equation (1), which follows from Theorem 3.4, we immediately get that the rank is at
most 2t /2−1, as both submatrices have rank at most 2t /2−1 equal to their smaller dimension.
3.2 Exact Algorithms for the Hamiltonicity Problem
In this section, we present Monte Carlo algorithms for solving the Hamiltonian cycle problem in
time O(1.888npoly(n)) in undirected graphs and directed bipartite graphs. These algorithms are
based on further ideas and insights about the family Xt of perfect matchings, and in particular we
greatly rely on Theorem 3.4.
First, we show that to solve the decision version, it is enough to solve the problem of computing
the parity of the number of Hamiltonian cycles modulo two. The main part of our algorithm lies
in the proofs of the following two lemmas (the proofs are provided in Section 3.2).
Lemma 3.6. There is an algorithm that, given an undirected graph G = (V, E) together with a
weight functionω : E → {1,...,ωmax}, finds the parity of the number of Hamiltonian cycles of weight
ω∗ for every ω∗ ∈ {0,...,nωmax} in O(1.888npoly(n + ωmax)) time.
Lemma 3.7. There is an algorithm that, given a directed bipartite graphG = (V,A) together with a
weight function ω : A → {1,...,ωmax}, finds the parity of the number of directed Hamiltonian cycles
of weight ω∗ for every ω∗ ∈ {0,...,nωmax} in O(1.888npoly(n + ωmax)) time.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.  
12:10 M. Cygan et al.
Now, by an application of the Isolation Lemma, we can show that our modulo two counting of
solutions suffices to determine (with high probability) whether or not G is Hamiltonian.
Definition 3.8. A function ω : U → Z isolates a set family F ⊆ 2U if there is a unique S ∈ F
with ω(S
) = minS ∈F ω(S).
Lemma 3.9 (Isolation Lemma, Mulmuley et al. (1987)). Let F ⊆ 2U be a nonempty set family
over a universe U . For each u ∈ U , choose a weight ω(u) ∈ {1, 2,...,ωmax} uniformly and independently at random. Then Pr[ω isolates F ] ≥ 1 − |U |/ωmax.
Theorem 3.10. There exists a Monte Carlo algorithm solving the Hamiltonian cycle problem in
O(1.888npoly(n)) time in undirected graphs and directed bipartite graphs.
Proof. Given a graph G (either undirected, or directed bipartite) with m edges (arcs), for each
edge (arc), assign an integer weight from the set {1,...,ωmax} uniformly and independently at
random, where ωmax = 2m. Then we use Lemma 3.6 (Lemma 3.7) to calculate the parity of the
number of Hamiltonian cycles of each weight ω∗ ∈ {0,...,nωmax}. If for some ω∗ there is an odd
number of Hamiltonian cycles, then our algorithm returns YES; otherwise, it returns NO.
The running time of the algorithm follows from the running time of the black-box usage of the
parity calculating algorithm. If there is no Hamiltonian cycle in our graph, then our algorithm
certainly returns NO. However, if the graph contains at least one Hamiltonian cycle, then by
Lemma 3.9, with probability at least 1/2, our weight function isolates the family of all Hamiltonian
cycles of G, and consequently for some weight there is an odd number of Hamiltonian cycles
and our algorithm returns YES. (Note that the weight of any Hamiltonian cycle is at most
nωmax = 2nm.) Therefore, we have obtained a Monte Carlo algorithm.
Further Uses of the Basis Matchings
In this section, we give two technical lemmas that form the core of our two algorithms, which
are based on the families Xt of perfect matchings introduced in Section 3. First, we show that the
number of subsets of all matchings in Xt is bounded by O(1.888t ) (Lemma 3.11). Second, we show
how to compute the number of extensions of basis matchings to Hamiltonian cycles (Lemma 3.14);
for this we use dynamic programming over the mentioned subsets of basis matchings.
Lemma 3.11. The cardinality of the set {Y ⊆ X : X ∈ Xt } is O(1.888t ).
Proof. Recall that Xt = {X (a) | a ∈ {0, 1}
t /2−1}. For an even integer t, define
r(t) = |{S ⊆ X (a) | a ∈ {0, 1}
t /2−1
}|
r2 (t) = |{S ⊆ X (a) | a ∈ {0, 1}
t /2 ∧ S ∩ {{t,t + 1}, {t − 1,t + 1}} = ∅}| .
Less formally,r(n) is the number of distinct matchings being subsets of the basis, whereas forr2 (n)
we consider longer bitstrings, and additionally we assume that the subset does not contain an edge
incident with the last element of the universe, i.e., to t + 1. In what follows, we prove the following
inequalities:
r(t) ≤ 2r(t − 2) + r2 (t − 2) ,
r2 (t) ≤ 4r(t − 2) + r2 (t − 2) .
The first inequality follows from the case analysis of the last bit of the string a and whether S
contains the edge incident with t − 1 or not (which we refer to as the last edge). When we analyze
r(t), we have four cases:
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:11
—The last bit of a is 0, and the set S contains the last edge.
—The last bit of a is 1, and the set S contains the last edge.
—The last bit of a is 0, and the set S does not contain the last edge.
—The last bit of a is 1, and the set S does not contain the last edge.
Note that all the subsets S from the first two cases can be upper bounded by 2r(t − 2), and from
the second two cases by r2 (t − 2), which follows directly from the definition ofr2. Now we analyze
r2 (t); here we have eight cases to consider, depending on the last 2 bits of a (four choices), and
whether S contains an edge between {t − 3,t − 2} and {t − 1,t} (two choices), which we call the
penultimate edge. Note that the edge incident with t + 1 is definitely not contained in S. When S
contains the penultimate edge, then we bound each of the four cases depending on the last 2 bits of
a independently by r(t − 2). Observe that so far we made no savings and no cases were considered
identical. However, the key case is when S does not contain the penultimate edge, which means
that S contains neither the penultimate nor the last edge. The contribution of all those four cases
toward r2 (t) can be upper bounded by r2 (t − 2), as the last bit of a does not matter anymore.
Observe that r(2) = 2 and r2 (2) = 3. Moreover, if we multiply the horizontal vector (r(t),r2 (t))
by the matrix A = (
2 4
1 1 ), we obtain (a,b), where a ≥ r(t + 2) and b ≥ r2 (t + 2). At the same time,
A = BDB−1, where
B =
 1−
√
17
2
1+
√
17
2
1 1 
,D =

3−
√
17
2 0
0 3+
√
17
2


, B−1 =


− 1√
17
1+
√
17
2
√
17
1√
17 −1−
√
17
2
√
17



.
Consequently, Ai = BDi
B−1, where
Di =




3−
√
17
2
i
0
0

3+
√
17
2
i




;
therefore, r(t) = O(( 3+
√
17
2 )
t /2) and the claimed upper bound follows, since matrices B and B−1
contain only fixed constants, which are hidden inside the O-notation.
In fact, one can show that our analysis is tight, since we do not overcount any subsets S in r(t)
or in r2 (t) in our case analysis.
Definition 3.12 (Perfect Matchings). For an undirected graph H, we denote the set of perfect
matchings in H by Π2 (H).
Recall that by Π2 (V ), we denote the set of all perfect matchings in the complete graph on V .
Definition 3.13 (Extensions to Hamiltonian Cycle). For an undirected graph H = (V, E), a weight
function ω : E → {0,...,ωmax}, a perfect matching M ∈ Π2 (V ), and an integer ω∗, we denote the
number of perfect matchings in H of weight ω∗ that together with M form a Hamiltonian cycle by
ext(M,ω∗,H,ω), that is,
ext(M,ω∗
,H,ω) =

M∈Π2 (H ),ω(M)=ω∗
[M 	 M = {V }].
Lemma 3.14. Given an undirected graph G = (V, E) and a weight function ω : E → {0,...,ωmax},
one can in O(1.888npoly(n + ωmax)) time compute all the (nωmax + 1)2n/2−1 values
ext(X (a),ω∗,G,ω) for a ∈ {0, 1}
n/2−1 and 0 ≤ ω∗ ≤ nωmax.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.       
12:12 M. Cygan et al.
Proof. Let v1 be an arbitrary but fixed vertex of G. For a (not necessarily perfect) matching M
in G, a vertex v, and a weight 0 ≤ ω∗ ≤ nωmax, let T [M,v,ω∗] denote the number of walks fromv1
to v in the complete graph on V that (1) contain an even number of edges, (2) start with an edge of
M, (3) alternately use an edge of M and an edge of E, (4) use each edge of M exactly once, and (5)
include edges fromE with a total weight of exactlyω∗. Observe that ext(M,ω∗,G,ω) = T [M,v1,ω∗]
for M ∈ Π2 (V ). Hence, it is enough to describe a dynamic programming routine computing all the
values T [X (a),v1,ω∗] for a ∈ {0, 1}
n/2−1, 0 ≤ ω∗ ≤ nωmax. To this end, it is sufficient to compute
T [M,v,ω∗] for each M that is a subset of some X (a) ∈ Xn, using the following recursive formula:
T [M,v,ω∗
] =

{u, u }∈M
u∈N (v)
T [M \ {{u,u
}},u
,ω∗ − ω({u,v})].
We also define a base case T [∅,v,ω∗] = [v = v1 ∧ ω∗ = 0] for v ∈ V . By Lemma 3.11, the above
formulas together with memoization prove the claimed algorithm.
Proofs of Lemmas 3.6 and 3.7
In this section, we prove Lemmas 3.6 and 3.7; that is, we focus on computing the number of
weighted Hamiltonian cycles modulo two.
Proof of Lemma 3.6. First, we iterate over pairs of distinct edges e1, e2 incident with some
arbitrary fixed vertex v1. We want to find the parity of the number of Hamiltonian cycles containing both e1 and e2. Note that for a different pair of edges incident with v1, we count different
Hamiltonian cycles and each Hamiltonian cycle is counted exactly once. We ensure that n is even
by subdividing the edge e1 if n is odd. This would result in two new edges e
1, e
1 , and we set
ω(e
1) = ω(e1), ω(e
1 ) = 0, where e
1 is incident with v1. We somewhat abuse notation and by e1
denote the edge e
1 in that case. Observe that there is a bijection between weighted Hamiltonian
cycles before the subdivision and after the subdivision.
Since n is even, note that any Hamiltonian cycle containing e1 and e2 can be uniquely decomposed into two perfect matchings M1, M2 in G, where e1 ∈ M1 and e2 ∈ M2. Let us fix a weight
0 ≤ ω∗ ≤ nωmax. Our goal is to compute the number of pairs (M1, M2), where M1, M2 are perfect
matchings in G, e1 ∈ M1, e2 ∈ M2, ω(M1) + ω(M2) = ω∗, and M1 ∪ M2 is a Hamiltonian cycle. Formally, we want to calculate the following sum modulo two:

M1∈Π2 (G)
e1∈M1

M2∈Π2 (G)
e2∈M2
ω(M1 )+ω(M2 )=ω∗
[M1 	 M2 = {V }] .
By Theorem 3.4, the above formula is equal (modulo two) to

M1∈Π2 (G)
e1∈M1

M2∈Π2 (G)
e2∈M2
ω(M1 )+ω(M2 )=ω∗

a ∈ {0,1}n/2−1
[M1 	 X (a) = {V }] · [M2 	 X (a¯) = {V }]
=

a ∈ {0,1}n/2−1

M1∈Π2 (G)
e1∈M1
[M1 	 X (a) = {V }]

M2∈Π2 (G)
e2∈M2
ω(M1 )+ω(M2 )=ω∗
[M2 	 X (a¯) = {V }]
=

a ∈ {0,1}n/2−1

ω1+ω2=ω∗
ext(X (a),ω1, (V, E1),ω) · ext(X (a¯),ω2, (V, E2),ω).
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:13
In the above, we first change the summation order, and then for i = 1, 2 denote Ei = (E \
E(v1,V )) ∪ {ei}. Note that all perfect matchings contributing to ext(X (a),ω1, (V, E1),ω) (and analogously for E2) contain the edge e1, as this is the only edge in the graph (V, E1) incident with v1.
By Lemma 3.14, we can find all the needed values in the claimed running time, and hence the
proof of Lemma 3.6 follows.
In the proof of Lemma 3.7, we have to deal with directed graphs while still using Lemma 3.14,
which can only handle undirected graphs. However, as we will show, one can exploit the bipartiteness to harness the directedness of the graph.
Proof of Lemma 3.7. Let G = (V,A) be a directed bipartite graph with bipartition V = V1 ∪V2.
Clearly, we can assume |V1 | = |V2 |, since otherwise there are no Hamiltonian cycles in G. We
create two auxiliary weighted undirected bipartite graphs G = (V1 V2, E,ω ) and Gr = (V1 
V2, Er,ωr ), where E = {{u,v} : u ∈ V1,v ∈ V2, (v,u) ∈ A}, Er = {{u,v} : u ∈ V1,v ∈ V2, (u,v) ∈ A},
and for u ∈ V1, v ∈ V2 we have ωr ({u,v}) = ω((u,v)) and ω ({u,v}) = ω((v,u)). That is, we split
the arcs of A depending on whether they have their start-point in V1 or V2 and take the two underlying undirected graphs after the split.
Note that each Hamiltonian cycle in G can be uniquely split into two sets of arcs, one of which
corresponds to a perfect matching in G and the other in Gr . Moreover, any pair of a perfect
matching in G and a perfect matching in Gr together forms a cycle cover in G, which may consist
of several cycles. Our goal is to consider all pairs of perfect matchings in G and Gr that together
form a Hamiltonian cycle in the underlying undirected graph of G, which guarantees that we
count exactly the Hamiltonian cycles in the directed bipartite graph G. Let us fix an integer 0 ≤
ω∗ ≤ nωmax and count the number of Hamiltonian cycles of weight ω∗ in the graph G: 
M1 ∈Π2 (G )

M2∈Π2 (Gr )
ω (M1 )+ωr (M2 )=ω∗
[M1 	 M2 = {V }]
(Thm 3.4) ≡

M1 ∈Π2 (G )

M2∈Π2 (Gr )
ω (M1 )+ωr (M2 )=ω∗

a ∈ {0,1}n/2−1
[M1 	 X (a) = {V }] · [M2 	 X (a¯) = {V }]
=

a ∈ {0,1}n/2−1

M1 ∈Π2 (G )
[M1 	 X (a) = {V }]

M2∈Π2 (Gr )
ω (M1 )+ωr (M2 )=ω∗
[M2 	 X (a¯) = {V }]
=

a ∈ {0,1}n/2−1

ω1+ω2=ω∗
ext(X (a),ω1,G,ω ) · ext(X (a¯),ω2,Gr,ωr ).
By Lemma 3.14, the proof of Lemma 3.7 follows.
4 SOLVING THE HAMILTONICITY PROBLEM USING PATH DECOMPOSITIONS
In this section, we present a (2 + √
2)
pwnO(1)
-time algorithm for solving the Hamiltonian cycle
on a graph G with a given path decomposition of width pw. Recall that partial solutions for the
Hamiltonian cycle are sets of paths such that all vertices before the current bag are internal in
some path, and vertices in the current bag may be endpoints, internal, or unused. It then suffices
to remember for each such partition of the current bag in what way the endpoints are connected
into pairs (these arrangements are perfect matchings on the set of endpoints); it is well known
that any further information about the paths is not needed. The downside is that this involves
roughly pwpw many partial solutions, which dominates the running time.
The key idea for our much faster algorithm is as follows: instead of storing for all partitions into
endpoints, internal, and unused vertices all the possible perfect matchings of the endpoints that can
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.                  
12:14 M. Cygan et al.
be implemented by path packings, we only store, intuitively, a combined “fingerprint” of all path
packings together. Indeed, we fix a global ordering of the vertices, which gives an induced ordering
for each subset, and store for each matching of the resulting family Xt the number of path packings
that give a single cycle together with this matching. (These matchings abstract away the need for
connecting through all so far unused vertices since this is covered by the partitions.) In fact, since
our basis works only over GF(2), we can only count those solutions modulo two. Nevertheless,
this is still useful since we ensure, up to sufficiently small error chance, the existence of a unique
Hamiltonian cycle of minimum weight via the Isolation Lemma; to this end we need to solve a
weighted version of our modulo-two counting problem.
Given this setup, let us solve the following problem by dynamic programming on a path decomposition: given a graph G = (V, E) along with a path decomposition of pathwidth pw and nonnegative edge weights ω : E → {1,...,ωmax}, the task is to compute for each ω∗ ∈ {1,...,n · ωmax}
the parity of the number of Hamiltonian cycles of G with weight exactly ω∗. We assume that we
are given a nice path decomposition for G of width at most pw; we treat the decomposition as a
sequence of bags that are ordered from left to right. We also fix an arbitrary ordering of the vertices of G. To solve this problem, we proceed as outlined above: for each partition into internal,
endpoint, and unused vertices, we take the basis for the perfect matchings on the endpoints with
respect to the induced order and compute (and store) the parity of the number of path packings
that are consistent with each basis matching. We maintain and process this information throughout the dynamic programming; the main work is spent (unsurprisingly) on bags that introduce
edges since this causes a rather involved recomputation of fingerprints because inherently we
cannot work explicitly on separate path packings.
For technical convenience, our algorithm “guesses” one edge {x,y} incident with a vertex x of
degree at most pw to be used in the Hamiltonian cycle. Given a nice path decomposition, it can
be easily seen that the rightmost introduce vertex bag can only introduce a vertex x of degree at
most pw: all its neighbors must be in the current bag and no additional possible neighbors can be
added on the right. It can be easily verified that all remaining bags, namely, introduce edge and
forget vertex bags, can be reordered freely under the constraint that no vertex is forgotten before
all its edges were introduced. Thus, for any edge {x,y} incident with x, we can reorder the decomposition such that the last three bags are as follows: (1) introduce edge {x,y}, with current vertex
set {x,y}; (2) forget vertex x; and (3) forget vertex y. It follows that the bag preceding (1) must
also have vertex set {x,y}; we call this the final bag and our dynamic programming algorithm will
process bags from left to right until it has computed the table of the final bag, at which point it will
stop and answer based on the table. Notice that this means that we are interested, for all choices
of total weight ω∗, in the parity of the number of path packings of weight ω∗ that would form a
Hamiltonian cycle together with edge {x,y}. This also implies that we are never interested in
counting partial solutions that contain one or more cycles since adding {x,y} to them cannot
create a single cycle.
Let the vertices of G = (V, E) be ordered arbitrarily, say, V = {v1,...,vn }. We perform dynamic
programming on the given path decomposition, proceeding from left to right until we reach
the final bag, i.e., the one preceding the introduce edge {x,y} bag. At each bag, with some
vertex set B, we compute table entries T [B0, B1, B2,ω∗, M] for all partitions B = B0 ∪ B1 ∪ B2,
all integers ω∗ ∈ {0,...,n · ωmax}, and all perfect matchings M from the basis for B1 under
ordering v1,...,vn restricted to B1. (To clarify the definition of the basis, for B1 = {vi0 ,...,vit−1 }
we order such that i0 < ··· < it−1 and we identify ic → c when applying Definition 3.1.) Each
entry contains the parity of the number of path packings P (each a set of edges) of the graph
induced by all vertices left of and including the current bag and all edges introduced so far, such
that
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:15
(1) P ∪ M is a single cycle,
(2) the total weight of the edges in P is equal to ω∗,
(3) the vertices in Bi have degree exactly i in P,
(4) and all vertices that only occur left of the current bag have degree 2; we denote those
by B.
We call P a (B0, B1, B2, B,ω∗)-path packing if it meets conditions (2), (3), and (4). If it respects all
four properties, then we call it a (B0, B1, B2, B,ω∗, M)-path packing, i.e., if additionally the union
with M is a single cycle. Note that entries T [B0, B1, B2,ω∗, M] with odd size of B1 will always be
zero, because there cannot be an odd number of endpoints in a family of vertex-disjoint paths; we
tacitly ignore these entries.
The main technical difficulty in the dynamic programming lies in handling the information
stored with respect to the basis for perfect matchings of B1, in particular when introducing a
new edge in the path decomposition. It is crucial that we can efficiently compute a representation
of the same information with respect to a different ordering. Intuitively, the following lemma
allows us to change the basis of our representation. Since we apply the lemma separately for each
partition B = B0 ∪ B1 ∪ B2, set of previous vertices B, and choice of weight ω∗, we state it in terms
of a simplified table with one entry T [M] for each basis matching M. The lemma applies to our
dynamic programming application by letting P be the set of all (B0, B1, B2, B,ω∗)-path packings
and letting S = B1.
Lemma 4.1. Let P denote a set of path packings, let t ≥ 2 be an even integer, and let S =
{v0,...,vt−1}. Let X denote the family of basis matchings on S that is obtained via Definition 3.1
when identifying each vi ∈ S with i ∈ {0,...,t − 1}. Furthermore, for each M ∈ X, let T [M] denote
the parity of the number of path packings P ∈ P such that M ∪ P is a single cycle. Let π : S → S
be any permutation of S and let X be the basis that is obtained when first permuting S according
to π and then identifying vi → i, i.e., when identifying each vi ∈ S with j ∈ {0,...,t − 1} such that
π (vi ) = vj . For any matching M ∈ X
, the parity of the number of path packings P ∈ P such that
M ∪ P is a single cycle can be computed from T [] in time 2t /2−1
t O(1)
; we denote these values by
T 
[M
].
Proof. Clearly, any permutation π : S → S of S can be reached from id : S → S : vi → vi by at
most t 2 swaps of two consecutive elements. Thus, it suffices to prove the lemma for the case that
π (vi ) = vi except for two vertices v = vj and w = vj+1 where we have π (vj) = vj+1 and π (vj+1) =
vj . In other words,w is the successor ofv in S (according to indexing of thevi ) and the only change
in ordering is swapping v and w. We refer to the ordering v0,...,vt−1 as the initial ordering and
to v0,...,vj−1,vj+1,vj ,vj+2,...,vt−1 as the obtained ordering.
Let M be an arbitrary matching in the basis X for the obtained ordering. We show that the
computation of T 
[M
] requires at most three values of T []. To this end, we need to consider all
cases for how M matchesv andw and how the vertices are grouped. We begin with some notation.
Recall the grouping of {v0,...,vt−1} into v0 | v1,v2 | ... | vt−3,vt−2 | vt−1. Throughout, we will
specify only the part of the ordering that is necessary to distinguish the different cases (along with
edges in M
)—e.g., the first case will be | v,w |, i.e., that v andw are in the same group of the initial
ordering. To avoid redundant cases, we sometimes explicitly do not fix the position of vertices in
the first and last group; e.g., inw | v
,v | w, the vertexw could be the first or second vertex of its
group, but this will make no difference since basis matchings only have to respect the grouping.
This option never applies tov orw sincew being the successor ofv always determines its position;
e.g., it must be the first vertex of its group in v | w.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.     
12:16 M. Cygan et al.
Fig. 1. Case i): matchings M
, M1, M2 restricted to the set {v,v
,w,w
} displayed with respect to the initial
ordering.
We first discuss two simple cases, namely, those where M is also a basis matching for the initial
ordering of vertices, implying that T 
[M
] ≡ T [M
]. For once, this happens if v and w are in the
same group, i.e., if the swap ofv andw takes the ordering from | v,w | to | w,v |. Since the grouping
in both orders is the same, it follows directly that M is also in the basis X for the initial ordering.
In the second simple case,v andw are in different (and hence consecutive) groups, and M contains
{v,w}; i.e., the swap of v and w takes the ordering from v | w to w | v. Observe that the grouping
of all endpoints of edges in M \ {{v,w}} is unchanged, and that v andw are in consecutive groups
in both orderings. Thus, we find again that M is also in the basis X for the initial ordering. In both
cases, we get
T 
[M
] ≡ T [M
].
It remains to consider the case that v and w are in consecutive groups and {v,w}  M
; the
swap takes the ordering from v | w to w | v, but we will need a bit more context. Accordingly, let
v and w be the two vertices such that {v,v
}, {w,w
} ∈ M
. We get four subcases, denoted Case
i) through iv), depending on whether v precedes or succeeds v and on whether w precedes or
succeeds w, both understood in the obtained ordering. Since M is in the basis X for the obtained
ordering, this will be enough to deduce the position and grouping of relevant vertices. Crucially,
recall that M being a basis matching means that it contains exactly one of the possible edges
between vertices of consecutive groups, and no further edges.
Case i): v precedes v and w precedes w. Having w | v in the obtained ordering, vertex v must
be the predecessor of w. Thus, the obtained ordering is w | v
,w | v, where we do not specify the
position ofw in its group; the initial ordering isw | v
,v | w. While M is not a basis matching for
w | v
,v | w, due to {v,v
} ∈ M
, the following two matchings M1 and M2 are in X (see Figure 1):
M1 := (M \ {{v,v
}, {w,w
}}) ∪ {{w
,v
}, {v,w}}
M2 := (M \ {{v,v
}, {w,w
}}) ∪ {{w
,v}, {v
,w}}.
We claim that for any path packing P ∈ P, we have that M ∪ P is a single cycle if and only if
exactly one of M1 ∪ P and M2 ∪ P is a single cycle: crucially, all three unions contain F := (M \
{{v,v
}, {w,w
}}) ∪ P. If at least one union is a single cycle, then F must form exactly two disjoint
paths with endpoints v, w, v
, and w
; otherwise, the claim holds trivially. In addition to F , the
three unions contain {{v,v
}, {w,w
}}, {{w
,v
}, {v,w}}, or {{w
,v}, {v
,w}}. Exactly two of these
three pairs of additional edges close F to a single cycle, whereas one creates two separate cycles.
(This corresponds exactly to the behavior of the three perfect matchings on four vertices.) This is
clearly equivalent to our claim, and hence, we can compute the desired value T 
[M
] by
T 
[M
] ≡ T [M1] +T [M2].
Case ii): v succeeds v and w succeeds w. Having w | v in the obtained ordering, the vertex w
must be the successor of v. Thus, the obtained ordering is w | v,w | v
, where we do not specify
the position ofv in its group; the initial ordering isv | w,w | v
. Again, M is not a basis matching
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:17
Fig. 2. Case ii): matchings M
, M1, M2 restricted to the set {v,v
,w,w
} displayed with respect to the initial
ordering.
Fig. 3. Case iv): matchings M
, M1, M2, M3 restricted to the set {u,u
,v,v
,w,w
} displayed with respect to
the initial ordering.
for v | w,w | v
, but the following two matchings M1 and M2 are in X (see Figure 2):
M1 := (M \ {{v,v
}, {w,w
}}) ∪ {{w
,v
}, {v,w}}
M2 := (M \ {{v,v
}, {w,w
}}) ∪ {{w
,v}, {v
,w}}.
Observe that M1 and M2 have the same relation to M as in the previous case. Thus, by the same
argumentation, we get
T 
[M
] ≡ T [M1] +T [M2].
Case iii): v precedes v and w succeeds w. Having w | v in the obtained ordering, the vertex
v must be the predecessor of w, and w must be the successor of v. Thus, the obtained ordering
is | v
,w | v,w |. This, however, contradicts the assumption that M is in the basis X for the
obtained ordering as it would contain two edges between the same group of vertices.
Case iv): v succeeds v and w precedes w. In this case, the four vertices v, v
, w, and w must
be in four different consecutive groups, as edges of M must be between consecutive groups; i.e.,
the obtained ordering is w | ,w | v,  | v
. The two other vertices in the groups of w and v, in
positions marked by , must be matched by M as there needs to be exactly one edge in M between
any two consecutive groups. Thus, the obtained ordering is w | u,w | v,u | v
, where {u,u
} ∈
M
, and the initial ordering isw | u,v | w,u | v
. In this final case, we require the following three
matchings M1, M2, and M3 that are easily seen to be in the basis X for the initial ordering (see
Figure 3):
M1 := (M \ {{u,u
}, {v,v
}, {w,w
}}) ∪ {{w
,u}, {v,u
}, {w,v
}}
M2 := (M \ {{u,u
}, {v,v
}, {w,w
}}) ∪ {{w
,v}, {u,w}, {u
,v
}}
M3 := (M \ {{u,u
}, {v,v
}, {w,w
}}) ∪ {{w
,v}, {u,u
}, {w,v
}}.
We claim that for every P ∈ P, we have that M ∪ P is a single cycle if and only if an odd
number of M1 ∪ P, M2 ∪ P, and M3 ∪ P are single cycles. Similar to the argument in Case i), if at
least one of the unions forms a single cycle, then F := (M \ {{u,u
}, {v,v
}, {w,w
}}) ∪ P must be
a disjoint union of three paths with endpoints in {u,u
,v,v
,w,w
}. A convenient way to verify
the claim is to use Table 1 with the Matching Connectivity matrix fort = 6: observe that M ∪ P =
F ∪ {{u,u
}, {v,v
}, {w,w
}}, so we can equivalently ask whether F ∪ {{u,u
}, {v,v
}, {w,w
}} is a
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.   
12:18 M. Cygan et al.
single cycle, and ditto for
M1 ∪ P = F ∪ {{w
,u}, {v,u
}, {w,v
}},
M2 ∪ P = F ∪ {{w
,v}, {u,w}, {u
,v
}},
M3 ∪ P = F ∪ {{w
,v}, {u,u
}, {w,v
}}.
The set F corresponds to a perfect matching MF on {u,u
,v,v
,w,w
} by letting two vertices
be matched if F contains a path connecting them. Thus, asking whether M ∪ P is single cycle
is equivalent to asking for MF ∪ {{u,u
}, {v,v
}, {w,w
}}; again, analogous statements hold for
Mi ∪ P. All that remains is to consult Table 1, noting that for the ordering w | u,v | w,u |
v
, the matchings {{u,u
}, {v,v
}, {w,w
}}, {{w
,u}, {v,u
}, {w,v
}}, {{w
,v}, {u,w}, {u
,v
}}, and
{{w
,v}, {u,u
}, {w,v
}} correspond to rows 8, 2, 4, and 5, respectively. The possible matchings MF
can now be checked by going over all columns and verifying that the sums modulo two over rows
2, 4, and 5 are equal to the value in row 8. This proves our claim and implies that the desired value
T 
[M
] can be computed via
T 
[M
] ≡ T [M1] +T [M2] +T [M3].
In all cases, we have seen that a single valueT 
[M
], for M ∈ X
, can be computed by accessing
up to three values in T []. Thus, each single value can be computed in only O(1) steps. Doing this
for all 2t /2−1 matchings in the basis X proves the claimed running time.
Now we can return to the description of our algorithm. The dynamic programming on the path
decomposition proceeds from “left” to “right,” using the table of the previous bag, denoted T [],
to compute the table of the current bag, denoted T 
[]. We use Tuv and T 
uv for the corresponding
tables that are obtained by changing ordering and basis (using Lemma 4.1) in such a way that u
and v are the last two vertices in the total order. For introduce and forget vertex bags, there is not
much work required since by themselves vertices do not affect our path packings. The main work
lies in the computations required for the introduce edge bags: path packings that use the new edge
have a different set B1 of degree-1 vertices, which comes with a different basis.
First Bag. For the first bag, the vertex set B is empty and we only get a single trivial table entry:
T 
[∅, ∅, ∅, 0, ∅] ≡ 1.
Introduce Vertex Bag. We have a current bag with vertex set B that introduces a vertex v. Accordingly, the previous bag has vertex set B \ {v}. Furthermore, the set of vertices that occur only
on the left is the same for both bags. Clearly, in the subgraph given by all vertices of the current
and preceding bags plus all edges introduced so far, no path packing can include edges incident
with v. Thus,
T 
[B0, B1, B2, ·, ·] ≡ 0,
for all partitions B = B0 ∪ B1 ∪ B2 with v ∈ B1 ∪ B2. For partitions with v ∈ B0 and any choice
of weight ω∗ and B1-basis matching M, we already have the correct number in the table for the
previous bag, namely,
T 
[B0, B1, B2,ω∗
, M] ≡ T [B0 \ {v}, B1, B2,ω∗
, M].
Forget Vertex Bag. We have a current bag with vertex set B that “forgets” vertex v; the previous bag has vertex set B ∪ {v}. Let B be the vertices that occur only left of the current bag and
note that B \ {v} occur only left of the previous bag. Fix any partition B = B0 ∪ B1 ∪ B2, a matching M from the B1-basis (with standard ordering), and a weight ω∗. If P is a (B0, B1, B2, B,ω∗, M)-
path packing, then v must have degree 2 in P by definition. Conversely, any (B0, B1, B2 ∪ {v},
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.    
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:19
B \ {v},ω∗, M)-path packing P (whose number modulo two is stored in the previous bag) is also
a (B0, B1, B2, B,ω∗, M)-path packing. Hence,
T 
[B0, B1, B2,ω∗
, M] ≡ T [B0, B1, B2 ∪ {v},ω∗
, M].
Introduce Edge Bag. We have a current bag with vertex set B that introduces an edge {u,v}
with u,v ∈ B. The previous bag has the same vertex set B, but the counted path packings cannot
make use of the edge {u,v}, and both bags have the same set B of vertices that occur only left of
them. First, we compute from the tableT [] of the previous bag the tableTuv []; i.e., the information
is represented with respect to a basis that has u and v as the last two vertices in the ordering using
Lemma 4.1. We will proceed by computing T 
uv [], which will subsequently be transformed to T 
[];
this completes the procedure for an introduce edge bag.
We explain the computation of T 
uv [B0, B1, B2,ω∗, M] from Tuv [] for an arbitrary partition B =
B0 ∪ B1 ∪ B2, integer weight ω∗, and perfect matching M; the latter is from the basis for B1 with
modified ordering ofV (i.e., the ordering is induced fromv1,...,vn except that u and v are the last
two elements). We need to consider different cases depending on which sets Bi contain u and v.
i) u ∈ B0 or v ∈ B0: In this simple case, no (B0, B1, B2, B,ω∗)-path packing may contain the
edge {u,v} and the same is true for all perfect matchings M on B1; in particular, this is true for the
matchings from a basis. Thus, directly from the definition of our tables, we get that
T 
uv [B0, B1, B2,ω∗
, M] ≡ Tuv [B0, B1, B2,ω∗
, M]
for all basis matchings M.
ii) u,v ∈ B1: Since M is a perfect matching on B1, it may contain the edge {u,v}. (Recall that
M is from the basis on B1 with respect to the ordering induced from v1 ...,vn except for u and v
being last in the ordering.) We further distinguish cases according to whether {u,v} ∈ M.
ii.1) {u,v} ∈ M: If {u,v} ∈ M and a (B0, B1, B2, B,ω∗, M)-path packing P contains the edge {u,v},
then M ∪ P contains a single cycle on vertices u and v. By definition of our table entries, we compute the parity of the number of path packings where, among others, M ∪ P is a single cycle.
Thus, considering the cycle on u and v, path packings P with {u,v} ∈ P that need to be taken into
account cannot have any further edges beyond {u,v}, implying that B1 = {u,v} and B2 = B = ∅
for such path packings. Clearly, there is a single such path packing, namely, P = {{u,v}}, and its
weight is exactly ω({u,v}). Apart from this, we already know fromTuv [] the parity of the number
of (B0, B1, B2, B,ω∗, M)-path packings that avoid the edge {u,v} and get
T 
uv [B0, B1, B2,ω∗
, M] ≡ Tuv [B0, B1, B2,ω∗
, M]
+ [B2 = B = ∅ ∧ B1 = {u,v} ∧ ω∗ = ω({u,v})].
Note the use of Iverson’s bracket notation in the second term of the recurrence: we get a contribution of 1 corresponding to path packing P = {{u,v}} whenever B2 = B = ∅, B1 = {u,v}, and
ω∗ = ω({u,v}), which are necessary and sufficient for path packings P that include {u,v} and with
M ∪ P being a single cycle, as discussed above.
ii.2) {u,v}  M: we have {u,v}  M, which implies that {p,u}, {q,v} ∈ M for some p,q ∈ B1 \
{u,v} (with p  q) since M is a perfect matching of B1. As before, we already know the parity of
the number of (B0, B1, B2, B,ω∗, M)-path packings that do not contain {u,v} from Tuv []; these
values can be simply retrieved from Tuv [] later.
It remains to compute the parity of the number of (B0, B1, B2, B,ω∗, M)-path packings
that do contain {u,v}, i.e., those that form a single cycle with M. To this end, we consider
all (B0, B1, B2, B,ω∗)-path packings P with {u,v} ∈ P, i.e., without the condition that P ∪ M is
a single cycle, and relate them to path packings considered in the previous bag. Fix any such path
packing P and observe that P ∪ M is a disjoint union of cycles, as M is a perfect matching on the
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.               
12:20 M. Cygan et al.
endpoints of paths in P. Since {u,v} ∈ P, there is in P ∪ M a cycle S = (z1,..., zr,p,u,v,q, z1). To
get a corresponding path packing P that was considered for the previous bag, we need to get rid of
edge {u,v} while retaining essentially the same cycle structure. The solution is to effectively move
the edge {u,v} into the matching: let P := P \ {{u,v}} and let M := (M \ {{p,u}, {q,v}}) ∪ {{p,q}};
i.e., the additional edge in M is modeled by contracting p,u,v,q into just p,q. Observe that P is
a (B0 ∪ {u,v}, B1 \ {u,v}, B2, B,ω∗ − ω({u,v}))-path packing. Furthermore, clearly P ∪ M contains a cycle S = (z1,..., zr,p,q, z1), and all further cycles are the same as in P ∪ M. As a consequence, P ∪ M is a single cycle if and only if P ∪ M is a single cycle. Put formally, P is
a (B0, B1, B2, B,ω∗, M)-path packing if and only if P is a (B0 ∪ {u,v}, B1 \ {u,v}, B2, B,ω∗ −
ω({u,v}), M
)-path packing. This fact is useful for the computation since M is in the basis for B1
with modified ordering, which we check next.3
Let us see that M is indeed in the basis for B1: First of all, since u and v are at the end of
the ordering of B1, when we remove these two vertices, the remaining vertices keep their current
ordering. Second, due to the structure of bases for B1, we see that the edges {p,u}, {q,v} ∈ M imply
that the ordering of B1 ends either with ... | p,r | q,u | v or with ... p | q,u | v. (Recall that the
basis matchings are exactly all ways of pairing up elements from adjacent groups.) Accordingly, the
ordering for B1 \ {u,v} ends in ... | p,r | q or in ... p | q. If we have ... | p,r | q,u | v, then M =
X (a00) and M = X (a0) for some bitstring a: the 0 following a in a00 determines that a vertex of the
group preceding | p,r | is matched with r; the subsequent 0 then determines the edge {p,u}; and
{q,v} ∈ X (a00) follows. If we have ... p | q,u | v, then we have to distinguish two subcases: i) If
B1 = {p,q,u,v}, then its entire ordering isp | q,u | v and B1 \ {u,v} has orderingp | q. Accordingly,
we get M = X (0) and M = M(ε). Otherwise, we have ii) with |B1 | ≥ 6 and ordering ... | r,p |
q,u | v. In this case, we have M = X (a10) and M = X (a1), where the 1 in a10 determines that r
is matched with the previous group, and the 0 then determines the edge {p,u}. In either subcase,
we have M = (a
0) and M = (a
), possibly with a = ε. Overall, we always get that M is part of
the basis for B1 \ {u,v}, and its corresponding bitstring is the same as the one for M minus the
last position. Thus, taking into account the contribution for path packings without {u,v}, we can
compute T 
uv [B0, B1, B2,ω∗, M] as follows:
T 
uv [B0, B1, B2,ω∗
, M] ≡ Tuv [B0, B1, B2,ω∗
, M]
+Tuv [B0 ∪ {u,v}, B1 \ {u,v}, B2,ω∗ − ω({u,v}), M
].
iii) u ∈ B1 and v ∈ B2: We get that {u,v}  M because v  B1, but there must be some p ∈
B1 \ {u} with {p,u} ∈ M since M is a perfect matching of B1. Again, we get the contribution of Tuv [B0, B1, B2,ω∗, M] for all (B0, B1, B2, B,ω∗, M)-path packings that do not contain the
edge {u,v}. We use the same idea as in case ii).
If a (B0, B1, B2, B,ω∗)-path packing P contains the edge {u,v}, then P ∪ M contains a cycle (z1,..., zr,v,u,p, z1). Again, we effectively move the edge {u,v} “into” M: consider P :=
P \ {{u,v}} and M := (M \ {{p,u}}) ∪ {{p,v}}. Observe that P is a (B0 ∪ {u}, (B1 \ {u}) ∪ {v}, B2 \
{v}, B,ω∗ − ω({u,v}))-path packing. Furthermore, P ∪ M contains a cycle (z1,..., zr,v,p, z1),
and all further cycles (if there are any) are the same as in P ∪ M. Thus, M ∪ P is a single cycle if and
only if M ∪ P is a single cycle. Again, we need to check that M is in the basis for (B1 \ {u}) ∪ {v}.
In the present case, this is straightforward: since u and v are last in the modified ordering of V ,
they both occupy the last position on B1 and (B1 \ {u}) ∪ {v}, respectively. Since M and M differ exactly by replacing u with v, we get that M is in the basis for (B1 \ {u}) ∪ {v} and, in fact,
3Note, however, that this is not crucial since if M would not be in the basis, we could still compute Tuv [B0 ∪ {u, v }, B1 \
{u, v }, B2, ω∗ − ω({u, v }), M
] using Lemma 4.1.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.        
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:21
corresponds to the same bitstring as M for B1. We get
T 
uv [B0, B1, B2,ω∗
, M] ≡ Tuv [B0, B1, B2,ω∗
, M]
+Tuv [B0 ∪ {u}, (B1 \ {u}) ∪ {v}, B2 \ {v},ω∗ − ω({u,v}), M
].
iv) u ∈ B2 and v ∈ B1: This case is symmetric to the previous one. Despite u being second to
last and v being last in the modified ordering, this requires no change of argumentation since we
always have only one of them in the set of matched vertices.
v) u,v ∈ B2: Clearly no perfect matching M on B1 can contain {u,v} or any other edge incident
with u or v. Nevertheless, (B0, B1, B2, B,ω∗)-path packings P may contain the edge {u,v}. The
parity of the number of such path packings that do not use {u,v} and that are consistent with M
is already stored in Tuv [B0, B1, B2,ω∗, M].
Let us consider a (B0, B1, B2, B,ω∗)-path packing P that does contain {u,v}. Let P := P \ {{u,v}}
and M = M ∪ {{u,v}}. Observe that P is a (B0, B1 ∪ {u,v}, B2 \ {u,v}, B,ω∗ − ω({u,v}))-path
packing. It is easy to see that P ∪ M is a single cycle if and only if P ∪ M is a single cycle,
since P ∪ M = P ∪ M
.
Let us check that M is in the basis for B1 ∪ {u,v} with modified ordering. Let the end of the
ordering of B1 be ... | p,q | r, implying that the ordering of B1 ∪ {u,v} ends with ... | p,q | r,u | v.
The basis matching M on B1 must contain {p,r} or {q,r} by definition. Thus, if M = X (a), then
M = X (a1), where the additional 1 in a1 determines that a vertex of group | p,q | is matched
to r in group | r,u |, and the edge {u,v} ∈ X (a1) then follows. Thus, M is indeed in the basis
for B1 ∪ {u,v} with modified ordering. We get
T 
uv [B0, B1, B2,ω∗
, M] ≡ Tuv [B0, B1, B2,ω∗
, M]
+Tuv [B0, B1 ∪ {u,v}, B2 \ {u,v},ω∗ − ω({u,v}), M ∪ {{u,v}}].
Now we have handled all cases for computing T 
uv [B0, B1, B2,ω∗, M]. It remains to apply
Lemma 4.1 again to compute the table T 
[] that represents the data with respect to the standard
ordering. This completes the necessary work for an introduce edge bag.
Output after Computing Table of Final Bag. The dynamic programming terminates after reaching the final bag, i.e., the one directly preceding the introduce edge bag of the guessed edge {x,y}
and the forget vertex bags for x and y. Thus, the vertex set of this bag is B = {x,y} and all other
vertices appear only in bags to the left of it. Similarly, all edges except for the edge {x,y} have been
processed; i.e., their introduce edge bags must precede B. (It is easy to see that the final bag itself
cannot be an introduce edge bag, as there is only one possible edge, which is introduced in the succeeding bag.) Thus, Hamiltonian cycles P of weight ω∗ and containing edge {x,y} correspond one
to one to path packings P \ {{x,y}} with endpoints x and y and weight ω∗ − ω({x,y}). Observe that
all such path packings form a Hamiltonian cycle of weight ω∗ when combined with the edge {x,y}.
By definition of the computed tables T [], the parity of the number of these path packings is stored
in T [∅, {x,y}, ∅,ω∗ − ω({x,y}), {{x,y}}]; note that {{x,y}} is the unique basis matching on ground
set {x,y}. Accordingly, the algorithm answers YES if T [∅, {x,y}, ∅,ω∗ − ω({x,y}), {{x,y}}] ≡ 1 for
at least one choice of ω∗, and NO otherwise.
Running Time. Let us now analyze the time required to compute all table entries for one bag.
We already know how to compute T [B0, B1, B2,ω∗, ·] in time 2|B1 |/2−1 |B1 |
O(1)
, spending effectively |B1 |
O(1) per table entry; each entry corresponds to one basis matching on B1. For every
weight 0 ≤ ω∗ ≤ nωmax, the number of tuples (B0, B1, B2, M) where B = B0 ∪ B1 ∪ B2 is a partition
of B and M is one of the 2|B1 |/2−1 basis matchings is upper bounded by (2 + √
2)|B |
; this can be seen
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.   
12:22 M. Cygan et al.
using the multinomial theorem:

B=B0∪B1∪B2
2|B1 |/2−1 ≤

B=B0∪B1∪B2
2|B1 |/2 =

|B |=a+b+c
 |B|
a,b,c

1a (
√
2)
b 1c = (1 +
√
2 + 1)|B |
.
Thus, we obtain the following lemma.
Lemma 4.2. There is an algorithm that, given a graph G along with a path decomposition of width
pw, computes the table entries T [] corresponding to the rightmost introduce edge bag of the path
decomposition in (2 + √
2)
pwωmaxnO(1) time.
Now, we can wrap up by first stating a lemma for counting modulo two, followed by the main
theorem proved by using the Isolation Lemma.
Lemma 4.3. There is an algorithm that, given a graph G = (V, E) along with a path decomposition
of width pw and a weight function ω : E → {1,...,ωmax}, finds the parity of the number of Hamiltonian cycles of weight ω∗ for every ω∗ ∈ {0,...,nωmax} in (2 + √
2)
pwωmaxnO(1) time.
Proof. Recall that the vertex x introduced rightmost in the decomposition is of degree at most
pw. Let {y1,...,ydeg(x )} = N (x) be the set of neighbors of the vertex x. On a high level the algorithm
is as follows: for each i = 1,..., deg(x), we want to count the parity of the number of Hamiltonian
cycles going through the edge {x,yi} in the graph G with the edges {x,y1},..., {x,yi−1} removed.
Note that this way, each Hamiltonian cycle will be counted exactly once.
For a fixed i, we reorder the path decomposition as described in the setup of the dynamic
programming at the beginning of the section, so that the last three bags of the path decomposition are of the following types: (1) introduce edge {x,yi}, with associated vertex set {x,yi};
(2) forget vertex x; and (3) forget vertex yi . Then use Lemma 4.2 to compute the table entry
T [∅, {x,yi}, ∅,ω∗, {{x,yi}}] corresponding to the final bag, which precedes the introduce edge
bag for {x,yi}, for every weight ω∗ ≤ n · ωmax. Note that by definition of entries of T , the value
T [∅, {x,yi}, ∅,ω∗, {{x,yi}}] equals the parity of the number of Hamiltonian cycles of weight ω∗
going through the edge {x,yi}, and hence the lemma follows.
Theorem 4.4. There exists a randomized algorithm that, given a graph G along with a path decomposition of width pw, solves the Hamiltonian cycle problem in (2 + √
2)
pwnO(1) time. The algorithm
cannot give false positives and may give false negatives with probability at most 1/2.
Proof. We use the following routine. Assign for each edge e ∈ E a weight ω(e) ∈
{1, 2,...,ωmax} uniformly and independently at random, where ωmax = 2|E|. Next, we run the
algorithm from Lemma 4.3 in order to find the parity of the number of Hamiltonian cycles of
weight ω∗ for every weight ω∗ ≤ n · ωmax ≤ n2|E|. If for at least one ω∗ the parity is 1, return YES;
otherwise, return NO.
This procedure clearly runs in the claimed running time. If the algorithm returns YES, then there
exists a Hamiltonian cycle of some weight. Conversely, suppose that there exists a Hamiltonian
cycle. Then with probability at least 1 − |E|/2|E| = 1/2, we have by Lemma 3.9 that ω isolates the
family of all Hamiltonian cycles ofG. Hence, with probability at least 1/2, there exists a unique minimum weight Hamiltonian cycle H minimizing ω(H) and for this weight the number of weighted
Hamiltonian cycles is odd.
Further Results
Combining the ideas from the proof of Theorem 4.4 with Theorem 4.5 and an observation from
Cygan et al. (2011), we will now give an application to fast exponential-time algorithms for the
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.  
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:23
Hamiltonian cycle problems on graphs of degree at most 3. To obtain this, we require the following
result.
Theorem 4.5 (Fomin et al. 2009). For any ϵ > 0, there exists an integer nϵ such that for any
graph G with n > nϵ vertices,
pw(G) ≤
1
6
n3 +
1
3
n4 +
13
30n5 + n≥6 + ϵn,
where ni is the number of vertices of degree i in G for any i ∈ {3,..., 5} and n≥6 is the number of
vertices of degree at least 6.
This theorem is constructive, and the corresponding path decomposition (and, consequently,
tree decomposition) can be found in polynomial time. An observation from Cygan et al. (2011)
is that once two edges incident with a vertex v have been introduced in the decomposition, path
packings with v ∈ B0, i.e., with v having degree 0 in the path packing, cannot be completed to
Hamiltonian cycles: indeed, at most one more edge incident with v exists in the graph, but its
degree in a Hamiltonian cycle needs to be 2. Similarly, if at most one edge incident with v has been
introduced, then no path packings with v ∈ B2 exist. Thus, in each bag of a path decomposition,
say, with vertex set B, it suffices to consider for each v ∈ B only two instead of three cases:
—If at most one edge incident to v has been introduced so far in the path decomposition, then
either v ∈ B0 or v ∈ B1 in a nonzero entry T [B0, B1, B2, ·, ·]; consequently, the choice v ∈ B2
is neglected.
—On the other hand, if at least two edges incident to v have been introduced already, then
only states satisfying v ∈ B1 and v ∈ B2 are considered in the dynamic programming as
states with v ∈ B0 will not contribute to the entries in the final bag (here we assume v is
not incident with the edge introduced last in the decomposition).
Consequently, the number of states considered for each bag is upper bounded by
O(

i
	
pw
i


2i/2−1) ≤ O((1 + √
2)
pw), and hence we obtain the following.
Corollary 4.6. There exists a randomized algorithm that, given a graph G of maximum degree
3, solves the Hamiltonian cycle problem for any constant ϵ > 0 in (1 + √
2)
n/6+ϵnnO(1) ≤ O(1.1583n )
time. The algorithm cannot give false positives and may give false negatives with probability at most
1/2.
Finally, we prove that following the same high-level approach as in Lemma 4.3 by altering the
state definition in the dynamic programming routine, we can find the parity of the number of paths
of length k in a given graph.
Lemma 4.7. There is an algorithm that, given a graph G along with a path decomposition of width
pw, a weight function ω : E → {1,...,ωmax}, and an integer k, finds the parity of the number of paths
of length k of weight ω∗ for every ω∗ ∈ {0,...,nωmax} in (2 + √
2)
pwωmaxnO(1) time.
Proof. We iterate over the endpoints of the path; that is, for each unordered pair of vertices
x,y, we want to find the parity of the number of paths of length k of all weights between x and y.
For a fixed pair x,y, we transform the path decomposition into a nice path decomposition whose
final two bags are forget vertex x and forget vertex y. This can be done by first adding x and y to
all bags and appending a new bag with vertex set {x,y}, followed by standard transformations to
get a nice path decomposition, which increases the width of the path decomposition by at most 2.
As before, we perform dynamic programming on the given path decomposition, proceeding from left to right. At each bag, with some vertex set B, we compute table entries
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
12:24 M. Cygan et al.
T [h, B0, B1, B2,ω∗, M] for all h ∈ {0,...,n − 1}, all partitions B = B0 ∪ B1 ∪ B2, all integers ω∗ ∈ {0,...,n · ωmax}, and all perfect matchings M from the basis for B1 under ordering
v1,...,vn restricted to B1. Each entry contains the parity of the number of path packings P (each
a set of edges) of the graph induced by all vertices left of and including the current bag and all
edges introduced so far, such that
(1) P consists of exactly h edges,
(2) P ∪ M is a single cycle,
(3) the total weight of the edges in P is equal to ω∗,
(4) the vertices in Bi have degree exactly i in P, and
(5) all vertices that only occur left of the current bag are of degree 0 or 2; we denote those
by B.
What is different compared to the old definition of entries of T is that
— the additional counter h keeps track of the number of edges used in the path packing, and
—vertices of B are allowed to have degree 0, as the path we are looking for is not necessarily
Hamiltonian.
To accommodate those changes, the dynamic programming formulas need to be changed
slightly. Updating the counter h is straightforward; for example, the formula for the introduce
edge {u,v} bag, case u,v ∈ B2, becomes
T 
uv [h, B0, B1, B2,ω∗
, M] ≡ Tuv [h, B0, B1, B2,ω∗
, M]
+Tuv [h − 1, B0, B1 ∪ {u,v}, B2 \ {u,v},ω∗ − ω({u,v}), M ∪ {{u,v}}].
However, there are two nontrivial differences compared to the previous dynamic programming.
First, in the forget vertex bag, we allow the vertex v to be of degree 0:
T 
[h, B0, B1, B2,ω∗
, M] ≡ T [h, B0, B1, B2 ∪ {v},ω∗
, M] +T [h, B0 ∪ {v}, B1, B2,ω∗
, M].
Second, in the subcase ii.1) of the introduce edge {u,v} case analysis, where we assume u,v ∈ B1
and {u,v} ∈ M, the formula becomes
T 
uv [h, B0, B1, B2,ω∗
, M] ≡ Tuv [h, B0, B1, B2,ω∗
, M]
+ [h = 1 ∧ B2 = ∅ ∧ B1 = {u,v} ∧ ω∗ = ω({u,v})];
i.e., we no longer require B = ∅, as the path we are looking for does not have to visit all vertices
of the graph.
The dynamic programming terminates after reaching the final bag, i.e., the one directly preceding the forget vertex bags for x and y. Thus, the vertex set of this bag is B = {x,y} and all other
vertices appear only in bags to the left of it. By definition, the entry T [k, ∅, {x,y}, ∅,ω∗, {{x,y}}]
equals the parity of the number of paths of length k of weight ω∗ between x and y.
By applying the Isolation Lemma in exactly the same manner as before, we obtain the following
theorem.
Theorem 4.8. There exists a randomized algorithm that, given a graph G along with a path decomposition of width pw, together with an integer k, checks whether G admits a path of length k in
time (2 + √
2)
pwnO(1)
. The algorithm cannot give false positives and may give false negatives with
probability at most 1/2.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.    
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:25
5 LOWER BOUND FOR THE HAMILTONICITY PROBLEM
In this section, we give an indication that the running time of our algorithm from Section 4 is
hard to improve: we show that no algorithm can achieve a significantly better dependence on
the pathwidth of the input graph (even at the cost of a larger polynomial factor in the input size),
without giving also a breakthrough result for solving CNF-Sat; this is expressed by the main
theorem of this section.
Theorem 5.1. If there is an algorithm that solves the Hamiltonian cycle problem in (2 + √
2 −
ϵ )
pw|V |
O(1) time for some ϵ > 0, then there exists an algorithm that solves the CNF-Sat problem in
(2 − ϵ 
)
nmO(1) time for some ϵ  > 0.
Recall the definition of the Matching Connectivity matrix Ht : all rows and columns are indexed by perfect matchings M1, M2 of the complete graph on t vertices and Ht[M1, M2] = [M1 ∪
M2 is a Hamiltonian cycle]. Our proof uses the lower bound on the rank of Ht , in particular, the
fact that the family of basis matchings Xt from Section 3 induces a permutation submatrix in Ht
(see Proposition 3.3). We will now provide an overview.
High-Level Overview of the Proof Idea. Following previous lower bounds for algorithms exploiting
small width path decompositions for different problems (see, e.g., Lokshtanov et al. 2011), the
high-level idea is as follows: Create a graph containing vertices grouped in sets Vi,j , such that
Sj =
i Vi,j separates Vi
,j fromVi,j fori < i < i. The sets Sj will be used as separators in path
decompositions. Now add a gadget to the graph such that any Hamiltonian cycle must “behave”
isomorphically with respect to each Sj ; i.e., unifying Sj with Sj in some standard way, vertices
have the same number of edges incident with vertices “on the left” (i.e., vertices in the connected
component of the graph obtained after removing Sj with vertices from Sh with h < j) and the
connections established by paths in the left side of the graph are the same in both. Enforcing
that this pattern propagates in any Hamiltonian cycle, we can encode an assignment of the CNFformula as one possible pattern and check whether different clauses are satisfied by this single
pattern in different columns of the Vi,js. To do this while keeping the Sjs as small as possible,
we use generic gadgets and Proposition 3.3. In particular, we ensure the matching induced by the
connections of paths in the Hamiltonian cycle left and right of the separator is one of the basis
matchings of Xt . By Proposition 3.3, the matching on the left is then determined by the matching
on the right, which allows enforcing the repeating pattern.
5.1 Gadgets
In this section, we will introduce three gadgets used for the final construction that allow control on
the Hamiltonian cycles. Some of these gadgets accept parameters to be set in the final construction.
Vertices with Labeled Incident Edges. The following two gadgets allow us to label incident edges
of a vertex v with a labeling function λv , ensuring that every Hamiltonian cycle enters and leaves
a vertex with edges of the same label.
Definition 5.2. A label gadget is a pair (v, λv ), where λv is a labeling of the edges incident with
v. A Hamiltonian cycle C is consistent with a label gadget (v, λv ) if λv (e) = λv (e
), where e, e are
the two edges of C incident with v.
The pair (v, λv ) is called a two-label gadget if the codomain of λv is {1, 2} and a multilabel gadget
otherwise.
When we use several label gadgets simultaneously, there will be several labelings and we say
an e edge has label l with respect to v if λv (e) = l. The first gadget is for a vertex whose incident
edges have only two distinct labels, denoted by dashed and solid lines in figures. It is shown at
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
12:26 M. Cygan et al.
Fig. 4. Gadgets for vertices with labeled incident edges. On the left-hand side, the two-label gadget is shown.
The two label classes are denoted by normal and dashed lines. On the right-hand side, the multilabel gadget
for six labels is shown. The gray vertices represent two-label gadgets and the labels of their incident edges
are denoted by normal and dashed lines. A numberi next to a leaving edge indicates that the edge represents
an edge in the original graph with label i.
the left-hand side in Figure 4. We have to ensure that any Hamiltonian cycle contains exactly two
edges of the set of edges leaving the gadget and that they are of the same label, and this can be
seen to hold by a simple case analysis: if the cycle enters the gadget in vertex v1, it must continue
with v2,v3. Then it cannot leave the gadget, because then it is impossible to visit all six remaining
vertices. Hence, it must continue with v6 and then v5,v4,v9,v8,v7 is forced. The cases where it
enters at a different vertex are symmetric.
Let us continue with the multilabel gadget, which we will first formally describe. Given a vertex
v in a graph G with incident edges X and a labeling λv : X → {1,..., k} that assigns one of the k
labels {1,..., k} to every incident edge, we obtain G by replacing v as follows:
—Create a cycle of 3k vertices consecutively denoted by va
1 ,vb
1 ,vc
1 ,va
2 ,vb
2 ,vc
2 ,...,vc
k .
—For every 1 ≤ i ≤ k, and every vertexw  v incident with an edge e ∈ X such that λv (e) = i,
add the edges va
i w and vb
i w.
—For every 1 ≤ i < k, add a two-label gadget consisting of vertex дi , edges {дi,va
i }, {дi,vb
i }
labeled by 1, and edges {дi,va
i+1}, {дi,vb
i+1} labeled by 2. The дis are called guard vertices.
An instructive example with k = 6 is shown on the right-hand side of Figure 4.
Lemma 5.3. There is a Hamiltonian cycle of G consistent with (v, λv ) if and only if G has a
Hamiltonian cycle.
Proof. For the backward direction, note that in a Hamiltonian cycle a guard vertexдi is adjacent
either to both va
i and vb
i or to both va
i+1 and vb
i+1, and all the pairs can be adjacent to at most one
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:27
Fig. 5. Example of the induced subgraph gadget, with X = {v1,...,v10} and F = {{{v1,v3},
{v2,v6}, {v1,v6}, {v4,v5}}, {{v3,v6}, {v5,v7}, {v6,v8}, {v9,v10}}, {{v6,v10}, {v8,v9}, {v7,v10}}}. The bold edges
to IF indicate that in fact there are edges to every vertex in IF . Label 1 edges are drawn dashed while label
2 edges are drawn normally. The gray vertices are 2-label gadgets.
guard vertex since otherwise there is a cycle on four vertices. Moreover, since each vertex vc
i is
of degree 2, any Hamiltonian cycle of G contains the edges {vb
i ,vc
i } for 1 ≤ i ≤ k, as well as the
edges {vc
i ,va
i+1} for 1 ≤ i < k and finally the edge {vc
k ,va
1 }. Therefore, since all guard vertices must
be visited, any Hamiltonian cycle of G contains only two edges leaving the gadget and they must
be incident with va
i and vb
i for some i.
For the forward direction, let there be a Hamiltonian cycle of G that enters and leaves at edges
incident with v with label i. Then we have to show that there is a path P from va
i to vb
i going
through all vertices of the gadget (and no other vertices). Notice that such a P exists consisting
of edges between vb
j and vc
j , edges between vc
j and va
j+1 (where addition is modulo k), and edges
between дj and (i) va
j and vb
j for j < i, and (ii) va
j+1 and vb
j+1 for j ≥ i.
Induced Subgraph Gadget. We will now discuss the induced subgraph gadget, which is illustrated
in Figure 5. The function of the gadget is described as follows:
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
12:28 M. Cygan et al.
Definition 5.4. An induced subgraph gadget in a graph G = (V, E) is described by a tuple
(X, a,b, F ), where X ⊂ V , a,b ∈ V \ X, F ⊆ 2E(X,X )
, ∅  F , and |F | ≥ 2. A Hamiltonian cycle
C of G is consistent with (X, a,b, F ) if {a,b} ∈ C and C ∩ E(X,X) ∈ F . We refer to X as the ground
set, a,b as the special vertices, and F as the projection family.
This gadget allows us very strong control on how every Hamiltonian cycle of G must behave
in the graph induced by X. It should be noted that we will use this gadget several times and
allow induced subgraph gadgets to have overlapping ground sets. In this case, for every separate
induced subgraph gadget, we will process an edge independently. The gadget is implemented with
the following construction, obtaining a modified graph G from G:
—Remove all edges E(X,X) from the graph G.
—Add a set I|F |, i.e., an independent set of |F | vertices toG, and make all its vertices adjacent
to both a and b.
—Let F = {F1,..., F }, and for i = 1,..., do the following:
—Let Fi = {e1,..., e |Fi |}.
—Add a path of two-label gadgets Pi = {p1
i ,...,p |Fi |
i }, with all edges having label 1.
—From every vertex v of the independent set I|F |, add an edge with label 1 to p1
i and p |Fi |
i .
—For j = 1,..., |Fi |, add edges {pj
i , x} and {pj
i ,y} with label 2, where ej = {x,y}.
An illustration of the gadget is provided in Figure 5. We will now prove the correctness of the
gadget. Let us remark here that the vertices a and b are not useful for applying the gadget but are
used to actually implement it as in the above construction.
Lemma 5.5. There exists a Hamiltonian cycle C in G that is consistent with (X, a,b, F ) if and only
if there exists a Hamiltonian cycle in G
.
The intuition behind the proof of this lemma is that in a Hamiltonian cycle of the graph G
, the
part of the cycle that goes from a to b visits all vertices from the independent set I|F | and all paths
except the one corresponding to the element of F that is chosen.
Proof. For the forward direction, let Fi ∈ F be the intersection of C with E(X,X). Then the
Hamiltonian cycle in G can be extended to a Hamiltonian cycle in G by replacing every edge
ej ∈ Fi with two edges {u,pj
i } and {pj
i ,v}, where ej = {u,v}, and by replacing the edge {a,b} by
the path a,д1, P1,д2, P2,..., Pi−1,дi, Pi+1,дi+1,..., P|F |д|F |,b, where д1,...,д|F | is an arbitrary
ordering of I|F |.
For the reverse direction, let C be a Hamiltonian cycle of G
. Observe that since I|F | is independent, the Hamiltonian cycle C contains exactly 2|F | edges between I|F | and NG (I|F |) =
{p1
i ,p |Fi |
i : 1 ≤ i ≤ |F |} ∪ {a,b}. By the two-label gadgets, we know that if for some 1 ≤ i ≤ |F |
the Hamiltonian cycle C contains an edge between I|F | and {p1
i ,p |Fi |
i }, then C contains exactly
one edge between I|F | and p1
i as well as exactly one edge between I|F | and p |Fi |
i . However, C
cannot contain 2|F | edges between I|F | and {p1
i ,p |Fi |
i : 1 ≤ i ≤ |F |}, because then it would induce
a cycle not visiting any other vertices.
Furthermore, C cannot contain two edges between a and I|F |, since then it would have to
contain zero or two edges between b and I|F |, in both cases making it impossible to visit the other
original vertices of G. Similarly, C cannot contain two edges between b and I|F |.
Consequently,C contains exactly one edge between a and I|F |, exactly one edge between b and
I|F |, and exactly two edges between Pi and I|F | for |F | − 1 indices i ∈ [|F |]. So there is exactly
one index 1 ≤ i0 ≤ |F | such that p1
i and p |Fi |
i are not adjacent to a vertex of I|F |. Since C visits
all the vertices of Pi0 by label 2 edges only, we can obtain a Hamiltonian cycle C in G from C by
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.   
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:29
Fig. 6. An overview of the construction for the Hamiltonian path lower bound. The y
i vertices are used
to complete the potential Hamiltonian cycle and their incident bold edges indicate that they are adjacent
to each vertex of the indicated Ki
β , which denotes cliques of β vertices. The gray circles ci are multilabel
gadgets (see Figure 4) and the gray rectangles Gi,j are induced subgraph gadgets, used as further illustrated
in Figure 7. The empty nameless vertices are vertices in Vi,j that can occur in two induced subgraph gadgets
(or cliques).
removing all the edges of the gadget and adding the edge {a,b} together with edges of Fi0 . Note
that the Hamiltonian cycle C is consistent with (X, a,b, F ) as it does not contain any edge of
E(X,X) \ Fi0 since the graph G has the edges E(X,X) removed.
5.2 Construction
We will now describe the construction of the reduction; see also Figure 6. After the formal definition, we will provide some intuition. Our construction is parameterized by two integer constants
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
12:30 M. Cygan et al.
β and γ , which will be chosen later such that

i0+i1+i2 = β
i1 is even, i0, i1, i2>0
 β − 1
i0,i1 − 1,i2

√
2
i1
≥ 2γ , (2)
where we define multinomials with negative numbers to be 0.
Assume we are given a CNF-formula ϕ = C1 ∧ ... ∧Cm on variables x1,..., xn with n being a multiple of γ 4; let q = n
γ
. Partition the set {x1,..., xn } into n/γ blocks of size γ , denoted
X1,...,Xn/γ . Also, denote Xi = {xi,1,..., xi,γ }. Intuitively, we will represent the 2γ assignments
of a block of variables by the states of groups of vertices in a bag of the to-be-constructed path
decomposition. In Section 5.5, we will discuss how to fix β and γ such that the number of these
states, represented on the left-hand side of Equation (2), is at least 2γ .
In the following, we will use the family of matchings Xt defined in Definition 3.1. For ease
of notation, we denote X(S) for the family obtained from X|S | by unifying the elements of U|S |
with elements of S (using an arbitrary but fixed ordering), for any set S of even cardinality. The
construction of the instance of the Hamiltonicity problem is as follows:
(1) For everyi = 1,...,q, j = 1,...,m + 1, and k = 1,..., β, add verticesvi,j,k ; fori = 1,...,q
and j = 1,...,m + 1, denote Vi,j = {vi,j,1,...,vi,j, β }.
(2) For every i = 1,...,q, add a clique on β vertices Ki
β , and add an edge between all vertices
of the clique Ki
β and all vertices from Vi,1.
(3) For every i = 1,...,q, add a clique on β vertices Kˆi
β , and add an edge between all vertices
of the clique Kˆi
β and all vertices from Vi,m+1.
(4) For every i = 1,...,q − 1, add a vertex y
i and make it adjacent to all vertices of Ki
β and
Ki+1
β . Furthermore, a vertex y
q is added and made adjacent with all vertices of Kq
β and K1
β .
(5) For every i = 1,...,q and j = 1,...,m, add an induced subgraph gadget Gi,j with ground
set X, special vertices ai
j
,bi
j , and projection family F described as follows (see also
Figure 7):
(a) Add four vertices ai
j ,bi
j ,ci
j ,di
j and the edge {ai
j
,bi
j}, where the edge {ai
j
,bi
j} is guaranteed to be in any Hamiltonian cycle (as required by the induced subgraph gadget),
which is easily enforced by subdividing it (e.g., adding a vertex of degree adjacent to
only both vertices).
(b) The set X consists of the vertices Vi,j ∪Vi,j+1 and the vertices ci
j ,di
j .
(c) Given a vectors ∈ {0, 1, 2}β and a matching M ∈ X(s−1 (1)), we denote si,j as the coloring s : Vi,j → {0, 1, 2} obtained by identifying the sets {1,..., β} and Vi,j . Similarly,
we denote Mi,j as the matching of Vi,j obtained by the same unification. (Equivalently, we may take si,j ∈ {0, 1, 2}
Vi,j and Mi,j ∈ X(s−1
i,j
(1)).)
(d) For every vector s ∈ {0, 1, 2}β satisfying s(1) = 1, |s−1 (0)|, |s−1 (1)|, |s−1 (2)| > 0 and
matching M ∈ X(s−1 (1)), add an edgeset ηi,j (s, M) constructed as follows to the projection family F :
i. Add the edges of the path α1,..., α, where {α1,..., α } are the elements of
s−1
i,j
(2) sorted ascendingly (the ordering is in fact immaterial so long as we have
a simple path through these vertices).
4Note that since γ is a constant, this is easily established by adding at most γ dummy variables.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.  
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:31
Fig. 7. An edge set ηi,j (s, M) from projection set F of an induced subgraph gadgetG1,1 with β = 10 is shown.
In this example, we have coloring s with s(v1,1,2) = s(v1,1,7) = 0,s(v1,1,4) = s(v1,1,5) = s(v1,1,6) = s(v1,1,8) =
2 and matching M = {{1, 3}, {9, 10}}. The unique basis matching that gives a Hamiltonian cycle with M is
M = {{1, 9}, {3, 10}}, whose edges are seen on the right-hand side. The names y1,y2, z1, z2, α1, α, β1, β are
indicated for illustrating the formal definition in Step (5)(d). The gray rectangle indicates the border of the
gadget; i.e., only vertices on this rectangle can have neighbors outside the gadget (before taking Step 7 into
account).
ii. Add the edges of the path β1,..., β, where {β1,..., β } are the elements of
s−1
i,j+1
(0) sorted ascendingly.
iii. Denotey1 = vi,j,1 and let e = {y1,y2} be the edge of Mi,j incident with the smallest element of s−1
i,j
(1), being y1.
iv. Add all edges of Mi,j not equal to e.
v. Let M ∈ X(s−1 (1)) be the unique matching such that M ∪ M is a Hamiltonian
cycle (this exists and is unique due to Proposition 3.3).
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.    
12:32 M. Cygan et al.
vi. Denote z1 = vi,j+1,1 and let e = {z1, z2} be the edge of M
i,j+1 incident with the
smallest element of s−1
i,j+1
(1), being z1.
vii. Add all edges of M
i,j+1 not equal to e
.
viii. Add the edges {y1, ai
j}, {y2,ci
j}, {ci
j , α1}; {z1,bi
j}, {z2,di
j}, {di
j , β1}; {α, β }.
(6) Fix arbitrarily an injective mapping (which exists due to Equation (2)):
ψ : {0, 1}
γ →{(s, M) : s ∈ {0, 1, 2}
β ∧ s(1) = 1
∧ |s−1 (0)|, |s−1 (1)|, |s−1 (2)| > 0 ∧ |s−1 (1)| is even ∧ M ∈ X(s−1 (1))}.
(7) For j = 1,...,m:
(a) Add a multilabel gadget cj .
(b) For every i = 1,...,q and every partial assignment x ∈ {0, 1}
Xi of the variablesXi that
satisfies the clause Cj , consider the first vertex ρ of the path in the induced subgraph
gadget Gi,j corresponding to the element Fx = ηi,j (ψ (x)) of F .
(c) Let (ρ, σ ) be the first edge of the path Px corresponding to Fx in the construction of the
induced subgraph gadget. Note that this edge exists as F contains no singletons and
moreover this edge is of label 1. Add an edge (ρ,cj) and (cj , σ ) such that with respect
to ρ and σ, the edges have label 1, and with respect to the multilabel gadget cj , the
edges have a label that has not been used yet in the interval [j · 2γ + 1, (j + 1) · 2γ ],
which must exist since there are at most this many assignments of Xi .
The intuition behind the construction is as follows: Vi,j are blocks of vertices whose joint states
encode a joint assignment of Xi . In Steps 2 to 4, vertices are added to ensure that a set of disjoint
paths visiting all vertices in the remainder of the graph can be completed into a Hamiltonian cycle.
In Step 5, we create graphs Gi,j on Vi,j and Vi,j+1 such that for any set of these disjoint paths, the
intersections ofGi,j andGi,j+1 determine each other, given that the edgeset is a Hamiltonian cycle.
To do this, we use the induced subgraph gadget and for every state (s, M) we allow exactly one
edgeset in F that induces state (s, M). Intuitively, we establish this by adding the matchings M on
Vi,j and M on Vi,j+1 and replacing the edges of M and M incident with the smallest element with
paths visiting all vertices receiving value 2 and 0 in s, respectively. In Step 6, we fix an encoding
ψ of partial assignments in states of the group of vertices Vi,j . As mentioned before, this encoding
exists due to Equation (2). Finally, we check in Step 7 whether clause Cj is satisfied by adding a
multilabel gadget cj that can be visited if and only if in some graph Gi,j the intersection X from
the family F induces a state (s, M) = η−1
i,j (X) such that the partial assignment ψ −1 (s, M) satisfies
clause Cj . The labels to the clause gadget are chosen consecutively in 7c to ensure that adding
the multilabel gadgets increases the pathwidth by a constant only: the clause gadgets connect
the gadgets Gi,j and Gi
,j , which may complicate finding efficient path decompositions, but this
turns out to not be a problem since the multilabel gadgets are very path-like (e.g., it has constant
pathwidth independent of the number of labels).
5.3 From a Satisfying Assignment to a Hamiltonian Cycle
Suppose that x ∈ {0, 1}
n satisfies the formula ϕ, and recall that X1,...,Xq is a partition of the
variable set x1,..., xn. Let x (i) denote x restricted to Xi . Then we first claim that for every i =
1,...,q, the set
Ei =
m
j=1
ηi,j (ψ (x (i))) (3)
is a set of two disjoint paths in the constructed graph G, in which all vertices of ∪m
j=1Gi,j \
{Vi,1,Vi,m+1} are visited and all endpoints are in Vi,1 ∪Vi,m+1. In particular, one of the two paths
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.  
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:33
only consists of the vertices ai
j
,bi
j and vi,j,1. To see this, consider the application of the induced
subgraph gadget in Step 6 of the construction (see also Figure 7). Note that, using only edges from
the edge set ηi,j (s, M), the first vertex y1 of s−1
i,j
(1) is connected to the first vertex z1 of s−1
i,j+1
(1)
through ai
j ,bi
j . Recall that y2 is the second vertex of the lexicographically first edge of Mi,j. Suppose that y2 = vi,j,k .
Then, to show the claim on Ei , it is sufficient to show that y2 is connected to vi,j+1,k by a
path from Ei with internal vertices s−1
i,j
(2) ∪ s−1
i,j+1
({0, 1}) ∪ ci
j ,di
j : if this would hold for every
j, the pattern will propagate giving the concatenation of the paths from y2 to vi,j+1,k and the
shorter paths y1, ai
j ,bi
j , z1. We now argue that this follows by construction of ηi,j : from the edges
incident with Vi,j+1, we use edges both from ηi,j (s, M) and ηi,j+1 (s, M). Then from y2 the path
continues to ci
j , all verticess−1
i,j
(2), the edge (α, β ), all vertices from s−1
i,j+1
(0), the edge (β1,di
j ),
and all vertices from s−1
i,j+1
(1). For the last part, note that the edges from ηi,j (s, M) and ηi,j+1 (s, M)
incident with s−1
i,j+1
(1) are obtained by taking two matchings that form a cycle on s−1
i,j+1
(1) (by
the definition of η) and removing both edges incident with vi,j+1,1.
5
Denote E = ∪iEi . Now we alter the set E to a set E to visit all clause multilabel gadgets as
follows: since x satisfies the formula, for every j = 1,...,m, there exists i ∈ {1,...,q} such that
in x a variable of Xi satisfies Cj . Fix such an i and denote x  for x restricted to Xi . In the path
in the induced subgraph gadget corresponding to the element η(ψ (x 
)) of F , we added in Step
7c two edges to the clause gadget with the same label between vertices ρ and σ. Since we know
{ρ, σ }∈Ei (after expanding the gadgets), we can safely replace {ρ, σ } with {ρ,cj} and {cj , σ }.
Hence, there exists an edge set E = ∪iE
i that is a set of disjoint paths, with endpoints in
∪q
i=1Vi,1 ∪Vi,m+1 and in which all verticesc1,...,cm and vertices from ∪m
j=1Gi,j \ {Vi,1,Vi,m+1} are
visited. By definition of ηi,j , E
i is consistent with all induced subgraph gadgets, and E
i is also
consistent with all multilabel gadgets since {ρ,cj} and {cj, σ } will have the same label with respect to the multilabel gadget. Furthermore, we claim that after contracting the internal points of
these paths, we are left with a graph that has a Hamiltonian cycle. To see this, recall that for every
i = 1,...,q, the edge set E
i induces two paths with endpoints in Vi,1 and Vi,m+1, and it visits all
vertices from ∪m−1 j=2 Vi,j and some subset of Vi,1 and Vi,m (which depends on the choice of s). Thus,
we can use the cliques Ki
β and Kˆi
β to extend the two paths in E
i to a single path between two
vertices of Ki
β that visit Ki
β ∪ Kˆi
β ∪ (∪m
j=1Vi,j) ∪Vi,j . In this way, we obtain an edge set E∗ that is a
set of disjoint paths with exactly two endpoints in the cliques Ki
β for every i that visits all vertices
except the vertices y
1,...,t
q. This edge set can be easily completed into a Hamiltonian cycle by
connecting the y
q vertices to adjacent endpoints of these paths.
5.4 From a Hamiltonian Cycle to a Satisfying Assignment
Suppose we are given a Hamiltonian cycle C of G, consistent with all the induced subgraph and
multilabel gadgets.
Contract the clause gadgets to edges obtaining C
. By the multilabel gadget and the labeling,
the edges resulting from the contraction will be contained in an induced subgraph gadget. Let us
denote Ei,j for the edge set of Gi,j . By construction of the induced subgraph gadget, C ∩ Ei,j is an
element of the family F , so since ηi,j is injective, η−1
i,j (C ∩ Ei,j) is well defined.
We now show that in any Hamiltonian cycle, the pattern induced by Gi,j will be determined by
the pattern induced by Gi,j−1.
5In Figure 7, this path is v1,1,3, c 1
1, v1,1,4, v1,1,5, v1,1,6, v1,1,8, v1,2,7, v1,2,2, d1
1, v1,2,9, v1,2,10, v1,2,3.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.  
12:34 M. Cygan et al.
Lemma 5.6. For every i and j, we have that η−1
i,j (C ∩ Ei,j) = η−1
i,j+1 (C ∩ Ei,j+1).
Proof. Let (s, M) = η−1
i,j (C ∩ Ei,j) and (s
, M
) = η−1
i,j+1 (C ∩ Ei,j+1). By the construction in 5d
cases (i) and (ii), ηi,j (s, M) contains s(k) edges incident with a vertex vi,j+1,k and ηi,j+1 (s
, M
)
contains 2 − s
(k) edges incident with a vertex vi,j+1,k . Thus, since all vertices need to have degree
2 in C
, we know that s = s
. Thus, M and M give rise to matchings on the same vertex set.
Note that the matchings are from X(s−1
i,j
(1)) because of the range of η−1. Suppose that M  M
.
Then we claim that C induces a cycle on Z. To see this, note that in Step 5d, ηi,j (s, M) and
ηi,j (s
, M
) can be equivalently constructed as adding all edges of the matchings M and M∗ (with
possibly copies), where M∗ is the unique partner of M as picked in Step 5d(v.), and removing
two edges incident with one vertex and adding two other edges. By Proposition 3.3, C is not a
Hamiltonian cycle if M  M
. Thus, it contains at least two subcycles, one of which does not
contain the vertex whose incident edges are removed. This subcycle will still be present after the
change, contradicting that C is a Hamiltonian cycle. Thus, M = M
.
Hence, the cycleC must represent an assignment of the variables x1,..., xn. Furthermore, since
C visits all multilabel gadgets, it must represent a satisfying assignment.
5.5 Pathwidth and Efficiency Bound
We will first argue that the pathwidth of the constructed graph (after expanding all gadgets) G
is n
γ β + f (β,γ ) for some function f and then set the parameters β and γ in order to prove the
theorem.
Let κ = 1,...,q and j = 1,...,m. In the multilabel gadgetcj , recall that there is a vertex va
1 . Let
 be the maximum integer such that in the multilabel gadget cj , va
 is adjacent to a vertex in one
of the induced subgraph gadgets G1,j,...,Gκ,j . Then note that
Sκ,j =

κ
i=1
Vi,j


∪


q
κ=i+1
Vi,j+1


∪ {va
1 ,д,vc
 }
is a separator since the labels of an edge fromGi,j to the multilabel gadget are chosen proportional
to j in Step 7c, where д denotes all nine vertices of the expanded two-label gadget. Note that
intuitively, Sκ,j consists of the vertices in the first κ rows and jth column, the vertices in the last q −
κ rows and the j + 1’th column, and the set {va
1 ,д,vc
 } (note that  depends on κ). Clearly, the size
of Sκ,j equals nβ/γ + O(1) (where O(1) is 11 to be precise). Then the claimed path decomposition
is obtained, introducing and forgetting the following separators in the order
Sq,1 ∪ {y
q,y
1},Sq−1,1 ∪ {y
1,y
2},..., S1,1 ∪ {y
q−1,y
q },
Sq,2,..., Sq−1,2, S1,2,..., Sq,m, Sq−1,m,..., S1,m . (4)
Note that after removing all separators Sκ,j , all connected components are of size at most f (β,γ ):
one induced subgraph gadget is adjacent to at most 3 · 2γ consecutive vertices of a clause gadget,
and these will be separated from other vertices in that clause gadget. Also, all pairs of induced subgraph gadgets will be separated by some separator. Moreover, the neighborhood of every one of
these connected components is contained in Sκ,j for some κ and j. Thus, we can obtain a path decomposition using the union of two consecutive separators from Equation (4) as bags along with
adjacent small connected components, e.g., obtain from the sequence of separators from Equation (4) a path decomposition by creating bags for each of two consecutive separators and introduce and forget the connected components whose neighborhood is a subset of this bag. The
claimed upper bound on the pathwidth follows since the size of every union of two consecutive
separators is at most n
γ β + f (β,γ ).
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.               
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:35
Now we discuss how to fix the constants β and γ . It is easily seen that there exists some constant
C such that for sufficiently large β, we have

i0+i1+i2=β
i1 is even, i0, i1, i2>0
 β − 1
i0,i1 − 1,i2

√
2
i1
≥

i0+i1+i2=β
 β
i0,i1,i2

√
2
i1
/C = (2 +
√
2)
β /C,
where the inequality follows from elementary analysis and the equality follows directly from the
multinomial theorem. Hence, we may satisfy Equation (2) by setting β = γ
lg(2+
√
2) + O(1). Running
the assumed algorithm that solves the Hamiltonian cycle problem in (2 + √
2 − ϵ )
pw|V |
O(1) time
then takes time
(2 +
√
2 − ϵ )
n
γ
 γ
lg(2+
√
2)
+O (1)

≤ 2
lg(2+
√
2−ϵ ) n
γ
 γ
lg(2+
√
2)
+O (1)

= 2
n

lg(2+
√
2−ϵ )
lg(2+
√
2) + lg(2+
√
2−ϵ+O (1))
γ

,
modulo factors polynomial in the size of the CNF-formula. Then, choosingγ large enough such that
(
lg(2+
√
2−ϵ )
lg(2+
√
2) + lg(2+
√
2−ϵ )+O (1)
γ ) < 1 gives a (2 − ϵ 
)
nmO(1)
-time algorithm for CNF-Sat on n variables
and m clauses for some ϵ  > 0, concluding the proof of Theorem 5.1.
6 DIRECT PROOF OF A LOW-RANK MATRIX FACTORIZATION
OF THE MATCHING CONNECTIVITY MATRIX
This section provides a proof for Theorem 3.4, which implies that each family Xt corresponds to a
basis for the Matching Connectivity matrix Ht . The proof will be by induction. As a first tool, we
define a projection operator, called shrinkt , that takes any perfect matching of Ut and a parameter c ∈ {0, 1} and returns a perfect matching of Ut−2 (see Definition 6.1). For matchings X (·) ∈ Xt ,
depending on c, this will either be equivalent to undoing the last step in the recursive definition of X (·) or yield ∅ (see Proposition 6.2). Intuitively, the operator shrinkt (M, 1) adds to M an
edge {t − 2,t − 1}, which results in creating a path with three edges (if a cycle is created, then
shrinkt (M, 1) = ∅); this path is then contracted to a single edge. The operator shrinkt (M, 0) acts
similarly: it adds to M an edge {t − 3,t − 1} and contracts the created path with three edges, but the
additional twist is that the vertex t − 2 is renamed to t − 3, so that the new matching is a perfect
matching on Ut−2. As we will see in the proof of Theorem 3.4, the shrink operator is tailor made
for the inductive argument. A formal definition follows and is depicted in Figure 8.
Definition 6.1 (Projection to t − 2 first vertices). Let t ≥ 4 be an even integer. We define a function
shrinkt : (Π2 (Ut ) ∪ {∅}) × {0, 1} → Π2 (Ut−2) ∪ {∅}
as follows. For c ∈ {0, 1}, we let shrinkt (∅,c) := ∅. For M ∈ Π2 (Ut ), the definition is as follows.
We let α (i) := αM (i), recalling that αM (i) returns the element j ∈ Ut that is matched to i by M, i.e.,
with {i, j} ∈ M.
(1) If {t − 1,t − 2} ∈ M, then let
shrinkt (M, 1) := ∅,
shrinkt (M, 0) := M \ {{t − 1,t − 2}}.
(2) If {t − 1,t − 3} ∈ M, then let
shrinkt (M, 1) := (M \ {{t − 1,t − 3}, {t − 2, α (t − 2)}}) ∪ {{t − 3, α (t − 2)}},
shrinkt (M, 0) := ∅.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
12:36 M. Cygan et al.
Fig. 8. Rows represent the four subsequent cases in Definition 6.1. The first column corresponds to
shrinkt (M, 1), the second to shrinkt (M, 0). The dotted edges {t − 3,t − 1}, {t − 2,t − 1} are given for reference only.
(3) If {t − 2,t − 3} ∈ M, then for c ∈ {0, 1}, let
shrinkt (M,c) := (M \ {{t − 1, α (t − 1)}, {t − 2,t − 3}}) ∪ {{t − 3, α (t − 1)}}.
(4) Otherwise, i.e., if {t − 1,t − 2}, {t − 1,t − 3}, {t − 2,t − 3}  M, then let
shrinkt (M, 1) := (M \ {{t − 1, α (t − 1)}, {t − 2, α (t − 2)}}) ∪ {{α (t − 1), α (t − 2)}},
shrinkt (M, 0) := (M \ {{t − 1, α (t − 1)}, {t − 2, α (t − 2)}, {t − 3, α (t − 3)}})
∪ {{t − 3, α (t − 2)}, {α (t − 1), α (t − 3)}}.
We omit the subscript t when it is clear from context; i.e., for M ∈ Π2 (Ut ) and c ∈ {0, 1}, let
shrink(M,c) := shrinkt (M,c). We also define the shorthand Mc := shrink(M,c), for M ∈ Π2 (Ut )
and c ∈ {0, 1}, and call this the c-shrink of M.
The following can easily be seen by checking the first two rows of Figure 8.
Proposition 6.2. Let t ≥ 4 be an even integer, a ∈ {0, 1}
t /2−2, and b,c ∈ {0, 1}. The c-shrink of
X (ab) equals X (a) if b = c¯ and ∅ otherwise.
Now we show how our shrink operation interacts with the fact of whether or not two matchings of Ut form a Hamiltonian cycle. Recall the 	-operator: we have that the union of two perfect
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:37
matchings M and M of Ut is a Hamiltonian cycle if and only if M 	 M = {Ut }, i.e., if the connectivity provided by the edges of the two matchings creates a single connected component that
contains all verticesUt . (We do not make further use of the meet operator, but we find it convenient
for specifying also the set of vertices on which we have a Hamiltonian cycle.)
The main fact about this interaction is given by Lemma 6.3, the proof of which is deferred to
Section 6.1. It shows that the fact of whether perfect matchings M1 and M2 form a Hamiltonian
cycle depends directly on two pairs of projections of the two matchings.
Lemma 6.3. Let t ≥ 4 be an even integer and let M1, M2 ∈ Π2 (Ut ). Recall Mc
i = shrink(Mi,c).
Then
[M1 	 M2 = {Ut }] ≡ 
M0
1 	 M1
2 = {Ut−2}
	
+ 
M1
1 	 M0
2 = {Ut−2}
	
.
In other words, M1 ∪ M2 is a Hamiltonian cycle onUt if and only if exactly one of M0
1 ∪ M1
2 and M1
1 ∪
M0
2 is a Hamiltonian cycle on Ut−2.
As a special case of Lemma 6.3, when the second matching is in our intended basis, we get the
following lemma. Both lemmas are used for proving the main theorem of this section.
Lemma 6.4. Let t be an even integer t ≥ 6 and let M ∈ Π2 (Ut ). Furthermore, let X = X (ab) ∈ Xt ,
where b ∈ {0, 1} and a is a 0,1-string of length t
2 − 2. Then M ∪ X is a Hamiltonian cycle if and only
if shrink(M,b) ∪ X (a) is a Hamiltonian cycle, i.e.,
[M 	 X (ab) = {Ut }] = [shrink(M,b) 	 X (a) = {Ut−2}] .
We are now set up to prove Theorem 3.4; let us recall the theorem statement first.
Theorem 6.5 (Theorem 3.4 restated). Let t ≥ 2 be an even integer and let M1, M2 ∈ Π2 (Ut ). We
have that
[M1 	 M2 = {Ut }] ≡

a ∈{0,1}
t /2−1
[M1 	 X (a) = {Ut }] · [M2 	 X (a¯) = {Ut }],
where X (a),X (a¯) ∈ Xt according to Definition 3.1.
We establish a factorization of the Matching Connectivity matrix as the product of two smaller
rectangular matrices: the first matrix has rows labeled by (all) perfect matchings and columns
labeled by basis matchings X (a) with a ∈ {0, 1}
t /2−1. The second matrix has rows labeled by basis
matchings X (a¯) with a ∈ {0, 1}
t /2−1 and columns labeled by (all) perfect matchings. The entries
of both rectangular matrices are as in the large one: we have 1 if the two matchings form a
Hamiltonian cycle and 0 otherwise; in other words, they are submatrices of the large matrix. Note
that the two perfect matchings from Xt in each summand are exactly the unique pairs that give
Hamiltonian cycles (among basis matchings). Also note that the main statement of the theorem
is given in arithmetic modulo two.
Proof of Theorem 3.4. Let us quickly verify the theorem for the base case t = 2. There is a
unique perfect matching {{0, 1}} forU2 = {0, 1}. Thus, we can only pick M1 = M2 = {{0, 1}}. Hence,
for the left-hand side of the theorem statement, we get
LHS = [M1 	 M2 = {U2}] = 1.
Regarding the right-hand side, the only choice for a ∈ {0, 1}
t /2−1 in the sum is a = ε. (Note thatε¯ =
ε.) We recall that X (ε) = {{0, 1}}, and thus we get
RHS = [M1 	 X (ε) = {U2}] · [M2 	 X (ε) = {U2}] = 1.
This completes the base case t = 2.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
12:38 M. Cygan et al.
Now, we will perform an inductive argument to show that the theorem holds also for all even t ≥
4. We start from the right-hand side of the theorem statement and apply Lemmas 6.3 and 6.4 to
transform it into the left-hand side. As a first step, we split the right-hand side sum into two parts,
depending on the last position of a (to do so formally, we shorten a by one position and explicitly
specify 0 or 1 to be appended):
RHS =

a ∈{0,1}
t /2−2
[M1 	 X (a0) = {Ut }] · [M2 	 X (a0) = {Ut }]
+

a ∈{0,1}
t /2−2
[M1 	 X (a1) = {Ut }] · [M2 	 X (a1) = {Ut }].
Note that a0 = a¯1 and a1 = a¯0. Let us recall the statement of Lemma 6.4:
[M 	 X (ab) = {Ut }] = [shrinkt (M,b) 	 X (a) = {Ut−2}] .
Using the shorthand Mj
i := shrinkt (Mi, j), we can thus rewrite the RHS as follows:
RHS =

a ∈{0,1}
t /2−2

M0
1 	 X (a) = {Ut−2}
	
·

M1
2 	 X (a¯) = {Ut−2}
	
+

a ∈{0,1}
t /2−2

M1
1 	 X (a) = {Ut−2}
	
·

M0
2 	 X (a¯) = {Ut−2}
	
.
We note that both sums go over all bitstrings a of length t
2 − 2 = t−2
2 − 1. Thus, after brief inspection of the summands, we see that we can apply the inductive assumption to both sums
since Mj
i ∈ Π2 (Ut−2). We obtain
RHS = 
M0
1 	 M1
2 = {Ut−2}
	
+ 
M1
1 	 M0
2 = {Ut−2}
	
.
Finally, by a direct application of Lemma 6.3, we obtain
RHS = [M1 	 M2 = {Ut }] = LHS,
which is what we intended to prove. Thus, the theorem holds for all even integer t ≥ 2, as
claimed.
6.1 Proof of Lemma 6.3
In this section, we present the deferred proof of Lemma 6.3. Let us restate the lemma first.
Lemma 6.6 (Lemma 6.3 restated). Let t ≥ 4 be an even integer and let M1, M2 ∈ Π2 (Ut ). Recall Mc
i = shrink(Mi,c). Then
[M1 	 M2 = {Ut }] ≡ 
M0
1 	 M1
2 = {Ut−2}
	
+ 
M1
1 	 M0
2 = {Ut−2}
	
.
In other words, M1 ∪ M2 is a Hamiltonian cycle onUt if and only if exactly one of M0
1 ∪ M1
2 and M1
1 ∪
M0
2 is a Hamiltonian cycle on Ut−2.
Proof. According to the definition of the shrink operator, the matchings M0
1 , M1
1 , M0
2 , and M2
2
depend on which of the edges {t − 1,t − 2}, {t − 1,t − 3}, and {t − 2,t − 3} are contained in M1 and
M2, respectively; we will make an appropriate case distinction. Clearly, Mi contains at most one
of these edges, giving four possible cases. For M1 and M2 together, this gives rise to 16 different
cases, e.g., {t − 1,t − 2} ∈ M1 and {t − 2,t − 3} ∈ M2. Due to symmetry of the claimed equation
(i.e., swapping M1 and M2 yields the same statement), we can omit one of each pair of symmetric
cases: for example, if we have proved the statement for {t − 1,t − 2} ∈ M1 and {t − 2,t − 3} ∈ M2,
then it follows immediately for {t − 2,t − 3} ∈ M1 and {t − 1,t − 2} ∈ M2. There are six such pairs
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018. 
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:39
of cases, as they arise when M1 and M2 do not contain the same edge of {t − 1,t − 2}, {t − 1,t − 3},
and {t − 2,t − 3}. (Note that this includes the case that one of them contains such an edge and the
other does not.) The remaining 10 considered cases are organized as follows: first, the three cases
where M1 and M2 contain the same edge of {t − 1,t − 2}, {t − 1,t − 3}, and {t − 2,t − 3}; then, the
six cases where M1 and M2 make different “choices,” omitting the six mentioned symmetric cases;
finally, the single case that neither M1 nor M2 contains any edge of {t − 1,t − 2}, {t − 1,t − 3}, and
{t − 2,t − 3}, which is the most technical case.
Let us clarify and recall a few things. The union of two perfect matchings on some vertex set
is known to always give a disjoint union of cycles plus possibly a set of edges. (Single edges arise
when both matchings contain the same edge; we could equivalently regard them as cycles of length
2 using a double edge.) We let α := αM1 and β := αM2 be the corresponding functions for M1 and M2
that for any element return the one that it is matched to. Accordingly, the cycles in M1 ∪ M2 will
contain subpaths (α (t − 1),t − 1, β (t − 1)), (α (t − 2),t − 2, β (t − 2)), and (α (t − 3),t − 3, β (t − 3)).
Depending on the edges incident with t − 1, t − 2, and t − 3, we may get fewer paths: e.g., if {t −
1,t − 2} ∈ M1, then α (t − 1) = t − 2 and α (t − 2) = t − 1; we get paths (β (t − 2),t − 2,t − 1, β (t −
1)) and (α (t − 3),t − 3, β (t − 3)).
Intuitively, the shrink-operator works in two steps: (1) it removes all edges incident with t −
1 and t − 2, and may remove one or both edges incident with t − 3, thereby creating subpaths
with endpoints in Z := {t − 1,t − 2,t − 3, α (t − 1), α (t − 2), α (t − 3), β (t − 1), β (t − 2), β (t − 3)} in
M1 ∪ M2, and (2) it adds edges with both endpoints in Z \ {t − 1,t − 2}, which may connect the
subpaths into one or more cycles on vertex set Ut−2. The additional edges differ for M0
1 and M1
1 ,
and for M0
2 and M1
2 (by definition of shrink), leading to different ways of connecting the subpaths
at Z \ {t − 1,t − 2}.
In each of the 10 considered cases, we use the structure of subpaths with endpoints in Z to
verify that the equation from the lemma statement holds. Generally, we may assume that M1 ∪ M2
contains no cycle that is disjoint from t − 1, t − 2, and t − 3 since all edges of such a cycle are
present in both M0
1 ∪ M1
2 and M1
1 ∪ M0
2 by our above discussion; i.e., shrink does not delete them.
This, however, would imply that both unions contain a cycle that avoids t − 3, and hence, they
cannot be a Hamiltonian cycle on Ut−2  t − 3. In other words, it remains to prove the equation
for the case that all cycles in M1 ∪ M2 contain at least one vertex of {t − 1,t − 2,t − 3} each. Cases
4 to 10 are depicted in Figure 9.
Case 1. {t − 1,t − 2} ∈ M1 ∩ M2: Clearly, M1 ∪ M2 is no Hamiltonian cycle as both matchings
contain {t − 1,t − 2}. We observe that M1
1 = shrink(M1, 1) = ∅ and M1
2 = shrink(M2, 1) = ∅.
Hence, neither M0
1 ∪ M1
2 nor M1
1 ∪ M0
2 is a Hamiltonian cycle; the equation holds.
Case 2. {t − 1,t − 3} ∈ M1 ∩ M2: Clearly, M1 ∪ M2 is no Hamiltonian cycle as both matchings
contain {t − 1,t − 3}. We observe that M0
1 = shrink(M1, 0) = ∅ and M0
2 = shrink(M2, 0) = ∅.
Hence, neither M0
1 ∪ M1
2 nor M1
1 ∪ M0
2 is a Hamiltonian cycle; the equation holds.
Case 3. {t − 2,t − 3} ∈ M1 ∩ M2: Clearly, M1 ∪ M2 is no Hamiltonian cycle as both matchings
contain {t − 2,t − 3}. We will see that either both or none of M0
1 ∪ M1
2 and M1
1 ∪ M0
2 form a
Hamiltonian cycle. By Definition 6.1, we have
shrinkt (M,c) := (M \ {{t − 1, αM (t − 1)}, {t − 2,t − 3}}) ∪ {{t − 3, αM (t − 1)}},
when {t − 2,t − 3} ∈ M. Thus, M0
1 = M1
1 and M1
2 = M0
2 . It follows that M0
1 ∪ M1
2 is a Hamiltonian
cycle if and only if M1
1 ∪ M0
2 is a Hamiltonian cycle, as needed.
Case 4. {t − 1,t − 2} ∈ M1: We observe that M1 ∪ M2 contains subpaths (α (t − 3),t − 3, β (t − 3))
and (β (t − 1),t − 1,t − 2, β (t − 2)). By Definition 6.1, we get
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
12:40 M. Cygan et al.
Fig. 9. Cases 4 to 10 of the proof of Lemma 6.3. Solid edges belong to sets M1, M0
1 , M1
1 , while dashed edges are
from M2, M0
2 , M1
2 . The left column contains M1 ∪ M2, the middle column M0
1 ∪ M1
2 , and the right M1
1 ∪ M0
2 .
If we have Mc
i = ∅, then the corresponding entry contains ∅.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:41
M0
1 = M1 \ {{t − 1,t − 2}},
M1
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2, β (t − 2)}}) ∪ {{β (t − 1), β (t − 2)}},
M1
1 = ∅,
M0
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2, β (t − 2)}, {t − 3, β (t − 3)}})
∪ {{t − 3, β (t − 2)}, {β (t − 1), β (t − 3)}}.
Hence, we know that M1
1 ∪ M0
2 cannot form a Hamiltonian cycle. (In the following, we
will omit Mc
i if its partner is the empty set.) Further, we get that M0
1 ∪ M1
2 contains subpaths (α (t − 3),t − 3, β (t − 3)) and (β (t − 1), β (t − 2)). Hence, the remaining edges complete M1 ∪ M2 to a Hamiltonian cycle if and only if the same is true for M0
1 ∪ M1
2 .
Case 5. {t − 1,t − 3} ∈ M1: We observe that M1 ∪ M2 contains subpaths (α (t − 2),t − 2, β (t − 2))
and (β (t − 1),t − 1,t − 3, β (t − 3)). By Definition 6.1, we get
M0
1 = ∅,
M1
1 = (M1 \ {{t − 1,t − 3}, {t − 2, α (t − 2)}}) ∪ {{t − 3, α (t − 2)}},
M0
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2, β (t − 2)}, {t − 3, β (t − 3)}})
∪ {{t − 3, β (t − 2)}, {β (t − 1), β (t − 3)}}.
This time M0
1 ∪ M1
2 cannot form a Hamiltonian cycle, since M0
1 = ∅. For M1
1 ∪ M0
2 , we get subpaths (α (t − 2),t − 3, β (t − 2)) and (β (t − 1), β (t − 3)). Hence, the remaining edges complete M1 ∪
M2 to a Hamiltonian cycle if and only if the same is true for M1
1 ∪ M0
2 .
Case 6. {t − 2,t − 3} ∈ M1: We observe that M1 ∪ M2 contains subpaths (α (t − 1),t − 1, β (t − 1))
and (β (t − 2),t − 2,t − 3, β (t − 3)). By Definition 6.1, we get
M0
1 = (M1 \ {{t − 1, α (t − 1)}, {t − 2,t − 3}}) ∪ {{t − 3, α (t − 1)}},
M1
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2, β (t − 2)}}) ∪ {{β (t − 1), β (t − 2)}},
M1
1 = (M1 \ {{t − 1, α (t − 1)}, {t − 2,t − 3}}) ∪ {{t − 3, α (t − 1)}},
M0
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2, β (t − 2)}, {t − 3, β (t − 3)}})
∪ {{t − 3, β (t − 2)}, {β (t − 1), β (t − 3)}}.
Now, for M0
1 ∪ M1
2 , we get subpaths (α (t − 1),t − 3, β (t − 3)) and (β (t − 1), β (t − 2)), and for M1
1 ∪
M0
2 , we get subpaths (α (t − 1),t − 3, β (t − 2)) and (β (t − 1), β (t − 3)).
If the remaining edges contain any cycles, then none of M1 ∪ M2, M0
1 ∪ M1
2 , and M1
1 ∪ M0
2 form
a Hamiltonian cycle. (In the following, we will tacitly ignore this case.) Otherwise, all remaining
edges form two vertex-disjoint paths that start and end in different vertices of {α (t − 1), β (t −
1), β (t − 2), β (t − 3)}; for convenience, if, e.g., α (t − 1) = β (t − 2), then we take this as a trivial
path from α (t − 1) to β (t − 2). There are three ways in which those paths can connect the four
vertices:
(1) (α (t − 1),..., β (t − 1)) and (β (t − 2),..., β (t − 3)): In this case, M1 ∪ M2 is no Hamiltonian cycle, but both M0
1 ∪ M1
2 and M1
1 ∪ M0
2 are Hamiltonian cycles. (This can be easily seen
by combining the corresponding two subpaths with the two paths through the remaining
edges: either we get a single (Hamiltonian) cycle or there are two cycles.)
(2) (α (t − 1),..., β (t − 2)) and (β (t − 1),..., β (t − 3)): In this case, M1 ∪ M2 and M0
1 ∪ M1
2
are Hamiltonian cycles, and M1
1 ∪ M0
2 is no Hamiltonian cycle.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
12:42 M. Cygan et al.
(3) (α (t − 1),..., β (t − 3)) and (β (t − 1),..., β (t − 2)): In this case, M1 ∪ M2 and M1
1 ∪ M0
2
are Hamiltonian cycles, and M0
1 ∪ M1
2 is no Hamiltonian cycle.
Thus, for all configurations of the remaining edges, we get that M1 ∪ M2 forms a Hamiltonian
cycle if and only if exactly one of M0
1 ∪ M1
2 and M1
1 ∪ M0
2 is a Hamiltonian cycle.
Case 7. {t − 1,t − 2} ∈ M1 and {t − 1,t − 3} ∈ M2: We observe that M1 ∪ M2 contains a subpath (α (t − 3),t − 3,t − 1,t − 2, β (t − 2)). By Definition 6.1, we get
M0
1 = M1 \ {{t − 1,t − 2}},
M1
2 = (M2 \ {{t − 1,t − 3}, {t − 2, β (t − 2)}}) ∪ {{t − 3, β (t − 2)}},
M1
1 = ∅,
M0
2 = ∅.
Thus, M1
1 ∪ M0
2 is no Hamiltonian cycle. For M0
1 ∪ M1
2 , we get a single subpath (α (t − 3),t − 3, β (t −
2)). It follows easily that M1 ∪ M2 is a Hamiltonian cycle if and only if M0
1 ∪ M1
2 is a Hamiltonian
cycle.
Case 8. {t − 1,t − 2} ∈ M1 and {t − 2,t − 3} ∈ M2: We observe that M1 ∪ M2 contains a subpath (α (t − 3),t − 3,t − 2,t − 1, β (t − 1)). By Definition 6.1, we get
M0
1 = M1 \ {{t − 1,t − 2}},
M1
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2,t − 3}}) ∪ {{t − 3, β (t − 1)}},
M1
1 = ∅.
Thus, M1
1 ∪ M0
2 is no Hamiltonian cycle. For M0
1 ∪ M1
2 , we get a single subpath (α (t − 3),t − 3, β (t −
1)). This implies that M1 ∪ M2 is a Hamiltonian cycle if and only if M0
1 ∪ M1
2 is a Hamiltonian
cycle.
Case 9. {t − 1,t − 3} ∈ M1 and {t − 2,t − 3} ∈ M2: We observe that M1 ∪ M2 contains a
subpath (α (t − 2),t − 2,t − 3,t − 1, β (t − 1)). By Definition 6.1, we get
M0
1 = ∅,
M1
1 = (M1 \ {{t − 1,t − 3}, {t − 2, α (t − 2)}}) ∪ {{t − 3, α (t − 2)}},
M0
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2,t − 3}}) ∪ {{t − 3, β (t − 1)}}.
Thus, M0
1 ∪ M1
2 is no Hamiltonian cycle. For M1
1 ∪ M0
2 , we get a single subpath (α (t − 2),t − 3, β (t −
1)). This implies that M1 ∪ M2 is a Hamiltonian cycle if and only if M1
1 ∪ M0
2 is a Hamiltonian
cycle.
Case 10. {{t − 1,t − 2}, {t − 1,t − 3}, {t − 2,t − 3}} ∩ (M1 ∪ M2) = ∅: In this final case, we can
only observe the trivial subpaths in M1 ∪ M2, namely, (α (t − 1),t − 1, β (t − 1)), (α (t − 2),t −
2, β (t − 2)), and (α (t − 3),t − 3, β (t − 3)). By Definition 6.1, we get
M0
1 = (M1 \ {{t − 1, α (t − 1)}, {t − 2, α (t − 2)}, {t − 3, α (t − 3)}})
∪ {{t − 3, α (t − 2)}, {α (t − 1), α (t − 3)}},
M1
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2, β (t − 2)}}) ∪ {{β (t − 1), β (t − 2)}},
M1
1 = (M1 \ {{t − 1, α (t − 1)}, {t − 2, α (t − 2)}}) ∪ {{α (t − 1), α (t − 2)}},
M0
2 = (M2 \ {{t − 1, β (t − 1)}, {t − 2, β (t − 2)}, {t − 3, β (t − 3)}})
∪ {{t − 3, β (t − 2)}, {β (t − 1), β (t − 3)}}.
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
Fast Hamiltonicity Checking Via Bases of Perfect Matchings 12:43
Table 1. All 15 Configurations for Paths Connecting the
Vertices α (t − 1), α (t − 2), α (t − 3), β (t − 1), β (t − 2), and β (t − 3), and
Their Effect on Whether M1 ∪ M2, M0
1 ∪ M1
2 , and M1
1 ∪ M0
2 form a Hamiltonian Cycle
(This Is Denoted by 1 and 0, Respectively)
Configuration of Remaining Edges as Paths Between M1 ∪ M2 M0
1 ∪ M1
2 M1
1 ∪ M0
2
α (t − 1), α (t − 2), α (t − 3), β (t − 1), β (t − 2), β (t − 3) Is H-Cycle Is H-Cycle Is H-Cycle
α (t − 1)-α (t − 2), α (t − 3)-β (t − 1), β (t − 2)-β (t − 3) 1 1 0
α (t − 1)-α (t − 2), α (t − 3)-β (t − 2), β (t − 1)-β (t − 3) 1 1 0
α (t − 1)-α (t − 2), α (t − 3)-β (t − 3), β (t − 1)-β (t − 2) 0 0 0
α (t − 1)-α (t − 3), α (t − 2)-β (t − 1), β (t − 2)-β (t − 3) 1 0 1
α (t − 1)-α (t − 3), α (t − 2)-β (t − 2), β (t − 1)-β (t − 3) 0 0 0
α (t − 1)-α (t − 3), α (t − 2)-β (t − 3), β (t − 1)-β (t − 2) 1 0 1
α (t − 1)-β (t − 1), α (t − 2)-α (t − 3), β (t − 2)-β (t − 3) 0 1 1
α (t − 1)-β (t − 1), α (t − 2)-β (t − 2), α (t − 3)-β (t − 3) 0 1 1
α (t − 1)-β (t − 1), α (t − 2)-β (t − 3), α (t − 3)-β (t − 2) 0 0 0
α (t − 1)-β (t − 2), α (t − 2)-α (t − 3), β (t − 1)-β (t − 3) 1 1 0
α (t − 1)-β (t − 2), α (t − 2)-β (t − 1), α (t − 3)-β (t − 3) 0 1 1
α (t − 1)-β (t − 2), α (t − 2)-β (t − 3), α (t − 3)-β (t − 1) 1 0 1
α (t − 1)-β (t − 3), α (t − 2)-α (t − 3), β (t − 1)-β (t − 2) 1 0 1
α (t − 1)-β (t − 3), α (t − 2)-β (t − 1), α (t − 3)-β (t − 2) 1 1 0
α (t − 1)-β (t − 3), α (t − 2)-β (t − 2), α (t − 3)-β (t − 1) 0 1 1
Fig. 10. The structure of paths on the set {α (t − 1), α (t − 2), α (t − 3), β (t − 1), β (t − 2), β (t − 3)} in Case 10
of the proof of Lemma 6.3. Note that the matchings correspond to columns 8, 6, and 2, respectively, of Table 1.
Thus, M0
1 ∪ M1
2 hasTable 2 subpaths
(α (t − 1), α (t − 3)), (α (t − 2),t − 3, β (t − 3)), (β (t − 1), β (t − 2)),
and M1
1 ∪ M0
2 has subpaths
(α (t − 1), α (t − 2)), (α (t − 3),t − 3, β (t − 2)), (β (t − 1), β (t − 3)).
Thus, whether any of the three unions of perfect matchings is a Hamiltonian cycle depends again
on the paths given by all remaining edges. As before, if those edges give rise to cycles disjoint
from t − 1, t − 2, t − 3, then none of the three unions is a Hamiltonian cycle and we are done.
Otherwise, the remaining edges serve exactly to create three vertex disjoint paths between the
vertices α (t − 1), α (t − 2), α (t − 3), β (t − 1), β (t − 2), and β (t − 3); there are 15 configurations of
such paths, i.e., partitions of this set of endpoints into three pairs of connected vertices. Note that
again, we treat cases like α (t − 1) = β (t − 2) as those have a path connecting α (t − 1) and β (t − 2).
It can be easily verified that for each of the 15 configurations, we get the desired property
that M1 ∪ M2 is a Hamiltonian cycle if and only if exactly one of M0
1 ∪ M1
2 and M1
1 ∪ M0
2 is a
Journal of the ACM, Vol. 65, No. 3, Article 12. Publication date: March 2018.
12:44 M. Cygan et al.
Hamiltonian cycle. For completeness, we provide a table containing all 15 cases; see Table 2.
We would like to note that the binary columns of Table 2 correspond to columns 8, 6, and 2
of Table 1, which can be observed when looking at Figure 10, where we have reordered the
vertices {α (t − 1), α (t − 2), α (t − 3), β (t − 1), β (t − 2), β (t − 3)} and contracted {t − 1,t − 2,t − 3}.
This completes the proof of Lemma 6.3.
7 CONCLUSIONS
We have presented a set of matchings Xn, which forms a basis of the Matching Connectivity matrix Hn. In particular, we have obtained a factorization theorem (Theorem 3.4) that shows an
explicit way of expressing any perfect matching as a linear combination of matchings of Xn. As
a consequence, we obtained deterministic algorithms for computing the parity of the number of
Hamiltonian cycles in undirected graphs and directed bipartite graphs in 1.888nnO(1) time, which
together with the Isolation Lemma lead to Monte Carlo algorithms solving the decision versions
of Hamiltonicity within the same running time. Moreover, using the basis Xn, we presented an
algorithm that, given an undirected graph on n vertices along with a path decomposition of width
at most pw, decides Hamiltonicity in (2 + √
2)
pwnO(1) time. Somewhat surprisingly, we use the same
tool, i.e., the basis Xn, to show by an involved reduction from CNF-Sat that our bounded pathwidth
algorithm is optimal under the Strong Exponential Time Hypothesis.
Our results lead to several natural open problems. Can the basis Xn be used to obtain a deterministic O((2 − ϵ )
n )-time algorithm for Hamiltonicity? Can we handle directed graphs without
the bipartiteness assumption? Can we extend our bounded pathwidth algorithm to a bounded
treewidth algorithm with the same complexity?
Finally, we would like to note that the row space of the Matching Connectivity matrix Hn
clearly has several different bases. We have investigated a particular one, which proved to have
several interesting properties and applications; however, there might be different ones that are
also worth exploring. 