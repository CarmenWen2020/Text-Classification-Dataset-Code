We introduce a weighted version of the ranking algorithm by Karp et al. (STOC 1990), and we prove a competitive ratio of 0.6534 for the vertex-weighted online bipartite matching problem when online vertices arrive
in random order. Our result shows that random arrivals help beating the 1-1/e barrier even in the vertexweighted case. We build on the randomized primal-dual framework by Devanur et al. (SODA 2013) and design
a two dimensional gain sharing function, which depends not only on the rank of the offline vertex, but also
on the arrival time of the online vertex. To our knowledge, this is the first competitive ratio strictly larger
than 1-1/e for an online bipartite matching problem achieved under the randomized primal-dual framework.
Our algorithm has a natural interpretation that offline vertices offer a larger portion of their weights to the
online vertices as time increases, and each online vertex matches the neighbor with the highest offer at its
arrival.
CCS Concepts: • Theory of computation → Approximation algorithms analysis; Online algorithms;
Additional Key Words and Phrases: Vertex weighted, online bipartite matching, randomized primal-dual
1 INTRODUCTION
With a wide range of applications, Online Bipartite Matching and its variants are a focal point in
the online algorithms literature. Consider a bipartite graph G(U,V, E) on vertices U ∪V , where
the set V of offline vertices is known in advance and vertices in U arrive online. On the arrival of
an online vertex, its incident edges are revealed and the algorithm must irrevocably either match
it to one of its unmatched neighbors or leave it unmatched. In a seminal paper, Karp et al. [21]
proposed the Ranking algorithm, which picks at the beginning a random permutation over the
offline vertices V , and matches each online vertex to the first unmatched neighbor according to
the permutation. They proved a tight competitive ratio 1 − 1
e of Ranking when online vertices
arrive in an arbitrary order. The analysis has been simplified in a series of subsequent works
[5, 13, 15]. Further, the Ranking algorithm has been extended to other variants of the Online
Bipartite Matching problem, including the vertex-weighted case [2], the random arrival model
[20, 23], and the Adwords problem [7, 12, 25].
As a natural generalization, Online Vertex-Weighted Bipartite Matching was considered by
Aggarwal et al. [2]. In this problem, each offline vertex v ∈ V has a non-negative weight wv , and
the objective is to maximize the total weight of the matched offline vertices. A weighted version of the Ranking algorithm was proposed in Ref. [2] and shown to be (1 − 1
e )-competitive,
matching the problem hardness in the unweighted version. They fix a non-increasing perturbation functionψ : [0, 1] → [0, 1], and draw a rank yv ∈ [0, 1] uniformly and independently for each
offline vertexv ∈ V . The offline vertices are then sorted in decreasing order of the perturbed weight
wv · ψ (yv ). Each online vertex matches the first unmatched neighbor on the list upon its arrival. It
is shown that by choosing the perturbation functionψ (y) := 1 − ey−1, the weighted Ranking algorithm achieves a tight competitive ratio 1 − 1
e . In a subsequent work, Devanur et al. [13] simplified
the analysis under the randomized primal-dual framework and gave an alternative interpretation
of the algorithm: each offline vertex v makes an offer of value wv · (1 − д(yv )) as long as it is not
matched, where д(y) := ey−1 = 1 −ψ (y), and each online vertex matches the neighbor that offers
the highest.
Motivated by the practical importance of Online Bipartite Matching and its applications for
online advertisements, another line of research seeks for a better theoretical bound beyond the
worst-case hardness result provided by Karp et al. [21]. Online Bipartite Matching problem with
random arrivals was considered independently by Karande et al. [20] and Mahdian et al. [23].
They both studied the performance of Ranking assuming that online vertices arrive in a uniform
random order and proved competitive ratios 0.653 and 0.696, respectively. On the negative side,
Karande et al. [20] explicitly constructed an instance for which Ranking performs no better than
0.727, which is later improved to 0.724 by Chan et al. [10]. In terms of problem hardness, Manshadi
et al. [24] showed that no algorithm can achieve a competitive ratio larger than 0.823.
The natural next step is then to consider the Online Vertex-Weighted Bipartite Matching problem with random arrivals. Do random arrivals help beating 1 − 1
e even in the vertex-weighted case?
Arbitrary Arrivals Random Arrivals
Unweighted 1 − 1
e ≈ 0.632 [5, 13, 15, 21] 0.696 [23]
Vertex-weighted 1 − 1
e ≈ 0.632 [2, 13] 0.6534 (this paper)
1.1 Our Results and Techniques
We answer this affirmatively by showing that a generalized version of the Ranking algorithm
achieves a competitive ratio 0.6534.
Theorem 1.1. There exists a 0.6534-competitive algorithm for the Online Vertex-Weighted Bipartite Matching problem with random arrivals.
Interestingly, we do not obtain our result by generalizing existing works that break the 1 − 1
e
barrier on the unweighted case [20, 23] to the vertex-weighted case. Instead, we take a totally
different path and build our analysis on the randomized primal-dual technique introduced by
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.
Online Vertex-Weighted Bipartite Matching: Beating 1 − 1
e with Random Arrivals 38:3
Devanur et al. [13], which was used to provide a more unified analysis of the algorithms for the
Online Bipartite Matching problem with arbitrary arrival order and its extensions.
We first briefly review the proof of Devanur et al. [13]. The randomized primal-dual technique
can be viewed as a charging argument for sharing the gain of each matched edge between its two
endpoints. Recall that in the algorithm of Refs. [2] and [13], each unmatched offline vertex offers
a value of wv · (1 − д(yv )) to online vertices, and each online vertex matches the neighbor that
offers the highest at its arrival. Whenever an edge (u,v) is added to the matching, where v ∈ V is
an offline vertex and u ∈ U is an online vertex, imagine a total gain of wv being shared between u
and v such that u getswv · (1 − д(yv )) and v getswv · д(yv ). Since д is non-decreasing, the smaller
the rank of v, the smaller share it gets. For any edge (u,v) and any fixed ranks of online vertices
other than v, they showed that by fixing д(y) = ey−1, the expected gains of u and v (from all of
their incident edges) combined is at least (1 − 1
e ) · wv over the randomness of yv . This implies the
1 − 1
e competitive ratio.
Now we consider the problem with random arrivals.
Analogous to the offline vertices, as the online vertices arrive in random order, in the gain
sharing process, it is natural to give an online vertex u a smaller share if u arrives early (as it is
more likely be get matched), and a larger share whenu arrives late. Thus, we consider the following
version of the weighted Ranking algorithm.
Let yu be the arrival time of online vertex u ∈ U , which is chosen uniformly at random from
[0, 1]. Analogous to the ranks of the offline vertices, we also callyu the rank ofu ∈ U . Fix a function
д : [0, 1]2 → [0, 1] that is non-decreasing in the first dimension and non-increasing in the second
dimension. On the arrival of u ∈ U , each unmatched neighbor v ∈ V of u makes an offer of value
wv · (1 − д(yv ,yu )), and u matches the neighbor with the highest offer. This algorithm straightforwardly leads to a gain sharing rule for dual assignments: whenever u ∈ U matches v ∈ V , let
the gain of u be wv · (1 − д(yv ,yu )) and the gain of v be wv · д(yv ,yu ). It suffices to show that for
an appropriate function д, the expected gain of u and v combined is at least 0.6534 · wv over the
randomness of both yu and yv .
The main difficulty of the analysis is to give a good characterization of the behavior of the
algorithm when we vary the ranks of both u ∈ U and v ∈ V , while fixing the ranks of all other
vertices arbitrarily. The previous analysis for the unweighted case with random arrivals [20, 23]
heavily relies on a symmetry between the random ranks of offline vertices and online vertices:
Properties developed for the offline vertices in previous work directly translate to their online
counterparts. Unfortunately, the online and offline sides are no longer symmetric in the vertexweighted case. In particular, for the offline vertex v, an important property is that for any given
rank yu of the online vertex u, we can define a unique marginal rank θ such that v will be matched
if and only if its rank yv < θ. However, it is not possible to define such a marginal rank for the
online vertex u in the vertex-weighted case: As its arrival time changes, its matching status may
change back and forth. In particular, since the function д depends on the arrival time of u, it may
happen that u prefers neighbor v to z at one arrival time, but prefers z to v at another. The most
important technical ingredient of our analysis is an appropriate lower bound on the expected gain
that allows us to partially characterize the worst-case scenario (in the sense of minimizing the
lower bound on the expected gain). Further, the worst-case scenario does admit simple marginal
ranks even for the online vertex u. This allows us to design a symmetric gain sharing function д
and complete the competitive analysis of 0.6534.
As we will discuss in Section 5, our framework may be able to give stronger lower bound on
the competitive ratio, potentially matching or even improving the one of Mahdian and Yan [23], if
we had a tight analysis of a complex system of differential inequalities. Numerical results suggest
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.
38:4 Z. Huang et al.
that the integration shown in Section 5 may give a much larger lower bound on the competitive
ratio than the one we present in this article. However, giving a tight analysis on the integration is
highly non-trivial. Indeed, a significant portion of our analysis, e.g., Section 4 and part of Section 3,
is devoted to provide analyzable relaxations on this integration.
1.2 Other Related Works
There is a vast literature on problems related to Online Bipartite Matching. For space reasons, we
only list some of the most relative here.
Kesselheim et al. [22] considered the edge-weighted Online Bipartite Matching problem with
random arrivals, and proposed a 1
e -competitive algorithm. The competitive ratio is tight as it
matches the lower bound on the classical secretary problem [8]. Wang and Wong [26] considered
a different model of the Online Bipartite Matching problem with both sides of vertices arriving
online (in an arbitrary order). A vertex can only actively match other vertices at its arrival; if it
fails to match at its arrival, it may still get matched passively by other vertices later. They showed
a 0.526-competitive algorithm for a fractional version of the problem.
Recently, Cohen and Wajc [11] considered the Online Bipartite Matching (with arbitrary arrival
order) on regular graphs and provided a (1 − O(

logd/d))-competitive algorithm, where d is the
degree of vertices. Very recently, Huang et al. [17] proposed a fully online matching model in
which all vertices of the graph arrive online (in an arbitrary order). Extending the randomized
primal-dual technique, they obtained competitive ratios above 0.5 for both bipartite graphs and
general graphs.
Similar but different from the Online Bipartite Matching problem with random arrivals, in the
stochastic Online Bipartite Matching, the online vertices arrive according to some known probability distribution (with repetition). Competitive ratios breaking the 1 − 1
e barrier have been achieved
for the unweighted case [4, 6, 14] and the vertex-weighted case [6, 16, 19].
The Online Bipartite Matching problem with random arrivals is closely related to the oblivious
matching problem [1, 3, 10] (on bipartite graphs). It can be easily shown that Ranking has equivalent performance on the two problems. Thus, competitive ratios above 1 − 1
e [20, 23] directly
translate to the oblivious matching problem. Generalizations of the problem to arbitrary graphs
have also been considered, and competitive ratios above half are achieved for the unweighted
case [3, 10] and vertex-weighted case [1, 9].
2 PRELIMINARIES
We consider the Online Vertex-Weighted Bipartite Matching with random arrival order. Let
G(U,V, E) be the underlying graph, where vertices in V are given in advance and vertices in U
arrive online in random order. Each offline vertex v ∈ V is associated with a non-negative weight
wv . Without loss of generality, we assume the arrival time yu of each online vertex u ∈ U is drawn
independently and uniformly from [0, 1]. Mahdian and Yan [23] use another interpretation for the
random arrival model. They denote the order of arrival of online vertices by a permutation π and
assume that π is drawn uniformly at random from the permutation group Sn. It is easy to see the
equivalence between two interpretations: The algorithm draws n independent random variables
from [0, 1] uniformly at random before any online vertex arrives, and assigns the i-th smallest
variable to the i-th online vertex in the random permutation as its arrival time.
Weighted Ranking. Fix a function д : [0, 1]2 → [0, 1] such that ∂д(x,y)
∂x ≥ 0 and ∂д(x,y)
∂y ≤ 0. Each
offline vertex v ∈ V draws independently a random rank yv ∈ [0, 1] uniformly at random. Upon
the arrival of online vertex u ∈ U , u is matched to its unmatched neighbor v with maximum wv ·
(1 − д(yv ,yu )).
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019. 
Online Vertex-Weighted Bipartite Matching: Beating 1 − 1
e with Random Arrivals 38:5
Remark 2.1. In the adversarial model, Aggarwal et al.’s algorithm [2] can be interpreted as
choosing д(yv ,yu ) := eyv −1 in our algorithm. Our algorithm is a direct generalization of theirs
to the random arrival model.
For simplicity, for each u ∈ U , we also call its arrival time yu the rank of u. We use y : U ∪V →
[0, 1] to denote the vector of all ranks.
Consider the linear program relaxation of the bipartite matching problem and its dual.
max :
(u,v)∈E
wv · xuv min :
u ∈U
αu +

v ∈V
αv
s.t.
v:(u,v)∈E
xuv ≤ 1 ∀u ∈ U s.t. αu + αv ≥ wv ∀(u,v) ∈ E

u:(u,v)∈E
xuv ≤ 1 ∀v ∈ V αu ≥ 0 ∀u ∈ U
xuv ≥ 0 ∀(u,v) ∈ E αv ≥ 0 ∀v ∈ V
Randomized Primal-Dual. Our analysis builds on the randomized primal-dual technique by
Devanur et al. [13]. We set the primal variables according to the matching produced by Ranking, i.e., xuv = 1 if and only if u is matched to v by Ranking, and set the dual variables so that the
dual objective equals the primal. In particular, we split the gain wv of each matched edge (u,v)
between vertices u and v; the dual variable for each vertex then equals the share it gets. Given primal feasibility and equal objectives, the usual primal-dual techniques would further seek to show
approximate dual feasibility, namely, αu + αv ≥ F · wv for every edge (u,v), where F is the target
competitive ratio. Observe that the above primal and dual assignments are themselves random
variables. Devanur et al. [13] claimed that the primal-dual argument goes through given approximate dual feasibility in expectation. We formulate this insight in the following lemma and include
a proof for completeness.
Lemma 2.1. Ranking is F -competitive if we can set (non-negative) dual variables such that
—
(u,v)∈E xuv = 
u ∈V αu ; and
—Ey[αu + αv ] ≥ F · wv for all (u,v) ∈ E.
Proof. We can set a feasible dual solution α˜u := Ey[αu ]/F for all u ∈ V . It’s feasible because
we have α˜u + α˜v = Ey[αu + αv ]/F ≥ wv for all (u,v) ∈ E. Then, by duality, we know that the dual
solution is at least the optimal primal solution PRIMAL, which is also at least the optimal offline solution of the problem: 
u ∈V α˜u ≥ PRIMAL ≥ OPT. Then, by the first assumption, we have
OPT ≤ 
u ∈V α˜u = 
u ∈V
Ey[αu ]
F = 1
F Ey[

u ∈V αu ] = 1
F Ey[

(u,v)∈E wv · xuv ] = 1
F E[ALG], which
implies an F competitive ratio.
In the rest of the article, we set
д(x,y) = 1
2
(h(x) + 1 − h(y)), ∀x,y ∈ [0, 1],
where h : [0, 1] → [0, 1] is a non-decreasing function (to be fixed later) with h	
(x) ≤ h(x) for all
x ∈ [0, 1]. Observe that ∂д(x,y)
∂x = 1
2h	
(x) ≥ 0 and ∂д(x,y)
∂y = −1
2h	
(y) ≤ 0. By definition ofд, we have
д(x,y) + д(y, x) = 1. Moreover, for any x,y ∈ [0, 1], we have the following fact that will be useful
for our analysis.
Claim 2.1. ∂д(x,y)
∂y ≥ д(x,y) − 1.
Proof. ∂д(x,y)
∂y = −1
2h	
(y) ≥ −1
2h(y) ≥ 1
2 (h(x) + 1 − h(y)) − 1 = д(x,y) − 1.
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.              
38:6 Z. Huang et al.
3 A SIMPLE LOWER BOUND
In this section, we prove a slightly smaller competitive ratio, 5
4 − e−0.5 ≈ 0.6434, as a warm-up of
the later analysis.
We reinterpret our algorithm as follows. As time t increases, each unmatched offline vertex
v ∈ V is dynamically priced at wv · д(yv ,t). Since д is non-increasing in the second dimension,
the prices do not increase as time increases. Upon the arrival of u ∈ U , u can choose from its
unmatched neighbors by paying the corresponding price. The utility of u derived by choosing v
equals wv − wv · д(yv ,yu ). Then, u chooses the one that gives the highest utility. Recall that д is
non-decreasing in the first dimension. Thus, u prefers offline vertices with smaller ranks, as they
offer lower prices.
This leads to the following monotonicity property as in previous works [2, 13].
Fact 3.1 (Monotonicity). For any y, if v ∈ V is unmatched when u ∈ U arrives, then when yv
increases,v remains unmatched whenu arrives. Equivalently, ifv ∈ V is matched whenu ∈ U arrives,
then when yv decreases, v remains matched when u arrives.
Gain Sharing. The above interpretation induces a straightforward gain sharing rule: whenever
u ∈ U is matched to v ∈ V , let αv := wv · д(yv ,yu ) and αu := wv · (1 − д(yv ,yu )) = wv · д(yu,yv ).
Note that the gain of an offline vertex is larger if it is matched earlier, i.e., being matched earlier
is more beneficial for offline vertices (αv is larger). However, the fact does not hold for online
vertices. For each online vertex u ∈ U , the earlier u arrives (smaller yu is), the more offers u sees.
On the other hand, the prices of offline vertices are higher when u comes earlier. Thus, it is not
guaranteed that earlier arrival time yu induces larger αu .
This is where our algorithm deviates from previous ones [2, 13], in which the prices of offline
vertices are static (independent of time). The above observation is crucial and necessary for breaking the 1 − 1
e barrier in the random arrival model.
To apply Lemma 2.1, we consider a pair of neighbors v ∈ V and u ∈ U . We fix an arbitrary
assignment of ranks to all vertices but u,v. Our goal is to establish a lower bound of 1
wv · E[αu +
αv ], where the expectation is simultaneously taken over yu and yv .
Lemma 3.1. For eachy ∈ [0, 1], there exist thresholds 1 ≥ θ (y) ≥ β (y) ≥ 0 such that whenu arrives
at time yu = y,
—if yv < β (y), v is matched when u arrives;
—if yv ∈ (β (y), θ (y)), v is matched to u;
—if yv > θ (y), v is unmatched after u’s arrival.
Moreover, β (y) is a non-decreasing function and if θ (x) = 1 for some x ∈ [0, 1], then θ (x 	
) = 1 for all
x 	 ≥ x.
Proof. Consider the moment when u arrives. By Fact 3.1, there exists a threshold β (yu ) such
that v is matched when u arrives iff yv < β (yu ). Now suppose yv > β (yu ), in which case v is not
matched when u arrives. Thus, v is priced at wv · д(yv ,yu ) and u can get utility wv · д(yu,yv ) by
choosing v.
Recall that д(yu,yv ) is non-increasing in terms of yv . Let θ (yu ) ≥ β (yu ) be the minimum value
of yv such that v is not chosen by u. In other words, when β (yu ) < yv < θ (yu ), u matches v and
when yv > θ (yu ), v is unmatched after u’s arrival.
Next we show that β is a non-decreasing function of yu . By definition, if yv < β (yu ), then v is
matched when u arrives. Straightforwardly, when yu increases to y	
u (arrives even later), v would
remain matched. Hence, we have β (y	
u ) ≥ β (yu ) for all y	
u > yu , i.e., β is non-decreasing (refer to
Figure 1).
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019. 
Online Vertex-Weighted Bipartite Matching: Beating 1 − 1
e with Random Arrivals 38:7
Fig. 1. θ (yu ) and β (yu ) (left-hand side); truncated θ (yu ) and β (yu ) (right-hand side).
Finally, we show that if θ (x) = 1 for some x ∈ [0, 1], then θ (x 	
) = 1 for all x 	 ≥ x. Assume for the
sake of contradiction that θ (x 	
) < 1 for some x 	 > x. In other words, when yu = x 	 and yv = 1, v is
unmatched whenu arrives, butu chooses some vertex z  v, such thatwz · д(x 	
,yz ) > wv · д(x 	
, 1).
Now consider the case whenu arrives at time yu = x. Recall that we have θ (x) = 1, which means
that u matches v when yu = x and yv = 1. By our assumption, both v and z are unmatched when u
arrives at time x 	
. Thus, when u arrives at an earlier time x, bothv and z are unmatched. Moreover,
choosing z induces utility
wz · д(x,yz ) = wz · д(x 	
,yz ) · д(x,yz )
д(x 	
,yz ) > wv · д(x 	
, 1) · д(x,yz )
д(x 	
,yz )
= wv · д(x 	
, 1) · h(x) + 1 − h(yz )
h(x 	) + 1 − h(yz ) ≥ wv · д(x 	
, 1) · h(x) + 1 − h(1)
h(x 	) + 1 − h(1)
= wv · д(x 	
, 1) · д(x, 1)
д(x 	
, 1) = wv · д(x, 1),
where the second inequality holds since h is a non-decreasing function and x < x 	
.
This gives a contradiction, since when yu = x and yv = 1, u chooses v, while choosing z gives
strictly higher utility.
Remark 3.1. In the previous analysis by Devanur et al. [13] on the arbitrary arrival model, a
single marginal rank (independent of yu ) of v is defined, and they do not distinguish whether v
is matched with u, as the gain sharing depends only on the rank of v, e.g., the definition of β is
unnecessary.
Remark 3.2. Observe that the function θ is not necessarily monotone. This comes from the fact
that u may preferv to z whenu arrives at time t but prefer z tov when u arrives later at time t	 > t.
Note that this happens only when the offline vertices have general weights: for the unweighted
case, it is easy to show that θ must be non-decreasing.
We define τ ,γ ∈ [0, 1], which depends on the input instance, as follows.
If θ (y) < 1 for all y ∈ [0, 1], then let τ = 1; otherwise, let τ be the minimum value such that
θ (τ ) = 1. Let γ := β (1). Note that it is possible that γ ∈ {0, 1}.
Since β is non-decreasing, we define β−1 (x) := sup{y : β (y) = x} for all x ≤ γ .
In the following, we establish a lower bound for 1
wv · E[αu + αv ].
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.  
38:8 Z. Huang et al.
Lemma 3.2 (Main Lemma). For each pair of neighbors u ∈ U and v ∈ V , we have
1
wv
· E[αu + αv ] ≥ min
0≤γ,τ ≤1

(1 − τ ) · (1 −γ ) +
 γ
0
д(x, τ )dx +
 τ
0
д(x,γ )dx
.
It is worthwhile to make a comparison with a similar claim in the previous analysis by Devanur
et al. [13] on the arbitrary arrival model: 1
wv · E[αu + αv ] ≥ minθ {
 θ
0 д(y)dy + 1 − д(θ )}. The first
term in their lower bound comes from the gain of the offline vertexv while the 1 − д(θ ) term comes
from the fact that the online vertex u has gained at least 1 − д(θ ) for all values of yv . Compared
to theirs, our lower bound beats 1 − 1
e by utilizing the tradeoff between the gain  γ
0 д(x, τ )dx of v
and the “marginal” arrival time τ of u: in the previous analysis, only the tradeoff between the gain
1 − д(θ ) of u and the marginal rank θ of v is utilized.
We prove Lemma 3.2 by the following three lemmas.
Observe that for any yu ∈ [0, 1], if yv ∈ (β (yu ), θ (yu )), u,v are matched to each other, which
implies αu + αv = wv . Hence, we have the following lemma immediately.
Lemma 3.3 (Corner Gain). E[(αu + αv ) · 1(yu > τ ,yv > γ )] = wv · (1 − τ ) · (1 −γ ).
Now we give a lower bound for the gain of v when yv < γ , i.e., αv · 1(yv < γ ), plus the gain of
u when yv < γ and yu > τ , i.e., αu · 1(yv < γ ,yu > τ ). The key to prove the lemma is to show that
for all yv < γ , no matter when u arrives, we always have αv ≥ wv · д(yv , β−1 (yv )).
Lemma 3.4 (v’s Gain). E[αv · 1(yv < γ ) + αu · 1(yv < γ ,yu > τ )] ≥ wv ·
 γ
0 д(x, τ )dx.
Proof. Fix yv = x < γ . We first show that for all yu ∈ [0, 1], αv ≥ wv · д(x, β−1 (x)). By definition, we have β−1 (x) < 1. Hence, when yu > β−1 (x), v is already matched when u arrives. Suppose
v is matched to some z ∈ U , then we have yz ≤ β−1 (x) and, hence, αv ≥ wv · д(x, β−1 (x)). Now
consider when u arrives at time y < β−1 (x). If y > yz , then v is still matched to z when u arrives,
and αv ≥ wv · д(x, β−1 (x)) holds. Now, suppose y < yz . We compare the two processes, namely,
when yu > β−1 (x) and when yu = y.
We show that for each vertex w ∈ V , the time it is matched is not later in the second case
(compared to the first case). In other words, we show that decreasing the rank of any online vertex
is not harmful for all offline vertices. Suppose otherwise. Let w be the first vertex in V that is
matched later when yu = y than when yu > β−1 (x), i.e., among all these vertices, w’s matched
neighbor arrives the earliest when yu > β−1 (x).
Let u1 be the vertex w is matched to when yu > β−1 (x) and u2 be the vertex w is matched to
when yu = y. By assumption, we have yu2 > yu1 . Consider when yu = y and the moment when
u1 arrives, w remains unmatched but is not chosen by u1. However, w is the first vertex that is
matched later than it was when yu > β−1 (x). We know that at u1’s arrival, the set of unmatched
neighbors of u1 is a subset of that when yu > β−1 (x). This leads to a contradiction, since w gives
the highest utility, but is not chosen by u1.
In particular, this property holds for vertex v, i.e., v is matched earlier or at the arrival of z and,
hence, αv ≥ wv · д(x,yz ) ≥ wv · д(x, β−1 (x)), as claimed.
Observe that for yv < γ and yu ∈ (τ , β−1 (yv )), we have αu + αv = wv . Thus, for yv = x < γ , we
lower bound 1
wv · Eyu [αv · 1(yv < γ ) + αu · 1(yv < γ ,yu > τ )] by
f (x, β−1 (x)) := д(x, β−1 (x)) + max{0, β−1 (x) − τ } · (1 − д(x, β−1 (x))).
It suffices to show that f (x, β−1 (x)) ≥ д(x, τ ). Consider the following two cases.
(1) If β−1 (x) < τ , then f (x, β−1 (x)) = д(x, β−1 (x)) ≥ д(x, τ ), since ∂д(x,y)
∂y ≤ 0.
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.
Online Vertex-Weighted Bipartite Matching: Beating 1 − 1
e with Random Arrivals 38:9
(2) If β−1 (x) ≥ τ , then f (x, β−1 (x)) is non-decreasing in the second dimension, since
∂f (x, β−1 (x))
∂β−1 (x) = ∂д(x, β−1 (x))
∂β−1 (x) + 1 − д(x, β−1 (x)) − (β−1 (x) − τ ) ·
∂д(x, β−1 (x))
∂β−1 (x) ≥ 0,
where the inequality follows from Claim 2.1 and the fact that ∂д(x, β−1 (x ))
∂β−1 (x ) ≤ 0. Therefore,
we have f (x, β−1 (x)) ≥ f (x, τ ) = д(x, τ ).
Hence, for every fixed yv = x < γ , we have
Eyu [αv · 1(yv < γ ) + αu · 1(yv < γ ,yu > τ )] ≥ wv · д(x, τ ).
Taking integration over x ∈ (0,γ ) concludes the lemma.
Next, we give a lower bound for the gain of u when yu < τ , i.e., αu · 1(yu < τ ), plus the gain of
v when yu < τ and yv > γ , i.e., αv · 1(yu < τ ,yv > γ ). The following proof is in the same spirit as
in the proof of Lemma 3.4, although the ranks of off-line vertices have different meaning from the
ranks (arrival times) of online vertices.
Similar to the proof of Lemma 3.4, the key is to show that for all yu < τ , no matter what value
yv is, the gain of αu is always at least wv · д(yu, θ (yu )).
Lemma 3.5 (u’s Gain). E[αu · 1(yu < τ ) + αv · 1(yu < τ ,yv > γ )] ≥ wv ·
 τ
0 д(x,γ )dx.
Proof. Fix yu = x < τ . By definition, we have θ (x) < 1. The analysis is similar to the previous.
We first show that for all yv ∈ [0, 1], we have αu ≥ wv · д(x, θ (x)).
We use θ to denote the value that is arbitrarily close to, but larger than θ (x). By definition,
when yv = θ, u matches some vertex other than v. Thus, we have αu ≥ wv · д(x, θ (x)). Hence,
when yv > θ, i.e., v has a higher price, u would choose the same vertex as when yv = θ, and
αu ≥ wv · д(x, θ (x)) still holds.
Now consider the case when yv = y < θ.
As in the analysis of Lemma 3.4, we compare two processes, when yv = θ and when yv = y < θ.
We show that for each vertex w ∈ U (including u) with yw ≤ x = yu , the utility of w when yv = y
is not worse than its utility when yv = θ. Suppose otherwise. Let w be such a vertex with earliest
arrival time.
Let v	 be the vertex that is matched to w when yv = θ. Then we know that (when yv = y) at
w’s arrival, w chooses a vertex that gives less utility comparing to v	
. Hence, at this moment, v	 is
already matched to some w	 with yw	 < yw . This implies that when yv = θ, v	 (which is matched
to w) is unmatched when w	 arrives, but not chosen by w	
. Therefore, w	 has lower utility when
yv = y compared to the case when yv = θ, which contradicts the assumption that w is the first
such vertex.
Observe that when yv ∈ (γ , θ (x)), we have αu + αv = wv . Thus for any fixed yu = x < τ , we
lower bound 1
wv · Eyv [αu · 1(yu < τ ) + αv · 1(yu < τ ,yv > γ )] by
f (x, θ (x)) := д(x, θ (x)) + max{0, θ (x) −γ } · (1 − д(x, θ (x))).
In the following, we show that f (x, θ (x)) ≥ д(x,γ ). Consider the following two cases.
(1) If θ (x) ≤ γ , then f (x, θ (x)) = д(x, θ (x)) ≥ д(x,γ ), since ∂д(x,y)
∂y ≤ 0.
(2) If θ (x) > γ , then
∂f (x, θ (x))
∂θ (x) = ∂д(x, θ (x))
∂θ (x) + 1 − д(x, θ (x)) − (θ (x) −γ ) ·
∂д(x, θ (x))
∂θ (x) ≥ 0,
where the inequality follows from Claim (2.1) and ∂д(x,θ (x ))
∂θ (x ) ≤ 0. Therefore, we have
f (x, θ (x)) ≥ f (x,γ ) = д(x,γ ).
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019. 
38:10 Z. Huang et al.
Finally, integration over x ∈ (0, τ ) concludes the lemma.
Proof of Lemma 3.2. Observe that
αu + αv = (αu + αv ) · 1(yu > τ ,yv > γ ) + αv · 1(yv < γ ) + αu · 1(yv < γ ,yu > τ )
+ αu · 1(yu < τ ) + αv · 1(yu < τ ,yv > γ )
Combining Lemma 3.3, 3.4, and 3.5 finishes the proof immediately.
Theorem 3.6. Fix h(x) = min{1, ex−0.5}. For any pair of neighbors u and v, and any fixed ranks
of vertices in U ∪V \ {u,v}, we have 1
wv · Eyu,yv [αu + αv ] ≥ 5
4 − e−0.5 ≈ 0.6434.
Proof. It suffices to show that the right hand side (RHS) of Lemma 3.2 is at least 5
4 − e−0.5. Since
the expression is symmetric for τ and γ , we assume τ ≥ γ without loss of generality.
Let f (τ ,γ ) be the term on the RHS of Lemma 3.2 to be minimized. By our choice of д,
f (τ ,γ ) = 1 − τ −γ + τ · γ +
1
2
 γ
0
(h(x) + 1 − h(τ ))dx +
1
2
 τ
0
(h(x) + 1 − h(γ ))dx
= 1 − τ
2
(1 + h(γ )) − γ
2
(1 + h(τ )) + τ · γ +
1
2
 γ
0
h(x)dx +
1
2
 τ
0
h(x)dx.
Observe that
∂f (τ ,γ )
∂τ = γ − 1
2
(1 + h(γ )) − γ
2 · h	
(τ ) +
1
2
h(τ ).
It is easy to check that
γ − 1
2
h(γ )
⎧⎪
⎨
⎪
⎩
≤ 0 when γ ≤ 1
2 ,
> 0 when γ > 1
2 .
Hence, when γ ≤ 1
2 , we have
∂f (τ ,γ )
∂τ ≤ γ − 1
2
h(γ ) − 1
2
(1 − h(τ )) ≤ 0,
which means that the minimum is attained when τ = 1. Note that when γ ≤ 1
2 , we have
f (1,γ ) = 1
2
(1 − h(γ )) +
1
2
 γ
0
h(x)dx +
1
2
 1
0
h(x)dx,
which attains its minimum at γ = 0 (since h	
(γ ) = h(γ ) for γ ≤ 1
2 ):
f (1, 0) = 1
2
(1 − e−0.5) +
1
2
	 1
2
+ 1 − e−0.5


= 5
4 − e−0.5 ≈ 0.6434.
When τ ≥ γ > 1
2 , we have
∂f (τ ,γ )
∂τ = γ − 1
2
(1 + h(γ )) − γ
2 · 0 +
1
2 = γ − 1
2
h(γ ) > 0.
Hence, the minimum is attained when τ = γ , which is
f (γ ,γ ) = 1 − 2γ +γ 2 +
 γ
0
h(x)dx.
Observe that
d f (γ ,γ )
dγ = −2 + 2γ + h(γ ) ≥ −2 + 1 + 1 = 0.
The minimum is attained when γ = 1
2 , which equals f ( 1
2 , 1
2 ) = 5
4 − e−0.5 ≈ 0.6434.
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.   
Online Vertex-Weighted Bipartite Matching: Beating 1 − 1
e with Random Arrivals 38:11
4 IMPROVING THE COMPETITIVE RATIO
Observe that in Lemma 3.2, we relax the total gain of αu + αv into two parts:
(1) when yu ≥ τ and yv ≥ γ , αu + αv = wv ;
(2) for other ranks yu,yv , we lower bound αu and αv by wv · д(yu,γ ) and wv · д(yv , τ ),
respectively.
For the second part, the inequalities used in the proof of Lemmas 3.4 and 3.5 are tight only if β, θ
are two step functions (refer to Figure 1). On the other hand, given these β, θ, when yu ≤ τ and
yv ≤ γ , we actually have αu + αv = wv , which is strictly larger than our estimate wv · (д(yu,γ ) +
д(yv , τ )).
With this observation, it is natural to expect an improved bound if we can retrieve this part
of gain (even partially). In this section, we prove an improved competitive ratio 0.6534, using a
refined lower bound for 1
wv · E[αu + αv ] (compared to Lemma 3.2) as follows.
Lemma 4.1 (Improved Bound). For any pair of neighbors u ∈ U and v ∈ V , we have
1
wv
· E[αu + αv ] ≥ min
0≤γ,τ ≤1

(1 − τ )(1 −γ ) + (1 − τ )
 γ
0
д(x, τ )dx
+
 τ
0
min
θ ≤γ

д(x, θ ) +
 θ
0
д(y, x)dy +
 γ
θ
д(y, τ )dy
dx
.
Proof. Let γ and τ be defined as before, i.e., γ = β (1) and τ = min{x : θ (x) = 1}.
We divide 1
wv · E[αu + αv ] into three parts, namely (1) whenyu > τ and yv > γ ; (2) whenyu > τ
and yv < γ ; and (3) when yu < τ :
1
wv
· E[αu + αv ] = 1
wv
· E[(αu + αv ) · 1(yu > τ ,yv > γ )]
+
1
wv
· E[(αu + αv ) · 1(yu > τ ,yv < γ )]
+
1
wv
· E[(αu + αv ) · 1(yu < τ )].
As shown in Lemma 3.3, the first term is at least (1 − τ ) · (1 −γ ), as we have αu + αv = wv for
all yu > τ and yv > γ . Then, we consider the second term, the expected gain of αu + αv when
yv < γ and yu > τ . For any yv < γ , as we have shown in Lemma 3.4, αv ≥ wv · д(yv , β−1 (yv )) for
all yu > τ . Moreover, when yu < β−1 (yv ), we have αu + αv = wv . Hence, the second term can be
lower bounded by
 γ
0

(1 − τ ) · д(yv , β−1 (yv )) + max{0, β−1 (yv ) − τ } · 
1 − д(yv , β−1 (yv )) dyv .
Now, we consider the last term and fix a yu < τ .
As we have shown in Lemma 3.5, for all yv ∈ [0, 1], αu ≥ wv · д(yu, θ (yu )).
Consider the case when θ (yu ) > γ , then for yv ∈ (0,γ ), αv ≥ wv · д(yv ,yu ); for yv ∈ (γ , θ (yu )),
αu + αv = wv . Thus, the expected gain of αu + αv (taken over the randomness of yv ) can be lower
bounded by
wv ·

д(yu, θ (yu )) +
 γ
0
д(yv ,yu )dyv + (θ (yu ) −γ ) · (1 − д(yu, θ (yu )))
.
As we have shown in Lemma 3.5, the partial derivative with respect to θ (yu ) is non-negative;
thus, for the purpose of lower bounding 1
wv · E[αu + αv ], we can assume that θ (yu ) ≤ γ for all
yu < τ .
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.
38:12 Z. Huang et al.
Given that θ (yu ) ≤ γ , we have αv ≥ wv · д(yv ,yu ) when yv ∈ (0, θ (yu )); and αv ≥ wv ·
д(yv , β−1 (yv )) when yv ∈ (θ (yu ),γ ).
Hence, the third term can be lower bounded by
 τ
0


д(yu, θ (yu )) +
 θ (yu )
0
д(yv ,yu )dyv +
 γ
θ (yu )
д(yv , β−1 (yv ))dyv 
	
dyu .
Putting the three lower bounds together and taking the partial derivative with respect to
β−1 (yv ), for those β−1 (yv ) > τ , we have a non-negative derivative as follows:
∂д(yv , β−1 (yv ))
∂β−1 (yv ) + 1 − д(yv , β−1 (yv )) − (β−1 (yv ) − τ ) ·
∂д(yv , β−1 (yv ))
∂β−1 (yv ) ≥ 0.
Thus, for lower bounding 1
wv · E[αu + αv ], we assume β−1 (yv ) ≤ τ for all yv < γ . Hence,
1
wv
· E[αu + αv ] ≥ min
0≤γ,τ ≤1

(1 − τ )(1 −γ ) + (1 − τ )
 γ
0
д(yv , τ )dyv
+
 τ
0


д(yu, θ (yu )) +
 θ (yu )
0
д(yv ,yu )dyv +
 γ
θ (yu )
д(yv , τ )dyv 
	
dyu
⎫⎪
⎬
⎪
⎭
.
Taking the minimum over θ (yu ) concludes Lemma 4.1.
Observe that for any θ ≤ γ , we have
д(x, θ ) +
 θ
0
д(y, x)dy +
 γ
θ
д(y, τ )dy ≥ д(x,γ ) +
 γ
0
д(y, τ )dy.
Thus, the lower bound given by Lemma 4.1 is not worse than Lemma 3.2.
Theorem 4.2. Fix h(x) = min{1, 1
2 ex }. For any pair of neighbors u and v, and any fixed ranks of
vertices in U ∪V \ {u,v}, we have 1
wv · Eyu,yv [αu + αv ] ≥ 1 − ln 2
2 ≈ 0.6534.
Proof. For h(x) = min{1, 1
2 ex }, we have h	
(x) = h(x) when x < ln(2), and h	
(x) = 0, h(x) = 1
when x > ln(2).
Let f (τ ,γ ) be the expression on the RHS to be minimized in Lemma 4.1. Using д(x,y) = 1
2 (h(x +
1 − h(y))), we have
f (τ ,γ ) = (1 − τ )(1 −γ ) +
1 − τ
2

γ · (1 − h(τ )) +
 γ
0
h(x)dx
+
1
2
 τ
0
min
θ ≤γ

1 +γ + h(x) − h(θ ) − θ · h(x) − (γ − θ ) · h(τ ) +
 γ
0
h(x)dx
dx
= (1 − τ )(1 −γ ) + γ
2 · (1 − h(τ )) + τ
2
+
1
2
 γ
0
h(x)dx +
1
2
 τ
0
min
θ ≤γ
{q(τ , x, θ )}dx, (1)
where q(τ , x, θ ) := h(x) − h(θ ) − θ · h(x) + θ · h(τ ). Observe that
∂q(τ , x, θ )
∂θ = h(τ ) − h(x) − h	
(θ )

< 0 when θ < ln 2,
≥ 0 when θ ≥ ln 2.
Thus, we can lower bound q(τ , x, θ ) by (recall that θ ≤ γ and x < τ )
q(τ , x, min{ln 2,γ }) ≥ h(x) − h(γ ) − ln 2 · h(x) + ln 2 · h(τ ).
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019. 
Online Vertex-Weighted Bipartite Matching: Beating 1 − 1
e with Random Arrivals 38:13
Applying the lower bound on q(τ , x, θ ) in Equation (1), we have
f (τ ,γ ) ≥ (1 − τ )(1 −γ ) + γ
2 · (1 − h(τ )) + τ
2
+
1
2
 γ
0
h(x)dx
+
1
2
 τ
0
(h(x) − h(γ ) − ln 2 · h(x) + ln 2 · h(τ ))dx
= (1 − τ )(1 −γ ) + γ
2
(1 − h(τ )) + τ
2
(1 − h(γ )) +
1
2
 γ
0
h(x)dx
+
ln 2
2 τ · h(τ ) +
1 − ln 2
2
 τ
0
h(x)dx.
In the following, we show that f (τ ,γ ) ≥ 1 − ln 2
2 ≈ 0.6534 for all τ ,γ ∈ [0, 1], which (when combined with Lemma 4.1) yields Theorem 4.2.
First, observe that
∂f (τ ,γ )
∂γ = −(1 − τ ) − τ
2 · h	
(γ ) +
1
2
(1 − h(τ )) +
1
2
h(γ ) = 1
2
((h(γ ) − τ · h	
(γ )) − (1 + h(τ ) − 2τ )),
which is non-decreasing in γ .
Note that 1+h(τ ) − 2τ is strictly decreasing. Let τ ∗ ≈ 0.3574 be the solution for 1+h(τ )−2τ = 1.
Then, we know that for τ ≤ τ ∗,
∂f (τ ,γ )
∂γ
≤
1
2
(h(γ ) − 1) ≤ 0.
Thus,
f (τ ,γ ) ≥ f (τ , 1) = 1
2
(1 − h(τ )) +
ln 2
2 τ · h(τ ) +
1
2
 1
0
h(y)dy +
1 − ln 2
2
 τ
0
h(x)dx.
Recall that for τ < τ ∗, h	
(τ ) = h(τ ) = 1
2eτ . Since
∂f (τ , 1)
∂τ = −1
2
h(τ ) +
ln 2
2
h(τ ) +
ln 2
2 τ · h(τ ) +
1 − ln 2
2
h(τ ) = ln 2
2 τ · h(τ ) ≥ 0,
we have (for τ < τ ∗)
f (τ ,γ ) ≥ f (τ , 1) ≥ f (0, 1) = 1
2
(1 − h(0)) +
1
2
 1
0
h(y)dy = 1 − ln 2
2 ≈ 0.6534.
Now, we consider τ > τ ∗, in which case 1 + h(τ ) − 2τ < 1.
Observe that 1 + h(τ ) − 2τ > 1 − τ for all τ ∈ [0, 1], we have
∂f (τ ,γ )
∂γ

< 0 when γ < ln 2,
> 0 when γ > ln 2.
Hence, for τ > τ ∗, we have
f (τ ,γ ) ≥ f (τ , ln 2) = (1 − τ )(1 − ln 2) +
ln 2
2 · (1 − h(τ )) +
ln 2
2 τ · h(τ ) +
1
4
+
1 − ln 2
2
 τ
0
h(x)dx.
Taking derivative over τ on the RHS, we have
∂f (τ , ln 2)
∂τ = −(1 − ln 2) − ln 2
2 · h	
(τ ) +
ln 2
2 τ · h	
(τ ) +
1
2
h(τ ),
which is 1
2 − (1 − ln 2) > 0 when τ > ln 2. For τ ≤ ln 2, we have
∂f (τ , ln 2)
∂τ

< 0 when τ < τ0,
≥ 0 when τ ≥ τ0,
ACM Transactions on Algorithms, Vol. 15, No. 3, Article 38. Publication date: June 2019.
38:14 Z. Huang et al.
where τ0 ≈ 0.564375 is the solution of ∂f (τ,ln 2)
∂τ = 0. Thus, for τ > τ ∗, we have
f (τ ,γ ) ≥ f (τ , ln 2) ≥ f (τ0, ln 2) = (1 − τ0)(1 − ln 2) +
ln 2
4 · (2 − eτ0 + τ0 · eτ0 ) +
1
4
+
1 − ln 2
4 (eτ0 − 1) ≈ 0.6557 > 1 − ln 2
2 .
Thus, for all τ ,γ ∈ [0, 1], we have f (τ ,γ ) ≥ 1 − ln 2
2 , as claimed.
5 CONCLUSION
In this article, we show that competitive ratios above 1 − 1
e can be obtained under the randomized
primal-dual framework when equipped with a two-dimensional gain sharing function. The key of
the analysis is to lower bound the expected combined gain of every pair of neighbors (u,v), over
the randomness of the rank yv of the off-line vertex, and the arrival time yu of the online vertex.
Referring to Figure 1, it can be shown that the competitive ratio F ≥  1
0 f (yu )dyu , where
f (yu ) := (1 − θ (yu ) + β (yu )) · д(yu, θ (yu )) + θ (yu ) − β (yu )
+
 β (yu )
0
д(yv , β−1 (yv ))dyv +
 1
θ (yu )
д(yv , β−1 (yv ))dyv .
Note that here we assume β−1 (yv ) = 1 for all yv ≥ γ , and д(x, 1) = 0 for all x ∈ [0, 1].
For every fixed д, there exists threshold functions θ and β that minimize the integration. Thus,
the main difficulty is to find a function д such that the integration has a large lower bound for all
functions θ and β (which depend on the input instance). We have shown that there exists a choice
of д such that the minimum is attained when θ and β are step functions, based on which we can
give a lower bound on the competitive ratio.
It is thus an interesting open problem to know how much the competitive ratio can be improved by (fixing an appropriate function д and) giving a tighter lower bound for the integration.
We believe that it is possible to give a lower bound very close to (or even better than) the 0.696
competitive ratio obtained for the unweighted case [23]. 