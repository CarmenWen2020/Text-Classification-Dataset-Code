Shortest paths computation is one of the most fundamental problems in computer science. An important
variant of the problem is when edges can fail, and one needs to compute shortest paths that avoid a (failing)
edge. More formally, given a source node s, a target node t, and an edge e, a replacement path for the triple
(s,t, e) is a shortest s-t path avoiding edge e. Replacement paths computation can be seen either as a static
problem or as a data structure problem. In the static setting, a typical goal is to compute for fixed s and t, for
every possible failed edge e, the length of the best replacement path around e (replacement paths problem).
In the data structure setting, a typical goal is to design a data structure (distance sensitivity oracle) that, after
some preprocessing, quickly answers queries of the form: What is the length of the replacement path for the
triple (s,t, e)?
In this article, we focus on n-node directed graphs with integer edge weights in [−M, M], and present
improved replacement paths algorithms and distance sensitivity oracles based on fast matrix multiplication.
In more detail, we obtain the following main results:
• We describe a replacement paths algorithm with runtime O˜ (Mnω ), where ω < 2.373 is the fast
matrix multiplication exponent. For a comparison, the previous fastest algorithms have runtime
O˜ (Mn1+2ω/3) [Weimann,Yuster—FOCS’10] and, in the unweighted case, O˜ (n2.5) [Roditty, Zwick—
ICALP’05]. Our result shows that, at least for small integer weights, the replacement paths problem
in directed graphs may be easier than the related all-pairs shortest paths problem, as the current best
runtime for the latter is O˜ (M 1
4−ω n2+ 1
4−ω ): this is Ω(n2.5) even if ω = 2. Our algorithm also implies
that the k shortest simple s-t paths can be computed in O˜ (kMnω ) time.
• We consider the single-source generalization of the replacement paths problem, where only the
source s is fixed. We show how to solve this problem in all-pairs shortest paths time, currently
O˜ (M 1
4−ω n2+ 1
4−ω ). Our runtime reduces to O˜ (Mnω ) for positive weights, hence matching our mentioned result for the simpler replacement paths case (that, however, holds also for nonpositive
weights). One of the ingredients that we use is an algorithm to compute the distances from a set
S of source nodes to a set T of target nodes in O˜ (Mnω + |S |·|T | · (Mn) 1
4−ω ) time. This improves on a
result in Yuster,Zwick—FOCS’05.
• We present the first distance sensitivity oracle that achieves simultaneously subcubic preprocessing
time and sublinear query time. More precisely, for a given parameter α ∈ [0, 1], our oracle has preprocessing time O˜ (Mnω+ 1
2 + Mnω+α (4−ω)
) and query time O˜ (n1−α ). The previous best oracle for
small integer weights has O˜ (Mnω+1−α ) preprocessing time and (superlinear) O˜ (n1+α ) query time
[Weimann,Yuster-FOCS’10]. From a technical point of view, an interesting and novel aspect of our oracle is that it exploits as a subroutine our single-source replacement paths algorithm. We also present
an oracle with the same preprocessing time as in Weimann,Yuster—FOCS’10 and with smaller query
time O˜ (n1− 1−α 4−ω + n2α ).
CCS Concepts: • Theory of computation → Shortest paths; Data structures design and analysis;
Additional Key Words and Phrases: Replacement paths, distance sensitivity oracles, shortest paths
1 INTRODUCTION
Shortest paths computation is one of the most fundamental problems in computer science. A natural generalization of the shortest paths problem for failure prone graphs is to compute shortest paths avoiding a (failing) edge e, so called replacement paths w.r.t. e. A typical motivation for
replacement paths computation is to quickly recover from edge failures. Replacement paths are
useful also in contexts where one may wish to satisfy other constraints beyond short length [30].
For instance, in biological sequence alignment [11] replacement paths are useful in determining
which pieces of an alignment are most important. The replacement paths problem is also used in
the computation of Vickrey Prices of edges that are owned by selfish agents in a network [25, 33],
and in finding the k shortest simple paths between two nodes [30, 36, 37, 46].
More formally, letG = (V, E) be an n-nodem-edge directed graph, with integer edge weights (or
lengths) w : E → [−M, +M], where M is a positive integer.1 From now on, we will always assume
that the considered graphG contains no negative cycles, so shortest paths are well-defined. If there
are multiple shortest paths between two nodes in a given graph, then we will implicitly consider
a canonical shortest path obtained via some tie-breaking rule. In particular, Ps,t will denote the
(canonical) shortest path from s to t in the input graph. By distG (s,t), we denote the length of the
shortest path from s to t (distance from s to t) in G, and we will use the shortcut dist(s,t) when G
is clear from the context.2 Given two nodes s and t and an edge e, a replacement path Ps,t,e for the
triple (s,t, e) is the shortest path from s to t that avoids edge e, i.e., the shortest s-t path in G \ {e}.
Observe that, if e is not an edge of Ps,t , then we can assume w.l.o.g. that Ps,t,e = Ps,t . Hence, w.l.o.g.,
we will assume from now on that e belongs to Ps,t . For the sake of simplicity, we will next focus on
the computation of the lengths Ds,t,e := distG\ {e }(s,t) of the considered replacement paths Ps,t,e .
However, our approach can be adapted via standard techniques to allow for the computation of
any replacement path Ps,t,e in time linear in its number of edges. Intuitively, we can associate
with each distance Ds,t,e , the predecessor of t along Ps,t,e . This way, we can reconstruct Ps,t,e
proceeding backward node-by-node.
In the literature, there are two main high-level approaches used to compute replacement paths.
In the first approach, one solves the problem statically by precomputing the lengths Ds,t,e of all the
(non-trivial) replacement paths Ps,t,e and storing them in a table. Depending on the restrictions on
s and t, one obtains different variants of the problem. The so-called Replacement Path problem (RP)
1Throughout this article, for integers a ≤ b > 0, [a, b] = {a, a + 1, ..., b } and [b] = {1, 2, ..., b }. 2The weight function associated with the considered graph G will always be clear from the context.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
Faster Replacement Paths and Distance Sensitivity Oracles 15:3
is obtained by fixing both s and t. In this article, we will also consider the Single-Source Replacement
Paths problem (SSRP), where s is fixed and t is arbitrary. SSRP is a natural extension of RP, and
moreover, it turns out to be useful in the design of distance sensitivity oracles.
The second approach to replacement paths is to design a data structure that, after a preprocessing
step, quickly answers queries of the form (s,t, e) by returning Ds,t,e . Such a data structure is called
a Distance Sensitivity Oracle (DSO). As usual, one needs to compromise between the preprocessing
and query time.3 In this article, we will focus only on the all-pairs variant of DSOs (where both s
and t are arbitrary).
1.1 Related Work
1.1.1 Replacement Paths. RP is the best-studied variant of the replacement paths problem. Recall that here both the source s and the target t are fixed. The naive way to solve RP is to remove
each edge e ∈ Ps,t in turn and compute the shortest path in G \ {e} from scratch. This approach
is, however, unnecessarily time-consuming as the shortest paths computations share a lot of information. RP can be solved very efficiently in undirected graphs: Malik et al. [31] gave an O˜ (m)
time algorithm.4 Nardelli et al. [32] used Thorup’s linear time algorithm for single-source shortest
paths [40] to improve the runtime to O(mα (n)) in the word-RAM model of computation, where
α (·) is the inverse Ackermann function.
The best algorithm for the problem in sparse directed graphs with arbitrary edge weights is
by Gotthilf and Lewenstein [23] and runs in O(mn + n2 log logn) time. For dense directed graphs,
nothing much better than cubic time is known.5 Vassilevska Williams and Williams [43] showed
that RP in directed graphs is equivalent under subcubic reductions to the All-Pairs Shortest Paths
problem (APSP), i.e., the problem of computing all the pairwise distances in a given graph. This
essentially means that either both problems admit truly subcubic algorithms, i.e., algorithms with
runtimeO˜ (n3−ε ) for some constantε > 0, or neither of them does. It is worth pointing out that this
apparent cubic time barrier is only due to the wish to compute the replacement distances exactly.
In contrast, Bernstein [3] described an algorithm for RP in directed graphs with positive weights
that for any constant ε > 0, computes (1 + ε)-approximate replacement paths in O˜ ( 1
εm) time. For
weighted planar digraphs, the runtime can be reduced to O˜ (n) as shown by Emek et al. [18].
For unweighted directed graphs, Roditty and Zwick [37] gave a randomized combinatorial
algorithm that computes replacement paths in O˜ (m√
n) time.6 Weimann and Yuster [44] applied fast matrix multiplication techniques to the problem. Their randomized algorithm runs in
O˜ (Mn1+2ω/3) time, where ω < 2.373 [21, 42] is fast square matrix multiplication exponent defined
as the smallest constant such that two n × n matrices can be multiplied using O˜ (nω ) elementary
3Another important aspect is the space complexity; this is not the main focus of this article, and we will only have a brief
discussion of it.
4For notational convenience, throughout this article, we use a modified O˜ notation, which suppresses sub-polynomial
(rather than just poly-logarithmic) factors in Mn. However, the reader should be aware that in several cases the hidden
factor is only poly-logarithmic.
5Subpolynomial improvements are known. The best of these is achieved by combining the reduction from Replacement Paths to APSP presented in this article with the current fastest algorithm for APSP by Williams [45] running in
n3/2Θ(√logn) time, leading to the same running time for RP. 6The Roditty and Zwick algorithm can be extended to support integer edge weights in [1, M] in time O˜ (m√
Mn): The
algorithm processes detours shorter than L in O˜ (mL) time, and this works even in the weighted case. It processes detours longer than L by sampling O (n log n/L) vertices to hit every long detour. In the weighted case, we need to sample
O (nM log n/L) vertices instead. To obtain the new running time, one sets L = √
nM.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
15:4 F. Grandoni and V. V. Williams
operations.7 Using rectangular matrix multiplication algorithms [14, 20, 27], the running time can
be slightly improved to O(Mn2.584). Observe that, if ω = 2, Weimann and Yuster’s running time
would beO(Mn2.334). This would improve on Roditty and Zwick’sO(n2.5) running time (assuming
ω = 2) for dense unweighted graphs.
Somehow surprisingly, SSRP (where only the source s is fixed) has not received much attention in the literature. The only reference, to our knowledge, is a paper by Hershberger et al. [26],
which refers to the problem as edge-replacement shortest paths trees and shows that in the pathcomparison model of computation of Karger et al. [29], SSRP on directed graphs with arbitrary
edge weights requires Ω(mn) comparisons. The aforementioned reduction from APSP to RP by
Reference [43] suggests that there is little hope for a truly subcubic algorithm for SSRP. SSRP is a
natural problem, and moreover, it is a basic primitive for designing DSOs, as we will describe in
this article.
The RP problem is closely related to the problem of finding the second shortest path between
two nodes, and in general to the k shortest paths problem. For directed graphs and nonnegative
edge weights, Eppstein [19] gave an algorithm that returns the k shortest paths from s to t in
time O(m + n logn + k). The paths that Eppstein’s algorithm returns, however, may not be simple.
When the k shortest paths are required to be simple, the fastest-known algorithms for the problem
use algorithms for replacement paths. In more detail, Roditty and Zwick [37] showed that the k
simple shortest paths problem can be reduced to O(k) computations of the second shortest simple
path, and hence to the solution of O(k) instances of RP.
1.1.2 Distance Sensitivity Oracles. DSOs are very well studied in the literature. For arbitrary
non-negative edge weights, there are two trivial approaches. The first does no precomputation and
each query (s,t, e) is answered by computing the shortest path between s and t inG \ {e} explicitly
in O(m + n logn) time using Dijkstra’s algorithm. The second approach takes O˜ (mn2) preprocessing time to compute for every source node s and for every edge e in the shortest paths tree rooted
at s, the new shortest paths tree from s in G \ {e}. The queries are then answered in O(1) time
by looking up the stored solutions. Similar DSOs can be obtained for graphs with possibly negative weights but no negative cycles by adding an extra preprocessing step to replace all negative
weights by non-negative ones, as in Reference [28]. This preprocessing step either takes O˜ (mn)
time using the Bellman-Ford algorithm, or O(m√
n log M) time using Goldberg’s scaling algorithm
[22].
The preprocessing time for DSOs with arbitrary edge weights was improved to O˜ (mn 3
2 ) by
Demetrescu et al. [15], while keeping the query time constant. Bernstein and Karger further improved the preprocessing time to O˜ (
√
mn2) [4] and finally to O˜ (mn) [5]. The latter preprocessing
time matches, up to poly-logarithmic factors, the best-known runtime for APSP in the same setting, and seems therefore very hard to beat.
One can do better, at least in terms of preprocessing time, in the case of integer weights of small
absolute value. Weimann and Yuster [44] presented a DSO with preprocessing time O˜ (Mnω+1−α )
and query time O˜ (n1+α ) for any given parameter α ∈ [0, 1]. In particular, they showed that the
problem can be solved with both subcubic preprocessing time and subquadratic query time.8 An
obvious open problem is whether one can achieve subcubic preprocessing time with linear (or
even sublinear) query time. We answer this question affirmatively.
7The value ω is defined for the arithmetic circuit model where the elementary operations are multiplication and addition
of elements from an underlying field such as the complex numbers.
8Reference [44] also considers the case of f = O (1) (simultaneous) failures; part of our results can be extended in that
direction, but this is out of the scope of this article.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
Faster Replacement Paths and Distance Sensitivity Oracles 15:5
In this case one can also do better in terms of running time if one is allowed for a multiplicative or
additive error in the reported replacement path lengths (in some cases for general weights and/or
for multiple faults) [2, 12, 17]. In some cases, this is a direct consequence of fault-tolerant spanner
results [7–10, 13, 16, 34, 35]. We remark that the requirement of computing the replacement path
lengths exactly makes the problem substantially harder.
1.2 Our Results and Techniques
In this article, we present faster replacement paths algorithms and distance sensitivity oracles in
the case of dense graphs with small integer weights. All our results exploit fast matrix multiplication procedures. In more detail, we achieve the following main results:
1.2.1 Replacement Paths. Improving on References [37, 44], we present a faster algorithm for
the classical RP problem.
Theorem 1.1. There is a randomized algorithm that solves RP in n-node directed graphs with
integer weights in [−M, M] in O˜ (Mnω ) time, with failure probability9 polynomially small in n.
Theorem 1.1 improves on Roditty and Zwick’s O(n2.5) runtime for dense unweighted graphs. It
also improves the range of M for which there is a subcubic algorithm for the problem: In the case
of Weimann and Yuster’s algorithm it is roughly M ≤ n0.416, while for our algorithm it is roughly
M ≤ n0.627. Our result also shows that, at least for small integer weights, the replacement paths
problem in directed graphs might actually be easier than APSP in directed graphs. In more detail,
Zwick’s algorithm [49] solves APSP in O˜ (M 1
4−ω n2+ 1
4−ω ) time.10 Note that this runtime is Ω(n2.5)
even in unweighted directed graphs and assuming ω = 2. Furthermore, improving on O(nω ) for
replacement paths in directed unweighted graphs would likely require radically new techniques,
as the problem is closely related to Boolean matrix multiplication.
As a consequence of the aforementioned reduction from k shortest simple paths to RP in Reference [37], we obtain the following corollary:
Corollary 1.2. There is a randomized algorithm that solves k shortest simple paths in a directed
n-node graph with integer edge weights in [−M, M] in O˜ (kMnω ) time, with failure probability polynomially small in n.
Our result is based on two main ingredients: On the one hand, we exploit a simple (deterministic) reduction from RP to APSP; on the other hand, we design a divide-and-conquer randomized
recursive strategy.
In more detail, as in previous work, we rely on the notion of detour. Let P = Ps,t = {s = v1 →
v2 →···→ vk = t} be the considered shortest path from s to t in G. We next assume that P is
given, as well as all the distances between pairs of nodes along P. This can be easily computed in
O˜ (n2) extra time. For k > j, a detour Δ(vj,vk ) between vj and vk is a shortest path from vj to vk
that does not contain any other node of P. This detour is said to circumvent every edge between
vj and vk in P. It is well known (see, e.g., Reference Bernstein [3], Lemma 2.1) that for any edge
ei := (vi,vi+1) ∈ E(P), the shortest path between s and t in G \ {ei} is exactly the minimum out of
all paths of the form
s → v2 →···→ vj  Δ(vj,vk )  vk →···→ t,
where j ≤ i, i + 1 ≤ k, and  denotes concatenation.
9All the algorithms considered in this article return lengths that are never smaller than the correct ones; the failure probability refers to the event that a strictly larger length is returned.
10The runtime of Zwick’s algorithm can be slightly improved to O (M0.681n2.532) by using fast rectangular matrix multiplication [20].
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
15:6 F. Grandoni and V. V. Williams
Fig. 1. An example of the reduction from RP to APSP in the case of an unweighted graph.
Suppose that we are given for every vj ,vk ∈ P (j < k), the length of the detour Δ(vj ,vk ). We
will describe how to compute the lengths of all the replacement paths in only O(n2 logn) extra time. First, we compute in O(n2) time for every detour Δ(vj ,vk ), the length (vj,vk ) of the
path s →···→ vj  Δ(vj,vk )  vk →···→ t, as follows: As we are given P, we can in linear
time compute the length of each subpath s →···→ vj for all j and the length of each subpath
vk →···→ t for all k. Then (vj,vk ) can be computed in constant time by adding the lengths of
the two paths and that of the detour. After this, we sort the O(n2) triples (vj,vk , (vj,vk )) in nondecreasing order according to (·), in O(n2 logn) time. Furthermore, we store all the pairs (vi,i)
with vi ∈ P in a successor search data structure T (e.g., any balanced binary search tree), with
search key i. Intuitively, each such pair (vi,i) in T corresponds to an edge ei for which we did not
compute the replacement path length yet. We then scan the triples (vj,vk , (vj,vk )) according to
the aforementioned sorted order. For any such triple, we find all the pairs (vi,i) still in T with
j ≤ i ≤ k − 1 (in logarithmic time per pair). For any such pair (vi,i), we record that the shortest
replacement path length11 for ei is (vj,vk ), and then delete (vi,i) from T . Intuitively, all triples
(vj,vk , (vj,vk )) with j ≤ i ≤ k − 1 induce a candidate replacement path of length (vj,vk ) for ei .
By construction, among these options, we consider only the shortest one.
Given the above construction, a reduction to APSP can be easily achieved as follows12: For
every node vi of P, create two copies vin
i and vout
i . Create a new graph G by taking (G \ P) ∪
{vin
i ,vout
i }i ∈[k]. For every edge (vi,u) for u ∈ G \ P, add an edge (vout
i ,u) of the same weight in
G
. Similarly, for every edge (u,vi ) for u ∈ G \ P, add an edge (u,vin
i ) of the same weight in G
.
G is essentially G with the edges of P removed, except that each node of P is split into two.13 See
Figure 1 for an example conversion fromG toG
. Now solve APSP inG
. The shortest path between
vout
i and vin
j is exactly the optimal detour Δ(vi,vj) inG. Thus, with one call to an APSP algorithm,
and O(n2 logn) extra time, we obtain an algorithm for RP. Applying Zwick’s [49] algorithm for
APSP, we can solve the problem in O˜ (M 1
4−ω n2+ 1
4−ω ) (deterministic) time.
We are able to achieve a runtime strictly better than Zwick’s APSP algorithm via a bucketing argument. Let us partition P into q subpaths P1,..., Pq of size roughly n/q, for a carefully
chosen parameter q. Let us focus on the edges of one such subpath P between nodes vx and
vy . We construct an auxiliary graph GP as follows: Let Pl and Pr be the subpaths of P to the
left and right of P
, respectively. Take G and remove all incoming edges to nodes on Pl except
those in P and all outgoing edges from nodes on Pr except those in P. This will ensure that any
path that we compute exiting Pl does not reenter it and any path entering Pr does not reexit it.
Now remove all edges in P and split each node v in W (P
) := V (P
) − {vx ,vy } into two as before: a copy vin with all the remaining incoming edges and a copy vout with all the remaining
11The actual path can also be stored, as usual, with a matrix of successors.
12The possibility of such a reduction was mentioned in Reference [6]; here, we make it explicit and show that it can be
used to further improve the known runtime bounds.
13Splitting the nodes in two is not strictly necessary. Our algorithms would work even without the splitting. However, the
analysis is simpler with the splitting, since this way all computed detours are disjoint from P.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.        
Faster Replacement Paths and Distance Sensitivity Oracles 15:7
Fig. 2. An example of the transformation of a graph G into GP, given P and v2-v5 subpath P 
. Notice that
edges (y,v2) and (v5,y) are removed, and that all nodes in W (P 
) = V (P 
) − {v2,v5} get split into two. The
relevant paths in GP corresponding to detour paths circumventing edges in P are s → v2 → x → vin
3 , s →
v2 → x → y → z → v5 → t, and vout
4 → y → z → v5 → t.
outgoing edges. An example of the construction of GP is given in Figure 2. Let us compute the
shortest path lengths from s and to t in GP in O˜ (n2) time. The shortest replacement path from
s to t avoiding all edges in P is simply the shortest s-t path in GP. Consider now the shortest replacement path that leaves P not later than vx and reenters P at some node vi ∈ W (Pi ).
This path is obtained by appending to the shortest s-vin
i path in GP the subpath of P between vi
and t. Symmetrically, one can compute the shortest replacement path that leaves at some node
vi ∈ W (P
) and reenters P not earlier than vy . The only remaining replacement paths for edges in
P have a detour with both endpoints in W (P
). They can be derived by computing the shortest
paths distances between copies of nodes in W (P
) in GP. As we will discuss later, we are able
to perform the latter computation in time O˜ (Mnω + M 1
4−ω n 3
4−ω |W (P
)|
2− 2
4−ω ). Therefore, the total
computation time is O˜ (qMnω + qM 1
4−ω n 3
4−ω ( n
q )
2− 2
4−ω ). Choosing q = Θ(
(Mn) 1
4−ω /(Mnω−2)), so
n/q = Θ(
Mnω/(Mn) 1
4−ω ), the overall runtime of the algorithm is O˜ (M 1
2 (1+ 1
4−ω )
n1+ 1
2 (ω+ 1
4−ω )
). This
is strictly faster than Zwick’s APSP algorithm.
To achieve the claimed O˜ (Mnω ) runtime, we use recursion in combination with a randomized
contraction step. The idea is to partition P into Z subpaths as in the bucketing algorithm. However, here Z is sub-polynomial (rather than polynomial). For each subpath Pi , we construct a contracted versionG(Pi ) of the input graph, with slightly fewer nodes and slightly larger edge weights.
Graph G(Pi ) preserves the replacement path lengths w.r.t. the edges of Pi , and it can be computed
efficiently.
1.2.2 Single-Source Replacement Paths. We present the first subcubic algorithms for SSRP in
case of small integer weights. Recall that Hershberger et al. [26] gave a cubic lower bound for the
problem in the path-comparison model of Karger et al. [29]. We avoid this lower bound due to our
use of fast matrix multiplication, which falls outside the path-comparison model.
Theorem 1.3. There is a randomized algorithm that solves SSRP in n-node directed graphs with
integer weights in [−M, M] in time O˜ (M 1
4−ω n2+ 1
4−ω ). For positive weights the runtime can be reduced
to O˜ (Mnω ). The failure probability is polynomially small in n.
We remark that the runtime of our SSRP algorithm for integer weights in [−M, M] matches the
runtime of Zwick’s APSP algorithm [49]. We also remark that the runtime of our algorithm for
positive weights matches our own improved result for the simpler RP problem. We suspect that the
case in which the weights can be negative might be intrinsically harder, as the problem seems to
be more tightly related to APSP. Showing that this is the case, or obtaining an O˜ (Mnω ) algorithm
for possibly negative weights as well, is an interesting open problem.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.  
15:8 F. Grandoni and V. V. Williams
We give some intuition about our approach in the following: Let Ts be the shortest paths tree
from source s. Pv,u denotes the path fromv tou inTs , anddist(v,u) its length. For a pair (t, e) ∈ V ×
E, if e does not lie along Ps,t , then Ps,t,e = Ps,t . We call the remaining pairs (t, e) relevant, and focus
on them. The first step in our algorithm is a partition of Ts into a small (subpolynomial) number
of subtrees T 
. Using balanced tree separators, we can guarantee that each T  contains roughly
the same number of nodes (modulo constants). Let P be the path from s to the root of T 
. For any
relevant pair (t, e) there must exist some subtree T  such that t ∈ V (T 
) and either (a) e ∈ E(T 
) or
(b) e ∈ E(P
). This way, we identify a collection of subproblems, where each subproblem is of the
following two forms:
• In a subtree problem, we are given a subtree T  of T, and we want to compute replacement
paths Ps,t,e where both t and e belong to T  (handling (a) above).
• In a subpath problem, we are given a subpath P of T from the source s to a node t
, and a
subtree T  of T rooted at t
, and we want to compute replacement paths Ps,t,e with t in T 
and e in P (handling (b) above).
We solve each subtree problem T  recursively, after a preliminary compression step where we
replace the nodes outside T  with a subpolynomially smaller random subset B of them, adding
auxiliary edges (with subpolynomially larger weights) representing shortest paths between the
sampled nodes.
Handling subpath problems (P
,T 
) is the crux of our approach. The portion of Ps,t,e not in Ps,t
is called a detour and (w.l.o.g.) is a path that starts at some node v of Ps,t (before edge e) and ends at
some other node u of Ps,t (after edge e). Note that possibly v = s and/or u = t. For a given subpath
problem (P
,T 
), we distinguish two types of replacement paths Ps,t,e depending on their detour:
• In jumping paths, detours have both endpoints in P
;
• In departing paths, detours have only the starting node in P
.
We can reduce the computation of jumping paths to an instance of the RP problem that we solve
in O˜ (Mnω ) time with our own RP algorithm.
The computation of departing paths essentially reduces to the computation of their detours. For
positive weights, we are able to compute such detours inO˜ (Mnω ) time. We adapt an idea of Roditty
and Zwick [37] used in their unweighted RP algorithm. Roughly speaking, consider the detour P˜
v,u
of a departing path Ps,t,e , going from some v ∈ V (P
) to some u ∈ V (T 
) − {t
}. Suppose that P˜
v,u
has X nodes and hence length at most MX. Consequently, also the length of the shortest path Pv,u
fromv to u is at most MX, which implies that Pv,u contains at most MX nodes (here, we exploit the
positiveness of the weights). This forces v to be one of the final MX nodes of P (since u  V (P
)).
We exploit the above observation as follows: Let L be a proper integer threshold. We compute all
the distances in G − E(P
) from the final ML nodes of P to V (T 
); this way, we obtain the detours
with X ≤ L. Then, we sample a random set B of O˜ (n/L) nodes so w.h.p. B hits all the detours with
X ≥ L. We compute the shortest paths from V (P
) to B and from B to V (T 
), and then derive the
desired detour lengths by going through all the triples (v,b,u) ∈ V (P
) × B ×V (T 
).
Consider the computation of shortest paths in the two stages of the algorithm. In both cases,
we have to solve an instance of the following S-T shortest paths problem (STSP): Given a directed
edge-weighted graph G = (V, E), and two subsets of nodes S,T ⊆ V , compute all the distances
between pairs (s,t) ∈ S ×T . The best-known algorithm for STSP (for M small enough) is given in
Reference [47] and has runtime O˜ (Mnω + M 1
4−ω n 3
4−ω (|S | |T |)
1− 1
4−ω ). We improve this to:
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019. 
Faster Replacement Paths and Distance Sensitivity Oracles 15:9
Theorem 1.4. There is a randomized algorithm that solves STSP in n-node directed graphs with integer weights in [−M, M] in timeO˜ (Mnω + |S |·|T | · (Mn) 1
4−ω ), with failure probability polynomially
small in n.
Incidentally, Yuster and Zwick mention that with their distance oracle one can compute shortest
paths trees from Θ( ˜ Mnw−2) sources inO˜ (Mnw ) time. We can do the same from Θ( ˜ M1− 1
4−ω nω−1− 1
4−ω )
sources, which is Θ( ˜ √
n) even for M = O(1) and ω = 2, whereas the number of sources Yuster and
Zwick can handle is only Θ( ˜ 1) in that case.
Using our STSP algorithm and choosing L properly, we are able to solve a subpath problem in
time O˜ (Mnω + M 1
2 + 1
2(4−ω) n2+ 1
2(4−ω) ). This is O˜ (Mnω ) for ω big enough (in particular, it holds for the
current best upper bound—namely, 2.373). To obtain a runtime of O˜ (Mnω ) for any value of ω, we
use a scaling trick. We consider a logarithmic subset of intervals [X, 2X) = [X, 2X − 1], X ≥ L, and
search for the detours with a number of nodes in the interval by considering the detours that start
in the last 2MX nodes of P and pass through a sample of O˜ (n/X) nodes. This way, going through
the triples (v,b,u) costs only O˜ (Mn2) rather than O˜ (n3/L).
For arbitrary weights the idea of considering the final MX nodes of P does not work: Here, a
very low weight path might contain many nodes due to negative (or even zero) edge weights. In
this case, we simply solve APSP in G − E(P
) with Zwick’s algorithm (using our STSP algorithm
does not help, since possibly |V (P
)| = Ω(n) = |V (T 
)|). This solves SSRP for integer weights in
[−M, M] in the claimed O˜ (M 1
4−ω n2+ 1
4−ω ) time.
1.2.3 Distance Sensitivity Oracles. In this article, we present the first distance sensitivity oracle
that achieves simultaneously subcubic preprocessing time and sublinear query time.
Theorem 1.5. For any integer 1 ≤ S ≤ n, there is a randomized distance sensitivity oracle for nnode directed graphs with integer weights in [−M, M], with preprocessing time O˜ (Mnω · (S4−ω +
√
n)), query time O˜ ( n
S ), and failure probability polynomially small in n.
In particular, by choosing S = Θ(n 1
2(4−ω) ), one obtains subcubic preprocessing timeO˜ (Mnω+ 1
2 ) <
O(Mn2.873) and sublinear query time O˜ (n1− 1
2(4−ω) ) < O(n0.693). Recall that the oracle by Reference [44] has preprocessing time O˜ (Mnω+1−α ) and query time O˜ (n1+α ), for any given parameter
α ∈ [0, 1]. Our oracle is always better than that in terms of query time, and for α < 1
2 it improves
also on the preprocessing time.
The DSO in Reference [44] distinguishes between hop-short replacement paths, which contain at
most L = Θ(n1−α ) nodes, and the remaining hop-long paths. Hop-short path lengths are computed
in O˜ (n) time (at query time) by considering O˜ (L) (properly chosen) random subgraphs, and precomputing for each such graph the distance oracle in Reference [47] inO˜ (Mnω ) time. For hop-long
replacement paths Ps,t,e , the algorithm exploits a more involved procedure, based on the computation of an s-t shortest path in a proper auxiliary graph, whose construction (at query time) takes
superlinear time O˜ (n2/L).
We are able to reduce the query time for hop-short paths by a careful use of known techniques.
To address hop-long paths, we exploit a completely different approach. Let B be a random sample of
O˜ (n/L) nodes so w.h.p. every hop-long replacement path Ps,t,e contains some node b ∈ B. Observe
that the portion of Ps,t,e from s to b must be the replacement path for the triple (s,b, e). Similarly
for the triple (b,t, e). Suppose, then, that for every b ∈ B, we precomputed the quantities Ds,b,e
and Db,t,e . Then, we can trivially answer the query (s,t, e) by computing Ds,t,e = minb ∈B {Ds,b,e +
Db,t,e }. This takes O˜ (|B|) = O˜ ( n
L ) time, which is sublinear. Note that the computation of Dv,b,e is
equivalent to the computation of Db,v,e after reversing all edge directions.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
15:10 F. Grandoni and V. V. Williams
From the above discussion, we can reduce the problem of designing an improved DSO to the
problem of efficiently solving SSRP for all source nodes s ∈ B. In the case of positive weights,
the claimed result can be obtained directly by exploiting our O˜ (Mnω ) time SSRP algorithm. We
can achieve the same performance of the DSO for positive weights also in the case of arbitrary
weights (despite the fact that we are not able to solve SSRP equally fast in the two cases) by
means of a variant of our SSRP algorithm. Recall that we need to compute hop-long replacement
paths containing at least L nodes, for a proper integer threshold L. Also in this case, we exploit a
scaling trick: For a logarithmically large set of intervals [X, 2X), X ≥ L, we address the problem of
computing replacement paths with a number of nodes in the considered interval. To do this, we
sample O˜ (n/X) random nodes B, and solve SSRP on each b ∈ B, but only considering replacement
paths on at most 2X nodes. The last assumption allows us to reduce the runtime of the SSRP
algorithm, since in each subpath problem (P
,T 
), we need to consider only detours of departing
paths that start from the last 2X nodes of P (otherwise, the corresponding replacement paths
would have > 2X nodes). The runtime of the modified SSRP algorithm turns out to be O˜ (Mnω +
XM 1
4−ω n1+ 1
4−ω ). For increasing X, each execution of the modified SSRP algorithm becomes more
expensive, but this is compensated by the smaller number of executions (i.e., O˜ (n/X)).
Incidentally, we are also able to obtain a variant of the DSO in Reference [44] with the same
preprocessing time, but with an improved query time.
Theorem 1.6. For any integer 1 ≤ L ≤ n, there is a randomized distance sensitivity oracle for nnode directed graphs with integer weights in [−M, M], with preprocessing time O˜ (LMnω ), query time
O˜ (n/L 1
4−ω + (n/L)
2), and failure probability polynomially small in n.
Choosing L = Θ(n1−α ), this gives O˜ (Mnω+1−α ) ≤ O(Mn3.373−α ) preprocessing time and
O˜ (n1− 1−α 4−ω + n2α ) ≤ O˜ (n0.386+0.615α + n2α ) query time. While this DSO does not involve drastic new
techniques on top of the techniques needed for Theorem 1.5, we present it for the sake of completeness, since it implies a strict improvement on Reference [44] also for α > 1
2 .
While we state our results as randomized algorithms, we note that using Zwick’s bridging set
techniques [49] and the modification in Section 8 of Reference [47], our results can be derandomized with no significant loss in the running time.
1.3 Organization
The rest of this article is organized as follows: In Section 2, we introduce some preliminary definitions and results that will be needed in the rest of the article. In Section 3, we present our S-T
shortest paths algorithm. In Sections 4 and 5, we describe our algorithms for RP and SSRP, respectively. Finally, in Section 6, we present our distance sensitivity oracles.
2 PRELIMINARIES
We use standard graph notation. When the base of a logarithm is not specified, we assume it to
be 2. Throughout this article with high probability (w.h.p.) means with probability at least 1 − n−Q
for some constant Q > 0. By adapting the constants in our algorithm, we can make Q arbitrarily
large. As mentioned earlier, we use a modified O˜ notation that supresses no(1) factors.14
2.1 Matrix Multiplication and Shortest Paths
Matrix multiplication is a common tool to solve shortest path problems in the presence of small
integer weights. One of the key ingredients to that aim is the notion of distance product of two
14This notation is particularly useful for algorithms based on matrix multiplication, as the matrix multiplication exponent
ω is defined as an infimum, and the fastest n × n matrix multiplication algorithm really runs in nω+o(1) time anyway.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
Faster Replacement Paths and Distance Sensitivity Oracles 15:11
matrices. The distance product A  B of an a × b matrix A by a b × c matrix B is the a × c matrix C
such that Cij = mink=1,...,b {Aik + Bkj}. Alon, Galil, and Margalit [1], following Yuval [48], show
the following result:
Lemma 2.1. The distance product of an a × b matrix by a b × c matrix, where each entry is in
[−M, M] ∪ {+∞}, can be computed in time O˜ (min{abc, M · abc
(min{a,b,c })3−ω }). In particular, for a =
b = c = n, this runtime is O˜ (min{n3, Mnω }).
Based on the above result, and exploiting a clever random sampling approach, Zwick [49] obtained the currently fastest APSP algorithm for directed graphs with small integer weights (more
details about this algorithm are given later).
Theorem 2.2 [49]. Given a directed n-node graph G with integer weights in [−M, M], one can
solve APSP in G in time O˜ (M 1
4−ω n2+ 1
4−ω ).
This improves and generalizes earlier work by Alon et al. [1]. The runtime of Zwick’s algorithm
can be slightly improved to O(M0.681n2.532) by using fast rectangular matrix multiplication [20,
27]. Similar improvements can be achieved for most of our results, but we omit the straightforward
technical details here. We remark that in undirected graphs APSP can be solved faster—namely, in
O˜ (Mnω ) time [38, 39].
Sometimes, we will need to compute only a restricted subset of shortest paths. To this aim, the
following result in Reference [47] turns out to be useful:
Lemma 2.3 [47]. Given a directed n-node graph G with integer weights in [−M, M], one can compute inO˜ (Mnω ) time an n × n matrix D so the (i, j) entry of the distance product D  D is the distance
between nodes i and j in G. Furthermore, by the properties of D, the length of a shortest s-t path containing at least L nodes can be computed in O˜ (n/L) extra time.
The final claim of the previous lemma is only implicit in Reference [47], but it is crucial for
the design of our improved DSOs. We remark that the above result can also be interpreted as a
Distance Oracle that, after a O˜ (Mnω ) time preprocessing step, answers queries of the form (s,t, L)
by returning the length of the shortest s-t path containing at least L nodes in O˜ (n/L) time (hence,
as a special case, the shortest path length can be derived in O˜ (n) time). The techniques from the
above lemma can also be used to solve the Single-Source Shortest Paths problem (SSSP), asking to
compute the distances from a given source node s to all other vertices (and an associated shortest
path tree Ts ).
Corollary 2.4 [47]. Given a directed n-node graph G with integer weights in [−M, M], one can
solve SSSP in O˜ (Mnω ) time.
2.2 Hitting Hop-long Paths
In our algorithms, we sometimes use a random sampling approach to deal with long paths in a
faster way. One key ingredient in our analysis will be the following lemma, which is inspired by
Reference [44]. We remark that, while the upper bound L in the following lemma is used similarly
in the DSO by Reference [44], the lower bound L/8 is crucial to analyze our improved DSO from
Theorem 1.6.
Lemma 2.5. Given a set P of paths and two parameters 1 ≤ L ≤ n and N > 0, sample 4Nn/L nodes
B uniformly at random.15 With probability at least 1 − |P|ne−N for each P ∈ P there exists B(P) ⊆ B
that partitions P into subpaths of at least min{|V (P)|, L/8} and at most L nodes each.
15We can sample B with replacement.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.  
15:12 F. Grandoni and V. V. Williams
Proof. We show that the probability that the considered event does not hold for a fixed path
P from s to t is at most ne−N ; the full claim follows from the union bound. If P contains at most L
nodes, then the claim is trivially true by choosing B(P) = ∅. Otherwise, let us iteratively remove
the first L/2 nodes of P until the remaining path contains less than L/2 nodes. This partitions P into
at most 2n
L intervals containing L/2 nodes and a last interval that contains between 0 and L/2 − 1
nodes. Let us consider the central subinterval of L/4 nodes of each interval, except possibly the
last one.
Suppose that each central subinterval contains some node from B. In that case, we let B(P)
consist of one arbitrary node of B per subinterval. It is not hard to see that two consecutive nodes in
B(P) ∪ {s,t} in the order induced by P are at hop-distance at least L/8 and at most L. From the union
bound, the probability that there exists one subinterval not hit by B is at most 2n
L (1 − L
4n )
4N n
L ≤
ne−N .
Corollary 2.6. Let N and n be such that N ≥ n ≥ n ≥ 1, and let C > 0 be any constant. Let B
be a random sample of (C + 3)n ln N nodes of V . With probability at least 1 − 1/NC, the nodes of B
touch all detours on at least n/n edges, so the nodes of B partition every detour into subpaths on at
most 2n/n edges each.
Proof. It is sufficient to apply Lemma 2.5 with L = 2n/n and observe that the number of the
considered detours is at most n2.
2.3 Distance Sensitivity Oracles
The following lemma is at the heart of the DSO in Reference [44], and it will be crucial for us as
well.
Lemma 2.7 [44]. For an integer 1 ≤ L ≤ n and a constant C > 0, sample s = L · C logn graphs
{G1,...,Gs }, where eachGi is obtained fromG by independently removing each edge with probability
1/L. ForC large enough, the following two claims hold w.h.p.: (a) For any edge e ∈ G, there are Θ(logn)
graphs Gi not containing e. (b) For any replacement path Ps,t,e on at most L nodes, there is at least
one Gi that does not contain e but contains Ps,t,e .
3 A FASTER STSP ALGORITHM
Recall that in the S-T shortest paths problem (STSP), we are given a directed edge-weighted graph
G = (V, E), and two subsets of nodes S,T ⊆ V . Our goal is to compute all the distances between
pairs (s,t) ∈ S ×T .
Our STSP algorithm builds upon Zwick’s APSP algorithm [49] by combining a new idea with
an approach from Reference [47]. Let us start by sketching how Zwick’s algorithm works. For
a matrix D and V 
,V  ⊆ V , let D[V 
,V ] denote the matrix obtained by considering only the
rows and columns indexed by V  and V , respectively. The algorithm consists of a sequence of
iterations i = 1,..., log3/2 n. At iteration i, one is given a distance matrix D, containing upper
bounds on the distances between nodes. Initially D contains edge weights (+∞ for missing edges).
The algorithm samples a subset Bi of bridge nodes, where each node is sampled independently
with probability pi = min{1, 9 ln n
si }, si = (3/2)
i
. Then one sets,
D ← min{D,roundsi M (D[V, Bi]) roundsi M (D[Bi,V ])},
where the minimum is computed element-wise. Here roundM (·) is a function that takes as input
a matrix and returns the same matrix where the entries of absolute value larger than M are set to
+∞. Zwick shows that for any i and any two nodes u,v, if there is a shortest path fromu to v on at
most (3/2)
i edges, then after iteration i w.h.p. D[u,v] = dist(u,v). By Lemma 2.1, the runtime of
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.   
Faster Replacement Paths and Distance Sensitivity Oracles 15:13
the algorithm up until some given iteration  is O˜ (Mnωs3−ω
 ), and after that iteration is O˜ (n3/s ):
hence, the overall runtime is O˜ (M1/(4−ω)
n2+1/(4−ω)
). At the end of the algorithm, the shortest path
distances are given by D with probability at least 1 − 1/n. It is not hard to show that, by replacing
the factor 9 in the probability pi with 3Q + 6 forQ > 1, the failure probability decreases to n−Q ; we
next consider this variant of the algorithm. By halting the algorithm after  iterations, we obtain
the following corollary that we will need later:
Corollary 3.1. The distances between all pairs of nodes that have shortest paths on at most S
nodes can be computed in time O˜ (MnωS3−ω ), with failure probability polynomially small in n.
We next adapt Zwick’s algorithm to solve STSP, by making the following changes:
(1) Starting from B0 = V , we let Bi be a random subset of Bi−1 so |Bi | = pi · |V |, whereas before
pi = min{1, (9 lnn)/si}.
(2) We update only a portion of the matrix D at each iteration according to the formula
D[S ∪ Bi,T ∪ Bi] ← min{D[S ∪ Bi,T ∪ Bi],
roundsi M (D[S ∪ Bi, Bi]) roundsi M (D[Bi,T ∪ Bi])}.
At the end of the process the submatrix D[S,T ] contains the desired distances. The first change
introduces a dependency between the sets Bi at different iterations, which is crucial for our purposes. This type of dependency was also used by Yuster and Zwick [47] in the construction of their
distance oracle. The second step allows us to save time while computing distances for the relevant
pairs of nodes as in Zwick’s original algorithm. This step is where we improve on the runtime for
STSP obtained by applying the distance oracle of Reference [47] directly.
Reminder of Theorem 1.4. There is a randomized algorithm that solves STSP in n-node directed
graphs with integer weights in [−M, M]in timeO˜ (Mnω + |S |·|T | · (Mn) 1
4−ω ), with failure probability
polynomially small in n.
Proof. The correctness analysis follows along the same line as in References [49] and [47].
Consider next the runtime. Let us assume σ := |S |≤|T | =: τ , the other case being symmetric. We
also letγ ≤ σ be a proper threshold to be fixed later, and βi := |Bi |. At a given iteration i, we need to
compute the distance product of a (σ + βi ) × βi matrix by a βi × (τ + βi ) matrix with entries (other
than +∞) of absolute value at most O˜ (Mn/βi ): this costs the minimum of O˜ ((σ + βi )βi (τ + βi ))
and O˜ ( Mn
β3−ω i
(σ + βi )(τ + βi )) by Lemma 2.1. For βi ≥ σ, this is at most O˜ ( Mn2
β2−ω i
) ≤ O˜ (Mnω ). For
σ > βi ≥ γ , this is at most O˜ ( Mn
β3−ω i
σ τ ) ≤ O˜ ( Mn
γ 3−ω σ τ ). In the remaining case γ > βi the runtime is
O˜ (στβi ) ≤ O˜ (στγ ). Choosing γ = (Mn) 1
4−ω gives the claimed runtime.
We will need the following corollary, which is similar in spirit to Corollary 3.1:
Corollary 3.2. Given an n-node directed graph G with integer edge weights in [−M, M], an integer 1 ≤ Z ≤ n − 1, and a subset W of q nodes with q = O˜ ( n
Z ). In time O˜ (Mnω ) one can compute
upper bounds on the pairwise distances among nodes in W so, with failure probability polynomially
small in n, the distance is computed correctly whenever there exists a shortest path of hop-length at
most Z.
Proof. It is sufficient to truncate the execution of the algorithm from Theorem 1.4 as soon as
si ≥ Z. Modulo poly-logarithmic factors, the running time is
log
3/2 Z )
i=1
Msi

n
si
ω
= Mnω
log
3/2 Z )
i=1

1
si
ω−1
= O(Mnω ).
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.         
15:14 F. Grandoni and V. V. Williams
Fig. 3. Algorithm rp for RP. The input to the problem is (G,s,t). Here L, P, s, t, and distP (·, ·) are considered
as global variables used by Procedure recRP.
4 REPLACEMENT PATHS
In this section, we present our recursive RP algorithm rp running in time O˜ (Mnω ). The main
algorithm is described in Figure 3. In the pseudocode, we assume that each variable corresponding
to a graph also carries the associated edge weights.
The algorithm initially (lines 1–2) computes the shortests-t path Ps,t = P = (s = v1,v2,...,vl =
t), as well as all the distances distP (vi,vj) between pairs of nodes along P with i < j. Then (lines
3–4), it fills in a list L of triples of type (vi,vj ,d), with i < j, where d is the length of some s-t
path avoiding all edges along P between vi and vj . Finally (lines 6–15), the list L is processed as
described in Section 1.2.1 to obtain all the replacement path lengths.
We next focus on the recursive procedure recRP, which is the core of our algorithm. The procedure is described in Figure 4. Let Z be a sub-polynomial function of n to be fixed later. The input to
the procedure is a pair (G˜, P˜). Here G˜ is an edge-weighted multi-digraph with n˜ nodes and largest
absolute weight M˜ containing nodess and t. Furthermore, P˜ is a path in G˜ from s˜ to t˜ that is also a
subpath of P. InitiallyG˜ = G and P˜ = P. As it will be clearer later, by construction there are at most
O(logZ n) parallel edges between each pair of nodes in G˜. As standard, to compute distances in G˜
or in its subgraphs, it is sufficient to keep a minimum length edge for each set of parallel (equally
directed) edges. This does not affect the asymptotic runtime. We assume that parallel edges16 are
labeled, so we are able to identify edges corresponding to the original path P.
The goal of the procedure is to compute all the lengths of replacement paths for edges in E(P˜),
and add a corresponding entry to L. Recall that W (P˜) := V (P˜) \ {s˜,t˜}. We can classify the detours
of such replacement paths in four types according to their starting node v˜ and ending node u˜:
(1) v˜,u˜  W (P˜);
(2) v˜  W (P˜) and u˜ ∈ W (P˜);
(3) v˜ ∈ W (P˜) and u˜  W (P˜);
(4) v˜,u˜ ∈ W (P˜).
The replacement paths of the first three types are handled in lines 1–9. The procedure initially
computes the graphG˜
P˜ as described in Section 1.2.1. Recall that in this graph, we remove the edges
16It is possible to avoid parallel edges, but the algorithm and analysis become more technical.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.   
Faster Replacement Paths and Distance Sensitivity Oracles 15:15
Fig. 4. Procedure recRP. The input is a pair (G˜, P˜). Byn˜ and M˜ , we denote the number of nodes and the largest
absolute weight in G˜, respectively. The starting and ending nodes of P˜ are denoted by s˜ and t˜, respectively.
Here Z is a sub-polynomial function of n, while L, P, s, t, and distP (·, ·) are considered as global variables.
of P˜ and split all nodes vi ∈ W (P˜) into vin
i (with no outgoing edges) and vout
i (with no incoming
edges). The shortest s-t path in G˜
P˜ gives the best replacement path of Type (1). The replacement
paths of Type (2) are handled in lines 4–6. Any such path corresponds to a shortest path from s to
some vin
i , vi ∈ W (P˜), in G˜
P˜ plus the portion of P from vi to t. The replacement paths of Type (3)
are handled symmetrically in lines 7–9. In each case, we add a proper triple (v˜,u˜,d) to L, so the
corresponding replacement path lengths are computed correctly in lines 5–15 of rp.
It remains to consider replacement paths of Type (4), which are handled recursively. The base of
the recursion (lines 10–15) is when n˜ ≤ Z. In this case, we use a brute-force approach: We simply
compute the shortest paths between all pair of nodes in W (P˜) in the graph G˜ − E(P˜), and from
that we derive the corresponding entries of L.
The recursive case (lines 16–27) works as follows: First, we partition P˜ intoZ subpaths P1,..., PZ
of roughly the same length (i.e., of length |E(P˜)|/Z or |E(P˜)|/Z). This is similar to the bucketing
algorithm described in Section 1.2.1; however, here Z is a sub-polynomial (rather than polynomial)
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
15:16 F. Grandoni and V. V. Williams
function of n. For each subpath Pi , we perform the following steps: First, we sample a set Bi of
Θ( n˜
Z · logn) nodes uniformly at random as in Corollary 2.6 (where N, n, and n are replaced by n,
n˜, and 2n˜/Z, respectively). We construct a complete digraph Gi on nodes Vi := V (Pi ) ∪ Bi ∪ {s,t}.
Next, we compute the distances in G˜ − E(Pi ) between pairs of nodes in Vi . We label each edge of
Gi with the corresponding distance if its absolute value is at most ZM˜ , and otherwise, we label it
with +∞. At this point, we add back the edges of E(Pi ). Finally, we apply the procedure recursively
to the pair (Gi, Pi ).
We first consider the runtime of rp.
Lemma 4.1. Procedure rp runs in O˜ (Mnω ) time.
Proof. Line 1 can be executed in time O˜ (Mnω ) using Corollary 2.4. Line 2 can be easily implemented in O(n2) time.
We next consider how many triples are ever added by the algorithm to L. We will show that that
number is O(n2), and hence lines 7–15 of Algorithm rp can be executed in O˜ (n2) time.
The depth of the recursion is O(logZ n) ≤ O(logn), and the number of generated subproblems
in recursion level p is at most Zp . Line 3 of recRP adds at most one entry to L for each subproblem.
Observe that the number of such subproblems is at most O(n). Indeed, consider the recursion tree
(that has one node per subproblem). The leaves of such tree induce a partition of the edges of
the input path, hence there are at most n many such leaves. The internal nodes of the recursion
tree have degree Z ≥ 2, hence their number is upper bounded by the number of leaves. Each node
vin
i is considered at most O(logn) times in line 4, hence line 5 adds at most O(n logn) entries to
L altogether. The same holds for line 8. The total number of pairs (vi,vj) considered in line 13
in recursion level p is O(Zp (n/Zp )
2) = O(n2/Zp ), and summing over all levels, we get that O(n2)
triples are added to L by line 13. Finally, each edge vjvj+1 is considered at most O(logn) times in
line 23, hence the total number of entries added to L in line 24 is O(n logn). The claim follows.
We next analyze the runtime of the calls to recRP. Consider some level p = 0,...,O(logZ n)
of the recursion tree. At this level the algorithm generates at most Zp instances. Consider one
such instance (G˜, P˜). Observe that G˜ and P˜ contain n˜ = Θ(n/Zp · loдpn) and Θ(n/Zp ) nodes, respectively. Furthermore, the largest absolute weight in G˜ is M˜ ≤ MZp . Intuitively, the increase of
the value of M˜ in the subproblems is compensated by a comparable decrease of the number n˜ of
considered nodes.
The total runtime of lines 1–9 is dominated by the execution of line 2, which can be performed in
time O˜ (M˜ n˜
ω )) by Corollary 2.4. Consider next lines 17–27 (excluding the time spent on recursive
calls). The algorithm generates Z subproblems. The time spent on each subproblem (lines 19–27)
is dominated by the distances computation of line 20, which can be performed in time O˜ (M˜ n˜
ω ) by
Corollary 3.2.
Altogether each instance of level p requires time O˜ (ZM˜ n˜
ω ) = O˜ (Zp+1M(
n logp n
Zp )
ω ). Since there
are Zp such instances, the total runtime on level p is
O˜

ZMnω logpω n
Zp(ω−2)

.
We can guarantee that lines 1–9 plus 17–27 at level p in the recursion (hence, altogether) take
timeO˜ (Mnω ) by imposing the following conditions on Z: for ω > 2, set Z = 2 logω/(ω−2) n, and for
ω = 2, choose Z so Z = no(1) and (logn)
logZ n = no(1)
; e.g., Z = 2C
√log n works.
It remains to consider the total time spent on base cases (lines 10–15). There are O(n/Z) base
case instances, each one involving at most Z nodes. We can compute all-pairs distances trivially in
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
Faster Replacement Paths and Distance Sensitivity Oracles 15:17
O(Z3) time in each such instance. Hence, the total runtime of solving these instances is O(nZ2) =
O˜ (n). The claim follows.
We next discuss the correctness of rp.
Lemma 4.2. For every pair (G˜, P˜) on which we execute recRP, the distances between nodes in V (G˜)
are the same in G − E(P˜) and in G˜ − E(P˜) w.h.p.
Proof. Let us assume that the high probability events of Corollaries 2.6 and 3.2 hold whenever
we execute lines 18 and 20. The claim on the probability then follows by the union bound for a
sufficiently large constant C, observing that the total number of recursive calls is polynomially
bounded.
We prove the claim by induction. The base case is when (G˜, P˜) = (G, P), where the claim trivially
holds. Next assume that the claim holds for a given pair (G˜, P˜). It is sufficient to show that it then
holds also for any associated subproblem (Gi, Pi ). By assumption any shortest path in G˜ − E(Pi )
between nodes in {s,t} ∪V (Pi ) is partitioned by Bi into subpaths of at most Z edges (hence, of
absolute value at most ZM˜ ). Therefore, Gi − E(Pi ) preserves the distances of G˜ − E(Pi ) between
nodes Vi = V (Gi ). Thus, by inductive hypothesis, the same holds w.r.t. to G − E(Pi ).
Lemma 4.3. Procedure rp solves RP with polynomially small failure probability in n.
Proof. Let us assume that the high-probability event of Lemma 4.2 holds. Consider a given
edge e ∈ E(P), and the associated replacement path of length d. Let the corresponding detour start
at node v˜ and end at node u˜. By the previous discussion it is sufficient to show that a triple (v˜,u˜,d)
is added to L at some point. Let recRP(G˜, P˜) be the lowest level call of recRP where both v˜ and u˜
belong to P˜. If the considered call is a base case, then a proper triple is added to L in lines 10–15.
Otherwise, the considered detour must correspond to one of the cases (1), (2), and (3) described
before, and a corresponding triple is added to L in lines 1–9.
We are now ready to prove Theorem 1.1.
Reminder of Theorem 1.1. There is a randomized algorithm that solves RP in n-node directed
graphs with integer weights in [−M, M] inO˜ (Mnω ) time, with failure probability polynomially small
in n.
Proof. Consider algorithm rp. Its runtime is O˜ (Mnω ) by Lemma 4.1. This algorithm is correct
with high probability by Lemma 4.3. The claim follows.
5 SINGLE-SOURCE REPLACEMENT PATHS
We show how to solve SSRP, by reducing it to a small (subpolynomial) set of subpath problems
and smaller instances (Section 5.1), and by solving each subpath problem efficiently (Section 5.2).
Recall that in SSRP, we are given as input a graph G with edge weights w(·) and a source node
s. For any t ∈ V (G) and for any edge e along the shortest path Ps,t from s to t, we wish to compute
the length Ds,t,e of the replacement path for the triple (s,t, e).
The shortest path treeTs and the corresponding distances distG (s, ·) can be computed inO(Mnω )
time by Corollary 2.4. If u is a descendant ofv inTs , then one can derive in constant time the values
distG (v,u) = distG (s,u) − distG (s,v). Hence, we will assume that the latter quantities are implicitly given. Our estimates D˜ s,t,e of Ds,t,e are initialized to +∞ and considered as global variables as
well.
By Z, we will denote a suitably chosen subpolynomial function of n, which is a global variable. Similarly to the RP case, for ω > 2, one can set Z = poly log(n) and otherwise (say) Z =
2
√log n log log n.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.    
15:18 F. Grandoni and V. V. Williams
Fig. 5. Recursive algorithm ssrp for SSRP. The input is a pair (G˜,T˜). Here n˜ and M˜ are the number of nodes
and largest absolute weight in G˜, respectively. As usual, the weight function of G˜ is considered implicit. Tree
T˜, rooted at t˜, is a subtree of Ts . Here Z is a subpolynomial function of the original number of nodes n, and
C > 0 is a sufficiently large constant.
5.1 From SSRP to Subpath Problems
We next describe a recursive procedure ssrp to solve SSRP. This procedure takes as input a pair
(G˜,T˜). Here G˜ is an n˜-node multi-digraph G˜ with edge weights w˜ (·) of absolute value at most M˜ ,
containing the source node s of the starting input instance. We will guarantee that there are at most
O(logZ n) parallel edges at any time, hence the cost of handling such parallel edges is negligible
analogously to the RP case. Furthermore, T˜ is a subtree of G˜ and of Ts , rooted at the node t˜ in T˜ at
minimum hop-distance from s in Ts . By P˜, we will denote the shortest path from s to t˜.
The goal of the procedure is to compute Ds,t,e for all (t, e) ∈ V (T˜) × E(T˜).
17 It is then sufficient
to call this procedure on input (G,Ts ).
We remark that by n, we denote the number of nodes in the input graph G: We will guarantee
that the failure probability of ssrp is polynomially small in n (and hence the overall algorithm fails
with polynomially small probability by the union bound).
We consider Algorithm ssrp in Figure 5. Steps 1–4 address the base case, where the problem is
solved with the trivial cubic algorithm for small enough n˜.
Otherwise, in Step 5, we partition T˜ into Z = Θ(Z) subtrees with roughly the same number of
nodes Θ( n˜
Z ) using balanced tree separators. In more detail, recall that for each tree T of n nodes
there exists a node v (balanced tree separator) such that T can be split into two edge-disjoint trees
T  and T  sharing node v only, and each one containing at least n/3 + 1 nodes. By applying this
17Whenever e  E(Ps t ), we implicitly assume that the pair (t, e ) is neglected. This is to slightly simplify the notation.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019. 
Faster Replacement Paths and Distance Sensitivity Oracles 15:19
procedure recursively it is easy to obtain Z ∈ [Z, 3Z] trees each one containing between n˜
3Z and n˜
Z nodes. Each splitting step, and hence the overall procedure, can be performed in O˜ (n˜) time.
Then for each tree Ti the algorithm works as follows: Let Pi be the shortest path in G˜ between
s and the root ti of Ti . For each t ∈ V (Ti ), the relevant pairs (t, e) are of the following two types:
(a) e ∈ E(Pi ) or (b) e ∈ E(Ti ). We define the subproblem of computing Ds,t,e for the pairs (t, e) of
the first and second type a subpath problem and a subtree problem, respectively.
The subpath problem associated withTi is solved by calling in Step 7 procedure subpath, which
is described in next subsection.
The subtree problem associated with Ti is instead addressed recursively in Steps 8–17. In more
detail, we start by building a compressed multi-digraph Gi analogously to the RP case in Steps
8–16. Each such graph contains O˜ ( n˜
Z ) nodes and has edge weights of absolute value at most ZM˜ .
By a similar argument as in the RP case, distances between nodes of Gi are the same in Gi − E(Ti )
and in G˜ − E(Ti ) (hence, in G − E(Ti ) by induction) w.h.p. Then, in Step 17, we call recursively
ssrp on (Gi,Ti ).
Given the above algorithm, we can prove the following lemma:
Lemma 5.1. Given an algorithm that solves a subpath problem in timeO˜ (M˜ αn˜β ) with failure probability at most n−Q , for constants Q > 0 and β ≥ α + 1 ≥ 1, there is an algorithm that solves SSRP in
time O˜ (Mnω + Mα nβ ) with failure probability at most O˜ (n−Q+1).
Proof. By the union bound, the failure probability of the algorithm can be upper-bounded by
summing the failure probabilities of the O˜ (n) subpath problems and the O˜ (n) compression steps.
Analogously to the RP case, the compression step in each subtree problem preserves the correct
replacement path distances with a failure probability that can be made as small as n−Q by choosing
properly the constants in the sampling step and in the computation of shortest paths. The claim
follows.
Now consider the runtime. In each recursive call involving n˜ nodes and absolute weights at most
M˜ , we partition the tree into at most 3Z subtrees containing at most n˜/Z nodes each, and then we
perform a compression step that increases the number of nodes to at most 2Cn˜ logn/Z and the
absolute weights to at most MZ˜ . Thus, at level i ≥ 0 of the recursion tree, the algorithm executes
at most (3Z)
i+1 compression steps and subpath procedures on instances on at most n(2C logn)
i
/Zi
nodes and with weights of absolute value at most MZi
. The number of recursive levels is at most
logZ /(2C log n) n. The (leaf) instances on at most Z nodes are solved using the cubic time algorithm
in overall time O(nZ3) = O˜ (n). We analyze the rest of the runtime.
Consider first the compression steps. Each compression step can be performed in time M˜ n˜
ωд(n)
for some subpolynomial function д(·). Hence, all the compression steps generated by SSRP instances at level i in the recursion tree can be performed in time
(3Z)
i+1 · (MZi
)

n

2C logn
Z
i


ω
д(n)
ω ≥2
≤ Mnω3Z д(n) · (6C logn)
i ω .
Summing over all the levels i of the recursion tree, the runtime of the compression steps is
Mnω3Z д(n)
logZ /

(2C logn) n
i=0
(6C logn)
iω
≤ Mnω3Z д(n) logn · 2
ω log(6C log n) logn
log Z −log(2C logn)
Z=2
√logn log logn
≤ Mnωд(n) · 2O (
√log n log log n)
.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.   
15:20 F. Grandoni and V. V. Williams
Fig. 6. Procedure subpath to solve a subpath problem (G˜,T˜). HereG˜ has n˜ nodes and largest absolute weight
M˜ . By P˜ = (v1,v2,...,vh ), we denote the shortest path in G˜ from s to the root t˜ of T˜, and by Vx the last
x nodes of that path. Here L is a proper integer parameter. In the case of arbitrary weights Steps 3–9 are
replaced by D˜ detour
v,t ← distG˜−E(P˜)
(v,t) for any (v,t) ∈ V (P˜) ×V (T˜), where such distances are computed
with the algorithm from Theorem 2.2.
In the first inequality above, we simply upper bounded the sum with 1 + logZ /(2C log n) n ≤ logn
times the largest term in the sum, which is achieved for the largest value of i.
Similarly, the subpath problems generated by SSRP instances at level i ≥ 0 in the recursion tree
take time at most
(3Z)
i+1 · (MZi
)
α

n

2C logn
Z
i


β
д(n)
β ≥α+1
≤ Mα nβ 3Z д(n) · (6C logn)
i β ,
and hence their total execution time is at most
Mα nβ 3Z д(n) logn · 2
β log(6C log n) logn
log Z −log(2C logn) ≤ Mα nβд(n) · 2O (
√log n log log n)
.
The claim on the runtime follows.
5.2 Solving Subpath Problems
Consider a subpath problem (G˜,T˜), where as usualG˜ has n˜ nodes and largest absolute weight M˜ . By
P˜, we denote the shortest path inG˜ between s and the root t˜ ofT˜. Recall that our goal is to compute
Ds,t,e for all (t, e) ∈ V (T˜) × E(P˜). We will show how to do that in time O˜ (M˜ n˜
ω ). W.l.o.g., we can
assume that M˜ ≤ n˜
3−ω, since, otherwise, we can solve trivially the problem in O˜ (n˜
3) ⊆ O˜ (M˜ n˜
ω )
time.
We use procedure subpath described in Figure 6. As mentioned in the introduction, we distinguish between two types of replacement paths Ps,t,e for the considered pairs (t, e), e = uv. A
jumping path Ps,t,e leaves P˜ at some node (between s and u) and then meets P˜ again at some other
node (between v and t˜). A departing path Ps,t,e leaves P˜ at some node (between s and u) and never
meets P˜ again.
Jumping paths are addressed in Steps 1–2 via a simple reduction to RP; indeed, in this case,
the considered replacement path for the triple (s,t, e) is a replacement path for the triple (s,t˜, e)
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.   
Faster Replacement Paths and Distance Sensitivity Oracles 15:21
followed by a shortest path from t˜ to t. Here, we fix the parameters in the algorithm (without
substantially affecting the runtime), so the failure probability is polynomially small in n (rather
than in n˜). Alternatively, it is sufficient to repeat Steps 1–2 for Θ(logn/ logn˜) many times.
It remains to consider the departing paths. Consider first the case of arbitrary weights. We start
by observing that it is sufficient to compute all the distances distG (v,t) from nodes v in P˜ to nodes
t in T˜ in the graph G := G˜ − E(P˜). Let s = v1,v2 ...vh = t˜ be the sequence of nodes in P˜. For e =
vivi+1 and any t ∈ V (T˜), the shortest departing path for (s,t, e) has length minj ≤i{distG (s,vj) +
distG (vj,t)}. For a fixed t, we can compute these quantities for all e ∈ P˜ via a single scan of the
nodes of P˜ fromv1 to vh (updating the corresponding minimum each time). This takes O(n2) time,
and is performed in Steps 10–13. For the computation of the distances distG (v,t) one can directly
apply Zwick’s APSP algorithm to graph G
.
Lemma 5.2. There is an algorithm that solves a given subpath problem on an n˜-node directed graph
with integer weights in [−M˜ , M˜ ] in timeO˜ (M˜ 1
4−ω n˜
2+ 1
4−ω ), with failure probability polynomially small
in n.
The part of Theorem 1.3 relative to negative weights follows from Lemmas 5.1 and 5.2.
The rest of this section is devoted to the computation of departing paths in the case of positive
weights (Steps 3–9). Let Vx be the final x nodes of P˜. We first consider the detours (of departing
paths), which contain at most L nodes, for a proper parameter L. As we already mentioned in the
introduction, such detours must start at some node inVM L˜ . Indeed, the length of these detours is at
most M˜ (L − 1), and this is also an upper bound on the length of the original shortest paths among
the same endpoints; since weights are strictly positive integers, the latter paths cannot contain
more than M˜ (L − 1) + 1 ≤ ML˜ nodes. Notice that such a claim would not hold in the presence of
negative (or even zero) weights.
We use the STSP algorithm from Theorem 1.4 to compute the distances distG (v,t) fromv ∈ VM L˜
to all t ∈ V (T˜) in G
. For the remaining detours, let us define O(logn˜) intervals [Xi, 2Xi ) with
Xi = 2i
L and 0 ≤ i ≤ log2
n˜
L . For each i, we search for detours with a number of nodes in [Xi, 2Xi )
as follows: We sample a bridge set Bi of n˜
Xi · C logn nodes, so Bi hits any detour on at least Xi
nodes with polynomially (in n) small failure probability according to Corollary 2.6. We compute
the distances in G from any node in V2MX˜ i to any node in Bi and from any node in Bi to any node
in V (Ti ), using our STSP algorithm from Theorem 1.4. For each (v,t) ∈ V2MX˜ i ×V (Ti ), the desired
distance is minb ∈Bi {distG (v,b) + distG (b,t)}.
Lemma 5.3. There is an algorithm that solves a given subpath problem on an n˜-node directed graph
with integer weights in [1, M˜ ] in time O˜ (M˜ n˜
ω ), with failure probability polynomially small in n.
Proof. Consider the above algorithm. The algorithm fails if either the execution of the RP
algorithm fails, or at least one of the executions of the STSP algorithm fails, or for some i the
sample Bi does not hit all the detours on at least Xi nodes. The claim on the failure probability
follows.
The computation of jumping paths and of departing paths from their detours takes O˜ (M˜ n˜
ω )
time. The computation of the detours themselves takes time
O˜ (M˜ n˜
ω + ML˜ n˜ (M˜ n˜) 1
4−ω ) +

i
O˜

M˜ n˜
ω + n˜
Xi
n˜(M˜ n˜) 1
4−ω + MX˜ i
n˜
Xi
n˜

= O˜

M˜ n˜
ω +

ML˜ n˜ + n˜2
L

(M˜ n˜) 1
4−ω

.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019. 
15:22 F. Grandoni and V. V. Williams
Choosing L =

n˜/M˜ gives an overall runtime of O˜ (M˜ n˜
ω +

M˜ n˜
3
2 (M˜ n˜) 1
4−ω ), which is O˜ (M˜ n˜
ω ) for
any value of ω ∈ [2, 3], since by assumption M˜ ≤ n˜
3−ω < n˜
7−2ω.
Combining Lemmas 5.1 and 5.3, one obtains the part of Theorem 1.3 corresponding to positive
weights (note that the compression step in procedure ssrp does not create negative weights if the
input weights are positive).
6 DISTANCE SENSITIVITY ORACLES
In this section, we present our improved DSOs. We start with the DSO from Theorem 1.5. We
consider first the case of positive integer weights (Section 6.1), and later extend the result to allow for non-positive weights (Section 6.2). In Section 6.3, we describe the alternative DSO from
Theorem 1.6. We conclude the section with a brief discussion about the space complexity.
6.1 Positive Weights
The basic strategy is as follows: Given two integer parameters 0 ≤ S ≤ L ≤ n, we distinguish three
types of replacement paths: hop-long and hop-shortreplacement paths contain at least L and at most
S nodes, respectively; the remaining paths are hop-average. We design a distinct oracle for each
kind of path. In particular, the oracle for hop-long paths will crucially exploit our SSRP algorithm.
The preprocessing and query time of the overall oracle is given by the sum of the preprocessing
and query times of these three oracles.
(1) Hop-short paths. We sample S · C logn random graphs G1,...,GS ·C log n as in Lemma 2.7.
We compute all-pairs shortest paths on at most S nodes in each Gi as in Corollary 3.1, in time
O˜ (S3−ωMnω ) per graph, and hence O˜ (S4−ωMnω ) altogether. For a query (s,t, e), it is sufficient to
return the shortest distance from s to t in the graphs Gi not containing e. By Lemma 2.7 w.h.p.
the number of considered graphs (and hence the query time) is O(logn), and at least one of them
contains Ps,t,e if it is hop-short.
(2) Hop-average paths. We sample L · C logn random graphsG1,...,GL·C log n as in Lemma 2.7.
We apply the preprocessing step of the distance oracle from Lemma 2.3 to each sampled graph.
This takes O˜ (LMnω ) preprocessing time and allows us to answer a query (s,t, e), by considering
all the Θ(logn) graphs Gi not containing e and querying the corresponding distance oracles in
O˜ (n/S) time. By Lemmas 2.7 and 2.3, w.h.p. the answer is correct if Ps,t,e is hop-average.
(3) Hop-long paths. We sample n
L · C logn nodes B as in Lemma 2.5 so w.h.p. B hits all the
replacement paths on at least L nodes. We solve SSRP from any source b ∈ B both in the original
graph and in the graph where we reverse all the edges. The preprocessing time is O˜ ( n
L Mnω ). To
answer a query (s,t, e), it is sufficient to consider the concatenation of replacement paths Ps,b,e
and Pb,t,e for any b ∈ B; this takes O˜ (n/L) time and returns the correct answer w.h.p. if Ps,t,e is
hop-long.
Altogether, we obtain an O˜ (Mnω (S4−ω + L + n
L )) preprocessing time and an O˜ ( n
S ) query time.
Setting L = Θ(max{
√
n, S}) concludes the proof of Theorem 1.5 for positive weights.
6.2 Negative Weights
We use the same approach as above for hop-short and hop-average paths (which also works in the
presence of non-positive weights). For hop-long paths, we exploit a variant of our SSRP algorithm,
where we are only interested in computing correctly the replacement paths on at most X nodes.
Observe that, in each subpath problem (P
,T 
), it is sufficient to consider the detours of departing
paths that start in the first X nodes; otherwise, the departing replacement path would be too long.
Using our STSP algorithm, the runtime reduces to O˜ (Mnω + XM 1
4−ω n1+ 1
4−ω ). Note that we can use
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.  
Faster Replacement Paths and Distance Sensitivity Oracles 15:23
the same parameter X also in the recursive calls, since the compression step can only reduce the
number of nodes in each path. By the same argument as in Lemma 5.1, this also upper-bounds the
overall runtime of the algorithm.
Lemma 6.1. For any 0 ≤ X ≤ n, there is an algorithm of runtime O˜ (Mnω + XM 1
4−ω n1+ 1
4−ω ) for
SSRP that computes correctly all the replacement path distances of paths with at most X nodes with
failure probability polynomially small in n.
We exploit the modified SSRP algorithm as follows: We define O(logn) intervals [Xi, 2Xi ) with
L ≤ Xi := 2i
L < 2n. To compute the replacement paths with a number of nodes in [Xi, 2Xi ), we
sample n
Xi · C logn nodes Bi as in Lemma 2.5 so w.h.p. Bi hits all the replacement paths on at
least Xi nodes. We solve SSRP from each source b ∈ Bi in the original graph and in the graph with
reversed edge directions, using the modified SSRP algorithm with parameter X = 2Xi . The preprocessing time is O˜ ( n
Xi
Mnω + n
Xi
Xi M 1
4−ω n1+ 1
4−ω ) ≤ O˜ ( n
L Mnω + M 1
4−ω n2+ 1
4−ω ). For a query (s,t, e), it
is sufficient to consider all the triples (s,b,t) with b ∈ Bi , which takes O˜ ( n
Xi
) ≤ O˜ ( n
L ) time. Since
LMnω + n
L Mnω ≥ Mnω+ 1
2 ≥ M 1
4−ω n2+ 1
4−ω for any ω ∈ [2, 3], the extra term M 1
4−ω n2+ 1
4−ω is irrelevant in the runtime of the preprocessing stage. Hence, we obtain (modulo polylogarithmic factors)
the same preprocessing and query time as in the case of positive weights. This concludes the proof
of Theorem 1.5.
6.3 An Alternative Oracle
We next describe the DSO from Theorem 1.6. We again distinguish between hop-short, hopaverage, and hop-long paths. We handle the first two types of paths as we did before. This takes
O˜ (Mnω (S4−ω + L)) preprocessing time and O˜ ( n
S ) query time.
Consider next hop-long paths. We exploit the O˜ (L) random graphs Gi that we used in the computation of hop-average paths. Recall that we precomputed the distance oracle from Lemma 2.3
for each such graph. We sample n
L · C logn nodes B as in Lemma 2.5, and we compute all the distances of absolute value at most ML between pairs of nodes in B in each Gi . This can be done
in O˜ (Mnω ) time per graph as observed in Reference [44]. We also construct an auxiliary graph
with a dummy node r and edges of cost zero from r to any other node. In this graph, we compute
distances d(v) := dist(r,v) from r in time O˜ (Mnω ).
Given a query (s,t, e), we construct an auxiliary graph on node set B ∪ {s,t}. For any pair b1,b2 ∈
B, we set the weight w
(b1b2) of edge b1b2 to the minimum (precomputed) distance from b1 to b2
in any graph Gi not containing e. Since there are O(logn) such graphs, this step costs O˜ (|B|
2). At
this point, we set the distances from s to B and from B to t. It is here that our algorithm (for hoplong paths) deviates from Reference [44]. In Reference [44] the authors query the distance oracle
for any pair (s,b) and (b,t) with b ∈ B. Since each query takes O˜ (n) time, altogether this costs
O˜ (n|B|) time. We rather observe that, due to the lower bound part of Lemma 2.5, it is sufficient to
consider only the shortest paths from s and to t that contain Ω(L) nodes. This costs only O˜ (n/L)
by the final claim of Lemma 2.3. Therefore, we are able to construct the auxiliary graph in O˜ (n/L ·
|B| + |B|
2) time only. The rest of the query proceeds as in Reference [44]: We add d(u) − d(v) to
each auxiliary weight w
(uv), which makes edge weights non-negative. Then, we use Dijkstra’s
algorithm to compute the shortest s-t path in the auxiliary graph in time O˜ (|B|
2). Summarizing,
the preprocessing time for hop-long paths is O˜ (LMnω ), and the query time is O˜ (n2/L2).
The overall failure probability is polynomially small in n by the usual arguments. Choosing
S = L 1
4−ω completes the proof of Theorem 1.6.
ACM Transactions on Algorithms, Vol. 16, No. 1, Article 15. Publication date: December 2019.
15:24 F. Grandoni and V. V. Williams
6.4 Space Complexity
Consider first the DSO from Theorem 1.6. Note that for hop-average replacement paths it is
sufficient to store, for each relevant distance oracle, only the portion corresponding to paths
containing at least S nodes: this takes O(n2/S) space only. Altogether, the space complexity is
O˜ (n2
S + n2L/S + (n/L)
2L) = O˜ (n2L 1
4−ω ). For the DSO from Theorem 1.5, we need to add to the
above space complexity a term O˜ (n2 |B|) = O˜ (n3/L). For a comparison, the DSO in Reference [44]
has space complexity O˜ (n2L); this is always worse than O˜ (n2L 1
4−ω ) and worse than O˜ (n3/L) for L
large enough.