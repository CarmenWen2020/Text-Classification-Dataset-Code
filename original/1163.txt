Abstract
We consider the classic partial sums problem on the ultra-wide word RAM model of computation. This model extends the classic w-bit word RAM model with special ultrawords of length 
 bits that support standard arithmetic and boolean operation and scattered memory access operations that can access w (non-contiguous) locations in memory. The ultra-wide word RAM model captures (and idealizes) modern vector processor architectures.

Our main result is a new in-place data structure for the partial sum problem that only stores a constant number of ultrawords in addition to the input and supports operations in doubly logarithmic time. This matches the best known time bounds for the problem (among polynomial space data structures) while improving the space from superlinear to a constant number of ultrawords. Our results are based on a simple and elegant in-place word RAM data structure, known as the Fenwick tree. Our main technical contribution is a new efficient parallel ultra-wide word RAM implementation of the Fenwick tree, which is likely of independent interest.

Previous
Keywords
Partial sums

Ultra-wide word RAM

Word-level parallelism

1. Introduction
Let  be an array of integers of length n. The partial sums problem is to maintain a data structure for A under the following operations:

•
: return 
.

•
: set .

The partial sums problem is a classic and well-studied data structure problem [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19]. Partial sums is a natural range query problem with applications in areas such as list indexing and dynamic ranking [10], dynamic arrays [8], [13], and arithmetic coding [4], [20]. From a lower bound perspective, the problem has been central in the development of new techniques for proving lower bounds [21]. In classic models of computation the complexity of the partial sums problem is well-understood with tight logarithmic upper and lower bounds on the operations [9]. Hence, a natural question is if practical models of computation capturing modern hardware advances will allow us the overcome the logarithmic barrier.

One such model is the RAM with byte overlap (RAMBO) model of computation [3], [22], [23]. The RAMBO model extends the standard w-bit word RAM model [24] with special words where individual bits are shared among other words, i.e., changing a bit in a word will also change the bit in the words that share that bit. The precise model depends on the layout of shared bits. This memory architecture is feasible to design in hardware and prototypes have been built [25]. In the RAMBO model Brodnik et al. [26] gave a time-space trade-off for partial sums that uses 
 space and supports operations in  time for a parameter τ, . Here, the n term in the space bound is for the special words with shared bits (organized in a tree layout) and the 
 term is for standard words. Plugging in constant τ, this gives an 
 space and constant time solution, for any . Alternatively, they also show that it is possible to achieve  space and  time.

More recently, Farzan et al. [27] introduced the ultra-wide word RAM (UWRAM) model of computation. The UWRAM model also extends the word RAM model, but with special ultrawords of length 
 bits. The model supports standard arithmetic and boolean operations on ultrawords and scattered memory access operations that access w locations in memory specified by an ultraword in parallel. The UWRAM captures modern vector processor architectures [28], [29], [30], [31]. We present the details of the UWRAM model in Section 2. Farzan et al. [27] showed how to simulate algorithms on RAMBO model on the UWRAM model at the cost of slightly increasing space. Simulating the above solution for partial sums they gave a time-space trade-off for partial sums that uses 
 space and supports operations in  time for a parameter τ, . For constant τ, this is 
 space and constant time, for any . Alternatively, if they simulate the above linear space solution they achieve  space and  time.

1.1. Setup and results
We revisit the partial sums problem on the UWRAM and present a simple new algorithm that significantly improves the space overhead of the previous solutions. Let A be an array of n w-bit integers. An in-place data structure for the partial sums problem is a data structure that modifies the input array A, e.g., by replacing some of the entries in A, to efficiently support operations. In addition to the modified array the data structure is only allowed to store  of ultrawords. This definition extends the standard in-place/implicit data structure concept [32], [33], [34], [35], [36] to the UWRAM, by allowing a constant number of ultrawords to be stored instead of (standard) words. Clearly, without this modification computation on ultrawords is impossible. As in Farzan et al. [27] we distinguish between the restricted UWRAM that supports a minimal set of instructions on ultrawords consisting of addition, subtraction, shifts, and bitwise boolean operations and the multiplication UWRAM that extends the instruction set of the restricted UWRAM with a multiplication operation on ultrawords. We show the following main result:

Theorem 1

Given an array A of n w-bit integers, we can construct in-place partial sums data structures for A that support  and  operations in  time on a restricted UWRAM.

Compared to the previous result, Theorem 1 matches the  time bound of Farzan et al. [27] while improving the space overhead from  to a constant number of ultrawords. This is important in practical applications since modern vector processors have a very limited number of ultrawords available.
Technically, our solution is based on a simple and elegant in-place word RAM data structure, called the Fenwick tree (see Section 3 for a detailed description). The Fenwick tree supports operations in  tree by sequentially traversing an implicit tree structure. We show how to efficiently compute the access pattern on the tree structure in parallel using prefix sum computations on ultrawords. Then, given the locations to access we use scattered memory operations to access them all in parallel. In total, this leads to the exponential improvement of Fenwick trees. The main bottleneck in our algorithm is the prefix sum computation. Interestingly, if we allow multiplication we can compute prefix sums in constant time leading to the following Corollary for the multiplication UWRAM:

Corollary 2

Given an array A of n w-bit integers, we can construct in-place partial sums data structures for A that support  and  operations in constant time on a multiplication UWRAM.

Multiplication (or prefix sum computation) is not an
Image 1
operation (it cannot be implemented by a constant depth, polynomial size circuit) and therefore likely not practical to implement on ultraword. However, Corollary 2 shows that we can achieve significant improvements on the UWRAM with special operations. Since UWRAM capture modern processors, we believe it is worth investigating further, and that our work is a first step in this direction.
1.2. Outline
The paper is organized as follows. In Section 2 and 3 we review the UWRAM model of computation and the Fenwick tree. In Section 4 we present our UWRAM implementation of the Fenwick tree. Finally, in Section 4.4 we discuss extensions of the result and open problems.

2. The ultra-wide word RAM model
The word RAM model of computation [24] consists of an infinite memory of w-bit words and an instruction set of arithmetic, boolean, and memory access instructions such as the ones available in standard programming languages such as C. We assume that we can store a pointer into the input in a single word and hence , where n is the size of the input. The time complexity of a word RAM algorithm is the number of instructions and the space complexity is the number of words used by the algorithm.

The ultra-wide word RAM (UWRAM) model of computation [27] extends the word RAM model with special ultrawords of 
 bits. We distinguish between the restricted UWRAM that supports a minimal set of instructions on ultrawords consisting of addition, subtraction, shifts, and bitwise boolean operations and the multiplication UWRAM that additionally supports multiplication. The time complexity is the number of instructions (on standard words or ultrawords) and the space complexity is the number of (standard) words used by the algorithm. The restricted UWRAM captures modern vector processor architectures [28], [29], [30], [31]. For instance, the Intel AVX-512 vector extension [29] supports similar operations on 512-bit wide words (i.e., a factor of 8 compared to 
).

2.1. Word-level parallelism
Due to their similarities, we can adopt many word-level parallelism techniques from the word RAM to the UWRAM. We briefly review the key primitives and techniques that we will use.

Let X be an ultraword of 
 bits. We often view X as divided into w words of w consecutive bits each. See Fig. 1(a). We number the words in X from right-to-left starting from 0 and use the notation  to denote the j-th word in X. Similarly, the bits of each word  are numbered from right-to-left starting from 0. If only the rightmost  words in X are non-zero, we say that X has length ℓ. For simplicity in the presentation, we reserve the leftmost bit of each word to be a test bit for word-level parallelism operations. One may always remove this assumption at no asymptotic cost, e.g., by using two words in an ultraword to simulate each single word. Some of our operations below require precomputed constants depending on w, which we assume are available (e.g., computed at “compile-time”).

Fig. 1
Download : Download high-res image (62KB)
Download : Download full-size image
Fig. 1. (a) The layout of an ultraword of w2 divided into w words each of w bits. The leftmost bit of each word is reserved to be a test bit. (b) Componentwise addition using addition. (c) Componentwise comparison using subtraction. (d) Copying the test bits to all positions in their word using subtraction. In this example test bits w − 1 and 1 are 1. All other bits are 0.

We now show how to implement common operations on ultrawords that we will use later. Most of these are already available in hardware on modern vector processor architectures. Componentwise arithmetic and bitwise operations are straightforward to implement using standard word-level parallelism techniques from the word RAM. For instance, given ultrawords X and Y, we can compute the componentwise addition, i.e., the ultraword Z such that  for  by adding X and Y (see Fig. 1(b)) and &'ing with the mask 
 to clear any overflow in test bits (we use exponentiation to denote bit repetition, i.e., 
). We can also compare X and Y componentwise by |'ing in the test bits of X, subtracting Y (see Fig. 1(c)), and masking out the test bits by &'ing with 
. The j-th test bit of the result contains a 1 iff . Given X and another ultraword T containing only test bits, we can extract the words in X according to the test bits, i.e., the ultraword E such that  if the j-th test bit of T is 1 and  otherwise. To do so we first copy the test bits to all positions in their word by subtracting  from T (see Fig. 1(d)). Then, we & the result with X. All of the above mentioned operation take constant time on a restricted UWRAM. Given an ultraword X of length ℓ, the prefix sum of X is the ultraword P of length ℓ, such that 
. We assume here that the integers computed in the prefix sum never exceed the maximum size available in a word such that  is always well-defined. We need the following result.

Lemma 3

Given an ultraword X of length ℓ we can compute the prefix sum of X in  time on a restricted UWRAM and in  time on a multiplication UWRAM.

Proof

First consider the restricted UWRAM. We implement a standard parallel prefix-sum algorithm [37] (see also the survey by Blelloch [38]). For simplicity, we assume that ℓ is a power of two. The algorithm consists of two phases that conceptually construct and traverse a perfectly balanced binary tree T of height  whose leaves are the ℓ words of X.

Given an internal node v in T, let 
 and 
 denote the left and right child of v, respectively. The first phase performs a bottom-up traversal of T and computes for each node v an integer . If v is a leaf,  is the corresponding integer in X and if v is an internal node 
. The second phase performs a top-down traversal of T and computes an integer . If v is the root then  and if v is an internal node then 
 and 
. After the second phase the integers at the leaves is the prefix sum shifted by a single element and missing the last element. We shift and add the last element to produce the final prefix sum. Since T is perfectly balanced we can implement each level of a phase in constant time using shifting and addition. The final shift and addition of the last element takes constant time. It follows that the total time is . During the computation we only need to maintain all of the values in a constant number of ultrawords.

Next consider the multiplication instruction set. We can then simply multiply X with the constant 
 and mask out the ℓ rightmost words of the result to produce the prefix sum. See Hagerup [24] for a detailed description of why this is correct. In total this uses  time. □

2.2. Memory access
The UWRAM supports standard memory access operation to read or write a single word or a sequence of w contiguous words. More interestingly, the UWRAM also supports scattered access operations that access w memory locations (not necessarily contiguous) in parallel. Given an ultraword A containing w memory addresses, a scattered read loads the contents of the addresses into an ultraword X, such that  contains the contents of memory location . Given two ultrawords A and X scattered write sets the contents memory location  to be . Scattered memory accesses capture the memory model used by IBM's Cell architecture [31]. Scattered memory access operations were also proposed by Larsen and Pagh [39] in the context of the I/O model of computation.

3. Fenwick trees
Let A be an array of n w-bit integers and assume for simplicity that n is a power of two. The Fenwick tree [4], [20] is an in-place data structure that replaces the array A as follows. If , then leave A unchanged. Otherwise, replace all values at even entries  by the sum . Then, recurse on the subarray . The resulting array F stores a subset of the partial sums of A organized in a tree layout (see Fig. 2).

Fig. 2
Download : Download high-res image (26KB)
Download : Download full-size image
Fig. 2. An array A and the Fenwick tree F. The lines above F indicate the partial sum of A stored at the rightmost endpoint of the line. For instance, F[12]=A[9]+A[10]+A[11]+A[12]=0 + 1 + 3 + 4 = 8.

To answer  query, we compute a sequence of indices in F and add the values in F at these indices together. Let  denote the position of the rightmost bit in an integer x. Define the sum sequence 
 given by 
 and 
, for . The final element 
 is 0. We compute and return 
. Note that the length of the sequence r is the number of 1 bits in x plus 1. For instance, for 
 the sum sequence is 
. Hence, . We access at most  entries in F and hence the total time for  is . Note that we can always recover the original array A using the  operation, since .

To compute , we compute a sequence of indices in F and add Δ to the values in F at each of these indices. Define the update sequence 
 given by 
 and 
, for . The final element 
 is 2n. We set 
. Note that the length of the sequence t is the number of groups of consecutive 1 bits in x plus 1. For instance, for  the update sequence is . Hence,  adds 5 to , , and . Similar to the  operation, the total running time for  is .

4. Partial sums on the ultra-wide word RAM
We now present an efficient implementation of Fenwick trees on the UWRAM model of computation. We only store the Fenwick tree, as the array F described in Section 3 and a constant number of ultraword constants that we use for computation. We first show some basic properties of the sum and update sequences in Section 4.1, before presenting our UWRAM implementation of the operations in Sections 4.2 and 4.3.

4.1. Computing sum and update sequences
To compute the sum and update sequences we cannot directly apply the recursive definitions, since this would need  steps. Instead, we show how to express the sequences as a prefix sum that we can efficiently derive from the input integer i. Then, using Lemma 3 we will show how to compute it in on the UWRAM in the following sections.

Let 
 and 
 be the sum sequence and update sequences, respectively, for i as defined in Section 3. Define the offset sum sequence 
 and offset update sequence 
 for i to be the sequences of differences of the sum and update sequences, respectively, that is, 
, for  and 
, for . By definition, we have that(1)
 
 

We also have that 
 and hence each sum offset is a power of 2 corresponding to the rightmost 1 bit in 
. Thus, 
 corresponds to the rightmost 1 in 
. Adding 
 (i.e., subtracting 
) “clears” the rightmost 1 bit in i. Thus, 
 corresponds to the 1 bit in i immediately to left of the rightmost 1 bit. In general, we have that 
, where b is the position of the j-th rightmost bit in i, for . For instance, for 
 the offset sum sequence is  corresponding to the three 1 bits in the binary representation of i. In the example in Fig. 2 we have that .

Similarly, for the update offsets, we have that 
. Hence, 
 corresponds to rightmost 1 in i. Adding 
 clears the rightmost consecutive group of 1 bits in i and flips the following 0 bit to 1. In general, we have that 
, where b is the position of the j-th rightmost 0 to the left of , for . For instance, for 
 the offset update sequence is .

4.2. Sum
To compute the , the main idea is to first construct the sum sequence in an ultraword, then use a scattered read to retrieve the entries from F in parallel into another ultraword, and finally sum the entries of this ultraword to compute the final result. We do this in 3 steps as follows. See Fig. 3 for an example of the computed ultrawords during the algorithm.

Fig. 3
Download : Download high-res image (27KB)
Download : Download full-size image
Fig. 3. Computing the sum sequence for i = 13 = (1011)2. Words with 0 are left blank. I contains duplicates of i. M is a precomputed mask. O is the bitwise & of I and M. P is the prefix sum of the non-zero words in O. P′ is P shifted left by one word. S is the sum sequence obtained by componentwise subtraction of P′ from I.

Step 1: compute offsets  Compute the ultraword O such that 
 if 
 is a value in the offset sum sequence of i and 0 otherwise, i.e., the non-zero entries of O form the offset sum sequence for i. To do so we first construct the ultraword I consisting of  duplicates of i, i.e.,  for . We then compute the bitwise & of I and a mask M, such that 
 for , i.e., bit j of  and the other bits of  are 0. By the discussion in Section 4.1 the resulting ultraword is O.

On the multiplication UWRAM we can construct I in constant time by multiplying i with 
. On the restricted UWRAM we can construct I in  time by repeatedly doubling using shifts and bitwise |. The rest of the computation takes constant time in both models.

Step 2: compute sum sequence  Compute an ultraword S of length  whose non-zero entries is the sum sequence 
. To do so we first compute the prefix sum P of the non-zero words of O, i.e., we compute the prefix sum of O and then extract the words corresponding to non-zero words in O (for the extraction we compare O and the ultraword containing only 0s. We then use the test bits of the resulting ultraword to extract the non-zero words as described in Section 2.1). Then we shift P by 1 word to the left to produce an ultraword 
 and finally subtract 
 from I to produce an ultraword S. By (1) the non-zero words in S is the sum sequence for i.

By Lemma 3 the prefix sum computation takes constant time on a multiplication UWRAM and  time on a restricted UWRAM. The remaining steps take constant time.

Step 3: compute sum  Finally, we compute 
. To do so we do a scattered read on S to retrieve 
 into a single ultraword 
 and compute a prefix sum on 
. The sum is then the last word in the result. The scattered read takes constant time. The prefix sum computation takes constant time on a multiplication UWRAM and  time on a restricted UWRAM. We assume here that . If not we may simply temporarily set  during the computation. Also note that it suffices to perform the first phase of the prefix sum computation as discussed in the proof of Lemma 3 since we only need the sum of all of the retrieved entries.

In total, the  operation takes constant time on a multiplication UWRAM and  time on a restricted UWRAM.

4.3. Update
We compute  similar to our algorithm for . We describe how to modify each step of .

In step 1, we modify the computation of the ultraword O such that it now contains the update offsets, that is, 
 if 
 is an update offset for i and 0 otherwise. To do so we now construct a mask M such that  contains a 0 in bit j if j is to the left of  and 1 elsewhere. We then compute a bitwise | of M and I and negate the result. Finally, we set word  of the result to be 
. By the discussion in Section 4.1 the resulting ultraword is O.

In step 2, since O now contains the offsets and not the negative offsets, we change the final subtraction to an addition to produce the update sequence stored in a single ultraword U.

In step 3, we do a scattered read on U to retrieve 
 into a single ultraword 
. We then construct an ultraword D containing Δ on all words corresponding to non-zero words in U. We add D to 
 to produce an ultraword 
. Finally, we do a scattered write on U and 
 to update F.

The changes are all constant time operations and hence we obtain the same complexity as in Section 4.2. Thus, the  operation takes constant time on a multiplication UWRAM and  time on a restricted UWRAM.

In summary, we use  time on a restricted UWRAM and  time on a multiplication UWRAM for both operations. We only store the Fenwick tree in the array F and a constant number of ultrawords. This completes the proof of Theorem 1 and Corollary 2.

4.4. Extensions and open problems
We sometimes also consider the following operations in the context of partial sums:

•
: return .

•
: return the smallest i such that 

As mentioned  is trivial to support since . In contrast, the  operation does not seem to easily lend itself to an efficient parallel implementation on the UWRAM. While it is straightforward to implement in  time by “top-down” traversal of the Fenwick tree our techniques do not appear be useful to speed up this solution on the UWRAM. We leave it as an open problem to investigate the complexity of the  operation on the UWRAM.
Our results leave the precise relation between UWRAM and RAMBO model of computation open. While Farzan et al. [27] show how to simulate RAMBO algorithms with a small overhead in space our results show that a direct approach to designing UWRAM algorithms can produce significantly better results. We wonder what the precise relation between the models is and if stronger simulation results are possible.