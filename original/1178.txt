Abstract
We present an adaptation of the Approximate Bayesian Computation method to estimate the satisfaction probability function of a temporal logic property for Markov Population Models.

In this paper, we tackle the problem of estimating the satisfaction probability function of a temporal logic property w.r.t. a parametric Markovian model of Chemical Reaction Network. We want to assess the probability with which the trajectories generated by a parametric Markov Population Model (MPM) satisfy a logical formula over the whole parameter space. In the first step of the work, we formally define a distance between a trajectory of an MPM and a logical property. If the distance is 0, the trajectory satisfies the property. The larger the distance is, further the trajectory is from satisfying the property. In the second step, we adapt the Approximate Bayesian Computation method using the distance defined in the first step. This adaptation yields a new algorithm, called automaton-ABC, whose output is a density function that directly leads to the estimation of the desired satisfaction probability function. We apply our methodology to several examples and models, and we compare it to state-of-the-art techniques. We show that the sequential version of our algorithm relying on ABC-SMC leads to an efficient exploration of the parameter space with respect to the formula and gives good approximations of the satisfaction probability function at a reduced computational cost.

Keywords
Statistical model checking
Time-bounded reachability
Markov population models
Chemical reaction networks
Bayesian inference
Approximate Bayesian computation
HASL
Linear hybrid automata

1. Introduction
Approximate Bayesian computation (ABC) algorithms have gained popularity over the last decade and are applied for parameter inference in many modelling fields, including systems biology [1], [2], [3], [4] and cancer research [5]. They proved decisive in many cases when classical Bayesian parameter inference methods are challenging to implement. ABC allows approximating the posterior distribution of a model without evaluating the likelihood function in complex models when the computation cost is too high or even impossible. ABC methods are likelihood-free and only rely on model simulations. Simply speaking, only parameters for which simulated summary statistics are close to observed ones, relative to a distance, are preserved while the others are dismissed. These parameters are sampled from the ABC posterior, which approximates the true posterior distribution. The initial idea of our work relies on transposing this concept, initially developed for statistical inference, to temporal logic. We want to adapt the ABC approach so that only parameters which yield simulations that fulfil a given temporal logic formula are retained while others are discarded.

In this paper, we propose a new method for parametric verification of Markov Population Models (MPMs) based on the ABC algorithm. We use hybrid automata to formally measure a score of an MPM trajectory w.r.t. a logical property. In keeping with the ABC vocabulary, this score will be called distance in the remainder of this paper. We use this distance within the ABC framework to estimate the subset of the parameter space in which the logical property can be satisfied thanks to the obtained ABC posterior. We show that the sequential version of ABC is perfectly suited to the use of the distance from a property, leading to an efficient exploration of the parameter space. Our method also allows the estimation of the satisfaction function of a formula, with a remarkable result linking this satisfaction function to the ABC posterior. We demonstrate the effectiveness of our method by its application to several models of Chemical Reaction Networks (CRN).

The work presented in this paper extends that introduced in [6], in many aspects, including 1) the addition of the methodology for estimating the probability satisfaction function of the considered formula from the output of modified ABC algorithms presented in [6]; 2) an extended application part which better highlights the potential of the framework through diverse case studies; 3) the addition of the proof of the soundness of the approach w.r.t. the satisfiability distances the framework relies on.

The paper is organised as follows: Section 2 introduces background material about parametric MPMs, reachability problems, the hybrid automata specification language, and the ABC framework. In Section 3, the notion of satisfiability distance for reachability problems is introduced and plugged, via hybrid automata specifications, within a novel ABC framework which, therefore, allows for identifying the subspace of parameters for which the probability of satisfying the considered reachability property is strictly positive. The novel ABC framework is demonstrated through several experiments in Section 4 and Section 5, while some conclusive remarks and perspectives are discussed in Section 6.

1.1. Related work
In the realm of computational systems biology [7], probabilistic modelling has become increasingly relevant [8], in particular for modelling of Chemical Reaction Network systems that are characterised by low molecular populations such as, for example, genetic regulatory networks [9]. Stochastic simulation algorithms [10] and the corresponding tools, e.g. [11], provide the modellers with practical means for observing the dynamics of a CRN model resulting from a specific parameter instance. On the other hand, stochastic model checking approaches [12] in either their numerical [13] or statistical (i.e. simulation-based) [14], [15] formulation enrich the ability to analyse the dynamics of a CRN instance through the assessment of formally specified properties expressed in temporal logic terms [16]. There exist two formulations of the stochastic model checking problem, the so-called threshold problem, which is concerned with establishing whether the probability that a formula Œ¶ is satisfied by a model instance 
 fulfils a probabilistic constraint ‚àºp (with  and ) as opposed to the estimation problem, which is concerned with estimating the probability that 
 fulfils Œ¶. In recent years, the parametric verification of a probabilistic model (also referred to as parameterised model checking) has received much attention. It is concerned with combining parameter estimation techniques with stochastic model checking, i.e. with studying how the stochastic model checking problem for a property Œ¶ is affected by the parameters Œ∏ upon which a probabilistic model (i.e. an MPM)  depends.

In this respect, a significant number of approaches have been proposed that tackle parametric verification w.r.t. the threshold problem perspective such as [17], in which a bounded approximation of parameter space fulfilling a CSL [18] threshold formula is efficiently determined through an adaptation of MPM uniformisation, or also [19], [20] and, more recently, a novel ABC-based method [21] that is based on observations even solves parameter inference and statistical parameter synthesis in one go.

Our method, on the other hand, tackles the estimation problem in stochastic model checking and is in line with the works of Bortolussi et al. [22], where the so-called smoothed model checking (Smoothed MC) method to estimate the satisfaction probability function of parametric MPM is detailed. Methods belonging to this family do not solve the parameter synthesis problem explicitly but provide good estimates of the satisfaction function that can lead to parameter synthesis, e.g. [23] which is also based on Smoothed MC.

2. Background
In this section, we briefly introduce the background material upon which the remainder of the paper relies. We recall the essential concepts of (i) Markov population models (of chemical reaction networks); (ii) temporal logic and reachability problems; (iii) Hybrid Automata Specification Language; and (iv) ABC methods (whose automaton extension is introduced in Section 3).

2.1. Markov population models
A Markov population model (MPM) is a form of continuous-time Markov chain (CTMC) [24], [25] suitable for modelling of population processes, i.e. systems whose states represent the number of individuals of different species and whose transitions correspond to adding/removal of individuals.

Definition 2.1 Markov Population Model

A Markov population model (MPM) for  population species is a triple 
 such that:

‚Ä¢
 is a countable set of states

‚Ä¢
: is the infinitesimal generator matrix (with 
)

‚Ä¢
 is the initial state probability distribution1 (i.e. 
).

As a consequence of the memoryless property of MPMs, we have that the probability of observing state changes within a given delay is driven by a negative exponential distribution. Therefore, given that the system is in state s at time t, the probability of observing a transition to state 
 within time 
 is 
 where 
 is the exit rate of state s, and 
 is the (time-independent) probability of jumping from s to 
.
Since we are interested in assessing how the probability that an MPM exhibits a given (spatio-temporal) behaviour changes in function of some model's parameters in the remainder, we refer to the notion of parametric MPM (pMPM). In practice, we consider as potential parameters of an MPM the rates of its transitions (i.e. the entries of the infinitesimal generator matrix) yielding the following notion of pMPM.

Parametric MPM. We say an MPM is parametric, denoted 
 if Q depends on a set of parameters Œ∏ belonging to a parameter space Œò.

Chemical reaction networks. In the context of this paper, we consider Chemical Reaction Networks (CRNs) as a formalism for expressing population models. CRNs use chemical equations to capture the dynamics of population models, and are commonly used for modelling of biological systems as well as of epidemic spreading scenarios. Although CRNs are often inherently mapped on their continuous-deterministic semantics (by means of which species quantities are given as concentrations and their dynamics are described by a system of differential equations) here we focus on their discrete-stochastic semantics, by which species quantities are assumed to be given as individual counts (hence the name population) whose dynamics is described by a Markov chain. Therefore the definition of CRN we give below is inherently referred to the discrete-stochastic semantics.

Definition 2.2 Chemical Reaction Network

A (parametric) chemical reaction network (pCRN) with n species and m reaction channels is a 4-tuple 
 defined as follows:

‚Ä¢
 is a set of species

‚Ä¢
 is a set of reaction channels where each 
 () is characterised by an equation with the following form:
 
 
 where 
 are the stoichiometric coefficients of the reaction's reactants, respectively, products. Furthermore 
 is characterised by a pair 
 with

‚Äì
 
 the change vector,

‚Äì
 is the propensity function of 
.

‚Ä¢
 is a d-dimensional vector of parameters affecting the kinetic rate of the reaction channels, with 
.

‚Ä¢
 is the initial state

The dynamics of a CRN is governed by its reactions channels. Assuming the system is in state 
 at time 
 reaction 
 may occur, moving the system to state 
, at time 
, with the delay 
 which is stochastically dependent on both the current state X and the actual value of the parameters Œ∏ (as we will see in the MPM semantics of CRNs the probability distribution of delay 
 is 
)).
Remark

For the sake of simplicity in our framework we assume reactions to obey the mass-action law. That means that the propensity functions are proportional to the product of the non-null stoichiometric coefficients of a reaction's reactants.

Definition 2.3 pMPM of a CRN

A pMPM model 
 of a CRN 
 is defined as follows:

‚Ä¢
 is a countable set of states whose elements are vectors 
 where 
 is the population of the i-th species.

‚Ä¢
: is the infinitesimal generator matrix whose entries are defined as:
 

‚Ä¢
 is defined as 

Notice that by construction, the non-diagonal entries of 
 are given by the sum of the propensities of those reactions whose occurrence leads the CRN to move from state X to state Y. This is in line with the semantics of Markovian events, according to which the distribution of the minimum between a set of concurrent exponentially distributed reactions is itself exponentially distributed with rate given by the sum of the rates of the racing events.
Example 2.1 CRN of infection spreading

As a first example of CRN let us consider the SIR compartmental model [26], which describes the spread of infectious disease among a constant population. The CRN for the SIR is defined as 
 where species S represent the susceptible individuals, I the infected and R the recovered ones. The system's dynamics is given by two reactions channels encoded by chemical equations (1).(1)
 Reaction 
 describes the infection step: a susceptible person meets an infected person and gets infected. Reaction 
 models the recovering step: infected may become immune from the disease. The parameter vector of the model is 
. The CRN of the SIR yields a finite-state MPM with the following kinds of state-dependent transitions. For 
 a state such that 
 two kinds of transitions are possible, i.e. 
 and 
. For states such that 
 only one transition is possible i.e. 
, whereas any state such that 
 is absorbing.

Paths/Trajectories of an MPM. In order to analyse the dynamics of MPMs, we need to refer to the notion of run of an MPM. Intuitively a run is an observation of the model evolution in time. There are two equivalent ways of representing a run either as a path [13], i.e. a sequence of states interleaved by (real-valued) sojourn times, or as a signal [27], i.e., a function that maps a time domain  over a domain  (which is dependent on the set of states of the MPM). In the remainder, we stick with the notion of path for defining the semantics of MITL temporal logic, knowing that such definitions can straightforwardly re-formulated w.r.t. the notion of signals. Given an MPM model 
 whose initial state is 
, we denote 
 the set of all possible paths (or trajectories) of the MPM originating in state 
. A path/trajectory 
 is a (possibly infinite) sequence 
 
, with 
 being the sojourn-time in state 
. For 
 a path,  and 
, we denote 
 the -th state of œÉ, 
 the sojourn-time of œÉ in 
,

 the suffix of œÉ starting at state , 
 the sum of the sojourn times up to and including state k,

Image 1
the state of œÉ at time t and  the t-shifted suffix of œÉ, i.e. the suffix of œÉ that starts at time t (hence requiring the sojourn time of state
Image 1
to be modified accordingly). Formally 
 
 where k is the greatest index such that 
. For example, for 
 
 
 we have 
, , 
, 
 and 
 and 
. Notice that trajectories of an MPM are c√†dl√†g (i.e. step) functions of time. In order to indicate the reaction event that yielded a transition of the path of a CRN model, we sometimes adopt the following notation 
 
 
 
 
 
 
, where 
 indicates that reaction 
 occurred on the i-th transition of the path.
Probability measure of MPM paths. An MPM inherently induces a measure of probability2 on its paths [13]. For 
 a sequence of states of an MPM  such that 
 () and 
 a sequence of non-empty time intervals in 
, we let 
 be the cylinder set consisting of all paths 
 such that 
 () and 
 (). Furthermore we let 
 denote the smallest œÉ algebra containing all sets 
. The probability measure on 
 is then defined by induction w.r.t. k as follows:(2)
  where 
 and 
. In essence 
 states that for a CTMC/MPM  the probability of a path is given by the product of the probability to observe each constituent transitions 
 with a delay that falls in the corresponding binding interval 
. In terms of vocabulary a measurable subset of trajectories of 
 may be referred to as an event of  and its probability is given by 
. In the realm of probabilistic model checking, temporal logic languages provide the modeller with a powerful language for characterising relevant events of an MPM model in terms of formulae (i.e. formal properties). The probability that a temporal logic property œÜ is satisfied by an MPM model  is defined in terms of the probability measure 
 (see Definition 2.4).

Regions of an MPM. In the remainder, we refer to the notion of region associated with an MPM. A region, respectively a time-bounded region, of an n-dimensional MPM is any subset of 
, respectively 
, characterised by a collection of hyper-rectangles of dimension no larger than n. A region is elementary if it is characterised by a single hyper-rectangle. For example for a bi-dimensional MPM with state space 
, 
 is an elementary region, with 
 in  (for 
, with 
 we denote 
 the integer valued interval bounded by 
 and 
) while 
 is unbounded. On the other hand 
 is a non-elementary region (
 is either in  or , 
 is larger than 5), whereas 
 is an elementary time-bounded region (similar to 
, but with the supplemental condition that the time is in ).

2.2. Temporal logic and reachability problems
Temporal logics [28], [29] are formal languages that state properties about the time evolution of a system and define algorithms for automatically verifying whether a system model satisfies a given property. Initially introduced to target the verification of (untimed) non-probabilistic models through either linear-time reasoning [30] or branching-time reasoning [31] they have then been extended to different domains, including that of real-time systems (e.g. [32], [27]) as well as that of probabilistic systems (e.g. [33], [12], [13], [34]). In temporal logic reasoning, the term reachability problem identifies the class of problems consisting in establishing whether a given model reaches (i.e., enters) at some point during its execution a specific region of its state-space usually associated with some state condition œÜ. If the considered model inherently quantifies the elapsing time (like MPMs), then one may also consider time-bounded reachability for which the focus is on establishing whether the target region of the state-space is entered within a time-interval 
. Temporal logic formalisms are equipped with operators for expressing reachability problems. In the context of this paper, we refer to a linear-time temporal logic such as the Metric Interval Temporal Logic (MITL [27]), which allows for stating time-bounded reachability problems for MPM models by combining state-conditions (expressed through inequalities on state variables) with time-bounded temporal operators.

MITL syntax. MITL formulae are terms of the following grammar:
 where ‚ä§ stands for the true formula, Œº denotes an atomic proposition (i.e. an inequality built on top of model's state-variables), ¬¨ and ‚àß are the basic negation and conjunction connectives of propositional logic and 
 is the time-bounded until temporal operator with 
 being the bounding interval.

The truth of an MITL formula is defined w.r.t. to a path œÉ (i.e. a function of time) issued by an MPM model. Formally it is expressed through a so-called satisfaction relationship, denoted ‚ä®. For œÉ a path of the MPM 
,  reads: path œÉ satisfies œÜ.

MITL semantics for temporal formulae. For 
 a path of MPM model 
, 
 a time instant the satisfaction relation ‚ä® of MITL temporal formula is defined as follows:


Download : Download high-res image (34KB)
Download : Download full-size image
Intuitively MITL semantics states that an atomic proposition Œº is satisfied by a path œÉ as of time t if the state condition Œº is satisfied in the state in which œÉ is at time t (

Image 3
). On the other hand, a time-bounded until formula 
 is satisfied by œÉ as of time t if and only if 
 is satisfied by œÉ as of a future time instant 
 which is no further than the time-bounding interval, (i.e. 
) while 
 is sustainedly satisfied beforehand (i.e. 
). As usual, we consider two derivations of the time-bounded until operator: the time-bounded eventuality 
, which stands for ‚Äúat some point within 
 œÜ is satisfied‚Äù and the time-bounded globally 
 which stands for ‚ÄúœÜ is always satisfied within 
‚Äù. In the remainder we assume that a path 
 satisfies an MITL formula œÜ, denoted , if it does so starting from , i.e. . Furthermore, we restrict our focus to the non-nested fragment of MITL, i.e., we consider only formulae such that the operands of a temporal modality are Boolean combinations of atomic propositions Œº. While bearing a definite limitation in terms of expressiveness, this constraint still allows us to treat the most common reachability problems.
MITL formulae and MPM regions. MITL propositional formulae induce untimed regions over the state space of an MPM. For example, for a bi-dimensional MPM the formula 
 induces the region 
 while 
 induces the region 
. By a slight abuse of vocabulary, we say that two formulae 
, 
 are disjoint if their corresponding regions are. In the remainder, we assume regions are characterised by MITL propositional formulae in disjunctive normal form (DNF).

Model checking MPMs. In the context of this paper, we consider the verification of MITL formulae against probabilistic models, and more specifically against MPMs. Generally speaking probabilistic model checking boils down to assessing with what probability a (temporal logic) formula œÜ is satisfied by a probabilistic model 
, which we refer to as the satisfaction probability of œÜ against 
, denoted 
. Intuitively the satisfaction probability 
 is given by the probability measure of the set of paths that satisfy œÜ, as stated in the following definition.

Definition 2.4 Satisfaction probability of an MPM

For 
 an MPM and œÜ an MITL formula, the satisfaction probability of œÜ w.r.t. 
 is defined as:
 where 
 is the probability measure (2) induced by 
 over 
.

 may be assessed either exactly through numerical model checkers [35], [36] (although these are affected by the state-space explosion problem, hence they are limited to models of reasonable size) or being estimated through statistical model checkers [37], [38], [39], [40] (through which the estimates of 
 are obtained by statistical inference based on trajectory samples of arbitrary size).

Parametric model checking of MPMs. If model checking of MPMs is concerned with evaluating what is the probability that a property œÜ is satisfied by a model 
, that corresponds to parameters value 
, in many realistic applications, it is crucial to be able to investigate how the satisfaction probability of œÜ changes with the model's parameters. Indeed, parametric model checking [22] is concerned with evaluating the so-called satisfaction function of a formula œÜ w.r.t. the domain of a model's parameters.

Definition 2.5 Satisfaction probability function

Let 
 be a parametric MPM. The function:
 is called the satisfaction probability function.

The satisfaction probability function expresses how the satisfaction probability of œÜ changes with the parameters.
An automata-based framework for estimating 
. Our goal is to introduce a framework aimed at statistically estimating 
. Since we opt for an (adaptation of the) Approximation Bayesian Computation approach, the estimation of 
 relies on the capability to measure (on-the-fly) how distant a model's trace œÉ (issued by stochastic simulation) is from satisfying an MITL formula œÜ, which we denote  (see Definition 3.1). Although algorithms for assessing  could be, in principle, conceived based on the MITL syntax directly (as it is the case with, e.g. methods for assessing the robustness of a formula against real-valued signals [41], [27]), in our framework we opted to rely on an automata-based formalism: given a (non-nested) reachability formula œÜ, we define a linear hybrid automaton 
 that when synchronised with a trace œÉ is capable of measuring . The benefit of such an approach is that, based on the operational semantics of the Hybrid Automata Specification Language (HASL) [42], we can straightforwardly assess  simply by reproducing the simulation of the synchronised product process 
. Furthermore, by relying on linear hybrid automata, our framework is suitable to be integrated within the COSMOS statistical model checking platform [43] (although the experiments presented in this paper have been obtained through a standalone prototype developed on purpose for this paper).

2.3. Hybrid automata specification language
The distance automata we introduce as part of our framework for estimating 
 rely on the HASL [42] formalism. HASL statistical model checking is based on the idea of employing a linear hybrid automaton (LHA)  as a monitor that filters trajectories issued by a discrete-state stochastic process3 
, while collecting relevant statistics in the process. To this aim, HASL defines a procedure for simulating the (synchronised) product process 
 whose trajectories are determined by two kinds of events: synchronised events, that correspond to the occurrence of a transition in 
 that drags along a synchronising one in , and autonomous events, that happen autonomously in  (i.e. without a change of state in 
) as soon as a certain (e.g. state or time) condition is satisfied in the current state of 
. In the following, we give a short overview of the HASL formalism, referring the reader to [42] for an exhaustive treatment.

2.3.1. Hybrid automata for monitoring of trajectories
An LHA for HASL is an automaton that has access to certain elements of model 
, namely the events and the state-variable of 
. Formally, an LHA is defined as an n-tuple: where: E is a finite alphabet of events (the events of 
 that drive the synchronisation, in the context of this paper E inherently corresponds with 
 the set of reactions of a CRN); L is a finite set of locations; , a location invariant function (Prop being the set of atomic propositions built on top of variables X); Init is a subset of L called the initial locations; Final is a subset of L called the final locations; 
 an n-tuple of data variables; 
 is a function that gives, for each location, the rate at which variable 
 evolves (where the rate for variable 
 is given by an indicator function that depends on the state of the model 
); 
, a set of edges, where for an edge 
, denoted 
 
 in the remainder, we have that 
 is either a subset of events 
 or 
 where ‚ôØ denotes the autonomous event (i.e. an event triggered by the LHA hence not corresponding to any event of E) with  the set of constraints, whose elements are Boolean combinations of inequalities of the form 
 where 
 and c are constants, , whereas  is the set of left-closed constraints, and 
 is an n-tuple of functions characterising how each LHA variable 
 is going to be updated on traversal of the edge.4

Selection of a model's trajectory with an automaton  is achieved through synchronisation of 
 with  (see below), i.e. by letting  synchronise its transitions with the transitions of the trajectory œÉ being sampled. To this aim, an LHA admits two kinds of transitions: synchronising transitions (associated with a subset  of event names, with ALL denoting Œ£), which may be traversed when an event (in E) is observed on œÉ (for example a reaction occurs), and autonomous transitions (denoted by ‚ôØ) which are traversed autonomously (and have priority over synchronised transitions), on given conditions, typically to update relevant statistics or terminate (accept) the analysis of œÉ. Since automata-based formalisms are at least as expressive as temporal logic based on classical temporal modalities (see [44]), in the remainder we denote 
 the HASL automaton equivalent to an MITL formula œÜ (i.e. 
 accepts a trajectory œÉ of an MPM model 
 if and only if ).

Determinism constraints. An LHA for HASL must ensure that the synchronisation of an arbitrary trajectory 
 is finite and unique, hence ruling out possible Zeno-like divergences as well as non-determinism. To this aim an LHA for HASL must comply with the following constraints: c1 (initial determinism): at most one initial location  can have its invariant  verified ( 
, 
); c2 (determinism on events): synchronisation of  w.r.t. an arbitrary event e must be deterministic (
 
, 
, if 
 
 and 
 
 then either 
 or 
.); c3 ( 
 
 ): at most one autonomous transition can ever be enabled (
, if 
 
 and 
 
 then either 
 or 
); c4 ( 
 
 )  cannot contain a loop of autonomous transitions (i.e. for all sequences 
 
 
 
 such that 
, there exists  such that 
). The LHA automata we define as part of our framework (Section 3.2) fulfil the above described constraints.

2.3.2. Synchronised product process 
For the sake of brevity here, we provide only an intuitive description of the product process 
 whose operational semantics is formally defined in [42]. The states of 
 are triples  where s is the current state of the 
, l the current location of the ,  the current valuation of the variables of  and ‚ä• denotes the rejecting state, i.e., the state entered when synchronisation fails, hence when a trajectory is rejected. Notice that a configuration of 
 has the following form 
, where  is the current state of 
, 
 is the current time, and 
 is the schedule of the enabled events of 
. The synchronisation starts from the initial state , where s is a possible initial state of 
 (i.e. 
), l is an initial location of the LHA (i.e. ) and the LHA variables are all set to zero (i.e. ).5 From the initial state, the synchronisation process evolves through transitions where each transition corresponds to traversal of either a synchronised or an autonomous edge of the LHA.6 Furthermore, if an autonomous and a synchronised edge are concurrently enabled, the autonomous transition is taken first. Assuming  is the current state of 
, let us describe how the synchronisation evolves. If in the current location l of the LHA there exists an enabled autonomous edge 
 
, then that edge will be traversed leading to a new state 
 where the state of 
 (i.e. s) is unchanged whereas the new location 
 and the new variables' valuation 
 might differ from l, respectively ŒΩ, as a consequence of the edge traversal. On the other hand, if an event e of 
 (corresponding to transition 
) occurs in state , either an enabled synchronous edge 
 
 (with 
) exists leading to new state 
 of process 
 (from which synchronisation will continue) or the synchronisation halts hence the trace is rejected (formally this is achieved with the system entering the rejecting state ‚ä•).

Example 2.2 LHA for the SIR model

Fig. 1 depicts a two-locations LHA (center) for time-bounded measures (over the time interval , T being a constant) of the SIR model (left). The LHA has locations 
 (with 
 the initial location, 
 the final location), variables 
 with t a clock variable, 
 a real-valued variable (for measuring the average population of infected individuals I) and 
 an integer variable (for counting the number of occurrences of the 
 reaction). While in 
, t changes with flow 1 (i.e. as t is a clock) while 
 flow is given by 
 (i.e. the population of I, hence 
 measures the integral of the population I while in 
). The synchronisation with a path œÉ (i.e. with its I-projection denoted 
) of the SIR model is as follows. At time , the LHA starts in 
 and stays there up to . As soon as , the synchronisation with œÉ ends as the autonomous transition 
 
 becomes enabled hence is fired (by definition, autonomous transitions have priority over synchronised transitions in HASL). As long as  the LHA is in 
 where it synchronises with the occurrences of the SIR reactions: on the occurrence of 
, transition 
 
 (which is synchronised on event set 
) is fired hence increasing the counter 
, whereas on the occurrence of any other reaction (i.e. 
 in this case), transition 
 
 (which is synchronised on event set 
, where ALL stands for the reactions set 
 of the considered CRN) fires without updating any variable. Finally, on ending the synchronisation with œÉ (when ), variable 
 is updated to 
 which corresponds to the average population of I observed over the time interval . Fig. 1 (bottom) includes an example of a path œÉ of the SIR model (
 being the I-projection of œÉ) and the corresponding synchronisation with the LHA (denoted 
) assuming  as time-bound of the synchronisation. Notice that the states of 
 are denoted 
 with 
 the I-projection of the current state of 
, l the current location of  and 
 the values of the variables of .

Fig. 1
Download : Download high-res image (260KB)
Download : Download full-size image
Fig. 1. An LHA (center) for assessing the average of the population of infected individuals (i.e. XI) over time-interval [0,T] for the SIR model (left). Plots (right) show the projection (blue plot) œÉI (w.r.t. species I) of a possible trajectory œÉ issued by the SIR model (blue plot) and the corresponding evolution (red plot) of the LHA variable x1 (that stores the integral of the population of I i.e. 
) resulting when œÉI is synchronised with the LHA. Notice that on ending the measurement (i.e. at time‚ÄØ=‚ÄØT), the LHA set x1‚ÄØ=‚ÄØx1/T, which is indeed the average population of I over [0,T]. (For interpretation of the colours in the figure(s), the reader is referred to the web version of this article.)

2.4. The ABC method
Given a parametric model 
 and an MITL (reachability) formula œÜ, our goal is to estimate the satisfaction probability function 
, i.e. the function that characterises how the probability that œÜ is satisfied by 
 varies w.r.t. the parameter . To this aim, we rely upon the class of Bayesian inference methods known as Approximate Bayesian Computation (ABC). Generally speaking, statistical inference is interested in inferring properties of an underlying probability distribution based on some data observed through an experiment 
. Bayesian inference methods rely on the Bayesian interpretation of probability. Starting from some prior distribution , which expresses an initial belief on the distribution over the parameters domain Œò, Bayesian methods estimate the posterior distribution 
 over Œò based on the observed data 
. Formally, the posterior distribution is defined by:
 
 where  denotes the likelihood function, that is, the function that measures how probable y is to be observed given the model's parameters Œ∏.

An inherent drawback of Bayesian statistics is in that, by definition, the posterior distribution relies on the accessibility to the likelihood function 
, which, particularly for complex models, may be too expensive to compute or even intractable. ABC algorithms have been introduced to tackle this issue, i.e. as a likelihood-free alternative to classical Bayesian methods (we refer to [45], [46] for exhaustive surveys of ABC or rejection-sampling methods).

Simple ABC method. The basic idea behind the ABC method is to obtain an approximate estimate, denoted 
, of the posterior distribution 
, in the form of a number of parameter samples 
 drawn from the ABC posterior distribution. This is achieved through an iterative procedure (Algorithm 1) by which, at each iteration, we start off by drawing a parameter vector 
 from a prior, i.e. 
 , we simulate the model 
, and we accept parameter Œ∏ if the corresponding simulation 
 is ‚Äúclose enough‚Äù to the observations according to a chosen threshold œµ. Notice that in Algorithm 1, 
 represents summary statistics7 computed on the observations 
 and on the simulated trace 
, while 
 is a distance in the space of summary statistics. The accepted parameters 
 together with the corresponding traces 
 give samples 
 drawn from the joint distribution: 
ùüô
 where 
ùüô
 (with ùüô
 denoting the indicator function representing the set of traces whose distance from 
 is within the tolerance œµ). 
 approximates the posterior distribution: the smaller the œµ , the closer the simulations 
 are to the observations 
, so the better the approximation.

Algorithm 1
Download : Download high-res image (49KB)
Download : Download full-size image
Algorithm 1. Simple ABC.

The ABC-SMC method. The chosen value of œµ is crucial for the performance of the simple ABC algorithm: a small œµ is needed to achieve a good approximation. However, this may result in a high rejection rate leading to cumbersome computations. To overcome this issue, the more elaborate algorithm known as ABC Sequential Monte Carlo (ABC-SMC), has been proposed [48]. It is an SMC based approach [49] through which a population of N particles is iteratively sampled with increasing accuracy until the targeted level of accuracy 
 is obtained. At the first iteration, the particles are initialised through the simple ABC algorithm using a large enough 
 to limit the computation cost. 
 possibly equals infinity, which is equivalent to only sampling from the prior distribution. Then, at each step i, , the particles are moved by a transition kernel  (for example, a Gaussian one [49]) until they match the next level, tighter, approximation constraint 
. At iteration M, we finally get N particles that fulfil the desired approximation 
. Some ad-hoc strategies are proposed to find a proper sequence 
 ensuring an efficient convergence towards the posterior distribution.

A basic point about ABC algorithms is that, by definition, they all rely on a notion of distance (between the simulations 
 and observations 
). Based on this characteristic, in Section 3, we introduce an HASL-based adaptation of the ABC scheme to estimate the satisfaction probability function 
. In essence, we plug a distance automaton in the ABC procedure and use it as machinery to assess how far trajectories issued by an MPM model with parameter Œ∏ are from satisfying an MITL formula œÜ. Furthermore, as we will demonstrate, distance automata yield a null distance for any simulation that satisfy the considered formula œÜ. With the HASL-based extension of ABC, we are going to estimate the ABC-posterior using a zero tolerance, i.e. with .

2.5. Kernel density estimation
ABC methods only deliver samples 
 drawn from the ABC posterior distribution. However, our goal is to approximate a continuous (density) function (related to 
). Therefore, we resort to kernel density estimation (KDE) [50], [51].

The goal of KDE is to derive an approximation 
 of an unknown probability density function œÄ given a finite number of samples (
 in our case) of a random variable. The approximation 
 is obtained by the sum of the application of some kernel function K to the samples. A kernel function is a continuous function. Its application to a sample captures the contribution, in terms of probability mass, brought by the sample to the density œÄ to be estimated (i.e. essentially, a kernel is a manner to weight data samples).

Definition 2.6 Kernel function

A function 
 is a kernel function if:

1.

2.

Based on kernel functions, one can define a kernel density estimator [50].

Definition 2.7 Kernel density estimator

Let 
 be N i.i.d. samples from an unknown density œÄ on Œò. The kernel density estimator 
 associated with a kernel function K on  is:
 
 

 is a rescaled function based on kernel K. The scale factor h is called the bandwidth parameter. h is either a scalar, a vector or a matrix, depending on the dimension of Œò and the choice of 
.

With this estimator, each sample contributes to the probability mass over the whole set Œò, with the idea that the further we are from the observation, the lower the probability is.

Several choices for the kernel function and the calibration method of the bandwidth are available [50], [51]. In our work, we select the bandwidth by minimising the Least Squares Cross-Validation criterion, and use Gaussian and Beta kernels [52] with the multivariate estimator of [53].

In Section 3.4 we introduce an adaptation of the KDE approach to our goal, that is, given the samples 
 issued by the Automaton-ABC method, we adapt KDE for approximating the satisfaction probability function 
.

3. Methods
We introduce an ABC-based methodology to approximate the satisfaction function (Definition 2.5) of a time-bounded reachability MITL formula œÜ w.r.t. a parametric MPM model 
. Our methodology consists of four aspects: i) the formalisation of the notion of distance of a model's path from a reachability region (i.e. a time-bounded MPM region related to a time-bounded reachability problem), ii) the introduction of the corresponding HASL specifications to measure such distance, iii) the definition of a novel ABC method adapted to reachability problems, i.e. an ABC algorithm in which the convergence is driven by the distance from a reachability region, and, finally, iv) the derivation of the normalisation constant through which the satisfaction function is obtained from the ABC posterior density.

3.1. Satisfiability distances for reachability problems
ABC algorithms (Algorithm 1 and Algorithm 2) allow one to explore a model's parameter space through an iterative procedure whose convergence is based on a notion of distance (of a model's path from some observations). In order to adapt them to reachability problems, we introduce the notion of satisfiability distance (named simply distance in the remainder) of a model's path œÉ w.r.t. a reachability property œÜ. The distance of œÉ from œÜ should be defined so to comply with the following guidelines: i) it should express how ‚Äúfar‚Äù œÉ is from satisfying œÜ (i.e. the farther œÉ is from satisfying œÜ the largest the distance), ii) it should evaluate to zero whenever  and iii) it should favour the convergence of the ABC algorithm. We point out that the step-function nature of the paths of MPMs8 induces some peculiarities on the characterisation of such a distance, particularly w.r.t. the convergence of the ABC scheme (see details below). Furthermore, we stress that the notion of satisfiability distance we need to introduce is strictly related to that of time-bounded satisfiability regions (Section 2.1), i.e. the part of the space-time domain the satisfiability of the considered formula depends upon.

Algorithm 2
Download : Download high-res image (89KB)
Download : Download full-size image
Algorithm 2. ABC Sequential Monte Carlo.

Based on MITL formulae, we distinguish three kinds of reachability problems: eventual reachability problems (
) are concerned with paths entering a region Œº within a given time interval 
, global reachability problems (
) are concerned with paths never leaving a region Œº within a time interval I, and conditional reachability problems (
) are concerned with paths entering a region 
 within a time interval I and without ever leaving a region 
 beforehand. 
 and 
 formulae induce a simple time-bounded satisfiability region which we denote 
 in the remainder, i.e. 
, where 
 is the set of states where Œº is satisfied, whereas 
 formulae induce a compound satisfiability region given by 
.

Based on the notion of satisfiability region associated with a propositional formula Œº, we introduce the notion of satisfiability distance of a path from a satisfiability region. Such a satisfiability region is associated with different types of temporal formulae built on top of Œº.

Definition 3.1 Satisfiability distance

Given a path 
 of a n-dimensional MPM 
 with state space 
, a closed time-bounding interval 
, an elementary propositional formula Œº, we define the distance  from the satisfiability region for the following kinds of temporal formulae built on top of Œº:

1) 
(3) where

Image 5
is the time instant of the last jump occurred on œÉ before 
‚Åé
 and 
 
 denotes the Euclidean distance of a point 
 from the closest point of a time-bounded region 
.
For non-elementary propositional formulae 
, we define the distance:
 
 where 
 are elementary formulae.

2) 
(4) where 
 
 denotes the Euclidean distance of a point  from the closest state of a state space subset 
. 
 is the integral of the Euclidean distance from 
 of any point of œÉ that occurs within 
.

Similarly, for non-elementary propositional formulae, we define the distance
 
 where 
 are elementary formulae.

3) 
(5)
 where

Image 7
is the earliest time corresponding to the closest point between œÉ and region 
.
Remark 3.1 Null distance

In agreement with the semantics of the temporal modalities, the distance (3) of an MPM path œÉ from a 
, formula is 0 if and only if œÉ has at least one point traversing region 
 (e.g. Fig. 2a), while the distance (4) from a 
 formula is 0 if and only if within 
 all points

Image 1
fall in 
 (Fig. 2b), and finally the distance (5) from a 
 formula is 0 if and only if there exists 
 such that
Image 8
is in 
 while is consistently in 
 beforehand (Fig. 2c).
Fig. 2
Download : Download high-res image (170KB)
Download : Download full-size image
Fig. 2. Examples of paths with zero-distance (left) and positive distance (right) from an F, a G and a U region (positive distances are depicted in red).

Remark 3.2 Positive distance

Conversely, distance (3) of œÉ from 
 yields a positive value, given by minimal Euclidian distance between œÉ and 
, whenever œÉ contains jumps in 
 (Fig. 2d), whereas distance (4) of œÉ from 
 yields a positive value, corresponding with the volume of the hyperrectangle delimited by the segments of œÉ that (within 
) lie outside 
 (Fig. 2e). Finally, for an Until formula 
, we observe that distance (5) bears 3 components: 
 which accounts for the fact that a path satisfying 
 must never leave region 
 before 
, 
 that accounts for the fact that œÉ must enter region 
 within 
 and 
 that accounts for the fact that there must be a time 
 where œÉ switch from region 
 to region 
 directly, i.e. without spending time in any intermediate region: if that is not the case (i.e. if œÉ within 
 has points in the complementary region 
) then (5) yields a positive value given which accounts for the sum of the minimal distances of each such point from either regions 
 or 
 (see plot in Fig. 2f).

Remark 3.3 ABC convergence aspects

In order to be employed in ABC frameworks, satisfiability distances shall account for the convergence of the ABC algorithms, in the first place by ensuring that each path is ranked with an as large a value of distance as the path is further from satisfying the considered formula, which, indeed (3), (4) and (5) do. Experimental evidence showed that the convergence of ABC algorithms for eventual formulae 
 is affected by a peculiar aspect of a model's path œÉ, that is, the presence/lack of jumps within the bounding interval 
. Specifically if, within 
, œÉ does not contain any jump (and lies outside region 
) then it is more convenient (from a convergence standpoint) that the distance 
, i.e. (3), is set to the Euclidian distance between region 
 and the point entered at the last jump occurred before entering 
 even if within 
 the path is actually closer to 
 (e.g. Fig. 3a). Such an aspect ensures that the ABC-driven parameter search is not mislead by anomalous situations such as, e.g. parameters  that yield a model 
 for which there is a non-null probability of reaching an absorbing state before 
. On the other hand, if œÉ contains jumps in 
, then it is more convenient that 
 is set to the Euclidian distance of the closest point amongst the point corresponding to the last jump before 
 and those corresponding to jumps occurring in 
 (e.g. Fig. 3c).

Fig. 3
Download : Download high-res image (401KB)
Download : Download full-size image
Fig. 3. Automaton 
 (top) for measuring the distance of a path œÉ for an eventual property concerning observed species XO and examples (bottom) of measured distance d: positive distance (a), null distance (b), selection of the minimum distance (c) in case of presence of jumps in [t1,t2] and evolution of the computed distance d along a path (d).

Below we prove that the satisfiability distances for F, G and U formulae are sound w.r.t. the second criteria listed above, that is: if a path œÉ satisfies a formula œÜ then the distance is . We start off by proving such property for F and G formulae concerning elementary regions, we then extend the proof to F and G concerning non-elementary regions and finally, based on results proved for F and G, we extend the prove also to U formulae.

Lemma 3.1

Soundness elementary F
For 
 a path of an MPM 
 and Œº an MITL proposition corresponding to an elementary region then

Proof

‚áí Let us assume that 
. which means 
. Then from MITL semantics 
‚Åé
‚Åé
 hence

Image 9
. By definition,
Image 10
. Since 
‚Åé
 and
Image 9
then trivially
Image 11
hence 
.
‚áê Let us assume that 
. It means 
 and

Image 12
(the first case of distance computation cannot produce 0). Then
Image 13
. As 
 is a distance,
Image 14
, i.e. 
‚Åé
. From MITL semantics, 
. ‚ñ°
Lemma 3.2

Soundness elementary G
For 
 a path of an MPM 
 and Œº an MITL proposition corresponding to an elementary region then


Proof

‚áí Let us assume that 
 which means 
. By definition, 
. From MITL semantics it follows 
,  i.e. 
,

Image 15
. 
, 
. So
Image 16
hence
Image 17
. In conclusion, 
.
‚áê Suppose that 
. Let us prove 
.

We have :

Image 17
. As
Image 18
is a non-negative continuous function and its integral equals 0, then this function is the null function over 
. So,
Image 16
. This means
Image 19
. In other words, 
. ‚ñ°
Having proved the soundness of the satisfiability distance for F and G formulae with elementary regions, we straightforwardly extend this result to formulae that involve non-elementary propositions.

Proposition 3.1

Soundness non-elementary F and G
For 
 a path of an MPM 
 and 
 an MITL propositional formula in DNF where each 
 corresponds to an elementary region then

Proof

 
 

For Until formula, result follows from 
 and the proof of the distances for eventual and global regions. ‚ñ°

Lemma 3.3

Soundness U
For 
 a path of an MPM 
 and 
 and 
 two MITL propositions corresponding to elementary regions then

Proof

The proof of the above equivalence is a direct consequence of the following decomposition of a time-bounded U formulae as a combination of time-bounded F and G formulae:
 which follows straightforwardly from the semantics of the U operator.

‚áí Assuming 
 then 
 and therefore, from Lemma 3.2, 
. Furthermore if 
 then also 
 such that 1) 
, hence, from Lemma 3.1, also 
 and 2) since

Image 20
then 
 in (5) is 
 and since 
 then, from Proposition 3.1, also 
. Thus the three addends in (5) are all zero which proves the implication ‚áí.
‚áê similar approach by reversing ‚áí. ‚ñ°

3.2. HASL specifications for satisfiability distances
Based on the HASL formalism, we discuss the problem of defining hybrid automata specifications to measure the satisfiability distances introduced in the previous section. For the sake of simplicity, the automata presented here refer to temporal formulae built on top of a generic mono-dimensional (elementary) proposition 
, where 
 denotes the population of an observable quantity O of an MPM model 
 and 
. Distance automata for formulae based on n-dimensional regions are simply adaptations of those in Fig. 3 and Fig. 4.

Fig. 4
Download : Download high-res image (131KB)
Download : Download full-size image
Fig. 4. Automaton 
 for global property.

Distance automaton 
. Automaton 
 (Fig. 3) is designed to measure the distance (3) of a path œÉ (of an MPM model 
) from the region associated with 
, i.e. the region corresponding to the observed species 
 within time 
. It uses 4 variables: d (computed distance), t (current time along the path), n (population of the observed species O after the most recent occurrence of a reaction) and 
 (population of O before the most recent occurrence of a reaction). The synchronisation of œÉ with 
 is managed through a number of mutually exclusive autonomous transitions (from 
 to 
), plus a single synchronised transition (from 
 to 
), which results in the automaton looping between 
 and 
 up until a termination condition is fulfilled. It is straightforward to show that 
 complies with the HASL determinism constraints (Section 2.3.1) and therefore the synchronisation of an arbitrary path œÉ yields a unique path in the product process 
. Specifically, synchronisation of œÉ with 
 works as follows. At the start (
) the distance is initialised to  and the initial value of the observed species are stored in 
. Once in 
, the analysis of œÉ begins and is driven by seven mutually exclusive autonomous transitions. If initially œÉ is inside the region (and this include even initially with  in case 
 too), then transition 
 
 occurs immediately and the synchronisation stops with distance . On the other hand if, while in 
, the path has not entered 
, distance d must be computed depending on different conditions (that correspond to 4 mutually exclusive autonomous transitions linking 
). Specifically: in case 
 (i.e. œÉ has not yet temporally reached the time interval 
) then either œÉ has entered 
, in which case d is correctly set to 9 through firing of 
 
 
 or, œÉ has not entered 
 and then d is set to the Euclidian distance of the current point of the path from the nearest corner of the region (either 
 or 
) through firing of 
 
 
. On the other hand if 
, in accordance with (3), the distance of the current point of the path is either: i) left unchanged (by firing of 
 
 
), if the last occurred reaction had not produced a jump w.r.t. the observed species (i.e. 
), or, conversely, ii) to the minimum between the previous value of d and the distance of the current point from 
 (by firing of 
 
 
) if the last occurred reaction did produce a jump w.r.t. O.

Proposition 3.2

Let 
 be a species of an MPM model , 
 be the distance LHA corresponding to the MITL reachability formula 
 and 
 be a path of , then:
 where 
 denotes the value stored in variable d of automata 
 when 
 has synchronised with œÉ.

Proof

See Appendix A. ‚ñ°

Distance automaton 
. Automaton 
 (Fig. 4) is designed to measure the distance of a path œÉ w.r.t. to a formula 
, based on (4). It uses the same variables as 
 (hence d stores the measured distance corresponding with the integral of the segments that, within 
, fall outside the region) plus an extra timer 
, to measure the duration of a segment falling outside the region within 
, and a boolean flag in, which is set to  if the last segment of the path originates in 
 outside of the region 
. in is used to distinguish cases where the path is out of the region 
 with 
 and a new event occurs after a time 
, in order to add 
‚Åé
 instead of 
‚Åé
. After the initialisation of variables (
), analysis begins in 
: for events occurring before 
, we distinguish two cases. If

Image 21
, the distance is set to zero (
 top arc). Otherwise, d is the distance of
Image 1
from 
 otherwise (
 midway arc). Indeed, if, for example, the next jump of œÉ happens at 
, then the final distance is given by 
 (
 bottom arc). For events occurring at 
, if
Image 22
(sequence 
), the distance is incremented by the surface defined by the path segment (of duration 
) laying outside 
 and the closest border of 
. The distance is left unchanged if
Image 21
(sequence 
).
Distance automaton 
. Automaton 
 refers to measuring the distance of paths from a sequence of regions consisting of a G region (related to an observed quantity O) temporally followed by an F region (related to an observed quantity 
). In practical terms, such an automaton is associated with the MITL formula 
, for which we assume 
 (i.e. the G region precedes the F region), while 
 and 
, resp. 
, denotes the population of species O, resp. 
. This automaton is a concatenation of the automata 
 and 
, which is illustrated in Appendix B.

3.3. Automaton-ABC: ABC with satisfiability distance
We now introduce the adaptation of the ABC algorithms discussed in Section 2.4, which we name automaton-ABC in the remainder, to estimate the satisfaction probability function of a reachability formula œÜ by a parametric MPM 
. A preliminary version of the method was presented in [6], where ABC was used to show regions where parameters were susceptible to satisfying the probability. However, the method presented in [6] was not equipped with necessary means for directly estimating the satisfaction probability function. We point out that with the Automaton-ABC, the estimation of the ABC posterior distribution (
) is no longer computed as a limit approximation (i.e.  
 
), as with classical ABC, but rather as an estimation of the exact distribution, since paths are accepted exclusively if their distance to the satisfiability region is zero.

Simple ABC with satisfiability distance. With Algorithm 3, we propose a modified version of the simple ABC Algorithm adapted to satisfiability distances. The algorithm takes as inputs a parametric MPM 
, a prior distribution œÄ over Œò and a distance automaton 
 corresponding to a reachability formula œÜ. It works as follows: at each iteration, a parameter 
 is drawn from the prior , a path 
 is sampled from the MPM 
 and the distance 
 is computed by synchronisation of 
 with automaton 
; 
 is accepted if the distance from œÜ is 
 (i.e. if 
 by Proposition 3.1).

Algorithm 3
Download : Download high-res image (43KB)
Download : Download full-size image
Algorithm 3. Automaton-ABC with 
 automaton.

Proposition 3.3 links Algorithm 3 with the satisfaction probability function (Definition 2.5).

Proposition 3.3

For 
 a parametric MPM, œÜ an MITL formula and œÄ a prior distribution over the parameter set Œò, the 
 sampled by the Algorithm 3 are drawn from a density function 
:
 
 where 
 is the probability satisfaction function of Definition 2.5 and 
 is a positive constant.

Proof

Let 
. Then 
. ABC is a reformulation of the accept-reject algorithm. Thus, the samples 
 from Algorithm 3 are drawn from a density 
:
ùüô
 
 
  
 
 
  
 
 
  where 
 is the density related to the MPM 
 with regard to a measure 
.

As 
, ùüô
ùüô
. One can obtain the marginal distribution of Œ∏ by integration over the whole set of paths 
:
 ùüô
 

As 
, we can conclude that 
 
. ‚ñ°

This result transforms the regression of a smooth function into the regression of a probability density function. First, each parameter sampled from the 
 gives information, because it produced a simulation that verifies œÜ. Also, as 
 is a probability density function, the relative position of each parameter to the other sampled parameters gives much information about the satisfaction probability function. The denser in sampled parameters a subset of parameters space, the higher the satisfaction probability function over the subset.

The functioning/motivation behind Algorithm 4 may be summarised by the following remarks. If with Algorithm 3, we do not exploit the real-value of the measured distance (i.e. we only accept/reject paths depending on whether their distance is zero, i.e. if they satisfy œÜ.), with Algorithm 4, we take advantage of the distance value to rank paths and accept the parameters whose corresponding paths are closer (i.e. better ranked) to the satisfiability regions than others (even if they do not necessarily satisfy œÜ). This can lead to a faster convergence of the algorithm corresponding to a faster exploration of the parameter space.

Algorithm 4 has the same inputs as Algorithm 3, plus a kernel distribution K and a hyper-parameter  representing how fast the tolerance œµ decreases along with the iterations.

It works as follows. Initially, N parameters/particles 
 are drawn from the prior , and the first tolerance level œµ to reach equals the Œ±-quantile of the distances 
, resulting from the synchronised simulations 
. Then, at each iteration i, each parameter 
 () is moved by a kernel distribution K, and the synchronised simulation 
 is performed. This procedure is done until the resulting distance 
 is below the current tolerance level œµ, which means the parameter 
 is kept. After doing so for the N parameters, we compute a new tolerance level œµ that equals the Œ±-quantile of the distances 
. These iterations are repeated until the last tolerance level  is reached. The introduction of several steps with positive decreasing tolerances leads to an efficient exploration of the parameter space driven by 
.

3.4. Estimation of the satisfaction probability function
Based on the samples 
 of the Algorithm 4, we can estimate the satisfaction probability function thanks to Proposition 3.3. This procedure is twofold: estimation of the ABC posterior density and estimation of the constant K.

Estimation of the  posterior distribution. We estimate our ABC posterior based on the samples 
 with kernel density estimation (Section 2.5). Two kernels are used: Gaussian and beta [52]. Beta kernels are useful when we have to estimate densities over bounded supports with positive probabilities on the boundaries, but are more computationally expensive for the calibration of the bandwidth. The optimal bandwidth is obtained by Least Squares Cross-Validation minimisation [50].

Estimation of K. K is estimated by a single-point estimation of 
‚Åé
 and 
‚Åé
. 
‚Åé
 should be chosen wisely: verifying œÜ should not be rare, and 
‚Åé
 should be in a region where 
 can be well approximated (a region of high posterior probability). Then, 
‚Åé
 can be estimated with statistical model checkers. One can choose several Œ∏, estimate the constants, and compute the mean to get a more stable kernel density estimation.

4. Application
We applied the automaton-ABC method to tackle the estimation of satisfaction probability function on three models of biological systems: the enzymatic reaction network (Michaelis-Menten kinetics), a model of viral infection and the SIR chemical reaction network.

4.1. Enzymatic reaction system
4.1.1. Model
We consider the model of Enzymatic Reaction system (Michaelis-Mentens kinetics [54]) described by Equation (6), in which a substrate species S is converted into a product P through the mediation of an enzyme E. The dynamics depend on the kinetic rates that induce a parameter vector 
. We thus consider the underlying parametric MPM 
. The initial state is 
.(6)
 Fig. 5 shows two (4-dimensional) paths sampled from the MPM model 
 of the enzymatic reaction system with parameters  (top) and  (bottom). The dynamics of the ER system (Fig. 5) is such that the totality of the substrate (initially 
) is converted into the product at speed dependent on parameters Œ∏. With , the totality of S is converted before , whereas with a tenfold speed reduction in the formation of the ES complex and synthesis of P (i.e. ), we have that only about 30% of S has been converted at .

Fig. 5
Download : Download high-res image (256KB)
Download : Download full-size image
Fig. 5. Paths of the ER system with Œ∏top‚ÄØ=‚ÄØ(1,1,1), Œ∏bottom‚ÄØ=‚ÄØ(0.1,1,0.1).

4.1.2. Preliminary tests of distance automata
Before actually applying the distance automata of Section 3.2 to the ABC framework of Section 3.3, we have executed several experiments aimed at testing whether the distance measured by automata 
, 
 and 
, in isolation, that is, not plugged within ABC algorithms, give reasonable readings. The results are shown in Fig. 7. To this aim, we have used the statistical model checker Cosmos [43], i.e. we have developed the MPM model of the ER system (in terms of a generalised stochastic Petri net model, the input modelling formalism for Cosmos) as well the distance automata with Cosmos.

More specifically, for these tests, we have considered different configurations of the ER model and observed whether the distance (from specific regions) measured through the automata was in line with the dynamics exhibited by several paths sampled from each configuration. For example, Fig. 6 shows batches of paths of the ER model for species P, corresponding to the parameter sets 
, 
 and 
 (i.e. only 
 varies). It appears that paths for 
 (red) are likely to traverse 
, those for 
 (blue) to traverse  and those for 
 (green) to traverse . We have therefore considered the following time-bounded reachability formulae, each of which is associated to a corresponding time-bounded region:

‚Ä¢
 associated with region named ,

‚Ä¢
 associated with region named ,

‚Ä¢
 associated with region named ,

‚Ä¢
 associated with region named ,

‚Ä¢
 associated with region named ,

‚Ä¢
 associated with region named .

Fig. 6
Download : Download high-res image (224KB)
Download : Download full-size image
Fig. 6. Relationship between paths of ER system for species P corresponding to parameter configurations with fixed k1‚ÄØ=‚ÄØk2‚ÄØ=‚ÄØ1 and different values of k3‚ÄØ‚àà‚ÄØ{10,20,50} and three different regions TR1, TR2 and TR3.

We point out that formulae 
 (which correspond to region , ,  of Fig. 6) are examples of formulae for which there is a fairly large subset of values for 
 (with 
) which yields a positive satisfaction probability. On the other hand, 
 are formulae where only a small subset of 
 (with 
 = 1) yields a positive satisfaction probability.

Such intuition is confirmed by the plots showed in the first row of Fig. 7, which depicts the average value of the distance of paths from time regions ,  and  measured with Cosmos, as a function of 
, using specific instances of 
, i.e. 
, 
 and 
. We observe that, for example, the measured distance from region  monotonically decreases as 
 increases and cancels for 
, while the distance from region  is zero when 
, whereas it grows as 
 increases.

Fig. 7
Download : Download high-res image (478KB)
Download : Download full-size image
Fig. 7. Average distances of the automata based on the six formulae œÜi, i‚ÄØ‚àà‚ÄØ{1,‚Ä¶,6}, computed by Cosmos with approximation of 0.1 and 99% level of confidence. First row: 
. Second row: 
.

4.1.3. Satisfaction probability function estimation
We apply automaton-ABC Algorithm 4 to the ER parametric MPM defined over 
. ,  and  corresponds to one-dimensional experiments: only 
 varies over  (
 are fixed), a uniform prior  is set. ,  and  corresponds to two-dimensional experiments: 
 and 
 varies over  (
 is fixed), a uniform prior  over each parameter is set.

The estimated function of  exhibits a rather uniform profile, with a 95% credibility interval that 
 is satisfied for 
 (approximately), which is in agreement with the average distance measure (Fig. 7, first row). When the average distance is zero, the estimated probability by both Prism model checking and automaton-ABC is one. The estimated functions for  and , instead, result in narrower 95% credibility intervals with 
 () resp. 
 (), again in line with average measured distance (Fig. 7, first row).

Fig. 9 depicts the results of the 2D experiments on the ER system with examples of F, G, and  formulae. The triangular profile of the joint posterior in experiments  and  (computed with 
 and 
) indicates that only very low values of 
 (
 for , 
 for ) combined with rather high values of 
 (i.e. 
 for , 
 for ) result in paths entering , resp. never leaving , which means that the algorithm managed to catch the correlation between the parameters. This is intuitively correct in both cases. In fact,  corresponds to a very low synthesis of P, which is not compatible with fast creation of the ES complex (i.e. only very small 
 are not ruled out), and even the compensation effect obtained by fast decomplexation (i.e. large 
) will not suffice for paths to stay in .

Fig. 9
Download : Download high-res image (985KB)
Download : Download full-size image
Fig. 9. Results of 2D experiments of ER system with 1000 particles (
, k3‚ÄØ=‚ÄØ1). Top: the 2D weighted histogram of the automaton-ABC posterior. Middle: estimation of the satisfaction probability function with Prism by Statistical model checking (99% confidence interval with approximation 0.01). Bottom: kernel density estimation of the satisfaction probability function.

One can notice that the estimated satisfaction probability function of region  (most-left bottom picture of Fig. 9) has a lot of probability mass around . At first glance, one could conclude in a problem of bias of the kernel density estimator since the satisfaction probability function estimated by Statistical Model Checking (second row, first column picture) does not show the same shape in this area. However, if we run Statistical MC with a refined grid around zero (Fig. 10), one can surprisingly notice that the probability values are high around . This behaviour was not expected, and automaton-ABC algorithm allowed us to discover this small area of high satisfaction probability that was not caught by Statistical Model Checking with the original grid of 20 points per axis.

Fig. 10
Download : Download high-res image (327KB)
Download : Download full-size image
Fig. 10. Statistical Model Checking of the ER model with TR4 over [0.0,0.0005]√ó[0.0,20.0]. 10 points for the first axis and 20 points for the second axis.

Similarly to experiment ,  limits the speed of the initial decrease of E (with initially 
) to 50 within , which again is compatible only with slow ES complexation and cannot be compensated by fast decomplexation.

The  experiment caught an even more important correlation between the two parameters. In fact, the posterior for  is contained in the one obtained for , which is expected because if a path verifies , then it also verifies .

4.1.4. Remarks
Results have been obtained by running Algorithm 4 with sample size . There are no notable differences in performance between Algorithm 3, Algorithm 4 for 1D experiments on , ,  because of the large size of the resulting distributions. However, simple automaton-ABC Algorithm 3 is not worth considering for  and . Given the large size of the support for the considered priors (), we remark that the probability of sampling (a pair of) parameters in the resulting ABC posterior distribution are about 
 
‚Åé
 
. This leads to an infinitesimal probability of drawing from the prior  particles that fall in such a narrow distribution, let alone the fact that even a parameter sampled from the obtained distribution could produce paths that do not satisfy œÜ. By adding several transitional steps with the sequential version (Algorithm 4), the problem becomes treatable. The results for  required about 
 simulations of the model, which is the highest number of simulations in all experiments.

4.2. SIR
We consider the classical SIR compartmental model [26] introduced in Example 2.1. We tested our algorithm on a single formula 
 with one 1D experiment and one 2D experiment. This formula means the considered epidemic is active within the time  but disappears during the time . In the 1D experiment, we fix 
 and we take 
. In the 2D experiment, both parameters vary: 
 and 
. Fig. 11 reports results for such experiments, including the comparison of the probability satisfaction function obtained through the ABC-automaton method with that obtained through Prism model checker (numerical method for both 1D and 2D experiments). One can see that the satisfaction probability function is well reconstructed in both cases.

Fig. 11
Download : Download high-res image (589KB)
Download : Download full-size image
Fig. 11. Results for the SIR model with œÜ‚ÄØ=‚ÄØG[0,100](I‚ÄØ>‚ÄØ0)‚àßF[100,120](I‚ÄØ=‚ÄØ0). On the top left figure: automaton-ABC posterior weighted histogram with 1000 particles for the 1D experiment; in

Image 23
: the true satisfaction probability function computed with Prism model checker using the numerical engine of Prism over 40 points; in
Image 24
: the estimated satisfaction function with kernel density estimation method. The three other figures correspond to the 2D experiment. On the top right figure: the 2D histogram of the automaton-ABC posterior. On the bottom left figure: the kernel density estimation of the satisfaction probability function. On the bottom right figure: the estimation of the satisfaction probability function by Prism model checker (numerical engine).
Whereas the success is expected in the 1D experiment because the histogram suggests a Gaussian-like shape of the density, the result for the 2D experiment is more remarkable because it is hard to guess the density shape based on the 2D histogram. However, our algorithm managed to reproduce the same complex shape and values given by the Model Checking estimates.

4.3. Intracellular viral infection
We consider a model of cell viral infection [55] described by Equations (7).(7)
 
 
 
 
 
 

N represents the nucleotides and A the amino acids. G is the genomic nucleic acids, T the template nucleic acids, S the viral structural protein and V the secreted virus. In this model, we assume nucleotides and amino acids have constant concentrations 
 and 
: we suppose these species are in large number.

Satisfaction probability function estimation. A 2D experiment is considered with the following logical property: 
. This property expresses that the species G remains stable and low within time , and then a burst of speed in the creation of G occurs within , which is needed material to the creation of the virus V.

We vary the nucleotides and amino acids concentrations: 
 and 
. Fig. 12 reports the results of the experiment. Considering the end time of the formula, each simulation of this model is more computationally expensive than the other considered models. But our methodology still allows a proper run of the experiment, and we get a good approximation of the satisfaction function (about 
 simulations).

Fig. 12
Download : Download high-res image (315KB)
Download : Download full-size image
Fig. 12. Results for the intracellular viral infection model with œÜ‚ÄØ=‚ÄØG[0,50]G‚ÄØ‚â§‚ÄØ10‚àßF[50,200]G‚ÄØ>‚ÄØ100. Left: the 2D histogram of the automaton-ABC posterior. Center: kernel density estimation of the satisfaction probability function. Right: estimation of the satisfaction probability function by Monte-Carlo simulations (based on a 99% confidence level and approximation 0.01).

4.4. About implementation of automaton-ABC method
The implementation of automaton-ABC methods leads to a Julia package.10 It includes both simulation and synchronised simulation of MPM, support for CRN representation of MPMs and automaton-ABC related methods.

ABC related algorithms are distributed and the experiments were performed using HPC resources from the ‚ÄúM√©socentre‚Äù computing center of CentraleSup√©lec and √âcole Normale Sup√©rieure Paris-Saclay supported by CNRS and R√©gion √éle-de-France (http://mesocentre.centralesupelec.fr/).

Table 1, Table 2 show performance results for the whole set of experiments. We omit Kernel Density Estimation since it only depends on the number of particles N and the choice of the kernel. The computational time of Least-Squares Cross Validations can be expensive when the kernel is a multivariate beta kernel with a high number of particles (). However, Least Squares Cross-Validation estimates are easily distributable.


Table 1. Performance results for the one-dimensional experiments of automaton-ABC.

Exp	ER TR1	ER TR2	ER TR3	SIR 1D
Num. of jobs	1	1	1	1
Num. of sim.	2263	4896	7197	25404
Time (sec)	7.5	10.9	8.7	7.1

Table 2. Performance results for the two-dimensional experiments of automaton-ABC.

Exp	ER TR4	ER TR5	ER TR6		
Num. of jobs	120	120	120		
Num. of sim.	256641	32367	47649		
Time (sec)	66.18	29.2	31.9		

Exp	SIR 2D	Viral inf.
Num. of jobs	120	120
Num. of sim.	17284	6125
Time (sec)	13.1	70.1
When the number of jobs is 120, the run was distributed on the Mesocentre HPC cluster. Otherwise, it was run on a Dell XPS 9370 with CPU Intel i7 8550U @ 1.8GHz x 8 cores.

Our tool for automaton-ABC is quite efficient because the run of an experiment is rarely higher than one minute. For example, the experiment about the region TR4 of the ER model performs 256000 simulations within a minute over the cluster (without counting the other computations of the ABC algorithm), knowing that each simulation that reaches  is about 2000 steps of Stochastic Simulation Algorithm [10].

The SIR 2D experiment has higher computational time than the 1D experiment, even if it is run with 120 jobs. This is explained by the fact that creating and dealing with many jobs has a higher computational cost when the execution time per job is low. It is the case here: less than 7 seconds of computation has to be distributed over 120 jobs, which is not helpful. The viral infection model has a higher computational cost per simulation because it is a much more complex model than the two others.

This computational time has to be put in perspective to classical Statistical Model Checking methods. For example, in experiment , the Statistical MC run over a grid of 200 points of a much smaller set than . It lasted more than one hour, and we saw this grid missed a region of high probability for 
 formula.

5. Discussion
Comparison with Smoothed Model Checking. We discuss some results of Smoothed MC algorithm for which a Python version is given in [23]. The main idea of Smoothed MC algorithm is to estimate the satisfaction function 
 over an interval  with Gaussian Processes (GP) in a Bayesian framework. Initially, the function is estimated over d points of I using classical stochastic model checking: this establishes a data set D. Given a GP prior and a likelihood of the observations that are, by nature, Binomial, one can then compute a posterior  that is also a GP thanks to the Bayes rule (the constant of normalisation is computed with the Expectation-Propagation algorithm). At each iteration i, a new 
 is added in D and 
 is estimated through classical stochastic model checking to increase the training set D and therefore have a better accuracy until a convergence criterion is met. For the sake of comparison, we reproduced the 1D experiments for the ER model (Section 4.1) using the Smoothed MC tool [23]. Fig. 13 depicts plots of the satisfaction probabilities obtained with Smoothed MC, which show a good agreement with those obtained with the ABC-automaton approach (Fig. 8). Table 3 reports the number of trajectories generated by both algorithms, showing a clear advantage for the ABC-automaton approach. In this table, we do not include any simulation for the estimation of 
 for , which is required for the estimation of the constant K. On the contrary, this table does not show the cost of normalisation constant estimation in the Smoothed MC posterior by Expectation-Propagation. Also, a default value of 600 trajectories is set for each satisfiability probability estimation by statistical model checking, which should be higher if one wants a high confidence level and an approximation of 0.01.

Fig. 13
Download : Download high-res image (69KB)
Download : Download full-size image
Fig. 13. Estimation of the satisfaction probability functions in experiments R1, R2, R3 for the ER system reported in Fig. 8 with Smoothed MC algorithm. In blue: the estimated function; in green: the lower bound; in orange: the upper bound.


Table 3. Number of simulations before termination for both algorithms. For automaton-ABC: number of N‚ÄØ=‚ÄØ1000 particles. For Smoothed MC: each point of the dataset is estimated with 600 trajectories (default value).

R1	R2	R3
Smoothed MC	27000	37200	32400
Automaton-ABC	2263	4896	7197
In return, the ABC method does not have the same statistical guarantees as Smoothed MC because it does not assume any specific form for the ABC density 
: we minimise the Least Squares Cross-Validation criterion to have the better trade-off between bias and variance over the  particles in kernel density estimation. To run 2D experiments, we have adapted the available Smoothed MC code, but preliminary tests seem to indicate a prohibitive computational time. Indeed, convergence for 2D experiments such as R4 required many more trajectories simulation (
). The end time of simulations is much higher than the 1D experiments (
). The 2D experiments on the ER system show that our method gives an efficient way to identify the region of the parameter space where the satisfaction function is positive. Once such exploration is performed, one can either use our kernel density estimation based method as it is done in this paper (on which a large literature exists), or regression methods over the identified region, such as Smoothed MC that trade higher computational cost for better statistical guarantees. We further remark that since the main computational cost of the ABC approach is the simulation of trajectories, our method is well suited for distributed computing, which is not the case for all regression methods (e.g. Smoothed MC is, by nature, sequential).

Comparison with robustness-based approaches. The framework we introduce in this paper naturally compares with approaches for assessing the robustness of a temporal logic property w.r.t. (deterministic) continuous and hybrid models [41], [56]. Intuitively the notion of robustness has been proposed so to overcome the limits of methods for establishing the Boolean satisfaction of a formula (i.e. model checking) by introduction of a scoring function that allow for quantifying how ‚Äústrongly‚Äù a trace œÉ (hence a model) satisfies a formula œÜ. More precisely the robustness of œÉ w.r.t. to œÜ is a real-valued function that expresses how far œÉ is from dissatisfying (positive robustness) or satisfying (negative robustness) œÜ. Initially introduced only w.r.t. the space perspective, spatial-robustness [57] has then been extended to the time perspective yielding the notions of temporal-robustness as well as the combined space/time-robustness [41]. Such robustness measures have then been plugged into dedicated simulation-based procedures for identifying the subspace of a non-probabilistic model's parameters for which a formula is guaranteed to hold (e.g. the BREACH tool [56]).

In our framework, on the other hand, the scoring of traces is done through so-called satisfiability-distance measures, e.g. (3), (4), (5), i.e. non-negative functions that express how far œÉ is from satisfying œÜ by taking into account the combined spatio-temporal dimension (and yielding 0 if ): therefore our satisfiability-distance semantically correspond to negative trace-robustness. The main limitation of our approach is that the definition of satisfiability-distances we gave is limited to a fragment of the full STL syntax, whereas, conversely robustness measures are defined (recursively) on the entire STL language. It would be certainly worth, as future developments, to consider whether the robustness measures definition could be adapted, so to replace satisfiability-distances, in our framework for exploring the parameter space of MPMs. In this respect it is worth pointing out that existing robustness-based frameworks [41], [56], being addressed to deterministic (i.e. non-probabilistic) models, cannot straight away be applied to probabilistic systems, as parameter search for stochastic systems requires to plug a trace scoring measure within a procedure for estimating the probability satisfaction function of œÜ.

6. Conclusion
We developed a novel ABC-based framework to address probabilistic verification of temporal logic formulae against parametric MPMs. Our method allows an efficient exploration of the parameter space thanks to a formal definition of distance between the model's trajectories and the satisfiability region associated with the considered formula. Such distances are measured with linear hybrid automata.

We have shown that the estimation of the satisfaction probability function for a formula œÜ can be achieved thanks to a sound relation with the resulting ABC posterior distribution of the automaton-ABC. The estimation of the probability of satisfying œÜ boils down to a density estimation problem, which opens up to future improvements and tools from an active research area in statistics. We tested this novel approach through many case studies, which showed promising results. Our method can also be used as a heuristic for estimating the satisfaction probability function because it explores the parameter space w.r.t. a logical property in an efficient manner and then can be combined with other regression methods over a subset of the parameter space. Some aspects remain to be considered to extend this work, including i) support for automatic generation of the LHA corresponding to a given formula (which is currently done manually), including the case of formulae for non-elementary regions; ii) the extension to a less constrained set of formulae (currently the method only considers a fragment of MITL temporal logic formulae); iii) the integration of the automaton-ABC framework within the Cosmos statistical model checking platform.

Appendix A.
Proposition 3.2. Let 
 be a species of an MPM model , 
 be the distance LHA automaton corresponding to the MITL reachability formula 
 and 
 be a path of , then:
 where 
 denotes the value stored in variable d of automata 
 when 
 has synchronised with œÉ.

Proof

We recall that  denotes a generic state of the product process 
, where s is a state of , l is a location of 
 and 
 a valuation of the variables of 
. In the remainder we use the notation 
‚Åé
 to indicate that state 
 of 
 is reachable from , i.e. 
‚Åé
 means that there exists a finite sequence of (synchronised/autonomous) transitions that takes 
 from  to 
.

The proof boils down to showing that the synchronisation of an arbitrary path 
 with 
 leads the product process 
 to reach, from the initial state 
, a state

Image 25
, (i.e. 
 being the only accepting location of 
), where 
‚Åé
 is the time instant when
Image 25
is reached and 
‚Åé
 is equal to 
 as in (3).
Given an arbitrary path 
 and its projection w.r.t. the observed species 
, i.e. 
, we denote11 
, resp. 
, the time instant of the last jump contained in 
 before 
, resp. 
 (see examples in Fig. A.14). We consider the following partition of the set of paths of , i.e. 
 where 
 is the set of paths whose projection 
 contains no jumps within 
, 
 are the paths that contain no jumps within 
 but at least one jump in 
, 
 the paths that contain at least one jump within 
 and no jumps in 
 and 
 the paths that contain at least one jump within 
 and at least one jumps in 
. Examples of paths characterising such a partition of 
 are given in Fig. A.14.

Fig. A.14
Download : Download high-res image (198KB)
Download : Download full-size image
Fig. A.14. Examples of paths belonging to the different subsets of the partition 
. Vertical dashed lines delimit an unspecified part of a path.

Let 
 denote a generic state of the product process 
, where  is a state of ,  is a location of 
 and 
 are the values of the four variables of 
. In the remainder we denote Œº the propositional formula 
, 
 the state of an arbitrary path 
 is in at time 
, i.e. 
, 
 the distance between the initial state 
 of œÉ and the region 
 and 
 is the minimal distance from 
 for the segment of 
 delimited by time interval 
 with 
.

1) 
. In this case 
 is constant (at least) until 
. We distinguish between 2 cases:

a) 
 then either the condition Œº is satisfied in the initial state 
 i.e. 
 and hence the synchronisation of œÉ with  yields the following unique path on 
: 
 
 
 and therefore 
, or Œº is not satisfied in the initial state, i.e. 
 in which case the synchronisation of œÉ with  yields the following unique path on 
: 
 
 
 

b) 
 then either i) 
 hence the synchronisation yields the following unique path on 
: 
 
 
 
 and therefore 
, or ii) 
 hence the synchronisation yields the following unique path on 
: 
 
 
 
 and therefore 
.

2) 
. In this case 
 is constant until 
 and contains at least 1 jump in 
 and 
 is the time of the last jump before 
. We distinguish between 2 cases:

a) 
, in this case the synchronisation of œÉ with 
 yields the following unique path 
 
 
 
 
 where 
 is the time of the first jump that occurs on 
 within 
 and r is corresponding reaction occurred at 
; therefore 
.

b) 
, in this case we distinguish between 2 further cases: i) 
 such that 
, in this case the synchronisation of œÉ with 
 yields a unique path 
 
 
‚Åé
 
 or ii) 
 and in this case the synchronisation of œÉ with 
 yields a unique path 
 
 
‚Åé
 
 
 
 where 
 is the time instant of the last but one jump before 
. Therefore 
.

3) 

Similar to previous cases.

4) 

Similar to previous cases. ‚ñ°

Appendix B. Automaton 
Fig. B.15 depicts automaton 
 corresponding to the conjunction of a G formula with and F formula such that the time-bounding interval of the G formula temporally precedes that of the F formula. Automaton 
 is simply obtained by concatenation of 
 and 
.