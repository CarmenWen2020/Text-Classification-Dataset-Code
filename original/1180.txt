Abstract
Formally defining how outputs of nondeterministic computations may be combined, we propose a nondeterministic Turing machine variant to compute functions. First, we describe our inspiration, the association of a computation tree with the divide and conquer strategy. Next, we define the variant and prove its equivalence with the deterministic Turing machine model. Then, we give some examples and relate the variant to alternating, counting and metric Turing machines. After, we define the variant's time complexity classes and compare them to deterministic space, giving a new characterization of the Image 1 and Image 2 classes. Finally, we outline future work.

Keywords
Nondeterministic Turing machines
Computable functions
Divide and conquer
Time complexity
Polynomial space
Counting Turing machines

1. Introduction
“Although the subject of this paper is ostensibly the computable numbers, it is almost equally easy to define and investigate computable functions of an integral variable or a real or computable variable, computable predicates, and so forth.” — Turing, 1936.

While the deterministic Turing machine model has been easily adapted to decide languages and to compute functions (e.g. in [1], [2]), this has not been the case for its nondeterministic variant. Arbitrarily encoding an output is not enough when programming a nondeterministic Turing machine to compute a function. The problem we face is turning an exponentially bounded number of outputs into one.

1.1. Informal description
Our variant is based on the divide and conquer strategy [3, Chapter 4] and its association with a computation tree of a nondeterministic Turing machine. We define the steps of the divide and conquer strategy below:

1.
divide: divide the problem into subproblems,

2.
conquer: obtain the solution to each subproblem directly or indirectly (that is, using the divide and conquer strategy recursively),

3.
combine: combine the solutions to the subproblems to obtain the solution to the original problem.

First, we associate the divide step with its branch vertices. Then, we associate the direct conquer step with the vertices of paths in which the first vertex is the root or the child of a branch vertex and the last vertex is a leaf. Next, we associate the indirect conquer step with the vertices of paths in which the first vertex is the root or the child of a branch vertex and the last vertex is a branch vertex. By this association, each vertex is associated with exactly one conquer. These associations are illustrated in Fig. 1, where vertices surrounded by a “D” are associated with a direct conquer and vertices surrounded by an “I” are associated with an indirect conquer.

Fig. 1
Download : Download high-res image (74KB)
Download : Download full-size image
Fig. 1. The association of the conquers of the divide and conquer strategy with the vertices of a computation tree.

Now, we associate each conquer with a problem. First, we associate the conquer of the root with the original problem. Then, we associate each conquer of a child c of a branch vertex b with a subproblem of the problem associated with the conquer of b. For example, in Fig. 1, the conquer of u is associated with the original problem, the conquers of  and x are associated with the subproblems of the problem associated with the conquer of u (the original problem) and the conquers of y and z are associated with the subproblems of the problem associated with the conquer of x.

Finally, to complete the association, we describe how to obtain the solutions to these problems by these conquers, more precisely, how to obtain a solution by a direct conquer and how to do the combine step to combine the solutions to the subproblems of a problem to obtain a solution by an indirect conquer.

To obtain a solution by a direct conquer, we treat its vertices as a computation path of a deterministic Turing machine and obtain its solution based on the state of the configuration of its last vertex t. The solution is “yes” if t is an accepting configuration and “no” if t is a rejecting configuration. If t is neither (t is not a halting configuration), then we will say that the solution is “pending”.

To combine the solutions to the subproblems of a problem to obtain a solution by an indirect conquer, we follow the rules of acceptance and rejection of the nondeterministic Turing machine model. The solution is “yes” if at least one of the solutions is “yes”, “no” if all of the solutions are “no”, and “pending” otherwise. The combination of two solutions is described by Table 1.


Table 1. The combination of two solutions following the rules of acceptance and rejection of the nondeterministic Turing machine model.

Solution #1	Solution #2	Combination
yes	yes	yes
yes	pending	yes
yes	no	yes
pending	yes	yes
pending	pending	pending
pending	no	pending
no	yes	yes
no	pending	pending
no	no	no
These combinations are performed “on-demand”. Whenever a solution to a subproblem is obtained, we try to combine it. One may give the association made above as a second description of how a nondeterministic Turing machine decides an input in polynomial time, even when it branches exponentially.

Note that, by differentiating “pending” from “not pending” solutions, we handle the case of non-halting branches, since as soon as the solution to the original problem is “not pending”, we can halt the computation. For example, in Fig. 1, suppose alternatively that the configuration of v does not lead to a halting configuration, then the solution to the problem associated with the conquer of u (the original problem since u is the root) will only be “yes” and allow us to halt if at least one of the solutions to the problems associated with the conquers of w and x is “yes”.

In the next section, we will formally define and extend the association made above so it works with any type of solution. Our proposal is to adapt the obtainment of a solution by a direct conquer as a deterministic Turing machine is normally adapted to compute functions, by obtaining the solution not from the state but from the tape content of the configuration of its last vertex. To adapt how to combine the solutions to the subproblems of a problem to obtain a solution by an indirect conquer, we will define a mapping of nondeterminism to Turing machines responsible for these combinations.

Coming back to Turing's analogy of computation as a person working with a tape, we may describe our variant as an unbounded number of people with each person working with their own tape. First, there is only one person working, but when there is a nondeterministic transition, they call another person for each branch, and so on. The difference between deciding a problem and computing a function is that in the first case, the person who calls only observes if one of the people called accepts or if all of them reject, and in the second, they combine the solutions found.

2. Formal definition
First, we make a general definition of a combination. One that allows us to combine solutions be they “yes” or “no” answers or arbitrary values. In any case, we denote a “pending” solution by the special ϕ symbol.

Definition 2.1 Combining function

Define a combining function λ to be a symmetric1 function such that

1.
 if  for all ,

2.
 if  for all ,

3.
 
 
  if .

where , , are the solutions to be combined.
By item 1, if all of the solutions are “pending”, then their combination is also pending. For example, consider the case when none of the branches of a tree halt. By item 2, if none of the solutions are pending, then their combination is also not pending. For example, consider the case when all of the branches of a computation tree halt. By item 3, if the combination is defined for a subsequence of the solutions,2 then it is also defined and is the same for any supersequence. If that was not the case, then we would need to have all of the solutions to know their combination, contradicting the rules of acceptance and rejection of the nondeterministic Turing machine model. For example, consider the case when at least one of the branches of a computation tree accepts. Some examples of combining functions are given in the next section.

When combining solutions, we normally do not care about their order, so a combining function is symmetric. If their order is important for a particular problem, then it may be embedded into the solutions. This “lack of order by default” comes from the fact that the children of a branch vertex are a set. They would not be if, instead of sets, the images of a transition function were sequences. We chose to workaround this by making a combining function symmetric, but an alternative definition of our variant could be made based on combining functions that are not necessarily symmetric by using an alternative definition of a transition function.

Now, assuming a standard nondeterministic Turing machine definition (e.g. the one found in [2, Chapter 7]) we formulate how an instance of our variant may be declared. Note that, we do not distinguish between s being one or many symbols when writing the input  of a transition function δ, thus ensuring the next definitions work whether we assume a single-tape or multitape definition.

Definition 2.2 Combining Turing machine

Define a combining Turing machine to be a pair  where N is a nondeterministic Turing machine and π is a function defined for every nondeterministic , i.e. , such that  is a deterministic Turing machine that computes a combining function capable of taking  arguments where δ is the transition function of N.

The nondeterministic Turing machine N is responsible for computing the solutions and the images of π are responsible for combining them. Their association is fulfilled by the following definition.

Definition 2.3 Vertex output

Let  be a combining Turing machine and v be a vertex of a tree of N. Denote the state of v by  and the tape head symbols of v by . Define the output of v according to π, denoted by , to be

1.
the output tape content of v if v is a leaf and a halting configuration,

2.
ϕ if v is a leaf but not a halting configuration,

3.
 if , , are the children of v where λ is the combining function computed by ,

4.
 if u is the only child of v.

Convention

In the definition above and throughout this paper, when we refer to a tree of a nondeterministic Turing machine, we are actually referring to a cut tree. Hence, in item 2 of Definition 2.3, v may be a leaf and a non-halting configuration.

The output of a vertex is the solution to the problem associated with it. In items 1 and 2, we define the output of the last vertex of a direct conquer. In item 3, we define the output of the last vertex of an indirect conquer, that is, of a branch vertex. In item 4, we propagate upwards the output of the last vertex of a conquer until we reach a branch vertex (not inclusive) or the root (inclusive). Thus, the solution to the original problem is the output of the root.

Finally, we define the functions computed by our variant. As it is the case of the deterministic Turing machine model and because we are differentiating “pending” from “not pending” solutions, our variant computes partial functions.

Definition 2.4 Computable function

A combining Turing machine  computes the partial function f if whenever  is defined, there is a tree of N for x such that the output of its root, according to π, is .

As evidence of the Church-Turing thesis, we show that the functions defined above are the same as the computable functions, that is, a combining Turing machine has no more power than a deterministic Turing machine.

Theorem 2.1 Equivalence

A function is computable by a deterministic Turing machine if and only if it is computable by a combining Turing machine.

Proof

By Definition 2.3 and Definition 2.4, deterministic computations (of functions) are a subset of our variant's computations, so we only need to show the backwards direction. A deterministic Turing machine may compute the output of a combining Turing machine  for an input x as follows:

Visit the tree of N for x as in a breadth-first search. At each new leaf: Compute its output and recompute the outputs of its ancestors. If the output of the root is not ϕ, then give it as  and halt. □

3. Examples
We adopt the convention that unless otherwise stated, a nondeterministic Turing machine writes 1 on the tape before accepting and 0 before rejecting.

Definition 3.1

Define  to be a Turing machine that computes the combining function  such that
 

Example 3.1

Let N be a nondeterministic Turing machine. We can compute the characteristic function of N with the combining Turing machine  such that  for all nondeterministic .

Remark

Although  and the next combining functions given in this section are variadic functions, this is not a requirement. Definition 2.1 only requires that combining functions take at least 2 arguments and Definition 2.2 only requires that the machine  can take  arguments. Both requirements are met by variadic functions.

Definition 3.2

Define  to be a Turing machine that computes the combining function  such that
 

Remark

By interpreting 1 as “true”, 0 as “false” and ϕ as “undefined”,  is the disjunction and  is the conjunction of Kleene's 3-valued logic [4].

Example 3.2

Let N be an alternating Turing machine [5]. We can compute the characteristic function of N with the combining Turing machine  such that for each nondeterministic , 
 

Definition 3.3

Define  to be a Turing machine that computes the combining function  such that 
 

Example 3.3

Let N be a counting Turing machine [6] such that every path halts. We can compute the number of accepting paths of N with the combining Turing machine  such that  for all nondeterministic .

Definition 3.4

Define  to be a Turing machine that computes the combining function  such that 
 

Example 3.4

Let N be a metric Turing machine [7]. We can compute the maximum value of N with the combining Turing machine  such that  for all nondeterministic .

4. Time complexity
We assume time and space constructible functions.

Definition 4.1 Nonbranch vertex time

Let  be a combining Turing machine and v be a nonbranch vertex of a tree of N. Define the time to compute the output , denoted by  to be

1.
0 if v is a leaf,

2.
 if u is the only child of v.

Note that the time to compute the output of the root of a computation tree with no branches is simply its depth. As it is the case of the nondeterministic Turing machine model and as noted in the proof of Theorem 2.1, our variant is merely an extension of the deterministic Turing machine model. At first it may seem strange that the time to compute the output of a leaf is 0 but this comes from the fact that the number of edges of a path of n vertices is .

Definition 4.2

Let  be a combining Turing machine and  be some of the n children of a branch vertex v of a tree of N such that 
 
 
  where λ is the combining function computable by the Turing machine . Denote the running time of  for the inputs  by . Define the time to compute the output  according to , denoted by , to be(1) 
 
 
 

In the definition above, we define the time to compute the output of a branch vertex using some (when ) or all (when ) of the outputs of its children. By expression (1), the time to compute the output of the branch vertex v using the outputs of  is the time it takes to compute all of , expressed by , added to the time it takes to combine , expressed by .

The next definition captures the time it takes to compute the output of a branch vertex “on-demand” as the computation tree grows. In the scope of this paper, we are only interested in the time complexity of our variant and will assume combinations are made as quickly as possible by trying to combine an output as soon as it is “not pending” and with every permutation of other “not pending” outputs at the same time.

Definition 4.3 Branch vertex time

Let  be a combining Turing machine and v be a branch vertex of a tree of N. Define the time to compute the output , denoted by , to be  such that that is,  is the minimum among all .

In the expression above,  is any permutation of some or all of the children of the branch vertex v and  is the permutation that according to Definition 4.2 is the fastest to compute and combine. Some might say that the time definitions presented above are unrealistic and we do not claim they are not, but that they are reasonable if one follows Turing's extended analogy given at the end of Section 1. Furthermore, as we show in the following theorems, the simulation of our variant using the less unrealistic and more grounded deterministic Turing machine model does not blow up in space.

Example 4.1

Consider the case when a branch vertex v has three children  such that  and . Then, by Definition 4.2,  and by Definition 4.3, . In this case, even though  is redundant because  and  already gives us the information needed to know , the information given by  is the key to a faster combination. That is, it is faster to wait for  and the combination of  than to wait for the combination of .

Finally, now that we have defined the time it takes to compute the output of any vertex, we define the running time of our variant and its time complexity classes.

Definition 4.4 Running time

Define the running time of a combining Turing machine  for an input x to be the time to compute the output of the root of the computation tree of N for x according to π.

Definition 4.5 Time complexity classes

Let  for almost all n. Define

Image 3
to be the set of functions computed by  time-bounded combining Turing machines.
Before working with our variant's time complexity, we will briefly recall the definition of some auxiliary complexity classes that are useful for our theorems and proofs.

Definition 4.6

Let  for almost all n. Define

Image 4
to be the set of languages decided by  time-bounded alternating Turing machines.
Definition 4.7

Let  for almost all n. Define

Image 5
to be the set of functions computed by  space-bounded nondeterministic Turing machines.
Definition 4.8

Let  for almost all n. Define

Image 6
to be the set of functions computed by  space-bounded deterministic Turing machines.
Definition 4.9

Let  for almost all n. Define

Image 7
to be the set of functions computed by  time-bounded deterministic Turing machines.
We are now ready to relate our variant's time complexity classes to other classic complexity classes. To compare function classes to language classes we will, as it is normally done, use oracles.

Theorem 4.1

Image 8
.
Proof

It is easy to see (by induction) that the combining Turing machine given in Example 3.2 can compute the characteristic function of an alternating Turing machine with no time overhead. Hence, By Theorem 3.1 of [5], Therefore, □

Theorem 4.2

Image 12
.
Proof idea

Visit the computation tree as in a depth-first search, bounding the depth by . Use a stack to store the vertices outputs. Reduce the stack whenever possible. Bound the time of the simulations of  by . By induction, the space used is bounded by .

Proof

Let

Image 13
. By Definition 4.5, there is a  time-bounded combining Turing machine  that computes f. Define α to be such that the running time of  for any input of length n is at most . We describe M, a  space-bounded deterministic Turing machine with one read-only input tape, seven working tapes and one write-only output tape that simulates .
M= “On an input x of length n, do as follows:

By the definition of α, we know that the running time of  for x is at most . Then, by Definition 4.4, there is a tree of N for x of depth less than or equal to  such that the output of its root, according to π, is equal to . Since the computation tree may have an exponential number of paths and vertices, we can not store them using  space. Instead, we use a stack to store the outputs needed to evaluate the output of any vertex and to compute the output of the root.

1.
Use the 1st working tape to store a stack of vertices outputs. Denote by  the output on top of .

To know when and which  we should use to combine the outputs, that is, to reduce the stack, we also use an auxiliary stack to store the vertices that give us this information. The vertices we store and the way they give us this information is explained further below.

2.
Use the 2nd working tape to store a stack of vertices. Denote by  the vertex on top of .

3.
Compute  in the 3rd working tape.

Since T is time constructible, the time to compute  is bounded by . By the inclusion

Image 14
, the space used by the 3rd working tape to compute  is bounded by .
One may argue that the present algorithm only works if some α is known. While this is true, one may simply try the algorithm for  until M outputs some . Since  is time bounded, this shall eventually happen and, by iterating over α alone, we only increase the running time.

4.
For each , arbitrarily order  in the 4th working tape. That is, make a sequence of the sets that are the images of δ. Then, a path  of N can be enumerated by  where  if  is the k-th child of . We are simply labeling the edges of the computation tree.

Since δ is finite, the space used by 4th working tape is constant.

5.
Use the 5th working tape to store  counters. Using each counter to store the index of a transition according to the order established in the last step, we can enumerate any path of N for x of depth less than or equal to .

Let b be the maximum number of children any vertex of a tree of N may have. Separating the counters with a special symbol, the space used by the 5th working tape to store the  counters is at most .

The way we enumerate the paths is similar to the way one may enumerate them when showing nondeterministic Turing machines are equivalent to deterministic Turing machines (e.g. in [2, p. 164]), but since here we already know the time-bound of  for x, we can iterate over them, in the next step, as in a depth-first search instead of as in a breadth-first search.

6.
For each enumeration e, do the following:

For example, if  and , then iterate e over .

(a)
Try to simulate, in the 6th working tape, N on x along the path enumerated by e.

Since the path enumerated by e has at most  edges, by the inclusion

Image 14
, the space used by the 6th tape is bounded by .
(b)
If e does not enumerate a valid path (when the simulation of the step above fails at some point because of an invalid transition), then accordingly increment the counters and continue to the next enumeration (go to step 6). If e enumerates a valid path with length less than , then take this into account when incrementing the counters and going to the next enumeration, for example, if  and 1111 enumerates a valid path of length 2 (11), then the next enumeration should be 1211 instead of 1112.

(c)
Let u be the last vertex of the path. If u is a halting configuration, then push the output tape content of u to the outputs stack. Otherwise, push ϕ to the outputs stack. In the first case, we are handling item 1 of Definition 2.3 and in the second case, we are handling item 2 of Definition 2.3.

(d)
Let w be the first ancestor of u such that w is a branch vertex. If there is no such w, then break (go to step 7). Observe this only happens when  does not branch on x, that is,  is deterministic on x. Otherwise, push w to the vertices stack.

Let 
 be a vertex between w and u. Note that, if there is any 
, by item 4 of Definition 2.3, 
 is equal to .

In the steps above (steps 6a → 6d), we have stacked an output not with its vertex but with the first branch ancestor of its vertex. Therefore, for every child of a branch vertex z, we will have its output stacked (on the outputs stack) with a copy of z (on the vertices stack). It is in the next step that we combine them and reduce the stack.

(e)
While  where h is the number of vertices on the vertices stack and , do the following:

Observe that we use 1-based numbering. So  is the top vertex and  is the bottom vertex.

The condition  means that we have evaluated all the r outputs of the r children of the branch vertex . We are ready to evaluate their combination. That is why we stack copies of branch vertices, because the number of copies of a branch vertex is what gives us the information of when we can evaluate its output and remove the outputs  of its children and its copies  from the stacks.

i.
Pop  and .

ii.
If all of  are ϕ, then push ϕ to the outputs stack and go to step 6(e)iv. This corresponds to item 1 of Definition 2.1.

iii.
For each subsequence of the permutations of , do the following:

A.
Simulate, in the 7th working tape, the machine  on the subsequence fixing the other inputs as ϕ. Bound the time by .

The reason we bound the time and try all of the subsequences of all permutations is because we are assuming that the running time of  is arbitrary and do not know for which or if there is any subsequence of the permutations of  such that  runs in

Image 7
.
Because we are bounding the time by  and by the inclusion

Image 14
, the space used by the 7th working tape is bounded by .
B.
If the output of the simulation is not ϕ, then push it to the outputs stack and break (go to step 6(e)iv). When evaluating a whole sequence and all of  are not ϕ, this corresponds to item 2 of Definition 2.1. When evaluating a proper subsequence or if at least one of  is ϕ, then this case corresponds to item 3 of Definition 2.1.

C.
If evaluating the last subsequence of the last permutation, then push ϕ to the outputs stack. Note that, we only know that the time to obtain the output of the root is less than or equal to . It could be that the time to obtain the output of one of its children is more than . In this case, by item 3 of Definition 2.1, the output of  is not needed to compute the output of the root.

iv.
If  is not the root of the computation tree, then push the first ancestor 
 of  such that 
 is a branch vertex to the vertices stack.

Notice that in step 6 we stack outputs and vertices in the same way we described above. In the supplementary material of this paper, we give an example and illustrate how the stacks are reduced.

7.
Copy  to the output tape and halt.”

To complete the proof, we show that the space used by the 1st and 2nd working tape (the stacks), is bounded by . Recall that b is the maximum number of children any vertex of a tree of N may have. By induction and assuming the worst case, a tree such that every internal vertex has b children, we show that the number of outputs stacked to compute the output of the root of a tree of depth d is :

1.
Base case: A tree of depth  has only the output of its only vertex, that is, the number of outputs stacked to compute the output of its root is 1 which is equal to .

2.
Inductive step: Assume the number of outputs stacked to compute the output of the root of a tree of depth d is . Since we are computing the outputs as in a depth-first search, the number of outputs stacked to compute the output of the root of a tree of depth  is the sum of the number of outputs stacked to compute the output of the root of a tree of depth d, that is, the number of outputs stacked to compute the output of its last child, and , that is, the number of outputs of its other children, which have already been computed. By assumption, the number of outputs stacked to compute the output of a tree of depth d is . Thus, the number of outputs stacked to compute the output of a tree of depth  is

By the induction above, the number of outputs stacked is bounded by the depth of the computation tree, that is, . For each output stored on the outputs stack, there is one vertex stored on the vertices stack and since  is  time-bounded and by the inclusion

Image 14
, each output or vertex uses at most  space. Hence, both the space used by the 1st and 2nd working tape are bounded by . Therefore, M is space-bounded by  and
Image 15
. □
Corollary 4.3

Image 16
.
Corollary 4.4



5. Future work
In the future, we hope to:

1.
Define classes and separate problems based on the complexity of their combinations: How does bounding the resources for the combinations influence the power of combining Turing machines? Which natural problems are in these classes? Of these natural problems, are they complete for their classes? Are there two

Image 18
-complete problems that are in distinct classes?
2.
Define the space complexity of our variant: First, to capture combining Turing machines of logarithmic space, we need to restrict the combinations to be computed by Turing machines with a read-only input tape and a write-once output tape (as it is normally done in log-space reductions, e.g. in [8, p. 88]). Then, we may use Example 3.2 and Theorem 3.1 of [5] as in the proof of Theorem 4.1 and modify M from the proof of Theorem 4.2 to relate the space complexity of combining Turing machines to deterministic time.

3.
Relate our variant to other computation models: For instance, we can give an extra random source to combining functions to intuitively simulate probabilistic Turing machines with combining Turing machines. Then, we may use combining Turing machines as a framework to describe, compose and study nondeterministic (as in Example 3.1), alternating (as in Example 3.2), counting (as in Example 3.3), metric (as in Example 3.4) and probabilistic Turing machines.

About the paper

This is part and fruit of the author's bachelor's thesis, written under the supervision of Prof. Jerusa Marchi at the Departamento de Informática e Estatística (INE) of the Universidade Federal de Santa Catarina (UFSC).