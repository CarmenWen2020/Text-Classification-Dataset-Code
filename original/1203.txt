Abstract
This paper introduces a new communication abstraction, called Set-Constrained Delivery Broadcast (SCD-broadcast), whose aim is to provide its users with an appropriate abstraction level when they have to implement objects or distributed tasks in an asynchronous message-passing system prone to process crash failures. This abstraction allows each process to broadcast messages and deliver a sequence of sets of messages in such a way that, if a process delivers a set of messages including a message m and later delivers a set of messages including a message , no process delivers first a set of messages including  and later a set of message including m.

After having presented an algorithm implementing SCD-broadcast, the paper investigates its programming power and its computability limits. On the “power” side it presents SCD-broadcast-based algorithms, which are both simple and efficient, building objects (such as snapshot and conflict-free replicated data types), and distributed tasks. On the “computability limits” side it shows that SCD-broadcast and read/write registers are computationally equivalent.


Keywords
Abstraction
Asynchronous system
Communication abstraction
Communication pattern
onflict-free replicated data type
Design simplicity
Distributed task
Linearizability
Message-passing system
Process crash
Read/write atomic registerS
equential consistency
Snapshot object

1. Introduction
Programming abstractions. Informatics is a science of abstractions, and a main difficulty consists in providing users with a “desired level of abstraction and generality – one that is broad enough to encompass interesting new situations, yet specific enough to address the crucial issues” as expressed in [19]. When considering sequential computing, functional programming and object-oriented programming are well-know examples of what means “desired level of abstraction and generality”.

In the context of asynchronous distributed systems where the computing entities (processes) communicate –at the basic level– by sending and receiving messages through an underlying communication network, and where some of them can experience failures, a main issue consists in finding appropriate communication-oriented abstractions, where the meaning of the term “appropriate” is related to the problems we intend to solve. Solving a problem at the send/receive abstraction level is similar to the writing of a program in a low-level programming language. Programmers must be provided with abstractions that allow them to concentrate on the problem they solve and not on the specific features of the underlying system. This is not new. Since a long time, high level programming languages have proved the benefit of this approach. From a synchronization point of view, this approach is the one promoted in software transactional memory [37], whose aims is to allow programmers to focus on the synchronization needed to solve their problems and not on the way this synchronization must be implemented (see the textbooks [21], [33]).

If we consider specific coordination/cooperation problems, “matchings” between problems and specific communication abstractions are known. One of the most famous examples concerns the consensus problem whose solution rests on the total order broadcast abstraction (also called atomic broadcast). Another “matching” example is the causal message delivery broadcast abstraction [12], [35], which allows for a very simple implementation of a causal read/write memory [2].1

Aim of the paper. The aim of this paper is to introduce and investigate a high level communication abstraction which allows for simple and efficient implementations of concurrent objects and distributed tasks, in the context of asynchronous message-passing systems prone to process crash failures. The concurrent objects in which we are interested are defined by a sequential specification [22] (e.g., a queue). Differently, a task extends to the distributed context the notion of a function [11], [30]. It is defined by a mapping from a set of input vectors to a set of output vectors, whose sizes are the number of processes. An input vector I defines the input value  of each process 
, and, similarly, an output vector O defines the output  of each process 
. Agreement problems such as consensus and k-set agreement are distributed tasks. What makes the implementation of a task difficult is the fact that each process knows only its input, and, due to net effect of asynchrony and process failures, no process can distinguish if another process is very slow or crashed. The difficulty results in an impossibility for consensus [18], even in a system in which at most one process may crash.

A new broadcast abstraction. The Set-Constrained Delivery broadcast (in short SCD-broadcast) communication abstraction proposed in the paper allows a process to broadcast messages, and to deliver sets of messages (instead of a single message) in such a way that, if a process 
 delivers a message set  containing a message m, and later delivers a message set 
 containing a message 
, then no process 
 can deliver first a set containing 
 and later another set containing m. Let us notice that 
 is not prevented from delivering m and 
 in the same set. Moreover, SCD-broadcast imposes no constraint on the order in which a process must process the messages it receives in a given message set.

After having defined SCD-broadcast, the paper presents an implementation of it in asynchronous systems where a minority of processes may crash. This assumption is actually a necessary and sufficient condition to cope with the net effect of asynchrony and process failures (see below). The SCD-broadcast of an application message generates 
 implementation messages, and assuming an upper bound Δ on message transfer delays and zero processing time, its time complexity is upper bounded by 2Δ time units (by “time complexity” we mean the time elapsed between the SCD-broadcast of an application message m and the latest time at which m is locally delivered at the application layer by all the processes that have not crashed).

Implementing objects and tasks. Then, the paper addresses two fundamental issues of SCD-broadcast: its abstraction power and its computability limits. As far as its abstraction power is concerned, i.e., its ability and easiness to implement atomic (linearizable) or sequentially consistent concurrent objects [22], [28] and read/write solvable distributed tasks, the paper presents, on the one side, two algorithms implementing atomic objects (namely a snapshot object [1], [3], and a distributed increasing/decreasing counter), and, on the other side, an algorithm solving the lattice agreement task [6], [17].

The two concurrent objects (snapshot and counter) have been chosen because they are encountered in many applications, and are also good representatives of the class of objects identified in [4]. The objects of this class are characterized by the fact that each pair  and  of their operations either commute (i.e., in any state, executing  before  leads to the same state as executing  before , as is the case for a counter), or any of  and  can overwrite the other (e.g., executing  before  leads to the same state as executing  alone). Our implementation of a counter can be adapted for all objects with commutative operations, and our implementation of the snapshot object illustrates how overwriting operations can be obtained directly from the SCD-broadcast abstraction. Concerning these objects, it is also shown that a slight change in the algorithms allows us to obtain implementations (with a smaller cost) in which the consistency condition is weakened from linearizability to sequential consistency [27].

In the case of read/write solvable tasks, SCD-broadcast shows how the concurrency inherent (but hidden) in a task definition can be easily mastered and solved.

A distributed software engineering dimension. All the algorithms presented in the paper are based on the same communication pattern. As far as objects are concerned, the way this communication pattern is used brings to light two genericity dimensions of the algorithms implementing them. One is on the variety of objects that, despite their individual features (e.g., snapshot vs counter), have very similar SCD-broadcast-based implementations (actually, they all have the same communication pattern-based structure). The other one is on the consistency condition they have to satisfy (linearizability vs sequential consistency).

On programming languages for distributed computing. Differently from sequential computing for which there are plenty of high level languages (each with its idiosyncrasies), there is no specific language for distributed computing. Instead, addressing distributed settings is done by the enrichment of sequential computing languages with high level communication abstractions. When considering asynchronous systems with process crash failures, total order broadcast is one of them. SCD-broadcast is a candidate to be one of them, when one has to implement read/write solvable objects and distributed tasks.

The computability limits of SCD-broadcast. The paper also investigates the computability power of the SCD-broadcast abstraction, namely it shows that SCD-broadcast and atomic read/write registers (or equivalently snapshot objects) have the same computability power in asynchronous systems prone to process crash failures. Everything that can be implemented with atomic read/write registers can be implemented with SCD-broadcast, and vice versa.

As read/write registers (or snapshot objects) can be implemented in asynchronous message-passing systems where only a minority of processes may crash [5], it follows that the proposed algorithm implementing SCD-broadcast is resilience-optimal in these systems. From a theoretical point of view, this means that the consensus number of SCD-broadcast is 1 (the weakest possible).

Roadmap. The paper is composed of 10 sections. Section 2 defines the SCD-broadcast abstraction and the associated communication pattern used in all the algorithms presented in the paper. Section 4 presents a resilience-optimal algorithm implementing SCD-broadcast in asynchronous message-passing systems prone to process crash failures, while Section 5 adopts a distributed software engineering point of view and presents a communication pattern associated with SCD-broadcast. Then, Sections 6-8 present SCD-broadcast-based algorithms for concurrent objects and tasks. Section 9 focuses on the computability limits of SCD-broadcast. Finally, Section 10 concludes the paper.

Remark

It is worth noticing that a self-stabilizing version of the SCD algorithm presented in this article is described in [29], and an extension of it where up to  processes may commit Byzantine failures is described in [10]. It is still an open problem to find an SCD algorithm coping with up to  Byzantine processes.

2. The SCD-broadcast communication abstraction
Process model. The computing model is composed of a set of n asynchronous sequential processes, denoted 
, ..., 
. “Asynchronous” means that each process proceeds at its own speed, which can be arbitrary and always remains unknown to the other processes.

A process may halt prematurely (crash failure), but it executes its local algorithm correctly until it crashes (if it ever does). The model parameter t denotes the maximal number of processes that may crash in a run r. A process that crashes in a run is said to be faulty in r. Otherwise, it is non-faulty.

Definition of SCD-broadcast. The set-constrained delivery broadcast abstraction (SCD-broadcast) provides the processes with one operation  and one event . The operation takes a message m to broadcast as input parameter. When the event is triggered at a process 
, it dispenses a non-empty set of messages  to 
. Using a classical terminology, when a process invokes the operation , we say that it “scd-broadcasts a message m”. Similarly, when  is triggered at a process, we say that it “scd-delivers the set of messages ”. By a slight abuse of language, when we are interested in a message m, we say that a process “scd-delivers the message m” when actually it scd-delivers a message set  containing m.

SCD-broadcast is defined by the following set of properties, where we assume –without loss of generality– that all the messages that are scd-broadcast are different.

•
Validity. If a process scd-delivers a set containing a message m, then m was scd-broadcast by a process.

•
Integrity. A message is scd-delivered at most once by each process.

•
MS-Ordering. Let 
 be a process that scd-delivers first a message set 
 and later a message set 
. For any pair of messages 
 and 
, no process 
 scd-delivers first a message set 
 containing 
 and later a message set 
 containing m.

•
Termination-1. If a non-faulty process scd-broadcasts a message m, it terminates its scd-broadcast invocation and scd-delivers a message set containing m.

•
Termination-2. If a process scd-delivers a message m, every non-faulty process scd-delivers a message set containing m.

Termination-1 and Termination-2 are classical liveness properties (found for example in Uniform Reliable Broadcast [9], [34]). The other ones are safety properties. Validity and Integrity are classical communication-related properties. The first states that there is neither message creation nor message corruption, while the second states that there is no message duplication.

The MS-Ordering property is new, and characterizes SCD-broadcast. It states that the contents of the sets of messages scd-delivered at any two processes are not totally independent: the sequence of sets scd-delivered at a process 
 and the sequence of sets scd-delivered at a process 
 must be mutually consistent in the sense that a process 
 cannot scd-deliver first 
 and later 
, while another process 
 scd-delivers first 
 and later 
. Let us nevertheless observe that if 
 scd-delivers first 
 and later 
, 
 may scd-deliver m and 
 in the same set of messages.

Let us remark that, if the MS-Ordering property is suppressed and messages are scd-delivered one at a time, SCD-broadcast boils down to the well-known Uniform Reliable Broadcast abstraction [13], [34].

An example. Let 
, 
, 
, 
, 
, 
, 
 and 
 be messages that have been scd-broadcast by different processes. Processes deliver sets of messages and do not deliver more than one set at once; whereas there is no particular order within each set. The following scd-deliveries of message sets by 
, 
 and 
 respect the definition of SCD-broadcast:

•
at 
: 
, 
, 
, 
.

•
at 
: 
, 
, 
, 
, 
.

•
at 
: 
, 
, 
, 
.

Differently, due to the scd-deliveries of the sets including 
 and 
, the following scd-deliveries by 
 and 
 do not satisfy the MS-broadcast property:
•
at 
: 
, 
, ...

•
at 
: 
, 
, ...

A containment property. Let 
 denote the ℓ-th message set scd-delivered by 
. Hence, at some time, 
 scd-delivered the sequence of message sets 
. Let 
. The following Containment property follows directly from the MS-Ordering and Termination-2 properties: : 
.

Partial order on messages created by the message sets. The MS-Ordering and Integrity properties establish a partial order on the set of all the messages, defined as follows. Let 
 be the local message delivery order at process 
 defined as follows: 
 if 
 scd-delivers the message set containing m before the message set containing 
. As no message is scd-delivered twice, it is easy to see that 
 is a partial order (locally known by 
). The containment property implies that there is a total order (which remains unknown to the processes) on the whole set of messages, that complies with the partial order 
. This is where SCD-broadcast can be seen as a weakening of total order broadcast.

3. Underlying communication network
Send/receive asynchronous network. Each pair of processes communicate through two uni-directional channels on which they send and receive messages. Hence, the communication network is a complete network: any process 
 can directly send a message to any process 
 (including itself). A process 
 invokes the operation “ type(m)  
” to send to 
 the message m, whose type is type. The operation “ type()  
” allows 
 to receive from 
 a message whose type is type.

Each channel is reliable (no loss, corruption, nor creation of messages), not necessarily FIFO, and asynchronous (while the transit time of each message is finite, there is no upper bound on message transit times) Let us notice that, due to process and message asynchrony, no process can know if another process crashed or is only very slow.

Uniform FIFO-broadcast abstraction. To simplify the presentation, and without loss of generality, we consider that the system is equipped with a FIFO-broadcast abstraction. Such an abstraction can be built on top of the previous basic system model without enriching it with additional assumptions (see e.g. [34]). It is defined by an operation  and an event , which satisfy the properties of Uniform Reliable Broadcast (Validity, Integrity, Termination-1, and Termination-2, with the same definitions as in SCD-broadcast), plus the following message ordering property.

•
FIFO-Order. For any pair of processes 
 and 
, if 
 fifo-delivers first a message m and later a message 
, both from 
, no process fifo-delivers 
 before m.

4. An implementation of SCD-broadcast
This section shows that the SCD-broadcast communication abstraction is not an oracle-like object (oracles allow us to extend our understanding of computing, but cannot be implemented). It describes an implementation of SCD-broadcast in an asynchronous send/receive message-passing system in which any minority of processes may crash. This system model is denoted 
 (where 
 stands for “Crash Asynchronous Message-Passing” and  is its restriction on failures). As  is the weakest assumption on process failures that allows a read/write register to be built on top of an asynchronous message-passing system [5],2 and SCD-broadcast and read/write registers are computationally equivalent (as shown in Sections 6 and 9), the proposed implementation is optimal from a resilience point of view.

4.1. Algorithm
This section describes Algorithm 1, which implements SCD-broadcast in 
. From a terminology point of view, an application message is a message that has been scd-broadcast by a process, while a protocol message is an implementation message generated by the algorithm.

Algorithm 1
Download : Download high-res image (187KB)
Download : Download full-size image
Algorithm 1. An implementation of SCD-broadcast in 
 (code for pi).

Local metadata quadruplets. For each application message m, each process stores a quadruplet  whose fields have the following meaning.

•
 contains an application message m,

•
 contains the id of the sender of ,

•
 contains the local date (sequence number) associated with m by its sender. Hence, the pair  is the identity of the application message m, denoted .

•
 is an array of size n, initialized to . Then,  will contain the sequence number associated with m by 
 when it broadcast the message forward_msg. This last field is crucial in the scd-delivery by the process 
 of a message set containing m.

Local variables at a process 
. Each process 
 manages the following local variables.

•
: buffer (initially empty) where the quadruplets containing messages that have been fifo-delivered but not yet scd-delivered in a message set are stored.

•
: set of quadruplets containing messages to be scd-delivered.

•
: local logical clock which takes the values 0, 1, 2, ..., that measure the local progress of 
. Each application message scd-broadcast by 
 is identified by a pair , where sn is the current value of 
.

•
: array of clock values; 
 is the greatest lock value x such that the application message m identified  has been scd-delivered by 
.

Protocol message. The algorithm uses a single type of protocol message denoted forward_msg
. Such a message is made up of five fields: the first field is an associated application message m, the second and third form a pair  that is the identity of the application message and the fourth and fifth form a pair 
 that describes the local progress (as captured by 
) of the forwarder process 
 when it fifo-broadcast this protocol message to the other processes by invoking  forward_msg
 (line 11).

Operation . When 
 invokes the operation , where m is an application message, it executes the internal operation 
, which initializes the algorithm, and waits until it has no more message from itself pending in 
, which means it has scd-delivered a set containing m (lines 19 and 20).

Uniform fifo-broadcast of a message forward_msg. When a process 
 fifo-delivers a protocol message forward_msg
, it first invokes the internal operation 
. In addition to other statements, the first fifo-delivery of such a message by a process 
 entails its participation in the uniform reliable fifo-broadcast of this message (lines 5 and 11). In addition to the invocation of , the fifo-delivery of forward_msg() also invokes , which strives to scd-deliver a message set (lines 4).

The core of the algorithm. Expressed with the relations 
, , introduced in Section 2, the main issue of the algorithm is to ensure that, if there are two message m and 
 and a process 
 such that 
, then there is no 
 such that 
. To this end, a process 
 is allowed to scd-deliver a message m before a message 
 only if it knows that a majority of processes 
 have fifo-delivered a protocol message forward_msg before a protocol message forward_msg
; 
 knows it either (i) because it fifo-delivered from 
 a message forward_msg but not yet a message forward_msg
, or (ii) because it fifo-delivered from 
 both forward_msg and forward_msg
 and the sending date smn is smaller than the sending date 
. The MS-Ordering property follows then from the impossibility that a majority of processes “sees m before 
”, while another majority “sees 
 before m”.

Internal operation . This operation can be seen as an enrichment (with the fields g and 
) of the reliable fifo-broadcast implemented by the protocol messages forward_msg
. Considering such a message forward_msg
, m was scd-broadcast by 
 at its local time 
, and relayed by the forwarding process 
 at its local time 
. If 
, 
 has already scd-delivered a message set containing m (see lines 18 and 20). If 
, there are two cases defined by the predicate of line 6.

•
No quadruplet  in 
 is such that . In this case, 
 creates a quadruplet associated with m, and adds it to 
 (lines 8-10). Then, 
 participates in the fifo-broadcast of m identified by 
. (line 11) and records its local progress by increasing 
 (line 12).

•
There is a quadruplet  in 
 associated with m, i.e., 
. In this case, 
 assigns 
 to  (line 7), thereby indicating that m was known and forwarded by 
 at its local time 
.

Internal operation . When a process 
 executes , it first computes the set 
 of the quadruplets  containing application messages m which have been seen by a majority of processes (line 15). From 
's point of view, a message has been seen by a process 
 if  has been set to a finite value (line 7).

As indicated in a previous paragraph, if a majority of processes received first a message forward_msg carrying 
 and later another message forward_msg carrying m, it might be that some process 
 scd-delivered a set containing 
 before scd-delivering a set containing m. Therefore, 
 must avoid scd-delivering a set containing m before scd-delivering a set containing 
. This is done at line 16, where 
 withdraws the quadruplet  corresponding to m if it cannot deliver 
 yet (i.e. the corresponding 
 is not in 
) or it does not have the proof that the situation cannot happen, i.e. no majority of processes saw the message corresponding to  before the message corresponding to 
 (this is captured by the predicate 
 
).

If 
 is not empty after it has been purged (lines 16-17), 
 computes a message set to scd-deliver. This set  contains all the application messages in the quadruplets of 
 (line 20). These quadruplets are withdrawn from 
 (line 18). Moreover, before this scd-delivery, 
 needs to updates 
 for all the entries such that  where 
 (line 18). This update is needed to ensure that the future uses of the predicate of line 17 are correct.

4.2. Cost and proof of correctness
Lemma 1 Validity

If a process scd-delivers a message set containing m, some process cd-broadcast m.

Proof

If a process 
 scd-delivers a set containing a message m, it previously added into 
 a quadruplet  such that  (line 10), for which it follows that it fifo-delivered a protocol message forward_msg. Due to the fifo-validity property, it follows that a process generated the fifo-broadcast of this message, which originated from an invocation of . 

Lemma 2 Integrity

No process scd-delivers the same message twice.

Proof

Let us observe that, due to the wait statement at line 2, and the increase of 
 at line 15 between two successive scd-broadcast by a process 
, no two application messages can have the same identity . It follows that there is a single quadruplet  that can be added to 
, and this is done only once (line 10). Finally, let us observe that this quadruplet is suppressed from 
, just before m is scd-delivered (line 19-20), which concludes the proof of the lemma. 

Lemma 3

If 
 fifo-broadcasts forward_msg
 (i.e., executes line 11), each non-faulty process 
 executes once  forward_msg
.

Proof

Let 
 be a correct process. First, we prove that 
 broadcasts a message forward_msg
. As 
 is non-faulty, 
 will eventually receive the message sent by 
. At that time, if 
, after the condition on line 6 and whatever its result, 
 contains a quadruplet  with  and 
. That  was inserted at line 10 (possibly after the reception of a different message), just before 
 sent a message forward_msg
 at line 11. Otherwise, 
 was incremented on line 18, when validating some 
 added to 
 after 
 received a (first) message forward_msg
 from 
. Because the messages forward_msg() are fifo-broadcast (hence they are delivered in their sending order), 
 sent message forward_msg
 before forward_msg
, and all other processes only forward messages, 
 received forward_msg
 from 
 before the message forward_msg
. At that time, 
, so the previous case applies.

After 
 broadcasts its message forward_msg
 on line 11, there is a 
 with 
, until it is removed on line 16 and 
. Therefore, one of the conditions at lines 5 and 6 will stay false for the stamp  and 
 will never execute line 11 with the same stamp 
 later. 

Lemma 4 MS-Ordering

Let 
 be a process that scd-delivers a set 
 containing a message m and later scd-delivers a set 
 containing a message 
. No process 
 scd-delivers first a set 
 containing 
 and later a message set 
 containing m.

Proof

Let us suppose there are two messages m and 
 and two processes 
 and 
 such that 
 scd-delivers a set 
 containing m and later scd-delivers a set 
 containing 
 and 
 scd-delivers a set 
 containing 
 and later scd-delivers a set 
 containing m.

When m is delivered by 
, there is an element 
 such that  and because of line 15, 
 has received a message forward_msg from more than 
 
 processes.

•
If there is no element 
 such that 
, since 
 has not been delivered by 
 yet, 
 has not received a message forward_msg
 from any process (lines 10 and 19). Hence, because the communication channels are FIFO, more than 
 
 processes have sent a message forward_msg before sending a message forward_msg
.

•
Otherwise, 
 after line 16. As the communication channels are FIFO, more than half of the processes have sent a message forward_msg before a message forward_msg
.

Using the same reasoning, it follows that when 
 is delivered by 
, more than 
 
 processes have sent a message forward_msg
 before sending a message forward_msg. There exists a process 
 in the intersection of the two majorities, that has (a) sent forward_msg before sending forward_msg
 and (b) sent forward_msg
 before sending a message forward_msg. However, it follows from Lemma 3 that 
 can send a single message forward_msg
 and a single message forward_msg, which leads to a contradiction. 

Lemma 5

If a non-faulty process executes  forward_msg
 (line 11), it scd-delivers a message set containing m.

Proof

Let 
 be a non-faulty process. For any pair of messages  and 
 ever inserted in 
, let  and 
. Let 
 be the dependency relation defined as follows: 
 
 (i.e. the dependency does not exist if 
 knows that a majority of processes have seen the first update –due to 
– before the second –due to ). Let 
 denote the transitive closure of 
.

Let us suppose (by contradiction) that the timestamp 
 associated with the message m (carried by the protocol message forward_msg
 fifo-broadcast by 
), has an infinity of predecessors according to 
. As the number of processes is finite, an infinity of these predecessors have been generated by the same process, let us say 
. Let 
 be the infinite sequence of the timestamps associated with the invocations of the  issued by 
. The situation is depicted by Fig. 1.

Fig. 1
Download : Download high-res image (56KB)
Download : Download full-size image
Fig. 1. Message pattern introduced in Lemma 5.

As 
 is non-faulty, 
 eventually receives a message forward_msg
, which means 
 broadcast an infinity of messages forward_msg
 after having broadcast the message forward_msg
. Let 
 and 
 be the timestamps associated with the next two messages scd-broadcast by 
, with 
. By hypothesis, we have 
. Moreover, all processes received their first message forward_msg
 before their first message forward_msg
, so 
. Let us express the path 
:

In the time interval starting when 
 sent the message forward_msg
 and finishing when it sent the message forward_msg
, the waiting condition of line 2 became true, so 
 scd-delivered a set containing the message , and according to Lemma 1, no set containing the message . Therefore, there is an index l such that process 
 delivered sets containing messages associated with a timestamp 
 for all 
 but not for 
. Because the channels are FIFO and thanks to lines 15 and 16, it means that a majority of processes have sent a message forward_msg
 before a message forward_msg
, which contradicts the fact that 
.

Let us suppose a non-faulty process 
 has fifo-broadcast a message forward_msg
 (line 10). It inserted a quadruplet  with timestamp 
 on line 9 and by what precedes, 
 has a finite number of predecessors 
 according to 
. As 
 is non-faulty, according to Lemma 3, it eventually receives a message forward_msg
 for all  and from all non-faulty processes, which are in majority.

Let pred be the set of all quadruplets 
 such that 
. Let us consider the moment when 
 receives the last message forward_msg
 sent by a correct process 
. For all 
, either 
 has already been delivered or 
 is inserted 
 on line 15. Moreover, no 
 will be removed from 
, on line 16, as the removal condition is the same as the definition of 
. In particular for 
, either m has already been scd-delivered or m is present in 
 on line 17 and will be scd-delivered on line 20. 

Lemma 6 Termination-1

If a non-faulty process scd-broadcasts a message m, it scd-delivers a message set containing m.

Proof

If a non-faulty process 
 scd-broadcasts a message m, it executes the procedure 
 (lines 1 and 3). Similarly to Lemma 3, as no message forward_msg
 was previously broadcast, 
 and there is no 
 such that 
. Therefore, 
 fifo-broadcasts the message forward_msg
 at line 11). Then, due to Lemma 5, it scd-delivers a message set containing m. 

Lemma 7 Termination-2

If a process scd-delivers a message m, every non-faulty process scd-delivers a message set containing m.

Proof

Let 
 be a process 
 that scd-delivers a message m. At line 20, there is a quadruplet 
 such that . At line 15, 
, and  was inserted in 
 at line 10, just before 
 fifo-broadcast the message forward_msg
. By Lemma 3, every non-faulty process 
 sends a message forward_msg
, so by Lemma 5, 
 scd-delivers a message set containing m. 

Theorem 1

Algorithm 1 implements the SCD-broadcast communication abstraction in 
. Moreover, each invocation of the operation  requires 
 protocol messages. If there is an upper bound Δ on messages transfer delays (and local computation times are equal to zero), each SCD-broadcast takes at most 2Δ time units.

Proof

The proof follows from Lemma 1 (Validity), Lemma 2 (Integrity), Lemma 4 (MS-Ordering), Lemma 6 (Termination-1), and Lemma 7 (Termination-2).

The 
 message complexity comes from the fact that, due to the predicates of line 5 and 6, each application message m is forwarded at most once by each process (line 11). The 2Δ follows from the same argument. 

5. An SCD-broadcast-based communication pattern
All the algorithms implementing concurrent objects and tasks, which are presented in this paper, are based on the same communication pattern described by Algorithm 2. This pattern involves each process, either as a client (when it invokes an operation), or as a server (when it scd-delivers a message set).

Algorithm 2
Download : Download high-res image (157KB)
Download : Download full-size image
Algorithm 2. Communication pattern (Code for pi).

When a process 
 invokes an operation , it executes once the lines 1-3 for a task, and 0, 1, or 2 times for an operation on a concurrent object. In this last case, this number of times depends on the consistency condition which is implemented (linearizability [22] or sequential consistency [27]).

All the messages sent by a process 
 are used to synchronize its local data representation of the object, or its local view of the current state of the task. This synchronization is realized by the Boolean 
 and the parameter i carried by every message (lines 1, 3, and 6): 
 is blocked until the message it scd-broadcast just before is scd-delivered. The values carried by a message msg are related to the object/task that is implemented, and may require local computation.

It appears that the combination of this communication pattern and the properties of SCD-broadcast provides us with a single simple framework that allows for correct implementations of a specific family of concurrent objects and tasks.

The next three sections describe algorithms implementing a snapshot object, a counter object, and the lattice agreement task, respectively. All these algorithms consider the system model 
 enriched with SCD-broadcast (denoted 
[SCD-broadcast]), and use the previous communication pattern.

6. The power of SCD-broadcast: snapshot object
6.1. Snapshot object
Definition

The snapshot object was introduced in [1], [3]. A snapshot object is an array  of atomic read/write registers which provides the processes with two operations, denoted  and . The invocation of , where , by a process 
 assigns atomically v to . The invocation of  returns the value of  as if it was executed instantaneously. Hence, in any execution of a snapshot object, its operations  and  are linearizable.

The underlying atomic registers can be Single-Reader (SR) or Multi-Reader (MR) and Single-Writer (SR) or Multi-Writer (MW). We consider only SWMR and MWMR registers. If the registers are SWMR the snapshot is called SWMR snapshot (and we have then ). Moreover, we always have , when 
 invokes . If the registers are MWMR, the snapshot object is called MWMR.

Implementations based on read/write registers. Implementations of both SWMR and MWMR snapshot objects on top of read/write atomic registers have been proposed (e.g., [1], [3], [24], [25]). The “hardness” to build snapshot objects in read/write systems and associated lower bounds are presented in the survey [16]. The best algorithm known ([7]) to implement an SWMR snapshot requires  read/write on the base SWMR registers for both  and . As far as MWMR snapshot objects are concerned, there are implementations where each operation has an  cost.3

As far as the construction of an SWMR (or MWMR) snapshot object in crash-prone asynchronous message-passing systems where  is concerned, it is possible to stack two constructions: first an algorithm implementing SWMR (or MWMR) atomic read/write registers (e.g., [5])), and, on top of it, an algorithm implementing an SWMR (or MWMR) snapshot object. This stacking approach provides objects whose operation cost is 
 messages for SWMR snapshot, and 
 messages for MWMR snapshot.

6.2. An algorithm for atomic MWMR snapshot in 
[SCD-broadcast]
Local representation of REG at a process 
. At each process 
,  is represented by three local variables 
 (data part), plus 
 and 
 (control part).

•
 is a Boolean variable.

•
 contains the current value of , as known by 
.

•
 is an array of timestamps associated with the values stored in 
. A timestamp is a pair made of a local clock value and a process identity. Its initial value is . The fields associated with 
 are denoted 
.

Timestamp-based order relation. We consider the classical lexicographical total order relation on timestamps, denoted 
. Let  and . We have 
.

Algorithm 3: snapshot operation. This algorithm consists of one instance of the communication pattern introduced in Section 5 (line 1), followed by the return of a copy of the local value of 
 (line 2). The message sync(i), which is scd-broadcast is a pure synchronization message, whose aim is to entail the refreshment of the value of 
 (lines 5-11) which occurs before the setting of 
 to true (line 12).

Algorithm 3
Download : Download high-res image (119KB)
Download : Download full-size image
Algorithm 3. Construction of an MWMR snapshot object 
 (code for pi).

Algorithm 3: write operation. (Lines 3-4) When a process 
 wants to assign a value v to , it invokes . This operation is made up of two instances of the communication pattern. The first one (line 3) is a re-synchronization, as in the snapshot operation, whose side effect is here to provide 
 with an up-to-date value of 
. In the second instance of the communication pattern, 
 associates the timestamp 
 with v, and scd-broadcasts the data/control message write
. In addition to informing the other processes on its write of , this message write() acts as a re-synchronization message, exactly as a message sync(i). When this synchronization terminates (i.e., when the Boolean 
 is set to true), 
 returns from the write operation.

Algorithm 3: scd-delivery of a set of messages. When process 
 scd-delivers a message set, namely, it first looks if there are messages write(). If it is the case, for each register  for which there are messages write (line 5), 
 computes the maximal timestamp carried by these messages (line 6), and updates accordingly its local representation of  (lines 7-10). Finally, if 
 is the sender of one of these messages (write() or sync()), 
 is set to true, which terminates 
's re-synchronization (line 12).

Remark

Linearizability imposes that, when two snapshot operations are not concurrent, the second operation returns a value at least as recent as the first one. In [5], this is done by forcing the readers to mimic the algorithm executed by the writers, which is usually summarized by the adage “readers must write”. This step is not required in Algorithm 3 because the sync() message sent during a snapshot operation by 
 (Line 1) serves two purposes: 1) it gathers all write messages sent by write operations that have already terminated when 
 started its snapshot operation, and 2) it orders, by transitivity, all sync() messages sent by subsequent snapshot operations with all write messages received by 
 before the end of its snapshot operation.

6.3. Proof of Algorithm 3
As they are implicitly used in the proofs that follow, let us recall the properties of the SCD-broadcast abstraction. The non-faulty processes scd-deliver the same messages (exactly one each), and each of them was scd-broadcast. As a faulty process behaves correctly until it crashes, it scd-delivers a subset of the messages scd-delivered by the non-faulty processes.

Without loss of generality, we assume that there is an initial write operation issued by a non-faulty process. Moreover, if a process crashes in a snapshot operation, its snapshot is not considered. If a process crashes in a write operation, its write is considered only if the message write() it sent at line 4 is scd-delivered to at least one non-faulty process (and by the Termination-2 property, to all non-faulty processes). Let us notice that a message sync() scd-broadcast by a process 
 does not modify the local variables of the other processes.

Lemma 8

If a non-faulty process invokes an operation, it returns from its invocation.

Proof

Let 
 be a non-faulty process that invokes a read or write operation. By the Termination-1 property of SCD-broadcast, it eventually receives a message set containing the message sync() or write() it sends at line 2, 3 or 4. As all the statements associated with the scd-delivery of a message set (lines 5-12) terminate, it follows that the synchronization Boolean 
 is eventually set to true. Consequently, 
 returns from the invocation of its operation. 

Extension of the relation 
. The relation 
 is extended to a partial order on arrays of timestamps, denoted 
, defined as follows: 
. Moreover, 
.

Definition

Let 
 be the set of the array values taken by 
 at line 12 (end of the processing of a message set by process 
). Let 
.

Lemma 9

The order 
 is total on TSA.

Proof

Let us first observe that, for any i, all values in 
 are totally ordered (this comes from 
 whose entries can only increase, lines 7 and 10). Hence, let  be an array value of 
, and  an array value of 
, where .

Let us assume, by contradiction, that 
 and 
. As 
, there is a registers r such that . According to lines 7 and 9, there is a message write received by 
 when 
 and not received by 
 when 
 (because ). Similarly, there is a message write
 received by 
 when 
 and not received by 
 when 
. This situation contradicts the MS-Ordering property, from which we conclude that either 
 or 
. 

Definitions

Let us associate a timestamp  with each write operation as follows. Let 
 be the invoking process;  is the timestamp of v as defined by 
 at line 4, i.e., 
.

Let  and  be any two operations. The relation ≺ on the whole set of operations is defined as follows:  if  terminated before  started. It is easy to see that ≺ is a real-time-compliant partial order on all the operations.

Lemma 10

No two write operations on the same register  and  have the same timestamp, and  ⇒ 
.

Proof

Let  and  be the timestamp of  and , respectively. If ,  and  have been produced by different processes, and their timestamp differ at least in their process identity.

So, let us consider that the operations have been issued by the same process 
, with  first. As  precedes , 
 first (line 4) invoked  write, and later write. It follows that these SCD-broadcast invocations are separated by a local reset of the Boolean 
 at line 4. Moreover, before the reset of 
 due to the scd-delivery of the message

Image 2
, we have 
 (lines 6-10). Hence, we have 
 before the reset of 
 (line 12). Then, due to the “+1” at line 4, write is such that , which concludes the proof of the first part of the lemma.
Let us now consider that . If  and  have been produced by the same process we have  from the previous reasoning. So let us assume that they have been produced by different processes 
 and 
. Before terminating  (when the Boolean 
 is set true at line 12), 
 received a message set 
 containing the message write. When 
 executes , it first invokes  sync(j) at line 3. Because  terminated before  started, this message sync(j) cannot belong to 
.

Due to Integrity and Termination-2 of SCD-broadcast, 
 eventually scd-delivers exactly one message set 
 containing write. Moreover, it also scd-delivers exactly one message set 
 containing its own message sync(j). On the other side, 
 scd-delivers exactly one message set 
 containing the message sync(j). It follows from the MS-Ordering property that, if 
, 
 cannot scd-deliver 
 before 
. Then, whatever the case (
 or 
 is scd-delivered at 
 before 
), it follows from the fact that the messages write() are processed (lines 5-11) before the messages sync(j) (line 12), that we have 
 when 
 is set to true. It then follows from line 4 that , which concludes the proof of the lemma. 

Associating timestamp arrays with operations. Let us associate a timestamp array  with each operation  as follows.

•
Case . Let 
 be the invoking process;  is the value of 
 when 
 returns from the snapshot operation (line 2).

•
Case . Let 
, where A is a set of array values, denote the smallest array value of A according to 
. Let 
. Hence,  is the first  of TSA, that reports the operation .

Lemma 11

Let  and 
 be two distinct operations such that 
. We have 
. Moreover, if 
 is a write operation, we have 
.

Proof

Let 
 and 
 be the processes that performed  and 
, respectively. Let syncj be the sync(j) message sent by 
 (at line 1 or 3) during the execution of 
. Let 
 be the value of 
 when  terminates (line 2 or 4), and 
 the value of 
 when 
 becomes true for the first time after 
 sent syncj (line 1 or 3). Let us notice that 
 and 
 are elements of the set TSA.

According to lines 7 and 10, for all r, 
 is the largest timestamp carried by a message write received by 
 in a message set before  terminates. Let m be a message such that there is a set sm scd-delivered by 
 before it terminated . As 
 sent syncj after 
 terminated, 
 did not receive any set containing syncj before it terminated . By the properties Termination-2 and MS-Ordering, 
 received message m in the same set as syncj or in a message set 
 received before the set containing syncj. Therefore, we have 
.

If  is a snapshot operation, then 
. Otherwise, . As 
 has to wait until it processes a set of messages including its write() message (and executes line 12), we have 
. Finally, due to the fact that 
 and Lemma 9, we have 
.

If 
 is a snapshot operation, then 
 (line 2). Otherwise,  and thanks to the +1 in line 4, 
 is strictly smaller than 
 which, due to Lemma 9, implies 
.

It follows that, in all cases, we have
 and if 
 is a write operation, we have
 which concludes the proof of the lemma. 

The previous lemmas allow the operations to be linearized (i.e., totally ordered in an order compliant with both the sequential specification of a register, and their real-time occurrence order) according to a total order extension of the reflexive and transitive closure of the 
 relation defined thereafter.

Definition 1

Let 
 be two operations. We define the 
 relation by 
 if one of the following properties holds:

•
,

•
,

•
, op is a write operation and 
 is a snapshot operation,

•
,  and 
 are two write operations on the same register and 
.

Lemma 12

The snapshot object built by Algorithm 3 is linearizable.

Proof

We recall the definition of the 
 relation: 
 if one of the following properties holds:

•
,

•
,

•
, op is a write operation and 
 is a snapshot operation,

•
,  and 
 are two write operations on the same register and 
.

We define the 
 relation as the reflexive and transitive closure of the 
 relation.
Let us prove that the 
 relation is a partial order on all operations. Transitivity and reflexivity are given by construction. Let us prove antisymmetry. Suppose there are 
 such that 
 and 
 for all . By Lemma 11, for all , we have 
, and 
, so the timestamp array of all operations are the same. Moreover, if 
 is a snapshot operation, then 
 is the only possible case (% stands for “modulo”) , and by Lemma 11 again, 
 is a snapshot operation. Therefore, only two cases are possible.

•
Let us suppose that all the 
 are snapshot operations and for all i, 
. As ≺ is a partial order relation, it is antisymmetric, so all the 
 are the same operation.

•
Otherwise, all the 
 are write operations. By Lemma 11, for all 
. The operations 
 and 
 are ordered by the fourth point, so they are write operations on the same register and 
. By antisymmetry of the 
 relation, all the 
 have the same timestamp, so by Lemma 10, they are the same operation, which proves antisymmetry.

Let 
 be a total order extension of 
. Relation 
 is real-time compliant because 
 contains ≺.
Let us consider a snapshot operation  and a register r such that . According to line 4, it is associated to the value v that is returned by  for r, and comes from a write message sent by a write operation 
. By definition of 
, we have 
 (Lemma 11), and therefore 
. Moreover, for any different write operation 
 on r, by Lemma 10, 
. If 
, then 
. Otherwise we have 
, and (due to the first item of the definition of 
) we have 
. In both cases, the value written by 
 is the last value written on r before , according to 
. 

Time and message costs. An invocation of  involves one invocation of , while an invocation of  involves two. As  costs 
 protocol messages and 2Δ time units,  cost the same, and  costs the double.

Theorem 2

Algorithm 3 builds an MWMR atomic snapshot object in the model 
. The operation  costs one SCD-broadcast, the  operation costs two.

Proof

The proof follows from Lemma 8, Lemma 12. The cost of the operation  follows from line 1, and the one of  follows from lines 3-4. 

The next corollary follows from (i) Theorem 1, (ii) Theorem 2 and (iii) the fact that the constraint  is an upper bound on the number of faulty processes to build a read/write register (or snapshot object) [5].

Corollary 1

Algorithm 1 is resiliency optimal.

Comparison with other algorithms. Interestingly, Algorithm 3 is more efficient (from both time and message point of views) than the stacking of a read/write snapshot algorithm running on top of a message-passing emulation of a read/write atomic memory (as presented on Fig. 2, such a stacking would costs 
 messages and  time units, see Section 6.1).

Fig. 2
Download : Download high-res image (114KB)
Download : Download full-size image
Fig. 2. Comparison of various algorithms (best complexities are highlighted). See [5], [7], [14], [31], [32].

Sequentially consistent snapshot object. When considering Algorithm 3, let us suppress line 1 and line 3 (i.e., the messages sync are suppressed). The resulting algorithm no more implements a linearizable snapshot object. However, it still implements a snapshot object that is sequentially consistent [27]. This means that the order in which each process sees the operations performed on the snapshot object is consistent with a same total order similarly to linearizability except that this order may not respect real time. This results from the suppression of the real-time compliance due to the messages sync. The operation  is purely local, hence its cost is 0. The cost of the operation  is one SCD-broadcast, i.e., 2Δ time units and 
 protocol messages. The proof of this algorithm is left to the reader.

7. The power of SCD-broadcast: counter object
Definition

Let a counter be an object which can be manipulated by three parameterless operations denoted , , and . Let C be a counter. From a sequential specification point of view  adds 1 to C,  subtracts 1 from C,  returns the value of C. As indicated in the Introduction, due to its commutative operations, this object is a good representative of a class of CRDT objects (conflict-free replicated data type as defined in [36]).

The operation  is similar to the operation  of the snapshot object. Differently from the  operation on a snapshot object (which requires a synchronization message sync() and a data/synchronization message write()), the update operations  and  require only one data/synchronization message plus() or minus(). This is the gain obtained from the fact that, from a process 
 point of view, the operations  and  which appear between two consecutive of its  invocations are commutative.

Lemma 13

If a non-faulty process invokes an operation, it returns from its invocation.

Proof

Let 
 be a non-faulty process that invokes ,  or . By the Termination-1 property of SCD-broadcast, it eventually receives a message set containing the message plus(), minus() or sync() it sends at line 1 or 3. As all the statements associated with the scd-delivery of a message set (lines 5-8) terminate, it follows that the synchronization Boolean 
 is eventually set to true. Consequently, 
 returns from the invocation of its operation. 

Definition 2

Let 
 be an operation performed by 
. We define 
 as a set of messages by:

•
If 
 is an  or  operation, and 
 is the message sent during its execution at line 1, then 
.

•
If 
 is a  operation, then 
 is the union of all sets of messages scd_delivered by 
 before it executed line 4.

We define the 
 relation by 
 if one of the following conditions hold:
•
;

•
,  is an  or a  operation and 
 is a  operation.

Lemma 14

The counter object built by Algorithm 4 is linearizable.

Proof

Let us prove that 
 is a strict partial order relation. Let us suppose 
. If 
 is a  operation, we have 
. If 
 is an  or a  operation, we have 
. In both cases, we have 
, which proves transitivity as well as antisymmetry and irreflexivity since it is impossible to have .

Let us prove that 
 is real-time compliant. Let 
 and 
 be two operations performed by processes 
 and 
 respectively, and let 
 and 
 be the message sent during the execution of 
 and 
 respectively, on line 1 or 3. Suppose that 
 (
 terminated before 
 started). When 
 returns from 
, by the waiting condition of line 1 or 3, it has received 
, but 
 has not yet sent 
. Therefore, 
, and consequently 
. By the waiting condition during the execution of 
 (line 1 or 3), we have 
. By the Containment property of SCD-broadcast, we therefore have 
, so 
. Let 
 be a total order extension of 
. It is real-time compliant because 
 contains ≺.

Let us now consider the value returned by a  operation . Let p be the number of plus() messages in  and let m be the number of minus() messages in . According to line 1,  returns the value of 
 that is modified only at line 7 and contains the value , by commutativity of additions and subtractions. Moreover, due to the definition of 
, all pairs composed of a  and an  or  operations are ordered by 
, and consequently,  has the same  and  predecessors according to both 
 and to 
. Therefore, the value returned by  is the number of times  has been called, minus the number of times  has been called, before  according to 
, which concludes the lemma. 

Theorem 3

Algorithm 4 implements an atomic counter.

Proof

Follows from Lemma 13, Lemma 14. 

An algorithm satisfying sequential consistency. The previous algorithm can be easily modified to obtain a sequentially consistent counter. To this end, a technique similar to the one introduced in [8] can be used to allow the operations  and  to have a fast implementation. “Fast” means here that these operations are purely local: they do not require the invoking process to wait in the algorithm implementing them. Differently, the operation  issued by a process 
 cannot be fast, namely, all the previous  and  operations issued by 
 must be applied to its local copy of the counter for its invocation of  to terminate (this is the rule known under the name “read your writes”).

Algorithm 5 is the resulting algorithm. In addition to 
, each process manages a synchronization counter 
 initialized to 0, which counts the number of  and  executed by 
 and not yet locally applied to 
. Only when 
 is equal to 0, 
 is allowed to read 
.

Algorithm 5
Download : Download high-res image (91KB)
Download : Download full-size image
Algorithm 5. Construction of a seq. consistent counter in 
 (code for pi).

The cost of an operation  and  is 0 time units plus the 
 protocol messages of the underlying SCD-broadcast. The time cost of the operation  by a process 
 depends on the value of 
. It is 0 when 
 has no “pending” counter operations.

Remark

As in [8], using the same technique, it is possible to design a sequentially consistent counter in which the operation  is fast, while the operations  and  are not.

8. The power of SCD-broadcast: lattice agreement task
Definition

Let S be a partially ordered set, and ≤ its partial order relation. Given 
, an upper bound of 
 is an element x of S such that 
. The least upper bound of 
 is an upper bound z of 
 such that, for all upper bounds y of 
, . S is called a semilattice if all its finite subsets have a least upper bound. Let 
 denotes the least upper bound of 
.

Let us assume that each process 
 has an input value 
 that is an element of a semilattice S. The lattice agreement task was introduced in [6] and generalized in [17]. It provides each process with an operation denoted , such that a process 
 invokes 
 (we say that 
 proposes 
); this operation returns an element  (we say that it decides z). The task is defined by the following properties, where it is assumed that each non-faulty process invokes .

•
Validity. If process 
 decides 
, we have 
.

•
Containment. If 
 decides 
 and 
 decides 
, we have 
 or 
.

•
Termination. If a non-faulty process proposes a value, it decides a value.

Theorem 4

Algorithm 6 solves lattice agreement.

Proof

The Termination property follows from the Termination-1 property of SCD-broadcast (if a non-faulty process SCD-broadcasts a message m, it SCD-delivers a message set containing m). The Validity property follows from the definition of the  operation, and the fact that, when a process 
 executes line 2, 
 contains 
 (it executed before lines 3-4 when it received a message set containing the message msg
 it SCD-broadcast at line 1).

As far as the Containment property is concerned we have the following. Let us assume, by contradiction, that there are two processes 
 ans 
 such that we have neither 
 nor 
.This means that there is a value 
, and a value 
. Let 
 and 
 be the message sets (scd-delivered by 
) which contained v and 
 respectively. As 
 and 
, we have 
, and 
 was scd-delivered before 
.

Defining similarly 
 (containing 
) and 
 (containing v), we have 
, and 
 was scd-delivered before 
. It follows that 
 and 
, from which it follows that 
 is not a partial order. A contradiction with the SCD-broadcast definition. 

Remark 1

SCD-broadcast can be built on top of read/write registers (see below Theorem 5). It follows that the combination of Algorithm 6 and Algorithm 7 provides us with a pure read/write algorithm solving the lattice agreement task. As far as we know, this is the first algorithm solving lattice agreement, based only on read/write registers.

Algorithm 7
Download : Download high-res image (133KB)
Download : Download full-size image
Algorithm 7. An implementation of SCD-broadcast on top of snapshot objects (code for pi).

Remark 2

Similarly to the algorithms implementing snapshot objects and counters satisfying sequential consistency (instead of linearizability), Algorithm 6 uses no message sync().

Let us also notice the following. Objects are specified by “witness” correct executions, which are defined by sequential specifications. According to the time notion associated with these sequences we have two consistency conditions: linearizability (the same “physical” time for all the objects) or sequential consistency (a logical time is associated with each object, independently from the other objects). Differently, as distributed tasks are defined by relations from input vectors to output vectors (i.e., without referring to specific execution patterns or a time notion), the notion of a consistency condition (such as linearizability or sequential consistency) is meaningless for tasks.

9. The computability limit of SCD-broadcast
This section presents an algorithm building SCD-broadcast on top of SWMR snapshot objects. (Such snapshot objects can be easily obtained from MWMR snapshot objects [15].) Hence, it follows from (a) this algorithm, (b) Algorithm 1, and (c) the impossibility proof to build an atomic register on top of asynchronous message-passing systems where  process may crash [5], that SCD-broadcast cannot be implemented in 
, and snapshot objects and SCD-broadcast are computationally equivalent.

9.1. From snapshot to SCD-broadcast
Shared objects. The shared memory is composed of two SWMR snapshot objects. Let ϵ denote the empty sequence.

•
: snapshot object (initialized to ), such that  contains the messages scd-broadcast by 
.

•
: snapshot object (initialized to ), such that  contains the sequence of the sets of messages scd-delivered by 
.

The notation ⊕ is used for the concatenation of a message set at the end of a sequence of message sets.
Local objects Each process 
 manages the following local objects.

•
: local copy of the snapshot object SENT.

•
: local copy of the snapshot object SETS_SEQ.

•
: auxiliary variable whose aim is to contain the next message set that 
 has to scd-deliver.

The function  returns the set of all the messages contained in .
Description of Algorithm 7. When a process 
 invokes , it adds m to 
 and  to inform all the processes on the scd-broadcast of m. It then invokes the internal procedure  from which it exits once it has a set containing m (line 1).

A background task T ensures that all messages will be scd-delivered (line 2). This task invokes repeatedly the internal procedure . As, locally, both the application process and the underlying task T can invoke , which accesses the local variables of 
, those variables are protected by a local fair mutual exclusion algorithm providing the operations  and  (lines 3 and 11).

The procedure  first invokes the internal procedure , whose aim is to allow 
 to scd-deliver sets of messages which have been scd-broadcast and not yet locally scd-delivered.

To this end,  works as follows (lines 12-17). Process 
 first obtains a snapshot of SETS_SEQ, and saves it in 
 (line 12). This allows 
 to know which message sets have been scd-delivered by all the processes; 
 then enters a “while” loop to scd-deliver as many message sets as possible according to what was scd-delivered by the other processes. For each process 
 that has scd-delivered a message set set containing messages not yet scd-delivered by 
 (predicate of line 13), 
 builds a set 
 containing the messages in set that it has not yet scd-delivered (line 14), and locally scd-delivers it (line 16). This local scd-delivery needs to update accordingly both 
 (local update) and  (global update).

When it returns from , 
 strives to scd-deliver messages not yet scd-delivered by the other processes. To this end, it first obtains a snapshot of SENT, which it stores in 
 (line 5). If there are messages that can be scd-delivered (computation of 
 at line 6, and predicate at line 7), 
 scd-delivers them and updates 
 and  (lines 7-9) accordingly.

9.2. Proof of Algorithm 7
Lemma 15

If a process scd-delivers a set containing a message m, some process invoked .

Proof

The proof follows directly from the text of the algorithm, which copies messages from SENT to SETS_SEQ, without creating new messages. 

Lemma 16

No process scd-delivers the same message twice.

Proof

Let us first observe that, due to lines 7 and 15, all messages that are scd-delivered at a process 
 have been added to 
. The proof then follows directly from (a) this observation, (b) the fact that (due to the local mutual exclusion at each process) 
 is updated consistently, and (c) lines 6 and 14, which state that a message already scd-delivered (i.e., a message belonging to 
) cannot be added to 
. 

Lemma 17

Any invocation of  by a non-faulty process 
 terminates.

Proof

The proof consists in showing that the internal procedure  terminates. As the mutex algorithm is assumed to be fair, process 
 cannot block forever at line 3. Hence, 
 invokes the internal procedure . It then issues first a snapshot invocation on SETS_SEQ and stores the value it obtains the value of 
. There is consequently a finite number of message sets in 
. Hence, the “while” of lines 13-17 can be executed only a finite number of times, and it follows that any invocation of  by a non-faulty process terminates. The same reasoning (replacing SETS_SEQ by SENT) shows that process 
 cannot block forever when it executes the lines 5-10 of the procedure . 

Lemma 18

If a non-faulty process scd-broadcasts a message m, it scd-delivers a message set containing m.

Proof

Let 
 be a non-faulty process that scd-broadcasts a message m. As it is non-faulty, 
 adds m to  and then invokes  (line 1). As , it is eventually added to 
 if not yet scd-delivered (line 6), and scd-delivered at line 9, which concludes the proof of the lemma. 

Lemma 19

If a non-faulty process scd-delivers a message m, every non-faulty process scd-delivers a message set containing m.

Proof

Let us assume that a process scd-delivers a message set containing a message m. It follows that the process that invoked  added m to SENT (otherwise no process could scd-deliver m). Let 
 be a correct process. It invokes  infinitely often (line 2). Hence, there is a first execution of  such that 
 contains m (line 5). If then follows from line 6 that m will be added to 
 (if not yet scd-delivered). If follows that 
 will scd-deliver a set of messages containing m at line 9. 

Lemma 20

Let 
 be a process that scd-delivers a set 
 containing a message m and later scd-delivers a set 
 containing a message 
. No process 
 scd-delivers first a set 
 containing 
 and later a set 
 containing m.

Proof

Let us consider two messages m and 
. Due to total order property on the operations on the snapshot object SENT, it is possible to order the write operations of m and 
 into SENT. Without loss of generality, let us assume that m is added to SENT before 
. We show that no process scd-delivers 
 before m.4

Let us consider a process 
 that scd-delivers the message 
. There are two cases.

•
 scd-delivers the message 
 at line 9. Hence, 
 obtained 
 from the snapshot object SENT (lines 5-6). As m was written in SENT before 
, we conclude that SENT contains m. It then follows from line 6 that, if 
 has not scd-delivered m before (i.e., m is not in 
), then 
 scd-delivers it in the same set as 
.

•
 scd-delivers the message 
 at line 16. Due to the predicate used at line 13 to build a set of messages to scd-deliver, this means that there is a process 
 that has previously scd-delivered a set of messages containing 
.

Moreover, let us observe that the first time the message 
 is copied from SENT to some  occurs at line 8. As m was written in SENT before 
, the corresponding process 
 cannot see 
 and not m. It follows from the previous item that 
 has scd-delivered m in the same message set (as the one including 
), or in a previous message set. It then follows from the predicate of line 13 that 
 cannot scd-deliver 
 before m.

To summarize, the scd-deliveries of message sets in the procedure  cannot violate the MS-Ordering property, which is established at lines 6-10.

Theorem 5

Algorithm 7 implements SCD-Broadcast in the classical wait-free read/write model 
.

Proof

The proof follows from Lemma 15 (Validity), Lemma 16 (Integrity), Lemma 17, Lemma 18 (Termination-1), Lemma 19 (Termination-2), and Lemma 20 (MS-Ordering). 

10. Conclusion
This paper has introduced a new communication abstraction, suited to asynchronous message-passing systems where computing entities (processes) may crash. Denoted SCD-broadcast, it allows processes to broadcast messages and deliver sets of messages (instead of delivering each message one after the other). More precisely, if a process 
 delivers a set of messages containing a message m, and later delivers a set of messages containing a message 
, no process 
 can deliver a set of messages containing 
 before a set of messages containing m. Moreover, there is no local constraint imposed on the processing order of the messages belonging to a same message set. SCD-broadcast has the following noteworthy features:

•
It can be implemented in asynchronous message passing systems where any minority of processes may crash. Its costs are upper bounded by twice the network latency (from a time point of view) and 
 (from a message point of view).

•
Its computability power is the same as the one of atomic read/write register (anything that can be implemented in asynchronous read/write systems can be implemented with SCD-broadcast).

•
It promotes a communication pattern which is simple to use, when one has to implement concurrent objects defined by a sequential specification or distributed tasks.

•
When interested in the implementation of a concurrent object O, a simple weakening of the SCD-broadcast-based atomic implementation of O provides us with an SCD-broadcast-based implementation satisfying sequential consistency (moreover, the sequentially consistent implementation is more efficient than the atomic one).

On programming languages for distributed computing. Differently from sequential computing for which there are plenty of high level languages (each with its idiosyncrasies), there is no specific language for distributed computing. Instead, addressing distributed settings is done by the enrichment of sequential computing languages with high level communication abstractions. When considering asynchronous systems with process crash failures, total order broadcast is one of them. SCD-broadcast is a candidate to be one of them, when one has to implement read/write solvable objects and distributed tasks.

Remark

It is worth noticing that the a self-stabilizing version of the SCD algorithm presented in this article is described in [29], and an extension of it where up to  processes may commit Byzantine failures is described in [10]. It is still an open problem to find an SCD algorithm coping with up to  Byzantine processes.