Abstract
We study the deep relation existing between differential logical relations and incremental computing by showing how self-differences in the former precisely correspond to derivatives in the latter. The byproduct of such a relationship is twofold: on the one hand, we show how differential logical relations can be seen as a powerful meta-theoretical tool in the analysis of incremental computations, enabling an easy proof of soundness of differentiation. On the other hand, we generalize differential logical relations so as to be able to interpret full recursion, something not possible in the original system.


Keywords
Differential logical relations
Differential semantics
Incremental lambda calculus
Program difference
Program derivatives

1. Introduction
One of the major challenges programming language theory is facing these days is the development of adequate abstractions to deal with the highly increasing complexity and heterogeneity of modern software systems. Indeed, since the very birth of the discipline, researchers have been focused on the design of compositional techniques for software analysis whereby one can study the overall behavior of a system by inspecting its constituent parts in isolation. A prime example of the successfulness of such an analysis is given by the theory of program equivalence. Notwithstanding its successful history, program equivalence is revealing some weaknesses when applied to nowadays software, where exact reasoning about components is, either because of the very nature of the software involved or because of the cost of such an analysis, oftentimes not feasible. Examples witnessing such weaknesses are given by the fields of probabilistic computing, where small perturbations in probabilities break equivalence, numerical computing, where program implementing numerical functions can be optimized at the price of introducing an acceptable error in the output, and, more generally, approximate computing [29] where accuracy of the result is partially sacrificed to gain efficiency.

The common pattern behind all the aforementioned examples is the shift from an exact analysis of software, whereby equivalent pieces of software are interchangeable within any system, to an approximate analysis of software, whereby non-equivalent pieces of software are replaced within a system at the price of producing an acceptable error, and thus an approximately correct result. Moving from an exact to an approximate analysis of programs poses several challenges to programming language semantics, the main one arguably concerning compositionality. In fact, once we replace a program P with a non-equivalent one Q in a system , then  may amplify the error introduced by the replacement of P with Q, this way invalidating compositionality of the analysis. This point becomes evident when studying (higher-order) program metric or program distance [32], [15], [20], [6]: if the distance between P and Q is upper bounded by a number , then it may not be so for  and .

Motivated by these general observations, researchers are showing an increasing interest in quantitative analysis of programs, with a special focus on differential properties of programs. Although the expression differential has no precise meaning in this context, we may identify it with the collection of properties relating local and global changes in software. Thus, for instance, we can think of the (error produced by the) replacement of P with Q as a local change, and investigate its relationship with the global change we observe between  and .

The study of such differential properties has led, oftentimes abusing terminology, to the development of several notions of a program derivative. Among those, some of the main ones one encounters when looking at the relevant literature are the following:

•
Those coming from the field of automatic differentiation [11], which aim to extend the notion of a derivative one finds in mathematical analysis [35] to arbitrary programs. Examples are given by [12], [1], [34], [10], as well as by references therein.

•
Those coming from the differential λ-calculus [19], whose original motivations rely on quantitative semantics [25] and linear logic [24].

•
Those coming from incremental computing [31], [30], which aim to find ways to incrementally compute outputs as inputs changes.

•
Those coming from differential logical relations [16] via the notion of a self-difference, which aim to provide context-sensitive compositional distances between programs.

It is thus natural to ask whether any connections exist between such notions. Although for some of the aforementioned cases the answer seems to be negative (for instance, the derivatives one finds in incremental computing are generalizations of finite differences [33], whereas the ones found in calculi for automatic differentiation are actual derivatives), others have conceptual similarities. This is the case for differential logical relations and incremental computing, as both study the relationship between input and output changes.

In this paper, we study such similarities and establish a formal connection between differential logical relations and incremental computing, by showing how self-differences in the former precisely correspond to derivatives in the latter. In fact, as we will see, the derivative of a program P can be seen as a way to quantify how much changes in the input of P influence changes in its output, this way acting as a self-difference for P. Besides its conceptual implications, the advantages of such a correspondence are twofold. On the one hand, differential logical relations qualify as a lightweight operational technique for incremental computing: we witness that by giving a proof of soundness of differentiation for the incremental λ-calculus [13]. On the other hand, we can use results coming from incremental computing to go beyond the current theory of differential logical relations. We witness that by relying on the work by Giarrusso, Régis-Gianas, and Schuster [23] on untyped program derivatives to define a form of step-indexed differential logical relations, this way giving differential semantics to calculi with full recursion (something not possible in the original formulation of differential logical relations [16]).

Structure of the paper. In Section 2, we introduce the target calculus of this work as well as differential logical relations and the incremental λ-calculus. In Section 3, we establish a formal connection between differential logical relations and the incremental λ-calculus by showing that program derivatives (in the sense of incremental computing) are self-distances (in the sense of differential logical relations). Additionally, we give a differential logical relation-based proof of soundness of differentiation, the main result in the theory of incremental computing. In Section 4 we show how to extend the theory developed in Section 3 to a language with sum and list types. Finally, in Section 5 we take advantage of the connection between differential logical relations and incremental computing by extending the former to a calculus with full recursion.

2. Preliminaries: differential logical relations and the incremental λ-calculus
In this section, we shortly review the main ideas behind differential logical relations (DLRs) and the incremental λ-calculus. To do so, we introduce the vehicle calculus of this work, namely a simply typed λ-calculus with a primitive type for real numbers, which we denote by 
. The calculus is standard and it is essentially the same calculus used by Dal Lago et al. to define differential logical relations [16]. The syntax and static semantics of 
 are given in Fig. 1, where we assume to have primitives  
  for any real number r and constants  
 
  for any function1 
.

Fig. 1
Download : Download high-res image (56KB)
Download : Download full-size image
Fig. 1. Syntax and statics of 
.

We use letters  to range over terms, and  to range over values. We follow standard notational conventions [9]. Accordingly, we work with terms modulo renaming of bound variables and denote by  the capture-avoiding substitution of s for x in t. Contexts, i.e. terms with a hole , are denoted by the letters  and we write  for the capture-binding substitution of t for the hole  in C. We write 
 and 
 for the collections of terms and values of type σ, respectively, omitting subscripts when types are not relevant. Finally, we use the notation 
 and 
 for the sets of closed terms and closed values of type σ (again, omitting subscripts when types are not relevant). As customary, we refer to closed terms as programs.

We endow 
 with a call-by-value dynamic semantics defined the reduction rules in Fig. 2, where for a function 
 and a number  we write 
 for the mapping 
. Notice, in particular, that  
 
  
 
 
 eventually reduces to  
 
 . Since 
 is simply-typed, a standard reducibility proof [26] shows that 
 is strongly normalizing. In particular, any program t evaluates to a (unique) closed value v — that we indicate as  — in a finite number of reduction steps (notation ). We write 
, for , to state that t evaluates to v in n reduction steps. As it is customary, we denote by 
⁎
 the reflexive and transitive closure of →.

Fig. 2
Download : Download high-res image (26KB)
Download : Download full-size image
Fig. 2. Dynamics of 
.

2.1. Program equivalence and program distance: an overview
Despite its simplicity, 
 allows us to justify the shift from program equivalence — that is, the family of notions concerning equality between programs — to program distance.

First, let us define a suitable notion of program equivalence for 
 programs. Due to its simple nature, program equivalence for 
 terms can be defined by means of several notions of program equivalence, ranging from denotationally-based to operationally-based equivalences. Here, we choose extensional or applicative equivalence.2

Definition 1

Define the type-indexed family of relations 
 as follows (where ):
 
 
 As usual, we omit type subscripts when not relevant.

It is well-known that extensional equivalence is a congruence, and thus a compositional technique for reasoning about program behaviors. In particular, if , then  holds for any context C (of the right type). Unfortunately, one soon realizes that due to the presence of (constants for) real-numbers, program equivalence is a too coarse notion for reasoning about 
 programs. For it is desirable to regard two programs of type R whose outputs are ε apart to be themselves ε apart, rather than just state that the two are not equivalent.3 The natural way to overcome this problem is to refine 
 into a map 
 following Lawvere's correspondence between ordered sets and (generalized) metric spaces [27]. Accordingly, we obtain the following maps:
  
 
 
 
 which can be easily proved to be generalized metrics4 [27]. To make δ a useful notion for reasoning about the (quantitative) behavior of programs, we need it to support the (quantitative refinement of the) compositionality principle ensured by ≅. As compositionality of ≅ takes the form of a congruence property, it is easy to realize to that compositionality of δ takes the form of non-expansiveness: for all terms 
 and  we must have 
. That is, contexts do not amplify distances.

Unfortunately, we immediately see that δ fails to be non-expansive, and thus compositional. Even worse, any reasonable non-expansive metric-like map trivializes, meaning that it collapses to a congruence relation. Roughly, given two terms  which are  apart, for any real number  it is always possible to find a context C such that  and  are  apart. For it is sufficient to take a term t using its input x enough times: once the terms  and  are evaluated, any time t uses x the distance between s and 
 is detected and added to the one previously measured. Remarkably, this holds even if any map φ in the language of 
 is non-expansive (i.e. 1-Lipschitz).

2.2. Differential logical relations
The failure of non-expansiveness of quantitative refinements of notions of program equivalence has led researchers to propose several notions of program distance [15], [32], [20] aiming to restore compositionality. All the notions proposed share a common feature: they all impose calculi linearity constraints, this way providing static information on the number of times a program can use its input (and thus on how much the program can amplify distances). The notions of program distance thus obtained are indeed compositional, but still have two major drawbacks. First, they are tailored to linear calculi and are not very informative when applied to non-linear calculi via, e.g., standard translations [24]. Second, and most important, they do not account for the role of the environment in determining distances. Let us expand on this last point by means of an example. Consider the (linear) programs  and  
 
  for the identity and sine function, respectively. It is easy to see that measuring the distance between t and s as we did when defining δ, we are forced to conclude such a distance to be ∞. In fact, for  we have . This is rather unsatisfactory, as such distance does not take into account which input the environment will actually pass to t and s. For instance, if the environment feeds t and s with an input v close to zero, then the distance between tv and sv should be close to 0 too, and thus we would like to conclude that in all such cases the distance between t and s is itself close to zero.

Summing up, ordinary notions of program distance are not sensitive to the context in which programs are used. This ultimately relies on the fact that measuring the distance between two programs (regarded as functions) as just one single number there is no way to give information on how such programs interact with the environments in which they are used. Differential logical relations [16] have been introduced as a way to define a context-sensitive notion of program distance on non-linear calculi. The main novelty of differential logical relations (which was previously theorized by Westbrook and Chaudhuri [38] in the setting of approximate program transformations [28]) is to consider richer notions of distance (also called differences) between programs, whereby the difference between two programs is, in general, not a number, but a function describing how differences between inputs turn into differences between outputs.

Differential logical relations take the form of (type-indexed) ternary relations 
 relating pairs of programs together with differences between them. When dealing with programs of type , differences take the form of functions mapping input programs of type σ and differences for such programs to differences for programs of type τ. This is why here we consider a computationally-oriented notion of difference whereby differences between programs are defined as programs themselves [38] rather than as semantical objects.

We formalize these ideas by assigning to each type σ a type Δσ whose inhabitants are terms acting as differences between terms of type σ.

Definition 2

The map Δ associates to each type σ a type Δσ which we refer to as the type of σ-differences. We define Δ recursively as follows.

Notice, in particular, that a difference between two programs of type  is a program taking an input of type σ and a σ-difference, and returning a τ-difference.
Obviously, given two programs 
 of type σ, not all programs of type Δσ can act as (meaningful) differences between t and 
. Differential logical relations (DLRs for short) are ternary relations specifically designed to isolate meaningful differences between programs. More precisely, a DLR is a type-indexed family of ternary relations 
, where 
 and 
, such that 
 holds if and only if dt is a difference5 between t and 
 (and similarly for values).

Definition 3 Asymmetric DLRs

A differential logical relation is a type-indexed family of (pairs of) ternary relations 
 such that:

•
 
  
  
 
 if and only if 
.

•
 if and only if 
, for any .

•
 if and only if for all 
, if 
 then 
.

•
 if and only if 
, where 
.

Remark 4

Contrary to the original formulation of DLRs [16], here we work with asymmetric DLRs: if dt is a difference between t and 
, then dt may not be a difference between 
 and t. For instance,  
  is a difference between  
  and  
 , as by adding 3 to 2 we reach 5. Yet, according to such a reading, it is not true that  
  is a difference between  
  and  
  (the desired difference being, in fact,  
 
 ).

Example 5

[16]
Let  
 
  and 
. Then  
 
  is a difference between t and 
. For, proving 
 requires to prove that for all  
 
  
  
 
 such that 
 
  
  
 
 (meaning that 
), we have 
 
  
 
  
 
, i.e. 
, which is indeed the case. Observe how  
 
  
  evaluates to a real number which is indeed small when the two arguments are themselves close to 0.

As already remarked, DLRs have been introduced with the goal of developing a compositional theory of program distance. This goal is achieved by the so-called Fundamental Lemma [16].

Lemma 6 Fundamental Lemma, Version 1

For any program 
 there exists a self-difference dt for it. That is, 
.

Lemma 6 enables compositional reasoning on program differences. Informally, by regarding a context  as a term  we are guaranteed a self-difference dt for t to exist, so that given two programs 
 of type σ with difference ds between them, one can compute the difference between  and 
 starting from s, ds, and dt alone.

2.3. The incremental λ-calculus and program derivatives
Albeit enabling compositional reasoning on program differences, Lemma 6 has the major drawback of guaranteeing the existence of self-distances without giving any explicit information on how to construct them. As we will see in the next section, the self-distances of Lemma 6 are precisely the program derivatives used in the incremental λ-calculus.

The incremental λ-calculus is a formalism introduced by Cai et al. [13] as a foundational calculus for incremental computation [31], [30]. Suppose we are given a program f regarded as a function, and an input a (think, for instance, of a as a database). Let us also suppose to compute  and then to modify the input a by a change da, this way obtaining a new input  (for instance, we may add a new entry to the database a). Incremental computing seeks for ways to obtain the result of  without computing f on the new input  from scratch. In fact, sometimes it is indeed possible to obtain such a result in terms of  and 
, for a suitable function6 
. For instance, let 
 and suppose we have computed , for some a. Let us now change a to . When asked to compute  we can take advantage of having already computed 
 by observing that 
, where 
.

In order to provide a formal foundation for higher-order incremental computation, Cai et al. [13] studied incrementalization of a simply-typed λ-calculus similar to 
. More precisely, for any type σ a type of σ-changes coinciding with Δσ is introduced, as well as an operator ⊕ (called change update) building an expression 
 from an expression 
 and a change 
. To account for incrementalization, the so-called derivative7 
 of an expression 
 is also introduced and it is shown that for all terms 
, 
, and σ-change ds, one has , where ≡ stands for denotational equality. All the aforementioned results are proved by means of denotational semantics, although some operationally-based proofs employing techniques resembling DLRs are given in Giarrusso's PhD thesis [22].

In the next section, we will show how we can easily prove such results using DLRs and, dually, how by identifying differences with changes we can improve on the current theory of program differences. To do so, however, we first need to formally introduce the update operator ⊕ and the notion of a program derivative. We begin recalling a couple of basic definitions from finite difference calculus [33].

Definition 7

Given functions 
 and 
, define the maps 
 and 
 by:

The map Δφ is known as the finite difference of φ. For instance, the finite difference of the sine function sin is the function Δsin defined by . Notice that .

Definition 8

Define the partial operator  as follows:
  
  
 
  
 
  
 
  
 
  where the symbol ⊕ in  
 
  is the one in Definition 7.

The definition of  may appear weird at first, but it will become clear once the notion of a derivative is introduced. Intuitively, given a term t and a change dt, we can see  as the term obtained by changing t according to dt. Clearly, this is possible only if dt has the ‘right’ structure (for instance, it would be meaningless to do something like changing a function according to a number). We immediately notice that if v is a value and  is defined, then dv and  are values too. Moreover, the following typing rule is admissible, whenever  is defined: where for 
, we have 
.

Next, we define the notion of a derivative of a term.

Definition 9

The derivative Dt of a term t is thus defined: 
  
  
 
  
 
 

Observe that we can indeed think of Dt as the generalization of finite differences to arbitrary programs. For instance, we have  
 
  
 
 . In a similar fashion, we can compute the derivative of the higher-order function  
 
  as  
 
 . Moreover, we easily see that if , then  and that  is defined and equal to t itself. For instance, we have: 
 
  
 
  
 
  
 
  
 
  which is nothing by  
 
 .
3. Bridging the gap
In this section, we relate DLRs with the incremental λ-calculus we have introduced in the previous section. We do so by acting on two orthogonal axes. On the one hand, we show that program derivatives are precisely the self-distances of Lemma 6. That is, for any program t, Dt is a self-distance for t. This result allows us to strengthen the fundamental lemma of DLRs (Lemma 6), as now self-differences can be effectively computed. On the other hand, we prove by means of DLRs a major result on the incremental λ-calculus, namely soundness of differentiation [13]. To the best of the authors' knowledge, all proofs of such a result rely on either denotational semantics or logical relations tailored for such purpose (see Remark 15).

Let us begin proving that derivatives are actually self-differences. In order to achieve such a result, we have to first extend the notion of a DLR to open terms [16]. Given an environment Γ, we denote by  the collection of Γ-substitutions, i.e. the collection of maps ρ mapping variables  to closed values 
. In particular, we use the notation dρ to denote substitutions in .

Definition 10

We extend the notion of a DLR to substitutions over an environment Γ as follows: 
, where 
 and .

As it is customary, we write  for the application of the substitution ρ to the term t, and  for the substitution mapping x to v and behaving as ρ otherwise. Before proving our refinement of Lemma 6, let us observe that DLRs are closed under reduction, in the following sense.

Lemma 11

The following holds for all closed terms:
⁎
⁎
⁎
⁎

We are now ready to prove our new version of the Fundamental Lemma.

Lemma 12 Fundamental Lemma, Version 2

For any program 
 we have 
.

Proof

The thesis follows from the stronger statement: for any term  and value  we have
 The proof of the latter is a routine induction on t and v. We show a couple of cases as illustrative examples.

•
Consider the case of real-valued maps 
. We have to show that for all values  
 
 
 
 such that 
 
 
 
 we have
 
  
 
 
 
 
 
  
 
 
 
  
 
 
 i.e.
 We are done since 
 
 
 
 implies 
, and

•
Consider the case of abstractions . Assume 
. We have to show
 i.e.
 for all 
 such that 
. By Lemma 11, it is sufficient to show
 where , 
, , which indeed holds by induction hypothesis. □

Notice how Lemma 12 improves the compositionality principle of DLRs. Given a term  and two values 
 such that 
 the impact of replacing v with 
 in t can be computed as . Next, we show how the incremental λ-calculus can benefit from DLRs by showing how the latter support an easy proof of soundness of differentiation.

Theorem 13

Soundness of differentiation [13], [23]
For all 
 and values 
 such that 
, we have 
.

Our proof of Theorem 13 is based on the following result which states that changes indeed behave as such. Recall that ≅ extends to open terms by stipulating that for 
 we have 
 iff 
, for any substitution  (and similarly for values).

Proposition 14

The following holds for all (possibly open) terms 
 and values 
 such that  and  is defined.

Proof

The proof is by induction on σ, the relevant case being the one of values. We show how to handle the case for arrow types. Assume 
. We have to show that for any , 
. First, observe that we have the following general result (by induction on t), where : . By Lemma 12, we have 
, hence 
. In particular, we must have , 
, and , for some 
, and ds. Since  (notice that this term is indeed defined, as it is obtained from , which is defined by hypothesis, replacing variables  with closed values v, Dv), in order to prove the thesis we have to show 
 for any closed value v of type σ. Since  we obtain the thesis from 
 and 
, the latter being a consequence of Lemma 12. □

We can finally prove soundness of differentiation.

Proof of Theorem 13

Assume 
. From Lemma 12, we obtain 
, and thus 
, by Lemma 11. We conclude that 
 from Proposition 14. □

Remark 15

To the best of the authors' knowledge, all proofs of Theorem 13 in the literature are based on either denotational semantics or on logical relations resembling DLRs, but specifically extended with a clause requiring 
 for all related terms 
, at any type [23], [22]. Notice the use of syntactic equality: the reason behind such a choice is that the logical relation obtained is meant to relate only programs with their derivative (in which case we indeed have ), rather than as a tool to reason about program differences.

4. Language extensions
 is a minimal language which serves as a vehicle to study program differences. However, not so many interesting programs can be written in 
, and thus one may wonder whether our techniques scale to richer languages. In Section 5, we will show that differential logical relations can be extended to languages with full recursion. Here, we show by means of examples that our framework is robust with respect to language extensions given in the form of new data types. More specifically, we show how to extend differential logical relations to sum and list types. First, we extend the syntax of 
 with the new types and term constructs. This is done in Fig. 3.

Fig. 3
Download : Download high-res image (66KB)
Download : Download full-size image
Fig. 3. Syntax of 
 with sums and lists.

To extend the results of the previous section to 
 with sum and list types, what we have to do is to first define suitable difference spaces for such types, and then to extend DLRs accordingly. A standard notion of a difference space for sum types [22] is given by . The rationale behind this definition is that whenever we compare elements of type  we either compare elements coming from the same type (viz. σ or τ) or we compare elements coming from different types (e.g. σ for the first element and τ for the second one). In the first case, a difference is a just a difference between the original terms (thus either an element of Δσ or an element of Δτ). In the second case, instead, we should compare terms coming from different types, something not possible in our framework: we thus simply take as a difference the second term, this way witnessing that we have a ‘jump’ from one type to another (so that a difference tells that we have such a jump and the target term of the jump). More precisely, let 
 be values of type  and dv be a difference between them. Then, we have four possible cases:

•
Both v and 
 come from the type σ (i.e. 
 and 
). In that case, dv will be an element of Δσ (injected into ) acting as a difference between w and 
.

•
Both v and 
 come from the type τ. As before, in this case dv will be an element of dτ acting as a difference between w and 
.

•
 comes from the type σ and 
 from τ, so that we have a ‘jump’ from σ to τ. In that case, dv is just 
 (injected into , and witnesses that we have ‘jumped’ from σ to τ.

•
 comes from the type σ and 
 from τ, so that we have a ‘jump’ from σ to τ. As before, in this case dv is just 
 (injected into , and witnesses that we have ‘jumped’ from τ to σ.

For list types, things are simpler since we may take as difference space just lists of differences. Formally: . Before extending differential logical relations, it is useful to introduce some syntactic sugar.

Remark 16

Due to the form of , it is convenient to introduce the following syntactic sugar for nested (with depth two) injection and case analysis on sum types: that allows us to inject and do pattern matching over 4-ary sums.

We are now ready to extend DLRs.

Definition 17

We extend Definition 3 with the following clauses.

•
 if and only if the following holds:

•
 if and only if either 
 or 
, 
, 
, and 
 and 
.

To extend Lemma 12 to Definition 17, we need to extend the notion of a derivative to our new type constructors. To do so, we introduce some syntactic sugar which will improve readability. Given lists t, s, we write 
 for the nested case analysis on t and s returning a dummy value for those cases not listed in the pattern matching (such a syntax will be used only for terms related by differential logical relations, this way ensuring the incomplete case analysis of our syntax to be indeed exhaustive). We use a similar syntax for nested case analysis on sum types.

Definition 18

We extend Definition 9 with the following clauses:
 
 
 

We now have all the ingredients to extend the Fundamental Lemma (Lemma 12) to sum and list types.

Lemma 19 Fundamental Lemma, Version 3

For any program 
 we have 
.

The proof of Lemma 19 is a straightforward extension of the one of Lemma 12. Notice how the incomplete case analysis of the derivative of the pattern matching constructs for sums and lists perfectly matches the one in Definition 17.

We have thus achieved the desired extension of DLRs (and their meta-theory) to list and sum types. Moreover, the exact same methodology we have used here can be used to extend DLRs to richer languages. However, so far we have focused on theoretical aspects of DLRs giving little attention on how they can be used in practice. Can we apply derivatives and differential logical relations to perform differential analysis of interesting higher-order programs? Consider, for instance, the higher-order function  obeying the laws
 Can we define the derivative Dmap, this way giving (by Lemma 19) a self-difference for map? We answer this question affirmatively in the next section, where we extend differential logical relations to full recursion.

5. Differential logical relations in presence of recursion via step-indexing
The connection between DLRs and the incremental λ-calculus of previous sections can also be used as the starting point towards an extension of DLRs beyond the simply-typed setting of previous sections, this way generalizing Lemma 12 to Turing complete calculi. In this section, we show how to achieve such a goal for an extension of 
, which we call 
, with a fixed point combinator. To handle full recursion, we refine DLRs using the so-called step-indexing technique [7], [3]. A similar technique has been recently proposed for an untyped incremental λ-calculus [23].

The syntax and static semantics of 
 are obtained by extending the one of 
 with a fixed point operator . We extend the notational conventions used for 
 to 
 mutatis mutandis. The static and dynamic semantics of 
 are given by extending the one of 
 with the rules in Fig. 5. Notice also that we can ignore the λ-abstraction constructor and encode terms of the form  as  where f does not appear (free) in t. We extend the notations  and 
 to 
 in the obvious way. All this is standard, and does not pose any significant problem.

Fig. 5
Download : Download high-res image (14KB)
Download : Download full-size image
Fig. 5. Statics and dynamics of 
.

To extend DLRs to 
, we need to handle possibly infinitary behaviors. We do so relying on step-indexing [7].

Definition 20 Step-indexed asymmetric DLRs

A step-indexed DLR consists of a family of type-indexed (pairs of) relations 
; such that:

•
 
  
  
 
 if and only if 
.

•
 if and only if 
, for any .

•
 if and only if for all 
, we have:

•
 if and only if 
 implies 
.

Definition 20 is not conceptually far from the original definition of DLRs. Its main novelty is the introduction of a new parameter (the natural number n in its defining clauses) which behaves as a standard step-index in ordinary logical relations. Notice that we can also straightforwardly refine Definition 17 with the step-index parameter. For instance, we have 
 if and only if the following holds:

To prove the 
 counterpart of Lemma 12, we need to extend the notion of a derivative to 
 terms. In order to improve the understanding and readability of our results, it is convenient to introduce some syntactic sugar in the form of a term  whose dynamics is the following
⁎
 and which can be easily constructed via nested fix. We are now ready to define 
 derivatives.

Definition 21

The derivative Dt of a 
 term t is defined by extending Definition 9 (resp. Definition 18) with the following clause:

The rationale behind the definition of  is as follows [8], [4]. Given a function , let μf be its (least) fixed point, so that . As a consequence, by the very definition of the derivative of an application, we have: . Therefore,  is a fixed point of the map , and thus we can stipulate . This way, obtain the desired result:

The last piece we need in order to prove the extension of Lemma 12 to 
 is the extension of step-indexed DLRs to substitution maps:

Definition 22

We extend the notion of a step-indexed DLR to substitutions over an environment Γ as follows: 
, where 
 and .

We are finally ready to extend Lemma 12 to 
.

Lemma 23 Fundamental Lemma, Version 4

For any term  and value :
 for all 
 and for any .

Proof sketch

The proof is by induction on n, t, and v, mimicking the one of Lemma 12 and using the following standard results:
 □

Let us now come back to the example of the higher-order combinator map. First, let us define map formally:
 where  and . We can now compute Dmap, obtaining: 
  Notice that in the same way as map obeys the laws  and 
, we have  and
 The Fundamental Lemma (Lemma 23) ensures that Dmap is indeed a self-difference of map, and thus provides a way to perform a differential (and context-sensitive) analysis of map.

6. Related work
Differential logical relations have been introduced by the authors and Yoshimizu [16], building over intuitions by Westbrook and Chaudhuri [38], and are currently under investigation. Differently from the one considered in this work, the first formulation of differential logical relations [16] is symmetric and considers semantical difference spaces, so that differences between programs are semantical objects (such as numbers and functions), rather than programs themselves. Whereas we have found that working with asymmetric DLRs makes proofs clearer (besides, asymmetry is in line with Lawvere's analysis of the notion of a distance [27]), working with syntactic difference spaces does not really affect our results. In fact, we could consider semantic-based difference spaces and show that the denotation of a derivative of a program is a self-difference for the program. This, however, would uselessly complicate the exposition of our results, as we should have to go throw the denotational semantics of both 
 and 
.

The incremental λ-calculus has been introduced by Cai et al. [13] as a simply-typed calculus, and by Giarrusso et al. [23] as an untyped calculus. The former work introduces the notions of a program derivative and change update, and gives a denotational proof of soundness of differentiation. Operationally-based proofs of the same result are given in Giarrusso PhD's thesis [23], [22] by means of logical relations (see Remark 15). Remarkably, both Giarrusso's thesis [22] and the work by Giarrusso et al. [23] use ternary logical relations nearly identical to differential logical relations to relate programs with changes between them. Moreover, the logical relations introduced in the aforementioned papers have been mechanized in CoQ. The authors believe it is important to stress how essentially the same technique has independently emerged in different fields (and with different purposes) to prove two different kinds of differential properties of programs.

Finally, semantical investigations of abstract notions of difference have been given in terms of category theory by Alvarez-Picallo and Ong [5].

7. Conclusion
In this work, we have established a formal connection between differential logical relations and the incremental λ-calculus, whereby the self-differences of the former are identified with the program derivatives of the latter. Albeit the results proved here are not technically involved, by establishing a formal connection between two different fields they improve the current understanding of differential properties of programs, such an understanding being still in its infancy. The fact that essentially the same technique has been independently developed in different fields, one looking at software optimization and the other studying semantical notions of distance between programs, witnesses that, at least in the authors' opinion, the technique deserves to be further investigated.

In addition to its conceptual relevance, the connection established in the present work also allows us to obtain technical improvements both on the theory of incremental λ-calculus and on the one of differential logical relations. Concerning the former, we have showed how differential logical relations constitute a lightweight operational technique for incremental computing, and we have witnessed that by giving a new, relatively easy proof of soundness of differentiation. Concerning the latter, we have strengthened the fundamental lemma of DLRs by showing how program derivatives constitute self-differences, this way reaching an higher level of compositionality. A further consequence of such a connection is the extension of DLRs to calculi with full recursion by means the step-indexing.