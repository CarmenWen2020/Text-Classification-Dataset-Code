Abstract
Solid codes provide outstanding fault-tolerance when used for information transmission through a noisy channel involving not only symbol substitutions, but also synchronisation errors and black-outs. In this paper we provide an automaton theoretic characterisation of solid codes which takes this fault-tolerance into account.

The fault-tolerance afforded by a solid code L can be summarised as follows: Consider messages, encoded using L, being sent through a noisy channel. Any code words in L, which are present in the received message, will be decoded correctly, unless they themselves happen to be the results of errors. Thus, errors in the received message will not lead to incorrect decodings of those parts which are error-free.

In this paper we consider acceptors which are fault-tolerant in this sense when analysing such received messages. These acceptors characterise the class of solid codes. For finite solid codes an automaton characterisation was published in the sixties by Levenshtein and Romanov. The characterisation uses state-invariant finite-state transducers which act as decoders in such a way that an output is generated exactly when a code word has been read completely. State-invariance means that acceptance does not depend on the initial state — every state can be used as the initial state.

The results of Levenshtein and Romanov depend strongly on the fact that the code is finite. In this paper we provide a general automaton theoretic characterisation of arbitrary solid codes without any such restriction. Moreover, the solid code is regular as a language if and only if the automaton used in the characterisation can be reduced to an equivalent finite automaton with equivalent properties.

The main results of this paper are as follows: Every acceptor defines a solid code. For every solid code there is a fault-tolerant acceptor defining the code. Such acceptors expose the decomposition of potentially faulty received messages according to the code. For solid codes which are regular as languages these acceptors can be chosen to be finite while preserving all important combinatorial properties.

Part of this work was presented at the 14th Journées Montoises of Theoretical Computer Science [32].

Keywords
Code
Acceptor
Finite automaton
Fault-tolerance
State-invariance

1. Automata for codes
Automaton theory has many rôles in coding theory: automata are used to characterise classes of codes; they are employed to decide code properties; transducers serve as abstract models for encoding and decoding; they express error resistance properties; they can be used as filters for pattern matching; etc. Many details about automaton theoretic aspects of coding theory, but not all, can be found in the book “Codes and Automata” by Berstel, Perrin and Reutenauer [4]. The critical surveys [25], [26] may add further perspectives.

When considering the theory of codes, one has to distinguish two nearly disjoint fields, both called “coding theory”: the theory of error-correcting codes, mainly block codes (see [18], for example); the theory of codes with words of possibly different lengths, sometimes referred to as variable-length codes (see [3], [49], for example). A systematic proposal to unify these different aspects was made in [28].

Automaton theoretic models are of particular interest for codes which are finite or regular languages, because the corresponding algorithms rely on a finite-state transition processes. In many cases the restriction to finitely many states is not essential, but provides a deeper understanding of the computations involved and makes several properties decidable [28], [11].

Automaton theoretic studies of codes take into account at least the following different points of view, when considering a given class  of languages 
⁎
 satisfying certain properties.

•
Acceptors for exactly the languages .

•
Acceptors or decoders for exactly the messages encoded by languages , that is for 
⁎
 with .

•
Fault-tolerant acceptors or decoders for the messages encoded by languages .

•
Error-correcting acceptors or decoders for the messages encoded by languages .

Obviously, these settings are quite different. In this paper we describe fault-tolerant acceptors for messages encoded by solid codes.
For finite solid codes such automata were characterised in 1964 as state-invariant decoders without look-ahead (see Section 5). This characterisation is due to Levenshtein [40] and Romanov [46]. We generalise these considerations to infinite solid codes and show how a finite description of such codes translates into a finite description of a finite fault-tolerant acceptor for such codes. Intuitively, these acceptors are also state-invariant and do not resort to look-ahead. In general, to handle such situations, one needs to refer to a channel model as outlined in [28].

We show that every acceptor defines a solid code and that every solid code can be represented in this way. The acceptors considered in this context may be infinite; they are fault tolerant in the following sense: in an encoded message received after transmission through a noisy channel they correctly identify those code words which have been transmitted correctly. Thus, we do not look at acceptors of solid codes themselves, but at fault-tolerant acceptors of messages encoded by solid codes.

Consider a message encoded using a solid code. The encoded message is a sequence of code words. The message received after transmission through a noisy channel is a sequence of symbols the combination of some of which may result in the recovery of a code word. The usage of a solid code guarantees, that code words in the received message are detected unequivocally. A fault-tolerant acceptor, when reading a received message, will indicate the appearance of code words and possibly enable a decoding.

One of the best known characterisations of a class of codes by automata concerns prefix codes: Prefix codes are precisely the languages accepted by tree-shaped automata with the initial state as the root and the leaves as accepting states. Alternatively, if A is an acceptor with input alphabet X and  is the language accepted by A, then the language 
 is a prefix code or consists only of the empty word. Moreover, every prefix code is obtained in this fashion. When A is finite then the prefix code is regular.

Similar, but less explicit characterisations exist also for hypercodes [54], [52], [53] and code classes related to infix or outfix codes [19], [22], [45], typically in terms of the syntactic monoid of such codes. In addition, many studies concern the automaton theoretic characterisation of the set of messages encoded using a given code. To get a fairly comprehensive understanding of the situation we refer to [4], [28], [49], [56]. Further important early studies concerning the connection between automata and codes include [13], [38], [39], [41], [44].

In this paper we consider the class of solid codes. A solid code is a language L such that every word has a unique decomposition into words belonging to L and words which do not contain a word in L. Thus, solid codes are strongly resistant to transmission errors: those parts of a message which were transmitted correctly are also decoded correctly. We provide further details about solid codes in Section 4 below.

For finite solid codes an automaton characterisation was given by Levenshtein [40] and Romanov [46]. The characterisation uses state-invariant finite-state transducers which act as decoders in such a way that an output is generated exactly when a code word has been read completely. State-invariance means that the acceptance does not depend on the initial state – every state can be used as the initial state. Intuitively, state-invariance expresses the fact that, when an encoded message is read after transmission through a noisy channel, the decoder will find the code words regardless of intermediate incorrect parts.

The results of Levenshtein and Romanov depend strongly on the fact that the code is finite. In this paper we provide a general automaton theoretic characterisation of arbitrary solid codes. Moreover, the solid code is regular as a language if and only if the automaton used in the characterisation can be reduced to an equivalent finite automaton. Our characterisation does not involve decoders, but only acceptors. To define decoders one would need to know how the encoding is done: for a finite code L one can make the simple assumption that L encodes the symbols in an alphabet of size ; for an infinite code L the encoding would be specified by significantly more complicated transducer, the choice of which depends very much on the technical circumstances.

We use ideas from the constructions of Levenshtein and Romanov. Intuitively, though not quite truly, the acceptors involved are state-invariant. The concept of a decoded output being issued exactly at the end of reading a code word is modelled by accepting a word only if no accepting state was entered before the end of the word.

The main results of this paper are as follows: Every acceptor defines a solid code. For every solid code there is a fault-tolerant acceptor defining the code. Such acceptors expose the decomposition of potentially faulty received messages according to the code. For solid codes which are regular as languages these acceptors can be chosen to be finite while preserving all important combinatorial properties.

Our paper is structured as follows: In Section 2 we introduce the notation and some basic notions. Properties of solid codes are reviewed in Section 4. In Section 5 we define state-invariant decoders without look-ahead for finite solid codes and summarise the corresponding results of Levenshtein and Romanov. We introduce the main tool for our construction, the Levenshtein-Romanov mapping, in Section 6. We prove several of its properties under various assumptions. This leads to new characterisations of several classes of codes in s Section 7. In Section 8 we show that every acceptor defines a solid code and that every solid code defines a fault-tolerant acceptor. However, the fault-tolerant acceptors defined by solid codes are usually infinite, even when the solid code is a regular language. In Section 9 we show how to construct a reduced fault-tolerant acceptor for a solid code.

2. Notation and basic notions
We introduce some notation and review several notions and facts needed in this paper. As general references we use: the “Handbook of Formal Languages” [47], [48] for the theories of formal languages and automata; the monographs “Abstrakte Automaten” (Abstract Automata) [51] and “Algebraic Theory of Automata” [12] for foundations of automaton theory; the monographs “Theory of Codes” [3], “Codes and Automata” [4], “Free Monoids and Languages” [49], “Languages and Codes” [56] and the article “Codes” [28] for the theory of codes.

By  and 
 we denote the sets of positive and non-negative integers, respectively. We use the common notation for operations on sets; when there is no risk of confusion, we omit set brackets for singleton sets.

Let X be a set, and let ≅ be an equivalence relation on X. For , 
 is the equivalence class of x, and  is the factor set, that is the set of equivalence classes of the elements of X. We write  instead of 
 when which equivalence relation is used is obvious from the context.

An alphabet is a non-empty set. The elements of an alphabet are called symbols. Finite sequences of symbols are called words.

Let X be an alphabet. The set of all words over X, including the empty word ε, is denoted by 
⁎
. To exclude the empty word we write 
, that is, 
⁎
. With concatenation of words as multiplication, the set 
⁎
 is a monoid. A language over X is a subset of 
⁎
. For a language 
⁎
 and a word 
⁎
, the set
⁎
 is the left quotient of L by u. Given a language L, two words 
⁎
 are said to be Nerode equivalent with respect to L, 
, if and only if 
. Then 
 denotes the Nerode equivalence class of u.

In our context, the case when the alphabet X is a singleton set usually leads to trivial and clumsy exceptions. In the sequel we assume, unless stated otherwise, that an alphabet contains at least two distinct symbols and these will include a and b or other ones as needed without special mention.

For a word 
⁎
,
⁎
⁎
 is the set of prefixes of w. The set of proper prefixes of w is
 For 
⁎
, let 
 
 
 Note that 
, but that 
 is possible. One defines suffixes and infixes of words analogously. Thus
⁎
⁎
 is the set of suffixes of w, and
⁎
⁎
⁎
 is the set of infixes of w. The sets of proper suffixes and proper infixes of w are
 and
 respectively. For  and 
, the r-root of L is the set As , one has .

Let 
⁎
. The shuffle product of u and v is the set For languages 
⁎
, the shuffle product of L and 
 is the set

We consider the following classes of codes or languages 
 related to codes:


Name	Definition	Class
prefix code	LX+ ∩ L = ∅	
suffix code	X+L ∩ L = ∅	
infix code	
bifix code	
overlap-free2	
solid code	
p-infix code	X⁎LX+ ∩ L = ∅	
s-infix code	X+LX⁎ ∩ L = ∅	
comma-free code	X+LX+ ∩ L2 = ∅	
hypercode	
Image 3
To keep statements simple, we allow for L to be empty in all these cases. A language 
 is a prefix code or a suffix code, if and only if  or , respectively. For details about the classes of languages, see [28]. We summarise the relations between these classes:

•
;

•
;

•
;

•
;

•
.

The containments are shown in Fig. 1.
Fig. 1
Download : Download high-res image (52KB)
Download : Download full-size image
Fig. 1. Relations between the language or code classes considered.

Most of the usual classes of codes can be described conveniently as independent sets for various types of dependence systems on 
⁎
 or as sets of incomparable words with respect to certain n-ary relations on 
⁎
. For details we refer to [28] and the literature cited there. In this paper we refer to only a small number of such relations, all binary, and all being partial orders on 
⁎
. Their list is as follows for 
⁎
:


Relation	Definition	Independent Languages
u≤pv	v ∈ uX⁎	prefix codes
u≤sv	v ∈ X⁎u	suffix codes
u≤iv	v ∈ X⁎uX⁎	infix codes
The strict versions of these partial orders require that . Thus, for example, one has 
 if and only if 
. We also use the length-lexicographical order 
 on 
⁎
. To define this order one assumes an arbitrary, but fixed total order 
 on X, which, in turn, defines the lexicographical order 
 on 
⁎
. Then the length-lexicographical order is defined by the following conditions: 
 if and only if

1.
either 

2.
or  and 
.

The length-lexicographical order is not interesting from the point of view of codes. Its sets of incomparable words are singleton sets. It is, however, useful for the enumeration of words in 
⁎
.
We now turn to basic definitions in automaton theory. We do not make any assumptions about finiteness or computability. Such assumptions are introduced only when needed.

Definition 1

A deterministic semi-automaton is a construct  such that

1.
Q is a non-empty set, the set of states;

2.
X is a finite alphabet, the input alphabet;

3.
 is the transition function.

We permit the set of states to be infinite; we also permit the transition function to be non-computable. The input alphabet is always assumed to be finite. As we do not consider non-deterministic semi-automata in this paper, we omit the word ‘deterministic’ in the sequel. A semi-automaton is said to be finite if its set of states is finite. The definition of δ is extended to 
⁎
 by sequentiality as usual.
Definition 2

A deterministic acceptor is a construct 
 such that

1.
 is a deterministic semi-automaton;

2.
 is the initial state;

3.
 is the set of accepting states.

The language accepted by an acceptor A as above is the set
⁎
 A language is regular (or rational) if and only if it is accepted by a finite acceptor. Occasionally we also need to consider further classes in the language hierarchy; for those we refer to the general references listed above.
An acceptor is (initially) connected if, for every state , there is an input word 
⁎
 such that 
. It is strongly connected if, for any two states 
, there is an input word 
⁎
 such that . A state  is said to be useless if, for every word 
⁎
, .

There are several instances when we need to change the initial state of an acceptor. To indicate the fact that 
 has been replaced by state q as the initial state we write 
. If q is a useless state, then 
. An acceptor, which is initially connected and has no useless states, need not be strongly connected. On the other hand, if A is strongly connected and , then A has no useless states and is, a fortiori, initially connected.

Occasionally we need to consider an acceptor, the transition function of which is only a partial function. Such an acceptor is said to be partial; we sometimes emphasise the fact that the acceptor is not partial by saying that it is a total acceptor.

Let 
 and 
 be two partial or total acceptors. A is said to be a (partial) subacceptor of A if the following four conditions are satisfied:

1.
;

2.
;

3.
;

4.
for all 
 and all , if 
 is defined, then also  is defined and 
.

In such a case we write 
.
Definition 3

Let 
 be an acceptor, and let . A word 
 is accepted by A at stage i if the following conditions are met:

1.
;

2.
there are exactly  distinct prefixes 
 such that 
 for .

We denote by 
 the set of words which are accepted by A at stage i.
We list a few immediate consequences of this definition:

1.
 is the set of all non-empty words w such that 
 with 
 for every proper prefix u of w. In particular, when 
, this excludes the empty word. See Fig. 2.

Fig. 2
Download : Download high-res image (30KB)
Download : Download full-size image
Fig. 2. An automaton illustrating the acceptance at stages. There is only one accepting state, f. One has L1(Ae)=a⁎b and L1(Af)={b} ∪a+b = a⁎b. In general, for i > 0, 
⁎
.

2.
 for .

3.
The set 
 is the set of all non-empty words accepted by A, that is, 
.

Remark 1

The definition of 
 does not depend on the acceptor A. Consider a non-empty language 
. For , let 
 be the set of words in L which have exactly  proper prefixes in L. Let A be any deterministic acceptor3 for L, that is, . Then 
.

Recall that an equivalence relation ≅ on the set Q of states of an acceptor 
 is a congruence if and only if the following conditions are satisfied for all 
 and all :

1.
If 
 then 
 and q are either both in F or both in .

2.
If 
 then 
.

Given a congruence ≅, the factor acceptor is defined as
 where
 The following remark is used several times in the sequel.
Remark 2

Let A be an acceptor and let ≅ be a congruence on A. One has . Moreover, using Remark 1, one has 
 for all .

Each acceptor has a unique maximal congruence 
, often referred to as state equivalence: 
 are equivalent, 
, if and only if 
. The acceptor 
 is the reduced acceptor for A. If 
 is finite, then it has the smallest number of states among all acceptors for the language . See [51], [12] or other advanced textbooks on automata for details.
Given a language 
⁎
, the reduced acceptor (unique up to isomorphisms)can be built using the equivalence classes of words in 
⁎
 with respect to the Nerode equivalence. The set of states is the set of equivalence classes 
 with 
⁎
. This set is finite if and only if L is a regular language. The initial state is the class 
. The set F of accepting states consists of exactly those classes 
 for which . The transition function under input  leads from 
 to 
. These definitions do not depend on the representatives of the equivalence classes. We refer to this construction as the Nerode construction4

We also need to consider equivalence of states of different acceptors and equivalence of different acceptors. This is most conveniently expressed for automata with outputs [51], but can be re-phrased for acceptors as follows: Consider two acceptors 
 and 
. States  and 
 are equivalent, 
, if and only if 
. The acceptor A is said to simulate 
 if and only if, for every state 
 there is a state  with 
. The acceptors A and 
 are said to be universally equivalent,5 
, if and only if A and 
 simulate each other.

Remark 3

Let A and 
 be universally equivalent acceptors, and let q and 
 be equivalent states of A and 
, respectively. Then, for all 
.

We state an automaton theoretic characterisation of prefix codes, well-known in coding theory (see, for example, [3], [28]), adapted to the present terminology. To make the presentation self-contained, we include a proof.
Proposition 1

Let 
 be an acceptor with 
. Then 
 is a prefix code. Conversely, if 
 is a non-empty prefix code then there is an acceptor A such that 
.

Proof

If 
, nothing needs to be proved. Assume, therefore, that 
 contains at least two distinct words u and w. If 
 is not a prefix code such words exist with u a proper prefix of w, that is,  for some 
. But then 
 with , hence 
, a contradiction!

For the converse, consider the acceptor 
 defined as follows: Let  with 
, and s is a new symbol; let  and, for  and , let
  In essence, the transition function defines the tree of code words; however, the leaves are combined into the initial state ε which is also the only final state; the state s serves as a sink state. A word w is accepted if and only if . Thus 
⁎
.

As L is a prefix code, we have 
. □

Consider a property P of words in 
 according to which words in 
⁎
 can be decomposed into factors. For example, if L is a prefix code, then every word in 
 can be decomposed uniquely into a product of words in L, and every word in 
⁎
 can be decomposed into a product of words which are in L or which have no infix, which is in L. In this case, P would be defined as follows: A word 
 satisfies P if and only if . In general, a word may have any finite number of decompositions according to P. This idea is captured in the following definition.
Definition 4

Let P be a property of words in 
. A P-decomposition of a word 
⁎
 is a construct 
 with the following properties:

1.
.

2.
 with 
, each satisfying P.

3.
 with 
⁎
 such that no 
 has an infix satisfying P.

4.
.

Such P-decompositions are required, for instance, for the decoding of encoded messages received over a noisy channel. The decoder will attempt to determine a decomposition of the received messages into words possibly related to code words, and then attempt to invert the encoding, possibly correcting errors. The first part of this process is modelled by an acceptor as follows.
Definition 5

Let A be an acceptor, let P be a property of words in 
, let 
, and let 
 be a P-decomposition of w. Let
 The acceptor A exposes the P-decomposition 
 if and only if the following conditions are satisfied

1.
 for all 
.

2.
 for all 
.

Let A, P, w and 
 be as in Definition 5. If , then 
 is the empty sequence and 
. If , then the word 
 is accepted at stage i. The ends, but not the beginnings, of the infixes listed in 
 are recognised in the given order.
3. Restricted infix codes
In this section we provide new characterisations of p-infix and p-suffix codes. These characterisations may turn out to be interesting beyond the scope of the present paper. They resemble the fact that , is a prefix (suffix) code if and only if 
⁎
 
⁎
.

Theorem 1

Let 
 and .

1.
L is a p-infix code if and only if 
⁎
.

2.
L is a s-infix code if and only if 
⁎
.

Proof

We only prove the first statement. The second one follows by duality.

Suppose that L is a p-infix code, that is, 
⁎
. Then 
⁎
⁎
⁎
.

For the converse, assume that L is not a p-infix code. Let 
⁎
. Then there are words  and 
⁎
 such that 
. Then u is in L, but not in 
⁎
. □

4. Solid codes
Solid codes were introduced in [40] as strongly regular codes; they are called codes without overlap in [42]. The term solid codes seems to appear in [50] for the first time. A combinatorial characterisation of solid codes is provided in [33]. Many properties of solid codes are summarised in [28].

There are two definitions of solid codes, reflecting two different ways of interpreting the same situation: one purely combinatorial; a second one implying error-resistance properties.

The first and earlier definition is purely combinatorial; it defines “strongly regular codes” in the sense of [40] or “codes without overlap” in the sense of [42].

Definition 6

A solid code over X is a language 
 which is an overlap-free infix code.

For the second definition we need the following auxiliary notion. For a language 
 and a word 
⁎
, an L-decomposition of w is a construct 
 with 
 and 
 of words in 
⁎
, such that
 
 and, for , 
. An L-decomposition is a special kind of P-decomposition according to Definition 4. For every 
, every word in 
⁎
 has at least one L-decomposition.
Definition 7

A solid code over X is a language 
 such that every word in 
⁎
 has a unique L-decomposition.

Theorem 2

[33]
Solid codes as defined in Definition 6, Definition 7 are the same.

There is a subtle difference between the two definitions of solid codes which becomes apparent when one attempts to relatives the concept in the following sense: The properties are no longer required to hold for all words in 
⁎
, but only for words in a given language 
⁎
. Intuitively, for Definition 6, L would behave as an overlap-free infix code only for words in M; similarly, for Definition 7, only the words in M would need to have unique L-decompositions. These ideas are explored in [10], [16], [23], [24].
By the standard relativisation technique proposed in [10], the relativised versions of the two definitions are not equivalent in general.

Within the hierarchy of classes of codes, the solid codes form a proper subclass of the comma-free codes. They are incomparable to the hypercodes. Solid hypercodes have superb error-detection and synchronisation capabilities.

For a constructively given linear language L, it is undecidable whether it is a solid code (see [28], Table 9.1 and Theorem 9.5). On the other hand, if L is regular (constructively given), then it is decidable whether L is a solid code (see [33] and [28], Table 9.1).

These results are extended and refined in [14]: For regular languages given by finite non-deterministic acceptors, polynomial time bounds, in terms of the number of states and the number of transitions, are derived for deciding the properties of being overlap-free or solid. For linear languages the property of being overlap-free is undecidable in general. From [28], Theorem 9.5, it is known that the property of being an infix code is undecidable for linear languages.

For further general information regarding various aspects of solid codes see [33], [28], [50], [56]. Specific properties of solid codes are discussed in the following publications: information rate of solid codes [31], [29], [42], [43]; maximality of solid codes [27], [36], [37], [35], [30]; relativised solid codes [16], [10], [23], [24]; involution solid codes in the context of DNA computing [20], [34], [21]; information transmission [2]; application to pattern matching [15].6

5. State-invariant decoders for finite solid codes
For finite solid codes a characterisation in terms of transducers is given in [46]. This work is presented in more general terms in Chapter 11 of [28]. Here we provide a brief summary of these results.

Definition 8

A finite deterministic transducer is a construct  with the following properties and interpretation:

1.
Q is a finite non-empty set of states;

2.
X is the input alphabet and Y is the output alphabet; X and Y are finite and non-empty;

3.
 is the transition function;

4.
⁎
 is the output function.

The behaviour of a transducer on input words is defined by sequentiality as usual: 
  and 
 
Definition 9

Let X and Y be alphabets and 
 with . Let f be a bijection of X onto L. A state-invariant decoder for f without look-ahead is a finite deterministic transducer  with the following properties:

1.
For all  and all 
.

2.
For all , all  and all 
.

A state-invariant transducer without look-ahead for f produces exactly the decodings of the words in L; these are produced regardless of the initial state of the transducer and precisely at the time when the last symbol of a word in L has been read. If such a transducer reads an arbitrary word 
, the output is the concatenation of the decodings of those words in L, which it encounters as disjoint infixes of w. This establishes an intuitive connection with Definition 7.
Theorem 3

[46]
Let X and Y be alphabets and 
 with . Let f be a bijection of X onto L. Then L is solid code if and only if there is a state-invariant decoder without look-ahead for f.

A detailed proof of this theorem is given in [28]. The main construction, due to Levenshtein [40] and Romanov [46] is described in the next sections of this paper. There we also point out connections to related ideas in combinatorics on words or stringology.
6. Levenshtein-Romanov mapping
In our construction of acceptors for solid codes, the following mapping, due to Levenshtein [40] and Romanov [46], is essential.

Definition 10

Let X be an alphabet and let 
 with . The mapping 
⁎
⁎
 defined by
  is called the Levenshtein-Romanov mapping for L.

When 
 is used in the sequel we assume, without special mention, that L is non-empty and that L does not contain the empty word.
Proposition 2

Let 
 with  and let 
⁎
. The Levenshtein-Romanov mapping 
 has the following properties:

1.
, and if 
 and 
 then 
.

2.
If 
 then 
; in particular, 
.

3.
 if and only if 
.

4.
.

5.
If 
 then 
.

6.
.

7.
⁎
 if and only if 
⁎
.

Proof

1.
This follows from 
.

2.
Also obvious by the definition of 
.

3.
If  then , hence 
. Conversely, as 
, 
 implies .

4.
As 
, 
 by (3).

5.
We have
 by (2). By (4), 
. Thus 
.

6.
First we prove that 
. Assume the contrary. As 
 and 
, there is a word 
 such that 
. As 
, also 
. Moreover, 
. As 
 is the longest suffix of w which is a prefix of L, one has 
, but , a contradiction! As a consequence one has
 Using (5) this proves that 
.

7.
Let  where . Then 
, that is 
⁎
. The other direction follows from 
. □

The statements of Proposition 2 can be interpreted as follows: The Levenshtein-Romanov mapping 
 maps 
⁎
 onto ; it is the identity exactly on . With respect to 
, the mapping is monotone. By the sixth statement, it is sequential. The fifth property can be understood to express some kind of continuity.
The following statement is a direct consequence of the definition of 
.

Lemma 1

Let 
. Then 
⁎
 for all 
⁎
.

In connection with Proposition 2 the question arises whether 
 for all 
⁎
. We answer this in the following.
Proposition 3

Let 
 with . The following conditions are equivalent.

1.
⁎
.

2.
 for all 
⁎
.

Proof

Let 
⁎
. Since , we have 
.

Assume 
 for some 
⁎
. Then 
⁎
 by Lemma 1. By definition 
. Thus 
⁎
. □

The condition of 
⁎
 in Proposition 3 leads to new insights into the structure of certain kinds of prefix or suffix codes as discussed in the sequel.
The Levenshtein-Romanov mapping was introduced in 1964; it is essential for the construction of state-invariant decoders without look-ahead for finite solid codes. It was re-introduced 10 years later by Aho and Corasick as the failure function in their algorithm for string matching [1]. Various versions of this algorithm are presented and analysed in [4], [6]. In this part of the literature the resulting automaton for a finite set of “patterns” is known as the Aho-Corasick automaton, the string-matching automaton, the dictionary-matching automaton, the dictionary automaton or the pattern-matching machine. Related constructs are used in [5], [17] to formulate algorithms for deciding the unique decipherability of a given finite language used as a code. Aho-Corasick automata have the same underlying transition structure as the state-invariant transducers without look-ahead for finite solid codes. The underlying ideas of Aho-Corasick automata are also found in Levenshtein's 1964 paper on properties of coding and self-adjusting automata [41]. Some parts of Proposition 2 are proved implicitly in [40], [46], [28] or explicitly as Lemma 5.1 of [6].

7. The condition 
⁎
 and its dual
The conditions that 
⁎
 or its dual 
⁎
 have unexpected consequences, some of which are explored in the present section.

Lemma 2

Let 
. The following statements hold true:

1.
If 
 then 
⁎
.

2.
If L is a prefix code then 
⁎
 implies 
⁎
.

3.
If L is a suffix code then 
⁎
 implies 
⁎
.

Proof

(1) Clearly 
⁎
. Consider 
⁎
 with . Then there is 
 such that . As 
⁎
, one has 
 with  and 
. Thus 
, a contradiction.

(2) Let L be a prefix code and consider 
⁎
. Then 
 with 
⁎
 and 
. If 
, then  with , and 
, contradicting the fact that L is a prefix code. Hence 
 and 
 as . Therefore, 
⁎
, a contradiction.

(3) Let L be a suffix code and consider 
⁎
. Then 
 with 
, and 
⁎
. As L is a suffix code 
. Therefore, 
⁎
. □

Each of the conditions 
⁎
 and 
⁎
 implies that L is uniquely decodable, that is, a code. In contrast, the condition 
 does not imply this: The language  over  satisfies the condition, but is not a code.
The converse of Lemma 2 (1) is not true in general, not even for codes. Consider  with . The language L is a code. One has . Hence 
⁎
. But 
. This same example shows also that Statements (2) and (3) of the same lemma do not hold true for arbitrary codes. Corollary 1 below shows, that the implications are actually equivalences.

By left-right duality one obtains the following results.

Lemma 3

Let 
⁎
. The following statements hold true:

1.
If 
 then 
⁎
.

2.
If L is a suffix code then 
⁎
 implies 
⁎
.

3.
If L is a prefix code then 
⁎
 implies 
⁎
.

Corollary 1

Let 
 with .

1.
L is a p-infix code if and only if L is a prefix code and 
⁎
.

2.
L is a p-infix code if and only if L is a prefix code and 
⁎
.

3.
L is an s-infix code if and only if L is a suffix code and 
⁎
.

4.
L is an s-infix code if and only if L is a suffix code and 
⁎
.

Proof

We prove only the first statement. The remaining ones follow by duality.

Let L be a p-infix code, that is, 
⁎
. Then 
, hence 
⁎
 by Lemma 2 (1).

Conversely, let L be a prefix code and 
⁎
. Then 
⁎
, that is, L is a p-infix code. □

These results lead to new characterisations of s-infix codes and overlap-free prefix codes as follows.
Theorem 4

Let 
 with . L is an s-infix code if and only if 
 for all 
⁎
 and .

Proof

Let L be an s-infix code. Then L is a suffix code and 
⁎
 by Corollary 1 (3). Let 
⁎
 and . Then 
⁎
, hence 
 by Proposition 3. As  one has 
. Thus 
 as L is a suffix code.

For the converse, assume that 
 for all 
⁎
 and . Suppose that . Then 
 by Proposition 2. Hence , that is, L is a suffix code. To prove that L is an s-infix code, we need to show that 
⁎
. The inclusion 
⁎
 is true by definition. For the converse inclusion consider 
⁎
. Then  for some 
⁎
 and . Hence 
. On the other hand, by the definition of 
 implies 
. Thus . □

Theorem 5

Let 
 with . L is an overlap-free prefix code if and only if 
 for all  and 
.

Proof

Let L be an overlap-free prefix code. Consider  and 
. Thus 
. By Proposition 2 one has 
.

We now prove that 
. Assume the contrary, that is, 
. As L is a prefix code, it follows from 
 and 
 that 
. Thus 
 for some 
 with 
. Hence there is a word  with 
 such that u and w overlap, contradicting the assumption that L is overlap-free.

Thus 
. By Proposition 2 this implies 
.

Conversely, assume that 
 for all  and all 
. Suppose that L not a prefix code or not overlap-free.

If L is not a prefix code, then there are  and 
 such that . Thus 
, hence , a contradiction.

If L is not overlap-free, there are non-empty words  such that  and . Thus 
. Hence 
 and 
, again a contradiction! □

In the sequel we use a combination of the premises of Theorem 4, Theorem 5. We consider languages, which are both s-infix codes and overlap-free prefix codes. Such languages are precisely the solid codes.
8. Fault-tolerant acceptors for solid codes
We now consider fault-tolerant acceptors for solid codes. The underlying idea is derived from Definition 9, Theorem 3 and the proof of that theorem. Those constructions rely on the assumption that the solid codes under consideration are finite, allowing one to consider a specific natural encoding. We drop this assumption. Consequently, without any knowledge about the encoding, we cannot expect to obtain a decoder, but only an acceptor. In general, this acceptor can be infinite. For finite solid codes the acceptor is similar to a finite state-invariant transducer without look-ahead. For arbitrary solid codes we expect to obtain an acceptor with special properties which correspond to state-invariance and the lack of look-ahead. Moreover, we expect these properties to be preserved when the acceptor is reduced. This would guarantee that a solid code, which is regular (or rational) as a language, is accepted by a finite acceptor with these special properties.

We follow the structure of Proposition 1, the characterisation of prefix codes by acceptors: In Theorem 6 we state that every acceptor A defines a solid code: this code is the suffix root of the language consisting of all those words which are accepted by A regardless of the initial state. In Theorem 8 we state that every solid code L defines an acceptor A such that the solid code 
 defined by A coincides with L.

Theorem 6

Let 
 be a deterministic acceptor. The following statements hold true:

1.
The language
 is an overlap-free p-infix code.

2.
The language
 is a solid code.

Proof

Let
 We need to prove that 
 is a p-infix code and overlap-free.

By Proposition 1, the languages 
 are prefix codes for all . Hence, also their intersection 
 is a prefix code.

Suppose that 
 is not a p-infix code. Then there are words 
 and 
 such that 
. As 
, one has  and  for all . Therefore, also 
. The fact that 
 implies that 
, a contradiction!

Now suppose that 
 is not overlap-free. Then there are words 
, not necessarily distinct, which overlap. Without loss of generality, we assume there are words 
 such that 
 and 
. As 
, one has
 for all . The fact that 
 implies that 
, a contradiction!

This proves, that 
 is an overlap-free p-infix code. As 
, also L is an overlap-free p-infix code. By definition, L is also a suffix code. Hence, L is a solid code. □

In Theorem 6 we include the situation when 
. This is not very useful, but also means that such states q should be discarded.
Definition 11

Let 
 be a deterministic acceptor. Define
 and

Theorem 7

Let A and 
 be universally equivalent acceptors. Then 
 and 
.

Proof

The first statement follows from Remark 3. The second statement is an immediate consequence. □

In the statements of Theorem 6 the intersection expresses a kind of state invariance; taking the suffix root can be interpreted as avoiding look-ahead.
The following example shows that taking the suffix root is essential.

Example 1

Let  where  and  for . Then 
⁎
 which is an overlap-free p-infix code but not a suffix code, hence not a solid code. The suffix root of the intersection is the singleton language , a trivial solid code over the alphabet . The corresponding automaton is shown in Fig. 2. □

By Theorem 6, every deterministic acceptor, finite or infinite, describes a solid code as the suffix root of the language accepted regardless of the initial state. We now show that every solid code, regardless of its cardinality, is defined by an acceptor in this fashion. To our knowledge, this construction was first proposed in [40], [46], but only for finite solid codes; for those the acceptor can be converted into a state-invariant decoder without look-ahead in the sense of Theorem 3. For arbitrary finite languages the resulting finite acceptor is essentially the Aho-Corasick automaton (or string-matching automaton, dictionary automaton or pattern matching machine, etc.). In the sequel, in considering a language L over X, we only assume that 
 and . We do not assume that L is finite or has any simple computational structure; not even that L is recursively enumerable. Certainly, to perform concrete constructions one would have to make additional assumptions about L.
Definition 12

Let 
 with . The Levenshtein-Romanov acceptor for L is the acceptor 
 defined as follows:

1.
;

2.
;

3.
;

4.
 for  and .

The language  accepted by the Levenshtein-Romanov acceptor A for a language L is usually not equal to L. The difference will be explained further below. The reduced acceptor obtained from A is called the reduced Levenshtein-Romanov acceptor for L.
Example 2

The language accepted by the Levenshtein-Romanov acceptor for L with 
 turns out to be a subset of 
⁎
. The details are as follows:

Proposition 4

Let 
 with . Let 
 be the Levenshtein-Romanov acceptor for L.

1.
For all  and all 
⁎
, one has 
.

2.
⁎
.

3.
⁎
 if and only if 
⁎
.

4.
If 
 then 
⁎
.

Proof

1.
As , one has 
 by Proposition 2. For , one has
 Consider  with 
 and  and assume that 
. Then
 by Proposition 2.

2.
For  one has 
, hence . If  then 
, hence 
⁎
, again by Proposition 2.

3.
One has  if and only if 
 by the definition of A. If 
⁎
 then 
⁎
 implies 
, hence 
⁎
 by Proposition 3. Conversely, if 
⁎
, then 
 for all 
⁎
 by Proposition 3. This implies .

4.
This follows from Lemma 2.1 and 3. □

Example 3

Consider 
 instead. The Levenshtein-Romanov acceptor 
 for 
 is obtained from A by making also the state ba accepting. Now 
⁎
 and, hence 
⁎
. However, 
. This shows that the converse of Proposition 4 (4) is not true in general. □

Lemma 4

Let 
 with , and let  be its Levenshtein-Romanov acceptor. Then the following statements hold true:

1.
A is initially connected and has no useless states.

2.
A is strongly connected, if and only if for every word  there is a word 
 such that .

3.
If  then A is not strongly connected.

4.
If L is finite and  then A is strongly connected.

5.
If L is an overlap-free prefix code with , then A is strongly connected.

Proof

1.
The statement is a direct consequence of Definition 12.

2.
By Proposition 4 (1), one has 
. Hence, 
 if . By (1) the acceptor A is initially connected. Therefore, it is strongly connected. Otherwise, one cannot return to the state ε.

3.
Since , we have  for every 
.

4.
Let  and let . Then 
⁎
. Thus 
 for every 
⁎
.

5.
Let  and consider . Then there is a 
⁎
 such that . Now Theorem 5 implies 
, that is, . □

From Lemma 3 one concludes that the Levenshtein-Romanov acceptor for a non-empty language 
 with  is strongly connected if and only if . This holds, in particular, for a non-empty solid code L.
The language 
⁎
 over  of Example 2 is an overlap-free prefix code containing b. Note that the word b has no proper prefixes or suffixes, hence does not overlap any word in the language including itself. As  its Levenshtein-Romanov acceptor, shown in Fig. 3, is not strongly connected. The reduced acceptor shown in Fig. 4, however, is strongly connected.

Corollary 2

Let 
 with , and let A be the Levenshtein-Romanov acceptor for L. For , if 
 then 
⁎
.

Proof

In each case 
. □

Corollary 3

Let 
 with , and let A be the Levenshtein-Romanov acceptor for L. If 
⁎
 and L is regular then also  is regular.

Proof

The assumption implies that 
⁎
. With L also 
⁎
 is regular. □

The Levenshtein-Romanov acceptor A for a language L is finite if and only if  is finite, hence, if and only if L is finite. Thus, when L is an infinite regular language satisfying the condition 
⁎
, the acceptor A is infinite, but 
⁎
 is regular. As we want to characterise fault-tolerant acceptors for solid codes we have to investigate how the special properties of the Levenshtein-Romanov acceptor are translated into properties of the equivalent reduced acceptor.
Remark 4

The condition 
⁎
 does not imply that L is a code. Consider the language . Then . Hence 
⁎
. However, L is not a code. The same language also satisfies 
.

Proposition 5

Let 
 be a non-empty overlap-free prefix code. Let A be the Levenshtein-Romanov acceptor for L. Then,
 for all  and all .

Proof

Consider  and . By Theorem 5, one has
 for all 
. Thus,
 and
 This proves the statements taking into account that , but 
. □

Thus the accepting states of the Levenshtein-Romanov acceptor A for an overlap-free prefix code essentially reset the acceptor to the initial state. When a long word is read, once an accepting state is reached a corresponding output can be generated, and the reading continues with the rest of the input starting again in the initial state ε.
Proposition 6

Let 
 with , and let A be the Levenshtein-Romanov acceptor for L. The following statements hold true:

1.
If L is an s-infix code, then 
 for all .

2.
If L is a solid code, then 
 for all .

Proof

Let .

1.
For , one has 
, hence, trivially 
. Let L be an s-infix code. Assume that . Then
 by Theorem 4 as L is an s-infix code. This proves that 
.

2.
Let L be a solid code. Then L is a prefix code. Thus, 
. We show that 
 for all 
. This would prove that 
.

Suppose otherwise. Then  for some 
. Consider 
. By assumption 
. There are two cases:

(a)
: Then 
 is an infix of , contradicting the fact that L is an infix code.

(b)
: Then 
 and  overlap, contradicting the fact that L is a solid code. □

By combining the statements of Proposition 5, Proposition 6 one obtains the following property of the Levenshtein-Romanov construction.
Theorem 8

Let 
 be a non-empty solid code, and let A be the Levenshtein-Romanov acceptor for L. Then 
 

Proof

One has 
⁎
 by Corollary 2. By Proposition 5, 
 for all . Hence 
 
 The intersection is a subset of 
, hence of 
⁎
. As L is also a suffix code, . This proves the equality as claimed. □

From Propositions 6 and 8 we obtain a characterisation of solid codes by their fault-tolerant decoders.
Corollary 4

A language 
 is a non-empty solid code if and only if there is an acceptor 
 such that 
 
 If, in addition, L is a regular language, then there is a finite acceptor with this property. Moreover, if , the acceptor can be chosen to be strongly connected.

Proof

The statement follows from Propositions 6 and 8, Corollary 3, Remark 2 and Lemma 3. □

Example 4

Let  and L = 
. The language L is regular and a maximal solid code (see [33], [56]). The states and transitions of the Levenshtein-Romanov acceptor for L are summarised in the following table:


State	Transition
a	b
ε	a	ε
a	a	ab
ab	aba	ε
abai+1	abaib
aba	abaib2
a	ε
Accepting states are 
. Reduction results in the following six states:
 The reduced acceptor is shown in Fig. 6. □
Fig. 6
Download : Download high-res image (72KB)
Download : Download full-size image
Fig. 6. The reduced Levenshtein-Romanov acceptor for the solid code 
 of Example 4.

Theorem 9

Let 
 be a non-empty solid code. For every word 
, the Levenshtein-Romanov acceptor for L exposes the L-decomposition of w.

Proof

Let 
 be the L-decomposition of w, where
 For , no prefix of 
 is accepted. Let . Then 
 and 
. Assume now, that 
 for i with . As 
, one has
 hence
 for all 
 by Proposition 2. Using the properties of the decomposition,
 for every 
 and
 Thus
 □

The construction of the state-invariant transducer without look-ahead used in the proofs of Theorem 3 DIFFERS slightly from our construction of the Levenshtein-Romanov acceptor as follows: There the set of states is 
 instead of . The transition from a state q upon input x leads to 
 if 
, and to ε otherwise. Hence, in that construction, the state ε cannot be interpreted as an accepting state as it is reached by the empty word or a word which does not end on a proper prefix of L or a word which ends on a word in L. To distinguish these cases, for each state q and each input symbol x, a Mealy output  is issued, which is the empty word, if 
, and the decoding of qx otherwise. In our construction these situations are separated. Hence we could attach Moore outputs to the states, not the transitions, as follows: For an accepting state q, that is, , the output is the decoding of q; otherwise the output is the empty word. With this modification, the Levenshtein-Romanov acceptor for a finite solid code can be considered as a decoder. On the other hand, the older construction also exposes the L-decomposition of every word by issuing non-empty outputs at the ends of the words in L.

9. Reduced fault-tolerant acceptors for solid codes
The Example 2, Example 4 lead to the assumption that for regular solid codes L the reduced Levenshtein-Romanov acceptors are finite. The results of this section show that this is indeed the case. To this end we prove in Theorem 10 a certain converse to Theorem 6.

We start with a property of left quotients of codes.

Lemma 5

Let 
.

1.
L is an overlap-free prefix code if and only if 
 for all 
⁎
.

2.
L is a suffix code if and only if 
⁎
 for all .

Proof

1.
Assume 
. Then , and 
 for some 
. If  then 
, hence L is no prefix code. If  then  and 
 overlap.

Conversely, if L is no prefix code then 
 for . If L is not overlap-free then  with 
 and . Consequently, 
.

2.
Assume 
⁎
. Then  and there is a 
⁎
 such that 
 with 
. This implies 
 contradicting the assumption that L is a suffix code.

If L is not a suffix code then 
 for some 
 and , that is, 
⁎
. □

Theorem 10

Let L be a non-empty subset of 
, and let A be an initially connected acceptor with 
⁎
. The following statements hold true:

1.
A has no useless states.

2.
If L is an overlap-free p-infix code then
⁎

3.
If L is a solid code then 
.

Proof

Let 
. First we prove that A has no useless states. Consider a state q of A. As A is initially connected, there is a word w such that 
. For  one has 
⁎
, hence 
. Therefore, q is not useless.

For any word 
⁎
, let
 
 If 
, one has 
⁎
⁎
.

Now assume that L is an overlap-free p-infix code. We show that 
 for . Let 
 and assume that 
. Then there is a 
⁎
 such that 
, that is, 
. By Lemma 5.1 
. Thus 
 where 
⁎
 and 
 and we obtain 
 for some 
, a contradiction to 
⁎
.

The inclusion 
 is obvious, and Proposition 1 yields 
⁎
.

Finally, if L is a solid code, it is not only an overlap-free p-infix code, but also a suffix code, hence 
⁎
 and, therefore, Item 2 yields
⁎
 □

The inclusions in Theorem 10.2 can be proper. We derive an example.
Example 5

Let 
⁎
. Then L is an overlap-free p-infix code. Let 
⁎
⁎
. The equations in the proof of Theorem 10 show 
 for all . Thus 
⁎
 for all . Moreover, 
⁎
 and 
 if 
. This yields  
 
⁎
.

Observe that the prefix code 
⁎
 is p-infix but not overlap-free. This follows from 
⁎
 and 
. □

Note that the sets 
 as defined in the proof of Theorem 10 determine the states in the following sense.

Lemma 6

Let 
 be a non-empty suffix code. For 
⁎
 let 
 as defined in the proof of Theorem 10. Then 
⁎
. Hence, for 
⁎
, one has 
⁎
 if and only if 
.

Proof

Suppose 
⁎
. Then  with  and  for some suffix 
 of w. Hence, 
. Since L is a suffix code, this is impossible. As 
⁎
⁎
 and 
⁎
⁎
, one has 
⁎
 if and only if 
. □

It is well known that, for any given language L, the reduced acceptor A of L can be built incrementally based on the equivalence classes of the Nerode equivalence with respect to L. To obtain the states and to define the transitions of A, one enumerates the words in 
⁎
 according to the length-lexicographical order 
. The states are denoted by representatives of the equivalence classes of words. When all words up to and including w have been considered, one has an acceptor, partial or total,
 One starts with 
, where 
, 
 is nowhere defined, and where 
 either contains 
 or is empty depending on whether  or not.
Assume that 
 has been built. If 
 is total, then the process ends with 
; moreover, let 
 for all 
⁎
 with 
. Otherwise, the process continues with the word w following v in the length-lexicographical order by building 
 from 
. Let  with . Then 
. If 
 is defined then 
. Otherwise, if w is equivalent to some 
 then define 
 and
  for all 
 and . If w is not equivalent to some such r, let 
 be a new state, 
,
 
 and
  for all 
 and . The construction is summarised as follows:

Proposition 7

For every language L, the procedure above converges to the reduced acceptor A for L in the following sense:

1.
If 
 is total for some 
⁎
 then 
 for every 
⁎
.

2.
For every 
⁎
, if 
 is partial then the states in 
 represent classes of the Nerode equivalence, 
 is defined by the multiplication of these classes by symbols on the right, and 
 consists of exactly those states in 
 which represent classes contained in L. Moreover, for every word 
⁎
 with 
, 
 is partial subacceptor of the partial or total acceptor 
, and for some such v, this inclusion is proper.

Moreover, assume that the following two properties are decidable for all 
⁎
:
•
Is ?

•
Is 
?

Then the process is effective. In particular, if L is regular, then the finite reduced acceptor for L is obtained in finitely many steps.
This is, of course, well-known, but rarely stated in these terms. For the present paper we use these ideas applied to the special case when the language under consideration has the form 
⁎
 where L is a solid code. Using Theorem 10 and Proposition 7, for any solid code L, one can build a reduced acceptor equivalent to the Levenshtein-Romanov acceptor for L.
Theorem 11

Let 
 be a non-empty solid code. The reduced Levenshtein-Romanov acceptor for L is determined by the procedure above. Moreover, if L is given constructively as a regular language,7 then the reduced Levenshtein-Romanov acceptor for L can be computed from the description of L.

Proof

One builds the reduced acceptor for 
⁎
. When L is constructively regular, the two properties above in Proposition 7 are decidable. □

The construction of the reduced Levenshtein-Romanov acceptor for a given regular solid code as outlined above is highly inefficient. For detailed complexity analyses of similar algorithms and related ones we refer to [4], [8], [6], [7], [9], [55] and literature cited there. The construction outlined above can most likely be improved. A simple upper bound on the time complexity of the task of constructing the reduced Levenshtein-Romanov acceptor for a given regular solid code can be obtained from Theorem 10 using well-known automaton theoretic algorithms:
Remark 5

Let 
 be a non-empty solid code, given as an initially connected deterministic finite acceptor 
 with . Construct the non-deterministic acceptor 
 with
  where  and . Then 
⁎
. Next, build an initially connected deterministic acceptor 
 such that 
⁎
. Finally, one reduces 
. Let  and . Constructing 
 takes  steps. One has 
, and building 
 takes at most 
 steps. Reducing 
 requires at most 
 steps.

Thus, the reduced Levenshtein-Romanov acceptor for L can be obtained in time8 
.

As an acceptor A with  a solid code has quite specific properties [14] it seems likely that the bound stated in Remark 5 can be improved significantly.