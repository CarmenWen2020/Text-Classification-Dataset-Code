Abstract
We investigate the problem of scheduling jobs on open shop and flow shop systems of two machines, subject to the constraints that only some jobs can be scheduled simultaneously on different machines. These constraints are given by a simple undirected graph G, called the agreement graph. The objective is to minimize the makespan. We first show that the open shop problem with two distinct values of release times is NP-hard even for operation sizes in {1,2} and we present a restricted case that can be solved in polynomial time. Then, we consider the problem with null release times and we show that when restricted to arbitrary trees, the problem is NP-hard. We also present a linear algorithm when restricted to caterpillars and we show that this algorithm can be used to solve the case of cycles in polynomial time. For the flow shop problem, we show that the problem is NP-hard for trees and that this result holds even if the preemption is allowed.

Keywords
Scheduling
Complexity
Flow shop
Open shop
Makespan
Agreement graphs

1. Introduction
In shop scheduling problems with agreement graphs, we have a set {
} of n jobs that has to be processed on a given set {
} of m dedicated machines and a simple undirected graph  over the jobs, called the agreement graph. Each job 
 consists of m operations 
 (), where 
 has to be processed on machine 
 for 
 time units. The processing times 
 are nonnegative numbers. Two operations belonging to the same job cannot be processed at the same time and each machine can process at most one job at a time. On the other hand, each vertex in G represents a job and two jobs can be processed at the same time on different machines (are not in conflict) if and only if they are adjacent in G. The objective is to find a feasible schedule that minimizes the makespan 
, i.e. the overall time needed to process all the jobs. When the operations of each job can be processed in any order, the model is referred to as Open Shop with Agreement graph (OSA) and when the jobs have the same processing order through the machines, the model is referred to as Flow Shop with Agreement graph (FSA).

Shop scheduling with agreement graphs can be found in the problems of shop scheduling under resource constraints, where jobs may conflict with each other if they share the same resources [1]. We use the three field classification  of Graham et al. [2] to denote our scheduling problem. In this classification, the α field describes the machine environment, the β field provides details of processing characteristics and constraints and the γ field describes the objective to be optimized. According to this classification, we denote our scheduling problem by 
, where  indicates the presence of an agreement graph  over the jobs. The proportionate processing times assumption implies that each job has the same processing time on each machine; in that case, the resulting problem is denoted 
. Besides the processing times, a job 
 can have a release time 
, where any operation of 
 cannot begin before time 
. A schedule is called preemptive if each job can be preempted at any time and restarted later at no cost. In the open shop system, the preempted job can be restarted on another machine, whereas, in the flow shop system, a job cannot start processing on machine 
 until it has completed its processing on machine 
. Therefore, in this latter case, the preempted job should be put back on the same machine. The complement of the agreement graph is called the conflict graph and it is clear that the problem of scheduling with agreement graph and the problem of scheduling with conflict graph are polynomially equivalent.

Tellache and Boudhar [3] studied the Open Shop problem with Conflict graph (OSC). They showed that the two-machine OSC problem with 
 is NP-hard in the strong sense even when restricted to complements of bipartite graphs. The same result holds for the three-machine OSC problem with an arbitrary conflict graph and 
. After that, efficient algorithms were proposed for the two-machine OSC problem with 
, and for the three-machine OSC problem with 
 and conflict graphs being complements of triangle-free graphs. They also proved that by allowing preemption, the two-machine OSC problem becomes easy to solve for arbitrary conflict graphs. On the other hand, they found that the OSC problem is polynomially equivalent to a particular case of the open shop problem under resource constraints, from which new complexity results of the latter problem were established. Recently, Tellache et al. [4] showed that the proportionate two-machine OSA problem is NP-hard in the strong sense for two distinct values of processing times 
, ( and ( or )) and more general agreement graphs. This result closes the complexity status of the two-machine OSA problem with two values of processing times. They also derived new complexity results of the open shop under resource constraints and of the partition into triangles problem. The same authors addressed in [5] the Flow Shop problem with Conflict graph (FSC). They found that the two-machine FSC problem is NP-hard in the strong sense even when restricted to a complement of a complete split graph. They also showed that, for complements of complete bipartite graphs, the problem remains NP-hard. This latter result holds even if the preemption is allowed. Then, they considered the case of unit-time operations and they showed that it is NP-hard in the strong sense. On the other hand, an 
 algorithm for the problem 
 
 
 was given and graph classes on which the problem 
 
 
 is solvable in polynomial time were presented (where 
 
 
 indicates the presence of a conflict graph 
 
 over the jobs). After that, they proved that the FSC problem is polynomially equivalent to a special case of the flow shop problem under resource constraints, from which new complexity results of the latter problem were established. In [6], the authors studied the FSC problem on two machines with unit-time operations. They developed a mathematical model and a branch and bound algorithm. For the same problem, Cai Y. et al. [7] presented a 4/3-approximation algorithm for an arbitrary conflict graph. For arbitrary processing times and complements of complete bipartite graphs, they established a simple 3/2-approximation algorithm. The two-machine FSC problem has also been addressed in [8], the authors proved that the permutation schedules are not dominant even for two machines and they presented a special case for which an optimal schedule can be found by a permutation schedule. Then, four Mixed Integer Linear Programming (MILP) models have been presented alongside with an experimental study.

In this paper, we study the OSA and FSA problems with release times and when the agreement graph is a tree. Section 2 considers the open shop problem, whereas Section 3 is devoted to the flow shop case.

2. Open shop
In this section, we first consider the OSA problem with two distinct values of release times, then we study the problem when restricted to trees.

2.1. Case of 
 and 
It has been shown in [3] that 
 can be solved in 
 for arbitrary agreement graphs. In what follows, we show that when the release times of the jobs take values in  (r arbitrary), the problem becomes NP-hard in the strong sense for agreement graphs having the form , where the subgraph  induced by A is an empty (edgeless) graph and the subgraph  induced by B has a specific form, e.g. an empty, a complete, a bipartite graph, etc. Depending on the structure of , the graph G can take different forms. For instance, if  is an empty (resp. bipartite) graph, then G is a bipartite (resp. 3-partite) graph and when  is a complete graph, we obtain a split agreement graph.

Theorem 1

 is NP-hard in the strong sense for G being a graph of the form  (defined above).

Proof

The candidate used in the reduction process is the 3-dimensional matching problem (3DM) which is known to be NP-complete in the strong sense [9]. The input consists of a set , where X, Y and Z are disjoint sets having the same number q of elements. Does M contain a subset 
 of q triples such that no two elements of 
 agree in any coordinate?

Given an arbitrary instance of 3-DM, we construct an instance I of our scheduling problem as follows. Let 
. For each , let 
 so that 
. To each 
  corresponds a subgraph 
 of the agreement graph G defined as follows. Let 
 be the jobs set such that 
, whereas 
. The set 
 is in correspondence with the set 
 so that each element 
 of 
 is associated with a unique job 
 of 
 (see Fig. 1). Each job 
 of 
 is adjacent to its corresponding job 
 of 
. Moreover, all the jobs of 
 (resp. 
) are adjacent to all of the jobs of 
 (resp. 
). On the other hand, each element y of Y (resp. z of Z) corresponds to a unique job 
 of 
 (resp. 
 of 
). Each job 
 (already denoted 
) of 
 (resp. 
 denoted 
 of 
) is adjacent to the job 
 of 
 (resp. 
 of 
) corresponding to the element y (resp. z). Finally, each job 
 of 
 is adjacent to its unique corresponding job 
 of 
. Let 
 and 
, 
 and 
 are defined analogously. The sets 
, 
, 
 and 
 form each an independent set and let 
. The adjacency among the vertices of 
 is such that the subgraph  induced by B has the fixed structure mentioned in the beginning of this theorem. Each job has the same processing time on the two machines and they are indicated in Fig. 1 along with the release times. Note that in Fig. 1, 
, 
, 
 and 
. The graph G satisfies the form given in the beginning of the proof since it can be written as , and this completes the construction of the instance I.

Fig. 1
Download : Download high-res image (117KB)
Download : Download full-size image
Fig. 1. Instance I of Theorem 1.

Now, we prove that there exists a feasible schedule σ for I with 
 if and only if 3-DM has a solution.

Suppose that 3-DM has a matching 
 and let 
 be the subset of 
 corresponding to 
 such that 
 . We construct the schedule σ of I as follows. We schedule each job of 
 with its corresponding jobs of 
, 
, 
 and 
 in a time interval of length 8 as shown in Fig. 2.(a) and (b). This requires 8q time units to schedule all the jobs of 
. The remaining jobs of 
 and 
 and the jobs of 
 and 
 are scheduled starting from , such that for each i , the jobs are scheduled in a time interval of length 8, as depicted in Fig. 2.(c) and (d). The obtained schedule is feasible and 
 
.

Fig. 2
Download : Download high-res image (58KB)
Download : Download full-size image
Fig. 2. Schedule σ of the jobs of I.

Conversely, assume that there is a feasible schedule σ for I with 
. Since 
 (resp. 
), then the total processing time of all the jobs of 
 and 
 (resp. 
 and 
) on each machine is equal to  (resp. ). The total processing time of 
, 
 and 
 on each machine sums up to . Therefore, the total processing time of all the jobs on each machine is equal to . This implies that the jobs should be scheduled without idle times on both machines and 
. The jobs of 
 are mutually in conflict with 
 and 
. This implies that, at each instant in the time interval , we have exactly one of the jobs of 
 in processing. The jobs of 
 are adjacent only to the jobs of 
. By scheduling all the jobs of 
, we are left with one operation on each machine of each set 
. On the other hand, the jobs of 
 can be processed only with their corresponding jobs of 
. By scheduling all the operations of 
, we have on each machine an idle time of one unit opposite to each operation of 
 scheduled in parallel with an operation of 
. Furthermore, each job of 
 is adjacent to exactly one job of 
. By processing all the jobs of 
, we have an idle time of one unit opposite to each operation of 
. The jobs of 
 can be processed simultaneously with the jobs of 
 or with the remaining parts of the operations of 
 and 
. Since the jobs of 
 should be processed in  and since in this interval we have exactly one of the jobs of 
 in processing at each instant, the only possible configuration is to process the jobs of 
 in parallel with the jobs of 
. We are left with one operation on each machine of each set 
, these operations should be processed with the remaining parts of their corresponding operations of 
 and 
, as depicted in Fig. 2. We can observe that the operations of 
 scheduled on 
 in the time interval  correspond to a subset 
 with q elements that represents a solution of 3-DM. Another solution of 3-DM can be obtained if the operations of 
 scheduled on 
 in the time interval  are different from the former set. This completes the proof of the theorem. □

In what follows, we show that, when restricted to 
, the problem can be solved in polynomial time for a particular class of agreement graphs.

Theorem 2

 can be solved in polynomial time for complements of bipartite graphs.

Proof

We will also use an algorithm that finds an optimal schedule for the two-machine OSA problem with unit-time operations and an arbitrary agreement graph (see Theorem 9 of [3]). This algorithm constructs first a bipartite graph from the agreement graph, in which each vertex represents an operation and two vertices are adjacent if and only if the corresponding operations can be processed in parallel. The optimal schedule is obtained by searching a maximum matching in the constructed bipartite graph. We denote this algorithm by Algorithm 2.

We prove this theorem by cases:

1.
Case 01: if 
 and 
. We schedule the jobs of 
 at 
 and the jobs of 
 at 
 using Algorithm 1. Clearly, the jobs of 
 require 
 time units without idle times.

(a)
If 
.

i.
If 
 and 
. We schedule the jobs of 
 at 
 and the jobs of 
 at 
 using Algorithm 1.

ii.
If 
 or 
. We use Algorithm 2 on the operations of 
 and we schedule these operations starting from .

(b)
If 
.

i.
If 
 and 
. We schedule the jobs of 
 at 
 and the jobs of 
 at 
 using Algorithm 1.

ii.
If 
 or (exclusive) 
. If 
, schedule the block of 
 after the bloc of 
 and then schedule the operations of the job of 
 (if any) in parallel with the last two operations of 
 that are scheduled simultaneously. The jobs of 
 are scheduled by Algorithm 1 at 
 (at 
 if 
). Same instructions if 
 by reversing the roles of the two cliques.

iii.
If 
 and 
. If the jobs of 
 and 
 are adjacent, schedule them simultaneously. Otherwise, if 
, schedule the operations of 
 that are processed simultaneously after  in parallel with the job of 
 that is of the same clique (if only one of the two sets 
 and 
 has one job, we schedule after  two operations of the same clique as the set containing one job). If 
, schedule after  two operations processed simultaneously of 
 and two operations processed simultaneously of 
 and then process in parallel with them the jobs of 
 of the same clique.

2.
Case 02: if 
 or (exclusive) 
. We use Algorithm 2 on the operations of 
 and we schedule these operations starting from .

(a)
If 
. Do the same instructions as in 1a.

(b)
If 
. We consider 
, similar instructions can be taken when 
 by reversing the roles of the two cliques. We distinguish two cases:

i.
The jobs of 
 are scheduled without idle times. We use Algorithm 2 on the operations of 
, and since we have two cliques in 
, we can have at most two idle times on each machine in the schedule of 
.

A.
If the jobs of 
 are scheduled without idle times, then we schedule this bloc at 
.

B.
If we have one idle time on each machine in the jobs of 
, then 
 or (exclusive) 
.

•
If 
, then the job of 
 is in conflict with all the jobs of 
 if 
 or adjacent to at most one job of 
 if 
. We schedule the job of 
 simultaneously with the job of 
 after  and we have a complete schedule without idle times. However, if 
, we distinguish two cases: 
 and 
. If 
, then 
 and . We schedule the operations of 
 using Algorithm 2 and we process them at . If 
 and the job of 
 is adjacent to a job in 
, we schedule 
 in parallel with that job after . If 
 is in conflict with all the jobs of 
, we check if 
 is adjacent to one job in 
 (in case 
). If it is the case, we schedule them simultaneously, and process the remaining job of 
 in parallel with the other operations of 
 that are scheduled after . Otherwise, 
 is in conflict with all the jobs so we cannot avoid an idle time opposite to each operation of that job.

•
If 
, there exist at least two operations of 
 that are scheduled simultaneously in 
, we schedule these operations in parallel with the job of 
 after , and we have a complete schedule without idle times.

C.
If we have two idle times on each machine in the jobs of 
, then 
 and 
 and the jobs of 
 and 
 are in conflict.

•
If 
, we schedule two operations of 
, that are processed simultaneously in 
, in parallel with the operations of 
 after , and we cannot avoid the idle time opposite to each operation of 
.

•
If 
, we schedule the job of 
 (resp. the operations of 
 scheduled in parallel with the job of 
) in parallel with the job of 
 (resp. of 
) after . However, if 
, then 
. We check, in this case, if the job of 
 is adjacent to at least one job of 
. If this is the case, we schedule the job of 
 in parallel with its adjacent job and the job of 
 with two other operations of 
 after , otherwise we cannot avoid an idle time opposite to the operations of 
.

ii.
The jobs of 
 are scheduled with an idle time on each machine. This means that 
 and, the job of 
 is in conflict with all the jobs of 
 if 
 or adjacent to at most one job of 
 if 
.

A.
If 
. We use Algorithm 2 on the operations of 
 and one operation of 
. Observe that in this case we cannot avoid one idle time on each machine. If we have more than one idle time on each machine, then 
. In this latter case, if 
, then 
 and 
 are in conflict, and the obtained schedule is optimal. Now, if 
 or 
, we schedule the job of 
 in parallel with two operations of 
 at  and we have an optimal schedule with one idle time on each machine.

B.
If 
.

•
If 
 and 
. Schedule the jobs of 
 and the jobs of 
 using Algorithm 1 after .

•
If 
 and 
. If 
, then schedule the job of 
 in parallel with two operations of 
 that are scheduled simultaneously after , and schedule 
 using Algorithm 1. Now, if 
, we use Algorithm 2 on the operations of 
. If we have an idle time in the schedule of 
, then we check if 
 is adjacent to one job of 
. If this is the case, schedule the two jobs in parallel before  and use Algorithm 2 on the operations of 
 and the remaining job of 
. If the schedule has one idle time, then we cannot avoid one idle time on each machine in the optimal schedule.

•
If 
 and 
. We schedule the job of 
 in parallel with those of 
.

•
If 
. We check if 
 is adjacent to one job of 
. If this is the case, schedule the two jobs in parallel and schedule the remaining job of 
 in parallel with the jobs of 
 after . If this is not the case, we use Algorithm 2 on the operations of 
. If we have more than one idle time on each machine in the schedule of 
, then 
 and the job of 
 is in conflict with 
. In this case, we schedule the job of 
 in parallel with the jobs of 
 after , and we cannot avoid an idle time opposite to the operations of 
 since it is in conflict with all the jobs. Now, If we have one idle time on each machine in the schedule of 
, then 
 is in conflict with all the jobs of 
 if 
 or adjacent to at most one job of 
 if 
. In the first case, we cannot avoid an idle time opposite to each operation of 
. In the second case, if 
 and 
 is adjacent to one job of 
, then schedule the job of 
 in parallel with its adjacent job and the remaining job of 
 in parallel with two operations of 
 that are processed simultaneously after . Otherwise, we cannot avoid an idle time opposite to each operation of 
.

3.
Case 03: if 
 and 
. We use Algorithm 2 on the operations of 
 and we schedule these operations starting from .

(a)
If 
. Do the same instructions as in 1a.

(b)
If 
 and the jobs of 
 and 
 are adjacent, then 
 and .

i.
If 
 and 
. We schedule the jobs of 
 at 
 and the jobs of 
 at 
 using Algorithm 1.

ii.
If 
 and 
.

A.
If the jobs of 
 and 
 are adjacent, schedule them simultaneously at  and 
.

B.
If the jobs of 
 and 
 are not adjacent, schedule an operation of 
 (resp. of 
) in parallel with the operation of 
 (resp. of 
) scheduled after  and we have a schedule with 
.

C.
If 
 or (exclusive) 
. If the job of 
 is adjacent to the two jobs of 
, schedule that job in parallel with the two operations of 
 that are processed after , otherwise schedule the job of 
 opposite to idle times.

iii.
If 
 or (exclusive) 
. We use Algorithm 2 on the operations of 
 and the two operations of 
 scheduled after 

(c)
If 
 and the jobs of 
 and 
 are not adjacent then 
. In this case, .

i.
If . We use Algorithm 2 on the operations of 
 and one operation of one job of 
 (since 
 and 
 have the same role). We do the same process with one operation of the other job of 
 and we choose the schedule with the minimum 
.

ii.
If . We use Algorithm 2 on the operations of 
 and the two operations of one job of 
. We do the same process with the operations of the other job of 
, then with one operation of each job of 
 and we choose the schedule with the minimum 
 from the three schedules.

iii.
If . We use Algorithm 2 on the operations of 
 and the two operations of the job of 
 and one operation of the job of 
 (since 
 and 
 have the same role). We do the same process with the two operations of the job of 
 and one operation of 
 and we chose the schedule with the minimum 
.

(d)
If 
 and (
 or (exclusive) 
). In this case . We use Algorithm 2 on the operations of 
 and one operation of the job of 
 (since 
 and 
 have the same role) and we schedule these operations starting from .

In each case, one can check that the obtained schedule has a minimum number of idle times on each machine. Therefore, the obtained schedule is optimal. □

2.2. Case of trees
In this section, we study the two-machine OSA problem on trees; we show that the problem is NP-hard for arbitrary trees. Then, we present an algorithm to solve in linear time the case in which the agreement graph is a caterpillar and we use this algorithm to solve the problem when restricted to cycles. Recall that the preemptive version of the two-machine OSA problem can be solved in polynomial time for arbitrary agreement graphs including trees [3].

Theorem 3

 is NP-hard in the ordinary sense for G being a tree.

Proof

The candidate used in the reduction process is the 2-Partition problem, which is known to be NP-complete in the ordinary sense [9]. It is defined as follows: given a set 
 of n positive integers with 
 for some integer B, does there exist a partition of N into two subsets 
 and 
, such that 
?.

Given an arbitrary instance of 2-Partition, we construct an instance I of our problem; Table 1 summarizes the processing times of the  jobs, where 
 and 
, and Fig. 3 presents the agreement graph which is a tree (this proof is inspired from Theorem 1 of [10]).


Table 1. Theorem 3: Processing times.

M1	M2
Jj, j = 1,…,n	2aj	2aj
, j = 1,…,n	0	aj
Jn+1	2B + 2	4B
Jn+2	2	1
Jn+3	1	1
Jn+4	2	1
Jn+5	1	1
Fig. 3
Download : Download high-res image (35KB)
Download : Download full-size image
Fig. 3. Theorem 3: Agreement graph G = (V,E).

We show that 2-Partition has a solution if and only if there exists a feasible schedule σ for I with 
.

Suppose that 2-Partition has a solution 
 and 
. Let 
 and 
 (resp. 
 and 
) be the sets of the jobs of  (resp. of 
) corresponding to 
 and 
 respectively. A feasible schedule σ for I with 
 is shown in Fig. 4. Note that since the jobs of 
 are in one-to-one correspondence with those of 
 and since the processing time of an operation of 
 on 
 is half the processing time of its corresponding operation of 
 on 
, we have an idle time opposite to each operation of 
. Moreover, the operations of 
 on 
 are scheduled opposite to an idle time of B time units.

Fig. 4
Download : Download high-res image (52KB)
Download : Download full-size image
Fig. 4. 2-Partition reduces to O2|AgreeG = (V,E)|Cmax with G is a tree.

Conversely, suppose that there exists a feasible schedule σ for I with 
. Since 
 (resp. 
) agrees only with 
 (resp. 
), we schedule the two jobs simultaneously as much as possible. On the other hand, 
 can be processed in parallel with the jobs of  and with 
 and 
. Let 
 be the set of jobs of  scheduled on 
 simultaneously with the operation of 
 on 
. Depending on the processing time of 
 (denoted by 
) we distinguish three case:

•
Case 
: Fig. 5 shows that by decreasing the processing time of the operations of 
 by 
 (
), the time needed to schedule the remaining operations of  on 
 with those of 
 on 
 increases by at least 
 
. This is due to the fact that the processing time of an operation of 
 on 
 is half the processing time of its corresponding operation of  on 
. As a consequence and even by processing the remaining operations (of , 
, 
, 
, 
 and 
) without any idle time, the minimum makespan that we can obtain is 
 
.

Fig. 5
Download : Download high-res image (63KB)
Download : Download full-size image
Fig. 5. Theorem 3: Case of 
.

•
Case 
: Fig. 6 shows that by increasing the processing time of the operations of 
 by 
 (
), the time needed to schedule these operations with 
 and 
 on 
 increases by 
. On the other hand, the time needed to process the remaining operations of  on 
 with those of 
 on 
 decreases by at most 
 
. Therefore, by scheduling the remaining operations without any idle time, the minimum makespan that we can obtain is 
 
.

Fig. 6
Download : Download high-res image (61KB)
Download : Download full-size image
Fig. 6. Theorem 3: Case of 
.

•
Case 
: Fig. 4 shows that by processing 2B time units of 
 in parallel with 
, we obtain a schedule with 
.

Therefore, the only possible case is 
. Let 
 be a subset of N corresponding to the jobs of 
. We have 
 and the Theorem follows. □
In what follows, we show that, when we restrict our attention to caterpillars, the two-machine OSA problem can be solved in linear time for arbitrary processing times.
Theorem 4

 can be solved in -time for G being a caterpillar.

Proof

Let (P) denote the two-machine OSA problem with G being a caterpillar and let I be an instance of (P) and  is the agreement graph associated. We construct an auxiliary graph 
 from G as follows (see Fig. 7):

•
, where 
 represents the operations of the jobs of V to be processed on machine 
.

•
For each two jobs 
 and 
, two edges {
, 
} and {
, 
} exist if and only if 
 and 
 are adjacent in G.

By construction of 
, one can verify that this graph is a connection of two disjoint caterpillars and that it is an agreement graph over the operations of I. Note that if some jobs in G have only one operation, we obtain more than two disjoint caterpillars in 
 and an optimal schedule is obtained by the concatenation of the optimal schedules of the disjoint caterpillars.
Fig. 7
Download : Download high-res image (50KB)
Download : Download full-size image
Fig. 7. Theorem 4: Transformation from G = (V,E) to G′ = (V′,E′). (a) graph G = (V,E). (b) graph G′ = (V′,E′).

Let 
 be an instance of (P) and 
 is the agreement graph associated (each job has a unique operation). It is clear that an optimal schedule for 
 is also optimal for I. We consider another instance 
 derived from 
 by relaxing the constraints on the operations, such that each operation can be processed on any of the two machines. Therefore, 
 can be viewed as an instance of the problem of scheduling on two-identical machines with an agreement graph. This latter problem can be solved in -time when the agreement graph is a caterpillar by an algorithm proposed in [10].

When applying the algorithm of [10], we first determine a maximum weighted independent set 
⁎
 in 
, then we remove the edges connecting each pair of jobs in 
⁎
. We obtain a set of connected caterpillars, let 
 denote one of these caterpillars and 
⁎
⁎
. The algorithm schedules the jobs of 
⁎
 in a given order on the first machine and the jobs of 
⁎
 on the second machine. We shall need the following lemma.

Lemma 1

The operations of 
⁎
 are of the same machine.

Proof

Let 
 be a vertex in the central path of 
 and 
 be a leaf of 
. We arrange the vertices of 
 as follows: we take the sequence of the vertices of the central path from left to right and after each vertex we add the list of its leaves, as shown in the following sequence, where 
 is the number of leaves of 
:(1)
 We proceed by contradiction. Suppose that there exist two operations a and b of 
⁎
 of different machines. We suppose without loose of generality (WLG) that a and b are two consecutive operations of 
⁎
 following the order of sequence (1). Recall that 
⁎
 is a maximum weighted independent set of 
. We distinguish two cases:

•
Case 1: a is a vertex of the central path. We suppose WLG that a is 
 in sequence (1). Then, b cannot be 
 nor a leaf of 
 because they are adjacent to 
. b cannot also be 
 nor a leaf of 
 because they are of the same machine as 
. Therefore, b can be either 
 or a leaf of 
. In the two cases, we have 
 and 
 that are connected and they are in 
⁎
, which is a contradiction.

•
Case 2: a is a leaf. We suppose WLG that a is 
 in sequence (1). Then, b cannot be 
 because it is adjacent to 
. b cannot also be 
 nor a leaf of 
 because they are of the same machine. The possible cases of b are either 
 or a leaf of 
. In the two cases, we have 
 and 
 that are connected and they are in 
⁎
, which is a contradiction.

It follows that the operations of 
⁎
 are of the same machine and the lemma follows. □
In a similar way, we can show that the operations of 
⁎
 are of the same machine.
Now, if we schedule the operations of 
 on their respective machines following the algorithm of [10], we obtain an optimal schedule σ for 
, which is feasible for I, thus σ is also optimal for I. The graph 
 is constructed in -time, the algorithm runs in -time and the theorem follows. □

In the following, we show that the algorithm applied on caterpillars can be used to solve the two-machine OSA problem on cycles in polynomial time.
Theorem 5

 can be solved in 
-time for G being a cycle.

Proof

Given an instance I of the two-machine OSA problem with  is a cycle, we construct an auxiliary graph 
 from G similarly to Theorem 4 (see Fig. 8). Since the edges in 
 joint pairs of operations of different machines, we distinguish two cases:

•
Case 1: n is odd (see Fig. 8.(a)). When all the jobs have an operation on each machine, we obtain a cycle of length 2n. However, when some jobs have only one operation, we obtain a collection of disjoint paths.

•
Case 2: n is even (see Fig. 8.(b)). When all the jobs have an operation on each machine, we obtain two disjoint cycles each of length n. However, when some jobs have only one operation, we obtain a collection of disjoint paths and at most one cycle.

Fig. 8
Download : Download high-res image (73KB)
Download : Download full-size image
Fig. 8. Theorem 5: Transformation from G = (V,E) to G′ = (V′,E′). (a) case of n odd. (b) case of n even.

Clearly, an optimal schedule for I is obtained by the concatenation of the optimal schedules of the disjoint paths and cycles of 
. An optimal schedule for paths can be obtained by applying the algorithm of Theorem 4 since these latter are sub-classes of caterpillars. Now, we consider the cycles of 
. By using the same idea of Claim 6 of [10], observe that in any feasible schedule, it is not possible to process each operation in parallel with its two adjacent operations, otherwise the operations will be scheduled in a circular way. Therefore, there exist at least two adjacent operations in the cycle that are not processed in parallel in the optimal schedule. Then, to obtain an optimal schedule, we remove at each iteration an edge from the cycle, we apply the algorithm of Theorem 4 on the resulting path and then we choose the schedule with the minimum makespan. We call the algorithm of Theorem 4 at most 2n times and the construction of 
 is done in , then the algorithm runs in 
. □

3. Flow shop
We consider in this section the two-machine FSA problem when restricted to trees. For the case of unit-time operations, this problem can be solved in polynomial time [5]. The following results show that the problem becomes NP-hard for arbitrary processing times and this results holds even if the preemption is allowed. The next two theorems are inspired from Theorems 2 and 3 of [5].

Theorem 6

 is NP-hard in the ordinary sense for G being a tree.

Proof

The candidate used in the reduction process is the 2-Partition problem (see Theorem 3). Given an arbitrary instance of 2-Partition, we build an instance I of 
 in the following way. The set of jobs is composed of  jobs 
 such that:

•
, .

•

The job 
 is adjacent to all the other jobs 
, while these latter are mutually in conflict. The agreement graph is given in Fig. 9, which is a tree.
Fig. 9
Download : Download high-res image (19KB)
Download : Download full-size image
Fig. 9. Agreement graph G = (V,E) of I.

We claim that 2-Partition has a solution if and only if there exists a feasible schedule σ for I with 
.

Suppose that 2-Partition has a solution 
 and 
. A feasible schedule σ for I is shown in Fig. 10. Note that the operations corresponding to N1 (resp. 
) on 
 (resp. 
) are scheduled opposite to an idle time. The resulting schedule is feasible with respect to the agreement constraints between the jobs and has total length 4B.

Fig. 10
Download : Download high-res image (16KB)
Download : Download full-size image
Fig. 10. 2-Partition reduces to F2|AgreeG = (V,E),prpt|Cmax with G is a tree.

Conversely, suppose that there is a feasible schedule σ for I with 
. Since the processing times of the jobs 
 sum up to 2B on each machine and since they are mutually in conflict, it follows that exactly one of these jobs is executed on one of the machines at each time unit. Let 
 (resp. 
) be the set of jobs processed on 
 (resp. 
) in parallel with the operation of 
. We denote by 
 (resp. 
) the total processing time of the operations of 
 (resp. of 
). Suppose by contradiction that 
 (resp. 
), this means that a part of the operation of 
 on 
 (resp. on 
) is processed opposite to an idle time. This contradicts the fact that we have, at each time unit, exactly one job of 
 processed on one of the machines. It follows that, 
. On the other hand, each job should be processed first on 
 and next on 
. Therefore, the operation of 
 on 
 should be completed before starting its operation on 
, and the jobs of 
 on 
 cannot begin processing before completing their operations on 
. As a consequence, the only possible schedule is the one given in Fig. 10. The sets 
 and 
 are disjoint and 
 which constitutes a solution to 2-Partition. □

The following result shows that even by allowing preemption (denoted ) the problem remains NP-hard.
Theorem 7

 is NP-hard in the ordinary sense for G being a tree.

Proof

We use in the reduction process the 2-Partition problem and we consider the same instance I of Theorem 6. We claim that 2-Partition has a solution if and only if our scheduling problem has a solution σ with 
.

Assume that 2-Partition has a solution 
 and 
. Since all non preemptive schedules are preemptive, the schedule σ of I obtained in Theorem 6 is also feasible for the preemptive version and we have 
.

Now, suppose that there exists a feasible schedule σ for I with 
. Given the schedule of Fig. 10 and since the preemption is allowed, the only possible case is to have preemptions in the operations processed in the time interval  in one hand side and in the operations of the interval  on the other hand side. The other cases of preemptions between the operations of the time intervals  and  are discarded due to the precedence constraints between the operations of each job and due to the fact that each job has the same processing time on each machine. Let 
 (resp. 
) be the set of jobs processed in parallel with the operation of 
 on 
 (resp. 
). We have the sets 
 and 
 are disjoint and 
 and the solution of 2-Partition follows. □

4. Conclusion
In this work, we showed that the two-machine OSA problem is NP-hard in the strong sense for 
 (r arbitrary), 
 and general agreement graphs, whereas, when 
 the problem is polynomially solvable for complements of bipartite graphs. After that, we proved that the two-machine OSA and FSA problems are NP-hard when restricted to trees. This result holds for the two-machine FSA problem even if the preemption is allowed. Then, we presented a linear-time algorithm to solve the two-machine OSA problem in which the agreement graph is a caterpillar and we used this algorithm to solve the case of cycles.

For future perspectives, more research is needed concerning the complexity of the FSA and OSA problems when restricted to other graph classes, e.g. interval, permutation and comparability graphs. It would be interesting also to design other polynomial cases and to develop efficient algorithms to solve the NP-hard cases.