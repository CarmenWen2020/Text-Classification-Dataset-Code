Abstract
In the constrained synchronization problem we want to know if a given input automaton admits a synchronizing word contained in a (fixed) regular constraint language. Here we study the computational complexity of the constrained synchronization problem for the class of regular commutative constraint languages and the computational complexity of the problem restricted to commutative input semi-automata. We give a full classification of the computational complexity of the constrained synchronization problem for commutative regular constraints. Depending on the constraint language, our problem becomes PSPACE-complete, NP-complete or polynomial time solvable. In addition, we derive a polynomial time decision procedure for the complexity of the constrained synchronization problem, given a constraint automaton accepting a commutative language as input. Furthermore, for commutative input semi-automata, the problem is decidable in polynomial time, regardless of the regular constraint language.

Keywords
Constrained synchronization
Computational complexity
Automata theory
Commutative language

1. Introduction
A deterministic and complete semi-automaton is synchronizing if it admits a reset word, i.e., a word which leads to a definite state, regardless of the starting state. This notion has a wide range of applications, from software testing, circuit synthesis, communication engineering and the like, see [2], [3]. The famous Černý conjecture [4] states that a minimal synchronizing word of an n-state complete and deterministic automaton has length at most 
. We refer to the mentioned survey articles [2], [3] for details.

Due to its importance, the notion of synchronization has undergone a range of generalizations and variations for other automata models. It was noted in [5] that in some generalizations only certain paths, or input words, are allowed (namely those for which the input automaton is defined). In [6] the notion of constrained synchronization was introduced in connection with a reduction procedure for synchronizing automata. The paper [7] introduced the computational problem of constrained synchronization. In this problem, we search for a synchronizing word coming from a specific subset of allowed input sequences. Note that in this problem, the input automata are complete and deterministic, whereas the constraint is, as originally introduced, given by a partial deterministic automaton. For further motivation and applications we refer to the aforementioned paper [7]. In this paper, a complete analysis of the complexity landscape when the constraint language is given by a small partial automaton was done.

It is natural to extend this result to other language classes, or even to give a complete classification of all the complexity classes that can arise. Our work is in this vein, we look at the complexity landscape for commutative regular constraint languages, where a language is commutative if we can permute the letters of every word in the language and the resulting word is still in the language. Furthermore, we look at the complexity if we restrict our input semi-automata to be commutative, a natural variation of the original problem (a semi-automaton is commutative if permutations of words give the same target state if read from the same starting state).

Let us mention that restricting the solution space by a regular language has also been applied in other areas, for example to topological sorting [8], solving word equations [9], [10], constraint programming [11], or shortest path problems [12]. The road coloring problem asks for a labeling of a given graph such that a synchronizing automaton results. A closely related problem to our problem of constrained synchronization is to restrict the possible labeling(s), and this problem was investigated in [13].

Overview and contribution. In the present work, we investigate two problems, (1) the constrained synchronization problem for commutative regular constraint languages, and (2) the constrained problem for arbitrary regular constraint languages but only commutative input automata. In the first case, we establish a trichotomy result, showing that, depending on the constraint language, we only get an -complete, a -complete or a polynomial time solvable constrained problem. Such effects, i.e., that only certain complexities occur for families of problems, also occur in other domains, noteworthy the famous Schaefer dichotomy theorem [14] about the complexities of the Boolean satisfiability problem, where only  or -completeness arise. In the second case, we show that deciding synchronizability for commutative automata is always doable in polynomial time, for every regular constraint language. Furthermore, our solution to the first problem yields a criterion so that we can decide in polynomial time, for a given constraint language, what complexity the corresponding constrained problem has. The proof is based on a so called cropped vector representation, introduced in Definition 16. This vector representation captures the information if a given letter, together with other letters, is allowed to appear infinitely often, or a finite number of times (where only the cases if it is not allowed to appear at all, only once, or more than once, are relevant). The formulation of the trichotomy result in Theorem 26 will use this representation.

In Section 2 we introduce and recap notions from computational complexity, automata theory and the theory of formal languages. In Subsection 2.2 we take a closer look at the computational complexity and related issues for the problem to decide if a given automaton is synchronizing, checking if a given word synchronizes a given automaton and computing a synchronizing word. For the former decision problem, we show that it is NLOGSPACE-complete for an at least binary alphabet, and in DLOGPSPACE otherwise, and the latter decision problem is always in DLOGPSPACE.

In Section 3 we investigate the problem for commutative and regular constraint languages. In Subsection 3.1 we state results that allow us to simplify a given constraint language, and based on these simplifications, introduce the cropped vector representation in Definition 16. Together with Proposition 18, the maximal vectors of a cropped vector representation contain all information of the constraint language relevant to the computational complexity of the problem. We also discuss, in Subsection 3.2, questions of uniqueness of these representations. Then, in Subsection 3.3 we discuss the cases when the problem is in P. In Subsection 3.4 when it is NP-hard (and in NP when combined with Lemma 11) and in Subsection 3.5 when it is PSPACE-hard (and in PSPACE with Theorem 8. Then in Subsection 3.6 we combine the previous results and show that they cover all possibilities, as stated in Theorem 26. The section closes with Subsection 3.6, establishing a polynomial time decision procedure for the complexity of the constrained problem for a given automaton describing a constraint language.

Section 4 proceeds to consider arbitrary regular constraint languages but restricts the class of input automata to commutative automata. The main result of this section, Theorem 45, establishes that in this case, the problem is always in P. We arrive at this result by investigating in detail, in Subsection 4.1, the structure of the set of synchronizing words of commutative automata.

2. Prerequisites
2.1. General notions
By Σ we always denote a finite alphabet. A word is an element of the free monoid 
⁎
, i.e., the set of all finite sequences with concatenation as operation. For 
⁎
, we denote their concatenation by , but often we omit the concatenation symbol and simply write uv. The subsets of 
⁎
 are also called languages. By 
 we denote the set of all words of non-zero length. By 
 we denote the natural numbers with zero. Setting  for all 
, we use the symbol ∞ in connection with 
. Hence we regard 
 as an ordered set with top element ∞.

For two words 
⁎
, u is called a prefix of v, if there exists a word 
⁎
 such that , it is called a suffix of v, if there exists a word 
⁎
 such that , and a factor of v if there exists 
⁎
 such that . The word u is a subsequence of v, if there exists , factors 
, , of u with 
 and words 
⁎
 such that 
.

A language 
⁎
 is called commutative, if with , every word arising out of w by permuting its letters is also in L. Essentially, a commutative language is defined by conditions that say how often a letter is allowed to appear in its words, but not by the actual position of that letter. We use the shuffle operation in connection with unary languages frequently to write commutative languages.

Definition 1

The shuffle operation, denoted by ⧢, is defined as⧢ 
⁎
 
  for 
⁎
 and 
⧢
⧢ for 
⁎
.

The shuffle operation is commutative, distributive over union [15] and associative. Note that a word 
⁎
 is a subsequence of another word 
⁎
 if and only if ⧢
⁎
. Languages 
⁎
 such that ⧢
⁎
 are also called order ideals for the subsequence order.

Throughout the paper, we consider deterministic finite automata (DFAs). Recall that a DFA  is a tuple 
, where the alphabet Σ is a finite set of input symbols, Q is the finite state set, with initial state 
, and final state set . The transition function  extends to words from 
⁎
 in the usual way. The function δ can be further extended to sets of states in the following way. For every set  with  and 
⁎
, we set . We call  complete if δ is defined for every ; if δ is undefined for some , the automaton  is called partial (PDFA for short). If , we call  a unary automaton. The set 
⁎
 denotes the language accepted by .

A semi-automaton is a finite automaton without a specified initial state and with no specified set of final states. The properties of being deterministic, partial, and complete for semi-automata are defined as for DFAs. When the context is clear, we call both deterministic finite automata and semi-automata simply automata. For some semi-automaton (or DFA) with state set Q and transition function , a state q is called a sink state, if for all  we have . Also, when we mention semi-automata without any additional modifiers, we mean deterministic and complete semi-automata by default.

If we want to add an explicit initial state r and an explicit set of final states S to a deterministic semi-automaton  or change them in a DFA 
, we use the notation 
.

We assume the reader to have some basic knowledge in computational complexity theory and formal language theory, as contained, e.g., in [16]. For instance, we make use of regular expressions to describe languages. For a word 
⁎
 we denote by  its length, and for a symbol  we write 
 to denote the number of occurrences of x in the word. We denote the empty word, i.e., the word of length zero, by ε. We also make use of complexity classes like , , or . With 
 we denote a logspace many-one reduction. If for two problems 
 it holds that 
 and 
, then we write 
.

2.2. Synchronizing automata and computational complexity
An automaton  is called synchronizing if there exists a word 
⁎
 with . In this case, we call w a synchronizing word for . We call a state  with  for some 
⁎
 a synchronizing state.

Note that if a synchronizing automaton has a sink state, then this sink state must be the unique synchronizing state.

Theorem 2

[2]
For any deterministic complete semi-automaton, we can decide if it is synchronizing in polynomial time 
. Additionally, if we want to compute a synchronizing word w, then we can do this in time 
 and the length of w is in 
.

A language 
⁎
 is called a right (left-) ideal if 
⁎
 (
⁎
), or a two-sided ideal, if L is both, a right and a left ideal. The following obvious remark, stating that the set of synchronizing words is a two-sided ideal, is used frequently without further mentioning.

Lemma 3

Let  be a deterministic and complete semi-automaton and 
⁎
 be a synchronizing word for . Then for every 
⁎
, the word uwv is also synchronizing for .

Next, we look at two decision problem in more detail: the problem to decide if a given word synchronizes a given automaton, and the problem to decide if a given automaton is synchronizing.

Theorem 4

Given 
⁎
 and a deterministic and complete automaton , it is in DLOGPSPACE to decide if w is a synchronizing word for .

Proof

We assume the states of  are ordered 
. We build a deterministic Turing machine that first simulates  starting from 
 when reading w. This can be achieved, using logarithmic space, by only maintaining two counters on the working tape: one points to the current position in the word, the other stores the index of the current state. After w is completely processed, the resulting state is stored permanently. Then, the machine restarts this process again, but starting with 
 and using a different counter for the current state. After this second simulation of  starting in 
 has finished, the machine compares the resulting state with the stored state from the previous simulation run. If both are different, then w is not a synchronizing word and the machine aborts with giving this result. Otherwise, the machine continuous in the same way but simulating  when started from 
 and so on until  is stimulated when started from the last state 
. If the machine has not aborted yet, the resulting states after each simulation run are all equal and w is a synchronizing word. The whole procedure can be implemented with four counters storing a binary number: a counter pointing to the current reading position in w, a counter storing the state of the first simulation run of , a counter to store the state of all the other simulation runs started at different states, and a counter to store the state from which  will be started in each run. □

In [17, Lemma 14] it was shown that deciding if a given deterministic and complete automaton is synchronizing is NLOGSPACE-complete. In their reduction, the authors used an alphabet of size three. Here, we improve on that result by showing that we get NLOGSPACE-hardness even for a (fixed) binary alphabet, and L-completeness for a unary alphabet.

Theorem 5

Let Σ be a fixed alphabet. If  then it is NLOGSPACE-complete to decide if a given deterministic and complete automaton over Σ is synchronizing (for logspace-reductions), and for  it is in DLOGPSPACE.

Proof

That the problem is contained in NLOGSPACE for every alphabet was established in [17, Lemma 14]. To restate the argument briefly: we can decide synchronizability by cycling through all pairs of states and non-deterministically guess a word that maps both to a single state, which is sufficient to decide synchronizability.

Next, we give a reduction that shows NLOGSPACE-hardness and uses only a binary alphabet. We use the directed graph reachability problem, shown to be complete for NLOGSPACE in [18], where the input is a directed graph  with vertex set 
 and two distinct vertices 
 and 
. We want to know if there exists a path from s to t. Without loss of generality, we can assume that t has no outgoing edges, s has no incoming edges and precisely one outgoing edge to a vertex 
 and all other vertices have precisely two outgoing edges. For  we fix a naming  of the two distinct vertices with .

Then, we construct the automaton  with  and transition function given by 
  Next, we argue that the so constructed automaton has a synchronizing word if and only if there exists a path from s to t in the graph. The fact that the letter b maps s to itself will be used multiple times in the following argument. Now, if  has a synchronizing word 
⁎
, then t, as it is a sink state, must be the synchronizing state. Hence . We can suppose w starts with a, as , because if not, there must exist a largest suffix starting with a, and we can take that for the following argument. Write , with u being the shortest prefix such that . As for every  we have 
 iff 
⁎
, we can write 
 with 
 with some prefix 
⁎
. Then, the vertices
 trace out a path in G from s to t.

Conversely, suppose there exists a path from s to t in G. Then, we can define a word 
⁎
 such that . Note that we have to go to 
, hence the word starts with a. As  (here, again we use  and that all other states except t are mapped to s by bb), the word  synchronizes .

Lastly, if , it is easy to see that  is synchronizing if and only if the directed graph with outdegree one, vertex set Q and edges  has only a single trivial cycle, i.e., there is precisely one vertex  such  is an edge and for every other 
 there exists a path from 
 to q. Further, this last condition is equivalent with the fact that 
 is a synchronizing word for  (see also Lemma 22 for a more general statement based on the same observations). Hence, using Theorem 4 with input 
 we find that deciding if  is synchronizing can be done in deterministic log-space. □

Note that the method of proof (and also the one from [17]) shows that if the alphabet is not fixed, but part of the input, the problem to check if a given complete and deterministic input automaton is synchronizing is NLOGSPACE-complete.

2.3. The constrained synchronization problem
In [7] the constrained synchronization problem was defined for a fixed partial deterministic automaton 
.

Decision Problem 1

[7]
-Constr-Sync

Input:
Deterministic complete semi-automaton .

Question:
Is there a synchronizing word 
⁎
 for  with ?

The automaton  is called the constraint automaton. If an automaton  is a yes-instance of -Constr-Sync we call  synchronizing with respect to . Most of the time in Section 3 and Section 4, we do not specify  and rather talk about L-Constr-Sync for a regular language 
⁎
.

Note that in the constrained problem, the alphabet is fixed by the constraint language.

Here, we are concerned with L-Constr-Sync for the case that the constraint language L is a commutative regular language.

2.4. Unary languages
Let  be a unary alphabet. Suppose 
⁎
 is regular with an accepting complete deterministic automaton 
. Then by considering the sequence of states 
 we find numbers  with  minimal such that 
. We call these numbers the index i and the period p of the automaton . If 
, then . In our discussion unary languages that are accepted by automata with a single final state appear.

Lemma 6

[19]
Let 
⁎
 be a unary language that is accepted by an automaton with a single final state, index i and period p. Then either  with  (and if the automaton is minimal we would have ), or L is infinite with 
⁎
 and . Hence two words  with  are both in L or not if and only if .

2.5. Known results on constrained synchronization and commutative languages
Here we collect results from [7], [19], and some consequences that we use later. First a mild extension of a lemma from [7], where it was formulated only for the class , but it also holds for  and .

Lemma 7

Let  and 
 be PDFAs. Let  denote any of the complexity classes ,  or . If  is a finite union of 
 such that for each  the problem 
-Constr-Sync belongs to , then

Image 1
.
Proof

Notation as in the statement. Set 
. The proof for  works by checking in polynomial time all the languages 
 in order, which is a polynomial time operation.1 The same argument gives the claim for . This does not use nondeterminism. Alternatively, we can use nondeterminism by guessing  first, and then checking for synchronizability in 
. For  the same procedure of checking the languages 
 in order works, as running a machine for each 
, one after another, only needs a constant amount of extra instructions. Further, as each machine only needs polynomial space, the total procedure only uses polynomial space. Alternatively we can use  by Savitch's Theorem [20] and guess the language 
. □

The next result from [7] states that the computational complexity of -Constr-Sync is in .

Theorem 8

[7]
For each constraint automaton 
 the problem -Constr-Sync is in .

If , then

Image 2
is obviously in . Simply feed this single word into the input semi-automaton for every state and check if a unique state results. Hence by Lemma 7 the next is implied.
Lemma 9

Let 
 be a constraint automaton such that  is finite, then

Image 3
.
The following result from [7] gives a sufficient condition to deduce that -Constr-Sync belongs to .

Theorem 10

[7]
Let 
 be a partial deterministic finite automaton. Then,

Image 4
if there is a  such that for all states , if 
 is infinite, then 
⁎
.
With this we can deduce another sufficient condition for

Image 5
in case L is a commutative regular language.
Lemma 11

Let Σ be the alphabet and suppose . If
⁎
⧢
⧢⧢
 for finite languages 
, then

Image 6
.
Proof

We can assume , as for unary languages

Image 7
, as a unary input automaton is synchronizing if and only if it has a sink state. Then, checking if there exists a word in L that leads the unary input automaton into the sink state can be done in polynomial time. As finite languages are regular, and the shuffle operation preserves regular languages, the language L is regular. Let 
 be some partial automaton with . First note that, if , no final state can be a sink state, as then other letters than a appear infinitely often. Further, we can assume for each state  we have some 
⁎
 with . For otherwise we can drop this state and all transitions to it and get another partial automaton that still accepts the same language. Also we can assume that each state is reachable, i.e., for  we have  with 
. Now, suppose that 
⁎
 for  is infinite. Choose 
⁎
 with 
 and . Then if 
 we have 
⁎
. This gives 
⁎
, as otherwise, if 
 for some , then for each  we would have 
. But by Definition of L every letter distinct from a can only appear a bounded number of times. □
The next result from [7] is useful in making several simplifying assumptions about the constraint language later in Section 3.1.

Theorem 12

[7]
Let 
⁎
. If 
⁎
⁎
, then

Image 8
-Constr-Sync.
The following Theorem 13 is taken from [19] and will be crucial in deriving our vector representation form for the constraint language later in Section 3.1.

Theorem 13

Let 
 be the alphabet. A commutative language 
⁎
 is regular if and only if it can be written in the form
 
⧢⧢
 with non-empty unary regular languages 
⁎
 for  and  such that for each 
 there exists a unary automaton with a single final state accepting it.

With respect to the constrained synchronization problem (Problem 1), for commutative constraint languages , we refer more to the form given by Theorem 13 than to the specific automaton 
 underlying it. In Section 3.7 we give some details how to compute such a form for a given automaton accepting a commutative language.

2.6. Other computational problems used
For establishing our hardness results, we need the following computational problem taken from [21], which is a PSPACE-complete problem for at least binary alphabets, also see [22], [3].

Decision Problem 2

Sync-Into-Subset

Input:
Det. complete semi-automaton  and .

Question:
Is there a word 
⁎
 with ?

Remark 14

The terminology is not homogeneous in the literature. For instance, Sync-Into-Subset has a different name in [21] and in [22].

We also need the next problem from [23], which is -complete in general, but -complete for unary automata, see [24].

Decision Problem 3

Intersection-Non-Emptiness

Input:
Deterministic complete automata 
, 
, …, 
.

Question:
Is there a word accepted by them all?

3. Synchronization with regular commutative constraints
Our main result, Theorem 26, gives a complete classification of the computational complexity of L-Constr-Sync, for different regular commutative constraint languages. In the following sections, we prove various simplifications, propositions, corollaries and lemmata that ultimately will all be used in proving Theorem 26. First, we will give criteria that allow certain simplification of the constraint language, and derive a mechanism to describe a given constraint language by a set of vectors, which gives all the essential information with regard to our problem. This notion is used repeatedly in all the following arguments. In Section 3.3 we give sufficient conditions for containment in . Then we single out those instances that give hardness results for the complexity classes  and  in Section 3.4 and Section 3.5. Finally, in Section 3.6, we combine all these results to prove Theorem 26. From Theorem 26, in the last Section 3.7, a decision procedure is derived to decide the complexity of -Constr-Sync, if we allow  to be part of our input.

3.1. Simplifications of the constraint language
Our first Proposition 15 follows from Theorem 12. Very roughly, it says that for the letters that are allowed infinitely often, the exact way in which they appear is not that important, but only that we can find arbitrary long sequences of them. We then use this result to derive a more compact description, in terms of vectors over 
, to capture the essential part of a commutative constraint language L with respect to the problem L-Constr-Sync.

Proposition 15 Infinite language simplification

Let 
 be the alphabet. Consider the constrained synchronization problem (Problem 1) with a commutative and regular constraint language 
⁎
. Suppose
 
⧢⧢
 with unary languages 
⁎
 for  and . If for some 
 and 
 the unary language 
 is infinite, then construct the new language
 
⧢⧢
 with
⁎
  We simply change the single language 
 for the language 
⁎
. Then a complete and deterministic input semi-automaton  has a synchronizing word in L if and only if it has one in 
 and

Image 9
-Constr-Sync.
Proof

Notation as in the statement of the proposition. Because 
 one direction is clear. Conversely suppose we have some synchronizing word 
 and assume 
⧢⧢
. If 
, then as 
 for  we have . So suppose 
. As 
 is infinite, we have some  such that 
. This gives
⧢⧢
 as 
 for 
. Hence  and by Theorem 12 the claim follows. □

Suppose L is a constraint language with
 
⧢⧢
 according to Theorem 13. By Proposition 15, for our purposes we can assume that if 
 is infinite, then it has the form 
⁎
. The unary languages 
 for  and  are accepted by some unary automaton with a single final state. By Lemma 6, if such a language is non-empty and finite it contains only a single word. Hence, the only relevant information is whether such a unary language part is infinite or what length has the single unary word it contains. This is captured by the next definition.

Definition 16

Cropped vector representation of L
Let 
 be the alphabet. Consider the constrained synchronization problem (Problem 1) with commutative regular constraint language L. Suppose(1)
 
⧢⧢
 with non-empty unary languages 
⁎
 for  and  that are acceptable by unary automata with a single final state. Then we say that a set of vectors 
 corresponds to L, according to Equation (1), if 
 with2
  for  and . By Theorem 13, every regular commutative constraint language has at least one vector representation.

Example 17

Let  with 
. For the language ⧢
⁎
⧢⧢
⁎
 we have . Please see Example 27 for other languages.

The language L is infinite precisely if for some vector at least one entry equals ∞. Another important observation, quite similar to Proposition 15, allows us to make further assumptions about the constraint language, or the vectors corresponding to it. It will be used in the proofs of Proposition 24 and Proposition 25.

For two vectors 
 and 
 from 
, we write  if and only if 
 for all . This gives a partial order on 
.

Proposition 18 Comparable vectors simplification

Let 
. Consider L-Constr-Sync. Suppose L has the form stated in Theorem 13,(2)
 
⧢⧢
 with unary languages 
⁎
 for  and . Let N be the vector set, corresponding to Equation (2) and according to Definition 16. Suppose  with  and 
 for 
, i.e., the vector x arises out of the part 
⧢⧢
 in the above union for L. Construct the new language
 
⧢⧢
 without the part 
⧢⧢
. Then a complete and deterministic input semi-automaton  has a synchronizing word in L if and only if it has one in 
 and

Image 10
.
Proof

Notation as in the statement of the proposition. Suppose we have some synchronizing word . If 
⧢⧢
 with 
, then also 
. So suppose 
⧢⧢
. Let 
 with 
 and corresponding part 
⧢⧢
. As  for each 
 with  we find 
 such that 
. Hence 
⧢⧢
 and by Theorem 12 the claim follows. □

Example 19

Let  with 
, 
, 
. If 
⁎
⧢
⁎
⧢⧢, then . After simplification by Proposition 18 and Proposition 15, we get a computationally equivalent constrained synchronization problem, with constraint language 
⁎
⧢⧢ and vector representation 
. In this case 
 contains precisely the maximal vector in N.

Hence, by taking the maximal vectors, which does not change the complexity, we can assume that the vectors associated with a regular commutative constraint language are pairwise incomparable.

3.2. The (non-)uniqueness of the cropped vector representation
The cropped vector representation of a regular commutative language depends on the form given in Theorem 13. This can be derived similarly as in Section 3.7 - see Corollary 33 - from an accepting automaton. So, using the minimal automaton, we can in fact define a unique such form. However, in our results, we do not need uniqueness, not even for the maximal vectors. This is so, because in the reductions, and the polynomial time procedures, only existence of a certain cropped vector representation gives us sufficient information.

Nevertheless, it is natural to ask if such a representation is unique and, in fact, it is easy to see that it is not. However, the maximal vectors derived from a cropped vector representation are uniquely determined.

Proposition 20

Let 
⁎
 be commutative and regular and suppose 
 are the maximal vectors derived from two cropped vector representations. Then 
.

Proof

It is easy to see that there exists a constant K such that if we have an ∞-entry in some vector in N or 
, then we find a word with at least that length in L.

Suppose 
. Then, by definition of the cropped vector representation, there exists 
 with 
 if 
 and 
 otherwise. However, this implies that there must be a vector 
 such that 
 if 
 and 
 otherwise. Hence, . Reasoning similarly with the roles of 
 and N reversed, we then find a vector 
 such that 
, which implies, by maximality, 
. So, we find 
. □

Now, we present a different approach to the cropped vector representation. Let 
 with 
 be an automaton accepting a commutative language. Then, define a map 
⁎
 by setting 
 with
  for . Then, 
 corresponds to a cropped vector representation for . Hence, we can take the maximal vectors from 
.

Such an approach would circumvent the usage of Theorem 13, but has the disadvantage of being less concrete. For example, the link of the cropped vector representation to, for example, Proposition 15 is less obvious with this approach.

3.3. The polynomial time solvable variants of the problem
If in the sets 
⧢⧢
 each 
 is either infinite or 
, then

Image 7
.
Proposition 21

Let 
 be the alphabet. Consider the constrained synchronization problem (Problem 1). Suppose the commutative and regular constraint language 
⁎
 is decomposed as stated in Theorem 13,(3)
 
⧢⧢
 Denote by 
 the vector representation, according to Definition 16 and corresponding to Equation (3). If for all  and all  we have 
, then the problem is in P.

Proof

By Proposition 15, we can assume that if 
 is infinite with  and  we have 
⁎
. By assumption, every letter in 
⧢⧢
 either appears not at all, or infinitely often, which by the above means without any restriction. Hence,
⧢⧢
⁎
 for some3 . The constrained synchronization problem for each single language 
⁎
 can be solved in polynomial time. Just ignore all transitions by letters in  for a given input semi-automaton. The resulting unconstrained synchronization problem can then be solved in polynomial time by Theorem 2. By Lemma 7 the original problem can be solved in polynomial time. □

Interestingly, because of Lemma 22 stated next, if in the sets 
⧢⧢
, we have at most one 
 such that 
, and at most one other 
 such that 
 is infinite, and 
 for all 
, then also

Image 7
. However, as shown later, if 
 and 
 is infinite, then the problem becomes NP-hard.
Lemma 22

Let  be a unary semi-automaton with  and . Then 
 for some  if and only if 
.

Proof

Intuitively, the action of the letter a partitions the state set into a set of cycles and non-cycle states, where to a cycle a (possibly empty) subset of non-cycle states corresponds that are directed in a “tree-like” fashion to the cycle. With this picture in mind, applying the letter  times moves the states in S to cycle states, which gives the claim.

For a more formal argument, consider the state sets 
 for . As , we can deduce, using the monotonicity of the application of a letter for subset inclusion inductively, that 
 for every . Hence, if 
, we must have 
, or said differently, the letter a permutes the state set 
. As these sets can only get smaller, we must have a smallest i such that 
. But then, inductively, 
 for every . Also, as the sets get smaller, but not smaller than a singleton set, we can deduce . Now, let  be an arbitrary subset. Then 
 and by the above reasoning the letter a permutes the latter set, hence it acts injective on the former state set. A similar reasoning, as we do not leave the permuted set 
, then gives, inductively, that 
 for every . Hence, if 
 and , then 
, and if , then, as the sets only get smaller, but not smaller than a single element, we also find 
. □

Proposition 23

Let 
 be the alphabet. Consider the constrained synchronization problem (Problem 1). Suppose the commutative constraint language 
⁎
 is decomposed as stated in Theorem 13,(4)
 
⧢⧢
 Denote by 
 the vector representation, according to Definition 16 and corresponding to Equation (4). If for all , in the vector 
, at most one entry equals ∞ and at most one entry is non-zero, and if so it equals one, then the problem is solvable in polynomial time.

Proof

By Proposition 15, we can assume that if 
 is infinite with  and  we have 
⁎
. By Lemma 7 we can consider a single language of the form 
⧢⧢
. If in the corresponding vector no ∞ appears, this language is finite. This case is solvable in polynomial time by Lemma 9. If only a single entry equals ∞, and all others are zero, then this is solvable in polynomial time by Proposition 21. So assume we have 
 with 
⁎
, 
 and 
 for 
.

Let  be a semi-automaton. By the constrained language, only the letters 
 and 
 can appear in a synchronizing word. For abbreviation we write a for 
 and b for 
. We can assume  by ignoring all other transitions. The letter b must appear precisely once. First, let us only consider the transitions labeled with a, i.e., view  as a unary automaton over .

Set 
. With the same argument as in the proof of Lemma 22, the letter a permutes the state set T, which gives 
 for each . So, to see if there exists a word of the form 
 with 
, we just have to test all words with , and, by applying Lemma 22 to 
, we only have to test . In total we only need to test  words 
 and each can be done in polynomial time. □

3.4. The NP-hard variants of the problem
In this section, we state a criterion, in terms of the constraint language, which gives -hardness. Surprisingly, in contrast to Proposition 23, if, in some infinite part 
⧢⧢
, there exists  such that 
 with , then the problem gets NP-hard.

Proposition 24

Let 
 be the alphabet. Consider the constrained synchronization problem (Problem 1). Suppose the commutative constraint language 
⁎
 is decomposed as stated in Theorem 13,(5)
 
⧢⧢
 Denote by N the vector representation, according to Definition 16 and corresponding to Equation (5). Suppose we find 
 and a maximal4 vector 
 such that at least one of the following conditions is true:

(i)
 and 
 for distinct 
, or

(ii)
 and 
 for distinct 
.

Then the problem is NP-hard.
First a rough outline of the reduction that we will construct. We use the problem Intersection-Non-Emptiness (Problem 3), which is -complete for unary alphabets. We combine the input automata into a big single automata, in which the input automata are embedded. The letter that is allowed to appear infinitely often plays the role of the transition letter of the input automata. The letter (or the two letters) that appears only finitely often, but at least once, is used (1) to prepare the now embedded input automata in such a way that after reading this letter a well-defined situation is created that, among other things, simulates “parallel runs” of the embedded input automata, and (2) to ensure that after these “parallel runs” we can map the resulting states to a defined synchronizing sink state if and only if all the embedded automata accept a common word. Hence, the letter that is unrestricted is the letter over which the input automata are defined, the restricted letter(s) is (are) used to enforce that we have a word that is accepted by them all. In the construction, we, additionally, use a set P of states that guarantees we use the set 
⧢⧢
 for permissible synchronizing words. We do this because the property of it having one letter that can occur arbitrary often, and one letter to appear a specific, strictly greater than one, number of times, is crucial.

Please see Fig. 1 for a drawing of our reduction in accordance with the notation that will be introduced in the proof.

Fig. 1
Download : Download high-res image (114KB)
Download : Download full-size image
Fig. 1. Schematic illustration of the reduction in the proof of Proposition 24 for Σ = {a,b}={a1,a2} and a language of the form 
⧢
⧢
⧢
. Here i0 = 1 with 
⁎
 and 
 for 2 ⩽ m < ∞. The transitions of the automata 
 are realized by the letter a, and are, for readability, left out.

Proof

Notation as in the statement of the Proposition. The proofs for both cases (i) and (ii) are very similar. We give a full proof for case (i) and then describe where it has to be altered to give a proof for case (ii).

(i) By Proposition 18 and as the assumption holds true for 
 if and only if it holds true for the set of maximal vectors of N, by taking the maximal vectors, we can assume without loss of generality that the vectors in N are incomparable. Write
 
⧢⧢
 in correspondence with the set N according to Definition 16.

By incomparability of the vectors in N for each 
 there exists some index  such that(6)
 We define a function 
 by choosing such an index j, i.e., setting  for each 
 with some  from Equation (6). We use these indices to distinguish the corresponding sets used in Definition 16
⧢⧢
 from the set
⧢⧢

We define a function 
 which will be used later to single out 
⧢⧢
 by setting5 for 
(7)
  For words 
⁎
 with 
 for all 
, the following holds(8)
⧢⧢
 As for each 
 we have some  such that 
 is finite6 and contains a unique word of length 
, and
 by choice of 
. Set

By Proposition 15 we can assume that if 
 is infinite with  and  we have 
⁎
. In what follows only the letters 
 and 
 are essential. We denote by a the letter 
, by b the letter 
. We also set 
 for abbreviation.

We use the problem Intersection-Non-Emptiness (Problem 3) for unary automata, which is NP-complete in this case, for our reduction. Let 
 be automata with 
 for  and disjoint state sets. Construct a semi-automaton  with state set 
 and transition function 
  and
  For 
 and  set
  and 
 for . Lastly for  we set  for each . Then our automaton is fully specified.

We argue that our semi-automaton  has a synchronizing word in L if and only if 
.

First suppose 
. Then it is easy to see that 
. We have 
 and 
. For 
 choose any 
. Let u be the concatenation of all these words in any order. Then we have 
 and 
⧢⧢
.

Conversely assume we have  with . As 
 is a sink state we have 
. We need one b to leave a state from 
. After this we end up in some state from 
. And from those states to get to 
, then 
 and so on until 
 we have to read  additional times the letter b. Hence, a word that can map any state in 
 to 
 has to contain at least m many times the letter b.

For some  we have 
⧢⧢
. Consider the states in P. The only way to go from 
 to 
 for 
 is to read at least  times the letter 
. Hence 
 and so by Equation (8) we have 
. But as 
 contains a unique word of length m and with 
 we have 
.

Write 
 with 
⁎
 for .

By construction 
. Hence by definition of the transition function
 Note that for all 
 and 
⁎
⁎
 with  we have(9)
 Assume 
 for some , then by Equation (9) as 
, we have
 Hence 
 for . As by construction of  only the letters a and b act non-trivial7 on the state set , 
 does not contain the letter b and no state from P can be entered from a state in , in particular not from 
, which implies 
 for each prefix of u of 
, we have that 
. This gives 
.

(ii) In this case let 
 and 
. Set 
. We can use essentially the same reduction. The difference is that we use the letter b to reset all automata 
 to their initial states. Instead of  states 
 we use m states 
, and the letter c is used to move from state 
 to state 
 until we reach the final sink state 
. All other letters induce self-loops on the states 
. Also inside the automata 
 the letter b also moves every state to the corresponding initial state. The letter c is used to move from a final state to the state 
. For non-final states the letter c induces a self-loop. With this construction, we can argue similarly to case (i) that the thus altered automaton construction admits a synchronizing word in the constraint language if and only if we have a unary word accepted by all input automata. □

3.5. The PSPACE-complete variants of the problem
Proposition 25

Let 
 be the alphabet. Consider the constrained synchronization Problem 1. Suppose the commutative constraint language L is decomposed as stated in Theorem 13,(10)
 
⧢⧢
 Denote by N the vector representation, according to Definition 16 and corresponding to Equation (10). Suppose we find 
 and distinct 
 and a maximal vector 
 such that 
 and 
. Then the problem is -hard.

First, a rough outline of the reduction that we will construct. We will use the problem Sync-Into-Subset (Problem 2), which is PSPACE-complete for some fixed binary alphabet. The two letters that are unrestricted are the letters over which an input automaton is defined, the restricted letter is used to enforce that we have some word over the unrestricted letters that maps all states into some specific set of states. Additionally, we add a set P of states that guarantees we use the set 
⧢⧢
 for permissible synchronizing words. We do this because the property of it having two letters that can occur arbitrary often, and one letter is required to appear a specific non-zero number of times, is crucial.

Please see Fig. 2 for a drawing of our reduction in accordance with the notation that we introduced in this proof.

Fig. 2
Download : Download high-res image (205KB)
Download : Download full-size image
Fig. 2. Schematic illustration of the reduction in the proof of Proposition 24 for Σ = {a,b,c}={a1,a2,a3} and a language of the form 
⧢
⧢
⧢
⧢
⧢
⧢
. Here i0 = 1 with 
⁎
, 
⁎
 and 
 for 1 ⩽ m < ∞. The transitions labeled by a and b in  are the original transitions of the input automaton and are left out for readability.

Proof

Notation as in the statement of the proposition. By Proposition 18 and as the assumption holds true for 
 if and only if it holds true for the set of maximal vectors of N, by taking the maximal vectors, we can assume without loss of generality that the vectors in N are incomparable. Write
 
⧢⧢
 in correspondence with the set N according to Definition 16.

By incomparability of the vectors in N for each 
 there exists some index  such that(11)
 We define a function 
 by choosing such an index j, i.e., setting  for each 
 with some  from Equation (11). We use these indices to distinguish the corresponding sets used in Definition 16
⧢⧢
 from the set
⧢⧢

We also define a function 
 which will be used later to single out 
⧢⧢
 by setting8 for 
(12)
  For a word 
⁎
 with 
 for all 
, the following holds(13)
⧢⧢
 As for each 
 we have some  such that 
 is finite9 and contains a unique word of length 
, and
 by choice of 
. Set

By Proposition 15 we can assume that if 
 is infinite with  and  we have 
⁎
. In what follows only the letters 
 and 
 are essential. We denote by a the letter 
, by b the letter 
 and by c the letter 
. We also set 
 for abbreviation.

Now our reduction from Sync-Into-Subset given in Definition 2. Set . Let  be a semi-automaton with non-empty subset . We construct an automaton 
 with 
.

For states 
 we set
  and for the states in P with 
 and  we set
  and 
 for .

We have that 
 has a synchronizing word  if and only if  for some 
⁎
.

First assume  for some 
⁎
. Then 
. We define 
 for 
 by setting10
  which is well-defined as 
 for 
 implies 
 by Equation (12). Let v be the concatenation of the 
 in any order and set 
. Then 
⧢⧢
. Note that the factors 
⁎
⁎
 and 
⁎
 of v pose no problem here as 
⁎
 and 
⁎
. Then by choice of the 
 we have 
, and as 
 is a sink state 
.

Conversely, assume 
 has a synchronizing word . As 
 is a sink state we must have 
. Also because 
 we have 
 for each 
. So by Equation (13) this implies 
⧢⧢
. Hence as 
 contains a unique word of length  we have 
. Write 
 with 
⁎
 for . For 
⁎
 with 
 we have
 But we reach 
 so we must have 
, for otherwise we would not have enough letters c left to transfer any state from 
 to 
. The condition 
 with 
 is only possible if 
. As for  we have  for each , we can remove all these letters from 
 to get a new word 
⁎
 with 
. □

3.6. Main theorem for commutative regular constraints
Combining everything up to now gives our main computational complexity classification result for

Image 11
with  commutative and regular.
Theorem 26

Let 
 be the alphabet. Consider the constrained synchronization problem (Problem 1). Suppose the commutative constraint language 
⁎
 is decomposed as stated in Theorem 13,(14)
 
⧢⧢
 Denote by 
 the vector representation, according to Definition 16 and corresponding to Equation (14). By taking the maximal vectors in N, which is no restriction by Proposition 18, we can assume the vectors in N are incomparable.

(i)
For all , if we have distinct 
 with 
, then 
 for all other 
. More formally,
 Furthermore, suppose N fulfills the condition mentioned in Proposition 24, then it is -complete.

(ii)
If the set N fulfills the condition imposed by Proposition 25, then it is -complete.

(iii)
In all other cases the problem is in .

Proof

Notation as in the statement of the Theorem. By Proposition 15 we can assume that if 
 is infinite, with  and , we have 
⁎
. Proposition 24 and Proposition 25 give the corresponding hardness results for case (i) and (ii). By Theorem 8 the problem is always in . This gives case (ii). Suppose case (i) holds. Beside hardness, we still have to show containment in . We will show that for each language 
⧢⧢
 with  the constrained synchronization problem for this language is in . By Lemma 7 this would give our claim for case (i). If two different languages 
, 
 with 
 are infinite, then we can apply Proposition 21 with the assumptions from case (i). Otherwise, either the language 
⧢⧢
 with  is finite, in which case we can apply Lemma 9, or a single language 
 with  is infinite, in which case we can apply Lemma 11, by the assumption that the infinite 
 equal 
⁎
. Hence for all these languages the problem is in .

Now suppose case (iii) holds. Then for each 
 with  one of the following conditions must hold, as otherwise we would be either in case (i) or (ii).

(a)
If 
 for two distinct 
 with 
 then 
 for all other 
 (for example , note that this condition is the same as one of two conditions states in case (i)).

(b)
If 
 and 
 for all 
. Then, either 
 for all 
, or 
 for some 
 and 
 for all 
 (for example ).

(c)
We have 
 for all  (for example ).

We consider the constrained synchronization problem (Problem 1) for the single language
⧢⧢
 corresponding to the vector 
 and show that it is in . In case (a), by Proposition 21 the problem is in . For case (b), by Proposition 23, the problem is in . In case (c), the corresponding language is finite and so, by Lemma 9, in . Taken together, by Lemma 7, the problem for L is in . □
The assumption that the vectors in N are incomparable is essential in the statement, otherwise it would be more complex. For example, a language with the vector representation  gives an NP-complete constrained problem. However, the formula stated in Theorem 26 for the NP-complete case is not fulfilled, as the first vector has two entries with ∞ and another non-zero finite entry. But for , the maximal vectors, the conditions in the NP-complete case above apply. We give some examples for all cases in Example 27.

Example 27

Let  with 
.

•
If ⧢
⁎
 with , then

Image 12
is -complete.
•
If ⧢
⁎
⧢ with , then

Image 12
is -complete.
•
The constraint language from Example 17 gives a -complete problem.

•
If ⧢
⁎
⁎
⧢⧢
⁎
 with , then

Image 12
is -complete.
•
If ⧢
⁎
 with , then

Image 7
.
•
If 
⁎
⧢
⁎
 with , then

Image 7
.
3.7. Deciding the computational complexity of the constrained synchronization problem
This section addresses the issue of deciding the computational complexity of

Image 11
, for a constraint automaton such that  is commutative.
The first definition is a mild generalization of a definition first given in [25], and used for state complexity questions in [19], [26].

Definition 28

Let 
 and suppose 
 is a complete and deterministic automaton accepting a commutative language. Set 
 for . The automaton 
 with 
,
 and 
 is called the commutative automaton constructed from .

If  is the minimal automaton of a commutative language, it is exactly the definition from [19], [26], [25]. In that case, also in [19], [26], [25], it was shown that 
, and that  is a union of certain shuffled languages. Both statements still hold for any automaton  such that  is commutative.

Theorem 29

Let 
 and suppose 
 is a complete and deterministic automaton accepting a commutative language. Denote by 
 the commutative automaton from Definition 28. Then 
.

Proof

If  then by definition 
, hence 
. Conversely suppose 
. Then 
, which is equivalent with 
 for some  and . As 
 and  is commutative, we have11 
. This gives
 as 
, and so
 Continuing similarly
 which gives 
. Doing this for all letters we find
 which gives 
, or . □

Remark 30

Let 
 be the commutative automaton of a automaton  accepting a commutative language. What happens if we construct 
? We get, up to renaming of the states, the automaton 
 again. This is because 
, which can be identified with 
 again.

The set of words that lead into a single state of the commutative automaton has a simple form.

Lemma 31

Let 
 and suppose 
 is a complete and deterministic automaton accepting a commutative language. Denote by 
 the commutative automaton from Definition 28. Let 
 and set 
⁎
. Then
⁎
⧢⧢

Proof

Notation as in the statement of the Lemma. First suppose 
⁎
 with 
. Then 
 for all . Hence 
 and as 
⧢⧢
 we get 
⧢⧢
. Conversely assume 
⧢⧢
. Then as 
 we have 
 for all . By definition this is equivalent with 
. □

Example 32

Note that the form from Lemma 31 need not hold for an arbitrary automaton. For example, let  and 
. Then a minimal automaton has two states with a single accepting state, and the commutative automaton derived from it has four states, with three accepting states. We have 
⧢
, but L cannot be written in the form 
⧢
 with unary languages 
 and 
.

As the language of a deterministic automaton can be written as a disjoint union of languages which lead into a single final state, the next is implied.

Corollary 33

Let 
 and suppose 
 is a complete and deterministic automaton accepting a commutative language. Denote by 
 the commutative automaton from Definition 28. Set . If  (the case  implies ), we write 
. Set12 
⁎
 for  and . Then(15)
 
⧢⧢

With these notions, we can derive a decision procedure. First construct the commutative automaton. Then derive a representation as given in Equation (15). Use this representation to compute a vector representation according to Definition 16. With the help of Theorem 26, from such a vector representation the computational complexity can be read off.

Theorem 34

Let 
 be a fixed alphabet. For a given (partial) automaton 
 accepting a commutative language, the computational complexity of

Image 13
can be decided in polynomial time.
Proof

We can assume  is complete, otherwise we add a sink state and if  is undefined for  and , we add a transition to the sink state. This operation does not alter the accepted language. First, we check, in polynomial time, if . If , then

Image 11
is decidable in constant time. So, from now on, assume . Construct13 the commutative automaton 
, which has at most 
 states. From it we can derive the form (15) given in Corollary 33. From this form we can compute a vector set N according to Definition 16, as it is easy to check if a unary language is finite or infinite. Also note that in this form the unary languages 
 can be accepted by unary automata with a single final state by the way they are defined. Then  is infinite if and only if in at least one vector the entry ∞ appears. The condition (i) from Theorem 26 can be checked easily, also condition (ii). Hence by Theorem 26 this gives a decision procedure for the computational complexity of the resulting problem
Image 11
. Every step can be performed in polynomial time. □
4. Synchronizing commutative semi-automata under arbitrary regular constraints
In Section 3 we have looked at the computational complexity of

Image 12
for different regular constraint languages L coming from the class of regular commutative languages. Another variant might be to restrict the input semi-automata to a certain class. We follow this approach here by restriction to commutative input semi-automata. We show that for these automata, the problem is always polynomial time solvable, for every regular constraint language.
But first, we need the following notions. Let  be a semi-automaton. We say that a state  is connected to a state , or t is reachable from s, if there exits a labeled path from s to t, i.e., we find a word 
⁎
 such that . A subset  is called a strongly connected component, if every two states in S are connected, and if S is maximal with this property. These are essentially graph theoretical concepts and properties of the automaton graph of , i.e., the graph resulting if we forget about the labeling of transitions. Also, these notions transfer to subsets, i.e., the power automaton of , having as states the subsets of states and as transition function the original transition function as induced on subsets [16]. In this sense, we also say that a subset of states  is reachable from another subset of states , if they are connected in the power automaton, i.e.,  for some word 
⁎
.

The strongly connected components of a given semi-automaton play a crucial role. Hence, it is worthwhile to keep in mind that, seeing the strongly connected components as single nodes in a new graph, they form a directed acyclic graph (DAG) [27].

A deterministic semi-automaton  is called commutative, if for any state  and symbols , we have  [28]. A word v is a permutation of another word u, if v results from u by reordering of its letters. For commutative automata [29] we have  for every two words  that are permutations of each other. We use this property without special mentioning here. Observe that, for commutative semi-automata, the power automaton is also commutative, i.e., we have  for every subset of states .

A semi-automaton  is called weakly acyclic, if there exists an ordering 
 of its states such that if 
 for some letter , then . An automaton is weakly acyclic, if  for 
⁎
 and  implies , i.e., the only loops in the automaton graph are self-loops. This is also equivalent with the fact that the reachability relation between the states is a partial order.

This section splits into three subsections. The first, Subsection 4.1, is concerned with the set of synchronizing words for commutative semi-automata. The main result of this subsection is Proposition 37, stating that the set of synchronizing words for a commutative automaton can be represented by a weakly acyclic and commutative automaton computable in polynomial time. Then, in Subsection 4.2, we show an auxiliary result that is also of independent interest, namely that, given m weakly acyclic and commutative automata, the set of words accepted by them all is recognizable by a weakly acyclic automaton computable in polynomial time for a fixed alphabet. Then, in Subsection 4.3, we combine all these results to show Theorem 45, the statement that for commutative input automata the constrained synchronization problem is tractable.

4.1. The structure of the set of synchronizing words for commutative automata
In commutative semi-automata, a synchronizing state must be a sink state, a property not true for general semi-automata.

Lemma 35

[29]
Let  be a commutative semi-automaton. Then, the synchronizing state must be a sink state (and hence is unique).

The next lemma is important in the proof of Proposition 37.

Lemma 36

Let  be a commutative semi-automaton,  a strongly connected component and 
⁎
. Then the states in  are pairwise connected.

Proof

Let 
. Then 
 and 
 for some 
. As S is a strongly connected component, we find 
⁎
 such that 
 and 
. But then, by commutativity, 
 and similarly 
. □

For commutative automata, the set of synchronizing words is represented by a weakly acyclic automata that is constructed out of the strongly connected components and computable in polynomial time.

Proposition 37

Let  be a synchronizing commutative semi-automaton with n states. Then, there exists a weakly acyclic commutative semi-automaton with at most n states and the same set of synchronizing words computable in polynomial time for a fixed alphabet.

Proof

Define an equivalence relation on Q by setting two states 
 to be equivalent 
 iff they are contained in the same strongly connected component. By Lemma 36 this is in fact a congruence relation, i.e., if 
, then 
 for every 
⁎
.

Let 
 be a transversal of the equivalence classes, i.e., we pick precisely one element from each class. Define  with 
 and 
 iff 
. As we have a congruence relation, we get the same automaton for every choice of transversal 
 (in fact, we only note in passing that  is a homomorphic image of  and corresponds to quotiening the automaton by the introduced congruence relation). Next, we argue that the sets of synchronizing words of both automata coincide.

Let 
 be the synchronizing state of . By Lemma 35 it is a sink state, and so 
 is a strongly connected component and we can deduce 
. Suppose 
⁎
 is a synchronizing word of . So, for each state 
 from the transversal, we have 
, which implies, as, inductively, for every prefix v of u we have 
, that 
 and u synchronizes . Conversely, suppose 
⁎
 synchronizes  and let . Then 
 for some 
. Again, for every prefix v of u, we have 
, as is easy to see by the definition of  and as ∼ is a congruence relation. So, 
, which implies, as 
 is a strongly connected component, that 
. □

Remark 38

With the method of proof from Proposition 37, we can slightly improve the running time stated in Theorem 2 for commutative input semi-automata.

Corollary 39

Let  be a commutative semi-automaton. Then it can be decided in time14  if  is synchronizing.

Proof

For a given directed acyclic graph with n nodes and m edges, a topological sorting can be performed in time , see [27]. Hence, if we consider the directed acyclic graph resulting from the strongly connected components [27] of the automaton graph of , we can topologically sort it in time , as we have at most  strongly connected components and  many edges among them, as this is an upper bound for the edges , as each state contributes  many edges. The strongly connected components themselves can also be computed in time  with a similar argument, see [27].

Another argument computes first the strongly connected components, from which the automaton  from the proof of Proposition 37 can be derived, and then uses the fact [35, Corollary 6] that for weakly acyclic automata we can decide synchronizability in , where m denotes the number of strongly connected components of . □

Let us note the following consequence of Lemma 43 and the bound  for a shortest synchronizing word in weakly acyclic automata [33, Proposition 1] and a bound for the shortest synchronizing word with respect to a constraint [35, Proposition 7]. This gives an alternative proof of the tight bound  for commutative automata from [29], [28].

Corollary 40

If  is a synchronizing commutative semi-automaton with n states, then there exists a synchronizing word of length at most  and, for every constraint PDFA , there exists a synchronizing word in  of length at most  
 .

Proof

By Lemma 43 the set of synchronizing words equals the set of synchronizing words of a weakly acyclic automaton, for which we have the known bounds. □

In fact, with a little more work and generalizing Lemma 43, using [33, Proposition 1], we can show the stronger statement that for commutative , if there exists a word 
⁎
 with , then there exists one of length at most .

4.2. Recognizing the intersection of weakly acyclic commutative automata
Here, we show that an automaton for the intersection of the languages accepted by weakly acyclic automata is computable in polynomial time.

Proposition 41

Let 
, , be weakly acyclic and commutative automata with at most n states. Then, 
 is recognizable by a weakly acyclic commutative automaton of size 
 computable in polynomial-time for a fixed alphabet.

Proof

Let 
. Define the threshold counting function 
⁎
 by 
.

Let . Suppose 
⁎
. If 
 for some , then 
 must traverse at least one self-loop labeled by 
 when reading u, as 
 is weakly acyclic. So, by not traversing these self-loops an appropriate number of times, we find a word 
⁎
 with 
, which implies 
, and 
.

For , set 
. Define 
. Let 
, by the above and using that 
 is commutative, we can deduce 
. If 
, then there exists 
 with 
 for all  and 
. As 
, we have 
. As before, there exists 
⁎
 with 
 for all  such that 
 and 
. Hence, 
, and as 
 for all  and by commutativity, this implies 
, which, furthermore, implies 
, as both end up in the same state of 
. Summarizing, we have shown
 As  was chosen arbitrarily, 
.

Finally, a language of the form 
 is recognizable by a weakly acyclic commutative automaton: set 
 with  and 
 and 
. It is obvious that  is commutative and 
 as  essentially implements the threshold counting expressed by 
.

As 
 contains 
 words, the sets 
 and their intersection can be computed in polynomial time. Also, the automaton recognizing 
 is computable in polynomial time. □

Remark 42

With Proposition 41, we can deduce that we can decide in time 
, for some computable function f, if the intersection of the languages recognized by m weakly acyclic commutative automata is non-empty. Hence, this problem is in XP for these types of automata and parameterized by the size of the alphabet (see [34] for an introduction to parameterized complexity theory). Contrary, for general commutative, even unary, automata this problem is NP-complete [32], and, further, for fixed alphabet sizes, -complete with the number of input automata as parameter, see [32].

4.3. A polynomial-time algorithm for the constrained synchronization problem with commutative input semi-automata
Here, we show the main result of this section that the constraint synchronization problem is tractable for commutative input automata. But first, we need a lemma stating that we can compute an automaton for the set of synchronizing words of a commutative automaton in polynomial-time.

Lemma 43

Let  be a commutative semi-automaton with n states. Then, the set of synchronizing words is recognizable by an automaton of size 
 computable in polynomial time for a fixed alphabet.

Proof

First, we can test in polynomial time if  is synchronizing. If not, an automaton with a single state and empty set of final states recognizes the empty set. Otherwise, by Proposition 37 we can compute a weakly acyclic automaton  having the same set of synchronizing words in polynomial time. By Lemma 35, there exists a unique synchronizing state 
. For , let 
 be the automaton  but with start state q and set of final states 
. Then, the set of synchronizing words of  is 
 
 By Proposition 41, we can compute in polynomial time a weakly acyclic commutative automaton of size 
 recognizing the above set. □

Remark 44

In the proof of Lemma 43, as  is weakly acyclic, we can show that 
 
⁎
 
 
 which improves the running time of the algorithm. In terms of the partial order given on the states by the reachability relation, this is implied as every letter either moves to a larger state or induces a self-loop, which implies that we can take the above intersection over the minimal states with respect to the partial order.

Now, combining the above results we can prove our main result concerning the constrained synchronization problem.

Theorem 45

Let 
⁎
 be regular. Then, for a commutative input semi-automaton  with n states, the problem if  admits a synchronizing word in L is solvable in polynomial time.

Proof

By Lemma 43, we can compute in polynomial time an automaton  of size 
 recognizing the set of synchronizing words of . By the product automaton construction [16], using an automaton for L, we can compute in polynomial time a recognizing automaton for the intersection . Then, checking that the resulting automaton for the intersection recognizes a non-empty language can also be done in polynomial time [16]. □

The degree of the polynomial measuring the running time depends on the alphabet size. But note that a fixed constraint automaton also fixes the alphabet, hence this parameter is not allowed to vary in the input semi-automata.

5. Conclusion
We have looked at the constrained synchronization problem (Problem 1) for commutative regular constraint languages, thereby continuing the investigation started in [7], [31]. The complexity landscape for regular commutative constraint languages is completely understood. Only the complexity classes ,  and  arise, and we have given conditions for , -complete and -complete problems. In [7] the question was raised if we can find constraint languages that give other levels of the polynomial time hierarchy. At least for commutative regular languages this is not the case. Furthermore, we have given a procedure to decide the computational complexity of

Image 11
, for a given automaton  accepting a commutative language. Lastly, if we restrict the problem to commutative input semi-automata, the problem is always in , for every regular constraint language. This motivates the question of what types of input semi-automata can be used to realize certain complexities. A question for possible future investigations.