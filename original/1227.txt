Abstract
We consider the single-machine scheduling problem to tradeoff between the number and the length of accepted jobs. The algorithm introduced by Lin and Wang (2007) (called Lin-Wang's algorithm), for solving the single-machine scheduling problem to minimize the number of tardy jobs, is closely related to our research. The original version of Lin-Wang's algorithm runs in O(n2) time. By using the technique of the preemptive scheduling combined with a data structure, we show in this paper that a variant of Lin-Wang's algorithm actually runs in O(nlog⁡n) time. This enables us to further show that the tradeoff problem can be solved in O(nlog⁡n) time.

Keywords
Single-machine
Preemptive scheduling
Number of tardy jobs
Tradeoff

1. Introduction
In the single-machine scheduling problem for minimizing the number of tardy jobs, we have n jobs 
 to be scheduled on a single machine available from time 0. Each job 
 has a processing time (or length) 
 and a due date 
. Then we use the notation 
 to indicate a job 
. A job 
 with 
 must be tardy in every schedule, and so, can be deleted from the job instance. Thus, we assume in the sequel that 
 for . For a subset 
, we use 
 to denote the total processing time of the jobs in 
, and call 
 the length of 
. Given a schedule σ of the n jobs, let 
 and 
 denote the start time and the completion time, respectively, of 
 in σ. 
 is tardy in σ if 
 and early otherwise. Moreover, let 
 stand for the tardy index of 
 in σ, that is, 
 if 
 is tardy in σ and 
 if 
 is early in σ. The number of tardy jobs in schedule σ is given by 
. For simplicity, σ will be omitted unless it is required. Then the problem is denoted by 
.

In a schedule of , the tardy jobs can be scheduled after all early jobs in an arbitrary order. For convenience, when we describe a schedule, we only consider the early jobs. A schedule is called tight if the jobs are processed consecutively in the schedule. The EDD-schedule of  is defined to be the tight schedule in which the jobs are scheduled in EDD (earliest due date first) order. A subset  of  is called EDD-feasible if every job is early in the EDD-schedule of .

In practice, the manufacturer sometimes needs to consider the machine occupation time for processing the jobs to reduce expenses. In such circumstance, the jobs are selectively processed. Suppose that the scheduler wants to schedule k () early jobs such that their total length is as small as possible, or equivalently the machine occupation time is minimized. For this purpose, one should find an EDD-feasible subset 
⁎
 with 
⁎
 such that the length 
⁎
 is as small as possible. We call such an 
⁎
 a k-optimal subset of . In the case that no k-subset of  is EDD-feasible, the problem is infeasible.

Let m be the largest index in  such that there exists an EDD-feasible m-subset of . By regarding  as a variable, the scheduler has to tradeoff between k (the number of accepted jobs) and 
⁎
 (the minimum length of accepted jobs). This inspires us to investigate the single-machine scheduling problem to tradeoff between the number and the length of accepted jobs (tradeoff problem), denoted by 
⁎
, with the aim to find a subset list 
⁎
⁎
⁎
 of , where 
⁎
 is a k-optimal subset of  for each . We call 
⁎
⁎
⁎
 an optimal-subset list of .

To solve the tradeoff problem 
⁎
, the starting point is to figure out the properties satisfied by the optimal schedules for problem 
. It is well known that problem 
 is solvable by Moore-Hodgson's algorithm presented in Moore [8] in  time. Although it is classical and simple, Moore-Hodgson's algorithm does not work for the resolution of problem 
⁎
. So we resort to another algorithm, the one devised by Lin and Wang [6] for solving problem 
 in 
 time.

Lin-Wang's Algorithm

For problem 
.

–
Relabel the jobs in SPT (shortest processing time first) order such that 
 and break the ties (if any) by the EDD rule.

–
Generate the set of scheduled jobs  iteratively in the following way:

Initially set 
 and 
, where we regard 
 as an empty schedule.

For , do the following: Consider the EDD-schedule π of 
. If all jobs are early in π, then regard 
 as early and set 
 and 
. If some job is tardy in π, then regard 
 as tardy and set 
 and 
.

–
Output the final set 
 and the schedule 
.

Compared with Moore-Hodgson's algorithm, Lin-Wang's algorithm has the following advantages: (i) it returns an optimal schedule which minimizes 
, and subject to this, further minimizes the length of early jobs, and (ii) in the implementation of Lin-Wang's algorithm, once a job is chosen as an early job at some step, it will be early in the final schedule. With these advantages, Lin-Wang's algorithm has been used in the literature as subroutines for solving several scheduling settings, for example, in He et al. [2], Hoogeveen and T'kindt [3], and Luo et al. [7].

It should be clarified that Lin and Wang [6] claimed (without proof) that their algorithm runs in  time. However, Hoogeveen and T'kindt [3] pointed out that the  time complexity claimed in Lin and Wang [6] seems unreasonable and an 
 time complexity can be easily observed. After we communicated with the authors of Lin and Wang [6], they agreed with the comments in Hoogeveen and T'kindt [3]. So the original version of Lin-Wang's algorithm requires 
 time. In this paper, we present a variant of Lin-Wang's algorithm with running time . As a consequence, the tradeoff problem 
⁎
 is also solvable in  time.

Apart from the reasons stated above, our research is also motivated by several classical open problems related to the criterion 
. Let  denote the single-machine primary-secondary scheduling problem which asks for finding a schedule minimizing the secondary criterion g subject to the restriction that the primary criterion f is minimized. Seven problems related to the criterion 
 were posed as open in Lee and Vairaktarakis [5] in 1993. Some progresses in the study of these problems were made in Huo et al. [4] and Yuan [9]. Huo et al. [4] showed that the two problems 
 and 
 are binary NP-hard. The work in Yuan [9] implies that the two problems 
 and 
 are unary NP-hard. Up to now, the complexities of the two problems 
 and 
 are still open and the exact complexities (unary NP-hard or pseudo-polynomially solvable) of the three binary NP-hard problems 
, 
, and 
 are still unaddressed. This means that we need to find out more properties for minimizing the criterion 
. We conjecture that the two problems 
 and 
 are polynomially solvable and the other three problems 
, 
, and 
 are pseudo-polynomially solvable. Moreover, we believe that the preemptive scheduling technique in this paper may play an important role in addressing these problems. Finally, our -time algorithm for problem 
 can be directly used as subroutines for solving the problems studied in Hoogeveen and T'kindt [3] and Luo et al. [7], respectively, such that the time complexities of their algorithms can be reduced by a factor of .

This paper is organized as follows. In Section 2, by using the technique of the preemptive scheduling together with a data structure, we propose a variant of Lin-Wang's algorithm running in  time. In each iteration k with , the new algorithm generates the job set 
, which is identical to that returned by Lin-Wang's algorithm. Consequently, the optimal schedule output by the new algorithm is the same as that output by Lin-Wang's algorithm. In Section 3, we show that an optimal-subset list 
⁎
⁎
⁎
 of the tradeoff problem 
⁎
 can be obtained from 
, , in  time. As a consequence, problem 
⁎
 is solvable in  time.

2. A variant of Lin-Wang's algorithm
Consider the job instance 
 and recall that 
 for . Assume that the jobs in  are relabeled in the SPT order such that 
, where ties are broken by the EDD rule. Note that this sorting procedure can be done in  time. Let  stand for the set of early jobs in a schedule σ. From the implementation of Lin-Wang's algorithm, we have the following observation.

Observation 2.1

Lin-Wang's algorithm has the following properties for 
 and 
:

(i)
,

(ii)
for each k with , 
, 
 is EDD-feasible, and 
 is the EDD-schedule of 
,

(iii)
for each k with , 
 if and only if 
 is EDD-feasible; equivalently, 
 if and only if 
 is not EDD-feasible.

We use 
 to denote the preemptive version of problem 
 in which the jobs are scheduled preemptively. It is not hard to verify the following observation.

Observation 2.2

Problem 
 on instance  is equivalent to problem 
 on instance  in the following sense:

(i)
every optimal schedule for problem 
 is an optimal schedule for problem 
, and

(ii)
for every optimal schedule σ for problem 
, the tight schedule in which the jobs are scheduled in the increasing order of their completion time in σ is an optimal schedule for problem 
.

The following lemma can be proved easily by using the job-shifting argument.

Lemma 2.1

A subset  is EDD-feasible if and only if there is a (preemptive or nonpreemptive) schedule of  such that all the jobs in  are early in the schedule.

For our purpose, artificial idle times in a (preemptive) schedule are allowed. For a schedule π of , let  denote the set of time intervals occupied by the early jobs in π. In our algorithm, the time intervals in  will be naturally sorted in the order from left to right. For each , we use 
 to denote the set of early jobs processed in  in π and use 
 to denote the maximum due date of the jobs in 
. Then 
. Sometimes, it is necessary to introduce the trivial time interval . In this case, we define 
 and 
. If no early job starts at time 0, we will add the trivial time interval  into . This guarantees that the first time interval in  always starts at time 0. We also use 
 to denote the set of early jobs completely processed in the time interval  in π. The notation 
 is useful in our discussion and write 
.

Definition 2.1

Let  be an EDD-feasible subset. Let π be a schedule of  such that all the jobs in  are early in π. Suppose that 
, where 
. π is called a DD-schedule of  if

(a)
for every job (if any) 
 with 
, 
 is not EDD-feasible,

(b)
 for , and

(c)
.

If π is a DD-schedule of , we also say that  is a DD-interval family of .

Intuitively, when we only care about the DD-interval families and the jobs scheduled in each interval, a DD-schedule π can be regarded as a “due-date” schedule in which each job is preemptively scheduled as late as possible subject to its due date, with only exceptions in the first interval of . In general, such a DD-schedule σ of  can be obtained iteratively in the following way: Initially set , where  denotes the set of unscheduled jobs in  in the subsequent iterations. At each iteration, if there is an unscheduled job 
, then preemptively schedule 
 in the 
 units of idle times directly before 
, reset 
, and enter into the next iteration. This procedure is repeated until all the jobs in  are scheduled. Moreover, if there is an interval  such that the idle times before t in σ are not enough to preemptively schedule any job 
 with 
, then 
 is also a DD-schedule of , where 
 is the schedule of  obtained from σ by rescheduling the jobs in 
 consecutively from time 0 to 
 such that all the jobs in 
 are still early in 
 (with or without keeping their order in σ).

For a given EDD-feasible subset , there may exist distinct DD-interval families, and distinct DD-schedules of  may induce a common DD-interval family. However, in our algorithm, it is sufficient to consider just one DD-interval family of each . The following lemma, which follows from Definition 2.1 directly, is crucial for our analysis.

Lemma 2.2

Let  be an EDD-feasible subset and let π be a DD-schedule of . For each 
, 
 is EDD-feasible if and only if there are at least 
 units of idle time before time 
 in π.

One shortcoming of Lin-Wang's algorithm is as follows: At each iteration k with , the EDD-schedule of 
 must be generated with  time in the worst case. This leads to the 
-time complexity of Lin-Wang's algorithm. In order to overcome this shortcoming, we present in the following a new algorithm, called Modified Algorithm. In each iteration k, instead of generating the EDD-schedule of 
, we will only update the DD-interval family of 
.

We will use a simple data structure: For an EDD-feasible subset , the intervals in a DD-interval family 
 are stored as a sorted list such that 
. The label of interval 
 is defined to be 
, . So, we may write  as a list 
. Three operations on  will be involved: (Finding) find an interval 
 in ; (Deleting) delete an interval 
 in ; (Inserting) insert a new interval (disjoint with the intervals in ) into . The following lemma is implied in Cormen et al. [1].

Lemma 2.3

For a sorted list , each of the three operations (Finding, Deleting, and Inserting) can be implemented in  time (by applying binary search).

The intuition of Modified Algorithm can be stated as follows. First of all, the jobs are sorted in SPT order such that 
. Then we consider the job 
 for  iteratively. At iteration k, we generate a triple 
 such that 
 is an EDD-feasible subset of 
, and moreover, there is a DD-schedule 
 of 
 with 
 and 
. The design of the algorithm will guarantee that 
. To save the time complexity, the schedule 
 will not be generated in the algorithm.

At the beginning of iteration k, the triple 
 is given in hand, and we will consider the next job 
. Assume that 
. The times not occupied by 
 are called idle times with respect to 
. These idle times correspond to the idle times in schedule 
.

Let 
 be the length of idle times before 
 with respect to 
. Let x be the maximum index in  with 
. Then x can be found by applying binary search on the  labels 
 in  time. Moreover, we clearly have(1)
 Whether there are enough idle times for processing 
 before time 
 depends on whether 
. But we will not calculate 
 by Equation (1) in view of time complexity. Indeed, if 
 and x is sufficiently large, too many operations are involved. Alternatively, we use the following way to check if 
 or not (without the value 
 in hand).

If 
, we know that 
 directly. Otherwise, for , we calculate the values
 iteratively, until we either (Possibility 1) find the maximum index  with
 or (Possibility 2) find that

If Possibility 1 occurs, there are enough idle times before 
 with respect to 
 for processing 
. Then the last 
 units of idle times before 
 with respect to 
 are filled to obtain 
 (and also to obtain 
). After this, 
 is updated accordingly. Note that we need to find the intervals 
 by binary search, each of which costs  time. Thus, the time complexity for dealing with Possibility 1 in the algorithm is given by .

If Possibility 2 occurs, there are not enough idle times before 
 with respect to 
 for processing 
. Then we set 
. The case  can be trivially handled by setting 
. In the case where , we have 
 and there are no jobs 
 that can be completely processed in the idle times before 
 because 
. Then the first x intervals 
 in 
 are replaced by the unique interval 
⁎
 to obtain 
, where 
⁎
 is the total length of these intervals. Such an action enables us to set 
. Note that we need to find the intervals 
 by binary search. Thus, the time complexity for dealing with Possibility 2 in the algorithm is given by .

We finally show that Modified Algorithm has  operations in total for finding, deleting or inserting intervals. Then it can be shown that the time complexity of the algorithm is . Now our algorithm can be formally described as follows.

Modified Algorithm

For problem 
.

Step 1. (Initialization) Relabel the jobs in  in SPT order such that 
 and break the ties (if any) by the EDD rule.

Step 2. (Initial Setting) Set 
, 
, and 
.

Step 3. (Iterations) For , do the following iteratively:

Step 3.1. (Checking 
 and 
) Do the following:

–
If 
, then set 
, 
 and 
, and enter into the next iteration .

–
Otherwise, 
 and the procedure at iteration k is continued.

Step 3.2. (Finding 
) Assume that 
 and define 
. By applying binary search on the  labels 
, we find the maximum label 
 with 
. Once 
 has been found, we also obtain the interval 
 because 
 is the label of this interval. Note that 
, and if , then 
.
Step 3.3. (Finding 
) By applying binary search, we find the interval 
, which is the next interval of 
 in 
.

Step 3.4. (Checking Idle Times) Initially set 
, which is the length of idle times in the interval 
 but before 
, and set . Do the following iteratively:

(3.4.1)
If 
, then set  and go to Step 3.5.

(3.4.2)
If 
, then set  and go to Step 3.5.

(3.4.3)
If 
 and , then go to Step 3.6.

(3.4.4)
If 
 and , then do the following:

–
By applying binary search, we find the interval 
, which is the previous interval of 
 in 
.

–
Set 
, , and return to Step 3.4.

Step 3.5. (Accepting 
) Set 
 and do the following.
–
(Setting 
, 
 and 
) Set 
 and 
 if 
, and set 
 and 
 if 
. Set 
 if 
, and set 
 if 
.

–
(Setting 
) Set 
 if , and set 
 if .

–
(Deleting) Delete the 
 intervals 
 from 
.

–
(Inserting) Insert the new interval 
 into the list 
, 
 to obtain 
. This leads to the following operation “Setting 
”.

–
(Setting 
) Set 
 if , and set 
 if .

Step 3.6. (Rejecting 
) Set 
.
(3.6.1)
(For ) If , then set 
 and 
.

(3.6.2)
(For ) If , then do the following.

–
(Setting 
) Set 
.

–
(Calculating 
⁎
) Calculate the value
⁎
 which is the length of the first x intervals in 
. Note that 
⁎
 can also be calculated efficiently by 
⁎
. But this does not affect the final time complexity.

–
(Deleting) Delete the  intervals 
 from 
 by applying binary search.

–
(Inserting) Insert the new interval 
⁎
 into the list 
 by applying binary search to obtain 
. This leads to the following operation “Setting 
”.

–
(Setting 
) Set 
⁎
.

Step 4. (Generating) Generate the EDD-schedule π of 
.
Step 5. (Output) Output 
 and π. □

Now we give an instance to demonstrate the implementation of Modified Algorithm. Let 
 be the instance defined in Table 1.


Table 1. The scheduling instance 
.

Jobs	J1	J2	J3	J4	J5	J6	J7	J8	J9	J10
Processing times	1	1	1	1	2	3	3	4	5	5
Due dates	2	5	10	12	16	7	13	6	12	18
The 10 iterations of Modified Algorithm are described as follows, where in each figure for iteration k, the value 
 is indicated by “•”.

• (Fig. 1) For , we have 
, 
, and

Fig. 1
Download : Download high-res image (47KB)
Download : Download full-size image
Fig. 1. The triple 
.

• (Fig. 2) For , we have 
, 
, and

Fig. 2
Download : Download high-res image (42KB)
Download : Download full-size image
Fig. 2. The triple 
.

• (Fig. 3) For , we have 
, 
, and

Fig. 3
Download : Download high-res image (32KB)
Download : Download full-size image
Fig. 3. The triple 
.

• (Fig. 4) For , we have 
, 
, and

Fig. 4
Download : Download high-res image (31KB)
Download : Download full-size image
Fig. 4. The triple 
.

• (Fig. 5) For , we have 
, 
, and

Fig. 5
Download : Download high-res image (32KB)
Download : Download full-size image
Fig. 5. The triple 
.

• (Fig. 6) For , we have 
, 
, and

Fig. 6
Download : Download high-res image (18KB)
Download : Download full-size image
Fig. 6. The triple 
.

Remark

From the implementation of Modified Algorithm, we can see that: If 
, then all the intervals in 
 which are obtained by the “Finding operations” in Step 3.4 are covered and replaced by a larger interval in 
, and if 
, then all the intervals in 
 which are obtained by the “Finding operations” in Step 3.4 are replaced by a larger interval 
⁎
 in 
. This is the main reason why our algorithm can save the time complexity.

The next lemma reveals the relations between 
, , in Lin-Wang's algorithm and 
, , in Modified Algorithm on a common job instance 
. Correctness of this lemma follows from a deep understanding of the two algorithms, i.e., Lin-Wang's algorithm and Modified Algorithm. For the sake of completeness, we present a formal proof of this lemma in the appendix.

Lemma 2.4

For each iteration  in both algorithms, 
 and 
 is a DD-interval family of 
. Moreover, there is a DD-schedule 
 of 
 such that 
 and 
.

Theorem 2.1

Modified Algorithm solves problem 
 in  time.

Proof

The correctness of this algorithm follows from Lemma 2.4 and the correctness of Lin-Wang's algorithm. In the next paragraphs, we analyze its time complexity.

The total running time of Steps 1 and 4 is . Steps 2 and 5 run in a constant time. For Step 3, the running time is dominated by the three operations on the list 
: Finding, Deleting, and Inserting. Each of these operations can be done in  time. Thus, it suffices to show that the total number of such operations in Step 3 is .

To this end, we introduce a dummy job 
 and define 
 as an interval in 
 (in Step 3 of Modified Algorithm) in the following way, for .

• 
. For ,

– if 
 (or equivalently, 
), then 
 is defined to be the first interval in 
, and

– if 
 (or equivalently, 
), then 
 is defined to be the unique interval in 
﹨
.

Now let  be the directed graph in which the vertex set is given by 
 and each arc in A is of the form 
 satisfying

• , 
 for , and 
.

Let 
 and 
 denote the out-degree and in-degree of 
 in T, respectively, for . Note that 
. Furthermore, from the knowledge of graph theory, we have

(i) 
.

Suppose that there is a certain  such that 
. Consequently, there are two jobs 
 and 
 with  such that 
. Without loss of generality, we may assume that . From the definition of A, we have 
 for , and 
. This is clearly a contradiction. Hence, we have

(ii) 
.

Let us consider Step 3 of Modified Algorithm at iteration k. We do the “Finding operations” for finding the intervals 
 with 
, and possibly, two other intervals directly before or after these intervals in 
. Thus, there are at most 
 “Finding operations” at iteration k. There are at most 
 “Deleting operations” at iteration k, because in the worst case, all the intervals 
 with 
 should be deleted from 
. Finally, we have one “Inserting operation” to insert the interval 
 to obtain 
 if 
. Thus, there are at most 
 operations of “Finding, Deleting and Inserting” at iteration k. From statements (i) and (ii), the total number of such operations in Step 3 is at most 
. The result follows. □

3. The tradeoff problem
Consider the tradeoff problem 
⁎
 on instance 
 and let 
 be the n subsets generated by Lin-Wang's algorithm. Then 
. Write 
. Note that, if , no k-subset of  can be EDD-feasible. Thus, we only need to find, for each , a k-optimal subset of .

For , let 
 be the smallest index in  such that 
. We call 
 the critical-subset list of . In the following, we will show that the critical-subset list 
 of  must be an optimal-subset list of , that is, for each , 
 is a k-optimal subset of . To this end, we first prove several lemmas. As stated before, 
 for .

Lemma 3.1

For each , there is a k-optimal subset 
 of  such that 
.

Proof

Given , let 
 be a k-optimal subset of . If 
, then we are done. Suppose in the following that 
. Let 
 be the job in 
 with the smallest due date. Let 
﹨
. Since 
 and 
, it is easy to see that 
 is EDD-feasible and 
. From the k-optimality of 
, we conclude that 
 is a k-optimal subset of  such that 
. □

Let 
 be the instance obtained from ﹨
 by setting(2)
 

Lemma 3.2

A subset  of  with 
 is EDD-feasible for instance  if and only if 
﹨
 is an EDD-feasible subset for instance 
.

Proof

Let  with 
 be an EDD-feasible subset of  and let σ be the EDD schedule of . Let 
 be the schedule obtained from σ by removing the job 
 from the time interval 
 and shifting the subschedule of σ from time 
 an amount of length 
 to the left, and replacing the scheduled jobs of  with their counterparts in 
. Let 
﹨
. For any 
, it can be observed that if 
, then 
; if 
, then 
; if 
, then 
, where 
 is the completion time of 
 in 
. Thus, every job in 
 is early in 
. It follows that 
 is an EDD-feasible subset of 
.

Conversely, let 
 be an EDD-feasible subset of 
, let 
 be the EDD schedule of 
 and let 
 be the completion time of 
 in 
. Let i be the largest index such that 
 and 
. If 
 contains no such job 
, then we may assume that 
. Note that if 
, then 
; if 
, then 
. Now let σ be the schedule obtained from 
 by inserting the job 
 in the interval 
, and shifting the subschedule of 
 from time 
 an amount of length 
 to the right, and replacing the scheduled jobs of 
 with their counterparts in . Since 
, we have 
 and hence 
 is early in σ. Let 
. For each 
, if 
, then 
; if 
, then 
; if 
, then 
. So, all jobs in  are early in σ and hence 
 is an EDD-feasible subset of . □

Lemma 3.3

Given , we have 
⁎
, where 
⁎
 is a k-optimal subset of  and 
 is a -optimal subset of 
.

Proof

Let 
⁎
 be a k-optimal subset of  and let 
 be a -optimal subset of 
. From Lemma 3.1, there exists a k-optimal subset of , denoted by , such that 
. Let 
﹨
. By Lemma 3.2, 
 is an EDD-feasible subset of 
. Since 
 and 
, from the -optimality of 
, we have(3)
⁎

On the other hand, let 
. From Lemma 3.2, we see that  is an EDD-feasible subset of . Since  and 
, the k-optimality of 
⁎
 implies that(4)
⁎
 Combining (3) and (4), we deduce that 
⁎
, as required. □

Recall that 
 and the due date 
 of 
 is defined in (2) for . Let 
 be the  subsets of jobs generated by running Lin-Wang's algorithm on instance 
. We remark that if 
, then 
.

Lemma 3.4

For each , we have 
, where 
.

Proof

Since 
, the case when  holds trivially. Let i be the smallest index in  such that 
. Then  and 
. Let 
 be the jobs in 
 sequenced in SPT order, i.e., 
. Depending on whether 
, we distinguish the following two cases.

Case 1: 
. Then 
. Since 
, we have 
. By Observation 2.1(iii), we have 
. Since 
 is EDD-feasible, Lemma 3.2 implies that 
 is EDD-feasible for instance 
. Then Lin-Wang's algorithm should have put 
 into 
 to generate 
, i.e., 
, a contradiction. So Case 1 cannot occur.

Case 2: 
. Then 
 and 
. Moreover, since 
 is EDD-feasible for instance 
, by Lemma 3.2, we deduce that 
 is EDD-feasible. If there is no job 
 such that 
 is EDD-feasible and 
, then Lin-Wang's algorithm should have put 
 into 
 to generate 
, i.e., 
, contradicting the choice of i. So, such a job 
 must exist, and by Observation 2.1(iii) it is exactly the job 
, i.e., 
 and 
. Since 
 is EDD-feasible, it follows from Lemma 3.2 that 
 is EDD-feasible. Since 
, 
 should be dealt with before 
 when applying Lin-Wang's algorithm on instance 
 and hence we should have 
, contradicting the fact that 
. Hence, Case 2 cannot occur either.

In either case, we derive a contradiction and hence such an index i does not exist. Therefore, 
 for each . □

Lemma 3.5

The critical-subset list 
 of  is an optimal-subset list of , that is, for each , 
 is a k-optimal subset of .

Proof

Let us make some preparations for the proof of this lemma. Recall that 
 is the new instance as defined in (2). For each , let 
 be a k-optimal subset of . From Lemma 3.1, we may choose 
 such that 
 for . For each , let 
 be a -optimal subset of 
. From Lemma 3.3, we see that(5)
 Let 
 be the  subsets of jobs returned by running Lin-Wang's algorithm on instance 
 (possibly, 
). Moreover, we define 
 and set 
 to be the smallest index in  such that 
 for 
. Then 
 is the critical-subset list of 
. From Lemma 3.4, it is clear that 
 and 
﹨
. Recall that 
 is the smallest index such that 
 for . Then we have(6)

Let us now proceed to prove this lemma by induction on n. If , then the result holds trivially. Inductively, suppose  and the result holds for any instance with  jobs. Especially, the result holds for instance 
. Note that 
. Then 
 is clearly a 1-optimal subset of .

We show in the following that, for each , 
 is a k-optimal subset of . By the induction hypothesis, the critical-subset list 
 of 
 is an optimal-subset list of 
. Then 
 is a -optimal set of 
. This means that 
. From Equations (5) and (6), we have
 From the fact that 
 is an EDD-feasible subset of k jobs of , we conclude that 
 is a k-optimal subset of . The lemma follows. □

Theorem 3.1

The tradeoff problem 
⁎
 is solvable in  time.

Proof

For an instance , running Modified Algorithm, we obtain the n EDD-feasible subsets 
, which are identical to the n subsets returned by Lin-Wang's algorithm on . This procedure takes  time by Theorem 2.1. After this, we calculate 
, and for , determine the smallest index 
 such that 
. Since 
, the m indices 
, together with the m subsets 
, can be determined in  time. From Lemma 3.5, for each , 
 is a k-optimal subset of . Therefore, the tradeoff problem 
⁎
 can be solved in  time. □