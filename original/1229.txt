Abstract
Hardware security tokens have now been used for several decades to store cryptographic keys. When deployed, the security of the corresponding schemes fundamentally relies on the tamper-resistance of the tokens – a very strong assumption in practice. Moreover, even secure tokens, which are expensive and cumbersome, can often be subverted.

We introduce a new cryptographic primitive called Encryption schemes with Password-protected Assisted Decryption (EPAD schemes), in which a user's decryption key is shared between a user device (or token) on which no assumption is made, and an online server. The user shares a human-memorizable password with the server. To decrypt a ciphertext, the user launches, from a public computer, a distributed protocol with the device and the server, authenticating herself to the server with her password (unknown to the device); in such a way that her secret key is never reconstructed during the interaction. We propose a strong security model which guarantees that (1) for an efficient adversary to infer any information about a user's plaintexts, it must know her password and have corrupted her device (secrecy is guaranteed if only one of the two conditions is fulfilled), (2) the device and the server are unable to infer any information about the ciphertexts they help to decrypt (even though they could together reconstruct the secret key), and (3) the user is able to verify that the device and the server both performed the expected computations. These EPAD schemes are in the password-only model, meaning that the user is not required to remember a trusted public key, and her password remains safe even if she is led to interact with a wrong server and a malicious device.

We then give a practical pairixng-based EPAD scheme. Our construction is provably secure under standard computational assumptions, using non-interactive proof systems which can be efficiently instantiated in the standard security model, i.e., without relying on the random oracle heuristic.

Keywords
Cryptography
Public-key encryption
Password
Provable security

1. Introduction
Mobile devices are ubiquitous nowadays: smartphones and tablets have not only become prevalent in daily communication but also in numerous security-critical tasks. These devices collect and compile a large amount of confidential information to which access must be controlled. If such a device is infected by malware, an attacker may gain full access to the compromised device and be able to control it and steal any information stored on it. In addition to that, smartphones and tablets are easily lost or stolen even though they usually only use (human-memorizable) passwords to prevent unauthorized access.

Despite their practicality, the use of mobile devices to store sensitive data incurs various security issues (since they fail to protect sensitive information and passwords in particular): vulnerability to dictionary attacks (since passwords are weak-entropy secrets), re-use of passwords for multiple services, frequent leakage of password databases, and many more. A possible solution is to use a physical device that provides extra security. A hardware security module is a tamper-resistant device that strengthens encryption practices and is used in addition to or in place of passwords. These modules often come in the form of plug-in cards or external devices from which secret information cannot be easily leaked to anyone who gets hold of it. However, such modules are often costly, inconvenient to use and may even be subverted, i.e., corrupt from their very production. In this paper, we investigate how we can get rid of such tamper-resistant devices, and show how to rely on a smartphone (combined with a public computer) on which no hardware-security assumption is made. We thus use a device (such as a smartphone) as a token, meaning in particular that these two terms are used interchangeably in the following.

1.1. Encryption schemes with password-protected assisted decryption
In this work, we focus on encryption, and consider the problem of achieving security guarantees equivalent to those of hardware security modules without making any assumption on the device in possession of the user. Therefore, no assumption is made here on a user token, i.e., it is not presumed to be tamper-proof or malware-free. The token just acts as a virtual smart-card.

To mitigate this lack of security from the token, we introduce a server which assists the user with the decryption. In a real-world scenario, the user could log-in from a public computer, use her phone as a token, and communicate with a remote server to decrypt ciphertexts she receives. Concretely, the secret key of the user is shared between the token and the server, and a password is shared between the user and the server. Nevertheless, the introduction of a server should not weaken the security of the original scheme: an attacker should not be able to leverage the server alone to infer any information about the plaintexts of the user. Besides, introducing a token and a server should not jeopardize the privacy of a user: they should assist her in a blind manner, i.e., without being able to infer any information about the plaintexts they help decrypt. This property is later referred to as blindness.

We also require verifiability for the user. First, although the user is not required to remember the decryption key, she should still be able to verify that the token and server both correctly performed their computations with respect to the public key. As we do not want to require the user to remember the public encryption key, it is assumed that a public key is attached to the ciphertext. Since a different key than that attached may have been used to compute the ciphertext, the protocol should only guarantee verifiability with respect to the attached key, but should not leak any information about the passwords held by the user and the server.

The advantage of having the user enter her password on a public computer rather than directly on her token is twofold. First, if an adversary takes control of the token, without knowing the user's password it cannot decrypt her ciphertexts (assuming an appropriate throttling mechanism preventing online dictionary attacks). Secondly, if the computer from which the user starts a decryption query is corrupt (e.g., has a keylogger on it), her password is leaked, but as long as her token is not corrupt, no one can decrypt her ciphertexts. Hence separating the user algorithm and the token guarantees security if either the user password is not leaked or if the token is not corrupt.

1.2. Three levels of authentication
For the sake of clarity, consider the user is logging-in from a public (untrusted) computer, and interacts with an (insecure) token (such as her smartphone or tablet) and a remote server. She shares a password with the server, and her decryption key is shared between the token and the server. Recall that no assumption is made on the hardware security of the token, but that she types her password into the public computer. We now present the authentication required between these three parties involved in our protocol.

User–Token Authentication. Since the token would in practice be a smartphone or a tablet, a PIN is usually required to access them (in very few attempts), which is similar to having the user authenticate to the token. The user can then initiate the decryption protocol between the three entities, from the public computer, by logging-in to the server using her password. No secure channel between the user's machine and the token is assumed.

Similarly, no higher-level mechanism is assumed for the token to authenticate itself to the user. The user is supposed to recognize her token and have it at proximity. Nonetheless, if the scheme is verifiable and secure, the user is assured that even if she is led to interact with a malicious token, the result of the decryption protocol must be correct if it terminates, and that the protocol leaks no information about her password.

Token–Server Authentication. The token authenticates itself to the server using its share of the user decryption key. Having the token prove to the server that it belongs to the user prevents adversaries from taking advantage of the servers' throttling mechanism to block an honest-user account. Indeed, without this authentication an attacker could request decryptions on behalf of the user with an arbitrary token and make several password attempts until the server blocks her account. Even more damaging, the malicious token could also make queries to the server to infer information about the share of the server.

Likewise, the server must authenticate itself to the token using its own share of the decryption key. Otherwise, a malicious server without the user password could exploit the token to get information about it's share of the decryption key.

Server–User Authentication. In our model, the user need only remember her password. She must then be able to recover the address of the server sharing a decryption key with her token. A straightforward solution would be to retrieve this address from the token; but then a corrupt token may lure her into executing the decryption protocol with a malicious server via a phishing attack. The user may also simply mistype the address of the server. The server on which the user lands may even be certified within a PKI, but not one with which she shares a password, or one which shares the decryption key with the token. If this server is malicious, it could try to infer information about the user's password or the decryption key share held by the token.

Therefore, since the secret values (passwords or decryption-key shares) must be protected, the user and the server authenticate themselves to each other, and they do so via their common password. Note that this authentication must not leak any information on the password. In particular, it protects the user's password from an adversarial server which does not know her password, and it also preserves the confidentiality of her messages against an attacker which does not know her password and tries to exploit her server. These requirements are captured by our security definition.

A scheme satisfying all the aforementioned properties is called an Encryption scheme with Password-protected Decryption (EPAD) scheme.

1.2.1. Comparison with prior work
For cryptographic authentication, Camenisch, Lehmann, Neven and Samelin introduced [15] password-authenticated server-aided signatures (Pass2Sign). Their approach aims to offer comparable security guarantees to hardware security modules even when using a potentially corrupt device. To do so, they introduce a server which shares the secret key with the device. To compute a signature, the user starts a protocol with the server from her device, using a password to authenticate herself to the server. The secret key is never reconstructed during the protocol, so if the device is subsequently corrupted (assuming previously entered passwords have been erased), only a share of the secret key is lost and the attacker is unable to compute valid signatures. The device thus simply acts as a virtual smart card.

However, their work relies on two crucial assumptions: 1) the device is not corrupt at the moment the user enters her password, as an attacker would otherwise be able to impersonate the user and sign on her behalf and 2) the device securely erases previously typed passwords, since a corruption would directly leak them. Hence they do not completely achieve their ambitious goal of making no assumptions on the security of the device.

The scenario we consider (disregarding our new blindness property) is a hybrid of that of Pass2Sign (in which the user enters her password from the device) and of password-protected secret sharing [4], [14], [3], [30]. An important difference w.r.t. the latter is that the decryption key is never reconstructed, thereby protecting the user in case of corruption of her machine (i.e., the public computer from which she initiates the protocol). This property also allows the user to prevent further use of her device should it be stolen, by asking the server to block her account. This also hinders online dictionary attacks.

Moreover, interaction allows the server to enforce a throttling mechanism and refuse to decrypt if it detects suspicious behavior (e.g., several failed password attempts). From a commercial perspective, interaction also allows the server to run a paid service and charge the user for decryption requests.

Contrarily to the model of Pass2Sign, we do not assume that communication between the token and the server is a priori authenticated (via TLS for instance). Our security model ensures that interacting with a malicious party leaks no information about either the key shares or the passwords held by the user and the server. In our construction, the token and the server leverage the fact that they share the user's secret key to authenticate themselves to each other.

Finally, separating the public machine (on which the user types her password) and the token provides a strictly stronger security than that of password-authenticated server-aided signatures (for which a malware-infected token leaks both the user's password and secret-key share); while being no less convenient than technologies leveraging two-factor authentication mechanisms.

1.2.2. Contributions
The contributions of the paper are manifold.

Security Model. We first formalize the security properties required of an EPAD scheme. As explained above, an EPAD scheme enables a user to make decryption queries without revealing information about the ciphertexts being decrypted. This property was formalized by Green [26] (for classical public-key encryption (PKE) schemes) as blind decryption. To preserve user privacy, we propose a similar blindness property, the main difference being that there no longer is a centralized decryption entity as decryption is shared between the token and the server. Hence we require that neither the token nor the server should be able to infer any information about the ciphertexts the user wants to decrypt. The requirements of this property are strong, as it captures the scenario in which an adversary may have corrupted both the token and the server; and hence knows both shares of the decryption key, and the password. Our protocol achieves this strong notion of privacy by having the user perform some blinding step on the underlying plaintext (i.e., use a temporary high-entropy secret), and by randomizing the ciphertext before sending it to the token and the server for decryption. This implies that – to ensure user privacy – the scheme should tolerate some form of malleability.

Due to this mild form of malleability, which allows users to re-randomize their ciphertexts, the confidentiality notion considered for EPAD schemes is similar to Replayable Chosen-Ciphertext Attacks security (RCCA) defined by Canetti, Krawczyk and Nielsen for classical PKE [18]. Our notion is called Password-protected Indistinguishability under Replayable Chosen-Ciphertext Attacks (P-IND-RCCA) and takes into account the fact that decryption requests should be protected by user passwords. More precisely, it ensures that unless an adversary both knows the user's password (by corrupting the user's machine or the server) and has corrupted her token, it cannot infer any information about the user's plaintexts in reasonable time. It captures both indistinguishability under replayable chosen-ciphertext attacks and password authentication. The formal model for P-IND-RCCA security is inspired by the Bellare–Rogaway–Pointcheval (BPR) model for password-based authenticated-key-exchange protocols [7]. It covers the cases of concurrent protocol executions, with potentially many users, tokens and servers.

The third security notion in our model is verifiability which guarantees that the user accepts the result of the decryption protocol only if the token and the server performed their computations correctly.

As we target the most efficient solutions possible, these properties are captured via game-based security definitions rather than functionalities in the universal composability framework [16]; see Section 4.2.6 for an in-depth discussion.

Technical Challenges. The fact user passwords are not entered into the token may, at first sight, seem a simple solution to the problem in Pass2Sign, and thereby to achieve the level of security provided by secure hardware. However, it raises several challenges detailed hereafter. (1) The token – without knowing the password – must be able to ensure that the user and server have correctly authenticated themselves to each other, and that it shares its secret key with the server, before performing computations. Otherwise, an attacker which does not know the password or the other key share, could exploit the token and gain information about its share. (2) Throughout the entire protocol, the parties must ensure they are communicating with the expected party, and that they are not victims of man-in-the-middle attacks (recall that the communication is not assumed to be a priori authenticated). (3) Although the token terminates decryption, plaintexts must remain hidden from its view, even though the user and server only share a low-entropy secret. (4) The token must be convinced that the server correctly performed its computation, even without knowing the only piece of information shared between the user and the server (i.e., the password). (5) Finally, the protocol should guarantee user privacy despite the fact that together, the token and the server know all secrets.

Efficient and Secure Construction. We overcome these challenges and propose a concrete pairing-based EPAD scheme. It uses as a building block the publicly verifiable RCCA-secure encryption scheme of Faonio, Fiore, Herranz and Ràfols [24], though similar techniques can be applied to other such schemes (e.g., Libert, Peters and Qian's [36]). Section 4.2.1 gives further insight into the technicalities of our scheme.

The construction may at first seem complex as it uses several classical cryptographic primitives as building blocks, and one may wonder whether a general Multi-Party Computation (MPC) between the token and the server could solve the problem. The issue here is that the token – without any information on the user's password – would need to verify the password held by the server. Hence a practical solution with off-the-shelf MPC is not immediate. Besides, it is not clear how such a solution would guarantee blindness.

Finally, our construction is proven secure in the standard model; one may wonder whether it could be simplified in a stronger model such as the Random-Oracle Model (ROM). However since our techniques heavily rely on the malleability of zero-knowledge proofs, ROM-based proofs do not seem appropriate.

2. Preliminaries
This section introduces the notation used throughout the paper, as well as the building blocks on which the constructions herein are based.

2.1. General notation
The security parameter is denoted λ, and input lengths are always assumed to be bounded by some polynomial in λ. A Probabilistic algorithm is said to run in Polynomial Time (i.e., it is a PPT or efficient algorithm) if its running time is polynomial in λ.

Unless stated otherwise, p denotes a prime number. For a group  with neutral element 
, 
⁎
 stands for ﹨
. For an integer , 〚〛 denotes the set . Vectors and matrices are denoted in bold font, and vectors are by default column vectors. For a given matrix A, 
 stands for its transpose. For two matrices A and B of equal size,  denotes their Hadamard (i.e., element-wise) product. If A and B are vectors, then their Hadamard product is simply denoted .

Given an Oracle , the notation  means that  is its inner (secret) state, while ⋅ denotes the (adversarial) query.

Entropy is commonly used as a measure of password quality [33], [13], in this work the effort of guessing a password x sampled from some probability distribution  is measured by the min-entropy 
. Min-entropy describes the unpredictability of an outcome determined solely by the probability of the most likely result, and is appropriate for describing passwords and other non-uniform distributions of secrets.

2.2. Bilinear structures and SXDH assumption
An (asymmetric) bilinear structure is a tuple 
 where 
, 
 and 
 are p-order groups, and such that 
 is a pairing, i.e., an efficiently computable non-degenerate (
) bilinear map. Let 
 denote 
, which is a generator of 
. Type-3 bilinear structures are bilinear structures for which there is no known efficiently computable homomorphism from 
 to 
. A bilinear structure generator is an algorithm  which, on input 
, returns the description of a bilinear structure. For integers , given vectors 
 and 
,  denotes the matrix  
 
.

We now introduce the hardness assumption on which our construction relies.

Definition 1 SXDH assumption

The Symmetric eXternal Diffie–Hellman (SXDH) assumption over a bilinear structure generator  is that given , for 
, the Decisional Diffie–Hellman (DDH) assumption holds in both 
 and 
 with overwhelming probability. That is, no efficient adversary has a non-negligible advantage (in λ) in distinguishing 
 from 
, for , 
 and 
.

2.3. Signatures
We here introduce the syntax of digital signature schemes. See Appendix 5 for the definition of their strong one-time security and for specific instantiations.

Syntax & Correctness. A signature scheme consists of a setup algorithm 
, a key-generation algorithm , a signing algorithm  and a verification algorithm . The scheme is correct if  for all parameters and keys so generated, and all messages M.

2.4. Public-key encryption
This section introduces public-key encryption schemes, variants thereof and their security, as well as instantiations.

Syntax. A public-key encryption scheme consists of a setup algorithm 
, a key-generation algorithm  which returns a public encryption key and a secret decryption key, a probabilistic encryption algorithm  (the randomness r may at times be omitted from the syntax) and a deterministic decryption algorithm . An encryption scheme is labeled if the encryption and decryption algorithm additionally take as input a label or public data ℓ which is non-malleably attached to the ciphertext. In this case, the label is indicated on these algorithms by a superscript.

IND-PCA Security. INDistinguishability under Chosen Plaintext-Checkable Attacks [1] (IND-PCA) guarantees that an encryption scheme reveals no information about plaintexts even if an adversary can check whether ciphertexts encrypt messages of its choice. Abdalla, Benhamouda and Pointcheval [1] argued that this weakening of IND-CCA of security is enough for many password-related applications. In fact if the message space is small enough to enumerate all messages, it is equivalent to IND-CCA security. See Appendix 6.1 for a formal definition.

RCCA Security. Indistinguishability under Replayable Chosen-Ciphertext Attacks [18] (RCCA) is a relaxation of the classical CCA security tolerating a mild form of malleability. It allows for the re-randomization of ciphertexts while still providing strong security guarantees. See Appendix 6.1 for a formal definition.

Publicly Verifiable Encryption. A PKE scheme is verifiable if there exists a deterministic algorithm  such that no efficient adversary can, on the input of pk and with non-negligible probability, produce a ciphertext C such that  and .

Re-randomizable Encryption. A PKE scheme is re-randomizable if there exists an algorithm 
 which given a public key pk and a ciphertext C, outputs a new ciphertext 
. It returns ⊥ if any of its inputs are ill-formed.

Unlinkability. A re-randomizable encryption scheme is perfectly unlinkable [38], [19], [36] if the re-randomized valid ciphertexts have the same distribution as fresh encryptions of their underlying plaintexts.

Threshold Decryption. Threshold encryption schemes [20] are schemes in which decryption keys are shared between several parties. For a given ciphertext, each party can compute a decryption share with her key share, and a threshold number of those decryption shares is necessary to reconstruct the plaintext. If there are n parties, the security requirement of a t-out-of-n scheme is that no information about the plaintext can be inferred from less than  shares. In the RCCA variant of this security notion, during the second query phase (which targets a specific honest party), the challenger first decrypts the ciphertext of the query with the secret key it has generated, and checks whether it results in one of the challenge messages before answering with a decryption share if it is not the case.

2.5. Smooth projective hash functions
Smooth Projective Hash Functions (SPHFs) [21] are hash functions defined over a set , and which can be evaluated in two ways on a subset . An SPHF can be evaluated on  using a hashing key hk, which can be seen as a private key. On , it can also be evaluated with a projective key hp, which can be seen a public key, and a witness of membership to . We use the definition due to Gennaro and Lindell [25], in which projective keys depend on words in .

Syntax [9]. An SPHF over a language  is defined by five algorithms: 
 generates public parameters;  generates a hashing key for ;  derives a projective key hp from hk depending on a word ;  outputs hash value for any word , and  outputs a hash value on a word  given a projective key and a witness w for the membership of C. The public parameters are given as implicit input to all the other algorithms. When  is the language of ciphertexts of a given message for a certain scheme, the public parameters typically contain the encryption key, and may even include the decryption key to efficiently test language membership.

Correctness. An SPHF is said to be correct if for all  with witness w, for all 
, , , .

Adaptive Smoothness. An SPHF is smooth if its hash values on all  are statistically indistinguishable from uniformly random values. Katz and Vaikuntanathan introduced [32] SPHFs (KV-SPHFs) with word-independent projective keys, and for which smoothness holds even if the words depend on the projective keys. KV-SPHFs are the most flexible kind since the words on which they are evaluated can be chosen even after computing and publishing the projective keys. In this sense, they are adaptive.

A KV-SPHF is smooth if its hash values on all  are statistically indistinguishable from uniformly random values, even if C depends on projective keys. Formally, a KV-SPHF is ε-smooth [9] if, for any map  onto , the following two distributions are ε-close:
 A KV-SPHF is perfectly smooth if it is 0-smooth.

2.6. Key-derivation functions
A Key-Derivation Function (KDF) computes pseudorandom keys of appropriate length from a source key material which is not uniformly distributed, or which still has high entropy despite partial adversarial knowledge. The results can then be used as secret keys for cryptosystems.

Syntax. A key-derivation function [35] , takes as input a source key material SKM, an extractor-salt value XTS, some context information CTX and a length L, and returns an L-bit string K. See Appendix 9 for the formal security definition of KDFs.

2.7. Malleable non-interactive proofs
As the construction in Section 4 heavily relies on malleability and non-interactive zero-knowledge proofs, this section recalls the definition of proofs which are still sound under “controlled malleability”. These proofs allow to compute, from a proof π on a word x, a new proof 
 on a transformation 
 of x without the knowledge of a witness for 
, but only if the transformation belongs to a class of “allowed” transformations. The soundness of the proof system can then be defined w.r.t. this class of transformations. In addition to that, the soundness definition can even be extended to consider cases in which proofs are simulatable but remain sound under this controlled malleability.

Chase et al. [19] gave a definition of proof systems that are extractable under controlled malleability and a generic construction based on signatures and extractable proof systems. In App. 8.3, we give a similar definition which only requires soundness and then a generic construction from signatures and proof system that are only extractable in a sense defined therein. The reason is that the EPAD construction in Section 4 uses Groth–Sahai proofs from which group elements can be extracted but not exponents.

Syntax of Proof Systems. A non-interactive proof system for a language  (with corresponding relation ) consists of an algorithm 
 which returns a common reference string, an algorithm  which computes a proof on the input of a word x and of a witness w, and an algorithm  which returns a bit indicating whether the proof is considered valid. See App. 8.3 for definitions of the classical soundness and zero-knowledge properties.

Transformations. A transformation is an efficiently computable function 
. A relation  is said to be closed under T if for any , . Transformation T is then said to be admissible for . A class  of transformations is allowable for  if for every transformation , T is admissible for .

A non-interactive proof system for a relation  is malleable [19] w.r.t. a class  of allowable transformations for  if there exists an algorithm 
 (word x may further be omitted from the syntax) which compute a proof 
 for 
 from a valid proof π for x, without the knowledge of 
.

2.7.1. Groth–Sahai proofs
Groth and Sahai [28] (GS) built an efficient proof system for a large class of equations in bilinear groups. It actually allows to extract witness group elements (but not exponents). Their proofs are re-randomizable and malleable w.r.t. additive transformations. The proof system is recalled in Appendix 8.3. Using a structure-preserving signature scheme, one can apply the generic construction in Sec. 8.1 to the GS proof system to obtain a zero-knowledge proof system which is CM simulation sound w.r.t. additive transformations.

3. Model
This section introduces Encryption schemes with Password-protected Assisted Decryption (EPAD schemes). As mentioned in the introduction, an EPAD scheme is an encryption scheme which involves three parties, a user , a token  and a server . The user , sharing a password with a server , is logging-in from a computer, and her decryption key is shared between the token  and the server . The protocol allows the user to decrypt ciphertexts with the help of the token  and the server , granted that each authentication between the three parties (based on the private values mentioned above) succeeds.

Informally, the security notions required for such a scheme are as follows. First, the P-IND-RCCA property captures both the indistinguishability of the encryption scheme and password authentication. It ensures that the adversary cannot recover any information on the plaintext without knowing the password of the user and having access to the token, and that the decryption can only succeed if the user and the server share the same password. Then, the blindness property implies that neither the token nor the server can recover any information on the ciphertext the user wants to decrypt on their own. Finally, the verifiability property ensures that the user is convinced the decryption has been correctly done.

3.1. Syntax
In a three-party setting with a user , a token  and a server , an EPAD scheme consists of the following algorithms.

:
generates public parameters on input a security parameter. These parameters are implicit inputs to all the other algorithms.

:
generates a public key, a secret key and shares thereof.

:
a probabilistic encryption algorithm.

:
a deterministic decryption algorithm, an interactive decryption protocol between a user algorithm with input a public key, a user password and a ciphertext; a token algorithm with input a secret-key share; and a server algorithm with input a secret-key share and a server password. The passwords are here treated as bit strings.

Correctness. An EPAD scheme is correct if the decryption of an encrypted plaintext, whether by the deterministic decryption algorithm or by the interactive protocol with 
, results in the plaintext. That is, for all , all M and all 
.
3.2. Security definitions
This section formalizes the security properties expected from EPAD schemes. These properties are Password-protected Indistinguishability under Replayable Chosen-Ciphertext Attacks (P-IND-RCCA), blindness and verifiability.

3.2.1. P-IND-RCCA security
Password-protected Indistinguishability under Replayable Chosen-Ciphertext Attacks (P-IND-RCCA) ensures that no efficient adversary can infer any information about a user's plaintext as long as it does not know her password (by corrupting the user's machine or the server) or does not have access to her token. It captures both indistinguishability under replayable chosen-ciphertext attacks and password authentication. The latter means that decryption can only succeed if the user and the server have the same password.

The formal model for P-IND-RCCA security is inspired by the Bellare–Rogaway–Pointcheval (BPR) model for password-based authenticated-key-exchange protocols [7]. It covers the cases of concurrent protocol executions, with potentially many users, tokens and servers. In addition to that, a user may possess several tokens and could be registered on several servers.

Game Overview. The P-IND-RCCA security experiment features an adversary . After an initial parameter generation phase,  can request that the challenger generates keys and passwords for the users. The passwords are generated via a password generator  that returns values in some dictionary D. The min-entropy of the output distribution of  is denoted 
.

Next,  is given access to several oracles modeling different types of attacks (password-related or chosen-ciphertext attacks); and to a test oracle which can be called at any time, but only once (a definition with several test queries would be equivalent). On input two messages and a user identity chosen by , this test oracle randomly chooses one of the messages, and returns an encryption of this message under the user's public key. If  guesses which message was encrypted, it is considered successful. An EPAD scheme is then said to be P-IND-RCCA secure if no efficient adversary can win the game with probability significantly greater than , where ϵ is the maximum advantage one can gain from trivial online dictionary attacks (i.e., guessing passwords should be the only possible attacks).

Initialization & Game Variables. A set of users U is assumed to be fixed. For every , the set of tokens belonging to  is denoted by , and the set of servers with which  shares a password is denoted . The set of all tokens is denoted T and the set of all servers S.

During the initialization phase, public parameters for the encryption scheme are generated. Secret-key shares for all tokens and servers are set to ⊥. Further on, for , 
 denotes the set of all user key-shares for id.

A finite instance set I for all party algorithms is also assumed to be fixed. Each instance  of the algorithm of party id maintains a state 
. A session identifier 
, and partner identities 
 and 
 allow to match instances in protocol executions.

A variable 
 indicates whether an active attack has been performed on the ith instance of the algorithm of party id.

Variables 
 and 
 respectively indicate whether the ith algorithm instance of party id has accepted and terminated. As in the BPR model, acceptance and termination are distinguished. When an instance terminates, it does not output any further message. Nevertheless, it can accept at a certain point of its computation but terminate later. This may occur when an instance confirms its partners, in which case it accepts, and thereafter continues the computation until termination.

A queue 
 of added users, i.e., users for which keys and passwords have been generated, and a queue of corrupt users 
 are also initialized.

At the end of the initialization phase, the encryption parameters, the sets of participants and the user public keys are returned in a public input pin, and the rest is set in a secret input sin. That is, 
 and 
. The secret input sin is later made available to all oracles.

Oracles. Throughout the experiment,  is given access to the oracles detailed below which it can query in any order.

–
: returns the encryption with a user public key of one of two messages, all chosen by the adversary. The challenge user identity 
⁎
 is not required to be honest (i.e., the adversary may know her password), but the challenge token 
⁎
 and challenge server 
⁎
 cannot both be corrupt, otherwise the adversary would be able to reconstruct her secret key and trivially win the game. The public key 
⁎
 is the one for which 
⁎
 and 
⁎
 hold secret-key shares. For simplicity, the adversary may query this oracle at most once. Note also that as in the BPR model [7] and the model for distributed session key [8], this query is not restricted to be the last query of the adversary.

–
: adds an honest user identity. In addition to a user identity , the adversary specifies a set  of tokens and a set  of servers for . Note that these can be corrupt, except for the challenge identities 
⁎
, 
⁎
, 
⁎
: parties 
⁎
 and 
⁎
 cannot both be corrupt (see the definition of oracle ). For each server in , a password 
 and a transformation 
 thereof is generated by the password generator . Keys and secret-key shares for all token–server pairs of the user are also generated.

–
: returns the transcript of an honest (i.e., without the interference of the adversary) decryption-protocol execution on a ciphertext C. Note that  queries thereby model offline dictionary attacks among others. The execution is between the ith, jth and kth instances the algorithms of a user , a token  and a server . The notation 
, 
 and 
 mean that algorithms ,  and  are respectively run with the states 
, 
 and 
. If 
 is one of the challenge messages (with 
 the secret key for which  and  hold shares), the oracle returns a special string  as in the classical definition of RCCA security (see Sec. 2.4). The parties may be corrupt (in which case  has their states), but 
⁎
 and 
⁎
 cannot both be corrupt.

–
: the adversary can perform active attacks via this oracle. The adversary can send a message to an algorithm instance (e.g., the kth instance of a server algorithm), all of its choice. The notation  respectively stands for ,  or  if , T or S. This algorithm then runs the instance on that message. To prompt the ith instance of the algorithm of a user  to initiate a protocol execution on a ciphertext C with the jth instance of a token  and the kth instance of a server , the adversary can query oracle  on . If such a query decrypt to either of the challenge messages, the oracle returns  to prevent trivial wins.

In addition to an output message 
, the algorithm also returns to  acceptance and termination states acc and 
, a session identifier sid and partner instances 
 and 
, and a state 
. Identity 
 is always assumed to be the party which should receive the next flow of id, i.e., a token identity if , a server identity if  and a token identity if . Variables 
, 
 and 
 and 
 are updated in case the instance accepts, and all values are revealed to the adversary except the state (which may contain a password or a secret-key share).  can access this state by corrupting party id.

If  knows the password of the challenge user 
⁎
, by corrupting either that identity or 
⁎
, then queries to 
⁎
 are rejected. It translates the fact that in case of a server breach or if there is a keylogger on the user's machine, then no security can be expected if an attacker also has access to her token.

Likewise, if 
⁎
 is corrupt as well as 
⁎
, queries to 
⁎
 are rejected. It reflects the fact that if a user's token is corrupt, no security can be expected if her password is also leaked. Indeed, in that case, an attacker can use the server which shares a key with the token in order to decrypt the ciphertexts.

–
: gives the adversary control over all the instances of a party algorithm. In the case of a user, the adversary not only receives her passwords and the states of all her algorithm instances, but may also overwrite the password held by each of her servers. If the party being corrupted is a token or a server, the adversary receives the states of all of its algorithm instances and also its key shares. Once a  query has been made with an identity 
⁎
, the corruption of both 
⁎
 and 
⁎
 is not allowed. That is to prevent the adversary from reconstructing her secret key and trivially win the game.

Only static corruptions are here considered, i.e., the adversary cannot corrupt a party of which an algorithm instance is in the middle of a protocol execution. It is expressed by the condition “
”.

Definition 2 P-IND-RCCA

An EPAD scheme is P-IND-RCCA secure if for all , for every efficient adversary ,
 
 is negligibly close to 
.

The term 
 accounts for online dictionary attacks. An EPAD scheme should guarantee that these are the best attacks possible.

Remark 1 On one-round protocols

There cannot exist a one-round protocol secure against offline dictionary attacks.1 To understand why, note that the server must be able to explicitly check the user's password before attempting to decrypt. The server cannot just return a value that allows the user to decrypt in case she shares the same password, as an adversary could otherwise compute a ciphertext with a user's public key, and then make several decryption requests for it with a different password each time – since no check on the password is done server-side, no throttling mechanism can be implemented, and the server will always reply. The adversary can then check which request succeeds, thus effectively mounting a dictionary attack (online) on the user's password.

Given that observation (i.e., that a server must always explicitly check a user's password), if a one-round protocol existed, an adversary could intercept the transcript of an honest execution of the decryption protocol. In that execution, the user would have had to send sufficient information for the server to verify her password, without having received any prior indication that the server shares this password. It means that an adversary (which does not know user password) could compute a ciphertext with a public-key for which it knows the private key, send the ciphertext to the user and then perform an offline dictionary attack with the information sent by the user. Therefore, a protocol secure against offline dictionary attacks must consist of at least two rounds. It is not surprising as the user, who initiates the protocol, should verify the server holds the same password as she does.2

3.2.2. Blindness
This property formalizes the idea that neither the token nor the server should be able to infer any information about the ciphertexts the user wants to decrypt. This is analogous to Green's notion of blindness [26] except that in his work, the decryptor is a centralized entity, whereas the decryption process is here shared between the token and the server.

In the formal definition, the challenge ciphertexts 
 and 
 must be either both valid or both invalid, i.e., 
 should hold, which is a minimal condition to exclude trivial wins. Besides, the definition might at first seem too strict as the token and server are therein corrupt and can together reconstruct the full secret key and the password. However, the definition can in practice be achieved by letting the user rerandomize her ciphertexts and blind the underlying plaintexts with temporary high-entropy secrets before sending the ciphertext to the token and the server.

Definition 3 Blindness

An EPAD scheme satisfies blindness if for all , for every efficient adversary ,
⁎
 
 is negligibly close to 1/2.

3.2.3. Verifiability
This property captures the idea that the user should accept the result of the decryption protocol only if the token and the server have correctly performed their computations. If they did not, the user should detect this is the case, and abort, returning the error symbol ⊥.

Definition 4 Verifiability

An EPAD scheme is verifiable if for all , for every efficient adversary ,
 

4. Construction
In this section, we build an EPAD scheme from the RCCA-secure encryption scheme of Faonio, Fiore, Herranz and Ràfols [24] (see App. 6.3). Similar techniques can a priori be applied to any publicly verifiable, structure-preserving RCCA-secure scheme. The public-verifiability aspect is to easily make the scheme threshold while maintaining the security of the original scheme.

The section starts by showing how users can blind the plaintexts underlying the ciphertexts they want to decrypt. It then continues with the main construction and its efficiency assessment.

4.1. Verification of blinded ciphertexts
As mentioned in Sec. 3.2.2, EPAD schemes should satisfy blindness, meaning that even if the token and the server are corrupt, they cannot infer any information about the ciphertexts they are helping a user to decrypt. It is a stringent requirement as a corrupt token and server can reconstruct the secret key, and if the server is actually one associated to the user, it also has her password. Thus given a ciphertext, the user must be able to blind the underlying plaintext using only public information.

On the other hand, EPAD schemes also aim for an RCCA type of security, so the only type of malleability that should be expected is re-randomization. Therefore, the user cannot a priori blind the plaintext and produce a new valid ciphertext (except with negligible probability) since she does not remember her secret key. Nonetheless, she can provide enough information auxiliary to the modified ciphertext which allows the token and the server to verify, with their secret key shares, that she correctly blinded the underlying plaintext of a valid ciphertext, and that she knows the blinding factor.

We thus introduce a new algorithm 
 which, given a public key and a ciphertext of the scheme of Faonio et al., essentially adds a one-time pad to the plaintext and gives a Groth–Sahai proof of knowledge of the pad in some auxiliary information. The new ciphertext can then be verified by another algorithm 
 on the input of a secret-key share and of the auxiliary information. Similar techniques can a priori be applied to other publicly-verifiable schemes. Algorithms  and  are formally defined in App. 6.3.2.

4.2. Construction
This section presents our main construction which is further denoted . Recall from Sec. 3 that a secure scheme must be at least two rounds. Our protocol, which consists of two rounds, is therefore round optimal.

Building Blocks. The construction uses as building blocks

–
the RCCA-secure encryption scheme of Faonio et al. (App. 6.3) denoted 

–
the short Cramer–Shoup encryption scheme in 
 (App. 6.2) with hash-function family 
 to encrypt passwords. It is further denoted 

–
Groth's one-time signature scheme (see App. 5.1), further denoted , with hash-function family 

–
the KV-SPHF for short Cramer–Shoup ciphertexts (App. 7.2)

–
a (single-keyed) Hash-based Message Authentication Code [6] (HMAC), further denoted , with 
 as family of compression functions (SHA-256 in practice)

–
Krawczyk's KDF (App. 9) denoted  with

⁎
for the extraction phase, HMAC based on a family 
 of Merkle–Damgård hash functions with 
 as underlying family of compression functions (SHA-512 in practice), and

⁎
for the expansion phase, HMAC with 
 as family of compression functions (SHA-256 in practice)

–
the SXDH-based simulation-sound Groth–Sahai proof system (App. 8.3) which is controllably malleable w.r.t. additive transformations in 
 and satisfies strong derivation privacy (App. 8.2), and which uses Jutla and Roy's scheme (further denoted ) as underlying signature scheme (App. 5.2). The proof system is further denoted .

4.2.1. Construction overview
The main steps of the scheme are depicted on Fig. 1. The high-level description follows (for notations and details, see the appendices cited in the building blocks above).

Setup & Key Generation.
The parameters include parameters for the scheme of Faonio et al., for the SPHF for Elgamal ciphertexts, and for the simulation-sound GS proof system.

Encryption & Decryption Algorithms.
These are the same as the ones of the scheme of Faonio et al.

Interactive Decryption.
During the interactive decryption protocol , the parties proceed as follows.

–
At the beginning of the protocol, the user and the server essentially do a one-round Password-Authenticated Key Exchange (PAKE) with short Cramer–Shoup encryption of their passwords and KV-SPHF evaluations on them; following techniques of Benhamouda et al. [9]. The underlying idea is to enable each party to implicitly check via the projective keys that the ciphertext of the other party encrypts the same password as hers (see Sec. 2.5).

The encrypted passwords are bound to the ongoing session via the projective keys sent during the PAKE and used as labels for the encrypted passwords. It prevents replay attacks since the corresponding hashing keys are needed to recover the PAKE key.

The key obtained later serves two purposes. It is first used as key material for a KDF of which the output is used to authenticate the respective next flows of the server and then the user, thereby making sure that the other party holds the same password. Its second use is to mask the partial decryption of the server so that only a party who has the same password as the server can later remove it and retrieve the plaintext.

In parallel, the token and the server verify that the other party knows a share of the secret key, and the user checks that the token and the server can together reconstruct the secret key. The user therefore makes sure that the server knows both a secret-key share, and her password if their PAKE outputs are the same (which she ascertains with the MAC).

Note that, to bind its proof to the ongoing session, the token also signs the proof (and the input from the user) with a one-time scheme. The verification key is used as label for an encryption (with a key different from the one used to encrypt the passwords) of the partial user public key relative to the token share. As only the server can also compute the partial user public key of the token, it can check (given the decryption key) that the token is the party who computed the ciphertext, and that the one-time verification key was not altered.

On the other hand, the server need not do the same as no computation involving the token share is done before the server must prove knowledge of the hashing key corresponding to the projective key sent in the first round. As the projective key is authenticated together with the server proof via the MAC, and as the smoothness of the SPHF guarantees that the hashing key can be recovered with only negligible probability, the server proof is also bound to the ongoing session.

–
After the PAKE, the user re-randomizes her ciphertext and blinds the underlying plaintext (as in Sec. 4.1) so that even if the token and the server are corrupt, they cannot infer any information about the ciphertext they help her decrypt. She also authenticates the blinded, re-randomized ciphertext with a key derived with the KDF from the PAKE key as key material. She then sends the ciphertext and the tag to the token.

–
The token verifies that the user correctly blinded the plaintext of a valid ciphertext, and that she knows the blinding factor, before forwarding to the server what it just received. This verification could actually be done in parallel of the server computation, but before partially decrypting the ciphertext. It is to make sure that no attacker can obtain partial decryption from the token on invalid ciphertexts and possibly infer information about its share.

–
The server verifies the authenticity of the flow via the MAC and then performs the same verifications as the token. If they succeed, it partially decrypts the ciphertext and masks it with the PAKE key. The server then sends the partially decrypted (and masked) ciphertext to the token, along with a proof that she decrypted the ciphertext with the key share of which she proved knowledge in the first round (i.e., verification is done w.r.t. the GS commitment to that share and which was sent in the first round), and that it masked the result with the PAKE key from the first round. Although the token does not know the password shared by the user and the token, it is convinced that the mask is really the PAKE key from the first round. That is because the token verifies the server proof w.r.t. the encrypted passwords and the projective keys that were sent in the first round, and this is absolutely crucial to prevent man-in-the-middle attacks between the token and the server.

–
After verifying the proof, the token finishes the decryption and uses the malleability of GS proofs w.r.t. additive transformations to compute, from the server proof, a proof that it and the server both correctly performed their computations. It then sends the decrypted, though blinded (by the user) and masked, plaintext and the proof of correct computation.

–
The user verifies the proof, and if it is correct, removes her blinding factor, removes the mask with the PAKE key and can then recover the plaintext.

In the P-IND-RCCA security proof, soundness must be guaranteed even after giving the adversary simulated proofs, which is why the GS proof system must be CM simulation sound w.r.t. additive transformations (see Section 8.1). It is due to the fact that secret keys are kept across different sessions.
Fig. 1
Download : Download high-res image (321KB)
Download : Download full-size image
Fig. 1. Construction Overview.

4.2.2. Formal description
The decryption protocol is given on Fig. 1. Each message sent is assumed to be prepended with a session identifier and the identities of the two partner instances. It is assumed that an algorithm aborts if it receives an ill-formed message or if a verification fails, and that it erases all its temporary variables (which include its randomness) once it terminates. The proofs from the token and the server are outlined below.

Notation. Let 
 be an injection, namely the bit representation of 
 elements. Integers in  are identified with their binary representations in 
. For three integers , j and k, whenever computational costs in a bilinear structure are considered, 
 denotes a j-exponentiation in 
 and 
 denotes the computation of product k pairing values. As for communication costs, 
 denotes j elements in 
 and 
 denotes j elements in 
.

In the following  is a Simulation-Sound Groth Sahai proof system with two main algorithms, a  algorithm that generates valid proofs for a statement with respect to the secret used, and  that checks if a proof is valid with respect to a statement. An extra algorithm  allows to further refine a proof by using extra witnesses.

 is a one time signature, with a  key generation algorithm, a  signing algorithm, and a verification  algorithm checking the consistency of the signature with respect to it's public key.

 is a plaintext checkable encryption scheme, while 
 is a randomizable CCA encryption scheme allowing access to extra algorithms: a randomization  algorithm, and  that respectively allow to blind the payload in a ciphertext, and to check consistency to know whether the decryption algorithm will return a value different from ⊥.

 are the 4 algorithms constituting an SPHF, to generate keys to allow to implicitly prove the validity of a statement with respect to a given witness.

Parameters. Given two families 
 and 
 of hash functions from 
⁎
 to 
, to generate public parameters,

–
generate a bilinear structure 
. Let 
 be the bit length of p

–
select 
 and 

–
generate a salt value 
 for the KDF

–
generate keys for the short Cramer–Shoup encryption scheme in 
, i.e.,

Decryption key 

Encryption key 

–
generate parameters for 
, i.e., GS parameters 
; 
 in soundness mode

–
generate parameters for , i.e., GS parameters 
; 
 in soundness mode and a pair of keys 

–
return 
.

Passwords. Passwords are elements of 
; 
 is not a valid password.

Key Generation. To generate keys for , run 
. The secret-key shares 
, are such that 
 and 
 for . Generate also another pair 
. Note that 
 is of the form 
 
. The token is given 
, and the server 
. The whole token share (cf. the syntax of Sec. 3) is then 
 and the whole server share is 
.

Acceptance and Termination. The  instance accepts after verifying tag 
, and terminates after returning M. The  instance accepts after receiving 
, and terminates after sending 
 and 
 to the user. The  instance accepts after verifying 
, and terminates after sending 
 and 
 to the token.

First Proofs 
 from the Token. In the first round, the token proves with  to the server that it knows the other share of the user secret key. Proof 
 then consists of 20 
 element, 26 
 elements and 2 
 elements, and verifying it costs 
.

First Proofs 
 from the Server. Leveraging the malleability of , the server computes a proof of knowledge of the complete user secret key.

Second Proof 
 from the Server. After the server partially decrypts the ciphertext and masks the result with an SPH, it proves that it correctly performed its computation. In particular, the server proves that secret-key shares it used to partially decrypt are the ones to which it committed in the first round. It also proves that the password it encrypted in the first round is the same that is used to computed the SPH mask.

Equations. Let 
. The server must prove knowledge of 
, 
 and 
 such that

With , proof 
 consists of 38 
 elements, 42 
 elements and 2 
 elements. Verifying it costs 
. Note that the token verifies w.r.t. to the commitments 
 it infers from the first proof 
 and its secret-key share.

Second Proof 
 from the Token. Upon receiving 
 from the server, the token decryption algorithm first verifies it. If 
 is correct, the token algorithm uses the malleability of GS proofs to compute a proof that decryption was done with the full secret key of which knowledge was proved in the first round.

4.2.3. Correctness & security
The scheme  is correct. In Theorem 1, we demonstrate that, assuming the SXDH assumption over  holds, that  is secure, that 
 is second-preimage resistant and that 
 is collision-resistant,  is P-IND-RCCA secure. Then in Theorem 2, we prove that  satisfies blindness under the SXDH assumption over . Finally, in Theorem 3, we show that  is verifiable if  is secure and if the SXDH assumption over  holds.

Theorem 1 P-IND-RCCA

Assuming that the SXDH assumption over  holds, that  is secure, that 
 is second-preimage resistant and that 
 is collision-resistant,  is P-IND-RCCA secure.

Proof Outline. The proof strategy consists in defining a sequence of indistinguishable games that gradually calls on the security of each underlying primitive. The adversary cannot modify the messages computed by honest parties within a session at the end of the game sequence, unless it knows their passwords in the case of user and server identities. The messages computed by honest parties are also independent of the passwords which can only be guessed with probability at most 
. The security of the last game is eventually reduced to the 1-out-of-2 IND-RCCA security of 
 (recall that  and  cannot both be corrupt).

Note however, that the security of the primitives does not exclude the possibility that the adversary encrypts in 
 a token key share for which it computes a valid proof 
, even though:

1.
the token and server are honest,

2.
the adversary is only given zero-knowledge proofs throughout the game, and

3.
the smooth projective hashes computed by the server also convey no information about the key shares.

The proof thus branches in two cases depending on whether this attack is excluded or not. The proof proceeds as explained above in the first case, whereas the simulation soundness of  is instead leveraged to reduce to the 1-out-of-2 IND-RCCA security of 
 in the second case. Intuitively, that is because the simulation soundness of  guarantees that if 
 is valid, then the adversary must have computed on its own sufficient information about the key shares to break the security of 
.
Formal Proof. Let  be an adversary for the P-IND-RCCA game which makes at most 
  queries and at most 
  queries. A message is subsequently said to be oracle-generated if it was computed by the challenger as a response to a  query and it was not altered. Otherwise, the message is said to be adversarially generated. If an adversarially generated message is given as an input to an algorithm which simply forwards it (possibly after some verifications), the message is still considered adversarially generated. Recall that only static corruptions are considered. However,  can of course modify the messages sent between the parties. Recall also that all instances are assumed to erase their temporary variables (which include their randomness) upon termination.

Further distinguish the following cases:

1.
 never makes a  query to an  instance on a valid tuple (i.e., which passes all verification) 
 such that 
 is oracle-generated but 
 is adversarially generated, although  and  are honest.

2.
 makes a  query of the above form.

In the first case, the main idea is to define a game which is indistinguishable from the real one, but in which the adversary cannot modify the messages computed by honest parties within a session, unless it knows their passwords in the case of user and server identities. Moreover, the oracle-generated messages in this latter game are independent of the passwords, so as long as a user and one of her servers are honest,  can only guess their common password, and it can only do so with probability at most 
. Winning the 1-out-of-2 IND-RCCA security of 
 can then be reduced to winning that game.
To this end, consider the sequence of games hereafter. It starts by modifying how  queries are handled, and then continues with  queries.

Game 0.
This is the real P-IND-RCCA game.

Game 1.
In this game, the challenger generates trapdoor  parameters, i.e., a signing key sk which allows to simulate proofs, as well as the discrete-logarithm relations between 
 and 
, and between 
 and 
, which allow to extract committed group elements. As the resulting parameters are perfectly indistinguishable from honest parameters, Game 1 and Game 0 are perfectly indistinguishable.

Game 2.
To answer  queries with identities ,  and , the challenger simulates 
 and 
. Note that since  satisfies perfect strong derivation privacy, proofs in the previous game (leveraging its malleability) are perfectly indistinguishable from proofs computed with the full secret key. By the zero-knowledge property of , these latter are indistinguishable from simulates proofs of the full secret key.

The zero-knowledge property of  implies that  can distinguish this game from the previous one with an advantage of at most 
, with the latter denoting the supremal advantage of any PPT adversary in distinguishing real proofs from simulated ones.

Note that even if  is corrupt at the beginning of the protocol and  thus knows the witness of the proofs, it still cannot distinguish real proofs from simulated ones since  is zero-knowledge. Moreover, as temporary variables of the token algorithm instance are erased upon termination,  cannot distinguish real proofs from simulated ones by corrupting  after the execution either.

Game 3.
To answer  queries with identities ,  and , the challenger computes 
. Game 3 from Game 2 are perfectly indistinguishable by correctness of the SPHF.

Game 4.
To answer  queries with identities ,  and , the challenger now computes 
 as 
 and 
 as 
 (recall that 
 is assumed not to be a valid password).

The indistinguishability of Game 4 from Game 3 stems from the IND-CPA security (implied by the IND-PCA security) of 
 which relies on the SXDH assumption. The distinguishing advantage of  is at most 
, with 
 denoting the supremal advantage of any efficient adversary in the IND-CPA game with scheme 
.

Game 5.
The challenger now answers  queries with identities ,  and  by choosing 
 uniformly at random. This game is perfectly indistinguishable from the previous one by the smoothness property of the SPHF.

Game 6.
In this game, the challenger also saves the short-Cramer–Shoup decryption key dk. Game 6 is perfectly indistinguishable from Game 5.

Game 7.
To answer  queries to an  instance on 
 and on 
, the challenger simulates 
 and 
. The challenger also simulates 
 and 
 to answer queries to  instances. The same arguments as in Game 2 imply that  can distinguish Game 7 from Game 6 with an advantage of at most 
.

Game 8.
The challenger now answers  queries on 
 to an  instance as follows:

–
if 
 or 
 or 
, return ⊥

–
if 
 is oracle-generated and the tuple of the  query also is, compute 
 (the challenger knows 
 since 
 is honestly generated). In this case, this game is perfectly indistinguishable from the previous one by the correctness of the SPHF

–
if 
 and 
 are oracle-generated (i.e., ⁎⁎
⁎ was computed as an answer to a  query) but the tuple is adversarially generated, if  is honest, abort as  contradicted the strong one-time security of . If  is corrupt, then reply with ⊥ if  is corrupt; if  is honest, compute 
.

Denoting by 
 the supremal advantage of any efficient adversary in the strong one-time security game,  can distinguish this game from the previous one with an advantage of at most 
 (the reduction algorithm must guess the  instance for which it sets the one-time signing key as that of the challenger)

–
if 
 is oracle-generated but 
 is adversarially generated,

⁎
if  is corrupt then

∘
if 
⁎
⁎
⁎
 and 
⁎
 is corrupt, reply with ⊥ thereby following the definition of oracle 

∘
else, compute 

⁎
if  is honest, then  is necessarily corrupt as 
 is oracle-generated and 
 is adversarially generated (cf. conditions of case 1). Compute 
 as in the real game

–
if 
 is adversarially generated and  and  are honest, check whether 
. If so, i.e.,  correctly guessed 
, abort and return 1 indicating that  won the game (which increases the advantage of  in this game). If not, generate 
 uniformly at random, and the perfect smoothness of the SPHF implies the perfect indistinguishability from the previous game

–
if 
 is adversarially generated and  or  is corrupt,

⁎
if 
⁎
⁎
⁎
 and 
⁎
 is corrupt, return ⊥. By definition of oracle , Game 8 is perfectly indistinguishable from Game 7

⁎
if  is honest, compute 
 as in the real game.

The advantage of  in the previous game is therefore upper-bounded by its advantage in Game 8 plus 
.

Game 9.
The challenger now answers  on 
 to a  instance as follows:

–
if 
, return ⊥

–
if 
 is oracle-generated, compute
 (the challenger knows 
 as 
 is honestly generated). In this case, Game 9 is perfectly indistinguishable from Game 8 by the correctness of the SPHF

–
if 
 is adversarially generated and  and  are honest, check whether 
. If so (i.e.,  correctly guessed 
), abort and return 1. If not, choose 
 uniformly at random, and the perfect smoothness of the SPHF implies the perfect indistinguishability from the previous game

–
if the tuple is adversarially generated and  or  is corrupt, compute 
 as in the real game.

The advantage of  in the previous game is thus upper-bounded by its advantage in this game.

From this game onwards, the randomness used to encrypt passwords is necessary to compute neither 
 nor 
 in case  and  are honest.

Game 10.
In this game, the challenger answers  queries to

–
an  instance on tuples 
 such that 
 is oracle-generated, and which are oracle-generated if  is honest, by generating 
 in case  is honest

–
a  instance on oracle-generated tuples 
 by setting 
, the latter being the value of the partner  instance of the  in the current session

A lemma by Katz and Vaikuntanathan [32, Lemma 1] states that SPH values are computationally indistinguishable from uniformly random group elements even if hashing keys and ciphertexts are used several times and if projective keys made public, under the assumption that the encryption scheme is IND-PCA secure (they actually prove it in the case of IND-CCA security, but the application of the lemma only makes use of plaintext-check queries) and that the SPHF is statistically smooth. The lemma then entails that  can distinguish Game 10 from Game 9 with an advantage of at most 
, with 
 denoting the supremal advantage of any efficient adversary which makes at most 
 plaintext-check queries in the IND-PCA game with scheme 
.

Game 11.
For prompting queries ⁎⁎⁎ to a  instance and  queries to an  instance on oracle-generated tuples 
 such that 
 is also oracle-generated, if  and  are honest, the challenger computes 
 as 
 and 
 as 
. Distinguishing Game 11 from Game 10 can then be reduced to winning the IND-PCA game for 
.

Note that for any  query on 
 to an  instance, if the tuple is oracle-generated and 
 also is, the reduction algorithm already knows the password encrypted in 
 and can then do the same test as the challenger of Game 8. Similarly for  queries on tuples 
 to  instances. In case 
 or 
 is adversarially generated, the reduction can make a plaintext-check queries.

It follows that  can distinguish Game 11 from Game 10 with an advantage at most 
. Note also that from this game on, the messages computed by instances of  and  are independent of the passwords if they are both honest,  can then guess their common password with probability at most 
 at each  query.

Game 12.
For  queries to an  instance on tuples 
 such that 
 is oracle-generated, and which are oracle-generated if  is honest, the challenger generates 
 uniformly at random in case  is honest. For a  query to a partner  instance on an oracle-generated tuple 
, the challenger sets 
.

Distinguishing this game from the previous can be reduced to the security of  w.r.t. uniformly random sources. Note that since the distribution of the source is independent of the adversary, generating the salt value XTS before the end of the PAKE does not raise any issue in the reduction. Indeed, the reduction algorithm can generate a uniformly random source value at the beginning of the reduction, submit it to the KDF-security-game challenger, then receive back a uniform salt value before generating the other parameters for .

Denoting by 
 the supremal advantage of any efficient adversary which makes no oracle query in the KDF security game with scheme  (cf. Appendix 9), adversary  can distinguish Game 12 from Game 11 with an advantage at most 
 (the reduction algorithm guesses the instances of  and  for which it sets the keys as the key returned by the KDF challenger).

Game 13.
For a  query on an adversarially generated tuple 
 to a  instance, abort the protocol if  and  are honest. Moreover, if the tuple is oracle-generated in a different session, abort the protocol. Likewise, for a  query on an adversarially generated tuple 
 to an  instance, if  and  are honest, abort the protocol. Besides, if the tuple is oracle-generated in a different session, abort the protocol.

Distinguishing Game 13 from Game 12 can be reduced to the security of . It follows  can distinguish Game 13 from Game 12 with an advantage of at most 
, with 
 being the supremal advantage of any efficient adversary which makes at most one oracle query in the PRF game with scheme  (cf. Appendix 9) (the reduction algorithm guesses the  and  instance for which it sets the common MAC key as the challenge one).

Game 14.
For a  query to a  instance on pair 
 which is either adversarially generated or oracle-generated in a different session, abort if  and  are honest. Indeed, the word for which 
 is a proof is generated anew for each session since 
 is always freshly generated (and 
 is thus not the image of a previous projective key under an additive transformation). It follows that

–
if 
 is oracle generated in a different session, the verification can only succeed with negligible probability if  is sound. In this case,  can distinguish this game from the previous with an advantage of at most 
, with the latter denoting the supremal advantage of any efficient adversary which makes at most 
 queries in the CM-simulation-soundness game for 

–
if 
 is adversarially generated, the CM simulation soundness of  guarantees that the commitments , , ,  satisfy 
 and 
 (with proof elements excerpted from 
). However, these commitments can then be used to contradict the perfect smoothness of the KV-SPHF for short Cramer–Shoup ciphertexts. Indeed, given 
 and  such that 
, these commitments and 
 can be used to distinguish 
 from 
 simply by testing whether 
. The perfect smoothness of the KV-SPHF for short Cramer–Shoup ciphertexts implies that it can only occur with probability . Therefore, in this case, the adversary can distinguish this game from the previous one with an advantage of at most 
 (the algorithm for the reduction to the perfect smoothness of the SPHF must guess the query for which it sets the projective key as 
)

 can then distinguish this game from the previous one with an advantage of at most 
.
In Game 14, once the challenge tuple 
⁎
⁎
⁎
 is defined, all values received by 
⁎
, 
⁎
 and 
⁎
 instances up to 
⁎
⁎
 included are either all oracle-generated in the same session or replied to with ⊥ as long as these identities are honest. In particular, if 
⁎
 is corrupt,  queries to 
⁎
 instances are rejected (by definition of oracle ) and  thus cannot make successful  queries to 
⁎
 instances anymore as long as 
⁎
 is honest; and if 
⁎
 and 
⁎
 are corrupt,  queries to 
⁎
 instances are rejected anyway. Likewise, if 
⁎
 is corrupt,  queries to 
⁎
 instances are rejected (recall that 
⁎
 and 
⁎
 cannot both be corrupt) and  cannot make successful  queries to 
⁎
 instances anymore. Winning the 1-out-of-2 RCCA game for 
 can then reduced to winning Game 14 as follows.

At the beginning of the game, the reduction algorithm, further denoted , guesses the identities 
⁎
, 
⁎
 and 
⁎
. If  later makes its  query on a different tuple of identities,  simply aborts and sends to the challenger a bit chosen uniformly at random.

Recall that 
⁎
 and 
⁎
 cannot both be corrupt by definition of P-IND-RCCA game. On this account, first suppose that 
⁎
 is honest throughout the game.  then sets the public key as the public key of 
⁎
 and asks for a secret key share that it sets as the share of 
⁎
 (which is given to  in case of corruption). The other share is then implicitly the share of party 
⁎
.

For  queries and  queries on oracle-generated tuples 
⁎
 to 
⁎
 instances, since 
 is computed by , the latter can make decryption queries to the RCCA challenger on the original ciphertext 
, receive back 
⁎
⁎
, and multiply it by 
⁎
, with R denoting the blinding factor generated by algorithm .

 also simulates with the trapdoor proofs 
 and 
.

For query , algorithm  simply forwards 
 to the RCCA challenger. After the test query, for  queries as above, if 
 decrypts to 
 or 
, the RCCA challenger answers with  and so does .

For a prompting  query on 
⁎
⁎
⁎
⁎
 to a 
⁎
 instance, the reduction makes a decryption query to the RCCA challenger on 
. If it decrypts to 
 or 
, the reduction algorithm receives  and forwards it to .

The condition “
 return ” guarantees that  can answer with ⊥  queries and prompting  queries on 
⁎
, and perfectly emulate the Game-14 challenger.

Moreover, recall that in case 1),  never makes a  query on a valid tuple 
⁎
⁎
⁎
⁎
⁎
 such that 
⁎
⁎
 is oracle-generated but 
⁎
 is adversarially generated, although 
⁎
 and 
⁎
 are honest. It means that if 
⁎
 is honest,  can obtain partial decryption from 
⁎
 only with oracle-generated tuples, and the condition mentioned above ensures that 
⁎
 never has to make a decryption query on a ciphertext which decrypts to 
 or 
. If 
⁎
 is corrupt and 
⁎
 is honest,  never has to make such a decryption query either as  would never submit a valid tuple in the first flow. If 
⁎
 and 
⁎
 are both corrupt, then  can simply answer  queries with ⊥.

As  perfectly emulates the Game-14 challenger, it wins the RCCA game with at least the same advantage as  in that game.

In case 
⁎
 is honest throughout the game, the reduction is similar except that  now sets the key share it gets as the share of 
⁎
. Note that in Game 14, all valid pairs 
⁎
⁎
 submitted to 
⁎
 instances are oracle-generated in the same session if 
⁎
 and 
⁎
 are honest. If either of them is corrupt, all  queries to 
⁎
 instances are rejected. Consequently,  never has to make a decryption query on a ciphertext that decrypts to 
 or 
.

It follows that the advantage of  in the P-IND-RCCA game in case 1) is at most

In the second case,  and  are honest in the query that distinguishes the two cases. The major argument is that only  and  can compute 
 and that only  holds the decryption 
. Therefore, an adversary cannot distinguish 
 from encryption of a dummy message which contains no information about the token share. Moreover, as long as  and  are honest, 
 is indistinguishable from a uniformly random value and 
 thus contains no information about the shares either. For the adversary to compute a valid tuple from that point, it has to compute a valid proof on the token share after only getting zero-knowledge ones. This valid proof can then be used to contradict the 1-out-of-2 security of 
.

To prove it formally, consider the following sequence of games.

Game 0–5.
These are the same as in the previous case.

Game 6.
To answer  queries with identities ,  and , the challenger computes, the challenger generates 
 uniformly at random.  can distinguish this game from the previous one with an advantage of at most 
.

Game 7.
In this game, to answer  queries with identities ,  and , the challenger generates 
. This game is perfectly indistinguishable from the previous one as 
 is uniformly random in the latter.

Game 8.
To answer  queries with identities ,  and , the challenger now computes 
 as 
 (and verifies that 
). The indistinguishability from the previous games stems from the IND-CPA security of 
 (which is implies by its IND-PCA security). Therefore,  can distinguish this game from the previous one with an advantage of at most 
, with 
 denoting the supremal advantage of any efficient adversary in the IND-CPA game with scheme 
.

Game 9.
To compute 
 and 
 to answer  queries to  instances, the challenger now simulates them with the trapdoor. Likewise, the challenger simulates 
 and 
 to answers  queries to  instances. The zero-knowledge property of  implies that  can distinguish this game from the previous one with an advantage of at most 
.

Game 10.
The challenger now answers  queries to an  instance on 
 such that 
 is oracle-generated by computing 
. This game is perfectly indistinguishable from the previous one by the correctness of the SPHF.

Game 11.
The challenger now answers  to a  instance on 
 such that 
 is oracle-generated by computing 
. This game is perfectly indistinguishable from the previous one by the correctness of the SPHF.

Game 12.
In this game, the challenger answers  queries to

–
an  instance on tuples 
 such that 
 is oracle-generated by generating 
 in case  is honest

–
a  instance on oracle-generated tuples 
 by setting 
, the latter being the value of the partner  instance of the  in the current session

Katz and Vaikuntanathan's lemma [32, Lemma 1] implies that  can distinguish this game from the previous one with an advantage of at most 
.

Game 13.
For  queries to an  instance on tuples 
 such that 
 is oracle-generated, the challenger generates 
 uniformly at random in case  is honest. For a  query to a partner  instance on an oracle-generated tuple 
, the challenger sets 
.

Distinguishing this game from the previous can be reduced to the security of  w.r.t. uniformly random sources.

Denoting by 
 the supremal advantage of any efficient adversary which makes no oracle query in the KDF security game with scheme  (cf. Appendix 9), this game can be distinguished from the previous one with an advantage of at most 
.

Game 14.
In this game, if  is honest, the challenger answers  queries to  instances on 
 tuples by generating 
. This game is perfectly indistinguishable from the previous one as 
 is uniformly random in the latter.

Game 15.
To answer  queries to  instances on oracle-generated pairs 
, the challenger now generates 
 and computes 
 as 
. To answer  queries to the partner  instance in this session on tuples 
, the challenger verifies that 
. The indistinguishability from the previous game follows from the IND-PCA security of 
. Indeed, for queries to  instances as above, if 
 is oracle-generated (i.e., ⁎⁎
⁎ was computed as an answer to a  query), then the reduction need not make a decryption query as it computed it itself. If 
 is adversarially generated, i.e., 
 was computed with a label different from ovk, the reduction algorithm can then make a decryption query.

Distinguishing this game from the previous one can thus be done with an advantage of at most 
.

Game 16.
To answer  queries to  instances on oracle-generated pairs 
, the challenger now generates 
 and computes 
 as 
. To answer  queries to the partner  instance in this session on tuples 
, if 
 is oracle-generated in the same session, the challenger skips the verification, otherwise the challenger verifies that 
. Once again, indistinguishability from the previous game follows from the IND-PCA security of 
. Adversary  can distinguish this game from the previous one with an advantage of at most 
.

Game 17.
For  queries to  instances on tuples 
, if ovk and 
 are oracle-generated but in different sessions, return ⊥. Denoting by 
 the supremal advantage of any efficient adversary in the strong one-time security game,  can distinguish this game from the previous with an advantage of at most 
 (the reduction algorithm must guess the  instance for which it sets the one-time signing key as that of the challenger).

Game 18.
For  queries to  instances on tuples 
, if ovk is adversarially generated and 
 is oracle-generated, the challenger returns ⊥. Adversary  can distinguish this game from the previous one with an advantage of at most . Indeed, if 
 is oracle-generated, there exists a 
 as defined in Game 16 which is independent of all the other messages computed by the challenger and of all the inputs from .

Winning the 1-out-of-2 RCCA game can then be reduced to winning the last game as follows. At the beginning of the game, the reduction algorithm, denoted , guesses again the identities 
⁎
, 
⁎
 and 
⁎
. (If  later makes its  query on a different tuple of identities,  simply aborts and sends to the challenger a bit chosen uniformly at random.)  then sets the public key as the public key of 
⁎
 and asks for a secret key share that it sets as the share of 
⁎
. The other share is then implicitly the share of 
⁎
.

Recall that if  corrupts 
⁎
, algorithm  can reply to  queries to 
⁎
 instances with ⊥ and perfectly emulate the challenger of the last game.

Whenever  makes its first  query to an 
⁎
 instance on a valid tuple 
⁎
⁎
⁎
⁎
⁎
 such that 
⁎
⁎
 is oracle-generated but 
⁎
 is adversarially generated, ovk and 
⁎
 are necessarily adversarially generated by definition of the challenger of the last game. By CM simulation soundness of  w.r.t. additive transformations (which holds under the existential unforgeability of ), either (i) 
⁎
⁎
⁎
⁎
, or there exists an oracle-generated proof (respectively by an 
⁎
 instance or by a 
⁎
 instance) 
 such that (ii-a) 
 or (ii-b) 
⁎
⁎
 and a tuple 
, with 
 representing a transformation, such that 
⁎
⁎
. It follows that for  either 
⁎
 or 
 is a commitment to 
⁎
; and assume without loss of generality that it is the former.  then computes 
⁎
⁎
 for , i.e., commitments to 
 with the same randomness used to compute 
⁎
.

If  makes a  query on the guessed identities,  simply forwards 
 to the RCCA challenger, and receives back a challenge ciphertext 
⁎
 which encrypts 
 for 
. (If the guess was incorrect,  aborts its interaction with  and sends a uniformly random bit to the challenger.) Note that 
⁎
⁎
⁎
 and that 
⁎
⁎
⁎
. Therefore, 
⁎
⁎
⁎
. Algorithm  can then test the previous equality with 
 and 
 and win the 1-out-of-2 RCCA game with at least the same advantage as  in the selective P-IND-RCCA game.

Hence, in case 2),  wins the P-IND-RCCA game with an advantage of at most

Theorem 2 Blindness

 satisfies blindness under the SXDH assumption over .

The blindness property of  can be proved as follows via a sequence of indistinguishable games starting from the real game and ending with a game in which the advantage of any adversary is nil.
Game 0.
This is the real game.

Game 1.
The challenger generates  parameters  in witness-indistinguishability mode. This CRS is computationally indistinguishable from the one in the previous game under the SXDH assumption over .

Game 2.
Instead of computing  and Σ as algorithm , the challenger simulates those values with the GS proof-system simulator. Further denote the resulting algorithm as . Game 2 is perfectly indistinguishable from Game 1 since the simulation is perfect.

Game 3.
In this game, the challenger runs  on 
. Game 3 is perfectly indistinguishable from Game 2 since the scheme of Faonio et al. is perfectly unlikable.

Game 4.
Instead of running algorithm  on 
, the challenger runs it on  for 
. Game 4 is perfectly indistinguishable from Game 3 since  computes 
 as 
 for 
, which entirely re-randomizes 
 in Game 3.

Note that in Game 4, the advantage of any adversary is nil.

It follows that  satisfies blindness under the SXDH assumption over .
Theorem 3 Verifiability

 is verifiable if  is secure and if the SXDH assumption over  holds.

Suppose that there exists an efficient adversary  which wins the verifiability game with a non-negligible probability, i.e., it returns 
 and C such that the honest execution of  on 
 with  results in a value different from  and ⊥. In the event in which  wins the game, then either 
 or not. If so, then there exists an algorithm  which runs  as sub-routine and contradicts the perfect soundness of the GS proof system. If 
, then there exists an algorithm  which runs  as sub-routine and wins the MAC game with non-negligible probability.
In the first case, the correctness of the SPHF guarantees that 
. Therefore, if the value returned by  at the end of the protocol is different from both  and ⊥, adversary  necessarily contradicted the soundness of  for to the language
 which is impossible under the existential unforgeability of Jutla and Roy's signature, which relies on the SXDH assumption.

In the second case, i.e., if 
, the verifiability of  can be reduced to the security of the MAC through a sequence of games as below.

Game 0.
This is the real game.

Game 1.
In this game, the challenger replaces 
 with a uniformly random value. By the smoothness of the SPHF, Game 1 is perfectly indistinguishable from Game 0.

Game 2.
The challenger now generates a random key 
 instead of computing it with the KDF. The indistinguishability of Game 2 from Game 1 can then be reduced to the security of  w.r.t. uniformly random source.

Note that as the distribution of the source is independent of the adversary, generating the salt value XTS before the end of the PAKE does not raise any issue in the reduction. Indeed, the reduction algorithm can generate a uniformly random source value at the beginning of the reduction, submit it to the KDF-security-game challenger, then receive back a uniform salt value before generating the other parameters for .

Therefore, an efficient adversary can distinguish Game 2 from Game 1 with advantage at most 
, with 
 denoting the supremal advantage of any efficient adversary which makes at most 
 queries in the KDF security game with scheme  (cf. Appendix 9).

As  must compute a tuple 
 such that 
 to win Game 0 without any prior MAC computation by , it does so with non-negligible probability in Game 2. It follows that  can then be run as sub-routine to win the MAC game with non-negligible probability. Once again, under the assumptions on the compression functions (which imply the security of HMAC), an efficient adversary can only do so with negligible probability; a contradiction. It follows that such an adversary  cannot exist and  is thus verifiable.

4.2.4. Efficiency
Table 1 sums up the theoretical communication cost of the decryption protocol. Concretely, for a 128-bit security, adopting the Cocks-Pinch modified curve with p a 672 bit prime and an embedding degree  (following parameters advised by Guillevic in [29]), elements in 
 and 
 are of size 672 bits, while elements of 
 are of size 4028 bits. We estimate the resulting communication complexity in Table 2.


Table 1. Theoretical communication cost of the decryption protocol.

1st Flow	
2nd Flow	
3rd Flow	
4th Flow	

Table 2. Estimated communication in KB, λ = 128 and Cocks-Pinch modified curve.

1st Flow	0.41	5
2nd Flow	4.43	4.43
3rd Flow	4.92	4.92
4th Flow	6.73	6.73
4.2.5. On adaptive corruptions
The main reason why the decryption protocol is not secure against adaptive corruptions is that the short Cramer–Shoup encryption is “fully committing”, meaning that there is only one valid opening (i.e., message–randomness pair) for each commitment (i.e., ciphertext). However, in one of the intermediate games in the proof of P-IND-RCCA security, the challenger computes commitments to dummy passwords for honest parties. It means that if the adversary corrupts an honest party right after she has sent her commitment, the challenger cannot return to the adversary a valid opening which contains the actual password of that party.

To overcome this hurdle, one could instead use an equivocable commitment scheme which supports adaptively smooth KV-SPHFs. As an equivocable commitment scheme allows to compute a valid opening to any commitment given a trapdoor, such a scheme together with a KV-SPHF should make the protocol secure against adaptive corruptions. Blazy and Chevalier's commitment scheme and its associated KV-SPHF [10] precisely satisfy these conditions. The commitment scheme relies on the SXDH assumption, and although its size is constant in the bit length of the message (i.e., 4 
 elements and 2 
 elements for each commitment), it is still larger than that of the short Cramer–Shoup encryption scheme. The latter was then chosen for efficiency reasons but at the expense of adaptive corruptions.

Note also that if 
⁎
 is corrupted right after the end of the PAKE (i.e., at the end of the first round), then the adversary could get from the server instance a partial decryption on the challenge ciphertext with the third flow (even if the 
⁎
 instance was prompted on a different ciphertext). To prevent this, the token could again compute a one-time signature as in the first flow, but also include 
 in the label of the encryption. Doing so ensures the server that the third flow went through the token, which would not be possible in case of corruption of 
⁎
 as token queries are then rejected.

4.2.6. On composability
The Section-3 definitions are game-based and do not guarantee composability. However, a UC [16] functionality for EPAD schemes could be defined in the same vein as for PAKE [17] and RCCA-secure encryption schemes [18] considered together. Yet, to achieve composability, and as for PAKE protocols, it would be necessary for the UC simulator (in case the adversary correctly guesses the password of an honest party) to be able to compute correct SPH values on invalid words C (encrypting 
) with the sole knowledge of a projective key hp from the adversary and not of the corresponding hashing key hk.

Benhamouda et al. [9] introduced trapdoor SPHFs exactly for this purpose and gave a construction for the original Cramer–Shoup encryption scheme which is computationally and adaptively smooth under the SXDH assumption. It could readily be adapted to the short version of their scheme, though each projective key would contain one more 
 element. Alternatively, one could also use structure-preserving SPHFs which were introduced by Blazy and Chevalier [10].

4.2.7. Mitigating server breaches
EPAD schemes have so far been defined only w.r.t. a single server. Nevertheless, password theft from server databases is common in practice, and users even tend to use the same password for several services. It means that not only the confidentiality of user messages is threatened if a single server is compromised (and if her token is corrupt), but also potential other services.

To mitigate the impact of server breaches, a potential solution is to use threshold cryptography [39], [22]. User passwords are then encrypted in a database and the decryption key is shared between  servers so that no information about the passwords is leaked if at most a number t of them are corrupt. Nevertheless, any  servers should be able to recover user passwords. Blazy, Chevalier and Vergnaud [11, Sec. 5] proposed an efficient protocol for threshold PAKE [37] from SPHFs which is based on this idea. It allows a user and a gateway that interacts with  servers to agree on a common high-entropy key if the user password and the encrypted password match, without revealing any information about the passwords. However, if they do not, the keys obtained by each party are independent and uniformly random. In consequence, the security of the key exchange is guaranteed so long as at most t servers are corrupt.

The EPAD scheme in Section 3 can then be turned into a scheme with n servers and which withstand the corruption of t of them (i.e., a t-out-of-n scheme) as follows. During the set-up phase, the user encrypts her password and sends the encrypted password and a t-out-of-n secret-key share to each server. The 
 secret key is -out-of- shared between the n servers and the token so that any  servers and the token can decrypt user ciphertexts. During the decryption protocol, each of the participating servers plays in parallel the role of the gateway of Blazy, Chevalier and Vergnaud's protocol, and uses the resulting keys to authenticate the second flow in the protocol of Fig. 1. In the last flow, each server would then have to prove that it partially decrypted the ciphertext with its 
 key share and masked it with the key resulting from the threshold PAKE. As the threshold PAKE is based on SPHFs, the same techniques (as in Sec. 3) leveraging malleability apply.

5. Signatures
This section first gives the definition of strong one-time security of signature schemes. It then presents Groth's one-time signature scheme as well as a structure-preserving existentially unforgeable signature scheme due to Jutla and Roy [31].

Strong One-Time Security. A signature scheme is one-time strongly unforgeable against chosen-message attacks if no efficient adversary can forge a signature on a message even after obtaining a single signature (potentially on the same message). That is to say, for all , for every efficient adversary ,
⁎
⁎
⁎
⁎
  
⁎
⁎
 
 is negligible. Oracle 
 can be queried only once, say on a message M. It computes and returns , and adds  to 
.

5.1. Groth's strong one-time signatures
Given a group generator  and family of hash functions , Groth's [27] signature scheme consists of the following algorithms.

:
run 
. Generate 
. Set and return .

:
generate 
⁎
. Compute 
 and 
. Generate 
⁎
 and compute 
. Set  and . Return .

⁎
:
generate 
, and compute and return 
.

:
parse σ as . Return 1 if 
, else return 0.

Groth proved [27, Theorem 18] that it is one-time strongly unforgeable against chosen-message attacks if the discrete-logarithm assumption over  holds and if  is a family of collision-resistant hash functions.

5.2. Jutla and Roy's signature scheme
The following signature scheme, parametrized by a bilinear structure generator , is due to Jutla and Roy [31]. It allows to sign vectors of first-group elements, and it is existentially unforgeable under the SXDH assumption.

:
run 
. Return .

:
Generate 
, 
, 
. Set vk3 
 and 
. Return .

:
Generate 
. Compute
 
 
 Set and return 
.

:
If 
 and
 
 then return 1, else return 0.

6. Public-key encryption
This section recalls some security definitions for public-key encryption schemes as well as instantiations that are building blocks of the construction in Section 4.

6.1. Security definitions
This section recalls the formal definitions of IND-PCA and IND-RCCA security.

6.1.1. IND-PCA security
A labeled encryption scheme  is IND-PCA secure if for every , for every efficient adversary , is negligibly close to 1/2 (the advantage of  is then the distance of that probability to 1/2). Oracle , with a state (Q and sk), replies to a  query by returning the truth value of 
 and setting . If  ever queries  on 
⁎
⁎
, its advantage is set to 0 since 
 is overwritten by a uniformly random bit.

6.1.2. IND-RCCA security
An encryption scheme  is IND-RCCA secure if for every , for every efficient adversary ,
⁎
⁎
 
 is negligibly close to 1/2. Oracle , with state 
, replies to C queries by first computing . If 
 or 
, it returns a special string  indicating that C encrypts one of the challenge messages, otherwise it returns M.

6.2. Short Cramer–Shoup encryption
Given a group generator  (i.e., an algorithm which returns a prime p and the description of a p-order group on the input of a security parameter 
) and a family  of hash functions, the (labeled) short Cramer–Shoup encryption scheme [1] consists of the following algorithms.

:
generate 
 and 
. Set and return .

:
. Compute 
. (Parameters pp may further be omitted in the syntax.) Return .

:
compute 
, 
,  and 
. Set and return .

:
compute 
 and . If 
 then return M, else return ⊥.

Abdalla, Benhamouda and Pointcheval proved that this scheme is IND-PCA secure if the DDH assumption over  holds and if  is second-preimage resistant.

6.3. Encryption scheme of Faonio, Fiore, Herranz and Ràfols
Faonio, Fiore, Herranz and Ràfols [24] constructed a publicly verifiable, re-randomizable, structure-preserving encryption scheme which is secure under the matrix decisional Diffie–Hellman assumption [23]. The explicit version of their scheme under the SXDH assumption is given below.

 
  run 
. Generate a Groth–Sahai common reference string, i.e., 
 and 
. Set and return .

 
  generate 
, 
, 
 and 
. Compute
 
 and
 
 For , generate 
. Generate 
. Compute matrices 
 and 
. Set
  
 
 
 
 Return . If ciphertext blinding is necessary as in Section 4.1, store also G in sk.

Matrices 
, 
 and 
, and scalars 
 are parameters for the quasi-adaptive non-interactive zero-knowledge proof system of Kiltz and Wee for linear spaces [34] with witness-sampleable distribution.

 
 

∘
compute a tag, i.e.,

–

–
 

–
 

∘
compute a smooth projective hash π of the tag, i.e.,
 
 

∘
prove that π is well-formed, i.e.,

–
 for  and 

–
 
, with 
 if  and 
 otherwise

–
 

–
 
 for 

–
 

–
 
 for 

–

–
 
 

–
 

–
 

∘
prove that the commitments are well-formed, i.e., that  
 
 is in 
 and that  
 
 is in 
. That is, for , compute

∘
set and return
 A ciphertext comprises 14 
 elements, 15 
 elements and 4 
 elements.

 
 
∘
verify that the commitments are well-formed, i.e., that
 
 
 and that
 
  
 

∘
verify that the opening to  is the smooth projective hash of the tag, i.e., that
  
 
  
 
  
 

∘
if both verifications succeed, compute and return 
, else return ⊥.

 
  do the same verifications as algorithm  (they do not require knowledge of sk, only of pk). If they succeed, return 1, else return 0.
 
  first verify that the ciphertext is valid. Next, re-randomize the tag, and all proofs and commitments, i.e., do

–

–
 

–
 

–
re-randomize π, i.e., compute
 
 

–
 for  and 

–

–

–
 for 

–

–
 for 

–

–
 

–
compute
 
 

–

–

–
set and return 
.

6.3.1. Threshold decryption
The scheme of Faonio et al. can be turned into a t-out-of-n scheme by doing a t-out-of-n Shamir share [39] of 
 and 
. Before partially decrypting the plaintext, each shareholder first verifies the validity of the ciphertext, which is possible as the scheme is publicly verifiable. If the ciphertext is invalid, the shareholder returns ⊥. As a result, any  shares are sufficient to decrypt ciphertexts, but no information about the plaintexts can be inferred with only t shares.

6.3.2. Verification of blinded ciphertexts
This section gives an algorithm to blind the plaintext underlying a ciphertext of the scheme of Faonio et al. without the knowledge of the secret key, and an algorithm to verify that the blinding was done correctly given a share of the secret key and auxiliary information provided by the first algorithm.

Formally, these algorithms are as follows.

 
 

∘
if  return ⊥

∘
parse 

∘
generate a blinding factor 

∘
blind the payload part of the ciphertext, i.e., 

∘
 

∘

∘
denote by 
 the matrix  
 
, with 
 if  and 
 otherwise. It is a commitment to 
 with the same randomness as for 

∘
set 
. Note that  is not replaced by 
, as one would not be able to prove that it is well-formed for the scheme of Faonio et al. is RCCA-secure

∘
commit to R, i.e.,

–
;  
 

∘
Note that The issue is that without the secret key, one cannot compute 
 for . However, 
 and 
 are part of the ciphertext, so the user can compute 
  Given Σ and G (which is part of the secret key), one can then compute 
 and 

∘
. It is essentially a designated GS proof intended for any party who knows G

∘
return 
.

 
 
∘
verify that commitments 
 are well-formed as in algorithm 

∘
compute 
 and 
. This requires the matrix G in the secret key. If this matrix is kept in a share of the secret key, then the key share is enough.

∘
verify with the corrective terms 
 and 
 that the opening to  is the smooth projective hash of the tag, i.e., that

∘
if both verifications succeed, return 1, else return 0.

7. Smooth projective hash functions
This section explains how smooth projective hash function can be viewed as proofs of membership with designated verifier, and recalls a KV-SPHF for short Cramer–Shoup ciphertexts.

7.1. Designated-verifier proofs of membership
SPHFs can be seen as designated-verifier proofs of membership to  [2], [12]. Indeed, to prove that a word C is in , a designated verifier can generate a key hk and compute a projective key hp which she sends to the prover. Given a membership witness w, the prover evaluates the SPHF on  with hp and sends the result as a proof to the verifier. To verify the proof, the verifier computes the SPHF on C using hk and accepts if and only if the result matches the proof value. The correctness of the protocol follows from the correctness of the SPHF, and its soundness from the adaptive smoothness of the SPHF.

7.2. KV-SPHF for short Cramer–Shoup ciphertexts
For a fixed tuple , denote by 
 the language 
. Given a group generator ,  and , the following scheme, due to Abdalla, Benhamouda and Pointcheval [1], is a perfectly smooth KV-SPHF for 
.

:
generate 
. Compute 
. Return .

:
return 
.

:
return 
. Note that hp actually depends on neither M nor ℓ.

:
compute . Return 
.

:
compute . Return 
.

8. Proof systems
A proof system  is correct if for all , for all 
, for all , .

Π satisfies 
-soundness if for all , for every adversary , 
 

Π is 
-witness-indistinguishable if for all , for every PPT adversary ,
 

Π is 
-zero-knowledge if there exist two algorithms 
 and  such that for all , the distribution of crs is the same as that of , and such that for every PPT adversary  that makes at most q oracle queries,
  
 
 with 
 an oracle that computes and returns  on input , and returns ⊥ on input ; and 
 an oracle that computes and returns  on input , and returns ⊥ on input .

8.1. Simulation soundness under controlled malleability
In certain cases, it is necessary to be able to simulate proofs while still ensuring that no PPT algorithm can compute new valid proofs for false statements without a trapdoor. This property is commonly known as simulation soundness. However, a proof system cannot a priori be both malleable and simulation sound as malleability allows to compute proofs on transformed words without the knowledge of a witness. Chase et al. [19] put forth a relaxed version of simulation soundness which allows for malleability while guaranteeing a meaningful form of soundness; namely an adversary cannot compute (without trapdoor) a valid proof for the membership of x to  if  and x is not the image under an admissible transformation (from a pre-determined class) of a word for which it was given a simulated proof. Their definition requires the proof system to be a proof of knowledge (i.e., it requires extractability), but the following definition is rather for proof of statements.

Formal Definition. Let  be a non-interactive zero-knowledge proof system for a language  which is malleable w.r.t. a class  of allowable transformations for the relation  relative to . The proof system is said to satisfy Controlled-Malleable (CM) simulation soundness w.r.t.  if for all , for every PPT adversary , is negligible, with  an oracle which computes simulated proofs π on inputs x and adds  to Q.

Generic Construction. Let  be an efficient relation with corresponding language . Consider a class  of allowable transformations for  containing the identity, and for which membership can be efficiently tested. Consider an existentially unforgeable signature scheme , and a sound witness-indistinguishable proof system 
 for the language:
 Suppose that it is partially extractable in the sense that there exists a trapdoor-setup algorithm which returns a trapdoor and a CRS indistinguishable from the output of ; and an extraction algorithm such that no PPT adversary has significant probability of computing a valid proof π on a word , where the value ⁎
⁎ returned by the extractor on the input of the CRS, the trapdoor and  is such that 
. Let 
 be a class of transformations such that for all 
, there exists 
 such that 
 and 
.

We devise a new proof system Π, described hereafter, which is inspired by the scheme of Chase et al. [19, Section 3]:

:
run 
, 
 and . Set and return 
.

:
run 
. Return π.

:
return 
.

:
return 
.

Under the above assumptions, Π is complete, zero-knowledge and CM simulation sound w.r.t. . Indeed, it suffices to define  as  only it returns sk as trapdoor, and  as an algorithm which signs x with sk and honestly proves knowledge of . The witness indistinguishability of 
 implies Π is zero-knowledge. The simulation soundness of Π stems from the fact that, since 
 is sound, an adversary can win the game only if it can compute a valid signature on a word 
 such that 
⁎ was never queried. However, as 
 is partially extractable, that would contradict the existential unforgeability of .
8.2. Strong derivation privacy
In addition to the completeness, (CM simulation) soundness and zero-knowledge property for proof systems, a malleable proof system should also satisfy derivation privacy. It captures the idea that given , proofs on a word 
 computed with  and 
 as a witness should be indistinguishable from those computed with  and a valid proof π for x. Note that re-randomizable malleable proofs necessarily satisfy derivation privacy [19, Theorem 2.7] (randomize then evaluate). An even stronger notion of derivation privacy is that the proof computed with  should be indistinguishable from those computed by the zero-knowledge simulator. Following a theorem of Chase et al. [19, Theorem 3.4], the above construction Π satisfies strong derivation privacy if 
 satisfies derivation privacy.

8.3. Groth–Sahai proofs
Groth and Sahai (GS) designed a practical, non-interactive witness-indistinguishable proof system for a wide class of statements in bilinear groups [28]. More precisely, their system allows to prove the existence of values which simultaneously satisfy pairing product equations, multi-scalar multiplication equations in the source groups, and quadratic equations in 
. That is, given integers 
, the GS proof system allows to prove that there exists 
, 
, 
 and 
 which satisfy sets of equations of the form
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 with the other values being public. The set of public values for which all sets of equations are satisfiable is further denoted 
. Multiscalar multiplication equations in 
 are further omitted (i.e., 
) as there are not of interest in this paper, and as they are purely symmetric to equations in 
.

Their construction is given in the Common-Reference String (CRS) model. The CRS is generated in either of two modes: a soundness mode in which case the system is perfectly sound, and a witness-indistinguishability mode in which case the system is perfectly witness-indistinguishable. Under standard assumptions over bilinear groups, the two types of CRSs are indistinguishable.

8.3.1. Instantiation under the SXDH assumption
Common Reference String. In the instantiation under the SXDH assumption, the GS CRS contains two vectors 
 and two vectors 
. In a soundness setting,  and . Given the discrete-logarithm relation between 
 and 
, group-element variables can actually be efficiently extracted (which is not the case for 
 elements as the discrete-logarithm problem is hard). In a witness-indistinguishable setting, a and b are linearly independent (
 
 for 
), and so are v and w. In either setting, define  
 
 and  
 
.

Proof Computation. To compute a GS proof of satisfiability of equations of the form above,

–
commit to all variables, i.e.,

⁎
for all 〚〛, generate 

⁎
 

⁎
for all 〚〛, generate 

⁎
 

⁎
for all 〚
〛, generate 

⁎

⁎
for all 〚
〛, generate 

⁎

–
compute proof elements for each pairing product equation, i.e.,

⁎
generate 

⁎
 
 
 

⁎
  
 
 

–
for each multi-scalar multiplication equation in 
,

⁎
generate 

⁎
 
 

⁎
  
  
 

In case all 
 are nil, then T can be set as 0, and the proof element Θ can then be restricted to its second component. Besides, if all 
, then Π can be set as 1.
–
for each quadratic equation in 
,

⁎
generate 

⁎

⁎

In case all 
 are nil, then T can be set as 0. Moreover, Θ can also rather be set as 
 and Π as 
, which results in smaller proof elements (the verification algorithm would then first compute 
 and 
).
–
return all commitments 
 and all proof elements. Note that the resulting proof is perfectly re-randomizable, and that the proof system therefore satisfies derivation privacy.

Verification. Accept a proof parsed as above if and only if
–
for every pairing production equation,

–
for every multi-scalar multiplication equation in 
,

–
for every quadratic equation in 
,

Malleability. Additive transformations in 
 are admissible for the relation of multi-scalar multiplication equations in 
. That is, for any set 〚
〛 such that 
 for all 〚
〛 and , given 
 and ℓ multi-scalar multiplication equations, the map is admissible. This map is identified with the tuple 
. Note that it is the identity at the coordinates i such that 
.
The GS proof system is malleable w.r.t. such transformation. More precisely, its algorithm  first parses a valid π as above, generates 
, and computes

–

–
for all 〚〛, 
.

It then returns 
.
OR Proofs. Define 
 as the language of pairs 
 such that 
 or 
. To prove a statement 
, following techniques of Groth [27], it suffices to introduce new variables 
, and 
, 
, 
 and 
 for , and then GS prove the satisfiability of the sets of equations for , and with 
 denoting the variable 
 for 
 and 
 the one for 
, and likewise for the other public values. If 
 (with witness ), set 
 and 
, 
 and 
, and similarly for the other variables; and vice versa if 
. The last equation implies that 
, which guarantees that 
 or 
. To prove the last equation, it suffices to consider 
 as both an extra x and an extra y variable such that  and .

Simulation Soundness under Controlled Malleability. The generic construction of a CM simulation proof system of Sec. 8.1 can be applied with Jutla and Roy's signature scheme (App. 5.2) to the GS proof system for multi-scalar multiplication equations in 
; the latter being malleable w.r.t. additive transformations in 
.

In more detail, given equations of the form
 
 
 
 
 for , let  denote the class of additive transformations. These transformations are identified with tuples 
. For a given transformation 
, let 〚〛 denote the set of indices such that 
. Set μ as 
. The components of μ are nothing but the public values which are affected by the transformation (i.e., it corresponds to 
 in the generic construction). A CM simulation sound GS proof for multi-scalar multiplication equations in 
 is then a proof that there exists X and y such that all ℓ equations are satisfied or that there exists μ, 
 and a Jutla–Roy signature σ such that  and 
.

Compared to a standard GS proof, a CM-simulation-sound GS proof introduces  additional variables 
, 5 additional 
 variables and 1 additional 
 variables for σ,  additional variables 
 for the transformation, and 2 additional 
 variables x and y (which should satisfy ).

In terms of equations, it introduces 2 pairing-product equations for the verification of the signature,  multi-scalar multiplication equations in 
 for the transformation, and 2 quadratic equations in 
 for x and y. That means  
 and  
 elements to commit to the additional variables; 4 
 and 8 
 elements as proof elements for the verification of the signature (which costs 
); 2 
, 2 
 and 2 
 elements as proof elements for the two equations in 
, whose verification costs 2 
 + 6 
; and  
 and  
 elements for the multi-scalar multiplication equations in 
 introduced by μ, the verification of each of which costs 
.

9. Key-derivation functions
This section gives the formal security definition of key-derivation functions, and recalls Krawczyk's scheme [35].

9.1. Security
The security of key-derivation functions can be defined w.r.t. a specific source of keying material which returns a material SKM and a public piece of information inf.

Definition 5

[35, Definition 7]
A key-derivation function , which supports salt values from a finite set Σ, is secure w.r.t. a source (of key material)  if for every efficient adversary , is negligibly close to 1/2, with  an oracle which, on input , replies to a  query with  and then adds CTX to Q.

The previous definition is w.r.t. a specific source, but it can be extended to all sources which return materials with enough entropy even when conditioned on the public information. Formally, for an integer m, a source  is a m-entropy source if for all s in the range of key materials and all i in the support of public information returned by , 
. A key-derivation function is then said to be m-entropy secure if it is secure w.r.t. all m-entropy sources.

9.2. Krawczyk's key-derivation function
Krawczyk gave [35, Section 4.2] a secure construction of KDFs from Hash-based Message Authentication Codes [6] (HMAC) which follows the extract-then-expand paradigm.

More precisely, let 
 be a family of Merkle–Damgård hash functions with k-bit outputs which is based on a family of compression functions 
 (e.g., SHA-512). Assume (single-keyed) HMAC to be built from NMAC [6], and NMAC to be built from 
. If 
 is a family of pairwise-independent compression functions, and 
 is collision-resistant against linear-size circuits, then [35, Corollary 9] NMAC truncated by c bits is a 
-statistical extractor on n-block inputs. If 
 is modeled as a family of random functions independent from the source, then the same result applies to HMAC.

Moreover, given another family of compression functions 
 (think of SHA-256), if 
 is a Pseudo-Random Function (PRF), and if 
 is a PRF under a class of affine related-key attacks (defined by the inner and outer pads), then [5, Theorem 3.3, Lemma 5.2] HMAC is a 
-PRF for 
, 
 explicited in Bellare's paper [5].

Notation. In the construction is described in Algorithm 1, given two integers  and 
, 
 denotes the sub-string of x consisting of its first d bits.