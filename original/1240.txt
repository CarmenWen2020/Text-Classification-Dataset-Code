Abstract
In this paper, we study the generalized submodular maximization problem with a non-negative monotone submodular set function as the objective function and subject to a matroid constraint. The problem is generalized through the curvature parameter α∈[0,1] which measures how far a set function deviates from linearity to submodularity. We propose a deterministic approximation algorithm which uses the approximation algorithm proposed by Buchbinder et al. [2] as a building block and inherits the approximation guarantee for α=1. For general value of the curvature parameter α∈[0,1], we present an approximation algorithm with a factor of 1+hα(y)+Δ⋅[3+α−(2+α)y−(1+α)hα(y)]2+α+(1+α)(1−y), where y∈[0,1] is a predefined parameter for tuning the ratio. In particular, when α=1 we obtain a ratio 0.5008 when setting y=0.9, coinciding with the renowned state-of-art approximate ratio; when α=0 that the object is a linear function, the approximation factor equals one and our algorithm is indeed an exact algorithm that always produces optimum solutions.

Keywords
Approximation algorithm
Submodular maximization
Total curvature
Matroid constraint
Deterministic algorithm

1. Introduction
The theory of submodular maximization provides a general and unified framework for various combinatorial optimization problems including Maximum Coverage, Maximum Cut and Facility Location [13]. Furthermore, it also appears in a wide variety of applications such as viral marketing [20], information gathering [22], feature selection for classification [21], influence maximization in social networks [20], document summarization [24], speeding up satisfiability solvers [29], machine learning [4], computer vision [16], operations research [17], social welfare [31], combinatorial auctions [23] and data privacy [27]. As a consequence of its importance in these applications, a wide range of efficient approximation algorithms have been developed for maximizing submodular functions subject to different constraints.

It is considered as a fundamental problem in optimization to maximize a monotone submodular function with a single matroid constraint, and has attracted considerable attention in recent years. In this problem, N is a ground set of n elements and 
 is a non-negative monotone set function, which can be considered as an oracle that returns the value of any set immediately. A set function 
 is submodular if and only if  holds for any subset . The aim is to seek a subset S of N, simultaneously satisfying the feasibility constraint of the matroid  and maximizing the value of f. The matroid concept is a useful combinatorial structure which generalizes the concept of linear independence in linear algebra to set theory.

Moreover, a well-studied generalization for the set function of submodular maximization has revoked the research interest [11], [32], [18], [19], [30], [5], which is denoted by total curvature of f and first addressed by Conforti and Cornuéjols [11]. Intuitively, the curvature depicts how far a function f deviates from linearity. Formally, a submodular function f is with curvature , if  holds for any subset  and element ﹨.

For matroid constraints, the renowned approximation ratio  is possibly the best performance guarantee unless the algorithm uses exponentially-many queries in the size of the ground set N [25] even for its special case of cardinality constraint. Later, Feige [12] pointed out that there exists no polynomial-time algorithm with an approximation factor better than . On the algorithmic side, it is shown that the standard greedy algorithm [26] achieves a -approximation ratio when f is with the curvature α [11]. In fact, the greedy approach is a basic method for submodular maximization, which starts from an empty set and iteratively adds to the current solution one element producing the largest marginal profit of the objective function while satisfying the constraints. In recent years, the continuous greedy as a mile stone was devised by Calinescu et al. [8], and was shown achieves the possibly best 
 approximation guarantee [9], [31]. The algorithm has a ratio impressively matching the inapproximability result given by Feige [12], employing the main tools including continuous greedy and pipage rounding [1], where continuous greedy process for approximating the relaxation of the problem within a factor of 
 and pipage rounding (or swap rounding [10]) for recovering a fractional solution of value at least 
 
. Moreover, for making it suitable for computation model, Balkanski et al. [6] parallelized the continuous greedy and presented a -approximation algorithm with 
 adaptivity, where 
 is the rank of the matroid. The adaptive complexity model was recently introduced in the context of submodular optimization in [7] to quantify the information theoretic complexity of black-box optimization in a parallel computation model. Another recent elegant work on the problem was due to Filmus and Ward [14], in which the key technique is non-oblivious local search and an optimal approximation guarantee of 
 is attained. Similar to the continuous greedy approach, their algorithm is also a randomized algorithm. Moreover, the above algorithms are difficult to be derandomized because they are intrinsically randomized. Therefore, a natural open problem arises: does there exist a deterministic algorithm with approximation ratio 
?

Towards closing the open problem, Buchbinder et al. [2] proposed a deterministic 0.5008-approximation algorithm. Observing the obstacles of utilizing derandomization techniques to submodular maximization problems, their main algorithm is built by two straightforward procedures: one is a deterministic partition algorithm, which greedily selects the element that satisfies the constraints and maximizes the marginal profit, and finally gets two pieces of a certain base of the given matroid; the other is a randomized algorithm with a known deterministic version. In fact, the latter algorithm is proposed in [3] and known as Residual Random Greedy (RRG) algorithm. It is also a greedy-like randomized algorithm and can be derandomized to Residual Parallel Greedy (RPG) algorithm through employing perfect matching. The main algorithm merges these two procedures in the following way: firstly, the partition algorithm constructs two disjoint sets whose union is a specific base of the given matroid; secondly, the RPG algorithm finds the completed part for each of the two sets aiming to make them a base on appropriate contracted matroids; lastly, the output is the one of the two bases with larger objective value. Among the steps, we employ the novel method proposed by Buchbinder et al. for the sake of selecting parameters to eventually guarantee that the ratio is larger than 1/2.

1.1. Main results
Our main result is a deterministic approximation algorithm for maximizing a generalized monotone submodular function subject to a matroid constraint. The set function is generalized through a curvature parameter  and essentially reduces to a submodular function when . Our algorithm employs the deterministic algorithm devised by Buchbinder [2] as a building block and it reaches an same ratio of 0.5008 when . Then, we extend the whole analysis of all algorithms to an arbitrary curvature  and state the conclusion with the following theorem.

Theorem 1

For any total curvature  and calibrating parameter , there exists a deterministic algorithm with the following ratio
 
 where 
 
.

Fig. 1 and Table 1 illustrate the relationship among the curvature α, the approximation ratios and the individually selected parameter y numerically. Similar to the result in [2], the approximation guarantee is exactly 0.5008 when  if we choose the parameter appropriately, i.e. . Besides, as demonstrated in Table 1 our ratio is strictly larger than 0.5008 for any other . Particularly, when the curvature α equals 0, the problem is polynomial-time solvable.

Fig. 1
Download : Download high-res image (106KB)
Download : Download full-size image
Fig. 1. Illustration of the relationship between calibrating parameter y, curvature α and approximation ratios.


Table 1. The approximation ratios regarding different values of y and a list of total curvature parameters α ∈ [0,1].

Cur. α	Best y	Ratio	Cur. α	Best y	Ratio
1.0	0.9	0.50087	0.48	1.0	0.67568
0.98	0.9	0.50527	0.46	1.0	0.68493
0.96	1.0	0.5102	0.44	1.0	0.69444
0.94	1.0	0.51546	0.42	1.0	0.70423
0.92	1.0	0.52083	0.4	1.0	0.71429
0.9	1.0	0.52632	0.38	1.0	0.72464
0.88	1.0	0.53191	0.36	1.0	0.73529
0.86	1.0	0.53763	0.34	1.0	0.74627
0.84	1.0	0.54348	0.32	1.0	0.75758
0.82	1.0	0.54945	0.3	1.0	0.76923
0.8	1.0	0.55556	0.28	1.0	0.78125
0.78	1.0	0.5618	0.26	1.0	0.79365
0.76	1.0	0.56818	0.24	1.0	0.80645
0.74	1.0	0.57471	0.22	1.0	0.81967
0.72	1.0	0.5814	0.2	1.0	0.83333
0.7	1.0	0.58824	0.18	1.0	0.84746
0.68	1.0	0.59524	0.16	1.0	0.86207
0.66	1.0	0.60241	0.14	1.0	0.87719
0.64	1.0	0.60976	0.12	1.0	0.89286
0.62	1.0	0.61728	0.1	1.0	0.90909
0.6	1.0	0.625	0.08	1.0	0.92593
0.58	1.0	0.63291	0.06	1.0	0.9434
0.56	1.0	0.64103	0.04	1.0	0.96154
0.54	1.0	0.64935	0.02	1.0	0.98039
0.52	1.0	0.65789	0.0	1.0	1.0
0.5	1.0	0.66667			
1.2. Technical overview
Our result is inspired by the elegant work of Buchbinder et al. [2] which is a deterministic algorithm with an approximation ratio 0.5008 for maximizing a monotone submodular set function over a matroid constraint. When the curvature of the set function equals to 1, the result can easily reduce to their primal conclusions; However when for general curvature α, we need more sophisticated analysis on the inequalities about monotonicity comparing to the previous work as we replace those inequalities of monotonicity with curvature, and we also employ other mathematical tools such as infinite series.

1.3. Organizations
The remainder of the paper is organized as below: Section 2 introduces preliminary definitions of the paper; Section 3 devises the two greedy-like algorithms and presents all the analyses; Section 4 illustrates the derandomization of the presented algorithms; Section 5 finally concludes the paper.

2. Preliminaries
In this section, we will formally describe the notations and definitions used throughout the paper. Given a ground set N of n elements, we say a set function 
 is submodular if and only if  holds for any . Besides, a set function f is monotone if  holds for all . The marginal contribution for a submodular function of selecting an element  to S is denoted by 
. A submodular function f has total curvature  if it is the minimum α for which  holds for any  and ﹨. For briefness, we abbreviate 
 and ﹨ as 
 and , respectively.

Let the pair  be a independence system regarding the ground set N and the independence system  is a matroid, if  is a nonempty collection of subsets of N and satisfies the downward closed and augmentation properties. The independence system  is downward closed if for all  and , then . The augmentation property states that if  and , then there exists an element ﹨ such that .

We say a subset  is independent or feasible if S is an element in . The rank of a matroid  is denoted by 
 and it is the common size of the maximal independent sets of . A maximal independent set is called the base of  and denoted by B. In this paper, we assume the rank 
 of  is at least 2 because the above problem can be solved in linear time when 
. Furthermore, following the definitions on matroid theory as in [28], we say  is the matroid obtained from  by contracting S, which is an independent set of . For the convenience of the algorithms to verify the feasibility constraint of the given matroid, we assume that the algorithms can directly query the matroid through an independence oracle traditionally. For instance, the independence oracle returns whether  is independent or not, for a set S is given as an input. Additionally, we present some technical lemmas hereby for preparing the technique proofs of our main claim. Besides the usage in the paper, these lemmas nevertheless bring some valuable insight of the properties of matroid.

Lemma 2

([15], [33]) Given two bases 
 and 
 of a matroid , and a partition 
, there exists a partition 
 such that 
 and 
 are both bases of .

Lemma 3

([13]) Let 
 be a submodular function and S be an arbitrary set . For all random set 
 which includes every element of S with probability p, then we have

The aim of our problem is to find a subset S of N maximizing a non-negative, monotone and submodular function 
 over a matroid  constraint. The set function f is generalized with respect to total curvature . Moreover, the optimal solution for the problem we consider is denoted by OPT.

3. Generalizing the 0.5008-approximation algorithm with curvature
We begin the whole analysis with the greedy-like Partition algorithm. The input includes the matroid , the submodular function f and a probabilistic parameter . At each round, it chooses elements with maximal marginal profit in a specific contracted matroid from both disjoint sets. Then, the algorithm keeps one element according to the judgemental condition. The Partition algorithm formally proceeds as in Algorithm 2.

Algorithm 2
Download : Download high-res image (60KB)
Download : Download full-size image
Algorithm 2. Partition.

Algorithm 2 gives a separation of a base B as output. The following lemma shows a lower bound on both two disjoint sets.

Lemma 4

For the generalized set function f with curvature α, for any base B of matroid  and parameters , , the output of the Partition algorithm satisfies
 
 where
 
 and
 

Proof

Following the construction of this algorithm, for every , we can get the followings from the construction of the algorithm

For every 
, we construct a set 
 such that 
 is a base of  following a similar line as Buchbinder et al.'s method [2]. According to the rules of matroid, there exists an element 
 such that 
 is a base of . So we assume 
 is an candidate for the 
 selection in the m-th iteration. Then, we have
 where the second inequality follows by submodularity and the last follows by monotonicity with curvature.

We denote 
 or ∅ and 
 or ∅. For these two notations, only two cases can happen. The first is 
 and 
, which means there is an element added into set S after iteration m; The second is the reverse of the first.

By rearranging the last two inequalities, we get

It is a recurrent formula about m. Then, we have
 
 

Again, by rearranging we get

For
 
 we reduce it to a common denominator
 
 
 where the last inequality can be verified by simple calculation. □

Next, the lemma below states that for any base B of the matroid , we can obtain a good partition regarding the two disjoint sets generated by Algorithm 2.

Lemma 5

For any base B of the matroid , a partition 
 exists such that the following two characteristics both hold:

(1)
 and 
 are bases of .

(2)
 and 
.

Proof

Following Lemma 2, there lies a way to divide B into two disjoint subsets 
 and 
, such that 
 and 
 are bases of .

Assume we have constructed 
. Namely, for 
, there must exist a set 
 such that 
 is a base of . For the case 
 in Algorithm 2, we set 
 to make sure that 
 is a base of . Then we have

For another situation, 
, we easily set 
 and immediately get

By combining these two inequalities, we get the recurrence relation with respect to the index m:

Since 
 and 
, we can get
 

After rearranging, we finally get the result

Similarly, we can prove the second conclusion 
. □

Before giving the theoretical analysis of the algorithm, we build sets 
 for each integer 
. In fact, 
 is obtained from an arbitrary base B of the matroid  and it is indeed a maximal independent set of the contracted matroid 
. Besides, a bijection mapping 
 is also constructed following a similar line as in [2]. This mapping gives a connection between each element 
 and an element of 
 in a specific way that 
 is a base of 
.

In the following, we state formally the lemma regarding Algorithm 3 which will plays a central role in later analysis.

Lemma 6

For a possibly random set  and any integer 
,

Proof

Given that the decisions in first  iterations are deterministic, and the sets 
 and 
 have been selected. Then, we get
 
 
 where the inequality apparently holds following the behavior of the algorithm, and the result is exactly the expectation of 
. Thus,
 where the first inequality follows from submodularity, and the second from the monotonicity with curvature.

By rearranging we have
 □

Then we give a conclusive result of the above lemma related to the matroid rank 
.

Corollary 7

For a possibly random set  and each 
,
 

Proof

Note that sets 
 and 
. Therefore, we immediately have the following result
 
 
 □

We immediately have approximation guarantee  for Algorithm 3 by setting  in the above corollary. The next lemma presents a lower bound on 
 for each 
.

Lemma 8

For all 
, the expected value of 
 has the following lower bound
 
 where
 
 and
 
 

Proof

For the case the integer 
, 
, the correctness of the lemma follows from Corollary 7 immediately.

For the other cases, we show the result by induction. For the case , the lemma obviously holds since 
 and 
. Then we suppose the lemma also holds for 
 as the induction hypothesis. For 
, we prove the lemma conditioned on the situation 
, 
 and 
 are deterministic.
 
 
 
 
 
 where the property of 
 is the reason the first inequality holds, the second and the last inequalities follow from submodularity, and the third is true by choosing  in Corollary 7.

By rearranging and following the induction hypothesis, we get
 
 
 
 
 
 
 
 
 

Recall that the derivative of 
 is 
 
. Thus,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 □

Moreover, the above lemma can be extended to non-integral values. We describe the extension as in the next lemma:

Lemma 9

For each , 
 and 
, then

Proof

We prove this lemma by discussing two cases:

For Case 1: 
 is an integer while in the other case, 
. For the case 
 is an integer, the parameter β equals to 1. So apparently we can get the conclusion from Lemma 8 by incorporating  into the formula.

For Case 2: we firstly have the Taylor expansion of 
 as
 
 

Therefore, we can get the expansion
 
 
 

Besides, we also have
 
 Then since we assume that the rank 
 of the matroid  satisfies 
 in the beginning, there must be at least one of the values among 
 or 
 in 
. So we derive the following result directly by Lemma 8:
 
 
 
 
 
 
 
 Then, we have the following inequality through using the expansion again:
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 □

Furthermore, the following corollary gives an additional lower bound of the output 
 of Algorithm 3.

Corollary 10

For an arbitrary base 
 of the matroid  and any , we have

Proof

Firstly, for each iteration we focus on the expected value of the marginal profit
 
 
 where the inequality is given by Corollary 7 by setting 
.

Obviously, we have

Then,
 
 
 
 
 where the first inequality follows from monotonicity with curvature of the set function f. The second can also be obtained from Corollary 7 by setting 
.

Since each element of B is included in 
 with probability 
, we have
 
 
 
 from Lemma 3. By combining the last two inequalities, we get
 
 

Combining with Lemma 9 yields
 Then we eventually have the correctness of this lemma as follows:
 
 
 □

Recall that the Partition algorithm builds two disjoint sets 
 and 
 in the first procedure of the main algorithm. Then the optimal solution OPT is clearly a base of the matroid  because of the assumption of this problem. Then, OPT can be split into two split sets that are respectively denoted by 
 and 
. Based on Lemma 5, 
 and 
 can be considered as supplementary sets of 
 and 
, respectively. Therefore, the unions of 
 and 
 are two bases of the matroid . So we use the next lemma to show the property of 
 and 
 that are the two complementary sets of one of the disjoint sets 
 for the analysis of our main algorithm.

Lemma 11

For 
 and 
 which are the two complementary sets for the set 
, the following inequality holds

Proof

We prove this lemma by using the submodularity and monotonicity of the set function
 where the first inequality holds because of the submodularity of f, the second one is true because f is monotone and the last is guaranteed by Corollary 10 with 
, since 
 is one of the bases of 
 and 
 is the output of the RRG algorithm. □

Consequently, for the outputs generated by the main algorithm, we can get a lower bound on their linear combination.

Lemma 12

For each ,

Proof

Focusing on the first implementation of the RRG algorithm, we know that 
 and 
 are two bases of the contracting matroid 
. Then, we get this following Corollary 10 by setting 
 and 
 where the first inequality follows from Corollary 10. Lemma 5 and Lemma 11 help the second inequality held up. Rearranging and we get
 □

Now we present the proof of Theorem 1 through combining with the previous lemmas.

Proof of Theorem 1

Based on Lemma 12, we assume
 
 

By setting the base as , we can obtain the subsequent inequality according to Lemma 4.

Now focusing on the expected value of T and S output by the main algorithm, we get a lower bound as in the following
 
 
 
 where Lemma 12 leads to the second inequality and the final one is directly guaranteed by Lemma 4. □

Anyhow, the main algorithm is still a randomized procedure since the element selection in Algorithm 3 is probabilistic. Nevertheless, we provide an algorithm in the next chapter for its derandomization and consequently obtain a deterministic algorithm, while retaining all the properties. Moreover, the final deterministic main algorithm remains satisfying the conclusion of Theorem 1.

4. Algorithm derandomization
The following lemma ensures that the perfect matching demanded in the algorithm exists. This guarantees that our algorithm can be successfully derandomized.

Lemma 13

For Algorithm 4, the statements in the following are true:

(1)
For each 
 and 
, 
 is a maximal independent set of the matroid  and each element  occurs 
 times among the sets 
.

(2)
There is a perfect matching for each 
, 
, with a weight no less than
 
 
 

The next corollary summarizes the properties of Algorithm 4, which are similar to the properties of Algorithm 3 that already proved in Section 3. The first conclusion can be seen as Corollary 7 derandomized. For its proof, we remove the expectation and show the relationship between the output and a base of  through using a random set. The second conclusion is the non-randomized form of Corollary 10 which gives a lower bound to the output of Algorithm 4.

Corollary 14

For every base 
 of  and B is the input base of Algorithm 4, the output set S satisfies the following claims:

(1)
, where  is a possibly random set.

(2)
.

5. Conclusion
For generalized submodular maximization with a total curvature  over a matroid constraint, we presented a deterministic approximation algorithm achieving an approximation ratio of 
 
 with respect to the calibrating parameter . The ratio equals 0.5008 when , and equals 1 when  for which the submodular function reduces to a linear function. The result essentially extends the 0.5008-approximation algorithm devised by Buchbinder et al. [2] to general α, while retains the approximation ratio better than 1/2 for the total curvature .