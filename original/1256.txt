Abstract
We study parallel Load Balancing protocols for the client-server distributed model defined as follows. There is a set C of n clients and a set S of n servers where each client has (at most) a constant number d⩾1 of requests that must be assigned to some server. The client set and the server one are connected to each other via a fixed bipartite graph: the requests of client v can only be sent to the servers in its neighborhood N(v). The goal is to assign every client request so as to minimize the maximum load of the servers.

In this setting, efficient parallel protocols are available only for dense topologies. In particular, a simple protocol, named raes, has been recently introduced by Becchetti et al. [1] for regular dense bipartite graphs. They show that this symmetric, non-adaptive protocol achieves constant maximum load with parallel completion time O(log⁡n) and overall work O(n), w.h.p.

Motivated by proximity constraints arising in some client-server systems, we analyze raes over almost-regular bipartite graphs where nodes may have neighborhoods of small size. In detail, we prove that, w.h.p., the raes protocol keeps the same performances as above (in terms of maximum load, completion time, and work complexity, respectively) on any almost-regular bipartite graph with degree Ω(log2⁡n).

Our analysis significantly departs from that in [1] since it requires to cope with non-trivial stochastic-dependence issues on the random choices of the algorithmic process which are due to the worst-case, sparse topology of the underlying graph.

Keywords
Parallel balanced allocations
Balls-into-bins processes
Randomized algorithms

1. Introduction
1.1. The framework and our goal
We study parallel Load Balancing allocation in client-server distributed systems. We have a client-server bipartite graph  where:  is the set of clients, each one having a number of requests which is bounded by some constant ;  is the set of servers; the edge set E represents the client-server assignments which are considered admissible because of proximity constraints (a client can send a request only to the servers in its neighborhood).

The algorithmic goal of the entities is to assign the requests in parallel so as to minimize the maximum server load.2

To analyze the performance of the proposed protocol for the above distributed task, we adopt the standard synchronous distributed model introduced for parallel balls-into-bins processes by Adler et al. in [2]: here, clients and servers are autonomous computing entities that can exchange information (only) over the edges of G. Adler et al. introduce the class of symmetric, non-adaptive protocols and show several tight bounds on the trade-offs between the maximum load and the complexity (i.e. completion time and work complexity3) of the proposed solutions. Informally, a protocol is said to be symmetric if the entities are anonymous, so all the clients (servers) act in the same way and, moreover, all possible request destinations are chosen independently and uniformly at random. The protocol is said to be non-adaptive if each client restricts itself to a fixed number of (possibly random) candidate servers in its neighborhood before communication starts. Symmetric, non-adaptive protocols have the practical merits to be easy to implement and more flexible [2]. Such solutions have interesting applications, such as Load Balancing in communication networks, request scheduling and hashing [3], [4], [5], [6].

We notice that efficient symmetric, non-adaptive protocols are known (only) for dense regular bipartite graphs and almost-tight lower bounds are known for this important class of parallel protocols [2], [1], [7] (see also Subsection 1.3 for a short description of such results).

The main goal of this paper does not consist of improving previous solutions with respect to specific complexity measures. Rather, still aiming at efficient solutions that achieve bounded maximum load,4 we focus on symmetric, non-adaptive Load Balancing protocols that work over restricted, non dense graph topologies. This natural extension of previous work is inspired by possible network applications where: i) based on previous experiences, a client (a server) may decide to send (accept) the requests only to (from) a fixed subset of trusted servers (clients) and/or ii) clients and servers are placed over a metric space so that only non-random client-servers interactions turn out to be feasible because of proximity constraints. Such possible scenarios motivated previous important studies on sequential Load Balancing algorithms [8], [9], [10]. To the best of our knowledge, efficient solutions for non-dense graphs are in fact available only for the classic sequential model. Here, each client request is scheduled once at time so that, for instance, the well-known best-of-k-choices strategy [11] can be applied: the loads of the servers are updated at each assignment and the new considered request is assigned to a server that has the current minimal load out of k servers chosen independently and uniformly at random [8], [9], [10].

The raes Algorithm. As for the parallel distributed model we adopt in this paper, in [1] Becchetti et al. propose a symmetric, non-adaptive algorithm, named raes (for Request a link, then Accept if Enough Space), which is based on the well-known Threshold criterion [2]. This approach has been adopted in the context of simulation of PRAM algorithms over the Distributed Memory Machine (DMM) under the name of c-collision process [12]. Informally, raes works in rounds, each consisting of two phases. Initially, each client has  balls.5 In the first phase of each round, if client u has 
 alive balls (i.e. to be still accepted by some server), u selects 
 servers independently and uniformly at random (with replacement) from . It then submits each of the 
 balls to each selected client. In the second phase of the round, each server accepts all requests received in the first phase of the current round, unless doing so would cause it to exceed the limit of cd accepted balls, where the parameter c is a suitable large constant; if this is the case, the server is said to be saturated and rejects all requests it received in the first phase of the current round. The algorithm completes when every client has no further balls to be submitted.

We observe that servers only give back Boolean answers to the clients requests and, moreover, if the algorithm terminates, the maximum load of the servers will be at most cd. Becchetti et al. prove6 that, over any Δ-regular bipartite graph with , raes terminates within  rounds and the total work is , with high probability7 (for short, w.h.p.).

1.2. Our contribution
We analyze the raes algorithm on every bipartite graph  of degree 
 (recall that ) that satisfies the following almost-regularity property: the ratio between the maximal degree of the servers and the minimal degree of the client is bounded by some absolute constant.

Under this setting, we prove it is possible to set the algorithm parameter c as a sufficiently large constant, such that, for every constant request number d, the raes process terminates within  rounds and requires  work, w.h.p.

The formal definition of almost-regular graphs and the formal statement of the above result are given in Theorem 1, while we here remark that the considered notion of almost regularity allows a certain variance of the degrees of entities of the same type. Just as a (“non-extremal”) example, we may consider a bipartite graph where: most of the clients have (minimal) degree 
, while few of them have degree ; most of the servers have (maximal) degree 
, while few of them have degree .

Algorithm analysis: an overview. In the case of dense graphs, the key-fact exploited by Becchetti et al.'s analysis of the raes algorithm [1] is the following. Since each client has  servers in its neighborhood, it is possible to fix a sufficiently large constant c, such that, at every round, the fraction of non-saturated8 servers in the neighborhood  of every client v is always at least 1/2. Thanks to a basic counting argument, this fact holds deterministically and independently of the previous load configurations yielded by the process. So, every alive client request has probability at least 1/2 to be accepted at each round: this allows to get a logarithmic completion time of raes on dense graphs.

In the case of non-dense graphs (i.e. for node degree ), the key property above does not hold deterministically: the fraction of non-saturated servers in a fixed neighborhood is a random variable that can even take value 1 and, very importantly, it depends on the graph topology and on the random choices performed by the nodes during the previous rounds. This scenario makes the analysis considerably harder than that of the dense case.

To cope with the issues above, we consider a variant of raes, called saer (Stop Accepting if Exceeding Requests) that works like raes with the exception that, whenever a server v, in the second phase of a given round, gets an overall load larger than cd, then v rejects all requests arrived in the first phase of the current round and it becomes burnt. Once a server gets burnt, it will never accept any further request for all successive rounds (see Algorithm 2 in Section 3).

We consider this variant of raes since the notion of burnt server is more restrictive and somewhat more “static” w.r.t. that of saturated servers used in raes: this allows us to analyze the number of burnt servers and that of alive requests in a rigorous way. Moreover, being a natural alternative, its analysis may have a per se interest.

We then show a simple coupling between raes and saer that implies that both the completion time and the work of the former cannot be stochastically larger than those of the latter. Thanks to this result, we can thus focus on the analysis of the saer algorithm. Similarly to raes, if this new version terminates, then each server will have load at most cd and, hence, the main technical issue is to provide a bound (if any) on the number of rounds required by saer to let every client ball assigned to some server. For an arbitrary client v, we look at its server neighborhood  and we establish a clean recursive formula that describes the expected decreasing rate of the overall number 
 of requests that the neighborhood of v receives at round t. This expectation is derived for round t by conditioning on the sequence of the maximum fractions of burnt servers in any client's neighborhood produced by the algorithmic process at rounds . It turns out that, for a sufficiently large c, the conditional expected decreasing rate of 
 is exponential. Then, using a coupling argument, we derive a concentration bound for this rate that holds as long as the conditional expectation of 
 keeps of magnitude . To complete our argument, we consider a further (and final) stage of the process9 that starts when 
: here, we do not look anymore at the decreasing rate of 
, rather we show that, w.h.p., the fraction of burnt servers in  can increase, along a time window of length , by an overall additive factor of magnitude at most . Thanks to this fact, we can then show that the  requests that survived the first stage have high chances to be assigned during this last stage if the latter lasts  additional rounds.

1.3. Previous work
Load Balancing algorithms have been the subject of a long and extremely active line of research with important applications in several topics of Computer Science such as hashing, PRAM simulation, and scheduling. A well-established and effective way to model such problems is by using the classic balls-into-bins processes. In such processes, there are typically m balls that must be assigned to n bins. In what follows, we use this framework to describe those previous results which are more related to the setting of this work.

Sequential algorithms on the complete bipartite graph. It is well-known that if n balls are thrown independently and uniformly at random into n bins, the maximum load of a bin is bounded by , w.h.p. (see for instance [13]). Azar et al. [11] proved the following breakthrough result. Assume the balls are assigned sequentially, one at a time and, for each ball,  bins are chosen independently and uniformly at random, and the ball is assigned to the least full bin (with ties broken arbitrarily). This greedy strategy is also known as “best of k choices”. Then, they prove that the final maximum load is , w.h.p. A similar result was also derived in a different version of the model by Karp et al. in [14]. Berenbrink et al. extended the analysis of the greedy algorithm for the heavily-loaded case  [15]. Then, several versions of this sequential algorithm have been studied by considering, for instance, non-uniform choices in the assignment process [16], [17], [18]. Moreover, several works addressed weighted balls [19], [20], [21], while the case of heterogeneous bins was studied in [18]. Recently, balls-into-bins processes have also been analyzed over game theoretic frameworks [22], [23].

Sequential algorithms on restricted bipartite graphs. Sequential algorithms for restricted balls-bins (i.e. client-server) topologies have been considered in [24], [9], [10]: here, each ball  comes with its admissible cluster of bins and decides its strategy according to the current loads in its cluster determined by the choices of the previous balls 
. In this setting, Kenthapadi and Panigrahy [10] analyze the well-known sequential greedy algorithm [11]: each client u, in turn, chooses a pair of servers uniformly at random from  and assigns the ball to the server having the current minimum load. They prove that, if the size of every  is at least 
, then the greedy algorithm achieves maximum load , w.h.p. In [9], Godfrey analyzed the sequential greedy algorithm on the input model where a random cluster of servers  is assigned to each client u before the algorithm starts. In more detail, each client u places its ball in a uniform-random server among those in  with the current fewest number of balls. He proves that, if the random subsets  are chosen according to any fixed almost-uniform distribution over the server set  and the subsets  have size , then the greedy algorithm achieves optimal maximum load, w.h.p. The overall work is 
, where 
. Further bounds are determined when the overall number m of balls is smaller than the size of the server set . Berenbrink et al. [24] consider the sequential framework adopted in [9] and improve the analysis of the greedy algorithm along different directions. In detail, they consider weaker notions of almost-uniform distributions for the random server clusters assigned to the clients and, moreover, they also consider an input framework formed by deterministic, worst-case server clusters of size . In the case where the overall number of balls is , with any  and , they show that a suitable version of the sequential greedy algorithm achieves maximum load 1, w.h.p. Notice that the greedy algorithm adopted in [10], [9] does require every server to give information to their clients about its current load: in some applications, this feature of the algorithm might yield critical issues in terms of privacy and security of the involved entities [25], [26]. On the other hand, we notice that, the simple threshold approach adopted by both raes and saer can be implemented in a fully decentralized fashion so that the clients cannot get a good approximation about the current load of the servers (see also the remarks after Algorithm 2 in Section 3).

Parallel algorithms on the complete bipartite graph. Inspired by applications arising from parallel distributed systems, a rich and active research has been focused on computational entities which are able to communicate with each other (with some constraints that depend on the specific version of the model). Then, protocols operate in synchronous rounds, in each of which balls and bins exchange messages once. In [2], Adler et al. consider some non-adaptive symmetric protocols and analyze their performances in terms of maximum load, number of rounds, and message complexity. For instance, they introduce a parallelization of the greedy algorithm [11] and show that for any constant number r rounds and for any constant number of random choices k, it achieves maximum load 
, w.h.p. They also give a more complex greedy algorithm that works in  rounds and achieves  maximum load, w.h.p. Interestingly enough, they prove that the above performance trade-offs are essentially optimal for the restricted class of non-adaptive, symmetric algorithms. This class also includes the Threshold algorithms where, informally speaking, at every round, every bin, that receives more than a fixed threshold T of balls, re-throws the excess balls in the next round (such rejected balls can be chosen in an arbitrary “fair” way). Parallel Threshold algorithms have been introduced by Lenzen et al. in [7] for the heavily-loaded case, i.e. when . Finally, we mention some adaptive and/or non-symmetric protocols on the complete graph that have been presented in recent work (e.g. [27], [28], [7], [29]) that achieve significantly better performances than symmetric and/or non-adaptive ones [2]. Such strategies are rather complex and so their setting is far from the aim of this paper (as discussed in the previous subsection, this being the analysis of basic, non-adaptive symmetric protocols over restricted client-server topologies).

Parallel algorithms on restricted bipartite graphs. The only rigorous analysis of parallel protocols for restricted client-server topologies we are aware of is that in [1] by Becchetti et al. for the raes protocol which has been discussed in the previous part of this introduction.

2. Preliminaries
In the Load Balancing problem we have a system formed by a client-server bipartite graph  where:

•
the subset 
 represents the set of clients;

•
the subset 
 represents the set of servers;

•
the edge set E determines, for each client v, the subset  of servers the client v can make a request to (i.e. it can send a ball10). For any node (client or server) , we denote its degree in G as , i.e.  and we define

At the beginning, each client has (at most d) balls where  is an arbitrary constant (w.r.t. n) that, in the sequel, we call request number, and the goal is to design a parallel distributed protocol that assigns each ball of every client  to one server in .

According to previous work [2], [29], we study the Load Balancing problem over the fully-decentralized computational model  where bi-directional node communications take place only along the edges in E, in synchronous rounds. In more detail, each round consists of two phases: in the first phase, each client v sends its unsettled (i.e. alive) balls to a selection of servers in . Then, in the second phase, servers answer to each of the received balls by either accepting or rejecting.

We remark that our considered algorithms work under the following further model constrains: clients may only send the ball IDs11; servers may only answer each ball request with one bit (accept/reject); moreover, there is no global labeling of the nodes of G, each node v just keeps a local labeling of its links.

We analyze the cost of the proposed algorithmic solution with respect to two fundamental complexity measures:

•
the completion time which is defined as the number of rounds required by the protocol to successfully assign all the client balls to the servers;

•
the (overall) work which is defined as the overall number of exchanged messages among the nodes of the network during the protocol's execution.

3. Two simple protocols for Load Balancing and their performances
We analyze two simple protocols for Load Balancing, the first one is called raes (Request a link, then Accept if Enough Space) and it is the one introduced in [1], while the second one is a variant of raes and it is named saer (Stop Accepting if Exceeding Request). They are both based on a simple, non-adaptive threshold criterion the servers use to accept or reject the incoming balls. The protocol is organized in rounds and, in turn, each round consists of two phases. For the sake of readability, we consider the case where every client has exactly d balls, where the request number d is an arbitrary fixed constant: the analysis of the general case (⩽d) is in fact similar.

To analyze the performance of raes we consider its variant, the saer protocol, that adopts a more restrictive way to assign balls to the servers: informally, once a server has received a certain overall number (i.e. a threshold) of balls, it will reject the new balls for all the next steps of the process. The formal description of saer is given in Algorithm 2.

Algorithm 2
Download : Download high-res image (135KB)
Download : Download full-size image
Algorithm 2. Protocol saer(c,d).

Remarks

Some simple facts easily follow from the protocol description above. (i) The protocols complete at round  if and only if every client has successfully placed all its d balls within round T. If this happens, then the maximum load of the servers is clearly bounded by cd. The main technical question is thus to provide bounds in concentration on the completion time of the protocols and on their performed work. This issue will be the subject of the next section.

As for the decentralized implementation, we observe that the knowledge of the parameter c (which, in turn, depends on the degree of the underlying almost-regular bipartite graph - see Theorem 1 in the next subsection) is required only by the servers while clients need no knowledge of global parameters. Interestingly enough, this fact implies that, for reasons of security and/or privacy, the servers may suitably choose c so that the clients cannot get any good approximation of their current load.

3.1. The main theorem
According to the definition of client-server bipartite graphs and those of the two protocols raes and saer we gave above, we can state our main technical contribution as follows.

Theorem 1

Performances of saer and raes processes
For any constants 
 with , and for any sufficiently large , let  be any bipartite graph such that: , 
, and 
. For any constant , consider the Load Balancing problem on G with request number d. Then, for any sufficiently large constant ,12 both the protocols raes and saer have completion time  and their work is , w.h.p.

A simple counting argument implies that 
 for every bipartite graph while Theorem 1 requires the “almost-regularity” hypothesis 
. We remark that this condition allows a relative-large variance of the node degree. For instance, the theorem holds for a topology where: the minimum client degree and the maximum server degree are 
, some clients have degree , while some servers have (minimal) degree .

4. Proof of Theorem 1 for saer
To prove the claim of Theorem 1 for the saer process, in Subsection 4.1, we provide an upper bound on the fraction of burnt servers that holds for each round of a time window of logarithmic length. In Subsection 4.2, we first show how to easily get the logarithmic bound on the completion time and, then, we derive a linear bound on the work performed by this protocol.

4.1. On the fraction of burnt servers
In this section, we prove the claim of Theorem 1 for saer on any bipartite graph  that satisfies the conditions: 
 and 
. Since the protocol saer makes a crucial use of burnt servers, in what follows, we define this notion and some important random variables of the algorithmic process which are related to it. For every round  and every server , let 
 be the random variable indicating the number of balls that server u receives at round t.

Definition 2 Burnt servers

For every integer , we say that a server  is burnt at round t of the process saer if
 
 Moreover, for every client , define 
 as the fraction of burnt servers in the neighborhood of v at time t, i.e.,
 
 We also define 
 as the maximum fraction of burnt nodes in any client's neighborhood at round t, i.e., 
.

The proof of Theorem 1 relies on the following upper bound on the fraction of burnt servers that holds for a time window of logarithmic length.

Lemma 3 On the fraction of burnt servers

Under the hypothesis of Theorem 1, for any constant , it holds(1) 
 
 
 

The next subsection is devoted to the proof of Lemma 3.

4.1.1. Proof of Lemma 3
We start by defining the random variables that describe the saer process.

Definition 4

For every round  and for every client , let 
 be the overall number of balls that all the servers in the neighborhood  receive at round t; moreover, let 
 be the maximum number of balls that every server neighborhood receives at round t. Formally,
 
 

We observe that since a burnt server at round t has received more than cd balls since the start of the process, for every  and every ,(2)
 
 
 We also name the expression in the r.h.s. of the inequality above since it will be often used in our analysis.
Definition 5

For every round  and every client , let
 
 
 

Notice that the above definitions and (2) easily imply that, for every  and every ,(3)
 
 We next write the random variable 
 in terms of more “elementary” random variables.
Definition 6

For every round , client  and ball , let 
 be the binary random variable indicating whether the v's i-th ball is still alive at round t in the saer process, i.e., it has still not been accepted by some server at the beginning of round t. Let 
 be the equivalent random variable in the raes process.

Definition 7

For every round , client , server  and ball , let 
 be the binary random variable indicating whether the (random) contacted server for the v's i-th ball at round t is u in the saer process. Let 
 be the equivalent random variable in the raes process.

Notice that, according to the above definitions, if a ball i is not alive at round t, the corresponding value of the random variables 
 is not relevant for the evolution of the process and, thus, they will not be considered.

Then, for every fixed client  and , we can write(4)
 
  
 
 

The above random variables have the following useful properties.

Lemma 8

1.
For every , ,  and , the random variables 
 and 
 are mutually independent.

2.
For every  and every choice of positive reals 
 for , it holds
 

3.
For every , the random variables 
 are negatively associated.13

Proof

Claim 1 follows from the observation that saer is non-adaptive and symmetric and, hence, at each round, each client  chooses the (random) destination of its i-th request regardless of the value of 
 while the latter determines whether the request is really sent or not.

As for Claim 2, notice that 
 iff v's i-th request has been rejected at each previous round, and this happens iff the destination of the i-th request is a burnt server.

Finally, Claim 3 follows from the fact that, for each , if 
 for  then, for every 
 with 
, it holds that 
. Moreover, for each fixed  the random variables 
 are independent. □

Step-by-step analysis via induction. We first consider the first round of the process and give the following bound on the maximum number of balls a client neighborhood can receive.

Lemma 9 First round

Under the hypothesis of Theorem 1, for every , with probability at least 
, it holds
 
 and(5)
 
 

Proof

The random variable 
 can be written as in (4). Then, since for each  and , 
 is a Bernoulli random variable of parameter , we get
  
 
 
 
 From Claim 3 of Lemma 8, we can apply the Chernoff bound for negatively associated random variables with  (Theorem 23) thus obtaining(6)
 
 
 
 
 
 Observe that the last inequality holds for every sufficiently large n since, in every bipartite graph, we have 
. Finally, from Definition 5, (6) and from a union bound, we get (5). □

The next result is a key step of the proof of Lemma 3. We look at every fixed round  of the random process and derive, for every client , an upper bound in concentration on the random variable 
, assuming some fixed bound on the variable 
. This bound shows that, conditional on the bound sequence above, the number of alive balls in  decreases, at each round t, by a factor that explicit depends on the fraction of burnt servers at round . For every  we give an upper bound on 
 conditional to some fixed upper bound on 
.

Lemma 10

Round  by induction
Under the hypothesis of Theorem 1, for every client  and every real 
(7)
 
 
 Moreover, for every 
,
 

Proof

By expressing 
 as the sum in (4), we can apply the first two claims in Lemma 8 and get
 
 
 In order to get the claimed bound in concentration, we need to apply the Chernoff bound to the sum of random variables of the form 
. To this aim, we know that for every  and every , 
 is a Bernoulli random variable of parameter . However, the distributions of 
 are rather difficult to analyze since there are several correlations among the random variables in 
. To cope with this issue, we exploit Claim 2 of Lemma 8 and construct nd ad-hoc independent Bernoulli random variables, 
 for which:(8)
 
 and such that each 
 stochastically dominates 
. Formally, thanks to (8) and Claim 2 of Lemma 8, we can define a coupling14 between 
 and 
 such that(9) 
 

To define the coupling, we consider nd uniform and independent random variables in , 
 with  and . Given ,  and , we define the following set of random variables:
 which is nothing but the previous random variables of 
 according to the following sorting (
 for some h):

…
.
In the next definition, we will improperly use the term 
 to denote the event in which the random variables 
 of subset 
 take any fixed values in . For every  and , given 
 we define the following two events
 
 Now we can define the coupling. For 
 
 
 Now we show that the coupling is well defined, i.e. the marginal laws are the same of 
 and 
. It's trivial that 
 
 
 We have also that(10) 
 
 
 
 
(11) 
 
 
 
 (10) follows by the independence of the random variables 
 with  and . (11) follows by the chain rule with the same sorting adopted in the definition of 
. It's easy to see that the coupling satisfies (9). Indeed 
 
 
 Indeed, for every  and ,
 since for every 
 
 and we can derive the last inequality from the fact that
 
 By using the coupling, from (9), we get(12)
 
  
 
 
 where  is every positive real that satisfies 
. In detail, (12) follows from (9) and, moreover, to get (12) we apply the Chernoff bound with  for negatively associated random variables (see Theorem 23 in Appendix A). Indeed, Claim 3 of Lemma 8 and (8) imply that the random variables
 conditioning on the event 
, are distributed as Bernoulli ones of parameter 
 and they are negatively associated (see Definition 22 in Appendix A). □
Wrapping up: process analysis in two time stages. Lemma 9, Lemma 10 provide the decreasing rate of the number of alive balls in every fixed , conditioning on the events “
”.

We now need to derive the specific sequence of 
 that effectively works for our process and that leads to Lemma 3. Moreover, we notice that (7) in Lemma 10 (only) allows a sufficiently strong concentration as long as the bound μ we can use on the expectation of 
 keeps of order , while we clearly need to get an effective concentration bound until this value reaches 0.

To address the issues above, we split our analysis in two time stages. Roughly speaking, the first stage proceeds as long as the expectation of 
 is  and we show it is characterized by an exponential decreasing of 
 (see Lemma 11 and Lemma 12). In the second stage, our technical goal is instead to show that the fraction of burnt nodes in  keeps bounded by some constant <1, while neglecting the decreasing rate of the balls received by  (since we cannot anymore get strong concentration bounds on this random variable). Essentially, our analysis shows that: i) the process starts this second stage when the expectation of 
 is ; ii) during a subsequent window of  rounds, the fraction of burnt nodes in  keeps bounded by some constant <1 and, hence, all the alive requests will be successfully assigned, w.h.p.

As for the first stage, we consider the sequence 
 defined by the following recurrence(13)
 
 
 
 
  In Appendix B, we will prove the following properties.

Lemma 11

For every , let 
 be the sequence defined by the recurrence (13). Then, for every , the following facts hold:

•
 is increasing;

•
for all , 
 
.

The next lemma provides some useful concentration bounds on the random variables 
 and 
 for the first stage.

Lemma 12 Stage I: fast decreasing of the active balls

Under the hypothesis of Theorem 1, an integer 
 exists such that, for every ,(14) 
 
 
 
 
 and(15)
 

Proof

We consider 
 as in (13) and apply Lemma 10 for every , with
 
 
 We get, for every ,(16)
 
 
 
 
 
 where the last inequality in (16) holds because, for every , 
. From (3), we know that 
 
, so, using a union bound over all clients v, we get(17)
 
 
 
 
 
 
 
 
 where in the first inequality we also used the definition of 
 given in (13). We now establish when (17) turns to be a “high probability”. Since , Lemma 11 and the fact that 
 ensure that for a sufficiently large n we can take  as the smallest integer for which(18)
 
 and, hence,(19)
 
 Indeed, from of Lemma 11, since , then 
 and so, from (18), we can say that T verifies
 
 
 Finally, by using (19) in (17), we get (14) and (15) for every . □

Lemma 13 Stage II: the fraction of burnt servers keeps small

Under the hypothesis of Theorem 1, there exists  (it can be the same stated in the previous lemma) such that, for every t in the range , 
 
 
 
 and
 
 where
 and 
 is defined in (13) and 
 is defined by the recurrence(20) 
 
 

Proof

At first, we analyze some properties of the sequence 
 in (20). We notice that the sequence is increasing and that, for every  and ,
 
 
 
 
 
 As in the proof of the previous lemma, we take T as the first integer such that(21)
 
 So, for every t such that , (21) and Lemma 10 imply that
 
 
 
 
 
 
 Taking 
 
, for Lemma 10 we get
 
 
 

By a union bound over all the clients , from (3) and from the definition of 
 in (20),
 
 
 
 
 
 □

Remark

The analysis given in the above proof is the key point in which the density hypothesis 
 is required. More in detail, we use this hypothesis to keep 
 constant. In fact, we would need the weaker condition 
, however, we consider here a stronger hypothesis to make the argument simpler.

Lemma 12, Lemma 13 imply Lemma 3. Indeed, for the chain rule, taking 
 and  we get(22)
 
 
 
 where in the first inequality of (22) we used the chain rule, Lemma 12, Lemma 13, while the second last inequality of (22) follows from the binomial inequality, i.e., for every  and for every , 
. Concluding, we have shown that 
 for every , and 
 for all t such that , with probability at least 
. Since , we have that 
 and 
 and, whereas 
, we have that, with probability at least 
, 
 for every t such that .

4.2. On the performance of saer
To complete the proof of Theorem 1, we show the following consequence of Lemma 3.

Corollary 14

Under the assumptions of Theorem 1, the protocol saer has completion time  and its work is , w.h.p.

Proof

Consider every fixed ball of a client . By choosing15 the parameter c as indicated by Lemma 3, (1) implies that the probability the ball is not accepted for all rounds , conditioning on the bound given in Lemma 3, is 
. Then, by applying a union bound for all balls and all clients, and considering the probability of the conditioning event, we get that saer() completes in  rounds, with probability at least 
.

To analyze the overall work performed by saer we proceed using an approach similar to that in the analysis of the Becchetti et al.'s algorithm raes. For every  and every ball , recall the random variable 
 introduced in Definition 6. Then, the random variable counting the total number of requests performed by the clients (plus the relative answers by the servers) to assign the nd balls can be easily bounded by
 
 
 
 To prove that  w.h.p., we show that, for every fixed  and every , it holds(23)
 
 
 
 
 
 
 To this aim, we use the method of bounded differences (see Theorem 24 in Appendix A). We notice that the random variable 
, conditioning on a number k of alive balls at the end of round , can be written as a function of k independent random variables that satisfies the Lipschitz condition with coefficient  (see definition in Theorem 24). Indeed, we define the random variables 
 as the set of alive balls at the end of round t and the random variables 
, taking values in , indicating the server-destination in  the alive ball tries to connect to at round t. The random variables 
 with 
 are mutually independent, and we can write, given the number k of alive balls at round ,
 
 
 The function f satisfies the Lipschitz condition with coefficient  because, if we change one of the values 
, we are changing the destination of a ball from some 
 to some 
. If 
 has received fewer than cd requests since the start of the process, the change of the destination of the i-th ball from 
 to 
 would not have any impact. On the other hand, in the worst case, at most cd balls that try to settle in 
 switch from settled to not settled. A symmetric argument holds for 
 and so if
 then
 Lemma 3 implies that at every round  the fraction of burnt nodes in any node's neighborhood remains bounded by 1/2 with probability at least 
. Therefore, for every  holds
 
 
 
 
 
 
 and we can apply Theorem 24 with  (since ) and , obtaining (23).

From (23) and the chain rule, it follows that for  rounds the number of alive balls decreases at each round by a factor 4/5, w.h.p. Hence, at the end of the T-th round, the number of alive balls is smaller than , w.h.p. From Theorem 1, we know that the remaining  alive balls are assigned within  round: this implies an additional work of . Observe that the work until round T is 
. Hence, for any integer , we get the claimed linear bound for the work complexity of saer(). □

5. Proof of Theorem 1 for raes
Our analysis of the raes process proving Theorem 1 proceeds as follows. We first introduce a suitable coupling between the saer process and the raes one. We then show that this coupling implies an upper bound on the fraction of saturated nodes in the raes process which is similar to that on the number of burnt servers for the saer process we proved in Lemma 3. Then, we apply (in a way similar to what we did for saer) the obtained bound to derive the performance bounds on the raes process.

To analyze the raes process we first need to introduce the following random variables.

Definition 15

Let us consider the raes process. For every  and every , let 
 be the number of balls the server u receives at round t, and let 
 be the total number of balls the server u accepts within round t.

In the raes process, like the saer process, the server never accepts more than cd balls, but in a different and more natural way: a server  rejects the received balls at round t if it gets saturated at round t.

Definition 16

For every integer , we say that a server  is saturated at round t of the process raes if
 Moreover, for every client , let 
 be the fraction of saturated servers in the neighborhood of v at round t, i.e.,
 
 We also define 
 as the maximum fraction of saturated nodes in any client's neighborhood at round t, i.e. 
.

To establish an upper bound on the fraction of saturated servers in the raes process, we introduce a suitable coupling between the saer process and the raes one.

The coupling between saer and raes. Let us consider the raes and saer processes on the same client-server graph  and with the same initial client's requests. Then, informally speaking, our next aim is to show that the maximum fraction of saturated servers 
, according to the saer process, can be “probabilistically” bounded by the maximum fraction of burnt servers 
, according to the raes process. To make this argument rigorous, we use the notion of stochastic domination, denoted as 
, that we recall in Definition 25 in Appendix A. This will allow us to prove a result equivalent to that in Lemma 3 for the raes process. To show that 
, we construct a coupling 
 between the two random variables such that 
. The simple coupling forces, at any round t, any non-settled ball i of a client  to choose the same server destination in the two processes. Essentially, according to this coupling, we easily get that the number of alive balls in the raes process turns out to be never larger than that in the saer process.

Definition 17

For every ,  and , let 
 be the random variables taking values in  indicating the contacted server for the v's i-th ball at round t in the saer process. Let 
 the equivalent random variable in the raes process.

We observe that the random variables 
 are independent, since each server's ball chooses the server destination independently from the other balls. We observe also that, from Definition 7, we have that 
 if and only if 
.

We remark that both processes at each round t are completely described by the random variables 
. Indeed, if we know the destination of each server's ball at each round, we can derive which is the set of saturated/burnt nodes, which balls have been rejected and which requests are still active at each round t. So, we can define the coupling between the two processes thanks to such random variables.

To define the coupling, we introduce the following random variables.

Definition 18

For every , client  and ball , let 
 be the random variable indicating the destination of the i-th's ball of v. Since it is chosen uniformly at random in , it holds that
 
 

Definition 19

Coupling between saer and raes
For every , every client , and every ball , we define the coupling 
 between 
 and 
 such that
 So, in the coupling, each ball  of a client  at each round  chooses the same server destination in both processes raes and saer.

In what follows we will make use of the subscript C to indicate random variables that are defined over the joint probability space the coupling is defined over.

On the fraction of saturated servers. We now use the above coupling to show the analogousness of Lemma 3 for raes.

Lemma 20 On the fraction of saturated servers

Under the hypothesis of Theorem 1, for any , with probability at least 
, it holds that, for every , the fraction of saturated nodes in raes satisfies
 

Proof

To prove the lemma, we use the coupling in Definition 19, to show that, for every round , the random variable 
 is stochastically dominated by 
, i.e.,(24)
 Then, thanks to Lemma 3, we can derive that, for every , it holds 
 
.

We next prove that the considered coupling satisfies (24): in more detail, thanks to Lemma 26 in Appendix A, it suffices to prove that, according to the coupling, for every , it holds(25)

We first prove, by induction on t, that, at each round , if a fixed server  is saturated in raes, then it is also burnt in saer.

As for the first round, we notice that every ball of the clients is alive, and, moreover, a node is saturated iff it is burnt since, at the first round, for each server u, it holds 
 (see Definition 16). Then, by the definition of the coupling, we can state that the two processes are identical, and get the claim for .

As for , we can assume that, for every round , if a server is saturated in raes at round j, it is also burnt in saer at round j and we want to prove the same holds at round t. Notice that, by definition of the coupling, each ball chooses the same destination in both processes. Thus, by induction hypothesis, we have that each ball which is alive in the raes process at round  is also alive in the saer process at round , i.e. for every round , for every client , and for every ball ,
 The above equation implies that, for every round  and for every server , 
. Indeed we have(26)
 
 
 
 
 and, moreover, from the coupling, at every round , for every  and , 
.

Now, we get that if a server  is saturated in raes at round t, then it is also burnt in saer at round t. Indeed, if u is saturated at round t, it holds(27)
 and, since 
, from (26) and (27),
 
 
 It thus follows that the server u is also burnt in the saer process.

This fact implies that for all  and each , the fraction of saturated server in the neighborhood of v in raes is dominated by the fraction of burnt server in raes, i.e. 
 
 and so (25) holds. □

Performance analysis of raes. Theorem 1 is a consequence of Lemma 20: its formal proof proceeds in the same way to that for the saer process in Subsection 4.2 and, thus, it is omitted.

Corollary 21

Under the assumptions of Theorem 1, the protocol raes has completion time  and its work is , w.h.p.

6. Conclusions and future work
We studied two simple parallel Load Balancing protocol and we give a probabilistic analysis of their performances. The main novelty of this paper lies in considering client-server bipartite graphs that are much more sparse than those considered in previous work. This new setting can model important network scenarios where proximity and/or trust issues force very restricted sets of admissible client-server assignments. From a technical point of view, such sparse topologies yield new probabilistic issues that make our analysis more challenging than that for the dense case and rather different from the previous ones.

Several interesting open questions are left open by our paper. In particular, we are intrigued by the analysis of the protocols (or simple variants of them) over graphs with 
 degree and/or in the presence of a dynamic framework where, for instance, the client requests arrive on line and some random topology change may happen during the protocol execution. We discussed the former question in the remark after Lemma 13. As for the latter, we believe that the simple structure of the two considered protocols can well manage such a dynamic scenario and achieves a metastable regime with good performances.