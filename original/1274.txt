Abstract
The Minimum Spanning Tree problem (abbr. MSTP) is a well-known combinatorial optimization problem that has been extensively studied by the researchers in the field of evolutionary computing to theoretically analyze the optimization performance of evolutionary algorithms. Within the paper, we consider a constrained version of the problem named 2-Hop (1,2)-Minimum Spanning Tree problem (abbr. 2H-(1,2)-MSTP) in the context of evolutionary algorithms, which has been shown to be NP-hard. Following how evolutionary algorithms are applied to solve the MSTP, we first consider the evolutionary algorithms with search points in edge-based representation adapted to the 2H-(1,2)-MSTP (including the (1+1) EA, Global Simple Evolutionary Multi-Objective Optimizer and its two variants). More specifically, we separately investigate the upper bounds on their expected time (i.e., the expected number of fitness evaluations) to obtain a 32-approximate solution with respect to different fitness functions. Inspired by the special structure of 2-hop spanning trees, we also consider the (1+1) EA with search points in vertex-based representation that seems not so natural for the problem and give an upper bound on its expected time to obtain a 32-approximate solution, which is better than the above mentioned ones.

Keywords
Minimum spanning tree
Bounded hop minimum spanning tree
2-Hop (1,2)-minimum spanning tree
Evolutionary algorithm
Runtime analysis

1. Introduction
Over the past decades, evolutionary algorithms have been extensively studied to solve the combinatorial optimization problems abstracted from real applications in various areas, including engineering, logistics, and economics. Although the theoretical understanding of the behavior of evolutionary algorithms (more specifically, their expected time) has achieved lots of progress, in particular, for the well-known Traveling Salesperson problem [1], [2], [3], [4], [5], [6], Vertex Cover problem [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], Knapsack problem [18], [19], [20], [21], [22], [23], [24], Makespan Scheduling problem [25], [26], [27], [28], [29], [30], [31], and Minimum Spanning Tree problem [32], [33], [34], [35], [36], [37], etc, its development still lags far behind its success in practical applications.

Within the paper, we study the theoretical performance of evolutionary algorithms for a constrained version of the Minimum Spanning Tree problem (abbr. MSTP), aiming to get insight into their abilities to emulate the local search operations based on their populations and investigate the influence of different representations for search points on their performance. In the following, we start with an introduction to the background of the problem and related work in the field of evolutionary computing. Given an edge-weighted graph G, the MSTP asks for a connected subgraph of G that contains all vertices in G, without any cycle and with the minimum cost, where the cost of the subgraph is defined as the sum of the weights on its edges. It is well-known that the MSTP is polynomial-time solvable, using the classic Prim's algorithm [38] or Kruskal's algorithm [39].

Neumann and Wegener [32] studied the performance of the Randomized Local Search (abbr. RLS) and () EA for the MSTP. Taking advantage of the fitness function that penalizes the disconnectivity of the corresponding subgraph induced by the search point, the expected time of the two algorithms to obtain an optimal solution were shown to have an upper bound 
 and a lower bound 
, where m and n denote the numbers of edges and vertices in the considered graph, respectively, and 
 denotes the maximum weight that the edges have. Considering the case that 
 has a very large value, the upper bound given above was improved to 
 using the technique designed by Reichel and Skutella [40] to adjust the weights of the fitness function. Later Witt [35] further improved the upper bound on the expected time of the () EA to 
 by adaptive drift analysis with a skillful potential function, where  is the circumference (length of the longest cycle) of the underlying graph. Neumann and Wegener [33] studied the performance of the algorithm SEMO (Simple Evolutionary Multi-Objective Optimizer [41]) and GSEMO (Global SEMO) for the MSTP with respect to a two-objective fitness function, which consists of the number of connected components in the corresponding subgraph induced by the search point and the cost of the chosen edges. They showed that the expected time of the two algorithms can be upper bounded by 
.

Kratsch et al. [34] investigated the NP-hard problem, Maximum Leaf Spanning Tree problem (looks for a spanning tree with the maximum number of leaves), by evolutionary algorithms in the context of fixed-parameter tractability [42], [43], where the number of leaves is considered as the parameter. More specifically, they studied whether or not the considered evolutionary algorithm can obtain a feasible solution to the problem in expected FPT-runtime [12], with respect to two mutation operators. Corus et al. [36] examined the NP-hard Generalized MSTP. The problem has an edge-weighted complete graph  with a partition 
 of the vertex set V as input and asks for a subgraph of G with the minimum cost that connects a vertex of each 
. Two approaches for the bi-level optimization problem were considered: Spanned Nodes Representation and Global Structure Representation. The Spanned Nodes Representation first selects in the upper level problem a vertex (called spanned node) from each cluster 
 then finds on the lower level a minimum spanning tree for these spanned nodes. The Global Structure Representation first constructs a complete graph 
 with m vertices (each one corresponds to a cluster 
 in G) and finds in the upper level problem a spanning tree of H, then it selects on the lower level a spanned vertex from each cluster 
. They showed that their specific () EA working with the Spanned Nodes Representation is not a fixed-parameter evolutionary algorithm, whereas the one working with the Global Structure Representation is. Neumann [44] considered the multi-objective version of the MSTP (each edge e in the input graph has a weight vector 
, and 
 is a positive integer for all ) that asks for a Pareto set that contains a minimum spanning tree with respect to each 
. He showed that a simple evolutionary algorithm can obtain a population that is a 2-approximation of the Pareto front. Besides the work mentioned above, there is also an active research line on evolutionary algorithms for the Bounded Diameter MSTP [45], [46], [47], where the problem looks for a spanning tree with the minimum cost such that the number of edges on any path in the tree is upper bounded by some given number.

The constrained version of the MSTP studied in this paper was abstracted from the realistic scenarios of telecommunication network construction, more specifically, connecting several sites to some central one r using a spanning tree with the minimum cost. Considering factors such as transmission delay and reliability, it is natural to constrain the number of hops (i.e., edges) in the unique path connecting any site with r in the required spanning tree by an upper bound k, leading to the k-hop constraint. Thus the realistic problem can be modeled as follows, which is well-known as k-Hop Minimum Spanning Tree problem (abbr. kH-MSTP): Given a complete graph , where each vertex of  corresponds to a unique site (the specific vertex r corresponds to the central site), and the weight function W is defined on the edge-set E (the weight on each edge 
 depends on the cost of the connection between the two sites v and 
), the aim is to find a k-hop spanning tree with the minimum cost (i.e., a spanning tree with the minimum cost such that for any vertex , the unique path connecting v and r in it contains at most k edges).

The kH-MSTP has been studied in literature [48], [49], [50], [51], [52], [53], and it is NP-hard as the 2H-MSTP (i.e., ) was shown to be NP-hard [54]. Manyem and Stallmann showed that the kH-MSTP is not in APX [55], and Althaus et al. proposed an approximation algorithm with ratio  for it [56]. Interestingly, the 2H-MSTP has a close relationship with the classical clustering problems. For example, the 2H-MSTP can be treated as a non-metric version of the well-known Uncapacitated Facility Location problem [57], [58], more specifically, each vertex  can be chosen as a facility with open cost  or a client that should be assigned to a facility 
 with cost 
. Dahl [54] studied the 2H-MSTP from a polyhedral point of view based on a directed formulation. Alfandari and Paschos [59] modeled a real-case network design problem facing by a French telecommunications company as the 2H-MSTP and showed that it cannot be approximated with a ratio better than . The famous Traveling Salesperson problem and Steiner Tree problem have been studied extensively under the (1,2)-setting such that each edge in the considered graph has weight 1 or 2 [60], [61], [62], [63], [64] (one can consider that the weights on the edges are not well-defined, just “small” and “large”). Thus Alfandari and Paschos [59] also investigated the 2H-MSTP under the (1,2)-setting and gave an approximation algorithm with ratio 5/4. Note that the NP-hardness of the 2H-MSTP also holds even under the (1,2)-setting. To our best knowledge, there is no literature on the rigorous runtime analysis of evolutionary algorithms for the kH-MSTP.

In the remainder of the paper, we consider the 2H-MSTP under the (1,2)-setting, called 2-Hop ()-Minimum Spanning Tree problem (abbr. 2H-()-MSTP), in the context of evolutionary algorithms. More specifically, we study the expected time (i.e., the expected number of fitness evaluations) of the considered evolutionary algorithms to obtain an approximate solution to the problem and the corresponding approximation ratio. Our study is to offer insight into the structural property of the problem and get hints for the analysis of evolutionary algorithms for related problems such as the kH-MSTP, Bounded Diameter MSTP, Cluster Median problem, and Facility Location problem.

Literature [36], [65], [66], [67] shows that the choice of representations for search points has an enormous impact on the performance of evolutionary algorithms. Thus, apart from considering the edge-based representation for search points in this paper (i.e., the algorithms look for the edges that are in the optimal solution to the 2H-()-MSTP), we also consider the vertex-based representation for search points that seems not so natural for the problem (i.e., the algorithms look for the neighbors of r in the optimal solution to the 2H-()-MSTP), based on the fact that the optimal solution is easy to construct if the neighbors of r in it are known.

Since a search point (or solution) in edge-based representation may not be feasible (a solution is feasible if it corresponds to a 2-hop spanning tree), we first analyze the performance of the classic () EA (with search points in edge-based representation) to get a feasible solution to the 2H-()-MSTP with respect to a designed fitness function. Assume the considered graph  contains  vertices and m edges. Due to the elitist selection mechanism, if the () EA has obtained a feasible solution, then it needs to “swap” an edge in the spanning tree with an edge not in it (i.e., takes expected time 
) to further improve the maintained solution without introducing any cycle or causing any disconnectivity. Thus we also study a multi-objective evolutionary algorithm, called Global Simple Evolutionary Multi-Objective Optimizer (abbr. GSEMO, with search points in edge-based representation), aiming to avoid the “swap” operation by maintaining a population. The GSEMO keeps a solution with i edges for each  (i.e., its population size is at most ) and can construct a 2-hop spanning tree in the greedy way (as the way of Prim's algorithm and Kruskal's algorithm). However, the large population of the GSEMO may slow down its optimization process, hence we present two variants of the GSEMO, named GSEMO-1 and GSEMO-2, where each of them maintains a population with at most two solutions. We show that the GSEMO-1 and GSEMO-2 can efficiently emulate the “swap” operation and the local search operation with more than two edges, respectively. Afterwards, using the local search technique, we separately analyze the upper bounds on the expected time of the four algorithms mentioned above to get an approximate solution with ratio 3/2. A summary of the obtained results is given in Table 1.


Table 1. Overview of the upper bounds on the expected time of the four algorithms with search points in edge-based representation (namely, the (1 + 1) EA, Global Simple Evolutionary Multi-Objective Optimizer (GSEMO) and its two variants (GSEMO-1 and GSEMO-2)) and the (1 + 1) EA with search points in vertex-based representation to get an approximate solution to the 2H-(1,2)-MSTP with ratio 2 or 3/2. Variables m and n + 1 denote the numbers of edges and vertices in the considered graph, respectively, and m = Θ(n2).

Edge-based representation	Vertex-based representation
Ratio	2 (worst case)	3/2	3/2
() EA		O(m6n)	O(n4)
GSEMO		O(m6n2)	/
GSEMO-1	O(mn)	O(m6n)	/
GSEMO-2		O(m4n)	/
With respect to the vertex-based representation, we only consider the () EA (with search points in vertex-based representation) and show that its performance to get an approximate solution with ratio 3/2 is much better than that of the above mentioned algorithms. There are two reasons for its better performance: (1) the edges are assumed to be connected in a way with the minimum cost based on the neighbors of r specified by the considered solution, i.e., all solutions in vertex-based representation are feasible; (2) an algorithm with search points in vertex-based representation is more efficient than one with search points in edge-based representation to emulate a local search operation. For example, consider a feasible solution x with two vertices v and 
 that are neighbor and not neighbor to r, respectively, and a local search operation on x that makes v and 
 not neighbor and neighbor to r, respectively, in the resulting feasible solution. Then obviously, the () EA with search points in vertex-based representation and the one with search points in edge-based representation take expected time 
 and 
, respectively, to emulate the operation, where  is the number of edges incident to v or 
 in the graph specified by x (as the () EA with search points in edge-based representation considers not only the removal but also the addition of edges to make the resulting solution feasible).

This paper extends and refines the conference version [68]. Firstly, the discussion for the vertex-based representation is newly added. Secondly, for the four algorithms with search points in edge-based representation (including the () EA, GSEMO and its two variants), this paper replaces the previously complicated fitness functions with new ones (Section 3) and gives a completely new discussion for their performance to get a feasible solution (Section 4). Finally, more details of the algorithms and illustrations are included.

The rest of the paper is organized as follows. Section 2 introduces related definitions. Section 3 presents the four considered algorithms with search points in edge-based representation, namely,  EA, GSEMO and its two variants, and Section 4 analyzes their performance to obtain a feasible solution. The in-depth analysis for their performance to get an approximate solution to the 2H-()-MSTP with ratio 3/2 is given in Section 5. Section 6 considers the  EA with search points in vertex-based representation and its performance to get an approximate solution to the 2H-()-MSTP with ratio 3/2. Section 7 is used to conclude this work.

2. Preliminaries
A graph is complete if there is an edge between any two vertices in the graph. Consider a complete edge-weighted graph , where r is a specific vertex that is called the root of G in the remaining context, 
, 
, and  (i.e., G has  vertices including r and m edges). For any vertex , denote by 
 () the set containing all the vertices 
 with 
. For any edge-subset 
, denote by 
 the graph obtained by removing all edges in 
 from G (i.e., 
 and G have the same vertex-set ).

A spanning tree T of  is a subgraph of G that connects all vertices in  and has no cycle. The weight of T is the sum of the weights on its edges. A spanning tree of G is the minimum if it has the minimum weight among all spanning trees of G. The Minimum Spanning Tree problem (abbr. MSTP) on G looks for a subset 
⁎
 of E such that 
⁎
 is a minimum spanning tree of G. As each edge in the considered graph G has weight 1 or 2, the Minimum Spanning Tree problem on G is also called the ()-Minimum Spanning Tree problem (abbr. ()-MSTP) on G in the context.

In the paper a constrained variant of the ()-MSTP on  is studied, named 2-Hop ()-Minimum Spanning Tree problem (abbr. 2H-()-MSTP), which looks for a minimum spanning tree 
⁎
 of G satisfying the 2-hop constraint. Recall that the 2-hop constraint requires that for any vertex , the unique path connecting v and r in 
⁎
 contains at most two edges.

As mentioned in the previous section, two representations for search points are considered: Edge-based representation and vertex-based representation. The search space corresponding to the edge-based representation consists of all bit-strings with fixed length m. That is, for a search point 
 (in edge-based representation), the edge 
 () is chosen if and only if 
. Denote by  the subset of E containing all edges chosen by x. For simplicity of notation, let  be the same graph as . Denote the cost of x by
 

The search space corresponding to the vertex-based representation consists of all bit-strings with fixed length n. That is, for a search point 
 (in vertex-based representation), the vertex 
 () is chosen if and only if 
. Denote by  the subset of V containing all vertices chosen by x. Now based on , an unambiguous way to construct a 2-hop spanning tree  with the minimum cost is given as follows: firstly remove all edges of E from G except the edges between r and the vertices of ; secondly for each vertex , if there is a vertex 
 with 
, then connect v to 
 with an edge, otherwise, connect v to an arbitrarily vertex 
 with an edge. Denote the cost of x (i.e., the sum of weights on the edges in ) by 
 

Note that for any search point x in vertex-based representation,  is always a 2-hop spanning tree of G, i.e., x is always a feasible solution. However, for a search point x in edge-based representation,  may not be a 2-hop spanning tree of G, i.e., x may be an infeasible solution. Thus we have the following notations for the search point x in edge-based representation.

Denote by 
 the number of 1-bits in x (i.e., the Hamming weight of x), 
 the connected component in  that contains the root r, and 
 the number of connected components in . Given two vertices 
 and 
 in , the distance between them, denoted by 
, is defined as the number of edges on the shortest path connecting 
 and 
 in  if they are in the same connected component of ; otherwise,  (as G contains  vertices, the distance between 
 and 
 ranges from 1 to n if 
 is in the same connected component with 
). Denote by 
 the number of vertices  with 
, where  is an integer (i.e., 
 is the number of vertices that are not in the same connected component 
 with r in ). Denote by 
 the number of vertices where they are in the same connected component 
 with r in , but their distances to r are greater than 2.

Using the notations given above, the 2H-()-MSTP can be reformulated as looking for a search point x in edge-based representation with the minimum cost such that 
 and 
 for any vertex .

3. Algorithms with search points in edge-based representation
In the section, we present four evolutionary algorithms with search points in edge-based representation, namely,  EA, Global Simple Evolutionary Multi-Objective Optimizer (abbr. GSEMO) and its two variants (GSEMO-1 and GSEMO-2).

3.1.  EA
The  EA (given in Algorithm 1) starts with an arbitrary solution. In each iteration, the algorithm generates an offspring y based on the maintained solution x using standard bit mutation and accepts y if it is at least as good as x. The scalar-valued fitness function 
 exploited by the () EA is given below, which not only considers the cost of the solution x (term ) but also penalizes the vertices whose distances to r are greater than 2 (term 
) and the excess Hamming weight (term 
) with penalization coefficients 
 and 
, respectively.

Algorithm 1
Download : Download high-res image (43KB)
Download : Download full-size image
Algorithm 1. (1 + 1) EA.

Recall that the graph  considered in the paper is complete (i.e., 
), and , thus the two penalization coefficients 
 and 
 are large enough. The extra factor 2 of the penalization coefficient of the term 
 compared to that of the term 
 helps the algorithm to make a trade-off.

Observe that although the fitness function 
 guides the () EA to find a feasible solution, it has few benefits in improving a feasible solution. For example, assume that the () EA has obtained a feasible solution x. As any infeasible solution cannot be accepted by the algorithm ever again, the () EA needs to apply the “swap” operation to construct a new feasible solution, where the “swap” operation replaces an edge of  with one of  (i.e., flip a 1-bit and a 0-bit in x). Each execution of the “swap” operation takes expected time 
 and cannot be decomposed (i.e., the edge-removal operation and the edge-addition operation should be accomplished at the same time; otherwise, an infeasible solution is constructed). Thus we also consider several multi-objective evolutionary algorithms and try to use their populations to avoid the expensive runtime caused by the “swap” operation.

3.2. Multi-objective evolutionary algorithms
The Global Simple Evolutionary Multi-Objective Optimizer (abbr. GSEMO, given in Algorithm 2) uses a vector-valued fitness function
 where 
 (as the first element of the vector considers the Hamming weight of x, the second one  can ignore the term 
 that is considered in 
). Any optimal solution (in edge-based representation) to the 2H-()-MSTP has exactly Hamming weight n, thus the GSEMO can only keep the solutions with Hamming weights ranging from 0 to n and works in an incremental way to find a feasible solution (as the way of Prim's algorithm and Kruskal's algorithm). For the solutions with Hamming weights over n (as the initial population of the algorithm contains an arbitrary solution), they are defined to be dominated by the solutions with Hamming weights in , where the definition of the dominance in the context of the GSEMO is given as follows. Given two solutions y and z, if at most one of the values 
 and 
 is in , then we set
 otherwise (i.e., both 
 and 
 are in ),
 where 
 says that y dominates z with respect to 
. Solution y strongly dominates z if 
 but 
, written 
.

Algorithm 2
Download : Download high-res image (57KB)
Download : Download full-size image
Algorithm 2. GSEMO.

The GSEMO starts with a population S that contains an arbitrary solution. In each iteration, the GSEMO picks an individual x randomly from S and generates an offspring y based on x using standard bit mutation. If y is not strongly dominated by a solution in S with respect to 
, then all solutions dominated by y with respect to 
 in S are discarded, and y is included into S. By the dominance given above with respect to 
, if S has a solution x with Hamming weight in , then S has neither a solution with the same Hamming weight 
 nor a solution with Hamming weight over n; otherwise, the size of S is exactly 1 (as any two solutions with Hamming weights over n are comparable with respect to 
). Thus the size of S is upper bounded by .

Unfortunately, the large size  of the population maintained by the GSEMO may slow down its optimization process, hence we present a variant of it, named GSEMO-1 (given in Algorithm 3). The GSEMO-1 uses the same fitness function 
 as GSEMO but differs at the notion of dominance between solutions, written 
, whose definition is inspired by that of the dominance 
 given in [69]. Given two solutions y and z, if at most one of the values 
 and 
 is in , then we set
 otherwise,
 where 
 says that y dominates z with respect to 
. Solution y strongly dominates z if 
 but 
, written 
.

Algorithm 3
Download : Download high-res image (58KB)
Download : Download full-size image
Algorithm 3. GSEMO-1.

Consequently, two bit strings y and z are incomparable if and only if both 
 and 
 are in  and 
, implying that the size of the population maintained by the GSEMO-1 can be upper bounded by 2. The purpose to keep such a population that can maintain two solutions with Hamming weights n and  respectively at the same time, is that the solution with Hamming weight  can be an intermediate to accelerate the optimization process of the solution with Hamming weight n. More specifically, consider a “swap” operation on the feasible solution x maintained by the GSEMO-1 that replaces an edge  with an edge in 
 such that the resulting solution has a better fitness than x. Its execution can be split into two separate steps: The first step is including the edge 
, which results in an infeasible solution with Hamming weight  (assume that the infeasible solution can be accepted by the algorithm); the second step is removing the edge e from the infeasible solution to construct a feasible solution. As both the first and second step can be accomplished in runtime , the “swap” operation can be emulated within runtime , not 
.

Inspired by the idea of the GSEMO-1 that maintains an extra infeasible solution with Hamming weight , we design an algorithm that maintains an extra infeasible solution such that replacing exactly one of its edges with a new edge can generate a feasible solution, to further accelerate the optimization process. Thus we have the following notations.

Given a solution x, denote by 
 the subset of V with the minimum size such that adding the edges between r and the vertices of 
 into  obtains a solution 
 with 
. Observe that if 
, then a solution 
 with 
 and 
 (i.e., 
) can be obtained by adding the edge  into  with 
. Note that 
 may contain cycles, but the edges whose removal from 
 obtains a feasible solution is easy to find. Thus we can use the solutions x with 
 as intermediates to promote the optimization process of the maintained solutions. The second variant of the GSEMO, named GSEMO-2, is given in Algorithm 4, using the following vector-valued fitness function
 where 
.

Algorithm 4
Download : Download high-res image (58KB)
Download : Download full-size image
Algorithm 4. GSEMO-2.

Given two solutions y and z, if at most one of 
 and 
 is in , then we set
 otherwise,
 where 
 says that y dominates z with respect 
. Solution y strongly dominates z if 
 but 
, written 
. Consequently, two bit strings y and z are incomparable if and only if both 
 and 
 are in  and 
, implying that the size of the population maintained by the GSEMO-2 can be upper bounded by 2.

Regarding the way to decide whether 
, we first have the observation that 
 if and only if 
 and 
, and 
 if and only if 
. Thus the remaining issue is to decide whether 
 under the assumption that 
 and 
. Unfortunately, it is tedious to list all possible structures of  satisfying 
, so we give a simple way to decide whether 
: For each vertex  that is not a neighbor of r in , adding the edge between v and r into  and deciding whether 
 for the resulting solution 
. If there is such a vertex v, then obviously 
; otherwise, 
.

4. Performance of the four algorithms with search points in edge-based representation for feasible solutions
As  has  vertices, and each edge in E has weight 1 or 2, the weight of a spanning tree in G ranges from n to 2n. Thus we have the observation given below.

Observation

Any feasible solution to the 2H-()-MSTP on G has a worst-case approximation ratio 2.

Given a solution x with 
 (i.e.,  has at least one cycle), the following lemma indicates that  contains 
 edges such that removing any of them obtains a better solution.

Lemma 4.1

Given a solution x with 
, it contains 
 many 1-bits, each of whose flip results in a new solution 
 with 
, 
, and 
.

Proof

Let C be an arbitrary cycle in  (note that C contains at least three edges as the considered graph G is a simple graph). If C is not in the connected component 
 that contains r, then for the solution 
 obtained by a mutation that flips exactly one of the 1-bits in x corresponding to the edges in C, it satisfies the claimed conditions. The discussion for the situation that C is in the connected component 
 is divided into two cases.

Case (1). All vertices in C have distances not greater than 1 to r in . That is, for any vertex , there always exists an edge between v and r in . As C contains at least three edges, it contains an edge 
, where neither 
 nor 
 is r. Additionally, we can derive that for any vertex 
, the shortest path connecting v and r in  cannot contain the edge e. Thus the removal of e would not change the distances of the vertices in V to r. For the solution obtained by the mutation that flips the 1-bit corresponding to the edge e in x and nothing else, it satisfies the claimed conditions.

Case (2). There exists a vertex  whose distance to r is not less than 2. Let P be a shortest path connecting v and r in , and 
 be a neighbor of v in  that is in C, but not in P. Note that 
 cannot be the root r. Denote by 
 the solution obtained by the mutation flipping the 1-bit corresponding to 
 in x and nothing else. In the following discussion, we show that 
. Firstly, as 
 is a subgraph of , we have that(1)

Now we assume that there exists a vertex 
 with 
, but 
. That is, any shortest path connecting 
 and r in  always goes through the edge 
, implying that 
, a contradiction to the assumption. In other words, for any vertex 
, if 
 then 
. Thus 
 and(2)

By Inequalities (1) and (2), we have 
. Then combining the equality with the obvious fact that 
 and 
 shows that 
 satisfies the claimed conditions.

Now we show the existence of 
 many such 1-bits in x. Initialize an edge-set 
. Let C be an arbitrary cycle in 
, and e be the edge in C found by the way mentioned above. Include the edge e into 
. Repeat the above process until 
 has no cycle. Then it is easy to see that 
 contains 
 many edges, and the 
 many 1-bits in x corresponding to the edges in 
 are obtained. □

4.1.  EA with search points in edge-based representation
In the subsection, we study the performance of the  EA with search points in edge-based representation to get a feasible solution to the 2H-()-MSTP on .

Theorem 4.2

The  EA with search points in edge-based representation takes expected time  to obtain a feasible solution to the 2H-()-MSTP on .

Proof

Since the algorithm starts with an arbitrary solution x, the case of 
 (i.e., 
) should be considered. Let 
 be the potential of x, using which we analyze the expected time of the algorithm to obtain a solution 
 with 
 (note that 
 is a feasible solution). The following discussion is divided into three cases based on the value of 
.

Case (I). 
 (i.e., 
). For any vertex v with 
, flipping the 0-bit corresponding to the edge between v and r in x generates a new solution 
 with 
 and 
. Meanwhile, since 
, 
 and 
, implying that the solution 
 can be accepted by the algorithm. Considering the 
 many 0-bits in x that correspond to the edges between r and the vertices v with 
, standard bit mutation selects exactly one of them and nothing else with probability 
 
. Thus combining the probability with the potential decrement mentioned above gives a drift in the potential of 
 
.

Case (II). 
 (i.e., 
). If 
 then the algorithm obtains a feasible solution. Thus in the following discussion, we assume that 
. For any vertex v with 
, flipping the 0-bit corresponding to the edge between v and r in x generates a new solution 
 with 
. However, the flip causes 
, thus 
 and 
, implying that the solution 
 can be accepted by the algorithm. Using the drift analysis similar to that given for Case (I), we can derive that the drift in the potential is 
 
 as well.

Case (III). 
 (i.e., 
). Lemma 4.1 shows that x has 
 many 1-bits, each of whose flip results in a solution 
 with 
, 
 and 
. Thus 
 and 
, implying that the solution 
 can be accepted by the algorithm. Additionally, the analysis similar to that given for Case (II) shows that x has 
 0-bits, each of whose flip results in a solution 
 with 
, 
 and 
. Thus the solution 
 can be accepted by the algorithm as well. Considering all the 
 1-bits and 
 0-bits in x (i.e., at least  bits of x in total), standard bit mutation selects exactly one of them and nothing else with probability 
 
. Then combining the probability with the potential decrement mentioned above gives a drift in the potential of 
 
 as well.

Summarizing the above analysis, the drift in the potential is always 
 
. Since the potential value cannot increase during the optimization process, and it can be upper bounded by 2m where 
, the Multiplicative Drift Theorem [70] gives that the algorithm takes expected time  to find the solution 
 with 
. □

4.2. GSEMO and its variants
In the subsection, we separately study the performance of the GSEMO and its two variants with search points in edge-based representation to get a feasible solution to the 2H-()-MSTP on .

Theorem 4.3

The GSEMO with search points in edge-based representation takes expected time  to obtain a feasible solution to the 2H-()-MSTP on .

Proof

Since the algorithm starts with a population that contains an arbitrary solution, we first consider the expected time of the algorithm to obtain a solution 
 with 
. Let S be the population maintained by the GSEMO, and 
 be the first potential of the GSEMO. Observe that 
 cannot increase during the optimization process by the dominance with respect to 
. Let 
. For the 
 1-bits in 
, standard bit mutation selects exactly one of them and nothing else with probability 
 
 (recall that the population size of the GSEMO is not greater than ), and its execution generates a solution 
 with Hamming weight 
 that can be accepted by the algorithm (according to the dominance with respect to 
). Thus the drift in the potential 
 is 
 
. Combining the drift with the fact that 
, the Multiplicative Drift Theorem [70] gives that the algorithm takes expected time  to find a population with 
.

Now we consider the process of the algorithm to obtain a feasible solution based on the solution 
 (note that 
 cannot be replaced by any solution according to the dominance with respect to 
). Let 
 be the subset of S in which each solution x satisfies 
. As 
 satisfies 
, 
 cannot be empty. Let 
 be the second potential of the GSEMO, and 
. Observe that 
 cannot increase during the optimization process by the dominance with respect to 
, and 
 is a feasible solution if and only if 
. Thus in the following discussion, we assume that 
, i.e., 
.

For any vertex v with 
, flipping the 0-bit corresponding to the edge between v and r in 
 generates a new solution 
 with 
 and 
. If S has a solution 
 with 
, then 
; otherwise, a contradiction to the definition of 
. Thus 
 (if 
 exists), and the solution 
 can be accepted by the algorithm. That is, the potential is decreased by 1. Considering the 
 many 0-bits in x that correspond to the edges between r and the vertices v with 
, standard bit mutation selects exactly one of them and nothing else with probability 
 
. Thus the drift in the potential 
 is 
 
. Combining the drift with the fact that 
, the Multiplicative Drift Theorem [70] gives that the algorithm takes expected time  to find a population with 
, after the acceptance of 
.

Summarizing the above analysis gives that the algorithm takes expected time  to find a feasible solution. □

Theorem 4.4

The GSEMO-1 with search points in edge-based representation takes expected time  to obtain a feasible solution to the 2H-()-MSTP on .

Proof

We first consider the expected time of the algorithm to find a solution with Hamming weight n, using the potential function 
. W.l.o.g., assume that the population S maintained by the GSEMO-1 has no solution x with 
. Then the dominance with respect to 
 indicates that S has a unique solution 
.

Case (1). 
. Observe that 
 has at least 
 many connected components except 
, and G has at least 
 many edges between r and them. Standard bit mutation selects exactly one of the 0-bits corresponding to the 
 many edges in 
 and nothing else with probability 
 
 (recall that the population size of the algorithm can be upper bounded by 2), and its execution generates a new solution 
 with 
 and 
 (as 
). Thus 
, implying that 
 can be accepted by the algorithm, and the potential decreases by 1.

Case (2). 
. Lemma 4.1 shows that there are 
 many 1-bits in 
, each of whose flip results in a new solution 
 with 
 and 
. If 
 has Hamming weight n, then no solution in S is comparable to it with respect to 
; otherwise, 
 dominates 
 with respect to 
 as 
 and 
. Thus we have that 
 can be accepted by the algorithm, and the potential decreases by 1. Since 
, 
, and standard bit mutation selects exactly one of the 0-bits corresponding to the 
 many edges in 
 and nothing else with probability 
 
.

The above discussion shows that the drift in the potential is always 
 
. As , and its value cannot increase during the optimization process by the dominance with respect to 
, the Multiplicative Drift Theorem [70] gives that the algorithm takes expected time  to obtain a population with potential 0, which contains a solution with Hamming weight n. Note that before the acceptance of the solution with Hamming weight n, the population size remains 1.

Now we assume that the population S contains a solution 
 with 
 and consider the expected time of the algorithm to find a feasible solution based on 
. If 
, then 
 is feasible, and the proof is done.

Thus in the following discussion, 
 is assumed to be infeasible, i.e., 
. Let  be a vertex with 
, and 
 be the solution obtained by flipping the 0-bit corresponding to the edge  in 
 and nothing else. Observe that 
 and , thus
 Standard bit mutation selects the 0-bit corresponding to the edge  in 
 and nothing else with probability , thus the algorithm takes expected time  to get 
.

If the population S has no solution with Hamming weight , or 
 for the solution 
 maintained in the population with Hamming weight , then the solution 
 is accepted; otherwise, rejected. In the following discussion, we assume that the population contains a solution 
 with Hamming weight  such that 
.

By Lemma 4.1, there exists a 1-bit in 
 whose flip results in a solution 
 with Hamming weight n such that 
 and 
, where the execution of the corresponding mutation takes expected time . Moreover, for the solution 
, we have
 Let 
 be the solution with Hamming weight n in the population, after the construction of 
. For 
, it has 
.

The update process of the solution with Hamming weight n in the population is illustrated in Fig. 1. Considering the mutation generating 
 and the one generating 
, the algorithm totally takes expected time  to get the improved solution 
 with 
 and

Fig. 1
Download : Download high-res image (27KB)
Download : Download full-size image
Fig. 1. An illustration for the proof of Theorem 4.4. Each rectangle represents a population, and each solid circle represents a solution in the population (note that the hollow circle indicates that the population may or may not have such a solution). The solutions above and below the dashed line have Hamming weight n and n + 1, respectively.

Combining the above conclusion with the fact that the value of 
 can be upper bounded by 
, and that the size of the population can be upper bounded by 2, the Additive Drift Theorem [71] gives that the algorithm takes expected time  to get a solution 
⁎
 with 
⁎
 and 
⁎
 (i.e., 
⁎
 is a feasible solution) starting with the solution 
. Apparently,  is more expensive than the expected time  to get 
, thus we have the claimed expected time  for the GSEMO-1. □

Theorem 4.5

The GSEMO-2 with search points in edge-based representation takes expected time  to obtain a feasible solution to the 2H-()-MSTP on .

Proof

We first analyze the expected time of the algorithm to find a solution 
 with 
, using the potential function 
. W.l.o.g., assume that the population S maintained by the algorithm has no solution x with 
. Then the dominance with respect to 
 indicates that the population S has a unique solution 
.

For a connected component C in 
 except 
, as it has at least one vertex, there is at least one edge between r and C, whose inclusion into 
 generates a new solution 
 with 
. Although 
 may be greater than 
, 
, implying that 
, and 
 dominates 
 with respect to 
. Thus 
 can be accepted by the algorithm, and the potential 
 is decreased by 1. Considering the 
 many such edges between r and the 
 many connected components in 
 except 
, standard bit mutation selects exactly one of them and nothing else with probability 
 
, and the drift in the potential is 
 
.

Combining the drift with the fact 
 and that 
 cannot increase during the optimization process by the dominance with respect to 
, the Multiplicative Drift Theorem [70] gives that the algorithm takes expected time  to find a population with 
, which contains a solution 
 with 
.

Now we analyze the expected time of the algorithm to find a solution 
 with 
 and 
 based on the solution 
, using the potential function 
. Note that after the acceptance of the solution 
, no solution x with 
 can be accepted by the dominance with respect to 
, thus all solutions x considered in the following discussion are assumed to have 
. W.l.o.g., assume that the population S maintained by the algorithm has no solution x with 
. Then the dominance with respect to 
 indicates that the population S has a unique solution 
.

For a vertex 
, including the edge between v and r into 
 generates a new solution 
 with 
 and 
. Thus 
 also can be accepted by the algorithm, and the potential 
 is decreased by at least one. Considering all 0-bits in 
 corresponding to the edges between r and the vertices in 
, standard bit mutation selects exactly one of them and nothing else with probability 
 
, and the drift in the potential 
 is 
 
.

Combining the drift with the fact 
 and that 
 cannot increase during the optimization process by the dominance with respect to 
, the Multiplicative Drift Theorem [70] gives that after the acceptance of 
, the algorithm takes expected time  to find a population with 
, which contains a solution 
 with 
 and 
.

Observe that the solution 
 may contain cycles, i.e., 
. Lemma 4.1 shows that there are 
 1-bits in 
, each of whose flip results in a solution 
 with 
, 
, 
, and 
, implying that 
, 
, and 
 can be accepted by the algorithm. Standard bit mutation selects exactly one of the 1-bits in x corresponding to the 
 (as 
) edges and nothing else with probability 
 
. Combining the probability with the fact 
, we can derive that the algorithm totally takes expected time
 
 
 to find a solution 
⁎
 with 
⁎
 and 
⁎
 starting with the solution 
.

Summarizing the above analysis, the algorithm takes expected time  to obtain a feasible solution of G. □

The above proof of Theorem 4.5 only considers the solution x with 
 in the population maintained by the GSEMO-2. For the other possible solution 
 with 
 in the population, we will show its power to help the algorithm to find a solution with an improved ratio in the next section.

5. Performance of the four algorithms with search points in edge-based representation for 3/2-approximation
The section studies the performance of the four algorithms to get an approximate solution with ratio 3/2 to the 2H-()-MSTP on , based on their abilities to emulate local search operations.

Theorem 5.1

The  EA with search points in edge-based representation takes expected time 
 to obtain a 3/2-approximate solution to the 2H-()-MSTP on .

Proof

Assume that the algorithm has obtained a feasible solution 
. Theorem 4.2 indicates that the process of the algorithm to get 
 takes expected time . In the following discussion, we introduce several operations to optimize 
.

We start with some related notions. As 
 is a spanning tree of G, if we treat the specific vertex r as the root of the tree, then there is a well-defined ancestor-descendant relationship in 
. More specifically, for any edge 
 with endpoints v and 
 in 
, if v is in the unique path connecting 
 and r in 
, then v is the parent of 
, and 
 is a child of v in 
. If 
 has a child 
 in 
, then 
 is a grandchild of v, and v is the grandparent of 
 in 
.

Operation 1

If there is a grandchild 
 of r in 
 such that the edge between 
 and its parent 
 in 
 has weight 2, but 
, then swap the edge 
 with the edge 
. The illustrations of Operation 1 and the following four operations are given in Fig. 2.

Fig. 2
Download : Download high-res image (58KB)
Download : Download full-size image
Fig. 2. Illustrations of Operation 1, Operation 5 considered in Theorem 5.1. In particular, the illustration of Operation 5 given above only considers the case that v2 is a child of r with no children, and v3 is a grandchild of r in G(x1).

Operation 2

If there is a child 
 and a grandchild 
 of r in 
 such that the edge between 
 and its parent 
 (not 
) has weight 2, but 
, then swap the edge 
 with the edge 
.

Operation 3

If there are two children 
 and 
 of r in 
 such that 
 has no child, and 
, then swap the edge 
 with the edge 
.

Obviously, each application of Operation 1, Operation 2, and Operation 3 on 
 gets an improved solution 
 with 
 that can be accepted by the algorithm. Since the mutation corresponding to an application of them can be generated with probability 
, the algorithm takes expected time 
 to get the improved solution 
.

Operation 4

If there is a grandchild 
 of r and a vertex 
 that is either a grandchild or a child with no child of r in 
, such that the edge between 
 and its parent 
 in 
 and the edge 
 have the same weight, but the edge between 
 and its parent 
 (may be r) in 
 has a larger weight than the edge 
, then swap the edges 
 and 
 with the edges 
 and 
.

Each application of Operation 4 on 
 gets an improved solution 
 with 
, which can be accepted by the algorithm. The mutation corresponding to the application can be generated with probability 
, thus the algorithm takes expected time 
 to get 
. Now we consider a grandchild 
 of r in 
 and two vertices 
 and 
, each of which is either a grandchild of r or a child of r with no child in 
. Let 
, 
, and 
 be the parents of 
, 
, and 
, respectively (
 and 
 may be r if 
 and 
 are the children of r in 
).

Operation 5

If 
, but 
, then swap 
, 
, 
 with 
, 
, and 
.

Each application of Operation 5 gets an improved solution 
 with 
 that can be accepted by the algorithm. The mutation corresponding to the application can be generated with probability 
, thus the algorithm takes expected time 
 to get 
.

Summarizing the analysis for the above operations, each application improve the fitness of the maintained solution by 1. Combining the conclusion with the fact that 
 and 
⁎
, where 
⁎
 is an optimal solution to the 2H-()-MSTP on G, we can derive that Operation 1, Operation 5 can be applied at most n times. Thus, starting with 
, the algorithm takes expected time 
 to get a feasible solution 
 on which Operation 1, Operation 5 are not applicable.

Now we analyze the cost of the solution 
. We start with some related notations. Given a feasible solution x, the vertices of V can be partitioned into the following subsets according to the structure of  (an illustration can be found at Fig. 3).

1)
, contains all the vertices , where v is a child of r in , and ;

2)
, contains all the vertices , where v is a child of r in , and ;

3)
, contains all the vertices , where v is a grandchild of r in , and  (p is the parent of v in );

4)
, contains all the vertices , where v is a grandchild of r in , and  (p is the parent of v in ).

Moreover, the vertices in 
 are partitioned into the following two subsets.
1)
, contains all the vertices 
, where v has no child in ;

2)
, contains all the vertices 
, where v has at least one child in .

Fig. 3
Download : Download high-res image (53KB)
Download : Download full-size image
Fig. 3. An illustration for the partition of the vertices in G(x1). The thickness of edges is used to distinguish the weights on the edges: Thin ones have weight 1, and thick ones have weight 2.

Consider a vertex 
. Firstly, 
 for any vertex 
; otherwise, Operation 1 or 2 or 3 is applicable on 
. Then 
 for any vertex 
; otherwise, Operation 4 is applicable on 
. Thus, 
 for any vertex 
. If there exists a vertex 
 with 
, then 
; otherwise, Operation 4 is applicable on 
.

Let 
 be a vertex of 
 with 
 (recall that 
 is the set containing all the vertices 
 in G with 
). The above analysis shows that 
). Now we consider the possible cases for the vertex 
 in 
⁎
, where 
⁎
 is an optimal solution to the 2H-()-MSTP on G. If the parent 
 of 
 in 
⁎
 is a vertex of 
, then the edge between 
 and 
 in 
⁎
 has weight 2; otherwise (i.e., 
), the above analysis shows that the edge between 
 and its parent r in 
⁎
 has weight 2.

Assume that the parent 
 of 
 in 
⁎
 is a vertex of 
, where 
. We have that if there is a vertex 
 in 
 that is also the child of 
 in 
⁎
, then 
; otherwise, Operation 5 is applicable on 
 with respect to 
, 
, and 
. That is, there is no vertex 
 in 
 with 
. In other words, if there is a subset 
 in which the vertices have the same common parent p in 
⁎
, then one of the following three cases holds:

Case (I). p is the vertex r, thus all the edges between p and the vertices in 
 have weight 2;

Case (II). p is a child of r, and there is exactly one vertex 
 with 
. That is, all edges between p and the vertices in 
 have weight 2, the edge  has weight 1, and the edge  has weight 2;

Case (III). p is a child of r, and there is no vertex 
 with 
. That is, all edges between p and the vertices in 
 have weight 2.

Summarizing the above analysis, we have
⁎
 The following inequality can be easily derived, where the last inequality relation holds because each vertex in 
 has at least one child in 
, i.e., 
.

Therefore, the approximation ratio of 
 is
⁎
 
 
 

The above conclusion gives that the algorithm takes expected time 
 to obtain an approximate solution with ratio 3/2. □

Using almost the same reasoning given in the proof for Theorem 5.1 and the population sizes of the GSEMO and GSEMO-1, we can get the following theorem.

Theorem 5.2

The GSEMO and GSEMO-1 with search points in edge-based representation take expected time 
 and 
, respectively, to obtain a 3/2-approximate solution to the 2H-()-MSTP on .

Now we consider the performance of the GSEMO-2 to obtain a 3/2-approximate solution, based on the first four local search operations given in the proof for Theorem 5.1 and two new local search operations.

Theorem 5.3

The GSEMO-2 with edge-based representation takes expected time 
 to obtain a 3/2-approximate solution to the 2H-()-MSTP on .

Proof

(See Fig. 4.) Assume that the algorithm has obtained a population that contains a feasible solution 
, i.e., 
 and 
. Theorem 4.5 shows that the algorithm takes expected time  to get such a population. In the following discussion, several local search operations are introduced to optimize 
, including Operation 1, Operation 4 given in the proof for Theorem 5.1 and two new operations given below. Consider a grandchild 
 of r and two vertices 
 and 
, each of which is either a grandchild of r or a child of r with no child in 
. Let 
 and 
 be the parents of 
 and 
, respectively (
 and 
 may be r if 
 and 
 are the children of r in 
).

Fig. 4
Download : Download high-res image (17KB)
Download : Download full-size image
Fig. 4. An illustration for the proof of Theorem 5.3. Each rectangle represents a population, and each solid circle represents a solution in the population (note that the hollow circle indicates that the population may or may not have such a solution). For each solution x, if it locates above the dashed line, then |Vd(x)| = 0; otherwise, |Vd(x)| = 1.

Operation 6

If 
, 
, and the population has no solution except 
 or the other solution 
 with 
 in the population has 
, then swap the edges 
 and 
 in 
 with 
 and 
.

If Operation 6 is applicable, then the obtained solution 
 has 
, 
, 
, 
 and 
, implying that 
 can be accepted by the algorithm. Thus after the trial of Operation 6, the population contains a solution 
 with 
 and 
. As 
 and 
, 
 and 
. Denote by v the unique vertex in 
, and p the parent of v in 
.

Operation 7

If 
, where 
 is the solution in the population with 
, then swap the edge  in 
 with the edge .

Note that 
 may be different from the above mentioned solution 
, as during the phase that after the trial of Operation 6 but before the trial of Operation 7, 
 may be replaced by other solutions. Thus 
 and 
. If Operation 7 is applicable, then the obtained solution 
 has 
, 
 and 
, i.e., 
 is a feasible solution. As the edges  and  may have weights 1 and 2, respectively, 
. Therefore,
 That is, if Operation 7 is applicable, then the obtained solution 
 can be accepted by the algorithm, replacing the maintained feasible solution 
; otherwise, 
, implying 
. Thus after the trial of Operation 7, the population contains a feasible solution 
 with 
.

Summarizing the above analysis, the trials of Operation 6, Operation 7 can emulate Operation 5 given in the proof for Theorem 5.1 and improve the cost of the feasible solution in the population by at least 1. The update process of the solutions is given in Fig. 4. The mutations corresponding to Operation 6, Operation 7 can be generated with probability 
 and 
, respectively, i.e., the algorithm totally takes expected time 
.

Since 
 and 
⁎
, where 
⁎
 is an optimal solution to the 2H-()-MSTP on G, Operation 1, Operation 4, Operation 6, Operation 7 can be applied at most  times. That is, starting with 
, the algorithm takes expected time 
 to get a feasible solution 
 on which Operation 1, Operation 4, Operation 6, Operation 7 are not applicable. The reasoning given in the proof for Theorem 5.1 implies that 
 has approximation ratio 3/2. □

By the proof for Theorem 5.1, it is not hard to see that the traditional local search algorithm (more specifically, the algorithm has to consider all the edges involved in each local search operation simultaneously) takes time 
 to get a 3/2-approximate solution to the 2H-()-MSTP. Thus the GSEMO-2 has a better upper bound on the time complexity than the traditional local search algorithm (note that the time complexity of the GSEMO-2 is expected), and the mechanism to tolerate some infeasible solutions in the population as intermediates to accelerate the emulation of local search operations is efficient.

6. Performance of the  EA with search points in vertex-based representation for 3/2-approximation
The section considers the () EA (given in Algorithm 1) with search points in vertex-based representation and studies its performance with respect to a trivial fitness function 
 (as all search points in vertex-based representation are feasible, it is unnecessary to penalize their infeasibility). Recall that a search point x in vertex-based representation is represented as a bit string with length n, thus the probability  given in Step 4 of the  EA (see Algorithm 1) should be replaced with .

Theorem 6.1

The  EA with search points in vertex-based representation takes expected time 
 to obtain a 3/2-approximate solution to the 2H-()-MSTP on .

Proof

The proof for Theorem 5.1 shows that if Operation 1, Operation 5 are not applicable on a 2-hop spanning tree, then it is a 3/2-approximate solution to the 2H-()-MSTP on . Thus in the following discussion, we analyze the expected time of the  EA with search points in vertex-based representation to emulate the five local search operations.

Let x be the solution maintained by the algorithm. Recall that the vertices of  are connected to the vertices of  with the minimum cost in , thus the algorithm emulates the five operations by adjusting the vertices chosen by x. The case indicated by Operation 1 (see the illustration given in Fig. 2a) shows that 
 but 
. Thus Operation 1 can be emulated by flipping the bit corresponding to 
 in x from 0 to 1, and the algorithm takes expected time  to generate the mutation. Similar analysis can be applied to Operation 3, and the algorithm takes expected time  to emulate it.

The case indicated by Operation 2 (see the illustration given in Fig. 2b) shows that 
 and 
. Thus 
 should be connected to a vertex of  with the minimum cost in . However, the condition of Operation 2 that 
 indicates that 
 is not connected in the optimal way, a contradiction. Therefore, the case indicated by Operation 2 does not exist in .

For Operation 4 (see the illustration given in Fig. 2d), if 
 is a child of r in , i.e., 
, then it can be emulated by flipping the bit corresponding to 
 from 0 to 1 and the bit corresponding to 
 from 1 to 0; if 
 is a grandchild of r in , i.e., 
, then it can be emulated by flipping the bit corresponding to 
 from 0 to 1. Considering the above two cases for Operation 4, the algorithm takes expected time 
 to emulate it.

For Operation 5 (see the illustration given in Fig. 2e), if 
 and 
 are the children of r in , then it can be emulated by flipping the bit corresponding to 
 from 0 to 1 and the bits corresponding to 
 and 
 from 1 to 0; if exactly one of 
 and 
 (say 
) is the child of r in , then it can be emulated by flipping the bit corresponding to 
 from 0 to 1 and the bit corresponding to 
 from 1 to 0; if neither 
 nor 
 is the child of r in , then it can be emulated by flipping the bit corresponding to 
 from 0 to 1. Considering the above three cases for Operation 5, the algorithm takes expected time 
 to emulate it.

Each application of Operation 1, Operation 5 improves the fitness of the solution by at least one. As  and 
⁎
, where 
⁎
 is an optimal solution to the 2H-()-MSTP on , the process of the algorithm to obtain a solution on which Operation 1, Operation 5 are not applicable contains at most n many applications of the five operations. Combining the above conclusion with the expected time of the algorithm to emulate them, we can derive that the process takes expected runtime 
, i.e., the algorithm obtains a 3/2-approximate solution to the problem within expected time 
. □

7. Conclusion
In the paper we studied a constrained version of the Minimum Spanning Tree problem, named 2-Hop ()-Minimum Spanning Tree problem (abbr. 2H-()-MSTP), on a complete edge-weighted graph in which each edge has weight 1 or 2. As the 2H-()-MSTP is NP-hard, we investigated the expected time of several evolutionary algorithms designed for it to obtain an approximate solution to the problem with a target ratio. Two representations for the search points were considered: Edge-based representation and vertex-based representation.

For the edge-based representation, a solution represented in this way may be infeasible, so firstly, we investigated the expected time of the () EA and GSEMO to obtain a feasible solution to the problem. Observed that the large population of the GSEMO slows its optimization process, hence we presented its two variants (namely, GSEMO-1 and GSEMO-2), where each of them maintains a population with at most two solutions (a feasible one and an infeasible one). The analysis for the performance of the two variants showed that the interplay between the two solutions can accelerate the optimization process. Secondly, by introducing several local search operations, we investigated the performance of the four algorithms mentioned above to get an approximate solution with ratio 3/2 to the 2H-()-MSTP. By comparing the expected time of the () EA and GSEMO-2 for 3/2 approximations, it is easy to see that the mechanism of the GSEMO-2 keeping a feasible solution and an infeasible one in the population has an advantage over the classic local search technique. That is because the local search operation with the worst expected time can be decomposed into two operations under the mechanism of the GSEMO-2, moreover, the two operations do not required to be accomplished at the same time.

For the vertex-based representation, the considered algorithm  EA only needs to select the vertices that are neighbor to r, as all the other vertices are assumed to be connected to the neighbors of r with the minimum cost. Thus the local search operations mentioned above that swap edges can be reformulated as the local search operations that swap vertices. Moreover, the number of vertices participating in a local search operation is less than that of the participating edges. Thus the expected time of the  EA with search points in vertex-based representation to emulate these local search operations can be improved significantly. Consequently, the  EA with search points in vertex-based representation is shown to have better performance to obtain an approximate solution with ratio 3/2 to the 2H-()-MSTP, compared with the  EA with search points in edge-based representation.

It is not hard to see that the reasoning given in the paper can be adapted to the 2H-()-MSTP on a complete edge-weighted graph, in which each edge has weight 1 or α (α is an integer greater than 2). Moreover, the ideas (in particular, the mechanism of the GSEMO-1 and GSEMO-2 keeping a feasible solution and an infeasible solution) and reasoning introduced in the paper may be applied to design and analyze the evolutionary algorithms for the Bounded Diameter MSTP, the Uncapacitated Facility problem, the Cluster Median problem, and the generalized versions of the 2H-()-MSTP, where the constraint on the number of hops is relaxed to an integer , or the weight on each edge in the input graph has more than two options. Future work on these problems would be interesting and enrich the theoretical results for the behaviors of the evolutionary computing.