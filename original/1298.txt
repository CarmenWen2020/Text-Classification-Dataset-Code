Abstract
At SCN 2018, Fiore and Pagnin proposed a generic compiler (called “Matrioska”) allowing to transform sufficiently expressive single-key homomorphic signatures (SKHSs) into multi-key homomorphic signatures (MKHSs) under falsifiable assumptions in the standard model. Matrioska is designed for homomorphic signatures that support programs represented as circuits. The MKHS schemes obtained through Matrioska support the evaluation and verification of arbitrary circuits over data signed from multiple users, but they require the underlying SKHS scheme to work with circuits whose size is exponential in the number of users, and thus can only support a constant number of users.

In this work, we propose a new generic compiler to convert an SKHS scheme into an MKHS scheme. Our compiler is a generalization of Matrioska for homomorphic signatures that support programs in any model of computation. When instantiated with SKHS for circuits, we recover the Matrioska compiler of Fiore and Pagnin. As an additional contribution, we show how to instantiate our generic compiler in the Turing Machines (TM) model and argue that this instantiation allows to overcome some limitations of Matrioska:
•
First, the MKHS we obtain require the underlying SKHS to support TMs whose size depends only linearly in the number of users.

•
Second, when instantiated with an SKHS with succinctness  and fast enough verification time, e.g.,  or  (where T, S, and n are the running time, description size, and input length of the program to verify, respectively), our compiler yields an MKHS in which the time complexity of both the prover and the verifier remains  even if executed on programs with inputs from  users.

While we leave constructing an SKHS with these efficiency properties as an open problem, we make one step towards this goal by proposing an SKHS scheme with verification time  under falsifiable assumptions in the standard model

Keywords
Homomorphic authenticators
Turing machines
Secure delegation of computations

1. Introduction
Consider a user Alice who outsources storage of her data x to a powerful server, and let Bob be another user (also referred here as client) who wants to evaluate a public function f on Alice's data x. Since x may be very large (and f may be expensive) Bob can delegate this computation to the server which evaluates  and returns y to Bob. How can Bob be convinced that the server's computation was done correctly, when receiving only a small amount of information (i.e., much less than the size of x)?

Homomorphic signatures [7] provide a generic solution to this problem. In homomorphic signatures, Alice has a private signing key sk corresponding to a public verification key pk that is known to anyone, including Bob and the server. Alice sends to the server x along with a signature σ on x. The server can now compute y as before, and homomorphically generate a signature 
⁎
 proving that indeed . A distinguishing property of homomorphic signatures is that the size of 
⁎
 is significantly smaller than that of x, i.e., logarithmic or constant in . Note that without such requirement homomorphic signatures could be trivially realized from regular digital signatures as the server could send to Bob x and Alice's signature on it. If the computational efficiency of verifying 
⁎
 with respect to f is also a concern (namely, it is too expensive for Bob), some works introduced the notion of efficient verification. The idea is that Bob can do a one-time preprocessing for the function f, and later verify any signatures for f's outputs in constant time.

Multi-key homomorphic signatures (MKHSs) [15] are a generalization of homomorphic signatures (from hereon referred to as “single-key homomorphic signatures”, SKHS, for distinction) to  users. In MKHS, each user has a pair of keys 
 and signs its own input 
 obtaining a signature 
 that is outsourced to the server (along with the corresponding input). The server now computes 
 and homomorphically evaluates a signature 
⁎
 proving that y was computed correctly. Verification of 
⁎
 now requires the public keys of all the clients.

MKHS were introduced by Fiore et al. [15] who proposed a construction based on lattices. In 2018, Fiore and Pagnin [16] proposed a generic compiler (called Matrioska) for turning SKHSs into MKHSs. Using their transform, each user can sign its own input using the signing algorithm of the underlying SKHS. Matrioska exploits the homomorphic property of the SKHS to combine the signatures from different clients in t steps. The length of the final signature 
⁎
 is , where ℓ is the signature length in the underlying SKHS.

Although the result of [16] establishes a general connection between SKHSs and MKHSs, this result is limited to the case when the number of users is a small constant. The reason of this limitation is that, in order to create an MKHS scheme that supports the evaluation of a circuit of size s, the Matrioska compiler needs to start from an SKHS that supports a circuit of size 
, where c is some constant that depends on the SKHS scheme.

This double-exponential dependence on t stems from the compiler's approach of [16] in which one builds t circuits such that, roughly speaking, the circuit at step i takes as input the description of the circuit built in the previous step . So, by assuming that each circuit has size polynomial in its input length, the growth is double-exponential.

1.1. Our results
The first contribution of our work is the proposal of a new generic compiler for turning an SKHS into an MKHS and that supports the evaluation and verification of programs represented in any model of computation.

We designed our compiler by abstracting away the compiler of [16] (that was designed to work specifically for programs represented as circuits) in order to support general computational models. Such abstraction allows us to separate the steps of the compiler that rely on the properties of the SKHS from those steps that instead solely depend on the given computational model. We believe this separation also offers a better explanation of the Matrioska compiler. A crucial building block for the steps unrelated to the SKHS scheme is an algorithm, called , that on input the description of a function F and a portion of the input x (the suffix 
 that we want to fix in the description of the function), outputs the description of another function 
 that is the partial application of F on 
, i.e., s.t. for any 
, 
.

A bit more precisely, to be used in our compiler, this  algorithm must satisfy some other properties related to efficiently locating the fixed input in 
 description and to recursively applying  (due to the high technicality of these properties we refer to Section 4.1 for more details).

Therefore, to instantiate our compiler in a given model of computation one needs to plug in two main ingredients: an SKHS and the implementation of , both for programs described in the given model.

Since our compiler is abstract we cannot provide a concrete efficiency analysis of the MKHS it produces. What we provide generically, though, is a framework to conduct such analysis based on the following parameters:

•
the efficiency of the SKHS verification algorithm, expressed as two functions 
 and 
 that determine the running time and the description size of the verification algorithm in terms of the running time T and size S of the program to verify;

•
the efficiency of the  function, i.e., the size and running time of the function with hardcoded inputs that it returns.

The second parameter, the efficiency of , is specific to the computational model as its implementation (and complexity) depends on how programs are represented. The first parameter, the efficiency of SKHS verification, is specific to the SKHS scheme one starts from. To test our compiler we consider five representative cases that span from a realistic one (i.e., the one achieved by the SKHS of [21] where verification would take time ) to a nearly optimal one, where the verification time is  (where T, S, and n are the running time, description size, and input length of the program to verify, respectively).
Next, we show that the Matrioska compiler of [16] can be seen as an instantiation of our compiler in the circuits model. For this case we revisit the efficiency analysis of [16] that estimate the size of the circuits supported by the SKHS scheme in order to be used to create an MKHS for t users. We show that, even under the most favorable assumption about the SKHS verification, i.e., , the SKHS must support circuits of size at least exponential in t. Such lower bound somehow shows the limits of applying this compiler to the circuits model.

Our second main contribution is then to propose an instantiation of our compiler for programs represented as (multi-tape) Turing machines. In particular, our technical contribution is the design of the  algorithm for programs represented as TMs thanks to which we can overcome the aforementioned limitations of the circuits model (and of the Matrioska compiler). The first advantage of our compiler for TMs is that, independently of the efficiency of the SKHS verification, we obtain an MKHS scheme that supports the multi-key evaluation of a TM of size S for t users, starting from an SKHS scheme that supports TMs of size, roughly, 
, where 
 is the (fixed) size of the TM expressing the SKHS scheme's verification algorithm. Namely, with respect to the size of the TMs, we obtain only a linear dependence on the number of users. In contrast, in the original Matrioska transform, the circuits size supported by the SKHS scheme must be exponentially smaller than that supported in the multi-key evaluation. The second advantage is that, by assuming the underlying SKHS to have verification times (
, 
, or 
), we obtain an MKHS in which the underlying SKHS is executed on programs whose running time depends only linearly on t. This means that our compiler yields an MKHS that can support up to  number of users In contrast, in the circuit model, under the same assumption about 
, the compiler yields an MKHS that can support constant number of users. We defer the reader to Section 6.3 for the detailed analysis.

Towards efficiently instantiating our compiler  To the best of our knowledge, no existing SKHS directly supports Turing machines, and thus our compiler needs to take into account the overhead required to represent Turing machines as circuits. If we consider the state-of-the-art SKHS [21], its verification time for a TM running in time at most T is , which does not fit the most efficient cases of our compiler mentioned earlier (i.e., those allowing to support a super-constant number of users).

As the last contribution of this paper, we make progress towards closing this gap. In particular, we show how to construct an efficiently verifiable SKHS with verification time 
 
 from any SKHS with verification time T. The latter is achieved leveraging so-called non-interactive delegation systems, which exist under falsifiable assumptions in the standard model [23]. The only drawback is that the signature length is 
 
, and thus still depends on T. When using the SKHS scheme of [21] in the instantiation, we can obtain a single-key scheme with verification time 
 that for the sake of our compiler needs to support TMs running up to 
 time. We leave it as an open problem to design a delegation scheme with better succinctness, which would directly allow our MKHS compiler to have a polynomial verification time, and thus support an arbitrary polynomial number of users.

1.2. Paper organization
In Section 2, we review known constructions of homomorphic signatures. We recall a few standard preliminaries in Section 3. The general definition of the compiler is described and analyzed in Section 4. We recall the original Matrioska compiler in Section 5 and do an efficiency analysis of this compiler. In Section 6, we proposed our TM-based compiler and analyzed its efficiency. Finally, in Section 7, we propose a generic transform for improving the verification time of SKHSs. We conclude our paper in Section 8.

2. Related work
Homomorphic signatures were introduced by Johnson et al. [22], and the first scheme for computing linear functions over signed vectors was proposed by Boneh et al. [6]. Several works then proposed constructions of linearly-homomorphic signatures [1], [8], [3], [11], [12], [18], [4], [25], [9], [14], [10]. Only a few works propose constructions that support more expressive functions such as polynomials [7], [13] and circuits of bounded polynomial depth [21].

In [15], Fiore et al. introduced multi-key homomorphic signatures and showed a construction for functions represented as circuits with bounded depth under standard lattice-based assumptions. Compared to the scheme in [15], the MKHS schemes obtained from our compiler perform worse, as [15] can tolerate a polynomial number of users while keeping the complexity of the scheme polynomial-time. However we stress that [15] builds a scheme based on specific algebraic techniques, whereas the goal of our work is to establish a general result that works for any SKHS. Lai et al. [24] show how to construct MKHSs using SNARKs and standard digital signatures; however, SNARKS inherently require non-falsifiable assumptions [20]. More recently, Schabhüser et al. [26] and Aranha et al. [2] construct MKHSs supporting linear functions using bilinear maps.

3. Preliminaries
Notation. Let λ be the security parameter,  be a message space,  be a polynomial function based on λ, and let . The notation 
 denotes uniformly sampling a value s from a set S. A function  said to be negligible in λ, if for every polynomial p, there exists an integer N such that for all integers , 
 
. If A is a probabilistic algorithm (i.e., it uses random coins),  denotes assigning the output of the execution of A to the variable y. We use the notation  for a constant value and  for a fixed polynomial based on the security parameter λ.

3.1. Homomorphic signature schemes
In this section, we first recall the notion of labeled programs introduced by Gennaro and Wichs [19] and extended by Fiore et al. [15] for programs with inputs from more than one user. Then, we review the definitions of SKHS and MKHS schemes and the correctness, succinctness, and security properties of them.

Labeled programs  The input program in most single-key and multi-key homomorphic signature schemes is modeled as a labeled program. A labeled program 
 consists of an n-variate function 
 and a set of labels 
⁎
. Labeled programs 
,...,
 can be composed using a function 
. The function G evaluates on the outputs of 
. The inputs of the composed program 
⁎
 are all distinct inputs of the labeled programs 
 (the inputs with the same labels are grouped together). For multi-key homomorphic signatures [15], the identity of the user (i.e. id) are added to the labels such that  where τ is a tag. Actually, τ is a string to determine a data item in a set of inputs generated by the user with identity id.

Multi-labeled programs [5]  A multi-labeled program 
 is a pair , where  is a labeled program and 
⁎
 is a dataset identifier. Multi-labeled programs 
 with the same Δ, can also be composed using a function 
 as 
⁎
.

In SKHS schemes, labels in a labeled program are tags used to specify on which inputs, among a set of data items, the program is to be executed.

Definition 1

Multi-key homomorphic signature scheme [15]
A multi-key homomorphic signature scheme is a tuple of the following five probabilistic polynomial time (PPT) algorithms 
, .

-
: given the security parameter λ, this algorithm outputs the public parameter  which is the default input of other algorithms. This parameter describes a message space , a label space , where  is an identity space and  is a tag space, a signature space , and a set of admissible functions 
.

-
: given the public parameter pp, this algorithm outputs a secret key sk and a public key pk.

-
: given the secret key sk, a dataset identifier 
, a message , and a label of the message , this algorithm outputs a signature .

-
: given a labeled program , a dataset identifier 
, and a set of public key and signature pairs 
, this algorithm outputs an authenticator 
 that is supposed to vouch for the correctness of the result message 
.

-
: given a labeled program , a dataset identifier 
, a set of public keys for identities contributed in , an authenticator 
, and a message , this algorithm outputs  for accepting or  for rejecting the result.

MKHS correctness  An MKHS scheme is correct if it has the authentication correctness and evaluation correctness properties defined as follows.

-
Authentication correctness: Let 
, and let 
 be a key pair for any user with identity . For any , any dataset identifier 
, and any , if σ is the output of 
, then we have 
, where  is the labeled program for the identity function such that .

-
Evaluation correctness: Let 
, and let 
 be a set of key pairs for a set of users with identifier 
 where 
. Let 
 be a function for composing labeled programs. For any triples 
 and a fixed dataset identifier Δ, if for each i, 
, then we have 
⁎
, 
⁎
 
⁎
⁎
, where 
⁎
, 
⁎
 and 
⁎
.

MKHS succinctness  Let 
, let 
 be a labeled program with 
, let 
 be a set of key pairs, and let 
 be a set of signatures. We say that an MKHS scheme has the succinctness property if and only if the size of the authenticator 
 logarithmically depends on n, but possibly linearly in t. Namely, there is a fixed polynomial p such that 
.

MKHS security  In the security model defined by Fiore et al. [15], in addition to asking for signatures, the adversary can also corrupt signers. Since each user has its own secret and public keys, corrupting a user doesn't violate the integrity of computations on messages signed by other users. Let 
 be an MKHS scheme and A be a probabilistic polynomial-time adversary. To define the security of the scheme, we define a game 
 between the adversary A and the challenger C as follows:

•
Setup: We assume that the adversary A knows the security parameter λ. The challenger C initializes 
 as the of corrupted identities, runs 
 and sends the public parameter  to A.

•
Signing Queries: A is given the oracle access to the  algorithm (
) and can adaptively send requests of the form  to 
 where 
, ,  and . When A sends his/her query, C examines the following conditions and sends σ to A:

-
If 
 does not exist (i.e., it is the first query with dataset Δ) C creates 
.

-
If no signing query with label  or corruption query on id was ever issued, C generates and stores 
.

-
If 
 already contains a pair 
 for some message 
, C ignores the query.

-
If 
 does not contain any pair , C computes , and adds  to 
.

•
Corruption Queries: In corruption queries, A is given oracle access to  algorithm (
) and can adaptively send queries of the form  to 
. During the game, C initiates an empty list 
 of corrupted users. When A sends a corruption query  such that  to C, C examines the following conditions and sends 
 to A:

-
If A request id for the first time, C adds id to 
 and returns 
 (if a key pair for id was not generated before, it generates it in this step, 
).

-
If A request an identity which was requested before (i.e., 
), C sends to A the previously computed pair 
.

•
Forgery: Finally, A outputs a tuple 
⁎
⁎
⁎
⁎
 where 
⁎
⁎
⁎
, 
⁎
. The adversary A wins the game, if and only if 
⁎
, 
⁎
, 
⁎
⁎
, 
⁎
, 
⁎
, for all 
⁎
, 
, and at least one of the following forgeries occurs:

1.
Type-I forgery: 
⁎
 is a new dataset which is not queried before.

2.
Type-II forgery: 
⁎
 is not a new dataset (
⁎
 was queried to the signing oracle), for all , 
⁎
⁎
 and 
⁎
⁎
.

3.
Type-III forgery: 
⁎
 exists and there exists at least an index  such that 
⁎
⁎
. In other words, 
⁎
⁎
 contains at least one label 
 which was never queried to the signing oracle and 
 is not a corrupted identity, namely 
.

We say that scheme 
 is secure if for all probabilistic polynomial-time adversaries A, there is a negligible function  such that: 
 
Non-adaptive corruption queries  We remind the reader about a proposition shown in [15] to argue that, when corruption queries are made non adaptively, it is enough to prove security for adversaries that make no corruptions.

Proposition 1

[15]
MKHS is secure against adversaries that do not make corruption queries if and only if MKHS is secure against adversaries that make non-adaptive corruption queries.

Remark 1

An instantiation of the MKHS definition where only one key is generated and the same id is used for all labels covers the definition of the SKHS scheme as a special case.

4. Our generic compiler from SKHS to MKHS
In this section we propose our generic compiler that converts a single-key homomorphic signature scheme into a multi-key homomorphic signature scheme. Our compiler generalizes the one proposed by Fiore et al. [16] (called “Matrioska”) that works for homomorphic signature schemes for programs that are modeled as circuits. In contrast, our compiler works for schemes that supports programs defined in any model of computation (not limited to circuits).

4.1. Notation and building blocks
To define our compiler, we first introduce some notation and building blocks.

Notation. We denote by  the message space of the SKHS scheme. We denote a function with n inputs and m outputs by 
. By slightly abusing notation, we also use its name, namely F, to denote the description of the function, which is assumed to be a string in 
 for some integer length ℓ. For a function F we denote by  its running time, and by  (or ) the size of its description. Note that the description depends on the computational model at hand, e.g., it can be the description of a circuit, a Turing machine or a RAM machine.

Definition 2

Equality function (
)
For a given , the equality function 
 takes as input a value  and is defined as follows:
 

Definition 3

Composition function ()
We assume the existence of a polynomial-time computable function  that on input the description of two functions  outputs the description of a function H that computes their sequential composition. More formally, on input two functions
 we have  such that 

Masking function (). This is a central building block of our compiler. Intuitively,  is a polynomial-time computable function that on input the description of a function F and a portion of an input string, it outputs the description of a function 
 which computes the same as F but with the specified inputs already fixed. Namely, 
 is a partial application of F. In addition to this basic functionality we assume a few more properties.

The first one is that one can specify a set of indices, among the input symbols that are fixed, so that for each of these indices  returns the position in the description of 
 where the corresponding symbol was written. Essentially we can keep track of where the fixed symbols are in the description of the new function. This property is useful in the compiler where we provide 
 as an “almost” fixed input of the SKHS verification function, where “almost” is due to the fact that some of the inputs fixed in 
 are not provided and thus we need to locate where they are.

The other property of  is more specific to our application in the compiler. Let us say there are t functions 
 and a function 
 which encodes fixed inputs 
. Also, let us assume that one iteratively applies  on the function 
 and a fixed input that is the description of 
 except for the input value 
. Notice that with such iterative applications, at the step  one obtains a function 
 in which none of the original inputs 
 is fixed anymore. Then the last property of  requires that for such a scenario there exists an alternative algorithm 
⁎
 that can produce directly 
 without knowing 
.

We stress that in this section we only provide an abstract description of , including its functionality and its properties. The actual implementation of  heavily depends on the computational model used to represent the functions. Therefore to instantiate our compiler, one needs to specify how  can be implemented. For the circuits model, this essentially recovers the proposal in [16] that, roughly, is based on creating a new circuit where the fixed inputs are hardwired in constant gates in such a way that they can be easily located. For the Turing machines model, we show how to implement  in section 6.

In what follows we provide a formal definition of .

Definition 4

 takes as input a tuple  and returns a pair 
 where:

-
F is the description of a function with  inputs.

-
 is a set of indices, of cardinality , that correspond to the inputs that we want to fix.

-
 are the values of the input string that we want to fix. For example, for an input 
, V is defined so that, for every , 
.

-
 is the subset of indices that correspond to the inputs that we want to track.

-
 is the description of a function with 
 inputs.

-
 is the set of indices in the description of the function 
 that correspond to the inputs that were specified to be tracked in the set J. Hence the cardinality of 
 is the same as that of J.

The  function should satisfy four properties:
I.
Partial application of F. Namely, the function 
 is the same as executing F partially applied on the inputs in . More formally, let 
. Then for any 
, we have 
 where 
 is such that
 

II.
Locate the fixed inputs in 
. The intuition behind this property is that J specifies a subset of indices, among the ones in the set I, so that for every  one can track where  is written in the description of 
. To this end, the  function returns another set 
 that specifies where each of these inputs has been written. More formally, if we let 
 and 
, then it holds for all 
.

III.
Iterative execution of . There exists a function 
⁎
 that takes as input a tuple 
⁎
⁎
 and outputs a pair 
 where

-
F is the description of a function with n inputs.

-
.

-
.

-
⁎
.

-
 is the description of a function with 
 inputs.

-
.

-
⁎
⁎
 for some 
⁎
.

and that satisfies the following property.
Let F be a function with n inputs, ,  be two subsets of indices, and  be a function that encodes inputs to be fixed. Consider, a first execution of 
 and then, for  to , consider the iterative executions
 where:

-
Each 
 is some function with 
 inputs.

-
 is such that 
. Namely, the indices of inputs that are not fixed (i.e. they became variable in the new function 
) must be contained in 
.

-
 is such that for all 
 we have 
. This models that we are considering a partial application of 
 on 
 as first input, except that some indices are removed from its description.

Then, it holds that
⁎
⁎
⁎
 with
-
⁎
 such that 
⁎
. In other words, 
⁎
 only contains the inputs that will stay fixed until the last execution.

-
⁎
 such that 
⁎
. In other words, 
⁎
 only contains the additional inputs (other than 
) that are provided to 
.

In summary, the third property of the  function models that, an iterative application of it as above, it should be possible to create the description of the last function without knowing the original inputs with indices in the set J.

IV.
Complexity of . There are two functions 
 and 
 that determine the running time and the description size, respectively, of the function 
 that is returned by  on input a function F.

4.2. Our compiler
Let us now describe our compiler for turning an SKHS into an MKHS.

Definition 5 SKHS to MKHS compiler

Let 
, , , ,  be an SKHS scheme for programs in a given computational model, and let  be three functions as in Definition 2, Definition 3, Definition 4. The compiler described below outputs an MKHS scheme 
, , , ,  for programs in the same computational model as the SKHS one.

-
. The  algorithm takes as input a security parameter λ, a bound 
 for the number of distinct users, and a computation cost parameter cp. This parameter determines some upper bounds for the acceptable computational costs of the input functions to the  and  algorithms in the given model of computation. It outputs 
 where  is the users identity space and 
 is generated by invoking the  algorithm as follows.
 where 
 (which is derived from cp) determines some bounds for the computational complexity of functions supported by the  and  algorithms. The public parameter 
 includes a message space , a tag space , a signature space , and a set of admissible functions F determined according to 
. Note, we slightly depart from the notation of Definition 1 assuming that  takes 
 and cp as additional inputs (and similarly for ). This is more convenient here to show more clearly the dependence of parameters. Also it can be done without loss of generality as we could assume that there is an algorithm for each choice of these values.

-
. The key generation takes as input the public parameter , parses it as 
, and invokes the 
 algorithm to generate the secret/public key pair .

This algorithm is run by each user with identity . Throughout the paper, we use 
 to denote that the keys are associated to the user with identity id.

-
. This algorithm takes as input the secret key sk of the user with identity , the data set identifier Δ, the message , and the label  where , and runs the following algorithm:

-
. Let 
 be the number of distinct public keys taken as input by the algorithm. Let 
 be the labeled program where  and for each , 
 such that 
 and 
. The resulting signature is computed as follows.

 
 , there is only one signing user with identity id and public key 
. Namely, all signatures 
 belong to this user and in the labeled program , all labels has the form 
 with  and some 
. In this case, the  algorithm directly runs the  algorithm as follows.

 
 , there is more than one signing users with identifiers 
 and different public keys 
. Assume that each user with identity 
 contributes 
 messages such that 
. We assume ( without loss of generality) that labels and their corresponding messages and signatures are ordered based on the user's identifier. Namely, the set of triples of labels, messages, and signatures belong to the user with identity 
 is 
 where 
, 
, and 
. In this case, the  algorithm executes the following  steps.

–
Step 0: compute 
 and convert F to a single output function by running 
, 
. Hence, we have that
  
 works by running F on the inputs and comparing its output to the embedded value y, to check whether it is equal to y or not.

Notice that the function 
 takes its inputs from all users. However, recall that the  algorithm can be executed on functions with inputs from one user only. For this reason, in the next steps we apply repeatedly the  function to create a function 
 takes 
 inputs only from user 
, and has inputs from users 
 fixed in its description. To do this we also exploit the property of the SKHS verification algorithm.

–
Step 1: First, compute
 where 
, 
 such that 
, and 
. Essentially, 
 is the partial application of 
 on the last 
 inputs 
. Hence,
  Also, by setting 
 we are asking  to keep track of all the inputs from users 
, and therefore the set 
 contains the indices in 
 in which the inputs 
 have been written in the description of 
. Now that the function 
 takes inputs from the first user only, we execute the SKHS evaluation algorithm on it as follows.

–
Step i, : From this step on, the goal is to prove that 
 verifies correctly with the program 
. Let us consider the case of  in which one would like to verify 
. The challenge is that the verifier would need to reconstruct the function 
 whose description, however, contain inputs from all users except the first one. To eliminate this dependency, the following procedure is repeated for the remaining users. Let 
 be the program that models the SKHS verification algorithm on the appropriate input length 
.1 By the correctness of the SKHS verification we have that
 where 
 and 
.

Also, we denote 
.

Therefore, in the i-th step we create 
 by fixing the input tuple 
 of 
 except for the values of user 
 that are present in the description of 
. Notice that the set 
 records the indices where the inputs from users 
 are in the description of 
. Let us parse this set with the following notation 
. The  function is executed as follows
 where

-
.

-
 such that for all 
, we have 
. Such definition of 
 models that we are asking  to fix the whole input 
 except those values that correspond to the inputs of user 
 that, by the correctness of the previous  execution, are in the positions 
 in 
's description.

We also observe that by passing 
 as the last input of , we are essentially asking  to keep track of the values in positions 
, and thus 
 contains the indices where these values have been written in the description of 
.
By the property I of , if we assume 
 and 
, the function 
 is such that
  Since the function 
 takes in only inputs of user 
, we can run  on it as below to create 
.

Finally, notice that in the last step, the function 
 just takes its inputs from the last user and the evaluation algorithm is executed on it as follows.

The tuple of the signatures 
 is sent to the verifier as an authenticator for verifying the result y.
-
. The verification algorithm takes as inputs the labeled program 
, the public key of all users, the dataset identifier Δ, the authenticator 
, and the result message , and outputs one bit  deciding whether the result is correct or not.

 
 , the labeled program 
 takes inputs from a single user with identity id and public-key pk, and for every , 
 for some 
. In this case 
 and the verifier only runs the verification algorithm in the SKHS scheme as bellow and returns b.
  
 
 , the labeled program 
 takes inputs from more than one user. The verifier constructs 
 like the Step 0 explained in the  algorithm, parses 
 to 
, and reconstructs 
 using the public values 
, and the third property of the  function as
⁎
⁎
⁎
 where the sets of indices 
 are as in the  algorithm, 
⁎
 is the empty function, the sets 
 are defined as in , and each 
⁎
 encodes only the inputs of 
 after 
 (that are public). Finally, the verifier runs the following algorithm.

4.3. Succinctness, correctness and security of the compiler
The succinctness, correctness, and proof of security of the compiler follows the ones given for Matrioska [16].

Succinctness  Let 
 be an SKHS scheme with the succinctness l. The succinctness of the multi-key homomorphic signature scheme which is obtained by the compiler is determined by the size of 
 which is the output of the  algorithm. As 
 and each 
 is the output of the  algorithm, so the succinctness of the MKHS scheme is .

Correctness  Let 
 is an SKHS scheme with the correctness property, then MKHS scheme 
 obtained from the compiler has the correctness property according to the correctness of scheme defined in the Definition 1.

Proof

The correctness property consists of the authentication correctness and evaluation correctness. The main idea of the proof is quite similar to the proof of the Matrioska [16], with the difference that in our case the steps are generalized to any computational model and make use of the properties of the generic  function. Hence, the correctness of the MKHS scheme obtained from the compiler is reduced to the correctness of the SKHS scheme. The details of the proof is in Appendix A. □

Security  Let 
 be a secure SKHS scheme, then the MKHS scheme 
 generated by the compiler is secure.

Now, we explain an intuition of the security proof for the MKHS generated by the compiler and details of the proof can be found in [16].

Proof

Let  be a PPT adversary against the 
 MKHS scheme. We show that if the adversary  makes a forgery in 
, we can create another PPT adversary  that outputs a forgery against the SKHS scheme 
 such that 
 where t is the maximum number of distinct identities.

Let  outputs a forgery 
⁎
⁎
⁎
⁎
 where 
⁎
⁎
⁎
 and 
⁎
⁎
⁎
⁎
⁎
. For (), since the MKHS scheme generated by the compiler is similar to an SKHS scheme, it is obvious that a forgery in 
 leads a forgery in 
. For (), we show how a forgery in 
 leads a forgery in 
.

-
Let  outputs a Type-I forgery, namely 
⁎
 be a new dataset identifier. In the verifier side, the  algorithm invokes 
⁎
, 
⁎
⁎
 algorithm. So, if 
⁎
 is not queried before, then  outputs a Type-I forgery in 
.

-
Let  outputs a Type-II forgery in 
 such that 
 and 
⁎
⁎
. This algorithm creates 
 and calls 
, 
⁎
⁎
, 1) algorithm which outputs 1. Therefore, in at least one step  of the compiler, there is a function 
 such that
 and 
. Therefore the adversary  can output a Type-II forgery in 
.

-
Let  outputs a Type-III forgery in 
 and there is at least an index  such that 
⁎
. Since in the steps of the compiler, the functions are created using the input program and they are used in  algorithm as the input function, then the Type-III forgery is unavoidable in 
. Another case that the adversary  can output a type-III forgery in 
 is that there is a 
⁎
 such that 
⁎
 be a Type-II forgery in 
 for some identity 
 which is used during the verification in the compiler.  □

Remark 2

Lai et al. [24] introduced the notion of insider-unforgeability for SKHS and MKHS and proposed constructions of these schemes from non-falsifiable assumptions. We observe that in the case our compiler is applied to an insider-unforgeable SKHS scheme, the resulting MKHS scheme would also satisfy insider unforgeability. Intuitively, this is due to the fact that an SKHS with insider unforgeability is essentially a succinct proof system. Note though that applying our compiler to an insider-unforgeable SKHS makes the purpose of the compiler less interesting. Indeed, insider unforgeable SKHS imply SNARGs, which are known to require non-falsifiable assumptions under which one could build directly a more efficient MKHS (as proposed in [24]).

4.4. General efficiency analysis
In this section, we provide a general framework to analyze the efficiency of the MKHS scheme obtained through our compiler. In particular, we are interested in analyzing the complexity of running the  and  algorithms. To this end, our analysis focuses on showing the running time and the description size of the functions 
 built during the steps of the  algorithm – this is in fact the main burden of our general compiler. This analysis clearly includes also the complexity of the last function 
 that the verifier feeds to the  algorithm.

We stress that here we only provide a general framework to analyze these costs. As we shall see, the final complexity depends on the specific SKHS we start from, the computational model supported by it, and the  function.

Given a function 
 built in the i-th step of the compiler, we denote its running time with 
 and the size of its description with 
.

Let HSV be the program that realizes the  algorithm on an input 
. We assume that its running time  and description size  are determined using the following functions:
 Namely, they are both a function of HSV's input length and the security parameter, and the running time of HSV may also depend on the running time of E.

Let us now review the steps of the compiler to analyze the growth in the description size and the verification time. Let 
 be the program we start from and let us assume it has size 
 and that runs in time at most 
 on n inputs.

-
Step 1: We build the function 
 using the mask function as 
. By the property IV of the  function (see Definition 4), we have

-
Step i (): let 
 be the program that models the SKHS verification algorithm to be run on a labeled program of size 
 and with running in time at most 
 on 
 inputs. The function 
 is created using the mask function as 
.

By the property IV of the  function, we have
 In turn, as mentioned earlier the time and size costs of 
 are
 Therefore, by combining these equations we obtain the following relation at every step :(1)
(2)
 At this point it is clear that to resolve this relation one needs to instantiate the functions 
 and 
 (that depends on the SKHS scheme used in the compiler), and the functions 
 and 
 (that depend on the  function, which in turn depends on the computational model).

For this reason we defer the reader to the following two sections to see how the analysis can be completed in two models of computation, that of circuits (which recovers the result of Fiore et al. [16]) and that of Turing machines (that we show how to instantiate in this work).
To ease the comparison, we assume that the function 
 can be expressed generally as below:
 for some functions 
 and 
 that are both polynomials in their inputs. We can see in Section 5.1 and Section 6.4, how the computational model and implementation of the  function can affect the description size of the final function 
 created in the compiler. In particular, one can see that in a uniform model of computation such as Turing machines the description of the Turing machine can be independent of the input length, i.e., 
 is a fixed polynomial 
, whereas in a model like circuits the size of the circuit description is at least as large as the input size.

Regarding the running time of the  algorithm, to ease the comparison we consider the following five cases of the function 
:

-
Case 1: 
.

-
Case 2: 
.

-
Case 3: 
 for a constant .

-
Case 4: 
.

-
Case 5: 
.

Notably, the first case models the efficiency of the state-of-the-art SKHS scheme for circuits proposed by Gorbunov et al. [21]. In case 1, even if we assume that 
 is the identity function, it is not hard to see that the recurrence of equation (1) would resolve 
 having a factor 
, exponential in the number t of users. For this reason, we consider the additional cases 2–5 as they show the potential of our compiler and can motivate further research in designing SKHS with more efficient verification algorithms. We note that the last case 5 is the most optimistic one, as it is saying that the running time of the SKHS verification depends linearly in the description size of the function to verify, without any multiplicative factor, depending on a constant (i.e., ) or the security parameter (i.e., ). Finally, we stress that the verification algorithm must read the function to verify, which is an input, and thus it seems unrealistic to assume a verification time smaller than the size S.
5. Our compiler in the circuits model: Matrioska
The compiler proposed by Fiore et al. [16] can be seen as an instantiation of our general compiler described in Section 4.2 when instantiated in the circuits model of computation. Below we recall the circuit model used in [16] and explain how the  and  functions work there.

In the circuit model, a circuit C is described using a tuple 
, 
, 
, 
, 
, 
 where

-
 is the number of inputs,

-
 is the number of outputs,

-
 is the number of gates,

-
 is a function determines the left wire for a given gate 
,

-
 is a function determines the right wire for a given gate 
,

-
G is a function that maps each gate 
 to a bit.

In Matrioska, the 
, , and  functions that are used by the compiler are modeled using circuits. The function 
 is modeled by a circuit that models the xor operation. The  function just binds the outputs of the first circuit to the inputs of the second circuit, and is used by the function . In Algorithm 1 we show how the description of this provided in [16] can be seen as an instance of our  definition. In a nutshell, the algorithm creates a mask circuit M that outputs the inputs of the circuit C and them it runs the  function to binds the outputs of M to the inputs of C. We defer the reader to [16] for more details.
Algorithm 1
Download : Download high-res image (77KB)
Download : Download full-size image
Algorithm 1.  function in Matrioska.

Let us assume that , , , ,  are the algorithms generated by Matrioska. The algorithms  and  are exactly the same as the algorithms presented in Definition 5. In the inputs of the  algorithm, the computation cost parameter cp is a pair  where s and d are upper bounds for the size and depth of the circuits supported by the generated MKHS scheme, respectively. In the  and  algorithms, the steps are the same as the steps described in Definition 5, but the 
, , , and every function 
 created in the i-th step of these algorithms are modeled using a circuit.

5.1. Efficiency analysis
Fiore and Pagnin analyzed the efficiency of their compiler [16] by showing how the circuits 
 grow and what is the size of the last circuit 
, which is the one that needs to be computed by the verifier. In their analysis, this size depends in a double exponential manner on t, roughly 
, where c is a constant such that the SKHS verification on input a circuit C is a circuit with 
 gates. The depth of the circuit is a function of its size. This assumption is quite general (it simply assumes that the verification circuit is a polynomial of its input size) but not very tight.

For a fair comparison with the compiler proposed in this paper, we revisit the complexity analysis of Matrioska considering the most favorable assumption regarding the complexity of the SKHS verification with respect to the input program. Even in such optimistic case, we show that the MKHS scheme obtained through the Matrioska compiler implies a blowup that is at least exponential in the number t of users.

In the circuit model we take the circuit size (i.e., the number of gates) as a measure for the running time, while the description size of a circuit with q gates is assumed to be , following the model adopted in [16]. Therefore, applying the case 5, in what follows we assume that
 and 
.

Let us now review how the compiler proceeds.

-
Step 1: In the first step, the circuit 
 is created by running the  function that invokes 
. The size of this circuit is 
 where n is the total number of inputs of 
 and the number of gates in the masking circuit 
.

-
Step i (): Let 
 be the description of the circuit that models the verification algorithm of the SKHS scheme that is created in the i-th step of the compiler. This circuit is to be run on the input
 Next, 
 is built using the  function that internally computes 
 where 
 is a “mask” circuit that is as large as the input 
 above (see Algorithm 1). Let  be a  such that  +  + 
 +1. The size of the circuit 
 is
 As one can see, from the above equation we can easily derive a lower bound
 and with an easy inductive proof we also get that for every 

Hence, we obtain that in the Matrioska compiler the complexity growth in case 5 is still exponential in the number of users, namely
6. Instantiating our compiler for Turing machines
In this section, we show how to instantiate our compiler of Section 4.2 for SKHS that support programs modeled as Turing Machines (TM). To this end, we show how the building blocks of section 4.1 can be instantiated in the TM model.

In particular, a crucial difference with the Matrioska compiler of [16] is a more efficient implementation of the  function that, independently of the complexity of the SKHS verification algorithm, avoids an exponential blowup in the size of the TMs 
 built during the steps of the compiler.

In Matrioska, the exponential blow up in the circuit size is mainly due to “gluing” the Mask circuit to the description of the circuit 
 used in each step. The size of the Mask circuit depends on the input size of 
, that in turn includes the size of the circuit 
 created in the previous step.

In the case of the Turing machines instantiation, we overcome this blowup by defining the Turing machines in such a way that the input values are located at the beginning of the input tape. This way we can finding and remove the input values in each step in a much simpler way than in Matrioska as we can simply “cut” the tape from the left at an appropriate location. In the next section we begin by describing our TM model.

6.1. Turing machines conventions
We model the functions in our compiler by using multi-tape Turing machines. Since every multi-tape Turing machine has an equivalent single-tape Turing machine [27], all of the multi-tape Turing machines used in this paper can be realized by transforming them to a traditional single-tape Turing machine. A multi-tape Turing machine is a 7-tuple 
 with the following semantics:

-
Q is the set of all states.

-
Σ is the input alphabet (the union of all input alphabets for all tapes i.e. 
 
).

-
▷◁ is the tape alphabet. It is the union of the input alphabet and four special symbols, which are not in the input alphabet. B symbol is used for determining the blank cells, ⋄ symbol is used for separating values on the tape, ▷ symbol is used for determining the beginning of the values, and ◁ symbol is used for determining the end of the values on a tape.

-
 is the start state.

-
 is the set of accept states.

-
 is the set of reject states.

-
 is the transition function where k is the number of tapes used in a Turing machine and , , and  stand for Right, Left, and Stop, respectively.

We use TM instead of Turing machine for simplicity throughout the paper. For describing a TM, we add a new part to the general description of the multi-tape TMs. The description of TMs used in our compiler contains
 where i is a TM identifier and cv is the constant inputs of a TM. The transition function of TMs used in our compiler is 
 and all TMs have four tapes as:
-
Variables tape: This tape contains variable inputs of TMs.

-
Constants tape: This tape is read-only and contains constant inputs of TMs and is determined in the description of TMs. Intuitively, this tape contains values that are hardwired in the TM description.

-
Work tape: This tape is used during the execution of TMs.

-
Outputs tape: This tape contains the outputs that are determined after the execution of a TM.

Each of these four tapes has a head that can read/write one symbol at a time. The beginning (resp. end) of the values on the tapes is determined by the tape symbol ▷ (resp. ◁).
Without loss of generality, in our compiler we assume that all the TMs have the following behavior. Before executing a computation, the TM copies the content of the variable tape to the work tape, then appends the values of the constant tape on the work tape, and terminates the work tape with the ◁ symbol. Then, the TM executes its transition function on the work tape without needing to read the variable and constant tapes. The output of the TM is the content of the output tape when the TM halts. At the start state of TMs, we assume the heads should be at the beginning of the values on the tapes. In halting states, the head of the output tape comes back to the beginning of the output values, and the values on the work tape are erased (because, in the sequential composition of TMs, the next TM works on the same work tape).

6.2. TM-based instantiation of our compiler's building blocks
In the instantiation of the compiler proposed in Definition 5 for Turing machines model of computation, we use three families of four-tape Turing machines: (1) a family of Turing machines for modeling the main functions to be evaluated, (2) a family of Turing machines for modeling the equality check operation, and (3) a family of Turing machines for modeling the verification algorithm of a single-key homomorphic signature. We give more details on these machines below:

-
: This machine runs the program 
 and writes its output on the output tape. The input values 
 can be constant or variable. The constant inputs are specified in 
. In a situation where all inputs are variable, this tape can be empty. The description of this machine is

-
: This machine simply checks if a variable input on the variable tape is equal to the constant input y (it is in 
) or not. If the equality check is satisfied, it writes the value 1 otherwise writes the value 0 on the output tape. The description of this TM is

-
: This Turing machine models the verification algorithm of a sufficiently expressive single-key homomorphic signature. It takes as constant inputs (they are in 
), the description of a Turing machine 
, the public key of the verifier pk, the dataset identifier Δ, the result bit b, and the signature of the result σ. If the verification is satisfied, the value 1 otherwise the value 0 is written on the output tape. The description of this machine is

We also define two deterministic functions  and  that operate on Turing machines and create a new Turing machine as their output.
6.2.1. TM-based composition function
A composition function, , is a function that takes as input two TMs and combines them to make a new TM. Let
 and
 are two TMs and 
. To construct 
, 
, the function  takes 
 and 
 as the inputs and specifies the following parameters:

-
,

-
,

-
,

-
,

-
,

-
,

-
,

-
.

To complete the construction, we need to determine the parameter 
 and 
 (the rest of the parameters are available). The transition function 
 contains essential transitions for going from the halting states of 
 to the start state of 
. The contents of the tapes after the execution of 
, are shown in Fig. 1.

Fig. 1
Download : Download high-res image (72KB)
Download : Download full-size image
Fig. 1. Values of the tapes after the execution of 
.

At first, 
 should copy the content of the output tape (the output of 
) to the end of the variable tape. It should move the head of the output tape to the right, copy the output values to the variable tape, remove the output values from the output tape, and finally return the head of the variable tape to the beginning of the values belongs to 
. The transition function 
 for 4 tapes is defined as follows,
 where 
 and for each 
. The set of transitions in 
 are as follows:

-
At the end of the execution of 
, the work tape is empty and the location of the heads are shown in Fig. 1. This transition moves the head of the variable and constant tapes to the right.

◁◁▷◁◁▷

-
This transition writes ▷ symbol on the variable tape for determining the beginning of the variable inputs of 
 and moves the head of variable tape and output tape to the right.

▷▷
▷▷

-
This transition copies the content of the output tape to the variable tape and writes the blank symbol on the output tape.

▷
▷

-
When the output tape reaches the end of the output values determined with ◁, the head of the variable tape returns to the beginning of the variable inputs of 
.

▷◁
◁▷

▷
▷

-
When the head of the variable tape reaches the beginning of the variable inputs of 
, this transition moves to the start state of 
.

▷▷
▷▷

6.2.2. TM-based  function
Here we show a realization of the  function for our TM model. For simplicity, our realization works for a slightly more restricted case than that of Definition 4: we assume that  always encodes a suffix of the input, rather than an arbitrary subset. Note that this is sufficient when instantiating our compiler of section 4.2 in our TM model as the constant tape is always at the beginning of the description and then, by the convention mentioned in section 6.2, the TM works on the variable input followed by the constant input.

The function 
 takes as input the description of a Turing machine 
 that accepts inputs of length 
, a set 
 for some , a function 
 and a set 
. Notice that the integer s essentially denotes where to “cut” the input so that only inputs after s are fixed.  outputs a new Turing machine 
 and a set 
 that are built as follows. The constant tape 
 is 
, while the rest of the TM stays the same, i.e., 
, 
, 
, 
, 
, 
, 
. The set 
 is defined as 
. Namely, we are simply shifting the indices in 
, as in 
 those values are at the beginning.

In other words, we are placing at the beginning of the constant tape of 
 the suffix of the input encoded by 
, let us call it v, that we want to fix. Since our TMs always copy the variable inputs followed by the constant tape in the work tape, we obtain that executing 
 on an s-long input 
 works the same as executing 
 on 
.

We define the following theorem to show that our TM-based  function satisfies the four properties of  function defined in Definition 4 (when executed on suffixes of inputs).

Theorem

The TM-based  function satisfies the properties of the general  function defined in Definition 4 when executed on sets 
 of the form 
 for some .

Let 
 where 
 and 
 have 
 and 
 inputs, respectively. We recall each property defined in Definition 4 and prove that the TM-based  function satisfies each of them.
I.
Partial application of 
. Let 
. Then for any 
, we have 
 where 
 is such that
 

Proof

First, notice that by construction 
 and 
. Next, according to the Turing machine conventions explained in Section 6.1, before executing 
, the content of its variable tape and constant tape are written on its working tape, receptively. Thus, the content of the working tape of 
 will be 
. According to the definition of TM-based  function, we have 
, 
, 
, 
, 
, 
, 
. Thus, executing 
 on 
 is the same as executing 
 on the input 
 (since it is also written on the working tape and 
 is appended to it). □

II.
Locate the fixed inputs in 
.

Proof

In the Turing model used in this paper, the constant inputs of a Turing machine are located in the beginning of its description. Thus, finding the new indices of the fixed inputs in 
 is a simple work which is done by shifting the indices 
 where s is where the inputs are cut from the constant tape. □

III.
Iterative execution of . This property of the  function models that, by iterative execution of  function as explained in the third property of Definition 4, there is a TM-base function 
⁎
 that can create the description of the last Turing machine without knowing the original inputs with indices in the set J.

Proof

Let 
⁎
⁎
⁎
 where

-
 is a Turing machine with n inputs.

-
.

-
.

-
⁎
 contains the inputs of TM that will stay fixed until the last execution.

-
Each 
 is some Turing machine with 
 inputs.

-
 is such that 
.

-
⁎
 is the set of fixed values that only contains the additional inputs (other than 
) that are provided to 
.

In the iterative execution of the TM-based  function, the description of 
 will be as follows.
⁎
⁎
⁎
 There is a sample pseudocode in Algorithm 2 that can create this description without knowing the original inputs. □
Algorithm 2
Download : Download high-res image (77KB)
Download : Download full-size image
Algorithm 2. 
⁎
 function in TM-based compiler.

IV.
Complexity of . There are two functions 
 and 
 that determine the running time and the description size, respectively, of the Turing machine 
 that is returned by  on input a function 
.

Proof

At run time, the variable and constant inputs are written on the work tape and the Turing machine executes on the work tape. Since the sum of the constant and variable inputs size is the same in 
 and 
 and 
, we have 
. Regarding to the description size, the TM-based  adds 
 value from the constant tape and 
. □

6.3. Complexity analysis of the TM-based compiler
In this section, we describe the effect of using the TM computational model on the complexity of the proposed compiler compared to using the circuit model of computation. We define some notations used for complexity analysis in Table 1. For the TM instantiation we call 
 the TM instantiation of the function 
 generated in the i-th step of the compiler.


Table 1. Notation used in the complexity analysis in Turing based compiler.

Notation	Description
Sp	the size of the program TM(p) to be verified.
Tp	the running time of TM(p).
the size of 
.
the size of TM(v).
Scmp	the additional three two states and six transitions in the  function.
Si	the size of TM(i) created in the i-th step of the compiler.
Ti	the running time of TM(i) created in the i-th step of the compiler.
TVi	the verification time of TM(i−1).
6.4. Growth in the description size
Let  be a polynomial function expressing the size of a tuple 
, and let the size of the TM expressing the verification algorithm of the SKHS be a fixed polynomial, i.e. 
. In what follows we analyze the growth of the TMs used through the steps of our compiler. In our compiler 
 is created using the compose function and its size is 
. At step 1, the machine 
 obtained from the application of  is essentially the same as 
 with the inputs of all the users but the first one in the constant tape. Hence, its size is
 At step i, with , the compiler uses a machine 
 whose size is that of 
, i.e., 
, plus what is written in the constant tape, which is: the description of 
 with the first 
 inputs removed, the 
 labels and the tuple consisting of public key, signature and output bit, which has size .
 More formally, we claim that
  We prove this claim as follows.

-
Step 1: This follows by the construction of 
 as already mentioned above.

-
Step : we show the claim by induction. Let us assume that
 
 In every step i for , the machine 
 is created by adding to the constant tape of 
 the description of 
 without the 
 inputs of user i that in its constant tape 
. Hence we have
 
 
 which equals the value to be proven.

We notice that for , 
 can be simplified with
 This bound establishes our claim that the size of the last Turing machine depends only linearly on the number of the users.
6.5. Running time analysis
For analyzing the running time in our compiler, we explain the growth in the running time for different cases explained in Section 4.4. First of all, we analyzed that the Case 1 where 
 corresponds to the way our compiler can be instantiated using the existing SKHS construction of Gorbunov et al. [21]. Then, in Section 6.5.2, we generally analyze the verification cost in other cases.

6.5.1. Efficiency of constructing the MKHS from the existing SKHS
The SKHS scheme proposed by Gorbunov et al. [21] can evaluate any circuit with bounded depth. The main cost of the verification algorithm in this scheme is the homomorphic evaluation of the circuit to be verified. This is done gate-by-gate, and each gate evaluation has a fixed  cost. Therefore, for a circuit with N gates, the verification cost is . This scheme can be used for programs represented as Turing machines by using the following result, which shows how to represent a Turing machine using a Boolean circuit.

Theorem 1

Fischer and Pippenger [17] have shown that a  time-bounded Turing machine (TM) can be simulated on n bits by a combinational (Boolean) circuit with  gates.

Thinking of the verification algorithm of [21] as a Turing machine that evaluates a circuit in  steps, and by using the above theorem we get that 
 for a fixed polynomial , where TV and 
 are the running time of the verification algorithm and input program, respectively. In this case we claim that the verification time in the i-th step is
 
Proof

The case for  follows immediately by construction. For  we prove the claim by induction.

•
For , the verification time of 
 is:
 where in the first inequality we used the assumption 
.

•
For , let us assume that 
. Then the verification time of 
 is:
 Above, in the first inequality we applied the inductive hypothesis, in the second we used that, for , 
, in the third step we used , and in the last inequality we used the assumption 
 (namely the result holds asymptotically for such sufficiently large running time 
).  □

Therefore, the upper bound for 
 is 
. This means that for existing SKHS scheme, our compiler can support a constant number of users.
Comparison with the compiler of [16]
For a fair comparison, in Appendix B we also analyze the efficiency of the Matrioska compiler [16] using a similar assumption, namely that the SKHS verification circuit has 
 gates, where 
 is the description's size for the input program P that is modeled with the model of [16]. From our analysis in Appendix B we get that the size of the verification circuit in the last step is, at least
 which is slightly worse than our upper bound.

6.5.2. General efficiency analysis of our compiler
As we proved in Section 6.5.1, the verification time of the MKHS created using the existing SKHS scheme is exponential. In this section, we examine how the compiler performs in the other cases defined in Section 4.4 and show the cases where our compiler can support a polynomial number of users. We summarize the results of this analysis in Table 2.


Table 2. The verification time in TM-based compiler.

SKHS verification time	MKHS verification time	Number of users
Case 1	
exponential	O(1)

Case 2	TV = p(λ)Tp	exponential	O(1)

Case 3	
exponential	O(1)
quasi-polynomiala	
polynomial (if )	

Case 4	
polynomial	

Case 5	TV = Sp + np(λ)	polynomial	
a if we can tolerate quasi-polynomial verification cost.

We provide an example of the verification cost for each case in Table 2 and compute the verification cost in the MKHS creates using our compiler.

•
Case 2: 
 for some fixed .

In this case, it is easy to see that for all  to t, 
, and thus the running time of  is at most 
. In this case, the number of users can be constant.

•
Case 3: 
 for a constant  and a fixed .

The verification time of the Turing machine created in step i of our compiler is:
 
 which we prove inductively as follows.

For , 
 holds by construction and by the assumption on TV.

For any , let us assume that
 
 then by following the construction we have
 
 
 which yields the claimed value. Notice that the value of T can be simplified with an upper bound
 

From this bound we deduce that in this case (4) our compiler can support up to  without incurring in an exponential running time.

•
Case 4: 
 for a fixed .

According to the size analysis in Section 6.4, we have
 
 We assume for all , 
 where . Thus, we have(3)
 Let 
. We claim that the verification time in step i of our compiler is:
 which we prove inductively as follows.

For , 
 holds by construction and by the assumption on TV, and clearly satisfies the upper bound above.

For any , let us assume that
 then we obtain the claimed value from the following sequence of inequalities
 where the first equality holds by the equation (3), the second inequality holds by applying our inductive hypothesis, and the last one holds by assuming that 
.

Since S linearly depends on t, thus 
 is a polynomial value based on the security parameter. From this bound we deduce that in this case (4) our compiler can support up to  users.

•
Case 5: 
 for a fixed .

In this case we have

Since, 
 linearly depends on the number of users. Thus we can assume, for some , and all , 
. Clearly the verification time in step i of our compiler is:
 From this bound we deduce that in this case (5), our compiler can support up to  users.

7. Decreasing the verification cost
The verification time for the existing SKHS construction [21] is 
 
 and it depends on the time of the input program. In our compiler, this dependency makes the verification time of MKHS grows exponentially with respect to the number of users (as explained in Section 6.5.1). In this section, we explain how to reduce the verification time of an SKHS with the verification time 
 
 to 
.

By considering the efficiency of the delegation system proposed by Kalai et al. [23], we claim that every SKHS which its verification time does not depend linearly to the time of the input program and its input length, can be converted to a new construction such that its verification time linearly depends on the time of the input program. For this conversion, we define the following theorem.

Theorem 2

Let 
 be a single-key homomorphic signature scheme that is correct and unforgeable. If 
 has succinctness l and verification time of  where T is the execution time of the input function, and we have an adaptively sound non-interactive delegation scheme 
 with the proof length 
 
 and the verification time  where n is the input length, we can build an efficiently verifiable single-key homomorphic signature, which is correct and unforgeable with the succinctness  and verification time of .

For proving this theorem, we first recall the delegation system introduced by Kalai et al. [23] and then, we construct an efficiently verifiable single-key homomorphic signature scheme. Finally we prove the properties described for this scheme.
7.1. Publicly verifiable non-interactive delegation
Let M be a Turing machine with the halting time bound T and input length n. We define 
 as a language consisting of tuples  such that M accepts x if and only if M halts in atmost T steps where 
 and 
.

Definition 6

Publicly verifiable non-interactive delegation scheme [23]
A publicly verifiable non-interactive delegation scheme 
 for the Turing machine M with the time-bound T and the input length n, is a tuple of three probabilistic polynomial-time algorithms :

-
: the setup algorithm takes the security parameter λ, time-bound T, and input length n as input and outputs the public-key , and the verification-key  of the delegation system.

-
: the proving algorithm takes the public-key  and input message x as inputs, and outputs a proof π. This algorithm is run by the prover.

-
: the verification algorithm takes the verification-key , input message x, and proof π as inputs, and outputs a Boolean value. If proof is valid, it outputs one otherwise outputs zero. This algorithm is run by the verifier.

This delegation system has the following properties:

•
completeness: for all λ,n and T we have
 

•
soundness: for all probabilistic polynomial time adversary A and security parameter λ we have 
 
 

•
efficiency: the proof and CRS length is 
 
, the prover's run time is  and the verifier's run time is .

7.2. Efficiently verifiable single-key homomorphic signature
Recently, Kalai et al. [23] introduced a publicly verifiable non-interactive delegation system with adaptive soundness for any program with the execution time T which is secure in the CRS model. Their proposed delegation system is efficient, namely, the CRS and the proof length is 
 
 and the prover's and verifier's run time are  and , respectively.

To reduce the verification time in the known SKHS scheme, we use this delegation scheme. In other words, we build an efficiently verifiable single-key homomorphic signature (ESKHS) from the standard SKHS scheme 
, , , ,  by using the delegation system described in Definition 6. Actually, we use the proof generated by the prover of the delegation system to prove the correct execution of the verification algorithm in the single-key homomorphic signature.

Let 
 be the input of the  algorithm and 
 be the Turing description of this algorithm. An efficiently verifiable SKHS is a tuple of five probabilistic polynomial time (PPT) algorithms 
,  described in Fig. 2. As we can see in Fig. 2, the length of  is . So 
 satisfies a weaker succinctness property because the signature has a component of length 
 
, where T is the runtime of the SKHS verification. Furthermore, the  algorithm runs ; so, the verification time is  for a fixed polynomial .

Fig. 2
Download : Download high-res image (102KB)
Download : Download full-size image
Fig. 2. Efficiently verifiable SKHS.

In the case 
, notice that we can bound
 
 
 which is 
 whenever 
, which for example holds for 
.

Correctness  Proving the correctness of 
 consists of proving the correctness of each signed messages and the correctness of the signature which is the output of the  algorithm.

-
Authentication correctness: Authentication correctness is directly derived from the authentication correctness of 
.

-
Evaluation correctness: Since 
, 
 is correct based on the evaluation correctness of 
, and π is correct based on the completeness of 
, so 
 has the evaluation correctness property.

Security  For proving the security of 
, we define the following theorem:

Theorem 3

If 
 is an unforgeable single-key homomorphic signature and 
 is an adaptively sound publicly verifiable non-interactive delegation system under Definition 6, then the efficiently verifiable single-key homomorphic signature scheme 
 is also unforgeable.

Proof

Let there exists an adversary 
 who wins the unforgeability game for the proposed efficiently verifiable single-key homomorphic and outputs a forgery in 
. We show how to construct a new adversary A, that can use 
 to do a forgery in 
 or break the soundness of 
. Actually, A plays the role of the challenger C in the SKHS unforgeability game for the adversary 
.

If the adversary 
 outputs a forgery (
⁎
, 
⁎
, 
⁎
, 
⁎
) where 
⁎
⁎
⁎
, A can check the validity for the signature 
⁎
 using 
⁎
⁎
⁎
⁎
 algorithm:

•
if , A breaks the soundness of the delegation system and the security of this scheme is reduced to the security of the delegation system.

•
if , A does a forgery in the SKHS scheme and the security of this scheme is reduced to the security of the SKHS scheme. □

Using EHS in our compiler  Let us analyze the efficiency of the MKHS scheme that results from using EHS in our compiler as the input SKHS scheme. Also, we consider an instantiation with an SKHS scheme where the verification takes time 
, for which we can assume 
.

So, in the EHS signature scheme, we have 
 where 
 is the input size of the verification algorithm. Considering that EHS signatures are not fully succinct, as 
, we have that the input size 
 of the verification algorithm also depends on T. Essentially, for EHS with 
, which follows our Case 1 in Section 6.5.1, means that with this construction the number of users t needs to be a constant in order to have a polynomial-time verifier.

This leaves the interesting open problem of finding a delegation system, secure in the standard model, in which proofs have better complexity, so that our compiler can yield a more efficient MKHS that can support  users.

8. Conclusion
In this paper, we generalized the compiler proposed by Fiore et al. [16] for converting a single-key homomorphic signature to a multi-key homomorphic signature in any model of computation (not limited to circuits model). We provide a generic efficiency analysis for the compiler. However, this is rather a framework and the full analysis can be obtained only when instantiating the compiler for a specific computational model. We show how Matrioska [16] can be viewed as an instantiation of our compiler in the circuit model and provide an efficiency analysis under tighter assumptions about the complexity of the SKHS verification algorithm. Notably, we show that this instantiation has a growth exponential in the number t of users. Then, we proposed our TM-based instantiation of the general compiler. In particular the technical contribution of this instantiation is the definition of the multi-tape TM model and the design of the Mask function that works efficiently on it. Then, we analyze the efficiency of the TM-based instantiation. Notably, we show that some assumptions our compiler yields a MKHS in which the growth is linear in the number of users and thus it can tolerate a polynomial number of users. Since the verification time of the SKHS scheme affects on the verification time of the MKHS scheme created by our compiler, we provide a transformation to improve the efficiency of the verification algorithm in the SKHS scheme using a delegation system. With state-of-the-art delegation schemes that are secure in the standard model (i.e., no random oracles) under falsifiable assumptions, we obtain an MKHS scheme whose verification is 
. We leave it as an open problem to design an SKHS or a delegation scheme with better succinctness, which would directly allow our MKHS compiler to have a polynomial verification time, and thus support an arbitrary polynomial number of users.