Abstract
Machines usually require maintenance after running a fixed period. A calibration at a cost has to be performed during the process. Finding a feasible schedule minimizing the total cost of calibrations is of great importance. In this paper, we deal with a single machine scheduling model with K types of calibrations. A calibration of type k∈{1,…,K} can be made instantaneously at any time point, which incurs a cost fk and can keep the machine active for a length Tk. Given a set of n jobs with release times, deadlines, and processing times, the goal is to minimize the total cost of calibrations by assigning all jobs in the calibrated state, where job preemption is allowed.

We investigate two agreeable settings. Regarding agreeable jobs, later release times imply later deadlines. We establish a pseudo-polynomial time optimal algorithm and a (3+ε)-approximation algorithm. Moreover, if the largest job processing time is no more than any calibration length, it admits a (2+ε)-approximation algorithm. As for agreeable calibrations, where the cost of each calibration is proportional to its length, a 2-approximation algorithm is presented.

Keywords
Scheduling
Calibration
Approximation algorithms
Dynamic programming

1. Introduction
Scheduling plays an essential role in the rich history of combinatorial optimization. Various new scheduling models have been appearing along with practical applications. In 2013, Bender et al. [2] came up with a class of scheduling problems related to calibrations, attracting a widespread attention. It was motivated from the Integrated Stockpile Evaluation (ISE) program [3] to test nuclear weapons periodically. The tests require calibrations that are expensive in a monetary (though not necessarily temporal) sense. Clearly, such a scenario happens in many areas where machines performing jobs need calibrating periodically, including robotics [4], [5], pharmaceuticals [6], [7], and digital cameras [8], [9].

The calibration scheduling problem was initially proposed with only one type of calibrations. Bender et al. [2] gave a polynomial-time algorithm to compute an optimal solution when jobs have unit processing times on a single machine, while a 2-approximation algorithm was presented for parallel machines. Later on, Chen et al. [10] proved that when the number m of machines is constant, the problem can be solved in polynomial time. When m is part of the input, they designed a polynomial-time approximation scheme (PTAS). However, the complexity is still open for an arbitrary number of machines.

Fineman and Sheridan [11] considered arbitrary job processing times, while job preemption is not allowed. To tackle this intractable problem, they made a relaxation by dealing with a resource-augmentation version [12]. When preemption is allowed, Angel et al. [13] generalized the algorithm from [2] and showed that it is solvable in polynomial time.

There have been in the literature quite a few variants. Wang [14] introduced the time-slot cost, which depends on the starting time. The goal is to compute a schedule with a minimum time-slot cost using at most B calibrations. They proposed dynamic programs for different scenarios. Chau et al. [15] investigated the throughput model, where the goal is to maximize the total profit of scheduled jobs. They showed that the problem admits a constant approximation algorithm for arbitrary job processing times. The other variants can be found in [16] and [17].

Regarding many calibration types, however, little is known. Angel et al. [13] proved that when jobs have unit processing times, the problem can be solved in polynomial time.

In this paper, we focus on a scheduling problem with K calibration types on a single machine, where jobs are preemptive. The machine can process jobs if and only if it is at a calibrated state. Each type of calibrations incurs a cost and can keep the machine at a calibrated state for a period of time. The action of calibrating the machine is instantaneous. A set of jobs, each of which has a release time, a deadline, and a processing time, must be scheduled on the machine so that the total calibration cost is minimized, subject to the time constraints. Note that allowing job preemption is reasonable, since otherwise checking if a feasible schedule exists becomes strongly NP-complete even for the case without a calibration issue [18].

In real-life applications, it often appears that earlier arriving jobs leave also earlier, implying that a job does not have a larger deadline than those with larger release times. Such a job setting is called “agreeable” jobs. Regarding calibrations, a meaningful setting says that the cost of each calibration is proportional to its length. We denote it as “agreeable” calibrations. Detailed formulations will be presented in Section 2.

Our contributions. We investigate the calibration scheduling problem, respectively, under the above two settings. No matter what setting is taken, the problem is NP-hard even if all the jobs have a common release time and a common deadline. A polynomial-time reduction from the subset sum problem, known as NP-complete, is easily constructed. Our main contribution stated below thus concentrates on designing approximation algorithms.

•
Under the agreeable jobs setting, we first address a pseudo-polynomial time optimal algorithm, and then derive a -approximation algorithm. If the jobs are small, i.e., no job processing times are larger than any calibration length, a better approximation bound  is achieved.

•
Under the agreeable calibrations setting, we give a 2-approximation algorithm.

2. Preliminaries
Problem definition. Given a single machine and a set of n jobs, each job j has release time , deadline , and processing time . Preemption of jobs is allowed, i.e., the processing of any job may be interrupted and resumed at a later time. We have the choices among K types of calibrations. When the machine performs a calibration of type  instantaneously, it can maintain calibrated for a length  at a cost . Jobs can only be processed in the calibrated states. We assume all inputs are integers. A feasible schedule guarantees that all jobs are scheduled non-overlapped in the time windows between their release times and deadlines. Without loss of generality, we assume that the calibrations are non-overlapping. Otherwise, if two calibrations overlap, we can always find a solution without changing the cost by delaying the latter calibration to start at the end of the former one. The goal is to find a feasible schedule that minimizes the total cost of the calibrations.

We give an illustrative example with three jobs and two types of calibrations, where , , ; , , ; , , , and , ; , . A feasible schedule with total cost of 10 is shown in Fig. 1.

Fig. 1
Download : Download high-res image (43KB)
Download : Download full-size image
Fig. 1. A feasible schedule.

We use solid rectangles and hollow rectangles to represent jobs and calibrations, respectively. Note that the cost of the schedule in which the last calibration starts at time 9 is no worse than that of the schedule in which the last calibration starts at time 8.

In the following we formally define the two special settings. By agreeable jobs, we refer to the fact that the jobs can be ordered as , and . Furthermore, we say that the problem has small processing times if job processing times are upper bounded by any calibration length, i.e., . By agreeable calibrations, we mean that the cost of each calibration is proportional to its length, i.e., , for some constant c. Without loss of generality, assume . Moreover, we also assume without loss of generality that the calibrations are sorted as  and .

To see the above problems are NP-hard, we give a standard reduction from the subset sum problem, known to be NP-complete, which asks if there exists a subset S of positive integers  such that , for a given integer . For any instance of the subset sum problem, we define a scheduling instance as follows.

Let , for all i. For each , we construct two calibration types with costs (and lengths), respectively,  and . There are  jobs with a common release time 0 and a common deadline . The first n jobs each have a processing time , for , and the last job has a processing time . Obviously, , and . The instance has both agreeable jobs and agreeable calibrations. Clearly, a feasible schedule requires a total length of calibrations at least D.

If the subset sum instance has a solution S, then picking up exactly one calibration from each of type 2i for  and one calibration from each of type  for  covers all jobs in length of D. If the scheduling instance has an exact cover at a cost D, it is not hard to see exactly n calibrations are used. In addition, either one calibration from type 2i or 2i−1 is taken but not both. It implies, the other way round, a solution of the subset sum instance by collecting i∈S if type 2i is used.

In the next sections, we will address approximation algorithms under the two settings, respectively.

3. Agreeable jobs with arbitrary processing times
In this section, we consider scheduling agreeable jobs with arbitrary processing times by proposing dynamic program algorithms. We first establish a pseudo-polynomial time optimal algorithm. Then we show how to transform it into a polynomial-time algorithm by losing a factor of (3+ε) on the objective value.

3.1. A pseudo-polynomial time optimal algorithm
It is very necessary for us to define several time points firstly that are pertinent in any schedule. For the unit processing time jobs case, Angel et al. described some dominating properties in [13]. We obtain the following by dividing the jobs into unit processing time jobs, i.e., we replace each job j by pj unit processing time jobs.

Naturally, let Φ:={dj−h|j=1,…,n,h=1,…,P}, where P=∑j=1npj.

Proposition 1

Proposition 1 [13]
There exists an optimal schedule O of value OPT where all calibrations start at times from the set Φ.

Due to Proposition 1, we observe that in the optimal solution O, calibrations can be represented as a set of blocks. Each block consists of consecutive calibrations. And in particular, we are interested in the schedules verifying Proposition 1 in which calibrations start as late as possible. So there must be some deadline in the last calibration, and there is no empty slot from the starting time of this block to that deadline. A time slot t refers to the time interval [t,t+1).

Indeed, consider each calibration one by one from the last one in an optimal solution. If there is some deadline in it, then we delay the second-to-last calibration until it encounters the last calibration or some deadline. If there is not any deadline in it, then it can be delayed until it encounters some deadline. This process does not increase any cost and it is still an optimal solution.

In what follows, we only consider those schedules satisfying Proposition 1. Moreover, since jobs have agreeable deadlines, the following proposition holds.

Proposition 2

Lemma 1 [14]
There exists an optimal solution in which jobs are scheduled in non-decreasing order of their deadlines.

Therefore, we can assume that in the optimal solution O, jobs are executed in the order 1,2,..,n. Job j starts only after the completion of job j−1. Each job is either scheduled entirely inside a block, or starts in a calibration of a block and completes in the next block of calibrations.

Let F:={f1,f1+1,f1+2,…,Pf1}, where f1=mink⁡fk. An optimal schedule uses at least one shortest calibration, and in the worst case, each unit of every job needs one shortest calibration. Thus f1≤OPT≤Pf1, i.e., OPT∈F. Let [n]:={1,…,n} and [K]:={1,…,K}.

We are now ready to describe our dynamic program.

Dynamic Program-I (DP-I). Let c(j,f,s,t,k) be the minimum completion time of job j in schedules for the first j jobs, as well as the state, where

•
f∈F is the upper bound of the cost of the opened calibrations,

•
s∈Φ is the starting time of the last block of calibrations,

•
t∈Φ and k∈[K] are the starting time and the type of the last calibration, respectively, and

•
job j∈[n] completes in between s and t+Tk.

When scheduling jobs according to the non-decreasing order of deadlines, each job may be scheduled across several calibrations. Specifically, when job j comes, it will be scheduled after job j−1 by Proposition 2. Thus, our idea of the dynamic program algorithm is to compute the number of time slots available for job j and schedule the remaining part of job j to several newly opened calibrations with the last one of type k starting at time t. We distinguish three cases (see Fig. 2 as an illustration):

1.
Job j is entirely scheduled across the existing calibrations and job j starts at time max⁡{c(j−1,f,s,t,k),rj}. Job j will be scheduled from max⁡{c(j−1,f,s,t,k),rj} to max⁡{c(j−1,f,s,t,k),rj}+pj.

2.
Job j is scheduled across several calibrations but starts at a time point in the existing calibrations and then completes at a time point in the newly opened calibrations. Job j will be executed from max⁡{c(j−1,f′,s′,t′,k′),rj} to t′+Tk′, then from max⁡{s,t′+Tk′} to max⁡{s,t′+Tk′}+pj−(t′+Tk′−max⁡{c(j−1,f′,s′,t′,k′),rj}).

3.
Job j is scheduled across several calibrations but starts at time max⁡{s,rj} in the newly opened calibrations. Thus, job j is executed from max⁡{s,rj} to max⁡{s,rj}+pj.

Fig. 2
Download : Download high-res image (172KB)
Download : Download full-size image
Fig. 2. Illustration of different cases for scheduling job j in DP-I. Let cj−1 be the completion time of job j − 1, and Os→t be the minimum cost to cover the interval from s to t.

To compute the value of a fixed state, such as c(j,f,s,t,k), there are three cases to consider. In fact, we just need to record the schedule which makes the completion time of job j minimum. Then choose this completion time of job j as the value of c(j,f,s,t,k). If not, when the state c(j,f,s,t,k) is fixed, it means that there are less available time slots for future jobs. So if c(j,f,s,t,k) is not minimum and corresponds to a feasible solution for future jobs, then the corresponding schedule with minimum c(j,f,s,t,k) is dominant since it leaves more time slots for potential future jobs.

The formal recursive function is included in the following theorem.

Theorem 1

For scheduling agreeable jobs with arbitrary processing times, DP-I computes an optimal solution in pseudo-polynomial time.

Proof

If the jobs {1,…,j} cannot be scheduled across the opened calibrations whose total cost is at most f, then the schedule is infeasible, and c(j,f,s,t,k)=+∞. Particularly, if there are not enough time slots for job j, i.e., c(j,f,s,t,k)>dj, then the completion time of the schedule is +∞.

We prove the other claims in the dynamic program. It is sufficient to show that we have tried all possibilities of scheduling jobs. As described above, we have three alternatives in mathematics:

1.
c(j,f,s,t,k)=max⁡{c(j−1,f,s,t,k),rj}+pj.

2.
When rj<t′+Tk′, and the schedule of the first j−1 jobs is of cost at most f′≤f−(Os→t+fk). Then c(j,f,s,t,k)=minf′,s′,t′,k′⁡{pj−(t′+Tk′−max⁡{c(j−1,f′,s′,t′,k′),rj})+max⁡{s,t′+Tk′}}.

3.
When rj≥t′+Tk′, and the schedule of the first j−1 jobs is of cost at most f′≤f−(Os→t+fk). Then c(j,f,s,t,k)=max⁡{s,rj}+pj.

For simplicity, let cj represent the completion time of job j. Therefore, the formal recursive function is as follows: c(j,f,s,t,k)=min⁡{cj,if cj=pj+max⁡{c(j−1,f,s,t,k),rj} and cj≤min⁡{dj,t+Tk}min⁡{cj|cj=pj−[(t′+Tk′)−max⁡{c(j−1,f′,s′,t′,k′),rj}]+max⁡{s,t′+Tk′},cj≤min⁡{dj,t+Tk},rj<t′+Tk′,f′+Os→t+fk≤f,f′∈F,s′,t′∈Φ,k′∈[K]}min⁡{cj|cj=max⁡{s,rj}+pj,cj≤min⁡{dj,t+Tk},rj≥t′+Tk′,f′+Os→t+fk≤f,f′∈F,s′,t′∈Φ,k′∈[K]}+∞ where Os→t represents the minimum cost to cover the interval from s to t. Observe that Os→t can be obtained with the pseudo-polynomial time algorithm described in [19].

We initialize the table as follows:c(1,f,s,t,k)={max⁡{s,r1}+p1,if f≥Os→t+fk and max⁡{s,r1}+p1≤min⁡{d1,t+Tk},+∞,otherwise.

The objective is to find the minimum cost f such that c(n,f,s,t,k)≤dn for some parameters f∈F,s,t∈Φ,k∈[K]. Thus we have proved the correctness of DP-I. In what follows, we will analyze its running time.

Time complexity. For DP-I, the number of states is n⋅|F|⋅|Φ|2⋅K=O(n3KP3f1) due to |F|=O(Pf1), |Φ|=O(nP), and |[K]|=K. To compute the value of a state c(j,f,s,t,k), we traverse all the values of f′, s′, t′ and k′, so the running time is O(n2KP3f1). Besides, the running time of computing Os→t is pseudo-polynomial. Hence, the total running time is pseudo-polynomial. □

In the following section, we turn to an approximation algorithm by scaling the running time down to polynomial.

3.2. An approximation algorithm
Observe that |F|=O(Pf1) and |Φ|=O(nP), where f1 and P can be pseudo-polynomial. In this section, we are focused on dealing with these pseudo-polynomial terms. In the first phase, scale the values in the set F. Let F′:={f1⋅(1+η)q|q=0,…,⌈log1+η⁡P⌉}, where η>0 can be arbitrarily small. Running DP-I with f∈F′ provides a feasible solution with a bounded loss of approximation factor, while the pseudo-polynomial term of f1 is removed. In the second phase, we deal with Φ whose size is pseudo-polynomial. Finally, we combine the above two phases to obtain a (3+ε)-approximation polynomial-time algorithm.

Phase 1. Scale the values in the set F.

Define the set of different objective values of the schedules as F′. Let F′:={f1⋅(1+η)q|q=0,…,⌈log1+η⁡P⌉}, where η>0 can be arbitrarily small.

We calculate the loss of scaling F to F′, that is, we show that after using DP-I with parameters j∈[n],f∈F′,s,t∈Φ,k∈[K], we will get a cost no more than (1+ε¯)OPT, where ε¯>0 can be arbitrarily small.

Lemma 1

Assume that f∈F′, and run DP-I with parameters j∈[n],f∈F′,s,t∈Φ,k∈[K]. Let f¯ be the minimum cost in {f|c(n,f,s,t,k)<+∞,f∈F′,s,t∈Φ,k∈[K]}. Then, f¯≤(1+η)nOPT. Particularly, if η=Θ(ε¯n), then (1+η)n≤(1+ε¯), and the size of F′ is still polynomial.

Proof

Recall Proposition 1: in the optimal solution O, calibrations can be represented as a set of blocks. Assume that there are in total n0 (n0≤n) blocks, and, given calibrations, jobs are scheduled as early as possible. For any i∈{1,2,…,n0}, let OPTi be the total cost of calibrations in the first i blocks in O, and Δi be the cost of calibrations in the i-th block, i.e., Δi=OPTi−OPTi−1.

In the optimal solution O, assume that job j completes in the i-th block. Aiming for the first j jobs scheduled across the first i blocks, we define a state c(j,gi,si,ti,ki), as well as the completion time of job j, where the cost gi∈F′ is no less than and the closest value to gi−1+Δi, si is the starting time of the i-th block, and, ti and ki are the starting time and the type of the last calibration in the i-th block, respectively. Let g0:=0 and Δ0:=0.

Note that for arbitrary two jobs, j1,j2, they may complete in the same block, which implies that gj1,gj2 (sj1,sj2, tj1,tj2, or kj1,kj2) can be identical.

Next, we will prove that gn0 obtained by this construction is no greater than (1+η)nOPT. And finally we show the cost of the solution returned by our dynamic program is no more than gn0.

To prove gn0≤(1+η)nOPT, we use induction.

The first job completes in the first block in O, and c(1,g1,s1,t1,k1) represents the current state. By definition, g1 is no less than and the closest value in F′ to OPT1, so g1≤(1+η)OPT1.

By induction hypothesis, for the first j jobs, job j completes in the i-th block in O, the state is c(j,gi,si,ti,ki), and, gi≤(1+η)iOPTi.

Then for the first j+1 jobs, if job j+1 completes in the i-th block in O, then the state is c(j+1,gi,si,ti,ki). The cost for the first j+1 jobs is still gi, and gi≤(1+η)iOPTi. Otherwise, job j+1 completes in the (i+1)-th block in O. Then the state is c(j+1,gi+1,si+1,ti+1,ki+1). Since gi+1 is no less than and the closest value in F′ to gi+Δi+1, thusgi+1≤(1+η)(gi+Δi+1)≤(1+η)((1+η)iOPTi+Δi+1)=(1+η)i+1(OPTi+Δi+1)=(1+η)i+1OPTi+1. Therefore, for n jobs, job n completes in the n0-th block in O. The state is c(n,gn0,sn0,tn0,kn0), and gn0≤(1+η)n0OPTn0≤(1+η)nOPT.

Finally, we just need to show that those states constructed from the optimal solution O exist in our dynamic program. For the state c(1,g1,s1,t1,k1), our dynamic program saves a schedule of the identical cost g1 with the minimum completion time of job 1, which implies that the solution of our dynamic program can leave more space to the future jobs than the optimal solution O.

Then assume that c(j,gi,si,ti,ki) corresponds to a feasible solution for the first j jobs. If job j+1 completes in the i-th block in O, then by the state c(j,gi,si,ti,ki) existing in our dynamic program, job j+1 in our algorithm completes no later than its completion time in O. Similarly, if job j+1 completes in the (i+1)-th block in O, job j+1 in our algorithm also completes no later than its completion time in O by the state c(j+1,gi+1,si+1,ti+1,ki+1) existing in our dynamic program.

Thus, by the dynamic program, we can choose the minimum cost gn0⁎ corresponding to all the states c(n,⋅,sn0,tn0,kn0), and gn0⁎≤gn0. In the end, f¯≤gn0⁎≤gn0≤(1+η)nOPT. Lemma 1 follows. □

Remark. Let η:=ε¯2n. Then (1+η)n=(1+ε¯2n)n≤eε¯/2≤1+ε¯. By Lemma 1, f¯≤(1+ε¯)OPT. Moreover, the time complexity includes the running time of computing Os→t and O(nK2|Φ|4|F′|2)=O(n5K2P4(1ηln⁡P)2)=O(1ε¯2n7K2P4ln2⁡P). Thus, the total time is still pseudo-polynomial without f1.

Next, we will discuss how to discretize Φ when restricting f to the set F.

Phase 2. Discretize Φ.

Recall Proposition 1, Proposition 2. In the optimal solution O, calibrations are represented as a set of blocks and each block consists of consecutive calibrations. Assume that in the last calibration of a block, there exists some deadline, and there is no empty slot from the starting time of this block to that deadline.

By this observation, we define Φ′ as follows and show a crucial lemma.

Let Φ′:={dj−⌊(1+ρ)ℓ⌋|j=1,…,n,ℓ=0,…,⌈log1+ρ⁡P⌉}, where ρ>0 can be arbitrarily small.

Lemma 2

For a block in the optimal schedule O, let d be the distance between the starting time of this block and some deadline dj′ in the last calibration. Then [dj′−(1+ρ)d,dj′−d]∩Φ′ is not empty.

Proof

Observe that there exists an ℓ satisfying d∈[(1+ρ)ℓ−1,(1+ρ)ℓ] by the definition of Φ′. Thus, ⌈(1+ρ)ℓ−1⌉≤d≤⌊(1+ρ)ℓ⌋. Naturally,dj′−(1+ρ)d≤dj′−(1+ρ)⌈(1+ρ)ℓ−1⌉≤dj′−⌊(1+ρ)ℓ⌋≤dj′−d. Hence we find a point dj′−⌊(1+ρ)ℓ⌋ satisfying dj′−⌊(1+ρ)ℓ⌋∈[dj′−(1+ρ)d,dj′−d]∩Φ′. Lemma 2 follows. □

Lemma 3

For scheduling agreeable jobs with arbitrary processing times, there exists a (3+ε′)-approximate solution in which the calibrations start at times in Φ′, where ε′>0 can be arbitrarily small.

Proof

We initially allow having overlapping calibrations (a time slot can be covered by more than one calibration), which will be handled later without increasing the solution's cost.

For a block I in the optimal solution O, in which all blocks start at Φ, there must be some deadline dj′ in the last calibration in block I. Let the starting time of this block be x, and then all the slots between x and dj′ are executing jobs. Let this length from x to dj′ be d. See Fig. 3 as an illustration. By Lemma 2, there exists a point s∈Φ′ such that the length from s to x is no more than ρd. Naturally, the calibrations in block I in O form a feasible solution to cover the length from s to x.

Fig. 3
Download : Download high-res image (80KB)
Download : Download full-size image
Fig. 3. Illustration of our analysis for a block in the optimal solution O.

By Lemma 2, we can also get that there exists a point t∈Φ′ such that if we open two consecutive identical calibrations starting at time t and t+Tk, respectively, and use the same type with the last calibration CkO in the block I in O, where CkO represents one calibration of type k in O, we can cover the CkO completely. See Fig. 3 for a clearer description.

Our constructed solution for covering block I is as follows. First, use the FPTAS algorithm for covering the length from s to t. Second, settle two identical calibrations of type k starting at t and t+Tk, respectively. Denote Fs→t to be the cost of the FPTAS algorithm [19] for covering the length from s to t. Let OPT(I) be the cost of block I in O. And let OPTa→b be the optimal value covering the length from a to b, where a and b are time points.

Thus, the constructed solution cost is no more than Fs→t+fk+fk. We claim that Fs→t≤(1+ε″)OPTs→t≤(1+ε″)(OPTs→x+OPTx→t). ThenFs→t+fk≤(1+ε″)(OPTs→x+OPTx→t+fk)≤2(1+ε″)OPT(I). The last inequality holds since the solution of block I is feasible for covering the length from s to x and the solution of block I except the last calibration of length Tk is feasible for covering the length from x to t. Besides, we have fk≤OPT(I). Eventually, we obtain Fs→t+fk+fk≤(3+ε′)OPT(I). We can construct a (3+ε′)-approximate solution for all blocks in the optimal solution. □

Phase 3. Get a constant approximation ratio.

In this section, we combine Lemma 1 and Lemma 3 to obtain a modified dynamic program which outputs a feasible solution of cost no more than (3+ε)OPT.

By Lemma 3, note that, in the worst case, the cost of a schedule can be as high as (3+ε)Pf1. Thus, the range of the cost is from f1 to f1⋅(1+η)q, where q=⌈log1+η⁡[(3+ε)P]⌉.

We define F″:={f1⋅(1+η)q|q=0,…,⌈log1+η⁡[(3+ε)P]⌉}. We slightly modify DP-I as follows:

Modified Dynamic Program-I (MDP-I). Let c(j,f,s,t,k) be the minimum completion time of job j in schedules for the first j jobs, as well as the state, where

•
f∈F″ is the upper bound of the cost of the opened calibrations,

•
s∈Φ′ is the starting time of the last block of calibrations,

•
t∈Φ′ and k∈[K] are the starting time of the second-to-last calibration and the type of the last two calibrations, respectively, and

•
job j∈[n] completes in between s and t+2Tk.

Here, we directly give the recursive function depending on Φ′ and F″. c(j,f,s,t,k)=min⁡{cj,if cj=pj+max⁡{c(j−1,f,s,t,k),rj} and cj≤min⁡{dj,t+2Tk}min⁡{cj|cj=pj−[(t′+2Tk′)−max⁡{c(j−1,f′,s′,t′,k′),rj}]+max⁡{s,t′+2Tk′},cj≤min⁡{dj,t+2Tk},rj<t′+2Tk′,f′+Fs→t+2fk≤f,f′∈F″,s′,t′∈Φ′,k′∈[K]}min⁡{cj|cj=max⁡{s,rj}+pj,cj≤min⁡{dj,t+2Tk},rj≥t′+2Tk′,f′+Fs→t+2fk≤f,f′∈F″,s′,t′∈Φ′,k′∈[K]}+∞ where Fs→t represents the cost to cover the interval from s to t. We will use the solution returned by the FPTAS algorithm for the knapsack cover problem [19].

We initialize the table as follows:c(1,f,s,t,k)={max⁡{s,r1}+p1,if f≥2fk+Fs→t and max⁡{s,r1}+p1≤min⁡{d1,t+2Tk},+∞,otherwise. The objective is to find the minimum cost f such that c(n,f,s,t,k)≤dn for some parameters f∈F″,s,t∈Φ′,k∈[K].

As described above, if the schedule is infeasible, the completion time of such a schedule is +∞. We also distinguish three cases (see Fig. 4 as an illustration): job j can be completely scheduled across the existing calibrations, job j starts in the existing calibrations and ends in the newly opened calibrations, or job j is completely scheduled across the newly opened calibrations.

Fig. 4
Download : Download high-res image (169KB)
Download : Download full-size image
Fig. 4. Illustration of different cases for scheduling job j in MDP-I. Let cj−1 be the completion time of job j − 1, and Fs→t be the cost to cover the interval from s to t by an FPTAS.

Our final goal is to prove the following theorem:

Theorem 2

For scheduling agreeable jobs with arbitrary processing times, MDP-I computes an approximate solution which achieves the performance ratio of (3+ε), where ε>0 can be arbitrarily small. The running time of MDP-I is polynomial in n and 1/ε.

Proof

By Lemma 1 and Lemma 3, we observe that MDP-I eventually considers our constructed solution, so the cost of the solution returned by MDP-I is a lower bound of the cost of our constructed solution. Thus, MDP-I outputs a feasible solution of cost no more than (3+ε′)(1+ε¯)OPT. Let ε′:=ε7, and ε¯:=ε4. Then (3+ε′)(1+ε¯)≤(3+ε).

Time complexity. For MDP-I, since |F″|=O(log1+η⁡[(3+ε)P]), |Φ′|=O(nlog1+ρ⁡P), and |[K]|=K, the number of states is n⋅|F″|⋅|Φ′|2⋅K=O(n3K(log1+η⁡[(3+ε)P])(log1+ρ2⁡P))=O(1η1ρ2n3Kln3⁡P)=O(1ε3n4Kln3⁡P), where η=ε2n and ρ=ε. To compute the value of a state, we traverse all the values of f′, s′, t′ and k′, so the running time is O(1ε3n3Kln3⁡P). Moreover, Fs→t can be computed in polynomial time in n and 1/ε.

Hence, the overall running time is polynomial in n and 1/ε. □

4. Agreeable jobs with small processing times
In this section, we consider scheduling agreeable jobs with small processing times, in which not only jobs have agreeable deadlines, but also job processing times are upper bounded by any calibration length.

For this problem, we also provide a pseudo-polynomial time optimal algorithm, and then we adapt it into a polynomial running time algorithm by losing a factor of (2+ε) on the objective value.

We follow a similar approach as in the previous section. The difference derives from the fact that when scheduling jobs according to the non-decreasing order of deadlines, each job must be scheduled across no more than two calibrations. Owing to this point, we only need four parameters for the new dynamic program.

4.1. A pseudo-polynomial time optimal algorithm
Different from the previous definition, we can redefine F:={f1,f1+1,…,nf1}, where f1=mink⁡fk. Because each job can fit into one single calibration, we get f1≤OPT≤nf1, and OPT∈F. Thus, we can write a new dynamic program below, based on F and Φ.

Dynamic Program-II (DP-II). Let c(j,f,t,k) be the minimum completion time of job j in schedules for the first j jobs, as well as the state, where

•
f∈F is the upper bound of the cost of the opened calibrations,

•
t∈Φ and k∈[K] are the starting time and the type of the last calibration, respectively, and

•
job j∈[n] completes in between t and t+Tk.

When scheduling jobs according to the non-decreasing order of deadlines, each job must be scheduled across no more than two calibrations. Specifically, when job j comes, it will be scheduled after job j−1 by Proposition 2. Thus, our idea of the dynamic program algorithm is to compute the number of time slots available for job j and schedule the remaining part of job j to a newly opened calibration of type k starting at time t. We distinguish three cases:

1.
job j is entirely scheduled within the same calibration as the completion time of job j−1,

2.
job j is scheduled across two calibrations: it starts in the same calibration as the completion time of job j−1 and ends in a newly opened calibration, or

3.
job j is scheduled within a different calibration as job j−1.

To compute the value of a fixed state, such as c(j,f,t,k). In fact, we just need to record the schedule which makes the completion time of job j minimum. Then choose this completion time of job j as the value of c(j,f,t,k). The formal recursive function is included in the following theorem.

Theorem 3

For scheduling agreeable jobs with small processing times, DP-II computes an optimal solution in O(n5K2P2f12) time.

Proof

We write the formal recursive function as follows: c(j,f,t,k)=min⁡{cj,if cj=pj+max⁡{c(j−1,f,t,k),rj} and cj≤min⁡{dj,t+Tk}min⁡{cj|cj=pj−[(t′+Tk′)−max⁡{c(j−1,f′,t′,k′),rj}]+max⁡{t,t′+Tk′},rj<t′+Tk′,cj≤min⁡{dj,t+Tk},f′+fk≤f,f′∈F,t′∈Φ,k′∈[K]}min⁡{cj|cj=max⁡{t,rj}+pj,rj≥t′+Tk′,cj≤min⁡{dj,t+Tk},f′+fk≤f,f′∈F,t′∈Φ,k′∈[K]}+∞

We initialize the table as follows:c(1,f,t,k)={max⁡{t,r1}+p1,if f≥fk and max⁡{t,r1}+p1≤min⁡{d1,t+Tk},+∞,otherwise. The objective is to find the minimum cost f such that c(n,f,t,k)≤dn for some parameters f∈F,t∈Φ,k∈[K].

The correctness of the DP-II can be shown along the same line as the proof of Theorem 1 and is omitted. The remaining analysis is about the time complexity.

Time complexity. For DP-II, the number of states is n⋅|F|⋅|Φ|⋅K=O(n3KPf1) due to |F|=O(nf1), |Φ|=O(nP), and |{1,…,K}|=K. To compute the value of a state, we traverse all the values of f′, t′ and k′, so the running time is O(n2KPf1). Hence, the overall running time is O(n5K2P2f12). □

In the next section, we will obtain an approximation algorithm by reducing the running time to polynomial.

4.2. An approximation algorithm
This section aims to avoid going through all different parameter values in DP-II to acquire a polynomial-time algorithm. Thus, we concentrate on the sets F and Φ whose sizes are pseudo-polynomial and reduce the sizes of such sets. Define the new set of different objective values of the schedules as F′.

Let F′:={f1⋅(1+η)q|q=0,…,⌈log1+η⁡n⌉}. Then |F′|=O(log1+η⁡n). By Lemma 1, considering the values in F′ can lead to a solution whose cost is no more than (1+ε¯)OPT, where η=ε¯2n.

Similarly, we define the new set of the starting times of the calibrations as Φ′:={dj−aT1|j=1,…,n,a=0,…,n}. Then |Φ′|=O(n2).

Next, we show that if we restrict the starting times of calibrations to Φ′ and do not restrict the costs, then there exists a solution of cost no more than twice the optimal cost. Overlapping calibrations are allowed, which will be handled later without increasing the cost of the solution.

Lemma 4

For scheduling agreeable jobs with small processing times, there exists a 2-approximate solution in which the calibrations start at times in Φ′.

Proof

Assume the sequence of the calibrations in O to be {Ci1O,Ci2O,…,CiqO}, where q∈N and CiuO represents one calibration of type iu in O.

We prove that when restricting the starting times of the calibrations in S to Φ′, our desired conclusion can be obtained. Let CiuO be a calibration in O such that it does not start at some time in Φ′. We replace it with two consecutive calibrations of the same type such that the first one starts at a time point in Φ′ and such that both calibrations jointly cover the same interval as CiuO.

We take a block of consecutive calibrations in O as an illustration. In Fig. 5, the block consists of {CiuO,Ciu+1O,…,Ciu+vO}. The starting time of the calibration CiuO is at most at a distance of P from a deadline dh since the schedule O verifies Proposition 1. Assume the distance between dh and the starting time of CiuO to be ℓ. Furthermore, since maxj⁡pj≤T1, then ℓ≤P≤nT1. There is an integer point t=dh−aT1∈[dh−ℓ−Tiu,dh−ℓ]∩Φ′, where a∈{0,…,n}. Thus, we can replace such a calibration by two identical calibrations starting respectively at t and t+Tiu.

Fig. 5
Download : Download high-res image (82KB)
Download : Download full-size image
Fig. 5. Illustration of the relationship between the optimal solution O and the constructed solution S.

Repeat such a modification as long as there is a calibration that does not start at a time point in Φ′ in the schedule (except the newly added calibrations).

For every calibration in O, there are two consecutive identical calibrations of the same type, in which the starting time of the first one belongs to Φ′. All jobs stay at their original times as in O. Hence, the cost of such a schedule is 2OPT. □

Since calibrations may overlap each other, the schedule is feasible for jobs but not necessarily for the calibrations. To make all calibrations used be non-overlapping, we need the following observation.

Observation 1

A schedule with overlapping calibrations can be transformed into a schedule without overlapping calibrations in polynomial time without increasing the cost of the solution.

When two calibrations overlap, we can postpone the second calibration to start as soon as the first calibration ends. Meanwhile, all the jobs stay scheduled at their initial time slots. We modify at most 2n calibrations. Refer to [16] for the same Observation to deal with the overlapping calibrations polynomially for scheduling agreeable jobs with arbitrary processing times.
By Lemma 4, the range of the choices of the cost needs redefining. Let F″:={f1⋅(1+η)q|q=0,…,⌈log1+η⁡[(2+ε)n]⌉}. Then we consider a modified dynamic program based on F″ and Φ′.

Modified Dynamic Program-II (MDP-II).

•
Restrict the cost to F″.

•
Restrict the starting times of calibrations to Φ′.

•
When a new job comes, there are two possibilities:

–
no new calibrations are required, or

–
add two new consecutive calibrations of the same type.

Under the above setting, run DP.
The objective is to find the smallest f such that c(n,f,t,k)≤dn for some parameters f∈F″,t∈Φ′,k∈[K].

With the above procedure, we are able to achieve a feasible solution whose cost is no more than (2+ε)OPT, where ε>0 can be arbitrarily small.

Theorem 4

For scheduling agreeable jobs with small processing times, MDP-II computes a feasible solution of cost no more than (2+ε)OPT, where ε>0 can be arbitrarily small. The running time of MDP-II is polynomial in n and 1/ε.

Proof

We combine Lemma 1 with Lemma 4 to prove the theorem. Observe that the schedule S′ of cost f(S′) returned by MDP-II allows the calibrations to overlap. Thus f(S′) is a lower bound of the cost of such a schedule. Moreover, f(S′)≤2OPT⋅(1+ε¯) by Lemma 1. Thus f(S′)≤2(1+ε¯)OPT=(2+ε)OPT, where ε=2ε¯.

Eventually, perform the same operations as in Observation 1 to make all calibrations non-overlapping, and get a feasible schedule of cost no more than f(S′) and then no more than (2+ε)OPT.

Time complexity. For MDP-II, the number of states is n⋅|F″|⋅|Φ′|⋅|[K]|=O(1εn4Kln⁡n), due to |F″|=O(log1+η⁡[(2+ε)n]), |Φ′|=O(n2), and |[K]|=K. To compute the value of a state, we traverse all the values of f′, t′ and k′, so the running time is O(1εn3Kln⁡n). Hence, the overall running time is O(1ε2n7K2ln2⁡n). □

5. Agreeable calibrations
In this part, we consider a case where the cost of each calibration is equal to its length. We give a 2-approximation algorithm: using the Preemptive Lazy Binning (PLB) algorithm [13] with the shortest calibration.

Theorem 5

For the problem with agreeable calibrations, the PLB algorithm with the shortest calibration is a 2 approximation.

Proof

As shown in Fig. 6, we replace all calibrations in O with type 1 such that they cover the initial calibrations {Ci1O,Ci2O,…,CiqO}, i.e., if a calibration has length Tiu, then we replace it with ⌈Tiu/T1⌉ calibrations of type 1. Jobs stay scheduled at the same time slots. See S′ in Fig. 6. Similarly, if there exist some overlapping calibrations, perform the operations as in Observation 1. Now we obtain a non-overlapping schedule S.

For any CiuO in O, the constructed S′ above will cover it by at most Tiu+T1≤2Tiu since T1≤Tiu. So the cost of S is no more than twice of the optimal value.

Recall that the PLB algorithm proposed in [13] returns a schedule with the minimum number of calibrations in polynomial time when there are calibrations with one type. If we are only allowed to use the shortest calibration of length T1, S is a feasible schedule, while the PLB algorithm returns a schedule with at most as many calibrations as in S.

Hence, the cost of the returned schedule using the PLB algorithm with the shortest calibration is no more than the cost of S and then no more than twice the optimal value. □

6. Conclusion
This paper studied the scheduling problem with many types of calibrations. Up to our knowledge, we are the first to propose approximation algorithms for this model. In particular, two nontrivial special cases under mild agreeable assumptions were investigated. Although the problem seems very hard, a PTAS is not excluded even for the general problem without the assumptions. To improve the approximation bounds, novel techniques and more insights are needed.