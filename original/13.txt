Abstract
This paper explores how robots that are not designed for being social can still act and be perceived as social and what form this social interaction takes. It does so through a case study of Automated Guided Vehicles (AGVs) at a Norwegian hospital that interact with patients, nurses, caregivers and other machinery. These robots are primarily tasked with moving goods such as medical equipment, food and garbage and are programmed to be automated, e.g., taking hospital elevators by themselves. Although the robots are unanthropomorphized, our research shows a strong perception of autonomy of the AGVs, specifically in relation to how voices and appearances of robots can make the robots more acceptable through appearing more “alive.” They take part in an intricate domestication process as non-human actors relating to the human actors that also frequent the hospital corridors, making them part of the digitalization infrastructure at the hospital. This is particularly tied to their usage of the local Norwegian dialect and a projection of clumsiness, which gives them a sense of personality, or an impression of being friendly animal-like creatures one can enjoy observing without interacting with. This is framed theoretically through three dimensions of understanding the domestication of social robots as healthcare technology. The first dimension is Practical Domestication, where using voice as a "human factor" in unanthropomorphized robots can be of great value, if done well, by making them more approachable. A non-standardized voice can be an effective tool to give the robot a sense of personality. The second dimension is Symbolical Domestication, seeing how unanthropomorphized robots present novel ways of achieving trust from the public. When people get to know the non-perfect robot in itself, not masked as a person or animal, there is interest and trust in the machine. The last dimension is Cognitive Domestication, seeing how human practices change through the interaction with technology. Additionally, we suggest that there is a fourth dimension, which we term Social Domestication, at work.

Previous
Next 
Keywords
Hospital robots

Domestication

Robots

Automated Guided Vehicle (AVG)

Humanrobot interaction

1. Introduction
Technology supporting and managing patients and personnel in healthcare settings is increasingly receiving research focus, as novel technologies such as robots are being used in the global healthcare sector are seen as potential technological supplements to help mitigate demographic challenges. In 2017, The World Health Organization (WHO) estimated that more than one billion people—primarily elderly and people with disabilities—are in need of one or more assistive products and that only 10% of those in need actually have access to this technology (World Health Organization, 2017). The lack of access can lead to a technological lock-in—excluding people from participating fully in society—accompanied by “poverty and isolation; [thereby] increasing the impact of disease and disability on the person, their family and on society as a whole” (World Health Organization, 2017, p. 2). This number is projected to increase to 2 billion in 2050, showcasing major societal challenges that increased manpower alone cannot solve. Technology is often suggested as a possible solution; however, there are still multiple problems with existing technologies used in healthcare settings “such as device failure, inappropriate use, insufficient user-training and inadequate inspection and maintenance” (Newtown et al., 2010, p. 15), which can lead to “junction work” of mitigating systems to fit, often done by nurses (Piras and Zanutto, 2016). This invisible work is often overlooked and/or underpaid (Stisen et al., 2016). Technological innovation and implementation are thus highly needed and are indeed being introduced to many sectors of society at a rapid pace, as the world is entering the age we term the Robotocene (Søraa and Fyhn, 2018). Given these realities we should both be aware and proactive on how we deal with the increase of robots in society.

As the pillar of modern health care, hospitals are key in leading technological adaptation and development, e.g., through interactive displays to support coordination and communication at surgery wards (Bossen and Jensen, 2008), digitalized medication plans (Bossen and Markussen, 2010) and tests of commonplace technologies such as mobile phones (Lee et al., 2011), radio-frequency identification for trauma care (Parlak et al., 2012), mobile technology for transmitting, storing, modifying and retrieving data (Standing and Standing, 2008; Tang and Carpendale, 2008), transitions from paper to digital systems at emergency departments (Vezyridis et al., 2011), as well as the introductions of electronic health records (Barrett and Stephens 2017). Pilot projects can, according to Hertzum and colleagues (2019), lead to uncertainty of the technology if the messiness of pilot implementation in information systems design becomes too dominant. At a larger system level, technological implementation in hospitals is also transforming the healthcare sector, as seen through Computer-Supported Cooperative Work (CSCW) which “studies how healthcare work is collaboratively and practically achieved and designing systems to support that work” (Fitzpatrick and Ellingsen, 2013, p. 609).

Navigating healthcare technology is no easy task. Harrison and colleagues (2007) describe five types of sociotechnical interaction of Healthcare Information Technologies (HITs): (1) how they change existing social systems, (2) how technical and physical infrastructures mediate their use, (3) how social systems mediate HITs’ use, (4) how the social systems are in turn changed, and (5) how this interaction leads to changes in HITs’ properties. Technology also has negative consequences, as Ash and colleagues (2004, p. 104) describe in their study of two main error groups of Patient Care Information Systems (PCISs): “those in the process of entering and retrieving information, and those in the communication and coordination process that the PCIS is supposed to support.” However, Berg (1999, p. 87) argues that good ICT implementation is “meticulous interrelation of the system's functioning with the skilled and pragmatically oriented work of health care professionals.” ICT can also take attention and time away from patients that are being consulted or examined, as Chen and colleagues (2011) show in their study on how healthcare personnel have to do “micro-negotiation with computers” when communicating with patients in addition to their other tasks. The digitization, automation and robotization of the healthcare sector are dependent on hospitals leading the way. In Norway this is made possible by the five largest hospitals being research hospitals connected to universities which, in addition to their core task of care, healing and rehabilitation, also provide innovation and research development. But how can healthcare systems meet the challenges of implementing technology in a just and responsible way? Van Wynsberghe argues:

It will be a test for healthcare systems around the world to maintain standards of care, let alone improve quality of care. Policy makers are grappling with the question of how such setbacks are to be mitigated. One possible answer: robots. (Van Wynsberghe, 2016, p. 1)

One of the key challenges when designing and implementing robots is how user acceptance comes into play. As Broadbent and colleagues (2009) describe, there is a need for research that investigates potential users’ needs and expectations of the interaction between robot and human in order to increase acceptance in specific situations. When discussing robots in healthcare— especially social robots—design choices often lean towards anthropomorphization (the tendency to project a sense of humanity towards an object, e.g., machines). There is a distinction in the assessment of robots’ success, depending on the type of robot (e.g., the success of an entertainment robot is different than that of an industry robot). In the following section, we will unwrap selected previous research specifically on hospital robots, before returning to how hospital service robots in specific can be understood.

1.1. Related works
Several studies indicate that robots that do not look human, but rather as tools, e.g., vacuum-cleaners and trashcans, often get treated as animals or pets in a zoomorphization process (Flanagan and Nissenbaum, 2007; Forlizzi and DiSalvo, 2006; Yang et al., 2015). This phenomenon is discussed by Seibt (2018, p. 138) through an ontology of asymmetric social interactions which she discusses through a lens of “sociomorphization.” This sociomorphization of dealing with robots have parallels in other studies. For example, Ljungbald and colleagues (2012) found four major understandings of robots seen through the eyes of hospital staff: alien, machine, worker and work partner. Which of these are applied is in the eye of the beholder and depends upon which usage area and agency we humans assign to them. Several factors, e.g., gender, age and social context impacts how robots are received (Mutlu and Frolizzi, 2008; Rossetti et al., 1998)—e.g., robots can be seen as positive in maternity wards, but negative in cancer wards (Cheon and Su, 2017).

In their hermeneutic study of telecare, Karlsen and colleagues (2019, p. 1309) warn that, rather than easing burdens, new technology might add burdens to care practices, finding that “family caregivers experienced that telecare could benefit them but was also an additional responsibility.” Cheon and Su (2017, p. 191) argue that “roboticists and designers need to make transparent what forms of future users they desire and expect in their design processes”—i.e., similar to what Woolager (1990) calls “configuring the user” through active co-design of robotic systems. This, they argue, can prevent robots being designed by experts who often envision an “ideal robot [that is] diametrically opposed to how robots are envisioned today by users” (Cheon and Su, 2017, p. 192). In their longitudinal studies of robots in homes, they found that users first saw robots as tools but gradually changed their perceptions to see the robots as agents that facilitated inter-social communication. In a study of an autonomous delivery robot, Mutlu and Frolizzi (2008) provide design guidelines for robots in organizations, arguing for “patient profiles” in relation to robots. They divide such profiles into four main categories which they call (1) workflow, (2) (political) goals, (3) social/emotional context, and (4) use of their physical environment (Mutlu and Frolizzi, 2008, p. 291):

(1) When staff interruptibility is low, interruptions by the robot are perceived as worsening the workflow. (2) A misalignment between the goals of the unit and the benefits provided by the robot might cause people to reject the use of the robot.

(3) Intimate relationships between caretakers and patients cause a lower tolerance for interruptions. (4) In high traffic and/or cluttered hallways, the robot is perceived as taking precedence over people.

These four focus areas are also present in some form in other studies. For example, Auger (2014, p. 41) asks how robots can become domestic products, pointing to better inclusion of designers and arguing that “ideas of adaptation and domestication, applied through design to robot related technologies, could provide new routes for robots.” Su and colleagues (2014) provide a discourse analysis of how health care robots are presented through video in hospital contexts, finding that certain utopian goals of robots go hand in hand with possible dystopian consequences. They provide several examples: A new type of doctor who can work both locally and remotely is combined with the risk of local doctors being seen as “second best.” Healthcare systems where care can become democratized with everyone having to the best doctors through telemedicine is combined with the risk of no one settling for less than the best. Staff may be empowered and see robots as their co-workers in keeping the hospitals running neatly, but there is the risk that the staff become enslaved to the robots, adding burdens of robot maintenance to their already time-pressed duties. Hospital conglomerates where multiple hospitals may share robot resources is combined with the risk of hospitals competing to be the “main hub.” And, lastly, better care assistance, where robots enhance the overall level of care is combined with the risk of robots being too effective, outperforming humans and relegating them to only menial tasks. There have also been several studies of social robots in elderly care centers (Sabelli et al., 2011), including research focusing on the importance of social cues for increasing humans’ receptivity for robot interaction (Parekh and Lim, 2020).

Bartneck and colleagues (2009) recommend five key criteria for assessing social robots: anthropomorphism, animacy, likeability, perceived intelligence and perceived safety. However, these criteria and the previous research are not necessarily transferable to industrialized service robots. Service robots follow a quite different path of “domestication”—especially in terms of social interaction—than robots designed primarily for being social. In the following part we introduce a robot case study used in this paper: Automated Guided Vehicle (AGV) service robots.

1.2. Unanthropomorphized AGV robots in hospital corridors
Not all robots are shaped like humans (androids) or like animals (zoomorphic robots). Some robots are shaped more specifically to their task, e.g., industrialized arm robots and service robots. In this case study we will explore one example of such a task designed robot: Automated Guided Vehicles (AGVs). The 21 AVGs in question are implemented at St. Olav's hospital in Trondheim, Norway. They drive around in the corridors of the hospital carrying goods such as medical equipment, food and waste. The robots follow a pre-defined path between two points of pickup and delivery, based on transportation algorithms. They use lasers to navigate and have sensors to avoid people, obstacles, and dangerous situations. In 2006, St. Olav's became the first hospital in Scandinavia to implement these kinds of robots. The hospital is connected to the Norwegian University of Science and Technology (NTNU), Norway's largest university, which has a special national responsibility to educate the majority of Norway's engineers and technical staff. The AGVs at St. Olav's primarily transport heavy items, using an ID-chip to collect the goods to be transported from wall-mounted pick-up and delivery points and then transporting them on the optimal route. The ID-chips are removed when the AGV has delivered the goods to the target location. The AGV will then receive a signal on which new ID-chip is closest, allowing it to be routed to the nearest collection of goods to be retrieved.

They navigate by built-in sensors and scanners. These register if humans or objects are in front of it, in which case it will stop. If items are to be transported across different hospital floors, the AGVs take an elevator, while announcing their movement to anyone within hearing range. When an AGV is using an elevator, no one else is permitted to use that elevator. Although it is possible to trick the robot and ride with it in the elevator, the robot takes its time parking in the elevator, making it more time consuming than waiting for another elevator or taking the stairs. When the AGVs start running out of energy, they drive to the nearest charging station and recharge their batteries. An important feature of the AGVs is their work environment, i.e., they inhabit the same work environment as humans do, sharing their space. The robots can be seen below: Fig. 1 is the robot itself, and in Fig. 2 the robot can be seen loading goods:

Fig 1
Download : Download high-res image (376KB)
Download : Download full-size image
Fig. 1. An example of an AGV.

Fig 2
Download : Download high-res image (394KB)
Download : Download full-size image
Fig. 2. An example of an AGV loading goods.

AGVs are portable service robots and come in several varieties based on how they are guided, e.g., wire, guide tapes, laser targets, gyroscopic and cameras. They are categorized by the International Federation of Robotics as service robots and, accounting for 41% of global sales, represent the largest segment of service robots sold annually (followed by maintenance robots, 39% and vacuum cleaners, 19%) (International Federation of Robotics, 2019). This paper will not go into the technical details, as it is out of the scope of our study (see however: Cummings et al., 2012; Gaskins and Tanchoco, 1987; Le-Anh and De Koster, 2006; Samson et al., 1993; Vis, 2006).

Our focus is to unpack how robots are adapted within hospitals by looking at how AGVs are “domesticated” by different people that interact with them at the hospital, i.e., how humans adapt to the robots and vise-versa. Our main inquiry is how robots—such as industrialized service robots like the AGV—that are not designed for their social skills can still act and be perceived as social and what form this social interaction takes. We will first give an account of our theoretical approach of Domestication Theory, followed by our empirical basis and methodological venture point. This will be followed by a discussion of the findings—where we present three key features of the robots—and seeing how the AGVs could be understood through Mutlu and Frolizzi's (2008) “design guidelines” and Su and colleagues’ (2014) inquiries into the "mundanely miraculous” robots in healthcare.

2. Theoretical considerations for domesticating robots
This study draws on Science and Technology Studies (STS) (Callon 1987; Latour 1987; Law and Bijker 1992), giving a social-constructivist investigation into how the relations between technology and human actors are embedded in intricate socio-technical networks and systems that constantly change and affect each other. STS challenges reductionist theories such as technological determinism by suggesting that societal technology developments are not determining socio-cultural usage of said technology, but rather that there is a co-production occurring between technology and society. The production is mutual as people influence how the technology works, how it functions and how it is developed, while the technology also influences people's behavior (Lagesen, 2012). Thus, STS aims to open the black-boxes of technology, radically challenging how technological developments are being implemented by conducting bottom-up studies of how users relate to technologies. The field is especially potent at investigating how different actors in the healthcare system relate to technology (Vikkelsø, 2005) and how the users shape and reshape technology (Oudshoorn and Pinch, 2003). When exploring how robots are implemented in hospital settings and how different human actors and non-human actors relate to them, STS perspectives can help trace how robots within the larger socio-material networks they inhabit, how robots are understood by the people it meets on its path and, consequently, how they are given specific meanings.

Within STS, Domestication Theory has been suggested as a useful theoretical analytical tool (Lie and Sørensen, 1996) to study how humans relate to technology in their daily lives and habitats. The focus is on how technology is domesticated into everyday life in three overlapping and continuously ongoing dimensions: practical, i.e., how users physically take technology into use; symbolic, i.e., what meaning-bearers the technology represents for the users; and cognitive, i.e., how users learn and develop by using the technology. An overview is provided in Fig. 3 below, where our chosen topic of domesticating robot technology can be seen drawing on all three dimensions:

Fig 3
Download : Download high-res image (160KB)
Download : Download full-size image
Fig. 3. Dimensional model of domesticating technology.

This approach builds on other strains of domestication theory (Silverstone and Haddon, 1996) which regard domestication of technology as something carried out in a more linear phase model. The dimensional model of domestication focuses more strongly on how humans adapt to technology in a two-way process, i.e., how we shape the technology to our daily lives and how the technology also shapes us in return. Previous research on robots (Broadbent et al., 2009) has shown that there are primarily two ways in which user acceptance of robots might change: by changing the robots, or by changing the users. Domestication theory can be utilized to challenge this binary approach, arguing that there is a co-production process between the technology and the users; they are inevitably both changed through mutual interaction. Making technology work requires an awareness of the multiple dimensions of configurability (Balka and Wagner 2006, p. 229), and dimensions of user domestication of technology can provide knowledge on such configurability.

Going back to Auger's (2014) “Ideas of adaptation and domestication,” we can thus see that domestication theory can provide us with analytical lenses on how specific human-robot interaction can happen in practice. This is a dimensional, not linear, process, featuring an overflowing network of processes between technology and human actors. Auger uses “domestication” as a concept to distinguish between domestication of technologies and domestication of products: “This approach means that a domesticated robot could be seen as a product rather than as an object of research or science fiction, thereby introducing the rules and expectations of the domestic habitat and the role of design in adapting technology to it” (Auger, 2014, p. 22). This shows how robots (in Auger's case, home robots) are seen as confusing by people who, partly due to influences from science fiction, do not really know what to think about them. However, in the hospital we have a different setting that involve less complex robots than the social robots made for the home-sphere. Thus, in our study domestication will not mean “taking robots into the home” but rather taking robots into daily life. Because they are not overly complex on paper, the AGVs in question are, in Su and colleagues’ (2014) terminology, "mundanely miraculous,” as they only promise to do the mundane tasks – but with an almost accidental perceived autonomy. However, as we will see, the domestication of service robots is not a straightforward process.

3. Methodology
The data used for this article stems from a qualitative part of a large study of how people and architecture interacted in a hospital setting. It was based on a collaboration between the Faculty of Architecture at the Norwegian University of Technology and Science (NTNU) and the Women-Child Centre at St. Olav's University Hospital, in Norway. The qualitative and explorative part of the project was called “From spaces to places—Domestication processes of hospital architecture.” During this study, a new actor was found to play a novel part in the hospital architecture—the AGV. During the research for the larger project on how people adjusted, used, got around and were affected by the architecture, there were some methodical conundrums with how the interviewees’ responses were linked to physical spaces, as the effects that architecture have on people often plays out in the subconscious. If interviewees reported feeling happy, we would not know if that happiness was linked to the architecture or something else. As the experience of being in a hospital is connected to the discourses of what a “hospital” means for the individual person, e.g., as can be seen in this statement by one of our informants: “It doesn't feel like a hospital when there are colors on the walls, and not the hospital-white, light blue, or light green.” This is connected to the already existing discourses about hospitals. In an earlier, similar study on the architectural quality of a Canadian hospital, Alvaro and colleagues (2015) used observational techniques for analyzing the perceived use of the hospital buildings in how staff and patients used the different hospital spaces, but also how they interacted with each other. Our exploratory study of the user experiences at the Women-Child Centre of St Olav's Hospital followed this naturalistic observational research approach, in which observations of employees, visitors and patients were the starting point for understanding the way people make sense of their environment. For this purpose, we used two main methods for the data collection: go-along interviews, and naturalistic observations, as described below.

3.1. Go-along Interviews
Go-along Interviews were the primary empirical method utilized for our study. Healthcare staff, patients, and visitors were followed on their routes at the hospital, with the researchers asking questions and hearing their stories concerning why they move like they do, where they are heading to, and what they were feeling at the moment. Hospitals are places where people experience life changing moments, and there are strong feelings involved. The Women-Child Centre, which includes the Children's Cancer Department, is often the site of especially strong, life-altering feelings and experiences. The visiting parents shared stories of sadness and hope of living in the hospital with their child, walking the corridors, finding small moments of calmness or special places of peace—months after months. The interviewees were primarily recruited from the hospital's “mother-child centre” (as this was the Centre collaborating on the research project) with an emphasis on patients and people dealing directly with patients, like their visitors. Healthcare staff interviewed were mostly medical doctors and nurses, but also nurse-assistants and cleaning personnel. Eight go-along interviews with healthcare personnel were conducted, as well as eight interviews with parents of sick children. The interviews lasted approximately one to two hours. A tape recorder was used, and the interviews were later transcribed ad verbatim. The ethical data application was approved, provided we did not use the tape recorder in public settings. This led us to not use the recorder when walking through areas with other people and only using the recorder when alone. Go-along interviews included nurses in the children's cancer department; nurses in the children's orthopedic policlinic, and an additional group meeting with the healthcare staff members from the childhood medicine and surgery, teachers, and parents at the children's medicine and parents at the children's cancer department

Open interviews are inductive in their design—they do not seek to deductively test hypotheses, but rather to explore a topic with ontological inquiries. The go-along interviews were formed as traditional open interviews to create new knowledge through exploration. This type of exploratory methodology can be seen as related to phenomenological studies. Carpiano (2009, p. 263) emphasizes that “place may matter for health (particularly in terms of the participants)” and that it "may facilitate researchers’ understandings of local knowledge as well as the social and physical context.” We agree with Carpiano, as our study in a health context also emphasizes the material space as important for how health is perceived as a social infrastructure—where in our focus, robot technology also roams. In addition to the go-along interviews, six conversations with different visitors, healthcare staff and parents were also noted down, anonymized and transcribed.

3.2. Naturalistic observations
Naturalistic observations were used to monitor the use of specific areas and how people used the areas, without their awareness, though in a qualitative matter. This method was also possible to mix with awareness and short questions on specific behavior. As Alvaro and colleagues (2015) point out, naturalistic observation is not just “watching people,” but is based on theories of how spaces are used. We did four naturalistic observations in different places in the hospital, with each observation lasting several hours which involved taking pictures, writing down conversations and sounds, registering subjective feelings of temperature and other senses, noting people asking for directions, people looking for signs, employees taking breaks and everything else we found notable. The observations included different areas of the hospital building: the atrium, cantina, Children's Cancer Department, Aula, the hospital school and the hospital kindergarten. In addition, two “show and tell tours” were done: one with the head of all children's departments and the second with a “welfare nurse” who was hired to increase the wellbeing of the children who were patients. The show and tell tours revealed experiences of the staff—such as bad planning of doors that open in the wrong direction and high doorsteps to the balcony of the patients’ rooms—that make it useless for many users. These tours also showed how the AGVs were used in the children's education in the hospital; thus, the tours gave a lot of information about the users.

This methodology provided new insight on how people used and gave meaning to the environment around them, e.g., the architectural spaces (the study that produced our data was primarily concerned with the use of the hospital's architectural space). Even though the larger study had another focus than robot-human interaction, the explorative design led us to robots as important parts of people's experiences in the hospital. The robots became a side-path in many interviews and observations, even though the robots were not a planned part of the study. The salience of robots was thus discovered because of the explorative methodology and might have been missed if we had used questionnaires or another non-explorative design. In deciding to follow that trail, we analyzed the data by field-coding common threads and findings, ultimately resulting in this article.

3.3. Methodological surprises in the form of AGVs
Although not an initial part of the larger project's research design, AGV hospital robots kept on being an active part of what the people in the hospital cared about and talked about during the empirical data collection concerning hospital architecture. As our paper will show, the people interviewed talked about the robots in different ways, and they had different meanings attached to them: e.g., an easy state of mind or the feeling of looking at animals at a zoo. We also saw children in the hospital-school “hunting” for different robots as a playful game and irritated nurses and doctors who had to wait for the robots to finish using elevators. These different meanings and experiences, especially the positive encounters, were quite different than what we have previously experienced with robots at more industrial settings (Fyhn and Søraa, 2017; Søraa, 2019). We started to wonder why and decided to back-track, following these actors in the existing data material. As few questions were asked with the robots in mind when the study was designed, they entered the data material as a side-track, but their importance is showcased in their multiple mentions in our data material.

This can be exemplified with the following conversation with a father to his terminally ill child—where the family lived at the hospital for a long time. The father explained how he went walking in the hallways of the hospital after receiving the message of his child's illness. He explained that while taking breaks, walking in the hallways to calm down, he met a robot that had got stuck between some trolleys, which fascinated him. The robot moved back and forth, repeating: “I am a hospital robot! You need to move.” This encounter, the father explained, was one of the very few positive factors in his very hard days as a visitor at the hospital. The robots were often mentioned in snippets similar to this in the empirical data.

In our analysis of the material, we focused on the encounters humans in the hospital had with the AGVs and what it symbolized for them. As the primary data did not include the AGVs as a focal point, this provided a methodological challenge, but by revisiting the data and seeing a surprising amount of robot related discussions, it was evident that these AGVs had an impact larger than their intended function on several actors who frequented hospitals. By providing a sociotechnical human-technology appropriation process though the STS lens of domestication theory as described in the previous subsection, we investigated how humans can domesticate robots in new—and in this instance, unintended—ways.

4. Domesticating robots in a hospital setting
Implementing robotic systems in existing societal structures such as hospitals presents potential challenges, but also good opportunities. The primary goal is to have an effective implementation process resulting in the robot being widely accepted and useful. For this to be successful, technology should not be overly complicated, as Piras and Zanutto (2016) discuss. Simple functions are often better than technology overload. As described previously, (Bartneck et al., 2009) recommends five key criteria for assessing social robots: anthropomorphism, animacy, likeability, perceived intelligence and perceived safety. However, these criteria are not necessarily transferable to industrialized service robots. In the following analysis we will look closely at the robots through the theoretical lens of domestication theory, focusing on the three dimensions of domestication of the dimensional model: practical, symbolic and cognitive.

4.1. Practical domestication of the robots
Robots need to be embedded into existing infrastructure, and the infrastructure needs to be adapted to the robots. One example on this is how garbage and waste are handled at the hospital. When full, waste bins are emptied into containers that are then sealed. These are then given one of the pick-up ID-chips, which allows an AVG to come and collect it. From this point no human touch is required, as the AGV will transport the waste-goods to an automated vacuum collection point, which sucks the garbage away to a local burning facility connected to the district heating system. The reduction of human contact with garbage and waste has the potential to reduce infection.

However, sharing space with robots is not without conflict. The AGVs often need to move between floors and are thus equipped with elevator access and even override capabilities. One example of such conflict can be found in the pediatric care department of the hospital where nurses care for children who have completed surgery. When the children enter the department, they are rolled in their beds through a number of locations: reception; preparation for surgery on bedpost; operation; recovery; and bedtime. Nurses bring the child to recovery and roll them up on the bedside. Sometimes it is urgent to have the child enter the room on the bedpost to continue treatment. This is not necessarily understood by AGVs standing in the way. The AGVs have priority access to the elevator that is large enough to accommodate a bed, and there is only one emergency elevator reserved for 113 patients. A nurse told us:

We are bothered a lot with the robots. Once I was told by a robot that I had to leave the elevator because the robot was using it. It overrides the elevator, and I was let out into the basement of the hospital with a patient from recovery and had to get out of there. So, we stood there, and had to wait until the robot had finished.

The nurses desired the ability to override the AGVs’ use of the elevators, taking back control from the robots. This is currently not an option, as robots can reserve the elevators in advance. The nurses, however, cannot reserve elevators, and are thus left waiting for the cumbersome robots to slowly squeeze themselves into the elevator and “steal it.” The battle between humans and machines is in this case judged by the elevator—in itself a machine—which has been granted authority by human programmers and the hospital leadership. However, the elevator is made biased by the AGVs’ overriding ability.

Although the robots are primarily tasked with transporting goods, the way humans relate to them can also be very creative. One example of such creativity was observed through a game called “robot hunting” played by pediatric patients at the hospital school. This school has few pupils, and lessons ranging from just 15 minutes, at the rooms of the sickest children, to multiple hour lessons in a special school environment in the hospital. One of the nurses who has half of their position paid by the Norwegian Cancer Society as an “activity-nurse” told us how they integrate the AGVs into the activities for the older children using a game they have called “robot hunting” (Robotjakt). Robot hunting is played by the sick children who are able to play. The children have their own list of robots, as seen below in Figure 4:

Fig 4
Download : Download high-res image (354KB)
Download : Download full-size image
Fig. 4. A sheet from the "robot hunting" game.

The columns from left to right contain: the number of the robot; if it has been found; and the robot's “gender," where M is male, and D is female. The children hunt these robots as passengers in a rickshaw-like bicycle, pedaled by the activity nurse or a teacher. The hunt takes place in the basement network of hallways which connects the different hospital buildings underground. School subjects, such as mathematics and Norwegian, are integrated into these activities, and the children make posters of their activities as part of the classes. The robots provide a positive experience, as two children interviewed explained while returning to the school after a hunt:

We drive around [in a bicycle-wagon] looking for them. They follow the yellow lines on the floor, so we find them. When we see one, we tell [the nurse] to hurry up and bicycle toward it... We found almost all of them! Some of them are really rude!

Through the robot hunting, children can escape the confines and boredom that being sick and hospitalized often entails. They can, for a moment, focus on something completely different, adding value to the time spent at the hospital. Hunting also empowers children, making them part of a quest of sorts—a stark contrast to more monotonous hospital life. The game and their exploration of the hospital is, because of the bicycling, framed as a quite active and fast activity. This exploration familiarizes the children with the hospital environment in a playful way, making it less scary and hostile. And, since the hospital staff is involved, the safety of the children is ensured. Although robot hunting from rickshaws was probably not an intended usage by the robots’ developers, it demonstrates how robots can be implemented in novel ways.

Robots that speak are instantly more interesting to humans than those that do not. When bought by St. Olav's, the AGVs initially spoke English. Although Norwegians’ English literacy rate is quite high, making the robots use Norwegian language was key for successful implementation. Somewhere along the process it was decided that these robots would be implemented with the local dialect in Trondheim, the “Trøndersk” Mid-Norway dialect from Trøndelag county. The area has a strong geopolitical identity, e.g., by having hosted the capital of Norway from ca. 997–1217. Identification with the dialect is quite strong in the area, and it is distinctive enough that most Norwegians can pinpoint it immediately. The dialect is generally perceived as quite slow, cozy and to the point, and it does not signify a particularly high socio-economic status. Norway's decentralization policy actively celebrates dialects as an aspect of cultural heritage that should be encouraged, leading most Norwegians to speak their hometown dialect at home, in school, on live TV or even if talking to the king. However, when Norwegian children are playing with dolls, they often switch between standardized Book-Norwegian (Bokmål or book-language, one out of two official written languages in Norway) and their dialect, e.g., representing the doll's voice and a storyteller-voice.

As explained in the previous section, the AGVs can override and reserve the hospital elevators (even to the point of refusing to leave the elevator when sick patient needs to take it), giving them a special relationship with the elevators. The elevators, however, speak with a Southern Norwegian dialect, which is completely different from the Mid-Norway dialect. This is because the elevator manufacturer is headquartered in the south of Norway where the woman reading all their elevator voices is employed, (although there are some additional elevator voices, the southern female voice is the most common one). Reprogramming the elevators to match the robot voices was not seen as cost-effective, resulting in this myriad of dialects being heard from the different digital systems at the hospital.

An opposite example can be the robotic “flawless but uncanny voice,” e.g., that which is heard at Gardermoen airport in Norway or the local bus company's announcement of stops in Trondheim. These voices use all the appropriate courtesy phrases, but they can be experienced as being in full control and not necessarily kind. Furthermore, when implemented in a different localized context the voice can seem uncanny, as it misreads the local bus-stop names by pronouncing them not as the locals say them, but as one would say them if one had no localized knowledge of how they are pronounced. The AGVs at St Olav's hospital, on the other hand, speak in the broad Mid-Norway dialect, but they are not polite. On the contrary, they are rather humorously rude. When telling people to please move away from the corridor where the robot is driving, the AGV will shout: (Norwegian: “Fløtt dæ, æ ska fræm, æ e en sykehusrobot!”), which in English can be translated as:

Move away, I am going forward, I am a hospital robot!

This statement does not feel scary or rude but can rather be described as exciting and humorous. The dialect, the choice of words and the lack of courtesy phrases makes the robot more easily domesticated, as it follows domestic local life more closely than a standardized and often more "official" voice and dialect would imply. Of course, the dimension of practical domestication needs to be working, i.e., the robots need to provide the service they were deployed to do—moving goods such as food, waste and linens around in the hospital. They must prove useful through this practical, physical work. For this purpose, they have been domesticated like herd animals were hundreds of years ago: for the transportation of our human goods. These robots can therefore be quite easily compared to animals like donkeys (which, unlike horses, are also perceived as stubborn and a bit faulty/dorky/suboptimal!). This relates to Harrison and colleagues’ (2007) description of how sociotechnical interaction of HITs changes existing social systems—here by providing something surprising as well as a practical value of doing what they are tasked to do.

Key takeaway from the practical domestication of the robot: The robots need to be embedded into existing infrastructure and the infrastructure needs to be adapted to the robots, but this is not a straightforward process. The AGVs at the hospital were given certain traits of antromorphization such as voice and humorous maneuvers (although somewhat unintended). The robots also did their job in terms of carrying the goods they were set to, but also gained additional importance as part of games for hospitalized children to “hunt.” This embeddedness in the sociotechnical system of the hospital was not without conflict, as the robot was in some cases given too much agency and control, e.g., in the case of overriding elevators and blocking it for sick patients.

4.2. Symbolic domestication of the robots
The AGVs in St. Olav's hospital were originally created to be quite industrial-looking and designed primarily for undertaking a specific task: moving goods. Consequently, one might suspect that human involvement and interest would be minimal. However, hospitals are a place of care, safety and healing. Robots thus have the potential to enhance or detract from this quality instead of making hospitals appear like industrial factories. For many patients, hospitals occupy an intimate and vulnerable space, which can make robot implementation challenging.

What do these robots symbolically represent for people interacting with them? The robots create joy when they make mistakes, such as getting stuck with their jaws on racks, walls or other robots. We observed robots in a long queue in the basement, where there was a bit of chaos. The robots ripped and swung, yelled, and tried again. In line, like a flock of belt animals trying to get through the garden, the robots represented a clumsiness in the technology, which our informants perceived as charming. These symbolic values that are laid on the robots—clumsiness, predictability and the rude tone—make them appear harmless. It may be that clumsiness and their working out of the problems make them especially "acceptable.”

The impression that the robots are some kind of domestic animal just doing their thing make them more approachable than a robot waiting for your command while looking at you and “expecting” an answer. There is less of a feeling that the robot is in control when you choose to interact with it on its way to something else, and, in that manner, it can feel safer. These robots certainly do not have any plans for you programmed into themselves.

These unintended comic features of the robots can also be recognized in an interview with the father of one of the patients, which we briefly introduced earlier. Because of his child's severe long-term illness, he had to spend significant amounts of time at the hospital. This father mentioned that the robots were a positive distraction in his very stressful days; they quite unexpectedly helped him deal with a great sorrow. The father explained how he, after receiving the message about the child's disease, walked into the hallway and took a break to clear his head:

As I was standing there, I looked in fascination at a robot for a long time. It drove back and forth in the area in front of an elevator where it had got stuck. It yelled at the trolleys that had been put in the wrong place, blocking it, insisting that the immobile trolley had to move, “because I am in fact, a hospital robot!”

This is an example of a symbolic domestication process where something unintended happens. Technology is often used differently than how the producers and developers intend, and users can, through novel forms of interaction, prescribe new meanings into technology. The experience at St. Olav's Hospital shows that it is not a robot's perfection that makes for a safe and positive domestication, but rather its imperfection.

The AGVs work primarily in a supportive role, not a transformative role, thus representing an easier domestication. Consider Tang and Carpendale's (2008) study of the introduction of an information system for monitoring waiting time targets for patients in the emergency department, where whiteboards where abolished but paper was eventually kept as an “old technology” due to it being crucial for the daily work of healthcare workers. In their study, going paperless was considered too transformative, making the reshaping of that particular sociotechnical network too difficult without good alternatives to paper. For the AGVs in our study, they symbolize less of a change than the removal of paper would. Using Ljungbald and colleagues’ (2012) framework in their study of robots seen through the eyes of hospital staff as either alien, machine, worker or work partner, AGVs can, in this case, be quite well described as robots that, in attempting to be a worker or work partner by actively taking over human worker tasks of moving things, was actually seen more as a machine—but a silly and simplistic machine—thus not reaching a level of alien “scariness.” It was clear to everyone who met an AGV that this was in fact a robot—as the AGV itself proclaimed with its catchphrase “move, I am a hospital robot.”

If we look at the symbolic domestication of the AGVs in relation to Mutlu and Frolizzi's (2008) four categories, we can see that yes, (1) interruptions by the robot are perceived as worsening the workflow of healthcare staff, e.g., when the robots took control over the elevators and that (2) there could also be a misalignment between the goals of the unit and the benefits provided by the robot. However, this misalignment—the robot being quite “silly” in the terms of the people encountering it—made it more approachable and liked, instead of leading people to reject the robot. Mutlu and Frolizzi's third claim (3), the intimate relationships between caretakers and patients could cause a lower tolerance for interruptions, was also observed to be reversed in some cases, as was seen with the father of the sick child who, in an attempt to clear his head, enjoyed distracting himself by watching the AGV and a trolley “battle for a hallway.” Yet again, this is unintended design, but relates to (4). In high traffic and/or cluttered hallways, the robot is perceived as taking precedence over people—in most cases this is true; human actors at the hospital did not like being blocked by the AGVs when they had places to go to.

Key takeaway from the symbolic domestication of the robot: When humans encounter robots, we need to place them within our ontological frames of the world. For the people interacting with robots, the robots were thus ontologically coded to be seen as something akin to pack animals, something “harmless and a bit stupid”—symbolically they represented something not really understanding the world it was placed in. This “silliness” was symbolically seen as positive in an otherwise quite strict setting of the hospital.

4.3. Cognitive domestication of the robots
How do people change their practices when having to interact or be in the same room with a robot? There is a cognitive domestication occurring on account of the robots being interactive. You can put your foot in front of it, and it will tell you to move in a rude manner. Because it projects a fun personality, learning what not to do becomes less of a hassle than it would be with a typical “voice of God” scenario where almighty technology teaches humans what to do. As co-inhabitants of the hospital, robots must interact with humans, but humans also learn when interacting with robots how to interact with technology. Using voice as a key “human factor” in unanthropomorphized robots, if done well, is of great value by making them more approachable. A non-standardized voice can be an effective tool to give the robot a sense of personality. Creating robots that can work and be invited to interact in people's intimate sphere should perhaps focus on creating a robot that is not too perfect in such a sense that you lose control and get anxious about it. In order to create enthusiasm, it may be necessary to give some likeability. By making the robot sound like a “mechanic at work” rather than a “posh Victorian lady at court”—being aware of the potential for the reproduction of stereotypes—the robot can become more appreciated. It appears that the physical appearance of the robot is not necessarily reacted to in a negative manner by the humans having to interact with it.

However, the robots’ local dialect can pose a challenge to immigrant populations because they often lack experience with, or culturally dependent associations with, the variety of Norwegian dialects. Even so, the robots appeal to people, including immigrants, and this lack of fear does not exclude people from approaching the machines. We argue that the low threshold, made possible by its silliness, could become part of an inclusion process for those that are not familiar with robot technology in their environment. Although the robots are unanthropomorphized, our study demonstrates a strong agency of these machines, which is particularly tied to their usage of the local Norwegian dialect giving them a sense of “personality.”

We found that the unanthropomorphization of robots present novel ways to achieve acceptance from the public. When people get to know the non-perfect robot in itself, not masked as a person or animal, there is interest and trust in the machine. It may also be that the robots are important in the sense that they have not been “made up” or shaped as something other than what they are. They are not belt animals. They are robots. When robots look like something else, their inherent qualities become less accessible, and, in some ways, they wander dangerously close to the uncanny valley. St. Olav's robots are not hidden behind a mask that makes them appear as something other than what they are. They are understandable as robots, and are, in that, sense honest. People in the hospital are drawn to the robots in different ways, and patients and visitors have given the robots the ability to give them comfort through hard times in their lives.

As Bossen and Jensen (2008, p. 464) discuss, implementing ICT systems in hospitals is concerned with “creating a fit, i.e., adapting technology and work processes to each other, attributing appropriate meaning to new clues for interpretation and action.” This has similar connotations to Harrison and colleagues’ (2007) last steps on how social systems mediate use, in turn changing the social systems as humans undergo cognitive processes when dealing with HITs which leads to changes in the properties of the technologies—i.e., the domestication of the technology cognitively changes the life at the hospital.

Cognitive domestication of technology implies learning with and through the technology in question, finding new ways of using it, which both changes the technology and the user in the domestication process. But what does it mean for human users to interact with AGVs? Parekh and Lim (2020) urge us to focus on the importance of social cues for increasing human's receptivity for robot interaction. With the AGVs in question, voice (in certain dialects) made people stop and wonder what this was, and how they should relate to it. The interesting aspect in this cognitive process is not how humans were intended to relate with the AGVs, where the robots would just move about their day and the humans in the hospital would not interact with them. Instead, the interesting aspect involves the unintended interactions: children being tasked to go on “robot hunts” or using the robots as a means to hide-and-seek games. This, what Su and colleagues (2014) term "mundanely miraculous,” shows an important cognitive process of domesticating robots—unintended ways of learning to use robots as part of sociotechnical infrastructure.

Key takeaway from cognitive domestication of the robot: In this part we have seen how AGVs are embedded into sociotechnical practices. Different than symbolic domestication (what users think about technology), cognitive domestication thus allows us to see how humans learn and actually change their thinking and practices in relation to said technology. We have seen how unintended domestications of the robots allow for hospital staff and visitors to think creatively about what using robots as part of their lives at the hospital can entail—thus changing the hospital into something different than what it was before. The AGVs are thus highly technologically advanced and cause humans to change their practices, e.g., by not picking up as many things and transporting it around, as it is now the job of the robots. But through their “silly behavior,” the robots added something novel to the mix. This we will explore in the discussion through a novel suggested fourth dimension of domestication—the social dimension.

5. Discussion and analysis: Social domestication of robots
The three dimensions of domestication of technology (practical, symbolic, cognitive) have shown how the AGVs underwent multiple levels of often unintended domestications. In this discussion, we turn our analytical gaze particularly on these unintended domestications through a focus on the social component of them. As stated in the introduction, an industrial service robot like an AGV is designed with the purpose of efficiently performing certain mundane tasks, like moving goods. These are tasks that humans do not find particularly interesting and do not mind leaving to robots. On paper, the robots could be left almost entirely alone, with little to no human interaction. However, as we will argue through this discussion relating back to key previous literature (specifically Bartneck et al., 2009; Harrison et al., 2007; Mutlu and Frolizzi, 2008; Su et al., 2014)—unintended social interaction is key in this domestication process.

Firstly, revisiting Harrison and colleagues’ (2007) five types of sociotechnical interaction of HITs, how should the AGVs be categorized? We can see (1) how they change existing social systems, by being active actors in the hospital setting and physically taking up space, (2) how technical and physical infrastructures mediate their use, e.g., through the AGVs interaction and control over the elevator-systems, (3) how social systems mediate use, e.g., how the AGVs were included in the children's hide-and-seek games, thus (4) changing the social systems and (5) how this interaction leads to changes in HITs. The AGVs are also robot-ambassadors of future robotic implementation, but they are not seen as threatening conquerors of a competing “robot species,” but rather as goofy things of different cultures who can't really make out the cultural practices of the human-centric hospital, e.g., of how to (politely) ride in elevators. There is thus a social dimension to the domestication that happens unintendedly, but nevertheless, the sociotechnical interactions are still happening, and meaning must be given by humans into what these robots are doing at the hospital and how the humans should relate to them, see also Søraa et al., (2021).

Bartneck and colleagues (2009) recommend five key criteria for assessing social robots, and, as stated in the introduction, these might not apply well to service robots. For (1) anthropomorphism, we saw that there was rather a zoomorphization, as humans tended to view the AGVs more as pack-animals in herds. For (2) animacy, a certain sentient quality was reported, and although no informant saw the robot as a fully sentient, alive creature, the individual robots were given names, personalities, genders and voices. Thus, (3) we will argue that the likeability of the robot increased—as they went from being a “something” to a “someone” in certain cases, especially when they did something that the informants regarded as “silly.” For social robots, (4) perceived intelligence is seen as important, but for the AGVs the perceived un-intelligence was more important. Of course, they needed the finesse to do their tasks of picking up things and delivering them—their reason d-etre to begin with—but the steps between, where the social-interactions happened, benefitted from a perceived un-intelligent behavior. For (5) perceived safety, however, it is crucial that robots do not override elevators when sick patients need to use them. So, matched up with Bartneck and colleagues’ (2009) dimensions, we can see that the AGVs do not need to meet all criteria of their social robot cousins but that, in some cases, unintended social actions can be effective when robots are not meant to be social.

This unintended social encounter can be seen through Su and colleagues’ (2014) concept of the "mundanely miraculous” robots in healthcare. It is the mundane quality of the AGVs that make people enjoy their (social) company—and the robot becomes a topic of conversation. The hospital material situated in strictness, control, tests, improvement, health fixing, and order were thus given a social spice it did not know it needed. The AGVs brought something unintended in their social interactions. We would thus argue that, in addition to practical, symbolic and cognitive domestication, it is also beneficial to investigate the social domestication of technology. The AGVs become part of a wide array of actors: nurses, doctors, technicians, patients, caregivers, teachers along with a whole system of non-human actors like garbage disposals, pick-up calendars, drugs, tests, pills, corridors and elevators to mention some. This is something the AGVs have to relate to for working in the hospital.

Social domestication of technology shows how a technology is part of an intricate network of actors relating to it in different ways that, together, co-shape the domestication of the technology. With hospital robots like AGVs, there are institutional, informal and formal relations working together. For the institutional formal relations, hospital workers need to be assured that the AGVs will do their job and pick up and deliver things. They must also socially-relate to the AGVs when they misbehave, e.g., by blocking elevators—as we've seen, negative aspects can also be part of domestication as it is negotiating between beneficial and unbeneficial aspects of domesticating the technology. For the informal social domestication, in the case of the AGVs, we have seen how the unintended plays a crucial role. When robots do not do what we think or believe they should do, humans can be surprised, but here on a positive note. When a robot suddenly speaks to you in a local dialect, that represents a positive new social connection to the robot.

Let us return to Auger, (2014, p. 20) who begins his discussion of adaptation and domestication by asking “Why are robots not becoming domestic products?” He argues that the majority of proposed domestic robots were essentially maladapted to everyday life. Here we would argue that, for industrial service robots like the AGVs, social interaction is the spice that makes domestication possible. Perhaps it is partly due to the fact that the robots are not in the home, they are not too invasive, and one can choose to interact with them in goofy, zoomorphic ways rather than trying to anthropomorphize them, that they work well.

5.1. Key learnings and actionable steps
Reflecting on our study, we provide the following key learnings presented as a list of actionable steps on how to think about introducing non-social robots to social settings (taken to mean any environment where humans might wander):

1)
What social cues are built into the robot? What is their function, and for who are they intended?

2)
What voice is chosen for the robot? Who relates well and less well with this voice? Does the language or dialect make a difference to different user-groups?

3)
What extra activities could be built around the introduction of the robot? Are there disadvantaged groups that could have a positive experience interacting with it in novel ways?

4)
How do people who encounter the robot change their behaviors both towards the robot and towards other parts of the environment where the robot exists?

5)
Are there groups who become unintended users of the robots, and should they be part of the design process? Are the thoughts of non-users who have negative experiences or feelings towards the robots taken into account?

6. Summary
This paper has explored how the domestication of robots in a hospital setting can take a wide variety of forms through a case study on how Automated Guided Vehicles (AGVs) have been domesticated at a Norwegian hospital. It shows how the robots are domesticated both practically, symbolically and cognitively. This domestication is taking part among a wide actor network of hospital entities—both human and non-human. The robots, primarily tasked to move different goods around in the hospital in an autonomous manner, are shown to provide novel domestication possibilities for Human Robot Interaction, e.g., through the way dialect has been successfully implemented in the robots’ design, thereby creating a sense of autonomy and familiarity or “accessibility” for the humans who interact with the AGVs. The robots were used for a wide variety of purposes, e.g., a “find the robot” game played by hospitalized pediatric patients. The AGVs are taking part in an intricate domestication process at the hospital as non-human actors relating to the human actors that also frequent the hospital corridors. Some encounters were voluntary—such as “spotting and finding” games involving the robots in the hospital school—while other encounters are involuntary—as when humans are required by the robots to vacate an elevator—showing an intricate implementation of robots as part of a larger network of healthcare digitalization in this hospital case study. This we have thematized as Social domestication of technology, which shows how a technology is part of an intricate network of actors relating to it in different ways that, together, co-shape the domestication of the technology.