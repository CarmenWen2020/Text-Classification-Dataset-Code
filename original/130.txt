Consumer sleep-tracking devices provide an unobtrusive and affordable way to learn about personal sleep habits. Recent
research focused primarily on the information provided by such devices, i.e., whether the information is accurate and
meaningful to people. However, little is known about how people judge the credibility of such information, and how the
functionality and the design may influence such judgements. Hence, the aim of this research was to examine how consumers
assess the credibility of sleep-tracking devices. We conducted a qualitative study with 22 participants who tracked their sleep
for 3 nights with three different devices: Fitbit Charge 2, Neuroon EEG, and SleepScope, a medical sleep monitor. Based
on semi-structured interviews, we found that people assess the credibility of sleep-tracking devices based not only on the
credibility of sleep data per se, but also on device functionality, interface design and physical appearance. People found it
difficult to judge credibility, because of the complexities of sleep stages and micro-arousals (sleep fallacy) and the black boxed
nature of devices (black box fallacy), and also because of the misalignment between objective sleep measures and subjective
sleep quality. We discuss the significance of design and functionality on the credibility of personal health technologies and
highlight design challenges and opportunities to enhance their credibility.
CCS Concepts: ‚Ä¢ Human-centered computing ‚Üí Empirical studies in HCI.
Additional Key Words and Phrases: Sleep-tracking, Credibility, Wearable sensors, Consumer devices, Personal
informatics, Quantified self
1 INTRODUCTION
Consumer sleep-tracking devices provide an affordable and unobtrusive way for individual users to gain insights
into their sleep patterns. Devices like Fitbit and Neuroon provide users with information about the sleep duration,
awakenings during a night, and sleep stages (light sleep, deep sleep, and REM sleep). This information is produced
based on data from various sensors: devices worn on the wrist (like Fitbit) often contain accelerometers and optical
heart rate sensors, whereas devices worn as a sleep mask (like Neuroon) also contain electroencephalography to
record electrical activity of the brain. In principle, electroencephalography can provide more accurate insight into
sleep stages, but the downside is that sensors worn on the head can be more obtrusive than wrist-worn sensors
and hence interfere with sleep [77]. In other words, in choosing a consumer sleep-tracking device, users are faced
with a trade-off between data quality and other factors like physical appearance and price. To complicate matters
further, the accuracy of even the most advanced consumer sleep-tracking device is limited compared to medical
devices [21, 55]. Medical sleep-tracking typically involves data from multiple sensors (accelerometers, heart rate,
EEG, breathing) as well as personalized interpretations from sleep experts that take into account age, gender,
health conditions and lifestyle [41, 81].
There is broad range of research on the information provided by sleep-tracking technologies, but these studies
appear to fall into two separate areas. On the one hand, numerous studies have examined the accuracy of
consumer devices compared to medical devices through controlled experiments [21, 48, 55, 57]. Such studies
indicate that consumer devices tend to overestimate sleep and underestimate wake, and measurement accuracy
can be associated to a person‚Äôs age, subjective sleep quality and sleep patterns [54, 56]. However, these studies
are based on assessments made by researchers, rather than assessments made by device users. On the other hand,
studies in HCI have shown how people make sense of information about their own sleep and the challenges they
face in collecting, interpreting, and acting upon such personal health information. For example, simple usability
issues like battery limits and lack of comfort as well as irregular sleep patterns make it difficult to collect useful
information [61]. Lack of contextual information and limited knowledge about sleep and sleep stages can make
it difficult to interpret sleep information and to take actions from it [61, 77]. However, these HCI studies are
not concerned with the accuracy of sleep information, or the credibility that people place in such information.
Furthermore, these studies do not provide people with opportunities to compare consumer devices with medical
devices.
To address this gap, this research examines how people judge the credibility of consumer sleep tracking devices
in comparison with a medical device. Credibility is defined as believability, i.e., whether a person perceives a
technology as trustworthy (truthful and free from bias) and as based on expertise (knowledge and competency)
[27]. Credibility is of utmost importance for ubiquitous computing devices that report health and well-being data
and offer recommendations to users [86], as users rely on these devices to assess their health and well-being
and to explore opportunities to improve their health. A lack of credibility in such devices is likely to undermine
the sustained usage and the potential benefit of these devices [16, 29, 50]. Users may even stop using a device
if it is perceived non-credible [86]. Despite of the importance of credibility of sleep-tracking technologies, and
self-tracking devices more broadly, there appears to be a lack of research into the perceptions of device users.
In our study, we invited twenty-two people to track their sleep for 3 nights concurrently using three devices:
two consumer devices (Fitbit Charge 2 wristband and Neuroon wearable EEG eye mask) and one medical device
(SleepScope, a portable medical EEG). All three devices generated similar types of information, like total sleep
time (TST), number of awakenings (NAWK), and sleep stages. However, participants were faced with differences
in the actual measurements provided by the different devices, which prompted them to make judgements about
which device to believe in. Based on semi-structured interviews, we examined how people assessed the credibility
of these three devices. Guided by Fogg and Tseng‚Äôs framework of credibility [27], we sought to unpack how
these judgements were influenced by different technology levels (device hardware, interface, functionality, and
information), as well as whether these judgements were based on personal experience or surface level judgements.
The main contribution of this study is the empirical understanding of how people assess the credibility of
sleep-tracking devices. The contribution builds on well-established HCI theories on credibility [27, 86]. Our
findings show that people assess the credibility of a sleep-tracking device at different technology levels: from the
quality of sleep data, to the mechanism, the dashboard design and even the physical appearance of the device.
Assessments were affected by the participants‚Äô mental models of sleep-tracking, their difficulties in understanding
sleep stages (sleep fallacy), and the black boxed nature of sleep tracking devices (black box fallacy). Based on
these findings, we provide practical guidance for the design of credible sleep-tracking technologies.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:3
2 RELATED WORK
2.1 Fundamentals of Human Sleep
Human sleep can be measured either subjectively or objectively along multiple dimensions [10]. Subjective
sleep quality is characterized by individual‚Äôs perception and satisfaction of sleep and is often measured using
sleep diaries [13] or established questionnaires such as the Pittsburgh Sleep Quality Index (PSQI) [11] and Sleep
disorder questionnaire (SDQ) [22]. These tools involve answering multiple questions daily or once every month.
Human sleep can also be measured objectively in terms of timing, duration and ratio. Objective sleep quality
is often characterized by a set of overall sleep metrics including total sleep time (TST), wake after sleep onset
(WASO), sleep onset latency (SOL) and sleep efficiency (SE), and the structural organization of sleep such as sleep
cycles. A sleep cycle typically consists of four sleep stages: light sleep, deep sleep, REM sleep and wake. Light
sleep and deep sleep, also called non-REM sleep, are defined by the imprints on the EEG of highly rhythmic
and/or large amplitude graphoelements [43]. Light sleep stage is where the sleep spindles and K-complexes
emerge [30], which play important roles in consolidating brain functions related to learning, memory and in
child development [2, 37, 88]. In addition, sleep spindle density has been associated with IQ [26]. Deep sleep is
important for physical recovery [3], cognition [92], and for balancing sympathetic and parasympathetic nervous
systems [52]. As for the role of REM sleep, it was not until recently that scientists uncovered the functional role
of REM sleep in brain maturation [65] and emotion regulation [31]. Another important concept related to sleep
is arousals, or awakenings. Whereas sleep arousals were previously considered as marker of sleep disruption
and detrimental for sleep quality, recent studies have corrected this view and instead consider sleep arousals as
an essential part of human sleep that occur spontaneously. The functional significance of arousals in sleep is
to ensure the reversibility of sleep, otherwise sleep would be identical to coma [33]. Sleep arousals are further
classified into cortical, subcortical and autonomic arousal [33]. It is worth noting that some arousals could be
pathologic, such as the ones associated with sleep apnea and bruxism [33].
Regardless of measuring the same phenomenon, subjective sleep quality and objective sleep quality are only
moderately correlated [40, 90]. The discrepancy between the two is often referred to as ‚Äúsleep state misperception‚Äù
[36]. Such misperception commonly exists among healthy adults [40] but could be more pronounced in pregnant
women [76] and in clinical populations with Alzheimer disease, depression and sleep problems [38, 44, 62, 71, 87].
As we will show later in the findings, the discrepancy between objective measurements and subjective sleep
experience adds an extra layer of complexity for participants to assess the credibility of sleep data. Participants
had to reconcile such discrepancy to achieve a plausible view of their sleep.
2.2 Sleep Tracking and Monitoring Technologies
Measuring sleep structure has been the central task of all sleep tracking and monitoring technologies. Unlike
other physiological signs such as heart rate and blood pressure, sleep structure cannot be directly measured
but rather can only be inferred from other bio-signals. Human sleep is a complicated process accompanied by
multiple streams of physiological changes in brain activities [85], limb movements [39], heart rate [89], body
temperature [67], to name but a few.
In clinical settings, polysomnography (PSG) is the gold standard for measuring sleep structure and is mainly
used for diagnosing breathing-related sleep disorders [4]. A PSG test involves concurrent monitoring on many
physiological metrics including brainwave, oxygen level in blood, heart rate, breathing, and eye and leg movement.
All these bio-signals are used to infer sleep stages. Sleep researchers have established a standard for sleep scoring
[41]. They first divide the raw signals into 30s-epoch, and then assign a sleep stage epoch-by-epoch by visual
evaluation. Nevertheless, sleep scoring involves many subjective judgements and therefore the average inter-rater
agreement is only around 80% [81]. Wrist actigraphy is a less obtrusive alternative to PSG in clinical settings. It
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:4 ‚Ä¢ Liang and Ploderer
can be used for longitudinal monitoring of sleep in free-living conditions and is mainly used for diagnosing sleep
disorders related to circadian cycle [66, 73].
In recent years, consumer sleep-tracking technologies are becoming increasingly popular among individual
users and researchers because they are unobtrusive, affordable and easy to use [48, 82]. These tools are designed
in a way that people can use at home without the need for constant technical support. Like clinical sleep
monitors, consumer sleep-tracking technologies broadly fall into two genres: EEG-based and actigraphy-based
devices. EEG-based devices include Zeo Personal Sleep Coach, Neuroon eye mask, and SleepShepherd headband.
These devices use embedded single or multi-channel EEG to measure users‚Äô brainwaves during sleep, which
is then mapped to sleep stages. The genre of actigraphy-based devices includes popular activity trackers like
Fitbit, smartwatches like Apple Watch, as well as smartphone applications like SleepBot and SleepAsAndroid.
These devices or applications rely on embedded accelerometer to measures users‚Äô limb movement, and some
wearable wristbands measure heart rate. These data are used to infer users‚Äô sleep structure and sleep quality
using proprietary algorithms. Whereas older apps and devices mostly produced aggregated results on sleep such
as total sleep time, total wake time, and sleep efficiency, newer apps and devices also provide information on
sleep stages.
Human-computer interaction researchers have intensively studied how users interact with sleep-tracking
technologies. Previous studies have qualitatively examined how users make sense of sleep data from single
source [47, 60], the impact of consumer sleep-tracking devices on sleep hygiene [77], and the opportunities
for sleep-tracking tools to enhance sleep hygiene [14]. There is strong evidence that sleep-tracking increases
people‚Äôs awareness of sleep health and support healthy sleep behaviors [61]. However, the long-term impact of
sleep-tracking on sleep quality remains limited [58]. Some of the main obstacles include technology transparency,
not tracking triggers, not giving actionable knowledge and not providing personalized recommendations [61].
Consequently, new sleep-tracking and analysis tools were developed to lower tracking effort [15], to explore the
associations between sleep and external factors [47, 60], to support behavior changes for better sleep [5] and to
support self-experimentation [17, 84].
The accuracy of consumer sleep-tracking devices has been a major concern for individual users and for
researchers [5, 58, 59, 61, 77]. Many studies have examined the validity and reliability of these devices in
laboratories [18, 19, 21, 63, 70] and in participants‚Äô own living environment [55]. Validation studies on previous
wearable wristbands such as Fitbit Charge HR [19] and Jawbone UP [46] revealed that these devices generally
underestimated wake time while overestimated sleep time and sleep efficiency in healthy adults, and their
measurements of sleep stages had no correlation to medical devices [21, 48, 55, 57]. Whereas achieving better
accuracy has been the main goal of many sleep-tracking technologies, it remains unknown if better accuracy
increases perceived believability. This study set out to test this hypothesis.
2.3 Credibility in Human-Computer Interaction
Credibility has been well-studied in psychology for more than six decades [12] and has a relatively short history
in human-computer interaction. It is a perceived quality and is not a direct measure of actual quality. Previous
studies defined credibility as believability and outlined four different types of credibility: presumed credibility,
reputed credibility, surface credibility, and experienced credibility. Presumed credibility relates to a person‚Äôs
assumptions and stereotypes. Reputed credibility relates to what a person has heard from third parties like
friends or advertisements. Surface credibility relates to first impressions based on simple inspections, whereas
experienced credibility is based on trying out the technology [27, 32].
With respect to what users focus on when they assess the credibility of computer products, Fogg and Tseng‚Äôs
systems perspective highlighted four dimensions involved in credibility assessment: device, interface, functional
and information. Device credibility and interface credibility relate to the physical aspect of a device and its
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:5
user interface. Functional credibility relates to how a device achieves the functions it supposed to achieve,
and information credibility relates to the perceived believability of information itself. Many factors have been
shown to affect credibility assessment, such as user familiarity with the content, cognitive load, situational
context, and visual design [28]. There is a rich body of research on how users judge the credibility of online
information. Information credibility is defined as the extent to which one perceives the information to be
believable [86]. Existing studies have identified a variety of antecedents of e-Health information credibility,
including completeness of information [24], accuracy of information [6], visual appeal [79], and user traits such
as demographics, motivation and beliefs [23, 69].
Despite of the importance of credibility, no study has systematically examined the credibility of personal
information from sleep-tracking devices. As has been described in the previous section, studies on consumer
sleep-tracking technologies have been mostly focusing on usability [14, 58, 61, 77], accuracy (both quantitative
and qualitative) [21, 48, 55] and efficacy [16, 58]. Our study sets out to investigate the credibility of sleep-tracking
technologies systematically in all four aspects outlined in Fogg and Tseng‚Äôs systems perspective: device, interface,
functionality, and information.
3 METHOD
To investigate the credibility of sleep-tracking devices, we conducted a field study with 22 participants who
tracked their sleep for 3 nights concurrently using three devices (Fitbit, Neuroon, and a medical device), followed
by a semi-structured interview. By investigating how participants assess the credibility of these devices, this
study seeks to offer insights into the factors that affect judgements and to pave the way for creating more credible
digital health devices.
3.1 Participants
We recruited 22 participants (nine women, average age = 25 years) by distributing posters around the campus of
the University of Tokyo. We excluded applicants who had diagnosed chronic conditions (including cardiovascular diseases, hypertension, and diabetes) and who could not attend the briefing and interview in person. All
participants were students enrolled in the university. The ethics committee of the University of Tokyo approved
this study. All participants provided written informed consent. Participants received a ¬•6000 (equivalent to $58)
shopping card as an appreciation for their contribution to the study. No participant dropped out during the study.
Table 1 provides an overview of the demographic information of all participants. The ID numbers starting
with N indicate novice users of sleep-tracking devices and those starting with E indicate experienced users who
had used some type of tracking device before. The sleep problems listed in Table 1 were based on subjective
perception and were not based on diagnosis. Seven participants were having perceived poor sleep at the time of
this study as indicated by the PSQI (Pittsburgh Sleep Quality Index) [11]. Most of the problems were temporary
due to the humid weather in June and had gone at the time of the interviews. The table also includes participants‚Äô
conceptions of what these devices measure, which influenced their perceptions of credibility as described in the
findings section.
3.2 Sleep-tracking Devices
Participants in this study received three devices to track their sleep over 3 consecutive nights: a Fitbit Charge
2 [78], Neuroon [83], and a portable medical sleep monitor SleepScope [75]. Participants were asked to use
these devices in parallel and to compare the results from each device during an interview at the end of the
study. The rationale for providing multiple devices was based on a multiple source strategy reported in social
psychology, which purports that having access to different sources of information (and technology) about the
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:6 ‚Ä¢ Liang and Ploderer
Table 1. Demographic Information of Participants
ID Sex Age PSQI1 Perceived sleep problems
N12 F 22 6 Insomnia
N2 F 22 3 None
N3 M 23 11 Snore, insomnia
N4 M 30 6 Daytime sleepiness
E5 F 25 4 Snore
N6 M 26 3 None
N7 M 29 2 None
N8 M 21 7 None
E9 M 25 2 None
E10 F 28 4 Sleep paralysis, out of breath, snore
N11 M 21 7 None
N12 F 23 3 None
E13 F 23 1 None
N14 F 29 4 Temporary insomnia
E15 M 23 1 None
E16 M 24 2 Snore
E17 F 26 5 Sleep deficiency
E18 M 25 6 Temporary insomnia
E19 M 26 4 None
N20 F 32 3 None
E21 M 24 3 None
N22 M 33 4 None
1A PSQI (Pittsburgh Sleep Quality Index) [11] greater than or equal to 5 indicates poor sleep quality.
2
ID numbers starting with N indicate novice users; those starting with E indicate experienced users.
same phenomenon can increase participation engagement by allowing them to compare, contrast, and if necessary,
reconcile contradictory information [34].
Fitbit Charge 2, Neuroon, and the SleepScope medical device were chosen because while they offer largely the
same information about sleep, they differ in terms of other factors that may influence their credibility, i.e., in
the physical manifestation of the device, interface design and amount of information, mechanism to collect and
process data, and accuracy in information. At the time of the study, the Fitbit Charge 2 wristband and Neuroon
were amongst the most popular actigraphy-based and EEG-based consumer devices. As summarized in Table 2, the
Fitbit Charge 2 is worn on the wrist, presents information through a mobile app dashboard, and the information
is based on data measured by accelerometer and optical heart rate sensor. In comparison, Neuroon is worn on the
eyes, presents information through a mobile app dashboard (with different design), and the information is based
on data measured by EEG. The SleepScope medical device was provided as a reference point to compare the
information from the other 2 devices. We opted for a medical EEG device with interpretation from sleep experts
rather than a medical wrist-worn actigraphy device, because the latter is known to be inaccurate [64]. A further
consideration in choosing these devices was that they could be worn in parallel, as illustrated in Fig. 1. Other
wearable EEG products such as Emotive and SleepShepherd were not selected because they were uncomfortable
to wear during sleep and they could not be used concurrently with the medical device.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:7
Table 2. Comparison of three devices in the aspects of device, interface, sensor and information
Device Interface Sensor Information
Fitbit Charge 2 Wristband Mobile app Accelerometer, Total sleep time (TST)
dashboard pulse oximeter Wake after sleep onset (WASO)
Number of awakenings (NAWK)
Sleep efficiency (SE)
Ratio of 4 sleep stages
Population benchmark
Neuroon Eye mask Mobile app EEG (dry TST, WASO, NAWK, SE
dashboard electrodes), Ratio of 4 sleep stages
EOG,
accelerometer,
pulse oximeter
Sleep Scope Electrodes Printed report EEG TST, WASO, NAWK, SE
(medical device) attached to head; (gel-type Ratio of 5 sleep stages
a cable connects electrodes) REM onset latency
electrodes and Duration of each sleep cycle
device Delta power, alpha power, etc.
Fig. 1. Placement of devices (left: front view; right: side view).
3.3 Data Collection and Analysis
The study started with a briefing session with each participant to explain how to use the devices and to install the
necessary applications on their smartphones. Each participant received a Fitbit Charge 2 wristband, a Neuroon
wearable EEG eye mask, a portable medical sleep monitor SleepScope, and accessories (batteries, electrodes and
manuals). Participants were orally instructed to properly place the sensors. For example, Fitbit should be worn on
non-dominant wrist and be placed a finger‚Äôs width above wrist bone; the two electrodes of the medical devices
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:8 ‚Ä¢ Liang and Ploderer
should be put in the center of forehead and behind the lobe of an ear. While we did not give any information
to participants on how each device works, a few participants mentioned in their interviews afterwards that
they looked up information about the devices on their own. We also provided participants with the link to a
digital sleep diary to record their subjective sleep experience. The sleep diary consisted of nine questions adapted
from standard sleep diary [13], such as ‚Äúwhat time did you get into bed‚Äù, ‚Äúhow many times did you wake up‚Äù,
‚Äúwhat time did you get out of bed for the day‚Äù, and ‚Äúhow would you rate the quality of your sleep‚Äù. Participants
were instructed to fill in the diary every morning during data collection experiment. At the end of the briefing,
participants were asked to fill in PSQI (Pittsburgh Sleep Quality Index) questionnaire [11] to establish a baseline
of their sleep.
Participants then tracked their sleep using three devices concurrently for 3 nights in their homes. We analyzed
sleep data of the second night to avoid the first-night effect [68]. The data of the third night was used only when
Fitbit failed to generate sleep stage data on the second night. We retrieved Fitbit data through the Fitbit Web API.
Neuroon data was manually retrieved from the dashboard, as there was no public API available at the time of this
study. The medical data was sent to the company for analysis by sleep experts who downloaded the data from
the device and manually interpreted the data following established sleep scoring standard [41]. A full analysis
report was returned for each participant within one week.
When all sleep data were available, we conducted a one-hour semi-structured interview with each participant.
Interview questions focused on participants‚Äô prior knowledge of sleep, their subjective sleep quality (as noted
in the diary), their experience with the three devices, comparison of sleep data from three devices and their
evaluation of the overall credibility of each device. We did not fix the order of questions but adapted to the ‚Äúflow‚Äù
of the interview. During the interview, we presented to participants the sleep data measured by three devices on
the same nights to encourage questions and reflection about the devices and the sleep data. We not only showed
them the hypnograms from three devices plotted on the same time scale, but also a summary of the numerical
data including TST, WASO, SE, and the ratio of each sleep stage. All interviews were conducted in English and
were audio-recorded and transcribed verbatim.
The qualitative data from the interview transcripts was analyzed following the principles of a thematic analysis
[9]. First, all authors read through the transcripts to become familiar with what the data entails and to discuss
initial codes. Initial codes focused on usability concerns and the physical appearance of devices, sleep patterns
and assumptions, and on the discrepancy between different sleep data and the trustworthiness of these data. The
first author then coded by iteratively going through all transcripts in a software called Saturate, generating 498
unique codes. Due to the emerging codes around trustworthiness of the data and how such trust was shaped by
the device, information and prior assumptions, we started to frame the data based on Fogg and Tseng‚Äôs systems
perspective of credibility assessment [27]. Based on contextual information from participants and their statements,
we sought to distinguish between statements based on experience, as opposed to superficial judgements based on
presumption, reputation, or surface level inspections of the device. Thereafter both authors went through the
excerpts and initial codes together to combine codes into overarching themes. The codes were grouped through
virtual post-it notes on Padlet (https://padlet.com/). After several iterations, we grouped our codes into four
themes: credibility in sleep information, functional credibility of sleep-tracking devices, dashboard interface
credibility, and device physical appearance and credibility. These themes are described in detail in the next
section.
4 FINDINGS
The findings show how the credibility of sleep-tracking devices rests on several factors: people judge credibility
not only from the information that they receive but also based on their perceptions of the device functionality as
well as based on their interactions with the device and interface. It is important to note that people‚Äôs judgements
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:9
Table 3. Identified Factors Affecting Credibility Assessment at Each Technology Level
Technology level Factors
Information credibility Sleep fallacy
Validation with medical device
Agreement with prior sleep knowledge and assumptions
Agreement with subjective and desirable sleep experience
Functional credibility Black-box fallacy
EEG sensing
Interface credibility Comprehensiveness of data
Granularity/fragmentation of data
Device credibility Device fitness
Up-to-date appearance
may not always be accurate, because judgements could be based on presumptions, reputation and surface
level judgements in addition to actual experience. Furthermore, some participants found it difficult to interpret
sleep stages (sleep fallacy), and the black boxed nature of devices made it difficult for them to understand how
information was sensed and processed (black box fallacy). Table 3 provides an overview of the findings about
credibility assessments at different technology levels. In what follows, we first present the discrepancies between
sleep data from different devices, followed by our findings about how people assess the credibility of devices in
light of these discrepancies.
4.1 Discrepancies in Sleep Data
The findings highlighted discrepancies between data from different devices as well as discrepancies between device
data and how people subjectively assess their sleep. As described in section 2, we expected such discrepancies.
They are an important premise for this study because the lack of a single and accurate sleep assessment prompts
people to compare and assess the credibility of different devices (which will be described in sections 4.2-4.5).
4.1.1 Conflicting Data from Three Devices. As illustrated in Fig. 2, the medical device and Fitbit were closely
aligned for almost all participants on total sleep time (TST). However, 15 out of 22 participants had conflicting data
on TST measured by Neuroon compared to the medical device. This was largely because the Neuroon eye mask
easily slid off participants‚Äô faces, which for 16 of the participants led to poor sleep data. Participants recognized
these conflicts and commented that ‚ÄúNeuroon cannot be fixed on the face so the data is not reliable‚Äù (E18).
The discrepancies became more obvious when comparing the number of awakenings (NAWK) between devices
and experiences recorded by participants in their sleep diary. As illustrated in Fig. 3, all the participants were
faced with discrepancies between their subjective experience and the device data. Participants typically recorded
only a small number of awakenings, which largely aligned with the number of awakenings counted by Fitbit
and, though to a lesser degree, with the count provided by Neuroon. For this metric, there was a discrepancy
between the participants‚Äô subjective experience from their sleep diary and the data from the medical device, with
the medical device data presenting a larger number of awakenings for all participants. The medical data was
more closely aligned with a second Fitbit metric that presents the sum of the number of awakenings and the
number of brief periods of restlessness (less than 2 minutes), but neither data reflected the subjective experiences
of participants. Participants mentioned that the discrepancy on awakenings may be attributed to the differences
in how this metric was defined.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:10 ‚Ä¢ Liang and Ploderer
Fig. 2. Comparison of total sleep time (TST) with three devices and sleep diary.
Fig. 3. Comparison of number of awakenings (NAWK) measured with three devices and sleep diary.
"I think the definition of awakening is different. I counted the awakenings that I recognized that I was
awake. But maybe the medical device counted something different." (E13)
"I think the difference is the threshold of the awakening. It‚Äôs because I moved too much during my sleep.
I wasn‚Äôt awake, but I moved, so the devices categorized it as awakening." (E16)
Discrepancies were also found among devices on sleep stage ratios. For example, Fig. 4 illustrates deep sleep
ratio measured with three devices. Compared to Fitbit and Neuroon, the medical device showed much lower ratio
of deep sleep for almost all participants. E16 commented that ‚ÄúI was shocked to see that I had no deep sleep on the
medical report‚Äù and N22 said ‚ÄúI‚Äôm surprised that I seldom had deep sleep. I thought it was natural to have deep sleep,
in all sleep cycles, at least 3 times in one night. But according to the data, I didn‚Äôt have much deep sleep‚Äù.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:11
Fig. 4. Comparison of deep sleep ratio measured with three devices.
4.1.2 Subjective Meaning of Sleep Quality. A second challenge in interpreting the sleep data is that human sleep
can be measured using multiple metrics. In this study we asked participants to choose the most important and
least important sleep metric for them. The results shown in Fig. 5 demonstrates that most participants (16 out
of 22) consider feeling fresh in the morning as an indicator of having slept well. Other important sleep metrics
include total sleep time (5), sleep efficiency (4) and sleep onset latency (4).
Fig. 5. Distribution of the most important and least important sleep metric for participants.
We also found that some participants considered more than one metric as critical in assessing their sleep
quality. The main reason is that human sleep can be measured along multiple dimensions, and these dimensions
are not totally independent from one another. For example, N1 and E12 considered wake up freshness and sleep
efficiency equally critical as these two metrics are correlated.
"Sleep efficiency is important for me. . . also wake up freshness. I think these two are correlated." (N1)
"Bedtime will affect how fresh I feel when I wake up." (E19)
On the other hand, 6 out of 22 participants considered the number of awakenings as least important, followed
by total sleep time (3), sleep onset latency (3) and wake after sleep onset (3). These metrics were considered not
important partly because participants had no problem in these dimensions of sleep quality. For example, N7
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:12 ‚Ä¢ Liang and Ploderer
states that "Number of awakenings is not important for me because I can easily get back to sleep." While wake up
freshness was often considered as an important sleep metric, E5 and N14 expressed their concern of relying on
this subjective measure that could potentially be affected by many factors other than sleep quality. "During exam
period, I usually woke up feeling fresh despite of short sleep hours. It was because I was motivated, not because my
sleep quality was good. Feeling could be tricky." (N11) In addition, E13, E17, E18, E21 found it hard to discard any
sleep metric as they were all important. "All these metrics are important to a certain degree." (E13)
4.2 Credibility in Sleep Information
Information credibility relates to perceived believability of information about sleep length, sleep stages, etc. In
judging this data, participants relied on the authority of the medical device information to validate information
from Neuroon and Fitbit. Furthermore, participants judged information based on its plausibility in light of their
knowledge and experience of sleep, even if their knowledge was limited.
4.2.1 Sleep Fallacy. Human sleep is a complex phenomenon that can be measured by many metrics along multiple
dimensions. Interpreting the full set of metrics requires extensive domain expertise, which is often challenging
for users of sleep-tracking technologies. Although participants in our study intuitively understood basic sleep
metrics like total sleep time (TST) and time awake after sleep onset (WASO), they at times misinterpreted sleep
stages. Nine of 22 participants considered deep sleep the most important to feel refreshed, while five participants
doubted the significance of light sleep. Some participants also had unrealistic expectations on the amount of deep
sleep that healthy adults could possibly get, which deviated significantly from scientific findings that healthy
adults typically spend 16-20% of total sleep time in deep sleep stage [74].
"I still don‚Äôt get a clear idea of light sleep. How does light sleep differ from deep sleep? Is it really as
important as deep sleep for me?" (N6)
"I thought that sleep would be mostly deep sleep, at least 50%. That‚Äôs what I would guess without any
knowledge of how sleep works." (E21)
Some participants had an incorrect understanding of the functional role of REM sleep. REM sleep plays an
important role in brain maturation and emotional memory processing [39]. It is an essential component of normal
human sleep regardless of age. Nevertheless, seven participants had negative impression on REM sleep, and they
associated having dreams with tiredness or stress. N4 and E13 thought dreaming had negative impact on overall
sleep quality, while N3 and E15 clearly stated that they preferred not having dreams at all.
"Is REM necessary? I do not know whether it is good or not to have dreams. . . " (N3)
"In my understanding, if you are dreaming, either you are too tired, or you are sleeping too much. If I‚Äôm
dreaming, that means my mind is not sleeping. I‚Äôm thinking of something else." (N4)
Another aspect of sleep fallacy relates to micro-arousals. Recent findings in sleep science indicate that microarousal is an essential part of human sleep and is important in ensuring the reversibility of sleep, otherwise sleep
would be identical to coma [33]. In healthy adults, the average duration is around 15 seconds, and the number
increases with age [8]. In our study, we found a common misunderstanding amongst participants who associated
sleep disruptions solely with adverse consequences, because participants were not aware of the need for normal
and healthy periods of micro-arousal.
"The medical report shows even more awakenings than the Fitbit. Do I have any problem?" (E18)
"Is it normal to be awake this often?‚Äù (E19)
Sleep fallacy affects the perceptions of information credibility. For example, some participants gave high
credence to devices that produce better results‚Äîsuch as longer sleep or less awakenings‚Äîbecause they assumed
that those are indicative of good sleep.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:13
"I would imagine more deep sleep is good. So I trust Neuroon because it gave better data." (N14, Fitbit
only showed three deep sleep bouts in the first half of night, while Neuroon showed extra two deep
sleep bouts in the second half of night)
4.2.2 Validation with Medical Device Information Increases Reputed Credibility. A major consideration in judging
the information from consumer sleep-tracking devices was if it aligned with the information provided in the
report from the medical device. It is not surprising that by introducing this study to participants as a comparison
between two different consumer devices and a medical device, that our participants perceived the medical device
as having the highest level of accuracy. After all, labelling a device as ‚Äòmedical‚Äô and having data interpreted by
professional sleep experts enhances the reputation of the sleep information received. Hence, we found that the
medical device indeed served as an authority for many participants that they first used to validate the information
from other devices.
"It‚Äôs already tested before it was released to be used in the hospital or for medical treatment, so I think
it‚Äôs the most reliable." (E19)
"When you say that it‚Äôs a medical device, there is a little bit of bias in my feeling and maybe because I
study medical related subjects, I more rely on authority‚Äôs device than the commercial ones." (N20)
Subsequently, people believed in information from consumer devices when it aligned well with the information
from the medical device.
"Because both Fitbit and the medical device say that I was awake here, I would trust the data." (N2)
"I trust Fitbit over Neuroon because it detected deep sleep in the second half of my sleep, which is
consistent with the medical device." (N14)
4.2.3 Agreement with Prior Sleep Knowledge and Presumptions Increases Credibility. Our analysis suggests that
many participants also assessed the credibility of sleep data by comparing the data with their prior knowledge. The
data that agreed with what they presumed thus gained more credence than that deviated from their knowledge.
For instance, a few participants knew that going to bed late would lead to poor sleep and that deep sleep was
more likely to occur in the first half of night, and they were satisfied with the device that produced supportive
data.
"Maybe I should trust the medical device on deep sleep, because I went to bed really late and I might not
get that much deep sleep right after the exam. Fitbit showed too much deep sleep." (N11)
"As far as I know, usually we have good rest between 10 to 2 am. According to the data, I had deep sleep
after 10 and before 2. I think I‚Äôm very satisfied with this data. It is true." (N20)
However, some participants had limited knowledge and erroneous presumptions. For them, data validity was
less important than the agreement of data to what they assumed, especially on deep sleep. Being presented with
data of deep sleep ratio by medical device (0.4%), Fitbit (17%) and Neuroon (24%), N14 reluctantly gave high
credence to consumer devices despite that her rationale was in favor of the medical device. "My brain is telling me
the medical device is correct, but I don‚Äôt want to trust medical device (because the numbers are not good). Probably
just take average of Fitbit and Neuroon." (N14). Similarly, N4 favored Fitbit over medical device for deep sleep. "As
for deep sleep, I trust Fitbit over the medical device because there‚Äôs some deep sleep between 2-4 am as I expected."
(N4).
4.2.4 Agreement with Subjective and Desirable Sleep Experience Increases Credibility. Another important reference
for credibility assessment of sleep data was the subjective sleep experience of participants, as noted in their
diaries. Participants leveraged notes on dreams and sleep onset latency as reference points, and they were inclined
to give more credence to device data that aligned with their notes and recollections of their sleep experience.
"The REM is just before waking up, so it corresponds to my image that I often wake up from dreams. I
trust Fitbit over Neuroon because it‚Äôs more consistent with my feeling." (E16)
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:14 ‚Ä¢ Liang and Ploderer
"Deep sleep is only 0.6% in the medical report. According to my feeling, I felt good when I woke up. Before
I saw the results, I trusted medical device. But now I choose Fitbit because it‚Äôs closer to my feeling." (E18)
Although subjective experience of sleep was frequently used as a reference point, participants acknowledged
that feelings could be incomplete, inaccurate and unreliable, stating that ‚Äúwe do not consciously experience sleep
stages‚Äù (11 out of 22 participants), ‚Äúmemory is unreliable‚Äù (8), and ‚Äúaawakenings could be too brief to be noticed‚Äù (6).
Participants have expectations of their sleep data based on their subjective sleep experience. The desirability
of sleep data was an important consideration especially when sleep experience and sleep data did not align.
Particularly participants who were confident of their sleep quality were inclined to give high credence to devices
that produced desirable numbers. For example, N7 considered the one long awakening on Fitbit more believable
than the 18 brief awakenings indicated by medical device and stated that "I think I should believe in Fitbit because
the numbers are better. I told you I aim at better numbers, because I generally sleep well." (N7). Medical data with
exaggerated number of awakenings or low deep sleep ratio were very likely to be discarded as non-credible.
"In terms of awakenings, I trust Fitbit because it follows my definition of awakening. I don‚Äôt know what
the medical device measures. Maybe my brain was awake, but my eyes were not awake." (N12)
"The medical report only showed very brief deep sleep. Compared with Fitbit, it‚Äôs unbelievable because I
felt good after I woke up." (E13)
"Normally, one would believe medical data, but so many awakenings reduced my willingness to believe
it." (N22)
Participants highlighted a number of considerations in reconciling sleep data and subjective experience. We
identified three strategies that participants adopted to reach a plausible view of their sleep. As summarized
in Table 4, eight participants chose to believe their subjective sleep experience, while six participants favored
device data. The rest chose to combine both: believing subjective experience on perceivable sleep metrics such
as awakenings while relying on devices for non-perceivable metrics such as deep sleep and REM sleep. The
choice of strategy had little to do with personal history of sleep disorder or prior self-tracking experience. That
said, it is possible that good sleepers were more inclined to favor their subjective experience over data, as the
average PSQI of group A (3.25¬±1.67) was lower (indicating better subjective sleep) than that of group B (4.63¬±2.82)
and group C (4.67¬±2.42), though the difference was not statistically significant according to Kruskal-Wallis test
(ùúí
2 = 5.50, p = 0.24).
4.3 Functional Credibility of Sleep-tracking Devices
Functional credibility relates to how a device achieves the functions it is supposed to achieve. Judging functional
credibility of sleep-tracking devices was difficult for many participants, because they perceived the sleep-tracking
devices as a black box that conceals how data is collected and processed. Hence, many participants relied on
surface cues to judge the credibility: devices that collect EEG signals were seen as more credible in inferring
sleep stages.
4.3.1 Black Box Fallacy. Sleep-tracking devices are complicated technologies that remain a black box for end
users in terms of what these devices measure and how the measures are processed and mapped to sleep stages.
Firstly, we found that many participants were not familiar wih what exactly each device measured, regardless
of whether they were experienced users or novice users (see Table 5). Only around half of the participants (12
out of 22 participants) knew exactly what the medical device measured, other participants either had no idea
or thought the medical device measured limb movements like Fitbit. "In terms of technical mechanism, I‚Äôm not
sure how the medical device measures movements." (N20) Some participants thought the medical device used a
multimodal sensing scheme (though the electrode behind ear was just a ground electrode)."The medical device
uses two electrodes, which made me feel it‚Äôs more reliable." (N14)
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:15
Table 4. Strategies Participants Adopted to Reconcile Discrepancies between Data and Subjective Experience
Strategies Participants Quotes
(A) Favor Group A ‚ÄúI believe my feeling and I doubt the records here. I feel my sleep is
subjective (8 participants) better than average, based on the time it takes me to fall asleep,
experience N1, N7, E9, and the fact that I don‚Äôt wake up during sleep.‚Äù (E13)
N12, E13, E17, ‚ÄúIf the device says something different from how I feel, I would say
E21, N22 the device got broken.‚Äù (E17)
‚ÄúThe clinical data is telling me all those sleep cycles, but I don‚Äôt
know what I can get out of it. The only thing that I definitely know
is I felt rested in the morning.‚Äù (N22)
(B) Combine Group B ‚ÄúI would believe my experience, but for REM and deep sleep,
subjective (8 participants) there is no other way but to believe the medical data.‚Äù (N3)
experience and N3, N6, E10, ‚ÄúI will take average of the data from all devices for light sleep and
device data N14, E16, E18, REM. For awakenings I believe my feeling, and for deep sleep I
E19, N20 should believe the medical data.‚Äù (N14)
‚ÄúI only believe my feeling on the awakenings. Other than that, I
believe the Fitbit data.‚Äù (E19)
(C) Favor device Group C ‚ÄúI don‚Äôt think clearly during sleep, so I can‚Äôt really believe my
data (6 participants) experience. Maybe machines are more reliable and trustable.‚Äù (N2)
N2, N4, E5, N8, ‚ÄúI will believe the medical data because I‚Äôm not really certain
N11, E15 about the quality of my sleep.‚Äù (E15)
On the other hand, two participants (N8, N11) thought Fitbit relied on the same mechanism of Neuroon and
the medical device (measuring brainwaves), while 3 participants (N4, E16, N20) thought Neuroon detected limb
movements like Fitbit.
"So the Fitbit senses brainwaves by detecting the blood flow I think. . . Oh, movements. Then I guess
movements reflect brainwaves because the Fitbit data is quite similar to the medical data." (N8)
Black box fallacy led some participants to arrive at wrong conclusions on the inner workings of these devices.
For example, E17 and E21 assumed that the lights in Neuroon were optical sensors used to track users‚Äô cornea.
Since they thought this extra modality of input could enhance measurement accuracy, they gave more credence
to Neuroon than Fitbit. ‚ÄúI think the Neuroon uses good principle because there are the lights that track your pupils.‚Äù
(E21). On the contrary, good knowledge on how devices work is essential for participants to form realistic
expectations on the devices.
"Fitbit didn‚Äôt detect the first REM. Maybe it was too short. Also, there are two long awakenings on Fitbit
while the other devices didn‚Äôt detect them. I guess I was moving my arm or something during sleep. It
seems quite logical because your arm is more likely to move than your head, so maybe that‚Äôs because of
this." (N20)
Secondly, even for participants who understood how devices collected data, it was often not clear how these
signals related to sleep stages. This was particularly relevant for Fitbit, as participants were unclear how movement
and heart rate data could be turned into sleep stages without having brainwave measures.
"I‚Äôm not quite sure of how Fitbit measures REM sleep. During REM sleep, our body doesn‚Äôt move, so how
do wristbands measure it?" (N6)
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:16 ‚Ä¢ Liang and Ploderer
Table 5. Participants‚Äô Perception on What Devices Measure
ID Fitbit1 Neuroon 2 Medical device3
N14 No idea Brainwaves Brainwaves
N2 No idea No idea Brainwaves
N3 Movement No idea No idea
N4 Movement Movement Brainwaves
E5 No idea No idea No idea
N6 Movement Brainwaves Brainwaves
N7 No idea Brainwaves Brainwaves
N8 Brainwaves No idea No idea
E9 Movement & heart rate No idea No idea
E10 No idea No idea No idea
N11 Brainwaves & heart rate Brainwaves Brainwaves
N12 No idea No idea No idea
E13 No idea Brainwaves Brainwaves
N14 No idea No idea No idea
E15 No idea Brainwaves Brainwaves
E16 Movement Movement No idea
E17 Heart rate No idea No idea
E18 Heart rate Brainwaves Brainwave
E19 Movement Brainwaves Brainwaves
N20 Movement Movement Movement
E21 Movement & heart rate Brainwaves Brainwaves
N22 No idea Brainwaves Brainwaves
1Fitbit measures movement and heart rate.
2Neuroon measures brainwave, eye and limb movement, and blood oxygen saturation.
3Medical device measures brainwave.
4
ID numbers starting with N indicate novice users; those starting with E indicate experienced users.
"I see, the mechanism is on the movement of the body. Then how can it recognize what is light sleep and
deep sleep? We don‚Äôt move in REM sleep? I thought I didn‚Äôt move in all the three stages." (N7)
Consequently, several participants questioned the credibility of the Fitbit device. Even when Fitbit agreed quite
well to the medical device, participants attributed it to other reasons. Some believed that REM sleep stage might
be easy to measure by any device, and thus good measurement accuracy on that sleep stage did not justify the
advantage of Fitbit. One participant (N12) even considered the good agreement as coincidence.
"REM sleep is easy to measure, right? All three devices have the same results." (N11)
"So the Fitbit measures movement and heart rate. What becomes the significance of that data? I know
your brainwave is supposed to tell you something about your sleep stages, but how can you measure the
REM cycle and light sleep and deep sleep with heartbeat or movement? Maybe if I knew how heart rate
is tied to brainwave, I will be convinced, but at this point, to me it‚Äôs just like a coincidence that Fitbit
gave similar results as the medical device." (N12)
4.3.2 EEG Sensing Increases Presumed Credibility. As participants had limited knowledge on how sleep-tracking
devices work, they presumed that devices relying on EEG sensors worn on the head are more credible than
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:17
devices worn on the wrists. Hence, a major consideration in judging the functional credibility of sleep-tracking
devices was whether it included EEG signals, even though the exact nature of EEG sensing was not understood.
Consequently, Neuroon and the medical device were in general considered more trustworthy than Fitbit.
"Because the medical device puts sensors here on the head, it could catch more information, better than
using here (the wrist)." (E15)
"I think Neuroon should be more accurate for deep sleep because it measures brainwaves, but for Fitbit it
measures only movement." (E19)
4.4 Dashboard Interface Credibility
Interface Credibility relates to the way a device visualizes information and the interaction experience. Fitbit
and Neuroon allowed participants to view sleep metrics through a mobile dashboard interface, as illustrated in
Fig. 6 (a) and (b). Information from the medical device was presented to participants through a printed report
that incorporated sleep stages as interpreted by sleep experts, as illustrated in Fig. 6 (c). In interacting with these
dashboards and the report, we found that credibility was judged based on surface level appearances like the
amount of detail offered as well as by the granularity of the information. There were no comments about other
obvious differences in these examples, like the different colors used in these visualizations (e.g., whether an
alarming color like red is better suited to denote awakenings, poor signals, or REM sleep), the immediacy of the
dashboard compared to the report received after several days, or about the degree of interactivity that the Fitbit
and Neuroon dashboards offered compared to the printed report.
4.4.1 More Detail May Both Increase and Decrease Surface Credibility. Based on simple inspection, participants
noted that the medical report gave more comprehensive data than the consumer devices. For example, sleep
was classified into five stages (wake W, light sleep N1, light sleep N2, deep sleep N3, and REM sleep R) in the
medical report but was only classified into four stages on the consumer dashboards (wake, light sleep, deep sleep,
and REM sleep). In addition, the medical report offered extra information about the number of sleep cycles, the
duration of each sleep cycle, arousal index, and metrics of brainwave signal spectrum such as alpha, beta, and
delta power.
A few participants considered the medical device most credible due to the extra amount of details given in
the medical report. "I think I believe the medical device because the data is in more detailed than the consumer
devices." (E16). Others considered too much detail unnecessary, and they gave more credence to Fitbit because
the data was easier to understand and thus more trustworthy.
"The medical data is more into details. It takes time to understand the data. If I just want something that
I can check regularly or compare with previous days, Fitbit is more appropriate." (E5)
"I believe Fitbit over Neuroon not because it‚Äôs close to the medical report, but because it is easy to
understand, and the movement is reasonable." (N11)
4.4.1 More Detail May Both Increase and Decrease Surface Credibility. Based on simple inspection, participants
noted that the medical report gave more comprehensive data than the consumer devices. For example, sleep
was classified into five stages (wake W, light sleep N1, light sleep N2, deep sleep N3, and REM sleep R) in the
medical report but was only classified into four stages on the consumer dashboards (wake, light sleep, deep sleep,
and REM sleep). In addition, the medical report offered extra information about the number of sleep cycles, the
duration of each sleep cycle, arousal index, and metrics of brainwave signal spectrum such as alpha, beta, and
delta power.
A few participants considered the medical device most credible due to the extra amount of details given in the
medical report. "I think I believe the medical device because the data is in more detailed than the consumer devices."
(E16). Others considered too much detail unnecessary, and they gave more credence to Fitbit because the data
was easier to understand and thus more trustworthy.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:18 ‚Ä¢ Liang and Ploderer
Fig. 6. Interface of three devices: (a) Fitbit dashboard, (b) Neuroon dashboard, and (c) medical report.
"The medical data is more into details. It takes time to understand the data. If I just want something that
I can check regularly or compare with previous days, Fitbit is more appropriate." (E5)
"I believe Fitbit over Neuroon not because it‚Äôs close to the medical report, but because it is easy to
understand, and the movement is reasonable." (N11)
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:19
4.4.2 Higher Data Granularity May Both Increase and Decrease Surface Credibility. A second surface level cue for
judging the dashboard credibility was the degree of granularity of the data. In the medical report, the hypnogram
of a whole night‚Äôs sleep is featured by high granularity (and thus more fragmentations), while the hypnograms
in Fibit and Neuroon dashboards look smoother and more continuous. On the one hand, many participants found
it hard to believe in highly fragmented plots. As illustrated in Fig. 7, the hypnogram of E10 contains many brief
segments of deep sleep. She commented, ‚ÄúI have a hard time believing small things moving like that in the medical
report, because I don‚Äôt know if it makes much sense to have a deep sleep of 30 seconds and then completely change. I
feel I can believe things that are longer and more consistent like what‚Äôs shown on Fitbit." (E10, Fig. 7). For the same
reason, N6 did not believe medical data for awakenings and light sleep because these parts were too fragmented.
Fig. 7. The hypnogram of E10 contains many brief segments of deep sleep (highlighted in dashed red circles). The fragmentation of the data on the interface undermined the credibility of the medical device for E10.
"I‚Äôm trying to think on how fragmented the data is. I trust the medical device for deep and REM sleep,
but not for awake and light sleep. These parts are just too messy." (N6)
On the other hand, two participants considered the medical device the most credible exactly because of the
high data granularity in the plot. The quotes below suggest that participants here did not necessarily consider the
detailed content provided but rather used the layout as a heuristic cue to judge the believability of the devices.
"Medical data are plotted by points while Fitbit data are plotted by lines. I think the graph that is plotted
by points is more accurate than that plotted by lines because the sampling rate is higher. Fitbit just take
two or three points and it couldn‚Äôt get accurate data in between." (N7)
"It‚Äôs hard to detect deep and REM sleep because they are only small portion of sleep. So sampling rate
could have strong impact on the results of REM and deep sleep." (N11)
4.5 Device Physical Appearance and Credibility
Device credibility relates to the physical aspect of a device such as physical appearance and hardware structure.
We found that physical attractiveness indeed affected surface credibility. For example, one participant gave higher
credence to Neuroon simply because it looked more up-to-date than the medical device. "In general, I would trust
Neuroon even more than the medical device, because it‚Äôs newer. The medical device looks old because the display is
like those on cellphones eight years ago." (N11).
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:20 ‚Ä¢ Liang and Ploderer
The shape of a device also influenced perceptions of credibility. Devices that were easy to wear and whose
sensors were firmly placed received more credence especially after participants had gained first-hand experience
with the devices. The three devices used in this study were very different in shape. The Fitbit device was a
lightweight wristband worn on the non-dominant arm. Neuroon was an eye mask worn on the face and was fixed
by a rubber band. In the study, the eye mask easily slid off participants‚Äô faces, leading to deteriorated signals and
thus poor data quality. Sixteen out of the 22 participants complained that Neuroon eye mask slid off their faces.
Many of them gave low credence to Neuroon after the experiment even if they initially ranked it better than
Fitbit. The medical device consisted of a body cuboid of size 95mm by 64mm, which did not need to be attached
to the user. Instead, it connected to two electrodes that were glued to the head, one on the forehead and the other
behind an ear. Despite the inconvenience of the wires, the fact that the two electrodes were adhesive, and that
the device was not worn on the body lent the medical device more credibility than the consumer devices.
"The medical device had contact to my forehead and neck all the time, but Neuroon may have slid off
my face, and Fitbit may have gotten some errors when I changed my position." (N11)
"I‚Äôm just wondering what happened to the signal quality. Maybe it didn‚Äôt fit my facial shape. Maybe
somehow the mask was not touching where it was supposed to touch." (E17)
5 DISCUSSION
This paper presents an understanding of how people assess the credibility of sleep-tracking devices. Building
on well-established HCI theory on credibility [27], our findings reveal that credibility is based on assumptions,
personal experience of sleep (and time awake), and comparing data from consumer devices with data from
the medical device. The credibility of information per se is not the sole factor in judging a device: functional,
interface, and device aspects also influence judgements. These judgements are often superficial, rather than based
on experience and deep understanding, and to some extent inaccurate. The credibility framing highlighted two
fallacies in sleep-tracking. Firstly, like others [61, 77], we observed sleep metrics and sleep stages do not align
with the way people experience and understand their sleep. We also observed that participants interpreted sleep
disruptions as a concern, because they were unaware that micro-arousals are an essential and healthy part of
human sleep [33]. Both of these misconceptions lead to sleep fallacies. Secondly, technologies conceal the way
data is collected and processed, which makes it difficult to develop a better understanding of sleep and results in
a black-box fallacy.
The novelty of this contribution lies in that we used three devices of distinct design, mechanism and information
accuracy to tease out the factors that affect users‚Äô credibility assessment at different technology levels. This
methodology allowed us to uncover aspects that are key to different technology levels of credibility and that
are not possible to be disentangled using one device, such as device functionality (related to presumed and
surface credibility), dashboard interface design (related to surface credibility) and physical appearance (related to
surface and experienced credibility). The medical device provided a reference point for participants to evaluate
the accuracy of consumer devices, thus allowing us the probe whether accuracy is key to information credibility
as has been suggested in other context such as online health systems and car navigation systems [27].
This study sets a precedent in studying the credibility of sleep-tracking technologies. In what follows we
discuss the findings along the four technology levels of credibility assessment, the two types of fallacies we
observed in sleep-tracking, and the ways in which people aligned their knowledge and experience with sleep
data. Based on these discussions, we highlight design opportunities to strengthen credibility.
5.1 Four Levels of Credibility Assessment
Sleep-tracking research has been dominantly focused on users‚Äô perception of sleep information per se, especially
whether the information is accurate [59, 61, 77, 94] and meaningful to people [14‚Äì16, 47, 60]. This study confirms
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:21
that the perceived accuracy of sleep data itself indeed is a main aspect that participants considered when assessing
the credibility of a sleep-tracking device, as several participants gave high credence to medical data and to
consumer devices that agreed with the medical device. This finding echoes the work by Yang and colleagues
that users of self-tracking devices took accuracy into account when they assessed their data [45]. Without
having medical data as reference point, therefore, previous sleep-tracking studies generally assumed that better
measurement accuracy led to higher credibility, as it would increase the trustworthiness of sleep data offered by
these devices [20, 21, 55].
Nevertheless, our study further found that data accuracy, despite of being a key concern in sleep research, is
not necessarily a key concern when people assess the credibility of technology. In the domain of sleep medicine,
sleep diaries or questionnaires that measure subjective sleep experience are routinely ranked lower than any
kind of sleep-tracking devices‚Äîeither contactless devices, contact devices or PSG‚Äîwith respect to accuracy [42].
However, our study shows that approximately a third of the participants gave higher credence to their subjective
experience over data, and another third acknowledged the importance of both subjectivity and objectivity. Data
accuracy that is high-valued in clinical sleep research thus may not necessarily reflect what people value in
sleep-tracking in daily life. To this end, our study provides complementary insights into the role of accuracy in
sleep-tracking. In addition to medical data, participants also relied on their prior sleep knowledge and subjective
sleep experience to assess the believability of the sleep data. The availability of multiple reference points added
an extra layer of complexity. When these reference points contradicted one another, especially when subjective
sleep experience deviated from device data, participants had to reconcile the differences by either choosing one
over the other or by combining or averaging over the two.
Second, in addition to the perceived quality of sleep data, our analysis showed that participants also considered
the credibility of the device mechanism. The mechanism of a device mostly affected presumed and surface credibility of a device. Due to the black-box nature of sleep-tracking devices, most participants had no understanding
of how exactly the devices work. Nevertheless, they relied on heuristic cues such as the placement of sensors and
were prone to give credence to devices that rely on EEG sensing.
Third, our finding echoes previous studies on e-health system that the comprehensiveness and granularity of
data presented on dashboard interface affected surface credibility [25, 79, 80]. Other factors such as color scheme,
the immediacy of data, and the degree of interactivity did not seem to affect participants‚Äô assessment of interface
credibility in this study. The potential impact of these factors is left for further investigation. Interestingly, no
consensus was found regarding the effect of data comprehensiveness and granularity. For a few participants,
comprehensive data with high granularity in the medical report gained reputed credibility. Nevertheless, the
majority of participants considered comprehensive data overwhelming to digest on daily basis, and they were
reluctant to believe data in high granularity as they assumed fragmented data were not believable. Hence, Fitbit
gained more credence over medical report for its clear and simple interface design and for the smoothened
plots in the dashboard. Compared to Neuroon, Fitbit was also considered more credible because it offered extra
information (e.g. personal and population benchmark) to help users gain insights into their sleep quality [93].
These findings indicate that a balance between comprehensiveness and simplicity is the key to interface credibility
in sleep-tracking. It is thus critical to present the right amount of sleep data that is easy to interpret and digest
for each user.
Fourth, we found that conveying credence through physical appearance is important for consumer sleeptracking devices, as participants did ‚Äújudge a book by its cover‚Äù. Among the two consumer devices, many
participants initially gave more credence to Neuroon than Fitbit due to its resemblance to the medical device
(e.g. the device was worn on the head to detect brainwaves) or because it looked more up to date. Nevertheless,
they later changed their opinion because Neuroon often slid off their faces and led to deteriorated signal quality.
As Neuroon had problem fitting to various types of facial geometry, many participants concluded that Fitbit
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:22 ‚Ä¢ Liang and Ploderer
was more credible among the two consumer devices. These findings show that physical appearance of a device
affected not only surface credibility but also experienced credibility.
5.2 Two Types of Fallacies in Sleep Tracking
Another key finding of this study is the two types of fallacy in participants‚Äô mental model of sleep-tracking: sleep
fallacy and black-box fallacy. These fallacies can negatively affect the ways in which users assess credibility and
how they interpret sleep data.
Sleep fallacies mainly occurred due to participants‚Äô misunderstanding of sleep continuity (e.g. number of
awakenings) and sleep stages. Brief awakenings, though often being considered as a symbol of sleep disruption
and thus associated to poor sleep, are a normal part of human sleep [33]. Many participants were doubtful about
the excessive number of awakenings shown in the medical report, especially when they did not consciously
experience those awakenings and they were confident of their sleep quality. In contrast, consumer devices tended
to ignore brief arousals and only marked awakenings that lasted longer than 2 minutes, which contributed
to increased credibility. Additionally, participants often had a limited understanding of the functional role of
different sleep stages and the normal amount of each sleep stage that healthy adults can possibly get. In line
with the finding in [77], we found that participants placed undue emphasis on deep sleep. Furthermore, many
participants had unrealistic expectation of how much deep sleep they could possibly get (higher than 50%). In
contrast, the functional importance of REM was not recognized: some participants wrongly assumed that REM
contributes little to body restoration; others associated having dreams with tiredness or stress.
Technology transparency has been considered important in sleep tracking [58, 61, 77]. However, we found that
participants often failed to assess the functional credibility of the three sleep-tracking devices through sensible
analysis, because the devices remained a black box that prevented participants from constructing a correct
conceptual model of how they work [15, 77]. Some participants wrongly asserted that Fitbit detected brainwave
through blood flow, while others assumed that the medical EEG measured body movements. Due to lack of domain
knowledge, it was difficult for participants to understand the sensing modalities from the physical structure of
device, like sensors and lights. Without knowing how the bio-signals relate to sleep stages, participants found
it hard to believe Fitbit data despite of its agreement with the medical device. Consequently, credible device
information was considered as non-credible. Therefore, helping users understand how sleep-tracking devices
work is critical to gaining credibility, as has been shown in previous studies about people‚Äôs trust on machines
[72].
5.3 (Mis)alignment between Subjective Sleep Experience and Objective Sleep Data
In this study, good alignment on total sleep time was found‚Äîfor many participant‚Äîbetween Fitbit and the medical
device (regardless of relying on different mechanisms), and between device data and what participants recorded
in their sleep diary. However, significant discrepancies were found for awakenings and sleep stages (especially
deep sleep).
The reason for such discrepancies boils down to the tension between what users consciously experience about
their sleep (i.e. the known) and what users are not able to consciously experience during sleep (i.e. the unknown).
The fifteenth century Philosopher Nicholas of Cusa argued that knowledge is always interpreted within the
context of a combination of known and unknown [7]. This is especially true in sleep tracking where people may
know about prolonged awakenings and total sleep, but where they also have to make sense of the objective data
that they cannot consciously experience and know, such as sleep stages and brief awakenings marked by EEG
signals.
Our findings show that participants adopted different strategies to reach a plausible view on these data. For
awakenings, they were inclined to ignore brief arousals that were not consciously perceived and only relied on
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:23
long awakenings that they remembered or noted in their diary to judge the credibility of device data. Participants
were sensitive to excessive number of awakenings, which echoes findings from related work that sleep quality
essentially means sleep continuity for many people [1]. Consequently, medical device data lost credibility because
it counted in any kind of awakenings, both long awakenings that participants knew about as well as microarousals that they were not aware of. Fitbit and Neuroon, on the other hand, gained credibility by only recording
major awakenings longer than 2 minutes. Neuroon totally ignored shorter awakenings, while Fitbit marked them
as restlessness. Although Fitbit restlessness is inferred from wrist movement rather than from brainwave signals,
it agreed reasonably well to micro EEG arousals in medical data as indicated by the quantitative comparison.
Some participants attributed the discrepancies on awakenings to the difference in how this metric was defined in
different settings. Indeed, the interchangeable use of ‚Äúawakening‚Äù and ‚Äúarousal‚Äù may account for the misalignment
of medical data and subjective experience in terms of sleep continuity.
For sleep stages, on the other hand, many participants tended to judge the credibility of the unperceivable
objective measures based on subjective sleep satisfaction‚Äîsomething they were certain of. Even though the
correlations between subjective feeling and objective measures are typically only moderate [40, 90], many
participants assumed a proportional relationship between how restorative they felt about their sleep and the
ratio of deep sleep. Consequently, they questioned the believability of extremely low ratio of deep sleep indicated
by the medical report and favored data from consumer devices that showed a higher ratio. This phenomenon can
be best explained by the confirmation bias theory in psychology, where people favor information that confirms
their preexisting beliefs to alleviate cognitive dissonance [91].
The misalignment between objective sleep measures and subjective sleep quality‚Äîa phenomenon known as
sleep misperception‚Äîhas been well-documented in sleep research [35, 36]. From a human-computer interaction
perspective, we narrowed down possible reasons to the inconsistency in metric definition (i.e. awakening vs
arousal) and to the undue mapping from subjective sleep experience to objective measures. Addressing the
misalignment between what devices say and how people feel about their sleep is important as it affects not
only how users assess the believability of sleep data but also sustained usage of sleep-tracking technologies [51].
Despite of the tension between objectivity and subjectivity in sleep tracking, it is probably less appropriate to
consider the solution as a dichotomy where we need to choose one or the other than bringing the two together.
Objective sleep quality and subjective sleep quality measures different aspects of the same phenomenon and
complement each other. The mission of sleep tracking technologies is to achieve a better alignment between the
two by addressing the reasons for misalignment.
5.4 Design Challenges and Opportunities
Based on these observations, we highlight the following design challenges and opportunities to enhance the
credibility of sleep-tracking technologies.
Design challenge 1: Support the construction of sleep knowledge. Our findings show that sleep fallacy was common
and a major reason for confirmation bias in sleep-tracking. A key opportunity for design is to provide users with
an opportunity to construct new knowledge, which builds on the knowledge and experience of users, expands on
sleep data, addresses potential fallacies and biases, and provides insight into evidence-based sleep knowledge.
We recommend sleep-tracking devices offer evidence-based information on how sleep metrics are defined, the
functional roles of micro arousal and sleep stages, the physiological changes accompanying each sleep stage, as
well as the National Sleep Foundation Recommendations [74] to benchmark good sleep (i.e. the recommended
range for objective sleep measures). Being able to construct new knowledge is critical for users to assess the
trustworthiness of sleep data against scientific knowledge as well as to align objective measures and subjective
sleep experience.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
17:24 ‚Ä¢ Liang and Ploderer
Design challenge 2: Increase the transparency of device mechanism and validity. Technology transparency has
been considered important in sleep tracking [58, 61, 77]. It is thus critical to help users form an appropriate
mental model of how sleep-tracking devices work and the validity of different types of devices. Some of the key
information include what bio-signals are measured and the significance of these signals in sleep staging. Plotting
bio-signals together with sleep data to emphasize the signal patterns that are used to infer sleep stages may also
increase perceived trustworthiness. Since each type of sleep-tracking technology has its target user group [64],
we recommend device makers to also inform users the strength and limitations of the device based on established
evidence to help them form realistic expectations [21, 48, 55].
Design challenge 3: Identify objective measures that are relevant and knowable to each user. Our findings show
that the key to interface credibility is to strike a balance between comprehensiveness and simplicity. Previous
study found that users abandoned tracking devices if they perceived the collected data as not useful [51]. Instead
of showing the same full set of sleep measures to all users on daily basis, an alternative strategy is to adapt the
dashboard content to the sleep pattern and needs of each user through user profiling. For example, users can
be sub-grouped based on clinical/physiological characteristics or based on association of objective measurers
and subjective sleep quality rating [49]. Our finding show that participants used different metrics to assess
their sleep quality. Therefore, sleep-tracking technologies may focus on objective measures that users relate to
or incorporate conscious experiences and knowledge that people have about their sleep. One approach is to
develop new algorithms to predict subjective sleep quality based on multiple nights of objective measures, or to
incorporate diary data, as findings from sleep studies show that several nights of actigraphy measurements are
needed to reach a better match to subjective sleep quality [53]. In addition, metrics demonstrating high variations
over a time period (e.g. one month or half a year) should be prioritized over more constant metrics, because these
metrics has more clinical significance [53]. These strategies will not only help users to narrow down their focus
on the most relevant metrics but also contribute to the alignment of objective measures and subjective sleep
quality.
5.5 Recommendations for Future Research
The limitations of this study point out several directions for future research. First, this study provides insight into
experience related to initial credibility of sleep-tracking devices developed over three nights, but it did not look at
how credibility may be lost and regained over time [16, 29, 61]. Our findings pave the way for future longitudinal
studies to investigate how the credibility of sleep-tracking devices may be lost, to what extent it can be regained,
and what factors are involved. Second, the possible effects of gender, age, motivation for sleep-tracking and prior
experience with sleep tracking was not explored in the current study due to the homogeneity of the study cohort
(e.g., all college students). While investigating the effect of these factors was not the focus of this study, future
research may examine the importance of these factors for the development of credibility and how they may
be used to profile and model users. Third, this study did not delve into the possible effects of interface design
aspects such as color scheme, the immediacy of data, and the degree of interactivity as they were out of the main
scope. Further studies are needed to examine how these aspects may affect perceived interface credibility of
sleep-tracking devices.
6 CONCLUSION
This study has examined how people assess and perceive the credibility of sleep-tracking technologies. Our
findings provided insights into credibility at four different technology levels: information quality, device functionality, dashboard interface design, and physical appearance of a device. Credibility assessments were based on
first-hand experience with three sleep-tracking devices as well as on superficial judgements and assumptions.
We identified two blind spots‚Äîsleep fallacy (incomplete and erroneous sleep knowledge) and black-box fallacy
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 1, Article 17. Publication date: March 2020.
‚ÄúHow Does Fitbit Measure Brainwaves‚Äù: A Qualitative Study into the Credibility of Sleep-tracking Technologies ‚Ä¢ 17:25
(incorrect understanding of device mechanism)‚Äîwhich pose challenges in assessing credibility. These findings
offer two implications. First, enhancing the credibility of sleep-tracking technologies should seek solutions at
different technology levels ranging from information accuracy (as has been generally assumed in previous studies)
to mechanism, interface design and device design. Second, because the details of sleep stages and the inner
workings of black-boxed devices were not well understood, and because of the potential misalignment between
objective data and subjective sleep experience, people‚Äôs credibility assessment may deviate from the real level of
trustworthiness of the devices. Therefore, addressing these two fallacies and the misalignment between objective
data and subjective sleep experience is central to the design of credible sleep-tracking technologies that help
people gain insights into their sleep by allowing them to establish connections between their lived experience,
their data and scientific evidence.
