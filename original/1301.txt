Abstract
A well known result by Kilian (1988) [23] asserts that general secure two computation (2PC) with statistical security, can be based on OT. Specifically, in the client-server model, where only one party – the client – receives an output, Kilian's result shows that given the ability to call an ideal oracle that computes OT, two parties can securely compute an arbitrary function of their inputs with unconditional security. Ishai et al. (2011) [20] further showed that this can be done efficiently for every two-party functionality in NC1 in a single round.

However, their results only achieve statistical security, namely, it is allowed to have some error in security. This leaves open the natural question as to which client-server functionalities can be computed with perfect security in the OT-hybrid model, and what is the round complexity of such computation. So far, only a handful of functionalities were known to have such protocols. In addition to the obvious theoretical appeal of the question towards better understanding secure computation, perfect, as opposed to statistical reductions, may be useful for designing secure multiparty protocols with high concrete efficiency, achieved by eliminating the dependence on a security parameter.

In this work, we identify a large class of client-server functionalities f:X×Y↦{0,1}, where the server's domain X is larger than the client's domain Y, that have a perfect reduction to OT. Furthermore, our reduction is 1-round using an oracle to secure evaluation of many parallel invocations of 1-out-of-2 bit OT, as done by Ishai et al. (2011) [20]. Interestingly, the set of functions that we are able to compute was previously identified by Asharov (2014) [3] in the context of fairness in two-party computation, naming these functions full-dimensional. Our result also extends to randomized non-Boolean functions f:X×Y↦{0,…,k−1} satisfying |X|>(k−1)⋅|Y|.

Keywords
Oblivious transfer
Perfect security
Two-party computation

1. Introduction
In the setting of secure two-party computation (2PC), the goal is to allow two mutually distrustful parties to compute some function of their private inputs. The computation should preserve some security properties, even in the face of adversarial behavior by one of the parties. The two most common types of adversaries are malicious adversaries (which may instruct the corrupted party to deviate from the prescribed protocol in an arbitrary way), and semi-honest adversaries (which must follow the instructions of the protocol, but may try to infer additional information based on the view of the corrupted party).

Oblivious transfer (OT) is a two-party functionality, fundamental to 2PC and the more general secure multiparty computation (MPC). It was first introduced by Rabin [29] and Even et al. [14]. In the setting of  
 , there is a receiver holding a bit , and a sender holding two bit-messages 
. At the end of the interaction, the receiver learns 
 and nothing else, and the sender learns nothing. It turns out that OT can be used in the construction of protocols, both in 2PC and MPC with various security guarantees [23], [34], [15], [7]. Moreover, giving to the parties access to an ideal process that computes OT securely, is potentially useful.

Constructing protocols in this model, called the OT-hybrid model, could be used for optimizing the complexity of real world, computationally secure protocols for several reasons. First, using the OT-precomputation paradigm of Beaver [5], the heavy computation of OT can many times be pushed back to an offline phase. This offline phase is performed before the actual inputs for the computation (and possibly even the function to be computed) are known. Later, as the actual computation takes place, the precomputed OTs are very cheaply converted into actual OT interactions. Furthermore, the OT-extension paradigm of [6] offers a way to efficiently implement many OTs using a relatively small number of base OTs. This can be done using only symmetric-key primitives (e.g., one-way functions, pseudorandom generators). Furthermore, it can also be used to implement  
  (i.e., the receiver chooses one out of two string of length s) using a sub-linear (in the security parameter) number of calls to  
  and some additional sub-linear work, assuming a strong variant of PRG [18]. Additionally, there is a variety of computational assumptions that are sufficient to realize OT [28], or even with unconditional security under physical assumptions [11], [27], [12], [33], [22].

An interesting family of two-party functionalities are the client-server functionalities, where only one party – the client – receives an output. In addition to the OT functionality mentioned earlier, client-server functionalities include many other examples. Securely computing some of these functionalities could be useful for many interesting applications, both in theory and in practice.

For client-server, a well known result due to Kilian [23], asserts that OT is complete. That is, any two-party client-server functionality can be computed with unconditional security in the OT-hybrid model. Ishai, Prabhakaran, and Sahai [19] further showed that the protocol can be made efficient. Later, it was shown by Ishai et al. [20], that in the OT-hybrid model, every client-server functionality can be computed using a single round. Furthermore, the protocol's computational and communication complexity are efficient for functions in 
. However, all of the results achieve only statistical security, namely, it is allowed to have some error in security.

For the case of perfect security in this setting much less is known. Given access to (many parallel) ideal computations for  
 , Brassard et al. [9] showed how to compute the functionality  
 , and Wolf and Wullschleger [32] showed how to compute  
 , which is the same as  
  where the roles of the parties are reversed. Furthermore, the former protocol has a single round, in which the parties invoke the OT, and with no additional bits to be sent over the channel between the parties. The latter protocol requires an additional bit to be sent by the server.

Observe that the result of [9] implies that any client-server functionality f can be computed with perfect security against semi-honest corruptions. Indeed, let n be the number of inputs in the client's domain, and let s be the number of bits required to represent an output of f. The server will send to the  
  functionality all of the possible outputs with respect to its input, and the client will send its input. The client then outputs whatever it received from the OT. Clearly, the protocol is secure against semi-honest adversaries, however, in the malicious case, this is not true, in general. This is due to the fact that the server has complete control over the output of the client. For instance, for the “greater-than” function, the server can force the output of the client to be 1 if and only if y is even. Therefore, we are only interested in security against malicious adversaries.

Ishai et al. [21] studied perfectly secure multiparty computation in the correlated randomness model. They showed that any multiparty client-server functionality can be computed with perfect security, when the parties have access to a correlated randomness whose correlation depends on the function to be computed by the parties.

There are also various client-server functionalities that can be computed trivially (even in the plain model). For example, the XOR functionality can be computed by having the server sending its input to the client. These simple examples suggest that fairness is not a necessary condition for being able to compute a function perfectly in the client-server model.

Thus, the state of affairs is that most two-party client-server functionalities remain unclassified as to perfect security in the OT-hybrid model. In this work we address the following natural questions.

Which client-server functionalities can be computed with perfect security against malicious adversaries in the OT-hybrid model? What is the round complexity of such protocols?

The questions have an obvious theoretical appeal to it, and understanding it could help us gain a better understanding of general secure computation. In addition, perfect security may be useful for designing multiparty protocols with high concrete efficiency, achieved by eliminating the dependency on a security parameter.
We stress that, under the assumption that , it is impossible to achieve completeness theorems in our setting, similar to the completeness theorems of Kilian [23]. Indeed, suppose the parties want to compute an NP relation with perfect zero-knowledge and perfect soundness. Then it is impossible even when given access to any ideal functionality with no input (distributing some kind of correlated randomness) [21]. This is due to the fact that if such a protocol does exist, then one can use the simulator to decide the relation, putting it in BPP. Since OT can be perfectly reduced to a suitable no-input functionality, this implies that no such protocol exist in the OT-hybrid model.

1.1. Our results
Our main result states that if the parties have access to many parallel ideal computations of  
 , most client-server functionalities, where the server's domain is larger than the client's domain, can be computed with perfect full-security in a single round. Interestingly, the set of functions that we are able to compute was previously identified by Asharov [3] in the context of fairness in two-party computation, naming these functions as full-dimensional.

Let  be a function, where the server's domain size  is larger than the client's domain size . Write 
 and 
. We consider the geometric representation of f as  points over 
, where the 
 coordinate of the 
 point is 
. We then consider the convex polytope1 defined by these points. The function is called full-dimensional if the dimension of the polytope is exactly the same as the dimension of the space, i.e., . For example, if the points form a triangle in the plane then f is full-dimensional.2 We prove the following theorem:

Theorem 1.1 Informal

Let  be a client-server functionality. If f is full-dimensional, then it can be computed with perfect full-security in the OT-hybrid model in a single round. Furthermore, the number of OT calls is .

In fact, we generalize the above theorem, and we give a similar criterion for randomized non-Boolean functions. The class of functions that our protocol can compute can be further extended by adding to  inputs that fix the output. This class of functions includes many interesting examples, such as Yao's “millionaires' problem” (i.e., the “greater-than” function). Here the parties have inputs that ranges from 1 to some natural number n, and the output of the client is 1 if and only if its input is greater than or equal to the server's input.

Note that the communication complexity of our protocol is polynomial in the client's domain size, and not in its input's size. For functions with small domain, however, this does improve upon known construction that achieve statistical security (e.g., the single round protocol by Ishai et al. [20], see Section 7 for more details).

Its was proven by [3], that the number of deterministic Boolean full-dimensional functions tends to 1 exponentially fast as  and  grow. Specifically, a uniformly random function with domains sizes  and , will be full-dimensional with probability at least 
, where 
 denotes the probability that a uniformly random Boolean  matrix is singular. The value 
 has been recently shown to be 
 [31].

Theorem 1.1 identifies a set of client-server functionalities that are computable with perfect full-security. It does not yield a full characterization of such functions. For example, the status of the equality function 
, defined as  if and only if , is currently unknown. However, for the case of Boolean functions (even randomized), we are able to show that the protocol suggested in the proof of Theorem 1.1 computes only full-dimensional functions.

1.2. Our techniques
Our construction is based on the protocol of Ishai et al. [20], which admits statistical security. Roughly speaking, we identify two key issues with their construction that prevents the protocol from achieving perfect security. We then show how for full-dimensional functions, these issues can be fixed.

The construction makes use of perfect randomized encoding (PRE) [2]. A PRE 
 of a function f, is a randomized function such that for every input x and a uniformly random choice of the randomness r, it is possible to decode 
 and compute  without errors. In addition, the output distribution of 
 on input x reveals no information about x except from what follows from . As f is a PRE of itself, usually the PRE has an additional property. Here, we rely on a property called decomposability. Roughly, a PRE is said to be decomposable if it can be written as 
, where each 
 depends only on the randomness and the 
 bit of the input x. Observe that each 
 can be written as one of two vectors, depending on the 
 bit of x, i.e., we can write 
 as 
, where 
 depends on the randomness r. This definition can be viewed as the perfectly secure version of garbled circuits [34], [25].

The protocol of Ishai et al. [20].  Let us first give a brief overview of the protocol of Ishai et al. [20], which will be dubbed the IKOPS protocol. Recall that it is a single round protocol in the OT-hybrid model that achieves statistical security.

The main idea is to have the server run an “MPC in the head” [19]. That is, the (real) server locally emulates the execution of a perfectly secure3 multiparty protocol Π, computing some related functionality (described below), with many virtual servers performing the computation and have no output, and many virtual clients, each receiving an output. Each virtual client is associated with a value for each bit of the input y of the real client. Stated differently, if m is the number of bits in y, then there will be 2m virtual clients, denoted 
, with 
 associated with the predicate 
. For each input x of the server, the underlying protocol Π computes (and distributes among the virtual clients) a decomposable PRE 
 of the function 
, defined as 
. Specifically, the input of the virtual servers' are secret sharing of the real server's input x and randomness r. The output of the virtual client 
 in an honest execution of Π is 
, i.e., the part of the encoding that corresponds to the 
 bit of y being equal to b.

The real client can now use the available OT functionality in order to recover the correct output of the PRE and reconstruct the output , namely, it will recover the view of 
 for all . As part of the “MPC in the head” paradigm, the client and server jointly set up a watchlist (the views of some of the virtual servers) allowing the client to verify consistency between the virtual servers' views and the virtual clients' views. If the client found an inconsistency, it outputs 
 for some default value 
. However, it is unclear how to have the server send only some of the views according to the request of the client. Ishai et al. [20] handled this by letting the client get each view with some constant probability independently of the other views.

The security of the protocol as described so far can still be breached by a malicious server. By tampering with the outputs of the virtual clients, a malicious server could force the output of the real client to be  for some inputs y and force the output to be 
 for other values of y, where the choice is completely determined by the adversary. To overcome this problem, the function f is replaced with a function 
 where each bit 
 is replaced with κ random bits whose XOR equals to 
, where κ is the security parameter.4 This modification prevents the adversary from having complete control over which inputs the client will output 
, and for which inputs it will output .

Towards achieving perfect security.  Two problems arise when trying to use the IKOPS protocol to achieve perfect security. First, recall that the client will receive the view of each virtual server with constant probability independently of the other virtual views. As a result, a malicious client could potentially receive the views of all virtual servers and thus it could learn the server's input. Second, with some non-zero probability, a malicious server might still be able to have the client output be 
 for some inputs y, but output  for other inputs y. We next present a solution for each of the two issues.

Perfect security against a corrupted client.  We solve the former issue, by showing how the server and the client can sample a watchlist of a fixed the size. Ideally, we would like to have the client request exactly t views, where t bounds the number of corruptions allowed in the multiparty protocol Π. This requires the server and the client to be able to compute the functionality  
  with perfect security, where n denotes the number of virtual servers in Π and s denotes the length of their views. However, it is not known if implementing it in the OT-hybrid model with perfect security is even possible. Therefore, we slightly relax the security requirement, so that a malicious client will not be able to receive more than twice the number of views that an honest client receives. We then let the honest client ask for exactly  of the views. The idea in constructing such a watchlist is the following. For each view of a virtual server, the real server sends (via the OT functionality) either a masking of the view, or a share of the concatenation of the maskings. That is, the server's input to the OT5 is 
, where 
 is the view of the 
 virtual server, where 
 is a vector of random strings, and where  is the 
 share of r for some threshold secret sharing scheme with sufficiently large threshold value.6 As a result, in each invocation of the OT, the client will be able to learn either a masked view or a share, which bounds the number of views it can receive.

Perfect security against a corrupted server.  To solve the second issue, it will be convenient to present the server security requirement from a geometric point of view. To simplify the explanation in this introduction, we only focus on deterministic Boolean functions. Recall that we can view the function f as  points over 
, where the 
 coordinate of the 
 point is 
. Observe that all a simulator for a malicious server can do is to send a random input according to some distribution D. The goal of the simulator is to force the distribution of the client's output to be equivalent to the distribution in the real world. Thus, perfect simulation of a malicious server is possible if and only if there exists such distribution D over the server's inputs in the ideal world, such that for every input  of the client, 
, where 
 is the probability the client outputs 1 in the real world on input y. Observe that for every , the value 
 can be written as a convex combination7 of the points 
. Moreover, all of these convex combinations have the same coefficients. Thus, the point 
 lies inside the convex hull of the points of f. This results in an equivalent definition to state perfect security: simulation of an adversary is possible if and only if the vector of outputs 
 in the real world is in the convex-hull of the points in 
 described by f.

Now, consider the IKOPS protocol. It could be the case that an adversary causes the vector of outputs 
 to have different errors in each coordinate, hence the point is not necessarily inside the convex-hull of the points of f. To fix this issue, instead of having the client output according to a default value in case of an inconsistency, the client will now sample 
 uniformly at random and output 
. From a geometric perspective, it outputs 1 with probability 
, where c is the center of the polytope.8 We claim that if f is full-dimensional, then this results in a perfectly secure protocol. We next present a rough intuition. Let p denote the probability of detecting an inconsistency (more precisely, for each y the probability 
 of detecting an inconsistency is in , for some small ε). Further define the matrix 
 (i.e., each row of 
 describes a point in 
). Thus, the output vector of the client q is close to the point 
, give or take ±ε in each coordinate, for some small ε. If p is close to 1, this point q is close to c, and since c is an internal point, q is also internal for a sufficiently small ε. Otherwise, the point q will be close to the boundary. As a result, it is unclear as to why perfect security holds. Here, we utilize a special property of IKOPS protocol's security. We manage to prove that ε is bounded by 
, for some small 
 (independent of p). That is, ε depends on p, unlike the standard security requirement. This property allows us to prove that perfect security holds.

1.3. Related work
In the 2PC settings, Cleve [10] showed that the functionality of coin-tossing, where the parties output the same random bit, is impossible to compute with full-security, even in the OT-hybrid model. In spite of that, in the seminal work Gordon et al. [16], and later followed by [3], [26], [13], [4], it was discovered that in the OT-hybrid model, most two-party functionalities can be evaluated with full security by efficient protocols. In particular, [4] completes the characterization of symmetric Boolean functions (where both parties receive the same output). However, all known general protocols for such functionalities have round complexity that is super-logarithmic in the security parameter. Moreover, this was proven to be necessary for functions with embedded XOR [16].

1.4. Organization
In Section 2 we provide some notations and definitions that we use in this work, alongside some required mathematical background. Section 3 is dedicated to expressing security in geometrical terms and the formal statement of our result. In Sections 4 and 5 we present the proof of the main theorem. In Section 6 we show that the analysis of our protocol for Boolean functions is tight. Finally, in Section 7 we briefly discuss the efficiency of our construction.

2. Preliminaries
2.1. Notations
We use calligraphic letters to denote sets, uppercase for random variables and matrices, lowercase for values, and we use bold characters to denote vectors and points. All logarithms are in base 2. For , let . For a set  we write  to indicate that s is selected uniformly at random from . Given a random variable (or a distribution) X, we write  to indicate that x is selected according to X. We use poly to denote an unspecified polynomial, and we use polylog to denote an unspecified polylogarithmic function. For a randomized function (or an algorithm) f we write  to denote the random variable induced by the function on input x, and write  to denote the value when the randomness of f is fixed to r.

For a matrix 
, we let  be its 
 row, we let  be its 
 column, and we denote by 
 the transpose of M. For a pair of matrices 
, we denote by 
 the concatenation of 
 to the right of 
.

2.2. Cryptographic tools
Definition 2.1

The statistical distance between two finite random variables X and Y is
 
 

2.2.1. Secret sharing schemes
A -out-of-n secret-sharing scheme is a mechanism for sharing data among a set of parties 
, such that every set of size  can reconstruct the secret, while any smaller set knows nothing about the secret. As a convention, for a secret s and  we let  be the 
 share, namely, the share received by 
. In this work, we rely on Shamir's secret sharing scheme [30].

In a -out-of-n Shamir's secret sharing scheme over a field , where , a secret  is shared as follows: A polynomial  of degree at most  over  is picked uniformly at random, conditioned on . Each party 
, for , receives a share  (we abuse notation and let i be the element in  associated with 
).

2.2.2. Decomposable randomized encoding
We recall the definition of randomized encoding [34], [2]. They are known to exist unconditionally [17], [2].

Definition 2.2 Randomized encoding

Let 
 be some function. We say that a function 
 is a perfect randomized encoding (PRE) of f if the following holds.

Correctness:
There exists a decoding algorithm  such that for every 
 

Privacy:
There exists a randomized algorithm  such that for every 
 it holds that
 where .

Definition 2.3 Decomposable randomized encoding

For every 
, we write 
, where 
 is the 
 bit of x. A randomized encoding 
 is said to be decomposable if it can be written as
 where each 
, for , can be written as one of two vectors that depends on 
, i.e., we can write it as 
, where 
 depends on the randomness r.

2.3. Mathematical background
Definition 2.4 Convex combination and convex hull

Let 
 be a set of vectors. A convex combination is a linear combination 
 where 
 and 
 for all . The convex hull of , denoted
 
 
 is the set of all vectors that can be represented as a convex combination of the vectors in . For a matrix 
 we let 
.

Definition 2.5 Affine hull

For a set of vectors 
, we define their affine hull to be the set
 
 
 For a matrix 
 we let 
.

Definition 2.6 Affine independence

A set of points 
 is said to be affinely independent if whenever 
 and 
, then 
 for every . Observe that 
 are affinely independent if and only if 
 are linearly independent.

For a square matrix 
, we denote by  the determinant of M, and we denote by 
 the 'th cofactor of M, which is the  matrix obtained by removing the i'th row and j'th column of M. It is well known that:

Fact 2.7

Let 
 be an invertible matrix. Then for every  it holds that 
.

2.4. The model of computation
We follow the standard ideal vs. real paradigm for defining security. Intuitively, the security notion is defined by describing an ideal functionality, in which both the corrupted and non-corrupted parties interact with a trusted entity. A real world protocol is deemed secure if an adversary in the real world cannot cause more harm than an adversary in the ideal world. This is captured by showing that an ideal world adversary (simulator) can simulate the full view of the real world adversary.

We focus our attention on the client-server model. In this model a server  holds some input x and a client  holds some input y. At the end of the interaction the client learns the output of some function of x and y, while the server learns nothing. We further restrict ourselves to allow only a single round of interaction between the two parties, however, as only trivial functionalities are computable in this setting, the parties interact in the  model. We next formalize the interaction is done in this model.

2.4.1. The OT functionality
We start by formally defining the (family) of the OT functionality. The  
  functionality, is a two-party client-server functionality in which the server inputs a pair of bit-messages 
 and 
, and the client inputs a single bit b. The server receives ⊥ and the client receives 
. For every natural number , we define the functionality  
 
 as follows. Let 
 and let 
, where 
 for every i. We let 
. The functionality is then defined as . That is, it is the equivalent to computing  
  ℓ times in parallel. Finally, we let  
 
.

A generalization of  
  is the  
  functionality, which lets the client pick one out of n bits 
 supplied by the server, and on input  the client learns 
. This can be further generalized to  
  where the n bits are replaced by strings 
, and can be generalized even further to  
  where the input i of the client is replaced with k inputs 
, and it receives 
.

2.4.2. The 1-round  model
We next describe the execution in the 1-round  model. In the following we fix a (possibly randomized) client-server functionality . A protocol Π in the 1-round  model with security parameter κ, is a triple of randomized functions . The server and client use the function α and β respectively to obtain their inputs to the OT functionality. The client then computes the local function γ on its view to obtain an output. Formally, the computation is done as follows.

Inputs:
The server  holds input  and the client  holds input . In addition, both parties hold the security parameter 
.

Parties send inputs to the OT:
 samples  bits 
, and  samples  bits 
, for some  determined by the protocol.  and  send a and b to the OT functionality, respectively.  then receives  from the OT.

Outputs:
The server  outputs nothing, while the client  computes the local function 
 and outputs the result.

We refer to the  used in the protocol as the communication complexity (CC) of Π.

We consider an adversary  that controls a single party. The adversary has access to the full view of that party. We assume the adversary is malicious, that is, it may instruct the corrupted party to deviate from the protocol in any way it chooses. The adversary is non-uniform, and is given an auxiliary input . For simplicity we do not concern ourselves with the efficiency of the protocols or the adversaries, namely, we assume that the parties and the adversary are unbounded.

Fix inputs , , and . For an adversary  corrupting the server, we let

Image 1
denote the output of the client in a random execution of Π. For an adversary  corrupting the client, we let
Image 2
denote the adversary's view in a random execution of Π. This includes its input, auxiliary input, randomness, and the output received from the OT functionality.
2.4.3. The ideal model
We now describe the interaction in the ideal model, which specifies the requirements for fully secure computation of the function f with security parameter κ. Let  be an adversary in the ideal world, which is given an auxiliary input  and corrupts one of the parties.

2.4.4. The ideal model – full-security
Inputs:
The server  holds input  and the client  holds input . The adversary is given an auxiliary input 
⁎
 and the input of the corrupted party. The trusted party  holds 
.

Parties send inputs:
The honest party sends its input to . The adversary sends a value w from its domain as the input for corrupted party.

The trusted party performs computation:
 selects a random string r and computes  if  is corrupted and computes  if  is corrupted.  then sends z to  (which is also given to  in case  is corrupted).

Outputs:
An honest server outputs nothing, an honest client output z, and the malicious party outputs nothing. The adversary outputs some function of its view.

Fix inputs , , and . For an adversary  corrupting the server we let

Image 3
denote the output of the client in a random execution of the above ideal world process. For an adversary  corrupting the client we let
Image 4
be the view description being the output of  in such a process.
We next present the definition for security against malicious adversaries. The definition we present is tailored to the setting of the 1-round two-party client-server in the  model.

Definition 2.8 Malicious security

Let  be a protocol for computing f in the 1-round  model. Let  be a positive function of the security parameter.

1.
Correctness: We say that Π is correct if for all , , and 
 Here, 
, 
 and the probability is taken over the random coins of α, β, γ, and f.

2.
Server security: We say that Π is ε-server secure, if for any non-uniform adversary  corrupting the server in the  world, there exists a non-uniform adversary 
 (called the simulator) corrupting the server in the ideal world, such that We say that Π has perfect server security if it is 0-server secure.

3.
Client security: We say that Π is ε-client secure, if for any non-uniform adversary  corrupting the client in the  world, there exists a non-uniform simulator 
 corrupting the client in the ideal world, such that We say that Π has perfect client security if it is 0-client secure.

We say that Π computes f with ε-statistical full-security, if Π is correct, is ε-server secure, and is ε-client secure. Finally, we say that Π computes f with perfect full-security, if it computes f with 0-statistical full-security.

To alleviate notation, from now on we will completely remove 
 from the input to the functions α, β, and γ, and remove κ from ℓ and ε. Statistical security will now be stated as a function of ε and the CC of the protocol as a function of ℓ. Observe that aborts in this model are irrelevant. Indeed, an honest server outputs nothing, and if a malicious server aborts then the client can output 
 for some default value 
, which can be perfectly simulated. Therefore, throughout the paper we assume without loss of generality that the adversary does not abort the execution.

In our construction, we also use the notion of security with input-dependent abort [20]. Generally, it is a relaxation of the standard full-security notion, which allows an adversary to learn at most 1 bit of information by causing the protocol to abort, depending on the other party's input. We next state the perfect security variant of the notion. Furthermore, the security notion is written with respect to only a malicious server. Since we work in the client-server model, the trusted party does not send to the server any output. Therefore, in this relaxation selective abort attacks [23], [24] are simulatable.

Definition 2.9 Input-dependent server security

Fix . In the input-dependent model, we modify the ideal world so that the malicious adversary corrupting the server, in addition to sending an input 
⁎
, also gives the trusted party  a predicate .  then sends to the client 
⁎
 if , and ⊥ otherwise. We let

Image 7
denote the output of the client in a random execution of the above ideal world process, with  corrupting the server.
Let Π be a protocol that computes f in the 1-round  model. We say that Π has perfect input-dependent server security, if for every non-uniform adversary  corrupting the server in the  world, there exists a non-uniform adversary 
 corrupting the server in the input-dependent ideal world, such that for all , , and 
⁎
 it holds that

3. A class of perfectly computable client-server functions
In this section, we state the main result of this paper – presenting a large class of two-party client-server functions that are computable with perfect security. We start with presenting a geometric view of security in our model. We take a similar approach to that of [3] to representing the server-security requirement geometrically.

3.1. A geometrical representation of the security requirements
Boolean functions.  We start with giving the details for (randomized) Boolean functions. For any function  we associate an  matrix 
 defined as 
, where the probability is taken over f's random coins (if f is deterministic, then this value is Boolean). Let 
. Observe that in the ideal world, every strategy that is employed by a simulator corrupting the server can be encoded with a probability vector 
, where 
 corresponds to the probability of sending 
 to . Therefore, if the input of the client is y, then the probability that the output is 1, equals to 
. On the other hand, in the 1-round  model, a malicious server can only choose a string 
⁎
, where ℓ is the CC of the protocol , and send it to the OT functionality. Then on input , the probability the client outputs 1 is exactly
⁎
⁎
 where  and the probability is over the randomness of β and γ. This implies that an ideal world simulator must send a random input 
⁎
 such that the client will output 1 with probability 
⁎
. Thus, perfect security against a corrupted server holds if and only if for every 
⁎
 there exists a probability vector 
 such that for every 
⁎
 Equivalently, for every 
⁎
 the vector 
⁎
⁎
 is inside the convex-hull of the rows of 
. Furthermore, observe that this holds true regardless of the auxiliary input held by a corrupt server.

General functions.  We now extend the above discussion to non-Boolean functions. For every function , and every possible output , we associate an  matrix 
 defined as 
. Similarly to the Boolean case, in the ideal world, every strategy that is employed by a corrupt server can be encoded with a probability vector 
, hence the probability that the client will output z, on input y, is 
. In the 1-round  model, for a string 
⁎
 chosen by a malicious server, the probability to output z equals to
⁎
⁎
 where  and the probability is over the randomness of β and γ. Therefore, perfect security against a corrupted server holds if and only if for every 
⁎
 there exists a probability vector 
 such that for every  and for every (1)
⁎
 Observe that since p is a probability vector and since 
 is the all-one matrix, it is equivalent to consider only  possible values for z instead of all k values considered in Equation (1). This allows us to write the above formulation more succinctly.

Let 
 be the concatenation of the matrices by columns, and let 
⁎
⁎
. Then Equation (1) is equivalent to saying that for every 
⁎
 the vector 
⁎
 belongs to the convex-hull of the rows of 
. It will be convenient to index the columns of 
 with , i.e., we let 
.9 We now have an equivalent definition of perfect server security.

Lemma 3.1

Let Π be a protocol for computing some function  in the 1-round  model with CC of ℓ. Then Π has perfect server security if and only if for every 
⁎
 it holds that
⁎

We next describe another security notion against a corrupt server. Intuitively, it states that for a malicious server, the less it deviates from the prescribed protocol, the better it can be simulated. Moreover, instead of using the traditional 
 distance (i.e., statistical distance) we phrase the security in terms of the 
 norm. This, somewhat non-standard definition will later act as a sufficient condition for reducing perfect server-security to perfect client-security.

Definition 3.2

Let , satisfy  if and only if . Let  be a protocol for computing f in the 1-round  model. We say that Π is strong ε-server secure10 if the following holds. For every message 
⁎
 sent by a malicious server in the  world, there exists a probability vector 
 such that
⁎

3.2. Stating the main result
With the above representation in mind, we are now ready to state our main result. We first recall the definition of a full-dimensional function, as stated in [3].

Definition 3.3 Full-dimensional function

We say that a function  is full-dimensional if
 That is, the affine-hull defined by the rows of 
 spans the entire vector space.

Recall that a basis for an affine space of dimension n has cardinality . Therefore for full-dimensional functions it must holds that . We are now ready to state our main result.

Theorem 3.4

Let  be a full-dimensional function. Then there exists a protocol Π in the 1-round  model, that computes f with perfect full-security. Furthermore, if f is deterministic the CC is the following. Let 
 denote the size of the smallest formula for evaluating the i'th bit of , and let 
. Then Π has CC at most
 where 
 is some global constant independent of the function f.

Although the communication complexity of our protocol is roughly , for functions with small client-domain, it does yield a concrete improvement upon known protocols such as the protocol proposed by [20] (see Section 7 for more details).

A simple corollary of Theorem 3.4 is that for a full-dimensional functions, adding to client inputs that fixes the output, results in a function that can still be computed with perfect security.

Corollary 3.5

Let  be some function. Assume that there exists a subset 
 that fixes the output distribution of f, i.e., for all 
 there exists a distribution 
 over  such that 
 for every . If the function 
, defined as 
, is full-dimensional, then f can be computed the 1-round  model with perfect full-security and with the same communication complexity as 
.

Proof

Let Π be the protocol for 
 guaranteed by Theorem 3.4. Then the parties computes f as follows.  act the same as in Π. If the input of  is 
, then  samples from 
 and outputs the result, and if its input is 
, then  acts the same as in Π. □

Many interesting examples of functionalities that satisfy the constraints in Theorem 3.4 and Corollary 3.5 exist. The following are two example for such functionalities.

Yao's millionaires' problem:
The server and the client each hold a number from 1 to n. The output is 1 if and only if the client's input is larger than or equal to the server's input. The matrix for this function has a constant column of 1's. After removing it, the last row of the matrix will be the all 0 vector and the other rows are linearly independent, therefore the resulting function is full-dimensional. Hence the function satisfies the constraints in Corollary 3.5.

Set membership:
The server holds a subset  of some finite universe Ω, and the client holds an element . The client wishes to know if . The matrix for this function contains all possible Boolean vectors of length , hence the function is full-dimensional.

Theorem 3.4 clearly follows from the following two lemmata. The first lemma reduces the problem of constructing a perfectly secure protocol, to the task of constructing a protocol with perfect client security and strong statistical server security (as in Definition 3.2). The second lemma states that such a protocol exists.

Lemma 3.6

Let  be some function. Define the function  as  if  and , for every . Assume that for every , there exists a protocol 
 in the 1-round  model that computes g with correctness, is strong ε-server secure, and has CC at most . Then, if f is full-dimensional, there exists a protocol 
 in the 1-round  model, that computes f with perfect full-security. Moreover, if f is deterministic then 
 has CC at most
 
 where . Moreover, if 
 has perfect client security then so does 
.

Lemma 3.7

Let  be a function satisfying  if and only if . Then for every , there exists a protocol 
 in the 1-round  model that computes g with correctness, is strong ε-server secure, and has perfect client security. Furthermore, its communication complexity is the following. Let 
 denote the size of the smallest formula for evaluating the 
 bit of , and let 
. Then 
 has CC at most
 where 
 is some global constant independent of the function g and of ε.

We prove Lemma 3.6 in Section 4 and we prove Lemma 3.7 in Section 5.

4. Reducing perfect server security to strong server security
In this section, we reduce the problem of constructing a perfectly secure protocol, to the problem of constructing a protocol that has strong statistical server security. The idea is to wrap the given protocol for computing g, so that whenever the output of 
 is ⊥ (for small enough ε), the client will choose 
 at random and output 
. Stated from a geometric point of view, the client outputs according to a distribution that is consistent with the center of the convex-hull of the rows of 
 (we stress that any point that is strictly inside the convex-hull would suffice). We then show that, with a certain probability, the vector of outputs is distributed according a “correct” output distribution, namely according to a distribution consistent with the rows of 
, and with the complement probability, it lies somewhere inside a small hypercube located around the center. Therefore the final vector of outputs is inside some hypercube that is around some point inside the convex-hull. The size of the hypercube is proportional to the security of 
, hence by choosing a sufficiently small ε, the entire hypercube is also inside the convex-hull, thus completing the proof. We next formalize this intuition.

Proof of Lemma 3.6

It is easy to see that if the probability that the output of 
 equals ⊥ is 0 for every  for some , then 
 computes f with perfect security.

Assume otherwise, and denote . Since f is full-dimensional there exists a subset 
 of the rows of 
, that are affinely independent. Let 
 be the vector associated with uniform distribution over  (i.e., 
 if  and 
 otherwise), and let 
 be the center of the simplex11 defined by the points in . Observe that for every  it holds that 
. Indeed, recall that 
 is the all-one matrix, and c is defined as the convex combination of the rows of 
. The protocol 
 is described as follows.

Image 9
Protocol 4.1

Input: Server  has input  and client  has input .

1.
The parties execute protocol 
 with a sufficiently small  to be determined by the analysis. Let z be the output  receive.

2.
If , then  output z. Otherwise, output 
 with probability 
 (and output 0 with the complement probability).

Image 10
Correctness follows from the fact that 
 is correct. It remains to show that perfect server-security holds. Moreover, if 
 has perfect client security, then by the fact that no further interaction is made, so does 
.

We next show that 
 has perfect server security. Recall that for a protocol  with CC ℓ, for 
⁎
, for , and for  we let
⁎
⁎
 where  and the probability is over the randomness of β and γ. By Lemma 3.1, it suffices to show that for every 
⁎
 sent to the OT by a malicious server, it holds that(2)
⁎
 Fix 
⁎
. For brevity, we write 
 and 
 instead of 
⁎
 and 
⁎
 respectively. Since 
 is strong ε-server secure, it follows that there exists a probability vector 
 such that(3)
 where 
 satisfies 
. Let 
 be the vector p with 
 removed. We first show that Equation (2) follows from the following two claims.

Claim 4.2

There exists a vector 
 satisfying 
, such that

Claim 4.3

There exists a sufficiently small  such that
 where 
 is the same as in Claim 4.2.

Indeed, by Claim 4.3 there exists a probability vector 
 such that
 Then by Claim 4.2 it follows that
 Recall that the entries of 
 sum up to 
. Therefore 
 is a probability vector, hence Equation (2) holds. □
We next prove Claim 4.2 and Claim 4.3.

Proof of Claim 4.2

Let 
 
. Observe that for every  and  it holds that
 where the first equality is by the description of 
, the second is by Equation (3), and the third follows from the definition of g. Define the vector 
 as follows. For every  and  let 
. Then
 To conclude the proof, we upper-bound 
. Observe that
 
 □

Proof of Claim 4.3

One approach would be to use similar techniques as in [3], namely, take a “small enough” Euclidean ball around c and take ε to be small enough so that 
 is contained inside the ball. This approach, however, only proves the existence of such an ε. We take a slightly different approach, which would also provide an explicit upper bound on ε for deterministic functions.

For every  let 
, let 
 
 be a basis for 
, and let 
 be the corresponding change of basis matrix. Then(4)
 
 
 
 
 

Observe that a point v is in the convex-hull of  if and only if it can be written as 
, where the 
's are non-negative real numbers that sum up to at most 1. Indeed, we can write
 
 
 
 Next, as 
 
 forms a basis, there exists a vector 
 such that 
. Then, if 
 
, by Equation (4) it follows that
 
 
 where 
 for every , implying that the point is inside . Thus, it suffices to find ε for which 
 
. It holds that
 
 
 
 
 
 
 
 
 where the third equality is by Fact 2.7, and the second inequality is due to the fact that each entry in A is a real number between -1 and 1. Therefore, by taking 
 
 the claim follows. Observe that if the function f is deterministic, then the entries of A are in  implying that , and hence taking 
 
 suffices. Therefore the communication complexity will be at most 
 
 in this case. □

5. A statistically secure protocol with strong server security
In this section we fix a function  satisfying  if and only if . We show how to construct a protocol for computing the function g in the 1-round  model. The protocol we construct has perfect client security, and has strong statistical server security. Our protocol is a modified version of the protocol by Ishai et al. [20], which we shall next give an overview of. Their protocol is parametrized with ε, and we denote this protocol by 
. It is a single round protocol in the  model, that has ε-statistical full-security. It is stated for functions computable by 
 circuits, however, this is only done for efficiency reasons, which is not a concern in our paper. We therefore restate it for general functions, and bound its communication complexity as a function of , , and k (which are assumed to be finite in our work).

5.1. The IKOPS protocol
We next give the rough idea of 
. First, we view the inputs x and y as a binary strings.12 The main idea behind the 
 is to have the server run an “MPC in the head” [19]. That is, the (real) server locally emulates the execution of a perfectly secure multiparty protocol Π with many virtual servers performing the computation, and 2m virtual clients, denoted 
, receiving output, where m is the number of bits in the client's input y. The underlying protocol Π computes a decomposable PRE 
 of g. Specifically, the output of client 
 in an execution of Π is the corresponds to the 
 bit of y, when the bit equals to b.

The real client can then use the available OT in order to recover the correct output of the PRE and reconstruct the output . As part of the “MPC in the head” paradigm, the client further ask the server to send a watchlist (the views of some of the virtual servers) and check consistency. If there was an inconsistency, then the client outputs ⊥. To make sure that the client will not receive too large of a watchlist and break the privacy requirement, it will get each view with some (constant) probability independently of the other views.

Observe that although the client can use OT in order to receive the correct output from the virtual clients, the two real parties need to use string-OT, while they only have access to bit-OT. This technicality can be overcome using the perfect reduction from  
  to OT that was put forward in the elegant work of Brassard et al. [9], which also constitutes one of the few examples of perfect reductions to  
  known so far. They proved the following theorem.

Theorem 5.1

There exists a protocol 
 in the 1-round  world that computes  
  with perfect full-security. Furthermore, its communication complexity is at most .

The security of the protocol described so far can still be breached by a malicious server. By tampering with the outputs of the virtual clients, a malicious server could force the output of the real client to be  for some inputs y and force the output to be ⊥ for other values of y, where the choice is completely determined by the adversary. To overcome this problem, we replace g with a function 
 where each bit 
 is replaced with 
 random bit whose XOR equals to 
, for some large 
.13 Here, the adversary does not have complete control over which inputs the client will output ⊥, and for which inputs it will output . We next describe the protocol formally. We start with some notations.

Notations.  Throughout the following section, client's input are now binary strings y of length m. Let 
 and let 
 be a randomized function that on input m bits 
, outputs 
 random bits 
 conditioned on 
 for every . We also let 
 be the inverse of , namely,
 Finally, we let 
 be defined as
 and let 
 be a decomposable PRE of 
.

Image 9
Protocol 5.2

Input: Server has input  and client has input 
.

•
:

1.
The server  runs “MPC in the head” for the following functionality. There are 
 virtual servers 
 with inputs and 
 virtual clients 
 receiving outputs. Each virtual server holds a share of the 's input and randomness, where the shares are in an n-out-of-n secret sharing scheme. Each virtual client 
 will receive 
, namely, it will receive the 
 component of the decomposable PRE where the first part of the input is fixed to x. In addition every virtual client will hold 
 which is the value of 
 that depends only on x and the randomness.

2.
The virtual parties execute a multiparty protocol in order to compute 
. The protocol used has perfect full-security tolerating  corrupted virtual servers and any number of corrupted virtual clients. We also assume that the virtual clients receive messages at the last round of the protocol. (e.g., the BGW protocol [8]).

3.
Let 
 be the view of 
, and let 
.

4.
Let 
 denote the view of 
. For each  the server prepares a collection of strings 
 of length , where 
 is located in a randomly chosen entry of 
, while the other entries are ⊥ (this allows the server to send each 
 with probability ). Let 
.

5.
Output 
.

•
:

1.
The client computes 
.

2.
Let 
.

3.
Let 
 (i.e., a constant vector of length ).

4.
Output 
.

•
:

1.
Let 
.14 Write 
, where 
 corresponds to the outputs of the virtual clients and 
 corresponds to the watchlist being the views of a subset of the virtual servers.

2.
For every 
 in 
, we may write without loss of generality that 
, where 
 is the (only) message that 
 sent to 
.

3.
If there exists 
, or 
 and 
 that are inconsistent, output ⊥.

4.
Otherwise, apply the PRE decoder on 
 to recover the output z.

Image 10
We summarize the properties of the protocol below.

Theorem 5.3

[20, Theorem 1]
For every , 
 computes g with ε-statistical full security.15 Furthermore, using the PRE from [17], [2] and the BGW protocol, the CC will be the following. Let 
 denote the size of the smallest formula for evaluating the i'th bit of , and let 
. Then, 
 has CC at most
 where 
 is some global constant independent of the function g and of ε.

Observe that 
 has a (small) non-zero probability of the client seeing too many views of the virtual servers (in the worst case all of them which gives him the knowledge of x). Thus, 
 is not perfectly client secure.

In the following section, we slightly tweak 
, making the watchlists of a fixed size in a such a way that no malicious client will be able to receive  of the virtual servers' views, thereby making it perfectly client secure. The new protocol will have the desired properties as stated in Lemma 3.7.

5.2. Setting up a fixed-size watchlist
Recall the problem with client privacy was in the fact that the client may watch the internal state of too many servers, breaching perfect security of the protocol 
, and thus of the entire construction. To solve this problem, we replace the current watchlist setup with a fixed-size watchlist setup.

Ideally, in order to achieve the fixed-size watchlist, the parties could use a perfectly secure protocol for computing  
 . Unfortunately, we do not know, if such a protocol even exists in the  model. Instead, we slightly relax the security notion, so that we will be able to construct the protocol, and its security guarantees still suffice for the main protocol. Specifically, we show how in the  model, the parties can compute  
  in a single round, so that a malicious client will only be able to learn at most t strings rather than . We stress that the construction we suggest does not achieve perfect server security. Instead, it admits perfect input-dependent security. That is, the server may choose a subset of the client's inputs (to  
 ), that will cause the protocol to abort. As we show in Section 5.3, this will not affect the security properties of our final construction, since in this case the client will know the server is corrupted.

Let  where , and . For simplicity, we assume that t is even. Let 
 and 
 be the  
  and  
  functionalities respectively. We next briefly explain the ideas behind the construction. The parties will use protocol 
 in order to simulate computation of n instances of  
  in parallel. On input 
, where each 
, the 
 pair of strings the server will send (by first applying 
) will be masking of the 
 string 
, and a Shamir share of the concatenation of all of the maskings, that is, the pair will be 
, where 
 is a uniformly chosen random string of length 
. The client will then recover the maskings of the correct outputs alongside the shares, which will help him to reconstruct the outputs. Since for each i the client will learn either a share or a masked string, a malicious client will not be able to learn to many masked strings. The protocol 
 for computing 
 in the 1-round  model is formally described as follows.

Construction 5.4

Input: Server  holds 
, and client  holds 
.

•
: Sample n random strings 
 uniformly at random and independently. For every , let 
 be the 
 share of 
 in an -out-of-n Shamir's secret sharing (we pad  if needed). Output 
 (the 
's are also padded accordingly).

•
: Output 
, where 
 if  and 
 otherwise.

•
: Let 
, let 
, and let 
. If the elements in 
 agree on a common secret 
, then output 
. Otherwise output ⊥.

Lemma 5.5

 computes 
 with CC at most 
 and with the following properties:

•
 is correct.

•
 has perfect input-dependent server security.

•
For any non-uniform adversary  corrupting the client in the  world, there exists a non-uniform simulator 
 corrupting the client in the ideal world of 
, such that for all 
,  of size , and 
⁎
 it holds that In other words, although the simulator receives  indexes as input, it is allowed to ask the trusted party for t strings from the server's input.

Intuitively, a malicious server cannot force the client to reconstruct two different secrets r for two different inputs. This is due to the fact that for every two different inputs the set of common 
's that are 1 (i.e., the number of common shares the client will receive for both inputs) is of size at least . This implies that up to a certain set of client-inputs that the adversary can choose, the client will receive a correct output. As for a malicious client, observe that it can ask for at most t masked values, as otherwise it will not have enough shares to recover the secret r.

We next incorporate 
 into 
 to get a protocol that is perfectly client-secure. The proof of Lemma 5.5 is deferred to Section 5.4.

5.3. Upgrading the IKOPS protocol
We are finally ready to prove Lemma 3.7. As stated in Section 5.2, we replace the randomly chosen watchlist with a fixed-size one using 
. Formally, the protocol, denoted 
, is described as follows.

Image 9
Protocol 5.6

Input: Server has input  and client has input 
.

•
: Output 
 as in 
, with the exception of 
 being equal to 
 (recall that 
 is the view of the virtual server 
).

•
: Output 
 as in 
, with the exception of 
 being equal to 
, where  is of size  chosen uniformly at random (recall that  bounds the number of corrupted parties in the MPC protocol).

•
: Output same as 
, with the exception that we apply 
 to recover the outputs and watchlist.

Image 10
Clearly, Lemma 3.7 follows from the following lemma, asserting the security of 
.

Lemma 5.7

For every , 
 computes g with correctness, it is strong ε-server secure, and has perfect client security. Furthermore, using the PRE from [17], [2] and the BGW protocol, the CC will be the following. Let 
 denote the size of the smallest formula for evaluating the i'th bit of , and let 
. Then, 
 has CC at most
 where 
 is some global constant independent of the function and of ε. In comparison to 
, the only difference in the CC is in the constant and the exponent of 
 taken. Specifically, it holds that
 
 

Proof

Correctness trivially holds. We next prove that the protocol is strong ε-server secure. Consider a message 
⁎
 sent by a malicious server holding  and an auxiliary input 
⁎
 in the  world. We need to show the existence of a certain probability vector 
 satisfying the constraints given in Definition 3.2. It will be convenient to describe the vector p using a simulator  that will describe the probability of sending 
⁎
 to  as an input.

The idea is to have the simulator check the inconsistencies made by the adversary. This is done via an inconsistency graph, where each vertex corresponds to a virtual party, and each edge corresponds to an inconsistency between the corresponding pair of parties. There are three cases in which the simulator will send ⊥ to . The first case is when there is a large vertex cover among the servers. Observe that in this case, in the  world the client will see an inconsistency with high probability, and hence it will output ⊥. The second case is when there are two virtual clients 
 and 
, corresponding to the same bit of  that are both inconsistent with the same server. Observe that the real client will always see an inconsistency, regardless of its input or randomness. The final case remaining, is when for each 
, the adversary tampered with exactly one of 
 or 
. Here the real client will not notice the inconsistency only in the case where it asked for the virtual clients the adversary did not tamper with, which happens with low probability. For all other cases, the probability that the real client will see an inconsistency is independent of its input. Therefore the simulator can compute it and send ⊥ with this probability. When the simulator does not send ⊥ as its input, it uses the MPC simulator to reconstruct an input for the server and sends it to the trusted party.

We next formalize the description of the simulator. The simulator holds 
⁎
 and  as input.

1.
Write 
⁎
⁎
⁎
, where 
⁎
 corresponds to the outputs of the virtual clients and 
⁎
 corresponds to the watchlist being the views of the virtual servers.

2.
Apply the simulator guaranteed by the security of 
 to each pair of messages in 
⁎
 to obtain 
, and apply the simulator guaranteed by 
 for each pair in 
⁎
 to obtain 
 and a predicate P (if the output of the simulator is ⊥ instead of views, then send ⊥ to  and halt).

3.
Generate an inconsistency graph 
, with  as vertices, and where 
 is an edge if and only if 
 and 
 are inconsistent. Let  be a minimum vertex cover of 
.16 If  then send ⊥ to .

4.
Otherwise, pick a subset  of size  uniformly at random. If there exist 
 with an edge between them in G or , then send ⊥ to .

5.
Otherwise, extend 
 into an inconsistency graph G, where there are new vertices 
, and  is an edge if and only if 
 is inconsistent with 
 (i.e., the view 
 received from 
 is inconsistent with the view of 
).

6.
If there exists  and  such that either

•
both 
 and 
 are edges in G for some 
, or

•
for every 
, exactly one of 
 and 
 is an edge

then send ⊥ to .
7.
Otherwise, send ⊥ with probability 
, where e is the number of edges of the form 
, where , , 
, and . With the complement probability, apply the (malicious) MPC simulator on the virtual servers 
, where , to get an input for each of virtual servers in . The simulator  can then use the inputs of the other virtual servers to get an input 
⁎
, and send it to .

The vector p is then defined as 
⁎
⁎
. Recall that for every  and  we denote
⁎
⁎
 where  and the probability is over the randomness of β and γ. To alleviate notations, we will write 
⁎
. Fix 
 and . We show that17(5)

Observe that since both 
 and 
 have perfect server-security, each 
 and each 
 in the  world is distributed exactly the same as its counterpart in the ideal world. Therefore, we may condition on the event that they are the same. Furthermore, by the security of 
, we may also assume that the watchlist  is distributed the same, and that , as otherwise in both worlds the client will output ⊥. In the following we fix the views and . We next separate into three cases, stated in the following claims (proven below). These claims together immediately imply Equation (5).

Claim 5.8

If  then Equation (5) holds.

Claim 5.9

Assume that  and that for every  and every , there exists 
 such that either both 
 and 
 are consistent with 
, or both are inconsistent with 
. Then Equation (5) holds. Moreover, the simulation is perfect.

Claim 5.10

Assume that  and that there exists  and , such that for every 
 exactly one of the views 
 and 
 is inconsistent with 
, then Equation (5) holds.

Proof of Claim 5.8

Intuitively, the vertex cover of the graph G gives us information on which servers “misbehaved”. A large vertex cover means that a lot of servers have inconsistent views, implying that there are many edges in the graph. Therefore, a random subset of the vertices would contain at least one edge with high probability. We next formalize this intuition.

Since  then the maximum matching in 
 is of size at least . Therefore, in the  world, the expected number of edges that the client will have in its watchlist is at least
 
 
 
 
 By applying Hoeffding's inequality,18 with probability at least 
 the client will output ⊥. As in the ideal world the simulator sends ⊥ to  with probability 1, Equation (5) follows. □

Proof of Claim 5.9

We separate into two cases. For the first case, assume that there exist , , and 
 such that both 
 and 
 are inconsistent with 
. Then the simulator always sends ⊥ in this case. Furthermore, in the  world, for every input 
 the client will see an inconsistency between either 
 and 
, or between 
 and 
. Thus, Equation (5) holds with no error.

By the assumptions of the claim, for the second case we may assume that for every  and every , there exists 
 such that both 
 and 
 are consistent with 
. In this case, in the  world, the client will see an inconsistency with probability 
. With the complement probability, its output is determined by whatever the virtual servers computed. On the other hand, the output of the client in the ideal world is either ⊥ with probability 
 or it is determined by the MPC simulator. Since it is assumed to be perfect and  bound from above the number of corrupted servers, it follows that Equation (5) holds with no error. □

Proof of Claim 5.10

By construction, the ideal world simulator always sends ⊥ in this case, i.e., 
. Additionally, in the  world, the client uses  on its input y to receive 
 random bits 
 conditioned on 
 for every . Since we assume that exactly 
 virtual clients, corresponding to the same input bit 
, where tampered by the adversary, it follows that with probability 
 the client will see only consistent views. Therefore, for every 
 it holds that
⁎
 and for every 
⁎
 Equation (5) follows. □

We next show that the protocol has perfect client-security. Consider an adversary  corrupting the client. We construct the simulator 
. The construction of the simulator is done in the natural way, namely, it will apply the simulators of 
 and 
, and then the decoding of the PRE, to receive an output. It can then use the MPC simulator to simulate the views of the virtual servers in its watchlist. Formally, the simulator operates as follows.

1.
On input 
 and auxiliary input 
⁎
, query  to receive a message 
⁎
 to be sent to the OT.

2.
Write 
⁎
⁎
⁎
, where 
⁎
 corresponds to the outputs and 
⁎
 corresponds to the watchlist.

3.
Apply the simulator guaranteed by the security of 
 to each pair of messages in 
⁎
 to obtain 
 for some 
, and apply the simulator 
, guaranteed by the security of 
, for each pair in 
⁎
 to obtain a set .

4.
Send 
 to  to obtain an output z.

5.
Apply the PRE simulator on z to obtain outputs 
 for each virtual client.

6.
If  then output 
 alongside whatever 
 outputs and halt.

7.
Otherwise, apply the (semi-honest) MPC simulator for the parties 
 with random strings as inputs, and on 
 with 
 as the output respectively. Send the output of the MPC simulator to 
, outputs whatever it outputs and halt.

The security of 
 and 
 implies that 
 and  are distributed exactly the same in both worlds. Therefore, the output 
 is distributed the same, hence applying the PRE simulator on z will also result in the same distribution. Now, if  then 
 is guaranteed to produce a correct view as an output. If , then the MPC simulator will perfectly generate  virtual views. Handing them over to 
 would result in the view that is distributed the same as in the  world. □

5.4. Proof of Lemma 5.5
We first prove the following simple claim, stating that the client will always reconstruct a unique secret (if its not outputting ⊥).

Claim 5.11

Consider a message 
⁎
⁎
⁎
⁎
⁎
 sent to the OT by a malicious server. Then for any different inputs 
 for the client, either it will output ⊥ for at least one of the inputs, or there exists a common secret r that will be reconstructed for both inputs.

Proof

Let 
 be the set of all indexes not chosen by both inputs. Observe that for every , for both inputs the client will receive the string 
⁎
 which corresponds to a share. Then , hence the client can reconstruct a secret r in case these share are consistent. Therefore the secret will be the same for both 
 and 
. □

We now prove the lemma.

Proof of Lemma 5.5

By construction, it is not hard to see that the protocol is correct. We next prove that the protocol has perfect input-dependent security. Consider an adversary  corrupting the server. We construct a simulator 
 as follows.

1.
On input x and auxiliary input 
⁎
, query  to receive the message
⁎
⁎
⁎
⁎
⁎
 it sends to the OT functionality.

2.
If there are no  shares from 
⁎
 that are consistent, then send the constant 1 predicate alongside some arbitrary input 
 to the trusted party  (i.e., fix the output of the client to ⊥).

3.
Otherwise, let  be the maximum set of indexes  such that the 
⁎
 are shares consistent with single value 
.

4.
Send to  the input 
⁎
 alongside the predicate 
 defined as 
 if and only if .

To see why the simulator works, observe that 
 sends constant 1 predicate if and only if  sent at most t consistent shares, forcing the client to output ⊥ in the ideal world. Since this happens if there are too many inconsistencies,  will output ⊥ in the  world as well. Furthermore, if there are at least  shares that are consistent, then by Claim 5.11, there is a unique secret r that can be reconstructed. Therefore, in the  world, on input y,  will output ⊥ if , and output 
⁎
 otherwise. As  was chosen to be the maximum set of indexes, the same holds in the input-dependent ideal world.

We next show that the relaxed security requirement against malicious clients holds. Let  be an adversary corrupting the client. The simulator 
 works as follows.

1.
On input y and auxiliary input 
⁎
, query  to receive the message 
⁎
 it sends to the OT functionality.

2.
If there are strictly more than t 0's in 
⁎
 then output n random strings, each of length s.

3.
Otherwise, send 
⁎
 to  to receive the output 
⁎
.

4.
Sample n random strings 
, and for every  let 
 be a share of 
 in an -out-of-n Shamir's secret sharing (pad  if needed).

5.
Generate the values
⁎
⁎
 where each 
 is padded accordingly.

6.
Compute and output 
 
⁎
⁎

 works since in the case where there are more than t 0's in 
⁎
, by the properties the secret sharing scheme, the view of  in the  world consist only of random values. Otherwise,  will receive the masked 
 for the indexes i on which 
⁎
, and shares of the maskings for the indexes i on which 
⁎
. □

6. Tightness of the analysis
Recall that our final protocol is a “wrapper” for an upgraded version of the protocol by Ishai et al. [20], namely, protocol 
 from Section 5.3. In the following section, we prove that for any (randomized) Boolean function f that is not full-dimensional, and does not satisfy the constraints in Corollary 3.5, no “wrapper” protocol for 
 will compute f with perfect full-security. Here, the “wrapper” protocol simply replaces the output ⊥ that the client receive from 
 with a random bit. Formally, any “wrapper” protocol is parametrized with a probability vector 
 and an , and is denoted as 
. Let  be defined as  if  and . The “wrapper” protocol 
 is described as follows.

Image 9
Protocol 6.1

Input: Server  has input  and client  has input .

1.
The parties execute protocol 
 in order to compute g. Let z be the output  receive.

2.
If , then  output z. Otherwise, output 1 with probability 
.

Image 10
We next claim that the protocol cannot compute Boolean functions that are not full-dimensional with perfect full-security.

Theorem 6.2

Let  denote a (possibly randomized) Boolean function that has no constant columns, i.e., 
 is not constant for every , and is not full-dimensional, i.e., 
. Then for every 
 and every , 
 does not compute f with perfect server-security.

Proof

Assume towards contradiction that 
 has perfect server-security, for some v and ε. We next construct  adversaries, such that each adversary forces the vector of outputs of the client 
, to be a different point inside the convex-hull of the rows of 
. We then show that these points are affinely independent, giving us a contradiction. First, write each input of the client as a binary string y of length m. For every  define the adversary 
 as follows.

1.
Fix an encoding 
, and fix some 
⁎
 such that 
⁎
. (such an 
⁎
 exists, since 
 does not have constant columns).

2.
Execute 
 honestly with input 
⁎
, as fixed above, with the following one exception: for every , , and 
, modify 
 such that it is inconsistent with 
.

Finally, define the adversary 
 who picks an arbitrary 
⁎
 as an input, and acts honestly with the exception that it tampers with all 
's, making them inconsistent with the corresponding 
. Let 
⁎
⁎
 be the message 
 sends to the OT.

Let us analyze the client's vector of outputs 
⁎
⁎
, for any adversary 
, for . For brevity, we will write 
⁎
 instead. By definition, 
 forces the client to sample its output according to v, hence 
⁎
. Next, fix . Observe that for every 
, any of their encodings will differ on at least one bit, i.e., 
 for some  and 
, hence on input 
, the client will see 
 for every i. Since the inconsistency is made with every virtual server, on input 
, the client will notice it and output ⊥ with probability 1. By the description of 
, it follows that(6)
⁎
 for every 
. On the other hand, on input y, the client outputs ⊥ if and only if the event 
 occurs, which happens with probability 
. With the complement probability 
 it does not detect an inconsistency, and outputs 
⁎
. Therefore(7)
⁎
⁎
 Let(8)
⁎
 Then Equations (6), (7), and (8) imply that
⁎
 where 
 is the 
 unit vector in 
.

To conclude the proof, observe that 
⁎
 was chosen so that 
⁎
, hence 
, implying that the set of points 
⁎
 are affinely independent. Furthermore, since 
 is assumed to have perfect server security, Lemma 3.1 implies that all of these points lie inside 
. Therefore, 
 contradicting the assumption that f is not full-dimensional. □

7. A note on efficiency
While our main goal is to understand the feasibility of perfectly secure 2PC, our construction does confer concrete efficiency benefits for certain parameter ranges. It is instructive to compare our construction with the IKOPS protocol, for deterministic functions (from the right class). Here we focus on the number of OT calls, which are the most expensive part to implement in practice (usually with computational security). Specifically, for simplicity, we consider the number of calls to a  
  oracle, of any length s, rather than  
 . We note that the strings' length of our OT's is quite a bit larger than in IKOPS (due to the step ensuring perfect client security, where the length is multiplied by the number of servers). However, we claim that this comparison is somewhat justified when having practical efficiency in mind, since for particularly long strings, a string-OT oracle can be used to pick short PRG seeds instead of the strings themselves during a preprocessing phase. This will be done by having the server send 
 and 
 to the “short” string-OT functionality, and the client will receive 
, where  as its input. Then, to implement the “long” string-OT during the protocol execution, the sender sends to the client 
, for , where  is a PRG and 
 and 
 are the “long” messages.

Fix a deterministic function  satisfying the conditions of Corollary 3.5. The number of calls to string-OT in 
 and 
 is 
, where c is a constant circa 1400 (c is roughly the same in both protocols). When considering our perfectly secure protocol, we set 
 
, where . On the one hand, this results in communication complexity that is polynomial in  and k, which may be prohibitive for functions with large client-domain or range sizes. On the other hand, for functions with a small client-domain and range sizes, we do better than IKOPS even for real world error ranges, and the advantage grows as the allowed error ε decreases. For instance, consider the greater than function , with an error of 
. The communication complexity we obtain is bounded by a factor smaller than  than that of the IKOPS protocol.