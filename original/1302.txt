Abstract
Obtaining lower bounds for NP-hard problems has for a long time been an active area of research. Algebraic techniques introduced by Jonsson et al. (2017) [4] show that the fine-grained time complexity of the parameterized Image 1 problem correlates to the lattice of strong partial clones. With this ordering they isolated a relation R such that Image 2 can be solved at least as fast as any other NP-hard Image 1 problem. In this paper we extend this method and show that such languages also exist for the surjective SAT problem, the max ones problem, the propositional abduction problem, and the Boolean valued constraint satisfaction problem over finite-valued constraint languages. These languages may be interesting when investigating the borderline between polynomial time, subexponential time and exponential-time algorithms since they in a precise sense can be regarded as NP-hard problems with minimum time complexity. Indeed, with the help of these languages we relate all of the above problems to the exponential time hypothesis (ETH) in several different ways.

Keywords
Constraint satisfaction problems
Fine-grained complexity
Universal algebra

1. Introduction
In this article we study the fine-grained complexity of NP-hard optimization problems and logical reasoning problems, with a particular focus on describing the relative complexity of the problems in each class. For each problem class under consideration we are interested in determining an intractable problem which is ‘maximally easy’, in the sense that there cannot exist any other intractable problem in the class with a strictly lower (exponential) running time. After successfully accomplishing this for the four problems under consideration we then explore the likelihood of obtaining subexponential time algorithms, in light of the exponential-time hypothesis, where we obtain several strong equivalent characterizations.

Background
A superficial analysis of the NP-complete problems may lead one to think that they are a highly uniform class of problems: in fact, under polynomial-time reductions, the NP-complete problems may be viewed as a single problem. However, there are many indications (both from practical and theoretical viewpoints) that the NP-complete problems are a diverse set of problems with highly varying properties, and this becomes visible as soon as one analyses these problems with more refined methods than polynomial-time reductions. This has inspired a strong line of research on the ‘inner structure’ of the set of NP-complete problem, sometimes referred to as fine-grained complexity, to contrast it against classical coarse-grained complexity. Examples include the intensive search for faster algorithms for NP-complete problems [1] and the highly influential work on the exponential-time hypothesis (ETH) and its variants [2]. Such research might not directly resolve whether P is equal to NP or not, but rather attempts to explain the seemingly large difference in complexity between NP-hard problems, and what makes one problem seemingly harder than another. Tangentially related research includes investigations into more restricted nondeterministic complexity classes than NP, e.g., the complexity class VertexNLIN, which is also defined with respect to a fine-grained complexity parameter [3].

Unfortunately, there is a lack of general methods for studying and comparing the complexity of NP-complete problems with more restricted notions of reducibility. Jonsson et al. [4] presented a framework based on clone theory, applicable to problems that can be viewed as ‘assigning values to variables’, such as Boolean satisfiability (SAT) problems, constraint satisfaction problems (CSPs), the vertex cover problem, and integer programming problems. In short, every instance of a ‘variable assignment problem’ corresponds to a set of potential models, and with the algebraic approach it is possible to describe the symmetry of this solution space by properties of partial polymorphisms, in such a way that computationally hard problems have a small amount of symmetry, while comparably easier problems have a richer amount of symmetry. The corresponding algebraic method for studying classical complexity based on total polymorphisms, the so-called algebraic approach, turned out to be immensely successful and recently resulted in a complete characterization of the classical complexity of CSPs: the CSP dichotomy theorem [5], [6]. For a direct comparison between the classical and fine-grained approach, see e.g. the survey by Couceiro et al. [7]. Hence, while the algebraic framework for studying fine-grained complexity is not as mature as the algebraic approach for studying classical complexity, there is potentially much to gain from expanding this toolbox, and investigating its limits by exploring new classes of problems.

Aims and methods
Inspired by this algebraic framework of Jonsson et al. [4] we study fine-grained complexity aspects for a wide range of ‘variable assignment problems’ of particular importance in Boolean optimization and propositional logical reasoning. To analyze and relate the complexity of these problems in greater detail we utilize polynomial-time reductions which increase the number of variables by a constant factor (linear variable reductions or LV-reductions) and reductions which increase the amount of variables by a constant (constant variable reductions or CV-reductions). Note the following: (1) if a problem A is solvable in 
 time (where n denotes the number of variables and m the size of the instance) for all  and if problem B is LV-reducible to A then B is also solvable in 
 time for all  and (2) if A is solvable in time 
 and if B is CV-reducible to A then B is also solvable in time 
. Thus, LV-reductions preserve subexponential complexity while CV-reductions preserve the exact constant in an exponential running time of the form 
.

While there exist NP-hard problems solvable in subexponential time, e.g., the feedback arc set problem restricted to tournaments [8], it is widely believed that this is not the case for all NP-hard problems. The particular conjecture that the 3-SAT problem is not solvable in subexponential time is known as the exponential-time hypothesis (ETH) [9]. Thus, the ETH can be seen as a stronger, more fine-grained variant of P ≠ NP, which has proven to be an immensely useful tool for proving superpolynomial lower bounds for many different types of problems [10]. In this vein, and with the aforementioned algebraic approach, Jonsson et al. [4] studied the Boolean satisfiability

Image 3
problem and identified an NP-hard
Image 4
problem CV-reducible to all other NP-hard
Image 3
problems. Hence
Image 4
is, in a sense, the easiest NP-complete
Image 3
problem since if any other NP-hard
Image 5
can be solved in 
 time, then this holds for
Image 4
, too. The existence of an ‘easiest problem’ of this form is not only an interesting theoretical curiosity, but has important consequences. For example: if there exists any NP-hard
Image 5
problem solvable in subexponential time, then the easiest problem
Image 4
must be solvable in subexponential time, too. Hence, if we can prove that 3-SAT is no harder than
Image 4
, via a suitable LV-reduction, then no NP-hard
Image 5
problem is solvable in subexponential time without violating the ETH. The advantage is then that it is significantly easier to show the existence of an LV-reduction of this form for a concrete language , than to consider arbitrary intractable problems
Image 5
. With the aid of this result, Jonsson et al. [4] also analyzed the applicability of the sparsification lemma [11] for arbitrary
Image 3
problem, and proved that sparsification of
Image 5
is always possible when Γ is finite. This should not be taken for granted since Santhanam and Srinivasan [12] have proven that sparsification is not always possible for infinite constraint languages. This study was later generalized to a broad class of finite-domain constraint satisfaction problems where it was proven that one can find an ‘easiest NP-hard CSP’ for every fixed, finite, domain [13]. Curiously, this sequence of problems was shown to decrease in complexity, in the sense that one for every  can find an NP-hard finite-domain CSP problem solvable in 
 time, even though none of these problems are solvable in subexponential time without contradicting the ETH. However, if one steps into the realm of infinite-domain CSPs, then it is known that there cannot exist an ‘easiest NP-hard infinite-domain CSP’, unless the ETH is false [14]. Thus, while easiest problems of this form exist for finite-domain CSPs and SAT problems, they should in general not be taken for granted. We believe that the existence and construction of such easiest languages forms an important puzzle piece in the quest of relating the complexity of NP-hard problems with each other, since it effectively gives a lower bound on the time complexity of a given problem with respect to constraint language restrictions.
Our results
As a logical continuation on the work on

Image 3
and
Image 6
we pursue the study of CV- and LV-reducibility in the context of Boolean optimization problems and logical reasoning problems. In particular, we investigate the complexity of the maximum ones problem (
Image 7
), the surjective satisfiability problem (
Image 8
), the propositional abduction problem (
Image 9
) and the Boolean valued constraint satisfaction problem (
Image 10
). These problems are presented in greater detail in Section 2, but for the moment they can be summarized as follows.
•
The

Image 7
problem [15] is a variant of
Image 3
where the goal is to find a satisfying assignment which maximizes the number of variables assigned the value 1. This problem is closely related to the 0/1 Linear Programming problem.
•
The

Image 11
problem is another twist on the classical
Image 5
problem where the goal is to find a surjective solution, which in the Boolean domain simply means that the presented solution is not constantly 0 or constantly 1 [16]. The
Image 8
problem is not only of theoretical interest and its complexity classification has been used to simplify complexity classifications of other problems of practical interest, e.g., enumeration problems [17].
•
The

Image 12
problem is a well-known problem within artificial intelligence where the goal is to find an explanation of a manifestation which is consistent with a given Γ-formula. A complexity trichotomy is known for every finite, Boolean language Γ [18], [19], and we concentrate on the case when
Image 12
is included in NP.
•
The

Image 10
problem is a function minimization problem that generalizes the
Image 13
and
Image 14
problems [15].
We treat both the unweighted and weighted versions of

Image 7
and
Image 10
and use the prefix
Image 15
to denote the unweighted problem and
Image 16
to denote the weighted version. All of these problems are well-studied with respect to separating tractable cases from NP-hard cases [15], [20] but much less is known when considering the weaker schemes of LV-reductions and CV-reductions. We begin (in Section 3) by identifying the easiest languages for
Image 8
,
Image 17
, and
Image 9
. The idea behind these proofs is to first perform a ‘coarse-grained’ complexity analysis, based on existing classical complexity classifications, and for each such case determine the easiest problem by identifying a constraint language with the richest set of partial polymorphisms. However, this may still result in a large number of cases that needs to be compared, and to identify an easiest problem one needs to prove that one such problem is CV-reducible to every other problem, which in general is highly non-trivial. To accomplish this for the
Image 17
problem we investigate a novel reduction technique based on weighted primitive positive implementations [21].
For

Image 10
the situation differs even more since the algebraic techniques developed for
Image 6
are not applicable — instead we use multimorphisms [22] when considering the complexity of
Image 10
in Section 3.4. We prove that the binary function 
, which returns 0 if its two arguments are different and 1 otherwise, results in the easiest NP-hard
Image 10
problem. This problem is very familiar since it is the Max Cut problem slightly disguised. The complexity landscape surrounding these problems is outlined in Section 3.5. Interestingly, it turns out that none of the identified problems, with the possible exception of the easiest
Image 9
problem, is easier than the easiest
Image 3
problem from Jonsson et al. [4].
With the aid of the languages identified in Section 3, we continue (in Section 4) by relating the problems to subexponential complexity, using the ETH as a guiding star. This is accomplished via the aforementioned LV-reductions since they preserve subexponential complexity. For each such problem there are then two main questions with respect to subexponential complexity: is it possible to find an LV-reduction from 3-SAT, and is every such problem LV-reducible to 3-SAT? Since LV-reductions preserve subexponential complexity this means that we (1) rule out the possibility of subexponential algorithms if the ETH is true, and (2) show that every such problem is solvable in subexponential time if the ETH is false. If both of these conditions are proven to hold for a problem one therefore obtains a complete understanding of subexponential complexity (under the ETH). In particular, our results imply (1) if the ETH is true then no NP-complete

Image 18
,
Image 19
,
Image 11
,
Image 12
, or
Image 20
problem is solvable in subexponential time and (2) if the ETH is false then
Image 18
,
Image 11
, and
Image 21
are solvable in subexponential time for every choice of Γ and Δ and . Here,
Image 21
is the
Image 22
problem restricted to instances where the sum to minimize contains at most dn terms. Thus, to disprove the ETH, our result implies that it is sufficient to find a single language Γ or a set of cost functions Δ such that
Image 18
,
Image 19
,
Image 11
,
Image 12
, or
Image 20
is NP-hard and solvable in subexponential time.
2. Preliminaries
Let Γ denote a finite set of finitary relations over . We call Γ a Boolean constraint language, and when there is no risk for confusion, simply a constraint language. Given 
 we let  denote its arity, and similarly for functions. When  we typically omit the set notation and treat R as a constraint language. We write 
 for the set of all rational numbers larger than or equal to 0.

2.1. Problem definitions
Let us now properly define the problems under consideration in this article. We begin with the constraint satisfaction problem over a set of relations Γ over a domain D (

Image 23
), which is defined as follows.

CSP(Γ)

Instance: A set V of variables and a set C of constraint applications 
 where , , and 
.

Question: Is there a function  such that 
 for each 
 in C?

For the Boolean domain this problem is typically denoted as

Image 5
, and in addition we write k-SAT to denote the variant of the satisfiability problem where each input clause is of length k. One may also remark that k-SAT can be formulated as a
Image 5
problem by letting the constraint language Γ consist of relations corresponding to the set of models of k-ary clauses. By
Image 5
-B we mean the
Image 5
problem restricted to instances where each variable can occur in at most B constraints. Similarly, we write k-SAT-B for the variant of k-SAT where each variable can occur in at most B constraints. These restricted problems are occasionally useful since each instance contains at most B n constraints. We now define the variants of
Image 5
that are considered in this article. The weighted maximum ones problem over Γ (
Image 24
) is defined as follows.

Image 19
Instance: A

Image 5
instance 
 where each variable 
 has an associated weight 
Objective: Find a satisfying assignment h to 
 which maximizes the sum 
.

Example 1

Naturally, every NP-hard

Image 5
problem results in a natural optimization variant
Image 19
where one wishes to find a solution maximizing the number of variables assigned 1. However,
Image 17
also includes many problems without a clear link to the standard satisfiability problem. For example, consider the relation
Image 25
, and take an instance of
Image 26
, interpreted as the complement of a graph (i.e., a constraint
Image 27
means that there is no edge between x and y). The resulting problem is then nothing else than a reformulation of the (weighted variant of) the Max Independent Set problem, which is well known to be NP-hard. In contrast,
Image 28
is a special case of 2-SAT, and is thus solvable in polynomial time.
The unweighted maximum ones problem (

Image 29
) is the
Image 19
problem where all weights have the value 1. Occasionally, it does not matter whether the problem is weighted or unweighted, and in that case we simply write
Image 30
.

Image 11
Instance: A

Image 5
instance I.
Question: Does there exist a satisfying assignment to I which is surjective?

Note that, since we operate in the Boolean domain, an assignment is surjective if and only if it is non-constant, i.e., does not assign the same value to each variable.

A finite-valued cost function on  is a function 
. The valued constraint satisfaction problem over a finite set of finite-valued cost functions Δ (

Image 20
) is defined as follows.

Image 20
Instance: A set 
 of variables and an objective function
 
 where 
 is a cost function in Δ, 
 is a tuple over the variables V, and 
 is a non-negative rational weight.

Objective: Find an assignment  such that 
 is minimized.

When the set of cost functions is singleton  we write

Image 31
for the
Image 10
problem over . We let
Image 32
be the
Image 33
problem without weights and
Image 34
(for ) denote the
Image 32
problem restricted to instances containing at most  constraints.
Example 2

Many optimization problems can be viewed as

Image 20
problems for suitable Δ; well-known examples are the
Image 35
and
Image 36
problems where the number of satisfied constraints in a
Image 37
instance are maximized or minimized. For each Γ, there obviously exists sets of cost functions 
 such that
Image 36
is polynomial-time equivalent to
Image 38
and
Image 35
is polynomial-time equivalent to
Image 39
.
For a second, concrete example, recall that 
 is the Boolean cost function which returns 0 if and only if its two arguments are unequal, and consider the problem

Image 40
. Then note that a
Image 40
instance can be viewed as a graph, and under this interpretation the task is thus to minimize the (sum of the weight of the) edges outside the cut, i.e., maximizing the edges crossing the cut. Hence, this problem is a reformulation of the well-known Max-Cut problem.
We have defined

Image 32
,
Image 33
,
Image 41
and
Image 42
as optimization problems, but to obtain a more uniform treatment we often view them as decision problems, i.e. given k we ask if there is a solution with objective value k or better. We note that the representation of k has a size bounded by those of the representations of the weights. Thus, the introduction of the parameter k does not fundamentally change the problems.
We close this section by introducing the propositional abduction problem over a constraint language Γ (

Image 12
) (denoted V-ABD in Nordh & Zanuttini [19] and PQ-ABDUCTION(Γ) in Creignou & Zanuttini [18]). Given a set of variables A we let  be the set of all (positive and negative) literals obtainable from A.

ABD (Γ)

Instance: , where φ is a Γ-formula, , 

Question: Does there exist an  such that

1.
 is satisfiable, and

2.
 is unsatisfiable.

Thus, the task is to find an explanation, which is a subset of literals, which is (1) consistent with the input formula, and (2) together with the input formula logically implies the manifestation q.

2.2. Size-preserving reductions and subexponential time
If A is a computational problem, then we let  be the set of problem instances and  be the size of any , i.e. the number of bits required to represent I. Many problems can in a natural way be viewed as problems of assigning values from a fixed finite set to a collection of variables. This is certainly the case for the problems under consideration in this article but it is also the case for various graph problems such as

Image 43
and Max Independent Set. We call problems of this kind variable problems and let  denote the set of variables of an instance I.
Definition 1

Let 
 and 
 be variable problems in NP. The function f from 
 to 
 is a many-one linear variable reduction (LV-reduction) with parameter  if

1.
I is a yes-instance of 
 if and only if  is a yes-instance of 
,

2.
, and

3.
 can be computed in time .

LV-reductions can be seen as a restricted form of SERF-reductions [11]. The term CV-reduction is used to denote LV-reductions with parameter 1, and we write 
 to denote that the problem 
 has an CV-reduction to 
. If 
 and 
 are two NP-hard problems we say that 
 is at least as easy as (or not harder than) 
 if 
 is solvable in 
 time whenever 
 is solvable in 
 time. By definition, if 
 then 
 is not harder than 
 but the converse is not true in general. If 
 and 
 are two problems mutually CV-reducible to each other, i.e., 
 and 
, then we write 
.

A problem solvable in time 
 for all  is a subexponential problem, and we let

Image 44
denote the class of all variable problems solvable in subexponential time. It is straightforward to prove that LV-reductions preserve subexponential complexity for all problems A and B considered in this article, in the sense that if A is LV-reducible to B then
Image 45
if
Image 46
. Naturally,
Image 44
can be defined using other complexity parameters than  [11]. The conjecture that 3-SAT is not solvable in subexponential time is then known as the exponential-time hypothesis (ETH) [9].
2.3. Operations and relations
We now define the most important classes of operations and relations. An operation f is called arithmetical if  for every . The max function is defined as  if  and 1 otherwise. We often express a Boolean relation R as a logical formula whose satisfying assignment corresponds to the tuples of R, often using the notation 
, where n is the arity of R and where 
 is a first-order formula with free variables 
. F and T are the two constant relations  and  while Neq denotes inequality, i.e. the relation . The relation  is defined as 
. The relation  is defined dually. The relations 
 and 
 are the relations corresponding to the clauses 
 and 
 
 
. For any n-ary relation R we let 
, , denote the -ary relation defined as 
. We let 
. Variables are typically named 
 or x, and as a convention we typically order the arguments of relations in such a way that any constant arguments occur as the last (one or two) arguments.

2.4. Clone theory
An operation 
 is a polymorphism of a relation R if for every 
 it holds that 
, where f is applied element-wise. In this case R is closed, or invariant, under f. For a set of functions  we define Inv (often abbreviated as ) to be the set of all relations invariant under all functions in . Dually, for a set of relations Γ,  is defined to be the set of polymorphisms of Γ. Sets of the form  are known as clones and sets of the form Inv are known as co-clones. A clone  can equivalently well be described as a set of functions which (1) contains every function which returns a fixed argument (projections), and (2) is closed under functional composition. These two conditions can also be combined to form a closure operator over functions, and a generating set of a clone is called a base. In the Boolean domain clones are fully determined due to Post [23]. See Table 2 for a comprehensive list of Boolean clones, and Fig. 1 for a visualization of their inclusion structure. It is then known that the relationship between clones and co-clones constitutes a Galois connection [24].

Theorem 1

Let Γ, 
 be sets of relations. Then 
 if and only if 
.

Co-clones can equivalently be described as sets containing all relations R definable through primitive positive implementations (pp-implementations) over a constraint language Γ, i.e. definitions of the form
 where each 
 and each 
 is a tuple over 
, 
 and where . We typically use the expressions ‘pp-implementations’ and ‘pp-definitions’ interchangeably. As a shorthand we let  for a constraint language Γ, and as can be verified this is the smallest set of relations closed under pp-implementations over Γ. In this case Γ is said to be a base of , and if a co-clone admits a finite base it is said to be finitely generated; otherwise it is said to be infinitely generated.
Fig. 1
Download : Download high-res image (248KB)
Download : Download full-size image
Fig. 1. The lattice of Boolean clones.

It is known that if 
 is finite and 
 then

Image 47
is polynomial-time reducible to
Image 23
[25]. With this fact and Post's classification of all Boolean clones [23] Schaefer's dichotomy theorem [26] for
Image 3
follows almost immediately. The complexity of
Image 30
is also preserved under finite expansions with relations pp-definable in Γ, and hence follow the standard Galois connection [15]. Note, however, that 
 does not imply that
Image 48
or that
Image 47
LV-reduces to
Image 23
since the number of constraints is not necessarily linearly bounded by the number of variables.
To study these restricted classes of reductions we are therefore in need of Galois connections with increased granularity. In Jonsson et al. [4] the

Image 3
problem is studied with the Galois connection between closure under pp-definitions without existential quantification and strong partial clones. Here, we concentrate on the relational description and instead refer the reader to Schnoor & Schnoor [17], and Couceiro et al. [7], for the corresponding definitions on the functional side. If R is an n-ary Boolean relation and Γ a constraint language then R has a quantifier-free primitive positive implementation (qfpp-implementation) in Γ if
 where each 
 and each 
 is a tuple over 
. We use 
 to denote the smallest set of relations closed under qfpp-definability over Γ. If 
 then  is sometimes called a weak system, or a weak co-clone. In Jonsson et al. [4] it is proven that if 
 and if Γ and 
 are both finite constraint languages then
Image 49
. It is not hard to extend this result to the weighted
Image 17
problem since it follows the standard Galois connection, and therefore we use this fact without explicit proof. The only minor complication is that one has to ensure that the resulting variable is given a weight which matches the sum of the weights of the variables which it has replaced when equality constraints are removed, and variables are identified. Similarly, it is very straightforward to show that the same reduction technique works for
Image 8
and
Image 9
, and we thus have the following theorem.
Theorem 2

Let Γ and Δ be finite Boolean constraint languages. If 
, then

1.
Image 50
,
2.
Image 51
,
3.
Image 52
, and
4.
Image 53
.
Example 3

We consider a simple example to highlight the type of reduction one obtains via Theorem 2. Recall that 
 is the ternary relation , define the relation 
 as , and observe that this relation is qfpp-definable over 
 since 
. Next, consider an instance  of (e.g.)

Image 54
. Any constraint 
 is then replaced by the constraints prescribed by the above qfpp-definition, i.e., we introduce the constraints 
. Crucially, while the number of constraints increases by a constant factor, the number of variables does not change at all, and it follows that the original instance has a solution of cost m if and only if the new instance has a solution of cost m.
However, this does not hold (a priori) for the unweighted

Image 55
problem since one cannot safely remove equality constraints without using weights. We will circumvent this problem by introducing a special class of relations which are qfpp-definable without using equality.
Definition 2

(Schnoor & Schnoor [17]) A weak base 
 of a co-clone  is a base of  with the property that for any base Γ of  it holds that 
.

Weak bases for Boolean co-clones are well understood due to Lagerkvist [27], and Lagerkvist & Wahlström [28]. See Table 1 for a comprehensive list of weak bases. As a convention, we write 
 for the weak base of the co-clone  in Table 1. In addition, these weak bases satisfy an additional minimality condition which implies that they can be qfpp-defined without using equality. Hence, the aforementioned problem for

Image 55
does not occur, and we obtain the following theorem.

Table 1. Weak bases for all Boolean co-clones from Lagerkvist [27].

Co-clone	Weak base
{Eq(x1,x2)}
{F(x1)}
{T(x1)}
{F(x1)∧T(x2)}
{(x1 → x2)}
{(x1 → x2)∧F(x3)}
{(x1 → x2)∧T(x3)}
{(x1 → x2)∧F(x3)∧T(x4)}
{ORn(x1,…,xn)∧T(xn+1)}
{ORn(x1,…,xn)∧T(xn+1)|n ≥ 2}
{ORn(x1,…,xn)∧F(xn+1)∧T(xn+2)}
{ORn(x1,…,xn)∧F(xn+1)∧T(xn+2)|n ≥ 2}
{ORn(x1,…,xn)∧(xn+1 → x1⋯xn)∧T(xn+2)}
{ORn(x1,…,xn)∧(xn+1 → x1⋯xn)∧T(xn+2)|n ≥ 2}
{ORn(x1,…,xn)∧(xn+1 → x1⋯xn)∧F(xn+2)∧T(xn+3)}
{ORn(x1,…,xn)∧(xn+1 → x1⋯xn)∧F(xn+2)∧T(xn+3)|n ≥ 2}
{NANDn(x1,…,xn)∧F(xn+1)}
{NANDn(x1,…,xn)∧F(xn+1)|n ≥ 2}
{NANDn(x1,…,xn)∧F(xn+1)∧T(xn+2)}
{NANDn(x1,…,xn)∧F(xn+1)∧T(xn+2)|n ≥ 2}
{NANDn(x1,…,xn)∧(x1 → xn+1)∧…∧(xn → xn+1)∧F(xn+2)}
{NANDn(x1,…,xn)∧(x1 → xn+1)∧…∧(xn → xn+1)∧F(xn+2)|n ≥ 2}
{NANDn(x1,…,xn)∧(x1 → xn+1)∧…∧(xn → xn+1)∧F(xn+2)∧T(xn+3)}
{NANDn(x1,…,xn)∧(x1 → xn+1)∧…∧(xn → xn+1)∧F(xn+2)∧T(xn+3)|n ≥ 2}
{Neq(x1,x2)}
{Neq(x1,x2)∧F(x3)∧T(x4)}
{OR2(x1,x2)∧Neq(x1,x3)∧Neq(x2,x4)∧F(x5)∧T(x6)}
{4-EVEN(x1,x2,x3,x4)}
{3-EVEN(x1,x2,x3)∧F(x4)}
{3-ODD(x1,x2,x3)∧T(x4)}
{3-EVEN3≠(x1,…,x6)∧F(x7)∧T(x8)}
{4-EVEN4≠(x1,…,x8)}
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
{(x1↔x2x3)∧(x2∨x3 → x4)}
{(x1↔x2x3)∧(x2∨x3 → x4)∧F(x5)}
{(x1↔x2x3)∧T(x4)}
{(x1↔x2x3)∧F(x4)∧T(x5)}
{4-EVEN(x1,x2,x3,x4)∧x1x4↔x2x3}
{4-EVEN4≠(x1,…,x8)∧x1x4↔x2x3}
 
 
 
 
 
 
 
 
{(x1∨x2)∧(x1x2↔x3)∧T(x4)}
Theorem 3

Let  be a finitely generated Boolean co-clone and let 
 be the weak base of  from Table 1. Let Γ be an arbitrary finite base of . Then:

1.
Image 56
,
2.
Image 57
,
3.
Image 58
,
4.
Image 59
, and
5.
Image 60
.
Naturally, this is only impactful if the problem in question is intractable, since two polynomially solvable problems are trivially CV-reducible to each other.

Example 4

Let us take a concrete example from Table 1. Recall the relational definitions from Section 2.3. We now see that 
 and 
 from Table 1 are the two relations (where the tuples in the relations are listed as rows)
 
 

3. The easiest NP-hard
Image 61
,
Image 62
,
Image 63
, and
Image 33
problems
We will now study the complexity of

Image 61
,
Image 62
,
Image 42
, and
Image 33
with respect to CV-reductions (we return to the complexity of
Image 55
in Section 4). We remind the reader that constraint languages Γ and sets of cost functions Δ are always finite. We prove that for all of these problems we can identify a single language which is CV-reducible to every other NP-hard language. Hence, each such problem can be regarded as being ‘maximally easy’, in the sense that there cannot exist any other NP-hard problem within the class solvable within a strictly smaller running time. We will typically refer to each such problem as the ‘easiest NP-hard problem’ within the class, but remind the reader that we by this phrase do not claim that there cannot exist other problems with the same complexity (such a claim would be much too strong since it might even be the case that all problems are solvable in polynomial time, and would thus trivially be CV-reducible to each other).
Out of the infinite number of candidate languages generating different co-clones, we then prove that the language 
 defines the easiest

Image 8
problem and the easiest
Image 17
problem, while the language 
 results in the easiest NP-complete
Image 9
problem. Recall that we write 
 for the weak base of the co-clone  from Table 1. It might be interesting to note that 
 is the same language as for
Image 3
[4], which might be contrary to intuition since one could be led to believe that the co-clones in the lower parts of the co-clone lattice, generated by very simple languages where the corresponding
Image 3
problem is in P, would result in even easier problems. For example,
Image 5
is trivially in P for 
 since Γ is then closed under a constant operation, while
Image 11
is NP-hard for these cases, and a priori there is no clear reason why the problem
Image 64
should be easier.
For the

Image 10
problem the situation is a bit different since it is defined in the setting of cost functions, rather than constraint languages, and here we instead prove that the familiar problem Max Cut results in the easiest
Image 10
problem. In addition, we summarize and relate the results together by illustrating the complexity landscape of these problems in Section 3.5.
3.1. The surjective
Image 65
problem
Recall that the

Image 11
problem is the problem of determining whether a set of constraints over a Boolean Γ admits a surjective solution, which in the Boolean domain simply implies that the solution in question is not constant. While very little is known regarding the complexity of this problem for arbitrary finite domains [30], a complete complexity dichotomy has been established for
Image 11
. Say that a Boolean operation 
 is essentially unary if there exists a unary function g and  such that 
 for all 
. We then have the following result from Creignou et al. [16].
Theorem 4

Image 67
is NP-complete if  consists of essentially unary operations and is in P otherwise.
Theorem 5

Let Γ be a finite constraint language such that

Image 67
is NP-hard. Then
Image 68
.
Proof

Recall from Theorem 3 that each weak base 
 results in the easiest NP-hard

Image 8
problem for the co-clone . Hence, all we have to show is that
Image 69
for every  where
Image 70
is NP-hard.
We first observe that given an instance of

Image 64
, we may assume (1) that , and (2) that every variable occurs in at least one constraint. The other cases are easy. Indeed, if  we simply output an arbitrary unsatisfiable instance. Otherwise, if there exists some variable that does not occur in any constraint, then surjectivity is not an issue. In this case we introduce a fresh variable z and add the constraint 
 for every unconstrained variable x. We can assume the properties (1) and (2) also when given an instance of
Image 71
,
Image 72
or
Image 73
, for very similar reasons.
We give the reductions in terms of local constraint transformations and note that in total, they introduce a constant number of global variables and run in polynomial time since all involved constraint languages are finite. Let 
 denote two fresh variables. Each implementation is written as 
, where 
 is the relation in question and ϕ is a qfpp-definition (without equality) over the variables 
. Using these implementations we can then obtain a CV-reduction by (1) introducing the two fresh variables 
 and 
 and (2) replacing each constraint in the input instance by the constraints prescribed by the qfpp-definition. The reduction sequences are summarized in Fig. 3.

Fig. 3
Download : Download high-res image (20KB)
Download : Download full-size image
Fig. 3. The size preserving reduction sequences for

Image 61
.
With 
 we use the following implementation:
 The second constraint ensures that the constraints 
, 
 and 
 hold. If f is a satisfying assignment where 
 then we may use the assignment 
 instead since the complement of a valid assignment is also a valid assignment for languages closed under complement.

To implement 
 with 
 use
 Note that 
, 
, and 
. Hence, any solution f where 
, assigns all variables a and is therefore trivial.

The reductions from 
 to 
 and 
 are very similar, hence we only include the latter. The implementation is
 One verifies that 
 and 
. Therefore, any solution f where 
 assigns all variables 1 and is therefore trivial.

For the last step it is easy to verify that 
 can implement both 
 and 
 with one global variable in each case. □

Interestingly,

Image 64
is CV-interreducible to the easiest NP-hard SAT problem,
Image 74
, since every instance of the latter admits a solution if and only if it admits a surjective solution (provided that every variable appears in at least one constraint). To see this, simply observe that a 
-constraint which is not trivially unsatisfiable, can only be satisfied by a surjective assignment.
3.2. The propositional abduction problem
The complexity of propositional abduction is well-studied, and for constraint languages this problem enjoys a trichotomy between 
-complete, NP-complete, and tractable cases (recall that we by constraint language always mean a finite set of relations).

Theorem 6

Creignou & Zanuttini [19]
Let Γ be a Boolean (finite) constraint language. Then

Image 75
is NP-complete if 
, 
-complete if 
, and in P otherwise.
Here, finiteness is not merely a simplifying assumption, but absolutely crucial, since it is known that there exists an infinite set of relations Γ such that

Image 12
is NP-intermediate [31]. In the sequel, we thus concentrate on the case when
Image 12
is NP-complete and when Γ is finite.
Theorem 7

If Γ is a finite constraint language such that

Image 75
is NP-complete, then
Image 76
.
Our proof makes use of the following two lemmas.

Lemma 1

Suppose 
 for some j and some function , and that the binary relation 
 is pp-definable from 
. Then

Image 77
.
Proof

Let  be an instance of

Image 78
. We construct a 
-formula 
 over the variables , where Y is a fresh variable, as follows: For every constraint 
 in φ, create the constraints 
, and finally add the constraint . The very last constraint is over a relation that is pp-definable from 
, and can therefore be eliminated while only introducing a constant number of additional variables. The equality constraints can all be eliminated by identification of variables.
We claim that  is a Yes-instance of

Image 78
if and only if 
 is a Yes-instance of
Image 79
. For , if  is satisfiable and  is unsatisfiable, then 
 is satisfiable and 
 is unsatisfiable. For , assume 
 is satisfiable and 
 is unsatisfiable. Then 
 must also be satisfiable (since  is part of 
), and 
 must be unsatisfiable (since it is a restriction). From this follows that 
 is satisfiable and 
 is unsatisfiable. □
Let  be the function that maps 0 to 1 and 1 to 0. We define this function also on relations through 
.

Lemma 2

Suppose 
 for some permutation π, and that the binary relation 
 is pp-definable from 
. Then

Image 77
.
Proof

Let  be an instance of

Image 78
. We construct a 
-formula 
 on variables 
, where 
 is a fresh variable, as follows. For each constraint 
 in φ, create the constraint 
. Finally, add the constraint 
. The last constraint can be eliminated at the cost of only a constant number of additional variables since is over a relation that is pp-definable from 
 (possibly introduced equality constraints can be eliminated by identification of variables).
We claim that  is a Yes-instance of

Image 78
if and only if 
 is a Yes-instance of
Image 79
. For , let E be an arbitrary set of literals and define . If  is satisfiable and  is unsatisfiable, then 
 is satisfiable and 
 is unsatisfiable. This means, since 
 is part of 
, also that 
 is unsatisfiable. For , again let 
 be an arbitrary set of literals and define 
. Assume 
 is satisfiable and 
 is unsatisfiable. Since the only constraint in 
 in which 
 occurs is 
, this means that also 
 is unsatisfiable. Hence, 
 is satisfiable and 
 is unsatisfiable. □
We can now prove the theorem.

Proof of Theorem 7

According to Theorem 6 (see also Fig. 4) there are six distinct cases to consider when the propositional abduction problem is NP-complete. These are the co-clones , 
, 
, 
, 
, and 
. For each such co-clone  let 
 denote the weak base from Table 1, and recall from Theorem 3 that

Image 80
when Γ is a finite base of .
Fig. 4
Download : Download high-res image (251KB)
Download : Download full-size image
Fig. 4. The complexity of

Image 12
: the 
-complete cases are colored in red, the NP-complete cases for finitely generated co-clones are colored in gray, the NP-complete cases for infinitely generated co-clones are drawn as dashed, gray circles, and the tractable cases are drawn in white. (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)
Note that
 One easily verifies that the binary relation 
 is pp-definable from each of 
, 
 and 
. From Lemma 1 it follows that

Image 81
,
Image 82
, and
Image 83
.
Note also that
 It is easy to check that the binary relation 
 is pp-definable both from 
 and from 
. Hence, by Lemma 2 it follows that

Image 84
and
Image 85
.
3.3. The
Image 63
problem
Here we use a slight reformulation of Khanna et al.'s [15] complexity classification of the

Image 63
problem expressed in terms of polymorphisms. Say that a constraint language is 1-closed if it is preserved by the constant Boolean function 1.
Theorem 8

[15]
Let Γ be a finite Boolean constraint language.

Image 87
is solvable in polynomial time if Γ is 1-closed, closed under max, or closed under an arithmetical operation, and is NP-hard otherwise.
Theorem 9

Let Γ be a finite constraint language such that

Image 87
is NP-complete. Then there exists 
, 
, 
, 
, 
, 
 (relations defined in Table 2) such that
Image 89
. This holds both for the weighted and the unweighted version of the problem.

Table 2. List of all Boolean clones with definitions and bases, where id(x)=x and 
, 
 
 
. See e.g. [29].

Clone	Definition	Base
All Boolean functions	{x∧y,¬x}
{f|f is 0-reproducing}	{x∧y,x ⊕ y}
{f|f is 1-reproducing}	{x∨y,x ⊕ y ⊕ 1}
{x∨y,x∧(y ⊕ z ⊕ 1)}
{f|f is monotonic}	{x∨y,x∧y,0,1}
{x∨y,x∧y,1}
{x∨y,x∧y,0}
{x∨y,x∧y}
{f|f is 0-separating of degree n}	{x → y,dual(hn)}
{f|f is 0-separating}	{x → y}
{f|f is 1-separating of degree n}	{x∧¬y,hn}
{f|f is 1-separating}	{x∧¬y}
{x∨(y∧¬z),dual(hn)}
{x∨(y∧¬z)}
{dual(hn),1}
{x∨(y∧z),1}
{x∨(y∧z),dual(hn)}
{x∨(y∧z)}
{x∧(y∨¬z),hn}
{x∧(y∨¬z)}
{hn,0}
{x∧(y∨z),0}
{x∧(y∨z),hn}
{x∧(y∨z)}
{f|f is self-dual}	{(x∧¬y)∨(x∧¬z)∨(¬y∧¬z)}
{(x∧y)∨(x∧¬z)∨(y∧¬z)}
{h2}
{f|f is affine}	{x ⊕ y,1}
{x ⊕ y}
{x ⊕ y ⊕ 1}
{x ⊕ y ⊕ z}
{x ⊕ y ⊕ z ⊕ 1}
{f|f is a disjunction or constants}	{x∨y,0,1}
{x∨y,0}
{x∨y,1}
{x∨y}
{f|f is a conjunction or constants}	{x∧y,0,1}
{x∧y,0}
{x∧y,1}
{x∧y}
{f|f depends on at most one variable}	{¬x,0,1}
{¬x}
{f|f is a projection or a constant}	{id,0,1}
{id,0}
{id,1}
{id}
We will prove the theorem with the help of the following lemmas, all of which holds both in the weighted and unweighted case.

Lemma 3

If Γ is a constraint language and R is a relation that is qfpp-definable without equality in Γ, then

Image 89
.
Proof

Since R is qfpp-definable without equality in Γ, every constraint over R can be replaced with a finite set of constraints over Γ. □

Note that if equality relations were allowed in the qfpp-formula for R, then these would have to be eliminated. The natural way to do this is by identification of variables, but for this approach to work we need general weights for the variables.

Lemma 4

If R and 
 are relations that satisfy(1)
(2)
 
 then

Image 90
.
Proof

To see why this is true, consider the following reduction. Given an instance of

Image 91
over n variables, we construct an instance of
Image 92
over the same set of variables (preserving variable weights), extended with two fresh, unit-weight, variables 
 and 
. Let 
 be the summed weights of every variable in the given instance that does not occur in any constraint. For every constraint 
 in the given instance we add the constraint 
 to the new instance. From (1) and the fact that a solution always can be changed to map each unconstrained variable to the value 1, it follows that if the original instance has a solution with objective value ≥k, then the new instance has a solution with objective value , and hence 
 since 
 must hold in the original instance (since setting all unconstrained variables to 1 is a solution).
For the other direction, consider a solution to the new instance with objective value 
. Assume first that 
 is assigned the value 0. By (2) it follows that every variable that occurs in a constraint must be assigned the value 0, so the objective is at most 
. This is a contradiction, so 
 must be assigned the value 1. It then follows from (2) that there is a solution the original instance with objective value 
. Hence, the original instance has a solution with objective value ≥k if and only if the new instance has a solution with objective value 
. □

We now have all the results in place that we need to prove the theorem.

Proof of Theorem 9

By Theorem 8 in combination with Table 2 and Fig. 1 it follows that

Image 30
is NP-complete if and only if 
 or if 
. Then, in principle, for every co-clone we have to decide which language is CV-reducible to every other base of the co-clone, but since a weak base always has this property, we can eliminate a lot of tedious work and directly consult the precomputed relations in Table 1. From this we first see that 
, 
, 
 and 
 for every . Hence, in the four infinite chains 
, 
, 
, 
 we only have to consider the bottom-most co-clones 
, 
, 
, 
.
For 
 we can define relations 
 with 
, 
, 
, 
, and 
, satisfying the requirements of Lemma 4 as follows
 and similarly a relation 
 using 
, also satisfying the requirements of Lemma 4, as follows
 Since these are qfpp-definitions without equality, the corresponding CV-reductions to the bases from Table 2 follows from Lemma 3.

Using Fig. 1 we then see that the only remaining cases for Γ when 
 is when 
 or when 
. This concludes the proof. □

Using qfpp-implementations to further decrease the set of relations in Theorem 9 appears difficult and we therefore make use of more powerful implementations. Let  be the set of all optimal solutions of a

Image 19
instance I. A relation R has a weighted pp definition (wpp-definition) [21] in Γ if there exists an instance I of
Image 19
on variables V such that
 for some 
. The set of all relations wpp-definable in Γ is denoted 
 and we furthermore have that if 
 is finite then
Image 93
is polynomial-time reducible to
Image 19
[21]. If there is a
Image 19
instance I on V such that
 for 
 satisfying 
, then we say that R is qfwpp-definable in Γ. We use 
 for set of all relations qfwpp-definable in Γ. It is not hard to check that if 
, then every instance is mapped to an instance of equally many variables — hence
Image 93
is CV-reducible to
Image 19
whenever 
 is finite.
Theorem 10

Let Γ be a constraint language such that

Image 94
is NP-hard. Then it holds that
Image 95
.
Proof

We need to prove that 
 for every 
. Let us first consider the case of 
. First, note that(†)
 We will see that it is not difficult to obtain a qfwpp-definition of 
 with 
, armed with this information. Let I be the

Image 96
instance over the variables 
 with the single constraint 
, where 
 have the weight 1 and all other variables the weight 0. It is then easy to see that I has exactly three optimal solutions 
, 
, 
, and that
 and
 which implies that 
. Hence, it is rather easy, albeit tedious, to prove that a relation is qfwpp-definable over another relation when given an equality akin to (†). To avoid needless repetition, we have prepared these  definitions in Table 3, from which it is easy to derive the necessary qfwpp-definitions. □

Table 3.  definitions for

Image 17
.
R1	R2	 definition of R1 with R2
3.4. The
Image 33
problem
Let us first remark that the

Image 10
problem does not follow the standard Galois connection in Theorem 1. For a concrete counter example, recall the two relations  and , and consider the problem
Image 97
(crucially, remember that every
Image 13
problem can be seen as a special case of a
Image 33
problem). On the one hand, it is then known that
Image 97
is tractable, but on the other hand, the pp-definable relation 
 results in an NP-hard problem (see, e.g., Theorem 2.11 in Khanna et al. [32]).
Thus, the weak base method is not applicable, and alternative methods are required. For this purpose we use multimorphisms from Cohen et al. [22]. Let Δ be a set of cost functions on , let p be a unary operation on , and let  be binary operations on . We say that Δ admits the binary multimorphism  if it holds that  for every  and 
. Similarly Δ admits the unary multimorphism (p) if it holds that  for every  and 
. We have the following result.

Theorem 11

[22]
Let Δ be a set of finite-valued cost functions on . If Δ admits the unary (0)-multimorphism, the unary (1)-multimorphism or the binary -multimorphism, then

Image 98
is in PO. Otherwise
Image 98
is NP-hard.
Recall that the function 
 equals  and that the minimization problem

Image 40
and the maximization problem Max Cut are trivially CV-reducible to each other. We will make use of (a variant of) the concept of expressibility [22]. We say that a cost function g is ∄-expressible in Δ if
 
 for some tuples 
 over 
, weights 
,  and cost functions 
. It is not hard to see that if every function in a finite set 
 is ∄-expressible in Δ, then
Image 99
. Note that if a unary cost function 
 is expressible in Δ with 
, then we can force a variable to take the constant value c. If we can force variables to the constants 0 and 1, then we can allow tuples 
 over 
 in the ∄-expression, and still obtain a CV-reduction.
Theorem 12

Let Δ be a set of finite-valued cost functions on . If the problem

Image 98
is NP-hard, then
Image 100
.
Proof

The proof consists of two parts. Using the assumption that

Image 20
is NP-hard we will (1) prove that we can ∄-express 
 or force two variables 
 and 
 to 0 and 1, respectively, and (2) (in case we did not already ∄-express 
 in previous step) show that there exists a certain function which is ∄-expressible over Δ, which together with the two constant variables 
 and 
 can ∄-express 
.
Step 1.

Image 20
is NP-hard, so by Theorem 11 we know that Δ does not admit the unary (0)-multimorphism or the unary (1)-multimorphism, unless P = NP. Therefore there are  and 
, 
 such that  and . We may assume 
 and 
.
Define 
 where
 
 

Note that

If 
, then 
 for suitable 
 and 
. This is an ∄-expression, and we are done. Otherwise 
, which means we can force variables 
 and 
 to 0 and 1, respectively, with the term 
 (given sufficiently high weight).

Step 2. Assume now that 
 was not ∄-expressed in the previous step and recall that we have access to variables 
 and 
 that are forced to take values 0 and 1, respectively. We know that Δ does not admit the -multimorphism (by Theorem 11) since

Image 20
is NP-hard by assumption. Hence, there exists a k-ary function  and 
, 
 such that Define 
 where
  for . Note the following:
Set . Now  and(3)
 

If , then 
 for some 
 and 
.

Otherwise, assume . We can do this without loss of generality since the other case is symmetric. Furthermore, we can without loss of generality (by scaling and translating the function h) assume that . Let 
 for some 
 and 
 such that 
 and 
. Then define 
. This function satisfies 
 and 
. Moreover, we have
 
 
 where the inequality follows from (3). Hence, we can ∄-express 
 as 
 for some 
 and 
. □

3.5. The broader picture
The results in Section 3 do not describe the relative complexity between

Image 3
,
Image 8
,
Image 9
, Max-Ones and
Image 10
. We have thus far not been able to precisely pinpoint the complexity of
Image 9
to the other problems, but we readily see that
1.
Image 101
, and
2.
Image 102
-Max Independent Set
Image 103
,
where 
 and 
 are the unary cost functions  and , respectively, and 
 denotes the binary cost function .
We have the following relation.

Lemma 5

Image 104
.
Proof

Note that 
 is ∄-expressible in 
 since
 
 Hence (see Section 3.4),

Image 105
.
To complete the proof, we present a CV-reduction from

Image 106
to
Image 107
. Let 
 and 
 be two fresh variables. We make sure 
 and 
 are not mapped to the same value with the term 
 (with a sufficiently high weight). Let  and note that 
 is invariant under σ in the sense that 
. Hence, if I is an instance of
Image 107
and ϕ is a solution to I of cost C, then  is another solution to I of cost C. We can therefore, without loss of generality, assume that every solution maps 
 to 0 and 
 to 1. Now, every term 
 can be replaced with 
, and every term 
 with 
. □
4. Subexponential time and the exponential-time hypothesis
Recall that the ETH states that 3-

Image 110
[9]. We remind the reader that the ETH can be based on different size parameters (such as the number of variables or the number of clauses) and that these different definitions often coincide [11]. In this section we investigate the consequences of the ETH for the
Image 61
,
Image 62
,
Image 41
, and
Image 32
problems. A direct consequence of Section 3 is that if there exists any finite constraint language Γ or set of cost functions Δ such that
Image 19
,
Image 11
or
Image 20
is NP-hard and in
Image 44
, then
Image 74
is in
Image 44
which implies that the ETH is false [4]. The other direction is interesting too since it highlights the likelihood of subexponential time algorithms for the problems, relative to the ETH. We investigate these questions for
Image 8
,
Image 9
,
Image 55
, and
Image 10
, in Section 4.1–4.4. In Section 4.5 we summarize our results and bring them together with the help of the ETH.
4.1. Lower bounds for surjective satisfiability
Recall from Fig. 7 that if there exists an NP-hard

Image 11
problem in
Image 44
then
Image 111
which contradicts the ETH [4]. Hence, all that remains to show is that every
Image 11
problem is in
Image 44
if the ETH is false, which we accomplish with the following lemma.
Lemma 6

If the ETH is false then for every finite constraint language Γ the problem

Image 67
is in
Image 112
.
Proof

If the ETH does not hold then

Image 113
is in
Image 44
since Γ is finite [4]. We present an SE algorithm for
Image 11
based on an SE algorithm for
Image 113
.
Arbitrarily choose  and let A be an algorithm for

Image 113
that runs in 
 time. Given an instance  of
Image 11
, do the following:
1.
 ‘no’

2.
for every pair of distinct variables , let  ‘yes’ if  or 

3.
return ans

This algorithm answers ‘yes’ if and only if  has a surjective solution. Furthermore, it runs in 
 time, so

Image 11
is in
Image 44
. □
4.2. Lower bounds for propositional abduction
From Theorem 7 we see that if there exists an NP-complete

Image 12
problem in
Image 44
then
Image 114
, too. We now show that this problem cannot be solvable in subexponential time without violating the ETH, which implies that no NP-complete
Image 12
problem is solvable in subexponential time (under the ETH).
Lemma 7

If

Image 115
for some finite constraint language Γ such that
Image 75
is NP-complete then the ETH is false.
Proof

First, assume

Image 116
and that
Image 12
is NP-complete. In particular this implies that the problem
Image 117
via Theorem 7. From Jonsson et al. [4] there exists a  such that 3-SAT-
Image 46
if and only if 3-
Image 118
. Hence, to prove the claim we will give an LV-reduction from 3-SAT-B to
Image 119
.
In Creignou and Zanuttini [33] it is proven that there exists a reduction which, given a SAT formula φ over n variables and m constraints, produces an instance 
 of

Image 120
over 3n variables where 
 contains  binary constraints, and a single constraint of arity  of the form 
, where each 
 is either a positive or negative atom of the form x or ¬x. Since m is linearly bounded with respect to n it therefore follows that 
 contains  binary constraints and a single constraint of arity , of the aforementioned form. Using standard techniques (see, e.g., Section 5.2 in Creignou and Zanuttini [33]) one can then prove that 
 can be pp-defined by 
 requiring only  variables and constraints. Similarly, each binary constraint in 
 can be pp-defined by 
 with a constant number of fresh variables, and if we replace each constraint in 
 in this manner we obtain an instance of
Image 121
with a linear amount of fresh variables and constraints. □
Hence, NP-complete

Image 12
problems are unlikely to be solvable in subexponential time, since this would contradict the ETH. However, we have been unable to strengthen the other direction, showing that every NP-complete
Image 12
problem is in
Image 44
if the ETH is false, and it is currently unclear whether such a result is feasible. We discuss this in greater detail in Section 5.
4.3. Lower bounds for max-ones
We now turn to the unweighted

Image 55
problem, where we obtain a complete understanding of subexponential complexity with respect to the ETH.
Lemma 8

If

Image 122
is in
Image 112
for some finite constraint language Γ such that
Image 122
is NP-hard, then the ETH is false.
Proof

From Jonsson et al. [4] it follows that 3-

Image 123
if and only if
Image 74
-
Image 124
. Combining this with Theorem 9 we only have to prove that
Image 74
-2 LV-reduces to
Image 125
for 
. We provide an illustrative reduction from
Image 74
-2 to
Image 126
; the remaining reductions are presented in Lemma 10, Lemma 14 in the end of this section. Since 
 is the
Image 127
relation with one additional constant column, the
Image 126
problem is basically the maximum independent set problem or, equivalently, the maximum clique problem in the complement graph. Given an instance I of
Image 128
-2 we create for every constraint 3 vertices, one corresponding to each feasible assignment of values to the variables occurring in the constraint. We add edges between all pairs of vertices that are not inconsistent and that do not correspond to the same constraint. The instance I is satisfied if and only if there is a clique of size m where m is the number of constraints in I. Since  this implies that the number of vertices is . □
Hence, we have ruled out the possibility that, assuming the ETH, there could exist a

Image 129
problem which is NP-complete. It is also not difficult to prove the opposite, i.e., that if the ETH is false, then
Image 129
for every Boolean constraint language Γ.
Lemma 9

If the ETH is false, then

Image 130
for every Boolean constraint language Γ.
Proof

Define SNP to be the class of properties expressible by formulas of the type 
 where F is a quantifier-free logical formula, 
 are second order existential quantifiers, and 
 are first-order universal quantifiers. Monadic SNP (MSNP) is the restriction of SNP where all second-order predicates are required to be unary [34]. The associated search problem tries to identify instantiations of 
 that make the resulting first-order formula true. We will be interested in properties that can be expressed by formulas that additionally contain size-constrained existential quantifiers. A size-constrained existential quantifier is of the form ∃S, , where  is the number of inputs where relation S holds, and . Define size-constrained SNP as the class of properties of relations and numbers that are expressible by formulas 
 where the existential quantifiers are allowed to be size-constrained.

If the ETH is false then 3-

Image 65
is solvable in subexponential time. By Impagliazzo et al. [11] this problem is size-constrained MSNP-complete under size-preserving SERF reductions. Hence, we only have to prove that
Image 55
is included in size-constrained MSNP for it to be solvable in subexponential time. Impagliazzo et al. [11] shows that k-SAT is in SNP by providing an explicit formula  where F is a universal formula and S a unary predicate interpreted such that  if and only if x is true. Let k be the highest arity of any relation in Γ. Since k-
Image 65
can qfpp implement any k-ary Boolean relation it is therefore sufficient to prove that
Image 131
is in size-constrained MSNP. This is easy to do with the formula where K is the parameter corresponding to the number of variables that have to be assigned 1. □
Additional reductions for
Image 55
In this section we provide the reductions for

Image 55
which were missing in Lemma 8.
Lemma 10

Image 132
-2 LV-reduces to
Image 133
.
Proof

We reduce an instance I of

Image 74
-2 on n variables and m constraints to an instance of
Image 134
containing at most  variables. Let 
 be two fresh global variables constrained as 
. Note that this forces 
 to 0 and 
 to 1 in any satisfying assignment. Now, for every variable x in the
Image 65
-instance we create an additional variable 
 which we constrain as 
. This correctly implements 
. For the i-th constraint, 
, in I we (1) create three variables 
, and (2) add the constraints
 Note that this correctly defines 
 if 
 are not all assigned 0. Since every variable in the
Image 65
-instance I can occur in at most two constraints we have that . Hence, the resulting
Image 41
instance contains at most  variables. Now, importantly, since x and 
, and 
 and 
, must take different values it holds that the measure of a solution of this new instance is exactly the number of variables 
 that are mapped to 1. Thus, the crucial observation is that one cannot have an optimal solution with objective value  unless one for each block of auxiliary variables 
 assign at least one of them a non-zero value. Hence, for an optimal solution the objective value is  if and only if I is satisfiable. □
Lemma 11

Image 133
LV-reduces to
Image 135
.
Proof

We reduce an instance I of

Image 134
on n variables to an instance of
Image 136
on  variables. Let 
 be fresh variables and constrain them as 
. Note that this forces 
 to 0, and that if 
 is mapped to 0, then so are the variables 
. If 
 is mapped to 1 on the other hand, then 
 can be mapped to 1. For every constraint 
 we create the constraints
 The resulting
Image 136
instance has  variables and has a solution with measure  if and only if I has a solution with measure k. □
Lemma 12

Image 137
LV-reduces to
Image 138
.
Proof

We reduce an instance I of

Image 139
over n variables to an instance of
Image 140
over  variables. Create two fresh variables 
 and constrain them as 
 in order to force 
 and 
 to be mapped to different values. We then create the  variables 
 and constrain them as 
. This forces all of the variables 
 to be mapped to the same value as 
. We can now express 
 using the implementation
 Note that in any optimal solution of the new instance 
 will be mapped to 1 which means that the implementation of 
 given above will be correct. The resulting instance has a solution with measure  if and only if I has a solution with measure k. □
Lemma 13

Image 141
LV-reduces to
Image 142
.
Proof

We reduce an instance of

Image 126
on n variables to an instance of
Image 143
on  variables. Create two new variables 
 and 
 and constrain them as 
. Note that this forces 
 to 0 and 
 to 1. For every variable x we introduce two extra variables 
 and 
 and constrain them as 
. Note that this implements the constraints 
 and 
, and that no matter what x is mapped to exactly one of 
 and 
 is mapped to 1. For every constraint 
 we then introduce the constraint 
. The resulting instance has a solution with measure  if and only if I has a solution with measure k. □
Lemma 14

Image 133
LV-reduces to
Image 144
.
Proof

We reduce an instance of

Image 134
on n variables to an instance of
Image 145
on  variables. Create two new variables 
 and 
 and constrain them as 
. Note that this forces 
 and 
 to be mapped to different values. We then introduce fresh variables 
 and constrain them as 
. This will ensure that every variable 
 is mapped to the same value as 
 and therefore that in every optimal solution 
 is mapped to 0 and 
 is mapped to 1. For every constraint 
 we introduce the constraints
 The resulting instance has a solution with measure  if and only if I has a solution with measure k. □
4.4. Lower bounds for VCSP
For VCSP we have already established that there cannot exist any NP-hard

Image 20
problem in
Image 44
(under the ETH). The other direction appears significantly harder, if true, but we do manage to prove a partial converse for the unweighted VCSP problem with at most  constraints for some fixed  (
Image 146
). We state the following results using
Image 18
as a starting point, rather than the ETH, since it simplifies the proof of the forthcoming Theorem 13.
Lemma 15

If

Image 130
for every finite Boolean constraint language Γ then
Image 147
for every finite set of Boolean cost functions Δ and .
Proof

We first show that if every

Image 129
, then
Image 148
for all Γ, too. Here
Image 149
denotes the minimization variant of
Image 18
where the goal instead is to minimize the number of variables assigned 1. Arbitrarily choose a finite constraint language Γ over . We present an LV-reduction from
Image 149
to
Image 150
. Let 
 be an arbitrary instance of
Image 149
with optimal value K. Consider the instance 
 of
Image 150
where:
 For each variable 
 that is assigned 0, the corresponding variables 
 are assigned 1, and vice-versa. It follows that the optimal value of 
 is . Hence,
Image 148
since
Image 151
.
Now, arbitrarily choose  and a finite set of Boolean cost functions Δ. Since Δ is finite, we may without loss of generality assume that each function  has its range in .

We show that

Image 152
by exhibiting an LV-reduction from
Image 21
to
Image 149
where Γ is finite and only depends on Δ. Given a tuple 
, let 
. Adding 1 to the sum ensures a non-zero value, which is necessary since the value of  corresponds to an index, which starts with 1. For each  of arity k, define
 
 and let 
.
One may interpret 
 as follows: for each 
 the relation 
 contains exactly one tuple 
. If 
, then this is the tuple 
. If 
, then this is the tuple 
 where the 1 is in position 
. We show below how 
 can be used for ‘translating’ each 
 into its corresponding weight as prescribed by f.

Let 
 be an arbitrary instance of

Image 21
where 
. For each variable 
 we begin by introducing a fresh variable 
. Now, assume the instance has an optimal solution with value K. For each term 
 in the sum, do the following:
1.
introduce 
 fresh variables 
,

2.
for each 
 such that 
, introduce 
 fresh variables 
,

3.
introduce the constraint 
,

4.
introduce the constraints 
, and

5.
for each 
, let 
 and do the following if 
: let  and introduce the constraints 
.

It is not difficult to realize that the resulting instance has optimal value 
 given the interpretation of 
 and the following motivation of step 5: the Neq constraints introduced in step 5 ensure that the weight of 
 does not influence the weight of the construction and this explains that we need to adjust the optimal value with 
.

Furthermore, the instance contains at most
 variables where  and 
. By noting that  and that  are constants that only depend on Δ, it follows that the reduction is an LV-reduction. □

4.5. Wrapping up
We have seen several consequences of the ETH in the preceding sections. These results can more generally be related together as follows.

Theorem 13

The following statements are equivalent.

1.
The exponential-time hypothesis is false.

2.
Image 153
for every finite Γ.
3.
Image 153
for some finite Γ such that
Image 67
is NP-hard.
4.
Image 130
for every finite Γ.
5.
Image 130
for some finite Γ such that
Image 122
is NP-hard.
6.
Image 154
for every finite set of finite-valued cost functions Δ and .
Proof

The implication  follows from Lemma 6, and the implication  is trivial. For the implication , first observe from Fig. 7 that if there exists an NP-hard

Image 5
problem in
Image 44
, then
Image 155
, too, which contradicts the ETH [4]. An application of Lemma 9 then gives the implication .
Next, the implication  is trivial, and  follows by Lemma 8. The implication  follows from Lemma 15. We finish the proof by showing . Let  be an instance of

Image 74
-2. Note that I contains at most  constraints. Let f be the function defined by  if 
 and  otherwise. Create an instance of
Image 156
by, for every constraint 
, adding to the cost function the term 
. This instance has a solution with objective value 0 if and only if I is satisfiable. Hence,
Image 74
-
Image 124
which contradicts the ETH [4]. □
5. Future research
We have studied the fine-grained complexity of several variants and extensions of the Boolean satisfiability problems. In many cases we were able to identify an ‘easiest NP-hard problem’ in each class, which we were able to use in order to relate the complexity of these problems to the ETH. Interestingly, for

Image 8
and
Image 55
we were able to obtain a complete understanding of the possibility of obtaining subexponential algorithms, under the ETH. While the results for
Image 9
and
Image 10
are not quite as strong, it is worth mentioning that our results, to the best of our knowledge, are still the first of their kind for these problems. Let us now touch upon some directions for future research.
The abduction problem  While we were able to identify an ‘easiest NP-complete

Image 9
problem’, several questions remain unanswered. First, it would be interesting to generalize the study to infinite constraint languages, where
Image 9
is more interesting than the other problems under consideration due to the existence of NP-intermediate problems [31], i.e., there exists an infinite 
 such that
Image 157
is neither tractable, nor NP-complete, if P ≠ NP. Despite this, is it possible to use the algebraic approach to study fine-grained complexity of NP-intermediate problems? Here, the good news are that the algebraic aspect works equivalently well for infinite sets of relations, e.g., the co-clone 
 admits a weak base [28]. The more challenging aspect is thus to apply the algebraic approach in such a way that it leads to interesting reductions. Is it, for example, possible to find an ‘easiest NP-intermediate
Image 9
problem’ with respect to the co-clone 
? Another interesting direction is to perform a more careful analysis of the easiest NP-complete problem
Image 158
: is it possible to relate it to the easiest
Image 3
problem, or are the two problems fundamentally incomparable?
Weighted versus unweighted problems  Theorem 13 only applies to unweighted problems and lifting these results to the weighted case does not appear straightforward. We believe that some of these obstacles could be overcome with generalized sparsification techniques and provide an example proving that if any NP-hard

Image 19
problem is in
Image 44
, then
Image 43
can be approximated within a multiplicative error of  (for any ) in subexponential time. Assume that
Image 159
is NP-hard, and arbitrarily choose . Let
Image 160
be the
Image 43
problem restricted to graphs  where . We first prove that
Image 160
is in
Image 44
for arbitrary . By Theorem 10, we infer that
Image 161
. Given an instance  of
Image 160
, one can introduce one fresh variable 
 for each  and one fresh variable 
 for each edge . For each edge , we then constrain the variables 
 and 
 as 
 where 
. It can then be verified that the maximum value of 
 for an optimal solution h (where 
 is the weight associated with the edge e) equals the weight of a maximum cut in . This is an LV-reduction since . Now consider an instance  of the unrestricted
Image 43
problem. By Batson et al. [35], we can (in polynomial time) compute a cut sparsifier 
 with only 
 edges (where 
 is a constant depending only on ϵ), which approximately preserves the value of the maximum cut of  to within a multiplicative error of . By using the LV-reduction above from
Image 162
to
Image 19
, it follows that we can approximate the maximum cut of  within  in subexponential time.