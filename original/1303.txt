Abstract
The key escrow problem is one of the main barriers to the widespread real-world use of identity-based encryption (IBE). Specifically, a key generation center (KGC), which generates secret keys for a given identity, has the power to decrypt all ciphertexts. At PKC 2009, Chow defined a notion of security against the KGC, that relies on assuming that it cannot discover the underlying identities behind ciphertexts. However, this is not a realistic assumption since, in practice, the KGC manages an identity list, and hence it can easily guess the identities corresponding to given ciphertexts. Chow later amended this issue by introducing a new entity called an identity-certifying authority (ICA) and proposed an anonymous key-issuing protocol. Essentially, this allows the users, KGC, and ICA to interactively generate secret keys without users ever having to reveal their identities to the KGC. Unfortunately, since Chow separately defined the security of IBE and that of the anonymous key-issuing protocol, his IBE definition did not provide any formal treatment when the ICA is used to authenticate the users. Effectively, all of the subsequent works following Chow lack the formal proofs needed to determine whether or not it delivers a secure solution to the key escrow problem.

In this paper, based on Chow's work, we formally define an IBE scheme that resolves the key escrow problem and provide formal definitions of security against corrupted users, KGC, and ICA. Along the way, we observe that if we are allowed to assume a fully trusted ICA, as in Chow's work, then we can construct a trivial (and meaningless) IBE scheme that is secure against the KGC. Finally, we present two instantiations in our new security model: a lattice-based construction based on the Gentry–Peikert–Vaikuntanathan IBE scheme (STOC 2008) and Rückert's lattice-based blind signature scheme (ASIACRYPT 2010), and a pairing-based construction based on the Boneh–Franklin IBE scheme (CRYPTO 2001) and Boldyreva's blind signature scheme (PKC 2003).

Keywords
Identity-based encryption
Key escrow problem
Lattices
Pairings

1. Introduction
1.1. Identity-based encryption
Public key cryptography has long been in widespread real-world use, but it has the issue that public keys look like random strings. Consequently, public key infrastructure (PKI) has also been developed to prove the validity of public keys. Identity-based encryption (IBE) [1] can reduce the costs associated with PKI systems by enabling users to select arbitrary strings (such as e-mail addresses or bio-information) as public keys. A special entity called the key-generation center (KGC) maintains a master public/secret key pair . The KGC (implicitly) confirms the validity of each user  and then issues an associated secret key 
 using the master secret key . Once the master public key  has been downloaded from the KGC, anyone can encrypt messages to any user as long as they know the recipient's .

1.2. Key escrow problem and current solutions
The key escrow problem is a significant barrier to the widespread real-world use of IBE, and is a severe concern for communication privacy. Notably, the KGC potentially has the power to decrypt all ciphertexts, since it can generate secret keys for any . Several attempts have already been made to deal with this issue by reducing the amount of trust on the KGC.

One line of research is to make users participate in the secret key-generation process. In certificateless encryption (CE) [2], in addition to the secret key 
 generated by the KGC, each users generate their own public/secret key pair . Here, both the  and  are required to encrypt messages, so decryption involves both 
 and . Effectively, the KGC can no longer decrypt ciphertexts since it does not know . However, requiring additional individual public keys detracts one of the main merits of IBE since the size of public information grows linearly with the number of users in the system. Garg et al. [3], [4] proposed registration-based encryption (RBE), which improved the CE approach by having the KGC aggregate and succinctly compress all users' public keys into the master public key . Instead of generating a secret key 
 for each user, the KGC only needs to update and maintain  using the pair  of each user . As in standard IBE, encryption and decryption only require  and , respectively. Recently, Goyal and Vusirikala extended Garg et al.'s works to consider the verifiability of the key accumulation process [5]. One drawback when implementing RBE in practice, however, is that  must be periodically updated by the KGC, and the users must fetch this updated information.

Another approach is to define an independent notion of security against the KGC for standard IBEs. Here, we call an IBE standard if encryption requires only a static  and , and decryption requires only 
, as originally defined in [1]. We want to define a notion that captures some type of anonymity [6], [7] for the KGC. In other words, we want to guarantee that ciphertexts remain anonymous and that the KGC cannot determine the correct identity needed to decrypt a given ciphertext. Based on this high-level idea, Izabachène and Pointcheval [8] formalized anonymity concerning the KGC for identity-based key encapsulation mechanisms (IB-KEMs). However, as Chow [9] pointed out, their definition is incomplete since it considers the situation where an adversary can only obtain the challenge ciphertext, whereas, in a standard IB-KEM, adversaries can obtain both the challenge ciphertext and the corresponding session key. In order to define a more stringent notion of security against the KGC, Chow [9] introduced the notion of KGC anonymous ciphertext indistinguishability (ACI-KGC), which guarantees that the KGC cannot obtain any information about the corresponding plaintext from a ciphertext if the user's identity is chosen randomly and is unknown to the KGC. However, as he noted, requiring ACI-KGC is still insufficient in practice: the KGC typically manages a list of issued identity/secret key pairs, so it could decrypt any ciphertext via brute force by running the decryption algorithm against all the secret keys issued so far. In other words, even though ACI-KGC is a well-motivated security definition, it does not capture real-world scenarios. To resolve this gap between the security notion and practical implementation, Chow also introduced, in the same paper, a new entity called an identity-certifying authority (ICA) and defined an anonymous key-issuing protocol. In this protocol, the ICA authenticates the user's identity  by providing them certificates. The user can then use this certificate to interact with the KGC and obtain 
 without revealing their identity , an idea reminiscent of blind IBEs [10], [11].1 Since the KGC is now outsourcing the work of authenticating users to the ICA, it will no longer know which identities it has generated secret keys for.

Chow's work [9] was a significant step toward defining a standard IBE scheme that can resolve the key escrow problem. However, in this research, we identify some deficiencies in this formulation and show that the definition must be refined. First, as explained above, Chow introduced the ICA and proposed an anonymous key-issuing protocol involving the user, the KGC, and the ICA to make the definition more practical. However, unfortunately, ACI-KGC and security of the anonymous key-issuing protocol were separately defined; Chow defined ACI-KGC only between the user and the KGC and did not provide any formal treatment when the ICA is used to authenticate the users. He provided some informal argument suggesting that something similar to ACI-KGC should hold for a standard IBE scheme in the presence of the ICA. However, on closer look, ACI-KGC is not a notion which can be naturally extended to such scenarios.2 In fact, in case the ICA is fully trusted, as in Chow's work, we observe that there exists a trivial construction that meets the definition while such a construction should be deemed insecure in practice. Consider the following IBE scheme, defined between the users, the KGC, and the fully trusted ICA: the ICA plays the role of the KGC in a standard IBE scheme, and the KGC does nothing. It is easy to see that this construction achieves ACI-KGC security since the KGC holds no secret information, and standard anonymous IBE readily implies ACI-KGC. We have simply transferred all the trust from the KGC to the ICA and also deferred the key escrow problem to it. This shows that, for a well-defined and well-motivated security notion, we cannot fully trust the ICA. Considering the relevance of key escrow problems for IBE in practice, we must provide a formal treatment of ACI-KGC in the presence of an ICA, which avoids this insecure construction. We remark that all subsequent works [12], [13] have followed Chow's definition. Finally, since all prior schemes are based on pairing, constructing a post-quantum IBE under any sensible security notion that resolves the key escrow problem remains open.

1.3. Our contribution
In this paper, we formalize a standard IBE scheme that captures the key escrow problem, and provide two instantiations based on lattices and pairings. Our formalization is inspired by Chow's original work and is based on the idea of creating an ICA to authenticate the system's users. We describe this scheme as blind IBE with certified identities to differentiate between prior formalizations. This terminology follows from the fact that the proposed secret key-generation process can be seen as a blind IBE combined with an ICA to certify user identities. Under our new definition, we propose a lattice-based and pairing-based constructions. At a high level, both of our constructions follow a similar template by carefully combining a standard anonymous IBE scheme (that is insecure under key escrows) with an appropriate blind signature scheme. Both constructions are secure in the random oracle model. We note that as far as we are aware, this is the first post-quantum IBE to resolve the key escrow problem based on Chow's work.3 Our contributions are summarized in more detail in the following.

Formalization of a blind IBE with certified identities. We formalize a standard IBE scheme (which we call blind IBE with certified identities) that resolves the key escrow problem based on Chow's work [9]. Our definition involves three entities: the users, the KGC, and the ICA. The ICA is responsible for authenticating users by issuing certificates, while the KGC is responsible for (blindly) generating secret keys for users. We define three security notions, one for each of the three entities involved. Specifically, we define indistinguishability and anonymity against chosen plaintext attacks for the users (IND-ANON-CPA), the KGC (IND-ANON-KGC), and the ICA (IND-ANON-ICA). The first of these, IND-ANON-CPA, captures the standard concept of IBE security, while the second and third model cases where the KGC or the ICA is malicious. Our IBE formalization takes all the aforementioned issues into account: the syntax captures anonymous key-issuing via IND-ANON-KGC security, and the ICA is no longer fully trusted due to our additional definition of IND-ANON-ICA security. Our formalization can be seen as a natural and formal extension of Chow's idea of combining ACI-KGC security with an anonymous key-issuing protocol.

Lattice-based instantiation. We provide a concrete instantiation of a blind IBE with certified identities, based on the learning with errors (LWE) problem in the random oracle model. Our construction is based on the lattice-based IBE scheme by Gentry–Peikert–Vaikuntanathan (GPV-IBE) [17], which is arguably the most efficient IBE scheme based on standard lattice assumptions. The two main technical hurdles involved in our construction are as follows.

(a) Realizing anonymous key issuing. Unlike standard IBE, where the KGC knows (i.e., authorizes via some certification mechanism) which ID it is issuing secret keys to, IBE schemes that deal with the key escrow problem cannot allow the KGC to know the IDs corresponding to the secret keys. This is the main reason why the ICA was introduced: it authorizes users by providing them with certificates that do not leak their ID to the KGC, which they can then use to obtain secret keys from the KGC. The main problem here is thus figuring out what the certificate should look like and how to combine it with GPV-IBE's key-generation process.

Our main observation is that the secret keys of GPV-IBE are only a short vector over 
, and the key-generation process of GPV-IBE can be viewed as a signing algorithm through the Naor transformation [14]. Concretely, a secret key for , which is a short vector over 
, can be seen as a signature for some message (related to ) over 
. At a high level, the user in our construction will end up receiving two certificates: one from the ICA and another from the KGC, and then the user will combine them to form a secret key for the GPV-IBE. However, the two certificates must be related to one specific ID in some meaningful way, or otherwise, the user can simply mix-and-match different certificates together. To this end, we build on the lattice-based blind signature scheme proposed by Rückert [18] and use it in a way so that the KGC can blindly sign to a vector over 
 which implicitly commits to an ID. We note that Rückert [19] later mentions that the blind signature scheme in [18] is vulnerable in some use cases; however, the way we use it avoids this problem.

(b) Satisfying IND-ANON-KGC security. Informally, IND-ANON-KGC security stipulates that even if the KGC receives polynomially many ciphertexts for the same ID, as long as the ID is sampled from a sufficiently high min-entropy source, then it cannot tell whether the ciphertexts are real or sampled uniformly at random from the ciphertext space. In other words, even though the KGC can construct secret keys for any ID, it should not be able to identify the right ID corresponding to the ciphertexts with more than negligible probability. Below we recall the ciphertext of GPV-IBE: 
 and 
, where  is the plaintext, 
 is included in , 
 is a hash value (derived from the random oracle), 
 is a uniformly random vector over 
, and  are small “noise” terms.

At first glance, IND-ANON-KGC security seems highly related to the notion of multi-challenge IND-CPA security of IBE [20], where an adversary can obtain polynomially many challenge ciphertexts. Therefore, it may seem that the security proof of IND-ANON-KGC follows from a simple hybrid argument since so does standard multi-challenge security. However, this intuition is inaccurate. The key difference between the two security notions is that in IND-ANON-KGC the KGC holds the master secret key to the IBE scheme, i.e., the trapdoor for the lattice generated by A. This prevents us from using a hybrid argument. Moreover, since the adversary for IND-ANON-KGC (which is the KGC) has the power to fully recover the randomness s from 
 in the ciphertext, this prevents us from using an entropy-based argument on the vector s to argue uniformness of 
, as was done in previous proofs for GPV-IBE in the multi-challenge setting [21]. We, therefore, depart from previous proof techniques for GPV-IBE to prove IND-ANON-KGC of our proposed IBE scheme. We take advantage of the fact that the adversary does not know the ID corresponding to the challenge ciphertext. Note that to the contrary, in the multi-challenge setting, the adversary was able to specify the ID that is being encrypted. In our security proof, we use the fact that 
 is distributed as a uniformly random vector from the view of the adversary in the random oracle model and view 
 as the LWE secret, rather than the encryption randomness s as in previous proofs.

Pairing-based instantiation. We also provide an instantiation of a blind IBE scheme with certified identities, based on the DBDH problem in the random oracle model. The high-level approach is similar to our lattice-based scheme: we combine an anonymous IBE scheme with a blind signature scheme where the blind signatures can be viewed as secret keys of the anonymous IBE scheme. As for the building blocks, we use the anonymous IBE scheme of Boneh-Franklin (BF-IBE) [14] and the blind signature of Boldyreva [22]. Since Boldyreva's blind signature scheme is based on the Boneh-Lynn-Shacham (BLS) signature scheme [23], the blind signature can be reused as a secret key of the BF-IBE scheme.

We note that Chow [9] constructs a blind IBE scheme with certified identities with a different design approach (albeit without a formal security proof as mentioned above). Unlike our construction using a specific blind signature scheme, he uses a commitment scheme with some additional property and combines it with the anonymous IBE scheme of Gentry [24]. In the same paper, he also briefly mentions the possibility of realizing a blind IBE scheme with certified identities based on the more efficient BF-IBE by combining it with Boldyreva's blind signature scheme. However, details on how to combine them are not provided.

Differences from the conference version. The preliminary version appeared at the 24th European Symposium on Research in Computer Security (ESORICS 2019) [25] that mainly focused on a lattice-based constriction. In the current version, we additionally constructed a pairing-based scheme (Section 5). Moreover, we added the security proofs for our lattice-based scheme that were omitted in the preliminary version (Section 4.2).

2. Preliminaries
Notations. For a distribution or random variable X we write  to denote the operation of sampling a random x according to X. For a set S, we write  as a shorthand for . For a vector 
, denote  as the standard Euclidean norm. For a matrix 
, denote  as the length of the longest column and 
 as the longest column of the Gram-Schmidt orthogonalization of R. We denote 
 as the largest singular value of R. Finally, denote  as an interactive protocol between two PPT algorithms A and B.

2.1. Background on lattices
Lattices and Gaussian measures. A (full-rank-integer) m-dimensional lattice Λ in 
 is a set of the form 
, where 
 are m linearly independent vectors in 
. We call B the basis of the lattice Λ. For any positive integers  and , a matrix 
 and a vector 
, we define the lattices 
 and 
.

Lemma 1

[17]
Let  be positive integers such that . Let σ be any positive real such that . Then for 
 and 
, the distribution of  is statistically close to uniform over 
.

Furthermore, fix 
. Then the conditional distribution of 
 given  for a uniformly random A in 
 is statistically close to 
.

Lemma 2

[17]
Let  be positive integers with , , and u be an arbitrary vector in 
. Then, for all but a 
 fraction of 
, if we sample a vector 
, we have .

Lemma 3

Noise rerandomization, [26]
Let  be positive integers and r a positive real satisfying . Let 
 be arbitrary and z chosen from 
. Then there exists a PPT algorithm  such that for any 
 and positive real 
,  outputs 
, where 
 is distributed statistically close to 
.

Sampling algorithms. The following lemma states useful algorithms for sampling short vectors from lattices.

Lemma 4

[([17], [27]] Let  be integers with .

•
: There exists a randomized algorithm that outputs a matrix 
 and a full-rank matrix 
, where 
 is a basis for 
, A is statistically close to uniform and 
.

•
: There exists a randomized algorithm that, given a matrix 
, a vector 
, a basis 
 for 
, and a Gaussian parameter 
, outputs a vector 
 sampled from a distribution which is -close to 
.

Hardness assumption. We define the Learning with Errors (LWE) problem introduced by Regev [28].

Definition 1 Learning with errors

For integers , , , an error distribution  over 
, and a PPT algorithm , the advantage for the learning with errors problem 
 of  is defined as 
 where 
, 
, 
, and . We say that the  assumption holds if 
 is negligible for all PPT algorithm .

We note adding the noise term  to the uniform element in 
 is done intentionally. This is only a syntactical change to make the proof using 3 during the security proof easier as done in prior works [26], [21].

For prime q and , the (decisional) 
 for  has been shown by Regev [28] via a quantum reduction to be as hard as approximating the worst-case  and  problems to within 
 factors in the 
-norm in the worst case. In the subsequent works, (partial) dequantumization of the reduction were achieved [29], [30].

2.2. Background on pairings
Bilinear groups. We define bilinear groups as follows.

Definition 2 Bilinear groups

Let p be a λ-bit prime,  and 
 be groups of order p, 
 be a bilinear map (pairing), and g be a generator of . We require bilinearlity: for all 
 and 
, 
, and non-degeneracy:  hold. We say that 
 is a bilinear group.

Hardness assumption. We define the Decision Bilinear Diffie-Hellman (DBDH) problem as follows.

Definition 3 DBDH

For a PPT algorithm , the advantage of the DBDH problem of  is defined as 
 where 
 and 
 is a bilinear group with a λ-bit prime p. We say that the  assumption holds if 
 is negligible for all PPT algorithm .

2.3. General primitives
Pseudorandom function. We provide the standard definition of pseudorandom function.

Definition 4 Pseudorandom function

A pseudorandom function is defined by a PPT algorithm , where , , and  are sets (implicitly) parameterized by the security parameter λ, and we further assume  is an efficiently sampleable set. We say the PRF is pseudorandom if the advantage
 is negligible for any PPT adversary  where . Here,  is a random function that returns uniformly random elements over .

In the random oracle model, a hash function can be used as a PRF. In case we use multiple independent PRFs in a scheme, we can append the index of the PRF with the actual input and feed it to the hash function.

Digital signature scheme. We define a deterministic digital signature scheme where the randomness used to sign a message is derived deterministically from the signing key and the message. Using PRFs, any digital signature scheme can be derandomized.

Definition 5 Digital signatures

A digital signature scheme 
 with message space 
 is a triple of polynomial time algorithms , ,  of the following form:

:
The key generation algorithm takes as input the security parameter 
 and outputs a verification key 
 and signing key 
.

:
The (deterministic) signing algorithm takes as inputs the signing key 
 and message 
, and outputs a signature 
.

:
The verification algorithm takes as inputs the verification key 
, message 
 and signature 
, and outputs ⊤ if the signature is valid and outputs ⊥ otherwise.

Correctness. We say a digital signature scheme is correct if for all , messages 
, 
, 
, we have 
.

Eucma security. The security notion of existential unforgeability under an adaptive chosen message attack () is defined by the following game between an adversary  and a challenger.

•
Setup: The challenger runs 
 and provides  the verification key 
.

•
Signature Queries: When  submits a message 
, the challenger responds by returning 
.

•
Forgery: Finally,  outputs a pair 
⁎
⁎
. The adversary  wins if 
⁎
⁎
 and 
⁎
 was not submitted by  as a signature query.

We say 
 is  secure if the advantage
 is negligible for any PPT .

3. Blind identity-based encryption with certified identities
In this section, we present a new and secure IBE formalization that resolves the key escrow problem. As mentioned in the introduction, we refer to this primitive as blind IBE with certified identities, since the secret key-generation process can be seen as blind IBE [10], [11] with an ICA to certify users' identities. For simplicity, we occasionally call it “IBE” for simplicity.

In our scheme, users first authenticate themselves with the ICA to obtain certificates, which they then use to run an interactive protocol with the KGC and construct secret keys 
 for use as in standard IBE. Here, the KGC never knows which user  it is interacting with, and in particular, this implies that it does not know the 
. We assume that users communicate with the ICA and the KGC via secure channels. Note that we use the same encryption and decryption algorithms as in standard IBE.

Definition 6 Blind IBE with certified identities

A blind IBE scheme with certified identities 
 consists of the following PPT algorithms:

:
The setup algorithm takes as input a security parameter 
, and outputs a public parameter . We assume the identity space  and the message space  are defined by . Moreover, we assume  are implicitly provided as input to all algorithms.

:
The setup algorithm run by KGC takes as input , and outputs a master public key  and a master secret key .

:
The key-generation algorithm run by ICA takes as input , and outputs a certificate verification key  and a certificate-issuing key .

:
The certificate-issuing algorithm run by ICA takes as inputs a certificate verification key , certificate-issuing key  and an identity , and outputs a certificate  and a trapdoor information .

:
The encryption algorithm run by a user takes as inputs the master public key , an identity  and a message , and outputs a ciphertext .

:
The decryption algorithm run by a user takes as input the master public key , a secret key 
 and a ciphertext , and outputs  or ⊥.

:
The interactive key-issuing protocol between a user and the KGC involves two interactive algorithms  and . The user and the KGC interactively run the  algorithm and the  algorithm, respectively, as follows.

User:
The user takes as input , , ,  as specified by the input of , and sends a first-round message 
 to KGC.

KGC:
The KGC takes as input , ,  as specified by the input of  along with the message 
 sent by the user, and returns a second-round message 
 to the user.

User:
On input the message 
 from the KGC, the user (locally) outputs either 
 or ⊥.

We denote  to indicate that the final output obtained by the user and the KGC are the secret key 
 and an empty string ϵ, respectively. Note that depending on what the KGC responds as the second message 
, 
 may be set to ⊥. Furthermore, we call 
 as the transcript of the protocol.

Correctness. For all , all , and all , 
 holds with overwhelming probability where it is taken over the randomness used in running 
, , , , 
, and .

Remark 1 On the round complexity of key issuing

The above definition only considers a two-move key-issuing protocol. One can easily generalize the definition to a multi-move protocol, however, we restricted it to a two-move protocol for simplicity. Indeed, the instantiation we provide in Section 4 and Section 5 will be two-move.

Security against users. As in standard IBE, we consider the notion of security against corrupted users and define indistinguishability against chosen plaintext attacks. We call this IND-ANON-CPA, to explicitly indicate that it implies anonymity. Broadly speaking, this differs from other similar definitions or standard IBE in that an adversary  can access the certifying oracle, that will output certificates for any  (except the challenge identity 
⁎
), and can also supply the obtained certificates to the key-generation oracle. Note that we do not consider an adversary  that can obtain a certificate for 
⁎
, since this will allow  to trivially break security. This corresponds to the assumption that, in practice, an adversary cannot obtain a certificate for the challenge identity 
⁎
.

Definition 7 IND-ANON-CPA

We define IND-ANON-CPA security by the following game between a challenger and a PPT adversary . Below, let  be a sampling algorithm that takes a master public key as input and outputs an element in the ciphertext space.

•
Setup. At the outset of the game, the challenger runs 
, , , and initializes an empty list . The challenger further picks a random coin  and keeps it secret. The challenger gives  to . After this,  can adaptively make the following three types of queries to the challenger in arbitrary order: certificate, secret key, and challenge queries.  can query the first two arbitrarily polynomially many times and the third only once.

Certificate Query:
If  submits  to the challenger, the challenger computes  and returns  to . It then stores  to IDList.

Secret Key Query:
If  submits a first-round message 
 to the challenger, the challenger runs the  algorithm taking as inputs , ,  and the message 
, and obtains a second-round message 
. It then returns 
 to .

Challenge Query:
If  submits 
⁎
⁎
 to the challenger where 
⁎
, 
⁎
, and 
⁎
, the challenger proceeds as follows: If , the challenger returns 
⁎
⁎
⁎
. Otherwise, if , the challenger returns 
⁎
.

•
Guess.  outputs a guess 
 for . We say that 
 is IND-ANON-CPA secure if the advantage
 is negligible for any PPT adversary .

Security against the KGC. We also consider the notion of security against the honest-but-curious KGC, which follows the protocol but attempts to obtain information about the underlying plaintexts from the observed ciphertexts. This is a more stringent and practical security notion than the corresponding notion informally stated in [9]. A more detailed explanation on the difference between prior works is provided in Remark 2. In brief, our definition guarantees that if the KGC runs, i.e., generates secret keys as specified, it cannot obtain any information about the corresponding identities or plaintexts from ciphertexts, even if it uses knowledge obtained via the key-issuing protocol.

At the start of the security game, the adversary  is given the master secret key  along with all public information . In addition,  is allowed to access two oracles, namely, the key-generation and encryption oracles. First,  obtains the secret key 
 for a randomly chosen identity  from the key-generation oracle. This captures the scenario where an unknown user  generates their secret key 
 via executing  with the KGC. The identities sent to the key-generation oracle are stored in an identity list . In addition, for any plaintext  and any  in ,  can ask for a ciphertext  from the encryption oracle. This captures the scenario where the KGC can observe ciphertexts for all users to whom it has issued secret keys. In the challenge phase,  specifies the challenge identity 
⁎
 from  (and submits an arbitrary message 
⁎
) to obtain the challenge ciphertext 
⁎
. Note that  does not specify  nor 
⁎
 itself, but simply specifies the indices in . It is clear that if ciphertexts reveal any information about the corresponding identities,  could easily win the game by creating 
⁎
. In particular, our definition captures both indistinguishability and anonymity.

Definition 8 IND-ANON-KGC

We define IND-ANON-KGC security by the following game between a challenger and a PPT adversary . Below, let  be a sampling algorithm that takes a master public key as input and outputs an element in the ciphertext space.4

•
Setup. At the outset of the game, the challenger runs 
, ,  and initializes an empty set  and a counter 
. The challenger further picks a random coin  and keeps it secret. The challenger gives  to . After this,  can adaptively make the following three types of queries to the challenger in an arbitrary order: encryption, issue key, and challenge queries.  can query the first two arbitrarily polynomial many times and the third only once.

Encryption Query:
If  submits an index i and a message  to the challenger, the challenger first checks if 
 where [0] is defined as the empty set. If not, the challenger forces  to output a random coin 
 in . Otherwise, the challenger retrieves the i-th entry  of  and returns .

IssueKey Query:
If  makes an IssueKey query, the challenger first randomly samples  and computes . It then runs  on inputs , , ,  to generate the first-round message 
 and returns 
 to . Finally, the challenger stores  to  and updates 
.

Challenge Query:
If  submits 
⁎
⁎
 to the challenger where 
⁎
, the challenger first checks if 
⁎
. If not, the challenger forces  to output a random coin 
 in . Otherwise, the challenger proceeds as follows: The challenger first retrieves the 
⁎
-th entry 
⁎
 of . Then, if , the challenger returns 
⁎
⁎
⁎
. Otherwise, if , the challenger returns 
⁎
.

•
Guess.  outputs a guess 
 for . We say that 
 is IND-ANON-KGC secure if the advantage
 is negligible for any PPT adversary .

Remark 2 Differences from the existing definition

As described above, our idea is based on Chow's work [9]. However, Chow's notion of security against the KGC (ACI-KGC) is defined for standard IBE under the assumption that the KGC does not know the identities used in the system. However, this assumption is generally invalid since, in practice, the KGC manages identity lists in order to identify users before generating their keys.5 By contrast, IND-ANON-KGC is defined for a version of IBE where the KGC generates secret keys without having access to such an identity list, meaning that the key-generation process does not violate the real-world usage.

Security against the ICA. Unlike Chow's work [9] that only considered a fully trusted ICA, we aim to define security against a potentially malicious ICA. However, such a definition is difficult. A malicious ICA can generate certificates for any identity  and thereby obtain the corresponding secret keys by impersonating the user and interacting with the KGC. Therefore, in principle, we cannot allow the ICA to have arbitrary access to the key-generation oracle (i.e., interacting with the KGC). Given this, we model the malicious ICA to have the capability of generating a potentially malicious key pair 6 while disallowing it to have access to the key-generation oracle. Unlike Chow's definition, our definition prevents to construct a trivial IBE scheme secure against the KGC mentioned in the introduction; the ICA plays the role of the KGC in a standard IBE scheme and the KGC does nothing.

Definition 9 IND-ANON-ICA

We define IND-ANON-ICA security by the following game between a challenger and a PPT adversary . Below, let  be a sampling algorithm that takes a master public key as input and outputs an element in the ciphertext space.

•
Setup. At the outset of the game, the challenger runs 
 and . The challenger picks a random coin  and keeps it secret. The challenger gives  to . Then,  can make the following challenge query once.

Challenge Query:
If  submits 
⁎
⁎
 to the challenger where 
⁎
 and 
⁎
, the challenger proceeds as follows: If , the challenger returns 
⁎
⁎
⁎
. Otherwise, if , the challenger returns 
⁎
.

•
Guess.  outputs a guess 
 for . We say that 
 is IND-ANON-ICA secure if the advantage
 is negligible for any PPT adversary .

Remark 3

One can consider a stronger definition than what we define above; the malicious ICA is allowed to obtain secret keys for any 
⁎
 during the game. The reason why we do not define this stronger notion is that, compared to our weaker definition, it seems to only capture some additional unnatural scenarios. In practice, if the ICA can impersonate any user 
⁎
 and interact with the KGC, it is only fair to assume that it is also able to impersonate 
⁎
, and hence, obtain a secret key for 
⁎
 by interacting with the KGC. Nonetheless, we like to point out that our construction appearing in the next sections can in fact be proven to satisfy such a stronger definition.

4. Lattice-based construction
4.1. Proposed IBE scheme from lattices
In this section, we present our lattice-based scheme. This combines the GPV-IBE scheme [17] with Rückert's full-domain-hash style lattice-based blind signature scheme [18]. Although Rückert [19] later found out [18] that his signature scheme is vulnerable (to an attack we will explain later), fortunately, this vulnerability does not affect our scheme. Informally, this is because we can guarantee that the KGC only issues a secret key when it sees a valid certificate (presumably signed by the ICA).

Construction. Let the identity space  of the IBE scheme 
 be 
⁎
. In practice, by using collusion resistant hash functions, we can set 
 for . Here, we occasionally treat elements in 
 as binary strings over 
 through some fixed canonical embedding. Let  be any pseudorandom function with appropriate domain  and range . I.e., let  include  and the set of all the first-round messages 
, and let range  include an appropriate length of randomness used by algorithms  and . Finally, let 
, ,  be a deterministic digital signature scheme with message space 
 where the randomness used to sign a message is derived deterministically from the signing key and the message. Using PRFs, any digital signature scheme can be derandomized. We assume that 
 provides the standard security notion of existential unforgeability under an adaptive chosen message attack ().

:
Choose positive integers  and prime q, and output 
, where 
⁎
 is a hash function modeled as a random oracle.

:
Run 
 and sample a PRF key 
. Then, output a master pubic key 
 and a master secret key 
.

:
Run 
 and sample a PRF key 
. Then, output a certificate verification key 
 and a certificate issuing key 
.

:
Parse 
 and compute 
. Then, sample a short vector 
 and compute 
. Furthermore, compute 
 and 
. Finally, output a certificate 
 and trapdoor information 
. Here, we assume all the randomness used in this algorithm is derived from 
.

:
Compute 
. To encrypt a message , sample 
, 
, and 
, and compute 
 and 
. Finally, output a ciphertext 
.

:
Parse 
 and 
. Compute 
. Output 0 if w is closer to 0 than to  modulo q, and 1, otherwise.

:
The user and the KGC interactively runs  and , respectively (Fig. 1).

User:
On input , , , set the first-round message 
 and send 
 to the KGC. Here, 
.

KGC:
On input , ,  and the first-round message 
, parse 
 and 
. If 
, then set 
 and send 
 to the user. Otherwise, parse  and 
. Then, sample a short vector 
, set 
, and send 
 to the user. Here, we assume all the randomness used in this algorithm is derived from 
.

User:
If 
, then output ⊥. Otherwise, parse 
 and 
, set 
 and (locally) output the secret key 
.

Fig. 1
Download : Download high-res image (99KB)
Download : Download full-size image
Fig. 1. Flow of the key-issuing protocol (lattice-based).

Remark 4 Generating randomness via PRFs

Here, we generate the randomness used by the  and  algorithms via PRFs. This has the effect of only allowing the adversary to obtain one valid certificate  per identity  and one valid second-round message 
 per first-round message 
. We require this condition during the security proof for reasons similar to those for other lattice-based IBE schemes [17], [31], [32].

Remark 5 Role of certificates

If the validity of  is not checked, then users can obtain information about the master secret key as follows. First, the user samples 
 from 
, computes 
, and then sends 
 directly to the KGC, which returns 
 such that 
. If we let 
, then 
. This means that the user has obtained an e satisfying . If enough users collude together, then we can recover a trapdoor 
 for A such that 
. Thus, for the security proof, we must require that users cannot obtain such an e. This attack has been identified by Rückert [19] as an issue in constructing a full-domain-hash style lattice-based blind signature scheme. In our scheme, users have no choice but to use the 
 issued by the ICA unless they can forge , and this issue does not appear.

Correctness. The following lemma states the correctness of our blind IBE scheme with certified identity.

Lemma 5 Correctness

Suppose the parameters  and 
 satisfy  and 
. Then our scheme is correct with overwhelming probability.

Proof

If the key issuing protocol between the user and the KGC is run correctly, then any user  will obtain a secret key 
 such that 
. Let . Then when we run  with 
, we obtain 
. By Lemma 4, we have that 
 is distributed negligibly close to 
. Then, by Lemma 2, we have 
 with overwhelming probability. Since, 
 and 
 and 
 the error term w can be bounded by 
, where we used the subgaussian property to make a finer analysis of the noise bound on 
 (See for example [17], [33]). Hence, for the error term to have absolute value less than , it suffices to choose the parameters as in the statement.

Parameter Selection. For the system to satisfy correctness and make the security proof work, we need the following restrictions. Note that we will prove the security of the scheme under the LWE assumption whose noise rate is α, which is lower than 
 that is used in the encryption algorithm.

•
The error term is less than  (i.e., 
 by Lemma 5)

•
TrapGen operates properly (i.e.,  by Lemma 4)

•
Samplable from 
 (i.e., 
 by Lemma 4),

•
σ is sufficiently large so that we can apply Lemma 1 (i.e., ),

•
We can apply Lemma 3 (i.e., 
),

•
 is hard (i.e.,  for prime q).

To satisfy these requirements, for example, we can set the parameters 
 as: 
, 
, 
, 
, and 
, where  is a constant that can be set arbitrarily small. In the above, we round up m to the nearest integer and q to the nearest largest prime.
Multi-bit Encryption. Although the above scheme only provides 1-bit encryption, we can extend it to provide k-bit encryption without incurring a factor k blow up of the ciphertext size. We change the range of the hash function as 
⁎
. Then, a plaintext vector 
 is encrypted as 
 where 
 and 
 (where 
 is the same). Note that the secret key is now required to be a matrix 
.

4.2. Security analysis
Theorem 1

Our blind IBE scheme with certified identity 
 is IND-ANON-CPA secure in the random oracle model if the underlying signature scheme 
 is  secure, the  is pseudorandom, and assuming the hardness of 
. Alternatively, we can get rid of the second requirement by replacing the  by the random oracle.

Proof Overview. The high level structure of the proof follows the original GPV-IBE security proof. That is, for a random oracle query , the simulator first samples 
 from 
 and sets 
, instead of sampling 
 from 
. Since our key-issuing protocol is 2-move, and 
 contained in 
 depends on the key issuing, we employ this idea twice: the simulator samples 
 from 
 and 
 from 
, and sets 
, and also sets 
. We remark that the distribution of 
 is statistically close to uniform over 
 [17], and thus 
 and 
 are identical from 's view. We also remark that we adopt the proof strategy of Katsumata et al. [21]. In the original GPV-IBE scheme the so-called partitioning technique was used to prove security; the simulator divides the identity space into two in such a way that for one partition it can only construct secret keys and for the other it can only construct challenge ciphertexts. However, this proof strategy was notorious for having a loose reduction. Recently, Katsumata et al. [21] provided a much tighter reduction by following the proof technique of the Cramer-Shoup encryption scheme [34]. Since our proof follows the strategy of [21], it enjoys tight security as well.

Proof

Let  be an algorithm that outputs a random element from 
 and  a PPT algorithm which breaks the IND-ANON-CPA security of our blind IBE scheme with certified identity. We make some assumptions on  to make our proof simpler without loss of generality. First, we assume that  never queries the random oracle on the same input. Next, we assume that whenever  queries for a certificate or a challenge ciphertext, the corresponding  has already been queried to the random oracle . In the following let 
 denote the event that  wins in 
. We modify the games so that in the final game, the adversary will have no winning advantage.

: This is the original security game. At the beginning of the game the challenger prepares  as specified by the game and gives  to . The challenger also prepares three empty lists , , and . Here, the lists  and  are absent in the security definition and only introduced to be used throughout this proof. Then, the challenger picks a random coin  and answers to the queries made by the adversary  as follows:

•
When  makes a random oracle query on , the challenger samples a random 
 and updates 
. Then, it returns 
 to .

•
When  queries for a certificate corresponding to , the challenger runs  and returns  to . It further updates  and . Here, as in the real scheme, the randomness used to run  is generated by 
, where the PRF key 
 is included in the certificate issuing key .

•
When  queries for a secret key with a first-round message 
, the challenger parses 
 and returns the second-round message 
 or ⊥ to  depending on 
. Here, the randomness used to run  is generated by 
, where the PRF key 
 is included in the master secret key .

•
When  queries for a challenge ciphertext on 
⁎
 and message 
⁎
, the challenger returns 
⁎
⁎
⁎
 if  and 
⁎
 if .

At the end of the game,  outputs a guess 
 for . Finally, the challenger outputs 
. We have 
 
 
 by definition.

: In this game, we change how the challenger generates the randomness used for  and . In the previous game, the challenger generated PRF keys 
 and 
 and created randomnesses 
 and 
 for inputs  and 
, respectively. In this game, the challenger uniformly randomly samples 
 and 
 from the appropriate domains for each inputs  and 
, and responds with the same randomness for same inputs. Due to the pseudorandomness of the underlying PRF, this makes negligible difference. Therefore, we have 
. In the following games, we will no longer explicitly mention the used randomness for simplicity and assume 
 and 
.

: In this game, we change how the challenger answers the secret key queries. In particular, the challenger responds as follows for a secret key query:

•
When  queries for a secret key with input a first-round message 
, the challenger first checks whether 
. If not, it returns the second-round message 
 to . Next, it sets 
 and checks whether , where ⋆ represents an arbitrary value. If not, the challenger aborts the game and forces  to output a random coin. Otherwise, the challenger proceeds as in the previous game.

As we show in Lemma 6, we have 
 by the  security of the underlying signatures scheme. We postpone the proof to the end of the game sequence so as not to interrupt the proof.
: In this game, we change how the random oracle queries are answered. In particular, the challenger responds as follows for a random oracle query:

•
When  makes a random oracle query on , the challenger first samples 
 and 
. Then, it sets 
 and updates 
. Finally, it returns 
 to .

Here, the challenger responds to the other queries exactly as in the previous game. In particular, 
 are not used anywhere and the only difference between the previous game is how 
 is created. Then, due to Lemma 1, the distribution of 
 in 
 is statistically close to that of 
. Therefore, we have 
.
: In this game, we change how the challenger answers the certificate queries. In particular, the challenger responds as follows for a certificate query:

•
When  queries for a certificate corresponding to , the challenger retrieves the unique entry 
, which is guaranteed by the assumption we made on . Then, it sets 
 and computes 
. The challenger further runs 
. Finally, it returns 
 and updates .

The only difference from the previous game is how  is generated. Here, note that 
 is uniquely determined once 
 and 
 is fixed since we use deterministic signature schemes. Therefore, for any fixed , we consider the random variables 
 and 
 who are distributed according to the distribution of  conditioned on 
 in 
 and 
, respectively. It is easy to see that 
 is distributed uniformly random over 
 when the challenger runs 
, since 
 is chosen independently from 
. Next we see how 
 is distributed. Recall that owing to the change we made in 
, we have 
. Therefore, due to Lemma 1 and the fact that 
 is information theoretically hidden from , 
 and 
 are independently distributed according to the uniform distribution over 
 with all but negligible probability. In other words, 
 is distributed independently from 
 with all but negligible probability. Therefore, from the view of the adversary , 
 is distributed negligibly close to a uniformly distribution over 
. Hence, we have 
.
: In this game, we change how the challenger answers the secret key queries. In particular, the challenger responds as follows for a secret key query:

•
When  queries for a secret key with input a first-round message 
, the challenger runs identically as in 
 up to the checking of . In case , the challenger aborts as in the previous game. Otherwise, if  for some  and , the challenger retrieves the unique entry 
, which is guaranteed from the way the challenger answers certificate queries. Finally, the challenge sets 
 and returns the second-round message 
 to .

Note that in this game, the challenger does not run algorithm  to sample the vector 
 anymore. Specifically, the challenger no longer requires 
 to play the role of the KGC in this game. Recall, we got rid of the PRF key inside  in 
. The only difference from the previous game is how the vector 
 is generated. For any fixed , let 
 and 
 be random variables distributed according to the distribution of the vector 
 conditioned on 
 and 
 in 
 and 
, respectively. Since in 
, the challenger used algorithm  to sample 
, due to Lemma 4, 
 is distributed negligibly close to 
. On the other hand, due to Lemma 1, 
 is distributed negligibly close to 
. Therefore, we have 
.
: In this game, we change how 
 are created. Namely, the challenger chooses 
 without generating the associated trapdoor 
. By Lemma 4, this makes negligible difference. Since the challenger can answer all secret key queries without  due to the change we made in 
, the view of  is altered only negligibly. Therefore, we have 
.

: In this game, we change the way the challenge ciphertext is created when . Recall in the previous games, when , the challenge ciphertext was created as in the real scheme. In this game, to create the challenge ciphertext for identity 
⁎
 and message bit 
⁎
, the challenger first retrieves the unique tuple 
⁎
⁎
⁎
⁎
 (which is guaranteed to exist by the assumption we made on ). It then sets 
⁎
⁎
⁎
. It further samples 
, 
 and computes 
. The challenger then runs the following algorithm from Lemma 3:
⁎
 
 where 
 is an identity matrix in 
. Let 
 denote the first entry of 
 and let 
 denote the remaining entries. Finally, the challenger outputs the challenge ciphertext as(1)
 We show that the view of  is changed only negligibly. Let 
⁎
, 
, and 
. Then by the noise rerandomization lemma (i.e., Lemma 3), we see that
⁎
⁎
 where the distribution of 
 is negligibly close to 
. Here, the last equality follows from 
⁎
⁎
⁎
. Furthermore, we are able to apply Lemma 3 since we have the following for our parameter selection:
⁎
 Therefore, we have 
.

: In this game, we further change the way the challenge ciphertext is created when . To create the challenge ciphertext when , the challenger first picks 
, 
 and sets 
. It then runs algorithm  as in the previous 
 and sets the challenge ciphertext as in (1). As we show in Lemma 7, we have 
 by assuming the hardness of the  problem. We postpone the proof to the end of the game sequence so as not to interrupt the proof.

: In this game, we further change the way the challenge ciphertext is created. When , the challenger first picks 
, 
 and computes
⁎
 It then parses 
 into 
 and 
 and sets the challenge ciphertext as in (1). Following the same argument we made to move from 
 to 
, we have 
.

: In this game, we change the way the challenge ciphertext is created once more. Regardless of the value of , the challenger samples 
⁎
 and returns 
⁎
 to . We show that this alters the view of  only negligibly. Noice that in the previous game when , the challenge ciphertext could be written as follows:
⁎
 where 
 is the first entry of 
 and 
 is the remaining entries. It suffices to show that the joint distribution of 
⁎
 is negligible close to the uniform distribution over 
, conditioned on 
⁎
. Since 
⁎
⁎
⁎
 and 
⁎
⁎
 are independent, we have 
⁎
⁎
. Moreover, since  never makes a certificate query for 
⁎
, 
⁎
 is distributed uniformly random over 
 from the view of ; 
⁎
. Hence, using the left over hash lemma, we conclude that 
⁎
 is statistically close to uniform over 
. Therefore, we have 
.

In this game, the adversary has no winning advantage since the challenge ciphertext is distributed identically for both  and 1. Namely, we have 
.

Combining everything together, we conclude

To finish the proof of Theorem 1, it remains to prove the following two Lemma 6, Lemma 7.

Lemma 6

If the underlying signature scheme 
 is  secure, then 
.

Proof

We observe that 
 and 
 are the same unless the adversary  makes a secret key query with input a second-round message 
 such that 
 and 
. We denote this event  and define ϵ as the probability that  occurs in 
. Since 
, it suffices to show ϵ is negligible. To show this, we prove that there exists an adversary  that has advantage ϵ in breaking the  security game of 
. We give the description of  in the following.

At the outset of the  game,  is provided the verification key 
 by the 
-challenger and  sets the certificate verification key as 
.  further prepares ,  as the 
-challenger and provides  with .  answers the random oracle and challenge ciphertext queries as the 
-challenger. This can be done since  does not require the signing key 
 corresponding to the verification key 
 to answer any of these queries. When  queries for a certificate corresponding to ,  queries its 
-challenger on message 
 and obtains 
. It then sets 
 and 
 and returns  to . Moreover, when  queries for a secret key with a first-round message 
, if  does not occur, then it proceeds as in the 
-challenger (which can be done without knowledge of 
). Otherwise, if  occurs,  outputs 
 as its forgery to the 
-challenger and terminates. In case  terminates without triggering , then  aborts the  game.

It is easy to check that unless  occurs,  completely simulates the view of 
 to . Furthermore, when  occurs, by the definition of , we have 
 and 
. In particular, since all the signature queries made by  are stored in  by the way  answers 's certificate queries, this means that  has never queried a signature query on message 
. Therefore, 
 is a valid forgery. This completes the proof of Lemma 6.

Lemma 7

If the 
 assumption holds, then 
.

Proof

To prove the lemma, we use  to construct an LWE adversary  as follows:

At the beginning of the game,  samples m times the LWE oracle and forms the LWE instance 
, where 
. The task of  is to distinguish whether 
 for some 
 or 
.  sets the master public key as , prepares  and , and samples a random coin  as in the 
-challenger. Here, we assume that  is given an LWE instance which is consistent with the  (that is, ) output by algorithm . Note that due to the modification we made in 
,  does not require 
 to answer any of 's queries. To generate the challenge ciphertext, if , it generates the challenge ciphertext as in (1). If ,  returns a random ciphertext using . At the end of the game,  outputs 
. Finally,  outputs 1 if 
 and 0 otherwise. It can be seen that if A and v are valid LWE instances (i.e., 
), then the view of  corresponds to 
. Otherwise (i.e., 
), it corresponds to 
. We therefore conclude that assuming the hardness of the 
 problem, we have 
.

Theorem 2

Our blind IBE scheme with certified identity 
 is IND-ANON-KGC secure in the random oracle model if the  is pseudorandom and assuming the hardness of the 
 problem. Alternatively, we can get rid of the first requirement by replacing the  by the random oracle.

Proof Overview. In our security proof, we use the fact that 
 is distributed as a uniformly random vector from the view of the adversary in the random oracle model and embed 
 as the LWE secret, rather than embedding the encryption randomness s as in previous proofs. Recall that the LWE assumption informally states the following: given a uniformly random matrix 
 and some vector 
, there is no PPT algorithm that can decide with non-negligible probability whether v is of the form 
 for some secret vector 
 and noise x, or a uniformly random vector over 
. To restate, while in prior proofs encryption randomness s was set as the LWE secret d, during our security proof, we set 
 as d instead. Moreover, since the encryption randomness s of each ciphertext is completely known to the adversary in the IND-ANON-KGC setting, we set each of the s as the columns of the LWE matrix B.

Proof

Let  be a PPT adversary against the IND-ANON-KGC security game with advantage ϵ. We assume  makes at most Q IssueKey queries and N encryption queries, where  and  can be arbitrary large polynomials. We also define the sampling algorithm  as an algorithm which takes any 
 as input and outputs 
, where 
, 
, and 
. In the following let 
 denote the event that  wins in 
. We modify the games so that in the final game, the adversary will have no winning advantage.

: This is the original security game. At the beginning of the game the challenger prepares , , and  as specified by the game and gives  to . The challenger also prepares two empty lists  and , and an integer 
. Here, the list  is absent in the security definition and only introduced to be used throughout this proof. Moreover, throughout this proof, for clarity we adopt the notation  to indicate that the i-th index of the list  is set to . Initially, we have  for all . The challenger also picks a random coin  which it keeps secret. Finally, the challenger answers to the queries made by the adversary  as follows:

•
When  makes a random oracle query on , the challenger first checks if . If so, it retrieves the (unique) tuple 
 and returns 
 to . Otherwise, it samples a random 
 and updates 
. Then, it returns 
 to . Here, the challenger can query the random oracle similarly to  (See the following item on IssueKey query).

•
When  makes the j-th () encryption query on index i and a message 
, the challenger checks 
. If not, the challenger forces  to output a random coin 
. Otherwise, it retrieves 
 and the unique tuple 
 (which is guaranteed to exist). Then, it computes 
 and 
 as specified by the scheme and returns the ciphertext 
 to .

•
When  makes an IssueKey query, the challenger first samples . It then queries the random oracle on input  and receives back 
. Then, it proceeds with generating  as specified by algorithm  (i.e., runs the algorithm after the receiving 
 back from the random oracle), and sets the first-round message 
. It then returns 
 to . Finally, the challenger updates 
 and then sets 
. Here, as in the real scheme, the randomness used to compute 
 is generated by 
, where the PRF key 
 is included in the certificate issuing key  which the challenger generates at the beginning of the game.

•
When  queries for a challenge ciphertext on index 
⁎
 and a message 
⁎
, the challenger checks 
⁎
. If not, the challenger forces  to output a random coin 
. Otherwise, it retrieves 
⁎
⁎
 and the unique tuple 
⁎
⁎
. It returns 
⁎
 if . Otherwise, if , it proceeds the same as it does for the encryption queries and returns 
⁎
⁎
⁎
 to .

At the end of the game,  outputs a guess 
 for . Finally, the challenger outputs 
. We have 
 
 
 by definition.

: In this game, we change how the challenger generates the randomness used for answering the IssueKey query. In particular, the challenger always samples fresh randomness to be used when made an IssueKey query. Notably, even if the challenger happens to sample the same  on two different IssueKey queries, it will use an independently sampled randomness. The only difference in the view of the adversary  in 
 and 
, is how the randomness are generated to answer the IssueKey query. Since the identity space  is exponentially large and  only makes  many queries, the probability of sampling the same  for two different IssueKey queries is negligible. Conditioned on this fact, the view of  is negligibly close assuming the pseudorandomness of the PRF. Therefore, combining the two arguments, we have 
. In the following games, we will no longer explicitly mention the used randomness for simplicity and assume 
.

: In this game, we change how the challenger responds to the IssueKey queries. In particular, the challenger responds as follows for an IssueKey query:

•
When  queries for an IssueKey query, the challenger first samples . The challenger then queries the random oracle on input  and receives back 
. Then, it samples 
 (independent of ) and signs 
, where 
 is included in the certificate issuing key . It then sets 
, and returns 
 to . Finally, the challenger updates 
 and sets 
.

From the view of the adversary , the only difference between the two games are in how the vector 
 is created. In the previous game, the challenger first sampled 
 and set 
 where 
 was obtained via a random oracle query. Here, combining the three facts: 
 is information theoretically hidden from ; A is statistically close to uniform (Lemma 4); and by the left-over-hash lemma, we have that 
 is distributed uniformly close to random over 
 regardless of the value taken by 
. Therefore, since the distribution of 
 is statistically close in 
 and 
, we have 
.
: In this game, we change when the challenger queries each identity  sampled during the IssueKey query to the random oracle. Namely, we make the following changes:

•
When  queries for an IssueKey query the challenger directly samples 
 and signs 
. It then sets 
, and returns 
 to . Finally, the challenger updates 
.

•
When  makes the j-th () encryption query on index i and a message 
, the challenger first checks 
. If not, the challenger forces  to output a random coin 
. It then further checks if . If so, the challenger samples 
 and sets 
. Otherwise, it retrieves 
. Then, the challenger queries the random oracle on input 
 and receives back 
. Finally, it computes 
 and 
 as specified by the scheme and returns the ciphertext 
 to .

•
When  queries for a challenge ciphertext on index 
⁎
 and message 
⁎
, it proceeds as it did to answer the encryption query.

The only difference between the previous game is the timing on which  is sampled by the challenger; in particular, the timing when the random oracle is queried on input  sampled by the challenger. However, since in 
 the challenger never required  to answer the IssueKey query anymore due to the modification we made, it is easy to see that the view of  is identical in both games. Here, note that the randomness used by the challenger to answer the IssueKey queries were no longer tied to  due to the modification we made in 
. In particular, the challenger is only required to check whether the i-th identity 
 was sampled or not when it is queried on the i-th index for the encryption or challenge ciphertext query. Therefore we have 
.

: In this game, at the outset of the game, the challenger samples a random index  and keeps it secret. It then checks whether the index 
⁎
 submitted by  as the challenge ciphertext satisfies 
⁎
. We call the event which this does not occur as . If event  occurs, the challenger forces  to output a random coin 
. Otherwise, it proceeds in the same was as in the previous game. We have
 Here, the second line follows from the fact that conditioned on event  not occurring 
 and 
 are identical. The final line follows from the fact that 
 occurs independently of event , and when  occurs the challenger outputs a random coin 
 on behalf of .

: In this game, we modify how the challenger answers the encryption and challenge ciphertext query on . In particular, we make the following modification:

•
When  makes the j-th () encryption query on index i and a message 
, if , then it proceeds as in the previous game. Otherwise, if , then the challenger samples 
 and returns 
 to .

•
When  queries for a challenge ciphertext on index 
⁎
 and message 
⁎
, it checks whether 
⁎
 and forces  to output a random coin 
 if not satisfied. Otherwise, it returns 
⁎
 to  regardless of the value of .

We prove in Lemma 8 that 
 assuming the hardness of the LWE problem.
Before we provide the proof of the lemma, we conclude our proof of Theorem 2. Observe that since the challenge ciphertext is sampled in the same way for both  and 1, we have 
. Therefore, combining everything together, we have
 Thus, since , we conclude that 
 is negligible for all PPT adversary .

To finish the proof of Theorem 2, it remains to prove the following Lemma 8.

Lemma 8

If the 
 assumption holds, then 
.

Proof

To prove the lemma, we use  to construct an LWE adversary  as follows:  is given access to an LWE oracle 
 which returns (a fresh) 
 upon each invocation. The task of  is to distinguish whether 
 in which case 
 for 
, or 
 in which case 
 for 
 and 
. Looking ahead,  implicitly sets 
; if 
, then  perfectly simulates 
 and otherwise  perfectly simulates 
.

At the beginning of the game,  prepares all , ,  and samples a random coin . It also samples  as in 
. It then provides  with  and answers to 's queries as follows:

•
When  makes a random oracle query on ,  first checks if . If not, then  replies in the same way as the 
-challenger. Otherwise,  aborts and outputs a random  and terminates.

•
When  queries for an IssueKey query,  replies in the same way as the 
-challenger. This can be done since  has .

•
When  either makes the j-th () encryption query on index i or a challenge ciphertext on index 
⁎
 with a corresponding message ,  first checks if  or 
⁎
. If not, it proceeds in the same way as the 
-challenger. Otherwise,  queries the oracle 
 and receives 
. It then samples 
 and sets
 Finally, it returns 
 as 
 or 
⁎
 to . Here, note that  never queries the random oracle on input 
.

At the end of the game, unless  aborts,  outputs 
. In this case,  outputs 1 if 
 and 0 otherwise. We now analyze the success probability of . In case 
 for some 
, then the above perfectly simulates 
 perfectly conditioned on  not aborting. Specifically, we have . On the other hand, when 
, the above perfectly simulates 
 condition on  not aborting. This is because every 
 is distributed randomly over 
 in case 
 is uniform random over 
. Finally, we observe that the probability that  aborts is negligible. First, 
 is information theoretically hidden from  since we are in the random oracle model. Therefore, since the number of IssueKey query Q is polynomially bounded and the identity space  is exponentially large, the probability that  queries 
 is negligible. We therefore conclude that assuming the hardness of the 
 problem, we have 
.

Theorem 3

Our blind IBE scheme with certified identity 
 is IND-ANON-ICA secure in the random oracle model if the  is pseudorandom and assuming the hardness of the 
 problem. Alternatively, we can get rid of the first requirement by replacing the  by the random oracle.

Proof

The IND-ANON-ICA game played between the adversary and the challenger is a strictly weaker variant of the IND-ANON-CPA game. In other words, any adversary with non-negligible advantage against the IND-ANON-ICA game also has non-negligible advantage against the IND-ANON-CPA game. Therefore, Theorem 1 proves Theorem 3. We point out that since the challenger never requires to answer a certificate query in the IND-ANON-ICA game, we do not additionally require the  security for the signature scheme 
.

5. Pairing-based construction
5.1. Proposed IBE scheme from pairings
In this section, we present our pairing-based scheme. This combines the BF-IBE scheme [14] with the Boldyreva's blind signature scheme [22]. At a high level, this is similar to our lattice-based scheme where we combined the GPV-IBE with Rückert's blind signature scheme. Roughly, we are able to mix the BF-IBE scheme with Boldyreva's blind signature scheme since the signature generated by Boldyreva's scheme is a BLS signature [23] which can be interpreted as a secret key of the BF-IBE scheme.

Construction. Let  and 
 be groups with prime order p,  be a generator, and 
 be a pairing. Let the identity space  of the IBE scheme 
 be 
. Finally, let 
, ,  be a digital signature scheme with message space 
 for some n. Unlike the lattice-based construction, we do not assume that 
 is deterministic. We assume that 
 provides the standard security notion of existential unforgeability under an adaptive chosen message attack ().

:
Choose 
 where p be a λ-bit prime number. Output 
 where 
⁎
 is a hash function modeled as random oracle.

:
Choose 
 and compute 
. Then, output a master pubic key  and a master secret key .

:
Run 
. Then, output a certificate verification key 
 and a certificate issuing key 
.

:
Parse 
 and compute 
. Then, choose 
 and compute 
. Furthermore, compute 
 and 
. Finally, output a certificate 
 and trapdoor information 
.

:
Compute 
. To encrypt a message 
, sample 
, and compute 
 and 
. Finally, output a ciphertext 
.

:
Parse 
 and 
. Compute 
 and output M.

:
The user and the KGC interactively runs  and , respectively (Fig. 2).

User:
On input , , , set the first-round message 
 and send 
 to the KGC. Here, 
.

KGC:
On input , ,  and the first-round message 
, parse 
 and 
. If 
, then set 
 and send 
 to the user. Otherwise, parse  and . Then, compute 
, set 
, and send 
 to the user.

User:
If 
, then output ⊥. Otherwise, parse 
 and 
, compute 
 and (locally) output the secret key 
.

Fig. 2
Download : Download high-res image (80KB)
Download : Download full-size image
Fig. 2. Flow of the key-issuing protocol (pairing-based).

Correctness. 
 holds. Then, 
 holds.

5.2. Security analysis
Theorem 4

Our blind IBE scheme with certified identity 
 is IND-ANON-CPA secure in the random oracle model if the underlying signature scheme 
 is  secure, and assuming the hardness of the DBDH problem.

Proof

Let  be an algorithm that outputs a random element from 
 and  a PPT algorithm which breaks the IND-ANON-CPA security of our blind IBE scheme with certified identity. We make some assumptions on  to make our proof simpler without loss of generality. First, we assume that  never queries the random oracle on the same input. Next, we assume that whenever  queries for a certificate or a challenge ciphertext, the corresponding  has already been queried to the random oracle . In the following let 
 denote the event that  wins in 
. We modify the games so that in the final game, the adversary will have no winning advantage.

: This is the original security game. At the beginning of the game the challenger prepares  as specified by the game and gives  to . The challenger also prepares three empty lists , , and . Here, the lists  and  are absent in the security definition and only introduced to be used throughout this proof. Then, the challenger picks a random coin  and answers to the queries made by the adversary  as follows:

•
When  makes a random oracle query on , the challenger samples a random 
 and updates 
. Then, it returns 
 to .

•
When  queries for a certificate corresponding to , the challenger runs  and returns  to . It further updates  and .

•
When  queries for a secret key with a first-round message 
, the challenger parses 
 and returns the second-round message 
 or ⊥ to  depending on 
.

•
When  queries for a challenge ciphertext on 
⁎
 and message 
⁎
, the challenger returns 
⁎
⁎
⁎
 if  and 
⁎
 if .

At the end of the game,  outputs a guess 
 for . Finally, the challenger outputs 
. We have 
 
 
 by definition.

: In this game, we change how the challenger answers the secret key queries. In particular, the challenger responds as follows for a secret key query:

•
When  queries for a secret key with input a first-round message 
, the challenger first checks whether 
. If not, it returns the second-round message 
 to . Next, it sets 
 and checks whether , where ⋆ represents an arbitrary value. If not, the challenger aborts the game and forces  to output a random coin. Otherwise, the challenger proceeds as in the previous game.

As in Lemma 6, we have 
 by the  security of the underlying signatures scheme. We omit the proof since it is the same as that of Lemma 6.
: In this game, we change how the challenger generates the challenge ciphertext. When  queries for a challenge ciphertext on 
⁎
 and message 
⁎
, the challenger returns 
⁎
 regardless of . In this game, the adversary has no winning advantage since the challenge ciphertext is distributed identically for both  and 1. Namely, we have 
. Finally, we show that 
 by the DBDH assumption.

Lemma 9

If the DBDH assumption holds, then 
.

Proof

Let 
 be a DBDH instance. We use  to construct a DBDH adversary  as follows: At the beginning of game,  sets 
, i.e., implicitly sets . Moreover,  sets δ to be some real in  which we defined later. Then,  answers to the queries made by the adversary  as follows:

•
When  makes a random oracle query on ,  samples a random 
. With the probability ,  sets 
 and updates 
. Otherwise,  sets 
 and updates 
. Then,  returns 
 to .

•
When  queries for a certificate corresponding to ,  samples 
, computes 
, 
, and 
.  returns  to  where 
 and 
.  further updates  and .

•
When  queries for a secret key with a first-round message 
,  parses 
.  returns 
 if 
. Otherwise,  extracts 
 from 
. We remark that such an entry always exists due to the modification we made in 
.  extracts 
 from 
. If 
, then  aborts the game and forces  to output a random coin. Otherwise, if 
, then  computes 
. Here, 
 holds (since ).  returns the second-round message 
 to .

•
When  queries for a challenge ciphertext on 
⁎
 and message 
⁎
,  extracts the entry 
⁎
⁎
⁎
⁎
. If 
⁎
, then  aborts the game and forces  to output a random coin. Otherwise, if 
⁎
, then  sets 
⁎
 and computes 
⁎
⁎
⁎
.

It is clear that if 
, then  perfectly simulates 
 to  conditioned on not aborting since 
⁎
⁎
⁎
⁎
⁎
⁎
⁎
. On the other hand, if Z is random, then  perfectly simulates 
 condition on not aborting. Now, the probability that  does not abort is 
 where Q is the number of random oracle queries. We set 
 to maximize this probability, and in this case, the probability that  does not abort is at least 
 where 
 is the base of the natural logarithm. Therefore, since  does not abort with non-negligible probability, assuming the hardness of DBDH, no adversary can distinguish 
 and 
 with non-negligible probability.

Theorem 5

Our blind IBE scheme with certified identity 
 is IND-ANON-KGC secure in the random oracle model assuming the hardness of the DBDH problem.

Proof

Let  be a PPT adversary against the IND-ANON-KGC security game with advantage ϵ. We assume  makes at most Q IssueKey queries, and N encryption queries, where  and  can be arbitrary large polynomials. We also define the sampling algorithm  as an algorithm which outputs a random element from 
. In the following let 
 denote the event that  wins in 
. We modify the games so that in the final game, the adversary will have no winning advantage.

: This is the original security game. At the beginning of the game the challenger prepares , , and  as specified by the game and gives  to . The challenger also prepares two empty lists  and , and an integer 
. Here, the list  is absent in the security definition and only introduced to be used throughout this proof. Moreover, throughout this proof, for clarity we adopt the notation  to indicate that the i-th index of the list  is set to . Initially, we have  for all . The challenger also picks a random coin  which it keeps secret. Finally, the challenger answers to the queries made by the adversary  as follows:

•
When  makes a random oracle query on , the challenger first checks if . If so, it retrieves the (unique) tuple 
 and returns 
 to . Otherwise, it samples a random 
 and updates 
. Then, it returns 
 to . Here, the challenger can query the random oracle similarly to  (See the following item on IssueKey query).

•
When  makes the j-th () encryption query on index i and a message 
, the challenger checks 
. If not, the challenger forces  to output a random coin 
. Otherwise, it retrieves 
 and the unique tuple 
 (which is guaranteed to exist). Then, it computes 
 and 
 as specified by the scheme and returns the ciphertext 
 to .

•
When  makes an IssueKey query, the challenger first samples . It then queries the random oracle on input  and receives back 
. Then, it proceeds with generating  as specified by algorithm  (i.e., runs the algorithm after the receiving 
 back from the random oracle), and sets the first-round message 
. It then returns 
 to . Finally, the challenger updates 
 and then sets 
.

•
When  queries for a challenge ciphertext on index 
⁎
 and a message 
⁎
, the challenger checks 
⁎
. If not, the challenger forces  to output a random coin 
. Otherwise, it retrieves 
⁎
⁎
 and the unique tuple 
⁎
⁎
. It returns 
⁎
 if . Otherwise, if , it proceeds the same as it does for the encryption queries and returns 
⁎
⁎
⁎
 to .

At the end of the game,  outputs a guess 
 for . Finally, the challenger outputs 
. We have 
 
 
 by definition.

: In this game, we change how the challenger responds to the IssueKey queries. In particular, the challenger responds as follows for an IssueKey query:

•
When  queries for an IssueKey query, the challenger first samples . The challenger then queries the random oracle on input  and receives back 
. Then, it randomly samples 
 (independent of ) and signs 
, where 
. It then sets 
, and returns 
 to . Finally, the challenger updates 
 and sets 
.

From the view of the adversary , the only difference between the two games are in how the element 
 is created. In the previous game, the challenger first sampled 
 and set 
 where 
 was obtained via a random oracle query. Since 
 is information theoretically hidden from , 
 is distributed uniformly close to random over  regardless of the value taken by 
. Therefore, the distribution of 
 is the same in 
 and 
. Specifically, we have 
. Due to the modification we made in this game, the challenger no longer requires to know 
 to answer 's IssueKey query.
: In this game, we change when the challenger queries each identity  sampled during the IssueKey query to the random oracle. Namely, we make the following changes:

•
When  queries for an IssueKey query the challenger directly samples  and signs 
. It then sets 
, and returns 
 to . Finally, the challenger updates 
.

•
When  makes the j-th () encryption query on index i and a message 
, the challenger first checks 
. If not, the challenger forces  to output a random coin 
. It then further checks if . If so, the challenger samples 
 and sets 
. Otherwise, it retrieves 
. Then, the challenger queries the random oracle on input 
 and receives back 
. Finally, it computes 
 and 
 as specified by the scheme and returns the ciphertext 
 to .

•
When  queries for a challenge ciphertext on index 
⁎
 and message 
⁎
, it proceeds as it did to answer the encryption query.

The only difference between the previous game is the timing on which  is sampled by the challenger; in particular, the timing when the random oracle is queried on input  sampled by the challenger. However, since in 
 the challenger never required  to answer the IssueKey query anymore due to the modification we made, it is easy to see that the view of  is identical in both games. Therefore we have 
.

: In this game, at the outset of the game, the challenger samples a random index  and keeps it secret. It then checks whether the index 
⁎
 submitted by  as the challenge ciphertext satisfies 
⁎
. We call the event which this does not occur as . If event  occurs, the challenger forces  to output a random coin 
. Otherwise, it proceeds in the same was as in the previous game. Using the same argument used in Theorem 2, we have 
.

: In this game, we modify how the challenger answers the challenge ciphertext query. Specifically, we make the following modification:

•
When  queries for a challenge ciphertext on index 
⁎
 and message 
⁎
, it checks whether 
⁎
 and forces  to output a random coin 
 if not satisfied. Otherwise, it returns 
⁎
 to  regardless of the value of .

We prove in Lemma 10 that 
 assuming the hardness of the DBDH problem.
Before we provide the proof of the lemma, we conclude are proof of Theorem 5. Observe that since the challenge ciphertext is sampled in the same way for both  and 1, we have 
. Therefore, combining everything together, we have
 Thus, since , we conclude that 
 is negligible for all PPT adversary .

To finish the proof of Theorem 5, it remains to prove the following Lemma 10.

Lemma 10

If the DBDH assumption holds, then 
.

Proof

To prove the lemma, we use  to construct an DBDH adversary  as follows: Let 
 be an DBDH instance. The task of  is to distinguish whether 
, or random. Looking ahead,  implicitly sets 
. If 
, then  perfectly simulates 
 and if Z is random, then  perfectly simulates 
.

At the beginning of the game,  prepares all , ,  and samples a random coin  and . It then provides  with  and answers to 's queries as follows:

•
When  makes a random oracle query on ,  first checks if . If not, then  replies in the same way as the 
-challenger. If , then  aborts and outputs a random  and terminates.

•
When  queries for an IssueKey query,  replies in the same way as the 
-challenger. This can be done since  has .

•
When  makes the j-th () encryption query on index i with a corresponding message 
,  first checks if . If so,  chooses 
 and computes the ciphertext as(2)
 Otherwise,  computes 
 in the same way as the 
-challenger. Finally, it returns 
 as 
 to . Here, note that  never queries the random oracle on input 
.

•
When  queries for a challenge ciphertext on index 
⁎
 and message 
⁎
,  first checks 
⁎
. If not, it forces  to output a random coin 
. If 
⁎
,  then computes the challenge ciphertext as follows.
⁎
⁎
⁎
 Finally, it returns 
⁎
⁎
 as 
⁎
 to .

At the end of the game, unless  aborts,  outputs 
. In this case,  outputs 1 if 
 and 0 otherwise. We now analyze the success probability of . Recall that  implicitly sets 
. First, we observe that encryption queries for the case  are answered perfectly regardless of the value Z; 
 in (2) satisfies 
. Now, in case 
, then the above perfectly simulates 
 conditioned on  not aborting since 
 holds and 
 is randomness used nowhere else. On the other hand, when Z is random, the above perfectly simulates 
 conditioned on  not aborting. This follows since 
 and Z are independently random and not used anywhere else. Finally, we observe that the probability that  aborts is negligible. First, 
 is information theoretically hidden from  since we are in the random oracle model. Therefore, since the number of IssueKey query Q is polynomially bounded and the identity space  is exponentially large, the probability that  queries 
 is negligible. We therefore conclude that assuming the hardness of the DBDH problem, we have 
.

This completes the proof of Theorem 5.
As in the lattice-based one, the following theorem holds.

Theorem 6

Our blind IBE scheme with certified identity 
 is IND-ANON-ICA secure in the random oracle model assuming the hardness of the DBDH problem.