The rate of depression in college students is rising, which is known to increase suicide risk, lower academic performance and
double the likelihood of dropping out of school. Existing work on fnding relationships between passively sensed behavior
and depression, as well as detecting depression, mainly derives relevant unimodal features from a single sensor. However,
co-occurrence of values in multiple sensors may provide better features, because such features can describe behavior in
context. We present a new method to extract contextually fltered features from passively collected, time-series mobile data via
association rule mining. After calculating traditional unimodal features from the data, we extract rules that relate unimodal
features to each other using association rule mining. We extract rules from each class separately (e.g., depression vs. nondepression). We introduce a new metric to select a subset of rules that distinguish between the two classes. From these rules,
which capture the relationship between multiple unimodal features, we automatically extract contextually fltered features.
These features are then fed into a traditional machine learning pipeline to detect the class of interest (in our case, depression),
defned by whether a student has a high BDI-II score at the end of the semester. The behavior rules generated by our methods
are highly interpretable representations of diferences between classes. Our best model uses contextually-fltered features to
signifcantly outperform a standard model that uses only unimodal features, by an average of 9.7% across a variety of metrics.
We further verifed the generalizability of our approach on a second dataset, and achieved very similar results.
CCS Concepts: • Human-centered computing Ubiquitous and mobile computing; • Applied computing Life and
medical sciences.
Additional Key Words and Phrases: Behavior mining, Passive sensing, Depression detection, Association rule mining
1
116:2 • Xu et al.
INTRODUCTION
Major depressive disorder (MDD), also known simply as depression, is a common and consequential health
challenge. It is often accompanied by low self-esteem [17], loss of interest in normally enjoyable activities,
anxiety [39], low energy, and pain [63, 81]. Recent studies found that MDD afects approximately 216 million
people around the world [82]. Lifetime depression rates are higher in the developed world (15%) compared to the
developing world (11%) [50]. In 2015, an estimated 6.7% of all U.S. adults and 10.3% of young adults had at least
one MDD episode over the past year. Among 6.5% of young adults, it was reported that the depressive episodes
resulted in severe impairment [2].
The college experience introduces majorstressorsthat afect young adults in a variety of ways,such as academic
participation [42], social interactions, fnancial conditions, and physical and mental health [46]. Moreover,
depression is one of the most common symptoms among people with suicidal propensity [52, 64]. In a report by
the American College Health Association in 2018 [3], approximately 13.1% of undergraduate students seriously
considered suicide in the past year and 2.0% attempted suicide. Yet many of them do not even realize they are
depressed until they begin experiencing severe functional deterioration [22, 46], and even those that do may not
seek health treatment [29, 40].
Detecting depression and identifying early signs of depression can mitigate or prevent its negative consequences. However, traditional depressive symptom screening methods mainly rely on periodic self-reports, whose
efectiveness is impacted by subjectivity and compliance. There is a growing realization that everyday devices,
including mobile phones and wearable devices (e.g., smart bands, smartwatches), that consistently and passively
collect behavioral sensor data, can help us to understand the relationship between people’s daily behavior and
depression [8, 19, 55], complement traditional screening methods and provide the potential for introducing
real-time interventions [83, 84]. Over the past few years, diferent studies have identifed signifcant correlations
between mobile sensing data and depression [27, 70, 86]. However, most of the previous work has mainly focused
on a single sensor channel such as location [19, 30, 70].
Some previous work has directly combined multiple sensor channels but has treated each sensor channel
as a separate feature, which misses the opportunity to capture co-occurrence relationships between sensors
(e.g., [76, 84]). Such co-occurrence relationships might be able to boost the performance of machine learning
models for depression detection and prediction, and more importantly, might be able to provide better insights
for understanding people’s depression-related behavior from wearable and mobile sensors. In this paper, we
present a new approach to capturing these co-occurrence relationships across sensor channels with the goal of
identifying students who experienced depressive symptoms at the end of the semester.
Specifcally, we present a new method for generating contextually fltered features, which performs better
than prior feature selection approaches for accurately detecting depression. Given a data set composed of timeseries sensor measurements, unimodal features can be calculated as aggregates over diferent time periods (e.g.,
daily or every morning) within a single sensor in that data set. We defne contextually fltered features to be
those features that are calculated as an aggregate (mean or standard deviation) over a fltered subset of the time
periods in the data, with fltering decisions made based on the values of context (as defned by co-occurrence of
features), e.g., mean of sleep over the nights only when students are of-campus and have high activity levels.
Association Rule Mining [4] (ARM) is used to decide which features to use for contextual fltering and aggregation.
For example, suppose ARM identifes the rule “when students are sitting in a classroom, they are also interacting
with their phone”. The unimodal features for ‘sitting in a classroom’ and ‘interacting with their phone’ represent
simple averages of how often each happens. The contextual fltered feature calculated from this same rule would
be an average of ‘interacting with their phone’ that only includes days where ‘sitting in a classroom’ is true.
Contextually fltered features are more likely to be able to capture signals of interest around health behaviors,
as demonstrated by the improved performance of our approach. Prior approaches to depression detection have
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:3
leveraged only unimodal features computed over the entire observation period (e.g., [19, 70]), or have manually
created and selected any contextual features (e.g., [87]). In contrast, our method leverages association rule mining
[4, 77] to automatically and systematically generate contextual features from extracted behavior rules, which
defne subsets of time periods relevant to a specifc context. The behavior rules generated by our method reveal
behavior diferences between the depression group (having mild or more severe depressive symptoms, as measured
by the Beck Depression Inventory (BDI-II) [11]) and the non-depression group. Prior work in association rule
mining directly uses extracted rules for classifcation using a rules-based classifer, without generating features
from them (e.g., [56]). Our approach automatically generates rich contextual features from those rules, which can
be used with a wide range of classifcation algorithms.
Our approach is fully automated. It produces a classifer for detecting whether, at the end of the academic
semester, a student will have a BDI-II score greater than 13, indicating mild or more severe depressive symptoms
[12, 28]. We demonstrate that it outperforms a standard pipeline with unimodal features calculated on the same
data, but not fltered with any specifc context. When applied to data collected from 138 students at a US university,
the new classifer outperforms the standard classifer by 10.2% on accuracy (81.8% vs. 71.6%) and 9.6% on F1 score
(84.3% vs. 74.7%) in detecting post-semester depression. Further, our results are robust. We replicate our method
on a second dataset collected at the same university a year later and obtain a classifer with an accuracy of 84.0%
and F1 score of 88.1%, which outperforms the baseline by 10.0% and 6.4%, respectively.
The contributions of the paper are as follows:
• We present a new approach to perform rule selection on population subgroups that represent diferent
classes of interest, and a new method to generate contextually fltered behavior features based on the
outcomes of traditional rule mining algorithms on mobile sensing data.
• We demonstrate that using our method, the best rules are highly interpretable and can capture students’
routine behaviors, as well as behavior pattern diferences between a subgroup with depressive symptoms
and a subgroup without depressive symptoms. The rules obtained by our algorithm help us to better
understand students’ life experiences related to depressive symptoms.
• We demonstrate that the best model, trained on the contextual features extracted from these rules, outperforms the baseline (using unimodal features), by an average of 9.7% across a variety of metrics.
• We further verify the generalizability of our method. We frst apply the rule selected by our method to an
independent, second dataset. On this new dataset, the classifer, trained on features extracted based on the
same rules, outperforms the baseline by an average of 5.6%. When we run our entire method on the second
dataset (mining rules, selecting rules, selecting contextual features and building a classifer) the resulting
classifer outperforms the baseline by an average of 7.1%.
To the best of our knowledge, we are the frst to automatically generate contextually fltered features to improve the
classifer accuracy in diferentiating between two classes, in our case performing depression detection. Our results
create new opportunities for future research, both for depression and for using rule mining to identify useful
behavioral features in domains beyond depression. We frst summarize related work on depression detection
using mobile sensing, rule mining algorithms, and human routine modeling in Section 2. We introduce our rule
mining, selecting and contextually fltered feature extraction algorithm in Section 3. Then, we briefy describe the
dataset we apply our approach to, and the implementation of our approach in Section 4. We present the results of
applying our approach to this dataset: the selected rules and the contextually fltered features, in Section 5. We
discuss some implications from our results, limitations of our work, as well as future directions in Sections 6
and 7. Finally, we summarize our contributions and the implications of our work in Section 8.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:4 • Xu et al.
2 RELATED WORK
Daily behaviors, such as movement patterns, communication, phone use, physical activity, and sleep, can be
sensed by various sensors embedded in smartphones and wearable ftness trackers. Features captured by sensors
can be indicative of behavioral symptoms of depression. A rich body of work has demonstrated the feasibility of
identifying depressive symptoms through passive sensing of daily behaviors [19, 26, 43, 70, 87]. Knowing how a
person, with or without depressive symptoms, enacts their daily routine may provide another perspective to
understand and detect depression.
Time series data, such as that used in the work modeling depression, has been modeled using a range of
algorithms. Techniques that have been applied to model human behavior include Association Rule Mining
(ARM) [61, 71–73], T-patterns [16], topic models [31] and maximum causal entropy [9, 10]. Of these, ARM is
particularly well suited to generating contextual features, because it is used to fnd frequent patterns, correlations,
or associations between features. In this section, we review and summarize the related literature on depression
detection via mobile sensing, association rule mining, particularly on rule selection and classifcation, as well as
other techniques for human routine behavior modeling.
2.1 Depression and Mobile Sensing
Recent successes in using mobile sensing to understand and detect depression have made the topic increasingly
interesting for researchers. Initial work in this domain explored the statistical relationship between behavior features from mobile sensors and depression (e.g., depression severity) while more recent advances have
demonstrated machine learning models that successfully use mobile sensing features for depression detection.
Katikalapudi et al. [49] ran a month-long study with 216 college students and found a direct relationship
between depressive symptoms and Internet use. Saeb et al. [70] collected location and phone usage data from
28 adults over two weeks. Their analysis suggested that location features, such as location variance, location
entropy and circadian movement (regularity in 24-hour rhythm), are related to depressive symptoms. They also
found phone usage features, usage duration and usage frequency to be signifcantly correlated to depression
scores. Wang et al. [86] conducted the StudentLife study at Dartmouth, involving 48 students over a 10-week
term. Their analysis revealed signifcant correlations between depression scores and conversation duration,
sleep duration, and frequency and number of Bluetooth encounters. Further analysis of this dataset also found
signifcant relationships between changes in depression scores and features such as sleep duration, speech
duration, and mobility [13].
Beyond the work in identifying relationships between mobile sensor data and depression scores, past work
has used those relationships to develop machine learning models to detect depression. Saeb et al. [70] employed
location features extracted from 28 adults’ data over a two-week period. The model trained on their features
achieved a leave-one-out average accuracy of 86.5% for distinguishing between participants with and without
depressive symptoms. Similarly, Canzian and Musolesi [19] collected data from a group of 28 participants, and
trained models on an individual level with location features to detect periods when users experienced depression.
Their model achieved 0.71 sensitivity and 0.87 specifcity scores. Farhan et al. [30] detected biweekly depression
college students using a dataset involving 79 college students over eight months. Their features were extracted
from location data and their model achieved an F1 score of 0.82. In addition to using the single sensor channel of
location data to detect depression, some work has also combined data from multiple sensors to do this. Wahle
et al. [84] trained models on 36 participants over ten weeks. They used unimodal features from location, physical
activity, phone usage, calls, messages, and WiFi scans, and achieved an accuracy of 61.5%. Wang et al. [87]
detected depression on a weekly basis using features from smartphone and wearable data collected from 68
college students over two nine-week terms. They achieved 81.5% recall and 69.1% precision.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:5
A rich body of literature has suggested the importance of contextual information (e.g., [1, 25]) for depression
detection [18, 83]. Nevertheless, most of the previous work involving machine learning techniques either uses
data from a single sensor (e.g., location) or directly combines unimodal features from multiple sensors data into
a larger input vector to train models. Very little work has investigated the use of multi-channel (or sensor) cooccurrence information to leverage context at the feature level efectively. Wang et al. [87] use some hand-crafted
multi-channel features based on DSM-5 (Diagnostic and Statistical Manual of Mental Disorders) depressive
symptoms [7], such as phone usage in study spaces for the symptom of diminished ability to concentrate, and
dwell time, phone usage, and conversation in social spaces for the symptom of diminished interest in activities.
Their features were intuitive and easy to interpret. The features in our work are similar in their interpretability.
However, their feature extraction process requires expert domain knowledge and a tedious trial-and-error process.
To the best of our knowledge, we are the frst to propose a computational method that can automatically identify
the intrinsic relationships between multiple sensors and extract contextually fltered features (as we defned
in Section 1) for depression detection.
2.2 Association Rule Mining and Classification
Association Rule Mining (ARM) is a data mining method that can fnd frequent patterns, correlations, associations,
or causal structures from datasets. It has been used in a range of domains, from helping to discover sales
correlations in transaction datasets [65] to identifying disease correlations in medical datasets [6].
ARM outputs frequent co-occurrence patterns expressed as association rules [4]. Each association rule is of the
form [X → Y], where X and Y are co-occurring sets of context features, and the association rule indicates that
the context features in Y are likely to occur whenever the features in X are observed. For rule [X → Y], two
parameters are defned [4]:
• Support: Support represents the fraction of times the context set {X,Y } occurs in the dataset, i.e., the joint
probability sup = P(X,Y).
• Confdence: Confdence represents the proportion of times Y co-occurs whenever X occurs, i.e., the
conditional probability conf = P(Y |X).
A support and confdence threshold, namely supmin and confmin, is applied to the rule miner, indicating the
minimum support and confdence allowable for each discovered rule.
2.2.1 Selecting Rules. A key drawback of ARM is that it usually generates a large number of rules, so that it
becomes difcult to identify useful rules. In the data mining community, several researchers have focused on
techniques for selecting the top rules, such as ranking rules based on measures such as confdence [20], selecting
a set of rules to fulfll some interestingness criteria such as conciseness, coverage, etc. [38, 45, 62] or minimizing
the redundancy based on rule redundancy criteria [53, 57, 93, 94]. While high support and confdence may be
desirable in traditional data mining [4, 5], a high support value in mobile context data mining results in rules
which have broad preconditions and are less useful because they capture common daily routines rather than
things relevant to the detection of a variable of interest [72]. The existing rule selection metrics do not explicitly
emphasize the contextual specifcity of the rules or focus on the ability of rules to diferentiate between two
classes, which is important for capturing behavior pattern diferences between sub-groups of interest.
2.2.2 Using Rules for Classification. Liu et al. [56] introduced class association rules, a modifcation to ARM that
outputs [X → y] where X is the item set and y is the class label. They defne support and confdence at the rule
level as follows: Support for a rule is the proportion of instances in the data set that match X; Confdence is the
ratio of instances which match X and are labeled y divided by all instances that match X. Rules whose support
and confdence are above a pre-determined threshold are selected and used as binary features for a rule-based
classifer. Some follow-up work aimed to improve this algorithm’s efciency [90, 95], but did not signifcantly
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:6 • Xu et al.
change the prediction mechanism. Other work has combined class association rules with classifers such as
logistic regression [47], decision trees [68] and support vector machines [51]. However, these methods mainly
integrate rules into the model directly and do not post-process the original features based on the rules (e.g., use
the rule-based feature vector to train SVM classifer [51]). This can miss intrinsic co-occurrence relationships
between the context X and Y. We show in Section 5 that a rule-based classifer does not have as good performance
as contextually fltered features for depression detection.
2.3 Modeling Human Routine Behavior
While the ability to use ARM for classifcation is intriguing, the rules generated by ARM are also intrinsically
interesting because of their ability to describe and model human behavior. A clear picture of the many aspects of
routine behavior can help researchers to generate theories and models of human behavior [9]. It may also provide
a better understanding of depressive symptoms. A variety of data mining and machine learning techniques have
been used to model human routines. For example, Brdiczka et al. [16] use T-patterns [58] to automatically fnd
recurrences of events in behavior logs. Farrahi and Gatica-Perez [31] use n-gram topic models [88] to capture
user context and actions. Banovic et al. [9] employ the maximum causal entropy algorithm [97] to model routine
behaviors and their variance. Pierson et al. [66] propose Cyclic Hidden Markov Models to model cycles in human
behavior.
Among these options, ARM is a powerful method for mining contextual data to better understand human
behavior. Nath [61] describe the ACE system (Acquisitional Context Engine), which uses ARM to mine cooccurrence patterns amongst context events, and exploits the resulting patterns to speculatively sense user
context in an energy-efcient manner. Srinivasan et al. [73] present the MobileMiner system, which runs on a
smartphone and can discover frequent co-occurrence patterns indicating which context events frequently occur
together. Recently, the authors employed the same algorithm and the RuleSelector system [72] to capture user
context and to allow smartphone users to browse, modify, and select action rules from a small set of summarized
rules presented to the user in a manner similar to the IFTTT (If-This-Then-That) platform.
Previous work has also directly leveraged the outcomes of rule mining algorithms to perform behavior
prediction. This approach has worked for simple behavior modeling such as phone application usage or phone
charging behavior [72, 73]. Since this method mines behavior of multiple users together, without treating subgroups of interest separately, it can easily overlook the behavior diferences between groups, especially when
dealing with complex behaviors such as depressive symptoms.
3 RULE MINING, SELECTION, AND MULTIMODAL FEATURE EXTRACTION ALGORITHM
In this section, we introduce our method that can capture behavior diferences between two groups of users using
mobile behavioral data. We introduce our algorithm to extract contextually fltered features based on rule mining
and rule selection for a classifcation problem. Figure 1 visualizes the overall pipeline for our method. We frst
extract unimodal features and then use ARM to generate rules, on a per-class basis, using those features. We then
use a novel metric to select the top rules. The key idea of our approach is to identify rules that identify important
diferences between classes of users. The classes can be diferent by (1) sharing similar contexts but with diferent
behavior in those contexts (see Section 3.2.1), or (2) having contexts that are common in one class and uncommon
in the other class (see Section 3.2.2). Based on the top rules, we describe a new, automated approach to obtain
contextually fltered features based on the top rules (see Section 3.3).
3.1 Step 1: Rule Mining in Two Classes Separately
We frstsplit the dataset into two groups according to our classifcation label, namely grp1 and grp2. (i.e., depression
group versus non-depression group). We perform ARM on them separately to generate a large rule set in each
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:7
Fig. 1. The high-level pipeline of the integration of rule mining algorithms and machine learning models. The dashed frame
highlights the novel contribution of the paper. We designed a new metric to select the top rules from the rule set generated
by ARM. We also proposed a new approach to extract contextually filtered features based on the top rules. Finally, we use
these features to train classifiers.
group. ARM naturally fts our problem since we obtain multiple features from various sensors at the same time.
In a rule [X → Y], both X and Y would contain behavioral features. An example rule could be: [X: {Staying at
home, Low activity level} → Y: {Being asleep}] during the night. Next, we devise a novel approach to select the
best rules from the two rule sets.
3.2 Step 2: Rule Selection Using a Novel Metric
As described above, our method emphasizes the characteristics of and diferences between the two classifcation
groups. Among the two rule sets generated from the two groups described in Section 3.1, there can be rules that
are discovered in both groups, capturing common contexts between both groups, that we can use to see how the
two groups behave diferently; and rules that only appear in one group, that indicate contexts that vary between
the groups. To capture the diference, we use two complementary perspectives: one looks at rules that are the
same between two groups but with diferent sup and conf values, while the other looks at rules that are unique to
only one group.
3.2.1 Common Rules in Two Groups. Mobile behavioral data is likely to include many common behavior patterns.
Thus, the set of rules present in each group may be very similar. However, even if a rule is present in both groups,
sup and conf can be very diferent in the groups. We present a set of metrics for characterizing the usefulness of a
rule for identifying group membership of an individual.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:8 • Xu et al.
Contextual Specifcity. Rules that are too general are unlikely to discriminate between the two groups. We flter
rules that are not very specifc. For example, a rule that captures a behavior pattern such as changing locations
every weekday morning (from home to work) is less specifc than a rule that is more specifc, e.g., changing
location with a low level of physical activity but a high number of co-locations with other people (the number of
Bluetooth encounters). We formalize this in terms of the number of features in X for a rule [X → Y].
CtxSpec = |X |
Confdence Diference. The confdence of a rule, i.e., the conditional probability, indicates how probable Y is to
occur given the context feature set X. For the same X, the diference in confdence directly refects the diferent
probabilities of Y between two groups. For example, when in working spaces such as ofces or libraries (same X),
people with depressive symptoms may have more difculties with concentration [7], thus spending more time
interacting with their phones [87]; this could appear in our analysis as higher confdence for the behavior rule Ri
[X: {Stay at working spaces} → Y: {Phone interaction time}] for people with depressive symptoms.
The bigger the diference in confdence, the greater the discrepancy in the expression of the rule between the
two groups. We formalize this as
ConfDif = |∆conf|
Condition Discrepancy. The probability of the context set X, i.e., P(X), closely interrelates with the confdence of
the rule. We are interested in rules that have diferent context probability across groups. Continuing the previous
example, people with depressive symptoms may spend less time in working or social spaces [7], leading to a P(X,Y ) sup diferent P(X) for those with and without depressive symptoms for rule Ri . Note that P(X) = P(Y |X) = conf . Thus
we formalize this as sup CondDisc = |∆ | conf
Direction Diference. We would like to fnd the rules that have CondDisc and ConfDif in the same direction. In
other words, we are interested in a rule that has both higher P(X) and higher P(Y |X) in one group than the other.
We formalize this as  sup 1 if sign(∆conf · ∆conf) is positive DirDif = 0 otherwise
Based on these characteristics, we combine the four characteristics into a metric M using Equation 1. The
intuition comes from a weighted addition of the logarithm value of the three characteristics. The logarithmic
function is monotonically increasing, thus it will not change the relative order when ranking the rules based on
the metric.
M = DirDif · CtxSpecw1 · ConfDifw2 · CondDiscw3 (1)
DirDif simply causes features to be dropped if a rule has reverse directions on the ConfDif and CondDisc
between two groups. The three weight values are used to adjust the relative importance of the remaining three
characteristics. We rely on M to rank the rules that are common in both groups and select the top-n rules. We
remove redundant rules by the defnition: Rule1 covers Rule2 ⇐⇒ X2 ⊆ X1 and Y2 ⊆ Y1. Algorithm 1 (top)
presents the procedure.
3.2.2 Unique Rules in One Group. In addition to common rules that are mined from both groups, the two groups
can also have unique rules discovered in one group but not the other. These rules refect the diferences of
behavior patterns and contexts between the two groups. Selecting the best unique rules in each group can also
help identify the distinctions between the two groups. ConfDif, CondDesc and DirDif are undefned when a
rule is present in only one group. We solve this by setting sup and conf to zero when a rule is not present, thus conf
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:9
simplifying the calculation of ConfDif and CondDesc as shown in Equation 2. DirDif is not used since it always
equals 1. We then employ the same metric M as Equation 1 and select the top-n rules.
ConfDif = conf
sup (2) CondDisc = conf
However, note that the approach above could treat a rule as being unique to one group if the threshold values
fltered the rule out in the other group. For instance, take a rule r that occurs in both groups with sup1 = 0.101
and sup2 = 0.099, which are very close. The rule would not appear in grp2 when the threshold supmin = 0.100 is
applied, while it would appear in grp1.
Thus we need to flter out these rules whose sup and conf are close to the threshold. We set the minimal distance
to be 99th percentiles of the |∆sup| and |∆conf| we observe from Section 3.2.1 which shows their distributions,
and flter out rules that are close to this threshold, as shown in lines 15-18 of Algorithm 1. Similar to the common
rules, we rank the resulting unique rules using metric M, and remove any redundant rules.
Overall, we obtain Tcommon from Section 3.2.1 and Tunique from Section 3.2.2. The fnal set of top rules is
calculated on line 28 as Ttop = Tcommon ∪ Tunique . Next, we describe a new approach to extract contextually
fltered features from the top rule set.
3.3 Step 3: Contextually Filtered Feature Creation
Once a top rule set Ttop has been selected using the algorithms described in Section 3.2, they can be used to
generate contextually fltered features. These features in turn can be fed into a machine learning model to train a
classifer.
For each rule [X → Y], we use X as the “selector” (or flter) to select the days over which to aggregate (the days
that fulfll the context feature sets, i.e., the elements of [X]). For each element of [Y], we calculate the mean and
standard deviation using data from all of the fltered days. Consider as an example, the rule [X: {Being at sport
spaces, High activity level } → Y: {Long phone call duration}]. We select all time periods, or epochs (described in
Section 4.2), Ep for person p that fulfll the context {Being at sport spaces, High activity level }. Then, we calculate
the average and standard deviation of the features in Y only for the selected epochs. Thus in this example, the
new contextually fltered features for the person p are the mean and standard deviation of Duration of out-going
call, for all epochs in which the person spent a long time in sport spaces and had a high level of physical activity.
Algorithm 2 presents the feature extraction procedure. Note that one rule can have multiple features in set
Y, thus the number of features generated can be greater than the number of rules. There can also be duplicate
features y in Y for diferent rules. However, as the context (X) of these rules are diferent, the contextually fltered
feature calculated from the same y in diferent rules is expected to have diferent mean and standard deviation
values.
The fnal feature set for each person can be used for training classifers to identify group membership of a
person. In the rest of the paper, we describe how we apply our approach for rule mining, rule selection and
contextually fltered feature extraction on our dataset, with a focus on depression detection among undergraduate
students.
4 TWO YEAR DATA COLLECTION WITH FIRST AND SECOND YEAR STUDENTS
In this section, we briefy describe the depression dataset that we use to demonstrate the efectiveness of our rule
selection and contextually fltered feature extraction algorithms. Our data collection was inspired by and modeled
after the work of Wang et al. [86]. We describe our specifc approach in more depth in the following sections.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:10 • Xu et al.
1
2
Data: grp1, grp2, mining thresholds supmin and confmin
R1 = ARM(grp1, supmin, confmin);
R2 = ARM(grp2, supmin, confmin);
3
4
5
6
7
8
9
10
// Select Common Rules, see Section 3.2.1
Rcommon = (R1 ∩ R2);
for each rule r in Rcommon do
CtxSpec = |X |;
ConfDif = |∆conf|;
sup CondDisc = |∆ | ; conf
sup DirDif = sign(∆conf · ∆conf) > 0;
Mcommon[r] = DirDif · CtxSpecw1 · ConfDifw2
end
· CondDiscw3
11 sort(Mcommon) ;
12 Tcommon = Mcommon[0]...Mcommon[n � 1] ;
∗ ∗ 13 Tcommon = Tcommon \ {r ∈ Tcommon | ∃ r ∈ Tcommon,r , r,Xr ⊆ Xr ∗Yr ⊆ Yr ∗ } ;
// Sort by score
// Select top n rules
// Remove redundancy
// Select Unique Rules, see Section 3.2.2
14 Runique = (R1 ∪ R2) \ (R1 ∩ R2);
15 supd is = 99th percentile(|∆sup| in Rcommon);
16 confd is = 99th percentile(|∆conf| in Rcommon);
17 Runique = Runique \ {r ∈ Runique | rsup < supmin + supd is } ; // Remove rules close to threshold
18 Runique = Runique \ {r ∈ Runique | rconf < con fmin + con fd is };
19 for each rule r in Runique do
20 CtxSpec = |X |;
21 ConfDif = conf ;
22 CondDisc = sup ; conf
23 Munique [r] = CtxSpecw1 · ConfDifw2 · CondDiscw3
24 end
25 sort(Munique );
26 Tunique = Munique [0]...Munique [n � 1];
∗ ∗ 27 Tunique = Tunique \ {r ∈ Tunique | ∃ r ∈ Tunique ,r , r,Xr ⊆ Xr ∗Yr ⊆ Yr ∗ };
// Merge The Rules
28 Ttop = Tcommon ∪Tunique ;
Algorithm 1: Given a data set split into two groups based on a label (such as depressive symptoms/no depressive
symptoms), select the best rules that are present in both groups (lines 3-13), and unique to one group (lines
14-27).
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:11
Data: person set P, top rule set Ttop
1 for each person p ∈ P do
2 Let Ep be all epochs involving person p;
3 Let Ep.f be all features in Ep , start empty;
4 for each rule r ∈ Ttop do
5 Er = all epochs e ∈ Ep where X is fulflled;
6 for each unimodal feature y ∈ Y do
7 rmean(y) = mean(y, Er ) ;
8 rstd(y) = std(y, Er );
9 Ep.f = Ep.f ∪ {rmean(y),rstd(y)};
10 end
11 end
12 end
Algorithm 2: Extracting contextually fltered features from the top rule set.
4.1 Data Collection
During Phase I of the study, we recruited 188 frst-year undergraduate students at a Carnegie-classifed R-1
university in the United States via emails and Facebook posts. Students were invited to the lab to provide informed
consent, download a mobile application to track sensor data from their smartphones, and receive a Fitbit Flex 2
to track their steps and sleep. They were asked to keep the application installed, and wear the Fitbit tracker over
one semester (106 days). At the beginning and the end of the semester, they were required to answer a depression
assessment questionnaire to evaluate their depressive symptoms. For their participation, the participants were
allowed to keep the Fitbit Flex 2 and received up to $205, based on their compliance.
We recruited another group of 267 undergraduate studentsin Phase II of ourstudy, one year later. 85 participants
were return participants from Phase I, 33 participants were new second-year participants, and 149 participants in
Phase II were new frst-year participants. We used a similar data collection procedure as used in Phase I. We use
this second dataset to verify the generalizability of our method.
Table 1. Information of the two studies afer removing students who dropped out or were missing a significant amount of data.
Students with a post-semester BDI-II score greater than 13 were in the depression group, in accord with the interpretation of
the BDI-II [12]. Note that owing to some subtle distinctions of the study goals, we did not collect pre-semester BDI-II scores
in Phase II.
Overall Dropped out Removed Dataset Pre-semester BDI-II Post-semester BDI-II Study Days Number Number Number Size Non-dep Grp Dep Grp Non-dep Grp Dep Grp
Phase I 106 188 28 22 138 114 24 81 57 (41.3%)
Phase II 113 267 31 24 212 - - 136 76 (35.8%)
Table 1 summarizes both phases of data collection, which was IRB-approved. During Phase I data collection,
28 students dropped out of the study owing to various personal reason. During data cleaning, we removed 22
further students who we were missing a signifcant amount of data. 138 students out of 188 recruited were used
for analysis. Among the 267 students in the Phase II dataset, 31 dropped out and 24 were removed due to missing
data, leaving 212 students.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:12 • Xu et al.
4.1.1 Ground Truth Data Collection. We employed the Beck Depression Inventory-II (BDI-II) [12], a widely used
psychometric test for depressive symptoms severity measurement, to obtain ground truth. The BDI-II has strong
psychometric properties [12, 37] and is the most widely used self-report measure of the presence and severity of
depressive symptoms in non-clinical samples and clinical trials of depression [37]. Self-reported depression on
the BDI-II has been shown to discriminate patients who were diagnosed with mild, moderate, and severe major
depressive episodes as defned by the DSM-5 [74]. Importantly for our purposes, many studies have provided
validation information and normative data about the BDI-II in large college student samples (e.g., [23, 75, 91, 92]).
The questionnaire contains 21 questions, with each answer being scored on a scale of 0-3. For college students, the
cut-ofs on this scale are 0-13 (no or minimal depression), 14-19 (mild depression), 20-28 (moderate depression),
and 29-63 (severe depression) [28]. We labeled the students whose post-semester BDI-II score was higher or equal
to 14 as having depressive symptoms.
Participants answered the BDI-II questionnaire at the beginning (week 1) and at the end (week 16) of the
semester. Forty-one percent of participants in Phase I, and thirty-six percent in Phase II, had depressive symptoms
consistent with mild or stronger depression according to their BDI-II scores. This is similar to national rates for
depression among college students: as reported in the ACHA-NCHA II [3], 35.6% of college students experienced
depression in the past year and 18.4% were diagnosed with depression.
Note that the BDI-II asks about the severity of depressive symptoms in the past two weeks. Thus, we use
passively sensed data collected throughout the semester to predict participant status on the BDI-II at the end
(week 16) of the study.
4.1.2 Passive Mobile Data Collection. We installed the AWARE framework [32] to collect sensor data unobtrusively from students’ smartphones. The application recorded students’ nearby Bluetooth addresses, call logs,
phone usage (charging activity and screen status), and location. Further, participants were required to wear a
Fitbit Flex 2 that recorded their steps and sleep status (leftmost part of Figure 1 shows the sensor type). While
Calls and Phone Usage are event-based data, Bluetooth, Location, Sleep, and Steps are sampled, time series data.
We sampled Bluetooth and Location coordinates at 1 sample per 10 minutes, Sleep at 1 sample per minute, and
Steps at 1 sample per 5 minutes. Data from AWARE was de-identifed locally on the phone and automatically
transferred over Wi-Fi to our back-end server on a regular basis. Data from Fitbit was collected using the Fitbit
API at the end of the study. Participants were required to keep their phone and Fitbit charged and carry/wear
them at all times.
4.2 Unimodal Feature Extraction
The sensor streams from which we collected data included sleep (Fitbit), steps (Fitbit), Bluetooth (phone), calls
(phone), screen use (phone) and GPS (phone). Since we are interested in aggregating sensor values into features
for the entire study, we used the approach describe in Wang et al. [86] to group raw sensor data into epochs
that capture behavior at diferent times of day. Past literature has suggested that people usually have diferent
behavior patterns during diferent times of the day [21], and between weekdays and weekends [69]. Following
Wang et al. [86], we divide the data into four epochs for weekdays (night i.e., 12am-6am, morning i.e., 6am-12pm,
afternoon i.e., 12pm-6pm, evening i.e., 6pm-12am) and the same four epochs for weekends, resulting in 8 epochs.
We then aggregate sensor streams on a per-day, per-epoch basis into daily-epoch features (such as the number
of phone calls on the morning of Tuesday, February 18, 2017). Aggregation is done on a per-day basis producing
daily-epoch features. For sampled data, such as Bluetooth data, features naturally divide on epoch boundaries.
For event-based data, such as phone calls, we use the start time of an event to determine which epoch it belongs
to (e.g., a phone call from 11:55 am to 12:05 pm, would be in the morning epoch).
Most features are aggregated using a mix of mean, maximum, minimum, and standard deviation for sampled
data, and count and duration for event-based data, if appropriate. However, some features require additional
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:13
Table 2. Sensor data and information aggregated into features.
Sensor Source Sampling Information Being Aggregated into Features Number of Samples
Per-person
Screen
AWARE
event-based
Number of unlocks per minute,
total time with interaction, total time unlocked
Number and duration of in-coming
/out-going/missed calls
39843.2 ± 22126.9
Call 379.6 ± 275.8
Bluetooth
Location
1 per 10 minutes
Number of unique devices,
number of scans of most/least frequent device
GPS latitude, longitude, altitude
24579.0 ± 106960.9
9692.8 ± 4444.2
Sleep Fitbit 1 per minute Asleep/restless/awake/unknown duration and onset 34963.6 ± 15630.6
Step 1 per 5 minutes Number of steps 23390.6 ± 10197.7
pre-processing. For location features, we calculate location variance (sum of the variance in latitude and longitude
coordinates), total distance traveled, average/variance of speed and circadian movement (the degree that a person’s
mobility patterns follow a 24-hour circadian cycle [70]). We also cluster locations within a epoch and globally, to
determine the number of signifcant places, number of transitions between places, radius of gyration [19], percentage
of time spent at top-3 frequented clusters/moving/rarely visited locations, length of stay at clusters and location
entropy. We analyze the user’s location patterns in relation to the college campus map, focusing specifcally on
Greek houses (which tend to hold social events), residential halls, athletic facilities, green spaces, and academic
buildings. For sleep, we add sleep efciency, and sleep onset. For steps, we group activity into active bouts and
sedentary bouts (less than 10 steps in a 5-minute interval). For Bluetooth, we cluster devices into frequently seen
groups and count prevalence of each cluster.
Finally, we aggegate daily features into full features, within an epoch, using the mean and standard deviation
of daily-epoch features. For example, the average number of calls (weekday morning epoch) is calculated as an
average over the daily-epoch feature which captures the number of calls made each weekday morning (6am-12pm).
We calculate a total of 212 daily-epoch features from the raw sensor streams (summarized in Table 2. This results
in a total of 212 x 2 (mean and std deviation), or 424 features per epoch. The pipeline introduced in Section 4.3 is
run separately on each epoch, and makes use of full features to calculate rules. It then creates new full features
that aggregate only some days, as described in Section 3.3.
Each sensor stream results in features that are designed to capture behavior variability related to variables that
might be infuenced by depressive symptoms [7]. For example, depression can cause sleep disturbances [80] and
diminished concentration [24]. The former might impact features such as time in bed, while the latter might
impact a metric such as phone use, which could rise with distraction and depression [24].
4.3 Pipeline for Detecting Depression
Our pipeline for depression detection is shown in Figure 2. As described next, the data set is split into two parts
(Dataset for rule mining, and Dataset for model training). The frst is used to calculate and select features; to
which the algorithm described in Section 3 is applied. The results of this algorithm are used to create contextually
fltered features that are combined with the unimodal features calculated on the dataset for model training. This
second data set is then used to train and test a model using AdaBoost [35] with decision-tree-based component
classifers, with leave-one-out cross-validation. More detail on each of these steps is provided below.
4.3.1 Data Set Preparation. To avoid overftting, we randomly divided our dataset on a per-person basis into two
subsets. We created a RuleGenerateSet of 50 people for extracting rules (20 in the depression group; 30 other),
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:14 • Xu et al.
Fig. 2. The detailed pipeline of rule mining, pairing, selecting and models training. The dashed frame highlights the novel
procedures in the pipeline.
and a TrainTestSet of 88 people to train and test the machine learning models (37 in the depression group; 51
other). We applied our rule mining and selecting algorithm (Section 3.1 and 3.2) on the RuleGenerateSet and
calculated the contextually fltered features (Section 3.3) on the TrainTestSet.
4.3.2 Feature Selection. We selected a subset of the 424 features in each of the eight epochs to reduce computational complexity. We employed mutual information [67] to perform feature selection. We used the method
described in [54] to estimate the mutual information gain. Random noise was added to the variables to remove
repeated values, thus each calculation batch would have a diferent ranking order and have a slightly diferent top
feature set. We started with the whole feature set, repeated the calculation and iteratively selected the intersection
of the top 50 features until the number of features converged. We ended up with 23 top features on average
(Min = 18, Max = 29, 181 in total) among the 8 epochs. We denote these 181 features as the unimodal feature
set, which we used to train baseline classifers since this approach is similar to the common practices used in
previous literature related to depression detection [84].
We considered the top features in each epoch group to identify the daily-epoch features to be used for rule
mining. Specifcally, a daily-epoch feature would be selected as long as either the mean or standard deviation of
the feature is in the top feature set. We obtained an average of 20 (Min=15, Max=29) top daily-epoch features in
each epoch. We used these features for rule mining in Section 4.3.
4.3.3 Feature Preparation before Rule Mining. ARM is typically applied on symbolic or categorical data. We
therefore recoded each of the selected features, for rule selection using ARM only, into the three categories: low,
moderate, and high, using a binning method. Each category contained 33.3% of each feature, which means the
two cut-of thresholds were 33.3 and 66.6 quantiles of the data. Note that since each individual has diferent
behavior patterns, we discretized the data within each individual rather than across individuals. Ideally, each day
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:15
would contain all of the selected top daily-epoch features. However, sometimes not all features were available
due to missing data arising from issues with low smartphone battery, data transfer from the phone to the server,
or users not giving permission for certain data to be collected. In each epoch, we fltered out the days where
more than half of the features were missing before rule mining.
4.3.4 Rule Mining and Selecting. Once we obtained the discretized top daily-epoch features, we fed them into our
pipeline. We employed the tools provided by [33] to mine rules 16 separate times: Once in each of the 8 epochs
for each class of users (depressive symptoms and no depressive symptoms). Some epochs (e.g., weekday morning
group) would generate over one million rules if their threshold were as low as other epochs. Therefore, we set
supmin and confmin in each group separately (0.07-0.19) to control the number of generated rules. We found
approximately 16,000 rules (Min = 4,500, Max = 26,000) among the groups. For each epoch, we used Algorithm 1
(top) to select the best common rules, and Algorithm 1 (bottom) to select the best unique rules, for the two classes
of participants. Note that we used grid search for Equation 1, ranging from 0.0 to 2.0 with 0.5 as the interval, to
set the best weights (w1,w2,w3) which were (1.0, 1.5, 0.5). We used the F1 score in the RuleGenerateSet as the
metric for selection (using the same procedure in Section 4.3.5). We obtained an average of 13 rules (Min = 6,
Max = 19 rules) per epoch, 105 in total.
4.3.5 Feature Extraction and Model Training. After we obtained the rules, we turned to the TrainTestSet and used
Algorithm 2 to extract an average of 17 contextually fltered features (Min = 8, Max = 23) per epoch, 137 in total.
Note that one rule X → Y can have multiple features y in Y, thus the number of contextually fltered features
generated can be greater than the number of rules. We aggregated each y in Y, for each individual, using mean
and standard deviation, over daily-epochs that matched X. We added 274 additional features to the unimodal
features already available for each participant (137×2). From this, model training can commence.
5 VALIDATION OF ALGORITHM
In this section, we verify our methods from several perspectives. We frst show in Section 5.1 that the top rules
can capture the behavior diferences between the student group with depressive symptoms and the student group
without depressive symptoms. These results indicate that the rules from our method have good interpretability
and can help better understand students’ life experiences related to depressive symptoms. Then, in Section 5.2,
we demonstrate that the best classifer trained on our contextually fltered features can achieve an average of 9.7%
performance increase over the baseline model trained on unimodal features. We further verify the generalizability
of our method in Section 5.3. Our rules mined in Section 5.2.1 can be directly applied to a separate dataset to
extract contextually-fltered features and train classifers on that dataset, and the resulting model outperforms
the baseline model on the same dataset by 5.6%. We also re-execute our pipeline on the separate dataset, and our
best model has an average increase of 7.1% over the equivalent baseline. These results verify the efectiveness
and generalizability of our method.
5.1 Rules Can Capture Routines Behaviors and Behavior Patern Diferences between Groups
Our method described in Section 3 aims to fnd rules that can distinguish between classes of participants. We
show that the top rules discovered in our dataset are able to capture students’ behavior patterns as well as the
behavior diferences between students who report depressive symptoms on the BDI-II and those who do not.
Figure 3 visualizes heatmaps that represent how many students’ behavior was captured by each of the 105
rules throughout the study period. From both heatmaps of weekdays and weekends, we observed abnormal color
patterns during the middle of the study. The academic calendar of the university showed that this period was
when midterm examinations took place, followed by a spring break. Students would usually have a stressful
period to prepare for examinations, and then have a brief relaxing period. As a result, during the midterm and
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:16 • Xu et al.
(a) Weekday Rules (Lef: Non-depression Group, Right: Depression Group)
(b) Weekend Rules (Lef: Students with no depressive symptoms, Right: depressive symptoms)
Fig. 3. Heatmaps of prevalence of the top 105 rules among students with and without depressive symptoms, for weekends
and weekdays. X axis is day of semester, Y axis shows rules aligned from morning to night epochs. Color indicates the
proportion of students in a class that fulfill a particular rule. The brighter the color, the larger proportion of students having
the patern. The abnormal vertical color paterns in the middle of both figures correspond to the mid-term examines and the
break period, indicating that the rules can capture people’s routine behavior. Rule names on the lef indicate some example
rules that are significantly diferent between the two classes of participants (see Table 3).
break period, some rules, which otherwise match many students, match very few students (represented by dark
areas in the middle-top of the heatmap). This is positive evidence that contextually fltered features capture routine
behavior, unlike their unimodal counterparts.
We further investigate the rules that capture diferent behavior patterns between students with depressive
symptoms and students without depressive symptoms. We used a paired t-test on every rule to identify the rules
that were signifcantly diferent between the two groups. Table 3 summarizes a subset of the top 20 rules in
weekday/weekend rules that show the strongest signifcant diference (see the full list of top rules in Appendix).
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:17
(a) A Rule Common in Groups. More in Non-dep Group (b) A Rule that is Unique to Non-dep Group
(c) A Rule Common in Groups. More in Dep Group (d) A Rule that is Unique to in Dep Group
(e) A Similar Rule with Same Context Unique To (f ) A Similar Rule with Same Context Unique To
Non-dep Group Dep Group
Fig. 4. Heatmaps of example rules that captures behavior diferences between depression group and non-depression group.
The percentage indicates the average proportion of students fulfilling the rule throughout the study period. Color indicates
proportion of students on each day (X axis) Table 3 summarizes the details of the rules.
Weekday night rule No.5 (the frst row in Table 3) indicates that students are be likely to have good sleep
quality when they are on-campus and have low co-location (i.e., the number of Bluetooth encounters) during
weekday nights. This rule is present in both groups, but appears signifcantly more in the non-depression group
(t75 = 3.99,p < 0.001, see Figure 4a). Weekday night rule No.9 (the second row in Table 3) indicates students’
sleep bouts (periods of continuous sleep) are likely to be longer when they are on-campus and sleep efciency is
high. This rule is unique to the non-depression group (t75 = 2.88,p < 0.01, see Figure 4b).
Weekend morning rule No.3 (the third row in Table 3) indicates that when students have poor sleep (the
sleep is intermittent), they are more likely to have low mobility (few location transitions) during weekend
mornings (6am - 12pm). This rule is found in both groups, with signifcantly more students in the depression
group (t29 = �2.54,p < 0.05, see Figure 4c) experiencing this. The CondDisc also shows that students with
depressive symptoms are more like to match this rule’s context (0.36 vs. 0.27), indicating worse sleep quality.
Another example rule refects the relationship of mobile phone usage, sleep duration and depression. Weekend
night rule No. 19 (the fourth row in Table 3) is only ranked high enough to be selected in the depression group.
This suggests the potential efect of phone usage on sleep quality for depressive students. We discuss these
fndings more in Section 6.
We also fnd interesting unique rules in each group that refected the diferences between the two groups.
Weekend morning rules No. 10 and No.11 (the last two rows in Table 3) share the same context set X, but have
diferent Ys. Rule No. 10 is unique to the non-depression group and rule No. 11 is unique to the depression group.
They indicated that students without depressive symptoms are more likely to have a high sleep efciency when
their location movement is low during weekend morning periods, but students with depressive symptoms are
more likely to only have a medium sleep efciency for the same context (see Figure 4e and 4f).
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:18 • Xu et al.
Table 3. Examples of rules that capture behavior diference between students with and without depressive symptoms. We
tested a rule’s ability to diferentiate between classes using a paired t-test; significance level is indicated in the Rule column.
We selected rules for this table that show the strongest significant diference. All top 20 weekday/weekend rules can be found
in the appendix. Type is the method by which the rule was found. Prop in Non-dep and Prop in Dep are the proportion of
students in a class that fulfill the rule, averaged over days in the study. Note that M varies between diferent epochs (people
can have diferent behavior patern during the day) as well as their types (i.e., common or unique). E.g., M of a weekday
night rule can be much bigger than that of a weekday morning rule.
Prop in Prop in Ctx Conf Cond Rule X Y Type M Non-dep Dep Spec Dif Disc
- [CampusMap] Percentage of Wkdy time of-campus (low) [Sleep] Sleep Night Common 11.4% 8.5% 2 0.137 0.094 0.031 - [Bluetooth] Number of efciency (high) No.5∗∗∗
unique device of others (low)
- [CampusMap] Percentage of Wkdy [Sleep] Maximum time of-campus (low) Unique Night length of 10.1% 7.9% 2 0.535 0.335 0.453 - [Sleep] Sleep (Non-dep) No.9∗∗ asleep bouts (high) efciency (high)
- [Sleep] Number of Wkend bouts being asleep (high) [Location] Number of Morning Common 9.2% 12.3% 2 0.054 0.081 0.007 - [Sleep] Number of location transition (low) No.3∗
bouts being restless (high)
Wkend - [Screen] Mean length of [Sleep] Mean length of Unique Night 7.8% 10.3% 1 0.387 0.374 0.147 screen being unlock (high) being asleep (low) (Dep) No.19∗
- [Location] Number of
Wkend location transition (low) [Sleep] Sleep Unique Morning - [CampusMap] Number of 11.2% 5.5% 2 0.456 0.469 0.422 efciency (high) (Non-dep) No.10∗∗∗ building transition
on-campus (low)
- [Location] Number of
Wkend location transition (low) [Sleep] Sleep Unique Morning - [CampusMap] Number of 9.8% 16.6% 2 0.435 0.483 0.398 efciency (medium) (Dep) No.11∗∗∗ building transition
on-campus (low)
∗ indicates p < 0.05, ∗∗ indicates p < 0.01, ∗∗∗ indicates p < 0.001
5.2 Contextually Filtered Features Lead to Higher Performing Machine Learning Models
In this section, we show that the models trained on the contextually fltered features extracted via our method can
achieve a better performance than other models. We also perform an ablation study on the three components in
metric M (CtxSpec, ConfDif, CondDisc), which demonstrates the relative importance of the three characteristics
as ConfDif > CtxSpec > CondDisc. We validate the generalizability of our method by applying it to separate
dataset (the Phase II data described in Section 4.1).
5.2.1 Contextually Filtered Features Can Beter Identify Students with Depressive Symptoms. Recall that after
we obtained the best rules from our RuleGenerateSet (50 students: 20 in the depression group and 30 in the
non-depression group), we extracted contextually fltered features using these rules on the TrainTestSet (88
students, 37 in the depression group and 51 in the non-depression group).
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:19
Table 4. Comparison of baseline machine learning classifiers and contextually filtered features. The models above the dashed
line are baselines. Models based on unimodal features, contextually filtered features, and hybrid features, are trained using
AdaBoost [35] with decision-tree-based component classifiers, with leave-one-out cross-validation. The number of estimator
and the maximum depth of the decision-tree are hyper-parameters that can be tuned. We use grid search to select the best
parameters for each model. Our best model with hybrid features has the number of estimator as 10 and the maximum depth
as 3. A t-test on the test results between the hybrid features and unimodal raw features show that our method significantly
outperforms the standard method (p < 0.01).
Classifcation Features Accuracy Precision Recall F1 Score
Majority 0.579 0.579 1.000 0.734
Best Single Feature 0.704 0.725 0.755 0.740
CPAR [95] Class Association Rules 0.608 0.629 0.850 0.723
AdaBoost [35] Unimodal Features 0.716 0.725 0.771 0.747
AdaBoost [35] Contextually Filtered Features 0.807 0.765 0.886 0.821
AdaBoost [35] Hybrid Features 0.818 0.843 0.843 0.843
Performance Increase of Hybrid over Unimodal 10.2% 11.8% 7.2% 9.6%
Average Increase: 9.7%
We tested two feature sets: 1) Contextually Filtered Features: only the features extracted based on rules
(vector length 274); 2) Hybrid Features: both the contextually fltered features and the unimodal features
(vector length 455 (274+181), see Section 4.3.2). We employed AdaBoost [35] with decision-tree-based component
classifers during the training. To avoid over-ftting, we used leave-one-out cross-validation, since previous work
has consistently found that this method is approximately unbiased and has small variance [79, 96].
We compared our models with four baselines: 1) Majority: the classifer simply predicts the major label in the
dataset (i.e., no depressive symptoms; 2) Best Single Feature: prediction is made based on the value of the single
feature that best distinguishes the classes; 3) Class Association Rules: labels are embedded into the input during
association rule mining and the generated rules are used for classifcation [56, 95]; 4) Unimodal Features: the
model is trained on the unimodal features before rule mining (vector length 181, a common practice in previous
work [84]).
We summarize the results in Table 4 with four metrics: accuracy, precision, recall and F1 score. The model
trained on the hybrid features has the best performance, followed by the model trained on contextually fltered
features. Our best model has accuracy 0.818 and F1 score 0.843. It outperforms the baseline model using the
unimodal features, by an average of 9.7% absolute increase, indicating the efectiveness of our method. Since
the area of using mobile sensing for depression detection is fairly new, we lack a benchmark for comparison.
However, these baselines provide strong evidence that our model is either better than previous work [19, 30, 84],
or comparable to the state-of-the-art [70, 87].
5.2.2 Relative Importance of The Three Characteristics For Classification. M (Equation 1) is composed of three
characteristics: Contextual Specifcity, Confdence Diference and Condition Discrepancy. It is interesting to
examine which component is important for rule selection, so that we can have a better understanding of metric
M.
The weight values, calculated using grid search in Section 3, refect the relative importance of the three
characteristics. The greater the weight value is, the more important role the corresponding characteristic plays in
the metric M. Our weights show the importance of ConfDif (w2 = 1.5), followed by CtxSpec (w1 = 1.0), followed
by CondDisc (w3 = 0.5).
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:20 • Xu et al.
Table 5. Results of the ablation study. One of the three weight values is set to zero in each trial, which can lead to diferent
rule sets, and new models are trained based on these rules. The other weights (w1,w2,w3) are set to (1.0, 1.5, 0.5), as described
in Section 3. The results are presented in an ascending order according to F1 score.
Classifcation Ablated Metric Accuracy Precision Recall F1 Score
ConfDif - w2 = 0 0.761 0.804 0.788 0.796
Depression Detection with
Contextually Filtered Features
CtxSpec - w1 = 0
CondDisc - w3 = 0
0.761
0.784
0.863
0.808
0.759
0.824
0.807
0.816
No Metric Ablated 0.807 0.765 0.886 0.821
We further examined the efect of each characteristic, using an ablation study on the three weights. We set one
of the weights to zero in each trial and redo the rule selection, feature extraction and modeling training. Table 5
summarizes the results. Removing CtxSpec (w1 = 0) and ConfDif (w2 = 0) lead to similar results, with both models
having a drop in accuracy of 4.5 percentage-points. The model without CtxSpec has a slightly higher F1 score than
without ConfDif. Removing CondDisc (w3 = 0) has the least impact on the results, with two percentage-points
drop in accuracy. These results are consistent with the relative order of weight values. Confdence Diference is
the most essential part in the metric M, and the Condition Discrepancy is the least important part.
5.3 Verification on A Second Dataset
Conducting such a large-scale data collection study (as described in Section 4) can be very expensive in terms of
time and money. Despite this, knowing how well our method can perform on another dataset can tell us about its
generalizability.
We collected a separate Phase II dataset one year later from the same university (as described in Section 4.1).
Of the 211 participants with good data in Phase II, 65 also had participated in the Phase I study. The same data
collection apps and wearable devices were used in the two phases. This provides a unique opportunity to verify
our method in a consistent way.
There are three aspects to the robustness of our method: 1) model-level, 2) rule-level, and 3) pipeline-level. Most
existing work tests robustness using cross-validation in which training and testing are an average of iterative
trials run on a single data divided into train and test data. Our work does this as well. However, unlike all of the
past work we have been able to fnd, we have the opportunity to also test our work on multiple data sets. This
lets us test several forms of robustness:
(1) To study model-level robustness, we run the whole pipeline on Phase I dataset, train the model on the
Phase I dataset, and test the model on the Phase II dataset.
(2) To study rule-level robustness, we split the pipeline into two datasets, mine the rules from the Phase I
dataset, use these rules to extract contextually fltered feature on Phase II dataset, and train/test the model
on the Phase II dataset.
(3) To study pipeline-level robustness, we replicate the whole pipeline on Phase II.
In this work, we test all 3 forms of robustness. Table 6 summarizes the results of 2) rule-level and 3) pipelinelevel robustness. We also tested (1) model-level robustness. However, our model is not reliable on the second
dataset (accuracy of 54.2%, no better than a majority-based baseline predictor).
5.3.1 Verification of The Generalizability of Rules. We select rules using Phase I data. We then use the rules on
the the Phase II dataset to extract contextually fltered features and train the models. The top half of Table 6
summarizes the results. Despite the similarities in the data collection and in the student population, we expect a
drop in the performance from Phase I (see Table 4), due to not having the exact same participants and to Phase II
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:21
Table 6. Verification results. The same model and cross-validation technique are used as in Table 4. A paired t-test comparing
the hybrid features and unimodal features shows strong significance, for both the rule and pipeline verification (p < 0.001).
Classifcation Features Accuracy Precision Recall F1 Score
Majority 0.643 0.643 1.000 0.783
Best Single Feature 0.646 0.655 0.949 0.775
Verifcation On Class Association Rules 0.601 0.642 0.854 0.733
Phase II Dataset with Unimodal Features 0.656 0.701 0.809 0.751
The Rules From Phase I Contextually Filtered Features 0.689 0.757 0.779 0.768
Hybrid Features 0.731 0.762 0.846 0.801
Performance Increase of Hybrid over Unimodal 7.5% 6.1% 3.7% 5.0%
Average Increase: 5.6%
Majority 0.656 0.656 1.000 0.793
Best Single Feature 0.702 0.745 0.824 0.782
Verifcation with Class Association Rules 0.626 0.804 0.691 0.743
The Pipeline Unimodal Features 0.740 0.760 0.884 0.817
on Phase II Dataset Contextually Filtered Features 0.809 0.877 0.826 0.850
Hybrid Features 0.840 0.857 0.907 0.881
Performance Increase of Hybrid over Unimodal 10.0% 9.7% 2.3% 6.4%
Average Increase: 7.1%
occurring one year after Phase I. Indeed, the best model has accuracy 0.731 and F1 score 0.801 (compared to 0.818
and 0.843, respectively one Phase I only).
In addition, our model still outperforms all the baselines on the Phase II dataset. It also outperforms the model
built with the unimodal features by an average of 5.6% absolute increase on the metrics of accuracy, precision,
recall and F1 score. Baselines were all prepared using only Phase II data, making these results all the more
impressive. These results verify the generalizability and overall stability of the outcome rules from our method.
5.3.2 Verification of The Generalizability of Pipeline. As an additional verifcation, we reapply the whole pipeline
as described in Section 4.3 on Phase II. We omit the grid search and set the weights asw1 = 1.0,w2 = 1.5,w3 = 0.5,
since M, as a general formula capturing interesting rules, should be the same on either dataset. The bottom half
of Table 6 summarizes the results. The best model (hybrid of unimodal and contextually fltered features) has an
accuracy of 0.840 and F1 score of 0.881.
This pipeline again outperforms the baseline models, which are also trained entirely on Phase II. This model
also outperforms the unimodal features model by an average of 7.1% absolute increase on the metrics. These
results validate the generalizability of our overall algorithm.
6 DISCUSSION
In this section, we discuss insights obtained from our analysis and implications for intervention design for
depression. We also discuss potential directions for generalizing and improving our approach.
6.1 Relation to the Depression Literature
Our fndings in Section 5 are consistent with the current literature on depression, adding support for the validity
of our methods. For example, the features in Y in weekday night rule No.5 and No.9 (see top 2 rules in Table 3)
suggest that those students with depressive symptoms are less likely to have good sleep quality (high sleep
efciency and long asleep bouts). The contrast between weekend morning rule No.10 and No.11 (see bottom 2
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:22 • Xu et al.
rules in Table 3) also reveal this for students who are in the same context. These results can be supported by
relevant fndings in psychology and clinical psychiatry that sleep disturbance is a common symptom of depression
[7, 78, 80]. Weekend morning rule No.3 implies a relationship between depression and both mobility and sleep,
that not only echoes previous literature regarding the efect of depression on sleep [7, 87], but also is supported
by the fndings of other studies similar to ours which show that depression and diminished locomotion co-occur
[19, 70]. Weekend night rule No. 19 suggests the potential efect of phone usage on sleep quality for students with
symptoms of depression. Although this rule does not show a direct relation between phone usage and depression,
it does refect the rich literature that depression may lead to more phone usage [24, 36, 70, 84].
6.1.1 Location and Sleep Information for Depression Detection. The top rules for feature extraction and model
training cover all type of sensors (except phone calls) in Figure 1, showing the multimodality of our method. The
absence of calls in these rules might be explained by the fact that an increasing number of students use social
media platforms or text messages, instead of phone calls, for communication, resulting in less informative data
in the call logs. Among the 105 top rules, we observed a large number of rules involving location and sleep: 89
rules had at least one feature (in either X or Y) relevant to Location, 75 rules had at least one feature relevant to
CampusMap which is actually based on Location, and 50 rules had at least one feature relevant to Sleep. Examples
in Table 3 also reveal the dominance of location and sleep information in the rules. This resonates with fndings
in other work about mobile sensing for depression detection [19, 70, 84, 87].
6.2 Robustness and Generalizability of Our Method
Our results demonstrate strong robustness at the rule and pipeline level. Our approach is signifcantly better
than baseline models on the Phase II data in both cases. To our knowledge, no prior work has explored this issue
and our dataset is unique in allowing for multi-year robustness verifcation.
We found that model robustness is not as reliable (accuracy of 54.2%, no better than a majority-based baseline
predictor). An important area of future work will be the development of modeling approaches that are robust
over multiple years and in new student populations.
6.3 Beyond Depression Detection
Our method in Section 3 is agnostic to the specifc classes on which it is trained. In this paper, we focus on
depression detection among college students, and split the dataset based on student scores on the BDI-II, which
indicate the presence of depressive symptoms. It would be interesting to explore other prediction tasks. For
instance, instead of focusing on detecting which students in our population will have symptoms of depression at
the end of the semester, we could focus on detecting which students are successfully coping with their depressive
symptoms by maintaining or improving their BDI-II score over the course of the semester, and which students
are experiencing more severe depressive symptoms at the end of the semester. This could be explored by splitting
based on the direction of change in the BDI-II score from pre-semester to post-semester, for those students with
medium to high BDI-II scores at the start of the semester.
Further, our method can be applied outside the domain of depression, and to other time-series datasets about
human behavior, to detect behaviors and states of interest in the studied populations. Compared to previous
work such as [87], our method does not depend on domain knowledge and hand-crafted features.
One open problem for our approach is how to generalize it to multi-class rather than two class problems. While
this should be a straightforward extension of our rule selection methods, it remains as future work.
6.4 Leveraging Association Rule Mining and Other Algorithms
There are a number of metrics for selecting rules mined using ARM that are not covered in this paper (lift
[59], match [89], etc.). We heuristically designed our metric M using criteria that capture diferences between
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection • 116:23
two groups. It has some space for improvement. For instance, the current M will rank a rule with high context
probability (P(X)) but diferent signs (DirDif = 0) at bottom, which may miss some interesting information.
More complex metrics can be explored based on the outcomes of traditional ARM. Recent work such as temporal
association rule mining [44, 85] and graph association rule mining [14, 60], have the potential to take temporal
information into account. In addition, sequential pattern mining [15] and sequential rule mining [34] can also be
employed to investigate temporal sequences or behavior sequences. Moreover, some deep-learning techniques
such as long short-term memory (LSTM) [41] may capture more nonlinear and complex relationships among
features in the neural network. Although current deep-learning models are relatively less interpretable, more and
more works try to understand the principle of neural network [48]. These approaches all have the potential to be
combined with our method to identify contextualized behavior diferences between groups, providing richer
information to understand human behavior.
7 LIMITATIONS
In this section, we describe a few of the limitations of our work. First, we only had the post-semester BDI-II score
to use as ground truth, resulting in a single label per student over the whole semester. As such, compared to other
work such as [87], we were not able to investigate more fne-grained dynamics of students’ behavior. In the future,
we plan to collect depression scores more frequently to support a more fne-grained analysis. Second, in the
Phase II dataset, we did not explicitly remove participants who also participated in the Phase I dataset. This could
afect the results of Section 5.3.2, where we mined rules from Phase I and tested it on Phase II, since there were
overlapping students in both datasets. While the re-application of the entire pipeline on Phase II did demonstrate
the generalizability of our approach, separating out the repeat participants could help in better understanding the
generalizability of the rules extracted from Phase I. Third, our method relies on the unimodal features extracted
from the dataset. The rule mining is applied on the unimodal features. Thus the capability of our method is
limited by these features. If the unimodal features do not capture any aspect of users’ behavior, neither can our
method do. There may exist more meaningful features to be extracted at the unimodal feature extraction stage
(see Section 4.2), which may enable our method to better capture behavior routines as well as behavior pattern
diferences. Finally, further methods for dealing with missing data could be explored. We removed user-days
points that were missing more than half of the features from the study to avoid the bias of low-quality data.
But this might neglect the case where a day of missing data could be related to students’ depression status (e.g.,
not charging the phone because of the diminished desire for social interaction [7]). However, the percentage
of students with depressive symptoms on the BDI-II who were removed from the dataset due to missing data
(8 out of 24) is similar to the percentage who were not removed, which lends us confdence that our data is
representative even after those students were removed.
8 CONCLUSION
In this paper, we present a new method based on association rule mining for generating contextually fltered
features in an automated way, which can perform betterthan standard feature selection approachesfor depression
detection. We apply our novel method on a passive mobile and wearable dataset with 138 college students, whose
depressive symptoms at the end of the semester were measured by their post-semester BDI-II score. We show that
the best rules selected by our method are highly interpretable and can capture students’ routine behaviors, and
behavior pattern diferences between students with and without depressive symptoms. Based on the resulting
contextually fltered features, we train classifers to predict whether a student will have depressive symptoms
at the end of the semester (i.e., the post-semester BDI-II score greater than 13) based on their behavior during
the semester. We demonstrate that our best model outperforms a standard model by an average of 9.7% across
a variety of metrics. We further verify the generalizability of our method by applying both the rules from the
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 3, No. 3, Article 116. Publication date: September 2019.
116:24 • Xu et al.
original dataset, and the overall method, to a second similar dataset. Our best model outperforms the standard
approach by an average of 5.6% and 7.1%, respectively.