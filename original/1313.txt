Abstract
We revisit the online UNIT CLUSTERING and UNIT COVERING problems in higher dimensions: Given a set of n points in a metric space, that arrive one by one, UNIT CLUSTERING asks to partition the points into the minimum number of clusters (subsets) of diameter at most one; whereas UNIT COVERING asks to cover all points by the minimum number of balls of unit radius. In this paper, we work in ℝ𝑑 using the 𝐿∞ norm. We show that the competitive ratio of any online algorithm (deterministic or randomized) for UNIT CLUSTERING is Ω(𝑑). In particular, it depends on the dimension d, and this resolves an open problem raised by Epstein and van Stee (Theor Comput Sci 407(1–3):85–96, 2008). We also give a randomized online algorithm with competitive ratio 𝑂(𝑑2) for UNIT CLUSTERING of integer points (i.e., points in ℤ𝑑, 𝑑∈ℕ, under the 𝐿∞ norm). We show that the competitive ratio of any deterministic online algorithm for UNIT COVERING is at least 2𝑑. This ratio is the best possible, as it can be attained by a simple deterministic algorithm that assigns points to a predefined set of unit hypercubes. We complement these results with some additional lower bounds for related problems in higher dimensions.

Access provided by University of Auckland Library

Introduction
Covering and clustering are ubiquitous problems in the theory of algorithms, computational geometry, optimization, and others. Such problems can be asked in any metric space, however this generality often restricts the quality of the results, particularly for online algorithms. Here we study lower bounds for several such problems in ℝ𝑑, for a positive integer d, under the 𝐿∞ norm. Recall that a ball under the 𝐿∞ norm is an axis-aligned hypercube. We first consider their offline versions.

Problem 1
k-CENTER. Given a set of n points in ℝ𝑑 and an integer k, cover the set by k congruent balls centered at k of the points so that the diameter of the balls is minimized.

The following two problems are dual to Problem 1.

Problem 2
UNIT COVERING. Given a set of n points in ℝ𝑑, cover the set by balls of unit diameter so that the number of balls is minimized.

Problem 3
UNIT CLUSTERING. Given a set of n points in ℝ𝑑, partition the set into clusters of diameter at most one so that the number of clusters is minimized.

Problems 1 and 2 are easily solved in polynomial time for points on the line (𝑑=1); however, both problems become NP-hard already in the Euclidean plane [22, 28]. Factor 2 approximations are known for k -CENTER in any metric space (and so for any dimension) [21, 23]; see also [29, Ch. 5], [30, Ch. 2], while polynomial-time approximation schemes are known for UNIT COVERING for any fixed dimension [25]. However, these algorithms are notoriously inefficient and thereby impractical; see also [6] for a summary of results and different time vs. ratio trade-offs.

Problems 2 and 3 look similar; indeed, one can go from balls to clusters and vice versa in a straightforward way: The balls in a unit covering form unit clusters if we assign multiply covered points to unique balls. Conversely, the points in a unit cluster are contained in a unit ball under 𝐿∞ norm, as the 𝑥𝑖-coordinates of the points differ by at most 1 for 𝑖=1,…,𝑑. As such, the two problems are identical in the offline setting under the 𝐿∞ normFootnote1.

We next consider their online versions. In this paper we focus on Problems 2 and 3 in particular. It is worth emphasizing two common properties: (i) a point assigned to a cluster must remain in that cluster; and (ii) two distinct clusters cannot merge into one cluster, i.e., the clusters maintain their identities.

The performance of an online algorithm 𝖠𝖫𝖦 is measured by comparing it to an optimal offline algorithm 𝖮𝖯𝖳 using the standard notion of competitive ratio [7, Ch. 1]. The competitive ratio of 𝖠𝖫𝖦 is defined as sup𝜎𝖠𝖫𝖦(𝜎)𝖮𝖯𝖳(𝜎), where 𝜎 is an input sequence of request points, 𝖮𝖯𝖳(𝜎) is the cost of an optimal offline algorithm for 𝜎 and 𝖠𝖫𝖦(𝜎) denotes the cost of the solution produced by 𝖠𝖫𝖦 for this input. For randomized algorithms, 𝖠𝖫𝖦(𝜎) is replaced by the expectation 𝐸[𝖠𝖫𝖦(𝜎)], and the competitive ratio of 𝖠𝖫𝖦 is sup𝜎𝐸[𝖠𝖫𝖦(𝜎)]𝖮𝖯𝖳(𝜎). Whenever there is no danger of confusion, we use 𝖠𝖫𝖦 to refer to an algorithm or the cost of its solution, as needed.

When discussing lower bounds for a randomized online algorithm, one can distinguish between two types of adversaries [5]. An adaptive online adversary constructs the next input item (e.g., point) online, based on the previous input items and previous actions of the algorithm. In contrast, an oblivious adversary must construct the entire input sequence in advance, without having access to the actions of the algorithm. Obviously, an adaptive adversary is more powerful, hence the competitive ratio against an adaptive adversary is greater or equal than against an oblivious adversary. Unless specified otherwise, upper bounds on the competitive ratio for randomized online algorithms assume an adaptive adversary, and lower bounds an oblivious adversary. Note, however, that for deterministic online algorithms, the competitive ratio is the same under both adversarial models.

Related Previous Work Charikar et al. [11] studied the online version of UNIT COVERING. The points arrive one by one and each point needs to be assigned to a new or to an existing unit ball upon arrival; the 𝐿2 norm is used in ℝ𝑑, 𝑑∈ℕ. The location of each new ball is fixed as soon as it is opened. The authors provided a deterministic algorithm of competitive ratio 𝑂(2𝑑𝑑log𝑑) and gave a lower bound of Ω(log𝑑/logloglog𝑑) on the competitive ratio of any deterministic online algorithm for this problem.

Recently, Dumitrescu, Ghosh, and Tóth [17] showed that the competitive ratio of Algorithm Centered for online UNIT COVERING in ℝ𝑑, 𝑑∈ℕ, under the 𝐿2 norm is bounded by the Newton numberFootnote2 of the Euclidean ball in the same dimension. In particular, this ratio is 𝑂(1.321𝑑). They also established a lower bound of 𝑑+1 for every 𝑑≥1 (and 4 for 𝑑=2).

Chan and Zarrabi-Zadeh [10] introduced the online UNIT CLUSTERING problem. Whereas the input and the objective of this problem are identical to those for UNIT COVERING, this latter problem is more flexible in that the algorithm is not required to produce unit balls at any time, but rather the smallest enclosing ball of each cluster should have diameter at most 1; moreover, a ball may change (grow or shift) in time. The 𝐿∞ norm is used in ℝ𝑑, 𝑑∈ℕ. The authors showed that several standard approaches for UNIT CLUSTERING, namely Algorithm Centered, Algorithm Grid, and Algorithm Greedy, all have competitive ratio at most 2 for points on the line (𝑑=1). Moreover, the first two algorithms above are applicable for UNIT COVERING, with a competitive ratio at most 2 for 𝑑=1, as well.

In fact, Chan and Zarrabi-Zadeh [10] showed that no online algorithm (deterministic or randomized) for UNIT COVERING can have a competitive ratio better than 2 in one dimension (𝑑=1). They also showed that it is possible to get better results for UNIT CLUSTERING than for UNIT COVERING. Specifically, they devised the first algorithm with competitive ratio below 2 for 𝑑=1, namely a randomized algorithm with competitive ratio 15/8; they further improved this ratio to 11/6 [31]. Moreover, they developed a general method to achieve competitive ratio below 2𝑑 in ℝ𝑑 under the 𝐿∞ norm for any 𝑑≥2, by lifting the one-dimensional algorithm to higher dimensions. In particular, the existence of an algorithm for UNIT CLUSTERING with competitive ratio 𝜌1 for 𝑑=1 yields an algorithm with competitive ratio 𝜌𝑑=2𝑑−1𝜌1 for every 𝑑≥2 for this problem. The current best competitive ratio for UNIT CLUSTERING in ℝ𝑑, 2𝑑−153 for every 𝑑≥2, is obtained in exactly this way (by lifting the algorithm of Ehmsen and Larsen [18]).

A simple deterministic algorithm (Algorithm Grid below) that assigns points to a predefined set of unit cubes that partition ℝ𝑑 can be easily proven to be 2𝑑-competitive for both UNIT COVERING and UNIT CLUSTERING. Since each cluster of 𝖮𝖯𝖳 can be split into at most 2𝑑 grid-cell clusters created by the algorithm, the competitive ratio of Algorithm Grid is at most 2𝑑, and this analysis is tight. See Fig. 1 for an example in the plane.

Algorithm Grid Build a uniform grid in ℝ𝑑 where cells are unit cubes of the form ∏𝑑𝑗=1[𝑖𝑗,𝑖𝑗+1), where 𝑖𝑗∈ℤ for 𝑗=1,…,𝑑. For each new point p, if the grid cell containing p is nonempty, put p in the corresponding cluster; otherwise open a new cluster for the grid cell and put p in it.

Fig. 1
figure 1
Example for Algorithm Grid in the plane; here 𝖠𝖫𝖦=11 and 𝖮𝖯𝖳=6

Full size image
We summarize the current best online algorithms for UNIT CLUSTERING in low dimensions; see Table 1. For 𝑑=1, the current best ratio, 5/3, is due to Ehmsen and Larsen [18] and is produced by a deterministic algorithm; on the other hand, the current best lower bound for deterministic algorithms, 13/8, is due to Kawahara and Kobayashi [26]. The current best lower bound for randomized algorithms, 3/2, is due to Epstein and van Stee [20].

For 𝑑=2, the current best ratio, 10/3, follows from lifting the algorithm of Ehmsen and Larsen [18] from 𝑑=1 to 𝑑=2 by using the technique of Chan and Zarrabi-Zadeh [10] mentioned earlier. The current best lower bound for deterministic algorithms, 13/6, is due to Ehmsen and Larsen [18]. The current best lower bound for randomized algorithms, 11/6, is due to Epstein and van Stee [20].

Table 1 Current best bounds on the competitive ratio of deterministic algorithms for online UNIT COVERING and UNIT CLUSTERING in ℝ𝑑 under 𝐿∞ norm for 𝑑=1, 𝑑=2, and 𝑑≥3
Full size table
Notation and Terminology Throughout this paper the 𝐿∞ norm is used in ℝ𝑑 (𝑑≥1). A hyperrectangle in ℝ𝑑 is the Cartesian product of d closed intervals 𝑅=∏𝑑𝑖=1[𝑎𝑖,𝑏𝑖], where the lengths 𝑏𝑖−𝑎𝑖 of the intervals, for 𝑖=1,…,𝑑, are the extents of R. A hyperrectangle is a hypercube (or cube, for short) if all d extents have the same length, and a unit cube if all d extents have unit length. For a vector 𝐱∈ℝ𝑑 and a set 𝑆⊂ℝ𝑑, we denote by 𝐱+𝑆={𝐱+𝐬:𝐬∈𝑆} the translate of S by vector 𝐱. In particular, every unit cube in ℝ𝑑 can be written in the form 𝐱+[0,1]𝑑 for some 𝐱∈ℝ𝑑. For a random variable X, 𝔼[𝑋] denotes its expected value.

Contributions We obtain the following results:

(i)
The competitive ratio of every online algorithm (deterministic or randomized) for UNIT CLUSTERING in ℝ𝑑 under the 𝐿∞ norm is Ω(𝑑) (Theorem 1 in Sect. 2). We thereby give a positive answer to a question of Epstein and van Stee; specifically, they asked whether the competitive ratio grows with the dimension [20, Sec. 4]. The question was reposed in [18, Sec. 7].

(ii)
The competitive ratio of every deterministic online algorithm for UNIT COVERING in ℝ𝑑 under the 𝐿∞ norm is at least 2𝑑 for every 𝑑≥1. This bound cannot be improved; as such, Algorithm Grid is optimal in this setting (Theorem 2 in Sect. 3). This generalizes a result by Chan and Zarrabi-Zadeh [10] from 𝑑=1 to higher dimensions.

(iii)
The competitive ratio of every deterministic online algorithm for UNIT COVERING in ℤ𝑑 under the 𝐿∞ norm is at least 𝑑+1 for every 𝑑≥1 (Theorem 3 in Sect. 4).

(iv)
We give a randomized algorithm with competitive ratio 𝑂(𝑑2) for UNIT COVERING in ℤ𝑑, 𝑑∈ℕ, under the 𝐿∞ norm (Theorem 4 in Sect. 4). The algorithm applies to UNIT CLUSTERING in ℤ𝑑, 𝑑∈ℕ, with the same competitive ratio.

(v)
The competitive ratio of Algorithm Greedy for UNIT CLUSTERING in ℝ𝑑 under the 𝐿∞ norm is unbounded for every 𝑑≥2 (Theorem 5 in Sect. 5). The competitive ratio of Algorithm Greedy for UNIT CLUSTERING in ℤ𝑑 under the 𝐿∞ norm is at least 2𝑑−1 and at most 2𝑑−1+12 for every 𝑑≥2 (Theorem 6 in Sect. 5).

Broader Perspective Several other variants of UNIT CLUSTERING have been studied in [19]. A survey of algorithms for UNIT CLUSTERING in the context of online algorithms appears in [12]; see also [16] for a review overview. Clustering with variable sized clusters has been studied in [13, 14]. Grid-based online algorithms for clustering problems have been developed by the same authors [15].

UNIT COVERING is a variant of SET COVER. Alon et al. [1] gave a deterministic online algorithm of competitive ratio 𝑂(log𝑚log𝑛) for SET COVER, where n is the number of possible points (the size of the ground set) and m is the number of sets in the family. If every element appears in at most Δ sets, the competitive ratio of the algorithm can be improved to 𝑂(logΔlog𝑛). Buchbinder and Naor [9] improved these competitive ratio to 𝑂(log𝑚log(𝑛/𝖮𝖯𝖳)) and 𝑂(logΔlog(𝑛/𝖮𝖯𝖳)), respectively, under the same assumptions. For several combinatorial optimization problems (e.g., covering and packing), the classic technique that rounds a fractional linear programming solution to an integer solution has been adapted to the online setting [2,3,4, 9, 24].

In these results, the underlying set system for the covering and packing problem must be finite: The online algorithms and their analyses rely on the size of the ground set. For UNIT CLUSTERING and UNIT CLUSTERING over infinite sets, such as ℝ𝑑 or ℤ𝑑, these techniques could only be used after a suitable discretization and a covering of the domain with finite sets, and it is unclear whether they can beat the trivial competitive ratio of 2𝑑 in a substantive way.

Lower Bound for Online UNIT CLUSTERING
In this section, we prove the following theorem.

Theorem 1
The competitive ratio of every (i) deterministic algorithm, and (ii) randomized algorithm, for UNIT CLUSTERING in ℝ𝑑, 𝑑∈ℕ, under the 𝐿∞ norm is Ω(𝑑).

Proof
Let 𝑑≥3 and let 𝜚 be the competitive ratio of an online algorithm. We may assume that 𝜚≤𝑑, otherwise there is nothing to prove. Let K be a sufficiently large even integer (that depends on d).

Deterministic Algorithm We first prove a lower bound for a deterministic algorithm, assuming without loss of generality an adaptive deterministic adversary. We present a total of ⌊𝑑/2⌋𝐾𝑑 points to the algorithm, and show that it creates Ω(𝑑⋅𝖮𝖯𝖳) clusters, where 𝖮𝖯𝖳 is the offline minimum number of clusters for the final set of points. Specifically, we present the points to the algorithm in ⌊𝑑/2⌋ rounds. Round 𝑖=1,…,⌊𝑑/2⌋ consists of the following three events:

(i)
The adversary presents (inserts) a set 𝑆𝑖 of 𝐾𝑑 points; 𝑆𝑖 is determined by a vector 𝜎(𝑖)∈{−1,0,1}𝑑 to be defined later. We denote by 𝑆≤𝑖=⋃𝑖𝑗=1𝑆𝑖 the set of points presented so far.

(ii)
The algorithm creates new clusters or expands existing clusters to cover 𝑆𝑖.

(iii)
If 𝑖<⌊𝑑/2⌋, the adversary computes 𝜎(𝑖+1) from the clusters that cover 𝑆𝑖.

In the first round, the adversary presents points of the integer lattice; namely 𝑆1=[𝐾]𝑑, where [𝐾]={𝑥∈ℤ:1≤𝑥≤𝐾}. In round 𝑖=2,…,⌊𝑑/2⌋, the point set 𝑆𝑖 will depend on the clusters created by the algorithm in previous rounds. We say that a cluster expires in round i if it contains some points from 𝑆𝑖 but no additional points can (or will) be added to it in any subsequent round. We show that over ⌊𝑑/2⌋ rounds, Ω(𝑑⋅𝖮𝖯𝖳) clusters expire, which readily implies 𝜚=Ω(𝑑).

Fig. 2
figure 2
a A 6×6 section of the integer grid and 𝖮𝖯𝖳1=9 clusters. b–d Near-optimal solutions 𝐶(𝑆1,𝜏) for 𝜏=(0,1), (1, 0), and (1, 1). e, f The perturbation with signature 𝜎=(−1,0), and clusters 𝐶(𝑆,𝜏) for 𝜏=(0,0) and 𝜏=(0,1), where S is the union of the perturbed points (full dots), and grid points (empty circles). g, h The perturbation with signature 𝜎=(1,0) and clusters 𝐶(𝑆,𝜏) for 𝜏=(1,0) and 𝜏=(1,1) and the same S

Full size image
Optimal Solutions For 𝑖=1,…,⌊𝑑/2⌋, denote by 𝖮𝖯𝖳𝑖 the offline optimum for the set 𝑆≤𝑖 of points presented up to round i. Since 𝑆1=[𝐾]𝑑 and K is even, 𝖮𝖯𝖳1=𝐾𝑑/2𝑑. The optimum solution for 𝑆1 is unique, and each cluster in the optimum solution is a Cartesian product ∏𝑑𝑖=1{𝑎𝑖,𝑎𝑖+1}, where 𝑎𝑖∈[𝐾] is odd for 𝑖=1,…,𝑑 (Fig. 2a).

Near-Optimal Solutions Consider 2𝑑−1 additional near-optimal solutions for 𝑆1 obtained by translating the optimal clusters by a d-dimensional 0−1 vector, and adding new clusters along the boundary of the cube [𝐾]𝑑. We shall argue that the points inserted in round i, 𝑖≥2, can be added to some but not all of these clusters. To make this precise, we formally define these solutions for the integer grid 𝑆1. First we define an infinite set of hypercubes

={∏𝑖=1𝑑[𝑎𝑖,𝑎𝑖+1]:𝑎𝑖∈ℤ is  odd  for 𝑖=1,…,𝑑}.
For any point set 𝑆⊂ℝ𝑑 and a vector 𝜏∈{0,1}𝑑, let the clusters 𝐶(𝑆,𝜏) be the subsets of S that lie in translates 𝑄+𝜏 of hypercubes 𝑄∈, that is, let

𝐶(𝑆,𝜏)={𝑆∩(𝑄+𝜏):𝑄∈}.
In general, the clusters 𝐶(𝑆,𝜏) do not contain all points in S. However, since 𝑆1 is an integer grid, the clusters 𝐶(𝑆1,𝜏) contain all points in 𝑆1 for every 𝜏∈{0,1}𝑑. See Fig. 2a–d for examples. Note that if 𝑆∩(𝑄+𝜏)≠∅ for some 𝑄∈, then every point in 𝑄+𝜏 is within unit distance from S, and in particular, ℤ𝑑∩(𝑄+𝜏) comprises 2𝑑 points with coordinates in {0,1,…,𝐾+1}. Consequently, the number of clusters in 𝐶(𝑆1,𝜏) is at most

(𝐾+2)𝑑2𝑑=𝐾𝑑+𝑂(𝑑𝐾𝑑−1)2𝑑=𝖮𝖯𝖳1⋅(1+𝑂(𝑑𝐾))=(1+𝑜(1))𝖮𝖯𝖳1,
if K is sufficiently large with respect to d.

In round 𝑖=2,…,⌊𝑑/2⌋, the point set 𝑆𝑖 is a perturbation of the integer grid 𝑆1 (as described below). Further, we will ensure (cf., Observation 1 below) that for every 𝑖=1,…,⌊𝑑/2⌋, the point set 𝑆≤𝑖 is covered by the clusters 𝐶(𝑆1,𝜏) for some 𝜏∈{0,1}𝑑. In particular, the final point set 𝑆≤⌊𝑑/2⌋ is covered by the clusters 𝐶(𝑆1,𝜏) for some 𝜏∈{0,1}𝑑. Consequently,

𝖮𝖯𝖳𝑖=𝖮𝖯𝖳1(1+𝑜(1))=(1+𝑜(1))𝐾𝑑2𝑑, for all 𝑖=1,…,⌊𝑑/2⌋.
(1)
At the end, we have 𝖮𝖯𝖳=𝖮𝖯𝖳⌊𝑑/2⌋=(1+𝑜(1))𝐾𝑑2𝑑.

Perturbation A perturbation of the integer grid 𝑆1 is encoded by a vector 𝜎∈{−1,0,1}𝑑, that we call the signature of the perturbation. Let 𝜀∈(0,12). For an integer point 𝑝=(𝑝1,…,𝑝𝑑)∈𝑆1 and a signature 𝜎, the perturbed point 𝑝′=(𝑝′1,…,𝑝′𝑑) is defined as follows; see Fig. 2e, h for examples in the plane: For 𝑗=1,…,𝑑, let

𝑝′𝑗=𝑝𝑗 when 𝜎𝑗=0;

𝑝′𝑗=𝑝𝑗+𝜀 if 𝑝𝑗 is odd, and 𝑝′𝑗=𝑝𝑗−𝜀 if 𝑝𝑗 is even when 𝜎𝑗=−1;

𝑝′𝑗=𝑝𝑗+𝜀 if 𝑝𝑗 is even, and 𝑝′𝑗=𝑝𝑗−𝜀 if 𝑝𝑗 is odd when 𝜎𝑗=1.

For 𝑖=2,…,⌊𝑑/2⌋, the point set 𝑆𝑖 is a perturbation of 𝑆1 with signature 𝜎(𝑖)∈{−1,0,1}𝑑. The signature of 𝑆1 is 𝜎(1)=(0,…,0) (and so 𝑆1 can be viewed as a null perturbation of itself). At the end of round 𝑖=1,…,⌊𝑑/2⌋−1, we compute 𝜎(𝑖+1) from 𝜎(𝑖) and the clusters that cover 𝑆𝑖 (as described below). The signature 𝜎(𝑖) determines the set 𝑆𝑖, for every 𝑖=2,…,⌊𝑑/2⌋. Note the following relation between the signatures 𝜎(𝑖) and the clusters 𝐶(𝑆𝑖,𝜏). ◻

Observation 1
Consider a point set 𝑆𝑖 with signature 𝜎(𝑖)∈{−1,0,1}𝑑. The clusters 𝐶(𝑆𝑖,𝜏) cover 𝑆𝑖 if and only if for all 𝑗=1,…𝑑,

𝜎𝑗(𝑖)=0, or

𝜎𝑗(𝑖)=−1 and 𝜏𝑗=0 (e.g., Fig. 2e, f for 𝑗=1), or

𝜎𝑗(𝑖)=1 and 𝜏𝑗=1 (e.g., Fig. 2g, h for 𝑗=1).

In the sequence of signatures 𝜎(1),…,𝜎(⌊𝑑/2⌋), we always change one zero coordinate to a nonzero coordinate. In particular any nonzero coordinate 𝜎𝑗(𝑖)∈{−1,1} remains unchanged, that is, 𝜎𝑗(𝑖)=𝜎𝑗(𝑖+1)=⋯=𝜎(⌊𝑑/2⌋). Consequently, for all 𝑖=1,…,⌊𝑑/2⌋, if the clusters 𝐶(𝑆1,𝜏) cover 𝑆𝑖 for some 𝜏∈{0,1}𝑑, they also cover 𝑆≤𝑖. In particular, the clusters 𝐶(𝑆1,𝜏) that cover 𝑆⌊𝑑/2⌋ also cover the final point set 𝑆≤⌊𝑑/2⌋.

Adversary Strategy At the end of round 𝑖=1,…,⌊𝑑/2⌋−1, we compute 𝜎(𝑖+1) from 𝜎(𝑖) by changing a 0-coordinate to −1 or +1, based on the clusters created by the 𝜚-competitive online algorithm. Note that every point in 𝑆𝑖, 𝑖=1,2,…,⌊𝑑/2⌋, has 𝑖−1 perturbed coordinates and 𝑑+1−𝑖 unperturbed coordinates. For all points in 𝑆𝑖, all unperturbed coordinates are integers. The algorithm covers 𝑆𝑖 with at most 𝜚⋅𝖮𝖯𝖳𝑖 clusters. Let 𝜋𝑖:ℝ𝑑→ℝ𝑑+1−𝑖 be the orthogonal projection to the subspace spanned by the 𝑑+1−𝑖 unperturbed coordinate axes. Then every point in 𝑆1 and its corresponding perturbations in 𝑆2,…,𝑆𝑖 project to the same point with integer coordinates in ℝ𝑑+1−𝑖. This implies that 𝜋𝑖(𝑆𝑖)=𝜋𝑖(𝑆1)⊂ℤ𝑑+1−𝑖, and the projection 𝜋𝑖(𝐶) of a cluster C contains at most 2𝑑+1−𝑖 points in 𝜋𝑖(𝑆𝑖), that is, |𝜋𝑖(𝐶∩𝑆𝑖)|≤2𝑑+1−𝑖. A cluster C created by the algorithm is called

small if |𝜋𝑖(𝐶∩𝑆𝑖)|≤2𝑑+1−𝑖2𝜚=2𝑑−𝑖𝜚, and

big otherwise.

Note that we distinguish between small and big clusters in round i with respect to the 𝑑+1−𝑖 unperturbed coordinates; in particular, a small cluster in round i may become large in another round, or vice versa. As we shall see, small clusters contain few points and can be ignored for now. Big clusters, however, are constrained by the points they contain, and they cannot expand in some of the coordinate directions. The adversary will present points in the next round that cannot be added to most of the big clusters, rendering these clusters useless in subsequent rounds.

The 𝐿∞-diameter of a cluster and any of its projections to a subspace spanned by coordinate axes is most 1. Consequently, a small cluster contains at most (2𝑑−𝑖/𝜚)⋅2𝑖−1=2𝑑/(2𝜚) points of 𝑆𝑖. Indeed, for each small cluster C, the projection 𝜋𝑖(𝐶) contains at most 2𝑑−𝑖/𝜚 points in 𝜋𝑖(𝑆𝑖). Each point in 𝜋𝑖(𝑆𝑖) is the image of 𝐾𝑖−1 points of 𝑆𝑖; since 𝑆𝑖 is a perturbation of the integer grid, any cluster contains at most 2𝑖−1 of these preimages. The total number of points in 𝑆𝑖 that lie in small clusters is at most (see (1))

(𝜚⋅𝖮𝖯𝖳𝑖) 2𝑑2𝜚=𝖮𝖯𝖳𝑖⋅2𝑑−1=(12+𝑜(1))𝐾𝑑.
Consequently, the remaining (12−𝑜(1))𝐾𝑑 points in 𝑆𝑖 are covered by big clusters. As any unit cluster contains at most 2𝑑 points in 𝑆𝑖, the number of big clusters is at least

(12−𝑜(1))𝐾𝑑2𝑑.
(2)
For a cluster C, let s(C) denote the number of unperturbed coordinates in which its extent is 1. Then the projection 𝜋𝑖(𝐶) contains at most 2𝑠(𝐶) integer points in ℤ𝑑+1−𝑖, hence |𝜋𝑖(𝐶∩𝑆𝑖)|≤2𝑠(𝐶). Comparing the lower and upper bounds on the cardinality of 𝜋𝑖(𝐶∩𝑆𝑖), for a big cluster C, yields

2𝑑−𝑖/𝜚<𝑑−𝑖−log2𝜚<2𝑠(𝐶)𝑠(𝐶).
Consider the following experiment: choose one of the zero coordinates of the signature 𝜎(𝑖) uniformly at random (i.e., all 𝑑+1−𝑖 choices are equally likely), and change it to −1 or +1 with equal probability 1/2. Observe that if the j-th extent of a cluster C is 1, then it cannot be expanded in dimension j. We say that a big cluster C expires if no point can (or will) be added to C in the future. Recall that 𝑖≤⌊𝑑/2⌋ and we assume that 𝜚≤𝑑. Consequently, a big cluster C expires with probability at least

𝑠(𝐶)𝑑+1−𝑖⋅12>𝑑−𝑖−log2𝜚2(𝑑+1−𝑖)≥𝑑−⌊𝑑/2⌋−log2𝑑2𝑑=Ω(1).
(3)
Combining (2) and (3), the expected number of clusters that expire is

Ω(1)⋅(12−𝑜(1))𝐾𝑑2𝑑=Ω(𝖮𝖯𝖳).
It follows that there exists an unperturbed coordinate j, and a perturbation of it such that Ω(𝖮𝖯𝖳) big clusters expire at the end of round 𝑖=1,…,⌊𝑑/2⌋−1. The adversary derandomizes the above experiment: it precomputes all possible perturbations (changing a 0-coordinate of 𝜎(𝑖) to −1 or +1), and makes the choice that maximizes the number of big clusters that expire in that round.

In round 𝑖=⌊𝑑/2⌋, all clusters that cover any point in 𝑆⌊𝑑/2⌋ expire, because no point will be added to any of these clusters. Since 𝑆⌊𝑑/2⌋ is a perturbation of 𝑆1, at least 𝖮𝖯𝖳1=Ω(𝖮𝖯𝖳) clusters expire in the last round, as well.

If a cluster expires in round i, then it contains some points of 𝑆𝑖 but does not contain any point of 𝑆𝑗 for 𝑗>𝑖. Consequently, each cluster expires in at most one round, and the total number of expired clusters over all ⌊𝑑/2⌋ rounds is Ω(𝑑⋅𝖮𝖯𝖳). Since each of these clusters was created by the algorithm in one of the rounds, we have 𝜚⋅𝖮𝖯𝖳=Ω(𝑑⋅𝖮𝖯𝖳), which implies 𝜚=Ω(𝑑), as claimed.

Randomized Algorithm We modify the above argument to establish a lower bound of Ω(𝑑) for a randomized algorithm with an oblivious (randomized) adversary. The adversary starts with the integer grid 𝑆1=[𝐾]𝑑, with signature 𝜎(1)=0 as before. At the end of round 𝑖=1,…,⌊𝑑/2⌋−1, it chooses an unperturbed coordinate of 𝜎(𝑖) uniformly at random, and switches it to −1 or +1 with equal probability (independently of the clusters created by the algorithm) to obtain 𝜎(𝑖+1). By (3), the expected number of big clusters that expire in round i, 1≤𝑖<⌊𝑑/2⌋, is Ω(𝖮𝖯𝖳𝑖)=Ω(𝖮𝖯𝖳); and all (1−𝑜(1))𝖮𝖯𝖳⌊𝑑/2⌋=Ω(𝖮𝖯𝖳) big clusters expire in round ⌊𝑑/2⌋. Consequently, the expected number of clusters created by the algorithm is Ω(𝑑⋅𝖮𝖯𝖳), which implies 𝜚=Ω(𝑑), as required. ◻

Lower Bound for Online UNIT COVERING in ℝ𝑑
The following theorem extends a result from [10] from 𝑑=1 to higher dimensions.

Theorem 2
The competitive ratio of every deterministic online algorithm for UNIT COVERING in ℝ𝑑 under the 𝐿∞ norm is at least 2𝑑 for every 𝑑≥1.

Recall that Algorithm Grid attains a competitive ratio of 2𝑑. As such, Algorithm Grid is optimal in this setting, and the lower bound in Theorem 2 cannot be improved.

Proof
Consider a deterministic online algorithm 𝖠𝖫𝖦 for UNIT COVERING in ℝ𝑑. We present an input instance 𝜎 for which the solution 𝖠𝖫𝖦(𝜎) is at least 2𝑑 times 𝖮𝖯𝖳(𝜎). In particular, 𝜎 consists of 2𝑑 points in ℝ𝑑 that fit in a unit cube, hence 𝖮𝖯𝖳(𝜎)=1, and we show that 𝖠𝖫𝖦 is required to place a new unit cube for each point in 𝜎. Our proof works like a two player game between Alice and Bob. Here, Alice is presenting points to Bob, one at a time. If a new cube is required, Bob (who plays the role of the algorithm) decides where to place it. Alice tries to force Bob to place as many new cubes as possible by presenting the points in a smart way. Bob tries to place new cubes in a way such that they may cover other points presented by Alice in the future, thereby reducing the need of placing new cubes quite often.

Throughout the game, Alice maintains a sequence of axis-aligned cubes 𝑄1⊂𝑄2,⊂…, each of side-length less than 1, and Bob places axis-aligned cubes 𝑈1,𝑈2,… to cover points presented by Alice.

Let 𝑄0=𝑈0=∅. In step i, 𝑖=1,…,2𝑑, Alice obtains 𝑄𝑖 from 𝑄𝑖−1, where 𝑄𝑖−1⊂𝑄𝑖. More precisely, 𝑄𝑖 is obtained by scaling up (slightly) 𝑄𝑖−1 from a vertex. This transformation defines a one-to-one correspondence between the vertices of 𝑄𝑖 and 𝑄𝑖+1 (as in Lemma 2 that follows). Alice then presents an arbitrary vertex of 𝑄𝑖 that is not covered as the next point 𝑝𝑖∈𝜎, and Bob covers it by placing the unit cube 𝑈𝑖.

For every 𝑖∈ℕ, let 𝛿𝑖=2−2𝑖 and 𝑥𝑖=1−2𝛿𝑖 (in particular, 𝑥1=1/2, 𝑥2=7/8, and 𝑥3=31/32). For 𝑖=1,…,2𝑑, the side length of cube 𝑄𝑖 is equal to 𝑥𝑖. Note that (𝑥𝑖)𝑖∈ℕ is a strictly increasing sequence converging to 1.

In step 1, Alice chooses 𝑄1 as an arbitrary cube of side-length 𝑥1, and the first point 𝑝1 as an arbitrary vertex of 𝑄1. Next, Bob places 𝑈1 to cover 𝑝1. The remaining points 𝑝𝑖, for 𝑖=2,…,2𝑑, in 𝜎 are chosen adaptively, depending on Bob’s moves.

By the end of step i, for 𝑖=1,…,2𝑑, Alice has placed points 𝑝1,…,𝑝𝑖, and Bob has placed unit cubes 𝑈1,…,𝑈𝑖 (one for each of these points). An illustration of the planar version of the game appears in Fig. 3. ◻

Fig. 3
figure 3
A lower bound of 2𝑑 on the competitive ratio. The figure illustrates the case 𝑑=2. Left: The first two points in 𝜎 arrive. Right: the last two points in 𝜎 arrive. The cubes placed by Bob (𝑈1,𝑈2,𝑈3) and the vertices that are deeply covered (𝑞1 and 𝑞3) are dashed

Full size image
A vertex 𝑣𝑖 of 𝑄𝑖 is said to be covered at time t if 𝑣𝑖 is contained in the union of the cubes placed before time t. Otherwise, 𝑣𝑖 is exposed (i.e., not covered) at time t. Note that in step 1, all 2𝑑 vertices of 𝑄1 are exposed until Bob places 𝑈1.

We maintain the following two invariants for 𝑖=1,…,2𝑑:

(I)
the cube 𝑄𝑖 contains the points 𝑝1,…,𝑝𝑖;

(II)
the cube 𝑄𝑖 has at least 2𝑑−𝑖+1 exposed vertices until 𝑈𝑖 is placed in step i (i.e., the union ⋃𝑗<𝑖𝑈𝑗 contains at most 𝑖−1 vertices of 𝑄𝑖).

Invariant (II) ensures that Alice can present an exposed vertex of 𝑄𝑖 in steps 𝑖=1,…,2𝑑. An exposed vertex 𝑣𝑖 of 𝑄𝑖 is said to be deeply covered by 𝑈𝑖 in step i if 𝑣𝑖 is contained in 𝑈𝑖 and its distance from the boundary of 𝑈𝑖 is larger than 𝛿𝑖=(1−𝑥𝑖)/2; i.e., 𝑣𝑖∈𝑈𝑖 and dist(𝑣𝑖,∂𝑈𝑖)>𝛿𝑖. As we shall see, a deeply covered vertex helps producing exposed vertices in the next round.

Lemma 1
For 𝑖∈{1,…,2𝑑−1}, at most one exposed vertex of 𝑄𝑖 is deeply covered by 𝑈𝑖 in step i.

Proof
Assume, to the contrary, that 𝑢𝑖 and 𝑣𝑖 are two exposed vertices of 𝑄𝑖 (in step i), that are deeply covered by 𝑈𝑖. Since 𝑢𝑖 and 𝑣𝑖 differ in at least one coordinate, the extent of 𝑈𝑖 in that coordinate is larger than

𝑥𝑖+2(1−𝑥𝑖)2=1,
which is a contradiction.

If no exposed vertex of 𝑄𝑖 is deeply covered by 𝑈𝑖, let 𝑄𝑖+1 be the unique axis-aligned cube of side length 𝑥𝑖+1 that contains 𝑄𝑖 and has 𝑝𝑖 as a vertex (i.e., 𝑄𝑖+1 is obtained by scaling up 𝑄𝑖 from 𝑝𝑖). Otherwise, let 𝑞𝑖 be the unique exposed vertex of 𝑄𝑖 that is deeply covered by 𝑈𝑖 (possibly, 𝑞𝑖=𝑝𝑖); and let 𝑄𝑖+1 be the unique axis-aligned cube of side length 𝑥𝑖+1 that contains 𝑄𝑖 and has 𝑞𝑖 as a vertex (i.e., 𝑄𝑖+1 is obtained by scaling up 𝑄𝑖 from 𝑞𝑖).

Lemma 2
For 𝑖∈{1,…,2𝑑−1}, let 𝑣𝑖 be an exposed vertex of 𝑄𝑖 in step i that is not deeply covered by 𝑈𝑖, and not the common vertex of 𝑄𝑖 and 𝑄𝑖+1. Let 𝑣𝑖+1 be the vertex of 𝑄𝑖+1 corresponding to 𝑣𝑖. Then 𝑣𝑖+1 is not covered by ⋃𝑖𝑗=1𝑈𝑗.

Proof
We claim that 𝑣𝑖+1 is not covered by 𝑈𝑖. First assume that 𝑣𝑖∉𝑈𝑖. We obtain 𝑣𝑖+1 from 𝑣𝑖 by scaling up 𝑄𝑖 from a vertex (𝑝𝑖 or 𝑞𝑖) in 𝑈𝑖. Since 𝑈𝑖 is convex, both 𝑣𝑖 and 𝑣𝑖+1 are in the exterior of 𝑈𝑖, and so 𝑣𝑖+1 is not covered by 𝑈𝑖. Next assume that 𝑣𝑖∈𝑈𝑖. Since 𝑣𝑖 is not deeply covered by 𝑈𝑖, its distance to the boundary of 𝑈𝑖 is at most 𝛿𝑖. By construction, there exist parallel faces of 𝑄𝑖 and 𝑄𝑖+1 that are incident to 𝑣𝑖 and 𝑣𝑖+1, respectively, but are not incident to the common vertex of 𝑄𝑖 and 𝑄𝑖+1. Two such faces are at distance

𝑥𝑖+1−𝑥𝑖=2(𝛿𝑖−𝛿𝑖+1)=3⋅2−(2𝑖+1)=3𝛿𝑖2>𝛿𝑖
from each other. This implies that 𝑣𝑖+1 is not covered by 𝑈𝑖.

Since 𝑣𝑖 was not covered by the union of previous cubes ⋃𝑗<𝑖𝑈𝑗 and all previous cubes intersect 𝑄𝑖, it follows that the ray 𝑣𝑖𝑣𝑖+1−→−−− does not intersect any previous cube 𝑈𝑗, 𝑗<𝑖. In particular, 𝑣𝑖+1 is not covered by ⋃𝑗<𝑖𝑈𝑗. As such, 𝑣𝑖+1∉𝑈𝑖, hence 𝑣𝑖+1∉⋃𝑖𝑗=1𝑈𝑗, as claimed. ◻

Invariant (I) follows inductively, by construction. Invariant (II) follows inductively from Lemmata 1 and 2. By Invariant (II), Alice can choose an exposed vertex of 𝑄𝑖 in steps 𝑖=1,…,2𝑑, and Bob is required to place a new cube after each of these 2𝑑 points, hence 𝖠𝖫𝖦(𝜎)=2𝑑. Invariant (I) yields 𝖮𝖯𝖳(𝜎)=1. This completes the proof of Theorem 2. ◻

Online UNIT COVERING in ℤ𝑑
Lower Bound When we consider unit covering over the integer lattice ℤ𝑑, 𝑑≥1, the adversary has fewer choices, and the 2𝑑 lower bound of Theorem 2 no longer applies. Here we prove a lower bound that is linear in d.

Theorem 3
The competitive ratio of every deterministic online algorithm for UNIT COVERING in ℤ𝑑 under the 𝐿∞ norm is at least 𝑑+1 for every 𝑑≥1.

Proof
We construct an input sequence 𝑝1,…,𝑝𝑑+1∈ℤ𝑑 for which 𝖮𝖯𝖳=1 and 𝖠𝖫𝖦=𝑑+1 using an adaptive adversary. We construct such a sequence inductively, so that

each new point 𝑝𝑖 requires a new cube, 𝑄𝑖⊂ℝ𝑑, and

all points presented can be covered by one integer unit cube incident to the origin.

Let 𝑥1,…,𝑥𝑑 be the d coordinate axes in ℝ𝑑; and 𝑥𝑑+1 be the new axis in ℝ𝑑+1. The induction basis is 𝑑=1. We may assume for concreteness that 𝑝1=0, and suppose that the algorithm opens a unit interval [𝑥,𝑥+1] to cover this point. If 𝑥=−1, let 𝑝2=1, else let 𝑝2=−1. The algorithm now opens a new unit interval to cover 𝑝2. It is easily seen that 𝑝1,𝑝2∈ℤ and {𝑝1,𝑝2} define a unit interval.

For the induction step, assume the existence of a sequence 𝜎=𝑝1,…,𝑝𝑑+1∈ℤ𝑑 that forces the algorithm to open a new unit cube, 𝑄𝑖⊂ℝ𝑑, to cover each new point 𝑝𝑖, 𝑖=1,…,𝑑+1 (and so 𝖠𝖫𝖦=𝑑+1), while 𝖮𝖯𝖳=1 with 𝜎 being covered by a single cube 𝑈𝑑⊂ℤ𝑑. Present a sequence of 𝑑+2 points to the algorithm in ℝ𝑑+1; the first 𝑑+1 points of this sequence are: (𝑝1,0),…,(𝑝𝑑+1,0). The algorithm must use 𝑑+1 cubes, say, 𝑄1,…,𝑄𝑑+1⊂ℝ𝑑+1 to cover these points. As such, the 𝑑+1 unit cubes 𝜋(𝑄1),…,𝜋(𝑄𝑑+1)⊂ℝ𝑑, cover 𝑝1,…,𝑝𝑑+1∈ℤ𝑑, where 𝜋(𝑄𝑖) is the projection onto the first d coordinates of 𝑄𝑖; moreover, the unit cubes 𝜋(𝑄1),…,𝜋(𝑄𝑑) do not cover 𝑝𝑑+1. Only 𝜋(𝑄𝑑) contains 𝑝𝑑+1, but the cube 𝑄𝑑 cannot contain both (𝑝𝑑+1,−1) and (𝑝𝑑+1,1). Consequently, (𝑝𝑑+1,−1) or (𝑝𝑑+1,1) is not covered by ⋃𝑑+1𝑖=1𝑄𝑖. The adversary presents such an exposed point, which requires a new cube 𝑄𝑑+2. (Note that the points 𝑝1,…,𝑝𝑑+2 form a lattice path, where 𝑝𝑖 and 𝑝𝑖+1 differ in the (𝑖+1)-th coordinate.) This completes the inductive step, and thereby the proof of the theorem. ◻

Upper Bound We substantially improve on the 2𝑑 upper bound on the competitive ratio of UNIT COVERING in ℝ𝑑 (achieved by Algorithm Grid) when the input points are in ℤ𝑑 (or the 2𝑑−1+12 upper bound of Algorithm Greedy in Sect. 5).

The online algorithm by Buchbinder and Naor [9] for SET COVER, for the unit covering problem over ℤ𝑑, yields an algorithm with 𝑂(𝑑log(𝑛/𝖮𝖯𝖳)) competitive ratio under the assumption that a set of n possible integer points is given in advance. Recently, Gupta and Nagarajan [24] gave an online randomized algorithm for a broad family of combinatorial optimization problems that can be expressed as sparse integer programs. For unit covering over the integers in [𝑛]𝑑, their results yield a competitive ratio of 𝑂(𝑑2), where [𝑛]={1,2,…,𝑛}. The competitive ratio does not depend on n, but the algorithm must know n in advance. We remark that if the algorithm is allowed to maintain several candidate solutions and return a best candidate at termination (which is customary in data stream models [27]), then this approach combined with a standard randomized shifting method [25] would yield a competitive ratio of 𝑂(𝑑2). However, in the online model we consider here, the algorithm can maintain only one solution, and this approach is no longer viable.

We now remove the dependence on n so as to get a truly online algorithm for UNIT COVERING over ℤ𝑑. Consider the following randomized algorithm.

Algorithm Iterative Reweighing Let 𝑃⊂ℤ𝑑 be the set of points presented to the algorithm and  the set of cubes chosen by the algorithm; initially 𝑃==∅. The algorithm chooses cubes for two different reasons, and it keeps them in sets 1 and 2, where =1∪2. It also maintains a third set of cubes, , for bookkeeping purposes; initially =∅. In addition, the algorithm maintains a weight function on all integer unit cubes. Initially 𝑤(𝑄)=2−(𝑑+1) for all integer unit cubes (this is the default value for all cubes that are disjoint from P).

We describe one iteration of the algorithm. Let 𝑝∈ℤ𝑑 be a new point; put 𝑃←𝑃∪{𝑝}. Let (𝑝) be the set of 2𝑑 integer unit cubes that contain p.

1.
If 𝑝∈⋃, then do nothing.

2.
Else if 𝑝∈⋃, then let 𝑄∈∩(𝑝) be an arbitrary cube and put 1←1∪{𝑄}.

3.
Else if ∑𝑄∈(𝑝)𝑤(𝑄)≥1, then let Q be an arbitrary cube in (𝑝) and put 2←2∪{𝑄}.

4.
Else, the weights give a probability distribution on (𝑝). Successively choose cubes from (𝑝) at random with this distribution in 2d independent trials and add them to . Let 𝑄∈∩(𝑝) be an arbitrary cube and put 1←1∪{𝑄}. Double the weight of every cube in (𝑝).

Theorem 4
The competitive ratio of Algorithm Iterative Reweighing for UNIT COVERING in ℤ𝑑,𝑑∈ℕ, under the 𝐿∞ norm is 𝑂(𝑑2).

Proof
Suppose that a set P of n points is presented to the algorithm sequentially, and the algorithm created unit cubes in =1∪2. Note that 1⊆. We show that 𝔼[||]=𝑂(𝑑2⋅𝖮𝖯𝖳) and 𝔼[|2|]=𝑂(𝖮𝖯𝖳). This immediately implies that 𝔼[||]≤𝔼[|1|]+𝔼[|2|]≤𝔼[||]+𝔼[|2|]=𝑂(𝑑2⋅𝖮𝖯𝖳).

First consider 𝔼[||]. New cubes are added to  in step 4. In this case, the algorithm places at most 2d cubes into , and doubles the weight of all 2𝑑 cubes in (𝑝) that contain p. Let 𝖮𝖯𝖳 be an offline optimum set of unit cubes. Each point 𝑝∈𝑃 lies in some cube 𝑄𝑝∈𝖮𝖯𝖳. The weight of 𝑄𝑝 is initially 2−(𝑑+1), and it never exceeds 2; indeed, since 𝑄𝑝∈(𝑝), its weight before the last doubling must have been at most 1 in step 4 of the algorithm; thus its weight is doubled in at most 𝑑+2 iterations. Consequently, the algorithm invokes step 4 in at most (𝑑+2)𝖮𝖯𝖳 iterations. In each such iteration, it adds at most 2d cubes to . Overall, we have ||≤(𝑑+2)⋅2𝑑⋅𝖮𝖯𝖳=𝑂(𝑑2⋅𝖮𝖯𝖳), as required.

Next consider 𝔼[|2|]. A new cube is added to 2 in step 3. In this case, none of the cubes in (𝑝) is in  and ∑𝑄∈(𝑝)𝑤(𝑄)≥1 when point p is presented, and the algorithm increments |2| by one. At the beginning of the algorithm, we have ∑𝑄∈(𝑝)𝑤(𝑄)=∑𝑄∈(𝑝)2−(𝑑+1)=2𝑑⋅2−(𝑑+1)=1/2. Assume that the weights of the cubes in (𝑝) were increased in t iterations, starting from the beginning of the algorithm, and the sum of weights of the cubes in (𝑝) increases by 𝛿1,…,𝛿𝑡>0 (the weights of several cubes may have been doubled in an iteration). Since ∑𝑄∈(𝑝)𝑤(𝑄)=1/2+∑𝑡𝑖=1𝛿𝑖, then ∑𝑄∈(𝑝)𝑤(𝑄)≥1 implies ∑𝑡𝑖=1𝛿𝑖≥1/2. For every 𝑖=1,…,𝑡, the sum of weights of some cubes in (𝑝), say, 𝑖⊂(𝑝), increased by 𝛿𝑖 in step 4 of a previous iteration. Since the weights doubled, the sum of the weights of these cubes was 𝛿𝑖 at the beginning of that iteration, and the algorithm added one of them into  with probability at least 𝛿𝑖 in one random draw, which was repeated 2d times independently. Consequently, the probability that the algorithm did not add any cube from 𝑖 to  in that iteration is at most (1−𝛿𝑖)2𝑑. The probability that none of the cubes in (𝑝) has been added to  before point p arrives is (by independence) at most

∏𝑖=1𝑡(1−𝛿𝑖)2𝑑≤𝑒−2𝑑∑𝑡𝑖=1𝛿𝑖≤𝑒−𝑑.
The total number of points p for which step 3 applies is at most |P|. Since each unit cube contains at most 2𝑑 points, we have |𝑃|≤2𝑑⋅𝖮𝖯𝖳. Therefore 𝔼[|2|]≤|𝑃|𝑒−𝑑≤(2/𝑒)𝑑𝖮𝖯𝖳≤𝖮𝖯𝖳, as claimed. ◻

The above algorithm applies to UNIT CLUSTERING of integer points in ℤ𝑑 with the same competitive ratio:

Corollary 1
The competitive ratio of Algorithm Iterative Reweighing for UNIT CLUSTERING in ℤ𝑑,𝑑∈ℕ, under the 𝐿∞ norm is 𝑂(𝑑2).

Lower Bound for Algorithm Greedy for UNIT CLUSTERING
Chan and Zarrabi-Zadeh [10] showed that the greedy algorithm for UNIT CLUSTERING on the line (𝑑=1) has competitive ratio of 2 (this includes both an upper bound on the ratio and a tight example). Here we show that the competitive ratio of the greedy algorithm is unbounded for 𝑑≥2. We first recall the algorithm:

Algorithm Greedy For each new point p, if p fits in some existing cluster, put p in such a cluster (break ties arbitrarily); otherwise open a new cluster for p.

Theorem 5
The competitive ratio of Algorithm Greedy for UNIT CLUSTERING in ℝ𝑑 under the 𝐿∞ norm is unbounded for every 𝑑≥2.

Proof
It suffices to consider 𝑑=2; the construction extends to arbitrary dimensions 𝑑≥2. The adversary presents 2n points in pairs {(1+𝑖/𝑛,𝑖/𝑛),(𝑖/𝑛,1+𝑖/𝑛)} for 𝑖=0,1,…,𝑛−1. Each pair of points spans a unit square that does not contain any subsequent point. Consequently, the greedy algorithm will create n clusters, one for each point pair. However, 𝖮𝖯𝖳=2 since the clusters 𝐶1={(1+𝑖/𝑛,𝑖/𝑛):𝑖=0,1,…,𝑛−1} and 𝐶2={(𝑖/𝑛,1+𝑖/𝑛):𝑖=0,1,…,𝑛−1} are contained in the unit squares [1,2]×[0,1] and [0,1]×[1,2], respectively. ◻

When we restrict Algorithm Greedy to integer points, its competitive ratio is exponential in d.

Theorem 6
The competitive ratio of Algorithm Greedy for UNIT CLUSTERING in ℤ𝑑 under the 𝐿∞ norm is at least 2𝑑−1 and at most 2𝑑−1+12 for every 𝑑≥1.

Fig. 4
figure 4
A planar instance for the greedy algorithm with 𝐾=12

Full size image
Proof
We first prove the lower bound. Consider an integer input sequence implementing a barycentric subdivision of the space, as illustrated in Fig. 4. Let K be a sufficiently large positive multiple of 4 (that depends on d). We present a point set S, where |𝑆|=(2+𝑜(1))(𝐾/2)𝑑 points to the algorithm, and show that it creates (1+𝑜(1))2𝑑−1𝖮𝖯𝖳 clusters.

Let 𝑆=𝐵∪𝐷, where

𝐴𝐵𝐶𝐷𝐸={(𝑥1,…,𝑥𝑑) | 𝑥𝑖≡0(mod4), 0≤𝑥𝑖≤𝐾, 𝑖=1,…,𝑑},=𝐴+{0,1}𝑑,={(𝑥1,…,𝑥𝑑) | 𝑥𝑖≡2(mod4), 0≤𝑥𝑖≤𝐾, 𝑖=1,…,𝑑},=𝐶+{0,1}𝑑,={{𝑢,𝑣}:𝑢∈𝐵,𝑣∈𝐷,||𝑢−𝑣||∞≤1}.
Note that each element of C is the barycenter (center of mass) of 2𝑑 elements of A, namely the vertices of a cell of (4ℤ)𝑑 containing the element. Here E is a set of pairs of lattice points (edges) that can be put in one-to-one correspondence with the points in D. As such, we have

|𝐴||𝐶||𝐸|𝖮𝖯𝖳=(𝐾4+1)𝑑, |𝐵|=2𝑑|𝐴|=(1+𝑜(1))𝐾𝑑2𝑑,=(𝐾4)𝑑, |𝐷|=2𝑑|𝐶|=(1+𝑜(1))𝐾𝑑2𝑑,=|𝐷|=(1+𝑜(1))𝐾𝑑2𝑑,=|𝐴∪𝐶|=|𝐴|+|𝐶|=(2+𝑜(1))(𝐾4)𝑑.
It follows that |𝐸|=(1+𝑜(1))2𝑑−1𝖮𝖯𝖳. The input sequence presents the points in pairs, namely those in E. The greedy algorithm makes one new non-extendable cluster for each such “diagonal” pair (each cluster is a unit cube), so its competitive ratio is at least 2𝑑−1 for every 𝑑≥2.

An upper bound of 2𝑑 follows from the fact that each cluster in 𝖮𝖯𝖳 contains at most 2𝑑 integer points; we further reduce this bound. Let Γ1,…,Γ𝑘 be the clusters of an optimal partition (𝑘=𝖮𝖯𝖳). Assume that the algorithm produces m clusters of size at least 2 and s singleton clusters. Since each cluster of 𝖮𝖯𝖳 contains at most one singleton cluster created by the algorithm, we have

𝖠𝖫𝖦=𝑚+𝑠≤(𝑘−𝑠)2𝑑+𝑠(2𝑑−1)2+𝑠=𝑘2𝑑−𝑠2+𝑠=𝑘2𝑑−1+𝑠2≤𝑘2𝑑−1+𝑘2=𝑘(2𝑑−1+12),
as required. ◻

Conclusions
Our results in Theorems 1 and 2 show that the competitive ratio for both online UNIT CLUSTERING and UNIT COVERING grows with the dimension of the space. From a broader perspective, the main question is how the curse of dimensionality plays out for online algorithms in this area. In principle, the growth rates in the dimension may be different for UNIT CLUSTERING and UNIT COVERING.

On the one hand, the tight bound obtained for UNIT COVERING in ℝ𝑑 shows that the growth rate of the competitive ratio for this problem must be exponential. On the other hand, currently no online algorithm is known for UNIT CLUSTERING in ℝ𝑑 under the 𝐿∞ norm with a competitive ratio 𝑜(2𝑑). The current best upper bound for the competitive ratio under this norm is 2𝑑⋅56 for sufficiently large dimensions 𝑑≥2, which is only marginally better than the trivial 2𝑑 ratio. This evidence suggests that the growth rate of the competitive ratio for this problem may be exponential, as well. The additional degree of flexibility (or “ambiguity”) in UNIT CLUSTERING may be a reason for the difficulty in obtaining a better lower bound if this is how things will finally turn out.

Several directions remain for future study. We summarize a few specific questions of interest.

Question 1
Is there an upper bound of 𝑜(2𝑑) on the competitive ratio for UNIT CLUSTERING in ℝ𝑑 under the 𝐿∞ norm?

Question 2
Is there a lower bound on the competitive ratio for UNIT CLUSTERING that is exponential in d? Is there a superlinear lower bound?

For online UNIT COVERING in ℝ𝑑 under the 𝐿∞ norm, the competitive ratio of the deterministic Algorithm Grid is 2𝑑, which is the best possible. One remaining issue is in regard to randomized algorithms and oblivious adversaries.

Question 3
Is there an upper bound of 𝑜(2𝑑) on the competitive ratio of randomized algorithms for UNIT COVERING in ℝ𝑑 under the 𝐿∞ norm?

Question 4
Is there a superlinear lower bound on the competitive ratio of randomized algorithms (against oblivious adversaries) for UNIT COVERING in ℝ𝑑 under the 𝐿∞ norm?

The reader is also referred to [16] for a discussion of related problems.