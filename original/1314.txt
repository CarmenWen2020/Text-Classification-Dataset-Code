Computing shortest paths in networks that exhibit a time-dependent metric is a core routine for many applications, with route planning in road networks being a prime example. In this work, we present an axiomatic approach which shows that for directed networks that satisfy certain properties we can provide time-dependent distance oracles that provably exhibit subquadratic preprocessing time and space (independent of the metric’s amount of disconcavity), query time sublinear on the network size or the actual Dijkstra rank of the query at hand (measuring the distance ordering of the destination from the origin), and small stretch factor (approximation error).

Access provided by University of Auckland Library

Introduction
Contemporary technological infrastructures (e.g., road networks, social networks, e-commerce platforms, energy-management systems) are typically of very large scale and impose as a routine task the computation of min-cost paths in real-time, while their characteristics usually evolve with time. The large-scale and real-time response challenges have been addressed in the last 20 years by means of a new algorithmic trend: the provision of oracles. That is, data structures created by appropriately selecting precomputed information (summaries) and which subsequently support query algorithms with real-time responses. The quality of an oracle is assessed by its preprocessing space and time requirements, the time-complexity of the query algorithm and the approximation guarantee (stretch). Numerous oracles have been proposed and analyzed (see e.g., [1, 22, 23, 26,27,28, 31, 32] and references therein) for large-scale, mostly undirected networks, accompanied by a static arc-cost metric. In tandem with oracles, an equally important effort (with similar characteristics) has also emerged in the last 20 years under the tag of speedup techniques for approaches tailored to work extremely well in real-life instances (see e.g., [3] and references therein).

The temporality of the network characteristics is often depicted by some kind of predetermined dependence of the metric on the actual time that each resource is used (e.g., traversal time of individual segments in road networks, packet-loss rate in IT networks, arc availability in social networks, etc). Perhaps the most typical application scenario, motivating also our work, is route planning in road networks, where the time for traversing an arc 𝑎=𝑢𝑣 (modeling a road segment) depends on the temporal traffic conditions while traversing it, and thus on the departure time from its tail u. This gives rise to time-varying network models and to computing min-cost (a.k.a. shortest) paths in such networks. Several variants of this model try to capture time-variation of the underlying graph structure and/or the arc-cost metric, e.g., dynamic shortest paths, parametric shortest paths, stochastic shortest paths, temporal networks, etc; see [17] for a discussion on these variants and their comparison.

In this work, we consider the case in which the cost variation of each arc a is determined by a function D[a], which is considered to be a continuous, piecewise linear (pwl) and periodic functionFootnote1 of the time at which the resource is actually being used [7, 8, 13, 21]. When providing route plans in such so-called time-dependent road networks, arc-cost values are determined by evaluating arc-travel-time functions, while time-dependent shortest paths are construed as minimum-travel-time paths. The goal is then to determine the cost (minimum-travel-time) of an optimal path from an origin o to a destination d, as a function of the departure-time 𝑡𝑜 from o. Due to the time-dependence of the arc-cost metric, the actual arc-cost value of each arc 𝑎=𝑢𝑣 can be computed only for specific departure-times from u, e.g., for the earliest presence-time 𝑡𝑢≥𝑡𝑜 at u, which is the earliest possible time that uv may start being traversed by a commuter originating from (𝑜,𝑡𝑜).

Problem Statements and Related Work
Two variants of the time-dependent shortest path problem have been considered in the literature:

𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜) (resp. 𝑇𝐷𝑆𝑃(𝑜,⋆,𝑡𝑜)) focuses on the one-to-one (resp. one-to-all) determination of the scalar cost of a minimum-travel-time (shortest) path to the destination d (resp. for all d), when departing from the origin o at time 𝑡𝑜.

TDSP(o, d) (resp., 𝑇𝐷𝑆𝑃(𝑜,⋆)) focuses on the one-to-one (resp., one-to-all) succinct representation of the time-dependent minimum-travel-time function(s) D[o, d] from o to d (resp. towards all reachable d), and all departure-times from o.

Tractability of TDSP Problems
𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜) has been studied as early as [5]. The first work concerning 𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜) with continuous departure-times axis was [11] where it was proved that, if waiting-at-nodes is allowed unconditionally, then 𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜) is solvable in quasilinear time via a time-dependent variant of Dijkstra’s algorithm (we call it 𝚃𝙳𝙳, for Time-Dependent Dijkstra), which relaxes arcs by computing the arc costs “on the fly”, upon settling their tails. A more complete treatment for the continuous case, considering various limitations in the waiting-times at the nodes of the network, was provided in [14]; an algorithm was also given for 𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜), whose complexity cannot be bounded by a function of the network topology. An excellent overview of the problem is provided in [21]. Among other results, it was proved that for affine arc-cost functions possessing the FIFO property (according to which all the arc-cost functions have slopes at least −1), in addition to 𝚃𝙳𝙳, a time-dependent variant of the label-correcting Bellman-Ford algorithm works. Moreover, if waiting-at-nodes is forbidden and the arc-costs do not preserve the FIFO property, then subpath-optimality of shortest paths is not necessarily preserved. In such a case, many variants of the problem are also 𝐍𝐏-hard [25]. Additionally, when shortest path costs are well defined and optimal waiting-times at nodes always exist, a non-FIFO arc with unrestricted-waiting-at-tail policy is equivalent to a FIFO arc in which waiting at the tail is not beneficial [21]. For all these reasons, we focus in this work on instances for which the FIFO property holds, as indeed is the case with most of past and recent work on 𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜); see e.g., [7, 8, 13, 15,16,17, 20].

The complexity of TDSP(o, d) was first questioned in [6, 7] and remained open until recently, when it was proved in [13] that, in case of FIFO-abiding pwl arc-cost functions, for a single origin-destination pair (o, d) the space complexity for succinctly representing D[o, d] is (1+𝐾)⋅𝑛𝛩(log𝑛), where n is the number of vertices and K is the total number of breakpoints (or legs) of all the arc-cost functions. Note that K can be substituted by the number 𝐾∗ (𝐾∗≤𝐾) of concavity-spoiling breakpoints (at which the arc-cost slopes increase) of the arc-cost functions [17, Section 3]. Several output-sensitive algorithms for the exact computation of D[o, d] have been presented in [7, 8, 13, 21], the most efficient ones being those in [8, 13].

Polynomial-Time Approximation Algorithms
Due to the above mentioned hardness of TDSP(o, d), and also since the time-dependent arc-costs are typically only (e.g., pwl) approximations of the actual costs, it is quite natural to seek for succinct representations of approximations to D[o, d], which aim at trading-off accuracy for computational effort. Several polynomial-time one-to-one (i.e., for a given (o, d) pair), (1+𝜀)-approximation algorithms for TDSP(o, d) have recently appeared in the literature [8, 13, 20]. The algorithm proposed in [8] requires

(1𝜀⋅(𝐷max[𝑜,𝑑]−𝐷min[𝑜,𝑑]))
calls of 𝑇𝐷𝑆𝑃(𝑑,𝑜,𝑡𝑑) in the reverse instance,Footnote2 for producing a (1+𝜀)-upper-approximating function 𝛥⎯⎯⎯⎯[𝑜,𝑑] of the min-travel-time function D[o, d], where 𝐷max[𝑜,𝑑]=max𝑡∈[0,𝑇)𝐷[𝑜,𝑑](𝑡), 𝐷min[𝑜,𝑑]=min𝑡∈[0,𝑇)𝐷[𝑜,𝑑](𝑡), and T is the time period. Another one-to-one (1+𝜀)−approximation algorithm was provided in [13]. That algorithm makes

(𝐾𝜀log(𝐷max[𝑜,𝑑]𝐷min[𝑜,𝑑])⋅log(𝑇𝐾𝜀𝐷min[𝑜,𝑑]))
calls to 𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜). Two further one-to-one (1+𝜀)-approximation algorithms for D[o, d] were given in [20]. The first algorithm requires

(𝐾𝜀⋅[log(𝐷max[𝑜,𝑑]𝐷min[𝑜,𝑑])+log(𝑇𝐾𝐷min[𝑜,𝑑])])
and the second algorithm requires

(𝐾⋅[1𝜀log(𝐷max[𝑜,𝑑]𝐷min[𝑜,𝑑])+log(𝐿𝐾𝜀𝐷min[𝑜,𝑑])])
calls to 𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜).

The first one-to-all (1+𝜀)-approximation algorithm for 𝑇𝐷𝑆𝑃(𝑜,⋆), called the bisection (𝙱𝙸𝚂) method, was given in [17]. It is based on bisecting the (common to all functions) axis of departure-times from o and considers slightly stricter assumptions than just the FIFO property for the arc-cost metric. 𝙱𝙸𝚂 requires

(𝐾∗log(1/𝜀)𝜀⋅log2(𝑛))
calls to 𝑇𝐷𝑆𝑃(𝑜,⋆,𝑡𝑜) to approximate the one-to-all problem 𝑇𝐷𝑆𝑃(𝑜,⋆). In the worst-case, this is a comparable amount of 𝑇𝐷𝑆𝑃(𝑜,⋆,𝑡𝑜) calls to those required by all known [8, 13, 20] (and aforementioned) one-to-one approximation algorithms, which solve just the TDSP(o, d) (single-pair) case.

Oracles for Time-Dependent Networks
Minimum-travel-time oracles for time-dependent networks—from now on being referred to as TD-oracles—had received no attention until recently [17].

A TD-oracle consists of an offline-precomputed data structure, which consequently allows the real-time evaluation of an upper-approximation 𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜) (summary) of the unknown function 𝐷[𝑜,𝑑](𝑡𝑜), for any possible query (𝑜,𝑑,𝑡𝑜)∈𝑉×𝑉×ℝ≥0 that may appear in an online fashion. The maximum value of the ratio 𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜)/𝐷[𝑜,𝑑](𝑡𝑜) is referred to as stretch factor or approximation guarantee.

One trivial oracle would be to precompute a succinct representation of 𝛥⎯⎯⎯⎯[𝑜,𝑑] for each origin-destination pair (𝑜,𝑑)∈𝑉×𝑉, for the sake of rapid evaluations in the future, but at the expense of superquadratic space.

Another trivial oracle would be to precompute nothing and just execute 𝚃𝙳𝙳 “on-the-fly” for each new query (𝑜,𝑑,𝑡𝑜), at the expense of superlinear query-time.

A non-trivial TD-oracle should thus aim to trade-off smoothly preprocessing requirements with query-response times and stretch factors. In particular, it should precompute a data structure in subquadratic time and space, provide a query algorithm which evaluates efficiently (i.e., much faster than 𝚃𝙳𝙳) 𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜), and provide a provably good approximation guarantee for 𝛥⎯⎯⎯⎯[𝑜,𝑑]. Note that there exists important applied work (speedup heuristics) for computing approximately optimal routes in time-dependent road networks (e.g., [4, 9, 10, 19]), which however provide mainly empirical evidence on the success of the adopted approaches.

The first non-trivial TD-oracles were provided in [17]. Their high-level construction works as follows: a subset of vertices (landmarks) is selected uniformly at random and subsequently upper-approximations of the minimum travel-time functions (called travel-time summaries) from any landmark to all other vertices were computed, using the 𝙱𝙸𝚂 one-to-many approximation algorithm. Two query algorithms, 𝙵𝙲𝙰 (simple) and 𝚁𝚀𝙰 (recursive), exploit these preprocessed travel-time summaries in order to answer any possible online query, by executing proper calls of 𝚃𝙳𝙳 from the origin up to the closest landmarks, and then complementing the travel-time information with the preprocessed data. Under certain conditions (cf. Sect. 4), those TD-oracles required (𝑛2−𝛽(𝐾∗+1)) preprocessing space and time, for some constant 𝛽∈(0,1), and are able to answer queries in time (𝑛𝛿), for some constant 𝛿∈(0,1). When 𝐾∗∈o(𝑛), the oracles can be fine-tuned so as to assure sublinear query-times, small stretch factor, and subquadratic preprocessing requirements in n. An extensive experimental evaluation of those oracles on a real-world road network was provided in [15], demonstrating their practicality, at the expense, however, of large memory consumption due to the linear dependence of the preprocessing requirements on 𝐾∗, which can be 𝛺(𝑛).

Challenge and Our Contributions
The main challenge addressed in this work is to provide TD-oracles that achieve:

Subquadratic preprocessing requirements, independent of 𝐾∗.

Query algorithms delivering arrival times with small stretch factor (smaller than 2) for any possible (𝑜,𝑑,𝑡𝑜)∈𝑉×𝑉×ℝ≥0 query.

Query-times sublinear, not only in the worst-case (i.e., in n), but also in the number 𝛤[𝑜,𝑑](𝑡𝑜) of settled vertices when executing 𝚃𝙳𝙳(𝑜,⋆,𝑡𝑜) (i.e., 𝚃𝙳𝙳 for solving 𝑇𝐷𝑆𝑃(𝑜,⋆,𝑡𝑜)) until d is settled, known as the Dijkstra-rankFootnote3 of that query.

We provide an axiomatic approach to address positively the aforementioned challenge. Our approach is axiomatic in the sense that: (a) we define certain properties which the underlying time-dependent network should satisfy; (b) we carry out an experimental analysis on real-world networks stemming from our prime application scenario (road networks), which shows that these networks indeed satisfy these properties; and (c) we provide new TD-oracles and perform a theoretical analysis on their performance on the class of networks satisfying these properties.

At a high-level, the construction of our new TD-oracles resemble those in [17]. However, to avoid the dependence on 𝐾∗, a new approximation method for preprocessing travel-time summaries (other than 𝙱𝙸𝚂) is required. Moreover, the requirement for achieving sublinear query time not only on network size, but also on the Dijkstra-rank, requires a different (hierarchical) approach than the (flat) approaches in [17], for constructing the sought TD-oracles and for answering queries. In particular, our specific contributions are as follows. We provide:

(i)
A novel and remarkably simple algorithm, called 𝚃𝚁𝙰𝙿 (cf. Sect. 5), for constructing one-to-many (1+𝜀)-upper-approximations 𝛥⎯⎯⎯⎯[𝑜,𝑑] (summaries) of minimum-travel-time functions D[o, d], for all “sufficiently distant” destinations d from the origin o. The 𝚃𝚁𝙰𝙿 algorithm requires o(𝑛) calls to 𝑇𝐷𝑆𝑃(𝑜,⋆,𝑡𝑜), which is independent of the degree of disconcavity 𝐾∗. Its novelty is that it does not require the concavity of the unknown function to approximate.

(ii)
Two new TD-oracles, 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 and 𝙵𝙻𝙰𝚃 (cf. Sect. 7). 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 exploits 𝚃𝚁𝙰𝙿, while 𝙵𝙻𝙰𝚃 exploits a proper combination of both 𝚃𝚁𝙰𝙿 and 𝙱𝙸𝚂, to construct minimum-travel-time summaries from randomly selected landmarks towards all reachable destinations. The preprocessed data structures of both TD-oracles require subquadratic space and time, independent of 𝐾∗. The query algorithms of both 𝙵𝙻𝙰𝚃 and 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 are based on proper extensions of the 𝚁𝚀𝙰 algorithm [17], in order to recover missing summaries for local neighborhoods around a landmark. In both cases sublinear query-times are achieved.

(iii)
A new hierarchical TD-oracle, called 𝙷𝙾𝚁𝙽 (cf. Sect. 8). 𝙷𝙾𝚁𝙽 sets up a hierarchy of landmarks, from many local landmarks possessing summaries only for small neighborhoods of destinations around them, up to a few global landmarks possessing summaries for all reachable destinations. 𝙷𝙾𝚁𝙽’s preprocessing requirements are again subquadratic. We then devise and analyze a novel query algorithm (𝙷𝚀𝙰) which exploits this hierarchy and achieves a query-time sublinear in the Dijkstra-rank of the query at hand.

Except for the choice of landmarks, our algorithms are deterministic. The stretch factor of all query algorithms is 1+𝜎, where 𝜎∈(𝜀,1) depends on the preprocessing approximation factor 𝜀 and the network properties. Table 1 summarizes the bounds of the TD-oracles presented here and their comparison with the oracles in [17].

Table 1 Bounds of new oracles for TD-instances, as functions of the parameters 𝛼,𝛽,𝛿∈(0,1)
Full size table
A recent experimental study [16] demonstrates the excellent performance of our oracles in practice, achieving considerable memory savings and query times about three orders of magnitude faster than 𝚃𝙳𝙳, and more than 70% faster than those in [15]. Preliminary parts of this work appeared in [18].

Preliminaries
A time-dependent network instance, or TD-instance henceforth, consists of a directed graph 𝐺=(𝑉,𝐴) with |𝑉|=𝑛 vertices and |𝐴|=𝑚 arcs. As is typical for shortest-path computations, we focus on strongly-connected graphs. Queries for non-strongly-connected instances could then be answered by separate calls to algorithms for strongly-connected components which lie on the way from the origin’s towards the destination’s components.

Each arc 𝑎∈𝐴 is accompanied with a continuous, pwl arc-cost function 𝐷[𝑎]:ℝ≥0↦ℝ>0. We assume that all these functions are periodic with period 𝑇>0 and are defined as follows: ∀𝑘∈ℕ,∀𝑡∈[0,𝑇), 𝐷[𝑎](𝑘𝑇+𝑡)=𝑑[𝑎](𝑡), where 𝑑[𝑎]:[0,𝑇)→[ 𝐷⎯⎯⎯[𝑎] , 𝐷⎯⎯⎯⎯⎯[𝑎] ] is such that lim𝑡↑𝑇𝑑[𝑎](𝑡)=𝑑[𝑎](0), for some fixed integers 0<𝐷⎯⎯⎯[𝑎]≤𝐷⎯⎯⎯⎯⎯[𝑎]. 𝐷⎯⎯⎯[𝑎] and 𝐷⎯⎯⎯⎯⎯[𝑎] denote the minimum (i.e., free-flow) and maximum (i.e., full-congestion) traversal-times ever seen for arc a.

Since D[a] is periodic, continuous and pwl function, it can be represented succinctly by a sequence of 𝐾𝑎 breakpoints (i.e., pairs of departure-times and arc-cost values) defining d[a]. Let 𝐾=∑𝑎∈𝐴𝐾𝑎 be the number of breakpoints representing all arc-cost functions, 𝐾max=max𝑎∈𝐴𝐾𝑎, and let 𝐾∗ be the number of concavity-spoiling breakpoints (the ones at which the arc-cost function slopes increase). Clearly, 𝐾∗≤𝐾, and 𝐾∗=0 for concave arc-cost functions. It is assumed in this work that the traversal-time function d[a] of each arc 𝑎∈𝐴 requires a small (e.g., sublinear) number of breakpoints: 𝐾𝑎∈o(𝑛). This is justified by real-world scenarios, where these breakpoints are periodically sampled traversal-times within the period [0, T), which are mainly collected via crowd-sourced information provided automatically (e.g., per minute) by the commuters. In other words, we anticipate 𝐾𝑎∈(𝑇) breakpoints per arc, or 𝐾∈(𝑚⋅𝑇) breakpoints in overall for the entire graph. Under certain conditions (sparsity and scaling) that will be explained later in this section, the required space to store the instance would remain subquadratic in the graph size. Moreover, the two extreme traversal times 𝐷⎯⎯⎯[𝑎] (for the free-flow metric) and 𝐷⎯⎯⎯⎯⎯[𝑎] (for the full-congestion metric) are also assumed to be part of the input. For example, during the preprocessing we determine and store them along with the representation of each d[a] as a collection of breakpoints. This is done only once per arc, so that we have the entire (static) free-flow and full-congestion metrics at our disposal. Since each arc only has at most 𝐾max∈(𝑇) breakpoints (0<𝛼<1), we need in total an amount of (𝑚⋅𝑇) operations and (𝑚) space, to determine and store these extreme traversal-times, for all the arcs in the network.

To ease the exposition and also for the sake of compliance with terminology in previous works (inspired by the primary application scenario of route planning in time-dependent road networks), we consider arc-costs as arc-travel-times and time-dependent shortest paths as minimum-travel-time paths. This terminology facilitates the following definitions.

The arc-arrival-time function of an arc 𝑢𝑣∈𝐴 is 𝐴𝑟𝑟[𝑢𝑣](𝑡𝑢)=𝑡𝑢+𝐷[𝑢𝑣](𝑡𝑢), ∀𝑡∈[0,∞), i.e., it provides the actual arrival-time at v, depending on the departure-time 𝑡𝑢 from u. In this work we focus on time-dependent instances abiding with the strict-FIFO property, i.e., for which all the arc-arrival-time functions Arr[uv] are strictly increasing. Equivalently, all the arc-travel-time functions D[uv] have slope strictly larger than −1. We can also express the arc-travel-time function D[uv] of an arc uv as a function of the arrival-time 𝑡𝑣=𝑡𝑢+𝐷[𝑢𝑣](𝑡𝑢) at the head v. This is particularly useful when we need to work with the reverse TD-instance (𝐺⃖ =(𝑉,𝐴,(𝐷⃖ [𝑎])𝑎∈𝐴), where 𝐷⃖ [𝑢𝑣](𝑡𝑣)=𝑡𝑣−𝑡𝑢 is the time for traversing uv, measured now as a function of the arrival-time 𝑡𝑣 at v. In 𝐺⃖ , we traverse an arc 𝑢𝑣∈𝐴 backwards in time (there is no need to actually reverse the direction of a), that is, from (𝑣,𝑡𝑣) we move back to to (𝑢,𝑡𝑢), by setting 𝑡𝑢=𝑡𝑣−𝐷⃖ [𝑢𝑣](𝑡𝑣). The reverse TD-instance is used when we seek, starting from (𝑑,𝑡𝑑), a minimum-travel-time od-path of latest-departure 𝑡𝑜 from o such that we can be at d by time 𝑡𝑑.

The path-arrival-time function of a path 𝑝=⟨𝑎1,…,𝑎𝑘⟩ in G is the composition 𝐴𝑟𝑟[𝑝](𝑡)=𝐴𝑟𝑟[𝑎𝑘](𝐴𝑟𝑟[𝑎𝑘−1](⋯(𝐴𝑟𝑟[𝑎1](𝑡))⋯)) of the arc-arrival-time functions of its constituent arcs 𝑎1,…,𝑎𝑘. The path-travel-time function is then 𝐷[𝑝](𝑡)=𝐴𝑟𝑟[𝑝](𝑡)−𝑡.

For any (𝑜,𝑑)∈𝑉×𝑉, let 𝑜,𝑑 denote the set of od-paths. For any 𝑝∈𝑜,𝑥 and 𝑞∈𝑥,𝑑, the path 𝑠=𝑝∙𝑞∈𝑜,𝑑 is the concatenation of p and q at x. The earliest-arrival-time function is defined as 𝐴𝑟𝑟[𝑜,𝑑](𝑡𝑜)=min𝑝∈𝑜,𝑑{𝐴𝑟𝑟[𝑝](𝑡𝑜)}, ∀𝑡𝑜≥0, while the minimum-travel-time 𝐷[𝑜,𝑑](𝑡𝑜)=min𝑝∈𝑜,𝑑{𝐷[𝑝](𝑡𝑜)}=𝐴𝑟𝑟[𝑜,𝑑](𝑡𝑜)−𝑡𝑜. Observe that, when the FIFO property is not fulfilled, the above mentioned definition may not refer to pure travel-times, as it may possibly contain waiting times at the origin and/or intermediate vertices. As previously mentioned, the present work focuses on FIFO-abiding TD-instances, for which it is the case that 𝐷[𝑜,𝑑](𝑡𝑜) is indeed the actual travel-time along some od-path with no waits, since it never pays-off to wait in those instances.

For a query (𝑜,𝑑,𝑡𝑜), 𝑆𝑃[𝑜,𝑑](𝑡𝑜)={𝑝∈𝑃𝑜,𝑑:𝐴𝑟𝑟[𝑝](𝑡𝑜)=𝐴𝑟𝑟[𝑜,𝑑](𝑡𝑜)} denotes the set of earliest-arrival-time (equivalently, minimum-travel-time, for FIFO TD-instances) paths, and 𝐴𝑆𝑃[𝑜,𝑑;𝜀](𝑡𝑜)={𝑝∈𝑃𝑜,𝑑:𝐷[𝑝](𝑡𝑜)≤(1+𝜀)⋅𝐷[𝑜,𝑑](𝑡𝑜)} denotes the set of od-paths whose travel-time values are (1+𝜀)-approximations of the minimum-travel-time among all od-paths.

When we say that we “grow a 𝚃𝙳𝙳 ball from (𝑜,𝑡𝑜)”, or “centered at (𝑜,𝑡𝑜)”, we refer to the execution of 𝚃𝙳𝙳 for discovering time-dependent shortest paths from 𝑜∈𝑉 for departure time 𝑡𝑜∈[0,𝑇), i.e., solutions to the problem 𝑇𝐷𝑆𝑃(𝑜,⋆,𝑡𝑜) (resp. to 𝑇𝐷𝑆𝑃(𝑜,𝑑,𝑡𝑜), for a specific destination d). Such a call, which we denote as 𝚃𝙳𝙳(𝑜,⋆,𝑡𝑜) (resp. 𝚃𝙳𝙳(𝑜,𝑑,𝑡𝑜)), takes time:

(𝑚⋅max𝑎∈𝐴{𝐸𝑣𝑎𝑙(𝐷[𝑎])}+𝑛log(𝑛))=(𝑚loglog(𝐾max)+𝑛log(𝑛))
where Eval(D[a]) is the worst-case cost for evaluating the arc-travel-time function D[a]. It is noted that, since D[a] is periodic, continuous and pwl, Eval(D[a]) can be implemented either in time (log(𝐾𝑎)) by a binary search among the 𝐾𝑎 breakpoints describing the function for identifying the right leg of D[a] in which the departure time lies, or even in time (loglog(𝐾𝑎)), while still requiring space (𝐾), by using more advanced predecessor-search data structures like the van Emde Boas trees [29, 30].

Apart from the travel-time metric for measuring distances of destinations from the origin, another metric is also implicitly considered when using Dijkstra-like algorithms (e.g., 𝚃𝙳𝙳) for serving a query (𝑜,𝑑,𝑡𝑜), called the Dijkstra-rank 𝛤[𝑜,𝑑](𝑡𝑜), which is the number of settled vertices up to d, when executing 𝚃𝙳𝙳(𝑜,𝑑,𝑡𝑜). This is an important metric because the performance of Dijkstra-like algorithms is quasi-linear, not only in the network size, but indeed in the actual Dijkstra-rank of the query at hand.

Returning to the travel-time metric, for each 𝑎=𝑢𝑣∈𝐴 and [𝑡𝑠,𝑡𝑓)⊆[0,𝑇), we define upper- and lower-bounding travel-time metrics. In particular, the minimally-congested travel-time is

𝐷⎯⎯⎯[𝑢𝑣](𝑡𝑠,𝑡𝑓)=inf𝑡𝑢∈[𝑡𝑠,𝑡𝑓){𝐷[𝑢𝑣](𝑡𝑢)}
and the maximally-congested travel-time is

𝐷⎯⎯⎯⎯⎯[𝑢𝑣](𝑡𝑠,𝑡𝑓)=sup𝑡𝑢∈[𝑡𝑠,𝑡𝑓){𝐷[𝑢𝑣](𝑡𝑢)}.
If [𝑡𝑠,𝑡𝑓)=[0,𝑇), we refer to the static free-flow and full-congestion metrics 𝑑⎯⎯,𝑑⎯⎯⎯:𝐴→(0,∞), respectively. In particular, as already mentioned, each arc 𝑎∈𝐴 is also accompanied with scalars 𝐷⎯⎯⎯[𝑎]=𝐷⎯⎯⎯[𝑎](0,𝑇) and 𝐷⎯⎯⎯⎯⎯[𝑎]=𝐷⎯⎯⎯⎯⎯[𝑎](0,𝑇) for these static metrics. For any arc-cost metric D, diam(G, D) is the diameter (largest possible vertex-to-vertex distance) of the graph in that metric. For example, 𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯) and 𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯⎯⎯) denote the free-flow and full-congestion diameters of G, respectively.

In our TD-instance, we can assume without loss of generality (wlog) that 𝑇≥𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯) and 𝑇=𝑛𝛼 for some given constant 𝛼∈(0,1) of our control. If either of these two assumptions is violated, we can easily transform our TD-instance to comply with it:

If 𝑇<𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯), then we pick a positive integer 𝑐≥1 so that (𝑐−1)⋅𝑇<𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯)≤𝑐⋅𝑇=𝑇′. Consequently we consider c consecutive copies of each d[a] as a single function 𝑑′[𝑎]:[0,𝑇′)↦ℝ>0 and we use the new periodic arc-travel-time function 𝐷′[𝑎](𝑡+𝑘⋅𝑇′)=𝑑′[𝑎](𝑡), ∀𝑡∈[0,𝑇′). The new TD-instance obviously has period 𝑇′=𝑐⋅𝑇≥𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯′)>(𝑐−1)⋅𝑇. We make here the assumption that 𝑐∈(1), i.e., at most a constant number of copies of [0, T) would be required. This assumption is quite reasonable for our motivating examples, since in a typical road network instance the period T is either 24 hours (single-day) or (most usually) 7 days. Even in a continental-size road network, like that of Europe, the free-flow diameter cannot be dramatically larger than T.

If 𝑇≠𝑛𝛼, then we exploit the fact that, for all the involved functions in our TD-instance, both the domain and the codomain determine (travel-, earliest-arrival-, or presence-) time points. We represent values in both the domain and the codomain in each of these functions as multiples of a new unit of time, 𝑇𝑛𝛼. For instance, we might have to move from second-units to either millisecond- or to minute-units, depending on how T compares with 𝑛𝛼. Along the domain (x-) axis of the arc-travel-time functions, all values 𝑡≥0 are now mapped to 𝑡″=𝑡⋅𝑛𝛼𝑇 units. Thus, the domain of each function d[a] is now confined to [0,𝑇″=𝑇⋅𝑛𝛼𝑇=𝑛𝛼). Along the codomain (y-) axis of the involved (arc-travel-time / arc-arrival-time) functions, we have that 𝐷″[𝑎](𝑡″)=𝐷[𝑎](𝑡)⋅𝑛𝛼𝑇 as well. I.e., all (including free-flow, time-dependent, or fully-congested) travel-times in the TD-instance are also scaled by the same multiplicative factor 𝑛𝛼𝑇. In particular, the comparison of 𝑇″ with 𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯″) is the same as that of T with 𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯).

Consequently, from now on we can safely consider TD-instances with 𝑇=𝑛𝛼≥𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯).

We now proceed with some definition of balls under the travel-time metrics. For any 𝑣∈𝑉, departure-time 𝑡𝑣∈ℝ≥0, integer 𝐹∈[𝑛]Footnote4 and scalar 𝑅>0:

𝐵[𝑣;size=𝐹](𝑡𝑣) denotes a TD-ball from (𝑣,𝑡𝑣) containing the first F settled vertices (i.e., a ball of size F), in the time-dependent travel-time metric.

𝐵[𝑣;radius=𝑅](𝑡𝑣) denotes a TD-ball from (𝑣,𝑡𝑣) containing all the settled vertices with distance from (𝑣,𝑡𝑣) at most R (i.e., a ball of radius R), in the time-dependent metric.

Analogously, 𝐵⎯⎯⎯[𝑣;size=𝐹] and 𝐵⎯⎯⎯⎯[𝑣;size=𝐹] denote the size-F balls from v, whereas 𝐵⎯⎯⎯[𝑣;radius=𝑅]) and 𝐵⎯⎯⎯⎯[𝑣;radius=𝑅] denote the radius-R balls from v, in the free-flow and fully-congested travel-time metrics respectively.

For arbitrary 𝜀⎯⎯⎯,𝜀⎯⎯>0, a pair of continuous, pwl, periodic functions 𝛥⎯⎯⎯⎯[𝑜,𝑑] and 𝛥⎯⎯⎯[𝑜,𝑑]), with a (hopefully) small number of breakpoints, are (1+𝜀⎯⎯⎯)-upper-approximation and (1+𝜀⎯⎯)-lower-approximation of D[o, d] respectively, if the following holds: ∀𝑡𝑜≥0,

𝐷[𝑜,𝑑](𝑡𝑜)1+𝜀⎯⎯≤𝛥⎯⎯⎯[𝑜,𝑑](𝑡𝑜)≤𝐷[𝑜,𝑑](𝑡𝑜)≤𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜)≤(1+𝜀⎯⎯⎯)⋅𝐷[𝑜,𝑑](𝑡𝑜)
Clearly, when we only know that these functions are upper- and lower approximations of D[o, d] but we cannot specify the exact quality of the approximations because D[o, d] is hard to compute, it would suffice to prove that ∀𝑡𝑜≥0, 𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜)≤(1+𝜀)⋅𝛥⎯⎯⎯[𝑜,𝑑](𝑡𝑜), in order to claim that 𝛥⎯⎯⎯⎯[𝑜,𝑑] is a (1+𝜀)-upper-approximation of D[o, d], for some 𝜀>0.

Finally, we consider TD-instances on sparse graphs. This is because our goal is to design TD-oracles using subquadratic preprocessing space, sublinear query time, and small stretch factor, e.g., smaller than 2. In [1, 23] it was shown that, even in the much lighter case of static and undirected networks, a stretch factor less than 2 would be possible with subquadratic preprocessing space and sublinear query time only when 𝑚∈o(𝑛2). For the much more demanding case of time-dependent instances that we consider in this work, we concentrate on instances with n vertices and 𝑚∈(𝑛) arcs for two reasons: (i) they are interesting from a practical point of view, since almost all real-world instances stemming from our main application scenario (route planning in road networks) fulfill this property; (ii) any Dijkstra-like query algorithm would probably fail to achieve sublinear query time, due to the existence of many high-degree vertices.

For convenience, the notation used throughout the paper is summarized in “Appendix A”.

Properties, Validity and Implications
The directedness and time-dependence in the underlying network imply an asymmetric arc-cost metric that also evolves with time. To achieve a smooth and measurable transition from static and undirected graphs towards time-dependent and directed graphs, we need a quantification of the degrees of asymmetry and evolution of our metric over time. These are captured via a set of parameters 𝛬min,𝛬max,𝜁,𝜆 of the input instance (that will be formally defined in Sect. 3.1), which are also provided as part of the input, depicting the steepness of the minimum-travel-time functions, the ratio of minimum-travel-times in opposite directions, and the relation between graph expansion and travel-times.

In the rest of this section, we start by defining three properties for the values of these parameters. These properties constitute the foundations of our axiomatic approach. We then discuss the characteristics of the TD-instances as they result from the TD-oracle requirements and the implications of these properties. Finally, we present our experimental analysis which validates the three properties on real-world TD-instances stemming from our main application scenario (road networks).

Properties
The first property states that all minimum-travel-time partial derivatives (a.k.a slopes) are bounded within a given interval.

Proposition 1
(Bounded travel-time slopes) For constants 𝛬min∈[0,1) and 𝛬max≥0, the following holds:

∀(𝑜,𝑑)∈𝑉×𝑉, ∀0≤𝑡1<𝑡2, 𝐷[𝑜,𝑑](𝑡2)−𝐷[𝑜,𝑑](𝑡1)𝑡2−𝑡1∈[−𝛬min,𝛬max].
The lower-bound of −1 in the minimum-travel-time function slopes is indeed a direct consequence of the FIFO property, which is typically assumed to hold in several time-dependent road network instances. The parameter 𝛬max represents the maximum possible rate of change of minimum-travel-times in the network, which only makes sense to be bounded (in particular, independent of the network size) in realistic instances such as the ones representing urban-traffic time-dependent road networks.

The second property asserts that the ratio of minimum-travel-times in opposite directions between two vertices, for any specific departure-time but not necessarily via the same path, is upper bounded by a given constant.

Proposition 2
(Bounded opposite trips) ∃ 𝜁≥1, ∀(𝑜,𝑑)∈𝑉×𝑉, ∀𝑡∈[0,𝑇), 𝐷[𝑜,𝑑](𝑡)≤𝜁⋅𝐷[𝑑,𝑜](𝑡).

This property holds naturally in road networks. For instance, it is rather unlikely that a trip in one direction is more than, say, 10 times longer than the trip in the opposite direction, when departing from either endpoint of the trip at a given time.

The next property guarantees that, when we extend (under the free-flow metric) the radius of a size-F free-flow ball, up to the value of the full-congestion radius in it, the blow-up in the size of the new (free-flow again) ball is bounded by a slowly growing (in particular, polylogarithmic) function in the network size. Figure 1 visualizes this property, which is formally stated as follows.

Fig. 1
figure 1
Visualization of Property 3

Full size image
Proposition 3
(Bounded growth of free-flow balls) For 𝑅>1, consider any free-flow ball 𝐵⎯⎯⎯=𝐵⎯⎯⎯[ℓ;𝑟𝑎𝑑𝑖𝑢𝑠=𝑅] around some vertex ℓ, which also has size 𝐹=|𝐵⎯⎯⎯|. Let 𝑅∗=max𝑣∈𝐵⎯⎯⎯{𝐷⎯⎯⎯⎯⎯[ℓ,𝑣]} be the maximum travel-time of a vertex 𝑣∈𝐵⎯⎯⎯ from ℓ, under the full-congestion metric, and 𝐹∗=|𝐵⎯⎯⎯[ℓ;radius=𝑅∗]| is the size of the (extended) free-flow ball around ℓ of radius 𝑅∗≥𝑅. Then, it holds that 𝐹∗∈(𝐹polylog(𝐹)).

Property 3 is significant in our analysis, because it guarantees the following: Whenever we restrict our efforts to a small subgraph of the entire network, e.g. a free-flow ball B from 𝑣∈𝑉 with the F closest destinations, then we can safely assume that, under either the time-dependent or the full-congestion metric, the smallest ball from v containing all these destinations of B has size (𝐹polylog(𝐹)). We have assessed the meaningfulness of Property 3 by verifying it in the real-world road network instances that we have at our disposal (cf. [16, Section 2]).

Finally, we need a systematic way to correlate the travel-time metric with the Dijkstra-rank metric induced by it. For this reason, inspired by the notion of the doubling dimension (e.g., see [2] and references therein), we consider some scalar 𝜆≥1 and a function 𝑓:ℕ↦[1,∞), such that the following holds: ∀(𝑜,𝑑,𝑡𝑜)∈𝑉×𝑉×[0,𝑇), (i) (𝐷[𝑜,𝑑](𝑡𝑜))𝜆≤𝛤[𝑜,𝑑](𝑡𝑜)≤𝑓(𝑛)⋅(𝐷[𝑜,𝑑](𝑡𝑜))𝜆.

This property trivially holds, e.g., for 𝜆=1, 𝑓(𝑛)=𝑛min𝑢𝑣∈𝐴𝐷⎯⎯⎯[𝑢𝑣]. Our interest is for the largest allowable value for 𝜆, for slow-growing (e.g., at most polylogarithmic) function f(n). Observe that, for vertices whose travel-time distance is 𝐷[𝑜,𝑑]>1, it holds that 𝜆≤log(𝑛) would suffice, since 𝛤[𝑜,𝑑]≤𝑛=2log(𝑛)∈(𝐷[𝑜,𝑑]log(𝑛)). Our last property quantifies exactly the boundedness of this correlation by restricting 𝜆 and f(n).

Proposition 4
(Correlation of travel time and Dijkstra-rank) There exist 𝜆,𝑐∈(1) and 𝑓(𝑛)∈(log𝑐(𝑛)), for which the following holds, for any 𝑡𝑜∈[0,𝑇) and travel-time value 𝐷[𝑜,𝑑](𝑡𝑜)>1:

𝐷[𝑜,𝑑](𝑡𝑜)𝜆≤𝛤[𝑜,𝑑](𝑡𝑜)≤𝑓(𝑛)⋅𝐷[𝑜,𝑑](𝑡𝑜)𝜆.
Analogous inequalities hold for the free-flow and the full-congestion metrics 𝐷⎯⎯⎯ and 𝐷⎯⎯⎯⎯⎯.

The importance of Property 4, is that it allows us to bound within small multiplicative factors the penalization that we undergo, when we have to “jump” from the travel-time metric to the Dijkstra-rank metric and vice versa.

Note that static oracles based on the doubling dimension (e.g., [2]) typically concern undirected graphs for which they require the second inequality of the property, for some constant value for the exponent 𝜆 of the expansion. In the present work, since we have to deal with directed graphs, we additionally require the first inequality. However, we also introduce some slackness by allowing some divergence from the corresponding powers by polylogarithmic factors.

Implications of Properties and TD-Oracle Requirements
We proceed with some simple consequences of the requirements of TD-oracles set in Sect. 1, as well as of the aforementioned properties, in order to shed light on the implications they impose on the considered TD-instance G.

We begin with an implication of Property 1 on the variation of travel-time distances from an origin to a destination, under the time-dependent metric.

Lemma 1
(Variation between free-flow and full-congestion metrics) For any pair of vertices (𝑜,𝑑)∈𝑉×𝑉, 𝐷max[𝑜,𝑑]=max𝑡∈[0,𝑇){𝐷[𝑜,𝑑](𝑡)} and 𝐷min[𝑜,𝑑]=min𝑡∈[0,𝑇){𝐷[𝑜,𝑑](𝑡)}, it holds that 𝐷max[𝑜,𝑑]−𝐷min[𝑜,𝑑]≤𝛬min⋅𝛬max𝛬min+𝛬max⋅𝑇<𝑇.

Proof
(Lemma 1) Assume without loss of generality (e.g., by shifting times over the time-axis) that 𝐷min[𝑜,𝑑]=𝐷[𝑜,𝑑](0) and 𝐷max[𝑜,𝑑]=𝐷[𝑜,𝑑](𝑡⎯⎯). We apply Property 1 for the time points 𝑡1=𝑡⎯⎯−𝑇<𝑡2=0<𝑡3=𝑡⎯⎯.


The maximum value of the upper-bounding lower envelope (as a function of 𝑡⎯⎯) in the RHS of this last inequality is achieved at 𝑡⎯⎯=𝛬min𝛬min+𝛬max⋅𝑇. Therefore, we conclude that

𝐷max[𝑜,𝑑]−𝐷min[𝑜,𝑑]≤𝛬min𝛬max𝛬min+𝛬max⋅𝑇<𝑇
since 𝛬min𝛬max𝛬min+𝛬max<𝛬min≤1, for 𝛬min∈(0,1) and 𝛬𝑚𝑎𝑥≥0. ◻

Property 2 implies that our TD-instance should be strongly connected, which is indeed the case for almost all real-world TD-instances (e.g., road networks). Moreover, it quantifies the “degree of directedness” by the value of the 𝜁 parameter.

We now turn to the implications of Property 4 on the density of free-flow balls with small radius, which are materialized in Lemma 2. This lemma demonstrates that radius-1 free-flow balls are small in their size. This allows the exclusion from the preprocessing phase of all those destinations which are very close to a given landmark, since they can easily be dealt with by the query algorithm for a controllable additional cost. Moreover, Lemma 2 gives a nice natural interpretation of f(n): It expresses the maximum number of destinations at free-flow distance at most 1 from any given landmark, after scaling the travel-time metric so that 𝑇=𝑛𝛼.

Lemma 2
(Polylogarithmic Size of Radius-1 Free-Flow Balls) The number of destinations at free-flow travel-time at most 1 from an arbitrary vertex ℓ∈𝑉 is at most f(n).

Proof
(Lemma 2) Consider the ball 𝐵=𝐵⎯⎯⎯[ℓ;radius=1]. We exploit the fact a ball around ℓ may only expand, as we increase its radius. That is, ∀𝜔>0 it holds that 𝐵⎯⎯⎯[ℓ;radius=1]⊆𝐵⎯⎯⎯[ℓ;radius=1+𝜔]. Since Property 4 holds for the free-flows, we have:

|𝐵⎯⎯⎯[ℓ;radius=1]|≤|𝐵⎯⎯⎯[ℓ;radius=1+𝜔]|≤𝑓(𝑛)⋅(1+𝜔)𝜆→𝜔↓0𝑓(𝑛)
◻

Finally, we wish to specify the connection of our scaling of the time-axis so that 𝑇=𝑛𝛼 and 𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯)=𝑛𝛼𝜈 for a constant 𝜈∈(0,1) with the value of 𝜆. This is indeed the appropriate scaling factor which guarantees both the low density of radius-1 balls and the validity of Property 4.

Lemma 3
(𝛼𝜆𝜈≈1) Consider an instance for which the time axis is scaled so that 𝑇=𝑛𝛼 and 𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯)=𝑛𝛼𝜈 for 𝜈∈(0,1). Then, the following holds:

1𝜆⋅(1−log(𝑓(𝑛))log(𝑛))≤𝛼𝜈≤1𝜆
Proof
(Lemma 3) Under the free-flow metric, observe that along the longest min-travel-time path (which determines the free-flow diameter), if we consider one terminal point as the origin then the other terminal point is at travel-time distance 𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯) and at Dijkstra-rank distance exactly n from it, assuming strong connectivity in the network.

The upper bound is quite simple to be proved, taking into account that Property 4 holds:

𝑛𝛼𝜈=𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯)≤𝑛1/𝜆⇒𝛼𝜈≤1𝜆
Analogously, for the lower bound we exploit again Property 4:

𝑛𝛼𝜈=𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯)≥(𝑛𝑓(𝑛))1/𝜆⇒(𝑓(𝑛))1/𝜆≥𝑛1/𝜆−𝛼𝜈⇒1𝜆log(𝑓(𝑛))≥(1𝜆−𝛼𝜈)log(𝑛)⇒𝛼𝜈≥1𝜆(1−log(𝑓(𝑛))log(𝑛))
◻

To summarize, in the rest of the paper we consider sparse, strongly connected TD-instances, possessing the features described in Properties 1, 2, 3 and 4, with 𝑇=𝑛𝛼, and with no more than f(n) vertices at free-flow distance 1 from any vertex.

Validity of Properties
The aforementioned properties were verified through an experimental analysis on three TD-instances.

A real-world TD-instance concerning the road network of the urban-area of the city of Berlin, kindly provided to us by TomTom (in the frame of [12]), consisting of 𝑛=473,253 vertices and 𝑚=1,126,468 arcs, in which the arc-delay functions are the continuous, pwl interpolants of five-minute samples of the average travel-times in each road segment.

A real-world TD-instance concerning the national road network of Germany, kindly provided to us by PTV AG [24] for scientific use, consisting of 𝑛=4,692,091 vertices and 𝑚=10,805,429 arcs, with similar (to the Berlin instance) arc-delay functions.

A real-world benchmark TD-instance of Western Europe’s (WE) road network, kindly provided by PTV AG [24] for scientific use, consisting of 𝑛=18,010,173 vertices and 𝑚=42,188,664 arcs. The time-dependent arc travel time functions were generated as described in [19], reflecting a high amount of traffic for all types of roads (highways, national roads, urban roads), all of which posses non-constant time-dependent arc travel time functions.

We performed 50, 000 random queries (𝑜,𝑑,𝑡𝑜) on all the aforementioned TD-instances, by selecting 50, 000 random (o, d) pairs and focusing on the harder case of rush-hour departure times 𝑡𝑜.

Our experimental analysis (a preliminary version of which was reported in [16]) exhibited the following numbers for the parameters 𝛬max (Property 1) and 𝜁max (maximum value of 𝜁, Property 2):

Berlin TD-instance: 𝛬max<0.225, 𝜁max<2.043.

Germany TD-instance: 𝛬max<0.454, 𝜁max<2.256.

W. Europe TD-instance (heavy-traffic variant): 𝛬max<8.33, 𝜁𝑚𝑎𝑥<2.331.

Property 3 has also been verified in our benchmark networks, where the blow-up in the ball size 𝐹∗ is less than 10 times that of F. For more details on this experiment, the reader is deferred to [16, Section 6.2 and Table 4].

As for Property 4, the value of 𝜆 depends on the choice of the scaling parameter 𝛼, for the travel-time metric. In particular, as we explain in the next section, 𝜆≤1𝛼. Moreover, f(n) concerns the maximum number of vertices contained in a radius-1 ball under the free-flow metric.

In summary, the experimental analysis on the aforementioned TD-instances reveals that real-world time-dependent networks indeed possess features captured by the parameters described in the four properties and that the values of these parameters are small constants.

Review of TD Oracles in [17] and New Variants
We now give an overview of the TD-oracles presented and analyzed in [17]. Those oracles are essential for understanding the new oracles presented and analyzed in this work. Recall that at a high-level, these oracles comprise of two phases: a preprocessing phase (landmark selection and computation of approximation summaries from these landmarks to all other vertices using 𝙱𝙸𝚂) and a query phase. Note also that the analysis of the TD-oracles in [17] is based on sparse TD-instances possessing Properties 1 and 2.

Review of TD Oracles in [17]
The TD-oracles in [17] start by first determining, for some 𝜌∈(0,1), a set L of 𝜌𝑛 𝐢𝐮𝐚𝐫Footnote5 selected landmarks (vertices acting as reference points). During the preprocessing phase, all (1+𝜀)-upper-approximating functions (travel-time summaries) 𝛥⎯⎯⎯⎯[ℓ,𝑣] are constructed from each landmark ℓ∈𝐿 towards every reachable destination 𝑣∈𝑉, using the 𝙱𝙸𝚂 approximation algorithm that keeps bisecting the common axis of departure-times from ℓ, until the desired approximation guarantee is achieved in each subinterval, for all destinations. It is proved in [17] that 𝙱𝙸𝚂 requires

(𝐾∗𝜀max𝑑∈𝑉{log(𝑇⋅(𝛬max+1)𝜀min𝑡𝑜{𝐷[𝑜,𝑑](𝑡𝑜)})}max𝑑∈𝑉{log(max𝑡𝑜{𝐷[𝑜,𝑑](𝑡𝑜)}min𝑡𝑜{𝐷[𝑜,𝑑](𝑡𝑜)})})
calls to 𝚃𝙳𝙳(𝑜,⋆,𝑡𝑜), for a given origin 𝑜∈𝑉 and all reachable destinations from it. This in turn implies at most (𝐾∗⋅log(1/𝜀)𝜀log2(𝑛)) calls, when 𝑇,𝐷⎯⎯⎯⎯⎯[𝑜,𝑑]∈poly(𝑛) and 𝐷⎯⎯⎯[𝑜,𝑑]≥1.

Two query algorithms were proposed in [17], 𝙵𝙲𝙰 and 𝚁𝚀𝙰, which provide constant and (1+𝜎)-approximations (for constant 𝜎>𝜀) to minimum-travel-times, respectively.

𝙵𝙲𝙰 is a simple sublinear-time algorithm for evaluating 𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜), guaranteeing a constant approximation w.r.t. 𝐷[𝑜,𝑑](𝑡𝑜). In particular, it grows a 𝚃𝙳𝙳 ball 𝐵[𝑜](𝑡𝑜)={𝑥∈𝑉:𝐷[𝑜,𝑥](𝑡𝑜)≤𝐷[𝑜,ℓ𝑜](𝑡𝑜)} from (𝑜,𝑡𝑜), until either d or the closest landmark ℓ𝑜∈argminℓ∈𝐿{𝐷[𝑜,ℓ](𝑡𝑜)} is settled. 𝙵𝙲𝙰 then returns either the exact travel-time value, or the approximate travel-time value via ℓ𝑜, 𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜)=𝐷[𝑜,ℓ𝑜](𝑡𝑜)+𝛥⎯⎯⎯⎯[ℓ𝑜,𝑑](𝑡𝑜+𝐷[𝑜,ℓ𝑜](𝑡𝑜)), which is a guaranteed (1+𝜀+𝜓)-approximation; 𝜓 is a constant depending on 𝜀,𝜁 and 𝛬max, but not on the size of the network.

𝚁𝚀𝙰 improves the approximation guarantee provided by 𝙵𝙲𝙰, by exploiting carefully a number of recursive accesses to the preprocessed information, each of which produces (via calls to 𝙵𝙲𝙰) additional candidate od-paths. The tuning parameter 𝑟∈ℕ – the recursion budget – is the depth of the produced recursion tree. 𝚁𝚀𝙰 works as follows: As long as the destination vertex has not yet been discovered in the explored area around the origin, and there is still some remaining recursion budget, it “guesses” (by exhaustively searching for it) the next vertex 𝑤𝑘 at the boundary of the current ball, along the (unknown) shortest od-path. Then, it grows a new 𝚃𝙳𝙳 ball from the new center

(𝑤𝑘 , 𝑡𝑘=𝑡𝑜+𝐷[𝑜,𝑤1](𝑡𝑜)+𝐷[𝑤1,𝑤2](𝑡1)+⋯+𝐷[𝑤𝑘−1,𝑤𝑘](𝑡𝑘−1)),
where 𝑤𝑖, 1≤𝑖≤𝑘−1 are the centers found so far, until it reaches the closest landmark ℓ𝑘 to it, at distance 𝑅𝑘=𝐷[𝑤𝑘,ℓ𝑘](𝑡𝑘) from 𝑤𝑘. Landmark ℓ𝑘 offers an alternative od-path 𝑆𝑂𝐿𝑘=𝑃𝑜,𝑤1∙⋯∙𝑃𝑤𝑘−1,𝑤𝑘∙𝑄𝑘∙𝛱𝑘 by a new application of 𝙵𝙲𝙰, where 𝑃𝑤𝑖,𝑤𝑖+1∈𝑆𝑃[𝑤𝑖,𝑤𝑖+1](𝑡𝑖), 𝑄𝑘∈𝑆𝑃[𝑤𝑘,ℓ𝑘](𝑡𝑘), and 𝛱𝑘∈𝐴𝑆𝑃[ℓ𝑘,𝑑;𝜀](𝑡𝑘+𝑅𝑘) is the approximate suffix subpath provided by the oracle. Observe that 𝑆𝑂𝐿𝑘 uses a longer (optimal, if all centers lie on the unknown shortest path) prefix-subpath 𝑃𝑜,𝑤1∙⋯∙𝑃𝑤𝑘−1,𝑤𝑘 which is then completed with a shorter approximate suffix-subpath 𝑄𝑘∙𝛱𝑘.

It is proved in [17], and is also analytically explained (for the sake of completeness) in “Appendix B”, that the expected time complexity of 𝚁𝚀𝙰 is (𝜌−𝑟−1⋅polylog(𝑛)).

It is also proved that the minimum-travel-time over all approximate od-paths discovered by 𝚁𝚀𝙰 is a (1+𝜎)−approximation of 𝐷[𝑜,𝑑](𝑡𝑜), for a constant 𝜎=𝜎(𝑟)>𝜀.

New Variants
In [17] there was no scaling of the instance, other than the assumption that the minimum travel-time ever observed is at least 1. In this work, we need to connect the travel-time metric with the Dijkstra-rank metric more tightly. Therefore, we scale the instance so that 𝑇=𝑛𝛼, for a properly chosen scaling factor 𝛼≈1𝜈𝜆 that also affects Property 4. Of course, we can no longer take for granted that the minimum travel-time ever seen in the network is at least 1. But we have also shown (cf. Lemma 2) that the number of destinations at travel-time at most 1 around any origin is (𝑓(𝑛)). Therefore, we consider a variant of 𝙱𝙸𝚂, which we call 𝙱𝙸𝚂+, that simply ignores all destinations at free-flow distance smaller than 1 from the origin vertex. The following lemma clarifies this under the lens of our TD-instance.

Lemma 4
For a TD-instance with scaled travel-times metric so that 𝑇=𝑛𝛼, which also abides with Properties 1,  2 and 4, the one-to-many travel-time approximation algorithm 𝙱𝙸𝚂+ requires (𝐾∗⋅log(1/𝜀)𝜀⋅log2(𝑛)) calls of 𝚃𝙳𝙳(𝑜,⋆,𝑡𝑜) to provide summaries of minimum-travel-time functions from a given origin 𝑜∈𝑉 towards all destinations at free-flow travel-time distance 𝐷⎯⎯⎯[𝑜,𝑑]>1 from o.

Proof
(Lemma 4) The crucial observation, which is a direct consequence of Lemma 1, is the following:

𝐷max[𝑜,𝑑]−𝐷min[𝑜,𝑑]≤𝑇=𝑛𝛼⇒𝐷max[𝑜,𝑑]𝐷min[𝑜,𝑑]≤1+𝑛𝛼𝐷min[𝑜,𝑑]<1+𝑛𝛼,
exploiting the fact that 𝙱𝙸𝚂+ only accounts for od-pairs with 𝐷min[𝑜,𝑑]≥𝐷⎯⎯⎯[𝑜,𝑑]>1. Adapting the analysis of [17, Theorem 1], we conclude that 𝙱𝙸𝚂+ requires (𝐾∗⋅log(1/𝜀)𝜀⋅log2(𝑛)) calls of 𝚃𝙳𝙳(𝑜,⋆,𝑡𝑜) for computing (1+𝜀)-approximate travel-time functions which lie at distance more than 1 from any given origin 𝑜∈𝑉. ◻

Since 𝙱𝙸𝚂+ excludes from the preprocessing of landmarks all the (free-flow) radius-1 balls around each landmark, we have to extend both 𝙵𝙲𝙰 and 𝚁𝚀𝙰 so that each time a new landmark is settled, this excluded ball around it is explored “on-the-fly” during the query phase. We call these extensions 𝙵𝙲𝙰+ and 𝚁𝚀𝙰+, respectively. Because all these balls are only of size (𝑓(𝑛))⊂o(𝑛) (cf. Lemma 2), this extension does not severely affect the overall performances of the query algorithms.

The next theorem is a consequence of the analysis presented in [17], and summarizes the performances of the previously described (new) variants of the oracles presented in that work. To avoid unnecessary repetition, we detail in its proof only the extension steps required to the proofs of the results in [17].

Theorem 1
Assume that a TD-instance with 𝑚∈(𝑛) and compliant with Properties 1, 2 and 4, is preprocessed using 𝙱𝙸𝚂+ for constructing travel-time summaries from 𝜌𝑛 𝐢𝐮𝐚𝐫 chosen landmarks, where 1𝜌∈𝛺(𝑓(𝑛)). Moreover, each query is served by the query algorithm 𝚁𝚀𝙰+ with recursion depth 𝑟∈ℕ (for 𝑟=0 we get 𝙵𝙲𝙰+). Then, the expected preprocessing space 𝑆𝙱𝙸𝚂+ and time 𝑃𝙱𝙸𝚂+ for 𝙱𝙸𝚂+, and the expected query time 𝑄𝚁𝚀𝙰+ for 𝚁𝚀𝙰+, are:

𝔼{𝑆𝙱𝙸𝚂+}𝔼{𝑃𝙱𝙸𝚂+}𝔼{𝑄𝚁𝚀𝙰+}∈(𝐾∗𝜌𝑛2log2(𝑛))∈(𝐾∗𝜌𝑛2log3(𝑛))∈(1𝜌)𝑟+1+o(1)
As for the approximation guarantees, the following hold: For 𝑟=0, 𝚁𝚀𝙰+ (i.e., 𝙵𝙲𝙰+) returns either an exact od-path, or an approximate od-path via the landmark ℓ𝑜 closest to o, such that 𝐷[𝑜,𝑑](𝑡𝑜)≤𝑅𝑜+𝛥⎯⎯⎯⎯[ℓ𝑜,𝑑](𝑡𝑜+𝑅𝑜)≤(1+𝜀)⋅𝐷[𝑜,𝑑](𝑡𝑜)+𝜓⋅𝑅𝑜≤(1+𝜀+𝜓)⋅𝐷[𝑜,𝑑](𝑡𝑜), where 𝑅𝑜=𝐷[𝑜,ℓ𝑜](𝑡𝑜) is the minimum-travel-time to ℓ𝑜, and 𝜓=1+𝛬max(1+𝜀)(1+2𝜁+𝛬max𝜁)+(1+𝜀)𝜁 is a cost-metric dependent constant. When 𝑟≥1, 𝚁𝚀𝙰+ returns an od-path that guarantees stretch 1+𝜎, where 𝜎=𝜎(𝑟)≤𝜀⋅(1+𝜀/𝜓)𝑟+1(1+𝜀/𝜓)𝑟+1−1.

Proof
(Theorem 1) From the analysis in [17, Theorem 2] we know that for each of the 𝜌𝑛 landmarks we conduct (𝐾∗⋅log(1/𝜀)⋅log2(𝑛)𝜀) TDSP probes, each requiring (𝑛log(𝑛)+𝑚loglog(𝐾max))=(𝑛log(𝑛)) additional time and (𝑛) additional space. Compared to the analysis in [17], the extra polylogarithmic factor in the number of TDSP probes is due to the fact that the period T and the travel-time ratio 𝐷⎯⎯⎯⎯⎯ / 𝐷⎯⎯⎯ can no longer be assumed to be independent of the network size, but they are both upper-bounded by 𝑛𝛼, as it has already been explained.

The stretch factors of 𝙵𝙲𝙰+ and 𝚁𝚀𝙰+ follow from the proofs of [17, Theorems 3 and 5]. As for the query times, the size of each ball that we grow is ((1/𝜌)⋅log(𝑛)) with high probability, and each ball stops at the very first (new) landmark that will be settled in it. At this time, we have to also grow a radius-1 ball from that landmark, of size at most f(n). Therefore, exploiting a union bound on all the grown balls (as shown in “Appendix B”), the expected cost per ball is (with high probability) at most

((log(𝑛)/𝜌)[log(log(𝑛)/𝜌)+loglog(𝐾max)]+𝑓(𝑛)[log(𝑓(𝑛))+loglog(𝐾max)])⊆((1/𝜌)1+o(1)),
for 1/𝜌∈𝛺(𝑓(𝑛)). Now, the claimed query times are obtained by following the proofs of [17, Theorems 4 and 6]. ◻

When 𝐾∗∈o(𝑛) the TD-oracles of [17], as well as their extensions presented in this section, achieve both sublinear query times and subquadratic preprocessing requirements.

The 𝚃𝚁𝙰𝙿 Approximation Method
We now introduce the 𝚃𝚁𝙰𝙿 approximation method, a novel algorithm for computing one-to-many upper-approximations of the unknown min-travel-time functions from a given vertex ℓ towards all sufficiently distant destinations from it. Typically ℓ is perceived as a critical node in the network, a landmark. In particular, for a given landmark ℓ, a positive scalar 𝜀>0 and a positive integer 𝐹∈ℤ>0, the goal is to provide, (1+𝜀)-upper-approximating functions 𝛥⎯⎯⎯⎯[ℓ,𝑣] of the actual min-travel-time functions 𝐷[ℓ,𝑣] for all reachable destinations from ℓ, except for a small subset of F “nearby” destinations for which the achieved approximation is not required to reach the required guarantee.Footnote6

Fig. 2
figure 2
The upper- and lower-approximating functions 𝛿⎯⎯⎯𝑘[ℓ,𝑣] (thick orange, upper pwl) and 𝛿⎯⎯𝑘[ℓ,𝑣] (thick green, lower pwl) for the unknown min-travel-time function 𝐷[ℓ,𝑣] (blue pwl), within the interval 𝐼𝑘=[𝑡𝑠=(𝑘−1)𝜏,𝑡𝑓=𝑘𝜏) (Color figure online)

Full size image
𝚃𝚁𝙰𝙿 is a remarkably simple algorithm, which in a nutshell works as follows (cf. the pseudocode of the algorithm in Fig. 3). In step 1, for each destination v we determine the maximum time-interval for the consecutive departure-time samples, that would suffice in order to get a (1+𝜀)-approximation of 𝐷[ℓ,𝑣]. Consequently (steps 2-4) we determine the value of 𝜏∗, so that the required approximation guarantee is achieved for all the 𝑛−𝐹 “faraway” destinations from ℓ. Then, in steps 5-16, the interval [0, T) is split into a number of ⌈𝑇𝜏∗⌉ consecutive length-𝜏∗ subintervals. We proceed with the sampling of travel-times to all “faraway” destinations, for all the selected sampled departure times. We also determine the zenith-point (𝑡⎯⎯𝑚,𝐷⎯⎯⎯⎯⎯𝑚) and the nadir-point (𝑡⎯𝑚,𝐷⎯⎯⎯𝑚) in our upper- and lower-approximating functions per subinterval (cf. Fig. 2). Finally, we do the same calculations of the zenith-point and the nadir-point also w.r.t. the last sample point, for the last subinterval of the [0, T); cf. steps 17-21 in 𝚃𝚁𝙰𝙿’s pseudocode.

The tuning parameter 𝜏∗, a function of F and 𝜀, will be fixed later in such a way that (i) the required approximation guarantee for the upper-approximating travel-time functions is achieved, for all 𝑛−𝐹 “faraway” destinations from each landmark ℓ; and (ii) the number 𝑇𝜏∗ of sampled departure-times from the landmarks are not more than needed, since this would lead to an increase in the required preprocessing time and space. Then, for each subinterval [𝑡𝑠,𝑡𝑓=𝑡𝑠+𝜏∗)⊆[0,𝑇), a (1+𝜀)-upper-approximation of the projection 𝐷[ℓ,𝑣]:[𝑡𝑠,𝑡𝑓)↦ℝ>0 is constructed. The concatenation of all these (1+𝜀)-upper-approximations per subinterval constitutes the requested (1+𝜀)-upper-approximation 𝛥⎯⎯⎯⎯[ℓ,𝑣] of 𝐷[ℓ,𝑣]:[0,𝑇)↦ℝ>0. Figure 2 provides a visualization of 𝚃𝚁𝙰𝙿’s rationale: the unknown (blue) function is “trapped” between an upper- (orange) and a lower- (green) approximating function.

Note that, contrary to the 𝙱𝙸𝚂 approximation method [17], no assumption is made on the shapes of the travel-time functions to approximate within each subinterval; in particular, no assumption is made on them being concave, as was the case for 𝙱𝙸𝚂. 𝚃𝚁𝙰𝙿 only exploits the fact that 𝜏∗ can be chosen to be sufficiently small so as to guarantee the required approximation for all “faraway” destinations, along with Property 1 on the boundedness of travel-time slopes.

Fig. 3
figure 3
The pseudocode for the 𝚃𝚁𝙰𝙿 approximation algorithm. Each (continuous, pwl) upper-approximating function 𝛥[ℓ,𝑣] is stored, and eventually returned, as a sequence of breakpoints, i.e., a list of pairs of sampled departure times from ℓ and the corresponding min-travel-time values

Full size image
The pseudocode of 𝚃𝚁𝙰𝙿, provided in Fig. 3, is discussed and analyzed in the rest of this section. We start by describing the upper-approximating (𝛿⎯⎯⎯𝑘[ℓ,𝑣]) and lower-approximating (𝛿⎯⎯𝑘[ℓ,𝑣]) functions of 𝐷[ℓ,𝑣] that we consider within the subinterval 𝐼𝑘=[𝑡𝑠=(𝑘−1)𝜏∗,𝑡𝑓=𝑘𝜏∗)⊂[0,𝑇), 𝑘∈[⌊𝑇𝜏⌋], or for 𝐼⌊𝑇/𝜏∗⌋+1=[𝑡𝑠=⌊𝑇/𝜏∗⌋⋅𝜏∗,𝑡𝑓=𝑇) (cf. Fig. 2): ∀𝑘∈⌈𝑇/𝜏∗⌉, ∀𝑡∈𝐼𝑘,

𝛿⎯⎯⎯𝑘[ℓ,𝑣](𝑡):=min{𝐷[ℓ,𝑣](𝑡𝑓)+𝛬min𝑡𝑓−𝛬min𝑡 , 𝐷[ℓ,𝑣](𝑡𝑠)−𝛬max𝑡𝑠+𝛬max𝑡 }
(1)
𝛿⎯⎯𝑘[ℓ,𝑣](𝑡):=max{𝐷[ℓ,𝑣](𝑡𝑓)−𝛬max𝑡𝑓+𝛬max𝑡 , 𝐷[ℓ,𝑣](𝑡𝑠)+𝛬min𝑡𝑠−𝛬min𝑡}
(2)
The following lemma demonstrates that indeed these are upper- and lower- approximations of 𝐷[ℓ,𝑣] within 𝐼𝑘.

Lemma 5
For all 𝑘∈[⌈𝑇𝜏∗⌉] and 𝑡∈𝐼𝑘, it holds that 𝛿⎯⎯⎯𝑘[ℓ,𝑣](𝑡)≥𝐷[ℓ,𝑣](𝑡)≥𝛿⎯⎯𝑘[ℓ,𝑣](𝑡).

Proof
(Lemma 5) By Property 1, for any departure-time 𝑡∈𝐼𝑘 from ℓ and any destination vertex 𝑣∈𝑉, the following inequalities hold:


Combining the two inequalities we get the following bounding functions for 𝐷[ℓ,𝑣] within 𝐼𝑘: ∀𝑣∈𝑉,∀𝑡∈𝐼𝑘:

𝐷[ℓ,𝑣](𝑡)≥𝐷[ℓ,𝑣](𝑡)≤max{−𝛬min𝑡+𝛬min𝑡𝑠+𝐷[ℓ,𝑣](𝑡𝑠) , 𝛬max𝑡−𝛬max𝑡𝑓+𝐷[ℓ,𝑣](𝑡𝑓)}=𝛿⎯⎯𝑘[ℓ,𝑣](𝑡)min{𝛬max𝑡−𝛬max𝑡𝑠+𝐷[ℓ,𝑣](𝑡𝑠) , −𝛬min𝑡+𝛬min𝑡𝑓+𝐷[ℓ,𝑣](𝑡𝑓)}=𝛿⎯⎯⎯𝑘[ℓ,𝑣](𝑡)
◻

Let (𝑡⎯𝑚[ℓ,𝑣](𝑘),𝐷⎯⎯⎯𝑚[ℓ,𝑣](𝑘)) and (𝑡⎯⎯𝑚[ℓ,𝑣](𝑘),𝐷⎯⎯⎯⎯⎯𝑚[ℓ,𝑣](𝑘)) be the intersections of the legs in the definitions of 𝛿⎯⎯𝑘[ℓ,𝑣] and 𝛿⎯⎯⎯𝑘[ℓ,𝑣], respectively (see Fig. 2). The three breakpoints determining the (continuous, pwl) function 𝛿⎯⎯⎯𝑘[ℓ,𝑣], which are computed and stored by 𝚃𝚁𝙰𝙿 in steps 8–21, are the following:

⟨ (𝑡𝑘−1,𝐷[ℓ,𝑣](𝑡𝑘−1)) , (𝑡⎯⎯𝑚[ℓ,𝑣](𝑘),𝐷⎯⎯⎯⎯⎯𝑚[ℓ,𝑣](𝑘)) , (𝑡𝑘,𝐷[ℓ,𝑣](𝑡𝑘)) ⟩
The lower-approximating function 𝛿⎯⎯𝑘[ℓ,𝑣] is only used for our analysis, and is not actually stored by 𝚃𝚁𝙰𝙿. Since 𝐷[ℓ,𝑣] lies between these two approximations within the interval 𝐼𝑘, the maximum additive error 𝑀𝐴𝐸[ℓ,𝑣](𝐼𝑘) for 𝛿⎯⎯⎯𝑘[ℓ,𝑣] in 𝐼𝑘 (i.e., the length of the purple dashed line in Fig. 2) is defined as follows:

𝑀𝐴𝐸[ℓ,𝑣](𝐼𝑘):===≤max𝑡∈𝐼𝑘{𝛿⎯⎯⎯𝑘[ℓ,𝑣](𝑡)−𝛿⎯⎯𝑘[ℓ,𝑣](𝑡)}𝛿⎯⎯⎯𝑘[ℓ,𝑣](𝑡⎯𝑚[ℓ,𝑣](𝑘))−𝐷⎯⎯⎯𝑚[ℓ,𝑣](𝑘)𝐷⎯⎯⎯⎯⎯𝑚[ℓ,𝑣](𝑘)−𝛿⎯⎯[ℓ,𝑣](𝑡⎯⎯𝑚[ℓ,𝑣](𝑘))𝐷⎯⎯⎯⎯⎯𝑚[ℓ,𝑣](𝑘)−𝐷⎯⎯⎯𝑚[ℓ,𝑣](𝑘)
(3)
The following lemma proves that, for 𝜏∗ sufficiently small, 𝑀𝐴𝐸[ℓ,𝑣](𝐼𝑘) cannot be large. In particular, it provides a sufficient condition for the value of 𝜏∗ so that 𝛿⎯⎯⎯𝑘[ℓ,𝑣] is indeed a (1+𝜀)-upper-approximation of 𝐷[ℓ,𝑣] within 𝐼𝑘.

Lemma 6
For all (ℓ,𝑣)∈𝐿×𝑉 and 𝑘∈[⌈𝑇𝜏∗⌉], the following hold:

(i)
𝑀𝐴𝐸[ℓ,𝑣](𝐼𝑘)≤𝛬max⋅𝜏∗;

(ii)
𝛿⎯⎯⎯𝑘[ℓ,𝑣] is a (1+𝜀)-upper-approximation of 𝐷[ℓ,𝑣] within 𝐼𝑘, if

𝐷⎯⎯⎯[ℓ,𝑣]≥(𝛬min𝛬min+𝛬max+1𝜀)⋅𝛬max⋅𝜏∗
Proof
(Lemma 6) In order to simplify notation within the proof, we drop the dependence of 𝑡⎯𝑚, 𝑡⎯⎯𝑚, 𝐷⎯⎯⎯𝑚 and 𝐷⎯⎯⎯⎯⎯𝑚 from ℓ, v and k. Since (𝑡⎯𝑚,𝐷⎯⎯⎯𝑚) is the intersection of two lines, it is easy to show that:

𝑡⎯𝑚=𝐷[ℓ,𝑣](𝑡𝑠)−𝐷[ℓ,𝑣](𝑡𝑓)𝛬min+𝛬max+𝛬min𝑡𝑠+𝛬max𝑡𝑓𝛬min+𝛬max
(4)
𝐷⎯⎯⎯𝑚=𝛬max𝐷[ℓ,𝑣](𝑡𝑠)+𝛬min𝐷[ℓ,𝑣](𝑡𝑓)𝛬min+𝛬max−𝛬min⋅𝛬max𝛬min+𝛬max⋅(𝑡𝑓−𝑡𝑠)
(5)
Analogously, (𝑡⎯⎯𝑚,𝐷⎯⎯⎯⎯⎯𝑚) is also the intersection of two lines. Therefore:

𝑡⎯⎯𝑚=𝐷[ℓ,𝑣](𝑡𝑓)−𝐷[ℓ,𝑣](𝑡𝑠)𝛬min+𝛬max+𝛬min𝑡𝑓+𝛬max𝑡𝑠𝛬min+𝛬max
(6)
𝐷⎯⎯⎯⎯⎯𝑚=𝛬max𝐷[ℓ,𝑣](𝑡𝑓)+𝛬min𝐷[ℓ,𝑣](𝑡𝑠)𝛬min+𝛬max+𝛬min𝛬max𝛬min+𝛬max(𝑡𝑓−𝑡𝑠)
(7)
(i)
We start with the upper bound on the maximum absolute error:

𝑀𝐴𝐸[ℓ,𝑣](𝐼𝑘)≤𝐷⎯⎯⎯⎯⎯𝑚−𝐷⎯⎯⎯𝑚=𝛬max𝐷[ℓ,𝑣](𝑡𝑓)+𝛬min𝐷[ℓ,𝑣](𝑡𝑠)𝛬min+𝛬max+𝛬min𝛬max𝛬min+𝛬max(𝑡𝑓−𝑡𝑠)−𝛬max𝐷[ℓ,𝑣](𝑡𝑠)+𝛬min𝐷[ℓ,𝑣](𝑡𝑓)𝛬min+𝛬max+𝛬min𝛬max𝛬min+𝛬max(𝑡𝑓−𝑡𝑠)=(𝛬max−𝛬min)[𝐷[ℓ,𝑣](𝑡𝑓)−𝐷[ℓ,𝑣](𝑡𝑠)]+2𝛬min𝛬𝑚𝑎𝑥(𝑡𝑓−𝑡𝑠)𝛬min+𝛬max=(𝛬max−𝛬min)[𝐷[ℓ,𝑣](𝑡𝑓)−𝐷[ℓ,𝑣](𝑡𝑠)]𝑡𝑓−𝑡𝑠+2𝛬min𝛬𝑚𝑎𝑥𝛬min+𝛬max(𝑡𝑓−𝑡𝑠)≤/∗Property 1∗/(𝛬max−𝛬min)𝛬max+2𝛬min𝛬𝑚𝑎𝑥𝛬min+𝛬max(𝑡𝑓−𝑡𝑠)=𝛬max𝜏∗
(ii)
From the definition of MAE (see Eq. 3) we have that ∀𝑡∈𝐼𝑘,

𝛿⎯⎯⎯𝑘[ℓ,𝑣](𝑡)≤≤≤𝛿⎯⎯𝑘[ℓ,𝑣](𝑡)+𝑀𝐴𝐸[ℓ,𝑣](𝐼𝑘)𝛿⎯⎯𝑘[ℓ,𝑣](𝑡)+𝛬max𝜏∗=𝛿⎯⎯𝑘[ℓ,𝑣](𝑡)⋅(1+𝛬max𝜏∗𝛿⎯⎯𝑘[ℓ,𝑣](𝑡))𝐷[ℓ,𝑣](𝑡)⋅(1+𝛬max𝜏∗𝛿⎯⎯𝑘[ℓ,𝑣](𝑡))
In order to deduce a (1+𝜀)-approximation, the following condition is sufficient:


A weaker sufficient condition is when we assure this last inequality for the minimum value 𝐷⎯⎯⎯𝑚[ℓ,𝑣](𝑡𝑠,𝑡𝑓) (actually, for its equivalent given in eq. (5)) of 𝛿⎯⎯𝑘[ℓ,𝑣](𝑡) within the entire length-𝜏∗ subinterval 𝐼𝑘:

𝛬max𝜏∗𝜀≤𝛬max𝐷[ℓ,𝑣](𝑡𝑠)+𝛬min𝐷[ℓ,𝑣](𝑡𝑓)𝛬min+𝛬max−𝛬min⋅𝛬max𝛬min+𝛬max⋅𝜏∗
We make this sufficient condition even weaker by substituting all travel-times 𝐷⎯⎯⎯[ℓ,𝑣] from ℓ to v with the minimum possible (i.e., the free-flow) value:


◻

It is noted that the sufficient condition (ii) in Lemma 6 is independent of the actual departure time 𝑡∈𝐼𝑘, and only depends on the free-flow travel-time 𝐷⎯⎯⎯[ℓ,𝑣], the length 𝜏∗ that we choose for the subintervals, the targeted approximation guarantee, and parameters of the travel-time metric.

Having this sufficient condition at hand, it is now straightforward to determine the appropriate value of 𝜏∗ so that a good approximation is guaranteed for all but the F closest (under the free-flow metric) destinations from ℓ. This is exactly what 𝚃𝚁𝙰𝙿 does (cf. steps 1–4 in Fig. 3): First, for each destination vertex v, the appropriate (candidate) value 𝜏[ℓ,𝑣] for 𝜏∗ is determined, so that v gets also a good approximation. The vertices are then ordered according to these candidate values, and 𝜏∗ is set to the F-th smallest value in this order. The set 𝑉[ℓ](𝜏∗)={𝑣∈𝑉:𝜏[ℓ,𝑣]>𝜏∗} contains 𝑛−𝐹 “faraway” destinations for which we must get a good approximation within 𝐼𝑘. Unfortunately, an analogous approximation guarantee does not necessarily hold for the F “nearby” vertices from ℓ, therefore these destinations are simply ignored by 𝚃𝚁𝙰𝙿.

The next theorem states that 𝚃𝚁𝙰𝙿 provides a (1+𝜀)-upper-approximation 𝛥⎯⎯⎯⎯[ℓ,𝑣] for the entire period, and all the faraway destinations v from ℓ. It also estimates the requirements of 𝚃𝚁𝙰𝙿 in space, in terms of the number of breakpoints to store per travel-time summary, and running time, in terms of 𝚃𝙳𝙳 calls for computing the sampled departure-times from ℓ.

Theorem 2
For a given landmark ℓ∈𝑉, 𝜀>0 and integer 𝐹>𝑓(𝑛), let 𝜏[ℓ,𝑣], 𝜏∗ and 𝑉[ℓ](𝜏∗) be defined as follows:

𝜏[ℓ,𝑣]𝜏∗𝑉[ℓ](𝜏∗):=𝐷⎯⎯⎯[ℓ,𝑣](1𝜀+𝛬min𝛬min+𝛬max)𝛬max, ∀𝑣∈𝑉:= the 𝐹− th  smallest 𝜏[ℓ,𝑣]− value .:={𝑣∈𝑉:𝜏[ℓ,𝑣]>𝜏∗}
For each 𝑣∈𝑉[ℓ](𝜏∗), let 𝛥⎯⎯⎯⎯[ℓ,𝑣] be the concatenation of all upper-approximating functions 𝛿⎯⎯⎯𝑘[ℓ,𝑣] that 𝚃𝚁𝙰𝙿 returns per subinterval 𝐼𝑘=[ 𝑡𝑠𝑘=(𝑘−1)𝜏∗ , 𝑡𝑓𝑘=min{𝑘𝜏∗,𝑇} ):𝑘∈[⌈𝑇𝜏∗⌉]. Then the following hold, for all 𝑣∈𝑉[ℓ](𝜏∗):

(i)
𝛥⎯⎯⎯⎯[ℓ,𝑣] is a (1+𝜀)-upper-approximation of 𝐷[ℓ,𝑣] in [0, T).

(ii)
The number of calls to 𝚃𝙳𝙳(ℓ,⋆,𝑡) for the construction of travel-time summaries for all 𝑣∈𝑉[ℓ](𝜏) is ⌈𝑇𝜏∗⌉∈(𝑛𝛼𝜀).

(iii)
The overall space for succinctly representing the summaries from ℓ to all the faraway destinations 𝑣∈𝑉[ℓ](𝜏) is at most 2⌈𝑇𝜏∗⌉⋅(𝑛−𝐹)∈(𝑛1+𝛼𝜀) breakpoints.

Proof
(Theorem 2) Recall first that for each 𝑣∈𝑉[ℓ](𝜏∗) it holds that 𝐷⎯⎯⎯[ℓ,𝑣]>1, because of our choice of 𝐹>𝑓(𝑛) (cf. Lemma 2).

Regarding statement (i) note that, by definition, the following holds for all 𝑣∈𝑉[ℓ](𝜏): 𝜏[ℓ,𝑣]≥𝜏∗⇒𝐷⎯⎯⎯[ℓ,𝑣]≥(1𝜀+𝛬min𝛬min+𝛬max)⋅𝛬max⋅𝜏∗. Therefore, by Lemma 6, the produced upper-approximation within each subinterval 𝐼𝑘 is a (1+𝜀)-upper-approximation of 𝐷[ℓ,𝑣]. The concatenation of all these functions constitutes 𝛥⎯⎯⎯⎯[ℓ,𝑣], which is then also an (1+𝜀)-upper-approximation of 𝐷[ℓ,𝑣] within [0, T).

We proceed now with statements (ii) and (iii). 𝚃𝚁𝙰𝙿 preprocesses concurrently all the summaries from ℓ to each 𝑣∈𝑉[ℓ](𝜏∗), by making ⌈𝑇𝜏∗⌉≤1+𝑇⋅𝛬max⋅(1𝜀+𝛬min𝛬min+𝛬max)∈(𝑛𝛼𝜀) calls to 𝚃𝙳𝙳(ℓ,⋆,𝑡). This is because we sample endpoints of consecutive subintervals of length 𝜏∗≥1(1𝜀+𝛬min𝛬min+𝛬max)𝛬max, since we only care about destinations v at free-flow distance from ℓ that is 𝐷⎯⎯⎯[ℓ,𝑣]>1.

As for the succinct representation of all these summaries, 𝚃𝚁𝙰𝙿 needs at most 2⌈𝑇𝜏∗⌉(𝑛−𝐹)∈(𝑇⋅𝑛⋅𝛬max𝜀⋅(1+𝜀𝛬min𝛬min+𝛬max))⊆(𝑛1+𝛼𝜀) breakpoints, because there is at most one intermediate breakpoint (𝑡⎯⎯𝑚,𝐷⎯⎯⎯⎯⎯𝑚) per subinterval (cf. Fig. 2), and there exist 𝑛−𝐹 “faraway” destinations in 𝑉[ℓ](𝜏∗). ◻

Overview of Our Results
Recall from Sect. 4 that the performance of TD-oracles in [17] depends on 𝐾∗ (the degree of disconcavity of the input TD-instance). Achieving both subquadratic preprocessing requirements and sublinear query time is only possible when 𝐾∗∈o(𝑛). Unfortunately, experimental evidence [15] demonstrated that it may be the case that 𝐾∗∈𝛺(𝑛). In this work, we devise and analyze novel oracles, whose performance is independent of 𝐾∗, without compromising the subquadratic preprocessing requirements and the sublinearity in the query performance. Moreover, we provide a novel hierarchical oracle, which achieves query performance that is essentially sublinear in the Dijkstra-rank of the query at hand, rather than the network size. Before digging into the details of our new TD-oracles, we provide in this section a more detailed overview of our results, to serve as a roadmap in what follows.

The preprocssing phase of all oracles starts with a random landmark set 𝐿⊂𝐢𝐮𝐚𝐫(𝜌)𝑉, i.e., we decide independently and uniformly at random whether each vertex is a landmark, with probability 𝜌=𝑛−𝜔 for a constant 𝜔∈(0,1). Clearly, the expected number of landmarks is 𝔼{|𝐿|}=𝜌𝑛=𝑛1−𝜔.

We consider as “nearby” vertices of ℓ∈𝐿, all the vertices at free-flow distance at most 𝑅⎯⎯⎯=𝑇𝜃 from it, for a constant 𝜃∈(0,1) to be determined later.

Let 𝐹=maxℓ∈𝐿{|𝐵⎯⎯⎯[ℓ;radius=𝑅⎯⎯⎯]|} be the maximum number of “nearby” destinations from any landmark ℓ. The remaining (at most 𝑛−𝐹) vertices are perceived as “faraway” destinations from ℓ.

The next lemma shows that the main parameters we should consider w.r.t. a TD-instance are 𝜆 (cf. Property 4) and 𝛼∈(0,1) such that 𝑇=𝑛𝛼. All the other parameters essentially adjust their values to them.

Lemma 7
Let 𝜈∈(0,1) and 𝜃∈(0,𝜈) such that 𝑇=𝑛𝛼=𝑑𝑖𝑎𝑚(𝐺,𝐷⎯⎯⎯)1/𝜈, 𝑅⎯⎯⎯=𝑇𝜃=𝑛𝛼𝜃, and 𝜈𝜃∈(1). Assume also that 𝜆,𝑓(𝑛) are compliant with Property 4.

Then, the following hold:

(i)
𝛼𝜆𝜈∈1−o(1).

(ii)
𝐹∈𝑛[1±o(1)]𝜃/𝜈.

Proof
(Lemma 7) Property (i) trivially holds, as a consequence of Lemma 3. As for property (ii), this is also an implication of Property 4 and Lemma 3. In particular, for the upper bound on F we have:

𝐹=≤/∗Property 4∗/≤/∗Lemma 3∗/∈⊆maxℓ∈𝐿{|𝐵⎯⎯⎯[ℓ;radius=𝑅⎯⎯⎯]|}𝑓(𝑛)⋅𝑅⎯⎯⎯𝜆=𝑛log(𝑓(𝑛))log(𝑛)⋅𝑛𝛼𝜃𝜆𝑛log(𝑓(𝑛))log(𝑛)+𝜃𝜈𝑛𝜃𝜈⋅(1+𝜈𝜃log(𝑓(𝑛))log(𝑛))𝑛𝜃𝜈⋅[1+o(1)]
The last step is because we consider instances with 𝑓(𝑛)∈o(𝑛), and moreover due to the fact that we set our (yet unspecified) tuning parameter 𝜃 so that 𝜈𝜃∈o(log(𝑛)log(𝑓(𝑛))).

As for the lower bound on F, we exploit the fact that 𝑅⎯⎯⎯ is the radius of at least one size-F free-flow ball around a landmark. Thus, by Property 4 and Lemma 3 we have:

𝐹≥𝑅⎯⎯⎯𝜆≥𝑛𝛼𝜃𝜆=𝑛𝜃𝜈⋅𝛼𝜆𝜈≥𝑛𝜃𝜈⋅(1−log(𝑓(𝑛))log(𝑛))∈𝑛𝜃𝜈⋅[1−o(1)]
◻

The complexity bounds of our TD-oracles, as well as the trade-offs between preprocessing requirements and query performance that will be presented in the rest of the paper, are summarized in Table 2.

Table 2 Trade-offs of oracles for TD-instances, among the tuning parameters 𝛽 (for the preprocessing requirements), 𝛿 (for the query performance) and r (for the targeted approximation guarantee), as functions of the input parameters 𝜆∈(1) (determined in Property 4) and 𝛾>1 (determining the Dijsktra ranks per level of the 𝙷𝙾𝚁𝙽 oracle, cf. Sect. 8)
Full size table
Oracles with Fully-Informed Landmarks
In this section we describe two novel oracles, the 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 oracle and the 𝙵𝙻𝙰𝚃 oracle, with landmarks possessing summaries for all reachable destinations (fully-informed landmarks), excluding possibly a small neighborhood of destinations around them. Their preprocessing phase makes calls to 𝚃𝚁𝙰𝙿 and/or 𝙱𝙸𝚂+. Whenever called, 𝙱𝙸𝚂+ will handle the (at most F) “nearby” destinations from ℓ which are also at free-flow distance from ℓ at least 1. 𝚃𝚁𝙰𝙿 will take over the (at least 𝑛−𝐹) “faraway” destinations from ℓ.

The 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 Oracle
A first attempt towards avoiding the dependency of the preprocessing requirements on 𝐾∗, is to develop an oracle whose preprocessing phase is based solely on the one-to-many approximation algorithm 𝚃𝚁𝙰𝙿. We call this oracle 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈. We now present separately the preprocessing phase and the query algorithm of the oracle.

Preprocessing of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈: The entire period [0, T) is first split into subintervals of length

𝜏∗=𝑅⎯⎯⎯(1+𝜀𝛬min𝛬min+𝛬max)⋅𝛬max𝜀≥𝜀𝑅⎯⎯⎯(1+𝜀)𝛬max
each. Then, for each landmark ℓ∈𝐿 the approximation algorithm 𝚃𝚁𝙰𝙿 is executed, which constructs the (1+𝜀)-upper-approximation functions 𝛥[ℓ,𝑣], for all the “faraway” destinations 𝑣∈𝑉[ℓ](𝜏∗) from ℓ (cf. Theorem 2). These functions are succinctly stored as sequences of breakpoints, for future use.

Recursive Query Algorithm for 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈: The oracle uses a variant of the 𝚁𝚀𝙰 query algorithm, which we call 𝚁𝚀𝙰+. This algorithm proceeds exactly as 𝚁𝚀𝙰, the only difference being an explicit handling of each newly settled landmark. In particular, whenever a new landmark ℓ is settled, 𝚁𝚀𝙰+ computes (on-the-fly) also the time-dependent distances from ℓ to each of the “nearby” vertices (which were excluded from ℓ’s preprocessed data structure) by growing a small TDD-ball from it until all its “nearby” vertices are settled. The size of this 𝚃𝙳𝙳 ball is at most 𝐹polylog(𝐹) (cf. Property 3). Then 𝚁𝚀𝙰+ proceeds exactly as 𝚁𝚀𝙰.

The following theorem analyzes the performance of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈.

Theorem 3
The expected query time and the expected preprocessing space and time requirements of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 are: 𝔼{𝑄𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}∈𝑛𝜔𝑟+max{𝜔,𝜃𝜈}+o(1), 𝔼{𝑆𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}∈(𝑛2−𝜔+𝛼⋅(1−𝜃)), and 𝔼{𝑃𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}∈𝑛2−𝜔+𝛼⋅(1−𝜃)+o(1). The achieved approximation guarantee for the queries is the same as that of Theorem 1.

Proof
(Theorem 3) Starting with the approximation guarantee, since the query algorithm (𝚁𝚀𝙰+) is the same and is based on the same (either preprocessed, or discovered on-the-fly) landmark-to-vertex travel-times, it is clear that the approximation guarantee of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 is exactly the one described in Theorem 1.

We therefore focus on the preprocessing requirements and the query-time performance of the oracle.

By Theorem 2, during its preprocessing 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 makes at most ⌈𝑇𝜏∗⌉≤1+𝑇𝜏∗≤1+1+𝜀𝜀⋅𝛬max⋅𝑛𝛼(1−𝜃)∈(𝑛𝛼(1−𝜃)) calls to 𝚃𝙳𝙳(ℓ,⋆,𝑡), for departure-times 𝑡∈{0,𝜏∗,2𝜏∗,…,⌈𝑇𝜏∗⌉−1} and each landmark ℓ∈𝐿.

The preprocessing-time is dominated by the aggregate time for all these 𝚃𝙳𝙳 probes. Taking into account that each 𝚃𝙳𝙳 probe takes time (𝑚loglog(𝐾max)+𝑛log(𝑛))=(𝑛log(𝑛)) and that 𝔼{|𝐿|}=𝜌𝑛=𝑛1−𝜔, we get the following:

𝔼{𝑃𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}=⊆𝔼{|𝐿|}⋅⌈𝑇𝜏∗⌉⋅(𝑛log(𝑛))(𝑛1−𝜔+𝑎(1−𝜃)+1+loglog(𝑛)log(𝑛))⊆𝑛2−𝜔+𝛼⋅(1−𝜃)+o(1)
The calculations are analogous for the required preprocessing space. By Theorem 2, for all landmarks ℓ∈𝐿 and all their “faraway” destinations 𝑣∈𝑉[ℓ](𝜏∗), the total number of breakpoints to store is:

𝔼{𝑆𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}=∈𝔼{|𝐿|}⋅2⌈𝑇𝜏⌉⋅(𝑛−𝐹)𝑛1−𝜔⋅(𝑛𝛼(1−𝜃))⋅𝑛=(𝑛2−𝜔+𝛼⋅(1−𝜃))
As for the query-time complexity of 𝚁𝚀𝙰+, which is used by 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈, recall from Sect. 4 that the expected number of 𝚃𝙳𝙳 balls that it grows around ball centers is 1+(1/𝜌)𝑟. Additionally, 𝚁𝚀𝙰+ grows 1+(1/𝜌)𝑟 𝚃𝙳𝙳 balls from the corresponding closest landmarks.

A 𝚃𝙳𝙳 ball from a new center up to the closest landmark takes time

((1/𝜌)[loglog(𝐾max)+log(1/𝜌)])=(𝑛𝜔+loglog(𝑛)log(𝑛))
By Lemma 7, a 𝚃𝙳𝙳 ball from a landmark, until all F “nearby” destinations are settled, requires time

(𝐹polylog(𝐹)loglog(𝐾max))⊆𝑛[1+o(1)]𝜃𝜈
Thus, the expected query-time is upper-bounded as follows:

𝔼{𝑄𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}∈((1/𝜌)𝑟⋅[(1/𝜌)⋅(loglog(𝐾max)+log(1/𝜌))+𝐹polylog(𝐹)loglog(𝐾max)])=(𝑛𝜔𝑟⋅[𝑛𝜔+loglog(𝑛)log(𝑛)+𝑛[1+o(1)]𝜃/𝜈])⊆𝑛𝜔𝑟+max{𝜔,𝜃𝜈}+o(1)
◻

The next corollary is a parameter-tuning example showcasing the trade-offs among the sublinearity of query-time, the subquadratic preprocessing requirements and the achieved stretch of the chosen paths.

Corollary 1
Consider the execution of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 on a TD-instance with a recursion budget 𝑟∈{0,1,…,𝜆−1} and setup of parameters 𝜔=𝛿𝑟+1 and 𝜃=𝜔𝜈, where 𝜈∈1−o(1). Then, 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 achieves (sublinear) expected query time 𝑛𝛿+o(1) and (subquadratic) expected preprocessing requirements 𝑛2−𝛽+o(1) for all constants 1>𝛿>𝑟+1𝜆+𝜈≈𝑟+1𝜆+1 and 𝛽=𝛿𝑟+1⋅(1+1𝜆)−1𝜆>0.

Proof
(Corollary 1) By Lemma 7, we know that 𝛼𝜆𝜈∈1−o(1). Since 𝜈∈1−o(1) as well, it must also hold that 𝛼∈1±o(1)𝜆. Then, we get the following performances for 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈:

𝔼{𝑄𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}𝔼{𝑃𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈} , 𝔼{𝑆𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈}∈∈=𝑛𝜔𝑟+max{𝜔,𝜃/𝜈}+o(1)=𝑛𝜔(𝑟+1)+o(1)=𝑛𝛿+o(1)𝑛2−𝜔+𝛼(1−𝜃)+o(1)=𝑛2−𝜔+𝛼−𝛼𝜈𝜔+o(1)𝑛2−[𝜔(1+𝛼𝜈)−𝛼]+o(1)=𝑛2−[𝜔(1+𝜈𝜆)−1𝜆]+o(1)
To achieve the claimed subquadratic preprocessing requirement (i.e., 𝛽>0), we must ensure the following:

𝛽:=𝜔(1+1𝜆)−1𝜆=𝛿𝑟+1𝜆+1𝜆−1𝜆>0⇔𝛿𝑟+1𝜆+1𝜆>1𝜆⇔𝛿>𝑟+1𝜆+1
Along with the query-time sublinearity requirement (i.e., 1>𝛿), we conclude that it suffices to choose a recursion budget 0≤𝑟≤𝜆−1. ◻

Remark 1
Note that the query-time performance of 𝚁𝚀𝙰+ is analogous to that of 𝚁𝚀𝙰 (cf. [17]) for 𝜔=𝜃𝜈.

Table 3 provides a clear picture of the trade-off between query-sublinearity, preprocessing-subquadraticity and the achieved stretch factor. In particular, we assume a TD-instance with 𝜆=10, 𝛼=1𝜆, 𝜈=1−o(1), 𝛿∈(𝑟+1𝜆+1,1), 𝛽=𝛿𝑟+1⋅𝜆+𝜈𝜆−1𝜆≈𝛿𝑟+1⋅(1+1𝜆)−1𝜆, 𝜔=𝛿𝑟+1, and 𝜃=𝜔𝜈. The cells of the table (except for the last row) indicate the exponent of subquadraticity, 2−𝛽=1+(1+1𝜆)⋅(1−𝛿𝑟+1). The red values in the table correspond to pairs of 𝛿- and r-values which cannot guarantee subquadratic preprocessing requirements. The last row gives the worst-case approximation guarantee that the query algorithm achieves, for the corresponding values of the recursion budget r. The metric-dependent (but scaling-invariant) parameters, which also affect the stretch factor 1+𝜎, are set to the values 𝜁=2.043 and 𝛬max=0.225, as they were measured for the Berlin TD-instance (cf. Sect. 3.3). The preprocessing parameter concerning the summaries’ approximation guarantee is set to 𝜀=0.01.

Table 3 Trade-offs of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 among query-sublinearity (𝑛𝛿), preprocessing-subquadraticity (𝑛2−𝛽), and achieved worst-case approximation guarantee 1+𝜎(𝑟,𝜀,𝜓)
Full size table
The 𝙵𝙻𝙰𝚃 Oracle
Our second attempt, the 𝙵𝙻𝙰𝚃 oracle, provides preprocessed information for almost all reachable destinations (except for a few “too close” destinations) from each landmark. We consider again 𝚁𝚀𝙰+ as the query algorithm of 𝙵𝙻𝙰𝚃. That is, upon settling a new landmark ℓ, a quite small (in particular, of radius 1 under the free-flow metric) 𝚃𝙳𝙳 ball from ℓ must be grown, in order to cover an intentionally left “hole” in the preprocessed information w.r.t. ℓ.

The preprocessing phase of 𝙵𝙻𝙰𝚃 is based on a proper combination of 𝙱𝙸𝚂+ and 𝚃𝚁𝙰𝙿 for constructing travel-time summaries (cf. Fig. 4). Each landmark ℓ∈𝐿 possesses summaries for all reachable destinations 𝑣∈𝑉, except for the “too close” destinations (i.e., at free-flow distance at most 1 from ℓ). In particular, (i) travel-time summaries from ℓ towards the – at most 𝐹=maxℓ∈𝐿{|𝐵⎯⎯⎯[ℓ;radius=𝑅⎯⎯⎯]|} – “nearby” (but not “too close”) destinations 𝑣∈𝐵⎯⎯⎯[ℓ;radius=𝑅⎯⎯⎯] are precomputed using 𝙱𝙸𝚂+; (ii) travel-time summaries from ℓ towards the “faraway” destinations 𝑣∈𝑉∖𝐵⎯⎯⎯[ℓ;radius=𝑅⎯⎯⎯] are precomputed using 𝚃𝚁𝙰𝙿 by setting, again, 𝜏∗=𝑅⎯⎯⎯(1+𝜀𝛬min𝛬min+𝛬max)⋅𝛬max𝜀≥𝜀𝑅⎯⎯⎯(1+𝜀)𝛬max.

Fig. 4
figure 4
The preprocessing scheme of the 𝙵𝙻𝙰𝚃 oracle

Full size image
The preprocessing requirements for the summaries created by 𝚃𝚁𝙰𝙿 are exactly the same as in 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈. As for the summaries computed by 𝙱𝙸𝚂+, we tackle the linear dependence of the algorithm on 𝐾∗ by ensuring that F is sufficiently small and exploiting Property 3 which guarantees that the involved subgraph 𝐵⎯⎯⎯[ℓ;radius=𝑅∗] in the preprocessing phase of 𝙱𝙸𝚂+ on behalf of ℓ has size (𝐹polylog(𝐹)).

The next lemma shows that 𝙱𝙸𝚂+ is only affected by the concavity-spoiling breakpoints of arc-travel-time functions in the free-flow ball 𝐵⎯⎯⎯[ℓ;radius=𝑅∗], rather than the entire graph (cf. Lemma 3 for the notation).

Lemma 8
Fix any ℓ∈𝐿, the free-flow ball 𝐵=𝐵⎯⎯⎯[ℓ;radius=𝑅] from it, and the maximum full-congestion distance from ℓ within B, 𝑅∗=max𝑧∈𝐵{ 𝐷⎯⎯⎯⎯⎯[ℓ,𝑧] }.

Then, for any departure time 𝑡∈[0,𝑇) from ℓ, and any destination 𝑣∈𝐵, there is no intermediate vertex 𝑢∈𝑉∖𝐵⎯⎯⎯[ℓ;radius=𝑅∗] along the corresponding time-dependent shortest path from ℓ to v.

Proof
(Lemma 8) From the definitions of the involved Dijkstra balls under the free-flow and full-congestion metrics, and from Property 3, the following holds: ∀𝑡∈[0,𝑇), 𝐷[ℓ,𝑣](𝑡)≤𝐷⎯⎯⎯⎯⎯[ℓ,𝑣]≤𝑅∗<𝐷⎯⎯⎯[ℓ,𝑢]≤𝐷[ℓ,𝑢](𝑡). ◻

The following theorem summarizes the complexities of the 𝙵𝙻𝙰𝚃 oracle.

Theorem 4
The expected query-time 𝑄𝙵𝙻𝙰𝚃 as well as the expected preprocessing time 𝔼{𝑃𝙵𝙻𝙰𝚃} and space 𝔼{𝑆𝙵𝙻𝙰𝚃} of 𝙵𝙻𝙰𝚃 are:

𝔼{𝑄𝙵𝙻𝙰𝚃}∈𝔼{𝑃𝙵𝙻𝙰𝚃} , 𝔼{𝑆𝙵𝙻𝙰𝚃}∈𝑛𝜔(𝑟+1)+o(1)𝑛1−𝜔+o(1)⋅[𝑛2𝜃/𝜈+𝑛1+𝛼⋅(1−𝜃)]
Proof
(Theorem 4) Recall that 𝚁𝚀𝙰+ grows an expected number of (1+(1/𝜌)𝑟) 𝚃𝙳𝙳 balls from the centers to their closest landmarks. By Theorem 1 and recalling that 𝜌=𝑛−𝜔, the time complexity of this is

((1/𝜌)𝑟+1[log(1/𝜌)+loglog(𝐾max)])∈(𝑛𝜔(𝑟+1)[log(𝑛𝜔)+loglog(𝑛)])⊂𝑛𝜔(𝑟+1)+o(1)
Moreover, for each of the ((1/𝜌)𝑟) settled landmarks, a small-sized ball has to be grown, in order to cover the destinations which are “too close” to ℓ. The size of each such ball is only 𝑓(𝑛)polylog(𝑓(𝑛))⊂polylog(𝑛). The expected time for growing all these landmark-centered balls is

((1/𝜌)𝑟⋅polylog(𝑛))⊂(𝑛𝜔𝑟+o(1))
From the above we conclude that 𝔼{𝑄𝙵𝙻𝙰𝚃}∈⊂𝑛𝜔(𝑟+1)+o(1).

Regarding the preprocessing phase, 𝙵𝙻𝙰𝚃 is charged the entire space and time of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 for preprocessing “faraway” destinations, plus the space and time consumed by 𝙱𝙸𝚂+ for the “nearby” destinations, from each landmark.

In particular, per landmark ℓ∈𝐿 we need:

(i)
(𝐹2polylog(𝐹)⊂polylog(𝑛)) space required by 𝙱𝙸𝚂+, since by Lemma 8 the involved graph for computing travel-time summaries of all the (at most) F “nearby” destinations around ℓ, only contains (𝐹polylog(𝐹)) vertices and concavity-spoiling breakpoints at the arc-travel-time functions;

(ii)
2⌈𝑇𝜏∗⌉(𝑛−𝐹)∈(𝑛𝛼(1−𝜃)) space, required by 𝚃𝚁𝙰𝙿 for storing travel-time summaries of all the 𝑛−𝐹<𝑛 “faraway” destinations.

Summarizing, the expected preprocessing space of 𝙵𝙻𝙰𝚃 is:

𝔼{𝑆𝙵𝙻𝙰𝚃}==𝔼{|𝐿|}⋅(𝐹2polylog(𝐹)+2⌈𝑇𝜏∗⌉⋅(𝑛−𝐹))∈/∗Lemma 7∗/𝑛1−𝜔⋅[𝑛(2𝜃/𝜈)⋅[1+o(1)]+𝑛1+𝛼⋅(1−𝜃)]𝑛1−𝜔+o(1)⋅[𝑛2𝜃/𝜈+𝑛1+𝛼⋅(1−𝜃)]
The preprocessing-time bound is computed similarly. Again, it consists of the 𝙱𝙸𝚂+ time for the “nearby” destinations, plus the 𝚃𝚁𝙰𝙿 time for the “faraway” destinations, per landmark ℓ.

𝔼{𝑃𝙵𝙻𝙰𝚃}∈𝔼{|𝐿|}⋅( 𝐹2polylog(𝐹)loglog(𝐾max)+⌈𝑇𝜏∗⌉⋅((𝑛−𝐹)⋅[log(𝑛−𝐹)+loglog(𝐾max)]) )=/∗Lemma 7∗/𝑛1−𝜔[𝑛(2𝜃/𝜈)⋅[1+o(1)]+𝑛1+𝛼⋅(1−𝜃)[1+o(1)]]=𝑛1−𝜔+o(1)⋅[𝑛2𝜃/𝜈+𝑛1+𝛼⋅(1−𝜃)]
◻

We provide a corollary which shows a parameter-tuning example for trading off the sublinearity of query-time, the subquadratic preprocessing requirements and the worst-case approximation of the chosen paths, in the case of 𝙵𝙻𝙰𝚃.

Corollary 2
Consider the execution of 𝙵𝙻𝙰𝚃 on a TD-instance with a recursion budget 𝑟∈{0,1,…,2𝜆−1} and set up of parameters 𝜔=𝛿𝑟+1 and 𝜃=𝜈+𝛼𝜈2+𝛼𝜈, where 𝜈∈1−o(1). Then, 𝙵𝙻𝙰𝚃 achieves (sublinear) expected query time 𝑛𝛿+o(1) and (subquadratic) expected preprocessing requirements 𝑛2−𝛽+o(1) for all constants 1>𝛿>𝑟+12𝜆+1 and 𝛽=𝛿𝑟+1−12𝜆+1>0.

Proof
(Corollary 2) We already know from the proof of Corollary 1 that the particular choice of 𝜔 ensures sublinearity of the expected query time, 𝑛𝛿+o(1). As for the requirement for subquadratic preprocessing space and time, observe that:

𝑛2−𝜔+𝛼(1−𝜃)+o(1)=𝑛2−𝛿𝑟+1+𝛼−𝛼𝜃+o(1)=𝑛2−𝛿𝑟+1+1𝜆−1+1/𝜆2𝜆+1+o(1)=𝑛2−[𝛿𝑟+1−12𝜆+1]+o(1)
This is because 𝛼𝜃=𝛼𝜈+𝛼2𝜈2+𝛼𝜈=1+1/𝜆2𝜆+1±o(1). Moreover, the choice of 𝜃 guarantees that 𝜈𝜃=2+𝛼𝜈1+𝛼<3, as it is required in the proof of Lemma 7. Finally, it must also hold that

𝛽=𝛿𝑟+1−12𝜆+1>0⇔𝛿>𝑟+12𝜆+1
which indeed is the case. ◻

Table 4 provides a concrete example of the trade-off of the 𝙵𝙻𝙰𝚃 oracle among the query-sublinearity, the preprocessing-subquadraticity and the achieved worst-case approximation guarantee, for a TD-instance with 𝜆=10, 𝛼=1𝜆, 𝛿∈(𝑟+12𝜆+1,1), 𝛽=𝛿𝑟+1−12𝜆+1, 𝜔=𝛿𝑟+1, and 𝜃=𝜈+𝛼𝜈2+𝛼𝜈. The cells of the table (except for the last row) indicate the exponent of subquadraticity, 2−𝛽. The red values in the table correspond to pairs of 𝛿- and r-values which cannot guarantee subquadratic preprocessing requirements. The last row gives the worst-case approximation guarantees that the query algorithm achieves, for the corresponding values of the recursion budget r. The metric-dependent (but scaling-invariant) parameters, which also affect the stretch factor 1+𝜎, are set to the values 𝜁=2.043 and 𝛬max=0.225, as they were measured for the Berlin TD-instance (cf. Sect. 3.3). The preprocessing parameter concerning the summaries’ approximation guarantee is set to 𝜖=0.01. Because of the looser dependence of 𝛿 on r in Corollary 2, the recursion budget that we can afford in 𝙵𝙻𝙰𝚃 is essentially doubled, compared to the recursion budget of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈. As a consequence, 𝙵𝙻𝙰𝚃 allows for even better approximation guarantees, for essentially the same requirements for sublinearity in query-times and subquadraticity in preprocessing.

Table 4 Trade-offs of 𝙵𝙻𝙰𝚃 among query-sublinearity (𝑛𝛿), preprocessing quadraticity (𝑛2−𝛽), and achieved worst-case approximation guarantee 1+𝜎(𝑟,𝜀,𝜓)
Full size table
Comparison of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 and 𝙵𝙻𝙰𝚃
Both 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 and 𝙵𝙻𝙰𝚃 depend on the travel-time metric, but are independent of the degree of disconcavity 𝐾∗. On the one hand, 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈 is a simpler oracle, at least w.r.t. its preprocessing phase. On the other hand, 𝙵𝙻𝙰𝚃 achieves a better worst-case approximation guarantee, for the same TD-instance and the same anticipations for sublinearity of query-time and subquadraticity of the preprocessing requirements. This is because 𝙵𝙻𝙰𝚃 can afford roughly two times the recursion budget of 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈, and r has an exponential effect on the approximation guarantee that 𝚁𝚀𝙰+ achieves.

Quality of Approximation Provided by 𝙵𝙻𝙰𝚃
At this point we provide a detailed justification why the query algorithm of 𝙵𝙻𝙰𝚃 actually constitutes a PTAS for the TDSP problem. A similar argument would also apply for 𝚃𝚁𝙰𝙿𝙾𝙽𝙻𝚈, with some straightforward modifications.

As already mentioned, all variants of 𝚁𝚀𝙰 achieve an approximation guarantee of

1+𝜎(𝑟,𝜀,𝜓)=1+𝜀⋅(1+𝜀/𝜓)𝑟+1(1+𝜀/𝜓)𝑟+1−1
given the approximation guarantee (1+𝜀) for the preprocessed landmark-to-vertex distances, and the parameter 𝜓=1+𝛬max(1+𝜀)(1+2𝜁+𝛬max𝜁)+(1+𝜀)𝜁. It should be noted at this point that 𝜓 is only dependent on the parameters 𝛬max,𝜁 of the arc-cost metric. In particular, it does not depend on scalings (i.e., change in units) of time in the instance at hand. Clearly 𝜎↓𝜀 as r tends to infinity. But we simply cannot afford an infinite recursion budget to the query algorithm. On the other hand, assuming that an approximation guarantee 1+𝜎 is targeted, then there is a lower bound on the recursion budget required to achieve it:


This then implies, using standard inequalities 𝑥≥ln(1+𝑥)≥𝑥−𝑥22 and straightforward calculations, that a recursion budget 𝑟≥𝜓𝜎−𝜀 would suffice to achieve approximation guarantee 1+𝜎 for 𝚁𝚀𝙰, given that the one for the preprocessed distances is 1+𝜀 and that 𝜓≥(𝜎−𝜀)𝜀2𝜎−3𝜀.

For example, one can demand an approximation guarantee of 1+𝜀=1+𝜎3 for the preprocessed information and then afford a recursion budget 𝑟≥3𝜓2𝜎 in order to achieve this. As mentioned in Table 2, 𝚁𝚀𝙰’s recursion budget in 𝙵𝙻𝙰𝚃 is at most 𝑟≤2𝜆−1. Demanding both the aforementioned upper and lower bound for r, it should hold that 𝜆≥3𝜓4𝜎+12, i.e., not all values of 𝜎 would be achievable for an instance with given values for 𝜆 and 𝜓.

In any case, a lower bound on 𝙵𝙻𝙰𝚃’s approximation guarantee for the queries is given by the following:


On the other hand, as previously mentioned, 𝜓 is a constant that is only dependent on the arc-cost metric, and is not affected by any scaling (change in units) of time in the instance. On the other hand, as we show in Lemma 7, 𝜆≈1𝛼𝜈>1𝛼. This allows us to choose 1𝛼∈𝛺(𝜓), in order to be able to afford a recursion budget which will guarantee that 𝜎 converges to 𝜀.

A Hierarchical Oracle with Partially-Informed Landmarks
We now describe and analyze the Hierarchical ORacle for time-dependent Networks (𝙷𝙾𝚁𝙽), whose query algorithm is highly competitive against 𝚃𝙳𝙳, not only for long-range queries (i.e., having Dijkstra-rank proportional to the network size) but also for medium- and short-range queries, while ensuring subquadratic preprocessing space and time.

It should be noted that, although short- and medium-range queries are a quite small minority (at least) when sampling origin-destination pairs uniformly at random, in practice most of the queries are of these types in real-world scenarios. Therefore, it is important and practically relevant to achieve provable approximation guarantees and sublinear query-time that depends on the actual Dijkstra-rank of the query at hand and not on the network size.

The main idea of 𝙷𝙾𝚁𝙽 is to preprocess:

many landmarks, each possessing summaries for a few destinations around them, so that all short-range queries can be answered using only these landmarks;

landmark sets of exponentially decreasing sizes, organized in a hierarchy according to their sizes, possessing summaries for more and more (but still not all) destinations around them, so that medium-range queries can be answered by them;

a single set at the top of the hierarchy, of only a few landmarks with preprocessed information for all reachable destinations, as in 𝙵𝙻𝙰𝚃’s preprocessing phase.

For a landmark ℓ, the area of coverage 𝐶[ℓ]⊂𝑉 of ℓ is the set of its surrounding vertices, for which ℓ possesses travel-time summaries. The landmark ℓ is called informed for each 𝑣∈𝐶[ℓ], and uninformed for each 𝑣∈𝑉∖𝐶[ℓ]. Particularly for the destinations which are “too close” from ℓ, i.e., at free-flow distance at most 1, we consider that ℓ is always informed, although no travel-time summaries are ever computed for them, since the query algorithm will deal with them anyway “on-the-fly”. The query-time overhead for dealing with the “too close” destinations per settled landmark is only (𝑓(𝑛)polylog(𝑛)), and therefore is actually negligible.

The landmarks are organized in a hierarchy, according to the sizes of their areas of coverage. Each level 𝐿𝑖 in the hierarchy is accompanied with a targeted Dijkstra-rank 𝑁𝑖∈[𝑛]. The goal of 𝙷𝙾𝚁𝙽 is to ensure that 𝐿𝑖 suffices for 𝚁𝚀𝙰+ to successfully address queries (𝑜,𝑑,𝑡𝑜) with 𝛤[𝑜,𝑑](𝑡𝑜)≤𝑁𝑖, in time o(𝑁𝑖). The difficulty of this approach lies in the analysis of the query algorithm. We want to execute a variant of 𝚁𝚀𝙰+ which, based on a minimal subset of landmarks, would guarantee a (1+𝜎(𝑟))-approximate solution for any query (𝑜,𝑑,𝑡𝑜) (as in 𝙵𝙻𝙰𝚃), but also a time-complexity sublinear in 𝛤[𝑜,𝑑](𝑡𝑜), rather than the sublinearity in the network size that is guaranteed by 𝙵𝙻𝙰𝚃.

Towards this direction, we propose the Hierarchical Query Algorithm (𝙷𝚀𝙰) which initially grows a ball from (𝑜,𝑡𝑜), until an informed landmark ℓ w.r.t. d is settled that is also at the “right distance” from o, given the density of landmarks belonging to the same level with ℓ. 𝙷𝚀𝙰 uses the level 𝐿𝑖 in the hierarchy that contains ℓ (actually, the size of the corresponding areas of coverage) as a baseline and continues with the execution of 𝚁𝚀𝙰+, considering only landmarks having coverage at least equal to that of ℓ (cf. Fig. 5).

In the rest of this section, we provide the details and analysis of the 𝙷𝙾𝚁𝙽 TD-oracle.

Fig. 5
figure 5
Demonstration of execution of 𝙷𝚀𝙰. Dashed circles indicate areas of coverage. Solid circular stripes indicate the rings of the corresponding levels in the hierarchy. Landmark ℓ1,𝑜 is uninformed and ℓ3,𝑜, although informed, comes too early. ℓ2,𝑜 is both informed and within the ring of its own level, leading 𝙷𝚀𝙰 to deduce that the appropriate level is 𝑖=2

Full size image
Setting-Up 𝙷𝙾𝚁𝙽
We use the following parameters to set up the hierarchical construction required by 𝙷𝙾𝚁𝙽:

(i)
The parameter 𝑘∈(loglog(𝑛)) determines the number of levels (minus one) comprising the hierarchy of landmarks.

(ii)
The parameter 𝛾>1 determines the actual values of the targeted Dijkstra-ranks, one per level of the hierarchy. In particular, as 𝛾 gets closer to 1, the targeted Dijkstra-ranks accumulate closer to small- and medium-rank queries.

(iii)
The parameter 𝛿∈(0,1) quantifies the anticipated sublinearity of the query algorithm (𝙷𝚀𝙰), in each level of the hierarchy, compared to the targeted Dijkstra-rank of this level. In particular, if 𝑁𝑖 is the targeted Dijkstra-rank corresponding to level 𝐿𝑖 in the hierarchy, then 𝙷𝚀𝙰 should be executed in time ((𝑁𝑖)𝛿+𝑜(1)), if only the landmarks in this level and in higher levels are allowed to be used.

Preprocessing of 𝙷𝙾𝚁𝙽
The preprocessing phase of 𝙷𝙾𝚁𝙽 consists of the following steps.

1.
For each 𝑖∈[𝑘]:

The targeted Dijkstra-rank for level-i is set to 𝑁𝑖=𝑛(𝛾𝑖−1)/𝛾𝑖.

A randomly chosen (we call it level-i) landmark set 𝐿𝑖⊂𝐢𝐮𝐚𝐫(𝜌𝑖)𝑉 is constructed, where 𝜌𝑖=𝑁−𝛿/(𝑟+1)𝑖=𝑛−𝛿(𝛾𝑖−1)/[(𝑟+1)𝛾𝑖].

For each landmark ℓ𝑖∈𝐿𝑖, let 𝐶[ℓ𝑖] be the smallest free-flow ball centered at ℓ𝑖 containing 𝑐𝑖=𝑁𝑖⋅𝑛𝜉𝑖=𝑛(𝛾𝑖−1)/𝛾𝑖+𝜉𝑖 vertices, for a sufficiently (but not too) small constant 𝜉𝑖>0, whose range will be determined by Theorem 5 (in particular, by the analysis of 𝙷𝚀𝙰). Let 𝐹𝑖=𝑐𝜒𝑖 be the number of “nearby” vertices around ℓ𝑖, where 𝜒=𝜃𝜈=1+𝛼2+𝛼𝜈∈[12,22+𝜈] is an appropriate value determined so as to ensure the correctness of 𝙵𝙻𝙰𝚃’s analysis w.r.t. the level-i of the hierarchy (cf. Theorem 4 and Corollary 2).

2.
An ultimate level 𝐿𝑘+1⊂𝐢𝐮𝐚𝐫(𝜌𝑘+1)𝑉 of landmarks is constructed, with 𝜌𝑘+1=𝑛−𝛿𝑟+1, to ensure that 𝙷𝙾𝚁𝙽 is also competitive against queries with Dijkstra-ranks greater than 𝑛(𝛾𝑘−1)/𝛾𝑘. We choose in this case 𝑐𝑘+1=𝑁𝑘+1=𝑛, 𝐹𝑘+1=𝑛𝜒 and 𝐶[ℓ𝑘+1]=𝑉, ∀ℓ𝑘+1∈𝐿𝑘+1.

3.
For each level 𝑖∈[𝑘+1] and landmark ℓ𝑖∈𝐿𝑖, the travel-time summaries are constructed, for almost all destinations 𝑣∈𝐶[ℓ𝑖].

The summaries for the 𝐹𝑖 “nearby” vertices around ℓ𝑖 are constructed with 𝙱𝙸𝚂+. Again, the “too close” destinations (i.e., at free-flow travel-time distance less than 1) around ℓ𝑖 are excluded from the preprocessing, but this will only impose a negligible overhead for the query algorithm, as it was explained in the analysis of 𝙵𝙻𝙰𝚃.

The summaries for the remaining 𝑐𝑖−𝐹𝑖 “faraway” vertices of ℓ𝑖 are constructed with 𝚃𝚁𝙰𝙿.

Description of the Hierarchical Query Algorithm
We now turn to the description of the hierarchical query algorithm (𝙷𝚀𝙰) for answering a query (𝑜,𝑑,𝑡𝑜). Recall that ℓ𝑜 is the closest landmark to the origin o (cf. Sect. 4). We start by defining two stopping or termination criteria that are used by 𝙷𝚀𝙰.

Early Stopping Criterion (ESC): Some landmark ℓ𝑜∈𝐿=∪𝑖∈[𝑘+1]𝐿𝑖 is settled which is also “informed” (i.e., 𝑑∈𝐶[ℓ𝑜]) and, moreover, for some tuning parameter 𝜑≥1 it holds that

𝛥⎯⎯⎯⎯[ℓ𝑜,𝑑](𝑡𝑜+𝐷[𝑜,ℓ𝑜](𝑡𝑜))𝐷[𝑜,ℓ𝑜](𝑡𝑜)≥(1+𝜀)⋅𝜑⋅(𝑟+1)+𝜓−1
where 𝜓 is defined in Theorem 1.

Appropriate Level of Hierarchy (ALH): For 𝑖∈[𝑘+1], some level-i landmark ℓ𝑖,𝑜∈𝐿𝑖 is settled, for which the following hold:

(i)
ℓ𝑖,𝑜 is “informed”: 𝑑∈𝐶[ℓ𝑖,𝑜];

(ii)
ℓ𝑖,𝑜 is at the “right distance”: 𝑁𝛿/(𝑟+1)𝑖ln(𝑛)≤𝛤[𝑜,ℓ𝑖,𝑜](𝑡𝑜)≤ln(𝑛)⋅𝑁𝛿/(𝑟+1)𝑖.

In a nutshell, if (ESC) holds then already ℓ𝑜 provides 𝙷𝚀𝙰 with a very good approximation and its execution is terminated. If on the other hand (ALH) holds, then 𝙷𝚀𝙰 concludes that i is the appropriate level of the hierarchy to consider w.r.t. (𝑜,𝑑,𝑡𝑜). The main steps of 𝙷𝚀𝙰 are shown in Fig. 6.

Fig. 6
figure 6
The main steps of the query algorithm 𝙷𝚀𝙰

Full size image
Observe that the level-(𝑘+1) landmarks are always “informed”. Thus, if no level-(≤𝑘) “informed” landmark is discovered at the “right distance”, then the first level-(𝑘+1) landmark that will be found at distance larger than ln(𝑛)⋅𝑁𝛿/(𝑟+1)𝑘 will be considered to be at the “right distance”, and 𝙷𝚀𝙰 will conclude that the appropriate level is 𝑘+1.

Observe also that 𝚁𝚀𝙰+𝑖 (cf. Fig. 6) may fail to construct approximate solutions via each settled landmark contained in 𝑀𝑖=∪𝑘+1𝑗=𝑖𝐿𝑗, since some of the settled landmarks may not be “informed” about d. Nevertheless, as we shall show shortly, this is not a problem for the analysis of our algorithm: all the landmarks of 𝑀𝑖 which are settled by 𝙷𝚀𝙰 and correspond to balls whose centers lie on the (unknown) shortest path, will indeed be “informed”, and this is enough for our approximation guarantee whose proof is only based on these balls.

Theorem 5, whose proof is provided in Sect. 8.4, summarizes the performance of 𝙷𝙾𝚁𝙽.

Theorem 5
Consider a sparse TD-instance, abiding with Properties 1, 2, 3 and 4, a recursion budget 𝑟∈{0,1,…,2𝜆−⌈2𝜆+1𝛾⌉}, and the following setup of the involved parameters: 𝜑≥𝜓⋅(1+𝜀/𝜓)𝑟+1−1𝜀⋅(𝑟+1), 𝑘∈(loglog(𝑛)), 𝛿∈(𝛾(𝑟+1)(𝛾−1)(2𝜆+1) , 1), 𝜔=𝛿𝑟+1, 𝜃=𝜈+𝛼𝜈2+𝛼𝜈, 𝜈∈1−o(1), 𝛽=(𝛾−1)𝛿𝛾(𝑟+1)−12𝜆+1, 𝜉𝑖∈(𝛺(loglog(𝑛)log(𝑛)),1−𝛾−𝑖) for all 𝑖∈[𝑘].

Then, 𝙷𝙾𝚁𝙽 achieves preprocessing requirements 𝔼{𝑃𝙷𝙾𝚁𝙽} and 𝔼{𝑆𝙷𝙾𝚁𝙽}∈𝑛2−𝛽+o(1). Moreover, for any query (𝑜,𝑑,𝑡𝑜) such that 𝑁𝑖∗−1<𝛤[𝑜,𝑑](𝑡𝑜)≤𝑁𝑖∗ for some 𝑖∗∈[𝑘+1], 𝙷𝙾𝚁𝙽’s query algorithm (𝙷𝚀𝙰) achieves expected time complexity 𝔼{𝑄𝙷𝚀𝙰}∈(𝑁𝑖∗)𝛿+o(1), and approximation guarantee 1+𝜀(1+𝜀/𝜓)𝑟+1(1+𝜀/𝜓)𝑟+1−1, with probability at least 1−(1𝑛).

Analysis of 𝙷𝙾𝚁𝙽
The construction of the travel-time summaries for 𝙷𝙾𝚁𝙽 is based on 𝙵𝙻𝙰𝚃’s preprocessing scenario, i.e., a proper combination of 𝙱𝙸𝚂+ and 𝚃𝚁𝙰𝙿 for each level in the landmark-hierarchy. The queries are served by the 𝙷𝚀𝙰 query algorithm.

The oracle exploits two fundamental invariants:

I1
The approximation guarantee of a path via some landmark ℓ strongly depends on the relative distance of the landmark from the origin o, compared to the distance of the destination d from o.

I2
Given that the expected distance of the closest level-i landmark from the origin is roughly 1𝜌𝑖, it is rather unlikely that it will appear too early or too late, i.e., outside a sufficiently wide ring-stripe around (𝑜,𝑡𝑜).

Invariant I1 is exploited by the (ESC) criterion, in order to handle the exceptional case where a higher-level landmark (which also happens to be “informed”) appears before the first “informed” landmark from the appropriate level. Invariant I2 is actually an event that holds with high probability, as is shown in the detailed analysis of the oracle below, and is exploited by the (ALH) criterion. Therefore, the event that an “informed” landmark is settled which is also at the “right distance”, whereas the previously discovered landmarks (most likely of smaller levels) were “uninformed”, reveals an asymptotic bound for the unknown Dijkstra-rank 𝛤[𝑜,𝑑](𝑡𝑜) of the destination.

We now provide a sequence of lemmata, which will eventually be used in the proof of our main technical result (Theorem 5) concerning the complexities of 𝙷𝙾𝚁𝙽. In the following, when we mention an (ESC) termination (resp. (ALH) termination), we refer to the termination of 𝙷𝚀𝙰 due to the (ESC) criterion (resp. (ALH) criterion). We start with an upper bound on the free-flow distance of a discovered landmark ℓ𝑜 from d. At this point we do not require that 𝑑∈𝐶[ℓ𝑜].

Lemma 9
If ℓ𝑜∈𝐿 was settled by the initial 𝚃𝙳𝙳 ball grown by 𝙷𝚀𝙰 from (𝑜,𝑡𝑜), then the following holds: 𝐷⎯⎯⎯[ℓ𝑜,𝑑]≤𝜁1−𝛬min⋅𝐷[𝑜,ℓ𝑜](𝑡𝑜)+𝐷[𝑜,𝑑](𝑡𝑜).

Proof
(Lemma 9) By Property 2 we know that:

𝐷[ℓ𝑜,𝑜](𝑡𝑜)≤𝜁⋅𝐷[𝑜,ℓ𝑜](𝑡𝑜)
(8)
By Property 1 we also know that:

∀𝑥>0,⇒−𝛬min⋅𝑥≤𝐷[ℓ𝑜,𝑜](𝑡𝑜−𝑥)≤𝐷[ℓ𝑜,𝑜](𝑡𝑜)−𝐷[ℓ𝑜,𝑜](𝑡𝑜−𝑥)𝐷[ℓ𝑜,𝑜](𝑡𝑜)+𝛬min⋅𝑥
(9)
We look for a particular departure-time 𝑡𝑜−𝑥𝑜, and the corresponding minimum-travel-time 𝐷[ℓ𝑜,𝑜](𝑡𝑜−𝑥𝑜), so as to be at the origin o exactly at time 𝑡𝑜. That is:

𝑡𝑜=⇒ 𝑥𝑜=⇒ 𝑥𝑜≤𝑡𝑜−𝑥𝑜+𝐷[ℓ𝑜,𝑜](𝑡𝑜−𝑥𝑜)𝐷[ℓ𝑜,𝑜](𝑡𝑜−𝑥𝑜)≤/∗(9)∗/𝐷[ℓ𝑜,𝑜](𝑡𝑜)+𝛬min⋅𝑥𝑜𝐷[ℓ𝑜,𝑜](𝑡𝑜)1−𝛬min≤/∗(8)∗/𝜁1−𝛬min⋅𝐷[𝑜,ℓ𝑜](𝑡𝑜)
(10)
Finally, we upper-bound the free-flow distance of ℓ𝑜 from d by exploiting the triangle inequality:

𝐷⎯⎯⎯[ℓ𝑜,𝑑]≤𝐷[ℓ𝑜,𝑑](𝑡𝑜−𝑥𝑜)≤𝐷[ℓ𝑜,𝑜](𝑡𝑜−𝑥𝑜)+𝐷[𝑜,𝑑](𝑡𝑜)≤/∗(10)∗/𝜁1−𝛬min⋅𝐷[𝑜,ℓ𝑜](𝑡𝑜)+𝐷[𝑜,𝑑](𝑡𝑜)
which is exactly the desired inequality. ◻

The following lemma provides an upper bound on the approximation guarantee of 𝙷𝚀𝙰, when an (ESC) termination occurs.

Lemma 10
Assume that ℓ𝑜∈𝐿 is “informed” (i.e., 𝑑∈𝐶[ℓ𝑜]) and settled by the initial 𝚃𝙳𝙳 ball that 𝙷𝚀𝙰 grows from (𝑜,𝑡𝑜). Then, the following hold whenever 𝙷𝚀𝙰 terminates due to the (ESC) criterion:

(i)
For any 𝜑>0, the reported travel-time is a (1+𝜀+𝜓𝜑⋅(𝑟+1))-approximation of the minimum travel-time.

(ii)
For 𝜑≥𝜓⋅[(1+𝜀/𝜓)𝑟+1−1]𝜀⋅(𝑟+1), the reported travel-time is a (1+𝜀⋅(1+𝜀/𝜓)𝑟+1(1+𝜀/𝜓)𝑟+1−1)-approximation of the minimum travel-time.

Proof
(Lemma 10) Let 𝑅𝑜=𝐷[𝑜,ℓ𝑜](𝑡𝑜) and 𝑅𝑑=𝐷[𝑜,𝑑](𝑡𝑜). We begin with the proof of the first statement. By Theorem 1 (cf. also the analysis of 𝙵𝙲𝙰 in [17]) we know that:

⇒𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜)=𝑅𝑜+𝛥⎯⎯⎯⎯[ℓ𝑜,𝑑](𝑡𝑜+𝑅𝑜)≤(1+𝜀)⋅𝑅𝑑+𝜓⋅𝑅𝑜⎧⎩⎨⎪⎪𝛥⎯⎯⎯⎯[ℓ𝑜,𝑑](𝑡𝑜+𝑅𝑜)𝑅𝑜≤(1+𝜀)⋅𝑅𝑑𝑅𝑜+𝜓−1𝛥⎯⎯⎯⎯[ℓ𝑜,𝑑](𝑡𝑜+𝑅𝑜)𝑅𝑑≤1+𝜀+(𝜓−1)⋅𝑅𝑜𝑅𝑑
By the (𝐄𝐒𝐂) termination criterion we also know that:

𝛥⎯⎯⎯⎯[ℓ𝑜,𝑑](𝑡𝑜+𝑅𝑜)𝑅𝑜≥(1+𝜀)⋅𝜙⋅(𝑟+1)+𝜓−1
Therefore, we deduce that:

⇒(1+𝜀)⋅𝜑⋅(𝑟+1)+𝜓−1≤(1+𝜀)⋅𝑅𝑑𝑅𝑜+𝜓−1𝑅𝑑𝑅𝑜≥𝜑⋅(𝑟+1)⇒𝜓⋅𝑅𝑜𝑅𝑑≤𝜓𝜑⋅(𝑟+1)
from which comes the first statement of the lemma:

𝛥⎯⎯⎯⎯[𝑜,𝑑](𝑡𝑜)𝑅𝑑≤1+𝜀+𝜓⋅𝑅𝑜𝑅𝑑≤1+𝜀+𝜓𝜑⋅(𝑟+1)
As for the second statement in the lemma, it suffices to observe that, since 𝜑≥𝜓⋅[(1+𝜀/𝜓)𝑟+1−1]𝜀⋅(𝑟+1), it holds that:

1+𝜀+𝜓𝜑⋅(𝑟+1)≤1+𝜀⋅(1+𝜀/𝜓)𝑟+1(1+𝜀/𝜓)𝑟+1−1
◻

We proceed now by studying the first appearance of a level-i landmark within the unique outgoing ball from (𝑜,𝑡𝑜). The next lemma shows that, with high probability, this first appearance of a level-i landmark will take place in the following ring around o w.r.t. level-i:

𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜):=𝐵[𝑜 ; size=(𝑁𝑖)𝛿/(𝑟+1)⋅ln(𝑛)](𝑡𝑜) ∖ 𝐵[𝑜 ; size=(𝑁𝑖)𝛿/(𝑟+1)ln(𝑛)](𝑡𝑜)=𝐵[𝑜 ; size=ln(𝑛)𝜌𝑖](𝑡𝑜) ∖ 𝐵[𝑜 ; size=1𝜌𝑖ln(𝑛)](𝑡𝑜)
since 𝜌𝑖=𝑁−𝛿/(𝑟+1)𝑖.

Lemma 11
For each 𝑖∈[𝑘], there exists a level-i landmark in 𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜), with probability 1−(1𝑛).

Proof
(Lemma 11) Consider any subset of vertices 𝑆⊆𝑉, of size 𝑠=|𝑆|∈ℕ. The probability that none of the vertices in S is a level-i landmark, i.e., 𝐿𝑖∩𝑆=∅, is (1−𝜌𝑖)𝑠≤exp(−𝑠𝜌𝑖).

Observe now that, for 𝑖∈[𝑘], 𝑠𝑖=|𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜)|=ln(𝑛)𝜌𝑖−1𝜌𝑖ln(𝑛). Thus, we conclude that:

ℙ{|𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜)∩𝐿𝑖|=0}≤exp(−𝑠𝑖⋅𝜌𝑖)=exp(1ln(𝑛))𝑛∈(1𝑛).
◻

The next lemma states that whenever a landmark is settled at the “right distance” and it happens to have coverage at least as large as the actual (but unknown) Dijkstra-rank 𝛤[𝑜,𝑑](𝑡𝑜) of the query at hand, it must also hold that this landmark is “informed” about d.

Lemma 12
Assume that, during the initial 𝚃𝙳𝙳 ball grown by 𝙷𝚀𝙰, some landmark ℓ𝑖,𝑜∈𝐿𝑖∩𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜) is settled “at the right distance”. Assume also that 𝛤[𝑜,𝑑](𝑡𝑜)≤𝑁𝑖. Then it holds that ℓ𝑖,𝑜 is also “informed”: 𝑑∈𝐶[ℓ𝑖,𝑜].

Proof
(Lemma 12)

Let 𝑅𝑖,𝑜=𝐷[𝑜,ℓ𝑖,𝑜](𝑡𝑜) and recall that 𝑅𝑑=𝐷[𝑜,𝑑](𝑡𝑜). Assume also that 𝑅𝑑>𝑅𝑖,𝑜, because otherwise an exact solution will be anyway discovered before ℓ𝑖,𝑜 is settled and no (ALH) termination could have occurred. Then we have, by Lemma 9:

𝐷⎯⎯⎯[ℓ𝑖,𝑜,𝑑]≤=⇒𝛤⎯⎯⎯[ℓ𝑖,𝑜,𝑑]≤=≤𝜁1−𝛬min𝑅𝑖,𝑜+𝑅𝑑<(1+𝜁1−𝛬min)⋅𝑅𝑑≤/∗ Property  4∗/(1+𝜁1−𝛬min)⋅𝑁1/𝜆𝑖(1+𝜁1−𝛬min)⋅𝑛(𝛾𝑖−1)/(𝜆𝛾𝑖)≤/∗ Property  4∗/𝑓(𝑛)⋅(𝐷⎯⎯⎯[ℓ𝑖,𝑜,𝑑])𝜆𝑓(𝑛)⋅(1+𝜁1−𝛬min)𝜆⋅𝑛(𝛾𝑖−1)/𝛾𝑖𝑛𝑐loglog(𝑛)log(𝑛)⋅𝑛𝜆log(1+𝜁1−𝛬min)/log(𝑛)⋅𝑛(𝛾𝑖−1)/𝛾𝑖𝑛(𝛾𝑖−1)/𝛾𝑖+𝜉𝑖
for a small constant 𝜉𝑖∈𝛺(loglog(𝑛)log(𝑛)), i.e., not converging too fast to 0, since 𝑐,𝜁,𝛬min,𝜆∈(1), and 𝑓(𝑛)∈(log𝑐(𝑛)), according to Properties 1, 2 and 4. The last inequality implies that 𝑑∈𝐶[ℓ𝑖,𝑜]. ◻

Assume now some level-j in the hierarchy, such that 1≤𝑗<𝑖∗ where 𝑖∗ is the actual level that corresponds to the query at hand: 𝑁𝑖∗−1<𝛤[𝑜,𝑑](𝑡𝑜)≤𝑁𝑖∗ (cf. statement of Theorem 5). The next lemma states that 𝙷𝚀𝙰 will not settle within its initial ball any landmark ℓ∈𝐿𝑗 that is both at the “right distance” (i.e., ℓ∈𝑅𝐼𝑁𝐺[𝑜;𝑗](𝑡𝑜)) and informed (i.e., 𝑑∈𝐶[ℓ]). In other words, thre is no chance for the (ALH) termination, if it occurs first, to cause an incorrect “guess” by 𝙷𝚀𝙰 for the appropriate level for the query at hand.

Lemma 13
For 𝑖∈[𝑘], assume that 𝛤[𝑜,𝑑](𝑡𝑜)>𝑁𝑖 and also that, while 𝙷𝚀𝙰 grows the initial ball from (𝑜,𝑡𝑜), no (ESC) termination occurs. Then, ∀𝑗∈[𝑖], no landmark of 𝐿𝑗∩𝑅𝐼𝑁𝐺[𝑜;𝑗](𝑡𝑜) contains d in its coverage:

𝑑∉∪1≤𝑗≤𝑖∪ℓ∈𝐿𝑗∩𝑅𝐼𝑁𝐺[𝑜;𝑗](𝑡𝑜)𝐶[ℓ]
Proof
(Lemma 13) Let 𝑅𝑑=𝐷[𝑜,𝑑](𝑡𝑜), while 𝑅𝑗,𝑜=𝐷[𝑜,ℓ𝑗,𝑜](𝑡𝑜) is the actual distance of some level-j landmark ℓ𝑗,𝑜∈𝑅𝐼𝑁𝐺[𝑜;𝑗](𝑡𝑜)∩𝐿𝑗 from o.

We start by providing a simple proof for the cases of 1≤𝑗≤𝑖−1. We shall then handle the case 𝑗=𝑖 separately, since it is a little bit more involved.

Fix an arbitrary 𝑗∈[𝑖−1]. By the triangle inequality, the following holds:

𝐷[ℓ𝑗,𝑜,𝑑](𝑡𝑜+𝑅𝑗,𝑜)≥𝑅𝑑−𝑅𝑗,𝑜≥/∗ Property  4∗/(𝛤[𝑜,𝑑](𝑡𝑜)𝑓(𝑛))1/𝜆−(𝛤[𝑜,ℓ𝑗,𝑜](𝑡𝑜))1/𝜆>(𝑁𝑖𝑓(𝑛))1/𝜆−(ln(𝑛)⋅𝑁𝛿/(𝑟+1)𝑗)1/𝜆=1𝑓1/𝜆(𝑛)𝑛(𝛾𝑖−1)/(𝜆𝛾𝑖)−ln1/𝜆(𝑛)⋅𝑛𝛿(𝛾𝑗−1)/((𝑟+1)𝜆𝛾𝑗)=𝑛(𝛾𝑗−1)/(𝜆𝛾𝑗)⋅[𝑛(𝛾𝑖−𝑗−1)/(𝜆𝛾𝑖)𝑓1/𝜆(𝑛)−ln1/𝜆(𝑛)𝑛(1−𝛿𝑟+1)(𝛾𝑗−1)/(𝜆𝛾𝑗)]
The strict inequality is due to the facts that 𝛤[𝑜,𝑑](𝑡𝑜)>𝑁𝑖 and ℓ𝑗,𝑜∈𝑅𝐼𝑁𝐺[𝑜;𝑗](𝑡𝑜)⇒𝛤[𝑜,ℓ𝑗,𝑜](𝑡𝑜)≤𝑁𝛿/(𝑟+1)𝑗⋅ln(𝑛).

We apply once more Property 4, to get a lower bound on the Dijkstra-rank 𝛤[ℓ𝑗,𝑜,𝑑](𝑡𝑜+𝑅𝑗,𝑜):

𝛤[ℓ𝑗,𝑜,𝑑](𝑡𝑜+𝑅𝑗,𝑜)≥>(𝐷[ℓ𝑗,𝑜,𝑑](𝑡𝑜+𝑅𝑗,𝑜))𝜆𝑛(𝛾𝑗−1)/(𝛾𝑗)⋅[𝑛(𝛾𝑖−𝑗−1)/(𝜆𝛾𝑖)𝑓1/𝜆(𝑛)−ln1/𝜆(𝑛)𝑛(1−𝛿𝑟+1)(𝛾𝑗−1)/(𝜆𝛾𝑗)]𝜆
Recall that, according to Property 3, the rank of d from ℓ𝑗,𝑜 may vary within the TD-metric only by polylogarithmic factors. Therefore, the following inequality is deduced for the free-flow Dijkstra-rank of d from ℓ𝑗,𝑜:

𝛤⎯⎯⎯[ℓ𝑗,𝑜,𝑑]≥>≥≥>𝛤[ℓ𝑗,𝑜,𝑑](𝑡𝑜+𝑅𝑗,𝑜)polylog(𝑛)𝑛(𝛾𝑗−1)/(𝛾𝑗)polylog(𝑛)⋅[𝑛(𝛾𝑖−𝑗−1)/(𝜆𝛾𝑖)𝑓1/𝜆(𝑛)−ln1/𝜆(𝑛)𝑛(1−𝛿𝑟+1)(𝛾𝑗−1)/(𝜆𝛾𝑗)]𝜆𝑛(𝛾𝑗−1)/(𝛾𝑗)polylog(𝑛)𝑓(𝑛)⋅[𝑛(𝛾𝑖−𝑗−1)/(𝜆𝛾𝑖)−𝑓1/𝜆(𝑛)ln1/𝜆(𝑛)𝑛(1−𝛿𝑟+1)(𝛾𝑗−1)/(𝜆𝛾𝑗)]𝜆𝑛𝛾𝑗−1𝛾𝑗+𝛾𝑖−𝑗−1𝛾𝑖⋅[1−o(1)]−(loglog(𝑛)log(𝑛))𝑛(𝛾𝑗−1)/(𝛾𝑗)+𝜉𝑗
where the last inequality holds for

𝜉𝑗<𝛾−1𝛾𝑘≤𝛾−1𝛾𝑖=1𝛾𝑖−1−1𝛾𝑖≤1𝛾𝑗−1𝛾𝑖=𝛾𝑖−𝑗−1𝛾𝑖.
This last inequality implies also that 𝑑∉𝐶[ℓ𝑗,𝑜].

We shall now study the case 𝑗=𝑖. We fix an arbitrary level-i landmark which is at the “right distance”: ℓ𝑖,𝑜∈𝐿𝑖∩𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜). For sake of contradiction, we assume that, if it is ever settled by the initial 𝚃𝙳𝙳 ball from (𝑜,𝑡𝑜), ℓ𝑖,𝑜 does not cause an (ESC) termination. This implies (cf. proof of Lemma 10) that:

𝛥⎯⎯⎯⎯[ℓ𝑖,𝑜,𝑑](𝑡𝑜+𝑅𝑖,𝑜)𝑅𝑖,𝑜<⇒𝑅𝑖,𝑜>⇒𝑅𝑖,𝑜>(1+𝜀)𝜑(𝑟+1)+𝜓−1=:𝜒𝛥⎯⎯⎯⎯[ℓ𝑖,𝑜,𝑑](𝑡𝑜+𝑅𝑖,𝑜)𝜒≥𝐷[ℓ𝑖,𝑜,𝑑](𝑡𝑜+𝑅𝑖,𝑜)𝜒≥/∗ triangle  ineq. ∗/𝑅𝑑−𝑅𝑖,𝑜𝜒𝑅𝑑1+𝜒>/∗ Property  4∗/𝑛(𝛾𝑖−1)/(𝜆𝛾𝑖)(1+𝜒)𝑓1/𝜆(𝑛)
(11)
Nevertheless, we also know that for any ℓ𝑖,𝑜∈𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜) the following holds:

𝛤[𝑜,ℓ𝑖,𝑜](𝑡𝑜)≤⇒/∗ Property  4∗/𝑅𝑖,𝑜=𝐷[𝑜,ℓ𝑖,𝑜](𝑡𝑜)≤≤𝑁𝛿/(𝑟+1)𝑖ln(𝑛)=𝑛𝛿(𝛾𝑖−1)/((𝑟+1)𝛾𝑖)⋅ln(𝑛)(𝛤[𝑜,ℓ𝑖,𝑜](𝑡𝑜))1/𝜆𝑛𝛿(𝛾𝑖−1)/((𝑟+1)𝜆𝛾𝑖)⋅ln1/𝜆(𝑛)
(12)
Inequalities (11) and (12) may hold at the same time only if

𝑛(1−𝛿𝑟+1)(𝛾𝑖−1)/(𝜆𝛾𝑖)<(1+𝜒)𝑓1/𝜆(𝑛)ln1/𝜆(𝑛)⇒(1−𝛿𝑟+1)𝛾𝑖−1𝛾𝑖log(𝑛)−log(ln(𝑛))−log(𝑓(𝑛))<𝜆log(1+𝜒)⇒log(𝑛)<𝛾𝑖⋅[log(ln(𝑛))+log(𝑓(𝑛))+𝜆log(1+𝜒)](𝛾𝑖−1)⋅(1−𝛿𝑟+1)∈(loglog(𝑛))
which is certainly impossible for 𝛾,𝛿,𝜆,𝜒,𝑟∈(1), and 𝑓(𝑛)∈polylog(𝑛). This contradiction implies that any landmark 𝑖∈𝐿𝑖∈𝑅𝐼𝑁𝐺[𝑜;𝑖](𝑡𝑜) will certainly trigger the (ESC) termination criterion. ◻

The last lemma proves that when an (ALH) termination occurs, 𝙷𝚀𝙰 achieves the desired approximation guarantee with high probability, and also sublinearity in the targeted Dijkstra-rank.

Lemma 14
For 𝑖∗∈{2,3,…,𝑘+1}, let 𝑁𝑖∗−1<𝛤[𝑜,𝑑](𝑡𝑜)≤𝑁𝑖∗. Assume also that 𝙷𝚀𝙰 terminated due to the (ALH) criterion. Then, with probability 1−(1𝑛), 𝙷𝚀𝙰 returns an (1+𝜀(1+𝜀/𝜓)𝑟+1(1+𝜀/𝜓)𝑟+1−1)−approximate solution. The expected query-time is ((𝑁𝑖∗)𝛿+𝑜(1)).

Proof
(Lemma 14) We start with the upper bound on the expected query time.

As it was already explained by Lemmas 11–13, we know that a successful “guess” of 𝑖∗ occurs with probability 1−(1𝑛). Then, 𝙷𝚀𝙰 proceeds with the execution of 𝚁𝚀𝙰+𝑖∗, whose expected time is (cf. Theorem 1):

((1/𝜌𝑖∗)𝑟+1log(1/𝜌𝑖∗))=((𝑁𝑖∗)𝛿+𝑜(1))
since 𝜌𝑖∗=𝑁−𝛿/(𝑟+1)𝑖∗. In the unlikely event of a wrong guess for the appropriate level, in worst-case 𝙷𝚀𝙰 will falsely assume that 𝑖∗=𝑘+1, therefore the contribution of a wrong guess to the expected query time is at most (1𝑛)⋅𝑛𝛿+o(1)=𝑛−1+𝛿+o(1)∈o(1), i.e., it is indeed negligible.

As for the approximation guarantee, since the analysis for 𝚁𝚀𝙰+𝑖∗ is based solely on the quality of the paths via landmarks discovered from ball centers located along a minimum-travel-time od-path 𝑝∗∈𝑆𝑃[𝑜,𝑑](𝑡𝑜) (cf. Sect. 4 and the corresponding proof for 𝚁𝚀𝙰 in [17]), it suffices to prove that all the level-(≥𝑖∗) landmarks discovered from ball centers which reside at the (unknown) shortest od-path, are “informed” about d.

For an arbitrary ball center 𝑤𝑖∗,𝑗∈𝑝∗ and its closest level-i landmark for some 𝑖≥𝑖∗, ℓ𝑖,𝑗∈𝐿𝑖, let 𝑅𝑖∗,𝑗=𝐷[𝑤𝑖∗,𝑗,ℓ𝑖,𝑗](𝑡𝑜+𝐷[𝑜,𝑤𝑖∗,𝑗](𝑡𝑜)). Then, either 𝑅𝑑≤𝑅𝑖∗,𝑜+…+𝑅𝑖∗,𝑗, in which case an exact solution is returned, or else the following holds (cf. Lemma 9):

𝐷⎯⎯⎯[ℓ𝑖,𝑗,𝑑]≤𝜁1−𝛬min𝑅𝑖∗,𝑗+𝑅𝑑<(1+𝜁1−𝛬min)⋅𝑅𝑑≤/∗ Property  4∗/(1+𝜁1−𝛬min)⋅𝑛(𝛾𝑖−1)/(𝜆𝛾𝑖)⇒𝛤⎯⎯⎯[ℓ𝑖,𝑗,𝑑]≤/∗ Property  4∗/𝑓(𝑛)⋅(𝐷⎯⎯⎯[ℓ𝑖,𝑗,𝑑])𝜆≤𝑓(𝑛)⋅(1+𝜁1−𝛬min)𝜆⋅𝑛(𝛾𝑖−1)/𝛾𝑖≤𝑛[𝑐loglog(𝑛)+𝜆log(1+𝜁1−𝛬min)]log(𝑛)+𝛾𝑖−1𝛾𝑖≤𝑛𝛾𝑖−1𝛾𝑖+𝜉𝑖
for 𝑐,𝜁,𝛬min,𝜆∈(1), 𝑓(𝑛)≤log𝑐(𝑛), and 𝜉𝑖∈𝛺(loglog(𝑛)log(𝑛)). Therefore, we conclude again that 𝑑∈𝐶[ℓ𝑖,𝑗].

Since all the level-(≥𝑖∗) landmarks which were settled from ball centers along the unknown min-cost path are indeed “informed”, the analysis of 𝚁𝚀𝙰+𝑖∗ (cf. Theorem 1 and [17]) provides the claimed approximation guarantee. ◻

We are now ready to provide the proof of our main theorem for 𝙷𝙾𝚁𝙽.

Proof
(Theorem 5) Recall that for each level 𝑖∈[𝑘]: (i) the targeted Dijkstra-rank is 𝑁𝑖=𝑛(𝛾−1)/𝛾𝑖; (ii) the coverage of each level-i landmark contains 𝑐𝑖=𝑁𝑖⋅𝑛𝜉𝑖=𝑛(𝛾−1)/𝛾𝑖+𝜉𝑖 destinations; (iii) the at most 𝐹𝑖=(𝑐𝑖)𝜃/𝜈 “nearby” (but not “too close”) destinations are preprocessed with 𝙱𝙸𝚂+, while the remaining 𝑐𝑖−𝐹𝑖 “faraway” destinations are preprocessed with 𝚃𝚁𝙰𝙿.

We start with the analysis of the preprocessing requirements of 𝙷𝙾𝚁𝙽. We wish to bound the preprocessing requirements with (𝑘+1)⋅𝑛2−𝛽, for a sufficiently small (but still, away from 0) 𝛽>0. We make the appropriate choices of our tuning parameters (cf. Theorem 4 and Corollary 2), so that in each level we are able to guarantee that the expected preprocessing requirements are 𝔼{𝑆𝑖} , 𝔼{𝑃𝑖}∈𝑛2−𝛽+o(1).

We compute the requirements of level-i, for each 𝑖∈[𝑘]. For this level, we generate |𝐿𝑖|=𝑛1−𝜔𝑖 landmarks, where 𝜔𝑖=𝛿𝑟+1⋅𝛾𝑖−1𝛾𝑖, each of which possesses summaries for (almost) all the 𝑐𝑖 destinations contained in its own area of coverage. Based on the analysis of the preprocessing phase of 𝙵𝙻𝙰𝚃 (cf. Theorem 4), but now restricting ourselves within the coverage of each landmark, we know that the overall space preprocessing requirements of level-i are bounded as follows.

𝔼{𝑆𝑖}∈=⊆(𝔼{|𝐿𝑖|}⋅(𝐹2𝑖polylog(𝐹𝑖)+𝑇1−𝜃(𝑐𝑖−𝐹𝑖)))(𝑛1−𝜔𝑖⋅[𝑛2𝜃𝜈(𝛾𝑖−1𝛾𝑖+𝜉𝑖)+o(1)+𝑛𝛼(1−𝜃)+𝛾𝑖−1𝛾𝑖+𝜉𝑖])𝑛1−𝜔𝑖+o(1)⋅[𝑛2𝜃𝜈+𝑛1+𝛼(1−𝜃)]
since we chose 𝜉𝑖∈(𝛺(loglog(𝑛)log(𝑛)) , 1−𝛾−𝑖). Similarly, the time preprocessing is bounded as follows.

𝔼{𝑃𝑖}∈(𝔼{|𝐿𝑖|}⋅(𝐹2𝑖polylog(𝐹𝑖)loglog(𝐾max)+𝑇1−𝜃(𝑐𝑖−𝐹𝑖)log(𝑐𝑖−𝐹𝑖)))=(𝑛1−𝜔𝑖⋅[𝑛2𝜃𝜈(𝛾𝑖−1𝛾𝑖+𝜉𝑖)+o(1)+𝑛𝛼(1−𝜃)+𝛾𝑖−1𝛾𝑖+𝜉𝑖+𝑜(1)])⊆𝑛1−𝜔𝑖+o(1)⋅[𝑛2𝜃𝜈+o(1)+𝑛1+𝛼(1−𝜃)]
Since we have chosen 𝜃=𝜈+𝛼𝜈2+𝛼𝜈, we can ensure that:

𝔼{𝑆𝑖} , 𝔼{𝑃𝑖}∈𝑛2−𝜔𝑖+𝛼(1−𝜃)+o(1)=𝑛2−𝛽𝑖+o(1)
where we have set 𝛽𝑖=𝜔𝑖+𝛼(1−𝜃)=𝛿⋅(𝛾𝑖−1)(𝑟+1)⋅𝛾𝑖−12𝜆+1. Observe that, by demanding that 𝛿>𝛾𝛾−1⋅𝑟+12𝜆+1, we can be sure that 𝛽=𝛿⋅(𝛾−1)(𝑟+1)⋅𝛾−12𝜆+1=min𝑖∈[𝑘+1]{𝛿⋅(𝛾𝑖−1)(𝑟+1)⋅𝛾𝑖−12𝜆+1}>0.

The overall preprocessing requirements of 𝙷𝙾𝚁𝙽 are 𝔼{𝑆𝙷𝙾𝚁𝙽} , 𝔼{𝑃𝙷𝙾𝚁𝙽}∈(𝑘+1)⋅𝑛2−𝛽+o(1)=𝑛2−𝛽+log(𝑘+1)log(𝑛)+o(1)=𝑛2−𝛽+o(1) for 𝑘∈(loglog(𝑛)).

We continue with the analysis of the query algorithm 𝙷𝚀𝙰 of 𝙷𝙾𝚁𝙽. We begin with the probability of 𝙷𝚀𝙰 making a correct guess for the appropriate level 𝑖∗ for the query at hand, provided that it was terminated due to the (𝐀𝐋𝐇) criterion.

Lemma 11 proves that, with probability 1−(1𝑛), at least one appearance of a level-𝑖∗ landmark occurs in the ring of 𝑖∗ around (𝑜,𝑡𝑜): 𝐿𝑖∗∩𝑅𝐼𝑁𝐺[𝑜;𝑖∗](𝑡𝑜)≠∅.

Lemma 12 then proves that the first level-𝑖∗ landmark ℓ𝑖∗,𝑜 settled by the initial 𝚃𝙳𝙳 ball within 𝑅𝐼𝑁𝐺[𝑜;𝑖∗](𝑡𝑜) is indeed an “informed” landmark: 𝑑∈𝐶[ℓ𝑖∗,𝑜].

Lemma 13 proves that no landmark of a previous level 𝑗<𝑖∗, which is settled before ℓ𝑖∗,𝑜, can be at the “right distance” and “informed”, without causing an (ESC) termination: ∀ℓ∈∪𝑗∈[𝑖∗−1](𝐿𝑗∩𝑅𝐼𝑁𝐺[𝑜;𝑗](𝑡𝑜)), 𝑑∉𝐶[ℓ], or settling ℓ implies (ESC) termination.

For any landmark ℓ∈∪𝑘+1𝑗=𝑖∗+1𝐿𝑗, if we settle ℓ before ℓ𝑖∗,𝑜 and it happens that 𝑑∈𝐶[ℓ] (i.e., ℓ is “informed”), this event will not interrupt the guessing procedure of 𝙷𝚀𝙰, because it is not in the ring corresponding to the level containing ℓ.

Therefore we conclude that, in the case of an (ALH) termination, with probability 1−(1𝑛), the “guess” of the appropriate level-𝑖∗ is indeed correct.

We now turn to the approximation guarantee. If 𝙷𝚀𝙰 terminates because of settling d then we have an exact answer. If the (𝐄𝐒𝐂) criterion caused termination, then Lemma 10.(ii) shows that we get the claimed approximation guarantee. If the (𝐀𝐋𝐇) criterion caused termination, then Lemma 14 states that we get the same approximation guarantee, with high probability.

Finally, regarding the query-time of 𝙷𝚀𝙰, note that this is dominated by the scenario in which the (ALH) criterion causes termination (if the initial 𝚃𝙳𝙳 ball settled the destination d, or terminated due to the (ESC) criterion, this can only improve the performance of 𝙷𝚀𝙰). Again from Lemma 14 we know that the expected query time in this case is (𝑁𝛿+o(1)𝑖∗), where 𝑖∗∈{2,3,…,𝑘+1} is the appropriate level for the query at hand: 𝑁𝑖∗−1=𝑛𝛾𝑖∗−1−1𝛾𝑖∗−1<𝛤[𝑜,𝑑](𝑡𝑜)≤𝑛𝛾𝑖∗−1𝛾𝑖∗=𝑁𝑖∗. The unlikely event of guessing a wrong value instead of 𝑖∗ has, as was already explained in the the proof of Lemma 14, a negligible contribution to the overall expected query-time. ◻

Conclusions
We presented and theoretically analyzed three oracles for sparse networks with a time-dependent, piecewise linear, and periodic travel-time metric via an axiomatic approach based on four fundamental properties of the arc-cost metric. These properties were inspired and verified in real-world road network instances. Our axiomatic approach achieves (for the first time): (a) subquadratic time and space preprocessing, which is independent in the amount of disconcavity of the travel-time metric (expressed by the parameter 𝐾∗, which is the number of concavity spoiling breakpoints in all arc functions); (b) sublinear query time not only on the network size n but also on the (unknown) Dijkstra-rank of the query at hand.

The key novelties of our approach are: (i) a remarkably simple and novel FPTAS (𝚃𝚁𝙰𝙿) for efficiently computing one-to-all distance summaries (a.k.a. query profiles in the algorithm engineering jargon) from a selected vertex to all other vertices in the network; (ii) the organization of a small subset of vertices (landmarks) in a hierarchical structure in such a way that landmarks at the lower levels of the hierarchy posses travel-time summaries to “nearby” destinations, while landmarks at the upper levels of the hierarchy possess distance summaries also to “faraway” (and eventually to all) destinations. This allowed for an adaptive query algorithm (𝙷𝚀𝙰) which achieves sublinearity compared to the Dijkstra-rank of the query at hand, rather than just the network size.

Directions for future research constitute the further improvement of the bounds of the presented TD-oracles, as well as an extensive practical assessment and simplification of the hierarchical (𝙷𝙾𝚁𝙽) oracle.

