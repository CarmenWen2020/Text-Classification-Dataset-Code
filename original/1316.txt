Abstract
We consider the following dynamic load-balancing process: given an underlying graph G with n nodes, in each step 𝑡≥0, a random edge is chosen, one unit of load is created, and placed at one of the endpoints. In the same step, assuming that loads are arbitrarily divisible, the two nodes balance their loads by averaging them. We are interested in the expected gap between the minimum and maximum loads at nodes as the process progresses, and its dependence on n and on the graph structure. Peres et al. (Random Struct Algorithms 47(4):760–775, 2015) studied the variant of this process, where the unit of load is placed in the least loaded endpoint of the chosen edge, and the averaging is not performed. In the case of dynamic load balancing on the cycle of length n the only known upper bound on the expected gap is of order (𝑛log𝑛), following from the majorization argument due to the same work. In this paper, we leverage the power of averaging and provide an improved upper bound of (𝑛√log𝑛). We introduce a new potential analysis technique, which enables us to bound the difference in load between k-hop neighbors on the cycle, for any 𝑘≤𝑛/2. We complement this with a “gap covering” argument, which bounds the maximum value of the gap by bounding its value across all possible subsets of a certain structure, and recursively bounding the gaps within each subset. We also show that our analysis can be extended to the specific instance of Harary graphs. On the other hand, we prove that the expected second moment of the gap is lower bounded by Ω(𝑛). Additionally, we provide experimental evidence that our upper bound on the gap is tight up to a logarithmic factor.

Introduction
This paper considers balls-into-bins processes where a sequence of m weights are placed into n bins via some randomized procedure, with the goal of minimizing the load imbalance between the most loaded and the least loaded bin. This family of randomized processes has been used to model several practical allocation problems, such as load-balancing [3, 14, 20], hashing [9], or even relaxed data structures [1, 2].

The classic formulation of this problem is known as d-choice process, in each step, a new weight is generated, and is placed in the least loaded of d randomly chosen bins. If 𝑑=1, then we have the uniform random choice scheme, whose properties are well understood, e.g. [18]. In particular, if we place 𝑚=𝑛 unit weights into the bins, then it is known that the most loaded bin will have expected Θ(log𝑛/loglog𝑛) load, whereas if 𝑚=Ω(𝑛log𝑛) we have that the expected maximum load is 𝑚/𝑛+Θ(𝑚log𝑛/𝑛‾‾‾‾‾‾‾‾‾√). Seminal work by Azar et al. [3] showed that, if we place n unit weights into n bins by the d-choice process with 𝑑≥2, then, surprisingly, the maximum load is reduced to Θ(loglog𝑛/log𝑑). A technical tour-de-force by Berenbrink, Czumaj, Steger, and Vöcking [4] extended this result to the “heavily-loaded” case where 𝑚≫𝑛, showing that in this case the maximum load is 𝑚/𝑛+loglog𝑛/log𝑑+𝑂(1) with failure probability at most 1/ poly𝑛. An elegant alternative proof for a slightly weaker version of this result was later provided by Talwar and Wieder [23].

More recently, Peres et al. [17] considered the graphical version of this process, where the bins are the vertices of a graph, an edge is chosen at every step, and the weight is placed at the less loaded endpoint of the edge, breaking ties arbitrarily. (The reader will notice that the classic 2-choice process corresponds to the case where the graph is a clique.) The authors focus on the evolution of the gap between the highest and lowest loaded bins, showing that, for graphs of 𝛽-edge-expansion [17], this gap is 𝑂(log𝑛/𝛽), with probability 1−1/poly𝑛.

Another closely related line of work considers static load-balancing processes, where each node in a graph starts with an arbitrary initial load, and the endpoints average their current loads at each step. Note that load balancing schemes which are commonly used in this setting are usually more involved than simply averaging the loads of the endpoints of the randomly chosen node, but the tools used in their analysis are still applicable to the static version of our process. To analyze such processes, it is common to map the process to a Markov chain and analyse its convergence [6, 10, 12], or derive an upper bound on a potential function which captures the discrepancy between the loads [5]. In both cases, the gap between the highest and lowest loaded bins can be characterized by the spectral gap of the graph [7, 11, 19, 21, 22].

By contrast to these two lines of previous work, in this paper we consider a graphical load balancing in the dynamic case, where weights arrive at each step rather than being statically allocated initially, but we allow balancing via continuous averaging, i.e. the resulting weights after the balancing step equal the average of the sum of the weights of the two nodes prior to balancing. Thus, our averaging step is more powerful relative to d-choice or static averaging, but it is applied in the more challenging dynamic scenario.

We will focus on the gap in the dynamic case on graphs of low expansion, specifically on cycles. In [17], it is shown that, in this case (but without averaging), the gap is 𝑂(𝑛log𝑛) both in expectation and with high probability. The techniques used in [17] imply that the averaging of the loads does not worsen the gap in expectation, our aim is to show that it actually helps to reduce it. Also, directly applying the tools from the static process to the dynamic one results in the upper bound which is larger than 𝑂(𝑛log𝑛). Upper bounding the gap for cycle graphs is known to be a challenging open problem [16]. As suggested in [17], to deal with the cycle case, there is a need for a new approach, which takes the structure of the load balancing graph into account.

Contribution
In this paper, we address this question for the case where averaging is performed on a cycle graph. Let Gap(t) be a difference between highest and lowest loads of the nodes at time step t. We provide the upper bound on the gap in the dynamic, heavily-loaded case, via a new potential argument. More formally, for any 𝑡>0, we show that for a cycle graph with n vertices:

𝔼[𝐺𝑎𝑝(𝑡)]=𝑂(𝑛√log(𝑛)).
(1)
We show that our technique can be used to upper bound the gap for the 4-connected Harary Graph. We complement this result with a lower bound of Ω(𝑛) on 𝔼[(𝐺𝑎𝑝(𝑡))2]. Further, we provide experimental evidence that the gap is of order Θ(𝑛√), making our upper bound accurate up to a log𝑛 factor. Our results extend to the case where the load generated at each node is weighted according to some distribution whose second moment is bounded. Formally, we allow our input to come from any distribution W, such that 𝔼[𝑊2]≤𝑀2, for some 𝑀>0.

Technical Overview
Our upper bound result is based on two main ideas. The first introduces a new parametrized hop-potential function, which measures the squared difference in load between any k-hop neighbors on the graph, where 𝑘≥1 is a fixed hop parameter. Let 𝐺=(𝑉,𝐸) be our input graph, where 𝑉={1,2,…,𝑛}. Throughout the paper, for any 1≤𝑖≤𝑛 we assume that the nodes 𝑖+𝑛 and 𝑖−𝑛 are the same as the node i. Let 𝑥𝑖(𝑡) be the load of node i at step t. Then, we define the k-hop potential as:

𝜙𝑘(𝑡)=∑𝑖=1𝑛(𝑥𝑖(𝑡)−𝑥𝑖+𝑘(𝑡))2.
The first technical step in the proof is to understand the expected (“steady-state”) value of the k-hop potential. We show that, in expectation, the k-hop potential has a recursive structure. While the expected values of k-hop potentials cannot be computed precisely, we can isolate upper and lower bounds on their values for cycles. In particular, for the k-hop potential on an n-cycle, we prove the following bound:

𝔼[𝜙𝑘(𝑡)]≤𝑘(𝑛−𝑘)−1,∀𝑘≥1.
(2)
In the second technical step, we shift gears, aiming to bound the maximum possible value of the gap between any two nodes, leveraging the fact that we understand the hop potential for any 𝑘≥1. We achieve this via a “gap covering” technique, which characterizes the maximum value of the gap across all possible subsets of a certain type.

More precisely, in the case of a cycle of length 𝑛=2𝑚, for each node i and hop count k, we define the set family 𝐴𝑖𝑘 to be formed of nodes {𝑖,𝑖+2𝑚−𝑘,𝑖+2×2𝑚−𝑘,𝑖+3×2𝑚−𝑘,…} (since we are on a cycle, 𝑖=𝑖+2𝑚−𝑘2𝑘). Then for any 1≤𝑘≤𝑚, we will have

∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+𝑛2𝑚−𝑘‾‾‾‾‾√𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√,
(3)
where 𝐺𝑎𝑝𝑋(𝑡) is the maximal gap inside the set X at time t. Intuitively, this result allows us recursively characterize the gap value at various “resolutions” across the graph.

Finally, we notice that we can “cover” the gap between any two nodes by carefully unwinding the recursion in the above inequality, considering all possible subsets of a well-chosen structure, and recursively bounding the gaps within each subset (this step is particularly delicate in the case where n is not a power of two, please see Sect. 5). We obtain that

𝔼[𝐺𝑎𝑝(𝑡)]=𝑂(𝑛√log(𝑛)),
(4)
as claimed. The logarithmic slack is caused by the second term on the right-hand-side of (2). We note that this technique extends to the case where inserted items are weighted, where the weights are coming from some distribution of bounded second moment.

Lower Bound
It is interesting to ask whether this upper bound is tight. To examine this question, we revisit the recursive structure of the k-hop potential, which we used to obtain the upper bound in Eq. (3). We can leverage this structure to obtain a lower bound on the expected k-hop potential as well. Starting from this lower bound, we can turn the upper bound argument “inside out,” to obtain a linear lower bound on the expected squared gap:

𝔼[𝐺𝑎𝑝(𝑡)2]=Ω(𝑛).
(5)
We conjecture that both upper and lower bounds on the expected gap are of order 𝑂(𝑛√) (given that 𝐸[𝑊2] is constant), and examine this claim empirically in Sect. 6.

Extensions and Discussion
We believe that the analysis template we described above is general, and can be extended to other graph families, such as regular expanders. Here, we focus on obtaining tight bounds on the gap for cycles, which is technically non-trivial, and leave the extensions for other graph families as future work. To substantiate our generality claim, we exhibit an application of our analysis technique to the specific instance of Harary graphs [13] in Sect. 7. More precisely, we provide the upper bound on a gap for a graph on n vertices, where each vertex i is connected with edges to vertices 𝑖−2,𝑖−1,𝑖+1 and 𝑖+2.

We discuss the relation between our results and bounds for the graphical power-of-two process on a cycle [17] in Sect. 8.

Related Work
As we have already discussed broad background, we will now mainly focus on the technical differences from previous work. As stated, we are the first to specifically consider the dynamic case for continuous averaging on cycles. The static case has been studied both with continuous averaging [5,6,7, 10,11,12, 19, 22] and discrete averaging [21]. However, their techniques would not apply (or would result in a worse bound) in our case, since we consider that weights would be introduced dynamically, during the processes’ execution.

To our knowledge, the only non-trivial upper bound on the gap of the process we consider which would follow from previous work is of (𝑛log𝑛), by the potential analysis of [17]: they consider 2-choice load balancing, and one can re-do their potential analysis for (continuous) averaging load balancing, yielding the same bounds. (Specifically, one can use the same definition of the potential Γ(𝑡) as in this reference, and will obtain the same upper bounds, since the pairwise load balancing we consider has slightly stronger guarantees.) However, as our bounds show, the resulting analysis is quite loose in the case of cycle graphs, yielding an Ω(𝑛√) gap between the bounds yielded by these techniques. Technically, this is a consequence of the majorization technique used in [17], which links dynamic averaging on the cycle with a very weak form of averaging on the clique. Reference [8] studies the performance differences between various load-balancing techniques; specifically, it shows that continuous averaging cannot improve the bound on the gap relative to d-choice on the clique. Unfortunately, this result does not seem to extend to arbitrary graphs.

Our potential analysis is substantially different from that of [17], as they track a sum of exponential potentials across the entire graph. By contrast, our analysis tracks the squared load differences between k-hop neighbors, establishing recurrences between these potentials. We note that this is also different from the usual square potentials used for analyzing averaging load balancing, e.g. [15], which usually compare against the global mean, as opposed to pairwise potential differences. Our approach is also different from the classic analyses of e.g. [3], which perform probabilistic induction on the number of bins at a given load, assuming a clique.

Generally, our technique can be seen as performing the induction needed to bound the gap not on the bin loads, as is common in previous work, e.g. [3], but over the topology of the graph. This approach is natural, since we wish to obtain tight, topology-specific bounds, but we believe we are the first to propose and analyze it successfully.

Averaging on the Cycle: Upper Bounding the Gap
Preliminaries
We consider a cycle graph 𝐺=(𝑉,𝐸) where 𝑉={1,2,…,𝑛}, such that each node i is connected to its left and right neighbors, 𝑖−1 and 𝑖+1 (recall that for any 1≤𝑖≤𝑛 the nodes 𝑖+𝑛 and 𝑖−𝑛 are the same as the node i).

We consider a stochastic process following real time 𝑡≥0, in which, at each step 𝑡+1, a ball of weight 𝑤(𝑡)≥0 is generated from a same distribution W. We associate a real-valued load 𝑥𝑖(𝑡) with each node i (𝑥𝑖(𝑡) is the value after t steps). Initially, we have that 𝑥𝑖(0)=0 for every node i. At step 𝑡+1, an edge (𝑖,𝑖+1) is chosen uniformly at random, and the two endpoint nodes update their weights as follows:

𝑥𝑖(𝑡+1)=𝑥𝑖+1(𝑡+1)=𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2.
We will assume that the second moment of the distribution W is bounded. That is: 𝐸[𝑊2]≤𝑀2, for some 𝑀>0. For simplicity, we will assume that weights are normalized by M. This gives us that 𝔼[𝑊2]≤1.

Let 𝑋(𝑡)=(𝑥1(𝑡),𝑥2(𝑡),…,𝑥𝑛(𝑡)) be the vector of the bin weights after step t. First, we define the following potential functions:

∀𝑘∈{1,2,…,𝑛−1}:𝜙𝑘(𝑡):=∑𝑖=1𝑛(𝑥𝑖(𝑡)−𝑥𝑖+𝑘(𝑡))2.
Notice that for every 1≤𝑖≤𝑛, we have that 𝜙𝑖(𝑡)=𝜙𝑛−𝑖(𝑡). We want to analyze what is the value of these functions in expectation after an additional ball is thrown, for a given load vector X(t).

We start with 𝜙1(𝑡+1):

𝔼[𝜙1(𝑡+1)|𝑋(𝑡),𝑤(𝑡)]=∑𝑖=1𝑛1𝑛((𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖+2(𝑡))2+(𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖−1(𝑡))2+∑𝑗≠𝑖−1,𝑖,𝑖+1(𝑥𝑗(𝑡)−𝑥𝑗+1(𝑡))2).
(6)
Notice that:

∑𝑖=1𝑛∑𝑗≠𝑖−1,𝑖,𝑖+1(𝑥𝑗(𝑡)−𝑥𝑗+1(𝑡))2=(𝑛−3)𝜙1(𝑡).
(7)
Hence we need to bound the remaining terms:

∑𝑖=1𝑛((𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖+2(𝑡))2+(𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖−1(𝑡))2)=∑𝑖=1𝑛(2𝑥𝑖(𝑡)2+2𝑥𝑖+1(𝑡)2+2𝑤(𝑡)2+4𝑥𝑖(𝑡)𝑥𝑖+1(𝑡)4+𝑥𝑖+2(𝑡)2+𝑥𝑖−1(𝑡)2−(𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡))(𝑥𝑖−1(𝑡)+𝑥𝑖+2(𝑡))).
where we used the fact that terms, which are linear in w(t), cancel out.

The right side of the above equation can be rewritten as:

∑𝑖=1𝑛𝑥𝑖(𝑡)22+∑𝑖=1𝑛𝑥𝑖+1(𝑡)22+∑𝑖=1𝑛𝑥𝑖+2(𝑡)2+∑𝑖=1𝑛𝑥𝑖−1(𝑡)2+∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+1(𝑡)−∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖−1(𝑡)−∑𝑖=1𝑛𝑥𝑖+1(𝑡)𝑥𝑖+2(𝑡)−∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+2(𝑡)−∑𝑖=1𝑛𝑥𝑖+1(𝑡)𝑥𝑖−1(𝑡)+𝑛𝑤(𝑡)22=3∑𝑖=1𝑛𝑥𝑖(𝑡)2−∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+1(𝑡)−2∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+2(𝑡)+𝑛𝑤(𝑡)22=∑𝑖=1𝑛(𝑥𝑖(𝑡)−𝑥𝑖+1(𝑡))22+∑𝑖=1𝑛(𝑥𝑖(𝑡)−𝑥𝑖+2(𝑡))2+𝑛𝑤(𝑡)22=𝜙1(𝑡)2+𝜙2(𝑡)+𝑛𝑤(𝑡)22.
By using the above equation and Eq. (7) in Eq. (6) we get that

𝔼[𝜙1(𝑡+1)|𝑋(𝑡),𝑤(𝑡)]=𝑛−2𝑛𝜙1(𝑡)+12(𝑤(𝑡)2−𝜙1(𝑡)𝑛)+𝜙2(𝑡)𝑛.
Now, we proceed with calculating the expected value of 𝜙𝑘(𝑡+1),

for 2≤𝑘≤⌊𝑛/2⌋:

𝔼[𝜙𝑘(𝑡+1)|𝑋(𝑡),𝑤(𝑡)]=∑𝑖=1𝑛1𝑛((𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖−𝑘(𝑡))2+(𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖+1−𝑘(𝑡))2+(𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖+𝑘(𝑡))2+(𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡)+𝑤(𝑡)2−𝑥𝑖+1+𝑘(𝑡))2+∑𝑗≠𝑖−𝑘,𝑖+1,𝑖,𝑖+1(𝑥𝑗(𝑡)−𝑥𝑗+𝑘(𝑡))2).
Notice that:

1𝑛∑𝑖=1𝑛∑𝑗≠𝑖−𝑘,𝑖+1−𝑘,𝑖+𝑘,𝑖+1+𝑘(𝑥𝑗(𝑡)−𝑥𝑗+𝑘(𝑡))2=𝑛−4𝑛𝜙𝑘(𝑡).
In the similar way as for 𝜙1(𝑡) the remaining terms can be rewritten as:

∑𝑖=1𝑛1𝑛(𝑥𝑖(𝑡)2+𝑥𝑖+1(𝑡)2+𝑤(𝑡)2+2𝑥𝑖(𝑡)𝑥𝑖+1(𝑡)+4𝑥2𝑖(𝑡)−(𝑥𝑖(𝑡)+𝑥𝑖+1(𝑡))(𝑥𝑖+𝑘(𝑡)+𝑥𝑖+𝑘+1(𝑡)+𝑥𝑖−𝑘(𝑡)+𝑥𝑖−𝑘+1(𝑡)))=1𝑛(𝑛𝑤(𝑡)2+6∑𝑖=1𝑛𝑥𝑖(𝑡)2+2∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+1(𝑡)−4∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+𝑘(𝑡)−2∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+𝑘+1(𝑡)−2∑𝑖=1𝑛𝑥𝑖(𝑡)𝑥𝑖+𝑘−1(𝑡))=2𝑛𝜙𝑘(𝑡)+(𝑤(𝑡)2−𝜙1(𝑡)𝑛)+𝜙𝑘+1(𝑡)𝑛+𝜙𝑘−1(𝑡)𝑛.
Hence, we get that:

𝔼[𝜙𝑘(𝑡+1)|𝑋(𝑡),𝑤(𝑡)]=𝑛−2𝑛𝜙𝑘(𝑡)+(𝑤(𝑡)2−𝜙1(𝑡)𝑛)+𝜙𝑘+1(𝑡)𝑛+𝜙𝑘−1(𝑡)𝑛.
If we remove conditioning on w(t) (note that 𝔼[𝑤(𝑡)2]=𝔼[𝑊2]) and express these equations for

𝜙1(𝑡+1),𝜙2(𝑡+1),…,𝜙𝑛−1(𝑡+1) (recall that 𝜙𝑘(𝑡)=𝜙𝑛−𝑘(𝑡)), we get:

⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪𝔼[𝜙1(𝑡+1)|𝑋(𝑡)]=(𝑛−2𝑛)𝜙1(𝑡)+12(𝔼[𝑊2]−𝜙1(𝑡)𝑛)+𝜙2(𝑡)𝑛.𝔼[𝜙2(𝑡+1)|𝑋(𝑡)]=(𝑛−2𝑛)𝜙2(𝑡)+(𝔼[𝑊2]−𝜙1(𝑡)𝑛)+𝜙1(𝑡)𝑛+𝜙3(𝑡)𝑛.…𝔼[𝜙⌊𝑛2⌋(𝑡+1)|𝑋(𝑡)]=(𝑛−2𝑛)𝜙⌊𝑛2⌋(𝑡)+(𝔼[𝑊2]−𝜙1(𝑡)𝑛)+𝜙⌊𝑛2⌋−1(𝑡)𝑛+𝜙⌊𝑛2⌋+1(𝑡)𝑛.…𝔼[𝜙𝑛−2(𝑡+1)|𝑋(𝑡)]=(𝑛−2𝑛)𝜙𝑛−2(𝑡)+(𝔼[𝑊2]−𝜙1(𝑡)𝑛)+𝜙𝑛−3(𝑡)𝑛+𝜙𝑛−1(𝑡)𝑛.𝔼[𝜙𝑛−1(𝑡+1)|𝑋(𝑡)]=(𝑛−2𝑛)𝜙𝑛−1(𝑡)+12(𝔼[𝑊2]−𝜙1(𝑡)𝑛)+𝜙𝑛−2(𝑡)𝑛.
(8)
Using the above equations we can prove the following:

Lemma 1
For every 𝑡≥0 and 1≤𝑘≤𝑛−1, we have that

𝔼[𝜙𝑘(𝑡)]≤(𝑘(𝑛−𝑘)−1)𝔼[𝑊2]≤𝑘(𝑛−𝑘)−1.
(9)
Proof
Let Φ(𝑡)=(𝜙1(𝑡),𝜙2(𝑡),…,𝜙𝑛−1(𝑡)) be the vector of values of our potentials at time step t and let 𝑌=(𝑦1,𝑦2,…,𝑦𝑛−1), be the vector containing our desired upper bounds for each potential. That is: for each 1≤𝑖≤𝑛−1, we have that 𝑦𝑖=(𝑖(𝑛−𝑖)−1)𝔼[𝑊2].

An interesting and easily checkable thing about the vector Y is that

𝔼[Φ(𝑡+1)|Φ(𝑡)=𝑌]=𝑌.
(10)
Next, consider the vector 𝑍(𝑡)=(𝑧1(𝑡),𝑧2(𝑡),…𝑧𝑛−1(𝑡))=𝑌−Φ(𝑡). Our goal is to show that for every step t and coordinate i, 𝔼[𝑧𝑖(𝑡)]≥0.

We have that

𝔼[𝑧1(𝑡+1)|𝑋(𝑡)]=𝑦1−𝔼[𝜙1(𝑡+1)|𝑋(𝑡)]=(𝑛−2𝑛)𝑦1+12(𝔼[𝑊2]−𝑦1𝑛)+𝑦2𝑛−((𝑛−2𝑛)𝜙1(𝑡)+12(𝔼[𝑊2]−𝜙1(𝑡)𝑛)+𝜙2(𝑡)𝑛)=(𝑛−2𝑛)𝑧1(𝑡)−𝑧1(𝑡)2𝑛+𝑧2(𝑡)𝑛.
and for 2≤𝑖≤⌊𝑛2⌋, we have that

𝔼[𝑧𝑖(𝑡+1)|𝑋(𝑡)]=(𝑛−2𝑛)𝑧𝑖(𝑡)−𝑧1(𝑡)𝑛+𝑧𝑖+1(𝑡)𝑛+𝑧𝑖−1(𝑡)𝑛.
Hence we get the following equations (recall that 𝑧𝑖(𝑡)=𝑧𝑛−𝑖(𝑡)):

⎧⎩⎨⎪⎪⎪⎪⎪⎪𝑛×𝔼[𝑧1(𝑡+1)|𝑋(𝑡)]=(𝑛−2−12)𝑧1(𝑡)+𝑧2(𝑡).𝑛×𝔼[𝑧2(𝑡+1)|𝑋(𝑡)]=−𝑧1(𝑡)+𝑧1(𝑡)+(𝑛−2)𝑧2(𝑡)+𝑧3(𝑡).𝑛×𝔼[𝑧3(𝑡+1)|𝑋(𝑡)]=−𝑧1(𝑡)+𝑧2(𝑡)+(𝑛−2)𝑧3(𝑡)+𝑧4(𝑡).…𝑛×𝔼[𝑧⌊𝑛2⌋(𝑡+1)|𝑋(𝑡)]=−𝑧1(𝑡)+𝑧⌊𝑛2⌋−1(𝑡)+(𝑛−2)𝑧⌊𝑛2⌋(𝑡)+𝑧⌊𝑛2⌋+1(𝑡).
(11)
Next, using induction on t, we show that for every 𝑡≥0

0≤𝔼[𝑧1(𝑡)]≤𝔼[𝑧2(𝑡)]≤⋯≤𝔼[𝑧⌊𝑛2⌋(𝑡)].
(12)
The base case holds trivially since 𝑍(0)=𝑌. For the induction step, assume that

0≤𝔼[𝑧1(𝑡)]≤𝔼[𝑧2(𝑡)]≤⋯≤𝔼[𝑧⌊𝑛2⌋(𝑡)]. First, we have that

𝑛𝔼[𝑧1(𝑡+1)]=𝑛𝔼𝑋(𝑡)[𝔼[𝑧1(𝑡+1)|𝑋(𝑡)]]=(𝑛−2−12)𝔼[𝑧1(𝑡)]+𝔼[𝑧2(𝑡)]≥0.
Additionally, we have that:

𝑛𝔼[𝑧1(𝑡+1)]=(𝑛−2−12)𝔼[𝑧1(𝑡)]+𝔼[𝑧2(𝑡)]≤(𝑛−2)𝔼[𝑧1(𝑡)]+𝔼[𝑧2(𝑡)]≤(𝑛−2)𝔼[𝑧2(𝑡)]+𝔼[𝑧3(𝑡)]=𝑛𝔼[𝑧2(𝑡+1)].
For 2≤𝑖≤⌊𝑛2⌋−2, we have that

𝑛𝔼[𝑧𝑖(𝑡+1)]=−𝔼[𝑧1(𝑡)]+𝔼[𝑧𝑖−1(𝑡)]+(𝑛−2)𝔼[𝑧𝑖(𝑡)]+𝔼[𝑧𝑖+1(𝑡)]≤−𝔼[𝑧1(𝑡)]+𝔼[𝑧𝑖(𝑡)]+(𝑛−2)𝔼[𝑧𝑖+1(𝑡)]+𝔼[𝑧𝑖+2(𝑡)]=𝑛𝔼[𝑧𝑖+1(𝑡+1)].
Next, observe that by our assumption:

𝔼[𝑧⌊𝑛2⌋+1(𝑡)]=𝔼[𝑧⌈𝑛2⌉−1(𝑡)]≥𝔼[𝑧⌊𝑛2⌋−2(𝑡)]. Finally, by using this observation we get that

𝑛𝔼[𝑧⌊𝑛2⌋−1(𝑡+1)]=−𝔼[𝑧1(𝑡)]+𝔼[𝑧⌊𝑛2⌋−2(𝑡)]+(𝑛−2)𝔼[𝑧⌊𝑛2⌋−1(𝑡)]+𝔼[𝑧⌊𝑛2⌋(𝑡)]≤−𝔼[𝑧1(𝑡)]+𝔼[𝑧⌊𝑛2⌋+1(𝑡)]+𝔼[𝑧⌊𝑛2⌋−1(𝑡)]+(𝑛−3)𝔼[𝑧⌊𝑛2⌋−1(𝑡)]+𝔼[𝑧⌊𝑛2⌋(𝑡)]≤−𝔼[𝑧1(𝑡)]+𝔼[𝑧⌊𝑛2⌋+1(𝑡)]+𝔼[𝑧⌊𝑛2⌋−1(𝑡)]+(𝑛−2)𝔼[𝑧⌊𝑛2⌋(𝑡)]=𝑛𝔼[𝑧⌊𝑛2⌋(𝑡+1)].
This completes the proof of the lemma. ◻

Upper Bound on the Gap for 𝑛=2𝑚
In this section we upper bound a gap in expectation for the case when 𝑛=2𝑚. is quite technical but not necessarily more interesting, and is provided in the Sect. 5.

We begin with some definitions. For a set 𝐴⊆{1,2,…,𝑛}, let

𝐺𝑎𝑝𝐴(𝑡)=max𝑖∈𝐴𝑥𝑖(𝑡)−min𝑖∈𝐴𝑥𝑖(𝑡).
Also, let 𝐴𝑖𝑘 be {𝑖,𝑖+2𝑚−𝑘,𝑖+2×2𝑚−𝑘,𝑖+3×2𝑚−𝑘,…} (Notice that 𝑖=𝑖+2𝑚−𝑘2𝑘). Our proof works as follows: for each 1≤𝑖≤𝑛 and 1≤𝑘≤𝑚, we look at the vertices given by the sets 𝐴𝑖𝑘−1 and 𝐴𝑖+2𝑚−𝑘𝑘−1 and try to characterise the gap after we merge those sets (note that this will give us the gap for the set 𝐴𝑖𝑘=𝐴𝑖𝑘−1∪𝐴𝑖+2𝑚−𝑘𝑘−1). Using this result, we are able to show that ∑𝑛𝑖=1𝐺𝑎𝑝𝐴𝑖𝑘(𝑡) is upper bounded by ∑𝑛𝑖=1𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡) plus n times maximum load difference between vertices at hop distance 2𝑚−𝑘. Next, we use 2𝑚−𝑘 hop distance potential 𝜙2𝑚−𝑘(𝑡) to upper bound maximum load difference between the vertices at hop distance 2𝑚−𝑘. By summing up the derived inequality for 𝑘=1 to m, we are able to upper bound ∑𝑛𝑖=1𝐺𝑎𝑝𝐴𝑖𝑚(𝑡) in terms of ∑𝑛𝑖=1𝐺𝑎𝑝𝐴𝑖0(𝑡) and ∑𝑚𝑘=1𝜙2𝑚−𝑘(𝑡). Notice that by our definitions, for each i, 𝐺𝑎𝑝𝐴𝑖0(𝑡)=0 (𝐴𝑖0 contains only vertex i) and 𝐺𝑎𝑝𝐴𝑖𝑚(𝑡)=𝐺𝑎𝑝(𝑡) (𝐴𝑖𝑚 contains all vertices). Hence, what is left is to use the upper bounds for the hop distance potentials, which we derived in the previous section.

We start by proving the following useful lemma.

Lemma 2
For any 1≤𝑖≤𝑛 and 1≤𝑘≤𝑚, we have that

2𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤2max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|+𝐺𝑎𝑝𝐴𝑖+2𝑚−𝑘𝑘−1(𝑡)+𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡).
(13)
Proof
Fix vertex i. Recall that 𝐴𝑖𝑘=𝐴𝑖𝑘−1∪𝐴𝑖+2𝑚−𝑘𝑘−1.

Let 𝑢=argmax𝑗∈𝐴𝑖𝑘𝑥𝑗(𝑡) and let 𝑣=argmin𝑗∈𝐴𝑖𝑘𝑥𝑗(𝑡). We consider several cases on the membership of nodes u and v, and bound the gap in each one:

Case 1 𝑢∈𝐴𝑖𝑘−1 and 𝑣∈𝐴𝑖𝑘−1. Then 𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)=𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡) and we have that

𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)=|𝑥𝑢(𝑡)−𝑥𝑣(𝑡)|≤|𝑥𝑢+2𝑚−𝑘(𝑡)−𝑥𝑢(𝑡)|+|𝑥𝑣+2𝑚−𝑘(𝑡)−𝑥𝑣(𝑡)|+|𝑥𝑢+2𝑚−𝑘(𝑡)−𝑥𝑣+2𝑚−𝑘(𝑡)|≤|𝑥𝑢+2𝑚−𝑘(𝑡)−𝑥𝑢(𝑡)|+|𝑥𝑣+2𝑚−𝑘(𝑡)−𝑥𝑣(𝑡)|+𝐺𝑎𝑝𝐴𝑖+2𝑚−𝑘𝑘−1(𝑡)≤2max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|+𝐺𝑎𝑝𝐴𝑖+2𝑚−𝑘𝑘−1(𝑡),
where we used the fact that both 𝑢+2𝑚−𝑘 and 𝑣+2𝑚−𝑘 belong to 𝐴𝑖+2𝑚−𝑘𝑘−1. This gives us that

2𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤2max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|+𝐺𝑎𝑝𝐴𝑖+2𝑚−𝑘𝑘−1(𝑡)+𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡).
(14)
Case 2 𝑢∈𝐴𝑖𝑘−1 and 𝑣∈𝐴𝑖+2𝑚−𝑘𝑘−1. Then we have that:

𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)=|𝑥𝑢(𝑡)−𝑥𝑣(𝑡)|≤|𝑥𝑢(𝑡)−𝑥𝑣+2𝑚−𝑘(𝑡)|+|𝑥𝑣+2𝑚−𝑘(𝑡)−𝑥𝑣(𝑡)|≤𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+max𝑗∈𝐴𝑖𝑘(|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|)
and

𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)=|𝑥𝑢(𝑡)−𝑥𝑣(𝑡)|≤|𝑥𝑢(𝑡)−𝑥𝑢+2𝑚−𝑘(𝑡)|+|𝑥𝑢+2𝑚−𝑘(𝑡)−𝑥𝑣(𝑡)|≤𝐺𝑎𝑝𝐴𝑖+2𝑚−𝑘𝑘−1(𝑡)+max𝑗∈𝐴𝑖𝑘(|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|),
where we used 𝑣+2𝑚−𝑘∈𝐴𝑖𝑘−1 and 𝑢+2𝑚−𝑘∈𝐴𝑖+2𝑚−𝑘𝑘−1. Hence, we again get that

2𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤2max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|+𝐺𝑎𝑝𝐴𝑖+2𝑚−𝑘𝑘−1(𝑡)+𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡).
(15)
Case 3 𝑢∈𝐴𝑖+2𝑚−𝑘𝑘−1 and 𝑣∈𝐴𝑖+2𝑚−𝑘𝑘−1, is similar to Case 1.

Case 4 𝑣∈𝐴𝑖𝑘−1 and 𝑢∈𝐴𝑖+2𝑚−𝑘𝑘−1, is similar to Case 2.

◻

Next, we upper bound the quantity ∑𝑛𝑖=1max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|.

Lemma 3
For any 1≤𝑘≤𝑚:

∑𝑖=1𝑛max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|≤𝑛2𝑚−𝑘‾‾‾‾‾√𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√.
(16)
Proof
Notice that for any i and 𝑖′∈𝐴𝑖𝑘, we have that 𝐴𝑖𝑘=𝐴𝑖′𝑘,

hence max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|=max𝑗∈𝐴𝑖′𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)| and this means that

∑𝑖=1𝑛max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|=𝑛2𝑚−𝑘∑𝑖=12𝑚−𝑘max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|≤𝐶𝑎𝑢𝑐ℎ𝑦−𝑆𝑐ℎ𝑤𝑎𝑟𝑧𝑛2𝑚−𝑘2𝑚−𝑘‾‾‾‾‾√∑𝑖=12𝑚−𝑘max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷≤𝑛2𝑚−𝑘2𝑚−𝑘‾‾‾‾‾√∑𝑗=1𝑛|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷=𝑛2𝑚−𝑘‾‾‾‾‾√𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√,
where in the last inequality we used a fact that sets 𝐴1𝑘,𝐴2𝑘,…,𝐴2𝑚−𝑘𝑘 are disjoint. ◻

Finally, using the above lemmas we can upper bound the expected gap at step t:

Theorem 1
For every 𝑡≥0, we have that

𝔼[𝐺𝑎𝑝(𝑡)]=𝑂(𝑛√log(𝑛)).
Proof
From Lemma 2 we have that

∑𝑖=1𝑛2𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖+2𝑚−𝑘𝑘−1(𝑡)+∑𝑖=1𝑛2max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|=2∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+2∑𝑖=1𝑛max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)|.
After dividing the above inequality by 2 and applying Lemma 3 we get that:

∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+𝑛2𝑚−𝑘‾‾‾‾‾√𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√.
Next, we sum up the above inequality for 𝑘=1 to m:

∑𝑘=1𝑚∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤∑𝑘=1𝑚∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+∑𝑘=1𝑚𝑛2𝑚−𝑘‾‾‾‾‾√𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√.
Recall that ∑𝑛𝑖=1𝐺𝑎𝑝𝐴𝑖𝑚(𝑡)=𝑛𝐺𝑎𝑝(𝑡) and ∑𝑛𝑖=1𝐺𝑎𝑝𝐴𝑖0(𝑡)=0. Hence, we get that

𝑛𝐺𝑎𝑝(𝑡)≤∑𝑘=1𝑚𝑛2𝑚−𝑘‾‾‾‾‾√𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√.
Next, we apply Jensen’s inequality and Lemma 1:

𝑛𝔼[𝐺𝑎𝑝(𝑡)]≤∑𝑘=1𝑚𝑛2𝑚−𝑘‾‾‾‾‾√𝔼𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√≤∑𝑘=1𝑚𝑛2𝑚−𝑘‾‾‾‾‾√𝔼[𝜙2𝑚−𝑘(𝑡)]‾‾‾‾‾‾‾‾‾‾√≤∑𝑘=1𝑚𝑛2𝑚−𝑘‾‾‾‾‾√2𝑚−𝑘(𝑛−2𝑚−𝑘)‾‾‾‾‾‾‾‾‾‾‾‾‾‾√≤𝑚𝑛𝑛√=𝑛(log𝑛)𝑛√.
This gives us the proof of the theorem. ◻

Gap Lower Bound
Next we prove the following theorem, which lower bounds the second moment of the gap in expectation.

Theorem 2
The following limit holds:

lim𝑡→∞𝔼[𝐺𝑎𝑝(𝑡)2]=Ω(𝑛𝔼[𝑊2])).
Proof
In this case we want to prove that not only does vector Z(t) have positive coordinates in expectation, but also 𝔼[𝑧⌊𝑛2⌋] converges to 0. This will give us that 𝜙⌊𝑛2⌋ approaches its upper bound (⌊𝑛2⌋⌈𝑛2⌉−1)𝔼[𝑊2] in expectation. Then, we can show that there exist two nodes (at distance ⌊𝑛2⌋) such that the expected square of difference between their loads is Ω(𝑛𝔼[𝑤2]).

Recall from Eq. (11) that

𝑛𝔼[𝑧⌊𝑛2⌋(𝑡+1)]=−𝔼[𝑧1(𝑡)]+𝔼[𝑧⌊𝑛2⌋+1(𝑡)]+𝔼[𝑧⌊𝑛2⌋−1(𝑡)]+(𝑛−2)𝔼[𝑧⌊𝑛2⌋(𝑡)].
We also know that Inequalities (12) hold for every t, hence we get that

𝔼[𝑧⌊𝑛2⌋(𝑡+1)]≤𝔼[𝑧⌊𝑛2⌋(𝑡)]−𝔼[𝑧1(𝑡)]𝑛.
The above inequality in combination with Inequalities (12) means that

𝔼[𝑧⌊𝑛2⌋(𝑡+⌊𝑛2⌋+1)]≤𝔼[𝑧⌊𝑛2⌋(𝑡+1)]−∑𝑖=𝑡𝑡+⌊𝑛2⌋𝔼[𝑧1(𝑖)]𝑛≤𝔼[𝑧⌊𝑛2⌋(𝑡+1)]−𝔼[𝑧1(𝑡+⌊𝑛2⌋)]𝑛
(17)
Again by using Eq. (11) and Inequalities (12), we can show that for every 1≤𝑖≤⌊𝑛2⌋−1:

𝔼[𝑧𝑖(𝑡+1)]≥𝔼[𝑧𝑖+1(𝑡)]𝑛.
This gives us that:

𝔼[𝑧1(𝑡+⌊𝑛2⌋)]≥(1𝑛)𝔼[𝑧2(𝑡+⌊𝑛2⌋−1)]≥(1𝑛)2𝔼[𝑧3(𝑡+⌊𝑛2⌋−2)]≥⋯≥(1𝑛)⌊𝑛2⌋−1𝔼[𝑧⌊𝑛2⌋(𝑡+⌊𝑛2⌋−(⌊𝑛2⌋−1))]=(1𝑛)⌊𝑛2⌋−1𝔼[𝑧⌊𝑛2⌋(𝑡+1)].
By plugging the above inequality in Inequality (17). we get that

𝔼[𝑧⌊𝑛2⌋(𝑡+⌊𝑛2⌋+1)]≤𝔼[𝑧⌊𝑛2⌋(𝑡+1)]−𝔼[𝑧1(𝑡+⌊𝑛2⌋)]𝑛≤𝔼[𝑧⌊𝑛2⌋(𝑡+1)]−(1𝑛)⌊𝑛2⌋𝔼[𝑧⌊𝑛2⌋(𝑡+1)]=(1−(1𝑛)⌊𝑛2⌋)𝔼[𝑧⌊𝑛2⌋(𝑡+1)].
Because (1−(1𝑛)⌊𝑛2⌋)<1 and does not depend on t, we get that

lim𝑡→∞𝔼[𝑧⌊𝑛2⌋(𝑡)]=0.
This means thatlim𝑡→∞𝔼[𝜙⌊𝑛2⌋(𝑡)]=Ω(𝑛2𝔼[𝑊2]).

Let 𝐺𝑎𝑝⌊𝑛2⌋(𝑡)=max1≤𝑖≤𝑛|𝑥𝑖(𝑡)−𝑥𝑖+⌊𝑛2⌋(𝑡)|. Note that:

𝐺𝑎𝑝(𝑡)2≥𝐺𝑎𝑝⌊𝑛2⌋(𝑡)2≥𝜙⌊𝑛2⌋(𝑡)𝑛.
Hence

lim𝑡→∞𝔼[𝐺𝑎𝑝(𝑡)2]=Ω(𝑛𝔼[𝑊2]).
Unfortunately we are not able to obtain the lower bound on the gap, since our approach uses the fact that the upper bounds on k-hop potentials are ’tight’. Since our potentials are quadratic, we are not able to derive any kind of lower bound for the gap itself. Intuitively, this will be an issue with any argument which uses convex potential. ◻

Upper Bound on the Gap, General Case
To prove Theorem 1 for the general case, we need to redefine our sets 𝐴𝑖𝑘. In order to do this, for each k we define 2𝑘 dimensional vector Δ𝑘=(𝛿1𝑘,𝛿2𝑘,…,𝛿2𝑘𝑘). For 𝑘=0, we have that Δ𝑘=(𝑛). For ⌊log𝑛⌋≥𝑘>0 we set Δ𝑘=(𝛼𝑘,𝛿1𝑘−1−𝛼𝑘,𝛼𝑘,𝛿2𝑘−1−𝛼𝑘,…,𝛼𝑘,𝛿2𝑘−1𝑘−1−𝛼𝑘). where

𝛼𝑘=⎧⎩⎨⎪⎪⌊𝑛2𝑘−1⌋/2,if⌊𝑛2𝑘−1⌋is even.⌊⌈𝑛2𝑘−1⌉/2⌋,otherwise.
First we prove the following Lemma:

Lemma 4
For any ⌊log𝑛⌋≥𝑘≥0, we have that

1. ∑2𝑘𝑖=1𝛿𝑖𝑘=𝑛.

2. For any 1≤𝑖≤2𝑘, 𝛿𝑖𝑘∈{⌈𝑛2𝑘⌉⌊𝑛2𝑘⌋} (notice that this means 𝛼𝑘=⌊𝑛2𝑘⌋ or 𝛼𝑘=⌈𝑛2𝑘⌉).

Proof
We prove the lemma using induction on k. Base case 𝑘=0 holds trivially. For the induction step, assume that Properties 1 and 2 hold for 𝑘−1, we aim to prove that they hold for k as well. We have that ∑2𝑘𝑖=1𝛿𝑖𝑘=∑2𝑘−1𝑖=1(𝛼𝑘+𝛿𝑖𝑘−1−𝛼𝑘)=∑2𝑘−1𝑖=1𝛿𝑖𝑘−1=𝑛. To prove Property 2 we consider several cases:

Case 1 𝑛2𝑘−1=2𝑞, for some integer q.

We have that 𝛼𝑘=𝑞, and hence for any 1≤𝑖≤2𝑘−1, 𝛿𝑖𝑘−1−𝛼𝑘=𝑞. Since ⌊𝑛2𝑘⌋=𝑞, Property 2 holds.

Case 2 𝑛2𝑘−1=2𝑞+1, for some integer q.

We have that 𝛼𝑘=𝑞, and hence for any 1≤𝑖≤2𝑘−1, 𝛿𝑖𝑘−1−𝛼𝑘=𝑞+1. Since ⌊𝑛2𝑘⌋=𝑞 and ⌈𝑛2𝑘⌉=𝑞+1, Property 2 holds.

Case 3 𝑛2𝑘−1=2𝑞+𝜖, for some integer q and 0<𝜖<1.

We have that ⌊𝑛2𝑘−1⌋=2𝑞 and ⌈𝑛2𝑘−1⌉=2𝑞+1. Additionally, 𝛼𝑘=𝑞, and hence for any 1≤𝑖≤2𝑘−1, (𝛿𝑖𝑘−1−𝛼𝑘)∈{𝑞,𝑞+1}. Since ⌊𝑛2𝑘⌋=𝑞 and ⌈𝑛2𝑘⌉=𝑞+1, Property 2 holds.

Case 4 𝑛2𝑘−1=2𝑞+1+𝜖, for some integer q and 0<𝜖<1.

We have that ⌊𝑛2𝑘−1⌋=2𝑞+1 and ⌈𝑛2𝑘−1⌉=2𝑞+2. Additionally, 𝛼𝑘=𝑞+1, and hence for any 1≤𝑖≤2𝑘−1, (𝛿𝑖𝑘−1−𝛼𝑘)∈{𝑞,𝑞+1}. Since ⌊𝑛2𝑘⌋=𝑞 and ⌈𝑛2𝑘⌉=𝑞+1, Property 2 holds. ◻

Next, for ⌊log𝑛⌋≥𝑘>0 we set

𝐴𝑖𝑘={𝑖,𝑖+𝛿1𝑘,𝑖+𝛿1𝑘+𝛿2𝑘,…,𝑖+∑𝑗=12𝑘−1𝛿𝑗𝑘}.
It is easy to see that for any ⌊log𝑛⌋≥𝑘>0 and i, we have that |𝐴𝑖𝑘|=2𝑘, 𝐴𝑖𝑘=𝐴𝑖𝑘−1∪𝐴𝑖+𝛼𝑘𝑘−1 and 𝐴𝑖𝑘−1∩𝐴𝑖+𝛼𝑘𝑘−1=∅. Also notice that for any 𝑢∈𝐴𝑖𝑘−1, 𝑢+𝛼𝑘∈𝐴𝑖+𝛼𝑘𝑘−1 and for any 𝑢∈𝐴𝑖+𝛼𝑘𝑘−1, 𝑢−𝛼𝑘∈𝐴𝑖𝑘−1.

Next we prove the lemma which is similar to the Lemma 2 for 𝑛=2𝑚 case:

Lemma 5
For any 1≤𝑖≤𝑛 and ⌊log𝑛⌋≥𝑘>0, we have that

2𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤2max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|+𝐺𝑎𝑝𝐴𝑖+𝛼𝑘𝑘−1(𝑡)+𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡).
(18)
Proof
Notice that the statement we need to prove is identical to that of Lemma 2, with the exception that in the letter we use 2𝑚−𝑘 instead of 𝛼𝑘. The proofs are also almost identical (2𝑚−𝑘 can be simply replaced with 𝛼𝑘). The only difference is that the proof of Lemma 2 uses the property that for any 𝑢∈𝐴𝑖+2𝑚−𝑘𝑘−1, |𝑥𝑢(𝑡)−𝑥𝑢+2𝑚−𝑘(𝑡)|≤max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+2𝑚−𝑘(𝑡)| and 𝑢+2𝑚−𝑘∈𝐴𝑖𝑘−1. Instead, we will use the property that for any 𝑢∈𝐴𝑖+𝛼𝑘𝑘−1, |𝑥𝑢(𝑡)−𝑥𝑢−𝛼𝑘(𝑡)|≤max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)| and 𝑢−𝛼𝑘∈𝐴𝑖𝑘−1. ◻

Next, we upper bound ∑𝑛𝑖=1max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|, by proving the following lemma, which is the analogue of Lemma 3.

Lemma 6
∑𝑖=1𝑛max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|≤⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝜙𝛼𝑘(𝑡)‾‾‾‾‾‾√
(19)
Proof
Notice that for any 1≤𝑢≤𝑛 and the sets 𝐴𝑢𝑘,𝐴𝑢+1𝑘,…,𝐴𝑢+⌊𝑛2𝑘⌋−1𝑘 are disjoint, because for any 1≤𝑗≤2𝑘, 𝛿𝑗𝑘≥⌊𝑛2𝑘⌋ (this means that for any 1≤𝑖≤𝑛, distances between consecutive vertices in 𝐴𝑖𝑘 are at least ⌊𝑛2𝑘⌋). Using this fact and Cauchy–Schwarz inequality we get that

∑𝑖=𝑢𝑢+⌊𝑛2𝑘⌋−1max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|≤⌊𝑛2𝑘⌋‾‾‾‾‾√∑𝑖=𝑢𝑢+⌊𝑛2𝑘⌋−1max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷≤⌊𝑛2𝑘⌋‾‾‾‾‾√∑𝑗=1𝑛|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷=⌊𝑛2𝑘⌋‾‾‾‾‾√𝜙𝛼𝑘(𝑡)‾‾‾‾‾‾√
Since the above inequality holds for any u we can write that:

∑𝑖=1𝑛max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|≤⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝜙𝛼𝑘(𝑡)‾‾‾‾‾‾√.◻
◻

With the above three lemmas in place, we are ready to prove Theorem 1 for general n.

From Lemma 5 we have that

∑𝑖=1𝑛2𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖+𝛼𝑘𝑘−1(𝑡)+∑𝑖=1𝑛2max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|=2∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+2∑𝑖=1𝑛max𝑗∈𝐴𝑖𝑘|𝑥𝑗(𝑡)−𝑥𝑗+𝛼𝑘(𝑡)|.
After dividing the above inequality by 2 and applying Lemma 6, we get that:

∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘(𝑡)≤∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖𝑘−1(𝑡)+⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝜙𝛼𝑘(𝑡)‾‾‾‾‾‾√.
Notice that for any i, 𝐺𝑎𝑝𝑖𝐴0(𝑡)=0. Hence, after summing up the above inequality for 𝑘=1 to ⌊log𝑛⌋ we get that

∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖⌊log𝑛⌋(𝑡)≤∑𝑘=1⌊log𝑛⌋⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝜙𝛼𝑘(𝑡)‾‾‾‾‾‾√.
Let 𝑖′=argmin𝑖𝐺𝑎𝑝𝐴𝑖⌊log𝑛⌋(𝑡). Notice that consecutive vertices in 𝐴𝑖′⌊log𝑛⌋ are 1 or 2 edges apart, hence for any 1≤𝑖≤𝑛, either 𝑖∈𝐴𝑖′⌊log𝑛⌋ or 𝑖+1∈𝐴𝑖′⌊log𝑛⌋. This gives us that

𝐺𝑎𝑝(𝑡)≤𝐺𝑎𝑝𝐴𝑖′⌊log𝑛⌋(𝑡)+2max𝑖|𝑥𝑖(𝑡)−𝑥𝑖+1(𝑡)|=𝐺𝑎𝑝𝐴𝑖′⌊log𝑛⌋(𝑡)+2max𝑖|𝑥𝑖(𝑡)−𝑥𝑖+1(𝑡)|2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾√≤𝐺𝑎𝑝𝐴𝑖′⌊log𝑛⌋(𝑡)+2𝜙1(𝑡)‾‾‾‾‾√.
By combining the above two inequalities we get that

𝑛𝐺𝑎𝑝(𝑡)≤𝑛𝐺𝑎𝑝𝐴𝑖′⌊log𝑛⌋(𝑡)+2𝑛𝜙1(𝑡)‾‾‾‾‾√≤∑𝑖=1𝑛𝐺𝑎𝑝𝐴𝑖⌊log𝑛⌋(𝑡)+2𝑛𝜙1(𝑡)‾‾‾‾‾√≤∑𝑘=1⌊log𝑛⌋⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝜙𝛼𝑘(𝑡)‾‾‾‾‾‾√+𝑛𝜙1(𝑡)‾‾‾‾‾√.
Next, we apply Jensen’s inequality and Lemma 1 (we are going to use a looser upper bound: 𝔼[𝜙𝑖(𝑡)]≤𝑖(𝑛−𝑖)−1≤𝑖𝑛)

𝑛𝔼[𝐺𝑎𝑝(𝑡)]≤2𝑛𝔼[𝜙1(𝑡)]‾‾‾‾‾‾√+∑𝑘=1⌊log𝑛⌋⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝔼𝜙𝛼𝑘(𝑡)‾‾‾‾‾‾√≤2𝑛𝔼[𝜙1(𝑡)]‾‾‾‾‾‾‾‾√+∑𝑘=1⌊log𝑛⌋⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝔼[𝜙𝛼𝑘(𝑡)]‾‾‾‾‾‾‾‾‾√≤2𝑛𝑛√+∑𝑘=1⌊log𝑛⌋⌈𝑛⌊𝑛2𝑘⌋⌉⌊𝑛2𝑘⌋‾‾‾‾‾√𝛼𝑘𝑛‾‾‾‾√=𝑂(𝑛𝑛√log𝑛).
This completes the proof.

Experimental Validation
On the practical side, we implemented our load balancing algorithm with unit weight increments on a cycle. The results confirm our hypothesis that the gap is of order Θ(𝑛√). In our experiment we observe the evolution of gap as we perform up to 109 increment operations. In Fig. 1 we ran our experiment 100 times and calculated average gap over all runs. x-axis shows number of balls thrown (which is the same as the number of increments) and y-axis is current average gap divided by 𝑛√. The experiment shows that once the number of thrown balls is large enough, the gap stays between 𝑛√ and 1.4𝑛√.

Fig. 1
figure 1
The evolution of average gap divided by square root of n, where n is the number of bins

Full size image
Harary Graph, Upper Bound on the Gap
Recall that the Harary graph 𝐻𝑘,𝑛 is a k-connected graph with n vertices, which has the smallest possible number of edges. In this section we show that our approach can be extended to the Harary graph 𝐻4,𝑛 (unless specified we will assume 𝐻4,𝑛 to be the Harary graph): each vertex i is connected with edges to vertices 𝑖−1, 𝑖+1 (called cycle edges), 𝑖−2 and 𝑖+2 (called extra edges). As before, the operation consists of picking an edge u.a.r and doing increment and averaging (for the simplicity we assume that increments have unit weights, the result can be extended to the random weights, in the similar fashion to the cycle case). After careful calculations which mimic the calculations for the cycle case, but by taking extra edges of the Harary graph into the account, we can derive the following equations for the hop potentials (hop distance is counted over the cycle edges only):

⎧⎩⎨⎪⎪⎪⎪⎪⎪𝔼[𝜙1(𝑡+1)]=𝑛−2𝑛𝔼[𝜙1(𝑡)]+34+𝔼[𝜙1(𝑡)]4𝑛+𝔼[𝜙3(𝑡)]2𝑛𝔼[𝜙2(𝑡+1)]=𝑛−2𝑛𝔼[𝜙2(𝑡)]+34−𝔼[𝜙2(𝑡)]4𝑛+𝔼[𝜙3(𝑡)]2𝑛+𝔼[𝜙4(𝑡)]2𝑛…𝔼[𝜙𝑘(𝑡+1)]=𝑛−2𝑛𝔼[𝜙𝑘(𝑡)]+1−𝔼[𝜙1(𝑡)]2𝑛−𝔼[𝜙2(𝑡)]2𝑛+𝔼[𝜙𝑘−2(𝑡)]2𝑛+𝔼[𝜙𝑘−1(𝑡)]2𝑛+𝔼[𝜙𝑘+1(𝑡)]2𝑛+𝔼[𝜙𝑘+2(𝑡)]2𝑛
Recall that for the cycle potential 𝜙𝑘(𝑡+1) depends on the potentials 𝜙𝑘(𝑡), 𝜙𝑘+1(𝑡), 𝜙𝑘−1(𝑡) and 𝜙1(𝑡) (please see Eq. (8)). In the case of Harary graph 𝜙𝑘(𝑡+1) depends on the potentials 𝜙𝑘+2(𝑡), 𝜙𝑘+1(𝑡), 𝜙𝑘(𝑡), 𝜙𝑘−1(𝑡), 𝜙𝑘−2(𝑡), 𝜙1(𝑡) and 𝜙2(𝑡). The reason is that we are able to perform load balancing operation on two hop neighbours. Similarly, if we have a graph where each vertex is connected with all vertices which are at hop distance at most ℓ (this is the Harary graph 𝐻2ℓ,𝑛), then 𝜙𝑘(𝑡+1) will depend on 𝜙𝑘+ℓ(𝑡), …, 𝜙𝑘+1(𝑡), 𝜙𝑘(𝑡), 𝜙𝑘−1(𝑡), …, 𝜙𝑘−ℓ(𝑡), and 𝜙1(𝑡), 𝜙2(𝑡), …, 𝜙ℓ(𝑡). Next step is to find the stationary points for the hop potentials. That is: the values which stay the same after we apply step given by the above equations. As before (please see Lemma 1), these values will be used as the upper bounds for the expected values of potentials. In the case of 𝐻4,𝑛, we get that for every t and k:

𝔼[𝜙𝑘(𝑡)]≤25𝑘(𝑛−𝑘)+𝛼.
(20)
Here, extra term 𝛼 has a closed form, which we omit and instead concentrate on the property that it is upper bounded by 2n. Observe that since the Harary graph contains cycle and we defined our hop potentials based on the hop counts of that cycle, we can upper bound the gap by using:

𝔼[𝐺𝑎𝑝(𝑡)]≤∑𝑘=1𝑚12𝑚−𝑘‾‾‾‾‾√𝔼𝜙2𝑚−𝑘(𝑡)‾‾‾‾‾‾‾√≤𝑂(𝑛√log𝑛).
(21)
Notice that since 𝛼≤2𝑛, for large enough k and n, the upper bound for 𝔼[𝜙𝑘(𝑡)] can be two times smaller than the upper bound for the cycle case, which was shown in Lemma 1. Hence, we can use this to slightly improve the constant hidden by big O notation in the upper bound. In general, we conjecture that for any pair of parameters 1≤𝑙1<𝑙2≤𝑛, a gap for the Harary graph 𝐻2𝑙2,𝑛 is smaller than a gap for the Harary graph 𝐻2𝑙1,𝑛. Unfortunately, we are not able to provide the exact dependence of a gap on the Harary graph parameter.

Discussion and Future Work
We have shown that in the case of dynamic averaging on a cycle the gap between highest and lowest loaded bins is upper bounded by 𝑂(𝑛√log𝑛) in expectation. Additionally we showed that the expected square of the gap is lower bounded by Ω(𝑛). It the future, it would be interesting to further tighten our results, matching our experimental analysis. We conjecture that the “correct” bound on the expected gap is Θ(𝑛√). As already discussed, we also plan to extend our results to more general graph families, in particular grid graphs.

Comparison of Two-Choice and Averaging Load Balancing
Finally, it is interesting to ask if it is possible to extend our gap bounds to the case of the classic two-choice load balancing process. In particular, is it possible to show that the gap in the case of averaging process is always smaller in expectation than the gap in the case of two choice process? Intuitively this should be the case, since the load balancing operation in the case of averaging can be viewed as picking up a random edge, incrementing the load of the less loaded endpoint, and then averaging the values. The extra averaging step should not make the gap larger. Indeed, the exponential potential used to analyse the gap in [17] can be used to upper bound the gap for the averaging process, since the exponential function is convex and averaging values does not increase it (by Jensen’s inequality).

Unfortunately, it is not clear if averaging helps to actually decrease the exponential potential. Additionally, this argument shows that averaging does not make the gap worse if applied to the particular technique of upper bounding the gap, and it is not clear if the gap itself is actually smaller, if we use averaging on top of the two-choice process. We conjecture that there exists a majorization argument which is based on how often the process performs the averaging step. More precisely, we consider the setting where after the increment step (using two choice), we perform averaging with probability 𝛽. The gap should decrease in expectation as we increase 𝛽. Note that the only result which lower bounds the gap for the two-choice process on the cycle is the straightforward Ω(log𝑛) lower bound which can be shown for the clique [17]. Where The lower bound comes from the observation that if Ω(𝑛log𝑛) balls of weight one are placed into n bins according to the two choice process, then the average load is Ω(log𝑛) and with constant probability there exists a bin which is empty. What would make the existence of the majorization argument interesting is that it would allow us to show that the lower bound we derived on the second moment of the gap while always performing averaging step on the cycle (𝛽=1) can be automatically used as the lower bound on the gap for two choice on the cycle (𝛽=0). We plan to investigate this connection in future work.