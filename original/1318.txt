Abstract
This study considers the soft capacitated vertex cover problem in a dynamic setting. This problem generalizes the dynamic model of the vertex cover problem, which has been intensively studied in recent years. Given a dynamically changing vertex-weighted graph 𝐺=(𝑉,𝐸), which allows edge insertions and edge deletions, the goal is to design a data structure that maintains an approximate minimum vertex cover while satisfying the capacity constraint of each vertex. That is, when picking a copy of a vertex v in the cover, the number of v’s incident edges covered by the copy is up to a given capacity of v. We extend Bhattacharya et al.’s work [SODA’15 and ICALP’15] to obtain a deterministic primal-dual algorithm for maintaining a constant-factor approximate minimum capacitated vertex cover with 𝑂(log𝑛/𝜖) amortized update time, where n is the number of vertices in the graph. The algorithm can be extended to (1) a more general model in which each edge is associated with a non-uniform and unsplittable demand, and (2) the more general capacitated set cover problem.

Access provided by University of Auckland Library

Introduction
Dynamic algorithms have received fast-growing attention in the past decades, especially for some classical combinatorial optimization problems such as connectivity [1, 10, 13, 15], routing [2, 8, 21, 22], vertex cover and maximum matching [3,4,5,6, 16,17,18,19,20]. This paper focuses on the fully dynamic model for the vertex cover problem, which has been intensively studied in recent years. Given a vertex-weighted graph 𝐺=(𝑉,𝐸), here we called the weight on each vertex as cost to avoid abusing this term in the following section. Such a graph is constantly updated due to a sequence of edge insertions and edge deletions, where the objective is to maintain a subset of vertices 𝑆⊆𝑉 at any given time, such that every edge is incident to at least one vertex in S and the total cost of S is minimized. We consider a generalization of the problem, where each vertex is associated with a given capacity. When picking a copy of a vertex v in the multiset S, the number of its incident edges that can be covered by such a copy is bounded by v’s given capacity. The objective is to find a soft capacitated weighted vertex cover S with minimum cost, i.e. ∑𝑣∈𝑆𝑐𝑣𝑥𝑣 is minimized, as well as an assignment of edges such that the number of edges assigned to a vertex v in S is at most 𝑘𝑣𝑥𝑣, where 𝑐𝑣 is the cost of v, 𝑘𝑣 is the capacity of v, and 𝑥𝑣 is the number of selected copies of v in S. Assume there is no bound on 𝑥𝑣. The static model of this generalization is the so-called soft capacitated vertex cover problem, introduced by Guha et al. [11], whereas if each 𝑥𝑣 is associated with a bound, it is called the hard capacitated vertex cover problem, introduced by Chuzhoy and Naor [9].

Prior work For the vertex cover problem in a dynamic setting, Ivkovic and Lloyd [14] presented the pioneering work wherein their fully dynamic algorithm maintains a 2-approximation factor to vertex cover with 𝑂((𝑛+𝑚)0.7072) update time, where n is the number of vertices and m is the number of edges. Onak and Rubinfeld [17] designed a randomized data structure that maintains a large constant approximation ratio with 𝑂(log2𝑛) amortized update time in expectation; this is the first result that achieves a constant approximation factor with polylogarithmic update time. Baswana et al. [3] designed another randomized data structure which improves the approximation ratio to two, and simultaneously improved the amortized update time to 𝑂(log𝑛). Recently, Solomon [20] gave the currently best randomized algorithm, which maintains a 2-approximate vertex cover with O(1) amortized update time.

For deterministic data structures, Onak and Rubinfeld [17] presented a data structure that maintains an 𝑂(log𝑛)-approximation algorithm with 𝑂(log2𝑛) amortized update time. Bhattacharya et al. [6] proposed the first deterministic data structure that maintains a constant ratio, precisely, a (2+𝜖)-approximation to vertex cover with polylogarithmic 𝑂(log𝑛/𝜖2) amortized updated time. Existing work also considered the worst-case update time. Neiman and Solomon [16] provided a 2-approximation dynamic algorithm with 𝑂(𝑚‾‾√) worst-case update time. Peleg and Solomon [18] improved the worst-case update time to 𝑂(𝛾/𝜖2), where 𝛾 is the arboricity of the input graph. Very recently, Bhattacharya et al. [4] extended their hierarchical data structure to achieve the currently best worst-case update time of 𝑂(𝑝𝑜𝑙𝑦(1/𝜖)⋅log3𝑛)Footnote1. Note that the above studies only discussed the unweighted vertex cover problem, the objective of which is to find a vertex cover with minimum cardinality.

Consider the dynamic (weighted) set cover problem. In the statics setting, given a universe U of n elements and a family F of m sets. Each set is associated with non-negative costs. The objective is to find a subfamily of sets 𝑆∈𝐹 of minimum cost that covers U. The dynamic set cover problem follows a sequence of element insertions and deletions, the objective is to maintain a subfamily of sets 𝑆∈𝐹 at any given time, such that the union of S covers the elements that we seen so far.

Bhattacharya et al. [7] used a hierarchical data structure similar to that reported in [6], and and presented an algorithm with 𝑂(𝑓2)-approximation ratio and 𝑂(𝑓log(𝑛+𝑚)) amortized updated time, where f is the maximum frequency of an element. Very recently, Gupta et al. [12] improved the amortized update time to 𝑂(𝑓2), albeit the dynamic algorithm achieves a higher approximation ratio of 𝑂(𝑓3). They also offered another 𝑂(log𝑛)-approximation dynamic algorithm in 𝑂(𝑓log𝑛) amortized update time. Bhattacharya et al. [5] simultaneously derived the same outcome with 𝑂(𝑓3)-approximation ratio and 𝑂(𝑓2) amortized update time for the unweighted set cover problem. Table 1 presents a summary of the above results.

Table 1 Summary of results for unweighted (resp. weighted) minimum vertex cover (UMVC (resp. WMVC)), unweighted (resp. weighted) minimum set cover (UMSC (resp. WMSC)), where f is the maximum frequency of an element, and weighted minimum capacitated vertex (resp. set) cover (WMCVC (resp. WMCSC))
Full size table
Our Contribution In this study we investigate the soft capacitated vertex cover problem in the dynamic setting, where there is no bound on the number of copies of each vertex that can be selected. We refer to the primal-dual technique reported in [11], and present the first deterministic algorithm for this problem, which can maintain an O(1)-approximate minimum capacitated (weighted) vertex cover with 𝑂(log𝑛/𝜖) amortized update time. The algorithm can be extended to a more general model in which each edge is associated with a given demand, and the demand has to be assigned to an incident vertex. That is, the demand of each edge is non-uniform and unsplittable. Also, it can be extended to solve the more general capacitated set cover problem, where the input graph is a hyper-graph, and each edge may connect to multiple vertices.

The proposed dynamic mechanism builds on Bhattacharya et al.’s (𝛼,𝛽)-partition structure [6, 7], but a careful adaptation has to be made to cope with the newly introduced capacity constraint. In dynamic vertex cover [6], the authors considered dynamically maintaining the dual problem of the relaxed vertex cover, that is, the fractional matching problem. They partitioned all of the vertices into different levels and designed a weight function for the fractional matching problem.

Briefly, applying the fractional matching technique in Bhattacharya et al.’s algorithm cannot directly lead to a constant approximation ratio in the capacitated vertex cover problem. The crux of our result is the re-design of a key parameter, weight function of a vertex, in the dual model. Details are shown in the next section.

Overview of Our Technique
First, we recall the mathematical model of the capacitated vertex cover problem which was first introduced by Guha et al. [11]. In this model, 𝑦𝑒𝑣 serves as a binary variable that indicates whether an edge e is covered by a vertex v. Let 𝑁𝑣 be the set of incident edges of v, 𝑘𝑣 and 𝑐𝑣 be the capacity and the cost of a vertex v, respectively. Let 𝑥𝑣 be the number of selected copies of a vertex v. An integer program (IP) model of the problem can be formulated as follows (the minimization program on the left):

figure a
If we allow a relaxation of the above primal form, i.e., dropping the integrality constraints, its dual problem yields a maximization problem. The linear program for the dual can be formulated as shown in the above (the maximization program on the right; also see [11]). One may consider this as a variant of the packing problem, where we want to pack a value of 𝜋𝑒 for each edge e, so that the sum of the packed values is maximized. Packing of e is limited by the sum of 𝑞𝑣 and 𝑙𝑒𝑣, where 𝑞𝑣 is the global ability of a vertex v emitted to v’s incident edges, and 𝑙𝑒𝑣 is the local ability of v distributed to its incident edge e.

In this study, we incorporate the above IP model with its LP relaxation for capacitated vertex cover into the dynamic mechanism proposed Bhattacharya et al.’s [6, 7]. They devised the weight function of a vertex (in the dual model). Based on the weight function, we can select a subset of vertices that obtains a feasible vertex cover. They also allowed a flexible range for weight function to quickly adjust the solution for dynamic updates while preserving its approximation quality. Due to the additional capacity constraint in our problem, a new weight function is obviously required.

Technical Challenges There are two major differences between our algorithm and Bhattacharya et al.’s [6, 7]. First, the capacity constraint in the primal problem leads to the two variables 𝑞𝑣 and 𝑙𝑒𝑣 in the dual problem in which we have to balance their values when approaching 𝑐𝑣 to maximize the dual objective. By contrast, the previous work considered one dual variable 𝑙𝑒𝑣 without the restriction on the coverage of a vertex. We thus re-design weight function of a vertex to specifically consider the capacitated scenario. Yet, even with the new definition of weight function, there is still a second challenge on how to approximate the solution within a constant factor in the dynamic environment. In order to achieve polylogarithmic amortized update time, Bhattacharya et al.’s fractional matching approach assigns the value of all v’s incident edges to v, which, however, may result in a non-constant h, hidden in the approximation ratio, where h is the largest number of copies selected in the cover. We observe that we cannot remove h from the approximation guarantee based on the (𝛼,𝛽)-partition structure if we just select the minimum value of 𝛼, as it is done in (Bhattacharya et al. [6, 7]). The key insight is that we show a bound on the value of 𝛼, which restricts the updates of the dynamic mechanism. With the help of this insight, we are able to revise the setting of 𝛼 to derive a constant approximation ratio, while maintaining the 𝑂(log𝑛/𝜖) update time.

Level Scheme and Its Key Property
The core of Bhattacharya et al.’s (𝛼,𝛽)-partition structure [6, 7]) is a level scheme [17] that is used to maintain a feasible solution in their dual problem. In this section, we demonstrate (in a different way from the original papers) how this scheme can be applied to our dual problem, and describe the key property that the scheme guarantees.

A level scheme is an assignment ℓ:𝑉→{0,1,…,𝐿} such that every vertex 𝑣∈𝑉 has a level ℓ(𝑣). Let 𝑐min and 𝑐max denote the minimum and maximum costs of a vertex, respectively. For our case, we set 𝐿=⌈log𝛽(𝑛𝜇𝛼/𝑐min)⌉ for some 𝛼,𝛽>1 and 𝜇>𝑐max. Based on ℓ, each edge (u, v) is also associated with a level ℓ(𝑢,𝑣), where ℓ(𝑢,𝑣)=max{ℓ(𝑢),ℓ(𝑣)}. An edge is assigned to the higher-level endpoint, and ties are broken arbitrarily if both endpoints have the same level. Conceptually, based on the level status of the vertices, the level scheme transforms an undirected graph into a directed structure. Each edge (u, v) has a weight w(u, v) according to its level, such that 𝑤(𝑢,𝑣)=𝜇𝛽−ℓ(𝑢,𝑣). Each vertex v also has a weight 𝑊𝑣, which is defined based on the incident edges of v and their corresponding levels. Before giving details on 𝑊𝑣, we first define some notations. Let 𝑁𝑣={𝑢∣(𝑢,𝑣)∈𝐸} be the set of vertices adjacent to v (i.e., the neighbors of v). Let 𝑁𝑣(𝑖) denote the set of level-i neighbors of v, and 𝑁𝑣(𝑖,𝑗) denote the set of v’s neighbors whose levels are in the range [i, j]. That is, 𝑁𝑣(𝑖)={𝑢∣(𝑢,𝑣)∈𝐸∧ℓ(𝑢)=𝑖} and 𝑁𝑣(𝑖,𝑗)={𝑢∣(𝑢,𝑣)∈𝐸∧ℓ(𝑢)∈[𝑖,𝑗]}. The degree of a vertex v is denoted by 𝐷𝑣=|𝑁𝑣|. Similarly, we define 𝐷𝑣(𝑖)=|𝑁𝑣(𝑖)| and 𝐷𝑣(𝑖,𝑗)=|𝑁𝑣(𝑖,𝑗)|. Finally, we use 𝛿(𝑣) to denote the set of edges assigned to a vertex v. Now, the weight 𝑊𝑣 of a vertex v is defined as follows:

Case 1 𝐷𝑣(0,ℓ(𝑣))>𝑘𝑣:

𝑊𝑣=𝑘𝑣𝜇𝛽−ℓ(𝑣)+∑𝑖>ℓ(𝑣)min{𝑘𝑣,𝐷𝑣(𝑖)}𝜇𝛽−𝑖
Case 2 𝐷𝑣(0,ℓ(𝑣))≤𝑘𝑣:

𝑊𝑣=𝐷𝑣(0,ℓ(𝑣))𝜇𝛽−ℓ(𝑣)+∑𝑖>ℓ(𝑣)min{𝑘𝑣,𝐷𝑣(𝑖)}𝜇𝛽−𝑖
The intuition behind this weight function refers to the primal-dual algorithm proposed by Guha et al. [11], where by the capacity constraint, in each iteration, a vertex can increase its dual value by at most 𝑘𝑣 edges, no matter how many incident edges it has. By a similar idea, we consider whether the number of level-i neighbors of v, 0≤𝑖≤ ℓ(𝑣), is larger than the capacity of v, and use it to define the weight of a vertex v. Note that the total weight of the edges that are assigned to v or incident to v can contribute at most 𝑘𝑣𝑤(𝑢,𝑣) to 𝑊𝑣, which is different from the [6, 7]. (In Bhattacharya et al. [6, 7], since they do not need to consider the capacity constraint, the weight of a vertex is simply the sum of the weights of all its incident edges; that is, 𝑊𝑣=∑𝑢∈𝑁(𝑣)𝑤(𝑢,𝑣).) Moreover, our proposed weight function provides a relationship between the weights of different levels, which plays an essential role when we consider the dynamic setting. Briefly, the weight of a vertex has two components: one that is dependent on the incident edges with level ℓ(𝑣), and the other that is dependent on the remaining incident edges. For convenience, we call the former component 𝐼𝑛𝑡𝑒𝑟𝑛𝑎𝑙𝑣 and the latter component as 𝐸𝑥𝑡𝑒𝑟𝑛𝑎𝑙𝑣. Moreover, we have:

𝐸𝑥𝑡𝑒𝑟𝑛𝑎𝑙𝑣≤𝑘𝑣∑𝑖>ℓ(𝑣)𝜇𝛽−𝑖  ≤  (1/(𝛽−1))𝑘𝑣𝜇𝛽−ℓ(𝑣).
In general, an arbitrary level scheme cannot be used to solve our problem. What we need is a valid level scheme, which is defined as follows.

Definition 1
A level scheme is valid if 𝑊𝑣≤𝑐𝑣, for every vertex v.

Lemma 1
Let 𝑉0 denote the set of level-0 vertices in a valid level scheme. Then, 𝑉∖𝑉0 forms a vertex cover of G.

Proof
Consider any edge (𝑢,𝑣)∈𝐸. We claim that at least one of its endpoints must be in 𝑉∖𝑉0. Suppose that the claim is false which implies that ℓ(𝑢)=ℓ(𝑣)=0 and 𝑤(𝑢,𝑣)=𝜇>𝑐max. Since w(u, v) appears in 𝐼𝑛𝑡𝑒𝑟𝑛𝑎𝑙𝑣, we have 𝑊𝑣≥𝑤(𝑢,𝑣). As a result, 𝑐𝑣≥𝑊𝑣≥𝜇>𝑐max, which leads to a contradiction. The claim thus follows, and so does the lemma.

◻

The above lemma implies that no edge is assigned to any level-0 vertex. In our mechanism, we will maintain a valid level scheme, based on which each vertex in 𝑉∖𝑉0 picks enough copies to cover all the edges assigned to it; this forms a valid capacitated vertex cover.

Next, we define the notion of tightness, which is used to measure how good a valid level scheme performs.

Definition 2
A valid level scheme with an associated edge assignment is 𝜀-tight if for every vertex v with |𝛿(𝑣)|>0, 𝑊𝑣∈(𝑐𝑣/𝜀,𝑐𝑣].

Lemma 2
Given an 𝜀-tight valid level scheme, we can obtain an 𝜀(2(𝛽/(𝛽−1))+1)-approximate solution to the weighted minimum capacitated vertex cover (WMCVC) problem.

Proof
First, we fix an arbitrary edge assignment that is consistent with the given valid level scheme. For each vertex v with |𝛿(𝑣)|>0, we pick ⌈|𝛿(𝑣)|/𝑘𝑣⌉ copies to cover all the |𝛿(𝑣)| edges assigned to it. To analyze the total cost of this capacitated vertex cover, we relate it to the value ∑𝑒𝜋𝑒 of a certain feasible solution of the dual problem, whose corresponding values of 𝑞𝑣 and 𝑙𝑒𝑣 are as follows:

For every vertex v:

∙ if ⌈|𝛿(𝑣)|/𝑘𝑣⌉>1: 𝑞𝑣=𝜇𝛽−ℓ(𝑣), and 𝑙𝑒𝑣=0;

∙ if ⌈|𝛿(𝑣)|/𝑘𝑣⌉≤1: 𝑞𝑣=𝜇∑𝑖∣𝐷𝑣(𝑖)>𝑘𝑣𝛽−𝑖,

𝑙𝑒𝑣=0 if 𝐷𝑣(ℓ(𝑒))>𝑘𝑣, and 𝑙𝑒𝑣=𝜇𝛽−ℓ(𝑒) otherwise.

For every edge e: 𝜋𝑒=𝜇𝛽−ℓ(𝑒).

It is easy to verify that the above choices of 𝑞𝑣, 𝑙𝑒𝑣, and 𝜋𝑒 give a feasible solution to the dual problem.

For the total cost of our solution, we separate the analysis into two parts, based on the multiplicity of the vertex:

Case 1 ⌈|𝛿(𝑣)|/𝑘𝑣⌉>1: In this case, the external component of 𝑊𝑣 is at most 1/(𝛽−1) of the internal component, so 𝑊𝑣≤(𝛽/(𝛽−1))𝑘𝑣𝑞𝑣. Then, the cost of all copies of v is:

⌈|𝛿(𝑣)|/𝑘𝑣⌉⋅𝑐𝑣≤⌈|𝛿(𝑣)|/𝑘𝑣⌉⋅𝜀⋅𝑊𝑣≤2⋅|𝛿(𝑣)|𝑘𝑣⋅𝜀⋅(𝛽/(𝛽−1))𝑘𝑣𝑞𝑣 = 2𝜀(𝛽/(𝛽−1))⋅∑𝑒∈𝛿(𝑣)𝜋𝑒.
Case 2 ⌈|𝛿(𝑣)|/𝑘𝑣⌉ =1: In this case, we pick one copy of vertex v, whose cost is:

𝑐𝑣≤𝜀⋅𝑊𝑣 ≤𝜀⋅∑𝑒∼𝑣𝜋𝑒 = 𝜀⋅(∑𝑒∈𝛿(𝑣)𝜋𝑒+∑𝑒∉𝛿(𝑣),𝑒∼𝑣𝜋𝑒),
where 𝑒∼𝑣 denotes e is an edge incident to v.

In summary, the total cost is bounded by

∑𝑣(max{𝜀,2𝜀(𝛽/(𝛽−1))}∑𝑒∈𝛿(𝑣)𝜋𝑒+𝜀∑𝑒∉𝛿(𝑣),𝑒∼𝑣𝜋𝑒)=∑𝑣(2𝜀(𝛽/(𝛽−1))∑𝑒∈𝛿(𝑣)𝜋𝑒+𝜀∑𝑒∉𝛿(𝑣),𝑒∼𝑣𝜋𝑒)=𝜀(2(𝛽/(𝛽−1))+1)∑𝑒𝜋𝑒≤𝜀(2(𝛽/(𝛽−1))+1)⋅𝑂𝑃𝑇,
where OPT denotes the optimal solution of the dual problem, which is also a lower bound of the cost of any weighted capacitated vertex cover. ◻

The next section discusses how to dynamically maintain an 𝜀-tight level scheme, for some constant factor 𝜀 and with amortized 𝑂(log𝑛/𝜖) update time. Before that, we show a greedy approach to get a (𝛽+1)-tight level scheme to the static problem as a warm up.

First, we have the following definition.

Definition 3
A valid level scheme 𝜆 is improvable if some vertex can drop its level to get another level scheme 𝜆′ such that 𝜆′ is valid; otherwise, we say 𝜆 is non-improvable.

Lemma 3
If a valid level scheme 𝜆 is non-improvable, then 𝜆 is (𝛽+1)-tight.

Proof
To prove this lemma, we compare the weight 𝑊𝑣 of a vertex v when its level is set to i and 𝑖+1, respectively (while the level of every other vertex remains unchanged).

Case 1 𝐷𝑣(0,𝑖)<𝑘𝑣 and 𝐷𝑣(0,𝑖+1)<𝑘𝑣:

𝑊𝑣(𝑖+1)𝑊𝑣(𝑖)=𝐷𝑣(0,𝑖+1)𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑣(𝑗)}𝜇𝛽−𝑗;=𝐷𝑣(0,𝑖)𝜇𝛽−(𝑖)+𝐷𝑣(𝑖+1)𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑣(𝑗)}𝜇𝛽−𝑗≤𝛽𝑊𝑣(𝑖+1);
Case 2 𝐷𝑣(0,𝑖+1)≥𝑘𝑣:

𝑊𝑣(𝑖+1)𝑊𝑣(𝑖)=𝑘𝑣𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑣(𝑗)}𝜇𝛽−𝑗;=min{𝐷𝑣(0,𝑖),𝑘𝑣}𝜇𝛽−(𝑖)+min{𝑘𝑣,𝐷𝑣(𝑖+1)}𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑣(𝑗)}𝜇𝛽−𝑗≤(𝛽+1)𝑊𝑣(𝑖+1);
In both cases, the weight 𝑊𝑣(𝑖) is at most (𝛽+1) times of 𝑊𝑣(𝑖+1). Thus, if a vertex cannot drop its level, either its current level is 0, or by doing so we have 𝑊𝑣(ℓ(𝑣)−1)>𝑐𝑣; the latter implies that the current value of 𝑊𝑣=𝑊𝑣(ℓ(𝑣)) is larger than 𝑐𝑣/(𝛽+1). Thus, if no vertex can drop its level, then the level scheme is (𝛽+1)-tight. ◻

If we set the level of every vertex to L initially, it is easy to check that by our choice of L as ⌈log𝛽(𝑛𝜇𝛼/𝑐min)⌉, such a level scheme is valid. Next, we examine each vertex one by one, and drop its level as much as possible while the scheme remains valid. In the end, we will obtain a non-improvable scheme, so that by the above lemma, the scheme is (𝛽+1)-tight. This implies a (𝛽+1)(2(𝛽/(𝛽−1))+1)-approximate solution for the WMCVC problem.

Maintaining an 𝛼(𝛽+1)-tight Level Scheme Dynamically
Fig. 1
figure 1
Framework of Sect. 3

Full size image
In this section, we present our O(1)-approximation algorithm for the WMCVC problem, with amortized 𝑂(log𝑛) update time for each edge insertion and edge deletion. We first state an invariant that is maintained throughout by our algorithm, and show how the latter is done. Next, we analyze the time required to maintain the invariant with the potential method, and show that our proposed method can be updated efficiently as desired. Similar to [6, 7], we allow a flexible range for the weight of a vertex, 𝑊𝑣, by a multiplicative constant 𝛼 so that we can obtain an 𝑂(log𝑛) amortized update time. See Fig. 1 for an illustration of the overall framework.

Let 𝑐∗𝑣 be 𝑐𝑣/𝛼(𝛽+1). The invariant that we maintain is as follows.

Invariant 1
(1) For every vertex 𝑣∈𝑉∖𝑉0, it holds that 𝑐∗𝑣≤𝑊𝑣≤𝑐𝑣, and (2) for every vertex 𝑣∈𝑉0, it holds that 𝑊𝑣≤𝑐𝑣 .

By maintaining the above invariant, we will automatically obtain an 𝛼(𝛽+1)-tight valid scheme. As mentioned, we will choose a value for 𝛼 in order to remove h from the approximation ratio, where h is the largest number of copies selected in the cover. In particular, we will set 𝛼=(2𝛽+1)/𝛽+2𝜖, where 0<𝜖<1 to balance the update time, and 𝛽=2.43 to minimize the approximation ratio, so that we achieve the following theorem.

Theorem 2
There exists a dynamic level scheme 𝜆 which can achieve a constant approximation ratio (≈36) for the WMCVC problem with 𝑂(log𝑛/𝜖) amortized update time.

The remainder of this section is devoted to proving Theorem 2.

The Algorithm: Handling Insertion or Deletion of an Edge
We now show how to maintain the invariant under edge insertions and deletions. A vertex is called dirty if it violates Invariant 1, and clean otherwise. Initially, the graph is empty, so that every vertex is clean and is at level zero.

Assume that at the time instant just prior to the 𝑡𝑡ℎ update, all vertices are clean. When the 𝑡𝑡ℎ update takes place, which either inserts or deletes an edge 𝑒=(𝑢,𝑣), we need to adjust the weights of u and v accordingly. Due to this adjustment, the vertices u, or v, or both may become dirty. To recover from this, we call the procedure FIX. The pseudo code of the update algorithm (Algorithm 1) appears in the next page.

figure b
figure c
The proposed algorithm ensures that Invariant 1 is maintained after each update, so that the dynamic scheme is 𝛼(𝛽+1)-tight as desired. To complete the discussion, as well as the proof of Theorem 2, it remains to show that each update can be performed efficiently, in amortized 𝑂(log𝑛) time.

Time Complexity
Each update involves two steps, namely the adjustment of weights of the endpoints, and the running of procedure FIX. We now give the time complexity analysis, where the main idea is to prove the following two facts: (Fact 1) the amortized time of the adjustment step is 𝑂(log𝑛), and (Fact 2) the amortized time of the procedure FIX is zero, irrespective of the number of vertices or edges that are affected during this step. Once the above two facts are proven, the time complexity analysis follows.

We use the standard potential method in our amortized analysis. Imagine that we have a bank account B. Initially, the graph is empty, and the bank account B has no potential. For each adjustment step during an edge insertion or deletion, we deposit some potential into the bank account B; after that, we use the potential in B to pay for the time of the procedure FIX.

Following the definition of [7], we say a vertex 𝑣∈𝑉 is active if its degree in G is non-zero, and passive otherwise. Now, the value of B is set by the following formula:

𝐵 = 1𝜖⋅(∑𝑒∈𝐸𝜙(𝑒)+∑𝑣∈𝑉𝜓(𝑣)),
where 0<𝜖<1, and 𝜙 and 𝜓 are functions defined as follows:

figure d
The following lemma proves Fact 1.

Lemma 4
After the adjustment step, the potential B increases by at most 𝑂(log𝑛/𝜖).

Proof
We separate the discussion into two cases: edge insertion and edge deletion. Let t be the moment where the update occurs.

Edge Insertion The inserted edge e generates a change of at most (𝛽(𝛽−1)+𝜖)𝐿 in 𝜙(𝑒). So, the summation ∑𝜙(𝑒) increases by at most 𝑂(log𝑛). For each endpoint v of e, there are two possible cases for the change in 𝜓(𝑣):

Case 1 The vertex v was passive at moment 𝑡−1. By the definition of 𝜓(𝑣), we had 𝜓(𝑣)=0 and ℓ(𝑣)=0 before the insertion of the edge e. Hence, after the insertion of e, we have

𝜓(𝑣) = 𝛽𝜇(𝛽−1)⋅max{0,𝛼𝑐∗𝑣−𝑊𝑣} ≤ 𝛽𝜇(𝛽−1)⋅𝛼𝑐∗𝑣≤ 𝛽𝜇(𝛽−1)⋅𝑐𝑣 < 𝛽𝛽−1.
Therefore, the summation ∑𝜓(𝑣) increases by at most O(1).

Case 2 The vertex v was active at moment 𝑡−1. In this case, the vertex v remains active at moment t. Thus, the weight 𝑊𝑣 increases, and 𝜓(𝑣) can only decrease.

In both cases, the total potential B increases by at most 𝑂(log𝑛/𝜖) after an edge insertion.

Edge Deletion If an edge e is deleted from E, then 𝜙(𝑒) drops to zero, so that the summation ∑𝜙(𝑒) decreases. In contrast, the weight 𝑊𝑣 of each endpoint v of e decreases by at most 𝜇𝛽−ℓ(𝑣). So, 𝜓(𝑣) increases by at most

𝛽(ℓ(𝑣)+1)𝜇(𝛽−1) ⋅ 𝜇𝛽−ℓ(𝑣)=𝛽𝛽−1,
which is a constant. Thus, the summation ∑𝜓(𝑣) increases by at most O(1). In summary, the total potential B increases by at most 𝑂(1/𝜖) after an edge deletion.

By the above arguments, the lemma follows. ◻

We now switch our attention to Fact 2. Observe that the procedure FIX performs a series of level up and level down events. For each such event, the level of a specific vertex v will be changed, which will then incur a change in its weight, and changes in the weights of some of the incident edges and their endpoints. The illustration and corresponding lemmas can refer to Fig. 1 first. Let 𝑡0 denote the moment before a level up or a level down event, and 𝑡1 denote the moment after the weights of the edges and vertices are updated due to this event. Let COUNT denote the number of times an edge in the graph G is updated (for simplicity, we assume that in one edge update, the weight and the assignment of the edge may be updated, and so do the weights of its endpoints, where all these can be done in O(1) time).

For ease of notation, in the following, a superscript t in a variable denotes the variable at moment t. For instance, 𝑊𝑡0𝑣 stands for the weight 𝑊𝑣 of v at moment 𝑡0. Also, we use Δ𝑥 to denote the quantity 𝑥𝑡0−𝑥𝑡1, so that

|ΔCOUNT|=|COUNT𝑡0−COUNT𝑡1|=COUNT𝑡1−COUNT𝑡0
represents the number of incident edges whose weights are changed between 𝑡0 and 𝑡1.

Briefly speaking, based on the level scheme and the potential function B, we can show:

For each level up event, each of the affected edges e would have its 𝜙(𝑒) value dropped, so that an 𝜖 fraction can pay for the weight updates of itself and its endpoints, while the remaining fraction can be converted into the increase in 𝜓(𝑣) value.

For each level down event, the reverse happens, where the vertex v would have its 𝜓(𝑣) value dropped, so that an 𝜖 fraction can pay for the weight updates of the affected edges and their endpoints, while the remaining fraction can be converted into the increase in 𝜙(𝑒) values of the affected edges. The 𝛼 value controls the frequency of the level down events, while trading this off with the approximation guarantee.

Sections 3.2.1 and 3.2.2 present the details of the amortized analysis of these two types of events, respectively. Finally, note that there is no potential input to the bank B after the adjustment step, so that the analysis implies that the procedure FIX must stop (as the potential in the bank is finite).

Amortized Time of Level Up
Let v be the vertex that undergoes the level up event, and 𝑖=ℓ(𝑣) denote its level at moment 𝑡0. By our notation, Δ𝐵=𝐵𝑡0−𝐵𝑡1 denotes the potential drop in the bank B from moment 𝑡0 to moment 𝑡1. To show that the amortized time of a level up event is at most zero, it is equivalent to show that Δ𝐵≥|ΔCOUNT|.

Recall that after a level up event, only the value of 𝜓(𝑣), the values of 𝜙(𝑒) and 𝜓(𝑢) for an edge (u, v) may be affected. In the following, we will examine carefully the changes in these values, and derive the desired bound for Δ𝐵. First, we have the following simple lemma.

Lemma 5
|ΔCOUNT|≤𝐷𝑡0𝑣(0,𝑖).

Proof
When v changes from level i to 𝑖+1, only those incident edges with levels i will be affected.

◻

The next three lemmas examine, respectively, the changes Δ𝜓(𝑣), Δ𝜙(𝑒), and Δ𝜓(𝑢).

Lemma 6
Δ𝜓(𝑣)=0.

Proof
Since v undergoes a level up event, we have 𝑊𝑡0𝑣>𝑐𝑣>𝛼𝑐∗𝑣, so that

𝜓𝑡0(𝑣)=0.
Next, we look at 𝜓𝑡1(𝑣). To begin with, we show a general relationship between 𝑊𝑡0𝑣 and 𝑊𝑡1𝑣, similar to that in the proof of Lemma 3. Let i denote the level ℓ(𝑣) of v at moment 𝑡0.

Case 1 𝐷𝑡0𝑣(0,𝑖)>𝑘𝑣

𝑊𝑡0𝑣𝑊𝑡1𝑣=𝑊𝑣(𝑖)=𝑘𝑣⋅𝜇𝛽−𝑖+min{𝑘𝑣,𝐷𝑡0𝑣(𝑖+1)}⋅𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗=𝑊𝑣(𝑖+1)=𝑘𝑣⋅𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗≥1𝛽+1𝑊𝑡0𝑣
Case 2 𝐷𝑡0𝑣(0,𝑖)≤𝑘𝑣

𝑊𝑡0𝑣𝑊𝑡1𝑣=𝑊𝑣(𝑖)=𝐷𝑡0𝑣(0,𝑖)⋅𝜇𝛽−𝑖+min{𝑘𝑣,𝐷𝑡0𝑣(𝑖+1)}⋅𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗=𝑊𝑣(𝑖+1)=min{𝑘𝑣,𝐷𝑡0𝑣(0,𝑖+1)}⋅𝜇𝛽−(𝑖+1)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗≥1𝛽+1𝑊𝑡0𝑣
Thus, 𝑊𝑡1𝑣≥𝑊𝑡0𝑣/(𝛽+1)>𝑐𝑣/(𝛽+1)=𝛼𝑐∗𝑣, which implies

𝜓𝑡1(𝑣)=0.
In summary, we have Δ𝜓(𝑣)=0−0=0 as desired. ◻

Lemma 7
For every edge e incident to v,

figure e
Proof
As mentioned, only those edges that are at the level in the range [0, i] are affected, so that

Δ𝜙(𝑢,𝑣)=𝜙𝑡0(𝑢,𝑣)−𝜙𝑡1(𝑢,𝑣)=(𝛽(𝛽−1)+𝜖)(𝐿−𝑖)−(𝛽(𝛽−1)+𝜖)(𝐿−(𝑖+1))=(𝛽(𝛽−1)+𝜖).
◻

Lemma 8
For every vertex 𝑢∈𝑁𝑡0𝑣, Δ𝜓(𝑢)≥−𝛽/(𝛽−1).

Proof
If ℓ(𝑢)∈[𝑖+1,𝐿], then 𝑤𝑡0(𝑢,𝑣)=𝑤𝑡1(𝑢,𝑣) and thus Δ𝑤(𝑢,𝑣)=0, which implies that Δ𝜓(𝑢)= 0. The potential 𝜓(𝑢) changes only when the level of vertex u is in the range [0, i]. Without loss of generality, we assume ℓ(𝑢)=𝑖 and prove the lemma by considering the relationship between 𝑘𝑢, 𝐷𝑡0𝑢(0,𝑖) and 𝐷𝑡0𝑢(𝑖+1). For those vertices u with ℓ(𝑢)∈[0,𝑖−1], we replace the term 𝐷𝑡0𝑢(0,𝑖) with 𝐷𝑡0𝑢(𝑖) while maintaining the same result.

Case 1𝐷𝑡0𝑢(0,𝑖)>𝑘𝑢, 𝐷𝑡0𝑢(𝑖+1)≥𝑘𝑢

𝑊𝑡0𝑢 = 𝑊𝑡1𝑢⇒Δ𝜓(𝑢) = 0.
Case 2𝐷𝑡0𝑢(0,𝑖)>𝑘𝑢, 𝐷𝑡0𝑢(𝑖+1)<𝑘𝑢

𝑊𝑡1𝑢Δ𝜓(𝑢) = 𝑊𝑡0𝑢+𝜇𝛽−(𝑖+1) = 𝛽(ℓ(𝑢)+1)𝜇(𝛽−1)⋅𝜇𝛽−(𝑖+1) = 1𝛽−1⋅𝛽ℓ(𝑢)−𝑖 > 0.
Case 3𝐷𝑡0𝑢(0,𝑖)≤𝑘𝑢, 𝐷𝑡0𝑢(𝑖+1)<𝑘𝑢

𝑊𝑡1𝑢Δ𝜓(𝑢) = 𝑊𝑡0𝑢−𝜇(𝛽−𝑖−𝛽−(𝑖+1)) = −𝛽(ℓ(𝑢)+1)𝜇(𝛽−1)⋅𝜇(𝛽−𝑖−𝛽−(𝑖+1)) = −𝛽(ℓ(𝑢)+1)𝛽𝑖+1 ≥ −1.
Case 4𝐷𝑡0𝑢(0,𝑖)≤𝑘𝑢, 𝐷𝑡0𝑢(𝑖+1)≥𝑘𝑢

𝑊𝑡1𝑢Δ𝜓(𝑢) =𝑊𝑡0𝑢−𝜇𝛽−𝑖 = −𝛽(ℓ(𝑢)+1)𝜇(𝛽−1)⋅𝜇𝛽−𝑖 = −𝛽𝛽−1(𝛽ℓ(𝑢)−𝑖) ≥ −𝛽𝛽−1.
◻

Based on the above lemmas, we derive the following and finish the proof for the case of level up.

Δ𝐵 = 1𝜖⋅⎛⎝⎜⎜Δ𝜓(𝑣)+∑𝑒∈𝐸Δ𝜙(𝑒)+∑𝑢∈𝑁𝑡0𝑣Δ𝜓(𝑢)⎞⎠⎟⎟ ≥ 1𝜖⋅(0+(𝛽(𝛽−1)+𝜖)𝐷𝑡0𝑣(0,𝑖)−𝛽𝛽−1𝐷𝑡0𝑣(0,𝑖)) = 𝐷𝑡0𝑣(0,𝑖)  ≥  |ΔCOUNT|.
Amortized Time of Level Down
We now show that the amortized time of level down for a vertex v is at most zero. Similar to the case of level up, we examine Δ𝜓(𝑣), Δ𝜙(𝑒), and Δ𝜓(𝑢), and show that Δ𝐵≥|ΔCOUNT|.

Before starting the proof of the level down case, recall that we have mentioned the parameter h at the end of the introduction, where h is the largest number of selected copies of all the vertices. That is, ℎ=max𝑣{⌈|𝛿𝑡0(𝑣)|/𝑘𝑣⌉}. Also, we let ℎ′=max𝑣{⌈𝐷𝑡0𝑣(0,ℓ(𝑣))/𝑘𝑣⌉}, where ℎ′≥ℎ, and set 𝜉≥0 such that ℎ′=ℎ+𝜉.

Lemma 9
|ΔCOUNT|≤𝐷𝑡0𝑣(0,𝑖)<ℎ′⋅𝛽𝑖𝑐∗𝑣𝜇.

Proof
When the vertex v moves from level i to 𝑖−1, only those edges whose levels are at most i are affected. This shows the first part of the inequality. Also, because v undergoes level down, we have 𝑊𝑡0𝑣<𝑐∗𝑣. Then, for the latter inequality, we partition the proof into two cases:

Case 1    ⌈|𝛿𝑡0(𝑣)|/𝑘𝑣⌉=1

𝑊𝑡0𝑣=& 𝐷𝑡0𝑣(0,𝑖)⋅𝜇𝛽−𝑖+∑𝑗>𝑖min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗⇒& 𝑐∗𝑣 > 𝐷𝑡0𝑣(0,𝑖)⋅𝜇𝛽−𝑖⇒& 𝐷𝑡0𝑣(0,𝑖) < 𝛽𝑖𝑐∗𝑣𝜇.
Case 2    ⌈|𝛿𝑡0(𝑣)|/𝑘𝑣⌉>1

𝑊𝑡0𝑣=& 𝑘𝑣⋅𝜇𝛽−𝑖+∑𝑗>𝑖min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗⇒& 𝑐∗𝑣>𝑘𝑣⋅𝜇𝛽−𝑖⇒& ℎ′𝑐∗𝑣>𝐷𝑡0𝑣(0,𝑖)𝑘𝑣⋅𝑘𝑣⋅𝜇𝛽−𝑖⇒& 𝐷𝑡0𝑣(0,𝑖)<ℎ′⋅𝛽𝑖𝑐∗𝑣𝜇.
◻

Now, we are ready to examine Δ𝜓(𝑣), Δ𝜙(𝑒), and Δ𝜓(𝑢), through the following lemmas.

Lemma 10
For every vertex 𝑢∈𝑁𝑡0𝑣, Δ𝜓(𝑢)≥−1/(𝛽−1).

Proof
If ℓ(𝑢)∈[𝑖,𝐿], then 𝑤𝑡0(𝑢,𝑣)=𝑤𝑡1(𝑢,𝑣) and Δ𝑤(𝑢,𝑣)=0, which implies Δ𝜓(𝑢)=0. The changes of potentials only occur at the vertex whose level is in the range [0,𝑖−1]. Without loss of generality, we assume ℓ(𝑢)=𝑖−1 and we consider the relationship between 𝑘𝑢, 𝐷𝑡0𝑢(0,𝑖−1) and 𝐷𝑡0𝑢(𝑖). For those vertices u and ℓ(𝑢)∈[0,𝑖−2], we replace the term 𝐷𝑡0𝑢(0,𝑖−1) with 𝐷𝑡0𝑢(𝑖−1) while maintaining the same result.

Case 1 𝐷𝑡0𝑢(0,𝑖−1)≥𝑘𝑢, 𝐷𝑡0𝑢(𝑖)>𝑘𝑢

𝑊𝑡0𝑢 = 𝑊𝑡1𝑢⇒Δ𝜓(𝑢) = 0.
Case 2 𝐷𝑡0𝑢(0,𝑖−1)≥𝑘𝑢, 𝐷𝑡0𝑢(𝑖)≤𝑘𝑢

𝑊𝑡1𝑢Δ𝜓(𝑢) = 𝑊𝑡0𝑢−𝜇𝛽−𝑖 = −𝛽(ℓ(𝑢)+1)𝜇(𝛽−1)⋅𝜇𝛽−𝑖 = −𝛽𝛽−1⋅𝛽ℓ(𝑢)−𝑖(∵ℓ(𝑢)≤𝑖−1) ≥ −1𝛽−1.
Case 3𝐷𝑡0𝑢(0,𝑖−1)<𝑘𝑢, 𝐷𝑡0𝑢(𝑖)>𝑘𝑢

⇒& 𝜓𝑡0(𝑢) 𝜓𝑡1(𝑢)⇒Δ𝜓(𝑢) > 0. 𝑊𝑡1𝑢=𝑊𝑡0𝑢+𝜇𝛽−(𝑖−1)
Case 4𝐷𝑡0𝑢(0,𝑖−1)<𝑘𝑢, 𝐷𝑡0𝑢(𝑖)≤𝑘𝑢

⇒& 𝜓𝑡0(𝑢) 𝜓𝑡1(𝑢)⇒Δ𝜓(𝑢) > 0.𝑊𝑡1𝑢=𝑊𝑡0𝑢+𝜇(𝛽−(𝑖−1)−𝛽−𝑖)
◻

Next, we partition 𝑁𝑡0𝑣 into three subsets: X, 𝑌1 and 𝑌2, i.e. 𝑁𝑡0𝑣=𝑋∪𝑌1∪𝑌2, where

𝑋𝑌1𝑌2={𝑢∣𝑢∈𝑁𝑡0𝑣(0,𝑖−1)},={𝑢∣𝑢∈𝑁𝑡0𝑣(𝑖)},={𝑢∣𝑢∈𝑁𝑡0𝑣(𝑖+1,𝐿)}.
Lemma 11
For every edge (u, v) incidents to a vertex v,

figure f
Proof
Fix any vertex 𝑢∈𝑁𝑡0𝑣. We consider the following two possible scenarios.

Case 1𝑢∈𝑌1∪𝑌2 When the level of the vertex v decreases from i to 𝑖−1, ℓ𝑡0(𝑢,𝑣)=ℓ𝑡1(𝑢,𝑣) and thus 𝜙𝑡0(𝑢,𝑣)=𝜙𝑡1(𝑢,𝑣), which implies Δ𝜙(𝑢,𝑣)=0.

Case 2 𝑢∈𝑋

When the level of the vertex v decreases from i to 𝑖−1, we have ℓ𝑡0(𝑢,𝑣)=𝑖 and ℓ𝑡1(𝑢,𝑣)=(𝑖−1). The following result is thus derived:

Δ𝜙(𝑢,𝑣)=(𝛽(𝛽−1)+𝜖)(𝐿−𝑖)−(𝛽(𝛽−1)+𝜖)(𝐿−𝑖+1)=−(𝛽(𝛽−1)+𝜖).
◻

Next, let 𝑊𝑡0𝑣=𝑥+𝑦1+𝑦2, where x, 𝑦1 and 𝑦2 on the right-hand-side correspond to the weights generated by the subsets X, 𝑌1, 𝑌2, respectively. So, we get the following lemmas:

Lemma 12
∑𝑢∈𝑁𝑡0𝑣Δ𝜙(𝑢,𝑣)≤−(𝛽(𝛽−1)+𝜖)(ℎ𝑥𝛽𝑖/𝜇).

Proof
We consider |X| in the following two cases:

Case 1|𝑋| ≤ 𝑘𝑣

𝑥=|𝑋|⋅𝜇𝛽−𝑖⇒|𝑋|=𝑥𝛽𝑖𝜇≤ℎ𝑥𝛽𝑖/𝜇(∵h≥1)
Case 2|𝑋| > 𝑘𝑣. Here, we may assume, without loss of generality, that 𝑦1=0. Then, we have

 𝑥=𝑘𝑣⋅𝜇𝛽−𝑖⇒ |𝑋|=|𝑋|𝑘𝑣⋅𝑥𝛽𝑖𝜇≤⌈𝛿𝑡0(𝑣)𝑘𝑣⌉⋅𝑥𝛽𝑖𝜇≤ℎ⋅𝑥𝛽𝑖𝜇.
Finally, since

∑𝑢∈𝑁𝑡0𝑣Δ𝜙(𝑢,𝑣)=|𝑋|⋅−(𝛽(𝛽−1)+𝜖),
the lemma thus follows. ◻

Lemma 13
Δ𝜓(𝑣)=(𝛼𝑐∗𝑣−𝑥−𝑦1−𝑦2)⋅𝛽𝑖+1𝜇(𝛽−1)−max{0,𝛼𝑐∗𝑣−𝛽𝑥−𝑦1−𝑦2}⋅𝛽𝑖𝜇(𝛽−1).

Proof
We have 𝑊𝑡0𝑣=𝑥+𝑦1+𝑦2<𝑐∗𝑣, and we have to consider the following relationship between 𝑥+𝑦1 and 𝑘𝑣⋅𝜇𝛽−𝑖. With the above relationship, we compute 𝑊𝑡1𝑣 by the following:

Case 1 |𝑋|<𝑘𝑣 and |𝑋+𝑌1|≤𝑘𝑣:

𝑊𝑡0𝑣𝑊𝑡1𝑣=𝑊𝑣(𝑖)=𝐷𝑡0𝑣(0,𝑖)𝜇𝛽−(𝑖)+∑𝑗>𝑖min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗;=𝑊𝑣(𝑖−1)=𝐷𝑡0𝑣(0,𝑖−1)𝜇𝛽−(𝑖−1)+𝐷𝑡0𝑣(𝑖)𝜇𝛽−(𝑖)+∑𝑗>𝑖+1min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗=𝛽𝑥+𝑦1+𝑦2;
Case 2 |𝑋+𝑌1|>𝑘𝑣:

𝑊𝑡0𝑣𝑊𝑡1𝑣=𝑊𝑣(𝑖)=𝑘𝑣𝜇𝛽−(𝑖)+∑𝑗>𝑖min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗;=𝑊𝑣(𝑖−1)=min{𝑘𝑣,𝐷𝑡0𝑣(0,𝑖−1)}𝜇𝛽−(𝑖−1)+min{𝑘𝑣,𝐷𝑡0𝑣(𝑖)}𝜇𝛽−(𝑖)+∑𝑗>𝑖min{𝑘𝑣,𝐷𝑡0𝑣(𝑗)}𝜇𝛽−𝑗≤(𝛽+1)𝑥+𝑦1+𝑦2;
By the above cases, we have a weight change of at least 𝛽𝑥+𝑦1+𝑦2 in 𝑊𝑣. The desired bound on Δ𝜓(𝑣) can thus be obtained by direct substitution. ◻

Finally, depending upon the value of 𝛼𝑐∗𝑣−𝛽𝑥−𝑦1−𝑦2, we consider two possible scenarios, where we show that in each case, Δ𝐵≥ℎ′⋅𝛽𝑖𝑐∗𝑣/𝜇. This in turn implies Δ𝐵≥|ΔCOUNT| as desired.

Case 1𝛼𝑐∗𝑣≤𝛽𝑥+𝑦1+𝑦2

𝜖⋅Δ𝐵=⎛⎝⎜⎜∑𝑢∈𝑁𝑡0𝑣Δ𝜓(𝑢)+∑𝑒∈𝐸Δ𝜙(𝑒)+Δ𝜓(𝑣)⎞⎠⎟⎟≥−1𝛽−1⋅ℎ𝑥𝛽𝑖𝜇−(𝛽(𝛽−1)+𝜖)⋅ℎ𝑥𝛽𝑖𝜇+(𝛼𝑐∗𝑣−𝑥−𝑦1−𝑦2)⋅𝛽𝑖+1𝜇(𝛽−1)≥𝛽𝑖𝜇(−1𝛽−1ℎ𝑐∗𝑣−(𝛽(𝛽−1)+𝜖)ℎ𝑐∗𝑣+(𝛼−1)𝛽𝛽−1𝑐∗𝑣)(∵𝑐∗𝑣≥𝑥+𝑦1+𝑦2)=𝛽𝑖𝑐∗𝑣𝜇(𝛽−1)((𝛼−1)𝛽−ℎ−(𝛽+(𝛽−1)𝜖)ℎ)=𝛽𝑖𝑐∗𝑣𝜇((𝛼−1)𝛽(𝛽−1)−ℎ(𝛽+1𝛽−1+𝜖))if let 𝛼=𝛽−1𝛽(ℎ(𝛽+1𝛽−1+2𝜖)+𝜉𝜖)+1≥𝜖ℎ′⋅𝛽𝑖𝑐∗𝑣𝜇.
Case 2 𝛼𝑐∗𝑣>𝛽𝑥+𝑦1+𝑦2

𝜖⋅Δ𝐵=⎛⎝⎜⎜∑𝑢∈𝑁𝑡0𝑣Δ𝜓(𝑢)+∑𝑒∈𝐸Δ𝜙(𝑒)+Δ𝜓(𝑣)⎞⎠⎟⎟≥−1𝛽−1⋅ℎ𝑥𝛽𝑖𝜇−(𝛽(𝛽−1)+𝜖)⋅ℎ𝑥𝛽𝑖𝜇+(𝛼𝑐∗𝑣−𝑥−𝑦1−𝑦2)⋅𝛽𝑖+1𝜇(𝛽−1)−(𝛼𝑐∗𝑣−𝛽𝑥−𝑦1−𝑦2)⋅𝛽𝑖𝜇(𝛽−1)=𝛽𝑖𝜇(𝛽−1)⋅(−𝑥ℎ−(𝛽+(𝛽−1)𝜖)𝑥ℎ+𝛼(𝛽−1)𝑐∗𝑣−(𝛽−1)(𝑦1+𝑦2))=𝛽𝑖𝜇(𝛽−1)⋅(𝛼(𝛽−1)𝑐∗𝑣−(𝛽+1+(𝛽−1)𝜖)𝑥ℎ−(𝛽−1)(𝑦1+𝑦2))≥𝛽𝑖𝑐∗𝑣𝜇⋅(𝛼−ℎ(𝛽+1𝛽−1+𝜖))if let 𝛼=𝛽−1𝛽(ℎ(𝛽+1𝛽−1+2𝜖)+𝜉𝜖)+1≥𝜖ℎ′⋅𝛽𝑖𝑐∗𝑣𝜇.
Thus, the level scheme remains 𝛼(𝛽+1)-tight after a level down event. However, the value of h is bounded by n, and h appears inside 𝛼, so that the approximation ratio of the scheme may become n in the worst-case. Fortunately, with the help of the following lemma, we can choose 𝛼 carefully, which in turn improves the approximation ratio from n to O(1).

Lemma 14
Suppose we set 𝛼≥𝛽/(𝛽−1). By the time a level down event occurs at v at moment 𝑡0, exactly one copy of v is selected. That is, ⌈|𝛿𝑡0(𝑣)|/𝑘𝑣⌉=1.

Proof
Assume to the contrary that v could decrease its level even if more than one copy of v is selected. Since v levels down, its weight 𝑊𝑣 must have decreased; this can happen only in one of the following cases:

Case 1 An incident edge whose level is in the range [0,ℓ(𝑣)] is deleted. In this case, since more than one copy of v is selected, 𝑊𝑣 is unchanged. Thus, this case cannot happen.

Case 2 An incident edge whose level is in the range [ℓ(𝑣)+1,𝐿] is deleted. In this case, the weight 𝑊𝑡0𝑣 at moment 𝑡0 is less than 𝑐∗𝑣. On the other hand, at the moment 𝑡′ when v attains the current level ℓ(𝑣) (from level ℓ(𝑣)−1), its weight 𝑊𝑡′𝑣 was at least 𝑐𝑣 before it leveled up, and became at least 𝑐𝑣/(𝛽+1) after it leveled up.

(The reason is from the proof of Lemma 3: the weight change between consecutive levels is at most a factor of 𝛽+1.) This implies that:

𝑐∗𝑣& > 𝑊𝑡0𝑣 ≥ 𝑘𝑣𝜇𝛽−ℓ(𝑣)
The above relation is true because v has to decrease its level at moment 𝑡0, which implies the first inequality.

Next, the second inequality holds because more than one copy of v is selected. Also, we have the following relation:

(𝛽/(𝛽−1))𝑘𝑣𝜇𝛽−ℓ(𝑣) ≥𝑊𝑡′𝑣 ≥ 𝑐𝑣/(𝛽+1)
To see why the above is true, notice that the first inequality holds since the leftmost term is the maximum possible value of 𝑊𝑣, while the second inequality holds naturally with the non-zero level of v. Combining the above two inequalities, we would have

𝑐𝑣𝛼(𝛽+1) = 𝑐∗𝑣 > 𝑘𝑣𝜇𝛽−ℓ(𝑣) ≥ 𝑐𝑣(𝛽−1)𝛽(𝛽+1),
so that 𝛼<𝛽/(𝛽−1). Which leads to a contradiction

Thus, the lemma follows. ◻

The above lemma states that if we choose 𝛼≥𝛽/(𝛽−1), then level down of v occurs only when ⌈|𝛿𝑡0(𝑣)|/𝑘𝑣⌉ is one. Then, Case 2 inside the proof of Lemma 9 will not occur, so that we can strengthen Lemma 9 to get |ΔCOUNT|≤𝐷𝑡0𝑣(0,𝑖)<𝛽𝑖𝑐∗𝑣/𝜇. Similarly, the proof of Lemma 12 can be revised, so that we can strengthen Lemma 12 by replacing h with one. On the other hand, we need 𝛼≥(2𝛽+1)/𝛽+2𝜖 to satisfy the amortized time analysis. Consequently, we set 𝛼=(2𝛽+1)/𝛽+2𝜖, and we can achieve the desired bound Δ𝐵≥𝛽𝑖𝑐∗𝑣/𝜇≥|ΔCOUNT|. The proof for the level down case is complete.

Summary and Extensions
With the appropriate setting of 𝛼=(2𝛽+1)/𝛽+2𝜖, where 0<𝜖<1, we get an 𝛼(𝛽+1)-tight level scheme. Then, by setting 𝛽=2.43, Theorem 2 is proven so that we get an approximate solution of ratio close to 36 with 𝑂((log𝑛)/𝜖) amortized update time. Finally, we consider two natural extensions of the capacitated vertex cover problem, and show how to adapt the proposed level scheme to handle these extensions

Capacitated Set Cover Here, we consider the capacitated set cover problem which is equivalent to the capacitated vertex cover problem in hyper-graphs. A hyper-graph 𝐺=(𝑉,𝐸) has |𝑉|=𝑛 vertices and |𝐸|=𝑚 hyper-edges, where each hyper-edge is incident to a set of vertices. Suppose that each hyper-edge is incident to at most f vertices. Our target is to find a subset of vertices, each with a certain number of copies, so that every edge in E is covered, while the total cost of the selected vertices (each of which is weighted by the corresponding number of copies) is minimized. Here, we treat the hyper-graph vertex cover problem as if the original vertex cover problem, and use the same level scheme and the definition of the weight of a vertex 𝑊𝑣. That is, the weight 𝑊𝑣 of a vertex v is defined as follows:

Case 1 𝐷𝑣(0,ℓ(𝑣))>𝑘𝑣:

𝑊𝑣=𝑘𝑣𝜇𝛽−ℓ(𝑣)+∑𝑖>ℓ(𝑣)min{𝑘𝑣,𝐷𝑣(𝑖)}𝜇𝛽−𝑖
Case 2 𝐷𝑣(0,ℓ(𝑣))≤𝑘𝑣:

𝑊𝑣=𝐷𝑣(0,ℓ(𝑣))𝜇𝛽−ℓ(𝑣)+∑𝑖>ℓ(𝑣)min{𝑘𝑣,𝐷𝑣(𝑖)}𝜇𝛽−𝑖
We also use the same conditions for level up and level down. However, we still need to do some adjustments for this problem. First, we re-design the number of levels, L, to be ⌈log𝛽(𝑚𝜇𝛼/𝑐min)⌉. Next, we adjust the flexible range by multiplying it by f so that 𝑊𝑣∈(𝑐𝑣/𝑓𝜀,𝑐𝑣]. In Lemma 2, we have proved that if there are more than 𝑘𝑣 edges assigned to a vertex v, then every edge is accounted for at most 2(𝛽/(𝛽−1))𝜋𝑒. But here, a hyper-edge e may be incident to at most f vertices so that the total time for a hyper-edge is bounded by at most (2(𝛽/(𝛽−1))+(𝑓−1))𝜋𝑒 instead.

By the arguments of Sect. 2, we observe that the approximation ratio comes from (1) the flexible range of weight function 𝑊𝑣 and (2) the total number of times an edge is used. Since both of these terms are increased by a factor of f in the dynamic set cover problem; thus, the approximation ratio here becomes 𝑂(𝑓2).

When we consider the updated time in the dynamic setting, we modify our potential function as follows:

figure g
From Sect. 3, we know that the update time in the dynamic vertex cover problem is related to the number of levels in the level scheme. Here, this number will be adjusted to 𝑂(log(𝑚+𝑛)). Furthermore, a hyper-edge is incident to at most f vertices (instead of at most two vertices in the vertex cover problem). Thus, it will affect at most f vertices when there is an edge insertion or deletion. Combining these, we can readily show that our scheme achieves 𝑂(𝑓log(𝑚+𝑛)) amortized update time.

Capacitated Vertex Cover with Non-uniform Unsplittable Demand In this part, we consider a more general model in which each edge has an unsplittable demand. That is, the demand of each edge must be covered by exactly one of its endpoints. We first show that, in a static setting, with some modification, our approach in Sect. 2 already gives an O(1)-approximate solution. First, when we consider the general case, we have to revise the capacity constraint in the primal problem to 𝑘𝑣𝑥𝑣−∑𝑒∈𝑁𝑣𝑦𝑒𝑣𝑑𝑒≥0, and we also have to change the vertex constraint in the dual problem to 𝑞𝑣𝑑𝑒+𝑙𝑒𝑣≥𝜋𝑒.

To cope with these changes, we will revise the number of levels of our level scheme to be 𝐿=⌈log𝛽(𝑘max𝜇𝛼/𝑐min)⌉, where 𝑘max denotes the maximum capacity of a vertex. Moreover, we adjust our definition of the weight 𝑊𝑣 of a vertex as follows:

Case 1 ∑𝑒∣𝑒∼𝑣,ℓ(𝑒)=ℓ(𝑣)𝑑𝑒>𝑘𝑣:

𝑊𝑣=𝑘𝑣𝜇𝛽−ℓ(𝑣)+∑𝑗∣ℓ(𝑒)=𝑗>ℓ(𝑣)min{𝑘𝑣,∑𝑒𝑑𝑒}𝜇𝛽−𝑗
Case 2 ∑𝑒∣𝑒∼𝑣,ℓ(𝑒)=ℓ(𝑣)𝑑𝑒≤𝑘𝑣:

𝑊𝑣=∑𝑒∣𝑒∼𝑣,ℓ(𝑒)=ℓ(𝑣)𝑑𝑒𝜇𝛽−ℓ(𝑣)+∑𝑗∣ℓ(𝑒)=𝑗>ℓ(𝑣)min{𝑘𝑣,∑𝑒𝑑𝑒}𝜇𝛽−𝑗
where 𝑒∼𝑣 denotes e is an edge incident to v.

Due to the change of the mathematical model in both primal and dual problems, we need a slightly different strategy from that in Sect. 2. We use the total demand of the unassigned edges to replace the number of unassigned edges to determine the value of 𝑞𝑣 and 𝑙𝑒𝑣. In particular:

If ⌈∑𝑒∈𝛿(𝑣)𝑑𝑒/𝑘𝑣⌉>1: 𝑞𝑣=𝜇𝛽−ℓ(𝑣), and 𝑙𝑒𝑣=0;

If ⌈∑𝑒∈𝛿(𝑣)𝑑𝑒/𝑘𝑣⌉≤1: 𝑞𝑣=𝜇∑𝑖∣∑ℓ(𝑒)=𝑖𝑑𝑒≥𝑘𝑣𝛽−𝑖, 𝑙𝑒𝑣=0 if ∑ℓ(𝑒)=𝑖𝑑𝑒≥𝑘𝑣, and 𝑙𝑒𝑣=𝑑𝑒⋅𝜇𝛽−ℓ(𝑒) otherwise.

For every edge e: 𝜋𝑒=𝑑𝑒⋅𝜇𝛽−ℓ(𝑒).

Then, we use the same technique as that in Sect. 2, and it is easy to verify that the above choices of 𝑞𝑣, 𝑙𝑒𝑣, and 𝜋𝑒 give a feasible solution to the dual problem. Again, for the total cost of our solution, we separate the analysis into two parts, based on the multiplicity of the vertex v:

Case 1 ⌈∑𝑒∈𝛿(𝑣)𝑑𝑒/𝑘𝑣⌉>1: In this case, the external component of 𝑊𝑣 is at most 1/(𝛽−1) of the internal component, so that 𝑊𝑣≤(𝛽/(𝛽−1))𝑘𝑣𝑞𝑣. Then, the cost of all copies of v is:

⌈∑𝑒∈𝛿(𝑣)𝑑𝑒/𝑘𝑣⌉⋅𝑐𝑣≤⌈∑𝑒∈𝛿(𝑣)𝑑𝑒/𝑘𝑣⌉⋅𝜀⋅𝑊𝑣≤2⋅∑𝑒∈𝛿(𝑣)𝑑𝑒𝑘𝑣⋅𝜀⋅(𝛽/(𝛽−1))𝑘𝑣𝑞𝑣=2(𝛽/(𝛽−1))𝜀⋅∑𝑒∈𝛿(𝑣)𝑑𝑒𝑞𝑣 = 2(𝛽/(𝛽−1))𝜀⋅∑𝑒∈𝛿(𝑣)𝜋𝑒.
Case 2 ⌈∑𝑒∈𝛿(𝑣)𝑑𝑒/𝑘𝑣⌉ =1: In this case, we pick one copy of vertex v, whose cost is:

𝑐𝑣≤𝜀⋅𝑊𝑣≤𝜀⋅∑𝑒∼𝑣𝜋𝑒 = 𝜀⋅(∑𝑒∈𝛿(𝑣)𝜋𝑒+∑𝑒∉𝛿(𝑣),𝑒∼𝑣𝜋𝑒),
As compared to the uniform demand case, every edge multiplies its demand. Yet, the selected copies also multiply the same constant. Thus, with an analogous analysis, the approximation ratio of the revised algorithm in this section (for non-uniform demand) is the same for the uniform demand case.

Unfortunately, when we consider the dynamic operations, an edge insertion or deletion may cause a vertex to adjust its level severely because the edge weight, in this case, connects to the edge’s demand. It is open whether we can maintain a constant approximation ratio with polylogarithmic update time for this general problem where edges have non-uniform unsplittable demands.

However, we still present two simple approaches for this problem by combining other techniques with the initially proposed level scheme in Sect. 2.

The first approach is to partition all of the edges into log2(𝑑max) clusters according to its demand (where the ith cluster contains edges with demand in the range [2𝑖−1,2𝑖)), and maintain each cluster by its own data structure. In every cluster, we set value of 𝛼=2((2𝛽+1)/𝛽+2𝜖). Whenever there is an edge insertion or edge deletion, we run the proposed algorithm in the corresponding cluster. That is, only the data structure of one cluster is updated per each edge update event. For the output, we select the vertices, and their corresponding number of copies, in each of the clusters to cover all the edges in that cluster. After these changes, we obtain an 𝑂(log𝑑max) approximation ratio solution with 𝑂(𝐿/𝜖)=𝑂(log𝑘max/𝜖) update time, where 𝑑max=max𝑒{𝑑𝑒} and 𝑘max=max𝑣{𝑘𝑣}.

The second approach works for integral demands. We view an edge e with demand d as d edges 𝑒1,𝑒2,…,𝑒𝑑 with uniform demand between the same endpoints. Then, we execute the proposed level scheme. The only problem is that those edges 𝑒1,𝑒2,…,𝑒𝑑 corresponding to the original edge e may be assigned to the different endpoints. We simply assign all edges to the endpoint that is covering the majority of these edges, based on the solution in the proposed level scheme. After that, the total time is increased by at most a factor of 2, so that we obtain an O(1)-approximate solution with the 𝑂(𝑑max𝐿/𝜖)=𝑂(𝑑maxlog𝑘max/𝜖) amortized update time.

Concluding Remarks
We have extended dynamic vertex cover to the more general WMCVC problem, and developed a constant-factor dynamic approximation algorithm with 𝑂(log𝑛/𝜖) amortized update time, where n is the number of the vertices. Note that, in Gupta et al.’s very recent paper [12], their greedy algorithm with minor adaptions is also able to work for the soft dynamic capacitated vertex cover problem. However, it only gives a logarithmic-factor approximation algorithm with 𝑂(log𝑛) amortized update time. Moreover, our proposed algorithm can also be extended to solve the (soft) capacitated set cover problem, and the soft capacitated vertex cover problem with non-uniform unsplittable edge demand.

We conclude this paper with some open problems. First, recall that in the static model, the soft capacitated vertex cover problem [11] can be approximated within a factor of two and three for the uniform and non-uniform edge demand cases, respectively. Here, we have shown that it is possible to design a dynamic scheme with O(1) approximation ratio with polylogartihmic update time for the uniform edge demand case. Thus, designing an O(1)-approximation ratio algorithm with 𝑂(log𝑘max), or polylogarithmic, update time for the non-uniform edge demand case seems promising.

Moreover, it would also be of significant interest to explore whether it is possible to derive a constant approximation ratio for the WMCVC problem under constant update time. Also, in recent years, more studies on the worst-case update time for dynamic algorithms have been conducted. It would be worthwhile to examine update time in the worst-case analysis.