Let C be an arithmetic circuit of size s, given as input that computes a polynomial 𝑓∈𝔽[𝑥1,𝑥2,…,𝑥𝑛], where 𝔽 is a finite field or the field of rationals. Using the Hadamard product of polynomials, we obtain new algorithms for the following two problems first studied by Koutis and Williams (Faster algebraic algorithms for path and packing problems, 2008, https://doi-org.ezproxy.auckland.ac.nz/10.1007/978-3-540-70575-8_47; ACM Trans Algorithms 12(3):31:1–31:18, 2016, https://doi-org.ezproxy.auckland.ac.nz/10.1145/2885499; Inf Process Lett 109(6):315–318, 2009, https://doi-org.ezproxy.auckland.ac.nz/10.1016/j.ipl.2008.11.004):

(k,n)−MLC: is the problem of computing the sum of the coefficients of all degree-k multilinear monomials in the polynomial f. We obtain a deterministic algorithm of running time (𝑛↓𝑘/2)⋅𝑛𝑂(log𝑘)⋅𝑠𝑂(1). This improvement over the 𝑂(𝑛𝑘) time brute-force search algorithm answers positively a question of Koutis and Williams (2016). As applications, we give exact counting algorithms, faster than brute-force search, for counting the number of copies of a tree of size k in a graph, and also the problem of exact counting of m-dimensional k-matchings.

k−MMD: is the problem of checking if there is a degree-k multilinear monomial in the polynomial f with non-zero coefficient. We obtain a randomized algorithm of running time 𝑂(4.32𝑘⋅𝑛𝑂(1)). Additionally, our algorithm is polynomial space bounded.

Other results include fast deterministic algorithms for (k,n)−MLC and k−MMD problems for depth three circuits.

Access provided by University of Auckland Library

Introduction
Let 𝔽 be any field and 𝑋={𝑥1,𝑥2,…,𝑥𝑛} be a set of commuting variables. Let 𝔽[𝑋] denote the commutative polynomial ring of multivariate polynomials over the field 𝔽 in the variables X. That is, the elements of 𝔽[𝑋] are 𝔽-linear combinations of monomials in the variables X, where monomials are variable products of the form

𝑚=𝑥𝑒11𝑥𝑒22⋯𝑥𝑒𝑛𝑛,
where the 𝑒𝑖 are nonnegative integers. The degree of the monomial m, defined above, is 𝑒1+𝑒2+⋯+𝑒𝑛. We denote by 𝑋𝑑 the set of all degree-d monomials in the variables X. The degree of a polynomial f is the maximum degree of a nonzero monomial occurring in f.

We denote the coefficient of a monomial m in f by [m]f. Thus, if f is a polynomial of degree d we can write it as a sum

𝑓=∑𝑚∈𝑋𝑑[𝑚]𝑓⋅𝑚,
A polynomial 𝑓∈𝔽[𝑋] is homogeneous if all its nonzero monomials have the same degree. A linear form is a homogeneous degree-1 polynomial. For a degree-d polynomial 𝑓∈𝔽[𝑋], its homogeneous component of degree ℓ≤𝑑, denoted 𝐻ℓ(𝑓) is

𝐻ℓ(𝑓)=∑𝑚∈𝑋ℓ[𝑚]𝑓⋅𝑚.
Thus, we can write 𝑓=∑𝑑ℓ=0𝐻ℓ(𝑓).

Computationally, a polynomial f in 𝔽[𝑋] can be given as input in different representations. When f is given explicitly as a list of all its nonzero monomials with coefficients, that is called the sparse representation. The sparse representation is usually inefficient because a degree d polynomial can have (𝑛+𝑑𝑑) nonzero monomials. There are more compact representations of polynomials, defined below, well-studied in algebraic complexity theory (see e.g. the survey by Shpilka and Yehudayoff [33]), that are central to the present paper.

Definition 1.1
(Arithmetic Circuit) An arithmetic circuit C over 𝔽 is a directed acyclic graph such that each indegree 0 node is labeled with an input variable from X or a scalar from 𝔽. Each internal node is called a gate. It has indegree (called fan-in) 2, and is labelled either (+) or (×) (addition or multiplication gate). Each gate of the circuit computes a polynomial. Each input gate computes the variable/scalar labelling it. The polynomial computed at a + (or ×) gate is the sum (respectively, product) of the polynomials computed at its inputs. The polynomial computed by C is the polynomial computed at the output gate of the circuit.

An arithmetic circuit C is said to be homogeneous if every gate in C computes a homogeneous polynomial.

Definition 1.2
(Algebraic Branching Programs (ABP)) [26, 29] An algebraic branching program (ABP) is a directed acyclic graph with one in-degree-0 vertex called the source, and one out-degree-0 vertex called the sink. The vertex set of the graph is partitioned into layers 0,1,…,ℓ, with directed edges only between adjacent layers (i to 𝑖+1). The source and the sink are at layers zero and ℓ respectively. Each edge is labeled by a linear form over variables 𝑥1,𝑥2,…,𝑥𝑛. Let 𝑃=(𝑒1,𝑒2,…,𝑒ℓ) be a source-to-sink directed path and let 𝐿𝑖 be the linear form labeling the edge 𝑒𝑖 on the path. Then the polynomial computed by the ABP is defined as the sum of products

∑𝑃∏𝑖=1ℓ𝐿𝑖,
(1)
where the sum is over all source-to-sink directed paths P. An ABP is homogeneous if all edge labels are homogeneous linear forms.

The Problems
Koutis and Williams [21, 22, 40] introduced and studied two natural algorithmic problems on arithmetic circuits:

1.
Given as input an arithmetic circuit C computing a polynomial 𝑓∈𝔽[𝑋], the k-multilinear monomial counting problem, denoted (k,n)−MLC is to compute the sum of the coefficients of all degree-k multilinear monomials in the polynomial f.Footnote1

2.
The k-multilinear monomial detection problem, denoted k−MMD, is to test if there is a degree-k multilinear monomial in the polynomial f with non-zero coefficient.

Both (k,n)−MLC and k−MMD can be solved in time 𝑂∗(𝑛𝑘) by a brute-force computation:Footnote2 Suppose the input polynomial f is represented by an arithmetic circuit C of size s. We can first easily compute from C a homogeneous circuit 𝐶′ of size 𝑂(𝑘2⋅𝑠) that represents the degree-k homogeneous component 𝐻𝑘(𝑓). This computation is done by keeping track of the different homogeneous components of C at every gate, discarding the homogeneous components of degree more than k [34] (or see the survey for details [33, Theorem 2.2]). Note that 𝐻𝑘(𝑓) has at most (𝑛+𝑘𝑘) monomials. We can compute the sparse representation of 𝐻𝑘(𝑓) in time 𝑂∗((𝑛+𝑘𝑘)), again gate by gate, bottom up, in the circuit 𝐶′.

The above two problems have attracted significant attention in recent times. In particular, Koutis [21], Williams [40], and Koutis-Williams [22] have studied (k,n)−MLC and k−MMD problems from the viewpoint of parameterized and exact algorithms. These problems are natural generalizations of the well-studied k-path detection and counting problems in a given graph [21]. Moreover, some other combinatorial problems like k−Tree, m−Dimensional k−Matching [22], well-studied in the parameterized complexity, reduce to these problems. In fact, the first randomized FPT algorithms for the decision version of these combinatorial problems were obtained from an 𝑂∗(2𝑘) algorithm for k−MMD for monotone circuits using an algebraic technique based on group algebras [21, 22, 40]. Recently, Brand et al. [9] have given the first randomized FPT algorithm for k−MMD for general circuits that runs in time 𝑂∗(4.32𝑘). Their method is based on exterior algebra and color coding [1].

In general, the exact counting versions of the k-path problem and many related problems are #W[1]-hard with respect to parameter k. For these counting problems, improvements to the trivial 𝑂∗(𝑛𝑘) time exhaustive search algorithm are known only in some cases (like counting k-paths) [7]. In this connection, Koutis and Williams [22] ask if there is an algorithm for (k,n)−MLC that improves upon the naive 𝑂∗(𝑛𝑘) time algorithm. It would yield faster algorithms for several exact counting problems. Indeed, Koutis and Williams in [22] give an algorithm of running time 𝑂∗(𝑛𝑘/2) to compute the parity of the sum of coefficients of degree-k multilinear monomials.

This Paper
In this paper, we make progress on the Koutis and Williams problem, mentioned above, by giving an 𝑂∗(𝑛𝑘/2) algorithm for the (k,n)−MLC problem. Broadly, we develop a new approach to the k−MMD, (k,n)−MLC problems, and related problems. Our algorithms are based on computing the Hadamard product of polynomials. The Hadamard product (also known as Schur product) generally refers to Hadamard product of matrices and is widely used in matrix analysis. We consider the Hadamard product of polynomials (e.g., see [4]).

The Hadamard product of polynomials has turned out to be a useful tool in noncommutative computation [4, 6]. A contribution of the present paper is to develop a new method for computing the Hadamard product in the commutative setting (as defined above), which turns out to be useful for designing efficient FPT and exact algorithms. An initial application of the Hadamard product of polynomials in arithmetic circuit complexity was in the context of proving hardness, e.g., showing hardness of the noncommutative determinant [6]. In contrast, the main application of Hadamard product in the present paper is in showing upper bound results. Broadly speaking, transferring techniques from circuit complexity to algorithm design is an important recent area of research. We refer the reader to the articles of Williams [39, 41].

At this point, before giving an overview of our results, we give some formal basic definitions and set up the notation for the paper.

Basic Definitions and Notation
We begin with the definition of the Hadamard product.

Definition 1.3
The Hadamard product of polynomials f and g in 𝔽[𝑋] is defined as

𝑓∘𝑔=∑𝑚([𝑚]𝑓⋅[𝑚]𝑔)⋅𝑚,
where m runs over all monomials nonzero in f or g, and [m]f denotes the coefficient of the monomial m in f.

The underlying field 𝔽 for the polynomials rings we study in this paper is either the field of rationals ℚ or a finite field 𝔽𝑝𝑚, where 𝑝𝑚 is a prime power. We briefly describe the complexity of field arithmetic in these fields. Details can be found in the textbook by von zur Gathen and Gerhard [37]. For 𝔽=ℚ, the field elements are given as a/b for integers 𝑎,𝑏,𝑏≠0, encoded in binary. The complexity of field arithmetic in ℚ is governed by the complexity of integer multiplication. By the well-known Schönhage-Strassen algorithm two n bit integers can be multiplied with 𝑂(𝑛log𝑛loglog𝑛) bit operations. Recently, this has been improved to 𝑂(𝑛log𝑛) by Harvey and van der Hoeven [19]. Consequently, field arithmetic in ℚ can be performed in with 𝑂(𝑛log𝑛) bit operations for rationals a/b, where a and 𝑏≠0 are n-bit integers.

For a finite field 𝔽𝑝𝑚, the field is given by the prime p in binary, along with a univariate irreducible polynomial p(z) of degree m which defines 𝐹𝑝𝑚 as the quotient ring 𝔽𝑝[𝑧]/(𝑝(𝑧)). The elements of 𝔽𝑝𝑚 are then representable as polynomials q(z) of degree at most 𝑚−1 with coefficients from the prime field 𝔽𝑝. In this representation each element of 𝔽𝑝𝑚 requires 𝑚log𝑝 bits. Addition in 𝔽𝑝𝑚 can be performed with 𝑂(𝑚log𝑝) bit operations. The complexity of multiplication is governed by the complexity of multiplying polynomials in 𝔽𝑝[𝑧]. There is a long line of work on fast polynomial multiplication [37], and the current best bound [18] has bit complexity 𝑂(𝑚log𝑝log(𝑚log𝑝)⋅4log∗(𝑚log𝑝)), where log∗(𝑥) is the number of times that the natural log function must be iteratively applied to x to make the resulting value bounded by 1.

A polynomial 𝑓∈𝔽[𝑋] is said to be multilinear if for every nonzero monomial 𝑚=𝑥𝑒11𝑥𝑒22⋯𝑥𝑒𝑛𝑛 of f we have 𝑒𝑖≤1.

An important family of polynomials for this paper are the elementary symmetric polynomials which are defined over any field 𝔽 as follows:

The elementary symmetric polynomial 𝑆𝑛,𝑘∈𝔽[𝑋] of degree k over the n variables 𝑋={𝑥1,𝑥2,…,𝑥𝑛} is defined as

𝑆𝑛,𝑘=∑𝑆⊂[𝑛]:|𝑆|=𝑘∏𝑖∈𝑆𝑥𝑖.
By definition, 𝑆𝑛,𝑘 is the sum of all the degree-k multilinear monomials.

Two other important families of multilinear polynomials relevant for this paper, again defined over all fields, are the determinant and permanent polynomials:

Let X={𝑋𝑖𝑗}1≤𝑖,𝑗≤𝑛 be an 𝑛×𝑛 matrix of commuting indeterminates. The 𝑛𝑡ℎ permanent polynomial is defined as:

Per(X)=∑𝜎∈𝑆𝑛∏𝑖=1𝑛𝑋𝑖,𝜎(𝑖).
It is a homogeneous degree-n multilinear polynomial. The 𝑛𝑡ℎ determinant polynomial is defined as

Det(X)=∑𝜎∈𝑆𝑛(−1)sgn(𝜎)∏˙𝑛𝑖=1𝑋𝑖,𝜎(𝑖).
Noncommutative Computation
Let 𝑌={𝑦1,𝑦2,…,𝑦𝑛} be n noncommuting variables. Monomials over Y are essentially words over Y, treated as an alphabet, and the free monoid 𝑌∗ is the set of all monomials over Y. The degree of a monomial is just its length. For a field 𝔽, we have the free noncommutative ring 𝔽⟨𝑌⟩, whose elements are finite 𝔽-linear combinations of monomials, with addition defined coefficient-wise and multiplication inherited from monomial multiplication by distributivity. The degree of a noncommutative polynomial g is the maximum degree of a nonzero monomial occurring in it, and g is called homogeneous if all its monomials have the same degree.

Noncommutative Circuits and ABPs

A noncommutative arithmetic circuit computing a polynomial in 𝔽⟨𝑌⟩ is defined like commutative arithmetic circuits (Definition 1.1). The only difference is that at each multiplication gate of the circuit the order of multiplication is important. This is taken care of by prescribing an order of the inputs at each multiplication gate.

A noncommutative ABP is also defined like commutative ABPs. The crucial difference again is the order of multiplication: more precisely, in Equation 1 of Definition 1.2 the product ∏ℓ𝑖=0𝐿𝑖 is left to right in increasing order of indices.

We note that when an input polynomial f is given by black-box access, in the commutative setting it means evaluating f at chosen scalar points 𝑎¯∈𝔽𝑛, and in the noncommutative setting it means evaluating f at any matrix tuple (𝑀1,𝑀2,…,𝑀𝑛) substituted for the variables.

An important ingredient of our main results in the following theorem [6] that allows us to compute in polynomial time the Hadamard product of a noncommutative ABP with a noncommutative polynomial f, even with only black-box access to f.

Theorem 1.4
[6, Corollary 4] Given a noncommutative ABP of size 𝑠1 computing a degree-d polynomial 𝑔∈𝔽⟨𝑌⟩ and another degree-d polynomial 𝑓∈𝔽⟨𝑌⟩ by an arithmetic circuit of size 𝑠2 we can compute an arithmetic circuit of size 𝑂(𝑠31⋅𝑠2) for 𝑓∘𝑔 in time polynomial in 𝑠1,𝑠2 and d. Furthermore, if f is given by black-box access then we can evaluate 𝑓∘𝑔 at any matrix-valued input (𝑀1,𝑀2,…,𝑀𝑛), where the 𝑀𝑖 are 𝑡×𝑡 matrices over 𝔽 in time polynomial in 𝑠1,𝑑 and t.

Further details on noncommutative computation can be found in Nisan’s work [26] and the survey paper [33].

From Commutative to Noncommutative

A crucial element of our results on Hadamard product computation is going from the commutative to the noncommutative setting.

Let 𝑋={𝑥1,𝑥2,…,𝑥𝑛} be n commuting variables and 𝑌={𝑦1,𝑦2,…,𝑦𝑛} be n corresponding noncommuting variables.Footnote3 Suppose 𝑓∈𝔽[𝑋] is a homogeneous degree-k polynomial represented by an arithmetic circuit C. We define its noncommutative version 𝐶ˆ which computes a noncommutative homogeneous degree-k polynomial denoted 𝑓̂ ∈𝔽⟨𝑌⟩ as follows.

Definition 1.5
Let C be a commutative arithmetic homogeneous circuit C computing a homogeneous degree-k polynomial 𝑓∈𝔽[𝑋]. The noncommutative version of C, 𝐶ˆ is the noncommutative circuit obtained from C by fixing an ordering of the inputs to each product gate in C and replacing 𝑥𝑖 by the noncommuting variable 𝑦𝑖,1≤𝑖≤𝑛. The polynomial computed by 𝐶ˆ is denoted 𝑓̂ ∈𝔽⟨𝑦1,𝑦2,…,𝑦𝑛⟩.

We similarly define the noncommutative version 𝐵ˆ of an ABP B.

The arithmetic circuit complexity of a polynomial f is the size s(f) of the smallest circuit representing f. The ABP complexity of f is the size b(f) of the smallest ABP representing f. This notation is used for both commutative and noncommutative polynomials.

Remark 1.6
The definition of the noncommutative 𝐶ˆ is entirely dependent on the ordering of the inputs to each product gate of C. This could, for instance, be by increasing order of the gate names of the circuit C. Since C is a homogeneous circuit, we note that the circuit 𝐶ˆ is also a homogeneous circuit.

We introduce the following notation:

𝑋𝑘𝑌𝑘≜{all degree 𝑘 monomials over 𝑋}.≜{all degree 𝑘 monomials over 𝑌}.
For mapping noncommutative polynomials back to commutative polynomials, we use the substitution map:

𝜈:𝑌→𝑋 defined as 𝜈(𝑥𝑖)=𝑦𝑖,1≤𝑖≤𝑛.
This map extends to 𝜈:𝑌𝑘→𝑋𝑘 and, by linearity, gives a ring homomorphism (it is easily checked that 𝜈(𝑓+𝑔)=𝜈(𝑓)+𝜈(𝑔) and 𝜈(𝑓𝑔)=𝜈(𝑓)𝜈(𝑔)):

𝜈:𝔽⟨𝑌⟩→𝔽[𝑋],
and its kernel, ker(𝜈), is precisely all those noncommutative polynomials over Y that vanish if the variables are allowed to commute.

Each monomial 𝑚∈𝑋𝑘 can appear as a different noncommutative monomial 𝑚̂ ∈𝜈−1(𝑚) in 𝑓̂ ∈𝔽⟨𝑌⟩. We will use the notation 𝑚̂ →𝑚 to denote that 𝑚̂ ∈𝜈−1(𝑚). Observe that

[𝑚]𝑓=∑𝑚̂ ∈𝜈−1(𝑚)[𝑚̂ ]𝑓̂ =∑𝑚̂ :𝑚̂ →𝑚[𝑚̂ ]𝑓̂ .
The noncommutative circuit 𝐶ˆ is not directly useful for computing Hadamard product. However, the following symmetrization helps. We first explain how permutations 𝜎∈𝑆𝑘 act on the set 𝑌𝑘 of degree-k monomials. The action extends, by linearity, to all homogeneous degree-k polynomials.

For each monomial 𝑚̂ =𝑦𝑖1𝑦𝑖2⋯𝑦𝑖𝑘, the permutation 𝜎∈𝑆𝑘 maps 𝑚̂  to the monomial 𝑚̂ 𝜎 defined as

𝑚̂ 𝜎=𝑦𝑖𝜎(1)𝑦𝑖𝜎(2)⋯𝑦𝑖𝜎(𝑘).
By linearity, the polynomial 𝑓̂  is mapped by 𝜎 to the polynomial

𝑓̂ 𝜎=∑𝑚̂ ∈𝑌𝑘[𝑚̂ ]𝑓̂ ⋅𝑚̂ 𝜎.
Definition 1.7
(Symmetrized polynomial) The symmetrized polynomial 𝑓∗∈𝔽⟨𝑌⟩ obtained from 𝑓∈𝔽[𝑋] is defined as the degree-k homogeneous polynomial

𝑓∗=∑𝜎∈𝑆𝑘𝑓̂ 𝜎.
Polynomial Identity Testing
A fundamental algorithmic problem concerning arithmetic circuits and algebraic branching programs is polynomial identity testing: Given a polynomial 𝑓∈𝔽[𝑋] as input, check if f is identically zero (which means that there are no nonzero monomials in f).

The polynomial identity testing (or PIT) problem is a central problem in the field of randomized and algebraic computation and has received a lot of attention over the years (see the survey [31, 33] for more details). When the field 𝔽 is larger than the degree, there is a simple randomized test using the Demillo-Lipton-Schwartz-Zippel Lemma [15, 32, 42]. The PIT problem has been studied both in the commutative and noncommutative settings [33].

The input polynomial f can be represented by an arithmetic circuit or an ABP, or simply given black-box access.

Complexity Theory Background
The basic complexity classes of interest in this paper are P and NP, which are the classes of decision problems solvable in deterministic polynomial time and nondeterministic polynomial time, respectively. Polynomial time as the notion of feasible computation, and the accompanying hardness theory of NP-completeness, is refined in the world of parameterized computation where the input instance is augmented with a fixed parameter k. Feasible parameterized computation means that the running time is of the form 𝑡(𝑘)⋅𝑛𝑂(1) for inputs of size n and fixed parameter k, where 𝑡(⋅) can be an arbitrary function that depends solely on parameter k. The parameterized analogue of P is denoted FPT. It is the class of fixed parameter time solvable problems, and algorithms with such running time are called FPT algorithms. The analogue of NP is denoted W[1], but the hardness theory has more technical details that can be found in the textbook by Downey and Fellows [16]. Cygan et al. [12] is a very good source for parameterized algorithms.

The notation 𝑂∗(𝑇(𝑛,𝑘)) suppresses polynomial factors. Thus, a function in 𝑂∗(𝑇(𝑛,𝑘)) is of the form 𝑂(𝑇(𝑛,𝑘)⋅poly(𝑛,𝑘)), where the notation poly(𝑛,𝑛′) is used as an alternative to 𝑂(𝑛𝑂(1)𝑛′𝑂(1)).

The following is a convenient notation for ascending sums of binomial coefficients:

(𝑛↓𝑖)≜∑𝑗=0𝑖(𝑛𝑗).
Overview of Results
We apply the Hadamard product of polynomials in the setting of commutative computation. This is achieved by combining earlier ideas [4, 6] with a symmetrization trick described in Sect. 2. We then use it to design new algorithms for (k,n)−MLC, k−MMD, and related problems.

Firstly, computing the Hadamard product of the elementary symmetric polynomial 𝑆𝑛,𝑘∈𝔽[𝑋] with a polynomial 𝑓∈𝔽[𝑋] sieves out precisely the degree-k multilinear component of f. This connection with the symmetric polynomial gives the following result.

Theorem 1.8
For input polynomials 𝑓∈𝔽[𝑥1,𝑥2,…,𝑥𝑛] to the (k,n)−MLC problem, where f is represented by an algebraic branching program of size s, there is a deterministic 𝑂∗((𝑛↓𝑘/2))-time algorithm. For input polynomials f represented by an arithmetic circuit C of size s, there is a deterministic 𝑂∗((𝑛↓𝑘/2)⋅𝑠𝑐⋅log𝑘)-time algorithm, where c is a constant.

In the above theorem, the underlying field 𝔽 could be the rationals or any finite field. We note that the above running time beats the naive 𝑂∗(𝑛𝑘) bound, answering the question asked by Koutis and Williams [22].

An important ingredient of the proof is Theorem 1.4, which a result in [6].

The other ingredient is an algorithm of Björklund et al. [8] for evaluating the rectangular permanent over noncommutative rings, that can be viewed as an algorithm for evaluating 𝑆∗𝑛,𝑘 (a symmetrized noncommutative version of 𝑆𝑛,𝑘, defined in Sect. 2) over matrices.

This yields a deterministic 𝑂∗((𝑛↓𝑘/2))-time algorithm when the input polynomial is given by an algebraic branching program (ABP).

When the input polynomial f is given by an arithmetic circuit, we can first obtain from it a circuit for the degree-k homogeneous component of f. Now, applying a standard transformation via depth-reduction we can transform this degree-k n-variate commutative arithmetic circuit of size, say s to an ABP of size 𝑠𝑂(log𝑘) [33] which yields the claimed algorithm for (k,n)−MLC.

Theorem 1.9
The k−MMD problem for input polynomials 𝑓∈𝔽[𝑋], represented as arithmetic circuits, has a randomized 𝑂∗(4.32𝑘)-time algorithm that is polynomial space-bounded, and 𝔽 is either the rationals or a finite field.

We briefly sketch the proof idea. Suppose that C is the input arithmetic circuit computing a homogeneous polynomial f of degree k. We essentially show that k−MMD is reducible to checking if the Hadamard product 𝑓∘𝐶′ is nonzero for some circuit 𝐶′ from a collection  of homogeneous degree-k depth two circuits. This collection of depth two circuits is obtained by application of color coding [1].

Furthermore, the commutative Hadamard product 𝑓∘𝐶′ turns out to be computable in 𝑂∗(2𝑘) time by a symmetrization trick combined with Ryser’s formula for the permanent. The overall running time (because of trying several choices for 𝐶′) turns out to be 𝑂∗(4.32𝑘). Finally, checking if 𝑓∘𝐶′ is nonzero reduces to an instance of polynomial identity testing which can be solved in randomized polynomial time using Demillo-Lipton-Schwartz-Zippel Lemma [15, 32, 42].

Next, we state the results showing fast deterministic algorithms for depth three circuits. We use the notation Σ[𝑠′]Π[𝑘]Σ to denote depth-three circuits with the output gate as a + gate of fan-in 𝑠′, with the next layer of × gates of fan-in k, each computing the product of k homogeneous linear forms over X. The overall size of the circuit is then 𝑠=𝑂(𝑠′⋅𝑘⋅𝑛).

Theorem 1.10
Given any homogeneous depth three Σ[𝑠′]Π[𝑘]Σ circuit of degree k, the (k,n)−MLC problem can be solved in deterministic 𝑂∗(2𝑘)-time. Over ℤ, the k−MMD problem can be solved in deterministic 𝑂∗(4𝑘)-time. Over finite fields, k−MMD problem can be solved in deterministic 𝑒𝑘𝑘𝑂(log𝑘)𝑂∗(2𝑐𝑘+2𝑘) time, where 𝑐≤5.

It is well-known that the elementary symmetric polynomial 𝑆𝑛,𝑘 can be computed using an ABP of size poly(𝑛,𝑘).

We then compute the Hadamard product of the given depth three circuit with that homogeneous ABP for 𝑆𝑛,𝑘, and check whether the resulting depth three circuit is identically zero or not. The same idea yields the algorithm to compute the sum of the coefficients of the multilinear terms as well.

Related Work We briefly discuss here some related work (we have a more detailed discussion appears in Sect. 7).

Soon after the first version of our paper [2] appeared in ArXiv, an independent work by Pratt [27, v1] and [28] also considers the k−MMD and (k,n)−MLC problems. The main ingredient of [27] is the application of Waring decomposition over the rationals of symmetric polynomials [23] which does not have any known analogue over finite fields of small characteristic.

The algorithms obtained [27] for k−MMD and (k,n)−MLC over the rationals are faster (𝑂∗(4.08𝑘)-time for k−MMD and 𝑂∗(𝑛𝑘/2)-time for (k,n)−MLC). In comparison, our algorithms work both over the rationals and finite fields. As already mentioned, the algorithm of Koutis and Williams [22] for (k,n)−MLC works over 𝔽2 and the running time is 𝑂∗(𝑛𝑘/2). In this sense, our algorithm for (k,n)−MLC can also be viewed as a generalization that is independent of the field’s characteristic. It is to be noted that over fields of small characteristic a Waring decomposition of the input polynomial may not even exist. For example, over 𝔽2 the polynomial xy has no Waring decomposition. The more recent work of Brand and Pratt [10], extending Pratt’s results [28] in explained in Sect. 7.

Our algorithm obtained in Theorem 1.9 for k−MMD appears quite different from the exterior algebra based algorithm [9], but it has the same running time of 𝑂∗(4.32𝑘) because of the specific application of color coding due to Hüffner et al. [20]. However, we note that our algorithm requires only poly(𝑛,𝑘) space, whereas the algorithm in [9] takes exponential space.

The field of parameterized approximate counting has seen several interesting directions in recent years. We refer the reader to [13, 14, 38] for results showing reductions from approximate counting to the decision problem.

Organization. The rest of this paper is organized as follows. In Sect. 2 we explain the Hadamard product framework. The proof of Theorem 1.8 and its consequences are given in Sect. 3. Section 5 contains the proof of Theorem 1.9. The proof of Theorem 1.10 is given in Sect. 6.

Hadamard Product Framework
Given two arithmetic circuits 𝐶1 and 𝐶2 computing polynomials 𝑓1 and 𝑓2, it is in general unlikely that 𝑓1∘𝑓2 can be computed by an arithmetic circuit C of size poly(|𝐶1|,|𝐶2|). This can be observed from the fact that for the symbolic matrix X=(𝑥𝑖,𝑗)1≤𝑖,𝑗≤𝑛, the Hadamard product of the determinant polynomial Det(X) with itself is the permanent polynomial Per(X) which does not have polynomial-size circuit assuming Valiant’s VP≠VNP hypothesis [35]. However, it is well known that Det(X) can be computed by a polynomial-size ABP [24].

Nevertheless, we develop a method for computing the scaled Hadamard product of commutative polynomials in some special cases.

Definition 2.1
The scaled Hadamard product of polynomials 𝑓,𝑔∈𝔽[𝑋] is defined as

𝑓∘ s 𝑔=∑𝑚(𝑚!⋅[𝑚]𝑓⋅[𝑚]𝑔)⋅𝑚,
where for monomial 𝑚=𝑥𝑒1𝑖1𝑥𝑒2𝑖2…𝑥𝑒𝑟𝑖𝑟 we define 𝑚!=𝑒1!⋅𝑒2!⋯𝑒𝑟!.

Computing the scaled Hadamard product is key to our algorithmic results for k−MMD and (k,n)−MLC. Broadly, it works as follows: we transform polynomials f and g to suitable noncommutative polynomials. We compute their (noncommutative) Hadamard product (Theorem 1.4) [4, 6], and then recover the scaled commutative Hadamard product 𝑓∘ s 𝑔 (or evaluate it at a desired point 𝑎⃗ ∈𝔽𝑛).

Suppose 𝑓∈𝔽[𝑥1,𝑥2,…,𝑥𝑛] is a homogeneous degree-k polynomial given by a circuit C. We have its noncommutative version 𝐶ˆ which computes the noncommutative homogeneous degree-k polynomial 𝑓̂ ∈𝔽⟨𝑦1,𝑦2,…,𝑦𝑛⟩ (see Definition 1.5).

Recall from Sect. 1.2.1 that 𝑋𝑘 denotes the set of all degree-k monomials over X, 𝑌𝑘 denote all degree-k noncommutative monomials over Y, and we have [𝑚]𝑓=∑𝑚̂ →𝑚[𝑚̂ ]𝑓̂ , where 𝑚∈𝑋𝑘 and 𝑚̂ ∈𝑌𝑘. We will use the symmetrized polynomial (see Definition 1.7), 𝑓∗=∑𝜎∈𝑆𝑘𝑓̂ 𝜎, to compute the scaled Hadamard product 𝑓∘ s 𝑔.

Lemma 2.2
For a homogeneous degree-k commutative polynomial 𝑓∈𝔽[𝑋] given by circuit C, and its noncommutative version 𝐶ˆ computing polynomial 𝑓̂ ∈𝔽⟨𝑌⟩, consider the symmetrized noncommutative polynomial 𝑓∗=∑𝜎∈𝑆𝑘𝑓̂ 𝜎. Then for each monomial 𝑚∈𝑋𝑘 and each word 𝑚′∈𝑌𝑘 such that 𝑚′→𝑚, we have: [𝑚′]𝑓∗=𝑚!⋅[𝑚]𝑓.

Proof
Let 𝑓=∑𝑚[𝑚]𝑓⋅𝑚 and 𝑓̂ =∑𝑚̂ [𝑚̂ ]𝑓̂ ⋅𝑚̂ . As already observed, [𝑚]𝑓=∑𝑚̂ →𝑚[𝑚̂ ]𝑓̂ . Now, we write 𝑓∗=∑𝑚′[𝑚′]𝑓∗⋅𝑚′. The group 𝑆𝑘 acts on 𝑌𝑘 by permuting the positions. Suppose 𝑚=𝑥𝑒1𝑖1⋯𝑥𝑒𝑞𝑖𝑞 is a type 𝑒𝑒=(𝑒1,…,𝑒𝑞) monomial over 𝑋𝑘 and 𝑚′→𝑚. Then, by the well-known Orbit-Stabilizer Theorem [11, Chapter 1] the orbit 𝑂𝑚′ of 𝑚′ under the action of 𝑆𝑘 has size 𝑘!𝑚!. It follows that

[𝑚′]𝑓∗=∑𝑚̂ ∈𝑂𝑚′𝑚!⋅[𝑚̂ ]𝑓̂ =𝑚!∑𝑚̂ →𝑚[𝑚̂ ]𝑓̂ =𝑚!⋅[𝑚]𝑓.
It is important to note that for some 𝑚̂ ∈𝑌𝑘 such that 𝑚̂ →𝑚, even if [𝑚̂ ]𝑓̂ =0 then also [𝑚̂ ]𝑓∗=𝑚!⋅[𝑚]𝑓. ◻

Next, we apply Lemma 2.2 to compute scaled Hadamard product in the commutative setting via noncommutative Hadamard product.

Remark 2.3
We note that given a commutative circuit C computing f, the noncommutative polynomial 𝑓̂  depends on the circuit structure of C. However, 𝑓∗ depends only on the polynomial f.

Lemma 2.4
Let 𝑔∈𝔽[𝑋] be a homogeneous degree-k polynomial and C be some arithmetic circuit for g. For any homogeneous degree-k polynomial 𝑓∈𝔽[𝑋] and any point 𝑎⃗ ∈𝔽𝑛

(𝑓∘ s 𝑔)(𝑎⃗ )=(𝑓∗∘𝑔̂ )(𝑎⃗ ),
where the noncommutative polynomial 𝑔̂  is defined by the given circuit C.

Proof
We write 𝑓=∑𝑚[𝑚]𝑓⋅𝑚 and 𝑔=∑𝑚′[𝑚′]𝑔⋅𝑚′. By definition, we have 𝑓∘ s 𝑔=∑𝑚𝑚!⋅[𝑚]𝑓⋅[𝑚]𝑔⋅𝑚.

The polynomial computed by 𝐶ˆ is 𝑔̂ (𝑌)=∑𝑚∈𝑋𝑘∑𝑚̂ →𝑚[𝑚̂ ]𝑔̂ ⋅𝑚̂ . By Lemma 2.2, the noncommutative polynomial 𝑓∗(𝑌)=∑𝑚∈𝑋𝑘∑𝑚̂ →𝑚𝑚!⋅[𝑚]𝑓⋅𝑚̂ . Therefore,

(𝑓∗∘𝑔̂ )(𝑌)=∑𝑚∈𝑋𝑘∑𝑚̂ →𝑚𝑚!⋅[𝑚]𝑓⋅[𝑚̂ ]𝑔̂ ⋅𝑚̂ =∑𝑚∈𝑋𝑘𝑚!⋅[𝑚]𝑓⋅(∑𝑚̂ →𝑚[𝑚̂ ]𝑔̂ )⋅𝑚̂ .
Consequently, for any point 𝑎⃗ ∈𝔽𝑛 we have

(𝑓∗∘𝑔̂ )(𝑎⃗ )=∑𝑚∈𝑋𝑘𝑚!⋅[𝑚]𝑓⋅(∑𝑚̂ →𝑚[𝑚̂ ]𝑔̂ )⋅𝑚̂ (𝑎⃗ ).
Since [𝑚]𝑔=∑𝑚̂ →𝑚[𝑚̂ ]𝑔̂ , we have

(𝑓∗∘𝑔̂ )(𝑎⃗ )=∑𝑚∈𝑋𝑘𝑚!⋅[𝑚]𝑓⋅𝑚(𝑎⃗ )⋅[𝑚]𝑔=(𝑓∘ s 𝑔)(𝑎⃗ ).
◻

We note an immediate corollary of the above.

Corollary 2.5
Let 𝑓1,𝑓2 be homogeneous degree-k polynomials in 𝔽[𝑋]. Given a noncommutative circuit C computing the polynomial 𝑓̂ 1∘𝑓∗2∈𝔽⟨𝑌⟩, one can obtain a commutative circuit 𝐶̃  for 𝑓1∘ s 𝑓2∈𝔽[𝑋] by replacing the noncommutative variables 𝑦𝑖 in C by the commutative variables 𝑥𝑖.

Proof
Let 𝑓1=∑𝑚[𝑚]𝑓1⋅𝑚1. So, 𝑓̂ 1=∑𝑚̂ [𝑚̂ ]𝑓̂ ⋅𝑚̂  and [𝑚]𝑓=∑𝑚̂ →𝑚[𝑚̂ ]𝑓̂ . Then, 𝑓̂ 1∘𝑓∗2(𝑌)=∑𝑚̂ [𝑚̂ ]𝑓̂ 1⋅[𝑚̂ ]𝑓∗2⋅𝑚̂ =∑𝑚̂ [𝑚̂ ]𝑓̂ 1⋅𝑚![𝑚]𝑓2⋅𝑚̂  where 𝑚̂ →𝑚. Now replacing the noncommutative variables by commutative variables, we obtain

𝑓̂ 1∘𝑓∗2(𝑋)=∑𝑚𝑚!⋅(∑𝑚̂ →𝑚[𝑚̂ ]𝑓̂ 1)⋅[𝑚]𝑓2⋅𝑚
Since, [𝑚]𝑓=∑𝑚̂ →𝑚[𝑚̂ ]𝑓̂ , we further simplify and get 𝑓̂ 1∘𝑓∗2(𝑋)=𝑓1∘ s 𝑓2(𝑋). ◻

Remark 2.6
A key conceptual tool in [27] is the apolar inner product for homogeneous degree-k polynomials f and g in 𝔽[𝑋], which is defined as

⟨𝑓,𝑔⟩=𝑓(∂𝑥1,…,∂𝑥𝑛)∘𝑔(𝑥1,…,𝑥𝑛).
We note that in the Hadamard product framework, we can express the apolar inner product of f and g as 𝑓∘ s 𝑔 evaluated at the all-ones vector 1⃗ ∈𝔽𝑛. In Sect. 7 we present more details.

The Sum of Coefficients of Multilinear Monomials
In this section we prove Theorem 1.8. As already sketched in Sect. 1, the main idea is to apply the symmetrization trick to reduce the (k,n)−MLC problem to evaluating the rectangular permanent over a suitable matrix ring. Then we use a result of [8] to solve the instance of the rectangular permanent evaluation problem.

Before we present the results we recall the definition of ABPs (Definition 1.2) and the following different but equivalent formulation of ABPs:

A homogeneous ABP of width w computing a degree-k polynomial over X can be thought of as the (1,𝑤)𝑡ℎ entry of the product of 𝑤×𝑤 matrices 𝑀1⋯𝑀𝑘 where entries of each 𝑀𝑖 are homogeneous linear forms over X. By [𝑥𝑗]𝑀𝑖, we denote the 𝑤×𝑤 matrix over 𝔽, such that (𝑝,𝑞)𝑡ℎ entry of the matrix,([𝑥𝑗]𝑀𝑖)(𝑝,𝑞)=[𝑥𝑗](𝑀𝑖(𝑝,𝑞)), the coefficient of 𝑥𝑗 in the linear form of the (𝑝,𝑞)𝑡ℎ entry of 𝑀𝑖.

Permanent of Rectangular Matrices
We now define the permanent of a rectangular matrix. The permanent of a rectangular 𝑘×𝑛 matrix 𝐴=(𝑎𝑖𝑗),𝑘≤𝑛, with entries over a ring R is defined as

rPer(𝐴)=∑𝜎∈𝐼𝑘,𝑛∏𝑖=1𝑘𝑎𝑖,𝜎(𝑖),
where 𝐼𝑘,𝑛 is the set of all injections from [k] to [n]. We define the noncommutative polynomial 𝑆∗𝑛,𝑘 as

𝑆∗𝑛,𝑘(𝑦1,𝑦2,…,𝑦𝑛)=∑𝑇⊆[𝑛]:|𝑇|=𝑘∑𝜎∈𝑆𝑘∏𝑖∈𝑇𝑦𝜎(𝑖),
which is the symmetrized version of the elementary symmetric polynomial 𝑆𝑛,𝑘 as defined in Lemma 2.2. Given a set of 𝑡×𝑡 matrices 𝑀1,…,𝑀𝑛 over some field 𝔽 define the rectangular (block) matrix 𝐴=(𝑎𝑖,𝑗)𝑖∈[𝑘],𝑗∈[𝑛] such that 𝑎𝑖,𝑗=𝑀𝑗. Thus, A is a 𝑘×𝑛 matrix with entries from the ring of 𝑡×𝑡 matrices over the field 𝔽. The following observation is crucial.

Observation 3.1
𝑆∗𝑛,𝑘(𝑀1,…,𝑀𝑛)=rPer(𝐴).

Proof
To see this, observe that ,

rPer(𝐴)=∑𝑇⊆[𝑛]:|𝑇|=𝑘Per(𝐴𝑇)=∑𝑇⊆[𝑛]:|𝑇|=𝑘∑𝜎∈𝑆𝑘∏𝑖∈𝑇𝑀𝜎(𝑖).
Here 𝐴𝑇 is the minor of A such that the columns are indexed by the set T. ◻

In the sequel, we will apply a result from [8], showing that over any ring R, the permanent of a rectangular 𝑘×𝑛 matrix can be evaluated with 𝑂∗((𝑛↓𝑘/2)) ring operations. In particular, if R is the matrix ring 𝕄𝑠(𝔽), the algorithm runs in time 𝑂(𝑘(𝑛↓𝑘/2)poly(𝑛,𝑠)). We now present the proof of Theorem 1.8.

Proof
We first prove a special case of the theorem when the polynomial f is given by a homogeneous degree-k ABP B of width w. Notice that we can compute the sum of the coefficients of the degree-k multilinear terms in f by evaluating (𝑓∘𝑆𝑛,𝑘)(1⃗ ). Now to compute the Hadamard product efficiently, we will transfer the problem to the noncommutative domain. Let 𝐵ˆ define the noncommutative version of the commutative ABP B for the polynomial f. By Lemma 2.4, it suffices to compute (𝐵ˆ∘𝑆∗𝑛,𝑘)(1⃗ ). Now, the following lemma reduces this computation to evaluating 𝑆∗𝑛,𝑘 over a suitable matrix ring. We recall the following result from [5] (see, also [6]). ◻

Lemma 3.2
(Theorem 2 of [5]) Let f be a homogeneous degree-k noncommutative polynomial in 𝔽⟨𝑌⟩ and B be an ABP of width w computing a homogeneous degree-k polynomial 𝑔=(𝑀1⋯𝑀𝑘)(1,𝑤) in 𝔽⟨𝑌⟩.

Then (𝑓∘𝑔)(1⃗ )=(𝑓(𝐴𝐵1,…,𝐴𝐵𝑛))(1,(𝑘+1)𝑤) where for each 𝑖∈[𝑛], 𝐴𝐵𝑖 is the following (𝑘+1)𝑤×(𝑘+1)𝑤 block superdiagonal matrix,

𝐴𝐵𝑖=⎡⎣⎢⎢⎢⎢⎢⎢00⋮00[𝑦𝑖]𝑀10⋮000[𝑦𝑖]𝑀2⋱00……⋱……00⋮[𝑦𝑖]𝑀𝑘0⎤⎦⎥⎥⎥⎥⎥⎥.
Proof
We sketch the proof as we will require some details for the proof of Theorem 1.8. For any monomial 𝑚̂ =𝑦𝑖1𝑦𝑖2⋯𝑦𝑖𝑘∈𝑌𝑘,

(𝐴𝐵𝑖1𝐴𝐵𝑖2⋯𝐴𝐵𝑖𝑘)(1,(𝑘+1)𝑤)=([𝑦𝑖1]𝑀1⋅[𝑦𝑖2]𝑀2⋯[𝑦𝑖𝑘]𝑀𝑘)(1,𝑤)=[𝑚̂ ]𝑔,
from the definition. Hence, we have,

𝑓(𝐴𝐵1,𝐴𝐵2,…,𝐴𝐵𝑛)(1,(𝑘+1)𝑤)=∑𝑚̂ ∈𝑌𝑘[𝑚̂ ]𝑓⋅𝑚̂ (𝐴𝐵𝑖1,𝐴𝐵𝑖2,…,𝐴𝐵𝑖𝑘)(1,(𝑘+1)𝑤)=∑𝑚̂ ∈𝑌𝑘[𝑚̂ ]𝑓⋅[𝑚̂ ]𝑔.
◻

Now, we construct a 𝑘×𝑛 rectangular matrix 𝐴=(𝑎𝑖,𝑗)𝑖∈[𝑘],𝑗∈[𝑛] from the ABP 𝐵ˆ (obtained from the given ABP B) by setting 𝑎𝑖,𝑗=𝐴𝐵ˆ𝑗 as defined. Using Observation 3.1, we now have,

rPer(𝐴)(1,(𝑘+1)𝑤)=𝑆∗𝑛,𝑘(𝐴𝐵ˆ1,…,𝐴𝐵ˆ𝑛)(1,(𝑘+1)𝑤).
Now by Lemmas 2.4 and 3.2, we conclude that,

𝑆∗𝑛,𝑘(𝐴𝐵ˆ1,…,𝐴𝐵ˆ𝑛)(1,(𝑘+1)𝑤).=(𝑆∗𝑛,𝑘∘𝐵ˆ)(1⃗ )=(𝑆𝑛,𝑘∘ s 𝐵)(1⃗ ).
Hence applying the algorithm of Björklund et al. for evaluating the rectangular permanent over noncommutative ring [8], we compute the sum of the coefficients deterministically in time 𝑂(𝑘(𝑛↓𝑘/2)poly(𝑛,𝑘,𝑤)).

Now, we prove the general case. We apply a standard transformation from circuits to ABPs [33, 36] and reduce the problem to the ABP case. More precisely, given an arithmetic circuit of size s computing a polynomial f of degree k, f can also be computed by a homogeneous ABP of size 𝑠𝑂(log𝑘). In particular, if f is given by an arithmetic circuit of size s, we first get a circuit of poly(𝑘,𝑠) size for degree-k part of f using a standard method of homogenization [33, Theorem 2.2]. Then, we convert the homogeneous circuit to a homogeneous ABP of size 𝑠𝑂(log𝑘). The width w of the new ABP is also bounded by 𝑠𝑂(log𝑘). Next, we apply the first part of the proof on the newly constructed ABP. Notice that the entire computation can be done in deterministic 𝑂(𝑘(𝑛↓𝑘/2)poly(𝑛,𝑘,𝑤)) time which is 𝑂∗((𝑛↓𝑘/2)⋅𝑠𝑐⋅log𝑘) for some constant c. ◻

Some Applications
We show some applications of Theorem 1.8 and the technique developed there. The first two are algorithmic applications and the last is a hardness result.

Applying Theorem 1.8, we improve the counting complexity of two combinatorial problems studied in [22]. To the best of our knowledge, nothing better than the brute-force exhaustive search algorithms were known for the counting version of these problems. We start with the k−Tree problem: Let T be a tree with k vertices and G be an n-vertex graph. A homomorphic embedding of T in G is defined by an injective map 𝜑:𝑉(𝑇)→𝑉(𝐺) such that for all 𝑢,𝑣∈𝑉(𝑇)

𝑢𝑣∈𝐸(𝑇)⟹𝜑(𝑢)𝜑(𝑣)∈𝐸(𝐺).
A copy of T in G is 𝜑(𝑇) for some homomorphic embedding 𝜑 of T in G. Let 𝑒𝑇,𝐺 denote the number of homomorphic embeddings of T in G and 𝑐𝑇,𝐺 denote the number of copies of T in G. Let Aut(𝑇) denote the automorphism group of T. For two such homomorphic embeddings 𝜑1 and 𝜑2 we have 𝜑1(𝑇)=𝜑2(𝑇) if and only if 𝜑−11𝜑2∈Aut(𝑇). Hence,

𝑐𝑇,𝐺=𝑒𝑇,𝐺|Aut(𝑇)|.
(2)
The exact counting version of k−Tree is the problem of counting the number of copies of T in G for an input pair (T, G). Clearly, there is a trivial 𝑂∗(𝑛𝑘) exhaustive search algorithm for the problem. We apply Theorem 1.8 to obtain an essentially quadratic speed-up.

Corollary 4.1
The exact counting k−Tree problem of counting the number of copies of a given k-vertex tree in a given n-vertex graph can be computed in deterministic 𝑂∗((𝑛↓𝑘/2)) time.

Proof
By Eq. 2 it suffices to count the number of homomorphic embeddings of T in G, as counting the number of automorphisms |Aut(𝑇)| of T can be done in poly(𝑘) time.

To this end, we will use a modification of the construction defined in [22, Theorem 2.2]. Let the nodes of T be {1,2,…,𝑘} and the nodes of G be {1,2,…,𝑛}. W.l.o.g., we can consider T to be a tree rooted at 1. As a consequence, every node 𝑖∈[𝑘] of T uniquely defines a subtree 𝑇𝑖 rooted at i. Let 𝑋={𝑥1,𝑥2,…,𝑥𝑛} be the set of n commuting variables corresponding to the n vertices of G. We inductively define a polynomial 𝐶𝑖𝑗 in 𝔽[𝑋] as follows:

If i is a leaf node of the tree T then 𝐶𝑖𝑗=𝑥𝑗.

Otherwise, let 𝑖1,𝑖2,…,𝑖ℓ be the children of i in T. Inductively, we can assume that the polynomials 𝐶𝑖𝑡,𝑗,1≤𝑡≤ℓ,1≤𝑗≤𝑛 are already defined. We define

𝐶𝑖𝑗=𝑥𝑗∏𝑡=1ℓ(∑𝑗′:(𝑗,𝑗′)∈𝐸(𝐺)𝐶𝑖𝑡,𝑗′).
Finally, we define the polynomial Q as

𝑄(𝑋)=∑𝑗=1𝑛𝐶1𝑗.
By definition, it follows that 𝐶𝑖𝑗 is a homogeneous polynomial of degree |𝑉(𝑇𝑖)| for each 𝑖∈[𝑘]. Consequently, Q(X) is a homogeneous degree-k polynomial. ◻

Claim 4.2
Let 𝑖∈[𝑘] and the subtree 𝑇𝑖 have r nodes. Then the number of degree-r multilinear monomials in 𝐶𝑖𝑗 is exactly the number of homomorphic embeddings of 𝑇𝑖 in G that maps i to j. Hence, the number of degree-r multilinear monomials in ∑𝑗∈𝑉(𝐺)𝐶𝑖𝑗 is the number of homomorphic embeddings of 𝑇𝑖 in G.

The above claim is easily proved by induction on the size of 𝑇𝑖. It is clearly true for |𝑉(𝑇𝑖)|=1. In general, suppose 𝑖1,𝑖2,…,𝑖ℓ are the children of i in tree T. Any homomorphic embedding 𝜑:𝑇𝑖→𝐺 that maps i to j is defined uniquely by homomorphic embeddings 𝜑𝑡:𝑇𝑖𝑡→𝐺 such that the ranges of the 𝜑𝑡 are all disjoint and the 𝑖𝑡 map to distinct G-neighbors of j. Clearly, from the definition of 𝐶𝑖𝑗 and induction, it follows that there is a unique multilinear monomial of 𝐶𝑖𝑗 that corresponds to 𝜑. Conversely, each multilinear monomial defines a unique homomorphic embedding 𝜑:𝑇𝑖→𝐺 that maps i to j.

Thus, the exact counting k−Tree problem is solved by counting the number of multilinear monomials in Q. By Theorem 1.8, it suffices to construct for Q an ABP of size poly(𝑛,𝑘).

From the recursively defined structure of the noncommutative formula for 𝐶𝑖𝑗 we can analyze the size. Let sizeℓ bound the noncommutative formula size for the polynomial 𝑄ℓ defined as above for trees of size ℓ (note that 𝑄𝑘=𝑄). We note from the formula structure that size1=𝑛 and

size𝑘=𝑛𝑘+∑𝑡=1ℓsize𝑘𝑡,
where 𝑘𝑡 are the subtree sizes and 𝑘1+𝑘2+⋯+𝑘ℓ=𝑘−1. Clearly, size𝑘≤𝑛𝑘2. Thus, Q has a formulas of size at most 𝑛𝑘2 which can be converted to an ABP of size 𝑂(𝑛𝑘2) by standard techniques [33]. ◻

We now consider the exact counting version of the m−Dimensional k−Matching problem: Let 𝑈1,𝑈2,…,𝑈𝑚 be mutually disjoint sets, and let C be a collection of m-tuples from their cartesian product 𝑈1×⋯×𝑈𝑚. An m-dimensional k-matching in C is a subcollection of k m-tuples such that no two of these m-tuples share a common coordinate. Koutis and Williams [22] obtain a faster parameterized algorithm for the decision version of this problem. We present an exact counting algorithm as an application of Theorem 1.8.

Corollary 4.3
Given mutually disjoint sets 𝑈𝑖, 𝑖∈[𝑚], and a collection C of m-tuples from 𝑈1×⋯×𝑈𝑚 , we can count the number of m-dimensional k-matchings in C in deterministic 𝑂∗((𝑛↓(𝑚−1)𝑘/2)) time.

Proof
Following [22], encode each element u in 𝑈=∪𝑚𝑖=2𝑈𝑖 by a variable 𝑥𝑢∈𝑋. Encode each m-tuple 𝑡=(𝑢1,…,𝑢𝑚)∈𝐶⊆𝑈1×⋯×𝑈𝑚 by the monomial 𝑀𝑡=∏𝑚𝑖=2𝑥𝑢𝑖. Assume 𝑈1={𝑢1,1,…,𝑢1,𝑛}, and let 𝑇𝑗⊆𝐶 denote the subset of m-tuples whose first coordinate is 𝑢1,𝑗. Consider the polynomial,

𝑃(𝑋,𝑧)=∏𝑗=1𝑛⎛⎝⎜⎜1+∑𝑡∈𝑇𝑗(𝑧⋅𝑀𝑡)⎞⎠⎟⎟
Clearly, P(X, z) has an ABP of size poly(𝑛,𝑚,|𝐶|). Let 𝑄(𝑋)=[𝑧𝑘]𝑃(𝑋,𝑧). In polynomial time we can obtain an ABP of size poly(𝑛,𝑚,|𝐶|) for Q(X) by standard method of Vandermonde matrix based interpolation on the variable z. Clearly, Q(X) is a homogeneous degree-km polynomial and the nonzero multilinear monomials of Q(X) are in 1−1 correspondence with the m-dimensional k-matchings in C. Therefore, the number of multilinear terms in Q(X) is the required count. We can now apply the first part of Theorem 1.8 to count the number of multilinear terms in Q(X).

◻

Hardness of the Rectangular Permanent Over General Rings
In [8], it is shown that the 𝑘×𝑛 rectangular permanent can be evaluated over commutative rings and commutative semirings in 𝑂(ℎ(𝑘)⋅poly(𝑛,𝑘)) time for some computable function h. In other words, the problem is in FPT, parameterized by the number of rows. An interesting question is to ask whether one can get any FPT algorithm when the entries are from noncommutative rings (in particular, matrix rings). We prove that such an algorithm is unlikely to exist. We show that counting the number of k-paths in a graph G, a well-known #W[1]-complete problem, reduces to this problem. So, unless ETH fails we do not have such an algorithm [16].

Theorem 4.4
Given a 𝑘×𝑛 matrix X with entries 𝑥𝑖𝑗∈𝕄𝑡×𝑡(ℚ), computing the rectangular permanent of X is #W[1]-hard with k as the parameter where 𝑡=(𝑘+1)𝑛 under polynomial-time many-one reduction.

Proof
If we have an algorithm to compute the permanent of a 𝑘×𝑛 matrix over noncommutative rings which is FPT in parameter k, that yields an algorithm which is FPT in k for evaluating the polynomial 𝑆∗𝑛,𝑘 on matrix inputs. This follows from Observation 3.1. Now, given a graph G we can compute a homogeneous ABP of width n and k layers for the graph polynomial 𝐶𝐺 defined as follows.

Let G(V, E) be a directed graph with n vertices where 𝑉(𝐺)={𝑣1,𝑣2,…,𝑣𝑛}. A k-walk is a sequence of k vertices 𝑣𝑖1,𝑣𝑖2,…,𝑣𝑖𝑘 where (𝑣𝑖𝑗,𝑣𝑖𝑗+1)∈𝐸 for each 1≤𝑗≤𝑘−1. A k-path is a k-walk where no vertex is repeated. Let A be the adjacency matrix of G, and let 𝑦1,𝑦2,…,𝑦𝑛 be noncommuting variables. Define an 𝑛×𝑛 matrix B

𝐵[𝑖,𝑗]=𝐴[𝑖,𝑗]⋅𝑦𝑖,  1≤𝑖,𝑗≤𝑛.
Let 1⃗  denote the all 1’s vector of length n. Let 𝑦⃗  be the length n vector defined by 𝑦⃗ [𝑖]=𝑦𝑖. The graph polynomial 𝐶𝐺∈𝔽⟨𝑌⟩ is defined as

𝐶𝐺(𝑌)=1⃗ 𝑇⋅𝐵𝑘−1⋅𝑦⃗ .
Let W be the set of all k-walks in G. The following observation is folklore. ◻

Observation 4.5
𝐶𝐺(𝑌)=∑𝑣𝑖1𝑣𝑖2…𝑣𝑖𝑘∈𝑊𝑦𝑖1𝑦𝑖2⋯𝑦𝑖𝑘.
Hence, G contains a k-path if and only if the graph polynomial 𝐶𝐺 contains a multilinear term.

Clearly the number of k-paths in G is equal to (𝐶𝐺∘𝑆𝑛,𝑘)(1⃗ ). By Lemma 2.4, we know that it suffices to compute (𝐶ˆ𝐺∘𝑆∗𝑛,𝑘)(1⃗ ). We construct 𝑘𝑛×𝑘𝑛 matrices 𝐴1,…,𝐴𝑛 from the ABP of 𝐶ˆ𝐺 following Lemma 3.2. Then from Lemma 3.2, we know that (𝐶ˆ𝐺∘𝑆∗𝑛,𝑘)(1⃗ )=𝑆∗𝑛,𝑘(𝐴1,…,𝐴𝑛)(1,𝑡) where 𝑡=(𝑘+1)𝑛. So if we have an algorithm which is FPT in k for evaluating 𝑆∗𝑛,𝑘 over matrix inputs, we also get an algorithm to count the number of k-paths in G in FPT(k) time. ◻

Multilinear Monomial Detection
In this section, we prove Theorem 1.9. First, we give an algorithm for computing the Hadamard product for a special case in the commutative setting. Any depth two Π[𝑘]Σ circuit computes the product of k homogeneous linear forms over the input set of variables X.

Lemma 5.1
Given an arithmetic circuit C of size s computing 𝑔∈𝔽[𝑋], and a homogeneous Π[𝑘]Σ circuit computing 𝑓∈𝔽[𝑋], and any point 𝑎⃗ ∈𝔽𝑛, we can evaluate (𝑓∘ s 𝑔)(𝑎⃗ ) in 𝑂∗(2𝑘) time and in polynomial space.

Proof
By standard homogenization technique [33, Theorem 2.2] we can extract the homogeneous degree-k component of C and thus we can assume that C computes a homogeneous degree-k polynomial. Write 𝑓=∏𝑘𝑗=1𝐿𝑗, for homogeneous linear forms 𝐿𝑗. The corresponding noncommutative polynomial 𝑓̂  is defined by the natural order of the j indices (and replacing 𝑥𝑖 by 𝑦𝑖 for each i). ◻

Claim 5.2
The noncommutative polynomial 𝑓∗ has a (noncommutative) Σ[2𝑘]Π[𝑘]Σ circuit, which we can write as 𝑓∗=∑2𝑘𝑖=1𝐶𝑖, where each 𝐶𝑖 is a (noncommutative) Π[𝑘]Σ circuit.

Before we prove the claim, we show that it easily yields the desired algorithm. First we notice that

𝐶ˆ∘𝑓∗=∑𝑖=12𝑘𝐶ˆ∘𝐶𝑖.
Now, by Theorem 1.4, we can compute in poly(𝑛,𝑠,𝑘) time a poly(𝑛,𝑠,𝑘) size circuit for the (noncommutative) Hadamard product 𝐶ˆ∘𝐶𝑖. As argued in the proof of Lemma 2.4, for any 𝑎⃗ ∈𝔽𝑛 we have

(𝑔∘ s 𝑓)(𝑎⃗ )=(𝐶∘ s 𝑓)(𝑎⃗ )=(𝐶ˆ∘𝑓∗)(𝑎⃗ ).
Thus, we can evaluate (𝑔∘ s 𝑓)(𝑎⃗ ) by incrementally computing (𝐶ˆ∘𝐶𝑖)(𝑎⃗ ) and adding up for 1≤𝑖≤2𝑘. This can be clearly implemented using only polynomial space. ◻

Proof of Claim 5.2
By definition,

𝑓∗=∑𝜎∈𝑆𝑘𝐿̂ 𝜎(1)𝐿̂ 𝜎(2)⋯𝐿̂ 𝜎(𝑘).
Now define the 𝑘×𝑘 matrix T such that the elements in each row of T are the linear forms 𝐿̂ 1,𝐿̂ 2,…,𝐿̂ 𝑘 in this order. Then the (noncommutative) permanent of T is given by

Perm(𝑇)=∑𝜎∈𝑆𝑘∏𝑗=1𝑘𝐿̂ 𝜎(𝑗)
which is just 𝑓∗.

We will now apply Ryser’s formula [30] to express Perm(𝑇) as a depth-3 homogeneous noncommutative Σ[2𝑘]Π[𝑘]Σ formula. We recall Ryser’s formula [30] for Per(𝐴), where A is a 𝑘×𝑘 matrix with noncommuting entries 𝐴𝑖𝑗:

Per(𝐴)=∑𝑆⊆[𝑘](−1)|𝑆|∏𝑖=1𝑘∑𝑗∈𝑆𝐴𝑖𝑗.
It is a Σ[2𝑘]Π[𝑘]Σ formula for the 𝑘×𝑘 noncommutative permanent. Now, substituting 𝐿̂ 𝑗 for 𝐴𝑖𝑗 1≤𝑖,𝑗≤𝑘, it follows that 𝑓∗=Per(𝑇) has a Σ[2𝑘]Π[𝑘]Σ noncommutative formula. Note that Ryser’s formula is usually given for the commutative permanent. It is easy to observe that the same proof, based on the principle of inclusion-exclusion, also holds for the noncommutative permanent. ◻

Remark 5.3
Over the rationals, we can get an alternative proof of Lemma 5.1 by using Fischer’s identity [17] to obtain a Σ[2𝑘]Π[𝑘]Σ formula for 𝑓∗.

Now we are ready to prove Theorem 1.9.

Proof
By homogenization, we can assume that C computes a homogeneous degree k polynomial f.

We will refer to maps 𝜁:[𝑛]→[𝑘] as coloring maps. The map 𝜁 can be seen as assigning colorsFootnote4 to the elements of [n]: 𝜁(𝑖) is the color of i.

We will pick a collection of coloring maps {𝜁𝑖:[𝑛]→[𝑘]} each picked independently and uniformly at random. For each coloring map 𝜁𝑖 we define a Π[𝑘]Σ formula

𝑃𝑖=∏𝑗=1𝑘∑ℓ:𝜁𝑖(ℓ)=𝑗𝑥ℓ.
A monomial is covered by a coloring map 𝜁𝑖 if the monomial is nonzero in 𝑃𝑖. The probability that a random coloring map covers a given degree-k multilinear monomial is

𝑘!⋅𝑘−𝑘≈𝑒−𝑘.
Hence, for a collection  of 𝑂∗(𝑒𝑘) many coloring maps ={𝜁𝑖:[𝑛]→[𝑘]} picked independently and uniformly at random, it holds with constant probability that every multilinear monomial of degree k is covered at least once by some 𝜁𝑖 in . This probability bound is by a simple and standard union bound argument. Now, for each coloring map 𝜁𝑖∈ we consider the circuit 𝐶′𝑖=𝐶∘ s 𝑃𝑖.

Notice that for each multilinear monomial m, the multiplicative factor m! is 1. Also, the coefficient of each monomial is exactly 1 in each 𝑃𝑖, and if f contains a multilinear term then it is covered by some 𝑃𝑖. Now, we perform the randomized polynomial identity test on each circuit 𝐶′𝑖 by applying the Demillo-Lipton-Schwartz-Zippel Lemma [15, 32, 42] in randomized polynomial time to complete the procedure. More precisely, we pick a random 𝑎⃗ ∈𝔽𝑛 and evaluate 𝐶′𝑖 at 𝑎⃗  to check if it is nonzero. By Lemma 5.1, the computation of 𝐶′𝑖(𝑎⃗ ) can be done deterministically in time 𝑂∗(2𝑘) time and poly(𝑛,𝑘) space.Footnote5 Hence the total running time of the procedure is 𝑂∗((2𝑒)𝑘).

In order to improve the running time to 𝑂∗(4.32𝑘), we apply the color coding technique of Hüffner et al. [20]. The idea is to use more than k colors to reduce the number of coloring maps required to cover the degree-k monomials. But this would increase the formal degree of each depth two circuit which we need to handle.

We will use 1.3k colorsFootnote6 and each circuit 𝑃𝑖 will now be a Π[1.3𝑘]Σ circuit. For each coloring map 𝜁𝑖:[𝑛]→[1.3𝑘] chosen uniformly at random, we define the following Π[1.3𝑘]Σ circuit

𝑃𝑖(𝑥1,𝑥2,…,𝑥𝑛,𝑧1,…,𝑧1.3𝑘)=∏𝑗=11.3𝑘(∑ℓ:𝜁𝑖(ℓ)=𝑗𝑥ℓ+𝑧𝑗).
Since each 𝑃𝑖 is of degree 1.3k, we need to modify the circuit C to another circuit 𝐶′ of degree 1.3k in order to apply Hadamard products. To that end, we define the circuit 𝐶′∈𝔽[𝑋,𝑍] as follows

𝐶′(𝑋,𝑍)=𝐶(𝑋)⋅𝑆1.3𝑘,0.3𝑘(𝑧1,…,𝑧1.3𝑘),
where 𝑆1.3𝑘,0.3𝑘(𝑧1,…,𝑧1.3𝑘) is the elementary symmetric polynomial of degree 0.3k over the variables 𝑧1,…,𝑧1.3𝑘. By the result of [20], for 𝑂∗(1.752𝑘) random coloring maps, with high probability each multilinear monomial in C is covered by the monomials of some 𝑃𝑖 (over the X variables).

Now to compute 𝐶′ˆ∘𝑃∗𝑖 for each i, we symmetrize the polynomial 𝑃𝑖. Of course, the symmetrization happens over the X variables as well as over the Z variables. But in 𝐶′ˆ we are only interested in the monomials (or words) where the rightmost 0.3k variables are over Z variables. In the noncommutative circuit 𝐶′ˆ, every subword 𝑧𝑖1𝑧𝑖2…𝑧𝑖0.3𝑘 receives a natural ordering 𝑖1<𝑖2<…<𝑖0.3𝑘.

Notice that

𝑃∗𝑖(𝑌,𝑍)=∑𝜎∈𝑆1.3𝑘∏𝑗=11.3𝑘(∑ℓ:𝜁𝑖(ℓ)=𝜎(𝑗)𝑦ℓ+𝑧𝜎(𝑗)).
Our goal is to understand the part of 𝑃∗𝑖(𝑌,𝑍) where each monomial ends with a subword of the form 𝑧𝑖1𝑧𝑖2…𝑧𝑖0.3𝑘 and the top k symbols are over the X variables. For a fixed set of indices 𝑊={𝑖1<𝑖2<…<𝑖0.3𝑘}, define the set 𝑇=[1.3𝑘]∖𝑊. Let 𝑆[𝑘],𝑇 be the set of permutations 𝜎∈𝑆1.3𝑘 such that 𝜎:[𝑘]→𝑇 and 𝜎(𝑘+𝑗)=𝑖𝑗 for 1≤𝑗≤0.3𝑘. As we have fixed the last 0.3k positions, each 𝜎∈𝑆[𝑘],𝑇 corresponds to some 𝜎′∈𝑆𝑘. Let 𝑍𝑊=𝑧𝑖1𝑧𝑖2…𝑧𝑖0.3𝑘. Now we notice the following. ◻

Observation 5.4
The part of 𝑃∗𝑖(𝑌,𝑍) where each monomial ends with the subword 𝑍𝑊 is 𝑃∗𝑖,𝑊⋅𝑍𝑊, where

𝑃∗𝑖,𝑊(𝑌)=∑𝜎∈𝑆[𝑘],𝑇∏𝑗=1𝑘(∑ℓ:𝜁𝑖(ℓ)=𝜎(𝑗)𝑦ℓ)=∑𝜎′∈𝑆𝑘∏𝑗=1𝑘⎛⎝⎜⎜∑ℓ:𝜁𝑖(ℓ)=𝜎′(𝑗)𝑦ℓ⎞⎠⎟⎟.
Now, just like the case above, it suffices to perform polynomial identity testing for

(𝐶′ˆ∘𝑃∗𝑖)(𝑌,𝑍)=∑𝑊⊆[1.3𝑘]:|𝑊|=0.3𝑘(𝐶ˆ(𝑌)∘𝑃∗𝑖,𝑊(𝑌))⋅𝑍𝑊.
for each i. But this is same as testing 𝐶′∘ s 𝑃𝑖 for identity. Now we eliminate the Z variables by substituting 1 and evaluate X variables on a random point 𝑎⃗ ∈𝔽𝑛. By Lemma 5.1, (𝐶′∘ s 𝑃𝑖)(𝑎⃗ ,1⃗ ) can be computed in 𝑂∗(21.3𝑘)=𝑂∗(2.46𝑘) time and poly(𝑛,𝑘) space. The bound on the success probability follows from Demillo-Lipton-Schwartz-Zippel Lemma [15, 32, 42].

We repeat the above procedure for each coloring map and obtain a randomized 𝑂∗(4.32𝑘) algorithm. This completes the proof of Theorem 1.9. ◻

Deterministic Algorithms for Depth Three Circuits
In this section we obtain fast deterministic algorithms for (k,n)−MLC and k−MMD for depth-three arithmetic circuits. These are obtained by a simple application of Hadamard product combined with symmetrization. We will require the following.

Theorem 6.1
[4, Theorem 4] Let A and B be noncommutative ABPs of sizes 𝑠1 and 𝑠2, computing homogeneous degree-k polynomials 𝑓1,𝑓2∈𝔽⟨𝑌⟩, respectively. Then, we can compute an ABP of size 𝑂(𝑠1𝑠2) for the Hadamard product 𝑓1∘𝑓2 in deterministic poly(𝑠1,𝑠2) time. Furthermore, if A and B are Π[𝑘]Σ circuits, then we can compute a Π[𝑘]Σ circuit for 𝑓1∘𝑓2 in poly(𝑠1,𝑠2) time.

We now prove Theorem 1.10.

Proof
Let C be the given Σ[𝑠′]Π[𝑘]Σ circuit computing the polynomial 𝑓∈𝔽[𝑋]. We first consider the k−MMD problem.

Suppose the coefficients are integers (without loss of generality, if we assume the underlying field is rationals). Let 𝐶=∑𝑠′𝑖=1𝐶𝑖 where each 𝐶𝑖 is a Π[𝑘]Σ circuit. We obtain a circuit for 𝐶∘ s 𝐶(𝑋) as follows. By Corollary 2.5, it suffices to obtain a circuit for 𝐶ˆ∘𝐶∗(𝑌). Notice that 𝐶∗=∑𝑠′𝑖=1𝐶∗𝑖 and by Claim 5.2 we know that each 𝐶∗𝑖 is a Σ[2𝑘]Π[𝑘]Σ circuit which can be computed in 𝑂∗(2𝑘) time. By distributivity, the problem of computing 𝐶ˆ∘𝐶∗(𝑌) reduces to computing the noncommutative Hadamard product of 𝑠′⋅2𝑘 many pairs of depth-two Π[𝑘]Σ circuits. By Theorem 6.1, each such Hadamard product can be computed in poly(𝑛,𝑘) time. Hence, we obtain a depth three commutative Σ[𝑠′⋅2𝑘]Π[𝑘]Σ circuit 𝐶̃  for 𝐶∘ s 𝐶(𝑋) in 𝑂∗(2𝑘) time. Note that m is a nonzero monomial in C if and only if [𝑚]𝐶̃ >0.

Let B be the poly(𝑛,𝑘) size ABP for 𝑆𝑛,𝑘. Now the idea is to compute 𝐶̃ ∘ s 𝐵(1⃗ ), and if it is nonzero, we know that C contains a degree-k multilinear term. Again this reduces to computing 𝑠′⋅2𝑘 scaled Hadamard products, each of the form Π[𝑘]Σ∘ s 𝐵(1⃗ ). By Lemma 5.1, each such computation can be done in 𝑂∗(2𝑘) time incurring a overall running time 𝑂∗(4𝑘).

In the case of finite fields, the above proof does not work since 𝐶̃ ∘ s 𝐵(1⃗ ) could be zero modulo the characteristic.The idea is similar to the proof of Theorem 1.9. But instead of random coloring maps we pick 𝜁𝑖:[𝑛]→[𝑘] from the explicit (n, k)-family perfect hash functions constructed in [25], which is of size 𝑒𝑘𝑘𝑂(log𝑘)log𝑛, and define a Π[𝑘]Σ formula

𝑃𝑖=∏𝑗=1𝑘∑ℓ:𝜁𝑖(ℓ)=𝑗𝑥ℓ
for each coloring map 𝜁𝑖. Now for each i, we construct the circuit 𝐶′𝑖=𝐶∘ s 𝑃𝑖. As already explained each 𝐶′𝑖(𝑋) is a Σ[𝑠′⋅2𝑘]Π[𝑘]Σ circuit and it can be obtained in deterministic 𝑂∗(2𝑘) time. Clearly, if C contains a multilinear monomial, we can detect it by doing identity testing of each 𝐶′𝑖. Now we apply a result of Saxena [31] where he shows that the identity testing of a ΣΠ[𝑘]Σ circuit over finite fields can be done in deterministic 𝑂∗(2𝑐𝑘) time where the constant 𝑐≤5. The final running time is 𝑒𝑘𝑘𝑂(log𝑘)𝑂∗(2𝑐𝑘+2𝑘).

As a by-product of the above technique, we get a fast deterministic algorithm to compute the sum of the coefficients of degree-k multilinear monomials in a depth there circuit, solving the (k,n)−MLC problem. Notice that, we need to compute 𝐶∘ s 𝐵(1⃗ ). As already explained, it can be obtained in deterministic 𝑂∗(2𝑘) time.

◻

Remark 6.2
The main result of [31, Theorem 1] is actually a polynomial identity testing algorithm for a larger class of circuits. It also uses the identity testing algorithm for noncommutative ABPs [29]. Indeed, the bound 𝑐≤5 is from [29, Theorem 4].

Discussion
In conclusion, we broadly compare the Hadamard product used in this paper with the apolar inner product used in the work of Pratt and others [10, 27, 28].

Recall, given two commutative homogeneous degree d polynomials f and g in 𝔽[X], the apolar inner product ⟨𝑓,𝑔⟩ is defined as follows.

⟨𝑓,𝑔⟩=𝑓(∂∂𝑥1,…,∂∂𝑥𝑛)𝑔=∑𝑚𝑚![𝑚]𝑓⋅[𝑚]𝑔,
where the sum is over all degree-d monomials 𝑚=𝑥𝑒11𝑥𝑒22…𝑥𝑒𝑛𝑛∈𝑋𝑑.

The Waring rank of a homogeneous degree-d polynomial 𝑓∈𝔽[𝑋] is the least r such that 𝑓=∑𝑟𝑗=1𝛼𝑗⋅𝐿𝑑𝑗, where for each j, 𝛼𝑗∈𝔽 and 𝐿𝑗 is a homogeneous linear form. If f has Waring rank r and g is given by an arithmetic circuit Pratt [27, 28] has shown that the apolar inner product of f and g can be computed in 𝑂∗(𝑟) time. Hence, using the Waring decomposition of the elementary symmetric polynomials (over the field of rationals) [23] yields faster algorithms [28] for k−MMD and (k,n)−MLC: 𝑂∗(4.08𝑘)-time for k−MMD and 𝑂∗(𝑛𝑘/2)-time for (k,n)−MLC) over the field of rationals.

However, the Waring decomposition does not appear to have a finite field analogue. For example, over 𝔽2 the polynomial xy has no Waring decomposition. In comparison, our algorithms are essentially oblivious to the underlying field.

More recently, Brand and Pratt [10] have shown that the apolar inner product of commutative polynomials f and g can be computed in 𝑂∗(𝑟) time if the partial derivative space of f has rank r. This strengthens Pratt’s result [28] as the Waring rank of f is an upper bound on its partial derivative rank.

It is interesting to compare this with the Hadamard product based approach of our paper. We first note that the apolar inner product of polynomials 𝑓,𝑔∈𝔽[𝑋] can be computed by first computing their scaled Hadamard product (see Sect. 2) and evaluating the resulting polynomial at 𝑥𝑖=1 for each 𝑖∈[𝑛]. Furthermore, the computation of Hadamard product of f and g can be done efficiently, as shown in Lemma 2.4 (Sect. 2), in time polynomial in the noncommutative algebra branching program complexity 𝑏(𝑓∗) (i.e. the minimum size of the ABP computing 𝑓∗) of the noncommutative polynomial 𝑓∗. The partial derivative space rank of f essentially coincides with 𝑏(𝑓∗):

Fact 7.1
For any commutative polynomial f, the ABP complexity 𝑏(𝑓∗) of 𝑓∗ is the dimension of the space of partial derivatives of f.

Proof
Let 𝑓∈𝔽[𝑋] be a homogeneous degree-k commutative polynomial, where 𝑋={𝑥1,𝑥2,…,𝑥𝑛} is a set of commuting variables. Let 𝑌={𝑦1,𝑦2,…,𝑦𝑛} be a corresponding set of free noncommuting variables.

Recall that Nisan [26] has shown that the ABP complexity b(g) of a noncommutative polynomial 𝑔∈𝔽⟨𝑌⟩ of degree k is exactly ∑𝑘ℓ=1rank(𝑀ℓ(𝑔)) where the matrix 𝑀ℓ(𝑔) is defined as follows. The rows of 𝑀ℓ(𝑔) are indexed by words in 𝑌ℓ and the columns of 𝑀ℓ(𝑔) are indexed by words in 𝑌𝑘−ℓ. For some 𝑤1∈𝑌ℓ and 𝑤2∈𝑌𝑘−ℓ, the (𝑤1,𝑤2)𝑡ℎ entry of 𝑀ℓ(𝑔) is [𝑤1𝑤2]𝑔.

We now consider the matrix 𝑀ℓ(𝑓∗) for the noncommutative polynomial 𝑓∗∈𝔽⟨𝑌⟩. Let 𝑤1∈𝑌ℓ and 𝑤2∈𝑌𝑘−ℓ. Let 𝜎∈𝑆ℓ and 𝜏∈𝑆𝑘−ℓ be any permutations. By definition of 𝑓∗, it is clear that

𝑀ℓ(𝑓∗)(𝑤1,𝑤2)=𝑀ℓ(𝑓∗)(𝑤𝜎1,𝑤𝜏2).
In particular, the row of 𝑀ℓ(𝑓∗) indexed by 𝑤1 is identical to the row indexed by 𝑤𝜎1.

Furthermore, the row of 𝑀ℓ(𝑓∗) indexed by 𝑤1 has the following structure for any 𝑤1∈𝑌ℓ: the 𝑤2-th entry of this row is the same as the 𝑤𝜏2-th entry of this row.

Now consider the partial derivative matrix of f, 𝑀̃ ℓ(𝑓) defined as follows. The rows of 𝑀̃ ℓ(𝑓) are indexed by commuting degree-ℓ monomials in Xℓ. For some 𝑚∈Xℓ, the corresponding row is the coefficient vector of ∂𝑓∂𝑚.

It follows from the above considerations that a subset of rows of 𝑀̃ ℓ(𝑓) labeled by monomials 𝑚1,𝑚2,…,𝑚𝑟 are linearly independent iff for noncommuting monomials 𝑤1,𝑤2,…,𝑤𝑟, such that 𝑤𝑖→𝑚𝑖, the rows of row of 𝑀ℓ(𝑓∗) indexed by the 𝑤𝑖 are linearly independent.

Therefore, rank(𝑀ℓ(𝑓∗))=rank(𝑀̃ ℓ(𝑓)), which completes the proof. ◻

We conclude with the following arithmetic circuit complexity question, a positive answer to which would have interesting algorithmic implications: Is there a polynomial f over the rationals that is positively weakly equivalentFootnote7 to the elementary symmetric polynomial 𝑆𝑛,𝑘 such that the ABP complexity 𝑏(𝑓∗) is 𝑂∗(2𝑘)? It would even suffice to show that 𝑓∗ has arithmetic circuits of size 𝑂∗(2𝑘) to improve on the current best deterministic algorithm for the k-path problem.