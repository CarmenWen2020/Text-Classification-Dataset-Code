We consider the streaming version of the following problem: given an input string s of length n, find the maximum exponent of a substring of s. We prove that any algorithm deciding, w.h.p., whether a string contains a square, uses memory of size ğ›º(ğ‘›), and thus does not satisfy the limitations of the streaming model. Thus the considered problem has no exact solution in the streaming model. Our main result is a Monte Carlo algorithm which computes the maximum exponent up to an additive error ğœ€<1/2: it outputs a number ğ›¼ such that s has a substring of exponent ğ›¼ but no substrings of exponent ğ›¼+ğœ€ or higher. The algorithm uses îˆ»(log2ğ‘›ğœ€) words of memory and performs îˆ»(logğ‘›) operations, including dictionary operations, per input symbol.

Access provided by University of Auckland Library

Introduction
The exponent of a string, which is the ratio between its length and its minimum period, is a natural measure of global periodicity. At the same time, the maximum exponent of a substring, also known as local or critical exponent of a string, measures local periodicity. The study of exponents and local exponents of strings can be traced back to the seminal papers by Thue [19, 20]. Here we focus on the algorithmic aspects. In the usual RAM model, the exponent of a string can be easily computed online in linear time; for example, the pattern preprocessing in the Knuthâ€“Morrisâ€“Pratt string matching algorithm [11] gives the exponent of the pattern for free. Note that this result holds for any alphabet. For local exponents, the things are more complicated. The â€œeasyâ€ case occurs when a string contains periodic substrings (a string is periodic if its minimal period is at least twice smaller than its length). Assuming polynomial integer alphabet (which is a common assumption in stringology), all maximal periodic substrings, or runs, can be found in linear time [13]. Over a general alphabet, the asymptotically best known algorithm, proposed in [6], finds all runs in time îˆ»(ğ‘›â‹…ğ›¼(ğ‘›)), where ğ›¼ is the inverse Ackermann function. In the opposite case, where the string contains no periodic substrings, only the case of a constant-size alphabet was analyzed. Here a linear-time algorithm was designed in [3]. This algorithm makes an explicit use of the lower bound on the local exponents of long strings (â€œrepetition thresholdâ€), which depends on the alphabet. We did not find any results for more general alphabets. A related problem of reporting all maximal substrings with exponents greater than a given threshold was considered, also over a constant-size alphabet, in [7, 12]. The solution in optimal îˆ»(ğ‘›/ğœ€) time for the threshold (1+ğœ€) was presented in [7], together with a detailed survey of related results.

We consider the problem of computing the local exponent of a stream. The streaming model of computation became quite popular in stringology in the last decade, after impressive results on streaming string matching [5, 16]. In the streaming model, the input string arrives online symbol by symbol; after reading a symbol, the algorithm must compute the answer for the string it has read. The main restriction is that the string cannot be stored after reading, because the available amount of memory is sublinear. This restriction is quite severe, and so most of the streaming algorithms are approximate, randomized, or both. Often, only Monte Carlo approximation algorithms can reach sublinear memory. This is the case for the computation of the local exponent as well as for other closely related problems: finding a longest repeated substring [14] and computing all runs [15]. The latter problem is closely related to finding the local exponent: it covers the case where the stream contains runs that can be detected by a streaming algorithm.

Our results are as follows. First we show that no streaming algorithm, even a Monte Carlo one, can compute the exact local exponent of a stream. More precisely, we show that it is impossible to correctly compare, using a sublinear amount of memory, the local exponent of a string with 2. Next we formulate the problem of approximating the local exponent with an additive error and then present the main result, which is the following theorem.

Theorem 1
There exists a Monte Carlo streaming algorithm which

given a length-n input stream s over a polynomial integer alphabet and an error parameter ğœ€âˆˆ(0;12], returns the number ğ›¼ such that s has a substring of exponent ğ›¼ but no substrings of exponent ğ›¼+ğœ€ or higher;

uses îˆ»(log2ğ‘›ğœ€) words of memory and performs îˆ»(logğ‘›) operations, including dictionary operations, per input symbol.

To prove Theorem 1, both the results and the technique of [15] are heavily used.

Preliminaries
Let s denote a string of length n over an alphabet ğ›´={1,â€¦,ğœ}, where ğœ is polynomial in n. We write s[i] for the ith symbol of s and s[i..j] for its substring (or factor) ğ‘ [ğ‘–]ğ‘ [ğ‘–+1]â‹¯ğ‘ [ğ‘—]. Thus, ğ‘ [1..ğ‘›]=ğ‘ . By convention, s[i..j] is an empty string if ğ‘—<ğ‘–. A prefix (resp. suffix) of s is a substring of the form s[1..j] (resp., s[j..n]). If ğ‘¤=ğ‘ [ğ‘–..ğ‘—], we say that w occurs (or has an occurrence) in s at position i. A period of s is a positive integer p such that ğ‘ [1..ğ‘›âˆ’ğ‘]=ğ‘ [ğ‘+1..ğ‘›]; ğ—‰ğ–¾ğ—‹(ğ‘ ) denotes the minimum period of s. We often refer to the strings having period p as p-periodic. The exponent of s is the ratio exp(ğ‘ )=|ğ‘ |/ğ—‰ğ–¾ğ—‹(ğ‘ ), where |s| denotes the length of s. The number ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ )=max{exp(ğ‘ [ğ‘–..ğ‘—])âˆ£1â‰¤ğ‘–<ğ‘—â‰¤ğ‘›} is the local (or critical) exponent of s.

A repetition of period p is a string s such that ğ‘=ğ—‰ğ–¾ğ—‹(ğ‘ )â‰¤|ğ‘ |/2. Thus, s is a repetition iff exp(ğ‘ )â‰¥2; repetitions of exponent 2 are called squares. A string containing no repetitions (or, equivalently, no squares) is called square-free. A repetition s[i..j] of period p is called a run (in s) if both ğ‘ [ğ‘–âˆ’1..ğ‘—] and ğ‘ [ğ‘–..ğ‘—+1], whenever exist, have no period p. Following [7], we use the term subrepetition for any string s satisfying 1<exp(ğ‘ )<2. Such a string can be factorized as ğ‘ =ğ‘¢ğ‘£ğ‘¢, where |ğ‘¢ğ‘£|=ğ—‰ğ–¾ğ—‹(ğ‘ ); u is its border.

We work in the streaming model of computation: the input string s[1..n] (the stream) is read from left to right, one symbol at a time, and cannot be stored, because the available space is sublinear in n. The space is counted as the number of îˆ»(logğ‘›)-bit machine words (in this paper, log stands for the binary logarithm).

A Monte Carlo algorithm gives a correct answer with high probability (at least 1âˆ’1ğ‘› on a length n input) and has deterministic working time and space. For the related streaming problems of finding a longest repeat and computing all runs [14, 15], Monte Carlo approximation algorithms were used, and proofs that other types of algorithms cannot work in the streaming model were presented. The present paper follows the same pattern.

The main result of [15] is heavily related to the computation of local exponents, so we give its precise formulation. Let ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–±ğ—ğ—‡ğ—Œ denote the following approximate version of the problem of computing all runs in a stream:

given an input string s and an error parameter ğœ€=ğœ€(ğ‘›)âˆˆ(0,12], report a set of substrings of s such that

(i)
for each run of exponent ğ›¼â‰¥2+ğœ€ in s a single substring of this run is reported, having the same period as the run itself and the exponent at least ğ›¼âˆ’ğœ€;

(ii)
for runs of smaller exponent, zero or one substring of each run is reported; if a substring is reported, it has the same period as the run and the exponent at least 2.

In the algorithm which solved ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–±ğ—ğ—‡ğ—Œ we extended the set of elementary operations with dictionary operations (insert, delete, lookup). The optimal choice of dictionary depends on ğœ€. The following theorem is the main result of [15].

Theorem 2
There is a Monte Carlo streaming algorithm that solves ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–±ğ—ğ—‡ğ—Œ performing îˆ»(logğ‘›) operations per read and using îˆ»(log2ğ‘›ğœ€) words of memory.

The algorithm from Theorem 2 can be used to approximate ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ ) whenever ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ )â‰¥2+ğœ€ (and sometimes this algorithm will be lucky to approximate ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ ) in the case 2â‰¤ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ )<2+ğœ€). The details are given in Sect. 4.

The Square-Freeness Problem
As it is known since Thue [19], there exist arbitrarily long square-free strings over three or more letters. Let ğ–²ğ—Šğ–¥ğ—‹ğ–¾ğ–¾(ğ›´,ğ‘›) be the following decision problem:

given a length-n stream over the alphabet ğ›´ of size ğœ>3, decide whether the stream is square-free.

The following theorem shows that sublinear memory is insufficient to solve this problem with high probability.

Theorem 3
There is a constant ğ›¾ such that every algorithm solving the problem ğ–²ğ—Šğ–¥ğ—‹ğ–¾ğ–¾(ğ›´,ğ‘›) with probability at least 1âˆ’1ğ‘› uses at least ğ›¾ğ‘›logğœ bits of memory.

Proof
The scheme of proof is rather standard for this sort of results. We first use Yaoâ€™s minimax principle [21] and then finalize the intermediary result exploiting the so-called amplification trick.

Step 1. Assume that some Monte Carlo streaming algorithm solves ğ–²ğ—Šğ–¥ğ—‹ğ–¾ğ–¾(ğ›´,ğ‘›) exactly using less than âŒŠlogğ¹âŒ‹ bits of memory, where F is the number of square-free strings of length ğ‘›â€²=ğ‘›2âˆ’1 over ğœâˆ’1 letters. Let us prove that its error probability is at least 1ğ‘›ğœ. According to Yaoâ€™s minimax principle, it is sufficient to construct a probability distribution îˆ½ over ğ›´ğ‘› such that for any deterministic algorithm ğ–£ using less than âŒŠlogğ¹âŒ‹ bits of memory, the expected probability of error on a string chosen according to îˆ½ is at least 1ğ‘›ğœ.

We define a length-n string w(x, k, c) as follows. We fix $âˆˆğ›´ and let ğ›´1=ğ›´âˆ’{$}. Next we fix two arbitrary square-free strings ğ‘¢1 and ğ‘¢2 of length ğ‘›â€² over ğ›´1; the only restriction is that their first letters are distinct. Let x be a square-free string of length ğ‘›â€² over ğ›´1, ğ‘âˆˆğ›´1, and ğ‘˜âˆˆ{1,â€¦,ğ‘›â€²}. Then

ğ‘¤(ğ‘¥,ğ‘˜,ğ‘)=ğ‘¥[1..ğ‘›â€²]$ğ‘ğ‘¥[ğ‘›â€²âˆ’ğ‘˜+2..ğ‘›â€²]$ğ‘¢ğ‘–[1..ğ‘›â€²âˆ’ğ‘˜],
where ğ‘–=1 if ğ‘¢1[1]â‰ ğ‘ and ğ‘–=2 otherwise. Due to the separators $, the string w(x, k, c) contains a unique square (ğ‘¥[ğ‘›â€²âˆ’ğ‘˜+1..ğ‘›â€²]$)2 if ğ‘=ğ‘¥[ğ‘›â€²âˆ’ğ‘˜+1]; in the case ğ‘â‰ ğ‘¥[ğ‘›â€²âˆ’ğ‘˜+1], w(x, k, c) is square free iff ğ‘ğ‘¥[ğ‘›â€²âˆ’ğ‘˜+2..ğ‘›â€²] is square free. Let îˆ½ be the uniform distribution over all strings w(x, k, c).

Since the available memory is insufficient to distinguish between any two square-free strings from ğ›´ğ‘›â€²1, there exists an â€œindistinguishableâ€ pair (ğ‘¥,ğ‘¥â€²) of such strings; that is, ğ–£ is in the same state after reading either x or ğ‘¥â€². Let ğ‘¥=ğ‘£ğ‘ğ‘ , ğ‘¥â€²=ğ‘£â€²ğ‘â€²ğ‘ , where ğ‘£,ğ‘£â€²,ğ‘ âˆˆğ›´âˆ—1, ğ‘,ğ‘â€²âˆˆğ›´1, and ğ‘â‰ ğ‘â€². Then ğ–£ returns the same answer on ğ‘¤(ğ‘¥,|ğ‘ |+1,ğ‘) and ğ‘¤(ğ‘¥â€²,|ğ‘ |+1,ğ‘), because the right halves of these two strings coincide. However, ğ‘¤(ğ‘¥,|ğ‘ |+1,ğ‘) contains the square (ğ‘ğ‘ $)2, while ğ‘¤(ğ‘¥â€²,|ğ‘ |+1,ğ‘) is square free. Therefore, ğ–£ errs on one of the analysed inputs; similarly, it errs on either ğ‘¤(ğ‘¥,|ğ‘ |+1,ğ‘â€²) or ğ‘¤(ğ‘¥â€²,|ğ‘ |+1,ğ‘â€²).

Consider an arbitrary maximal set of disjoint pairs (ğ‘¥,ğ‘¥â€²) of square-free strings from ğ›´ğ‘›â€²1, where the strings in each pair are indistinguishable by ğ–£. The memory of ğ–£ has no more than 2âŒŠlogğ¹âŒ‹âˆ’1â‰¤ğ¹/2 states. Since at most one string per state is left unpaired, the number of pairs is at least F/4. As was shown above, each pair causes two errors by ğ–£, to the total of at least F/2 errors. The number of strings in the distribution îˆ½ is ğ¹â‹…ğ‘›â€²â‹…(ğœâˆ’1), which implies that the probability of error is greater than 1ğ‘›ğœ.

Step 2. To use amplification, we relate the parameter F to n and ğœ. Namely, we show that there exists a positive constant ğ›¿ such that âŒŠlogğ¹âŒ‹â‰¥ğ›¿ğ‘›logğœ. Let ğ¶ğ‘˜(ğ‘›) be the number of k-ary square-free strings of length n. Then ğ¶ğ‘˜(ğ‘›) is an exponentially-growing function of n [4]. As was shown in [17], the base ğ›¼ğ‘˜ of this exponential function satisfies, as a function of k, the condition ğ›¼ğ‘˜=(ğ‘˜âˆ’1)âˆ’1/(ğ‘˜âˆ’1)âˆ’1/(ğ‘˜âˆ’1)3+ğ‘‚(1/ğ‘˜5). By definition of F we have ğ¹=ğ¶ğœâˆ’1(ğ‘›â€²); so we can write ğ¹>ğ‘‘(ğœâˆ’3)ğ‘›/2âˆ’1 for some positive constant d and thus logğ¹>(ğ‘›2âˆ’1)log(ğœâˆ’3)+logğ‘‘. If ğœâ‰¥5, this inequality implies the announced lower bound. For the remaining case ğœ=4 we use a more precise bound ğ›¼3>1.3; see [18, Theorem 4] for the method of obtaining lower bounds and [18, Table A.2] for numerical results. Hence in this case ğ¹>ğ‘‘â€²â‹…1.3ğ‘›/2âˆ’1 for some positive constant ğ‘‘â€², and then logğ¹>(ğ‘›2âˆ’1)log1.3+logğ‘‘â€²=ğ›º(ğ‘›)=ğ›º(ğ‘›logğœ). Thus we proved the existence of a positive ğ›¿ such that âŒŠlogğ¹âŒ‹â‰¥ğ›¿ğ‘›logğœ.

Now assume that some Monte Carlo streaming algorithm ğ–  solves ğ–²ğ—Šğ–¥ğ—‹ğ–¾ğ–¾ exactly with error probability ğœ€â‰¤1ğ‘› using s(n) bits of memory. Then we can run its k instances simultaneously and return the most frequent answer. The new algorithm ğ– ğ‘˜ uses îˆ»(ğ‘˜â‹…ğ‘ (ğ‘›)) bits of memory and its error probability ğœ€ğ‘˜ satisfies the inequality ğœ€ğ‘˜â‰¤âˆ‘2ğ‘–<ğ‘˜(ğ‘˜ğ‘–)(1âˆ’ğœ€)ğ‘–ğœ€ğ‘˜âˆ’ğ‘–â‰¤2ğ‘˜â‹…ğœ€ğ‘˜/2=(4ğœ€)ğ‘˜/2. Recall that ğœ=îˆ»(ğ‘›ğ‘) for some constant p. Let ğ‘˜=2ğ‘+3 and take any positive ğ›¾â‰¤ğ›¿ğ‘˜. If ğ‘ (ğ‘›)<ğ›¾ğ‘›logğœ, then algorithm ğ– ğ‘˜ uses less than ğ›¿ğ‘›logğœâ‰¤âŒŠlogğ¹âŒ‹ bits of memory. On the other hand, the error probability of ğ– ğ‘˜ is ğœ€ğ‘˜â‰¤(4ğœ€)ğ‘˜/2â‰¤(4ğ‘›)ğ‘+3/2, which is less than 1ğ‘›ğœ for n big enough because ğœ=îˆ»(ğ‘›ğ‘). From step 1 we know that this is impossible, so the theorem holds for the chosen value of ğ›¾. â—»

Theorem 3 shows that there is no hope to compute local exponents of streams exactly, because we cannot even correctly compare this exponent to 2 without an access to linear-size memory. Hence we come up with a natural approximation version ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–¤ğ—‘ğ—‰ of this problem:

given a stream s and an error parameter ğœ€âˆˆ(0,12], find a number ğ›¼ such that ğ›¼â‰¤ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ )<ğ›¼+ğœ€.

The rest of the paper describes the algorithm solving ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–¤ğ—‘ğ—‰ within the resource limitations listed in Theorem 1. In fact, the algorithm does more: it is able to output a position of a substring of exponent ğ›¼.

Tools
The algorithm solving ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–±ğ—ğ—‡ğ—Œ (Theorem 2) outputs substrings of s as triples (l, p, r) such that s[l..r] is a repetition of period p, so it can keep track of the maximum exponent among these triples without spending additional time or space. This version, returning the maximum exponent found, is below referred to as Algorithm Rep. Note that if Algorithm Rep finds at least one repetition, then it solves ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–¤ğ—‘ğ—‰ and, by Theorem 2, satisfies the conditions of Theorem 1. So the problem is how to process the streams in which Algorithm Rep finds nothing.

We explore an obvious idea: design an approximation algorithm (Algorithm Sub) for square-free or â€œnearly square-freeâ€ streams and run it in parallel with Algorithm Rep. Both algorithms update the current maximum exponent. If a repetition is detected, we abort Algorithm Sub and continue running Algorithm Rep. In the description of Algorithm Sub we thus assume that no repetition was detected until the current iteration.

We make use of particular data structures and general organization of data introduced in [15] for Algorithm Rep. All necessary details are reproduced in this section.

Fingerprints, Frames, Checkpoints
We use Karpâ€“Rabin fingerprints [10], which is a hash function ubiquitous in streaming string algorithms. Let p be a fixed prime from the range [ğ‘›4,ğ‘›5], and r be a fixed integer randomly chosen from {1,â€¦,ğ‘âˆ’1}. For a string s, its hash is defined as ğœ™(ğ‘ )=(âˆ‘ğ‘›ğ‘–=1ğ‘ [ğ‘–]â‹…ğ‘Ÿğ‘–)modğ‘. The probability of hash collision for two strings of length m is at most m/p. Our algorithm compares hashes of strings having equal lengths of the form 2ğ‘—. The probability that a pair of such strings collide is less than ğ‘›3/ğ‘ and thus less than the allowed error probability for Monte Carlo algorithms. Hence all further considerations assume that no collisions happen. For a string s, its frame is the tuple (|ğ‘ |,ğœ™(ğ‘ ),ğ‘Ÿ|ğ‘ |modğ‘,ğ‘Ÿâˆ’|ğ‘ |modğ‘). The crucial property of frames is the following.

Lemma 1
([5]) If the frames of any two of the strings A, B, AB are known, the frame of the third string can be computed in îˆ»(1) time.

All definitions below refer to the input stream s. For any i, the ith iteration of a streaming algorithm processing s begins with reading s[i] and ends just before reading ğ‘ [ğ‘–+1]. We write I(i) for the frame of ğ‘ [1..ğ‘–âˆ’1]. Lemma 1 implies that one can compute ğ¼(ğ‘–+1) in îˆ»(1) time from I(i) and s[i].

All information currently stored by our algorithm is associated with checkpoints, which form a subset of all positions. Each position k becomes a checkpoint at the kth iteration and â€œlivesâ€ during ğ—ğ—ğ—…(ğ‘˜) iterations, where the time-to-live function is defined by ğ—ğ—ğ—…(ğ‘˜)=2ğ‘¡ğœ€+2+ğ›½(ğ‘˜) with ğ‘¡ğœ€=âŒˆlog2ğœ€âŒ‰ and ğ›½(ğ‘˜) being the maximum power of 2 dividing k. If ğ‘˜+ğ—ğ—ğ—…(ğ‘˜)=ğ‘–, then at the start of the ith iteration k â€œdiesâ€ (loses the status of checkpoint) and all associated information is deleted. See the example in Fig. 1.

Lemma 2
([15])

1)
The number of checkpoints at iâ€™th iteration is îˆ»(logğ‘–ğœ€).

2)
If ğ‘–âˆ’ğ—ğ—ğ—…(ğ‘–)>0, then the checkpoint ğ‘–âˆ’ğ—ğ—ğ—…(ğ‘–) dies at the iâ€™th iteration. Otherwise, no checkpoint dies at this iteration.

Fig. 1
figure 1
The checkpoints (black) after the iteration ğ‘–=105 (ğ‘¡ğœ€=2). For example, ğ—ğ—ğ—…(52)=22+2+2=64, so the position 52 is a checkpoint until the iteration 116

Full size image
Remark 1
We should say a few words about the functions ğ›½(ğ‘˜) and âŒˆlogğ‘˜âŒ‰, both extensively used in our algorithm. Note that âŒˆlogğ‘˜âŒ‰=ğ—†ğ—Œğ–»(ğ‘˜âˆ’1)+1, where the function ğ—†ğ—Œğ–»(ğ‘¥) returns the position of the most significant 1 in the binary representation of x. With the aid of fusion trees, ğ—†ğ—Œğ–»(ğ‘¥) can be computed in constant number of operations with machine words; see [9]. A practical way to compute âŒˆlogğ‘˜âŒ‰ is to subtract the value ğ–¼ğ—…ğ—“(ğ‘˜) from the size of the machine word. The ğ–¼ğ—…ğ—“(ğ‘¥) function counts leading zeroes in the binary representation of an unsigned integer x in a machine word and is a standard CPU instruction. Further, ğ›½(ğ‘˜)=ğ–¼ğ—ğ—“(ğ‘˜), where the function ğ–¼ğ—ğ—“(ğ‘˜) counts trailing zeroes in the binary representation of k. Some CPU architectures contain ğ–¼ğ—ğ—“(ğ‘˜) as an instruction, but we can operate without it: it was shown in [15, Lemma 10] that all calls to ğ›½() during one iteration can be performed in îˆ»(logğ‘›) total time; this bound fits into Theorem 1.

Blocks, Groups, Navigation
Both Algorithm Rep and Algorithm Sub work with substrings of length 2ğ‘—, ğ‘—=0,â€¦,âŒŠlogğ‘›âŒ‹. The notions introduced below are illustrated by Fig. 2. For each iteration i and each j we distinguish a subclass of substrings of length 2ğ‘— called j-blocks. A substring u of length 2ğ‘— of the stream s is a j-block (at the ith iteration) if it occurs in s[1..i] at some checkpoint; i.e., if ğ‘¢=ğ‘ [ğ‘˜..ğ‘˜+2ğ‘—âˆ’1] where k is a checkpoint at the ith iteration. Note that u will lose the status of j-block at some future iteration if no checkpoints corresponding to the occurrences of u will remain alive. Below we say â€œcheckpoint occurrenceâ€ instead of â€œoccurrence at a checkpointâ€. For each j-block T we maintain a basic structure ğµğ‘‡ called group and consisting of

Frame of T

Doubly-connected list ğ‘™ğ‘–ğ‘ ğ‘¡ of all checkpoints, in increasing order, that are positions of occurrences of T

Position ğ‘“ğ‘Ÿğ‘’ğ‘ â„ (described below) and its frame ğ‘“ğ‘“ğ‘Ÿğ‘ğ‘šğ‘’=ğ¼(ğ‘“ğ‘Ÿğ‘’ğ‘ â„)

Number ğ‘’ğ‘¥ğ‘¡ (described below)

Apart from the checkpoint occurrences of j-blocks, we are interested in their fresh occurrences (whether at checkpoints or not). An occurrence at position k is fresh at ith iteration, if ğ‘˜>ğ‘–âˆ’2ğ‘—+1+1. This condition means that a fresh occurrence of a j-block was a suffix of the stream less than 2ğ‘— iterations below. So we immediately have

Observation 1
Any two fresh occurrences of the same j-block overlap.

By definitions of periods and repetitions, overlapping occurrences of the same string create a repetition. Hence Observation 1 implies

Observation 2
If the suffix of length 2ğ‘— of the current stream s[1..i] is a j-block which already has a fresh occurrence at position f, then s[f..i] is a repetition. Since ğ‘ [ğ‘“..ğ‘“+2ğ‘—âˆ’1]=ğ‘ [ğ‘–âˆ’2ğ‘—+1..ğ‘–], this repetition has the period ğ‘–âˆ’ğ‘“+1âˆ’2ğ‘— by definition. Then exp(ğ‘ [ğ‘“..ğ‘–])=ğ‘–âˆ’ğ‘“+1ğ‘–âˆ’ğ‘“+1âˆ’2ğ‘—.

Observation 3
Algorithm Rep needs to memorize, in some compressed form, all fresh occurrences of each j-block. For Algorithm Sub, we simplified the structure of a group and store just one fresh occurrence. If a second fresh occurrence is detected, we use Observation 2, update the answer with the exponent ğ›¼>2 of the repetition found, and stop the algorithm. The rest of the stream is then processed solely by Algorithm Rep.

Finally, the extension number ğ‘’ğ‘¥ğ‘¡ is used to memorize an additional information about the subrepetition uvu, where the right u is the fresh occurrence of a j-block and the left u is the previous checkpoint occurrence of the same block (depending on whether the fresh occurrence is at a checkpoint or not, the left u is either last or second last element of ğ‘™ğ‘–ğ‘ ğ‘¡). The number ğ‘’ğ‘¥ğ‘¡ shows that the subrepetition uvu can be extended in s by ğ‘’ğ‘¥ğ‘¡ symbols to the left, preserving the period.

Fig. 2
figure 2
Illustrating j-blocks and groups. Black positions are checkpoints; the arcs 1, 2, 3, 4 represent all occurrences of some substring T of length 2ğ‘— in the stream at the ith iteration. The occurrences 1 and 3 are at checkpoints (so T is a j-block), while the occurrences 2 and 4 are not. The group ğµğ‘‡ contains the information about the occurrences 1, 3, and 4: the positions of 1 and 3 are in ğµğ‘‡.ğ‘™ğ‘–ğ‘ ğ‘¡, the position of 4 is ğµğ‘‡.ğ‘“ğ‘Ÿğ‘’ğ‘ â„. The occurrence 2 is â€œforgottenâ€: no information is stored about it. Finally, the arcs 5 and 6 represent equal substrings of length ğµğ‘‡.ğ‘’ğ‘¥ğ‘¡

Full size image
Remark 2
A group is a constant-size structure (two frames, links to the beginning and the end of ğ‘™ğ‘–ğ‘ ğ‘¡, the numbers ğ‘“ğ‘Ÿğ‘’ğ‘ â„ and ğ‘’ğ‘¥ğ‘¡) plus a set of constant-size nodes (position, links to next and previous elements of the list). We store all groups in an array of constant-size cells endowed with a stack of empty cells. This way, creating a new group/node and deleting an existing group/node requires îˆ»(1) time. The size of the array is proportional to the number of groups plus the number of occurrences of j-blocks; both numbers are îˆ»(log2ğ‘›ğœ€), as follows from Lemma 2(1).

For navigation we use five dictionaries described in the following table. The values in the first four dictionaries are stored as links.

Id	Key	Value
ğ»1	j, hash F	group of the j-block with hash F
ğ»2	j, checkpoint k	group of the j-block occurring at k
ğ»3	j, position k	group of the j-block having the fresh occurrence at k
ğ»ğ»	j, checkpoint k	node for k in the group of the j-block occurring at k
ğ»ğ¶	checkpoint k	frame I(k)
Algorithm Sub
Let ğ‘¤=ğ‘ [ğ‘¡..ğ‘–] be a substring, ğ‘=ğ—‰ğ–¾ğ—‹(ğ‘¤). Let f be the smallest position satisfying ğ‘“â‰¥ğ‘¡ and ğ—ğ—ğ—…(ğ‘“)â‰¥2ğ‘, and let g be the largest position such that ğ‘”â‰¤ğ‘– and ğ—ğ—ğ—…(ğ‘”âˆ’ğ‘+1)â‰¥2ğ‘. We call the substring s[f..g] of w the core of w.

Lemma 3
Every substring s[t..i] with exp(ğ‘ [ğ‘¡..ğ‘–])â‰¥1+ğœ€ has a nonempty core. The exponent of the core is greater than exp(ğ‘ [ğ‘¡..ğ‘–])âˆ’ğœ€.

Proof
Let ğ—ğ—ğ—…(ğ‘¥)â‰¥2ğ‘ be the minimum time-to-live satisfying this inequality. Then ğ—ğ—ğ—…(ğ‘¥)=2âŒˆlogğ‘âŒ‰+1, so ğ›½(ğ‘¥)=âŒˆlogğ‘âŒ‰âˆ’1âˆ’ğ‘¡ğœ€ by the definition of ğ—ğ—ğ—…. Hence the distance between two consecutive positions with ğ—ğ—ğ—…â‰¥2ğ‘ is 2ğ›½(ğ‘¥)<2(logğ‘+1)âˆ’1âˆ’log2ğœ€=ğœ€ğ‘2. Therefore, the numbers f and g from the definition of the core satisfy ğ‘“âˆ’ğ‘¡,ğ‘–âˆ’ğ‘”<ğœ€ğ‘2. Since |ğ‘ [ğ‘¡..ğ‘–]|â‰¥(1+ğœ€)ğ‘, the length of s[f..g] is strictly greater than p. So s[f..g] has period p as a substring of s[t..i], and exp(ğ‘ [ğ‘“..ğ‘”])>exp(ğ‘ [ğ‘¡..ğ‘–])âˆ’ğœ€ğ‘ğ‘=exp(ğ‘ [ğ‘¡..ğ‘–])âˆ’ğœ€, as required. â—»

Lemma 3 shows that the core of a substring approximates its exponent with the desired precision. The idea of Algorithm Sub is to detect cores using the information about j-blocks, stored in groups. The detection becomes possible because the definition of a core implies that certain positions are checkpoints at the moment when the core is read (see Fig. 3). When a core is detected, its exponent is computed and used to update the answer. Some cores can be missed by the algorithm; the crucial fact, proved in Lemma 4 below, is that a core is missed only if some other substring of bigger exponent was detected before. This fact ensures the correctness of the answer found by Algorithm Sub.

One iteration of Algorithm Sub is presented below as Algorithm 1. As was already said, Algorithm Sub works in parallel with Algorithm Rep, which is responsible for â€œbigâ€ exponents. Moreover, the two algorithms share the auxiliary stages at each iteration, with some details simplified for Algorithm Sub. In line 1, we read a new symbol, compute the frame of the whole string and store it in the dictionary ğ»ğ¶. Then three nontrivial stages follow. These stages are described in [15] as Algorithms 1â€“3, endowed with the proofs of correctness and time bounds. So here we just recall the performed operations in brief.

figure a
Stage 1 (line 2). Lemma 2 indicates the only checkpoint which can die at the current iteration. We process each of îˆ»(logğ‘›) j-blocks at the checkpoint position, deleting the checkpoints from their groups and from dictionaries; groups without checkpoints are also deleted. The dictionaries ğ»2 and ğ»ğ» are used, an entry in ğ»ğ¶ is deleted.

Stage 2 (line 3). The j-blocks of the form s[k..i], where k is a checkpoint, are processed. For each block we compute its hash, retrieving I(k) from the dictionary ğ»ğ¶ and using Lemma 1. Then we extract the group B of this block from the table ğ»1; if B does not exist, it is created. A node for k is added to ğµ.ğ‘™ğ‘–ğ‘ ğ‘¡, and an element is added to ğ»ğ». The occurrence at k is fresh, so ğµ.ğ‘“ğ‘Ÿğ‘’ğ‘ â„ is set to k, ğµ.ğ‘“ğ‘“ğ‘Ÿğ‘ğ‘šğ‘’ is set to I(k), and a new element is added to the dictionary ğ»3. If a fresh occurrence existed before, a repetition is detected, which implies the abortion of the algorithm; the rest of the stream will be processed solely by Algorithm Rep. The stage includes one more loop over j: using ğ»2, the expired fresh checkpoint occurrences are deleted.

Stage 3 (line 5). A trick is used here to find the hash of the suffix ğ‘‡=ğ‘ [ğ‘˜..ğ‘–] of length 2ğ‘— in the case if k is not a checkpoint. If T has no checkpoint occurrences, it is useless in the search of (sub)repetitions, and we skip it. But if T has such an occurrence, then its prefix of length 2ğ‘—âˆ’1 is a (ğ‘—âˆ’1)-block occurring at the same checkpoint. We check at ğ»3 whether there is a (ğ‘—âˆ’1)-block ğ‘‡â€² with the fresh occurrence at k. If yes, we extract the frame I(k) as ğ‘“ğ‘“ğ‘Ÿğ‘ğ‘šğ‘’ of ğ‘‡â€² and get the hash of T by Lemma 1. The fresh occurrence of ğ‘‡â€² at k is then deleted as expired (it was not deleted at Stage 2 because k is not a checkpoint). After computing the hash of T, the group of T is retrieved from the dictionary ğ»1. If no such group exists (ğ‘‡â€² has checkpoint occurrences but T has not), we skip T (lines 6â€“7).

In lines 8â€“9, the algorithm stops according to Observation 3 if two fresh occurrences of T (at ğµ.ğ‘“ğ‘Ÿğ‘’ğ‘ â„ and at k) are found. Lines 10â€“22 are related to the main procedure: core detection.

Lemma 4
Suppose that Algorithm Sub processed a stream s and no repetitions were detected. Let s[t..i] be a substring of s such that exp(ğ‘ [ğ‘¡..ğ‘–])â‰¥1+ğœ€, ğ‘=ğ—‰ğ–¾ğ—‹(ğ‘ [ğ‘¡..ğ‘–]) and ğ‘ [ğ‘¡âˆ’1..ğ‘–] is not p-periodic. Then Algorithm Sub detected either the core of s[t..i] or some other substring of exponent greater than the exponent of this core.

Fig. 3
figure 3
Finding the core s[f..g] of a p-periodic substring s[t..i] (Lemma 4). Black positions are checkpoints, white positions can have any status. In the picture, ğ‘—=ğ‘—â€²+2 and ğ‘˜=6

Full size image
Proof
Let s[f..g] be the core of s[t..i] (see Fig. 3 for an illustration). Since it has period p, ğ‘ [ğ‘“..ğ‘”âˆ’ğ‘]=ğ‘ [ğ‘“+ğ‘..ğ‘”] by definition. Let us denote this repeated part by u. One has |ğ‘¢|=ğ‘”âˆ’ğ‘“âˆ’ğ‘+1. Let ğ‘—=âŒŠlog|ğ‘¢|âŒ‹. Then u is strictly shorter than a (ğ‘—+1)-block and (non-strictly) longer than a j-block. We prove the lemma by showing that Algorithm Sub followed one of two scenarios:

(i)
The core was detected at the gth iteration: for the j-block which is the suffix of s[1..g] (ğ‘‡2 in Fig. 3) the previous occurrence at a checkpoint was at distance p and ğ‘’ğ‘¥ğ‘¡=|ğ‘¢|âˆ’2ğ‘—; these two conditions imply ğ‘ [ğ‘“..ğ‘”âˆ’ğ‘]=ğ‘ [ğ‘“+ğ‘..ğ‘”];

(ii)
A substring of exponent bigger than the exponent of the core was detected no later than at the gth iteration.

Let ğ‘—â€²=max{0,âŒˆlogğ‘âŒ‰âˆ’1âˆ’ğ‘¡ğœ€}. As shown in the proof of Lemma 3, consecutive positions with ğ—ğ—ğ—…â‰¥2ğ‘ are at distance 2ğ‘—â€². Since f and ğ‘”âˆ’ğ‘+1 have ğ—ğ—ğ—…â‰¥2ğ‘ by the definition of a core, (ğ‘”âˆ’ğ‘+1)âˆ’ğ‘“=|ğ‘¢|=â„â‹…2ğ‘—â€² for some â„â‰¥1. Hence each of the positions ğ‘“,ğ‘“+2ğ‘—â€²,â€¦,ğ‘“+(â„âˆ’1)â‹…2ğ‘— remains a checkpoint for at least 2âŒˆlogğ‘âŒ‰+1 iterations and ğ‘¢=ğ‘ [ğ‘“..ğ‘”âˆ’ğ‘] is a concatenation of h ğ‘—â€²-blocks at these checkpoints. These ğ‘—â€²-blocks can be combined into overlapping j-blocks, denoted by ğ‘‡0,ğ‘‡1,â€¦,ğ‘‡ğ‘‘ as in Fig. 3. Note that ğ‘‘=â„âˆ’2ğ‘—âˆ’ğ‘—â€²; in particular, if h is a power of 2, then ğ‘ [ğ‘“..ğ‘”âˆ’ğ‘] is a single j-block.

Now we are going to show that Algorithm Sub followed either scenario (i) or scenario (ii) with respect to the core s[f..g]. To do this, we analyze the iterations ğ‘–0,â€¦,ğ‘–ğ‘‘ in which the right (in Fig. 3) occurrences of the j-blocks ğ‘‡0,ğ‘‡1,â€¦,ğ‘‡ğ‘‘ were suffixes of the stream; that is ğ‘–ğ‘Ÿ=ğ‘“+ğ‘+2ğ‘—+ğ‘Ÿ2ğ‘—â€²âˆ’1 for ğ‘Ÿ=0,â€¦,ğ‘‘ (thus ğ‘–ğ‘‘=ğ‘”). First consider the iteration ğ‘–0. At this iteration, f was a checkpoint and the stream had the j-block ğ‘‡0 at position ğ‘“+ğ‘ as a suffix. Hence, Algorithm Sub found, in line 11 or line 13, the rightmost previous checkpoint occurrence of ğ‘‡0. The checkpoint is either f or some ğ‘“â€²>ğ‘“. In the latter case, consider the three occurrences of ğ‘‡0: at f, ğ‘“â€², and ğ‘“+ğ‘ (Fig. 4). These occurrences neither overlap nor touch: otherwise, ğ‘‡0 had two fresh occurrences at some moment and a repetition was detected, which is impossible by the conditions of the lemma. Thus these occurrences form two subrepetitions ğ‘ [ğ‘“..ğ‘“â€²+2ğ‘—âˆ’1] and ğ‘ [ğ‘“â€²..ğ‘–0] overlapping by the middle occurrence. One of these subrepetitions was detected at the iteration ğ‘–0 and the other one had been found earlier at the iteration ğ‘“â€²+2ğ‘—âˆ’1. The sum of their periods is p. Then one of the periods is at most p/2, and the exponent of the corresponding substring is at least 1+2ğ‘—+1ğ‘. By definition of j, 2ğ‘—+1>|ğ‘¢|, so this exponent is greater than the exponent of the core, which is 1+|ğ‘¢|ğ‘. Therefore, scenario (ii) was realized.

Fig. 4
figure 4
Illustrating the proof of Lemma 4: an additional occurrence of ğ‘‡0 at position ğ‘“â€²

Full size image
Now consider the case where the rightmost previous checkpoint occurrence of ğ‘‡0 is at f. The two rightmost occurrences of ğ‘‡0 do not overlap or touch because no repetition was detected. Then, in particular, 2ğ‘—<ğ‘ (see Fig. 3). The algorithm computed f, p, and ğ‘—â€² in line 15 and set the extension of ğ‘‡0 to 0 in line 16. Next, in line 17 the algorithm retrieved the j-block at position ğ‘“âˆ’2ğ‘—â€². This position was a checkpoint at the considered iteration. Indeed, ğ—ğ—ğ—…(ğ‘“âˆ’2ğ‘—â€²)â‰¥2ğ‘ (as mentioned above, consecutive positions with ğ—ğ—ğ—…â‰¥2ğ‘ are at distance 2ğ‘—â€²). Then ğ—ğ—ğ—…(ğ‘“âˆ’2ğ‘—â€²)â‰¥2ğ‘—+2 because 2ğ‘—<ğ‘. It remains to note that 2ğ‘—+2 is greater than the difference between the current position ğ‘–0=ğ‘“+ğ‘+2ğ‘—âˆ’1 and ğ‘“âˆ’2ğ‘—â€². The retrieved j-block differs from the j-block at the position ğ‘“+ğ‘âˆ’2ğ‘—â€² because ğ‘“âˆ’2ğ‘—â€²<ğ‘¡ by the definition of a core and ğ‘ [ğ‘¡âˆ’1]â‰ ğ‘ [ğ‘¡+ğ‘âˆ’1] be the conditions of the lemma. Hence the condition in line 18 is false (note that ğ‘˜=ğ‘+ğ‘“); so the algorithm detected the subrepetition ğ‘ [ğ‘“..ğ‘–0] and updated the answer with its exponent1+2ğ‘—ğ‘ in line 22.

Next consider the iteration ğ‘–1, in which the stream had the suffix ğ‘‡1. At this iteration, the algorithm found the previous checkpoint occurrence of ğ‘‡1. If the checkpoint is greater than ğ‘“+2ğ‘—â€², then we repeat the above argument about three occurrences of ğ‘‡0 for the occurrences of ğ‘‡1 and conclude that scenario (ii) took place. Assume that the occurrence was found at ğ‘“+2ğ‘—â€². In line 17, the j-block at the checkpoint f was retrieved; this block is ğ‘‡0 and its fresh occurrence satisfies the condition in line 18. The extension of ğ‘‡1 is set in line 19 to 2ğ‘—. The value ğµâ€².ğ‘’ğ‘¥ğ‘¡ had been set to 0 during the iteration ğ‘–0 we considered above; thus the iteration ğ‘–1 ended by updating the answer in line 22 with the exponent 1+2ğ‘—+2ğ‘—â€²ğ‘ of the subrepetition ğ‘ [ğ‘“..ğ‘–1].

Finally we prove by induction the following claim: for any ğ‘Ÿâ‰¤ğ‘‘ either scenario (ii) was detected no later than at the iteration ğ‘–ğ‘Ÿ or the iteration ğ‘–ğ‘Ÿ ended by updating the answer with the exponent 1+2ğ‘—+ğ‘Ÿ2ğ‘—â€²ğ‘ of the subrepetition ğ‘ [ğ‘“..ğ‘–ğ‘Ÿ]. The base case is proved above; we proceed with the step case.

Consider the iteration ğ‘–ğ‘Ÿ for some ğ‘Ÿâ‰¥2 and suppose that scenario (ii) was not detected till its end. At the iteration ğ‘–ğ‘Ÿ, the algorithm found the previous checkpoint occurrence of ğ‘‡ğ‘Ÿ. If this checkpoint is greater than ğ‘“+ğ‘Ÿâ‹…2ğ‘—â€², scenario (ii) is detected repeating the above argument for ğ‘‡0 (Fig. 4). Since we assumed it was not detected, the previous checkpoint occurrence of ğ‘‡ğ‘Ÿ was at ğ‘“+ğ‘Ÿâ‹…2ğ‘—â€². By the same argument, the previous checkpoint occurrence of ğ‘‡ğ‘Ÿâˆ’1, found at the iteration ğ‘–ğ‘Ÿâˆ’1, was at ğ‘“+(ğ‘Ÿâˆ’1)2ğ‘—â€². Further, the iteration ğ‘–ğ‘Ÿâˆ’1 ended with updating the answer with the exponent 1+2ğ‘—+(ğ‘Ÿâˆ’1)2ğ‘—â€²ğ‘ of the string ğ‘ [ğ‘“..ğ‘–ğ‘Ÿâˆ’1] by the inductive hypothesis. This means (see line 22) that the extension of the block ğ‘‡ğ‘Ÿâˆ’1 was set to (ğ‘Ÿâˆ’1)2ğ‘—â€².

Consider the rest of the iteration ğ‘–ğ‘Ÿ after the checkpoint ğ‘“+ğ‘Ÿâ‹…2ğ‘—â€² was found. In line 17, the block ğ‘‡ğ‘Ÿâˆ’1 was retrieved. The condition in line 18 is true: it refers to the occurrence of ğ‘‡ğ‘Ÿâˆ’1 we analysed at the iteration ğ‘–ğ‘Ÿâˆ’1. In addition, the condition in line 20 holds: it says that when the algorithm processed the suffix ğ‘‡ğ‘Ÿâˆ’1 at that iteration, it found the checkpoint occurrence at ğ‘“+(ğ‘Ÿâˆ’1)2ğ‘—â€². Hence the algorithm set the extension of ğ‘‡ğ‘Ÿ to 2ğ‘—â€² at line 19 and updated it to 2ğ‘—â€²+(ğ‘Ÿâˆ’1)2ğ‘—â€²=ğ‘Ÿâ‹…2ğ‘—â€² in line 21. Then in line 22 the answer is updated with the required exponent 1+2ğ‘—+ğ‘Ÿ2ğ‘—â€²ğ‘. The claim is proved.

For ğ‘Ÿ=ğ‘‘, the claim says that if scenario (ii) was not detected, then at gth iteration the answer was updated with the exponent 1+2ğ‘—+ğ‘‘2ğ‘—â€²ğ‘. As 2ğ‘—+ğ‘‘2ğ‘—â€²=â„2ğ‘—â€²=|ğ‘¢|, this is exactly the exponent of the core s[f..g]. This means that scenario (i) took place. The lemma is proved. â—»

Remark 3
The condition in line 20 prevents Algorithm Sub from an error in a tricky situation illustrated by Fig. 5. At the current iteration i, for a suffix T of length 2ğ‘— the rightmost checkpoint occurrence was found at position f. The period p and the number ğ‘—â€² were computed, the j-block ğ‘‡â€² at the position ğ‘“âˆ’2ğ‘—â€² was retrieved, and this block appeared to have a fresh occurrence at ğ‘˜âˆ’2ğ‘—â€². Then the extension of T is set to 2ğ‘—â€² (the subrepetition ğ‘ [ğ‘“âˆ’2ğ‘—â€²..ğ‘–] is p-periodic). However, it would be an error to further increase the extension of T by the extension of ğ‘‡â€², because they are related to different subrepetitions: the extension of ğ‘‡â€² reflects the equality of two substrings Z shown in the picture. The condition in line 20 fails (if ğ‘˜âˆ’2ğ‘—â€² is a checkpoint, then ğ‘1=ğ‘˜âˆ’2ğ‘—â€² and ğ‘2=ğ‘“â€²; if not, then ğ‘1=ğ‘“â€²), so no error happens.

Fig. 5
figure 5
Illustrating special case of Algorithm 1: the extensions of the j-blocks T and ğ‘‡â€² refer to subrepetitions with different periods. At the ith iteration, the condition in line 20 fails, preventing the algorithm from adding the extension of ğ‘‡â€² to the extension of T

Full size image
Proof of Theorem 1
We run Algorithm Sub and Algorithm Rep in parallel (that is, after reading s[i] the ith iteration of each algorithm is performed; the order does not matter). If s contains a run of exponent at least 2+ğœ€, Algorithm Rep finds ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ ) with the error less than ğœ€. If any of the algorithms detects a repetition x (Algorithm Sub detects repetitions with the condition in line 8), then ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ )â‰¥exp(ğ‘¥)â‰¥2. So either exp(ğ‘¥) is a valid answer to ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–¤ğ—‘ğ—‰, or ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ )â‰¥2+ğœ€ and the answer can be found solely by Algorithm Rep. Hence, on detecting a repetition we stop Algorithm Sub and run Algorithm Rep for the rest of the stream.

Now suppose that no repetitions were found. Let x be a substring of s satisfying ğ—…ğ–¾ğ—‘ğ—‰(ğ‘ )=exp(ğ‘¥)â‰¥1+ğœ€. By Lemma 4, the answer obtained by Algorithm Sub cannot be smaller than exp(ğ‘§), where z is the core of x. By Lemma 3, exp(ğ‘§)>exp(ğ‘¥)âˆ’ğœ€. Hence Algorithm Sub solved ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–¤ğ—‘ğ—‰ correctly.

Algorithm Rep obliges the required space and time limitations by Theorem 2. It remains to estimate space and time consumed by Algorithm Sub. The space usage of Algorithm Sub is dominated by groups, which occupy îˆ»(log2ğ‘›ğœ€) words of space by Remark 2. The logarithmic time bounds for lines 2, 3, and 5 were proved in [15]; the remaining part of the algorithm uses îˆ»(1) operations per value of j (for âŒˆlogğ‘âŒ‰ see Remark 1), which is îˆ»(logğ‘›) per iteration. â—»

Conclusion and Open Questions
In this paper we presented the first streaming algorithm to compute the exponent of the input string. As often happens for streaming problems, the solution belongs to the class of Monte Carlo approximation algorithms because neither deterministic algorithms nor exact Monte Carlo algorithms can solve the problem in sublinear memory. Our algorithm has competitive parameters: its space usage is polynomial in logğ‘› and linear in 1/ğœ€, where n is the length of the input and ğœ€ is the additive error parameter. The îˆ»(logğ‘›) update time is also close to the minimum possible. In addition, our algorithm uses only practical data structures and the îˆ»-bounds hide no big constants.

Thus the natural question is â€œcan one do better?â€ More specifically,

Are there any space or time lower bounds for the ğ–ºğ—‰ğ—‰ğ—‹ğ—ˆğ—‘ğ–¤ğ—‘ğ—‰ problem?

Is it possible to improve space usage?

Is it possible to improve the update time to â€œpureâ€ îˆ»(logğ‘›), without dictionary operations?

Concerning the last question, we reproduce the remark from [15] on the choice of dictionaries, which shows what is the current â€œpureâ€ time bound.

Remark 4
If ğœ€ is small (inverse polynomial), it makes sense to use dynamic perfect hash tables [2, 8] as dictionaries. Both cited versions guarantee that with probability 1âˆ’ğ‘šâˆ’ğ‘, where m is the dictionary size and c is an arbitrary constant, all dictionary operations will take îˆ»(1) time. Thus the total probability of a failed run of an algorithm can still be kept below 1/n with îˆ»(logğ‘›) elementary operations between reads. However, this is not the case for big (such as constant or inverse polylog) values of ğœ€. So in this case we suggest to use deterministic dictionaries by Anderson and Thorup [1] which give us îˆ»(loglogğ‘›logloglogğ‘›â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆšâ‹…logğ‘›) elementary operations between reads.

