We show that there is a better-than-brute-force algorithm that, when given a small constant-depth Boolean circuit C made up of gates that compute constant-degree Polynomial Threshold functions or PTFs (i.e., Boolean functions that compute signs of constant-degree polynomials), counts the number of satisfying assignments to C in significantly better than brute-force time. Formally, for any constants d, k, there is an 𝜀>0 such that the zero-error randomized algorithm counts the number of satisfying assignments to a given depth-d circuit C made up of k-PTF gates such that C has at most 𝑛1+𝜀 many wires. The algorithm runs in time 2𝑛−𝑛Ω(𝜀). Before our result, no algorithm for beating brute-force search was known for counting the number of satisfying assignments even for a single degree-k PTF (which is a depth-1 circuit with linearly many wires).We give two different algorithms for the case of a single PTF. The first uses a learning algorithm for learning degree-1 PTFs (or Linear Threshold Functions) using comparison queries due to Kane, Lovett and Moran (STOC 2018), and the second uses a proof of Hofmeister (COCOON 1996) for converting a degree-1 PTF to a depth-two threshold circuit with small weights. We show that both these ideas fit nicely into a memoization approach that yields the #SAT algorithms.

Access provided by University of Auckland Library

Introduction
This paper adds to the growing line of work on circuit-analysis algorithms, where we are given as input a Boolean circuit C from a fixed class  computing a function 𝑓:{−1,1}𝑛→{−1,1},Footnote1 and we are required to compute some parameter of the function f. A typical example of this is the question of satisfiability, i.e. whether f is the constant function 1 or not. In this paper, we are interested in computing #SAT(f), which is the number of satisfying assignments of f (i.e. |{𝑎∈{−1,1}𝑛∣𝑓(𝑎)=−1}|).

Problems of this form can always be solved by “brute-force” in time poly(|𝐶|)⋅2𝑛 by trying all assignments to C. The question is can this brute-force algorithm be significantly improved, say to time 2𝑛/𝑛𝜔(1) when C is small, say |𝐶|≤𝑛𝑂(1).

Such algorithms, intuitively are able to distinguish a small circuit 𝐶∈ from a “black-box” and hence find some structure in C. This structure, in turn, is useful in answering other questions about , such as proving lower bounds against the class .Footnote2 There has been a large body of work in this area, a small sample of which can be found in [26, 27, 33, 37]. A striking result of this type was proved by Williams [33] who showed that for many circuit classes , even co-non-deterministic satisfiability algorithms running in better than brute-force time yield lower bounds against .

Recently, researchers have also uncovered tight connections between many combinatorial problems and circuit-analysis algorithms, showing that even modest improvements over brute-force search can be used to improve long-standing bounds for these combinatorial problems (see, e.g., [1,2,3, 38]). This yields further impetus in improving known circuit-analysis algorithms.

This paper is concerned with #SAT algorithms for constant depth threshold circuits, denoted as TC0, which are Boolean circuits where each gate computes a linear threshold function (LTF); an LTF computes a Boolean function which accepts or rejects based on the sign of a (real-valued) linear polynomial evaluated on its input. Such circuits are surprisingly powerful: for example, they can perform all integer arithmetic efficiently [4, 10], compute conjectured families of pseudorandom functions [23] (and hence are not amenable to Natural lower bound proof techniques in the sense defined by Razborov and Rudich [28]) and are at the frontier of our current lower bound techniques [8, 21].

It is natural, therefore, to try to come up with circuit-analysis algorithms for threshold circuits. Indeed, there has been a large body of work in the area (reviewed in the Previous Work paragraph later in the Introduction), but some extremely simple questions remain open.

An example of such a question is the existence of a better-than-brute-force algorithm for satisfiability of degree-k PTFs where k is a constant greater than 2. Informally, the question is the following: we are given a degree-k polynomial 𝑄(𝑥1,…,𝑥𝑛) in n Boolean variables and we ask if there is any Boolean assignment 𝑎∈{−1,1}𝑛 to 𝑥1,…,𝑥𝑛 such that 𝑄(𝑎)<0. Surprisingly, no algorithm is known for this problem that is significantly better than 2𝑛 time.Footnote3

Note that for a linear polynomial (i.e. 𝑘=1), this problem is trivial. For 𝑘=2 the problem is already non-trivial. While not noted explicitly in the literature, a better-than-brute-force algorithm for satisfiability of 2-PTFs is implied by the results from [32, 35]. However, the stronger counting variant of this problem for 2-PTFs is open as far as we know.

In this paper, we solve the counting variant of this problem for any constant-degree PTFs. We start with some definitions and then describe this result.

Definition 1
(Polynomial Threshold Functions) A Polynomial Threshold Function (PTF) on n variables of degree-k is a Boolean function 𝑓:{−1,1}𝑛→{−1,1} such that there is a degree-k multilinear polynomial 𝑃(𝑥1,…,𝑥𝑛)∈ℝ[𝑥1,…,𝑥𝑛] that, for all 𝑎∈{−1,1}𝑛, satisfies 𝑓(𝑎)=sgn(𝑃(𝑎)). (We assume that 𝑃(𝑎)≠0 for any 𝑎∈{−1,1}𝑛.)

In such a scenario, we call f a k-PTF. In the special case that 𝑘=1, we call f a Linear Threshold function (LTF). We also say that the polynomial P sign-represents f.

When 𝑃∈ℤ[𝑥1,…,𝑥𝑛], we define the weight of P, denoted w(P), to be the bit-complexity of the sum of the absolute values of all the coefficients of P. In particular, the coefficients of P are integers in the range [−2𝑤(𝑃),2𝑤(𝑃)].

We now formally define the #SAT problem for k-PTFs. Throughout, we assume that k is a constant and not a part of the input.

Definition 2
(#SAT problem for k-PTFs) The problem is defined as follows.

Input: A k-PTF f, specified by a degree-k polynomial 𝑃(𝑥1,…,𝑥𝑛) with integer coefficients.Footnote4

Output: The number of satisfying assignments to f. That is, the number of 𝑎∈{−1,1}𝑛 such that 𝑃(𝑎)<0.

We use #SAT(f) to denote this output. We say that the input instance has parameters (n, M) if n is the number of input variables and 𝑤(𝑃)≤𝑀.

Remark 3
An interesting setting of M is poly(𝑛) since any k-PTF can be represented by an integer polynomial with coefficients of bit-complexity at most 𝑂̃ (𝑛𝑘) [22]. However, note that our algorithms work even when M is exp(𝑛𝑜(1)), i.e. when the weights are slightly short of doubly exponential in n.

We give a better-than-brute-force algorithm for #SAT(𝑘-PTF). Formally we prove the following theorem.

Theorem 4
Fix any constant k. There is a deterministic algorithm that solves the #SAT problem for k-PTFs in time poly(𝑛,𝑀)⋅2𝑛−𝑆 where 𝑆=Ω̃ (𝑛1/(𝑘+1)) and (n, M) are the parameters of the input k-PTF f. (The Ω̃ (⋅) hides factors that are inverse polylogarithmic in n.)

Remark 5
An anonymous ITCS 2019 referee pointed out to us that from two results of Williams [32, 35], it follows that satisfiability for 2-PTFs can be solved in 2𝑛−Ω(𝑛√) time. Note that this is better than the runtime of our algorithm. However, the method does not seem to extend to 𝑘≥3.

Using a different approach, we give another algorithm for the same problem. This result is incomparable to Theorem 4. While the running time is better (and comparable to Williams’ algorithm mentioned above when 𝑘=2) as long as M is subexponential in n, the algorithm is zero-error randomized.Footnote5

Theorem 6
Fix any constant k. There is a zero-error randomized algorithm that solves the #SAT problem for k-PTFs in time poly(𝑛,𝑀)⋅2𝑛−𝑆 where 𝑆=Ω(𝑛1/𝑘) and (n, M) are the parameters of the input k-PTF f.

We then extend this result to a powerful model of circuits called k-PTF circuits, where each gate computes a k-PTF. This model was first studied by Kane, Kabanets and Lu [17] who proved strong average case lower bounds for slightly superlinear-size constant-depth k-PTF circuits. Using these ideas, Kabanets and Lu [18] were able to give a #SAT algorithm for a restricted class of k-PTF circuits, where each gate computes a PTF with a subquadratically many, say 𝑛1.99, monomials (while the size remains the same, i.e. slightly superlinear).Footnote6 A reason for this restriction on the PTFs was that they did not have an algorithm to handle even a single degree-2 PTF (which can have Ω(𝑛2) many monomials).

Building on our #SAT algorithm for k-PTFs and the ideas of [18], we are able to handle general k-PTF circuits of slightly superlinear size. We state these results formally below.

We first define k-PTF circuits formally.

Definition 7
(k-PTF circuits) A k-PTF circuit on n variables is a Boolean circuit on n variables where each gate g of fan-in m computes a fixed k-PTF of its m inputs. The size of the circuit is the number of wires in the circuit, and the depth of the circuit is the longest path from an input to the output gate.Footnote7

The problems we consider is the #SAT problem for k-PTF circuits, defined as follows.

Definition 8
(#SAT problem for k-PTF circuits) The problem is defined as follows.

Input: A k-PTF circuit C, where each gate g is labelled by an integer polynomial that sign-represents the function that is computed by g.

Output: The number of satisfying assignments to C.

We use #SAT(C) to denote this output. We say that the input instance has parameters (n, s, d, M) where n is the number of input variables, s is the size of C, d is the depth of C and M is the maximum over the weights of the degree-k polynomials specifying the k-PTFs in C. We will say that M is the weight of C, denoted by w(C).

We now state our result on #SAT for k-PTF circuits. The following result also implies a zero-error randomized version of Theorem 4.

Theorem 9
Fix any constants k, d. Then the following holds for some constant 𝜀𝑘,𝑑>0 depending on k, d. There is a zero-error randomized algorithm that solves the #SAT problem for k-PTF circuits of size at most 𝑠=𝑛1+𝜀𝑘,𝑑 with probability at least 1/4 and outputs ? otherwise. The algorithm runs in time poly(𝑛,𝑀)⋅2𝑛−𝑆, where 𝑆=𝑛𝜀𝑘,𝑑 and (n, s, d, M) are the parameters of the input k-PTF circuit.

We note that in the Williams [33] framework of proving lower bounds via satisfiability algorithms, zero-error randomized algorithms are as good as deterministic algorithms (as noted already above, even co-non-deterministic algorithms are good enough). However, the above theorem does not imply any new lower bounds, as slightly superlinear-size k-PTF circuits already follows from the work of Kane, Kabanets and Lu [17].

Previous work Satisfiability algorithms for TC0 have been widely investigated. Impagliazzo, Lovett, Paturi and Schneider [14, 16] give algorithms for checking satisfiability of depth-2 threshold circuits with O(n) gates. The former result was improved by Chen and Santhanam [6]. An incomparable result was proved by Williams [36] who obtained algorithms for subexponential-sized circuits from the class ACC0∘LTF, which is a subclass of subexponential TC0.Footnote8 For the special case of k-PTFs (and generalizations to sparse PTFs over the {0,1} basis) with small weights, a #SAT algorithm was devised by Sakai et al. [31].Footnote9 The high-level idea of our algorithm is the same as theirs.

For general constant-depth threshold circuits, the first satisfiability algorithm was given by Chen, Santhanam and Srinivasan [7]. In their paper, Chen et al. gave the first average case lower bound for TC0 circuits of slightly super linear size 𝑛1+𝜀𝑑, where 𝜀𝑑 depends on the depth of the circuit. (These are roughly the strongest size lower bounds we know for general TC0 circuits even in the worst case [15].) Using their ideas, they gave the first (zero-error randomized) improvement to brute-force-search for satisfiability algorithms (and indeed even #SAT algorithms) for constant depth TC0 circuits of size at most 𝑛1+𝜀𝑑.

The lower bound results of [7] were extended to the much more powerful class of k-PTF circuits (of roughly the same size as [7]) by Kane, Kabanets and Lu [17]. In a follow-up paper, Kabanets and Lu [18] considered the satisfiability question for k-PTF circuits, and could resolve this question in the special case that each PTF is subquadratically sparse, i.e. has 𝑛2−Ω(1) monomials. One of the reasons for this sparsity restriction is that their strategy does not seem to yield a SAT algorithm for a single degree-2 PTF (which is a depth-1 2-PTF circuit of linear size).

Proof outline
For simplicity we discuss SAT algorithms instead of #SAT algorithms.

Satisfiability algorithm for k-PTFs
At a high level, we follow the same strategy as Sakai et al. [31]. Their algorithm uses memoization, which is a standard and very useful strategy for satisfiability algorithms (see, e.g. [29]). Let  be a circuit class and 𝑛 be the subclass of circuits from  that have n variables. Memoization algorithms for -SAT fit into the following two-step template.

Step 1 Solve by brute-force all instances of -SAT where the input circuit 𝐶′∈𝑚 for some suitable 𝑚≪𝑛. (Typically, 𝑚=𝑛𝜀 for some constant 𝜀.) Usually this takes exp(𝑚𝑂(1))≪2𝑛 time.

Step 2 On the input 𝐶∈𝑛, set all input variables 𝑥𝑚+1,…,𝑥𝑛 to Boolean values and for each such setting, obtain 𝐶″∈𝑚 on m variables. Typically 𝐶″ is a circuit for which we have solved satisfiability in Step 1 and hence by a simple table lookup, we should be able to check if 𝐶″ is satisfiable in poly(|𝐶|) time. Overall, this takes time 𝑂∗(2𝑛−𝑚)≪2𝑛.

At first sight, this seems perfect for k-PTFs, since it is a standard result that the number of k-PTFs on m variables is at most 2𝑂(𝑚𝑘+1) [5]. Thus, Step 1 can be done in 2𝑂(𝑚𝑘+1)≪2𝑛 time.

For implementing Step 2, we need to ensure that the lookup (for satisfiability for k-PTFs on m variables) can be done quickly. Unfortunately how to do this is unclear. The following two ways suggest themselves.

Store all polynomials 𝑃′∈ℤ[𝑥1,…,𝑥𝑚] with small coefficients. Since every k-PTF f can be sign-represented by an integer polynomial with coefficients of size 2poly(𝑚) [22], this can be done with a table of size 2poly(𝑚) and in time 2poly(𝑚). When the coefficients are small (say of bit-complexity ≤𝑛𝑜(1)), then this strategy already yields a #SAT algorithm, as observed by Sakai et al. [31]. Unfortunately, in general, given a restriction 𝑃″∈ℤ[𝑥1,…,𝑥𝑚] of a polynomial 𝑃∈ℤ[𝑥1,…,𝑥𝑛], its coefficients can be much larger (say 2poly(𝑛)) and it is not clear how to efficiently find a polynomial with small coefficients that sign-represents the same function.

It is also known that every k-PTF on m variables can be uniquely identified by poly(𝑚) numbers of bit-complexity O(m) each [5]: these are called the “Chow parameters” of f. Again for this representation, it is unclear how to compute efficiently the Chow parameters of the function represented by the restricted polynomial 𝑃″. (Even for an LTF, computing the Chow parameters is as hard as Subset-sum [25].)

We show two different ways of circumventing these problems, using two different ideas from the literature.

Using learning theory We use a beautiful recent result of Kane, Lovett and Moran [19], who show that there is a simple decision tree that, when given as input the coefficients of any degree-k polynomial 𝑃′∈ℤ[𝑥1,…,𝑥𝑚], can determine the sign of the polynomial 𝑃′ at all points in {−1,1}𝑚 using only poly(𝑚) queries to the coefficients of P. Here, each query is a linear inequality on the coefficients of P; such a decision tree is called a linear decision tree.Footnote10

Our strategy is to replace Step 1 with the construction of this linear decision tree (which can be done in exp(𝑚𝑂(1)) time). At each leaf of the linear decision tree, we replace the truth table of the input polynomial 𝑃′ by a single bit that indicates whether 𝑓′=sgn(𝑃′) is satisfiable or not.

In Step 2, we simply run this decision tree on our restricted polynomial 𝑃″ and obtain the answer to the corresponding satisfiability query in poly(𝑚,𝑤(𝑃″)) time. Note, crucially, that the height of the linear decision tree implied by [19] construction is poly(𝑚) and independent of the bit-complexity of the coefficients of the polynomial 𝑃″ (which may be as big as poly(𝑛) in our algorithm). This concludes the description of the algorithm for k-PTF.

Using circuit complexity A famous result of Goldmann, Håstad and Razborov [9] shows that any linear threshold function (with possibly very large weights) can be simulated by a depth-2 threshold circuit with small weights. A simple proof of this was provided by Hofmeister [11]. The basic idea is to use the Chinese Remainder Theorem to reduce checking integer equalities involving very large integers to checking integer equalities with much smaller numbers (by going modulo small primes).

In our setting, this idea allows us to reduce (via a randomized procedure) the problem to be solved in Step 2 to solving satisfiability for k-PTFsFootnote11 on m variables with small coefficients, as long as M is not too large. Since there are not many such PTFs, we can compute and store the answers to all such queries beforehand. This yields the algorithm.

Satisfiability algorithm for k-PTF circuits
For k-PTF circuits, we follow a template set up by the result of Kabanets and Lu [18] on sparse-PTF circuits. We start by describing this template and then describe what is new in our algorithm.

The Kabanets–Lu algorithm is an induction on the depth d of the circuit (which is a fixed constant). Given as input a depth d k-PTF circuit C on n variables, Kabanets and Lu do the following:

Depth-reduction: In [18], it is shown that on a random restriction that sets all but 𝑛1−2𝛽 variables (here, think of 𝛽 as a small constant, say 0.01) to random Boolean values, the bottom layer of C simplifies in the following sense.

All but 𝑡≤𝑛𝛽 gates at the bottom layer become exponentially biased, i.e. on all but 𝛿=exp(−𝑛Ω(1)) fraction of inputs they are equal to a fixed 𝑏∈{−1,1}. Now, for each such biased gate g,  there is a minority value 𝑏𝑔∈{−1,1} that it takes on very few inputs. [18] show how to enumerate this small number of inputs in 𝛿⋅2𝑛 time and check if there is a satisfying assignment among these inputs. Having ascertained that there is no such assignment, we replace these gates by their majority value and there are only t gates at the bottom layer. At this point, we “guess” the output of these t “unbiased” gates and for each such guess 𝜎∈{−1,1}𝑡, we check if there is an assignment that simultaneously satisfies:

(a)
The depth 𝑑−1 circuit 𝐶′, obtained by setting the unbiased gates to the guess 𝜎, is satisfied.

(b)
Each unbiased gate 𝑔𝑖 evaluates to the corresponding value 𝜎𝑖.

Base case: Continuing this way, we eventually get to a base case which is an AND of sparse PTFs for which there is a satisfiability algorithm using the polynomial method.

In the above algorithm, there are two steps where subquadratic sparsity is crucially used. The first is the minority assignment enumeration algorithm for PTFs, which uses ideas of Chen and Santhanam [6] to reduce the problem to enumerating biased LTFs, which is easy [7]. The second is the base case, which uses a non-trivial polynomial approximation for LTFs [30]. Neither of these results hold for even degree-2 PTFs in general. To overcome this, we do the following.

Enumerating minority assignments Given a k-PTF on m variables that is 𝛿=exp(−𝑛Ω(1))-close to 𝑏∈{−1,1}, we enumerate its minority assignments as follows. First, we set up a linear decision tree as in the k-PTF satisfiability algorithm. Then we set all but 𝑞≈log1𝛿 variables of the PTF. On most such settings, the resulting PTF becomes the constant function and we can check this using the linear decision tree we created earlier. In this setting, there is nothing to do. Otherwise, we brute-force over the remaining variables to find the minority assignments. Setting parameters suitably, this yields an 𝑂(𝛿√⋅2𝑚) time algorithm to find the minority assignments of a k-PTF on m variables which is 𝛿-close to an explicit constant.

Base case Here, we make the additional observation (which [18] do not need) that the AND of PTFs that is obtained further is small in that it only has slightly superlinear size. Hence, we can apply another random restriction in the style of [18] and using the minority assignment enumeration ideas, reduce it to an AND of a small (say 𝑛0.1) number of PTFs on 𝑛0.01 (say) variables. At this point, we can again run the linear decision tree (in a slightly more generalized form) to check satisfiability.

#SAT for k-PTFs: the first algorithm
A result of Kane, Lovett, and Moran [19]
In this subsection, we formally present the result from [19] which we use in the memoization step of our #SAT algorithm in the following subsection. We begin with the following couple of definitions.

Definition 10
(Coefficient vectors) Fix any 𝑘,𝑚≥1. There are exactly 𝑟=∑𝑘𝑖=0(𝑚𝑖) many multilinear monomials of degree at most k. Any multilinear polynomial 𝑃(𝑥1,…,𝑥𝑚) of degree k can be identified with a list of the coefficients of its monomials in lexicographic order (say) and hence with some vector 𝑤∈ℝ𝑟. We call w the coefficient vector of P and use coeff𝑚,𝑘(𝑃) to denote this vector. When m, k are clear from context, we will simply use coeff(𝑃) instead of coeff𝑚,𝑘(𝑃).

Definition 11
(Linear Decision Trees) A Linear Decision Tree for a function 𝑓:ℝ𝑟→𝑆 (for some set S) is a decision tree where each internal node is labelled by a linear inequality, or query, of the form ∑𝑟𝑖=1𝑤𝑖𝑧𝑖≥𝜃 (here 𝑧1,…,𝑧𝑛 denote the input variables). Depending on the answer to this linear query, computation proceeds to the left or right child of this node, and this process continues until a leaf is reached, which is labelled with an element of S that is the output of f on the given input.

The following construction of linear decision trees from [19] will be crucial for us.

Theorem 12
There is a deterministic algorithm, which on input a positive integer r and a subset 𝐻⊆{−1,1}𝑟, produces a linear decision tree of depth Δ=𝑂(𝑟log2𝑟⋅log|𝐻|) that computes a function 𝐹:ℝ𝑟→{−1,1}|𝐻| and has the following properties.

1.
Each linear query has coefficients in {−2,−1,0,1,2}.

2.
Given as input any 𝑤∈ℝ𝑟 such that ⟨𝑤,𝑎⟩≠0 for all 𝑎∈{−1,1}𝑟, F(w) is the truth table of the LTF defined by w (with constant term 0) on inputs from 𝐻⊆{−1,1}𝑟.

Moreover, the algorithm runs in time 2𝑂(Δ).

Theorem 1.8 from [19] shows the existence of such a deterministic linear decision tree. However, as noted by an anonymous ITCS 2019 reviewer,Footnote12 their proof can in fact be slightly modified to yield an algorithm to construct it in the claimed running time. For completeness, we give a proof in “Appendix A”.

We will need a version of Theorem 12 for evaluating (tuples of) k-PTFs. It follows easily from Theorem 12.

Corollary 13
Fix positive constants k and c. Let 𝑟=∑𝑘𝑖=0(𝑚𝑖)=Θ(𝑚𝑘) denote the number of coefficients in a degree-k multilinear polynomial in m variables. There is a deterministic algorithm which on input positive integers m and ℓ≤𝑚𝑐 computes a function 𝐹:ℝ𝑟⋅ℓ→ℕ as follows: given as input any ℓ-tuple of coefficient vectors 𝑤⎯⎯⎯⎯⎯=(coeff𝑚,𝑘(𝑃1),…,coeff𝑚,𝑘(𝑃ℓ))∈ℝ𝑟⋅ℓ such that 𝑃𝑖(𝑎)≠0 for all 𝑎∈{−1,1}𝑚, 𝐹(𝑤⎯⎯⎯⎯⎯) is the number of common satisfying assignments to all the k-PTFs on {−1,1}𝑚 sign-represented by 𝑃1,…,𝑃ℓ. Further, the algorithm runs in time 2𝑂(Δ), where Δ=𝑂(ℓ⋅𝑚𝑘+1log2𝑚).

Proof
For each 𝑏∈{−1,1}𝑚, define eval𝑏∈{−1,1}𝑟 to be the vector of all evaluations of multilinear monomials of degree at most k, taken in lexicographic order, on the input b. Define 𝐻⊆{−1,1}𝑟 to be the set {eval𝑏 | 𝑏∈{−1,1}𝑚}. Clearly, |𝐻|≤2𝑚. Further, note that given any polynomial 𝑃(𝑥1,…,𝑥𝑚) of degree at most k, the truth table of the k-PTF sign-represented by P is given by the evaluation of the LTF represented by coeff(𝑃) at the points in H. Our aim, therefore, is to evaluate the LTFs corresponding to coeff(𝑃1),…,coeff(𝑃ℓ) at all the points in H.

For each i, we use the deterministic algorithm from Theorem 12 to produce a decision tree 𝑖 that evaluates the Boolean function 𝑓𝑖:{−1,1}𝑚→{−1,1} sign-represented by 𝑃𝑖 (or equivalently, evaluating the LTF corresponding to coeff(𝑃𝑖) at all points in H). Note that 𝑖 has depth 𝑂(𝑚𝑘log2𝑚⋅log(2𝑚))=𝑂(𝑚𝑘+1log2𝑚). The final tree  is obtained by simply running 1,…,ℓ in order, which is of depth 𝑂(ℓ⋅𝑚𝑘+1log2𝑚). Observe that the tree  outputs the number of common satisfying assignments to all the 𝑓𝑖.

The claim about the running time follows from the analogous claim in Theorem 12 and the fact that the number of common satisfying assignments to all the 𝑓𝑖 can be computed from the truth tables in 2𝑂(𝑚) time. This completes the proof. ◻

The #SAT algorithm
We are now ready to prove Theorem 4. We first state the algorithm, which follows a standard memoization idea (see, e.g. [29]). We assume that the input is a polynomial 𝑃∈ℤ[𝑥1,…,𝑥𝑛] of degree at most k that sign-represents a Boolean function f on n variables. The parameters of the instance are assumed to be (n, M) (recall from Definition 2 that 𝑀=𝑤(𝑃) is the bit-complexity of the sum of the absolute values of all the coefficients of P). Set 𝑚=𝑛1/(𝑘+1)/log𝑛.

Algorithm 

1.
Use the algorithm from Corollary 13 with ℓ=1 to construct a deterministic linear decision tree T such that on any input polynomial 𝑄(𝑥1,…,𝑥𝑚) (or more precisely coeff𝑚,𝑘(𝑄)) of degree at most k that sign-represents a k-PTF g on m variables, T computes the number of satisfying assignments to g.

2.
Set 𝑁=0 (N will ultimately be the number of satisfying assignments to f).

3.
For each setting 𝜎∈{−1,1}𝑛−𝑚 to the variables 𝑥𝑚+1,…,𝑥𝑛, do the following:

(a)
Compute the polynomial 𝑃𝜎 obtained by substituting the variables 𝑥𝑚+1,…,𝑥𝑛 accordingly in P.

(b)
Run T on coeff(𝑃𝜎) and compute its output 𝑁𝜎, the number of satisfying assignments to 𝑃𝜎. Add this to the current value of N.

4.
Output N.

Correctness It is clear from Corollary 13 (invoked for ℓ=1) and step 3b that algorithm  outputs the correct number of satisfying assignments to f.

Running time We show that the running time of algorithm  is poly(𝑛,𝑀)⋅2𝑛−𝑚. First note that by Corollary 13, the construction of a linear decision tree T takes 2𝑂(Γ) time, where Γ=𝑚𝑘+1log2𝑚, and hence, step 1 takes 2𝑂(Γ) time. Next, for a setting 𝜎∈{−1,1}𝑛−𝑚 to the variables 𝑥𝑚+1,…,𝑥𝑛, computing 𝑃𝜎 and constructing the vector coeff(𝑃𝜎) takes only poly(𝑛,𝑀) time. Recall that the depth of T is 𝑂(Γ) and thus, on input vector coeff(𝑃𝜎), each of whose entries has bit complexity at most M, it takes time 𝑂(Γ)⋅poly(𝑀,𝑛) to run T and obtain the output 𝑁𝜎. Therefore, step 3 takes poly(𝑛,𝑀)⋅2𝑛−𝑚 time. Finally, the claim about the total running time of algorithm  follows at once when we observe that for the setting 𝑚=(𝑛/log3𝑛)1/𝑘+1, Γ=𝑂(𝑛/log𝑛)=𝑜(𝑛).

#SAT for k-PTFs: the second algorithm
Here, we present an alternate approach to #SAT for k-PTFs. This approach uses memoization as before, but the idea now will be to first reduce the size of the coefficients, by going modulo small primes. A major hurdle with this is that PTFs use inequalities, which do not gel well with this operation. Hence, we will first transform our PTFs into a similar model which uses equalities, namely Exact Polynomial Threshold Functions.

Definition 14
(Exact Polynomial Threshold Functions [12, 13]) A Boolean function 𝐸:{−1,1}𝑛→{−1,1} is called an Exact Polynomial Threshold Function of degree 𝑘, or a 𝑘-EPTF, if there exists a multilinear polynomial 𝑃∈ℝ[𝑥1,…,𝑥𝑛] of degree 𝑘 such that for all 𝑎∈{−1,1}𝑛, 𝐸(𝑎)=−1 if and only if 𝑃(𝑎)=0. We refer to such a 𝑃 as a representation of 𝐸. When 𝑘=1, we call 𝐸 an Exact Threshold Function, or ETF for short.

The main idea in this algorithm is to first convert the given PTF to a disjoint OR of EPTFs. To do this, we follow Hofmeister [11], who showed how to do this for degree one. His proof is constructive and can easily be adapted to higher degrees.

Lemma 15
(Implicit in [11]) Let 𝑓:{−1,1}𝑛→{−1,1} be a 𝑘-PTF sign-represented by a polynomial 𝑃∈ℤ[𝑥1,…,𝑥𝑛] with parameters (𝑛,𝑀). Then it can be written as,

𝑓=⋁𝑖=1ℎ𝐸𝑖
where ℎ=𝑂(𝑀𝑛2𝑘) and each 𝐸𝑖 is a 𝑘-EPTF that can be represented by a degree k polynomial with weight 𝑂(𝑀+𝑘log𝑛).

Moreover, the OR is a disjoint OR i.e. at most one of the 𝐸𝑖s can evaluate to TRUE for a given input.

Finally, this transformation is constructive in the following sense. There is a deterministic algorithm running in poly(𝑛,𝑀) time that, on input an integer polynomial 𝑃∈ℤ[𝑥1,…,𝑥𝑛] with parameters (n, M) representing f, produces polynomials 𝑃1,…,𝑃ℎ of weight 𝑂(𝑀+𝑘log𝑛) where 𝑃𝑖 represents 𝐸𝑖 for each 𝑖∈[ℎ].

We include a proof of this lemma in “Appendix B” for completeness.

One of the bottlenecks to a brute force approach to satisfiability directly using this lemma is the size of the coefficients. For this reason, instead of evaluating an EPTF as is, we evaluate it modulo many small primes. We first define this modular version of EPTFs.

Definition 16
(modular EPTFs) Let 𝑃∈ℤ[𝑥1,…,𝑥𝑛] be any integer polynomial of degree at most k. For a prime p, we define the Boolean function 𝐸𝑝𝑃:{−1,1}𝑛→{−1,1} such that for all a, 𝐸𝑝𝑃(𝑎)=−1 if and only if 𝑃(𝑎)≡0mod𝑝.

We call such a Boolean function 𝐸𝑝𝑃 a p-modular k-EPTF.

Evaluating a polynomial modulo small enough primes will reduce the size of the coefficients but it will also introduce errors. However, if we evaluate modulo a random prime among sufficiently many primes, the error probability can be shown to be small. The underlying principle is the well-known Chinese Remainder Theorem, which we state below.

Theorem 17
(Chinese Remainder Theorem) Let {𝑝1,…,𝑝ℓ} be a set of distinct primes, and 𝑎∈ℤ. Then the following are equivalent:

for all 1≤𝑖≤ℓ, 𝑎≡0mod𝑝𝑖.

𝑎≡0mod∏ℓ𝑖=1𝑝𝑖.

In particular if 𝑎≠0 and 𝑎≡0(mod𝑝𝑖) for each 𝑖∈[ℓ], then ℓ≤log2|𝑎|.

Now we are ready to describe the algorithm in detail. The input, as earlier, will be a polynomial 𝑃∈ℤ[𝑥1,…,𝑥𝑛] of degree at most 𝑘 that sign-represents a Boolean function 𝑓 on 𝑛 variables. The parameters of the instance are taken to be (𝑛,𝑀). We assume that all monomials of the same degree are ordered among themselves using a predetermined ordering. One such ordering is the lexicographic ordering.

Algorithm 𝑝:

Set 𝑚=𝛿𝑛1/𝑘 and 𝐴=𝛽2𝑚 for a small enough constant 𝛿 and a large enough constant 𝛽.

1.
Using Lemma 15, decompose f as a disjoint OR of k-EPTFs

𝑓(𝑋)=⋁𝑖=1ℎ𝐸𝑖(𝑋).
Here ℎ=𝑂(𝑀𝑛2𝑘)=poly(𝑛,𝑀) and each 𝐸𝑖 is a 𝑘-EPTF represented by a degree-k polynomial 𝑃𝑖 with weight at most 𝑀′=𝑂(𝑀+log𝑛).

2.
We now describe the memoization step. For each prime 𝑝∈[1,𝑀′𝐴log(𝑀′𝐴)], we do the following. For each 𝑖∈[ℎ], consider all degree-k integer polynomials in 𝑥1,…,𝑥𝑚 such that the following holds.

The coefficients of the monomials with degree exactly 𝑘 are chosen by reducing the corresponding coefficients of the polynomial 𝑃𝑖 modulo p (to obtain a non-negative integer less than p).

The coefficients of the monomials of degree less than k are allowed to be any non-negative integers less than p. Let 𝑖,𝑝 be the set of all such polynomials.

Each polynomial 𝑄∈𝑖,𝑝 defines a p-modular k-EPTF 𝐸𝑝𝑄 of m variables. For each such Q, use brute force over all m input variables and count the number of satisfying assignments of 𝐸𝑝𝑄. Store the results in a table.

3.
Set 𝑁=0. (𝑁 will ultimately be the number of satisfying assignments to 𝑓).

4.
For each 𝜎:{𝑥𝑚+1,…,𝑥𝑛}→{−1,1}, for each 𝑖∈[ℎ], do the following. For each 𝑗∈[2𝑛], do the following.

(a)
Choose a uniformly random prime 𝑝𝑗∈[1,𝑀′𝐴log(𝑀′𝐴)].

(b)
Compute 𝑃𝑖,𝜎, the restriction of 𝑃𝑖 given by the partial assignment 𝜎. (Note that 𝑃𝑖,𝜎 is a polynomial in 𝑥1,…,𝑥𝑚. Further, since 𝑃𝑖 has degree at most k, the coefficient of any monomial of degree exactly k in 𝑃𝑖,𝜎 is the same as it is in 𝑃𝑖.)

(C)
Let Q be the polynomial in 𝑖,𝑝 obtained by reducing the coefficients of 𝑃𝑖 modulo 𝑝𝑗. Look up the number of satisfying assignments of 𝐸𝑝𝑗𝑄 in the table constructed in Step 2. Let this be 𝑁𝑖,𝜎,𝑗.

Arrange 𝑁𝑖,𝜎,1,…,𝑁𝑖,𝜎,2𝑛 in increasing order and let 𝑁𝑖,𝜎 be the smallest value. Add 𝑁𝑖,𝜎 to N.

5.
Output 𝑁.

We now prove Theorem 6 from the introduction. Note that Theorem 6 is trivial when 𝑀=2Ω(𝑛1/𝑘) since #SAT for k-PTFs can be solved in time poly(𝑛,𝑀)2𝑛 by a trivial brute-force algorithm. Hence, from now on, we assume that 𝑀≤2𝜀𝑛1/𝑘 for a suitably small constant 𝜀. The following statement now almost implies Theorem 6, except for the zero-error criterion.

Theorem 18
The following holds for large enough constant 𝛽 and small enough constants 𝜀,𝛿. 𝑝 is a randomized algorithm, which on input a polynomial 𝑃 of degree 𝑘 with parameters (𝑛,𝑀) with 𝑀≤2𝜀𝑛1/𝑘, outputs the number of satisfying assignments for 𝑓=sgn(𝑃) with probability 1−𝑜(1). The algorithm runs in time at most 2𝑛−Ω(𝑛1/𝑘).

Proof
Correctness Recall that f is decomposed as a disjoint OR of k-EPTFs 𝐸1,…,𝐸ℎ represented by polynomials 𝑃1,…,𝑃ℎ in Step 1. For any assignment 𝜎 considered in Step 4, we still have that the corresponding relation between the restrictions 𝑓𝜎 and 𝐸1,𝜎,…,𝐸ℎ,𝜎. It suffices to show that in Step 4, for each i and 𝜎, 𝑁𝑖,𝜎 equals the number of satisfying assignments of 𝐸𝑖,𝜎 with high probability.

To this end, we claim that for any restriction 𝜎 on the last 𝑛−𝑚 variables and any 𝑖∈[ℎ] the following holds.

Pr[𝑁𝑖,𝜎= number of satisfying assignments of 𝐸𝑖,𝜎]≥1−14𝑛
(1)
To show this we proceed as follows. Note that for each 𝑗∈[2𝑛], 𝑁𝑖,𝜎,𝑗 is equal to the number of 𝑎∈{−1,1}𝑚 such that 𝑃𝑖,𝜎(𝑎)≡0(mod𝑝𝑗). We call 𝑝𝑗 a bad prime for a if 𝑃𝑖,𝜎(𝑎) is non-zero but 𝑃𝑖,𝜎(𝑎)≡0(mod𝑝𝑗), i.e a is not a satisfying assignment of 𝐸𝑖,𝜎, but under the modulo operation, it gets counted as a satisfying assignment. Further, we say that 𝑝𝑗 is a bad prime if it is bad for some 𝑎∈{−1,1}𝑚, i.e. modulo 𝑝𝑗 some non-satisfying assignment gets counted as a satisfying assignment. Note that 𝑁𝑖,𝜎,𝑗 is always at least the number of satisfying assignments of 𝐸𝑖,𝜎, with equality occurring if 𝑝𝑗 is not a bad prime.

We now bound the probability that 𝑝𝑗 is a bad prime. Fix any 𝑎∈{−1,1}𝑚. As 𝑃𝑖 has weight at most 𝑀′, we have |𝑃𝑖,𝜎(𝑎)|≤2𝑀′. Using Theorem 17, the number of primes that are bad for a is bounded by 𝑀′. Hence the total number of bad primes is at most 𝑀′2𝑚. On the other hand, the total number of primes in the range [1,𝑀′𝐴log(𝑀′𝐴)] is at least Ω(𝑀′𝐴) by the Prime Number theorem. For a large enough constant 𝛽, this is at least 4𝑀′2𝑚. Thus, the probability that 𝑝𝑗 is a bad prime is at most 1/4.

Since 𝑁𝑖,𝜎 is the smallest of all the 𝑁𝑖,𝜎,𝑗 for 𝑗∈[2𝑛], we see that 𝑁𝑖,𝜎 is equal to the number of satisfying assignments of 𝐸𝑖,𝜎 unless every 𝑝𝑗 (𝑗∈[2𝑛]) is a bad prime. The probability of this is at most (1/4)𝑛. This proves (1).

By a union bound, the probability that there exist 𝜎 and i such that 𝑁𝑖,𝜎 is not equal to the number of satisfying assignments of 𝐸𝑖,𝜎 is at most ℎ2𝑛−𝑚/4𝑛=𝑂(𝑀𝑛2𝑘2𝑛−𝑚/4𝑛)=𝑜(1), where we have used the upper bound on M from the statement of the theorem. Hence with probability 1−𝑜(1), the algorithm correctly computes the number of satisfying assignments of 𝐸𝑖,𝜎 for each 𝜎,𝑖. In this case the algorithm correctly returns the number of satisfying assignments of f.

Running time The running time of the algorithm is dominated by the running times of Step 2 and Step 4.

In Step 2, the number of primes in the specified range is 𝑂(𝑀′2𝑚). For a given prime p and 𝑖∈[ℎ], the set 𝑖,𝑝 has size at most (𝑐1𝑀′2𝑚)𝑚𝑘−1 for some positive constant 𝑐1. Hence the number of modular 𝑘-EPTFs that are considered is at most 𝑂(ℎ𝑀′2𝑚)⋅(𝑐1𝑀′2𝑚)𝑚𝑘−1=2𝑂(𝑚𝑘+𝑚𝑘−1log𝑀′). For each such EPTF, it takes time 2𝑚⋅poly(𝑛,𝑀′)=2𝑚⋅poly(𝑛,𝑀) to brute force over all possible assignments. Hence the total time needed to execute this step is 2𝑂(𝑚𝑘+𝑚𝑘−1log𝑀′)⋅poly(𝑛,𝑀)≤2𝑛/2 for our choice of parameters and suitably small 𝜀,𝛿.

For Step 4, the total running time is 2𝑛−𝑚poly(𝑛,𝑀). Hence, for the given choice of parameters, and using 𝑀≤2𝜀𝑛1/𝑘 for suitably small 𝜀, the final running time is 2𝑛−Ω(𝑛1/𝑘). ◻

Making the algorithm zero-error The above almost implies Theorem 6 with the only exception being that the algorithm is not zero-error. However, there is a simple and elegant fix for this, as was pointed out to us by a anonymous reviewer.

Note that the above algorithm always returns an estimate that is at least the number of satisfying assignments of f, as the only source of error is when an non-satisfying assignment is incorrectly counted as a satisfying assignment at the time of computing 𝑁𝑖,𝜎 for some 𝑖∈[ℎ],𝜎∈{−1,1}𝑛−𝑚.

So, to get the zero-error algorithm, we proceed as follows. We run the above algorithm on polynomials P and −𝑃, which represent Boolean functions f and the negation of f respectively. The algorithm returns estimates 𝑁1 and 𝑁2, where 𝑁1≥𝑁𝑓 and 𝑁2≥𝑁¬𝑓 and 𝑁𝑔 denotes the number of satisfying assignments of g. Note that both inequalities are equalities precisely when 𝑁1+𝑁2=2𝑛, and this happens with probability 1−𝑜(1). Hence, the algorithm simply checks that 𝑁1+𝑁2=2𝑛 and returns 𝑁1 in this case. Otherwise, the algorithm returns ?.

Constant-depth circuits with PTF gates
In this section we give an algorithm for counting the number of satisfying assignments for a k-PTF circuit of constant depth and slightly superlinear size. We begin with some definitions.

Definition 19
Let 𝛿≤1 be any parameter. Two Boolean functions f, g are said to be 𝛿-close if Pr𝑥[𝑓(𝑥)≠𝑔(𝑥)]≤𝛿.

A k-PTF f specified by a polynomial P is said to be 𝛿-close to an explicit constant if it is 𝛿-close to a constant and such a constant can be computed efficiently, i.e. poly(𝑛,𝑀), where n is the number of variables in P and w(P) is at most M.

Definition 20
For a Boolean function 𝑓:{−1,1}𝑛→{−1,1}, the majority value of f is the bit value 𝑏∈{−1,1} which maximizes Pr𝑥[𝑓(𝑥)=𝑏] and the bit value −𝑏 is said to be its minority value.

For a Boolean function f with majority value b, an assignment 𝑥∈{−1,1}𝑛 is said to be a majority assignment if 𝑓(𝑥)=𝑏 and a minority assignment otherwise.

Definition 21
Given a k-PTF f on n variables specified by a polynomial P, a parameter 𝑚≤𝑛 and a partial assignment 𝜎∈{−1,1}𝑛−𝑚 on 𝑛−𝑚 variables, let 𝑃𝜎 be the polynomial obtained by substituting the variables in P according to 𝜎. If P has parameters (n, M) then 𝑃𝜎 has parameters (m, M). For a k-PTF circuit C, 𝐶𝜎 is defined similarly. If C has parameters (n, s, d, M) then 𝐶𝜎 has parameters (m, s, d, M).

Outline of the #SAT procedure For designing a #SAT algorithm for k-PTF circuits, we use the generic framework developed by Kabanets and Lu [18] with some crucial modifications.

Given a k-PTF circuit C on n variables of depth d we want to count the number of satisfying assignments 𝑎∈{−1,1}𝑛 such that 𝐶(𝑎)=−1. We in fact solve a slightly more general problem. Given (𝐶,), where C is a small k-PTF circuit of depth d and  is a set of k-PTF functions, such that ∑𝑓∈fan-in(𝑓) is small, we count the number of assignments that simultaneously satisfy C and all the function in .

At the core of the algorithm that solves this problem, Algorithm , is a recursive procedure 5, which works as follows: on inputs (𝐶,) it first applies a simplification step that outputs ≪2𝑛 instances of the form (𝐶′,′) such that

Both 𝐶′ and functions in ′ are on 𝑚≪𝑛 variables.

The sets of satisfying assignments of these instances “almost” partition the set of satisfying assignments of (𝐶,).

With all but very small probability the bottom layer of 𝐶′ has the following nice structure.

At most n gates are 𝛿-close to an explicit constant. We denote this set of gates by B (as we will simplify them by setting them to the constant they are close to).

At most 𝑛𝛽𝑑 gates are not 𝛿-close to an explicit constant. We denote these gates by G (as we will simplify them by “guessing” their values).

There is a small set of satisfying assignments that are not covered by the satisfying assignments of (𝐶′,′) but we can count these assignments with a brute-force algorithm that does not take too much time.

For each 𝐶′ with this nice structure, then we try to use this structure to create 𝐶″ which has depth 𝑑−1. Suppose we reduce the depth as follows:

Set all the gates in B to the values that they are biased towards.

Try all the settings of the values that the gates in G can take, thereby from 𝐶′ creating possibly 2𝑛𝛽𝑑 instances (𝐶″,′).

(𝐶″,′) now is an instance where 𝐶″ has depth 𝑑−1. Unfortunately, by simply setting biased gates to the values they are biased towards, we may miss out on the minority assignments to these gates which could eventually satisfy 𝐶′. We design a subroutine 3 to precisely handle this issue, i.e. to keep track of the number of minority assignments, say 𝑁𝐶′. This part of our algorithm is completely different from that of [18], which only works for subquadratically sparse PTFs.

Once 3 has computed 𝑁𝐶′, i.e. the number of satisfying assignments among the minority assignments, we now need to only count the number of satisfying assignments among the rest of the assignments.

To achieve this we use an idea similar to that in [7, 18], which involves appending ′ with a few more k-PTFs (this forces the biased gates to their majority values). This gives say a set ̃ ′. Similarly, while setting gates in G to their guessed values, we again use the same idea to ensure that we are counting satisfying assignments consistent with the guessed values, once again updating ̃ ′ to a new set ″. This creates instances of the form (𝐶″,″), where the depth of 𝐶″ is 𝑑−1.

This way, we iteratively decrease the depth of the circuit by 1. Finally, we have instances (𝐶″,″) such that the depth of 𝐶″ is 1, i.e. it is a single k-PTF, say h. At this stage we solve #SAT(𝐶̃ ), where 𝐶̃ =ℎ∧⋀𝑓∈″𝑓. This is handled in a subroutine 4. Here too our algorithm differs significantly from [18].

In what follows we will prove Theorem 9. In order to do so, we will set up various subroutines 1,2,3,4,5 designed to accomplish certain tasks and combine them together at the end to finally design algorithm  for the #SAT problem for k-PTF circuits.

1 will be an oracle, used in other routines, which will compute the number of common satisfying assignments for small AND of PTFs on few variables (using the same idea as in the algorithm for #SAT for k-PTFs). 2 will be a simplification step, which will allow us to argue about some structure in the circuit (this algorithm is from [18]). It will make many gates at the bottom of the circuit 𝛿-close to a constant, thus simplifying it. 3 will be used to count minority satisfying assignments for a bunch of PTFs that are 𝛿-close to an explicit constant, i.e. assignments which cause at least one of the PTFs to evaluate to its minority value. 4 will be a general base case of our algorithm, which will count satisfying assignments for AND of superlinearly many PTFs, by first using 2 to simplify the circuit, then reducing it to the case of small AND of PTFs and then using 1. 5 will be a recursive procedure, which will use 2 to first simplify the circuit, and then convert it into a circuit of lower depth, finally making a recursive call on the simplified circuit.

Parameter setting Let d be a constant. Let A, B be two fixed absolute large constants. Let 𝜁=min(1,𝐴/2𝐵𝑘2). For each 2≤𝑖≤𝑑, let 𝛽𝑖=𝐴⋅𝜀𝑖 and 𝜀𝑖=(𝜁10𝐴(𝑘+1))𝑖. Choose 𝛽1=1/10 and 𝜀1=1/10𝐴.

Oracle access to a subroutine Let 1(𝑛′,𝑠,𝑓1,…,𝑓𝑠) denote a subroutine with the following specification. Here, n is the number of variables in the original input circuit.

Input: AND of k-PTFs, say 𝑓1,…,𝑓𝑠 specified by polynomials 𝑃1,…,𝑃𝑠 respectively, such that 𝑠≤𝑛0.1 and for each 𝑖∈[𝑠], 𝑓𝑖 is defined over 𝑛′≤𝑛1/(2(𝑘+1)) variables and 𝑤(𝑃𝑖)≤𝑀.

Output: #{𝑎∈{−1,1}𝑛′∣∀𝑖∈[𝑠],𝑃𝑖(𝑎)=−1}.

In what follows, we will assume that we have access to the above subroutine 1. We will set up such an oracle and show that it answers any call to it in time poly(𝑛,𝑀) in Sect. 4.5.

Simplification of a k-PTF circuit
For any 1>𝜀≫(log𝑛)−1, let 𝛽=𝐴𝜀 and 𝛿=exp(−𝑛𝛽/𝐵⋅𝑘2), where A and B are constants. Note that it is these constants A, B we use in the parameter settings paragraph above. Let 2(𝐶,𝑑,𝑛,𝑀) be the following subroutine.

Input: k-PTF circuit C of depth d on n variables with size 𝑛1+𝜀 and weight M.

Output: A decision tree TDT which is a complete binary tree of depth 𝑛−𝑛1−2𝛽 such that for a uniformly random leaf 𝜎∈{−1,1}𝑛−𝑛1−2𝛽, the corresponding circuit 𝐶𝜎 is a good circuit with probability 1−exp(−𝑛𝜀), where 𝐶𝜎 is called good if its bottom layer has the following structure:

there are at most n gates which are 𝛿-close to an explicit constant. Let 𝐵𝜎 denote this set of gates.

there are at most 𝑛𝛽 gates that are not 𝛿-close to an explicit constant. Let us denote this set of gates by 𝐺𝜎.

In [18], such a subroutine 2(𝐶,𝑑,𝑛,𝑀) was designed. Specifically, they proved the following theorem.

Theorem 22
(Kabanets and Lu [18]) There is a zero-error randomized algorithm 2(𝐶,𝑑,𝑛,𝑀) that runs in time poly(𝑛,𝑀)⋅𝑂(2𝑛−𝑛1−2𝛽) and outputs a decision tree as described above with probability at least 1−1/210𝑛 (and outputs ? otherwise). Moreover, given a good 𝐶𝜎, there is a deterministic algorithm that runs in time poly(𝑛,𝑀) which computes 𝐵𝜎 and 𝐺𝜎.

Remark 23
In [18], it is easy to see that the probability of outputting ? is at most 1/2. To bring down this probability to 1/210𝑛, we run their procedure in parallel 10n times, and output the first tree that is output by the algorithm. The probability that no such tree is output is 1/210𝑛.

Remark 24
In designing the above subroutine in [18], they consider a more general class of polynomially sparse-PTF circuits (i.e. each gate computes a PTF with polynomially many monomials) as opposed to the k-PTF circuits we consider here. Under this weaker assumption, they get that 𝛿=exp(−𝑛Ω(𝛽3)). However, by redoing their analysis for degree k-PTFs, it is easy to see that 𝛿 could be set to exp(−𝑛𝛽/𝐵⋅𝑘2) for some constant B. Under this setting of 𝛿, we get exactly the same guarantees.

Further, while the statement of the result in [18] does not guarantee that the decision tree TDT obtained is a complete binary tree, it is easy to see that this follows from their analysis (and the analysis from [7] that is used as a black box).

In this sense, the above theorem statement is a slight restatement of [18, Lemma 11].

Enumerating the minority assignments
We now design an algorithm 3(𝑚,ℓ,𝛿,𝑔1,…,𝑔ℓ), which has the following behaviour.

Input: parameters 𝑚≤𝑛,ℓ,𝛿 such that 𝛿∈[exp(−𝑚1/10(𝑘+1)),1], ℓ≤𝑚2, k-PTFs 𝑔1,𝑔2,…,𝑔ℓ specified by polynomials 𝑃1,…,𝑃ℓ on m variables (𝑥1,…,𝑥𝑚) each of weight at most M and which are 𝛿-close to −1.

Oracle access to: 1.

Output: The set of all 𝑎∈{−1,1}𝑚 such that ∃𝑖∈[ℓ] for which 𝑃𝑖(𝑎)>0.

Lemma 25
There is a deterministic algorithm 3(𝑚,ℓ,𝛿,𝑔1,…,𝑔ℓ) as specified above that runs in time poly(𝑚,𝑀)⋅𝛿√⋅2𝑚.

Proof
We start with the description of the algorithm.

3(𝐦,ℓ,𝛿,𝐠1,…,𝐠ℓ)

1.
Set 𝑞=12log1𝛿≤𝑚2 and let =∅. ( will eventually be the collection of minority assignments i.e. all 𝑎∈{−1,1}𝑚 such that ∃𝑖∈[ℓ] for which 𝑃𝑖(𝑎)>0.)

2.
For each setting 𝜌∈{−1,1}𝑚−𝑞 to the variables 𝑥𝑞+1,…,𝑥𝑚, do the following:

(a)
Construct the restricted polynomials 𝑃1,𝜌,…,𝑃ℓ,𝜌. Let 𝑔𝑖,𝜌=sgn(𝑃𝑖,𝜌) for 𝑖∈[ℓ].

(b)
Using oracle 1(𝑞,1,−𝑔𝑖,𝜌), check for each 𝑖∈[ℓ] if 𝑔𝑖,𝜌 is the constant function −1 by checking if the output of the oracle on the input −𝑔𝑖,𝜌 is zero.

(c)
If there is an 𝑖∈[ℓ] such that 𝑔𝑖,𝜌 is not the constant function −1, try all possible assignments 𝜒 to the remaining q variables 𝑥1,…,𝑥𝑞. This way, enumerate all assignments 𝑏=(𝜒,𝜌) to 𝑥1,…,𝑥𝑚 for which there is an 𝑖∈[ℓ] such that 𝑃𝑖(𝑏)>0. Add such an assignment to the collection .

3.
Output .

Correctness If𝑎∈{−1,1}𝑚 is a minority assignment (i.e. ∃𝑖0∈[ℓ] so that 𝑃𝑖0(𝑎)>0) and if 𝑎=(𝜒,𝜌) where 𝜌 is an assignment to the last 𝑚−𝑞 variables, and 𝜒 to the first q, a will get added to  in the loop of step 2 corresponding to 𝜌 and that of 𝜒 in step 2c, because of 𝑖0 being a witness. Conversely, observe that we only add to the collection  when we encounter a minority assignment.

Running time For each setting 𝜌∈{−1,1}𝑚−𝑞 to the variables 𝑥𝑞+1,…,𝑥𝑚, step 2a takes poly(𝑚,𝑀) time and step 2b takes 𝑂(ℓ).poly(𝑚,𝑀)=poly(𝑚,𝑀) time and so combined, they take only poly(𝑚,𝑀) time. Let  be the set consisting of all assignments 𝜌 to the last 𝑚−𝑞 variables such that the algorithm enters the loop described in step 2c i.e.

={𝜌∈{−1,1}𝑚−𝑞|∃𝑖∈[ℓ]:𝑔𝑖,𝜌 is not the constant function−1}
and let 𝑐 denote its complement. Also note that for a 𝜌∈, enumeration of minority assignments in step 2c takes 2𝑞⋅ℓ⋅poly(𝑚,𝑀) time. Therefore, we can bound the total running time by

poly(𝑚,𝑀)(2𝑞⋅||+|𝑐|).
Next, we claim that the size of  is small:

Lemma 26
||≤ℓ⋅𝛿√⋅2𝑚−𝑞.

Proof
We define for 𝑖∈[ℓ], 𝑖={𝜌∈{−1,1}𝑚−𝑞|𝑔𝑖,𝜌 is not the constant function−1}. By the union bound, it is sufficient to show that |𝑖|≤𝛿√⋅2𝑚−𝑞 for a fixed 𝑖∈[ℓ]. Let 𝐷𝑚 denote the uniform distribution on {−1,1}𝑚 i.e. on all possible assignments to the variables 𝑥1,…,𝑥𝑚. Then from the definition of 𝛿-closeness, we know

Pr𝑎∼𝐷𝑚[𝑔𝑖(𝑎)=1]≤𝛿.
Writing LHS in the following way, we have


where 𝐷𝑚−𝑞 and 𝐷𝑞 denote uniform distributions on assignments to the last 𝑚−𝑞 variables and the first q variables respectively. By Markov’s inequality,

Pr𝜌∼𝐷𝑚−𝑞[Pr𝜒∼𝐷𝑞[𝑔𝑖,𝜌(𝜒)=1]≥𝛿√]≤𝛿√.
Consider a 𝜌 for which this event does not occur i.e. for which Pr𝜒∼𝐷𝑞[𝑔𝑖,𝜌(𝜒)=1]<𝛿√. For such a 𝜌, 𝑔𝑖,𝜌 has only 2𝑞=1/𝛿√ many inputs and therefore, 𝑔𝑖,𝜌 must be the constant function −1. Thus, we conclude that

Pr𝜌∼𝐷𝑚−𝑞[𝑔𝑖,𝜌 is not the constant function−1]≤𝛿√
or in other words, |𝑖|≤𝛿√⋅2𝑚−𝑞. ◻

Finally, by using the trivial bound |𝑐|≤2𝑚−𝑞 and the above claim, we obtain a total running time of poly(𝑚,𝑀)⋅𝛿√⋅2𝑚 and this concludes the proof of the lemma. ◻

#SAT for AND of k-PTFs
We design an algorithm 4(𝑛,𝑀,𝑔1,…,𝑔𝜏) with the following functionality.

Input: A set of k-PTFs 𝑔1,…,𝑔𝜏 specified by polynomials 𝑃1,…,𝑃𝜏 on n variables such that 𝑤(𝑝𝑖)≤𝑀 for each 𝑖∈[𝜏] and ∑𝑖∈[𝜏]fan-in(𝑔𝑖)≤𝑛1+𝜀1.

Oracle access to: 1,2.

Output: #{𝑎∈{−1,1}𝑛∣∀𝑖∈[𝜏],𝑃𝑖(𝑎)<0}.

The details of the algorithm
4(𝐧,𝐌,𝐠1,…,𝐠𝜏)

1.
Let 𝑚=𝑛𝛼 for 𝛼=𝜁𝜀12(𝑘+1). Let C denote the AND of 𝑔1,…,𝑔𝜏.

2.
Run 2(𝐶,2,𝑛,𝑀) to obtain the decision tree TDT. Initialize N to 0.

3.
For each leaf 𝜎 of TDT, do the following:

(A)
If 𝐶𝜎 is not good, count the number of satisfying assignments for 𝐶𝜎 by brute-force and add to 𝑁.

(B)
If 𝐶𝜎 is good, do the following:

(i)
𝐶𝜎 is now an AND of PTFs in 𝐵𝜎 and 𝐺𝜎, over 𝑛′=𝑛1−2𝛽1 variables, where all PTFs in 𝐵𝜎 are 𝛿-close to an explicit constant, where 𝛿=exp(−𝑛𝛽1/𝐵⋅𝑘2). Moreover, |𝐵𝜎|≤𝑛,|𝐺𝜎|≤𝑛𝛽1. Let 𝐵𝜎={ℎ1,…,ℎℓ} be specified by 𝑄1,…,𝑄ℓ. Suppose for 𝑖∈[ℓ], ℎ𝑖 is close to 𝑎𝑖∈{−1,1}. Then let 𝑄′𝑖=−𝑎𝑖⋅𝑄𝑖 and ℎ′𝑖=sgn(𝑄′𝑖). Let 𝐵′𝜎={𝑄′1,…,𝑄′ℓ}.

(ii)
For each restriction 𝜌:{𝑥𝑚+1,…,𝑥𝑛′}→{−1,1}, do the following:

(a)
Check if there exists ℎ′∈𝐵′𝜎 such that ℎ′𝜌 is not the constant function −1 using 1(𝑚,1,ℎ′𝜌).

(b)
If such an ℎ′∈𝐵′𝜎 exists, then count the number of satisfying assignments for 𝐶𝜎𝜌 by brute-force and add to 𝑁.

(c)
If the above does not hold, we have established that for each ℎ𝑖∈𝐵𝜎, ℎ𝑖,𝜌 is the constant function 𝑎𝑖. If ∃𝑖∈[ℓ] such that 𝑎𝑖=1, it means 𝐶𝜎𝜌 is also a constant 1 . Then simply halt. Else set each ℎ𝑖 to 𝑎𝑖. Thus, 𝐶𝜎𝜌 has been reduced to an AND of 𝑛𝛽1 many PTFs over 𝑚 variables. Call this set 𝐺′𝜎𝜌, use 1(𝑚,𝑛𝛽1,𝐺′𝜎𝜌) to calculate the number of satisfying assignments and add the output to 𝑁.

4.
Finally, output N.

The correctness argument and running time analysis
Lemma 27
4 is a zero-error randomized algorithm that counts the number of satisfying assignments correctly. Further, 4 runs in time poly(𝑛,𝑀)⋅𝑂(2𝑛−𝑛𝛼) and outputs the right answer with probability at least 1/2 (and outputs ? otherwise).

Proof
Correctness For a leaf 𝜎 of TDT, when 𝐶𝜎 is not good, we simply use brute-force, which is guaranteed to be correct. Otherwise,

If ℎ′𝜌 not the constant function −1 for some ℎ′∈𝐵′𝜎, then we again use brute-force, which is guaranteed to work correctly.

Otherwise, for each ℎ′∈𝐵′𝜎, ℎ′𝜌 is the constant function −1. Here we only need to consider the satisfying assignments for the gates in 𝐺𝜎𝜌. For this we use 1, that works correctly by assumption.

Further, we need to ensure that the parameters that we call 1 on, are valid. To see this, observe that 𝑚=𝑛𝛼≤𝑛1/(2(𝑘+1)) because of the setting of 𝛼 and further, we have 𝑛𝛽1≤𝑛0.1.

Finally, the claim about the error probability follows from the error probability of 2 (Theorem 22).

Running Time The time taken for constructing TDT is poly(𝑛,𝑀)⋅𝑂(2𝑛−𝑛1−2𝛽1), by Theorem 22. For a leaf 𝜎 of TDT, we know that step (A) is executed with probability at most 2−𝑛𝜀1. The total time for running step (A) is thus poly(𝑛,𝑀)⋅𝑂(2𝑛−𝑛𝜀1). We know that the oracle 1 answers calls in poly(𝑛,𝑀) time. Hence, the total time for running step (a) is poly(𝑛,𝑀)⋅𝑂(2𝑛−𝑛𝛼). Next, note that if step (b) is executed, then all PTFs in 𝐵𝜎 are 𝛿-close to −1. So, the number of times it runs is at most 𝛿⋅2𝑛′. Therefore, the total time for running step (b) is poly(𝑛,𝑀)⋅𝑂(2𝑛+𝑛𝛼−𝑛𝛽1/𝐵𝑘2). Recall that 𝜁=min(1,𝐴/2𝐵𝑘2), implying 𝛼=𝜁𝜀12(𝑘+1)=𝜁𝛽12𝐴(𝑘+1)≤𝛽14𝐵𝑘2(𝑘+1)<𝛽1𝐵𝑘2. Similar to the analysis of step (a), the total time for running step (c) is also poly(𝑛,𝑀)⋅𝑂(2𝑛−𝑛𝛼). We conclude that the total running time is poly(𝑛,𝑀)⋅𝑂(2𝑛−𝑛𝛼). This completes the proof.

#SAT for larger depth k-PTF circuits
Let C be a k-PTF circuit of depth 𝑑≥1 on n variables and let  be a set of k-PTFs 𝑔1,…,𝑔𝜏, which are specified by n-variate polynomials 𝑃1,…,𝑃𝜏. Let #SAT(𝐶,) denote #{𝑎∈{−1,1}𝑛∣𝐶(𝑎)<0 and ∀𝑖∈[𝜏],𝑃𝑖(𝑎)<0}. We now specify our depth-reduction algorithm 5(𝑛,𝑑,𝑀,𝑛1+𝜀𝑑,𝐶,).

Input: (𝐶,) as follows:

k-PTF circuit C with parameters (𝑛,𝑛1+𝜀𝑑,𝑑,𝑀).

a set  of k-PTFs 𝑔1,…,𝑔𝜏 on n variables, which are specified by polynomials 𝑃1,…,𝑃𝜏 such that ∑𝜏𝑖=1fan-in(𝑔𝑖)≤𝑛1+𝜀𝑑 and for each 𝑖∈[𝜏], 𝑤(𝑃𝑖)≤𝑀.

Oracle access to: 1,4.

Output: #SAT(𝐶,).

We start by describing the algorithm.

The details of the algorithm
Let count be a global counter initialized to 0 before the execution of the algorithm.

5(𝐧,𝐝,𝐌,𝐧1+𝜀𝐝,𝐂,)

1.
If 𝑑=1, output 4(𝑛,𝑀,{𝐶}∪) and halt.

2.
Run 2(𝐶,𝑑,𝑛,𝑀), which gives us a TDT. (If not, output ?.)

3.
For each leaf 𝜎∈{−1,1}𝑛−𝑛1−2𝛽𝑑 of TDT.

(a)
For each 𝑖∈[𝜏] compute 𝑃𝑖,𝜎, the polynomial obtained by substituting 𝜎 in its variables. Let 𝜎={𝑃1,𝜎,…,𝑃𝜏,𝜎}.

(b)
Obtain 𝐶𝜎. If 𝐶𝜎 is not a good circuit, then brute-force to find the number of satisfying assignments of (𝐶𝜎,𝜎), say 𝑁𝜎, and set 𝚌𝚘𝚞𝚗𝚝=𝚌𝚘𝚞𝚗𝚝+𝑁𝜎.

(c)
If 𝐶𝜎 is good then obtain 𝐵𝜎 and 𝐺𝜎.

(d)
Let 𝐵𝜎={ℎ1,…,ℎℓ} be specified by 𝑄1,…,𝑄ℓ. We know that each ℎ∈𝐵𝜎 is 𝛿-close to an explicit constant, for 𝛿=2−𝑛𝛽𝑑/𝐵𝑘2. Suppose for 𝑖∈[ℓ], ℎ𝑖 is close to 𝑎𝑖∈{−1,1}. Then let 𝑄′𝑖=−𝑎𝑖⋅𝑄𝑖 and ℎ′𝑖=sgn(𝑄′𝑖). Let 𝐵′𝜎={𝑄′1,…,𝑄′ℓ}.

(e)
Run 3(𝑛1−2𝛽𝑑,ℓ,𝛿,ℎ′1,…,ℎ′ℓ) to obtain the set 𝜎 of all the minority assignments of 𝐵𝜎. (Note that this uses oracle access to 1.) for each 𝑎∈𝜎, if ((𝐶(𝑎)<0) AND (∀𝑖∈[𝜏], 𝑃𝑖,𝜎(𝑎)<0)), then 𝚌𝚘𝚞𝚗𝚝=𝚌𝚘𝚞𝚗𝚝+1.

(f)
Let 𝐺𝜎={𝑓1,…,𝑓𝑡} be specified by polynomials 𝑅1,…,𝑅𝑡. We know that 𝑡≤𝑛𝛽𝑑. For each 𝑏∈{−1,1}𝑡,

i
Let 𝑅′𝑖=−𝑏𝑖⋅𝑅𝑖 for 𝑖∈[𝑡]. Let 𝐺′𝜎,𝑏={𝑅′1,…,𝑅′𝑡}.

ii
Let 𝐶𝜎,𝑏 be the circuit obtained from 𝐶𝜎 by replacing each ℎ𝑖 by 𝑎𝑖 1≤𝑖≤ℓ and each 𝑓𝑗 by 𝑏𝑗 for 1≤𝑗≤𝑡.

iii
𝜎,𝑏=𝜎∪𝐵′𝜎∪𝐺′𝜎,𝑏.

iv
If 𝑑>2 then run 5(𝑛1−2𝛽𝑑,𝑑−1,𝑀,𝑛1+𝜀𝑑,𝐶𝜎,𝑏,𝜎,𝑏) 𝑛1=10𝑛 times and let 𝑁𝜎 be the output of the first run that does not output ?. Set 𝚌𝚘𝚞𝚗𝚝=𝚌𝚘𝚞𝚗𝚝+𝑁𝜎. (If all runs of 5 output ?, then output ?.)

v
If 𝑑=2 then run 4(𝑛1−2𝛽𝑑,𝑀,𝐶𝜎,𝑏∪𝜎,𝑏) 𝑛1=10𝑛 times and let 𝑁𝜎 be the output of the first run that does not output ?. Set 𝚌𝚘𝚞𝚗𝚝=𝚌𝚘𝚞𝚗𝚝+𝑁𝜎. (If all runs of 5 output ?, then output ?.)

4.
Output count.

The correctness argument and running time analysis
Lemma 28
The algorithm 5 described above is a zero-error randomized algorithm which on input (𝐶,) as described above, correctly solves #SAT(𝐶,). Moreover, the algorithm outputs the correct answer (and not ?) with probability at least 1/2. Finally, 5(𝑛,𝑑,𝑀,𝑛1+𝜀𝑑,𝐶,∅) runs in time poly(𝑛,𝑀)⋅2𝑛−𝑛𝜁𝜀𝑑/2(𝑘+1), where parameters 𝜀𝑑,𝜁 are as defined at the beginning of Sect. 4.

Proof
We argue correctness by induction on the depth d of the circuit C.

Clearly, if 𝑑=1, correctness follows from the correctness of algorithm 4. This takes care of the base case.

If 𝑑≥2, we argue first that if the algorithm does not output ?, then it does output #SAT(𝐶,) correctly. Assume that the algorithm 2 outputs a decision tree TDT as required (otherwise, the algorithm outputs ? and we are done). Now, it is sufficient to argue that for each 𝜎, the number of satisfying assignments to (𝐶𝜎,𝜎) is computed correctly (if the algorithm does not output ?).

Fix any 𝜎. If 𝐶𝜎 is not a good circuit, then the algorithm uses brute-force to compute #SAT(𝐶𝜎,𝜎) which yields the right answer. So we may assume that 𝐶𝜎 is indeed good.

Now, the satisfying assignments to (𝐶𝜎,𝜎) break into two kinds: those that are minority assignments to the set 𝐵𝜎 and those that are majority assignments to 𝐵𝜎. The former set is enumerated in Step 3e (correctly by our analysis of 3) and hence we count all these assignments in this step.

Finally, we claim that the satisfying assignments to (𝐶𝜎,𝜎) that are majority assignments of all gates in 𝐵𝜎 are counted in Step 3f. To see this, note that each such assignment 𝑎∈{−1,1}𝑛1−2𝛽𝑑 forces the gates in 𝐺𝜎 to some values 𝑏1,…,𝑏𝑡∈{−1,1}. Note that for each such 𝑏∈{−1,1}𝑡, these assignments are exactly the satisfying assignments of the pair (𝐶𝜎,𝑏,𝜎,𝑏) as defined in the algorithm. In particular, the number satisfying assignments to (𝐶𝜎,𝜎) that are majority assignments of all gates in 𝐵𝜎 can be written as

∑𝑏∈{−1,1}𝑡# SAT(𝐶𝜎,𝑏,𝜎,𝑏).
We now want to apply the induction hypothesis to argue that all the terms in the sum are computed correctly. To do this, we need to argue that the size of 𝐶𝜎,𝑏 and the total fan-in of the gates in 𝜎,𝑏 are bounded as required (note that the total size of C remains the same, while the total fan-in of  increases by the total fan-in of the gates in 𝐵′𝜎∪𝐺′𝜎,𝑏 which is at most 𝑛1+𝜀𝑑). It can be checked that this boils down to the following two inequalities

𝑛(1−2𝛽𝑑)(1+𝜀𝑑−1)≥𝑛1+𝜀𝑑 and 𝑛(1−2𝛽𝑑)(1+𝜀𝑑−1)≤2𝑛1+𝜀𝑑
both of which are easily verified for our choice of parameters (for large enough n). Thus, by the induction hypothesis, all the terms in the sum are computed correctly (unless we get ?). Hence, the output of the algorithm is correct by induction.

Now, we analyze the probability of error. If 𝑑=1, the probability of error is at most 1/2 by the analysis of 4. If 𝑑>2, we get an error if either 2 outputs ? or there is some 𝜎 such that the corresponding runs of 5 or 4 output ?. The probability of each is at most 1/210𝑛. Taking a union bound over at most 2𝑛 many 𝜎, we see that the probability of error is at most 1/2Ω(𝑛)≤1/2.

Finally, we analyze the running time. Define (𝑛,𝑑,𝑀) to be the running time of the algorithm on a pair (𝐶,) as specified in the input description above. We need the following claim.

Lemma 29
(𝑛,𝑑,𝑀)≤poly(𝑛,𝑀)⋅2𝑛−𝑛𝜁𝜀𝑑/2(𝑘+1).

To see the above, we argue by induction. The case 𝑑=1 follows from the running time of 4. Further from the description of the algorithm, we get the following inequality for 𝑑≥2.

(𝑛,𝑑,𝑀)≤poly(𝑛,𝑀)⋅(2𝑛−𝑛1−2𝛽𝑑+2𝑛−𝑛𝜀𝑑+2𝑛−12⋅𝑛𝛽𝑑/(𝐵𝑘2)+2𝑛−𝑛(1−2𝛽𝑑)𝜁𝜀𝑑−1/2(𝑘+1))
(2)
The first term above accounts for the running time of 2 and all steps other than Steps 3b, 3e and 3f. The second term accounts for the brute force search in Step 3b since there are only a 2−𝑛𝜀𝑑 fraction of 𝜎 where it is performed. The third term accounts for the minority enumeration algorithm in Step 3e (running time follows from the running time of that algorithm). The last term is the running time of Step 3f and follows from the induction hypothesis.

It suffices to argue that each term in the RHS of (2) can be bounded by 2𝑛−𝑛𝜁𝜀𝑑/2(𝑘+1). This is an easy verification from our choice of parameters and left to the reader. This concludes the proof. ◻

Putting it together
In this subsection, we complete the proof of Theorem 9 using the aforementioned subroutines. We also need to describe the subroutine 1, which is critical for all the other subroutines. We shall do so inside our final algorithm for the #SAT problem for k-PTF circuits, algorithm . Recall that 1 has the following specifications:

Input: AND of k-PTFs, say 𝑓1,…,𝑓𝑠 specified by polynomials 𝑃1,…,𝑃𝑠 respectively, such that 𝑠≤𝑛0.1 and for each 𝑖∈[𝑠], 𝑓𝑖 is defined over 𝑛′≤𝑛1/(2(𝑘+1)) variables and 𝑤(𝑃𝑖)≤𝑀.

Output: #{𝑎∈{−1,1}𝑛′∣∀𝑖∈[𝑠],𝑓𝑖(𝑎)=−1}.

We are now ready to complete the proof of Theorem 9. Suppose C is the input k-PTF circuit with parameters (𝑛,𝑛1+𝜀𝑑,𝑑,𝑀). On these input parameters (𝐶,𝑛,𝑛1+𝜀𝑑,𝑑,𝑘,𝑀), we finally have the following algorithm for the #SAT problem for k-PTF circuits:

(𝐂,𝐧,𝐧1+𝜀𝐝,𝐝,𝐤,𝐌)

1.
(Oracle Construction Step) Construct the oracle 1 as follows. Use the algorithm from Corollary 13, with ℓ chosen to be 𝑛0.1 and m to be 𝑛1/2(𝑘+1), to construct a deterministic linear decision tree T such that on any input 𝑤⎯⎯⎯⎯⎯=(coeff𝑚,𝑘(𝑄1),…,coeff𝑚,𝑘(𝑄ℓ))∈ℝ𝑟⋅ℓ (where 𝑄𝑖s are polynomials of degree at most k that sign-represent k-PTFs 𝑔𝑖, each on m variables), T computes the number of common satisfying assignments to 𝑔1,…,𝑔ℓ.

2.
Run 5(𝑛,𝑑,𝑀,𝑛1+𝜀𝑑,𝐶,∅). For an internal call to 1, say on parameters (𝑛′,𝑠,𝑓1,…,𝑓𝑠) where 𝑛′≤𝑚 and 𝑠≤ℓ, run T on the input 𝑤⎯⎯⎯⎯⎯=(coeff𝑛′,𝑘(𝑃1),…,coeff𝑛′,𝑘(𝑃𝑠))∈ℝ𝑟⋅𝑠. (We expand out the coefficient vectors with dummy variables so that they depend on exactly m variables. Similarly, using some dummy polynomials, we can assume that there are exactly ℓ polynomials.)

Lemma 30
The construction of the oracle 1 in the above algorithm takes 2𝑂(𝑛0.6) time. Once constructed, the oracle 1 answers any call (with valid parameters) in poly(𝑛,𝑀) time.

Proof
Substituting the parameters ℓ=𝑛0.1 and 𝑚=𝑛1/(2(𝑘+1)) in Corollary 13, we see that the construction of 1 (step 1) takes 2𝑂(𝑛0.6log2𝑛) time. Also, the claimed running time of answering a call follows from the bound on the depth of T given by the proof of Corollary 13. ◻

With the correctness of 1 now firmly established, we finally argue the correctness and running time of algorithm .

Correctness The correctness of  follows from that of 1,2,3,4, and 5 (see Lemma 30, Theorem 22, Lemmas 25, 27, and 28 respectively). From the analysis of 5, we see th