We study a security game over a network played between a defender and k attackers. Every attacker chooses, probabilistically, a node of the network to damage. The defender chooses, probabilistically as well, a connected induced subgraph of the network of 𝜆 nodes to scan and clean. Each attacker wishes to maximize the probability of escaping her cleaning by the defender. On the other hand, the goal of the defender is to maximize the expected number of attackers that she catches. This game is a generalization of the model from the seminal paper of Mavronicolas et al. Mavronicolas et al. (in: International symposium on mathematical foundations of computer science, MFCS, pp 717–728, 2006). We are interested in Nash equilibria of this game, as well as in characterizing defense-optimal networks which allow for the best equilibrium defense ratio; this is the ratio of k over the expected number of attackers that the defender catches in equilibrium. We provide a characterization of the Nash equilibria of this game and defense-optimal networks. The equilibrium characterizations allow us to show that even if the attackers are centrally controlled the equilibria of the game remain the same. In addition, we give an algorithm for computing Nash equilibria. Our algorithm requires exponential time in the worst case, but it is polynomial-time for 𝜆 constantly close to 1 or n. For the special case of tree-networks, we further refine our characterization which allows us to derive a polynomial-time algorithm for deciding whether a tree is defense-optimal and if this is the case it computes a defense-optimal Nash equilibrium. On the other hand, we prove that it is 𝙽𝙿-hard to find a best-defense strategy if the tree is not defense-optimal. We complement this negative result with a polynomial-time constant-approximation algorithm that computes solutions that are close to optimal ones for general graphs. Finally, we provide asymptotically (almost) tight bounds for the Price of Defense for any 𝜆; this is the worst equilibrium defense ratio over all graphs.

Introduction
With technology becoming a ubiquitous and integral part of our lives, we find ourselves using several different types of computer networks. An important issue when dealing with such networks, which are often prone to security breaches [6], is to prevent and monitor unauthorized access and misuse of the network or its accessible resources. Therefore, the study of network security has attracted a lot of attention over the years [18]. Unfortunately, such breaches are often inevitable, since some parts of a large system are expected to have weaknesses that expose them to security attacks; history has indeed shown several successful and highly-publicized such incidents [17]. Therefore, the challenge for someone trying to keep those systems and networks of computers secure is to counteract these attacks as efficiently as possible, once they occur.

To that end, inventing and studying appropriate theoretical models that capture the essence of the problem is an important line of research, ongoing for a few years now [13, 14]. Here, extending some known models for very simple cases of attacks and defenses [11, 12], we introduce and analyze a more general model for a scenario of network attacks and defenses modeling it as a defense game.

The Network Security Game
We follow the terminology established by the seminal paper of Mavronicolas et al. [11]. We consider a network whose nodes are vulnerable to infection by threats called attackers; think of those as viruses, worms, Trojan horses or eavesdroppers [7] infecting the components of a computer network. Available to the network is a security software (or firewall), called the defender. The defender is only able to “clean” a limited part of the network from threats that occur; the reason for the limited cleaning capacity of the defender may be, for example, the cost of purchasing a global security software. The defender seeks to protect the network as much as possible, and on the other hand, every attacker seeks to increase the likelihood of not being caught. Both the attackers and the defender make individual decisions for their positioning in the network with the aim to maximize their own objectives.

Every attacker targets (and attacks) a node chosen via her own probability distribution over the nodes of the network. The defender cleans a connected induced subgraph of the network with size 𝜆, chosen via her own probability distribution over all connected induced subgraphs of the graph with 𝜆 nodes. The attack of a particular attacker is successful unless the node chosen by the attacker is incident to an edge (link) being cleaned by the defender, i.e. to an edge belonging in the induced subgraph chosen by the defender. One could equivalently think of the defender selecting a set of 𝜆 connected nodes to defend, and an attacker is successful if and only if she attacks a node that is not being defended. Since attacks and defenses over a large computer network are self-interested procedures that seek to maximize damage and protection, respectively, it is natural to model this network security scenario as a non-cooperative strategic game on graphs with two kinds of players: 𝑘≥1 attackers, each playing a vertex of the graph, and a single defender playing a connected induced subgraph of the graph. The (expected) payoff of an attacker is the probability that she is not caught by the defender; the (expected) payoff of the defender is the (expected) number of attackers she catches. We are interested in the Nash equilibria [15, 16] associated with this graph theoretic game, where no player can unilaterally improve her (expected) payoff by switching to another probability distribution. We are also interested in understanding and characterizing the networks that allow for a good defense ratio: given a strategy profile, i.e. a combination of strategies for the network entities (attackers and defender), the defense ratio of a network is the ratio of the total number of attackers over the defender’s expected payoff in that strategy profile.

Our Results
In this work we depart from and significantly extend the line of work of Mavronicolas et al. in their seminal paper [11] on defense games in graphs; we term the type of games we consider Connected Subgraph Defense (CSD) games. In our model the defender is more powerful than in [11,12,13,14], since her power is parameterized by the size, 𝜆, of the defended part of the network. We allow 𝜆 to take values from 1 to n, while in [11,12,13,14] only the case where 𝜆=2 was studied. We study many questions related to CSD games. We extend the notions of defense ratio and defense-optimal graphs for CSD games. In fact, the defense ratio of a given graph G and a given strategy profile S of the attackers and the defender is the ratio of the number of attackers, k, over the defender’s expected payoff (the number of attackers she catches on expectation). We thoroughly investigate the notion of the defense ratio for Nash equilibria strategy profiles.

Firstly, we precisely characterize the Nash equilibria and defense-optimal graphs in CSD games. This allows us to show that, in equilibrium, the game version of k uncoordinated attackers and a single defender is equivalent to the version in which a single leader coordinates the k attackers; meaning that both versions of the game have the exact same equilibria and defense ratio. We present an LP-based algorithm to compute an exact equilibrium of any given CSD game, whose running time is polynomial in (𝑛𝜆). Then, we focus on tree-graphs. There, we further refine our equilibrium characterization which allows us to derive a polynomial-time algorithm for deciding whether a tree is defense-optimal and, if this is the case, it computes a defense-optimal Nash equilibrium. A tree is defense-optimal if and only if it can be partitioned into 𝑛𝜆 disjoint sub-trees. On the other hand, we prove that it is 𝙽𝙿-hard to find a best-defense strategy if the tree is not defense-optimal.

We remark that a very crucial parameter for defense-optimality of a graph G is the “best” probability with which any vertex of G is defended in a NE; we call that probability MaxMin probability and denote it by 𝑝∗(𝐺). Then, for any graph G, the defense ratio in equilibrium is shown to be exactly 1𝑝∗(𝐺). Although it is hard to exactly compute 𝑝∗(𝐺) even for trees, we complement this negative result with a polynomial-time constant-approximation algorithm that computes solutions that are close to the optimal ones for any 𝜆, for any given general graph. In particular, we approximate the (best) defense ratio of any graph within a factor of 2+𝜆−3𝑛. Finally, we provide asymptotically tight bounds for the Price of Defense for any 𝜆∈𝜔(1)∩𝑜(𝑛), and almost tight bounds for any other value of 𝜆.

Related Work
Our graph-theoretic game is a direct generalization of the defense game considered by Mavronicolas et al. [11,12,13,14].

In the latter, the authors examined the case where the size of the defended part of the network is 𝜆=2, i.e. where the defender “cleans” an edge. This leads to a nice connection between equilibria and (fractional) matchings in the graph [13]. But when 𝜆 is greater than 2, one has to investigate (as we shall see here) how to sparsely cover the graph by as small a number as possible of connected induced subgraphs of size 𝜆. This direction can be seen as an extension of fractional matchings that cover the graph by equisized connected subgraphs. Sparse covering of graphs by connected induced subgraphs (clusters), not necessarily equisized, is a notion known to be useful also for distributed algorithms, since it affects message communication complexity [5].

In another line of work, Kearns and Ortiz [9] study Interdependent Security games in which a large number of players must make individual decisions regarding security. Each player’s safety may depend on the actions of the entire population (in a complex way). The graph-theoretic game that we consider could be seen as a particular instance of such games with some sort of limited interdependence: the actions of the defender and an attacker are interdependent, while the actions of the attackers are not dependent on each other.

Aspnes et al. [4] consider a graph-theoretic game that models containment of the spread of viruses on a network; each node individually must choose to either install anti-virus software at some cost, or risk infection if a virus reaches it without being stopped by some intermediate node with installed anti-virus software. Aspnes et al. [4] prove several algorithmic properties for their graph-theoretic game and establish connections to a certain graph-theoretic problem called Sum-of-Squares Partition.

A game on a weighted graph with two players, the tree player and the edge player, was studied by Alon et al. [2]. At each play, the tree player chooses a spanning tree and the edge player chooses an edge of the graph, and the payoffs of the players depend on whether the chosen edge belongs in the spanning tree. Alon et al. investigate the theoretical aspects of the above game and its connections to the k-server problem and network design.

Finally, there is a long line of work on security games [3] where many scenarios are modelled using graph theoretic problems [8, 10, 19, 20].

Preliminaries
The game
A Connected Subgraph Defense (CSD) game is defined by a graph 𝐺=(𝑉,𝐸), a defender, 𝑘≥1 attackers, and a positive integer 𝜆. Throughout the paper, 𝜆 is considered to be a given parameter of the game. A pure strategy for the defender is any induced connected subgraph H of G with 𝜆 vertices, which we term 𝜆-subgraph. For any 𝜆-subgraph H of G we denote V(H) its set of vertices. Since V(H) uniquely defines an induced subgraph of G, we will use the term 𝜆-subgraph to denote either V(H) or H. The action set of the defender is 𝐷:={𝑉(𝐻)|𝐻 is a 𝜆-subgraph of 𝐺} and we will denote its cardinality by 𝜃, i.e. 𝜃:=|𝐷|. For ease of presentation, we will also refer to D as [𝜃]:={1,2,…,𝜃}. A pure strategy for each of the attackers is any vertex of G. So, the action set of every attacker is V, the vertex set of G; we denote 𝑛:=|𝑉| and we similarly refer to V also as [n].

To play the game, the defender chooses a defense (mixed) strategy, i.e. a probability distribution over her action set, and each attacker chooses an attack (mixed) strategy, i.e. a probability distribution over the vertices of G. We denote a strategy by 𝑠:=(𝑠1,…,𝑠𝑑)∈𝛥𝑑, i.e. by the probability distribution over d enumerated pure strategies, where 𝛥𝑑:={𝑥1,…,𝑥𝑑≥0|∑𝑑𝑖=1𝑥𝑖=1} is the (𝑑−1)-unit simplex. In a defense strategy 𝑞∈𝛥𝜃, each pure strategy 𝑗∈[𝜃] is assigned a probability 𝑞𝑗.

We say that a pure strategy of the defender, i.e. a specific 𝜆-subgraph H of G, covers a vertex 𝑣∈𝑉, if 𝑣∈𝑉(𝐻). A defense strategy covers a vertex 𝑣∈𝑉 if it assigns strictly positive probability to at least one 𝜆-subgraph H of G which contains v.

Definition 1
(vertex-probability) The vertex-probability 𝑝𝑖 of vertex 𝑖∈[𝑛], is the probability that i will be covered, formally  𝑝𝑖:=∑𝑗∈[𝜃]:𝑖∈𝑗𝑞𝑗.

Payoffs and Strategy profiles. A strategy profile is a tuple of strategies 𝑆=(𝑞,𝑡1,…,𝑡𝑘), where q denotes the defender’s strategy and 𝑡𝑗 denotes the j-th attacker’s strategy, 𝑗∈[𝑘]. A strategy profile is pure if the support of every strategy has size one. The payoff of every attacker is 1 in any pure strategy profile where she does not choose a defended vertex, and 0 in all the rest. The payoff of the defender in a pure strategy profile where she defends V(H), is the number of attackers that choose a vertex in V(H). Under a strategy profile, the expected payoff of the defender is the expected number of attackers that she catches, which we call defense value, and the expected payoff of the attacker is the probability that she will not get caught. A best response strategy for a participant is a strategy that maximizes her expected payoff, given that the strategies of the rest of the participants are fixed. A Nash equilibrium is a strategy profile where all the participants are playing a best response strategy. In other words, neither the defender nor any of the attackers can increase their expected payoff by unilaterally changing their strategy.

Definition 2
(Defense ratio) For a given graph G we define a measure of the quality of a strategy profile S, called defense ratio of G and denoted DR(𝐺,𝑆), as the ratio of the total number of attackers k over the defense value.

In this work we are only interested in the cases where S is an equilibrium. For a given graph, when in equilibrium, the defender’s expected payoff is unique (due to Corollary 1 (a)) and achieves the equilibrium defense ratio DR(𝐺,𝑆∗), where 𝑆∗ is an equilibrium. The defense strategy in 𝑆∗ which achieves this defense ratio will be termed best-defense strategy.

Definition 3
(MaxMin probability, 𝑝∗) We call MaxMin Probability of a graph G the maximum, over all defense strategies, minimum vertex-probability in G, that is:

𝑝∗(𝐺):=max𝑞∈𝛥𝜃min𝑖∈[𝑛]𝑝𝑖.
As we will show in Lemma 1, the equilibrium defense ratio of a graph G turns out to be DR(𝐺,𝑆∗)=1/𝑝∗(𝐺).

Definition 4
(Price of defense) The Price of Defense, PoD, for a given parameter 𝜆 of the game, is the worst defense ratio, over all graphs on n vertices, achievable in equilibrium, that is:

PoD(𝜆)=sup𝐺DR(𝐺,𝑆∗).
Definition 5
(Defense-optimal graph) For a given 𝜆, a graph 𝐺∗ that achieves the minimum equilibrium defense ratio over all graphs on n vertices, i.e. 𝐺∗∈{𝐺′ | |𝑉(𝐺′)|=𝑛,DR(𝐺′,𝑆∗)≤DR(𝐺″,𝑆∗), for all 𝐺″ with |𝑉(𝐺″)|=𝑛}, is called defense-optimal graph.

In the following, for ease of presentation, whenever we refer to defense optimality, we implicitly assume that 𝜆 has a fixed value.

Nash Equilibria
In this section, we provide a characterization of Nash equilibria in CSD games, as well as important properties of their structure, which turn out to be useful for the development of our algorithms in the remainder of the paper.

Theorem 1
(Equilibrium characterization) For a given graph G, in any equilibrium with support 𝑆⊆[𝜃] of the defender and support 𝑇𝑗⊆[𝑛] of each attacker 𝑗∈[𝑘], the following conditions are necessary and sufficient:

1.
min𝑖∈[𝑛]𝑝𝑖 is maximized over all defense strategies, and

2.
⋃𝑗∈[𝑘]𝑇𝑗⊆𝑉∗, where 𝑉∗:={𝑖|min𝑖∈[𝑛]𝑝𝑖 is maximized over all defense strategies}, and

3.
every 𝑠∈𝑆 has the maximum expected total number of attackers on its vertices over all pure strategies.

Proof
First we will prove that the conditions in the statement of the theorem hold in equilibrium, i.e. equilibrium is sufficient for the conditions to hold.

Condition 1 By definition, in an equilibrium, the defender and each attacker have chosen a best response. Suppose that the defender has chosen some strategy 𝑞=(𝑞1,𝑞2,…,𝑞𝜃) over her action set [𝜃]; we will consider this strategy to be a vector variable for now. Given q, each vertex 𝑖∈[𝑛] has a vertex-probability 𝑝𝑖. Now consider the minimum vertex-probability 𝑝′:=min𝑖∈[𝑛]𝑝𝑖, and the set 𝑉′⊆𝑉 consisting of the vertices with vertex-probability 𝑝′, i.e. 𝑉′:={𝑖∈𝑉 | 𝑝𝑖=𝑝′}. Since an attacker plays a best response, her support will be a subset of 𝑉′; otherwise, if she assigns probability 𝑡𝑣>0 on a vertex 𝑣∉𝑉′ (with 𝑝𝑣>𝑝′) her expected payoff (see quantity (2)) can be strictly increased by choosing to move all of 𝑡𝑣 to another vertex 𝑢∈𝑉′, thus increasing her expected payoff by 𝑡𝑢⋅(𝑝𝑣−𝑝′). Therefore, every attacker’s support will be a subset of 𝑉′.

We will denote by 𝑡𝑗𝑖 the probability that the strategy of attacker 𝑗∈[𝑘] has assigned to vertex 𝑖∈[𝑛]. The expected payoff of the defender is:

∑𝑖∈[𝑛](𝑝𝑖∑𝑗∈[𝑘]𝑡𝑗𝑖).
(1)
Since as we argued above, in an equilibrium, each attacker’s strategy has support that is a subset of 𝑉′, the expected payoff of the defender will be

∑𝑖∈𝑉′(𝑝𝑖∑𝑗∈[𝑘]𝑡𝑗𝑖)+∑𝑖∈𝑉∖𝑉′(𝑝𝑖∑𝑗∈[𝑘]𝑡𝑗𝑖)=𝑝′⋅∑𝑖∈𝑉′(∑𝑗∈[𝑘]𝑡𝑗𝑖)=𝑝′⋅∑𝑗∈[𝑘]⎛⎝⎜⎜∑𝑖∈𝑉′𝑡𝑗𝑖⎞⎠⎟⎟=𝑝′⋅𝑘,
where the first equality is due to the fact that 𝑝𝑖=𝑝′, ∀𝑖∈𝑉′ and 𝑡𝑗𝑖=0, ∀𝑖∈𝑉∖𝑉′, and the last equality is due to the fact that the support of any strategy 𝑡𝑗=(𝑡𝑗1,…,𝑡𝑗𝑖) of an attacker 𝑗∈[𝑘] is a subset of 𝑉′. It is important to note here that the entire probability mass of each of the attackers is placed on vertices with minimum vertex-probability 𝑝′. So, according to the definition of the defender’s expected payoff, i.e., the expected number of attackers that are caught by the defender, this will be equal to 𝑝′⋅𝑘. Furthermore, in an equilibrium, the defender also plays a best response, i.e. she maximizes her expected payoff. Thus, given the above quantity, the defender in an equilibrium has expected payoff max𝑞∈𝛥𝜃𝑝′⋅𝑘, and Condition 1 of the theorem’s statement is satisfied.

Condition 2 The proof is by contradiction. Assume an equilibrium profile where the defender has strategy 𝑞=(𝑞1,…,𝑞𝜃) and there is an attacker, a, with strategy 𝑡=(𝑡1,…,𝑡𝑛) whose support includes vertex 𝑣∈[𝑛] with 𝑝𝑣>𝑝′, where 𝑝′:=min𝑖∈[𝑛]𝑝𝑖. Then a’s expected payoff is

∑𝑖∈𝑉∖{𝑣}𝑡𝑖(1−𝑝𝑖)+𝑡𝑣(1−𝑝𝑣).
(2)
However, a can increase her expected payoff by moving all her probability 𝑡𝑣 to a vertex 𝑣′ for which 𝑝𝑣′=𝑝′, which contradicts the equilibrium assumption.

Condition 3 The proof is by contradiction. Suppose that in an equilibrium the defender has strategy 𝑞∗∈𝛥𝜃, where supp(𝑞∗):=𝑆. According to Condition 1, this strategy achieves 𝑝∗(𝐺). Let us define the set

𝑉∗:={𝑖∈[𝑛] | min𝑖∈[𝑛]𝑝𝑖 is maximized over all defense strategies}.
We denote by 𝑁𝑖 the random variable that indicates the number of attackers on vertex 𝑖∈[𝑛], under the strategy profile determined by the strategy of the defender and each attacker. The expected payoff of the defender according to Eq. (1) is ∑𝑖∈[𝑛](𝑝𝑖⋅𝔼[𝑁𝑖]). Since, as argued above, in an equilibrium each attacker has support in 𝑉∗, the defender’s expected payoff is in fact 𝑝∗⋅∑𝑖∈𝑉∗𝔼[𝑁𝑖].

For the sake of contradiction, suppose that for the expected total number of attackers on two different pure defense strategies 𝑠1∈𝑆 and 𝑠2∈[𝜃] it holds that 𝔼[∑𝑖∈𝑠1𝑁𝑖]<𝔼[∑𝑗∈𝑠2𝑁𝑗], and equivalently 𝔼[∑𝑖∈𝑠1∖𝑠2𝑁𝑖]<𝔼[∑𝑗∈𝑠2∖𝑠1𝑁𝑗]. Then, the expected payoff of the defender can be strictly increased if she chooses a strategy 𝑞′=(𝑞′1,…,𝑞′𝜃) where 𝑞′𝑠1=0 and 𝑞′𝑠2=𝑞∗𝑠2+𝑞∗𝑠1. In particular, when the defender plays 𝑞∗ her expected payoff is

𝑈∗=𝑝∗⋅𝔼⎡⎣⎢⎢∑𝑖∈𝑉∖(𝑠1∪𝑠2)𝑁𝑖⎤⎦⎥⎥+𝑝∗⋅𝔼⎡⎣⎢⎢∑𝑗∈𝑠1∩𝑠2𝑁𝑗⎤⎦⎥⎥+𝑝∗⋅𝔼⎡⎣⎢⎢∑𝑙∈𝑠2∖𝑠1𝑁𝑙⎤⎦⎥⎥+𝑝∗⋅𝔼⎡⎣⎢⎢∑𝑟∈𝑠1∖𝑠2𝑁𝑟⎤⎦⎥⎥,
whereas when she plays 𝑞′ it is

𝑈′=𝑝∗⋅𝔼⎡⎣⎢⎢∑𝑖∈𝑉∖(𝑠1∪𝑠2)𝑁𝑖⎤⎦⎥⎥+𝑝∗⋅𝔼⎡⎣⎢⎢∑𝑗∈𝑠1∩𝑠2𝑁𝑗⎤⎦⎥⎥+(𝑝∗+𝑞∗𝑠1)⋅𝔼⎡⎣⎢⎢∑𝑙∈𝑠2∖𝑠1𝑁𝑙⎤⎦⎥⎥+(𝑝∗−𝑞∗𝑠1)⋅𝔼⎡⎣⎢⎢∑𝑟∈𝑠1∖𝑠2𝑁𝑟⎤⎦⎥⎥=𝑈∗+𝑞∗𝑠1⋅⎛⎝⎜⎜𝔼⎡⎣⎢⎢∑𝑙∈𝑠2∖𝑠1𝑁𝑙⎤⎦⎥⎥−𝔼⎡⎣⎢⎢∑𝑟∈𝑠1∖𝑠2𝑁𝑟⎤⎦⎥⎥⎞⎠⎟⎟>𝑈∗,
which contradicts the equilibrium assumption. Therefore, for every pure defense strategy 𝑠1∈𝑆 it holds that 𝔼[∑𝑖∈𝑠1𝑁𝑖]≥𝔼[∑𝑗∈𝑠2𝑁𝑗] for every 𝑠2∈[𝜃].

Now we will prove that equilibrium is necessary for the three conditions of the statement to hold. Suppose that all conditions hold and 𝑝∗(𝐺) is achieved for the defense strategy 𝑞=(𝑞1,…,𝑞𝜃). We will show that the defender and each attacker play a best response.

Consider an attacker 𝑗∈[𝑘] with strategy 𝑡=(𝑡1,…,𝑡𝑛) and support 𝑇𝑗⊆𝑉∗ according to Condition 2. Her expected payoff is

∑𝑖∈𝑇𝑗𝑡𝑖⋅(1−𝑝∗)=1−𝑝∗.
It suffices to consider unilateral deviations of j to pure strategies. Any pure strategy 𝑖′∈𝑇𝑗 gives her expected payoff 1−𝑝∗, since 𝑝𝑖′=𝑝∗ (because 𝑇𝑗⊆𝑉∗). Any pure strategy 𝑖′∈𝑉∗∖𝑇𝑗 also gives her expected payoff 1−𝑝∗ for the same reason. Finally, any pure strategy 𝑖′∈𝑉∖𝑉∗ gives her expected payoff 1−𝑝𝑖′<1−𝑝∗ by the definition of 𝑉∗. Therefore every attacker plays a best response.

Now consider the defender with strategy 𝑞=(𝑞1,…,𝑞𝜃) and support 𝑆⊆[𝜃]. According to Condition 1 of the theorem’s statement, q results to vertices of G having vertex-probability 𝑝∗. By Condition 3, for any pure defense strategy 𝑠1∈𝑆 it holds that 𝔼[∑𝑖∈𝑠1𝑁𝑖]≥𝔼[∑𝑗∈𝑠2𝑁𝑗] for every 𝑠2∈[𝜃], and let us denote 𝑁𝑚𝑎𝑥:=𝔼[∑𝑖∈𝑠1𝑁𝑖]. Now consider a unilateral deviation 𝑞′=(𝑞′1,…,𝑞′𝜃) of the defender. Her expected payoff is

𝑈(𝑞′)=∑𝑗∈[𝜃](𝑞′𝑗⋅𝔼[∑𝑖∈𝑗𝑁𝑖])≤∑𝑗∈[𝜃]𝑞′𝑗⋅𝑁𝑚𝑎𝑥=𝑁𝑚𝑎𝑥=∑𝑗∈𝑆(𝑞𝑗⋅𝔼[∑𝑖∈𝑗𝑁𝑖])=𝑈(𝑞),
where the penultimate equation holds due to the fact that ∑𝑗∈𝑆𝑞𝑗=1 and Condition 3. Therefore, q is a best response for the defender, and the three conditions of the theorem’s statement imply a strategy profile that is an equilibrium. ◻

Lemma 1
For any given graph G, the equilibrium defense ratio is DR(𝐺,𝑆∗)=1𝑝∗(𝐺), where 𝑝∗(𝐺):=max𝑞∈𝛥𝜃min𝑖∈[𝑛]𝑝𝑖 and 𝑆∗ is an equilibrium.

Proof
By Theorem 1, in an equilibrium, every attacker will have in her support only vertices that are defended with probability exactly 𝑝∗(𝐺). Thus, the expected number of attackers the defender catches is 𝑝∗(𝐺)⋅𝑘. By the definition of the defense ratio, DR(𝐺,𝑆∗)=𝑘𝑝∗(𝐺)⋅𝑘=1𝑝∗(𝐺). ◻

Corollary 1
The following hold.

(a)
For a given graph G, in any equilibrium, the expected payoff of the defender and each attacker is unique.

(b)
For a given graph G, in any equilibrium with support 𝑆⊆[𝜃] of the defender, for every 𝑠∈𝑆 there exists a vertex 𝑣∈𝑠 such that 𝑝𝑣=𝑝∗(𝐺).

(c)
In any CSD game on a graph G, the problem of finding the equilibrium defense ratio (or equivalently, 𝑝∗(𝐺)) for 𝑘≥2 attackers, reduces to the same problem in the game with 𝑘=1 attacker, which is a two-player constant-sum game.

Proof
   

(a)
By Theorem 1, at any equilibrium the defender chooses a strategy that induces probability 𝑝∗(𝐺) to some vertex of G (Condition 1). Also, each of the attackers has in her support T only vertices with vertex-probability 𝑝∗(𝐺). Therefore, all attackers attack only such vertices and the expected payoff of the defender is 𝑘⋅𝑝∗(𝐺). Consider also an attacker with strategy 𝑡=(𝑡1,𝑡2,…,𝑡𝑛). Her expected payoff is ∑𝑖∈[𝑛]𝑡𝑖⋅(1−𝑝𝑖), where 𝑝𝑖 is the vertex-probability of vertex i. This value is equal to ∑𝑖∈𝑇𝑡𝑖⋅(1−𝑝∗(𝐺))=1−𝑝∗(𝐺). Since 𝑝∗(𝐺) is unique for a graph G, the expected payoffs of the defender and each attacker is unique.

(b)
The proof is by contradiction. Consider an equilibrium where the defender’s strategy is 𝑞∈[𝜃] with support S, and there exists a pure strategy 𝑠∈𝑆 for which every vertex 𝑣∈𝑠 has 𝑝𝑣>𝑝∗(𝐺). By Condition 2 of Theorem 1, no attacker has in her support a vertex in s. Therefore, the defender can strictly increase her expected payoff by moving all her probability 𝑞𝑠>0 from s to some other pure strategy 𝑠′ that contains a vertex which is in the support of some attacker.

(c)
Observe that for any given graph G, the quantity 𝑝∗(𝐺), by definition, only depends on the graph and not the number of attackers k. That is, 𝑝∗(𝐺) is the same for every 𝑘≥1. Lemma 1 states that in any equilibrium 𝑆∗, it is DR(𝐺,𝑆∗)=1𝑝∗(𝐺), therefore the defense ratio in an equilibrium does not depend on k. This means that when we are given G and we are interested in the equilibrium defense ratio, we might as well consider the game with the single defender and a single attacker. By the definition of the game (see Sect. 2) the latter is a two-player constant-sum game.

◻

The following corollary implies that coordination (resp. individual selfishness) of the attackers cannot increase the attackers’ (resp. defender’s) expected payoff in equilibrium.

Corollary 2
Every equilibrium with uncoordinated attackers (i.e. as described in Sect. 2) is an equilibrium with coordinated (i.e. centrally controlled) attackers, and vice versa.

Proof
Let 𝑞∗ be a best-defense strategy for the defender. Then, in any best response of any attacker, coordinated or not, every attacker plays only pure strategies that yield maximum payoff against 𝑞∗; i.e. they play only strategies that are defended with probability 𝑝∗(𝐺). If this was not the case, either an uncoordinated attacker could increase her payoff by unilaterally changing her strategy, or the “coordinator” could increase the payoff the attackers collectively get by dictating all the attackers to play vertices that are covered with probability 𝑝∗(𝐺).

So, assume that we have an equilibrium in the uncoordinated case. This is an equilibrium for the coordinated case as well: according to Theorem 1, all attackers play vertices that are defended with probability 𝑝∗(𝐺) and thus the expected collective payoff of the attackers cannot be increased, and furthermore the expected total number of attackers on the vertices of a pure strategy that is in the support of the defender is maximized over all pure defense strategies, so no unilateral deviation of the defender can increase her expected payoff.

Conversely, in any equilibrium in the coordinated setting, the “coordinator” dictates all the attackers to attack vertices that are covered with probability 𝑝∗(𝐺), satisfying Conditions 1, 2 of Theorem 1. Also in the equilibrium of the coordinated setting, similarly to Condition 3 of Theorem 1, the “coordinator” will have placed the attackers in a way such that the vertices of any pure defense strategy in the support have maximum expected total number of attackers over all pure defense strategies; otherwise the defender can increase her expected payoff by neglecting a pure strategy with smaller than maximum expected total number of attackers, and move the probability assigned to that pure strategy to another one that has maximum expected total number of attackers. By Theorem 1, this is an equilibrium also for the uncoordinated setting. ◻

The following theorem provides an algorithm for computing an equilibrium for any CSD game, whose running time is polynomial in n when 𝜆=𝑐 or 𝜆=𝑛−𝑐, where c is a constant natural number.

Theorem 2
For any given graph G and parameter 𝜆, there is an algorithm that computes 𝑝∗(𝐺) and also finds an equilibrium in time polynomial in (𝑛𝜆).

Proof
Given a graph G, the number of attackers 𝑘≥1, and some 𝜆∈{1,2,…,𝑛}, the action set D of the defender is constructed by the vertex sets of at most (𝑛𝜆) 𝜆-subgraphs; so for D’s cardinality 𝜃 it holds that 𝜃≤(𝑛𝜆). Consider now the mixed strategy 𝑞∈𝛥𝜃 of the defender, where each pure strategy 𝑗∈[𝜃] is assigned probability 𝑞𝑗. Consider also the vertex-probability 𝑝𝑖 for each vertex 𝑖∈[𝑛]. According to Corollary 1 (a) and (c), the unique 𝑝∗(𝐺) in the case of a single attacker can be used to derive an equilibrium for the case of 𝑘≥2 attackers. Therefore, we will find 𝑝∗(𝐺) for a single attacker, find an equilibrium for that case, and then extend this equilibrium to an equilibrium in the case of 𝑘≥2 attackers. In more detail, after we find the defense strategy 𝑞∗ that maximizes min𝑖∈[𝑛]𝑝𝑖 (Condition 1 of Theorem 1), i.e. yields 𝑝∗(𝐺) on the set

𝑉∗:={𝑖∈𝑉 | 𝑝𝑖=max𝑞∈𝛥𝜃min𝑗∈[𝑛]𝑝𝑗}, an equilibrium is achieved if the single attacker assigns probability 1/|𝑉∗| to each vertex of 𝑉∗. This is because all conditions of Theorem 1 are satisfied. Then, an equilibrium for 𝑘≥2 is achieved if every attacker plays the same strategy as the single attacker; that is because again all conditions of Theorem 1 are satisfied.

The crucial observation that allows us to design such an algorithm is that we can compute 𝑝∗(𝐺) via a linear program which has 𝑂((𝑛𝜆)) many variables and O(n) constraints, and therefore its running time is in the worst case polynomial in (𝑛𝜆), for 𝜆∈{2,3,…,𝑛−1}. For the trivial cases 𝜆=1 and 𝜆=𝑛, 𝐷={{𝑖}|𝑖∈𝑉} and 𝐷=𝑉 respectively, therefore 𝑝∗(𝐺)=1/𝑛 and 𝑝∗(𝐺)=1 respectively. So in the rest of the proof we will assume that 𝜆∈{2,3…,𝑛−1}. It remains to show how 𝑝∗(𝐺) is computed.

Let us denote 𝑝∗:=𝑝∗(𝐺):=max𝑞∈𝛥𝜃min𝑖∈[𝑛]𝑝𝑖. The computation of 𝑝∗ can be done as follows. First, consider each of the (𝑛𝜆) subsets of V of size 𝜆, and find if it is a proper 𝜆-subgraph of G (i.e. connected); this can be done by running a Depth (or Breadth) First Search algorithm for each subset of size 𝜆. If it is not, then continue with the next subset. If it is, we consider it in the action set [𝜃], and assign to it a variable 𝑞𝑗 which stands for its assigned probability in a general defense strategy. Now, by definition, for some vertex 𝑖∈[𝑛], 𝑝𝑖=∑𝑗∈[𝜃]𝑖∈𝑗𝑞𝑗. Therefore, we will consider only pure strategies j which are 𝜆-subgraphs to create the 𝑝𝑖’s. To compute the minimum 𝑝𝑖 over all i’s we introduce the variable 𝑝′ and write the following set of n inequalities as a constraint in our linear program:

∑𝑗∈[𝜃]𝑖∈𝑗𝑞𝑗≥𝑝′,for𝑖∈{1,2,…,𝑛}.
The left-hand side of each of the above inequalities is in fact 𝑝𝑖. The variable constraints are 𝑝′,𝑞1,𝑞2,…,𝑞𝜃≥0 and also ∑𝜃𝑗=1𝑞𝑗=1, and all of the aforementioned constraints can be written in canonical form by applying standard transformations. Finally, the objective function of the linear program is variable 𝑝′ and we require its maximization, which is the value 𝑝∗. ◻

Connections to Other Types of Games
Although CSD games are defined as a normal form game with 𝑘+1 players, we can observe that they are a special case of other well-studied types of games: polymatrix games and Stackelberg games.

A polymatrix game is defined by a graph where every vertex represents a player and every edge represents a two-player game played by the endpoints of the edge. Every player has the same set of pure strategies in every game he is involved and to play the game he plays the same (mixed) strategy in every game. The payoff of every player is the sum they get from every two-player game they participate in. In a CSD game we observe the following. Firstly, the payoff of every attacker depends only on the strategy the defender plays, thus every attacker is involved only in one two-player game. In addition, all the attackers have the same set of pure strategies and they share the same payoff matrix. Similarly, the payoff the defender gets from catching an attacker depends only on the strategy the defender and this specific attacker chose. Hence, the payoff of the defender can be decomposed into a sum of payoffs from k two-player games. So, a CSD game can be seen as a polymatrix game where the underlying graph is a star with k leaves that correspond to the attackers and the defender is the center of the star. Although many-player polymatrix games have exponentially smaller representation size compared to the equivalent normal-form representation, we should note that this polymatrix game is of exponential size in the worst case since the defender can have exponential in n pure strategies to choose from.

A Stackelberg game is an extensive form two-player game. In the first round, one of the players commits to a (mixed) strategy. In the second round, the other player chooses a best response against the committed strategy of her opponent. In a Stackelberg equilibrium the first player is playing a strategy that maximizes her expected payoff, given that the second player plays a best response (mixed strategy). The MaxMin probability 𝑝∗(𝐺) for a CSD game on a graph G corresponds to a Stackelberg equilibrium. By Corollary 1(c), any CSD game, with 𝑘≥1 attackers has the same 𝑝∗ as that of the case with 𝑘=1. Furthermore, as in a Stackelberg game, in the CSD game with 𝑘=1 the defender chooses a mixed strategy that maximizes her expected payoff, given that the attacker plays a best response (mixed strategy). Therefore, when we are interested in the defense-ratio in equilibrium of a CSD game for some arbitrary 𝑘≥1, finding a Stackelberg equilibrium of the corresponding CSD game with 𝑘=1 suffices.

Defense-Optimal Graphs
We now focus our attention on defense-optimal graphs. We first characterize defense-optimal graphs with respect to the MaxMin probability 𝑝∗ and then use this characterization to analyze more specific classes of graphs like Hamiltonian graphs and tree graphs. We begin by an exact computation of the equilibrium defense ratio of any defense-optimal graph.

Theorem 3
In any defense-optimal graph G, we have that DR(𝐺,𝑆∗)=𝑛𝜆.

Proof
First we will show that 𝑛𝜆 is a lower bound on the equilibrium defense ratio DR(𝐺,𝑆∗) and then prove that it is tight. According to Lemma 1, a lower bound on DR(𝐺,𝑆∗) can be found by equivalently founding an upper bound on 𝑝∗(𝐺) over all graphs G with n vertices. Let us show that 𝑝∗(𝐺)≤𝜆𝑛 for every G.

Suppose there is a graph 𝐺′ such that 𝑝∗(𝐺′)>𝜆𝑛, and let us focus only on 𝐺′. Suppose also that the defender has an action set [𝜃] on 𝐺′. Fix the strategy 𝑞=(𝑞1,…,𝑞𝜃)∈𝛥𝜃 that achieves 𝑝∗(𝐺′). Then, by the definition of 𝑝∗(𝐺′), for the vertex probabilities 𝑝𝑖 it holds that 𝑝𝑖>𝜆𝑛 for all 𝑖∈[𝑛]. Therefore, it is

∑𝑖=1𝑛𝑝𝑖>𝜆.
(3)
Also, by the definition of a defense strategy, if X denotes the random variable corresponding to the number of vertices that the defender covers, then:

𝔼[𝑋]=∑𝑗=1𝜃𝑞𝑗⋅|𝐿𝑗|=𝜆(where 𝐿𝑗 is a 𝜆-subgraph of 𝐺, hence |𝐿𝑗|=𝜆∀𝑗∈[𝜃]).
(4)
Let us introduce the indicator variables 𝑋𝑖𝑗, 𝑖∈[𝑛], 𝑗∈[𝜃] with value 1 if vertex 𝑖∈𝐿𝑗, and 0 otherwise. Then,

𝔼[𝑋]=∑𝑗=1𝜃𝑞𝑗∑𝑖=1𝑛𝑋𝑖𝑗=∑𝑖=1𝑛∑𝑗=1𝜃𝑞𝑗𝑋𝑖𝑗=∑𝑖=1𝑛𝑝𝑖>𝜆(by Inequality (3)),
(5)
which contradicts Eq. (4).

It remains to show that the lower bound 𝑛𝜆 on DR(𝐺,𝑆∗) is tight. This is easy to do by showing that 𝜆𝑛 is a tight upper bound on 𝑝∗(𝐺): any Hamiltonian graph has 𝑝∗(𝐺)=𝜆𝑛 as we show in Observation 1. ◻

As an intermediate corollary of Theorem 3 we get the following characterization of defense-optimal graphs.

Corollary 3
A graph G is defense-optimal if and only if all of its vertices are defended with probability 𝜆𝑛.

Proof
Necessity of defense-optimality is trivial: every vertex has vertex-probability 𝜆𝑛, therefore 𝑝∗(𝐺)=𝜆𝑛, so by Theorem 3 the graph is defense-optimal.

Sufficiency of defense-optimality is also easy to see using the Eqs. (4), (5) of the proof of Theorem 3. Suppose that the graph is defense-optimal and consider an equilibrium where the defense strategy is 𝑞=(𝑞1,…,𝑞𝜃). Then the sum of vertex probabilities is ∑𝑛𝑖=1𝑝𝑖=𝜆 according to the aforementioned equations. Therefore, if there exists a vertex v with vertex-probability 𝑝𝑣>𝜆𝑛 then there is another vertex u with probability 𝑝𝑢<𝜆𝑛. This means that 𝑝∗(𝐺)<𝜆𝑛, and as a result the graph is not defense-optimal which contradicts our assumption. ◻

Someone may wonder whether Corollary 3 can be further exploited to prove that, in general, there are best-defense strategies in defense-optimal graphs are uniform, i.e. every pure strategy s in the support S of the defender is assigned probability 1/|S|. However, as we demonstrate in Fig. 1 this is not the case. On the other hand, this claim is true for Hamiltonian graphs and tree graphs.

Fig. 1
figure 1
An example of a defense-optimal graph G with no uniform best-defense strategy. Here 𝑛=7, 𝜆=3 and 𝑝∗(𝐺)=3/7 is achievable by assigning probability 3/7 to pure strategy {𝑣1,𝑣2,𝑣3} and probability 1/7 to each of the pure strategies {𝑣4,𝑣5,𝑣6}, {𝑣4,𝑣5,𝑣7}, {𝑣4,𝑣6,𝑣7}, {𝑣5,𝑣6,𝑣7}, so the graph is defense optimal. Suppose that there is a uniform best-defense strategy for the graph, with support of size r. Observe that 𝑣1 cannot participate in more than one pure defense strategies, so in the uniform defense strategy, the vertex-probability 𝑝𝑣1 has to be 1/r (by the definition of uniformity), but it also has to be 3/7 due to Corollary 3. Since 𝑟∈ℕ, this is a contradiction, and there is no uniform best-defense strategy for G

Full size image
Observation 1
All Hamiltonian graphs are defense-optimal.

Proof
Consider an arbitrary Hamiltonian graph G with n vertices. We will show that the graph can achieve vertex-probability 𝑝𝑖=𝜆𝑛 for every 𝑖∈[𝑛], thus by Corollary 3 it is defense-optimal. Consider a Hamiltonian cycle of G and let us denote it by H. In the rest of the proof H will be the graph under study. Now consider the whole action set D of the defender, i.e. every path on H starting from a vertex i going clockwise and ending at vertex 𝑖+𝜆−1. Observe that there are only n such paths, therefore 𝜃:=|𝐷|=𝑛. By assigning probability 1𝑛 to each pure strategy 𝑗∈[𝜃], since each vertex is in exactly 𝜆 pure strategies, each vertex 𝑖∈[𝑛] has vertex-probability 𝑝𝑖=𝜆⋅1𝜃=𝜆𝑛. ◻

Tree Graphs
In this section we focus on the case where the graph is a tree. First, we further refine the characterization of defense-optimal graphs for trees. Then, we utilize this characterization to derive an algorithm that decides in polynomial time whether a given tree is defense-optimal, and if that is the case, it constructs in polynomial time a defense-optimal strategy for it. On the other hand, in the case where the tree is not defense-optimal, we show that it is 𝙽𝙿-hard to compute a best-defense strategy for it, namely it is 𝙽𝙿-hard to compute 𝑝∗(𝐺). We first provide Lemma 2 which will be used in our polynomial-time algorithm for checking defense-optimality on trees. Henceforth, we write that a graph is covered by a defense strategy if every vertex of the graph is covered by a 𝜆-subgraph that is in the support of the defense strategy.

Lemma 2
A tree T is defense-optimal if and only if T can be decomposed into 𝑛𝜆 disjoint 𝜆-subgraphs.

Proof
(⇒)(⇒) Let T be defense-optimal. We will show that the support of any best-defense strategy on T must comprise of pure strategies that are disjoint 𝜆-subgraphs which altogether cover every 𝑣∈𝑉. Since those are disjoint and cover T, it follows that their number is 𝑛𝜆 in total.

If 𝜆=1 then the above trivially holds. Assume that 𝜆≥2 and consider a best-defense strategy on T whose support comprises of a collection  of 𝜆-subgraphs.

Let 𝑢∈𝑉 be a leaf of T and let 𝑣∈𝑉 be its parent. Any 𝜆-subgraph in  covering u must also cover v, since 𝜆≥2. Also, any 𝜆-subgraph in  covering v must also cover u, otherwise 𝑝𝑣 would be greater than 𝑝𝑢. Now, consider the neighbors of v. For those of them that are leaves, the same must hold as holds for u, namely v and its leaf-children must all be covered by the exact same 𝜆-subgraph(s).

Consider the case where there is a leaf 𝑢∈𝑉, such that a single 𝜆-subgraph contains u, its parent v, and all the other leaf-children of v (and, possibly, other vertices connected to v). Then we can remove this 𝜆-subgraph from  and the corresponding tree from T. This leaves the remainder of T being a forest comprising of trees 𝑇1,…,𝑇𝑥, each of which has a (best-)defense strategy comprising of the corresponding subset of (the remainder of)  on 𝑇𝑖. Notice that it must be the case that every tree 𝑇𝑖, 𝑖=1,2,…,𝑥, has size at least 𝜆 (otherwise the initial collection  would not have covered T). So, if there is always a leaf u in some tree of the forest, such that a single 𝜆-subgraph contains u, its parent v, and all the other leaf-children of v (and, possibly, other vertices connected to v), we can proceed in the same fashion for each of the 𝑇𝑖’s, always removing a 𝜆-subgraph from , and the corresponding vertices from T, until we end up with an empty tree. This means that  was indeed a collection of disjoint 𝜆-subgraphs covering T.

However, assume for the sake of contradiction that at some “iteration” the assumption does not hold, namely assume that there is a tree in the forest with no leaf u, such that a single 𝜆-subgraph contains u, its parent v, and all the other leaf-children of v (and, possibly, other vertices connected to v). This means that there are (at least) two 𝜆-subgraphs in , namely 𝐿1,𝐿2, that cover u. Due to our initial observations, u, together with its parent v and all of v’s leaf-children are contained in both 𝐿1 and 𝐿2. Since those are different 𝜆-subgraphs, there is a vertex z in the tree which belongs to 𝐿2 but does not belong to 𝐿1. Since 𝑝𝑧=𝑝𝑣 (due to the fact that  is the support of the defense-optimal strategy and Corollary 3), it must hold that there is a different 𝜆-subgraph, 𝐿3, which covers z but does not cover v or any of its leaf-children. If 𝐿3 also covers a vertex in 𝐿1∖𝐿2Footnote1, then there is a cycle in the tree which is a contradiction. So 𝐿3 must not cover vertices in 𝐿1∖𝐿2. Since 𝐿3 is different to 𝐿2, there must be a vertex 𝑧′ in the tree which belongs in 𝐿3 but not in 𝐿2 (also not in 𝐿1). Since 𝑝𝑧′=𝑝𝑧 (due to the fact that  is the support of the defense-optimal strategy and Corollary 3), it must hold that there is a different 𝜆-subgraph, 𝐿4, which covers 𝑧′ but does not cover z or any of the vertices in 𝐿2. Similarly to before, if 𝐿4 covers a vertex in 𝐿1∖𝐿2, then there is a cycle in the tree which is a contradiction. So 𝐿4 must not cover vertices in 𝐿1 or in 𝐿2.

Proceeding in the same way, we result in contradiction since the tree has finite number of vertices and there will need to be an overlap in coverage of some 𝐿𝑗 with some 𝐿𝑖, 𝑗>𝑖+1, which would mean that there is a cycle in the tree.

Therefore, there cannot be any overlaps between the 𝜆-subgraphs of , meaning that  comprises of 𝑛𝜆 disjoint 𝜆-subgraphs which altogether cover T.

(⇐⇐) Let ={𝐿1,…,𝐿𝑛𝜆} be a collection of 𝑛𝜆 disjoint 𝜆-subgraphs that altogether cover T. Let the defender play each 𝐿𝑖, 𝑖∈{1,…,𝑛𝜆}, equiprobably, that is, with probability 1/(𝑛𝜆)=𝜆𝑛. Then every vertex 𝑣∈𝑉 is covered with probability 𝑝𝑣=𝜆𝑛=𝑝∗(𝐺), meaning that T is defense-optimal. ◻

With Lemma 2 in hand we can derive a polynomial-time algorithm that decides if a tree is defense-optimal, and if it is, to produce a best-defense strategy.

Theorem 4
There exists a polynomial-time algorithm that decides whether a tree is defense-optimal, and if it is, it outputs a best-defense strategy.

Proof
The algorithm works as follows. Let us pick arbitrarily a vertex as the root of the tree. Initially, there is a pointer associated with a counter in every leaf of the tree T that moves “upwards” towards the root. For every move of the pointer the corresponding counter increases by one. The pointer moves until one of the following happens: either the counter is equal to 𝜆, or it reaches a vertex with degree greater or equal to 3 where it “stalls”. In the case where the counter is equal to 𝜆, we create a 𝜆-subgraph of T, we delete this 𝜆-subgraph from the tree, we move the pointer one position upwards, and we reset the counter back to zero. If a pointer stalls at a vertex of degree 𝑑≥3, it waits until all 𝑑−1 pointers reach this vertex. Then, all these pointers are merged to a single one and a new counter is created whose value is equal to the sum of the counters of all d pointers. If this sum is larger than 𝜆, then the algorithm returns that the graph is not defense-optimal. If this sum is less than or equal to 𝜆, then we proceed as if there was initially only this pointer with its counter; if the new counter is equal to 𝜆, then we create a 𝜆-subgraph of T and reset the counter to 0; else the pointer moves upwards and the counter increases by one. To see why the algorithm requires polynomial time, observe that we need at most n pointers and n counters and in addition every pointer moves at most n times.

We now argue about the correctness of the algorithm described above. Clearly, if the algorithm does not output that the tree is not defense-optimal, it means that it partitioned T into 𝜆-subgraphs. So, from Lemma 2 we get that T is defense-optimal and the uniform probability distribution over the produced partition covers every vertex with probability 𝜆𝑛. It remains to argue that when the algorithm outputs that the graph is not defense-optimal, this is indeed the case. Consider the case where we delete a 𝜆-subgraph of the (remaining) tree. Observe that the 𝜆-subgraph our algorithm deleted should be uniquely covered by this 𝜆-subgraph in any best-defense strategy; any other 𝜆-subgraph would overlap with some other 𝜆-subgraph. Hence, the deletion of such a 𝜆-subgraph was not a “wrong” move of our algorithm and the remaining tree is defense-optimal if and only if the tree before the deletion was defense-optimal. This means that any deletion that occurred by our algorithm did not make the remaining graph non defense-optimal. So, consider the case where after a merge that occurred at vertex v we get that the new counter is 𝑐>𝜆. Then, we can deduce that all the subtrees rooted at v associated with the counters have strictly less than 𝜆 vertices. Hence, in order to cover all the 𝑐>𝜆 vertices using 𝜆-subgraphs, at least two of these 𝜆-subgraphs cover vertex v. Hence, the condition of Lemma 2 is violated. But since every step of our algorithm so far was correct, it means that v cannot be covered only by one 𝜆-subgraph. Hence, our algorithm correctly outputs that the tree is not defense-optimal. ◻

In Theorem 4 we showed that it is easy to decide whether a tree is defense-optimal and if this is the case, it is easy to find a best-defense strategy for it. Now we prove that if a tree is not defense-optimal, then it is 𝙽𝙿-hard to compute 𝑝∗(𝐺). Note that the problem of computing 𝑝∗(𝐺) reduces to the problem of finding a best-defense strategy for graph G. Therefore finding a best-defense strategy is also 𝙽𝙿-hard.

Theorem 5
Computing 𝑝∗(𝐺) in CSD games is strongly 𝙽𝙿 -hard, even if the graph G is a tree. Consequently, finding a best-defense strategy is strongly 𝙽𝙿 -hard.

Proof
We will prove the theorem by reducing from the strongly 𝙽𝙿-hard problem 3-PARTITION. In an instance of 3-PARTITION we are given a multiset with n positive integers 𝑎1,𝑎2,…,𝑎𝑛 written in unary, where 𝑛=3𝑚 for some 𝑚∈ℕ>0, and we ask whether it can be partitioned into m triplets 𝑆1,𝑆2,…,𝑆𝑚 such that the sum of the numbers in each subset is equal. Let 𝑠=∑𝑛𝑖=1𝑎𝑖. Observe then that the problem is equivalent to asking whether there is a partition of the integers to m triplets such that the numbers in every triplet sum up to 𝑠𝑚. Without loss of generality, we can assume that 𝑎𝑖<𝑠𝑚 for every 𝑖∈[𝑛]; if this was not the case, the problem could be trivially answered. So, given an instance of 3-PARTITION, we create a tree 𝐺=(𝑉,𝐸) with 𝑠+1 vertices and 𝜆=𝑠𝑚+1. The tree is created as follows. For every integer 𝑎𝑖, we create a path with 𝑎𝑖 vertices. In addition, we create the vertex 𝑣0 and connect it to one of the two ends of each path. We will ask whether 𝑝∗(𝐺)≥1𝑚. Observe that this is a polynomial-time construction since the integers 𝑎𝑖 are given in unary.

Firstly, assume that the given instance of 3-PARTITION is satisfiable. Then, given 𝑆𝑗 we create a (𝑠𝑚+1)-subgraph of G as follows. If 𝑎𝑖∈𝑆𝑗, then we add the corresponding path of G to the subgraph. Finally, we add vertex 𝑣0 in our (𝑠𝑚+1)-subgraph and the resulting subgraph is connected (by the construction of G). Since the sum of 𝑎𝑖’s equals 𝑠𝑚, the constructed subgraph has 𝑠𝑚+1 vertices. If we assign probability 1𝑚 to every (𝑠𝑚+1)-subgraph we get that 𝑝𝑣≥1𝑚 for every 𝑣∈𝑉.

To prove the other direction, assume that 𝑝∗(𝐺)≥1𝑚 and observe the following. Firstly, since as we argued it is 𝑎𝑖<𝑠𝑚 for every 𝑖∈[𝑛], it holds that every (𝑠𝑚+1)-subgraph of G contains vertex 𝑣0. Thus, 𝑝𝑣0=1 and ∑𝑣≠𝑣0𝑝𝑣≥𝑠𝑚, since there are s vertices other than 𝑣0 and for each one of them holds that 𝑝𝑣≥1𝑚. In addition, observe that ∑𝑣∈𝑉𝑝𝑣=𝜆=𝑠𝑚+1. Hence, we get that 𝑝𝑣=𝑝∗(𝐺)=1𝑚 for every vertex 𝑣≠𝑣0. In addition, observe that every pure defense strategy that covers a leaf of this tree, covers all the vertices of the branch. Hence, for every branch of the tree, all its vertices are covered by the same set of pure strategies; if a vertex u that is closer to 𝑣0 is covered by one strategy that does not cover the whole branch, then the leaf 𝑢′ of the branch is covered with probability less than u. So, in order for 𝑝𝑣=𝑝∗(𝐺)=1𝑚 for every 𝑣≠𝑣0, it means that there exist a (𝑠𝑚+1)-subgraph that exactly covers a subset of the paths; this means that if a (𝑠𝑚+1)-subgraph covers a vertex in a path, then it covers every vertex of the path. Hence, by the construction of the graph, we get that this (𝑠𝑚+1)-subgraph of G corresponds to a subset of integers in the 3-PARTITION instance that sum up to 𝑠𝑚. Since, 3-PARTITION is 𝙽𝙿-hard, we get that computing 𝑝∗(𝐺) is 𝙽𝙿-hard. Also, since finding a best-defense strategy is at least as hard, we conclude it is 𝙽𝙿-hard. ◻

General Graphs
We conjecture that contrary to checking defense-optimality of tree graphs and constructing a corresponding defense-optimal strategy in polynomial time, it is 𝙽𝙿-hard to even decide whether a given (general) graph is defense-optimal.

Conjecture 1
It is 𝙽𝙿-hard to decide whether a graph is defense-optimal.

Approximation Algorithm for 𝑝∗(𝐺)
We showed in the previous section that, given a graph G, it is 𝙽𝙿-hard to compute 𝑝∗(𝐺), and consequently, 𝙽𝙿-hard to find a best-defense strategy. We also presented in Theorem  an algorithm for computing the exact value 𝑝∗(𝐺) of a given graph G (and therefore its best defense ratio), but this algorithm has running time polynomial in the size of the input only in the cases 𝜆=𝑐 or 𝜆=𝑛−𝑐, where c is a constant natural. On the positive side, we present now a polynomial-time algorithm which, given a graph G of n vertices, returns a defense strategy with defense ratio which is within factor 2+𝜆−3𝑛 of the best defense ratio for G. In particular, it achieves defense ratio 1/𝑝′≤(2+𝜆−3𝑛)/𝑝∗(𝐺), where 𝑝′=min𝑖∈[𝑛]𝑝𝑖 and every 𝑝𝑖, 𝑖∈[𝑛] is the vertex-probability determined by the constructed defense strategy. We henceforth write that a collection  of 𝜆-subgraphs covers a graph 𝐺=(𝑉,𝐸), if every vertex of V is covered by some 𝜆-subgraph in . The algorithm presented in this section returns a collection  of at most 2𝑛−3𝜆+1 𝜆-subgraphs that covers G. Therefore, the uniform defense strategy over  assigns probability at least 1/(2𝑛−3𝜆+1) to each 𝜆-subgraph.

For any collection  of 𝜆-subgraphs and for any 𝑣∈𝑉, let us denote by coverage(𝑣) the number of 𝜆-subgraphs in  which v belongs in. Observe that:

∑𝑣∈𝑉coverage(𝑣)=||⋅𝜆,
(6)
where || denotes the cardinality of .

We first prove Lemma 3, to be used in the proof of the main theorem of this section. We henceforth denote by V(G) and E(G) the vertex set and edge set, respectively, of some graph G.

Lemma 3
For any tree T of n vertices, and for any 𝜆≤𝑛, we can find a collection  of distinct 𝜆-subgraphs such that for every 𝑣∈𝑉, it holds that 1≤coverage(𝑣)≤degree(𝑣), except maybe for (at most) 𝜆−1 vertices, where for each of them it holds that coverage(𝑣)=degree(𝑣)+1.

Proof
We will prove the statement of the lemma by providing Algorithm 1 that takes as input T and 𝜆 and outputs the requested collection  of 𝜆-subgraphs.

figure a
The algorithm starts by picking an arbitrary vertex v to serve as the root of the tree. Then it performs a Depth-First-Search (DFS) starting from v. We will distinguish between visiting a vertex and covering a vertex in the following way. We say that DFS visited a vertex if it considered that vertex as a candidate to be inserted to some 𝜆-subgraph, and we say that DFS covered a vertex if it visited and inserted the vertex at some 𝜆-subgraph. By definition, DFS visits in a greedy manner first an uncovered child, and only if there is no such child, it visits its parent (lines 14–17, 21–24). The set-variable that keeps track of the covered vertices is S.

Starting with the root of T, the algorithm simply visits the whole vertex set according to DFS, putting each visited vertex in the same 𝜆-subgraph 𝐿𝑖 (starting with 𝑖=1) (lines 18–24), and when |𝐿𝑖|=𝜆, a new empty 𝜆-subgraph 𝐿𝑖+1 is picked to get filled in with 𝜆 vertices (lines 26–27) taking care of one extra thing: The first vertex that the algorithm puts in an empty 𝜆-subgraph 𝐿𝑖, 𝑖∈{1,2,…} is guaranteed to be one that has not been covered by any other 𝜆-subgraph so far (lines 13–17). This ensures that no two 𝜆-subgraphs will eventually be identical.

The algorithm will not only visit all vertices in T, but also cover them. That is because there is no point where the algorithm checks whether the currently visited vertex is uncovered and then does not cover it. On the contrary, it covers every vertex that it visits, except for some already covered one in case the current 𝜆-subgraph is empty (lines 13–24). And since DFS by construction visits every vertex, we know that at some point the whole vertex set will be covered, or equivalently, coverage(𝑣)≥1,∀𝑣∈𝑉. Therefore, the algorithm will eventually exit the while-loop in lines 12–29.

Now we prove that, after the algorithm terminates, every vertex 𝑣∈𝑉 is covered at most degree(v) times, except for at most 𝜆−1 vertices that are covered 𝑑𝑒𝑔𝑟𝑒𝑒(𝑣)+1 times. Observe that DFS visits every vertex v at most degree(v) times: (a) v will be visited after its parent u only if v is uncovered (lines 14–15, 21–22), v will get covered (lines 19–20), and will not get visited ever again by its parent since it will be covered (lines 16–17, 23–24). (b) v will be visited at most once by each of its children, say w, only if w does not have an uncovered child (lines 16–17, 23–24), and v will not get ever visited by its parent since v will be covered, and also v cannot be visited a second time by any of its children, since they can never be visited again (they can only be visited through v since T is a tree). Therefore, any vertex v will be visited exactly once after its parent is visited, and at most once by each of its children, having a total of at most degree(v) visits. And since, as argued above, the total number of times a vertex will be covered is at most the number of times it will get visited, when DFS terminates (i.e 𝑆=𝑉), it will be coverage(𝑣)≤𝑑𝑒𝑔𝑟𝑒𝑒(𝑣), for every 𝑣∈𝑉.

However, note that the last nonempty 𝜆-subgraph 𝐿𝑖 might not consist of 𝜆 vertices since the entire V was covered and DFS could not proceed further. In this case, the algorithm empties the set S that keeps track of the covered vertices, takes the current 𝐿𝑖 and fills it in with exactly another 𝜆−|𝐿𝑖| vertices. This is done by picking an arbitrary vertex from 𝐿𝑖 and setting it as the root of T, and performing one last DFS starting from it until 𝐿𝑖 has 𝜆 vertices in total (lines 30–33). To ensure that the DFS will continue only until it fills in this current 𝐿𝑖, the algorithm counts the number of times that it runs the while-loop of DFS, namely lines 12–29, via the variable count (line 34), which escapes the while-loop of DFS in case DFS has filled in 𝐿𝑖 (lines 28–29) and terminates. Observe that in the last 𝜆-subgraph 𝐿𝑖, a vertex v inserted in the last iteration of DFS (𝑐𝑜𝑢𝑛𝑡=1) and was not inserted in 𝐿𝑖 by the first run (𝑐𝑜𝑢𝑛𝑡=0) might have been covered by the first run of DFS exactly degree(v) times, therefore when the algorithm terminates it has been covered 𝑑𝑒𝑔𝑟𝑒𝑒(𝑣)+1 times. Since by the end of the first DFS run,‘ 𝐿𝑖 had at least one vertex, the cardinality of such vertices that are covered more times than their degree are at most 𝜆−1. ◻

We can now prove the following.

Lemma 4
For any graph G of n vertices, and for any 𝜆≤𝑛, there exist (at most) 2𝑛−3𝜆+1 𝜆-subgaphs of G that cover G.

Proof
Consider a spanning tree T of G. Then Lemma 3 applies to T. Observe that a collection  as described in the statement of the aforementioned lemma has the same qualities for G since 𝑉(𝑇)=𝑉(𝐺) and 𝐸(𝑇)⊆𝐸(𝐺). That is,  is a collection of distinct 𝜆-subgraphs of G, such that for every 𝑣∈𝑉, it holds that 1≤coverage(𝑣)≤degree(𝑣), except maybe for (at most) 𝜆−1 vertices, for each v of which, it is coverage(𝑣)=degree(𝑣)+1, where by degree(𝑣) we denote the degree of vertex v in T.

Fix a particular value for 𝜆 and consider a collection  of 𝜆-subgraphs as constructed in the proof of Lemma 3. Then, by Eq. (6),

||==∑𝑣∈𝑉coverage(𝑣)𝜆≤∑𝑣∈𝑉degree(𝑣)+(𝜆−1)𝜆2(𝑛−1)𝜆+𝜆−1𝜆=2𝑛−3𝜆+1.
◻

We conclude with the simple algorithm that achieves a defense strategy with defense ratio which is within factor 2+𝜆−3𝑛 of the best defense ratio for G.

Theorem 6
Given any graph 𝐺=(𝑉,𝐸), Algorithm 2 computes in time O(|E|) a defense strategy such that, for any combination of attack strategies, the resulting strategy profile S yields defense ratio DR(𝐺,𝑆)≤(2+𝜆−3𝑛)⋅DR(𝐺,𝑆∗).

figure b
Proof
As argued in Lemma 4, there is a collection  of 𝜆-subgraphs with ||≤2𝑛𝜆+1−3𝜆 which covers G. Therefore, the uniform defense strategy returned by Algorithm 2 (which determines the vertex-probability 𝑝𝑖 for each vertex i) achieves a minimum vertex-probability 𝑝′:=min𝑖∈[𝑛]𝑝𝑖 for which it holds that:

𝑝′=1||≥12𝑛𝜆+1−3𝜆=𝜆𝑛2+𝜆−3𝑛≥12+𝜆−3𝑛⋅𝑝∗(𝐺),
(7)
where the first equality is due to the fact that any leaf 𝑣∈𝑉 of the spanning tree T of G through which  was created has coverage(𝑣)=1, and therefore there is such a vertex v in G that is covered by exactly one 𝜆-subgraph; and the last inequality is due to the fact that 𝑝∗(𝐺)≤𝜆/𝑛 for any graph G (due to Corollary 3), where 𝑝∗(𝐺) is the MaxMin probability of G.

The above inequality implies that if the defender chooses the prescribed strategy, the minimum defense ratio cannot be too bad. That is because in the worst case for the defender, each attacker will choose a vertex 𝑣′ on which the aforementioned strategy of the defender results to vertex-probability 𝑝′ (so that the attacker is caught with minimum probability). As a result, the defender will have the minimum possible expected payoff which is 𝑝′⋅𝑘. Thus, for the constructed defend strategy and any combination of attack strategies, the resulting strategy profile S yields defense ratio:

DR(𝐺,𝑆)≤𝑘𝑝′⋅𝑘≤(2+𝜆−3𝑛)⋅1𝑝∗(𝐺)=(2+𝜆−3𝑛)⋅DR(𝐺,𝑆∗),
where the last equality is due to Lemma 1.

With respect to the running time, notice that Step 1 of Algorithm 2 can be executed in time 𝑂(|𝑉|+|𝐸(𝐺)|)=𝑂(|𝐸(𝐺)|). Step 2 can be executed in time 𝑂(|𝑉|+|𝐸(𝑇)|)=𝑂(|𝑉|). Finally, Step 3 can be executed in constant time. Therefore, the total running time of Algorithm 2 is O(|E(G)|). ◻

Corollary 4
For any graph G there is a polynomial (in both n and 𝜆) time approximation algorithm (Algorithm 2) with approximation factor 1/(2+𝜆−3𝑛) for the computation of 𝑝∗(𝐺).

The merit of finding a probability 𝑝′ that approximates (from below) 𝑝∗(𝐺) for a given graph G through an algorithm such as Algorithm 2 is in guaranteeing to the defender that, no matter what the attackers play, she always “catches” at least a portion 𝑝′ of them in expectation, where the best portion is 𝑝∗(𝐺) in an equilibrium. In fact, one can see from Inequality (7) (penultimate step) that Algorithm 2 guarantees that the defender catches a fraction of attackers which is at least 1/(2+𝜆−3𝑛) times the best expected number (among all strategy profiles, not only equilibrium profiles).

Bounds on the Price of Defense
In the following theorem we give a lower bound on the PoD for any given n and 2≤𝜆≤𝑛−1 by constructing a graph G with particular (very small) 𝑝∗(𝐺) (which, by Lemma 1 implies great best defense ratio).

Theorem 7
The PoD(𝜆) is lower bounded by ⌊2(𝑛−1)𝜆⌋ and ⌊2(𝑛−1)𝜆+1⌋ for 𝜆 even and odd respectively, when 𝜆∈{2,3,…,𝑛−1}.

Proof
We will prove the statement by showing that for any given n and 𝜆∈{2,3,…,𝑛−1}, there exists a graph 𝐺=(𝑉,𝐸) on n vertices that requires (at least) some number roughly 𝑏=⌊2(𝑛−1)𝜆+1⌋ of 𝜆-subgraphs to be covered and additionally this graph’s structure achieves 𝑝∗(𝐺) for the uniform defense strategy, i.e. each 𝜆-subgraph is assigned equal probability 1/b.

The graph we construct is the following. First, consider a line graph with 𝜎 vertices, where 𝜎=⌈𝜆2⌉. Keep a central vertex to use later, and using only 𝑛−1 vertices, create as many complete lines with 𝜎 vertices as possible, i.e. 𝑏=⌊𝑛−1𝜎⌋. Create another incomplete line (if needed) with strictly less than 𝜎 vertices using the remaining ones 𝑛−1−𝑏⋅𝜎. Now draw an edge from the central vertex to a single leaf of each of the constructed lines. For examples of the construction of G in each of the below three cases, see Figs. 2, 3, and 4.

Fig. 2
figure 2
An example of Case 1 of Theorem 7, where 𝑛=15 and 𝜆=6. Here, graph G has 𝜎=3 and 𝑏=4. The 𝜆-subgraphs 𝐿1,𝐿2,𝐿3,𝐿4 that constitute the support of a best-defense strategy are shown with various colors (Color figure online)

Full size image
Fig. 3
figure 3
An example of Case 2(a) of Theorem 7, where 𝑛=19 and 𝜆=7. Here, graph G has 𝜎=4 and 𝑏=4. The 𝜆-subgraphs 𝐿1,𝐿2,𝐿3,𝐿4 that constitute the support of a best-defense strategy are shown with various colors (Color figure online)

Full size image
Fig. 4
figure 4
An example of Case 2(b) of Theorem 7, where 𝑛=20 and 𝜆=7. Here, graph G has 𝜎=4 and 𝑏=4. The 𝜆-subgraphs 𝐿1,𝐿2,𝐿3,𝐿4,𝐿5 that constitute the support of a best-defense strategy are shown with various colors (Color figure online)

Full size image
Consider now a defense strategy 𝑞:=(𝑞1,𝑞2,…,𝑞𝜃)∈𝛥𝜃 and the vertex probabilities 𝑝1,𝑝2,…,𝑝𝑛 it induces on the vertices of G.

Case 1: 𝜆 is even. In this case 𝜎=𝜆/2 and observe that the diameter of this graph G is equal to 𝜆, therefore no 𝜆-subgraph that covers a leaf of a complete line can cover a leaf of another complete line. Also, any 𝜆-subgraph that covers a leaf of a complete line can also cover the whole incomplete line. Therefore, this graph can be covered by b 𝜆-subgraphs but no less. Assume that q covers G, i.e. 𝑝𝑖>0,∀𝑖∈[𝑛], and let us focus on the set 𝑉𝑐𝑜𝑚 of leaves of the complete lines of G, where |𝑉𝑐𝑜𝑚|=𝑏 as argued earlier, and denote 𝑉𝑐𝑜𝑚 by [b]. Consider the vertex probabilities 𝑝𝑖, 𝑖∈[𝑏], and note that ∑𝑖∈[𝑏]𝑝𝑖≤1 where strict inequality holds for the case where there exists some pure strategy 𝐿𝑗∈𝑠𝑢𝑝𝑝(𝑞) such that 𝐿𝑗∩𝑉𝑐𝑜𝑚=∅. Then for 𝑝′:=min𝑖∈[𝑏]𝑝𝑖 it holds that 𝑝′≤1/𝑏, otherwise 𝑝𝑖>1/𝑏, ∀𝑖∈[𝑏] and therefore ∑𝑖∈[𝑏]𝑝𝑖>1 which is a contradiction. Also, for 𝑝𝑖=1/𝑏, ∀𝑖∈[𝑏], it is 𝑝′=1/𝑏, which yields 𝑝∗(𝐺):=max𝑞∈𝛥𝜃𝑝′=1/𝑏.

Case 2: 𝜆 is odd. In this case 𝜎=(𝜆+1)/2 and the diameter of G equals 𝜆+1, therefore no 𝜆-subgraph that covers a leaf of a complete line can also cover a leaf of another complete line.

Subcase (a): 𝜎−(𝑛−1−𝑏⋅𝜎)≠1. Any 𝜆-subgraph that covers a leaf of a complete line can cover the whole incomplete line. Therefore, this graph can be covered with b 𝜆-subgraphs but no less. Following the analysis of Case 1, it is 𝑝∗(𝐺):=max𝑞∈𝛥𝜃𝑝′=1/𝑏.

Subcase (b): 𝜎−(𝑛−1−𝑏⋅𝜎)=1. No 𝜆-subgraph that covers a leaf of a complete line can cover the leaf of the incomplete line. Therefore, this graph can be covered by 𝑏+1 𝜆-subgraphs but no less. Following similar analysis as that of Case 1, where instead of 𝑉𝑐𝑜𝑚 we have 𝑉𝑐𝑜𝑚∪{𝑣𝑖𝑛𝑐} where 𝑣𝑖𝑛𝑐 is the leaf of the incomplete line, and instead of b we have 𝑏+1, we conclude that 𝑝∗(𝐺):=max𝑞∈𝛥𝜃𝑝′=1/(𝑏+1).

For Case 1, and Case 2(a), since each of the leaves of the b complete lines have vertex-probability 1/b, the defense strategy 𝑞∗ with probability 𝑞∗𝑖=1/𝑏 assigned to the respective pure defense strategy 𝐿𝑖,𝑖∈[𝑏] that contains vertex 𝑖∈[𝑏], yields 𝑝∗(𝐺). For Case 2(b), since each of the leaves of the b complete lines and the leaf 𝑣𝑖𝑛𝑐 of the incomplete line have vertex-probability 1/(𝑏+1), the defense strategy 𝑞∗ with probability 𝑞∗𝑖=1/(𝑏+1) assigned to the respective pure strategy 𝐿𝑖,𝑖∈[𝑏]∪{𝑣𝑖𝑛𝑐} that contains vertex 𝑖∈[𝑏]∪{𝑣𝑖𝑛𝑐}, yields 𝑝∗(𝐺).

By the above values of 𝑝∗(𝐺) and Lemma 1, the proof of the theorem is complete. ◻

Corollary 5
For any given n and 2≤𝜆≤𝑛−1, it holds that ⌊2(𝑛−1)𝜆+1⌋≤PoD(𝜆)≤2(𝑛−1)+𝜆−1𝜆. Furthermore, for the trivial cases 𝜆∈{1,𝑛} it is PoD(1)=𝑛 and PoD(𝑛)=1.

Proof
The lower bound is established by Theorem 7. The upper bound is due to Theorem 6. For the cases 𝜆=1 and 𝜆=𝑛, observe that the defender’s action set is 𝐷={{𝑖}|𝑖∈𝑉} and 𝐷={𝑉} respectively, therefore 𝑝∗(𝐺)=1/𝑛 and 𝑝∗(𝐺)=1 respectively, and again from Lemma 1 we get the values in the statement of the corollary. ◻

Conclusion and Open Problems
Our results extend the line of work by Mavronicolas et al. [11] on defense games in graphs. In these games, we have generalized the pure strategy of the defender to be a connected induced subgraph of the underlying graph of size 𝜆 instead of two adjacent vertices. We termed these new games Connected Subgraph Defense (CSD) games and studied the structure of equilibria and the complexity of finding one, depending on the power of the defender 𝜆. We also extended the notion of Price of Defense, as termed in [11], for any 𝜆 and found almost tight bounds for its value.

An interesting open problem is the following. For 𝜆 that is both more than constantly away from 1 and n, our LP-based algorithm for computing a Nash equilibrium is not efficient. That is because in that case, our algorithm considers the strategy space of the defender to have cardinality (𝑛𝜆) and brute forces through all of that space. Is there a polynomial time algorithm for computing a Nash equilibrium when 𝜆∈𝜔(1)∩𝑜(𝑛)? Another open problem is to determine the complexity of deciding whether a general graph is defense-optimal. We conjecture that it is 𝙽𝙿-hard.