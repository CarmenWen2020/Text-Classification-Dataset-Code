We propose a general scheme to compute tree-based data structures on arbitrary networks. This scheme is self-stabilizing, silent, and despite its generality, also efficient. It is written in the locally shared memory model with composite atomicity assuming the distributed unfair daemon, the weakest scheduling assumption of the model. Its stabilization time is in at most 4𝑛𝚖𝚊𝚡𝙲𝙲 rounds, where 𝑛𝚖𝚊𝚡𝙲𝙲 is the maximum number of processes in any connected component of the network. We illustrate the versatility and efficiency of our approach by proposing several instantiations solving classical spanning tree problems such as DFS, BFS, shortest-path, or unconstrained spanning tree/forest constructions, as well as other fundamental problems like leader election or finding maximum-bottleneck-bandwidth paths. We also exhibit polynomial upper bounds on its stabilization time in steps and process moves, holding for a large class of instantiations. In several cases, the polynomial step and move complexities we obtain for those instantiations match the best known complexities of existing algorithms, despite the latter being dedicated to particular problems. Furthermore, a significant set of instantiations of our scheme requires only bounded memory space per process. This set includes, but is not limited to, DFS, BFS, and shortest-path spanning tree constructions.

Access provided by University of Auckland Library

Introduction
A self-stabilizing algorithm [30] is able to recover a correct behavior in finite time, regardless of the arbitrary initial configuration of the system, and therefore also after a finite number of transient faults, provided that those faults do not alter the code of the processes. Self-stabilization makes no hypotheses on the nature (e.g., memory corruption or topological changes) or extent of transient faults that could hit the system. A self-stabilizing system recovers from the effects of those faults in an unified manner. Now, such versatility comes at a price, e.g., after transient faults cease, there is a finite time period, called the stabilization phase, during which the safety properties of the system are not guaranteed. Hence, self-stabilizing algorithms are mainly compared according to their stabilization time, the maximum duration of the stabilization phase.

Among the vast self-stabilizing literature, many works (see [38] for a survey) focus on tree-based constructions, i.e., constructions of specific distributed spanning tree—or forest—shaped data structures. Most of these constructions actually achieve an additional property called silence [32]: a silent self-stabilizing algorithm converges within finite time to a configuration from which the values of the communication registers used by the algorithm remain fixed. Silence is a desirable property. Indeed, as noted in [32], the silent property usually implies more simplicity in the algorithm design. Moreover, a silent algorithm may utilize less communication operations and communication bandwidth.

Self-stabilizing tree-based constructions are widely used as a basic building block of more complex self-stabilizing solutions. Indeed, composition is a natural way to design self-stabilizing algorithms [47] since it allows to simplify both the design and proofs of self-stabilizing algorithms. Various composition techniques have been introduced so far, e.g., collateral composition [37], fair composition [31], cross-over composition [4], and conditional composition [22]; and many self-stabilizing algorithms are actually made as a composition of a silent tree-based construction and another algorithm designed for tree/forest topologies, e.g. [3, 7, 21]. Notably, the silence property is not mandatory in such designs, however it allows to write simpler proofs [23]. Finally, notice that silent tree-based constructions have also been used to build very general results, e.g., the self-stabilizing proof-labeling scheme constructions proposed in [6].

We consider here the locally shared memory model with composite atomicity introduced by Dijkstra [2, 30], which is the most commonly used model in self-stabilization. In this model, executions proceed in atomic steps (in which a subset of enabled processes move, i.e., update their local states), and the asynchrony of the system is captured by the notion of daemon. The weakest (i.e., the most general) daemon is the distributed unfair daemon. Hence, solutions stabilizing under such an assumption are highly desirable, because they work under any daemon assumption.

The stabilization time of self-stabilizing algorithms is usually evaluated in terms of rounds, which capture the execution time according to the speed of the slowest processes. However, another crucial issue is the number of local state updates, i.e., the number of moves. Indeed, the stabilization time in moves captures the amount of computations an algorithm needs in order to recover a correct behavior. Notice that the number of moves and the number of (atomic) steps are closely related: if an execution e contains x steps, then the number y of moves in e satisfies 𝑥≤𝑦≤𝑛⋅𝑥, where n is the number of processes.Footnote1

The daemon assumption and the time complexity are closely related. Indeed, to obtain practical solutions, the designer usually tries to avoid strong assumptions on the daemon, like for example, assuming that all executions are synchronous. Now, when the considered daemon does not enforce any bound on the execution time of processes, the stabilization time in moves (resp. in steps) can be bounded only if the algorithm works under an unfair daemon. For example, if the daemon is assumed to be distributed and weakly fair (a daemon stronger than the distributed unfair one) and the studied algorithm actually requires the weakly fairness assumption to stabilize, then it is possible to construct executions whose convergence is arbitrarily long in terms of atomic steps (and so in moves), meaning that, in such executions, there are processes whose moves do not make the system progress in the convergence. In other words, these latter processes waste computation power and so energy. Such a situation should be therefore prevented, making the unfair daemon more desirable than the weakly fair one.

There are many self-stabilizing algorithms proven under the distributed unfair daemon, e.g. [1, 9, 24, 25, 34]. However, analyses of the stabilization time in steps, or moves, remain rather unusual and this may be an important issue. Indeed, recently, several self-stabilizing algorithms working under a distributed unfair daemon have been shown to have an exponential stabilization time in steps in the worst case. In [1], silent leader election algorithms from [24, 25] are shown to be exponential in steps in the worst case. In [29], the Breadth-First Search (BFS) algorithm of Huang and Chen [39] is also shown to be exponential in steps. Finally, in [35] authors show that the silent self-stabilizing algorithm they proposed in [34] is also exponential in steps.

Contribution. In this paper, we propose a general scheme to compute tree-based data structures on bidirectional weighted networks of arbitrary topology (n.b., the topologies are not necessarily connected). This algorithm is self-stabilizing and silent. It is written in the locally shared memory model with composite atomicity, assuming the distributed unfair daemon.

Despite its versatility, our scheme is efficient. Indeed, its stabilization time is at most 4𝑛𝚖𝚊𝚡𝙲𝙲 rounds, where 𝑛𝚖𝚊𝚡𝙲𝙲 is the maximum number of processes in a connected component. Moreover, its stabilization time in moves (and so in steps) is polynomial in usual cases; see the example instantiations we propose. Precisely, we exhibit polynomial upper bounds on its stabilization time in moves that depend on the particular problems we consider.

To illustrate the versatility and efficiency of our approach, we propose several instantiations for solving classical tree-based problems.

Assuming an input set of roots, we propose an instantiation to compute a spanning forest of arbitrary shaped trees, with non-rooted components detection.Footnote2 This instantiation stabilizes in 𝑂(𝑛𝚖𝚊𝚡𝙲𝙲⋅𝑛) moves, which matches the best known step complexity for spanning tree construction [13] with explicit parent pointers.Footnote3

Assuming then a rooted network with positive integer weights, we propose shortest-path spanning tree and DFS constructions, with non-rooted components detection. The shortest-path spanning tree construction stabilizes in 𝑂(𝑛𝚖𝚊𝚡𝙲𝙲3⋅𝑛⋅𝚆max) moves, where 𝚆max is the maximum weight of an edge. This move complexity matches the best known move complexity for this problem [27].

Assuming now that the network is identified (i.e., processes have distinct IDs), we propose two instantiations for electing a leader in each connected component and building a spanning tree rooted at each leader. In one version, stabilizing in 𝑂(𝑛𝚖𝚊𝚡𝙲𝙲2⋅𝑛) moves, the trees are of arbitrary topology. This move complexity matches the best known step complexity for leader election [1]. In the other version, stabilizing in 𝑂(𝑛𝚖𝚊𝚡𝙲𝙲3⋅𝑛) moves, the leader is guaranteed to be the process of minimal identifier in the connected component, and trees are BFS.

Finally, assuming a rooted network with a bandwidth assigned to each edge, we propose an instantiation computing for each process the maximum bottleneck bandwidth to the root, and a corresponding path (with the fewest edges).

Besides, most of these instantiations can be set to require only bounded memory (at the price of providing to the processes some knowledge about the graph topology; typically an upper bound on the number of processes). Furthermore, one can easily derive from these various examples other silent self-stabilizing tree-based constructions. A comparison table between some instances of our scheme and solutions from the literature is given in Table 1.

Table 1 Comparison between the stabilization time of some instances of our scheme and solutions from the literature (to be fair, we have replaced 𝑛𝚖𝚊𝚡𝙲𝙲 by n when the paper from the literature assumes a connected network)
Full size table
Related Work. This work is inspired by [27]. This paper also considers the composite atomicity model under the distributed unfair daemon. The proposed algorithm is efficient both in terms of rounds and moves, tolerates disconnections, but is restricted to the case of the shortest-path tree in a rooted network. Generalizing this work to obtain a generic yet efficient self-stabilizing algorithm requires a fine tuning of the algorithm (presented in Sect. 3) and a careful rewriting of the proofs of correctness (presented in the remaining sections). In particular, almost all the concepts used to prove termination or complexities need to be redefined to suit the new, more general setting. Consequently, their new properties and the corresponding proofs are mostly novel.

Another closely related work is the one of Cobb and Huang [11]. In that paper, a generic self-stabilizing algorithm is presented for constructing in a rooted connected network a spanning tree where a given metric is maximized. Now, since the network is assumed to be rooted (i.e., a leader process is already known), leader election is not an instance of their generic algorithm. Similarly, since they assume connected networks, the non-rooted components detection cannot be expressed too. Finally, their algorithm is proven in the composite atomicity model yet assuming a strong scheduling assumption: the sequential weakly fair daemon.

General schemes for arbitrary connected and identified networks have been proposed to transform almost any algorithm (specifically, those algorithms that can be self-stabilized) into its corresponding stabilizing version [8, 14, 36, 41]. Such universal transformers are, by essence, inefficient both in terms of space and time complexities: their purpose is only to demonstrate the feasibility of the transformation. In [41] and [8], authors respectively consider self-stabilization in asynchronous message-passing systems and in the synchronous locally shared memory model, while expressiveness of snap-stabilization is studied in [14, 36] assuming the locally shared memory model with composite atomicity and a distributed unfair daemon.

In [26, 33], the authors propose a method to design silent self-stabilizing algorithms for a class of fix-point problems, namely fix-point problems which can be expressed using r-operators. Their solution works in directed networks using bounded memory per process. In [33], they consider the locally shared memory model with read/write atomicity, while in [26], they generalize their approach to asynchronous message-passing systems. In both papers, they establish a stabilization time in 𝑂(𝐷+|𝕊|) rounds, where D is the network diameter and 𝕊 is the set on which the r-operator applies. However, this bound is actually proven for the synchronous case only.

The remainder of the related work only concerns the locally shared memory model with composite atomicity assuming a distributed unfair daemon. In [6], authors use the concept of labeling scheme introduced by Korman et al. [42] to design silent self-stabilizing algorithms with bounded memory per process. Using this approach, they show that every static task has a silent self-stabilizing algorithm which converges within a linear number of rounds in an arbitrary identified network. No step (nor move) complexity is given.

Efficient and general schemes for snap-stabilizing (non silent) waves in arbitrary connected and rooted networks are investigated in [17]. The obtained snap-stabilizing algorithms execute each wave in a polynomial number of rounds and steps.

Few other works consider the design of particular tree-based constructions and their step complexity. Self-stabilizing algorithms that construct BFS trees in arbitrary connected and rooted networks are proposed in [18, 19]. The algorithm in [18] is not silent and has a stabilization time in 𝑂(𝛥⋅𝑛3) steps, where 𝛥 is the maximum degree of the network. The silent algorithm given in [19] has a stabilization time in 𝑂(𝐷2) rounds and 𝑂(𝑛6) steps. Silent self-stabilizing algorithms that construct spanning trees of arbitrary topologies in arbitrary connected and rooted networks are given in [13, 43]. The solution proposed in [13] stabilizes in at most 4⋅𝑛 rounds and at most 5⋅𝑛2 steps, while the algorithm given in [43] stabilizes in at most 𝑛⋅𝐷 moves. However, the round complexity of this latter algorithm is not analyzed, and the parent of a process is not computed explicitly. Furthermore, Cournier [20] showed that the straightforward variant of this algorithm where a parent pointer variable is added has a stabilization time in 𝛺(𝑛2⋅𝐷) steps in an infinite class of networks.

Several other papers propose self-stabilizing algorithms stabilizing in both a polynomial number of rounds and a polynomial number of steps, e.g. [1] (for the leader election in arbitrary identified and connected networks), and [15, 16] (for the DFS token circulation in arbitrary connected and rooted networks). The silent leader election algorithm proposed in [1] stabilizes in at most 3⋅𝑛+𝐷 rounds and 𝑂(𝑛3) steps. The DFS token circulations given in [15, 16] execute each wave in O(n) rounds and 𝑂(𝑛2) steps using 𝑂(𝑛⋅log𝑛) space per process for the former, and 𝑂(𝑛3) rounds and 𝑂(𝑛3) steps using 𝑂(log𝑛) space per process for the latter. Note that in [15], processes are additionally assumed to be identified.

Roadmap. In the next section, we present the computational model and basic definitions. In Sect. 3, we describe our general scheme. Its proof of correctness is given in Sect. 4. A complexity analysis in moves is presented in Sect. 5, whereas an analysis of the stabilization time in rounds is proposed in Sect. 6. Various instantiations with their specific complexity analyses are presented in Sect. 7. Finally, we make concluding remarks in Sect. 8.

Preliminaries
We consider distributed systems made of 𝑛≥1 interconnected processes. Each process can directly communicate with a subset of other processes, called its neighbors. Communication is assumed to be bidirectional. Hence, the topology of the system is conveniently represented as a simple undirected graph 𝐺=(𝑉,𝐸), where V is the set of processes and E the set of edges, representing communication links. Every (undirected) edge {𝑢,𝑣} actually consists of two arcs: (u, v) (i.e., the directed link from u to v) and (v, u) (i.e., the directed link from v to u). For every process u, we denote by 𝑉𝑢 the set of processes (including u) in the same connected component of G as u. In the following, 𝑉𝑢 is simply referred to as the connected component of u. We denote by 𝑛𝚖𝚊𝚡𝙲𝙲 the maximum number of processes in a connected component of G. By definition, 𝑛𝚖𝚊𝚡𝙲𝙲≤𝑛.

Every process u can distinguish its neighbors using a local labeling of a given datatype Lbl. All labels of u’s neighbors are stored into the set 𝛤(𝑢). Moreover, we assume that each process u can identify its local label 𝛼𝑢(𝑣) in the set 𝛤(𝑣) of each neighbor v. Such labeling is called indirect naming in the literature [46]. When it is clear from the context, we use, by an abuse of notation, u to designate both the process u itself, and its local labels (i.e., we simply use u instead of 𝛼𝑢(𝑣) for 𝑣∈𝛤(𝑢)). Let 𝛿𝑢=|𝛤(𝑢)| be the degree of process u. The maximal degree of G is 𝛥=max𝑢∈𝑉𝛿𝑢.

We use the composite atomicity model of computation [2, 30] in which processes communicate using a finite number of locally shared registers, called variables. In one indivisible move, each process can read its own variables and that of its neighbors, performs local computation, and may change only its own variables. The state of a process is defined by the values of its local variables. A configuration of the system is a vector consisting of the states of each process.

A distributed algorithm consists of one local program per process. The program of each process consists of a finite set of rules of the form

𝑙𝑎𝑏𝑒𝑙 : 𝑔𝑢𝑎𝑟𝑑→ 𝑎𝑐𝑡𝑖𝑜𝑛
Labels are only used to identify rules in the reasoning. A guard is a Boolean predicate involving the state of the process and that of its neighbors. The action part of a rule updates the state of the process. A rule can be executed only if its guard evaluates to true; in this case, the rule is said to be enabled. By extension, a process is said to be enabled if at least one of its rules is enabled. We denote by Enabled(𝛾) the subset of processes that are enabled in configuration 𝛾.

When the configuration is 𝛾 and Enabled(𝛾)≠∅, a non-empty set ⊆Enabled(𝛾) is selected by a so-called daemon; then every process of  atomically executes one of its enabled rules, leading to a new configuration 𝛾′. The atomic transition from 𝛾 to 𝛾′ is called a step. We also say that each process of  executes an action or simply moves during the step from 𝛾 to 𝛾′. The possible steps induce a binary relation over , denoted by ↦. An execution is a maximal sequence of configurations 𝑒=𝛾0𝛾1⋯𝛾𝑖⋯ such that 𝛾𝑖−1↦𝛾𝑖 for all 𝑖>0. The term “maximal” means that the execution is either infinite, or ends at a terminal configuration in which no rule is enabled at any process.

As explained before, each step from a configuration to another is driven by a daemon. We define a daemon as a predicate over executions. We say that an execution e is an execution under the daemon S if S(e) holds. In this paper we assume that the daemon is distributed and unfair. “Distributed” means that while the configuration is not terminal, the daemon should select at least one enabled process, maybe more. “Unfair” means that there is no fairness constraint, i.e., the daemon might never select an enabled process unless it is the only enabled process. In other words, the distributed unfair daemon corresponds to the predicate true, i.e., this is the most general daemon.

In the composite atomicity model, an algorithm is silent if all its possible executions are finite. Hence, we can define silent self-stabilization as follows.

Definition 1
(Silent Self-Stabilization) Let  be a non-empty subset of configurations, called the set of legitimate configurations. A distributed system is silent and self-stabilizing under the daemon S for  if and only if the following two conditions hold:

all executions under S are finite, and

all terminal configurations belong to .

Three main units of measurement are used to evaluate time complexity in our model: the number of moves, steps, and rounds. The definition of a round uses the concept of neutralization: a process v is neutralized during a step 𝛾𝑖↦𝛾𝑖+1, if v is enabled in 𝛾𝑖 but not in configuration 𝛾𝑖+1, and does not execute any action in the step 𝛾𝑖↦𝛾𝑖+1. Then, the rounds are inductively defined as follows. The first round of an execution 𝑒=𝛾0𝛾1⋯ is the minimal prefix 𝑒′=𝛾0⋯𝛾𝑗 such that every process that is enabled in 𝛾0 either executes an action or is neutralized during a step of 𝑒′. Let 𝑒″ be the suffix 𝛾𝑗𝛾𝑗+1⋯ of e. The second round of e is the first round of 𝑒″, and so on.

The stabilization time of a silent self-stabilizing algorithm is the maximum time (in moves, steps, or rounds) over every execution possible under the considered daemon (starting from any initial configuration) to reach a terminal (legitimate) configuration.

Finally, a self-stabilizing algorithm requires bounded memory space if there exists a finite set S such that, along any execution from any configuration in which the states belong to S, all the reached states of any process u still belong to S.

Algorithm 𝖳𝖻𝖢
The Problem
We propose a general silent self-stabilizing algorithm, called 𝖳𝖻𝖢 (stands for Tree-based Constructions), which aims at converging to a terminal configuration where a specified spanning forest (maybe a single spanning tree) is (distributedly) defined. The various definitions used in 𝖳𝖻𝖢 and its code are respectively summarized and formally given in Fig. 1 and Algorithm 1. Furthermore, a (slightly simplified) version of 𝖳𝖻𝖢 has been implemented in Java and some instantiations can be simulated and visualized [40]. We invite the reader to use this tool to facilitate its understanding of the paper.

In this algorithm, each process u has threeFootnote4 constant inputs.

𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡𝑢: a Boolean value, which is true if u is allowed to be the root of a tree. In this case, u is called a candidate. In a terminal configuration, every tree root satisfies 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡, but the converse is not necessarily true. Moreover, for every connected component , if there is at least one candidate 𝑢∈, then every process of  should belong to a tree (so there is at least one tree root in ) in any terminal configuration. If there is no candidate in a connected component, we require that all processes of the component converge to a particular terminal state expressing the local detection of the absence of candidates.

𝑝𝑛𝑎𝑚𝑒𝑢: the name of u. 𝑝𝑛𝑎𝑚𝑒𝑢∈𝐼𝐷𝑠, where 𝐼𝐷𝑠=ℕ∪{⊥} is totally ordered by < and min<(𝐼𝐷𝑠)=⊥. The value of 𝑝𝑛𝑎𝑚𝑒𝑢 is problem dependent. Actually, we consider two particular cases of naming. In one case, ∀𝑣∈𝑉,𝑝𝑛𝑎𝑚𝑒𝑣=⊥. In the other case, ∀𝑢,𝑣∈𝑉,𝑝𝑛𝑎𝑚𝑒𝑢≠⊥∧(𝑢≠𝑣⇒𝑝𝑛𝑎𝑚𝑒𝑢≠𝑝𝑛𝑎𝑚𝑒𝑣), i.e., 𝑝𝑛𝑎𝑚𝑒𝑢 is a unique global identifier.

𝑑𝑖𝑠𝑡𝑅𝑜𝑜𝑡𝑢: a distance belonging to 𝐷𝑖𝑠𝑡𝑆𝑒𝑡 whose description is given below. The value 𝑑𝑖𝑠𝑡𝑅𝑜𝑜𝑡𝑢 is the distance value that the candidate u should take when it is a tree root; see the variable 𝑑𝑢 below.

Every tree is based on some kind of distance. We denote by 𝐷𝑖𝑠𝑡𝑆𝑒𝑡 the distance domain. We use distances to detect cycles. However, according to the specific problem we consider, we may also want to minimize the weight of the trees using the distances. Distances are computed using weights on arcs. Each edge {𝑢,𝑣} has then two weights belonging to 𝐷𝑖𝑠𝑡𝑆𝑒𝑡: 𝜔𝑢(𝑣) denotes the weight of the arc (u, v), and 𝜔𝑣(𝑢) denotes the weight of the arc (v, u). More precisely, we need an ordered magma (𝐷𝑖𝑠𝑡𝑆𝑒𝑡,⊕,≺), i.e., ⊕ is a closed binary operation on 𝐷𝑖𝑠𝑡𝑆𝑒𝑡 and ≺ is a total order on this set. The definition of (𝐷𝑖𝑠𝑡𝑆𝑒𝑡,⊕,≺) is problem dependent. Predicates 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢), 𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢), and 𝑃_𝑡𝑜𝐵𝑒𝐶 used in the algorithm are also problem dependent; see Fig. 1. If a process u satisfies 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) or 𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢), then u is required to minimize the weight of its tree. This minimization uses the ordered magma and the problem dependent constant 𝑑𝑖𝑠𝑡𝑅𝑜𝑜𝑡𝑢.

We assume that, for every arc (u, v) of G and for every values 𝑑1 and 𝑑2 in 𝐷𝑖𝑠𝑡𝑆𝑒𝑡, we have

𝑑1≺𝑑1⊕𝜔𝑢(𝑣), and

if 𝑑1≺𝑑2, then 𝑑1⊕𝜔𝑢(𝑣)⪯𝑑2⊕𝜔𝑢(𝑣).

Finally, for every integer 𝑖≥0, we define 𝑑1⊕(𝑖⋅𝑑2) as follows:

𝑑1⊕(0⋅𝑑2)≡𝑑1

𝑑1⊕(𝑖⋅𝑑2)≡(𝑑1⊕((𝑖−1)⋅𝑑2))⊕𝑑2 if 𝑖>0.

The Variables
In 𝖳𝖻𝖢, each process u maintains the following three variables.

𝑠𝑡𝑢∈{𝐼,𝐶,𝐸𝐵,𝐸𝐹}: this variable gives the status of the process. I, C, EB, and EF respectively stand for Isolated, Correct, Error Broadcast, and Error Feedback. The first two status, I and C, are involved in the normal behavior of the algorithm, while the two other ones, EB and EF, are used during the error correction. The meaning of EB and EF will be further detailed in Sect. 3.4. In a terminal configuration, if 𝑉𝑢 contains a candidate, then 𝑠𝑡𝑢=𝐶, otherwise 𝑠𝑡𝑢=𝐼.

𝑝𝑎𝑟𝑢∈{⊥}∪𝐿𝑏𝑙: In a terminal configuration, if 𝑉𝑢 contains a candidate, then either 𝑝𝑎𝑟𝑢=⊥, i.e., u is a tree root, or 𝑝𝑎𝑟𝑢 belongs to 𝛤(𝑢), i.e., 𝑝𝑎𝑟𝑢 designates a neighbor of u, referred to as its parent. Otherwise (𝑉𝑢 does not contain a candidate), the value of 𝑝𝑎𝑟𝑢 is meaningless.

𝑑𝑢∈𝐷𝑖𝑠𝑡𝑆𝑒𝑡: In a terminal configuration, if 𝑉𝑢 contains a candidate, then 𝑑𝑢 is larger than or equal to the weight of the tree path from u to its tree root, otherwise the value of 𝑑𝑢 is meaningless.

Typical Execution
Assume that the system starts from a configuration where, for every process u, 𝑠𝑡𝑢=𝐼. All processes that belong to a connected component containing no candidates are disabled forever.

Focus now on a connected component  where at least one process is a candidate. Then, any process u of status I that is a candidate or that satisfies the predicate 𝑃_𝑡𝑜𝐵𝑒𝐶 (this latter case cannot occur during the first step) is enabled to execute rule 𝐑𝐑. If selected by the daemon, it executes 𝐑𝐑(𝑢) to initiate a tree or to join a tree rooted at some candidate, choosing among the different possibilities the one that minimizes its distance value. Using this rule, it also switches its status to C and sets 𝑑𝑢 to 𝑑𝑖𝑠𝑡𝑅𝑜𝑜𝑡𝑢, or to 𝑑𝑣⊕𝜔𝑢(𝑣) if it chooses a parent v. In order to more precisely describe what happens, we focus on the two possible definitions of 𝑃_𝑡𝑜𝐵𝑒𝐶; see Fig. 1.

Case 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢)≡(∃𝑣∈𝛤(𝑢)∣𝑠𝑡𝑣=𝐶). Executions of rule 𝐑𝐑 are asynchronously propagated in  until all processes of  have status C. In parallel, rules 𝐑𝐔 are executed to reduce the weight of the trees, if necessary: when a process u with status C satisfies 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢), resp. 𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢), this means that u can reduce 𝑑𝑢 by selecting another neighbor with status C as parent, resp. by becoming a root, and this reduction is required by the specification of the problem to be solved (𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) and 𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) are problem dependent). If only 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) is satisfied, then u chooses as parent the neighbor which allows to minimize the value of 𝑑𝑢. In particular, a candidate u may lose its tree root condition if it finds a sufficiently suitable parent in its neighborhood. If only 𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) is satisfied, then u becomes a root. Finally, if both predicates are satisfied, u chooses among the two possibilities the one which minimizes the new value of 𝑑𝑢. Hence, the system eventually reaches a terminal configuration, where a specific spanning forest (maybe a single spanning tree) is defined (in a distributed manner) in every connected component containing at least one candidate, while all processes are isolated in the other components.

Case 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢)≡(∃𝑣∈𝛤(𝑢)∣𝑠𝑡𝑣=𝐶)∧(𝑑𝑖𝑠𝑡𝑁𝑒𝑖𝑔ℎ(𝑢)∈𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒). In that case, the variable 𝑑𝑢 is restricted to belong to 𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒, and thus the algorithm has bounded memory space. Note that we further require in this case that 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)≡𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑢)∧𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢); see Fig. 1. Therefore, rules 𝐑𝐔 are always enabled to reduce the weight of the trees if choosing some neighbor as parent makes the value of 𝑑𝑢 decrease (while keeping it in 𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒). Once the distance values are minimized, for any process u having status C in , we have 𝑑𝑢=𝑑𝑝𝑎𝑟𝑢⊕𝜔𝑢(𝑝𝑎𝑟𝑢). So, the distance of any process u having status C in  and at depth i in its tree belongs to ∪0≤𝑗≤𝑖𝑑𝑖𝑠𝑡𝐶𝑂𝑘(𝑗). Hence, all processes of  have the status C, or 𝐑𝐑 is enabled at some processes with a status different from C. Eventually the system reaches a terminal configuration, where every process of  has the status C and verifies ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(⋅).

Error Correction
Assume now that the system is in an arbitrary configuration. Inconsistencies between the states of neighboring processes are detected using Predicate 𝑃_𝑎𝑏𝑅𝑜𝑜𝑡. We call abnormal root any process u satisfying 𝑃_𝑎𝑏𝑅𝑜𝑜𝑡(𝑢). Informally (see the formal definition in Algorithm 1), a process u is an abnormal root if u is neither a normal root (i.e., ¬𝑃_𝑟𝑜𝑜𝑡(𝑢) holds), nor isolated (i.e. 𝑠𝑡𝑢≠𝐼), and satisfies one of the following three conditions:

1.
its parent pointer does not designate a neighbor,

2.
its distance 𝑑𝑢 is inconsistent with the distance of its parent, or

3.
its status is inconsistent with the status of its parent.

Every process u that is neither an abnormal root nor isolated satisfies one of the two following cases. Either u is a normal root (i.e., 𝑃_𝑟𝑜𝑜𝑡(𝑢) holds) or u points to some neighbor (i.e., 𝑝𝑎𝑟𝑢∈𝛤(𝑢)), and the state of u is coherent w.r.t. the state of its parent. In this latter case, 𝑢∈𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑝𝑎𝑟𝑢), i.e., u is a “real” child of its parent; see Sect. 3.5 for the formal definition.

Consider a path =𝑢0,…,𝑢𝑘 such that, for every 0≤𝑖<𝑘, 𝑢𝑖+1∈𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑢𝑖).  is acyclic. If 𝑢0 is either a normal or an abnormal root, then  is called a branch rooted at 𝑢0. Let u be a root (either normal or abnormal). We define the tree T(u) as the set of all processes that belong to a branch rooted at u. If u is a normal root, then T(u) is said to be a normal tree, otherwise u is an abnormal root and T(u) is said to be an abnormal tree. We call any configuration without abnormal trees a normal configuration. So, to recover a normal configuration, it is necessary to remove all abnormal trees.

For each abnormal tree T, we have two cases. If the abnormal root u of T can join another tree 𝑇′ using rule 𝐑𝐔(𝑢) (thus decreasing its distance value, since, in this case, 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) or 𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) must hold), then it does so and T disappears by becoming a subtree of 𝑇′. Otherwise, T is entirely removed in a top-down manner, starting from its abnormal root u. Now, in that case, we have to prevent the following situation: u leaves T; this removal creates some abnormal trees, each of those being rooted at a previous child of u; and later u joins one of those (created) trees, or a tree issued from them. (This issue is sometimes referred to as the count-to-infinity problem [44]). Hence, the idea is to freeze T, before removing it. By freezing we mean assigning to each member of the tree an error state, here EB or EF, so that (1) no member v of the tree is allowed to execute 𝐑𝐔(𝑣), and (2) no process w can join the tree by executing 𝐑𝐑(𝑤) or 𝐑𝐔(𝑤). Once frozen, the tree can be safely deleted from its root to its leaves.

The freezing mechanism (inspired from [5]) is achieved using the status EB and EF, and the rules 𝐑𝐄𝐁 and 𝐑𝐄𝐅. If a process is not involved into any freezing operation, then its status is I or C. Otherwise, it has status EB or EF and no neighbor can select it as its parent. These two latter status are actually used to perform a “Propagation of Information with Feedback” [10, 45] in the abnormal trees. This is why status EB means “Error Broadcast” and EF means “Error Feedback”. From an abnormal root, the status EB is broadcast down in the tree using the rule 𝐑𝐄𝐁. Then, once the EB wave reaches a leaf, the leaf initiates a convergecast EF-wave using the rule 𝐑𝐄𝐅. Once the EF-wave reaches the abnormal root, the tree is said to be dead, meaning that all processes in the tree have status EF and, consequently, no other process can join it. So, the tree can be safely deleted from its abnormal root toward its leaves. There are several possibilities for the deletion depending on whether the process u to be deleted is a candidate or verifies 𝑃_𝑡𝑜𝐵𝑒𝐶. If u is a candidate and does not verify 𝑃_𝑡𝑜𝐵𝑒𝐶: u becomes a normal root by executing 𝐑𝐑(𝑢). If u verifies 𝑃_𝑡𝑜𝐵𝑒𝐶, again the rule 𝐑𝐑(𝑢) is executed: u tries to directly join another “alive” tree. However if u is a candidate, and becoming a normal root allows it to further minimize 𝑑𝑢, then it does so. If u is not a candidate and does not verify 𝑃_𝑡𝑜𝐵𝑒𝐶, the rule 𝐑𝐈(𝑢) is executed: u becomes isolated, but might still join another tree later.

Let u be a process belonging to an abnormal tree of which it is not the root. Let v be its parent. From the previous explanation, it follows that during the correction, (𝑠𝑡𝑣,𝑠𝑡𝑢)∈{(𝐶,𝐶), (EB, C),  (EB, EB),  (EB, EF),  (𝐸𝐹,𝐸𝐹)} until v resets by 𝐑𝐑(𝑣) or 𝐑𝐈(𝑣). Now, due to the arbitrary initialization, the status of u and v may not be coherent, in this case u is also an abnormal root. Precisely, as formally defined in Algorithm 1, the status of u is incoherent w.r.t. the status of its parent v if 𝑠𝑡𝑢≠𝑠𝑡𝑣 and 𝑠𝑡𝑣≠𝐸𝐵. For example, if a process u belongs to a tree (i.e., 𝑠𝑡𝑢≠𝐼) and designates an isolated process v with 𝑝𝑎𝑟𝑢 (i.e., 𝑝𝑎𝑟𝑢=𝑣 and 𝑠𝑡𝑣=𝐼), then the status of u is incoherent w.r.t. its parent v, i.e., u is an abnormal root.

Actually, the freezing mechanism ensures that if a process is the root of an alive abnormal tree, it is in that situation since the initial configuration; see Lemma 9, page 20. The bounded move complexity of our scheme mainly relies on this strong property.

Fig. 1
figure 1
Various inputs and definitions used in Algorithm 𝖳𝖻𝖢, for any process u

Full size image
figure a
Definitions
Before proceeding with the proof of correctness and the move complexity analysis, we define some useful concepts and give some of their properties.

Root, Child, and Branch
Definition 2
(Normal and Abnormal Roots) Every process u that satisfies 𝑃_𝑟𝑜𝑜𝑡(𝑢) is said to be a normal root. Every process u that satisfies 𝑃_𝑎𝑏𝑅𝑜𝑜𝑡(𝑢) is said to be an abnormal root.

Definition 3
(Alive Abnormal Root) A process u is said to be an alive abnormal root (resp. a dead abnormal root) if u is an abnormal root and has a status different from EF (resp. has status EF).

Definition 4
(Children) For every process v and for every process 𝑢∈𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑣), u is said to be a child of v. Conversely, v is said to be the parent of u.

Observation 1
A process u is either a normal root, an isolated process (i.e., 𝑠𝑡𝑢=𝐼), an abnormal root, or a child of its parent (i.e., member of the set 𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑣), where 𝑣=𝑝𝑎𝑟𝑢).

Definition 5
(Branch) A branch is a sequence of processes 𝑣0,…,𝑣𝑘, for some integer 𝑘≥0, such that 𝑣0 is a normal or an abnormal root and, for every 0≤𝑖<𝑘, we have  𝑣𝑖+1∈𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑣𝑖). The process 𝑣𝑖 is said to be at depth i and 𝑣𝑖,…,𝑣𝑘 is called a sub-branch. The depth of the branch is k. The process 𝑣0, resp. 𝑣𝑘, is said to be the initial extremity, resp. terminal extremity, of the branch. If 𝑣0 is an abnormal root, the branch is said to be illegal, otherwise, the branch is said to be legal.

Observation 2
A branch depth is at most 𝑛𝚖𝚊𝚡𝙲𝙲−1. A process v having status I does not belong to any branch. If a process v has status C (resp. EF), then all processes of a sub-branch starting at v have status C (resp. EF).

Lemma 1
Let 𝛾↦𝛾′ be a step. Let 𝑣0,…,𝑣𝑘 be an illegal branch in 𝛾 such that 𝑠𝑡𝑣0=𝐸𝐵 and 𝑠𝑡𝑣𝑘∈{𝐸𝐵,𝐸𝐹}. If 𝑣0 is still an alive abnormal root in 𝛾′, then 𝑣0,…,𝑣𝑘 is still an illegal branch such that 𝑠𝑡𝑣0=𝐸𝐵 and 𝑠𝑡𝑣𝑘∈{𝐸𝐵,𝐸𝐹} in 𝛾′.

Proof
By definition of an illegal branch, 𝑣𝑖+1∈𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑣𝑖) in 𝛾, for every 𝑖∈[0,𝑘). Now, since 𝑠𝑡𝑣0=𝐸𝐵 and 𝑠𝑡𝑣𝑘∈{𝐸𝐵,𝐸𝐹} in 𝛾, we have 𝑠𝑡𝑣0⋯𝑠𝑡𝑣𝑘∈𝐸𝐵+𝐸𝐹∗ in 𝛾, by definition of 𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(⋅). So only 𝐑𝐄𝐅 may be executed, by a single process 𝑣𝑖 with 𝑖∈[0,𝑘] in 𝛾↦𝛾′. Thus, for every 𝑖∈[0,𝑘), (𝑠𝑡𝑣𝑖,𝑠𝑡𝑣𝑖+1)∈{(𝐸𝐵,𝐸𝐵),(𝐸𝐵,𝐸𝐹),(𝐸𝐹,𝐸𝐹)} still holds in 𝛾′. Hence, in 𝛾′, 𝑠𝑡𝑣𝑘∈{𝐸𝐵,𝐸𝐹} and 𝑣𝑖+1∈𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑣𝑖), for every 𝑖∈[0,𝑘). This means that 𝑣0,…𝑣𝑘 is still an illegal branch in 𝛾′. Moreover, if 𝑣0 is still an alive abnormal root in 𝛾′, then 𝑠𝑡𝑣0=𝐸𝐵. ◻

Correctness of 𝖳𝖻𝖢
Legitimate Configurations
Definition 6
(Legitimate State) A process u is said to be in a legitimate state of 𝖳𝖻𝖢 if u satisfies one of the following conditions:

1.
𝑃_𝑟𝑜𝑜𝑡(𝑢), and ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢);

2.
there is a process satisfying 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡 in 𝑉𝑢, 𝑠𝑡𝑢=𝐶, 𝑝𝑎𝑟𝑢∈𝛤(𝑢), 𝑑𝑢⪰𝑑𝑝𝑎𝑟𝑢⊕𝜔𝑢(𝑝𝑎𝑟𝑢), and ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)∧¬𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢);

3.
there is no process satisfying 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡 in 𝑉𝑢 and 𝑠𝑡𝑢=𝐼.

Definition 7
(Legitimate Configuration) A legitimate configuration of 𝖳𝖻𝖢 is a configuration where every process is in a legitimate state.

Partial Correctness
We now prove that the terminal configurations are exactly the legitimate configurations. We first prove one of the two inclusions.

Lemma 2
Any legitimate configuration of 𝖳𝖻𝖢 is terminal.

Proof
Let 𝛾 be a legitimate configuration of 𝖳𝖻𝖢 and u be a process.

Assume first that there is no process of 𝑉𝑢 that satisfies 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡 in 𝛾. Then, by definition of 𝛾, every process v in 𝑉𝑢 satisfies 𝑠𝑡𝑣=𝐼. Hence, since ¬𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡𝑣∧𝑠𝑡𝑣=𝐼 for every process v in 𝑉𝑢, no rule of 𝖳𝖻𝖢 is enabled at any process of 𝑉𝑢 in 𝛾.

Assume then that there is a process that satisfies 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡 in 𝛾. Then, every process 𝑣∈𝑉𝑢 satisfies one of the first two conditions in Definition 6.

This in particular means that 𝑠𝑡𝑣=𝐶, for every 𝑣∈𝑉𝑢. Hence, 𝐑𝐄𝐅(𝑣), 𝐑𝐈(𝑣), and 𝐑𝐑(𝑣) are all disabled at every 𝑣∈𝑉𝑢 in 𝛾. Moreover, we have ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)∧¬𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) for every 𝑣∈𝑉𝑢 (if 𝑃_𝑟𝑜𝑜𝑡(𝑣) is satisfied, then 𝑃_𝑟𝑜𝑜𝑡𝑉𝑎𝑙𝑖𝑑(𝑣) and thus 𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑣) are not), which implies that 𝐑𝐔(𝑣) is disabled at every 𝑣∈𝑉𝑢 in 𝛾. Finally, 𝑠𝑡𝑣=𝐶∧[𝑃_𝑟𝑜𝑜𝑡(𝑣)∨(𝑝𝑎𝑟𝑣∈𝛤(𝑣)∧𝑑𝑣⪰𝑑𝑝𝑎𝑟𝑣⊕𝜔𝑣(𝑝𝑎𝑟𝑣))] for every 𝑣∈𝑉𝑢 implies ¬𝑃_𝑎𝑏𝑅𝑜𝑜𝑡(𝑣)∧𝑠𝑡𝑝𝑎𝑟𝑣≠𝐸𝐵 for every 𝑣∈𝑉𝑢, and so 𝐑𝐄𝐁(𝑣) is disabled at every 𝑣∈𝑉𝑢 in 𝛾. Hence, no rule of 𝖳𝖻𝖢 is enabled at any process of 𝑉𝑢 in 𝛾. ◻

The following technical lemmas will help us to prove that any terminal configuration of 𝖳𝖻𝖢 is legitimate.

Lemma 3
In any terminal configuration of 𝖳𝖻𝖢, every process has status I or C.

Proof
Assume that there exists some process that has status EB. Consider a process u with status EB having the maximum distance value. Note that no process v that has status C can be a child of u, otherwise 𝐑𝐔(𝑣) or 𝐑𝐄𝐁(𝑣) would be enabled. Therefore, by definition of 𝐶ℎ𝑖𝑙𝑑𝑟𝑒𝑛(𝑢) and the maximality of 𝑑𝑢, u has only children of status EF. Thus 𝐑𝐄𝐅(𝑢) is enabled, a contradiction.

Assume now that there exists some process that has status EF. Consider a process u with status EF having the smallest distance value. As no process has status EB (see the previous case), u is an abnormal root. Now, since u is an abnormal root of status EF, 𝑃_𝑟𝑒𝑠𝑒𝑡(𝑢) holds. So, either 𝐑𝐈(𝑢) or  𝐑𝐑(𝑢) is enabled, a contradiction. ◻

Lemma 4
Let 𝛾 be any terminal configuration of 𝖳𝖻𝖢 and u be any process such that 𝑠𝑡𝑢=𝐶 in 𝛾. Then, u satisfies 𝑃_𝑟𝑜𝑜𝑡(𝑢) or 𝑝𝑎𝑟𝑢∈𝛤(𝑢)∧𝑠𝑡𝑝𝑎𝑟𝑢=𝐶∧𝑑𝑢⪰𝑑𝑝𝑎𝑟𝑢⊕𝜔𝑢(𝑝𝑎𝑟𝑢) in 𝛾.

Proof
In 𝛾, u satisfies ¬𝑃_𝑎𝑏𝑅𝑜𝑜𝑡(𝑢) because, otherwise, either 𝐑𝐔(𝑢) or 𝐑𝐄𝐁(𝑢) would be enabled, as 𝑠𝑡𝑢=𝐶 in 𝛾. We can thus conclude by Observation 1 that u satisfies 𝑃_𝑟𝑜𝑜𝑡(𝑢) or 𝑝𝑎𝑟𝑢∈𝛤(𝑢)∧𝑠𝑡𝑝𝑎𝑟𝑢=𝐶∧𝑑𝑢⪰𝑑𝑝𝑎𝑟𝑢⊕𝜔𝑢(𝑝𝑎𝑟𝑢) in 𝛾. ◻

Corollary 1
Let 𝛾 be a terminal configuration of 𝖳𝖻𝖢 and u be any process such that 𝑠𝑡𝑢=𝐶 and ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑢) hold in 𝛾. Then, u satisfies 𝑃_𝑟𝑜𝑜𝑡(𝑢) or 𝑝𝑎𝑟𝑢∈𝛤(𝑢)∧𝑑𝑢=𝑑𝑝𝑎𝑟𝑢⊕𝜔𝑢(𝑝𝑎𝑟𝑢) in 𝛾. Moreover, if 𝑝𝑎𝑟𝑢∈𝛤(𝑢) and 𝑑𝑝𝑎𝑟𝑢∈𝑑𝑖𝑠𝑡𝐶𝑂𝑘(𝑖−1), then 𝑑𝑢∈𝑑𝑖𝑠𝑡𝐶𝑂𝑘(𝑖).

Definition 8
Let 𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎 be any instance of Algorithm 𝖳𝖻𝖢 where 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢)≡(∃𝑣∈𝛤(𝑢)∣𝑠𝑡𝑣=𝐶)∧(𝑑𝑖𝑠𝑡𝑁𝑒𝑖𝑔ℎ(𝑢)∈𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒).

Lemma 5
Let 𝛾 be a terminal configuration of 𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎 and u be any process such that 𝑠𝑡𝑢=𝐶 in 𝛾. Then, ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑢) holds in 𝛾.

Proof
Assume that one or several processes having status C verify the predicate 𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(⋅) in 𝛾. Let us consider such a process u that has the smallest distance 𝑑𝑢.

We have 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)≡𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑢)∧𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢). As 𝛾 is terminal, 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) is not verified : hence 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢) is not verified. By definition of u, a neighbor of u, named v, verifies 𝑑𝑣⊕𝜔𝑢(𝑣)=𝑑𝑖𝑠𝑡𝑁𝑒𝑖𝑔ℎ(𝑢)≺𝑑𝑢, and 𝑠𝑡𝑣=𝐶. Let 𝑣0,⋯,𝑣𝑘=𝑣 be the branch whose terminal extremity is v (n.b., by definition, for 0<𝑖≤𝑘, 𝑣𝑖−1∈𝛤[𝑣𝑖]). We have 𝑑𝑣𝑖≺𝑑𝑢, for 0≤𝑖≤𝑘; so ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑣𝑖) is verified. According to Corollary 1, 𝑃_𝑟𝑜𝑜𝑡(𝑣0) is verified and for 0≤𝑖≤𝑘, we have 𝑑𝑣𝑖∈𝑑𝑖𝑠𝑡𝐶𝑂𝑘(𝑖), Moreover u is not in this branch, so 𝑘≤𝑛−2. We conclude that 𝑑𝑖𝑠𝑡𝑁𝑒𝑖𝑔ℎ(𝑢)∈𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒, leading to a contradiction: 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢) is verified. ◻

By the Lemma 5 and Corollary 1, we obtain the following result.

Corollary 2
Let 𝛾 be any terminal configuration of 𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎 and u be any process such that 𝑠𝑡𝑢=𝐶 in 𝛾. If u is at depth k, then 𝑑𝑢∈𝑑𝑖𝑠𝑡𝐶𝑂𝑘(𝑘).

Lemma 6
Let 𝛾 be a terminal configuration of 𝖳𝖻𝖢 and u be a process such that 𝑉𝑢 contains at least one process satisfying 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡. In 𝛾, u satisfies:

𝑠𝑡𝑢=𝐶,

¬𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) and ¬𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢), and

𝑃_𝑟𝑜𝑜𝑡(𝑢), or 𝑝𝑎𝑟𝑢∈𝛤(𝑢)∧𝑑𝑢⪰𝑑𝑝𝑎𝑟𝑢⊕𝜔𝑢(𝑝𝑎𝑟𝑢).

Proof
Let v be a process of 𝑉𝑢 such that 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡𝑣 in 𝛾. We have 𝑠𝑡𝑣∈{𝐶,𝐼}, by Lemma 3. Now, 𝑠𝑡𝑣≠𝐼, because otherwise 𝐑𝐑(𝑣) would be enabled in 𝛾. Therefore 𝑠𝑡𝑣=𝐶 in 𝛾.

Assume then, by contradiction, that there exists some process of 𝑉𝑢 that has status I in 𝛾. Consider now a process w of 𝑉𝑢 such that w has status I and at least one of its neighbors has status C in 𝛾 (such a process exists because every process has status I or C in 𝛾, by Lemma 3, whereas at least one process, e.g. v, of 𝑉𝑢 has status C, and 𝑉𝑢 is connected). According to the definition of 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑤), we have two cases:

Case 1:
𝑃_𝑡𝑜𝐵𝑒𝐶(𝑤)≡(∃𝑣∈𝛤(𝑤)∣𝑠𝑡𝑣=𝐶). 𝐑𝐑(𝑤) would be enabled in 𝛾, a contradiction.

Case 2:
𝑃_𝑡𝑜𝐵𝑒𝐶(𝑤)≡(∃𝑣∈𝛤(𝑤)∣𝑠𝑡𝑣=𝐶)∧(𝑑𝑖𝑠𝑡𝑁𝑒𝑖𝑔ℎ(𝑤)∈𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒). Any neighbor 𝑤′ of w that has the status C is at depth smaller than 𝑛−1 in their legal branch. Therefore, 𝑑𝑤′ belongs to ⋃0≤𝑗≤𝑛−2𝑑𝑖𝑠𝑡𝐶𝑂𝑘(𝑗) by Corollary 2, and thus 𝑑𝑖𝑠𝑡𝑁𝑒𝑖𝑔ℎ(𝑤)∈𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒. Hence, 𝐑𝐑(𝑤) is enabled in 𝛾, a contradiction.

Hence, we conclude that every process of 𝑉𝑢 (including u) has status C in 𝛾.

Moreover, since 𝑠𝑡𝑢=𝐶 in 𝛾, ¬𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) and ¬𝑃_𝑟𝑜𝑜𝑡𝐴𝑐𝑡𝑖𝑣𝑒(𝑢) hold in 𝛾 (otherwise, 𝐑𝐔(𝑢) would be enabled).

Finally, Lemma 4 allows us to conclude the proof. ◻

Lemma 7
Let 𝛾 be a terminal configuration of 𝖳𝖻𝖢 and u be a process such that 𝑉𝑢 contains no process satisfying 𝑐𝑎𝑛𝐵𝑒𝑅𝑜𝑜𝑡 in 𝛾. In 𝛾, 𝑠𝑡𝑢=𝐼.

Proof
Assume, for the purpose of contradiction, that u is not isolated in 𝛾. By Lemma 3, u has status C in 𝛾. Without loss of generality, assume u is a process subject to that condition with the smallest distance 𝑑𝑢 in 𝛾. Then, u is an abnormal root and enabled to execute 𝐑𝐄𝐁(𝑢) or 𝐑𝐔(𝑢) in 𝛾, a contradiction. ◻

Therefore, by Lemmas 6 and 7, we obtain the following result.

Theorem 1
Any terminal configuration of 𝖳𝖻𝖢 is legitimate.

Bounded Memory Space
Consider 𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎. By definition, 𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒 is a finite set. Then, there are two rules that allow to update the variable 𝑑𝑢: 𝐑𝐔(𝑢) and 𝐑𝐑(𝑢). These rules use the macro 𝑢𝑝𝑑𝑎𝑡𝑒(𝑢) to compute the new value of 𝑑𝑢. If 𝑑𝑢 takes value 𝑑𝑖𝑠𝑡𝑅𝑜𝑜𝑡𝑢, then 𝑑𝑢 trivially remains in 𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒. Otherwise, we should remark that 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)⇒𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢) and if the executed rule is 𝐑𝐑(𝑢), then 𝑠𝑡𝑢≠𝐶. Consequently, 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢) holds, which implies that 𝑑𝑢 also remains in 𝑑𝑖𝑠𝑡𝑆𝑒𝑡𝐹𝑖𝑛𝑖𝑡𝑒 in this case. Hence, we obtain the following result.

Observation 3
𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎 only requires bounded memory space.

Moreover, such instantiations have terminal configurations which are essentially the same as those using unbounded memory space. More precisely, by Definition 6, Lemmas 2 and 5, and Theorem 1, we have the following property.

Corollary 3
Consider any instantiation  identical to 𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎 except that 𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢)≡(∃𝑣∈𝛤(𝑢)∣𝑠𝑡𝑣=𝐶) and 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)≡𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑢).

In 𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎, we have 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)≡𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑢)∧𝑃_𝑡𝑜𝐵𝑒𝐶(𝑢), so 𝙼𝚒𝚗𝚒𝚖𝚒𝚣𝚎𝙵𝚒𝚗𝚒𝚝𝚎 and  have the same terminal configurations.

In other words, any instantiation requiring unbounded memory space such that 𝑃_𝑛𝑒𝑖𝑔ℎ𝐴𝑐𝑡𝑖𝑣𝑒(𝑢)≡𝑃_𝑛𝑒𝑖𝑔ℎ𝑉𝑎𝑙𝑖𝑑(𝑢) can be turned into a bounded memory space version with the same terminal configurations and, as we will see, the same upper bounds on the number of steps and rounds.

Step Complexity of \mathsf {TbC}
In this section, we establish some properties on every execution of \mathsf {TbC} under a distributed unfair daemon. These properties allow us to show the termination under a distributed unfair daemon and to exhibit an upper bound on the move complexity of any instance of \mathsf {TbC} .

{\mathcal {C}}-Segments
Definition 9
(AAR) Let {\mathcal {C}} be a connected component of G and let \gamma be a configuration. AAR (\gamma , {\mathcal {C}}) is the set of processes u \in {\mathcal {C}} such that, in \gamma , u is an alive abnormal root, or P\_rootActive (u) \wedge st_u = C holds.

We now prove that AAR (\gamma , {\mathcal {C}}) can never gain any new element.

Lemma 8
Let \gamma \mapsto \gamma ' be a step where a process u executes the rule \mathbf {R_{U}} or \mathbf {R_{R}} . Then, u is not an alive abnormal root in \gamma '.

Proof
We have par_{u} \in \varGamma (u) \cup \{\bot \} in \gamma '. We separately deal with these two cases.

First assume that par_{u} = \bot in \gamma '. We claim that, in this case, the constant canBeRoot_u is true. Recall that P\_rootActive (u) implies P\_rootValid (u), which in turn implies canBeRoot_u. Thus, for the purpose of contradiction, assume that neither canBeRoot_u nor P\_rootActive (u) hold. Note that par_{u} = \bot in \gamma ' implies that u must have executed the else part of update(u) in \gamma \mapsto \gamma '. Therefore, the second part of the main disjunction of the if condition must not hold. This means that st_u \ne C, and thus that u has executed the rule \mathbf {R_{R}} in \gamma \mapsto \gamma '. For this rule to be enabled, the second part of the conjunction in its guard must hold, which implies that P\_toBeC (u) holds. However, this last property, combined with the preceding ones, validates the if condition in update(u), which contradicts par_{u} = \bot in \gamma '. Therefore, canBeRoot_u is indeed true and thus P\_root (u) is true in \gamma ', which, in turn, implies \lnot P\_abRoot(u).

Assume now that par_{u} = v \in \varGamma (u) in \gamma '. Then st_v = C in \gamma , because par_{u} is chosen in the set \{v \in \varGamma (u)\ \mid \ st_v = C\}; see update(u). Consequently, the only rules that v may execute in \gamma \mapsto \gamma ' are \mathbf {R_{U}} or \mathbf {R_{EB}} . In \gamma \mapsto \gamma ', v either takes the status EB, decreases its distance value, or does not change the value of its variables. In all cases, u belongs to Children(v) in \gamma ', which prevents u from being an alive abnormal root in \gamma ', by Observation 1. More precisely, if v decreases its distance value, the fact that u still belongs to Children(v) in \gamma ' comes from the hypothesis on \oplus stating that for any distances d_1 and d_2 and any weight \omega of an edge, we have d_1 \oplus \omega \preceq d_2 \oplus \omega if d_1 \prec d_2. \square

One of the key properties allowing us to prove that \mathsf {TbC} has a polynomial move complexity is the following result.

Lemma 9
No alive abnormal root is created along any execution of \mathsf {TbC}.

Proof
Let \gamma \mapsto \gamma ' be a step and u be a process that is not an alive abnormal root in \gamma . Assume, by contradiction, that u is an alive abnormal root in \gamma '.

If the status of u is EF or I in \gamma ', then u is not an alive abnormal root in \gamma '. If u executes \mathbf {R_{U}} or \mathbf {R_{R}} during this step, then u is not an alive abnormal root in \gamma ' either, by Lemma 8. So the only rule that u may execute is \mathbf {R_{EB}} in \gamma \mapsto \gamma '. Furthermore, both in \gamma and \gamma ', u has status C or EB, and par_u \in \varGamma (u) \cup \{\bot \} (because u is not an abnormal root in \gamma ).

Assume first that par_{u} = \bot in \gamma '. Then, par_{u} = \bot already holds in \gamma . We thus have P\_root (u) in \gamma because \lnot P\_abRoot(u) in \gamma . Consequently, u executes no move in \gamma \mapsto \gamma ', and u is still a normal root in \gamma ', a contradiction.

Assume now that par_{u} = v \in \varGamma (u) in \gamma '. Whether u executes \mathbf {R_{EB}} or not, par_u already designates v in \gamma . Also, \lnot P\_abRoot(u) in \gamma implies that u \in Children(v) and st_{v} \in \{C,EB\} in \gamma , further implying that the only rules that v may execute in \gamma \mapsto \gamma ' are \mathbf {R_{U}} or \mathbf {R_{EB}} . Moreover, if st_{u} = EB in \gamma or u executes \mathbf {R_{EB}} in \gamma \mapsto \gamma ', then st_{v} = EB too in \gamma and v does not move in \gamma \mapsto \gamma '. Consequently, \lnot P\_abRoot(u) still holds in \gamma ', a contradiction. Otherwise, st_{u} = C in \gamma and u does not move in \gamma \mapsto \gamma '. In \gamma \mapsto \gamma ', v either takes the status EB, decreases its distance value, or does not change the value of its variables. In all cases, u still belongs to Children(v) in \gamma ', which prevents u from being an alive abnormal root in \gamma ' (by Observation 1), a contradiction. \square

Lemma 10
If a process u satisfies P\_rootActive (u) \wedge st_u = C, then it does so, and it never performed any move, since the beginning of the execution.

Proof
Let u be a process satisfying P\_rootActive (u) \wedge st_u = C. Note that the property does only depend on the local state on u. Assume thus, for the purpose of contradiction, that u did perform at least a move since the beginning of the execution, and consider the last such move, say during the step \gamma \mapsto \gamma '.

Since st_u = C holds in \gamma ', u must have executed \mathbf {R_{U}} or \mathbf {R_{R}} during that step. For P\_rootActive (u) to hold in \gamma ',

u must have executed the then part of update(u); otherwise d_u = distRoot_u in \gamma ' and so \lnot P\_rootValid (u), which implies \lnot P\_rootActive (u).

If it did so because of the first part of the disjunction in the if of update(u), then distNeigh(u) \preceq distRoot_u, which implies that d_u \preceq distRoot_u in \gamma '. Thus, in that case, P\_rootActive (u) cannot hold in \gamma ', a contradiction.

Otherwise (it did so because of the second part of the disjunction), in \gamma , st_u = C holds but P\_rootActive (u) does not. During \gamma \mapsto \gamma ', u executed \mathbf {R_{U}} and decreased its distance d_u.

As P\_rootActive (u) is monotone w.r.t. d_u, \lnot P\_rootActive (u) in \gamma implies \lnot P\_rootActive (u) in \gamma ', leading to a contradiction. \square

By the two preceding Lemmas, we obtain the following result.

Corollary 4
For every step \gamma \mapsto \gamma ', AAR (\gamma ',{\mathcal {C}}) \subseteq AAR (\gamma ,{\mathcal {C}}).

Based on Corollary 4, we can use the notion of {\mathcal {C}}-segment defined below to bound the total number of moves in an execution.

Definition 10
({\mathcal {C}}-Segment) Let e = \gamma _0\gamma _1\cdots be an execution of \mathsf {TbC} and {\mathcal {C}} be a connected component of G.

If there is no step \gamma _i \mapsto \gamma _{i+1} in e such that |AAR (\gamma _i,{\mathcal {C}})| > |AAR (\gamma _{i+1},{\mathcal {C}})|, then the first {\mathcal {C}}-segment of e is e itself and there is no other {\mathcal {C}}-segment.

Otherwise, let \gamma _i \mapsto \gamma _{i+1} be the first step of e such that |AAR (\gamma _i,{\mathcal {C}})| > |AAR (\gamma _{i+1},{\mathcal {C}})|. The first {\mathcal {C}}-segment of e is the prefix \gamma _0\cdots \gamma _{i+1}. The second {\mathcal {C}}-segment of e is the first {\mathcal {C}}-segment of the suffix \gamma _{i+1}\gamma _{i+2}\ldots , and so forth.

By Corollary 4, and since by definition |AAR (\gamma _i,{\mathcal {C}})| \le {n_{\mathtt {maxCC}}} for every connected component {\mathcal {C}} and every configuration \gamma _i, we have:

Observation 4
Let {\mathcal {C}} be a connected component of G. For every execution e of \mathsf {TbC}, e contains at most {n_{\mathtt {maxCC}}}+1 {\mathcal {C}}-segments.

We now prove some properties on the moves made by a process in a {\mathcal {C}}-segment.

Lemma 11
Let {\mathcal {C}} be a connected component of G, u be any process of {\mathcal {C}}, and {\mathcal {S}} be a {\mathcal {C}}-segment. During {\mathcal {S}}, if u executes the rule \mathbf {R_{EF}} , then u does not execute any other rule in the remaining of {\mathcal {S}}.

Proof
Let \gamma _1 \mapsto \gamma _2 be a step of {\mathcal {S}} in which u executes \mathbf {R_{EF}} . Note that u has status EB in \gamma _1. Let \gamma _3 \mapsto \gamma _4 be the next step in which u executes a rule. (If one of these two steps does not exist, then the lemma trivially holds.)

Let v be the root (at depth 0) of any branch in \gamma _1 containing u. By Definition 4, v must have status EB (and so satisfies \lnot P\_rootActive (u) \vee st_u \ne C forever, by Lemma 10), and must therefore be an alive abnormal root. This implies that v \in AAR (\gamma _1,{\mathcal {C}}). Note that we may have v=u. On the other hand, in \gamma _3, u is the dead abnormal root of all branches it belongs to since st_u = EF in \gamma _3 and u necessarily executes \mathbf {R_{I}} or \mathbf {R_{R}} in this step. By Observation 1, either u = v or u no more belongs to a branch whose initial extremity is v. In either case, v is no more an alive abnormal root in \gamma _3. Indeed, in the first case, u=v has status EF, while in the second case, if v were still an alive abnormal root, then u would still be in a branch with v as initial extremity, by Lemmas 1 and 9. Therefore v \notin AAR (\gamma _3,{\mathcal {C}}). Consequently, the steps \gamma _1 \mapsto \gamma _2, and \gamma _3 \mapsto \gamma _4 belong to two distinct {\mathcal {C}}-segments of the execution, by Corollary 4 and Definition 10. \square

By Lemma 11 and from the code of the algorithm, we obtain the following result.

Corollary 5
Let {\mathcal {C}} be a connected component of G and u be any process of {\mathcal {C}}. The sequence of rules executed by u during a {\mathcal {C}}-segment belongs to the following language:

\begin{aligned} (\mathbf {R_{I}} + \varepsilon )(\mathbf {R_{R}} + \varepsilon ) (\mathbf {R_{U}})^* (\mathbf {R_{EB}} + \varepsilon )(\mathbf {R_{EF}} + \varepsilon )\;. \end{aligned}
By Observation 4 and Corollary 5, we obtain the following result.

Theorem 2
If \#U is an upper bound on the number of rules \mathbf {R_{U}} executed by any process of {\mathcal {C}} in any {\mathcal {C}}-segment for any connected component {\mathcal {C}}, then the total number of moves in any execution is bounded by (\#U+4)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n.

Causal Chains
We now use the notion of causal chain defined below to further analyze the number of moves and steps in a {\mathcal {C}}-segment.

Definition 11
Let {\mathcal {C}} be a connected component of G, v_0 be a process of {\mathcal {C}}, and {\mathcal {S}} be any {\mathcal {C}}-segment. A causal chain of {\mathcal {S}} rooted at v_0 is a non-empty sequence of actions a_1,a_{2},\ldots ,a_k executed in {\mathcal {S}} such that the action a_1 sets par_{v_1} to v_0 and for all 2 \le i \le k, the action a_i sets par_{v_i} to v_{i-1} after the action a_{i-1} but not later than v_{i-1}’s next action.

Observation 5
  Let {\mathcal {C}} be a connected component of G, v_0 be a process of {\mathcal {C}}, and {\mathcal {S}} be any {\mathcal {C}}-segment. Let  a_1,a_{2},\ldots ,a_k be a causal chain of {\mathcal {S}} rooted at v_0. Denote by v_i the process that executes a_i, for all i \in \{1,\ldots , k\}.

For all  1 \le i \le k, a_i consists in the execution of update(v_i) (i.e., v_i executes the rule \mathbf {R_{U}} or \mathbf {R_{R}} ), and v_i is a process of {\mathcal {C}}.

Assume a_1 is executed in the step \gamma \mapsto \gamma ' of {\mathcal {S}}. Denote by ds_0 the distance value of process v_0 in \gamma ; we call this value the initiating value of the causal chain. For all 1 \le i \le k, a_i sets d_{v_i} to ((ds_{0}\oplus \omega _{v_1}(v_{0})) \oplus \cdots )\oplus \omega _{v_i}(v_{i-1}).

Lemma 12
Let {\mathcal {C}} be a connected component of G and {\mathcal {S}} be a {\mathcal {C}}-segment. All actions in a causal chain of {\mathcal {S}} are executed by different processes of {\mathcal {C}}, none of them being the root of the causal chain.

Proof
Assume, by contradiction, that there exists a process v such that, in some causal chain a_1,a_{2},\ldots ,a_k of {\mathcal {S}}, v is designated as parent in some action a_i executed in step \gamma _i \mapsto \gamma _{i+1} and executes the action a_j in step \gamma _j\mapsto \gamma _{j+1}, with j>i. Process v has status C in \gamma _i, and the value of d_{v} is strictly larger in \gamma _{j+1} than in \gamma _{i} (by Observation 5, second item). However, any rule \mathbf {R_{U}} executed by v makes the value of d_v decrease. Finally, since Process v has status C in \gamma _i, \mathbf {R_{R}} (v) will be no more executed in {\mathcal {S}} from that configuration, by Corollary 5 and from the rules’ guards. Hence, we obtain a contradiction (by Observation 5, first item). \square

Maximal Causal Chains
Definition 12
(Maximal causal chain) Let {\mathcal {C}} be a connected component of G, v_0 be a process of {\mathcal {C}}, and {\mathcal {S}} be any {\mathcal {C}}-segment. A maximal causal chain of {\mathcal {S}} rooted at v_0 is a causal chain a_1,a_{2},\ldots ,a_k of {\mathcal {S}} such that the causal chain is maximal and, either v_0 is a normal root or the action a_1 sets par_{v_1} to v_0 not later than any action executed by v_0 in {\mathcal {S}}.

The following lemma adds a property to Observation 5 for the specific case of maximal causal chains.

Lemma 13
Given any connected component {\mathcal {C}}, any {\mathcal {C}}-segment {\mathcal {S}}, and any process v \in {\mathcal {C}}, all maximal causal chains of {\mathcal {S}} rooted at v have the same initiating value.

Proof
For the purpose of contradiction, assume that there exist such {\mathcal {C}}, {\mathcal {S}}, and v such that two maximal causal chains of {\mathcal {S}} rooted at v have different initiating values d_1 and d_2. At least one of them, say d_1, must be different from distRoot_v. This value d_1 is necessarily the distance value of v at the beginning of {\mathcal {S}}, otherwise v would not be the root of the corresponding maximal causal chain. As a consequence, we must have d_2=distRoot_v.

Since d_1 is the distance value of v at the beginning of {\mathcal {S}}, there must exist an action a executing the else part of update(v) in {\mathcal {S}}. Moreover, since the maximal causal chain of {\mathcal {S}} rooted at v with initiating value d_1 exists, st_v = C initially (otherwise, no neighbor can choose v as parent before any action of v in {\mathcal {C}}). Thus, by Corollary 5, the action a is an execution of \mathbf {R_{U}} in the case when P\_rootActive (v) \wedge st_v = C holds. By definition of a {\mathcal {C}}-segment, Lemmas 8–10, and Corollary 4, the action a is thus executed during the last step of {\mathcal {S}} and thus no maximal causal chains of {\mathcal {S}} (which are never empty by definition) can be rooted at v with initiating value d_2=distRoot_v. This contradiction concludes the proof. \square

Definition 13
(SI_{{\mathcal {S}},v}) Let {\mathcal {C}} be a connected component of G, v be a process of {\mathcal {C}}, and {\mathcal {S}} be a {\mathcal {C}}-segment. We define SI_{{\mathcal {S}},v} as the set of all the distance values obtained after executing an action belonging to the maximal causal chains of {\mathcal {S}} rooted at v.

The following lemma will be used to establish the termination of \mathsf {TbC} in any case. It will also lead to a huge upper bound on the move complexity. However, we will see that in many practical cases, the upper bound in moves can be refined to be polynomial, see Theorem 3 and Corollary 8.

Lemma 14
Let {\mathcal {C}} be a connected component of G, v_0 be a process of {\mathcal {C}}, and {\mathcal {S}} be a {\mathcal {C}}-segment. The size of the set SI_{{\mathcal {S}},v_0} is bounded by ({n_{\mathtt {maxCC}}}-1)! (the factorial of {n_{\mathtt {maxCC}}}-1).

Proof
Let us consider a distance value d obtained after executing an action a_i belonging to a maximal causal chain a_1,a_{2},\ldots ,a_k of {\mathcal {S}} rooted at v_0. Denote by v_i the process that executes a_i, for all i \in \{1,\ldots , k\}. By Observation 5, we have d=((ds_{0}\oplus \omega _{v_1}(v_{0})) \oplus \cdots )\oplus \omega _{v_i}(v_{i-1}), with ds_{0} being the initiating value common to all maximal causal chains of {\mathcal {S}} rooted at v_0 (see Lemma 13). In other words, the value d is fully determined by the sequence of processes v_1,\ldots , v_i (v_0 and {\mathcal {S}} being fixed). Moreover, note that all the v_j, 0 \le j \le i are different processes and v_0 does not execute any action of any causal chain it is the root of, by

Lemma 12. Therefore, |SI_{{\mathcal {S}},v_0}| is bounded by ({n_{\mathtt {maxCC}}}-1)!. \square

Move Complexity of \mathsf {TbC}
Lemma 15
Let {\mathcal {C}} be a connected component of G, u \in {\mathcal {C}}, and {\mathcal {S}} be a {\mathcal {C}}-segment. If the size of SI_{{\mathcal {S}},v} is bounded by X for any process v \in {\mathcal {C}}, then the number of \mathbf {R_{U}} moves done by u in {\mathcal {S}} is bounded by X\cdot ({n_{\mathtt {maxCC}}}-1)+1.

Proof
By Corollary 5, \mathbf {R_{U}} (u) executions in {\mathcal {S}} are not interrupted by the executions of other rules at u, and they make the value of d_u decrease. Therefore, all the values of d_u obtained by the \mathbf {R_{U}} executions done by u in {\mathcal {S}} are different. By Definitions 12 and 13, all these values belong to the set \bigcup _{v \in {\mathcal {C}}\setminus \{u\}}SI_{{\mathcal {S}},v} \cup \{distRoot_u\}, which has size at most X\cdot ({n_{\mathtt {maxCC}}}-1)+1. \square

By Theorem 2 and Lemma 15, we obtain the following result.

Corollary 6
If the size of SI_{{\mathcal {S}},v} is bounded by X for any connected component {\mathcal {C}}, any process v \in {\mathcal {C}}, and any {\mathcal {C}}-segment {\mathcal {S}}, then the total number of moves during any execution is bounded by (X\cdot ({n_{\mathtt {maxCC}}}-1)+5)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n.

Combined with Lemma 14, this corollary already allows us to prove that \mathsf {TbC} always terminates and has a bounded move complexity.

Corollary 7
Algorithm \mathsf {TbC} is silent self-stabilizing under the distributed unfair daemon and has a bounded move (and step) complexity, a valid bound being 5n\cdot ({n_{\mathtt {maxCC}}}+1)!.

Let \mathtt {W}_{\max }= \max \{\omega _{u}(v) ~\mid ~ u \in V \wedge v \in \varGamma (u)\}. If all weights are strictly positive integers and \oplus is the addition operator, then the size of any SI_{{\mathcal {S}},u} is bounded by \mathtt {W}_{\max }({n_{\mathtt {maxCC}}}-1) for every connected component {\mathcal {C}}, every {\mathcal {C}}-segment {\mathcal {S}}, and every process u \in {\mathcal {C}} because, by Observation 5 and Lemma 12, SI_{{\mathcal {S}},u} \subseteq [ds_{{\mathcal {S}},u} + 1, ds_{{\mathcal {S}},u} + \mathtt {W}_{\max }(n_{cc}-1)], where n_{cc} \le {n_{\mathtt {maxCC}}} is the number of processes in {\mathcal {C}}, and ds_{{\mathcal {S}},u} is the common (by Lemma 13) initiating value of the maximal causal chains of {\mathcal {S}} rooted at u. Hence, we deduce the following theorem from Corollaries 6 and 7.

Theorem 3
Algorithm \mathsf {TbC} is silent self-stabilizing under the distributed unfair daemon and, when all weights are strictly positive integers and \oplus is the addition operator, its stabilization time in moves (and steps) is at most (\mathtt {W}_{\max }\cdot ({n_{\mathtt {maxCC}}}-1)^2+5)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n.

Lemma 16
Let {\mathcal {C}} be a connected component of G, v \in {\mathcal {C}}, and {\mathcal {S}} be a {\mathcal {C}}-segment. If all edges have the same weight, then |SI_{{\mathcal {S}},v}| < {n_{\mathtt {maxCC}}}.

Proof
Assume that all edges have the same weight \omega . According to Observation 5 and Lemma 12, we have SI_{{\mathcal {S}},v} \subseteq \{ ds_{{\mathcal {S}},v} \oplus (i.\omega ) ~|~ 1 \le i \le {n_{\mathtt {maxCC}}}-1\}, where ds_{{\mathcal {S}},v} is the common (by Lemma 13) initiating value of the maximal causal chains of {\mathcal {S}} rooted at v. \square

By Corollary 6 and Lemma 16, we obtain the following result.

Corollary 8
If all edges have the same weight, then the total number of moves (and steps) during any execution is bounded by (({n_{\mathtt {maxCC}}}-1)^2+5)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n.

Round Complexity of \mathsf {TbC}
Normal Configurations
We first introduce the notion of normal configurations, which will help us to partition the proof on the round complexity of \mathsf {TbC}.

Definition 14
(Normal Process) A process u is said to be normal if u satisfies the following two conditions:

1.
st_u \notin \{EB,EF\}, and

2.
\lnot P\_abRoot(u).

Definition 15
(Normal Configuration) Let \gamma be a configuration of \mathsf {TbC}. \gamma is said to be normal if every process is normal in \gamma ; otherwise \gamma is said to be abnormal.

Observation 6
In a normal configuration of \mathsf {TbC}, only the rules \mathbf {R_{U}} or \mathbf {R_{R}} may be enabled at any process.

We first prove that, once a normal configuration is reached, all subsequent configurations will be normal as well.

Lemma 17
Any step from a normal configuration of \mathsf {TbC} reaches a normal configuration of \mathsf {TbC}.

Proof
Let \gamma \mapsto \gamma ' be a step such that \gamma is a normal configuration and let u be a process.

In \gamma , every process v satisfies st_v \notin \{EB,EF\} and \lnot P\_abRoot(v). Hence, both \mathbf {R_{EB}} (u) and \mathbf {R_{EF}} (u) are disabled in \gamma , and consequently st_u \notin \{EB,EF\} still holds in \gamma '.

Moreover, since u is not an alive abnormal root in \gamma , Lemma 9 implies that u is not an alive abnormal root in \gamma ' either. Since st_u \ne EF in \gamma ', we obtain \lnot P\_abRoot(u) in \gamma '. \square

From an Arbitrary Configuration to a Normal Configuration
The lemma below essentially claims that all the processes that are in illegal branches progressively switch to status EB within {n_{\mathtt {maxCC}}} rounds, in order of increasing depth; see Definition 5, page 15, for the definition of depth.

Lemma 18
Let i \in {\mathbb {N}}. From the beginning of Round i+1, there does not exist any process both in state C and at depth less than i in an illegal branch.

Proof
We prove this lemma by induction on i. The base case (i=0) is trivially true, so we assume that the lemma holds for some integer i\ge 0.

From the beginning of Round i+1, no process can ever choose a parent which is at depth smaller than i in an illegal branch because those processes (if they exist) will never have status C, by induction hypothesis.

Then, let u be a process of status C in an illegal branch at the beginning of Round i+1. Its depth is thus at least i. By induction hypothesis, each of its ancestor at depth smaller than i has status EB and has at least one child not having status EF. Thus, no such ancestors can execute any rule, and consequently they cannot make the depth of u decrease to i or smaller. Therefore, no process can take status C at depth smaller than or equal to i in an illegal branch from the beginning of Round i+1.

Consider any process u with status C at depth i in an illegal branch at the beginning of Round i+1. It remains to prove that u will not stay so until the end of Round i+1. By induction hypothesis, u is an abnormal root, or the parent of u has not status C (i.e., it has status EB). During Round i+1, u will execute rule either \mathbf {R_{EB}} or \mathbf {R_{U}} and thus either switch to status EB, or join another branch (at a depth greater than i if that branch is illegal), or become a normal root turning its branch to be legal.

This concludes the proof of the lemma. \square

Definition 16
(Almost Normal Configuration) A configuration \gamma of \mathsf {TbC} is said to be almost normal if in \gamma , every process u satisfies st_u = C \Rightarrow \lnot P\_abRoot(u) \wedge [P\_root (u) \vee (par_u \in \varGamma (u) \wedge st_{par_u} = C)].

Lemma 19
Any step from an almost normal configuration of \mathsf {TbC} leads to an almost normal configuration of \mathsf {TbC}.

Proof
Let \gamma \mapsto \gamma ' be a step of \mathsf {TbC} such that \gamma is an almost normal configuration. Assume, for the purpose of contradiction, that \gamma ' is not an almost normal configuration. Then, by Definition 16, at least one process u satisfies one of the following two cases.

st_u = C \wedge P\_abRoot(u) in \gamma '. Then, Lemma 9 (page 20) implies that u is already an alive abnormal root in \gamma . However, since \gamma is an almost normal configuration, u cannot be an alive abnormal root of status C in \gamma . So, we necessarily have st_u = EB in \gamma . But, in this case, st_u \ne C in \gamma ', a contradiction.

st_u = C \wedge \lnot P\_abRoot(u) \wedge \lnot P\_root (u) \wedge [par_u \notin \varGamma (u) \vee st_{par_u} \ne C] in \gamma '. Now, \lnot P\_abRoot(u) \wedge \lnot P\_root (u) implies par_u \in \varGamma (u) by Observation 1 (page 15) and thus st_{par_u} = EB in \gamma ' from par_u \notin \varGamma (u) \vee st_{par_u} \ne C. Let v be the process par_u in \gamma '. By definition of an almost normal configuration (Definition 16), v does not execute \mathbf {R_{EB}} in \gamma \mapsto \gamma '. So, in \gamma , we have st_v = EB. If u executes \mathbf {R_{R}} or \mathbf {R_{U}} in \gamma \mapsto \gamma ' then par_u \ne v in \gamma '. If u executes \mathbf {R_{EB}} , \mathbf {R_{EF}} or \mathbf {R_{I}} in \gamma \mapsto \gamma ' then st_u \ne C in \gamma '. So u does not execute any rule in \gamma \mapsto \gamma '. Hence, we have st_u = C, par_u = v, and st_v = EB in \gamma , meaning that \gamma is not an almost normal configuration, a contradiction.

\square

From Lemmas 18 and 19, we obtain the following corollary.

Corollary 9
After at most {n_{\mathtt {maxCC}}} rounds, the system is in an almost normal configuration and remains so forever.

The next lemma essentially claims that once no process in an illegal branch has status C, processes in illegal branches progressively switch to status EF within at most {n_{\mathtt {maxCC}}} rounds, in order of decreasing depth.

Lemma 20
Let i \in {\mathbb {N}}^*. From the beginning of Round {n_{\mathtt {maxCC}}}+i, any process at depth larger than {n_{\mathtt {maxCC}}}-i in an illegal branch has status EF.

Proof
We prove this lemma by induction on i. The base case (i=1) is trivial (by Observation 2, page 15), so we assume that the lemma holds for some integer i\ge 1. At the beginning of Round {n_{\mathtt {maxCC}}}+i, any process at depth larger than {n_{\mathtt {maxCC}}}-i has status EF (by induction hypothesis). Therefore, processes with status EB at depth {n_{\mathtt {maxCC}}}-i in an illegal branch are enabled to execute the rule \mathbf {R_{EF}} at the beginning of Round {n_{\mathtt {maxCC}}}+i. These processes will thus all execute within Round {n_{\mathtt {maxCC}}}+i (they cannot be neutralized as no children can connect to them) and obtain status EF. We conclude the proof by noticing that, from Corollary 9, once Round {n_{\mathtt {maxCC}}} has terminated, any process in an illegal branch that executes some rule either gets status EF, or will be outside any illegal branch forever. \square

Definition 17
(Quasi Normal Configuration) An almost normal configuration \gamma of \mathsf {TbC} is said to be quasi normal if no process has status EB in \gamma .

Observation 7
There is no alive abnormal root in a quasi normal configuration.

Lemma 21
Any step from a quasi normal configuration of \mathsf {TbC} leads to a quasi normal configuration of \mathsf {TbC}.

Proof
Let \gamma \mapsto \gamma ' be a step of \mathsf {TbC} such that \gamma is a quasi normal configuration. First, by definition, a quasi normal configuration is also an almost normal configuration. So, \gamma ' is almost normal (Lemma 19) and no process has status EB in \gamma ' since no rule \mathbf {R_{EB}} is enabled in \gamma . Hence, \gamma ' is a quasi normal configuration. \square

From Lemmas 20 and 21, we obtain the following corollary.

Corollary 10
After at most 2{n_{\mathtt {maxCC}}} rounds, the system is in a quasi normal configuration and remains so forever.

The next lemma essentially claims that after the propagation of status EF in illegal branches, the maximum length of illegal branches progressively decreases until all illegal branches vanish.

Lemma 22
Let i \in {\mathbb {N}}^*. From the beginning of Round 2{n_{\mathtt {maxCC}}}+i, there does not exist any process at depth larger than {n_{\mathtt {maxCC}}}-i in an illegal branch.

Proof
We prove this lemma by induction on i. The base case (i=1) is trivial (by Observation 2, page 15), so we assume that the lemma holds for some integer i\ge 1. By induction hypothesis, at the beginning of Round 2{n_{\mathtt {maxCC}}}+i, no process is at depth larger than {n_{\mathtt {maxCC}}}-i in an illegal branch. All processes in an illegal branch have the status EF (by Lemma 20). So, at the beginning of Round 2{n_{\mathtt {maxCC}}}+i, any abnormal root satisfies the predicate P\_reset , and is enabled to execute either \mathbf {R_{I}} , or \mathbf {R_{R}} . So, all abnormal roots at the beginning of Round 2{n_{\mathtt {maxCC}}}+i are no more in an illegal branch at the end of this round: the maximal depth of the illegal branches has decreased, since by Corollary 9, no process can join an illegal tree after {n_{\mathtt {maxCC}}} rounds have occurred.\square

By Lemmas 17–22, we obtain the following result.

Theorem 4
After at most 3{n_{\mathtt {maxCC}}} rounds, a normal configuration of \mathsf {TbC} is reached, and the configuration remains normal forever.

From a Normal Configuration to a Terminal Configuration
From a normal configuration, Algorithm \mathsf {TbC} needs additional rounds to propagate the status C and the correct distances in the components of the graph containing at least one process satisfying canBeRoot. First, we observe the following fact.

Observation 8
In a normal configuration of \mathsf {TbC}, all processes in connected components containing no process satisfying canBeRoot are in state I and thus are disabled.

Let u be a process having the status C in a normal configuration \gamma . Along any execution from \gamma , the distance of u cannot increase and u keeps the status C.

From the previous observation, we only need to focus on any connected component {\mathcal {C}} containing at least one process satisfying canBeRoot.

Let us fix an arbitrary execution \mathsf {ex} of \mathsf {TbC} in {\mathcal {C}} starting from a normal configuration \gamma . By Corollary 7 (page 25), a terminal configuration is eventually reached after a finite number of steps along \mathsf {ex} .

Lemma 23
Let \mathtt {ST}_{{\mathcal {C}}}(i,\mathsf {ex}) be the set of processes defined as \{ u \in {\mathcal {C}}~|~ u performs a move along \mathsf {ex} after the beginning of Round i\}. If |\mathtt {ST}_{{\mathcal {C}}}(i,\mathsf {ex})| >0 then |\mathtt {ST}_{{\mathcal {C}}}(i+1,\mathsf {ex})| < |\mathtt {ST}_{{\mathcal {C}}}(i,\mathsf {ex})|.

Proof
By definition, \mathtt {ST}_{{\mathcal {C}}}(i+1,\mathsf {ex}) \subseteq \mathtt {ST}_{{\mathcal {C}}}(i,\mathsf {ex}). It is thus sufficient to prove that at least one process of \mathtt {ST}_{{\mathcal {C}}}(i,\mathsf {ex}) is enabled at the beginning of the i^{th} round and will do its last action during the i^{th} round of \mathsf {ex} .

Let \gamma _i be the configuration at the beginning of Round i of \mathsf {ex} , and let \gamma _f be the terminal configuration of \mathsf {ex} . Let us consider the process u \in \mathtt {ST}_{{\mathcal {C}}}(i,\mathsf {ex}) having the minimum distance d_u in \gamma _f, denoted by dmin(i). According to the definition of u and Observation 8, (*) every process w' of \mathtt {ST}_{{\mathcal {C}}}(i,\mathsf {ex}) satisfies dmin(i) \preceq d_{w'} or st_{w'}= I along \mathsf {ex} from \gamma _i.

Case 1.
In \gamma _f, par_u = \bot . This means that P\_root (u) holds in \gamma _f. This further implies that, along \mathsf {ex} from \gamma _i, the last action of u consists in executing the else part of update(u). At that time, u satisfies P\_rootActive (u) \vee st_u = I. Actually, by Lemma 10 page 21 and Observation 8, not only this must already hold from \gamma _i, but this action is the unique action of u along \mathsf {ex} . This action is thus done during the i^{th} round of \mathsf {ex} , and u \not \in \mathtt {ST}_{{\mathcal {C}}}(i+1,\mathsf {ex}), concluding the case.

Case 2.
In \gamma _f, par_u = w \in \varGamma (u). Along \mathsf {ex} from \gamma _i, u executes its last move in some step \gamma _j \mapsto \gamma _{j+1}. In this step, u executes the then part of update(u) since par_u \ne \perp in \gamma _f. In \gamma _j, distNeigh(u) = dmin(i). By Observation 8 and (*), we can conclude that distNeigh(u) is constantly equal to dmin(i) and P\_toBeC (u) is constantly true since \gamma _i. From the properties of P\_rootActive (u) and P\_neighActive (u), this also implies that the values of those two predicates only depends on d_u from \gamma _i (other influencing parameters being constant from \gamma _i). Furthermore, since P\_rootActive (u) and P\_neighActive (u) are monotone w.r.t. d_u, their respective values are constant from \gamma _i until u moves. Assume now, by contradiction, that u moves in some step \gamma _k \mapsto \gamma _{k+1} with i \le k < j. Without loss of generality, assume that k is maximum. Then, u necessarily executes the else part of update(u) in \gamma _k \mapsto \gamma _{k+1} (otherwise, u is not enabled in \gamma _j). Thus, distNeigh(u) \preceq distRoot_u so that u is enabled in \gamma _j. In this case, u necessarily has status C in \gamma _k (u otherwise executes the then part of update(u)). Again to execute the else part of update(u) during \gamma _k \mapsto \gamma _{k+1}, we should have P\_rootActive (u) and \lnot P\_neighActive (u) in \gamma _k. Overall, from \gamma _k to \gamma _j, we have st_u = C; and from \gamma _{k+1} to \gamma _j we have d_u = distRoot_u, which implies \lnot P\_rootActive (u). Moreover, \lnot P\_neighActive (u) holds in \gamma _j since it is monotone w.r.t. d_u and by Observation 8. So, u is disabled in \gamma _j, a contradiction. Hence, the only move of u from \gamma _i is during the step \gamma _j \mapsto \gamma _{j+1} and u was enabled since \gamma _i, i.e., u executes its last move during Round i, which means that u \not \in \mathtt {ST}_{{\mathcal {C}}}(i+1,\mathsf {ex}), concluding the case.

\square

From the previous lemma, and Theorems 1 and 4, we obtain the following result.

Corollary 11
A terminal legitimate configuration of any instantiation of \mathsf {TbC} is reached in at most 4{n_{\mathtt {maxCC}}} rounds from any configuration.

Instantiations
In this section, we illustrate the versatility of Algorithm \mathsf {TbC} by proposing several instantiations that solve various classical problems.

By Definition 7 and Theorem 1 (pages 16 and 18, respectively), any process u in a terminal configuration of an instance of \mathsf {TbC} satisfies one of the three following properties.

Property 1:
P\_root (u) and \lnot P\_neighActive (u).

Property 2:
There is a process satisfying canBeRoot in V_u, st_u = C, par_u \in \varGamma (u), d_u \succeq d_{par_u}\oplus \omega _u(par_u), and \lnot P\_neighActive (u) \wedge \lnot P\_rootActive (u).

Property 3:
There is no process satisfying canBeRoot in V_u and st_u = I.

By Corollaries 7 and 11 (pages 25 and 30, respectively), all instances of \mathsf {TbC} reach under the unfair daemon a terminal configuration in at most 4{n_{\mathtt {maxCC}}} rounds, starting from an arbitrary one.

Observation 9
Let {\mathcal {C}} be a connected component of G containing a process satisfying canBeRoot in an instance of \mathsf {TbC}. In any terminal configuration of this instance, at least one process of {\mathcal {C}} verifies P\_root (u). In particular, every process u that has the smallest d_u value in {\mathcal {C}} verifies P\_root (u).

Spanning Forest and Non-rooted Components Detection
figure b
Given an input set of processes rootSet, Algorithm \mathsf {Forest} is the instantiation of \mathsf {TbC} with the parameters given in Algorithm 2. Algorithm \mathsf {Forest} computes (in a self-stabilizing manner) a spanning forest in each connected component of G containing at least one process of rootSet. The forest consists of trees (of arbitrary topology), whose tree roots are processes of rootSet. Each process of rootSet is required to be a tree root in Version 1 of Algorithm \mathsf {Forest}, but not in Version 2. Moreover, in any component containing no process of rootSet, the processes eventually detect the absence of root by finally taking the status I (Isolated).

Correctness of \mathsf {Forest}. In a terminal configuration of \mathsf {Forest}, each process u satisfies one of the following conditions:

1.
P\_root (u), i.e., u is a tree-root and u \in rootSet.

2.
There is a process of rootSet in V_u, st_u = C, par_u \in \varGamma (u), d_u \ge d_{par_u}+1, u belongs to a tree rooted at some process of rootSet – its neighbor par_u is its parent in the tree. In Version 1 of the algorithm, u \notin rootSet.

3.
There is no process of rootSet in V_u and st_u = I, i.e., u is isolated.

Move Complexity of \mathsf {Forest}. Rule \mathbf {R_{U}} is executed at most once by each process u in any V_u-segment. Hence, the total number of moves (and steps) during any execution is bounded by 5\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n, by Theorem 2 (page 22).

Leader Election
figure c
Assuming the network is identified, Algorithm \mathsf {LE} is the instantiation of \mathsf {TbC} with the parameters given in Algorithm 3. In each connected component, Algorithm \mathsf {LE} elects a process \ell (i.e., P\_leader (\ell ) holds) and builds a tree (of arbitrary topology) rooted at \ell that spans the whole connected component.

The variable d_u of a process u has two fields. The first one, id, eventually contains the identifier of the leader in V_u. The second one, h, contains an upper bound on the distance to the leader in the built tree rooted at \ell .

Correctness of \mathsf {LE}. As canBeRoot is true for all processes, in a terminal configuration of \mathsf {LE} no process verifies Property 3 (i.e. no process has the status I).

Observation 10
In a terminal configuration of \mathsf {LE}, each process u satisfies one of the following conditions: (1) P\_root (u), or (2) st_u = C, par_u \in \varGamma (u), d_u = (d_{par_u}.id, -), and d_u.h \ge d_{par_u}.h+1.

In a terminal configuration of Algorithm \mathsf {LE}, each process u satisfies d_u = (pname_\ell ,-) where \ell is the single process in V_u verifying P\_root (\ell ).

Move Complexity of \mathsf {LE}. During a {\mathcal {C}}-segment, a process can only execute \mathbf {R_{U}} to improve its ID. Let u by any process. At the beginning of a segment, at most {n_{\mathtt {maxCC}}}-1 distinct IDs are stored in the distance variables of processes in V_u \setminus \{u\}. In the worst case, u can successively adopt each of them along the segment. Hence, the total number of moves (and steps) during any execution is bounded by ({n_{\mathtt {maxCC}}}+3)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n (Theorem 2, page 22), i.e., O({n_{\mathtt {maxCC}}}^2\cdot n).

Shortest-Path Tree and Non-rooted Components Detection
Assuming the existence of a unique root r and (strictly) positive integer weights for each edge, Algorithm \mathsf {RSP} is the instantiation of \mathsf {TbC} with the parameters given in Algorithm 4. Algorithm \mathsf {RSP} computes (in a self-stabilizing manner) a shortest-path tree spanning the connected component of G containing r. Moreover, in any other component, the processes eventually detect the absence of r by taking the status I (Isolated).

Recall that the weight of a path is the sum of its edge weights. The weighted distance between the processes u and v, denoted by d(u, v), is the minimum weight of a path from u to v. A shortest path from u to v is a path whose weight is d(u, v). A shortest-path (spanning) tree rooted at r is a tree rooted at r that spans V_r and such that, for every process u, the unique path from u to r in the built tree is a shortest path from u to r in V_r.

figure d
Correctness of \mathsf {RSP}. By definition, r is the unique process satisfying canBeRoot. So, only r can satisfy P\_root . By Observation 9, P\_root (r) holds in any terminal configuration of \mathsf {RSP}.

Observation 11
In a terminal configuration of Algorithm \mathsf {RSP}, each process u satisfies one of the following three conditions:

(1) u = r and P\_root (r) holds; (2) u \in V_r \setminus \{r\}, st_u = C, par_u \in \varGamma (u), and d_u = d_{par_u}+\omega _u(par_u); or (3) u \notin V_r and st_u = I.

In a terminal configuration of Algorithm \mathsf {RSP}, each process u satisfies u \notin V_r, or d_u = d(u,r).

Move Complexity of \mathsf {RSP}. All edge weights are strictly positive and \oplus is the addition operator, so the total number of moves (and steps) during any execution is bounded by (\mathtt {W}_{\max }\cdot ({n_{\mathtt {maxCC}}}-1)^2+5)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n (Theorem 3, page 25), i.e., O({n_{\mathtt {maxCC}}}^3\cdot n\cdot \mathtt {W}_{\max }).

Construction of BFS tree rooted at r. If all edge weights have the same value (for instance, 1) then Algorithm \mathsf {RSP} builds a BFS tree rooted at r in V_r. In any other component, the processes take the status I (Isolated). As edges have the same weight, the total number of moves (and steps) during any execution is bounded by (({n_{\mathtt {maxCC}}}-1)^2+5)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n (Corollary 8, page 25), i.e., O({n_{\mathtt {maxCC}}}^3\cdot n).

Bounded Memory Space version of \mathsf {RSP}. Corollary 3 (page 19) describes the instantiation of \mathsf {TbC} requiring only bounded memory space that is similar to \mathsf {RSP} (i.e., a terminal configuration of this instantiation is a terminal configuration of \mathsf {RSP}). The set {distSetFinite} can be any finite set containing every distance d that may be assumed in a terminal configuration of \mathsf {RSP}. Therefore, each process only needs to know an upper bound \mathtt {BL} on the maximum weighted distance to r. This corresponds to setting {distSetFinite} = \{ d \in {\mathbb {N}} ~| ~ d \le \mathtt {BL}\}. This could also be done by providing an upper bound B on the network size and an upper bound \mathtt {BW} on the edge weights, and setting \mathtt {BL}= B\cdot \mathtt {BW}. Finally, the move complexity of the Bounded Memory Space version of \mathsf {RSP} remains the same as the one of the initial version of \mathsf {RSP}, i.e., O({n_{\mathtt {maxCC}}}^3\cdot n\cdot \mathtt {W}_{\max }).

Leader Election of the Process with the Smallest Identifier and Shortest-Path-Tree Construction Requiring Bounded Memory Space
Assuming the network is identified, Algorithm \mathsf {LEM\_SP\_BD} is the instantiation of \mathsf {TbC} with the parameters given in Algorithm 5. The variable d has two fields. The first one, id, eventually contains the identifier of the elected process. The second one, h, contains the weighted distance to the elected process.

In each connected component, Algorithm \mathsf {LEM\_SP\_BD} elects (in a self-stabilizing manner) the process \ell (i.e., P\_leader (\ell ) holds) of smallest identifier and builds a shortest-path tree rooted at \ell .

The memory space required by Algorithm \mathsf {LEM\_SP\_BD} on each process is bounded by O(\log (B\cdot \mathtt {BW})) bits, where B is an upper bound on the maximum value of a process identifier and \mathtt {BW} is an upper bound on the edge weights (an upper bound on the maximum weighted distance could also be used; see the discussion on that matter in Sect. 7.3). However, each process needs to know both B and \mathtt {BW}.

Correctness of \mathsf {LEM\_SP\_BD}. As canBeRoot is true for all processes, in a terminal configuration of \mathsf {LEM\_SP\_BD}, no process has the status I. According to Corollary 3 (page 19), we have the following observation.

figure e
Observation 12
In a terminal configuration of Algorithm \mathsf {LEM\_SP\_BD}, each process u satisfies one of the following conditions: (1) P\_root (u), or (2) st_u = C, par_u \in \varGamma (u), d_u = (d_{par_u}.id, d_{par_u}.h + \omega _u(par_u)).

In a terminal configuration of Algorithm \mathsf {LEM\_SP\_BD}, for every process u of {\mathcal {C}}, d_u = (pname_\ell ,d(u,\ell )) with \ell being the process having the smallest identifier in {\mathcal {C}}.

Move Complexity of \mathsf {LEM\_SP\_BD}. SI_{{\mathcal {S}},v} is the set of d values obtained after executing an action belonging to the maximal causal chains rooted at v in the segment {\mathcal {S}}; see definition 13. SI_{{\mathcal {S}},v} \subseteq \{ ds_{{\mathcal {S}},v} \oplus (i \cdot (\bot , 1)) ~|~ 1 \le i \le \mathtt {W}_{\max }\cdot ({n_{\mathtt {maxCC}}}-1)\}, ds_{{\mathcal {S}},v} being the initiating value common to all maximal causal chains of {\mathcal {S}} rooted at v. So, |SI_{{\mathcal {S}},v}| \le \mathtt {W}_{\max }\cdot ({n_{\mathtt {maxCC}}}-1). According to Corollary 6 (page 24), the total number of moves (and steps) during any execution is bounded by (\mathtt {W}_{\max }\cdot ({n_{\mathtt {maxCC}}}-1)^2+5)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n, i.e., O({n_{\mathtt {maxCC}}}^3\cdot n\cdot \mathtt {W}_{\max }).

Construction of a BFS tree rooted at the process having the smallest identifier and requiring bounded memory space. If all edge weights have the same value (for instance, 1) then in each connected component {\mathcal {C}}, Algorithm \mathsf {LEM\_SP\_BD} builds a BFS tree rooted at the process having the smallest identifier of {\mathcal {C}}. As edges have the same weight, the total number of moves (and steps) during any execution is bounded by (({n_{\mathtt {maxCC}}}-1)^2+5)\cdot ({n_{\mathtt {maxCC}}}+1)\cdot n (Corollary 8, page 25), i.e., O({n_{\mathtt {maxCC}}}^3\cdot n).

Version of \mathsf {LEM\_SP\_BD} without any knowledge about the identifiers and the edge weights. Corollary 3 (page 19) presents the instantiation of \mathsf {TbC} not requiring any network knowledge and similar to \mathsf {LEM\_SP\_BD} (i.e. a terminal configuration of this instantiation is a terminal configuration of \mathsf {LEM\_SP\_BD}). The memory space required by this instance on each process is unbounded though. Indeed, given any bound B on the second component h of a distance, such a value B for h could be initially present at some process u and another process v might connect to u and obtain a second component larger than the bound B. The move complexity of this instance is also O({n_{\mathtt {maxCC}}}^3\cdot n\cdot \mathtt {W}_{\max }).

Depth-First Search Tree and Non-rooted Components Detection
Assume the existence of a unique root r. Algorithm \mathsf {RDFS} is the instantiation of \mathsf {TbC} with the parameters given in Algorithm 6. Algorithm \mathsf {RDFS} computes (in a self-stabilizing manner) a depth-first search (DFS) tree spanning the connected component of G containing r. Moreover, in any other component, processes eventually detect the absence of r by taking the status I (Isolated).

Here, the weight of the arc (u, v) is \alpha _u(v), the local label of u in \varGamma (v). Let {\mathcal {P}} = u_k,u_{k-1},\ldots u_0 = r be a (directed) path from process u_k to the root r. We define the weight of {\mathcal {P}} as the sequence 0, \alpha _1(u_0), \alpha _2(u_1), \ldots , \alpha _k(u_{k-1}). The lexicographical distance from process u to the root r, denoted by d_{lex}^r(u), is the minimum weight of a path from u to r (according to the lexicographical order).

figure f
Correctness of \mathsf {RDFS}. Algorithm \mathsf {RDFS} self-stabilizes to a terminal legitimate configuration that satisfies the following requirements.

Observation 13
In a legitimate configuration of Algorithm \mathsf {RDFS}, each process u satisfies one of the following three conditions:

1.
u = r and P\_root (r) holds;

2.
u \ne r, u \in V_r, st_u = C, par_u \in \varGamma (u), and d_u = d_{lex}(u,r) = d_{par_u}.\omega _u(par_u); or

3.
u \notin V_r and st_u = I.

Let T be a tree rooted at r that spans V_r. Following the result of [12], if for every process u \in V_r, the weight of the path from u to r in T is equal to d_{lex}^r(u), then T is a (first) DFS spanning tree of V_r.

Move Complexity of \mathsf {RDFS}. For this instance, we cannot apply Corollary 6 (page 24) to obtain a polynomial move complexity. However, by Lemma 14 we have a rough estimation of the move complexity, i.e., at most ({n_{\mathtt {maxCC}}}-1)! moves. We outline that this estimation is coarse-grained, and so can be further refined.

Bounded Memory Space version of \mathsf {RDFS}. Corollary 3 (page 19) describes the instantiation of \mathsf {TbC} requiring only bounded memory space that is similar to \mathsf {RDFS} (i.e., a terminal configuration of this instantiation is a terminal configuration of \mathsf {RDFS}). The set {distSetFinite} can be any finite set containing every distance d that may be assumed in a terminal configuration of \mathsf {RDFS}. Therefore, each process only needs to know an upper bound B on the network size and an upper bound \mathtt {BD} on \varDelta (the maximum degree of G). This corresponds to setting {distSetFinite} = \{0,\ldots ,\mathtt {BD}\}^{\le B}, the set of words of length at most B over the alphabet \{0,\ldots ,\mathtt {BD}\}.

Optimum-Bandwidth-Path (Spanning) Tree
Assume the existence of a unique root r. Algorithm \mathsf {RBW} is the instantiation of \mathsf {TbC} with the parameters given in Algorithm 7. The variable d on v contains the multiset of the edge bandwidths in the path from v to r. Note that storing only the bottleneck bandwidth or the set of edge bandwidths (even combined with the distance to r) would not satisfy the constraints on \oplus and \prec stated in Fig. 1.

Algorithm \mathsf {RBW} computes (in a self-stabilizing manner) a spanning tree rooted at r in V_r. The path from u to r in the spanning tree is one that maximizes the bandwidth. Moreover, in any other component, processes eventually detect the absence of r by taking the status I (Isolated).

The bandwidth of a path is the minimum of its edge bandwidths. The bandwidth capability between the processes u and v, denoted by bwc(u, v), is the maximum bandwidth of a path from u to v. An optimum bandwidth path from u to v is a path whose bandwidth is bwc(u, v). An optimum-bandwidth-path (spanning) tree rooted at r is a tree rooted at r that spans V_r and such that, for every process u, the unique path from u to r in the built tree is an optimum-bandwidth-path from u to r in V_r.

figure g
Correctness of \mathsf {RBW}. First note that the ordered magma and the weight assignment satisfy the constraints on \oplus and \prec stated in Fig. 1. By definition, r is the unique process satisfying canBeRoot. So, only r can satisfy P\_root . By Observation 9, P\_root (r) holds in any terminal configuration of \mathsf {RBW}.

Observation 14
In a terminal configuration of Algorithm \mathsf {RBW}, each process u satisfies one of the following three conditions:

1.
u = r and P\_root (r) holds;

2.
u \in V_r \setminus \{r\}, par_u \in \varGamma (u), d_u = d_{par_u} \uplus \{bw_u(v)\}, and st_u = C; or

3.
u \notin V_r and st_u = I.

In a terminal configuration of Algorithm \mathsf {RBW}, each process u satisfies u \notin V_r, or d_u is the multiset of the edge bandwidths of a path such that \min d_u = bwc(u,r).

Move Complexity of \mathsf {RBW}. SI_{{\mathcal {S}},v} is the set of distance values obtained after executing an action belonging to the maximal causal chains rooted at v in the segment {\mathcal {S}}; see Definition 13. Let k be the number of different edge bandwidths in the network. The size of SI_{{\mathcal {S}},v} is at most the number of multisets of at most {n_{\mathtt {maxCC}}}-1 elements from the set of the k possible edge bandwidths, such a multiset being added (by successive disjoint unions of singletons) to the initiating multiset ds_{{\mathcal {S}},v}. So the size of SI_{{\mathcal {S}},v} is bounded by \left( {\begin{array}{c}k+{n_{\mathtt {maxCC}}}-1\\ {n_{\mathtt {maxCC}}}-1\end{array}}\right) = \left( {\begin{array}{c}k+{n_{\mathtt {maxCC}}}-1\\ k\end{array}}\right) . According to Corollary 6 (page 24), the total number of moves during any execution, is bounded by (\left( {\begin{array}{c}k+{n_{\mathtt {maxCC}}}-1\\ k\end{array}}\right) ({n_{\mathtt {maxCC}}}-1)+5)({n_{\mathtt {maxCC}}}+1)n. In practice, the number k of different bandwidth values may be small (one per technology for example), or the bandwidth values may be grouped in a small number of ranges. When k is constant, the total number of moves during any execution becomes polynomial, in O({n_{\mathtt {maxCC}}}^{k+2} \cdot n).

Bounded Memory Space version of \mathsf {RBW}. Corollary 3 (page 19) describes the instantiation of \mathsf {TbC} requiring only bounded memory space similar to \mathsf {RBW} (i.e., a terminal configuration of this instantiation is a terminal configuration of \mathsf {RBW}). The set {distSetFinite} can be any finite set containing every distance d that may be assumed in a terminal configuration of \mathsf {RBW}, for example the set of all multisets of at most {n_{\mathtt {maxCC}}}-1 elements from the set of the k possible edge bandwidths. Therefore, each process only needs to know an upper bound B on the network size and an upper bound \mathtt {BW} on the edge bandwidths. Even better than the knowledge of \mathtt {BW} would be the complete knowledge of the k possible edge bandwidths. In this case, and when k is constant, the memory requirement for the distance d value would be logarithmic in {n_{\mathtt {maxCC}}}.

Conclusion
We proposed a general scheme, called Algorithm \mathsf {TbC}, to compute tree-based data structures on arbitrary (not necessarily connected) bidirectional networks.

Algorithm \mathsf {TbC} is self-stabilizing and silent. It is written in the locally shared memory model with composite atomicity. We have proven its correctness under the distributed unfair daemon hypothesis, the weakest scheduling assumption of the model. We have also shown that its stabilization time is at most 4{n_{\mathtt {maxCC}}} rounds, where {n_{\mathtt {maxCC}}} is the maximum number of processes in a connected component.

We illustrated the versatility of our approach by proposing several instantiations of \mathsf {TbC} that solve classical problems in various settings. For example, we can instantiate \mathsf {TbC} to solve leader election and/or spanning tree or forest constructions in identified or semi-anonymous (e.g., rooted) networks. These spanning structures may be of different types, e.g., arbitrary, BFS, DFS, shortest-path, ... Note also that, whenever the network is not connected, \mathsf {TbC} also achieves the non-rooted components detection.

In most of the cases, we exhibited polynomial upper bounds on the stabilization time in steps and process moves of the considered instantiations. Finally, in many cases, instantiations can be easily modified to handle bounded local memories, without any overhead.