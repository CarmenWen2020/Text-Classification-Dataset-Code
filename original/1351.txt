Abstract
Scientific communities confer many forms of credit on their successful members. The motivation provided by these forms of credit helps shaping a community’s collective attention toward different lines of research. The allocation of scientific credit, however, has also been the focus of long-documented pathologies: certain research questions are said to command more credit then they deserve; and certain researchers seem to receive a disproportionate share of the credit. Here we show that each of these pathologies can actually increase the collective productivity of a community. We consider a model for the allocation of credit, in which individuals pick a project among projects of varying importance and difficulty levels, and compete to receive credit with others who choose the same project. Under the most natural allocation mechanism, in which credit is divided equally among those who succeed at a project in proportion to the project’s importance, the resulting selection of projects by self-interested, credit-maximizing individuals will in general be socially sub-optimal. However, we show that there exist ways of allocating credit both out of proportion to the true importance of the projects and out of proportion to the relative contributions of the individuals, that lead credit-maximizing individuals to achieve social optimality. These results therefore suggest how well-known forms of misallocation of scientific credit can in fact serve to channel self-interested behavior into socially optimal outcomes.

Introduction
As a scientific community makes progress on its research questions, it also develops conventions for allocating credit to its members. Scientific credit comes in many forms; it includes explicit markers such as prizes, appointments to high-status positions, and publication in prestigious venues, but it also builds upon a broader base of informal reputational measures and standing within the community [7, 21, 25]. The mechanisms by which scientific credit is allocated have long been the subject of fascination among scientists, as well as a topic of research for scholars in the philosophy and sociology of science. A common theme in this line of inquiry has been the fundamental ways in which credit seems to be systematically misallocated by scientific communities over time—or at least allocated in ways that seem to violate certain intuitive notions of “fairness.” Two categories of misallocation in particular stand out, as follows.

1.
Certain research questions receive an “unfair” amount of credit. In other words, a community will often have certain questions on which progress is heavily rewarded, even when there is general agreement that other questions are equally important. Such issues, for example, have been at the heart of recent debates within the theoretical computer science community, focusing on the question of whether conference program committees tend to overvalue progress on questions that display “technical difficulty” [1, 18].

2.
Certain people receive an “unfair” amount of credit. Robert Merton’s celebrated formulation of the Matthew Effect asserts, roughly, that if two (or more) scientists independently or jointly discover an important result, then the more famous one receives a disproportionate share of the credit, even if their contributions were equivalent [24, 25].Footnote 1 Other attributes such as affiliations or academic pedigree can play an analogous role in discriminating among researchers.

There is a wide range of potential explanations for these two phenomena, and many are rooted in hypotheses about human cognitive factors: a fascination with “hard” problems or the use of such problems to identify talented problem-solvers in the first case; the effect of famous individuals as focal points or the confidence imparted by endorsement from a famous individual in the second case [24, 34].

A model of competition and credit in science. One can read this state of affairs as a story of how fundamental human biases lead to inherent unfairness, but we argue in this paper that it is useful to bring into the discussion an alternate interpretation, via a natural formal model for the process by which scientists choose problems and by which credit is allocated.

We begin by adapting a model proposed in influential work of Kitcher in the philosophy of science [20, 21, 33], and with roots in earlier work of Peirce, Arrow, and Bourdieu [2, 9, 27]. Kitcher’s model has some slightly complicated features that we do not need for our purposes, so we will focus the discussion in terms of the following closely related model; it is designed as a stylized abstraction of a community of n researchers who each choose independently among a set of m open problems to work on.

The m open problems will also be referred to as projects. Each project j has an importance 𝑤𝑗 (also called its weight), and a probability of success 𝑞𝑗 (with a corresponding failure probability 𝑓𝑗=1−𝑞𝑗). We assume these numbers are rational. The researchers will initially be modeled as identical, but we later consider generalizations to individuals with different problem-solving abilities.

Each researcher must choose a single project to work on. We model researchers as working independently, so if 𝑘𝑗 researchers work on project j, there is a probability of (1−𝑓𝑘𝑗𝑗) that at least one of them succeeds.

In the event that multiple researchers succeed at project j, one of them is chosen uniformly at random to receive an amount of credit equal to the project’s importance 𝑤𝑗. We can imagine there is a “race” to be the first to solve the problem, and the credit goes to the “winner” ; alternately, we get the same model if we imagine that all successful researchers divide the credit equally and the researchers are maximizing their expected utility.

Suppose that researchers are motivated by the amount of credit they receive: each researcher chooses a project to work on to maximize her expected amount of credit, given the choices of all other researchers. The selection of projects is thus a game, in which the players are the researchers, the strategies are the choices of projects, and the payoffs are the expected amount of credit received. This game-theoretic view forms the basis of Kitcher’s model of scientific competition; the view itself was perhaps first articulated explicitly in this form by the social scientist Pierre Bourdieu [7, 9], who wrote that researchers’ motivations

are organized by reference to – conscious or unconscious – anticipation of the average chances of profit ... Thus researchers’ tendency [is] to concentrate on those problems regarded as the most important ones ... The intense competition which is then triggered off is likely to bring about a fall in average rates of symbolic profit, and hence the departure of a fraction of researchers towards other objects which are less prestigious but around which the competition is less intense, so that they offer profits of at least as great.

Like the frameworks of Bourdieu and Kitcher, our model is a highly simplified version of the actual process of selecting research projects and competing for credit. We are focusing on projects that can be represented as problems to be solved; we are not modeling the process of collaboration among researchers, the ways in which problems build on each other, or the ways in which new problems arise; and we are not trying to capture the multiple ways in which one can measure the importance or difficulty of a problem. These are all interesting extensions, but our point is to identify a tractable model that contains the fundamental ingredients in our discussion: a competition for credit among projects of varying difficulty, in a way that causes credit-seeking individuals to distribute themselves across different projects. We will see how phenomena that are complex but intuitively familiar can arise even when a community has a single, universally agreed-upon measure of importance and difficulty across projects.

Credit as a mechanism for allocating effort. Our main focus is to extend this class of models to consider the issues raised at the outset of the paper, and in particular to the two sources of “unfairness” discussed there. The model we have described thus far is based on an intuitively fair allocation of credit that does not suffer from either of these two pathologies: all researchers are treated identically, and the credit a successful researcher receives is equal to the community’s agreed-upon measure of the importance of the problem solved. In other words, no problems are overvalued relative to their true importance, and no researchers are a priori favored in the assignment of credit.

Fig. 1
figure 1
In a self-interested players do not reach a socially optimal selection of projects. However, if the weight of project y is increased (b), or if one of the players is guaranteed a sufficiently disproportionate share of the credit in the event of joint success (c), then a socially optimal assignment of players to projects arises

Full size image

As a first thought experiment, suppose that we were allowed to design the rules by which credit was assigned in a research community; are these “fair” rules the ones we should use? The following very small example shows the difficulties we quickly run into. Suppose, for simplicity, that we are dealing with a community consisting of two players a and b, and two projects x and y. Project x is more important and also easier; it has 𝑤𝑥=1 and 𝑞𝑥=1/2. Project y is less important and more difficult; it has 𝑤𝑦=9/10 and 𝑞𝑦=1/3. Figure 1a shows the unique Nash equilibrium for this research community: both players work on x, each receiving an expected payoff 3/8 (since project x will be solved with probability 3/4, and a and b are equally likely to receive credit for it.)

If we were in charge of this research community, arguably the natural objective function for us to care about would be the social welfare, defined as the total expected importance of all projects successfully completed. And now here’s the difficulty: the unique Nash equilibrium does not maximize social welfare. It produces a social welfare of 3/4, whereas if the players divided up over the two different projects, we would obtain a social welfare of 1/2+3/10=4/5.

Can we change the way credit is assigned so as to create incentives for the players under which the resulting Nash equilibrium maximizes social welfare? In fact, there are two natural ways to do this, and each should be recognizable given the discussion at the beginning of the introduction.

First, we could declare that the credit received for succeeding at a project will not be proportional to its importance. Instead, in our example, we could decide that success at the harder project y will bring an amount of credit equal to 𝑤′𝑦≠𝑤𝑦. If 9/5>𝑤′𝑦>9/8, then the unique (up to symmetry) pure Nash equilibrium is socially optimal (Figure 1(b)).

Alternately we could declare that if players a and b both succeed at the same project, they will not split the credit equally, but instead in a ratio of c to 1. (Equivalently, if they both succeed, player a is selected to receive all the credit with probability 𝑐/(𝑐+1) and player b with probability 1/(𝑐+1).) If 𝑐>4, then it is not worth it for b to try competing with a on project x, and b will instead work on project y, again leading to a socially optimal Nash equilibrium (Figure 1(c)).

This example highlights that we can think of the amount of credit associated with different projects as something malleable; by choosing to have certain projects confer more credit, the community can create incentives that cause effort to be allocated in different ways.

We also note that we will be working with pure Nash equilibria, rather than mixed equilibria, and we will consider equilibria in this work to be pure unless explicitly stated otherwise. We believe this is appropriate for environments such as ours in which researchers tend to make discrete choices about the selection of projects, rather than randomizing over different projects; such fixed choices lead to strategy profiles that produce pure Nash equilibria, and this is consistent with earlier models of effort decisions by researchers (e.g. [20, 21, 33]).

What we see in the example is that the “fair” allocation of credit can be at odds with the goal of social optimality: if the community believes that as a whole it is being evaluated according to the total expected weight of successful projects, then by rewarding its participants according to these same weights, it produces a socially sub-optimal outcome. The two alternate ways of assigning credit above correspond to the two forms of “unfairness” discussed at the outset: overvaluing certain projects (in our example, the harder and less important project), and overvaluing the contributions of certain researchers. If done appropriately in this example, either of these can be used to achieve social optimality.

As a final point on the underlying motivation, we are not claiming that research communities are overtly trying to assign credit in a way that achieves social optimality, or arriving at credit allocations in general through explicit computation. It is clear that the human cognitive biases discussed earlier—in favor of certain topics and certain people—are a large and likely dominant contributor to this. Nor are we claiming that these forms of assigning credit, or the biases they introduce, are in any sense normatively desirable. What we do suggest, however, is that social optimality may be at odds with a fair allocation of credit and as a result eliminating biases from people’s behavior may be challenging.

Social optimality and misallocation of credit: General results. Our main results begin by establishing that the two kinds of mechanisms suggested by the example in Figure 1 are each sufficient to ensure social optimality in general—that is, in all instances. For any set of projects, it is possible to assign each project j a modified weight 𝑤′𝑗, potentially different from its real weight 𝑤𝑗, so that when players receive credit according to these modified weights, all Nash equilibria are socially optimal with respect to the real weights. It is also possible to assign each player i a weight 𝑧𝑖 so that when players divide credit on successful projects in proportion to their weights 𝑧𝑖, all Nash equilibria are again socially optimal. This makes precise the sense in which our two categories of credit misallocation can both be used to optimize social welfare.

These results in fact hold in a generalization of the basic model, in which the players are heterogeneous and have different levels of ability at solving problems. In this more general model, a player’s success at a project depends on both her ability and the project’s difficulty: each player i has a parameter 𝑝𝑖≤1 such that her probability of succeeding at project j is equal to the product 𝑝𝑖𝑞𝑗. Beyond this, the remaining aspects of the model remain the same; in particular, if multiple players all succeed at the same project, then one is selected uniformly at random to receive the credit. (That is, their ability affects their chance of succeeding, but not their share of the credit.) For this more general game, there still always exist re-weightings of projects and also re-weightings of credit shares to players that lead to socially optimal Nash equilibria.

Our results make use of the fact that the underlying game, even in its more general form with heterogeneous players, is both a congestion game [26, 28] and a monotone valid-utility game [17, 35, 37]. However, given the motivating setting for our analysis, we have the ability to modify certain parameters of the game—as part of a research community’s mechanism for allocating credit—that are not normally under the control of the modeler. As a result, our focus is on somewhat different questions, motivated by these credit allocation schemes. At the same time, there are interesting analogies to issues in congestion games from other settings. Re-weighting the amount of credit on projects can be viewed as a kind of “toll” system (as studied in e.g., [11, 13]), interpreting the effort of the researchers as the “traffic” in the congestion game. While there are often infrastructural costs for introducing incentivizing modifications to physical traffic systems, we argue here that the nature of scientific credit—since it is allocated in terms of “symbolic profit” in Bourdieu’s terminology—makes it much more malleable than physical infrastructure. Hence it becomes correspondingly more reasonable to model the relative implementation costs of different credit allocation schemes to be roughly comparable to each other. The crux of our analysis for re-weighting the players is to begin by considering an alternate model in which an ordering is defined on the players, and the first player in this ordering to succeed receives all the credit. This suggests interesting potential connections with the theory of priority algorithms introduced by Borodin et al. [8]; although the context is quite different, we too are asking whether there is a “greedy ordering” that leads to optimality. A related set of questions was considered by Strevens in his model of sequential progress on a research problem, working within Kitcher’s model of scientific competition [33].

We also consider some of the structural aspects of the underlying game; among other results, we show that the price of anarchy of the game is always strictly less than 2 (compared with a general upper bound of 2, which can sometimes be attained, for fully general monotone valid-utility games). For the case of identical players, we also show that the ratio of the price of anarchy to the price of stability (i.e. the welfare of the best Nash equilibrium relative to the worst) is at most 3/2. In particular, this implies that when there exists a Nash equilibrium that is optimal, there is no Nash equilibrium that is less than 2/3 times optimal.

Finally, we consider a still more general model, in which player success probabilities are arbitrary and unrelated: player i has a probability 𝑝𝑖𝑗 of succeeding on project j. We show that there exist instances of this general game in which no re-weighting of the projects yields a social optimal Nash equilibrium. However we do not rule out the possibility that there exists a re-weighting of the players that yields a socially optimal Nash equilibrium.

We note that the model of heterogeneous players with player parameters 𝑝𝑖≤1, project parameters 𝑞𝑗, and success probabilities 𝑝𝑖𝑞𝑗 is of course a special case of the model with general success probabilities 𝑝𝑖𝑗, and we believe it is a robust special case to consider, in that it approximates any scenario in which outcomes are determined by the ability of the player (𝑝𝑖) and by the difficulty of the project (𝑞𝑗). For example, it can be viewed as approximating to any case in which the matrix of success probabilities 𝑝𝑖𝑗 is nearly rank-one, since that would imply that the entries can be approximated by this product form.

Interpreting the model. With any simple theoretical model of a social process—in this case, credit among researchers—it is important to ask whether the overall behavior of the model captures fundamental qualitative aspects of the real system’s behavior. In this case we argue that it captures several important phenomena at a broad level. First, it is based on the idea that institutions within a research community can and do shift the amount of credit that different research topics receive, and in a number of cases with the goal of creating corresponding incentives toward certain research directions. Second, it argues that some of the typical ways in which credit is misallocated can interact in a complex fashion with social welfare, and that these misallocations can in fact play an important role in the maximization of welfare.

Moreover, there is a rapidly widening scope for the potential application of explicitly computational approaches to credit-allocation, as we see an increasing number of intentionally designed systems aimed at fostering massive Internet based-collaboration—these include large open-source projects, collaborative knowledge resources like Wikipedia, and collective problem-solving experiments such as the Polymath project [19]. For example, a number of credit-allocation conventions familiar from the scientific community have been built into Wikipedia, including the ways in which editors compete to have articles “featured” on the front page of the site [32], and the ways in which they go through internal review and promotion processes to achieve greater levels of status and responsibility [10, 23]. While the framework in this paper is only an initial foray in this direction, the general issue of designing credit-allocation schemes to optimize collective productivity becomes an increasingly wide-ranging question.

There are also potential connections to work in an area termed the economics of science, which studies the allocation of resources by organizations across different research projects [7, 30], in the context of activities such as R&D (e.g. [14]). An additional relevant literature is the one on procurement contests in which an organization offers a reward for the best innovation of some kind and competing firms decide how much effort to invest (e.g. [4, 12, 36]). While the central issues in these models are somewhat different, connecting them more closely to the questions raised here is an interesting question.

Finally, the model offers a set of simple and, in the end, intuitively natural interpretations for the specific ways in which misallocation can lead to greater collective productivity. The re-weighting of projects not only follows the informal roadmap contained in Pierre Bourdieu’s quote above, but sharpens it. Even without re-weighting of projects, the effect of competition does work to disperse some number of researchers out to harder and/or less attractive projects, which helps push the system toward states of higher social welfare. But the point is that this dispersion is not optimally balanced on its own; it needs to be helped along, and this is where the re-weighting of projects comes into play. The re-weighting of players is based on a different point—that when certain individuals are unfairly marginalized by a community, it can force them to embark on higher-risk courses of action, enabling beneficial innovation that would otherwise not have happened. In all these cases, it does not mean that such forms of misallocation are fair to the participants in the community, only that they can sometimes have the effect of increasing the community’s overall output.

As part of these interpretations, it is important to emphasize that the model is not claiming the research community is deliberately allocating credit unfairly to increase its welfare. There are two senses in which this is not a claim of the paper: first, because we are not asserting that the research community is explicitly computing measures of social welfare, even when it does engage in the creation of mechanisms for encouraging particular kinds of research; and second, because we do not believe it is normatively reasonable to impose unequal costs on a subset of researchers. The point of the model is a different one: to show that unfair allocation of credit can lead to higher levels of welfare for the overall community, and so to the extent that the community incurs global benefits through this increased welfare, it might set up implicit incentives to engage in this type of credit allocation, whether deliberately or not. In this way, the welfare-increasing properties of these biases may contribute to their being harder to eliminate.

Identical Players
We first consider the case of the project game defined in the introduction when all players are identical, and then move on to the case in which players have different levels of ability. Recall that 𝑤𝑗 denotes the weight (i.e. importance) of project j, and 𝑓𝑗 denotes the probability that any individual player fails to succeed at it. Thus, when there are k players working on project j, the contribution of project j to the social welfare is 𝑤𝑗(1−𝑓𝑘𝑗), and we denote this quantity by 𝜎𝑗(𝑘).

We denote the choices of all players by a strategy vector 𝐚, in which player i chooses to work on project 𝑎𝑖. As is standard, we denote by 𝑎−𝑖 the strategy vector 𝐚 without the 𝑖th coordinate and by 𝑗,𝑎−𝑖 the strategy vector 𝑎1,…,𝑎𝑖−1,𝑗,𝑎𝑖+1,…,𝑎𝑛. We use 𝐾𝑗(𝐚) to denote the set of players working on project j in strategy vector 𝐚, and we write 𝑘𝑗(𝐚)=|𝐾𝑗(𝐚)|. The social welfare obtained from strategy vector 𝐚 is 𝑢(𝐚)=∑𝑗∈𝑀𝜎𝑗(𝑘𝑗(𝐚)). Since each of the players working on the project is equally likely to receive the credit, the payoff, or utility, of player i under strategy vector 𝐚 is 𝑢𝑖(𝐚)=𝜎𝑎𝑖(𝑘𝑎𝑖(𝐚))𝑘𝑎𝑖(𝐚).

We make a few observations about these quantities. First, as noted in the introduction, 𝑢𝑖(𝐚) is the utility of i regardless of whether we interpret the credit as being assigned uniformly at random to one successful player on a project, or divided evenly over all successful players.

Moreover, since the players divide up the social welfare among themselves, we have ∑𝑖∈𝑁𝑢𝑖(𝐚)=𝑢(𝐚). Since a player’s utility depends solely on the number of other players choosing her project, it is not hard to verify that the game with identical players is a congestion game, and hence has pure Nash equilibria. Finally, we define the welfare improvement from increasing the number of players working on project j by 1; we denote this improvement by 𝑟𝑗(𝑘)=𝑤𝑗(1−𝑓𝑗)𝑓𝑘𝑗, where k is the number of players currently working on project j. The fact that 𝑟𝑗(𝑘) is decreasing in k is quite useful. For example, it implies that 𝑢𝑖(𝐚) is submodular in the number of players working on the same project as player i does.

We begin by developing some basic properties of the social optimum and of the set of Nash equilibria with identical players; we then build on this to prove bounds on the price of anarchy (the ratio of the social welfare of the social optimum to the worst Nash equilibrium) and the price of stability (the analogous ratio of the social optimum to the best Nash equilibrium). After this, we provide algorithms for re-weighting projects and re-weighting players so as to produce Nash equilibria that are socially optimal.

Before proceeding, we first state and prove three basic claims about the game with identical players. We begin by showing that the project game is a monotone valid-utility game. These games were defined by Vetta in [37] who showed that the price of anarchy for such games is upperbounded by 2.

Claim 2.1
The project game with identical players is a monotone valid-utility game.

Proof
We need a bit of additional notation: the quantity 𝑢(𝑎𝑖|𝑎−𝑖) will denote the marginal contribution of player i to the overall utility, given the choices made by all other players. By definition, this means that 𝑢(𝑎𝑖|𝑎−𝑖)=𝑟𝑎𝑖(𝑘𝑎𝑖(𝐚)−1).

The definition of a monotone valid-utility game [35, 37] requires verifying four properties of the utility functions, as follows.

1.
𝑢(𝐚) is submodular: Since 𝑢(𝐚) is the summation of the projects’ separate utilities, it is enough to prove that the utility of every project is submodular. For identical players this is settled by the simple observation that 𝑟𝑗(𝑘) is decreasing in k.

2.
𝑢(𝐚) is monotone: Naturally, a project’s success probability can only increase when more players are working on it, thus, the utility is monotone increasing.

3.
𝑢𝑖(𝐚)≥𝑢(𝑎𝑖|𝑎−𝑖): For this, we notice that 𝜎𝑗(𝑘𝑗(𝐚)) can be written as the sum of the marginal utilities contributed by the players on project j when they arrive to it in any order, and a player’s utility is the average of such contributions over all arrival orders. Since the utility is submodular, the smallest of these contributions occurs when i arrives last. In this case it is equal to 𝑢(𝑎𝑖|𝑎−𝑖). Hence this quantity is at most 𝑢𝑖(𝐚) as required.

4.
𝑢(𝐚)≥∑𝑖𝑢𝑖(𝐚): In this game, by the definition of a player’s utility, they are equal.

◻

Next, we show that the optimal solution can be computed in polynomial time by a simple greedy algorithm.

Claim 2.2
The optimal assignment can be computed by the following greedy algorithm: players are assigned to projects one at a time, and in each iteration a player is assigned to a project j with the greatest current marginal utility 𝑟𝑗(𝑘𝑗).

Proof
Assume towards a contradiction that the assignment resulting from the greedy algorithm 𝐚 is sub-optimal. Let 𝐨 be an optimal assignment which is the most similar to 𝐚 (i.e., minimizes ∑𝑗|𝑘𝑗(𝐚)−𝑘𝑗(𝐨)|). Since assignments are insensitive to the identity of the players and 𝑢(𝐨)>𝑢(𝐚), there exist two projects b and c such that:

𝑘𝑏(𝐚)>𝑘𝑏(𝐨)

𝑘𝑐(𝐚)<𝑘𝑐(𝐨)

Let i be the last player the algorithm assigned to project b. In the iteration when i was assigned to project b there were at most 𝑘𝑐(𝐚) players working on project c. As we noted at the beginning of Sect. 2, the function 𝑟𝑗(𝑘) is decreasing in k for all projects j, and hence 𝑟𝑏(𝑘𝑏(𝐚)−1)≥𝑟𝑐(𝑘𝑐(𝐚)). By this decreasing property we also have that 𝑟𝑏(𝑘𝑏(𝐨))≥𝑟𝑏(𝑘𝑏(𝐚)−1) and that 𝑟𝑐(𝑘𝑐(𝐚))≥𝑟𝑐(𝑘𝑐(𝐨)−1). Because 𝐨 is the optimal assignment then 𝑟𝑏(𝑘𝑏(𝐨))≤𝑟𝑐(𝑘𝑐(𝐨)−1). Hence we have that 𝑟𝑏(𝑘𝑏(𝐨))=𝑟𝑐(𝑘𝑐(𝐨)−1). Therefore, we can get another optimal solution, 𝐨1 by starting with 𝐨 and moving a single player from project c to project b. We can now reach a contradiction by observing that by construction 𝐨1 is more similar to 𝐚 than 𝐨 is. ◻

We now show that there exists a simple greedy algorithm for computing a Nash equilibrium. A similar claim was also proved in [15] in the context of a related class of congestion games.

Claim 2.3
A Nash equilibrium can be computed in polynomial time by the following algorithm: Iterate over all the players in an arbitrary order, and in each iteration let the current player i choose a project that maximizes her utility in respect to the choices made by earlier players.

Proof
Denote the assignment the algorithm computes by 𝐚. Assume towards a contradiction that player i, who is currently assigned to project j, can increase her payoff by switching to project l: 𝑢𝑖(𝑗,𝑎−𝑖)<𝑢𝑖(𝑙,𝑎−𝑖). Since all the players are identical, we can assume without loss of generality that i was the last player who chose project j. Denote by 𝐚′ the assignment vector at the iteration at which it was player i’s turn to choose a project. Since player i chose project j we have that 𝑢𝑖(𝑗,𝑎′−𝑖)≥𝑢𝑖(𝑙,𝑎′−𝑖). Noticing that 𝑘𝑙(𝐚)≥𝑘𝑙(𝐚′) and that player i’s utility function is submodular in the number of players working on the same project as her, we obtain a contradiction. ◻

We now prove that with identical players, any two Nash equilibria are very similar in their assignment of players to projects:Footnote 2

Claim 2.4
All pure Nash equilibria of the game are similar in that the number of researchers assigned to any project are within 1 of each other.

Proof
Formally, we show that for every two different Nash equilibria 𝐚 and 𝐛 and for every two projects j,l such that 𝑘𝑗(𝐚)>𝑘𝑗(𝐛) and 𝑘𝑙(𝐚)<𝑘𝑙(𝐛), we have the following relationships: 𝑘𝑗(𝐚)=𝑘𝑗(𝐛)+1 and 𝑘𝑙(𝐛)=𝑘𝑙(𝐚)+1. As assignments are insensitive to the identities of the players, we may assume there exists a player i such that 𝑎𝑖=𝑗 and 𝑏𝑖=𝑙. Since 𝐚 is a Nash equilibrium we have 𝑢𝑖(𝑗,𝑎−𝑖)≥𝑢𝑖(𝑙,𝑎−𝑖). On the other hand, 𝐛 is also a Nash equilibrium, and hence 𝑢𝑖(𝑗,𝑏−𝑖)≤𝑢𝑖(𝑙,𝑏−𝑖). Recall that j and l are two projects such that 𝑘𝑗(𝐚)>𝑘𝑗(𝐛) and 𝑘𝑙(𝐚)<𝑘𝑙(𝐛). Therefore, because a player’s utility is decreasing in the number of players working on the project, we have


𝑢𝑖(𝑗,𝑎−𝑖)≤𝑢𝑖(𝑗,𝑏−𝑖)≤𝑢𝑖(𝑙,𝑏−𝑖)≤𝑢𝑖(𝑙,𝑎−𝑖)≤𝑢𝑖(𝑗,𝑎−𝑖).

Therefore, 𝑢𝑖(𝑗,𝑎−𝑖)=𝑢𝑖(𝑗,𝑏−𝑖). This implies that 𝑘𝑗(𝐚)=𝑘𝑗(𝑗,𝑎−𝑖)=𝑘𝑗(𝑗,𝑏−𝑖)=𝑘𝑗(𝐛)+1. Similarly for 𝑢𝑖(𝑙,𝑏−𝑖)=𝑢𝑖(𝑙,𝑎−𝑖) we have that 𝑘𝑙(𝐛)=𝑘𝑙(𝑙,𝑏−𝑖)=𝑘𝑙(𝑙,𝑎−𝑖)=𝑘𝑙(𝐚)+1. ◻

The Price of Anarchy and Price of Stability
Observe that the price of anarchy (PoA) of the project game is at most 2. This is because our game is a monotone valid-utility game (Claim 2.1) and Vetta [37] showed that the price of anarchy (PoA) of monotone valid-utility games is at most 2. Here we provide a strengthened analysis of the price of anarchy that yields several consequences, all of which do not hold for monotone valid-utility games in general:Footnote 3

(i)
an upper-bound of 2−1𝑐 on the PoA for instances in which the worst Nash equilibrium has at most c players assigned to any single project.

(ii)
as a corollary of (i), a general upper bound of 2−1𝑛 on the PoA of any instance.

(iii)
an upper-bound of 32 between the worst Nash equilibrium and the best Nash equilibrium for any instance.

We first show that these bounds are tight, by means of the following example. Consider an instance with n players and n projects; all projects are guaranteed to succeed (i.e. 𝑞𝑗=1 for all j); and the weights of the projects are defined so that 𝑤1=1 and 𝑤𝑗=1/𝑛 for 𝑗>1. The socially optimal assignment of players to projects in this game is for each player to work on a different project, yielding a social welfare of 2−1𝑛. On the other hand, it is a Nash equilibrium for all players to work on project 1, yielding a social welfare of 1. Furthermore, for 𝑛=2, the social optimum is also a Nash equilibrium, establishing a ratio of 32 between the PoA and PoS in this case. (We also note that for general n, if we increase the weight of project 1 by arbitrarily little, we obtain an example in which the PoS is arbitrarily close to 2−1𝑛.)

To prove the upper bounds in (i)–(iii), we use Roughgarden’s notion of (𝜆,𝜇)-smoothness [29]Footnote 4

Definition 2.5
A monotone valid-utility game is (𝜆,𝜇)-smooth if for every two strategy vectors 𝐚 and 𝐛, we have that ∑𝑖∈𝑁𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝜆𝑢(𝐛)−𝜇𝑢(𝐚).

The following is a simple but useful claim based on Roughgarden’s paper [29]:

Claim 2.6
If a monotone valid-utility game is (𝜆,𝜇)-smooth then its price of anarchy is at most 1+𝜇𝜆.

Proof
Let 𝐚 be the worst Nash equilibrium and 𝐨 some optimal solution. Since 𝐚 is a Nash equilibrium then ∑𝑖∈𝑁𝑢𝑖(𝑜𝑖,𝑎−𝑖)≤∑𝑖∈𝑁𝑢𝑖(𝐚). Recall that this is a monotone valid-utility and hence ∑𝑖∈𝑁𝑢𝑖(𝐚)=𝑢(𝐚). Thus we have that 𝜆𝑢(𝐨)−𝜇𝑢(𝐚)≤∑𝑖∈𝑁𝑢𝑖(𝑜𝑖,𝑎−𝑖)≤𝑢(𝐚). By rearranging the terms we get that 𝑢(𝐨)≤1+𝜇𝜆𝑢(𝐚) as required. ◻

Theorem 2.7
The project game with identical players is (𝜆,𝜇)-smooth for 𝜆=1 and


𝜇=max{𝑙| 𝑘𝑙(𝐚)>𝑘𝑙(𝐛)≥1} 𝑘𝑙(𝐚)−𝑘𝑙(𝐛)𝑘𝑙(𝐚)−𝑘𝑙(𝐛)+1.

Before proving the theorem we assert that (i)-(iii) can indeed be derived from it. First observe that by Claim 2.6 and the claim that 𝜆=1, an instance maximizing the PoA is an instance for which the value of 𝜇 is maximized. It is not hard to see that if the number of players working on each project is at most c, then 𝜇≤𝑐−1𝑐 as 𝑘𝑙(𝐚)≤𝑐 and 𝑘𝑙(𝐛)≥1 for a project l maximizing the expression for 𝜇. Thus, by applying Claim 2.6 we get consequence (i). Consequence (ii) is obtained by observing that the number of players working on a project is always bounded by n. To obtain consequence (iii), it suffice to require that the (𝜆,𝜇)-smoothness condition only holds for Nash equilibria, rather than all arbitrary strategy vectors. In this case, for any two Nash equilibria 𝐚 and 𝐛, Claim 2.4 implies that the number of players working on each project in 𝐚 and 𝐛 can differ by at most one. Hence, by Theorem 2.7 we have that the (𝜆,𝜇)-smoothness condition for Nash equilibria holds for the project game with identical players with 𝜇=12. Now, similarly to Claim 2.6 we have that the ratio between 𝐚 the worst Nash equilibrium and 𝐛 the best Nash equilibrium is 𝑢(𝐛)𝑢(𝐚)≤32.

We are now ready to prove Theorem 2.7. We will show that for the project game with identical players a stronger condition than the one in Definition 2.5 holds. That is, there exist 𝜆 and 𝜇 such that, for every strategy vectors 𝐚 and 𝐛:


∀𝑗∈𝑀  ∑𝑖∈𝐾𝑗(𝐛)𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝜆𝜎𝑗(𝑘𝑗(𝐛))−𝜇𝜎𝑗(𝑘𝑗(𝐚)).

(1)

The next two claims compare two strategy vectors 𝐚 and 𝐛 with respect to a given project j in two cases: 𝑘𝑗(𝐚)>𝑘𝑗(𝐛)>0 (Claim 2.8) and 𝑘𝑗(𝐚)≤𝑘𝑗(𝐛) (Claim 2.9). More specifically, they establish the following:

If 𝑘𝑗(𝐚)>𝑘𝑗(𝐛)≥1 then ∑𝑖∈𝐾𝑗(𝐛)𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝜎𝑗(𝑘𝑗(𝐛))−𝑘𝑗(𝐚)−𝑘𝑗(𝐛)𝑘𝑗(𝐚)−𝑘𝑗(𝐛)+1𝜎𝑗(𝑘𝑗(𝐚)).

If 𝑘𝑗(𝐚)≤𝑘𝑗(𝐛) then ∑𝑖∈𝐾𝑗(𝐛)𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝜎𝑗(𝑘𝑗(𝐛)).

This completes the proof of Theorem 2.7 as we have that Condition 1 holds for the project game with identical players for 𝜆=1, 𝜇=max{𝑙| 𝑘𝑙(𝐚)>𝑘𝑙(𝐛)≥1} 𝑘𝑙(𝐚)−𝑘𝑙(𝐛)𝑘𝑙(𝐚)−𝑘𝑙(𝐛)+1 and hence the game is (𝜆,𝜇)-smooth for the appropriate values for Theorem 2.7. We now provide the proofs of Claim 2.8 and Claim 2.9:

Claim 2.8
If 𝑘𝑗(𝐚)>𝑘𝑗(𝐛)≥1 then ∑𝑖∈𝐾𝑗(𝐛)𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝜎𝑗(𝑘𝑗(𝐛))−𝑘𝑗(𝐚)−𝑘𝑗(𝐛)𝑘𝑗(𝐚)−𝑘𝑗(𝐛)+1𝜎𝑗(𝑘𝑗(𝐚)).

Proof
First, note that since all the players that work on project j in 𝐛 also work on it in 𝐚, we have that ∀𝑖∈𝐾𝑗(𝐛): 𝑢𝑖(𝑏𝑖,𝑎−𝑖)=𝑢𝑖(𝐚)=𝜎𝑗(𝑘𝑗(𝐚))𝑘𝑗(𝐚). Thus, ∑𝑖∈𝐾𝑗(𝐛)𝑢𝑖(𝑏𝑖,𝑎−𝑖)=𝑘𝑗(𝐛)⋅𝜎𝑗(𝑘𝑗(𝐚))𝑘𝑗(𝐚). Hence, what left to show is that


𝑘𝑗(𝐛)𝑘𝑗(𝐚)𝜎𝑗(𝑘𝑗(𝐚))+𝑘𝑗(𝐚)−𝑘𝑗(𝐛)𝑘𝑗(𝐚)−𝑘𝑗(𝐛)+1𝜎𝑗(𝑘𝑗(𝐚))≥𝜎𝑗(𝑘𝑗(𝐛)).

The proof is completed by observing that 𝜎𝑗(𝑘𝑗(𝐚))≥𝜎𝑗(𝑘𝑗(𝐛)) as 𝜎𝑗(⋅) is monotone and that for 𝑘𝑗(𝐛)≥1:


𝑘𝑗(𝐛)𝑘𝑗(𝐚)+𝑘𝑗(𝐚)−𝑘𝑗(𝐛)𝑘𝑗(𝐚)−𝑘𝑗(𝐛)+1≥𝑘𝑗(𝐛)𝑘𝑗(𝐚)+𝑘𝑗(𝐚)−𝑘𝑗(𝐛)𝑘𝑗(𝐚)=1.

◻

Claim 2.9
If 𝑘𝑗(𝐚)≤𝑘𝑗(𝐛) then ∑𝑖∈𝐾𝑗(𝐛)𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝜎𝑗(𝑘𝑗(𝐛)).

Proof
If 𝑘𝑗(𝐚)=𝑘𝑗(𝐛) then clearly the claim holds. Else, 𝑘𝑗(𝐚)<𝑘𝑗(𝐛). We first observe that ∀𝑖∈𝐾𝑗(𝐛): 𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝜎𝑗(𝑘𝑗(𝐚)+1)𝑘𝑗(𝐚)+1, since the utility of all players working on project j both in 𝐚 and in 𝐛 is 𝜎𝑗(𝑘𝑗(𝐚))𝑘𝑗(𝐚) and the utility of the rest of the players is 𝜎𝑗(𝑘𝑗(𝐚)+1)𝑘𝑗(𝐚)+1. Thus, we have that ∑𝑖∈𝐾𝑗(𝐛)𝑢𝑖(𝑏𝑖,𝑎−𝑖)≥𝑘𝑗(𝐛)⋅𝜎𝑗(𝑘𝑗(𝐚)+1)𝑘𝑗(𝐚)+1. The claim is completed by observing that 𝜎𝑗(𝑘𝑗(𝐚)+1)𝑘𝑗(𝐚)+1≥𝜎𝑗(𝑘𝑗(𝐛))𝑘𝑗(𝐛) since the utility of a player working on project j is decreasing in the number of other players working on it and by assumption 𝑘𝑗(𝐚)+1≤𝑘𝑗(𝐛). ◻

Re-Weighting Projects to Achieve Social Optimality
We now describe a mechanism for re-weighting projects so as to achieve social optimality. As discussed in the introduction, we show that it is possible to assign new weights {𝑤′𝑗} to the projects so that when utilities are allocated according to these new weights, all Nash equilibria are socially optimal. Note that the re-weighting of projects only affects players’ utilities, not the social welfare, as the latter is still computed using the true weights {𝑤𝑗}.

The idea is to choose weights so that when players are assigned according to the social optimum, they all receive identical utilities. The following re-weighting accomplishes this: we compute a socially optimal assignment 𝐨, and define 𝑤′𝑗=𝑘𝑗(𝐨)1−𝑓𝑘𝑗(𝐨)𝑗 for 𝑘𝑗(𝐨)>0 and 𝑤′𝑗=0 otherwise.

Theorem 2.10
Using the previously defined weights, every Nash equilibrium has the same social welfare as 𝐨.

Proof
We prove a stronger statement: for every project j and every Nash equilibrium 𝐚, 𝑘𝑗(𝐚)=𝑘𝑗(𝐨). First observe that the utility of each of the players when a strategy vector 𝐚 as specified above is played is 1. Also, a player’s utility for choosing a different project is less than 1 either because the utility functions are decreasing (for projects such that 𝑤′𝑗>0) or simply because 𝑤′𝑗=0. Thus, any 𝐚 adhering to the conditions above is an equilibrium.

For similar reasons, any strategy vector in which there exists project j such that 𝑘𝑗(𝐚)>𝑘𝑗(𝐨) cannot be an equilibrium. The reason is that in this case there has to exist a project l such that 𝑘𝑙(𝐚)<𝑘𝑙(𝐨) and a player can increase his utility by switching from project j to project l. ◻

It is interesting to reflect on the qualitative interpretation of these new weights for an instance with n players and a very large set of projects of equal weight and with success probabilities 𝑞1≥𝑞2≥𝑞3≥⋯ decreasing to 0. In this case, there will be a largest 𝑗∗ for which the optimal assignment places any players on 𝑗∗, and computational experiments with several natural distributions of {𝑞𝑗} indicate that the number of players assigned to projects increases roughly monotonically toward a maximum approximately near 𝑗∗. This means that the credit assigned to projects must increase toward 𝑗∗, and then be chosen so as to discourage players from working on projects beyond 𝑗∗. Moreover, the value of 𝑗∗ grows with n, the number of players. Hence we have a situation in which the research community can be viewed, roughly, as establishing the following coarse division of its projects into three categories: “too easy” (receiving relatively little credit), “just right” (near 𝑗∗, receiving an amount of credit that encourages extensive competition on these projects), and “too hard” (beyond 𝑗∗, receiving an amount of credit designed to dissuade effort on these projects). Moreover, smaller research communities reward easier problems (since 𝑗∗ is smaller), while larger communities focus their rewards on harder problems.

Re-Weighting and Ordering Players to Achieve Social Optimality
We now discuss the companion to the previous analysis: mechanisms in which the amount of credit that a successful player receives is based on its identity. In the introduction we discussed a mechanism for re-weighting the players to achieve social optimality. Recall that this means we assign each player i a weight 𝑧𝑖, and when a set S of players succeeds at a project j, we choose player 𝑖∈𝑆 to receive the credit 𝑤𝑗 with probability 𝑧𝑖∑ℎ∈𝑆𝑧ℎ. For the case of identical players the full generality of the reweighing mechanism is not required. In fact, we can instead consider a simpler mechanism: assign an absolute order to the players, and announce the convention that credit would go to the first player in the order to succeed at a project. It is not hard to observe that in this case, the players’ simultaneous choices would simulate the greedy algorithm to achieve social optimality: the first player in the announced order would choose a project without regard to the choices of other players; the second player would choose as though the first player would win any direct competition, but without regard to the choices of any other players; and so forth. This proves the following theorem:

Theorem 2.11
For any strict order on the players, 𝜋, such that player i that succeeds the project receives credit only in the case that all players prior to it in the order failed the project (e.g., 𝑢𝑖(𝐚)=𝑤𝑎𝑖⋅𝑓𝜋(𝑖)−1𝑎𝑖(1−𝑓𝑎𝑖)), all Nash equilibria of the resulting game are socially optimal.

We focus on the more general player re-weighing mechanism, in this paper, as for players with heterogeneous abilities, it is no longer the case that we can make an optimal allocation a Nash equilibrium simply by applying a strict ordering on the players. In the Appendix we show that it is also possible to re-weight the players in order to make any Nash equilibrium an optimal allocation. This is done by approximately simulating a strict order on the players using sharply decreasing weights. We include this proof in the appendix both for sake of completeness and since we find it useful for the understanding of the respective (more challenging) proof for players with heterogeneous abilities which applies similar techniques. Formally, in the Appendix we show that:

Theorem 2.12
With 𝜀>0 sufficiently small and the re-weighting of players defined by 𝑧𝑖=𝜀𝑖, all Nash equilibria of the resulting game are socially optimal.

Players of Heterogeneous Abilities
We now consider the case in which players have different levels of ability. Recall from the introduction that in this model, each player i has a parameter 𝑝𝑖≤1, and her probability of success at project j is 𝑝𝑖𝑞𝑗. As before, player i receives credit for her selected project 𝑎𝑖 if she succeeds at it and is chosen, uniformly at random, from among all players who succeed at it. Player i’s utility is the expected amount of credit she receives in this process.

Recall that 𝐾𝑗(𝐚) is the set of players working on project j in strategy vector 𝐚; we write 𝑠𝑗(𝐾𝑗(𝐚))=𝑤𝑗(1−∏𝑖∈𝐾𝑗(𝐚)(1−𝑝𝑖𝑞𝑗)) for the contribution of project j to the social welfare, so that the overall social welfare of 𝐚 is 𝑢(𝐚)=∑𝑗∈𝑀𝑠𝑗(𝐾𝑗(𝐚)). We denote the marginal utility of adding player i to project j by 𝑠𝑗(𝑖|𝐾𝑗(𝐚))=𝑠𝑗(𝐾𝑗(𝐚)∪{𝑖})−𝑠𝑗(𝐾𝑗(𝐚))=𝑤𝑗𝑝𝑖𝑞𝑗∏𝑙∈𝐾𝑗(𝐚)(1−𝑝𝑙𝑞𝑗) and we use 𝑢(𝑗|𝑎−𝑖)=𝑠𝑗(𝑖|𝐾𝑗(𝑎−𝑖)) to denote the marginal utility of player i choosing project j when the rest of the players choose 𝑎−𝑖.

There is a useful closed-form way to write i’s utility, as follows. First, suppose that in strategy vector 𝐚, player i selects project j, and let S denote the other players who select j. Then in order for i to receive the credit of 𝑤𝑗 for the project, she has to succeed (with probability 𝑝𝑖𝑞𝑗); moreover, some subset 𝑆′ of the other players on j will succeed (with probability ∏ℎ∈𝑆′𝑝ℎ𝑞𝑗) while the rest will fail (with probability ∏ℎ∈{𝑆−𝑆′}(1−𝑝ℎ𝑞𝑗)), and i must be selected from among the successful players (with probability 1|𝑆′|+1). Thus we have


𝑢𝑖(𝐚)=𝑤𝑗𝑝𝑖𝑞𝑗∑𝑆′⊆𝑆⎛⎝⎜⎜1|𝑆′|+1∏ℎ∈𝑆′𝑝ℎ𝑞𝑗∏ℎ∈{𝑆−𝑆′}(1−𝑝ℎ𝑞𝑗)⎞⎠⎟⎟.

This summation over all sets 𝑆′ is a natural quantity that is useful to define separately for future use; we denote it by 𝑐𝑗(𝑆) and refer to it as the competition function for project j. The competition function represents the expected reduction in credit to a player working on project j due to the competition from players in the set S; instead of the expected credit of 𝑤𝑗𝑝𝑖𝑞𝑗 that i would receive if she worked on j in isolation, she gets 𝑤𝑗𝑝𝑖𝑞𝑗𝑐𝑗(𝑆) when the players in S are also working on j. Thus, with 𝑎𝑖 denoting the project chosen by i, and 𝐾𝑎𝑖(𝐚) denoting the set of all players choosing project 𝑎𝑖, we have 𝑢𝑖(𝐚)=𝑤𝑎𝑖𝑝𝑖𝑞𝑎𝑖𝑐𝑎𝑖(𝐾𝑎𝑖(𝐚)−𝑖). We now state and prove a technical lemma giving an inductive form for the competition function that will be useful later on. For the sake of brevity we define:

Definition 3.1
For 𝑆′⊆𝑆 and project j, let 𝐼𝑗(𝑆′,𝑆)=∏ℎ∈𝑆′𝑝ℎ𝑞𝑗∏ℎ∈{𝑆−𝑆′}(1−𝑝ℎ𝑞𝑗).

Using the previous definition we have that: 𝑐𝑗(𝑆)=∑𝑆′⊆𝑆(1|𝑆′|+1𝐼𝑗(𝑆′,𝑆)).

Lemma 3.2
For any project j, set of players S, and player 𝑖∉𝑆, we have


𝑐𝑗(𝑆+𝑖)=𝑐𝑗(𝑆)−𝑝𝑖𝑞𝑗∑𝑆′⊆𝑆(1(|𝑆′|+1)(|𝑆′|+2)𝐼𝑗(𝑆′,𝑆)).

Proof
By distinguishing between the case in which the new player i succeeds and the case she fails we have that:


𝑐𝑗(𝑆+𝑖)==𝑝𝑖𝑞𝑗∑𝑆′⊆𝑆(1(|𝑆′|+2)𝐼𝑗(𝑆′,𝑆))+(1−𝑝𝑖𝑞𝑗)∑𝑆′⊆𝑆(1(|𝑆′|+1)𝐼𝑗(𝑆′,𝑆))𝑐𝑗(𝑆)−𝑝𝑖𝑞𝑗∑𝑆′⊆𝑆(1(|𝑆′|+1)(|𝑆′|+2)𝐼𝑗(𝑆′,𝑆)).

◻

Corollary 3.3
Consider a set of players S, two players 𝑖,𝑙∈𝑆 such that 𝑝𝑖≥𝑝𝑙 and a project j, then 𝑐𝑗(𝑆−𝑖)≥𝑐𝑗(𝑆−𝑙) since 𝑐𝑗((𝑆−𝑖−𝑙)+𝑙)≥𝑐𝑗((𝑆−𝑖−𝑙)+𝑖). Thus, when considering all players working on the same project the player facing the fiercest competition is the one with the minimal ability.

We can show the following basic facts about this general version of the game. We first show that the more general version of the game is still a monotone valid-utility game. The proof is very similar to the proof of Claim 2.1; the only part that changes in a non-trivial way is the proof that the utility (social welfare) function is submodular which we provide next:

Claim 3.4
The social welfare function of the project game with different abilities is submodular.

Proof
We show that 𝑢(𝐚) has decreasing marginal utility. Recall that 𝑢(𝐚) is the summation of the projects’ separate utilities. Hence it is enough to prove that the utility of every project is submodular. More formally, We need to show that for every two sets of players 𝑆′⊆𝑆 and for every project j and player i, we have 𝑠𝑗(𝑖|𝑆′)≥𝑠𝑗(𝑖|𝑆). To prove this, we observe that 𝑤𝑗𝑝𝑖𝑞𝑗∏𝑙∈𝑆′(1−𝑝𝑙𝑞𝑗)≥𝑤𝑗𝑝𝑖𝑞𝑗∏𝑙∈𝑆(1−𝑝𝑙𝑞𝑗) simply becasue 1≥∏𝑙∈{𝑆−𝑆∩𝑆′}(1−𝑝𝑙𝑞𝑗). ◻

Next, we show that the more general version of the game is a congestion game. This is less clear-cut than in the case of identical players, since now the payoffs depend not just on the number of players sharing a project but on their identities as well. To bypass this we prove that the utility functions for the project game with different abilities obey a certain structural property that, by results of Monderer and Shapley [26], implies that the game is a congestion game.

Claim 3.5
The project game with different abilities is a congestion game.

Proof
We will use a characterization of congestion games given by Monderer and Shapley in Corollary 2.9 of their paper [26]. Using the notation and terminology we have defined for the project game, the corollary can be written as follows.

Theorem 3.6
(Adapted from Monderer–Shapley) The project game is an (exact) potential game if for every two players i and l, projects 𝑥𝑖≠𝑦𝑖 and 𝑥𝑙≠𝑦𝑙 and strategy vector 𝑎−𝑖,𝑙:


𝑢𝑖(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)−𝑢𝑖(𝑥𝑖,𝑥𝑙,𝑎−𝑖,𝑙)+𝑢𝑙(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙)−𝑢𝑙(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)+𝑢𝑖(𝑥𝑖,𝑦𝑙,𝑎−𝑖,𝑙)−𝑢𝑖(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙)+𝑢𝑙(𝑥𝑖,𝑥𝑙,𝑎−𝑖,𝑙)−𝑢𝑙(𝑥𝑖,𝑦𝑙,𝑎−𝑖,𝑙)=0

We now use this to prove that the project game with different abilities is an exact potential game, from which the claim follows, since by another result of Monderer and Shapley, every finite exact potential game is isomorphic to a congestion game.

Recall that the utility of a player i is affected only by the players who are working on the same project as her. Hence, we should differentiate in the condition given in Theorem 3.6 between the cases in which players i and l are working on the same project and those in which they are not. Before proceeding with the case analysis, we present the following lemma that will turn out useful for handling some of the cases. The proof is provided below.

Lemma 3.7
For any three projects x, y, z such that 𝑥≠𝑦 and 𝑥≠𝑧:


𝑢𝑖(𝑥,𝑥,𝑎−𝑖,𝑙)−𝑢𝑖(𝑥,𝑦,𝑎−𝑖,𝑙)=𝑢𝑙(𝑥,𝑥,𝑎−𝑖,𝑙)−𝑢𝑙(𝑧,𝑥,𝑎−𝑖,𝑙).

By symmetry we can assume without loss of generality that 𝑥𝑖≠𝑦𝑙 and that 𝑦𝑖≠𝑥𝑙. This leaves us with the following four cases:

1.
𝑥𝑖≠𝑥𝑙 and 𝑦𝑖≠𝑦𝑙. By rearranging the terms we get:


𝑢𝑖(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)−𝑢𝑖(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙)=0+𝑢𝑖(𝑥𝑖,𝑦𝑙,𝑎−𝑖,𝑙)−𝑢𝑖(𝑥𝑖,𝑥𝑙,𝑎−𝑖,𝑙)=0+𝑢𝑙(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙)−𝑢𝑙(𝑥𝑖,𝑦𝑙,𝑎−𝑖,𝑙)=0+𝑢𝑙(𝑥𝑖,𝑥𝑙,𝑎−𝑖,𝑙)−𝑢𝑙(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)=0=0.

For example, 𝑢𝑖(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)−𝑢𝑖(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙)=0 since 𝐾𝑦𝑖(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)=𝐾𝑦𝑖(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙).

2.
𝑥𝑖=𝑥𝑙 and 𝑦𝑖≠𝑦𝑙. By using Lemma 3.7 we have that:


𝑢𝑖(𝑥𝑖,𝑦𝑙,𝑎−𝑖,𝑙)−𝑢𝑖(𝑥𝑖,𝑥𝑙,𝑎−𝑖,𝑙)+𝑢𝑙(𝑥𝑖,𝑥𝑙,𝑎−𝑖,𝑙)−𝑢𝑙(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)=0+𝑢𝑖(𝑦𝑖,𝑥𝑙,𝑎−𝑖,𝑙)−𝑢𝑖(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙)=0+𝑢𝑙(𝑦𝑖,𝑦𝑙,𝑎−𝑖,𝑙)−𝑢𝑙(𝑥𝑖,𝑦𝑙,𝑎−𝑖,𝑙)=0=0.

3.
𝑥𝑖≠𝑥𝑙 and 𝑦𝑖=𝑦𝑙. This case is symmetric to case 2.

4.
𝑥𝑖=𝑥𝑙 and 𝑦𝑖=𝑦𝑙. This case can be proved by using Lemma 3.7 twice, similar to case 2.

◻

Proof of Lemma 3.7
By using Lemma 3.2 we have that:


𝑢𝑖(𝑥,𝑥,𝑎−𝑖,𝑙)=𝑤𝑥𝑝𝑖𝑞𝑥⋅𝑐𝑥(𝐾𝑥(𝑎−𝑖,𝑙)+𝑙)=𝑤𝑥𝑝𝑖𝑞𝑥⋅(𝑐𝑥(𝐾𝑥(𝑎−𝑖,𝑙))−𝑝𝑙𝑞𝑥∑𝑆⊆𝐾𝑥(𝑎−𝑖,𝑙)(1(|𝑆|+1)(|𝑆|+2)𝐼𝑥(𝑆,𝐾𝑥(𝑎−𝑖,𝑙))))=𝑢𝑖(𝑥,𝑦,𝑎−𝑖,𝑙)−𝑤𝑥𝑝𝑖𝑞𝑥⋅𝑝𝑙𝑞𝑥∑𝑆⊆𝐾𝑥(𝑎−𝑖,𝑙)(1(|𝑆|+1)(|𝑆|+2)𝐼𝑥(𝑆,𝐾𝑥(𝑎−𝑖,𝑙)))

Similarly we have:


𝑢𝑙(𝑥,𝑥,𝑎−𝑖,𝑙)=𝑢𝑙(𝑧,𝑥,𝑎−𝑖,𝑙)−𝑤𝑥𝑝𝑙𝑞𝑥⋅𝑝𝑖𝑞𝑥∑𝑆⊆𝐾𝑥(𝑎−𝑖,𝑙)(1(|𝑆|+1)(|𝑆|+2)𝐼𝑥(𝑆,𝐾𝑥(𝑎−𝑖,𝑙)))

Hence, 𝑢𝑖(𝑥,𝑥,𝑎−𝑖,𝑙)−𝑢𝑖(𝑥,𝑦,𝑎−𝑖,𝑙)=𝑢𝑙(𝑥,𝑥,𝑎−𝑖,𝑙)−𝑢𝑙(𝑧,𝑥,𝑎−𝑖,𝑙). ◻

Next, we show how one can compute a Nash equilibrium in the project game with different abilities. We will later see that the optimal solution for this more general version of the game can no longer be computed in polynomial time.

Claim 3.8
A Nash equilibrium for the project game with different abilities can be computed in polynomial time.

Proof
We begin by presenting a greedy algorithm for computing a Nash equilibrium. We then prove that the algorithm indeed computes a Nash equilibrium and that it runs in polynomial time. The algorithm is defined as follows:

1.
Sort the players by their abilities.

2.
Go over the players in descending order of ability and allocate each player to the project maximizing her utility with respect to the players previously allocated.

Denote the resulting allocation by 𝐚. Assume towards a contradiction that 𝐚 is not a Nash equilibrium. Let player i be the first player in the order for which there exists some project j such that 𝑢𝑖(𝑗,𝑎−𝑖)>𝑢𝑖(𝐚). Let player l be the last player that joined project 𝑎𝑖. Note that for player l it has to be the case that 𝑢𝑙(𝐚)≥𝑢𝑙(𝑗,𝑎−𝑙), since its expected utility is exactly the same as it was in the time she made her choice and the expected utility from project j could have only decreased (this also implies that 𝑙≠𝑖). Recall that:


𝑤𝑎𝑖𝑝𝑙𝑞𝑎𝑖𝑐𝑎𝑖(𝐾𝑎𝑖(𝐚)−𝑙)=𝑢𝑙(𝐚)≥𝑢𝑙(𝑗,𝑎−𝑙)=𝑤𝑗𝑝𝑙𝑞𝑗𝑐𝑗(𝐾𝑗(𝐚)).

This implies that 𝑤𝑎𝑖𝑞𝑎𝑖𝑐𝑎𝑖(𝐾𝑎𝑖(𝐚)−𝑙)≥𝑤𝑗𝑞𝑗𝑐𝑗(𝐾𝑗(𝐚)). We now observe that by Corollary 3.3 since 𝑝𝑖>𝑝𝑙 we have that 𝑐𝑎𝑖(𝐾𝑎𝑖(𝐚)−𝑖)≥𝑐𝑎𝑖(𝐾𝑎𝑖(𝐚)−𝑙) and thus 𝑢𝑖(𝑗,𝑎−𝑖)≤𝑢𝑖(𝐚) in contradiction to the assumption that 𝐚 is not a Nash equilibrium.

We now show that the algorithm runs in polynomial time. To this end we show that the players’ utilities can be computed in polynomial time, this amounts to computing the competition functions:

Claim 3.9
The competition function can be computed in poly time.

Proof
We provide an alternative inductive formula for the competition function that can be evaluated in polynomial time. We define the probability that the set of successful players is of size k by l(S, k). Formally,


𝑙(𝑆,𝑘)=∑𝑆′⊆𝑆| |𝑆′|=𝑘⎛⎝⎜⎜∏ℎ∈𝑆′𝑝ℎ𝑞𝑗∏ℎ∈{𝑆−𝑆′}(1−𝑝ℎ𝑞𝑗)⎞⎠⎟⎟

With this notation in mind we have that:


𝑐𝑗(𝑆)=∑𝑆′⊆𝑆⎛⎝⎜⎜1|𝑆′|+1∏ℎ∈𝑆′𝑝ℎ𝑞𝑗∏ℎ∈{𝑆−𝑆′}(1−𝑝ℎ𝑞𝑗)⎞⎠⎟⎟=∑𝑘=0|𝑆|1𝑘+1𝑙(𝑆,𝑘)

We now consider the effect that adding an additional player ℎ∉𝑆 to the set of players working on a project has on the value of 𝑙(𝑆+ℎ,𝑘). It is not hard to see that 𝑙(𝑆+ℎ,𝑘)=(1−𝑝ℎ𝑞𝑗)⋅𝑙(𝑆,𝑘)+𝑝ℎ𝑞𝑗⋅𝑙(𝑆,𝑘−1), where 𝑙(𝑆,−1)=0.

This formula readily admits a simple algorithm for computing 𝑐𝑗(𝑆). We first fix some order on the players in S, for simplicity we rename the players according to this order. The algorithm performs |S| steps, where in step i it computes 𝑙({1,…,𝑖},𝑘) for every 𝑘∈{1,…,𝑖}. Observe that for each k computing 𝑙({1,…,𝑖},𝑘) can be done in constant time by using the values of 𝑙({1,…,𝑖−1},𝑘) and 𝑙({1,…,𝑖−1},𝑘−1) that where computed in the previous step. Therefore, we have that step i takes O(i) time implying that the whole computation of 𝑐𝑗(𝑆) takes 𝑂(𝑛2). ◻

Claim 3.10
Computing the social optimum for the project game with different abilities is NP-hard.

Proof
We use a reduction from the Subset Product problem, whose NP-completeness is established in Garey and Johnson [16]. The Subset Product problem is defined as follows: given a set of n natural numbers 𝑋={𝑥1,...,𝑥𝑛} and a target number 𝑞∗, does there exist a set 𝑆⊆𝑋 such that ∏𝑥𝑖∈𝑆𝑥𝑖=𝑞∗?

As a first step, we show that the closely related Multiplicative Number Partition problem (MNP) is NP-complete. In MNP, we are again given a set of n natural numbers 𝑋={𝑥1,...,𝑥𝑛}, but now we are asked whether there is a partition (S, T) of X such that ∏𝑥𝑖∈𝑆𝑥𝑖=∏𝑥𝑗∈𝑇𝑥𝑗. We can show that MNP is NP-complete by a reduction from Subset Product. This is similar to the reduction from Subset Sum to (Additive) Number Partition. That is, given an instance of Subset Product with a set X and a target 𝑞∗, we define 𝑝=∏𝑥𝑖∈𝑋𝑥𝑖. Notice that if p is not divided by 𝑞∗ without a remainder then there is no subset as needed. Hence, we can assume without loss of generality that 𝑞∗ divides p. We then show that we can solve MNP for 𝑋′=𝑋∪{𝑥𝑛+1=𝑝2/𝑞∗,𝑥𝑛+2=𝑝⋅𝑞∗} if and only if we can solve Subset Product.

Denote the two sets in the MNP problem by 𝑆′ and 𝑇′. Notice that 𝑥𝑛+1 and 𝑥𝑛+2 should be in different sets because 𝑥𝑛+1⋅𝑥𝑛+2>𝑝. Assume without loss of generality that 𝑥𝑛+1∈𝑆′. Define 𝑦=∏𝑥𝑖∈{𝑆′−𝑥𝑛+1}𝑥𝑖. By the definition of y we have that ∏𝑥𝑗∈{𝑇′−𝑥𝑛+2}𝑥𝑗=𝑝𝑦. By substituting in the equality ∏𝑥𝑖∈𝑆′𝑥𝑖=∏𝑥𝑗∈𝑇′𝑥𝑗 we get that:


𝑝2𝑞∗⋅𝑦=𝑝⋅𝑞∗⋅𝑝𝑦⟺𝑦𝑞∗=𝑞∗𝑦

Since both y and 𝑞∗ are positive we get that 𝑦=𝑞∗. Thus, we have proven the following lemma:

Lemma 3.11
For a partition (𝑆′,𝑇′) of 𝑋′ : ∏𝑥𝑖∈𝑆′𝑥𝑖=∏𝑥𝑗∈𝑇′𝑥𝑗 ⟺ ∏𝑥𝑖∈{𝑆′−𝑥𝑛+1}𝑥𝑖=𝑞∗

We can now conclude that for 𝑆={𝑆′−{𝑥𝑛+1}}, which by the construction is a subset of X, we have that ∏𝑥𝑖∈𝑆=𝑞∗. It follows that MNP is NP-complete.

Finally, we prove that the socially optimal assignment in the project game with different abilities is NP-hard. We do this by a reduction from MNP to the special case of the optimal assignment in which we have n players and 2 identical projects. In this special case we assume both projects have a weight of 1 and success probability 1, and player i has a failure probability 𝑓𝑖.

Given an instance of MNP, we create an instance of the optimal assignment problem by defining for every number 𝑥𝑖 a player i with failure probability 𝑓𝑖=1𝑥𝑖. The optimal solution to the assignment of players to projects is a partition (S, T) that maximizes the social welfare: (1−∏𝑖∈𝑆𝑓𝑖)+(1−∏𝑗∈𝑇𝑓𝑗). This implies that the optimal partition actually minimizes ∏𝑖∈𝑆𝑓𝑖+∏𝑗∈𝑇𝑓𝑗. By plugging in the values of 𝑓𝑖 and 𝑓𝑗. We have that the optimal solution minimizes:


∏𝑖∈𝑆1𝑥𝑖+∏𝑗∈𝑇1𝑥𝑗=∏𝑖∈𝑆𝑥𝑖+∏𝑗∈𝑇𝑥𝑗𝑝.

The following lemma completes the proof by establishing the connection between social welfare maximization and MNP.

Lemma 3.12
A partition (S, T) minimizes ∏𝑖∈𝑆𝑥𝑖+∏𝑗∈𝑇𝑥𝑗 if and only if it minimizes |∏𝑖∈𝑆𝑥𝑖−∏𝑗∈𝑇𝑥𝑗|.

Proof
In this proof, we use Π𝑆 as a shorthand for ∏𝑖∈𝑆𝑥𝑖. Let (S, T) and (𝑆′,𝑇′) be two partitions of X. We show that if Π𝑆+Π𝑇<Π𝑆′+Π𝑇′ then |Π𝑆−Π𝑇|<|Π𝑆′−Π𝑇′|. We begin by observing that the following three inequalities are equivalent, since all terms are products of natural (and hence non-negative) numbers:


Π𝑆+Π𝑇(Π𝑆+Π𝑇)2(Π𝑆)2+2Π𝑆⋅Π𝑇+(Π𝑇)2<Π𝑆′+Π𝑇′<(Π𝑆′+Π𝑇′)2<(Π𝑆′)2+2Π𝑆′⋅Π𝑇′+(Π𝑇′)2.

Since both (S, T) and (𝑆′,𝑇′) are partitions of X, we have that: Π𝑆⋅Π𝑇=Π𝑆′⋅Π𝑇′, and hence we can subtract four times this common product from both sides of the previous inequality to get three more equivalent inequalities:


(Π𝑆)2−2Π𝑆⋅Π𝑇+(Π𝑇)2(Π𝑆−Π𝑇)2|Π𝑆−Π𝑇|<(Π𝑆′)2−2Π𝑆′⋅Π𝑇′+(Π𝑇′)2<(Π𝑆′−Π𝑇′)2<|Π𝑆′−Π𝑇′|.

◻

This completes the proof since given a partition (S, T) that is an optimal solution to the project game with different abilities, we can determine the answer to MNP by checking whether ∏𝑖∈𝑆𝑥𝑖=∏𝑗∈𝑇𝑥𝑗. ◻

Re-Weighting Projects to Achieve Social Optimality
We now describe how to re-weight projects, creating new weights {𝑤′𝑗}, so as to make a given social optimum 𝐨 a Nash equilibrium. First, since the relative values of the project weights are all that matters, we can choose any project x arbitrarily and set its new weight 𝑤′𝑥 equal to 1. We will set the weights 𝑤′𝑗 of the other projects so that every player’s favorite alternate project (and hence the target of any potential deviation) is x.

Now, among all the players working on project 𝑗≠𝑥, which one has the greatest incentive to move to x? It is the player 𝑖∈𝐾𝑗(𝐨) with the lowest ability 𝑝𝑖, since all players 𝑖′∈𝐾𝑗(𝐨) experience the same competition function 𝑐𝑥(𝐾𝑥(𝐨)), but by Corollary 3.3 player i experiences the strongest competition from the other players in 𝐾𝑗(𝐨). This is because they all have ability at least as great as i, so i has the most to gain by moving off j.

Motivated by this, for a strategy vector 𝐚 and a project j, we define 𝛿𝑗(𝐚) to be the player 𝑖∈𝐾𝑗(𝐚) of minimum ability 𝑝𝑖. We define 𝑤′𝑥=1 and for every other project 𝑗≠𝑥, we define


𝑤′𝑗=𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨)−𝛿𝑗(𝐨)).

(2)

Theorem 3.13
The optimal assignment 𝐨 is a Nash equilibrium in the game with the given weights {𝑤′𝑗}.

Proof
To prove this, we will show that if a player did want to move to another project, she would choose to move to project x. After establishing this, it is enough to show that all the players working on project x in the optimal assignment do not want to move to another project, and that the rest of the players do not want to move to project x.

We now show that a player i working on a project other than x views x as her best alternate project.

Lemma 3.14
For any player i such that 𝑜𝑖≠𝑥, and for every project 𝑗≠𝑜𝑖, we have that 𝑢𝑖(𝑥,𝑜−𝑖)≥𝑢𝑖(𝑗,𝑜−𝑖)

Proof
We need to show that 𝑤′𝑥𝑝𝑖𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))≥𝑤′𝑗𝑝𝑖𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨)). By setting the weights to their values according to Formula (2), we get that:


𝑝𝑖𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))≥𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨)−𝛿𝑗(𝐨))𝑝𝑖𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨))

By rearranging the terms we have that: 𝑐𝑗(𝐾𝑗(𝐨)−𝛿𝑗(𝐨))≥𝑐𝑗(𝐾𝑗(𝐨)). Intuitively, this inequality follows from the fact that as more players work on a project, it is less likely that a specific player will be the one to succeed at it. Formally, it follows from Lemma 3.2 above. ◻

Finally, we show that players working on project x do not want to leave project x, and players not working on x do not want to move to x (and hence, by Lemma 3.14, do not want to move anywhere else either).

Lemma 3.15
1.
All players who are working in the optimal assignment on project x do not want to move to a different project.

2.
All players who are working in the optimal assignment on project different than x do not want to move to project x.

Proof
Assume towards a contradiction that there exists a player i who prefers to work on project 𝑗≠𝑜𝑖. This means that


𝑤′𝑜𝑖𝑝𝑖𝑞𝑜𝑖𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝑖)<𝑤′𝑗𝑝𝑖𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨))

For each of the two statements we set 𝑤′𝑜𝑖 and 𝑤′𝑗 to their values according to Formula (2) and get to a contradiction by rearranging the terms.

1.
We set 𝑤′𝑜𝑖=1 and 𝑤′𝑗=𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨)−𝛿𝑗(𝐨)) and get the following inequality:


𝑝𝑖𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨)−𝑖)<𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨)−𝛿𝑗(𝐨))𝑝𝑖𝑞𝑗𝑐𝑗(𝐾𝑗(𝐨))

After rearranging the inequality we get that:


𝑐𝑥(𝐾𝑥(𝐨)−𝑖)𝑐𝑥(𝐾𝑥(𝐨))<𝑐𝑗(𝐾𝑗(𝐨))𝑐𝑗(𝐾𝑗(𝐨)−𝛿𝑗(𝐨))

The contradiction follows by noticing that 𝑐𝑥(𝐾𝑥(𝐨)−𝑖)>𝑐𝑥(𝐾𝑥(𝐨)) by Lemma 3.2; however, by the same lemma we also have that 𝑐𝑗(𝐾𝑗(𝐨))<𝑐𝑗(𝐾𝑗(𝐨)−𝛿𝑗(𝐨)).

2.
We set 𝑤′𝑜𝑖=𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))𝑞𝑜𝑖𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝛿𝑜𝑖(𝐨)) and 𝑤′𝑗=1 and get the following inequality:


𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))𝑞𝑜𝑖𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝛿𝑜𝑖(𝐨))𝑝𝑖𝑞𝑜𝑖𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝑖)<𝑝𝑖𝑞𝑥𝑐𝑥(𝐾𝑥(𝐨))

After rearranging the inequality we get that:


𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝑖)𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝛿𝑜𝑖(𝐨))<1

This is in contradiction with Corollary 3.3 according to which if 𝑝𝑖≥𝑝𝛿𝑜𝑖(𝐨) then 𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝑖)≥𝑐𝑜𝑖(𝐾𝑜𝑖(𝐨)−𝛿𝑜𝑖(𝐨)).

◻

Since this establishes that all players want to stay with their current projects, it follows that 𝐨 is a Nash equilibrium under the modified weights, and hence the proof of Theorem 3.13 is complete.

Re-Weighting Players to Achieve Social Optimality
It is also possible to re-weight the players so as to make the social optimum a Nash equilibrium. Because the greedy algorithm no longer computes the social optimum, it is no longer sufficient to use a strict ordering on the players (or weights that approximately simulate such an ordering). However, we can use an extension of this plan that incorporates two additional ingredients: first, we base the greedy ordering on the socially optimal assignment, and second, we do not use a strict ordering but rather one that groups the players into stages of equal weight.

The algorithm for assigning weights is as follows. In the beginning, we fix an optimal assignment 𝐨 and a sufficiently small value of 𝜀>0 (to be determined below), and we declare all players to be unassigned. The algorithm then operates in a sequence of stages 𝑐=1,2,…. At the start of stage c, some players have been given weights and been assigned to projects, resulting in a partial strategy vector 𝐚𝐜 consisting only of players assigned before stage c. We show that at the start of stage c, each unassigned player would maximize her payoff by choosing a project from the set


𝑋𝑐=argmax𝑗 𝑤𝑗∏𝑙∈𝐾𝑗(𝐚𝐜)(1−𝑝𝑙𝑞𝑗)𝑞𝑗.

Thus in stage c, the algorithm does the following. It first computes this set of projects 𝑋𝑐. Then, for each project 𝑗∈𝑋𝑐 for which there exists a player i such that 𝑜𝑖=𝑗 and i is unassigned, it assigns i to project j, and sets 𝑧𝑖=𝜀𝑐.

We show that when the players have weights 𝐳 there exists an optimal assignment 𝐨′ which is a Nash equilibrium. Note that it is not necessarily the case that 𝐨′=𝐨. The reason for this is that in the final stage 𝑐∗ of the algorithm, it may be that the number of unassigned players is less than |𝑋𝑐∗|, and in this case some of the unassigned players might go to projects other than the ones corresponding to 𝐨.

Definition 3.16
Assignment 𝐨′ is constructed as follows:

1.
For every player i that was not assigned in the last stage of the algorithm, let 𝑜′𝑖=𝑜𝑖.

2.
For every project 𝑗∈𝑋𝑐∗ compute the value of the competition function before assigning the players from the last stage:


𝑐𝑗(𝐨′)=∑𝑆⊆𝐾𝑗(𝐨′)𝑧∗(∑𝑙∈𝑆𝑧𝑙)+𝑧∗𝐼𝑗(𝑆,𝐾𝑗(𝐨′))

where 𝑧∗=𝜀𝑐∗ is the weight defined for players that were assigned last and 𝐼𝑗(𝑆,𝐾𝑗(𝐨′) is the same as defined in Definition 3.1: 𝐼𝑗(𝑆,𝐾𝑗(𝐨′))=∏𝑙∈𝑆𝑝𝑙𝑞𝑗∏𝑙∈𝐾𝑗(𝐨′)−𝑆(1−𝑝𝑙𝑞𝑗).

3.
Sort all the projects in 𝑋𝑐∗ by their value for 𝑤𝑗𝑐𝑗(𝐨′).

4.
Assign each unassigned player to one of the top projects in 𝑋𝑐∗ according to the sorting.

Theorem 3.17
The previously defined assignment 𝐨′ is an optimal assignment and a Nash equilibrium in the game with weights 𝐳.

We begin by showing that 𝐨′ is indeed an optimal assignment:

Claim 3.18
𝐨′ is an optimal assignment (i.e., 𝑢(𝐨′)=𝑢(𝐨)).

Proof
By the construction of 𝐨′ the only players that might not work on the same project as in 𝐨 are those that were assigned last. All these players are assigned to projects in 𝑋𝑐∗. Notice that all projects in 𝑋𝑐∗ maximize 𝑤𝑗∏{𝑙∈𝐾𝑗(𝐚𝑐∗−1)}(1−𝑝𝑙𝑞𝑗)𝑞𝑗. Hence, the contribution of the players assigned last is the same regardless of which specific project in 𝑋𝑐∗ they are working on. Therefore 𝐨′ is an optimal assignment. ◻

Next, we show that 𝐨′ is a Nash equilibrium in the game with weights 𝐳. The proof resembles the proof of Theorem 2.12. As in Theorem 2.12, the actual utilities of the re-weighted players for a given strategy vector 𝐚 are denoted by 𝑢𝑖(𝐚;𝐳), and their “ideal” utilities under the partial order we are trying to simulate are denoted 𝑢𝑖ˆ(𝐚;𝐳):


𝑢𝑖ˆ(𝐚;𝐳)=𝑤𝑎𝑖𝑝𝑖𝑞𝑎𝑖∏𝑙∈𝜋<𝑖(𝐾𝑎𝑖(𝐚))(1−𝑝𝑙𝑞𝑎𝑖)

where 𝜋<𝑖(𝐾𝑎𝑖(𝐚)), as before, is the set of players working on project 𝑎𝑖 which are strictly before player i in the order.

Recalling that the projects’ weights and success probabilities are rational, let d be the common denominator of all the terms in the sets {𝑤𝑗:𝑗∈𝑀} and {𝑝𝑖𝑞𝑗:𝑖∈𝑁,𝑗∈𝑀}.

Claim 3.19
If for every player i and project j such that the weight of player i is unique among players working on project j:


𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳)−14𝑑𝑛+1≤𝑢𝑖(𝑗,𝑜′−𝑖;𝐳)≤𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳)+14𝑑𝑛+1,

then 𝐨′ is a Nash equilibrium.

Proof
Assume towards a contradiction that 𝐨′ is not a Nash equilibrium. Thus, there exists a player i and a project 𝑗≠𝑜′𝑖 such that 𝑢𝑖(𝑗,𝑜′−𝑖;𝐳)>𝑢𝑖(𝐨′;𝐳). Let c be the stage in which player i was assigned. By the weighting algorithm we have that 𝑢𝑖ˆ(𝐨′;𝐳)≥𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳). At this stage project 𝑜′𝑖 was one of the projects maximizing the marginal contribution to social welfare, thus


𝑤𝑜′𝑖∏𝑙∈𝐾𝑜′𝑖(𝐚𝐜)(1−𝑝𝑙𝑞𝑜′𝑖)𝑞𝑜′𝑖≥𝑤𝑗∏𝑙∈𝐾𝑗(𝐚𝐜)(1−𝑝𝑙𝑞𝑗)𝑞𝑗.

By multiplying both sides with 𝑝𝑖 we have that 𝑢𝑖ˆ(𝐨′;𝐳)≥𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳). We now distinguish between two cases:

1.
𝑢𝑖ˆ(𝐨′;𝐳)>𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳) – this implies that 𝑗∉𝑋𝑐 and therefore player i has a unique weight on project j and we can use the assumption of the claim to get that:


𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳)+14𝑑𝑛+1≥𝑢𝑖(𝑗,𝑜′−𝑖;𝐳)>𝑢𝑖(𝐨′;𝐳)≥𝑢𝑖ˆ(𝐨′;𝐳)−14𝑑𝑛+1

This implies that 𝑢𝑖ˆ(𝐨′;𝐳)−𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳)<12𝑑𝑛+1. But by the definition of d, since 𝑢𝑖ˆ(𝐨′;𝐳) and 𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳) are not equal, they must differ by at least 1𝑑𝑛+1, a contradiction.

2.
𝑢𝑖ˆ(𝐨′;𝐳)=𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳) – this implies that 𝑗∈𝑋𝑐. In this case there is another player l with the same weight as player i working on project j in 𝐨′. This is due to Lemma 3.20 below for 𝑐<𝑐∗ and by the construction of 𝐨′ for 𝑐<𝑐∗. In Lemma 3.21 below we show that for two players i and l of the same weight 𝑢𝑖(𝑗,𝑜′−𝑖;𝐳)≤𝑢𝑖ˆ(𝑗,𝑜′−𝑖,𝑙;𝐳)−12𝑑𝑛+1. By the definition of the marginal utility we have that \widehat{u_i}(\mathbf {o'}; \mathbf {z}) =\widehat{u_i}(j,o'_{-i}; \mathbf {z}) =\widehat{u_i}(j,o'_{-i,l}; \mathbf {z})𝑢𝑖ˆ(𝐨′;𝐳)=𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳)=𝑢𝑖ˆ(𝑗,𝑜′−𝑖,𝑙;𝐳). Thus, we have that {u_i} (o'; \mathbf {z}) < {u_i} (j,o'_{-i}; \mathbf {z}) \le \widehat{u_i} (\mathbf {o'}; \mathbf {z}) - \dfrac{1}{2d^{n+1}}𝑢𝑖(𝑜′;𝐳)<𝑢𝑖(𝑗,𝑜′−𝑖;𝐳)≤𝑢𝑖ˆ(𝐨′;𝐳)−12𝑑𝑛+1. This completes the proof as it contradicts the assumption that {u_i}(\mathbf {o}; \mathbf {z}) \ge \widehat{u_i}(\mathbf {o'}; \mathbf {z}) - \dfrac{1}{4d^{n+1}}𝑢𝑖(𝐨;𝐳)≥𝑢𝑖ˆ(𝐨′;𝐳)−14𝑑𝑛+1.

\square ◻

We now state and prove the two auxiliary lemmas we have used earlier:

Lemma 3.20
In every stage c<c^*𝑐<𝑐∗ of the algorithm, for every project j \in X_c𝑗∈𝑋𝑐 there exists an unassigned 𝑢𝑛𝑎𝑠𝑠𝑖𝑔𝑛𝑒𝑑 player i such that o_i=j𝑜𝑖=𝑗.

Proof
Assume towards a contradiction that in some stage c there exists a project j \in X_c𝑗∈𝑋𝑐 for which all the players working on it in \mathbf {o}𝐨 have already been assigned. Let player i be a player left unassigned after stage c, then u(i,o_{-i}) > u(\mathbf {o})𝑢(𝑖,𝑜−𝑖)>𝑢(𝐨). This is because in each stage the projects in the set X_c𝑋𝑐 maximize the marginal contribution. Since the utility is submodular, the marginal contribution of the projects can only decrease in every stage. Hence, player i’s marginal contribution to project j is greater than her contribution to project o_i𝑜𝑖. From this we conclude that u(i,o_{-i}) > u(\mathbf {o})𝑢(𝑖,𝑜−𝑖)>𝑢(𝐨), in contradiction to \mathbf {o}𝐨 being an optimal assignment. \square ◻

Lemma 3.21
For every two players i and l that have the same weight, {u_i} (o'_l,o'_{-i}; \mathbf {z}) \le \widehat{u_i} (o'_l,o'_{-i,l}; \mathbf {z}) - \frac{1}{2d^{n+1}}𝑢𝑖(𝑜′𝑙,𝑜′−𝑖;𝐳)≤𝑢𝑖ˆ(𝑜′𝑙,𝑜′−𝑖,𝑙;𝐳)−12𝑑𝑛+1.

Proof
Let z_i = z_l = z^*𝑧𝑖=𝑧𝑙=𝑧∗. We have

\begin{aligned}&u_i \left( o'_l,o'_{-i}; \mathbf {z}\right) \\&= \left( 1-p_l q_{o'_l}\right) \cdot w_{o'_l} p_iq_{o'_l} \sum _{S \subseteq \{K_{o'_l}\left( o'_{-i,l}\right) \}} \dfrac{z^*}{\left( \sum _{h \in S} z_h\right) + z^*} \cdot I_{o'_l}\left( S,K_{o'_l}\left( o'_{-i,l}\right) \right) \\&\quad +p_lq_{o'_l} \cdot w_{o'_l} p_iq_{o'_l} \sum _{S \subseteq \{K_{o'_l}\left( o'_{-i,l}\right) \}} \dfrac{z^*}{\left( \sum _{h \in S} z_h\right) + 2z^*} \cdot I_{o'_l}\left( S,K_{o'_l}\left( o'_{-i,l}\right) \right) . \end{aligned}

𝑢𝑖(𝑜′𝑙,𝑜′−𝑖;𝐳)=(1−𝑝𝑙𝑞𝑜′𝑙)⋅𝑤𝑜′𝑙𝑝𝑖𝑞𝑜′𝑙∑𝑆⊆{𝐾𝑜′𝑙(𝑜′−𝑖,𝑙)}𝑧∗(∑ℎ∈𝑆𝑧ℎ)+𝑧∗⋅𝐼𝑜′𝑙(𝑆,𝐾𝑜′𝑙(𝑜′−𝑖,𝑙))+𝑝𝑙𝑞𝑜′𝑙⋅𝑤𝑜′𝑙𝑝𝑖𝑞𝑜′𝑙∑𝑆⊆{𝐾𝑜′𝑙(𝑜′−𝑖,𝑙)}𝑧∗(∑ℎ∈𝑆𝑧ℎ)+2𝑧∗⋅𝐼𝑜′𝑙(𝑆,𝐾𝑜′𝑙(𝑜′−𝑖,𝑙)).

By rearranging the terms we have that u_i (o'_l,o'_{-i}; \mathbf {z}) =𝑢𝑖(𝑜′𝑙,𝑜′−𝑖;𝐳)=

\begin{aligned}&u_i\left( o'_l,o'_{-i,l}; \mathbf {z}\right) - w_{o'_l}p_lq_{o'_l} p_iq_{o'_l} \sum _{S \subseteq \{K_{o'_l}(o'_{-i,l} \}} \Bigg ( \dfrac{z^*}{\left( \sum _{h \in S} z_h\right) + z^*}\\&\quad - \dfrac{z^*}{\left( \sum _{h \in S} z_h\right) + 2z^*} \Bigg ) \cdot I_{o'_l}(S,K_{o'_l}(o'_{-i,l})). \end{aligned}

𝑢𝑖(𝑜′𝑙,𝑜′−𝑖,𝑙;𝐳)−𝑤𝑜′𝑙𝑝𝑙𝑞𝑜′𝑙𝑝𝑖𝑞𝑜′𝑙∑𝑆⊆{𝐾𝑜′𝑙(𝑜′−𝑖,𝑙}(𝑧∗(∑ℎ∈𝑆𝑧ℎ)+𝑧∗−𝑧∗(∑ℎ∈𝑆𝑧ℎ)+2𝑧∗)⋅𝐼𝑜′𝑙(𝑆,𝐾𝑜′𝑙(𝑜′−𝑖,𝑙)).

If we only consider the empty set in the summation we get that:

\begin{aligned} u_i (o'_l,o'_{-i}; \mathbf {z})&\le u_i(o'_l,o'_{-i,l}; \mathbf {z}) - \frac{1}{2} w_{o'_l}p_lq_{o'_l} p_iq_{o'_l} \prod _{\{h \in K_{o'_l}(o'_{-i,l}) \}}(1-p_hq_{o'_l}) \\&= u_i(o'_l,o'_{-i,l}; \mathbf {z}) - \frac{1}{2} p_lq_{o'_l} \cdot {\widehat{u}}_i(o'_l,o'_{-i,l}; \mathbf {z}) \end{aligned}

𝑢𝑖(𝑜′𝑙,𝑜′−𝑖;𝐳)≤𝑢𝑖(𝑜′𝑙,𝑜′−𝑖,𝑙;𝐳)−12𝑤𝑜′𝑙𝑝𝑙𝑞𝑜′𝑙𝑝𝑖𝑞𝑜′𝑙∏{ℎ∈𝐾𝑜′𝑙(𝑜′−𝑖,𝑙)}(1−𝑝ℎ𝑞𝑜′𝑙)=𝑢𝑖(𝑜′𝑙,𝑜′−𝑖,𝑙;𝐳)−12𝑝𝑙𝑞𝑜′𝑙⋅𝑢ˆ𝑖(𝑜′𝑙,𝑜′−𝑖,𝑙;𝐳)

By the definition of the common denominator we have that p_lq_{o'_l} \cdot {\widehat{u}}_i(o'_l,o'_{-i,l}; \mathbf {z}) \ge \dfrac{1}{d^{n+1}} 𝑝𝑙𝑞𝑜′𝑙⋅𝑢ˆ𝑖(𝑜′𝑙,𝑜′−𝑖,𝑙;𝐳)≥1𝑑𝑛+1 and hence u_i (o'_l,o'_{-i}; \mathbf {z}) \le u_i(o'_l,o'_{-i,l}; \mathbf {z}) - \frac{1}{2d^{n+1}} 𝑢𝑖(𝑜′𝑙,𝑜′−𝑖;𝐳)≤𝑢𝑖(𝑜′𝑙,𝑜′−𝑖,𝑙;𝐳)−12𝑑𝑛+1 as required. \square ◻

The proof of Theorem 3.17 is completed by observing that a very similar proof to the one we provided for identical players (Lemma 5.7) shows how for {\varepsilon }\le \dfrac{1}{8d^{n+1}w_l}𝜀≤18𝑑𝑛+1𝑤𝑙 the bounds for Claim 3.19 hold. That is: for every player i and project j: \widehat{u_i}(j,{o'}_{-i}; \mathbf {z}) -\dfrac{1}{4d^{n+1}} \le {u_i}(j,{o'}_{-i}; \mathbf {z}) \le \widehat{u_i}(j,{o'}_{-i}; \mathbf {z}) + \dfrac{1}{4d^{n+1}}𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳)−14𝑑𝑛+1≤𝑢𝑖(𝑗,𝑜′−𝑖;𝐳)≤𝑢𝑖ˆ(𝑗,𝑜′−𝑖;𝐳)+14𝑑𝑛+1. In particular, once we adjust the definition for \psi _i(j;S;\mathbf {a}) 𝜓𝑖(𝑗;𝑆;𝐚) as follows

\begin{aligned} \psi _i(j;S;\mathbf {a})=\dfrac{z_i}{z_i+\sum _{l\in S} z_l}p_iq_j \prod _{l \in S}p_lq_j \prod _{l \in \{K_j(a_{-i}) - S\} } (1-p_l q_j), \end{aligned}

𝜓𝑖(𝑗;𝑆;𝐚)=𝑧𝑖𝑧𝑖+∑𝑙∈𝑆𝑧𝑙𝑝𝑖𝑞𝑗∏𝑙∈𝑆𝑝𝑙𝑞𝑗∏𝑙∈{𝐾𝑗(𝑎−𝑖)−𝑆}(1−𝑝𝑙𝑞𝑗),

the proofs of Lemmas 5.4 and 5.5 for identical players easily extends to players with heterogeneous abilities. Thus we have that:

1.
\dfrac{1}{1+2 {\varepsilon }} {\widehat{u}}_i(j, a_{-i}; \mathbf {z}) \le w_j \cdot \sum _{S \subseteq \pi _{\small >i}(K_j(\mathbf {a}))} \psi _i(j;S;\mathbf {a}) \le {\widehat{u}}_i(j, a_{-i}; \mathbf {z})11+2𝜀𝑢ˆ𝑖(𝑗,𝑎−𝑖;𝐳)≤𝑤𝑗⋅∑𝑆⊆𝜋>𝑖(𝐾𝑗(𝐚))𝜓𝑖(𝑗;𝑆;𝐚)≤𝑢ˆ𝑖(𝑗,𝑎−𝑖;𝐳).

2.
\sum _{\begin{array}{c} S \subseteq K_j(a_{-i}) \\ S \cap \pi _{\small < i}(K_j(\mathbf {a}))\ne \emptyset \end{array} } \psi _i(j;S;\mathbf {a}) \le \dfrac{{\varepsilon }}{1+ {\varepsilon }} ∑𝑆⊆𝐾𝑗(𝑎−𝑖)𝑆∩𝜋<𝑖(𝐾𝑗(𝐚))≠∅𝜓𝑖(𝑗;𝑆;𝐚)≤𝜀1+𝜀.

This implies that we can use the proof of Lemma 5.7 as is to complete the proof of Theorem 3.17.

A Further Generalization: Arbitrary Success Probabilities
Finally, we consider a further generalization of the model, in which player i has an arbitrary success probability p_{ij}𝑝𝑖𝑗 when working on project j. The strategies and payoffs remain the same as before, subject to this modification. Also, this generalization is a monotone valid-utility game and congestion game; however, we omit the proofs since they are very similar to the proofs for the project game with different abilities.

An interesting feature of this generalization is that it is no longer always possible to make the social optimum a Nash equilibrium by re-weighting projects. To see why, consider the following example:

Example 4.1
There are two players 1 and 2, and two projects a and b. The two projects have weights w_a = w_b = 1𝑤𝑎=𝑤𝑏=1 and success probabilities p_{1a} = 1𝑝1𝑎=1, p_{1b} = 0.5𝑝1𝑏=0.5, p_{2a} = 0.5𝑝2𝑎=0.5, and p_{2b} = 0.1𝑝2𝑏=0.1. The social optimum is achieved if player 1 is assigned to project a and player 2 is assigned to project b. But this gives too little utility to player 2, and in order to keep player 2 on b, we need to re-weight the projects so that w_b' \ge 2.5 w_a'𝑤′𝑏≥2.5𝑤′𝑎. In this case, however, player 1 also has an incentive to move to b, proving that no re-weighting can enforce the social optimum.

The case of re-weighting players is an open question. In Sects. 2 and 3 , we used the re-weighting of players in a limited way, to simulate an ordering. It is possible that a similar tactic can also be used in the general model—that is, there may always exist a partial ordering on the players yielding a socially optimal Nash equilibrium. If this is not the case, one can potentially make use of weights on the players in more complex ways.

As one interesting partial result on the re-weighting of players in this model, we can show the following.

Theorem 4.2
If there exists a social optimum \mathbf {o}𝐨 that assigns each player to a distinct project, then it is possible to re-weight the players so that \mathbf {o}𝐨 is a Nash equilibrium.

Proof
The proof uses an analysis of the alternating-cycle structure of a bipartite graph on players and projects, combined with ideas from the proof of Theorem 3.17. As in other results on re-weighting players, we use the weights to simulate an ordering on the players. That is, we arrange the players in some specific order, and then we announce that all the credit on a project will be allocated to the first player in the order to succeed at it. We first describe how to construct such an ordering for which every Nash equilibrium in the resulting game is socially optimal, and then we show how to approximately simulate this order using weights.

Let \mathbf {o}𝐨 be an optimal assignment of players to projects in which there is at most one player working on each project. The following lemma establishes that there must be some player i who would choose her own project o_i𝑜𝑖 if she were placed first in the order.

Lemma 4.3
If in the optimal assignment there is at most one player working on each project, then there exists a player i such that o_i \in \arg \max _j w_jp_{i,j}𝑜𝑖∈argmax𝑗𝑤𝑗𝑝𝑖,𝑗.

Proof
Assume towards a contradiction that such a player does not exist. Then for every player i there exists a project g_i𝑔𝑖 such that w_{g_i}p_{i,g_i} > w_{o_i}p_{i,o_i}𝑤𝑔𝑖𝑝𝑖,𝑔𝑖>𝑤𝑜𝑖𝑝𝑖,𝑜𝑖. Since in the optimal assignment there is at most one player working on each project, we can picture the assignment as a matching between the projects and the players. Consider the bipartite graph which has the players on the left side, the projects on the right side and both the edges of the optimal matching \{(i,o_i)\}{(𝑖,𝑜𝑖)} and edges from each player to her preferred project \{(i,g_i)\}{(𝑖,𝑔𝑖)}. We color the edges in the first of these sets blue and the edges in the second of these sets red. This bipartite graph has 2n nodes and 2n edges, and it therefore contains a cycle C. The cycle C has interleaving red and blue edges, because each player on C has exactly one incident blue edge and one incident red edge. Hence, we can form a new perfect matching between players and projects by re-matching each player on C with the project to which she is matched using her red edge rather than her blue edge. Since all the players strictly prefer the projects to which they are connected by red edges, the social welfare of this new matching is greater than the social welfare of the blue matching, which contradicts the optimality of the blue matching. \square ◻

Given this lemma, we can construct the desired ordering by induction. We identify a player i with the property specified in Lemma 4.3 and place her first in the order. Since she knows she will receive all the credit from any project she succeeds at, she will choose her own project in the optimal solution o_i𝑜𝑖. We now remove i and o_i𝑜𝑖 from consideration and proceed inductively; the structure of the optimum on the remaining players is unchanged, so we can apply Lemma 4.3 on this smaller instance and continue in this way, thus producing an ordering.

The remainder of the proof is similar to the analysis for the case of identical players: we simulate the ordering i_1, i_2, \ldots , i_n𝑖1,𝑖2,…,𝑖𝑛 using player weights by choosing a sufficiently small {\varepsilon }> 0𝜀>0 and assigning player i_c𝑖𝑐 (the c^\mathrm{th}𝑐th player in the order) a weight of z_{i_c} = {\varepsilon }^c𝑧𝑖𝑐=𝜀𝑐.

\square ◻

It is interesting to note that once we are in the regime of this more general model one can construct instances in which a Braess like paradox appears – adding an additional player reduces the welfare of the best Nash equilibrium. Consider the following 2-player example:

Example 4.4
There are two players (1 and 2) and two projects (a and b). The weights of the projects are w_a=1𝑤𝑎=1, w_b=3/8𝑤𝑏=3/8 and the success probabilities are: p_{1a}=p_{2a}=0.5𝑝1𝑎=𝑝2𝑎=0.5, p_{1b}=p_{2b}=1𝑝1𝑏=𝑝2𝑏=1. For this 2-player instance the social welfare of the best Nash equilibrium, in which each player works on a different project is 7/8. If we add another player (3) such that p_{3a}=0, p_{3b}={\varepsilon }𝑝3𝑎=0,𝑝3𝑏=𝜀, we get that in any Nash equilibrium player 3 works on project b. However if player 3 is working on project b, then both players 1 and 2 prefer to work on project a which leads to a social welfare of 3/4 of the best Nash equilibrium instead of social welfare of 7/8 without player 3.

Discussion
In this paper we analyze how the credit distribution mechanism affects the choices of researchers of which project to work on. In a stylized model, we show that when the researchers compete one against the other, assigning credit unfairly can be beneficial to increasing the productivity of the research community as a whole. We focus on two specific methods for assigning credit unfairly: credit which is assigned unproportionally with respect to the projects’ importance and credit that is assigned based on the researchers identities. For the cases of identical and heterogeneous researchers we provide algorithms for computing a weighting that leads to an optimal allocation of the researchers to the projects.

Our paper is situated in a long line of research in sociology and philosophy of science aiming to understand how researchers work, for example, which problems they choose to work on and with whom. In the current paper we focused on a one-shot game in which researchers (or group of researchers) compete against each other. A recent paper from the sociology of science literature builds on our model and adds a temporal component [6]. Other papers that were published after the preliminary version of our paper appeared handled questions such as how to allocate credit in case of a collaboration [31] and how to incentivize researchers to release partial results [5]. On a more technical perspective, following our work, Bachrach et al. [3], consider which credit splitting rules ensures (approximate) social optimality.