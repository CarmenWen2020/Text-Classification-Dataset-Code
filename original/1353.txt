Abstract
Given a set P of n weighted points, a set Q of m points in the plane, and a positive integer k, we consider the optimization problem of finding a subset of Q with at most k points that dominates a subset of P with maximum total weight. A set 
 of points in the plane dominates a point p in the plane if some point 
 satisfies  and . We present an efficient algorithm solving this problem in  time and  space. Our result implies algorithms with better time bounds for related problems, including the disjoint union of cliques problem for interval graphs (equivalently, the hitting intervals problem) and the top-k representative skyline points problem in the plane.

Introduction
We consider the following optimization problem. Given two sets P and Q of points in the plane, and a positive integer k, find a subset of Q with at most k points that dominates as many points of P as possible. A set 
 of points in the plane dominates a point p in the plane if some point 
 satisfies  and . We provide an efficient algorithm solving the problem in  time, where n and m are the numbers of points in P and Q, respectively. The algorithm is quite simple and can be easily implemented. In fact, we solve a weighted variant, where the points of P have weights, possibly negative, and we want to dominate a subset of P with maximum total weight.

The (unweighted) problem generalizes problems that have been considered before in the context of scheduling, optimization in graphs and databases, and our algorithm directly improves the time bounds for the algorithms discussed on those contexts. We start describing the problem formally, explaining our results, and reviewing the connection to those other problems.

Problem Statement
For a point p in the plane, x(p) and y(p) denote its x-coordinate and y-coordinate, respectively. A point q dominates a point p if  and . A set 
 of points dominates p if some point of 
 dominates p.

For each point , let  be the closed 2-sided range . Note that  is the set of points in the plane dominated by q. For each subset 
, we define 
, that is, the set of points in the plane dominated by 
. See Fig. 1.

Fig. 1
figure 1
Left:  for a point q. Right: 
 for a set 
 with three points

Full size image

We are given two sets P and Q of points in the plane, and a function  assigning a weight w(p) to each point p of P. The weights may be negative. We extend the function w to regions of 
 by summing up the weights of the points of P contained in the region: 
 for each 
. We refer to w(R) as the weight of region R. If , then .

Given a positive integer k, we want to select a subset 
 with at most k points such that the total weight of the points of P dominated by 
 is maximized. We refer to this problem as maxDominance. Formally, we want to compute


 

and to obtain an optimal solution, that is, a subset 
 satisfying 
 and 
. In our algorithm it is important to ensure that each point 
 contributes w(p) to 
 exactly once, even if p is covered multiple times by the dominance regions , 
.

Previous Work
We are not aware of any previous work on the maxDominance problem in its full generality. A related problem is the maximum volume subset selection problem for anchored boxes, where we select k boxes among n given axis-parallel boxes, each box contained in the positive quadrant of 
 with a corner at the origin, that maximize the volume of the union of the selected boxes. The volume of the union is known as the hypervolume indicator. It can be solved in  time [5, 14] in 
, but it is NP-hard already in 
 [4]. This problem can be interpreted as a continuous version of the maxDominance problem. Placing a point in each cell of the arrangement defined by the anchored boxes with weight equal to be the volume of the cell, we reduce the maximum volume subset selection problem to the maxDominance problem. However, this reduction introduces 
 points, and thus is not very useful.

Other related problems include the disjoint union of cliques problem for interval graphs, the hitting intervals problem, and the top-k representative skyline points problem in the plane. We will describe the previous work for these problems after introducing them in the next subsection.

Our Contribution
Henceforth, we use  and  to bound the asymptotic time of the algorithms. Our main result is an algorithm to solve the maxDominance problem in  time and  space. This algorithm employs a dynamic programming approach where we use a data structure based on segment trees to speed up the computation. The main strengths of this result and our technique are the following:

The algorithm is simple.

The new result implies better time bounds for some optimization problems concerning intervals on the real line; the connection between these problems was not noticed before, and because of this we are improving on different problems simultaneously.

We can handle negative weights (for the points or the intervals). Previous related works did not consider negative weights; usually they considered unit weight per item, but can easily be extended to positive weights.

The presence of negative weights makes the formulation of the dynamic programming non-trivial, if we want to solve it efficiently. In particular, our formulation of the dynamic program is not the most natural one and it is different from the formulation used in related works that use dynamic programming [7, 12, 15]. For positive weights there are more natural dynamic programs that work because only points in the skyline of Q have to be considered as candidate points.

Our technique can solve other related problems. More specifically, our technique to solve the maxDominance problem can handle the special case where we may choose at most one point from each set 
, when the sets 
 form an antichain (defined in Sects. 1.3.2 and 4).

Overview of techniques We use a plane-sweep algorithm that considers a dynamic programming formulation for the input points above a horizontal line. In fact, we formulate two dynamic programming equations and, to compute them efficiently, construct a data structure supporting a few range query operations.

One dynamic programming equation is parametrized by the solution size, that is, the number  of selected points of Q for a solution, and a point  lying on the current horizontal sweep line. The equation represents the maximum dominance result determined by the solution size and the points of P and Q in quadrant II with respect to q. The other dynamic programming equation is parameterized by the solution size, the position of the sweep line, and the rightmost point 
 of the solution. The equation represents the maximum dominance result determined by the points of P and Q lying above the sweep line and the size of the solution whose rightmost point is 
.

The problem we consider is a weighted extension of the previous one by Lin et al. [15]. Since we allow negative weights, the points we need to select are not necessarily skyline points of Q, and we do not see how to compute fast enough the intermediary values in the dynamic programming equation of [15]. Nevertheless, in our formulation we do exploit that the points defining an optimal solution have to form a staircase. That is, the points of Q in the optimal solution do not dominate each other.

To obtain an efficient algorithm, we update the states of the equations using the rightmost selected point while the sweep line moves downwards. The update can be represented by several additions of x-ranges, corresponding to the x-coordinate of the rightmost selected point. Instead of computing dynamic programming states explicitly, we use a data structure that supports range maximum queries and range addition queries to compute the states if needed. We explain in detail a simple data structure based on segment trees [9, Section 10.3]. One could also use advanced data structures, like cut-link trees [16] or top trees [2].

To reduce the space complexity of our algorithm, we use a standard technique while constructing an optimal solution. To construct an optimal solution of size k, we find the 
 
th selected point in the optimal solution, divide the problem into two subproblems, one with points of P and Q in quadrant II and one with points of P and Q in quadrant IV, and solve them recursively. In total, our algorithm computes an optimal set of at most k points in  time using  space.

Representative skyline points
The skyline points of a set P of points are those that are not dominated by any other point of P. In a quite influential work, Lin et al. [15] introduce the top-k representative skyline points problem: given a set P of n points, select k of them maximizing the number of points from P they dominate. There is always an optimal solution consisting of k skyline points of P. Among other results, they provide an algorithm to solve this problem in the plane in 
 time and 
 space, where s is the number of the skyline points of P. (Additional data structures can be used to reduce the space bound to .) In the worst case we have , the running time is 
, and the space is 
 (or O(kn) using additional data structures).

Setting Q to be the points in the skyline and  for all , this problem is a special case of our problem. Thus, we can solve the top-k representative skyline points problem in  time and O(n) space. In the worst case, when , our new algorithm takes  time while the previous best algorithm [15] takes 
 time.

Lin et al. [15] also show that the problem is NP-hard in 3-dimensional space. Thus, our problem is NP-hard in 3 dimensions as well.

Several alternative measures have been introduced to choose the most representative points in the skyline, also in a variety of fields. See for example [1, 5, 17] for a small sample. A full survey of this work is beyond the scope of this article.

Constrained Version of Max Dominance Problem
As mentioned in the beginning of Sect. 1.3, our technique to solve the maxDominance problem can handle certain additional constraints in the set of points to be chosen.

We say that the sets 
 form an antichain if, for each  and each 
 and 
, we have 
 and 
. Consider the special case of maxDominance where we may choose at most one point from each set 
, when the sets 
 form an antichain. The algorithm we describe in Sect. 3 can easily be extended to this case. Let 
, and let . We can solve the variant of the maxDominance problem in the plane for n weighted points in P and points in Q using at most k points of Q and at most one point from each 
, , in  time using  space. The result also holds when there are negative weights.

For the special case that , we can solve the variant of the maxDominance problem in the plane for n positively weighted points in P and points in Q using at most one point from each 
, , in  time using  space.

Disjoint Cliques in Interval Graphs and Hitting Intervals
In the disjoint union of cliques problem (DUC for short), we are given a graph  and a positive integer k, and we are to find a set C of k disjoint cliques of G such that 
 is maximized. Here |c| is the number of vertices in a clique c, and a set of cliques is disjoint if each node of G belongs to at most one of the cliques.

For general graphs, the DUC problem is NP-hard and difficult in practice, as it includes the problem of finding a largest clique () as a special case. The problem keeps getting attention because of its applications in analyzing data; see for example [10, 19] for some recent results. Perhaps not so obvious, the problem encounters applications also in scheduling [7, 12].

Algorithmically, research has focused on particular classes of graphs. The DUC problem remains hard even in split (and thus chordal) graphs [18], where finding a maximum clique is solvable in polynomial time. On the positive side, Gavril [11], Yannakis and Gavril [18] and Jansen, Scheffler and Woeginger [12] provide polynomial-time algorithms for interval graphs, comparability graphs, co-comparability graphs, directed path graphs, cographs, and partial m-trees for a constant m.

We are interested in the DUC problem in interval graphs. It is well-known, and we discuss it in more detail in Sect. 5, that the DUC problem in interval graphs is equivalent to the HittingIntervals problem: given a set  of intervals on the real line and a value k, find k points on the real line such that the number of intervals of  hit by the points is maximized. Here, we say that a point  hits an interval I when . This problem is sometimes also called as the maximum piercing problem.

Jansen, Scheffler and Woeginger [12] provide an algorithm to solve the DUC problem in interval graphs in 
 time. As a clear example that sometimes it is difficult to trace previous work,Footnote 1 Chrobak et al. [7] also provide an algorithm with the same properties. Both papers consider this and other problems motivated by scheduling problems. Damaschke [8] improves the running time to O(k|E|) for connected interval graphs, which is relevant for graphs that are not very dense.

The weighted versions of the DUC problem in interval graphs and the HittingIntervals problem are also equivalent when the weights are positive. However, when negative weights are present, both problems are not equivalent anymore. Indeed, in the DUC problem we will never put a vertex with negative weight into the optimal solution, as we can remove it from the solution and increase the total value. In contrast, in the HittingIntervals problem we do not have any flexibility as to which intervals are counted. In any case, the DUC problem in interval graphs can be reduced to the HittingIntervals problem by first removing vertices with negative weights, and then solving the HittingIntervals problem in the remaining intervals. The reduction does not work in the other direction. Thus, the HittingIntervals problem is more general than the DUC problem in interval graphs.

In this paper, we use a simple reduction to the maxDominance problem which, together with our new algorithm for the maxDominance problem, solves the (weighted version of the) HittingIntervals problem in  time. As discussed, this also implies that the (weighted version of the) DUC problem in interval graphs can be solved also in  time. (The term O(|E|) comes from the graph complexity .) This improves all previous results when .

Organization
The rest of the paper is organized as follows. In Sect. 2, we introduce a data structure that maintains n values and supports a few update and query operations in  time per operation. In Sect. 3, we present an efficient algorithm that solves the maxDominance problem using the data structure introduced in Sect. 2. We then consider the case that the points have positive weights and show how the maxDominance problem and the top-k representative skyline points problem can be solved efficiently. In Sect. 4 we consider additional constraints in the set of feasible solutions. Then, in Sect. 5 we show how the HittingIntervals problem and the DUC problem for interval graphs are reduced to the maxDominance problem, and present efficient algorithms for the problems. We conclude the paper in Sect. 6.

Data Structure
We want to store n values 
, initially set to arbitrary values in , in a data structure that supports the following operations:

 returns the pair (t, a) with  and 
. As a special case, we can get 
 by querying .

 adds the value  to 
, where .

 sets the value of 
 to .

Using an adaptation of segment trees [9, Section 10.3], which can be interpreted also as an augmented binary search tree, we have the following.Footnote 2

Lemma 1
There is a data structure to maintain 
 in O(n) space that supports the operations ,  and  in  time per operation. The initialization of the data structure takes O(n) time.

Proof
We use a balanced binary search tree  with keys  at the leaf nodes. We use  to denote the leaf node of  that has key i and r for the root. For an internal node u of , we use 
 and 
 to denote its left and right child, respectively. For any two nodes u, v of , let  denote the path from u to v in  and let p(u) denote the parent node of .

Each node u of  represents a contiguous sequence of integers 
 for two integers x and 
 with 
. More precisely, a leaf node u with key i represents 
, and for an internal node u we have 
. A key property of this representation is that, for each contiguous sequence of integers 
 contained in , there is a set 
 of  nodes of  such that 
 is the disjoint union of 
, 
. In particular, for each 
 there is exactly one node 
 that is on the path . Furthermore, for any given integers x and 
 with 
, the set 
 can be found in  time using the search paths in  from the root to x and to 
, and all the nodes of 
 together have  ancestors in .

Fig. 2
figure 2
An example of the tree used in the proof of Lemma 1

Full size image

At each node u of  we store three values, ,  and . For any two nodes u and v of , we denote by 
 the sum of  along all vertices w in . (The value 
 will be considered only for vertices u and v in ancestor-descendant relation.) We maintain the following invariants:

For each leaf node u of , we have . For each internal node u of , ; thus .

For each leaf node  of , 
 is 
.

For each node u of ,  is the maximum among 
 over all leaf nodes v in the subtree rooted at u. An alternative, useful way to think of it is the following recursive formulation:


 
 

(1)

For each node u of ,  tells the index i of the leaf node that determines the value . Therefore,


 
 

(2)

Note that, for each node u of , we have 
. In particular,  is 
. It is clear that  takes O(n) space because we store only a constant amount of information per node. See Fig. 2 for an example.

We start with setting 
 and  for all leaf nodes  of , and  for all internal nodes u of . We then compute  and  in  from the bottom up using Equations (1) and (2). With this, we establish the invariant before making any operations. This initialization takes O(n) time and space.

Consider now the operation , where . We find the set U(i, j) of  nodes such that  is the disjoint union 
. Then 
 is the maximum of 
 over . These values 
 can be computed in  time in total because the nodes of U(i, j) altogether have  ancestors. The index t where the maximum is attained can be computed similarly, but using the indices .

Consider now the operation , which adds  to each of the elements 
. Again, we start with finding the set U(i, j) of  nodes. For each , we set . This settles the invariant for the values .

For the ancestors v of the nodes of U(i, j), traversing  in bottom-up manner, we update  and  using Equations (1) and (2). Since the nodes of U(i, j) altogether have  ancestors, we spend  time in total. See Fig. 3 for an example.

Fig. 3
figure 3
The tree of Fig. 2 after the operation . Grey nodes are nodes in U(1, 6). Nodes with thicker, green boundary are those that have to be updated, as they are in U(1, 6) or are their ancestors

Full size image

Consider now the operation , which sets 
 to . We compute the value 
 in  time by following the path  from , and at the leaf  set  to 
. With this we get the property 
. Then we update  and  for the nodes on  by following the path from  using equations (1) and (2). 

Max Dominance Problem
We first consider the most general case, where the points of P have weights, possibly negative. Some additional simplifications are possible when all the weights are positive. We want to choose a subset 
 of 
 with at most k points such that 
 is maximized. It is convenient to assume that the points of Q have different x- and y-coordinates. This can be enforced symbolically, for example replacing each point 
 by 
 for an infinitesimal . This can also be done explicitly in  time as follows: Sort the points of Q by their x-coordinates in . Then, for each point of P, apply a binary search among the x-coordinates of the sorted points of Q in  time. From this, compute the smallest difference 
 between the x-coordinates of a point  and a point  with . Similarly, compute the smallest difference 
 between the y-coordinates of a point  and a point  with . Finally, displace each point 
 of Q to 
, where 
. This guarantees that the points of Q have different x- and y-coordinates. Observe that the dominances of the points of Q remain the same as well, that is, 
 for every point q of Q and its displaced point 
.

For ease of description, we add a point 
 to Q, where 
 and 
. In particular, 
 does not dominate any other input point. Note that now we always have a solution 
 of weight 0. This solution corresponds to the empty set in the original instance.

Let 
 be the points of Q sorted by decreasing y-coordinate, that is, 
 for each . Clearly, 
 is the point we artificially added to Q. See Fig. 4.

Fig. 4
figure 4
An example showing the notation. The black dots correspond to 
 and the black crosses to 
. We have 
 and 
. If  for all , 
 and 

Full size image

For each , let 
 and 
. Note that 
. See Fig. 4. We use 
 to denote the sum of the point weights in 
 for any region R in the plane. Note that 
 for each i. (Here it is important that the points of P and Q have different y-coordinate.) Observe that 
, 
 and 
.

In general, we use the index  to bound the number of points selected from Q, while the indices i and j encode a point of Q, so that we use 
, 
 or 
. In all the cases that we consider we have . Therefore, the indices are always considered as ,  and .

For each  and , let


 

This means that we consider the weights of candidate solutions, restricted to 
, with at most  points selected among the points of 
. Thus, 
, and we are interested in the value 
. We have 
 because 
 is a candidate solution. Obviously, 
 for each .

For each ,  and , let


 

(3)

This means that we consider the weights of nonempty candidate solutions, restricted to 
, with at most  points selected among the points of 
 that must include the point 
. We have 
 because 
 is a candidate solution considered in Equation (3), and 
.

We will use dynamic programming to compute the values 
 and 
 for all , i and .

Fig. 5
figure 5
Left: 
 is the maximum weight of candidate solutions of size at most  for the points of P and Q contained in the gray region. Right: 
 is the maximum weight of candidate solutions, each containing 
, of size at most  for the points of P and Q contained in the gray region

Full size image

The following lemma provides the recursive formulas for the computation. See Figs. 5 and  6 for some intuition.

Lemma 2
For each ,  and , we have


 

Proof
We first show that 
. Let 
 be an index j that determines 
 and let 
 be an optimal solution defining 
. This means that 
 and 
 because 
. Therefore 
 is considered as a candidate solution in the definition of 
, and thus


 

Fig. 6
figure 6
Illustration for parts of the proof of Lemma 2. The gray region is 
. Left: 
. Right: the black dots contribute to 
, while the black crosses contribute to 

Full size image

Now we show that 
. Let 
 be an optimal subset of 
 defining 
. If 
, then


 

For 
, let 
 be the rightmost point of 
, that is, the one with largest x-coordinate. Note that 
 because 
. For any point 
 with 
, we have 
. Thus 
. See Fig. 6, left. We then conclude that


 

We have shown the first equality, for 
. Now we show the second equality, for 
. First, we show that 
 for . Let 
 be an optimal solution defining 
. Since 
 and 
, for 
, we have (see Fig. 6, right)


 

Since 
 and 
, we have


 

Finally, we show that 
 for . Let 
 be an optimal solution defining 
. This means that 
, 
 and 
. Therefore, 
 is a candidate solution considered in the definition of 
, and thus


 

The result follows. 

Fig. 7
figure 7
The black dots are the points in 
. They can contribute to 
 for any region R

Full size image

Initially, set 
 for all i in O(m) time. For each , the straightforward computation of 
 using the formulas of Lemma 2 takes 
 time, even if the values 
 are already available. Using the data structure of Lemma 1, we can do this step in  time. The algorithm can be interpreted as a sweep-line algorithm [9, Chapter 2]. We sweep the plane with a horizontal line from top to bottom, the points of Q are the events, and we maintain the values S(i, j) in a data structure, where 
 is the last event that was processed.

Lemma 3
Consider a fixed index  and assume that the values 
 are available for all i. We can compute 
 for all i in  time and  space.

Proof
We use an iterative algorithm, with a for loop with , where we maintain the values 
 in a data structure. First we analyze the relation between 
 and 
.

Consider first the case . Note that, because of Lemma 2,


 

Observe that the term 
 is the sum of the weights of the points of 
 contained in a region R. See Fig. 7, for an illustration. This means that


 
 
 

(4)

Our algorithm exploits the fact that each point 
 contributes the same change, , to all the indices j with 
.

For , Lemma 2 implies that


 

Fig. 8
figure 8
Left: at the end of iteration , 
 (because ) while 
 for . Right: During iteration , we handle 
. We have 
. Thus, we make , 
 and 

Full size image

Now we explain how we maintain the values 
 through the algorithm. See Fig. 8 for an example illustrating the description. We want to consider the points of Q sorted by x-coordinate. Let  be a permutation that sorts (the indices of) the points of Q by non-decreasing x-coordinate. Since the points of Q have different x-coordinates, 
. Note that  because of the way we choose the artificial point 
. We can compute  and its inverse 
 in  time.

We maintain values 
. It is convenient to interpret 
 as a value associated to the point 
, that is, the tth point of Q from left to right. Through the algorithm we maintain the invariant that, at the end of the ith iteration,


 
 

(5)

Note that 
 is not defined, when . Thus, we can interpret  as undefined. Before the for loop, we set 
 for all t and store the values 
 in the data structure of Lemma 1.

For each point , let  be the smallest integer such that 
. This means that p is to the right of 
 and to the left of or on the vertical line through 
. We can compute  for all  together in  time, as follows. First, we sort Q by x-coordinates in  time. Then, for each  we perform a binary search on the x-coordinates of the points of Q. This takes  time per point of P. A similar procedure, but based on the y-coordinates, is used to construct the sets 
 for all i. Each point p of P belongs to one of those sets, 
, or to none of them, when 
. (Note that these computations can be reused for different values of .)

Computationally, at the ith iteration we maintain the invariant (Equation (5)) by making the following operations:

For each point p in 
, apply . This takes care that the value w(p) has to be added to 
 to obtain 
, for all j with . See Equation (4).

If , set 
 to 
 by applying 
.

Recall Fig. 8 for an example. Note that the second operation is applied only once to each 
 over the whole algorithm, and it takes care that the invariant holds for the value t with . The first operation takes care that the invariant holds for all t with . Indeed, if , we add some finite values to 
, and if , we transform 
 to 
 because of Equation (4).

Recall that 
 because of Lemma 2. This implies that, at the end of the ith iteration, we get the value 
 by querying 
. Indeed, if we denote by t the value such that , then  returns


 

Each point of P is considered only once over all iterations. Thus, we perform  operations in the representation of 
. Since each operation takes  time, the result follows. 

Using Lemma 3 repeatedly, we can solve the problem maxDominance in  time. With some care we can use linear space.

Theorem 4
The maxDominance problem in the plane for n weighted points in P and m points in Q using at most k points of Q can be solved in  time using  space. The result also holds when there are negative weights.

Proof
We use the notation 
 to denote the table 
 for all . We can compute 
 in O(m) time.

For each , once we have 
 we can compute 
 in  time using  space because of Lemma 3. The running time over all applications of Lemma 3 together is . We reuse the space when computing each 
 so that we compute the final 
 in linear space. Then 
 gives the optimal value for the problem maxDominance, but we do not find the optimal solution yet because we do not have access to 
 for  anymore.

We use a standard technique to construct an optimal solution without affecting the asymptotic running time or space. If we unroll the relations in Lemma 2, we have


 

During the computation of the table 
, we maintain a table of pointers 
 telling in which index the maximum was achieved. Thus, for each i we have


 

Following the pointers 
, starting from 
, we can recover an optimal solution. In this procedure, 
 is the index of the th point in the optimal solution. We have 
 when the solution has fewer than k elements.

Set 
. For each 
 and i, we want to store an index 
 in the table 
 that leads to an optimal solution for 
. We achieve this with a small adaptation: for 
, we just compute the tables 
. For 
, we store the index 
. For 
, we store the index 
.

Fig. 9
figure 9
Left: the two-dimensional table ; the shaded regions are the ones computed during the recursion. Right: geometric interpretation of the recursion

Full size image

Recall that 
 is the optimal value. Set 
. See Fig. 9. There exists an optimal solution 
 such that 
. Moreover, such an optimal solution 
 contains at most 
 points from 
 and at most 
 points from 
. We can use the index t to split the problem because


 

See Fig. 9, right. Note that each point of P and Q goes to at most one of the recursive problems. We solve the problems recursively. Let A(k, m, n) denote the time needed to construct the optimal solution using this recursive approach. Since we need  time to compute the table 
 and 
, we have


 

where 
. This solves to . (Since , the size (number of cells) of the tables we have to compute at the same level of the recursion decreases geometrically through the recursive calls. See Fig. 9, left. A similar argument works using 
.)

At each level of the recursion we need O(1) additional space to keep the indices defining the optimal solution. All other space can be reused. Thus, we spend  space. 

Positive Weights
When the points have positive weights, we can make some simplifying steps as in the following lemma.

Lemma 5
Assume that the points of P have positive weights and Q has s points in the skyline; s is not known. After a preprocessing that takes  time and  space, we can assume that no point of Q is dominated by another point of Q and each point of P is dominated by some point of Q.

Proof
If some point 
 of Q is dominated by another point q of 
, then 
 and, for each candidate solution 
 with 
, the candidate solution 
 is at least as good as 
.

The skyline points of Q, that is, the points of Q not dominated by any other point of Q can be computed in  time, where s is the number of points in the skyline. This was shown by Kirkpatrick and Seidel [13]. The technique of Chan [6] to compute convex hulls optimally can be also used to obtain a simple algorithm with the same guarantee. Thus, after  preprocessing time, we can assume that Q consists of the s points in the skyline of Q.

If some point p of P is not dominated by any point of Q, then 
 for each 
, and removing p from P does not change the value of any candidate solution.

Removing the points of P that are dominated by no point of Q

can be done in  time as follows. Sort the (skyline) points of Q by x-coordinate. Then the points of Q are aligned in a staircase, that is, if 
 then 
 for any two points 
. Then apply binary search for each point  to check the dominance of p by points of Q using the staircase in  time, and thus in total  additional time. 

After applying Lemma 5 to “clean” the data, we are only interested in the points of Q in the skyline. As a consequence of Theorem 4 and Lemma 5 we obtain the following, which depends on the complexity of the skyline of Q.

Theorem 6
The maxDominance problem in the plane for n positively weighted points in P and m points in Q using at most k points of Q can be solved in  time using  space, where s is the number of points in the skyline of Q.

The points in the skyline are aligned in a staircase and have the shape depicted in Fig. 10. In particular, the ordering along y- or x-coordinates agree. Some steps in our algorithm for arbitrary weights can be slightly simplified in this case, at the conceptual level. However we do not know how to improve the time bound we obtained for the general case.

Fig. 10
figure 10
Remaining set after cleaning Q for the input of Fig. 4, if the points of P have positive weights

Full size image

As mentioned in the introduction, Lin et al. [15] consider the case when  and all points have unit weight. As a consequence of Theorem 4 and Lemma 5, we improve their results when 
.

Corollary 7
The top-k representative skyline points problem in the plane can be solved in  time and O(n) space, where n is the total number of points and s is the number of points in the skyline.

Constrained Version of Max Dominance Problem
Our technique to solve the maxDominance problem can handle certain additional constraints in the set of points to be chosen, as follows.

Recall that the sets 
 form an antichain if, for each  and each 
 and 
, we have 
 and 
. See Fig. 11. When the points of 
 are in the skyline, then forming an antichain is equivalent to requesting that each group 
 form a consecutive group in the skyline.

Fig. 11
figure 11
Geometric view of the property that the sets 
 form an antichain

Full size image

Consider the special case of maxDominance where we may choose at most one point from each set 
, when the sets 
 form an antichain. The algorithm we explained in Sect. 3 can easily be extended to this case. Define 
. We keep using the notation and the additional point 
 that was introduced in Sect. 3. We also introduce the new set 
. For each point 
, let a(i) be the index such that 
. Then, we define


 

and


 

Note that in 
 we are not allowed to select in 
 points from the set 
, that is, we cannot select any point from the same group as 
. On the other hand, in 
 we do not have such restriction for 
. We then have the following analogue of Lemma 2, whose proof we skip because it is essentially the same.

Lemma 8
For each ,  and , we have


 

Then we have the following analogue of Lemma 3.

Lemma 9
Consider a fixed index  and assume that the values 
 are available for all i. We can compute 
 for all i in  time and  space.

Proof
The proof of Lemma 3 applies nearly verbatim. The only difference is in computing the value 
 at the end of the ith iteration, instead of querying , where , we have to query for 
, where 
 is the rightmost point in 
, that is, the set before the current set 
. This guarantees that we only consider the values 
 for indices j with . 

We then obtain the following.

Theorem 10
Assume that we have an antichain of point sets 
 in the plane, let 
, and let . The variant of the maxDominance problem in the plane for n weighted points in P and points in Q using at most k points of Q and at most one point from each 
, , can be solved in  time using  space. The result also holds when there are negative weights.

In the special case that  and the weights of P are positive, one can do better. In such a case, we can assume that the solution will contain exactly k points of Q, that is, exactly one point from each group 
. We modify the definitions of 
 and 
 so that the sets 
 of points considered contain exactly  points and at most one point from each group 
. For each group 
, let  and  be the indices such that 
.

In this scenario, the values 
 are interesting only when , that is, when 
. This means, that it suffices to compute 
 for all i such that , then 
 for all i such that , etc. When computing 
 for all i with , we use the values 
 for all j with . In this setting each point 
 is considered once, namely when constructing 
. Thus, we do not need to compute the whole table 
 for all entries , but it suffices to compute a portion of linear size. Thus, we can compute 
 from 
 in 
 time, where 
 is the subset of points of P whose y-coordinate is between 
 and 
. Since each point of Q belongs to a single set 
 and each point of P to at most one 
, we obtain the following.

Theorem 11
Assume that we have an antichain of point sets 
 in the plane, let 
, and let . The variant of the maxDominance problem in the plane for n positively weighted points in P and points in Q using at most one point from each 
, , can be solved in  time using  space.

Hitting Intervals and Disjoint Clique Problem
An interval graph  is the intersection graph of a set  of intervals on the real line. That is, each interval of  is a node of the graph , and there is an edge between two nodes of  if and only if the two corresponding intervals intersect. The set  is called the geometric representation or geometric model of . Given an interval graph , we can find a geometric representation in  time [3]. In the opposite direction, given a set  of n intervals, we can construct the interval graph  in  time, where  is the edge set of . (The term  comes from sorting the endpoints of the intervals, and becomes O(n) if the input is sorted.) Thus, up to sorting, there is no difference in assuming that the input is given as an interval graph or as its geometric model.

A set of intervals on the real line intersect pairwise if and only if they all have a common point. For an interval graph , a subset 
 of intervals defines a clique if and only if there is a point piercing all the intervals of 
. Thus, there is a tight connection between the disjoint union of cliques problem and the interval piercing problem. More precisely, the total number of the nodes in k disjoint cliques of an interval graph  is the same as the total number of intervals of  hit (or pierced) by k points corresponding to the k cliques. Here, intervals that are hit by more than one point get assigned arbitrarily to only one clique. The same equivalence holds for weighted variants of the problem, if the weights are positive. When there are negative weights, the equivalence does not hold because we may have intervals with negative weights that are hit by a point, but we do not include them into the clique.

Assume that we are given a set 
 of (weighted) intervals and a set X of m points on the real line. We want to solve the HittingIntervals problem where we are allowed to choose points only from X. Thus, for a given integer k, we want to select a subset 
 of k points such that the sum of the weights of the intervals intersected by 
 is maximized.

For simplicity, we assume that each interval is closed. Map each interval 
 to the point 
 in the plane, and let 
. Since 
, every interval is mapped to a point lying on or above the diagonal of points with equal coordinates. (Usually this is the line , but we use x to denote something else.) A point  hits an interval 
 if and only if 
 is on the top-left quadrant defined by the point (x, x), and denoted by 
. See Fig. 12, left and center. By a counterclockwise rotation of the setting by  around the origin, 
 becomes exactly a dominance region, namely .

Fig. 12
figure 12
Left: a set of intervals in  and a point  hitting the intervals 
, 
, 
 and 
. Center: the image of the mapping 
 for the intervals on the left and the quadrant defined by 
. Right: the points 
 and 
 marked along the diagonal

Full size image

Consider the set  of  points, which lies on the diagonal of the plane. Then there is a bijection between each candidate solution, restricted to X, for the HittingIntervals problem for  and each candidate solution for the maxDominance problem for P and Q (after a rotation). By Theorem 4 we conclude the following.

Theorem 12
The HittingIntervals problem for weighted intervals using at most k hitting points from a prescribed set X can be solved in  time and  space, where n is the number of intervals and m is the number of points in X. The result also holds when the intervals have negative weights.

We can solve the HittingIntervals problem when the hitting points can be placed anywhere in . Indeed, in this case we can take X to be the set of endpoints of all intervals in . See Fig. 12, right. In this case X has O(n) points and we immediately obtain the following.

Corollary 13
The HittingIntervals problem for n weighted intervals using at most k hitting points can be solved in  time and O(n) space. The result also holds when the intervals have negative weights.

We can also solve the DUC problem for weighted interval graphs. As mentioned in the introduction, we remove the intervals with negative weights because they will never be in an optimal solution to the weighted DUC problem. Then, we are left with a DUC problem with positively weighted interval graphs. This problem is equivalent to the weighted HittingIntervals problem. By Corollary 13 we obtain the following.

Corollary 14
The DUC problem for weighted interval graphs  using at most k cliques can be solved in  time and  space.

Constrained version of hitting intervals As we did in Sect. 4, we can also consider a constrained version of the HittingIntervals problem. More precisely, assume that we are given a set of n intervals 
, an integer k, and a collection 
 for the locations of the k points such that 
 for . Set 
 and . We consider subsets 
 of X with at most k points such that at most one point can be selected from 
 for each .

We may assume that each 
 is a finite set. Indeed, if some 
 is an interval, we can replace it by the set of endpoints of intervals contained in 
, together with the endpoints of 
. This does not change the optimal values. With the replacement we may obtain  points in 
.

The geometric transformation we use in the proof of Theorem 12 also applies to this setting, and we obtain an instance of the problem considered in Sect. 4. Using Theorem 10 we conclude that the constrained version can be solved in  time.

We can further consider the particular case where the intervals have positive weights and . Thus, we may assume that we select a point from each 
. Theorem 11 then implies that the problem can be solved in  time.

Conclusion
We have seen that the maxDominance problem can be solved in  time and  space. Our algorithm employs a dynamic programming approach where we use a data structure based on segment trees to speed up the computation. We also present algorithms with better time bounds for the top-k representative skyline points problem in the plane and the disjoint union of cliques problem for interval graphs (equivalently, the hitting intervals problem). We also handle a constrained version of the problems, where the points that are selected come from a certain additionally structured input.

It seems that the “correct” time bound for the maxDominance problem may be . This means, that we only need to sort  once. A possible insight to obtain such time bound may be noting that to compute 
 from 
 we always make essentially the same sequence of operations to the data structure of Lemma 1, independently of . Only the setting of values through the operation set is different. In fact, the sequence of updates and queries to the data structure is known in advance. Another potentially relevant insight may be that the operation  is made exactly once for each value j. It is unclear how to exploit these features to improve the running time, if it can be improved.