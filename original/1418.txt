Almost surreptitiously, crowdsourcing has entered software engineering practice. In-house development, contracting, and outsourcing still dominate, but many development projects use crowdsourcing-for example, to squash bugs, test software, or gather alternative UI designs. Although the overall impact has been mundane so far, crowdsourcing could lead to fundamental, disruptive changes in how software is developed. Various crowdsourcing models have been applied to software development. Such changes offer exciting opportunities, but several challenges must be met for crowdsourcing software development to reach its potential.
Imagine These Headlines
More than 1,000 Developers Build Web Browser from Scratch in One Weekend

Major Software Company Fixes Core Vulnerability across 100 Systems in Two Hours

Individuals Worldwide Design Brilliantly Creative Approach to Improve Web Accessibility

Although those headlines might seem futuristic, even fantastic (and all are fictional), consider these real examples of crowdsourcing:

Players of FoldIt, a puzzle game with more than 57,000 users, solved a protein-folding problem in three weeks that had stumped researchers for years.1

Ten red balloons scattered across the US were located in less than nine hours by a team that recruited and coordinated thousands to help in its quest.2

A crowd of more than 70,000 contributors created and have maintained an encyclopedia with more than 35 million articles in 290 languages.3

All these examples were once considered equally fantastic, or at least clearly impossible.

This article is about software engineering, the crowd, and whether advances like these can be had in software. Although our introductory examples are pure fiction today, crowdsourcing clearly is already penetrating software development practice. Topcoder (www.topcoder.com) has hosted more than 427,500 software design, development, and data science competitions, awarding more than US$25,000 a day to competitors. More than 100,000 testers freelance on uTest (www.utest.com), testing new apps for compatibility with devices, performing functionality testing, and conducting usability inspections and studies.

In addition, more than 16,000,000 answers to programming questions have been provided on StackOverflow (stackoverflow.com), now the 69th-most-trafficked website in the US (as determined through www.alexa.com). Major software companies such as Netflix, Microsoft, Facebook, and Google regularly offer bug bounties, particularly concerning security vulnerabilities.4 New platforms for crowdsourcing software engineering are emerging regularly, offering different specialized services-for example, Bountify (bountify.co), AppStori (appstori.com), and Pay-4Bugs (www.pay4bugs.com).

Models
To examine crowdsourcing models for software development, it's useful to return to Jeff Howe's original definition:

Crowdsourcing represents the act of a company or institution taking a function once performed by employees and outsourcing it to an undefined (and generally large) network of people in the form of an open call.5

Ke Mao and his colleagues closely echoed that definition:

Crowdsourced Software Engineering is the act of undertaking any external software engineering tasks by an undefined, potentially large group of online workers in an open call format.6

Each definition homes in on the three factors that distinguish crowdsourcing from other outsourced work:

The work is solicited through an open call to which basically anyone can respond.

The workers who volunteer are unknown to the organization needing the work done.

The group of workers can be large.

What the open call's exact nature is and how it's issued, how an overall task is or isn't broken down into smaller tasks, if and how workers collaborate, and other such factors remain unspecified. Through variations in such aspects, various crowdsourcing models have emerged that have become common in software development.

Crowdsourcing is a form of collective intelligence, the general idea being that information processing can emerge from the actions of groups of individuals. Several collective-intelligence approaches have been applied to software development. For example, companies sometimes turn to internal open innovation, soliciting employee input on areas beyond their normal work assignments to get many ideas.7 Another example involves systems that mine and re-Use others' work-for example, code search engines that offer code examples or auto complete tools that mine and surface common coding idioms. We don't consider these systems crowdsourcing because they don't solicit work through an open call to undefined individuals outside an organization's boundaries.

Peer Production
One of the oldest and best-known models of software crowdsourcing is open source. Tens of thousands of people contribute to software projects such as Linux, Apache, Rails, and Firefox. Open source development is an example of peer production, a model in which control is decentralized and contributions are made without monetary reward.8 The contributors, rather than a paying client, decide the project's scope and goals.

Contributors are typically motivated by the opportunity to gain experience with new technologies, bolster their reputation, and contribute to a good cause. To do so, they must first get up to speed-learning about the project's conventions, architecture, designs, and social norms. This process can take days or weeks which might dissuade those casually interested from ever contributing. Yet, many contributors continue to make open source a success.

Other forms of peer production exist. For instance, in StackOverflow, developers share hard-earned expertise by answering questions.

Most large software companies have used crowdsourcing, whether to gather alternative UI designs, test, or fix bugs.
(You could argue that this isn't peer production because the question askers set the goals. However, the question askers are themselves members of the crowd rather than a distinguished class.) Expert questions on StackOverflow receive an answer in a median of just 11 minutes9, another example of crowdsourcing's power.

Competitions
A second crowdsourcing model, competitions, has recently gained significant attention in software development. Pioneered for software by TopCoder, competitions are similar to traditional outsourcing, in which a client requests work and pays for its completion. However, they treat workers as contestants rather than collaborators. First, a client proposes a project. Then a copilot (an experienced worker paid for this work) decomposes the project into a series of competitions that might cover requirements, architecture’ UI design, implementation, and testing. The copilot divides each competition into tasks that can be completed in a number of days. Contestants each provide a competing solution; from these, the copilot selects a winning entry and runner-up, and the corresponding workers are paid. Competitions give clients access to diverse solutions, which some believe leads to higher-quality results. At the same time, additional costs might arise that aren't immediately obvious.10

Table 1 The dimensions of crowdsourcing.
Table 1- The dimensions of crowdsourcing.
Competitions are particularly popular for software tasks in which diverse input is most valuable. For example, sites such as 99designs (www.99designs.com) let clients crowdsource visual-design tasks, reviewing alternative icons, logos, or website designs produced by the crowd to select the best option. Bug bounties, too, fall in this category: different workers might identify different bugs, increasing the likelihood a bug is found.

Microtasking
This model decomposes work into a set of self-contained microtasks, which can each be completed in minutes and which together constitute a solution to a more complex task. Microtasking is typified by Amazon's Mechanical Turk, a general platform in which clients post batches of microtasks (often automatically generated) that workers (“Turkers”) complete one at a time. To ensure quality, multiple workers might be asked to complete the same microtask, with the best solution selected by voting and other mechanisms.

This model's primary advantage is its extreme scalability. Because the tasks are small and self-contained, work can be distributed to arbitrarily large crowds, enabling the quick completion of large tasks.

This model has found success in software testing. Hundreds of thousands of testers participate in labor markets such as UserTesting.com (www.usertesting.com), TryMyUI (www.trymyui.com), TestBats (www.testbats.com), and uTest (www.utest.com). These services offer clients the benefits of a fluid labor force and speed. Clients can quickly locate and contract a workforce, with the platform handling worker screening and payment. So, a client can contract a labor force and obtain the completed task in less time than it might take to post a traditional job advertisement. For example, UserTesting.com promises to provide usability feedback in less than an hour. For small organizations looking to find skilled help quickly, this provides an enormous benefit.

The Dimensions of Crowdsourcing
Peer production, competitions, and microtasking have important differences. To compare crowdsourcing models and provide a sense of the space in which they exist, we identified eight foundational and orthogonal dimensions along which the models vary (see Table 1), building more generally on other taxonomies of the use of crowdsourcing.11,12

These dimensions enable the description of a range of models for crowdsourcing software engineering. Table 2 applies the dimensions to concrete example systems for peer production, competitions, and microtasking.

Other such systems can be similarly captured. For example, verification games transform formal software verification problems into a game-like experience to which even nonexperts can contribute. Using the dimensions, we describe the Pipe-Jam13 game thusly:

crowd size: medium

task length: minutes

Table 2 Applying the dimensions of crowdsourcing to concrete examples of three crowdsourcing models.

expertise demands: minimal

locus of control: client

incentives: intrinsic

task interdependence: medium

task context: none

replication: none

As these examples show, crowdsourcing systems with significantly varying approaches are possible.

Motivations
It's interesting to consider the forces driving the current emergence of crowdsourcing models, platforms, and environments, particularly in terms of their use in software development organizations. Many of the models are relatively novel, and their long-term benefits and drawbacks remain poorly understood. Businesses, however, must see tangible benefits to adopt and use crowdsourcing-even if experimentally. Here, we review several motives driving software development organizations to adopt crowdsourcing, as well as the forces motivating developers to participate.

Reduced Time to Market
Increased development speed is a frequent reason for crowdsourcing. The possibility to perform usability testing of a system in a few hours is tantalizing, given that such efforts typically take much longer in-house. The key is parallelism: many workers contribute with small efforts that constitute a potent whole. An individual or small team would have difficulty devoting as many eyes to search for bugs or vulnerabilities as a bug bounty could. Neither could such an individual or small team reach the breadth of devices and situations that a uTest usability test covers. A fluid, dynamic labor force that can engage with new tasks enables the parallelism inherent in work to translate into faster time to market.

This doesn't mean that every crowdsourced effort is faster. Far from it. The argument for crowdsourcing's speed holds for models with two characteristics. First, work must easily be broken down into short tasks. Second, each task must be mostly self-contained with minimal coordination demands, letting workers quickly make a contribution. These characteristics aren't necessarily true when work scales up-for instance, to the development of wholesale systems or significant aspects thereof.

Generating Alternative Solutions
Organizing work into self-contained tasks enables multiple workers to independently complete the same task. Because workers have diverse perspectives, backgrounds, and experiences' this often leads to the creation of alternative solutions. By selecting the best alternative-or, in some cases, requesting more work combining aspects of several alternatives-crowd sourcing can produce higher-quality solutions. In StackOverflow, developers can compare many alternative answers to their question, selecting the best for their needs. Similarly, 99designs lets clients rapidly solicit and compare many UI designs, increasing the likelihood of identifying new design ideas that no one person might have considered.

Not every task is set up to generate alternatives. Sites such as Test-Bats achieve test coverage by creating a range of diverse tasks and don't attempt the same task repeatedly. Similarly, in open source we see little alternative generation because the individual developers choose what to work on. Of course, alternative solutions sometimes are extensively discussed on mailing lists, and developers sometimes fork whole projects. But developers rarely explicitly develop and consider, for example, alternative architectures or implementations.

Employing Specialists
Decomposing large development tasks into smaller tasks enables greater flexibility in the use of specialist freelancers. Crowdsourcing might make it possible to rely less on in-house developers who are genera lists (and thus perhaps less fluent in a particular area of work) or on recruiting specialists into the team when necessary (which often requires substantial lead time).

Bringing in specialist freelancers through crowdsourcing happens today on a limited basis, and often on smaller tasks that are free to the company (for example, a Firebase expert who can explain the source of an exception on StackOverflow). However, the model could be taken further by using paid freelance work-witness the security experts who find a vulnerability through a bug bounty. This might be especially valuable for development tasks requiring intricate, detailed knowledge of technologies or frameworks. For that, specialists can use their deep understanding to build the best possible design, implement critical code, or troubleshoot a code base that in-house developers can't get “right.”

Freelancers might choose to become specialists in a narrow range of technologies, performing highly specialized tasks for short engagements across many projects, much as a vascular surgeon repeatedly performs a small number of related surgeries. At the same time, freelancing certainly isn't always applicable. A suitable task context must be available; otherwise, developers might spend more time trying to understand what to do than doing the work. Creating such contexts might be difficult. Moreover, many organizations need to retain sufficient expertise in-house so as to guide the freelancers in their work and to check it once it's complete. This might itself create significant new costs.

The Democratization of Participation
A definitional characteristic of crowdsourcing is the democratization of participation. Rather than assigning work to a team or outsourcing it to a subcontractor, crowdsourced work offers an open call, letting contributors determine how, when, and what to contribute, even as crowdsourcing models differ in the degree of control afforded to the crowd. In open source, anyone can voice their opinion and submit contributions for review. In a TopCoder competition, anyone can submit an entry. In a bug bounty, anyone can engage with the code base to find problems. To workers, this can be greatly liberating. They no longer have to work on what they've been assigned. Rather, they can choose where and when to contribute and be rewarded when their efforts are successful.

Yet, significant barriers often deter prospective contributors. In open source, developers must first become familiar with the code base, architecture, build environment, and work practices, which might take days or weeks. In other cases, the barriers might be more subtle. In communities that engage in competitions, established experts sometimes win most of the competitions, discouraging novices and effectively shutting them out of such competitions.

Learning Through Work
As we mentioned before, a key reason developers contribute to open source is to learn a new technology. They might want to learn a new framework (for example, AngularJS) or get up to speed on the style and idioms of a new project by reading some code and contributing a bug fix. Whereas millions use communities such as Codecademy (www.codecademy.com) to learn the basics of new technologies, going beyond requires jumping into a larger, real project. Different crowdsourcing models let developers do so with varying commitment levels.

However, to learn in today's crowdsourcing systems, software developers must first join, and acculturate themselves to, software projects. Although this might be easy for those who have worked on similar projects, it remains a serious hurdle for the very developers who have the most to learn.

The possibility to usability-test a system in a few hours is tantalizing, given that, in-house, that task often takes considerably longer.
Challenges
Even as crowdsourcing slowly but surely enters mainstream software development, key challenges remain for it to reach its true potential and for the scenarios sketched in the introduction to become reality-if that's indeed possible. In particular, further realizing many of crowdsourcing's benefits requires further decomposition of tasks and even greater participation in crowdsourcing platforms. Essentially, this asks whether we can increase the crowd's size, shrink the tasks, and lower the expertise and coordination demands.

Designing such software crowdsourcing models will require solving several problems. These models must involve new workflows that orchestrate a variety of subtasks to complete more complex tasks. Workflows must address quality issues; match work to workers, taking into consideration their expertise; coordinate the many contributions; share project knowledge across the crowd, and deal with other issues. None of these endeavors is trivial.

Yet more fundamentally, it's likely no coincidence that many of the tasks for which crowdsourcing has found the most success-testing, creating UI mockups, and answering questions-have clear goals and require minimal context. A key tenet of crowdsourcing is that each participant must be precisely informed of the task to be performed. Understanding the degree to which decomposition can create such self-contained tasks for more interdependent software work, and the potential overhead this creates, is a key challenge. For example, can the authoring of a software architecture be decomposed into short, self-contained tasks that don't require contributors to understand the complexity of the whole?

Even if decomposition methods are found, specification will remain an issue. Can requirements be crowdsourced? If not, can they be specified in sufficient detail without onerous overhead? Researchers have begun to study these problems, determining how to create crowdsourcing work flows for a variety of development tasks6,14and examining the challenges involved in designing new workflows.10

Crowdsourcing in its various forms has already changed software development. Open source aside, the number of new crowdsourcing platforms, the number of workers signing up and actively contributing, and the number of organizations actively experimenting with crowdsourcing all indicate a phenomenon that in many ways has crept up on the industry rather than taking it by storm. The potential advantages are tangible. The increasing shift of development work to fluid labor markets-for example, more than$1 billion annually in freelancing is brokered through Upwork (www.upwork.com) alone-portends the potential for even more dramatic shifts.

Such shifts might well call into question long-held fundamental beliefs about software development. As in any fundamentally disruptive shift, the ultimate ramifications are far from certain. Will future developers operate as highly skilled freelancers, choosing microtasks to follow their passion and bolster their skill set?15 Or, will they be mindless automatons, their work selected without their interest or consent, as Neal Stephenson envisioned in Snow Crash ?16

Regardless, serious challenges must be overcome if crowdsourcing is to have the same kind of impact in software development that it has had in other fields. The nature of software has much to do with this. Software is complex and isn't easily broken down into clearly articulated, self-contained, and rapidly understood and completed tasks. Rather, its intricate and invisible nature poses a challenge to crowdsourcing that will take years to address. Even so, truly foundational shifts rarely take place in our field, and crowdsourcing has that potential. It's worthwhile for the community to develop a deep understanding of how and when to apply crowdsourcing in software projects.