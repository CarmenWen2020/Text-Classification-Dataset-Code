Mutation Testing is a fault-based software testing technique that has been widely studied for over three decades. The literature on Mutation Testing has contributed a set of approaches, tools, developments, and empirical results. This paper provides a comprehensive analysis and survey of Mutation Testing. The paper also presents the results of several development trend analyses. These analyses provide evidence that Mutation Testing techniques and tools are reaching a state of maturity and applicability, while the topic of Mutation Testing itself is the subject of increasing interest.
SECTION 1Introduction
Mutation Testing is a fault-based testing technique which provides a testing criterion called the “mutation adequacy score.” The mutation adequacy score can be used to measure the effectiveness of a test set in terms of its ability to detect faults.

The general principle underlying Mutation Testing work is that the faults used by Mutation Testing represent the mistakes that programmers often make. By carefully choosing the location and type of mutant, we can also simulate any test adequacy criteria. Such faults are deliberately seeded into the original program by simple syntactic changes to create a set of faulty programs called mutants, each containing a different syntactic change. To assess the quality of a given test set, these mutants are executed against the input test set. If the result of running a mutant is different from the result of running the original program for any test cases in the input test set, the seeded fault denoted by the mutant is detected. One outcome of the Mutation Testing process is the mutation score, which indicates the quality of the input test set. The mutation score is the ratio of the number of detected faults over the total number of the seeded faults.

The history of Mutation Testing can be traced back to 1971 in a student paper by Lipton [144]. The birth of the field can also be identified in papers published in the late 1970s by DeMillo et al. [66] and Hamlet [107].

Mutation Testing can be used for testing software at the unit level, the integration level, and the specification level. It has been applied to many programming languages as a white box unit test technique, for example, Fortran programs [3], [36], [40], [131], [145], [181], Ada programs [29], [192], C programs [6], [56], [97], [213], [214], [237], [239], Java programs [44], [45], [127], [128], [129], [130], [150], [151], C# programs [69], [70], [71], [72], [73], SQL code [43], [212], [233], [234], and AspectJ programs [12], [13], [17], [90]. Mutation Testing has also been used for integration testing [54], [55], [56], [58]. Besides using Mutation Testing at the software implementation level, it has also been applied at the design level to test the specifications or models of a program. For example, at the design level, Mutation Testing has been applied to Finite State Machines [20], [28], [88], [111], Statecharts [95], [231], [260], Estelle Specifications [222], [223], Petri Nets [86], Network protocols [124], [202], [216], [238], Security Policies [139], [154], [165], [166], [201], and Web Services [140], [142], [143], [193], [245], [259].

Mutation Testing has been increasingly and widely studied since it was first proposed in the 1970s. There has been much research work on the various kinds of techniques seeking to turn Mutation Testing into a practical testing approach. However, there is little survey work in the literature on Mutation Testing. The first survey work was conducted by DeMillo [62] in 1989. This work summarized the background and research achievements of Mutation Testing at this early stage of development of the field. A survey review of the (very specific) subarea of Strong, Weak, and Firm mutation techniques was presented by Woodward [253], [256]. An introductory chapter on Mutation Testing can be found in the book by Mathur [155] and also in the book by Ammann and Offutt [11]. The most recent survey work was conducted by Offutt and Untch [191] in 2000. They summarized the history of Mutation Testing and provide an overview of the existing optimization techniques for Mutation Testing. However, since then, there have been more than 230 new publications on Mutation Testing.

In order to provide a complete survey covering all the publications related to Mutation Testing since the 1970s, we constructed a Mutation Testing publication repository, which includes more than 390 papers from 1977 to 2009 [121]. We also searched for master's and PhD theses that have made a significant contribution to the development of Mutation Testing. These are listed in Table 1. We took four steps to build this repository. First, we searched the online repositories of the main technical publishers, including IEEE XPlore, ACM Portal, Springer Online Library, Wiley InterScience, and Elsevier Online Library, collecting papers which have either “mutation testing,” “mutation analysis,” “mutants + testing,” “mutation operator + testing,” “fault injection,” and “fault-based testing” keywords in their title or abstract. Then, we went through the references for each paper in our repository to find missing papers using the same keyword rules. In this way, we performed a “transitive closure” on the literature. Mutation Testing work which was not concerned with software, for example, hardware, was removed and we also filtered out papers not written in English. Finally, we sent a draft of this paper to all cited authors asking them to check our citations. We have made the repository publicly available at http://www.dcs.kcl.ac.uk/pg/jiayue/repository/ [121]. Overall growth trend of all papers in Mutation Testing can be found in Fig. 1.

TABLE 1 A List of PhD and Master's Work on Mutation Testing


Fig. 1. Mutation testing publications from 1978-2009 (* indicates years in which a mutation workshop was held).
Show All

The rest of the paper is organized as follows: Section 2 introduces the fundamental theory of Mutation Testing, including the hypotheses, the process, and the problems of Mutation Testing. Section 3 explains the techniques for the reduction of the computational cost. Section 4 introduces the techniques for detecting equivalent mutants. The applications of Mutation Testing are introduced in Section 5. Section 6 summarizes the empirical experiments of the research work on Mutation Testing. Section 7 describes the development work on mutation tools. Section 8 discusses the evidences for the increasing importance of Mutation Testing. Section 9 discusses the unresolved problems, barriers, and the areas of success in Mutation Testing. The paper concludes in Section 10.

SECTION 2The Theory of Mutation Testing
This section will first introduce the two fundamental hypotheses of Mutation Testing. It then discusses the general process of Mutation Testing and the problems from which it suffers.

2.1 Fundamental Hypotheses
Mutation Testing promises to be effective in identifying adequate test data which can be used to find real faults [96]. However, the number of such potential faults for a given program is enormous; it is impossible to generate mutants representing all of them. Therefore, traditional Mutation Testing targets only a subset of these faults, those which are close to the correct version of the program, with the hope that these will be sufficient to simulate all faults. This theory is based on two hypotheses: the Competent Programmer Hypothesis (CPH) [3], [66] and the Coupling Effect [66].

The CPH was first introduced by DeMillo et al. in 1978 [66]. It states that programmers are competent, which implies that they tend to develop programs close to the correct version. As a result, although there may be faults in the program delivered by a competent programmer, we assume that these faults are merely a few simple faults which can be corrected by a few small syntactical changes. Therefore, in Mutation Testing, only faults constructed from several simple syntactical changes are applied, which represent the faults that are made by “competent programmers.” An example of the CPH can be found in Acree et al.'s work [3]. A theoretical discussion using the concept of program neighborhoods can also be found in Budd et al.'s work [37].

The Coupling Effect was also proposed by DeMillo et al. in 1978 [66]. Unlike the CPH concerning a programmer's behavior, the Coupling Effect concerns the type of faults used in mutation analysis. It states that “Test data that distinguishes all programs differing from a correct one by only simple errors is so sensitive that it also implicitly distinguishes more complex errors.” Offutt [174], [175] extended this into the Coupling Effect Hypothesis and the Mutation Coupling Effect Hypothesis with a precise definition of simple and complex faults (errors). In his definition, a simple fault is represented by a simple mutant which is created by making a single syntactical change, while a complex fault is represented as a complex mutant which is created by making more than one change.

According to Offutt, the Coupling Effect Hypothesis is that “complex faults are coupled to simple faults in such a way that a test data set that detects all simple faults in a program will detect a high percentage of the complex faults” [175]. The Mutation Coupling Effect Hypothesis now becomes “Complex mutants are coupled to simple mutants in such a way that a test data set that detects all simple mutants in a program will also detect a large percentage of the complex mutants” [175]. As a result, the mutants used in traditional Mutation Testing are limited to simple mutants only.

There has been much research work on the validation of the coupling effect hypothesis [145], [164], [174], [175]. Lipton and Sayward [145] conducted an empirical study using a small program, find. In their experiment, a small sample of second order, third order, and fourth order mutants is investigated. The results suggested that an adequate test set generated from first order mutants was also adequate for the samples of kth order mutants (k=2,…,4). Offutt [174], [175] extended this experiment using all possible second order mutants with two more programs, mid and trityp. The results suggested that test data developed to kill first order mutants killed over 99 percent second order and third order mutants. This study implied that the mutation coupling effect hypothesis does indeed manifest itself in practice. Similar results were found in the empirical study by Morell [164].

The validity of the mutation coupling effect has also been considered in the theoretical studies of Wah [242], [243], [244] and Kapoor [125]. In Wah's work [243], [244], a simple theoretical model, the q function model, was proposed which considers a program to be a set of finite functions. Wah applied test sets to the first order and the second order model. Empirical results indicated that the average survival ratio of first order mutants and second order mutants is 1/n and 1/n2, respectively, where n is the order of the domain [243]. This result is also similar to the estimated results of the empirical studies mentioned above. A formal proof of the coupling effect on the boolean logic faults can be also found in Kapoor's work [125].

2.2 The Process of Mutation Analysis
The traditional process of mutation analysis is illustrated in Fig. 2. In mutation analysis, from a program p, a set of faulty programs p′, called mutants, is generated by a few single syntactic changes to the original program p. As an illustration, Table 2 shows the mutant p′, generated by changing the and operator (&&) of the original program p, into the or operator (∥), thereby producing the mutant p′.


Fig. 2. Generic process of mutation analysis [191].
Show All

TABLE 2 An Example of Mutation Operation

A transformation rule that generates a mutant from the original program is known as a mutation operator.1 Table 2 contains only one example of a mutation operator; there are many others. Typical mutation operators are designed to modify variables and expressions by replacement, insertion, or deletion operators. Table 3 lists the first set of formalized mutation operators for the Fortran programming language. These typical mutation operators were implemented in the Mothra mutation system [131].

TABLE 3 The First Set of Mutation Operators: The 22 “Mothra” Fortran Mutation Operators (Adapted from [131])

To increase the flexibility of Mutation Testing in practical applications, Jia and Harman introduced a scripting language, the Mutation Operator Constraint Script (MOCS) [123]. The MOCS provides two types of constraint: Direct Substitution Constraint and Environmental Condition Constraint. The Direct Substitution Constraint allows users to select a specific transformation rule that performs a simple change while the Environmental Condition Constraint is used to specify the domain for applying mutation operators. Simao et al. [217] also proposed a transformation language, mudel, used to specify the description of mutation operators. Besides modifying program source, mutation operators can also be defined as rules to modify the grammar used to capture the syntax of a software artifact. A much more detailed account of these grammar-based mutation operators can be found in the work of Offutt et al. [177].

In the next step, a test set T is supplied to the system. Before starting the mutation analysis, this test set needs to be successfully executed against the original program p to check its correctness for the test case. If p is incorrect, it has to be fixed before running other mutants; otherwise, each mutant p′ will then be run against this test set T. If the result of running p′ is different from the result of running p for any test case in T, then the mutant p′ is said to be “killed”; otherwise, it is said to have “survived.”

After all test cases have been executed, there may still be a few “surviving” mutants. To improve the test set T, the program tester can provide additional test inputs to kill these surviving mutants. However, there are some mutants that can never be killed because they always produce the same output as the original program. These mutants are called Equivalent Mutants. They are syntactically different but functionally equivalent to the original program. Automatically detecting all equivalent mutants is impossible [35], [187] because program equivalence is undecidable. The equivalent mutant problem has been a barrier that prevents Mutation Testing from being more widely used. Several proposed solutions to the equivalent mutant problem are discussed in Section 4.

Mutation Testing concludes with an adequacy score, known as the Mutation Score, which indicates the quality of the input test set. The mutation score (MS) is the ratio of the number of killed mutants over the total number of nonequivalent mutants. The goal of mutation analysis is to raise the mutation score to 1, indicating the test set T is sufficient to detect all the faults denoted by the mutants.

2.3 The Problems of Mutation Analysis
Although Mutation Testing is able to effectively assess the quality of a test set, it still suffers from a number of problems. One problem that prevents Mutation Testing from becoming a practical testing technique is the high computational cost of executing the enormous number of mutants against a test set. The other problems are related to the amount of human effort involved in using Mutation Testing, for example, the human oracle problem [247] and the equivalent mutant problem [35].

The human oracle problem refers to the process of checking the original program's output with each test case. Strictly speaking, this is not a problem unique to Mutation Testing. In all forms of testing, once a set of inputs has been arrived at, there remains the problem of checking output [247]. However, mutating testing is effective precisely because it is demanding and this can lead to an increase in the number of test cases, thereby increasing oracle cost. This oracle cost is often the most expensive part of the overall test activity. Also, because of the undecidability of mutant equivalence, the detection of equivalent mutants typically involves additional human effort.

Although it is impossible to completely solve these problems, with existing advances in Mutation Testing the process of Mutation Testing can be automated and the runtime can allow for reasonable scalability, as this survey will show. A lot of previous work has focused on techniques to reduce computational cost, a topic to which we now turn.

SECTION 3Cost Reduction Techniques
Mutation Testing is widely believed to be a computationally expensive testing technique. However, this belief is partly based on the outdated assumption that all mutants in the traditional Mothra set need to be considered. In order to turn Mutation Testing into a practical testing technique, many cost reduction techniques have been proposed. In the survey work of Offutt and Untch [191], cost reduction techniques are divided into three types: “do fewer,” “do faster,” and “do smarter.” In this paper, these techniques are classified into two types, reduction of the generated mutants (which corresponds to “do fewer”) and reduction of the execution cost (which combines do faster and do smarter). Fig. 3 provides an overview of the chronological development of published ideas for cost reduction.


Fig. 3. Overview of the chronological development of mutant reduction techniques.
Show All

To take a closer look at the cost reduction research work, we counted the number of publications for each technique (see Fig. 4). From this figure, it is clear that Selective Mutation and Weak Mutation are the most widely studied cost reduction techniques. Each of the other techniques is studied in no more than five papers to date. The rest of the section will introduce each cost reduction technique in detail. Section 3.1 will present work on mutant reduction techniques, while Section 3.2 will cover execution reduction techniques.


Fig. 4. Percentage of publications using each mutant reduction technique.
Show All

3.1 Mutant Reduction Techniques
One of the major sources of computational cost in Mutation Testing is the inherent running cost in executing the large number of mutants against the test set. As a result, reducing the number of generated mutants without significant loss of test effectiveness has become a popular research problem. For a given set of mutants M and a set of test data T, MST(M) denotes the mutation score of the test set T applied to mutants M. The mutant reduction problem can be defined as the problem of finding a subset of mutants M′ from M, where MST(M′)≈MST(M). This section will introduce four techniques used to reduce the number of mutants: Mutant Sampling, Mutant Clustering, Selective Mutation, and Higher Order Mutation.

3.1.1 Mutant Sampling
Mutant Sampling is a simple approach that randomly chooses a small subset of mutants from the entire set. This idea was first proposed by Acree [2] and Budd [34]. In this approach, all possible mutants are generated first as in traditional Mutation Testing. x percent of these mutants are then selected randomly for mutation analysis and the remaining mutants are discarded. There were many empirical studies of this approach. The primary focus was on the choice of the random selection rate (x). In Wong and Mathur's studies [159], [248], the authors conducted an experiment using a random selection rate x percent from 10 to 40 percent in steps of 5 percent. The results suggested that random selection of 10 percent of mutants is only 16 percent less effective than a full set of mutants in terms of mutation score. This study implied that Mutant Sampling is valid with a x percent value higher than 10 percent. This finding also agreed with the empirical studies by DeMillo et al. [64] and King and Offutt [131]. Instead of fixing the sample rate, Sahinoglu and Spafford [207] proposed an alternative sampling approach based on the Bayesian sequential probability ratio test (SPRT). In their approach, the mutants are randomly selected until a statistically appropriate sample size has been reached. The result suggested that their model is more sensitive than the random selection because it is self-adjusting based on the available test set.

3.1.2 Mutant Clustering
The idea of Mutant Clustering was first proposed in Hussain's master's thesis [116]. Instead of selecting mutants randomly, Mutant Clustering chooses a subset of mutants using clustering algorithms. The process of Mutation Clustering starts from generating all first order mutants. A clustering algorithm is then applied to classify the first order mutants into different clusters based on the killable test cases. Each mutant in the same cluster is guaranteed to be killed by a similar set of test cases. Only a small number of mutants are selected from each cluster to be used in Mutation Testing; the remaining mutants are discarded. In Hussain's experiment, two clustering algorithms, K-means and Agglomerative clustering, were applied and the result was compared with random and greedy selection strategies. Empirical results suggest that Mutant Clustering is able to select fewer mutants but still maintain the mutation score. A development of the Mutant Clustering approach can be found in the work of Ji et al. [120]. Ji et al. use a domain reduction technique to avoid the need to execute all mutants.

3.1.3 Selective Mutation
A reduction in the number of mutants can also be achieved by reducing the number of mutation operators applied. This is the basic idea, underpinning Selective Mutation, which seeks to find a small set of mutation operators that generate a subset of all possible mutants without significant loss of test effectiveness. This idea was first suggested as “constrained mutation” by Mathur [156]. Offutt et al. [190] subsequently extended this idea, calling it Selective Mutation.

Mutation operators generate different numbers of mutants and some mutation operators generate far more mutants than others, many of which may turn out to be redundant. For example, two mutation operators of the 22 Mothra operators, ASR and SVR, were reported to generate approximately 30 to 40 percent of all mutants [131]. To effectively reduce the generated mutants, Mathur [156] suggested omitting two mutation operators ASR and SVR which generated most of the mutants. This idea was implemented as “2-selective mutation” by Offutt et al. [190].

Offutt et al. [190] have also extended Mathur and Wong's work by omitting four mutation operators (4-selective mutation) and omitting six mutation operators (6-selective mutation). In their studies, they reported that 2-selective mutation achieved a mean mutation score of 99.99 percent with a 24 percent reduction in the number of mutants reduced. 4-selective mutation achieved a mean mutation score of 99.84 percent with a 41 percent reduction in the number of mutants. 6-selective mutation achieved a mean mutation score of 88.71 percent with a 60 percent reduction in the number of mutants.

Wong and Mathur adopted another type of selection strategy, selection based on test effectiveness [248], [252], known as constraint mutation. Wong and Mathur suggested using only two mutation operators: ABS and RAR. The motivation for the ABS operator is that killing the mutants generated from ABS requires test cases from different parts of the input domain. The motivation for the ROR operator is that killing the mutants generated from ROR requires test cases which “examine” the mutated predicate [248], [252]. Empirical results suggest that these two mutation operators achieve an 80 percent reduction in the number of mutants and only 5 percent reduction in the mutation score in practice.

Offutt et al. [182] extended their six-selective mutation further using a similar selection strategy. Based on the type of the Mothra mutation operators, they divided them into three categories: statements, operands, and expressions. They tried to omit operators from each class in turn. They discovered that five operators from the operands and expressions class became the key operators. These five operators are ABS, UOI, LCR, AOR, and ROR. These key operators achieved 99.5 percent mutation score.

Mresa and Bottaci [167] proposed a different type of selective mutation. Instead of trying to achieve a small loss of test effectiveness, they also took the cost of detecting equivalent mutants into consideration. In their work, each mutation operator is assigned a score which is computed by its value and cost. Their results indicated that it was possible to reduce the number of equivalent mutants while maintaining effectiveness.

Based on previous experience, Barbosa et al. [19] defined a guideline for selecting a sufficient set of mutation operators from all possible mutation operators. They applied this guideline to Proteum's 77 C mutation operators [6] and obtained a set of 10 selected mutation operators, which achieved a mean mutation score of 99.6 percent with a 65.02 percent reduction in the number of mutants. They also compared their operators with Wong's and Offutt et al.'s set. The results showed their operator set achieved the highest mutation score.

The most recent research work on selective mutation was conducted by Namin and Andrews [168], [169], [170]. They formulated the selective mutation problem as a statistical problem: the variable selection or reduction problem. They applied linear statistical approaches to identify a subset of 28 mutation operators from 108 C mutation operators. The results suggested that these 28 operators are sufficient to predict the effectiveness of a test suite and it reduced 92 percent of all generated mutants. According to their results, this approach achieved the highest rate of reduction compared with other approaches.

3.1.4 Higher Order Mutation
Higher Order Mutation is a comparatively new form of Mutation Testing introduced by Jia and Harman [122]. The underlying motivation was to find those rare but valuable higher order mutants that denote subtle faults. In traditional Mutation Testing, mutants can be classified into first order mutants (FOMs) and higher order mutants (HOMs). FOMs are created by applying a mutation operator only once. HOMs are generated by applying mutation operators more than once.

In their work, Jia and Harman introduced the concept of subsuming HOMs. A subsuming HOM is harder to kill than the FOMs from which it is constructed. As a result, it may be preferable to replace FOMs with the single HOM to reduce the number of the mutants. In particular, they also introduced the concept of a strongly subsuming HOM (SSHOM) which is only killed by a subset of the intersection of test cases that kill each FOM from which it is constructed.

This idea has been partly proved by Polo et al.'s work [199]. In their experiment, they focused on a specific order of HOMs, the second order mutants. They proposed different algorithms to combine first order mutants to generate the second order ones. Empirical results suggest that applying second order mutants reduced test effort by approximately 50 percent, without much loss of test effectiveness. More recently, Langdon et al. have applied multi-object genetic programming to the generation of higher order mutants [136], [137]. In their experiment, they have found realistic higher order mutants that are harder to kill than any first order mutant.

3.2 Execution Cost Reduction Techniques
In addition to reducing the number of generated mutants, the computational cost can also be reduced by optimizing the mutant execution process. This section will introduce the three types of techniques used to optimize the execution process that have been considered in the literature.

3.2.1 Strong, Weak, and Firm Mutation
Based on the way in which we decide whether to analyze if a mutant is killed during the execution process, Mutation Testing techniques can be classified into three types: Strong Mutation, Weak Mutation, and Firm Mutation.

Strong Mutation is often referred to as traditional Mutation Testing. That is, it is the formulation originally proposed by DeMillo et al. [66]. In Strong Mutation, for a given program p, a mutant m of program p is said to be killed only if mutant m gives a different output from the original program p.

To optimize the execution of the Strong Mutation, Howden [115] proposed Weak Mutation. In Weak Mutation, a program p is assumed to be constructed from a set of components C={c1,…,cn}. Suppose mutant m is made by changing component cm; mutant m is said to be killed if any execution of component cm is different from mutant m. As a result, in Weak Mutation, instead of checking mutants after the execution of the entire program, the mutants need only to be checked immediately after the execution point of the mutant or mutated component.

In Howden's work [115], the component C referred to one of the following five types: variable reference, variable assignment, arithmetic expression, relational expression, and boolean expression. This definition of components was later refined by Offutt and Lee [183], [184]. Offutt and Lee defined four types of execution: evaluation after the first execution of an expression (Ex-Weak/1), the first execution of a statement (St-Weak/1), the first execution of a basic block (BB-Weak/1), and after N iterations of a basic block in a loop (BB-Weak/N).

The advantage of weak mutation is that each mutant does not require a complete execution process; once the mutated component is executed we can check for survival. Moreover, it might not even be necessary to generate each mutant, as the constraints for the test data can sometimes be determined in advance [253]. However, as different components of the original program may give different outputs from the original execution, weak mutation test sets can be less effective than strong mutation test sets. In this way, weak mutation sacrifices test effectiveness for improvements in test effort. This raises the question as to what kind of trade-off can be achieved.

There were many empirical studies on the Weak Mutation trade-off. Girgis and Woodward [103] implemented a weak mutation system for Fortran 77 programs. Their system is an analytical type of weak mutation system in which the mutants are killed by examining the program's internal state. In their experiment, four of Howden's five program components were considered. The results suggested that weak mutation is less computationally expensive than strong mutation. Marick [153] drew similar conclusions from his experiments.

A theoretical proof of Weak Mutation by Horgan and Mathur [113] showed that under certain conditions, test sets generated by weak mutation can also be expected to be as effective as strong mutation. Offutt and Lee [183], [184] presented a comprehensive empirical study using a weak mutation system named Leonardo. In their experiment, they used the 22 Mothra mutation operators as fault models instead of Howden's five component set. The results from their experiments indicated that Weak Mutation is an alternative to Strong Mutation in most common cases, agreeing with the probabilistic results of Horgan and Mathur [113] and experimental results of Girgis and Woodward [103] and Marick [153].

Firm Mutation was first proposed by Woodward and Halewood [257]. The idea of Firm Mutation is to overcome the disadvantages of both weak and strong mutations by providing a continuum of intermediate possibilities. That is, the “compare state” of Firm Mutation lies between the intermediate states after execution (Weak Mutation) and the final output (Strong Mutation). In 2001, Jackson and Woodward [119] proposed a parallel Firm Mutation approach for Java programs. Unfortunately, to date there is no publicly available firm mutation tool.

3.2.2 Runtime Optimization Techniques
The Interpreter-Based Technique is one of the optimization techniques used in the first generation of Mutation Testing tools [131], [181]. In traditional Interpreter-Based Techniques, the result of a mutant is interpreted from its source code directly. The main cost of this technique is determined by the cost of interpretation. To optimize the traditional Interpreter-Based approach, Offutt and King [131], [181] translated the original program into an intermediate form. Mutation and interpretation are performed at this intermediate code level. Interpreter-Based tools provide additional flexibility and are sufficiently efficient for mutating small programs. However, due to the nature of interpretation, it becomes slower as the scale of programs under test increases.

The Compiler-Based Technique is the most common approach to achieve program mutation [52], [53]. In a Compiler-Based Technique, each mutant is first compiled into an executable program; the compiled mutant is then executed by a number of test cases. Compared to source code interpretation techniques, this approach is much faster because execution of compiled binary code takes less time than interpretation. However, there is also a speed limitation, known as compilation bottleneck, due to the high compilation cost for programs whose runtime is much longer than the compilation/link time. [47].

DeMillo et al. proposed the Compiler-Integrated Technique [65] to optimize the performance of the traditional Compiler-Based Techniques. Because there is only a minor syntactic difference between each mutant and the original program, compiling each mutant separately in the Compiler-Based technique will result in redundant compilation cost. In the Compiler-Integrated technique, an instrumented compiler is designed to generate and compile mutants.

The instrumented compiler generates two outputs from the original program: an executable object code for the original program and a set of patches for mutants. Each patch contains instructions which can be applied to convert the original executable object code image directly to executable code for a mutant. As a result, this technique can effectively reduce the redundant cost from individual compilation. A much more detailed account can be found in the Krauser's PhD thesis [132].

The Mutant Schema Generation approach is also designed to reduce the overhead cost of the traditional interpreter-based techniques [235], [236], [237]. Instead of compiling each mutant separately, the mutant schema technique generates a metaprogram. Just like a “supermutant,” this metaprogram can be used to represent all possible mutants. Therefore, to run each mutant against the test set, only this metaprogram need be compiled. The cost of this technique is composed of a one-time compilation cost and the overall runtime cost. As this metaprogram is a compiled program, its running speed is faster than the interpreter-based technique. The results from Untch et al.'s work [237] suggest that the mutant schema prototype tool, TUMS, is significantly faster than Mothra using interpreter techniques. Much more extensive results are reported in detail in Untch's PhD dissertation [236]. A similar idea of the Mutant Schemata technique, named the Mutant Container, was proposed by Mathur independently. The details can be found in a software engineering course “handout” by Mathur [157].

The most recent work on reduction of the compilation cost is the Bytecode Translation Technique. This technique was first proposed by Ma et al. [151], [185]. In Bytecode Translation, mutants are generated from the compiled object code of the original program, instead of the source code. As a result, the generated “bytecode mutants” can be executed directly without compilation. As well as saving compilation cost, Bytecode Translation can also handle off-the-shelf programs which do not have available source code. This technique has been adopted in the Java programming language [151], [152], [185], [208]. However, not all programming languages provide an easy way to manipulate intermediate object code. There are also some limitations for the application of Bytecode Translation in Java, such as not all of the mutation operators can be represented at the Bytecode level [208].

Bogacki and Walter introduced an alternative approach to reduce compilation cost, called Aspect-Oriented Mutation [26], [27]. In their approach, an aspect patch is generated to capture the output of a method on the fly. Each aspect patch will run programs twice. The first execution obtains the results and context of the original program and mutants are generated and executed in the second execution. As a result, there is no need to compile each mutant. Empirical evaluation between a prototype tool and Jester can be found in the work of Bogacki and Walter [26].

3.2.3 Advanced Platforms Support for Mutation Testing
Mutation Testing has also been applied to many advanced computer architectures to distribute the overall computational cost among many processors. In 1988, Mathur and Krauser [158] were the first to perform Mutation Testing on a vector processor system. Krauser et al. [133], [134] proposed an approach for concurrent execution mutants under SIMD machines. Fleyshgakker and Weiss [92], [246] proposed an algorithm that significantly improved techniques for parallel Mutation Testing. Choi and Mathur [47] and Offutt et al. [189] have distributed the execution cost of Mutation Testing through MIMD machines. Zapf [261] extended this idea in a network environment, where each mutant is executed independently.

SECTION 4Equivalent Mutant Detection Techniques
To detect if a program and one of its mutants programs are equivalent is undecidable, as proved in the work of Budd and Angluin [35]. As a result, the detection of equivalent mutants alternatively may have to be carried out by humans. This has been a source of much theoretical interest. For a given program p, m denotes a mutant of program p. Recall that m is an equivalent mutant if m is syntactically different from p, but has the same behavior as p. Table 4 shows an example of equivalent mutant generated by changing the operator < of the original program into the operator !=. If the statements within the loop do not change the value of i, program p and mutant m will produce identical output.

TABLE 4 An Example of Equivalent Mutation

An equivalent mutant is created when a mutation leads to no possible observable change in behavior; the mutant is syntactically different but semantically identical to the original program from which it is created. Grün et al. [106] manually investigated eight equivalent mutants generated from the JAXEN XPATH query engine program. They pointed out four common equivalent mutant situations: The mutant is generated from dead code, the mutant improves speed, the mutant only alters the internal states and the mutant cannot be triggered (i.e., no input test data can change the program's behavior at the mutation point). It is worth noticing that these four are not the only situations that lead to equivalent mutants. For example, none of it applies to the example in Table 4.

As the mutation score is counted based on nonequivalent mutants without a complete detection of all equivalent mutants, the mutant score can never be 100 percent, which means the programmer will not have complete confidence in the adequacy of a potentially perfectly adequate test set. Empirical results indicate that there are 10 to 40 percent of mutants which are equivalent [178], [187]. Fortunately, there has been much research work on the detection of the equivalent mutants.

Baldwin and Sayward [18] proposed an approach that used compiler optimization techniques to detect equivalent mutants. This approach is based on the idea that the optimization procedure of source code will produce an equivalent program, so a mutant might be detected as equivalent mutants by either “optimization” or a “deoptimization process.” Baldwin and Sayward [18] proposed six types of compiler optimization rules that can be used for the detection of equivalent mutants. These six were implemented and empirically studied by Offutt and Craft [178]. The empirical results showed that, generally, 10 percent of all mutants were equivalent mutants for 15 subject programs.

Based on the work of constraint test data generation, Offutt and Pan [186], [187], [197] introduced a new equivalent mutant detection approach using constraint solving. In their approach, the equivalent mutant problem is formulated as a constraint satisfaction problem by analyzing the path condition of a mutant. A mutant is equivalent if and only if the input constraint is unsatisfiable. Empirical evaluation of a prototype has shown that this technique is able to detect a significant percentage of equivalent mutants (47.63 percent among 11 subject programs) for most of the programs. Their results suggest that the constraint satisfaction formulation is more powerful than the compiler optimization technique [178].

The program slicing technique has also been proposed to assist in the detection of equivalent mutants [109], [110], [241]. Voas and McGraw [241] were the first to suggest the application of program slicing to Mutation Testing. Hierons et al. [110] demonstrated an approach using slicing to assist the human analysis of equivalent mutants. This is achieved by the generation of a sliced program that denotes the answer to an equivalent mutant. This work was later extended by Harman et al. [109] using dependence analysis.

Adamopoulos et al. [5] proposed a co-evolutionary approach to detect possible equivalent mutants. In their work, a fitness function was designed to set a poor fitness value to an equivalent mutant. Using this fitness function, equivalent mutants are wiped out during the coevolution process and only mutants that are hard to kill and test cases that are good at detecting mutants are selected.

Ellims et al. [83] reported that mutants with syntactic difference and the same output can be also semantically different in terms of running profile. These mutants often have the same output as the original programs but have different execution time or memory usage. Ellims et al. suggested that “resource-aware” might be used to kill the potential mutants.

The most recent work on the equivalent mutants was conducted by Grün et al. [106], who investigated the impact of mutants. The impact of a mutant was defined as the different program behavior between the original program and the mutant and it was measured through the code coverage in their experiment. The empirical results suggested that there was a strong correlation between mutant “killability” and its impact on execution, which indicates that if a mutant has higher impact, it is less likely to be equivalent.

SECTION 5The Application of Mutation Testing
Since Mutation Testing was proposed in the 1970s, it has been applied to test both program source code (Program Mutation) [60] and program specification (Specification Mutation) [105]. Program Mutation belongs to the category of white-box-based testing, in which faults are seeded into source code, while Specification Mutation belongs to black-box-based testing, where faults are seeded into program specifications, but in which the source code may be unavailable during testing.

Fig. 5 shows the chronological development of research work on Program Mutation and Specification Mutation. Fig. 6 shows the percentage of the publications addressing each language to which Mutation Testing has been applied. As Fig. 5 shows, there has been more work on Program Mutation than Specification Mutation. Notably more than 50 percent of the work has been applied to Java, Fortran, and C. Fortran features highly because a lot of the earlier work on Mutation Testing was carried out on Fortran programs. In the following section, the applications of Program Mutation and Specification Mutation are summarized by the programming language targeted.


Fig. 5. Publications of the applications of mutation testing.
Show All


Fig. 6. Percentage of publications addressing each language to which Mutation Testing has been applied.
Show All

5.1 Program Mutation
Program Mutation has been applied to both the unit level [66] and the integration level [55] of testing. For unit-level Program Mutation, mutants are generated to represent the faults that programmers might have made within a software unit, while for the integration-level Program Mutation, mutants are designed to represent the integration faults caused by the connection or interaction between software units [240]. Applying Program Mutation at the integration level is also known as Interface Mutation, which was first introduced by Delamaro et al. [55] in 1996. Interface Mutation has been applied to C programs by Delamaro and Maldonado [54], Delamaro et al. [55], [56] and also to CORBA programs by Ghosh [98], Ghosh et al. [100], Ghosh and Mathur [101], [102]. Empirical evaluations of Interface Mutation can be found in Vincenzei et al.'s work [240] and Delamaro et al.'s work [57], [58].

5.1.1 Mutation Testing for Fortran
In the earliest days of Mutation Testing, most of the experiments on Mutation Testing targeted Fortran. Budd et al. [36], [40] were the first to design mutation operators for Fortran IV in 1977. Based on these studies, a Mutation Testing tool named PIMS was developed for testing Fortran IV programs [3], [36], [145]. However, there were no formal definitions of mutation operators for Fortran until 1987. In 1987, Offutt and King [131], [181] summarized the results from previous work and proposed 22 mutation operators for Fortran 77. This set of mutation operators became the first set of formalized mutation operators and consequently had greater influence on later definitions of mutation operators for applying Mutation Testing to the other programming languages. These mutation operators are divided into three groups; the Statement analysis group, the Predicate analysis group, and the Coincidental correctness group.

5.1.2 Mutation Testing for Ada
Ada mutation operators were first proposed by Bowser [29] in 1988. In 1997, based on previous work of Bowser's Ada mutation operators [29], Agrawal et al.'s C mutation operators [6], and the design of Fortran 77 mutation operators for mothra [131], Offutt et al. [192] redesigned mutation operators for Ada programs to produce a proposed set of 65 Ada mutation operators. According to the semantics of Ada, this set of Ada mutation operators is divided into five groups: the Operand Replacement Operators group, Statement Operators group, Expression Operators group, Coverage Operators group, and Tasking Operators group.

5.1.3 Mutation Testing for C
In 1989, Agrawal et al. [6] proposed a comprehensive set of mutation operators for the ANSI C programming language. There were 77 mutation operators defined in this set, which was designed to follow the C language specification. These operators are classified into variable mutation, operator mutation, constant mutation, and statement mutation. Delamaro and Maldonado [54], Delamaro et al. [55], [56], [58] investigated the application of Mutation Testing at the integration level. They selected 10 mutation operators from Agrawal et al.'s 77 mutation operators to test interfaces of C programs. These mutation operators focus on injecting faults into the signature of public functions. More recently, Higher Order Mutation Testing has also been applied to C programs by Jia and Harman [122].

There are also mutation operators that target specific C program defects or vulnerabilities. Shahriar and Zulkernine [214] proposed 8 mutation operators to generate mutants that represent Format String Bugs (FSBs). Vilela et al. [239] proposed 2 mutation operators representing faults associated with static and dynamic memory allocations, which were used to detect Buffer Overflows (BOFs). This work was subsequently extended by Shahriar and Zulkernine [213], who proposed 12 comprehensive mutation operators to support the testing of all BOF vulnerabilities, targeting vulnerable library functions, program statements, and buffer size. Ghosh et al. [97] have applied Mutation Testing to an Adaptive Vulnerability Analysis (AVA) to detect BOFs.

5.1.4 Mutation Testing for Java
Traditional mutation operators are not sufficient for testing Object-Oriented (OO) programming languages like Java [130], [151]. This is mainly because the faults represented by the traditional mutation operators are different to those in the OO environment due to OO's different programming structure. Moreover, there are new faults introduced by OO-specific features, such as inheritance and polymorphism.

As a result, the design of Java mutation operators was not strongly influenced by previous work. Kim et al. [128] were the first to design mutation operators for the Java programming language. They proposed 20 mutation operators for Java using Hazard and Operability Studies (HAZOP). HAZOP is a safety technique which investigates and records the result of system deviations. In Kim et al.'s work, HAZOP was applied to the Java syntax definition to identify the plausible faults of the Java programming language. Based on these plausible faults, 20 Java mutation operators were designed, falling into six groups: Types/Variables, Names, Classes/interface declarations, Blocks, Expressions, and others.

Based on their previous work on Java mutation operators, Kim et al. [127] introduced Class Mutation, which applies mutation to OO (Java) programs targeting faults related to OO-specific features. In Class Mutation, 3 mutation operators representing Java OO-features were selected from the 20 Java mutation operators. In 2000, Kim et al. [129] added another 10 mutation operators for Class Mutation. Finally, in 2001, the number of the Class mutation operators was extended to 15 and these mutation operators were classified into four types: polymorphic types, method overloading types, information hiding, and exception handling types [130]. A similar approach was also adopted by Chevalley and Thevenod-Fosse in their work [44], [45].

Ma et al. [150], [151] pointed out that the design of mutation operators should not start with the selected approach (Kim et al.'s approach [127]). They suggested that the selected mutation operators should be obtained from empirical results of the effectiveness of all mutation operators. Therefore, instead of continuing Kim et al.'s work [129], Ma et al. [150] proposed 24 comprehensive Java mutation operators based on previous studies of OO Fault models. These are classified into six groups: the Information Hiding group, Inheritance group, Polymorphism group, Overloading group, Java Specific Features group, and Common Programming Mistakes group. Ma et al. conducted an experiment to evaluate the usefulness of the proposed class mutation operators [149]. The results suggested that some class mutation model faults can be detected by traditional Mutation Testing. However, the mutants generated by the EOA class mutation (Reference assignment and content assignment replacement) and the EOC class mutation (reference comparison and content comparison replacement) cannot be killed by a traditional mutation adequate test set.

There are also alternative approaches to the definition of the mutation operators for Java. For example, instead of applying mutation operators to the program source, Alexander et al. [9], [24] designed a set of mutation operators to inject faults into Java utility libraries, such as the Java container library and the iterator library. Based on work on traditional mutation operators, Bradbury et al. [31] introduced an extension to the concurrent Java environment.

5.1.5 Mutation Testing for C#
Based on previous proposed Java mutation operators, Derezińska introduced an extension to a set of C# specialized mutation operators [70], [71] and implemented them in a C# mutation tool named CREAM [72]. Empirical results for this set of C# mutation operators using CREAM were reported by Derezińska [71], [73].

5.1.6 Mutation Testing for SQL
Mutation Testing has also been applied to SQL code to detect faults in database applications. The first attempt to design mutation operators for SQL was done by Chan et al. [43] in 2005. They proposed 7 SQL mutation operators based on the enhanced entity-relationship model. Tuya et al. [234] proposed another set of mutant operators for SQL query statements. This set of mutation operators is organized into four categories, including mutation of SQL clauses, mutation of operators in conditions and expressions, mutation handling NULL values, and mutation of identifiers. They also developed a tool named SQLMutation that implements this set of SQL mutation operators and an empirical evaluation concerning results using SQLMutation [233]. A development of this work targeting Java database applications can be found in the work of Zhou and Frankl [264]. Shahriar and Zulkernine [212] have also proposed a set of mutation operators to handle the full set of SQL statements from connection to manipulation of the database. They introduced 9 mutation operators and implemented them in an SQL mutation tool called MUSIC.

5.1.7 Mutation Testing for Aspect-Oriented Programming
Aspect-Oriented Programming (AOP) is a programming paradigm that aids programmers in separation of crosscutting concerns. Ferrari et al. [90] proposed 26 mutation operators based on a generalization of faults for general Aspect-Oriented programs. These mutation operators are divided into three groups: pointcut expressions, aspect declarations, and advice definitions and implementation. Empirical results from evaluation of this work using real-world applications can also be found in their work [90]. A recent work from Delamare et al. introduced an approach to detect equivalent mutants in AOP programs using static analysis of aspects and base code [51].

AspectJ is a widely studied aspect-oriented extension of the Java language, which provides many special constructs such as aspects, advice, join points, and pointcuts [13]. Baekken and Alexander [17] summarized previous research work on the fault model associated with AspectJ pointcuts. They proposed a complete AspectJ fault model based on the incorrect pointcut pattern, which was used as a set of mutation operators for AspectJ programs. Based on this work, Anbalagan and Xie [12], [13] proposed a framework to generate mutants for pointcuts and to detect equivalent mutants. To reduce the total number of mutants, a classification and ranking approach based on the strength of the pointcuts was also introduced in their framework.

5.1.8 Other Program Mutation Applications
Besides these programming languages, Mutation Testing has also been applied to Lustre programs [80], [81], PHP programs [215], Cobol programs [108], Matlab/Simulink [262], and spreadsheets [1]. There is also research work investigating the design of mutation operators for real-time systems [96], [171], [172], [227] and concurrent programs [8], [31], [41], [99], [147].

5.2 Specification Mutation
Although Mutation Testing was originally proposed as a white box testing technique at the implementation level, it has also been applied at the software design level. Mutation Testing at design level is often referred to as “Specification Mutation,” which was first introduced by Gopal and Budd in 1983 [38], [105]. In Specification Mutation, faults are typically seeded into a state machine or logic expressions to generate “specification mutants.” A specification mutant is said to be killed if its output condition is falsified. Specification Mutation can be used to find faults related to missing functions in the implementation or specification misinterpretation [195].

5.2.1 Mutation Testing for Formal Specifications
The formal specifications can be presented in many forms, for example, calculus expressions, Finite State Machines (FSMs), Petri Nets, and Statecharts. The earlier research work on Specification Mutation considered specifications of simple logical expressions. Gopal and Budd [38], [105] considered specifications in predicate calculus targeting the predicate structure of the program under test. A similar work applied to the refinement calculus specification can be found in the work of Aichernig [7]. Woodward [254], [257] investigated mutation operators for algebraic specifications. In their experiment, they applied an optimization approach to compile a specification mutant into executable code and evaluated the approach to provide empirical results [255].

More recently, many formal techniques have been proposed to specify the dynamic aspects of a software system, for example, FSMs, Petri Nets, and Statecharts. Fabbri et al. [88] applied Specification Mutation to validate specifications presented as FSMs. They proposed 9 mutation operators, representing faults related to the states, events, and outputs of an FSM. This set of mutation operators was later implemented as an extension of the C mutation tool Proteum [85]. An empirical evaluation of these mutation operators was reported by them [85]. Hierons and Merayo [111], [112] investigated the application of Mutation Testing to Probabilistic Finite State Machines (PFSMs). They defined 7 mutation operators and provided an approach to avoid equivalent mutants. Other work on EFSM mutation can also be found in the work of Batth et al. [20], Bombieri et al. [28] and Belli et al. [23].

Statecharts are widely used for the formal specification of complex reactive systems. Statecharts can be considered as an extension of FSMs, so the first set of mutation operators for Statecharts was also proposed by Fabbri et al. [87], based on their previous work on FSM mutation operators. Using Fabbri et al.'s Statecharts mutation operators, Yoon et al. [260] introduced a new test criterion, the State-based Mutation Test Criterion (SMTC). In the work of Trakhtenbrot [231], the author proposed new mutations to assess the quality of tests for statecharts at the implementation level as well as the model level. Other work on Statechart mutation can be found in the work of Fraser and Wotawa [95].

Besides FSMs and Statecharts, Specification Mutation has been also applied to a variety of specification languages. For example, Souza et al. [222], [223] investigated the application of Mutation Testing to the Estelle Specification language. Fabbri et al. [86] proposed mutation operators for Petri Nets. Srivatanakul et al. [225] performed an empirical study using Specification Mutation to CSP Specifications. Olsson and Runeson [196] and Sugeta et al. [226] proposed mutation operators for SDL. Definitions of mutation operators for formal specification language can be found in the work of Black et al. [25] and the work of Okun [195].

5.2.2 Mutation Testing for Running Environment
During the process of implementing specifications, bugs might be introduced by programmers due to insufficient knowledge of the final target environment. These bugs are called “environment bugs” and they can be hard to detect. Examples are the bugs caused by memory limitations, numeric limitations, value initialization, constant value interpretation, exception handling, and system errors [224]. Mutation Testing was first applied to the detection of such bugs by Spafford [224] in 1990. In his work, environment mutants were generated to detect integer arithmetic environmental bugs.

The idea of environment bugs was extended in the 1990s by Du and Mathur, as many empirical studies suggested that “the environment plays a significant role in triggering security flaws that lead to security violations” [78]. As a result, Mutation Testing was also applied to the validation of security vulnerabilities. Du and Mathur [78] defined an EAI fault mode for software vulnerability, and this model was applied to generate environmental mutants. Empirical results from the evaluation of their experiments are reported in [79].

5.2.3 Mutation Testing for Web Services
Lee and Offutt [142] were the first to apply Mutation Testing to Web Services. In 2001, they introduced an Interaction Specification Model to formalize the interactions between web components [142]. Based on this specification model, a set of generic mutation operators was proposed to mutate the XML data model. This work was later extended by Offutt and Xu [193] and Xu et al. [259] targeting the mutation of XML data and they renamed it XML perturbation. Instead of mutating XML data directly, they perturbed XML schemas to create invalid XML data using seven XML schema mutation operators. A constraint-based test case generation approach was also proposed and the results of empirical studies were reported [259]. Another set of XML schema mutation operators was proposed by Li and Miller [143].

There is also Web Service mutation work targeting specific XML-based language features, for example, the OWL-S specification language [140], [245] and WS-BPEL specification language [84]. Unlike the traditional XML specification language, OWL-S introduces semantics to workflow specification using an ontology specification language. In the work of Lee et al. [140], the authors propose mutation operators for detection of semantic errors caused by the misuse of the ontology classes.

5.2.4 Mutation Testing for Networks
Protocol robustness is an important aspect of any network system. Sidhu and Leung [216] investigated fault coverage of network protocols. Based on this work, Probert and Guo proposed a set of mutation operators to test network protocols [202]. Vigna et al. [238] applied Mutation Testing to network-based intrusion detection signatures, which are used to identify malicious traffic. Jing et al. [124] built an NFSM model for protocol messages and applied Mutation Testing to this model using the TTCN-3 specification language. Other work on the application of Mutation Testing to State-based protocols can be found in the work of Zhang et al. [263].

5.2.5 Mutation Testing for Security Policy
Mutation Testing has also been applied to security policies [139], [154], [165], [166], [201]. Much of this research work sought to design mutation operators that inject common flaws into different types of security policies. For example, Martin and Xie [154] applied mutation analysis to test XACML, an Oasis standard XML syntax for defining security policies. A similar approach has also been applied by Mouelhi et al. [166]. Le Traon et al. [139] introduced eight mutation operators for the Organization-Based Access Control OrBAC policy. Mouelhi et al. [165] proposed a generic metamodel for security policy formalisms. Based on this formalism, a set of mutation operators was introduced to apply to all rule-based formalisms. Hwang et al. proposed an approach that applies Mutation Testing to test firewall policies [117].

5.3 Other Testing Application
In addition to assessing the quality of test sets, Mutation Testing has also been used to support other testing activities, for example, test data generation and regression testing, including test data prioritization and test data minimization. In this section, we summarize the main work on mutation as support to these testing activities.

5.3.1 Test Data Generation
The main idea of mutation-based test data generation is to generate test data that can effectively kill mutants. Constraint-based test data generation (CBT) is one of the automatic test data generation techniques using Mutation Testing. It was first proposed in Offutt's PhD work [194]. Offutt suggested that there are three conditions for a test case to kill a mutant: reachability, necessity, and sufficiency. In CBT, each condition for a mutant is turned into constraint. Test data that guarantee to kill this mutant can be generated by finding input values that satisfy these constraints.

Godzilla is a test data generator that uses the CBT technique. It was implemented by DeMillo and Offutt [67] under the Mothra system. Godzilla applied control-flow analysis, symbolic evaluation, and a constraint satisfaction technique to generate and solve constraints for each mutant. Empirical results suggest that 90 percent of mutants can be killed using the CBT technique for most programs [68]. However, the CBT technique also suffers from some of the drawbacks associated with symbolic evaluation. Offutt et al. [179], [180] addressed these problems by proposing the Dynamic Domain Reduction technique.

Baudry et al. proposed an approach to automatically generate test data for components implemented by contract [22]. In this research work, a testing-for-trust methodology was introduced to keep the consistency of the three component artifacts: specification, implementation, and test data. Baudry et al. applied a genetic algorithm to generate test data. The generated test datum is then considered as a predator which is used to validate the program and the contract at the same time. Experimental results showed that 75 percent of mutants can be killed using this test data generation technique.

Besides generating test data directly, Mutation Testing has also been applied to improve the quality of test data. Baudry et al. [21] proposed an approach to improve the quality of test data using Mutation Testing with a Bacteriological Algorithm. Smith and Williams applied Mutation Testing as guidance to test data augmentation [219]. Le Traon et al. [138] use mutation analysis to improve component contract. Xie et al. [258] applied Mutation Testing to assist programmers in writing parameterized unit tests.

5.3.2 Regression Testing
Test case prioritization techniques are one way to assist regression testing. Mutation Testing has been applied as a test case prioritization technique by Do and Rothermel [75], [76]. Do and Rothermel measured how quickly a test suite detects the mutant in the testing process. Testing sequences are rescheduled based on the rate of mutant killing. Empirical studies suggested that this automated test case prioritization can effectively improve the rate of fault detection of test suites [76].

Mutation Testing has also been used to assist the test case minimization process. Test case minimization techniques aim to reduce the size of a test set without losing much test effectiveness. Offutt et al. [173] proposed an approach named Ping-Pong. The main idea is to generate mutants targeting a test criterion. A subset of test data with the highest mutation score is then selected. Empirical studies show that Ping-Pong can reduce a mutation adequacy test set by a mean of 33 percent without loss of test effectiveness.

In addition to the previously mentioned applications, mutation analysis has also been applied to other application domains. For example, Serrestou et al. proposed an approach to evaluate and improve the functional validation quality of RTL in a hardware environment [210], [211]. Mutation analysis has also been used to assist the evaluation of software clone detection tools [204], [205].

SECTION 6Empirical Evaluation
Empirical study is an important aspect in the evaluation and dissemination of any technique. In the following sections, the subject programs used in empirical studies are first summarized. Empirical results on the evaluation of Mutation Testing are then reported in detail.

6.1 Subject Programs
In order to investigate the empirical studies on Mutation Testing, we have collected all the subject programs for each empirical experiment work from our repository, as shown in Table 9 (Table 9 is located in the end of the paper). Table 9 shows the name, size, description, the year when the subject program was first applied, and the overall number of research papers that report results for this subject program. The table entry for some sizes and descriptions of the subject programs are shown as “not reported.” This occurs where the information is unavailable in the literature. Table 9 is sorted by the number of papers that use the subject program, so the first 10 programs are the most studied subject programs in the literature on Mutation Testing. These wildly studied programs are all laboratory programs under 50 LoC, but we also noticed that the 11th program is SPACE, a nontrivial real program.

To provide an overview of the trend of empirical studies on Mutation Testing to attack more challenging programs, we calculated the size of the largest subject program for each year. For each year on the horizontal axis, the data point in Fig. 7 shows the size of the largest program considered in a mutation study up to that point in time. Clearly, the definition of “program size” can be problematic, so the figure is merely intended to be used as a rough indicator. There is evidence to indicate that the size of the subject programs that can be handled by Mutation Testing is increasing. However, caution is required. We found that although some empirical experiments were reported to handle large programs, some studies applied only a few mutation operators. We also counted the number of newly introduced subject programs for each year. The results are shown in Fig. 8. The dashed line in the figure is the cumulative view of the results. The number of newly used subject programs is gradually increasing, which suggests a growth in practical work.


Fig. 7. The largest program applied for each year.
Show All


Fig. 8. New programs applied for each year.
Show All

In the empirical studies, it may be more indicative to use a real-world program rather than laboratory program. To understand the relationship between the use of laboratory programs and real-world programs in mutation experiments, we have counted each type by year. The results are shown in Fig. 9. In this study, we consider a real-world program to be either an open source or an industry program. In Fig. 9, the cumulative view shows that the number of real-world programs started increasing in 1992, while the number of laboratory programs had already started increasing by 1988. Fig. 9 also shows the number of laboratory and real programs introduced into studies each year as bars. This clearly indicates that, while there are correctly more laboratory programs overall, since 2002 far more new real programs than laboratory programs have been introduced. This finding provides some evidence to support the claim that the development of Mutation Testing is maturing.


Fig. 9. Laboratory programs versus real programs.
Show All

In our study, we found that for each research area of Mutation Testing, there is a different set of subject programs used as benchmarks. In Table 5, we have summarized these benchmark programs. We chose five active research areas based on our studies: Coupling effect, Selective Mutation, Weak, Strong, and Firm Mutation, Equivalent Mutant Detection, and experiments supporting testing, including the use of mutation analysis to select, minimize, prioritize, and generate test data.

TABLE 5 Subject Programs by Application

6.2 Empirical Results
Many researchers have conducted experiments to evaluate the effectiveness of Mutation Testing [14], [50], [61], [93], [94], [160], [188], [248]. These experiments can be divided into two types: comparing mutation criteria with data-flow criteria such as “all-use” and comparing mutants with real faults. Table 6 summarizes the evaluation type and the subject programs used in each of these experiments.

TABLE 6 Empirical Evaluation of Mutation Testing

Mathur and Wong have conducted experiments to compare the “all-use” criterion with mutation criteria [160], [248], [251]. In their experiment, Mathur and Wong manually generated 30 sets of test cases satisfying each criterion for each subject program. Empirical results suggested that mutation adequate test sets more easily satisfy the “all-use” criteria than all-use test sets satisfy mutation criteria. This result indicates mutation criteria “probsubsumes”2 the “all-use” criteria in general.

Offutt et al. conduced a similar experiment using 10 different programs [188]. The “cross scoring” result also provides evidence for Mathur and Wong's probsubsumes relationship [160], [248]. In addition to comparing the two criteria with each other, Offutt et al. also compared the two criteria in terms of the fault detection rate. This result showed that 16 percent more faults can be detected using mutation adequate test sets than “all-use” test sets, indicating that mutation criteria is “probbetter”3 than the “all-use” data flow. This conclusion also agreed with the results of the experiment of Frankl et al. [93], [94].

In addition to comparing mutation analysis with other testing criteria, there have also been empirical studies comparing real faults and mutants. In the work of Daran and Thévenod-Fosse [50], the authors conducted an experiment comparing real software errors with first order mutants. The experiment used a safety-critical program from the civil nuclear field as the subject program with 12 real faults and 24 generated mutants. Empirical results suggested that 85 percent of the errors caused by mutants were also produced by real faults, thereby providing evidence for the Mutation Coupling Effect Hypothesis. This result also agreed with DeMillo and Mathur's experiment [61]. DeMillo and Mathur carried out an extensive study of the errors in TeX reported by Knuth [61] and they demonstrated how simple mutants could detect real complex errors from TeX.

Andrews et al. [14] conducted an experiment comparing manually instrumented faults generated by experienced developers with mutants automatically generated by four carefully selected mutation operators. In the experiment, the Siemens suite (Printtokens, Printtokens2, Replace, Schedule, Schedule2, Tcas, and Totinfo) and the Space program were used as subjects. Empirical results suggested that, after filtering out equivalent mutants, the remaining nonequivalent mutants generated from the selected mutation operators were a good indication of the fault detection ability of a test suite. The results also suggested that the human-generated faults are different from the mutants; both human and autogenerated faults are needed for the detection of real faults.

Do and Rothermel [75], [76] studied the effect of both hand seeded faults and machine generated mutants on fault detection ability and the test prioritization order. In the test data prioritization study, Do and Rothermel considered several prioritization techniques to improve the fault detection rate. Their analysis showed that for noncontrol test case prioritization, the use of mutation can improve fault detection rates. However, the results are affected by the number of mutation faults applied. In the fault detection ability studies, Do and Rothermel followed Andrews et al.'s experimental procedure [14]. Results from four out of the six subject programs revealed a similar data spread to the work of Andrews et al. The effect of test set minimization using mutation can be found in the work of Wong et al. [249].

Despite evaluating Mutation Testing against other testing approaches, there are also experiments that use mutation analysis to evaluate different testing approaches. For example, Andrews et al. [15] conducted an experiment to compare test data generation using control flow and data flow. Thevenod-Fosse et al. [229] applied mutation analysis to compare random and deterministic input generation techniques. Bradbury et al. [32] used mutation analysis to evaluate traditional testing and model checking approaches on concurrent programs.

SECTION 7Tools for Mutation Testing
The development of Mutation Testing tools is an important enabler for the transformation of Mutation Testing from the laboratory into a practical and widely used testing technique. Without a fully automated mutation tool, Mutation Testing is unlikely to be accepted by industry. In this section, we summarize development work on Mutation Testing tools.

Since the idea of Mutation Testing was first proposed in the 1970s, many mutation tools have been built to support automated mutation analysis. In our study, we have collected information concerning 36 implemented mutation tools, including the academic tools reported in our repository as well as the tools from the open source and the industrial domains. Table 7 summarizes the application, publication time, and any notable characteristics for each tool. The detailed description of the tools can be found in the references cited in the final column of the table.

TABLE 7 Summary of Published Mutation Testing Tools

Fig. 10 shows the growth in the number of tools introduced. In Fig. 10, the development work can be classified into three stages. The first stage was from 1977 to 1981. In this early stage, in which the idea of Mutation Testing was first proposed, four prototype experimental mutation tools were built and used to support the establishment of the fundamental theory of mutation analysis, such as the Competent Programmer Hypothesis [3] and the Coupling Effect Hypothesis [66]. The second stage was from 1982 to 1999. There were four tools built in this period, three academic tools, Mothra for Fortran [63], [64], Proteum, TUMS for C [52], [53], [236], and one industry tool called Insure++. Engineering effort had been put into Mothra and Proteum so that they were able to handle small real programs not just laboratory programs. As a result, these two academic tools were widely used. Most of the advanced mutation techniques were experimented on using these two tools, for example, Weak Mutation [183], [184], Selective Mutation [182], [190], Mutant Sampling [159], [248], and Interface Mutation [54], [55]. The third stage of Mutation Testing development appears to have started from the turn of the new millennium, when the first mutation workshop was held. There have been 28 tools implemented since this time. In Fig. 10, the dashed line shows a cumulative view of this development work. We can see that the tool development trend is rapidly increasing since year 2000, indicating that research work on Mutation Testing remains active and increasingly practical.

Fig. 10. - The number of tools introduced for each year.
Fig. 10. The number of tools introduced for each year.
Show All

In order to explore the impact of Mutation Testing within the open source and industrial domains, we have classified tools into three classes: academic, open sources, and industrial. Table 8 shows the number of each class over two periods; one is before the year 2000, the other is from the year 2000 to the present. As can be seen, there are more open source and industrial tools implemented recently, indicating that Mutation Testing has gradually become a practical testing technique, embraced by both the open source and industrial communities.

TABLE 8 Classification of Mutation Testing Tools

SECTION 8Evidence for the Increasing Importance of Mutation Testing
To understand the general trend for the Mutation Testing research area, we analyzed the number of publications by year from 1977 to 2009. Consider again the results in Fig. 1; there are five apparent outliers in years 1994, 2001, 2006, 2007, and 2009. The reason for the last four years, is that there were four Mutation Testing workshops held in 2000 (with proceedings published in 2001), 2006, 2007, and 2009. However, there is no direct evidence to explain the spike in year 2004; this just appears to be an anomalous productive year for Mutation Testing. The reader will also notice that 1986 is unique as no publications were found. An interesting explanation was provided by Offutt [176]: “1986 was when we were maximally devoted to programming Mothra.”

We performed a regression analysis on these data and found there is a strong positive correlation between year and the number of publications (r=0.7858). In order to predict the trend of publications in the future, we have tried to find a trend line for these data using several common regression models: Linear, Logarithmic, Polynomial, Power, Exponential, and Moving average. The dashed line in Fig. 1 is the best fit line we found. It uses a quadratic model, which achieves the highest coefficient of determination (R2=0.7747). To put the Mutation Testing growth trend into a wider context, we also collected and plotted the publication data from DBLP for the subject of computer science as a whole [232]. According to DBLP, the general growth in computer science is also exponential. From this analysis it is clear that Mutation Testing remains at least as healthy as computer science itself.

In order to take a closer look at the growing trend of the research work on Mutation Testing, we have classified this work into theoretical work and practical work. The theoretical category includes the publications concerning the hypotheses supporting Mutation Testing, optimization techniques, techniques for reducing computational cost, and techniques for the detection of equivalent mutants and surveys. The practical category includes publications on applications of Mutation Testing, development work on Mutation Testing tools, and related empirical studies.

The goal of this separation of papers into theoretical and practical work is to allow us to analyze the temporal relationship between the development of theoretical and practical research effort by the community. Fig. 11 shows the overall cumulative result. It is clear that both theoretical and practical work is increasing. In 2006, for the first time, the total number of practical publications surpasses the number of theoretical publications. To take a closer look at this relationship, Fig. 12 shows the number of publications per year. From 1977 to 2000, there were fewer practical publications than theoretical. From 2000 to 2009, most of the research work appears to shift to the application area. This provides some evidence to suggest that the field is starting to move from foundational theory to practical application, possibly a sign of increasing maturity.


Fig. 11. Theoretical publications versus practical publications (cumulative view).
Show All

Fig. 12. - Theoretical publications versus practical publications.
Fig. 12. Theoretical publications versus practical publications.
Show All

In the Redwine-Riddle maturation model [203], there is a trend that indicates that a technology takes about 15 to 20 years to reach a level of maturity at which time industrial uptake takes place. Suppose we cast our attention back by 15 years to the mid 1990s. We reach a point where only approximately 25 percent of the current volume of output had then been published in the literature. (see Fig. 12). The ideas found in this early Mutation Testing literature have now been implemented in practical commercial Mutation Testing tools, as shown in Table 7. This observation suggests that the development of Mutation Testing is in line with Redwine and Riddle's findings.

Furthermore, the set of Mutation Testing systems developed in the laboratory now provides tooling for a great many different programming language paradigms (as shown in Table 7). This provides further evidence of maturity and offers hope that, as these tools mature, following the Redwine and Riddle model, we can expect a future state-of-practice in which a wide coverage of popular programming paradigms will be covered by real-world Mutation Testing tools.

Finally, an increasing level of maturity can also be seen in the development of the empirical studies reported on Mutation Testing. For example, there is a noticeable trend for empirical studies to involve more programs and to also involve bigger and more realistic programs, as can be seen in the chronological data on empirical studies presented in Figs. 7 and 8. However, it should also be noted that more work is required on real-world programs and that many of our empirical evidence still rests on studies of what would now be regarded as “toy programs.” There also appears to be an increasing degree of corroboration and replication of the results reported (see Table 6).

SECTION 9Discussion of Unresolved Problems, Barriers, and Areas of Success
This section discusses some of the findings and conclusions that can be drawn from this survey of the literature concerning the current state of Mutation Testing. Naturally, this account is, to some extent, influenced by the authors' own position on Mutation Testing. However, we have attempted to take a step back and to summarize unresolved problems, barriers, and areas of success in an objective manner, based on the available literature and the trends we have found within it.

9.1 Unresolved Problems
One barrier to wider application of Mutation Testing centers on the problems associated with Equivalent Mutants. As the survey shows, there has been a sustained interest in techniques for reducing the impact of equivalent mutants. This remains an unresolved problem. We see several possible developments along this line. Past work has concentrated on techniques to detect equivalent mutants once they have been produced. In the future, Mutation Testing approaches may seek to avoid their initial creation or to reduce their likelihood. Mutation Testing may be applied to languages that do not have equivalent mutants. Where equivalent mutants are a possibility, there will be a focus on designing operators and analyzing code so that their likelihood is reduced. Of course, we should be careful not to “throw the baby out with the bath water”; we seek to retain the highly valuable, so-called stubborn mutants, while filtering out those that are equivalent. However, behaviorally these two classes of mutants are highly similar.

Most work on Mutation Testing has been concerned with the generation of mutants. Comparatively, less work has concentrated on the generation of test cases to kill mutants. Though there are existing tools for mutant generation that are mature enough for commercial application, there is currently no tool that offers test cases generation to kill mutants at a similar level of maturity. The state of the art is therefore one in which Mutation Testing has provided a way to assess the quality of test suites, but there has been comparatively little work on improving the test suites, based on the associated mutation analysis. We expect that, in future, there will be much more work that seeks to use high-quality mutants as a basis for generating high-quality test data. However, at present, practical software test data generation for mutation test adequacy remains an unresolved problem.

9.2 Barriers to be Overcome
There remains a perception—perhaps misplaced, but nonetheless widely held—that Mutation Testing is costly and impractical. This remains a barrier to wider academic interest in the subject and also to a wider uptake within industry. We hope that this survey will go some way toward addressing the remaining doubts of academics. There is plenty of evidence in this survey to show that Mutation Testing is on the cusp of a rising trend of maturity and that it is making a transition from academic to industrial application.

The barriers to industrial uptake are more significant and will take longer to fully overcome. The primary barriers appear to be those that apply to many other emergent software technologies as they make their transition from laboratory to wider practical application. That is, a need for reliable tooling and compelling evidence to motivate the necessary investment of time and money in such tooling.

As the survey shows, there is an increasingly practical trend in empirical work. That is, as shown in Section 6, empirical studies are increasingly focussing on nontrivial industrial subjects, rather than laboratory programs. In order to provide a compelling body of evidence, sufficient to overcome remaining practitioner doubts, this trend will need to continue. There is also evidence that Mutation Testing tools are starting to emerge as practical commercial products (see Section 7). However, more tooling is required to ensure widespread industrial uptake. Furthermore, there is a pressing need to address the, currently unresolved, problem of test case generation. An automated practical tool that offered test case generation would be a compelling facilitator for industrial uptake of Mutation Testing. No such tool currently exists for test data generation, but recent developments in dynamic symbolic execution [104], [209], [230] and search-based test data generation [10], [135], [162] indicates that such a tool cannot be far off. The Mutation Testing community will need to ensure that it does not lag behind in this trend.

9.3 Areas of Success
As this paper has shown (see Figs. 1, 3, 11, and 12 and Tables 7 and 8), work on Mutation Testing is growing at a rapid rate and tools and techniques are reaching a level of maturity not previously witnessed in this field. There has also been a great deal of work to extend Mutation Testing to new languages, paradigms and to find new domains of application (see Figs. 5, 7, 8, and 9 and Tables 5 and 9). Based on this existing success, we can expect that the future will bring many more applications. There may shortly be few widely used programming languages to which Mutation Testing has yet to be applied.

TABLE 9a Programs Used in Empirical Studies
Table 9a- 
Programs Used in Empirical Studies
TABLE 9b
Table 9b
TABLE 9c
Table 9c
TABLE 9d
Table 9d
In all aspects of testing, there is a trade-off to be arrived at that balances the cost of test effort and the value of fault finding ability; a classic tension between effort and effectiveness. Traditionally, Mutation Testing has been seen to be a rather expensive technique that offers high value. However, more recently, authors have started to develop techniques that reduce costs, without overcompromising on quality. This has led to successful techniques for reducing mutation effort without significant reduction in test effectiveness (as described in Section 3).

SECTION 10Conclusion and Future Work
This paper has provided a detailed survey and analysis of trends and results on Mutation Testing. The paper covers theories, optimization techniques, equivalent mutant detection, applications, empirical studies, and mutation tools. There has been much optimization to reduce the cost of the Mutation Testing process. From the data we collected from and about the Mutation Testing literature, our analysis reveals an increasingly practical trend in the subject.

We also found evidence that there is an increasing number of new applications. There are more, larger and more realistic programs that can be handled by Mutation Testing. Recent trends also include the provision of new open source and industrial tools. These findings provide evidence to support the claim that the field of Mutation Testing is now reaching a mature state.

Recent work has tended to focus on more elaborate forms of mutation than on the relatively simple faults that have been previously considered. There is interest in the semantic effects of mutation, rather than the syntactic achievement of a mutation. This migration from the syntactic achievement of mutation to the desired semantic effect has raised interest in higher order mutation to generate subtle faults and to find those mutations that denote real faults. We hope the future will see a further coming of age, with the generation of more realistic mutants and the test cases to kill them and with the provision of practical tooling to support both.