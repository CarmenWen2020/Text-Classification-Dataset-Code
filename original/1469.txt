Abstract
In this paper, we study the market-oriented online bi-objective service scheduling problem for pleasingly parallel jobs with variable resources in cloud environments, from the perspective of SaaS (Software-as-as-Service) providers who provide job-execution services. The main process of scheduling SaaS services in clouds is: a SaaS provider purchases cloud instances from IaaS providers to schedule end users’ jobs and charges users accordingly. This problem has several particular features, such as the job-oriented end users, the pleasingly parallel jobs with soft deadline constraints, the online settings, and the variable numbers of resources. For maximizing both the revenue and the user satisfaction rate, we design an online algorithm for SaaS providers to optimally purchase IaaS instances and schedule pleasingly parallel jobs. The proposed algorithm can achieve competitive objectives in polynomial run-time. The theoretical analysis and simulations based on real-world Google job traces as well as synthetic datasets validate the effectiveness and efficiency of our algorithm.

Previous
Next 
Keywords
Service scheduling

Cloud computing

Online algorithm

Multi-objective optimization

Pleasingly parallel jobs

1. Introduction
The application scope of cloud computing is getting wider and wider. In clouds, resources are rent out to users in the form of services with a pay-per-use way, including Infrastructure-as-a-Service (IaaS) and Software-as-a-Service (SaaS), etc. (Armbrust et al., 2010). IaaS providers, such as Amazon EC2 (Amazon Web Services (AWS), 2021) and Microsoft Azure (Microsoft Azure, 2021), offer virtual machines (VMs) with different configurations (including vCPU, memory, storage, etc.) and prices as multiple types of instances (e.g., c5.large and t3.small). Most IaaS platforms support pay-as-you-go on-demand instances, i.e., one needs to pay per instance per unit time it has used. SaaS providers sell professional services to users, such as job-execution, web hosting, email access, and so on. In practice, to reduce the cost of establishing data centers and improve the flexibility of providing services, many SaaS providers tend to elastically purchase on-demand instances from IaaS providers and deploy their services on them. Considering that the purchase of instances from IaaS providers should be dynamic according to real-time demands, the resources of SaaS providers are variable. By trading SaaS services, on the one hand users only need to care about the service results without considering building data centers and configuring software, while on the other hand SaaS providers get revenue from users and pay for IaaS resources. This is featured as a market-oriented environment.

In this paper, we consider SaaS providers who provide job-execution services and focus on pleasingly parallel jobs (also called embarrassingly parallel jobs), which can be set flexible degrees of parallelism (DoPs) and divided into any number of tasks to run on different instances in parallel, without any overhead (Gunarathne et al., 2011a). In clouds, a large percentage of jobs are pleasingly parallel jobs. Typical examples are image processing such as 3D rendering, scientific computing such as BLAST searches, Monte Carlo simulations, parametric studies, massive searches such as key breaking. Besides, there are some kinds of data processing and analytics jobs which are pleasingly parallel. For example, map-only jobs such as the Smith Waterman algorithm fit into this type of jobs (while classic map-reduce jobs do not fit because they require synchronization and communications among tasks). The main process of service scheduling is shown in Fig. 1. Users arrive over time and submit their pleasingly parallel jobs. A SaaS provider purchases instances from an IaaS provider, schedules the submitted jobs selectively on purchased instances, returns the job-execution results to users, and charges them accordingly. In this process, SaaS providers should make decisions on the instance purchasing and job scheduling schemes.

In the above scenario, users arrive dynamically and SaaS providers need to make real-time decisions, while the information about the future is generally unknown and hard to be precisely predicted. Meanwhile, current decisions could have good or bad implications for the future. Therefore, an important issue to care about is that the instance purchasing and job scheduling decisions need to be made in an online mode without future information. This is practical in cloud environments but brings more difficulties. Besides, users in clouds are generally featured as job-oriented, which means they only pay attention to the job execution results and ignore the concrete execution process. Considering the features of pleasingly parallel jobs and job-oriented users, when scheduling jobs, besides the order of executing jobs, proper DoP and instances should also be selected. Different choices result in flexible execution time and completion time, corresponding to the soft deadline constraints of jobs.


Download : Download high-res image (322KB)
Download : Download full-size image
Fig. 1. The main process for SaaS providers to provide services: a SaaS provider dynamically purchases IaaS instances to execute users’ jobs and charges them accordingly.

All along, scheduling problems in various environments are always widely studied. Traditional environments such as machines (Azar et al., 2017), supercomputers (Cao et al., 2017a) and clusters (Guo et al., 2017) do not consider the cost of resources. Their main goal of scheduling is optimizing particular system objectives, including minimizing average makespan and maximizing throughput, etc. Conversely, market-oriented cloud environments (Buyya et al., 2009) often use commercial models with monetary cost and consider diverse quality of service levels. Thus, market-related objectives (e.g., revenue and cost) become major considerations. For SaaS providers, revenue (i.e., the income earned from users minus the cost paid to IaaS providers) is often the most significant concern. Meanwhile, to guarantee long-term profits, user satisfaction rate (i.e., the rate of the users whose jobs are completed by deadlines) is also an important goal, since rejecting too many users will result in their departure. Therefore, we deal with bi-objective scheduling problems and take both two objectives mentioned above into consideration.

Focusing on the market-oriented online bi-objective service scheduling for pleasingly parallel jobs with variable resources in cloud environments, we design an online algorithm for SaaS providers to help them make better decisions. In more detail, our contributions are summarized as follows: (1) We formally define and describe the market-oriented online bi-objective service scheduling problem focusing on pleasingly parallel jobs with various resources, and prove it as being NP-hard (cf. Theorem 1). (2) We then propose an online algorithm to efficiently decide the instance purchasing and job scheduling, which makes a trade-off between two objectives: maximizing SaaS providers’ revenue and maximizing user satisfaction rate. (3) We utilize strict theoretical analysis to prove that the proposed online algorithm achieves competitive objectives in polynomial run-time. Meanwhile, we construct extensive simulations based on synthetic and real-world Google job data to verify its effectiveness and efficiency.

The rest of the paper is organized as follows. Section 2 introduces the related work. Section 3 gives fundamental notations and formulates the market-oriented online bi-objective service scheduling problem for pleasingly parallel jobs with various resources in clouds as an integer programming. Section 4 designs an online algorithm with strict theoretical analysis. Section 5 constructs extensive evaluations. Section 6 concludes this paper and proposes future research direction.

2. Related work
Recently, there have been studies on traditional scheduling problems that focus on system objectives. Azar et al. (2017) utilize the correlated rounding technique to design a scheduling algorithm for restricted–related machines, with the aim of minimizing the makespan. Cao et al. (2017a) present a node location-aware job scheduling algorithm to improve the total throughput for the HPC system. Stec et al. (2019) solve the stochastic processing time scheduling problem on parallel identical machines to maximize the probability that all the jobs will be completed before a specified deadline. In Qi and Yuan (2019), Qi et al. investigate the problem of scheduling jobs on two identical machines and design a semi-online hierarchical algorithm for minimizing the load of machines.

In market-oriented environments such as clouds, service providers are more concerned about cost or profit. Li et al. (2016) focus on the utility value maximization problem for parallel and time-sensitive applications. They design a spatial–temporal interference based scheduling algorithm which is 2-approximate. Sahni and Vidyarthi (2018) focus on the workflow scheduling problem with deadline constraints in clouds. They design a cost-effective heuristic algorithm from the perspective of an application to minimize cost. Alkhanak and Lee (2018) design a completion time driven hyper-heuristic algorithm to help service providers schedule scientific jobs in clouds. Their objective is to optimize the cost of executing jobs. Unfortunately, all the above algorithms are under offline settings and cannot make decisions without future information.

To address the online mode in cloud environments, some researchers have focused on designing online algorithms. Zhang et al. (2016) present a scheduling algorithm from the perspective of cloud brokers that gather resource requests from customers to utilize the volume discount. The algorithm is stack centric, randomized, and online. Ghose et al. (2017) focus on the scientific workflow scheduling problem in cloud systems and design six different scheduling approaches. Their main goal is energy efficiency. Dambreville et al. (2017) address the online scheduling of cloud servers to minimize energy consumption. In Bao et al. (2018), Bao et al. propose an online strategy for scheduling jobs in distributed machine learning clusters. Their objective is to maximize the total utility of executing jobs, which depends on respective completion time of users. All the above studies take the assumption that resources are fixed as a prerequisite. In fact, adjusting the resources dynamically according to real-time demands is more efficient.

Rare studies design algorithms from the perspective of SaaS providers and take both the scheduling and resource acquiring into consideration at the same time, while simultaneous consideration increases the difficulty significantly. Wu et al. (2020) design a policy to decide how to purchase on-demand and spot instances for the jobs. The aim is to minimize the cost of purchasing instances. In another work (Zhu et al., 2018), Zhu et al. consider the workflow scheduling in a hybrid-cloud. The resources are scalable rather than fixed in quantity. They design an iterated heuristic algorithm to reduce the cost of renting VMs. But these two studies only consider offline settings. Cao et al. (2017b) propose an online algorithm which schedules service requests in hybrid clouds to minimize the cost of renting resources from public clouds. However, all the above researches have single objectives. Instead, we consider more complex objectives including revenue and user satisfaction rate, which conforms better to the practice with the long-term development considerations.

There are also many studies that consider multiple objectives when scheduling jobs. Huang et al. (2018) address the task assignment problem in clouds and develop a new algorithm for multi-objective scheduling on the basis of particle swarm optimization, with aims of minimizing power consumption and makespan. Kaur and Kadam (2018) propose a novel multi-objective job scheduling strategy in cloud and grid environments. In their paper, they make a trade-off among flowtime, makespan, and resource cost. In Peng et al. (2019), Peng et al. solve the task scheduling problem in mobile cloud environments. They design a scheduling algorithm on the basis of dynamic voltage scaling technique and whale optimization strategy to jointly optimize completion time and energy consumption. These three algorithms are offline algorithms which are unsuitable for online settings. Hu et al. (2018) propose an online task scheduling strategy to optimize both completion time and costs in geographically distributed data centers. Gasior et al. (2017) present a framework of studying multi-objective online scheduling problem in IaaS cloud computing systems. Their objectives include minimizing the SLA violation counts and maximizing the total provider’s income. Nevertheless, these two online multi-objective algorithms do not consider the dynamic purchasing of resources.

Particularly, focusing on pleasingly parallel jobs, there are many studies that have been proposed. Gunarathne et al. (2011b) present two pleasingly parallel biomedical applications and use them to analyze the performance of different cloud models. Li et al. (2016) mentioned above focuses on parallel and time-sensitive applications, which are in line with pleasingly parallel jobs. Zhang et al. (2014) focus on scheduling the multitasking workloads for big-data analytics. They introduce the ordinal optimization using rough models and the fast simulation to get the suboptimal solutions at a very fast speed. Stavrinides and Karatza (2017) concentrate on the big data analytics SaaS and study data-aware scheduling policies. Chen et al. (2019a) address the scheduling problem of big data analytics jobs. Their goal is to minimize the total job completion time while achieving max–min fairness. These algorithms are all offline algorithms. Shi et al. (2017) solve the problem of scheduling pleasingly parallel jobs and design an online algorithm to minimize job completion time. Zhou et al. (2017) focus on parallel computing jobs with soft deadline constraints and utilize the technique of primal–dual to design an online algorithm. The two algorithms mentioned above are online algorithms which do not consider variable resources. In Wu et al. (2020), Wu et al. design a policy to allocate self-owned, on-demand, and spot instances to the arriving pleasingly parallel jobs, using CAP3 in bioinformatics as an example. Their goal is cost optimization. The resources in this work are variable but the policy is offline. In summary, none of the above scheduling algorithms considers the pleasingly parallel jobs, the online settings, the variable resources, and the complex objectives at the same time.

After summarizing the existing work, the main contribution of this paper lies in that we design an online service scheduling algorithm for pleasingly parallel jobs with various resources in market-oriented cloud environments. In this algorithm, we take both the SaaS providers’ revenue and user satisfaction rate into consideration and help SaaS providers efficiently solve their scheduling problems.

3. System model
In this section, we first introduce the fundamental notations used in this paper and then use these notations to formulate the market-oriented online bi-objective service scheduling problem for pleasingly parallel jobs.

3.1. Fundamental notations
The SaaS providers periodically sum up the income and cost, and a period is called an accounting period. The time axis of an accounting period consists of  discrete time slots, represented as . User arrivals, instance purchasing, and job scheduling are based on time slots. In this paper, we only consider on-demand IaaS instances whose usage duration is  slots. We assume that SaaS providers purchase  types of on-demand instances from a public IaaS cloud, written as . These different types of heterogeneous instances have different physical configurations (including CPU and memory etc.) and correspond to different purchase prices.  represents the price of type- instances, which is the money a SaaS provider needs to pay if it purchases an instance  unit. An instance  unit corresponding to a type- instance running for one time slot.  denotes the number of type- instances newly purchased at time slot . Considering the huge capacity of public IaaS clouds, in theory  can be infinite. We use  to denote the number of type- instances that are available at time slot .

We use  to denote the total number of users who arrive in the whole accounting period, written as . User  arrives at time slot  and submits a pleasingly parallel job to the SaaS provider. For simplicity and without ambiguity, we also use  to denote the job of user . Only when a job arrives at the system, its information can be known by SaaS providers. Each job  can be described by a tuple (, , , , ).  is the arrival time and  is the deadline. Job  can be completed at any time slot between  and . We use  to represent the demand of job  for type- instances. It means to complete job , total  instance  units are required. The demands of job  for different types of instances are related to instances’ performances. A job can be executed on multiple types and numbers of instances, as long as the total demand is satisfied. Estimating a job’s demand which can also be understood as the execution time is a classic problem which attracts extensive studies (e.g., Chen et al., 2019b, Liang et al., 2015), falling beyond the scope of our study. Threshold  is used to limit job ’s degrees of parallelism (DoPs), which means job  can be divided into at most  independent tasks to run on different instances in parallel, without any overhead.  represents the value function of user , which is related to the execution time of job . This value function also denotes user ’s willingness to pay. Generally,  will decrease as the execution time increases. In this paper, we use ’s value function to indicate the valuation that SaaS providers can obtain from executing job . As a result, SaaS providers charge a corresponding amount of money as payment. The value functions can be arbitrary shapes as long as they are nonincreasing functions. For instance, the value function can be a linear decreasing function or have two stages (e.g., a constant until the deadline and a linear decreasing function after the deadline). Besides, since we do not consider the penalties of SaaS providers, the value function should be no less than 0.

We use  to represent the execution time which is the number of time slots that SaaS providers spend to execute a job. Considering the feature of jobs and users, with different scheduling schemes, the execution time is different. For job , considering its arrival time 
 and deadline 
, we have its execution time 
, where 
. Then the corresponding completion time is 
, and the corresponding valuation is 
. To express discrete time axis and make it convenient to correspond, we use 
 to represent the valuation of user  if its execution time is . We use binary variable 
 for indicating whether job ’s execution time is . Job  may have multiple possible values of execution time 
. Thus, the execution time  which makes 
 is its actual execution time. If a job’s execution time is , we also say that job  with execution time  is accepted. Then the values of 
 is: 
 The payment of user  that the SaaS provider should charge is 
, which equals the actual valuation of job . In this paper, we assume that SaaS providers can reject service requests without any penalties. For reference, Table 1 summarizes the fundamental notations that are used in this paper.

To provide services, SaaS providers need to make the following decisions:

(1) The number of type- instances that should be newly purchased from an IaaS cloud at each time slot , 
.

(2) Whether to accept user ’s job with execution time , 
.

(3) The number of type- instances allocated to user  at time slot  with execution time , 
.

Considering the features of pleasingly parallel jobs, job  can be scheduled with different DoPs on multiple types and numbers of instances, which results in diverse execution time and further leads to different valuations to user . For better understanding, we give a brief example. Job  arrives at time slot 
 with deadline 
. Then the set of possible execution time is 
. It has 
, 
 and 
. There are several possible scheduling schemes.

(1) Job  can be executed on 4 type- instances for 1 time slot (i.e., DoP is 4). Then  and completion time is 2. 
. The corresponding valuation is 
.

(2) Job  can be executed on 1 type- instance for 4 time slots (i.e., DoP is 4). Then  and completion time is 5. 
. The corresponding valuation is 
.

(3) Job  can be executed on 1 type- instance for 1 time slot and 1 type- instances for 2 time slots (i.e., DoP is 3). Then  and completion time is 3. 
 and 
. The corresponding valuation is 
.

Or,  and completion time is 4. 
 and 
. The corresponding valuation is 
.


Table 1. Summary of fundamental notations.

Number of time slots		set of time slots
Number of users		set of users
Arrival time of user 	
deadline of user 
Payment of user 		set of instance types
Number of instance types		usage duration of instances
Number of newly purchased type- instances at time slot 
Price of purchasing one unit type- instance for one time slot
Set of possible execution time of job 
Demand of job  for type- instances
Threshold of job ’s degrees of parallelism (DoPs)
Valuation of job  with execution time 
Whether job ’s execution time is  (if yes 
, otherwise 
)
Number of type- instances allocated to job  with execution time  at time slot 
Number of available type- instances at time slot 
Cost of user  with execution time 
Estimated offline cost of user  with execution time 
3.2. Problem formulation
Assuming that all the required information is known in advance, we use the fundamental notations mentioned above to formulate the market-oriented online service scheduling problem with various resources in cloud environments.

To build long-term attraction, when solving the scheduling problem, SaaS providers need to consider two objectives:

(1) Maximizing SaaS providers’ revenue (): The revenue of a SaaS provider is the total payment charged to users (i.e, the total valuation of job completions) minus the total cost of purchasing instances. SaaS providers pursue the greatest revenue as much as possible. (1)

(2) Maximizing user satisfaction rate (): If a user’s job is completed before its deadline, then this user’s service request is satisfied, which also means this user is satisfied. We define the user satisfaction rate of the system as the rate of satisfied users. Thus, to maximize the user satisfaction rate, we need to maximize the rate of the users whose jobs are completed by deadlines. According to the definition, . Guaranteeing a high user satisfaction rate can prevent users from leaving, which is beneficial to long-term profit. (2)
 

Optimizing the above two objectives simultaneously belongs to the multi-objective optimization problem. One classic method to address this problem is to transform several objectives into one aggregated objective. To do this, one can use the weighted sum method (Zadeh, 1963, Marler and Arora, 2010), which calculates the linear combination of several different objectives. In this paper, to take both the revenue  and user satisfaction rate  into consideration, we use the idea of the weighted sum method and linearly combine these two objectives by a factor  to get an aggregated objective . The factor  indicates the relative importance of objectives  and . It can be set by SaaS providers. Considering that the ranges of  and  are very different, we normalize these two objectives by min–max normalization (Han and Kamber, 2006). In this way, these two objectives can be scaled to fall within a specified range (i.e., ) and thus generate comparable influence to the final aggregated objective . (3)
 
Here 
 is the optimal revenue the system can obtain in an accounting period.

Then we can formulate the market-oriented online service scheduling problem for pleasingly parallel jobs with various resources in cloud environments to an integer programming (IP): (4)
 
(5)
 
(6)
(7)
(8)
(9)
(10)
(11)
(12)
 Constraint (5) implies that the number of instances distributed to a job should be enough to complete the job. In other words, partial completion is meaningless. Constraint (6) means one job can be completed at most once. In practice, practical thresholds should exist to limit DoPs, resulting in constraint (7). Constraints (8), (9) are resource capacity constraints. Constraints (11), (12) are the integer constraints, requiring the number of instances allocated to jobs and purchased from IaaS clouds at each time slot to be an integer.

Theorem 1

The market-oriented bi-objective online service scheduling problem for pleasingly parallel jobs with various resources in cloud environments (formulated to IP (4)) is NP-hard.

Proof

To prove Theorem 1, we reduce our scheduling problem to the 0-1 knapsack problem. This problem is a typical optimization problem which has been proven to be NP-hard (Kellerer et al., 2004). In the reduction, the jobs are considered as items, and the resources are considered as knapsacks. Focusing on the bi-objective service scheduling problem (4), we do the modifications as follows. (1) The objective is SaaS providers’ revenue maximization, which means Eq. (4) is modified to 
. (2) Only one time slot is considered (), which means symbol  is omitted. Correspondingly, all jobs come and complete at the same time (
), which means symbol  is omitted. (3) Only one type of instances is used (), which means symbol  is omitted. In combining with (2), there is only one scheduling scheme (
) which will not violate the DoP threshold. Thus constraints (5), (7) are removed. (4) Dynamic instance purchasing is not considered and the resource capacity of the SaaS provider is fixed, which means symbol  is omitted and thus constraints (8), (12) are removed. Then our scheduling problem can be reduced as: 
 From this reduction, the market-oriented online service scheduling problem in this paper can be regarded as a complicated expansion of 0-1 knapsack problem. Consequently, our problem is also NP-hard. □

Offline optimal solutions can be obtained by solving IP (4). However, according to Theorem 1, finding exact solutions is NP-hard. Moreover, online settings should also be considered. When making decisions, SaaS providers should only use the information already known. Considering these challenges, we propose an online algorithm to make approximate decisions.

4. An online service scheduling algorithm
In this section, we propose an online algorithm and prove its effectiveness through theoretical analysis. The main steps of the online algorithm are shown in Algorithm 1.


Download : Download high-res image (204KB)
Download : Download full-size image
4.1. The job scheduling strategy
When user  arrives at the system and submits its service request, the SaaS provider needs to make decisions immediately. In this process, we temporarily assume that all the arrived jobs until now have been accepted. The respective actual execution time is 
. First, we propose a job scheduling strategy which is straightforward and efficient to decide the instance purchasing and job scheduling schemes for job  (line 3 in Algorithm 1).

In the following description, we take type- instances as an example. For job ’s each possible execution time 
, we averagely allocate the total demand 
 to the whole execution interval 
, i.e, 
 
. That is, the number of type- instances needed by job  is the same in every time slot of interval 
. For each time slot  in 
, if the instances which are already purchased in previous time slots are enough to complete corresponding demands, then we allocate these instances to job . Otherwise, we purchase new instances until the instances are sufficient and set 
 to the corresponding value. When new instances are needed, we choose to purchase the instance type which has the maximum performance/price ratio. In this process, we need to note the DoP threshold. If an instance type cannot guarantee the threshold, then this type of instances will not be considered for executing this job. As a straightforward method, this job scheduling strategy can efficiently and fast produce feasible schemes.

Now we give a simple example to help understand the job scheduling strategy. Job ’s arrival time 
, deadline 
 and demand 
. Its possible execution time is . For execution time , 
. For execution time , 
. For execution time , 
.

4.2. The cost calculating strategy
Then, for the obtained job scheduling and instance purchasing schemes, we propose the following cost calculating strategy to calculate the cost of executing job  with execution time  (line 4 in Algorithm 1). We use 
 to represent that job  is executed with execution time .

Since an instance may be shared by multiple jobs, the cost of purchasing this instance should also be distributed among these jobs. Then we use the idea of proportional sharing (Si et al., 2013) to distribute the total cost among all the accepted users. Proportional sharing is a simple but effective cost distribution approach which distributes the cost of a jointly used common resource among its users. This method is also called average cost pricing in Moulin, 2002, Wang and Zhu, 2002, Lin et al., 2015. The main idea of this method is: dividing the total cost in proportion to individual revenue or demand. That is, a user’s sharing cost is the total cost times the proportion of its revenue or demand to the total revenue or demand.

Theoretically, users’ value functions can represent their revenues. However, value functions are personally defined which cannot adequately reflect the cost to complete jobs. Some users may have large valuations for small demands or vice versa. Hence, to distribute the cost fairly, we use the demands to calculate the sharing costs. However, the other problem is that the cost produced by executing a job is related to not only demand but also execution time. Thus, when considering the cost distribution of job 
, we need to synthesize the demand and execution time. To combine demand and execution time, we use the weighted sum method and min–max normalization again mentioned above. The aggregated result is defined as the weight of 
 which is used to calculate the sharing cost in Eq. (13). The weight of job  with execution time  is: 
 
 
where 
, 
, while  is the maximum number of possible execution time. Coefficient  can indicate the importance of demands and execution time. It is chosen from  and can be set by SaaS providers based on their requirements.

Then, 
’s sharing cost is the total cost times the proportion of 
’s weight to the total weight of all accepted users. The weight 
 here can be seen as the contribution of executing 
 to the total cost. Then the sharing cost of 
 is: (13)
 
  represents the cost function and  represents the total cost of executing all the users in  with their optimal execution time 
. If we appoint that job ’s execution time is , the total cost is represented as 
.

Nevertheless, only if the total cost is known, the cost of each job can be calculated accurately. In the practical online markets, it is impossible to calculate each user’s accurate sharing cost real-timely. Thus we consider estimating the cost for a user in the whole accounting period. The main process is as follows. When the instance purchasing and job scheduling schemes are determined, at first we calculate current cost 
 for job  with execution time . The total cost used in this calculation is the current total cost, supposing all the arrived jobs are accepted. Then, based on 
, we apportion job ’s cost to the jobs who arrive later than , and apportion the cost produced by the jobs who arrive later than  to job . That is, the estimated cost 
 of job  with execution time  in the whole accounting period is: 
 
Here, 
 is the set of users who arrive before .  can be obtained using historical data. In this estimation, we suppose that the probability of job arrivals and demands in every time slot is the same. By using such an estimation approach, we can conclude: 
.

4.3. The acceptance strategy
Next, we use the following acceptance strategy to decide the acceptance or rejection of user  (lines 6–14 in Algorithm 1). We choose the execution time which maximizes the gain increment (Eq. (14)) as the optimal execution time 
 of job . Only if the gain increment of 
 is high enough, job  will be accepted and the execution time is 
. If 
 is accepted, the payment user  should pay is its valuation corresponding to execution time 
. Finally, we run the job scheduling strategy once again for accepted job  with its execution time 
 to calculate actual schemes, according to all the jobs which are actually executed.

The gain increment to the aggregated objective  of job  with execution time  is: (14)
 
 
Both 
 and  can be obtained according to the historical data of the previous accounting period.

This gain increment considers both SaaS providers’ revenue and user satisfaction rate at the same time. According to 
, only the users whose valuations are large enough can get served. By adding 
 
, the online algorithm accepts more users whose valuations are small, which will decrease SaaS providers’ revenue but increase user satisfaction rate.  reflects the importance of providers’ revenue and user satisfaction rate. It can be set by SaaS providers according to their requirements. If , the goal of the algorithm is revenue maximization. With less , the algorithm considers more about user satisfaction rate.

4.4. Theoretical analysis
The online algorithm should achieve good performance and near-optimal objectives. Competitive ratio is used to measure the performance of an online algorithm. If whatever the input is, the ratio of the offline optimal objective to the objective achieved by the online algorithm is smaller than or equal to a specific value , then the online algorithm can be seen as achieving competitive ratio . This section proves that our online algorithm achieves competitive revenue and aggregated objective.

Theorem 2

The proposed online algorithm can achieve an expected competitive ratio of 
 
 in the SaaS providers’ revenue .  and  are related to users’ valuations.

Proof

We use subscripts 
 and 
 to represent the optimal solution and the solution obtained by our online algorithm respectively. For instance, 
 and 
 represent the  obtained by the optimal algorithm and our online algorithm respectively.

First, we suppose a fictional situation to give an upper bound of both  and : all the jobs are completed at the first time slot after their arrivals with instance purchase cost 0. Apparently, in our problem there is no situation that can produce larger revenue and user satisfaction rate than this fictional situation, including the optimal solution. Thus we have: (15)
(16)
 
 represents user ’s maximum valuation. Considering that value functions are nonincreasing, a user’s maximum valuation is generally its valuation for the first time slot.

Considering the fictional situation, the upper bound of the 
 is (Eq. (15)): 

Then, we consider the situation using our online algorithm. Let  and  denote the set of accepted and rejected users respectively. The total numbers of users of these two sets are 
 and 
 respectively.  is the actual total cost according to our algorithm. Apparently, this actual cost will be no larger than the total cost of serving all users in , that is, . The expectative revenue obtained by our online algorithm is the total valuation of completed jobs minus the actual cost, i.e.: (17)
(18)
(19)
 
 
(20)
 
 
(21)
 The set of all users  can be divided into the set of accepted users  and the set of rejected users . Besides,  and 
. Thus we can get Eq. (18) from Eq. (17). According to the acceptance strategy in Section 4.3, the users who are rejected have: 
 
 
. Thus we can get Eq. (19) from Eq. (18). Since the cost of rejected users must no larger than the total cost of serving all users, we can get Eq. (20) from Eq. (19). Let 
 represent user ’s minimum valuation. Then Eq. (21) can be deduced.

Next, we use parameters  and  to represent the bound of users’ valuations. By using these two parameters, we can calculate the competitive ratio more simply and beautifully. Considering some other costs such as software and manage fees, SaaS providers are willing to provide services only if users’ valuations are larger than the cost of purchasing instances. Hence, for most of users, their minimum valuations are no smaller than respective costs, which means the sum of all users’ minimum valuations is larger than or equal to  times the total instance cost: (22)
Meanwhile, the maximum valuations that users are willing to pay are finite, which means the sum of all users’ maximum valuations is smaller than or equal to  times the total instance cost: (23)
  and  can be obtained by historical data.

Finally, we calculate the competitive ratio of the revenue  as follows: (24)
 
 
(25)
 
(26)
 
 Considering Eqs. (22), (23), Eq. (25) can be deduced.

In conclusion, Theorem 2 can be proved. □

Theorem 3

The proposed online algorithm can achieve an expected competitive ratio of 
 
 in the aggregated objective .  and  are related to users’ valuations. .

Proof

Considering the same fictional situation mentioned above, according to Eqs. (15), (16), we can calculate the optimal solution 
 as follows: (27)
 
 
 
 Since 
, 
 
. Thus Eq. (27) can be deduced.

For the 
, 
 (Eq. (17)) and 
 
. Then the expectative aggregated objective 
 of our algorithm is: 
 
 
 
 
 
 
 
 
 
 
 The main process is similar to the proof of 
, i.e., Eqs. (17)–(21).

Then the competitive ratio of the aggregated objective  is: (28)
 
 
 
 
 
 

In conclusion, Theorem 3 can be proved. □

Theorem 4

The proposed online algorithm has polynomial time complexity.

Proof

For each possible execution time of each user, the time complexity of calculating the instance purchasing and job scheduling schemes is . Since there is at most  possible execution time, the time complexity of Algorithm 1 is . The process of re-computing does not increase the time complexity. □

5. Experimental evaluation
In this section, we study the effectiveness and efficiency of our online algorithm through synthetic and Google data (Google cluster data, 2021). For SaaS provider’s revenue  (Eq. (1)), user satisfaction rate  (equation (2)), and aggregated objective  (Eq. (3)), our algorithm achieves great performance under various scenarios.

5.1. Simulation setup
We simulate a cloud environment where a SaaS provider rents instances to provide pleasingly parallel job-execution services to users. In practice, users can submit their jobs to the SaaS provider through a web page. Then the SaaS provider schedules these jobs using our proposed online algorithm or other comparison algorithms on an IaaS cloud platform. In this paper, we program a simulator and focus on the simulation of the presented mathematical model. In our simulator, a simulated IaaS platform configures total  heterogeneous instance types and allows on-demand accesses. The concrete configurations and prices of instances are set according to the real instances provided by Amazon EC2. The job workloads used in our simulations are synthesized according to the experimental requirements, based on the observation of actual pleasingly parallel jobs and Google cluster data. We try to emulate a real cloud. However, because of the constraints of experimental conditions, we simplify some details such as the bandwidth constraints of the network and the performance interference of inter-VMs. The number of time slots  is set based on experimental scenarios. Each time slot consists of 10 min and thus the usage duration of a unit on-demand instance is  slots. Users’ value functions decrease with the increase of execution time. By default, we set  and . We randomly choose demand  and threshold  from specific ranges. The demand 
 of job  for type- instance is related to this instance’s performance. The higher the performance is, the smaller the demand is. For the experiments using Google data, we can get the demands and DoP thresholds from Google datasets, which contain the information of jobs submitted to Google cluster.

Table 2 shows the concrete experimental parameters. To obtain the optimal solution as a comparison, we relax the integer constraints of IP (4) and solve the linear programming, which generates the upper bound of the optimal solution. To reduce the effect of randomness, all the experiments are repeated 20 times to generate average results.


Table 2. Summary of parameters.

Experiments
EXP1	EXP2	EXP3	EXP4	EXP5
Nor	Uni	Cons	Nor
2, 5, 8, …, 26	10	2, 5, 8, …, 26	10
200	60, 80, …, 300
Uniform [1, 30]	Google dataset
Uniform [5, 30]	Google dataset
6	2, 6, …, 22	6
5.2. EXP1: Performance with different numbers of users per time slot
We first study the performance of our online algorithm when the number of users per time slot increases. To prove that our algorithm can adapt to multiple scenarios, we assume that user arrival follows normal (“Nor”), uniform (“Uni”) and constant (“Cons”) distributions respectively. The results are shown in two aspects: (1) comparison of optimal, actual and theoretical  and , and (2) the actual competitive ratio.

From Fig. 2(a), we can see that as the number of users increases, the aggregated objective  is almost unchanged. This result reveals that our algorithm is stable under different numbers of users. By contrast, in Fig. 2(b), SaaS providers’ revenue  increases almost linearly, which means the more users, the more revenue. From this perspective, guaranteeing user satisfaction rate to attract users is important for SaaS providers. Meanwhile, in both Fig. 2, Fig. 2, our algorithm’s actual results are similar to optimal solutions, which also reflects the good performance.


Download : Download high-res image (1MB)
Download : Download full-size image
Fig. 2. Performance with different numbers of users per time slot.


Download : Download high-res image (748KB)
Download : Download full-size image
Fig. 3. Competitive ratio with different numbers of users per time slot.

According to Eqs. (28), (26), the theoretical competitive ratios of  and  in this experiment are 4.76 and 3.33 respectively. It follows from Fig. 3, Fig. 3 that the actual competitive ratios are very small. This is strong evidence that our algorithm can obtain great performance with different numbers of users. With the number of users per time slot increasing, the actual competitive ratios of both  and  show a slight decrease. This is due to the fact that with more users requesting services, a bad instance purchasing or scheduling scheme will produce less influence to the entire decision. In addition, we can see that different distributions lead to similar results. This implies that our algorithm can be applied in a wide range of scenarios.

5.3. EXP2: Performance with different numbers of possible execution time
We then study the performance of our online algorithm when the number of possible execution time increases. The results are illustrated from the perspective of competitive ratio.

From Fig. 4, we can see that as the number of possible execution time increases, the competitive ratios of both  and  gradually increase. This is because as the number of possible execution time increases, out algorithm has more difficulties to make optimal decisions. However, the competitive ratios are still very small, reflecting the good performance of our algorithm.


Download : Download high-res image (178KB)
Download : Download full-size image
Fig. 4. Performance with different numbers of possible execution time.

5.4. EXP3: Performance with different values of 
We next study the change of SaaS providers’ revenue  and user satisfaction rate  when the value of  varies from 1 to 0.

It follows from Fig. 5 that with  decreasing, providers’ revenue gradually decreases and user satisfaction rate gradually increases. This is because when  is large, the algorithm will consider more about revenue. As  decreases, the algorithm gradually focuses more on user satisfaction rate, leading to the shift of decisions. When  is small, the changes become slight.


Download : Download high-res image (150KB)
Download : Download full-size image
Fig. 5. Performance with different values of .

5.5. EXP4: Runtime
To work efficiently in online markets, algorithms should run in polynomial-time. We next compare the execution time of solving the optimal solution and our online algorithm, when the number of users per time slot increases.

According to Fig. 6, it is obvious that to achieve optimal results, the time cost is quite large. As the number of users increases, the runtime increases rapidly. By contrast, our algorithm has polynomial time complexity and can be run much faster. Combining former experimental results, one can conclude that our algorithm achieves good performance with a small time cost. Thereby, our algorithm can be used widely in practice.


Download : Download high-res image (127KB)
Download : Download full-size image
Fig. 6. Runtime.

5.6. EXP5: Comparison with other algorithms
Finally, we compare our online algorithm with some other online scheduling algorithms under Google data, when the number of time slots increases.

Currently, there are rare studies which consider the pleasingly parallel jobs, the variable resources, the online settings, and the complex objectives at the same time. For comparison, we select several classic or recently published algorithms and make some adaptations to make them comparable with our proposed algorithm. We compare our online algorithm with the following five scheduling algorithms by evaluating the aggregated objective , SaaS providers’ revenue , and user satisfaction rate :

(1) Primal–Dual: The online primal–dual scheduling algorithm in Zhou et al. (2017) focuses on pleasingly parallel jobs with the aim of revenue maximization. Their algorithm utilizes the dual programming of the problem and sets marginal price functions for resources. According to the valuations and prices, this algorithm decides whether to accept users’ service requests. Nevertheless, resource purchasing is not considered in this algorithm. Hence we assume that the number of purchased instances is smaller (“PD-small”) or larger (“PD-large”) than the total demand respectively.

(2) Earliest Deadline First: This is one of the most classic scheduling algorithms (Liu and Layland, 1973, Dertouzos, 1974). Jobs with the earliest deadline will be scheduled first. The resource purchasing in this algorithm is also not considered and we set fixed instances which are similar to users’ demands. “EDF” is used to indicate this algorithm.

(3) Equal Opportunity: This algorithm purchases instances, accepts users, and schedules jobs with equal opportunity. We use “Equal-opp” to indicate this algorithm for short.

(4) OnTaPRA: This online algorithm designs for pleasingly parallel jobs and considers energy consumption (Shi et al., 2017). The main idea of this algorithm is: according to the Shortest Job First policy, put the tasks on the instances with the highest efficiency as long as the constraints are not violated. In this way, the job completion time will be reduced. Meanwhile, the instance purchasing and cost are also not considered in this paper. Assuming that instances are fixed which are similar to users’ demands and energy consumption is not considered, we modify this algorithm and apply it to our problem as a comparison.

(5) Dynalloc: This algorithm considers to use self-owned, on-demand and spot instances at the same time to execute jobs, with the aim of cost optimization (Wu et al., 2020). The main idea of this algorithm is distributing the workloads equally among the entire deadline and minimizing the integer instance hours of on-demand instances. In this process, the algorithm uses the self-owned resources first, then the spot instances, and last the on-demand instances. To compare with our online algorithm, we consider on-demand instances only and schedule the jobs by the Shortest Job First policy when using this algorithm.

As shown in Fig. 7, our online algorithm achieves better performance compared with all the comparison algorithms when applying for a long period. In terms of  and , our online algorithm can achieve significantly better results compared to all the comparison algorithms. This is mainly caused by three reasons. First, variable resources. Algorithms PD, EDF and OnTaPRA assume fixed resources before the scheduling, which are actually hard to predict in advance. On the one hand, insufficient instances will limit the service capability of SaaS providers, such as PD-small. On the other hand, excessive instances will produce insufferable costs, such as PD-large. Thereby, SaaS providers should purchase instances dynamically according to real-time service requests rather than purchase a fixed number in advance. Second, the scheduling objectives. Objectives decide the acceptance and scheduling policies of algorithms. Algorithm PD only considers the objective of revenue maximization and ignores the user satisfaction rate. The goal of algorithm OnTaPRA is minimizing completion time. Algorithms Equal-opp and Dynalloc can purchase resources dynamically. However, they ignore the economic factors (e.g., valuations of jobs and instance costs) and serve users as much as possible rather than accept and schedule jobs according to . Thus, there is a money loss. Third, the online settings. In practical cloud environments, when making decisions, the future information about user arrivals and demands is unknown, which means current decisions could have good or bad implications for the future. Thus when designing algorithms, we need to consider these uncertainties fully and carefully. In the comparison algorithms, only PD and OnTaPRA consider the online settings. All these comparison algorithms cannot fit well with our problem.


Download : Download high-res image (582KB)
Download : Download full-size image
Fig. 7. Comparison with other algorithms.

In terms of , algorithms PD-large, EDF, OnTaPRA and Dynalloc obtain a larger user satisfaction rate. This is due to the fact that they have abundant instances to serve most users rather than purchasing instances and scheduling jobs selectively according to the objective . As a result, their  and  are lower than our online algorithm.

In summary, our online algorithm achieves better performance than all the five comparison algorithms and it can effectively deal with the market-oriented online bi-objective scheduling problem for pleasingly parallel jobs with variable resources in cloud environments.

6. Conclusions and future work
This paper focuses on the market-oriented online bi-objective scheduling problem for pleasingly parallel jobs with variable resources in cloud environments. With unique features of variable resources and online settings etc., the scheduling focuses on bi-objective: maximizing SaaS providers’ revenue and maximizing user satisfaction rate. To address this problem, we propose an algorithm to help SaaS providers to decide how to purchase instances and schedule jobs in an online way. Our proposed online algorithm is computationally efficient and can achieve a good competitive ratio. The efficiency is verified through theoretical analysis and extensive simulations. Nowadays, most IaaS cloud platforms also support some other instances such as reserved and spot instances, which are suitable for different situations. In the future, we plan to take other instances into consideration and design efficient algorithms to solve scheduling problems in more complicated cloud environments.