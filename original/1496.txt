Abstract
The booming advances of cloud computing promote rapid growth of the number of cloud service Application Program Interfaces (APIs) published at the large-scale software cloud markets. Cloud service APIs recommendation remains a challenging issue for a composite cloud system construction, due to massively available candidate component cloud services with similar (or identical) functionalities in the cloud markets. As for a specific user, the probability distribution of the data indicating his/her preferences to the cloud service APIs may change with time, resulting in concept drifting preferences. To adapt users’ preference drifts and provide effective recommendation results to composite cloud system developers, we propose a concept drift-aware temporal cloud service APIs recommendation approach for composite cloud systems (or CD-APIR) in this paper. First, we track users temporal preferences through users’ behavior-aware information analysis. Second, we utilize Singular Value Decomposition (SVD) method to predict the missing values in the user–service matrices. Third, we identify the degree of users preference drifts by Jensen–Shannon (or JS) divergence. Finally, we recommend cloud service APIs by presenting a piecewise trading-off equation. Experimental evaluations conducted on WS-Dream dataset demonstrate that the CD-APIR approach can effectively improve the accuracy of cloud service APIs recommendation comparing with 7 representative approaches.

Previous
Next 
Keywords
Application Programming Interfaces (APIs)

Cloud service recommendation

Preference drift

Temporal recommendation

User behavior

User preference

1. Introduction
With the rapid advent of the cloud service industry, the fast growth of public available SOAP-based and RESTful cloud service Application Program Interfaces (APIs) has inspired the development of large-scale cloud service API markets (Bouguettaya et al., 2017). To name a few, there are ProgrammableWeb,1 api-platform,2 Alibaba Cloud Market,3 etc. With the help of service composition techniques, developers can select, rent, and then assemble cloud service APIs to build new and value-added composite cloud systems based on these cloud markets. Consequently, API mashups and composite cloud system applications are more and more popular recently (Lemos et al., 2016, Niu et al., 2017, He et al., 2017).

There are massive APIs with similar (or identical) functionalities but different Quality of Service (QoS) in the cloud markets (Zheng et al., 2010a, Wang, 2019). The non-functional requirements of different users (i.e., the composite cloud system developers) to the APIs are diverse. With the fast increase of the number of cloud service APIs and their information (i.e., service descriptive information, price, and QoS, etc.), information overload in the distribution and retrieval of cloud service APIs is a critical problem that should be investigated (Cao et al., 2020, Zhang et al., 2018b, Wang et al., 2018). Service selection decision should be made over the big data-space APIs’ non-functional information to match the user preference and the heterogeneous APIs information. To this end, an effective cloud service APIs recommendation based on data science techniques is urgently desired by users, cloud service APIs providers and the cloud market platforms (Wang et al., 2016, Ding et al., 2018).

Different from the traditional service provider-driven Web and/or Cloud service markets, the large-scale cloud service APIs market is more open and dynamic. Under the large-scale cloud APIs markets, the non-functional information of each API dynamically changes. For budget changes, application requirement changes, interest changes, etc., the users’ preferences to the APIs’ non-functional attributes may also change with time. Suppose that the users’ preferences for different APIs are expressed as a user–service rating matrix, where each row represents the user’s ratings to the APIs and each column represents an API’s ratings by different users. Changes, gradual or sudden, of the APIs information and the user’ preferences make the distribution of the users’ rating information to the cloud service APIs change with time, resulting in concept drifts of user preferences (Barddal et al., 2017, Lu et al., 2019, Gama et al., 2014). Traditional Web and/or Cloud service recommendation methods do not consider the issue that user preferences may drift, resulting in reduced accuracy of the traditional recommender models (Cao et al., 2009). Cloud service APIs recommendation for large-scale cloud markets while considering the preference drifts is a challenging issue.

First, it is difficult to track the users’ preference drifts. User preferences change over time. Concept drifts may take place in user preference data streams. Moreover, preference drifts are caused by hidden variables that cannot be directly measured. The direction of drifts (positive or negative) is unforeseen and different for each user. When the recommender model cannot adapt to the users’ preference drifts in time, the accuracy of the recommendation results will reduce accordingly.

Second, the traditional recommender models assume that user preferences are static. That is, users’ history information, regardless of the time of occurrence, plays an identical role in predicting current user preferences. However, the concept drifts of users’ temporal preferences are commonly seen during a period of time (Zhang et al., 2016). When user preferences drift, traditional recommender models use the original data blindly, resulting in suffering a significant reduction in performance.

Third, APIs’ QoS evaluation information collected via users’ feedbacks or reported by API providers may be biased. Identification of user preferences by requirement elicitation techniques may also be incomplete or incorrect. More useful information for constructing the recommender model should be analyzed based on users’ historical behavior data.

To the best of our knowledge, this is the first work that considers the effect of concept drifting preferences for cloud service APIs recommendation. Traditional Web and/or Cloud service recommendation approaches mainly predict quality of service (QoS) and user preferences through collaborative filtering (CF) algorithm, including user-based recommendation, item-based recommendation and integrated users and services recommendation (Zheng and Lyu, 2013, Zhang et al., 2018a, Zhang et al., 2018b). User-based CF recommends services by identifying similar users. It relies on users’ ratings of services to calculate similarity, or relies on purchasing the same services to cluster users. However, the users’ reported rating information may be not reliable and complete, and users may maliciously submit feedback information (Somu et al., 2018, Yao et al., 2015). Clustering users through the same service purchased may suffer from the cold-start and data sparsity problem. Item-based CF is also not applicable to the cloud service APIs recommendation. In the large-scale cloud service APIs markets, users often purchase composite cloud service APIs when developing composite cloud system applications. Moreover, users seldom repeatedly purchase cloud service APIs that are extremely similar to the purchased ones. Therefore, the recommendation of the cloud service APIs should make some changes in the service-based CF to avoid recommending similar APIs repeatedly (Qi et al., 2019a). Some recommendation approaches integrate users and services. They mainly combine QoS data of similar users and similar services to predict user preferences. However, due to the data sparsity problem in the large-scale cloud markets, the recommendation results will be inaccurate.

To summarize, existing service recommendation methods predict user preferences through users’ feedback data and/or purchased data. The identified preferences for specific users are static. However, as for a composite cloud systems developer under a large-scale cloud service APIs market, when renting cloud service APIs, his/her preferences may drift over time. The recommended services obtained by traditional approaches cannot accurately track preference drifts and meet the users’ dynamic changing demands, which will deteriorate the accuracy of recommendation approaches over time (Zafari et al., 2019). For the uncertainty of preference drifts, the degree of a preference drift impacts the accuracy of recommender model in different degree. A minor drift has little impact on the recommendation results, while a major drift impacts significantly. A model adaptation decision must be carefully made. An online learning mechanism is essential for the recommender system to stay with the current user preferences.

To deal with this above issue, we propose a concept drift-aware temporal cloud service APIs recommendation approach for building composite cloud systems (or CD-APIR) under the large-scale cloud market environments. CD-APIR tracks changes in user preferences through the temporal behavior-aware information, and combines the results of preference drift detection with cloud service APIs recommendation to generate recommendation results. The contributions of this paper are summarized as follows.

•
We model the degree of preference drift of a specific user by calculating the distance of two preference data stream distributions in neighboring time windows.

•
We analyze the behavior-aware information including users’ selecting, tracking, purchasing, and evaluation records and mark the time at which users’ behaviors occur with timestamps to predict the missing values in the user–service matrices based on Singular Value Decomposition (SVD).

•
We propose CD-APIR, a concept drift-aware temporal cloud service APIs recommendation approach for building composite cloud systems. Jensen–Shannon (or JS) divergence is utilized to identify the degree of preference drift for the users. A piecewise equation is presented to make trade-off decisions between the previous user preferences and the drifted up-to-date user preferences to make recommendations.

•
We conduct extensive experiments on WS-Dream dataset to verify the effectiveness of the proposed approach. Experimental results compared with 7 respective approaches show that our approach takes advantage of the temporal behavior-aware information and improves the recommendation accuracy, which sheds some light on a new way to make cloud service APIs recommendations.

The remainder of the paper is organized as follows. We give a motivating example of preference drift in Section 2. We summarize the related works done on service recommendation and interest drift in Section 3. We introduce the modeling approach of preference drift in Section 4. In Section 5, we present the CD-APIR approach in detail. Section 6 gives the experimental evaluations. Finally, Section 7 concludes the paper with some future directions.

2. Motivating example
Suppose that an application developer, say Alice, wants to develop an advanced composite cloud system app for weather forecasting by integrating open cloud service APIs. As illustrated in Fig. 1, during the early stage of the development, Alice prefers to the following four basic APIs to build the system. (1) Address identification APIs (
), which are used to identify the location of the user to provide default weather forecasting result; (2) Search APIs (
), which are used to search for the target city to provide the city’s weather forecasting result; (3) Map APIs (
); and (4) Obtaining weather APIs (
). During this stage, the recommender system should only recommend the above four types of APIs to Alice. With the system implementation, Alice may want to enhance the user experience of the system. Her interests to the APIs may drift. She may prefer the following four APIs. (1) Weather-related sound effects APIs (
), which are used to provide some auditory stimulations to the users; (2) View design APIs (
), which are used to enrich the users’ visual stimulation; (3) Short message services (or SMS) APIs (
), which are used to send reminders of weather warning to the users; (4) Authentication and encryption APIs (
), which are used to protect user privacy and solve the security problems. To satisfy Alice’s drifted preference, the recommender system needs to recommend these recently preferred APIs to her. If the recommendation is still based on the previous preference model, the drifted new preference of Alice may be ignored. The recommender system needs to identify the preference drifts in real-time to enhance recommendation accuracy.

3. Related work
In this section, we review some relevant existing works that significantly inspired our proposed CD-APIR approach which include service recommendation and interest drift.

3.1. Service recommendation
CF is one of the current popular service recommendation methods. After calculating the similarity, CF mainly use the similarity to filter out the items with low similarity by a fixed threshold. Then it predicts and fills in the missing values of the user–service matrix based on the existing ratings, QoS values, context and other data of users or services with high similarity (Zhang et al., 2018b, Xu et al., 2016).

Content-based recommendation mainly recommends services similar to those selected in the past. Knowledge-Based recommendation uses a similar function to construct a knowledge network to estimate how much the user’s demands match the recommendations. The combination of machine learning and collaborative filtering is a relatively popular recommendation approach recently (Zhang et al., 2019, Qin et al., 2020, Xia et al., 2015, Batmaz et al., 2019).

To solve the problem of data credibility, Su et al. (2017) paid attention to the problem of unreliable QoS data contributed by dishonest users, and proposed a trust-aware approach, namely TAP. It is used to predict reliable personalized QoS, which combines QoS data of trustworthy similar users and similar services to make prediction for active users. Somu et al. (2018) focused on cloud service providers (CSP), and proposed a Hypergraph Binary Fruit Fly Optimization based service ranking Algorithm (HBFFOA) to identify suitable service and trustworthy CSPs that meet user demands by similar CSPs.

To improve the accuracy and diversity of APIs recommendation results, Cao et al. (2020) proposed an integrated content and network-based service cluster and Web APIs recommendation approach, which utilizes the implicit co-invocation relationship between Web APIs inferred from the historical invocation between Mashups and Web APIs to recommend diverse Web APIs for each Mashups clusters. Qi et al. (2019a) paid attention to the efficiency of APIs recommendation and compatibilities between different Web APIs. They analyzed the input keywords describing the functions expected by application developers, and defined a weighted APIs correlation graph (W-ACG), and proposed a Keywords-based and Compatibility-aware APIs Recommendation (K-CAR) approach.

To address the problem of QoS instantaneity, that is, the QoS changes frequently over time, Ding et al. (2018) combined the CF and the ARIMA model to capture the temporal feature of user similarity and solve the data sparsity in the existing PITs (point in time) approach, and then predict the QoS values in the future PIT under QoS instantaneity. The work in Qi et al. (2019b) combined time factor and privacy protection for service recommendation.

Existing service recommendation approaches rarely consider the occurrence of preference drifts. User preferences change dynamically, and it may drift with some unmeasured variables. Solely filling missing values based on user similarity is not applicable in the cloud service API market, which cannot address the data sparsity. If users do not purchase similar services, the recommender system cannot cluster them. In addition, the cloud market will have increasing users without sophisticated programming knowledge (Yao et al., 2015). This may make users’ self-description information unreliable, which will reduce the accuracy of user-based recommendation.

3.2. Interest drift
The preference drift researches in traditional recommender systems mainly focus on reasoning the changes of user preferences to predict users’ future interests. Yin et al. (2016) focused on the phenomenon of user interest drifts across geographic regions, and proposed Spatial–Temporal LDA (ST-LDA) to enhance the inference of region-dependent personal interests through effectively exploiting the social and spatial correlation information. Zafari et al. (2019) considered the dynamics of preferences and the reasons for changes in user preferences, and proposed a latent factor model to capture the domain-dependent component-specific temporal patterns in preferences. Wangwatcharakul and Wongthanavasu (2018) used item clustering and linear regression techniques to predict the future interests of users by categories and Gaussian mixture models to fill the data matrix to solve data sparsity problem. To detect interest drifts, Cao et al. (2009) constructed a rating graph and a rating chain through the similarities between rated items to identify the type of a given user’s interest pattern for improving recommender systems.

Considering the changes of user preferences, especially the problem of concept drift, the learning model for cloud service APIs recommendation faces a hidden technical debt issue, i.e., the recommender system needs to continuously make new technical efforts to update the model to learn from new data (Sculley et al., 2015). Training new recommender models results in wasting model learning time and raising the operation and maintenance costs of the recommender system. In contrast to the code level issues, this debt may be difficult to be resolved because it is based on the system level data analysis.

To summarize, the existing recommender models assume that the users’ behavior information is static. Users’ historical behavior information is utilized to predict user preferences (Cao et al., 2020, Huang et al., 2018). However, they ignore that users’ preferences may change over time. When predicting the users’ preferences, the latest behavior information may play a more important role. To deal with the incomplete and vague item features and user-interest drifts, the existing interest drift-aware approaches perform fuzzy recommendations based on preference drift detection (Zhang et al., 2016, Zenebe et al., 2010, Cornelis et al., 2007). For the dynamics of user interests, users’ preferences to the APIs may change to different degrees over time. It is particularly important to study online adaptive recommendation methods based on accurately measuring the degree of preference drifts in real-time.

In this paper, we propose CD-APIR, which is an online adaptation approach to deal with preference drifts. The model adaptation is realized by the degree of preference drift detection and the trading-off piecewise equation. Online capturing the degree of preference drifts and updating the learning model for cloud service APIs recommendation may be one of the possible ways to address the technical debt problem of machine learning models. The proposed CD-APIR approach combines degree of preference drifts detection and drifts adaptation to predict the users’ real-time ratings to the APIs for cloud service APIs recommendation. CD-APIR contributes to more accurately predict the user preferences in real-time for temporal cloud service APIs recommendation.

4. Preference drift modeling
Given 
 as the set of users, and  is the total number of users registered in the large-scale cloud market (), we define 
 as the cloud service API set, where  is the total number of cloud service APIs published in the market ().

When users select, track, purchase, and evaluate services, they will generate temporal behavior-aware information about certain services. Each behavior establishes a connection between the user and the service, which can be recorded in the website’s server logs. These connections turn into the basic component of the user–service matrix.

Preferences indicate the users’ willingness to purchase services, which include both the selected and unselected cloud service APIs. The ratings are usually used to quantify the user preferences for them. Hence, we define the user preference to a specific API as the rating of the service 
 evaluated by the user 
, which is denoted by 
. The preference of a user  to all the APIs is defined as (1)
where  represents the -dimensional feature vector of all the cloud service APIs in a cloud market, and  represents the label, that is, the user 
 (
).

In particular, the user–service matrix is depicted in Fig. 2. It should be noted that each user only buys a few cloud service APIs from the market. For instance, during the early stage of developing the weather forecasting composite cloud system presented in Section 2, Alice may only prefer to and search for the APIs of 
, 
, 
, and 
. There is no browsing or usage information for other APIs in Alice’s historical behavior information. As a result, the user–service matrix is generally sparse (Cao et al., 2020, Yu et al., 2015).

Definition 1 Temporal User Preference

We define the temporal user preference of user  at a given time window  as (2)

Temporal behavior-aware information usually changes over time, thus we use a preference data stream to describe the sequence of ratings changing over time, where the order in which the preference appears is specified by a timestamp (Zafari et al., 2019).

Definition 2 User Preference Data Stream

Given a time period , user ’s preference data stream is defined as 
.

We give the following example to demonstrate the preference drift. Suppose that, in the early stage of the composite cloud system development, Alice formerly preferred to the APIs 
, 
, 
, and 
. In this stage, the temporal user preference of Alice is described as 
. When time goes to the system implementation stage, the temporal user preference of Alice would change to 
 (i.e., more prefers to 
, 
, 
, and 
) and 
 is higher than the fixed threshold . At this time, we can say that Alice’s preference has drifted. This is a realistic example of preference drift. We give the following definition of preference drift.

Definition 3 Preference Drift

Given a user  and its preference data streams 
, for , if 
, it is identified that there is a preference drift of user  at time window , where  measures the distance of two preference data stream distributions in different time windows, and  is a threshold value.

For example, suppose the user originally preferred to the services with high QoS, but the budget became tight due to some unknown reasons that recommender systems cannot measure. Then the user changed to focus on APIs’ prices and relax requirements for services’ performance. Preference drifts may not only change from preferring QoS to price, but also from preferring the type of interface to location, etc.

Definition 4 KL Divergence of Neighboring Temporal Preferences

We use Kullback–Leibler (KL) divergence (or relative entropy) to measure the dissimilarity between the distributions of corresponding user preferences in each neighboring time window’s matrix (Wang and Zhou, 2013, Dasu et al., 2006, Sebastião and Gama, 2007, Chen et al., 2017). The KL divergence of neighboring temporal preferences is defined as (3)
 
where 
 is the distributions of user ’s preference at time window , that is, ’s ratings of all services, which is generated by the approach proposed in Section 5.2.  and  are allocated by timestamps.  is the set of cloud service APIs. 
 is the distance between these two distributions, and 
.

The larger value of 
 indicates that the distributions of preferences in two time windows ( and ) are more different. If 
, 
 (MacKay and Mac Kay, 2003).

Noting that, the evaluation criteria provided by different users are different. This makes the distribution of different user preferences data stream 
 varies. The data variety results in a heterogeneous distribution of 
 values, which is not conducive to the comparison of the degree of preference drifts in a uniform metric. To address this issue, we utilize the min–max normalization to transform the 
 values to a uniform dimension with the range of . In this way, we will ensure that a larger value can indicate more serious preference drifts. We define the following  function to measure the degree of preference drift.

Definition 5 The Degree of Preference Drift

The degree of preference drift aims at providing a normalized value to measure the divergence between the preference distributions (Lu et al., 2019). Formally, the degree of preference drift 
 is defined as (4)
 
where 
 and 
 are the minimum and maximum 
 values of all users, respectively. The larger the value of 
, the larger degree of preference drift.

5. CD-APIR approach
In this section, we present the concept drift-aware temporal cloud service APIs recommendation approach for building composite cloud systems (or CD-APIR).

5.1. Overview of the recommender model
The recommender system needs to recommend the users’ preferred cloud service APIs by mining the hidden demands of users. The CD-APIR tracks changes in user preferences through temporal behavior-aware information, models the evolution of users preference, and then combines preference drifts with cloud service APIs recommendations (Liu, 2015).

As illustrated in Fig. 3, CD-APIR utilizes the behavior-aware information such as selecting, tracking, purchasing and evaluating to establish the connections between users and services. At the same time, timestamps are used to mark the time of user behaviors, and different time windows are allocated to form multiple time-based user–service matrices. Missing values are filled with Singular Value Decomposition (SVD) in user–service matrices. Subsequently, the recommender approach detects whether the user preference distributions have changed in different time windows, and measures the degree of preference drifts. The results of the preference drift detection are combined with the user–service matrices of different time windows to predict user preferences. Finally, recommended cloud service APIs are returned to target user.

5.2. Temporal behavior-aware information
To build the CD-APIR model, we need to collect and pre-process the user data and service data in the cloud vendor-driven API market. The recommender system needs to predict user preferences, that is, the APIs’ users may be interested in.

First of all, we extract user purchase, evaluation, QoS values and other records to establish user–service matrices. Every time a user purchases a certain cloud service API, a connection will be established between the user and this cloud service API. As a result, the ratings will be filled into the user–service matrix. If the user has not yet provided a rating on the website, recommender system uses the QoS value (
) evaluated by the user  of the invoked service  to fill in the user–service matrix. 
 needs to be normalized and converted into a rating, which can eliminate dimensions of each value and unify tendencies. We utilize the min–max normalization to map the values into the range of . For the indicators that bigger is better (5)
 
As for the indicators that smaller is better (6)
 
where 
 is the normalized rating user  gives to the service  (this equation is only applicable when the user has not provided an actual rating). 
 and 
 are the minimum and maximum QoS values of the services evaluated by all users, respectively. The user–service matrix is shown in Fig. 4(a). However, the user–service matrix is often sparse, and there are a lot of missing values in it.

We need to obtain more user–service connections through users’ behavior-aware information, such as selecting, searching and tracking (other than purchase and evaluation). Taking ProgrammableWeb as an example, when a user clicks on the “track API” in the website, this API will be added to the user’s watchlist. Through the watchlist, we can know what services the user may be interested in and build more user–service connections.


Download : Download high-res image (480KB)
Download : Download full-size image
Fig. 4. Temporal user–service matrices formation process.

However, unlike the user’s purchase and evaluation records, when the user tracked an API, we cannot know the user’s evaluation or the QoS value of the API, because the service has not been purchased and invoked. The user–service connection (the colored part in Fig. 4(b)) can be established by behavior-aware information. Since the users’ usage evaluation is unknown, we need to predict the users’ ratings.

We can deal with this problem through associated services. It is worth noting that, as mentioned above, the large-scale cloud markets are different from other markets. Users may seldom purchase cloud service APIs with the same functions. Unless for some fault-tolerance applications, user may need to bind some redundant APIs. However, this situation is rare.

We can extract service information from the server log or crawl them from the Web pages of the software cloud market to construct a service matrix. We associate APIs through combinations of services purchased by users. As shown in Fig. 5, 
 are clustered composite APIs. We take the user’s evaluation of the purchased service 
 to predict the user’s evaluation of 
, 
 and 
. The user may track a service at time , but has not purchased any service in the composite APIs. For example, the user tracked 
, but the user has not yet purchased 
, 
 or 
. We cannot get the relevant ratings from composite APIs. But we can predict the rating by (7)
where 
 is the similarity between 
 and 
, which is calculated by Pearson Correlation Coefficient (PCC) (Elahi et al., 2016), 
 is the 
’s evaluation of service , 
 is a group of users that are the most similar user 
 who have purchased service ,  is a normalization factor, and (8)
 

Then, through the established user–service connections, we predict user preferences for all unselected services. The matrix decomposition algorithm is cast as the state-of-the-art approach for its performance of filling the missing values for a large-scale sparse matrix and solving the problem of data sparsity. The advantages of SVD are to save computing resources and reduce noise. As illustrated in Fig. 6, in the recommender system, we do not have to use all the singular values, but select the largest  singular value to re-construct the matrix, which can basically express the original matrix.


Download : Download high-res image (66KB)
Download : Download full-size image
Fig. 6. Singular Value Decomposition for user–service matrix.

Hence, we perform SVD to fill the user–service matrix (
). Before SVD, the average value of each user’s ratings is subtracted for each service. Suppose 
 is the user–service matrix, where  represents the user,  represents the candidate service. Each value 
 in matrix 
 represents the preference of the user for each service in a certain time window.

Specifically, we decompose 
 by solving the following equation. (9)
where  is much smaller than  and . Thus, a large matrix 
 can be represented by three small matrices 
, 
 and 
, respectively.

In this way, SVD takes only the first few singular values to re-construct. It saves storage usage and calculation time, and reduces noise and server’s computing load for the cloud service APIs recommender system. The user–service matrix is shown in Fig. 4(f).

Now we can only identify the user’s preference during a period. However, when Alice’s preference change from preferring 
, 
, 
 and 
 to preferring 
, 
, 
, and 
, the change need to be extracted by the recommender system in real-time. Those new APIs should be recommended to Alice based on her drifted preference.

To this end, we need to analyze user preferences in different time windows. As illustrated in Fig. 7, there are many ways to allocate the time windows, and  represents the user–service connections at different times. Old time window represents the matrix constructed by user–service connections, occurring in certain period (from  to ), followed by the construction of multidimensional matrices over time. Each matrix represents user preferences at each time window. The occurrence of preference drifts are detected by analyzing user preferences in different window periods.

In Fig. 7(a), the starting points of two windows are fixed, while the ending point of two windows will be extended over time. We can also perform drift detection by comparing the most recent time window with the overall time window (as shown in Fig. 7(b)). Here the starting point of the old window is fixed. The ending points of the old window, the starting point and the ending point of the new window extend over time. In addition, when analyzing users’ preference drifts, multiple windows can also be allocated, this method can accurately obtain the time at which the preference drifts occur. As shown in Fig. 7(c), if 
, it indicates a greater degree of preference drift for user  at time .

The window allocation method can be decided according to the characteristics of the large-scale cloud markets. The window duration should not be too short, because a preference drift may not only take place at an exact timestamp but also last for a long period (Lu et al., 2019). Given the analysis of the problems studied in this paper, concept drift-aware recommendations need to address data sparsity and amplify the role of new window’s user preferences (Koren, 2009). Therefore, the second method (i.e., Fig. 7(b)) is more appropriate for solving these problems. After choosing this method to allocate the windows, we obtain the user–service matrices to describe the user preferences (see Fig. 4(e)).


Download : Download high-res image (247KB)
Download : Download full-size image
Fig. 7. Time windows for preference drift detection.

5.3. Preference drift detection
Preference drift detection is mainly used to evaluate the degree of preference drifts. The recommender system needs to detect the distribution changes of user preferences in different periods. When the recommender system finds that there is a degree of preference drift for some users, it need to update the predicted user preference to adapt to the drift.

After obtaining the user–service matrices, we need to calculate the dissimilarity of ratings in different time windows to measure the degree of drifts. When we allocate the two windows (old and new), preference drift detection can be understood as a two-sample detection problem. That is, it examines whether the population of two given matrices (also known as the sample sets) are from the same distribution.

Preference drift detection aims at identifying a shift in user preference distribution (Lu et al., 2014). According to Definition 5, 
 is the degree of preference drift between the distributions of the user’s old preference and new preference, which is calculated by Eq. (4).

The advantage of KL divergence is that it can not only report a warning when a preference drift occurs, but also provide the degree of the drift. However, KL divergence cannot be used as a strict distance measurement. Noting that KL divergence is not symmetric under the interchange of the distributions 
 and 
: in general 
 (MacKay and Mac Kay, 2003), which does not satisfy the symmetry requirements for distance measurement. We make some improvements and introduce Jensen–Shannon (JS) divergence to calculate the distance between the temporal user preference distributions. Unlike KL divergence, JS divergence is symmetrical and it can be used to measure the distance between distributions (Lin, 1991). At this time, we can obtain the degree of preference drift for each user by JS divergence as (10)
 
 
 
 
 where 
 is the distance between these two distributions (its range is ). The larger it is, the larger the degree of preference drift. A larger degree of preference drift means that the user’s preference has a larger degree of change. When we predict users’ ratings, we need to pay attention to the role of new preference distribution with larger JS divergence, because they are likely to be more in accord with the current user preference distribution.

5.4. Preference prediction
Users’ preference drifts can be tracked through preference drift detection. The recommender system amplifies the role of the users’ preference in the most recent period, and then performs user preference prediction, finally recommends APIs with high prediction ratings to the user. In this paper, we do not need to update the recommender model in the case of preference drifts. CD-APIR can online adapt to the new preference by a trade-off decision.

Specifically, the JS divergence is combined with the user–service matrices of different time windows to generate recommendation results. The recommender system compares the distance of user preference distributions in different time windows. According to Definition 3, when 
 is not lower than a fixed threshold , it indicates that the user preferences have drifted, and the role of the preferences at new time window needs to be considered.

In particular, when 
, we make a trade-off to combine the two time windows’ preference distributions and predict the user preference by (11)
where 
 is the user ’s final predicted rating for service , 
 and 
 represent the ratings in user–service matrices 
 and 
 in two time windows, respectively.  is a fixed threshold, and the range of its value is .

Furthermore, when 
 is less than the fixed threshold , it implies a minor drift. In general, this preference drift may be caused by abnormal data due to inaccurate user feedbacks, measurement errors, etc. In fact, user preference has not really drifted in this situation, and the drift need to be further observed and verified. It will be more accurate to use the original predicted preference.

In contrast, when 
, it indicates that user preferences drift dramatically, and the predicted old time window’s preferences have expired, that is, it cannot meet user demands at present. Recommendation should consider the users’ interest in the most recent period.

To ensure the stability of the recommender system, we further define the following piecewise equation for the above two conditions. (12)
 

To summarize, given the complex user preference drifts, the two time windows’ preference distributions are combined in Eq. (11) in order to more accurately tap the hidden demands of users. To further improve the accuracy of recommendations, we define Eq. (12). In Section 6.7, we will further verify the recommendation effectiveness for the piecewise equation.

Finally, through the predicted user preference, the Top- cloud service APIs are recommended to users. It is worth to note that, to avoid repeatedly recommending APIs that are the same as the user have purchased, the recommender system should exclude the purchased APIs from the recommended results.

6. Experiments
In this section, a set of experiments are conducted to evaluate the CD-APIR approach. To assess the effectiveness of the proposed approach for large-scale cloud service API markets, experiments were performed on a large-scale open service dataset. All the experiments were implemented using Python 3.7.3 on win32, with CPUs of 2.2 Ghz and 8 GB RAM. The operating system is Windows 10. To help other researchers repeat the experiments in this paper, we have published our implementation of CD-APIR and the competitors on Github, which is available at https://github.com/InBSLab/CD-APIR.

6.1. Dataset
In the experiments, to simulate actual API application scenarios, WS-Dream4 dataset is adopted. The dataset collects 5825 services’ performance data in 74 countries. All the services can be cast as RESTful or SOAP-based cloud service APIs. These services are accessed by 339 users in 31 countries. These data have actual response time (RTT) and throughput.

We calculate QoS values through RTT and generate user–service matrices. We normalize them by Eq. (6) to convert them into ratings. In this way, the maximum value of the user–service matrix is 5, which represents that service  is the most satisfactory for user . The minimum value is 0, which is the unsatisfactory service. Since there is no timestamps in the dataset, to simulate the real purchase environment, we selected ratings’ timestamps from the Movielens5 dataset and then mapped them to WS-Dream dataset. Preference drifts are caused by hidden variables that cannot be directly measured, therefore, we use the most recent 20% ratings as the user preferences for the new time window.

However, the matrix generated by the WS-Dream dataset is dense. To verify the recommendation effectiveness of our proposed approach in the face of data sparsity, we sorted and removed 50% of the data with lower ratings due to users will not choose unsatisfactory services. The experimental results were obtained by comparing the actual services of the test data with the predicted recommended services (Zheng et al., 2014, Zheng et al., 2010b).

6.2. Metrics
We define the following metrics to evaluate the effectiveness of the recommendation approaches.

(1) Accuracy. Accuracy is the most important evaluation criterion for recommender systems. This metric can directly reflect the quality of cloud service APIs recommendation approaches. In this paper, we define the following metrics (precision, recall and F-measure) to evaluate the accuracy of the recommender results. (13)
 
(14)
 
(15)
 
 where 
 represents the list of cloud service APIs actually selected by the user, and 
 represents the list of cloud service APIs generated by the recommender system.

(2) Coverage. This metric measures the coverage of all the cloud service APIs by a recommender system. It describes the ability to discover services in the long tail. Coverage is often used in conjunction with accuracy, as the recommender system cannot give a poor accuracy in order to improve coverage. It is the ratio of cloud service APIs list  that the recommender system can recommend in the total API set . Coverage is calculated by (16)
 

(3) Reaction time. The reaction time describes the average recommendation time to return the generated recommender list to a single user. The recommender system needs to present cloud service APIs to the user in the shortest possible time.

6.3. Approaches under comparison
Relevant existing works of cloud service recommendations mainly rely on Singular Value Decomposition, Collaborative Filtering, Hot services, PersonalRank, etc., as the primaryapproaches. Moreover, Euclidean distance and Wasserstein distance are representative data distribution-based concept drift detection approaches. These methods are all available for the concept drift-aware temporal cloud service APIs recommendation. Accordingly, to evaluate the effectiveness of the proposed approach, we implemented the following 7 respective approaches for cloud service APIs recommendation for comparison purpose. Specifically, the 7 approaches under comparison include:

•
SVD: The matrix decomposition algorithm is considered as a popular approach for its excellence in filling missing values for large-scale sparse matrices (Qin et al., 2020, Ba et al., 2013). SVD reduces the dimensionality of the user–service matrix, which can alleviate the problem of data sparsity. We perform SVD on the matrix to predict user ratings, then exclude services that are same as purchased services, and finally recommend the services with the highest ratings.

•
User-based CF: CF recommends services by predicting user preferences. User-based CF recommends services by identifying similar users. We rely on purchasing the same services to cluster users. It then predicts the APIs that users are interested in through the choices of similar users (Lin et al., 2014).

•
Item-based CF: In the large-scale cloud markets, users tend to assemble and build composite cloud system. Item-based CF measures similarity between APIs and predicts the user’s interest in them by the attributes of the user who selects them. The key to this approach is to mine and recommend composite APIs (Zheng et al., 2010a).

•
Hot: Recommendation based on popular cloud service APIs for keyword-based search is also a essential approach. According to the statistical results, a small number of popular APIs are frequently used in mashups by many users (Cao et al., 2020, Yao et al., 2015). That is, certain popular cloud service APIs can meet the demands of most users, such as maps and SMS verification codes. In addition, on the homepage of the website, it is necessary to present some popular services to mine the potential demands of users. If users find satisfactory services on the homepage, it will benefit the users’ search efficiency and increase the users’ loyalty to the large-scale cloud market. In this paper, Hot sorts cloud service APIs by the popularity and return them to users.

•
PersonalRank: The PersonalRank algorithm is proposed to map the relationship between users and services, such as selecting, purchasing and evaluating records, into an undirected bipartite graph (Hu et al., 2018). From the users’ nodes, it uses the graph link structure to recursively calculate the importance of each node. The relevance and importance of network nodes can be calculated based on the source node. The higher the PersonalRank value, the higher the importance of the source node.

•
ED-CDD: After allocating time windows, Euclidean distance-based concept drift detection approach (ED-CDD) is used to detect the distribution changes of user preferences. Euclidean distance is commonly used to calculate users’ similarity or services’ similarity in recommendation algorithms (Auch et al., 2020, Dhawan et al., 2015, Gao et al., 2017). In this paper, we use the Euclidean distance to measure the degree of preference drifts as a comparative approach.

•
WD-CDD: Wasserstein distance is commonly known as earth mover’s distance (EMD) (and also referred to as the “transportation metric”) (Goldenberg and Webb, 2019). Existing study has combined it with CF to address item cold-start problem (Meng et al., 2020). In this paper, after SVD predicts ratings and fills the missing values, Wasserstein distance-based concept drift detection (WD-CDD) is used to calculate the similarity of user preferences in different time windows to detect the degree of preference drifts.

6.4. Performance comparison
In the experiment, we compared the proposed CD-APIR approach with 7 respective approaches, through measuring precision, recall, F-measure, coverage and reaction time, respectively. We set the   60%, Top-  10, and   0.1. The experimental results are shown in Table 1.

Before running the algorithm, we subtract the average value of each user’s ratings from their ratings for each service selected. When the matrix is decomposed, the missing values in the matrix will be filled. However, we find that if the rating interval is  and the missing value is 0, the missing values will be replaced by values close to 0. After we subtract the average value, 0 becomes the average rating, and the processing of the output results will also become convenient. Ratings for services unselected (i.e. the null values) in the matrix are not subtracted.


Table 1. The results of performance comparison.

Metrics	CD-APIR	SVD	User-based CF	Item-based CF	Hot	Personal-Rank	ED-CDD	WD-CDD
Recommendation time	0.00307	0.00570	0.27906	17.02120	0.00037	0.00181	0.00320	0.00326
Precision	0.82035	0.80708	0.36431	0.73068	0.08348	0.18555	0.80944	0.80943
Recall	0.02780	0.02735	0.01369	0.02746	0.00283	0.00629	0.02742	0.02742
F-Measure	0.05377	0.05290	0.02639	0.05294	0.00547	0.01216	0.05305	0.05305
Coverage	0.20670	0.18884	0.05428	0.07088	0.00172	0.18238	0.19158	0.19193

Download : Download high-res image (356KB)
Download : Download full-size image
Fig. 8. The impact of parameter .


Download : Download high-res image (395KB)
Download : Download full-size image
Fig. 9. The impact of parameter Top-.


Download : Download high-res image (357KB)
Download : Download full-size image
Fig. 10. The impact of parameter .

From the results, we can know that, the CD-APIR is superior to other methods in accuracy (precision, recall and F-measure) and coverage. The precision of the CD-APIR has 1.09% improvement over two concept drift detection approaches of ED-CDD and WD-CDD, 1.33% improvement over SVD, 8.97% improvement over Item-based CF, 45.60% improvement over User-based CF, 63.48% improvement over PersonalRank, and 73.69% improvement over Hot. After taking preference drifts into consideration, allocating time windows and detecting the degree of drifts, all the data distribution-based concept drift detection approaches (CD-APIR, ED-CDD and WD-CDD) perform better. For drift detection, JS divergence is superior to Euclidean distance and Wasserstein distance. This indicates that JS divergence is more suitable for cloud service APIs recommendation. Furthermore, Item-based CF is more applicable to recommend cloud service APIs than User-based CF.

The recall, F-measure and coverage are also superior to the other 7 comparative approaches. The reason why these metrics is low in all experiments is that the number of recommended services (Top-) is few. In the parameter analysis in Section 6.6, we find that as the number of recommended services increases, recall, F-measure and coverage gradually increase.

In terms of coverage, the CD-APIR is more practical, as it can guarantee the effectiveness of the results on the basis of recommending more services.

In addition, the CD-APIR is superior in recommendation time, reducing the time to return the recommender list to a single user. When the CD-APIR shows superlative performance in terms of reaction time, it maintains excellent accuracy. Although Hot, User-based CF and PersonalRank performs better in recommender time, their accuracies are obviously lower than CD-APIR. Before recommending cloud service APIs, User-based CF spends more time calculating users’ similarity than Item-based CF.

The CD-APIR utilizes user behavior-aware information and SVD to solve the data sparsity problem and predict preference systematically. It focuses on the changes of user preferences over time, and generates recommender lists based on the results of preference drift detection. The experimental results show that the CD-APIR approach improves the accuracy and coverage of recommendation.

6.5. Impact of parameter 
When performing SVD, the choice of parameter  will impact the recommendation performance. In the recommender system, the information of the original matrix can be approximated by only taking a few singular values. Therefore, we do not have to use all the singular values, but select the largest  singular value to re-construct the matrix.

We change the value of the parameter , and investigate its impact on different recommendation approaches. The value of  is determined according to the proportion of singular values. In general, we believe that when  is small, it can significantly reduce the pressure on online storage, but it may cause the user–service matrix to lack the necessary recommendation information. If the  is large, the matrix can be better restored, but the recommender results may be affected by a few abnormal data, reducing the accuracy of recommendation.

In this experiment, we set Top-  10,   0.1, and  to gradually increase from 20% to 70% with a step value of 5%. We use the normalized user–service matrix as a basis for recommendation. ED-CDD and WD-CDD were performed as comparative data distribution-based concept drift detection approaches.


Table 2. Comparison of recommendation results.

Alice’s drifted preference	CD-APIR	SVD
IDs	APIs	Providers	IDs	APIs	Providers	IDs	APIs	Providers
3367	Permissions	SP20	3374	Views	SP20	3376	Forms	SP20
3253	Phone number	SP19271	3376	Forms	SP20	3813	Interface	SP3356
3374	Views	SP20	4328	SMS	SP34401	4276	SMS	SP11798
3384	Slide library	SP20	3680	Music catalog	SP20	3756	Weather	SP18990
3807	Phone notify	SP3356	3813	Interface	SP3356	4328	SMS	SP34401
4328	SMS	SP34401	3367	Permissions	SP20	3384	Slide library	SP20
3813	Interface	SP3356	3253	Phone number	SP19271	3727	Authentication	SP32369
3376	Forms	SP20	3807	Phone notify	SP3356	4124	Recruitment	SP10694
3680	Music catalog	SP20	3365	DWS	SP20	3356	Search	SP20
4276	SMS	SP11798	3727	Authentication	SP32369	3359	Area service	SP20
To investigate the optimal value of  in the cloud service APIs recommendation, we conducted experiments on the WS-Dream dataset. Fig. 8 presents the relationship between metrics and parameter  for different approaches.

With the gradual increase of , precision, recall and F-measure generally show a trend of increasing first and then decreasing. When  increase from 20% to 60%, the accuracy metrics (precision, recall, and F-measure) keep stable. When   55%, CD-APIR’s precision, recall, and F-measure are the best, which are 82.06%, 2.78% and 5.38%, respectively. When the  is 70%, the coverage is best, which is about 31.36%. The accuracy and recommend time of CD-APIR are superior to ED-CDD and WD-CDD.

After the accuracy and coverage are taken into consideration, we believe that when  is 60%, it is suitable for WS-Dream dataset for cloud service APIs recommendation.

6.6. Impact of parameter Top-
The number of services in the recommender result also has impact on the recommender system. To ensure effectiveness of the recommendation, the more services mean the more possible to satisfy user demands, which can include all the appropriate cloud service APIs comprehensively. However, the purpose of service recommendation is to firstly filter services for users. When the number of cloud service APIs recommended on the homepage is too large, it will not only reduce the user’s search efficiency, but also be not conducive to cultivating users’ recognition of the cloud service API market.

In this experiment, we investigate the best recommended number by adjusting the parameter Top-. We set   60% and   0.1. The number of recommended APIs is gradually increased from 2 to 20 with the step size of 1. Fig. 9 presents the impacts of Top- to the recommendation performance for different approaches.

CD-APIR keeps stable in precision. As  gradually increases, precision tends to increase first and then decrease. When   5, the precision of CD-APIR reaches a maximum of 82.65%. When   3, the precision of both ED-CDD and WD-CDD reaches 81.91%, respectively.

As the number of recommended services increases, other metrics increase steadily. When   20, recall, F-measure and coverage of CD-APIR are the best, which are 5.54%, 10.38% and 29.72%, respectively. After the various metrics are taken into consideration, we believe that   12 is suitable for cloud service APIs recommendation for CD-APIR.

6.7. Impact of parameter 
We also investigated the impacts of fixed threshold  on recommendation performance, that is, the impacts of the relationship between the degree of users’ preference drifts and the user–service matrices in different time windows on recommendation performance. In this experiment, we set   60%, Top-  12, and change  to gradually increase from 0 to 0.5 with a step size of 0.05. When   0, it means all the 
 in the range of . Fig. 10 presents the impacts of  on recommendation performance for different approaches.

We can see that, as  increases, accuracy and coverage gradually declines. When we focus on the accuracy and coverage of the recommender system,  should be set as 0 or 0.05. In this way, precision reaches 82.15%, recall reaches 3.34%, F-measure reaches 6.42%, and coverage reaches 23.00%. Coverages of ED-CDD and WD-CDD is about 21.70%. When  is in the range of , the metrics remain stable. The reason is that the number of users’ 
 in this range is few.

6.8. Case study
To show the exploitability and helpfulness of CD-APIR in the real-world application, we extracted the ratings of a target user (say Alice) from the dataset presented in Section 6.1. CD-APIR and SVD were used for cloud service APIs recommendations, respectively. The results are compared and analyzed in Table 2.

The first three columns of Table 2 present the top 10 cloud service APIs that Alice preferred at the new time window in the dataset. We will compare the results obtained by CD-APIR and SVD with the first three columns of Table 2 to show the effectiveness of CD-APIR. As stated in Section 2, Alice is developing a composite cloud system app for weather forecasting. She preferred to the four basic APIs of 
, 
, 
, and 
 at the old time window. Then, she would be at the stage of system implementation and prefer APIs of 
, 
, 
, and 
 at the new time window. That is, Alice’s preference may drift in the direction of enhancing the user experience. Her interests to the APIs would change into developing systems’ sound, view, SMS and encryption features.

As shown at the 4 to 6 columns of Table 2, CD-APIR recommended the first 8 APIs accurately, including Views, Music Catalog, SMS, Permissions, etc (see the bolded IDs for the APIs). As can be seen from the last three columns of Table 2, 10 APIs were recommended by SVD. The recommendation result of SVD deviated more from Alice’s new preferences. It recommended APIs such as weather, search and area service, etc. They are the APIs that Alice preferred in the early stages of development, but they cannot meet Alice’s demands at the new time window. It is because SVD solely uses the old time window’s model to perform recommendations. CD-APIR approach is combined with preference drifts. It recommends the users’ recently preferred APIs. By CD-APIR, the online model adaptation is realized based on the degree of preference drift detection and the trading-off piecewise equation.

7. Conclusion and future work
In this paper, we focus on the challenging issue of users’ preference drifts in APIs recommendation, and propose a concept drift-aware temporal cloud service APIs recommendation approach for building composite cloud systems (or CD-APIR). This approach first utilizes the users’ behavior-aware information to establish connections between users and cloud service APIs. Then, SVD is utilized to predict the missing values in the user–service matrix. The JS divergence is utilized to detect the degree of concept drift of users preferences. Finally, we combine the results of preference drift detection with user–service matrices in different time windows by proposing a trading-off piecewise equation to generate APIs recommendation results for each user. We conducted comparison experiments based on WS-Dream dataset to verify the effectiveness of the proposed approach. Experimental results demonstrate that CD-APIR approach improves precision, recall, F-measure, coverage of service recommendation and shortens the recommendation time.

In the future, we plan to explore the feasibility of recommending through dividing more time windows by timestamps. We will also investigate different types of drifts and their impacts. Due to new preferences may occur suddenly, gradually, incrementally, and iteratively, we will further research suitable cloud service APIs recommendation approaches in face of different types of preference drifts.

