Abstract
Design patterns (DPs) are recognised as a good practice in software development. However, the lack of appropriate documentation often hampers traceability, and their benefits are blurred among thousands of lines of code. Automatic methods for DP detection have become relevant but are usually based on the rigid analysis of either software metrics or specific properties of the source code. We propose GEML, a novel detection approach based on evolutionary machine learning using software properties of diverse nature. Firstly, GEML makes use of an evolutionary algorithm to extract those characteristics that better describe the DP, formulated in terms of human-readable rules, whose syntax is conformant with a context-free grammar. Secondly, a rule-based classifier is built to predict whether new code contains a hidden DP implementation. GEML has been validated over five DPs taken from a public repository recurrently adopted by machine learning studies. Then, we increase this number up to 15 diverse DPs, showing its effectiveness and robustness in terms of detection capability. An initial parameter study served to tune a parameter setup whose performance guarantees the general applicability of this approach without the need to adjust complex parameters to a specific pattern. Finally, a demonstration tool is also provided.

Previous
Next 
Keywords
Design pattern detection

Reverse engineering

Machine learning

Associative classification

Grammar-guided genetic programming

1. Introduction
Design patterns (DPs) are reusable template solutions that address recurrent software-design problems. The adoption of DPs is a best practice for programmers with the goal of improving the quality of software products — in terms of their maintainability, elegance, flexibility and understandability (Gamma et al., 1995). Given such benefits, and considering that manual inspection is an error-prone and time-consuming process, automatic Design Pattern Detection (DPD) has become a prominent area in the reverse-engineering research field (Bafandeh Mayvan et al., 2017). By automatically identifying the adoption of DPs, DPD techniques can improve the understanding of the design decisions in software systems, as well as the processes of redocumenting them, reimplementing them, and reusing them.

Different techniques have been proposed in the research literature to automate DPD, most of which search for particular structures in static code (Mayvan and Rasoolzadegan, 2017). In this case, the code structures defining DPs need to be predetermined by experts into a knowledge-base, as they usually are specific to the codebase of study. Having the expert defined these code structures may impose rigidity to the detection technique, and design patterns should be reinterpreted for particular contexts.

To reduce this limitation, machine learning (ML) techniques were proposed for DPD, e.g., Ferenc et al. (2005). These techniques are more easily adapted to different codebases because they learn from a collection of representative examples — and thus can recognise diverse implementations by simply replacing or extending such analysed collection of examples. In particular, ML-based approaches provide mechanisms to learn the structural and behavioural properties of the source code, as well as software metrics, that best describe the DP. Even so, despite the fact that DPs can be described considering these multiple aspects, current ML approaches consider either software metrics or code properties — structural, behavioural or both.

Unfortunately, the detection performance of existing ML-based approaches for DPD is affected by the design pattern under analysis, often requiring its specific parameter configuration. This characteristic makes them harder to adopt in practice: tuning parameters requires considerable effort by software engineers, since machine learning is often not their main area of expertise. Furthermore, the results provided by certain ML-based techniques like neural networks are difficult to understand and interpret by the human expert (Mori and Uchihira, 2019), thus making their recommendations less likely to be trusted (Dzindolet et al., 2003).

In this paper, we present GEML, a novel machine-learning-based approach for DPD from static code. More specifically, GEML is founded on associative classification (AC), a ML technique for which we have implemented a solution based on grammar-guided genetic programming (G3P). Our goal is to achieve the benefits of ML-based proposals while also addressing their limitations by using G3P as a basis of our approach. Like other ML-based proposals, GEML learns from DP examples, giving it the ability to capture diverse DP implementations. As for the limitations of previous ML proposals, GEML has been designed to promote extensibility, readability and flexibility.

For extensibility, GEML includes a customisable collection of design microstructures whose potential to identify DP instances is automatically determined by the evolutionary algorithm during the learning phase. For readability, GEML builds a rule-based classifier guided by a configurable context-free grammar that declares the syntax of the rules. Rules, as a well-established mechanism to encode human knowledge (Grosan and Abraham, 2011), describe the distinctive characteristics of DP instances in a more comprehensible way than the outcomes produced by black-box models (Kotsiantis et al., 2006). And for flexibility, GEML is applicable to each DP without requiring different algorithms or parameter configurations, since it searches for optimal rules to describe each particular DP.

In addition to these benefits, in our experiments, GEML also provided accuracy levels that outperformed other available techniques, providing competitive results even when very few samples are provided. Furthermore, GEML is able to maintain a stable behaviour with just a single general configuration, which we believe will make it more beneficial for software engineers in practical settings.

In short, GEML allows developers to execute it out-of-the-box without having to configure it for each DP, and customise its elements and parameters to gain detection power in particular scenarios. However, these desirable qualities would only make GEML beneficial in practice if it also provided (reasonably) similar performance as other existing techniques. Thus, we focus our evaluation on studying the effectiveness provided by GEML.

We perform several experiments in our evaluation. Firstly, we study GEML’s detection performance in depth through a sensitivity analysis. Although these kinds of analysis are laborious, they become essential to comprehend the internals of artificial intelligence techniques like those applied here. In particular, we aim to understand the extent to which each algorithmic component and its configuration contributed to detecting each individual DP. In this way we are able to determine the best detection capability offered by GEML. We also study the selection options and effectiveness of GEML if its configuration was customised in terms of the design microstructures eligible by the software engineer and software metrics – called operators – that describe the properties that best characterise each DP. Then, we also experimented with the alternative scenario in which software engineers did have the knowledge and time to customise it separately for each DP. As additional benefits of customising GEML individually for each DP, we expect that practitioners would also observe lower runtimes. Finally, we measure the detection performance of the general configuration of GEML. We anticipate that this would be the most common (and simpler) usage scenario for practitioners.

We also analyse how GEML behaves when the general configuration is set but the training conditions change. In this case, we consider up to 15 DPs – the highest number of DPs studied from a ML perspective – at the cost of reducing the number of available training samples. Even so, our results show that GEML is able to infer detection rules in all cases, not requiring any adaptation regarding its internal components and configuration. We also compare GEML’s detection performance to other DPD methods, including both ML and non-ML techniques. GEML provided higher accuracy and  score than MARPLE (Zanoni et al., 2015) – a well-known ML-based approach – for four out of the five DPs available for comparison (with up to 35% improvement in  for one of them). Against other non-ML-based techniques, GEML also recover more DP instances when validating with JHotDraw, a frequently studied project in DPD literature. Lastly, we analyse the strengths and weaknesses of GEML with respect to SSA and Ptidej, the two reference DPD tools most frequently used for comparative purposes. In this sense, GEML is highly competitive since it correctly identifies a higher number of DP implementations and support DPs whose detection is not available in these tools. GEML also overcomes some limitations of these tools, such as the absence of the classes implementing some roles of the DP and the excessive number of false positives. In short, the results of our evaluation show that GEML is a practical approach for DPD: it improves the effectiveness of current methods, while returning readable outcomes. Furthermore, the possibility of choosing the code properties more relevant for learning brings flexibility to the DPD process.

This paper provides the following contributions:

•
a novel DPD technique (GEML) based on machine learning with grammar-guided genetic programming that is able to provide a single configuration for detecting 15 DPs and returning human-readable rules;

•
the provision of a collection of design microstructures and metrics, in terms of operators that are derived by thecontext-free grammar (CFG) guiding the G3P algorithm and defined with both categorical and numerical values;

•
an analysis of which design microstructures and software metrics best represent each DP.

•
a experimental evaluation of GEML under different training and configuration scenarios, finding highly competitive results when compared against other ML and non-ML approaches;

•
a research demonstration tool to support software engineers in executing GEML and customising it for individual DPs.

The rest of the paper is organised as follows. Main concepts and terminology related to the applied techniques are introduced in Section 2. Section 3 presents the related work, and Section 4 provides a detailed description of our DPD model. Section 5 details the experimental methodology and framework. Then, the three experiments conducted are discussed in Sections 6 Experiment 1: Validation of the detection model, 7 Experiment 2: Comparison against DPD methods using P-Mart, 8 Experiment 3: Analysis of applicability. Section 9 describes the demonstration tool provided as additional material supporting this approach. Finally, threats to validity and concluding remarks are presented in Sections 10 Threats to validity, 11 Concluding remarks, respectively.

2. Theoretical background
Design patterns are descriptions of communicating objects and classes that are customised to solve a general design problem in a particular context (Gamma et al., 1995). They differ in the number and purpose of their defining roles, each one describing a specific task to be performed. Consequently, a DPD method does not only identify the code elements implementing the design pattern, but also the roles they play within the pattern structure. Notice that the definition of these elements and how they relate to each other might depend on the particularities of the programming language, e.g., Java allows implementing explicit interfaces but C++ does not. Besides, a given role could be played by more than one code element. Therefore, since design patterns are general and adaptable solutions, the presence of certain properties or a predefined structure for roles cannot be assumed. Their diverse nature, i.e., behavioural, creational or structural, suggests that different properties might be needed to characterise a given pattern, what definitely may hamper the detection process.

This section explains the most relevant theoretical concepts related to the techniques required by GEML to conduct the detection procedure. This is built on the basis of associative classification, i.e., a ML-based approach founded on the use of if-then rules over a classification approach looking for an understandable detection model (Thabtah, 2007). Internally, the classifier is constructed using an evolutionary technique, G3P, specially conceived to evolve computer programs according to a grammar, whose derivations and constraints define how these programs – i.e., a potential rule of the GEML’s detection model – are built.

2.1. Associative classification
Machine learning provides computational methods that allow learning from vast collections of data. ML techniques can be mostly divided into two major groups, unsupervised and supervised. Unsupervised techniques explore the data samples to find interesting and meaningful patterns describing them. A well-known technique within unsupervised learning is association rule mining (ARM) (Agrawal et al., 1993), where patterns are represented as a set of association rules. Formally, let I  {, …, } be a set of items, and let A and C be itemsets, i.e., A  {, …, } and C  {, …, }, an association rule is an implication of the type  where A  I, C  I, and A  C  .

In ARM, quality measures are computed to determine the quality of the produced rules, the support and confidence being the most representative measures. On the one hand, the support (Eq. (1)) indicates how frequently a rule is satisfied within a given set of data samples (). On the other hand, the confidence (Eq. (2)) measures the proportion of samples that satisfy the consequent from those already satisfying the antecedent. In both equations,  represents each data sample within . (1)
 
 (2)
 

Unlike unsupervised learning, supervised techniques make predictions based on the information extracted from past data. The purpose of a classification algorithm is to assign a predefined category, referred as class, to an unknown data sample. In particular, associative classification makes use of ARM techniques to build rule-based classifiers (Thabtah, 2007). With this aim, class association rules (CARs) (Liu et al., 1998), those in which the consequent determines the class, are generated. In general, AC can be viewed as a two-step process: () an ARM-based method is applied to mine a set of CARs; and () the set of CARs is pruned to exclusively select those rules that will be definitely constitute the classification model.

2.2. Grammar-guided genetic programming (G3P)
Inspired by the principles of natural evolution, evolutionary computation creates a population of individuals, each one representing a potential solution to the problem, which are then “evolved” during a number of generations (Eiben and Smith, 2015). An individual is characterised by its genotype, i.e., the computational structure used to encode the solution, and its phenotype, i.e., its real-world representation. In addition, a domain-specific fitness function has to be defined to assess the quality of an individual. In a general schema, for each generation, individuals are selected and modified with the aim of producing better individuals than their predecessors. More specifically, the algorithm selects a subset of the population to act as parents, often based on their fitness value. Parents are then combined to generate offspring by means of a crossover operator. Mutation can also be applied to the obtained individuals, looking for more diverse solutions. At the end of the generation, the best individuals survive and create the next population.

Genetic programming (GP) is a special type of EC technique in which individuals are encoded using tree structures (Koza, 1992). Originally conceived to evolve computer programs, GP requires specialised operators to manipulate tree-based solutions of different shapes and sizes. In particular, G3P is an extension of GP in which a CFG describes the syntactic constrains that must be satisfied by any valid individual. A CFG is defined by a four-tuple , where  is the root symbol,  is the set of non-terminal symbols, , is the set of terminal symbols and  is the set of production rules. A production rule indicates how a non-terminal symbol can be rewritten into one of their derivations until the expression only contains terminal symbols. Formally, it can be expressed as , where  and .

In G3P, each individual is created by deriving a different sequence of production rules, represented as a derivation tree. The elements of the CFG are also considered during the application of crossover and mutation to guarantee the production of valid solutions. G3P has been used to mine association rules (Luna et al., 2012), where the grammar formally defines the structure of the rule in terms of itemsets. In this context, each individual represents an association rule, and the evolutionary process is oriented towards finding a set of high-quality rules according to support and confidence criteria.

3. Related work
Multiple techniques have been proposed for automatic detection of structural, behavioural and creational design patterns, using both static and dynamic analysis of source code. Also, both types of techniques can be combined together depending on the pattern to be detected, e.g., by inspecting both class definitions and object collaborations (Ng et al., 2010, Lucia et al., 2018). Given that GEML performs static analysis, we mostly focused on these approaches for DP detection, with special attention to those proposals based on machine learning. In addition, even though the majority of studies take source code as input, other authors have explored detection at design stages too, e.g., using UML class diagrams (Di Martino and Esposito, 2016).

Within the scope of reasoning techniques, the Pat system (Kramer and Prechelt, 1996) is considered a pioneering work based on declarative logic programming. It defines the structural properties of DPs and the software project as Prolog facts. Then, the Prolog search engine is used to look for exact matches of these facts, which are identified as new DP instances. Similarly, the use of Prolog facts together with the use of meta-patterns (Pree and Sikora, 1997), which are common structures of DPs, were used by Hayashi et al. (2008). In this context, the FINDER tool (Dabain et al., 2015) integrates facts related to class structure and method invocations. Then, it filters out the fact base using predefined detection scripts. Fuzzy logic has been also used to deal with incomplete knowledge (Niere et al., 2002) in a attempt to make the detection process more flexible. In this approach, a fuzzy weight is assigned to each either structural or behavioural property thus reporting a level of confidence to each potential match. However, fuzzy-based approaches require an extensive base of knowledge to represent the diverse implementations. Given that such a base of knowledge has to be constructed by a group of experts, outcomes from the detection process could be biased.

Alternatively, techniques based on similarity scoring adopt graphs to represent structural information. The SSA tool (Tsantalis et al., 2006) searches for substructures that correspond to a predefined template of the graph describing the structure of a certain DP, i.e., the explicit representation of the relationships between roles. Mechanisms to deal with approximate matches can be applied too, such as considering a small variation range in the value of some properties. Similarly, behavioural properties like message passing are often considered to reduce false positives (Dong et al., 2009). In a different approach (Yu et al., 2015), a set of substructures are searched prior to the identification of the DP implementations. Then, method signatures are compared against a set of predefined templates describing the DPs to refine the results. In this vein, two other state-of-the-art approaches focus on improving the prediction performance of the substructures search process (Bafandeh Mayvan et al., 2017, Yu et al., 2018). While the former reduces the search space by conveniently partitioning the project graph, the latter defines ordered sequences to guide the search in such an order that the most representative classes of the pattern are discovered first, filtering irrelevant classes at an early stage. DPF is a model-based graph matching tool for which a meta-model and a domain-specific language are proposed to specify the structural and behavioural relationships describing DPs (Bernardi et al., 2014). Another popular tool, PINOT (Shi and Olsson, 2006), uses graphs as an abstract representation of methods taking part in candidate DP implementations, from which control flow is statically analysed.

Formal methods have been explored in the context of DPD too. More specifically, formal concept analysis has been applied to find groups of classes sharing common structural relations that represent candidate design patterns (Tonella and Antoniol, 2001). This approach was later extended introducing some additional contributions like a filtering phase of candidate patterns and proposing a language-independent variant (Arevalo et al., 2004). A case study was also conducted to detect structural patterns within two subsystems of a printer controller (Wierda et al., 2009). However, formal approaches can be computationally expensive due to the exponential growth of formal concepts (Poelmans et al., 2013).

Design patterns have also been expressed in terms of features and documented using annotations, from which automatic analysers can be built (Rasool et al., 2010, Rasool and Mader, 2011). As the authors acknowledge, incomplete definitions or inappropriate semantics negatively impact the detection process. Relations defined on the basis of a visual language represent another way to specify the properties of structural DPs (Lucia et al., 2009). In order to reduce false positives of the detection process, this method supports the definition of negative criteria, i.e., those properties that do not indicate the presence of a DP. Then it performs a low-level analysis of the relationships between classes in a second step.

Other authors have formulated DPD as a constraint satisfaction problem, defining those structural and behavioural conditions that each particular DP should satisfy. This type of method requires the manual definition and formalisation of the relationships between roles. DeMIMA (Guéhéneuc and Antoniol, 2008) and the DPJF tool (Binun and Kniesel, 2012) are representative examples of this approach, both supporting constraint relaxation. The former, which provides explanations of satisfied and non-satisfied constraints, has been later extended to include numerical properties as a way to reduce the number of candidates per role (Guéhéneuc et al., 2010). DeMIMA and its extensions are available within the Ptidej tool suite.

ML has been applied to support the DPD process, mainly building classification models to characterise DPs through the inspection of code implementations. These proposals differ in terms of the role that ML plays in the detection process, the properties of the source code used for learning, and the specific algorithm applied. A first work makes use of association rules to discard classes not playing a role according to some software metrics, so ML is not directly responsible for the detection (Gueheneuc et al., 2004). Similarly, decision trees and neural networks were trained with a set of manually defined features – named predictors – to reduce the number of false positives detected after a structural analysis of the code (Ferenc et al., 2005). A collection of software metrics was used to feed a neural network, whose goal is the identification of classes potentially playing a role in the DP before addressing the detection (Uchiyama et al., 2011).

The rest of methods rely on ML techniques to make a decision about the presence of a DP in the code. Alhusain et al. (2013) train multiple artificial neural networks, one for each role, with different subsets of metrics chosen via feature selection. They also proposed a second classifier to carry out the detection after filtering some candidates as in Uchiyama et al. (2011). In Chihada et al. (2015), the classification model is created using support vector machines. This method uses as an input a labelled set of manually identified pattern implementations and a set of metrics associated with their roles. Then a subgraph isomorphic algorithm is executed for candidate design patterns to be extracted from the code. In MARPLE (Zanoni et al., 2015), software metrics are not taken as inputs but a set of structural and behavioural properties, such as object compositions or method delegations. Implemented as an Eclipse plugin, MARPLE makes use of several clustering and classification algorithms implemented by Weka.1 More particularly, MARPLE is able to use different highly interpretable classifiers like decision trees. However, it does not use DP instances directly as an input. Since it executes a clustering algorithm prior to detection, it makes the resulting models not as representative of the original samples as expected and, consequently, more difficult to understand.

More recently, DPD has been treated as a multi-classification problem, where the goal is to determine which specific pattern is implemented by the input code (Dwivedi et al., 2018). Here, three different black-box classifiers – neural networks, support-vector machines and random forests – are trained using up to 67 software metrics. Convolutional neural networks and random forest have been also applied to learn from feature maps (Thaller et al., 2019). These elements are defined based on the occurrences of certain microstructures in the code.

Our proposal, GEML, belongs to the area of ML-based techniques for DPD. Compared to non-ML-based approaches, GEML does not need prior knowledge about the properties of the DP to be detected. Therefore, it can be adapted to organisational policies and different programming styles. As other ML-based methods, it automatically discovers which are the properties that best define each DP by exploring previous implementations from code repositories. As a counterpart, ML-based approaches require a labelled set of implementations, which may not be available in all contexts. Focusing on other ML-based alternatives, GEML differs from the existing approaches in the combination of software metrics and properties as input for learning. As for the algorithm, it uses G3P to produce a rule-based classifier instead of black-box detectors, such as neural networks or support vector machines. Outcomes from these kinds of models are harder to understand, which also reduces their likelihood for adoption by practitioners (Rana et al., 2014).

4. The GEML approach
Fig. 1 depicts the overall structure of GEML. Taking the approach as a black-box, the inputs required consist in the organisational repository containing patterns predicted in the past (i.e., samples), and the source code for which the detection process is carried out. After the execution of GEML, the detected DPs are returned. These patterns can be incorporated to the organisational repository for future detections, so that the detection model is progressively adapted to the specific development culture. Going into the detail of our approach, GEML has been proposed as a two-phased model. Firstly, the set of both structural, behavioural and metric-based software properties that best describe the design pattern under analysis are learned in form of rules. With this aim, a representative set of labelled DP implementations are scrutinised from the code repository, which contains both positive and negative samples. Keeping negative samples could provide relevant information about realistic scenarios, since similarities to a real DP could lead to misclassification otherwise. In fact, a high number of negative samples benefits the robustness of the detection process, specially when the amount of positive examples in public repositories is low (Alhusain et al., 2013, Thaller et al., 2019). Every pattern instance within the repository is characterised by its constituent elements, its source code and the role mapping, i.e., the correspondence between elements and roles.

The set of class association rules must be compliant with the CFG, formally defining the language syntax required to state the properties and constraints of the pattern. The G3P algorithm for DPD (G3P4DPD) has been developed to search for those rules that best characterise the implementations available in the repository. Since the resulting CARs have a descriptive nature, they could not be directly used for detection purposes. During the second step of the process, the most effective rules for the construction of the detection model will be chosen. With this aim, a pruning method is applied first to obtain the minimum set containing the most descriptive rules. Then, a strategy is followed to decide how to arrange the resulting rule set in order to build the detector, according to the precepts of different methods for associative classification (Thabtah, 2007). Both phases are explained in detail next.


Download : Download high-res image (140KB)
Download : Download full-size image
Fig. 1. Two-phased model for design pattern detection.

4.1. G3P-based algorithm for rule generation
Algorithm 1 shows the general procedure of G3P4DPD, which receives five inputs: the number of generations (maxGen), the population size (popSize), the number of individuals or CARs to be returned (extPopSize), the grammar (cfg) and the source code repository (repo). G3P4DPD keeps an external archive (extPop) composed of the most accurate individuals according to their evaluation. They are returned as output.


Download : Download high-res image (182KB)
Download : Download full-size image
Regarding its operation, G3P4DPD firstly creates a random population (pop) of popSize individuals conformant with the syntax prescribed by the grammar, cfg. The external archive, extPop, is then initialised to the empty set. Initial individuals of pop are evaluated by computing the fitness function, which obtains the support of the rule calculated from the repository repo. At this point, the algorithm iterates until the maxGen-th generation is reached. For each generation, the selection operator returns popSize individuals (parents) from the union between population pop and population extPop. Next, the crossover operator is applied with a certain probability over pairs of parents. After combining their genotypes, the obtained offspring are then mutated. The choice of the specific mutator is made randomly – between two possible operators – and seeks for a balance between search space exploration and the type and magnitude of the changes applied. On the one hand, diversityMutator looks for the improvement of population diversity by including new properties in the comparison expressions of the rule. On the other hand, dpdMutator is a DPD-specific mutator that aims to generate rules describing both positive and negative samples. Once these new offspring have been evaluated in terms of their support, they all replace the current population. Finally, the external archive is updated to keep those rules exceeding a certain support and confidence threshold, while ensuring that it does not exceed extPopSize elements, i.e., rules, and they are not repeated or redundant. Next sections explain in further detail how solutions are encoded and how the aforementioned genetic operators operate.

4.1.1. Encoding
On the one hand, the genotype of an individual is represented by a valid derivation tree of production rules, as formally defined by the CFG. On the other hand, its phenotype denotes the corresponding class association rule. As an example, Fig. 2 shows a genotype/phenotype mapping, the described rule stating that, if the element playing the role adapter delegates some functionality to the element adaptee, then this would expected to be a valid Adapter pattern.

As explained in Section 2.2, any CFG requires the definition of sets of terminal and non-terminal symbols, and the production rules to derive valid expressions from a root, non-terminal symbol. In this context, terminal symbols represent the software metrics, as well as the structural and behavioural properties that allow identifying the presence of a pattern instance, whereas non-terminal symbols define the derivable elements, including all the components needed to build comparison expressions between the aforementioned properties. Production rules determine the derivation steps that lead to the generation of detection rules, which are ultimately written in terms of terminal symbols. Notice that the CFG could be certainly customised to a specific design pattern, thus allowing a more efficient description of the most relevant properties of that pattern.


Download : Download high-res image (189KB)
Download : Download full-size image
Fig. 2. Example of correspondence between genotype and phenotype for an illustrative individual.

Fig. 3 shows the proposed grammar for the DPD process. Some production rules were omitted for readability. The first production rule listed in  determines that the root symbol, rule, can be derived into two other non-terminal symbols, antc and consq, representing the antecedent and the consequent, respectively. On the one hand, the antecedent can be defined as an inclusive sequence of numerical (numCmp) and categorical (catCmp) comparisons. On the other hand, consq can be derived into two possible terminals, expressing whether it is a positive detection of a design pattern instance, aPattern, or not, notAPattern. In addition, it is worth noting that this grammar has been slightly customised for the Adapter pattern, the non-terminal role being derived into adapter, adaptee and target. Similarly, adaptations of the grammar to other patterns could be also made straightforward by just setting the operators and roles that are more relevant to each pattern from those available, or exceptionally by implementing new operators. A more general possibility is to make the complete list of operators available to the algorithm and let it “find” which are the most relevant for the search. In any case, G3P4DPD would not be affected, since the algorithm receives the grammar definition as a parameter and it will adapt the search in consequence.

As mentioned above, each property of the DP is declared by the antecedent of the rule as a comparison, written as an expression in prefix form containing a comparator, an operator, one or more arguments, and a value. Numerical comparisons, numCmp, allow the representation of those properties based on software metrics. Each comparison comprises a numerical comparator (, ,  or ); a numerical operator that computes an object-oriented software metric from the CK (Chidamber–Kemerer) metric suite (Chidamber and Kemerer, 1994), such as NOM (number of methods), NOC (number of children), DIT (depth of inheritance tree) or RFC (response for a class); an argument referring to the measured element playing a role in the pattern; and a numerical constant (const). As an example, the comparison “NOC(target) 1” indicates that the target class has no subclasses. Likewise, other numerical software metrics could be implemented and added to the grammar without recompiling G3P4DPD.


Download : Download high-res image (635KB)
Download : Download full-size image
Fig. 3. Grammar used by the G3P4DPD algorithm.

On the other hand, categorical comparisons involve structural and behavioural properties. Structural properties serve to express characteristics of structural elements, such as a class being abstract or final, as well as the relationships between these elements, such as an aggregation or generalisation. Behavioural properties refer to those interactions between classes or method invocations that can be analysed from static code. These comparisons are composed by a categorical comparator ( or !); a categorical operator like linkArtefact or delegate; a number of arguments receiving the participating roles; and a value. As an example of a categorical comparison, “typeOf(target)=intface” describes that the target role is implemented by an interface. Table 1 shows the full list of available operators, their signatures and description. It is worth noting that categorical operators are mainly based on elemental design patterns (Smith, 2012), micro patterns (Gil and Maman, 2005) and design patterns clues (Fontana et al., 2011). They provide language elements that can be easily understood by the software engineer.

These structures can be expressed as categorical operators checking whether a code artefact satisfies a property on a true/false basis. For instance, Abstract Interface is an elemental design pattern checking whether a given code artefact is an interface. Usually, an artefact is a class or an interface. However, it largely depends on the specific programming language, and other artefacts could be considered like enumerations, or subtypes of artefacts, such as abstract and concrete classes. It implies that a large number of operators like isConcrete, isAbstract, isInterface and isEnumeration would be necessary to cover all types of artefacts. Besides, these operators would be strongly correlated, e.g., if isConcrete is true, then the others should be false, what could make rules redundant and add noise to the learning process. Therefore, the CFG declares multi-valued categorical operators, which are able to return different alternative terms instead. This is the case of typeOf, which allows analysing a source code artefact and returns a single value for all these possibilities. In this way, this operator replaces a number of redundant and unnecessarily inefficient boolean operators, while boosts the generation of more compact and readable rules.


Table 1. Grammar operators to describe design pattern implementations.

Numerical operators
Signature	Description
NOM()	Number of methods of 
NOC()	Number of children directly inherited from 
DIT()	Depth of the inheritance tree from 
RFC()	Number of distinct methods and constructors potentially invoked when an object of  receives a message
Categorical operators
Signature	Description
isFinal()	true if  cannot be extended; false otherwise
isSubclass()	true if  is a subclass; false otherwise
controlledInit()	true if  instantiates itself within an if or while block; false otherwise
controlledExcept()	true if  uses exceptions and an static flag to control its instantiation; false otherwise
conglomeration()	true if 2 or more methods of  are invoked from another method from ; false otherwise
returns(, )	true if a value of type  is returned from a method of ; false otherwise
receives(, )	true if a method of  receives a value of type  as argument; false otherwise
createObj(, )	true if  instantiates ; false otherwise
delegates(, )	true if a method of  invokes a method of ; false otherwise
sameElem(, )	true if  and  are coded by the same artefact; false otherwise
typeOf()	Returns the type of the artefact implementing  (absClass, intface, enum, class)
linkMethod(, )	Indicates if a method of  directly or indirectly overrides (directOver, indirOver), implements (directImpl, indirImpl) or is notLinked to a method of 
linkArtefact(, )	Returns the sort of link between the artefacts playing  and  (directInherit, indirInherit, directImpl, indirImpl, notLinked)
ctorVisibility()	Returns the visibility of the less restrictive constructor of  (private, protected, package, public)
aggregation(, )	Returns information about an attribute of  declared in  in terms of its visibility and instantiability
adapterMethod(, , )	Returns if a declared (decl) or inherited (inhr) method of , implemented from , delegates in a method of ; notLinked otherwise
redirectInFamily()	Returns if a declared method of  is delegated in a class or interface being extended or implemented by , once (single) or multiple times (multi); notLinked otherwise
sameInterfaceInstance(, )	Returns if  is a class or interface being extended or implemented by , which has one (single) or multiple (multi) fields of a class or interface being extended or implemented by ; notLinked otherwise
sameInterfaceContainer(, )	true if  is a class or interface being extended or implemented by , which defines a collection of a class or interface being extended or implemented by ; false otherwise
4.1.2. Genetic operators
There are three genetic operators to be considered in this evolutionary schema: selection, crossover and mutation. The selection operator is applied at the beginning of each generation in order to choose a set of parents for breeding. With this aim, a binary tournament selects two individuals from the union of pop and extPop, taking the best according to their fitness. This process is repeated until popSize parents are selected.

Regarding the crossover, this operator is applied to each pair of parents according to a given probability. The operator works by randomly selecting and swapping a single comparison from their respective genotype. Finding such a comparison requires traversing the derivation tree in pre-order until a cmp symbol is reached, delimited by and, cmp or consq, as illustrated in Fig. 4. Then, each offspring is mutated.

Two possible variants of mutator have been considered for this problem. Firstly, the so-called diversityMutator aims at generating rules with novel comparisons. To this end, it selects a number of comparisons and rebuilds the individual by randomly deriving these cmp until new terminal symbols are obtained. The number of comparisons is chosen with a random roulette wheel that promotes small changes against those significantly altering the individual. As an example, Fig. 5a shows how a categorical comparison is replaced by a numerical comparison. Secondly, dpdMutator aims at obtaining rules describing both positive and negative samples. The rationale behind this operator is that if a comparison describes the correct implementation of a pattern, its negation should imply an incorrect result. This operator traverses the derivation tree and rewrites the logical meaning of each comparison with an inverse probability to the number of comparisons in the antecedent. With this aim, it simply switches the comparison symbol, e.g.,  is replaced by , as illustrated in Fig. 5b. In addition, the terminal symbol of the consequent, i.e., the class label, will be also inverted with a probability of 0.5. For instance, if the comparison “typeOf(target)=intface” describes a recurrent property of positive samples for the Adapter pattern, “typeOf(target)!=intface” is likely to represent negative samples. At the end of the mutation operation, regardless of the specific variant being used, the mutated offspring is returned.


Download : Download high-res image (260KB)
Download : Download full-size image
Fig. 4. Example of the crossover operator.

4.2. Construction of the detection model
After completing the first step explained above, the G3PDPD algorithm returns its external archive composed of CARs. However, they still require to be scrutinised to select strictly those that will be part of the detection model. With this aim, the database coverage method is computed on the complete set of rules. This pruning method was originally defined for CBA (Liu et al., 1998), a general approach for associative classification, and later applied by other well-known algorithms like CMAR (Li et al., 2001) or CPAR (Yin and Han, 2003).

Algorithm 2 shows the pseudocode of the pruning method, conveniently adapted to this problem. The procedure takes the archive returned by G3P4DPD, extPop, the repository, repo, and a coverage threshold. As an output, it returns the pruned set of rules, ruleSet. To do this, rules are sorted according to their confidence, support and size, i.e., number of comparisons, respectively. More precisely, given two rules  and , it is said that  precedes  iff any of these conditions is satisfied: () conf()  conf(); () conf()  conf() and supp()  supp(); or () conf()  conf(), supp()  supp() and #comparison()  #comparison(). Then, all repository samples are scanned for each rule searching for those matching the antecedent. When positive, they are conveniently added to the list covSamples. In addition, if the rule correctly classifies at least one of these samples, i.e., the flag marked is true, then it will be added to ruleSet and the counter of covered samples in repo will be increased. In case a sample is covered by a number of rules greater than or equal to the threshold, it will be removed from repo so that this sample does not need to be checked again. Finally, if the rule does not contribute to increase the current detection capability, it will be discarded. This happens when the rule detects the same samples as other rules with higher confidence and support. This process is repeated until all samples in repo have been covered or until there are no more rules left.


Download : Download high-res image (190KB)
Download : Download full-size image
After the pruning procedure, the selected rules need to be arranged in order to constitute the classifier. Here, the four most commonly referenced strategies from the field of associative classification have been considered for comparison (Thabtah, 2007): maximum likelihood (MAXL); dominant factor multiple label (DFML); DFML, as defined by CMAR (DFML); and DFML, as determined by CPAR (DFML). They all operate differently when a new, unknown sample is received. For instance, the MAXL method selects the highest ranked rule covering the new sample, its consequent implying the prediction. This approach has been criticised by some authors since a single rule becomes responsible for the decision of the classifier (Li et al., 2001). In contrast, DFML selects all rules covering the incoming sample and distributes them according to their consequent (Hadi et al., 2016). The partition containing more rules determines the class. This method has been adapted in different proposals by changing how the most representative partition is obtained. A well-known variant is DFML, where the weighted  is computed for each partition, the set of rules with the highest value being returned. This measure analyses the strength of the rules based on their support and class frequency. Similarly, DFML calculates the Laplace accuracy to estimate the expected accuracy for each rule and selects the partition with its highest average. It should be noted that DFML considers only the best  rules within each partition,  being a prefixed parameter. Then, after sorting the rules, the classifier is ready to receive new code, apply the rules and predict the presence of a DP implementation.

5. Experimental settings
We first pose the research questions that set out the objectives to be validated in this section. Then we present the data repositories and explain the methodology followed in the experiments. The last section details the experimental framework.

5.1. Research questions
The conducted experiments aim at responding the following research questions (RQs):

•
RQ1. What configuration best informs our technique for each DP? The combination of parameters for the G3P-based machine learning algorithm and the pruning method might lead to vast number of results. It would be convenient to objectively provide the best parameter setup for each DP.

•
RQ2. For the software engineer, which are the most significant design elements and metrics to be considered for the detection of a given pattern? The combination of numerical (metrics) and categorical (behavioural and structural properties) attributes offers the engineer the possibility of using a wide range of microstructures and operators at his/her convenience. In this way, after analysing which operators are most frequently used to describe each pattern, the experimentation can be replicated by adjusting them in order to find out whether the results maintain the detection performance.

•
RQ3. Does GEML provide as much effectiveness as other ML-based DPD techniques? It would be convenient to study if, taking a single configuration for all DPs, our model is still competitive against a similar ML-based approach. Reaching a general-purpose configuration would relieve the software engineer of the need to set up the model.

•
RQ4. How does training conditions influence GEML? As any other ML-based approach, GEML requires the availability of DP examples to learn from. Therefore, it is important to study how GEML behaves when few examples are provided. This would allow the software engineer to confirm the potential of the technique under different execution scenarios.

•
RQ5. Does GEML provide as much effectiveness as other non-ML-based DPD techniques? Similarly to RQ3, it would be interesting to analyse the benefits that GEML brings compared to other non-ML-based DPD tools currently available to the software engineer, thus ensuring that it also contributes to advance in the state of the practice.

5.2. Experimental data sources
The experimentation considers a total of 15 design patterns, covering the three different categories defined by Gamma et al. (1995): creational (Abstract factory, Factory method and Singleton), behavioural (Command, Iterator, Observer, State, Strategy, Template Method and Visitor) and structural (Adapter, Bridge, Composite, Decorator and Proxy). These patterns provide different levels of complexity, as they differ in the number of roles and may present elements playing multiple roles.

Samples of these design patterns have been extracted from public repositories, but other institutional data sources could be valid too. More specifically, we conduct our experiments with implementations from two repositories, namely DPB and P-Mart, each with a different purpose. Firstly, we consider DPB (Fontana et al., 2012) because it provides the highest number of samples from publicly available repositories. Moreover, DPB was created by the authors of MARPLE to validate their approach, what ensures a fair comparison against this particular proposal, and contains both positive and negative samples, a requirement when experimenting with ML-based methods. DPB collects samples from nine industrial Java projects, plus one more project adopted from the literature. Table 2 lists the number of artefacts, methods, attributes and lines of code (LOC) of each software project contained by DPB. A limitation of this repository is that it only supports five design patterns (see Table 3, which includes the total number of samples [S], divided into positive [] and negative []).

In order to compare GEML against other non-ML-based proposals, we rely on P-Mart (Guéhéneuc, 2007) peer-validated repository frequently used in other DPD studies. P-Mart includes samples of 20 design patterns distributed among all projects listed in Table 2, with the exception of the DPExample project. Table 4 summarises the samples per project identified within P-Mart, as well as the number of existing DPs from those defined by Gamma. As can be observed, JHotDraw is the project containing the greatest variety of DPs (11), making it appropriate for its use as a test project when comparing GEML with other DPD studies, as will be explained later in Section 5.3.

The use of P-Mart allows GEML to be set against other DPD methods reporting results for JHotDraw, but this project limits the number of DPs available for comparison. Notice that P-Mart was not originally designed to specifically experiment with ML-based approaches due to the reduced number of positive samples, so it has to be enlarged to be suitable for training (Thaller et al., 2019). To carry out a more complete, accurate and practicable analysis, it is important to provide GEML with a more extensive collection of DPs for training than those available in P-Mart. Therefore, we have built a training repository in order to validate the applicability of GEML on an even greater number of design patterns. This is a common practice in DPD studies, especially in those presenting ML-based proposals (Ferenc et al., 2005, Alhusain et al., 2013, Thaller et al., 2019). Therefore, we have complemented the positive samples available in P-Mart with other instances manually validated from those recovered by DPD tools (Ferenc et al., 2005, Lucia et al., 2018). In particular, we include those pieces of code for which both SSA and Ptidej reported the presence of a DP implementation with all its roles. In the case of Ptidej, this information is complete. In contrast, some samples of P-Mart are not fully labelled, which has caused us to double-check the repository to maintain only those instances that describe all their roles. As for the negative samples, a common approach is to generate random candidates from the code and select those that are more similar to positive samples according to some heuristics (Thaller et al., 2019). We follow a similar procedure, so that a maximum of three negative samples per positive sample have been generated.2 The final list of design patterns available in the repository is shown in Table 3, together with the number of training samples. After preliminary experiments, the number of positive samples for the remaining seven DPs available in P-Mart has proven to be insufficient for training.


Table 2. Properties of the Java projects used for experimentation.

Project	Types	Methods	Attributes	LOC
DPExample	1749	4710	1786	32313
QuickUML 2001	230	1082	421	9233
Lexi v0.1.1 alpha	100	677	229	7101
JRefactory v2.6.24	578	4883	902	79732
Netbeans v1.0.x	6278	28568	7611	317542
JUnit v3.7	104	648	138	4956
JHotDraw v5.1	174	1316	331	8876
MapperXML v1.9.7	257	2120	691	14928
Nutch v0.4	335	1854	1309	23579
PMD v1.8	519	3665	1463	41554

Table 3. Samples per design pattern in each experiment.

Design pattern	Experiment #1	Experiment #2
–	S		–	S
Adapter	618	603	1221	65	180	245
Fact. method	562	482	1044	3	9	12
Decorator	93	154	247	2	6	8
Singleton	58	96	154	55	165	220
Composite	30	98	128	6	18	24
State	–	–	–	147	412	559
Templ. method	–	–	–	50	147	197
Proxy	–	–	–	19	57	76
Observer	–	–	–	8	14	22
Strategy	–	–	–	7	21	28
Abs. factory	–	–	–	6	18	24
Command	–	–	–	5	15	20
Visitor	–	–	–	3	9	12
Iterator	–	–	–	3	9	12
Bridge	–	–	–	2	6	8

Table 4. Characteristics of the projects available in P-Mart and DPExample.

Project	No. DPs	No. positive samples
DPExample	19	174
QuickUML 2001	6	7
Lexi v0.1.1 alpha	3	5
JRefactory v2.6.24	6	26
Netbeans v1.0.x	4	26
JUnit v3.7	5	8
JHotDraw v5.1	11	21
MapperXML v1.9.7	9	15
Nutch v0.4	8	15
PMD v1.8	9	14
5.3. Description of experiments
Three experiments have been planned in order to find an answer to these RQs:

•
Experiment #1. In this experiment, we validate the detection capability of GEML under laboratory settings. More specifically, we study how the parameter tuning influences our proposal and analyse different configurations with respect to MARPLE (Zanoni et al., 2015), another method based on machine learning.

•
Experiment #2. In this experiment we compare GEML against other recent non-ML-based DPD proposals: DePATOS (Yu et al., 2018), MLDA (Al-Obeidallah et al., 2018) and SparT (Xiong and Li, 2019). With this aim, for comparison purposes, we provide results on a P-Mart project, JHotDraw.

•
Experiment #3. This experiment focuses on more qualitative aspects, evaluating GEML in a more practical setting. Here, GEML is tested on a project, DPExample, taken from a different repository, DPB, than the one used for training. In this case, we compare our proposal with two non-ML-based DPD tools, SSA and Ptidej, which were run using the testing project as input. We choose these tools because they are the most frequently used for comparative purposes in DPD studies (selected in 88% and 35% of the works, respectively). In our preliminary analysis, we found other eight tools, but they were unavailable for download or failed in their installation or execution.

To cope with the intrinsic randomness of evolutionary algorithms, 30 independent runs with different random seeds are executed. For Experiment #1, the possible bias due to the training partitions of the input repository (DPB) is solved by carrying out a stratified 10-fold cross validation in every execution. In Experiment #2, we set the conditions that allow the comparison with other DPD approaches on a widely studied project, JHotDraw. All the DPD under analysis provide access to the recovered instances in this project, allowing a fair comparison by inspecting their level of agreement with respect to P-Mart. Also, JHotDraw is the P-Mart project with a greater variety of DP implementations. The rest of projects within P-Mart are used as the training set. Here we only consider as truly DP samples those labelled as positive on P-Mart. In Experiment #3 we want to simulate the process in which an engineer uses past projects to train the DPD model over all the possible DPs, and then apply the detection model on a new project. Since none of the nine P-Mart projects contains samples of all the DPs, we used them together for training, and the detection model is tested on DPExample. Since SSA and Ptidej do not require any training phase, they are directly executed using DPExample as input. True positive samples of DPExample have been manually revised.

Results are then reported in terms of the following commonly used classification measures: accuracy, which indicates the percentage of instances correctly classified; recall, which corresponds to the amount of DPs retrieved over the total number of samples within the repository; precision, which measures how many DPs are positively detected as positive; specificity, which indicates the proportion of negative samples correctly identified as negative; and  score, which calculates the harmonic mean between precision and recall. Once these performance metrics have been computed, the relevance of the results (Arcuri and Briand, 2014) needs to be statistically validated. Firstly, the Wilcoxon test allows performing pairwise comparisons, where the null hypothesis, , hypothesises that both algorithms – or configurations – perform equally well. The distributions to be compared represent the results of 30 executions of the evolutionary algorithm for a given DP and performance measure. As multiple configurations are tested, p-values are conveniently adjusted by using the Holm’s method. For those pairwise comparisons reporting significant differences, the Cliff’s delta test is carried out to measure the effect size. A 95% confidence level is considered for both tests.

5.4. Experimental framework
An implementation of GEML is provided in Java using JCLEC (Ventura et al., 2008), which includes functionalities and data structures to implement evolutionary algorithms. The VF2 algorithm (Cordella et al., 2004), available in the VFLib graph matching library,3 has been used for implementing the generation of candidates in Experiment #2. Three additional libraries have been used: ckjm,4 an implementation of the CK metric suite; Java Parser,5 a source code parser used to extract information and properties from code; and Javassist,6 a similar library that takes bytecode as input. They both are used to implement the grammar operators during rule evaluation, although bytecode-based operators are preferred because they allow a faster computation of the properties.

Table 5 lists the parameter setup and its variations for the detection model, including the G3P4DPD algorithm and the pruning procedure. The population size, the number of generations and the crossover probability have been set after preliminary experiments. The maximum number of derivations determines the limit of the genotype size, i.e., how long a rule can be. This value has been set to 25, as larger values would hardly generate individuals with admissible support. In addition, the size of the external archive has not been restricted to avoid discarding interesting rules and to test the effectiveness of the pruning method. The rest of parameters will be set according to the conclusions extracted from the parameter study in Section 6.1, which serves to determine their influence on the detection process. As for this analysis, support, confidence and coverage are configured according to the most frequently applied values within the AC field (Liu et al., 1998, Li et al., 2001).


Table 5. Parameter setup of the DPD model.

Parameter	Value
Population size	100
Number of generations	150
Crossover probability	0.8
Maximum number of derivations	25
Coverage threshold	1, 2, 3, 4
Support threshold	0.01, 0.05, 0.1
Confidence threshold	0.5, 0.6, 0.7
6. Experiment 1: Validation of the detection model
Experiment #1 is explained in this section. The internal elements of the detection model are analysed by means of an extensive parameter study (RQ1). Then, we also focus on the selection of the grammar operators, revealing the most recurrent microstructures and design elements to describe each DP (RQ2). Finally, the results are discussed with special emphasis on the effectiveness of the proposal (RQ3).

6.1. Parameter study
In response to RQ1, we carry out a parameter study focused on the three influential aspects required for the most fitting parametrisation of GEML: the coverage threshold, which is a key parameter for rule pruning; support and confidence thresholds, which effect the production of high-quality rules during the evolutionary search; and the strategy selection, which determines how the pruned rules are arranged to form the DPD model (see the Additional Material and Appendix for complete results).

6.1.1. Coverage threshold
The coverage threshold determines how many rules a given sample should satisfy to be considered as covered by the detection model. The lower the threshold, the lower the number of resulting rules. Following the recommendations of the AC literature (Liu et al., 1998, Li et al., 2001), we have selected four possible values, from 1 to 4. Default values for support and confidence have been set to 0.01 and 0.5. In addition, given that a classification strategy is required, MAXL has been chosen as the baseline procedure, since it is the simplest, only considering one rule for the classification. Again, the five classification measures are computed for each configuration, with special emphasis in , which reflects the effect of both precision and recall. After 30 executions, the best average values for  were obtained when the coverage threshold is equal to 1. As for the statistical analysis, the Wilcoxon test does not report significant differences in the case of the Adapter. In contrast, differences were found for the rest of patterns, especially when compared with largest values of the threshold. Considering these differences and the fact that lower coverage thresholds help reducing the size of the rule set, the threshold is set to 1 for all the patterns.

6.1.2. Support, confidence and classification strategy
The update mechanism of the archive is controlled by the support and confidence thresholds, looking for only preserving high-quality rules. In response to RQ1, we need to determine the parameters that return rules with the highest quality for each DP. With this aim, all the combinations of support and confidence thresholds (see Table 5), jointly with different classification strategies, have been analysed. The outcomes from these combinations can be found in the Appendix for each design pattern separately. Table 6 summarises the findings, showing the best combination of parameters with respect to .

For the sake of clarity, results are mainly analysed based on the values obtained for . In addition, notice that accuracy is not a fully reliable measure here, as long as the DPB repository is highly imbalanced. With respect to the classification performance of the different configurations, there is not a big difference for the Singleton, Adapter and Factory Method patterns. The same does not apply for the Decorator and Composite, however, for which differences of more than 20% are reported. These differences mainly occur between those configurations using different classification strategies, the support and confidence thresholds having less effect.


Table 6. Best classification performance in terms of  for each design pattern.

Strategy	Supp – Conf	Accuracy	Precision	Recall	Specificity	
Singleton	DFML	(0.01) – (0.7)					
Adapter	DFML	(0.01) – (0.7)					
Factory method	DFML	(0.05) – (0.7)					
Decorator	DFML	(0.05) – (0.7)					
Composite	DFML	(0.05) – (0.6)					
Regarding the classification strategy, it is worth noting that the same set of CARs has been used as input for all the strategies. In the case of DFML,  is set to 5, as suggested by its authors. Firstly, the results reveal that using only one rule for detection is not the best alternative, since MAXL is never able to return the best value for any performance measure. In fact, this strategy reaches significantly worse results for the Decorator and Composite patterns. Similarly, DFML obtains low detection performance for these patterns, even worse than MAXL. Note that this strategy only takes into account a reduced number of rules for detection, which is given by the value of . Thus, it could be argued that using a limited number of rules is not the best alternative for the DPD problem. Secondly, considering the strategies DFML and DFML, the latter stands out as the procedure that best exploits the detection capability of GEML. More specifically, the best values of  are reached when using this strategy. Focusing on the negative samples, other strategies could obtain better specificity results but at the expense of lower recall values, meaning that less DP instances would be recovered. Therefore, only configurations using DFML are considered when analysing how the support and confidence thresholds influence the detection model.

As for the support and confidence thresholds, the best performance is mostly reached for those configurations with a higher confidence threshold (0.7), the Composite being the only exception. We speculate that these rules are expected to provide more certainty in the detection. Nevertheless, notice that lower values are commonly used in the AC literature. Regarding the support, the Singleton and Adapter obtain the best results with the lowest support value (0.01), whilst 0.05 is the best value for the Factory Method, Decorator and Composite patterns. However, there is no best configuration with a support value of 0.1. Since this measure is related to the proportion of samples satisfying a rule, low values are needed to include those rules that are able to describe less common pattern implementations within the repository. Therefore, lower support values stand out as the best alternative, as suggested by the AC literature.

Finally, we summarise the main findings that give answer to RQ1:

•
Low support values are preferred for all design patterns, 0.01 showing better results for Singleton and Adapter. For Factory Method, Decorator and Composite, a support equal to 0.05 is recommended.

•
A confidence threshold equal to 0.7 is a good general choice, as only Composite obtains better results when setting another value (0.6).

•
For all design patterns, DFML is the pruning strategy providing best performance. This strategy is especially beneficial for the Decorator and Composite patterns.

6.2. Selection of grammar operators
The CFG determines the type of expressions (see Section 4.1.1) to appear within the rules describing DP implementations. As shown in Section 6.1, all these operators could be applied without further parametrisation to capture any type of design pattern under analysis, making the practical use of this detection model easier to the software engineer. Nevertheless, engineers could discard from the grammar those operators referred to microstructures that, in their opinion, are not descriptive of the pattern to be detected, or even are modified to comply with their organisational practices. It seems natural to think that the selection of a number of representative operators would produce rules formed from a limited set of pre-selected elements. In addition, it could reduce the search space and, consequently, the time required to find the best rules. Therefore, in response to RQ2, it is interesting to analyse to what extent the selection of operators influence the search process and which operators provide a better detection capability for each design pattern. With this aim, we have counted the number of occurrences in the pruned set of rules for the five design patterns after 30 executions. The results are depicted in Fig. 6 as box-plots, where the frequency of appearance has been normalised to the range [0, 1].

For the Singleton pattern, it can be observed that those operators related to the class instantiation, such as ctorVisibility or controlledExcep have a strong presence, whereas those requiring more than one role as input are hardly used. As for the Adapter, adapterMethod, which is a pattern-specific operator, appears in most of rules, whereas sameElem or sameInterfaceContainer are rarely selected. As expected, those operators related to object creation like createObj and returns commonly appear in the rules describing the samples of the Factory Method. Finally, redirectInFamily, sameInterfaceInstance and sameInterfaceContainer are recurrent operators for the Decorator and Composite patterns, as they are related to delegations between classes belonging to the same inheritance tree. The ability of G3P4DPD to mine negative rules is the reason why almost every operator appears in the final rule set. Notice that using a reduced set of operators would require a smaller number of generations, i.e., 100, to complete the search. Besides, including (potentially) dispensable operators within a rule could affect its readability too. Therefore, those operators whose mean frequency is less than or equal to 0.05 have been omitted from the experiments in order to find out how this selection would affect the detection performance. This value, depicted as dashed lines in Fig. 6, has been set to all DPs after preliminary experimentation.


Download : Download high-res image (961KB)
Download : Download full-size image
Fig. 6. Frequency of appearance of grammar operators in the resulting rules.


Table 7. Best results for the operator study.

Strategy	Supp – Conf	Accuracy	Precision	Recall	Specificity	
Singleton	DFML	(0.01) – (0.7)					
Adapter	DFML	(0.01) – (0.7)					
Factory method	DFML	(0.01) – (0.7)					
Decorator	DFML	(0.05) – (0.7)					
Composite	DFML	(0.05) – (0.5)					

Table 8. Comparison results for Experiment #1.

Best configuration	General-purpose configuration
GEML	MARPLE	GEML	MARPLE
Accuracy		Accuracy		Accuracy		Accuracy	
Singleton	0.9561	0.9411	0.88	0.91	0.9561	0.9411	0.93	0.90
Adapter	0.8688	0.8757	0.86	0.85	0.8688	0.8757	0.85	0.84
Factory method	0.8304	0.8503	0.82	0.83	0.8308	0.8489	0.82	0.83
Decorator	0.8229	0.7501	0.82	0.77	0.8188	0.7448	0.82	0.77
Composite	0.8859	0.7885	0.77	0.56	0.8888	0.7568	0.75	0.45
The experimentation has been carried out analogously to the previous experiments without selection of grammar operators. For brevity, only the best results will be shown (for a complete list of results, see Additional Material). Table 7 lists the best results obtained for each DP considering the reduced set of grammar operators. Figures in bold typeface represent those values that improve the analogous results – i.e. same support, confidence and strategy – obtained without reducing the set of operators (see Table 6). As can be observed, DFML is still the classification strategy obtaining the best results for every pattern. Regarding the confidence threshold, best values are mostly reached for configurations with a high value (0.7), the Composite being the only requiring a lower value (0.5). Again, a high support value (0.1) is never recommended. In general, note that the resulting values remain robust and there are not notorious differences with previous experiments including all operators. As for , in absolute terms, the selection seemingly benefits the results obtained for Singleton and Composite. In the case of the Adapter, values with or without selecting operators reflect practically a tie. We argue that this consistency in the results favours the engineers feeling able to adapt the selection of grammar operators either to the needs of their organisational repositories or to reduce the search space without significantly affecting the detection performance. Pairwise comparisons have been performed between analogous configurations having and having not reduced the set of grammar operators. This statistical analysis reflects that there are no significant differences, the Factory Method being the only exception, as it slightly improves when all operators are used.

•
GEML is able to automatically determine the type of operators more relevant to each category of design pattern. Those related to visibility and instantiation allow detecting creational patterns (Singleton and Factory method), whereas operators focused on delegation structures are highly effective to recover structural and behavioural patterns (Adapter, Decorator and Composite).

•
The general performance of GEML does not significantly decrease when the set of operators is reduced, Factory method being the only exception.

6.3. Performance comparison and discussion
Performance comparison.
Section 6.2 showed how robust GEML behaves when one specific part of the configuration, i.e., the grammar operators representing design microstructures, is refined. Nevertheless, even though it is likely that software engineers could make design-based decisions like selecting these microstructures, it still seems unrealistic to think that they would have the skills required to set up the rest of parameters and adjust the model to their needs. In these sense, for the sake of practicality, we have considered the use of a common model configuration for all design patterns taking the results listed in Section 6.1. As previously observed, DFML clearly dominates the rest of classification strategies. As for the support and confidence thresholds, S(0.01)-C(0.7) reaches the best values for the Singleton and Adapter, whereas S(0.05)-C(0.7) is the most appropriate for the Factory Method and Decorator. Finally, S(0.05)-C(0.6) was the best configuration for the Composite pattern. As lower values of support are preferred in order to find rare DP implementations, S(0.01) is seemingly a comprehensive choice. Similarly, C(0.7) is selected as the confidence threshold since it reaches the best values for all the cases, except for the Composite, for which also gets competitive performance values. The results obtained for this configuration for the five patterns are also shown in Table 8, which compiles the results obtained during the parameter study. More precisely, it shows the accuracy and  returned by the best configuration – in terms of  – found for each design pattern, as well as the default common configuration discussed above.

In response to RQ3, the detection performance of GEML is compared against MARPLE, a ML-based tool experimented under the same experimental methodology. More specifically, we compare the best results obtained by MARPLE for each pattern, as originally reported by the authors (Zanoni et al., 2015). The general-purpose configuration for MARPLE corresponds to a Random Forest classifier with k-Means as preprocessor, as this combination provided the best results for three out of the five patterns. Comparative results can be found in Table 8, considering the best and the general-purpose configuration for both techniques. As can be observed, considering the five DPs in this experiment, GEML outperforms MARPLE for the Singleton, Adapter and Factory Method, with percentage of improvements equal to 4.57%, 4.25% and 2.28%, respectively, when comparing general-purpose configurations. In contrast, MARPLE achieves an increase of 2.65% in  for the Decorator. However, GEML demonstrates a significant advantage in the case of the Composite pattern, obtaining an increase of 35.14% in  when comparing the results of our general-purpose configuration even against the best results of MARPLE, and 68.18% if we compare their best configurations. Again, it is worth remarking that GEML reaches more stable values along the different design patterns, in contrast to MARPLE.

GEML provides better detection performance for the Singleton pattern, whose structure exhibits one single role. In contrast, the worst results are returned for the Decorator and Composite. This is in line with the conclusions drawn by other DPD models (Uchiyama et al., 2011, Chihada et al., 2015, Zanoni et al., 2015), where the detection capacity decreases as the pattern complexity increases.

From the comparison results, the following findings related to RQ3 can be extracted:


Table 9. Comparison results for JHotDraw project.

Ground	GEML	DePATOS	SparT	MLDA
truth	P	TP	Pr	Re		P	TP	Pr	Re		P	TP	Pr	Re		P	TP	Pr	Re	
Adapter	1	1	1	1.00	1.00	1.00	38	1	0.03	1.00	0.05	12	1	0.08	1.00	0.15	19	1	0.05	1.00	0.10
Command	1	11	1	0.09	1.00	0.17	–	–	–	–	–	8	1	0.13	1.00	0.22	12	1	0.08	1.00	0.15
Composite	1	11	1	0.09	1.00	0.17	1	1	1.00	1.00	1.00	1	1	1.00	1.00	1.00	1	1	1.00	1.00	1.00
Decorator	1	2	1	0.50	1.00	0.67	3	0	0.00	0.00	0.00	3	1	0.33	1.00	0.50	1	1	1.00	1.00	1.00
Factory method	2	0	0	0.00	0.00	0.00	–	–	–	–	–	2	1	0.50	0.50	0.50	0	0	0.00	0.00	0.00
Observer	2	26	2	0.08	1.00	0.14	–	–	–	–	–	4	0	0.00	0.00	0.00	0	0	0.00	0.00	0.00
Singleton	2	2	2	1.00	1.00	1.00	–	–	–	–	–	2	2	1.00	1.00	1.00	2	2	1.00	1.00	1.00
State/Strategy	6	7	1	0.14	0.17	0.15	–	–	–	–	–	24	2	0.08	0.33	0.13	22	3	0.13	0.50	0.20
Template method	2	4	2	0.50	1.00	0.67	–	–	–	–	–	5	1	0.20	0.50	0.29	–	–	–	–	–
Total	18	64	11				42	2				61	10				57	9			
•
GEML outperforms MARPLE for four out the five patterns under comparison, achieving up to 68.18% of improvement in terms of F1 for the Composite pattern.

•
GEML provides more stable results than MARPLE, with more than 81% of accuracy and 74% of F1 for all patterns, using either its general-purpose or best configuration.

•
Like other ML proposals, GEML shows a better detection performance for less complex patterns.

Discussion of design characteristics.
GEML presents some characteristics in its design that makes it an appealing alternative beyond its good performance. We next discuss their implications from a more practical perspective. The use of a CFG and a large, diverse set of eligible design properties in terms of grammar operators facilitates the customisation of the detection process to the engineers’ needs. In contrast to other proposals, GEML allows both numerical and categorical properties, meaning the simultaneous use of metrics and design microstructures. In this way the software engineer can explicitly influence the design and developmental aspects that will guide the search. Furthermore, the resulting model would be able to capture the most significant properties in each moment, adapting the model to changes in the repository. Promoted by the use of ML techniques, new detected samples – both positive and negative – by the resulting models could also serve as an input for future detections. Thus, GEML would allow the progressive adjustment of the prediction to the organisational development culture, what is usually a dynamic element in companies. Finally, in comparison to other black-box proposals (Chihada et al., 2015, Dwivedi et al., 2018, Thaller et al., 2019), GEML uses a rule-based model, which is more comprehensible for practitioners (Kotsiantis et al., 2006).

7. Experiment 2: Comparison against DPD methods using P-Mart
This section presents the results and analysis of Experiment #2, in which GEML is compared to other DPD studies considering a project available in P-Mart, JHotDraw, as the testing project. We provide results from 10 out of the 11 Gamma’s DPs available in this project, since the rest of P-Mart projects cannot provide training instances for the Prototype pattern. Three recent DPD methods are chosen for comparison: DePATOS, which detects structural patterns using a sub-graph isomorphism algorithm (Yu et al., 2018); MLDA, a rule-based approach that analyses method signatures (Al-Obeidallah et al., 2018); and SparT, a method based on ontologies that combines structural, behavioural and semantic information (Xiong and Li, 2019). All these works provide results on JHotDraw that can be contrasted, since their authors both report absolute values of recovered instances, and give access to the DP implementations found. This allows us to compute the performance metrics (precision, recall, and F1) on the basis of a common ground truth, instead of comparing results validated over custom repositories created by the authors. Notice that, usually, P-Mart is extended in DPD studies, but the resulting datasets are not publicly available.

Table 9 lists the DPs under study and the results of the four methods in terms of number of recovered instances per DP, as well as the total sum. Precision, recall and F1 are computed considering positive samples labelled in P-Mart as the ground truth for all methods. None of the methods under comparison distinguish State from Strategy, so we report them together for GEML7 too. The symbol “-” is used to indicate that the particular DP is not supported by the method. GEML is the method that recovers more true DP implementations (11), followed by SparT (10) and MLDA (9). In terms of F1, GEML is the best method for four DPs (Adapter, Observer, Singleton and Template method), and the second best method for the remaining DPs. The only DP for which no implementation is found is the Factory method, which is not supported by DePATOS and not detected by MLDA. GEML considerably reduces the number of false positives for the Adapter and State/Strategy patterns compared to the rest of methods. In contrast, given that GEML is a ML-based approach, it suffers from the low number of training instances in some cases, such as Composite and Observer. Even so, GEML manages to detect the same number of true positives than the other methods for the Composite pattern, and it is the only method that is able to recover the two Observer implementations.

8. Experiment 3: Analysis of applicability
Experiment #3 is explained in this section on the basis of a practical scenario, and evaluated according to more qualitative aspects. The experimentation has been performed with a large number of DPs (15), showing that no adaptation is required to execute GEML when new DPs are introduced. The outcomes serve us to analyse how the change of the training repository might influence the behaviour of the proposed method (RQ4). Then, a comparison against reference non-ML-based DPD tools is provided (RQ5).

8.1. Influence of training factors
In response to RQ4, GEML is retrained by applying its general-purpose configuration and using a different input repository than in Experiment #1, as explained in Section 5.3. Then, the detection model is tested on DPExample. Table 10 shows the results for the median and best execution of the 30 runs. Pr and Re stand for precision and recall, respectively. Design patterns are sorted in decreasing number of positive training samples (see Table 3).

The results bring new insights. Despite the low number of training instances in the repository – a limiting factor inherent to machine learning – GEML is able to retrieve DP instances for 15 design patterns, all Gamma’s DP available in P-Mart, with the exception of Builder, Memento, Prototype and Facade. A general observation is that our method suffers when less than 10 training samples are provided. In these cases, it might happen that the lack of data result in executions for which no detection rules can be generated (marked as ‘-’ in Table 10). The degradation in performance is more evident in terms of precision, i.e., the rate of false positives tends to increase. Even so, GEML finds at least half of the true DP implementations during its best execution, with the exception of four design patterns (Observer, Abstract Factory, Command and Factory Method).


Table 10. Performance of GEML in the test project (DPExample) with and without using numerical properties.

With numerical properties	Without numerical properties
Median	Best	Median	Best
Pr	Re		Pr	Re		Pr	Re		Pr	Re	
State	0.09	0.67	0.16	0.13	0.67	0.22	0.10	0.67	0.18	0.14	0.67	0.23
Adapter	0.04	0.58	0.08	0.12	0.83	0.21	0.04	0.67	0.08	0.17	0.33	0.22
Singleton	0.81	0.81	0.81	0.81	0.81	0.81	0.81	0.81	0.81	0.81	0.81	0.81
Template method	0.22	0.21	0.20	0.55	0.86	0.67	0.40	0.86	0.55	0.55	0.86	0.67
Proxy	0.38	0.75	0.50	0.50	0.75	0.60	0.43	0.75	0.55	0.60	0.75	0.67
Observer	0.14	0.29	0.19	0.67	0.29	0.40	0.50	0.14	0.22	1.00	0.29	0.44
Strategy	0.09	0.50	0.15	0.10	0.50	0.16	0.09	0.50	0.15	0.11	0.63	0.19
Composite	0.10	0.50	0.17	0.12	0.50	0.19	0.10	0.50	0.17	0.13	0.67	0.22
Abstract factory	–	–	–	0.04	0.37	0.08	–	–	–	0.16	0.79	0.25
Command	–	–	–	0.01	0.40	0.02	0.01	0.40	0.02	0.01	0.20	0.02
Factory method	–	–	–	–	–	–	–	–	–	0.12	0.20	0.15
Visitor	0.36	0.93	0.52	0.42	0.93	0.58	0.36	0.93	0.52	0.42	0.93	0.58
Iterator	0.02	0.40	0.03	0.80	0.80	0.80	0.02	0.40	0.03	0.67	0.80	0.73
Decorator	0.75	0.33	0.45	0.80	0.67	0.73	1.00	0.33	0.50	0.80	0.67	0.73
Bridge	0.04	0.17	0.07	0.07	0.50	0.13	0.04	0.17	0.07	0.07	0.50	0.13
Another consequence of having a reduced training set is overfitting, since less variability of examples is presented to the algorithm. The fact that DPExample is the only project taken from the literature, in contrast to other open source projects used for training, may cause this project to present slight differences for some properties relying on role identification and software metrics. This is specially evident for two DPs, Adapter and Template Method, since GEML provides a considerably higher precision and recall in the training phase. For the Adapter, we have observed differences in how DPB and P-Mart label the roles, since DPB assigns one class per role at most (Zanoni et al., 2015). This affects the effectiveness of the adapterMethod operator, which works under the same assumption. Similarly, we realised that numerical properties (software metrics) become less informative in this experiment. The difference in size between classes inspected during training and those available for testing implies that the learned thresholds for measures like LOC and NOM are not so representative for the testing project. After excluding such operators, our method has improved its detection capability for six design patterns and has guaranteed more stable results for Abstract Factory, Command and Factory Method (see Table 10). The generated rule set for each DP is available as additional material.

The specificity of some operators has revealed as an important factor to counteract the low number of training samples. This is reflected in the Decorator pattern, for which GEML provides similar results than those obtained in Experiment #1 after learning from two positive samples only in Experiment #2. Looking at the resulting detection models, we observe that redirectInFamily – an operator particularly associated to the Decorator pattern – frequently appears in the rules, as shown in Section 6.2. This finding does not imply that new operators oriented towards a particular DP have to be implemented to support its detection. This can be observed in the case of the Visitor pattern, which has obtained the highest recall despite being a pattern with very few positive samples and not being considered in Experiment #1. For this specific pattern, the operator checking whether a role is implemented by an interface becomes highly relevant to identify its structure. Finally, State and Strategy share the same class structure, making it difficult to distinguish them and therefore to detect them correctly. For this reason, some DPD methods consider them together. According to our outcomes, GEML is able to differentiate State from Strategy, and vice versa, for around 10% of instances, and the corresponding false positives are often attributed to an usual misclassification between both DPs.

Finally, Table 11 provides the average execution time of each step of the DPD process applied to DPExample, a medium-size project. G3P4DPD is the step requiring more time, although it does not usually takes longer than one minute. Pruning the generated rules is a very fast procedure that mostly depends on the number of rules returned by G3P4DPD. Note that training the DPD model, i.e., rule generation and pruning, only needs to be carried out when new DP instances are added to the repository. The VF2 algorithm is efficient for candidate generation, and no great disparity is observed for design patterns with different number of roles. Then, the filtering step takes two seconds at most, depending on the different heuristics applied to each DP (see Section 5.3). Finally, the time required to proceed with the detection depends on both the number of candidates and the number of rules.


Table 11. Average execution time (ms) of each phase of the DPD process. Graph building from code takes 909.67 ms on average.

Rule	Candidates	DP detection
Gener.	Pruning	Gener.	Filtering	
State	68,188.23	29.27	24.00	168.37	1,066.80
Adapter	27,949.63	19.20	22.37	300.87	722.67
Singleton	19,112.73	6.50	15.57	204.23	1140.40
T. Method	39,412.37	17.83	18.20	178.30	584.30
Proxy	12,099.03	3.33	18.47	160.83	85.83
Observer	5157.50	67.67	24.50	75.37	60.43
Strategy	6980.83	1.63	24.03	260.57	197.23
Composite	14,909.90	1.40	22.30	237.47	697.50
A. Factory	8852.90	1.20	23.20	1,733.53	52.67
Command	11,596.50	0.97	37.30	240.57	342.03
F. Method	5145.03	0.80	31.20	160.07	2.67
Visitor	9765.87	0.70	17.13	27.93	3.13
Iterator	3928.11	0.74	23.95	14.03	110.71
Decorator	4174.20	0.50	35.43	434.97	3.93
Bridge	3961.95	0.72	31.55	158.61	4.10

Table 12. Comparison results for Experiment #2.

Ground truth	GEML	SSA	Ptidej
P	TP	P	TP	P	TP
State	12	57	8	41	3	104	9
Adapter	6	12	2	54	3	128	3
Singleton	21	21	17	22	17	82	15
T. Method	7	11	6	20	7	234	7
Proxy	4	5	3	2	2	127	4
Observer	7	2	2	4	2	–	–
Strategy	8	46	5	6	6	0	0
Composite	6	30	2	7	1	29	2
A. Factory	19	99	15	–	–	–	–
Command	5	79	1	4	3	36	2
F. Method	15	26	3	1	1	44	5
Visitor	15	33	14	11	11	2	2
Iterator	5	5	4	–	–	–	–
Decorator	6	5	4	19	5	–	–
Bridge	6	41	3	3	0	–	–
Total	142	472	89	194	61	786	49

Table 13. Coincidences among DPD tools.

Coincidences in positive implementations	Coincidences in true positive implementations
Unique	GEML	GEML	SSA 	All	GEML	GEML	SSA 	All
TP	 SSA	 Ptidej	Ptidej		 SSA	 Ptidej	Ptidej	
State	1	38.0%	53.3%	33.0%	24.6%	37.5%	70.0%	33.3%	30.0%
Adapter	0	15.8%	6.8%	20.6%	4.2%	75.0%	75.0%	100.0%	75.0%
Singleton	0	95.4%	17.15%	16.9%	16.9%	100.0%	68.4%	68.4%	68.4%
T. Method	0	52.4%	5.1%	8.6%	4.7%	85.7%	85.7%	100.0%	85.7%
Proxy	0	40.0%	1.5%	0.8%	0.8%	66.7%	50.0%	25.0%	25.0%
Observer	2	0.0%	–	–	–	0.0%	–	–	–
Strategy	0	10.6%	–	–	–	83.3%	–	–	–
Composite	2	23.3%	25.5%	12.5%	8.5%	25.0%	50.0%	50.0%	25.0%
A. Factory	15	–	–	–	–	0.0%	–	–	–
Command	0	2.4%	3.6%	8.6%	0.0%	40.0%	0.0%	75.0%	0.0%
F. Method	0	0.0%	40.0%	0.0%	0.0%	0.0%	60.0%	–	0.0%
Visitor	3	78.8%	6.1%	18.2%	6.1%	83.9%	6.5%	18.2%	6.5%
Iterator	4	–	–	–	–	–	–	–	–
Decorator	1	14.3%	–	–	–	50.0%	–	–	–
Bridge	3	7.3%	–	–	–	0.0%	–	–	–
•
The detection performance of GEML reaches up to 81%, though it varies depending on the design pattern. GEML achieves more than 50% of recall for 11 out of the 15 DPs, and more than 75% for six of them, despite the low number of samples available.

•
The detection capability is not only affected by the training set size, but also the particular characteristics of each DP and how roles are labelled in the repository.

•
The choice of operators, especially not using software metrics, become more relevant when few samples are available. The improvement can be up to 300% in terms of precision, 114% in terms of recall and 213% with respect to F1.

•
GEML is able to learn rules for any new design pattern without requiring the implementation of specific operators, but might have difficulties to produce rules for some DPs when the number of samples is significantly low.

8.2. Comparison with DPD tools
In the context of RQ3, the previous results should be contrasted with those obtained with other tools available to the software engineer, i.e., SSA and Ptidej. It should be noted that the conditions under which this comparison can be carried out (see Section 5.3) are not favourable for GEML. On the one hand, the number of training samples for some DPs is extremely low. On the other hand, since GEML has partially learned from the outcomes of both tools, GEML might fail to identify the instances not discovered by these tools. Even so, GEML manages to be superior, or at least competitive, to SSA and Ptidej. Table 12 shows the best results for GEML together with those obtained after running both tools. We report absolute numbers of positive DP implementations retrieved (P) and correctly identified (TP) by each method, since they seem easier to interpret and give an idea of the effort required to manually verify tool outcomes. As a reference, the actual number of DP implementations (ground truth) is provided too.

Overall, GEML detects 63% of the DP implementations, followed by SSA (43%) and Ptidej (35%). SSA applies a more conservative detection strategy that allows reducing the presence of false positives (FPs). Proxy, Strategy, Factory Method, Bridge and Visitor clearly illustrate this point. GEML shows more variability in this regard, with more than a half of FPs corresponding to three DPs: Abstract Factory (not supported by the other tools), Command and State. The issues discussed in previous Section 8.1, such as the low number of instances and overfitting, are the reason behind such behaviour. Even so, GEML considerably reduces the need of inspecting all classes within the project, and tends to return less FPs than Ptidej. We observe that this tool correctly identifies the classes implementing the design pattern, but fails to assign the roles and returns several permutations as solution for the same DP instance. SSA presents some limitations with respect to role identification too. For 12 DPs, SSA does not provide the classes playing one or more roles, meaning that the practitioner is required to manually inspect the code to complete the DP definition.

Each tool appears to be superior for a different set of design patterns, not necessarily those belonging to the same category (creational, structural or behavioural). Indeed, the only DPs for which the three tools return the majority of implementations are Singleton and Template Method. Difficulties to detect implementations of Factory Method, Composite and Adapter are observed in the three tools. SSA finds one DP instance more than GEML for Adapter, Template Method, Strategy and Decorator, and two more instances of the Command pattern. Higher differences are observed in favour of GEML for State (5), Bridge (3), Visitor (3) and Factory Method (2). Compared to Ptidej, GEML also returns a similar number of correct DP instances for State, Adapter, Template Method and Proxy. However, the lack of support to four DPs (Observer, Bridge, Abstract Factory and Decorator) and the fact that Strategy and State are considered together impose some limitations to Ptidej.

At this point the level of detection agreement between tools is discussed based on the intersection of their result sets so as not to focus solely on the number of DP instances detected. These coincidences are expressed as percentages in Table 13, what includes outcomes for both positive DP implementations and TPs. In light of the results, it does not seem evident to conclude which pair of tools provide more similar results. Due to the FP rate of Ptidej, GEML is closer to SSA in terms of positive implementations. Nevertheless, GEML achieves higher agreement with Ptidej for State and Proxy compared to the coincidences between SSA and Ptidej.

Next, we focus on those design patterns for which tools exhibit less agreement. GEML and SSA both found two out of the seven implementations of the Observer, but they returned different instances. Similarly, the implementation found by SSA for the Factory Method was not detected by GEML. This phenomenon is observed for Proxy implementations too, for which no pair of tools returns more than two equal instances. Furthermore, Table 13 also provides the number of TPs that only GEML was able to find. In total, GEML detects 12 implementations missed by SSA or Ptidej, not counting the Abstract Factory nor the Iterator instances, since neither SSA nor Ptidej consider these DPs. For the Observer, the Bridge and the Composite patterns, these DP implementations are the only TPs returned by GEML, meaning that it is highly effective to find instances that other tools would miss. As for the Visitor, apart from the three unique implementations returned, GEML is able to find all the instances (11) detected by SSA. This is not what happens more often and, even though each tool has its own ability to find out certain DP implementations, in most cases their results are complementary.

To conclude, we next compile the most relevant facts that give response to RQ5:

•
GEML finds more true positive instances than the two reference tools, SSA and Ptidej, including samples of the Abstract Factory pattern and Iterator (not available in these tools).

•
Considering only those DPs supported by all tools, 11% of the samples recovered by GEML were not found by any other tool used for comparison.

•
The level of agreement among all tools, in terms of true positive implementations, can reach more than 80%, but for some DPs is significantly lower. Tools for DPD are mutually complementary in terms of practical use.

9. Demonstration tool
GEML is publicly available as a Java-based demonstration tool (see Additional Material) that allows engineers to detect DP implementations from their own projects without requiring any expertise in ML or evolutionary techniques. The tool provides basic graphical support for the whole DPD process, divided into the following three phases:

1.
Generation of candidates. The source code is analysed to extract an initial set of potential DP implementations (candidates).

2.
Learning of the detection model. The G3P4DPD and pruning algorithms are executed to generate the set of detection rules.

3.
Recovery of design patterns. The detection rules, together with a classification strategy chosen by the software engineer, check whether the candidates are actually implementing a DP.

Each of these phases is detailed next. Firstly, for the generation of candidates, the project from which the set of potential samples for a given DP will be extracted must be selected. During this process, code artefacts and their relationships are scrutinised to find groups of related elements. Then, a role mapping procedure assigns a role to every artefact comprising the candidate according to its relationships. Taking the Adapter pattern as an example, the code artefact playing the adapter role has to implement the interface declared by target, while adapting the service provided by adaptee. Thus, it should be linked to at least two other code artefacts. Similarly, in the case of the Singleton pattern, each code artefact would correspond to a DP candidate, as it only has one role. Fig. 7 shows the screenshot with this configuration panel. Once candidates are found, they can be exported for future executions. A file containing software metrics is also generated.

In a different view, the learning of the detection model is conducted, the support and confidence thresholds being set as shown in Fig. 8. The user could also select the set of operators to be applied for mining the rules (see Sections 4.1.2 Genetic operators, 6.2 Selection of grammar operators ). The rest of parameters are set to their default values for simplicity, though advanced users could still modify them by simply editing an XML configuration file. This file also includes the path of the repository from which rules will be mined, so the user could modify it according to organisational or team requirements. Additionally, the resulting detection rules can be saved for future use.

To illustrate this operation, we have selected the project datapro4j,8 a Java library for processing and handling data from heterogeneous data sources, which contains implementations of the Singleton pattern. Fig. 9 shows two illustrative rules returned by G3P4DPD: one describing positive samples – consequent aPattern – and one for negative samples — consequent notAPattern. On the one hand, the first rule implies that implementations of the Singleton pattern scrutinised from this repository contain a non-public constructor, and a property of their own type to ensure that only one instance is created. In addition, DIT values are not greater than one, meaning that Singleton instances have no superclasses in this repository, except for Object, as any Java class. On the other hand, the second rule determines that those classes with a public constructor whose double invocation is not controlled by exceptions are not a valid implementation of Singleton. Notice that the use of exceptions is an alternative implementation of Singleton, which is usually coded in terms of a private constructor whose invocation is controlled by a static variable. However, the use of design microstructures as grammar operators allows detecting both cases. For this execution, the support and confidence thresholds were set to 0.01 and 0.7. In addition, the list of operators were limited to only those that best represent the Singleton pattern (see Section 6.2).

Finally, as for the recovery of design patterns, the classification strategy has to be selected. For the datapro4j example, we applied the MAXL strategy. Fig. 10 shows the implementations found for this pattern and repository, which are highly coincident with the actual specification of the library. It is also worth noting that these implementations could be added to the repository in order to gradually adjust this database to the corporate culture in future detections.

10. Threats to validity
Internal threats are those related to aspects of the experimentation that cannot ensure the causality of the obtained results. Here, the stochastic nature of the algorithm, as well as its setup and parametrisation are internal threats to be considered. Therefore, all experiments are based on 30 independent executions. Furthermore, a parameter study was conducted to determine the best values. As for the construction of the detection model, a stratified 10-fold cross validation is performed to avoid any bias due to the training data. Another threat for the internal validity refers to the setup of the detection method and, more specifically, to the selection of the pruning and classification strategies. On the one hand, the database coverage method has been considered for pruning, as it is a well-known, proved method in the AC literature, and has been already applied jointly to four of the classification strategies considered in this study. On the other hand, the detection performance of several classification strategies has been analysed as part of the experimentation. The statistical analysis has shown that the detection model is not greatly affected by these algorithms.

External validity is related to the generalisation of the experimental results. In this approach, we have selected 15 design patterns for validation and comparison purposes. In addition, these patterns present different number of roles and multiple roles played by a single artefact. Even so, the low number of training samples available for some DPs could limit the generalisation of conclusions. Similarly, the use of DPB and P-Mart repositories, which contain Java projects, implies that our conclusions could not be directly extrapolated to organisational environments of different nature. Nevertheless, these projects are of non-trivial size and they have become frequent benchmarks within the field. The application of GEML to other industrial projects might require its adaptation to their specific requirements, e.g., other programming languages or design microstructures (grammar operators). In this sense, the possibility to extend the collection of operators and the flexibility provided by the CFG makes GEML adaptable to organisational changes.

11. Concluding remarks
GEML was introduced as a novel automatic approach for design pattern detection based on evolutionary machine learning. Knowledge from code repositories is extracted by means of G3P4DPD in form of association rules, a highly readable format to represent knowledge (Grosan and Abraham, 2011). The use of an extendable context-free grammar to declare the syntax of rules makes the learning process highly flexible and adaptable to new organisational environments and design patterns. The application of a pruning method and several classification strategies – already proved in well-known associative classification approaches – to select those rules with best detection capabilities leads GEML to accurate and robust predictions.

An extensive experimentation shows that GEML is able to generate high-quality rules describing implementations of structural, creational and behavioural design patterns. A first study reveals that the prediction performance remains robust – also improving in general terms to other related proposal – even when a single common parametrisation is used for all the design patterns, without the need to adjust it individually. We think that this fact could significantly increase its application in practice, since the software engineer is not required to adjust the parameters. We have also analysed whether the detection capabilities of GEML are affected by changes in the training conditions, using a total of 15 DPs, including behavioural, creational and structural patterns. This is the largest set of patterns analysed so far for a ML-based DPD proposal. Results reveal that GEML remains highly competitive even when very few DP examples are available for learning. Compared to reference DPD methods and tools, GEML supports additional DPs and detects more implementations, although the low number of training samples could cause some variability in the rate of false positives. A demonstration tool is provided to show its use and allow programmers to analyse their own Java projects.

In the future we plan to incorporate new design microstructures – in form of grammar operators – that facilitate the detection of the remaining DPs. In addition, the current tool can be evolved and integrated within existing IDE platforms like Eclipse, thus integrating detection capabilities as part of the programming and maintenance tasks.

