Abstract
In the field of human-computer interaction, the term “integration” describes an emergent paradigm in which the human and the computer are tightly coupled. Our previous research has contributed to this paradigm through the design of “bodily integrated” systems, where the human body and the computing machinery are coupled in a way that allows bidirectional actuation. In this article, we build on this design research: we identify gaps in knowledge regarding bodily integration design and propose, in response, two key dimensions along which bodily integration systems can be categorized: bodily agency and bodily ownership. Conceiving each dimension from low to high allows us to define a four-quadrant design space that highlights key user experiences of bodily integration: Super-Body, Tele-Body, Chauffeured-Body, and Possessed-Body. We demonstrate how this design space can be used to analyze bodily integration design using three of our own bodily integration systems as illustrative examples. We also identify seven design strategies for interaction designers to design future bodily integration systems: turn-taking, safety, ease-in, movement, sensations & perceptions, personalization, and bystanders. Ultimately, we hope to advance the emergent integration paradigm through a body-centric design perspective.

Previous
Next 
Keywords
Human-computer integration

bodily integration

exertion

embodiment

1. Bodily integration
The term “integration” is increasingly used to describe an emergent paradigm in HCI in which the human and the computer are tightly coupled (Mueller, Lopes, et al., 2020). Farooq and Grudin (2016) characterize this change as a transition from the computer working for the user to with the user. They point out, as an example, how voice assistants have gone beyond taking orders (Human: “Wake me up at 7 am”) to working with humans (Assistant: “It is 6:40 am. You should get up now because bad weather will increase your journey time”). Here, humans and computers can both “act with autonomy” (Farooq & Grudin, 2016).

Interestingly, emerging systems increasingly focus on human-computer integration on a bodily level (Mueller, Lopes, et al., 2020; Mehta et al., 2018), treating the body as a form of material that can be altered, extended, re-appropriated or reduced. For example, the “Robotic Symbionts” system (Leigh & Maes, 2016) extends the human body with an autonomous hand extension, enabling the human-machine to grab objects typically too big for one hand. In “Proprioceptive Interaction”, the designers (Lopes, Ion, et al., 2015) repurpose the wrist as actuators that the human and the machine can share for two-way communication.

However, amid this expansion of innovation, design guidance for bodily integrated systems remains limited (Grudin, Höök, Maes, & Mueller, 2018; Leigh, Sareen, Kao, Liu, & Maes, 2017). Recent research has primarily focused on two areas: the technical challenges of integration (Bareket et al., 2016; Britton & Semaan, 2017; Jovanov, 2006), such as optimizing power consumption; and the philosophical challenges, including reconciling posthuman, cyborg and body-centric perspectives amid human-technology couplings (Roden, 2010). Through this article, we introduce an additional line of enquiry that focuses on the user experience of systems that allow for bidirectional physical interaction, i.e., actuation, between the human and computational machine. We draw on related concepts from psychology, that have recently gained interest in HCI (e.g. (Bergstrom-Lehtovirta, Coyle, Knibbe, & Hornbæk, 2018; Coyle, Moore, Kristensson, Fletcher, & Blackwell, 2012; Kasahara, Nishida, & Lopes, 2019; Kilteni, Groten, & Slater, 2012; Seinfeld, Feuchtner, Maselli, & Müller, 2020)), as important metrics of user experience. Namely, we evoke the concepts of bodily ownership and bodily agency, to examine the experience of human-machine integration systems, as it has been previously highlighted that our body and how much agency we have over it informs almost any experience (Blanke & Metzinger, 2009; Braun et al., 2018).

Ownership is concerned with the extent to which we consider something to be a part of our body (i.e., “that is me”) (Braun et al., 2018). Agency, conversely, alludes to the sense of control over our actions (i.e., “I did that” (Coyle et al., 2012)). We believe these to be key questions for human-machine integration, especially as the integrations become increasingly seamless. If I have an augmented tail (e.g., (Nabeshima, Saraiji, & Minamizawa, 2019; Svanaes, 2019)) that conveys my emotions or enhances my balance, do I come to believe that it is part of me (ownership)? If my hand extension (e.g., (Leigh & Maes, 2016)) seamlessly supports my grasp, do I feel in control of it (agency)?

We use ownership and agency as a lens through which we (a) retrospectively examine the experience of existing human-machine integration systems, (b) reveal a design space and further design opportunities for these systems, and (c) identify strategies for designers aiming to create future bodily integration systems.

This article is intended to present a useful starting point for future investigations in an emerging research area. The following stakeholders might find the design space and associated strategies we propose useful:

•
HCI researchers interested in understanding, analyzing and evaluating bodily integration experiences.

•
Design practitioners seeking practical advice on how to develop bodily integrated systems.

•
Designers interested in body-centric approaches to HCI, such as wearables Marshall et al., 2016and exertion games (Mueller, Khot, Gerling, & Mandryk, 2016; Mueller et al., 2012; Mueller et al., 2002; Mueller and Agamanolis, 2008; Mueller and Agamanolis, 2007; Mueller and Berthouze, 2010), wishing to transition from a “body movement representation” paradigm Garner et al., 2014 (such as promoted by movement-sensing cameras that represent bodies on screens) (Seinfeld et al., 2020) towards a more integrated relationship between the human body and computing machinery.

•
Cognitive scientists and psychophysics who aim to gain a deeper understanding on the boundaries of sense of agency and sense of ownership, their modulation and manipulation, and how cognitive processes deal with integrated bodies.

•
Engineers of existing body-worn devices such as exoskeletons and orthoses investigating future designs and wishing to re-conceptualize or reconsider user experiences.

The next two sections discuss related work and our approach towards answering the research question: “How do we design bodily integration?” The subsequent section presents a two-dimensional design space of bodily integrated systems across bodily agency and bodily ownership. We use these two dimensions to articulate four user experiences of bodily integration: Super-Body, Tele-Body, Chauffeured-Body, and Possessed-Body. We then describe how our design space and associated user experiences can be applied to existing design examples to demonstrate their usefulness for design practice. We conclude with seven design strategies for the design of future systems as well as discuss limitations and considerations for future research directions.

2. Related work
The research presented in this article was inspired by prior work concerning the design of bodily integration systems. These works describe opportunities to extend the human body through computational machinery, and specific uses of physical actuators that directly interact with the body. Despite the existing initial explorations, the approaches outlined in these works do not readily provide a complete answer on how to design bodily integration. Hence, our work is still needed.

As early as the 1960’s, prior work has advocated that there should be a “very close coupling” between the computational machine and the user (Licklider, 1960). As the decades have rolled on, these computational machines have reduced in size, leading to the emergence of many wearable technologies. As these wearables have become smaller, they have also become more powerful, leading to work that argues that wearables should now extend and augment human capabilities (Raisamo et al., 2019; Schmidt, 2017). These works tend to focus on sensing bodily actions. However, we see an opportunity afforded by actuation technology – which could also be wearable – to go beyond merely sensing, but enable acting on the human body.

Systems that act on the human body are already in existence, however, our understanding of the associated user experiences is still limited. For example, Leigh et al. (2017) developed a robotic extension to a human hand to support the user in everyday tasks, such as providing a firm surface for note-taking while being “on-the-go”. The system can also act on the hand, for example, pushing it away when in danger. Does the user come to see this extension as part of their body? And if so, what does this mean for their user experience? Furthermore, what does it mean for the user's sense of agency if control over the hand shifts from user to system and back?

Our work also draws inspiration from systems created as part of artistic practice, as they often challenge notions of bodily agency and ownership. In particular, Stelarc (2020) has developed a series of art performances using interactive devices that extend the human body with actuators. For example, he has developed a robotic third arm, and simultaneously augments his own arms with additional robotic components. Does this continuation of the aesthetic design support a greater sense of ownership over the third arm? Furthermore, as other people (attendees in Stelarc's art performances) can control all three arms by sending movement instructions over the internet, one questions how the integration between machine-arm and Stelarc's arm was designed and how does it interplay with Stelarc's own sense of agency?

Surprisingly, there appears to be little structured knowledge about how to design such bodily integration systems. These systems often feature mechanical structures complemented by actuators (Herr, 2009) or other actuating technologies, such as electrical muscle stimulation (EMS) (Tamaki, Miyaki, & Rekimoto, 2010), that the HCI community is familiar with. Yet, from our own experience, how to utilize these technologies to design bodily integration experiences seemed to be underdeveloped. We investigated these technologies through our design works, allowing us to extend prior practical work (Lopes & Baudisch, 2017) through pragmatic insights from our design practice.

Furthermore, we note that while the design challenges of traditional user interfaces (e.g., mouse and keyboard) are well understood, research on whole-body interactions (England et al., 2009) is more limited (Schiphorst, 2009), despite emerging guidance from theoretical work. For example, the larger research area of embodied interactions (as popularized by, amongst others, Dourish (P. Dourish, 2001)) has highlighted that HCI should pay more attention to the human body when designing interactive technology. Although these prior works do not address bodily integration directly, we learn from them more generally as they speak to the role of the human body in HCI.

Specifically, Hornecker et al.’s framework (2006) aims to explain the relationship between human bodies and tangible objects. It conceptualizes how objects have the potential to act on “something”. This “something” could be the human body. Building on this, Alexander et al. worked on the opportunities and challenges associated with objects that have the potential to act on the human body (Alexander et al., 2018). We take from these prior works that acting on the human body offers new opportunities and challenges that deserve their own dedicated investigation and wonder how objects that extend the human body can act on the human body and design for this, especially if such actuating objects have agency.

Hämäläinen et al. (2015) pointed out that gravity can play an important role in bodily interactions. This speaks to our focus on actuation, as gravity can be seen as one particular form of actuation, that is, “pulling” the human body and its limbs down to earth. Here, we extend this prior research by investigating the actuation of the human body in any direction of an integration experience.

More broadly speaking, Hummels et al.’s (2007) conceptualization of bodily movement as a design material resonates with our conceptualization of bodily ownership. The term design material asks us to consider who owns the body we are designing. However, the work does not address the design integration issues between the human body and computing machinery, which our work adds.

Working with an actuating device that users can carry, Segura et al. (2013) highlighted that designing for the human body raises technological, physical, and social issues. While this research complements our work because it considers acting on the human body through the motor in the device, its scope is limited to an entertainment scenario. Our work extends this prior work by considering how computing machinery can extend the human body with actuation technology more broadly.

In summary, there exists a body of integration design works with actuation technology. Nevertheless, there appears to be only limited knowledge about how to design such systems. In response, our article complements and expands upon the aforementioned prior investigations by contributing towards closing the gap in our knowledge on how to design integrated systems. We do so by presenting a design space that is produced by two dimensions: bodily agency and bodily ownership, which we explain below. This allows us to answer the research question: how do we design bodily integration?

3. Developing the design space
We started from a review of existing example systems, assembled following prior work by Marshall et al. (Marshall et al., 2011) who collected systems where users experience limited control over their body. This review was complemented by the design and assembly of our case studies, following an approach described by Benford et al. (Steve Benford et al., 2020), in which the authors assembled case studies from their own lab in order to arrive at a design space. Hence, we decided to not only assemble case studies, but also extend their source beyond one particular lab. Using a set of case studies to arrive at design knowledge is not new to HCI; in particular, Gaver et al. have proposed the notion of annotated portfolio research (Gaver & Bowers, 2012) as a useful approach in HCI. Our approach can be seen as an annotated portfolio showcasing three case studies, an approach previously taken to understand bodily experiences (Mueller, Kari, et al., 2018).

The case studies were documented using the following process: We took notes, videos and photographs during the design process as per the research-through-design approach (Zimmerman, Forlizzi, & Evenson, 2007). This assisted in recognizing where we made divergent decisions during the design process across the different case studies. We also conducted studies with each system, which we documented through notetaking. Participants were also interviewed; these interviews were videotaped. The interviews assisted in identifying partial overlap between the user experiences afforded by each system, despite their big differences and diverse application domains. We documented each case study with a video for dissemination online and an article that described the system and results of the associated research. We also presented the work to industry and academic visitors to our respective labs and talked about the case studies in public presentations of our work. This accumulated toward an advanced vocabulary to articulate what was going on in our studies and how we make sense of it.

Moreover, to promote deeper discussion with expert researchers and designers of actuation technologies, we also visited each other in our respective labs and arranged to meet at a seminar we organized to discuss the contributions of our works. The seminar was held at Dagstuhl, a full-time 5-day event about the particular topic of Human-Computer Integration with 29 experts. During these meetings, we became increasingly aware that the HCI community lacks a framework for the associated interactions that could help articulate the phenomenon and guide future design explorations.

During our explorations, we first found the HCI work around the concept of agency useful, as our actuators are sometimes controlled by the user, and sometimes by the computer. We also had experience with the concept of agency through our game design work, where related terms like autonomy feature prominently (Rigby & Ryan, 2011). This provided us with some understanding of the origin of the term “agency”, and in particular “sense of agency”, namely in psychology, which in turn led us to the notion of “sense of ownership”. This latter notion seemed particularly relevant when considering the participants’ interviews in our studies, in which some talked of becoming “one” with the computational machine, which we found intriguing. During the associated discussions, we found the work by Braun et al. (Braun et al., 2018) useful as it discusses both the sense of agency and ownership within one article. However, it was a review article and lacked discussion regarding the implications for interaction design. Nevertheless, this prior work in psychology helped us arrive at the two dimensions of bodily agency and bodily ownership (which we describe below); we found them helpful when categorizing our examples and reflecting on our case studies. Arriving at two dimensions resembles the practice by Benford et al. (Steve Benford et al., 2020) who were trying to unpack the design of cultural systems where there is a conflict between who is in control. The authors reflect on three systems to arrive at their results; a process we follow. This reflection, in combination with related work, allowed us to identify the two key dimensions by which we can characterize bodily integrated systems. Bodily agency emerged out of the observation that our focus on systems using actuation technology highlights the potential that the computing machinery can take control of the human body. Bodily ownership emerged from the observation that in our case studies, the system can be perceived as being “one” with the user's body, appearing to inform the resulting user experience. Furthermore, this being-part-of-the-body has been previously identified as being relevant to the notion of agency (Brugada-Ramentol, Clemens, & de Polavieja, 2019). We hence discuss both dimensions in more detail later in this article.

We summarized the data from our design process documentation using a clustering approach, where we tried to group findings across the case studies. We have experience with thematic analysis, however, as this data is not as homogenous as, for example, sole interview data in textual form, we did not find a full thematic analysis including code comparisons suitable here. Instead, we used thinking-through-writing in a collaborative online environment along with face-to-face meetings to conceptualize strategies for designers venturing into this field. We report on these strategies below, after the design space, and aim to illustrate them by referring back to our individual experiences with our systems, taking us back to our design practice.

We acknowledge that our approach has limitations. Our results emerged organically, rather than with a particular theory in mind, as can be common in design research labs. Therefore, we are aware that any results are based on (and hence biased by) our personal experiences. This allows us to articulate practical insights deeply rooted in design practice that should therefore be readily applicable to practitioners. However, this also means our approach could be difficult to replicate.

We further acknowledge that our framework might have not necessarily arisen in other labs working on the topic. As such, one might think that our scope is limited to our research and practice. However, we point to the fact that our case studies emerged from not just one, but two different labs, suggesting at least some generalizability. Furthermore, during the aforementioned seminar, we realized that we are not the only ones that struggled to articulate what we learned from our design work around bodily integration. We point out that unlike many other HCI works that derive implications for design (Paul Dourish, 2006) often from just one system, we derived our work from three systems. As such, we believe that our work has wider applicability. Nevertheless, we acknowledge that further design work could be conducted to strengthen our work's applicability. Furthermore, we point out that our approach has been used successfully for other related body-centric design projects, such as bodily play (Mueller, Byrne, Andres, & Patibanda, 2018; Mueller, Matjeka, et al., 2020), proxemics interactions (Mueller et al., 2014), movement-sensing (S. Benford et al., 2005), and cultural bodily experiences (Steve Benford et al., 2020). As such, we believe the approach is of value here.

4. Bodily Integration
Based on our own prior work and the extended literature, we argue that it can be helpful to examine bodily agency and ownership to understand the user experience of bodily integration systems. Both agency and ownership are concerned with a coupling between human body and computing machinery, but from different angles: bodily agency in terms of “who is controlling whom”, and bodily ownership in terms of “that is me”.

Prior work has highlighted the importance of control in understanding embodied interactions in HCI (Steve Benford et al., 2020), and the importance of ownership in making sense of bodily experiences (Brugada-Ramentol et al., 2019). Here, we bring these approaches together by looking at both control and ownership together, focusing on bodily integration within an HCI context. We argue that if we look at the degree of bodily agency and ownership, i.e., consider them as dimensions (which we do in more detail below), we can better understand and categorize bodily integration experiences.

Of course, other or additional dimensions are possible. During a Dagstuhl seminar (Grudin et al., 2018) on human-computer integration, the dimensions were extensively discussed and debated. Many dimensions were considered and dismissed as they either did not allow us to stress unique characteristics of integration systems or fell short in considering the role of the human body in the overall experience. In particular, we considered aspects of awareness and the system's alignment with the user's intention as additional dimensions. However, we felt that this four-dimensional design space would be too complex to articulate. Instead, we limit our scope to assist designers with their agency and ownership design with our contribution. We believe that these two dimensions provide a good starting point, as there is still limited discussion around them in HCI, yet they have been identified as key in other disciplines such as psychology (Braun et al., 2018). As such, we bring knowledge from psychology into the HCI integration field and make the associated dimensions applicable to designers, which we believe makes for a good compromise between scope and practicality. We encourage other design researchers to examine additional dimensions in future work. For example, we can imagine a coupling of our work with Benford et al.’s dimensions of awareness, surrender, and looseness (Steve Benford et al., 2020). We welcome such extensions to our framework, as we believe that bodily integration is a complex multidimensional field of study. We present in the next section a bodily integration design space, based on our argument to look at the bodily integration experience via a bodily agency and ownership dimension.

4.1. The bodily integration design space: the bodily agency dimension
The first dimension of the design space is “bodily agency”. This dimension is concerned with the extent to which the user has a sense of control over the computing machinery and their body, as the body could be affected by machinery (e.g. actuators) that directly interact with and control it (an extension previously highlighted (Steve Benford et al., 2020)).

Prior work has described the sense of agency as referring to “the experience of initiating and controlling an action” (Braun et al., 2018). The sense of bodily agency has been used to describe the feeling of authorship that we experience in sentences such as: “It must have been me who just pressed this button”; or “I am the one who is in control of this car” (Braun et al., 2018), or, simply, “I did that!” (Bergstrom-Lehtovirta et al., 2018). A sense of bodily agency involves distinguishing self-generated actions from actions generated by others. For example, if I move my arm, I am the one who is causing or generating the movement. If my arm is being moved – whether by someone else or by a machine – I still have the sense that I am the one moving, yet, the movement was involuntary because someone/something else was in control of it (Gallagher, 2013). Consequently, I would say, “I did not do that!” Similarly, if a bodily integration system would move a user's left arm, the user would also say “I did not do that!” However, what if the user is able to control this “arm movement” functionality, for example, by moving their right arm: The user now has control over their left arm, but mediated through the right arm: Would the user say “I did that?”

Moore (2016) stresses the importance of considering the sense of agency when designing interactive experiences, pointing toward early work that suggests that users “strongly desire the sense that they are in charge of the system and that the system responds to their actions” (Shneiderman, 1992). This suggestion could be rephrased as follows: interaction designers should give users a sense of agency over the system's outcomes in response to the user's actions. Moreover, it has been pointed out that we need to consider agency, especially when it comes to processes that are being automated, when “the system takes over a lot of control that would have been in the hands of the user” (Moore, 2016). For example, in an automated car driving experience, enhanced steering assistance could potentially lead the user to lose their sense of agency (Moore, 2016). Recent research has highlighted that managing situations where a system monopolizes agency, yet the user needs to be in control at certain points in time, is not trivial and further research is needed, especially with systems becoming increasingly highly automated (Berberian, 2019). Prior HCI work confirms the importance of considering the sense of agency when it comes to the design of interactive systems – for example see Benford et al. (Steve Benford et al., 2020), (Bergstrom-Lehtovirta et al., 2018, Coyle et al., 2012) and Kasahara et al. (2019) – and underpins our proposal to use bodily agency as one of the two dimensions of the bodily integration design space.

We focus on “bodily” control to demark a sense of control via bodily activation (Nacke, Kalyn, Lough, & Mandryk, 2011). Bodily activation links to motor control. Although we acknowledge that the sense of agency can entail intentional aspects ranging beyond our bodily boundaries (Braun et al., 2018), motor control processes are believed to be the most basic and almost always involved (Gallagher, 2013). We also acknowledge that prior work has highlighted that interfaces that do not focus on motor control should also be concerned with aspects of agency as they can offer interesting insights. For example, brain-computer interfaces can elicit different experiences of agency in users (Moore, 2016). Furthermore, systems can indirectly engage with motor control. For example, a system could aim to change human behavior by biasing decision making that influences motor control. Then there are other notions of control, such as in “I am the one who is in control over this feeling”. Our framework could potentially also be helpful in these cases. However, for now, our investigation focuses on bodily agency and leaves additional options for future work.

As prior work suggests that agency occupies a non-unitary phenomenal structure (Braun et al., 2018), we postulate that bodily agency runs along a dimension, and we also follow prior HCI research that suggests agency is an important consideration when seeking to understand technologically-augmented experiences and should be examined along a dimension (Steve Benford et al., 2020). We now present the two “ends” of the dimension.

4.1.1. A high and low degree of bodily agency
On one end of the bodily agency dimension are integration systems that allow the user to have a high sense of control over the computing machinery, and in extension, their body.

A common prosthesis offers a typical example of the user potentially having a high sense of control because it aims to replace an existing limb. However, as prostheses become more advanced, there are more aspects to control, and the user can reach a point of overload where they have to make too many control decisions.

On the other end of the dimension lie systems where the user has a low sense of bodily control. With advances in machine learning, more autonomous actions are possible than ever before. While these types of systems are often developed with the intent to help or support the user, they are also implemented for entertainment. For example, fairground rides (Marshall et al., 2011; Schnaedelbach et al., 2008) can be considered systems that limit a person's bodily agency. Admittedly, such constrained situations are generally enjoyed as they afford the user a thrilling experience.

4.2. The bodily integration design space: the bodily ownership dimension
The second design space dimension is concerned with the extent to which the user has a sense of ownership over the computing machinery being a part of their body. We follow prior work that stipulates that a “sense of ownership describes the feeling of mineness toward one's own body parts, feelings or thoughts” (Braun et al., 2018). As we are interested in bodily integration, we focus on “bodily ownership”. Indeed, bodily ownership is noted to be the area on which “most of the research conducted so far has focused on” (Braun et al., 2018).

The feeling of “mineness” is described in statements such as “This is ‘my’ hand” (Braun et al., 2018) and can be concerned with both individual limbs and the whole body. A famous example in this study area is the rubber hand illusion (Botvinick & Cohen, 1998). A rubber hand is placed (in an anatomically plausible position) in front of a volunteer, while their real hand is placed beneath the table, out of view. The researcher strikes both the artificial hand and the volunteer's real hand repeatedly and in synchrony. Most people experience an illusory sense of ownership of the artificial hand, even to the extent that a physiological fear response can be observed when the artificial hand is approached by a knife (Armel & Ramachandran, 2003; Guterstam, Petkova, & Ehrsson, 2011). Researchers have interpreted these results as implicit evidence of the artificial hand's successful embodiment: it becomes “mine” (Armel & Ramachandran, 2003). Furthermore, suppose the volunteer is asked to localize the position where they experience their hand to be (blindly). In that case, they tend to mislocalize their real hand's position toward the artificial hand (Braun et al., 2018).

The sense of bodily ownership has been described as having a complex and non-unitary phenomenal structure (Braun et al., 2018), resulting in interesting phenomena when using interactive technology. For example, when using virtual reality (VR) headsets, it is possible to have participants feel as if a virtual body seen in front of them is their own body, and localize themselves toward the virtual body (Lenggenhager, Tadi, Metzinger, & Blanke, 2007). Experiments like these strengthen our belief that there is potential to investigate the sense of bodily ownership as an important dimension of bodily integration systems.

4.2.1. A high and low degree of bodily ownership
At one end of the bodily ownership dimension are systems where the user experiences a high degree of “mineness”. Systems that are permanently attached to the human body, such as prostheses, can often be positioned on this end of the dimension.

At the other end are systems where the user experiences a low degree of “mineness”. VR experiments have shown that the degree of bodily ownership can be varied so that a user's bodily self-experience can be experimentally associated or dissociated (Braun et al., 2018); more specifically, different technology design can move the user experience along the dimension of bodily ownership.

5. The bodily integration design space
We argue that designers should consider both, bodily agency and ownership, in the design of bodily integrated systems. Prior work in psychology points out that both can play an important role (Blanke & Metzinger, 2009) in any self-experience (Braun et al., 2018), which we argue includes bodily integrated experiences. We acknowledge that prior work has highlighted that the experience of a sense of agency and ownership can be made in isolation (Braun et al., 2018). However, these experiences are not entirely independent from one another and can also naturally coincide (Braun et al., 2018). Therefore, our design space intends to prompt designers to consider both dimensions, particularly, how designing for their different extents might facilitate different user experiences. Mueller et al. (2020) undertook a similar visual approach to highlight the relationship between different perspectives on the body. Hence, we believe that our approach might also be useful here.

6. Four user experiences based on the design space's quadrants
The following sections describe the opportunities and challenges designers might face when designing for each quadrant, summarized below (Table 1).


Table 1. Opportunities and challenges for each quadrant of the design space.

Quadrant	Opportunity	Challenge
Super-
Body	Ability to explore what it feels like to become who one wants to be	How to deal with the loss of habituated bodily capability
Tele-
Body	Being in multiple places at the same time	Transferring human sensibility and responsiveness
Chauffeured-Body	“Letting go” enabling novel bodily experiences	Potential for negative responses such as motion sickness
Possessed-Body	Outsourcing mundane bodily tasks	Responsibility of bodily consequences
6.1. Upper-right: Super-Body
In the upper-right quadrant of the design space sit bodily integrated systems that facilitate high bodily agency and ownership. Typically, these systems aim to elevate the user's bodily abilities, even facilitate superhuman-like experiences. We, therefore, call the associated user experience one of having a “Super-Body”.

Systems from the sports engineering fields are particularly pertinent to this quadrant. For example, although they are not (yet) digitally enhanced, we note the case of the carbon fiber prosthetics used by Oscar Pistorius. The “running blades”, as they have become known, were extensively discussed as to whether they give Pistorius an advantage, and even “superhuman” abilities (Edwards, 2008).

We believe an athlete would aim to be in control of the blades: to experience a high degree of bodily agency. If the system facilitated low bodily agency – the blades “make” the athlete run – it would probably violate the sport's rules. Furthermore, in the beginning, an athlete would need to focus on staying balanced. Then, the athlete would move toward mastery, and instead of thinking about the blades, just think about sprinting. This progression could further the athlete's belief that it is “their legs” (bodily ownership) that carry them over the finish line, not a set of independent legs.

While the “running blades” case was controversial because the athlete needed to work within the confines of the sport's rules, other prostheses exist that openly market themselves as offering “Super-Body” abilities. For example, the “Bebionic Bionic Hand” (Ottobock 2021), a myoelectric-controlled prosthesis, allows users to maintain a constant gripping force, which is not possible with a “real” hand. We assume that the Bionic Hand designers aimed to facilitate high bodily agency due to the extensive effort undergone to develop a sophisticated control system that is marketed for its “precise” control (Ottobock 2021). We have also assumed that a high degree of bodily ownership is sought, given the “this is me” attitude stressed in advertisements for the prosthesis (Ottobock 2021). Interactive prostheses remain in their infancy; while they offer a few advantages over “real” limbs, they often fall short compared to a broader range of parameters. Nevertheless, interactive prostheses are useful because they point to the upper-right hand part of the design space and “Super-Body” integration experiences.

Research efforts in this “Super-Body” quadrant are most visible through the “Superhuman Sports” initiative (Superhuman Sports, 2020). This initiative aims to develop interactive technology for future sports competitions in which participants exhibit superhuman abilities; featuring, for example, leg-attached mechanical spring contraptions that enable users to jump higher (Superhuman Sports, 2018). The aim is to give the athlete a high sense of bodily agency, allowing them to compare their athletic prowess. Furthermore, the aim is also to facilitate high bodily ownership for the athlete to feel that this prowess belongs to them.

A very recent example sitting in this quadrant is a system by Kasahara et al. (2019) that uses electric muscle stimulation (EMS) to enable users to perform movements faster than they would be able to without the system. Movements include, for example, catching a falling pen, and taking a photo of a fast-moving baseball. The system achieves this reaction time acceleration while still providing the user with a sense of high agency. While this combination seems paradoxical – shouldn't users feel that they have accelerated beyond their biological capabilities? – the illusory agency is achieved by finding a “sweet spot” when timing the delivery of muscle stimulation. The findings revealed that when the stimulus was delivered too soon, users felt the action to be supernatural and not controlled by them. However, when the stimulation to produce “super-human” reaction time was delivered just a few milliseconds earlier than the user's original reaction time (~80ms), users perceived bodily agency over the movement (Kasahara et al., 2019). Furthermore, the use of EMS facilitated high bodily ownership; allowing participants to use “their own” hand to grab the falling pen, rather than, for example, controlling a robot hand to do it for them.

6.1.1. Design opportunity
The opportunity for designers creating systems in this quadrant is to help people experience themselves as being able to do something beyond their present capabilities, i.e., possessing bodily capabilities that they do not have without the system. In other words, the opportunity goes beyond merely providing users with tools that they can use (Bergström, Mottelson, Muresan, & Hornbæk, 2019); it enables users to become enhanced versions of themselves. The opportunity for interactive technology to help users figure out who they want to be when it comes to bodily interactions has already been highlighted (Mueller & Young, 2018; Mueller and Young, 2017). We extend this work by pointing out that bodily integrated systems located in this quadrant can help people explore what it might feel like to become who they want to be.

6.1.2. Design challenge
The challenge in this quadrant is that participants might get so used to their “Super-Body” that it becomes part of their perceived self and that this perception becomes habituated, persisting beyond their use of the system. For example, if the system is no longer available, will users miss what made them “them”, no longer feeling “themselves”? Providers of such systems might have various reasons for turning them off (no longer cost-effective, company becomes insolvent, etc.). How will people deal with such situations, where their sense of self has changed, seemingly going backward? Furthermore, how do people with such “Super-Body” powers experience others who lack those capabilities; will they feel superior? We believe that implications for the user's sense of self and social interactions are important challenges (Mueller, Lopes, et al., 2020) worthy of future research.

6.2. Upper-left: Tele-Body
In the upper-left quadrant sit systems that facilitate high bodily agency and low bodily ownership. We call the user experience “Tele-Body” due to the disjointed nature between the human body and an often tele-operated robot. A typical example is the “telexistence cockpit for humanoid robot control” (Tachi et al., 2003) that equips a human with sensors and actuators to allow them to control a remote robot. Such a setup is particularly useful when aiming to operate in a disaster zone or other dangerous areas (Tachi et al., 2003). In this case, the operator's body movements are mapped onto a geographically distant robot, and the robot provides bodily feedback to the person through actuators strapped onto the operator. The system aims to facilitate a high extent of bodily agency by sensing the operator's movement actions and replicating them on the remote robot. These functions give the operator a high degree of control over the robot's actions, in contrast to, for example, an AI-powered robot that executes actions autonomously. We also assume that the operator in this example experiences a low extent of bodily ownership, as it seems clear that the operator's body is in the local (safe) location, while the robot is located in the (dangerous) remote area.

Drones or quadcopters are increasingly designed to facilitate Tele-Body experiences. Users have a high extent of bodily agency as the drone's high definition cameras allow them a first-person view of a remote place, while the user controls the view through their bodily movements. For example, by wearing first-person view goggles, the user can “look around” a location far away from their actual position.

6.2.1. Design opportunity
The “tele” term highlights the opportunity: associated systems offer users the opportunity to be in multiple locations at the same time. This allows users to operate in remote and inhospitable places. Future work might explore if users can experience being in a separate location at a (slightly) different time, across the time continuum, as previously suggested (Sheridan & Mueller, 2010).

6.2.2. Design challenge
One challenge is the design of a suitable mapping, particularly with regard to sensibility and responsiveness, between bodily input and bodily output that comes as a consequence of the low extent of bodily ownership. For example, how to design the sensors and actuators so that the above “telexistence cockpit for humanoid robot control” (Tachi et al., 2003) allows the operator to use the robot's hands to pick up heavy debris while also being gentle when rescuing a human or animal is not a trivial task.

6.3. Lower-left: Chauffeured-Body
In the lower-left quadrant sit systems that facilitate a low extent of bodily agency and ownership. We call the user experience “Chauffeured-Body”, as the experience is analogous to a chauffeur “driving” the human body. Although systems have made significant advances to support the Chauffeured-Body, a current limitation is actuation technology that is both powerful yet safe.

Inferno (Diitalarti, 2016; Meta.Morf, 2018) is an example of a Chauffered-Body system from the arts. Participants wear an exoskeleton on their upper body, and the exoskeleton is controlled in real-time by a choreographer. Participants experience a low extent of bodily agency. Their movements – at least those of their upper body – are controlled by the exoskeleton and choreographed by another person. Were a participant to hit another person, for example, they might say: “This was not me! It was the choreographer!”. Participants probably also experience a low extent of bodily ownership as the artistically “oversized” exoskeleton contraption, which is also clearly attached to the main control system via a series of highly visible cables, is distinctly different from their bodies.

Another, more traditional, example in this quadrant is a rollercoaster. On rollercoasters, participants experience a low extent of bodily agency as they have little control over the ride. Strapped into their seat and unable to stop or pause the experience, users must endure it to the end. Riders also experience a low extent of bodily ownership as they would probably not describe the rollercoaster as a part of their body. Although this is a non-digital example, we point out that an increasing number of roller coaster rides emerge that incorporate interactive technology (Burt, 2019).

6.3.1. Design opportunity
One opportunity in this quadrant is for designers to facilitate novel experiences that thrive on unique bodily sensations. The rollercoaster example highlights this opportunity: participants can enjoy “letting go”, resulting in a “thrilling” experience (Schnaedelbach et al., 2008). While “letting go” by abdicating control to a computer has been previously considered in the context of interactive systems (Leong, Howard, & Vetere, 2008), the design space helps identify that this opportunity also extends to bodily integrated systems.

6.3.2. Design challenge
A limited sense of bodily control can, like with many fairground rides, lead to motion sickness and similar sensations of unease. Because fairground rides are generally of short duration, the risk of motion sickness is reduced. Designers of systems in this quadrant should take note of this principle and consider how long their users can experience the associated sensations.

6.4. Lower-right: Possessed-Body
In the lower-right quadrant sit systems facilitating low bodily agency and high bodily ownership. We call the user experience “Possessed-Body” as it can feel and appear as if an external force possesses the user's body. A constraint in supporting such experiences lies in the limited resolutions of associated technologies. For example, most EMS systems suffer from the fact that stimulating muscles indirectly through the skin allows for only coarse control.

We use the term possessed as the computing machinery can control the body, although it still appears as if the user is in control. While we commonly believe that we are in control of our bodies, medical practitioners can point to pathological instances where this is not the case. For example, seizures can result in uncontrolled shaking movements. We note that interactive technology can contribute to these experiences. For example, see epileptic seizures due to playing video games (Ferrie, De Marco, Grünewald, Giannakodimos, & Panayiotopoulos, 1994). Hence, we should consider the role technology can play for the “Possessed-Body” also from this perspective.

Many of the recently emerging EMS-systems occupy this quadrant. Typically, EMS users are aware that the actuated movements are not authored by themselves but are certainly executed by “their” body. For example, Pfeiffer et al. (2015) demonstrated an EMS system through which the computer can confer walking directions by stimulating the user's thighs to rotate the legs. In this instance, the user does not believe they are rotating their legs, but they retain full ownership of their legs. (Manabe, 2008) artwork of the “possessed” face uses EMS to control facial muscles in sync with digital sound. Also, Lopes et al. (2015) created an EMS device that “shows” users how to interact with new objects by moving their own body, causing them to directly manipulate the object in the correct poses. This work intends not to convince the user that they are causing the action, but to give an embodied instruction of the action required.

6.4.1. Design opportunity
One opportunity associated with the “Possessed Body” is for designers to create experiences in which the computing machinery “takes over”. This “taking over” might allow the user to focus on other tasks, reducing cognitive load. For example, we can envision an EMS-controlled arm executing a computer-controlled task while the user gives their attention to an operation with their other arm. This can include “outsourcing” mundane or undemanding tasks to the system. In contrast to outsourcing the job to a regular, non-integrated system, one possible advantage of such bodily integrated systems is that the user experiences a high degree of bodily ownership and feels the outcomes to be “theirs” (in contrast to, for example, having outsourced it to a robot).

Furthermore, designers have the opportunity to design Possessed-Body systems in ways that allow users to experience new and unusual bodily movements. Given that new and unusual bodily movements are one of the key strategies used to facilitate somaesthetics experiences (Höök, 2018), insights about this quadrant could extend our design approach to somaesthetics.

6.4.2. Design challenge
The term “possessed” already hints at the challenges. Users of such systems can feel “possessed”, as the computing machinery appears to have replaced the user's control over their body. This can lead to situations where systems take a “dark turn” (Greenberg, Boring, Vermeulen, & Dostal, 2014). For example, a system could employ actuators to “make” a user's hand harm another being. This raises many ethical and legal challenges, such as who is responsible, the user or the programmer?

7. Applying the bodily integration Design Space
This section describes how our bodily integration design space with its four quadrants can be applied to existing design examples to demonstrate the framework's usefulness for design practice. Our three systems support various application domains and employ different technologies, showcasing the general applicability of the framework.

We begin with a summary of the three systems (Table 2).


Table 2. Three example systems and their characteristics.

System	Application domain	Technology	Aim
Ava	Mobility	Electrical engine	Investigating novel riding experiences
Muscle Plotter	Work	Electrical muscle stimulation	Boosting engineering expertise
Balance Ninja	Entertainment	Galvanic Vestibular Stimulation	Exploring novel ways to experience the body as play
7.1. Design Example 1: Ava
“Ava” is an electric bike, or eBike (Figure 4). The eBike's engine is triggered by the rider leaning forward. When cycling, leaning forward is often the result of the rider intending to put more effort into pedaling and aiming to go faster. We strapped a smartphone to the rider's chest and used the on-board gyroscope to detect this leaning behavior. We then wirelessly coupled this leaning to the eBike's motor controller. When the rider leans, the eBike provides additional engine support, allowing the rider to go faster. We complemented this new functionality with a “turbo” sound effect, played when the eBike accelerates, which is intended to augment the rider's sensation of acceleration.

Figure 4:
Download : Download high-res image (587KB)
Download : Download full-size image
Figure 4. Ava, an augmented eBike

An associated study found that users enjoyed cycling with Ava. Users said they felt like a “superhero”, and that Ava appeared to give them “superpowers” to invoke extra strength to go faster using their body (Andres et al., 2016; Andres, Hoog, & Mueller, 2018).

With conventional eBikes, riders have to operate a throttle or lever (often with settings such as level 1, 2, or 3) to increase the power to the engine. This operational arrangement is reminiscent of a traditional task-based interface, via which the user provides a command to the machine. This paradigm of interaction between the user and the system is not an integration. In contrast, Ava tries to derive meaning from the user's bodily movement that is inherent to the cycling action.

We now examine Ava through the bodily integration design space to clarify the advantages of our design while also articulating opportunities to extend Ava.

7.1.1. Explaining Ava through the design space
Ava is situated in the Super-Body quadrant of the design space. Ava allows riders to experience relatively high bodily agency through the sensor that detects body posture. The sensing allows for continuous control of the engine's support, which is quite different from the coarse, throttle-supported controls of many common eBikes with their 1-2-3 settings. Furthermore, the Ava rider experiences high bodily ownership as their body and the body of the eBike appear to extend each other. It is challenging to unpack who is causing the acceleration: is it the rider putting in more effort; is it the associated leaning-forward action that “puts more weight onto the pedals”; or is it the electric engine? It appears that the combined action leads to an increase in speed, which is experienced by the rider visually, auditorily, and kinesthetically. This led riders to exclaim “I felt like a superhero!” when riding Ava; it was “them”, rather than the eBike, that enabled them to go fast. For example, one participant said: “There is extra power that comes from within my body to make the eBike go faster.”

7.1.2. Extending Ava through the design space
The design space helps to envision a move from the Super-Body quadrant to the Possessed-Body, where the system has more autonomy. The conceptualization of this movement allowed us to develop Ava's follow-up project, in which the system acts autonomously. In this project, the eBike uses data from traffic light change patterns. The system correlates the traffic light change patterns with the speed as well as the location of the rider to offer engine support to assist the rider to pass through all traffic lights while they are green (Andres, Kari, Kaenel, & Mueller, 2019). The original design's associated user experience was characterized as a Super-Body experience. However, by moving the system within the design space, the user experience shifts to one in which the user can appear to have less control, seemingly being “possessed”. This change was reflected in the responses of participants who trialed the new system, for example: “No matter how slow or fast you pedal, the bike knows how fast it wants to go.” Another example quote is: “The bike started to accelerate towards a red light. If I had been cycling on my own, I wouldn't have started accelerating at that point because I didn't know that the light was going to change”.

Alternatively, we can envision moving the system to the Tele-Body quadrant, where the user still has full control over the system, but the sense of bodily ownership is reduced. Here, the user controls a separate machine and uses an input gesture unrelated to the cycling effort (such as the head-tilt mentioned earlier), which the machine senses and uses to control the electric engine.

Moving this system even further across the design space to the Chauffeured-Body quadrant might inspire the invention of an automated, self-driving bike. The user has only limited bodily agency as the bike determines the best path to take once the rider has input where they want to go. The rider also experiences limited bodily ownership, making the experience almost feel like the rider is being chauffeured around by the system (similar to the self-riding bike (Pei et al., 2019)).

7.2. Design Example 2: Muscle-Plotter
Muscle-Plotter (Lopes, Yuksel, Guimbretiere, & Baudisch, 2016) is an interactive sketching system that integrates with the user's body to both monitor and adapt their drawing (Figure 5). For example, in a more technical use case, the system can support the user in drawing the correct wind aerodynamics around an object. In this example, the user sketches a car's outline, which Muscle-Plotter monitors through the instrumented pen. Next, the user seeks to visualize airflow around their car and so begins to draw left-to-right drag lines over and around their sketch. The system, having calculated the drag based on the digital representation of the drawn car, moves the user's wrist appropriately through the use of EMS to ensure the drag lines are aerodynamically correct. As such, the correct drag lines representing the computer simulation are drawn by the integration between user and machine on the same sheet of paper.

Figure 5:
Download : Download high-res image (184KB)
Download : Download full-size image
Figure 5. Muscle-Plotter

7.2.1. Explaining Muscle-Plotter through the design space
The design space helps to understand that Muscle-Plotter operates mostly on a turn-taking basis. First, the input is sensed through the digital pen, then digital data (the calculated streamlines) is outputted through the user's arm movement using EMS. Here, the actuation is based on digital data that uses input from a previous turn of the interaction. We note that one could have also used a tablet that asks the user to draw the shape of a car and have software draw the wind lines next, resulting in the same graphical representation, but executed much faster. However, we propose that the Muscle-Plotter represents a more integrated approach, even though the output might not be as accurate (because EMS does not allow for very fine-grained control of the pen movement). The user has some limited bodily agency. Specifically, they can pause the drawing action by lifting their wrist from the paper. However, any movement in the vertical plane is controlled by the system.

The user is entirely in control during the first half of the turn-taking. They draw the car with no interference or support from the system. For the second half, the system takes control of the user's arm (at least over its up-down movement) via EMS. Based on this understanding, we conclude that the system begins in the upper-right hand side of the design space, then moves to the lower-right hand side. Once the EMS is triggered and the hand's up and down movement is controlled by the computing machinery, the user is no longer in control of that movement, and they might experience low bodily agency. However, the user still controls the left-to-right movement, and through that movement (or pause thereof) can halt the EMS firing. Consequently, we can say that the user's bodily agency is limited to some extent. As an extension to the system, we could envision, for example, a system where the EMS also takes control of the horizontal movement, further reducing the user's bodily agency, and more firmly rendering Muscle-Plotter a possessed body experience. Study participants described how the system seemingly took control over their body in the second half of the experience. One participant remarked: “I can even close my eyes [participant closes eyes and demonstrates how the system still works]”. The fact that this effect was achieved with pen and paper, rather than on a tablet, might further facilitate high bodily ownership. The user did not know what the wind lines would look like, and they still had to move their hand to arrive at the results. The capacity to simply tap on a “draw streamlines” button might seem to be a more efficient approach to achieving the outcome. However, the requirement for the user to also move their arm appeared to facilitate high bodily ownership that contributed positively to the experience.

It appears, at least to outsiders, but possibly also to the user, that the user is in control of drawing the wind lines. One participant wanted to show their friend how “by covering the electrodes, they will think I am the one doing [the drawing]”. This performative aspect of human-machine integration remains an exciting avenue for future work.

7.2.2. Extending Muscle-Plotter through the design space
We now explain how the design space helps us to envision alternative versions of the system. For example, we can envision an alteration in which the user forfeits more control over their body and the system draws entire images using EMS. Such a system would be situated even further in the lower right hand of the design space. Advances in artificial intelligence (Oh et al., 2018) already offer a glimpse of such a future. These advances raise important questions such as: “who is the creative person behind the drawing?” The user is apparently painting, yet the system is in control of the output. Such an experience in the far lower-right of the design space can almost certainly be described as one of being possessed by the machine.

We can also envision the system being modified so that it moves into the Tele-Body quadrant. In this case, the system might support a physically separate task, as the user could input the drawing command with their left hand, while the right EMS-controlled hand outputs the resulting lines.

We can also envision another version sitting in the Chauffeured-Body quadrant. The system would act autonomously while facilitating low bodily ownership; this could be achieved through large actuators attached to the user's hand that move the hand around to draw the drag lines for the user.

7.3. Design Example 3: Balance Ninja
Balance Ninja is a two-player balance game (Byrne, Marshall, & Mueller, 2016; Byrne et al., 2016; ; Byrne et al., 2020) (Figure 6). Each player stands on a balance board, which extends slightly beyond the length of their stance. These boards rest above the floor on an 8 cm beam, creating an unstable surface on which the players have to balance. Balancing is relatively straightforward when players are stationary.

Figure 6
Download : Download high-res image (314KB)
Download : Download full-size image
Figure 6. Balance Ninja.

To play Balance Ninja, players stand on their board and face each other. The players’ angle of lean is measured through an accelerometer in a smartphone strapped around their chest. The players are also equipped with a Galvanic Vestibular Stimulation (GVS) system that applies a small (<2 mA) current via electrodes attached to the mastoid bones behind each ear. Applying the current to each electrode affects the player's sense of balance in that direction, causing them to lean to the side.

We programmed the system so that when player 1 leans, the phone sensors tell the server to activate player 2’s GVS system in that lean direction (and vice versa). If player 1 leans to the left, then the GVS causes player 2 to lean to the right; mirroring player 1’s moves (as they are facing each other). However, as player 2 moves, player 1’s GVS is activated, which causes them to lean. The further each player leans, the greater the stimulation level, causing a more significant loss of balance for the opposing player. By “battling” in this way, players are continually struggling to remain balanced while also trying to lean to knock the other player off their balance board. The maximum stimulation is applied when players are leaning around seven degrees from the vertical, which, although a noticeable lean, is not enough for a player to lose their balance without the GVS.

The game's objective is to cause the opposing player to lose their balance and either step off their board or touch their board to the floor. Players are free to “attack” at any time. A point is awarded, and the first player to reach five points wins the game. Points are displayed on a scoreboard visible to both players and the ultimate winner is the first player to reach five points.

7.3.1. Explaining Balance Ninja through the design space
Examining Balance Ninja through the design space reveals that the more players lean, the more Balance Ninja moves from the upper-right Super-Body to the lower-right Possessed-Body quadrant. Players experience low bodily agency when the GVS affects their sense of balance and makes them lean in one direction or the other. As the other player controls the GVS, the bodily agency is low. The player has limited control over when the system fires and the extent to which it fires. Players often tried to influence this by making their opponent laugh, thereby reducing their concentration on controlling their upper body and hence the sensor. The bodily ownership in Balance Ninja is high, as players experience the leaning body as theirs: it is their body that the opponent controls. Participant reports indicated that this heightened bodily ownership was important to the appeal of the entertainment experience (Byrne et al., 2016).

What seemed intriguing for many participants was that we chose not to use physical or mechanical actuators (such as solenoids or pistons) to move players in a more traditional approach to the design of fairground rides or games. In these systems, the actuating technology works even without the human body: a robot could replace the human, and the underlying system would still work. In contrast, with GVS, the system only works because there is a human body involved. This design results in an experience where there is a momentary loss of bodily control without a forceful external reason. This can result in situations where players might accidentally trip because they are not paying enough attention, rather than deterministically stepping off the board due to a mechanical contraption pushing them off.

These design features align with the previously articulated user experience of being “possessed”. A study (Byrne et al., 2016) confirmed this: “It was fun, as a game perspective trying to make the other person feel what I was feeling”. Participants described the best part as “the two occasions I got where it was really clear that the game was actually affecting my sense of balance”, and “when I did feel it, the kind of visceral feeling almost when you actually go: ‘actually this thing has made me unbalanced!’”

7.3.2. Extending Balance Ninja through the design space
The design space helps us to ideate alternative versions of Balance Ninja. For example, by considering the upper-right quadrant, we can envision a single-player version. Here, the player affects their balance through leaning. The player controls the system, but the system uses GVS to amplify the effects of any leaning actions. Such a game could not only be used for entertainment but possibly also for balance training by making existing balancing more challenging.

Alternatively, we can envision moving the game to the upper-left Tele-Body quadrant. For example, in a single-player game, motors installed in the balance board might affect its tilting, aiming to topple the player off. We believe this could facilitate lower bodily ownership.

Examining the lower-left Chauffeured-Body quadrant also inspires design alternatives. For example, we can envision the user enters a VR environment and sits in a “Haunted Swing”. Haunted Swings are 19th-century fairground rides that give riders the impression that they are turning upside down (here, it would be leaning left and right) by rotating the room independently from the platform on which the user is seated. Digital technology can push this experience further. For example, we developed AR Fighter (Byrne, Marshall, & Mueller, 2018); a two-player game in which participants also try to stay balanced while standing on one leg, wearing head-up displays that artificially tilt the vision of each player based on their partner's leaning in one direction or the other.

8. Design Strategies for Bodily Integrated Systems based on bodily agency and ownership
While the design space can be used to determine the “What?” of the design process, we must also consider the “How?”. We now present a set of strategies for consideration by designers interested in developing bodily integrated systems. We base these strategies on our experiences of designing, developing, trialing, and widely exhibiting bodily integrated systems. Furthermore, we also base these strategies on our experiences of conducting associated studies. Combining our research and practice insights with our craft knowledge has resulted in a better understanding of how designers can utilize the two dimensions to design bodily integration systems.

Arriving at design strategies is – at least for us – not necessarily a straightforward and meticulously planned process. The design strategies emerged organically through a messy design practice across multiple labs where thinking about the resulting user experience influenced future designs and vice versa (Mueller, Byrne, et al., 2018; Mueller, Matjeka, et al., 2020; Mueller et al., 2014). Like prior work, we used “thinking through writing” combined with whiteboard sessions, aiming to make sense of our practice (as in similar research endeavors (Mueller, Matjeka, et al., 2020)). We then combined these activities with “tinkering” sessions, in which we experimented with technologies like EMS, to make sense of our tacit knowledge and conceptual thinking. We also used a Dagstuhl seminar on Human-Computer Integration (Grudin et al., 2018) with Jonathan Grudin, a co-author of the seminal “integration” paper (Farooq & Grudin, 2016), to refine our thinking. Almost all seminar participants then came together to articulate a general vision of integration for the HCI field (Mueller, Lopes, et al., 2020). Some of the workshop participants also extracted specificities for playful integration in the context of digital games (Mueller, Kari, et al., 2020). While we consider play, we present a more general view on bodily integration for a broader application domain. Together, we extended our prior investigations through a deeper understanding of a specific subset of integration, that is, bodily integration, which culminated in the following strategies for interaction practitioners and design researchers.

We do not see our set of strategies as a final list, nor that these strategies guarantee results. Rather, we highlight that they are based on our design practice (what worked for us), and we hope that they will work for others. Given that we have built this article using bodily agency and bodily ownership, the fields from which these concepts originate might also contribute to the current and future strategies. For example, we can envision experiments based on the rubber hand illusion that could empirically confirm some of our strategies. Furthermore, we acknowledge that we have not yet validated our design strategies through additional design activities, such as design workshops where they could be trialed and compared with practices in which they are not employed. We hope that the strategies are abstract enough to be applied to a range of systems, yet precise and relevant enough to design practice to be immediately useful in the field.

We recommend to designers who are interested in developing bodily integration systems to read through the entire list of design strategies first. Then they should identify which ones apply to their particular application context. Although we aimed to articulate them as separate from technology as possible, we acknowledge that the strategies might not accommodate all (future) technologies. Furthermore, the strategies are not meant to be followed in a particular order, nor do they require to be implemented. They should serve designers as an initial list, rather than as a final “must-dos”. We have had good experiences with their implementation and offer them to designers as hopefully useful starting points.

We begin with a summary of the design strategies (Table 3).


Table 3. Seven design strategies.

Dimension the strategy is concerned with	Strategy title	Strategy
Bodily Agency
Turn-taking
Consider turn-taking to manage low bodily agency.
Safety
Consider allowing the user to regain high bodily agency at any time.
Ease-in	Consider easing users into altered bodily agency.
Movement	Consider engaging inherent movement for altered bodily agency.
Bodily Ownership	Sensations & perceptions	Consider sensations and perceptions for bodily ownership.
Personalization	Consider personalization to support bodily ownership.
Bodily Agency and Bodily Ownership	Bystanders	Consider communicating a user's altered bodily agency and ownership to bystanders.
8.1. Consider turn-taking to manage low bodily agency
Engaging with low bodily agency can have advantages, as we note with respect to Balance Ninja's entertainment values. However, engaging with low bodily agency also comes with challenges, such as participants feeling uncomfortable with the sensation. Designers should consider managing any limited bodily agency their system might facilitate. We suggest considering turn-taking (drawing from previous work in bodily play (Mueller, Gibbs, Vetere, & Edge, 2017)) as an easy and effective way to manage a user's low bodily agency. For example, suppose a designer aims to develop a highly automated system. In that case, a user's low bodily agency could be considered by implementing turn-taking, where at every other turn, the user regains (at least some) agency.

Muscle-Plotter provides a strong example of the benefits of turn-taking. The user begins by drawing the car outline, experiencing no reduced bodily agency because the EMS system has not yet been triggered. The EMS system fires only once it is time to draw the aerodynamic lines. Once they are drawn for that car outline, the next turn is to draw another car and the EMS is turned off until it is time for the next set of lines. This “on and off” experience of bodily agency seemed to help users to manage the loss of agency when EMS controlled their drawing arm, given that EMS control is a rather unusual and surprising experience for most participants.

Balance Ninja also uses turn-taking as a way to manage user's low bodily agency. Once players experience low bodily agency, triggered by the GVS, and tip their balance board onto the ground, the GVS stimulation stops. Another turn begins and players step back onto their balance board. The players can reconsider their tactics: for instance, whether they begin defensively, by trying to stay as straight for as long as possible, or offensively, and actively attempt to topple the other player first. We expanded our experimentation with turn-taking, alternating between offensive and defensive roles: requiring players to use their first turn trying to topple the other player over; then, requiring them to use their next turn to try not to fall over. While these adjustments may have helped players to better manage their limited bodily agency, we abandoned the idea because it appeared that players had more fun if they could flexibly choose to play offensively or defensively (as previously suggested for bodily play (Mueller et al., 2017)). However, we still contend that facilitating more turn-taking could better enable users of non-entertainment applications to manage low bodily agency.

When using Ava, the eBike, riders did not experience low bodily agency. However, the subsequent iteration of the eBike, which assists the rider to speed up to pass through traffic lights while they are green (Andres et al., 2019), demonstrates how turn-taking – in this instance the increase and decrease of engine support based on traffic light data – can provide a way to help users manage limited bodily agency. Our goal was to facilitate an experience that is unmistakably cycling, despite the computing machine sometimes taking “control” over the rider's body by “making” them cycle faster.

8.2. Safety. Consider allowing the user to regain high bodily agency at any time
Bodily integration systems often involve the computing machine controlling the human body in some shape or form. Earlier in this article, we outlined the benefits of this feature. However, this feature also presents harm risks to the human body and others. Accordingly, it is important for designers to empower the user with the ongoing capacity to regain high bodily agency at any time, should the user decide it is necessary. Most industrial machines have such an “emergency” switch. For instance, mechanical systems that could harm a human, such as industrial-size robots, feature a red “stop” button. When designing bodily integrated systems, designers should implement analogous safety functionality. We use the word analogous because we acknowledge that bodily integration designers experience additional challenges associated with the risk that the computing machine might take over control of the human body, rendering the user powerless to engage their motor control to press the button. Designers should consider other ways to empower users to regain bodily control, for example, through issuing a “stop” gesture or verbal command.

The Muscle-Plotter system allows users to regain high bodily agency at any time through the sensing system that tracks the user's hand. Suppose the user becomes uncomfortable with the low bodily agency as the EMS moves their hand. In that case, they can simply stop by lifting their hand from the paper, and the EMS stimulation will cease immediately. It is worth noting that other EMS-based systems have explored more complex approaches to provide users with a quick way to regain agency. For example, Affordance++ (Lopes et al., 2015) utilizes optical tracking to dismiss the EMS if the user quickly moves away from the location where the EMS was first triggered. Pose-IO, an EMS system for eyes-free communication (Lopes, Ion, et al., 2015), is an example of a system which uses the user's volitional movements to understand their need for bodily agency. Users of Pose-IO can dismiss the EMS feedback by simply shaking their hand.

Balance Ninja's design also considered that users should be able to regain high bodily agency at any time. If players experience low bodily agency in any negative way, they can easily turn the system off, using the easily accessible power button on their wearable gear. Furthermore, the GVS cables are attached to the electrodes behind the players’ ears using detachable clips. These clips allow players to pull on the cable using very little force and unclip themselves at any time. This design also afforded additional safety benefits, as excessive player stumbling would also unclip the cable from the electrode, allowing the player to regain bodily control quickly.

We modified Ava's breaks so that riders can regain high bodily agency at any time. Any amount of pressure the rider puts on the brakes will stop the eBike's engine support, regardless of what the bodily posture sensor stipulates.

8.3. Ease-in. Consider easing users into altered bodily agency
Users can find experiencing altered bodily agency uncomfortable, especially the first time. Users feel “out of control” and it is a sensation that can require time to accommodate. Getting used to the change can be facilitated by slowly easing users into the altered bodily agency. Benford et al. suggest that users should be eased into experiences (2009). We agree with their characterization of the overall experience as a trajectory (2009) and its importance on carefully designed entry points (Marshall et al., 2011). Accordingly, we suggest that designers consider easing users into the experience, especially if a bodily integration system aims to facilitate reduced bodily agency. For example, suppose designers want to develop a system that aims to control the user's body. In that case, it should do so carefully and slowly to ease users into the expected altered bodily agency.

Muscle-Plotter aims to ease users into a reduced bodily agency through its calibration procedure, which gently introduces users to the EMS experience.

Balance Ninja eases players into a reduced bodily agency by using two test rounds. Players can freely experiment with their bodily agency, without running the risk of losing points. During these rounds, players can explore the sensation of reduced bodily agency and test how far they can lean without losing balance. As systems without real-world consequences (Salen & Zimmerman, 2003), games lend themselves to the task of easing users into a reduced bodily agency, because they enable players to explore and try out different options. While we encourage designers to consider using games to ease users into their use of systems that involve reduced bodily agency, we leave the development of evidence about this matter for future work.

Our work on Ava, the eBike, highlighted the importance of easing users into altered bodily agency. Experimenting with hacking an existing eBike engine controller, we found that supporting a rider's pedaling effort through an engine can facilitate very different experiences, ranging from almost unnoticeable to abrupt and aggressive, and that this range of experiences depends upon how subtly and finely tuned the engine support is to the pedaling action. Consequently, we concentrated on getting the engine support right and adjusting the power output along a curve that was extensively refined over numerous trials. Even small malalignments could lead to a “jerking” of the engine and an unpleasant riding experience. We found the preferred approach comprised very subtly increases to the engine support, so that users never felt a specific “point” at which the engine “kicked in”, giving the user the impression that it was them “all along” who provided the push forward.

8.4. Movement. Consider engaging inherent movement for altered bodily agency
Rather than engaging unrelated movements as input in their designs, we recommend that designers consider identifying movements the user already performs, reducing the need to learn additional movements. These inherent movements can serve as implicit inputs (Fullerton, Swain, & Hoffman, 2004) to the system. For example, Svanaes’ tail makes use of the fact that a user's hip is already moving when walking (Svanaes & Solheim, 2016).

In Muscle-Plotter, we looked at how a user moves their hand over the paper when drawing lines. We used the left-to-right as an inherent movement (in Western cultures) to control when to fire the EMS. We could have used an unrelated movement, such as pressing a start/stop button with the other hand. However, we contend that engaging inherent movement supported the user to adapt to the altered bodily agency.

In Balance Ninja, the inherent movement of leaning when losing balance was used to control the balance of the other player. In other words, the movement inherent to losing balance was sensed and also actuated through the GVS. We could have also sensed other, unrelated movement, for example, a nod of the head. This approach might also have delivered an entertaining experience. However, we do not believe that the resulting experience would have been as successful as one using inherent movement.

With Ava, the eBike, the inherent movement of leaning forward, with the intent to accelerate, is sensed, and the engine is prompted to increase support. We believe we have supported the altered sense of bodily agency by utilizing such an inherent movement as implicit input. It is difficult for the user to separate the extent to which they and the engine individually contributed to the increased speed.

8.5. Sensations & perceptions. Consider sensations and perceptions for bodily ownership
Designers should consider employing sensations to provide feedback to facilitate high bodily ownership and perceptions to facilitate low bodily ownership. Prior work highlights that differentiating feedback between sensations and perceptions can be useful when designing body-centric systems (Mueller, Matjeka, et al., 2020). Localized sensations are felt mainly through touch, pain, proprioception (the “internal” perception of bodily posture and bodily boundaries), kinesthetic sensations (the “internal” perception of bodily movement) and temperature (Slatman, 2016). We find that enabling feedback that supports such localized sensations can facilitate heightened bodily ownership as it allows users to experience their bodies as theirs. In contrast, most existing interactive systems employ screens and audio. These systems enable users to perceive any information displayed, often on a screen distant from the body. The information belongs outside the perceiving body (Slatman, 2016), and the body is separated from the system, leading to reduced bodily ownership. We recommend that designers consider employing sensations for feedback to facilitate high, and perceptions (such as screens and speakers), to facilitate low bodily ownership.

Muscle-Plotter uses proprioception as the main feedback in response to the user's input. The user experiences the localized sensation of their hand moving and generating the computed streamlines. This experience appears to facilitate high bodily ownership. Users reported that it was their hand that produced the resulting drawing. We could also envision a version of the system that would provide the output on a screen, akin to the tablet version mentioned earlier. Here, the feedback would be perceived through the eyes; we contend that this feedback through a visual perception would facilitate lower bodily ownership.

In Balance Ninja, feedback is perceived through the kinesthetic sense. The user receives information from the computing machinery through the “internal” perception of bodily movement. If, conceptually, we compare this design to a version of the system where users perceive feedback through a screen that, for example, displays an avatar that “leans”, we contend that this latter design would facilitate lower bodily ownership because it does not engage with localized sensations of the body.

Ave, the eBike, engages kinesthetic sensations when providing feedback, including the feeling of increased airflow against the body when accelerating. The system also offers audio feedback in the form of the aforementioned acceleration sound. We believe that the wind sensation contributed to a heightened sense of bodily ownership. However, the acceleration sound might have reduced that sense of bodily ownership. The sound was emitted through a visible, handlebar-mounted speaker, making it apparent to the user that the sound came “from” the bike. We have considered design alternatives, including bone-conducting headphones, that might engender higher bodily ownership by making it more difficult for the user to attribute the sound source to the bike. We used bone-conducting headphones for the traffic light eBike we described earlier (Andres et al., 2019).

8.6. Personalization. Consider personalization to support bodily ownership
The sense of bodily ownership is a complex phenomenon, because every person's body is different. Prior work around technology use concerning the body has stressed this complexity (Slatman, 2016). However, many systems, especially commercial systems, still seem to subscribe to a one-size-fits-all approach. In particular, we highlight that HCI design could do more to better support people with physical disabilities. Extending these insights, we argue that designers consider personalization – the extent to which the system is personalized to the user's body – as a strategy to support bodily ownership. For example, Svanaes’ tail could support personalization by allowing users to change its size according to the person's center of mass to support balance (Svanaes & Solheim, 2016).

As an exploration into bodily ownership, the rubber hand illusion (Braun et al., 2018) has been personalized in several experiments. Researchers have used a different skin color on the rubber hand than the participant's skin color and the associated experimental results suggest that bodily personalization can support the sense of bodily ownership (Lira et al., 2017).

Muscle-Plotter supports personalization by way of the EMS design: the EMS electrodes are individually fitted to the user's arm. In future work, we could explore the extent to which custom-designing the electrode pad size might optimize the electrical stimulation and heighten the user's sense of bodily ownership. Other researchers have already explored how to customize EMS calibrations and electrode placement for users (Knibbe, Strohmeier, Boring, & Hornbæk, 2017).

Balance Ninja features a calibration step at the beginning of the experience to personalize the extent of GVS stimulation to each player. Because sending a current to the mastoid bones affects each person's sense of balance differently, an operator applies a small current, slowly increasing its intensity and asking the player to report as soon as they feel “something”. Through this calibration process, each player's experience is leveled to their opponent, to enable fair competition.

During the design of Ava, the importance of supporting different body shapes became increasingly apparent. Riders stressed how they could experience a feeling of integration with their bike, but only if it is well adjusted and finely tuned to their body shape. Accordingly, to support bodily ownership, we adjusted the seat and handlebar height to each participant's body shape, and also developed two versions of Ava based on two different frame types. Riders who are more comfortable with a step-in type frame could choose the appropriate version, and others could choose the more “conventional” frame shape. This personalization appeared to help participants experience bodily ownership, with the eBike becoming “part of” their bodies. Designers should consider personalization as a design strategy that can heighten bodily ownership. Further efforts are needed across the bodily integration field to better support a diverse range of body types when designing bodily integrated systems.

8.7. Bystanders. Consider communicating a user's altered bodily agency and ownership to bystanders
Bodily integrated systems can facilitate very personal, altered experiences of the user's body. These experiences can come from “within” and are consequently very private. Bystanders and passers-by are often unable to comprehend what the experience is like for the user and can even remain unaware that they are engaged in a bodily integration experience. The aforementioned Pose-IO device illustrates this situation in a “red hands or slapsies” game triggered by EMS (Lopes, Ion, et al., 2015). In this situation, the user plays a game in which they must avoid one of their hands being slapped by their own, other (EMS controlled) hand. However, because the game technology is hidden from sight, beneath the player's clothing, bystanders will not understand why the player is hitting their own hands, nor why the player finds this playful and laughs. The documentation video and associated study (and participant commentaries) underscore this misunderstanding, showing the player enjoying the experience before rolling up their sleeves to showcase the underlying technology, and inviting the audience to examine the system and understand the experience more fully. Keeping the bodily integration experience private can have advantages, such as facilitating “magical” experiences in which certain aspects are hidden from bystanders (as has already been suggested for spectators (Reeves, Benford, O'Malley, & Fraser, 2005)). However, to enhance understanding, draw other people in, and facilitate social benefits around bodily integration experiences, we recommend that designers consider communicating the altered bodily agency and ownership to bystanders. For example, designers could hint at altered bodily agency and ownership to others by omitting coverings over a system, so that its inner workings are clearly visible.

In Muscle-Plotter, a user could deliberately hide the altered bodily agency and ownership from any bystanders, and behave in a manner that suggests that they can perform aerodynamic calculations “themselves”, in the absence of any external support. This behavior might well be harmless in certain circumstances. However, if a user misrepresents their capacity to perform these calculations without support in other situations – for instance, in a job interview – then third parties, such as interviewers and their hiring organizations, are placed at risk. In these situations, the system support should be communicated to the third party.

Bystanders in Balance Ninja could similarly not understand “what was going on” when merely looking at the players struggling to perform a simple balancing task. To an uninformed onlooker, the balancing boards are very basic and do not pose much of a challenge. Consequently, players often explained to bystanders how the bodily integration system works and shared their experience verbally. Participants suggested informing bystanders by complementing the score display with information about when and how much the GVS system is stimulating.

Ava, the eBike, is based on an existing bike that we equipped with eBike functionality through some of the upgrade kits that exist in the commercial market. Due to the popularity of eBikes worldwide, most people nowadays would identify the bike as an eBike, we believe. When people with knowledge of eBikes see the rider seemingly climb hills with ease, they understand that there is an engine supporting the rider. The visible battery, engine, and associated cables give away the system. However, we recall the early days of the eBike era, when the speed of a person's bike elicited looks of surprise among bystanders unfamiliar with the technology. The fact that accidents with eBikes are more likely than with regular bikes (Fishman & Cherry, 2016; Petzoldt, Schleinitz, Heilmann, & Gehlert, 2017) suggests that we have still not adapted to the spread of engine-supported road bikes. We did not use any additional tactic to make bystanders aware that Ava is a bodily integrated system, as the outfitting with battery and engine already suggested that it was an eBike. However, one might speculate that the associated sound that complements the leaning forward action also functioned to make bystanders more aware that this was a bodily integration experience.

9. Discussion
Our framework around bodily integration has helped us in analyzing existing designs we have developed in our respective labs. By looking at the design space, we have determined where many existing systems sit and where we could “move” them to in the design space to facilitate different user experiences. The design space dimensions have helped to discuss our designs, providing a way to articulate design differences. We hope other designers and researchers will benefit from this work.

We acknowledge certain limitations to our contribution. Our findings are derived from our craft knowledge of having designed bodily integration experiences. Our work's strength is its practice-based orientation in a design tradition that is tightly linked with technology implementation. However, such an approach has inherent limitations (Höök & Löwgren, 2012). For example, our framework might need updating once new technologies emerge. More work is invited that interrogates and enhances the framework. We have only validated the framework through our own applied work and as a team conceptually for the purpose of this paper. Conducting workshops with designers where they are using the framework, compared to workshops without using the framework, could further validate the framework. Additional ways to validate the framework could include examining extra case studies or developing additional ones. Furthermore, contributions to validation could also include interviews with designers and users of bodily integration systems and tracking future work that uses the framework in their publications.

We acknowledge that our current framework is only a starting point and should be developed further in future work. There are several pathways to determine how the work could be further developed. For example, currently, we have only differentiated between high and low extents of each dimension. Further work could segment the dimensions into more fine-grained categorizations. This could help identify additional user experience types, too. Furthermore, additional dimensions could be added or examined separately, paying tribute to the fact that bodily integration is a complex phenomenon. Design practitioners should also consider what additional strategies might exist that could help design for particular locations in the design space.

With these future paths in mind, designers are encouraged to contemplate how their work could help to advance the framework. In particular, designers might want to reflect during use if their associated user experiences match our four quadrant names or are a subset thereof, such as “delighted superhero” or “challenged superhero”. By reflecting on their use of the framework, designers also have the opportunity to articulate their experiences, extending the strength of the framework and our knowledge of the integration field more generally.

We acknowledge that the current framework process could have also been more systematically derived. We could also study the framework in use with design practitioners. Similar to prior research that worked with industry practitioners (Isbister & Mueller, 2014) around a framework, our framework could also be exposed to industry; this could help systematically refine it, both through qualitative data such as interviews, but also quantitatively, for example by measuring how often designs end up in which quadrant, adding strength to the general applicability. The framework could also be systematically evaluated by taking additional design examples and analyzing them with the aim to confirm or refute the framework.

We also acknowledge that we mostly considered users living without a (temporary or permanent) disability. Bodily integration can be considered a beneficial advancement for people with limb loss, and significant progress has been made to support those using orthoses (specifically work on advancing traditional orthoses through digital means (Herr, 2020)). In our work, however, we have not focused on replacing limb functionality. Rather, we have investigated the resulting user experiences when human body and computing machinery are integrated. These experiences can include limb replacement functionality but can also mean enhancing existing bodily abilities. Nevertheless, we point to the need for future work that examines what role bodily integration can and should play for people living with a disability, acknowledging that such future work should build on prior research that already investigated related areas, such as the notion of interdependence (Bennett, Brady, & Branham, 2018).

Furthermore, we have also not fully examined the potential for a dystopian future of bodily integration, where systems aim to acquire too much control over the user's body. This can lead to anything from annoyance to outright rejection of the technology, which we believe is emphasized by the technology's intimate relationship with the user. For example, a very dark scenario would be one where advanced systems allow corporations and governments to control people's bodies at will (such as feared and investigated by individuals like Laura Forlano (Forlano, 2019) or data privacy organizations like Our Data Bodies ("Our data bodies," 2020)). Approaches such as dark patterns (Greenberg et al., 2014) as alternatives to design heuristics (Yilmaz, Daly, & Seifert, 2014) might be useful here to conduct such future research.

Another limitation is that we have only considered single-user and, at most, two-user systems and experiences. Future work might explore bodily integration that involves a large number of people; for example, we can envision a large bodily integrated team activity. The evolution of bodily integration in large-scale contexts could be an interesting avenue for future research.

We also acknowledge that we have yet to fully understand the long-term implications. For example, artist Neil Harbisson, who cannot see colors, has been wearing a device attached to a camera that allows him to “hear” colors through bone conduction. Scans of his brain suggest that over the years of using the system, his brain has become able to “see” the colors, rather than transform sound information into color representations, as his brain exhibits “significant changes in functional neural patterns, structural connectivity and cortical topography” (Alfaro, Bernabeu, Agulló, Parra, & Fernández, 2015). Understanding such long-term implications will help us shine a light on what it takes for users to adopt such bodily integration systems, and we see such investigations as exciting areas for future work.

We also acknowledge that our considerations of the complex notions of agency and ownership are in their infancy. For example, agency is a complex phenomenological structure (Braun et al., 2018) that involves various contributory elements that manifest themselves in the actual phenomenology of agency, which, itself, remains ambiguous (Gallagher, 2013). Gallagher suggested that agency should be unpacked into the complexities of the non-conscious, pre-reflective, and reflective levels (Gallagher, 2013). With respect to this call for an expansion of knowledge, our work has only scratched the surface of agency and ownership regarding bodily integration. We fully anticipate that advancements in the understanding of bodily agency and ownership in other disciplines will prompt and inform further work in HCI design.

10. Conclusion
Our work was motivated by the potential for human-computer integration fostered by contemporary technological advances, particularly those in which the human and the computing machinery are coupled in a way that allows them to act on each other physically. We believe that an integration approach can facilitate novel user experiences, and in particular, that bodily integration can offer exciting new opportunities for users to experience their body, and hence themselves, in interesting new ways. Understanding how to design such an integration between the human body and computing machinery is an underexplored area, particularly because there is limited knowledge about the associated user experiences. In response, we have conceptualized bodily integration as the foundation for an initial and accessible structured understanding of the myriad ways in which human bodies and computing machinery can integrate.

We expect that designers of prospective body-integrated interactive systems will use our dimensions and associated design space to analyze existing systems and to identify underexplored design opportunities as well as challenges. The design space also assists designers to predict what type of user experience a yet-to-be-developed system might produce. Similarly, we expect that researchers will also make use of our framework to undertake structured studies and evaluations of existing systems.

Across all three system innovations, the framework helped us to be more precise about the unique opportunities when considering the human body and computing machinery working together, and to identify interaction design challenges. Nevertheless, we note that supporting integration is not always the right thing to do. In particular, we highlight that bodily integration can bring ethical challenges with it (Grudin et al., 2018; Mueller, Lopes, et al., 2020). We believe that even if the computing machinery takes control over the user's body, the user should always have the last word (a principle we captured in one of our design strategies) and be able to terminate the relationship with the interactive device at any point.

Overall, we believe that our framework allows for more focused explorations and discussions on the design for and practice of bodily integration; that it will be particularly useful as a basis upon which to consider how technology can respond to a range of as yet unmet and underserved user needs; and that it will be helpful as a basis for developing our understanding of what emerging technologies might bring to an integrated future.