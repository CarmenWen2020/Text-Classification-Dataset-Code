Abstract
Programmers are frequently tasked with modifying, enhancing, and extending applications. To perform these tasks, programmers must understand existing code by forming mental representations. Empirical research is required to determine the mental representations constructed during program comprehension to inform the development of programming languages, instructional practices, and tools. To make recommendations for future work a systematic literature review was conducted that summarizes the empirical research on mental representations formed during program comprehension, how the methods and tasks have changed over time, and the research contributions.

The data items included in the systematic review are empirical studies of programmers that investigated the comprehension and internal representation of code written in a formal programming language. The eligibility criteria used in the review were meant to extract studies with a focus on knowledge representation as opposed to knowledge utilization.

The results revealed a lack of incremental research and a dramatic decline in the research meaning that newly developed or popularized languages and paradigms have not been a part of the research reviewed. Accordingly, we argue that there needs to be a resurgence of empirical research on the psychology of programming to inform the design of tools and languages, especially in new and emerging paradigms.

Previous
Next 
Keywords
Mental representations

Program comprehension

Systematic literature review

1. Introduction
Programmers are frequently tasked with modifying, enhancing, and extending applications. To perform these tasks, programmers must first understand the existing code. During the comprehension process, programmers form mental representations of the code they are working with (Détienne, 2001). Empirical research is required to determine how these mental representations are created and the form that they take as a starting point to developing programming languages and tools that fit with the underlying representations. Such an approach would assist programmers in the comprehension process and promote the formation of accurate mental representations. In the study conducted by Wiedenbeck et al. (1993) experts were able to build mental representations with more abstract characteristics than non-experts to support comprehension-related programming tasks such as maintenance and debugging. The findings reported by Wiedenbeck et al. (1993) are compatible with the notion that the ability of programmers to develop accurate mental representations of code is important for supporting programming tasks critical to the development of high-quality software (see also Petre and Blackwell, 1999).

The focus on program comprehension is of particular interest as many of the tasks performed by programmers, such as maintaining and modifying existing applications, require the understanding of code (Corritore and Wiedenbeck, 1999). Empirical research is required to develop an understanding of the comprehension strategies used by programmers. With the growing number of programming languages and tools under development with the goals of increasing productivity and ease of learning and use, there is a great need for this empirical research.

Before conducting more empirical research on mental representations, we need to know the current state of affairs in this area. Knowledge of past empirical research can assist in developing methods that can more accurately target and capture the mental representations under study. To make recommendations for future work on mental representations we must have an understanding of prior research methods and findings. By discovering what research has already been done, we can also learn what gaps remain.

Accordingly, the purpose of the literature review conducted here is to provide an analysis of the research that has been done to advance the body of knowledge related to the psychology of programming. Our review provides a comprehensive overview of the empirical studies performed to date that have contributed to the understanding of the comprehension strategies used by programmers to understand code, and the mental representations created in this process. The work presented here will assist researchers in the selection of appropriate tasks and methods for future work. This review will also assist researchers who want to perform incremental research by building on the work that has already been done in the domain. Empirical studies related to problem solving, program design and development, debugging skills, programmer performance, and learning programming languages that have no bearing on mental representations are not included in this review. The research questions addressed by our review are as follows:

1.
To date, what empirical research has examined mental representations during program comprehension?

2.
How have the methods used in the studies changed over time?

3.
How have the tasks used in the studies to stimulate the comprehension process changed over time?

4.
What are the contributions that have resulted from empirical research on program comprehension?

2. Background
Research in program comprehension encompasses both the study of the cognitive processes used by programmers to understand code and how programming languages and tools support these cognitive processes (Storey, 2006). The cognitive component of program comprehension that is of interest here is the abstract mental representations that are formed during program comprehension. These mental representations, often referred to as mental models, are founded in the theories of text comprehension (Pennington, 1987a).

There have been a variety of differing approaches to mental models including how they are defined and inferred (Cañas and Antolí, 1998). Cañas and Antolí suggested that the reason for this is because researchers from different disciplines study mental models using different tasks and are sometimes interested in different aspects of the representations. The unifying definition for a mental model, proposed by Cañas and Antolí (1998), is a dynamic representation formed in working memory as a result of using knowledge from long term memory and the environment. Mental model representations are described by Cañas and Antolí (1998) as both a process and the result of a simulation process elicited by a task.

The mental model approach to program comprehension is based on the propositional or text-based model and the situation model that were first developed to describe text comprehension (Détienne, 2001). The program model, formed by programmers when applying structural knowledge to the code resulting in a surface level representation, corresponds to the propositional or text-based model formed during text comprehension. The situation model, developed to describe the abstract representation of text, corresponds to the domain model formed during program comprehension when domain knowledge is used to form an understanding of the real world situation represented by the program. The mental model approach to program comprehension involves the construction of both the program model and the domain model (Détienne, 2001).

Empirical research on program comprehension has a direct impact on the development of programming languages and tools. Boshernitsan et al. (2007) developed iXj, a tool that uses a visual language to allow programmers to specify and execute code changes. The design of iXj was guided by the Cognitive Dimensions framework developed by Green (1989) to provide programmers with visual representations that reflect their own mental model of the source code. Tubaishat (2001) developed a theoretical model, Conceptual Model for Software Fault Localization (CMSFL), from empirical research on programming knowledge and plans. The CMSFL model was then used as the basis for developing the BUG-DOCTOR, an Automated Assistant Fault Localization (AASFL) tool that assists programmers with software fault localization. Arab (1992) developed a tool for formatting and documenting Pascal programs to assist programmers to write more readable and easier to understand programs. The development of this tool was influenced by empirical research that identified formatting and documenting as important factors in program comprehension.

Other common approaches to empirical research on programming languages and tools have been usability and comparative studies. Usability studies examine the human use of programming languages, whereas comparative studies compare the features of different programming languages. The usability studies reviewed by Hornbæk (2006) employed a variety of measures and definitions of usability, and often compared previous or competing versions. Comparative studies, including those performed by Prechelt (2000) and Nanz and Furia (2015), analyzed performance of programs written in programming languages from procedural, functional, and scripting paradigms, and also compared languages within these paradigms. Performance in these studies was measured using quantitative analysis of the program features such as lines of code, runtime, memory usage, and reliability. Programmer effort was also analyzed by Prechelt (2000) who measured the time required to write a program. Comparative studies on parallel programming languages have taken a similar approach in comparing solutions to problem sets or algorithms written in different parallel programming languages (Feo, 2015, Chamberlain, Deitz, Snyder, 2000). The study conducted by Feo (2015) also compared qualitative measures of how the programmers who wrote the solutions felt about how easy or difficult the program was to write, and what they felt was good or bad about the programming language.

The usability and comparative studies mentioned here are comparing programming languages that are already widely used. Studying a language when it is already widely used offers limited advances unless one is willing to modify the language as a result of the empirical observations. These studies did not take into consideration the user and their ability to understand and provide maintenance for programs written in different programming languages. Comparative studies are also limited in that they only give the user choice between existing languages; they do not direct the development of new languages that may require a complete departure from the current approaches to provide the user with languages and tools that align with their cognitive processes. The shift from comparative studies to research on program comprehension, especially in parallel programming where there is a significant lack of theory (Mattson and Wrinn, 2008), is necessary to inform the development of programming languages, instructional practices, and tools.

3. Method
To answer the research questions posed in this study, we conducted a systematic literature review following the guidelines provided by Kitchenham and Charters (2007) and in accordance with PRISMA guidelines (Moher et al., 2009). Systematic reviews are performed to collect literature relevant to answer specific research questions by using a well-defined and documented protocol in order to provide a fair evaluation and enable study audit and reproducibility (Kitchenham and Charters, 2007). In our systematic literature review we adopted as a search strategy automated search and backward snowballing technique. The automated search strategy included a search of databases from each of the relevant fields: psychology and computer science. All available publication types (e.g., theses, journal articles, conference papers, books) were included in the systematic review because the research fields involved in this study use some publication types more frequently than others. For example, computer science publications are more often conference papers whereas psychology publications tend to be journal articles. The inclusion of theses makes it more likely that unpublished work will be considered. To understand how research on program comprehension has developed over time, the review was not limited to a particular time period. The abstracts or full texts of documents extracted by the database searches were screened using specific inclusion and exclusion criteria (i.e., eligibility criteria). The eligibility criteria were used to ensure that the documents were relevant to the research questions presented earlier, which are centred around empirical studies on program comprehension. The automated search was followed by backward snowballing, a technique that uses the reference list of data items to identify additional data items (Wohlin, 2014).

The systematic review also included an analysis using the full text of empirical studies that met the eligibility criteria. The analysis consisted of identifying the year of the study and the tasks used to stimulate the comprehension process, and summarizing the methods used in the study and the findings. The summaries were then used to create categories that reflected the most prevalent methods and findings of the research included in our review. Categorizing the methods and findings assisted us in answering the research questions presented earlier by allowing us to make observations about how the research on mental representations of programs has changed over time and the resulting contributions.

3.1. Information sources
Five databases were included in the search process: Computer Source Index, ERIC, IEEE Xplore Digital Library, PsycINFO, and Scopus. Records in the Computer Source Index (formerly Computer Science Index) database are related to the current trends and advances in computer science. The ERIC database records are primarily related to the field of education, with publication dates from 1966 to present. The IEEE Xplore Digital Library database contains scientific and technical content published by the Institute of Electrical and Electronics Engineers (IEEE) and its publishing partners, from the fields of electrical engineering, computer science, and electronics. The publication dates range from 1872 to present. The records in the PsycINFO database refer to literature from the behavioural sciences and mental health fields of study, with publication dates ranging from 1887 to present. The Scopus database contains records from the sciences, health sciences, and social sciences, with publication dates ranging from 1966 to present.

The keyword, title, and abstract information were used to perform the database searches. The search string was developed using the main components of the search: mental representations, program comprehension, and programmers. Synonyms of these components were then identified from general knowledge acquired through of an initial investigation into this topic. All combinations of the synonyms were searched according to the requirements of the specific database. The combined words could be at most separated by two words and the wildcard symbol (*) was used to include alternative spellings of words. The following search string was used for database keyword searches of Computer Source, ERIC, and PsycINFO:

Program Comprehension: (((code OR program* OR software) N2 (understanding OR comprehen* OR stud* OR analy* OR maint* OR modif* OR recall* OR sort* OR categor* OR debug* OR classif* OR *copy*)) AND

Mental Representations: (((cognit* OR mental* OR knowledge OR program* OR situation*) N2 (model* OR represent* OR plan* OR structur* OR map* OR chunk* OR slic*)) OR schema*)) AND

Programmers: (programmer* OR coder*)

The search string for the IEEE Xplore Digital Library had to be modified slightly since it was the only database that imposed a limit on the number of wildcard symbols and keywords. Because of the multidisciplinary nature of the Scopus database, its search was limited by subject area to psychology, computer science, and engineering. The date of the last search of all databases was November 8, 2018. There were no restrictions put on the publication dates or publication types (e.g., theses, journal articles, conference papers, books) when performing the database searches.

Landman et al. (2017) found that when using the IEEE Xplore database the number of results were reduced when adding an OR to their search queries. Given their concern regarding inconsistencies, multiple search queries were tested using the IEEE Xplore database. When additional OR statements were added to the search query used in the current review, the number of results increased as expected.

To mitigate systematic bias in reviews that can be caused by publication bias, Kitchenham and Charters (2007) suggest contacting experts and researchers working in the area that may know of unpublished work. A request for unpublished work of relevance was sent to the Psychology of Programming Interest Group (PPIG) discussion group. The PPIG workshop is the primary venue for research in the psychological aspects of programming and its discussion group is subscribed to by leading researchers in the domain. As a result of this request, we received four unpublished papers.

Internet search engines were not used as an information source for our review due to their unsystematic nature and lack of quality control. Google and Google Scholar both use personalization filters that affect the results that are returned by searches (Pariser, 2011). The use of filters by search engines creates unpredictable and inconsistent searches. The lack of standardization could create bias since searches are filtered based on what the search engine determines the user wants resulting in an incomplete retrieval of data. Internet search engines cannot exclude results that are from predatory publishers.

3.2. Search strategy
The search results for each of the databases were as follows: Computer Source returned 65 records, ERIC returned 50 records, IEEE Xplore Digital Library returned 280 records, PsycINFO returned 92 records, and Scopus returned 879 records. In total, 1,366 data items were retrieved through database searches. There were 280 duplicate data items removed, leaving 1,158 unique data items as indicated in Fig. 1.

Fig. 1
Download : Download high-res image (196KB)
Download : Download full-size image
Fig. 1. PRISMA flow diagram.

3.3. Eligibility criteria
A preliminary screening was performed on the 1,158 unique data items that were extracted from the five database searches. The data items were screened by reading their titles and abstracts. In cases where it was not evident if the criteria were met from the abstract, then the full text was accessed and reviewed. The flow diagram outlining the results of each screening stage is found in Fig. 1.

The screening process and selection of the data items to include in our review were performed by the first author. The guidelines provided by Kitchenham and Charters (2007) suggest that a single researcher discuss included and excluded papers with other experts. Following these guidelines, the first author met regularly to discuss the selection of data items with the second and third author who are experts in computer science and psychology respectively. In addition to this, the inter-rater reliability was measured post-hoc by selecting a sample of included and excluded data items that were re-evaluated by the second author. The initial post-hoc inter-rater reliability of the two authors was 49 agreements out of 52 randomly selected papers (92.5%) for the exclusion/inclusion decisions. Refinement of the inclusion criteria allowed an agreement on two of the papers whereas further discussion of the specific papers produced agreement on the remaining papers.

For data items to be included in the review the following inclusion criteria were used:

1.
Had to be an empirical study.

2.
Study had to have participants that were programmers, meaning that they had prior knowledge of the programming language used in the study.

3.
Study had to use coded programs or code fragments that were written in a formal programming language.

4.
Study had to contribute to the understanding of the mental representations created during the comprehension process.

5.
Study had to contribute to the understanding of the process of building mental representations.

The following exclusion criteria were used to exclude data items from the review:

1.
Programming aptitude studies.

2.
Usability studies.

3.
Studies that involved the teaching and learning of a programming language (e.g., teaching methods, educational software).

4.
Studies on the problem solving process of programming.

5.
Studies on analytic and predictive techniques for programmer performance.

6.
Studies on program design and implementation.

7.
Studies on debugging strategies and skills.

After a preliminary screening using the inclusion and exclusion criteria the data items were reduced from 1,158 to 139 (see Fig. 1). In cases where an author republished their study using the same data and analysis, only the most recent publication was kept. Although studies on debugging strategies and skills were excluded, studies that used debugging as a task to stimulate the comprehension process to study programmers’ mental representations were included. For example, the study conducted by Stone et al. (1990) was eliminated because they investigated the debugging skills of programmers and how these skills can be improved. The study by Petre and Blackwell (1999) was excluded because they investigated the visual imagery produced by programmers during the software design phase. Their study did not include the writing or understanding of code. The study by Kamma and Jalote (2013) was eliminated as it examined programmer productivity. Another data item eliminated from the review was a study conducted by Yeh (2014) that did not involve programming or code and investigated the cognitive processes used by participants when solving a software design problem. The criteria for inclusion at this stage required that studies had contributed to the understanding of program comprehension and mental representations.

The documents that were not eliminated during the preliminary screening were then analyzed by reading the full text to determine if they met the eligibility criteria. As a result, 50 documents were included. In the guidelines provided by Kitchenham and Charters (2007) a search of databases alone is not sufficient for a complete systematic review. One of the manual search strategies suggested by Kitchenham and Charters (2007) is to search the reference lists from relevant studies, this is also known as backward snowballing (Wohlin, 2014). The 50 included studies from the automated search were used to perform one iteration of backward snowballing. The data items identified through backward snowballing were also subject to the same eligibility criteria as the data items from the automated search and as a result 20 additional data items were included as indicated in Fig. 1. The four unpublished data items received from the PPIG discussion group were also subject to the same eligibility criteria and resulted in the inclusion of one data item (see Fig. 1).

As a result of the screening process, the data items included in our review are empirical studies of programmers that investigated their comprehension and internal representation of code written in a formal programming language. The eligibility criteria used here are meant to extract studies with a focus on knowledge representation as opposed to knowledge utilization (Atwood and Ramsey, 1978).

3.4. Data extraction
The data extraction process was performed by the first author in consultation with the second and third author. The tasks used to stimulate the comprehension process were extracted from the data items by analyzing the description of the study’s methods and procedures. Tasks that were assigned to participants during the study to engage them with the code were included in the Task column of Table A.2. The methods and procedures of each study were analyzed to determine how the mental representations held by participants were measured and a summary was written by the first author describing each study’s method. Categories describing the methods were formed using the method summaries. After categorizing the methods of all the data items, the most common categories were included in Table A.2. A similar process was used to determine the contributions of each data item. The results of each study were analyzed to determine the main findings of the study and a summary of the findings was written for each study by the first author. Categories describing the types of mental representations formed by the participants of the studies were extracted from the summaries of findings and the most common categories were included in Table A.2.

4. Results
The data extracted from the 71 documents identified by the systematic review are provided in Table A.2. The items in the table are listed in chronological order to allow the reader to follow the development of the literature.

4.1. Research timeline
Empirical studies used to develop and validate theories on program comprehension first started to emerge in the 1970’s (Fig. 2), with the earliest study found by the systematic review conducted in 1976. The timeline depicted in Fig. 2 shows the growth and subsequent decline in the number of empirical studies that have been conducted on program comprehension. During the 1970’s and 1980’s, 20 studies were conducted. The number of studies grew to 39 in the 1990’s when it peaked. In more recent years the work in this area has dropped off almost completely with only 12 studies conducted since 2000 (Fig. 2). Throughout this timeline, various tasks have been used to stimulate the comprehension process that results in the formation of mental representations.

Fig. 2
Download : Download high-res image (139KB)
Download : Download full-size image
Fig. 2. Frequency of empirical studies on program comprehension.

4.2. Tasks
When examining the Task column in Table A.2, it appears that, in 23 of the studies, more than one task type was assigned to the participants. All studies that assigned more than one task type to participants included studying code as one of the task types. There were 52 instances where studying code was one of the task types assigned to programmers and in 29 of these instances studying code was the only task type assigned. The task of studying code was often given to participants without revealing the purpose and was most commonly followed by comprehension or recall questions. Studying code was used considerably more than any other task type (see Table 1).


Table 1. Frequency of tasks used for stimulating the comprehension process.

Task	Number of studies
Study	52
Modification	12
Maintenance	10
Debug	7
Reuse	4
Classify	3
Documentation	3
Write or Reconstruct Code	3
Hand Execution	2
Enhancement	1
Recopy	1
The modification tasks described in the studies included in our review tended to be specific changes in functionality that did not have a far reaching impact on other parts of the code. The modification task used by Navarro-Prieto and Cañas (2001) required programmers to modify a calculation used in the code. Boehm-Davis et al. (1987) required programmers to perform modifications to one or more specific locations in the code.

The maintenance tasks used in the studies included in our review required programmers to have an overall understanding of the code and often used industrial code (von Mayrhauser, Vans, 1994, von Mayrhauser, Vans, 1995, von Mayrhauser, Vans, 1996, von Mayrhauser, Vans, 1998). Studies that involved maintenance tasks often observed programmers in the workplace that were familiarizing themselves with code for the purpose of future maintenance or to perform a specific maintenance task (von Mayrhauser, Vans, 1994, von Mayrhauser, Vans, 1995, von Mayrhauser, Vans, 1996). There were also variations in the type of maintenance tasks and if the participants all performed the same maintenance task. In the study conducted by von Mayrhauser and Vans (1995) all participants performed a maintenance task but not necessarily the same type and Parkin (2004) compared the results of two different types of maintenance tasks. Other studies had programmers all performing the same maintenance task, including the study by Vans et al. (1999) where professional programmers were all performing corrective maintenance tasks and the study by von Mayrhauser and Vans (1998) where all participants performed adaptation tasks. Studies using maintenance tasks were the only studies that involved programmers with varying levels of prior familiarity with the code used in the study (von Mayrhauser, Vans, 1995, von Mayrhauser, Vans, 1998, Vans, von Maryhauser, Somlo, 1999).

In some cases, the tasks assigned to participants were specific to the programming paradigm of the language used in the study. For example, a reuse task was used to study the mental representations formed by object oriented programmers. Programmers were given code that could be reused in their assigned task either by copying the code to use as a template or by using object oriented design principles of reuse such as inheritance (Burkhardt, Détienne, 1995, Burkhardt, Détienne, Wiedenbeck, 1997, Burkhardt, Détienne, Wiedenbeck, 1998, Burkhardt, Détienne, Wiedenbeck, 2002). The reuse task specifically targets the use of object oriented design principles.

We found that the studies included in our review assigned tasks that varied in their level of realism. Of the most common tasks used to stimulate the comprehension process (see Fig. 3), studying was the only unrealistic task. Despite the observation made by Wiedenbeck et al. (1993) that experts found studying to be an unnatural task, it continued to be the most widely used task (see Fig. 3). Tasks that were considered to be more natural by experts were tasks that had a concrete objective such as debugging or determining the effects of modifications (Wiedenbeck et al., 1993).

Fig. 3
Download : Download high-res image (194KB)
Download : Download full-size image
Fig. 3. Frequency of most common tasks for stimulating the comprehension process.

There are have been more studies conducted using maintenance tasks than debugging or modification (see Table A.2). However, debugging and modification have been used throughout the timeline and have continued to be used in more recent studies as seen in Fig. 3. Maintenance was more commonly used than debugging and modification for a period of time between 1995-2005 but has not been used since (see Fig. 3).

4.3. Research methods
To determine how the methods used in the studies included in our review have changed over time, the method of each study has been categorized in Table A.2 for analysis. Through inspection of the Method column in Table A.2, it is apparent that a variety of techniques and measures have been used, both independently and in various combinations, to determine the mental representations formed by participants during the comprehension process. The most common technique was the use of comprehension questions (25 studies). Comprehension questions were also frequently used in addition to other measures to determine the mental representations formed by participants. Each study developed its own set of comprehension questions to measure the strength of different mental representations that may have been formed by the participants. Although some studies tested for the same types of representations (program and domain models studied by Pennington (1987b), Corritore, Wiedenbeck, 1991, Corritore, Wiedenbeck, 1999, Burkhardt et al. (1997), Burkhardt et al. (2002), Wiedenbeck and Ramalingam (1999), Wiedenbeck et al. (1999), Mosemann and Wiedenbeck (2001)) or knowledge structures (i.e., data flow, control flow, state, and function studied by Pennington (1987b), Teasley (1994), Shaft and Vessey (1995), Snyder (1995), Ramalingam and Wiedenbeck (1997), Khazaei and Jackson (2002)) the questions used varied between these studies. The use of verbal protocol analysis while participants performed a task and recall of code were also common techniques for measuring program comprehension (22 and 19 studies respectively). Recognition of code was used in nine studies, summarizing or describing the function of the code was used in five studies, and fill in the blank and sorting were each used three times, whereas all other techniques were each used only once. The recall of code required participants to reproduce the program used in the study either verbatim or a functionally equivalent version. The recognition of code required participants to determine if a given code fragment was from the program used in the study.

Comprehension questions form the method that has been used most consistently throughout the timeline of our review, whereas other techniques have been introduced and in some cases, discontinued at different points along the timeline (Fig. 2). The use of methods depicted in Fig. 2 shows that recall was used more frequently in earlier studies but dropped off around the time that verbal protocol analysis was introduced. The use of verbal protocol analysis first appeared in a study by Letovsky (1987) and was popular until it was last used by Vans et al. (1999) and did not reappear until a study by Nosál and Porubän (2015) (Fig. 4). Some of the more recent studies have introduced novel techniques for analyzing mental representations formed by programmers such as software that performed screen capture of their actions and monitoring of documents they accessed (Corritore and Wiedenbeck, 2001) and analysis of eye movement data (Fan, 2010).

Fig. 4
Download : Download high-res image (213KB)
Download : Download full-size image
Fig. 4. Frequency of most common methods used for determining the mental representations formed during the comprehension process.

The data collected in our review and found in the Method column of the extended online appendix1 indicate that the types of programmers compared in the studies have changed over time. From the first study in 1976 until 1990, the only types of programmers that were compared in the studies were programmers of varying levels of expertise (Shneiderman, 1976, Adelson, 1981, McKeithen, Reitman, Rueter, Hirtle, 1981, Ehrlich, Soloway, 1984, Soloway, Ehrlich, 1984, Adelson, 1984, Barfield, 1986, Schmidt, 1986, Bateson, Alexander, Murphy, 1987, Boehm-Davis, Holt, Schultz, 1987, Vessey, 1987, Vihmalo, Vihmalo, 1988, Davies, 1990b, Guerin, Matthews, 1990). Programmers were categorized as expert, intermediate, or novice to indicate their expertise in the programming language used in the study or their expertise in the domain relevant to the program. These studies used different definitions and measures to categorize participants’ level of expertise. The first occurrence in the data of comparing mental representations formed by programmers trained in different programming paradigms or languages was in 1990. Since that time, comparing programmers with different backgrounds has become a more common type of comparison having been used in studies conducted by Robertson and Yu (1990), Green and Navarro (1995), Corritore and Wiedenbeck (1999), Wiedenbeck and Ramalingam (1999), Wiedenbeck et al. (1999), Corritore and Wiedenbeck (2001), Navarro-Prieto and Cañas (2001), and Khazaei and Jackson (2002). The most common comparison of programming paradigms was between procedural programming and object oriented programming.

4.4. Research contributions
To analyze the contributions that have resulted from the research included in our review, the findings of each study have been categorized in Table A.2. Examination of the Findings column in Table A.2 reveals considerable variation in the description of the representations formed by programmers and the strategies used during the program comprehension process. The studies conducted by Shneiderman (1976), McKeithen et al. (1981), Ehrlich and Soloway (1984), Mynatt (1984), Barfield, 1986, Barfield, 1997, Guerin and Matthews (1990), Furman (1998), and Fan (2010) found that programmers used chunking to develop a mental representation of the code. Chunking involves the grouping of lines of code together during the comprehension process. The strategy used by programmers when chunking differed between studies. Guerin and Matthews found that programmers chunked by identifying functions in the code; Barfield concluded that programmers grouped sequential lines of code that fit logically together; Furman found that programmers used the visual structure of the code to form chunks; and Fan determined that programmers used beacons to recognize code chunks.

Another group of studies included in our review found that programmers formed mental representations at varying levels of abstraction. Studies performed by Pennington (1987b), Bergantz and Hassell (1991), Burkhardt et al. (1997), Burkhardt et al. (2002), Ramalingam and Wiedenbeck (1997), Corritore and Wiedenbeck (1999), Wiedenbeck and Ramalingam (1999), Wiedenbeck et al. (1999), Mosemann and Wiedenbeck (2001), and Parkin (2004) support the two model theory that programmers form low level program models and high level situation or domain models during the comprehension process. Studies conducted by von Mayrhauser, Vans, 1994, von Mayrhauser, Vans, 1995, von Mayrhauser, Vans, 1996, von Mayrhauser, Vans, 1998, Vans (1996), von Mayrhauser et al. (1997), and Vans et al. (1999) found that programmers formed mental models at three levels of abstraction and switched between them during the comprehension process, with the program model as the lowest level, the situation model as the intermediate level, and the domain model as the highest level of abstraction.

The knowledge structures and representations that compose the models at different levels of abstraction were also investigated by a number of studies. Pennington (1987b) found that mental models were developed by programmers using a bottom-up approach (concrete to abstract) since control flow representations were used initially in the comprehension process to form program models whereas data flow and functional representations were used later to form situation models. Shaft and Vessey (1995) determined that the direction in which the representations were developed depended on the expertise of the programmer in the application domain; in an unfamiliar domain programmers developed representations in a bottom-up direction (data flow, control flow, state, and function), but in familiar domains programmers developed representations in the opposite direction (top-down). Contrary to Pennington’s findings, Bergantz and Hassell (1991) concluded that control flow representations did not influence the comprehension process and that the representations used by programmers differed depending on their level of expertise: less experienced programmers developed more data flow relationships whereas more experienced programmers developed more function relationships in their mental representations. Teasley (1994) concluded that different types of knowledge structures are all acquired at a similar rate and there was no strong evidence to indicate that programmers use a bottom-up approach. Navarro-Prieto and Cañas (2001) compared programmers with backgrounds in different programming paradigms and found that procedural programmers had better developed control flow representations than data flow representations whereas visual programmers developed both representations equally well. Khazaei and Jackson (2002) compared the representations formed by programmers who had experience in both event driven and object oriented paradigms when understanding programs written in the different paradigms and found that programmers formed stronger control flow, data flow, and functional models when understanding event driven programs compared to object oriented programs. Snyder (1995) determined that the representations formed by programmers were dependent on the task they were assigned, and that modification tasks required the programmer to develop relationships between four representations: data flow, control flow, state, and function.

Contributions made by research on mental representations formed by programmers during program comprehension have been important in the development of tools and languages that are more intuitive and align with programmers’ internal representations. The lack of research on mental representations of parallel programmers reinforces the need to return to this research approach to develop tools and languages for parallel programmers instead of relying on usability and comparative studies. Research that analyses the usability of tools and languages and comparative studies is not informed by theories of program comprehension or mental representations of programmers and is unable to provide insight into how programmers internalize and represent code.

5. Discussion
The purpose of our study was to determine the extent of empirical research that examined mental representations formed during program comprehension to date, how the tasks and methods used in the research have changed over time, and the contributions that have resulted from the research.

5.1. Decline in research
To determine the extent of empirical research that has examined mental representations formed during program comprehension to date, a systematic review was performed and summarized in Table A.2. The timeline (Fig. 2) that resulted from the systematic review indicates that recently there has been a dramatic decline in research on program comprehension. The declining number of studies focusing on program comprehension and mental representations of programmers in recent years is possibly due to a change in focus. For example, there were a number of studies conducted in recent years that focused on strategies and tools for teaching programming (Oliveira Aureliano, 2013, Dillon, 2013, Lane, 2005), learning second or subsequent programming languages (Scholtz and Wiedenbeck, 1990), and designing programs (Yeh, 2014, Basili, Reiter, 1981) that did not meet the criteria for our review. For example, Whalley and Kasto (2014) conducted a study that examined the progression of learning and the development of cognitive structures during the learning process. Another study that was eliminated measured the amount of programmer effort required to write programs using different parallel programming models (Hochstein et al., 2008). Cañas and Antolí (1998) stated that research of mental representations was blocked due to lack of agreement in definition and methodology. The results of the current study found in Table A.2 support this conjecture by demonstrating the lack of agreement on the tasks used to elicit the mental representations and the methodology utilized to measure them. Other reasons for the observed decline may include a movement towards usability and comparative studies where there may be more funding particularly from companies wanting to demonstrate the usability of their programming languages and tools. Usability and comparative studies tend to have more concrete measures such as lines of code, runtime, and memory usage that allow a quantitative analysis of the program features providing more conclusive results.

5.2. Discussion of research questions
By examining the Task and Method columns in Table A.2, we were able to determine how the studies included in our review have changed over time. For a period of time, empirical studies on program comprehension and mental representations were performed on varying levels of programmers using a variety of programming languages. The tasks and methods used to assess and analyze program comprehension and mental representations of the participants were not consistent between studies. While Vessey (1987) criticized the use of debugging as a task to stimulate program comprehension, it has been used in studies throughout the timeline of our review by Weiser, 1981, Weiser, 1982, Adelson (1984), Gilmore and Green (1988), Davies (1990a), Romero and Du Boulay (2004), and Fan (2010). The research performed by Wiedenbeck et al. (1993) compared expert and novice programmers who were given the task of studying code for understanding and found that studying code was an unnatural task for the experts who commented that normally they would have a concrete objective, such as debugging or predicting the effects of modifications, in mind when reading code. Wiedenbeck speculated that depending on the task, different information may be extracted during program comprehension. Wiedenbeck’s observation underlines the importance of ensuring the task is appropriate for the participants in the study. In some cases researchers also expressed concerns over the validity of methods used to measure comprehension including comprehension questions (Shaft and Vessey, 1995) and recall (Guerin and Matthews, 1990) that are used in a number of other studies. The focus of the research has also shifted over time. Comparing expert and novice programmers was the focus early on in the research, although no common definition or measure of expertise was used in these studies. The focus has now shifted to comparing programmers with backgrounds in different programming paradigms and languages.

The contributions that resulted from the empirical research on program comprehension have been summarized in the Findings column of Table A.2. Although there are some researchers who build on their own work in an incremental fashion (Vessey, 1987) or use aspects of other studies as a model (Guerin and Matthews, 1990), this building process is limited and often deviates from the previous work in such a way that it is hard to connect the findings. Even studies that attempt to support the findings of other studies end up with inconclusive (Corritore and Wiedenbeck, 1999) or even contradictory results (Wiedenbeck and Ramalingam, 1999).

5.3. General observations
Another finding that emerged from the systematic review was that despite the widespread use of expert and novice as categories to describe programmers, no common definition or measure of expertise has been developed or adopted. Even studies that did not compare expert and novice programmers often used these categories to identify the group of programmers that were used as participants. There was also no consistency between the use of expert and experienced when describing programmers and these terms were often used interchangeably in the same study (Barfield, 1986, Vessey, 1987, Fix, Wiedenbeck, Scholtz, 1993).

6. Threats to validity
One threat to validity is the possibility that data items may be missing from our review. Every effort was made to find all relevant data items by selecting databases from both psychology and computer science domains and the multidisciplinary database Scopus. The database selection and development of the search strings was done in consultation with an Information Services Librarian who has experience developing search strings for systematic literature reviews to mitigate the threat of incomplete search terms. There was no restriction on the publication dates which also reduced the threat of missing data items. Backward snowballing was used to find additional data items that may have been missed by the automated search. To reduce the threat of publication bias as suggested by Kitchenham and Charters (2007), a request was sent to the PPIG discussion group for unpublished work. Although unpublished work might be considered as potentially posing a threat to validity as a result of its perceived poorer quality, the PPIG discussion group is subscribed to by experts in the psychology of programming field, many of whom are authors of published work included in our review.

The first author developed the research questions in consultation with the second and third author in order to mitigate the threat of inappropriate research questions. Preliminary research was also conducted by the first author to gain an understanding of what research questions may be able to provide insight for future empirical studies on mental representations. Another possible threat to validity is the appropriateness of the inclusion and exclusion criteria and the reliability of inclusion decisions. The first author developed the eligibility criteria in consultation with the second and third author, who are experts in high performance computing and cognitive psychology, respectively. To ensure consistency and reduce bias in the inclusion decisions, the first author met regularly with the second and third author to discuss the selection of data items. The results of the post-hoc inter-rater reliability between the first and second author indicates they were in agreement on 92.5% of the data items. This high inter-rater reliability demonstrates consistency and unbiased inclusion decisions during the screening process.

The data extraction process was performed by the first author, introducing a threat to validity as a result of subjective interpretation of the data. To mitigate this threat, the first author discussed the data extraction process with the second and third author and developed the categories for the methods and findings in consultation with them. The first author also held regular meetings with the two co-authors to discuss ambiguous data items as a way to ensure a valid coding of study properties.

7. Future Work
The decline in research on mental representations is not an indication that this topic lacks relevance or importance, but an indication of a shift in focus. Research topics that have gained more interest include usability and comparative studies which allow tools and languages to be compared and ranked as more or less superior without the risk of finding that the tool or language does not coincide with the mental representation of the user. Ericsson et al. (2006) found that there has also been more focus on organizational settings where programmers work in teams (Gren, Torkar, Feldt, 2017, Teh, Baniassad, Rooy, Boughton, 2012, Dingsøyr, Dybå, 2012). The study of programming teams would be attractive to software companies as they may anticipate a more immediate return on their investment into this area of research. However, the use of mental model theory to design programming tools and languages has demonstrated measurable benefits. For example, Sulír and Nosál’ (2015) studied mental model overlapping to develop source code annotations that allow programmers to share their mental models. From their study they found that the annotations improved program comprehension and reduced maintenance time. The program slicing tool developed by Korel and Rilling (1998) that assists with program comprehension was developed based on research that demonstrated the use of program slicing to improve the process of program understanding. In our view, the current trend in which the usability of languages is assessed after they have already been in use is counterproductive as it ignores cognitive processes involved in programming. Accordingly, we argue that there needs to be a resurgence of empirical research on the psychology of programming to inform the design of tools and languages, especially in new and emerging programming paradigms.

The study of expert mental representations is important for informing the development of programming languages, instructional practices, and tools. To perform research on expert programmers it is necessary to be able to determine if participants are in fact experts. There has been a lack of agreement among researchers on how expertise should be measured. Siegmund et al. (2013) found that programmer experience can be determined by measuring their self estimation of their experience level compared to their peers and their experience level with logical programming. The study conducted by Baltes and Diehl (2018) found that self-assessment of expertise by programmers was not consistent between programmers with different programming language backgrounds and that years of experience was not related to expertise. The position taken by Parnin et al. (2017) is that expertise cannot be measured using superficial measures such as years of experience but instead using multiple measures such as observing the brain activity of programmers during program comprehension and assessing programming knowledge using concept inventories. To date there remains no standard for measuring programmer expertise so there is a need for more research to develop a standard measure for categorizing programmers based on their expertise. The distinction between expert and experienced also needs to be established. Experience is a measure of time spent working in a particular field or performing a task, however, it does not necessarily translate into expertise, which is a measure of performance (Ericsson et al., 2006). One recommendation for future work is to develop a tool for assessing programmer expertise that is not solely reliant on experience as a gauge.

Empirical research on mental representations formed by programmers during program comprehension has been predominately conducted using sequential code. Studies involving parallel programmers are most often concerned with productivity (Hochstein, Carver, Shull, Asgari, Basili, Hollingsworth, Zelkowitz, 2005, Ebcioglu, Sarkar, El-Ghazawi, Urbanic, Center, 2006). However, the mental representations formed by expert parallel programmers during the comprehension of parallel programs is an important area of study to determine how their representations differ from the representations developed during sequential source code comprehension. The comprehension of parallel code requires programmers to mentally execute multiple timelines that are occurring in parallel at the machine level. Therefore, parallel program comprehension may require additional dimensions to construct a mental representation. To explore this research question, program comprehension studies need to be conducted using parallel programmers as participants and assign tasks that stimulate the comprehension process at a level that requires programmers to understand how the code executes in parallel. Possible tasks include identifying the presence of race conditions, rating efficiency or increasing efficiency of parallel programs.

Our literature review suggests that there is no consensus on the method that provides the most accurate account of the mental representations formed by programmers during the comprehension process. In addition, the different methods that have been used only provide an indirect analysis of these mental representations. Our review contains only one study, conducted by Fan (2010), that used eye tracking. Fan used eye tracking data to determine how the program comprehension process is affected by beacons, comments, and task motivation. This author concluded that eye tracking data can be used for tracing and analyzing the program comprehension process.

Work in psychology of programming has been moving towards the use of electroencephalography (EEG) to investigate models of cognition in recent years. For example, Crk et al. (2016) used EEG to determine programmer expertise. However, models of cognition are not the same as the mental representations that are of interest in our review. In future work it is recommended that eye tracking be used in conjunction with direct questioning to formulate a model of the mental representations formed by programmers during program comprehension.

8. Conclusion
Our review contains empirical studies that have been used to build a timeline to provide insight as to how the research on program comprehension and mental representations has evolved. The collection of knowledge contained in our review would be of interest to researchers who want to build on the work done by others in this field and those who want to expand this work to include new programming languages and paradigms. Our review demonstrates that the field of program comprehension is lacking incremental research that builds on previous work, and as a result, the research in this area has been scattered.

The results of our literature review indicate a lack of consistency and agreement in the tasks and methods used for studying mental representations formed during program comprehension. The classifications of programmers based on expertise also varies greatly between studies. There are no common definitions for these classifications and the terms expert and experienced are used interchangeably without considering the difference between these classifications.

Our review also points to gaps in the research on program comprehension. In recent years, the work in this field has declined dramatically and as a result, newly developed or popularized languages and paradigms have not been a part of the research reviewed here. In particular, parallel programming has been neglected in program comprehension research and consequently has developed using mostly informal approaches (Mattson and Wrinn, 2008). Because of the considerable differences between parallel programming and the programming examined in the studies in our review, it is impossible to determine whether the findings summarized in Table A.2 would resemble the comprehension process and mental representations formed by parallel programmers. Therefore, future work should focus on empirical research designed to analyze the mental representations formed by expert parallel programmers during program comprehension to inform the development of tools and languages that support parallel programmers.