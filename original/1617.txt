Abstract
The recognition of the need for high-quality software architecture is evident from the increasing trend in investigating architectural smells. Detection of architectural smells is paramount because they can seep through to design and implementation stages if left unidentified. Many architectural smells detection techniques and tools are proposed in the literature. The diversity in the detection techniques and tools suggests the need for their collective analysis to identify interesting aspects for practice and open research areas. To fulfill this, in this paper, we unify the knowledge about the detection of architectural smells through a systematic mapping study. We report on the existing detection techniques and tools for architectural smells to identify their limitations. We find there has been limited investigation of some architectural smells (e.g., micro-service smells); many architectural smells are not detected by tools yet; and there are limited empirical validations of techniques and tools. Based on our findings, we suggest several open research problems, including the need to (1) investigate undetected architectural smells (e.g., Java package smells), (2) improve the coverage of architectural smell detection across architecture styles (e.g., service-oriented and cloud), and (3) perform empirical validations of techniques and tools in industry across different languages and project domains.

Previous
Next 
Keywords
Architectural smells

Architectural debt

Antipatterns

Smell detection techniques

Systematic mapping study

1. Introduction
Software architecture forms the foundation and defines the structural and semantic composition of a software system (Bass et al., 2003). A software system’s architecture directly influences the software artifacts created in the subsequent development stages (e.g., design and implementation) (Losavio et al., 2003). Therefore, it is paramount that the quality of software architecture is not compromised. Still, it is common for the software architecture quality to be degraded because of the adoption of certain design decisions. For instance, a decision to create a centralized component that handles the majority of the responsibilities can lead to modularization problems in the architecture (Suryanarayana et al., 2015). Such inappropriate decisions introduce “bad smells” in the architecture, negatively impacting the architecture quality, mainly maintainability (Sabir et al., 2019, Bertran, 2011). The term “smell” refers to a structural problem in a software artifact. For instance, “code smells” refer to structural problems in source code (Fowler, 2018). In the literature, the term “smell” is interchangeably used with other terms, such as antipattern, flaw, anomaly, etc. (Mo et al., 2015, Mo et al., 2019, Vanciu and Abi-Antoun, 2013, Shin et al., 2006). In the rest of this paper, we use the term “smells” to refer the structural design problems in software architecture. However, while describing the techniques and tools, for consistency reason, we use the same terms (e.g., antipattern, flaw, etc.) as mentioned in the papers.

Based on the scope and impact of bad smells, they are often classified into three levels of granularity in the order: architecture (high-level), design, and implementation (low-level) (Sharma et al., 2020). Smells at the implementation level refer to the structural problems in the low-level constructs (functions or methods), such as Long Method, Long Parameter List, etc. (Fowler, 2018). At the design-level, structural problems in the classes, such as Missing Abstraction and Insufficient Modularization, are observed (Suryanarayana et al., 2015). In contrast to implementation and design smells, the architecture level smells indicate the structural problems in the components (which could be groups of classes) and their interactions with other components. Examples of architectural smells are God Component and Dense Structure (Azadi et al., 2019). The scope of this paper is limited to the analysis of architectural smells detection techniques and tools.

The timely detection and eradication of architectural smells are essential because, otherwise, the cost of fixing the repercussions later in the software development life cycle is exceptionally high, especially in large scale industrial projects (Reimanis et al., 2014). Over the past decade, several techniques and tools have been developed to detect architectural smells. These techniques and tools focus on various architecture styles (e.g., service, layered, etc.), architectural smells (e.g., dependency, performance, etc.), and types of software (e.g., web, middleware, etc.). As a specific example, Ouni et al. (2015b) identified service-oriented smells that impact the maintainability of web systems. Likewise, De Sanctis et al. (2017) detected performance smells in software architecture. The techniques and tools are validated, mostly, in two ways (through empirical studies and case studies) using a variety of data (from open source projects and commercial projects). For instance, Velasco-Elizondo et al. (2017) conducted an empirical validation of their detection technique for model-view-controller (MVC) architectural smells using open source web systems.

This demonstrates that the detection techniques and tools are diverse, and a systematic and comprehensive analysis of the available techniques and tools would help the research community learn about the interesting aspects and limitations. Currently, the information about architectural smells detection is spread across multiple literature databases, and to the best of our knowledge, there is no literary evidence of systematic gathering and discussion of such information.

To fill this gap, in this paper, we present a systematic mapping study on the detection of architectural smells. The objective is to unify the scattered knowledge about architectural smells detection techniques and tools into one literary source to analyze what has been accomplished in this area, highlight useful findings, and reflect on the limitations of what is available. As expected from a mapping study, we also report on publication trends of the architectural smells detection. To fulfill these objectives, we formulate the following research questions:

•
RQ1: What are the demographics of the published articles?

Goal — This RQ identifies when the articles are published; the venues where research related to architectural smells detection is published; and the origin type (academic or industry) of these articles.

•
RQ2: What detection techniques for architectural smells are proposed in literature?

Goal — This RQ identifies and analyzes the architectural smells detection techniques that have been proposed in the literature. We investigate what types of architectural smells can currently be detected; what architecture styles are handled by the techniques; and how the techniques are evaluated.

•
RQ3: What detection tools for architectural smells are proposed and evaluated in literature?

Goal — This RQ identifies and analyzes the detection tools that have been reported in the literature. The purpose of RQ3 is to highlight the architecture smell detection tools that are available to the software development community. Software tools make detection techniques more accessible to software practitioners, but not all detection techniques have supporting tools. Therefore, we also analyze detection tools separate to detection techniques. Similar to RQ2, we report on the architectural smells discussed in the tool papers. We also report on the validation, availability, and language support of the detection tools.

•
RQ4: What are the limitations of the reported detection techniques and tools?

Goal — This RQ identifies limitations reported in the proposed detection techniques and tools. The limitations are comprised of the ones found in the literature and identified through the collective analysis of the detection techniques and tools. Through this RQ, we identify undetected architectural smells, understudied architecture styles, and unexplored quality characteristics. This RQ also reflects on the limitations in the evaluation processes of the techniques and tools.

We present the systematic mapping process that defines our search strategy, inclusion criteria, and exclusion criteria using the guidelines of Petersen et al., 2008, Petersen et al., 2015. We developed a search string to retrieve the literature relevant to our research questions. We applied the search string to seven digital databases: Scopus, Web of Science, INSPEC, ACM Digital Library, IEEEXplore, SpringerLink, and DBLP. As a result, we retrieved 529 unique articles, which were reduced to 76 after applying the inclusion and exclusion criteria. We also performed snowballing on the selected articles using the guidelines of Wohlin (2014). After snowballing, the final list of articles (85) was selected for analysis. To analyze the gathered literature, we formalized an analysis framework comprising of several factors related to techniques, tools, and their validation. In addition, for an in-depth analysis, we matched the architectural smells that are detected by techniques and tools with a list of architectural smells presented or cataloged in the literature (de Andrade et al., 2014, Aniche et al., 2018, Taibi and Lenarduzzi, 2018, Král and Žemlicka, 2009, Smith and Williams, 2000, Garcia et al., 2009, Bogner et al., 2019, Lippert and Roock, 2006). This enabled us to identify known architectural smells that are not currently detected by any techniques or tools.

The main contribution of this paper is the systematic unification of the information about architectural smells detection (techniques and tools) that is scattered across various digital databases and libraries. We present a comprehensive analysis of architectural smells detection techniques and tools with a focus on highlighting the interesting findings, gaps, and limitations. We also discuss open research areas that need exploration and investigation.

2. Related work
Before describing our study, we provide an overview of related systematic reviews and mapping studies.

de Paulo Sobrinho et al. (2018) conducted a literature review to cover five W’s: which, when, what, who, and where on bad smells in different software artifacts (code, design, and architecture). They found that some kinds of smells are studied more frequently than others (which); that research in the area of bad smells is spread across time (when); that findings, claims, and experimental setups vary among different detection approaches (what); who the authors are that publish (continuously or sporadically) in the research area related to bad smells (who); and finally, which venues mostly publish the research about bad smells (where). They reported on the investigation of various bad smells in different software artifacts and at different granularity levels. Through their intensive analysis, they presented future directions for research in the area of bad smells. Compared to this study, they did not present details on architectural smells techniques and tools.

There are some literature reviews and mapping studies on architectural technical debt (ATD). Besker et al., 2016, Besker et al., 2018 performed a systematic literature review on ATD. Their focus was on the debt, interest, and principle related to the effort and cost required to deal with ATD. They also proposed a model to categorize the characteristics of ATD better. Alves et al. (2016) identified several indicators for detecting technical debt in software architecture through a systematic mapping study. Ampatzoglou et al. (2015) performed a systematic literature review to cover the financial aspects of technical debt management. Li et al. (2015a) published a mapping study on the management of technical debt. Verdecchia et al. (2018) applied a systematic mapping study to identify, classify, and evaluate studies that identify ATD. They focused on analyzing the publication trends, characteristics, and industry involvement in ATD identification. Tom et al. (2013) conducted a literature review to uncover the nature of technical debt and its implications on the software development process. Finally, the goal of Fernández-Sánchez et al. (2017) was to identify and analyze the key elements (related to the cost estimation and decision making) for managing technical debt. Generally, ATD is closely related to architectural smells, however, none of these studies investigated architecture smell detection specifically.

In a systematic literature review, Sabir et al. (2019) evaluated smell detection techniques and their evolution within the scope of object-oriented and service-oriented systems. They identified various commonalities and differences in the detection of bad smells in object-oriented and service-oriented systems. They reported several key findings, including some smells that receive less attention and a catalog of service-oriented smells that require more investigation. Vale et al. (2014) presented a systematic literature review on the existence of bad smells in the software product line (SPL). They concluded that research on SPL-specific smells is an open area to explore, considering many limitations and challenges discussed in the literature. They also provided a catalog of code smells, architectural smells, and hybrid smells. The systematic mapping study performed by Bandi et al. (2013) studied the empirical evaluations of techniques that investigate the effects of code decay on software quality. They also included design and architectural violations related to code decay and software quality. Although these reviews reported interesting findings and limitations about architectural smells detection, the scopes are limited to specific architectural styles or domains.

There are also some reviews on the detection of design-level smells—sub-optimal patterns in software design (Sharma and Spinellis, 2018). Mumtaz et al. (2019a) conducted a literature survey to identify gaps in the detection techniques for design smells. They analyzed the proposed techniques and experimental designs to locate limitations related to unexplored design smells and experimental evaluations. They found a scarcity of detection approaches for UML sequence diagrams and use cases. Similarly, Misbhauddin and Alshayeb (2015) provided a systematic review of existing research in UML model refactoring. Alkharabsheh et al. (2019) analyzed the detection approaches for design smells using several comparison factors. The comparison factors include smell type, detection techniques, detection tools, validation, artifact type, and language support. They also explored the relationship between the detected design smells and quality attributes. There is also a systematic review that compared bad smells detection tools in terms of bad smells coverage, language support, and usability issues (Fernandes et al., 2016). The scope of these reviews is limited to design smells. However, the comparison factors are relevant for our analysis.


Download : Download high-res image (101KB)
Download : Download full-size image
Fig. 1. Systematic Mapping Process.

Azadi et al. (2019) presented a review of architectural smells detection tools. They identified the architectural smells detected by various tools and presented a catalog of architectural smells. In their review, they also reported three quality principles (modularity, hierarchy, and health dependency structure) violated by the architectural smells. Furthermore, they discussed the differences between the detection strategies used by the tools to detect each smell. From a tool’s perspective, our work is different from Azadi et al. (2019) in that we mainly focus on highlighting the limitations by analyzing the detection tools. From our analysis, we identified many architectural smells (e.g., performance-related smells) that are not detected by currently available tools. We also provided details of the validations of the detection tools and presented the limitations related to the validation. In addition, we reflected on the language support provided by the tools and discussed some issues related to the language scalability. Furthermore, we discussed various ways the limitations in the detection tools could be addressed. In addition to detection tools, we also analyze other detection techniques (and their limitations) which do not have associated tools.

To summarize, from the architecture point of view, the systematic reviews related to software architecture either focus on financial aspects or their scope is limited to a specific domain. The literature reviews and mapping studies that focused on the financial aspects of technical debt had research questions aimed at measuring and managing the maintenance cost of the changes due to the existence of the technical debt. Some literature reviews had scope limited to a specific domain or paradigm, such as the reviews on the bad smells detection approaches for object-oriented and service-oriented systems. There is also a systematic literature review that reported on the studies investigating only those smells that belong to the software product line. To the best of our knowledge, there is no systematic review or mapping study that collectively covers both detection techniques and tools for architectural smells. We fill this gap with a systematic mapping study, where we analyze the detection techniques and tools with a broader scope of architectural smells detection. The systematic reviews and mapping studies at the design level used a variety of comparison factors (e.g., smell type, artifact type, domain, etc.) to evaluate the detection approaches. In our systematic mapping study, we also use similar analysis factors to compare the architectural smells detection techniques and tools.

3. Systematic mapping process
In this paper, we followed the systematic mapping guidelines provided by Petersen et al., 2008, Petersen et al., 2015. The first author executed the systematic mapping process, however, the results were iteratively discussed between the authors. Our mapping process contained three steps: planning, execution, and analysis. At the planning stage, we identified research questions and a mapping study protocol. The rationale of the mapping protocol was to formulate a method to execute the mapping process. In the execution phase, the searched literature was exposed to the inclusion and exclusion criteria to identify a set of articles for in-depth analysis. Lastly, at the results analysis stage, the selected literature was subjected to analysis to address the research questions. The systematic mapping process is also depicted as a flow chart in Fig. 1.


Table 1. Distribution of articles per electronic database.

Database	Search string	Retrieved articles
Scopus	“software architectur*” AND (“smell*” OR “antipattern*” OR “debt” OR “flaw*” OR “anomal*”)	115
Web of Science	“software architectur*” AND (“smell*” OR “antipattern*” OR “debt” OR “flaw*” OR “anomal*”)	78
INSPEC	“software architecture” AND (“smell*” OR “antipattern*” OR “debt” OR “flaw*” OR “anomal*”)	161
ACM Digital Library	“software architecture” AND (“smell*” OR “antipattern*” OR “debt” OR “flaw*” OR “anomal*”)	78
IEEEXplore	“software architectur*” AND (“smell*” OR “antipattern*” OR “debt” OR “flaw*” OR “anomal*”)	136
SpringerLink	“software architectur*” AND (“smell*” OR “antipattern*” OR “debt” OR “flaw*” OR “anomal*”)	244
DBLP	“software architectur*” (“smell*”  “antipattern*”  “debt”  “flaw*”  “anomal*”)	25
Total (includes duplication)		837
Total (unique articles)		529
Total (after inclusion and exclusion criteria)		76
Total (after snowballing)		85
3.1. Mapping protocol overview
We used the following mapping protocol that was discussed and finalized between the authors:

•
Search the databases and digital libraries from 1999 to 2019 inclusive using the search string (see Section 3.2)—retrieved 837 articles.

•
Remove duplicates (automatically and manually) to obtain unique articles (see Section 3.2)—resulted in 529 articles.

•
Apply inclusion and exclusion criteria (see Section 3.3)—resulted in 76 articles.

•
Apply snowballing to 76 articles (see Section 3.4)—identified 27 new articles.

•
Apply inclusion and exclusion criteria to 27 articles identified through snowballing (see Section 3.4)—removed 18 articles.

•
Extract data from the selected articles (85) that was needed to answer our research questions.

3.2. Search strategy
Searched databases — We searched the following databases and digital libraries because they are commonly used to extract computer science and software engineering publications: Scopus, Web of Science, INSPEC, ACM Digital Library, IEEEXplore, SpringerLink, and DBLP (Cavacini, 2015). We searched these databases and libraries to obtain information related to the detection of architectural smells in October 2019.

Search string — We formulated the following search string to locate the related work: “software architectur*” AND (“smell*” OR “antipattern*” OR “debt” OR “flaw*” OR “anomal*”). The included search terms were derived based on our research questions. First, the term “software architectur*” was included to get the literature confined to software architecture. Then, to narrow the software architecture literature to the papers discussing architectural smells, we included the term “smell*”. We also considered different terms that are used in the same context as smells in the literature. For instance, Sharma and Spinellis (Sharma and Spinellis, 2018) reported the use of the terms “smell” and “antipattern” interchangeably by software engineering researchers and practitioners. Similarly, other terms (“debt”, “flaw*”, and “anomal*”) were also used in the same context as smells (Sharma, 2019, Vanciu and Abi-Antoun, 2013). Therefore, we included these terms in our search string. Moreover, our search string used conjunction and disjunction operators to combine multiple search terms into a single search string. The specific search string used in each database is shown in Table 1.

Search string validation — To see the effectiveness of our search string, we performed a focused search analysis of the papers published in the International Conference on Software Engineering (ICSE) from 2016 to 2019. The reason for performing this exercise was to gain confidence in the search string. We chose ICSE because it is the flagship software engineering conference. We selected the four ICSE editions (2016–2019) because they are the most recent editions and represent a reasonably sized set of papers for manual validation. We manually looked at all the papers in these editions to shortlist the relevant ones (for comparison later). By reading through the abstracts and introductions of all papers from the proceedings of ICSE 2016–2019, we identified 15 papers of interest. By applying the search string within ICSE 2016–2019, we found 12 of the identified relevant papers (80%). The search string missed three papers (20%), two from ICSE ’19 and one from ICSE ’18. Subsequently, we executed a snowballing strategy on the 12 retrieved articles. As a result, we found the remaining papers that were previously missed by our search string. To conclude, 80% (12 out of 15) of the articles were found through our search string, and the remaining three papers were located through snowballing. Thus, we were confident that the search string combined with a snowballing strategy has good accuracy in finding the papers of interest.

Retrieved articles — We received 837 hits in total by applying the search string in the databases mentioned earlier. The number of retrieved articles respective to each electronic database is shown in Table 1. After removing the duplicated articles, the number of unique articles was reduced to 529. These 529 articles were exposed to our inclusion and exclusion criteria described in the next section.

3.3. Inclusion and exclusion criteria
We defined the inclusion and exclusion criteria to filter the set of articles—from the unique retrieved articles (529)—that were relevant to our research objectives and questions. The rationale of inclusion criteria was to consider articles that substantially discuss architectural smells detection. In contrast, the purpose of defining the exclusion criteria was to discard articles containing information that is insufficient for answering our research questions.

We used the following inclusion criteria:

•
Articles that discuss the detection of architectural smells.

•
Articles that describe techniques or tools aiming to detect architectural smells.

•
Articles that are written in English.

•
Articles that are published 1999 onwards because the term “bad smell” was introduced in this year.

•
We consider literature published in journals, conferences, books, and workshops.

The exclusion criterion was iteratively modified during the exclusion process. For instance, “briefings” was added to our exclusion criteria, when a briefing report was found during the snowballing process. The list of final exclusion criteria is:

•
Articles that discuss software architecture and architectural smells (not detection) in general.

•
Articles that define architectural smells or present only a catalog of architectural smells. Although such papers  (de Andrade et al., 2014, Aniche et al., 2018, Taibi and Lenarduzzi, 2018, Král and Žemlicka, 2009, Smith and Williams, 2000, Garcia et al., 2009, Bogner et al., 2019, Lippert and Roock, 2006) were excluded, we did use them to identify the architectural smells (including their aliases) that are detected by the techniques and tools and those smells that are not detected yet.

•
Articles that only consider architectural refactoring, not architectural smell detection.

•
Literature available in the form of interviews, news, posters, tutorials, and lectures.

•
Articles that present proposed work, such as visionary reports, proposals, briefings, etc.

•
Articles whose full text is not available.

The initial search in the digital databases was restricted to TAK (Title, Abstract, and Keywords). The titles and abstracts of the retrieved articles were reviewed to apply the inclusion and exclusion criteria. In some cases, where the relevance of the article was unclear from the titles and abstracts, we also read the introductions of the articles. After applying the inclusion and exclusion criteria to the articles (529), the number of articles was reduced to 76 (as shown in Table 1). These 76 articles became the candidates for the snowballing strategy described in the next section.

3.4. Snowballing
We used the guidelines of Wohlin (2014) to perform snowball sampling to search the relevant literature that might have been missed by our search string. We performed one iteration of forward and backward snowballing. By applying this snowballing strategy to the selected 76 articles, we identified 27 new articles. Similar to the articles (retrieved by our search string), the newly found 27 articles were also subjected to our inclusion and exclusion criteria. After the inclusion and exclusion criteria were applied, an additional nine articles were added to the pool of 76 articles making the final set of papers in this study 85 articles (also shown in Table 1).

4. Analysis framework
After obtaining the desired literature sources, we extracted the key factors related to the detection of architectural smells. In this section, we describe the factors constituting our analysis framework. The factors were extracted according to the guidelines provided by Petersen et al., 2008, Petersen et al., 2015 and driven by our research questions. The first author extracted the data from the 85 primary papers. To ensure descriptive validity, the other two authors also independently extracted the data from just over 15% of the primary papers. The disagreements (and perceptual differences in the observations) in the data extraction were then discussed among all the authors to reach a common ground on how the data should be extracted and processed. Once all three authors agreed on a common extraction and classification scheme, the first author extracted the data from the rest (85%) of the primary papers.

The analysis framework was developed by considering both the content of the papers and our research questions. To analyze the detection techniques and tools, some key factors needed to be identified (e.g., what kind of architectural smells are detected; what types of detection techniques are proposed). To have a comprehensive set of factors, we considered factors that have been used in prior studies to analyze the detection of design smells (Alkharabsheh et al., 2019, Mumtaz et al., 2019a) and bad smells detection tools (Fernandes et al., 2016). For the factors that are related to the evaluation of techniques, we also sought guidance from Jedlitschka et al. (2008). They reported some essential elements for an experimental setup in software engineering, which we also adopted with some variations (also used in Mumtaz et al., 2019a, Alkharabsheh et al., 2019 and Fernandes et al. (2016)). Moreover, to see the prominent publication venues and involvement of industry in the detection of architectural smells, we also considered some demographics-related factors as a part of our analysis. Consequently, in our analysis framework, we divided the factors (with some overlap) into three categories: demographics-related (RQ1), technique-related (RQ2), and tool-related (RQ3). The analysis framework is depicted (with examples) in Fig. 2. The category-wise explanation of the factors is provided in the rest of this section. Note that the “types” mentioned in each analysis factor were extracted from the primary papers. In the case of tool-related factors, where information is missing in the papers, we also extracted data from the official webpages of the tools.

•
Publication years — How many articles are published in each year.

Types – 2010 to 2019.

•
Publication venue — The venues in which the literature related to architectural smells detection is published.

Types — Journal, conference, and workshop.

•
Origin of publications — The affiliation of the authors who published the articles related to architectural smells detection.

Types — Academic and industry.

Technique-related factors — To answer RQ2, we formulated the following factors:

•
Technique type — The foremost information that we looked at was the technique types presented in the related corpus. The main idea was to first identify what techniques were employed for detection and then formulate a classification to categorize the detection techniques. For instance, if a technique used a graphical representation to locate undesired dependencies between components of the architecture (Hayashi et al., 2018), we classified the technique under the graph-based approach. To find such information, we read through the proposed technique sections of the articles.

Types — Rules-based, graph-based, design structure matrix, model-driven, code smells analysis, reverse engineering and history-based, search-based, visualization, and others.

•
Architecture style — The literature investigated different architecture styles while detecting the smells. For instance, some articles detected architectural smells for MVC architecture (Hayashi et al., 2017). To collect such information, we scanned for the architecture styles in the articles.

Types — Service-oriented architecture, Model-View-Controller, layered, component, cloud, client–server, C-language architecture, Java EE architecture, Android architecture, and aspect-oriented architecture.

•
Quality characteristic – The literature investigated some architectural quality characteristics. We map the articles to quality characteristics based on two criteria. First, if a primary paper specifically investigated a quality characteristic. Second, if the primary paper linked the detected architectural smells with a specific quality characteristic. For instance, many articles detected those architectural smells that impact the maintainability aspects of software systems. We used the quality characteristics chart specified in the ISO Standard (ISO25010) quality model (Anon, 2020).

Types — Maintainability, performance, and security.

•
Architectural smells – The articles focused on detecting a variety of architectural smells making smells another paramount element of our analysis framework.

Types — Service-oriented, performance, dependency, package, MVC-related, component, and other smells. The architectural smells that fall into these categories are listed in Table 14. There is no existing study that presents a comprehensive classification of architectural smells, and that is not the goal of this study since we are analyzing only the subset of architectural smells that are currently detected by techniques or tools. Therefore, in our mapping study, we discuss the architectural smells in the same way they are presented in the primary papers. For example, if a primary paper says that they have detected dependency smells, we classify the smells detected by that technique in the “dependency” category. The description of each smell is provided in Appendix. Mostly, we extracted the description of smells from the catalog papers, however if the definition of a smell is not provided in the catalog paper, we cited one of the primary papers where that description is available.

Since validation holds the key to see the applicability of a detection technique, we also examined if and how the techniques were validated. We noticed that, in many primary papers, “validation” and “evaluation” are used in the same context; therefore, we also use these terms interchangeably throughout this paper. Jedlitschka et al. (2008) discussed several essential ingredients of an experimental setup, such as evaluation variables, subjects, data, etc. We used these ingredients as guidance to analyze the evaluation data (project type, project domain, and project language) and evaluation measure. The factors are described as follows:

•
Validation type — We looked whether the technique was validated and, if so, the validation type. We found all studies were empirical in nature. Ideally, we would have categorized the validations using the five types of empirical studies reported by Easterbrook et al. (2008) (controlled experiments, case studies, survey, ethnographies, and action research). However, the primary papers did not report their validation type at this level of detail. Instead, the primary papers mentioned only case studies and empirical studies as the evaluation methods for the detection approaches. While a case study is a type of an empirical study (Easterbrook et al., 2008), we report these two validation types separately since these are the two terms used by the primary papers. Usually, a case study allows an in-depth examination of a particular case (single project/system/product), whereas an empirical study gives a more generalized understanding by considering multiple software systems at the same time in the evaluation process (Easterbrook et al., 2008). Still, the borderline between these types of evaluation is generally blurred (Runeson and Höst, 2009), and hence we rely on the terminologies used in the primary papers to classify them.

Types – Empirical study and case study.

•
Project type – The validations were performed with different types of projects.

Types — Open source, commercial, and student project.

•
Project domain — The projects also belonged to different software domains. Note that the “domain” here is software specific, such as application software (e.g., web application) or system software (e.g., driver).

Types — Software product line, web application, integration system, service-based systems, android system, distributed system, middleware, parser, and driver.

•
Project language – The investigated software projects were developed in different programming languages.

Types — Java, C#, C++, C, AspectJ, PHP, and Python.

•
Evaluation measure – The articles measured variables to analyze the effectiveness of the detection techniques.

Types — Precision, recall, correlation, causality, regression, execution (detection or computation) time, robustness, semantic similarity, ranking measure, decoupling level, propagation cost, maintenance cost, response time, throughput, utilization, debt history, and architects’ and developers’ feedback.

Tool-related factors — For detection tools (RQ3), we extracted the associated architectural smells, the associated technique type, the validation type, tool availability, and language support. These factors were also used in a comparative study to analyze bad smells detection tools (Fernandes et al., 2016). For architectural smells, technique type, and validation type, we used the same framework as described above for detection techniques. The two additional tool-specific factors are described as follows:

•
Tool availability — We searched in which form the architectural smells detection tools are available. If no information regarding tool availability was provided in the paper, we looked for the official webpage of the tool to obtain this information.

Types — Open source, commercial, and not available.

•
Language support – It was also important to note what programming languages are supported by the tool. The rationale was to see the coverage of the tool in terms of the development languages. Once again, if this information was not available in the paper, we located it from the official webpage of the tool.

Types — Java, C++, C, C#, Python, .Net, PHP, JavaScript, TypeScript, Go, Swift, COBOL, Apex, Kotlin, Ruby, Scala, HTML, CSS, ABAP, Flex, Objective-C, SQL, VB, XML, Ada, Fortran, JOVIAL, Assembly, F#, JSP, R, Erlang, Unix Scripts, and Pascal.

5. Architectural smells detection
This section answers our research questions by examining the demographics of the published literature on architectural smells detection (RQ1), presenting and discussing the detection techniques (RQ2) and tools (RQ3), and reflecting on the gaps and limitations of the detection techniques and tools (RQ4). The main findings of our RQs are summarized in Fig. 12.

5.1. Demographics (RQ1)
RQ1 — What are the demographics of the published articles?

When — Fig. 3 shows the distribution of publications each year (until 2019). There could be more articles published in 2019 that were not indexed because we executed our search in October 2019. Fig. 3 shows an overall trend of an increasing number of publications over the years except in 2013 and 2017. A subtle spike was observed in 2014, which resulted from one research group releasing multiple papers in that year.

Where — In Table 2, we list the venues that published the articles related to architectural smells detection. It can be seen that the articles are scattered across many venues; however, some venues tend to publish more on architectural smells detection. For instance, the dedicated conferences on software architecture and technical debt recorded the most publications. The conference with the most number of articles (6) is the European Conference on Software Architecture. In terms of journals, Information and Software Technology indexed the most articles (3).

Origin — We also looked at the affiliations of the researchers, who are active in studying architectural smells detection, to see whether they are from academia or industry. We saw that all of the active researchers have academic affiliations; however, some of them have collaborated with software companies. For instance, Reimanis et al. (2014) applied a detection technique in a company’s software to analyze its architectural quality. We did not find any article that was solely produced by industry.


Table 2. Publication venues.

Venue	Number of articles
European Conference on Software Architecture (ECSA)	6
International Conference on Technical Debt (ICTD)	5
International Conference on Software Engineering (ICSE)	5
International Conference on Service-Oriented Computing (ICSOC)	5
EUROMICRO Conference on Software Engineering and Advanced Applications (SEAA)	4
International Workshop on Managing Technical Debt (MTD)	4
Information and Software Technology (IST)	3
International Conference on Software Architecture (ICSA)	3
Working IEEE/IFIP Conference on Software Architecture (WICSA)	3
ACM SIGSOFT Conference on Quality of Software Architectures (QoSA)	2
Brazilian Symposium on Software Components, Architectures and Reuse (SBCARS)	2
IEEE Transactions on Software Engineering (TSE)	2
International Conference on Automated Software Engineering	2
Science of Computer Programming (SCP)	2
International Conference on Web Services (ICWS)	2
Journal of Systems and Software (JSS)	1
IEEE Transactions on Services Computing (TSC)	1
IEEE Working Conference on Reverse Engineering (WCRE)	1
IEEE Working Conference on Software Visualization (VISSOFT)	1
International Conference on Software Architecture Workshops (2017 ICSAW—Tool papers)	1
International Conference on Software Architecture Companion (2019 ICSA-C—QUDOS/CSE)	1
International Workshop on Bringing Architectural Design Thinking into Developers Daily Activities (BRIDGE)	1
International Conference on Engineering of Complex Computer Systems (ICECCS)	1
Software and Systems Modeling (SoSyM)	1
International Working Conference on Source Code Analysis and Manipulation (SCAM)	1
Australasian Computer Science Conference (ACSC)	1
International Conference on Software Maintenance and Evolution (ICSME)	1
ACM Symposium on Applied Computing (SAC)	1
IEICE Transaction on Information and Systems (TIS)	1
European Conference on Software Maintenance and Reengineering (CSMR)	1
Journal of Software Engineering Research and Development (JSERD)	1
Brazilian Symposium on Software Engineering (SBES)	1
Conference on Genetic and Evolutionary Computation (GECCO)	1
International Journal of Cooperative Information Systems (IJCIS)	1
International Symposium on Empirical Software Engineering and Measurement	1
International Conference on Software Engineering and Formal Methods (SEFM)	1
International Conference on Cloud Computing Technology and Science (CloudCom)	1
International Conference on Software Analysis, Evolution and Re-engineering (SANER)	1
Hawaii International Conference on System Sciences (HICSS)	1
Computer Software and Applications Conference (COMPSAC)	1
International Journal of Computer Theory and Engineering (IJCTE)	1
ACM SIGSOFT Software Engineering Notes (SEN)	1
International Conference on Software Process Improvement (CIMPS)	1
International Conference on Mobile Software Engineering and Systems (MOBILESoft)	1
Institute for System Programming (ISP)	1
Asia-Pacific Symposium on Internetware (INTERNETWARE)	1
Belgium-Netherlands Software Evolution Workshop (BENEVOL)	1
5.2. Detection techniques (RQ2)
RQ2 — What detection techniques for architectural smells are proposed in literature?

Several architectural smells detection techniques have been proposed in the literature. The goal of RQ2 is to analyze the detection techniques; therefore, we present and discuss the techniques in terms of the analysis framework (formulated in Section 4).

To address RQ2, we present the architectural smells detection techniques in terms of nine categories, identified from the “technique type” factor of our analysis framework during the data extraction and classification process. The nine categories are: rules-based, graph-based, design structure matrix, model-driven, code smells analysis, reverse engineering and history-based, search-based, visualization, and others. Analyzing the detection techniques based on their technique type allows identification of the key gaps, limitations, and possible future research directions. For instance, knowing which technique types have limited evaluation would open areas for future work.

In this section, we describe all the detection techniques in terms of these nine technique types. Inside each technique type, we also discuss the other technique-related factors (architecture style, smells detected, quality characteristic, architectural smells, and validation-related factors) to collectively analyze all the related techniques. The articles that belong to the nine categories are listed in Fig. 4. Note that, in Fig. 4, some primary references appear in two categories, for instance, Ouni et al. (2015b) appears in both rules-based and search-based categories. In such hybrid approaches, we found that the main techniques were using rules (metrics and thresholds) only to supplement them. Therefore, we describe the hybrid approaches in their main technique section. For instance, in Ouni et al. (2015b), rules were only supplementing the search-based technique, therefore, it is described in the search-based section. In all hybrid approaches, we found one dominating technique type and one supplementing (i.e., rules with metrics and thresholds). In one case, we also noticed that a technique visualized a dependency graph to identify smells, but since the technique allowed the interactive exploration of smells, we consider it in the “visualization” category rather than the “graph-based” category (Baum et al., 2018). Detailed supplementary material1 is available, which shows the mapping of each paper to the different categories. The supplemental material also shows how each paper in our dataset was categorized according to all factors in our analysis framework.

5.2.1. Rules-based
The rules-based approach is the most commonly applied strategy to detect smells in software architecture. 13 of the 85 (15.29%) papers proposed a rule-based approach. Rules-based approaches take advantage of: (1) metrics and their thresholds (rules), and (2) pre-defined frameworks, heuristics, or guidelines to detect structural problems in the software artifacts. In this section, we describe rules-based approaches that focused on detecting architectural smells.

Description of Existing Rules-based Techniques — Many rules-based techniques applied pre-defined frameworks and patterns to detect architectural smells (Velasco-Elizondo et al., 2017, Martini et al., 2018b, Goldstein and Segall, 2015, Moha et al., 2012, Palma et al., 2013, Palma, 2012, Palma et al., 2014c, Palma et al., 2018). These techniques used architectural guidelines and compliance checking to create frameworks for specifying and detecting architectural smells. In addition, these techniques studied a variety of software architectures, for instance, one technique detected smells in MVC (Velasco-Elizondo et al., 2017) and some in service architecture (Moha et al., 2012, Palma et al., 2013, Palma, 2012).


Download : Download high-res image (144KB)
Download : Download full-size image
Fig. 5. Validation type used in the detection techniques.


Download : Download high-res image (165KB)
Download : Download full-size image
Fig. 6. Project type used in the validation of detection techniques.

We also found a couple of techniques that used product metrics to detect architectural smells (Li et al., 2014, Skiada et al., 2018). Both of these techniques analyzed the possibility of whether modularity metrics could be used as indicators of architectural technical debt. One of these two techniques measured modularity metrics to identify modularity violations at the package-level (Skiada et al., 2018). The other technique detected dependency smells that were involved in increasing the complexity of the Java packages (Li et al., 2014).

The findings from the rules-based techniques in terms of the analysis factors are described as follows:

•
Architecture style — We observed that approximately 60% of the rules-based techniques focused on service-oriented architecture (Palma et al., 2014b, Nayrolles et al., 2013, Moha et al., 2012, Palma, 2012, Palma et al., 2014c, Palma et al., 2013, Yugov, 2016, Palma et al., 2018). We found only one technique that focused on MVC architecture (Velasco-Elizondo et al., 2017).

•
Quality characteristic — The rules-based techniques focused on a variety of quality aspects, such as modularity (Martini et al., 2018b, Skiada et al., 2018), maintainability (Li et al., 2014, Moha et al., 2012, Palma et al., 2013, Nayrolles et al., 2013, Palma, 2012, Palma et al., 2018, Palma et al., 2014c, Velasco-Elizondo et al., 2017, Yugov, 2016), complexity (Li et al., 2014, Palma et al., 2014b), and evolvability (Palma et al., 2014b, Moha et al., 2012, Palma et al., 2013, Nayrolles et al., 2013, Palma, 2012, Palma et al., 2018, Palma et al., 2014c, Yugov, 2016).

•
Smells detected — The architectural smells detected by rules-based approaches are presented in Table 3. Because of the attention on the service-oriented architecture, the detected smells were service-based, prominently, Multi-service, Chatty Service, Nano-service, Data Service, and Ambiguous Service. The technique that studied MVC architecture investigated MVC-related smells (Velasco-Elizondo et al., 2017). A few rules-based approaches also detected dependency and modularity smells in the architecture (Martini et al., 2018b, Li et al., 2014, Skiada et al., 2018). These techniques focused on package-level smells, however, the specific smells that can be detected were not described in the papers. Note that the package-level smells refer to smells in Java packages, which is semantically similar to namespaces in other languages (e.g., C#).

•
Validation — All but one of the techniques were validated. Approximately 60% of the techniques with validation were evaluated empirically, while the rest were validated through case studies (see Fig. 5). Open source systems were mainly used in the validations of the rules-based techniques (see Fig. 6), particularly, in the cases, where service-oriented smells were detected. The validation studies mainly measured precision and recall of the proposed approaches as indicators of the effectiveness of the techniques. For the techniques that used product metrics, one measured correlation (Li et al., 2014) and the other technique measured both correlation and regression (Skiada et al., 2018). In many techniques, in addition to measuring recall or precision, performance of their detection was also measured in terms of execution/computation time (Velasco-Elizondo et al., 2017, Goldstein and Segall, 2015, Nayrolles et al., 2013, Palma et al., 2013, Palma et al., 2018). In another technique, robustness, accuracy (recall and precision), execution time, and detection time were computed as performance indicators (Palma et al., 2014b).

Rules common in other technique types — We also noticed that rules-based approaches (specifically metrics and thresholds) were commonly used in combination with other technique types (Hayashi et al., 2018, Hayashi et al., 2017, Ouni et al., 2015a, Ouni et al., 2015b, Wang et al., 2017, Wang et al., 2016, Hassouna, 2017, Pismag and Kelly, 2017, Trubiani et al., 2014). For instance, graph-based techniques (e.g. Hayashi et al., 2018, Hayashi et al., 2017), search-based techniques (e.g. Ouni et al., 2015a, Ouni et al., 2015b, Wang et al., 2017, Wang et al., 2016, Hassouna, 2017 and Pismag and Kelly (2017), a model-driven technique (Cortellessa et al., 2014), and a visualization technique (Trubiani et al., 2014) incorporate some rules in the detection techniques. For all of these, rules are used only to supplement the main technique type, so these are described and analyzed later in the relevant technique type.


Table 3. Architectural smells detected by rules-based approaches.

Paper	Architectural smells
Goldstein and Segall (2015)	Cyclic Dependencies, Factory Pattern Violations, Layering Violations, other user-defined pattern violation
Li et al. (2014)	Dependency smellsa (package-level)
Martini et al. (2018b)	Dependency smellsa with respect to complexity and modularity
Moha et al., 2012, Palma et al., 2013	Multi-service, Tiny Service, Sand Pile, Chatty Service, Knot Service, Nobody Home, Duplicated Service, Bottleneck Service, Service Chain, Data Service
Nayrolles et al. (2013)	Multi-service, Tiny Service, Chatty Service, Knot Service, Bottleneck Service, Service Chain
Palma (2012)	Multi-service, Tiny Service, Duplicated Service, Bottleneck Service
Palma et al. (2014b)	Breaking Self-descriptiveness, Forgetting Hypermedia, Ignoring Caching, Ignoring MIME Types, Ignoring Status Code, Misusing Cookies, Tunneling through GET, Tunneling through POST
Palma et al. (2018)	Ambiguous Name, Bloated Service, Multi-service, Tiny Service, Nobody Home, Crudy Interface, Crudy URI, Sand Pile, Chatty Web Service, Forgetting Hypermedia, Ignoring MIME Types
Palma et al. (2014c)	Ambiguous Name, Chatty Web Service, Crudy Interface, Data Web Service, Duplicated Web Service, Fine-grained Web Service, God Object Web Service, Low Cohesive Operations (in the same portType), Maybe it is not RPC, Redundant PortTypes
Skiada et al. (2018)	Modularity violationsa (package-level)
Velasco-Elizondo et al. (2017)	Model, view, and controller using each other’s data/functionalities
Yugov (2016)	God Object
a
Specific smells not mentioned in the paper.

5.2.2. Graph-based
Graph-based approaches depict entities or components of a system as nodes, and the relationships are represented through edges. Graph-based techniques are extensively used to detect architectural smells because it is intuitive to represent problematic relationships between the entities of the software architecture in graphical form. In this section, we present graph-based approaches (9 of 85—10.58%) that were employed to detect architectural smells.

Description of Existing Graph-based Techniques — Graph-based techniques have been used to predict architectural smells (Tommasel, 2019, Díaz-Pace et al., 2018, Pigazzini, 2019). Two of these techniques used semantic information to predict the architectural smells (Pigazzini, 2019, Díaz-Pace et al., 2018). For instance, Díaz-Pace et al. (2018) explored the use of social network analysis to extract architecture information useful to predict the undesired dependencies in the future versions of Java projects. The predictions were mainly based on identifying problematic links (that represent dependency smells) between the components (represented as nodes in the graph) of the architecture. For instance, a node (component) involved in many links (many dependencies) with other nodes might create modularization issues in the architecture. Such links between nodes of a graph represent undesired dependencies that should be removed to have a better maintainable architecture. Another technique analyzed relationships between architectural smells using a dependency graph to see if a smell can indicate the presence of other smells (Le et al., 2018). We also observed a graph-based approach that not only detects architectural smells, but also suggests appropriate refactorings for the detected smells (Dietrich et al., 2012).

Some of the graph-based techniques used a combination of graph-based and rule-based techniques to identify architectural smells (Hayashi et al., 2018, Hayashi et al., 2017, Vanciu and Abi-Antoun, 2013, Tiwari et al., 2019). Some applied rules or constraints to the graphical representation of the software architecture (Hayashi et al., 2018, Hayashi et al., 2017, Vanciu and Abi-Antoun, 2013). Others combined product metrics with dependency graphs to detect architectural smells (Tiwari et al., 2019).

The findings from the graph-based techniques in terms of the analysis factors are described as follows:

•
Architecture style — Mostly, the architecture style is generic for the graph-based techniques, however, a couple of techniques focused on MVC architecture (Hayashi et al., 2018, Hayashi et al., 2017), and one focused on the software architecture in C-language environment (Tiwari et al., 2019).

•
Quality characteristic — The focus of graph-based techniques (approximately 67%) was mainly on maintainability quality (Tommasel, 2019, Le et al., 2018, Hayashi et al., 2017, Hayashi et al., 2018, Pigazzini, 2019, Tiwari et al., 2019). One technique focused on modularization aspects (a sub-characteristic of maintainability) of the software architecture (Dietrich et al., 2012) and another on security aspects (Vanciu and Abi-Antoun, 2013).

•
Smells detected — A variety of architectural smells were detected through graph-based approaches, for instance,dependency-related smells (e.g., Cyclic, Unstable, Hub-like, etc.) (Tommasel, 2019, Díaz-Pace et al., 2018, Le et al., 2018, Hayashi et al., 2018, Hayashi et al., 2017, Tiwari et al., 2019), responsibility violations (e.g., Scattered Functionality, Feature Concentration, etc.) (Hayashi et al., 2018, Hayashi et al., 2017, Pigazzini, 2019), and security flaws (e.g. Information Disclosure and Information Tampering) (Vanciu and Abi-Antoun, 2013). One technique detected the architectural smells at three abstraction levels: module (package), file, and function using graphs (Tiwari et al., 2019). Architectural smells detected by graph-based approaches are listed in Table 4.

•
Validation — The techniques were evaluated empirically mainly with open source projects (see Fig. 5, Fig. 6). All evaluations used projects developed in Java, except in one case (Tiwari et al., 2019), where the evaluation was performed using projects written in C. The effectiveness of the proposed graph-based approaches was measured using recall and precision, except in four papers, where two computed semantic similarity (Pigazzini, 2019, Díaz-Pace et al., 2018); one measured different constraints (e.g., provenance, transitivity, reachability, etc.) (Vanciu and Abi-Antoun, 2013); and one computed multiple correlations (Tiwari et al., 2019).


Table 4. Architectural smells detected by graph-based approaches.

Paper	Architectural smells
Díaz-Pace et al. (2018)	Cyclic Dependencies, Hub-like Dependencies
Dietrich et al. (2012)	Abstraction without Decoupling, Subtype Knowledge, Degenerated Inheritance, Cycles between Namespaces
Hayashi et al., 2017, Hayashi et al., 2018	Responsibility violations (Separation of Concerns), Dependency violations (Unauthorized dependency)
Le et al. (2018)	Concern Overload, Cyclic Dependency, Link Overload, Unused Interface, Sloppy Delegation, Co-change Coupling
Pigazzini (2019)	Scattered Functionality, Feature Concentration
Tiwari et al. (2019)	Large File, Hub-like Dependencies, Message Chain, Shotgun Surgery, Cyclic Dependencies, Inappropriate Intimacy, Feature Envy, Long Parameter List
Tommasel (2019)	Cyclic Dependencies, Unstable Dependencies, Hub-like Dependencies
Vanciu and Abi-Antoun (2013)	Security flaws (Information Disclosure, Information Tampering)

Table 5. Architectural smells detected by DSM approaches.

Paper	Architectural smells
Cai and Kazman (2016)	Unstable Interface, Modularity Violation, Improper Inheritance, Cross-module Cycle, Cross-package Cycle
Kazman et al. (2015)	Unstable Interface, Implicit Cross-module Dependency, Unhealthy Inheritance Hierarchy
Mo et al. (2015)	Unstable Interface, Implicit Cross-module Dependency, Unhealthy Inheritance Hierarchy, Cross-module Cycle, Cross-package Cycle
Mo et al. (2019)	Unstable Interface, Modularity Violations, Unhealthy Inheritance Hierarchy, Crossing, Clique, Package Cycle
Mo et al. (2018)	Unstable Interface, Modularity Violation, Unhealthy Inheritance, Cyclic Dependency, Package Cycle, Crossing
Nayebi et al. (2019)	Clique, Package Cycle, Improper Inheritance, Modularity Violation, Crossing, Unstable Interface
Snipes et al. (2018)	Unstable Interface, Implicit Cross-module Dependency, Unhealthy Inheritance Hierarchy, Clique, Package Cycle
Xiao et al. (2016)	Hub, Anchor Submission, Anchor Dominant, Modularity Violation
5.2.3. Design structure matrix (DSM)
A design structure matrix is a mechanism commonly used to design, develop, understand, and manage complex system (Eppinger and Browning, 2012). It is a two-dimensional matrix that represents the structural relationships in the software. DSMs are widely employed to detect architectural smells because the matrix can represent complex architectural components and their relationships.

Description of Existing DSM Techniques — Many approaches (8 of 85—9.41%) have been developed that use a DSM to represent software architecture data to locate clusters and patterns that represent architectural smells (Snipes et al., 2018, Kazman et al., 2015, Xiao et al., 2016, Mo et al., 2015, Mo et al., 2019, Cai and Kazman, 2016, Mo et al., 2018, Nayebi et al., 2019). For instance, one technique created a coupling probability matrix based on the design structure matrix idea to identify four types of architectural flaws (Xiao et al., 2016). Undesired coupling between components of the architecture was linked to dependency-related smells. Similarly, in two DSM techniques (Snipes et al., 2018, Kazman et al., 2015), the authors extracted data from software architecture and depicted it using DSM to identify file clusters that participated in architectural smells. Similarly, some approaches defined patterns and antipatterns based on design rule theory using architectural knowledge (Mo et al., 2015, Mo et al., 2019, Cai and Kazman, 2016). In these techniques, the complex software architecture was split into smaller components, patterns, etc. and depicted using the design rule space method.

The findings from the DSM techniques in terms of the analysis factors are described as follows:

•
Architecture style — None of the DSM techniques studied a specific architecture style, except one (Xiao et al., 2016) in which component architecture was studied. The rest were all applicable to generic architecture styles.

•
Quality characteristic — We noticed that only the maintainability of the software architecture was assessed through design structure matrix.

•
Smells detected — Architectural smells, such as Unstable Interface, Package Cycles, Unhealthy Inheritance, Clique, and Module Dependency, were mostly identified by structuring the architectural components and entities into a design structure matrix. All the DSM techniques supported the detection of Unstable Interface. In one technique, component-level smells (Hub, Anchor Submission, and Anchor Dominant) were identified (Xiao et al., 2016). The architectural smells detected by DSM approaches are listed in Table 5.

•
Validation — Both empirical and case studies were conducted with mainly commercial projects (see Fig. 5, Fig. 6). The projects used to evaluate the techniques were implemented in different development languages. Nearly 38% of the approaches used Java (Kazman et al., 2015, Mo et al., 2015, Mo et al., 2019) or C# (Snipes et al., 2018, Mo et al., 2018, Cai and Kazman, 2016), while 25% (Mo et al., 2018, Cai and Kazman, 2016) selected C and C++ projects for validation. In several techniques, the maintenance cost of the architecture was evaluated by considering change frequency, change churn, bug frequency, and bug churn (Snipes et al., 2018, Mo et al., 2018, Cai and Kazman, 2016, Xiao et al., 2016, Mo et al., 2015, Mo et al., 2019). The effectiveness of some techniques was also measured using recall (Snipes et al., 2018, Kazman et al., 2015, Cai and Kazman, 2016, Mo et al., 2015) and one through precision (Kazman et al., 2015). In one study, the evaluation measured the decoupling level and propagation cost of a system (Nayebi et al., 2019).

5.2.4. Model-driven
In model-driven methods, the structure and behavior of the systems are represented using abstractions and modeling (Miranda and Abreu, 2016). Model-driven approaches are common to detect architectural smells because, through modeling, abstractions can be created that generate structures to analyze software architecture. 9 of the 85 (10.58%) papers implemented model-driven approaches.

Description of Existing Model-driven Techniques — Many model-driven approaches took advantage of model transformation mechanisms to detect architectural smells (Arcelli et al., 2019, De Sanctis et al., 2017, Cortellessa et al., 2012, Czabanski et al., 2018, Cortellessa et al., 2010, Cortellessa et al., 2014, Trubiani and Koziolek, 2011). For instance, in two approaches the model transformation was achieved using intermediate XML representations (Cortellessa et al., 2010, Cortellessa et al., 2014). The detection of smells was accomplished by assigning logical predicates in the XML representations. Similarly, a couple of techniques used a stochastic process to model performance-aware components in software architecture (De Sanctis et al., 2017, Cortellessa et al., 2012). A model-driven technique detected anomalies related to communication within and among the components of the architecture (Shin et al., 2006). In another approach, a meta-model for a Java EE application was created. In the meta-model, they used Query/View/Transformation language to state the process of antipatterns detection (Zhang et al., 2012).

The findings from the model-driven techniques in terms of the analysis factors are described as follows:

•
Architecture style — Mostly, model-driven approaches did not focus on specific architecture styles, except for a few, where the techniques focused on micro-services (Arcelli et al., 2019), Java EE (Zhang et al., 2012), and component (Shin et al., 2006) architectures.

•
Quality characteristic — Approximately 67% of the approaches measured the impact of architectural smells on the performance of software architecture (Arcelli et al., 2019, De Sanctis et al., 2017, Cortellessa et al., 2012, Cortellessa et al., 2010, Cortellessa et al., 2014, Trubiani and Koziolek, 2011). There were also two methods that looked into maintainability aspects of software architecture (Czabanski et al., 2018, Zhang et al., 2012).

•
Smells detected — Most of the techniques measured and detected performance smells (Arcelli et al., 2019, De Sanctis et al., 2017, Cortellessa et al., 2012, Cortellessa et al., 2010, Cortellessa et al., 2014, Trubiani and Koziolek, 2011). The prominently detected smells were Blob, Unbalanced Processing, One-lane Bridge, Traffic Jam, and Ramp. The architectural smells detected by model-driven techniques are presented in Table 6.

•
Validation — From the validation perspective, case studies were performed with commercial and open source systems (see Fig. 5, Fig. 6). The project domains in half of the techniques were not specified (De Sanctis et al., 2017, Cortellessa et al., 2012, Trubiani and Koziolek, 2011), whereas the other half used web-based systems (Arcelli et al., 2019, Cortellessa et al., 2010, Cortellessa et al., 2014). In the case where a technique studied service architecture, the investigated projects were developed in REST (Arcelli et al., 2019). For Java EE architecture, Java projects were used (Zhang et al., 2012). Where the performance of the architecture was evaluated, response time, throughput, and utilization were measured. In some instances, recall was computed as an evaluation measure for the proposed techniques (Zhang et al., 2012, Czabanski et al., 2018, Shin et al., 2006).


Table 6. Architectural smells detected by model-driven approaches.

Paper	Architectural smells
Arcelli et al. (2019)	Pipe and Filter, One-lane Bridge
Cortellessa et al. (2012)	Blob, Unbalanced Processing, One-lane Bridge, Excessive Dynamic Allocation, Traffic Jam, Ramp
Cortellessa et al. (2010)	Unbalanced Processing (Concurrent Processing Systems), Circuitous Treasure Hunt, Ramp
Cortellessa et al. (2014)	Blob, Unbalanced Processing, Circuitous Treasure Hunt, Empty Semi-trucks, Tower of Babel, One-lane Bridge, Traffic Jam, Excessive Dynamic Allocation, Ramp, More is Less
Czabanski et al. (2018)	Unhealthy Inheritance, Cross-module Cycles, Package Cycles
De Sanctis et al. (2017)	Blob, Extensive Processing, One-lane Bridge, Excessive Dynamic Allocation, Traffic Jam, Ramp, Pipe and Filter
Shin et al. (2006)	Anomalies within and among components (communication-related)
Trubiani and Koziolek (2011)	Blob, Unbalanced Processing, Circuitous Treasure Hunt, Empty Semi-trucks, One-lane Bridge, Traffic Jam
Zhang et al. (2012)	Fine-grained Web Service, Multi-service, Tiny Service, Ignoring Reality, Too Much Code, Embedded Navigation Information, Accessing Entity Directly, Fine-grained Remote Calls, Transparent Facade, Session A-plenty, Stifle, Database Connection Hog, Performance Afterthoughts
5.2.5. Code smells analysis
Some of the proposed techniques (9 of 85—10.58%) analyzed code smells to identify architectural smells. The main idea of these methods is to see how source code smells can be used to detect smells in the software architecture.

Description of Existing Code Smells Analysis Techniques — Several detection techniques used the knowledge of code smells to locate architectural smells (Vidal et al., 2019, Vidal et al., 2016, Lenhard et al., 2017, Macia et al., 2011, Macia et al., 2012, Oizumi et al., 2015, Oizumi et al., 2014, Sierra et al., 2019, Sharma and Anwer, 2013). These techniques mainly looked at the correlation between code smells and architectural smells. In other words, the proposed techniques analyzed whether code smells in a software system could indicate smells in the corresponding architecture of that system. For example, a class shows the lack of modularization if it has a greater number of lines of code—represents a large class smell. This large class could indicate the modularization issues (e.g., Blob or God Object, etc.) in the related architecture of the system. Note that identifying the correlation between code and architectural smells may not be exactly the detection of architectural smells, but the correlation, if identified, can be used to predict the presence of architectural smells based on the analysis of code smells. As a specific instance, a technique used static code analysis and cloud information to predict the appearance of performance smells if a system is migrated to the cloud architecture (Sharma and Anwer, 2013). Approximately, half of the code smells analysis techniques also employed code smells metrics which were relevant to the identification of architectural smells (Lenhard et al., 2017, Sharma and Anwer, 2013, Oizumi et al., 2015, Oizumi et al., 2014, Macia et al., 2012). For instance, in Sharma and Anwer (2013), the authors used five code-level metrics (related to size and complexity) to detect “Blob” smell, which corresponds to the lack of modularization in the architecture. One paper also investigated the self-admitted technical debt left by the developers in the source code to identify some architectural divergences related to dependency smells (Sierra et al., 2019). This paper did not directly use the code smells to detect architectural smells but used the technical debt information stated (by the developers) in the comments of the source code.

The findings from the code smells analysis techniques in terms of the analysis factors are described as follows:

•
Architecture style — Code smells analysis techniques investigated different architecture styles. Approximately, 78% (Vidal et al., 2019, Sierra et al., 2019, Macia et al., 2011, Vidal et al., 2016, Oizumi et al., 2015, Oizumi et al., 2014, Macia et al., 2012) and 67% (Vidal et al., 2019, Macia et al., 2011, Vidal et al., 2016, Oizumi et al., 2015, Oizumi et al., 2014, Macia et al., 2012) of the studies examined layered and MVC architectures, respectively. We also found one technique for each of the following architectures: cloud (Sharma and Anwer, 2013), aspect-oriented (aspectual) (Macia et al., 2011), and client–server (Oizumi et al., 2014).

•
Quality characteristic — The techniques measured different quality characteristics (e.g., maintainability (Vidal et al., 2019, Macia et al., 2011, Oizumi et al., 2015, Vidal et al., 2016, Oizumi et al., 2014, Macia et al., 2012), consistency (Lenhard et al., 2017), and performance (Sharma and Anwer, 2013)).

•
Smells detected – Since the techniques mainly studied MVC and layered architectures, the architectural smells were mostly specific to these two architectures. In cloud architecture, performance smells (Empty Semi-trucks, Circuitous Treasure Hunt, and Blob) were detected (Sharma and Anwer, 2013). In one technique, inconsistent classes and components in the architecture were explored (Lenhard et al., 2017). The architectural smells detected through code smells analysis are listed in Table 7.

•
Validation – It can be seen from Fig. 5 that the techniques were validated using empirical studies and case studies. Most (67%—see Fig. 6) were conducted with open source Java projects (Vidal et al., 2019, Sierra et al., 2019, Lenhard et al., 2017, Vidal et al., 2016, Oizumi et al., 2015, Macia et al., 2012). Only one study used projects developed in C++, C#, and AspectJ languages for the validation (Macia et al., 2012). Most studies (67%) were validated using projects from the software product line, web, and middleware domains (Vidal et al., 2019, Macia et al., 2011, Vidal et al., 2016, Oizumi et al., 2015, Oizumi et al., 2014, Macia et al., 2012). The effectiveness of the approaches was mostly measured using correlation, precision, and recall.


Table 7. Architectural smells detected by code smells analysis approaches.

Paper	Architectural smells
Lenhard et al. (2017)	Inconsistent Classes/Components
Macia et al., 2012, Macia et al., 2011	Ambiguous Interface, Extraneous Connector, Connector Envy, Scattered Functionality, Concern Overload
Oizumi et al. (2015)	Ambiguous Interface, Concern Overload, Connector Envy, Cyclic Dependency, Scattered Functionality, Unused Interface
Oizumi et al. (2014)	Ambiguous Interface, Connector Envy, Concern Overload, Cyclic Dependency, Extraneous Connector, Scattered Functionality, Unused Interface, Architectural Violation
Sharma and Anwer (2013)	Empty Semi-trucks, Circuitous Treasure Hunt, Blob
Sierra et al. (2019)	Dependency smells (specific smells not mentioned)
Vidal et al., 2016, Vidal et al., 2019	Ambiguous Interface, Concern Overload, Connector Envy, Cyclic Dependency, Scattered Functionality, Unused Interface, Package-level Feature Envy, Package-level Dispersed Coupling
5.2.6. Reverse engineering and history-based
Reverse engineering is a process to deduce design and architectural features from the developed software systems to learn about the production procedures involved in their initial development (Chikofsky and Cross, 1990). History data analysis is also a way to understand the patterns and changes in the software systems. In this section, we describe approaches (4 of 85—4.7%) that explored historical data and reverse-engineered the artifacts to detect architectural smells.

Description of Existing Reverse Engineering and History-based Techniques — In the literature, we found a few techniques based on the historical data or reverse engineering of the software artifacts (Verdecchia, 2018, Xiao, 2015, von Detten and Becker, 2011, Arcelli Fontana et al., 2019). Some techniques used reverse engineering mechanisms and historical data analysis to cluster the data elements to identify architectural smells (Verdecchia, 2018, Xiao, 2015, von Detten and Becker, 2011). These techniques used architectural guidelines and compliance checking to identify clusters with problematic dependencies and connections. These problematic clusters were identified as architectural smells. One technique used only historical data to predict architectural smells (Arcelli Fontana et al., 2019). In this approach, the authors used a link-prediction strategy where dependency information from the previous versions of the software was used to predict architectural issues in the proceeding versions.

The findings from the reverse engineering and history-based techniques in terms of the analysis factors are described as follows:

•
Architecture style — These techniques focused on generalized architecture style, with an exception, where Verdecchia (2018) focused on the Android architecture.

•
Quality characteristic — All the techniques focused specifically on maintainability (Xiao, 2015, Arcelli Fontana et al., 2019, von Detten and Becker, 2011, Verdecchia, 2018).

•
Smells detected — Mostly, dependency-related architectural smells (e.g., Cyclic Dependency, Unstable Dependency, Hub-like Dependency, etc.) were identified by either reverse-engineering or extracting historical data from the systems (Xiao, 2015, Arcelli Fontana et al., 2019). However, in one technique, communication-related smells were identified (von Detten and Becker, 2011). The detected smells by each approach are presented in Table 8.

•
Validation — Half of the approaches were not validated. The two approaches where validations were performed; one (Xiao, 2015) performed an empirical study (using open source and commercial systems) and the other (von Detten and Becker, 2011) conducted a case study (with open source projects) (see Fig. 5). Both validations were performed using open source systems (see Fig. 6). Precision (von Detten and Becker, 2011) and debt history (Xiao, 2015) were used as evaluation measures.


Table 8. Architectural smells detected by reverse engineering and history-based approaches.

Paper	Architectural smells
Arcelli Fontana et al. (2019)	Unstable Dependency, Cyclic Dependency, Hub-like Dependency, Implicit Cross-package Dependency
Verdecchia (2018)	Android Architecture Violations
von Detten and Becker (2011)	Interface Violation, Undercover Transfer Object, Non-transfer Objects Communication, Unauthorized Call
Xiao (2015)	Dependency smells (specific smells not mentioned)

Table 9. Architectural smells detected by search-based approaches.

Paper	Architectural smells
Hassouna, 2017, Ouni et al., 2015b, Wang et al., 2017, Wang et al., 2016	Chatty Web Service, Crudy Interface, Data Web Service, Fine-grained Web Service, God Object Web Service, Maybe it is not RPC, Redundant PortTypes, Ambiguous Web Service
Ouni et al., 2015a, Pismag and Kelly, 2017	Multi-service, Nano-service, Chatty Service, Data Service, Ambiguous Service
5.2.7. Search-based
Search-based methods in software engineering formulate problems as computational search problems that can be solved with a metaheuristic approach (Clarke et al., 2003). A few approaches (6 of 85—7.05%) employed search-based techniques to detect architectural smells.

Description of Existing Search-based Techniques — We saw that all the search-based approaches were developed in combination with rules (Ouni et al., 2015b, Ouni et al., 2015a, Hassouna, 2017, Wang et al., 2017, Wang et al., 2016, Pismag and Kelly, 2017). The approaches mainly employed genetic programming, for instance, in (Ouni et al., 2015b), the approach implemented an algorithm to optimize the detection solution by using the crossover and mutation operations of the genetic programming. Their solution was composed of detection rules based on the real examples of smells in web services. The rules were formulated using product metrics and thresholds, and each rule represented an instance of a smell in the architecture.

The findings from the search-based techniques in terms of the analysis factors are described as follows:

•
Architecture style and quality characteristic — We observed that 100% of the search-based techniques focused on service-oriented architecture and maintainability quality characteristic.

•
Smells detected — The techniques investigated a variety of service-oriented smells, such as Multi-service, Chatty Service, Data Service, etc. The architectural smells detected by each search-based technique are listed in Table 9.

•
Validation — All of the search-based techniques were empirically validated using web-based systems (see Fig. 5). In addition, in Fig. 6, it can be seen that four out of the five (80%) techniques were evaluated with commercial projects. One (Ouni et al., 2015b) used open source projects in the evaluation. The effectiveness of all of the search-based techniques was measured using precision and recall.

5.2.8. Visualization
Only a few methods (4 of 85—4.7%) employed visualization strategies to detect architectural smells. Visualization techniques can aid in the understanding of large software systems with multivariate and multidimensional data (Mumtaz et al., 2018, Mumtaz et al., 2019b).

Description of Existing Visualization Techniques — Visualization techniques were not the commonly used techniques to detect architectural smells. Only four techniques used visualization (Baum et al., 2018, Eliasson et al., 2015, Trubiani et al., 2014, Brondum and Zhu, 2012). In one of the studies (Trubiani et al., 2014), a visualization technique was used in combination with detection rules (product metrics and thresholds) to identify architectural smells automatically. Others propose visualizations that enable developers or architects to manually identify architectural smells as they can use the interactive functionalities to explore the architecture (Brondum and Zhu, 2012, Baum et al., 2018, Eliasson et al., 2015).

The findings from the visualization techniques in terms of the analysis factors are described as follows:

•
Architecture style and quality characteristic — All the visualization techniques focused on generalized architecture style. In terms of quality characteristic, half ((Trubiani et al., 2014, Eliasson et al., 2015)) of the approaches focused on performance, while one considered maintainability (Baum et al., 2018).

•
Smells detected — Half of the techniques detected dependency-related architectural smells (Baum et al., 2018, Brondum and Zhu, 2012), and the other half identified performance smells (Trubiani et al., 2014, Eliasson et al., 2015). The architectural smells detected by the visualization techniques are presented in Table 10.

•
Validation — From the validation perspective, the visualization techniques were evaluated only through case studies (see Fig. 5) and mostly (50%) with commercial projects (see Fig. 6). Utilization, throughput, and response time were computed as performance evaluation measures (Trubiani et al., 2014). In the other performance-oriented approach, efficiency and maintenance cost were measured (Eliasson et al., 2015). In the remaining two techniques (Baum et al., 2018, Brondum and Zhu, 2012), the authors measured recall to express the effectiveness.


Table 10. Architectural smells detected by visualization approaches.

Paper	Architectural smells
Baum et al. (2018)	Cyclic Dependencies, Subtype Knowledge
Brondum and Zhu (2012)	Dependency smells (specific smells not mentioned)
Eliasson et al. (2015)	Misplaced Component
Trubiani et al. (2014)	Blob, Unbalanced Processing, Circuitous Treasure Hunt, Empty Semi-trucks, One-lane Bridge, Traffic Jam

Table 11. Mapping of detected architectural smells to tools as reported in the primary papers.

Architectural smell	Arcan	Sonargraph	Structure101	CLIO	Designite	DV8	SonarQube	inFusion	AI Reviewer	ARCADE	Hotspot Detector	Massey Architecture Explorer	STAN	CAST	SODA
Multi-service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Tiny Service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Sand Pile	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Chatty Service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Knot Service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Nobody Home	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Duplicated Service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Bottleneck Service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Service Chain	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Data Service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Bloated Service	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
Unstable Dependency	✓	✓	✓	—	✓	—	—	✓	✓	✓	✓	✓	✓	—	—
Hub-like Dependency	✓	✓	✓	—	—	—	—	—	✓	✓	✓	✓	✓	—	—
Cyclic Dependency	✓	✓	✓	—	✓	—	✓	✓	✓	✓	✓	✓	✓	—	—
Implicit Cross-module Dependency	—	—	—	—	—	—	—	—	✓	✓	✓	✓	✓	—	—
Package Cycles	—	✓	✓	—	—	✓	—	—	—	—	—	—	—	—	—
Biggest Package Cycle Group	—	✓	✓	—	—	—	—	—	—	—	—	—	—	—	—
Ambiguous Interface	—	—	—	—	✓	—	—	—	✓	✓	✓	✓	✓	—	—
Unstable Interface	—	—	—	—	—	✓	—	—	—	—	—	—	—	—	—
Unused Interface	—	—	—	—	—	—	—	—	—	✓	—	—	—	—	—
Unhealthy Inheritance Hierarchy	—	—	—	—	—	✓	—	—	—	—	—	—	—	—	—
Cyclic Hierarchy	—	—	—	—	—	—	—	—	✓	✓	✓	✓	✓	—	—
Multipath Hierarchy	—	—	—	—	—	—	—	—	✓	✓	✓	✓	✓	—	—
Abstraction without Decoupling	—	—	—	—	—	—	—	—	✓	✓	✓	✓	✓	—	—
Unutilized Abstraction	—	—	—	—	—	—	—	—	✓	✓	✓	✓	✓	—	—
Modularity Violations	—	—	—	✓	—	✓	—	—	—	—	—	—	—	—	—
God Component	—	—	—	—	✓	—	—	—	✓	✓	✓	✓	✓	—	—
Feature Concentration	—	—	—	—	✓	—	—	—	—	—	—	—	—	—	—
Scattered Functionality	—	—	—	—	✓	—	—	—	✓	✓	✓	✓	✓	—	—
Dense Structure	—	—	—	—	✓	—	—	—	—	—	—	—	—	—	—
Crossing	—	—	—	—	—	✓	—	—	—	—	—	—	—	—	—
Clique	—	—	—	—	—	✓	—	—	—	—	—	—	—	—	—
SAP Breaker	—	—	—	—	—	—	—	✓	—	—	—	—	—	—	—
Multiple Architecture Violations	✓	—	—	—	—	—	—	—	✓	✓	✓	✓	✓	—	—
Specification–implementation Violation	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—
Sloppy Delegation	—	—	—	—	—	—	—	—	—	✓	—	—	—	—	—
Co-change Coupling	—	—	—	—	—	—	—	—	—	✓	—	—	—	—	—
Separation of Concerns	—	—	—	—	—	—	—	—	—	✓	—	—	—	—	—
Concern Overload	—	—	—	—	—	—	—	—	—	✓	—	—	—	—	—
Link Overload	—	—	—	—	—	—	—	—	—	✓	—	—	—	—	—
5.2.9. Others
In this section, we briefly describe the techniques (11 of 85—12.94%) that do not fit in the above categories. In other words, a technique whose foundation is not based on any of the categories described above is placed into this “Others” category.

Fontana et al. (2019) proposed an approach to identify architectural technical debt using architecture decisions and change scenarios. Tamburri et al. (2019) found the correlation of community smells with architectural smells in sub-optimal modularization structures. The main idea was to use community smells as indicators of smells in the architecture. Martini et al. (2018a) used questionnaire and interviews to collect the detection procedure adopted by the software practitioners. They found that practitioners used the combination of tools and their knowledge of architecture to identify architectural technical debt. de Toledo et al. (2019) performed a qualitative analysis of documents and interviews to identify technical debt in the communication layer of a micro-service system. For instance, they identified too many point-to-point connections between micro-services (i.e., Chatty Micro-service), creating a high volume of connections passing through the communication layer.

Sanchez et al. (2014) presented an approach for specifying and identifying architectural smells as constraints using the Archery architectural description language. Mo et al. (2013) transformed architectural models into an augmented constraint network to identify dependency relations related to architectural decay. Trubiani et al. (2018) executed load testing using a profiler tool to obtain performance hotspots, which are related to the specifications of the performance antipatterns. Palma et al. (2014a) quantified the impact of service antipatterns on the maintenance effort in service-based systems. They performed multiple statistical tests to identify relationships between change-proneness/code churn and antipatterns. Tripathi et al. (2014) identified and presented wrong practices in the antipattern template of service-oriented architecture. Le et al. (2017) proposed a framework to detect architectural smells based on their symptoms with the help of architecture recovery and analysis.

Since the approaches described in the “Others” category are distinctive in nature, we are not describing their commonalities and differences as we did in the technique sections above. However, we found some commonalities between these techniques, for instance, some techniques detected dependency smells (Li et al., 2015b, Martini et al., 2018a, Fontana et al., 2019, Le et al., 2017); a few MVC smells (Sanchez et al., 2014, Mo et al., 2013, Le et al., 2017); and some identified smells in service-oriented architecture (de Toledo et al., 2019, Palma et al., 2014a, Tripathi et al., 2014).

5.3. Detection tools (RQ3)
RQ3 — What detection tools for architectural smells are proposed and evaluated in literature?

This section addresses RQ3 by describing the architectural smell detection tools reported in the literature (12 of 85—14.11%). The descriptions of tools are presented in a similar manner using a subset of the categories developed for detection techniques. We used only a subset because we adopted only those categories employed by the tools. Similar to detection techniques, the detailed supplementary material1 is also available for detection tools.

Graph-based — Fontana et al. (2016a) introduced an open source tool named Arcan that detects architectural smells in Java projects. The tool uses abstraction knowledge of the project to identify dependencies (including problematic architecturaldependencies) between the project’s elements. Later, Biaggi et al. (2018) improved the scalability of Arcan by adding the functionality to handle projects compiled in C and C++ languages. Fontana et al. (2017) evaluated the Arcan tool to see if architectural smells detected by Arcan are actually perceived as architectural issues. Fontana et al. (2016d) also reported their experience of employing two detection tools (Sonargraph and Structure101) to identify architectural erosion in the open source systems. In another report, Fontana et al. (2016c) presented their experience report on three architectural smells detection tools (Sonargraph, SonarQube, and inFusion). von Zitzewitz (2019) described the architecture, working, and application of the Sonargraph tool. The tool allowed software architects to describe the architectural blueprint using a customized domain specific language (DSL). Once the DSL was defined, the architecture quality was automatically checked and enforced during the development process.

Azadi et al. (2019) illustrated the key differences in the detection techniques exploited by the existing detection tools (AI Reviewer, ARCADE, Arcan, Designite, Hotspot Detector (no longer available as a standalone tool—now integrated into DV8 suite), Massey Architecture Explorer (no longer available), Sonargraph, STAN, and Structure101). They showed which and how the architectural smells were detected by these tools. For instance, in the case of Hub-like Dependency, the supported tools (ARCADE, AI Reviewer, Arcan, and Designite) employed graphs in different ways. AI Reviewer detected Hub-like Dependencies by focusing on the ingoing and outgoing dependencies of concrete classes (non-abstract) in the dependency graph; Arcan focused on abstraction and unbalanced (ingoing and outgoing) dependencies in the graph; Designite relied on fan-in and fan-out metrics to identify Hub-like Dependencies using the dependency graph; and finally, ARCADE detected this smell by comparing the ingoing and outgoing dependencies with the aggregated dependencies in the graph. Similarly, for each supported architectural smell, the authors demonstrated the different detection strategies of the tools. In a similar manner, Fontana et al. (2016b) explained how the technical debt indexes are computed in five different detection tools (CAST, inFusion, Sonargraph, SonarQube, and Structure101). They also demonstrated the different detection mechanisms used by these detection tools. We also observed that the most commonly employed detection tools were Arcan, Sonargraph, SonarQube, and Structure101.

Visualization — Sharma (2019) presented Designite (a quality assessment tool) that identifies several architectural smells. Designite also provides information about the root cause of the smells to assist the developers in refactoring. Cai and Kazman (2019) presented a tool suite, named DV8, that provides maintainability assessment using two metrics (decoupling level and propagation cost); detection of six architectural smells (Unstable Interface, Modularity Violations, Unhealthy Inheritance Hierarchy, Crossing, Clique, and Package Cycle); and quantification of maintenance cost. They showed that, by using DV8 suite metrics and visualization, they were able to automatically detect architectural smells and express the maintenance difficulties in the projects. The suite also calculated the maintenance cost of the files affected by the architectural smells.

History-based — Reimanis et al. (2014) measured and predicted the architecture quality of a system by using the structural information of that system. The structural information was in the form of product metrics about historical changes in the structure of the system’s architecture. The structural information (metrics) were fed to CLIO (an architectural degradation detection tool) (Wong et al., 2011) to automatically identify dependencies between the components of a commercial system. The main contribution of CLIO was the automated detection of smells in the commercial system developed in, previously not supported, C++ language.

Rules-based — Nayrolles et al. (2012) presented an open source service-oriented antipatterns detection tool, SODA, to automatically detect antipatterns in service-based systems. They identified several service-related architectural smells.

The findings from the tool papers in terms of the related analysis factors are described as follows:

•
Smells detected — The detected architectural smells reported in the tool papers are summarized in Table 11. Note that the architectural smells that can be detected by each tool is not mentioned on the official webpages of the tools, therefore, we relied on the smells reported in the tool papers. We noticed that identifying dependency smells was common among the detection tools. For instance, problematic dependencies, such as Cyclic, Unstable, Hub-like, Implicit Cross-module, etc. were common among the majority of the tools. On the other hand, only one tool (SODA) detects service-oriented smells.

•
Technique type — Since it is easier to depict and analyze dependencies using graphs, the most common technique type employed by the tools was graph-based (almost 67%) (Biaggi et al., 2018, Fontana et al., 2016a, Fontana et al., 2017, Fontana et al., 2016d, Fontana et al., 2016c, von Zitzewitz, 2019, Azadi et al., 2019, Fontana et al., 2016b). One tool, SODA (Nayrolles et al., 2012), handled the service-oriented architectural smells by implementing rules. Designite (Sharma, 2019) and DV8 (Cai and Kazman, 2019) used the combination of visualization and rules to identify architectural smells automatically. Another tool, CLIO (Reimanis et al., 2014), took advantage of historical information to detect architectural smells.

•
Validation — Only Arcan was empirically validated (see Fig. 7). In the rest of the tool papers, the evaluations were performed using case studies (4 out of 12 papers) or no validation was conducted (5 out of 12 papers).

•
Tool availability — We found that the detection tools are available as a mix of open source and commercial products. For instance, Arcan is fully open source; Structure101 is commercial; Sonargraph and SonarQube are available as open source (limited functionality) and commercial. In Table 12 and Fig. 8, we show the distribution of tools available as open source, commercial, both, and not available. Out of 15, three are open source, six are commercial, and three are available both as open source and commercial. Three tools (inFusion, Hotspot Detector, and Massey Architecture Explorer) are no longer available.

•
Language support — Language coverage is also spread to have maximum language support. Some tools, like DV8, SonarQube, and CAST, manage a long list of development languages, including C, C++, Java, C#, Python, PHP, .Net, and many more (see Table 13), whereas a few (e.g., Designite) provide only limited language support. Most of the supported languages are the compiled languages because there is no overhead of translating the programs into native code at run-time. Only a few interpreted languages (e.g., JavaScript, Python, etc.) are supported by the detection tools. The distribution of language support in terms of development languages is shown in Table 13. It is evident that Java has the most support, while other popular languages (e.g., C++ and C) also have favorable inclusion. However, some development languages (e.g., .Net, Python, and PHP) receive a little attention.


Download : Download high-res image (71KB)
Download : Download full-size image
Fig. 7. Validation type in detection tools.


Table 12. Tool availability.

Tool	Open source	Commercial
Arcan	✓	—
Sonargraph	✓	✓
Structure101	—	✓
CLIO	—	✓
Designite	✓	✓
DV8	—	✓
SonarQube	✓	✓
AI Reviewer	—	✓
ARCADE	✓	—
STAN	—	✓
CAST	—	✓
SODA	✓	—

Download : Download high-res image (73KB)
Download : Download full-size image
Fig. 8. Availability of detection tools.


Table 13. Language support provided by detection tools.

Tool	Java	C++	C	C#	Python	.Net	PHP	JavaScript	TypeScript	Go	Swift	COBOL	Apex	Kotlin	Ruby	Scala	HTML	CSS	ABAP	Flex	Objective-C	SQL	VB	XML	Ada	Fortran	JOVIAL	Assembly	F#	JSP	R	Erlang	Unix Scripts	Pascal
Arcan	✓	✓	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
Sonargraph	✓	✓	✓	✓	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
Structure101	✓	✓	✓	—	✓	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	✓
CLIO	✓	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
Designite	✓	—	—	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
DV8	✓	✓	✓	✓	✓	✓	✓	✓	✓	—	—	✓	—	—	—	—	✓	✓	—	—	✓	✓	✓	✓	✓	✓	✓	✓	—	—	—	—	—	✓
SonarQube	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	—	—	—	—	—	—	—	—	—	—
AI Reviewer	—	✓	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
ARCADE	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
STAN	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
CAST	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓	—	✓	✓	✓	✓	✓	✓	—	✓	✓	✓	✓	✓	✓	✓
SODA	✓	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
5.4. Limitations of detection techniques and tools (RQ4)
This section presents a discussion of the limitations of architectural smells detection techniques and tools reported in the literature and identified through the cumulative analysis of the detection techniques (RQ2) and tools (RQ3).

In Table 14, we show, for each architecture smell, whether existing techniques and tools can detect it. The number (in bracket in Table 14) represents the frequency of research articles in which a detection technique each smell is described. We observed some interesting patterns from Table 14. We found that across all technique categories, service-oriented and performance-related architectural smells were the most widely supported. It can also be seen that service-oriented smells are mainly detected by employing rules-based and search-based approaches, whereas performance-related smells were mostly identified through model-driven techniques. We also observed that the architectural smells that encapsulate dependency issues can be identified through almost all of the technique types. For instance, Cyclic Dependency is detected through rules-based, graph-based, design structure matrix, code smells analysis, history-based, and visualization techniques.

In the rest of this section, we discuss the limitations of architecture smell detection techniques and tools, as identified through this mapping study. These include limitations that are derived through the collective mapping of data extracted from the studies, as well as, the ones that are directly reported by study authors.

Undetected Smells — Table 14 shows that there are many smells that are not detected by existing techniques and tools. The undetected smells belong to package, services (including micro-services), MVC, and other architectural-level smells. Although service-oriented smells (e.g., Multi, Tiny, Knot, Data, etc.) are widely studied, there are still many service-specific smells, such as Golden Hammer, Silver Bullet, Brain Controller, etc. that are not detected yet. Some service smells, which are not currently detected, are at a more granular level (micro-services), for instance, Shared Libraries and Shared Persistency. We also saw that the package-related smells received limited attention, and there are several package smells (e.g., Package Instability, Missing Package Abstractness, etc.) that need detection. Furthermore, we found a few undetected smells that belong to MVC architecture, for instance, Brain Controller and Brain Repository. Also, some of the abstraction (e.g., Missing and Incomplete), encapsulation (e.g., Leaky and Missing), and hierarchy (e.g., Unnecessary and Speculative) specific smells are not subjected to any investigation. System-level smells (Too Many Subsystems, No Subsystems, and Overgeneralized Subsystems), in Table 14, represent problems with size and generalization in the system’s architecture.

We also observed the limited coverage of architectural smells in detection tools. As shown in Table 14, the detection tools mostly provide support for dependency-related and service-specific architectural smells. In the case of other types of architectural smells, tool support is still lacking. The primary papers also pointed out the need to integrate the detection approaches with tools (Ouni et al., 2015b) and improve the scalability of tools in terms of detected smells (Mo et al., 2015).

Increasing support for the currently unsupported architectural smells will be challenging. Some of the primary papers reported that not all architectural smells are equally easy to detect because some smells required additional information (e.g., evolution history data (Mo et al., 2015)). Therefore, when such information is not available for specific smells in certain datasets, it is challenging to detect them (Mo et al., 2015). Moreover, we noticed that static analysis techniques are commonly applied to detect the architectural smells, but the semantic analysis is rarely employed. We argue that semantic analysis techniques could pave ways to detect those architectural smells that encapsulate semantic information. Future research can continue to study ways to improve support across difficult to detect architectural smells. In addition, increased industry collaboration can also be beneficial to increase the data availability.

Lack of Adequate Quantification of Architectural Smells — We saw that many rules-based approaches were employed to detect architectural smells. However, identifying an appropriate set of metrics and their thresholds is a challenge (Ouni et al., 2015a, Ouni et al., 2015b, Le et al., 2018, Mo et al., 2015). For instance, Ouni et al. (2015b) identified thresholds by conducting experiments based on trial-and-error, which meant that the proper configuration of thresholds was required. This implies that there is a lack of adequate quantification of architectural smells.

Lack of Broader Focus on Quality Characteristics — Identifying the maintainability issues of the software systems was the main focus of many of the existing techniques (see Fig. 9). Note that this figure excludes articles where the focus was only on architecture quality in general and a specific quality characteristic is not mentioned. The second most investigated quality characteristic was performance. Furthermore, we found only one technique that supported the security smells of the software architecture (see Fig. 9). Other quality characteristics, such as usability, reliability, portability, etc. are not the focus of any detection technique or tool, urging the need to broaden the focus to detect architectural smells that impact a wider range of quality characteristics.

Lack of Inclusiveness of Architecture Styles — We observed that some architecture styles undergo more examination, for instance, service-oriented architecture was studied the most—19 research articles (see Fig. 10). Note that this figure excludes the articles that did not mention a specific architecture style. It can also be seen that MVC and layered architectures received reasonable investigation, but some architecture styles, such as component and cloud, have limited detection support. It is known that smells can reside in software architectures regardless of the architecture style, meaning that all styles of architecture should receive a fair analysis.


Download : Download high-res image (62KB)
Download : Download full-size image
Fig. 9. Frequency of the quality characteristics investigated by the detection techniques.


Download : Download high-res image (99KB)
Download : Download full-size image
Fig. 10. Frequency of the architecture styles investigated by the detection techniques.

Insufficiency of Empirical Validations — In terms of validation, we observed an even blend of empirical and case studies to evaluate the effectiveness of the techniques. The detection tools (except Arcan) have not been empirically validated—the majority of the tools are evaluated through case studies or not validated (also shown in Fig. 7). We found that the validations were performed using a limited number of software projects, which also corresponds to the limitation reported by the primary papers (Le et al., 2018, Mo et al., 2015). This suggests a need to have more empirical validations.

While the use of commercial and open source systems was also evenly distributed across the validations, software projects included in the validations are biased toward a small set of programming languages, such as Java, C#, and C++, which reduces the practical applicability of the techniques and tools in projects that employ other programming languages. Fig. 11 illustrates the languages used to validate the techniques. The primary papers also urged the need to include different architectures, domains, and languages to improve generalization (Le et al., 2018, Mo et al., 2015).


Download : Download high-res image (72KB)
Download : Download full-size image
Fig. 11. Development languages of the projects used for validations.

Limited Language Support — Following on from this, in addition to have limited languages in the projects involved in the validations of the techniques and tools, the tools themselves support only a limited set of languages. Table 13 shows the languages supported by each tool. Java is supported by the most tools, while only a few tools support .Net and PHP. In recent years, Python has become a popular development language among the software community, but we see only a few tools that support Python projects. It is important to note that language scalability can impact the usefulness and adoption of the tools, particularly as languages evolve, the detection tools will need to be updated to accommodate these changes.


Table 14. Technique and tool detection as per architectural smell (undetected are in bold). The number represents the frequency of research articles.

Smell category	Architectural smell	Rules-based	Graph-based	Design structure matrix	Model-driven	Code smells analysis	Reverse engg. & history	Search-based	Visualization	Others	Tool	Architectural smell	Rules-based	Graph-based	Design structure matrix	Model-driven	Code smells analysis	Reverse engg. & history	Search-based	Visualization	Others	Tool
Service	Low Cohesive Operations	(1)	—	—	—	—	—	—	—	—	—	Multi-service	(5)	—	—	(1)	—	—	—	—	(1)	✓
Tiny/Nano/Fine-grained Service	(7)	—	—	(1)	—	—	(5)	—	(1)	✓	Chatty Service	(6)	—	—	—	—	—	(5)	—	(1)	✓
Knot Service	(3)	—	—	—	—	—	—	—	(1)	✓	Bottleneck Service	(4)	—	—	—	—	—	—	—	(1)	✓
Service Chain	(3)	—	—	—	—	—	—	—	(1)	✓	Sand Pile	(3)	—	—	—	—	—	—	—	—	✓
Nobody Home	(3)	—	—	—	—	—	—	—	(1)	✓	Duplicated Service	(3)	—	—	—	—	—	—	—	—	✓
Data Service	(2)	—	—	—	—	—	(2)	—	—	✓	Ambiguous Name	(2)	—	—	—	—	—	—	—	—	—
Maybe it is not RPC	(2)	—	—	—	—	—	(3)	—	—	—	Redundant PortTypes	(2)	—	—	—	—	—	(3)	—	—	—
Bloated Service	(1)	—	—	—	—	—	—	—	(1)	✓	Forgetting Hypermedia	(2)	—	—	—	—	—	—	—	—	—
Crudy Interface	(3)	—	—	—	—	—	(3)	—	—	—	Ignoring MIME Types	(2)	—	—	—	—	—	—	—	—	—
Crudy URI	(1)	—	—	—	—	—	—	—	—	—	Ignoring Caching	(1)	—	—	—	—	—	—	—	—	—
Pipe and Filter	—	—	—	(1)	—	—	—	—	—	—	Golden Hammer	—	—	—	—	—	—	—	—	—	—
API Versioning	—	—	—	—	—	—	—	—	—	—	Silver Bullet	—	—	—	—	—	—	—	—	—	—
ESB Usage	—	—	—	—	—	—	—	—	—	—	Hard-coded Endpoints	—	—	—	—	—	—	—	—	—	—
Micro-service Greedy	—	—	—	—	—	—	—	—	—	—	Not Having an API Gateway	—	—	—	—	—	—	—	—	—	—
Shared Libraries	—	—	—	—	—	—	—	—	—	—	Shared Persistency	—	—	—	—	—	—	—	—	—	—
Too Many Standards	—	—	—	—	—	—	—	—	—	—	Wrong Cuts	—	—	—	—	—	—	—	—	—	—
Overstandardized SOA	—	—	—	—	—	—	—	—	—	—	Nothing New	—	—	—	—	—	—	—	—	—	—
Big Bang	—	—	—	—	—	—	—	—	—	—	Incomplete Service	—	—	—	—	—	—	—	—	—	—
No Legacy	—	—	—	—	—	—	—	—	—	—	Shiny Nickel	—	—	—	—	—	—	—	—	—	—
Performance	Excessive Dynamic Allocation	—	—	—	(3)	—	—	—	—	—	—	Ramp	—	—	—	(4)	—	—	—	—	—	—
Tower of Babel	—	—	—	(1)	—	—	—	—	(1)	—	More is Less	—	—	—	(1)	—	—	—	—	—	—
One-lane Bridge	—	—	—	(5)	—	—	—	(1)	—	—	Unbalanced Processing	—	—	—	(4)	—	—	—	(1)	—	—
Traffic Jam	—	—	—	(5)	—	—	—	(1)	—	—	Circuitous Treasure Hunt	—	—	—	(3)	(1)	—	—	(1)	(1)	—
Empty Semi-trucks	—	—	—	(2)	(1)	—	—	(1)	—	—	Extensive Processing	—	—	—	(1)	—	—	—	—	(1)	—
Dependency	Unauthorized Dependency	—	(2)	—	—	—	—	—	—	—	—	Unstable Dependency	—	—	—	—	—	(1)	—	—	(2)	✓
Hub-like Dependency	—	(3)	—	—	—	(1)	—	—	(2)	✓	Cyclic Dependency	(1)	(3)	(1)	—	(4)	(1)	—	(1)	(3)	✓
Implicit Cross-module Dependency	—	—	(3)	—	—	—	—	—	(1)	✓	Cycles between Namespaces	—	(1)	—	—	—	—	—	—	—	—
Package	Package Cycle	—	—	(6)	(1)	—	—	—	—	—	✓	Clique	—	—	(3)	—	—	—	—	—	—	✓
Too Small Package	—	—	—	—	—	—	—	—	—	—	Unused Package	—	—	—	—	—	—	—	—	—	—
Unclear Package Name	—	—	—	—	—	—	—	—	—	—	Package Instability	—	—	—	—	—	—	—	—	—	—
Missing Package Abstractness	—	—	—	—	—	—	—	—	—	—	Unbalanced Package Hierarchy	—	—	—	—	—	—	—	—	—	—
MVC	Sloppy Delegation	—	(1)	—	—	—	—	—	—	(1)	✓	Co-change Coupling	—	(1)	—	—	—	—	—	—	(1)	✓
Separation of Concerns	—	(2)	—	—	—	—	—	—	—	✓	Concern Overload	—	(1)	—	—	(6)	—	—	—	(3)	✓
Scattered Functionality	—	(1)	—	—	(4)	—	—	—	(3)	✓	Feature Concentration	—	(1)	—	—	—	—	—	—	—	—
Link Overload	—	(1)	—	—	—	—	—	—	(1)	✓	Connector Envy	—	—	—	—	(6)	—	—	—	(2)	—
Fat Repository	—	—	—	—	—	—	—	—	—	—	Promiscuous Controller	—	—	—	—	—	—	—	—	—	—
Brain Controller	—	—	—	—	—	—	—	—	—	—	Meddling Service	—	—	—	—	—	—	—	—	—	—
Brain Repository	—	—	—	—	—	—	—	—	—	—	Laborious Repository Method	—	—	—	—	—	—	—	—	—	—
Component	Anchor Submission	—	—	(1)	—	—	—	—	—	—	—	Anchor Dominant	—	—	(1)	—	—	—	—	—	—	—
Non-transfer Communication	—	—	—	—	—	(1)	—	—	—	—	Unauthorized Call	—	—	—	—	—	(1)	—	—	—	—
Undercover Transfer Object	—	—	—	—	—	(1)	—	—	—	—	Subtype Knowledge	—	(1)	—	—	—	—	—	✓	—	—
Abstraction without Decoupling	—	(1)	—	—	—	—	—	—	—	✓	Blob or God Object/Component	(3)	—	—	(4)	(1)	—	(3)	(1)	(1)	—
Other smells	Unhealthy Inheritance	—	—	(5)	(1)	—	—	—	—	—	✓	Improper Inheritance	—	—	(2)	—	—	—	—	—	—	—
Unstable Interface	—	—	(7)	—	—	—	—	—	—	✓	Unused Interface	—	(1)	—	—	(4)	—	—	—	(1)	✓
Ambiguous Interface	—	—	—	—	(6)	—	—	—	(1)	✓	Interface Violation	—	—	—	—	—	(1)	—	—	—	—
Degenerated Inheritance	—	(1)	—	—	—	—	—	—	—	—	Modularity Violations	(1)	—	(5)	—	—	—	—	—	(1)	✓
Misplaced Component	—	—	—	—	—	—	—	(1)	—	—	Security Flaws	—	(1)	—	—	—	—	—	—	—	—
Incomplete Abstraction	—	—	—	—	—	—	—	—	—	—	Missing Abstraction	—	—	—	—	—	—	—	—	—	—
Missing Encapsulation	—	—	—	—	—	—	—	—	—	—	Leaky Encapsulation	—	—	—	—	—	—	—	—	—	—
Speculative Hierarchy	—	—	—	—	—	—	—	—	—	—	Unnecessary Hierarchy	—	—	—	—	—	—	—	—	—	—
Too Many Subsystems	—	—	—	—	—	—	—	—	—	—	Overgeneralized Subsystems	—	—	—	—	—	—	—	—	—	—
No Subsystems	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—	—
Limited Involvement of Industry — We also noticed a scarcity of empirical studies that involve architects and developers from the software industry. Only a small percentage of studies performed a qualitative analysis of feedback obtained from developers using interviews and questionnaires (Martini et al., 2018a, de Toledo et al., 2019). To encourage industry adoption of the detection techniques and tools, more studies should look to include software practitioners in the validation.

Additionally, in RQ1, we found no academic and industrial collaborations in authorship of the detection technique and tool papers. However, some of the studies were validated using large scale industrial systems. Still, there is room to increase collaboration with industry in this research area. The limitations of some of the primary papers indicated that the lack of industry collaboration impact construct validity. These papers expressed concerns that developers might disagree with the selected examples of the architectural smells as the best candidates for architectural problems because of their understanding and expertise (Ouni et al., 2015a, Ouni et al., 2015b). Further validation with industry can alleviate these threats.

Other Limitations — We also found some limitations (reported in the primary papers) that were not identified by our collective analysis of the techniques and tools. Some papers reported potential threats to conclusion validity based on the statistical analysis. For instance, Le et al. (2018) noted that most of their results had statistical significance, but that some exceptional cases required further investigation. From an internal validity point of view, the most common threat reported in the primary paper was related to the appropriate selection of evaluation measures (e.g., Ouni et al., 2015b, Mo et al., 2015).

6. Discussion
In this section, first, we discuss the implications of the findings from the analysis of the detection techniques and tools. Later, we reflect on the significance of the open challenges (discussed in Section 5.4) and highlight possible directions for future research.

6.1. Implications of findings
Focus on dependency smells — We observed that detecting dependency smells is common among the majority of the techniques. One potential reason for this could be that it is relatively easy to depict dependencies using graph structures or visualizations (Baum et al., 2018). In addition, usually, dependency smells are connected with coupling issues in the architecture, which is related to maintainability. Since we have seen that, in most of the primary papers, researchers are interested in maintainability of software systems (see Fig. 9), this could also be a reason for detecting dependency smells. Finally, in terms of practical relevance, the software industry is mostly interested in reducing the maintenance cost (Banker et al., 1993). We know that dependency smells hinder the maintainability characteristic of a system (Arcelli Fontana et al., 2019), therefore, it is more relevant for the software industry to detect them. This argument is also supported by the smell coverage provided by detection tools. Most of the detection tools can detect common dependency smells. This could be because of industry demand, which would lead to higher tool adoption.

Many search-based techniques for service-oriented smells — We also noticed that most of the service-oriented smells are detected through search-based techniques. This could be driven by the scale and diversity of the data, as search-based techniques are suitable for large and diverse datasets (Ouni et al., 2015b). For example, search-based techniques use the architectural smells data (metrics and their thresholds) in many software systems to optimize the detection (Ouni et al., 2015b, Ouni et al., 2015a). It is also noteworthy that large-scale web services were used in the evaluations of the search-based techniques, further illustrating their ability to work with large-scale and diverse data.

Focus on maintainability quality — In terms of quality characteristics, maintainability is the focus in the majority of the detection techniques. This could be because of the innate relationship between smells and the maintainability of a software (Bavota et al., 2015). Another reason could be the desire to reduce the development costs associated with software maintenance. However, other software qualities like performance and security can be impacted by architectural smells, and these qualities have received much less attention in this research area.

Diversity in the detection techniques — One important finding is the lack of diversity in the detection techniques. Comparably, code smells analysis techniques are more diverse in terms of the investigated architecture styles (MVC, layered, and cloud). Additionally, they are also more diverse in the project domains (SPL, web, and middleware). These diversities in code smells analysis techniques make them more applicable to a wider range of projects. We observed that some techniques (e.g., DSM, search-based, and visualization) employed commercial systems and used multiple languages in their evaluations, which make them more scalable and generalizable. However, many architectural smells detection tools and methods (e.g., rules-based, graph-based, and code smells analysis) have less evidence of scalability and generalizability in the literature.

6.2. Open challenges and future research directions
Many smells still need detection — From the limitations, we found several architectural smells that are not detected by existing techniques or tools. The coverage of architectural smells in tools is even more limited, which can be a road-blocker for them to be employed in software industry. The undetected smells vary in terms of their granularity level. For instance, in object-oriented architecture, the undetectable smells exist at the class-level, package-level, interface-level, etc. The smells at these different granularity levels are inter-related. For example, Package Instability (a package-level smell) can raise coupling issues that affect communication between classes (a class-level smell). This suggests the need for equal attention regardless of their level because a smell at one level can affect (i.e., introducing another smell) the design structure of the other level.

We have seen a variety of undetected architectural smells, but how they should be prioritized depends on various aspects, such as impact on quality characteristics, complexity of refactoring, etc. Software organizations may have different quality goals; for instance, some focus on maintainability and some on security. Therefore, they prioritize the smells according to their quality goals. In the literature, the papers that describe the currently undetected architectural smells have reflected on the software quality problems which can appear if the smells are left undetected. For instance, Taibi and Lenarduzzi (2018) explained that the “Hard-coded Endpoints” smell can introduce issues in a micro-services environment. If micro-services are connected with Hard-coded Endpoints, it is problematic to change their locations, resulting in slowing down the maintainability process of software applications. As another instance, Package Instability can also impact maintainability because of high dependency between packages—the changes in one package force changes in another package. Similarly, in many papers, researchers have identified several quality characteristics (e.g., modularity, evolvability, modifiability, etc.) that could be impacted by the architectural smells (de Andrade et al., 2014, Aniche et al., 2018, Taibi and Lenarduzzi, 2018, Král and Žemlicka, 2009, Smith and Williams, 2000, Garcia et al., 2009, Bogner et al., 2019, Lippert and Roock, 2006). Therefore, the priority of detecting a particular smell lies in its severity and degree of impact on different software quality characteristics, and how important those quality characteristics are to software organizations. Another important aspect to prioritize the smells is based on the level of complexity involved in their refactorings. The complexity of the required refactoring is considered because if refactoring involves cumbersome tasks, more resources would be required to remove the smell. Future research should consider these impacts when prioritizing the smells to study for new detection methods and tools.

Conduct experiments to quantify undetected smells — We found that it was a challenge to adequately quantify and measure architectural smells. Some studies employed the metrics for code smells to determine their relations with architectural technical debt (Fontana et al., 2015, Lenhard et al., 2019). A major drawback of entirely relying on code metrics is losing the semantics of architectural smells. To avoid losing the semantic information of architecture, other methods, such as statistical analysis of software data (e.g., size, complexity, etc.) (Ferreira et al., 2012) and ROC (Receiver Operating Characteristic) curves (Shatnawi et al., 2010) can be adopted for identifying thresholds for architecture data. Therefore, we believe future studies should focus on identifying appropriate thresholds and metrics that can be used to quantify architectural smells better.

Measure the impact on a broader set of quality characteristics — Maintainability was the most commonly studied quality characteristic when considering architecture smell detection. It can give insight into the effort and resources required to fix the problems resulting from the smells. The second most investigated quality characteristic was performance. However, the detection techniques that consider other quality characteristics (e.g., security) are limited. We believe that it is important to understand the impact of architectural smells on other quality characteristics, since all are important for producing high quality software. For example, even if software is maintainable, if it has large security problems, it would not be considered high-quality software.

In addition, it is paramount to individually investigate the sub-characteristics of a quality characteristic. For instance, in maintainability, we observed that modularity and modifiability were focused during detection but sub-characteristics like testability or reusability were not given any attention. Future work could investigate ways to measure these quality sub-characteristics in the detection methods. This would require examining the relationship between different smells and sub-characteristics (e.g., reusability). The relationship could be established by performing empirical analysis of the impact of architectural smells on a particular quality characteristic. Such analysis would allow the tool developers to focus on a particular set of architectural smells that impact a specific type of quality characteristic.

Investigate the quality of other popular architecture styles — We observed that some architecture styles undergo more examination, for instance, service-oriented architecture. It is likely due to the popularity of using service-oriented architecture in recent years. However, architecture styles, such as component and cloud, are barely explored. The current spread of cloud technology and the shift of many technologies to the cloud environment suggest the significance of investigating the quality of cloud architecture. Future work could focus on understudied architecture styles to improve detection techniques across a broader range of architectures.

Enhance the diversity in empirical validations — Validation is the key to show the applicability of an approach, and the data is a vital ingredient in the validation process. In the existing approaches and tools, we noticed the lack of diversity in the empirical evaluations, for instance, less validations with a broader set of programming languages. This can bring many challenges because of the different styles and practices offered by the development languages, thus, not all detection techniques and tools will be able to be easily applied to additional programming languages. However, to ensure high-quality architecture across a wide range of software systems, future research must investigate ways to expand the detection techniques and tools (and their evaluation) across a wider range of programming languages. We suggest to include those development languages that are also common in software development. For instance, although .Net and PHP are popular development languages, we noticed that only a few tools support .Net and PHP projects. Similarly, the Python language is also supported by only a handful of tools. Future work can focus on improving the existing tools with an enhanced set of supported languages.

Need more scalable techniques and tools — In addition to supporting a wider range of programming languages, detection techniques and tools need to be empirically evaluated using realistic data to ensure scalability. For instance, in our results, we noticed that tools (except one) were either validated with case studies (33%) or not evaluated at all (42%). It is interesting to see that some tools (DV8, sonarQube, and CAST) can work with many programming languages, but there is scarcity of empirical evidence in the literature regarding their effectiveness. This shows the need to improve the scalability of the detection methods with more empirical evaluations and with industrial projects. Future studies should look to use industrial-scale commercial projects in the evaluation process of detection techniques and tools.

Involve software developers in evaluations — In the evaluation of detection techniques and tools, we found only a few studies that performed a qualitative analysis of feedback obtained from developers. We argue that there is no replacement of software developers in the process of evaluating the detection techniques. The input of developers in the evaluation processes of architectural smells would enhance the applicability in real-world scenarios.

Need a shift to academic–industrial collaborations — Related to the need to evaluate techniques and tools with industrial-scale data and a need for greater involvement of software practitioners in evaluations, we noticed that all the detection techniques and tools originated from academics in terms of authorship. Increasing academic and industrial collaboration in the creation of techniques and tools can help to minimize the gap between research and practice and encourage better adoption of the proposed techniques and tools by software practitioners.

7. Threats to validity
In this section, we present threats to validity based on the guidelines provided by Petersen et al. (2015).

Descriptive Validity — Descriptive validity refers to the accurate and objective description of observations. To reduce this threat, we recorded the data (article ID, article title, publication year, publication venue, and analysis factors) in a tabular representation. Article ID, article title, publication year, source (digital libraries), and publication venue were automatically recorded from the searched databases, whereas analysis factors were extracted by objectively analyzing the selected articles. In addition, the second and third authors of this paper also independently performed the data extraction process on a subset (just over 15%) of the primary papers. Any disagreements were resolved through iterative discussions between all authors. After these discussions and agreements were reached on how data should be extracted and categorized, the data was extracted from the remaining 85% of the primary papers. We also distinguished the technique and tool articles to support the recording of the data and extraction process. All of the detailed data and classifications for each paper are provided in our supplementary material1.

Theoretical Validity — Theoretical validity refers to our ability to capture intended data, keeping into consideration the biases and selection of subjects. The theoretical validity threats in our systematic mapping study were mainly originating from the incompleteness of the searched literature domain, inaccuracy in the gathered data, and inaccuracy in the data synthesis process.

The completeness of the literature domain depends on the electronic databases, search string, and inclusion and exclusion criteria. Due to a high number of electronic databases, it is not feasible to search through every available electronic database. Therefore, in this mapping study, we search seven well-known databases (Scopus, Web of Science, INSPEC, ACM Digital Library, IEEEXplore, SpringerLink, and DBLP) of software engineering and computer science literature.

Another limitation comes from the search string (used to retrieve the related articles) because relevant publications could be omitted by it. We confined our search string to the keywords that are the most relevant to architectural smells detection. The number of keywords with the use of appropriate logical operators in the search string could increase the number of retrieved articles, but then this might also result in a substantial number of irrelevant publications. To reduce the threat that our search string was missing relevant articles, we validated our search string by performing a focused search analysis of the papers published in International Conference on Software Engineering (ICSE) from 2016 to 2019. Using our search string and snowballing, we were able to find all articles from this small validation set. While we cannot guarantee that we identified every relevant paper, this gives us confidence that our dataset includes many articles of interest.


Table A.1. Description of architectural smells.

Architectural smell	Description
Abstraction without decoupling	This smell occurs where a client class uses a service represented as an abstract type, but also a concrete implementation of this service, represented as a non-abstract subtype of the abstract type (Azadi et al., 2019).
Ambiguous interface	This smell occurs when an abstraction (interface) is over-engineered by adding methods intended to accommodate potential future requirements but never used (de Andrade et al., 2014).
Ambiguous name	This smell occurs when developers use ambiguous or meaningless names for interfaces (Bogner et al., 2019).
Anchor submission	This smell occurs when each file structurally depends on the anchor file, but each member historically dominates the anchor (Xiao et al., 2016).
Anchor dominant	This smell occurs when each file structurally depends on the anchor file, and the anchor file historically dominates each member file (Xiao et al., 2016).
API versioning	This smell occurs when APIs are not semantically versioned (Taibi and Lenarduzzi, 2018).
Architecture violation	This smell occurs when an intended architecture is different from its actual implementation (Azadi et al., 2019).
Big bang	This smell occurs when an entire system is built at once (Král and Žemlicka, 2009).
Bottleneck service	This smell occurs when a service is highly used (high incoming and outgoing coupling) by other services (Bogner et al., 2019).
Bloated service	This smell occurs when a service becomes a blob with one large interface and/or lots of parameters (Palma et al., 2018).
Blob or God object/component	This smell occurs when a component implements an excessive number of concerns (Azadi et al., 2019).
Brain controller	This smell occurs when controllers have too much flow control (Aniche et al., 2018).
Brain repository	This smell occurs when a complex logic is developed in the repository (Aniche et al., 2018).
Circuitous treasure hunt	This smell occurs when an object looks in several places to find the information that it needs (Cortellessa et al., 2014).
Chatty service	This smell occurs when a service has a high number of connections with other services (Bogner et al., 2019).
Clique	This smell occurs when a group of files are tightly coupled by dependency cycles (Snipes et al., 2018).
Co-change coupling	This smell occurs when changes to a component require changes in another component (Le et al., 2018).
Concern overload	This smell occurs when a component implements an excessive number of concerns (Azadi et al., 2019).
Connector envy	This smell occurs when components cover too much functionality with respect to connections (de Andrade et al., 2014).
Crudy interface	This smell occurs when services show an RPC-like behavior by declaring CRUD-type operations (Bogner et al., 2019).
Crudy URI	This smell occurs when crudy verbs (e.g., create, read, update, or delete) are used in the APIs (Palma et al., 2018).
Cyclic dependency	This smell occurs when two or more architecture components depend on each other directly or indirectly (Azadi et al., 2019).
Cyclic hierarchy	This smell occurs when a direct referencing of a subtype from a supertype is created (Azadi et al., 2019).
Cycles between namespaces	This smell occurs when two or more namespaces depend on each other directly or indirectly (Azadi et al., 2019).
Data service	This smell occurs when a service has only accessor operations (getters and setters) (Bogner et al., 2019).
Degenerated inheritance	This smell occurs when there are multiple inheritance paths connecting subtypes with their supertypes or a concrete class with their abstractions (abstract classes or interfaces) (Azadi et al., 2019).
Dense structure	This smell occurs when an abstraction or a concrete class has (outgoing and ingoing) dependencies with a large number of other abstractions or concrete classes (Azadi et al., 2019).
Duplicated service	This smell occurs when a set of highly similar services exists (Bogner et al., 2019).
Empty semi-trucks	This smell occurs when an excessive number of requests is required to perform a task (Cortellessa et al., 2014).
ESB usage	This smell occurs when micro-services communicate via an ESB (enterprise service bus)—it adds complexities for registering and de-registering services on it (Taibi and Lenarduzzi, 2018).
Excessive dynamic allocation	This smell occurs when an application unnecessarily creates and destroys large numbers of objects during its execution (Cortellessa et al., 2014).
Extensive processing	This smell occurs when extensive processing impedes overall response time (Cortellessa et al., 2014).
Fat repository	This smell occurs when a repository is managing too many entities (Aniche et al., 2018).
Feature concentration	This smell occurs when different functionalities are implemented in a single design construct (de Andrade et al., 2014).
Forgetting hypermedia	This smell occurs when there is a lack of hypermedia (i.e., not linking resources) (Palma et al., 2018).
Golden hammer	This smell occurs when familiar technologies are used as solutions to every problem (Taibi and Lenarduzzi, 2018).
Hard-coded endpoints	This smell occurs when micro-services are connected with hard-coded endpoints, making the change in their locations problematic (Taibi and Lenarduzzi, 2018).
Hub-like dependency	This smell occurs when an abstraction or a concrete class has (outgoing and ingoing) dependencies with a large number of other abstractions or concrete classes (Azadi et al., 2019).
Ignoring MIME types	This smell occurs when resources do not support multiple formats (e.g., XML, JSON, etc.) (Palma et al., 2018).
Ignoring Caching	This smell occurs when developers avoid to implement the caching capability in the web applications (Palma et al., 2014b).
Implicit cross-module dependency	This smell occurs when two or more architecture components depend on each other directly or indirectly (Azadi et al., 2019).
Improper inheritance	This smell occurs when a parent class depends on its derived class or where a client depends on both the parent and derived classes (Cai and Kazman, 2016).
Incomplete service	This smell occurs when the client is given the responsibility to complete the service (Taibi and Lenarduzzi, 2018).
Incomplete abstraction	This smell occurs when an abstraction does not support interrelated methods completely (Suryanarayana et al., 2015).
Interface violation	This smell occurs when components in an architecture communicate without their interfaces (von Detten and Becker, 2011).
Knot service	This smell occurs when a set of very low cohesive services are tightly coupled (Bogner et al., 2019).
Laborious repository method	This smell occurs when a repository method has multiple database actions (Aniche et al., 2018).
Leaky encapsulation	This smell occurs when a class leaks implementation details because of its public implementation (Suryanarayana et al., 2015).
Link overload	This smell occurs when an abstraction or a concrete class has (outgoing and ingoing) dependencies with a large number of other abstractions or concrete classes (Azadi et al., 2019).
Low cohesive operations	This smell occurs when developers place very low cohesive operations (not semantically related) in a single portType (Taibi and Lenarduzzi, 2018).
Maybe it is not RPC	This smell occurs when a service mainly provides CRUD-type (create, read, update, and delete) operations (Bogner et al., 2019).
Meddling service	This smell occurs when services directly query the database (Aniche et al., 2018).
Micro-service greedy	This smell generates an explosion of the number of micro-services composing a system (Taibi and Lenarduzzi, 2018).
Missing abstraction	This smell occurs when clumps of data are used instead of creating classes or interfaces (Suryanarayana et al., 2015).
Missing encapsulation	This smell occurs when classes are not encapsulated (Suryanarayana et al., 2015).
Misplaced component	This smell occurs when an architecture component is placed somewhere else other than the one it was intended for, resulting in undesired dependencies (Eliasson et al., 2015).
More is less	This smell occurs when a system spends more time thrashing than accomplishing real work because there are too many processes relative to available resources (Cortellessa et al., 2014).
Modularity violation	This smell occurs when an architecture violates the modularity principles (Xiao et al., 2016).
Multi-service	This smell occurs when a service implements a multitude of methods related to different abstractions (Bogner et al., 2019).
Multipath hierarchy	This smell occurs when there are multiple inheritance paths connecting subtypes with their supertypes or a concrete class with their abstractions (Azadi et al., 2019).
Not having an API gateway	This smell occurs when service-consumers communicate directly with each micro-service (Taibi and Lenarduzzi, 2018).
Nobody home	This smell occurs when a service is defined but never used (Bogner et al., 2019).
Non-transfer communication	This smell occurs when communication between components is not accomplished using transfer objects (Xiao et al., 2016).
Nothing new	This smell occurs when inappropriate practices in object-oriented practices are attempted to apply in service-oriented (Král and Žemlicka, 2009).
No legacy	This smell occurs when a service provides limited standardized support of data types and interactions (Taibi and Lenarduzzi, 2018).
No subsystems	This smell occurs when a system has no subsystems (Lippert and Roock, 2006).
One-lane bridge	This smell occurs when only one or a few processes can be executed concurrently (Cortellessa et al., 2014).
Overgeneralized subsystems	This smell occurs when the generalization of the subsystems is overdone (Lippert and Roock, 2006).
Overstandardized SOA	This smell occurs when all aspects and dimensions of SOA are overstandardized (Král and Žemlicka, 2009).
Package cycle	This smell occurs when two or more packages depend on each other directly or indirectly (Azadi et al., 2019).
Package instability	This smell occurs when a package has many dependencies that frequently changes with other packages (Mo et al., 2015).
Missing package abstractness	This smell occurs when a package has unnecessary or missing abstraction (Suryanarayana et al., 2015).
Pipe and filter	This smell occurs when the slowest filter in the architecture results in low throughput (Cortellessa et al., 2014).
Promiscuous controller	This smell occurs when controllers are offering too many actions (Aniche et al., 2018).
Redundant portTypes	This smell occurs when multiple portTypes are duplicated with a similar set of operations (Bogner et al., 2019).
Sand pile	This smell occurs when a service is composed of multiple smaller services sharing common data (Bogner et al., 2019).
Scattered functionality	This smell occurs when a high-level concern is realized across multiple components (de Andrade et al., 2014).
Security flaws	This smell occurs when critical information is disclosed or tampered, when confidentiality and integrity are not ensured in the architecture (Vanciu and Abi-Antoun, 2013).
Separation of concerns	This smell occurs when the responsibilities of the components of an architecture are not appropriately separated (Hayashi et al., 2018).
Service Chain	This smell occurs when consecutive service invocations happen (Bogner et al., 2019).
Shared libraries	This smell occurs when shared libraries between different micro-services are used (Taibi and Lenarduzzi, 2018).
Shared persistency	This smell occurs when different micro-services access the same relational database, reducing the service independence (Taibi and Lenarduzzi, 2018).
Shiny nickel	This smell occurs due to inflexibility to incorporate new technologies within service architecture (Taibi and Lenarduzzi, 2018).
Silver bullet	This smell occurs when unknown technologies are implemented where they are not required (Taibi and Lenarduzzi, 2018).
Sloppy delegation	This smell occurs when a component delegates the functionality to other components, which should be performed internally by that component (Le et al., 2018).
Speculative hierarchy	This smell occurs when a hierarchy is created speculatively (Suryanarayana et al., 2015).
Subtype knowledge	This smell occurs when a direct referencing of a subtype from a supertype is created (Azadi et al., 2019).
Tiny/nano/fine-grained service	This smell occurs when a service has only a few operations (Bogner et al., 2019).
Ramp	This smell occurs when processing time increases as the system is used (Cortellessa et al., 2014).
Too many standards	This smell occurs when different development languages, protocols, frameworks are used in micro-services (Taibi and Lenarduzzi, 2018).
Too small package	This smell occurs when a package has only one or two classes (Lippert and Roock, 2006).
Too many subsystems	This smell occurs when a system consists of many subsystems (Lippert and Roock, 2006).
Tower of babel	This smell occurs when processes excessively convert, parse, and translate internal data into a common exchange format (Cortellessa et al., 2014).
Traffic jam	This smell occurs when one problem causes a backlog of jobs (Cortellessa et al., 2014).
Unbalanced processing	This smell occurs when processing cannot make use of available processors (Cortellessa et al., 2014).
Unauthorized dependency	This smell occurs when an unauthorized dependency exists between the components (Hayashi et al., 2018).
Unstable dependency	This smell occurs when a component depends on other components that are less stable than itself (Azadi et al., 2019).
Unused package	This smell occurs when a package is no longer in use (Lippert and Roock, 2006).
Unclear package name	This smell occurs when developers use ambiguous or meaningless names for packages (Lippert and Roock, 2006).
Unbalanced package hierarchy	This smell occurs when the package structure is unbalanced (Lippert and Roock, 2006).
Unauthorized call	This smell occurs when a calling component is not connected to the called component (Xiao et al., 2016).
Undercover transfer object	This smell occurs when transfer objects serve as data containers for the communication between components (von Detten and Becker, 2011).
Unhealthy inheritance hierarchy	This smell occurs when a direct referencing of a subtype from a supertype is created (Azadi et al., 2019).
Unstable interface	This smell occurs when an interface depends on other interfaces that are less stable than itself (Azadi et al., 2019).
Unused interface	This smell occurs when an abstraction (interface) is over-engineered by adding methods intended to accommodate potential future requirements but never used (de Andrade et al., 2014).
Unutilized abstraction	This smell occurs when a direct referencing of a concrete class is created, instead of referencing one of its supertypes, from an abstract class (Azadi et al., 2019).
Unnecessary hierarchy	This smell occurs when the inheritance hierarchy is unnecessarily created (Suryanarayana et al., 2015).
Wrong cuts	This smell occurs when micro-services are split based on technical layers instead of business capabilities (Taibi and Lenarduzzi, 2018).
Some limitations could also be imposed by our inclusion and exclusion criteria because ill-designed or incomplete inclusion and exclusion criteria could result in an incorrect selection of articles. To mitigate this threat, we iteratively modified the exclusion criteria during the selection process to ensure that no relevant articles were discarded and irrelevant articles were not included.

The analysis of the selected articles was performed in terms of various factors in the analysis framework. We designed the analysis framework to cover the main aspects of the detection techniques and tools to answer our research questions. We do not claim this analysis framework to be complete. Additional factors could be introduced to improve the comprehensiveness of the analysis process. However, the data we extracted has provided answers to our research questions and helped us identify many interesting findings when considering the research literature as a whole.

Finally, a threat is connected to the biases of the author, who was executing the extraction and classification process. This threat was mitigated by regular discussions about the data extraction and classification performed by the author with other authors of this mapping study.

Interpretive validity — This refers to the conclusions drawn based on the given data. A researcher’s biases could be a threat in interpreting the data. For instance, a researcher with experience in conducting case studies might misinterpret the results from other types of validations. This threat was mitigated by multiple rounds of discussions between authors on the conclusions drawn from our mapping study.

Repeatability — This refers to providing sufficient information about the research process to ensure the experiments could be repeated. We strived to ensure repeatability by providing detailed reporting of our mapping process and providing all of the detailed classifications for each article as supplementary material. We also used existing guidelines for conducting systemic mapping studies in software engineering to strengthen the repeatability.

8. Conclusion
In this paper, we performed a systematic mapping study of architectural smells detection techniques and tools. From the analysis of the literature, we highlighted some key findings. We observed that performance-related, dependency-originated, and service-oriented architectural smells are widely detected. We also observed that there are still many smells related to packages and services that are not detected by existing techniques and tools. Moreover, some of the architectural smells that are related to quality principles (such as abstraction, encapsulation, and hierarchy) lack detection techniques and tools. We also noticed the scarcity of empirical evaluations of detection techniques and tools, especially with large scale industrial projects. The selection of software projects for evaluation is also leaned toward programming languages, such as Java, C, C++, and C#, suggesting the need to include other development languages as well.

Based on our findings, we suggested some future research directions. We emphasize having a more in-depth analysis of architectural smells at different granularity levels, such as investigating the Package Instability and its impact on the communication between classes. Similarly, we suggest looking at the abstraction properties of the interfaces to understand the impact on the overall architecture of the software. Another promising future research direction is the identification of software metrics and their thresholds for the currently undetected architectural smells. Furthermore, accurate mapping of metrics to quality characteristics can open many ways in which quality characteristics can be measured and evaluated. We also suggest the inclusion of architecture styles that are currently adopted in industrial projects, such as cloud, micro-services, etc. Another future work could be conducting empirical validations with real-world projects covering a broader set of projects belonging to different domains and development languages. Lastly, for all the potential research directions mentioned in this study, we recommend focusing on the applicability and usefulness for the viewpoint of the software development industry.