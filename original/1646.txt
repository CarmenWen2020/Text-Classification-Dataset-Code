Abstract
Developer social networks (DSNs) are a tool for the analysis of community structures and collaborations between developers in software projects and software ecosystems. Within this paper, we present the results of a systematic mapping study on the use of DSNs in software engineering research. We identified 255 primary studies on DSNs. We mapped the primary studies to research directions, collected information about the data sources and the size of the studies, and conducted a bibliometric assessment. We found that nearly half of the research investigates the structure of developer communities. Other frequent topics are prediction systems build using DSNs, collaboration behavior between developers, and the roles of developers. Moreover, we determined that many publications use a small sample size regarding the number of projects, which could be problematic for the external validity of the research. Our study uncovered several open issues in the state of the art, e.g., studying inter-company collaborations, using multiple information sources for DSN research, as well as general lack of reporting guidelines or replication studies.

Previous
Next 
Keywords
Developer social networks

Mapping study

Literature survey

1. Introduction
Social structures within software development projects are a topic that received a lot of attention in different research communities, e.g., by researchers interested in open source development, global software engineering, and mining software repositories. Developer Social Networks (DSNs) are often inferred automatically from information that can be found in forges like GitHub, Mailing Lists (MLs), Issue Tracking Systems (ITSs), and Version Control Systems (VCSs) of software development projects. The DSNs give valuable insights into the projects, e.g., regarding the importance of individuals (Joblin et al., 2015), patterns in communication behavior (Damian et al., 2007b), for the identification of single points of failure (Tamburri et al., 2019), gender-aspects (Catolino et al., 2019), and even bugs (Pinzger et al., 2008). Due to the magnitude of publications on DSNs, the diversity of topics addressed by DSNs, and the lack of a contemporary literature review, a novel literature study is required to ensure that researchers and practitioners can get a complete overview on the state of the art of DSNs. This article describes a mapping study performed based on the rigorous guidelines by Kitchenham and Charters (2007) for literature reviews with the goal to identify and map research on DSNs. We map the publications on DSNs to research topics and analyze the scope of the publications in terms of data sources, number of projects, and number of people.

With our mapping study, we provide the following contributions.

•
A contemporary overview of the state of the art of the literature on DSNs.

•
A summary of the already investigated research directions, including the relevant literature.

•
A summary of the data sources, as well as the size of the DSNs in terms of number of projects and people involved.

•
A bibliometric assessment to identify influential publications, authors, venues, and interest in the topic over time.

•
The identification of open issues within the current state of the art.

We found that 49% of all publications on DSNs analyze the structure of the community, either in general, or with respect to other aspects of software development, e.g., the evolution, or the impact on code quality. Other frequent topics in research are prediction systems based on DSNs, e.g., for defect prediction or bug triage, the collaboration behavior between developers, and the roles of developers. Regarding the way that studies are conducted, we found that 79% of the studies are based on a single data source and 70% of the studies use less then 11 projects to draw conclusions. These are concerning findings regarding the generalizability of results. Regardless, 80% of publications use social networks with at least 100 people modeled by the network, i.e., large networks are usually the foundation for analysis, which is good for the generalizability. Thus, we believe there is a need for studies with high external validity on DSNs, especially more studies that consider a large amount of different projects in order to derive generalizable conclusions for diverse populations. Other open issues in the state of the art are, e.g., inter-company collaborations and the use of data from multiple information sources for the analysis of DSNs. Finally, the extraction of data from the publications for this mapping study revealed a lack of reporting guidelines for DSNs, i.e., some publications fail to report basic meta data about the studies conducted, e.g., the number of projects considered, the number of developers involved, or how data was processed, e.g., to deal with duplicate identities.

The remainder of this paper is organized as follows. We give a definition of DSNs in Section 2. In Section 3, we present our methodology for the mapping study, including our research questions, inclusion and exclusion criteria for the literature, how we identified publications, and the data we collected for each included publication. In Section 4, we give the results of our review, by listing the primary studies we found and map them to DSN concepts according to our research questions. In Section 5, we discuss open issues regarding DSN research based on the results of our mapping study. Then, we discuss related prior literature studies in Section 6, and conclude the article in Section 7.

2. Definition of Developer Social Networks (DSNs)
A definition is difficult, because different data sources, research goals, and modeling approaches are used to represent DSNs in the literature. Due to this, publications on DSNs contain the specific definition of their DSN structure, but this varies between publications. For our purpose, we require a definition, that can be applied to validate if a construct is an instance of a DSN. We identified three necessary and sufficient conditions for DSNs.

1.
A DSN is described by a graph  where  denotes a set of vertices and  a set of edges such that . The graph can be directed or undirected, depending on the intent of the researchers and the data that is used for modeling the DSN.

2.
The vertices or a subset of the vertices must represent actors of a software development process, e.g., developers, users, or project managers.

3.
The edges represent connections between vertices that are based on communication behavior (e.g., email communication) or collaboration behavior (e.g., contributions to the same software artifact).

An example of a DSN is given in Fig. 1. This figure depicts an anonymized excerpt of the DSN created by Bird et al. (2006a). The vertices in this graph represent different developers, which were active on Apache email lists. A directed edge between two vertices exists, if the developer has sent or replied to at least 150 emails of another developer.

3. Methodology
Our review follows the guidelines for systematic literature reviews proposed by Kitchenham and Charters (2007). Additionally, we used backward and forward snowballing, which was suggested for systematic literature studies by Wohlin (2014). In the following, we define our underlying research questions, inclusion and exclusion criteria, how we identified papers, and which data was collected for our study. We do not define our study as systematic literature review but as a systematic mapping study, because we did not perform any synthesis of the results, but only provide an overview of the literature.

3.1. Research questions
In order to study the state of the art in DSNs, we defined the following five research questions to guide our mapping study.

•
RQ1. What software engineering topics have been addressed by DSNs?

•
RQ2. Which data sources are used for modeling of DSNs?

•
RQ3. What is the scope of the analysis...

(a)
with respect to number of projects considered

(b)
and people modeled by the DSNs?

•
RQ4. What are the most influential...

(a)
publications?

(b)
authors?

(c)
venues?

•
RQ5. How did the interest in DSN research evolve over time?

The first three research questions guide our analysis of the state of the art of DSNs. We want to get insights into both the topics that are under investigation within the research community, as well as the amount of studies on different topics through our analysis for RQ1. The research questions RQ2 and RQ3 guide our investigation of the scope of studies. Through the answer to RQ2, we want to get valuable information about the data sources that researchers use to define social relationships. Through RQ3, we want to gain insights into how large the studies are, e.g., if they are case studies of specific cases with few projects or if they are broad studies over hundreds of projects. The fourth and fifth question give us insights into the community of DSN research itself. RQ4 will tell us which work had the most impact, i.e., early foundational work and later work that presented new ideas for the use of DSNs that influenced many other publications. Moreover, we assess if there are authors who are clearly distinguished in the field of DSN research through their publications. We also look at the venues where DSN research is most often published to gain insights into which communities frequently use DSNs in their research. Through RQ5 we want to understand how the interest in DSN research evolves over time, e.g., if the interest is still growing or if the topics of interest change over time.

3.2. Inclusion and exclusion criteria
To identify which papers should be part of our review, we defined the following criteria for inclusion:

•
publications that describe DSNs;

•
publications that describe how DSNs may be created; and

•
publications that describe theoretical aspects of DSNs.

Additionally, we used the following exclusion criteria:

•
publications that only summarize existing work without new contributions;

•
publications that only consider social networks or graph structures in general, without a direct and specific relation to software development;

•
publications that were not peer-reviewed; and

•
publications that are not published in English.

3.3. Identification of primary studies
Fig. 2 summarizes our workflow for the identification of primary studies. We used a five step procedure.

1.
Initial scan of the literature using search engines and prior literature studies to identify a seed of publications.

2.
Backward and forward snowballing of publications found in the initial scan.

3.
Second scan of the literature using search engines to capture the remainder of 2017 and to account for delayed indexing of publications.

4.
Backward and forward snowballing of publications found in the second scan.

5.
Final check of inclusion and exclusion criteria on all identified publications.

In the first step, we searched for publications by using five search engines: Google Scholar, IEEE Xplore, ACM Digital Library, Springer Link, Elsevier Search, and Scopus.1 We used three queries for each search engine: “developer social networks”, “developer network”, and “collaborative networks OSS”. Table 1 gives an overview on the number of hits we had with our search terms in each of the search engines. This initial search was conducted between May 2017 and September 2017. Due to the extremely high number of hits, we considered only 750 hits per search engine and search term to get the literature seed for our mapping study. Next, we selected candidates for inclusion by reading the titles, abstracts, and, if it was necessary, the introduction and conclusion sections of the publications. We identified 145 publications through this procedure from the search engines. Additionally, we scanned the primary studies from prior related literature studies by Zhang et al., 2014a, Tamburri et al., 2013, Manteli et al., 2012, and Abufouda and Abukwaik (2017) (see Section 6). We identified 39 additional publications from the prior studies. This difference is mainly due to the scope of the other literature studies, especially with respect to search terms. For example, Manteli et al. (2012) focus on global software engineering and, therefore, also use search terms that do not mention DSNs. Thus, we identified 184 publications in this first step.


Download : Download high-res image (274KB)
Download : Download full-size image
Fig. 2. Overview of the mapping study’s workflow.

In the second step, we checked the related work cited in each of the publications we found using the search engines. This step is also known as backward snowballing (Wohlin, 2014). Moreover, we used the “cited by” function of Google Scholar, to identify publications that cited the publications we identified with the search engines. This step is also known as forward snowballing (Wohlin, 2014). We also applied the snowballing to each additional publication we found. We identified 32 additional publications, i.e., 216 publications in total. The snowballing also served to mitigate potential negative effects because we did not consider every hit for the search terms with the search engines. Our assumption is that we find the literature we may have missed through the snowballing. Moreover, same as the use of the prior literature reviews as seed for the snowballing, the snowballing allowed us to identify literature that did not mention the DSN in the paper title or abstract and was, therefore, missed by our search.


Table 1. Search terms and number of hits for each search engine.

Search terms	Google Scholar	IEEE Xplore	ACM Digital Library	Springer Link	Elsevier Search	Scopus
Developers network	969,000	4,339	204,258	108,157	60,735	102
Developer social networks	235,000	513	249,607	48,021	26,642	131
Collaborative networks OSS	25,400	22	119,424	1,090	692	0
In the third step, we repeated our search for literature from the first step. This was required, because the initial search already started in May 2017, i.e., we could not be confident that all papers from 2016 were indexed by the search engines and part of the data for 2017 was not available yet. Moreover, we wanted to include recent publications, that would be missing otherwise. Thus, we repeated the search engines Google Scholar in July 2018 and July 2019 and with SCOPUS in February 2020. This way, we identified 31 new publications using Google Scholar and 29 publications using SCOPUS, bringing our total number of publications to 276. Afterwards, in the fourth step, we performed an additional round of snowballing on these publications and identified 20 additional publications, i.e., a total of 296 publications.

Before we started with the data collection, we validatedwhether all identified candidates met the inclusion criteria or violate the exclusion criteria in our last step. This way, we excluded 41 of the identified publications, mainly because they were not peer reviewed (e.g., book chapters, preprints on arXiv), summarized only existing work (e.g., surveys, dissertation summaries), or because they did not contain anything specific to developer social networks, regardless of our initial assessment. This left us with 255 primary studies.

3.4. Data collection
Once all literature was identified, we proceeded with the collection of the data required to answer our research questions. For RQ1, we first extracted the research questions and/or hypothesis that were formulated to guide the research, as well as the contributions as listed in the introduction or summarized in the abstract from the publications. We used inductive coding (Thomas, 2006) performed by two researchers to identify the research topics of the papers from the hypothesis and contributions in order to obtain the necessary information to answer RQ1. For this, we printed the title, research questions/hypotheses, and contributions of each publication on a separate sheet of paper and sorted them incrementally by their topic, starting with a coarse-grained separation until we were satisfied that our categories provided a sufficient amount of detail for our mapping study. For RQ2 and RQ3, we extracted the data source, the number of projects, and the number of participants in the DSN used within the publications. For RQ4 and RQ5, we collected meta data about the publications themselves, i.e., the title, authors, publication venue, year, and number of citations. We organized the collected data in a spreadsheet which is made available as supplementary material (Herbold et al., 2020).

4. Literature review
In this section, we provide the review of the state of the art of DSN research based on the data collection we described in Section 3. We systematically address different topics. We use the data from this review to answer our research questions in Section 5.

4.1. Research directions
Based on the description of the contributions, the research questions, and the research hypotheses of publications, we identified seven general research directions regarding DSNs. For four of the general research directions we identified subtopics, i.e., specific aspects that were considered within the general direction. Table 2 shows our mapping of publications to the research directions including subtopics.

Nearly half of the publications we identified analyze the community structures in software development projects. Most of these publications analyzed the general structure of the DSN. However, we also identified seven more specific subtopics of the analysis of community structures: the evolution of the communities by considering DSNs over time; community structures in the context of global software engineering; the formation of teams within development projects; the correlation between the community structure and code quality; the analysis of socio-technical congruence; the simulation of community structures; and the identification of community smells.

DSNs are frequently used for the creation or improvement of prediction models for various aspects in software development projects. We identified seven subtopics of prediction approaches using DSNs: bug triage, i.e., support for assigning appropriate developers to work on bug reports; defect prediction, i.e., using the social structure of a project to enhance models that estimate the defect-proneness of different parts of software; recommendation of suitable developers for project work in general; predictions of the outcome of a project, i.e., if projects are likely successful; predictions of suitable Web services; predictions of build failures; and prediction of appropriate developers for code review.

The collaboration behavior was also scrutinized using DSNs. While DSNs are modeling some direct or indirect collaboration behavior in software development projects, the analysis of the collaboration behavior itself is in general not the focus. The publications we identified for this research direction focus directly on the collaboration behavior, e.g., which tools were used or how collaboration behavior was impacted by the structure of projects. In addition to research on collaboration behavior in general, we identified three more specific subtopics: collaboration behavior in global software engineering; problems in collaboration behavior and how they are reflected in DSNs; and collaboration between developers from different companies, including competitors in open source projects.

DSNs are also frequently used to assess the roles of developers within a development project, e.g., whether a developer is a core developer or a peripheral developer. While the identification of roles for developers in general is the main topic of this research direction, we also identified two other subtopics; the analysis of how onboarding of peripheral developers within projects works; and how developers specialize within a project.

We also identified research regarding tools for DSN analysis, mostly for the visualization of DSNs based on different information sources.

The validity of DSN research was also considered by five publications. These publications do not question the validity of DSN research in general, but rather analyze how properties of DSN research may depend on the specific context of research projects, e.g., the scope of the analysis or the repository that was used as source for the DSNs.

Finally, we found one publication on a data set that directly contains the graph structure of a DSN. The lack of publications on data sets shows that researchers either generate DSNs from data they collect, or from more general data sets that do not model DSNs directly. Such data sets contain general information mined from software repositories from which a DSN is then built.



Download : Download high-res image (79KB)
Download : Download full-size image

Table 2. Overview of the literature on DSNs by research directions.

Category	#Pubs.	Publications
Community structure
General	75	Allaho and Lee, 2013, Amrit et al., 2004, Van Antwerp and Madey, 2010, Avelino et al., 2019, Bana and Arora, 2018, Batista et al., 2017, Behfar and Behfar, 2016, Behfar et al., 2018, Hajiakhoond Bidoki and Sukthankar, 2018, Bird et al., 2006a, Bird et al., 2006b, Bird et al., 2008, Canfora et al., 2011, Cherry and Robillard, 2008, Conaldi and Rullani, 2010, Crowston and Howison, 2005, Crowston and Howison, 2006, dos Santos et al., 2011, Gao and Madey, 2007a, Gao and Madey, 2007b, Geipel et al., 2014, Gloor et al., 2003, González-Barahona et al., 2004, Avelino et al., 2017, He et al., 2012, Howison et al., 2006, Hu and Zhao, 2008, Hu et al., 2012, Hu et al., 2016, Huang and Choi, 2011, Ichimura and Uemoto, 2015, Iyer and Lyytinen, 2019, Jermakovics et al., 2011, Jermakovics et al., 2013, Jiang et al., 2013, Joblin et al., 2015, Kamei et al., 2008, Kidane and Gloor, 2007, Leibzon, 2016, Lim and Bentley, 2011, Lima et al., 2014, Linåker et al., 2019, Long and Siau, 2007, Lopez-Fernandez et al., 2004, López-Fernández et al., 2008, Madey et al., 2002, Meneely and Williams, 2009, Meneely and Williams, 2010b, Meneely and Williams, 2010a, Mergel, 2015, Nzeko’o et al., 2015, Qiu et al., 2019, Robertsa et al., 2006, Schwind et al., 2008, Singh, 2010, Sowe et al., 2014, Sureka et al., 2011, Surian et al., 2010, Tamburri et al., 2019, Tan et al., 2007, Thung et al., 2013, Toral et al., 2010, Van Antwerp and Madey, 2010a, Wagstrom et al., 2005, Wang et al., 2019, Wiggins et al., 2008, Wolf et al., 2009b, Xu and Madey, 2004, Xu et al., 2005a, Xu et al., 2005b, Yu and Ramaswamy, 2013, Yu et al., 2014, Zanetti et al., 2012, Zhang et al., 2014 and Zhang et al. (2015)
DSN evolution	18	Aljemabi and Wang, 2018, Datta et al., 2011, Hannemann and Klamma, 2013, Hong et al., 2011, Joblin et al., 2017b, Kakimoto et al., 2006, Kavaler and Filkov, 2017, Kumar and Gupta, 2013, Kumar et al., 2019, Nakakoji et al., 2005, Ngamkajornwiwat et al., 2008, Rossi and Neville, 2010, Sharma and Kaulgud, 2011, Van Antwerp and Madey, 2010b, Weiss et al., 2006, Yu et al., 2014, Zanetti et al., 2013 and Zhang et al. (2011)
Global SWE	10	Ahuja et al., 2003, Avritzer et al., 2010, Cataldo and Herbsleb, 2008b, De Souza et al., 2007, Ehrlich and Chang, 2006, Ehrlich and Cataldo, 2012, Hinds and McGrath, 2006, Hossain and Zhu, 2009, Sarker et al., 0000 and Spinellis (2006)
Team formation	6	Caglayan et al., 2013, Crowston et al., 2007, Hahn et al., 2006, Hahn et al., 2008, Panichella et al., 2014b and Singh and Tan (2010)
Impact on code quality	6	Bettenburg and Hassan, 2010, Bettenburg and Hassan, 2013, Çaglayan and Bener, 2016, Datta, 2018, Hossain and Zhou, 2008 and Mockus (2010)
Socio-technical congruence	5	Cataldo et al., 2008, De Souza et al., 2005, Kwan et al., 2011, Syeed and Hammouda, 2013 and Valetto et al. (2007)
Simulation	4	Honsel et al., 2014, Honsel et al., 2015, Honsel et al., 2015 and Yu et al. (2008)
Community smells	2	Catolino et al. (2019) and Palomba et al. (2018)
Prediction
Bug triage	16	Banitaan and Alenezi, 2013, Bhattacharya and Neamtiu, 2010, Bhattacharya et al., 2012b, Chen et al., 2010, Jeong et al., 2009, Sun et al., 2017, Wang et al., 2013, Wu et al., 2011, Wu et al., 2018, Xuan et al., 2012b, Yang et al., 2014, Zanetti et al., 2013, Zhang and Lee, 2012, Zhang et al., 2013, Zhang et al., 2014a and Zhang et al. (2014b)
Defect prediction	12	Abreu and Premraj, 2009, Bhattacharya et al., 2012a, Biçer et al., 2011, Bird et al., 2009, Hu and Wong, 2013, Meneely et al., 2008, Miranskyy et al., 2014, Pinzger et al., 2008, Simpson, 2013, Wang and Wang, 2016, Zhang et al., 2014b and Zhang et al. (2019)
Project outcomes	9	Cataldo and Ehrlich, 2012, Jarczyk et al., 2018, Liu and Iyer, 2007, Peng et al., 2018, Peng, 2019, Singh et al., 2011, Surian et al., 2013, Wang et al., 2012 and Wang (2012)
Developers for tasks in general	7	Dráždilová et al., 2012, Hossain et al., 2006, Hu et al., 2018, Li et al., 2016, McDonald, 2003, Surian et al., 2011 and Wan et al. (2018)
Suitable web services	3	Bianchini et al., 2015, Bianchini et al., 2016a and Bianchini et al. (2016b)
Build failures	2	Schröter (2010) and Wolf et al. (2009a)
Developers for code review	1	Kerzazi and El Asri (2016)
Collaboration behavior
General	13	Cohen and Consens, 2018, Damian et al., 2013, Duc et al., 2011, Feczak and Hossain, 2009, Feczak and Hossain, 2011, Gharehyazie and Filkov, 2017, Kerzazi and El Asri, 2017, Licorish and MacDonell, 2017, Omoronyia et al., 2009, Ortu et al., 2015, Wu et al., 2016, Xuan et al., 2012a and Yang (2014)
Global SWE	10	Cataldo and Herbsleb, 2008a, Chang and Ehrlich, 2007, Damian et al., 2007b, Fonseca et al., 2006, Herbsleb and Mockus, 2003, Mikawa et al., 2009, Nguyen et al., 2008, Sarker et al., 2011, Urdangarin et al., 2008 and Wolf et al. (2008)
Problems	10	Begel et al., 2010, Bernardi et al., 2012, Bhowmik et al., 2016, Cataldo et al., 2006, Damian et al., 2007a, Ell, 2013, Orsila et al., 2009, Sapkota et al., 2020, Wang and Redmiles, 2016 and Xuan et al. (2016)
Inter-company collaboration behavior	1	Teixeira et al. (2015)
Developer roles
Identification	18	Zhang et al., 2012, Meneely et al., 2010, Bhattacharya et al., 2014b, Crowston et al., 2006, Datta et al., 2010, Dittrich et al., 2013, Huang and Liu, 2005, Joblin et al., 2017a, Lee et al., 2013, Licorish and MacDonell, 2014, Licorish and MacDonell, 2015, Lim et al., 2010, Lim and Finkelstein, 2012, Marczak et al., 2008, Pohl and Diehl, 2008, Sharma et al., 2017, Sowe et al., 2006 and Yu and Ramaswamy (2007)
Onboarding	9	Bird et al., 2007, Canfora et al., 2012, Casalnuovo et al., 2015, Cheng et al., 2017, Ducheneaut, 2005, El Asri et al., 2017, Gharehyazie et al., 2013, Gharehyazie et al., 2015 and Zhou and Mockus (2011)
Specialization	1	MacLean et al. (2011)
Tools	11	Borici et al., 2012, De Souza et al., 2004, de Souza et al., 2007, Gilbert and Karahalios, 2007, Gote et al., 2019, Ogawa et al., 2007, Ohira et al., 2005b, Ohira et al., 2005a, Sarma et al., 2009, Schwind and Wegmann, 2008 and Schwind et al. (2010)
DSN validity	5	Meneely and Williams, 2011, Aljemabi and Wang, 2017, Nia et al., 2010, Panichella et al., 2014a and Tymchuk et al. (2014)
Datasets	1	MacLean and Knutson (2013)

Table 3. Data sources that were used for the modeling of the DSNs.

Data source	#Pubs.	Publications
Forge	64	Aljemabi and Wang, 2018, Allaho and Lee, 2013, Bana and Arora, 2018, Batista et al., 2017, Behfar and Behfar, 2016, Behfar et al., 2018, Hajiakhoond Bidoki and Sukthankar, 2018, Caglayan et al., 2013, Catolino et al., 2019, Cohen and Consens, 2018, Conaldi and Rullani, 2010, dos Santos et al., 2011, Dráždilová et al., 2012, El Asri et al., 2017, Gao and Madey, 2007a, Gao and Madey, 2007b, Hahn et al., 2006, Hahn et al., 2008, He et al., 2012, Hu et al., 2016, Hu et al., 2018, Huang and Choi, 2011, Ichimura and Uemoto, 2015, Iyer and Lyytinen, 2019, Jarczyk et al., 2018, Jiang et al., 2013, Kerzazi and El Asri, 2016, Kerzazi and El Asri, 2017, Lee et al., 2013, Leibzon, 2016, Li et al., 2016, Lima et al., 2014, Liu and Iyer, 2007, Madey et al., 2002, Mergel, 2015, Ohira et al., 2005b, Ohira et al., 2005a, Peng et al., 2018, Peng, 2019, Qiu et al., 2019, Sapkota et al., 2020, Singh, 2010, Singh et al., 2011, Surian et al., 2010, Surian et al., 2011, Surian et al., 2013, Tamburri et al., 2019, Tan et al., 2007, Thung et al., 2013, Tymchuk et al., 2014, Van Antwerp and Madey, 2010a, Wan et al., 2018, Wang et al., 2012, Wang, 2012, Wang et al., 2019, Wu et al., 2016, Xu and Madey, 2004, Xu et al., 2005a, Xu et al., 2005b, Yu and Ramaswamy, 2013, Yu et al., 2014, Zhang et al., 2014 and Zhang et al. (2015)
ITS	49	Abreu and Premraj, 2009, Banitaan and Alenezi, 2013, Bettenburg and Hassan, 2010, Bhattacharya and Neamtiu, 2010, Bhattacharya et al., 2012b, Bhowmik et al., 2016, Cataldo et al., 2006, Cataldo et al., 2008, Cataldo and Ehrlich, 2012, Chen et al., 2010, Crowston and Howison, 2005, Crowston et al., 2006, Crowston and Howison, 2006, Datta et al., 2010, Duc et al., 2011, Ehrlich and Cataldo, 2012, Feczak and Hossain, 2009, Feczak and Hossain, 2011, Hong et al., 2011, Hossain and Zhou, 2008, Hossain and Zhu, 2009, Howison et al., 2006, Jeong et al., 2009, Kumar and Gupta, 2013, Kumar et al., 2019, Licorish and MacDonell, 2014, Licorish and MacDonell, 2015, Licorish and MacDonell, 2017, Long and Siau, 2007, Nguyen et al., 2008, Ortu et al., 2015, Sharma and Kaulgud, 2011, Sureka et al., 2011, Wang et al., 2013, Wolf et al., 2008, Wolf et al., 2009b, Wolf et al., 2009a, Wu et al., 2011, Wu et al., 2018, Xuan et al., 2012b, Yang et al., 2014, Zanetti et al., 2012, Zanetti et al., 2013, Zanetti et al., 2013, Zhang and Lee, 2012, Zhang et al., 2013, Zhang et al., 2014a, Zhang et al., 2014b and Zhou and Mockus (2011)
VCS	41	Van Antwerp and Madey, 2010, Avelino et al., 2019, Bird et al., 2009, Casalnuovo et al., 2015, Çaglayan and Bener, 2016, Cheng et al., 2017, De Souza et al., 2004, De Souza et al., 2005, Dittrich et al., 2013, Ell, 2013, González-Barahona et al., 2004, Gote et al., 2019, Avelino et al., 2017, Huang and Liu, 2005, Jermakovics et al., 2011, Jermakovics et al., 2013, Joblin et al., 2015, Joblin et al., 2017a, Joblin et al., 2017b, Kakimoto et al., 2006, Lopez-Fernandez et al., 2004, López-Fernández et al., 2008, MacLean and Knutson, 2013, Meneely et al., 2008, Meneely and Williams, 2009, Meneely and Williams, 2010b, Meneely and Williams, 2011, Miranskyy et al., 2014, Mockus, 2010, Orsila et al., 2009, Palomba et al., 2018, Pinzger et al., 2008, Pohl and Diehl, 2008, Schwind and Wegmann, 2008, Schwind et al., 2008, Schwind et al., 2010, Sun et al., 2017, Teixeira et al., 2015, Valetto et al., 2007, Van Antwerp and Madey, 2010b and Yu and Ramaswamy (2007)
ML	23	Ahuja et al., 2003, Bird et al., 2006a, Bird et al., 2006b, Bird et al., 2008, Gharehyazie et al., 2015, Gloor et al., 2003, Hossain et al., 2006, Kamei et al., 2008, Kavaler and Filkov, 2017, Kidane and Gloor, 2007, Nakakoji et al., 2005, Ngamkajornwiwat et al., 2008, Nia et al., 2010, Nzeko’o et al., 2015, Robertsa et al., 2006, Sharma et al., 2017, Sowe et al., 2006, Toral et al., 2010, Weiss et al., 2006, Xuan et al., 2016, Yu et al., 2008, Zhang et al., 2012 and Zhang et al. (2014b)
Other	14	Amrit et al., 2004, Bianchini et al., 2015, Bianchini et al., 2016a, Bianchini et al., 2016b, Borici et al., 2012, Cataldo and Herbsleb, 2008a, Damian et al., 2007a, de Souza et al., 2007, Hu and Zhao, 2008, Hu et al., 2012, Hu and Wong, 2013, Omoronyia et al., 2009, Wang and Wang, 2016 and Yang (2014)
Survey	13	Avritzer et al., 2010, Chang and Ehrlich, 2007, Cherry and Robillard, 2008, Ehrlich and Chang, 2006, Hinds and McGrath, 2006, Lim et al., 2010, Lim and Bentley, 2011, Lim and Finkelstein, 2012, McDonald, 2003, Mikawa et al., 2009, Sarker et al., 0000, Sarker et al., 2011 and Urdangarin et al. (2008)
ITS & VCS	19	Aljemabi and Wang, 2017, Bernardi et al., 2012, Bettenburg and Hassan, 2013, Bhattacharya et al., 2012a, Bhattacharya et al., 2014b, Biçer et al., 2011, Datta et al., 2011, Datta, 2018, Honsel et al., 2014, Honsel et al., 2015, Honsel et al., 2015, Kwan et al., 2011, Linåker et al., 2019, Meneely et al., 2010, Meneely and Williams, 2010a, Schröter, 2010, Simpson, 2013, Spinellis, 2006 and Zhang et al. (2019)
ML & VCS	14	Bird et al., 2007, Canfora et al., 2011, Canfora et al., 2012, Ducheneaut, 2005, Fonseca et al., 2006, Gharehyazie and Filkov, 2017, Gilbert and Karahalios, 2007, Hannemann and Klamma, 2013, Ogawa et al., 2007, Singh and Tan, 2010, Sowe et al., 2014, Syeed and Hammouda, 2013, Xuan et al., 2012a and Zhang et al. (2011)
Survey & Other	3	Damian et al., 2007b, Damian et al., 2013 and Marczak et al. (2008)
ML & ITS	2	MacLean et al. (2011) and Rossi and Neville (2010)
ML & Other	2	Crowston et al. (2007) and Wagstrom et al. (2005)
Forge & Survey	1	De Souza et al. (2007)
ITS & Survey	1	Herbsleb and Mockus (2003)
VCS & Forge	1	Geipel et al. (2014)
ITS, ML & VCS	3	Gharehyazie et al., 2013, Panichella et al., 2014b and Sarma et al. (2009)
ML, ITS & Other	1	Wiggins et al. (2008)
ITS, Survey & Other	1	Cataldo and Herbsleb (2008b)
ITS, VCS & Other	1	Begel et al. (2010)
ITS, ML, CVS & Other	2	Panichella et al. (2014a) and Wang and Redmiles (2016)
4.2. Data sources
There are five major data sources which are used by 241 of the 255 publications:

•
Forges like GitHub or SourceForge that are used by millions of developers for hosting and developing open source software. These forges offer an integration of VCSs and ITSs within a single environment, often coupled with other services like Web pages, hosting of releases, or Wikis. Thus, they are a rich source for collaborations between developers, both within a project, as well as across multiple projects.

•
ITSs like Jira or Bugzilla are used for the collection, tracking, and management of issues and work items within projects, e.g., change requests, bug reports, or questions by users. ITSs allow the discussion about issues, the definition of work flows for issues, and different types of resolutions.

•
VCSs like Git or SVN are systems that track and archive changes of files and folders over time. Typically, VCSs allow different development branches and support working collaboratively on the same resources (Sommerville et al., 2011).

•
MLs are collections of email addresses that can be used for communication within software projects. MLs may be restricted, e.g., not everybody may be allowed to post or subscribe to a ML. Participants of MLs may be natural persons (e.g., developers, users), but also systems (e.g., continuous integration systems, ITSs).

•
Surveys, i.e., interviews or questionnaires that were used to directly ask developers about their communication behavior within a development project.

In addition to the five major sources, there are other ways that researchers used to collect information about collaboration behavior which we summarized as “Other” in Table 3. These are IRC chats (Cataldo and Herbsleb, 2008b, Cataldo and Herbsleb, 2008a, Panichella et al., 2014a, Wang and Redmiles, 2016), plug-ins that monitor development environments (Omoronyia et al., 2009, Borici et al., 2012, de Souza et al., 2007), manual inspection of project documents, e.g., requirements (Damian et al., 2013, Damian et al., 2007b, Marczak et al., 2008), owners ob web service mash-ups (Bianchini et al., 2016a, Bianchini et al., 2016b, Bianchini et al., 2015), the web site Ohloh that provides statistics about open source development2 (Hu and Zhao, 2008, Hu et al., 2012), online discussion forums (Wiggins et al., 2008, Crowston et al., 2007), JAR files (Hu and Wong, 2013), the BlogLinks and Advogoto social networks3 of software developers (Wagstrom et al., 2005), on site researchers that observe communication behavior (Damian et al., 2007a), employee directories (Begel et al., 2010), and the code review portal Gerrit (Yang, 2014). Additionally, one publication discusses DSNs from an abstract perspective and proposes the use of tracking for every communication including phone calls, emails, etc. (Amrit et al., 2004).

Fig. 3 depicts the number of data sources that were used for modeling DSNs. It highlights that 204 of the 255 publications build a DSN that is based on a single source, 43 publications used a combination of two data sources, six publication three data sources and two publications four data sources.

4.3. Number of projects analyzed
A major factor regarding the external validity of results is the number of projects for which data is collected. If only data about very few projects is used for an empirical study about a phenomenon that can be studied using DSNs, the results may not generalize to other projects. The likelihood that the results generalize to software engineering in general increases with the number of projects that are analyzed. Table 4 shows the number of projects per publication. The data we collected shows that most papers on DSNs perform some sort of empirical study to demonstrate their approach or research a phenomenon. Only 12 of the 255 publications we identified did not perform any empirical study. Moreover, we identified 16 publications for which we could not identify the number of projects from the publication. There were two reasons for this: either the authors did not report how they selected a smaller subset from a larger database or the authors did not specify which projects were used at all. This is not only problematic for evaluating the external validity of a study, but also hinders replications of the results. Of the 227 publications for which we could identify the number of projects, 76 used only a single project for their empirical study, 69 used only 2–5 projects for the empirical study. In other words, about 33% of the publications on DSNs used a single project, another 30% used 2–5 projects. Both numbers are extremely low and do not allow for a generalization of the findings due to the limited context covered by the projects. Another 12 publications only considered 6–10 projects, which is still a small number. On the bright side, 50 publications used more than 100 projects, i.e., larger sample sizes that usually allow to generalize findings. 38 of these publications use a forge as data source. Regardless, our analysis of the sample sizes with respect to the number of projects indicates a severe threat to the external validity of many empirical studies on DSNs.



Download : Download high-res image (61KB)
Download : Download full-size image

Table 4. Number of projects that were analyzed as part of an empirical study of DSNs. Missing means that the number of projects is not or not accurately reported in the publication, NA means that the publication did not conduct an empirical study.

#Projects	#Pubs.	Publications
1	76	Abreu and Premraj, 2009, Ahuja et al., 2003, Avritzer et al., 2010, Bettenburg and Hassan, 2010, Bird et al., 2006a, Bird et al., 2006b, Caglayan et al., 2013, Cataldo et al., 2006, Cataldo and Herbsleb, 2008a, Cataldo et al., 2008, Cataldo and Ehrlich, 2012, Cherry and Robillard, 2008, Damian et al., 2007a, Datta et al., 2010, Datta et al., 2011, Datta, 2018, Ducheneaut, 2005, Ehrlich and Cataldo, 2012, Ell, 2013, González-Barahona et al., 2004, He et al., 2012, Hong et al., 2011, Honsel et al., 2014, Honsel et al., 2015, Hossain et al., 2006, Hu and Zhao, 2008, Kamei et al., 2008, Kumar and Gupta, 2013, Kwan et al., 2011, Li et al., 2016, Licorish and MacDonell, 2014, Licorish and MacDonell, 2015, Licorish and MacDonell, 2017, Lim et al., 2010, Lim and Bentley, 2011, Lim and Finkelstein, 2012, Linåker et al., 2019, MacLean et al., 2011, Marczak et al., 2008, McDonald, 2003, Meneely et al., 2008, Meneely and Williams, 2009, Meneely et al., 2010, Meneely and Williams, 2010a, Mikawa et al., 2009, Miranskyy et al., 2014, Mockus, 2010, Nakakoji et al., 2005, Ngamkajornwiwat et al., 2008, Nguyen et al., 2008, Omoronyia et al., 2009, Orsila et al., 2009, Pinzger et al., 2008, Pohl and Diehl, 2008, Robertsa et al., 2006, Rossi and Neville, 2010, Sarma et al., 2009, Schröter, 2010, Sharma and Kaulgud, 2011, Sharma et al., 2017, Simpson, 2013, Spinellis, 2006, Sureka et al., 2011, Syeed and Hammouda, 2013, Toral et al., 2010, Urdangarin et al., 2008, Wolf et al., 2008, Wolf et al., 2009b, Wolf et al., 2009a, Wu et al., 2011, Yang et al., 2014, Zanetti et al., 2013, Zhang et al., 2011, Zhang and Lee, 2012, Zhang et al., 2012 and Zhang et al. (2014a)
2–5	69	Aljemabi and Wang, 2018, Banitaan and Alenezi, 2013, Bernardi et al., 2012, Bettenburg and Hassan, 2013, Bhattacharya and Neamtiu, 2010, Bhattacharya et al., 2012b, Bhattacharya et al., 2014b, Bhowmik et al., 2016, Biçer et al., 2011, Bird et al., 2007, Bird et al., 2008, Bird et al., 2009, Canfora et al., 2011, Canfora et al., 2012, Cataldo and Herbsleb, 2008b, Çaglayan and Bener, 2016, Chang and Ehrlich, 2007, Chen et al., 2010, Crowston et al., 2007, Damian et al., 2013, de Souza et al., 2007, Dittrich et al., 2013, Duc et al., 2011, Ehrlich and Chang, 2006, El Asri et al., 2017, Gilbert and Karahalios, 2007, Gloor et al., 2003, Hannemann and Klamma, 2013, Honsel et al., 2015, Hu and Wong, 2013, Jeong et al., 2009, Jermakovics et al., 2011, Jermakovics et al., 2013, Kakimoto et al., 2006, Kavaler and Filkov, 2017, Kerzazi and El Asri, 2016, Kerzazi and El Asri, 2017, Kidane and Gloor, 2007, Kumar et al., 2019, Leibzon, 2016, Lopez-Fernandez et al., 2004, López-Fernández et al., 2008, Meneely and Williams, 2010b, Meneely and Williams, 2011, Nia et al., 2010, Nzeko’o et al., 2015, Ogawa et al., 2007, Panichella et al., 2014b, Sarker et al., 2011, Schwind and Wegmann, 2008, Schwind et al., 2008, Singh and Tan, 2010, Sowe et al., 2006, Sun et al., 2017, Van Antwerp and Madey, 2010b, Wang et al., 2013, Wang and Wang, 2016, Wang and Redmiles, 2016, Wiggins et al., 2008, Wu et al., 2018, Xuan et al., 2012b, Yang, 2014, Yu and Ramaswamy, 2007, Yu et al., 2008, Zanetti et al., 2013, Zhang et al., 2013, Zhang et al., 2014b, Zhang et al., 2014b and Zhang et al. (2019)
6–10	12	Bhattacharya et al., 2012a, Gharehyazie et al., 2013, Gharehyazie et al., 2015, Avelino et al., 2017, Huang and Liu, 2005, Joblin et al., 2015, Joblin et al., 2017a, Ortu et al., 2015, Palomba et al., 2018, Panichella et al., 2014a, Teixeira et al., 2015 and Zhou and Mockus (2011)
11–100	20	Aljemabi and Wang, 2017, Catolino et al., 2019, Crowston and Howison, 2005, De Souza et al., 2007, dos Santos et al., 2011, Geipel et al., 2014, Gharehyazie and Filkov, 2017, Hinds and McGrath, 2006, Hossain and Zhou, 2008, Hossain and Zhu, 2009, Joblin et al., 2017b, Sarker et al., 0000, Sowe et al., 2014, Tamburri et al., 2019, Weiss et al., 2006, Xuan et al., 2012a, Xuan et al., 2016, Zanetti et al., 2012, Zhang et al., 2014 and Zhang et al. (2015)
100	50	Allaho and Lee, 2013, Van Antwerp and Madey, 2010, Avelino et al., 2019, Batista et al., 2017, Bianchini et al., 2015, Bianchini et al., 2016a, Hajiakhoond Bidoki and Sukthankar, 2018, Casalnuovo et al., 2015, Cheng et al., 2017, Cohen and Consens, 2018, Conaldi and Rullani, 2010, Crowston et al., 2006, Crowston and Howison, 2006, Dráždilová et al., 2012, Feczak and Hossain, 2009, Feczak and Hossain, 2011, Hahn et al., 2006, Hahn et al., 2008, Howison et al., 2006, Hu et al., 2012, Hu et al., 2018, Huang and Choi, 2011, Iyer and Lyytinen, 2019, Jarczyk et al., 2018, Jiang et al., 2013, Lee et al., 2013, Liu and Iyer, 2007, Long and Siau, 2007, Madey et al., 2002, Mergel, 2015, Ohira et al., 2005b, Peng et al., 2018, Peng, 2019, Sapkota et al., 2020, Singh, 2010, Singh et al., 2011, Surian et al., 2010, Surian et al., 2011, Surian et al., 2013, Tan et al., 2007, Thung et al., 2013, Tymchuk et al., 2014, Wan et al., 2018, Wang et al., 2012, Wang, 2012, Wang et al., 2019, Wu et al., 2016, Xu et al., 2005a, Xu et al., 2005b and Yu and Ramaswamy (2013)
Missing	16	Bana and Arora, 2018, Behfar and Behfar, 2016, Behfar et al., 2018, Bianchini et al., 2016b, Damian et al., 2007b, Gao and Madey, 2007a, Herbsleb and Mockus, 2003, Hu et al., 2016, Lima et al., 2014, MacLean and Knutson, 2013, Qiu et al., 2019, Van Antwerp and Madey, 2010a, Wagstrom et al., 2005, Xu and Madey, 2004, Yu et al., 2014 and Yu et al. (2014)
NA	12	Amrit et al., 2004, Begel et al., 2010, Borici et al., 2012, De Souza et al., 2004, De Souza et al., 2005, Fonseca et al., 2006, Gao and Madey, 2007b, Gote et al., 2019, Ichimura and Uemoto, 2015, Ohira et al., 2005a, Schwind et al., 2010 and Valetto et al. (2007)
4.4. Number of developers in the DSNs
The second major factor regarding the validity of results is the number of people that are part of the DSNs. Table 5 shows the data we collected regarding the number of people in the DSNs. In case a publication created multiple DSNs, e.g., one per project considered, we report the mean value of the people in the DSNs. The number of people modeled by the DSNs is relatively high. 77 publications have more than 1000 people as part of their DSNs, 15 publications actually model more than 100,000 people. Only four publications have very small networks with less than or equal to 10 people, another 32 publications consider less than or equal to 100 people. Thus, for the publications for which the data about the number of people is available, the networks that are considered are in general relatively large. When we looked closely at the data, we observed two reasons for this: first, while many publications consider only few projects, these projects tend to be very large, e.g., Mozilla Firefox and the Eclipse IDE. Moreover, our data also shows that MLs and forges are the most common data sources for DSNs. Both capture not only developers, but also users of the respective projects. We also found a very concerning general trend in the literature: 66 of the 240 publications that performed an empirical study did not report the number of participants in the DSN. This is a vital piece of information for the estimation of both the internal and external validity of empirical studies that should always be reported.



Download : Download high-res image (72KB)
Download : Download full-size image

Table 5. Number of people that are inside the DSNs. Missing means that the number of people is not or not accurately reported in the publication, NA means that the publication did not conduct an empirical study.

#People	#Pubs.	Publications
1–10	4	Cherry and Robillard, 2008, Damian et al., 2007b, Omoronyia et al., 2009 and Pohl and Diehl (2008)
11–100	32	Abreu and Premraj, 2009, Ahuja et al., 2003, Avritzer et al., 2010, Banitaan and Alenezi, 2013, Bird et al., 2008, Cataldo and Ehrlich, 2012, Chang and Ehrlich, 2007, Crowston et al., 2007, Damian et al., 2013, Datta et al., 2010, De Souza et al., 2007, Ehrlich and Chang, 2006, Gharehyazie and Filkov, 2017, Honsel et al., 2015, Huang and Liu, 2005, Jarczyk et al., 2018, Jermakovics et al., 2011, Kakimoto et al., 2006, Kavaler and Filkov, 2017, Lim and Bentley, 2011, Marczak et al., 2008, Meneely et al., 2010, Meneely and Williams, 2010a, Mikawa et al., 2009, Palomba et al., 2018, Panichella et al., 2014a, Sarker et al., 0000, Sarker et al., 2011, Schwind et al., 2008, Urdangarin et al., 2008, Yu and Ramaswamy, 2007 and Zhang et al. (2012)
101–1000	64	Aljemabi and Wang, 2017, Bianchini et al., 2015, Bianchini et al., 2016a, Caglayan et al., 2013, Canfora et al., 2012, Cataldo et al., 2006, Cataldo and Herbsleb, 2008a, Cataldo et al., 2008, Crowston and Howison, 2006, Datta et al., 2011, Datta, 2018, Dittrich et al., 2013, Duc et al., 2011, Ducheneaut, 2005, Ehrlich and Cataldo, 2012, Gharehyazie et al., 2013, Gharehyazie et al., 2015, Gloor et al., 2003, Avelino et al., 2017, Herbsleb and Mockus, 2003, Honsel et al., 2015, Hossain et al., 2006, Huang and Choi, 2011, Jermakovics et al., 2013, Joblin et al., 2015, Joblin et al., 2017a, Joblin et al., 2017b, Kamei et al., 2008, Kerzazi and El Asri, 2017, Kwan et al., 2011, Licorish and MacDonell, 2014, Licorish and MacDonell, 2015, Licorish and MacDonell, 2017, Lim and Finkelstein, 2012, Linåker et al., 2019, López-Fernández et al., 2008, MacLean et al., 2011, Meneely et al., 2008, Meneely and Williams, 2009, Meneely and Williams, 2010b, Meneely and Williams, 2011, Mockus, 2010, Ngamkajornwiwat et al., 2008, Nguyen et al., 2008, Orsila et al., 2009, Ortu et al., 2015, Robertsa et al., 2006, Rossi and Neville, 2010, Schwind and Wegmann, 2008, Sowe et al., 2014, Spinellis, 2006, Sun et al., 2017, Surian et al., 2011, Tamburri et al., 2019, Tymchuk et al., 2014, Weiss et al., 2006, Wolf et al., 2008, Wolf et al., 2009a, Wu et al., 2011, Xuan et al., 2012a, Zanetti et al., 2012, Zanetti et al., 2013, Zhang et al., 2011 and Zhang and Lee (2012)
1001–10 000	35	Aljemabi and Wang, 2018, Avelino et al., 2019, Behfar and Behfar, 2016, Behfar et al., 2018, Bhowmik et al., 2016, Hajiakhoond Bidoki and Sukthankar, 2018, Bird et al., 2006a, Bird et al., 2006b, Canfora et al., 2011, Casalnuovo et al., 2015, El Asri et al., 2017, Hannemann and Klamma, 2013, He et al., 2012, Honsel et al., 2014, Hu and Zhao, 2008, Jeong et al., 2009, Kerzazi and El Asri, 2016, Kumar et al., 2019, Leibzon, 2016, Li et al., 2016, Lim et al., 2010, Liu and Iyer, 2007, Nakakoji et al., 2005, Nia et al., 2010, Nzeko’o et al., 2015, Ogawa et al., 2007, Singh, 2010, Sowe et al., 2006, Sureka et al., 2011, Syeed and Hammouda, 2013, Toral et al., 2010, Xuan et al., 2016, Yu et al., 2008, Zhang et al., 2014a and Zhang et al. (2019)
10 001–100 000	27	Van Antwerp and Madey, 2010, Batista et al., 2017, Bhattacharya et al., 2014b, Bird et al., 2007, Cohen and Consens, 2018, Dráždilová et al., 2012, Hu et al., 2012, Kumar and Gupta, 2013, Long and Siau, 2007, Madey et al., 2002, Panichella et al., 2014b, Qiu et al., 2019, Sapkota et al., 2020, Sarma et al., 2009, Sharma et al., 2017, Surian et al., 2010, Tan et al., 2007, Thung et al., 2013, Van Antwerp and Madey, 2010a, Van Antwerp and Madey, 2010b, Wan et al., 2018, Wang et al., 2013, Wu et al., 2018, Xuan et al., 2012b, Zanetti et al., 2013, Zhang et al., 2013 and Zhou and Mockus (2011)
15	Allaho and Lee, 2013, Bernardi et al., 2012, Conaldi and Rullani, 2010, Gao and Madey, 2007a, Hahn et al., 2008, Hong et al., 2011, Hu et al., 2018, Jiang et al., 2013, Lima et al., 2014, Ohira et al., 2005b, Wang et al., 2019, Xu et al., 2005b, Yu and Ramaswamy, 2013, Yu et al., 2014 and Yu et al. (2014)
Missing	66	Bana and Arora, 2018, Bettenburg and Hassan, 2010, Bettenburg and Hassan, 2013, Bhattacharya and Neamtiu, 2010, Bhattacharya et al., 2012b, Bhattacharya et al., 2012a, Bianchini et al., 2016b, Biçer et al., 2011, Bird et al., 2009, Cataldo and Herbsleb, 2008b, Catolino et al., 2019, Çaglayan and Bener, 2016, Chen et al., 2010, Cheng et al., 2017, Crowston and Howison, 2005, Crowston et al., 2006, Damian et al., 2007a, de Souza et al., 2007, dos Santos et al., 2011, Ell, 2013, Feczak and Hossain, 2009, Feczak and Hossain, 2011, Geipel et al., 2014, Gilbert and Karahalios, 2007, González-Barahona et al., 2004, Hahn et al., 2006, Hinds and McGrath, 2006, Hossain and Zhou, 2008, Hossain and Zhu, 2009, Howison et al., 2006, Hu and Wong, 2013, Hu et al., 2016, Iyer and Lyytinen, 2019, Kidane and Gloor, 2007, Lee et al., 2013, Lopez-Fernandez et al., 2004, MacLean and Knutson, 2013, McDonald, 2003, Mergel, 2015, Miranskyy et al., 2014, Peng et al., 2018, Peng, 2019, Pinzger et al., 2008, Schröter, 2010, Sharma and Kaulgud, 2011, Simpson, 2013, Singh and Tan, 2010, Singh et al., 2011, Surian et al., 2013, Teixeira et al., 2015, Wagstrom et al., 2005, Wang et al., 2012, Wang, 2012, Wang and Wang, 2016, Wang and Redmiles, 2016, Wiggins et al., 2008, Wolf et al., 2009b, Wu et al., 2016, Xu and Madey, 2004, Xu et al., 2005a, Yang, 2014, Yang et al., 2014, Zhang et al., 2014, Zhang et al., 2014b, Zhang et al., 2014b and Zhang et al. (2015)
NA	12	Amrit et al., 2004, Begel et al., 2010, Borici et al., 2012, De Souza et al., 2004, De Souza et al., 2005, Fonseca et al., 2006, Gao and Madey, 2007b, Gote et al., 2019, Ichimura and Uemoto, 2015, Ohira et al., 2005a, Schwind et al., 2010 and Valetto et al. (2007)
4.5. Influential publications
We collected data regarding the citation counts from Google Scholar. We take the pattern from the ACM Distinguished Paper awards to define our criterion for influential publications, and consider the top 10% with the most citations as influential. Since we have 255 publications, this means we consider the 25 publications with the most citations (Table 6). We note that the citations for the third most cited paper (Bird et al., 2006a) also include the citations for the paper (Bird et al., 2006b), because the two publications are considered as the same paper by Google Scholar. The 25 most influential publications address

•
software development with globally distributed projectmembers (Herbsleb and Mockus, 2003, Ahuja et al., 2003, Hinds and McGrath, 2006);

•
community structures in software development projects (Bird et al., 2006a, Crowston and Howison, 2005, Ducheneaut, 2005, Madey et al., 2002, Bird et al., 2008, Crowston and Howison, 2006, Lopez-Fernandez et al., 2004, Xu et al., 2005b);

•
the formation of teams in projects through collaboration (Hahn et al., 2008, Crowston et al., 2007);

•
the identification of relationships between developers (Begel et al., 2010);

•
the impact of coordination requirements between developers on tool design (Cataldo et al., 2006) and modularization (Cataldo et al., 2008);

•
communication issues (Damian et al., 2007a) and trust (Sarker et al., 2011);

•
the identification of core developers (Crowston et al., 2006);

•
predictions to support software engineering processes, i.e., bug triage (Jeong et al., 2009), defect prediction (Pinzger et al., 2008, Meneely et al., 2008, Bird et al., 2009), build failure prediction (Wolf et al., 2009a), and collaborations (McDonald, 2003).



Download : Download high-res image (79KB)
Download : Download full-size image

Table 6. Top 10% of publications ranked by number of citations. Data according to Google Scholar collected on 2020-02-24.

Title	Authors	Year	#Cit.
An empirical study of speed and communication in globally distributed software development	James D. Herbsleb, Audris Mockus	2003	1127
Individual Centrality and Performance in Virtual R&D Groups: An Empirical Study	Manju K. Ahuja, Dennis F. Galletta, Kathleen M. Carley	2003	665
Mining email social networks	Christian Bird, Alex Gourley, Premkumar Devanbu, Michael Gertz, Anand Swaminathan	2006	644
The social structure of free and open source software development	Kevin Crowston, James Howison	2005	602
Identification of Coordination Requirements: Implications for the Design of Collaboration and Awareness Tools	Marcelo Cataldo, Patrick A. Wagstrom, James D. Herbsleb, Kathleen M. Carley	2006	465
Socialization in an Open Source Software Community: A Socio-Technical Analysis	Nicolas Ducheneaut	2005	459
Improving Bug Triage with Bug Tossing Graphs	Gaeul Jeong, Sunghun Kim, Thomas Zimmermann	2009	434
The Open Source Software Development Phenomenon: An Analysis Based on Social Network Theory	Gregory Madey, Vincent Freeh, Renee Tynan	2002	342
The role of communication and trust in global virtual teams: A social network perspective	Saonee Sarker, Manju K. Ahuja, Suprateek Sarker, Sarah Kirkeby	2011	313
Latent social structure in open source projects	Christian Bird, David Pattison, Raissa D’Souza, Vladimir Filkov, Premkumar Devanbu	2008	301
Socio-Technical Congruence: A Framework for Assessing the Impact of Technical and Work Dependencies on Software Development Productivity	Marcelo Cataldo, James D. Herbsleb, Kathleen M. Carley	2008	300
Emergence of New Project Teams from Open Source Software Developer Networks: Impact of Prior Collaboration Ties	Jungpil Hahn, Jae Y. Moon, Chen Zhang	2008	296
Can developer-module networks predict failures?	Martin Pinzger, Nachiappan Nagappan, Brendan Murphy	2008	243
Predicting failures with developer networks and social network analysis	Andrew Meneely, Laurie Williams, Will Snipes, Jason Osborne	2008	241
Self-organization of teams for free/libre open source software development	Kevin Crowston, Qing Li, Kangning Wei, U. Y. Eseryel, James Howison	2007	240
Recommending collaboration with social networks: A comparative evaluation	David W. McDonald	2003	226
Codebook: discovering and exploiting relationships in software repositories	Andrew Begel, Yit P. Khoo, Thomas Zimmermann	2010	222
Predicting build failures using social network analysis on developer communication	Timo Wolf, Adrian Schröter, Daniela Damian, Thanh H.D. Nguyen	2009	217
Awareness in the Wild: Why Communication Breakdowns Occur	Daniela Damian, Luis Izquierdo, Janice Singer, Irwin Kwan	2007	214
Structures that work: social structure, work structure and coordination ease in geographically distributed teams	Pamela Hinds, Cathleen McGrath	2006	209
Applying social network analysis to the information in CVS repositories	Luis Lopez-Fernandez, Gregorio Robles, Jesus M. Gonzales-Barahona	2004	207
Core and Periphery in Free/Libre and Open Source Software Team Communications	Kevin Crowston, Kangning Wei, Qing Li, James Howison	2006	204
Hierarchy and centralization in free and open source software team communications	Kevin Crowston, James Howison	2006	200
A Topological Analysis of the Open Source Software Development Community	Jin Xu, Yongqin Gao, Scott Christley, Gregory Madey	2005	198
Putting It All Together: Using Socio-technical Networks to Predict Failures	Christian Bird, Nachiappan Nagappan, Harald Gall, Brendan Murphy, Premkumar Devanbu	2009	197
4.6. Influential authors
We identified 481 different authors who contributed to the literature on DSNs. We use a bibliometric approach to identify the most influential of these authors, based on three different indicators: (1) the number of citations of all publications on DSNs; (2) the number of publications on DSNs; and (3) the number of publications on DSNs we identified as influential (Section 4.5). We consider the top-5 authors in each category to be the most influential. For the bibliometric data we collected, this means that an author has to have at least 1397 citations, 8 publications, or 3 influential publications to be considered as one of the most influential authors.

Table 7 shows the nine most influential authors we identified according to these criteria. Below, we briefly summarize the research directions of the influential authors. We discuss authors that frequently collaborated with each other as a group.

•
James D. Herbsleb and Kathleen M. Carley are co-authors of three influential publications as well as several other publications. Herbsleb and Carley are both professors at Carnegie Mellon University. Their work covers structures and collaboration in global software engineering as well as socio-technical congruence within projects.

•
Premkumar Devanbu was the PhD advisor of Christian Bird, who wrote his dissertation on DSNs. Their work addressed social structures and openness of open source projects, as well as build failure prediction.

•
Kevin Crowston was the PhD advisor of James Howison, who wrote his dissertation on DSNs. Their work addressed community structures for open source software development.

•
Daniela Damian collaborated with different authors as part of her work on communication between developers from different perspectives.

•
Gregory Madey was the lead author of the first paper on DSNs we identified. He enabled many early papers through the SourceForge Research Data Archive (Van Antwerp and Madey, 2008).

•
Vladimir Filkov contributed to different aspects, including homophily, developer initiation into projects, communication behavior, as well as general structural aspects of DSNs.



Download : Download high-res image (88KB)
Download : Download full-size image
4.7. Important venues
The identified papers were published in 118 different venues, i.e., journals, conferences, and workshops. Table 8 lists the venues at which most papers on DSNs were published. Three conferences stand out: the International Conference on Open Source Software (OSS), the International Conference on Software Engineering (ICSE), and the International Conference on Mining Software Repositories (MSR). 18% of all papers on DSNs were published at these three venues. This is not surprising, as most publications analyze open source projects or ecosystems and employ software repository mining techniques. The ICSE is the top conference in the software engineering field, which highlights that there are papers of outstanding quality on DSNs. We note that the venues with most publications are mostly conferences, which is in line with the general conference-centered publication system of computer science research. The only three journals that made it into this list are Empirical Software Engineering, Information and Software Technology and the Journal of Systems and Software. However, there are also publications in other premier journals, e.g., the IEEE Transactions on Software Engineering (Kwan et al., 2011, Herbsleb and Mockus, 2003, Lim and Finkelstein, 2012, Catolino et al., 2019), ACM Transactions on Software Engineering Methodology (Singh, 2010), Management Information Systems Quarterly (Singh et al., 2011), and PLOS ONE (Xuan et al., 2016, Sapkota et al., 2020).


Table 8. Most important publication venues determined by the number of papers published. We omitted labels like IEEE, ACM, or similar from the conference names, as they often changed slightly throughout the years.

Venue	#Pubs.
International Conference on Software Engineering (ICSE)	17
International Conference on Open Source Software (OSS)	16
International Conference on Mining Software Repositories (MSR) (Workshop until 2007, Working Conference until 2015)	15
Conference on Computer Supported Cooperative Work (CSCW)	10
International Conference on the Foundations of Software Engineering (FSE)	8
Hawaii International Conference on System Sciences (HICSS)	8
Asia-Pacific Software Engineering Conference (APSEC)	8
Empirical Software Engineering, Springer	7
International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)	7
Information and Software Technology, Elsevier	6
Journal of Systems and Software (JSS)	5
International Conference on Global Software Engineering (ICGSE)	5
International Conference on Software Maintenance and Evolution (ICSME) (ICSM until 2013)	5
4.8. Interest over time
Another interesting aspect is the interest of researchers with respect to DSNs over time measured by the number of publications per year. Fig. 4 depicts the total number of publications per year since the initial publication by Madey et al. (2002) in 2002. The topic quickly gained traction in the research community with rising numbers of publications until the interest became steady with 11 to 21 publications per year between 2005 and 2018. However, there seems to be a slight decline in the interest in DSNs since 2014. We note that due to the time of our search, the data for 2020 (and possibly 2019) is incomplete.

Fig. 5 shows a heat map of the research directions over time. The interest in the general structure of DSNs has been steadily high over time. For all research directions, we see a fairly steady interest in the years 2005 to 2013. From 2013 onwards, the decline in overall interest in DSNs is also reflected in a more erratic interest in specific research directions. The most notable decline since 2013 is regarding global software engineering and tools, for which there are no publications anymore, even though the interest before was fairly high. Another important aspect is regarding the recent research, i.e., the years 2018 onwards. We note that the diversity of the research topics for which DSNs are used has declined, i.e., the ongoing research currently seems to be focused on community structures and predictive usages of DSNs. However, we see that there are still new topics emerging, i.e., the analysis of community smells (Palomba et al., 2018, Catolino et al., 2019).



Download : Download high-res image (64KB)
Download : Download full-size image
5. Discussion of open issues
Our mapping study shows that DSNs are a versatile method for software engineering research. Mostly, they are used for the analysis of social structures and communication. However, the applications of DSNs range beyond that, e.g., for predictive purposes. Within this section, we discuss open problems in DSN research.

5.1. General issues
Here, we discuss general issues within the current body of work on DSNs, that should be addressed by future work.

5.1.1. Lack of guidelines
There are no guidelines on how to conduct DSN research. Therefore, the studies on DSNs are performed and described very heterogeneously. This is not an issue in itself, as heterogeneity can also be positive if different aspects are analyzed. Moreover, many publications perform well-designed case studies and report all important data regardless of the lack of guidelines. However, we observed several issues that result from the inconsistent way studies with DSNs are performed:

•
lack of reporting of the exact data sources and/or selection criteria for case study subjects;

•
lack of reporting of important meta data about the study, e.g., number of projects, number of people; and

•
lack of reporting of pre-processing steps performed with the data, e.g., to merge identities in case the same people used multiple aliases.

The development of guidelines for research on DSNs can, therefore, help to enhance the quality of DSN research in general.

5.1.2. Studies with high external validity
Our data shows that many results regarding DSNs were obtained only on very few projects, i.e., over 69% of the publications used less than 11 projects to conduct their research. While this does not mean that the results are wrong or would not generalize to other contexts, this poses a threat to the generalizability of results, as such small samples can only represent populations with a limited context. This problem is to some degree further aggravated, because there is an overlap in the data that is used, i.e., multiple studies using the same data, sometimes the same single project (e.g., IBM Jazz or the Global Studio Project). Moreover, we noted a strong relation between the data sources and the size of studies. Fig. 6 shows the size of the studies with relation to the data source. The larger circles mean more publications. Almost all publications with large numbers of people and projects were based on data from forges. Thus, an open issue considered for all future publications is to use larger sample sizes regarding the number of projects, to enable a better generalizability of results. This could either be done by harnessing data from forges or by collecting data for more projects from other data sources.


Download : Download high-res image (136KB)
Download : Download full-size image
Fig. 6. Relationship between study sizes and data sources.

5.1.3. Lack of replications
There is general lack of replications in DSN research. The publications are more or less independent of each other, the exception being multiple publications by the same authors building on each other. We did not find any study that explicitly tried to replicate prior results. The lack of replications is especially problematic due to the often very small numbers of projects considered (see above). Thus, we believe that replication studies on DSN research are required for all research directions so far.

5.2. Open topics
Here, we discuss potential future directions of DSN research.

5.2.1. Inter-company collaborations
Since more and more companies contribute to open source software and/or develop their own software products as open source, the collaboration between developers of competing companies becomes an important issue. If developers from competing organizations contribute to the same project, this could lead to issues within a project, that could be analyzed through DSNs, e.g., with respect to team formation, onboarding, collaboration problems, and even impacts on the socio-technical congruence of projects. Within our mapping study, we only discovered one publication in this direction (Teixeira et al., 2015).

5.2.2. DSNs from multiple sources
The use of multiple sources for DSN studies allows a deeper analysis of developer communities. For example, how does the community on a ML differ from the community that can be observed in pull request discussions or in an ITS? Can we infer something about onboarding of developers from their integration in different DSNs? Do projects that use an ITS and a ML exhibit different collaboration properties than projects that just use an ITS or a ML? What exactly is the temporal–spatial relationship between the DSN structures of different sources? Does research regarding the team formation of projects based on MLs yield the same results as research on team formation on ITSs? How does migration to a new ITS affect the community structure? All of these are currently open questions. Especially the comparison of DSNs that are based on different data sources has been neglected so far, with only a single publication that directly compares the DSN structure obtained from ITS data with that obtained from VCS data (Aljemabi and Wang, 2017).

5.2.3. Diversity in DSNs
The role of gender and other issues related to diversity is an important recent trend in current software engineering research. There is already one recent publication that touches on the relation between gender and DSNs (Catolino et al., 2019). We believe that insights into the question if and how gender or other diversity related features impact DSNs can give researchers and practitioners valuable insights that may help to make software engineering both more inclusive and more effective.

5.2.4. Applications using DSNs
The current literature on DSNs has a strong focus on understanding community structures and the implications of the community structure on issues like developer roles, team formation, and collaboration behavior. However, there are only relatively few actionable applications of DSNs. CodeBook (Begel et al., 2010) is a notable exception that demonstrates how DSNs can be used to improve the daily life of software developers. While other publications also study applications of DSNs, e.g., for defect prediction, failure prediction, or developer recommendations, they are mostly not accompanied by a tool that makes the research actionable for practitioners. The tool papers that we identified cover mostly the visualization of DSNs. While visualizations are a useful tool for the analysis of communities, they are not actionable applications of DSNs. We believe that research that produces actionable tools can have a big impact, e.g., on already considered issues like bug triage or developer recommendations.

5.2.5. Data sets
We only identified a single publication that published a DSN as data set. While there are other publications that are based on public data sets, e.g., the source forge dump (Van Antwerp and Madey, 2008), these data sets are not yet DSNs. They only contain the data necessary to create a DSN. While there are certainly use cases, in which new DSNs must be created, e.g., because different information is used to create links between developers, there are also cases for which dedicated data sets on DSNs would have advantages. For example, benchmark data sets could allow, e.g., to compare different approaches for developer recommendation or the identification of core developers. Moreover, the collection of data from a large amount of software repositories can be very time consuming. Data sets for a large amount of projects could help with this issue, and, e.g., enable larger studies with MLs as sources for projects.

6. Related work
Our systematic mapping study is not the first literature study that covers DSNs. Within this section, we discuss related literature studies on DSNs, their differences to our work, and how we utilized them as sanity checks for our work.

Closest to our work is the survey by Zhang et al. (2014a). Similar to our work, the authors analyzed the data sources, as well as topics that were addressed with DSNs. However, there are several notable differences between the work by Zhanget al. and our work. First, the search strategy by Zhanget al. is different from ours. They used the search term “developer network” and identified 20 publications related to DSNs within the first 50 hits on Google Scholar. Using these publications as seed, the authors performed one round of forward/backward snowballing and identified a total of 86 primary studies this way. Due to this limited search, the authors only identified a limited body of the relevant literature. In comparison, we use more search terms and multiple search engines, consider 750 instead of 50 hits per search term/search engine, and performed exhaustive backward and forward snowballing until no further papers were identified, and performed an exhaustive search with Scopus. Moreover, the focus of the presentation and focus of the work from Zhanget al. differs from ours. We provide a systematic mapping of approaches to topics through inductive coding, i.e., are interested in the general topics and trends that are analyzed. In comparison, Zhanget al. provide a more detailed description of different approaches to address research topics, but do not systematically map publications into different categories. However, we used the description of research topics described by Zhanget al. as starting point for our inductive coding, but identified additional topics, e.g., global software engineering, team formation, inter-company collaboration behavior, and developer onboarding. Another difference to our work is that Zhanget al. also report on the metrics that were used for the analysis of the DSN, an aspect that is not covered by our mapping study.

The literature study by Tamburri et al. (2013) uses grounded theory to identify different types of social structures within open source software development. Thus, their focus is different from ours, which is on DSNs in general, not on social structures. However, DSNs play an important role in the study by Tamburriet al. and are part of the literature that they identify. Our inductive coding approach is in principle similar to the approach used by Tamburriet al. in the sense that we inductively infer the relevant concepts from the identified publications. However, the goal was completely different, i.e., we wanted to identify research topics instead of types of organizational structures. Thus, while we identify broad topics of research, Tamburriet al. identified detailed information for the topic of social and collaboration structures. Due to the different focus, the search strategies also differ. Most importantly, the search by Tamburriet al. also covers search terms like “organizational”, “knowledge community” and similar to account for the different focus. Moreover, the search engines used are different from ours. They used Web of Science, EBSCO, JSTOR knowledge storage, Wiley InterScience and ProQuest in addition to the search engines we used. On the other hand, we used Google Scholar, which was not used by Tamburriet al.. The authors identified 143 publications for their study.

Manteli et al. (2012) performed a literature study to analyze DSNs with respect to global software development. Their focus was on coordination, cooperation, and communication aspects of global software development. This scope of this survey is narrower than our mapping study of DSNs without further restrictions. Thus, while we identify broad topics of research, Manteliet al. identified detailed information for the DSNs in global software engineering. This shows in the difference in search terms and inclusion criteria. Moreover, there is a difference in search engines used. Manteliet al. used EBSCO and Wiley InterScience in addition to the engines we used, but did not use Google Scholar. The authors identified 23 primary studies on DSNs with a relation to global software development.

Abufouda and Abukwaik (2017) performed a systematic literature review on DSNs with the goal to identify how reliable constructed social networks are. This goal is different from our general focus, which shows, e.g., in the different exclusion criteria. The authors used the same search engines we also used, with the exception of Google Scholar and SCOPUS which were not considered. The authors identify 23 primary studies that meet the criteria for their survey. The data the authors collected is very detailed with respect to the required description of the model and covers aspects like vertex types, edge types, and validation criteria. Thus, the work by Abufouda and Abuwaik focuses on evaluating aspects related to the internal validity of studies. In comparison, we collect data related to the external validity of DSN studies in our work, i.e., the scope of the analysis that is conducted.

In addition to our comparison with related work above, there are several differences between our work and all the related literature. No other work performed a bibliometric assessment of influential authors, papers, and venues or the trends over time. Moreover, no work in the literature provides information about the scope of the networks, i.e., the number of projects and participants that are analyzed through DSNs in a publication. Therefore, none of the prior literature studies provides answers to our research questions RQ3–RQ5. Additionally, as discussed above, none of the works provides a complete or systematic mapping of research topics which could be used to answer RQ1 or empirical data to support the answer for RQ2. Overall, our work goes well beyond the currently available literature studies on DSNs, both in terms of identified publications as well as due to the research questions we address.

7. Conclusion
This article presents the results of our systematic mapping study on DSNs. We identified 255 primary studies published between 2002 and 2020. Our results show that DSNs were used for the analysis of many different software engineering research topics since their initial use in the year 2002 (Madey et al., 2002), e.g., the analysis of community structures, the creation or improvement of prediction models, the study of collaboration behavior, and the identification of developer roles within projects. Moreover, we found that the social networks are often modeled based on data collected from a single repository, e.g., a forge like GitHub or SourceForge, version control systems like Git or SVN, issue tracking systems like Jira or Bugzilla, or mailing lists. A few notable exceptions use on-site observation centric techniques instead of data from software repositories. We observed a tendency that many publications only use a small set of sample projects, which may inhibit the generalizability of findings. Related to this is a general lack of replications within the body of work, i.e., we did not find a single replication study. Through a bibliometric assessment we found that there are many highly cited papers on DSNs on a diverse set of topics, which highlights the many use cases for DSNs in software engineering research. Our data shows that the interest in DSNs in research is still high, though there is a slight declining trend in recent years after the interest peaked in 2014.

Based on our findings, we suggest that future research addresses aspects that were neglected so far, e.g., inter-company collaborations (Teixeira et al., 2015), practical applications of DSNs (Begel et al., 2010), and the relationship between social network structures and diversity (Catolino et al., 2019). Moreover, we believe that replication studies can help to address the question if current results from the state of the art generalize beyond the often relatively small set of projects that were used in many publications.

