Inexact (or approximate) computing is an attractive paradigm for digital processing at nanometric scales. Inexact computing is particularly interesting for computer arithmetic designs. This paper deals with the analysis and design of two new approximate 4-2 compressors for utilization in a multiplier. These designs rely on different features of compression, such that imprecision in computation (as measured by the error rate and the so-called normalized error distance) can meet with respect to circuit-based figures of merit of a design (number of transistors, delay and power consumption). Four different schemes for utilizing the proposed approximate compressors are proposed and analyzed for a Dadda multiplier. Extensive simulation results are provided and an application of the approximate multipliers to image processing is presented. The results show that the proposed designs accomplish significant reductions in power dissipation, delay and transistor count compared to an exact design; moreover, two of the proposed multiplier designs provide excellent capabilities for image multiplication with respect to average normalized error distance and peak signal-to-noise ratio (more than 50 dB for the considered image examples).
SECTION I.Introduction
Most computer arithmetic applications are implemented using digital logic circuits, thus operating with a high degree of reliability and precision. However, many applications such as in multimedia and image processing can tolerate errors and imprecision in computation and still produce meaningful and useful results. Accurate and precise models and algorithms are not always suitable or efficient for use in these applications. The paradigm of inexact computation relies on relaxing fully precise and completely deterministic building modules when, for example, designing energy-efficient systems. This allows imprecise computation to redirect the existing design process of digital circuits and systems by taking advantage of a decrease in complexity and cost with possibly a potential increase in performance and power efficiency. Approximate (or inexact) computing relies on using this property to design simplified, yet approximate circuits operating at higher performance and/or lower power consumption compared with precise (exact) logic circuits [1].

Addition and multiplication are widely used operations in computer arithmetic; for addition full-adder cells have been extensively analyzed for approximate computing [2]–[3][4]. Liang et al. [1] has compared these adders and proposed several new metrics for evaluating approximate and probabilistic adders with respect to unified figures of merit for design assessment for inexact computing applications. For each input to a circuit, the error distance (ED) is defined as the arithmetic distance between an erroneous output and the correct one [1]. The mean error distance (MED) and normalized error distance (NED) are proposed by considering the averaging effect of multiple inputs and the normalization of multiple-bit adders. The NED is nearly invariant with the size of an implementation and is therefore useful in the reliability assessment of a specific design. The tradeoff between precision and power has also been quantitatively evaluated in [1].

However, the design of approximate multipliers has received less attention. Multiplication can be thought as the repeated sum of partial products; however, the straightforward application of approximate adders when designing an approximate multiplier is not viable, because it would be very inefficient in terms of precision, hardware complexity and other performance metrics. Several approximate multipliers have been proposed in the literature [4]–[5][6][7]. Most of these designs use a truncated multiplication method; they estimate the least significant columns of the partial products as a constant. In [4], an imprecise array multiplier is used for neural network applications by omitting some of the least significant bits in the partial products (and thus removing some adders in the array). A truncated multiplier with a correction constant is proposed in [5]. For an n×n multiplier, this design calculates the sum of the n+k most significant columns of the partial products and truncates the other n−k columns. The n+k bit result is then rounded to n bits. The reduction error (i.e., the error generated by truncating the n−k least significant bits) and rounding error (i.e., the error generated by rounding the result to n bits) are found in the next step. The correction constant (n+k bits) is selected to be as close as possible to the estimated value of the sum of these errors to reduce the error distance.

A truncated multiplier with constant correction has the maximum error if the partial products in the n−k least significant columns are all ones or all zeros. A variable correction truncated multiplier has been proposed in [6]. This method changes the correction term based on column n−k−1. If all partial products in column n−k−1 are one, then the correction term is increased. Similarly, if all partial products in this column are zero, the correction term is decreased.

In [7], a simplified (and thus inaccurate) 2×2 multiplier block is proposed for building larger multiplier arrays. In the design of a fast multiplier, compressors have been widely used [8]–[9][10] to speed up the partial product reduction tree and decrease power dissipation. Optimized designs of 4-2 exact compressors have been proposed in [8]–[11][12][13][14][15][16]. Kelly et al. [17] and Ma et al.[18] have also considered compression for approximate multiplication. In [17], an approximate signed multiplier has been proposed for use in arithmetic data value speculation (AVDS); multiplication is performed using the Baugh-Wooley algorithm. However, no new design is proposed for the compressors for the inexact computation. Designs of approximate compressors have been proposed in [18]; however, these designs do not target multiplication. It should be noted that the approach of [7] improves over [17] [18] by utilizing a simplified multiplier block that is amenable to approximate multiplication.

Initially in this paper, two novel approximate 4-2 compressors are proposed and analyzed. It is shown that these simplified compressors have better delay and power consumption than the optimized (exact) 4-2 compressor designs found in the technical literature [8]. These approximate compressors are then used in the restoration module of a Dadda multiplier; four different schemes are proposed for inexact multiplication. Extensive simulation results are provided at circuit-level for figures of merit, such as delay, transistor count, power dissipation, error rate and normalized error distance under CMOS feature sizes of 32, 22 and 16 nm. The application of these multipliers to image processing is then presented. The results of two examples of multiplication of two images are reported; these results show that the third and fourth approximate multipliers yield an output product image that has a very high quality and resemblance to the image generated by an exact multiplier, i.e., excellent values for the average NED and the peak signal-to-noise ratio (PSNR) are found (for the PSNR more than 50db). The analysis and simulation results show that the proposed approximate designs for both the compressor and the multiplier are viable candidates for inexact computing.

This paper is organized as follows. Section 2 is a review of existing schemes for (exact) compressors. The two new designs of an approximate 4-2 compressor are presented in Section 3. Multiplication and four different approximate multipliers are proposed in Section 4. Simulation results for the approximate compressors and multipliers are provided in Section 5. The application of the proposed approximate multipliers to image processing is presented in Section 6. Section 7 concludes the manuscript.

SECTION II.Exact Compressors
The main goal of either multi-operand carry-save addition or parallel multiplication is to reduce n numbers to two numbers; therefore, n−2 compressors (or n−2 counters) have been widely used in computer arithmetic. A n−2 compressor (Fig. 1) is usually a slice of a circuit that reduces n numbers to two numbers when properly replicated. In slice i of the circuit, the n−2 compressor receives n bits in position i and one or more carry bits from the positions to the right, such as i – 1 or i – 2. It produces two output bits in positions i and i + 1 and one or more carry bits into the higher positions, such as i + 1 or i + 2. For the correct operation of the circuit shown in Fig. 1, the following inequality must be satisfied
n+ψ1+ψ2+ψ3+⋯≤3+2ψ1+4ψ2+8ψ3+…,(1)
View Source


Fig. 1.
Schematic diagram of n−2 compressors in a multi operand addition circuit [13].

Show All

where ψj denotes the number of carry bits from slice i to slice i+j.
A widely used structure for compression is the 4-2 compressor; a 4-2 compressor (Fig. 2) can be implemented with a carry bit between adjacent slices (ψ1=1). The carry bit from the position to the right is denoted as cin while the carry bit into the higher position is denoted as cout. The two output bits in positions i and i + 1 are also referred to as the sum and carry respectively.

Fig. 2. - $4-2$ compressor.
Fig. 2.
4−2 compressor.

Show All

The following equations give the outputs of the 4-2 compressor, while Table 1 shows its truth table.
Sum=x1⊕x2⊕x3⊕x4⊕Cin(2)
View Source
Cout=(x1⊕x2)x3+(x1⊕x2)¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯x1(3)
View Source
Carry=(x1⊕x2⊕x3⊕x4)Cin+(x1⊕x2⊕x3⊕x4)¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯x4.(4)
View Source

Table 1 Truth table of 4-2 compressor

The common implementation of a 4-2 compressor is accomplished by utilizing two full-adder (FA) cells (Fig. 3) [8]. Different designs have been proposed in the literature for 4-2 compressor [8]–[11][12][13][14][15][16].


Fig. 3.
Implementation of 4-2 compressor.

Show All

Fig. 4 shows the optimized design of an exact 4-2 compressor based on the so-called XOR-XNOR gates [8]; a XOR-XNOR gate simultaneously generates the XOR and XNOR output signals. The design of [8] consists of three XOR-XNOR (denoted by XOR∗) gates, one XOR and two 2-1 MUXes. The critical path of this design has a delay of 3Δ, where Δ is the unitary delay through any gate in the design.


Fig. 4.
Optimized 4-2 compressor of [8].

Show All

SECTION III.Proposed Approximate Compressors
In this section, two designs of an approximate compressor are proposed. Intuitively to design an approximate 4-2 compressor, it is possible to substitute the exact full-adder cells in Fig. 3 by an approximate full-adder cell (such as the first design proposed in [2]). However, this is not very efficient, because it produces at least 17 incorrect results out of 32 possible outputs, i.e., the error rate of this inexact compressor is more than 53 percent (where the error rate is given by the ratio of the number of erroneous outputs over the total number of outputs). Two different designs are proposed next to reduce the error rate; these designs offer significant performance improvement compared to an exact compressor with respect to delay, number of transistors and power consumption.

A. Design 1
As shown in Table 1, the carry output in an exact compressor has the same value of the input cin in 24 out of 32 states. Therefore, an approximate design must consider this feature. In Design 1, the carry is simplified to cin by changing the value of the other eight outputs.
Carry′=Cin.(5)
View Source

Since the Carry output has the higher weight of a binary bit, an erroneous value of this signal will produce a difference value of two in the output. For example, if the input pattern is “01001” (row 10 of Table 2), the correct output is “010” that is equal to 2. By simplifying the carry output to cin, the approximate compressor will generate the “000” pattern at the output (i.e., a value of 0). This substantial difference may not be acceptable; however, it can be compensated or reduced by simplifying the cout and sum signals. In particular, the simplification of sum to a value of 0 (second half of Table 2) reduces the difference between the approximate and the exact outputs as well as the complexity of its design. Also, the presence of some errors in the sum signal will results in a reductions of the delay of producing the approximate sum and the overall delay of the design (because it is on the critical path).
Sum′=Cin¯¯¯¯¯¯¯¯¯(x1⊕x2¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯+x3⊕x4¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯).(6)
View Source

Table 2 Truth table of the first approximate 4-2 compressor

In the last step, the change of the value of cout in some states, may reduce the error distance provided by approximate carry and sum and also more simplification in the proposed design.
Cout′=(x1¯¯¯¯¯x2¯¯¯¯¯+x3¯¯¯¯¯x4¯¯¯¯¯)¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯.(7)
View Source

Although the above mentioned simplifications of carry and sum increase the error rate in the proposed approximate compressor, its design complexity and therefore the power consumption are considerably decreased. This can be realized by comparing (2)-(4) and (5)-(7). Table 2 shows the truth table of the first proposed approximate compressor. It also shows the difference between the inexact output of the proposed approximate compressor and the output of the exact compressor. As shown in Table 2, the proposed design has 12 incorrect outputs out of 32 outputs (thus yielding an error rate of 37.5 percent). This is less than the error rate using the best approximate full-adder cell of [2].

Table 3 Truth table of second proposed 4-2 compressor

Equations (5)-(7) are the logic expressions for the outputs of the first design of the approximate 4-2 compressor proposed in this manuscript.

The gate level structure of the first proposed design (Fig. 6) shows that the critical path of this compressor has still a delay of 3Δ, so it is the same as for the exact compressor of Fig. 5. However, the propagation delay through the gates of this design is lower than the one for the exact compressor. For example, the propagation delay in the XOR* gate that generates both the XOR and XNOR signals in [8], is higher than the delay through a XNOR gate of the proposed design.

Therefore, the critical path delay in the proposed design is lower than in the exact design and moreover, the total number of gates in the proposed design is significantly less than that in the optimized exact compressor of [8].


Fig. 5.
Optimized 4-2 compressor of [6].

Show All


Fig. 6.
Gate level implementation of design 1.

Show All

B. Design 2
A second design of an approximate compressor is proposed to further increase performance as well as reducing the error rate. Since the carry and cout outputs have the same weight, the proposed equations for the approximate carry and cout in the previous part can be interchanged. In this new design, carry uses the right hand side of (7) and cout is always equal to cin; since cin is zero in the first stage, cout and cin will be zero in all stages. So, cin and cout can be ignored in the hardware design. Fig. 7 shows the block diagram of this approximate 4-2 compressor and the expressions below describe its outputs.
Sum′=(x1⊕x2¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯+x3⊕x4¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯)(8)
View Source
Carry′=(x1¯¯¯¯¯x2¯¯¯¯¯+x3¯¯¯¯¯x4¯¯¯¯¯)¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯.(9)
View Source


Fig. 7.
Approximate 4-2 compressor, design 2.

Show All

Note that (9) is the same as (7) and (8) is the same as (6) for cin=0. Fig. 8 shows the gate level implementation of the second proposed design. The delay of the critical path of this approximate design is 2Δ, so it is 1Δ less than the previous designs; moreover, a further reduction in the number of gates is accomplished.


Fig. 8.
Gate level implementation of design 2.

Show All

Table 3 shows the truth table of the second approximate design for a 4-2 compressor; this Table also shows the difference between the exact decimal value of the addition of the inputs and the decimal value of the outputs produced by the approximate compressor. For example when all inputs are 1, the decimal value of the addition of the inputs is 4. However, the approximate compressor produces a 1 for the carry and sum. The decimal value of the outputs in this case is 3; Table 2 shows that the difference is –1.

This design has therefore four incorrect outputs out of 16 outputs, so its error rate is now reduced to 25 percent. This is a very positive feature, because it shows that on a probabilistic basis, the imprecision of the proposed design is smaller than the other available schemes.

SECTION IV.Multiplication
In this section, the impact of using the proposed compressors for multiplication is investigated. A fast (exact) multiplier is usually composed of three parts (or modules) [8].

Partial product generation.

A carry save adder (CSA) tree to reduce the partial products’ matrix to an addition of only two operands.

A carry propagation adder (CPA) for the final computation of the binary result.

In the design of a multiplier, the second module plays a pivotal role in terms of delay, power consumption and circuit complexity. Compressors have been widely used [9] [10] to speed up the CSA tree and decrease its power dissipation, so to achieve fast and low-power operation. The use of approximate compressors in the CSA tree of a multiplier results in an approximate multiplier.

A 8 × 8 unsigned Dadda tree multiplier is considered to assess the impact of using the proposed compressors in approximate multipliers. The proposed multiplier uses in the first part AND gates to generate all partial products. In the second part, the approximate compressors proposed in the previous section are utilized in the CSA tree to reduce the partial products. The last part is an exact CPA to compute the final binary result. Fig. 9a shows the reduction circuitry of an exact multiplier for n=8. In this figure, the reduction part uses half-adders, full-adders and 4-2 compressors; each partial product bit is represented by a dot. In the first stage, two half-adders, two full-adders and eight compressors are utilized to reduce the partial products into at most four rows. In the second or final stage, 1 half-adder, 1 full-adder and 10 compressors are used to compute the two final rows of partial products. Therefore, two stages of reduction and three half-adders, three full-adders and 18 compressors are needed in the reduction circuitry of an 8 × 8 Dadda multiplier.


Fig. 9.
Reduction circuitry of an 8 × 8 dadda multiplier, (a) using design 1 compressors, (b) using design 2 compressors.

Show All

In this paper, four cases are considered for designing an approximate multiplier.

In the first case (Multiplier 1), Design 1 is used for all 4-2 compressors in Fig. 9a.

In the second case (Multiplier 2), Design 2 is used for the 4-2 compressors. Since Design 2 does not have cin and cout, the reduction circuitry of this multiplier requires a lower number of compressors (Fig. 9b). Multiplier 2 uses six half-adders, one full-adder and 17 compressors.

In the third case (Multiplier 3), Design 1 is used for the compressors in the n−1 least significant columns. The other n most significant columns in the reduction circuitry use exact 4-2 compressors.

In the fourth case (Multiplier 4), Design 2 and exact 4-2 compressors are used in the n−1 least significant columns and the n most significant columns in the reduction circuitry respectively.

The objectives of the first two approximate designs are to reduce the delay and power consumption compared with an exact multiplier; however, a high error distance is expected. The next two approximate multipliers (i.e., Multipliers 3 and 4) are proposed to decrease the error distance. The delay in these designs is determined by the exact compressors that are in the critical path; therefore, there is no improvement in delay for these approximate designs compared with an exact multiplier. However, it is expected that the utilization of approximate compressors in the least significant columns will decrease the power consumption and transistor count (as measure of circuit complexity). While the first two proposed multipliers have better performance in terms of delay and power consumption, the error distances in the third and fourth designs are expected to be significantly lower.

SECTION V.Simulation Results
In this section, he designs of the two approximate compressors (Section 3) and the four approximate multipliers (Section 4) are simulated using HSPICE. Predictive technology models (PTMs) at different CMOS feature sizes (32, 22 and 16 nm) are utilized in the HSPICE simulation.

A. Approximate Compressors
The two approximate compressors of this paper and the best low-power exact compressor of [8] (implemented by using XOR-XNOR gates) are simulated at a 1 GHz frequency; a fan-out of four is utilized in all simulations. The simulation results of the delay, power consumption and power-delay product (PDP) are given in Table 4 by using the PTMs at 32, 22 and 16 nm.

Table 4 Simulation results (@32 nm)

As expected, the second proposed design (Design 2) has the best delay, power consumption and PDP; these improvements are irrespective of feature size. This approximate design is 62 percent faster than the exact compressor at 16 nm CMOS technology and 44 percent faster on average for the three feature sizes considered. Moreover on average, Design 2 is also 35 percent faster than Design 1. The two proposed approximate designs achieve significant improvement in terms of power consumption; on average at different feature sizes, the power consumption of Design 1 is 57 percent less than the exact compressor, while Design 2 has a power consumption that is 60 percent less than the exact design of [8].

Table 5 compares these designs in terms of number of transistors, as a measure of circuit complexity. The exact compressor [8] uses 10 transistors to implement each XOR* gate, six transistors to implement the XOR gate and eight transistors to implement each MUX gate [8]; therefore, the exact compressor utilizes 52 transistors. A 50 percent improvement in circuit complexity is accomplished by Design 2, as reflected by the lower number of transistors. This is expected because the second approximate design has no cin and cout with only four inputs and two outputs (the exact compressor has five inputs and three outputs).

Table 5 Comparison of number of transistors

B. Approximate Multipliers
The four proposed approximate multipliers are simulated for n = 8. The delay, power consumption and number of transistors are investigated for these approximate designs as well as the exact multiplier. A comparison of the error distance (as measure of reliability [1]) of the proposed multipliers with other approximate multipliers is also pursued.

1. Delay
The delay of the reduction circuitry (second module) of a Dadda multiplier is dependent on the number of reduction stages and the delay of each stage. In Multipliers 1 and 2, the approximate compressors are used in all columns; therefore, the delay of the stages is equal to the delay of the approximate compressors. However, in Multipliers 3 and 4, the delay of the stages is equal to the delay of the exact compressors. So, the use of these approximate compressors in the n/2 LSBs cause no improvement in terms of delay compared to an exact multiplier. The delay improvement in the reduction circuitry of each multiplier (at 32 nm CMOS technology) compared to an exact adder is shown in Table 6.

Table 6 Delay improvement in reduction circuitry

2. Power Consumption
The power consumption of each multiplier is determined by the number and type of compressors used. Multipliers 1 and 2 use only approximate compressors so they have power consumption lower than Multipliers 3 and 4. Table 7 shows the power consumption improvement of each multiplier at 32 nm feature size with respect to an exact adder; this confirms that an approximate multiplier in the reduction circuitry will result in a considerable power saving.

Table 7 Power consumption improvement in reduction circuitry

3. Transistor Count
The transistor count is used in this paper as metric of circuit complexity. The first two approximate multipliers have a lower transistor count compared with Multipliers 3 and 4. Table 8 shows the transistor count improvement of the reduction circuitry of each multiplier compared to an exact adder.

Table 8 Transistor count improvement in reduction circuitry

4. Error Distance
Four additional approximate multipliers are simulated to compare the error distance. The multiplier (Multiplier 5) proposed in [7] is simulated for n=8. The truncated multiplier with constant correction [5] (Multiplier 6) and the truncated multiplier with variable correction [6] (Multiplier 7) are also simulated for n=8 and k=1. A further approximate multiplier (Multiplier 8) is simulated to investigate the impact of using the proposed approximate compressors compared with other approximate compressors. This 8 × 8 Dadda multiplier uses 4-2 compressors made of two approximate full-adders (Fig. 3). The first full-adder design proposed in [2] is used in this approximate multiplier. Table 9 summarizes the eight approximate multipliers assessed in this manuscript, i.e., the four proposed designs and the other four approximate multipliers together with their salient features.

Table 9 Approximate multipliers and their features

The normalized error distance is used to compare these approximate multipliers. In [1], the NED is defined as the average error distance over all inputs, normalized by the maximum possible error. In this paper the NED is defined for each input. Therefore the average NED is equivalent to the NED defined in [1]. The maximum high (low) NED is also defined as the largest absolute value of NED for the case in which the erroneous result is more (less) than the exact result. Table 10 shows the average NED, the maximum high and low NEDs and the number of correct results (or outputs) of approximate multipliers for n =8. The number of correct outputs out of the total outputs represents the probability of correctness for each design. Based on Table 10, the probability of correctness in Multiplier 1 is 0.16 percent (103 out of 65,025) while the probability of correctness in Multiplier 4 is 14.3 percent (9,320 out of 65,025). Since the proposed approximate compressors produce erroneous results for all-zero input patterns (row 1 in Tables 2 and 3), the proposed approximate multipliers will generate an erroneous result if at least one of the inputs is zero. However, in these cases (511 cases for n=8) the multiplier can produce correct result by adding a circuit for detecting the zero-valued inputs. Therefore, the zero-valued input patterns are not considered further in the simulation to investigate the proposed multipliers for a fair comparison.

Table 10 NED for n = 8

Based on Table 10, Multiplier 4 has the lowest average NED among all approximate multipliers. The average NED of Multiplier 4 is 18 times better than Multiplier 5, 2 times better than Multiplier 6 and 1.5 times better than Multiplier 7. Multiplier 5 has the highest number of correct outputs.

It has also the lowest maximum high NED. As the approximate output is always less than the exact output, the maximum high NED is 0 for this design; however, it has the worst maximum low NED among all considered designs.

A plot of the NED distribution is also generated (Fig. 10) to compare the performance of the approximate multipliers. The range of the product in a 8 × 8 multiplier is between 0 and 65,025 (unsigned values). All possible outputs are categorized in 127 intervals; in the first interval the output is between 0 and 512, in the second interval the output is between 513 and 1,024 and so on. In the last interval the output is between 64,513 and 65,025. The average NED of each interval is then computed for the approximate multiplier. Figs. 10a and 10b show that for Multipliers 1 and 2, the average NED increases only at very large or very small product values, i.e., these approximate multiplier incur on average in a small error in output compared to the exact calculation.


Fig. 10.
Average NED distribution in 8 × 8 approximate multipliers. (a) multiplier 1, (b) Multiplier 2, (c) Multiplier 3, (d) Multiplier 4.

Show All

SECTION VI.Application: Image Processing
In this section the application of the proposed approximate multipliers to image processing is illustrated. A multiplier is used to multiply two images on a pixel by pixel basis, thus blending the two images into a single output image. Fig. 11 shows two examples: both input images and the resulting output image are provided. A program has been developed in C#.net and simulated in Microsoft Visual Studio 2010 using the eight approximate multipliers at n=8. Figs. 12 and  13 show the outputs for the two examples.

Fig. 11. - Image multiplication (a) example 1, (b) example 2 (both using an exact multiplier).
Fig. 11.
Image multiplication (a) example 1, (b) example 2 (both using an exact multiplier).

Show All

Fig. 12. - Image multiplication results, for example 1, (a) Multiplier 1, (b) multiplier 2, (c) Multiplier 3, (d) Multiplier 4, (e) Multiplier 5, (f) Multiplier 6, (g) Multiplier 7, (h) Multiplier 8.
Fig. 12.
Image multiplication results, for example 1, (a) Multiplier 1, (b) multiplier 2, (c) Multiplier 3, (d) Multiplier 4, (e) Multiplier 5, (f) Multiplier 6, (g) Multiplier 7, (h) Multiplier 8.

Show All

Fig. 13. - Image multiplication results, for example 2, (a) Multiplier 1, (b) multiplier 2, (c) Multiplier 3, (d) Multiplier 4, (e) Multiplier 5, (f) Multiplier 6, (g) Multiplier 7, (h) Multiplier 8.
Fig. 13.
Image multiplication results, for example 2, (a) Multiplier 1, (b) multiplier 2, (c) Multiplier 3, (d) Multiplier 4, (e) Multiplier 5, (f) Multiplier 6, (g) Multiplier 7, (h) Multiplier 8.

Show All

The average NED and the peak signal-to-noise ratio that is based on the mean squared error (MSE) are computed to assess the quality of the output image and compare it with the output image generated by an exact multiplier. The equations for the MSE and PSNR are given in (10) and (11); in (10), m and p are the image dimensions and I(i,j) and K(i,j) are the exact and obtained values of each pixel respectively. In (11), MAXI represents the maximum value of each pixel.
MSE=1mp∑i=0m−1∑j=0p−1[I(i,j)−K(i,j)]2,(10)
View SourceRight-click on figure for MathML and additional features.
PSNR=10log10(MAX2IMSE).(11)
View SourceRight-click on figure for MathML and additional features.

Tables 11 and 12 show that the PSNRs of the output images generated by Multipliers 3 and 4, are nearly 50 dB, a value that is acceptable for most applications. Consistently, Multiplier 1 has the worst PSNR among four proposed designs. As discussed previously, the proposed approximate multipliers have a higher error distance for very large and very small input values in the product operands. Therefore the pixels that have high Red-Green-Blue (RGB) model values (such as of a white color) or small RGB model values (such as those of a black color), show a larger inaccuracy than other pixels due to the approximate nature of the compressors. However, the error distance of Multipliers 3 and 4 still remains very low.

Table 11 PSNR and average NED for first example

Table 12 PSNR and average NED for second example
Table - PSNR and average NED for second example
SECTION VII.Conclusion
Inexact computing is an emerging paradigm for computation at nanoscale. Computer arithmetic offers significant operational advantages for inexact computing; an extensive literature exists on approximate adders. However, this paper has initially focused on compression as used in a multiplier; to the best knowledge of the authors, no work has been reported on this topic.

This paper has presented the novel designs of two approximate 4-2 compressors. These approximate compressors are utilized in the reduction module of four approximate multipliers. The approximate compressors show a significant reduction in transistor count, power consumption and delay compared with an exact design.

In terms of transistor count, the first design has a 46 percent improvement, while the second design has a 50 percent improvement.

In terms of power consumption, the first design has a 57 percent improvement and the second design has a 60 percent improvement on average for CMOS implementation at feature sizes of 32, 22 and 16 nm.

In terms of delay, the second design has a 44 percent improvement compared to the exact compressor and 35 percent improvement compared to the first design on average at different CMOS feature sizes of 32, 22 and 16 nm.

Four different approximate schemes have been proposed in this paper to investigate the performance of the approximate compressors for the aforementioned metrics for inexact multiplication. The approximate compressors have been utilized in the reduction module of a Dadda multiplier. The following conclusions can be drawn from the simulation results presented in this manuscript.

The first and second proposed multipliers show a significant improvement in terms of power consumption and transistor count compared to an exact multiplier.

The first and second multipliers have larger average NEDs (and thus, larger PSNRs), while the second multiplier that uses the second proposed approximate compressor for all bits, has the best delay.

With relatively modest reductions in transistor count and power consumption, the third and fourth proposed multipliers have very low average NED values, thus presenting the best tradeoff for energy with accuracy.

Moreover, the application of these approximate multipliers to image processing has confirmed that two of the proposed designs achieve a PSNR of nearly 50 dB in the output generated by multiplying two input images, thus viable for most applications.

Table 13 compares the four proposed approximate design with four other approximate designs found in the technical literature by ranking them under various metrics. Multiplier 4 is overall the best design with respect to all figures of merit for approximate multiplication as well as the two PSNR examples. Multiplier 5 has the best performance in terms of Max High NED and number of correct outputs; however, its rather poor performance for the other figures of merit causes its ranking to be in the middle once the PSNR examples are considered. Multiplier 3 is the second best design among the schemes considered in this manuscript. It offers overall good performance in most metrics of Table 13. Current and future research addresses the tradeoffs of the different figures of merit in the proposed designs to establish conditions by which combined metrics can be attained. Moreover, physical designs of the approximate multipliers are being pursued to further confirm the analysis presented in this paper.

Table 13 Ranking of approximate multipliers
Table - Ranking of approximate multipliers
In conclusion, this paper has shown that by an appropriate design of an approximate compressor, multipliers can be designed for inexact computing; these multipliers offer significant advantages in terms of both circuit-level and error figures of merit. Although not discussed and beyond the scope of this manuscript, the proposed designs may also be useful in other arithmetic circuits for applications in which inexact computing can be used. The provision of an error indicator (as required for other applications) is a topic of current investigation.