Abstract—Energy-harvesting devices—which operate solely on
energy collected from their environment—have brought forth a
new paradigm of intermittent computing. These devices succumb
to frequent power outages that would cause conventional systems
to be stuck in a perpetual loop of restarting computation
and never making progress. Ensuring forward progress in an
intermittent execution model requires saving state in nonvolatile
memory (backup) and potentially re-executing from the last saved
state upon a power loss (restore). The interplay between spending
energy on useful processing and spending energy on these
necessary overheads yield unexpected trade-offs. To facilitate
early design space exploration, the field of intermittent computing
requires better models for 1) generalizing and reasoning about
these trade-offs and 2) helping architects and programmers in
making early-stage design decisions.
We propose the EH model, which characterizes an intermittent
system’s ability to maximize how much of its available energy is
spent on useful processor execution. The model parametrizes the
energy costs associated with intermittent execution to allow an
intuitive understanding of how forward progress can change. We
use the EH model to explore how forward progress is impacted
with the frequency of backups and the energy cost of backups and
restores. We validate the EH model with hardware measurements
on an MSP430 and characterize its parameters via simulation.
We also demonstrate how architects and programmers can use
the model to explore the design space of intermittent processors,
derive insights, and model new optimizations that are unique to
intermittent processor architectures.
I. INTRODUCTION
The batteryless operation of compute devices introduces
new and challenging trade-offs to programmers and computer
architects. Ambient energy sources (e.g., photovoltaic [23],
thermal [47], RF [52], WiFi [8]) do not provide a constant
stream of power to run the device [11]. Also, they typically
provide less average power than the device requires. To
overcome this, a common approach is to first store energy
in a capacitor, which then powers the device for a period of
time [11]. This sporadic power supply from ambient energy
sources requires an execution model that must inherently
support intermittent computation: computation may stop at
any point in the application because the energy supply has
depleted and cannot resume until the device has harvested
sufficient energy from the environment.
Intermittent computation requires that application state be
backed up in nonvolatile memory before energy is depleted and
restored when energy is available again. A good intermittent
architecture maximizes how much of the available energy
is spent on useful work (i.e., forward progress), not on the
necessary overheads of backups and restores. But building such
an architecture is no simple task. Researchers have proposed
a wide variety of processor designs ranging from simple inorder cores [6] to complex out-of-order cores [38] with a
diverse mix of nonvolatile memory technologies (e.g., flash [43]
and FRAM [12]). The variety of approaches being proposed
demonstrates the vast design space of intermittent processor
architectures. Should the architecture perform a backup every
cycle [38], at set periods [43], only at critical power levels [6],
when explicitly told by the program [12], or when implicitly
inferred in hardware [22]? Should we save only the program
counter and register file, or should we also save volatile
memory data [6], cache data [31], or only dirty values [38],
[56]? Should programmers manually write code that backs
up to nonvolatile memory, or should they use task-based
programming models [12], [34], checkpointing schemes [43],
or simply rely on hardware to perform backups under the
hood [22], [38]? Though simulators and tools exist for specific
systems, we are in need of a way to rapidly explore the design
space of intermittent processors to inform future architectures.
To address this need, we present and extend the EH
model1 [44], an analytical model for early design space
exploration that generalizes and characterizes the complex,
unconventional trade-offs that arise in intermittent processors.
We validate the model and demonstrate its utility as an earlystage design tool with several explorations and case studies:
• Given the expected behaviour of applications, where
should architects focus their efforts to maximize forward
progress (e.g., backup vs. restore mechanisms)?
• Can a programmer estimate how well their application
will perform under a specific architectural configuration
(e.g., optimal task lengths for systems like Chain [12])?
• Under what circumstances are architectural optimizations
(e.g., reduced bit-precision) beneficial to intermittent
systems?
• How can programmers transform their code to perform
better on state-of-the-art architectures (e.g., memory
locality for mixed-volatility caches [31], [56])?
Our EH model helps architects and programmers derive new
insights and rapidly explore this design space. We hope our
model excites further research in the field of energy harvesting
1Why EH? Well, we are Canadian, after all.
600
2018 51st Annual IEEE/ACM International Symposium on Microarchitecture
978-1-5386-6240-3/18/$31.00 ©2018 IEEE
DOI 10.1109/MICRO.2018.00055
CPU
Energy Supply
(E)
Energy 
Transducer
Nonvolatile Memory
Backup Restore
Processor State Volatile Memory
Fig. 1. An abstract energy-harvesting device.
by alleviating the complexity of designing efficient intermittent
systems.
II. BACKGROUND
Figure 1 represents an abstract energy-harvesting device. A
transducer harvests energy from the environment to charge a
capacitor. The energy is used by different hardware components:
the CPU, nonvolatile memory, and the backup/restore mechanism. Typically, the system waits until the capacitor reaches a
minimum threshold before it begins executing [6], [43]. Thus,
no forward progress can be made during the charging phase.
Once the minimum energy threshold is reached, an active
phase begins until the capacitor is depleted. Transitioning
between active and charging phases gives rise to intermittent
computation, which is a function of how much energy can be
harvested from the environment and how much energy is being
used by the architecture.
The main challenge in intermittent computation is this:
forward progress can only be made when the results of executed
instructions are saved to nonvolatile memory. Intermediate
results in volatile memory are lost during a power outage,
and expending energy on instructions whose output is not
saved before a power outage is wasteful. In this section, we
provide an overview of prior art designed to allow intermittent
computing systems to make forward progress in the face of
frequent power outages. We divide the techniques into two
categories: multi-backup and single-backup systems.
Multi-Backup Systems. A multi-backup system typically
performs several backups within a single active period. Mementos [43] inserts checkpoints into the code (at the end of
loop iterations or function calls) to back up volatile memory
elements (i.e., SRAM) to nonvolatile memory (i.e., Flash).
DINO [34], Chain [12], Alpaca [39] and Mayfly [21] break
the program into atomic tasks, with backups being performed
at the boundary between tasks, to maintain consistency while
ensuring forward progress. Ratchet [54] and Clank [22] keep
track of data that has been modified since the last power outage
and periodically back up just this data to nonvolatile memory.
Single-Backup Systems. A single-backup system saves system
state only once per active period. For example, Hibernus [5],
[6] and QuickRecall [25] use an analog to digital converter
(ADC) to sense when the voltage dips below a pre-defined
threshold to back up. Several works build upon this idea to
increase the efficiency of intermittent computing systems [1],
[4], [7], [32], [35].
Nonvolatile Processors. The multi- and single-backup systems
listed above augment conventional processors, which incorporate volatile memory such as SRAM, to work in the face
of power outages. An alternative approach uses nonvolatile
memory such as FRAM [28], [30], [36], [38], [53], [55], [58],
ReRam [33] or MRAM [45]. A nonvolatile processor (NVP)
does not require explicit checkpointing because all system
state is preserved across power outages. Upon recovering from
a power outage, the system resumes processing immediately
without needing to restore state. However, nonvolatile memory
suffers from higher power consumption. Thus, NVPs vary from
backing up every cycle to backing up only when the supply
voltage drops below a set threshold. Our EH model captures
both conventional and NVP architectures; NVP designs that
back up every cycle are characterized as multi-backup while
those that back up based on a threshold are characterized as
single backup.
As we demonstrate in the following sections, our EH model
supports both multi-backup (Section IV-A) and single-backup
architectures (Section IV-B) while still remaining general
enough to characterize new designs (Section VI). In the next
section, we provide a detailed description of the EH model.
III. THE EH MODEL
The goal of our model is to enable early design space
exploration of intermittent processor architectures by estimating
forward progress. Prior work models the behaviour of energyharvesting power sources, such as RF [51], vibration [27], [46],
photovoltaic [14] and piezoelectric [29] power. In contrast, we
focus on modeling a processor that is subject to intermittent
execution caused by harvesting energy. The EH model focuses
on the active period, during which the energy supply is
expended on executing instructions and performing backups
and restores. We differentiate between energy spent on forward
progress, backups, restores, and re-execution (i.e., dead energy)
caused when state was not saved before a power outage.
We list our model parameters in Table I. The output of our
model is p, an estimate of forward progress represented as
the fraction of the energy supply E expended on useful work
(i.e., not spent on backups, restores and dead execution). To
begin, we characterize the fundamental consumers of energy
E:
E −
eP + (nB · eB) +eD +eR

= 0 (1)
• eP is energy spent on forward progress.
• eB is energy spent on each of nB backups.
• eD is energy spent on dead execution.
• eR is energy spent on restoring backed-up state.
Often the energy budget is not fixed at E but rather increases
over time since the device can continue charging during an
active period. We model this additional energy by including
the device charging rate (εC) in the following equations for
each of the energy consumers.2
2The charging rate can be modelled as a separate component of Equation 1;
we opt to incorporate it into the individual equations to simplify the discussion
without loss of fidelity.
601
TABLE I
EH MODEL INPUT PARAMETERS AND OUTPUTS.
General Parameters
E ∈ R>0 joules energy supply per active period
ε ∈ R>0 joules/cycle execution energy per cycle
εC ∈ R≥0 joules/cycle charging energy per cycle
Backup Parameters
τB ∈ R>0 cycles time between backups
σB ∈ R>0 bytes/cycle memory backup bandwidth
ΩB ∈ R≥0 joules/byte backup energy cost
AB ∈ R≥0 bytes architectural state per backup
αB ∈ R≥0 bytes/cycle application state per backup
Restore Parameters
σR ∈ R>0 bytes/cycle memory restore bandwidth
ΩR ∈ R≥0 joules/byte restore energy cost
AR ∈ R≥0 bytes architectural state per restore
αR ∈ R≥0 bytes/cycle application state per restore
Model Output
τP ∈ R≥0 cycles time spent on forward progress
p = ε · τP/E % of E % energy spent on forward
progress
Energy for Forward Progress (eP). An application expends
some amount of energy per cycle (ε) while executing. During
an active period, a certain number of cycles will be used to
make forward progress (τP); the total energy spent on forward
progress is computed via Equation 2, along with any additional
charging energy per cycle. The execution energy cost ε includes
not only the processor but also any sensors and peripherals
that are active. Techniques that reduce ε (e.g., duty cycling
sensors, dynamic voltage scaling [37]) are always beneficial
for forward progress.
eP = (ε −εC)· τP (2)
Energy for Backups (eB). During active periods, computation
must be backed up to nonvolatile memory to make forward
progress. Some approaches may back up multiple times within
an active period [6], [22], [38]; others only once [43]. We
characterize how often backups occur with the number of
cycles between them (τB). The total number of backups is:
nB = τP
τB
(3)
To compute the energy spent on each backup (eB), we
multiply the cost of writing to nonvolatile memory (ΩB) by the
number of bytes written per backup. A system may back up
a fixed number of bytes each time (AB), such as architectural
state (e.g., program counter, registers) [38]. A system may also
incur a variable backup cost that is proportional to any changes
in application state since the last backup (αB bytes/cycle). For
example, dirty data in a volatile cache [31], [56] must be
saved, the amount of which depends on the application’s write
footprint (we explore this further in Section VI-A). Charging
during the time spent performing the backup gains additional
energy for the system; this energy is inversely proportional to
the nonvolatile memory backup bandwidth σB (e.g., for the
MSP430 CPU this corresponds to 2 cycles per word at 16MHz
or above, and 1 cycle per word for speeds below 16MHz [6],
[12], [43]). We calculate energy expended on backups as:
eB = (ΩB − εC
σB
)·(AB +αB · τB) (4)
Dead Energy (eD). Ideally, we would back up our data just
before our energy supply (E) is depleted. If this is not the case,
then the application has expended energy on computations
that are never stored in nonvolatile memory. Thus, some
number of cycles before the next backup (τD) contribute to
dead energy (eD). We calculate the amount of dead energy
expended in a similar way to the energy spent on forward
progress (Equation 2). In this case, we replace τP with τD
since application state after dead computation is not saved for
the next restore:
eD = (ε −εC)· τD (5)
The number of dead cycles can vary due to non-deterministic
effects in the energy supply and in the application behaviour.
To simplify the model, we consider the average case of dead
cycles: τD = τB
2 , shown in Equation 6; we discuss the impact
of variability in Section IV-A2.
0 ≤ τD ≤ τB, τD = τB
2 , on average (6)
Energy for Restores (eR). Before an application can resume
execution, it must expend energy (eR) to restore its last saved
state. Mirroring the backup overhead (Equation 4), this incurs
the cost of accessing nonvolatile memory (ΩR) scaled by the
amount of architectural (AR) and application (αR) state that
must be restored. AR represents a fixed number of bytes that
the processor must restore at the start of each active period
(e.g., register file). αR represents the variable cost of reverting
or cleaning up any uncommitted state left over from the dead
execution (τD) of the previous active period (e.g., flushing dead
instructions in nonvolatile processors [38]). Charging gains
additional energy during the restore process, whose duration
is inversely proportional to the nonvolatile memory restore
bandwidth σR. From this, we compute the restore energy as:
eR = (ΩR − εC
σR
)·(AR +αR · τD) (7)
Putting It All Together. Our model outputs the percentage of
energy spent on forward progress p as ε · τP/E. Solving for p
in Equation 1 yields:
p = 1− eD
E − eR
E
(1+ eB
(ε−εC)·τB )·(1− εC
ε ) (8)
In the first term of the denominator, forward progress is
scaled down by the ratio of backup overhead (eB) to how
much useful work each backup commits ((ε −εC)· τB). This
602
represents the backup cost-reward ratio that governs the rate
at which an application moves forward. The second term
represents additional progress made due to charging in the
active period. Note that the charging rate is generally much
lower than the consumption rate; progress p goes to ∞ when εC
approaches ε. In the numerator, one-time costs—dead energy
and restore energy—incurred once per active period, limit
progress. Thus, even if the cost of backups were completely
eliminated in the denominator, these one-time costs impose an
upper bound on performance and must be minimized.
Architects and programmers can garner many interesting
implications from Equation 8. The next section explores a few
of them in detail and discusses the insights they reveal.
IV. EXPLORATIONS
In the previous section, we demonstrate how to estimate
forward progress based on the energy consumption of different
components (Equation 1). This section focuses on how architects can use our model to design a system that maximizes
forward progress. We use the two common paradigms introduced in Section II: multi-backup and single-backup systems.
Recall that, a multi-backup system may invoke several backups
in a single active period whereas single-backup systems invoke
only one. Next, we detail the application of the EH model for
both these approaches to intermittent computing devices.
A. Multi-Backup Systems
We generalize multi-backup architectures to those that invoke
periodic backups once every τB cycles on average. τB is defined
by either periodic system backups, program-induced backups,
or both. Periodic system backups can take the form of:
• Hardware watchdog timers that force a backup after τB
cycles (e.g., Clank [22]);
• Compiler-inserted checkpoints (e.g., Mementos [43]);
• Nonvolatile processors [38] that back up every cycle (τB = 1).
Examples of program-induced backups are: when tasks commit
in transaction-based systems like Chain [12] or Mayfly [21]
(τB is the average task length in this case) or when memory
operations violate idempotency in Clank [22] (idempotency is
further explored in Sections V and VI-B).
We formulate our model in Section III such that it is
general enough to characterize an arbitrary number of backups
per active period. Thus modelling a multi-backup system is
as simple as setting the appropriate time between backups
(τB). We look at how to optimize the time between backups,
minimize dead cycles, and balance the restore-versus-backup
cost (Sections IV-A1, IV-A2, and IV-A3).
1) Optimal Time Between Backups: How many cycles apart
should backups be (τB) to maximize forward progress in a multibackup system? Figure 2 shows how progress (normalized to
ε) varies with the time between backups (τB) and backup cost
(ΩB). We set the execution energy (ε) to 1% of the active
period’s energy supply (E) for illustrative purposes, focusing
on general trends as opposed to the exact values. We also
assume no restore overhead nor charging energy for brevity; it
is straightforward to extend our analysis to include them. The
0%
20%
40%
60%
80%
100%
0.01 0.1 1 10
progress p
backup cost : execution energy
25 10 5 1
(ΩB/ϵ)
τB (cycles):
Fig. 2. Progress p for multi-backup system with varying τB and backup cost
ΩB (normalized to ε). Assumes E = 100, eC = 0, AB = ε = 1, αB = 0.1 and
ΩR = 0.
0%
20%
40%
60%
80%
100%
0.01 0.1 1 10
progress p
backup cost : execution energy
25 10 5 1
(ΩB/ϵ)
τB (cycles):
Fig. 3. Progress p for multi-backup system with varying τB and backup cost
ΩB (normalized to ε), with no architectural state (AB = 0). Assumes E = 100,
eC = 0, ε = 1, αB = 0.1 and ΩR = 0.
first takeaway is that reducing backup cost is always better for
performance, as expected. As the backup cost approaches 0,
forward progress favours more frequent backups since 1) this
minimizes dead cycles, and 2) backups are cheap.
The second takeaway is that the optimal time between
backups is not stagnant but varies depending on the backup
cost. Solving for the roots of ∂ p
∂ τB (Equation 8), we obtain the
optimal:
τB,opt = ΩB ·AB
ΩB ·αB +ε ·

2 ·
E
ε ·
ΩB ·αB +ε
ΩB ·AB
+1−1

(9)
The ratio ΩB·AB
ΩB·αB+ε dictates the optimal number of cycles
between backups. The numerator represents the compulsory
energy cost per backup while the denominator represents the
energy cost proportional to how much work was done since
the last backup. There is a trade-off between 1) backing up
less frequently if the compulsory cost is high and 2) backing
up more frequently if the proportional cost is high. With
Equation 9, programmers can estimate the optimal task length
for their code (e.g., in systems like Chain [12], a task can
be sized to match the optimal backup time), while system
designers can configure the optimal period for checkpoints [43]
and watchdog timers (e.g., in Clank [22], by choosing the
appropriate duration between watchdog interrupts).
Note that in cases with very little architectural state (AB
approaches 0), there is no sweet spot in the time between
backups, shown in Figure 3 (i.e., progress is monotonically
non-increasing with τB). Though rare, needing to back up nearly
603
0%
20%
40%
60%
80%
100%
1 10 100
progress p 
τB (cycles between backups, log scale) 
worst-case average best-case
Fig. 4. Progress p over τB for multi-backup system, varying from worst-case
to best-case τD. Assumes E = 100, eC = 0, ΩB = AB = ε = 1, αB = 0.1 and
ΩR = 0.
zero architectural state is possible in systems that track dirty
bits to save only the registers that have been modified (e.g., ondemand selective backups in nonvolatile processors [38]); only
the program counter is compulsory on every backup. Assuming
no cost of backing up architectural state (AB = 0) in Equations 4
and 8 leaves us with a simple relationship: limτB→0 p = 1. As
a result, when considering only the cost of application state,
it is always better to back up as frequently as possible since
the overhead decreases proportionally with the time between
backups (Equation 4).
2) Variability of Dead Cycles: So far our analysis for
multi-backup systems assumes the average dead cycles (τD
from Equation 6). Due to non-determinism in both the
system (e.g., fluctuations in energy source) and the application
(e.g., input-dependent program behaviour) [20], the number
of dead cycles can vary dramatically across active periods. In
this section, we explore how this variability affects important
design decisions.
Figure 4 shows how progress varies under the worst-case
(τD = τB) and best-case dead cycles (τD = 0). We set similar
system parameters as in Figure 2, assuming no restore or
charging energy for simplicity. The first takeaway is that
variability diminishes as the time between backups approaches
0; backing up more often decreases the likelihood of dead
execution. Conversely, a long time between backups increases
the risk of not backing up at all but opens up the possibility
of the ideal scenario (i.e., a single backup invoked at the end
of the active period). This introduces an interesting trade-off.
If aggressive performance gains are desired, an architect can
design a system with a long time between backups that are
scheduled in an intelligent or speculative way to consistently
minimize dead cycles. But if worst-case performance (i.e., tail
latency) is important, an architect can sacrifice the average case
and opt for a much lower τB. For example, Spendthrift [37]
speculates the amount of dead energy per active period and
employs voltage and frequency scaling to maximize efficiency.
Our analysis provides an upper bound on forward progress for
Spendthrift and related works that apply advanced speculative
techniques.
Following from this, how many cycles apart should backups
be invoked to maximize worst-case forward progress? At first
glance, one may assume that Equation 9 is sufficient; however
it assumes the average case of dead cycles. Solving instead
for the worst case (τD = τB):
τB,opt(wc) = ΩB ·AB
ΩB ·αB +ε ·
E
ε ·
ΩB ·αB +ε
ΩB ·AB
+1−1

(10)
Though similar to the average case in Equation 9, the key
takeaway is that τB,opt(wc) and τB,opt are never equal. The
optimal time between backups in the worst case is always less
than that of the average case, an important consideration when
designing for tail latency.
3) Cost of Backups and Restores: Given the number of
cycles between backups, should we focus on minimizing
backup or restore overhead in a multi-backup system? This
decision arises in situations where 1) an architect must
optimize for the average task length [12], or 2) a programmer
must optimize for periodic backups imposed by the system
(e.g., watchdog timers [22]). At first glance, one may assume
that it is always better to optimize backup cost since the
system performs a restore only once per active period. But if
the time between backups is too great, there may be insufficient
energy to back up resulting in no progress. In this section, we
explore the interplay between the time between backups and
the backup/restore overhead.
As the time between backups becomes significantly large (τB
approaches +∞), the performance improvement of reducing
the restore cost ( ∂ p
∂ eR ) outweighs that of the backup cost ( ∂ p
∂ eB ).
Since progress is inversely proportional to backup and restore
overhead, both partial derivatives are negative (i.e., a lower ∂ p
∂ eR
means that reducing eR yields better performance). Investigating
further, we solve for the number of cycles between backups at
the break-even point ( ∂ p
∂ eB = ∂ p
∂ eR ):
τB,be = 2
3 ·
E −eB −eR
ε (11)
From this, we have the following takeaways:
• If the time between backups is less than the break-even
point (τB < τB,be), reduce the cost of backups.
• If the time between backups is greater than the break-even
point (τB > τB,be), reduce the cost of restores.
As expected, with frequent backups (i.e., low τB), architects
should focus on optimizing the backup mechanisms to improve
performance. For example, a nonvolatile processor designer can
choose to discard the state of some structures (e.g., instruction
fetch queue, branch predictor) if they expect to back up
often [38]. Conversely, as the time between backups increases,
the restore overhead starts to dominate; it becomes more likely
that no backup is invoked at all within an active period. When
this happens, all execution is dead. As a result, we actually
start to see more restore invocations than backup invocations
when the time between backups exceeds the break-even point
(τB,be). With this analysis, architects and programmers gain
a better understanding of where to focus their optimization
efforts given the expected time between backups in their
systems. For instance, in Clank [22], checkpoints occur due
to idempotent violations and watchdog timers. Based on the
604
observed frequency of these checkpoints, the break-even point
can inform the Clank architect to optimize the restore or backup
overhead.
B. Single-Backup Systems
We characterize single-backup architectures as those that only
invoke a single backup per active period when they observe that
the energy supply has dropped too low, signaling an imminent
power loss. Examples include Hibernus [6] and single-backup
nonvolatile processor designs [38].
To model single-backup systems, the time between backups
and number of dead cycles are set to extreme cases: τB = τP
and τD = 0. We compute forward progress for single-backup
systems with:
p = 1− (ΩB−εC/σB)·AB
E − eR
E
(1+ (ΩB−εC/σB)·αB
ε−εC )·(1− εC
ε )
(12)
The key difference from the general case in Equation 8 is that
there is no more dead execution energy; we effectively assume
the best-case dead cycles from Equation 6. Though this is an
advantage over multi-backup systems, this often comes at two
costs. First, it introduces the risk of not having enough energy
to perform a full backup and potentially leaving nonvolatile
memory in an inconsistent state [42]. Second, the process
of reading the voltage ADC and monitoring for imminent
power losses is generally expensive, yielding up to 40% energy
overhead [22].
C. Summary of Explorations
We present some implications from our EH model for designing efficient energy-harvesting systems. We show how our
model characterizes state-of-the-art multi- and single-backup
architectures. We explore the optimal time between backups and
how it can help 1) programmers determine the granularity and
size of tasks [43] and 2) architects configure optimal watchdog
timers [22]. We provide architects with guidelines on when to
optimize backup or restore overhead. Our model can compute
lower and upper bounds on performance when accounting
for the non-determinism of intermittent execution, useful
when seeking aggressive performance gains [37]. Section VI
dives deeper into additional cases studies to demonstrate the
applications of our EH model. Next, we present experimental
results of our model validation and characterizations.
V. EXPERIMENTAL RESULTS
In this section, we present a hardware validation of the EH
model’s estimates of forward progress on a Texas Instruments
LaunchPad platform [50] with an embedded MSP430FR5994
microcontroller. The MSP430 is used extensively in the energyharvesting space [5], [6], [12], [34], [43]. First, we present
a validation of a simple counter program to demonstrate that
the EH model can capture the variation in forward progress
seen when the cycles between backups is varied. Next, we
show a validation of three state-of-the-art energy-harvesting
systems: one single-backup system (i.e., Hibernus) and two
multi-backup systems (i.e., Mementos and DINO). Finally,
65%
70%
75%
80%
85%
90%
95%
1500 15000
forward progress p
cycles between backups, log scale
Fig. 5. Validating a multi-backup system. Points are measured from hardware.
The dashed lines represent the upper and lower bounds estimated by the EH
model.
obtaining model parameters (e.g., application state) for systems
that do not exist in real hardware (such as Clank [22]) is only
possible via simulation. Therefore, we extend a simulator from
prior art [22] to characterize a range of applications. Namely,
we profile the cycles between backups (τB), dead cycles (τD),
and application state (αB) parameters.
A. Validation
The first experiment mimics a multi-backup system, where
backups are made at fixed time intervals (i.e., τB is constant
throughout a single experimental run). We sweep time between
backups through multiple runs, from 0.18ms to 7.1ms. The
application increments a counter until an interrupt occurs
every τB cycles, upon which the application backs up data
representing its current state. The data backed up consists of
an array and a timestamp, which are saved to the board’s
nonvolatile FRAM. The size of the array is equal to αB · τB
bytes, which varies as τB is varied. Application state (αB) is
set to be 0.1 bytes/cycle (Section V-B shows values for αB
from simulation—0.1 bytes/cycle is slightly below average).
We measure the power consumption of instructions executing
on the board using TI’s EnergyTrace system [50]. Load and
store operations to memory consume 1.2mW while all other
instructions consume 1.05mW. We measure forward progress
using onboard timers.
We also consider different active period lengths: 0.5s, 0.375s,
0.25s, and 0.125s based on prior work [6]. Figure 5 plots
measured forward progress, with the dashed lines indicating
the upper and lower bounds as predicted by the EH model
(τP). The variance in the measured data points is due to the
variation in dead cycles. That is, a backup may occur just
before the end of an active period (very few dead cycles).
Alternatively, the active period may end just before the next
backup can occur (dead cycles is close to τB), the worst case
for forward progress. The measured data points are within the
bounds calculated from the EH model, demonstrating that it
can capture the trends needed when exploring the design space
of intermittent architectures.
The next experiment compares the forward progress measured on hardware vs. the forward progress predicted by
the EH model for three energy-harvesting systems: Hibernus,
605
TABLE II
BENCHMARKS USED FOR HARDWARE VALIDATION.
Name Description
RSA Data encryption
CRC Checksum calculation
SENSE Statistics calculation of sensor data
AR Activity recognition from sensor data
MIDI Audio based data logging
DS Key-value histogram based data logger
RSA
CRC
SENSE
RSA
CRC
SENSE
AR
MIDI
DS
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
measured progress p
predicted progress p
Hibernus
Mementos
DINO
Fig. 6. Measured forward progress vs. predicted forward progress from EH
model. The diagonal line corresponds to zero error in model estimate.
Mementos and DINO. We run the same benchmarks (Table II)
as used in the original papers for each system. To track the exact
cycles spent on each phase of execution (i.e., forward progress,
backups, restores and dead cycles), we toggle a single-cycle
pulse on a general purpose I/O (GPIO) pin at the start and end of
each phase. These signals are captured and logged by a separate
high-performance microcontroller. This allows us to faithfully
capture how cycles are spent on the MSP microcontroller
without affecting the energy of the platform (apart from the
minimal energy cost of toggling a GPIO for 1 cycle each
time). We also measure the exact duration of the active period
by monitoring the voltage of the MSP microcontroller and
comparing against the threshold voltages for power on and off
specified by the device manufacturer.
Figure 6 shows the comparison of forward progress as
predicted by the EH model vs. measurements carried out on the
MSP Launchpad. The geometric mean error between predicted
and actual values is 1.60%. Some applications such as AR and
MIDI exhibit higher error for the DINO system. This is due to
the fact that the EH model uses a single value for the cycles
between backups (i.e., τB). However, these benchmarks use
several different backup periods ranging from 17 cycles to over
14,000 cycles between backups. We use the average of these
values as an input to the EH model, leading to larger error for
these applications. Predicted forward progress is lower than the
measured one for Mementos (geometric mean error of 6.97%).
Recall that for a multi-backup system, the EH model uses
AR DS MIDI
0%
10%
20%
30%
40%
50%
60%
70%
80%
measured progress p
relative similarity of τB to τB,opt
Fig. 7. Correlation between 1) measured forward progress and 2) relative
similarity of measured τB to optimal τB,opt from EH model.
τB
2 to estimate dead cycles (τD). However, the dead cycles in
Mementos are dependent on the amount of energy left over after
it has completed a backup. We account for this by subtracting
the energy left over after hitting the minimum voltage threshold.
However, Mementos continues to do work until it reaches the
next checkpoint where it can perform another backup, which
uses additional energy. This difference between the estimated
energy left over at the minimum voltage threshold vs. the
energy left over at the checkpoint leads to a lower forward
progress prediction by the EH model.
Next, we validate that our estimate of an optimal time
between backups (τB,opt, Equation 9) correlates with the
forward progress made by an application. Figure 7 shows the
forward progress of the DINO benchmarks. We also plot the
average τB using DINO compared to the optimal time between
backups estimated by our model. The AR benchmark, which
achieves an average τB that is nearly 70% of τB,opt, has the
highest forward progress. In contrast, DS and MIDI do not back
up optimally and have significantly lower forward progress.
Thus, the EH model can provide insights to the application
designer on the ideal τB,opt they should aim for to maximize
forward progress.
B. Characterization
We extend the simulator used in Clank [22] to better
understand the values of the EH model parameters. We add
a capacitor model to the simulator that supplies energy to
the system. We supply harvested energy from recorded RFbased voltage traces [43] and evaluate a subset of the MiBench
suite [18], compiled with GCC for ARM embedded processors
(6-2017-q2-update). The simulator provides statistics for each
active period (e.g., the number of backups, cycles between
backups, dead cycles). We provide a brief description of Clank
before presenting characterizations of the time between backups
(τB) and (τD).
In Clank, backups are induced by idempotency violations [22]; an idempotent sequence of instructions is one
that can be interrupted and re-executed yet still produce the
same result. Idempotency violations are specifically caused by
storing to a nonvolatile memory location that has been read
at least once since the last backup. This forces a backup; if
606
0
2000
4000
6000
8000
Cycles between backups
Fig. 8. The average τB with error bars for the standard error of the mean.
0
1000
2000
3000
4000
Dead cycles
Fig. 9. The average τD with error bars for the standard error of the mean.
power were to be lost after the store instruction completes,
re-executing from the previous checkpoint would read the new
memory value (instead of the old one) and produce incorrect
results. To identify violations, Clank uses volatile buffers and
detection logic—the original paper proposed different buffers
and optimizations to minimize backups. Our implementation
of Clank employs an 8-entry read-first buffer and 8-entry writefirst buffer to track violations. We use an 8000-cycle watchdog
timer in case no idempotent violations occur in that time. Clank
was based on an ARM Cortex-M0+, which requires 20 32-bit
registers to be backed up and restored. We base our timings on
the original paper [22] and our energy numbers on a datasheet
for the ARM core [48].
Figures 8 and 9 plots the average time between backups (τB)
and dead cycles (τD), respectively, across three voltage traces:
1) a trace that contains two short spikes of over 5V, while the
troughs are very close to 0V; 2) a trace that gradually increases
from a low voltage close to 0 to a voltage close to 2.5V; and 3) a
trace that has multiple peaks (3.5-5.5V) and troughs (0-1.5V).
The error bars represent the standard error of the mean, which
is the standard deviation of the distribution divided by the
square root of the sample size. The distributions we observed
for both parameters were closely packed around the median,
and while there was some variation caused by outliers, the error
bars show that the variation is insignificant. We also see that the
distributions across each voltage trace (not shown) were nearly
identical. We believe this is a function of two things. First,
active periods all have similar energy supplies (E) because the
amount of energy that can be charged within an active period
is very small. Second, because the energy supply is relatively
stable, the sequence of idempotent violations observed will be
0
0.3
0.6
0.9
1.2
Bytes per cycle
Fig. 10. The average αB, with error bars for the standard error of the mean.
similar. Because idempotent violations signal backups, both τB
and τD will see little variation. The very small values of dead
cycles for some benchmarks reflects the similarly small values
for time between backups; that is, τD cannot exceed τB.
To introduce greater variability, we simulate a hypothetical
mixed-volatility processor that uses a parametrized watchdog
timer to determine when to back up. We implement an
unbounded store queue to track modifications to application
state (αB) within a backup period. Note that the store queue
will require additional time (σB) and energy (ΩB) to back
up. Figure 10 plots the average application state (αB) when
using different watchdog timers for backups (250-3000 cycles
between backups, in increments of 250 cycles). We can see
that the bytes per cycle to be backed up is low across most
benchmarks (on average 0.16 bytes per cycle).
Combined with the time between backups, Figure 10 helps
us understand how much state needs to be backed up to make
forward progress. The data can also help us understand the
likelihood of idempotent violations. For example, lzfx’s frequent
backups in Clank (Figure 8) are likely due to its very high
rate of stores. Thus, the parameters in Table I can be chosen
to recreate the scenarios exhibited in realistic benchmarks and
evaluate future intermittent processing devices.
VI. CASE STUDIES
In this section, we apply our EH model to case studies of
state-of-the-art intermittent processor systems.
A. Store-Major Locality
In conventional architectures, high cache locality for load
instructions is generally far more beneficial to performance than
locality for store instructions. Unlike reading data, modifying
data is typically off the critical path of execution. State-of-theart intermittent processor systems may be equipped with volatile
(or hybrid volatile/nonvolatile) caches [31], [56] between the
processor and nonvolatile memory. Upon a backup, all dirty data
must be saved to nonvolatile memory; this process often lies on
the critical path of execution to prevent inconsistent nonvolatile
updates. In these systems, programmers and architects must
reconsider the trade-offs between load and store locality, which
we explore in this section.
Consider the example matrix transpose program in Listing 1.
With both arrays A and B encoded in standard row-major order
in memory, the conventional approach is to iterate through
607
Listing 1. Store-major loop example. 1 // conventional load-major
2 for (i = 0; i < m; i++)
3 for (j = 0; j < n; j++)
4 B[j][i] = A[i][j];
5
6 // store-major
7 for (i = 0; i < m; i++)
8 for (j = 0; j < n; j++)
9 B[i][j] = A[j][i];
the nested loop in load-major order (i.e., the innermost loop
iterates through the contiguous dimension of the array being
read). On one hand, this yields maximum cache locality for load
instructions, suffering a cache miss only once every βblock/βload
loads on average, where βblock is the cache block size and
βload is the number of bytes per load. On the other hand, store
instructions incur a cache miss on every access, assuming array
B does not fit in the cache. In conventional architectures, this
is of less concern for performance since the processor can
often continue executing without waiting for the store miss to
be serviced by memory. However, in an intermittent processor
system, load-major ordering increases the number of bytes
to back up by a factor of βblock/βstore on average compared
to store-major ordering, where βstore is the number of bytes
per store instruction. This is due to the fact that dirty state is
tracked at cache block granularity instead of byte granularity;
the latter would be too expensive in metadata overhead. To
illustrate this, we compare the load-major and store-major loops
(Line 6) in our example program. With store-major ordering, if
a backup is invoked after βblock/βstore store instructions in the
inner loop, there would only be one dirty block in the cache due
to maximum store locality. However, with load-major ordering,
after the same number of iterations, βblock/βstore cache blocks
must now be backed up, even though only βstore bytes have
been modified in each of the blocks.
We can characterize the ratio of performance overhead (in
cycles) with load-major loops (τload-ma jor) to store-major loops
(τstore-ma jor) as:
τload-ma jor
τstore-ma jor
=
αload ·τP
σload + (βblock/βstore)·nB·αB·τB
σB
(βblock/βload )·αload ·τP
σload + nB·αB·τB
σB
(13)
where αload is the average number of bytes read by the
application per cycle and σload is the nonvolatile memory
bandwidth for load operations. Simplifying Equation 13, we
find that store-major loops can improve performance over loadmajor loops only when:
αB ·( βblock
βstore −1)
αload ·( βblock
βload −1)
>
σB
σload
(14)
The first term represents the ratio of unique dirty blocks that
the application backs up to unique blocks that the application
loads into the cache. The second term represents the ratio
of backup bandwidth to read bandwidth on the nonvolatile
memory device. Programmers should transform their loops to
store-major order if either 1) the application is expected to
have a larger write footprint than read footprint, or 2) backing
Listing 2. Circular buffer for idempotency example.
1 // conventional
2 for (i = 0; i < n; i++)
3 A[i] = f(A[i]);
4
5 // circular buffer for idempotency
6 for (i = 0; i < n; i++)
7 A[(A.head + n + i) % N] = f(A[(A.head + i) % N]);
8 A.head = (A.head + n) % N;
up in nonvolatile memory is expensive relative to reading from
it. In our example (Listing 1), the read and write footprints
of the matrix transpose program are equal in size. If we
assume the same latency for reading from and backing up
to nonvolatile memory (i.e., σload = σB), we see that loadmajor and store-major ordering yield the same performance,
a takeaway that does not apply to conventional architectures.
For some memory devices, write latency can be much higher
than read latency (e.g., 10× for STT-RAM [56]), making storemajor loops beneficial. With this case study, we highlight the
importance of reconsidering conventional trade-offs and present
new insights for optimizing programs for cache locality on
intermittent processor architectures.
B. Circular Buffers for Idempotency
In a conventional single-threaded system, there is generally
no need for programmers to concern themselves with eliminating (or inducing) write-after-read memory dependencies. A
store instruction to some memory location can come either
immediately after or long after a load instruction from that same
location; neither would be particularly better for performance.
However, in the Clank processor [22], this is an important
design consideration. As discussed in Section V, backups are
induced by idempotency violations in Clank. Thus the average
time between idempotency violations in a program (i.e., the
time between each violating store instruction and its preceding
load) dictates the frequency of backups in the system. Since
there is a sweet spot in how frequently we should invoke
backups to maximize forward progress (Section IV-A1), the
ability to control idempotency violations is important for Clank.
Using Equation 9 from our model exploration, we introduce
a general technique for programmers to tune the idempotent
regions in their application (i.e., time between idempotency
violations) to match the optimal time between backups (τB,opt)
of the Clank architecture. We propose storing program arrays
in circular buffers in nonvolatile memory; the difference in
buffer size to array size controls the length of idempotent
regions. An example program snippet is shown in Listing 2.
In the conventional case, each iteration of the loop invokes an
idempotency violation due to first reading A[i] then writing
to it next. As a result, backups are very frequent, which may
be undesirable depending on the system parameters.
To address this, as long as the accesses to array A are in
ascending order during the loop, the code can be transformed
to use a circular buffer instead, shown in Line 7. With a
larger circular buffer (of size N) relative to the array size (n),
608
idempotency violations are effectively postponed.3 In general,
the average number of store instructions to A between violations
can be computed as N−n+1.
4 N = n implies the conventional
case with no circular buffering while N = 2 ·n implies double
buffering. With this analysis, given the configuration of the
underlying Clank architecture, the programmer can maximize
performance by solving for the optimal circular buffer size
(Nopt):
 
Nopt −n+1

· τstore = τB,opt (15)
where τstore is the average number of cycles between store
instructions, which can be obtained via application profiling.
With this case study, we show how our EH model can reveal
and characterize unconventional optimizations for intermittent
processor systems.
C. Reduced Bit-Precision Backups
Recently there has been an increased interest in reduced
bit-precision computation [16], [26], [36] and storage [24],
[41] in the architecture community. This is motivated by two
key trends:
1) The growing ubiquity of low-energy devices (e.g., mobile,
internet-of-things, sensor networks) have forced designers
to fight for every last nanojoule of energy under such tight
resource constraints.
2) The widespread use of cognitive (e.g., deep learning, natural language processing) and approximate (e.g., computer
vision, audio and video processing) applications have
opened opportunities for reduced-precision techniques due
to their natural resilience for bit errors.
Intermittent processor architectures provide a unique opportunity for exploiting reduced bit-precision in the backup process.5 Unlike in conventional systems, intermittent processors
frequently save state and thus incur more writes to nonvolatile
memory. In this section, we dive deeper and analyze the factors
that control the performance benefit of reducing bits.
First, we look at reducing bits in architectural (AB) and
application (αB) state. In terms of architectural state, data
words in the register file are attractive candidates for precision
reduction since they are a fixed cost per backup. Applicationspecific data that has been modified since the last backup—
either in volatile buffers [12], volatile caches [31], [56] or writeback buffers [22]—can be large when backups are infrequent.
Solving for ∂ p
∂αB and ∂ p
∂AB in Equation 8 for a multi-backup
system (the analysis is straightforward in single-backup cases),
we find that regardless of how large the architectural state
is (for AB > 0) and how small the application state is (for
αB > 0), the performance benefit of reducing application state
is always higher. Specifically, ∂ p
∂αB ≤ ∂ p
∂AB for τB ≥ 1; both partial
derivatives are negative since the amount of state to back up
3The extra overhead of indexing into the circular buffer is negligible when
N is a power of 2.
4Accounting for the write-back buffer in Clank [22] simply involves adding
the write-back buffer size w to the equation. 5The same analysis extends to the restore process as well; we only focus
on backups to simplify the discussion.
+0%
+1%
+2%
+3%
+4%
+5%
10 100 1000
increase in progress p 
per bit reduction 
τB (cycles between backups, log scale) 
64 : 1 128 : 1 256 : 1
Fig. 11. Increase in progress per bit reduction (| ∂ p
∂αB |) with varying τB for
benchmark susan on Clank [22]. Each curve corresponds to a different ratio of
ΩB ·AB to ΩB ·αB +ε. Assumes eC = 0 and ΩR = 0. The yellow dots indicate
the optimal time between backups (τB,bit).
inversely impacts forward progress. In addition, approximating
architectural state is risky and if not done carefully, can lead
to incorrect program control flow. For example, architectural
state such as the program counter (PC) and any registers might
contain memory addresses must be saved precisely for correct
program execution. Thus for the remainder of this section, we
focus on approximating application state alone.
Given these observations, under what circumstances is it
most beneficial to reduce bit-precision in application state?
The largest bit-precision reduction (i.e., maximum | ∂ p
∂αB |) is
achieved when the time between backups is:
τB,bit = 3
2 · ΩB ·AB
ΩB ·αB +ε ·
16
9 ·
E
ε ·
ΩB ·αB +ε
ΩB ·AB
+1−1

(16)
As expected, this is primarily dictated by the ratio of
compulsory architectural energy (ΩB ·AB) to the energy cost
proportional to how much work was done since the last
backup (ΩB · αB + ε). This is shown in Figure 11, which
plots how the benefit of reduced precision (| ∂ p
∂αB |) varies with
the time between backups for benchmark susan running on
a Clank system [22], configured as in Section V-A. As the
ratio ΩB·AB
ΩB·αB+ε decreases,6 bit-precision reduction favours more
frequent backups (i.e., τB,bit decreases) since the overhead of
saving application state is more impactful. A small ΩB·AB
ΩB·αB+ε
ratio is common when there are few architectural registers while
a large ratio is common in applications with small volatile
memory footprints. With Equation 16, we provide architects
with the sweet spot for deciding when to employ reducedprecision optimizations. For example, suppose we have an
architecture with a large register file, configured as in the
top curve in Figure 11. If we reduce precision by just 1 bit,
we can improve forward progress by up to 4.5% when the
time between backups is at its optimal (τB,bit = 315 cycles).
Note that this analysis does not factor in application error due
to reduced bit-precision. These curves merely help architects
determine if the benefit of reduced-precision will be sufficient
to warrant further investigation.
6We control this ratio by varying αB; all other parameters are set from our
Clank experiments in Section V.
609
D. Summary of Case Studies
We demonstrate how our EH model can 1) expose unconventional insights and 2) catalyze new techniques and optimizations
on state-of-the-art intermittent computing architectures. We
show that programmers and designers need to rethink the tradeoffs between load and store cache locality (Section VI-A). In
Section VI-B, we propose a program transformation that tunes
for the optimal time between backups on Clank processors [22].
We also explore the performance potential of reduced bitprecision, a popular optimization in emerging architectures
(Section VI-C).
VII. RELATED WORK
In this section, we look at evaluation methodologies for intermittent processor architectures and related work in modeling
resilience for real-time and high-performance computing.
Analytical Models. Energy driven computing provides a taxonomy of energy-harvesting designs, spanning power-neutral,
transient, and energy-driven systems [40]. Hibernus details a
mathematical model comparing the time spent on execution for
their system as well as Mementos and show that they achieve
lower overhead [6]. Mathematical models of data sensed by
energy-harvesting systems can aid designers [9]. Rodriguez
et al. build on the Hibernus analytical model and expand it
to show the breakdown of time and energy for three prior
approaches, namely Mementos [43], Hibernus [5] and Quick
Recall [25] across various application scenarios. They show that
Hibernus achieves lower overhead than Mementos and is more
energy efficient at lower interruption frequencies compared to
QuickRecall, while QuickRecall is more energy efficient at
higher frequencies. While these approaches aim to aid designers
to pick the optimal system for their situation, they are limited
to making a recommendation from a small set of approaches.
In contrast, our model targets a wider range of intermittent
computing architectures, including checkpoint-based and nonvolatile processor systems.
Simulation. Simulation has been used to evaluate different
devices [6], [22], [38]. Through simulation, Clank identified
that re-execution cost (i.e., dead cycles) can outweigh the
cost of checkpointing [22]. The EH model allows similar
observations to be made without the implementation details of
a backup/restore mechanism, revealing insights from simple
formulas. Several simulators enable exploration of various
designs in the energy-harvesting space. NVPsim explores NVP
designs by varying the choice of nonvolatile memory for onchip caches, the backup strategy and size of the energy buffer
[17]. SIREN supplements cycle-level simulation with realworld energy-harvesting conditions, captured from real power
sources [15]. In contrast to these simulators, the EH model
allows for more rapid and wide ranging exploration of the
intermittent computing design space. Ekho proposes an I–V
curve to capture how current changes when checkpointing
with a variable energy supply [20]. Our EH model is more
architecture centric, focusing on the active period and requiring
the energy supply to be fully charged before execution resumes.
Resilience. Checkpointing is a common mechanism for resilience against faults in real-time and high-performance computing. Early models for resilience [13], [57] bear similarities
to the multi-backup components of our model. This is because
faults were approximated as periodic events (based on mean
time to failure); though recent work [2], [3], [10], [19], [49]
opts for more sophisticated probabilistic models. The EH model
addresses a fundamentally different problem in general: faults
are spontaneous events while power losses are progressively
decaying events. This means that imminent power losses can
be anticipated (via ADC checks) and postponed (via charging),
both of which are unique to the single-backup and charging
components of our model. Our model is also unique in its
ability to account for architectural/application state and nonvolatile memory technologies, whereas resilience models often
focus on I/O congestion and thread scheduling [2], [3], [10],
[19], [49]. Still, the parallels between our multi-backup model
and prior models pose an interesting exploration space that
can bridge innovations between intermittence and resilience.
VIII. CONCLUSION
We propose the EH model, a step towards better understanding the implications and complex interactions that arise in
intermittent processor systems. We derive our model to compute
forward progress as the fraction of harvested energy that is
spent on useful processor execution, as opposed to energy spent
on backups, restores, dead execution and reading the supply
level. This makes for a clear understanding of how well a given
architecture performs and under what circumstances it performs
better. We present several explorations, hardware validations
and case studies that demonstrate the effectiveness of our model
for both architects and programmers. In particular, we show
how our model reveals new insights and unconventional design
considerations pertaining to cache locality, idempotency and
reduced bit-precision. Our EH model facilitates early design
space explorations, to both assist and excite research in this
field.
