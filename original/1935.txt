Abstract—Modern processors typically provide a small number
of hardware performance counters to capture a large number of
microarchitecture events 1
. These counters can easily generate a
huge amount (e.g., GB or TB per day) of data, which we call big
performance data in cloud computing platforms with more than
thousands of servers and millions of complex workloads running
in a ”24/7/365” manner. The big performance data provides
a precious foundation for root cause analysis of performance
bottlenecks, architecture and compiler optimization, and many
more. However, it is challenging to extract value from the big
performance data due to: 1) the many unperceivable errors (e.g.,
outliers and missing values); and 2) the difficulty of obtaining
insights, e.g., relating events to performance.
In this paper, we propose CounterMiner, a rigorous methodology that enables the measurement and understanding of big
performance data by using data mining and machine learning
techniques. It includes three novel components: 1) using data
cleaning to improve data quality by replacing outliers and filling
in missing values; 2) iteratively quantifying, ranking, and pruning
events based on their importance with respect to performance; 3)
quantifying interaction intensity between two events by residual
variance. We use sixteen benchmarks (eight from CloudSuite
and eight from the Spark 2 version of HiBench) to evaluate
CounterMiner. The experimental results show that CounterMiner
reduces the average error from 28.3% to 7.7% when multiplexing
10 events on 4 hardware counters. We also conduct a real-world
case study, showing that identifying important configuration
parameters of Spark programs by event importance is much
faster than directly ranking the importance of these parameters.
Index Terms—performance, big data, computer architecture,
performance counters, data mining
I. INTRODUCTION
Modern processors typically provide 4-8 hardware counters
to measure hundreds of crucial events such as cache and TLB
misses [1]–[4]. These events can generally reveal root causes
and key insights about the performance of computer systems.
1We use events to represent microarchitecture events throughput the paper.
2We use Spark to represent Apache Spark throughput the paper.
Therefore, performance counter based analysis is applied in a
wide range of applications, including task scheduling [5], [6],
workload characterization [7]–[14], performance optimization
of applications [15]–[18], compiler optimization [19]–[21],
architecture optimization [22], and many more. A number
of programable performance measurement tools have therefore been developed, including PAPI [23], VTune [24], Perfmon [25], Oprofile [26], and many others [27], [28].
However, there is a fundamental tension between accuracy and efficiency when using a small number of hardware
counters to measure a large number of events. On the one
side, the one counter one event (OCOE) approach can achieve
high accuracy because a number of events are measured by
the same number of hardware counters at a time. Obviously,
OCOE becomes inefficient with more than one hundred and
up to fourteen hundreds of measurable events [29].
This motivates the multiplexing (MLPX) approach, which
improves the measurement efficiency by scheduling events
from a fraction of execution to be counted on hardware
counters and extrapolating the full behavior of each event from
its samples. However, MLPX incurs large measurement errors
due to time-sharing and sampling [4], [30]–[32].
In cloud computing era, this problem is exaggerated for two
reasons. First, resolving the measurement errors of MLPX is
a requirement. A modern cloud computing platform usually
consists of more than thousand of servers and millions of complex workloads running services with diverse characteristics
in a ”24/7/365” manner. The major companies have good
incentives to understand the performance behavior because
a small performance improvement (e.g., 1%) can result in
millions of dollars of savings [7]. In this context, randomly
selecting and measuring a small number of events with OCOE
is not sufficient because the cloud services’ performance may
be affected by the unmeasured events. To measure a large
number of events, using MLPX and handling its measurement
errors are mandatory. Prior work shows that the errors cannot
613
2018 51st Annual IEEE/ACM International Symposium on Microarchitecture
978-1-5386-6240-3/18/$31.00 ©2018 IEEE
DOI 10.1109/MICRO.2018.00056
be effectively avoided during the sampling [33], [34].
Second, it becomes more difficult to extract insights of
performance behavior. The events of server processors in a
cloud computing platform can generate a huge amount of data,
leading to big performance data. For example, GWP (Googlewide-Profiler) [7] could generate several GBs of performance
data per day. If we treat the data equally, the high event
dimensionality (typically > 100) incurs extremely high cost.
In this paper, we propose CounterMiner, a rigorous methodology that enables the measurement and understanding of the
big performance data with data mining and machine learning
techniques. It includes three components: 1) data cleaner,
which improves the counter data quality by replacing outliers
and filling in missing values after the sampling of MLPX,
which is complementary to [33], [34]; 2) importance ranker,
which iteratively quantifies, ranks, and prunes events based on
their importance with respect to performance; 3) interaction
ranker, which quantifies interaction intensity between two
events by residual variance.
We use sixteen benchmarks that eight from CloudSuite [35]
and eight from the Spark version of HiBench [36] to evaluate
CounterMiner. The experimental results show that CounterMiner reduces the average error from 28.3% to 7.7% when
multiplexing 10 events on 4 hardware counters. We also
conduct a real-world case study, showing that identifying
important configuration parameters of Spark programs by
event importance is much faster than directly ranking the
importance of these parameters.
Moreover, CounterMiner reveals a number of interesting
findings: 1) the event of stall cycles due to instruction queue
full is the most important event for most cloud programs; 2)
the branch related events interact with other events the most
strongly; 3) there is a ’one-three significantly more important’
law (’one-three SMI’ for short) which concludes that generally one to three events of a benchmark are significantly
more important than others with respect to performance; 4)
a number of noisy events of a modern processor can be
definitely removed; 5) there are common important events
related to branches, TLBs (instruction, data, and second-level
TLBs), and remote memory and remote cache operations; 6)
the eight Spark benchmarks from HiBench surprisingly show
more diversity than those from CloudSuite when we look at
the top ten important events. These findings are valuable to
guide cross-layer performance optimizations of architecture
and applications of cloud systems.
The rest of this paper is organized as follows. Section II
discusses the background and motivation. Section III presents
our CounterMiner framework. Section IV describes the experimental methodology. Section V provides the results and
analysis. Section VI discusses the related work, and Section VI
concludes the paper.
II. BACKGROUND AND MOTIVATION
A. Hardware Counters
Every modern processor has a logical unit called Performance Monitoring Unit (PMU) which consists of a set of
hardware counters. A counter counts how many times a certain
event occurs during a time interval of a program’s execution.
The number of counters may vary across microarchitectures
or even processor modes within the same microarchitecture.
For example, ARM Cortex-A53 MPCore processor has six
counter registers [2] while recent Intel processors have three
fixed counters (which can only measure specific events such as
clock cycles and retired instructions) and eight programmable
counters per core (four per SMT thread if it is enabled) [1].
The events that can be measured by hardware counters
are predefined by processor vendors. The number of events
may also be significantly different for different generations
of processors within the same microarchitecture, let alone
different microarchitectures. For instance, the basic Ivy-Bridge
model defines only 338 events whereas the high-end IvyTown
chips support 1423 events [29]. In summary, the number of
events greatly outnumbers that of hardware counters (more
than one hundred vs. less than ten).
There are two ways to program hardware counters to capture
events. In the one counter one event (OCOE) approach, one
hardware counter is only programmed for counting one event
during the whole profiling period of a program. OCOE is
accurate because one counter is dedicated to one event at a
time. However, OCOE is ineffective because one usually needs
to measure a large number of events to identify the root causes
of performance bottlenecks for an unknown system [37]. The
number of events that can be simultaneously measured in
OCOE is equal to or less than that of the available hardware
counters of a processor.
Multiplexing (MLPX) is developed to improve the measurement efficiency by letting multiple events timeshare a single
hardware counter [4], [38]. In MLPX, events are scheduled
to be sampled during a fraction of execution. Based on the
samples, the full behavior of each event is extrapolated [30].
However, large measurement errors occur with MLPX because information may be lost when the event does not happen
during a sampled interval [30], [33], [34] but happens during
a un-sampled interval. Mathur et al. [38] reported that higher
than 50% of errors were observed when the SPEC CPU 2000
benchmarks were profiled with MLPX.
B. Motivation
1) Measurement Errors: while some prior works such as
[14], [15] employ OCOE to measure performance, MLPX is
mandatory when a large number of events need to be sampled,
e.g., for emerging workloads in cloud computing. Moreover,
quantifying measurement errors is a fundamental challenge
due to the sampling nature of MLPX.
We conduct the following experiments to observe the errors
caused by MLPX. We firstly run a set of cloud computing
programs and measure their events by OCOE. Since different
runs of the same program in cloud computing platforms may
take different times, which is caused by the non-deterministic
nature of modern operating systems, the different time series
for the same event may have different lengths. The traditional
approaches such as calculating the Euclidean or Manhattan
614
0% 
10% 
20% 
30% 
40% 
50% 
AGG BAY JON KME PGR SCN SOT WDC AVG 
error 
Fig. 1. The measurement errors caused by MLPX. WDC-wordcount, PGRpagerank, AGG-aggregation, JON-join, SCN-scan, SOT-sort, BAY-Bayes,
KME-kmeans, DAA-DataAnalytics, DAC-DataCaching, DAS-DataServing,
GPA-GraphAnalytics, IMA - In-memoryAnalytics, MES-MediaStreaming,
WSH-WebSearch, WSG-WebServing. AVG-average error.
distance between two vectors cannot calculate the performance
behavior differences [39] because they require the two vectors
have the same length. In order to compute the distance
(difference) between two time series, we must “wrap” the
time axis of one (or both) sequences to achieve a better
alignment. Dynamic time wrapping (DTW) [40] is a technique
for efficiently achieving this wrapping. It employs a dynamic
programming approach to align one time series to one another
so that the distance measurement is minimized. We therefore
employ DTW to calculate the distance between two event time
series as follows:
dist = DTW(S1, S2) (1)
where S1 and S2 are the first and second time series for the
same event, respectively. Note that the length of S1 is not
necessarily equal to that of S2.
First, we calculate the DTW between two time series
collected by OCOE, denoted by distref .
distref = DTW(Socoe1, Socoe2) (2)
where Socoe1 and Socoe2 are the two time series for a certain
event of the same program collected by OCOE. Due to
the accuracy of OCOE and non-deterministic nature of OS,
distref is a nonzero value but is theoretically close to zero.
Second, we compute the DTW between one time series collected by MLPX and one by OCOE, represented by distmea.
distmea = DTW(Smlpx, Socoe) (3)
where Smlpx and Socoe are the time series collected by MLPX
and OCOE, respectively. Smlpx and Socoe are for the same
program with the same event. Theoretically, distmea is larger
than distref due to MLPX.
Finally, we define the error caused by MLPX as follows:
error = |1 − distref
distmea
| × 100% (4)
This error definition roughly quantifies how close the time
series generated by MLPX is to the one obtained by OCOE.
Since Socoe1 and Socoe2 are both collected by OCOE for the
same program with the same event, distref is a very small
value that is close to zero. In contrast, distmea is larger than
distref . Thus, error reflects the error caused by MPLX.
Figure 1 shows that the errors caused by MLPX for the event
ICACHE.MISSES for 16 programs (the program description
is presented in Section IV-B). We can see that the minimum
and maximum errors are 8.8% and 43.3%, respectively. The
0
0.5
1
1.5
2
2.5
3
3.5
1
39
77
115
153
191
229
267
305
343
381
419
# of u ops(x103)
measurement samples
OCOE
MLPX
0
10
20
30
40
50
60
1
33
65
97
129
161
193
225
257
289
321
353
385
417
# of misses
measurement samples
OCOE
MLPX
outliers missing values
(a) (b)
Fig. 2. The outlier and missing value examples in benchmark WordCount.
(a) The outliers in the time series of event IDQ.DSB UOPS (the # of uops
delivered to Instruction Decode Queue from the Decode Stream Buffer path).
(b) The missing values in the time series of event ICACHE.MISSES (the #
of instruction cache misses per 1K instructions).
average error achieves 28.3%. For other events, we observe
similar or even higher errors.
By carefully analyzing the errors, we find two root causes:
outliers and missing values. Figure 2 (a) shows an example of
outliers. In the end of the time series of event IDQ.DSB UOPS
collected by MLPX, the number of UOPS is 4.2× of the
normal numbers collected by OCOE. Such outliers will significantly “improve” the overall results if they are taken into
account. On the other hand, Figure 2 (b) illustrates an example
of missing values. By using OCOE, we observe a large number
of instruction cache misses at the beginning of the time series
of event ICACHE.MISSES. This is reasonable because at the
beginning of a program execution, the instruction cache is
empty (a.k.a ”cold cache”) and a large number of misses
must happen. However, these instruction cache misses are not
observed by MLPX. These examples indicate that MLPX may
indeed cause large errors. Moreover, simultaneously measuring
more events in MLPX generally exacerbates the problem, as
shown in Figure 3. These errors, however, are difficult to
be removed by event scheduling [33], [34] and estimation
algorithms [38]during the sampling procedure. This motivates
us to reduce them by data cleaning techniques after the
sampling procedure of MLPX, which is very important for
mining the CPU big performance data in an off-line manner.
2) Are all events equally important?: Due to the large number of measurable events compared to the available hardware
counters (e.g., 207× for HaswellX [29]), MLPX is therefore
mandatory, but it comes at a high cost. Figure 3 shows
that the MLPX errors increase with more events measured
simultaneously with the limited hardware counters (red line
indicates the trend). To lower the errors, the number of events
measured by the same counter during a program’s execution
needs to be limited. However, this makes the same program
need to run many times to measure all the events of the
processor being used.
On the other side, measuring all events may not be necessary. First, even if we measure all the events accurately in an
ideal scenario at the same time, most values are zeros, which
is inconceivable. Second, the optimization overhead would be
extremely high when considering all the events of a processor.
In fact, to improve performance, an OS can only leverage
a small number of events to provide feedback to a runtime
system for optimization [29].
Therefore, it is crucial to identify a subset of events that are
615
37% 
35% 
41% 
55% 50% 
44% 
54% 
30% 
35% 
40% 
45% 
50% 
55% 
10 16 20 24 28 32 36 
error 
The number of events collected simultaneously 
Fig. 3. The error variation with the number of events (represented by the
numbers along with X axis) measured simultaneously.
strongly relevant for a given architecture or workload [29]. It
can reduce both measurement and optimization overhead. The
key to achieve this goal is to quantify the importance of events.
III. COUNTERMINER METHODOLOGY
CounterMiner is a methodology designed to mine the big
performance data collected from hardware counters. It reduces
the measurement errors of MLPX by leveraging data cleaning
techniques rather than traditional event scheduling [33], [34]
and estimation algorithms [38]. CounterMiner is complementary to [34] [33] [38] because CounterMiner does that
after (not during) the sampling. Moreover, it quantifies the
importance of events and the interactions between two events
with respect to performance. Figure 4 shows the workflow of
CounterMiner. It consists of four components: data collector,
data cleaner, importance ranker, and interaction ranker.
A. Data Collector
The data collector is in charge of sampling the values of
events when a program is running. It supports two modes:
OCOE and MLPX. The data collector can be any available
counter profiling tools such as Perf [41] and Permon2 [25]. In
this paper, we use the Linux Perf [41] because it is available
in all Linux distributions.
We take the sampled values of an event as a time series
since it is important to observe the time varying behaviors of
the event [30]. We formally describe the time series as follows:
T Sei = {Vi1, Vi2, ..., Vij , ..., Vin} (5)
where T Sei is the time series for the i
th event of a program,
Vij is the jth value of the i
th event, and n is the total
number of sampled values for T Sei. The important feature
as well as challenge of these time series is that their lengths
may be significantly different even for the same event of the
same program because of the non-deterministic behavior of a
modern OS. This property makes storing and analyzing these
time series challenging.
We store the collected time series in a database management
system (DBMS) which can be any popular DBMS such as
MySQL and SQL Server. In CounterMiner, we employ SQLite
because it seamlessly integrates with Python which is the
program language we used for data analysis. In the database,
we design a two-level table organization. The first level tables
store information including the name of a program, the names
of the measured events, the execution times of the program,
and the names of the second-level tables. The second-level
tables store the time series for the measured events for a
program at each run. Note that these two level tables may
need to be re-initialized when CounterMiner is applied on a
different microarchitecture.
Event selection Event selection Event selection
Perf Tools
Workloads
Raw time series
Data integrator
Data filter
Data interpolator
Importance 
quantification
Event selection
<e1,e2> pair
Removing outliers
Making up 
missed values
Data collector Data cleaner Importance Ranker Interaction Ranker
Machine learning algorithm library
Performance 
counter database
Fig. 4. Block Diagram of CounterMiner.
B. Data Cleaner
The outliers and missing values of events are the main
error sources of the collected data with MLPX. Data cleaner
replaces the outliers by normal values and fills in the missing
values. To evaluate the accuracy of the data cleaner, we take
the values of events collected by OCOE as golden references.
1) Replacing Outliers: To determine outliers, we first perform a rigorous statistic testing (see Section IV-C for the
testing tool) on the value distributions of all 229 events. We
find that, only for 100 events, their values follow Gaussian
distribution. We further investigate the value distributions
of the other 129 events and find they all show long tail
distribution but with different levels. In order to find out the
long tail distributions, we perform the statistic testing on them
using several different distribution functions such as logistic
and Gumbel (general extreme value - GEV) distributions. We
find the GEV distribution best fits the long tail distributions,
which has been confirmed by [15].
After knowing the value distributions of the events, we
design the criterion to replace the outliers. We employ a
general technique from data mining to determine outliers by
the following equation:
threshold = mean + n × std (6)
where threshold is the criterion for replacing outliers, mean
and std are the mean value and the standard deviation of a
series of values of an event, respectively; n is a control variable
which needs to be determined according to the distribution or
user requirements such as the percentage of data within the
threshold. According to [42], if a data series obeys Gaussian
distribution, n equals 3.
Since the values of a large number of events do not obey
the Gaussian distribution but instead long tail distribution. We
need to determine n by controlling the percentage of data
within the threshold. In this study, we specify that 99% of the
collected data for events of a program are within the threshold
because there are not many outliers based on our confirmed
observation. Table I shows the percentage of data within the
threshold with different n values. We see that when n is 5,
the percentages of data within the threshold for all programs
exceed 99%, we therefore set n to 5.
When an outlier is found, we use the median value of the
interval where the outlier locates to replace the outlier. The
interval length is calculated as follows.
L = M ax(T Sei) − M in(T Sei)
Roundup(Sqrt(Count(T Sei)), 0) (7)
616
Benchmarks n=3 n=5 Benchmarks n=3 n=5
wordcount 98.8% 99.3% DataAnalytics 99.3% 99.8%
pagerank 98.6% 99.4% DataCaching 99.1% 99.8%
aggregation 99.3% 99.8% DataServing 99.4% 99.8%
join 98.9% 99.8% GraphAnalytics 99.2% 99.8%
scan 99.3% 99.8% In-mAnalytics 99.2% 99.8%
sort 98.9% 99.5% MediaStreaming 99.3% 99.8%
bayes 98.6% 99.8% WebSearch 98.8% 99.7%
kmeans 99.1% 99.8% WebServing 99.1% 99.5%
TABLE I
THE COVERAGE RATE WITH DIFFERENT VALUES OF n.
with M ax(T Sei) and M in(T Sei) the maximum and minimum values in T Sei, respectively, Count(T Sei) the number
of values in T Sei, Sqrt the square root, and Roundup the
round up value.
2) Filling in Missing Values: To fill in missing values, we
first classify the event values into two categories: zero values
and none-zero values. Based on our observation, zero values
are highly likely to be missing values. However, it is still
possible that the values of a certain event at some points
are indeed zeros. It is therefore difficult to distinguish them
from the missing values. To address this issue, we check the
maximum and minimum values of the event in the past. If the
minimum value is zero and the maximum value is less than
0.01, we consider that the zero value for the event is not a
missing value. The rationale is that the maximum value of an
event is only 0.01 which is very close to zero, and even the
actual value is not zero, the error would not be high.
For the none-zero value category, we employ KNN (KNearest Neighbor) algorithm [43] to fill in missing values. For
example, a series of data for ICACHE.MISSES is as follows:
{X1, X2, X3, X4, X5, 0, X7, ..., Xi, ..., Xm} (8)
where Xi is the i
th value of ICACHE.MISSES, m is the
total number of values, and 0 is the missing value. We
use KNN regression to calculate the missing value and it is
represented by the average value of the k nearest neighbors.
The determination of k is important because it affects the
accuracy. In this study, we tried several values from 3 to 8
based on [42] and find that k = 5 is accurate enough to
represent the missing value.
C. Importance Ranker
In order to quantify the importance of events with respect to
IPC (Instructions Per Cycle), an accurate performance model
needs to be constructed. The inputs of the model are event
values and the output is IPC, which can be represented by:
IPC = perf(e1, e2, ..., ei, ..., en) (9)
where ei is the value of the i
th event, and n is the total number
of events. As discussed before, n is typically larger than 100
and up to 1423 for modern processors. For the processors
used in this paper, n is 229. It is extremely challenging
to build an accurate performance model with such a large
number of input parameters. Analytical modeling techniques
are not suitable for this case because they allow only a few
parameters (e.g., less than 5). Moreover, analytical models are
not accurate when dealing with complex cases. Statistical modeling techniques are either not accurate with high dimensional
inputs because they make an unrealistic assumption that the
relationship between the input parameters are linear. However,
complex nonlinear relationships typically exist between events
of modern processors.
To solve this problem, machine learning techniques are
applied to construct accurate models with high dimensional
inputs. To mitigate over-fitting, we use an ensemble learning
algorithm, Stochastic Gradient Boosted Regression Tree (SGBRT) [44], to construct the model. The key insight is that
SGBRT combines a number of tree models in a stagewise
manner, where each one reflects a part of the performance.
The final model is called ensemble model. With performance
model constructed, we can leverage the model to quantify the
importance of events and their interactions. Clearly, a more
accurate performance model results in more precise event
importance quantification.
For a single tree T in an ensemble model, one can use
I2
j (T) as a measure of importance for each event ej , which
is based on the number of times ej is selected for splitting a
tree weighted by the squared improvement to the model as a
result of each of those splits [45]. This measure of importance
is calculated as follows:
I2
j (T) = nt ·
nt
i=1
P2(k), (10)
where nt is the number of times ej is used to split tree T,
and P2(k) is the squared performance improvement to the
tree model by the kth split. In particular, P(k) is defined as
the relative IPC error which is (IPCk − IPCk−1)/IP Ck−1
after the kth split. If ej is used as a splitter in R trees in the
ensemble model, the importance of ej to the model equals:
I2
j = 1
R

R
m=1
I2
j (Tm). (11)
To make the results intuitive, the importance of an event is
normalized so that the sum across all events adds up to 100%.
A higher percentage indicates stronger influence of the event
on performance.
After the importance of each event with respect to performance is obtained, we rank them in a descending order.
Then, we remove the 10 least important events and take the
remainders as input parameters to construct a performance
model by using the SGBRT algorithm again. We conduct the
same procedure on the new model to quantify the importance
of the remaining events and rank them. This procedure may
iteratively repeat several times until we obtain the Most Accurate Performance Model (MAPM) for a program and we call
this procedure Event Importance Refinement (EIR). The event
importance obtained by MAPM is the most accurate [45].
D. Interaction Ranker
After we obtain a set of important events, we construct a
linear regression model per pair of the events and consider
617
the residual variance of the model as an indication for interaction intensity. The intuition is that if two microarchitecture
events are orthogonal (i.e., they do not interact), the residual
variance will be small because the linear model will be able
to accurately predict the combined effect of both events.
If on the other hand, the microarchitecture events interact
substantially, this will be reflected in the residual variance
being significantly larger than zero, because the linear model
is unable to accurately capture the combined effect of the
event pair. The linear regression model is trained for each
pair of important events by setting the values of all other
events to their respective means. This process is repeated for
each possible event pair. The residual variance or interaction
intensity for a particular event pair is computed as:
v = n
i=1
(pi − p)
2, (12)
where pi is the performance (IPC) predicted by the linear
regression model, p is the observed performance, and n is
the number of predictions. Zero indicates that there is no
interaction between two microarchitecture events, and a higher
value indicates a stronger interaction.
To indicate the importance of interactions among all possible pairs, we normalize interaction intensity against the other
pairs as follows:
Ii =
⎛
⎜⎜⎝
vi
n
j=1
vj
⎞
⎟⎟⎠
× 100%, (13)
where Ii is the importance of the i
th event-pair interaction
and vi is the i
th event-pair interaction intensity. After the
normalization, we can tell how much more/less important an
event pair is compared to another event pair, — reflecting the
relative interaction intensity of event pairs.
IV. EXPERIMENTAL METHODOLOGY
A. Experimental Cluster
Our experimental cluster consists of four Dell servers, one
serves as the master node and the other three serve as slave
nodes. Each server is equipped with 12 Intel(R) Xeon(R) CPU
E5-2630 v3 @ 2.40GHz eight-core processor with HaswellE microarchitecture and 64GB PC3 memory. The OS of
each node is SUSE Linux Enterprise Server 12. The OS of
the whole cluster is Mesos1.0. Although our experimental
cluster is small compared to a cloud platform, we believe that
evaluating CounterMiner in this environment is still sufficient,
because it is essentially a performance analysis methodology.
In a real cloud platform, CounterMiner can easily work with
the Google Wide profiler (GWP) to provide more meaningful
results. In addition, it can be integrated with cluster management tools such as Quasar [46] and other cloud computing
researches such as [47]–[49].
Benchmarks Framework Input data
wordcount Spark 2.0 generated by RandomTextWriter.
pagerank Spark 2.0 hyperlinks with Zipfian.
aggregation Spark 2.0 hyperlinks with Zipfian.
join Spark 2.0 hyperlinks with Zipfian.
scan Spark 2.0 hyperlinks with Zipfian.
sort Spark 2.0 generated by RandomTextWriter.
bayes Spark 2.0 words with Zipfian.
kmeans Spark 2.0 numbers with Gaussian.
DataAnalytics Hadoop a Wikimedia dataset.
DataCaching Memcached a Twitter dataset.
DataServing Cassandra a YCSB dataset.
GraphAnalytics GraphX a Twitter dataset.
In-mAnalytics SparkMLlib a move-rating dataset.
MediaStreaming Nginx a synthetic video dataset.
WebSearch Apache Solr a set of crawled websites.
WebServing Elgg generated by Faban.
TABLE II
THE EXPERIMENTED BENCHMARKS.
0
0.5
1
1.5
2
2.5
3
3.5
1
39
77
115
153
191
229
267
305
343
381
419
# of u ops(x103) 
measurement samples
OCOE
MLPX
MLPX-CLN
0
10
20
30
40
50
60
1
35
69
103
137
171
205
239
273
307
341
375
409
# of misses
measurement samples
OCOE
MLPX
MLPX-CLN
Outliers are replaced Missing values are filled in
Fig. 5. The event cleaning examples. (a) The replaced outliers in the time
series of IDQ.DSB UOPS. (b) The filled in values in the time series of
ICACHE.MISSES. MLPX-CLN represents the cleaned time series.
0% 
10% 
20% 
30% 
40% 
50% 
WDC PGR AGG JON SCN SOT BAY KME AVG 
error 
RAW CLN 
Fig. 6. The measurement error comparison between before and after our data
cleaning approach is employed.
B. Benchmarks
We employ CloudSuite 3.0 [35] and select eight programs
from HiBench with version of Spark 2.0 [36] (a.k.a ”SparkBench”) to evaluate CounterMiner in this study. CloudSuite
3.0 is a benchmark suite for cloud services and it consists
of eight applications based on their popularity in today’s
datacenters. HiBench with Spark 2.0 consists of a broad set
of MapReduce-like programs implemented by Spark 2.0. The
benchmarks are listed in Table II. The benchmarks in CloudSuite use different frameworks while the ones in HiBench
employ the same framework but represent four categories of
applications including websearch, SQL, machine learning, and
microbenchmarks.
C. Modeling Tools
We use Python, a freely available high-level programming
language, to perform our SGBRT modeling and KNN modeling. The Python version is 2.7 and we use scikit-learn 0.19.0
which is a machine learning algorithm library implemented
in Python to construct our performance models. To perform a
rigorous statistic testing for the value distribution of events,
we employ SciPy [50] which is an open-source software
for mathematics, science, and engineering. In which, we use
618
Abbr. Event Description
ISF ILD STALL.IQ FULL stall cycles due to IQ is full.
ISL ILD STALL LCP counts cycles where the decoder is stalled on an inst with a length changing prefix (LCP).
BRE BR INST EXEC.ALL BRANCHES counts all near executed branches (not necessarily retired).
IPD INST RETIRED.PREC DIST Precise inst retired event with HW to reduce effect of PEBS shadow in IP distribution.
BRB BR INST RETIRED.ALL BRANCHES counts the number of retired branch instructions.
BMP BR MISP RETIRED.ALL BRANCHES mispredicted macro branch instructions retired.
PI3 PAGE WALKER LOADS.ITLB L3 counts the number of extended page table walks from ITLB hit in the L3.
ITM ITLB MISSES.WALK DURATION counts the number of cycles while PMH (page miss handler) is busy with the page walk.
DSP DTLB STORE MIS.PDE CACHE MIS DTLB store misses with low part of linear-to-physical address translation missed.
DSH DTLB STORE MIS.STLB HIT store ops that miss the first TLB level but hit the second and do not cause page walks.
MMR MEM LD UOPS L3 MIS.R M Retired load uops whose data source was remote DRAM.
MUL MEM UOPS RETIRED.ALL LOADS Load uops retired to architected path with filter on bits 0 and 1 applied.
URA UOPS RETIRED.ALL Counts the number of micro-ops retired..
URS UOPS RETIRED.RETIRE SLOTS counts the number of retirement slots used in each cycle.
MCO MACHINE CLEARS.MEMORY ORDERING counts the number of machine clears due to memory order conflicts.
MSL MEM UOPS RETIRED.STLB MISLD load uops with true STLB (second level TLB) miss retired to architected path.
MLL MEM UOPS RETIRED LOCK LOAD load uops with locked access retired to architected path.
PDM PAGE WALKER LOADS.DTLB MEMORY number of DTLB page walker hits in memory.
TFA TLB FLUSH.STLB ANY count number of STLB (second TLB) flush attempts.
LAA LD BLKS PARTIAL.ADDR ALIAS false dependencies in MOB (memory order buffer) due to partial compare on address.
LSF LD BLKS.STORE FORWARD loads blocked by overlapping with store buffer that cannot be forwarded.
BRC BR INST RETIRED.CONDITIONAL counts the number of conditional branch instructions retired.
BNT BR MISP RETIRED.NEAR TAKEN number of near branch instructions retired that were mispredicted and taken.
LMH MEM LD UOPS L3 MIRE.R H retired load uops whose data sources were a remote HitM responses.
UEP UOPS EXECUTED PORT.PORT 0 cycles during which uops are dispatched from the Reservation Station (RS) to port 0 (on the per-thread basis).
MLH MEM LOAD UOPS RETIRED.L1 HIT retired load uops with L1 cache hits as data sources.
MST MEM UOPS RETIRED.STLB M ST store uops with true STLB miss retired to architected path.
IM4 ITLB MISSES.WALK COMPLD 4K code miss in all TLB levels causes a page walk that completes (4K).
IMC ITLB MISSES.WALK COMPLD misses in all ITLB levels that cause completed page walks.
LHN LD UOPS L3 H R.X N retired load uops which data sources were hits in L3 without snoops required.
CAC CYC ACT.CYC LDM PEND cycles with pending memory loads.
C2P CYC ACT.STAL L2 PEND number of missed L2.
LUO LSD.UOPS Number of uops delivered by the LSD.
PLM PAGE WALKER LD.DTLB MEM number of DTLB page walker loads from memory.
OTS OTHER ASSISTS.AVX TO SSE number of transitions from AVX-256 to legacy SSE when penalty applicable.
I4U IDQ.ALL MITE CYCLES 4 UOPS counts cycles MITE is delivered four uops. Set Cmask = 4.
ORA OFFCORE REQUESTS.ALL DATA RD data read requests sent to uncore (demand and prefetch).
BAA BACLEARS.ANY number of front end re-steers due to BPU (Branch Prediction Unit) misprediction.
LRC L2 RQSTS.CODE RD MISS number of instruction fetches that missed the L2 cache.
MIE MOVE ELIMINATION.INT ELIMINATED number of integer move elimination candidate uops that were eliminated.
ORO OFCORE REQ OUSTAND.AL D RD Offcore outstanding cacheable data read transactions in SQ (Super Queue) to uncore.
IDU IDQ.DSB UOPS the number of of uops delivered to IDQ (instruction dispatch queue) from DSB (decode stream buffer) path.
LRA L2 RQSTS.ALL RFO counts all L2 store RFO (read for ownership) requests.
TABLE III
EVENT NAME AND DESCRIPTION FOR THOSE APPEARED IN THE 10 MOST IMPORTANT EVENT LIST OF EACH BENCHMARK.
37% 35% 41% 
55% 50% 44% 
54% 
5.30% 
17.08% 
6.80% 
23.61% 28.96% 
13.38% 
29.39% 
0% 
10% 
20% 
30% 
40% 
50% 
60% 
10 16 20 24 28 32 36 
error 
The number of events collected simultanesously 
RAW 
Fig. 7. The measurement error comparison between before and after our data
cleaning approach is employed when different number of events are measured
simultaneously by MLPX.
scipy.stats.anderson to perform Anderson-Darling test for data
coming from a particular distribution.
V. RESULTS AND ANALYSIS
A. Error Reduction
Figure 5 shows the cleaning results for the outlier and missing value examples shown in Figure 2. MLPX-CLN represents
the cleaned times series for the corresponding events. The
benchmark is wordcount in these two examples. Figure 5 (a)
illustrates that the outliers are correctly replaced and Figure 5
(b) shows that most missing values are filled in.
Figure 6 compares the measurement errors before (blue
bars) and after (red bars) applying our data cleaning techniques
on the times series of ICACHE.MISSES for the sixteen
benchmarks. We see that our data cleaner significantly reduces
the errors caused by MLPX. In particular, the average error is
reduced from 28.3% to 7.7% thanks to data cleaning.
Figure 7 illustrates the behavior of the data cleaner when we
increase the number of events measured by MLPX at a time.
We made several interesting observations. 1) The data cleaner
significantly reduces the errors caused by MLPX in each case.
With 10 events, the error is reduced to only 5.3%. 2) The
data cleaner accurately follows the error trend when number
of simultaneously measured events increases. 3) Although no
error is larger than 30% in all cases, some errors are high such
as 23.6% in the case of 24 events. This indicates that we can
not measure too many (e.g., 24) events at the same time even
with data cleaner. As a general recommendation, the number
should not be larger than 20.
B. Important Events
As mentioned in Section III-C, the event importance obtained by MAPM (the most accurate performance model) is
the most accurate [45]. We therefore perform the EIR (event
importance refinement) procedure aiming to get MAPM before
619
0% 
5% 
10% 
15% 
20% 
25% 
30% 
35% 
40% 
45% 
229 
219 
209 
199 
189 
179 
169 
159 
149 
139 
129 
119 
109 
99 
89 
79 
69 
59 
49 
39 
29 
19 
9 
err 
wordcount kmeans 
pagerank aggregation 
join scan bayes sort 
avg 
Fig. 8. The error variation of the models when we reduce the number of
events used as their inputs for HiBench benchmarks. The X axis represents
the numbers of events.
we show the results for important microarchitecture events.
During EIR, we employ a number of training examples (m) to
train the model and use one-quarter of m unseen test examples
to evaluate the model accuracy. The error of the models is
defined as follows.
err = |IPCmeas − IPCpred|
IPCmeas
× 100% (14)
where IPCmeas is the measured IPC of a program and
IPCpred is the IPC predicted by the performance model.
Figure 8 show the error variation when we perform the
EIR for HiBench benchmarks. We see that considering more
events may not necessarily result in higher performance model
accuracy. For the experimented processors and benchmarks,
the average error is 14% when we take all 229 events as the
model inputs, while the lowest average error is only 6.3%
when around 150 events are taken as the model input parameters. This indicates that the exhausted list of events of modern
processors may contain a large number of noisy events.
Processor vendors could leverage the proposed approach to
systematically select proper events for their processors.
However, the accuracy of performance models decreases
when we further reduce the number of input events of the
models after they achieve the highest accuracy (e.g., 150
events in this study), as shown in Figure 8. When the number
of events decreases to 99, the average performance model error
increases to 9.6%, but is still very low. When we decrease
the number to 59, the average error further increases to 14%
which is the same as that of models with all 229 events. This
implies that using only 59 events can achieve the same results
of performance analysis by using 229 events. The benchmarks
from CloudSuite show the similar results. We therefore do not
show the figure due to limited space.
Figure 9 and 10 show the importance ranking of events
obtained by MAPM for the benchmarks from HiBench and
from CloudSuite, respectively. The Y axis represents event
importance and the X axis denotes the abbreviations of events
which are shown in Table III. Due to space limit, we show
the 10 most important events for each benchmark.We highlight
four key findings as follows.
First, the importance of one to three events of a benchmark is significantly higher than that of other events of the
same benchmark, and this is true for all benchmarks, —
both HiBench and CloudSuite. For example, the three most
important events of the benchmark wordcount are ISF, BRE,
and ORA. Their importance exceeds 5% while those of the
other events are less than 2.2%. We call this phenomenon
one-three significantly more important law (one-three SMI
law). Note that this is different from Pareto principle because
the accumulated importance of 20% of events is not around
80%. The one-three SMI law indicates that there is always
an opportunity to optimize cloud programs significantly more
efficiently by first tuning the parameters related to the top one
to three events than by tuning other ones. We will demonstrate
this in a case study in Section V-D.
Second, the importance rank of events may vary across
benchmarks. For instance, the most important event for wordcount is ISF while that for pagerank is BRE. This indicates
that different benchmarks have different characteristics at the
microarchitecture level.
Third, the common most important events for all the experimented cloud benchmarks are related to instruction queue,
branch, TLBs (instruction TLB, data TLB, and second level
TLB), memory load, and remote memory or cache access.
The second insight indicates that application-specific tuning is
needed at application level whereas the third one indicates that
common optimization approaches for different applications are
also effective at lower-level, e.g., microarchitecture or compiler. For example, enlarging the length of instruction queue
of processors used in cloud or enhancing the performance of
the memory sub-system of cloud servers may improve the
performance of most cloud services significantly because our
results show that ISF (stall cycles due to instruction queue
is full) is the most important event for most experimented
benchmarks.
Fourth, we surprisingly find that the eight benchmarks from
HiBench show more diversity than those from CloudSuite
based on the 10 most important events for each benchmark.
Only four important events (MUL, MLL, DSP, and DSH)
of CloudSuite benchmarks are not included in those of the
eight HiBench benchmarks while thirteen important events
(ORA, URA, URS, BRC, BAA, LRC, IMC, IM4, CAC, ORO,
IDU, LRA, and OTS) of the HiBench programs are not in
those of the eight CloudSuite benchmarks. The common belief
is that, the benchmarks from CloudSuite should be more
diverse than the ones from HiBench because the CloudSuite
benchmarks use different frameworks such as Hadoop, Spark,
and MemCached while the HiBench benchmarks only use
Apache Spark. Our counter-intuitive results indicate that, to
achieve application diversity, different frameworks may not be
more important than the algorithms and codes of benchmarks.
Moreover, our results indicate that more diverse benchmarks
need to be included in CloudSite3.0.
C. Important Event Interactions
Figure 11 and Figure 12 show the interaction intensity ranks
for the eight Spark benchmarks from HiBench and all the
benchmarks from CloudSuite, respectively. Again, we only
show the 10 most important interactions of event pairs. The Y
axis represents the importance of interaction intensity of event
pairs and the X axis denotes the event pairs.
620
0%
1%
2%
3%
4%
5%
6% 
ISF 
BRE 
ORA 
IPD 
BRB 
BMP 
MSL 
URA 
URS 
ITM 
BRE 
ISF 
BRB 
LMH 
BMP 
ITM 
PI3 
MCO 
BRC 
TFA 
ISF 
BRE 
BRB 
MSL 
BAA 
MMR 
PI3 
BMP 
IPD 
MCO 
BRE 
LRC 
ISF 
BRB 
LMH 
IPD 
BMP 
IMC 
IM4 
ITM 
BRE 
ISF 
LMH 
BRB 
MSL 
PI3 
MMR 
BMP 
MIE 
CAC 
ORO 
IDU 
ISF 
LRA 
BRE 
BRB 
BMP 
LMH 
MSL 
MST 
BRE 
ISF 
PI3 
MSL 
BRB 
IPD 
MST 
TFA 
MMR 
LMH 
ISF 
BRE 
IPD 
BRB 
IMT 
MSL 
PI3 
OTS 
BMP 
MCO 
wordcount pagerank aggregation join scan sort bayes kmeans 
6.1% 6.7% 6.6% 7.6% 
Fig. 9. The importance rank of the eight Spark benchmarks from Hibench when we employ the events which can construct the most accurate performance
models. Y axis represents the importance of events and the X axis denotes the abbreviations of the events.
0%
2%
4%
6%
ISF 
BRB 
BRE 
IPD 
MMR 
MSL 
LMH 
MUL 
MST 
MLL 
ISF 
BRB 
IPD 
BRE 
MSL 
BMP 
MMR 
LMH 
MST 
MLL 
ISF 
PI3 
BRE 
BRB 
IPD 
MMR 
MSL 
LMH 
ITM 
BMP 
ISF 
BRE 
BRB 
MSL 
DSP 
TFA 
MMR 
DSH 
MST 
BMP 
BRE 
ISF 
BRB 
MSL 
IPD 
MMR 
BMP 
PI3 
LMH 
MLL 
BRE 
ISF 
BRB 
MMR 
IPD 
MSL 
LMH 
BMP 
MCO 
PI3 
ISF 
MSL 
IPD 
BRE 
MMR 
BMP 
BRB 
MST 
LHN 
MLL 
MSL 
ISF 
BMP 
MMR 
LHN 
IPD 
ISL 
BRE 
MLL 
LMH 
DataAnalytics DataCaching DataServing GraphAnalytics In-mAnalytics MediaStreaming WebSearch WebServing 
6.4% 
Fig. 10. The importance rank of the eight benchmarks from CloudSuite when we employ the events which can construct the most accurate performance
models. Y axis represents the importance of events and the X axis denotes the abbreviations of the events.
0%
2%
4%
6%
8%
10%
12%
14%
16%
BRB-BMP 
ORA-BRB 
URA-URS 
BRB-ITM 
ORA-BMP 
ISF-BRB 
BRB-URA 
BRE-BRB 
ORA-ITM 
ISF-BRE 
BRB-BMP 
BRE-ISF 
BRE-BRB 
BRE-BMP 
ISF-BRB 
ISF-BMP 
BRB-BRC 
BRE-PI3 
BRE-ITM 
ISF-ITM 
BRE-MSL 
ISF-MSL 
MSL-BMP 
MSL-BAA 
MMR-BMP 
ISF-BRE 
MSL-PI3 
BRB-BMP 
BRB-MSL 
BRE-BRB 
BRB-BMP 
BRE-BRB 
ISF-BMP 
ISF-BRB 
BRE-ISF 
BRE-BMP 
LRC-BRB 
LRC-BMP 
BRE-IPD 
BMP-IMC 
ISF-BMP 
ISF-LMH 
BRE-BMP 
LMH-MMR 
LMH-BMP 
BRE-LMH 
BRE-ISF 
MMR-BMP 
ISF-MMR 
BRE-MMR 
ISF-MST 
LRA-MST 
ORO-MST 
BRE-MST 
IDU-MST 
BMP-LMH 
LRA-BRE 
BMP-MST 
ORO-LRA 
BRE-MSL 
ISF-BRB 
BRE-BRB 
BRE-ISF 
PI3-BRB 
ISF-PI3 
BRE-PI3 
MSL-MST 
MMR-LMH 
BRB-LMH 
BRE-LMH 
BRB-BMP 
ISF-BMP 
ISF-BRB 
ITM-BMP 
BRB-ITM 
BRE-BRB 
BRE-BMP 
PI3-BMP 
MSL-BMP 
BRB-PI3 
wordcount pagerank aggregation join scan sort bayes kmeans 
32% 20% 26% 17% 16% 28% 28% 28% 23% 
Fig. 11. The interaction rank of the important event pairs for the eight Sark benchmarks from HiBench. The Y axis represents the importance of interaction
intensity of event pairs. The X axis represents abbreviations of event pairs. XXX-YYY denotes an event pair.
0% 
10% 
20% 
30% 
ISF-BRB 
ISF-MLL 
BRB-MLL 
MSL-MLL 
BRB-MSL 
MMR-…
BRB-BRE 
MUL-MLL 
ISF-BRE 
BRB-LMH 
BRB-BMP 
BRB-BRE 
ISF-BRB 
BRE-BMP 
ISF-BMP 
BRB-MSL 
ISF-BRE 
MSL-BMP 
BRE-MSL 
BRE-MLL 
BRB-BMP 
BRE-BRB 
ISF-BMP 
ISF_BRB 
BRE-BMP 
PI3-BRB 
PI3-BMP 
ITM-BMP 
ISF-BRE 
BRB-ITM 
BRB-BMP 
BRE-BRB 
BRB-PI3 
ISF-BRB 
BMP-PI3 
BRE-BMP 
ISF-BMP 
BRE-PI3 
ISF-PI3 
BRE-ISF 
DSP-BMP 
BRE-BMP 
ISF-BMP 
BRB-BMP 
BRE-BRB 
DSP-DSH 
MSL-BMP 
ISF-BRB 
BRB-DSP 
BRE-DSP 
BRB-BMP 
BRE-BRB 
BRE-BMP 
BRB-PI3 
ISF-BRB 
BMP-PI3 
BRE-PI3 
BRE-ISF 
ISF-PI3 
ISF-MMR 
BMP-BRB 
BRB-MLL 
BRE-BRB 
BMP-MLL 
BRE-BMP 
BRE-MLL 
MSL-BRB 
MSL-BMP 
ISF-BRB 
MSL-BRE 
BMP-BRB 
ISF-BRB 
ISF-BMP 
ISL-BRB 
BMP-MLL 
BRB-MLL 
ISF-ISL 
BMP-ISL 
BMP-LHN 
MSL-BMP 
DataAnalytics 
36% 
DataCaching DataServing In-mAnalytics GraphAnalytics M-Streaming WebSearch WebServing 
31% 35% 33% 64% 
Fig. 12. The interaction rank of the important event pairs for the benchmarks from CouldSuite. The Y axis represents the importance of interaction intensity
of event pairs. The X axis represents abbreviations of event pairs. XXX-YYY denotes an event pair.
0%
2%
4%
6%
8%
10%
12%
14%
ISF-dmm 
ISF-mmf 
MSL-mmf 
MSL-ics 
ITM-dmm 
ITM-mmf 
BRB-kbm 
BRE-kbm 
ISF-bbs 
IPD-mmf 
TFA-exc 
PI3-exc 
BMP-exc 
BRC-dpl MCO-bbs 
ISF-exm 
ISF-dpl LMH-exm 
BMP-rdm 
ITM-mmf 
BRE-mmf 
BAA-mmf 
PI3-mmf 
BRB-mmf 
MMR-mmf 
MSL-mmf 
IPD-mmf 
MMR-kbf 
BAA-nwt 
PI3-ssb 
ITM-ics 
ITM-sfb 
BRE-rdm 
ISF-kbm 
IPD-dpl BRE-kbm 
IM4-ics 
IM4-kbm 
BRE-dmm 
IPD-mmf 
BRE-dmm 
BRE-mmf 
MMR-mmf 
MMR-ics 
CAC-dmm 
CAC-mmf 
MSL-kbm 
ISF-kbm 
BRE-bbs 
BRB-mmf 
ORO-bbs 
IDU-nwt 
MSL-rdm 
ORO-exm 
ISF-nwt 
ISF-mmf 
ISF-kbm 
MSL-nwt 
LMH-bbs 
MST-kbf 
PI3-ssb 
MST-nwt 
ISF-ssb 
MSL-ssb 
BRE-dpl MSL-dpl IPD-nwt 
ISF-rdm 
MSL-exc 
PI3-bbs 
BRE-exm 
PI3-exc 
MSL-exm 
MSL-kbf 
BMP-kbf 
BMP-dpl MSL-exc 
BMP-dmm 
MCO-dpl PI3-dpl 
wordcount pagerank aggregation join scan sort bayes kmeans 
34% 24% 26% 15% 
Fig. 13. The interaction rank of spark configuration parameter and event pairs. The Y axis represents the importance of the interaction of configuration
parameter and event pairs and the X axis denotes the abbreviations of the parameter and event pairs. In XXX-YYY, XXX represents an event, and YYY
represents a configuration parameter.
First, we see that all benchmarks have one or two dominant
pairs of events which interact with each other more strongly
than other event pairs. This indicates that we can focus on
analyzing the dominant interaction pairs with limited time
budget. Second, the branch related events interact strongly
with other events. In the 160 most important interaction
pairs for the 16 benchmarks (10 most important interaction
pairs for each), one branch related event is involved in 98
interaction pairs. Two branches related events are involved
in 36 interaction pairs. It means that 83.4% of the 160
most important interaction pairs contain branch related events.
These results imply that branch related events are critical
for cloud computing environment. Moreover, the pair BRBBMP (see Table III) appears in 12 of the 16 experimented
621
benchmarks and it is ranked as the most important interaction pair in 10 benchmarks (wordcount, pagerank, join,
kmeans, DataCaching, DataServing, In-memoryAnalytics, MediaStreaming, WebSearch, and WebServing). This indicates the
number of successfully retired branch instructions (BRB) and
that of mispredicted but finally successfully retired branch
instructions (BMP) interact strongly in most benchmarks. This
is because a small BRB surely results in a small BMP and a
large BMP is definitely caused by a large BRB.
Another interesting phenomenon is that the the events in
dominant interaction pairs of benchmarks from CloudSuite
interact much more strongly with each other than those in the
dominant pairs of benchmarks from HiBench, see Figure 11
and Figure 12. This indicates that a benchmark containing
more software tiers results in stronger interactions between
events than a benchmark only implementing algorithms. For
example, WebServing has four tiers: the web server, the
database server, the memcached server, and the clients. The
interaction intensity of its dominant interaction pair achieves
64%. In contrast, GraphAnalytics only implements the pagerank algorithm on a Spark Library GraphX. The interaction
intensity of its dominant interaction pair is only 19%.
Knowing the importance of interaction pairs is important
for performance analysis. First, it can explain why one event
value changes significantly when the other event value is
changed in the same interaction pair. Second, it can explain
why performance variation is larger with the change of two
event values at the same time than that with the change of one
of two event values.
D. Case Study
This case study shows an usage example of CounterMiner.
After we know the important events, we first leverage our interaction intensity quantification approach to determine which
configuration parameters of the Spark framework strongly
interact with the important events. We then tune two configuration parameters, e.g., A and B, which tightly correlate
with a more important and a less important event, respectively.
Finally, we observe the performance variation when we tuning
the two parameters. Note that the default values of Spark
configuration parameters can be found at [51].
Figure 13 shows the importance of interactions between
a Spark configuration parameter and an event. The Spark
configuration parameter names and their abbreviations are
shown in Table IV. For each benchmark, we see that there
exists one or two pairs of a Spark configuration parameter and
an event whose interaction intensities are much stronger than
other pairs. This implies that we should tune the configuration
parameter in the strongest interaction pair first, which more
likely leads to more performance gain. Second, the most
important pair of interaction between a Spark configuration
parameter and an event varies across benchmarks. It is because
of different characteristics between benchmarks and indicates
that different configuration parameters should be tuned first
for different programs for efficiently optimizing performance.
Abbr. Configuration Parameter
bbs spark.broadcast.blockSize.
dpl spark.default.parallelism.
dmm spark.driver.memory.
exc spark.executor.cores.
exm spark.executor.memory.
ics spark.io.compression.snappy.blockSize.
kbf spark.kryoserializer.buffer.
kbm spark.kryoserializer.buffer.max.
mmf spark.memory.fraction.
nwt spark.network.timeout.
rdm spark.reducer.maxSizeInFlight.
sfb spark.shuffle.file.buffer.
ssb spark.shuffle.sort.bypassMergeThreshold.
TABLE IV
THE NAMES AND ABBREVIATIONS OF SPARK CONFIGURATION
PARAMETERS THAT ARE INTERACT WITH THE IMPORTANT EVENTS
STRONGLY.
VRUW
0 
50 
100 
150 
200 
250 
300 
2M 4M 8M 16M 32M 
exec time (s) 
bbs 
0 
40 
80 
120 
160 
200 exec time (s) 
50 
100 
150 
200 
250 
300 
350 
400 
450 
500 
nwt 
Fig. 14. Execution time (in second) optimization for sort by tuning bbs and
nwt. bbs tightly correlates with the most important event (ORO) of sort. nwt
tightly correlates with the less important event I4U. See Table III for bbs and
nwt, Table IV for ORO and I4U.
... ... c1 c2 ci cn
t ... ... t c1 c2 ci cn
... ... c1 c2 ci cn
... ... c1 c2 ci cn
...
v1
v2
vm
A B
Fig. 15. An illustration of profiling times.ci denotes the value of the ith
configuration parameter; t represents the execution time of a benchmark; vm
denotes the mth value of a certain event.
We study an example to demonstrate how to optimize
the performance of Spark programs by using our event importance quantification. As shown in Figure 13, the most
important interaction pair of benchmark sort is ORO-bbs
and Figure 9 shows that ORO is the most important event
of sort. Looking at Table IV, we know bbs corresponds
to spark.broadcast.blockSize. We then choose an event not
in the 10 most important event list and find the Spark
configuration parameter that is tightly correlated with it.
In this example, we choose I4U and the corresponding
configuration parameter is nwt (spark.network.timeout). We
tune spark.broadcast.blockSize and spark.network.timeout separately and compare the performance variation. Figure 14
shows the results. We see that, the execution time reduction is
significantly larger when tuning bbs than tuning nwt. Specifically, average execution time variation is 111.3% when tuning
bbs while that is only 29.4% by tuning nwt. These results
confirm that CounterMiner can indeed provide the “handle”
to users to optimize performance more quickly and efficiently.
Nevertheless, one may think that it is unnecessary to identify
the important parameters of Spark programs by using our
event importance quantification (method A). Instead, one can
quantify the importance of parameters directly by using our
importance ranker (method B). We argue that it is untrue,
because method B takes much longer time than method A.
We use Figure 15 to illustrate the two methods. To quantify
the importance of either configuration parameters or events, we
need to collect a number of training examples. For method B,
622
0%
2%
4%
6%
ISF 
PI3 
BRB 
CRX 
IPD 
MLL 
MUL 
MSL 
BNT 
BRE 
BRE 
L2H 
L2R 
DSP 
L2C 
TFA 
L2A 
L2M 
L2S 
MSL 
DataCaching+DataCaching DataCaching+GraphAnalytics 
10.1% 
Fig. 16. The importance rank of events for co-located workloads: ’DataCaching + DataCaching’ and ’DataCaching + GraphAnalytics’.
we have to run a benchmark k times with k different configurations to collect k training examples because we can collect
the execution time of a program only after it completes its
execution. In contrast, for method A, we can collect m training
examples for an event during one execution of a benchmark
because we sample a number of values for the event during
one run of the benchmark with a certain configuration. Method
A therefore needs a much smaller number of benchmark runs
than method B.
Taking pagerank as an example, we have to run it 6000
times to collect 6000 training examples to build a performance
model with around 90% of accuracy by method B. Then we
identify the important configuration parameters. For method A,
we only run the benchmark 60 times to build a performance
model as a function of events with 90% of accuracy. To find
the tightly coupled configuration parameter and event pairs, we
need to additionally run the benchmark 1520 times. Therefore,
we need to run pagerank 1580 times in total to identify its
important configuration parameters by method A, which is
nearly only 1/4 as the time needed for method B.
E. Co-located Workloads
We now demonstrate how to use CounterMiner with colocated benchmarks running on a shared cluster, which is a
typical scenario in cloud computing environment. We consider
two cases. 1) An application is submitted to the cluster to
run when the same application is running. 2) An application
is submitted to the cluster to run when another application
is running. These are two typical cases people use cloud
platforms. In this study, we use ’DataCaching + DataCaching’
and ’DataCaching + GraphAnalytics’ to demonstrate the first
and second case, respectively.
Figure 16 shows the importance ranking of events for
the two cases. Note that CounterMiner can not show the
importance ranking for individual benchmarks in this context
because hardware counters and events are shared resources
among co-located benchmarks. The left part shows the importance ranking of events for ’DataCaching + DataCaching’.
Compared with Figure 9, we see that the most important event
is still ISF with the similar importance of 3.7%. However,
the importance order and events in the other top 9 important
event list of ’DataCaching + DataCaching’ are only slightly
different from those of ’DataCaching’. This indicates that
two ’DataCaching’ programs do not interfere with each other
severely.
In contrast, we see that the importance order of events and
events of ’DataCaching + GraphAnalytics’ are significantly
different from both of those of ’DataCaching’ and ’GraphAnalytics’. This indicates that ’GraphAnalytics’ churns the
execution of ’DataCaching’ severely. More interestingly, 6 L2
cache related events are ranked in the top 10 important event
list for ’DataCaching + GraphAnalytics’. No L2 cache related
events have been in the 10 most events for both ’DataCaching’
and ’GraphAnalytics’. This indicates that the mixed running
of these two benchmarks cause a lot of L1 cache misses for
both instruction and data caches, which should be avoided.
As observed above, we see that CounterMiner can capture
not only significant churns but also small ones in the context
of co-located workloads running in cloud platforms.
VI. RELATED WORK
A. Counter Data Management and Analysis
Google recently developed a profiling infrastructure, named
Google-Wide Profiling (GWP), to provide performance insights for cloud applications [7]. GWP employs a two-level
sampling technique (sample machines and sample time intervals within a machine for profiling) to collect counter
data in Google data centers. Huck et al. first developed
a framework to manage performance data [28] and then
proposed to leverage statistics techniques such as clustering
to analyze the performance data of parallel machines [52].
Dong et al. proposed to use statistical techniques such as PCA
(Principle Component Analysis) to extract important features
from performance counters [53]. CounterMiner differs from
these studies with twofold: 1) CounterMiner proposes data
cleaning techniques to clean the counter data collected by
MLPX; 2) CounterMiner not only extracts important events
but also directly quantifies the importance of an event with
respect to performance. The related studies that use PCA
or random linear projection can implicitly tell the important
events as a form of principle components or projected metrics
but can not explicitly quantify how important an event is.
This hinders one to directly leverage the important events to
optimize application performance.
B. Error Reduction
The measurement errors caused by MLPX have been observed for nearly two decades [29]–[31], [33], [34], [38],
[54]–[56] and several approaches were proposed to reduce
them. In MLPX, the values of unsampled time intervals of
an event are usually estimated by linear interpolating a value
between the predecessor and successor intervals. Mathur et
al. tried to develop a fine-grained estimation algorithm which
divides the time interval into several sub-intervals. They found
that performing a linear interpolation estimation for each
sub-interval results in better accuracy [38]. Weaver et al.
found that experimental setup significantly affects the accuracy
of measurements by hardware counters and they therefore
provided corresponding suggestions to reduce the errors [31].
Recently, Lim et al. propose a scheduling algorithm that
schedules n events on m counters (n>m) (vs. the traditional round-robin algorithm) to improve the measurement
accuracy [34]. The key idea is to monitor the most recent
three values of an event for determining whether another event
should be scheduled to monitor on a counter. If the values
of an event are not significantly different, another event will
623
be scheduled and vice-versa. Dimakoupoulou et al. found
that the measurement error of MLPX increases when Intel
hyper-thread is enabled. They then proposed a dynamic event
scheduling algorithm based on graph matching to reduce the
errors [33]. These studies try to reduce errors before or during the performance measurement. In contrast, our approach
decreases the errors after the performance measurement has
been completed.
C. Counter Applications
1) Workload Characterization: Recently, Kanev et al.
leveraged hardware counters to profile a warehouse-scale
computer [14] and they found a number of interesting observations. For example, the instruction locality of emerging
cloud computing workloads is getting weaker and therefore
the instruction cache needs to be redesigned. Ferdman et
al. employed hardware counters to characterize a group of
scale-out workloads and released the CloudSuite [9]. Later
on, Yasin et al. performed a deep characterization by using
hardware counters for the CloudSuite [11], [12]. Jia et al.
use performance counters to characterize data analysis workloads in datacenters [8]. Wang et al. characterized big data
workloads for internet services [10]. Xiong et al. employed
performance counters to characterize the big data analysis in
city transportation industry and they proposed a transportation
big data benchmark suite [13].
2) Architecture and Compiler Optimization: Kozyrakis et
al. employ hardware counters and other tools to analyze how
large-scale online services use resources in data centers and
then they provide several insights for server architecture design
in data centers [22]. Chen et al. leveraged hardware-event sampling to generate edge profiles to perform feedback-directed
optimization for application runtime performance [19]. Moseley et al. used hardware counters to optimize compilers and
show speedups between 32.5% and 893% on selected regions
of SPEC CPU 2006 benchmarks [20].
3) Application Optimization: Chen et al. used hardware
counters to observe the cache behavior and then proposed
a task-stealing algorithm for multisocket multicore architectures [5]. Blagodurov et al. developed a user level scheduling
algorithm for NUMA multicore systems under Linux by analyzing information from hardware performance counters [6].
By observing the CPI (Cycle Per Instruction) collected from
hardware counters, Zhang et al. proposed a CPU performance
isolation strategy for shared compute clusters [15]. Tam et al.
firstly carefully analyzed the L2 cache miss rate behavior of
commodity systems and subsequently proposed an algorithm
to approximate the L2 miss rate curves which can be used
for online optimizations [16]. He et al. proposed to leverage
fractals to approximate the L2 miss rate curves with much
lower overhead [17]. Based on hardware counters, Blagodurov
et al. proposed an algorithm to manage the contention of
NUMA multicore systems [18].
Although CounterMiner does not focus on workload characterization and optimization for architectures, compilers, and
applications, it provides an important step stone toward these
goals. After CounterMiner cleans the performance counter
data, these approaches can achieve better results. After CounterMiner quantifies the importance of microarchitecture events,
these approaches can be more efficient.
VII. CONCLUSIONS
This paper proposes CounterMiner, a methodology that
enables the measurement and understanding of the big performance data with three novel techniques: 1) using data cleaning
to improve data quality by replacing outliers and filling in
missing values; 2) iteratively quantifying, ranking and pruning
events based on the importance with respect to performance; 3)
quantifying interaction intensity between two events by residual variance. For various applications, experimental results
show that CounterMiner reduces the average error from 28.3%
to 7.7% when multiplexing 10 events on 4 hardware counters.
The real-world case study shows that identifying important
parameters of Spark programs by event importance is much
faster than directly ranking the importance of parameters.