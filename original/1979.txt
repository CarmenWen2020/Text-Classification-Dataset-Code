ABSTRACT
Quantum computers are susceptible to errors. While quantum computers can be guarded against errors using error correction codes,
near-term quantum computers will not have sufficient number
of qubits to implement error correction and must perform their
computation in the presence of errors. Qubit measurement is typically the most error-prone operation on a quantum computer, with
measurement errors ranging from 8% to 30% reported on current
machines. This goal of this paper is to mitigate measurement errors
by exploiting the state-dependent bias of measurement errors.
Experiments on the IBM-Q5 and IBM-Q14 machines show variation in measurement errors depending on the state being measured.
For example, measuring an all-zero state on IBM-Q5 has a fidelity of
84%; however, the fidelity drops to 62% while measuring the all-one
state. To improve measurement fidelity, we propose Invert-andMeasure, which transforms the system from a vulnerable state to a
stronger state and then performs the measurement in the stronger
state. We propose two designs for Invert-and-Measure. First, Static
Invert-and-Measure (SIM), which executes two instances of the program, one with standard measurements and the other with inverted
measurements and combines the results. Second, Adaptive Invert
and Measure (AIM), which learns the relative bias of different states
using runtime profiling and produces specialized inversions to
increase the likelihood of obtaining the correct answer. Our evaluations, using IBM-Q5 and IBM-Q14, show that SIM improves the
application reliability by up to 2X, and AIM by up to 3X.
CCS CONCEPTS
• Hardware: Quantum technologies;
KEYWORDS
Quantum Compilers, Correlated Errors, NISQ
1 INTRODUCTION
Quantum computers promise to solve hard problems, which are
beyond the capabilities of conventional computers. While quantum computers with several dozens of qubits have already been
demonstrated, machines with millions of qubits (required to obtain
exponential speedup on applications such as Shor’s algorithm) are
still several decades away. One of the biggest challenges in building
a large scale quantum computer is vulnerability to errors. Quantum
computers use qubits to encode and process information. Qubits are
extremely susceptible to noise and cannot hold the state for more
than several tens of microseconds. One of the ways we can tolerate
noise is by using quantum error correction codes. Unfortunately,
quantum error correction requires about 20 to 50 qubits to build one
fault tolerant logical qubit. Therefore in the near future, quantum
computers are likely to be operated in what is called as the Noisy
Intermediate Scale Quantum (NISQ) model of computing [21].
In a NISQ computing model, the application performs computation, then the output is measured, and this output gets logged. This
process is repeated for a large number of trials. If the error-free
output appears with a reasonable probability, then the output-log
can be used to infer the correct answer. Therefore, one of the key
performance metrics for a NISQ machine is the likelihood that the
output produced is error-free. This metric is called Probability of
Successful Trial (PST). Techniques that can help in reducing the
impact of errors on a NISQ machine leads to improvement in PST.
A program running on a NISQ machine can encounter an error
due to decoherence, qubit operation, or due to measurement at the
end of the computation. Measurement is typically the most errorprone operation on the current quantum computers. For example,
on the IBM machine, the average error rate for measurement is
6%-8% with the worst-case measurement error rate of 30%. Measuring a qubit is fundamentally challenging as qubits are extremely
low energy devices and during a process of measurement, qubit
devices are exposed to noisy measurement circuitry. Thus, even
if a quantum machine performs all the computation without encountering an error, in the end, the measurement can still result
in an erroneous output. The goal of this paper is to improve the
reliability of NISQ computers by mitigating measurement errors.
Measurement collapse the qubit in a state of superposition into a
classical binary state, 0 or 1. Thus, a measurement error manifests
itself as either a "1" being read as a "0" or vice versa. In this paper,
we observe that measurement errors do not affect all states equally.
For example, on IBM machines, measurement errors have statedependent bias such that the state "1" is erroneously read "0" (1 → 0)
more frequently as compared to state "0" measured as the state
"1" (0 → 1). While measuring a collective state of N qubits, we
would expect to encounter more errors for states that have a large
279
MICRO-52, October 12–16, 2019, Columbus, OH, USA Tannu and Qureshi
PST of measuring “00000” 0.84
(a) (b) (c)
PST of measuring “11111” 0.62 PST of inv & meas“11111” 0.78
Figure 1: On five qubit ibmqx4, probability of successfully measuring a state (a) All-zero state "00000" (b) All-ones state "11111"
(c) Measuring the All-ones state by first inverting the state and then performing the measurement (expected output "00000").
number of ones. We can exploit this bias to mitigate the impact of
measurement errors and improve the application reliability.
To show the state-dependent bias in measurement errors we
conduct a simple experiment. We initialize the IBM-Q5 (five qubit)
machine into an all-zero state (00000) and measured the state. This
experiment was repeated for one thousand trials. The experiment
is deemed to give the right output if we obtain the 00000 state and
incorrect if it gave any of the other 31 possible values. Figure 1(a)
shows the probability of obtaining the correct answer and the
probability of obtaining a few of the dominant incorrect states. We
note that the probability of successful measurement for the all-zero
state is 84%. Conversely, if we initialized the machine in an all-ones
(11111) state, then the probability of successful measurement drops
to 62%, as shown in Figure 1(b). Thus, reading a state of "1" is usually
more error-prone than reading a "0" state.
We also conducted an exhaustive experiment with all 32 states
("00000" to "11111") and observed that the probability of successful
measurement shows a strong inverse correlation with the Hamming
Weight (number of ones) of the state being measured. So, states with
higher number of ones are more susceptible to measurement errors
than the states with fewer ones. Furthermore, this state-dependent
bias is observed even for qubits in the state of superposition. For
example, a GHZ state is an equal superposition of all-one and all
zero state, when measured it is expected to produce the all-zero
state and the all-one state with 50% probability each. We observe
that on IBM-Q5, the all-zero state was four times as likely as the
all-ones state. We note that our experiments with all three publicly
available IBM machines (two 5-qubit machines and one 14-qubit
machine) showed such state-dependent bias in measurement errors.
The key insight in this paper is to exploit the state dependent
bias to reduce the impact of measurement errors. For example, if we
are likely to read a vulnerable state (high Hamming Weight), then
we can transform it into a stronger state (low Hamming Weight) by
inverting qubits before the measurement, performing the measurement, and inverting the measured result. We refer to such a method
of conditionally converting the state to obtain lower measurement
errors as Invert-And-Measure. For example, reconsider the example
of Figure 1(b) where we read the all-one state. Instead, if we inverted
the state (by using an additional "X" gate at each of the qubits) before the measurement and then we perform the measurement, then
the probability of successful measurement increases from 62% to
78%, as shown in Figure 1(c). Note that the measurement produces
a complementary state (all-zeros on correct output) and we must
invert this output to get the desired results.
Unfortunately, prior to measurement, we do not know the Hamming Weight of the output (and hence we do not know if the system
is in a weak or strong state). Always using inversion before measurement can degrade reliability if the system was already in the strong
state. We design two practical policies for Invert-and-Measure.
Our first policy is Static Invert-and-Measure (SIM), which splits
the trials into two (or more) groups, each using a different measurement mode: standard and inverted. In the standard-mode, input program is executed and qubits are read without any change. Whereas
in the inverted mode, the input program is executed, the qubits are
inverted and measurement is performed (the measured output is
inverted to maintain correctness). We merge outputs performed
in standard-mode and the inverted-mode to obtain the aggregated
output. Therefore, SIM ensures that only a subset of the trials are
affected by measurement in the vulnerable state. Our measurements
on IBM-Q14 (ibmq-melbourne) and IBM-Q5 (ibmqx2 and ibmqx4)
machines show that SIM can increase by PST by up to 2X.
While we observe a strong correlation of Hamming Weight of
state and the vulnerability of the state to the measurement errors,
this correlation is not always perfect, especially for the ibmqx4
machine. If we knew the strongest state for the given machine,
then we can steer the output of the machine to map to that state
instead of steering it towards an all-zero state. Our second policy,
Adaptive Invert-and-Measure (AIM) is based on this insight. AIM
learns the relative strength of basis state using runtime profiling
and performs targeted inversions such that probable solutions get
mapped to strong states when inversion is applied. Our evaluations
on IBMQ machines show that AIM provides significantly higher
improvement compared to SIM. AIM improves PST by up to 3X.
Overall, this paper makes the following contributions:
(1) We show that measurement errors have significant bias depending on the state being measured, with some states significantly more error-prone than other states.
(2) We propose to exploit the bias in measurement errors by
performing an inversion before measurement if the state
being measured is likely an error-prone state.
(3) We propose Static Invert-and-Measure (SIM) that obviates the
need for a-priori knowledge of the state being measured by
splitting the trials into standard-mode and inverted-mode
measurement and merging the results.
(4) We propose Adaptive Invert-and-Measure (AIM) that tailors
the inversion profile to suit the machine characteristics and
maps the likely solutions to be read in the strong state that
is specific to the machine.
280
Mitigating Measurement Errors in Quantum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
2 BACKGROUND
2.1 Primer on Qubits and Quantum Gates
Quantum computers owe their powers to two properties: superposition and entanglement. A state of a qubit (|ψ⟩) is a vector in a Hilbert
space that is represented as a linear superposition of two basis states
|0⟩ and |1⟩ as shown in Figure 2(a). Whereas, combined state of two
qubits can be represented as a0 ∗ |00⟩+a1 ∗ |01⟩+a2 ∗ |10⟩+a3 ∗ |11⟩
such that a
2
0
+ a
2
1
+ a
2
2
+ a
2
3
= 1. Qubit Measurement is used to
measure/read the state of the qubit. When qubit is measured, it
produces binary output (1 or 0) with probability depending on the
state of the qubit. As shown in Figure 2(b), when a qubit with a
state: |ψ⟩ is measured, it produces "|0⟩" with probability of |α |
2
and
"|1⟩" with probability of |β |
2
. Whereas, the measurement of n-qubit
state outputs 2
n basis states ( 000..0n to 111..1n) with probabilities
corresponding to the superposition of the n-qubit state.
= α 0 + β 1
X
(Invert qubit) Ψ'
(a) (b)
Probability 
Measure
Measure
0 1
β
2
α
2
0 1
β
2
α
2
Probability 
0 1
α
2
β
2
0 1
α
2
β
2
(c) (d)
Ψ’
= β 0 + α 1
Ψ
Ψ Ψ'
Ψ
+ β
2 α
2 + β = 1 2 α
2 = 1
Figure 2: (a) Quantum state is a superposition of |0⟩ and |1⟩
(b) Measurement of a qubit is probabilistic (c) X-gate inverts
the qubit state (d) Measurement of inverted qubit
A state of the qubit can be manipulated using a quantum gate.
For example, the "X" gate change the superposition by altering the
probability amplitudes α and β. In fact, as shown in Figure 2 (c), by
applying X-gate on a qubit with state |ψ⟩, we can invert the state
of qubit to produce a flipped state |ψ
′
⟩. When |ψ
′
⟩ is measured it
produces "|0⟩" with probability of |β |
2
and "|1⟩" with probability of
|α |
2
as shown in the Figure 2 (d).
2.2 Error Modes on Quantum Computers
Qubits are unreliable as they can lose their state within a few hundreds of microseconds or encounter operational errors. The error
rate for a qubit can be defined as a probability of undesired change
in the qubit state. Errors on quantum computers can be classified
as - Coherence-errors, Gate-errors, and Measurement-errors.
Coherence-Errors: A qubit can retain data for only a limited time
and this duration is called Coherence Time. A qubit in a high-energy
state (state |1⟩) naturally decays to the low-energy state (state |0⟩),
and the time constant associated with this exponential decay is
called as the T1 Coherence Time. It dictates the error rate such
that probability of qubit error scales as e
−t /T 1
. For existing IBM
quantum computers, the average T1 time is about 60µS.
Gate-Errors: Quantum operations are imperfect, and performing
gate operations on qubits can also affect their state incorrectly. For
IBM quantum-computers, single qubit gates have an error rate in
the range of 0.1%-0.3%, whereas the two-qubit gates have an error
rate in the range of 2%-5%.
Measurement-Errors: Measurement is the most error-prone operation in current quantum computers. Table 1 shows the minimum,
average, and maximum error-rates for the measurement operation
(readout operation in IBM terminology) for the three IBM machines
that we use in our evaluations. We note that the average error rate
for measurement operation in the range of 4%-8% and as high as
31%. The high rate of measurement errors can degrade the application level reliability, especially for low depth programs. Although
highly probable, measurement errors are easy to correct as they
manifest as bit-flip errors, and in this paper, we leverage this insight
to mitigate measurement errors.
Table 1: Error Rate of Measurement Operation
Machine Error Rate
Name Min Average Max
ibmqx2 (IBM-Q5) 1.20% 3.8% 12.8%
ibmqx4 (IBM-Q5) 3.4% 8.2% 20.7%
ibmq-melbourne (IBM-Q14) 2.2% 8.12% 31%
2.3 NISQ Model of Quantum Computation
Qubits can be protected against errors by using quantum error
correction (QEC) protocols. QEC use extra qubits to introduce redundancy in the information encoding. However, QEC requires
a large number of physical qubits (20x-50x) to enable one faulttolerant logical qubit. Near-term quantum computers (with few
tens/hundreds of qubits), may not able to leverage error correction
even for an application requiring few dozens of logical qubits. However, there exists a class of applications highlighted by Preskill [21]
that can still be viable with such Noisy and Intermediate-Scale Quantum (NISQ) machines. Figure 3(a) describes the general computing
model for the NISQ machines. In this model, the given program is
run, the output qubits are read/measured, and the result is logged.
This process is repeated for thousands of trials. As long as the correct results appear with high probability, we can infer the correct
result by analyzing the log.
(a)
0.25
00 01 10 11
Probability 
0.5
0.15
0.1
00 01 10 11
Probability 
0.5
0.15
0.1
0.25
00 01 10 11
Probability 
0.5
0.15
0.1
(b) (c)
1
Ideal Quantum Computer 
00 01 10 11
Probability 
0
Output of BV 2-bit key
0
Probability 
0
Output of BV 2-bit key
0
00 01 10 11
Probability 
0
Output of BV 2-bit key
0
00 01 10 11
Probability 
0
Output of BV 2-bit key
0 0
Output of BV 2-bit key
Error Free Output Erroneous Output
On NISQ Computer 
Execute
Program 
Read 
Qubits
Log
Output 
Initialize
Qubits 
Execute
Program 
Read 
Qubits
Log
Output 
Initialize
Qubits 
0.3
00 01 10 11
Probability 
0.20
0.35
0.15
On NISQ with biased errors 
(d)
Output of BV 2-bit key
0.3
00 01 10 11
Probability 
0.20
0.35
0.15
On NISQ with biased errors 
(d)
Output of BV 2-bit key
Repeat N times
Figure 3: (a) NISQ Model of computation (b) Output of
Bernstein-Vazirani (BV) with 2-bit key on an ideal quantum
computer (c) Successful execution on NISQ machine (d) Unsuccessful Execution on NISQ machine.
281
MICRO-52, October 12–16, 2019, Columbus, OH, USA Tannu and Qureshi
2.4 Impact of Errors on NISQ Applications
Errors can cause the NISQ machine to produce an incorrect output.
Figure 3(b) shows the distribution of output for a Bernstein-Vazirani
(BV) kernel storing 2-bit key "01". On an ideal, error-free machine,
we would get the secret key with 100% probability. Whereas on a
real quantum computer, qubit errors can produce incorrect output,
and we observe distribution of all possible outputs. For example,
in Figure 3(c) show a case where the correct output occurs with
50% probability, and each of the incorrect output is generated with
no more than 25% probability. Thus, we can correctly infer the
key, even in the presence of errors. Now, suppose we stored a
different key ("11"), as shown in Figure 3(d). The correct output
occurs with 30% probability, but one of the incorrect outputs occurs
with 35% probability. In such cases, we can not infer the correct key
by picking most frequently occurring output. This can especially
happen if certain states are more vulnerable to measurement errors,
causing a bias in output.
2.5 Goal of Our Paper
The goal of our paper is to improve the reliability of quantum
computers by mitigating errors due to measurement operations.
We note that measurement errors are simply binary errors where
a "1" is inferred instead of a "0" and vice versa. We observe that
measurement errors do not affect all the states equally and states
storing a "1" are typically more prone to measurement errors –
perhaps because the measurement is a long latency operation and
the coherence error can take the qubit from a high energy state
to a low energy state. We use this bias in measurement errors to
perform error mitigation. We provide experimental methodology
next and then perform a characterization of measurement errors.
3 BIAS IN MEASUREMENT ERRORS
This section provides characterization data for measurement errors
that highlight the state dependent bias in measurement errors and
it’s correlation with the Hamming Weight (the number of 1s).
3.1 State Dependent Bias
Qubits have a natural tendency to relax to the low energy state (0)
from the high energy state (1). This creates a data dependent bias
in measurements as qubit which already in State 0 is less likely to
change its state due to natural relaxation process as compared to
the qubit in State 1. For example, our evaluations on IBM quantum
computers show that a qubit in an excited state is more likely to
encounter an error as compared to the qubit in a low energy state.
To understand the state-dependent bias in measurement errors, we
generate all the 32 possible basis states (00000 to 11111) and measure
each state 16 thousand times. We compute the Basis Measurement
Strength (BMS) as the ratio of number of correct measurement to
the total number of trials for all 32 basis states. Figure 4 show the
relative BMS for all 32 states on IBM’s five qubitibmqx2 machine.
Note that the x-axis is in the ascending order of Hamming Weight.
We calculate relative BMS by dividing the BMS of each state with
the highest BMS. For ibmqx2, state "00000" is the strongest basis
state, whereas state "11111" is the weakest state with relative BMS
of 0.38 as the BMS reduce with increasing Hamming Weight. 00000 00001 00010 00100 01000
10000
00011
00101
00110
01001
01010
01100
10001
10010
10100
11000
00111
01011
01101
01110
10011
10101
10110
11001
11010
11100
01111
10111
11011
11101
11110
11111
5-bit Basis States
0.0
0.2
0.4
0.6
0.8
1.0
Relative 
Measurement Strength
direct measurement
equal superpostion
Figure 4: Probability of Successful Measurement for ibmqx2
basis states using equal superposition and direct basis measurement. (X-axis shows five bit basis states in ascending order of hamming weights)
With unbiased measurements, BMS for all the states should be
similar. However, our evaluations suggest that the probability of
successful measurement is inversely proportional to the Hamming
weight of basis states (Correlation coefficient = -0.93). Thus, the
larger the Hamming weight, the higher the probability of measurement error. To understand the impact of the size of the quantum
computer on measurement bias, we run similar experiments with
10-bit basis states on ibmq-melbourne for total 150 thousand trials.
Figure 5 show the relative BMS for all 1024 basis categorized as per
the Hamming Weight of the basis state. The data again shows a
strong inverse correlation between the measurement strength and
the Hamming Weight.
0 2 4 6 8 10
Hamming Weight of 10-bit basis states
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Average Relative
Measurement Strength
Figure 5: Relative Basis Measurement Strength for the
ibmq-melbourne machine. The data is averaged over all the
basis states with the identical Hamming Weight.
3.2 Impact of Bias on Superposition of States
Thus far, we have measured the vulnerability of measurement errors to states that do not have any superposition (classical states).
However, bias in measurement error can impact qubit states with
superposition. To understand how measurement bias affects the
superposition of states, we create the Greenberger-Horne-Zeilinger
(GHZ) state, which is an equal superposition of basis-states "00000"
and "11111" (GHZ-5 = 1√
2
(|00000⟩ + |11111⟩)).
If the GHZ-5 state is prepared and measured on a quantum computer with no errors, the output will be either "00000" or "11111"
with 0.5 probability respectively. However, when prepared and
measured on the IBM machine, the probability of measuring state
"00000" and state "11111" are unequal. As shown in the Figure 6,probability of measuring state "00000" reduces from from 0.5 to 0.4 and
from 0.5 to 0.1 for sate "11111". Our experiments suggest that measurement bias extends to the superposition of basis states. Note
that GHZ states are considered to be the maximally entangled state;
thus measurement bias also affects qubits that are entangled.
282
Mitigating Measurement Errors in Quantum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA 00000 00001 00010 00100 01000 10000 00011 00101 00110 01001 01010 01100 10001 10010 10100
11000
00111
01011
01101
01110
10011
10101
10110
11001
11010
11100
01111
10111
11011
11101
11110
11111
5-bit Basis States
0.0
0.1
0.2
0.3
0.4
0.5
0.6
Probability of
 Occurance
 Hamming 
Weight = 5 Hamming 
Weight = 0 
GHZ-5 on ibmq_melbourne (NISQ)
GHZ-5 on Ideal Quantum Computer
Figure 6: Output probability distribution for GHZ5 (X-axis is in ascending order of the Hamming Weight). On ideal machine
both "00000" and "11111" occur with 0.5 probability – errors affect state 11111 four times as state 00000.
Similar to GHZ, bias affects other superposition states as well.
For example, if we prepare superposition of all states for five qubits
using Hadamard (H) gates, and measure the output probability
distribution, it strongly correlate with the with the relative measurement strength as shown in the Figure 4.
3.3 Impact of Bias on NISQ Applications
State-dependent bias in the measurement errors produces nonuniformity in the measurement strength of basis states. The skew
in measurement strength degrades the reliability of NISQ machines.
For example, if the desired or optimal answer is a weak basis state,
then the probability of measuring the answer drops significantly.
Furthermore, weak states are often incorrectly measured as strong
states. To understand this masking effect, we execute an instance
of QAOA on the ibmq-melbourne machine. We use QAOA to solve
the max-cut problem for five input graphs (Graph-A to Graph-E)
such that each graph consists of six nodes and the desired output
(the partition that maximizes the cost function) is in the increasing
order of Hamming Weight, as shown in the Table 2. We execute
each graph for 32 thousand trials. All five graphs use an identical
number of gates and the optimal mapping (aware of variation in
error rates of different qubits).
Table 2: Impact of measurement bias on QAOA
Input Optimal Hamming Metric
Graph Output Weight PST IST ROCA
Graph-A 010000 1 6.5% 1.3 1
Graph-B 010100 2 5.5% 1.01 1
Graph-C 101001 3 5.0% 0.70 7
Graph-D 101011 4 1.9% 0.59 14
Graph-E 110110 4 1.5% 0.23 24
Table 2 shows the Probability of Successful Trials (PST), Inference
Strength (IST) that ratio of frequency of correct answer to the
frequency of most dominant incorrect answer and the rank of the
correct answer for the five graphs. We observe that PST is inversely
correlated to the Hamming Weight. As for input graphs A and
B, the PST is 2x higher as compared input graph D and E. Thus,
state-dependent measurement bias can significantly deteriorate the
reliability of the application.
The bias in measurement has a significant impact on the IST
and Rank of correct answer as well. IST drops significantly for the
input graphs E and F. When the expected output is a weak state
(Hamming Weight= 3 or 4) this indicate that incorrect answers have
a higher frequency of occurrence compared to the correct answer.
Along with IST, we use the Rank of Correct Answer (ROCA) to
understand how measurement bias impacts the ability to infer the
error-free answer. For A and B the correct answer appears with the
highest frequency, whereas, for D and E (high Hamming Weight) the
incorrect answers are more dominant than the correct answer. Our
goal is to reduce the impact of measurement errors, and make the
system fidelity be less dependent on which state is being measured.
We describe our methodology before discussing our solution.
4 METHODOLOGY
4.1 NISQ Benchmarks
Developing applications for near-term quantum computers is an
open problem [16, 21]. Quantum Approximate Optimization Algorithm (QAOA) [6] has emerged as an appealing use for NISQ
machines as it can be used to solve challenging optimization problems. We use QAOA as one of the kernels for our evaluation. The
other kernel we use is Bernstein-Vazirani (BV)[1] which deduces
a secret key hidden inside a quantum oracle. Note that both bv
and qaoa produce a binary string as the solution. For example, the
output of QAOA when solving a max-cut problem represents a
partition that maximizes the cost function. Whereas, BV produces a
secret key hidden in the quantum oracle and outputs a binary string
corresponding to the secret key. On an ideal quantum computer
(with no errors), these applications will produce correct output with
certainty. For BV, the correct string is generated with probability of
one, whereas for QAOA, the correct output string has the highest
frequency of occurrence. Note that QAOA solves an optimization
problem – solutions produced with QAOA can be used to calculate
the cost function, and the answer corresponding to optimal value
among all the tested solution can be used as the good enough solution. Table 3 shows the configurations of BV and QAOA used in
our study. For both QAOA and BV the number of gate operations
and measurement operations scale linearly with problem size.
Table 3: Benchmark Characteristics
Benchmark Problem/Algorithm Output
bv-4A 4 bit Bernstein-Vazirani Secret: 0111
bv-4B 4 bit Bernstein-Vazirani Secret: 1111
bv-6 6-bit Bernstein-Vazirani Secret: 011111
bv-7 7-bit Bernstein-Vazirani Secret: 0111111
qaoa-4A max-cut for 4 node graph Output cut: 0101
qaoa-4B max-cut for 4 node graph (p=2) Output cut: 0111
qaoa-6 max-cut for 6 node graph (p=2) Output cut: 101011
qaoa-7 max-cut for 7 node graph (p=2) Output cut: 1010110
283
MICRO-52, October 12–16, 2019, Columbus, OH, USA Tannu and Qureshi
4.2 Reliability Metrics
Our goal is to improve the reliability of NISQ machines. While
PST has been commonly used as the metric to denote the system
level reliability, we discuss two additional metrics that can provide
further insight into assessing the reliability of NISQ machines,
depending on the application.
4.2.1 Probability of Successful trial (PST):. PST has been used
to evaluate the reliability of NISQ applications [14]. To calculate
PST, a NISQ program is run multiple times, and the output of each
trial is logged. PST is evaluated by computing the ratio of a number
of error-free trials to the total number of trials. PST can be evaluated
for a class of problems that have known correct solution. However,
for benchmarks such as QAOA, we can have two possible correct
answers: a binary string that denotes the most optimal partition
and it’s inversion. In such case, for all our evaluations, we use
cumulative frequency of occurrence for both of the strings. Note
that by only knowing the PST, we do not know if the execution
will lead to a successful outcome or not.
PST =
Number of Trials with Correct Solution
Total Number of Trials
4.2.2 Inference Strength (IST):. When running a NISQ application, we need to consider the frequency of error-free outcomes
along with the erroneous outcome, as incorrect outputs can mask
the error-free outputs. Thus, suppressing erroneous trials is essential to determine the error-free answer from the erroneous ones.
To quantify this, we propose Inference Strength (IST), which is the
ratio of the frequency of error-free output to the number of most
frequently occurring erroneous output. IST can easily capture the
cases where the incorrect answer can dominate the correct answer.
For example, the correct answer appears with the highest frequency
in the output log only if IST exceeds 1.
IST =
Probability of Correct Solution
Probability of Strongest Incorrect Solution
4.2.3 Rank of Correct Answer (ROCA):. For discrete optimization problems, such as QAOA, we get a solution from the NISQ
machine, and we would compute the cost associated with the solution. However, instead of only testing the most frequently occurring
solution on the NISQ machine, we could also test "top K" answers
for possible solution. To compute the rank of the correct solution,
we sort the output log in descending order using frequency of occurrence and use the Rank of Correct Answer (ROCA) as a metric
to capture the effectiveness of the NISQ machine.
4.3 Machine Configuration and Parameters
For our evaluations, we use the publicly available quantum cloud
service from IBM [3]. We conduct our experiments on three quantum machines, as shown in the Table 4. We use multiple machines
to understand the machine specific and general measurement bias.
We evaluate all the benchmarks using the most optimal qubit allocation for both the baseline experiments and for proposed bias
mitigation techniques. We use allocations that are cognizant of
underlying noise and variation in the error rate such that benchmarks are mapped on strongest qubits and links with minimum
number of SWAPs. When running the benchmarks, we ensure that
the identical program (number of gates, and position of qubits)
are performed for the baseline and proposed policy. Moreover, we
run each benchmark for more than 32,000 trials and ensure that
the baseline and the proposed policy are evaluated in the same
calibration window such that the evaluations for the baseline and
proposed policy are executed in intertwined batches.
Table 4: Quantum Machines
Platform ibmqx2 ibmqx4 ibmq-melbourne
Number of Qubits 5 5 14
5 EXPLOITING BIAS USING INVERSION
Our characterization data shows that there is a significant bias in
the measurement errors, and these errors tend to show a strong
correlation with the Hamming Weight of the output being measured.
We could exploit this bias to reduce the impact of measurement
errors on the NISQ machines.
5.1 Invert-and-Measure: The Basic Concept
If we could guess the state being measured, and if it was a state that
is highly vulnerable to measurement errors, then we could instead
perform the measurement in an inverted mode. In the inverted
mode, the qubits would first be inverted (using the X gate), and
then the measurement is performed. The measurement would give
an output complementary to what is expected; however, we can
perform inversion on the measured output to get the desired state.
We exploit this insight in our proposal, Invert-and-Measure. For
example, if we were reading an all-ones state (highly error-prone)
then inverting the state will allow us to perform our measurement
in the all-zeros state (less error-prone).
Performing all the measurement in an inverted form is not always
beneficial. In fact, it can lead to more errors. For example, if we
were reading a strong state and we inverted and measured, then
we would increase the error rate of the system. Therefore, inverted
measurement makes sense if we know the state we are reading.
Applying an inverted measurement thus faces a practical challenge
as we do not know the state we are measuring before performing
the measurement. We propose Static Invert-and-Measure that avoids
the reliance on knowing which state is being measured.
5.2 Static Invert-and-Measure
Rather than performing all of the trials in the same measurement
mode, our Static Invert-and-Measure (SIM) policy divides the trials into multiple groups and performs a different measurement
mode on each group. The simplest form of SIM is to have two
measurement modes: standard and inverted, and use each measurement mode for half the trials, as shown in Figure 7(a). Note
that for measurements performed in the inverted mode, we flip
the measured results to get the expected output. The distribution
obtained from both modes of measurement is then combined to
obtain an aggregate distribution over all the trials. As SIM divides
284
Mitigating Measurement Errors in Quantum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
(a)
Initialize Execute Invert Invert
Measurements
Log 
Output
i <N/2
While (i < N) i++
yes
no
Measure
Initialize Execute Invert Measure Invert
Measurements
Log 
Output
i <N/2
While (i < N) i++
yes
no
Measure
Measure
H
H
X H
0
0
0
H
H
X H
0
0
0
H
H
H
H
H
X H
0
0
0
H
H
H
H
H
X H
0
0
0
H
H
X H
0
0
0
H
H
H
X
X
H
H
X H
0
0
0
H
H
H
X
X
(d)
Program Program
Output
001
101
100
000
Pr
0.45
0.35
0.15
0.05
Output
001
101
100
000
Pr
0.45
0.35
0.15
0.05
Output
010
000
011
110
Pr
0.75
0.15
0.05
0.05
Output
010
000
011
110
Pr
0.75
0.15
0.05
0.05
Input Graph
Output
101
111
100
001
Pr
0.75
0.15
0.05
0.05
Output
101
111
100
001
Pr
0.75
0.15
0.05
0.05
A
B C
D
Output
101
001
100
000
111
Pr
0.55
0.25
0.10
0.025
0.075
Output
101
001
100
000
111
Pr
0.55
0.25
0.10
0.025
0.075
(b)
(c)
Invert
Measure 
Qubits
QAOA
QAOA Measure 
Qubits
Merge & 
Normalize 
Figure 7: Static Invert-and-Measure (SIM): Split trials into standard-mode and inverted-mode, and merge results
the measurements into groups, the system may perform only half
of the measurements in the vulnerable state and the other half in
the stronger state so that the errors can get averaged out.
We explain the operation and effectiveness of SIM with an example, as shown in Figure 7(b). Consider a QAOA application that
produces a 3-bit output. The expected output of QAOA on an ideal
quantum computer is "101". If we run the application on a NISQ
machine, we can get different output in different trials. The PST is
0.35, and the incorrect answer "001" (with lower Hamming Weight)
is measured more frequently as compared to the correct answer
A . Whereas, for the inverted measurements, our expected measurement would be "010" (with high probability) B . We flip the
measurements obtained in an inverted mode to obtain the desired
probability distribution for the inverted mode C . Combining the distributions from the standard mode and inverted mode produces the
correct answer with the highest probability (PST=0.55), as shown in
D . Thus, SIM limits the vulnerability of measurement errors to bias
towards only one group and averaging the results from different
measurement mode improve the overall reliability of the system.
0000
XOR
0101
XOR
1111
XOR
1010
XOR
0101 (0.4)
0000
XOR
0101
XOR
1111
XOR
1010
XOR
0101 (0.4)
0000
(0.9)
0101
(0.4)
1010
(0.45)
1111
(0.3)
Measure
0000
XOR
0101
XOR
1111
XOR
1010
XOR
0101 (0.4)
0000
(0.9)
0101
(0.4)
1010
(0.45)
1111
(0.3)
Measure
0.51
X
X
0 1 0 1 
Measure
Figure 8: SIM with four inversion-Strings: all-zeros, all-ones,
even-bits-1, and odd-bits-1. Averaging over four modes increases the likelihood of getting a stronger state
5.3 Generalizing SIM to Multiple Modes
The basic insight in SIM is to transform a state being measured into
another state which might be less vulnerable to measurement errors.
This is achieved by inverting the measurement for some of the trials.
We can generalize this concept of measuring in a different basis as
having an Inversion-String that is applied to the set of qubits being
measured before doing the measurement. In standard mode, the
Inversion-String is all zeros, so no inversion is applied, and the state
is read as is. In the inverted mode, the Inversion-String is all ones,
so all the qubits are inverted before performing the measurement.
For an N-qubit machine, there are 2
N possible Inversion-Strings. In
fact, if we divide all the trials into 2
N groups, and applied a unique
Inversion-String to each of the group, then we would get an average
value of measurement error, regardless of the state being measured.
Applying all possible Inversion-Strings may not be a viable option, especially for a machine with dozens of qubits, given that the
number of Inversion-Strings grows exponentially with the number
of qubits. However, even if we choose a handful of Inversion-String,
we can still average out the measurement errors on those measurement modes. For example, the SIM policy described earlier
had two Inversion-Strings (all-zeros and all-ones) and is optimized
for cases where the state being measured is either very low Hamming Weight or very high Hamming Weight. We could add additional measurement modes which are designed for states that
may have moderate Hamming Weight. For example, we could add
an Inversion-String that has an alternating string of 1s and 0s. So,
our policy may have four Inversion-Strings altogether: all-ones,
all-zeros, even-bits-one, and odd-bits-one. Such a design with four
Inversion-Strings is shown in Figure 8. In this example, we are
measuring state "0101" which has BMS of 0.4, whereas the inverted
state "1010" can be measured with 0.45 probability. Thus, in this
case, SIM with only two modes (standard and inverted) may not
be effective in mitigating measurement bias. Whereas, if we use
four inversion strings ("0000", "1111", "0101", "1010") as shown in
the Figure 8, then the resultant measurement has higher reliability.
We find that such an implementation of SIM with four InversionStrings is effective at providing measurement errors close to average, without requiring us to know the state that is being measured
and without knowing the machine characteristics (which states
are vulnerable and which are not vulnerable). For our experiments
with SIM, we split the trials into four equal groups. We use the
four Inversion-Strings: no inversion (00000..0n ), full inversion
(11111..1n), even qubit inversion (10101..1n ), and odd qubit inversion (01010..0n). Using these inversion strings, we generate four
copies of a program and run each copy for an equal number of trials.
For partial and fully inverted copies we perform post-measurement
flips and combine all the outputs. We use inversion strings that
split the Hamming space into four equal parts. By adding more
inversion strings and execution modes, we can achieve incremental
benefits in IST at the cost of running extra trials.
5.4 Impact of SIM on Reliability of QAOA
To understand the effectiveness of SIM, we use QAOA to find the
max-cut for the input graph-D (output string: 101011). We run the
application on IBM-Q14 for 16 thousand trials in the baseline configuration. The output of QAOA with the baseline policy is shown
285
MICRO-52, October 12–16, 2019, Columbus, OH, USA Tannu and Qureshi 000000 000001 000010 000100 001000 010000 100000 000011 000101 000110
001001
001010
001100
010001
010010
010100
011000
100001
100010
100100
101000
110000
000111
001011
001101
001110
010011
010101
010110
011001
011010
011100
100011
100101
100110
101001
101010
101100
110001
110010
110100
111000
001111
010111
011011
011101
011110
100111
101011
101101
101110
110011
110101
110110
111001
111010
111100
011111
101111
110111
111011
111101
111110
111111
6-bit Basis States on IBM's Quantum Computer
0.005
0.010
0.015
0.020
0.025
0.030
Probability 
of Measurment
 Low Hamming Weight
 False Positive Outcomes 
 Correct 
Output Rank = 14 
Correct Output (a) 000000 000001 000010 000100 001000 010000 100000 000011 000101 000110 001001 001010 001100 010001 010010 010100 011000 100001 100010 100100 101000 110000 000111 001011 001101 001110 010011 010101 010110 011001 011010 011100 100011 100101 100110 101001 101010 101100 110001 110010 110100 111000 001111 010111 011011 011101 011110 100111 101011 101101 101110 110011 110101
110110
111001
111010
111100
011111
101111
110111
111011
111101
111110
111111
6-bit Basis States on IBM's Quantum Computer
0.005
0.010
0.015
0.020
0.025
0.030
Probability 
of Measurment
 Correct Output Rank = 6 
Correct Output (b)
Figure 9: Output of QAOA on the IBM-Q14 machine using the (a) Baseline policy (b) SIM
in the Figure 9(a). The baseline PST is only 1.9% and the Relative
Strength is 0.59. With the baseline policy, a significant number
of incorrect answers are generated, especially incorrect answers
that tend to have low Hamming Weight. The baseline produces 13
incorrect outcomes with a higher frequency of occurrence than the
correct answer, with ROCA of 14.
To improve reliability, we run QAOA with SIM. We prepare, four
copies of the executable such that first copy uses non-inverted
measurements, second and third copy uses alternating partial inversions, and the fourth copy uses fully inverted measurements. We
run each copy for 4096 trials and combine all four distributions after
post-correcting the outputs. Figure 9(b) shows the distribution of
outputs produced by SIM. SIM improves PST by 10% and the IST by
23%. The Rank of the correct answer improves from 14 to 6. Thus,
SIM can attenuate several of the incorrect outputs by averaging out
the measurements over a larger number of measurement modes.
5.5 Impact of SIM on PST
We conduct our experiments on three IBM machines: ibmqx2, ibmqx4,
ibmq-melbourne. Figure 10 shows the PST of the system with SIM,
normalized to the PST of the baseline machine. We observe that
across all three machines, SIM improves PST. SIM can improve PST
by as much as 2X for ibmqx4. SIM provides an improvement in
other reliability metrics (such as Relative Strength and Rank) as
well; however, we report results on those metrics in Section 7.
bv-4A
bv-4B
qaoa-4A
qaoa-4B
bv-4A
bv-4B
qaoa-4A
qaoa-4B
bv-6
bv-7
qaoa-6
qaoa0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
Relative
Improvement in PST
ibmqx2(Q-5) ibmqx4(Q-5) ibmq_melbourn(Q-14)
Static Invert & Measure
Figure 10: Impact of SIM on PST of the three machines.
6 ADAPTIVE INVERT-AND-MEASURE
With SIM, we perform measurement in four different modes with
the expectation that these inversion strings will average out the
errors, and overall reliability will be dictated by the average errorrate for measurement rather than the worst-case. We do this because
we do not know the state being measured. However, if we could
predict (using runtime profiling) the state being measured, then
we would use an Inversion-String that maps the given state to the
strongest state. For example, if the strongest state is all-zeros, then
the Inversion-String will be the same as the state being measured.
This would ensure that the system always performs measurement
in state with minimum measurement error rate.
While running a few "canary" trials to estimate the likely output
looks like a promising option, the success of getting the right answer
with a non-negligible probability again depends on the error rate
for the state being measured during the canary trials. If the state
that we are interested in measuring is a highly error-prone state,
then even in the canary trials we would encounter an error and get
the wrong output. Therefore, we need both the profile information
of the application as well as the profile information of the machine
to make use of the canary trials. Unfortunately, the measurement
error does not have a perfect correlation with the Hamming Weight,
and for some machines (e.g.ibmqx4) this correlation is weak.
6.1 Arbitrary Measurement Bias and Impact
On ibmqx2 and ibmq-melbourne measurement strength of the basis state is inversely proportional to its Hamming Weight. However,
not all quantum computers have measurement strengths that scale
predictably with Hamming Weight. For example, on ibmqx4, IBM’s
five-qubit quantum machine, we observe an arbitrary measurement
bias such that measurement strength is not strongly correlated with
the Hamming weight of the basis state. Figure 11 show the relative
measurement strength for all 32 basis states on IBM’s five-qubit
machine. The data shows that the strength of the measurement is
not monotonically decreasing with the Hamming Weight of the
basis state. To test if the bias is repeatable, we evaluated the measurement strength of different five-qubit basis states for 35 days
over 100 calibration cycles. We observe that the bias is repeatable.
286
Mitigating Measurement Errors in Quantum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
0.0
0.2
0.4
0.6
0.8
PST
Basis Measurment
00000
00001
00010
00100
01000
10000
00011
00101
00110
01001
01010
01100
10001
10010
10100
11000
00111
01011
01101
01110
10011
10101
10110
11001
11010
11100
01111
10111
11011
11101
11110
11111
Basis states on ibmqx4
0.0
0.2
0.4
0.6
0.8
PST
Bernstein Vazirani
Figure 11: (a) Probability of Successful Trial (PST) for ibmqx4
states (b) Probability of Successful Trial (PST) for BV for different desired output states.
The state-dependent bias, variability, and machine-specific errors
can collectively produce an arbitrary bias. Also, measurement errors
has a significant impact on the reliability of the NISQ machine. For
example, we execute 32 instances of BV-4 (each for 24 thousand
trials) on ibmqx4 such that each instance outputs 5-bit basis state (4-
bit secret key and 1-bit ancillary qubit). The PST for the experiments
with 32 different keys is shown in Figure 11(b). The x-axis is the
secret input key, and the states are arranged in the increasing order
of the Hamming Weight. We can observe a positive correlation
between the PST and the measurement strength as weak basis
states have significantly lower PST compared to the stronger states.
6.2 Design of Adaptive Invert-and-Measure
To adapt to any arbitrary bias in measurement, we propose Adaptive
Invert and Measure (AIM). AIM uses run-time profiling to build the
measurement strength curve for a given quantum computer and
uses targeted inversions. Figure 12 shows an overview of AIM.
Runtime 
Profiler RBMS
Compute 
L 
Adaptive Inversion
Invert & Strings (AI- Strings)
Measure
NISQ 
Application
(a) Pick basis 
state with 
highest L 
Runtime 
Profiler RBMS
Compute 
L 
Adaptive Inversion
Invert & Strings (AI- Strings)
Measure
NISQ 
Application
(a) Pick basis 
state with 
highest L 
(b)
Adaptive 
Inversion Meas Log 
Output
Post- Measurement
Correction
Repeat: i < N; i++;
NISQ 
Application
AI- Strings (b)
Adaptive 
Inversion Meas Log 
Output
Post- Measurement
Correction
Repeat: i < N; i++;
NISQ 
Application
AI- Strings
Figure 12: Design of Adaptive Invert-and-Measure
AIM contains three parts: (1) generating machine profile for measurement strength, (2) generating likely outputs for the application
using canary trials, and (3) running the application with tailored
Inversion-Strings that map the likely output states to the strongest
state of the machine. We describe these steps below.
6.2.1 Generating Measurement Strength Function: For a small machine (such as IBM-Q5) we can build an Relative Basis Measurement
Strength (RBMS) by measuring the probability of successful measurement for each of the possible states. However, for a larger machine
(such as IBM-Q14), evaluating all possible measurement states is
not a viable option due to the exponential growth in the number
of states. For IBM-Q5, we use a brute-force approach (similar to
Figure 11(a)). Whereas, for IBM-Q14, we use a divide-and-conquer
approach, where we learn the RBMS characterizing one window
of 4-qubits at a time (sliding window). For details please refer to
the Appendix-A: Characterizing RBMS.
6.2.2 Generating Candidates for Likely Output: AIM performs canary trials using the four Inversion-Strings used in SIM to produce
an output distribution that removes global bias. However, note that
a state that is low strength may appear with low probability in
this distribution simply due to measurement errors. Therefore, we
scale the output distribution with an inverse value of measurement
strength (for example, if the measurement strength of state X is
0.1 and state Y is 0.2, but both occur with same frequency, then we
scale the likelihood of X by a factor of two compared to Y).
We denote Li as the likelihood that the measured basis state i is
correct. Li
is defined by Equation 1.
Li =
Probability of occurrence of state i in output
Measurement strength of the state i (1)
We sort and select top "k" strings with the highest L value. In
practice, these "k" strings (or the strings within one or two hamming
distance) are the most likely to be the correct output.
6.2.3 Generating Inversion-Strings for Execution: When the likely
outputs are available, we use the Inversion-String that can map
them to the strongest state. For simplicity, if the strongest state
is an all-zero state, then the Inversion-String is the same as the
predicted output. We run the execution for a given number of trials
with this tailored Inversion-String. We do this for all of the "k"
predicted outputs (we use K=4 in our study). For our evaluations, if
we have N number of trials in the baseline, we use 25% of the trials
as canary trials to generate the possible outputs for the application.
For the remaining 75% of the trials, we use the tailored InversionString to perform the experiments. The total number of trials of the
application remains the same for the baseline and AIM.
6.3 Impact of AIM on Reliability of BV
Both SIM and AIM try to transform the state being measured into
another state using Inversion-Strings. SIM does so without any
knowledge of the application and the system characteristics using
statically selected strings. AIM performs system and application
profile to generate specialized Inversion-Strings to get the strongest
state for the measurement. Figure 13 shows the PST of BV for the
baseline, SIM, and AIM on the ibmqx4 machine. We experiment
with all possible basis states. We note that the PST with the baseline
and SIM are quite variable and the fidelity depends on the states,
with some states having quite low fidelity. With AIM, the PST
remains rather stable across all the possible states. Compared to
the baseline and SIM, AIM continues to have a consistently high
PST, with the exception of state all-zeros (the all-zero state is the
strongest, so the baseline has the highest PST). Thus, AIM not only
improves the PST but also makes the system have less dependence
on the values used by the applications.
287
MICRO-52, October 12–16, 2019, Columbus, OH, USA Tannu and Qureshi 00000 00001 00010 00100 01000 10000 00011 00101 00110 01001 01010 01100 10001 10010 10100 11000 00111 01011 01101 01110 10011 10101 10110 11001 11010
11100
01111
10111
11011
11101
11110
11111
Basis states on ibmqx4
0.0
0.2
0.4
0.6
0.8
PST
Baseline Static Invert Measure Adaptive Invert Measure
Figure 13: Bernstein-Vazirani executed on ibmqx4 for all possible keys using: Baseline, SIM, and AIM. Note that for the baseline
machine the application fidelity depends on the value of the stored key. Whereas with with AIM the PST remains high for all
possible states (and is close to the maximum, except for the trivial case of all-zero key).
7 EVALUATIONS
We use Probability of Successful Trial (PST), and Inference Strength
(IST) as the figure-of-merit to evaluate effectiveness of SIM, and
AIM on ibmqx2, ibmqx4, and ibmqx-melbourne.
7.1 Impact on Inference Strength
Table 5 shows the IST (ratio of the frequency of the correct output
to the frequency of the strongest incorrect output) for the baseline,
SIM, and AIM. If the IST is less than one, then the correct output is not the most frequently appearing output string, and errors
may have masked the correct output. For example,on ibmqx2, with
baseline policy, BV-4B, QAOA-4A, and QAOA-4B produce incorrect answer more frequently than the correct answer. Whereas,
using SIM and AIM, the benchmarks produce correct output with
highest frequency such that SIM improves IST by 1.2x and AIM
improves it by 1.56x. Note that ibmqx2, was consistently the most
reliable NISQ machine during our evaluations and showed relatively low variability in errors. On the other hand, ibmqx4 had
significantly higher gate and measurement error rates. SIM improves the IST by 3.4x and AIM improves it by 7.2x. In fact, on
ibmqx4, SIM improves the IST from 0.46 to 2.85 (6.2x) and AIM
improves the inference strength to 10.38 (22.5x improvement) for
BV-4A. Whereas, for benchmarks executed on ibmq-melbourne,
Table 5: Inference Strength (IST) for Baseline, SIM, and AIM
Benchmark Platform Baseline SIM AIM
BV-4A ibmqx2 (5 Qubits) 1.22 ✓ 1.12 ✓ 1.32 ✓
BV-4B ibmqx2 (5 Qubits) 0.9 1.25 ✓ 1.83✓
QAOA-4A ibmqx2 (5 Qubits) 0.73 0.86 1.27 ✓
QAOA-4B ibmqx2 (5 Qubits) 0.72 0.96 1.12 ✓
BV-4A ibmqx4 (5 Qubits) 0.46 2.85 ✓ 10.38 ✓
BV-4B ibmqx4 (5 Qubits) 4.8 ✓ 6.4 ✓ 5.7 ✓
QAOA-4A ibmqx4 (5 Qubits) 0.82 1.94 ✓ 2.03 ✓
QAOA-4B ibmqx4 (5 Qubits) 0.72 2.67 ✓ 1.98 ✓
BV-6 ibmq-melbourne 0.70 0.93 1.02 ✓
BV-7 ibmq-melbourne 0.62 0.84 1.09 ✓
QAOA-6 ibmq-melbourne 0.23 0.72 0.86
QAOA-7 ibmq-melbourne 0.18 0.36 0.78
SIM improves the relative strength by 1.9x and AIM improves it by
2.8x. Note that although ibmq-melbourne had a high measurement
error rate we did not observe as high an improvement in IST as for
scaled benchmarks (BV-6, BV-7, QAOA-6, and QAOA-7) because
measurement errors are not the only errors that produce incorrect
answers. For example, gate errors can degrade the IST as well, and
AIM and SIM can not protect against operational errors.
7.2 Impact of SIM and AIM on PST
By mitigating bias in the qubit measurement, we can improve the
measurement fidelity and overall reliability on NISQ machines.
Figure 14 shows the Probability of Successful Trial (PST) of SIM
and AIM, normalized to the baseline that uses variability-aware
qubit allocation. For ibmqx2, SIM improves the PST by 22% (upto 30%) and AIM improves it by 40% (up-to 56%). Due to highly
biased measurement errors on ibmqx4, SIM improves the PST by
74% (up-to 85%) and AIM improves it by 290% (up-to 329%). For
ibmq-melbourne, SIM improves the PST by 16% (up-to 20%) and
AIM improves it by 27% (up-to 36%). Both SIM and AIM are simple
techniques that improve the reliability of the NISQ machines by
mitigating measurement errors.
bv-4A
bv-4B
qaoa-4A
qaoa-4B
bv-4A
bv-4B
qaoa-4A
qaoa-4B
bv-6
bv-7
qaoa-6
qaoa-7
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Relative
Improvement in PST
ibmqx2(Q-5) ibmqx4(Q-5) ibmq_melbourn(Q-14)
Static Invert & Measure
Adaptive Invert & Measure
Figure 14: Probability of Successful Trial (PST) for SIM and
AIM, normalized to the baseline. SIM improves PST by up-to
2X, whereas AIM improves PST by up-to 3X.
Operating NISQ machines with consistently high reliability and
low variability is extremely challenging as qubit devices are sensitive to operating conditions. As the complexity of NISQ machines
will increase ensuring optimal operating condition for each and
every qubit device may not be possible. Therefore, it is essential to
develop techniques that can alleviate reliability issues at a software
level. The proposed techniques: SIM and AIM, achieve this goal by
using inverted measurements to mitigate state dependent bias in
measurement errors.
288
Mitigating Measurement Errors in Quantum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
8 RELATED WORK
Improving the reliability of NISQ is an interdisciplinary area of
research. Following are the current broad research directions.
Compiler Techniques: Several prior works have focused on the
compiler techniques to eliminate redundant gates and minimize the
number of SWAPs [2, 8, 13, 15, 19, 20, 22, 23, 31, 33]. While early
papers on qubit allocation were focused on the SWAP minimization, recent work [26] exploit the hardware characteristic when
allocating qubits. Moreover, [17, 18, 28], show significant reliability
gain using variability-aware compilation for NISQ.
Application and Device Specific Techniques: To tolerate noise,
researchers are developing and benchmarking algorithms that are
inherently resilient to noise, and require less number of resources [4,
7, 32]. Moreover, to mitigate the errors, researchers have proposed
error mitigation techniques [5, 9–12, 25, 29, 30].
Concurrent Work: In our concurrent work [27] at MICRO’19, we
demonstrate how correlated errors can degrade our ability to infer
correct answer on NISQ machines. To improve inference strength,
we propose EDM: Ensembles of Diverse Mapping that mitigate correlated errors by using different qubit mappings for different trials.
This paper and EDM use similar philosophy that on a NISQ machine, while executing a program, if we repeat identical program for
all trials then we can introduce correlation and bias in errors. This
can limit our ability to infer correct answers on a NISQ machine.
Our solution of flipping a vulnerable state bears resemblance to
the Data Bus Inversion [24]. Thus, there may be synergy in efficient
reliability solutions that we apply in classical machines to detect
and mitigate errors in near-term NISQ machines.
9 CONCLUSION
We focus on mitigating measurement errors, which tend to have
the highest error-rate on current machines. We observe that there
is state-dependent bias in measurement errors, with some states
experiencing significantly higher error rates compared to the other
states. Furthermore, the disparity between the measurement strength
of basis states can significantly affect the reliability of NISQ applications, especially while measuring states with a high Hamming
Weight. We propose to exploit this bias in measurement errors to improve the overall system reliability. For example, while measuring a
state which is highly susceptible to measurement errors, we invert
the state of the qubits and perform measurement in the inverted
mode. To avoid the reliance on a-priori knowing the state being
measured, we propose Static Invert-and-Measure (SIM), which splits
the trials into multiple groups and applied a different inversion
string to each group. SIM obtains measurement errors close to the
average and improves the application reliability by up to 2X.
If we could predict the state that is being measured, and the
error rate profile of the machine, then we can proactively map the
predicted state to the strongest state using a specifically designed
inversion string. We use this insight to propose Adaptive Invertand-Measure (AIM). AIM estimates the measurement strength of
the machine for each state. AIM also conducts a few "canary" trials
to learn the likely outcomes for the given application and uses the
inversion string that maps the predicted output to the strongest
state before performing the measurement. Our evaluations, using
three IBM machines (ibmqx2, ibmqx4, ibmqx14), shows that AIM
improves the reliability of the system by up to 3X