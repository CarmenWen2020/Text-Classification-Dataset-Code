ABSTRACT
Existing and near-term quantum computers face signi!cant reliability challenges because of high error rates caused by noise. Such machines are operated in the Noisy Intermediate Scale Quantum (NISQ)
model of computing. As NISQ machines exhibit high error-rates,
only programs that require a few qubits can be executed reliably.
Therefore, NISQ machines tend to underutilize its resources. In
this paper, we propose to improve the throughput and utilization
of NISQ machines by using multi-programming and enabling the
NISQ machine to concurrently execute multiple workloads.
Multi-programming a NISQ machine is non-trivial. This is because, a multi-programmed NISQ machine can have an adverse
impact on the reliability of the individual workloads. To enable
multi-programming in a robust manner, we propose three solutions.
First, we develop methods to partition the qubits into multiple reliable regions using error information from machine calibration
so that each program can have a fair allocation of reliable qubits.
Second, we observe that when two programs are of unequal lengths,
measurement operations can impact the reliability of the co-running
program. To reduce this interference, we propose a Delayed Instruction Scheduling (DIS) policy that delays the start of the shorter
program so that all the measurement operations can be performed
at the end. Third, we develop an Adaptive Multi-Programming (AMP)
design that monitors the reliability at runtime and reverts to single
program mode if the reliability impact of multi-programming is
greater than a prede!ned threshold. Our evaluations with IBMQ16 show that our proposals can improve resource utilization and
throughput by up to 2x, while limiting the impact on reliability.
CCS CONCEPTS
• Hardware: Quantum technologies;
KEYWORDS
Quantum Computer, Multi-programming, Reliability, NISQ
1 INTRODUCTION
Quantum computing can solve classically intractable applications
such as breaking cryptographic codes [37], physics and chemistry simulations [7, 20, 32] by using quantum bits (qubits) and
quantum-mechanical properties. Recently, IBM, Intel, and Google
have showcased prototypes comprising of 50, 49, and 72 qubits respectively [13, 14, 16]. The size of quantum computers is expected
to get to hundred(s) of qubits in the near future. Quantum computers require extremely complex control circuitry, sophisticated
microwave devices, cryogenic refrigerators that can maintain temperatures of few milli-kelvins, and shielding from environmental
noise. Therefore, quantum computers are typically accessible to
users via cloud services [2, 9, 34] instead of using a per-user system.
Quantum cloud services provide accessibility, ease of use, and
scalability [2, 9, 23, 34]. Cloud providers try to relieve the users
from resource management tasks by hiding the complexity involved
in operating a quantum computer. The recent advances in quantum
algorithms and hardware have fueled research (and commercial)
interests, and there is an exponential growth in number of users of
quantum computers, far outpacing the growth in number of quantum computers. As the demand for access to quantum computers
grow, this would lead to increasing wait-times, and therefore there
is a need to increase the throughput of quantum computers, so that
the same machine can scale to a larger number of users (or a larger
number of experiments from the same user within a shorter period
of time). In this paper, we study multi-programming as a means to
improve the throughput of near-term quantum computers.
Quantum computers are susceptible to errors. While quantum
computers can be made fault-tolerant using quantum error correction (QEC) codes, such codes are expensive (20-100 physical qubits
to form a fault-tolerant logical qubit). Therefore, we are unlikely
to see QEC being adopted until quantum computers have several
thousands of qubits. Consequently, near-term quantum computers
are likely to be operated without error correction, in a mode called
Noisy Intermediate-Scale Quantum (NISQ) [31] computing. In the
NISQ model of computing, computations are susceptible to errors
and therefore, an application is executed several times (called trials)
and the !nal answer is determined statistically. The likelihood that
a NISQ machine can execute large programs without encountering
an error is quite small, especially due to high error rates of 2-qubit
gate operations (CNOT) [40].
As CNOT operations dominate most quantum algorithms, we
explain the limitations of CNOT operations on the success rate
of a program using an example. The typical CNOT error-rate of
current machines is in the range of 2% to 4%. Figure 1(a) shows the
probability that a program containing a given number of CNOT
operations can be !nished without the computation encountering
any error. We analyze three di"erent CNOT error-rates, ranging
from 1% (optimistic) to 3% (current). For near-term quantum computers, a program with several tens of CNOT operations will have
291
MICRO-52, October 12–16, 2019, Columbus, OH, USA Das, Tannu, Nair, and !reshi
3
3
10
2
2
3 3
2
2
3
Qubit Allocation
4 unmapped 
qubits ~50% 
underutilization
Noise adaptive variation 
aware compiler
4 qubit 
program Calibration 
Data
(a) (b)
3
3
10
2
2
3 3
2
2
3
4 qubit 
program 
Less reliable
4 qubit 
program
Reliable
100 % utilization 
But one program has lower reliability
(c)
3
3
10
2
2
3 3
2
2
3
4 qubit 
program
Reliable
3 qubit 
program
Reliable
88 % utilization 
Both program are reliable
(d)
Figure 1: (a) High CNOT error rates on NISQ computers limit the number of operations that can be completed reliably (b)
Intelligent compilers use calibration data to locate reliable qubits but can leave resources underutilized (c) Two programs can
o!er 100% utilization but one will have lower reliability. (d) Two di!erent programs o!er 88% utilization but both are reliable.
an extremely low likelihood of being completed without any error.
Therefore, it is extremely di#cult to run large circuits that use more
qubits and greater circuit-depth. To execute applications reliably,
compilers use gate !delity data obtained from machine calibration
and map programs onto the most reliable qubits [25, 40]. Even then,
only smaller programs with low circuit depths and fewer qubits
execute reliably. The problem continues to persist as the size of
NISQ computers scale because improvements in gate error rates
is extremely slow. Consequently, as shown in Figure 1(b), an application tends to utilize only a fraction of the available resources.
The throughput of a NISQ computer can be improved by using the
remaining unused qubits to perform computations. To that end, this
paper advocates multi-programming for quantum computers, such
that multiple independent programs can be executed concurrently
on a NISQ machine to improve the system throughput.
Unlike conventional computers, sharing resources on a NISQ
computer is fundamentally challenging. When multiple programs
execute concurrently on a NISQ machine, the activity of one program can negatively a"ect the reliability of a co-executing program. So, the interference from resource sharing is not limited to
performance but also dictates the overall !delity of the computation performed by the NISQ machine. The goal of this paper is to
propose solutions that improve the throughput and utilization of
NISQ machines while limiting the impact on reliability associated
with multi-programming NISQ computers. We study three speci!c
sources of reliability impact and develop policies to mitigate them.
To enable multi-programming on NISQ computers, we !rst study
the problem of developing Fair and Reliable Partitioning (FRP) algorithms. Existing compiler policies reduce the cost of communication to overcome the restricted connectivity on NISQ computers [19, 38, 41] and perform computations on qubits and links with
the lowest error rates [25, 40]. For a NISQ computer that simultaneously executes two or more applications, the compiler may
not be able to optimize the reliability of each individual application and an application may end up with executing on error-prone
qubits. We observe that not all reliable qubits are co-located in
space. Thus, even an intelligent compiler cannot completely avoid
all the weak links and qubits. Hence, it is likely that some of the
reliable qubits remain unused. However, as shown in Figure 1(c),
the reliability of at least one of the programs could be very low on
a multi-programmed NISQ computer with 100% utilization. On the
contrary, if there exists two separate regions, each with reliable
qubits and links, it is possible to map two programs separately onto
these regions. As shown in Figure 1(d), such a scheme would help
improve qubit utilization without compromising the reliability of
either of the two programs.
The second problem we try to address is to reduce the impact of
scheduling the measurement operations. When two programs of
unequal lengths are executed concurrently, and the shorter program
!nishes, then the measurement operations of the shorter program
can interfere with the longer program. We propose the Delayed
Instruction Scheduling (DIS) policy that delays the scheduling of the
shorter program such that both programs !nish their gate operations at similar times, and then performs the qubit measurements.
The third problem we try to address is proactively ensure robustness under multi-programming. When multiple programs are run
concurrently, the activity of the NISQ machine is increased, which
can lead to increased cross talk noise and cause the error rate of
the operations to increase. To limit the reliability impact due to
multi-programming, we develop an Adaptive Multi-Programming
(AMP) design, which monitors the reliability impact at runtime,
and reverts the system to isolated execution if the reliability impact due to multi-programming exceeds a certain threshold. AMP
allows the system to use multi-programming when it is bene!cial,
while ensuring that the reliability of programs that are sensitive to
concurrency can still be maintained at conventional levels.
Overall, this paper makes the following contributions:
(1) We advocate the use of multi-programming to improve the
utilization and throughput of NISQ computers, whereby the qubits
are used to concurrently run multiple workloads.
(2) We develop Fair and Reliable Partitioning (FRP) algorithms that
try to split the qubit resources into multiple groups in a fair manner,
while avoiding the qubits/links that have extremely high error rates.
(3) We develop the Delayed Instruction Scheduling (DIS) policy to
mitigate the interference of measurement operations of one program on the gate operations of the co-running programs.
(4) We propose an Adaptive Multi-Programming (AMP) design that
monitors the reliability impact at runtime and reverts the system
to isolated execution mode if the reliability impact is high.
Our experiments on the IBM quantum computer IBM-Q16 show
that multi-programming can improve the throughput and qubit
utilization up to 2x with minimal impact on reliability.
292
A Case for Multi-Programming !antum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
2 BACKGROUND AND MOTIVATION
2.1 Basics of Quantum Computing
Quantum computers can solve problems deemed hard on conventional computers [7, 11, 20, 32, 37]. A qubit is the basic unit of
information on a quantum computer. Qubits can be in a superposition of multiple states which provides parallelism. For instance,
a system with n qubits can exist in a superposition of 2n possible
states at the same time. Quantum computers use entanglement to
create a correlated state over multiple qubits, where manipulating
one of them directly impacts the other qubits. In most quantum
algorithms, qubits are initialized in a superposition state, manipulated through quantum gate operations, and measured at the end
of the program. Measurements collapse qubits to a classical state.
2.2 Errors in Quantum Computers
Qubits are extremely sensitive to noise and prone to errors. Qubit
errors can be broadly classi!ed into the following categories:
(1) Coherence errors: Qubits retain their quantum state only for
an extremely small duration of time (coherence time), limiting the
circuit depth that can be run on a NISQ machine.
(2) Operational errors: Quantum gate operations are imperfect and
cannot be applied with precise accuracy. Operational errors or gate
errors refer to errors that occur during computations.
(3) Measurement errors: Qubits are measured to retrieve the !nal
result of a quantum program. Measurement errors lead to incorrect
results even if a program does not encounter other errors.
0 1 2 4 5 6
13 12
3
11 10 9 8 7
0
2
0 3
1 4
(a) (b)
Figure 2: Publicly available quantum computers (a) IBM QX4
Tenerife architecture (b) IBM Q16 Melbourne architecture
2.3 NISQ Model of Computing
Quantum computers can be protected against errors by leveraging Quantum Error Correction (QEC) codes [8, 10, 17], however,
such codes require an overhead of 20x-100x (physical qubits per
fault-tolerant qubit), so we are unlikely to see systems with such
codes until the system reaches a capacity of several thousands of
qubits. Figure 2 shows the architectures of current generation of
quantum computers from IBM, QX4 Tenerife and Q16 Melbourne.
1
Quantum computers are expected to scale up to hundreds of qubits
in near future [31]. Scaling quantum computers to a large number
of qubits is extremely challenging primarily due to two reasons.
Firstly, additional noise channels are introduced as systems grow
in size. Secondly, the complexity of the circuitry used to control
individual qubits increases. Current quantum computers are operated in a mode called Noisy Intermediate Scale Quantum (NISQ)
computing [13, 14, 16]. We are likely to see NISQ machines over
the next decade and such machines are expected to solve important
algorithms such as Quantum Approximate Optimization Algorithm
(QAOA) [6] and Variational Quantum Eigensolver (VQE) [22, 30].
1IBM Q16 Melbourne is a publicly accessible 14-qubit quantum computer from IBM
based on superconducting qubits. For the rest of the paper, we refer it as IBM Q16.
2.4 Application Fidelity Under NISQ
Reliably executing applications on NISQ machines is hard because
of very high error rates and lack of fault-tolerance. Hence, programs are executed multiple times. Each execution is called a trial.
The application reliability of a NISQ application, measured as the
Probability of a Successful Trial (PST) [40], depends on several factors, such as the number of quantum gates and circuit depth. It
also depends on the link error rates, coherence times, and measurement errors of the physical qubits on which the program is
mapped [25, 40]. We measure the PST of programs comprising of
two-qubit gate and measurement on IBM QX4 and IBM Q16.
Figure 3: Experimental demonstration of impact of gate errors on program "delity. Both IBM QX4 (left) and Q16 (right)
show an decrease in the program success rate (Probability of
Successful Trial) as the number of operations increase.
We form a synthetic program that performs a speci!ed number
(N) of CNOT operations on a single link and measure the target
qubit. The probability that a random guess will provide a correct
answer is 50%. Figure 3 shows the probability of getting the correct
answer as the number of CNOT operations in the program is varied
for IBM-QX4 and IBM-Q16. We note that once the program has
only few tens of CNOT operations, the output of the machine is no
better than a random guess. A program can use the CNOT budget by
performing few CNOT operations on several qubits (shorter depth)
or several CNOT operation on a few qubits of qubits (longer depth).
However, a program that has a large number of CNOT operations
on a large number of qubits will have intolerable error rates.
Program Cloud Services
Server
quantum 
object
Data
Analyze Distribution Infer 
answer
User
Collect 
Results
Figure 4: Cloud based user-quantum computer interface
2.5 Quantum Cloud Services and Challenges
Users can access quantum computers through cloud services as
shown in Figure 4. Quantum computers have huge deployment,
maintenance, and operating costs. This originates from the fundamental resources and infrastructure required to run a quantum
computer such as cryogenic coolers, superconducting wires, microwave devices, and sophisticated control circuitry. Cloud services
ensure ease of use where users can take their hands o" from actual resource management tasks. However, quantum cloud services
faces a few key challenges.
293
MICRO-52, October 12–16, 2019, Columbus, OH, USA Das, Tannu, Nair, and !reshi
2.5.1 Resource Underutilization: Qubit error rates improve extremely
slowly and currently 2-qubit gate error rates range in the order of
2-4%. Consequently, only a few operations (ranging in tens) can
be executed without encountering errors. The reliability of workloads using larger number of qubits, with greater circuit depths
is much lower than smaller workloads. Alternately, smaller workloads can signi!cantly leave resources unused on the quantum chip.
The resource underutilization becomes more signi!cant as NISQ
computers grow in size and more qubits are available on a quantum
chip. For example, allocating a 4-qubit program on IBM Q16 can
lead to more than 70% resource underutilization.
Figure 5: Pending tra#c for IBM Q16 on di!erent days
2.5.2 Contention for !antum Computers: Quantum computing
research has accelerated in recent years with demonstrations of
prototypes and investments from the industry to leverage these
machines for commercial advantage. This has led to an increase in
the number of active researchers from a wide spectrum of scienti!c
domains. However, the rate at which quantum computers are being
developed lags the rate of increase in the number of users. The
limited number of systems leads to increasing contention for access
and wait times in the queues can be large as shown in Figure 5.
Increasing the rate at which a quantum computer services the
requests can allow the system to handle a larger number of requests.
2.6 Proposal: Multi-programming NISQ
In this paper, we advocate multi-programming for improving the
utilization of NISQ computers and show that it is practical to concurrently run multiple applications instead of letting the unused
qubits remain idle. The increased throughput has added bene!ts for
cloud providers as it helps in servicing jobs quicker as the number
of users grow and quantum computers remain limited in number.
However, multi-programming a NISQ computer is non-trivial as
it can directly impact individual application reliability. When a
NISQ computer is multi-programmed, its physical qubits must be
distributed between the applications. But, physical qubits exhibit
variance in error rates and current compilers [25, 40] account for
such variation while performing qubit allocation and movement to
improve the reliability. Partitioning a quantum computer to share resources may eventually allocate weaker qubits to an application and
restrict a compiler’s optimization capabilities for choosing reliable
qubit movement paths. A degradation in reliability may also result
from additional unintended crosstalk channels [35] and on-going
measurement operations. Therefore, multi-programming must be
adaptive with a mechanism to detect degradation in reliability. We
identify three challenges in multi-programming NISQ machines
and provide e"ective solutions. We describe our evaluation methodology before discussing our solutions.
3 EVALUATION METHODOLOGY
We perform our evaluations on the IBM Q16 quantum computer. To
ensure fairness, for any two workloads which are used to compare
reliability, all experiments are performed in the same calibration
cycle and by launching experiments one after another.
3.1 Figure-of-merit: Trial Reduction Factor
Multi-programming enables sharing of quantum resources and improves machine throughput. When the throughput increases, the
e"ective number of trials performed on both programs combined
is reduced. We de!ne Trial Reduction Factor (TRF) as the ratio of
the number of trials performed when both programs execute individually (baseline) to the total number of trials performed when
the programs share resources. If Tindependent
i is the number of
trials performed when the i
th program is executed independently
and Tshared
ij is the number of trials performed when i
th and j
th
programs share resources, their TRF is de!ned by Equation (1).
TRFij =
Tindependent
i +Tindependent
j
Tshared
ij
(1)
3.2 Quantifying Application Reliability
To evaluate application reliability we use the metric: Probability of
a Successful Trial (PST), de!ned as the ratio of number of successful trials to the total number of trials performed [40]. For greater
reliability, a higher PST is desirable.
PST = Number of successful trials
Total number of trials (2)
3.3 NISQ Benchmarks
For our baseline we use NISQ benchmarks derived from prior works
on noise aware compilation policies [25, 40] described in Table 1.
Since out of 14 qubits on IBM Q16, only a few of them o"er low
gate and measurement error rates, we explore small benchmarks.
For the evaluation of our proposed policies for multi-programming,
we use a set of workload mixes derived from the NISQ benchmarks
speci!ed in Table 1.
Table 1: NISQ Benchmarks
Benchmark Description Qubits Number of Number of
Instructions CNOTs
bv_n3 Bernstein-Vazirani [1] 3 8 2
bv_n4 Bernstein-Vazirani [1] 4 11 3
To"oli_n3 To"oli gate 3 15 6
Fredkin_n3 Fredkin gate 3 16 8
Peres_n3 Peres gate 3 16 7
3.4 Baseline Setup
For the baseline, we estimate the PST of each NISQ benchmark by
executing it independently on IBM Q16 for 8192 trials using the
best qubit allocation derived from calibration data.
294
A Case for Multi-Programming !antum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
3.5 Overview of the Proposed Framework
Our evaluation framework is shown in Figure 6. It accepts two
workloads W1 and W2 (equivalent to two independent jobs) and
the most recent calibration data. Depending upon the number of
qubits required for each workload, the partitioning algorithm decides if they can both be executed reliably on the given quantum
computer. If there exists two regions where W1 and W2 can be
mapped and executed reliably, they are compiled together using
the qubit allocations received from the partitioning algorithm and
executed. The PST of each individual workload is calculated. The
impact on reliability of each program is computed by comparing
with the PST obtained by individually executing the same program
using the best qubit allocation (baseline).
Partitioning Algorithm: 
Locate two reliable partitions 
with X and Y qubits each
W1 W2 Calibration Data
Partitions 
exist?
Yes Compile 
W1, W2 
together
Compile 
W1, W2 
separate
No
IBM Q16
Melbourne
Perform N trials
Compute 
PST
Two partitions
W1: Workload #1
X qubits
W2: Workload #2
Y qubits
W1 PST
W2 PST
Figure 6: Overview of the proposed multi-programming
framework. The partitioning algorithm locates two reliable
regions on the NISQ computer, with X and Y qubits each. If it
can "nd two such regions, both workloads execute together.
If it is unable to locate the requested regions, it defaults to
the baseline and each benchmark is run individually
4 FAIR AND RELIABLE PARTITIONING
We advocate multi-programming NISQ computers to improve the
throughput by executing multiple programs concurrently. Since
the reliability of a NISQ application depends on the physical qubits
allocated to the program, it is important to ensure fairness while
allocating qubits to multiple programs in a shared environment.
4.1 Challenges in Fair Resource Allocation
The challenges in fair resource allocation arises from the uniqueness
of each physical qubit that is exhibited in the non-uniformity in
coherence times, gate and measurement error rates. Furthermore,
these error rates vary in time. Thus, the physical qubits allocated
to a program directly impacts its reliability [25, 40]. Compilers
account for this variation to perform qubit allocation and select
qubit movement paths to enable SWAP operations.
4.1.1 Restrictions on !bit Allocation: Multi-programming constrains the compiler to use a restricted set of physical qubits, limiting
its capability to optimize for greater reliability. In order to understand the restrictions imposed on qubit allocation, we look at the
allocations of a 4-qubit program P1 and a 5-qubit program P2 on
a hypothetical NISQ architecture. As shown in Figure 7(a), when
mapped independently, P1 is allocated physical qubits A, B, I, and J
A B C D E
J I H G F
2
2
2
2 2 2
24
322
3 4
A B C D E
J I H G F
2
2
2
2 2 2
24
322
3 4
4 qubit program 
allocation
5 qubit program 
allocation
5 qubit program 
allocation
4 qubit program 
allocation
(a) (b)
Figure 7: (a) Qubit allocation of a 4-qubit program P1 and a
5-qubit program P2. (b) Qubit allocations of P1 and P2 on a
multi-programmed NISQ computer. Each node represents a
qubit and label on each edge represents the link error rate.
whereas, P2 is allocated physical qubits A, B, C, I, and J. Figure 7(b)
shows a qubit allocation for both programs together. The average
link error rate of the regions allocated to P2 for independent execution and in the shared environment are 2.2 and 2.6 respectively.
The allocation in the shared environment is 18% weaker.
A B C
D E
B
A C
D E
Example Program
1. cnot q0, q4
2. cnot q1, q4
3. cnot q2, q4 
4. cnot q3, q4
q0 q4 q1
q2 q3
q0 q1
q2 q3
q4
Number of SWAPs : 1 Number of SWAPs : 0
(a) (b) (c)
Figure 8: (a) An example NISQ program (b) this topology requires 1 SWAP to perform Instruction 4 (c) this topology does
not require any extra SWAP to execute the program
4.1.2 Restrictions on !bit Movement: Application reliability not
only depends on qubit allocation, but also depends on program
characteristics and network topology of the allocated region. A
well-connected region can minimize the total cost of SWAPs inserted to bring two non-adjacent qubits physically next to each
other so that a CNOT gate can be executed. For instance, Figure 8
shows a program that executes 4 CNOT instructions and two possible network topologies. In the partition shown in Figure 8(b), the
compiler needs to insert a SWAP operation in order to perform the
4th CNOT instruction. However, a better connected region as shown
in Figure 8(c) requires lesser number of SWAPs (in this case 0). When
a quantum computer is partitioned for multi-programming, application reliability can vary based upon the number of SWAPs inserted.
This depends on the network topology of the assigned partition.
4.2 Qubit Allocation for Multi-programs
We study the average 2-qubit gate error rate on each physical link
and measurement error rates for each qubit of IBM Q16 as shown
in Figure 9.2 We make two key observations:
• Not all good links are spatially co-located. A region with good
links has weak links as well. For example, qubits Q2 and Q12 have
two links each with error rates of 4%, but the link that connects
them physically has an error rate of 17%.
2Error rates in this Figure are based on calibration data collected on 03.14.2018
295
MICRO-52, October 12–16, 2019, Columbus, OH, USA Das, Tannu, Nair, and !reshi
• Qubits with good connectivity and reliable links can still su"er
from high measurement error rates (for example: Q3, Q11).
• Qubits connected to link(s) with low gate error rate(s) do not
necessarily have a large degree of freedom (number of links) and
may also su"er from high measurement errors (for example: Q7).
We observe similar trends on IBM Q20 based on previously reported
numbers [40] since recent data is unavailable.
8 16 4 3 6 4
4 5
21
12 5 9 4 15
5 4 4 4 4 11
3
4 3
5
5
9
3
4
4 4
21 17
Q0 Q1 Q2 Q3 Q4 Q5 Q6
Q13 Q12 Q11 Q10 Q9 Q8 Q7
Figure 9: Error rates on IBM Q16 architecture. A node represents a qubit and the label on each edge represents the
2-qubit gate error rate for that link. Links marked in bold
have above mean 2-qubit gate error rate whereas qubits circled bold have greater than mean measurement error rate
Reliable qubits are thus usually distributed across the entire
architecture, rather than being situated next to each other. Current
noise aware compilers try to !nd a sweet spot by locating reliable
qubits as well as allocating program qubits to physically close and
well-connected qubits. The latter policy is crucial to minimize the
total number of SWAPs inserted. Thus, the compiler is compelled to
use some of the qubits and links that may not have the lowest error
rates. As a result, some of the reliable links and qubits with lower
measurement error rates may remain unused. Therefore, we draw
a key insight that as long as there exists more than one reasonably
good cluster of qubits on a quantum substrate with similar error
rates, it may be possible to run two independent programs on each
cluster without signi!cantly a"ecting their reliability. Using this
insight we design a qubit allocation algorithm that partitions the
quantum computer for enabling multi-programming.
4.2.1 Fairness in !bit Allocation: The qubit allocation algorithm
described in Algorithm 1 analyzes the underlying architecture and
ranks links and qubits depending upon their utility, and classi!es
the physical qubits into 3 groups of high, medium and low utility.
Utility of a physical qubit is de!ned as the ratio of the number
of links (degree of freedom) to the sum of link error rates. The
algorithm chooses a high utility qubit with good neighboring qubits
as the root and grows a graph by adding nodes along the boundary.
Compiler parameters 
4.2.2 To partition or not to partition? Post qubit selection, the compiler analyzes the reliability of each partition and $ags a warning if
at least one of the programs is allocated qubits with lower reliability
as compared to its qubit allocation in an isolated environment. The
296
A Case for Multi-Programming !antum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
compiler uses the tolerance factor to decide the di"erence in reliability it can tolerate. The ability to partition a quantum computer
not only depends on the size of the quantum computer, size of the
programs in context, and distribution of error rates but also on the
daily variation in error rates. Certain regions on a quantum computer exhibiting completely di"erent characteristics on di"erent
days thereby limiting the opportunities for multi-programming.
Algorithm 1 Fair and Reliable Partitioning
1: // Locate a reliable cluster on the chip
2: function create_sub_graph(Program, utility, CMR)
3: rank starting rank ; root node[rank];
4: while root node not found do
5: if 
4.2.3 Scalability: We implement our proposed algorithm and run
a mix of workloads on IBM Q16 with error rates shown in Figure 11.
For developing the mapping for a system with larger number of
qubits, information on reliable regions can be saved once they are
located and reused by other programs. As detection of reliable
regions only depend on calibration data; it can be done o%ine.
Furthermore, instruction scheduling can be performed in parallel
and merged together with appropriate barriers. Similarly, as we
are analyzing a cloud environment, the compilation latency can be
pipelined with execution of other jobs.
12 8 5 16 6 9
7 4
6
11 6 8 6 24
4 3 5 5 6 12
62
5 3
8
5
34
36
4
5 4
12 8
Q0 Q1 Q2 Q3 Q4 Q5 Q6
Q13 Q12 Q11 Q10 Q9 Q8 Q7
Figure 11: Error rates on IBM Q16 during experiment
4.3 Impact on Throughput and Reliability
With multi-programming for certain workload sizes on IBM Q16,
the resource utilization and throughput can be improved by 2x with
slight loss of program reliability. The Trial Reduction Factor (TRF)
is 0.5, indicating that the throughput of the machine is doubled
and the overall number of trials is reduced by 50%. Table 2 shows
the PST of each individual workload for the baseline and under
multi-programming.
Table 2: Probability of Successful Trial (PST) under isolated
execution and under multi-programming
Mix Number of Baseline Multi-Program
CNOTs PST in %age PST in %age
W1 
5 DELAYED INSTRUCTION SCHEDULING
In this section, we discuss interference from measurement as one
of the potential challenges in multi-programming a NISQ computer.
Qubits are extremely fragile and signals applied to one qubit can
leak on to the other qubits causing unwarranted $uctuations in
their quantum states. Interference may occur due to the crosstalk
introduced by additional operations and qubit measurement operations. We discuss how qubit measurements are performed on
current NISQ computers and propose an instruction scheduling
policy that minimizes the interference caused by them.
5.1 When Should Qubits be Measured?
Superconducting qubits [4, 18] at 15-20 milli-Kelvins are controlled
and measured using microwave signals generated at room temperature. The measurement setup also consists of signal attenuators,
ampli!ers, and circulators designed to operate at 4 Kelvin. This thermal gradient introduces noise channels into the system. When two
programs execute in parallel, conventional wisdom suggests that
they be launched as decoupled independent threads as shown in
Figure 13(a). In this scheduling, qubits of a program are measured as
soon as all its gate operations complete. Unfortunately, on a NISQ
computer, two programs cannot be completely decoupled since
measurements corresponding to the shorter program can inject
noise channels into the operating environment of the co-running
program, lowering its reliability. Another possible approach is to
schedule measurements after all gate operations are executed as
shown in Figure 13(b). This approach is currently used by the IBM
Qiskit compiler as the default. However, for two programs of di"erent lengths, if the qubit measurements of the shorter program are
delayed to protect the program in progress, they may decohere by
the time they are measured. To overcome this problem, we propose
that two parallelizable programs be context aware.
Program 2 (P2)
Program 1 (P1)
Measurements 
Barrier
(a) (b) (c)
Delay
Delay
P1 P2 P1 P2 P1 P2
Figure 13: (a) Programmer expects two programs to be decoupled completely (b) Default instruction scheduling from
IBM Compiler where all measurements are performed at the
end (c) Our proposed delayed instruction scheduling policy
where the shorter program thread starts late
5.2 Scheduling Algorithm for Multi-programs
In order to minimize the impact of qubit measurement operations
on on-going gate operations and to maximize the reliability of both
the applications, we propose a Delayed Instruction Scheduling (DIS)
policy such that both the applications complete around the same
time and all qubit measurements are performed only after gate
operations for both programs conclude. The same two programs
shown in Figure 13(a) will be scheduled as shown in Figure 13(c)
as per the delayed scheduling policy. The scheduling policy moves
all the measurements to the end by inserting appropriate barriers
as shown in Algorithm 2 and statically schedules instructions by
analyzing the data $ow graph of both the applications. The overall
schedule of the multi-programs is generated by Algorithm 3.
Algorithm 2 Instruction Scheduling
1: // Generate schedule for multi-programming
2: function generate_schedule(N program schedules)
3: if Delayed Instruction Scheduling then
4: Add all measurement instructions for
5: N programs in order of decoherence times
6: Add global barrier
7: end if
8: for Each program (Pi ) in N programs do
9: Add instruction of Pi to global schedule.
10: if all instructions of Pi are scheduled then
11: if Delayed Instruction Scheduling then
12: Insert barrier
13: end if
14: Decrement N
15: end if
16: end for
17: return global schedule
18: end function
5.3 Impact of Measurement Scheduling
We evaluate our partitioning scheme along with the proposed DIS
policy. We execute the compiled code on IBM Q16 and determine
the PST for the same mix of workloads used in Section 4.2. The
results are shown in Figure 14. Our partitioning scheme when
combined with the proposed instruction scheduling policy improves
the reliability. Overall, the TRF is still 0.5 and the reliability drops
by 10% on an average. However, we see an improvement in the
reliability of the longer program (3% average improvement in PST)
and the worst-case degradation in PST is about 22%. We expect the
impact of our policy will be higher when measurements can be
done in parallel and takes lower latency than current technologies.
Figure 14: Probability of Successful Trial (PST) of proposed
delayed instruction scheduling policy relative to baseline
298
A Case for Multi-Programming !antum Computers MICRO-52, October 12–16, 2019, Columbus, OH, USA
Algorithm 3 Multi-program Compilation
1: function (Chip coupling graph, N programs, calibration data)
2: for Each physical qubit (ph