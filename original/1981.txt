ABSTRACT
To understand how the human brain works, neuroscientists heavily
rely on brain simulations which incorporate the concept of time to
their operating model. In the simulations, neurons transmit their
signals through synapses whose weights change over time and by
the activity of the associated neurons. Such changes in synaptic
weights, known as learning, are thought to contribute to memory,
and various learning rules exist to model different behaviors of the
human brain. Due to the diverse neurons and learning rules, neuroscientists perform the simulations using highly programmable
general-purpose processors. Unfortunately, the processors greatly
suffer from the high computational overheads of the learning rules.
As an alternative, brain simulation accelerators achieve orders of
magnitude higher performance; however, they have limited flexibility and cannot support the diverse neurons and learning rules.
In this paper, we present FlexLearn, a flexible on-chip learning engine to enable fast and highly efficient brain simulations. FlexLearn
achieves high flexibility by supporting diverse biologically plausible
sub-rules which can be combined to simulate various target learning rules. To design FlexLearn, we first identify 17 representative
sub-rules which adjust the synaptic weights in different manners.
Then, we design and compact the specialized datapaths for the subrules and identify dependencies between them to maximize parallelism. After that, we present an example flexible brain simulation
processor by integrating the datapaths with the state-of-the-art flexible digital neuron and existing accelerator to support end-to-end
simulations. Our evaluation using a 45-nm cell library shows that
the 128-core brain simulation processor prototype with FlexLearn
greatly improves the harmonic mean per-area performance and
the energy efficiency by 30.07× and 126.87×, respectively, over the
server-class CPU. The prototype also achieves the harmonic mean
per-area speedup of 1.41× over the current state-of-the-art 128-core
accelerator which supports programmable learning rules.
CCS CONCEPTS
• Hardware → Neural systems; Integrated circuits.
KEYWORDS
brain simulations, neuromorphic accelerators, on-chip learning
1 INTRODUCTION
Neuroscientists strive to understand the working mechanism of
a humen brain, the central organ of the human nervous system
consisting of about 86 billion neurons [8]. To study the complex
human brain, neuroscientists heavily rely on simulations which
incorporate the concept of time to their operating models to closely
mimic the temporal behaviors of the human brain. In the simulations, a neuron transmits a signal to other neurons via synapses
when its internal state satisfies certain conditions. The signal affects not only the destination neurons’ internal states but also the
weights of the associated synapses. Such temporal changes in the
weights are called learning (or synaptic plasticity) and are widely
considered as an underlying mechanism of memory [60]. Taking
the temporal aspects into account allows neuroscientists to understand and mimic the mechanisms of the human brain (e.g., object
and speech recognition [15, 90]).
The human brain consists of a variety of highly complex neurons and learning rules. As a result, brain simulations demand fast
and highly flexible hardware capable of simulating the diverse neurons and learning rules. First, the synaptic weights of different
synapses change differently [64]. For example, upon receiving a
signal from the source neurons, some synapses temporarily change
their weights for only a short period of time (lasting up to few
seconds), whereas some other synapses memorize the signal by
making the weight changes permanent. Second, the behaviors of
the neurons may behave differently ever for the same set of input
signals during the same amount of time [45]. The internal state
of a neuron may be stable over time, whereas another neuron’s
state may decay over time and eventually reach the lowest possible
level if no input signals are received. As a result, demystifying the
human brain demands fast and highly flexible hardware capable of
simulating the diverse neurons and learning rules.
To satisfy the flexibility and high performance demands, neuroscientists typically rely on general-purpose processors offering high
304
MICRO-52, October 12–16, 2019, Columbus, OH, USA Baek and Lee et al.
programmability (e.g., CPUs [11, 29, 32, 38], GPUs [21, 41, 66, 101])
or high-performance accelerators [9, 18, 71, 79]. Unfortunately, their
limited performance and flexibility make difficult for neuroscientists to achieve fast and highly efficient brain simulations. On one
hand, CPU-based accelerators (e.g., SpiNNaker [71]) provide high
flexibility to simulate any neurons and learning rules; however, they
suffer from the low performance CPU cores and cannot achieve
high-performance simulations. On the other hand, the accelerators
like Intel’s Loihi [18] achieve high performance by optimizing their
designs for brain simulations. Unfortunately, the accelerators are
inflexible so that they can simulate only a limited set of neurons and
learning rules. A recent study [53] proposes a flexible digital neuron capable of simulating the diverse neuron models; however, it
only supports limited part of the brain simulation (i.e., neuron computation). Therefore, neuroscientists desperately demand a highly
flexible accelerator supporting the diverse neurons and learning
rules.
In this paper, we present FlexLearn, a highly flexible on-chip
learning architecture to support biologically plausible learning rules.
FlexLearn can be seamlessly augmented to existing neuron models
for enabling fast and highly efficient brain simulations. To design
FlexLearn, we first identify 17 representative sub-rules from an extensive analysis of prior neuroscience publications on learning. The
identified sub-rules serve as the primitives of the diverse learning
rules; a learning rule is essentially a combination of the sub-rules.
After classifying the sub-rules into six categories based on their
biological characteristics, we design per-category datapaths which
serve as the basic building blocks of FlexLearn. Next, to reduce the
hardware costs, we compact the datapaths by exploiting the common sub-expressions shared among the sub-rules. To improve the
performance of the datapaths, we identify dependencies between
the categories and maximize parallelism between them. The resulting design, FlexLearn, is capable of simulating the diverse learning
rules through microcodes by selectively activating the necessary
datapaths.
To build an example flexible brain simulation processor using
FlexLearn, we implement a 128-core brain simulation processor by
integrating FlexLearn with Flexon [53], the state-of-the-art flexible
neuron architecture. We synthesize its RTL code using a 45-nm cell
library for area, power, and latency evaluations. To compare our
processor against a convincing baseline, we carefully implement a
baseline 128-core brain simulation processor based on an end-toend industry solution which employs neuron and learning engine,
but with limited flexibility [18]. Our synthesis results show that
our processor design incurs only 6.25% additional area over the
baseline. To evaluate the performance and energy efficiency, we
use three biological neural networks used in real brain simulations
with four different learning rule combinations as our benchmarks.
The results show that our processor improves the harmonic mean
per-area speed and the energy efficiency by 30.07× (40.32 for speed)
and 126.87×, respectively, over the CPU. Compared to the brain
simulation processor baseline, our FlexLearn-based processor improves the per-area speedup and the energy efficiency by 1.41×
(1.50× for speedup) and 1.17×, respectively.
In summary, our work makes the following contributions:
Soma
Axon
Dendrite
Synapse
(a) Biological neural network
i
j
k
wik
wjk
Neuron
Synapse
Synaptic
Weight
wij
(b) Spiking neural network
Figure 1: Biological neurons and synapses, and the abstraction of the neurons and the synapses in SNNs
• Identification of the Target Learning (Sub-)Rules: From
an extensive analysis of neuroscience publications, we identify 17 representative sub-rules which can simulate diverse
learning rules. Our analysis clarifies what FlexLearn should
implement for high flexibility, and can guide future research
on brain simulation.
• FlexLearn Architecture: We present FlexLearn, a highly
flexible and efficient on-chip learning architecture for brain
simulations. FlexLearn is not only highly flexible by supporting the identified learning rules, but also highly efficient by
exploiting the common sub-expressions and dependencies
among the sub-rules.
• Example Brain Simulation Processor: We design an example brain simulation processor by integrating FlexLearn
with Flexon, the state-of-the-art flexible digital neuron to
realize both flexible, fast and highly efficient end-to-end simulations.
2 BACKGROUND
2.1 Organization of the Human Brain
In the human brain, neurons transmit electrochemical signals, called
spikes, over synapses, chemical channels between neurons, to communicate with each other. A neuron consists of three major components: dendrites, a soma, and axons (Figure 1a). Dendrites act as receivers of spikes sent from neighboring neurons through synapses.
The spikes are then relayed to the soma, the body of the neuron. The
soma maintains the neuron’s membrane potential which tracks the
temporal history of the received spikes. When the neuron’s membrane potential reaches threshold voltage, a pre-defined threshold,
the soma fires a spike to other neurons through the axons. During
the process, the membrane potential slowly decays over time and
maintains a steady state if no input spikes are received for a long
period of time.
When a neuron receives a spike through a synapse, the neuron’s
membrane potential changes with respect to the characteristics of
the synapse. Synapses are typically classified into two types: excitatory and inhibitory synapses. Excitatory synapses increase the
membrane potential whereas inhibitory synapses decrease the membrane potential. In addition to the type of a synapse, the amount
of change in the membrane potential depends on the strength of
the synapse, known as synaptic weight. As a result, a neuron’s
305
FlexLearn: Fast and Highly Efficient Brain Simulations Using Flexible On-Chip Learning MICRO-52, October 12–16, 2019, Columbus, OH, USA
t0
vi
t1
vj
spikej
wij
spikei
t0
t1
spikei
spikej
i w j
ij
Pre-Synaptic
Neuron
Post-Synaptic
Neuron
Synaptic
Weight
… …
Figure 2: Example working model of synaptic plasticity.
Spikes from the pre-synaptic (i) and post-synaptic (j) neurons affect the synaptic weight wij .
membrane potential tends to depend more heavily on spikes from
the neurons connected via synapses with higher weights rather
than those from synapses with lower weights. Such spike-triggered
changes in the membrane potential incur the complex behaviors of
the human brain [34].
Learning, also known as synaptic plasticity, is the ability of
synapses to strengthen or weaken over time and is widely believed as an underlying mechanism of memory [43, 58, 60, 74].
The changes in synaptic weights depend on various biological phenomena: spiking activity and membrane voltage of the connected
neurons, synaptic weight value, and even the external stimulus.
Depending on how each learning rule correlates which phenomena,
it mimics different behavior of the brain. Also, various sub-rules
explaining different biological phenomena interact with each other
to form a single learning rule and explain high level functions of
the brain (e.g., memory formation [40, 102]).
2.2 Modeling the Human Brain
As the temporal behaviors of the human brain depend on timing,
Spiking Neural Networks (SNNs) which incorporate the concept of
time to their operating model are highly useful for brain simulations.
An SNN is essentially a directed graph whose nodes are neurons and
edges are synapses (Figure 1b). SNNs model a synapse as an edge
whose source and destination nodes are pre- and post-synaptic
neurons, respectively, and weight is the synaptic weight of the
synapse. When the pre-synaptic neuron fires a spike, the spike
travels to the post-synaptic neurons through synapses after a predefined delay. Upon receiving a spike, the post-synaptic neuron
updates its internal state according to its neuron model and the
synaptic weight of the synapse the spike passed through.
The neuronal dynamics of biological neurons are characterized
by spiking neuron models in SNNs. A neuron maintains a temporal
internal state, and sends and receives spikes to and from other neurons, respectively. Spiking neuron models differ by how they model
the membrane potential of a neuron. For instance, the HodgkinHuxley model [42] expresses a neuron’s membrane potential as a
Resistor-Capacitor circuit (RC circuit), whereas Leaky Integrateand-Fire (LIF) model [86] simplifies the membrane potential as a
single state variable. Despite the differences, spiking neuron models
respect the basic mechanism of firing a spike when the membrane
potential reaches the threshold voltage.
SNNs model synaptic plasticity by updating the weight of a
synapse when the pre- and post-synaptic neurons fire spikes. Figure 2 illustrates an example synaptic plasticity mechanism which
updates the synaptic weight of a synapse when the pre- and postsynaptic neurons fire spikes. In the example, the pre-synaptic neuron i fires a spike as its membrane potential reaches its threshold
voltage at t0. Then, the fired spike goes to the postsynaptic neurons via synapses. When the spike passes the synapse, the synaptic
weight wij decreases (or depresses) depending on the neurons’ internal states. wij also depends on the activity of the post-synaptic
neuron j; the spike from j fired at t1 increments (or facilitates) wij .
2.3 Simulating the Human Brain
As the brain incorporates the concept of time, simulating the brain
involves evaluation of the temporal neuronal and synaptic state
updates during a fixed amount of time. To enable time-driven simulations, brain simulators utilize a pre-defined timestep ∆t which
represents the unit of time (e.g., 1 ms in biological time) of a simulation. After initializing the neuronal and synaptic states (t = 0),
the simulators advance the biological time by one timestep (t = ∆t)
by evaluating the neuronal and synaptic dynamics which occurs
during one timestep. Spikes generated by the neurons during [0, ∆t)
get propagated to their destination neurons after the delay of their
corresponding synapses. In this way, the simulation continues by
advancing the biological time by ∆t (t = ∆t, ∆t ×2, ∆t ×3). The simulation terminates when the biological time reaches a pre-defined
deadline (e.g., 1,000 timesteps).
For simplicity, we divide a timestep into three stages: neuron
computation, synaptic plasticity, and spike propagation.
Neuron Computation: This stage simulates the neuronal dynamics of neurons. As the first step, neurons receive the incoming spikes
from the previous timestep and accumulate the spikes according
to their neuron models. This stage also triggers a neuron to fire a
spike if its membrane potential reaches its threshold voltage. When
the neuron fires a spike, the information on the spike is propagated
to the next stage for synapses to update their weights.
Synaptic Plasticity: In this stage, the synaptic weights of synapses
are updated according to synapses’ learning rules and the information on whether neurons have fired a spike in the current time
range. The updated synaptic weights are then forwarded to the
next stage called spike propagation stage.
Spike Propagation: This stage is responsible for associating synaptic weights to the spikes and forwarding the spikes to their destination neurons. To do so, this stage first collects the spikes generated
by neurons, fetches the synaptic weights of the associated synapses,
and accumulates the synaptic weights of the spikes having the same
destination neuron. The accumulated weights are then forwarded
to the destination neurons after a pre-defined delay.
3 MOTIVATION & DESIGN GOALS
3.1 High Computational Overheads
To examine which of the brain simulation stages contributes the
most to the simulation latency, we profile a representative biological neural network used by Brunel [13], with diverse learning rules.
The Brunel network consists of 5,750 neurons. The neurons are
connected randomly with a 10% probability, resulting in the network having 3,306,250 synapses. Learning rules affect the 2,116,000
synapses; the synaptic weights of the remaining synapses remain
constant. We configure the network to use a timestep of 0.1 ms to
306
MICRO-52, October 12–16, 2019, Columbus, OH, USA Baek and Lee et al.
Neuron Compt. Synaptic Plasticity Spike Prop. Others
0 1 2 3 4 5
HB + FD + AIH
HB + FD
HB
Static
HB + FD + AIH
HB + FD
HB
Static
CPU w/
Flexon CPU
Latency w.r.t real-time
(a) Intel Xeon E5-2650 v4 CPU
0 1 2 3 4 5
HB + FD + AIH
HB + FD
HB
Static
HB + FD + AIH
HB + FD
HB
Static
GPU w/
Flexon GPU
Latency w.r.t real-time
(b) NVIDIA Titan X (Pascal) GPU
Figure 3: Breakdown of the simulation latency of Brunel network on the server-class CPU and GPU with representative
learning rule configurations
run for 1 second of biological time (i.e., 10,000 timesteps). The underlying server-class CPU and GPU are 12-core Intel Xeon E5-2650
v4 CPU [1] and NVIDIA Titan X (Pascal) GPU [2], respectively. We
use NEST [29] simulator for the CPU and GeNN [101] for the GPU.
Figure 3 shows the simulation latency breakdown with different
learning configurations; Others indicates the unclassified functions (e.g., network construction and random input generation).
The profiling results show that the synaptic plasticity stage incurs
the highest latency. The details of the learning configurations are
discussed in Section 4.1. When the learning configuration enables
only one sub-rule (HB), the synaptic plasticity stage contributes
to 51.9% and 75.0% of the total latency on the CPU and the GPU,
respectively. Enabling more sub-rules increases the contribution
of the synaptic plasticity stage to the total latency; the synaptic
plasticity stage incurs 88.9% of the total latency on the GPU when
three sub-rules are enabled (HB+FD+AIH).
We further profile the simulation latency in case the CPU and the
GPU cores offload the neuron computation stage to Flexon [53], the
state-of-the-art digital neuron supporting diverse neuron models.
When the digital neuron is available, the results show that the
synaptic plasticity stage incurs up to 73.0% and 89.6% of the total
latency on the CPU and the GPU, respectively. In addition, the
simulations lead to 5.4× and 4.7× higher latency with respect to
the real-time on the CPU and the GPU, respectively. (i.e., it takes
5.4 and 4.7 seconds to simulate 1 second of biological time). Such
slow simulation speeds are detrimental as various learning rules
operate on large timescales (e.g., hours to days [46, 95, 102]). In
summary, the synaptic plasticity stage is the major performance
bottleneck and should be accelerated to achieve fast and highly
efficient simulations.
Table 1: Summary of representative brain simulation chips
Name Performance Flexibility Brain
Learnings Neurons Simulations
SpiNNaker [71] Low High High ✓
TrueNorth [5] High Low Low ✗
Loihi [18] High Moderate Low ✗
Flexon [53] High None High ✗
FlexLearn (Ours) High High High ✓
3.2 Limitations of the Existing Accelerators
As different learning rules work together to explain various phenomena of the human brain, brain simulation accelerators should
be highly flexible by supporting the diverse learning rules. Unfortunately, we find that the existing accelerators are either slow or
inflexible. Table 1 summarizes the limitations of the representative
accelerators. First, to achieve high flexibility, SpiNNaker [71] is
equipped with low-power CPU cores; however, its performance is
limited by the CPU cores and incurs higher latency than the other
accelerators. Second, IBM’s TrueNorth [5] is a configurable neurosynaptic processor supporting highly efficient neuron computation.
TrueNorth achieves highly efficient neuron computation; however,
it lacks on-chip learning support. There are efforts to implement
on-chip learning on TrueNorth [67] by using its neuron cores to
emulate the learning; however, it incurs high overheads as additional neuron cores and connections are required to emulate the
synaptic behavior. Third, Loihi [18], the state-of-the-art neuromorphic accelerator with on-chip learning support, has limited support
toward diverse neuronal behaviors and various learning rules. It
supports only a limited set of biological phenomena which can be
expressed with a simple sum-of-products formula. For instance, it
cannot simulate STP which greatly enriches a biological neural network’s dynamical behaviors [93], complex spike pairing methods
such as suppression model, and the effect of neurons’ membrane
potential on stabilization. Fourth, Flexon [53] is a flexible digital
neuron capable of simulating the diverse neurons of the human
brain. It achieves high flexibility in terms of neurons; however, it
only supports the neuron computation stage of the brain simulation.
Therefore, a flexible hardware accelerator supporting the diverse
learning rules is a key requirement of brain simulations.
3.3 Design Goals
Motivated by the limited performance and flexibility of the existing
accelerators, we need a new highly flexible and efficient accelerator
achieving the following design goals. First, it should be flexible by
supporting the diverse learning rules of the human brain. Second,
it should achieve high efficiency in simulation speed and energy
efficiency. Third, it should be easily applicable to the existing accelerators to realize the end-to-end brain simulation (e.g., digital
neurons [53, 80]).
4 FLEXLEARN ARCHITECTURE
In this section we present FlexLearn, a flexible and highly efficient
on-chip learning accelerator for brain simulations. We first perform
an extensive analysis of prior neuroscience publications to figure
307
FlexLearn: Fast and Highly Efficient Brain Simulations Using Flexible On-Chip Learning MICRO-52, October 12–16, 2019, Columbus, OH, USA
Table 2: Summary of the representative sub-rules for learning
Biological Role Category Sub-rule
Long-Term
Plasticity (LT)
1. Hebbian (HB)
1.1. Nearest Pair [48]
1.2. All-to-All Pair [28]
1.3. Triplet Pair [70]
1.4. Suppression Pair [25]
1.5. Momentary Voltage [12]
1.6. Average Voltage [17]
2. Weight Dependence
(WD)
2.1. Additive [84]
2.2. Multiplicative [95]
2.3. Sublinear [35]
2.4. Mixed [97]
3. Reward-Based (RB) 3.1. Three-Factor STDP [63]
Short-Term
Plasticity (STP) 4. Fast Dynamics (FD) 4.1. Separate [4]
4.2. Merged [92]
Homeostasis
5. Activity-Dependent
Homeostasis (ADH)
5.1. Spike Dependent [97]
5.2. Voltage Dependent [17]
6. Activity-Independent
Homeostasis (AIH)
6.1. Linear Decay [12]
6.2. Exponential Decay [28]
out various learning rules. With the analysis, we identify 17 representative sub-rules and classify them into six different categories.
Next, we design per-category datapaths and use the datapaths as
the building blocks of FlexLearn (Section 4.1). After designing the
datapaths, we integrate and pipeline the datapaths according to
their dependencies (Section 4.2). Then, we design and present an
example brain simulation processor by integrating FlexLearn with
the state-of-the art flexible digital neuron to to perform end-to-end
brain simulations (Section 4.3).
4.1 Target Learning (Sub-)Rules
To identify the target learning rules of FlexLearn, we perform an
extensive analysis of prior neuroscience publications on the human
brain [4, 12, 17, 25, 28, 35, 48, 63, 70, 84, 92, 95, 97]. The literature
analysis indicates the critical need for supporting three major biological roles of learning (i.e., Long-Term Plasticity, Short-Term
Plasticity, Homeostasis) whose detailed biological characteristics
can be flexibly configured as a combination of sub-rules from the six
categories. (i.e., Hebbian, Weight Dependence, Reward-Based, Fast
Dynamics, Activity-Dependent Homeostasis, Activity-Independent
Homeostasis)
Then, we observe that different learning rules share a set of
common sub-rules from the categories and the flexible integrations
of the sub-rules can implement various high-level functions of the
brain [49]. Thus, implementing the sub-rules would be the most
cost-effective way to implement the wide-spectrum of learning
rules. More importantly, if a new learning rule is to be simulated in
future, it can be effectively done by adding only unique sub-rules
required by the new rule. In this way, the sub-rule implementation continues to enable flexible and efficient learning simulations.
Table 2 summarizes our target learning rules and their sub-rules.
Next, to minimize the sub-rule implementation costs, we design a
set of per-category datapaths. For the purpose, we first indentify five
types of traces which track the temporal history of the biological
phenomena affecting the amount of weight changes in different subrules. After designing the datapaths for the traces, we design the
t
t
t
𝑥(𝑡)
(Reset Trace)
s(t)
𝑥 𝑡
(Basic Trace)
𝐴
𝐴
Figure 4: Changes in traces with respect to spikes
datapaths for how the sub-rules in different categories correlate the
traces. By separating the datapath for the traces and the method for
correlating them, we can reuse the trace datapath for different subrules. The datapaths are then integrated to achieve high flexibility.
When integrating the datapaths, we minimize the hardware costs
by eliminating the redundant sub-datapaths shared among the
datapaths. In this section, we explain the mathematical models of
the sub-rules in detail to show how we design and optimize the
datapaths.
To facilitate mathematical descriptions of the learning rules, let
us consider a synapse which transmits spikes from a pre-synaptic
neuron i and a post-synaptic neuron j and the synapse’s synaptic
weight is wij . Then, assume that we are running a brain simulation
for an interval of ∆t whose current biological time is t. In such a
condition, a learning rule of the synapse can be seen as a function
which produces the synaptic state of the synapse (e.g., the value
of wij) at time t + ∆t by taking as input 1) the synaptic state at
time t, 2) whether the neurons fired a spike during (t,t + ∆t], and
3) the set of learning rules applied to the synapse. Using these
mathematical definitions, we first describe and design datapaths for
the traces that capture the various biological phenomena required
in the 17 sub-rules (Section 4.1.1). Then, we describe how each subrule correlates the trace values to calculate the amount of weight
change in the synapses and design the datapaths implementing
them (Section 4.1.2–4.1.4).
4.1.1 Traces. In the human brain, both the prior and the current
activities of a neuron can incur changes in synaptic weight. To track
the prior activities and the previous values within a single variable,
various learning rules utilize the concept of traces [64]. The most
basic form of a trace, x(t) (x(t) ≥ 0), for a neuron is defined as
x(t) = (1 −
∆t
τ
) · x(t − ∆t) +A·s(t) where s(t) denotes occurence of
a spike at time t and τ denotes the decay constant of the trace value.
If the neuron fires the spike at time t, s(t) = 1; otherwise, s(t) = 0.
Whenever the neuron fires a spike, it updates its trace value x(t)
by a constant A and decays its value over time in the absence of
a spike. Such dynamics of a trace enable accumulation of spiking
activity of the neuron within a single variable.
We find that the learning rules utilize five types of per-neuron
traces: basic, reset, dependent, linear, and voltage traces. The mathematical definitions for the traces are:
x(t) =



(1 −
∆t
τ
) · x(t − ∆t) + A · s(t) basic trace
(1 −
∆t
τ
) · x(t − ∆t) · s(t) + A · s(t) reset trace
(1 −
∆t
τ
) · x(t − ∆t) + e(t − ∆t) · s(t) dependent trace
(a + x(t − ∆t)) · s(t) linear trace
(1 −
∆t
τ
) · x(t − ∆t) +
∆t
τ
· v(t − ∆t) voltage trace
308
MICRO-52, October 12–16, 2019, Columbus, OH, USA Baek and Lee et al.
𝑥(𝑡－∆𝑡) × + 𝑥(𝑡)
1－∆𝑡/𝜏 𝐴
0
spike
1
0
(a) Basic trace
𝑥(𝑡－∆𝑡) ×
𝑥(𝑡) 𝐴
spike 1－∆𝑡/𝜏
1
0
(b) Reset trace
𝑥(𝑡－∆𝑡) × + 𝑥(𝑡)
1－∆𝑡/𝜏
0
spike
𝑦(𝑡－∆𝑡)
0
1
(c) Dependent trace
𝑥(𝑡－∆𝑡) + 𝑥(𝑡)
𝑎
+
spike
0 1
0
(d) Linear trace
𝑥(𝑡－∆𝑡) ×
𝑥(𝑡)
1－∆𝑡/𝜏
𝑣(𝑡－∆𝑡) ×
∆𝑡/𝜏
+
(e) Voltage trace
Figure 5: Datapaths for calculating traces
where the s(t) = 1 in the absence of the spike and s(t) = 0 if the
neuron fires the spike. Also, e in the dependent trace represents an
arbitrary trace (e.g., reset trace) that the trace depends on. Then,
a in the linear trace is a pre-defined constant, and v(t − ∆t) in the
voltage trace is the neuron’s membrane potential at t − ∆t. Figure 4 demonstrates how traces change with respect to the neuron’s
spiking activities. In the example, when a neuron fires a spike, the
basic trace increases by A whereas the reset trace is set to A. In
this way, the basic trace captures all previous spiking history; however, the reset trace tracks only the most recent spiking activity.
Figures 5a–5e show the datapaths implementing the five traces;
spike in the figures denotes whether the neuron fires a spike at
the given timestep.
4.1.2 Long-Term Plasticity. Long-Term Plasticity (LT) is the first
type of the biological roles we consider. Two forms of LT exist: LongTerm Depression (LTD) and Long-Term Potentiation (LTP) which
weaken and strengthen inter-neuron connections, respectively [94].
Due to their long-lasting effects, LTD and LTP are thought to be
highly relevant to memory [72]. The high importance of LT has
attracted significant interests from neuroscientists ever since Hebb’s
postulate [37] was proposed.
Three biological phenomena take part in the LT: the interaction
between the pre- and post- synaptic neurons, the synaptic weight,
and the external stimulus. The sub-rules from the three categories
(i.e., Hebbian (HB), Weight Dependence (WD), Reward-Based (RB))
describe each of the phenomena and are combined to take part in
the LT. LT is modeled as:
w(t) = w(t − ∆t) +
LT P
z }| {
RB(W D+(t) · H B+(t) +
LT D
z }| {
W D−(t) · H B−(t))
(1)
where ∆t denotes the timestep, and w(t) is the synaptic weight
at time t. W D+(t) and W D−(t) represent W D(t) for LTP and LTD,
respectively. The same applies to HB+(+) and HB−(t).
The STDP learning rule, for example, one of the most well-known
methods for explaining the long term plasticity, consists of two
sub-rule categories: HB and WD. Mathematically, the standard form
of STDP is defined as:
w(t) = w(t − ∆t) +
LT P
z }| {
(wmax − w(t − ∆t)) · xi (t) · sj(t)
− w(t − ∆t) · yj(t) · si (t)
| {z }
LT D
where wmax is a pre-defined largest weight value for the synapse
and the term wmax −w(t −∆t) andw(t −∆t) representW D+(t) and
W D−(t). For the HB term, each neuron keeps two seperate traces
x(t) and y(t) for pre-synapse and post-synapse, respectively. In
addition, the synaptic weight decreases (LTD) when the presynpatic
neuron fires (i.e., si(t) = 1), and the synaptic weight increases (LTP)
when the postsynaptic fires (i.e., sj(t) = 1). The x(t) from the
pre-synaptic neuron (i.e., xi(t)) and y(t) from the post-synaptic
neuron (i.e., yj(t)) represent each case when multiplied with spikes
of the post- and pre- synaptic neuron sj(t) and si(t). According to
the definition, various long-term plasticity models have different
1) model for explaining the HB term, 2) function for WD, and
3) existence of the RB term.
Hebbian Term: This category captures the interaction between the
pre- and post- synaptic neurons in terms of their spiking activities
and the membrane voltage of the post-synaptic neuron. Six different
sub-rules fall into this category: nearest pair, all-to-all pair, triplet
pair, suppression pair, momentary voltage, and average voltage.
When updating the synaptic weight, the first four models consider
various spike pairs between the pre- and post- neurons by utilizing
different traces. On the other hand, the last two sub-rules account
for the pre-synaptic neuron’s activities and the membrane voltage
of the post-synaptic neuron when changing the synaptic weight.
First, the nearest-neighbor pair model considers only the two
latest spikes, one from the pre-synaptic neuron and the other from
the post-synaptic neuron, using the reset trace. Second, the all-to-all
pair model utilizes the basic trace to make a pre-synaptic spike and
a post-synaptic spike interact with all prior post-synaptic spikes
and all prior pre-synaptic spikes, respectively. The two sub-rules
use the HB term defined as:
H B+(t) = xi (t) · sj(t), H B−(t) = yj(t) · si (t) (2)
The two aforementioned sub-rules only pair a single post-synaptic
spike with a single pre-synaptic spike. However, such single-spike
pairs cannot describe the frequency effects on synaptic weight updates [70], requiring additional traces. To do so, the triplet and
suppression sub-rules use:
H B+(t) = xi1(t) · yj2(t) · sj(t)
H B−(t) = yj1(t) · xi2(t) · si (t)
where xi1(t) and yj1(t) correspond to xi(t) and yj(t) in Equation 2,
and xi2(t) and yj2(t) are newly adopted traces to explain the effect
of multiple spike pairs (e.g., pre-post-pre). Specifically, triplet subrule employs the basic traces as the two new traces:
xi1(t) = (1 − ∆t /τx1) · xi1(t − ∆t) + si (t)
xi2(t) = (1 − ∆t /τx2) · xi2(t − ∆t) + si (t)
where τx1 and τx2 denote the decay constants for the traces and
yj1(t) and yj2(t) follow the same equation. On the other hand,
suppression sub-rule defines xi1(t) and yj1(t) as the dependency
309
FlexLearn: Fast and Highly Efficient Brain Simulations Using Flexible On-Chip Learning MICRO-52, October 12–16, 2019, Columbus, OH, USA
𝑣(𝑡)
𝜃𝑢𝑝
𝑙 𝜃𝑑𝑛
𝑙 𝜃𝑢𝑝
ℎ 𝜃𝑑𝑛
ℎ
𝐶𝑎(𝑡)
>
<
𝑎
0
𝜃𝑣 >
𝐻𝐵(𝑡)
10
11
0x
1 0 1 0 −𝑏
(a) Momentary voltage
hb[2]
-
𝑦(𝑡－∆𝑡)
𝑥(𝑡)
𝑊𝐷(𝑡)
𝑣ҧ(𝑡)
1
- ReLU
×
-
𝜃+
𝑣(𝑡) ReLU
1
𝜃 𝐻𝐵(𝑡) −
1 Π
Fig. 6a
1
hb[0]
01
00
1x
1
0
1
0 0
1
1
0
hb[2],hb[1]
hb == 100(2)
(b) HB
×
𝑥
𝑦
𝑤(𝑡－∆𝑡)
1/𝑤𝑚𝑎𝑥
𝜇
W𝐷(𝑡)
-
1
0
×
𝜆𝛼𝑤𝑚𝑎𝑥
is_hbp
1
0
(c) WD
𝐷
−(𝑡)
𝐷(𝑡𝑜𝑙𝑑)
1/𝜏
× -
𝑒
𝑥
×
× -
𝑅𝐵(𝑡)
× + 𝐶(𝑡)
𝐻𝐵(𝑡)
𝑡
𝑡𝑜𝑙𝑑
𝐶(𝑡𝑜𝑙𝑑)
1
0
rb
(d) RB
Figure 6: Datapaths for long-term plasticity
traces and xi2(t) and yj2(t) as the reset traces, resulting in:
xi1(t) = (1 − ∆t /τx1) · xi1(t − ∆t) + si (t) · xi2(t − ∆t)
xi2(t) = (1 − ∆t /τx2) · xi2(t − ∆t) · si (t) + si (t)
as the dynamics of the traces.
Until now, we discussed the HB term whose synaptic weight
updates depend on spike pairings and the current synaptic weights.
However, prior neuroscience publications report that the updates
can also depend on the membrane voltage of post-synaptic neurons [12, 17]. Two sub-rules model this phenomenon in different
manner: momentary voltage [12] and average voltage [17].
The momentary voltage model determines the direction of the
synaptic weight according to the instant voltage (v(t)) of the postsynaptic neuron. It introduces an additional basic trace (called calcium trace) Caj(t) to determine if a synaptic weight update should
be performed or not. The model is defined as:
Caj(t) = (1 − ∆t /τ ) · Caj(t − ∆t) + Jc · sj(t)
H B+(t) = a · si (t) if v(t) > θv and θ
l
up < Caj(t) < θ
h
up
H B−(t) = b · si (t) if v(t) ≤ θv and θ
l
dn < Caj(t) < θ
h
dn
where Jc is a pre-defined constant, θ
{l,h }
{up,dn}
define the upper and
the lower bounds of facilitation and depression, the a, and b is a predefined constant determining the amount of weight change when
the condition is met. Figure 6a shows the datapath implementing the
momentary voltage model; hb in the figure denotes the microcode
in Table 3.
Second, the average voltage model adopts different form of voltage; the low pass filtered voltage determines the amount of synaptic
weight updates. The mathematical definition of the average voltage
model introduces a voltage trace v±(t) and is defined as:
xi (t) = (1 − ∆t /τx ) · xi (t − ∆t) + si (t)
v−(t) = (1 − ∆t /τ−) · v−(t − ∆t) + ∆t /τ− · v(t − ∆t)
v+(t) = (1 − ∆t /τ+) · v+(t − ∆t) + ∆t /τ+ · v(t − ∆t)
H B+(t) = xi (t) · ReLU (v+(t) − θ−) · ReLU (v(t) − θ+) · sj(t)
H B−(t) = ReLU (v−(t) − θ−) · si (t)
where xi(t) defines a basic trace and ReLU (x) = max(0, x). Also,
θ+ and θ− define the lower bounds for voltage and voltage trace,
respectively, and τ± are pre-defined decay constants.
We reduce the hardware cost by making the datapaths share
circuit for the common sub-datapaths. Figure 6b shows the integrated datapath for the HB term. The red line and the blue line
in the figure represent the datapath for the triplet pair model and
the average voltage model respectively. Also, the green line in the
figure represents the common sub-expression shared among the
two sub-rules. As shown in the figure, we reduce the integrated
datapath by making the different sub-rules share the same circuit
for the common sub-expression.
Weight Dependence: As discussed in Equation 1, the amount
of synaptic weight changes due to LT depends on the definition
of W D±(t). Weight dependence, the synaptic weight updates depending on the current synaptic weight, can lead to stability and
biologically plausible distribution of synaptic weights [30]. From
prior neuroscience publications, we find that four biologically plausible definitions for W D±(t) exist: additive [84], multiplicative [95],
sublinear [35], and mixed [97] models. The mathematical definition
is:
W D±(t) =



λ, −λα additive
λwmax (1 −
w
wmax
), −λαw multiplicative
λwmax (1 −
w
wmax
)
µ
, −λαwmax (
w
wmax
)
µ
sublinear
cp , −cdw mixed
where the left and right formula indicates W D+ and W D−, respectively. λ denotes a learning rate, α is the ratio of LTP and LTD,
µ is a constant, and cp and cd
represent the average amounts of
potentiation and relative depression, respectively, after one spike
pairing. Among the models, additive model has no dependency
on the current synaptic weight and imposes hard boundaries on
synaptic weights. Figure 6c shows the datapath implementing the
four W D±(t) models; is_hbp in the figure denotes whether the
datapath is used for ltp or for ltd. Instead of using multiplexers with
microcodes to support various types of sub-rules, we select specific
parameters to emulate different sub-rules based on the micrcocode
(e.g., µ = 1 for multiplcative sub-rule).
Reward-Based STDP: The aforementioned sub-rules implement
unsupervised learning; however, reinforcement learning can be
described in a biologically plausible description [47]. Additional
traces for the external stimulus track the rewards for eligible actions.
To augment the concept of reward to the learning rules, threefactor STDP model [47], an implementation of reward-based STDP,
introduces two additional traces: dopamine (Di
) and eligibility
(Cij) traces represent low pass filtered version of the dopaminergic
spikes and HB term outcomes (HB±(t)). Mathematically, threefactor STDP is defined as:
C
−
i j(t) = e
(t−told )/τc
· Ci j(told )
Ci j(t) = C
−
i j(t) + W D±(t) · H B±(t) · si,j(t)
D
−
j
(t) = (1 − ∆t /τd ) · Dj(t − ∆t), Dj(t) = D
−
j
(t) + sd (t)
RB(t) = (C
−
i j(t) · D
−
j
(t) − Ci j(told ) · Dj(told )) · si,j,d (t)
told = t · si,j,d (t) + told · si,j,d (t)
where the sd
(t) is the incoming dopaminergic spikes and told is the
latest spiking time of the pre-synaptic-, post-synaptic- or dopaminergic spikes. Figure 6d illustrates the datapath for three-factor STDP;
rb in the figure denotes the microcode in Table 3.
310
MICRO-52, October 12–16, 2019, Columbus, OH, USA Baek and Lee et al.
𝑥(𝑡－∆𝑡)
×
+
𝑥(𝑡)
× 𝚺
𝑢(𝑡－∆𝑡) 1
𝑢𝑒(𝑡)
1− 𝑈
Π + 𝑢(𝑡)
Π
𝑤(𝑡)
𝑥𝑒 𝐹𝐷(𝑡) (𝑡)
𝑈
−1
0
1 1
!fd[0]
Figure 7: Datapath for short-term plasticity
𝑅𝐵(𝑡)
ℎ(𝑡)
𝑠𝑐𝑎𝑙𝑒
×
× × + 𝐴𝐷𝐻(𝑡)
𝑤(𝑡－∆𝑡)
𝛽𝑎(𝑡) -
𝛽𝑎𝑔𝑜𝑎𝑙 adh[0]
adh[0]
0
1
1
0
(a) ADH
𝛾𝑡
𝑤(𝑡－∆𝑡)
𝑡－𝑡 ×
𝑜𝑙𝑑
𝜃𝑤 >
aih[0]
−𝛽
aih[0]
𝐴𝐼𝐻(𝑡)
+
min
max
𝑤𝑚𝑖𝑛 𝛼
𝛾0 𝑤𝑚𝑎𝑥 1
0
1
0 0
1
0
1
(b) AIH
Figure 8: Datapaths for homeostasis
4.1.3 Short-Term Plasticity. Along with the LT, an inherent dynamics lasting 100 ms to about a second exists in biological synapses [33,
59]. The short-lasting dynamics is called Short-Term Plasticity (STP).
STP has been shown to encode temporal information in biological neural networks by changing the effective synaptic weights
according to inter-spike intervals [26]. From a computational point
of view, it is plausible that STP may be an underlying mechanism
of a number of processes which occur in daily life (e.g., speech
recognition) [93].
Fast Dynamics: The Fast Dynamics (FD) category is resposible for
exaplaining the STP: separate [4] and merged [92] model. First, the
separate model is defined as:
P(t) =
(P0 + (τP − 1) · P(t − ∆t))
τP
+ f · (1 − P(t − ∆t)) · si (t)
F D(t) = P(t) · w(t)
where P0, f , and τp is a constant and P(t) is a state variable tracking
the spiking activities of the pre-synaptic neuron. Also, the result
of FD(t) denotes the effective synaptic weight, which lasts only
temporally, at time t. Although the model is simple and easy to
implement, it can model only either the facilitating or the depressing
effect caused by a sequence of spikes; the two effects cannot be
taken into account concurrently.
Merged model avoids the limitation by employing two state
variables (i.e., x(t) and u(t)) rather than one:
xe(t) = (1 − ∆t /τr ec ) · xe(t − ∆t) · si (t) + si (t)
ue(t) = (1 − ∆t /τf ac ) · ue(t − ∆t) · si (t) + si (t)
x(t) = 1 + (x(t − ∆t)
Û
(1 − u(t − ∆t)) − 1) · xe(t − ∆t)
u(t) = U + u(t − ∆t) · (1 − U ) · ue(t − ∆t)
F D(t) = x(t) · u(t) · w(t) · si (t)
where xe(t) and ue(t) denotes the temporal distance between the
two latest pre-synaptic spikes with reset traces with pre-defined
decay constant τ {f ac,r ec }
. The state variables, x(t) andu(t) account
for the depressing and the facilitating effects, respectively, of a
series of spikes, and the two state variables are updated only when
si(t) = 1. The variables are affected only when the pre-synaptic
spike occurs. For instance, if the frequency of the pre-synaptic
spikes increases, the value of x(t) decreases and reduces the effective
weight. The datapath implementing the two STP models is shown
in Figure 7; fd in the figure denotes the microcode in Table 3.
4.1.4 Homeostasis. The last type of biological role synaptic plasticity affects is the Homeostasis; the ability of biological neural
networks to modulate the activity of synapses [89, 96]. Homeostasis counter-balances the synaptic weight changes by LT in a way
the synaptic weight distribution of an SNN does not deviate from
a stable form. Depending on whether the activity of the neuron is
relevant to the synaptic change, sub-rules are classified into two
different categories: Activity-Dependent Homeostasis (ADH) and
Activity-Independent Homeostasis (AIH) term. The general model
for explaining the effect of homeostasis is as follows:
w(t) = ADH(t) + AI H(t)
where the ADH(t) and AIH(t) represent AIH term and ADH term
respectively.
Activity-Dependent Homeostasis: Two sub-rules fall into this
category: spike dependent [97] and voltage dependent [17] models. Spike dependent model changes the direction and the amount
of synaptic weight update depending on the activity of the postsynaptic neuron. The model is defined as:
a(t) = (1 − ∆t /τ ) · a(t − ∆t) + sj(t) · ∆t /τ
ADH(t) = β · w(t − ∆t) · (aдoal − a(t))
where a(t) is a basic trace to reflect the spiking activity. The β is a
scaling constant reflecting the amount of weight changes induced
by the sub-rule, and aдoal is a constant reflecting the desired value
of the a(t) value.
The other model, voltage dependent model, depresses the amount
of synaptic weight updates by LT as follows:
h(t) = (1 − ∆t /τ ) · h(t − ∆t) + ∆t /τ · v(t − ∆t) + si (t)
ADH(t) =
h(t)
2
scale · RB(t)
where h(t) is a slight variation of the voltage trace, the average of
the membrane potential and spiking activity of the post-synaptic
neuron over a long timescale. Also, scale is a scaling constant to
reflect the amount of weight changes.
Activity-Independent Homeostasis: The two sub-rules in this
category, linear decay [12] and exponential decay [28] models, do
not take neuronal activity into account. First, linear decay model is
defined as:
AI H(t) =
(
w(t − ∆t) + α(t − told ) · si,j(t) if w(t − ∆t) > θw
w(t − ∆t) − β(t − told ) · si,j(t) if w(t − ∆t) < θw
told = t · si,j + told · si,j
where α and β is a constant determining the amount of weight
change by the sub-rule, and told refers to the latest spiking time
of the pre-synaptic- and post-synaptic neuron. Depending on the
current synaptic weight, the synaptic weight can saturate to extreme values. This model can stabilize synaptic weights against
spontaneous activity. Second, exponential decay model emulates
exponential decays by employing a decay constant γ0 as follows:
AI H(t) = γ0 · w(t − ∆t)
By doing so, the model can be used as a depression mechanism in the
absence of other depression mechanisms [28]. Figure 8 shows the
311
FlexLearn: Fast and Highly Efficient Brain Simulations Using Flexible On-Chip Learning MICRO-52, October 12–16, 2019, Columbus, OH, USA
Trace Datapaths (Fig. 5)
Traces
FD−1
Variables State Variables
@ time t
Trace
Update
Synaptic
Weight
Update
State Variables
@ time (t + ∆𝑡)
Traces Variables
Weight Update Outputs
AIH
𝑤(𝑡 − ∆𝑡) 𝑡 − 𝑡𝑜𝑙𝑑
WD
Weight Update Inputs
HB-1
ADH-1 ADH-2 HB-2
+
RB-1
RB-2
+
ADH-3
FD-2
ℎ(𝑡)
𝑥 𝑡 ,𝑦
− 𝑡 , 𝑣ҧ𝑡 ,
𝐷(𝑡), 𝐶𝑎(𝑡)
𝐶 𝑡𝑜𝑙𝑑 ,𝑡,𝑡𝑜𝑙𝑑
𝐷(𝑡),𝐷(𝑡𝑜𝑙𝑑)
𝛽𝑎(𝑡)
𝑤(𝑡)
𝐶(𝑡)
𝑢(𝑡), 𝑥(𝑡)
𝑣(𝑡)
RB 𝐶(𝑡𝑜𝑙𝑑)
-3
Figure 9: Datapath Integration in FlexLearn Architecture
Table 3: Microcodes to configure the datapaths
Signal Description Values
hbp[2:0]
/
hbd[2:0]
Select the model in
Hebbian category
for LTP/LTD
0: Nearest Pair
1: All-to-All Pair
2: Triplet Pair
3: Suppression Pair
4: Momentary Voltage
5: Average Voltage
6: Disable
wd[2:0]
Select the model in
Weight Dependence
category
0: Additive
1: Multiplicative
2: Sublinear
3: Mixed
4. Disable
rb Enable or disable
Reward-Based category
0: Enable
1: Disable
fd[1:0] Select the model in
Fast Dynamics category
0: Separate
1: Merged
2: Disable
adh[1:0]
Select the model in
Activity-Dependent
Homeostasis category
0: Spike Dependent
1: Voltage Dependent
2: Disable
aih[1:0]
Select the model in
Activity-InDependent
Homeostasis category
0: Linear Decay
1: Exponential decay
2: Disable
datapaths implementing these homeostatic plasticity mechanisms;
adh and aih in the figure denotes the microcode in Table 3.
4.2 Efficient Integration of the Datapaths
We now present FlexLearn architecture, a flexible and highly efficient on-chip learning accelerator supporting the diverse learning
rules. FlexLearn integrates the per-category datapaths to achieve
Core
Flexon
Neuron Memory Synapse Memory
Interconnection Controller
Neuron Datapaths
μ-code Decoder
Spikes from
Other Cores
Spikes to
Other Cores
Core Output Spikes
R R
R R
Syn
Buf
Neu
Core
Syn
Buf
Neu
Core
Syn
Buf
Neu
Core
Syn
Buf
Neu
Input Spikes
Spike Buffer
FlexLearn
Pre-Trace Engine
Trace Datapaths
μ-code Decoder
Plasticity Engine
Plasticity Datapaths
μ-code Decoder
Post-Trace Engine
Trace Datapaths
μ-code Decoder
Core
R R
R R
Syn
Buf
Neu
Core
Syn
Buf
Neu
Core
Syn
Buf
Neu
Core
Syn
Buf
Neu
Figure 10: Example flexible brain simulation processor with
FlexLearn
high flexibility. Figure 9 shows how FlexLearn integrates the datapaths. Given the current neuronal state (e.g., membrane voltage,
neuron trace) and synaptic state (e.g., synaptic weight) variables at
time t, the integrated datapath produces the updated state variables
(e.g., neuron trace, synatpic weight) for the next timestep t + ∆t
according to the specified learning rules.
Aimed at achieving higher performance, FlexLearn splits the
datapaths into smaller sub-datapaths. For example, the ADT datapath is split into three sub-datapaths ADT-{1,2,3}. By doing so,
FlexLearn can implement an 8-stage pipeline to improve throughput. Furthermore, employing the sub-datapaths allows data-parallel
sub-datapaths to run in parallel. As an example, when sub-rules
RB and HB are enabled, sub-datapaths RB-1 and HB-1 can run in
parallel. Lastly, we identify some sub-rules that update weights
for the synapses only when any of the connected neurons to the
synapses fire spikes (e.g., HB). To improve efficiency, we perform
weight update only for the syanpses connected to neurons that fire
spikes for such sub-rules.
As the datapaths should be enabled only when the target learning
rule demands them, FlexLearn provides 16-bit microcodes to selectively activate the datapaths (Table 3). Using the datapaths, brain
simulators can program FlexLearn to simulate their target learning rules. The microcodes instruct which of the datapaths should
be activated; the input to the multiplexers within FlexLearn is determined by parsing the given microcodes. One 16-bit microcode
corresponds to a learning rule for a synapse. By assigning different
microcodes to synapses, FlexLearn facilitates highly flexible brain
simulations involving diverse learning rules.
4.3 End-to-End Brain Simulation Processor
The datapaths of FlexLearn provide highly flexible learning; however, end-to-end brain simulations demand high flexibility in both
learning and neurons. To enable the end-to-end simulations, we
design and present an example brain simulation processor by integrating FlexLearn archiecture on top of the scalable architecture
similar to Loihi [18]. Loihi is the state-of-the-art brain simulation
hardware which supports up to 128 neuromorphic cores per chip
and a scalable asynchronous Network-on-Chip (NoC) for up to
312
MICRO-52, October 12–16, 2019, Columbus, OH, USA Baek and Lee et al.
FlexLearn
PlasticityEngine
Interconnection Controller
Core
Interconnection Controller
❶
❺
Synapse Memory Neuron Memory
❸ ❷
❹
Core
Synapse Memory Neuron Memory
Post-Trace
Engine
Pre-Trace
Engine
FlexLearn
Plasticity Engine
❷
❸
Post-Trace
Engine
Pre-Trace
Engine
Flexon Spike Buffers Flexon Spike Buffers
Figure 11: Working model of our example processor
16,348 chips. Despite the advantages in scalability, Loihi has limited support for both the learning rules and the neurons of the
human brain; Loihi supports only 11 out of our target 17 sub-rules,
and CUBA-variant neurons. To achieve high flexibility in neurons,
our accelerator employs Flexon [53]. Flexon is the state-of-the-art
digital neuron supporting the diverse neuron behaviors within
the human brain; however, it only supports the neuron computation stage of the brain simulation. By integrating the datapaths
with Flexon, our processor achieves highly flexible learning (using
FlexLearn) and neurons (using Flexon) at the same time.
Figure 10 illustrates the architecture of our processor. The cores
of the accelerator simulate on-chip learning and neuron computation, and are interconnected using the 2D mesh interconnection
network of Loihi. Each core consists of the datapaths of FlexLearn
and Flexon, spike buffers storing incoming spikes toward the core’s
neurons, an interconnection controller, and neuron and synapse
memory. The datapaths of FlexLearn and Flexon simulate on-chip
learning and neurons, respectively. Each core can process up to
35 neurons and 28,000 synapses using a 0.23-MB per-core SRAM
which serves as the neuron and the synapse memory. When a neuron of a source core fires a spike to a neuron of another destination
core, the spike goes through the interconnection network to the
destination core.
Figure 11 illustrates the working model of our processor. The
processor simulates a timestep of a brain simulation as follows.
First, Flexon retrieves input spikes from the spike buffers (❶), and
then updates the target neuron’s internal state using the datapaths
of Flexon. The information on whether the target neuron fires a
spike gets propagated to the post-trace engine, and also to the destination neurons (possibly on other cores) if the neuron fires a spike
(❷). After updating the neuron’s post-trace, a variable tracking the
activities of the post-synaptic neuron, the plasticity engine receives
the trace values and performs synaptic weight updates according to
the synapse’s learning rules (❸). When the target neuron is on another core, a notification of the spike is sent to the destination core
through the interconnection network. Then, the destination core’s
pre-trace engine receives the notification as the spike is generated
by the source/pre-synaptic neuron (❸ on the destination core). The
pre-trace engine then updates the pre-trace value of the destination
neuron and, applies the learning rules of the synapse, and the spike
information is stored to the spike buffers of the destination core to
trigger (❹–❺ on the destination core). By doing so, the destination
Table 4: RTL synthesis results of Loihi accelerator and
FlexLearn
Accelerator Component Area [mm2
] Power [mW]
128-Core Loihi
Neuron 0.4 35.3
Learning 5.3 542.2
SRAM 380.7 10360.2
Total 386.4 10937.7
128-Core FlexLearn
Neuron 2.1 396.0
Learning 27.7 3224.9
SRAM 380.7 10360.2
Total 410.5 13981.1
Table 5: Evaluated biological neural networks
Name Neurons Synapses Compatibility
CPU GPU TrueNorth Loihi FlexLearn
Brunel
[13]
5,750
CUB
Static: 1,190,250
Plastic: 2,116,000 ✓ ✓ ✗ ✓ ✓
Vogels
[98]
10,000
COBE
Static: 1,680,000
Plastic: 320,000 ✓ ✓ ✗ ✗ ✓
Izhikevich
[44]
1,000
Izhi.
Static: 360,000
Plastic: 640,000 ✓ ✓ ✗ ✗ ✓
core initiates neuron computation of the destination neuron. In this
way, our processor achieves not only highly flexible and efficient
brain simulations, but also high scalability using the inter-core
communication.
5 EVALUATION
5.1 Experimental Setup
To evaluate FlexLearn, we compare a 128-core brain simulation
processor using FlexLearn against server-class CPU, GPU, and 128-
core Loihi-style baseline processor. In this section, for brevity, we
use the terms FlexLearn and Loihi to indicate the brain simulation
processor using FlexLearn with Flexon and Loihi-style learning and
neuron engine, respectively. 12-core Intel Xeon E5-2650 v4 CPU [1]
and NVIDIA Titan X (Pascal) GPU [2] serve as the CPU and the
GPU. The number of cores for the accelerators is chosen to be
equal to that of Loihi [18]. The performance numbers for CPU and
GPU were obtained from NEST [29] and GeNN [101] simulators,
respectively. To measure the energy efficiency of the CPU and
the GPU, we use Intel Performance Counter Monitor [100] and
nvprof [3]. For Loihi accelerator and FlexLearn, we write RegisterTransfer Level (RTL) code in Verilog, and synthesize the code using
45-nm NanGate FreePDK45 library [88]. The Static Random Access
Memory (SRAM) costs are measured using CACTI 6.5 [65]. The
synthesis result indicates that both accelerators operates in 250
MHz. Table 4 shows the synthesis results. Our FlexLearn accelerator
greatly improves the flexibility over Loihi with only 6.3% chip area
and 27.8% power overheads.
We use the biological neural networks used by Brunel [13], Vogels et al. [98], and Izhikevich [44] as the benchmarks. Table 5
summarizes their characteristics. Along with the biological neural
networks, we utilize eight representative learning rule combinations (Table 6). The combinations are applied to the plastic synapses.
313
FlexLearn: Fast and Highly Efficient Brain Simulations Using Flexible On-Chip Learning MICRO-52, October 12–16, 2019, Columbus, OH, USA
Table 6: Evaluated learning rule configurations
Type Learning Rules Compatibility
CPU GPU TrueNorth Loihi FlexLearn
A
1.5. Mementary
2.1. Additive ✓ ✓ ✗ ✓ ✓
6.1. Linear Decay
B
1.3. Triplet
2.2. Multiplicative ✓ ✓ ✗ ✓ ✓
6.2. Exponential
C
1.4. Suppression ✓ ✓ ✗ ✗ ✓ 2.2. Multiplicative
D
1.2. All-to-All
2.2. Multiplicative ✓ ✓ ✗ ✗ ✓
4.1. Separate
Note that the underlying hardware may not support some configurations due to its inflexibility. For example, TrueNorth lacks support
for all of the evaluated learning rule combinations, and Vogels and
Izhikevich are not supported by Loihi due to its inflexibility in
neuron model. On the other hand, FlexLearn is highly flexible and
supports all of the configurations.
5.2 Flexible & Efficient Brain Simulations
In this experiment, we evaluate the brain simulation efficiency of
our FlexLearn processor against the server-class CPU and GPU,
and Loihi. We employ two performance metrics for the evaluation:
simulation speed and energy consumption. For the comparison,
we measure the latency and the energy consumption of the hardware when simulating the benchmarks for 10,000 timesteps. 10,000-
timestep simulations emulate 1 s of biological time for Brunel whose
timestep is 0.1 ms, and 10 s for Vogels and Izhikevich network as
their timesteps are 1 ms.
Our results clearly indicate that FlexLearn significantly improves
the brain simulation speed and energy efficiency. First, Figure 12
shows the speedups of our FlexLearn processor over the CPU and
the Flexon-augmented CPU. FlexLearn achieves the harmonic mean
speedups of 40.32× over the CPU, and 27.44× over the Flexonaugmented CPU. As Flexon targets only the neuron computation,
the Flexon-augmented CPU fails to mitigate the high performance
overheads of the learning rules. On the other hand, our FlexLearn
processor greatly improves the performance by providing highly
flexible learning rule support.
Second, Figure 13 shows the per-area performance improvements and the energy efficiency improvements of our FlexLearn
processor over the other platforms. FlexLearn achieves harmonic
mean performance improvement per area of 30.07× and 37.12×
over the CPU and the GPU, respectively. In terms of the energy
efficiency, FlexLearn achieves the harmonic mean improvements
of 126.87× and 262.16× over the CPU and the GPU, respectively.
Moreover, FlexLearn outperforms Loihi despite improved flexibility by efficiently integrating the datapaths to minimize the hardware
costs. Compared to Loihi, FlexLearn improves the performance per
area and the energy efficiency by 1.41× and 1.17×, respectively, in
harmonic means. Note that the CPU outperforms the GPU as the
brain simulations do not have enough parallelism to fully utilize
CPU Flexon-augmented CPU FlexLearn
0.1
1
10
100
A B C D A B C D A B C D
Brunel Vogels Izhikevich
Speedup
Figure 12: Speedup of FlexLearn over the CPU
CPU GPU Loihi FlexLearn
0.1
1
10
100
A B C D A B C D A B C D
Brunel Vogels Izhikevich
Performance / Area
(a) Per-area performance improvements over the CPU
0.1
1
10
100
1000
A B C D A B C D A B C D
Brunel Vogels Izhikevich
Energy Efficiency
(b) Energy efficiency improvements over the GPU
Figure 13: Improvements in the brain simulation efficiency
of FlexLearn over the CPU, GPU, and Loihi. The dotted lines
of Loihi indicate the simulations not supported by Loihi.
the GPU. Our analysis shows that the small synapse counts per
neuron are the primary reason for the underutilization.
Our experimental results also indicate the high flexibility of
FlexLearn over Loihi. In Figure 13, we observe that Loihi supports
only two simulations. On the other hand, FlexLearn supports all of
the simulations by implementing the 17 sub-rules; Loihi supports
only 11 of the 17 sub-rules. Furthermore, by integrating Flexon
with FlexLearn, our FlexLearn processor supports various neuron
models as well.
5.3 Low Hardware Costs
Aimed at minimizing the hardware costs, our FlexLearn datapath
exploits the common sub-expressions between the sub-rules of the
same category. We further reduce the datapath by integrating the
datapath for LTP and LTD. To evaluate the efficiency of the integration, we compare the hardware costs of FlexLearn’s integrated
datapath to a naïve integration of the datapaths. The naïve integration simply places all of the datapaths and activates one of the
datapaths at a time with respect to a given input. Figure 14 compares the chip area and the power consumption of each datapaths,
the naïve integration, and FlexLearn’s integrated datapath. The
results show that FlexLearn demands 27.8% smaller chip area and
314
MICRO-52, October 12–16, 2019, Columbus, OH, USA Baek and Lee et al.
0
1
2
3
4
5
0.00
0.01
0.02
0.03
0.04
0.05
HB WD RB FD ADH AIH FlexLearn
Power [mW]
Area [mm2]
Area Power
Naïve
Integration
Figure 14: Chip area and power consumption of the per-rule
datapaths and FlexLearn
consumes 40.8% less power than the naïve integration. By exploiting the characteristics of the learning rules, FlexLearn effectively
reduces the hardware costs.
6 RELATED WORK
Brain Simulators and Accelerators: The properties of brain simulations can greatly differ in topology (e.g., numbers of neurons and
synapses), neuronal behaviors (i.e., neuron models), and synapse
properties (i.e., synaptic plasticity). To support a variety of brain
simulations, general-purpose processors including CPUs and GPUs
have been a favorable choice. Examples of CPU-based simulators
include NEURON [38], GENESIS [11], NEST [29], Brian [32, 87], and
Auryn [103]. GPU-based simulators (e.g., CARLsim [66], NeMo [21],
NCS6 [41], GeNN [101]) provide faster simulation speeds by exploiting the parallelism inherent in neuronal dynamics. To improve
simulation speeds, the simulators often utilize multiple machines
to simulate large-scale biological neural networks. For instance, a
simulation of 900 million neurons and 9 trillion synapses has been
demonstrated by running C2 [7], a CPU-based cortical simulator
developed by IBM Research, on top of 147,465 CPUs [6].
To improve the simulation speeds, some prior studies propose
to employ FPGAs [16, 69, 85, 99]. Although FPGAs offer lower
programmability than general-purpose processors do, FPGAs can
be re-programmed to achieve high flexibility; users can re-program
an FPGA-based accelerator to implement additional learning rules
and neurons. NeuroFlow [16] and SNAVA [85] are example FPGAbased brain simulation accelerators. Unfortunately, the FPGA-based
accelerators are limited by the amount of resources available on
a target FPGA board. They also achieve lower performance than
custom accelerators implementing the same functionalities [52].
Aimed at improving the simulation efficiency, custom-designed
accelerators (e.g., TrueNorth [5, 62, 76], ROLLS [75], Loihi [18],
ODIN [22–24]) employ digital circuits implementing the learning rules and the neurons of the human brain. These accelerators
achieve fast simulation speeds and higher energy efficiency over
general-purpose processors and FPGAs. For instance, Loihi [18]
implements a limited set of learning rules which can be defined in a
sum-of-products form taking as input spike counts and per-neuron
traces. Some prior studies, aimed at achieving even higher energy efficiency, propose to employ analog circuits. Example analogbased accelerators include Neurogrid [9] and FACETS/BrainScaleS
project [77–79].
Despite the high efficiency, the existing accelerators are inflexible; they support only a limited set of learning rules and neurons. To achieve high flexibility, SpiNNaker [27, 68, 71] couples
custom-designed memory and communication architectures with
low-power ARM968 CPUs which simulate neuronal and synaptic
dynamics. However, as the low-power CPUs simulate the learning
rules and the neurons, SpiNNaker suffers from the low performance
of the CPUs.
We focus on the learning rules of the human brain in this work;
however, acceleration of the neurons is also an important topic as
neuronal state updates always occur at each timestep. Examples
of digital neurons, the custom-designed circuits specializing in
simulating neurons, include the work by Smith [80] and Flexon [53].
Aimed at implementing a complete brain simulation accelerator,
we demonstrated a Flexon-integrated FlexLearn prototype.
Brain Simulation Infrastructures: Brain simulations using the
underlying hardware require software front-ends interfacing with
the hardware. A typical workflow of a brain simulation is as follows.
First, researchers specify the properties of their target biological
neural networks (e.g., topology) using a hardware-independent
description language such as PyNN [19] and NeuroML [14, 31].
Then, given the description, a neural network compiler (e.g., LCompiler [54, 55], a neuromorphic compiler by Ji et al. [50]) compiles the
description and produces executable code for the underlying hardware or instruction set architecture (e.g., NISA [36]). During the
compilation, the compiler may apply optimizations to improve performance; for instance, LCompiler for Intel Loihi optimizes neuronto-core mapping to minimize energy consumption. After that, the
produced executable runs on the underlying hardware. When the
simulation outcomes are validated, the researcher can upload their
brain simulation configurations to ModelDB [39], the open database
for sharing latest findings in neuronal and synaptic dynamics.
Computing Like the Human Brain: Depending on how information is encoded, the abstraction of the human brain can be classified
into two types: Rate-based Neural Networks (RNNs) and Temporal Neural Networks (TNNs) [81, 82]. Our work focuses on RNNs
which use sequences of spikes from a single synapse to encode
and convey information [12, 17, 20]. As RNNs use multiple spikes
from a single synapse to communicate and compute, the highly
complex interactions between the spikes need to be considered (e.g.,
homeostasis [104]). On the other hand, TNNs encode information
in the spatio-temporal patterns between the spikes from multiple
synapses [56, 91]. With TNNs, the complex interactions needed by
RNNs are no longer necessary, allowing much more simpler abstractions to be used [10]. Using the space-time computing capability of
TNNs, prior studies demonstrate that various brain-like computations are possible with TNNs [51, 57, 61, 73]. For instance, a recent
study by Smith [83] utilizes TNNs to implement a generalized race
logic. As RNNs and TNNs both demand learning rules to adjust
the synaptic weights, FlexLearn can equally benefit both RNNs and
TNNs. Note that both RNNs and TNNs are active research topics,
and there is yet no consensus on which is more suitable to describe
the computations of the brain.
7 CONCLUSION
We presented FlexLearn, a highly flexible and efficient on-chip learning architecture for brain simulations. Motivated by the low flexibility of the existing accelerators, FlexLearn achieves highly flexible
on-chip learning by supporting diverse learning rules. FlexLearn
achieves high flexibility by using the datapaths implementing the
315
FlexLearn: Fast and Highly Efficient Brain Simulations Using Flexible On-Chip Learning MICRO-52, October 12–16, 2019, Columbus, OH, USA
sub-rules as the basic building blocks, and high efficiency by integrating the datapaths in an efficient manner. We then integrated
FlexLearn with Flexon, the state-of-the-art digital neuron, to implement an end-to-end brain simulation accelerator. The resulting
FlexLearn accelerator realizes fast and highly efficient brain simulations by achieving high flexibility.
