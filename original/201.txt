It is important to encourage older adults to remain active when interacting with assistive robots. This study proposes a schematic model for integrating levels of automation (LOAs) and transparency (LoTs) in assistive robots to match the preferences and expectations of older adults. Metrics to evaluate LOA and LoT design combinations are defined. We develop two distinctive test cases to examine interaction design considerations for robots working for this population in everyday tasks: a person-following task with a mobile robot and a table-setting task with a robot manipulator. Evaluations in user studies with older adults reveal that LOA and LoT combinations influence interaction elements. Low LOA and high LoT encouraged activity engagement while receiving adequate information regarding the robot's behavior. The variety of objective and subjective metrics is essential to provide a holistic framework for evaluating the interaction.
The global population of older adults (aged 65+) is increasing rapidly without commensurate growth in people that can support them [1]. This shortage is creating an eldercare gap in which the scarcity of caregivers, social support, and healthcare professionals has left many in this group facing many barriers in aging [2]. Assistive robots (ARs) can help reduce these barriers, facilitate independence, and promote more successful aging (e.g., [3]–[4][5]). While there has been progress in AR design and development for many daily applications [6], several challenges remain [7]. A significant challenge is the lack of fit between user expectations of the robot and its capabilities and behavior [8], leading to an interaction gap. Overexpectations can cause older adults to overrely on the robot, misuse or abuse it [9]. Underexpectations, where older adults ignore the robot's capabilities, can lead to disuse or abandonment.

A reliable design should meet the needs and preferences of older adults while keeping them informed of the robot's actions, capabilities, and limitations [9]. This tradeoff calls for an interaction design that pulls together several interaction-related elements to ensure that older adults’ preferences, expectations, and characteristics match with a robot's behavior and the tasks it can perform [10]. The article focuses on integrating levels of automation (LOAs) with levels of transparency (LoTs) of ARs for older adults to keep them active through the interaction.

We begin with definitions of LOA and LoT. The levels at which a human operator controls an automatic process are classified as LOAs [11], defined as the degree of robot involvement, the degree to which automation is employed in a given task, and the level of assistance provided to the user [12]. In the lowest LOA, the user manually controls the operations of the robot. In the highest LOA, the robot is fully autonomous. Intermediate LOAs can be viewed from the perspective of user consent versus exception. At the robot-oriented semiautonomous level [management by exception (MBE)], the robot informs the user as it initiates and implements actions unless the user objects. At the human-oriented semiautonomous level [management by consent (MBC)], the user must explicitly agree to suggested activities before the robot carries them out. MBC presumably increases users’ awareness of and control over the robot's behavior, but it does so at the cost of increased communication demands. Previous research in an aviation application [13] looked at MBC breakdowns as a function of conflict detection and found that operators were very poor at detecting conflicts before the system issued a request for consent. Hence, effective MBC should be supported by the system's interfaces (i.e., be connected with its LoTs).

Furthermore, even highly trained operators have difficulties detecting conflicts—raising concerns for ARs used by older adults. Difficulties are also evident in MBE systems since humans may not promptly detect potential conflicts, affecting failure avoidance and failure recovery times [14]. Therefore, interaction design is critical in both MBC and MBE since users cannot consent or object to something they cannot see, detect, or understand. Designing LOAs to fit the needs and demands of older-adult users is therefore essential for interaction design in AR operations [15]. It is necessary and challenging to keep the older adult involved in the task while controlling the robot.

LOA design can be modeled by the four stages of information processing [16] denoted as the OODA loop [17]: acquiring information (Observe), processing information (Orient), making decisions (Decide), and taking action (Act). Acquiring Information includes elements such as the illumination of the environment and any clutter in it. It may also include details such as items to be set on a dining table or the position where those items should be. Processing Information requires generating options for performing the task. It involves options such as movement speed and distance to keep from a person when following them. It may include the type of items to set for a person and the order of that setting. Making Decisions entails identifying which of the options to select in performing the task. Making decisions may involve deciding on the most appropriate following angle and distance of the robot when following a person in a person-following (PF) setting or deciding the order of setting items on a table for a table-setting (TS) task. Taking Action are steps associated with the decision made. Examples include following the user as they move along a corridor (PF) or picking up a plate and placing it on a table in front of the user (TS).

LoT is the degree of information (information quantity) provided to the user related to the state, reasoning process, and future plans of the system [18], specifying the amount and relevance of information presented by the robot to maintain the interaction [19], [20]. The information presented must conform with perceptual and cognitive peculiarities of the users [10], [21], [22] and relate to the environment, task, and robot [20]. Too little information may not be sufficient to ensure reliable interaction with the robot [8], whereas too much may cause confusion and error [20].

LoT design can be modeled using the situation awareness-based transparency model with the following levels [18]: Purpose and perception—the LoT that provides information on the current state of the environment, task, robot, human, or interaction. Comprehension and reasoning—the LoT that defines how the state of the environment, task, robot, human, or interaction may affect the users’ interaction with the robot. Projection and prediction—the LoT that gives information on the next stage in the interaction based on the present status and other intervening factors.

To ensure effective interaction, we propose a model for how to integrate LOA and LoT design (see Section III) and metrics for their evaluation. Two distinctive robotic test cases were specially developed to evaluate LOA–LoT integration in user studies in (see Sections IV and V): 1) PF with a mobile robot used to follow an older adult from behind and carry personal items; and 2) TS of a table for a meal with a robot manipulator. Each evaluation included a 2×2 design of two LOAs and two LoTs. The TS data were obtained from previous work [23] in which we evaluated the feasibility of incorporating LOA–LoT combinations for a robot arm in a domestic setting [23]. The LOA–LoT schematic model was not described in previous work [23], which included only preliminary analyses. In the current work, we additionally propose metrics to evaluate LOA–LoT. The aim was to determine whether there are commonalities in LOA–LoT interaction design implementations that go beyond specific ARs or tasks. These commonalities, if they exist, can lead to design recommendations for LOA–LoT combinations to improve older adults’ interaction with ARs. Section III describes the LOA–LoT schematic design model, the metrics for evaluation, and the research hypotheses. Section IV describes the experimental details for the PF and TS test cases. Results for LOA–LoT combinations are presented in Section V. Discussion is given in Section VI. Finally, design guidelines, implications, limitations of the research, and future work are given in Section VII.

SECTION III.

Schematic Model for Integrating LOA–LoT
A schematic model is proposed (see Fig. 1) for integrating LOA and LoT settings in a user interface through which robot involvement (LOA) and information quantity (LoT) can be adjusted for the task.


Fig. 1.

Schematic model for integrating LOA and LoT with interaction design for older adults and ARs.

Show All

The model must be adapted for each test case using a designated interface and considering ecological interface design principles [24]. LOA delineates the robot's role and actions expected in the interaction, including the information exchange between the robot and user in instructions and feedback. LoT explores what the content of this information from the robot should be. A significant interaction between LOA and LoT is expected, as lower LOAs require more involvement of the user and more information [13]. The mode through which the information exchange occurs is considered in the user interface design to ensure that it is convenient for users to receive the information while performing the task.

A. Design of the LOA Modes
A significant consideration in designing the LOA mode was to keep the older adult involved in the task while controlling the robot. Four LOAs were carefully weighed based on human-automation system design guidelines and recommendations [25]: Robot alone—the robot performs all actions without any form of human involvement. Robot-Oriented Semiautonomy (MBE)—the robot implements activities unless the user objects and informs the user of the implemented action following its execution. Human-Oriented Semiautonomy (MBC)—the user must explicitly agree to suggested actions before they are performed by the robot. Human alone—the robot is not involved in any part of the task. The human performs all actions.

To encompass the four levels at different phases of the OODA loop, two LOA modes were designed to ensure that: 1) the human was always kept in the loop, regardless of the automation level, and 2) the robot helped them at all times, but as little as possible, so that human skills were maintained and sedentary behavior was avoided. This resulted in the following two tested LOA modes (see also Fig. 2).


Fig. 2.

LOA modes designed for older adults’ interaction with ARs. The tested LOA modes are described as an OODA loop [27]. In the high LOA mode, decisions are made by the AR, but the human can overrule these upon execution. In the low LOA mode, the human makes the decision alone.

Show All

Low LOA mode: The robot minimally assisted the human in acquiring information related to the task by presenting information through the application interface. The robot also assisted in the information processing by providing options through which the task could be performed. The human had to agree to the suggestions before the operation could continue and then solely make the decision regarding what should be done, whereas the robot assisted in the execution of the actions.

High LOA mode: The robot was more involved than the human in acquiring information regarding details of the task, and fully processed that information. All decisions related to the task were made only by the robot. Although the robot executed the decision, it could be interrupted by the human.

B. Design of the LoT Modes
The aim of the LoT design was to provide as much information as needed to the user at every point in time without overload. During the interaction, the following information classes are provided.

Task-related information—information from the robot to the user regarding its state or its actions, as connected with the task at hand. It includes details of the task such as the time required to complete it, constraints connected to it, demands and dependencies in it, requirements for it, and progress in it [18], [26], [27].

Environment-related information—the type of environment (e.g., indoors, outdoors, corridor, open space), conditions prevalent in the environment (e.g., illumination conditions, clutter, obstacles, weather conditions), environmental constraints, and safety-related environmental information [3], [20], [28], [29].

Robot-related information—information pertaining to the operation and behavior of the robot, i.e., its degree of reliability, principles underlying its decision making, and all other (e.g., information on how to use a specific feature of the robot or on its battery charge level) [30], [31].

Human-related information—the human's physical condition (e.g., heart rate, tiredness), cognitive state (e.g., engrossed, confused), and emotional state or mood (e.g., happiness, fear). It also includes information regarding the workload or stress the human is experiencing [32].

Interaction-related information—details of the human's and robot's roles in the interaction and shared awareness and dynamics of the teamwork [32]. It entails information of how subtasks are allocated as the roles in the LOA condition being used and how each role would be executed.

Previous research on users’ LoT preferences regarding the four classes of information (task, environment, robot, human,) [33] revealed that older adults preferred the purpose and perception transparency level for these different classes. Most older adults wanted the robot to be current and immediate, providing only status information. In some situations, they asked for a higher level of transparency to understand why the robot took certain actions (comprehension and reasoning). In fewer cases, they asked to know what the robot planned to do next (projection and prediction). Based on [31], the amount of information for each class of information was designed into the LoT modes set as follows (see also Fig. 3).


Fig. 3.

LoT conditions developed for the experimental test cases are described in terms of the class and amount of information the AR provides. In the high LoT, the AR provides more predictions about all classes of information. In the low LoT, basic status information is given.

Show All

Low LoT mode—The robot presents status information regarding the environment, task, robot, and user. It also presents additional information to support the interaction in certain cases (e.g., if something is not functioning as expected).

High LoT mode—The robot presents status information regarding the environment, projects the next stage in the task, gives reasons for its actions, and presents how information about the user could affect its actions and the future state of the interaction.

C. Interaction Design Metrics
Five metrics were defined to evaluate the LOA–LoT model: engagement, fluency, comfortability, understanding, and trust. The metrics were selected to evaluate the user and system performance along with additional aspects that contribute to the overall interaction quality [6]–[7][8][9]. Additionally, they were connected with the perception of the input and output quality of the system from the standpoint of older adult user priorities. We selected measures that contributed to older adults independence and successful interaction with an AR. Each metric was composed of normalized objective and subjective measures that were combined by an averaging function.

Normalization between 0 and 1 was conducted for each of the objective and subjective values by feature scaling using the minimum and maximum values within each variable

Vn= a+(v−vmin)(b−a)vmax−vmin(1)

View Source where Vn= the normalized value between [a, b], with vmax = maximum value and vmin = minimum value.
The average values of all measures were then combined to create one combined metric for each assessment metric

METRIC =1n ∑i = 1n(Obji+Subi)(2)

View Source where METRIC = engagement, fluency, understanding, comfortability, and trust, as defined in the following; Obj = objective measures; Sub = subjective measures; and n = the total number of individual measures combined for the trials.
An aggregated metric was then implemented to combine all metrics

MA=15 ∑i = 15(Ei+Fi+Ui+Ci+Ti)(3)

View Source where MA= the aggregated metric, E = engagement, F = fluency, U = understanding, C = comfortability, and T = trust.
Engagement captures the details involved in initiating a connection between the human and the robot, maintaining that connection and regulating it till the end of the interaction [34]. This ensures activities that minimize sedentariness [35]. Prior studies have shown that the reported engagement of older adults with robots is generally lower than the younger adults [36]. Effort is therefore made to actively engage the older adults with the robot during interaction. Objective measures include gaze duration of the users as they focus on the robot or graphical user interface (GUI) of the robot and the number of user-initiated voice and gesture responses in the interaction. Subjective measures are assessed through questionnaires related to the attention given to the robot or GUI (using adaptations from the Engagement perception for social robots, attention dimension in [37]).

Fluency is the coordination of the shared task between the human and the robot for the successful synchronization of plans and actions [26]. A fluent interaction with the robot evokes appreciation and confidence of the user [26], which is important for the older adult to gain assurance in using the system [10]. It can be measured objectively through task duration of concurrent activity, human and robot idle time, or functional delay in the interaction. Subjective measures are assessed through questionnaires on the timing of the robot's actions and feedback during the interaction (a subset of the Human–Robot Fluency Scale in [26]).

Understanding is the accurate comprehension of details of the interaction to promote a successful interaction of the human with the robot [38]. In general, communicative actions performed by the robot are aimed at reducing the mismatch between the robot, and the older adult's perception regarding the state of the interaction, using the system, responses from and to the system [10], [38]. It can be measured objectively through the number of clarifications made by the participant to the experimenter regarding the information the robot is providing. Another objective measure is the participants’ reaction time while interacting with the robot. Subjective measures are assessed through questionnaires on the comprehension of the robot's actions and information that it provides during the interaction (the understanding dimension of the Situation Awareness Rating Technique in [39]).

Comfortability is the extent to which the human experiences ease, absence of stress, or pain, or other forms of discomfort resulting from interaction with the robot [40]. It is a measure that also encompasses the level of pleasure and comfort the users feel while interacting as well as the satisfaction with the state of the interaction and actions involved [40]. It can be measured objectively through physiological signals connected with stress, fatigue, or relaxation, such as heart rate difference measurement. Eye movements [40] observed in gaze shifting to monitor the actions during the interaction can also indicate some degree of discomfort or lack of ease. Gaze behavior was highlighted in previous research with users’ evaluation of the robot, ensuring it is not invading their personal space [41] or operating beyond acceptable speed limits perceived to be safe [3]. Subjective measures are assessed through questionnaires that relate to the ease of interaction with the robot and the extent of stress experienced during the interaction (a subset of the Robotic Social Attributes Scale [42]).

Trust is the disposition to rely upon the abilities or capabilities of the robot based on a certain degree of satisfaction in its level of performance [43]. This is necessary to assess because the information provided to the users, as reflected through the LoT design, influences the calibration of the user's trust in the system [20]. It can be measured objectively in terms of proximity to the robot and in other actions reflecting degrees of dependence on it. Subjective measures are assessed by questionnaires that relate to the extent of dependence on the robot and perception of mistakes the robot makes (a subset of the Human–Robot Trust Scale in [44]).

Two experimental test cases representing robotic applications for daily living activities were developed: PF and TS. Settings varied in task demands, environmental constraints, robot type and capabilities, and user expectations.

A. Experimental Platforms
1) PF Mobile Robot
A Pioneer LX mobile robot (50 cm width, 70 cm length, 45 cm height) was used [see Fig. 4 (left)] in the experiments. It had an integrated onboard computer and a laser rangefinder (SICK S300) positioned approximately 20 cm above the ground to detect and avoid nearby obstacles. The person-tracking and person-following commands were executed in ROS [45], [46] using OpenPTrack. The robot was programmed to stop if it detected an object 50 cm from its core. The robot followed the first person it detected by moving to a defined position behind them (as set in the program). The angular and linear velocity of the robot was dynamically updated according to the angular displacement of the target and its distance from the robot, respectively. Parameters such as maximum following the speed (1.0 m/s), acceleration coefficient (0.5), following distance (0.3 m), and following angle (30°) were set according to previous research recommendations for social-following robots to ensure user satisfaction, trust, comfort, and, overall, a perception of safety [47]–[48][49].


Fig. 4.

Left: The PF robot platform. Right: The experimental setup with the robot following the user.

Show All

2) TS Robot Arm Manipulator
A KUKA LBR iiwa 14 R820 manipulator was equipped with a pneumatic gripper and suction for picking up and placing items at specific positions on the table. ROS was used to implement the task and to link all modules that were programmed in Python [45]. A dedicated GUI was designed on a computer monitor placed to the left of the user to enable them to give instructions to the robot and receive feedback from it.

B. Test Case Task Descriptions
1) PF Task
The task required the participant to walk a designated path to retrieve an item placed at about 25 m away with a mobile AR following him/her autonomously from behind. The study took place in a 2.5 m wide corridor in a university laboratory building. The participant was expected to place the item on the robot after retrieving it, and return to the start position for each of the experimental conditions [see Fig. 4 (right)]. The robot continuously communicated with the user regarding its state to keep them aware of its actions based on the feedback recommendations in previous studies [33].

2) TS Task
In the TS task [23], a robotic arm positioned on a table in front of the user placed a plate, fork, knife, and cup at specific positions on the table in preparation for a meal (see Fig. 5). Depending on the LOA, the user was involved in the process by deciding which item to set and in which order.


Fig. 5.

Left: TS robot platform and experimental setup. Right: A participant instructing the robot through screen on the left.

Show All

C. Experimental Design
Each experiment was designed as a mixed between- and within-participant design with LOA (High/Low) and LoT (High/Low) conditions manipulated in a similar manner for both test cases (see Figs. 4 and 5). Each participant experienced one test case. The LOA was the between-participant variable. Participants completed the task twice in the LOA assigned to them, once for each LoT. The LoT order was counterbalanced to avoid order effects.

The dependent variables were the aforementioned interaction design metrics adapted for each test case, as detailed in the following and summarized in Table I.

TABLE I Interaction Design Metrics


Engagement: For PF, this was considered as the extent to which a participant-initiated communication with the robot while gazing at the robot, and the duration of gazes that they made toward the robot during this communication. For TS, it was the number of times participants looked toward the GUI where the robot's information was provided, their gaze duration as they focused on the robot, and the number of user-initiated voice and gesture responses unrelated to the task.

Fluency: For PF, this was the robot idle time not used since the robot was actively and continuously following and tracking the participant.

Understanding: For PF, this was the reaction time measured by the time it took participants to react when the robot gave instructions such as: “I will follow you, as you move. You can start moving now.” In the TS, reaction time was not an indicative measure since participants sat right in front of the robot, and the user interface allowed them the opportunity to promptly respond to the instructions the robot gave through the GUI (results [23] revealed an immediate response).

Comfortability: For PF, this was measured as the number of times participants glanced back at the robot, where a glance back may indicate discomfort about the robot invading personal space [41], going beyond safe speed limits [3] or about losing the robot (as observed through comments from users in previous studies [49]). This was not indicative for the TS since participants were sitting in front of the robot. Each participant's heart rate at the beginning of the experiment was normalized to 100 bpm. The difference in heart rate throughout the experiment and in each of the conditions was then calculated relative to this normalized value. An identical scale for the heart rate difference measurement was used in both test cases.

Trust: For PF, this was measured as the walking duration to pick up an item without looking back at the robot following them from behind, and the time spent waiting for the robot when the robot lost track or was delayed. In the TS, it was measured in terms of the participants’ perception of safety (categorized into three levels according to the initial location of the participant): 1) standing next to the robot, 2) sitting with hands on the table, and 3) sitting far from the robot.

D. Hypotheses
The experimental evaluation aimed to assess LOA–LoT design combinations with the following hypotheses, which were based on the characteristics of older adults in relation to degree of control while interacting with a machine [50] and information presented to the older adults in interaction [51], [52].

H1: There will be an LOA–LoT interaction effect on the overall performance and interaction quality, as measured through the aggregated metric consisting of engagement, fluency, understanding, comfortability, and trust.

H2: Low LOA and high LoT will increase engagement.

H3: High LOA and low LoT will increase fluency.

H4: Low LOA and high LoT will increase understanding.

H5: Low LOA and high LoT will increase comfortability.

H6: Low LOA and high LoT will increase trust.

E. Participants
Twenty-four healthy older-adult participants with no major physical disability or impairment (14 females, 10 males) aged 62–85 (M = 75.4, SD = 5.8) were recruited via social networks and colleagues. Only two of them had slight physical challenges with walking. Most of the participants had lived most of their adult years in Israel. Ten participated in the PF experiment, and the other 14 participated in the TS experiment. A preliminary discussion was held with each participant before the experiment to ascertain comfortability with the robot and to ensure understanding of the procedure and fitness for the task.

F. Experimental Procedure
Participants completed a preliminary questionnaire (consisting of demographic information, the Technology Adoption Propensity (TAP) [53] and the Negative Attitude toward Robots Scale [54]) before being introduced to the robot and performing the task. The PF experiment took place as described above. In the low LOA, the robot received the participants’ consent before it began to follow them, but in the high LOA, it started following immediately. For the low LoT, the robot gave the participant a status update regarding what it was doing (e.g., “following,” “stopping”) at a pace of 5 s. In the high LoT, the robot provided its current actions and additional information on the reason for taking these actions (e.g., “Stopping because there is an obstacle ahead”).

In the TS experiment, the user-initiated the robot's operation with a start button that also served as a “stop at any time” button. In the high LOA, the robot sets the items autonomously. In the low LOA, the robot acquired the participant's choice of items to set (via the GUI), in addition to their consent for starting or stopping the operation. Information from the robot was presented in visual form through the GUI. The low LoT included text messages that specified the current action of the robot (e.g., “bringing a plate,” “placing a fork”), whereas the high LOT, in addition to this text, stated the reason for the robot's actions, (e.g., “I'm bringing the plate as you asked”).

Participants were told that the robot would behave differently in the two trials. After each trial, they were given a posttrial questionnaire, which used a 3-point Likert scale with 3 representing “Agree” and 1 representing “Disagree.” This simple scale was selected due to the difficulties the older adults had experienced in previous trials with 5- and 7-point scales [55]. A final questionnaire was provided at the end of the experiment to enable the participants to explicitly retell their experience with the robot. All procedures were approved by the university's ethical committee.

G. Statistical Analyses
Analyses were performed using a two-tailed general linear mixed model (GLMM) analysis. The fixed effects were the LOAs and LoTs and one random effect that accounted for individual differences among participants. To ensure that analyzed variables conformed to the GLMM requirements, the variables that included time (e.g., gaze duration, human active time) were log-transformed. The cumulative logit model was used for variables with ordinal values (e.g., perception of safety, questionnaire responses). The Wald chi-square test was included as a multivariable generalization test to evaluate the multiple parameters involved in the analyses.

SECTION V.

Experimental Results
A. Characteristics of Users
Most of the participants were acquainted with the use of innovative technologies (M = 3.39, SD = 0.72). The TAP index [20] revealed that most of them affirmed that technology could provide more control and flexibility in life (PF: M = 2.48, SD = 1.59; TS: M = 3.86, SD = 1.17). Participants showed confidence in learning new technologies (M = 2.95, SD = 1.18), were comfortable communicating with robots (M = 3.43, SD = 1.50) and trusted technology (M = 3.04, SD = 1.58). In total, 80% were positive about interacting with a robot (M = 4.14, SD = 0.86).

B. Aggregated Metric
The means distribution of the combined objective and subjective data across the four LOA–LoT combinations for each of the evaluation metrics is presented in Fig. 6. The GLMM analyses revealed that there was a significant influence of LOA and LoT on the overall aggregated metric for PF (F(3, 16) = 3.91, p = 0.026) and TS (F(3, 22) = 2.35, p = 0.033). This confirms H1. Details of the metrics are presented in Table II. Individual objective measures before normalization and aggregation appear in the Appendixes.


Fig. 6.

Summary of normalized metrics for the two robotic test cases.

Show All

TABLE II Aggregated Metric in Both Tasks (Significance Highlighted)


C. Engagement
The LOA–LoT interaction had a significant influence on engagement for both the PF task (M = 0.58, SD = 0.16), X2(3, N = 20) = 8.82 p = 0.03) and the TS task (M = 0.75, SD = 0.78), X2(1, N = 28) = 30.91, p<0.01). The low LOA and high LoT significantly engaged the participants compared to the other experimental conditions (p<0.01) in both test cases. This confirms H2.

D. Fluency
Fluency was not significantly affected by the LOA–LoT interaction in the PF task (M = 0.74, SD = 0.16), X2(3, N = 20) = 0.652 p = 0.89), but was significant in the TS (M = 0.83, SD = 0.13), X2(1, N = 28) = 13.05, p<0.01). The high LOA and low LoT significantly increased fluency compared to the other LOA–LoT combinations (p<0.01) in the TS. This supports H3 for the TS task only.

E. Understanding
Understanding was significantly affected by the LOA–LoT interaction in the PF task (M = 0.72, SD = 0.25), X2(3, N = 20) = 33.15 p<0.01), but was not significantly affected in the TS (M = 0.85, SD = 0.15), X2(1, N = 28) = 2.51, p = 0.47). Low LOA and high LoT conditions significantly increased understanding compared to other conditions (p<0.01) in the PF. This supports H4 for the PF task only.

F. Comfortability
Comfortability was not significantly affected by the LOA–LoT interaction in the PF (M = 0.69, SD = 0.15), X2(3, N = 20) = 2.03 p = 0.57), but was significantly affected in the TS (M = 0.69, SD = 0.14), X2(1, N = 28) = 9.07, p = 0.03). The high LOA and high LoT produced a significantly higher level of comfort compared to the other conditions (p<0.1) in the TS. This supports H5 for the TS task only.

G. Trust
The interaction effect of LOA–LoT on trust was not statistically significant in both test cases (PF: (M = 0.52, SD = 0.19), X2(3, N = 20) = 3.79, p = 0.29); TS: (M = 0.65, SD = 0.18), X2(1, N = 28) = 4.06, p = 0.26). Thus, H6 is not supported.

LOA–LoT interaction effects were found in both test cases for the aggregated metric and for engagement. Combining the low LOA (which promotes higher engagement) with high LoT (which provides more information) was observed to improve the interaction as assessed through the defined metrics. A summary of the main findings is presented in Table III. Previous research indicated that, in high LOA, users can become frustrated due to a lack of control that they sometimes feel [56]. More frustration can ensue if they are not aware of what is happening [19]. Therefore, providing a higher degree of control (through a low LOA) and increased transparency (through a high LoT) can minimize these potential challenges when older adults interact with ARs. This corresponds with previous recommendations for enhanced interaction design aiming to improve the sense of control in the automation [56] and transparency of the robot's actions [19], [53].

TABLE III Summary of Main Findings


A. Task-Robot Dependent Influences
The results for fluency, understanding, and comfortability were not consistent, implying that task- or robot-related factors may have influenced the interaction.

For example, in fluency, the LOA–LoT interaction was significant in the TS, but not in the PF. This finding may be related to participants’ workload; the PF task required them to move forward as the robot followed them from behind. Therefore, it is possible that they identified fewer delays in the interaction compared to the TS task where they sat at a table and passively observed the robot's actions. This probably led to the higher tendency of participants to notice delays in the process of setting the table. This is also related to the observations in [57] where participants indicated, via the questionnaires, delays they noticed. However, in both test cases, the high LOA combinations increased the fluency.

The differences observed in understanding can also be explained by the different conditions prevalent in the test cases. Perhaps the difference in feedback modality through which the participants received information in the test cases affected their understanding, resulting in different needs for clarification. Voice feedback when the robot was behind the user (as was the case in the PF) may have afforded a different level of clarity than the visual feedback when the robot was in front of the user (as was the case in the TS). Thus, the position of the user relative to the robot could also have influenced these differences.

These task-dependent factors that influenced fluency and understanding may also have affected the comfortability. However, we cannot assert these claims since the study did not specifically examine the interaction effect of these factors.

B. Perception of Older Adults Toward the LOA–LoT Design
The older adults were confident in interacting with the robots in both test cases. This could be seen in their willingness to participate in the experiment after the explanations had been made to them. They seemed to have a relatively high level of confidence when interacting with the robot in all conditions. This could explain the lack of significant difference in the experimental conditions for the trust metric in both test cases.

The older adults also preferred to be more involved and active when they collaborated with the robot. Their responses in the questionnaires and discussions indicated that they considered the low LOA as an invitation by the robot to collaborate on tasks as opposed to the high LOA where they seemed to perceive the AR as being more independent. They were also more particular about the LoT they preferred in each LOA mode. They considered the AR more communicative at a high LoT compared to a low LoT. Combining both low LOA and high LOT as a behavior of the AR appealed more to them on the interactive level. This behavior, as they described it, seemed to portray the AR more as a companion supporting them, rather than as a tool carrying out house chores in isolation.

These results are in line with our previous studies in which we investigated designs related to LOAs and LoTs for similar tasks with young adults as participants [49], [57]. However, it seemed that younger adults preferred the higher LOA mode irrespective of the LoT mode. Further research should investigate this.

A. Practical Implications
This study revealed the importance of integrating LOAs with LoTs in the design of ARs supporting older adults. The LOA–LoT integration proposed was successfully implemented and tested in the two test cases, providing evidence for the feasibility and viability of the design in ARs. The satisfactory interaction of the older adult with the ARs in both test cases using the implemented model met the expectations regarding the potential benefits of shared control and information sharing, and contributed to active physical and cognitive involvement, which are important to encourage successful aging in older adults [58]. The significant results observed through the metrics proposed for evaluation of the LOA–LoT design reveal the potential of using the defined metrics for further assessment of other human-robot interaction (HRI) related studies. The combination of objective and subjective measures provides a holistic framework for evaluating the interaction and can be employed as a standard in HRI evaluation.

B. Guidelines for LOA–LoT Design for Older Adults
Guidelines for LOA–LoT designs in ARs for older adults are proposed as follows.

We recommend operating the robot at a low LOA to keep the older adult more actively involved in the task.

Combining a low LOA with a high LoT helps maintain older adults’ awareness of the robot's operations without overloading them with information.

LoTs should be adapted for the specific LOA to ensure that the robot's actions match the expectations of the older adult.

C. Limitations of the Study
The recommendations are based on two robotic test cases with two different types of robots; thus, preferences and the recommendations made might vary for other test cases. It is also worth noting that the older adults who participated in the user studies were mainly in the younger-old (65 to 74 years) and older-old (75 to 84 years) groups. Only some of the participants were in the group of the oldest-old (85 years and above). Also, all the participants were primarily healthy and were physically and cognitively fit to come independently to the labs for experiments. Specific health status records, physical or mental measures were not obtained from individual participants.

D. Future Research Directions
Future work should assess the robustness of the LOA–LoT design for different cases of task complexity, environmental changes, workload, malfunctions, and user characteristics. The metrics defined in this study should be refined and evaluated. As an example, the difference in heart rate used in the comfortability metric can be upgraded to heart rate variability. Other adaptable LOA–LoT options could also be explored to improve the interaction.

Further investigations with older adults should include the oldest-old and groups with varying physical or mental capacities and needs. A longitudinal study is also recommended to explore the influence of the users’ familiarity with AR affecting various aspects of interaction with the robot over time, as well as LoT preferences for specific LOAs. Examining two task areas (mobility and supervision) as well using multidimensional measurements added weight to the findings and also provided insights for further exploration of the dynamics of ARs in a variety of situations but in particular their utility for the elderly.

