ABSTRACT
Transactional Memory (TM) has been considered as a promising
alternative to existing synchronization operations, which are often
the largest stumbling block to unleashing parallelism of applications.
Efficient implementations of TM, however, are challenging due to
the tension between lowering performance overhead and avoiding
unnecessary aborts.
In this paper, we present Reachability-based Optimistic Concurrency Control for Transactional Memory (ROCoCoTM), a novel
scheme which offloads concurrency control (CC) algorithms, the
central building blocks of TM systems, to reconfigurable hardware.
To reduce the abort rate, an innovative formalization of mainstream
CC algorithms is developed to reveal a common restriction that
leads to unnecessary aborts. This restriction is resolved by the ROCoCo algorithm with a centralized validation phase, which can be
efficiently pipelined in hardware. Thanks to a high-performance offloading engine implemented in reconfigurable hardware, ROCoCo
algorithm results in decreased abort rates and reduced performance
overhead. The whole system is implemented on Intel’s HARP2 platform and evaluated with the STAMP benchmark suite. Experiments
show 1.55x and 8.05x geomean speedup over TinySTM and an HTM
based on Intel TSX, respectively. Given the fast-growing deployment of commodity CPU-FPGA platforms, ROCoCoTM paves the
way for software programmers to exploit heterogeneous computing
resources with a high-level transactional abstraction to effectively
extract the parallelism in modern applications.
CCS CONCEPTS
• Hardware → Hardware accelerators; • Computing methodologies → Parallel programming languages; • Computer systems
organization → Reconfigurable computing
KEYWORDS
FPGA, Hardware Accelerator, Transactional Memory

1 INTRODUCTION
With the prevalence of parallel computing facilities, the ability to expose the inherent parallelism in applications with a reduced level of
programming effort is becoming increasingly critical. Transactional
memory (TM) has been considered as a promising solution toward
the above objective and attracted extensive attraction in both the
programming and architecture communities [21]. TM provides a
concise framework to a wide variety of essential problems such as
parallelizing programs with unknown dependence [50], achieving
fine-grained synchronization without managing locks [63], extracting concurrency from legacy codes [56], and achieving durability
in non-volatile memories [32].
From the programming perspective, the basic idea of TM is to
devise semantics and language constructs, which can be used by
programmers to identify atomic code blocks and thus alleviate the
burden of coordinating concurrent access to shared states [1]. From
an implementation point of view, TM can be realized as a software
runtime (STM) or a hardware architecture (HTM). Both approaches
are designed to extract parallelism by proactively orchestrating
transactions to maximize parallelism and aborting transactions
that would result in unsafe states to enforce correctness. Numerous studies have been dedicated to developing efficient STM and
HTM solutions. Among these, both Intel [71] and IBM [28] already
released commodity processors incorporating HTM.
However, empirical evaluations of TM on commodity systems
only demonstrate limited performance improvement. The speedup
is especially unsatisfying on benchmarks with long transactions
running on processors with a modest number of cores [13, 14, 70]. In
the case of STM, the major performance overhead is caused by the
manipulation and inspection of transactional states (i.e. metadata)
to resolve conflicts among concurrent transactions [6, 62]. On the
other hand, HTM alleviates the overhead by providing architectural
911
MICRO-52, October 12–16, 2019, Columbus, OH, USA Li and Liu, et al.
support for transactions. For example, Intel TSX [71] is equipped
with hardware support for new instructions to identify transactional regions and modified cache coherence protocols for conflict
detection. However, HTMs suffer from spurious aborts introduced
by architectural limitations like cache capacity [14]. In summary,
the tradeoff between reducing performance overhead and avoiding
spurious aborts is the central challenge of TM designs.
To make things worse, TM systems are notoriously hard to design, in particular their concurrency control (CC) algorithms for
achieving transactional semantics by scheduling interleaved transactions. Previous works investigate the effectiveness of CC algorithms by arguing how anomalies (race conditions) and restrictions
(false alarms) are resolved in a case-by-case manner [3, 41, 59].
Given the complexity of ordering read-write operations among
transactions, even a tiny modification on CC algorithm may hamper its correctness.
The prevalence of commodity CPU-FPGA platforms [8, 26, 52]
offer new opportunities to resolve the tension between performance
overheads and abort rates in TM designs [7, 42]. In this work, we
first formalize transactional semantics. We use the formalization to
analyse mainstream CC algorithms and identify a new restriction
that leads to unnecessary aborts. To relieve this restriction, we
propose a novel CC algorithm with centralized validation scheme.
This algorithm can be efficiently pipelined on FPGAs, which also
reduces the performance overhead.
The major contributions of this paper are as follows.
• We establish an axiom-based transactional semantics on the
basis of the order theory to discern ambiguity around design
choices of CC algorithms. With this formalization we identify the if-and-only-if conditions of common transactional
semantics. Then we show that mainstream CC algorithms
are based the sufficient but not necessary condition for correctness and thus lead to over-stretched designs.
• We propose a novel ROCoCo algorithm (Reachability-based
Optimistic Concurrency Control) for serializability. Experiments show that this algorithm reduces aborts by up to 56.2%
and 20.2% when compared with 2PL and TOCC algorithms
on synthesized benchmarks.
• Based on the ROCoCo algorithm, we implement a hybrid
TM system (ROCoCoTM) whose validate phase is offloaded
to an out-of-core FPGA. Evaluations with the STAMP benchmark suite [46] on Intel HARP2, a heterogeneous CPU-FPGA
platform, show that ROCoCoTM enables 1.55x and 8.05x geomean speedups over TinySTM [17], a STM with TOCC, and
an HTM with 2PL based on Intel TSX, respectively.
The rest of this paper is structured as follows. Section 2 introduces backgrounds and related works. Section 3 proposes the axiombased transactional semantics. Section 4 presents the ROCoCo algorithm. Section 5 shows how ROCoCoTM is implemented on a
heterogeneous CPU-FPGA platform. Section 6 reports experimental
results on Intel HARP2 platform. Section 7 concludes the paper.
2 BACKGROUNDS
2.1 Transactional Semantics
To simplify the programming model, a transaction groups several
read and write operations into one code snippet that executes as
Figure 1: Two threads manipulate two objects {x,y} through
transactions.
if it is the only computation in the system. Practical systems execute multiple transactions concurrently for better performance. For
example, in figure 1 two transactions t1 and t2 access two objects
x and y concurrently. The classic definition of transaction asserts
atomicity and isolation. Roughly speaking, atomicity means a transaction either completes (commits) as a whole, or aborts and undoes
any update it has made to the system, while isolation suggests a
transaction should not interfere concurrent transactions [20].
The definition is vague [43] in that the concept of isolation
is not accurate. A common interpretation of isolation is that
"state changes made by other concurrently executing threads after
a transaction T begins are not visible to T while T executes" [48].
Then both transactions in figure 1 will commit, i.e. both x and y
are set to 1, since both writes are not visible to the other’s reads.
This result is counter-intuitive because only one transaction can
write successfully if these two transactions are executed serially by
a single thread.
Transactional semantics specify which results of concurrent
executions of transactions meet intuitive expectations [20]. TM
systems differ substantially in terms of the semantics they enforce.
The aforementioned isolation leads to a semantic named snapshot
isolation (SI) that suffers from the write skew anomaly [16] as
shown in figure 1. The majority of TMs claim serializability [49],
which states that the result of concurrent transactions should be
identical to a result in which they execute serially. Since serializability leads to more intuitive results than SI by avoiding more race
conditions, we say serializability is stronger than SI.
2.2 Concurrency Control
A concurrency control (CC) algorithm enforces a specific semantic by (a) scheduling concurrent read/write (R/W) operations to
avoid violations during execution, and/or (b) optimistically executing transactions and validating their memory footprints before
committing transactions. In case of serializability, CC can be classified as optimistic CC (OCC) or pessimistic CC (PCC) depending
on whether approach (b) is used or not [36]. Empirically, PCC causes
more unnecessary aborts than OCC [48, 72].
A transactional semantics S is compositional if the whole system enforces whenever each object enforces S [69]. It has be proven
912
FPGA-Accelerated Optimistic Concurrency Control for Transactional Memory MICRO-52, October 12–16, 2019, Columbus, OH, USA
that SI is compositional, while serializability is not. Since SI’s correctness is easy to guarantee by providing multi-version objects, it
is provided by almost all databases [35] and some TMs [10, 40, 55].
In contrast, one has to reason how race conditions are resolved
case-by-case if targeted semantics is serializability [44, 47, 61].
A key insight from previous works [22, 69] is that CC algorithms
based on a non-compositional semantics must either rely on a centralized scheduler for all objects, or else place additional restrictions.
This insight can be exploited to guide the design of CC algorithms
for serializability. For example, in PCC algorithms exemplified by
2-phase-locking (2PL) [5, 37, 48], an object that is locked by a transaction’s execution phase cannot be accessed by another one, until it
is released during the commit phase of the first transaction. This
restriction may degrade 2PL’s performance as it forbids concurrent
accesses to an object. Under 2PL, t2 of figure 1 will be either blocked
or aborted when it tries to access object x that was locked by t1.
2.3 Related Works
Previous works on OCC rely on centralization and/or restriction to
enforce serializability during the validation phase, which is launched
between the (optimistic) execution phase and the commit phases.
Centralization. In Backward OCC (BOCC) and Forward OCC
(FOCC) algorithms [25, 36], validations are conducted by broadcasting the updated objects of a validated/committed transaction
to all the other transactions. These algorithms are only efficient for
broadcast-friendly systems, e.g. HTMs based on snooping protocols [2, 57]. Otherwise, the serialized broadcast will significantly
drag down the overall performance. Other endeavours attempt to
conduct system-wide validation with a centralized thread [45] or
bookkeeping [12, 44, 62], which are prone to become bottleneck.
Restrictions. A sufficient condition for serializability is that
the ordering among concurrent transactions with regard to their
R/W-dependences is acyclic [49, 54]. A sufficient approach to maintaining acyclicity is to abort transactions that have both incoming
and outgoing R/W-dependences during validation [4, 29, 53, 54].
These implementations are conservative because they do not check
whether dependences of a transaction actually occur within a cycle.
To reduce unnecessary aborts caused by restrictions, recent
works on serializability in both TM [17, 53] and database [66, 73]
resort to Timestamped OCC (TOCC) with a minimized centralization, i.e. a shared monotonic-increasing timestamp. A unique
timestamp is associated with each transaction during execution
or validation phase, with which a transaction stamps its updated
objects at commit phase. A transaction is aborted if it reads some
objects with greater timestamps. Then transactions are serialized
in the order of timestamps. Nevertheless, TOCC is sufficient but
not necessary to serializability, as demonstrated in section 3.1.
We propose a novel CC algorithm, ROCoCo, to balance the performance overhead and abort rate. Our key motivation is that with
the advent of heterogeneous architectures, it is profitable to offload
the centralized validation phase off OCC to an out-of-core accelerator. FPGAs could serve our purpose by providing massive bit-level
parallelism to track the dependencies among transactions.
3 AXIOM-BASED SEMANTICS
Transactional semantics are essential to guarantee the correctness
and avoid unnecessary aborts of TM designs. Although previous
Figure 2: Two cases for phantom orderings
works have formalized transactional semantics with the order theory [19, 60], our formalization distinguishes the previous ones in
the following two points: (1) we apply interval order to analyse the
restriction of TOCC algorithms and show that TOCC is sufficient
but unnecessary for serializability; (2) we prove that acyclicity is
the if-and-only-if conditions of serializability so that over-stretched
semantics can be avoided. To motivate the new formalization proposed in this work, we demonstrate a case study on the restriction,
so called phantom ordering, that is ubiquitous in TOCC.
3.1 Case Study: Phantom Ordering
As discussed in section 2.3, a transaction in TOCC acquires a
monotonically-increasing timestamp to validate its R/W-conflicts
to concurrent transactions. A happen-before relation →rw on a set
of transactions can be deducted from the R/W-conflicts. Note that
→rw is a logical order rather than the order in which transactions
should happen in real time.
• (Read-after-Write) If a transaction t1 reads an updated object
from t2, t2 should happen before t1, denoted as t2 →rw t1.
• (Write-after-Read) If a transaction t1 writes an object whose
previous version was read by t2, then t2 →rw t1.
• (Write-after-write) If a transaction t1 overwrite an object
that was written by t2, then t2 →rw t1.
With timestamped objects, TOCC algorithms enforce serializability by aborting transactions whose →rw violate the ordering
of timestamps. As a result, the equivalent serial execution of transactions can be predicated by their timestamps.
However, a restriction arises if an aborted transaction could
have been committed by reordering the timestamps. For example,
assuming each transaction acquires a timestamp when it starts [54,
74], in figure 2 (a), t1 acquires a smaller timestamp (TS1 = 1) than
t2, which causes it to abort since t1 reads the updated x whose
version (TX(x) = 2) is updated by t2. Although t1 can commit if it
is ordered after t2, a phantom ordering induced by the ordering of
timestamp acquisition prevents the reorder.
To overcome the restriction, Lazy Snapshot Algorithm (LSA) [17]
postpones the acquisition of timestamps until the validation phase.
Then t1 of figure 2 (a) can commit with a larger timestamp than
that of t2. Yet the phantom ordering persists. As shown in figure 2
(b), even though this trace can be serialized as t2 →rw t3 →rw t1
913
MICRO-52, October 12–16, 2019, Columbus, OH, USA Li and Liu, et al.
Figure 3: Transactional semantics can be incrementally built
up with axioms.
according to R/W dependencies, the timestamps forbid ordering t2
before t1, which causes t3 to abort.
Being aware of these false alarms, some TM designs [10, 29] rely
on more complex timestamps. Nevertheless, our formalization will
show that the phantom ordering still haunts CC algorithms as long
as global ordering primitives [34] are used as criteria for validation.
3.2 Formalization
The gist of the above-mentioned restriction is that the current definition of serializability only states the existence of a serial execution,
without telling how to achieve the serial execution. Although monotonically timestamping each transaction is sufficient, its necessity
is challenged by the phantom ordering.
To avoid over-stretching serializability, we introduce the axiombased transactional semantics, where a set of transactions T =
{t1,t2, ...} meet a semantic if and only if some axioms are followed
by their R/W-dependency →rw . Then a CC algorithm is both sufficient and necessary for a semantic when it only aborts transactions
whose R/W-dependencies violate the corresponding axioms.
Nomenclature. The nomenclature of our discussion largely
follows that of Herlihy et al. [22, 23]. The order theory generalizes
intuitions on a binary relation of a set by specifying axioms that
the relation must follow. For example, a strictly partial order is
a relation following irreflexive, asymmetric and transitive order;
while a strictly total order, or linear order, is a strictly partial order
plus complete order (i.e. all pairs of elements are related).
Generally, a set of transactions T and its relation are denoted as
a tuple (T,→), where t1 → t2 indicates that behaviours of transaction t1 should be visible to t2 under that relation. Given (T,→),
two transactions t1 and t2 are concurrent if they are not related,
written as t1 ∼ t2
1
. Since arbitrarily scheduling concurrent transactions in a set of R/W-dependent transactions (T,→rw ) will lead
to incomprehensible results, transactional semantics are required.
An overview of axiom-based semantics is shown in figure 3
(a). Here the arrow between two semantics S1 → S2 indicates that
the semantic S2 strengthens S1 by following the axiom on the arrow
in addition to S1’s axioms. With additional axioms, a semantic is
stronger than another one in the sense that it is more restrictive
and leads to more aborts.
The notion of strengthened semantics in Figure 3 (a) can be
captured by extended relations. A relation → on transaction set
1Not to be confused with NOT visible, written as t1 ↛ t2.
T is said to be extended to a stronger relation →s if ∀t1,t2 ∈ T ,
t1 → t2 indicates t1 →s t2, written as (T,→) ⊆ (T,→s ). The
common interpretation of atomicity and isolation from section 2.1
leads to snapshot isolation in 3 (a), which can be extended to other
semantics with axioms.
Serializability. Finding an equivalent serial execution of concurrent transactions T can be viewed as extending →rw on T to
a linear order. To this end, PCC algorithms like 2PL enforce serializability by solely scheduling R/W operations so that →rw is a
partial order 2
, which may result in too many unnecessary waits
and aborts during execution. On the other hand, an OCC algorithm
generates (T,→rw ) in execution phase, and finds a set of committed transaction Tc ⊆ T by aborting some transactions in validation
phase, such that (Tc ,→rw ) can be linearly-extended.
It is well understood that (Tc ,→rw ) can be extended to linear
order if →rw is acyclic. Since any finite and acyclic set has at
least one minimal elements, a linear order can be constructed by
iteratively picking up a minimal element. We can further prove that
acyclicity is both sufficient and necessary to serializability3
.
As the axiom for serializability, acyclicity is also not compositional. For example, in figure 1 (b), although R/W-dependencies
with regard to either object x or y are acyclic individually, their
compositional trace is not acyclic.
Strict serializability and interval order. TOCC algorithms
associate committed transactions with unique timestamps that correspond to the order of equivalent serial executions. Since the timestamps are acquired between the start and the end of transactions,
they also represent the real-time order →r t , where t1 →r t t2 if t2
starts after the end of t1 in real time [22]. A serializable (T,→) is
strict serializable if its serial equivalence is compatible with its
real-time order [23]. Apparently, TOCC enforces strict serializability. But how does strict serializability limits concurrency and lead
to unnecessary abort for serializability?
We will show TOCC is unnecessary to serializability by analysing
the inevitability of the phantom ordering in strict serializability,
no matter how the timestamp is designed. If the timestamps can
be acquired anytime between the start and the end of transactions,
each transaction can be viewed as an interval on the real axis. The
left-to-right precedence relation of these intervals on a real axis, i.e.
the real-time order →r t of transactions on the real time, is characterized as interval order in order theory. By definition [18], a
partial-ordered set is an interval order if it has no subset isomorphic
to a pair of two-element linearly ordered sets shown in figure 3 (b),
i.e., for every two related transactions committed by TOCC (t1 → t2
and t3 → t4 in figure 3 (b)), there always exists a phantom ordering
(t1 → t4) even though t1 and t4 are unrelated in R/W-dependency.
Note that strict serializability is also not a compositional semantic, since acyclicity, the non-compositional axiom, cannot be
2According to the order-extension principle, a relation can be extended to a linear
order if but not only if it is a partial order.
3Proof. (Acyclicity ⇒ serializability) It can be proved by constructing the linear order,
i.e. order of serial execution, from acyclic order with topological sorting.
(Acyclicity ⇐ serializability) Assuming →rw is cyclic, let ▷ be the transitive
closure of →rw . Then there exists distinct t1, t2 ∈ T , such that t1 ▷ t2 and t1 ◁ t2.
As ▷ is the smallest transitive relation that contains →rw , any linear order (which is
also transitive) that contains →rw must contain ▷. Then the linear order extended
from {T, →rw } is not asymmetric when t1 and t2 are considered, which counters
the definition of linear order. Therefore →rw should be acyclic.
914
FPGA-Accelerated Optimistic Concurrency Control for Transactional Memory MICRO-52, October 12–16, 2019, Columbus, OH, USA
inferred from interval order. But if each transaction only operates
on a single object, an interval order on these transactions is sufficient for acyclicity4
, which leads to the compositional semantic
named linearizability5
, as shown in Figure 3 (a).
4 ROCOCO ALGORITHM
ROCoCo algorithm avoids restriction of TOCC by validating acyclicity without using timestamps. Although detecting cycles in the R/W
dependency graph has been extensively studied in transaction processing and race detection, these approaches either incur huge
computation complexity which can only be applied to offline analysis [41], or adapt Kahn’s topological sorting [33] algorithm that is
equivalent to TOCC [67]. Without using timestamps, ROCoCo can
detect and abort a transaction that cause cycles inO(1), and validate
(T,→rw ) in O(|T |), making it suitable for online validation of OCC
as discussed in section 4.1. The centralized validation mechanism
of ROCoCo can be efficiently pipelined on FPGA to further reduce
overhead as discussed in section 4.2.
4.1 ROCoCo
ROCoCo algorithm is inspired by the Warshall algorithm [68] to
compute the transitive closure, or reachability, of a graph. Intuitively, for k acyclic transactions Tk
, a cycle is formed between Tk
and a new transaction tk+1
if there exists two paths in the R/Wdependency graph, such that tk+1
can reach a transaction ti ∈ Tk
through one path, and ti can reach tk+1
through another path. ROCoCo ameliorates Warshall algorithm by iteratively constructing a
bitwise matrix to record reachability of transactions during OCC.
The essence of validating acyclicity is to probe the extended
linear order from the incomplete and intransitive relation →rw . To
this end, transitive closure is a powerful tool in that it describes
the smallest (in the subset sense) transitive binary relation that
contains →rw . In what follows, terminologies from order theory
and graph theory, such as element (i.e. transaction) and vertex,
related pair (i.e. R/W-dependency) and edge, acyclic relation and
directed acyclic graph (DAG), precede and "can reach", succeed and
"be reachable from", are used interchangeably.
Formally, the transitive closure (T, ▷) of any finite binary relation
(T,→) can be constructed iteratively as follows. Initially ▷0 =→.
Then ▷k
is the transitive relation induced by k relations from →, i.e.
t0 ▷k
tk+1
if ∃t1, ...,tk ∈ T such that t0 → t1 → ... → tk → tk+1
(t0 reaches tk+1 by stepping k edges in the corresponding graph).
We say t0 can reach tk+1
, ortk+1
is reachable from t0, if t0 ▷tk+1
.
Finally, ▷ =
Ð
i ≤ |T |,i ∈N ▷i
, where |T | is the size of T .
Warshall’s algorithm [68] for transitive closure simplifies this
procedure by observing the fact that an element ti can reach a
distinct tj
, iff. ti → tj
, or there exists a distinct tk
such that ti →
tk and tk ▷ tj
. Then the transitive closure can be constructed by
iterating vertices in the DAG. However, the best-case performance
of Warshall’s algorithm is O(|T |
3
). This cost is still unacceptable for
4A relations of single-object transactions is irreflexive and asymmetric. Irreflexivity
and interval order indicates transitivity (considering t2 and t3 are the same transaction
in figure 3 (b)). Then the relation is partial order, and thus acyclic.
5The term “linearizability” is heavily overloaded in the TM community. The linearizability in our paper follows the definition of Herlihy et al. [23], i.e. it “can be viewed
as a special case of strict serializability where transactions are restricted to consist of
a single operation applied to a single object”.
Figure 4: ROCoCo algorithm for serializability
on-line validation of TM. Moreover, this algorithm cannot handle
cyclic graph no element can abort during its procedure.
To address this problem, we further exploit the fact: an element
ti
is reachable from a distinct tj
iff. ti ← tj
, or there exists a distinct
tk
such that ti ← tk and tk ◁ tj
. Note this fact is the dual of
above-mentioned fact in Warshall’s algorithm. We use forward to
represent the direction of relations (i.e. →) in Warshall’s fact,
and backward to represent the direction (i.e. ←) in the dual fact.
With these facts, we propose the ROCoCo algorithm that can detect
and abort transactions that cause cycles in O(1), and calculate the
transitive closure of (T,→rw ) in O(|T |).
We start describing ROCoCo with conflict detection of (T,→rw ).
Similar to adjacent vectors for edges of a DAG, vectors of forwardly
and backwardly related pairs, f and b, between the transaction t and
previous k committed transactionsTk
, are generated from (T,→rw ).
Here f[i] indicates t →rw ti
. And b[i] indicates t ←rw ti
A manager validates the transaction t by inspecting (f, b), and
discards t if cycles are detected, as shown in figure 4 (a). We exploit
the fact for cycle detection: a cycle is formed if there exists a distinct
transaction ti ∈ Tk
such that t ◁ ti and t ▷ ti
. To detect cycles
within O(1), the transitive closure of Tk
is stored as an intermediate
result. All committed transactions Tk before t form a DAG, whose
transitive closure is maintained by the manager as a reachability
matrix Rk
, where rij indicates ti ▷ tj
, as shown in Figure 4. To
begin with , when t1 commits, R1 = [1] since a vertex can always
reach itself. When validating t, according to the Warshall’s fact, a
proceeding vector p where p[i] indicates t ▷ ti
, can be calculated
as p[i] = f[i] ∨ (Ô
j ∈ {1,...,k }
(f[j] ∧ r[i][j])). Dually, a succeeding
vector s where s[i] = b[i] ∨ (Ô
j ∈ {1,...,k }
(b[j] ∧ r[j][i])) can be
calculated. If ∨ and ∧ are viewed as + and × on boolean algebra,
then s = b + Rk × b and p = f + R
T
k
× f. According to the fact of
cycle detection, if p ∧ s , 0, a cycle is detected.
If no cycle is detected, t can commit as tk+1
. Then Rk must
be updated to the transitive closure Rk+1 of {Tk
,tk+1
} for future
validations, as shown in figure 4 (b). For this purpose, p and s are
appended to Rk as the (k + 1)
th row and column, respectively.
And the previous Rk
[i][j], (i, j ≤ k) should be updated accordingly.
Considering the transitivity of ({Tk
,tk+1
}, ▷), we can see ti ▷ tj
if
(ti ▷ tk+1
) ∧ (tj ◁ tk+1
), which is equivalent to (p[i] ∧ s[j]). Since
915
MICRO-52, October 12–16, 2019, Columbus, OH, USA Li and Liu, et al.
Figure 5: Pipelined ROCoCo on FPGA with sliding window
of transactions (W = 64)
all bit manipulations in figure 4 are parallel, ROCoCo can validate
(T,→rw ) with |T | iterations of the above-mentioned procedure.
A deficiency in ROCoCo is that it greedily commits a transaction
if it does not cause cycles with regard to previous transactions,
without considering future transactions. There exists cases in which
committing a transaction may cause more future transactions to
abort. Optimizations on ROCoCO are possible if the validation
phase has a global view.
ROCoCo allows more transactions to commit compared to previous algorithms based on topological sorting. Although Kahn’s
topological sorting has running time linear to the number of transactions plus the number of relation pairs, it suffers the phantom
ordering since it presumes a linear order on a DAG during its traversal, which contradicts the intuition that the transitive closure of
a DAG can be disjoint sub-graphs if the DAG is disjoint.
4.2 ROCoCo on FPGA
ROCoCo algorithm exploits bit-level parallelism to provide O(1)
validation for each transaction. However, commodity CPUs are inefficient in bit manipulation. In particular, computation in Figure 4 (a)
involves transposition of bit matrices Rk
, which is time-consuming
in RAM-based architectures. Thus, ROCoCo is impractical on commodity CPUs with SIMD instructions.
FPGAs arise as the Dues Ex Machina to our bit-intensive algorithm. Commercial FPGAs provide massive number of LUTs, registers, BRAMs and DSPs to exploit various forms of parallelism, ranging from bit-level to task-level parallelism [65]. Moreover, emerging
CPU-FPGA platforms are equipped with low-latency interconnections [11] to accommodate fine-grained CPU-FPGA interactions.
These heterogeneous systems match the requirements of ROCoCo.
When implementing the ROCoCo algorithm on FPGA, a problem
appears as there is no bound on the number of transactions, even
though |T | is finite. Since hardware resource has to be bounded, we
employ the sliding window of transactions in our implementation, a
technique adapted from task window [31, 39, 64]. Our insight for
this technique is that transactions relying on distant snapshots are
prone to abort. Thus, we only provide serializability for a sliding
window ofW transactions with ROCoCo algorithm on FPGA. When
transaction tk+1 has committed, transactions that neglect updates
of tk−W abort. In this way, the FPGA only need to keep records for
W transactions. To ensure long transactions can eventually commit,
irrevocability may be required. In our evaluation, W = 64 is chosen
as we spawn at most 28 threads in current ROCoCoTM on Intel
HARP2.
Figure 5 shows a pipelined ROCoCo implementation. Before a
transaction is allowed to commit as tk+1
, its bloom-filter signature and succeeding/proceeding vector are stored as bookkeeping
h−1. The oldest bookkeeping h63 for tk−63 is discarded when tk+1
commits, as shown in the top left corner of Figure 5. A conflict
detector, as shown in the left part of Figure 5, detects conflicts between incoming transaction t’s read/write addresses and historical
signatures. The design choice for the signature will be detailed in
section 4.2. The reachability matrix is implemented as 2D-registers
in the manager. When tk+1
commits, the 2D-registers shift and
update accordingly.
Although multiple transactions are concurrently validated on
FPGA, the atomicity of validation phase can still be guaranteed.
When a transaction is allowed to commit, the following transactions will observe this effect immediately (broadcast of the signal
"tk+1
commit" in Figure 5) and act accordingly. Speculative conflict
detection to previously undecided transactions in the detector is
needed, in order to ensure reactions to commits are finished in one
clock cycle. In this way, each transaction commits atomically, while
a non-blocking pipeline is maintained.
5 IMPLEMENTATION OF ROCOCOTM
In this section, we present ROCoCoTM, a TM based on the ROCoCo
algorithm. ROCoCoTM can be deployed on tightly coupled CPUFPGA architectures. An overview of ROCoCoTM is presented in
section 5.1, which highlights important design choices involved in
offloading the validation phase to FPGA. Design choices for the
bloom-filter signature and the algorithm on CPU-side are elaborated
in section 5.2 and section 5.3, respectively.
5.1 ROCoCoTM Overview
ROCoCoTM features a hierarchical meta-pipeline in which each
stage can be further composed of pipelines [51]. Figure 6 (a) and
(b) show how transactions flow through the architectural metapipeline across CPU and FPGA. Transactions are first executed
(Executor in Figure 6 (a)) and then committed (Committer) on
CPU, while conflicts are detected (Detector in Figure 6 (b)) and
managed (Manager) by a pipeline on FPGA. These stages of transactional execution are cascaded via two asynchronous message
queues (the pull/push queue in Figure 6) between CPU and FPGA
to form a meta-pipeline so that communication latency may be
amortized by overlapped transactions.
An out-of-core FPGA is deployed for the detection of conflicts
and the respective validation as discussed in section 4.2. Both Detector and Manager are fully-pipelined without back pressure on the
pull queue to avoid stalls of transactional execution on CPU-side.
Compared to the exclusive validation on a dedicated thread (figure 6
(c)) in a previous centralized validation scheme [45], pipelined validation on FPGA can significantly reduce the amortized validation
overhead per transaction, as shown in figure 6 (d).
To decouple validation from other steps of transactional processing, ROCoCoTM adopts a lazy version management strategy
and a hybrid conflict detection scheme, i.e. eager conflict detection
916
FPGA-Accelerated Optimistic Concurrency Control for Transactional Memory MICRO-52, October 12–16, 2019, Columbus, OH, USA
Figure 6: Transactions flow through the architectural meta-pipeline across CPU and FPGA in ROCoCoTM. The timing diagram
for validating transactions with an exclusive core and a hardware pipelined module are compared.
by CPU and lazy detection by Detector on FPGA purely based on
global metadata. A thread can serve as either an executor or a committer based on the status of the transaction. During execution, a
transaction bookkeeps its read/write addresses and tentative writes
in private R/W-set and redo-log, respectively. It sends R/W-set to
FPGA and waits for verdict when the execution finishes. If approved, the committer iterates the redo-log and updates the actual
locations. To ensure that the read-set of each transaction remains
consistent during execution, a transaction intersects its read-set
signature against write-set signatures of committed transactions
and may abort when read-after-write conflicts are eagerly detected.
In this way, fast paths for detecting true conflicts between executing
transactions and committed transactions is constructed without any
atomic operation. These transactions aborts fast without incurring
the out-of-core latency. ROCoCoTM prefers global metadata (bloomfilter signatures) to per-location metadata (locks or timestamps per
object) so that FPGA could detect conflicts without incurring the
latency of accessing memory locations. The detailed algorithm on
CPU-side will be discussed section 5.3.
The current implementation of ROCoCoTM supports serializability among 64 transactions in the sliding window on FPGA. For
other pairs of transactions, strict serializability is guaranteed by
eager conflict detection and early abort on CPU. Since most transactions that violate timestamped order re-arrange transactions within
64 transactions incurred by 28 concurrent threads, ROCoCoTM’s
semantic allow more transactions to commit than TOCC.
As for the forward progress, the deadlock-freedom is guaranteed
by commit-time locking such that no shared resources are locked by
any transaction before committing. However, ROCoCoTM cannot
guarantee livelock-freedom in two cases: 1) when the number of
threads T exceeds the size of sliding window W , a long-running
transaction may be continuously aborted due to the overflow of
the sliding window; 2) when T <= W , a skewed workload with
extreme long-running transactions flooded by an overwhelming
number of tiny transactions may suffer from livelock. Under current
configuration (T = 28,W = 64), no livelock is observed.
5.2 Parallel Bloom-Filter Signatures
Parallel (partitioned) bloom filters [58] have been widely used in
HTMs to compute signatures representing an unbounded set of
Figure 7: False positivity of query and set intersection of
bloom-filter signatures under different parameters
elements. The problem of such an approach is the introduction of
false positivity. A signature is computed by using k parallel filters,
each of which hashes an element to one of m/k bits, as shown in
Figure 7 (a). It supports element insertion, membership query, set
union, and set intersection operations with bit-wise operators [9].
For ROCoCoTM, parallel bloom-filter signatures would be implemented with both hardwired logic on FPGA and AVX instructions
on CPU. To adapt to different architectures, we choose the approximated universal hashing with the multiply-shift scheme [15]. In
this way, the signature of an address can be computed with several
AVX instructions.
A major concern for designing the bloom-filter signature is to
decide appropriate sizes of signatures so that an acceptable false
positive rate can be attained. We use an established probabilistic
model [30] to analyse the false positivity of query and set intersection6 of bloom-filter signatures. The respective false positivity of an
bloom-filter signature storing n elements are depicted in Figure 7 (a)
and (b). Here m and k are chosen to ease the implementation with
AVX2 instructions on CPUs. False set-overlap for set intersections
can be frequent even with a small number of elements. To lower
the false positivity, we choose m = 512,n = 8 for ROCoCoTM and
only perform intersection operations on signatures with at most 8
6Here we concern false set-overlap of intersection, i.e. a bitwise AND of two signatures
of disjoint sets indicates an non-empty intersection
917
MICRO-52, October 12–16, 2019, Columbus, OH, USA Li and Liu, et al.
UpdateSet
(a) A transaction loads
global timestamp as its
local timestamp at start
(b) The transaction updates
its validated timestamp if
no conflict is found
(c) The transaction traces
missed updates with MissSet
after finding a conflict
(d) The transaction
aborts if it attempts to
read a missed update
GlobalTS
Executor
LocalTS
MissSet
Committed transactions before PrefixTS
Committing transactions after GlobalTS
Ready-to-commit transactions after GlobalTS
Ready transactions
from FPGA
ReadSet
0x03
WriteSet
RedoLog
ValidTS
UpdateSet
UpdateSet
Executor
0x02
MissSet
ReadSet
WriteSet
RedoLog
0x02
TempSet
No Overlap
Executor
0x03
MissSet
ReadSet
WriteSet
RedoLog
0x02
TempSet
0x02
0x03
Executor
0x03
MissSet
ReadSet
WriteSet
RedoLog
0x02
UpdateSet
addr
TM_ABORT()
Figure 8: LSA for strict serializability based on bloom-filter
signatures
elements. Coincidentally, each 512-bit cacheline can store exactly
eight 64-bit addresses.
5.3 Algorithms on CPU-side
To decouple validation while maintaining opacity7
[19] on CPUside, ROCoCoTM performs eager conflict detection to committed
transactions by adapting LSA from TinySTM [17]. Unlike TinySTM
where per-location metadata are required, ROCoCoTM relies on
thread-local bloom-filter signatures to detect collisions. In what
follows, all set operations are based on bloom-filters.
The gist of the algorithm is that each transaction incrementally
maintains a valid snapshot of memory states by comparing its read
set to write sets of committed transactions. As shown in Figure 8
(a), each committed transaction creates a snapshot indexed by an
incremental global timestamp (GlobalTS). An executing transaction
initially acquires the GlobalTS as its local timestamp (LocalTS)
and validated timestamp (ValidTS). When the transaction reads
an address, it copies the signatures of the write sets between its
LocalTS and current GlobalTS as a temporary set (TempSet), and
attempts to extend ValidTS by intersecting its read set to TempSet.
If no overlap is found, it updates the ValidTS to indicate that no
collision has been found before ValidTS (Figure 8 (b)). Otherwise,
one of addresses in its read set might have been updated after
7A transaction’s read-set must stay consistent during its execution
Algorithm 1 Transactional Load and Store in ROCoCoTM
Procedure TM_READ(var, addr)
1: if WriteSet.Query(addr) then
2: var = RedoLog[addr]
3: return
4: end if
5: while UpdateSet.Query(addr) do
6: if MissSet != ∅ then TM_ABORT() else back_off()
7: end while
8: v = Memory[addr]
9: TempSet = ∅
10: while LocalTS < GlobalTS.acquire() do
11: TempSet.unite(CommitQueue[LocalTS])
12: LocalTS = LocalTS + 1
13: end while
14: if MissSet != ∅ || ReadSet.Interset(TempSet) != ∅ then
15: MissSet = MissSet.Unite(TempSet)
16: if MissSet.Query(addr) then
17: TM_ABORT()
18: end if
19: end if
20: ReadSet.Insert(addr)
Procedure TM_WRITE(var, addr)
21: WriteSet.Insert(addr)
22: RedoLog.Insert(var, addr)
ValidTS. In this case, it copies current TempSet and future write
sets of committed transactions to a miss set (Figure 8 (c)) for missed
updates since ValidTS. If a transaction reads an address in miss set,
it cannot maintain a valid snapshot and should abort (Figure 8 (d)).
Algorithm 1 shows the detailed algorithm for transactional read
and write during the execution phase. Different conditions of line
14 corresponds to various scenarios in Figure 8. Since the set intersection on bloom-filter signatures features a sharp rise of false
positivity after recording eight elements, the read set summarizes
a signature for every subset of eight addresses. If the signature
of the whole read set overlaps with TempSet, the transaction iterates signatures in each sub-set for more accurate intersection with
TempSet. In this way most conflict resolution are conducted with
an time complexity of O(1). There is only a small chance of an O(r)
(r is the size of read-set) overhead when the miss set is empty and
the intersection between TempSet and the read set is non-empty.
When a transaction finishes execution, a read-only transaction
will be committed directly. On the other hand, a transaction with
a non-empty write set has to be validated by out-of-core FPGA to
ensure transactional semantics with regard to the other transactions. A transaction sends its read set and write set along with the
ValidTS to the FPGA and waits for validation. A transaction’s read
set and write set are transferred in terms of address rather than
signature, so that the query operation on signatures can be used
to minimize the possibility of false positivity of conflict detection
on FPGA. The FPGA records the history of committed transactions
with two signatures (one for read set and the other for write set)
per transaction so that an upper bound of required resources can
be determined a priori.
918
FPGA-Accelerated Optimistic Concurrency Control for Transactional Memory MICRO-52, October 12–16, 2019, Columbus, OH, USA
When the FPGA decides that a transaction can be committed,
it pushes the ready-to-commit transaction into a queue. Before
committing, a transaction publishes its signature to the update set
(Figure 8 (a)), which serves as a commit-time locking on updating
addresses (line 5 of Algorithm 1). Therefore, isolation between committing and executing transactions is preserved, since no partial
results of committing transactions are observed. Multiple transactions can be committed concurrently, as long as no write-write
conflicts are detected among them by FPGA. A transaction will
increment and release the GlobalTS after commitment. Thus, atomicity on the CPU-side is guaranteed since a transaction’s updates
only become visible to other transactions after it commits.
This CPU-side design is specialized for speculation in loop parallelization, which is the programming model used in STAMP benchmark suites. As a result, the need for strong atomicity [20] is obviated since all codes in parallelized loops could run inside transactions. Modifications such as stall before non-transactional codes
can be added to ROCoCoTM if strong atomicity is preferred. Nevertheless, the ROCoCo algorithm on FPGA-side is general enough
to accommodate all programming models of TM.
6 EVALUATION
In this section, we report the evaluation results of ROCoCoTM. The
experiments are designed to answer the following questions.
(1) Does the ROCoCo algorithm attain a lower abort rate than
mainstream CC algorithms (section 6.1)?
(2) Does ROCoCoTM perform better on the STAMP benchmark
suites on commodity systems than established STMs and
HTMs (section 6.2 and section 6.3)?
(3) Does the centralized validation mechanism on FPGA constitute a bottleneck of ROCoCoTM (section 6.4)?
(4) What is the overhead of ROCoCoTM in terms of FPGA resources (section 6.5)?
6.1 Micro-Benchmark for CC Algorithms
To isolate the impacts of the concurrency control from those of other
components in a TM system, we use memory traces extracted from
a simple synthetic micro-benchmark similar to EigenBench [24]
to test three concurrency control algorithms: 2PL, TOCC, and the
ROCoCo algorithm proposed in this work. The functionality of
the micro-benchmark is to emulate transactions with a random
set of array accesses. The array consists of 1024 memory locations.
Each transaction accesses N memory locations with 50% read and
50% write. Given every two transactions, the possibility of at least
one collision on memory locations is (1 − (1 − N/1024)
N ). In this
experiment, we set N = 4, 8, 12, ...32, corresponding to a collision
rate of 1.5%-63.8%. Fifty traces are generated with varying random
seeds for each collision rate. Then we assume T transactions are
executed concurrently. In other words, the tentative updates of the
last T transactions, no matter they commit or not, are not visible
to current transactions. We test two cases, T = 4 and T = 16, to
approximate four and sixteen concurrent threads, respectively.
Figure 9 shows the experimental results. Compared with 2PL
and TOCC, ROCoCo achieves the lowest abort rate in all scenarios.
In the 4-thread cases, ROCoCo is only slightly better (a reduction
of up to 8.6%) than TOCC, since the possibility for a transaction to
Figure 9: Abort rate to collision rate of the three CC algorithms for different number of concurrent threads, i.e. T = 4
(left) and T = 16 (right)
neglect the updates of concurrent transactions (i.e. write-after-read
dependency in section 3.1) is low. Hence, fewer transactions need to
be rearranged against the timestamped order in 4-thread cases than
16-thread cases. Nevertheless, both OCC algorithms enables considerable reduction of the abort rate over 2PL. With the 16-thread
simulation targeting a modest number of cores, ROCoCo shows
up to 56.2% and 20.2% lower aborts with regard to 2PL and TOCC,
respectively, at a collision rate of 22.3%. Thus, under low or medium
collision rate with a high amount of concurrency, over-serialization
introduced by the timestamped order of strict serializability is not
negligible for the OCC algorithm, which can be effectively circumvented by the ROCoCo algorithm. As the collision rate increases to
over 50%, the possibility of forming dependence cycles among 16
threads rises abruptly and the three algorithms perform similarly.
6.2 Experimental Setup on HARP2
We evaluate the performance of ROCoCoTM with STAMP benchmarks running on the Intel HARP2 Platform [26], an experimental server featuring in-package integration of a 2.4 GHz 14-core
Haswell Xeon processor (at most 28 concurrent threads with hyperthreading) and an Arria 10 FPGA (10AX115U3F45E2SGE3). The processor and FPGA are interconnected with a CCI (Cache-Coherent
Interface) interface [27], which greatly reduces the communication latency and increases the bandwidth. Both CPU and FPGA
share the Last-Level Cache (LLC) of CPU. The round-trip latency
of transferring a cacheline between CPU and FPGA is measured to
be less than 600 ns8
through the low-latency channel built upon
QPI, which is several orders of magnitude smaller than the latency
of FPGA as discrete PCIe accelerating card. Such in-package integrated platforms are preferable for applications with fine-grained
CPU-FPGA interactions such as TM systems.
For the STAMP benchmark suite, we choose TinySTM (v1.0.4)
as the baseline STM, as it outperforms a number of STM and HTM
systems on STAMP in recent evaluations [14, 48]. We use a configuration that is similar to ROCoCoTM, which is commit-time
locking (lazy conflict detection) with write-back of tentative states
on commit (lazy version management). Evaluations of TinySTM
on HARP2 show no significant difference between commit-time
8Around 200 ns for read-hit to LLC on FPGA, and less than 400 ns for write back to
LLC from FPGA. In contract, the de facto PCIe interconnect for ASIC accelerators
incur a round-trip latency of over 1us.
919
MICRO-52, October 12–16, 2019, Columbus, OH, USA Li and Liu, et al.
Figure 10: Speedup (solid line, left y-axis) with regard to sequential execution and abort rate (dashed line, right y-axis)
under the varying number of threads ({1, 4, 8, 14, 28} on the xaxis) in the STAMP benchmark suite. Abort rates attributed
to FPGA in ROCoCoTM is drawn as dotted lines.
locking and the default encounter-time locking. We implement an
HTM based on Intel TSX. As TSX will trigger abort under various
indeterministic micro-architectural conditions, a transaction will
fall back to use a global lock if it aborts for too many times. This
fallback path is necessary due to the best-effort nature of TSX. Individually tuning the retry policy for each benchmark will result
in better performance, but it is impractical for common cases. So
we stay with a constant retry policy and find that the 4-time retry
performs best on HARP2. All benchmark programs are compiled
with GCC (v5.4.0) -O3 and tested with the respective largest input
dataset.
6.3 Performance on STAMP
Figure 10 shows speedups and abort rates of executing STAMP
benchmark applications with TinySTM, TSX and ROCoCoTM, respectively. Speedups depicted on the left y-axis are relative to the
sequential baseline of STAMP. Abort rates are calculated as the
ratio of the number of aborted transactions over the total number
of executed transactions, which is depicted on the right y-axis (note
the y-axis for the abort rate is inverted). To show how out-of-core
validation contributes to aborts in ROCoCoTM, the abort rate on
FPGA-side is explicitly depicted as dotted lines. We exclude the
bayes benchmark due its high variability.
The first observation is that ROCoCoTM scales better than TinySTM
and TSX. In the case of 14-thread9
, ROCoCoTM outperforms TinySTM
and TSX by 1.41x and 4.04x in geomean, respectively. While for
28-thread, ROCoCoTM achieves a geomean speedup of 1.55x and
8.05x to TinySTM and TSX, respectively. Considering these two
cases, it seems that the centralized validation mechanism on FPGA
has less impact on performance than the cache thrashing due to
hyper-threading.
For TSX, we can observe the avalanche of aborts when concurrency reaches certain thresholds for all applications10, especially for
28-thread ssca2. This can be attribute to TSX’s eager conflict detection and eager version management, where an aborted transactions
will cause more transactions to abort in a chain. Although TSX
attains the best performance at 4-thread cases, due to the booming
abort rate, it performance fails to scale up to 28 threads.
On the other hand, when considering the addition of cache
thrashing from 14 threads to 28 threads, ROCoCoTM can scale
better than TinySTM since it exhibits smaller memory footprints
with the bloom-filter signatures. In some cases ROCoCoTM and
TinySTM exhibits similar abort rate since ROCoCoTM adopts the
TSA algorithm from TinySTM on CPU-side. As indicated by the
dotted line for aborted transactions on FPGA-side, most aborts of
ROCoCoTM fails fast on CPU, without going through the validation process on FPGA. Besides, transactions with empty write sets,
which accounts for a large percentage of transactions in genome
and intruder, will commit directly on CPU-side. There optimizations successfully reduce performance overhead of ROCoCoTM in
there cases where ROCoCoTM and TinySTM have similar abort
rate .
9We have to alter the default log2 barrier of original STAMP to a pthread barrier
to enable 14- and 28-thread tests. Such modification leads to slightly and similar
performance loss for all TMs at 8-thread.
10the ceiling of TSX abort rate is 83.3% since each transaction retries at most 4 times
before acquiring a global lock as a fallback
920
FPGA-Accelerated Optimistic Concurrency Control for Transactional Memory MICRO-52, October 12–16, 2019, Columbus, OH, USA
Particularly, the workloads of labyrinth and yada are considered more transaction-friendly, since they involve pointer-chasing
on concurrent data structures with non-negligible conflict rates.
These conflicts can only resort to transactions. Whereas conflicts
induced by sharing atomic counters or dynamic buffers in kmeans
and intruder can be resolved by other programming constructs [48].
ROCoCoTM achieves noteworthy lower abort rate than that of
TinySTM in labyrinth and yada. In this way ROCoCoTM outperforms TinySTM on high-contentious applications with reduced
abort rates.
Another point to note is that ROCoCoTM incurs a higher performance penalty than TinySTM in 1-thread case. For 1-thread applications, TinySTM outperforms ROCoCoTM by a factor of 1.32x.
This is because TinySTM never needs to resolve a conflict or validate a transaction with only one thread. As ROCoCoTM still has to
validate read-write transactions by out-of-core FPGA, the communication latency dominates the overhead. However, the overhead
becomes less prominent as the number of transaction increases.
With an increased number of threads, concurrent transactions will
trigger the conflict resolution and validation much more frequently
for both TinySTM and ROCoCoTM. Since ROCoCoTM resolves conflicts by bloom-filter signatures and offloads the validation process
to FPGA, the amortized overhead seems to be lower than that of
TinySTM in cases of 14 and 28 threads.
One exception to this trend is ssca2, which features an enormous
number of short transactions with low contention rate. Accordingly,
its scalability is limited by the overhead of maintaining transactions
rather than the contentious memory accesses. While ROCoCoTM
maintains less metadata, its amortized overhead for each transaction
is increased by out-of-core communications. Such an overhead
makes ssca2 scales poorly on ROCoCoTM.
6.4 Amortized Overhead of Validation
To quantitatively study the potential bottleneck of centralized validation, we instrumented the TinySTM and ROCoCoTM to report
the time spent in validation. Since TinySTM is configured to be
commit-time locking, a dedicated validation phase before transactions’ commit is required, where the CPU goes over all timestamped objects in read set. The amortized validation overheads per
transaction for some benchmarks are shown in figure 11. The pertransaction overhead stays below one micro-second for all cases
in ROCoCoTM. Thus, we can safely conclude that the centralized
validation bottleneck can be avoided by pipelining on FPGA. On
the other hand, with its huge read set during execution, labyrinth
incurs a larger amortized overhead on TinySTM than that of ROCoCoTM. With a hardwired bloom-filter based validate mechanism,
the amortized overhead of ROCoCoTM is insensitive to the size of
read set.
6.5 Resource Consumption on FPGA
In the current implementation of ROCoCoTM on HARP2, its FPGA
component is clocked at 200MHz, where the 512-bit bloom filter is
the critical path. Since ROCoCoTM are fully-pipelined, it consumes
113485 (62.9%) registers, 249442 (58.39%) ALMs, 223 (14.7%) DSPs
(for hashing), and only 2055802 (3.7%) BRAM bits. These BRAM
bits are mainly used for storing historical signatures.
Figure 11: Per-transaction validation overhead measured in
micro-second for some STAMP benchmarks.
More accurate bloom-filter is possible under current resource
consumption. However, even though we extend the bloom-filter
signatures to 1024-bit at the cost of lower clock frequency, no
noteworthy improvement on the abort rate can be observed, which
proves that our quantitative analysis on bloom filter stands. With
the incoming Stratix 10 FPGA devices featuring low cost pipeline
registers [38], ROCoCoTM may operate at higher frequency, leading
to lower out-of-core validation overhead.
7 CONCLUSION
In this paper we study transactional semantics and CC algorithms
with a new formalization based on the order theory. Based on
this formalization, we prove mainstream OCC algorithms can at
best provide strict serializability and propose a centralized OCC
algorithm named ROCoCo. We implement ROCoCoTM, a hybrid
TM with out-of-core hardware validation, for fast-growing CPUFPGA platforms,.
This work can be extended in several directions. From a programming perspective, there are still a vast number of in-between semantics besides what we list in Figure 3. For example, there are many
rigorously proved relaxed consistency models residing between
quiescent and sequential consistency in multi-processor designs. It
is appealing to formalize these semantics with the axiom-based semantics to provide insights for other transactional systems. At the
algorithm level, it is intriguing to study non-greedy CC algorithms
for the avoidance of sub-optimal aborts. At the implementation
level, it is worth trying to apply ROCoCo to transactional systems
with a centralized control unit, such as directory-based HTMs.
