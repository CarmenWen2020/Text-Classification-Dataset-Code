Fig. 1. Overview of the proposed holographic near-eye display: (a) photograph of the prototype and (b) pupil-shifting holographic optical element for eye-box
expansion. (c) Photographs of the expanded eye-box consisting of switchable exit-pupil arrays, for each color channel. (d) Photograph of an augmented reality
display result captured using the benchtop prototype.
Holographic displays have great potential to realize mixed reality by modulating the wavefront of light in a fundamental manner. As a computational
display, holographic displays offer a large degree of freedom, such as focus
cue generation and vision correction. However, the limited bandwidth of
spatial light modulator imposes an inherent trade-off relationship between
the field of view and eye-box size. Thus, we demonstrate the first practical
eye-box expansion method for a holographic near-eye display. Instead of
providing an intrinsic large exit-pupil, we shift the optical system’s exitpupil to cover the expanded eye-box area with pupil-tracking. For compact
implementation, a pupil-shifting holographic optical element (PSHOE) is
proposed that can reduce the form factor for exit-pupil shifting. A thorough
analysis of the design parameters and display performance are provided.
In particular, we provide a comprehensive analysis of the incorporation
of the holographic optical element into a holographic display system. The
influence of holographic optical elements on the intrinsic exit-pupil and
pupil switching is revealed by numerical simulation and Wigner distribution
function analysis.
CCS Concepts: • Hardware → Emerging optical and photonic technologies;
Displays and imagers; • Computing methodologies → Mixed/augmented
reality;
Additional Key Words and Phrases: Holography, near-eye display, eye-box
expansion, computational displays, holographic optical elements
1 INTRODUCTION
Holographic displays can provide natural monocular focus cues
and a high resolution as well as vision-correction ability, making
them strong candidates for future near-eye displays. To illustrate the
possibilities as a near-eye display, various related academic studies
have been performed recently. However, many issues remain to
be resolved for successful commercialization as near-eye displays.
Speckle noise, heavy computation load, and the limited bandwidth of
the spatial light modulator (SLM) are typical issues for implementing
near-eye holographic displays.
In particular, the limited bandwidth of the SLM imposes an important trade-off relationship between field of view (FOV) and eye-box
size. The product of the FOV and the eye-box size made by the
system must be constant as étendue [Brooker 2003], which is determined by the size and pixel pitch of the SLM. Currently commercialized products have a variation of FOV depending on the display
method of the product. Although it is difficult to define an optimal
FOV, it is a shared goal to achieve as large an FOV as possible for
more immersive user experiences. Usually, enlarging the FOV requires a trade-off with other design factors, such as resolution or
form factor. In the case of a holographic display, enlarging the FOV
is a problem directly related to the trade-off relationship with the
eye box. When using the 2k SLM, which is easily available on the
market, the typical eye-box size is approximately 1 mm. Therefore,
the pupil position of the user must be fixed at a pin-point and it is
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
195:2 • C. Jang, K. Bang, G. Li, and B. Lee
difficult to be used as a practical wearable display application. Since
the eye-box issue is a physically constrained problem, a solution
requires not an incremental improvement but a new optical design
and display method.
In this paper, a novel method is proposed to increase the eyebox of a near-eye holographic display without fundamentally degrading the advantages of the display performance or form factor.
Figure 1 shows the overview of the display system proposed in
this section. The system consists of compact elements such as a
lens holographic optical element (HOE), fiber laser, a micro-electromechanical-system (MEMS) mirror, an SLM, and an additional HOE
for pupil shifting. The key of the proposed method is to devise a
system that can move the position of the exit-pupil to tweak the
constraints imposed by étendue. In addition, the effects of the holographic optical element on the display system are analyzed in a
comprehensive manner through simulation when used as an image
combiner or an eye-piece for a holographic display. The behavior
of the volume hologram is not straightforward to describe with
simple diffractive optics or ray optics simulation methods. Thus far,
there have been only limited analyses of the effects of the volume
hologram, although many studies have incorporated HOEs into a
near-eye display. We clarify these effects using a novel numerical
analysis incorporating the volume hologram and Wigner distribution function analysis. Finally, we provide the design method
and related analysis of the proposed eye-box expansion method
and demonstrate the prototypes and display results. The specific
contributions offered by this paper are as follows:
• Eye-box expansion method of a holographic near-eye display
and design of a novel holographic optical element for exitpupil shifting.
• Quantitative trade-off and design-space analysis for eye-box
expansion.
• Wavefront analysis of aberrations caused by a holographic
optical element and the numerical calculation method for
generating a corrected computer-generated hologram (CGH).
• The influence of holographic optical element eye-piece on
intrinsic exit-pupil and pupil switching is revealed by Wigner
distribution function.
2 RELATED WORKS
2.1 Holographic displays
Holographic displays are believed to be the ultimate 3D displays
for satisfying high image quality and natural focus cues [Yaraş et al.
2010]. However, there are some difficulties in implementing ideal
holographic displays, such as speckle noise, complex modulation,
computational load, and SLM bandwidth as depicted below.
Studies have sought to overcome the speckle issue, which is a
classic problem of digital holography. Time multiplexing methods
or pixel separation encoding methods have been studied for speckle
reduction [Mori et al. 2014; Takaki and Yokouchi 2011]. A partially
coherent light source can be used to suppress speckle by reducing
the temporal coherency [Deng and Chu 2017].
Commonly available SLMs can support phase-only or amplitudeonly modulation, although complex modulation of light is desired for
accurate expression of image gradation. Therefore, phase retrieval
algorithms [Fienup 1982; Georgiou et al. 2008] or double-phase
encoding methods have been studied [Hsueh and Sawchuk 1978].
Alternatively, a pair of SLMs or a grating can be used for complex
modulation [Gao et al. 2017].
In addition, excessive computational complexity has made it difficult to achieve real-time operation of a holographic display. However, in recent years, various efficient computation techniques have
been studied [Park 2017], in addition to improvements of GPU performance and CGH generation algorithms. Look-up-table based
methods have been proposed to speed up the calculation [Pan et al.
2009]. Entire pipelines from image rendering to CGH generation
have been constructed to achieve fast real-time computation [Maimone et al. 2017; Shi et al. 2017]. In particular, Maimone et al. [2017]
have demonstrated high-quality imagery as a compact holographic
near-eye display and proposed a linearly separable convolution
method with a real-time varying convolution kernel. Light field
based hologram rendering techniques have been studied for fast
rendering and correct intra-occlusion effects [Shi et al. 2017].
The limited bandwidth of SLMs has been an important bottleneck
of holographic display technology that limits performance. In particular, the limited SLM bandwidth imposes a critical trade-off between
FOV and eye-box size for near-eye displays. Some studies have proposed to enhance the bandwidth of holographic display systems [Li
et al. 2015]. However, the eye-box issue remains unresolved, as will
be more elaborated in the following paragraph.
2.2 Eye-box expanding methods
In an optical system, the product of the area through which light
passes and the spreading angle of the light is preserved, which
is known as étendue or Lagrange invariant [Brooker 2003]. The
étendue of a holographic display is decided by the size and pixel
pitch of the SLM. As a result, the product of FOV and exit-pupil size
is limited by the bandwidth of the SLM, and the size of the intrinsic
exit-pupil E is determined as follows:
E =
Lλ
2p sin(FOV /2)
(1)
where L is the size of the SLM, p is the pixel pitch of the SLM, and
λ is the wavelength of light source. For the bandwidth of 2k or 4k
SLMs currently available in the market, the size is slightly more
or less than two millimeters to provide 45◦ of FOV. Therefore, the
exit-pupil of the holographic near-eye display must be very small
to provide satisfactory FOV. A holographic near-eye display that
satisfies large FOV and large eye-box size has not been introduced.
There are some tricks to tweaking the trade-off relation of étendue to expand the eye-box size. See-real has developed a technology
that changes the viewing window by applying a directional backlight and eye-tracking technology to a large-scale flat panel-type
holographic display [Häussler et al. 2009]. Similar approaches have
been studied in other 3D displays, such as compressive light field
or depth fused displays [Maimone et al. 2014; Park et al. 2015]. In
near-eye displays, waveguide-type displays replicate the exit-pupils
for eye-box expandsion [Levola 2006; Yu et al. 2017], however, the
replicated exit-pupils can only have focus distance at infinite distance intrinsically. To provide focus cues, exit-pupil steering has
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
Holographic Near-eye Display with Expanded Eye-box • 195:3
been demonstrated as a light field projection-type display by incorporating pupil-tracking [Jang et al. 2017]. However, the optical
system for exit-pupil shifting was bulky due to the size of the steering mirror, and exit-pupil shifting for a holographic display has not
been introduced. In this paper, we present a compact holographic
near-eye display system with an expanded eye-box.
2.3 Imaging systems incorporating holographic optical
elements
There have been many attempts to incorporate HOEs into imaging
and display systems because of the unique properties of volume
gratings. In general, HOEs provide high selectivity/transparency
and design flexibility, but also unwanted aberrations [Close 1975].
Sinha et al. [2004] proposed a study that involved incorporating
volume grating into the imaging system. An off-axis lens HOE can
be used as a see-through HUD system by designing aberrationcorrecting systems with lenses [Peng et al. 2014]. For the case of a
holographic display, the compensation becomes guaranteed since
the holographic display has an intrinsic ability to correct the optical
aberration [Li et al. 2016; Maimone et al. 2017; Yeom et al. 2015].
However, research has been limited to correcting aberrations using
an approximation or manual correction. There has been only limited comprehensive analyses of the effects of the volume hologram
when it is combined with a holographic near-eye display system.
This paper offers a more analytical understanding of the effects of
incorporating the HOE into a near-eye display system based on
ray-tracing and Wigner distribution function analysis.
3 PRINCIPLE
The proposed system is largely based on the projection-type neareye display utilizing the off-axis lens HOE as an image combiner
[Jang et al. 2017; Maimone et al. 2017]. As shown in Figure 2 (a), the
spherical light wave form S1 is incident from the oblique direction,
and then diffracted by the optical element into an on-axis spherical
wave, which is focused into a point E1. The desired hologram image
can be displayed by loading complex wavefront information on
the SLM in the middle of the optical path, and E1 then forms an
exit-pupil. If the observer’s eye-pupil is located correctly on the exitpupil, the observer can see the full image that the display system can
represent. The novelty of this paper is to explore the possibilities of
exit-pupil shifting/switching in holographic near-eye display design
to expand the eye-box. In this section, the exit-pupil shifting method
is proposed based on the holographic near-eye display that utilizes
an off-axis lens HOE with a spherical reference wave.
3.1 Exit-pupil shifting for an off-axis lens HOE
In Figure 2 (a), the volume hologram provides maximum diffraction
efficiency to light with a certain incidence angle and wavelength, or
phase-matched light. In addition, within a certain degree of tolerance
for the incidence angle or wavelength, the HOE still behaves like
a concave mirror without excessive efficiency degradation. Within
this tolerance, it is possible to control the incidence angle of input
light to create a shifted exit-pupil as shown in Figure 2 (b). When
this exit-pupil shifting is performed in accordance with tracking
of the observer’s eye pupil position, the eye-box can be effectively
Fig. 2. Basic principle of exit-pupil shifting for a lens HOE. (a) The lens HOE
forms an intrinsic eye-box E1 with the reference wave illuminated from S1.
(b) When the point light source is shifted, the exit-pupil is shifted from E1 to
E2. (c) Simplified conceptual diagram of the exit-pupil expandsion method:
Formation of exit-pupil arrays using a point light source array.
Fig. 3. Configuration of proposed pupil shifting HOE: (a) Optical fabrication
stage and (b) operation of PSHOE.
expanded to cover a larger area than the intrinsic exit-pupil. Figure 2 (c) shows a simplified conceptual diagram of the exit-pupil
expandsion method. Switchable point light sources in different positions will generate corresponding exit-pupils in different positions
to cover the eye movement of the user.
3.2 Pupil-shifting HOE (PSHOE)
To implement switchable point light sources, an LD array or LED
array may be used or a mechanically moving single light source can
be implemented. However, it is difficult to achieve a compact form
factor using such approaches and mechanical movement should be
minimized for a wearable device.
As an alternative, this study proposes a lens-array HOE that
operates with an oblique angle. As shown in Figure 3 (a), a signal
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
195:4 • C. Jang, K. Bang, G. Li, and B. Lee
Fig. 4. Design example of a compact prototype of the proposed system.
wave is formed with light incident on a lens array obliquely, and
a spherical wave from a point light source at a specific position is
recorded as a reference wave. In this way, numerous lenslet hogels
(h1, h2, · · · , hn) can be formed that generate point light sources
with shifted locations. In the design, the HOE can create a light
source array within a narrow space by using a single light source
and only changing the direction of the laser beam. At the same
time, it is possible to set the direction or numerical aperture of the
spreading spherical wave of each light source array. An additional
lens is placed so that the spherical wave generated by each point
light source is collected at a certain distance, to use the maximum
area of the SLM with the limited numerical aperture of a lenslet. By
setting the reference wave as a spherical wave, the optical path can
be reduced compactly and operated using a single MEMS mirror.
This HOE is named the pupil-shifting HOE (PSHOE) for simplicity.
Figure 3 (b) shows the operation of the PSHOE. A thin laser beam
generated by a fiber-coupled laser is deflected by a small MEMS
mirror incident on the PSHOE. Then the laser beam selects a hogel,
which is a lenslet hologram generating a spherical wave.
4 IMPLEMENTATION
Figure 4 shows a design example of a compact near-eye holographic
display prototype that performs pupil-shifting. The beam path is
folded by half mirrors, and the point light source array is replaced
with the PSHOE. Notably, the system can be implemented by using
only compact components without a large-aperture lens. The laser
beam is deflected by a MEMS mirror and is then incident on the
PSHOE. The desired lenslet hologram can be selectively illuminated
to form a point light source at the desired position. The size of the
MEMS mirror and the fiber laser can be made sufficiently small to
achieve a compact form factor.
Fig. 5. Optimization of the angle of the point light source array plane to
minimize the exit-pupil aberration. The light source array angle indicates
the angle between normal vectors of the lens HOE and the PSHOE. An
optimal angle of approximately 90◦
is chosen.
4.1 Parameter design
Position of the point light source array. Assuming the point light
source array has a planar structure, a simulation is conducted to
determine at which angle the point light source array should be
arranged to minimize the exit-pupil aberration. Volume hologram
theory is used to predict the precise behavior of the HOE. The simulation is fundamentally based on a coupled wave theory employing
the grating vector cloud method [Uchida 1973] [Supplementary A]
and is implemented as a ray-tracing simulation for fast calculation
[Supplementary B]. The details of the simulation for parameter design is presented in [Supplementary C]. As a result of the simulation,
we find that there is an optimum angle of PSHOE to minimize the
exit-pupil aberration for shifting.
Figure 5 shows the maximum size of the pupil aberration according to the PSHOE angle setting. If the distortion of the pupil
becomes severe at a certain position, the image cannot be properly
transmitted to the user’s pupil because of vignetting. The result
shows that the optimal angle is approximately 90◦
. Since this angle
is not greatly influenced by the scaling, the point light source array
angle is determined first before other parameters.
Magnification of the HOE eye-piece and eye-relief. Next, the magnification and eye-relief of the HOE are determined by setting the
point source distance of the reference beam. The magnification of
the lens HOE is related to the size of the eye box that can be formed.
To increase the magnification, it is necessary to increase the focus
distance of the signal wave. However, increasing the focus distance
of the signal wave will make the eye-relief too large, and the form
factor will be traded for the eye-box size. Figure 6 shows the design
space obtained by the simulation. In our design, the point source
distance should be larger than 70 mm to secure the optical path, and
we set the eye relief smaller than 40 mm for the form factor. The
resulting specification is indicated in Figure 6. The magnifications
are 0.32 along the horizontal direction and 0.7 along the vertical direction, which means that 1 mm of displacement in the point source
will shift the exit-pupil by approximately 0.32 mm. In general, the
horizontal direction imposes the dominant design limitations since
the HOE eye-piece has obliquity only in the horizontal direction.
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
Holographic Near-eye Display with Expanded Eye-box • 195:5
Fig. 6. Parameter optimization of horizontal magnification and vertical
magnification according to the eye-relief length and point source distance.
Magnification is defined as the ratio of displacement between the point
source and each sagittal curve that is generated by the lens HOE.
Therefore, further analysis and assessments will mainly focus on
the horizontal direction.
SLM position. To modulate the wavefront and display the hologram image, the SLM should be located between the light path of
the light source and the lens HOE. The SLM position is decided to
cover the light emitted from the light source. The center position of
the SLM is decided as 40 mm from the point light source.
Formation of the resultant exit-pupil array. Finally, the shape of
the resultant exit-pupil array is simulated to show the resultant
formation of the eye-box. In Figure 7, ray-tracing simulation results
are presented to show the shape of the exit-pupils noted as different
colors. The shape of each exit-pupil varies according to its location.
By imposing the condition that the exit-pupil size should be smaller
than the size of the minimum eye-pupil of 2 mm, approximately a
total of 7 mm of eye-box size along the horizontal axis is supported
with the design specification. Including the nearly 2 mm of intrinsic
minimum eye-box size, the system can cover approximately 9 mm of
eye movement. The actual exit-pupil array is much denser; however,
only 25 exit-pupils are indicated for simplicity.
4.2 Optical prototyping
For implementation, a compact prototype and a benchtop version
prototype were produced based on the same design specifications.
The compact prototype was designed to verify the overall design
form factor and fast pupil shifting function. The purpose of the
benchtop version was to eliminate some image quality degradation
factors, such as a DC term and wavefront uniformity of the light
source. For both prototypes, the design factors, such as FOV or size
of the eye-box, were identical.
Lens HOE fabrication. The HOE is designed to have a focal length
of 38 mm and a point source distance of 80 mm. Since exit-pupil
shifting requires a large angular tolerance of the HOE, we used a
relatively thin volume hologram material (a photopolymer with
a thickness of 4 µm, provided by Covestro) [Berneth et al. 2011].
The The HOE is fabricated by recording an interference pattern in a
photopolymer on the floating optical table. To fabricate the full-color
lens HOE, a wavelength multiplexing method is used by illuminating
R, G, and B lasers (660 nm, 532 nm, 473 nm) simultaneously on the
photopolymer [Hong et al. 2014] [Supplement A.3] .
Fig. 7. Ray-tracing simulation of eye-box formation. (a) The light generated
from the point-source array is indicated by the red color, and the light
diffracted by the HOE is indicated by the green color. Green dots show the
point source array. The blue dotted line indicates the exit-pupil plane. (b)
The intersection of the rays at the exit-pupil plane is illustrated to show the
location and shape of the exit-pupil array.
PSHOE fabrication. The PSHOE is fabricated using the configuration in Figure 3 (a). A PMMA lens-array (Fresnel Tech) is used to
generate the point source array. Each lenslet has a focal length of 3.3
mm and a pitch of 1 mm. The focusing lens has a focal length of 150
mm, and the reference wave has a focal length of 30 mm. The oblique
angle is designed as 45◦
. For fabrication, index-matching oil and
anti-reflection coated glass is used to suppress unwanted reflection.
Figure 1 (b) shows the fabricated PSHOE. When viewed from the
oblique angle, a point source array is formed with spherical wave
illumination as designed. The fabricated PSHOE is approximately
24 mm by 22 mm and consists of more than 500 point sources with
1 mm pitch.
Compact prototype implementation. The compact prototype is
shown in the Figure 8 (a). A compact full-color light source is implemented by coupling three wavelengths of R, G, and B (638 nm, 520
nm, 450 nm) into a single mode fiber and attaching a lens to the end
tip. The aperture size of the MEMS mirror (Mirrorcle, DK-105) is
1.2 mm. The precision of the mechanical tilt of the MEMS mirror is
within 10 µrad, and the angular speed of the MEMS mirror is greater
than 1000 rad/s. The large-angle step-response settling time is less
than 100 µs, providing a sufficiently small latency for exit-pupil
switching. A 2k SLM (Pluto, Holoeye) is used that operates at 60 Hz.
The pupil-tracking camera is located off-axis from the user’s sight.
The framerate of the camera is 120 Hz with 0.6◦ of gaze precision
(Pupil labs). The ellipse-detecting algorithm gives approximately 3
ms of latency according to the manufacturer [Kassner et al. 2014].
The devices are synchronized by a main computer and operate as a
color sequential scheme. The casing of the prototype is produced
using a 3D printer. Overall, a compact form factor can be achieved
as shown in the figure.
Benchtop prototype implementation. Figure 9 shows the benchtop
version prototype. A 4k SLM (JD8714, Jasper) is used that operates
at 60 Hz. For the benchtop version, the DC components of light
generated by the SLM are filtered using a 4-f imaging system, and
the PSHOE is replaced with an objective lens attached to a linear
stage. This change was made because the wavefront uniformity of
the point light sources generated by the PSHOE is not clean enough
since the lens-array used to fabricate the PSHOE could not provide
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
195:6 • C. Jang, K. Bang, G. Li, and B. Lee
Fig. 8. Photographs of the (a) compact prototype and (b) benchtop prototype.
the desired optical quality. An objective lens (20X, Olympus) with a
linear stage is used for point light source shifting, and a 4-f system
is built using lenses with an f -number of 1.4 (Nikon). The DC filter
is located at the imaged point source. The distance between the
focus point of the objective lens and the SLM is set to the same
specifications as the compact prototype. Also, the specification of
the Lens HOE is the same.
5 ANALYSIS FOR EXIT-PUPIL SHIFTING OF THE
HOLOGRAPHIC NEAR-EYE DISPLAY
This section analyzes the effects of pupil-shifting with the lens
HOE on the characteristics of the display system. The purpose is
to quantify the optical aberration caused by the HOE eye-piece for
numerical compensation and to analyze the Wigner distribution in
the exit-pupil domain. When displaying the hologram with the HOE,
the CGH must be corrected to compensate the wavefront distortion.
Previous studies have focused on correcting the output of an image
by manually correcting the Zernike coefficients [Maimone et al.
2017] or applying a simple correction by using approximation when
the viewing angle is small [Yeom et al. 2015]. However, such methods
have not included numerical simulation of the volume hologram,
and the effect caused by exit-pupil shifting has not been studied.
Therefore, this section quantitatively analyzes how to numerically
calculate and correct aberration caused by the HOE. Lastly, the
supported angular-spatial bandwidth within the eye-box is discussed
using the simulation. The simulation reveals the properties of the
spatially varying bandwidth and FOV change of the system.
5.1 Wavefront analysis of the system using ray-tracing
simulation of the HOE
Wavefront calculation with ray-tracing simulation of the HOE. Let
us assume that the system is displaying a virtual image point at a
certain location in the real-world. From the viewpoint of the observer, a bundle of rays emitted from the point should be reproduced
as a form of spherical wave, on the HOE plane. Since the first order
diffraction of the HOE satisfies the reciprocal property, the input
rays can be obtained that should be incident to the holographic
lens by inverting the output ray bundle. If the HOE act as an ideal
lens, these rays will be in the shape of a spherical wave as well.
However, Bragg mismatch of the HOE will cause aberration and
modify the ray directions. By tracing this ray bundle back to the
SLM, it is possible to extract the wavefront that the SLM should
form. Since a normalized k-vector of each ray can be expressed as a
gradient of the wavefront at the same plane, the target wavefront
can be reconstructed by using Equations 2 and 3 [Supplementary
B] [Harker and O’Leary 2008].
−→k = ∇UT (x,y), (2)
∂UT
∂x
= kx (x,y)/k0, (3)
∂UT
∂y
= ky (x,y)/k0. (4)
Note that the wavefront is defined at the SLM plane (x,y). If the
ray bundle is sufficiently dense, the target wavefront UT that can
image the correct point considering the distortion of the HOE can
be numerically calculated. The wavefront can be converted to the
complex electric field ET as follows:
ET (x,y) = exp {i2πUT (x,y)/λ} . (5)
By dividing the obtained electric field by the electric field of the
light source spread to the SLM, we can calculate the optical phase
to be modulated by the SLM, that is, a sub-hologram for the initial
point image:
Hsub (x,y) = LPF {ET (x,y)/Es (x,y)} . (6)
The US is defined as a spherical wavefront from the light source
point located at (xs , ys , zs ):
US (x,y) =

−→r (x,y, zslm) − −→r (xs ,ys , zs )


, (7)
ES (x,y) = exp (i2πUs (x,y)/λ) . (8)
Here, the sub-hologram is cut by the low-pass filter (LPF ) at cutoff frequency to prevent an aliasing considering the pixel pitch of
the SLM at the wavefront. Figure 9 (c) shows the wavefront and
hologram of the CGH that the SLM should display for a point image
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
Holographic Near-eye Display with Expanded Eye-box • 195:7
Fig. 9. Numerically simulated wavefronts of (a) the target wavefront UT
and (b) the difference of the target wavefront and source wavefront, which
is the wavefront modulation of the SLM. (c) Phase image of the resultant
compensated sub-hologram Hsub .
located at 1 diopter and 0.1 radian from the center of the FOV along
the horizontal direction.
CGH calculation using Zernike coefficient mapping. Theoretically,
it is possible to obtain a whole sub-hologram of every image point
to be displayed in this manner, but performing such ray tracing
and wavefront reconstruction for all points is computationally too
expensive. Thus, for more efficient computation, the Zernike coefficients of the resultant wavefront can be mapped in the 3D space
according to the position of the point source. Generally, distorted
wavefronts can be decomposed into several Zernike functions and
these coefficients gradually change in near-by image points. By calculating the coefficients at tens of sampling points in 3D space, the
continuous mapping function can be obtained by the interpolation
method. As a result, a Zernike coefficient map can be obtained as a
function of position in the displayed image domain.
For a single image point, Uslm can be approximated as a linear
combination of Zernike functions:
Uslm(x,y) =
Õ
j
cjZj(x,y), (9)
where cj and Zj stand for the j
th Zernike coefficients and Zernike
basis function, respectively. Once the calibration map is obtained,
a wavefront can be calculated for a random image point using the
above approximation. A similar method was used in previous work
[Maimone et al. 2017]; the difference is that the Zernike coefficient
map can be calculated numerically in this method.
Here, the construction of the final hologram to be displayed in
the SLM using the above map is described. For the n
th point image
in the displayed image domain located at (xn, yn, zn), Zernike coefficients cjs are calculated from the final mapping functions. Each
sub wavefront is calculated by a linear sum of coefficients and basis
ALGORITHM 1: Automated experimental calibration algorithm
xm, ym ← Preset sampling positions for calibration;
Zj ← Zernike basis functions;
cm j,c ent er ← Initial estimation values for Zernike coefficients;
Ranдej ← Ranдe0,j
;
repeat
Costm,min = inf ;
for each cm j in cm j,c ent er − Ranдej /2 to cm j,c ent er + Ranдej /2
do
Ht ot (x, y) =
Í
m LP F (exp(i
2π
λ
Í
j
cm jZj(x − xm, y − ym)));
Display Ht ot ;
Capture P S Fm;
Costm ← Cost Func(P S Fm);
if Costm,min > Costm then
Costm,min, cm j,min ← Costm, cm j ;
end
end
cm j.c ent er ← cm j,min;
Reduce Ranдej
;
until max(Costm,min) < Costt arдe t ;
Zernike functions Z1, Z2, · · · , Zj
. Since the basis functions are calculated in advance, the wavefront can be calculated by the linear sum
of Zj
. The sub-wavefront is calculated by applying an anti-aliasing
filter LPF , and then converted to the complex field to be summed
up as the final hologram Htot :
Htot (x,y) =
Õ
n
anLPF



exp
©
­
«
i
2π
λ
Õ
j
cj


xn,yn,zn
Zj(x,y)
ª
®
¬



,
(10)
where an denotes the intensity of the n
th image point. In the experiment, hologram calculation is performed off-line using the CUDA
library.
5.2 Experimental verification
The previous section described how to calculate the aberrationcompensated holograms numerically. Using the presented method,
a calibration map can be easily obtained if the optical parameters of
the system are known. In this section, we introduce an automated
experimental calibration algorithm and verify the validity of the
numerically obtained calibration map by comparing the results.
The purpose is not only verification but also fast and accurate calibration. In a practical laboratory environment, various errors may
occur due to misalignment or unexpected aberrations. In this perspective, experimental calibration has advantages of robustness and
accuracy but it typically requires long calibration times. Therefore,
we propose that it is efficient to use both numerical and experimental calibration methods. The numerical results can be used as
an initial guess to reduce the calibration time, and then the automated experimental calibration algorithm will provide reliable and
accurate results.
Calibration algorithm. Our automated experimental calibration
algorithm is based on an n-ary search that finds the combination
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
195:8 • C. Jang, K. Bang, G. Li, and B. Lee
Fig. 10. Resultant Zernike coefficients map of the calibration experiment at
the 0 D plane and center exit-pupil. (a) x-shift, (b) y-shift, (c) defocus, (d)
vertical astigmatism, and (e) oblique astigmatism.
of Zernike coefficients for an optimal PSF narrowing down the
search ranges, as presented in Algorithm 1. A similar method has
been proposed to find the Zernike coefficient combination using
genetic algorithms [Kaczorowski et al. 2015]. However, we found
that genetic algorithms do not always find the optimal solution
after many generations when adopted in our system. The details
of the used algorithm are as follows. Initially, estimated Zernike
coefficients cmj,center are assigned to mmax sampling points over
the entire display area. For each sampling point, the sub-hologram is
generated by linear combination of the Zernike basis functions. The
total hologram Htot is displayed, and the PSFs are captured with
a camera while scanning the Zernike coefficients in the searching
range around the estimated value. A high dynamic range (HDR)
image is obtained through multiple captures using different shutter
speeds. To decide the optimal PSF, the cost function (CostFunc) is
calculated as a weighted sum of the peak intensity, the circularity
of the PSF, and the spread distance from the center of gravity. After
finding the minimum cost within a single search area, the estimated
Zernike coefficients are updated, and the next level of search is
performed within a narrower range.
When high orders of Zernike coefficients and dense search are
required, the scanning method would not be very efficient. However,
we already know from simulation result that astigmatisms are the
dominant factors and numerically calculated results provide a good
initial guess. Therefore, we found that a sufficiently good calibration
quality can be obtained under the following conditions: scanning
Fig. 11. Plots of Zernike coefficients values acquired by experimental calibration (solid line) and numerical simulation (dotted line). The results verify
the validity of the numerical simulation used in the study. (a) Plotted along
the horizontal direction of the FOV within a center exit-pupil. The vertical
angle and depth are fixed as the center and 2 D, respectively. (b) Plotted
along the exit-pupil location with a fixed display image point.
3 Zernike coefficients (vertical astigmatism, defocus, oblique astigmatism) and a searching density of 5 × 5 × 5, which requires a
3-dimensional 5-ary search. The search was performed up to 5 levels. Note that the x and y-shift components do not require scanning.
The number of sampling points was 5 × 5 for each depth plane
(0, 2, and 4 diopters). All sampling points in one depth plane can
be calibrated in parallel because PSFs at different positions can be
acquired in a single capture. As a result, 625 HDR image captures are
required to calibrate one depth plane, which takes approximately 60
minutes. After calibration, the final calibration map is obtained using the linear interpolation method. The visualization of calibration
is presented in [Supplementary D]
Comparison between numerical simulation vs. experimental calibration. Figure 11 shows the fitted result of the calibration for each
Zernike component and shift component. The dominant four components are fitted, such as x-shifts, defocus, and vertical and oblique
astigmatisms, since the coma aberration is small and other higherorder terms are almost negligible. Each axis is the location on the
image captured by the CCD camera representing the FOV. Each
curve is not linear, showing asymmetrical characteristics along the
FOV. The shape and gradient of the curves are dependent on the
specifications of the system, such as the angle of the SLM, the position of the HOE, and the recording conditions of HOE. Figure 11 (a)
shows the comparison of the Zernike coefficient values between the
calibration values obtained using a numerical simulation (indicated
as dotted lines) and experimental calibration result (indicated as
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
Holographic Near-eye Display with Expanded Eye-box • 195:9
Fig. 12. The simulated WDF boundaries at the exit-pupil domain. Each
figure shows the WDF when the exit-pupil is shifted to the (a-b) left, (c-d)
center, and (e-f ) right, respectively. (a), (c), and (e) show the case when the
SLM acts as a simple mirror and (b), (d), and (f ) show the full bandwidth
of WDF, in other words, the spatial-angular support of the holographic
near-eye display system incorporated with a volume hologram.
solid lines), plotted according to the FOV. The FOV indicates the
horizontal location of the image point while the vertical position is
fixed in the center. The numerical simulation results show a significant level of agreement with the experimental results. The results
verify the validity of the numerical simulation used in the study.
Figure 11 (b) plots the Zernike coefficients according to the exitpupil location, with the fixed image point located at the center and
2 D. A reasonable fitting result is obtained, although some error is
observed. The origin of the error could be the misalignment and
optical aberration. The error could also be caused by the high-order
Zernike aberration terms that are not included in the calibration.
5.3 Wigner distribution analysis of the bandwidth
property
The Wigner distribution function (WDF) is a transform that was first
introduced in quantum mechanics, but can also be used to describe
an optical field [Zhang and Levoy 2009]. WDF is defined as follows:
W (x,y) =
∫ 
E

x +
fu
2

E

x −
fu
2
 exp (−i2π fuu)d fu, (11)
where x denotes the spatial domain and u denotes the angular component domain of the optical field. Compared with the Fourier
Fig. 13. Photographs of camera captured retinal PSFs. (a) shows the PSFs
of image points located at different positions, as indicated in Figure 12 (d).
Spatially varying bandwidth results for different sizes of the retinal blurring
and PSF quality. (b) shows the intentionally engineered PSFs with different
shapes of retinal blur. Each PSF is designed to have the shape of a circle,
rectangle, triangle, or star when blurred.
transform, WDF can represent the angular and spatial boundaries
of the optical signal, which makes it a useful tool for analyzing
the bandwidth of the holographic display. Recently, Shi et al. have
used WDF for an analysis of the resolution and DOF of holographic
display [Shi et al. 2017]. In this section, the boundary of the WDF is
numerically simulated, taking the lens HOE eye-piece into account
to explore the spatial-angular support of the proposed system.
WDF of the intrinsic eye-box. The discussion starts with the WDF
of the intrinsic eye-box. If the SLM operates like a simple mirror
without any diffraction pattern, light will be focused on the holographic lens’s original focus point. In this focus point, the range of
the angular frequency components will be the as same as the numerical aperture of the focused light cone. Thus, the WDF will have the
shape of a line segment as shown in the Figure 12 (c). When the SLM
acts as a grating to deflect the light, it induces a phase mismatch
of the HOE and forms a distorted wave in the exit-pupil domain.
In the WDF, it will form a curved segment that contributes to the
bandwidth. To see the total bandwidth produced by the system, the
SLM is assumed to generate quasi-continuous plane waves within
its maximum frequency. When the light is incident from the tilted
angle, the deflection angle of the output plane wave θout has the
following range:
sin−1

−
λ
2p
− sin(θin)

< θout < sin−1

λ
2p
− sin(θin)

, (12)
where θin is the incident angle on the SLM and p denotes the pixel
pitch. The diffraction of the ray bundle for each plane wave on the
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
195:10 • C. Jang, K. Bang, G. Li, and B. Lee
HOE is simulated and summed together to obtain the boundary
of the total WDF as shown in Figure 12 (d). In the simulation, the
specifications of the prototype are used. The pixel pitch of the SLM
is set as 3.74 µm, and the wavelength is set as 660 nm.
The WDF of the expanded eye-box. Figure 12 (a), (b), (e), and (f)
show the variation of the WDF when exit-pupil shifting is applied.
Figure 12 (a) and (e) show the case of the exit-pupil at left (-3.5 mm)
and right (3.5 mm) respectively, when the SLM is a simple mirror.
Each shows a slightly curved line, which represents the aberration
of the exit-pupil shape. In the simulation, the slight eye-relief change
caused by the eye-rotation is also considered. The eye is assumed as
a sphere with a diameter of 25 mm, having its rotation axis at the
center. The full WDFs are presented in Figure 12 (b) and (f) for each
case. The colormap shows the intensity of corresponding spatialangular component. The diffraction efficiency degradation caused
by Bragg mismatch of HOE is also considered. Notably, the WDF
shapes change with some tendencies according to the exit-pupil
positions. In terms of the angular bandwidth, a variation of the FOV
is predicted according to the exit-pupil position. When the exit-pupil
is shifted to a positive location, the entire FOV tends to shift in a
positive direction as well, and vice versa. Although this behavior is
not an intended property, it can be useful for certain applications
since the system can provide more FOV near the center of the fovea
region. Also, the size of FOV also slightly varies according to the
exit-pupils. The maximum value was 52◦
and the minimum was
38◦
in horizontal direction. In general, each exit-pupil provides
approximately 45◦ of FOV in the horizontal direction, as designed.
5.4 PSF engineering based on WDF analysis
A typical holographic display using a common lens produces a rectangular or parallelogram WDF. However, the use of a holographic
lens makes the shape of the WDF irregularly distorted, as shown
in the Figure 12. As a result, a holographic lens is expected to induce two effects: first, the bandwidth changes along the x-axis even
inside the single exit pupil. The change in bandwidth may cause
irregular shaped vignetting when there is a pupil-detection error
[Supplementary F]. To prevent this vignetting, the pupil detection
error should be sufficiently small to ensure that the light enters the
pupil.
Second, the bandwidth of each displayed image point may vary
depending on the position or depth, since the shape of the support
on the WDF is different for every image point. Thus, each image
point will make a different PSF when observed by a user, resulting in slight differences in image quality such as resolution and
brightness. Typically, positive angular components will have an effectively larger numerical aperture that will induce a larger blurring
effect. Figure 13 (a) shows that the captured PSFs located at different
positions have different numerical apertures, as expected.
This effect varies not only along the x-axis but also along the
y-axis and even with exit-pupil shifting. Qualitatively, this effect
means that the spatially varying aberration components over the
HOE eye-piece cause irregular imaging quality of the system. The
irregular PSFs may be noticeable to the user or even disturb the
accurate accommodation effect. To solve this issue, the PSF can be
freely designed or engineered to have a customized size and shape
Fig. 14. Generated exit-pupil arrays for (a) red color, (b) green color and
(c) blue color. The photographs were captured directly by a CCD sensor
located at the exit-pupil domain without a camera lens.
Fig. 15. Video-captured image of a demonstration of the dynamic eye-box
[Supplementary Video].
within the maximum supported bandwidth, based on the presented
analysis and simulations. Using the simulation method presented
in Section 5.1, a ray bundle having the desired numerical aperture
and blur shape can be traced back to the SLM plane, and an aliasing
filter LPF can be designed. Figure 13 (b) shows simple examples
of PSF engineering. All PSFs are captured at the same position but
designed to have different blur shapes.
6 RESULTS
6.1 Eye-box expansion result
Figure 14 shows the resultant eye-box consisting of an exit-pupil
array using the prototype. The eye-box is captured using a CCD
sensor without a lens to show the shape of the exit-pupils. The
image is captured while the MEMS mirror scans the whole PSHOE
area rapidly. The size of the expanded eye-box is 7 mm by 7 mm
as designed, and the variation of the exit-pupil shapes is consistent
with the simulation. The diffraction efficiency is low at the side
positions due to the wavelength mismatch of the recorded laser and
the display laser. However it can be resolved by controlling the laser
power according to the pupil selection.
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
Holographic Near-eye Display with Expanded Eye-box • 195:11
Fig. 16. Photographs of augmented reality display results for the compact
prototype with different focus distances. (a) Focused at a close distance and
(b) focused at a far distance. For each case, a dandelion flower (located at a
close distance) and a tropical fish (located at a far distance) are magnified
in the right.
Figure 15 shows a video-captured image of a dynamic eye-box
demonstration synchronized with eye movement. At the left, the
pupil-captured images are shown for different times t1, t2, and t3.
According to the movement of the user’s pupil, the exit-pupil is
switched to tracking the eye-movement as shown in the right of
Figure 15. To show the intrinsic shape of the exit-pupil, the SLM
operates as a planar mirror. These results verify that the proposed
method provides the eye-box expansion function as designed.
6.2 Display result
The experimental results are presented in this section. Figure 16
shows photographs of augmented reality display results using the
compact prototype, as captured by a CCD camera (f /1.4, Pointgrey).
A phase only hologram is used instead of double phase encoding
[Hsueh and Sawchuk 1978], since the compact prototype cannot
perform the filtering. The random pixel separation method is used
to reduce the speckle [Mori et al. 2014] by dividing the object points
into 9 groups and displaying sequentially at each frame. The hologram computation load is not changed in this method. The image
is captured by displaying the monochromatic images (R, G, and B)
sequentially, and subsequent synthesis without any image process.
Due to the noise, the overall image is hazy and the contrast is low.
To reduce the high order noise, the numerical aperture size of the
sub-hologram is halved, resulting a reduced blurring effect. Also, a
grid is displayed to relieve the noise in the empty region. Source of
Fig. 17. Photographs of an augmented reality display result for the benchtop
prototype with different focus distances. (a) Focused at a close distance and
(b) focused at a far distance. For each case, a dandelion flower (located at a
close distance) and a wing of a bird (located at a far distance) are magnified
in the right. A toy owl is located at a close distance to show the camera
focus distance.
noises are DC noise, speckle noise, and wavefront degradation by
the PSHOE. More images are provided in [Supplementary F].
Figure 17 shows photographs of augmented reality display results
using the benchtop prototype. The results verify that a full-color
gradation hologram image can be successfully displayed using the
proposed system, showing improved image quality compared with
the compact prototype. Although the optical transparencies of both
prototypes are identical, reduction of DC noise allows enhanced
contrast and brightness. Still, some artifacts can be observed such
as slight noise or limited contrast. As expected in Figure 13 (a),
the right side of the image shows some resolution degradation.
However, overall, the prototype shows an appropriate focus cues
with reasonable resolution and good see-through properties.
Figure 18 shows photographs of the display results captured at
the different exit-pupil locations to verify the eye-box expansion.
The relative location in the expanded eye-box is indicated in the
right of each photograph. The real view is blocked for comparison
of image regardless of the outside scene. The result verifies the
proposed method of eye-box expansion.
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
195:12 • C. Jang, K. Bang, G. Li, and B. Lee
Fig. 18. Photographs of display results without real-world scene captured
at the different exit-pupil locations. The displacement is indicated in the
right of each photograph. Slight variation of FOV is observed as discussed.
7 DISCUSSION
7.1 Assessments
Resolution. In theory, the maximum resolution of the holographic
display is decided by the numerical aperture of the point image
and therefore changes according to the supported bandwidth of
corresponding points. For example, if the user’s pupil size is smaller
than the total support area of WDF, the system can provide a maximum image resolution of the user’s original eyesight. However, in
practice, the resolution is further degraded by the quality of the
aberration compensation and wavefront quality of the light source.
The measured MTF shows an intensity value of greater than 0.3
at 20 cycles per degree (cpd) at the center of FOV. However, when
the image is displayed instead of a single pixel as shown in Figure 17, the signal to noise ratio tends to be degraded due to the
speckle noise. The results of resolution measurement are presented
in [Supplementary E].
Field of view. The prototype has a large FOV of approximately
45◦
in the horizontal direction and 40◦
in vertical direction. As
discussed in Section 5, the FOV slightly varies according to the
exit-pupil position. The FOV can be further increased by reducing
the intrinsic exit-pupil size. Although the proposed method can
expand the eye-box for eye-saccades, the intrinsic exit-pupil size is
still decided by the bandwidth of the SLM. Nevertheless, we claim
that by adopting the proposed method, a 4k SLM is sufficient to
cover 45◦ of FOV with practical eye-box size and resolution.
Real-time display. We have demonstrated real-time exit-pupil
switching with pupil-tracking and display results at different exitpupil locations. However, we note that real-time display with online CGH calculation is not demonstrated in this paper because our
CGH rendering is not sufficiently fast for real-time display. Since
real-time hologram generation and a fast eye-tracking algorithm
itself are outside the main scope of this study, the total latency is not
addressed in detail. The proposed method has the advantage of short
pupil-switching latency of less than 1 ms, since the MEMS mirror can
provide a very fast scanning speed. Therefore, the proposed pupilswitching system itself does not impose a bottleneck of framerate,
which is imposed by the eye-tracking delay and rendering time of
the hologram. Real-time display can be accomplished by adopting
previous works on CGH acceleration [Maimone et al. 2017; Shi et al.
2017].
Artifacts. To fabricate the PSHOE, a customized lens-array is used.
However, the surface of the lens-array itself is not sufficiently clean
to achieve satisfactory optical quality. When used as a spherical
wavefront light source, the wavefront quality varies for each lenslet,
which results in image quality degradation.
In addition, the wavelength mismatch between the recording/display
stages induces some issues. The wavelengths of the laser sources
(638 nm, 520 nm, and 450 nm) are slightly different from those used
for HOE fabrication (660 nm, 532 nm, and 473 nm). The blue laser
has the largest difference between the fabrication stage and the
display stage. The exit-pupil of blue color is formed at a slightly
shifted position compared to the other wavelengths R and G. At
ACM Trans. Graph., Vol. 37, No. 6, Article 195. Publication date: November 2018.
Holographic Near-eye Display with Expanded Eye-box • 195:13
the same time, the wavelength mismatch caused the diffraction efficiency degradations of both lens HOE and PSHOE. However, it is
not a fundamental limitation of HOE fabrication. The color shifting
issue can be easily addressed by using the same wavelengths in
the both stages, and the wavefront of the HOE can be enhanced by
using a high-quality lens-array. Greater engineering effort could
be focused on the PSHOE. In theory, each hogel of the PSHOE can
be calibrated to generate more uniform efficiency in the fabrication stage using a holographic printing method, to compensate the
diffraction efficiencies according to location.
The degree of Bragg mismatch of lens HOE for each exit-pupil
also affects the color uniformity. We expect such issues could be
further mitigated by engineering of the lens HOE fabrication and
precise calibration for each exit-pupil.
Finally, we note that the major reason for noise in the compact
prototype was an unfiltered DC component. We expect that a thickvolume hologram can be used for DC filtering instead of the 4-f
imaging system for practical realization.
7.2 Further expansion of the eye-box size
The exit-pupil distortion imposes a main limitation on the eye-box
expansion of the system. If the shift is larger than a certain level, distortion become too large, and the exit-pupil cannot operate properly
due to the vignetting effect, as mentioned in Section 3. An eye-box
size of 10 mm or larger is required for practical use. Although this
study achieved an eye-box with a total size of 9 mm (7 mm of shifted
eye-box and 2 mm of for the intrinsic eye-box size), which is close
to practical, distortion will be a problem when trying to further
increase the eye-box or to create a smaller eye relief. Although the
distortion is an intrinsic property of the lens HOE, the unique advantage of combining the holographic display and HOE is that there
is large room for design flexibility. We believe that the following
methods can be used to address these issues: First, HOE can be multiplexed for multiple intrinsic exit-pupils so that the distortion would
not be as large. Second, a doublet structure design can be adopted for
the lens HOE or even meta-lens for aberration reduction [Groever
et al. 2017]. Third, an aberration pre-compensated wavefront can
be recorded for each hogel of the PSHOE in the fabrication stage
using the holographic printing method [Jang et al. 2016; Wakunami
et al. 2016].
8 CONCLUSIONS
Holographic displays have a great potential to realize mixed reality
by modulating light in a fundamental manner. As a computational
display, holographic displays offer a large degree of freedom such
as focus cue generation and vision correction. However, the limited
bandwidth imposes an inherent trade-off relationship between the
field of view and eye-box size. We have demonstrated the first practical eye-box expansion method for a holographic near-eye display.
For implementation, a pupil-shifting HOE is proposed that can reduce the form factor for exit-pupil shifting. A thorough analysis
of the design parameters and display performance are provided. In
particular, we provide a comprehensive analysis for incorporating
the HOE into a holographic near-eye display system. The influence
of the holographic optical elements on the intrinsic exit-pupil and
pupil switching is revealed by numerical simulation and Wigner distribution function analysis. This work demonstrates the possibility
of practical realization of holographic near-eye displays.