We present a direct-to-indirect transport technique that enables accurate realtime rendering of indirect illumination in mostly static scenes of complexity
on par with modern games while supporting fully dynamic lights, cameras
and diffuse surface materials. Our key contribution is an algorithm for
reconstructing the incident radiance field from a sparse set of local samples —
radiance probes — by incorporating mutual visibility into the reconstruction
filter. To compute global illumination, we factorize the direct-to-indirect
transport operator into global and local parts, sample the global transport
with sparse radiance probes at real-time, and use the sampled radiance field
as input to our precomputed local reconstruction operator to obtain indirect
radiance. In contrast to previous methods aiming to encode the global directto-indirect transport operator, our precomputed data is local in the sense that
it needs no long-range interactions between probes and receivers, and every
receiver depends only on a small, constant number of nearby radiance probes,
aiding compression, storage, and iterative workflows. While not as accurate,
we demonstrate that our method can also be used for rendering indirect
illumination on glossy surfaces, and approximating global illumination in
scenes with large-scale dynamic geometry.
CCS Concepts: • Computing methodologies → Rendering;
Additional Key Words and Phrases: Global illumination, real-time rendering
1 INTRODUCTION
Indirect (global) illumination is widely acknowledged to be a key
factor in perceived image realism. Over the past decade, the film
industry has largely switched from more or less phenomenological
models to physically-based rendering techniques [Christensen and
Jarosz 2016] as they offer realistic, predictable, and controllable
results. Yet, real-time rendering of accurate indirect lighting remains
a challenge, as the necessary integration over the space of all light
paths remains too costly to be performed for every pixel. The issues
are only aggravated by high-DPI screens, stereo rendering, and the
high frame rate requirements of VR headsets. Consequently, typical
applications today do not support detailed indirect illumination
with local, dynamic light sources, and instead mostly resort to static
pre-computation or a limited form of dynamic illumination through
precomputed radiance transfer [Sloan et al. 2002].
We present a technique that enables accurate real-time rendering
of indirect diffuse illumination in mostly static scenes of complexity
on par with modern games with fully dynamic lights, cameras and
diffuse and emissive surface materials. Our key contribution is an
algorithm for faithfully interpolating incident radiance captured at
a sparse set of low-frequency “radiance probes” to nearby receiver
points. While much previous work has built on the same basic ideas,
our method features little inappropriate light leaking thanks due to
our novel formulation of the interpolation at the surfaces seen by
both the probes and the receiver points, not only spatially between
the samples. Using our interpolator, we formulate a novel direct-toindirect precomputed transport technique that yields results that
compare favorably to path traced references with probe sets that
are extremely sparse in comparison to previous methods at similar
quality. We study the properties of our reconstruction using tools
for analyzing light field sampling and reconstruction; this allows
reasoning about the role of spatial sampling densities and angular
bandwidths.
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
230:2 • Ari Silvennoinen and Jaakko Lehtinen
2 RELATED WORK
Real-time global illumination methods draw efficiency from two
main sources: 1) geometric approximations that enable faster integration, e.g., using point-based models or voxels instead of accurate
geometry [Christensen 2008; Crassin et al. 2011; Ritschel et al. 2009],
and 2) interpolating illumination from sparse sample sets, or sampling it densely but poorly and attempting to remove noise after
the fact using sophisticated non-linear filters (e.g., [Dammertz et al.
2010; Kontkanen et al. 2004]). Our method makes use of exact geometry and sparse samplings.
Interpolation methods. Our work most naturally relates to sparse
interpolation techniques. E.g. Ward [1992], Křivánek et al. [2005]
interpolated irradiance and bandlimited radiance, respectively, from
point sets whose local density is driven by distance to close-by
geometry. Schwarzhaupt et al. [2012] introduced a second order,
occlusion-aware error metric for irradiance caching. Lehtinen et al.
[2008] perform similar interpolation, but address changing spatial
frequency needs with a hierarchy of grids. We share these methods’
fundamental idea — computing illumination sparsely and interpolating — but address their greatest shortcoming: light leaks due to
interpolation weights that do not respect visibility. Our algorithm
is able to faithfully interpolate radiance from much sparser cache
point sets.
Local-global separation. Arikan et. al [2005] interpolate radiance
represented as spherical harmonic expansions from sparse samples,
and model the shadowing effect of local occluders by approximate
visibility. In a sense, we share many of the same goals. Our technique
accounts for visibility in a more precise manner, and consequently
yields superior results as the number of probes decreases.
Precomputed light transport. Precomputed radiance transfer methods [Sloan et al. 2002], including “direct-to-indirect” techniques
[Hašan et al. 2006], precompute linear operators that map emitted
or direct illumination functions into indirect radiance or irradiance
sampled over the scene surfaces. We use our interpolation method to
formulate a novel direct-to-indirect technique, where direct illumination is captured at runtime at a sparse set of probes, and mapped
to the incident radiance of densely sampled nearby receiver points
through precomputed local interpolation operators. On a high level,
our algorithm is precisely equivalent to earlier direct-to-indirect
methods [Hašan et al. 2006; Kontkanen et al. 2006; Lehtinen et al.
2008; Martin 2010], but one with a transport operator explicitly factorized into global and local components. Both operators are sparse:
there is a relatively small number of probes only, and each receiver
point only needs to consult the radiance from a small subset of
nearby probes. This is in contrast to earlier direct-to-indirect techniques that globally link senders and receivers together. The locality,
which aids compression and streaming, furthermore makes it simple
for us to support indirect illumination effects from limited forms of
dynamic blockers. We make use of clustered principal component
analysis for compression [Sloan et al. 2003].
Light Field Probes. Light field probes are spatial samples of the
angular variation in the light field [Buehler et al. 2001]. They may be
represented in various forms, e.g., cube maps [Hooker 2016; McGuire
et al. 2017] or spherical harmonics expansions [Ramamoorthi and
Hanrahan 2001], which is also our choice. Hooker [2016] uses a
sparse set of cube maps for accelerating final gathering in a precomputation program. Like us, they make use of precise visibility
between probes and query points; in contrast, they consult probes
near the secondary hits of the final gather rays whereas we query the
probes near the rays’ origins. In our direct-to-indirect setting, their
approach would be prohibitively expensive, as it would link receiver
points to potentially all probes in a scene. McGuire et al. [2017]
performed ray tracing in cube maps with depth information; they
also perform spatial interpolation, but with weighting that leads
to inaccurate reconstruction with sparse samplings. In contrast to
these methods, we sample the light field in an angle-bandlimited
format using spherical harmonics. We reason about why and when
such a representation is still sufficient for faithful reconstruction of
irradiance below.
3 LOCAL TRANSPORT OPERATOR
Section 3.1 introduces our premise, interpolation of radiance from
sparse samples of the directional radiance field. Section 3.2 presents
a novel interpolation method that accounts for precise visibility and
thus significantly reduces the signature “light leaking” of interpolation techniques. We also analyze the effect of angular bandwidth
stored at the radiance samples. Section 3.3 builds a local precomputed radiance transfer method using the novel interpolation operator. Finally, Section 3.4 studies the properties of the interpolator
by light field analysis techniques. Section 4 then describes a full
working direct-to-indirect transport algorithm.
Assumptions. We assume throughout that the radiance field leaving the scene surfaces is diffuse; however, our framework supports
glossy BRDFs for the final bounce towards the viewer. This is a common approximation in real-time global illumination techniques. We
further assume that the scene is mostly static, but do offer support
for approximate dynamic occluders. In addition, dynamic objects
can receive indirect illumination by combining our method with
(ir)radiance volumes [Greger et al. 1998].
a) Direction mismatch b) Visibility mismatch c) Our approach
Fig. 2. Issues and solutions for interpolation from a sparse set of
radiance probes. a) Using the same constant direction ω when interpolating radiance is incorrect. b) Reprojecting the point Γ(x,ω) seen by
the receiver x in the direction ω to the probes improves interpolation
significantly. Still, interpolating radiance in directions where Γ cannot
be seen by some probes leads to incorrect results. c) Our reprojected interpolation with added visibility weighting enables much more faithful
reconstruction.
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
Real-time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes • 230:3
3.1 Overview
Our goal is to compute indirect illumination at a dense set of receiver
points, which are either surface points or points in a radiance volume.
This requires a dense sampling of the incident radiance field L(x,ω)
over directions ω for all receiver points x. As it continues to be too
expensive to perform a real-time dense angular radiance sampling,
e.g., by rendering cube maps or tracing hundreds of rays per receiver,
we aim to instead reconstruct the angular incident radiance function
at the receivers by interpolation from a much sparser set of radiance
observations Li(ω) := L(pi
,ω) (radiance probes), where each probe
captures the angular variation as seen from the probe position pi
(Figure 2).
Our goal is shared by much previous work, e.g., [Křivánek et al.
2005; Ward et al. 1988]. These reconstructions typically take spatial
averages of the probes’ radiance (or irradiance) by
L(x,ω) ≈
Í
i wi(x)L(pi
,ω)
Í
k wk
(x)
, (1)
where wi(x) are spatial interpolation weights that are functions of
the positions of the probe and the receiver, and potentially differences in their surface normals (Figure 2a). Some methods also make
use of the spatial gradient ∇xL [Ward and Heckbert 1992].
We observe two key issues in the reconstruction performed according to Equation (1). First, interpolating the radiance using the
same fixed direction ω for all probes is incorrect, because these
directions do not generally point towards the surface point Γ(x,ω)
seen by the receiver x in the direction ω (Figure 2a). Reprojecting the
directions appropriately, i.e., consulting the probes’ radiance in the
direction of the point Γ(x,ω) seen by the receiver in the direction ω,
remedies the issue; this solution (“sheared reconstruction”) has been
employed in several light field reconstruction techniques [Buehler
et al. 2001; Chai et al. 2000; Egan et al. 2011, 2009; Gortler et al. 1996;
Lehtinen et al. 2011]. Second, local visibility easily causes erroneous
interpolation of radiance in directions that are not mutually visible
by the probes and the receiver (Figure 2b); here, the blue radiance
sample from p2 incorrectly contributes to the weighted estimate.
(This is the cause of the well-known “light leaks” in irradiance volume -type methods.) Some techniques attempt to mitigate this issue
by consulting the visibility between the receiver x and the probe p2
[McGuire et al. 2017]; however, the unoccluded line of sight does not
guarantee that the radiance sample would be valid. Note, however,
that there also exist directions — marked with green arrows in Figure 2b — where p2 could appropriately contribute to the radiance
estimate at x; hence leaving p2 unused is wasteful. While sheared
reconstruction techniques alleviate some of these issues [Egan et al.
2011, 2009], they still fundamentally require denser spatial sampling
in regions of complex visibility.
3.2 Visibility-Aware Interpolation
Our key idea is to perform an intermediate reparameterization from
the angular domain onto the scene surfaces — where visibility can
be accounted for precisely — and then back into the angular domain.
That is, when querying the radiance from a receiver x in a given
directionω, we only use information from radiance probes that directly
see the point Γ(x,ω) seen by the receiver in that direction. Furthermore,
finding Γ(x,ω) allows us to consult the probes’ radiance in the
appropriately reprojected direction (Figure 2c).
Technically, we combine the spatial interpolation weights wi(x)
with directional, per-probe binary visibility weights Vi(ω) that pick
out, for each direction separately, only probes that see the same
surface point the receiver x sees. Concretely, our radiance reconstruction is defined by
L(x,ω) ≈
Í
i wi(x)Vi(ω)L(pi
,ψi(ω))
Í
k wk
(x)Vk
(ω)
, (2)
where the sum is over all probes, wi(x) = w(x, pi
;ri) is a spatial
weight kernel with a finite support radius ri
, Vi(ω) = V (Γ(x,ω), pi)
is the visibility between the hit point given by the ray-cast operator
Γ and the probe at pi
, and ψi(ω) is the direction from pi to the hit
point Γ(x,ω) (see Figure 2c). The probes’ contributions are glued
together by a partition of unity forced by the division by the sum of
the combined weights, while the spatial weights guarantee smooth
reconstruction across space. If no probe sees Γ(x,ω), we define its
radiance to be zero.
3.3 Bandlimited Probes and PRT
Notably, given infinite angular resolution at the probes, and remembering the diffuse radiance field assumption, the reconstruction of
Equation (2) is exact as long as the point Γ(x,ω) is seen by at least
one probe. No set of spatial interpolation weights only can guarantee this. However, a high-resolution angular sampling of the probes’
radiance is still overly expensive in terms of both computation storage, as we desire to perform this operation at real-time rates at a
probe set that covers a complex scene. This motivates us to replace
the probes’ radiance fields by finite-dimensional basis expansions
given in terms of spherical harmonics. We study the effect of this
approximation in Section 3.4.
Concretely, we approximate the probes’ radiance fields by
L(pi
,ω) =
Õ
j
λijYj(ω), (3)
where λ, the probe radiance vector, contains the basis expansion
coefficients for all probes flattened into a long vector, and Yj are
the spherical harmonic basis functions. For convenience, we index
the probe radiance λ using probe index i and basis function index j.
Each color band has its own vector λr, λд, λb
, but we omit these
for simplicity of notation except when otherwise noted.
For a fixed receiver x, we define a local transport operator Px {λ}(ω)
that transforms the probe radiance vector λ to interpolated incident radiance at x as a function of the continuous direction ω by
evaluating Equation (2) using the probes’ basis expansions:
Px {λ}(ω) =
Í
i wi(x)Vi(ω)
Í
j λijYj(ψi(ω))
Í
k wk
(x)Vk
(ω)
(4)
=
Õ
i
Õ
j
λij
wi(x)Vi(ω)Yj(ψi(ω))
Í
k wk
(x)Vk
(ω)
=
Õ
i
Õ
j
λijKij(x,ω),
with Kij(x,ω) =
( wi (x)Vi (ω)Yj(ψi (ω))
Í
k wk (x)Vk (ω)
if Í
k wk
(x)Vk
(ω) > 0
0 otherwise.
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
230:4 • Ari Silvennoinen and Jaakko Lehtinen
Hierarchical Transport Matrix sender-to-receiver Global Transport Matrix sender-to-receiver Probe Transport sender-to-probe Local Transport probe-to-receiver
Hierarchical
Transport Link
Hierarchical
Sender Node
Matrix
Vector
Receiver Irradiance
Sender Coecient
Local Transport Coecient
Probe Basis Coecient
Transport Coecient
a) Legend b) Global transport c) Hierarchical transport d) Our factorized transport
Fig. 3. a) Legend. Typical direct-to-indirect transport methods aim to compress the dense global transport operator (b) using a global, fixed
hierarchy over the senders and receivers (c). We instead factorize the global transport operator into two parts: global probe transport and sparse
“last-leg” local interpolation (d).
Receiver
Scene
Receiver
Irradiance
Sender
Coecients
Transport
Coecients
Receiver
Hierarchical senders
Receiver
Irradiance
Hierarchical Transport sender-to-receiver
Receiver
Probe
Local Transport probe-to-receiver
Scene
Sender Coecients
Probe Transport
Coecients
Probe Transport sender-to-probe
. .
Sender
Visibility
Sender Basis
Function
. . . .
Receiver Visibility Receiver Radiance
. .
Spotlight Spotlight
Spotlight
Receiver
Irradiance
Probe Basis
Coecient
Local Transport
Coecient . Probe Basis Function
Probe Radiance Reconstruction
Probe Radiance Probe Basis Function
. . Visibility Probe Basis Function
.
.
Fig. 4. Scene with a spotlight and a receiver (top left). We are seeking to reconstruct the irradiance at the receiver (top left). The ceiling geometry
is subdivided into three piecewise constant hierarchical sender patches (bottom left). Hierarchical transport with piecewise constant basis functions
amounts to multiplying the direct light coefficients in the sender basis with the precomputed transport coefficients, but using only three coefficients
results in a poor approximation to the receiver irradiance (bottom left). Our factorized approach allows efficient decoupling of high-frequency
near-field visibility from low-frequency illumination (left). The direct lighting is projected to the probe basis (top right). Our local transport results
in more accurate reconstruction of the receiver irradiance with fewer coefficients due to decoupled near-field visibility (bottom right).
The transport kernel Kij(x,ω) is the angular function that results
from projecting the value of the jth spherical harmonic from the
ith probe onto the scene surface seen in the direction of Γ(x,ω),
modulated by visibility, and divided by the weights of other probes.
The intuitive meaning of the linear combination is that the probes
project their approximate radiance functions onto surfaces visible
to them, and the receiver blends together results from all probes
that see the point Γ(x,ω).
Precomputed Transport. The local transport operator Px can be
used to measure the interpolated incident radiance at x in various
ways. Owing to linearity, and, in line with the voluminous literature
on precomputed radiance transfer, the result of the measurement
with a general spherical function Φ is a linear function of the probe
radiance vector λ:
⟨Px {λ}, Φ⟩ =
∫
Px {λ}(ω)Φ(ω)dω (5)
=
Õ
i
Õ
j
λijϕij , (6)
where the transport coefficients ϕij are given by ⟨Kij(x, ·), Φ⟩.
Irradiance Transport. In particular, the irradiance I(x) at a receiver
x is computed by measuring the interpolated approximate radiance
field by the cosine lobe:
I(x) ≈ ∫
Px {λ}(ω) cos θdω =
Õ
ij
λijαij , (7)
where the double indices i and j have been flattened using a single,
linear index ij for notational convenience, and the entries of the irradiance transport vector αx are given by αij = ⟨Kij(x, ·), cos θ⟩. This
corresponds to the SH transport vectors of, e.g., Sloan et al. [2002].
Note that most entries in αx are zero, as only few probes contribute
to each receiver.
Radiance Transport. We approximate the interpolated incident radiance field at x using a directional basis expansion with orthogonal
basis functions Bk
:
L(x,ω) ≈ Px {λ}(ω) ≈ Õ
k
bkBk
(ω). (8)
Finding the expansion coefficientsbk
reduces to measuring Px {λ}(ω)
by the basis functions Bk
(ω), which yields the radiance transport
matrix Bx with entries β(ij)k = ⟨Kij(x, ·), Bk
⟩, again in line with
the transport matrices of Sloan et al. and others. The coefficients of
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
Real-time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes • 230:5
transported radiance are given by Bxλ. Bx is a nk × ninj radiance
transport matrix, where nk
is the number of receiver basis functions,
ni
is the number of probes, and nj
is the number of probe basis functions. The rows contain the transport vectors for the corresponding
basis functions:
Bx =







β(1,1),1 β(1,2),1
· · · β(ni
,nj),1
.
.
.
.
.
.
.
.
.
β(1,1),nk
β(1,2),nk
· · · β(ni
,nj),nk







. (9)
Note, again, that due to the local support of the weights wi(x), this
matrix is sparse: only few probes contribute to each receiver.
A Note on Color. Importantly, as the color of surfaces seen by
the probes is encoded in the probe radiance vectors, the transport
coefficients ϕij are decoupled from surface color, and encode only
geometric information. In particular, this means that we are free
to change surface properties, such as diffuse albedo and emissivity,
without changing the transport coefficients.
Discussion. Previous direct-to-indirect transport methods aim
to efficiently compute and store the global transport operator that
maps basis expansions of (ir)radiance defined at the scene surfaces
into basis expansions that describe indirect illumination, again on
the scene surfaces, linking senders and receivers globally across
the scene [Hašan et al. 2006; Jendersie et al. 2016; Lehtinen et al.
2008; Loos et al. 2011]. In this framework, our approach is to instead
factorize the global transport operator into two parts: a precomputed local transport matrix that accounts for near field effects
between the receiver and the mutually visible surfaces seen by the
probes, and a global probe transport operator that captures radiance (also far-field) in a sparse set of probes at runtime (Figure 3).
In effect, our construction amounts to a local, custom sender basis for each receiver given in terms of the local probes only. This
automatically decouples the effects of high-frequency near-field
visibility and slowly-varying distant irradiance in a natural way
without the need for increasing the number of hierarchical transport links (Figure 4), enabling high-quality indirect shadows with
a small number of precomputed transport coefficients. The global
probe transport operator can be implemented in a variety of ways
(e.g. our precomputed gather from texture, rendering cube maps,
hierarchical direct-to-indirect methods); all it needs to produce are
the SH expansions of incident radiance at the probe locations.
3.4 Analysis
To analyze our interpolator, we study a flatland scenario depicted
in Figure 5a. The scene consists of a planar (line) receiver at y = 0,
and two textured surfaces at y = 0.25 (small, greenish segment) and
y = 2 (larger, reddish segment). In addition, a bright area light is
situated in the middle of the reddish surface. We study the light
field incident onto points on the receiver as a function of space x
and angle w using the angle parameterization of Chai et al. [2000]:
the direction w of a ray emanating from a point x is specified by
its intersection with the y = 1 line, such that an intersection point
directly above x always means w = 0. The incident radiance field
on the receiver is shown in Figure 5b, where the two blue example
rays in Figure 5a correspond to the two marked points.
Figure 5c depicts a version of the light field that has been bandlimited (blurred) along the angular dimension, but with full resolution
along the x axis. Note how the extremely bright light correspondingly “bleeds” along the angular dimension, but not along the spatial dimension: receiver points that do not see any part of the light
source remain properly occluded. Ramamoorthi and Hanrahan’s
[2001] and Basri and Jacobs’ [2003] deep results tell us that given a
low-frequency BRDF at the receiver, we can reconstruct outgoing
radiance from such bandlimited incident signal. This permits us to
seek reconstruction of this bandlimited signal instead of the original
signal with full resolution over angle.
Next, we introduce a sparse spatial sampling of the bandlimited
light field (Figure 5d). This stage corresponds precisely to computing
finite SH expansions over the angular domain at a sparse set of probe
locations. (The sample columns have been fattened for visualization
only; they are Diracs in x.)
Figure 5e illustrates naive interpolation from the samples using
Equation 1. This corresponds to blending the probes’ SH coefficient
vectors using the spatial weighting functions wi(x). This results in
significant light leaking and blurring.
Our visibility-aware reconstruction is depicted in Figure 5f. For
each ray (x,w) in the output light field, we consult nearby probes,
and use their radiance value (which is bandlimited in angle) for
reconstruction only if the point seen at the end of the ray (x,w)
is visible to the probe too. This panel clearly illustrates our approximation: due to the bandlimited probes’ inability to represent
discontinuities, the light source seen by the probe influences also
surfaces that are nearby the light source in angle (diagonal light
streaks along the edges of the green surface). However, the accuracy
of the approximation increases with the angular bandwidth of the
probes. This is seen in the final panel (Figure 5g) which illustrates
reconstruction from the same set of 10 spatial probe locations, but
with increased angular resolution.
Figure 6 depicts the interpolation in a realistic scenario. Radiance
from two bandlimited probes is interpolated in a visibility-aware
manner to a third receiver point and compared to the standard
interpolation. In addition to the flatland example, this figure also
includes a final convolution of the radiance field with the cosine
kernel (panels j, k); this is the irradiance function seen by the receiver as a function of the surface normal. As can be seen, while the
reconstruction of angular variation is not perfect, once the interpolated radiance function is convolved with the cosine kernel, the
reconstruction can remain faithful.
4 IMPLEMENTATION
This section describes our practical global illumination technique
using our factorized transport approach. We describe how we precompute and compress the local transport operator in Section 4.1.
The runtime part, including details on how we evaluate the probe
transport, is described in Section 4.2.
4.1 Precomputation
Probe Locations and Radii. Our goal is to find a sparse set of
probe locations and support radii with the two properties: 1) every
surface point is under the support of at least one probe, and, 2),
every surface point is visible from at least one probe.
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
230:6 • Ari Silvennoinen and Jaakko Lehtinen
w
x
2
y
1
0
0.25
area light
textured
surface
textured
surface
receiver plane
direction plane
x
w
x
w
x
w
x
w
x
w
x
w
a) b) c) d) e) f) g)
ray 2
ray 1
ray 1
ray 2
Fig. 5. 2D analysis of sampling and reconstruction of a diffuse radiance field from sparse spatial samples bandlimited in angle (cf. Section 3.4). a)
Scene. The planar receiver sits at y = 0. Two surfaces at y = 0.25 and y = 2 shine radiance onto the receiver. A bright area light is situated in the
middle of the further occluder. Rays emanating from the occluder are parameterized by their x coordinate and their intersection with the y = 1 line.
b) The light field seen by the receiver over space x and angle w. The two rays from the previous panel are indicated. c) The light field, bandlimited
(blurred) over angle, but not space. This bandlimited version suffices to reconstruct reflected radiance for low-frequency BRDFs at the receiver
[Basri and Jacobs 2003; Durand et al. 2005; Ramamoorthi and Hanrahan 2001]. d) A sparse spatial sampling of the angle-bandlimited light field. e)
Reconstruction from the samples by spatial blending only (Equation (1); no reprojection/shearing, no visibility). f) Our reconstruction from the
same samples. g) Our reconstruction from the same samples, but with increased angular bandwidth (samples are sharper in w). As all surfaces are
seen by a probe, the result converges to ground truth with increasing bandwidth — even with this fixed set of spatial samples.
To find the probe locations, we use a greedy algorithm with a single parameter ρprobes, the desired spacing. To avoid placing probes
inside scene geometry, we first voxelize the scene and flood-fill the
empty interior space. Next, we generate a vastly overcomplete set
of candidate locations pi
in empty voxels near the scene surfaces,
i.e., in empty voxels with non-empty neighbors. We then compute
a kernel density estimate from the candidates pi using the weight
function wi(x; ρprobes) (see below), and iteratively remove candidates from the densest regions until we have met our target probe
count. To avoid introducing additional parameters, we set the target
probe count to the number of points in a regular grid that covers
the scene with grid spacing set to ρprobes.
Every receiver should fall under the support of at least one probe,
but smooth spatial interpolation necessitates coverage from multiple
probes for each receiver. The user provides the desired number
Noverlap of overlapping probes per receiver. Since the probe set
obtained in previous step has approximately constant density, we
use a fixed radius r for all probes, i.e., ri ≡ r. To find r, we perform
a search over possible radii and choose the one that best satisfies
the overlap constraint on average. All our results use Noverlap = 10.
Spatial Weight Function. For spatial interpolation, we use a radial
weight kernel wi(x;r) = w(∥x − pi ∥2/r), where r is the radius
obtained in the previous step, and w(t) is given by
w(t) =
(
2t
3 − 3t
2 + 1, if 0 ≤ t ≤ 1
0, otherwise.
(10)
Precomputed Radiance Transport and Compression. We proceed
to precompute transport coefficients αx or Bx for all receivers. (Section 5 shows results for both irradiance (scalar) and 1st order SH
transport.) Receivers are only linked to probes whose support radius covers the receiver: other probes contribute nothing as per
Equation (2). The coefficients are then compressed using Clustered
Principal Components Analysis [Sloan et al. 2003]: receivers are
split to clusters, and the transport matrices in each cluster approximated separately. More precisely, the transport vectors/matrices of
all receivers in a cluster c are stacked vertically into the matrix Tc ,
and the Singular Value Decomposition applied:
Tc = UΣVT ≈ UcΣcV
T
c
. (11)
Compression is obtained by replacing the diagonal matrix of singular values Σ with a truncated version Σc , where only the nc largest
entries have been kept. The cluster projection matrix ΣcV
T
c has size
nc ×ninj
(recall that ni
is the total number of probes and nj the number of basis functions captured by the probes). As only few receivers
contribute to a spatially coherent cluster of receivers, large blocks
of the columns of ΣcV
T
c
are zeros — it suffices to store the non-zero
columns. The receiver reconstruction coefficient matrix Uc encodes
the linear response of each receiver in the cluster to each of the nc
dimensions of the intermediate cluster-specific illumination basis;
i.e., it contains ncnk numbers per receiver, where nk
is the number
of rows in the radiance transport matrix Bx (in case of irradiance,
nk = 1). The cluster projection matrix ΣcV
T
c
and reconstruction
coefficients Uc are stored in 16-bit floating point.
As computing the SVD for very large matrices is inefficient, we
build, in departure from Sloan et al. [2003], our clusters in two steps.
An initial clustering is obtained by building an AABB-tree over the
receiver positions, splitting the longest axis until the leaf nodes
contain fewer than 1024 points. The clusters are then adaptively
refined [Sloan et al. 2003] based on a fixed error threshold and a
maximum number of SVD coefficients (we use a threshold of 0.005
and a maximum of 32 coefficients).
4.2 Runtime
Probe Transport. Our method places no restrictions on how to
compute the probe transport, i.e., the probes’ SH coefficients λ at
runtime. We choose to perform the projection with the aid of a direct
illumination light map that is updated every frame, accounting for
the diffuse albedo and emissivity of each surface point. For each
probe, we use a fixed set of uniformly distributed “relight rays”, and
precompute the direct light map uv coordinates of the relight ray hit
points ahead of time by tracing visibility rays (this does not preclude
dynamic blockers; see section 5.1). At runtime, the probes merely
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
Real-time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes • 230:7
(a) View from probe p1 (b) View from receiver x (c) View from probe p2
(d) SH projection of (a) (e) SH projection of (b) (f) SH projection of (c)
(g) Reconstr. of (b) from
(d), (f) by Eq (4) (vis. only)
(h) SH projection of (g)
(visualization only)
(i) Interpolated (d), (f)
(fails, visibility-agnostic)
(j) Cosine convolved (e)
(ground truth)
(k) Cosine convolved (h)
(our result)
(l) Cosine convolved (i)
(fails, visibility-agnostic)
Fig. 6. Illustration of visibility-aware interpolation. (a)-(c) Fisheye
views from probes p1, p2, and receiver x. (d)-(f) Spherical harmonic
approximations of the angular radiance field at the probes and the
receiver. (d) and (f) are computed at runtime; the expansion (e) is for
visualization only, and is never formed explicitly. (g), (h) visualize
the interpolated radiance field seen by the receiver, as evaluated by
Equation (4), and its SH projection. In a perfect reconstruction, (g) =
(b) and (h) = (e). This spherical image is also never explicitly formed.
(i) visualizes the SH expansion obtained by directly interpolating the
SH coefficients λ1,2 (cf. Figure 2a). This fails due to lack of visibility
awareness. (j), (k) The diffuse BRDF acts as a low-pass filter to the
radiance field [Ramamoorthi and Hanrahan 2001]. Even though the
radiance field is not matched precisely, the low frequencies remain
relatively intact through our entire pipeline. This is apparent in the
match between (j) and (k) (fourth row).
loop over all their relight rays, consult the current radiance at the
appropriate uv coordinates in the direct illumination texture, and
multiply by the spherical harmonics at the appropriate direction. To
avoid evaluating spherical harmonics at runtime, we precompute
their values together with the proper PDF-weights in the directions
of the relight rays.
Cluster Radiance Transport. Once obtained, the probe radiance
vector λ is transformed by the PCA clusters’ projection matrices
ΣcV
T
c
to yield the nc dimensional light basis vector for each cluster.
These coefficients are finally multiplied by the cluster’s receiver
reconstruction coefficients Uc to obtain the nk
-dimensional transported radiance coefficients at each receiver. The result is then used
to compute the reflected radiance by evaluating the receiver BRDF.
For scalar irradiance transport, this reduces simply to multiplication
with the local albedo and division by π. Higher-order transport
can be evaluated in various ways. In our results, we use an order-1
version of the irradiance convolution of Ramamoorthi and Hanrahan [2001] to support normal mapping. This means scaling the
transported SH coefficients by fixed constants and evaluating the
resulting 4-term expansion in the direction of the surface normal.
To account for infinite light bounces, the resulting diffuse component of the outgoing radiance is fed back to the system and used
as input for the next direct-to-indirect transport iteration.
5 RESULTS
We have implemented our method using C++ and DirectX 11, using
compute shaders to evaluate the runtime radiance transport. All
images in this paper contain the raw output of our method without
any additional screen-space ambient occlusion or reflection effects.
In all results, we define the receivers as the sample points of a
light map’s texels for ease of final reconstruction from the camera’s
point of view (for resolutions, see Table 1; note that any other set
of receivers can be used just as well). The accompanying video
features animations with dynamic lights. In addition to the standard
Cornell and Sponza, we demonstrate the method on two novel
scenes, Gallery from a “triple-A” Xbox One title, and Brutalist
Hall from an unannounced title. All results are computed on a Intel
Core i7-3770K CPU PC with 32 GB memory and NVIDIA Titan X
Pascal GPU. Unless otherwise noted, all results are computed with
probes of SH order 7 (64 basis functions) and irradiance (scalar)
transport (Equation 7). All scenes use a direct illumination light
map of size 20482
to gather direct illumination to the surfaces prior
to computing the probe radiance vectors. We use 8000 relight rays
per probe.
Comparison to Ground Truth. A sampling of our results is shown
in Figure 7. The figure compares our irradiance transport against
a converged reference, where the irradiance at the same light map
texels is computed using path tracing. In order to reveal all the
intricate lighting details, we show our comparisons without albedo
maps, as they tend to hide lighting imperfections. Please see the
accompanying video for dynamic illumination in the same scenes.
While using only less than 90MB of GPU memory and < 5ms of GPU
time for indirect lighting, we observe a generally good match with
the reference with the chosen parameters. Section 5.2 presents analysis of errors. Table 1 provides detailed statistics of our scenes and
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
230:8 • Ari Silvennoinen and Jaakko Lehtinen
Textured view, probes and 16x error Our result Path traced lightmaps
Gallery 1 Gallery 2 Sponza 1 Sponza 2 Brutalist Hall 1 Brutalist Hall 2
Fig. 7. We compare our results (left and middle) to path traced reference (right) using three scenes, (Gallery, Sponza, and Brutalist Hall)
and two different lighting configurations in each scene. The probe positions are shown in insets in the left column. We show the comparisons
as lighting-only images assuming a constant albedo of (0.5, 0.5, 0.5). Note that the albedo maps still contribute to the indirect lighting. The
supplemental material contains all images in uncompressed form. Please see the supplemental video for dynamic illumination.
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
Real-time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes • 230:9
5 probes 109 probes
Direct lighting & probes Interpolated SH irradiance [Arikan et al. 2005] Our result Reference
Fig. 8. We compare our interpolation (middle right) to spatial interpolation (middle left) and to radiance caching with irradiance decomposition
[Arikan et al. 2005] (middle). The images show indirect illumination from two point light sources with varying number of probes (left). Our method
is closer to the path traced reference (right) in both cases and yields superior results in the sparse probe setting.
Table 1. Statistics and memory consumption for all test scenes. Precomputation time contains both radiance and irradiance transport. For
performance figures, see Table 2.
Transport statistics Compression statistics and memory
Scene Precomp.
time
Lightmap
resolution #Probes #Receivers #Clusters Avg. #SVD
coeffs./receiver
Avg. #Probes /
SVD cluster
Total
memory
Gallery 52 min 12162
275 321 745 2311 15.56 17.55 86MB
Sponza 45 min 12162
150 246 325 935 24.41 20.17 72MB
Brutalist Hall 72 min 10882
260 567 370 2223 18.89 13.40 89MB
Table 2. Timing breakdowns for our test scenes.
Scene Scene
relight (ms)
Probe
relight (ms)
Cluster SVD
projection (ms)
Receiver
irradiance (ms) Total GPU (ms)
Gallery 0.70 0.84 2.06 0.30 3.90
Sponza 0.36 1.01 1.00 0.13 2.50
Brutalist Hall 1.28 1.55 1.80 0.24 4.87
transport parameters, including the number of probes and memory
usage. See Table 2 for a timing breakdown for the indirect lighting.
In all scenes, the full rendering is performed at 90 FPS.
Dynamic Material Properties. Since the precomputed transport
coefficients do not encode any material information, we support
dynamic surface material properties, such as textured diffuse albedo,
emissivity, normal maps and surface roughness, all of which can
be freely changed or animated at runtime. Figure 9d demonstrates
area shadows from a door with an emissive surface material. See
the accompanying video for an interactive session.
Temporal Stability. The accompanying result video demonstrates
the our method is temporally stable and does not suffer from flickering artifacts. Temporally stable results are achieved by maintaining
a sufficient sample rate when sampling the input illumination.
Comparison to Previous Methods. Figure 8 shows a comparison
between our method and the local-global irradiance separation of
Arikan et al. [Arikan et al. 2005]. Like ours, their method interpolates spherical harmonics illumination vectors from nearby probes.
In contrast to our technique, they proceed to heuristically subtract
radiance from local occluders processed one triangle at a time, resulting in double occlusion from overlaid occluders due to lack of
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
230:10 • Ari Silvennoinen and Jaakko Lehtinen
proper occluder fusion. To compare, we implemented an idealized
version of their technique using accurately sampled visibility instead of their approximation; this effectively compares against the
best-case output of their method. Spatial-only interpolation (Equation 1) is included as a reference in Figure 8; it does not yield usable
results with a small number of probes. Using the same sparse set of
probes, the interpolation of Arikan et al. contains visible artifacts.
When the probe count is increased, both comparison methods start
to resemble the ground truth, but our method is closest to the path
traced reference in both cases. Notably, our interpolator yields a
high-quality result also with the sparse probe set.
Discussion. The uncompressed local transport matrix has dimensions Receivers × Probes · SHBasisFunctions and the probe transport matrix has dimensions Probes · SHBasisFunctions × Probes ·
ReliдhtRays. Typical numbers are 500K receivers, 200 probes, 64 SH
basis functions and 8000 relight rays. Compared to the full transport
matrix consisting of all senders and receivers, the total number of
coefficients in our factorized transport correspond to an effective
sparsity factor of the order 10−4
for uncompressed matrices. With
SVD compression, the observed effective sparsity factor is of order
10−5
. Previously, Lehtinen et al. [2008] reported sparsity factors of
order 10−3
. However, the results are not directly comparable, as the
reported numbers are from different scenes and using a different
receiver/sender parametrization.
5.1 Extensions
Normal Mapping. Normal maps are used to add high-frequency
surface details without increasing the triangle count of the scene.
Unfortunately, scalar transport is insufficient to support normal
mapping at the receivers, as the irradiance varies with the local
surface normal. To enable normal mapping, we instead project the
interpolated radiance signal to order-1 spherical harmonics (4 coefficients) at the receivers (Equation 8), allowing us to apply an order-1
version of Ramamoorthi and Hanrahan’s [2001] efficient irradiance
convolution in the SH domain. To counter the increased memory
use due to the richer representation (4 instead of 1 transport coefficients per receiver), we simultaneously lower the probes’ SH order
to 4 (25 coefficients). These changes result in approximately the
same memory use as scalar transport using order-7 probes. Figure
9a shows an example. Naturally, the overall accuracy suffers due to
the probes’ lower angular bandwith, but results remain plausible;
increasing the order at both receivers and the probes allows more
faithful results at the cost of more memory and GPU time.
Glossy Materials. While a low-order expansion allows normal
mapping on diffuse surfaces, the low bandwidth of the angular variation at the receivers is not sufficient to enable accurate rendering of
glossy or specular materials; in practice, increasing the receiver SH
order sufficiently quickly ends up in a storage and runtime problem.
We can, however, support an approximate form of specular transport
by interpreting the linear terms in the SH expansion as a directional
light source [Sloan 2008], with the diffuse component given by the
DC term, and apply any standard BRDF model to this approximation.
Figure 9b depicts an example (only specular illumination shown).
Here, we use a Cook-Torrance BRDF with GGX normal distribution
and Smith shadowing-masking term [Walter et al. 2007]. Although
this is a crude approximation, it provides visually pleasing results
at negligible additional cost.
Dynamic Occluders. While our basic technique is fixed to a scene
through precomputation, the local supports of the probes allows
insertion of dynamic blockers; intuitively, as probes only affect
receivers close by, changes in radiance seen by the probes due to
moving objects have at least some hope of being captured in the local
interactions. Figure 9c demonstrates a soft area-light shadows from
a dynamic sphere occluder blocking the relight rays. Naturally, the
accuracy of the approximation depends on the size of the occluder
relative to the probe density: detailed occlusion from small occluders
is generally not possible with a sparse probe set. However, larger
objects, such as dynamic doors and windows, yield usable results
in many cases, and we expect this to increase the applicability of
our method in practical applications. Please see the accompanying
video for an interactive session.
5.2 Error Analysis
Reconstruction Error. We analyze the expected error in irradiance
reconstruction by studying how the incident light field changes
at a fixed receiver by a round trip to the probes and back. That is,
taking a ground truth angular radiance field at the receiver, we use
our interpolation technique to project it backwards to the probes,
then back to the receiver, and comparing the two. The better the
reconstruction enabled by the probe set, the smaller the difference.
To enable numerical estimation, we represent the incident radiance at a fixed receiver x using a order 9 (100-coefficient) SH
expansion, called the receiver radiance vector λx. The receiver radiance is first projected to the probes’ SH basis via a dual projection
operator P
∗ defined analogously to the forward one: each probe
takes the role of a receiver, and the receiver becomes the only probe
and has infinite support. This gives us the probe radiance vector
λ = P
∗λx that represents the receiver light field projected to the
probes’ perspectives. To pull the radiance back to the receiver, we
apply our reconstruction operator Px {λ} to the probe radiance
vector λ, and measure the reconstructed irradiance with a cosine
measurement functional. Putting this together, the squared irradiance reconstruction error E(x) for a fixed receiver radiance vector
λx is
E(x; λx) = ∥⟨cos θ, (I − Px {λ}P∗
)λx⟩∥2
2
, (12)
where I is the identity operator. We note that the error is quadratic in
the probe radiance vector, and that we can consequently measure the
average round-trip error over all possible unit radiance vectors λx
by computing the L2 operator norm of the linear operator ⟨cos θ, (I−
Px {λ}P∗
) ·⟩. The inclusion of the the cosine measurement term
ensures that we measure error in irradiance reconstruction (the final
result we seek), not the intermediate radiance reconstruction. The
norm is visualized in the bottom row of Figure 10 in Cornell. As
can be seen, increasing the density of probes causes a reduction in
the expected error.
Probe Density vs. Quality. Figure 10 visualizes the effect of probe
density to reconstruction error. The first rows visualize the transported irradiance in Cornell with an increasing probe count in a
fixed lighting condition and using order-7 probes (64 coefficients).
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
Real-time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes • 230:11
a) Normal mapping b) Indirect
specular lighting
c) Dynamic indirect shadowing from
moving sphere blocker
d) Dynamically turning
surface to area light
Fig. 9. Extensions (see Section 5.1 and the accompanying video). a) Normal mapping through 1st-order transport to receivers. b) Approximate
indirect specular lighting by interpreting 1-st order radiance at receivers as a directional light. c) A dynamic sphere blocker used for modulating
the visibility during probe relight. d) The emission of any surface may be changed at will at no extra runtime cost. Here the polygons in a door in
Sponza have been turned emissive; soft shadows automatically result. Main View Probes, inset
No probes
∥⟨cos θ, (I − Px {λ}P
∗) ·⟩∥2
a) 2 probes c) 10 probes c) 29 probes d) Path traced ground truth
Fig. 10. Effect of the density of light probes on the accuracy of illumination using order-7 probes (64 coefficients). Top two rows: The Cornell box
in fixed illumination. Only incident irradiance is visualized for added clarity (surface albedo not shown, but causes color bleeding). The thumbnails
on the middle rows show the position of the probes. Even with only two probes, the indirect illumination is captured relatively faithfully. Loss of
detail in small-scale local indirect shadows can be noticed, but additional probes remedy the situation. Notice, in particular, the erroneous red color
bleeding in the inset in column a). Bottom row:Visualization of the operator norm of the forward-and-backward projection operator (Section 5.2).
The color denotes the average L2 error over all possible illuminations conditions. Note how areas of high error correspond to the regions of poorer
fidelity in the result images above.
ACM Transactions on Graphics, Vol. 36, No. 6, Article 230. Publication date: November 2017.
230:12 • Ari Silvennoinen and Jaakko Lehtinen
a) SH 0 (1 coefficients) b) SH 1 (4 coefficients) c) SH 2 (9 coefficients) d) SH 7 (64 coefficients) e) Reference
Fig. 11. Effect of the order of the probes’ SH expansions on the final result. Lighting only (top). Difference to ground truth (16x magnified, bottom).
Differences between successive approximations quickly taper off to the point it is hard to see them in a side-by-side visualization; the reader is
encouraged to flip back and forth between the full-resolution images provided in the supplemental material.
Fig. 12. This figure demonstrates a failure case due to insufficient
probe density and bandwidth. Path-traced reference reference (middle)
contains a high-frequency secondary area light source (green), and our
reconstruction (left) has blurred the incident radiance field in the near
vicinity (red). The error is localized to the bottom-right region (right),
where the probe density and bandwidth are too low to represent the
incident illumination, leaving most of the image unaffected.
Only irradiance is shown, as final multiplication by the albedo hides
problems even in this simple scene. The small thumbnails in the
middle row show the positions of the probes. Generally, the irradiance is reconstructed remarkably well even from just 2 probes.
However, erroneous color bleeding and washed-out indirect shadows can be observed (see inset). The bottom row shows a heat-map
visualization of the L2 operator norm of the back-and-forth transport operator that attempts to reconstruct the receivers’ original
radiance field by projecting to the probes and back; this visualization is not tied to a particular lighting condition (see above). We
note how the areas of worst mismatches between our result and
the reference can be found in the areas of higher error. As expected,
increasing the density of the probes reduces the expected error.
Probe SH Order vs. Quality. Figure 11 visualizes the quality of
transported irradiance at a fixed lighting condition and fixed probe
set as a function of the probes’ bandwith, i.e., the number of basis
functions nj
. Results remain plausible even at very low orders, and
fidelity quickly increases to the point it is difficult to see the differences side by side. The reader is encouraged to flip back-and-forth
in the full-resolution images found in the supplemental material.
Interestingly, the quality difference resulting from lowering the
probes’ SH order can be countered by a denser spatial sampling: the
closer the probes are to the receivers, the less bandwidth they need.
Previous analysis show that in the limit, when probes coincide with
receivers, order 2 is sufficient for high-fidelity reconstruction [Ramamoorthi and Hanrahan 2001]. A full study of the 2D parameter
space remains future work.
A Typical Failure Case. As shown by the various analyses above,
the reconstruction error of our method is directly linked to probe
density and bandwidth. Figure 12 shows a typical failure where the
angular bandwidth at the probes is insufficient to capture the local
light field in enough detail given the sparsity of the probes.
6 CONCLUSION
We have described a technique for interpolating radiance from
sparse samplings of a diffuse light field, where the angular bandwidth (resolution) of the samples is limited due to their representation as spherical harmonics expansions. Despite these limitations
(sparsity, low bandwidth), our method allows a much more faithful
reconstruction of the incident light field than previous techniques
that make use of such sparse sample sets.
It remains an interesting challenge to incorporate light field analysis tools in the sampling stage to drive the positions and bandwidths
of the light probes. Furthermore, it is intriguing to see if our interpolation on surfaces seen by samples and receivers (as opposed to
locally in the space-direction parameterization near the receiver)
enables sampling of also non-diffuse light fields using spatial samplings that are sparser than previous local analyses of sampling and
reconstruction would indicate.