We present CoLux, a novel system for measuring micro 3D motion of multiple
independently moving objects at macroscopic stando distances. CoLux is
based on speckle imaging, where the scene is illuminated with a coherent
light source and imaged with a camera. Coherent light, on interacting with
optically rough surfaces, creates a high-frequency speckle pattern in the
captured images. The motion of objects results in movement of speckle,
which can be measured to estimate the object motion. Speckle imaging is
widely used for micro-motion estimation in several applications, including
industrial inspection, scientic imaging, and user interfaces (e.g., optical
mice). However, current speckle imaging methods are largely limited to
measuring 2D motion (parallel to the sensor image plane) of a single rigid
object. We develop a novel theoretical model for speckle movement due
to multi-object motion, and present a simple technique based on global
scale-space speckle motion analysis for measuring small (5-50 microns)
compound motion of multiple objects, along all three axes. Using these
tools, we develop a method for measuring 3D micro-motion histograms
of multiple independently moving objects, without tracking the individual
motion trajectories. In order to demonstrate the capabilities of CoLux, we
develop a hardware prototype and a proof-of-concept subtle hand gesture
recognition system with a broad range of potential applications in user
interfaces and interactive computer graphics.
CCS Concepts: • Computing methodologies → Computational photography; • Human-centered computing → Interaction devices;
Additional Key Words and Phrases: Computational imaging; micro motion
measurement; user interfaces; gesture recognition
1 INTRODUCTION
The ability to measure extremely small non-rigid or multi-object
motion has a wide range of applications, from biological cell imaging [Godinez and Rohr 2015], to hand-gesture recognition [Lien
et al. 2016] for user interfaces. Measuring such micro-motions at
macroscopic stand-o distances is generally not possible with conventional cameras and vision systems without using sophisticated
optics. Furthermore, measuring multi-object or non-rigid motion is
fundamentally more challenging than tracking a single object due
to the considerably higher number of degrees of freedom, especially
if the objects are devoid of texture.
We propose CoLux, a novel micro-motion measurement technique based on speckle imaging. Coherent light, on interacting
with optically rough objects, creates a high-frequency speckle pattern. An example is shown in Fig. 1. Motion of the objects results
in movement of the speckle pattern, and, given only the moving
speckle pattern, it is possible to estimate the object motions. Previous speckle-based motion estimation techniques have been limited
to single-body rigid motion estimation [Gregory 1978; Jacquot and
Rastogi 1979; Jakobsen et al. 2012; Zalevsky et al. 2009], or sensor
ego-motion estimation [Jo et al. 2015; Zizka et al. 2011]. Furthermore, most previous techniques are largely restricted to measuring
2D lateral motion (parallel to the sensor plane). Although some
techniques [García et al. 2008; Jakobsen et al. 2012; Jo et al. 2015;
Zizka et al. 2011] can measure axial motion, the motion sensitivity
along the axial direction is 1-2 order of magnitude lower than that
of lateral motion.
Multi-object motion analysis via bare sensor speckle imaging: In
designing CoLux, our goal is to measure the motions of multiple
independently moving objects with high <50 µm (microns) sensitivity
along all three spatial dimensions (we assume the dominant motion
of the objects to be translation, e.g., small cells moving in a medium,
or nger tips performing a subtle gesture). The motion sensitivity
of a speckle imaging system is directly proportional to the amount
of sensor defocus. Our goal is to measure micro-motions. Therefore,
ACM Transactions on Graphics, Vol. 36, No. 4, Article 34. Publication date: July 2017.
34:2 • B. M. Smith et. al.
we use a bare (lens-less) sensor in CoLux. In addition to reducing
cost and hardware complexity, the extreme defocus of a bare sensor
results in extreme motion sensitivity. However, such large defocus
also leads to overlap of multiple speckle patterns from dierent
objects, and also cross-speckle due to interference of light from
dierent objects. The resulting speckle pattern does not obey laws
of speckle movement due to rigid object motion, and thus individual
object trajectories cannot be recovered.
Our key observation is that, by using light sources with high temporal, but low spatial coherence, the cross-speckle terms vanish. By
exploiting the statistical randomness of speckle patterns [Goodman
2000], we present a simple and ecient technique for recovering individual object motions, without needing to separate the individual
speckle patterns. The proposed technique is based on a global scalespace analysis of the sequence of captured speckle images, which
enables measuring multiple object motions simultaneously; previous motion measurement techniques based on local optical ow [Jo
et al. 2015] cannot recover multiple motions. As an additional bene-
t, the global method can measure complex 3D compound motions
with considerably higher axial motion sensitivity (<50 µm) as compared to previous approaches [García et al. 2008; Jakobsen et al.
2012; Jo et al. 2015; Zizka et al. 2011], while retaining high lateral
motion sensitivity (<5 µm). Although CoLux achieves high motion
sensitivity along all three axes, it cannot track multiple individual
objects. Instead, it measures aggregate motion statistics of the scene,
represented as a 3D motion histogram, which can be analyzed to
recover the dynamic conguration of the scene, e.g., to recognize
subtle hand gestures.
Hand gesture recognition system: To demonstrate the capabilities
and potential applicability of CoLux, we develop a proof-of-concept
hand gesture recognition system that can dierentiate subtle nger
movements. We are motivated by the fact that micro-motion gestures are dicult, if not impossible, to capture with conventional
vision sensors alone. Our intention is not to compete directly with
gesture recognition techniques based on conventional computer
vision techniques that use RGB(D) cameras. Instead, CoLux oers
complementary benets: extreme motion sensitivity, but no spatial
specicity, whereas conventional cameras oer spatial specicity
but lower motion sensitivity. We take inspiration from Soli [Lien
et al. 2016], a recent gesture recognition method based on millimeterwave radar sensing, and measure aggregate motion of the scene
(hand) at high temporal resolution, without tracking individual
objects (ngers). While the overall goal of CoLux and Soli are similar, they dier signicantly in the underlying imaging modality
(speckle imaging vs. radar). While Soli has required signicant custom hardware development, our prototype consists of o-the-shelf
components, as shown in Fig. 1. Such components are widely used in
low-cost and low-power devices such as optical laser mice, and are
commercially available in compact form factors. We have trained
a light-weight random forest classier that can run in real-time
on commodity hardware, and show recognition results on several
single- and multi-nger gestures involving 3D motions. With our
prototype system, we achieve an overall gesture-level accuracy of
83% for 5 dierent subjects over 7 gestures.
Contributions: This paper makes two main contributions:
(1) A novel theoretical model and practical method for measuring multiple rigid or nonrigid motions. We present a technique based on global scale-space analysis of the speckle
sequence to recover small (5-50 µm) compound motions
of multiple objects along all three axes. As a secondary
benet, this global technique achieves higher axial motion
sensitivity (<50 µm) as compared to previous speckle based
motion estimation approaches.
(2) Conceptual design, hardware prototyping, and a novel proofof-concept system for high-speed subtle gesture recognition,
with a broad range of potential applications in interactive
computer graphics, gaming, and virtual reality.
2 RELATED WORK
Video motion magnication: Recently, techniques for magnifying
small periodic motion in videos have been proposed [Davis et al.
2014; Wadhwa et al. 2013; Wu et al. 2012]. These can be considered
digital motion magnication techniques because they digitally amplify motion in videos by suppressing noise in the desired temporal
frequency bands. In contrast, CoLux amplies motion sensitivity
using optical imaging techniques during capture to measure micromotions. Such subtle motions cannot be captured by a conventional
camera, and thus cannot be magnied via digital post-processing.
Video motion magnication techniques serve as visualization tools.
On the other hand, the speckle patterns captured by the CoLux
sensor are not suitable for human visualization, but can instead be
used for quantitative motion measurement and analysis.
Non-rigid and multi-object motion analysis: Multi-object motion
analysis techniques can be broadly classied into two categories.
The rst category encompasses techniques that track locations of
individual objects over time. For example, most camera-based handtracking and gesture recognition systems [Weichert et al. 2013; Xu
et al. 2015] explicitly estimate a hand’s pose and skeletal structure.
Tracking spatio-temporal trajectories of individual objects can provide highly detailed motion information but is not always possible
if objects lack texture or if the motions are small. CoLux belongs to
the second category of techniques that do not explicitly compute
the 3D structure of the scene or track individual points. For instance,
recent techniques based on alternative sensing modalities such as
millimeter-wave radar [Lien et al. 2016] and radio waves [Zhao et al.
2014] recognize hand gestures by performing aggregate motion analysis of the entire scene over time. While previous techniques [Lien
et al. 2016; Zhao et al. 2014] achieve limited motion sensitivity or
require dedicated hardware, CoLux can achieve high motion sensitivity leading to ne-grained motion classication with o-the-shelf,
typically inexpensive hardware technology.
3 SPECKLE FORMATION MODEL
This section is intended to introduce potentially unfamiliar concepts,
and to establish notation. Speckle phenomena are well-studied, and
more detailed introductions can be found in, e.g., [Goodman 2007].
Consider a temporally coherent light source (e.g., a laser diode)
illuminating an optically rough surface Ψ, as shown in Fig. 2 (a). The
light emitted by a coherent source is characterized by the underlying
ACM Transactions on Graphics, Vol. 36, No. 4, Article 34. Publication date: July 2017.
CoLux: Multi-Object 3D Micro-Motion Analysis Using Speckle Imaging • 34:3
( )
light source
bare sensor
surface
Ψ
light source
bare sensor
surface
Ψ
sensor
object
sensor
object
sensor
object
(a) (b) (c)
Fig. 2. (a) Speckle formation model. A bare sensor images a surface Ψ illuminated by a coherent light source located at L, which is approximately co-located
with the sensor. (b) Speckle motion model for rigid object motion. As the object moves in 3D, the speckle paern recorded by the sensor also moves. (c)
alitative depiction of speckle motion. Lateral object motion results in speckle paern shi. Axial motion results in speckle image contraction or expansion.
electric eld U, which varies sinusoidally over time t:
US(L, t) = US cos(ωt + ϕS (t)), (1)
where L is the spatial location of the light source,US is the amplitude
(US =
√
LS , LS is the radiant intensity of the source), ϕS (t) is the
phase of the light emitted by the source towards a scene point S,
and ω =
2πc
λ
is the modulation frequency, where c is the speed of
light, and λ is the wavelength of the coherent source. In practice, a
coherent source emits a narrow band of wavelengths [λmin, λmax ].
λ is the mean wavelength, i.e., λ =
λmin+λmax
2
.
Suppose the surface is imaged by a bare sensor, as shown in Fig. 2
(a). The electric eld at pixel p due to the light reected from the
point S is given as:
US(p,t) = α(S)US cos 
ωt + ϕS (t) − 2π
2Γ(S)
λ
+ ϕ
r
S

, (2)
where α(S) encodes the light attenuation due to reection at S and
the intensity fall-o due to propagation. The phase of the emitted
electric eld is shifted by 2π
2Γ(S)
λ
during propagation along the path
L → S → p, where Γ(S) is the distance of S from the source (we
assume that the sensor and the source are co-located). ϕ
r
S
is the
change in phase due to reection at point S.
Since the sensor is bare, we assume that each pixel collects light
from every point on the surface. The total electric eld U(p) at pixel
p is then given by integrating the elds US(p,t) from all scene points
over the surface Ψ:
U(p,t) =
∫
Ψ
US(p,t)dS =
∫
Ψ
β(S) cos 
ωt + ϕbS (t)

dS , (3)
where β(S) = α(S)US and ϕbS (t) = ϕS (t) −2π
2Γ(S)
λ
+ϕ
r
S
. The speckle
image I, which is the measured image brightness due to this electric
eld, is given as:
I(p) = κ
∫τ
0

U(p,t)
2
dt , (4)
where τ is the sensor integration time, and κ is a proportionality factor incorporating sensor gain. An example speckle pattern observed
by illuminating small pieces of chalk is shown in Fig. 1.
Properties of Speckle
Statistical randomness: A speckle pattern due to reection of coherent light from an optically rough surface is statistically random [Goodman 2000]. Intuitively, this is because each point on
the illuminated surface acts as a secondary light source that emits
spherical wavefronts. The total light received at a camera pixel is
the superposition of all the wavefronts. The phase of each of these
wavefronts varies rapidly as the path lengths (from scene point to
sensor) change due to surface roughness, resulting in a statistically
random speckle intensity distribution. This statistical randomness
manifests as the following two properties of speckle images:
(I ∗ I)(u,v) = Λ(u,v) ,
| {z }
Auto-correlation property
(5)
where I(u,v) is a speckle image, [u,v] are image coordinates, and ∗ is
the 2D correlation operator. Λ(u,v) = κδ(u,v) is a scaled dirac-delta
function δ(u,v), as shown in Fig. 3 (a), where κ =
Í
u,v

I(u,v)
2
is
the square-norm of the speckle image; and
(I1 ∗ I2)(u,v) = 0 ,
| {z }
Cross-correlation property
(6)
where I1(u,v) and I2(u,v) are speckle images due to reection from
two dierent rough surfaces Ψ1 and Ψ2, respectively. Intuitively,
these two properties state that speckle images can be treated as
mutually orthogonal random functions, i.e., with high probability, a
speckle pattern is uncorrelated with anything but itself.
High spatial frequency: The mean ‘size’ χ of an individual speckle
in a speckle image is proportional to the wavelength of light, and
is given as χ ≈
λΓ
Ω
[Dainty 1975; Goodman 2000, 2007], where λ
is the wavelength of light, Γ is the distance of the object from the
sensor, and Ω is the area of the illuminated pattern. Speckle size depends on several other factors, including imaging geometry, surface
properties including roughness and BRDF, and sensor properties
including pixel size, aperture and focal length. For visible or NIR
wavelengths (∼ 380−800 nm), the speckle size is limited only by the
sensor pixel size, resulting in extremely high spatial frequencies.
4 SPECKLE MOTION MODEL: RIGID MOTION
In this section, in order to make the paper as self-contained as possible, we review the basics of the speckle motion model due to single
object rigid motion. For detailed derivations, the interested reader
is referred to previous work [Jacquot and Rastogi 1979; Jakobsen
et al. 2012; Jo et al. 2015] and the supplementary technical report.
A well known result in optics is that small object motion does not
change the speckle pattern, but only translates or scales it by a small
ACM Transactions on Graphics, Vol. 36, No. 4, Article 34. Publication date: July 201