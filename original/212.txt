The stable relationship between personality and EEG ensures the feasibility of personality inference from brain activities. In this paper, we recognize an individual's personality traits by analyzing brain waves when he or she watches emotional materials. Thirty-seven participants took part in this study and watched 7 standardized film clips that characterize real-life emotional experiences and target seven discrete emotions. Features extracted from EEG signals and subjective ratings enter the SVM classifier as inputs to predict five dimensions of personality traits. Our model achieves better classification performance for Extraversion (81.08 percent), Agreeableness (86.11 percent), and Conscientiousness (80.56 percent) when positive emotions are elicited than negative ones, higher classification accuracies for Neuroticism (78.38-81.08 percent) when negative emotions, except disgust, are evoked than positive emotions, and the highest classification accuracy for Openness (83.78 percent) when a disgusting film clip is presented. Additionally, the introduction of features from subjective ratings increases not only classification accuracy in all five personality traits (ranging from 0.43 percent for Conscientiousness to 6.3 percent for Neuroticism) but also the discriminative power of the classification accuracies between five personality traits in each category of emotion. These results demonstrate the advantage of personality inference from EEG signals over state-of-the-art explicit behavioral indicators in terms of classification accuracy.

SECTION 1Introduction
Personality has been conceptualized from a variety of theoretical perspectives, but the core of the personality is a set of individual differences in behavior and experience that are affected by the development of an individual, such as personal specific emotion, social relationships, and personal memories [1], [2]. Personality reflects a person's particular behavior pattern in everyday life. There are many theories and measurements of personality, but the Big Five personality traits have gained the most widespread recognition and play an irreplaceable role in the scientific community [3].

The Big Five personality traits [4], [5] , also known as the five factor model (FFM), describe personality in five dimensions: Extraversion, Agreeableness, Conscientiousness, Neuroticism, and Openness to experience [6]. Each dimension has six facets, which cover almost all personality characters [7] . The FFM plays an important role in an individual's everyday life. Many studies have explored its influence on a variety of situations, such as academic achievement [8], job performance [9], romantic relationships [10] , and career success [11]. For example, Dahlen and White [12] found predictive utility of emotional stability, agreeableness, and openness to experience in predicting aggressive driving behaviors. Given the important role of FFM in everyday life and research, measuring it is a focus of researchers.

There are several measures of the Big Five personality traits; the questionnaire is a common one, such as the International Personality Item Pool (IPIP) constructed by Goldberg [13] and the Big Five Inventory (BFI) [14]. The BFI is one of the most widely used tools and freely available [15]. The BFI consists of forty-four characteristics that describe five dimensions of personality traits. Participants are asked to indicate to what extent he/she agrees or disagrees with the description using a five-point Likert scale. Its highly repeatable reliability and content validity have been proved in different regions and different age groups [15] , [16]. Because this method was based on participants’ self-assessment, it could be influenced by social desirability to a greater or lesser extent.

Researches also developed other approaches to measure personality. Because personality is an implicit psychological construct that cannot be observed directly, recent studies mainly relied on explicit behavioral indicators (e.g., the digital footprints on social networks) for the prediction of personality traits [17] . For example, researchers have become interested in predicting personality traits using data from online social media, such as Twitter and Facebook [18], [19]. This approach collects users’ network behaviors and the contents generated by users, such as status updates, posted images, places they have visited, and managed relationships that provide rich information about their habits, preferences, skills, personal attitudes and values. Personality inference from digital footprints on social networks assumes that a user's online and real-life behaviors do not differ greatly in the same context. Rentfrow and Gosling [20] have studied the connections between music preferences and personality. They found that the reflective and complex dimensions were positively related to openness to experience. The social media profile picture is also a good indicator of personality. Previous studies suggested that agreeable and conscientious users showed more positive emotions in their profile pictures, while users score high on Openness to Experience preferred more aesthetic photos [18]. Youyou et al. [19] indicated that computer-based personality judgments were more accurate than those made by humans when the amount of Facebook likes (i.e., users click “Like” below a post on Facebook) was large enough. Obviously, these findings give researchers confidence and future research directions in which they can leverage the generated content to reveal a user's personality.

Compared to explicit behavioral indicators, interior emotional changes measured by physiological and biological indices are preferable to avoid social desirability bias and deception [21]. It is difficult to disguise an individual's real feelings by the recognition of emotions from physiological signals. Among of them (e.g., electrocardiograph, skin temperature, and galvanic skin response), emotion recognition from electroencephalogram (EEG) signals achieves a higher classification accuracy. Recently, there has been a growing amount of effort to recognize a person's emotional states from EEG signals using realistic music videos or movie clips with high ecological validity [22], [23]. These EEG-based emotion recognition systems identify not only the valence and arousal dimensions but also similar discrete emotions that are close in the valence-arousal coordinate space [24].

Personality represents the coherent integration of feeling, action, appraisal, and desires over time and space. Two dimensions of the Big Five personality traits, Extraversion and Neuroticism (sometimes referred to by the other end of the dimension as Emotional Stability) have been associated with individual differences in affective level and environmental responsivity [25], [26] . According to trait congruency effect, people with different personality traits show cognitive biases when processing emotional information and advantages of noticing, identifying, memorizing and judging emotional materials which are consistent with their personality traits [27]. Canli [28] found that Extraversion and Neuroticism were associated with differential activation to positive slides (Extraversion) and to threat cues (Neuroticism) using functional magnetic resonance imaging (fMRI). Extraversion was correlated with activation in a wide range of brain regions (e.g., amygdala, caudate, medio-frontal gyrus, right fusiform gyrus) in response to positively valenced slides but unrelated to activation in response to negatively valenced slides. Neuroticism, on the other hand, was correlated with activation in response to negatively valenced slides but unrelated to activation in response to positively valenced slides.

In addition, the stable relationship between personality and EEG data ensures the feasibility of predicting personality through the analysis of brain activity. For example, many researchers concluded that Extraversion, an indicator of proneness to positive affectivity, was related to right frontal EEG asymmetry [29], [30], while Neuroticism, an indicator of proneness to negative affectivity, reflected greater activation in the left hemisphere [31], [32]. Results from Event-related potentials (ERPs) also provide support for predicting personality. For example, Mardaga and Hansenne [33] found that low-harm avoidance participants showed smaller N200 amplitudes and larger P300 amplitudes when pleasant pictures were presented compared to neutral pictures, but this was not the case for high-harm avoidance individuals. Researchers also found a significant association between ERP indices, such as N1/P2 amplitude and slope, and Reinforcement Sensitivity Theory (RST) Personalities [34]. Due to a substantial overlap between RST-based and Big-five personality traits, these studies provide evidence of the possibility of recognizing personality based on brain activities. To the best of our knowledge, however, no existing research has analyzed implicit emotional fluctuation on the basis of EEG signals to predict personality.

In addition, emotion regulation (ER) played an important role in the response to emotional events [35]. Gross [36] described ER as the capacity to decrease stress for better psychological health and increase physiological activation for avoiding worse physical health automatically or intentionally. ER has two major strategies: cognitive reappraisal (CR) and expressive suppression (ES). CR involves reinterpreting the meaning of the emotional stimulus in order to change the trajectory of an emotional response [37], [38], [39]. ES represents a response-focused strategy, which means the act of masking facial giveaways for hiding a current emotional state [40]. Both strategies have proven to be correlated with the Big Five personality traits, particularly Extraversion and Neuroticism [41], [42]. Several researches have indicated that extrovert users are more likely to use CR strategy [40], [41], while individuals with a higher level of Neuroticism and lower level of Extraversion are more likely to apply the ES strategy [40], [43], [44]. Additionally, previous studies have suggested that extroverted users have a higher capability of emotion regulation with adaptive emotion-regulation strategies than neurotic users [42], [45], [46]. Thus, the possible role of ER in improving the performance of the classification models is considered in this study.

The main purpose of this paper was using EEG data to recognize Big-five personality traits. We attempt to build five independent models to recognize an individual's personality traits based on subtle changes in brain activity when he or she watches a series of emotional film clips. ER is also included in our model. The results showed our model achieves better classification performance for Extraversion (81.08 percent), Agreeableness (86.11 percent), and Conscientiousness (80.56 percent) when positive emotional videos are presented than negative ones, higher classification accuracies for Neuroticism (78.38-81.08 percent) when negative emotions, except disgust, are elicited compared to positive emotions, and the highest classification accuracy for Openness (83.78 percent) when a disgusting film clip is presented. Moreover, the introduction of features from subjective ratings of cognitive reappraisal and expressive suppression increases not only the classification accuracies in all of the five personality traits (ranging from 0.43 percent for Conscientiousness to 6.3 percent for Neuroticism) but also the discriminative power of classification accuracies between five personality traits in each category of emotion.

SECTION 2 Experimental Design and Data Acquisition
2.1 Participants
43 undergraduate or graduate students participated in this experiment, but six of them were excluded from the final analysis due to equipment failure or excessive artefacts of EEG signals. Finally, we collected 37 valid samples (17 males and 20 females) aged between 18 and 26 years old (mean (M)=23.95, standard deviation (SD)=1.56). All of them were right-handed, had normal or corrected-to-normal vision, and had no psychiatric disorder or neurological illness. All participants were required not to ingest tobacco or caffeine 24 hours before the experiment. Ethical approval was given by the Institutional Review Board of the Institute of Psychology, Chinese Academy of Sciences.

2.2 Experimental Materials
2.2.1 The Big-Five Inventory (BFI)
Based on extensive application of the BFI, the 44-item multi-dimensional personality inventory has proven to be a valid measuring tool of personal structure. In this study, we used the Chinese version of the BFI [47], a 5-point Likert scale that measures an individual on the Big Five dimensions of personality (Extraversion, Agreeableness, Conscientiousness, Neuroticism, and Openness to experience) from “disagree strongly” to “agree strongly”. The internal consistencies of each dimension are as follows: Extraversion has 8 items (α=0.778); Agreeableness has 9 items (α=0.735); Conscientiousness has 9 items (α=0.732); Neuroticism has 8 items (α=0.720); Openness has 10 items (α=0.785).

2.2.2 The Emotion Regulation Questionnaire (ERQ)
The 10-item ERQ is built to measure two emotion regulation strategies [41], which are Cognitive Reappraisal (CR) and Expressive Suppression (ES). The Chinese version of the ERQ [48] was used in this experiment and the internal consistencies of two dimensions are 0.85 for CR and 0.77 for ES. This scale aimed to measure emotion regulation ability, and all participants were asked to make a judgement about the extent of agreement based on a 7-point Likert scale from 1 (strongly disagree) to 7 (strongly agree).

2.2.3 Emotion Elicitation Materials
In this work, we used seven emotional Chinese film clips to elicit three positive emotions (amusement, joy, tenderness) and four negative emotions (anger, disgust, fear, sadness). All of these film clips were chosen from the existing standardized database of Chinese movies, and the effects of these emotion-induced materials were provided in [24]. As shown in Table 1, these film excerpts lasted 67 to 144 seconds and contained independent and integrated content to elicit a single target emotion. Each film clip was adjusted to the same resolution (720 × 576), and the volume was manipulated at a comfortable level using two speakers.

TABLE 1 Brief Description of Seven Standardized Emotional Film Clips Used in This Work
Table 1- 
Brief Description of Seven Standardized Emotional Film Clips Used in This Work
We collected the participants’ responses after watching each film clip. Because we selected film clips from the standardized database to elicit different discrete emotions, we compared every participant's self-assessments with the standardized database and ignored cases where the participant's ratings on each target emotion were inconsistent with the ground truth of the database.

2.3 Experimental Procedure
Upon arrival, the experimenter introduced the experiment, and all participants signed an inform consent voluntarily. Then, the participants filled two questionnaires (BFI & ERQ) when the experimenter set up the EEG recording system. Emotional film clips were presented on a 15-inch LCD screen. The distance between participants’ eyes and the screen centre was maintained at about 0.6 meters.

To keep all of the participants in a neutral state, a distraction task was designed at the beginning of each trial [24]. Then, a 40-s rest with eyes open and another 40-s rest with eyes closed were arranged before watching each film clip. The experimental task was to watch a film clip and then complete a revised version of the self-assessment manikin (SAM) developed by [49], which directly measured arousal, valence, liking, familiarity and dominance in addition to seven differential emotions, including amusement, joy, tenderness, anger, disgust, fear, and sadness, based on a 9-point Likert scale (1 = “not at all”, 5 = “moderately”, 9 = “extremely”). They were encouraged to answer all questions based on their true emotional feelings when watching each film excerpt, instead of their expected feelings or general mood.

In the practice session, the participants watched two neutral film clips to familiarize themselves with the experimental procedure, e.g., distraction task, baseline rest, and questionnaire. We put the Quik-Cap on the participant's head for a while to prevent undesired emotions that can arise from unfamiliar or uncomfortable feelings. Then, we described the process of EEG recording and advised the participant to stay as static as possible to prevent artefacts from movements of the body. All participants were seated in a soundproofed room and kept their chins on the chin strap during the formal experiment. They were required to turn off all wireless and Bluetooth devices to isolate possible interference with the EEG signals. During the formal session, the order of play of seven film clips was set to pseudorandom to guarantee that the same valence of movie would not be played consecutively [50]. The whole experiment lasted about 1.5 hours, and the participants received ¥100 as reimbursement. The detailed procedure of our experiment is illustrated in Fig. 1.

Fig. 1. - 
Experimental procedure and flowchart.
Fig. 1.
Experimental procedure and flowchart.

Show All

2.4 EEG Data Acquisition and Preprocessing
We used a 32-electrode Neuroscan Quik-Cap to collect participants’ brain activities when they watched film clips. The Quik-Cap is manufactured of highly elastic breathable material with soft neoprene electrode gel reservoirs for enhanced user comfort. All electrodes were placed according to the International 10-20 electrode placement standard. The reference electrodes were placed on the left and right mastoids and the ground electrode was placed mid-forehead. Two horizontal and two vertical electrooculograms (EOGs) were recorded with electrodes placed 10 mm away from the outer canthi of both eyes and below and above the left eye [51]. In addition to two reference electrodes, the remaining 30 channels consists of Fp1, Fp2, F3, F4, F7, F8, Ft7, Ft8, Fc3, Fc4, T3, T4, C3, C4, Tp7, Tp8, Cp3, Cp4, T5, T6, P3, P4, O1, O2, Fz, FCz, Cz, CPz, Pz, and Oz. The sampling rate is 1,024 Hz.

EEG signals were preprocessed in EEGLAB, which is an open source Matlab toolbox for physiological signal processing [52]. First, the EEG signals were digitally filtered with a 1-45 Hz bandpass to remove linear trends and minimize the introduction of artefacts. Second, we performed independent component analysis (ICA) to decompose the EEG signals into independent components characterized by their topographies and PSDs. The experimenter visually inspected these features and marked each independent component as either an EOG artefact or EEG signal component. The artefacts components were discarded from the subsequent process, resulting in a mean rejection rate of 9.8 percent (range = 3.1-22.3 percent), while the signal components were back projected to reconstruct artefact-free EEG signals [24]. Third, because we only used one reference electrode during the EEG recording, we re-referenced the data to the average of the two electrodes. Finally, we went through the whole dataset for each participant and blocked off all sections of data that were contaminated (e.g., abnormal trends based on channel statistical distributions).

2.5 Feature Extraction and Normalization
We used the short-time Fourier transform (STFT) with a sliding time-window approach for feature extraction and normalization based on time-frequency analysis. STFT is a classic technique to analyse a signal jointly in time and frequency [53]. Compared to other signal descriptors [54], STFT can well represent the EEG signals in a two-dimensional spectral domain and provides insights into both the frequency and temporal evolution of the time-frequency features associated with brain activities. The time-frequency features are estimated based on the concept of event-related desynchronization and synchronization that represents changes of the power in specific frequency bands [55], [56]. As illustrated in Fig. 2, the STFT extracts several segments of the EEG signals by using a window that moves with time. If the time window is sufficiently narrow, then each segment that is extracted can be viewed as stationary, which enables the Fourier transform to be used [24]. By moving the window along the time axis, the relation between the variance of the frequency and time can be identified.


Fig. 2.
Schematic representation of our sliding time-window approach for time-frequency feature extraction. The power spectral features of the EEG signals are computed in a time window wn and in the frequency band fb of interest. The power spectral features that are recorded during the process of watching a film clip are averaged over both time and frequency. The original figure was presented in [24].

Show All

In this work, EEG signals were segmented into a number of 2-s time windows with a 50 percent overlap between two successive time windows. The power spectral features of the EEG signals on 30 channels were extracted in 5 frequency bands: delta (δ:1-4Hz), theta (θ:4-8Hz), alpha (α:8-12Hz), beta (β:13-30Hz), and gamma (γ:31-45Hz). In addition to the power spectral features, the difference between the spectral power of all of the 12 symmetrical pairs of electrodes on the right and the left hemispheres was extracted to measure asymmetric brain activity in 5 frequency bands. These 12 pairs of electrodes were: Fp1-Fp2, F3-F4, F7-F8, Ft7-Ft8, Fc3-Fc4, T3-T4, C3-C4, Tp7-Tp8, Cp3-Cp4, T5-T6, P3-P4, and O1-O2. As a result, a total number of 210 (150 PSDs and 60 ASMs) EEG features were used.

We normalized the segmented EEG data when watching each film clip with a corresponding resting period with eyes open to reduce individual variability and the lasting effects of the previous elicited emotions on the current target emotion. Similarly, the power spectral features recorded during a resting period were averaged over the same frequency band and time. Then, we subtracted the baseline power of each resting period from all of the corresponding segments of the extracted features in such a way that the change in the power was based only on the current film clip and was not affected by the previous clips [24], [57] .

SECTION 3Emotion Analysis for Personality Inference
3.1 Personality Classification
In addition to 210 PSD and ASM features, which were extracted from EEG signals, 8 subjective scores were selected as features, including two emotion regulation strategies (cognitive reappraisal and expressive suppression), five dimensions of the SAM (arousal, valence, liking, familiarity and dominance), and the score of target emotion (e.g., the score for joy when watching a joyful film clip).

We chose Linear Discriminant Analysis (LDA) for supervised feature reduction, which projected high-dimensional data with labels into a low-dimensional space with good class-separability by maximizing Fisher separation criterion. The personality trait score is used as ground truth. However, because the number of features was large relative to the number of observations, the within-class covariance matrix of the features becomes singular. To solve this problem, we applied Sparse LDA [58], which performs feature selection to automatically choose a subset of features. The SLDA performs the LDA to find a subset of features that have the largest Fisher separation value with a sparseness criterion imposed such that class separation and dimension reduction are performed simultaneously. The SLDA is based upon the optimal scoring interpretation of LDA and extended to perform sparse discrimination via mixtures of Gaussians if boundaries between classes are non-linear or if subgroups are present within each class. Note that we followed the original paper of SLDA [58] and used the terminology ‘feature selection’ in this work. The reason was that in the implementation of SLDA, the algorithm will perform the elastic net regression with early stopping at a particular value (i.e., the value of the parameter STOP) of the L1 regularization parameter [59]. Therefore, STOP is an integer that determines the desired number of non-zero variables. The number of features after the SLDA process is not equal to the number of class minus 1, but the value of STOP.

The features obtained after SLDA were entered as inputs to a Support Vector Machine (SVM) for personality classification. Specifically, we built five SVMs, and each SVM corresponded to one dimension of personality traits. We collected an individual's self-reports on the Big Five dimensions of personality and computed the mean of each dimension. Then, we used the medians (Extraversion-3.63, Agreeableness-3.89, Conscientiousness-3.56, Neuroticism-2.25, and Openness to experience-3.5) to divide all participants into two classes for each dimension of personality traits. In our implementation using Matlab, we applied the SpaSM toolbox for SLDA [60] and the LIBSVM toolbox for SVM [61]. Because original feature dimension was 210 or 218 when adding 8 features of subjective ratings, we searched the range of [−210, −1] or [−218, −1] in each testing to optimize the parameter STOP in the SpaSM toolbox each time. In LIBSVM toolbox, we chose the RBF kernel function and optimized the cost parameter c and gamma parameter g in the range [−8, 8] using SVMcgForClass. The leave-one-subject-out cross validation was used in this study. At each time, 36 participants were selected for training the classifier and the remaining one participant was used for testing. The average classification accuracy was used to indicate the model performance.

3.2 Experimental Results
3.2.1 Personality Analysis
The participants’ assessments for personality traits were shown as follows: Extraversion (M=3.46,SD=0.64), Agreeableness (M=3.88,SD=0.54), Conscientiousness (M=3.5,SD=0.57), Neuroticism (M=2.44,SD=0.72), and Openness (M=3.52,SD=0.61). Bivariate correlation (Pearson correlation) analyses showed that there was a significant negative correlation between Neuroticism and Agreeableness (r=−.533,p<0.001) and between Neuroticism and Conscientiousness (r=−.536,p<0.001). These results indicated that the five dimensions of personality traits were independent from each other except Neuroticism. Participants with low scores on the dimension of Neuroticism tended to report more agreeableness and conscientiousness.

3.2.2 Emotions Elicitation
The participants’ self-reported scores on Cognitive Reappraisal (M=5.78,SD=0.83) and Expressive Suppression (M=3.51,SD=1.36) were analyzed. The descriptive statistical results of the self-assessment scale and the mean intensity rating of the target emotion for seven film clips are shown in Table 2. All seven categories of emotional film clips elicited moderate to high arousal levels on a 9-point Likert scale (mean = 5.43-7.46). On average, the arousal level of Amusement (mean = 6.14) was a little higher than the levels of Tenderness (mean = 6) and Joy (mean = 5.7). The arousal levels of Anger (mean = 7.46) and Fear (mean = 7.3) were significantly higher than Sadness (mean = 5.92) and Disgust (mean = 5.43). The levels of self-reported valence and liking were consistent with our expectations. The positive film clips generated significantly higher valence levels (mean = 5.89-6.92) than negative film excerpts (mean = 1.08-1.68). The participants preferred the positive movies (mean = 5.08-6.89) to the negative ones (mean = 1.49-3.86). The participants were unfamiliar with selected videos except a disgusting film clip from Farewell My Concubine and a sad film clip from Changjiang qi hao. The levels of self-reported dominance ranged from 3.68-4.03, a helpless and weak feeling (i.e., without control) when watching a fearful or angry film clip, to 6.7, an empowered feeling (i.e., in control of everything) when watching a joyful video.

TABLE 2 Mean Ratings of Self-Assessment Scale and Mean Intensity Rating of Target Emotion for Selected Film Clips
Table 2- 
Mean Ratings of Self-Assessment Scale and Mean Intensity Rating of Target Emotion for Selected Film Clips
There were 3 out of 259 (7 emotional categories × 37 participants) cases where the participant did not rate the target emotion (the last column in Table 2) at least one point higher than the other non-target emotions. These 3 cases were excluded from further analysis because the participants’ responses after watching each film clip were inconsistent with the ground truth of the standardized database of movie-induced emotions. On average, the mean intensity ratings of Amusement (mean = 6.81) and Tenderness (mean = 7.17) were higher than that of Joy (mean = 6.03). On the other hand, the mean intensity rating of Anger (mean = 7.7) was larger than that of the level of Fear (mean = 6.54), both of which were greater than the intensity ratings of Sadness (mean = 5.64) and Disgust (mean = 5.54).

3.2.3 Personality Inference from EEG Singlas
We compared the classification accuracy of two models: one SVM classifier with 210 EEG features (150 PSDs and 60 ASMs) and the other SVM classifier with 210 EEG features and 8 subjective ratings (CR, ES, arousal, valence, liking, familiarity, dominance, and target emotion). A paired-sample t-test showed that the introduction of features from subjective ratings significantly increased the average classification accuracy of personality traits (mean = 2.92 percent, t(34)=3.077,p<0.01).

As shown in Table 3, the average classification accuracies of the model with only EEG features were 73.8 percent for Conscientiousness and 71.49 percent for Agreeableness, which were higher than the classification accuracies for Extraversion, Neuroticism, and Openness (64.06-64.76 percent). Moreover, when positive emotions were elicited, the classification accuracies were higher for Extraversion (72.97 percent when a joyful film clip was presented), Agreeableness (77.78 percent when an amusing movie was played), and Conscientiousness (78.38 percent when a joyful video was presented). In contrast, when negative emotions were elicited, the classification accuracies were higher for Neuroticism (72.97-81.08 percent except disgust) and Openness (72.97-78.38 percent except sadness). When participants watched a disgusting film clip, the classification accuracy was higher for Conscientiousness (83.78 percent).

TABLE 3 Comparison of Classification Accuracy Between Classification with PSD & ASM Features from EEG Signals and Classification with Features from Both EEG Signals and Subjective Ratings (the Highest Classification Accuracies of Personality Traits Were Highlighted for Each Emotional Category)

When features from subjective ratings were entered as model inputs, the SVM classifier achieved better classification accuracies in all of the five personality traits. The improvement of classification accuracy ranged from 0.43 percent for Conscientiousness to 6.3 percent for Neuroticism. In addition, although the differences of classification accuracies between positive and negative emotional materials were the same between two SVM classifiers, the introduction of features from subjective ratings increased the discriminative power of classification accuracies between five personality traits. Specifically, when positive emotional materials were played, classification accuracies were improved: 1) from 72.97 percent to 81.08 percent for Extraversion (with a joyful film clip); 2) from 77.78 percent to 86.11 percent for Agreeableness (with an amusing movie); and 3) from 63.89 percent to 80.56 percent for Conscientiousness (with a joyful video). In contrast, when negative emotional materials were presented, the classification accuracies increased to 78.38-81.08 percent for Neuroticism. Similarly, the highest prediction accuracy of Neuroticism occurred when the participants watched a film clip that made them feel angry. When a disgusting video was played, the classification accuracy of Conscientiousness (83.78 percent) did not enhance, but the accuracy of Openness improved from 78.38 percent to 83.78 percent due to the introduction of more features from subjective ratings.

Also, we performed three classifications using both EEG signals and subjective rating features from: (1) all 7 film clips, (2) 3 positive emotions, and (3) 4 negative emotions, respectively. Compared to the model with features from each film clip, the model with features from all film clips achieved worse classification performance for all five personality traits (from 55.41 percent to 67.82 percent). In contrast, the model with features from 3 positive film clips achieved better classification performance for Extraversion (71.17 percent) and Agreeableness (78.72 percent) traits, while the model with features from 4 negative film clips achieved better classification performance for Neuroticism (71.94 percent) and Openness (72.7 percent) traits.

3.2.4 Personality Inference from Facebook Likes
In this section, we compared the accuracy of Big Five personality inference from EEG signals and from the generic digital footprint on social network (e.g., Facebook Likes). Facebook Likes are used by Facebook users to express positive association with online and offline products, activities, sports, musicians, books, restaurants, or websites [26]. We obtained the sample data from the myPersonality project which was a popular Facebook application that offered to its users psychometric tests and feedback on their scores (including the Big-five inventory). In the process of data screening, all participants must have:

1. Chinese nationality;

2. At least 20 Facebook Likes [26];

3. Complete Big-five inventory scores.

These screening conditions resulted in a sample of 88 participants whose demographic characteristics were similar to our sample (Table 4). To infer personality from Facebook Likes, we first represented an individual's Likes as a matrix, where entries were set to 1 if there existed a relationship between an individual and a Like and 0 otherwise. The categories of Likes were excluded if there was no entries, resulting in a total of 99 categories of Likes. These 99 feature vectors were entered as inputs to five SVMs for classification of five personality traits. Similarly, we used the medians (Extraversion-3.645, Agreeableness-3.5, Conscientiousness-3.25, Neuroticism-2.7, and Openness to experience-4) to divide all participants into two classes for each dimension of personality traits. In our implementation using Matlab, we applied the SpaSM toolbox for SLDA and the LIBSVM toolbox for SVM. A 11-fold cross validation was applied to avoid overfitting.

TABLE 4 Comparison of the Big Five Personality Inference from EEG Signals and from Facebook Likes
Table 4- 
Comparison of the Big Five Personality Inference from EEG Signals and from Facebook Likes
TABLE 5 SLDA-Based Top Five Features Extracted from EEG Signals (PSD and ASM) and Subjective Ratings (ER and SAM)

As shown in Table 4, personality inference from EEG signals achieved better classification performance than that from Facebook Likes for all five dimensions. The recognition accuracies of personality from Facebook Likes were lower than the random chance except the dimension of Openness, indicating that personality judgments based on explicit behaviors require a large amount of digital footprint on social networks to achieve an acceptable accuracy (e.g., a sample of 86,220 volunteers in [26]).

3.2.5 Selected Features
In this work, we applied the SLDA that performs feature selection to intelligently choose a subset of features. Due to page limitations, we only analyzed the top 5 features for each dimension of personality traits in the category of emotion with the highest classification accuracy (e.g., Extraversion in the emotional category of joy, Agreeableness in the emotional category of amusement, Conscientiousness in the emotional category of tenderness, Neuroticism in the emotional category of anger, Openness in the emotional category of disgust).

Compared to features from subjective ratings, more PSD and ASM features extracted from EEG signals were selected as the top 5 features with greater weights in the prediction of personality traits ( Table 5). Specifically, the delta frequency band in the frontal cortex and gamma frequency band in the temporal cortex were sensitive to recognize an individual's Extraversion trait. The theta frequency band in the parietal cortex, the beta frequency band in the frontal cortex, and the frontal theta and alpha asymmetry features (Fp1-Fp2) played important roles in predicting the Agreeableness trait. The gamma frequency band in the frontal cortex and the theta middle line (Cz and Oz) contributed more to the classification of the Conscientiousness trait. Theta and beta frequency bands in the frontal and parietal cortex were sensitive to predicting the Neuroticism trait. The alpha frequency band in the temporal cortex, the beta frequency band in the frontal cortex, the frontal theta asymmetry feature (Fp1-Fp2) and the frontal beta asymmetry feature (F3-F4) all played important roles in recognizing the Openness traits.

On the other hand, we found that CR and ES worked together to predict Extraversion for all of the seven categories of emotions, while CR played an important role in recognizing Agreeableness only when a joyful or disgusting film clip was presented. Dominance was another salient factor for personality inference. It contributed a lot to the prediction of Extraversion for all positive emotions and disgust as well as the prediction of Openness for tenderness and fear only. In the five dimensions of SAM, familiarity contributed to the classification of the Agreeableness and Conscientiousness traits, and Liking was sensitive to recognize an individual's Openness trait.

SECTION 4 Discussion
In this experiment, the classification accuracies of our model with only EEG features were, on average, higher for Conscientiousness and Agreeableness traits (71.49-73.8 percent) than those for Extraversion, Neuroticism, and Openness traits (64.06-64.76 percent). When positive emotional materials were presented, the classification accuracies were higher for Extraversion, Agreeableness, and Conscientiousness traits. In contrast, when negative emotional content was presented, the classification accuracies were higher for Neuroticism (except disgust) and Openness (except sadness) traits. According to our analyses of the SLDA-based feature weights, PSD and ASM features extracted from EEG signals contributed more to the prediction of personality traits compared to those features from subjective ratings. These EEG features consisted of frontal alpha asymmetry features, frontal theta asymmetry features, frontal beta asymmetry features, and the theta middle line features, as well as delta, theta, beta and gamma frequency bands in the frontal, temporal and parietal cortex.

The frontal spectral power asymmetries have been proven sensitive to emotional fluctuation, reflecting the affective and motivational processing of emotional states asymmetrically [62]. Particularly, the frontal alpha asymmetry (FAA) features played an important role in recognizing different emotional states. The previous study indicated that the FAA feature F3-F4 distinguished between positive and negative emotions, while AF3-AF4 differentiated a positive emotion from similar emotions in both valence and arousal dimensions [24]. FAA refers to the patterns of asymmetrical anterior EEG activities in the alpha band, which was a typical indicator of asymmetric brain activity in the frontal cortex [63]. The theory of approach/withdrawal motivation states that positive emotions are correlated with approach motivation, while negative emotions are correlated with withdrawal motivation [64]. The valence model of FAA suggests that the greater brain activities in the left hemisphere are associated with positive emotions, while the greater right hemisphere activities are associated with negative emotions [65]. Both trait positive (or negative) emotions and state positive (or negative) emotions are associated with more activities in the left than right frontal cortex, which are manifested in the greater spectral power of the alpha band in the right than left frontal cortex [66]. The theta frequency band in the frontal middle line [67] and parieto-temporal region [68] was another source of dominant features used to classify positive and negative emotions.

We also found that the introduction of features from subjective ratings increased the classification accuracies in all of the five personality traits (ranging from 0.43 percent for Conscientiousness to 6.3 percent for Neuroticism). These subjective indices also improved the discriminative power of classification accuracies between five personality traits in each category of emotion. According to the SLDA-based feature weights, emotion regulation played important roles in the prediction of personality. Specifically, CR and ES worked together to predict Extraversion for all of the seven categories of emotions, while CR played an important role in recognizing Agreeableness only when a joyful or disgusting film clip was presented. These results suggested that, no matter which category of emotion was elicited, extroverted individuals tended to reinterpret the meanings of emotional film clips to change the trajectory of their emotional responses (CR strategy), while introverted individuals were more likely to represent a response-focused strategy to hide their current emotional states (ES strategy). These findings were consistent with the literature [40], [41], [43], [44]. On the other hand, the Agreeableness trait was only associated with effective strategies for emotion regulation. These results implied that agreeable people were more likely to choose positive emotional situations and might have greater aptitude for emotion regulation than disagreeable ones. Previous studies have explored the differences of agreeable people and disagreeable people in the situation selection stage of the emotion regulation sequence [69] . The authors found that participants with a higher level of agreeableness preferred positive pictures and media than those with a lower level of agreeableness.

To the best of our knowledge, this work was the first attempt to recognize an individual's personality traits by analyzing brain activity when he or she watches a series of emotional film clips. Our methodology can, in fact, assess personalized emotional fluctuations to infer personality traits with satisfactory accuracy. Using only brain wave dynamics, we effectively distinguished between two classes of each dimension of personality traits. Future studies may benefit from the recordings of a user's brain activities in response to emotional stimuli as well as his/her digital footprints on social networks to infer personality.

Our system is developed for personalized emotion recognition and personality inference. These achievements could have a highly relevant impact in personality disorder psychopathology diagnosis and treatment because a personality disorder produces an altered emotional response. Currently, the emotional state is determined in a clinical setting using questionnaires that have limited accuracy and quantitative power. Hence, monitoring rapid emotional responses in terms of stimulation time could make an objective evaluation of disordered progression possible.

SECTION 5 Conclusions
In this paper, we confirmed the feasibility to recognize an individual's Big-five personality traits through the analyses of brain activities when he or she watched emotional film clips. We compared the classification accuracy of two models: one SVM classifier with EEG features and another SVM classifier with features from both EEG and subjective ratings. Our model achieved better classification performance for Extraversion, Agreeableness, and Conscientiousness when positive emotional videos were presented than negative ones. Neuroticism and Openness were better classified when negative emotions were elicited. Moreover, the introduction of subjective evaluations improved not only the classification accuracies in all of the five personality traits but also the discriminative power of classification accuracies between five personality traits in each category of emotion.

The contribution of our framework was to develop a working system with high performance, which did not exist for personality inference through the analyses of an individual's brain waves in response to emotional film clips. The performance of our system can be regarded as a benchmark, such that more advanced techniques for feature extraction, feature selection, and classification deserve further study in their own right and will be reported in future work.