It has been widely suggested that a key goal of visualization systems is to assist decision making, but is this true? We conduct a critical investigation on whether the activity of decision making is indeed central to the visualization domain. By approaching decision making as a user task , we explore the degree to which decision tasks are evident in visualization research and user studies. Our analysis suggests that decision tasks are not commonly found in current visualization task taxonomies and that the visualization field has yet to leverage guidance from decision theory domains on how to study such tasks. We further found that the majority of visualizations addressing decision making were not evaluated based on their ability to assist decision tasks. Finally, to help expand the impact of visual analytics in organizational as well as casual decision making activities, we initiate a research agenda on how decision making assistance could be elevated throughout visualization research.
SECTION 1Introduction
The introduction section of many seminal books about visualization emphasizes that a vital goal of data visualization is to assist decision making activities. Bertin, in 1983, suggested that visualization is to enable “the decision maker to discover what should be said and done” [14]. Cook & Thomas, in 2005, illuminated an era where visual analytics will be used in a “massive, multi-dimensional, multi-source, time-varying information stream to make decisions in a time-critical manner.” [37]. Munzner, in 2014, included decision making as a structural element of her definition of visualization, as the case where decisions are made by humans, contrasting this with “computational decision making” where visualization usage is redundant [111]. To illustrate the potential of data visualization, almost all use case examples in Spence's book involve a decision making task (e.g., a car purchase), to which visualization helps the decision maker to untangle “fuzzy” goals, derive data, interact and annotate, all shaping a “mental model” that will finally lead to an informed choice [150]. Ward et al., in 2015, was even more explicit about the importance of decision making as being the absolute reason “why visualization is important” assisting the decision maker to manage the “information overflow” [167]. More recent books, by Tominski & Schumann (2020) and Ware (2021), in the same spirit suggest that visualizations are to facilitate “flexible decision making” via user “guidance” [155] while “the goal of most visualization is decision making”, respectively [168].

Fig. 1: - Well-established taxonomies ranging from low to high-level visualization tasks [4], [19], [85]. The red annotations illustrate our main research question: Has decision making been studied explicitly within visualization research, and, if not, should it?
Fig. 1:
Well-established taxonomies ranging from low to high-level visualization tasks [4], [19], [85]. The red annotations illustrate our main research question: Has decision making been studied explicitly within visualization research, and, if not, should it?

Show All

These books do not claim decision making is the only important high-level goal of visualization; they do include and describe other goals such as sensemaking, exploratory analysis, or presentation as well. However, in all these seminal visualization books, references to decision making stop at an introductory or overview level. The rest of the content guides the reader on how to select visual encodings based on perceptual principles or which visualizations better support users in various analytic tasks, such as to discover a correlation or monitor a trend over time. There is a notable lack of discussion on how users make decisions with visualized data or how we should design visualizations to eventually facilitate a decision making task.

Now, one might argue that decision making is too high-level or too ambiguous to be discussed within visualization fundamentals. But, other tasks such as “exploratory analysis” or “sensemaking” that are arguably even more ambiguous than decision making have their deserved place in visualization theory. Additionally, decision making is not an ambiguous goal; it is the subject of systematic study in other fields including psychology, cognitive science, economics, and management science. Echoing such systematic study, two seminal papers by van Wijk (2005) and Fekete et al. (2008) argue that the final decisions of visualization users constitute a better and more operationalizable way of assessing the value of data visualization than more ambiguous goals such as “insight” or the amount of extracted “knowledge” [52], [161]. Ware (2021) similarly advocates that “Most studies have only compared parallel tasks for perception of basic patterns but the whole point of these visualization techniques is to support decision making where many variables are involved” [168]. Another hypothesis for the lack of deeper study of decision making is that it maintains a hierarchical, perhaps even dependent, relationship with other visualization tasks. That is, decision making includes those tasks or they include it. But if this is the case, one should, at a minimum, be able to find some discussion of that relationship between tasks/goals.

Presumably, despite its consensually agreed importance, the study of decision making still lacks an explicit tie to visualization research. To be able to truly improve decision making, the field of visualization needs to build a deeper understanding of just what decision making is and how we can study it more explicitly.

To assist that goal, we contribute an extensive systematic literature review of: (i) theory and empirical visualization papers on the topic of decision making, (ii) visualization techniques and systems that aim to aid decision making activities (iii) visualization task taxonomy papers, (iv) visualization scholarly books. We seek solid evidence to verify or refute our hypothesis that visualization research has largely lacked a systematic study of and connection to decision making. Our primary contribution is a synthesis of this literature through the lens of decision making tasks to identify gaps in taxonomies, theories, and user studies. Additionally, we explain potential reasons for the omission of decision making tasks, and we provide actionable suggestions for visualization via a research agenda. We hope all these components can help broaden the impact of visualization to decision making activities.

SECTION 2Background: Visualization Research & Decision Making
Visualization books, as reviewed in the introduction, refer to decision making at an introductory or overview discussion level. To better understand the state of decision making-related research in the visualization community, we examined academic papers related to this topic. We first describe the rules we applied in order to identify a feasible core of seminal visualization papers that contribute to our understanding of human decisions.

2.1 Methodology for Paper Selection
Arguably, any well-designed visualization can potentially contribute to data-informed decisions. We narrowed our scope to visualization papers which appear explicit in their contribution to decision making activities. To identify such papers, we applied the following criteria.

We started with a pool of visualization papers that contain the word “decision” in title or abstract. We considered all years of all major visualization venues resulting in 301 initial papers: TVCG (108 papers), InfoVis (9), VAST (22), EuroVis (93), and CHI (69). For CHI, as it is not a venue targeted to visualization, we also included the word “visualization” in the query. We considered only full-length papers excluding extended abstracts, posters, and workshop papers, except BELIV(7). We then removed papers where the word decision in the abstract did not refer to human user decisions, but instead to other decisions such as designer decisions, algorithmic decisions, as well as duplicate entries. We also removed a few papers that did not contain data visualizations (e.g., a VR experience without data). For TVCG, InfoVis and VAST, we searched in the IEEE Computer Society Digital Library (computer.org/csdl/). For CHI and BELIV, we used the ACM Digital Library (dl.acm.org). For EuroVis, we used the DSpace platform of the Eurographics Digital Library (diglib.eg.org). We also used Google Scholar for complementary searches because we spotted some missing entries or invalid links within the original digital libraries.


Fig. 2:
An overview stacked area chart of the 123 visualization papers of our literature review (TVCG, VAST, InfoVis, EuroVis, CHI, BELIV) which contain the word “decision” in their abstract/title.

Show All

Our methodology resulted in 123 visualization papers (shown in Fig. 2), from TVCG (62), InfoVis (4), VAST (12), CHI (23), EuroVis (17), and BELIV (5). We note that while the aforementioned venue selection helped us identify a large and relevant collection of papers, we might have missed seminal works from nonstandard visualization venues [116] or papers in visualization venues that do not mention decisions or decision making in their title/abstract [63]. Please refer to osf for supplementary material of the methodology we followed (e.g., precise queries and removals) as well the complete list of derived papers https://osf.io/j7hsu/?view_only=8bdb9dfc2d214d2fa34b5af6184bd029.

Fig. 2 shows that although in the early years of visualization the occurrences of “decision making” were sparse, there has been a strong trend over the last two years. We tag papers in our review into “theory & empirical” and “design” categories, based on the new IEEE VIS area model1. Theory & Empirical papers, corresponding to Area 1, are either papers that aim to contribute to fundamental questions on how we understand, assess, categorize, or formalize visualizations and/or visual analytics as well as empirical research papers which aim to contribute research methodologies or concrete results of assessments of a visualization/visual analytics. We expect that these papers are more likely to contain fundamental understanding of decision making in the context of visualization. We will use the term “design” papers to refer to all other papers containing the remaining areas. These papers broadly include new visualization techniques, tools, or systems to which one of the stated goals of the development effort is to assist decision making. In many instances, the benefit to decision making is not necessarily framed as a fundamental contribution in these articles, but more as an incidental contribution. The design papers will be discussed in Section 5.

2.2 Visualization & Decision Making Foundations
This section discusses the 38 theory & empirical visualization papers on the topic of decision making as derived from our paper selection method. By investigating these papers, which we consider as the closest to our paper, we sought to better understand the role of decision making as a task in visualization research and to determine whether it has been underrepresented in this discipline as we hypothesize. Other objectives and questions arise as well. For example, do most visualization researchers consider decision making a task that visualization can or should assist? What are the characteristics or attributes of decision making which make it an activity that could be aided by visualization? How could visualization assist decision making or how would one evaluate whether a visualization is indeed assisting decision making?

Decision making has been widely identified as a task that visualization can or should assist. Most works acknowledge decision making as a critical high-level goal for visualization, but, similarly to the scholarly visualization books, do not provide further elaboration [12], [28], [40], [51], [109], [138], [140], [156], [190]. Others explicitly advocate via underpinning elements [5], [6], [38], [134] or literature reviews [44], [72], [74] that decision making tasks are understudied in visualization research [36]. Empirical studies provided preliminary evidence that visualization users respond differently to analytic tasks, such as magnitude estimations [81], [184] or comparisons [42], than to their direct-equivalent decision tasks [42], [81], [184]. That controversy led researchers to hypothesize that visualization users rely on different heuristics (e.g. loss aversion [184]) to judge the same data for different purposes, concluding that perceptual [81] or analytic [42] accuracy “may not feed forward directly into decision making” [81].

Visualization research has proposed potential characteristics of decision making which make it an activity that could be aided by visualization. At first, decision making is pervasive; even data analysis itself involves micro decisions during the personal workflow of the analyst that visualization tools could facilitate [74], [100], [133], [134], [180]. High-level decision making involves improvisational practices [98], data communication [98], collaborative data work [79], [98], and a need for uncertainty awareness [38], [54], [72], [82], [133] that require people to be informed by data in a timely manner. Visualization can also help to address irrationality phenomena related to decision making [45] such as how vulnerable decision makers can be to framing [73], to risk aversion [184] to numerical anchors [32] or irrelevant data [43]. Most importantly, visualization can act as first-line-of-defense interface between a decision maker and skewed or malicious data [38].

Visualizations could contribute several interventions to aid decision making tasks. Research has shown that visualizations which offer sufficient guidance [136], [184] emphasize critical information [41], [136] or alter the way users interact with the data by removing the displayed data [41] can encourage more rational decisions. Along with visualizing the underlying data that are relevant to the decision, visualizations can also display the decision process itself [100] or offer tools that further facilitate multiverse analysis [100].

Guidelines of how we can evaluate whether a visualization is assisting decision making remain an open challenge for visualization research. To evaluate decisions, we eventually need to inject decision tasks into the experimental protocols. However, even when the goal is to eventually improve decision making activities, most studies favor perceptual accuracy [32], [115] and avoid exposing participants to decision making tasks (we discuss this in more detail in section 5). Decision tasks also have been examined but are rather rudimentary [41]–[42][43], [184]. Narrowing complexity to binary choice questions serves to reliably capture a human tendency (e.g., to select between a fast and an effortful strategy). Yet visualization problems typically involve several attributes and data points. More complex tasks that have been studied are multi-attribute choice tasks [36], [44], auction bidding tasks [136], and time intervals choices (e.g. when to arrive to catch a bus) [54]. A few works build on knowledge from decision making disciplines to propose new ways to evaluate the decision making capability of a system, including profit-maximizing decision strategies [44], [136], [184], to vary decision task complexity with cognitive fit theory [154], to study group decision making tasks using joint activity theory [79], to infer user's decision strategies using eye tracking [88], or to consider less common performance metrics such as working memory and locus of control [36].

All these works outline several opportunities for visualization to aid decision making tasks. Yet, as with the scholarly books, when compared to the perceptual design guidelines, theories, and evaluations, the content on decision making remains scarce in the visualization literature. We next investigate how the theory meets the practice; how visualizations verify their effectiveness on aiding decision making. We first specify what constitutes a “decision making task” in the context of visualization (Section 3) and then investigate its place in the visualization task taxonomies (Section 4). Section 5 finally investigates how visualizations validate their ability to assist decision tasks in practice.

SECTION 3What Is Decision Making?
Decision making has been studied across several domains including mathematical optimization problems [107], machine automation [29], economics [25], political [70] and management science [13], as well as psychology perspectives [68]. Within computer science, the related notions of decision support systems and recommender systems also have a rich history with significant study [128]. Providing a synthesis overview of “What is decision making?” across all these disciplines would be a valuable, but unfeasible goal for a single paper to contribute to visualization research. Even within fields where the study of decision making has been a primary focus for years, extracting the “big picture” of human decisions with ontological commonalities with other fields (e.g. psychology or economics) is exceptionally challenging [1]. The purpose of this paper is not to explain decision making as a field of study. Instead, we narrow our scope by approaching decision making as a potential user task that can be aided by visualization.


Fig. 3:
3-stage decision making model by Herbert Simon [112], [146].

Show All

Decision making that is more relevant to visualization can be a task to which solely computational solutions appear inadequate and thus cannot be fully automated. For example, suppose that a country needs to decide on an energy transition plan accounting for costs, supply risk of materials, and recycling potential of energy technologies, and all these cumulative of time, global and local politics as well as human factors and incentives. This type of decision is common and critical for organizations (e.g., policing, recidivism, recruiting, medical judgments). Personal decision making also can be hindered by data complexity or, even when datasets are small, by human biases and uncertainty (e.g., which real-estate property to buy, which medical treatment to undergo, or who to vote in national elections). Instead, a decision problem that can be automated or is solvable by the human brain alone does not necessarily require aid from a visualization tool [142].

One of the most versatile accounts of the act of human decision making was given by the Nobel Prize and Turing Award winner Herbert A. Simon [146]. Due to its conceptual simplicity and wide applicability, Simon's model, originated in management science, has been transposed by several other domains including economics [145], psychology [148] and political science [147]. Building on that, Simon invented the concept of “bounded rationality” as an alternative basis for the mathematical modeling of decision making [23]. Within a psychology perspective, Kahneman later expanded upon Simon's idea by focusing on the erroneous effects of irrationality in simple tasks [80]. Interestingly, Gigerenzer's research on decision making–which greatly contradicts Kahneman's approach–also expands upon Simon's model to argue that simplified decision strategies often lead to better outcomes than a theoretically optimal procedure [58].

Simon identifies three essential stages in human decision making: INTELLIGENCE, DESIGN, and CHOICE [146] (Fig. 3). During the INTELLIGENCE decision stage, the decision maker is identifying the problem by collecting and understanding the data relevant to the decision to be made [112], [146]. In the context of a decision making process, the INTELLIGENCE stage is a subtask that can be approached as “sense-making” [172] or data exploration [85]. Sensemaking concerns the framing of a cognitive representation of a situation by drawing upon various data sources [90]. Conversely, in analytics, decision making has been also identified as a subtask within a sensemaking loop [121] (we elaborate on this conflicting observation in Section 4).

During the DESIGN decision stage, the decision maker deals with the generation and synthesis of alternative solutions to the problem [112], [146]. Visualization research has shown that the design and scenario simulation of decision alternatives can be a large area of opportunity for novel visualization tools [11], [47]. During the CHOICE decision stage, the decision maker deals with selecting the ‘best’ solution from amongst the alternative solutions using some criteria. Choice tasks have been defined in the context of multidimensional visualizations as a multi-attribute choice tasks [44] and have been addressed by several visualization techniques that help users to define the importance of decision criteria and visually combine multiple attributes into aggregated scores [63], [118]. Choice tasks have also been studied in visualization as tasks of narrower complexity, yet vulnerable to cognitive biases and uncertainty [45], [81]. We note here that while these classes of activities in Simon's model conceptually can help us disentangle the decision making process, they are shown to be more tangled and iterative in real world decision making [47].

In this paper, a task is identified as a “decision making” task when the human user has an explicit intent to derive an ultimate choice of direction as a final outcome (i.e., CHOICE stage of Simon's model). Such choices can be involved with an important decision, such as the energy plan mentioned before, or other large, collaborative, or high-stakes decisions. Other choices can be also more personal or smaller, such as a person deciding which coffee maker to buy or an analyst choosing which model parameter to use. Now, specifying the way such large or micro tasks can be ultimately assisted by a tool is another important discussion, which it is out of the scope of this paper. Assistance might be needed in the form of traditional decision-support, including a level of automation or guidance, but also with minimal intervention, by providing the kind of information the decision maker needs in an effective format. The means with which decision makers need to be aided by visualization is left to future work to investigate. Our focus here is study, in the context of visualization, of the human decision task, at any level of granularity, as soon as it leads to an explicit and intentional CHOICE act.

SECTION 4Where Do Decision Tasks Hide?
This section investigates whether decision tasks, as described in the previous section, are included in visualization task taxonomies, and if so, how and where. We identify as “decision tasks” those tasks that, at a minimum, contain the CHOICE stage (see Figure 3). We characterize as “low-level” decision tasks those tasks that contain only the CHOICE stage and “high-level” decision tasks as those including the addition of any other stage in Figure 3.

4.1 Revisiting Visualization Task Taxonomies
Visualization task taxonomies can serve both general-purposes as well as particular domain activities and datasets [86]. Building on the review of general-purpose visualization task taxonomies by Brehmer & Munzner [19], we revisit papers that explicitly contribute a visualization task classification system including low-level tasks (often conflated with interaction techniques) [4], [9], [21], [26], [31], [33], [48], [61], [83], [96], [131], [144], [157], [158], [166], [171], [181], [188], high-level tasks [6], [24], [102], [121], and papers with intermediate tasks or tasks that span both levels [19], [69], [110], [120], [130], [131], [151].

Although decision making is often considered as the ultimate high-level goal of data visualization [6], [9], [24], we could not find a taxonomy that contains decision making as an explicit task [6], [19], [102], [121] akin to other high-level tasks such as exploratory analysis, identification of causal-effect relationships, or presentation [85], [139]. We found one paper [141] (not in Brehmer & Munzner's review) that explicitly identifies decision making as a task that differs from other high-level tasks such as problem solving, sensemaking, knowledge discovery, and forecasting, without unfortunately providing descriptions for each of them.

Several taxonomies of low-level analytic tasks have been proposed [4], [9], [21], [26], [31], [33], [48], [61], [83], [96], [131], [144], [157], [158], [166], [171], [181], [188]. Low-level analytic tasks, such as retrieve a value, filter, find extrema, sort, characterize distribution, find anomalies, cluster, and correlation [4] (shown in Fig. 1C.), are meant to cover basic activities people do when analyzing data. Similarly with the high-level taxonomies, we could not find a low-level taxonomy that contains making a decision as an explicit task even in the form of a low-level choice task of narrow complexity (e.g., a binary choice).

The visualization task taxonomy papers do not clarify whether decision making tasks are intentionally omitted nor do they identify the reasons for such omission. Decision making is almost never defined or even casually described. Some taxonomy papers mentioned decision making as a distinct task from sensemaking [19], [141]. For example, Brehmer & Munzner [19] specify sensemaking as a task which is included in “Discover” and all types of “search”: “lookup”, “locate”, “browse”, and “explore” (shown in Fig. 1.A), but there is no similar clarification for decision making tasks. Instead, other researchers mention a type of decision making as a subpart of the sensemaking loop of the analyst (e.g., choosing a prediction or next action) [121] or, generally, of the analyst's workflow (e.g., choose analysis steps/encodings) [69] without further elaboration of their relation with a broader class of decision making tasks.

Similarly, while omitting decision tasks from their taxonomy, other researchers mention decision making as part of collaborative activity [120], or as a component of the tasks “Expressing Ideas” and “Describe” [151]. Interestingly, participants involved in the creation of Roth's taxonomy seem to describe some of their tasks as “advanced decision making” [130]. Yet it was not clear why decision making was finally omitted. Other works admit explicitly that decision making constitutes a gap in visual analytics [6], [158], while Andrienko & Andrienko [9] suggest that their low-level tasks can be pre-conditions to assist the CHOICE decision making stage (i.e. multi-attribute choice task) (described in Section 3). We only found one non-visualization paper (but included in Brehmer & Munzner [19] review) that includes both “decide” and “choose” tasks in their taxonomy [110]. This was an extensive taxonomy from 1993 containing over 150 elements, both high-level and low-level tasks. The tasks “decide” (“Arrive at an answer, choice, or conclusion based on the available information (the current situation)” and “choose” (“Select after consideration of alternatives - decide on one among the proffered alternatives”) are listed as distinct subtasks of the “Problem solving and planning task”. Yet, this relation was briefly listed in a table and not discussed in the paper.

4.2 Why Visualization Taxonomies Omit Decision Tasks?
Although we were not able to extract explicit argumentation on why decision making is omitted in visualization taxonomy papers, we hypothesize possible reasons and discuss them next.

Speculation 1: Lack of Distinctiveness
Decision making is a subtask of other analytic tasks or just a combination of them.

HIGH-LEVEL TASKS
While elements or certain types of decision making could be part of other high-level analytic tasks, the visualization papers do not seem to suggest that decision making constitutes a subtask. For example, some well established visualization tasks are exploratory analysis, confirmatory analysis and presentation (shown in Fig. 1.B). Exploratory and confirmatory analysis differ on whether the user has formed a-priori hypotheses when conducting data analysis. If not, the user conducts an exploratory analysis task, to search the data, analyze and finally identify useful information [85]. As soon as she forms one or more hypotheses, the user conducts a confirmatory analysis task, seeking to either confirm or reject these hypotheses [85]. Once the analysis is concluded, the aim is to communicate the result effectively in a presentation task [85].

To help illustrate how decision making does not necessarily fit exploration or hypothesis tasks, we draw from an interaction with a senior manager who described her common decision tasks and her relation with the data analyst team of the company: “The decision maker always has a question in mind;a why and the reason is always there. And you stick with that. Whatever you are doing you're trying to answer that question, while analysts, a large proportion of analysts, don't have a concrete question in mind. They see data and try to highlight whatever interesting pattern they find. There are a lot of interesting patterns, but likely not relevant to your question.” [47]. In this example, decision making appears to be closer to directed search having a concrete question in mind which cannot be easily characterized as exploratory analysis. On the other hand, there is no hypothesis testing either since the decision maker has a question and not a statement in mind. Some later extensions of Simon's model (Figure 3) proposed a REVIEW stage right below the CHOICE stage. Perhaps this stage of decision making (check if a choice was indeed a good one) could be seen as a form confirmatory analysis.

Another important relationship to explore is that between decision making and sensemaking. Figure 4 illustrates some of the possible relationships between the two. One view is that decision making is a component of the sensemaking process. For example, Pirolli and Card suggest that there is decision making as a part of the sensemaking loop of the analyst (without clarifying if this is about every type of decision making) [121]. This model views decision making as a specific, distinct activity one makes after knowledge and insight have been gathered and synthesized.


Fig. 4:
Illustrating the confusion on the relation of decision making with well-established high-level visualization tasks like sensemaking.

Show All

In contrast, one might view decision making as a broad expansive task which frequently contains sensemaking as an important initial subtask. This point of view elevates decision making to be a primary human activity and positions sensemaking as a vital step in the process employed to make a decision. We wonder if many of the seminal books on visualization cited in the introduction of this paper follow this perspective, even if not explicitly stated there.

Sedig et al. [141] argue that sensemaking and decision making tasks can differ in terms of processing load and can be highly user–and context–dependent. For example, there are types of decision making that are rapid and based on dynamic, ‘real-time’ information. In such cases, little processing load should be placed on the user's mental state, and a deep understanding of the information space might not be feasible. On the other hand, sensemaking by definition requires the user to engage in deep and effortful mental processing of information. Consequently those tasks might need to be aided by different visual analytic systems [141]. So, it seems plausible that decision making could have its deserved place among other high-level analytic tasks (illustrated in Fig. 1 A + B).

Considering all these different points of view, we are not able to identify a consensus view on the relationship between decision making and sensemaking.

LOW-LEVEL TASKS
Arguably, to make a choice one might need to perform several other analytic tasks, e.g., to sort attributes and compare values. So one could argue that making a choice is not a primary low-level task. However, the other low-level analytic tasks are not necessarily mutually exclusive. For example, to find an extreme value, a user may first sort the data cases [4], or to find an anomaly, the user may in some cases be looking for extreme values and in others for different patterns [4]. So the lack of distinctiveness does not seem to be a sufficient argument for excluding “choice” from low-level visualization taxonomies. In addition, depending on the decision making strategy (e.g., elimination by aspects, weighted additive, satisficing [41]) the associated subtasks might differ. So, the reasonable overlap between a decision task and other low-level tasks does not seem to be enough reason for its omission (illustrated in Fig. 1 C).

Speculation 2: Lack of Operationalizability
Decision making is too high-level, thus not operationalizable to be included as a task.

HIGH-LEVEL TASKS
Indeed, decision making can be inherently subjective, domain-dependent, and it often concerns ill-defined problems and trade-offs [146]. But are exploratory analysis and sensemaking more operationalizable? We would argue that those two activities are most often viewed generally or abstractly, without a formal, operational model. Yet each of them is frequently listed in high-level visualization task taxonomies. Furthermore, the fields of economics, operations research, and management science have extensively studied decision making and can provide models that operationalize complex decision making activities [1]. Based on knowledge extracted by those fields, van Wijk (2005) [161] and Fekete et al. (2008) [52] argued that the final decisions of visualization users could be a more operationalizable way of assessing the value of visualization than other currently established visualization goals such as “insight” [27], [114], [135].

LOW-LEVEL TASKS
As we saw in the related work, some tasks that belong to the CHOICE stage have already been operationalized in visualization studies either as choice tasks of lesser complexity [41]–[42][43], [184] or as a multi-attribute choice where many alternatives and attributes are examined [36], [44]. Moreover, most low-level tasks are not necessarily designed to systematically cover high-level tasks such as “Learning a domain” or “Predicting the future” [4].

Overall, the lack of operationalizability does not seem a sufficient reason for excluding decision tasks from visualization taxonomies.

Speculation 3: Lack of Interestingness
Decision making is too uninteresting or too low-level to be included as a task.

HIGH-LEVEL TASKS
It was clear from all of the scholarly books mentioned in the introduction and the papers on visualization theory discussed in the related work section that decision making as a high-level activity is crucial and an integral part of the definition of visualization as a scientific field [111]. So a lack of relevance or interestingness does not seem to be a sufficient argument for excluding decision tasks from high-level visualization task taxonomies.

LOW-LEVEL TASKS
One argument for excluding “choice” in a low-level task taxonomy is that it can be computationally solvable and thus is not so relevant for visualization. However, this is also the case for most low-level tasks, e.g., finding a correlation or a max value can be fully resolved by computational methods. Thus, a lack of “interestingness” could be attributed to many other low-level analytic tasks.

Generally, low level tasks are not meant to be the reason why we need visualization systems. Visualizations are needed where there is room for human judgment, and automated computational methods cannot provide sufficient solutions [111]. Such low-level analytic tasks when evaluating a system are often meant to act like a “checklist” [4] to assess its effectiveness. For example, if a user can effectively identify a correlation in a visualization system, it may be a stepping stone towards complex pattern recognition during exploratory analysis. Likewise, systems which fail to aid low-level analytic tasks are unlikely to assist high-level tasks. Therefore, a choice task of narrow complexity, although it cannot cover high-level decision making activities, could still constitute an informative proxy task.

On that, as we saw in the related work, there is evidence that visual analytic tasks elicit different responses from equivalent decision making tasks. Users who respond correctly to visual analytic tasks (e.g. a “comparison” task) were shown to fail on an almost identical task, when framed as a decision [42]. So, the lack of interestingness does not seem to be a sufficient reason for omitting decision tasks from visualization task taxonomies.

Overall, a low-level decision task has the same limitations as do the existing low-level analytic tasks. First, as in low-level analytic tasks, low-level decision tasks do not necessarily systematically cover high-level decision tasks. Second, as in low-level analytic tasks, low-level decision tasks are not necessarily mutually exclusive with other low-level analytic tasks. For example, to choose an alternative, one may need to derive values, determine ranges, identify an outlier (e.g., a cheap choice), and check the correlation between price and quality. Third, as in low-level analytic tasks, a low-level decision task does not necessarily specify the procedure to complete the task (e.g., one may choose the first alternative that satisfies her needs or review extensively all options). Finally, it is again possible to replace some low-level decision tasks with computational methods (e.g., computationally identify a single alternative that is superior to all others).

Both a low-level or a high-level decision task differs from other analytic tasks in that it serves different user goals. The goal of making a decision is not to compare values, sort, determine ranges or correlations, neither to explore, confirm a hypothesis or derive a comprehensive summary of a dataset. Instead, the goal of decision making is to investigate, synthesize, and finally to make a selection among several possible alternatives. It seems that the omission of decision tasks from visualization taxonomies is not a strategic or intentional act, especially given the confusion and lack of clarity with terminology. We think that instead it might be associated with the lack of fundamental knowledge of decision theories within the visualization literature and community.

SECTION 5Does Visualization Assist Decision Tasks?
In prior work with professional decision makers who work in large organizations [47], we found that while the decision makers might use some visualizations within the preliminary steps of the INTELLIGENcE stage (discussed in Section 3) or when they want to present results to others, they do not typically use visualizations as an aid within their actual decision making process (stages DESIGN and CHOICE).

One decision maker explained this as “Visualization is just one little part of the job. How to model the decision process supporting the flow with sufficient flexibility is more important. […] It's inconvenient to distinguish between the tool itself and how I do the decision process. I can explore the data, the patterns, which are also important and useful, but that part is more in collecting evidence for my later decision making. But in the existing tools, either you have to program it or you have to do a lot to transform the data. […] For visualization, I still use those tools, but for decision making I draw flow charts. […] Computers don't give you much advantage over pen and paper […] It's not about sitting in front of the computer, but have the notebook with me, maybe when I am eating lunch and I think or talk to people for something. It is about the convenience” [47]. Although this could simply be a matter of personal preference for this individual, it suggests that visualizations might not be designed to aid such decision making tasks.

This section examines whether, in practice, visualization systems intended to assist decision making activities are actually evaluated based on their ability to improve decision tasks. As derived by our methodology (Section 2.1), we found 85 design papers (shown in Table 1) that mention decision making as an objective. More specifically, all these papers report in their abstract that decision making is one of the (or the only) key motivation for the creation of the technique or system. The table illustrates both the quantity and diversity of applications/use cases/domains needing decision making assistance. Note, however, that these papers provide a superset; a pool of papers about techniques or systems that are probably the closest to contributing to decision making. It is reasonable to infer that all those papers do not explicitly test decision tasks. Some of them do not have decision making as the only target goal of the visualization.

Only a few (6% or 5/85 papers) of these design papers [3], [22], [64], [132], [152] mentioning decision making performed a quantitative evaluation involving decision tasks. However, in multiple of the cases, the evaluation was more focused on a particular aspect of decision making, such as fairness/anti-bias [3], prediction under uncertainty [64], or speed of decision [22]. The papers with quantitative evaluations also typically focused not on general multivariate decision making, but on decisions in a specific domain context such as network security [152] or image analysis [22]. Perhaps the most rigorous quantitative analysis was done on a visual analytics system for financial planning [132]. The research team found that their FinVis application helped their study participants make better financial portfolio decisions as compared to subjects using a tabular version with the same information.

In the papers from this set involving some form of qualitative evaluation (categories #2 and #4 in Table 1), a larger group overall, the researchers still did not seem to ask participants to attempt to make a decision with the tool. Just 4% or 3/85 papers [11], [66], [173] involved a decision task. Two of these again focused on a specific domain, software release planning [11] and prostate cancer treatment [66], while one involved more general ranking and multi-criteria decision making [173]. Also, note that the papers discussed in the prior paragraph above about quantitative evaluations using decision tasks also typically gathered qualitative feedback as well.

Perhaps surprisingly, the LineUp system [63], which many might associate most closely with the CHOICE stage of decision making via visualization, does not even appear in Table 1 because decision making is not mentioned in its title or abstract. The paper includes a qualitative evaluation, but it is not focused on decision making. A similar subsequent system, Weightlifter [118], appears in the Table, but its paper only included a general qualitative evaluation of its design.

Looking at all of these design papers mentioning decision making as a goal, one finds a notable scarcity of actual user studies assessing that objective. Our review showed that even for those researchers who wanted test decision tasks, decision making was difficult to assess. Furthermore, the visualization literature does not provide guidance and support on how to do it, while taxonomies do not encourage it.

Table 1: 85 visualization design (technique or system) papers mentioning decision making in their title or abstract.

Admittedly, many of these visualizations help with a level of data understanding of certain stages of decision making (e.g., the INTELLIGENCE stage) assessing only that. Yet it is notable that in this pool, so few papers focus on decision making explicitly. One can wonder whether the lack of decision tasks in visualization taxonomies (discussed in 4) might make researchers overlook decision tasks.

SECTION 6Developing a Research Agenda
Historically, the notion of visual analytics emerged in the early 2000's, when the field was described as the union of three key components: interactive visualization, computational analysis, and analytical reasoning [37]. The interactive visualization component has always been a fundamental aspect of the discipline either out of necessity to handle increasing amounts of data, or as a way to allow human-driven and iterative data exploration in which the analyst is in control of the information space [46]. The other two components, however, were viewed as areas for growth, where researchers from other communities could migrate towards visual analytics and add to this growing field.

The computational analysis component of the discipline has been a great success as researchers and ideas from neighboring fields such as statistics, data mining, machine learning, and big data have flocked to visual analytics and made fundamental contributions over the past 15 years. Visual analytics systems are now addressing larger and more complex data sets and they are providing sophisticated new platforms for analysts to better understand these data sets.

We believe it is safe to say that the analytical reasoning component of visualization research has not achieved the same level of focus or success, however. It is much less common to encounter papers with a strong emphasis on support for analytical reasoning and that apply approaches from disciplines such as the cognitive and decision sciences. We view this shortcoming of achieving the true visual analytics vision as a key research goal for the future with respect to decision making and visualization. In fact, Keim et al's [84] early definition of visual analytics included decision making at its core: “Visual analytics combines automated analysis techniques with interactive visualizations for an effective understanding, reasoning and decision making on the basis of very large and complex data sets”. Fostering new and innovative research for both assisting decision making activities in visualization systems and evaluating that objective remains as a fundamental objective for our community to achieve.

To help realize the visual analytics vision, our analysis of the current state of decision making as a component of the visualization research agenda leads us to believe that this is an area ripe for further work. Below we list directions or natural next steps that follow from our analysis. Each provides an opportunity for visualization researchers to make important contributions and explore how visualization can better assist decision making.

6.1 Leverage Other Domains & Expand
It is important that visualization researchers become more aware of and learn from research done on decision making in other disciplines [74]. Academic areas such as economics, behavioral science, management, naturalistic decision making, operations research, psychology, and cognitive science, among others, all have deep and rich histories of studying decision making both among individuals and organizations.

Invite Researchers from Decision Making Domains
One challenge in using techniques from decision making domains is that they tend to use a set of terminology and jargon that makes it difficult for visualization researchers to approach that work [1]. We consider it vital to encourage contributions from researchers in other domains who can help us adapt and transpose this knowledge to fit visualization applications better. This can be achieved through cross-domain collaborations or by embracing initiatives like the IEEE VIS 2020 Workshop on Visualization Psychology2, and even expanding them with economists, management researchers and decision theorists.

Provide Evaluation Methodologies
Decision making disciplines can also help visualization research to develop more sophisticated evaluation methods to determine how well a visualization provides that support [44], [49]. If the developers of a new system opt to make this claim, then they need the tools to validate that it does. Research in uncertainty visualization currently paves this path [74], [117], and we hope that many other visualization areas will follow in developing better methods to evaluate the effectiveness of visualization systems for aiding decision making. Currently, we lack effective methods and approaches for assessing that capability especially for tasks that go beyond the CHOICE stage combining choices with the DESIGN and the INTELLIGENCE decision making stages.

However, while the partnership with decision making disciplines will help visualization research to refrain from “re-inventing the wheel”, none of those domains studies decisions in the context of large data and technology artifacts. The tasks under study typically involve very small datasets or are even not related to data and technology, which partly explains why most visualization papers focus on binary or decision tasks of narrow complexity. Thus the appropriation of those methods to serve the true visualization challenges and needs is necessary. For example, the cognitive bias research often faces the limitation that the biases studied in psychology are observed within two or three decision alternatives, so visualization researchers need to propose procedures for extending those observations to larger datasets as well as to verify that the observed phenomena replicate in the data analysis context [43]. Identifying how to balance this equilibrium at a point at which satisfactory internal and external validity accompany applicability for visualization adds another level of complexity to the design of evaluation methodologies that verify decision quality.

6.2 Clarify Tasks & Calibrate Claims
The developed frameworks and taxonomies for visualization tasks largely omit decision making as a fundamental activity that visualization can aid. Researchers must explore further whether decision making should occupy a position in such taxonomies alongside tasks such as exploratory analysis, sensemaking, and discovery. We see opportunities to further develop visualization-focused task taxonomies, particularly for high-level tasks and objectives. Generating a better understanding of the relationships, overlaps, and differences between such high-level goals can help our community better explain the value of visualization and how it can be applied to many different real world scenarios. Decision making, sensemaking, exploration, problem solving, insight extraction and several other high-level tasks share many similarities, and visualization researchers are often not clear about distinguishing them. As a result, such terms are often used interchangeably [141]. We advocate for the importance of making a formal distinction among those high-level tasks in the context of visualization to bring more clarity to the visual analytics landscape [141]. We will attempt a bolder suggestion here: visualization, as a multidisciplinary yet independent scientific field, can also propose its own definitions and boundaries of relevant tasks without being intimidated by the fuzziness that accompany those terms in other domains.

As we observed, many visualization papers currently make ambiguous claims in their introduction that their work aids decision making. If visualization taxonomies provide a more clear terminology on describing those tasks, that will also help visualization design papers to be more succinct in their claims, tool descriptions and evaluations.

Moreover, while in this work we discuss decision making as a single user task, in reality, decision making constitutes a class of various decision making tasks, from which some might be more or less relevant to data analysis. Thus the design space of those decision tasks needs to be thoroughly investigated in the context of data analysis.

6.3 Equip Visualization Designers with Decision Making Guidelines
Visualization literature has contributed a vast number of frameworks and guidelines based on how humans see data. Visualization empirical research offers several design guidelines. For example, visual channels have been ranked by effectiveness according to channel and data type; color palettes have been investigated based on discriminability or aesthetic preferences; and various visualization designs have been compared for their ability to represent probabilities and risk. Yet, our literature analysis showed that in comparison to the large body of work that builds on vision science and statistics, we know very little about how to design for humans who make decisions with visualized data after veridically perceiving them [116].

To provide such guidelines, we consider two critical pre-conditions. First, visualization research needs to increase the user studies that contain decision making tasks [81]. Second, visualization research needs to broaden the profiles of target users. Most visualization field works focus on data analysts; people whose primary job function is to answer questions with data, not to make decisions with data [47]. Empirical findings suggest that decision making can rely on different heuristics (e.g., loss aversion) which are not always related to analytic accuracy [81]. Preliminary research with organizational decision makers indicates several improvements that decision makers would like to see in visualization systems, such as trade-off analysis, scenario-based and question-oriented data interfaces, or to enrich interactivity with flexible data inputs, collaboration features, and in situ visualizations [47]. We further need to explore the data visualization needs of everyday decision makers. We suggest that the profile of the decision maker needs to be investigated, both in professional and casual contexts.

SECTION 7Conclusion & Future
Visualization research collectively advocates that decision making is, or should be, a core goal of visualization. We revisited visualization history, theory and practice to find that, in fact, visualization largely lacks explicit ties to decision making. Visualization task taxonomies typically omit decision tasks. Visualization theory fails to provide guidance on how to study human decisions in the context of data analysis and visualization. Finally, visualization designs lack evaluation of their capability to improve decision activities and neglect to consult decision makers as their target users. To help address these shortcomings, we propose a research agenda on how we, as a community, can incorporate the formal study of decision making as a fundamental use case for future visualization systems to effectively support and assist.

Building such visualizations for decision makers entails that more data will become accessible to everyday citizens and persons of authority. Decision making plays a vital role in society, one in which all our information, beliefs and elaborate analyses come into action. Visualization can contribute to both ends of influence on those actions; it can equip citizen decision makers with personal visual analytic tools contributing to data democratization movements, and it can equip organizations with visual systems that promote transparency, fairness via bias mitigation, and mixed-initiative decision workflows. The resulting interfaces, while being able to exploit the advantages of intelligent technologies, will also be able to shift control to the human decision maker.