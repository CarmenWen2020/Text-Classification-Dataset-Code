Transferable deep representations for visual domain adaptation (DA) provides a route to learn from labeled source images to recognize target images without the aid of target-domain supervision. Relevant researches increasingly arouse a great amount of interest due to its potential industrial prospect for non-laborious annotation and remarkable generalization. However, DA presumes source images are identically sampled from a single source while Multi-Source DA (MSDA) is ubiquitous in the real-world. In MSDA, the domain shifts exist not only between source and target domains but also among the sources; especially, the multi-source and target domains may disagree on their semantics (e.g., category shifts). This issue challenges the existing solutions for MSDAs. In this paper, we propose Deep CockTail Network (DCTN), a universal and flexibly-deployed framework to address the problems. DCTN uses a multi-way adversarial learning pipeline to minimize the domain discrepancy between the target and each of the multiple in order to learn domain-invariant features. The derived source-specific perplexity scores measure how similar each target feature appears as a feature from one of source domains. The multi-source category classifiers are integrated with the perplexity scores to categorize target images. We accordingly derive a theoretical analysis towards DCTN, including the interpretation why DCTN can be successful without precisely crafting the source-specific hyper-parameters, and target expected loss upper bounds in terms of domain and category shifts. In our experiments, DCTNs have been evaluated on four benchmarks, whose empirical studies involve vanilla and three challenging category-shift transfer problems in MSDA, i.e., source-shift, target-shift and source-target-shift scenarios. The results thoroughly reveal that DCTN significantly boosts classification accuracies in MSDA and performs extraordinarily to resist negative transfers across different MSDA scenarios.

Access provided by University of Auckland Library

Introduction
Considerable advances in deep representation learning have recently improved the state-of-the-art approaches on a huge variety of machine vision problems (Krizhevsky et al. 2012; Ren et al. 2015; Long et al. 2015; Liang et al. 2016; Xu et al. 2015; Johnson et al. 2017; Ho and Gopalan 2014; Kan et al. 2014; Zhang et al. 2019). These eyeball-catching prospects can be greatly attributed to the availability of large scale labeled datasets for supervised learning (Deng et al. 2009; Cordts et al. 2015). Nevertheless, these successes are challenged by domain shift problem (Pan and Yang 2010), since the traditional assumptions that their training dataset and test set follow the same distributions are often violated. This poses a major obstacle in adapting predictive models across domains and leads to a performance degradation on target domains (Gretton et al. 2009).

To mitigate the negative effects caused by domain shift, (unsupervised) Domain Adaptation (DA) (Pan and Yang 2010) arises to reduce the discrepancy between the source and target domain distributions, typically by exploring domain-invariant data structures or transferable representations, which endows the classifier with the consistent classification ability on source and target examples (Tzeng et al. 2015; Bousmalis et al. 2017; Gebru et al. 2017). Most existing DA approaches are preconditioned on a single source where labeled examples are identically drawn from an individual source underlying distribution. This setup is widely admitted in traditional DA researches, while merely reflects a tip of the iceberg of realistic transfer circumstances.

In a variety of real-world cases, we often witness data drawn from multiple source domains. For instance, for the sake of illness typicality, medical images are conventionally collected from hospitals all over the country in a long time. This application circumstances produce a large amount of datasets that should be treated as a set of multiple sources. Consequently, Multi-Source Domain Adaptation (MSDA) has increasingly grabbed considerable attention in many applications (Yang et al. 2007; Duan et al. 2012; Jhuo et al. 2013a), since reasonable approaches might achieve more transfer learning performance gains.

Compared with the deep single-source DA with witnessed progresses, scarce researches have been committed to deep MSDA due to complex domain shift conditions. Especially, domain shift exists not only between a target and each source, but also across multiple source domains. MSDA presents in an extensive variety of scenarios arousing serious negative transfer influences (Pan and Yang 2010) due to the category shifts across domains. For instance, the categories distributed across multiple source domains may not guarantee their class consistencies (Fig. 1b). In this source-category-shift MSDA scenario, the shifts of multi-source domains and their categories should be taken into account. Another case is derived from the popular single-source open-set DA research (Busto and Gall 2017), where some part of categories in a target domain are not included in source domains. These â€œoutlierâ€ categories are traditionally unified as a negative class called â€œunknownâ€ (Fig. 1c). In our paper, this MSDA-extended open-set setting is termed target-category-shift MSDA scenario. More generally, these two cases would simultaneously occur and leads to source-target-category-shift MSDA scenarios (Fig. 1d). All these category-shift cases deteriorate the domain-shift damages to most existing DA algorithms and are nontrivial to solve.

Attempting to overcome the domain-shift and category-shift challenges, in this paper, we present Deep CockTail Network (DCTN), a flexibly-deployed adversarial learning framework to address MSDA problems across diverse transfer scenarios. DCTN encapsulates category classifiers for multi-source domains respectively, then the target category predictor is formulated by integrating their category probabilistic predictions on a target example with their source-target perplexity scores. In particular, each of the perplexity scores represents the domain-feature similarity between the target and each source, thus, referring to the outcome each source-target domain discriminator produces (source-target domain discriminators are deployed to separate features from the target and each source. Like other adversarial DA approaches, domain discriminators of DCTN facilitates to learn a domain-invariant feature extractor in a multi-source-domain condition). The more similarity between a source and the target on their features, the more convincing this source-specific classifier predicts the target example. Hence each target feature would be fed into multi-source classifiers, whose predictions are reweighted by the source-specific perplexity scores to classify this target example. Analogous to make cocktail, it inspires our framework dubbed by Deep CockTail Network.

Fig. 1
figure 1
A brief illustration of Multi-Source (unsupervised) Domain Adaptation (MSDA) scenarios and their hierarchical relation. a Vanilla MSDA scenarios consider multi-source and target examples that exactly share their categories. b Multi-source data are collected from source domains where domain shift and categorical misalignment co-exist between the source domains. c Multiple sources meet an open-set target domain (Saito et al. 2018) including some â€œunknownâ€ categories non-existent in the sources. d Source and target category shifts (b, c) simultaneously occur in this scenario. Note that, b is derived from our original version (Xu et al. 2018); c, d are first taken into account in this paper. MSDA problems in these scenarios can be settled by our DCTN. (For simplicity, we only reveal the cases with two source domains. Best viewed in color.)

Full size image
Theoretically, we compare DCTN with the methods based on source distribution weighted combining rule (Mancini et al. 2009), where the target distribution is supposed to be represented as the weighted linear combination of multiple source distributions. This old-school MSDA theory provides an adaptation upper bound of expected classification error on the target domain. However, the multi-source weight combination involves with crafting a set of source-specific hyper-parameters by experiences; thus, it could not keep abreast of the current advancing approaches. DCTN does not rely on this mixture assumption. In contrast, the learning algorithm of DCTN employs a multi-way adversarial scheme to adaptively decide the multi-source balancing rule according to their source-target perplexity scores. The DCTN target category prediction maintains an expected loss upper bound underlying a reasonable DA approximation presumption, yet free of specifying multi-source hyper-parameters. More importantly, it can be developed to suit the cases of source and target category shifts in MSDA.

Overall, our work mainly contributes in three aspects:

We investigate four representative MSDA scenarios, i.e., vanilla, source-category-shift, target-category-shift and source-target-category-shift, and propose Deep CockTail Network (DCTN), to solve these challenging and complex MSDA problems by a universal framework.

Under two assumptions derived from our learning algorithm, we develop the bound of the target instance loss in DCTN. It explains why DCTN can success without relying on the source-distribution-weighted-combing rule. Based on this, we develop the upper bounds of target expected loss across all aforementioned MSDA scenarios.

We conduct extensive experiments on four MSDA benchmarks including diverse source-to-target transfer cases in four different category shift scenarios. Our experimental results demonstrate the superiority and versatility of DCTN.

The remainder of this paper can be concluded as follows. Related works are described in Sect. 2. Details of problem setup on diverse MSDA problems are in Sect. 3 and our method is presented in Sect. 4. Experimental results are given in Sect. 5. We conclude this paper in Sect. 6.

Related Work
Domain Adaptation with a Single Source
Provided a source domain with ground truth and target domain without labels, unsupervised domain adaptation (Pan and Yang 2010; Gong et al. 2014; Shao et al. 2014; Xu et al. 2016) aims to learn a model well-performed on a target domain. Since the source and target belong to different distributions, the technical problem in UDA is how to mitigate the domain shift between them. Inspired by the two-sample test (Gretton et al. 2007), various statistical discrepancy measures can be directly applied to regulate the domain shift during optimization, e.g., shallow-model-based TCA (Pan et al. 2011), JDA (Baktashmotlagh et al. 2016), deep-model-based DAN (Long et al. 2015), CMD (Zellinger et al. 2017), WMMD (Yan et al. 2017), RTN (Long et al. 2016), STN (Yao et al. 2019), in which diverse statistical measures are used as the regularizer to learn domain-invariant features.

Adversarial learning behaves effectively to learn more transferable representations (Ganin et al. 2017; Tzeng et al. 2017). It determines a couple of networks and trains them in the opposite direction: a domain discriminator minimizes the classification error to distinguish samples from source and target, while domain mapping learns transferable representations by confusing the domain discriminator. These so-called adversarial DA algorithms are classed into three branches. The first alternatively trains discriminator and feature extractor so that the extractor is encouraged to directly confuse the source and target. Namely, the probabilistic discriminative decisions about learned transferable representations should be consistent with [12,12], no matter which domain the examples come from. The second proposes a reversal gradient layer, which flips the gradient values after its back-propagated from the discriminator. The operation allows a joint learning of discriminator and feature extractor and is easy for implementation, which makes it very popular in the adversarial domain adaptation. Finally, GAN-style adversary (Goodfellow et al. 2014) also suits a domain adaptation setting (Tzeng et al. 2017), which mostly performs as an asymmetric transfer pipeline. Due to the flexibility of adversarial learning framework, recent researches about adversarial DA perform superiorly in visual recognition across domains (Long et al. 2016; Gebru et al. 2017) and tasks (Motiian et al. 2017) and transfer structure learning (Bousmalis et al. 2017; Hoffman et al. 2016).

Besides these mainstream branches of DA approaches, there are also other diverse methods to learn domain-invariant features: semi-supervised method (Saito et al. 2017), domain reconstruction (Ghifary et al. 2016), duality (Haeusser et al. 2017), alignments (Fernando et al. 2013; Zhang et al. 2017; Sun et al. 2016), manifold learning (Gong et al. 2012), tensor methods (Koniusz et al. 2017; Lu et al. 2017), feature norm adaptation (Xu et al. 2019), etc.

Multi-source Domain Adaptation
The UDA approaches mentioned above mainly consider target domain versus single source domain. If multiple sources are available, the domain shifts among sources should also be considered. A-SVM (Yang et al. 2007) leverages the ensemble of source-specific classifiers to fine-tune the target categorization model; The Domain Adaptation Machine (Duan et al. 2012) introduces domain-dependent regularizer term based on a smoothness assumption, and enforces target classifier to make a similar decision to the relevant source classifier. Domain reconstruction method (Jhuo et al. 2013a) enforces different source domains to have jointly low ranks, which forms a compact source set close to the target domain.

MSDA also develops with some theoretical supports (Mancini et al. 2009; Blitzer et al. 2008; Ben-David et al. 2010). Blitzer et al. (2008) firstly provide the learning bound for MSDA. Mancini et al. (2009) claims that an ideal target hypothesis can be represented by a distribution weighted combination of source hypotheses. This methodology is so-called source distribution weighted combining rule, closely meaning that if the relations between target and each source can be discovered, we are able to use multiple source-specific classifiers to obtain an ideal target class prediction.

Very recently, some approaches based on neural nets attempt to address the MSDA problem. Zhao et al. (2018) developed a new adversarial learning paradigm by iteratively constructing zero-sum games between the target and one of the source domains. Mancini et al. (2018) proposes a multi-DA normalization layer that aligns multi-source domains in the target. They indeed have facilitated the progresses in MSDA whereas presented several limitations. Inspired by Xu et al. (2018) and Peng et al. (2019) develops a discrepancy-based DA algorithm to reweight the importances of multiple domains. They have performed promising results in a vanilla MSDA problem but if category shifts simultaneously exist across domains, which commonly appears in practice, they become unavailable.

Category-Shift Problems in Domain Adaptation
Most existing DA literatures consider DA problems in a close-set DA setup, where source domain and target domain exactly share their categories. This transfer precondition simplifies the analysis of most DA algorithms, but is unable to handle the situation where source and target categories are different. Increasingly, a variety of researches in turn focus on addressing these more challenging problems. For examples, Kim et al. (2020) suggests a new DA paradigm to address potential data-leakage issues. Cao et al. (2018) and Cao et al. (2018) investigate the partial DA problem where target categories presents as a proper subset of the source categories. Distinctly, Saito et al. (2018) and Busto and Gall (2017) investigate the open-set DA problem where some of target categories are unknown in the source domainFootnote1. (You et al. 2019) investigates universal domain adaptation (UDA), i.e., the DA problem concluding the aforementioned two scenarios. These existing category-shift transfer scenarios, however, rely on a â€œsingle-source-domainâ€ setting. In contrast, diverse category shifts usually appear in practical MSDA problems, which is the focus of this paper.

Overview of MSDA
In unsupervised domain adaptation, images from target domain lack of annotation, hampers a straightforward usage of supervised learning to acquire a classifier adaptive to target distribution. Source domain offers categories information via a circuitous route. Nevertheless, category-shift problem is aggravated in MSDA compared with single source domain adaptation. In this paper, we explore category-shift problem for MSDA and summarize four representative adaptation scenarios, i.e., vanilla, source-category-shift, target-category-shift and source-target-category-shift MSDAs. In the following section, we will elaborate these four adaptation scenarios in a principle way.

In the context of multi-source domain adaptation, source domain images {(ğ—ğ‘—,ğ˜ğ‘—)}ğ‘€ğ‘—=1 are drawn from M different source domains with underlying distributions {ğ‘ƒğ‘—(ğ‘¥ğ‘¥,ğ‘¦ğ‘¦)}ğ‘€ğ‘—=1, respectively. ğ—ğ‘—={ğ‘¥ğ‘¥ğ‘—ğ‘–}ğ‘ğ‘—ğ‘–=1 represents ğ‘ğ‘— images from source j in total and ğ˜ğ‘—={ğ‘¦ğ‘¦ğ‘—ğ‘–}ğ‘ğ‘—ğ‘–=1 corresponds to their labels. Target domain images ğ—(ğ‘¡)={ğ‘¥ğ‘¥(ğ‘¡)ğ‘–}ğ‘(ğ‘¡)ğ‘–=1 are drawn from underlying distribution ğ‘ƒğ‘¡(ğ‘¥ğ‘¥,ğ‘¦ğ‘¦) without label observation ğ˜(ğ‘¡). For MSDA, images from source and target domains are utilized for training; test images (ğ—ğ‘¡ğ‘’ğ‘ ğ‘¡,ğ˜ğ‘¡ğ‘’ğ‘ ğ‘¡) are only drawn from the target to evaluate the classifier adaptation performance.

Vanilla MSDA
ğ’ğ‘— denotes a category set of labels in ğ˜ğ‘— for source domain j, ğ’(ğ‘ ) denotes the category set of the source domain, and ğ’(ğ‘¡) is the unobserved category set of our target domain. In vanilla MSDA scenario, the category sets of multiple sources ({ğ’ğ‘˜}ğ‘€ğ‘˜=1) and the target (ğ’(ğ‘¡)) are consistent, namely, ğ’(ğ‘ )=ğ’ğ‘˜ (âˆ€ğ‘˜âˆˆ[ğ‘€]={1,2,â€¦,ğ‘€}) and ğ’(ğ‘¡) holds ğ’(ğ‘ )=ğ’ğ‘˜=ğ’(ğ‘¡). This scenario presumes M source and target domains customized by consistent category semantics.

Category-Shift Scenarios in MSDA
In a vanilla scenario, images darwn from different domains share the same category set. Distinguished from this, category-shift MSDA scenario advocates that the category sets from different domains maybe also different. To this end, ğ’(ğ‘ )=ğ’ğ‘˜=ğ’(ğ‘¡) (âˆ€ ğ‘˜âˆˆ [M] ) is generalized to suit different scenarios.

Specifically, in the source-category-shift scenario, ğ’(ğ‘ )=ğ’ğ‘˜=ğ’(ğ‘¡) (âˆ€ ğ‘˜âˆˆ [M] ) turns to ğ’ğ‘—â‰ ğ’ğ‘˜ and ğ’(ğ‘¡)=â‹ƒğ‘€ğ‘—=1ğ’ğ‘—. ğ’ğ‘—âˆ©ğ’ğ‘˜ indicates the public classes between sources j and k. ğ’ğ‘—âˆ©ğ’ğ‘˜â‰ ğ’ğ‘—âˆªğ’ğ‘˜ refers to the source category shift. In the target-category-shift scenarios, ğ’(ğ‘ )=â‹ƒğ‘€ğ‘—=1ğ’ğ‘—=ğ’(ğ‘¡) becomes ğ’(ğ‘ )=â‹ƒğ‘€ğ‘—=1ğ’ğ‘—â‰ ğ’(ğ‘¡). Resumbling the spirit of the recent open-set single-source DA researches (Busto and Gall 2017; Saito et al. 2018), we consider a target-category-shift MSDA scenarios holding ğ’(ğ‘ )=â‹ƒğ‘€ğ‘—=1ğ’ğ‘—âŠ‚ğ’(ğ‘¡). The categories in ğ’(ğ‘¡)/â‹ƒğ‘€ğ‘—=1ğ’ğ‘— are conventionally unified and treated as an â€œunknownâ€ category ğ‘ğ‘¢. The MSDA is supposed to preclude the target examples belonging to ğ‘ğ‘¢=ğ’(ğ‘¡)/â‹ƒğ‘€ğ‘—=1ğ’ğ‘— and correctly categorize the rest into {ğ’ğ‘—}ğ‘€ğ‘—=1.

Finally, in source-target-category-shift scenario, the aforementioned category shifts simultaneously occur. This encourages us to address the both challenges by a unified framework.

Deep CockTail Networks (DCTNs)
Irrespective of either vanilla or the other multi-source transfer scenarios, MSDAs remain challenging to tackle and moreover, few researches are investigated under deep DA background. In this section, we introduce Deep CockTail Network (DCTN), an adversarial domain adaptation framework specified for MSDA. The framework is tailor-designed to address a vanilla MSDA problem yet ought to be noted that, DCTN could also be flexibly deployed to adapt the target domains in the source-category-shift, target-category-shift and source-target-shift-open-set scenarios by a mildly reconfiguring the learning pipeline.

In Sect. 4.1, we elaborate the basic pipeline of DCTN and the principle how DCTN predicts target data categories in diverse scenarios. In Sect. 4.2, we present the alternating learning algorithm of DCTN. In Sect. 4.3, we unveil the theoretical insight behind DCTN.

Framework
DCTN consists of four components: three subnets, i.e., feature extractor, (multi-source) domain discriminator, (multi-source) category classifier, and an unlearnable cocktail target category predictor to classify target examples (Fig. 2).

Feature extractor F incorporates a deep convolution neural network as the backbone, and maps images from M sources and the target into a common feature space. Apart from weight-shared architecture for all the domains, the joint adversarial learning with subsequent domain discriminators contributes F to learning both target-source-specific relations and domain-invariant features.

Fig. 2
figure 2
The overview of Deep CockTail Network (DCTN). Our framework receives multi-source instances with annotated ground truth and adapts to classify the target samples. We confine the problem with only source j and k for simplicity. (i) The feature extractor maps target, source j and k into a common feature space. (ii) The category classifier receives target feature and produces the jth and kth classifications based upon the categories in source j and k respectively. (iii) The domain discriminator receives features from source j, k and target, then offers the kth advesary between target and source k, as well as the jth advesary between target and source j. The jth and kth advesary provide the source-j,k perplexity scores to reweight the jth and kth classifications correspondingly. (iv) The cocktail target category predictor integrates all reweighted classification results, so as to predict the target examplesâ€™ categories across diverse category-shift scenarios. Since the samples from multi-source domains merely produce the training losses, their flows (outputs) are omitted to mainly illustrate the whole process of identifying target samples for simplicity. (Best viewed in color.)

Full size image
(Multi-source) domain discriminator D is built upon M source-specific discriminators {ğ·ğ‘—}ğ‘€ğ‘—=1 for adversary. Given an image ğ‘¥ğ‘¥, the domain discriminator D receives the feature ğ¹(ğ‘¥ğ‘¥), and then each source-specific discriminator ğ·ğ‘— (âˆ€ğ‘—âˆˆ[ğ‘€]) classifies respectively whether x originates from the source j or the target. The data flow coming from each source does not trigger those discriminators belonging to other source domains, while for the data flow from each target instance ğ‘¥ğ‘¥(ğ‘¡), the domain discriminator D yields M source-specific discriminative outcomes {ğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))}ğ‘€ğ‘—=1 between the target and the M sources, respectively. They are leveraged to update the discriminator D, and provide the target-source perplexity scores {ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)}ğ‘€ğ‘—=1 defined as

ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)=âˆ’log(1âˆ’ğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))).
(1)
ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—) implies how similar ğ‘¥ğ‘¥(ğ‘¡) is as a sample drawn from source j.

(Multi-source) category classifier C is a multi-output net composed of M source-specific category classifiers {ğ¶ğ‘—}ğ‘€ğ‘—=1. Each classifier is a softmax classifier configured by the category set that corresponds to its source. The category classifier takes an image mapping from feature extractor as input. For each image from source j, only the gradient derived from ğ¶ğ‘— is activated for the parameter updating. For a target image ğ‘¥ğ‘¥(ğ‘¡) instead, all source-specific classifiers provide M categorization results {ğ¶ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))}ğ‘€ğ‘—=1, contributing to the parameters updating of C.

Cocktail target category predictor is the key component to categorize target examples. Specifically, given a target sample ğ‘¥ğ‘¥(ğ‘¡), our cocktail target category predictor takes its source perplexity scores {ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)}ğ‘€ğ‘—=1 to re-weight {ğ¶ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))}ğ‘€ğ‘—=1, and then integrates them for classification. Here we specify the classification principle in four MSDA scenarios:

1.
In a vanilla MSDA scenario, the category sets of a target domain and M source domains are consistent. Hence target category predictor is formulated by re-weighting source-specific classifier prediction with target-source perplexity scores:

ğ¶ğ‘¡(ğ‘¥ğ‘¥(ğ‘¡)):=âˆ‘ğ‘—=1ğ‘€ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)âˆ‘ğ‘€ğ‘˜=1ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜) ğ¶ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡))),
(2)
where ğ¶ğ‘¡(ğ‘¥ğ‘¥(ğ‘¡)) denotes category probability forecast by the target predictor, and each entry of ğ¶ğ‘¡(ğ‘¥ğ‘¥(ğ‘¡)) denotes the integrated probability of ğ‘¥ğ‘¥(ğ‘¡) belonging to a specific category.

2.
In category-shift MSDA scenarios, categories across M source and a target domains are not always shared. Therefore, we modify Eq. 2 to suit all cases. Specifically, each source classifier is obligated to classify those categories in its corresponding source. DCTN is expected to identify â€œunknownâ€ ğ‘ğ‘¢ excluded by categories of M-source domains. To this, we activate all the source classifiers to identify the target examples in ğ‘ğ‘¢. So Eq. 2 turns to

ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡)):=âˆ‘ğ’(ğ‘¡)ğ‘—ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)âˆ‘ğ’(ğ‘¡)ğ‘˜ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜)ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡))),
(3)
where ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))    represents the softmax prediction of the ğ‘—ğ‘¡â„ source classifier ğ¶ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡))), i.e., the probability that ğ‘¥ğ‘¥(ğ‘¡) belongs to c. ğ’(ğ‘¡)ğ‘— derived from ğ’(ğ‘¡) in Eq. 2 further includes the categories that M sources do not contain, e.g., ğ’(ğ‘¡)ğ‘—=ğ’ğ‘—âˆª{ğ‘ğ‘¢}. So ğ¶ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡))) turns into a (|ğ’ğ‘—|+1)-slot softmax category predictor, in order to synchronically recognize the categories in ğ’ğ‘— and the â€œunknownâ€ ğ‘ğ‘¢. Note that only the sources including c would join the perplexity re-weighting to classify c.

Learning
DCTN follows an alternative adaptation pipeline given a pre-trained feature extractor and category classifier. At the very beginning of learning, we adopt source images to train the feature extractor F and the category classifier C. Those networks and the cocktail target classifier then predict categories for all target imagesFootnote2 and annotate those with high confidences. Thus, we obtain the pre-trained feature extractor and category classifiers via fine-tuning with labeled multi-source images and pseudo-labeled target images. With pre-training, DCTN employs a multi-way adversary scheme to learn a mapping shared by all domains; then the feature extractor and the category classifiers are jointly trained with multi-source labeled and target pseudo-labeled images. These two stages repeat until the maximal epoch is reached.

Multi-way Adversarial Adaptation
Multi-way adversarial adaptation in DCTN is proposed to obtain domain-invariant features. It is formulated as follows:

minğ¹ maxğ· ğ‘‰(ğ¹,ğ·;ğ¶)=â„’ğ‘ğ‘‘ğ‘£(ğ¹,ğ·)+â„’ğ‘ğ‘™ğ‘ (ğ¹,ğ¶),
(4)
where the first term denotes our multi-way adversarial loss and the second term indicates cross-entropy losses for source-specific classification; C are frozen to offer stable values in the gradients. This multi-way adversarial loss are defined as

â„’ğ‘ğ‘‘ğ‘£(ğ¹,ğ·)=1ğ‘€âˆ‘ğ‘—ğ‘€[ğ”¼ğ‘¥ğ‘¥âˆ¼ğ—ğ‘—[logğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥))]+ğ”¼ğ‘¥ğ‘¥(ğ‘¡)âˆ¼ğ—ğ‘¡[log(1âˆ’ğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡))))]].
(5)
The optimization based on Eq. 5 is solely used to train D. Since the feature extractor F learns the mapping with respect to the multiple source domains and the target domain, the domain distributions simultaneously changes in adversary, which results in an oscillation that spoils our feature extractor. Regarding such concern, when source and target feature mappings share their architectures, the domain confusion can be introduced to substitute the adversarial objective (Tzeng et al. 2017), which performs stably to learn F. Inspired by this, we have obtained the multi-domain confusion loss:

â„’ğ‘ğ‘‘ğ‘£(ğ¹,ğ·)=1ğ‘€âˆ‘ğ‘—ğ‘€[ğ”¼ğ‘¥ğ‘¥âˆ¼ğ—ğ‘—â„’ğ‘ğ‘“(ğ‘¥ğ‘¥;ğ¹,ğ·ğ‘—)+ğ”¼ğ‘¥ğ‘¥(ğ‘¡)âˆ¼ğ—ğ‘¡â„’ğ‘ğ‘“(ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)],
(6)
where

â„’ğ‘ğ‘“(ğ‘¥ğ‘¥;ğ¹,ğ·ğ‘—)=12logğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥))+12log(1âˆ’ğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥))).
(7)
Thus, DCTN updates its feature extractor F by optimizing the objective Eq. 4 w.r.t. Eq. 6.

Online hard source-domain batch mining When sampling mini-batches, the multi-way adversarial adaptation stochastically receives m examples from M sources respectively to update the feature extractor F in each iteration. However, the images drawn from different source domains would be not always helpful for boosting the adaptation, and as the model training proceeds, redundant source images would turn to draw back the previous adaptation performance. Thus we design a simple yet effective hard domain batch mining technique to improve the training efficiency. Specifically, in each iteration, DCTN randomly draws m target examples {ğ‘¥ğ‘¥(ğ‘¡)ğ‘–}ğ‘šğ‘–=1 and m source examples for each source, i.e., {{ğ‘¥ğ‘¥1,ğ‘–}ğ‘šğ‘–=1,â‹¯,{ğ‘¥ğ‘¥ğ‘€,ğ‘–}ğ‘šğ‘–=1}. So there are totally ğ‘š(ğ‘€+1) images for training DCTN per iteration. We keep the discriminator training as described in Eq. 4. As for feature extractor training, we independently consider the adversary between the target and each source. Given this, âˆ‘ğ‘šğ‘–{âˆ’logğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥ğ‘—,ğ‘–))âˆ’log[1âˆ’ğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡)ğ‘–))]} can be viewed as the â€œdifficultyâ€ degree to distinguish ğ‘¥ğ‘¥(ğ‘¡)ğ‘– from m images of the source j. Therefore, if F performs worst to transform target features to confuse the source ğ‘—âˆ—, it leads to ğ‘—âˆ—=argmaxğ‘—âˆˆ[ğ‘€]âˆ‘ğ‘šğ‘–{âˆ’logğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥ğ‘—ğ‘–))âˆ’log[1âˆ’ğ·ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡)ğ‘–))]}. Based upon the domain confusion loss, we use the source ğ‘—âˆ— and the target examples in the mini-batch to train the feature extractor F. This technique is concluded by Algorithm 1.

figure a
figure b
Target Discriminative Adaptation
Resembling the spirit of existing work about adversarial DAs, the multi-way adversarial adaptation process does not consider the category variation during learning. No matter which MSDA scenario is considered, DCTN undergoes the identical adversarial process. Though it is able to produce domain-invariant features, it does not insure their abilities to classify a target domain. Ben-David et al. (2010) demonstrate that, to accommodate a source classifier in the target, DA algorithms requires the category classifier working well on different domains. But in case of a variety of MSDA scenarios, their classifiers should account for the categorical mis-alignment across M sources and the target, to prevent the damage caused by the non-consistent category sets across M sources and the unobserved categories (â€œunknownâ€) in the target domain.

To achieve a universal target category predictor, we incorporate target examples to learn classifiable features with source data via discriminatively fine-tuning {ğ¶ğ‘—}ğ‘€ğ‘—=1. We develop a switchable strategy to select and annotate target samples. To this, the feature extractor F and multi-source classifiers {ğ¶ğ‘—}ğ‘€ğ‘—=1 are trained with multi-source labeled samples and these pseudo-labeled target examples. In particular, we use the target category predictor obtained in the previous iteration to annotate each target sample. Afterwards, the strategy selects suitable target examples ğ—(ğ‘)ğ‘¡ and annotate them with pseudo labels ğ˜(ğ‘)ğ‘¡.

Specifically, DCTN incorporates two criteria to identify target samples with high confidences and low uncertainties, respectively. First, for each target sample, DCTN considers the category with the highest prediction probability according to Eq. 3. If the probability is larger than a threshold ğ›¾>0, this target sample would be selected as a high-confidence candidate. Second, DCTN further takes the classfication entropy of Eq. 3 to identify the candidates with low uncertainties. In vanilla and source-category-shift scenarios, only the target samples with high confidences and low uncertainties would get pseudo labels and join the fine-tuning. In the scenarios with target category shifts, DCTN additionally incorporate the target samples with low uncertainties and categorize them into the unknown class ğ‘ğ‘¢. The pseudo-labeling strategy is summarized as follows

ğ‘¦ğ‘¦(ğ‘¡)=â§â©â¨âªâª1ğ‘=argmaxğ’ğ‘ âˆª{ğ‘ğ‘¢}{ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡))}1ğ‘ğ‘¢Ent(ğ¶ğ‘¡(ğ‘¥ğ‘¥(ğ‘¡)))<ğœ   ğ‘ğ‘›ğ‘‘ ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡))>ğ›¾ Ent(ğ¶ğ‘¡(ğ‘¥ğ‘¥(ğ‘¡)))â‰¥ğœ,
(8)
where 1ğ‘ denotes the one-hot representation of the label w.r.t. the category c. Ent(ğ¶ğ‘¡(ğ‘¥ğ‘¥(ğ‘¡))) denotes the target category prediction entropy of ğ‘¥ğ‘¥(ğ‘¡). If ğ‘¥ğ‘¥(ğ‘¡) does not satisfy Eq. 8, it would be ignored in the discriminative adaptation phase. The discriminative adaptation objective is defined as

minğ¹, ğ¶ â„’ğ‘ğ‘™ğ‘ (ğ¹,ğ¶)=âˆ‘ğ‘—ğ‘€ ğ”¼(ğ‘¥ğ‘¥,ğ‘¦ğ‘¦)âˆ¼(ğ—ğ‘—,ğ˜ğ‘—)[â„’(ğ¶ğ‘—(ğ¹(ğ‘¥ğ‘¥)),ğ‘¦ğ‘¦)]+ğ”¼(ğ‘¥ğ‘¥(ğ‘¡),ğ‘¦ğ‘¦^(ğ‘¡))âˆ¼(ğ—(ğ‘)ğ‘¡,ğ˜(ğ‘)ğ‘¡)[âˆ‘ğ‘—=1ğ‘€â„’(ğ¶ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡))),ğ‘¦ğ‘¦^(ğ‘¡))],
(9)
where â„’ denotes the cross-entropy loss between predictions and (pseudo) labels; (ğ—(ğ‘)ğ‘¡,ğ˜(ğ‘)ğ‘¡) represent the selected target data and their pseudo labels, which are leveraged to update F and {ğ¶ğ‘—}ğ‘€ğ‘—=1.

The hyper-parameters ğ›¾ and ğœ are very important in our annotation strategy. For ğ›¾, DCTN incorporates the threshold close to 1 in order to ensure the high prediction probability to the pseudo label of each selected target example during training. While it does not suit ğœ. Concretely, after the first iteration in the alternative learning, some target images would be selected as belonging to the unknown classes, which further join to fine-tune the feature extractor, enabling each source-classifier to identify the unknown target classes. As the unknown classes can be gradually identified by our source-classifiers, their entropy value would become lower than those in the initial stage. A fixed threshold is not able to detect this change. To this, if DCTN uses a low entropy threshold ğœ, the scheme will mistreat more known-class images as unknown classes; while if DCTN uses a high entropy threshold, the number of selected unknown-class target images would progressively decrease, even leading to no images selected into the unknown class for discriminative adaptation in the later stages. The both cases would harms the final performance of DCTNs. To overcome this problem, DCTN tend to choose a top x%. It implies that ğœ is a virtual threshold and no matter how the training progresses, the uncertain target samples will be selected in a certain number. The detailed setup of ğ›¾ and ğœ is found in the â€œAppendixâ€.

Theoretical Analysis
In this section, we dive deeper into DCTN from a theoretical perspective.

We first provide some notation and a brief introductin of distribution weight combining rule, which our method is inspired from. However, we find it needs to craft some source-specific hyper-parameters and is insuitable when neural networks are basic models. Therefore, we develop a new methodology connected with DCTN. By choosing more appropriate assumptions, it derives the learning adaptation upperbounds with regards to different MSDA problems.

Reviewing Distribution Weighted Combining Rule
Let {ğ’«ğ‘—}ğ‘€ğ‘—=1 and ğ’«ğ‘¡ denote source and target distributionsFootnote3, respectively. Given an instance ğ‘¥ğ‘¥, {ğ’«ğ‘—(ğ¹(ğ‘¥ğ‘¥))}ğ‘€ğ‘—=1 and ğ’«ğ‘¡(ğ¹(ğ‘¥ğ‘¥)) denote the probabilities of ğ‘¥ğ‘¥ drawn from {ğ’«ğ‘—}ğ‘€ğ‘—=1 and ğ’«ğ‘¡, respectively. Following source distribution weighted combining rule (Mancini et al. 2009), the target distribution denotes a mixture of multi-source distributions with the coefficients by normalized source distributions weighted by an implicit simplex â–³={ğœ†:ğœ†ğ‘—â‰¥0,âˆ‘ğ‘€ğ‘—=1ğœ†ğ‘—=1}ğ‘€ğ‘—=1, namely, ğ’«ğ‘¡(ğ¹(ğ‘¥ğ‘¥))=âˆ‘ğ‘€ğ‘âˆˆğ’ğ‘˜ğœ†ğ‘˜ğ’«ğ‘˜(ğ¹(ğ‘¥ğ‘¥)). For simplicity, we consider the vanilla MSDA case so that ğ’(ğ‘¡)=ğ’ğ‘˜, âˆ€ğ‘˜âˆˆ[ğ‘€]. Under the assumption in Mancini et al. (2009), an ideal target classifier ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡)) is derived by integrating source classifiers {ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))}ğ‘€ğ‘—=1:

ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡))=âˆ‘ğ‘—=1ğ‘€ğœ†ğ‘—ğ’«ğ‘—(ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))ğ’«ğ‘¡(ğ¹(ğ‘¥ğ‘¥(ğ‘¡))) ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡))).
(10)
Therefore we frame it into DA theory to further give its interpretation. In more specific, ğ’³ represents the input (feature) space; ğ‘“:ğ’³â†’â„ denotes the target function to learn (refer to the labels); â„:ğ’³â†’â„ denotes the hypotheses in â„‹ with respect to a specific underlying distribution (correspond to the classifier); ğ¿:â„Ã—â„â†’â„ denote a classification loss function. The MSDA learning objective function is formulated as

minâ„âˆˆâ„‹ â„’(ğ’«,â„,ğ‘“)=ğ”¼ğ‘¥âˆ¼ğ’«[ğ¿(â„(ğ‘¥),ğ‘“(ğ‘¥))],
(11)
where according to the definition of {ğ’«ğ‘—}ğ‘€ğ‘—=1 and ğ’«ğ‘¡, x denote the feature of ğ‘¥ğ‘¥ that ğ‘¥âˆ¼ğ’«(ğ¹(ğ‘¥ğ‘¥)). We would like to write it as ğ‘¥âˆ¼ğ’«(ğ‘¥) in our analysis. Suppose M source hypotheses {â„1,â‹¯,â„ğ‘€} correspond to {ğ’«1,â‹¯,ğ’«ğ‘€} and thus, for all ğ‘—âˆˆ[ğ‘€], â„’(ğ’«,â„,ğ‘“)â‰¤ğœ–, (ğœ–>0), source distribution weight combining rule holds an upper bound of target expected loss:

Proposition 1
(Mancini et al. 2009) Given a target distribution ğ’«ğ‘¡ as a mixture ğ‘ƒğœ† of multiple source distributions {ğ’«ğ‘—}ğ‘€ğ‘—=1 w.r.t.,ğœ†, the expected loss of its mixture hypothesis â„ğœ† is at most ğœ– w.r.t. any target function f, i.e., â„’(ğ‘ƒğœ†,â„ğœ†,ğ‘“)â‰¤ğœ–, where

ğ’«ğ‘¡(ğ‘¥)=ğ‘ƒğœ†(ğ‘¥)=âˆ‘ğ‘—=1ğ‘€ğœ†ğ‘—ğ’«ğ‘—(ğ‘¥), âˆ€ğœ†âˆˆâ–³,
(12)
and

â„ğœ†(ğ‘¥)=âˆ‘ğ‘—=1ğ‘€ğœ†ğ‘—ğ’«ğ‘—(ğ‘¥)ğ’«ğ‘¡(ğ‘¥)â„ğ‘—(ğ‘¥).
(13)
The mixture hypothesis â„ğœ† corresponds to ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡)) in Eq. 10. The theorem demonstrates that, if we are able to find optimal hyper-parameters ğœ†âˆˆâ–³, the target distribution can be represented as a mixture of multiple source distributions in Eq. 12, and the target classifier is certified to keep an upper bound of target distribution.

Equation 10 becomes a common assumption in many existing MSDA algorithms. However, â–³ in practice is implicit and always unobservable. In this case, it would not be a good assumption to learn transferable features in DCTN.

Instance DA Loss in DCTN
Similar with Eq. 10, our target predictor in DCTN integrates M source-target relations with perplexity scores to reweight and aggregate the target category predictions from M category source classifiers. However, the multi-source perplexity scores are completely built on the discriminative results according to the multi-way adversarial learning principle instead of a presumed simplex in distribution weight combining rule. Although DCTN does not rely on the distribution weight combining rule, some meaningful upper bounds are also held to guarantee its target classification.

Specifically, according to Eqs. 2, 3, the cocktail target category predictor refers to a hypotheses â„ğ‘¡:

â„ğ‘¡(ğ‘¥)=âˆ‘ğ‘—=1ğ‘€âˆ’log(1âˆ’ğ·âˆ—ğ‘—(ğ‘¥))âˆ‘ğ‘€ğ‘˜=1âˆ’log(1âˆ’ğ·âˆ—ğ‘˜(ğ‘¥))â„ğ‘—(ğ‘¥),
(14)
where ğ·âˆ—ğ‘— (âˆ€ğ‘—âˆˆ[ğ‘€]) denotes the optimal domain discriminator with respect to the source j and the target.

Distinct from Eq. 10 where F is fixed, multi-way adversarial learning encourages DCTNs to learn domain-invariant features.

Lemma 1
âˆ€ğ‘—âˆˆ[ğ‘€], the optimal ğ·ğ‘— corresponds to

ğ·âˆ—ğ‘—(ğ‘¥)=ğ’«ğ‘—(ğ‘¥)ğ’«ğ‘—(ğ‘¥)+ğ’«ğ‘¡(ğ‘¥),
(15)
so that

â„ğ‘¡(ğ‘¥)=âˆ‘ğ‘—=1ğ‘€log(1+ğ’«ğ‘—(ğ‘¥)ğ’«ğ‘¡(ğ‘¥))âˆ‘ğ‘€ğ‘˜=1log(1+ğ’«ğ‘˜(ğ‘¥)ğ’«ğ‘¡(ğ‘¥))â„ğ‘—(ğ‘¥).
(16)
Note that â„ğ‘¡ is proposed to classify target examples in the feature space, i.e., ğ‘¥ğ‘¡=ğ¹âˆ—(ğ‘¥ğ‘¥ğ‘¡), where ğ¹âˆ— is the optimal feature extractor obtained by our multi-way adversarial learning, and ğ‘¥ğ‘¥ğ‘¡âˆ¼ğ—ğ‘¡. Since target feature ğ‘¥ğ‘¡ is drawn from ğ’«ğ‘¡, it is reasonable to assume ğ’«ğ‘—(ğ‘¥ğ‘¡)â‰¤ğ’«ğ‘¡(ğ‘¥ğ‘¡) (ğ’«ğ‘—(ğ‘¥ğ‘¡) denotes the probability of the target feature ğ‘¥ğ‘¡ drawn from the source j). Due to the adversarial DA manner, for âˆ€ğ‘—âˆˆ[ğ‘€], ğ’«ğ‘— has been enforced to approach ğ’«ğ‘¡. Given this, it would be appropriate to suppose a source-specific approximation ratio ğ›¼ğ‘—âˆˆ(0,1) to describe the source-j-to-target adaptation, namely,

Assumption 1
(Multi-way adversarial learning) Provided a well-trained feature extractor ğ¹âˆ—, âˆ€ğ‘—âˆˆ[ğ‘€], it corresponds to an approximate ratio ğ›¼ğ‘—âˆˆ(0,1) so that âˆ€ğ‘¥ğ‘¡âˆˆğ’³, there exists ğ›¼ğ‘—ğ’«ğ‘¡(ğ‘¥ğ‘¡)â‰¤ğ’«ğ‘—(ğ‘¥ğ‘¡)â‰¤ğ’«ğ‘¡(ğ‘¥ğ‘¡).

ğ›¼ğ‘—ğ’«ğ‘¡(ğ‘¥ğ‘¡)â‰¤ğ’«ğ‘—(ğ‘¥ğ‘¡) implies the upper bound of the discrepancy between ğ’«ğ‘¡ and ğ’«ğ‘— in the optimized feature space. ğ›¼ğ‘— closer to 1 indicates the source j and the target more difficult to tell apart. ğ‘¥ğ‘¡ is drawn from a target domain rather than a source domain. To this end, it is more reasonable to assume ğ’«ğ‘—(ğ‘¥ğ‘¡) â‰¤ ğ’«ğ‘¡(ğ‘¥ğ‘¡). Beyond this, we also consider the pseudo-labeling strategy in discriminative adaptation, leading to another assumption about pseudo-labeled examples:

Assumption 2
(Pseudo-labeled discriminative adapatation) Given a well-trained feature extractor and M source-specific classifiers, after each multi-way adversarial DA updates, target examples hold ğœŒâˆˆ(0,1) as a probability of false labels by the pseudo-labeling strategy.

which states ğœŒÃ—100%-at-least target examples whose categories are correctly forecast by our pseudo-annotating strategy. Based upon the assumptions, we develop an upper bound of a target classification error in terms of a given target feature ğ‘¥ğ‘¡.

Proposition 2
Suppose the converged feature extractor ğ¹âˆ— satisfying Assumptions 1 and 2. Given a target feature ğ‘¥ğ‘¡, its classification loss â„’(ğ’«ğ‘¡,â„ğ‘¡,ğ‘“)(ğ‘¥) in DCTN can be upper bounded as follows:

â„’(ğ’«ğ‘¡,â„ğ‘¡,ğ‘“)(ğ‘¥)â‰¤1âˆ‘ğ‘€ğ‘˜=1log(1+ğ›¼ğ‘˜)âˆ‘ğ‘—=1ğ‘€ğ’«ğ‘—(ğ‘¥)ğ¿(â„ğ‘—(ğ‘¥),ğ‘“(ğ‘¥)),
(17)
where ğ¿(â„ğ‘—(ğ‘¥),ğ‘“(ğ‘¥)) indicates an instance loss of the ğ‘—ğ‘¡â„ source classifier.

The target instance bound of DCTN is composed of a target featureâ€™s bounds on all source classifiers with its corresponding probabilities that it belongs to these sources. It indicates that, the closer a target feature is located at a source center, the higher its probability belongs to this source. So as long as there is a source suits well to a target feature (the adversarial learning and classification fine-tuning perform well in this source), the DCTN performance would be guaranteed since the classification bound and the probability that the target feature belongs to this source have jointly dominated the bound. It demonstrates the connection between DCTN and those methods based on multi-source mixture assumption to a target sample. However, DCTN do not rely on it since the probability that a target sample belongs to a source is based on their transferable features automatically obtained by adversarial learning instead of pre-given by human experience.

Vanilla MSDA
Based on the target instance loss with respect to â„ğ‘¡ in Eq. 17, we provide the MSDA generalization bound of DCTN in the vanilla scenario:

Proposition 3
Suppose the converged feature extractor ğ¹âˆ— satisfying Assumptions 1 and 2. For all ğ‘—âˆˆ[ğ‘€], the source maintains â„’(ğ’«ğ‘—,â„ğ‘—,ğ‘“)â‰¤ğœ–ğ‘—, (ğœ–ğ‘—>0). Then the expected loss of a mixture hypothesis â„ğ‘¡ defined by Eq. 14 is at most ğœ–â€² w.r.t. any target function f :  â„’(ğ’«ğ‘¡,â„ğ‘¡,ğ‘“)â‰¤ğœ–â€², where

ğœ–â€²=1âˆ‘ğ‘€ğ‘˜=1log(1+ğ›¼ğ‘˜)((1âˆ’ğœŒ)âˆ‘ğ‘—âˆˆ[ğ‘€]ğœ–ğ‘—+ğ‘€ğœŒ)
(18)
Equation 18 denotes a surrogate target loss produced by the target category predictor [Eq.(2)], since it is not directly implemented to train the feature extractor F and M-source classifiers {ğ¶ğ‘—}ğ‘€ğ‘—=1. Equation 18 implies some guidances in transfer learning. Concretely, if it holds ğ›¼ğ‘˜â†’0, âˆ€ğ‘˜âˆˆ[ğ‘€], then ğœ–â€²â†’0 and learning DCTN will fail. As long as some of source domains successfully approach the target (âˆƒğ‘˜âˆˆ[ğ‘€], ğ›¼ğ‘˜â†’0), ğœ–â€² could provide a meaningful upper bound to reflect the MSDA process. Especially, when âˆ€ğ‘˜âˆˆ[ğ‘€] it holds ğ›¼ğ‘˜â†’1, Eq. 18 would turn into a normal classification bound over the average of M-source classifiers. In terms of ğœŒ, it shows the worst case about the mismatched categories in MSDA.

Category-Shift MSDAs
Though Eq. 18 is discussed in a vanilla MSDA scenario, the category predictor with source shifts also resembles the spirit. Concretely, we found that

ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡))=âˆ‘ğ‘âˆˆğ’ğ‘—ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)âˆ‘ğ‘âˆˆğ’ğ‘˜ğ‘ (ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜) ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))=âˆ‘ğ‘âˆˆğ’ğ‘—ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))âˆ‘ğ‘âˆˆğ’ğ‘˜ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜)+âˆ‘ğ‘âˆ‰ğ’ğ‘˜ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜)+âˆ‘ğ‘âˆ‰ğ’ğ‘—ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))âˆ‘ğ‘âˆˆğ’ğ‘˜ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜)+âˆ‘ğ‘âˆ‰ğ’ğ‘˜ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜)=âˆ‘ğ‘—âˆˆ[ğ‘€]ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘—)ğ¶ğ‘—(ğ‘|ğ¹(ğ‘¥ğ‘¥(ğ‘¡)))âˆ‘ğ‘˜âˆˆ[ğ‘€]ğ‘ (ğ‘|ğ‘¥ğ‘¥(ğ‘¡);ğ¹,ğ·ğ‘˜).
(19)
Given this, Eq. 3 could be viewed as the class-specific learner extended from Eq. 2. If {ğ¶ğ‘¡(ğ‘|ğ‘¥ğ‘¥(ğ‘¡)),ğ‘=1,...,ğ‘€} denotes a simplex with respect to all classes in the target domain, Eq. 3 turns into the special case of Eq. 2, thus, following the similar analysis.

In a MSDA problem with target category shifts, we conduct an upper bound of the target surrogate loss derived from Proposition 3. Let ğœŒâ€² denote the proportion of target data wrongly labeled by our unknown-class discovery strategy,

Proposition 4
Suppose the converged feature extractor ğ¹âˆ— satisfying Assumptions 1 and 2. For all ğ‘—âˆˆ[ğ‘€], the source maintains â„’(ğ’«ğ‘—,â„ğ‘—,ğ‘“)â‰¤ğœ–ğ‘—, (ğœ–ğ‘—>0). Then the expected loss of a mixture hypothesis â„ğ‘¡ defined by Eq. 14 is at most ğœ–â€² w.r.t. any target function ğ‘“:â„’(ğ’«ğ‘¡,â„ğ‘¡,ğ‘“)â‰¤ğœ–â€², where

ğœ–â€²=(1âˆ’ğœŒâ€²)(1âˆ’ğœŒ)âˆ‘ğ‘—âˆˆ[ğ‘€]ğœ–ğ‘—+((1âˆ’ğœŒâ€²)ğœŒ+ğœŒâ€²)ğ‘€âˆ‘ğ‘€ğ‘˜=1log(1+ğ›¼ğ‘˜).
(20)
Equation 20 is upper bounded by Eq. 18. The equality is satisfied when ğœŒâ€²â†’0, implying that no unknown target example has been missed to detect with our entropy-based â€œunknownâ€ target example discovery strategy. In the source-target-category-shift scenario, learning DCTN could be considered as combining the analysis of the both category-shift scenarios.

Experiments
In the context of MSDA, we evaluate the classification accuracy of the target category predictor in experiments. Four adaptation learning cases, i.e., vanilla, source-category-shift, target-category-shift and source-target-category-shift MSDA problems, will be thoroughly studied. Each empirical study is implemented with a single GTX GeForce 1080 GPU on PyTorch platform. More implementation details are referred to the supplementary material.

Benchmarks and Measures
Four widely-applied DA benchmarks, i.e., Office-31 (Saenko et al. 2010), ImageCLEF-DA, Digits-five and DomainNet (Peng et al. 2019) are introduced for the vanilla MSDA experimental evaluations. We follow the test routine in the previous works (Long et al. 2015, 2016) for fair comparisons. For reproducibility, the detailed dataset splits are released.Footnote4

Office-31 is a classical benchmark for object recognition with 31 categories. It has three datasets, A (Amazon), D (DSLR), W (Webcam). There are 4652 images in total.

ImageCLEF-DA is released for the ImageCLEF 2014 domain adaptation challenge. It covers 12 object categories (aeroplane, bike, bird, boat, bottle, bus, car, dog, horse, monitor, motorbike, and people) shared in the three famous real-world datasets, I (ImageNet ILSVRC 2012), P (Pascal VOC 2012), C (Caltech-256). It includes 50 images in each class and totally 600 images for each domain.

Digits-five includes five digit image sets drawn from following public datasets, mt (MNIST) (LeCun et al. 1998), mm (MNIST-M) (Ganin et al. 2017), sv(SVHN) (Netzer et al. 2011), up (USPS) and sy (Synthetic Digits) (Ganin et al. 2017), respectively. We draw 25,000 for training and 9,000 for testing in each set, i.e., MNIST, MNIST-M, SVHN and Synthetic Digits and choose the entire USPS dataset as one domain with only 9,298 images.

DomainNet includes six natural image domain sets. e.g., clp(Clipart), inf(Infograph), pnt(Painting), qdr(Quickdraw), rel(Real) and skt(Sketch), with 345 categories and around 0.6 million images in total.

Note that, DCTNâ€™s performance in the vanilla MSDA based on DomainNet have been provided in Peng et al. (2019). They used AlexNet as DCTNâ€™s backbone to compare with M3SDA in ResNet101. To this, we evaluate DCTN and M3SDA by using the same backbones in Office-31, ImageCLEF and Digits-five in the vanilla MSDA scenarios (Sect. 5.2). In terms of DomainNet, we standardized their backbones with ResNet101 and evaluated them when source and target category shifts both exist (Sect. 5.4).

Table 1 Accuracy (%) on Office-31 in the vanilla MSDA setting
Full size table
Table 2 Accuracy on ImageCLEF-DA in the vanilla MSDA setting
Full size table
As for the evaluation results, we follow the standard evaluation protocols adopted in unsupervised domain adaptation (Long et al. 2015; Ganin and Lempitsky 2015), and derive them to suit different MSDA scenarios (details are introduced in the corresponding sub-sections). Generally, for Office-31 and ImageCLEF-DA datasets, we use all labeled source examples and all unlabeled target examples. We compare the average classification accuracy of each method on three random independent experiments, and report the standard error of the classification accuracies by different experiments of the same transfer task. For the digit-5 and DomainNet benchmarks, we use all labeled source and unlabeled target training samples, then evaluate its performance on target test sets. We randomly run 3 times till the model converges and then choose the best results to report the accuracy. Finally, we perform model selection by tuning hyper-parameters using transfer cross-validation.

MSDA in Vanilla Scenarios
The existing work of MSDA lack comprehensive evaluations on complex real-world visual recognition. In our experiment, we introduce three traditional MSDA approaches, e.g., RDALR (Jhuo et al. 2013b), sparse FRAME (sFRAME) (Xie et al. 2015), SGF (Gopalan et al. 2011) as the baselines in Office-31, and two deep MSDA approaches Multi-Source Batch Normalization (MSBN) (Mancini et al. 2018) and M3SDA as the baselines in Office-31 and ImageCLEF-DA. Besides, we also compare our DCTN with several single-source visual DA baselines, which include the conventional methods, e.g., Transfer Component Analysis (TCA) (Pan et al. 2011) and Geodesic Flow Kernel (GFK) (Gong et al. 2012), as well as several state-of-the-art deep DA approaches: Deep Domain Confusion (DDC) (Tzeng et al. 2015), Deep Reconstruction-classification Networks (DRCN) (Ghifary et al. 2016), Reversed Gradient (RevGrad) (Ganin and Lempitsky 2015), Pixel Domain Adaptation (PixelDA) (Bousmalis et al. 2017), Domain Adaptation Network (DAN) (Long et al. 2015), Residual Transfer Network (RTN) (Long et al. 2016) and Joint Adaptation Network (JAN) (Long et al. 2017). To achieve more comprehensive understanding about multi-source transfer, we compare our DCTN with these single source DA approaches by two different evaluation protocols. (1) Single source: Since they belong to single-source DA approaches, we directly report their single source transfer results from their original paper. (2) Source combine: multiple source domains are combined into a traditional single-source versus target domain adaptation setup. It helps to testify whether it would be able to boost the transfer performance gains through augmenting another source domain. Additionally, as baselines in the Source combine and multi-source standards, we use all images from sources to train backbone-based multi-source classifiers and apply them to classify target examples. These Source only results confirm whether our multi-source transfers are available (Negative indicates failure of adaptation). For fair comparisons, deep DA baselines in Office-31 and ImageCLEF-DA employ the Alexnet backbones, and share the same backbone model (see our â€œAppendixâ€) in Digits-five. The Source-combine results are basically derived from the official codes provided by their original papers.

Object recognition We report all transfer cases and compare our DCTN with the baselines in Tables 1 and 2 bolditalic, bold and italic indicate the performance of top 1, 2 and 3, respectively). Table 1 shows DCTN yielding the competitive results in the Office-31 transfer tasks A,W â†’ D and A,D â†’ W, performing impressively in D,W â†’  A. More specifically, DCTN significantly exceeds the traditional methods by a huge margin and mostly outperforms the single-source deep DA baselines, i.e., DAN, RTN, JAN, RevGred, and their source-combine variants. It reveals that if MSDA is treated as a single source DA problem by combining sources, the performance gain can not be fully excavated. Through the data transfer by DCTN, the potential power of multiple sources are efficiently used to boost the adaptation performance. Note that, MSBN is very competitive so that exceeds DCTN by 0.3% in Office-31 on its averaged accuracy. But MSBN does not generalize well across transfer cases: though achieving remarkable improvement in D,W â†’  A, MSBN remains inconspicuous in A,W â†’ D and A,D â†’ W (fall behind source-combine single source DA variants). In a comparison, DCTN wins the top-3 performances in all transfer cases and thus, demonstrates more significant generalization ability. In ImageCLEF-DA, source-combine DA variants achieve more superior than their original single source models, whereas remains inferior to our DCTN. It validates that, no matter whether the domain size is equal or not, DCTN is able to learn more transferable and discriminative features than the other baselines, from multi-source transfer for natural image domains. MSBN completely fails in ImageCLEF-DA and even appears negative transfer compared with the source-only baseline.

Digit recognition Different from the previous visual recognition benchmarks, Digit-five contains five domains in total and is specified for multi-domain learning. We investigate 4-to-1 transfer results of DCTN within the following domain shifts: mm, mt, sy, up  â†’  sv; mt, sv, sy, up  â†’  mm; mt, sv, mm, up  â†’  sy and mt, sv, sy, mm  â†’  up, and provide the performance on average. We compare DCTN with RevGred, DAN and their source-combine transfer variants.

Table 3 Classification accuracy (%) on Digits-five dataset for MSDA in the vanilla setting
Full size table
Table 4 Average accuracy (%) performances of the above baselines
Full size table
Fig. 3
figure 3
The absolute performances based upon the mean accuracies (%) of Source only, RevGread, DAN and DCTN on Office-31 and ImageCLEF-DA under the MSDA category shift scenario. The curves denote their accuracies changing as the public classes across multiple sources increase. Higher is better

Full size image
Fig. 4
figure 4
The relative performance (degraded accuraies, the accuracy under vanilla scenario minus the the accuracy under category shift) of Source only, RevGread, DAN and DCTN on Office-31 and ImageCLEF-DA under MSDA category shift scenario. The curves denote how much their accuracies drop as the public classes across multiple sources increase. Lower is better

Full size image
Fig. 5
figure 5
The transfer gains (the accuracy of the baseline minus the accuracy of source only) of Source only, RevGread, DAN and DCTN on Office-31 and ImageCLEF-DA under MSDA category shift scenario. The negative value means the negative transfer, which causes even heavier model damage than those without domain adaptation. Higher is better

Full size image
Overall accuracies of the baselines are concluded in Table 3. First of all, it is apparent that accuracies of single source DA approaches fall behind their source-combine. It implies that as M increases, multiple sources provide more evidences to boost transfer performance gains than those solely involved with a single source domain. However, we observe that these source-combine typically perform worse than their source-only except for mt, sv, sy, up  â†’  mm. In other words, despite of potential benefits multiple sources bring about, single source deep DA approaches conventionally suffer negative transfer. Therefore, it can not take advantage of the multi-source information into the model. In comparison, DCTN consistently shows positive transfer performances compared with the source only, and no matter of source-combine and multi-source ensemble, DCTN always outperforms the other baselines. In Table 4, the mean accuracy of our DCTN exceeds the second best by 3.6%.

MSDA in Source-Category-Shift Scenarios
In this subsection, we switch to evaluate DCTN in the category shift scenario, where the multiple sources do not share the same categories. We compare our DCTN with state-of-the-art approaches, i.e., DAN and RevGred, under the single-source and source-combine evaluation settings. Our experiments are conducted in four MSDA transfer cases: A,D â†’ W and A,W â†’ D in Office-31; I,P â†’ C and C,P â†’ I.

Evaluation protocol Since source-category-shift is newly proposed in MSDA scenario, benchmarks should be amended to to evaluate DA algorithms in this scenario. Specifically, suppose that M sources involve C categories and ğ¶ğ‘â‰¤ğ¶ indicates the number of their public classes. Due to ğ‘€=2, we consider the alphabetical order of the C classes and take the first ğ¶âˆ’ğ¶ğ‘2 and last ğ¶âˆ’ğ¶ğ‘2 classes as the source-specific private classes, then the rest proportion ğ¶ğ‘ğ¶ denotes the public classes. To unveil the comprehensive the baselines in this scenario, we evaluate them by specifying the public-class proportions ğ¶ğ‘ğ¶ in {0,0.3,0.5,0.7,1}, respectively.

We elaborate three metrics to reflect the adaptation capability of baselines from different perspectives. First, classification accuracy is to evaluate whether the baseline helps the classifier address the domain/category shift problem.

Second, We employ a relative measure termed degraded accuracy by examining how much performance drops when source-category shift exists, which is simply calculated as follows:

ğ·ğ´(ğ¶ğ‘ğ¶)=ğ´ğ‘ğ‘(ğ¶â€²ğ‘ğ¶=1)âˆ’ğ´ğ‘ğ‘(ğ¶ğ‘ğ¶),
(21)
where ğ´ğ‘ğ‘(ğ¶ğ‘ğ¶) denotes the accuracy when the public-class proportion is ğ¶ğ‘ğ¶, and ğ´ğ‘ğ‘(ğ¶â€²ğ‘ğ¶=1) means the accuracy of the model trained in vanilla MSDA scenario. The formula showcases the performance drop caused by inconsistent categories of sources. The lower value means the algorithms less affected by this negative effect, performing more robust in this scenario. Finally, we employ transfer gain as the third metric to further confirm the availability of transfer learning. Transfer gain is calculated through subtracting the baselineâ€™s accuracy with the accuracy of Source only. A positive value undoubtedly means that the transfer is available, while a negative value means the DA approach aggravates the domain shift problem.

Results The experiments cover the four transfer cases. Experimental results on these metrics (mean accuracy, degraded accuracy and transfer gain), are illustrated in Figs. 3, 4 and 5, respectively. DCTN always outperforms other baselines in different proportions of public classes and transfer cases. Generally, the improvement becomes larger as the sources contain more public classes. In Fig. 4, it can be observed that both Source only and DCTN behave neck and neck in ImageCELF-DA.

Table 5 Accuracy (%) of each method based on the 10-shared-class target-category-shift scenario in Office-31
Full size table
Considering the relative enhancement measure, in Office-31, Source-only even obtains lower DA values than DCTN. Note that, it does not imply Source-only outperforms our DCTN. In particular, compared with DA algorithms, i.e., DAN, RevGred and DCTN, Source-only undergoes fully-supervised learning, therefore, is free of the risk caused by category misalignment. To some extent, it should be treated as a sort of consecutive strategy preferring the safety of supervised training rather than adapting to a domain without labeled data.

Considering the absolute performance shown in Fig. 3, it is obvious that, Source-only are almost inferior to all DA approaches.

Besides of superior transfer performance improvement, another merit of DCTN is the strong resistance against the potential negative transfer influences. As demonstrated in Fig. 5, compared with other state of the art methods, DCTN remain positive values in all transfer cases. Specifically, in Office-31, DAN shows impressive transfer performance in A,D â†’ W with 0% public classes, but its performance on transfer gain is quite unstable as the public class number becomes challenging. RevGred performs more stable and better than DAN in general, whereas both of them inevitably suffer from negative transfer and are wholly suppressed by our DCTN. Similarly, in ImageCLEF-DA, DAN and RevGred still fail to achieve a promising transfer performance. In particular, when the number of public classes is small, their transfers even result in more model damages.

MSDA in Target-Category-Shift Scenarios
In this subsection, we evaluate DCTN in the target-category-shift scenario. As we previously discussed, it can be viewed as an open-set DA problem in a multi-source condition. We follows the similar experimental setting by reconfiguring Office-31 benchmark as Saito et al. (2018). Concretely, we randomly choose the 10 classes in the Caltech dataset (Gong et al. 2012) as the common classes of the sources and target and the rest 21 are â€œunknownâ€. In order to fairly compare with the single-domain open-set DA methods (Saito et al. 2018; Busto and Gall 2017) (they can be treated as Source-combine baselines in the target-shift experiments), we follow their protocols. Specifically, we evaluate all baselines on three domains in Office-31 with different numbers and for each domain, 1â€“11 classes are selected as shared classes across sources and target; 21â€“31 classes are selected as unknown target classes for identification. We accept the routine adapted in Saito et al. (2018) so that 11â€“20 classes have been abandoned.

Baselines For a fair comparison, we compare five state-of-the-art open-set DA approaches with our DCTN in target-category-shift MSDA scenario: OSVM, MMD + OSVM, BP + OSVM, ATI-ğœ† + OSVM, and RevGred-OP (Saito et al. 2018). The first four methods are derived from Open-set SVM (OSVM) (Busto and Gall 2017), which employ a threshold to preclude the target examples probably belonging to the â€œunknownâ€ class. The last one is developed from RevGred. Since they are not open-sourced, to ensure the fairness in our comparisons, we directly report their published performance results in the single source open-set scenario.

Evaluations Two evaluation measures, i.e., OS and OS*, are used to evaluate DCTN and comparison methods. The first testifies the methods on all target categories. The second evaluates them on 10 known categories. As can be observed in Table 5, in evaluation criteria OS and OS*, the single best accuracies of RevGred-OP remain suppressed by DCTN in A,W â†’ D (97.1, 99.4 of DCTN better than 96.8, 96.9 of RevGred-OP) and A,D â†’ W (96.7, 98.9 of DCTN better than 94.4, 94.6 of RevGred-OP).

MSDA in Source-Target-Category-Shift Scenarios
Source and target category shifts may concurrently appear. How much the joint negative transfer they bring about and whether it can be mitigated by MSDA algorithms, remain underexplored. To this, we start the evaluation from the experimental setup in MSDA with the target category shift, then further vary the proportion of the public categories, similar to the source-shift practice in Section 5.3. Our experiments are conducted in four transfer cases: A,D â†’ W and A,W â†’ D in Office-31; clp,pnt,dqr,rel,skt â†’ inf and clp,pnt,dqr,rel,inf â†’ skr in DomainNet. For DomainNet, we selected the categories with IDs over 250 and unify them to construct the unknown class ğ‘ğ‘¢. Afterwards, we change the proportions of public categories from 0%, 50% to 100%. Since DomainNet is a very challenging benchmark. So we slightly change the data-split routine in Office-31. Specifically, in the case of 0%, we select 1â€“125 classes into the first and second sources, 126â€“250 classes into the third and fourth sources, then let the last source contains all 250 categories; in the case of 50%, we select 1â€“166 categories into the first and second sources, 84â€“250 categoies into the third and fourth sources, the last source contains all 250 categories. So the public classes in DomainNet refers to those shared across source 1,2 and source 3,4. This setting simplifies the complex category relation across the five source domains, encourage the evaluation to focus on the varation of performances across baselines.

Fig. 6
figure 6
The accuracies (%) of Source only, M3SDA and DCTN based on two transfer cases, in the source-target-category-shift scenario on Office-31 (OS and OS* indicate two evaluation protocols in target category shift scenarios). The curves denote their accuracies changing as the percentage of public classes across multiple sources increases. Higher is better

Full size image
Fig. 7
figure 7
The accuracies (%) of Source only, M3SDA and DCTN based on two transfer cases, in the source-target-category-shift scenario on DomainNet (OS and OS* indicate two evaluation protocols in target category shift scenarios). The curves denote their accuracies changing as the percentage of classes across multiple sources increases. Higher is better

Full size image
In terms of the baselines, distinct from what were evaluated in the previous sub-section, we considered the comparison between M3SDA and DCTN along with Source-only. Since M3SDA and DCTN are both state-of-the-art MSDA algorithms while with a similar spirit behind, thus, it would be insightful whether DCTN and M3SDA can both prevent the negative transfer or not. Since the original M3SDA algorithm is unable to handle the unknown categories in the target domain, for a fair comparison, we endowed M3SDA with the identical strategy in DCTN to screen the unknown-class samples. All baselines are evaluated based on the classification accuracy under OS and OS* criterion.

The results are illustrated in Figs. 6 and 7. In A,W â†’ D , clp,pnt,dqr,rel,inf â†’ skr and clp,pnt,dqr,rel,skr â†’ inf,all the accuracy curves of DCTN and MSDA performed as upper envelopes of the Source-only, showing that the negative transfer effects have been eliminated in the cases. Notably, DCTN keeps ahead in all cases and protocols. But when the proportion of public classes decreases, the transfer gains brought by DCTN and MSDA are gradually minimized. Especially, when there are no public categories across the source domains, the transfer improvement from M3SDA has been completely erased in all transfer cases. In A,D â†’ W,M3SDA has suffered a serious negative transfer effects in the OS and OS* protocols. Instead, DCTN is still able to provide a transfer gain in this case. The results showcase the superiority of DCTN in these tough category-shift scenario.

Fig. 8
figure 8
The t-SNE (Maaten and Hinton 2008) visulization of A,D â†’ W. Green, black and red represent domains A, D and W respectively. We use different markers to denote 5 categories, e.g., bookcase, calculator, monitor, printer, ruler. Best viewed in color

Full size image
Fig. 9
figure 9
Analysis: a the accuracies of DCTN, adversarial-only and pseudo-only models; b the accuracies of testing samples and pseudo-labeled target samples; c the convergence performance on different losses. Best viewed in color

Full size image
Model Analysis
Feature visualization Take the task of A,D  â†’  W in Office-31 for example.

We visualize the DCTN activations before and after adaptation, which is impressive to demonstrate that the transferability learnt by DCTN. For simplicity, both source domains have been separated to emphasize the contrast of the target domain. As we can see in Fig. 8, compared with those from source only, our activations from A  â†’  W and D  â†’  W have shown good adaptation patterns. This indicates DCTN can successfully learn transferable features with multiple sources. Besides, the target activations become more clear to categorize, which suggests that the features learned by DCTN attains desirable discriminative property. Finally, even if the multi-source transfer has been composed of hard transfer task (A  â†’  W), DCTN is still able to adapt to target domain without the performance degradation in D  â†’  W.

Table 6 Ablation study of Algorithm 1 in Office-31
Full size table
Ablation study The learning of DCTN consists of the multi-way adversary and auto-labeling scheme. To further reveal their function, we decompose DCTN into two variants: The adversarial-only model excludes the pseudo-labels and updates the category classifier with source samples. The pseudo-only model forbids the adversary and categorize target samples with average multi-source results. As shown in Fig. 9a, the accuracy of adversary behaves stably in each iteration. But due to the lack of target class guidance, its final performance hits a bottleneck. Without the adversary, the accuracy of pseudo labels significantly drops and pulls down the DCTN accuracy. It indicates that both adaptations cooperate with each other to achieve desirable transfer behaviors. Diving deeper in Fig. 9b, the test accuracy and the pseudo label accuracy show converged in the alternative learning, which implicitly reveals the consistency between both adaptations. We also provide the ablation to the domain batch mining technique (Table 6), which testifies the methodâ€™s efficacy.

Pseudo-labeling strategy From the ablation above, we know pseudo-labeled target samples are playing a key role of training a well-performed DCTN. So it is important to check whether annotation strategy may improve other baseline. To this, we evaluate DAN, RTN, JAN, RevGred (four single-source DA algorithms with their source-combine results), MSBN, M3SDA and our DCTN (three MSDA algorithms) independently when they are learned with and without using our pseudo-labeling strategy. In Fig. 10, we observed that the accuracies of all single-source approaches and MSBN have been decreased, probably due to using a single classifier for prediction. Instead, M3SDA and DCTN are benefited from the pseudo-labeling strategy.

Convergence analysis As DCTN involves a complex learning procedure including adversarial learning and alternative adaptation, we testify the convergence performance of different losses. In the process of hard transfer A â†’ W, Fig. 9c demonstrates that, despite deviation, the classification loss, adversarial loss and test error gradually converge.

Fig. 10
figure 10
The comparison of different algorithms when they use and donâ€™t use pseudo-labeled target samples in training

Full size image
Conclusion
In this paper, we have explored the unsupervised DA involved with multiple sources challenged by domain shift and category shift. Beside the vanilla MSDA transfer scenario, we further investigate three other innovative and realistic MSDA scenarios, where the category sets across multiple sources and the target are assumed to be inconsistent. In order to overcome these transfer challenges, we propose deep cocktail network (DCTN), an adversarial DA framework to obtain transferable and discriminative features from multiple sources to a target domain. It constitutes an alternating learning process that delicately refers to our target classification principle. DCTN can be flexibly deployed in ordinary MSDA and category shift scenarios, and more importantly, it suits the open-set scenario with a mild reconfiguration. Delving into the motivation of DCTN, we further reveal that, DCTN connects with a previous MSDA theory and enjoys an expected loss upper bound through an adversarial DA assumption instead of specifying a strong target mixture precondition. Finally, DCTN is evaluated across three benchmarks with massive transfer combinations under three scenarios. It achieves state-of-the-art results in most of our evaluation criteria and behaves extraordinarily to resist negative transfer effects.