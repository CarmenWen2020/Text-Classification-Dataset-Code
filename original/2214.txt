This paper is concerned with the problem of multi-view 3D reconstruction with an un-calibrated micro-lens array based light field camera. To acquire 3D Euclidean reconstruction, existing approaches commonly apply the calibration with a checkerboard and motion estimation from static scenes in two steps. Self-calibration is the process of simultaneously estimating intrinsic and extrinsic parameters directly from un-calibrated light fields without the help of a checkerboard. While the self-calibration technique for conventional (pinhole) camera is well understood, how to extend it to light field camera remains a challenging task. This is primarily due to the ultra-small baseline of the light field camera. We propose an effective self-calibration method for a light field camera for automatic metric reconstruction without a laborious pre-calibration process. In contrast to conventional self-calibration, we show how such a self-calibration method can be made numerically stable, by exploiting the regularity and measurement redundancies unique for the light field camera. The proposed method is built upon the derivation of a novel ray-space homography constraint (RSHC) using PlÃ¼cker parameterization as well as a ray-space infinity homography (RSIH). We also propose a new concept of â€œrays of the absolute conic (RAC)â€ defined as a special quadric in 5D projective space â„™5. A set of new equations are established and solved for self-calibration and 3D metric reconstruction specifically designed for a light field camera . We validate the efficacy of the proposed method on both synthetic and real light fields, and have obtained superior results in both accuracy and robustness.

Access provided by University of Auckland Library

Introduction
Light fields are commonly represented as spatial and angular discrete sampling of rays. Since the first hand-held light field camera (LFC) (Ng et al. 2005) is put forwarded in the last decade, significant efforts have been spent to develop compact and handy LFCs. Due to the regular and abundant angular information of light fields, commercial micro-lens array based LFCs such as Lytro (2011) and Raytrix (2013) gain increasing popularity and have been applied to many computer vision tasks, e.g. structure-from-motion (SfM) (Johannsen et al. 2015; Zhang et al. 2017b; Nousias et al. 2019), 3D reconstruction (Johannsen et al. 2016; Zhang et al. 2017a; Vianello et al. 2018), light field stitching (Birklbauer and Bimber 2014; Guo et al. 2016; Ren et al. 2017) and robust SLAM (Dansereau et al. 2011; Dong et al. 2013; Li et al. 2019). In order to perform these 3D metric related tasks, having an LFC metrically calibrated is essential.

Traditionally, existing multi-view LFC based applications conduct LFC calibration as a pre-processing separately and achieve their method with calibrated light fields. However, most LFC calibration methods are often conducted in an ad hoc way, depending on a direct adaption of the calibration method designed for a single pinhole camera. Even if it only requires a single printed checkerboard, the pre-calibration process is still time-consuming and laborious, considering need of the additional captured light fields. It is much desirable to have a â€œself-calibrationâ€ (aka auto-calibration, or on-the-fly) method that can automatically determine the parameters of an LFC without the aid of any specific calibration target, but simply from observing the static scene. Once this is done, it is possible to compute a 3D metric reconstruction from multiple un-calibrated light fields directly.

Although an underlying LFC can be equivalent to an array of pinhole cameras, for which one could use the traditional self-calibration technique developed for one single pinhole camera. Taking a large number of sub-aperture images extracted from the light field into consideration, self-calibrating the sub-aperture images independently is still an onerous task. Moreover, treating each sub-aperture as a tiny pinhole camera overlooks the regularity among sub-apertures resulting in unstable estimation  (Zhang et al. 2019c). Due to regularly arranged view points of an LFC on a plane, it is necessary to process the light field as a whole. It is our view that the abundant and regular rays captured by the LFC provide rich and redundant constraints that one needs to utilize for better numerical stability of any LFC based algorithms.

Besides, the constant baseline during self-calibration is another advantage of LFCs compared with traditional pinhole cameras. Since the traditional self-calibration methods cannot recover the scale directly, the translation between the first pair of cameras has a unit vector. However, the light field is equivalent to numerous sub-aperture images regularly arranged on a plane, and the baseline indicates the translation between neighboring sub-aperture images (Bok et al. 2017; Zhang et al. 2019c). Consequently, the constant intrinsic parameters, especially the baseline, make it easy to constrain the translation up to a uniform scale for 3D metric reconstruction (aka similar reconstruction) directly. It is also worth noting that since the Euclidean distance of static scenes is not provided in advance, the LFC self-calibration method recovers metric structure instead of isometric structure.

To the best of our knowledge, there is no dedicated LFC self-calibration algorithm available in the literature. This work is proposed to fill in this gap by providing the first self-calibration algorithm specifically designed for an LFC. The overview of the proposed algorithm is illustrated in Fig. 1. Specifically, by exploiting ray-space infinity homography and its conjugate rotation, a novel â€œrays of the absolute conicâ€ (RAC) quadric equation is derived for an LFC. Solving these RAC equations gives rise to accurate and robust LFC self-calibration, and at the same time, 3D metric reconstruction can be computed via rayâ€“ray correspondences. The rayâ€“ray correspondence is two rays emitted from the same 3D point but sampled by two light fields. Also note that similar to some traditional self-calibration algorithms, the effect of radial distortion is neglected to simplify the proposed self-calibration method. Moreover, a common belief in these traditional self-calibration algorithms is numerical instability because of the insufficient features, and it still requires further research. Contrary to this, we show in this paper, by extensive experiments, the proposed LFC self-calibration method is numerically stable, and the estimated results (both camera parameters and reconstructed 3D structures) are accurate and robust to noise and outliers.

Fig. 1
figure 1
An overview of LFC self-calibration and 3D metric reconstruction. We decode sub-aperture images and extract rayâ€“ray correspondences from two LFs with PlÃ¼cker parameterization. Rayâ€“ray correspondence is two rays from the same 3D point but sampled by two light fields. Given these rayâ€“ray correspondences, we generate the ray-space homography constraint (RSHC). The LFC parameters including LFC intrinsic matrix ğ¾ğ¾ and relative pose ğ‘…ğ‘…,ğ‘¡ğ‘¡ are then solved. We also implement 3D metric reconstruction with an un-calibrated LFC

Full size image
In summary, the main contributions are:

1.
we develop a ray-space homography constraint based on rayâ€“ray correspondences with PlÃ¼cker parameterization.

2.
we explore the ray-space infinity homography and present a new concept of â€œrays of the absolute conicâ€ for LFC self-calibration.

3.
we design a self-calibration algorithm of which the effectiveness is verified by 3D metric reconstruction with an un-calibrated LFC.

Related Work
Light Field Camera Motion Estimation
Researchers focus on recovering accurate LFC positions since the hand-held LFC is first introduced by Ng (2005). Light field essentially records the rays in space. PlÃ¼cker coordinate also provides a reliable mathematical mechanism to uniformly parameterize rays and describe ray-to-ray transformation. For this reason, motion estimation for generalized cameras is a natural application for light field imaging. Pless (2003) utilizes rays to represent image pixels with PlÃ¼cker coordinates. The generalized epipolar constraint between rayâ€“ray correspondences is first proposed for motion estimation for generalized cameras. A linear framework requiring 17 rayâ€“ray correspondences is proposed and solved via the Singular Value Decomposition (SVD). Based on PlÃ¼cker coordinates, Bartoli and Sturm (2001, 2004) present the 3D line motion matrix for projective transformation and then specialize it to the affine, similar and Euclidean transformations. Different algebraic distances are defined to estimate motion from 3D line-line correspondences. Bartoli and Sturm (2005) also derive PlÃ¼cker constraints for traditional camera motion estimation and 3D reconstruction from 3D line-line correspondences, including initialization, triangulation and bundle adjustment. Sturm (2005) further unifies the theory of multi-view geometry for generalized cameras. This can also be applied to LFCs by considering an LFC as an array of pinhole cameras. Li et al. (2008) analyze the degeneracy of the generalized epipolar constraint on three typical generalized cameras, including non-overlapping, axial and non-overlapping-axial multi-cameras. For these types of cameras, a linear method, where the essential matrix is first recovered and the rotation matrix is then decomposed, is proposed to avoid the ambiguity. It is worth noting that an LFC does not cause these degeneracies due to the overlapping and planar views. Moreover, Kneip et al. (2014) combine the generalized epipolar constraint with eigenvalue minimization and develop an iterative solution to estimate motion of multi-cameras from at least 7 correspondences. This algorithm is numerical instability and sensitive to initialization although less correspondences are utilized.

Johannsen et al. (2015) first introduce PlÃ¼cker parameterization to represent rays captured by an LFC. They derive a linear ray-point constraint extended from the method of Li et al. (2008) to estimate LFCâ€™s pose. This constraint defines the relationship between the 3D point and the rays intersected at that point, but it is difficult to recover the 3D point accurately with rays in a single light field, taken the ultra-small baseline of an LFC into consideration. Instead of ray-point constraint associated with 3D points, the ray constraints using line and plane are developed respectively by Zhang et al. (2017b). They explore the transformations of ray-line and ray-plane with the changing pose. Similarly, either ray-line constraint or ray-plane constraint is sensitive to small noises, due to ultra-small baseline of the LFC. More recently, Nousias et al. (2019) summarize a complete structure-from-motion pipeline for a calibrated LFC. They also demonstrate that rayâ€“ray constraint of Li et al. (2008) is stable compared with ray-point constraint of Johannsen et al. (2015) for the initialization of LFC motion estimation.

In the following, the term metric structure implies that the structure is defined up to a similarity according to  Hartley and Zisserman (2003). The metric structure is an isometric structure composed with an isotropic scaling. In summary, the above methods enable 3D metric reconstruction to recover from pre-calibrated LFCs. The reconstruction that is directly recovered from multiple light fields without a prior calibration may result in a projective reconstruction, as also demonstrated in Zhang et al. (2019c), so having a metrically calibrated LFC is important.

Light Field Camera Calibration
Many research groups have extensively explored various LFC calibration algorithms to further perform multi-view light field based tasks. The first LFC calibration algorithm is proposed by Dansereau et al. (2013), which derives a 4D decoding matrix containing 12 free parameters. This matrix transforms recorded pixels into rays outside the LFC. However, they utilize a traditional calibration for initialization, which is still a time-consuming process for LFC, as verified in Zhang et al. (2019c). Besides, their intrinsic parameters are redundant and dependent, which leads to irregular rays for post-processing (e.g. SfM and 3D reconstruction, as also demonstrated in Birklbauer and Bimber 2014). Contrary to this, Bok et al. (2014; 2017) propose a geometric projection with 6 intrinsic parameters that are complex but have clear physical meaning. They generate line features extracted from sub-images of raw data for calibration. However, the low-resolution of sub-image brings challenges for accurate line feature extraction, so does the unfocused capturing status. It also demonstrates that raw data with low-resolution sub-images (e.g. 14Ã—14 for Lytro Illum) can not perform LFC based algorithms stably. Consequently, for most LFC based applications, the first step is usually seeking another light field representation, such as sub-aperture images.

Zhang et al. (2019c) also present a 6-parameter multi-projection-center (MPC) model. It is applicable to both traditional LFC and focused LFC designs. A 3D linear point-ray constraint is defined as the relationship between geometric structure and sampling rays, which also shows the importance of intrinsic parameters for 3D reconstruction. An efficient LFC calibration pipeline is developed for generic LFC. The projections of an LFC onto planes and conics are also explored under the MPC model by Zhang and Wang (2018) and Zhang et al. (2019b) respectively. Given that a light field essentially represents the collection of rays as a whole, a ray-space projection model is extended from the MPC model with the introduction of PlÃ¼cker parameterization by Zhang et al. (2019a). They also develop a simple 6Ã—6 intrinsic matrix which encapsulates all the six intrinsic parameters. A linear constraint and a rayâ€“ray cost function are established for linear initial solution and non-linear optimization respectively. Based on ray-space projection model, Zhang et al. (2020) propose the ray-space epipolar geometry to intrinsically describe the relation between two light fields.

Existing LFC calibration algorithms are conducted with the help of special calibration targets. Even only a single printed checkerboard is needed, the prior calibration is still time-consuming, let alone to capture the additional light fields for calibration before applying multi-view light field tasks. A self-calibration algorithm specifically designed for an LFC is important to reduce the workload of laborious calibration.

Self-Calibration
Traditional self-calibration has gained increasing attentions since the seminal work presented by Maybank et al. (1992). Existing approaches can be roughly divided into three categories: (1) direct method for estimating dual image of the absolute conic (DIAC) based on the Kruppaâ€™s equation (Luong and Faugeras 1997; Seo et al. 2001; Paudel and Van Gool 2018); (2) stratified method for estimating the plane at infinity based on Modulus constraint followed by solving DIAC (Hartley et al. 1999; Pollefeys and Van Gool 1999; NistÃ©r 2004; Chandraker et al. 2007b; Gherardi and Fusiello 2010; 3) joint estimation of both the plane at infinity and DIAC in the form of dual image of the absolute quadric (DIAQ) (Triggs 1997; Chandraker et al. 2007a; Habed et al. 2014). In order to increase numerical stability and find the minimal case for self-calibration, algebraic polynomial methods are involved (Paudel and Van Gool 2018; Larsson et al. 2018). Gurdjos et al. (2009) try to add spectral constraints in self-calibration algorithm to avoid ambiguous motion sequences and increase the numerical stability.

A seemingly straightforward choice for self-calibrating an LFC is to consider it as a direct extension of that for a single pinhole camera, given that an LFC is equivalent to a collection of pinhole cameras. Dealing with sub-aperture images independently, however, incurs burdensome processes. Moreover, an LFC is also a special design whose principle points are regularly arranged on a plane and this arrangement remains constant among light fields, which provides geometric constraint for feature extraction and self-calibration. For efficient use of abundant and regular rays captured by an LFC, it is necessary to uniformly process a light field as a whole. Inspired by the traditional self-calibration, a ray-space homography is established to decompose ray-space infinity homography and specifically derive rays of the absolute conic for an LFC.

Ray-Space Homography
A traditional 2D camera is a mapping between the 3D scene point and a 2D image point, as described by Hartley and Zisserman (2003), while compact LFCs are innovated from the traditional 2D camera with a similar but different way to record 3D scene. An LFC attaches to a micro-lens array in front of the sensor enables 3D reconstruction of the scene from a single photographic exposure, because it collects rays emanating from the scene point at different directions. To simplify the discussion of geometric analysis in the following section, a pixel captured by an LFC is generalized to a 4D ray from a 3D point (Ng 2006) in contrast with a 2D image point for a traditional camera. With the angular sampling of the light field, the ray captured by an LFC is usually represented by ğ‘™ğ‘™=(ğ‘–,ğ‘—,ğ‘¢,ğ‘£)âŠ¤âˆˆâ„4 in a two-parallel-plane parameterization (Levoy and Hanrahan 1996), where (ğ‘¢,ğ‘£)âŠ¤ refers to relative image points of a pinhole camera with the projection center at (ğ‘–,ğ‘—,0)âŠ¤, as shown in Fig. 3. Each independent view point (ğ‘–,ğ‘—)âŠ¤ corresponds to a sub-aperture image. Subsequently, with the help of shifted view points, an LFC can also be considered as an array of pinhole cameras regularly arranged on the view plane. Inversely, the traditional camera is the specialization of the LFC to the case of only one projection center (0,0,0)âŠ¤ on the view plane (Zhang et al. 2019c).

In this section, a light field is described as a collection of rays, which is represented via PlÃ¼cker parameterization. A rayâ€“ray correspondence indicates two rays from the same 3D point but sampled by two light fields. Based on the ray-space projection matrix, ray-space homography is derived to describe the transformation of PlÃ¼cker ray between different light field coordinate frames. Ray-space infinity homography is then decomposed from ray-space homography. Table 1 gives the definitions of notations used in the following sections.

Table 1 Definitions of notations used in the paper
Full size table
PlÃ¼cker Parameterization of Ray
A rigid body in 3D projective space is well-known to have six degrees of freedom (three for rotation and three for translation), while a ray (line) has only four degrees of freedom (Hartley and Zisserman 2003). It is hard to linearly formulate transformations of rays, such as rotation and translation. Considering that a light field typically represents a collection of rays in 3D projective space, we need a new mechanism to parameterize arbitrary rays. Consequently, the approach we will take is to represent a ray in free space by PlÃ¼cker parameterization. It provides mathematically elegant and linear equations for transformations of rays. In addition, PlÃ¼cker coordinates are a homogeneous parameterization to unambiguously represent a ray in 3D projective geometry. We will briefly introduce PlÃ¼cker parameterization of rays as follows.

Suppose a ray ğ‘Ÿğ‘Ÿ in 3D projective space denotes (ğ‘ ,ğ‘¡,ğ‘¥,ğ‘¦)âŠ¤ in a two-parallel-plane parameterization, where (ğ‘ ,ğ‘¡)âŠ¤ and (ğ‘¥,ğ‘¦)âŠ¤ indicate the view point (positional information of ğ‘Ÿğ‘Ÿ) and relative image point (directional information of ğ‘Ÿğ‘Ÿ) respectively. A ray ğ‘Ÿğ‘Ÿ can be represented by its direction ğ‘ğ‘=(ğ‘¥,ğ‘¦,1)âŠ¤ and a point (ğ‘ ,ğ‘¡,0)âŠ¤ that it passes through. In PlÃ¼cker parameterization, the ray is defined as a pair of vectors, namely a moment vector ğ‘šğ‘šâˆˆâ„3âˆ–{00} and a direction vector ğ‘ğ‘âˆˆâ„3, as shown in Fig. 2. Note that, the moment vector is the cross product between the direction of the ray and arbitrary point on the ray. In other words, the moment vector ğ‘šğ‘š is perpendicular to the plane containing the ray and the origin, that is ğ‘šğ‘šâŠ¤ğ‘ğ‘=0, as shown in Fig. 2. In summary, the moment vector and the direction vector of arbitrary ray are defined as (Pottmann and Wallner 2009),

{ğ‘šğ‘šğ‘ğ‘=(ğ‘ ,ğ‘¡,0)âŠ¤Ã—(ğ‘¥,ğ‘¦,1)âŠ¤=(ğ‘¡,âˆ’ğ‘ ,ğ‘ ğ‘¦âˆ’ğ‘¡ğ‘¥)âŠ¤=(ğ‘¥,ğ‘¦,1)âŠ¤,
(1)
where îˆ¾=(ğ‘šğ‘šâŠ¤,ğ‘ğ‘âŠ¤)âŠ¤ is PlÃ¼cker coordinate. The PlÃ¼cker coordinates are homogeneous coordinates. In upcoming equations, the calligraphic symbol, such as îˆ¾ for the ray ğ‘Ÿğ‘Ÿ, indicates the PlÃ¼cker coordinates obtained by stacking the moment vector on top of the direction vector.

Fig. 2
figure 2
PlÃ¼cker parameterization of the ray. A ray can be represented by its direction ğ‘ğ‘ and a point (ğ‘ ,ğ‘¡,0)âŠ¤ on the ray. The PlÃ¼cker coordinates of the ray is defined as îˆ¾=(ğ‘šğ‘šâŠ¤,ğ‘ğ‘âŠ¤)âŠ¤, where ğ‘šğ‘š=(ğ‘ ,ğ‘¡,0)âŠ¤Ã—ğ‘ğ‘ indicates the moment vector and be perpendicular to ğ‘ğ‘, i.e. ğ‘šğ‘šâŠ¤ğ‘ğ‘=0

Full size image
For the sake of discussions in the following section, we list the relevant equations. The point represented by a homogeneous vector (ğ‘‹ğ‘‹âŠ¤,ğ‘‹4)âŠ¤ lies on the ray îˆ¾ iff

âˆ’ğ‘‹4ğ‘šğ‘š+ğ‘‹ğ‘‹Ã—ğ‘ğ‘=00,
(2)
The matrix form is defined as,

(âˆ’ğ‘‹4ğ¼ğ¼[ğ‘‹ğ‘‹]Ã—)îˆ¾=00,
(3)
where [â‹…]Ã— denotes the vector cross product (Hartley and Zisserman 2003).

Two rays îˆ¾1 and îˆ¾2 given in the same coordinate frame intersect iff

ğ‘ğ‘2âŠ¤ğ‘šğ‘š1+ğ‘šğ‘š2âŠ¤ğ‘ğ‘1=0.
(4)
Rayâ€“Ray Correspondences
For traditional pinhole cameras, a 3D scene point is projected to a pixel on the 2D image plane. The relations between two images taken from different view points is established by finding pixel-pixel correspondence relating to the same 3D scene point. In contrast, a light field is represented as a collection of rays. The ray with PlÃ¼cker coordinates is a basic algebraic entity of a light field. With the help of shifted views in a light field, multiple rays emanating from the same 3D point are sampled. Consequently, the rayâ€“ray correspondences between two light fields are defined as two sets of rays with PlÃ¼cker coordinates,

{îˆ¸ğ‘–}ğ‘–=1,â€¦,ğ‘›âŸ·{îˆ¸â€²ğ‘—}ğ‘—=1,â€¦,ğ‘š,
(5)
where îˆ¸ğ‘– and îˆ¸â€²ğ‘— are from the same 3D point but are recorded in different light fields. îˆ¸=(ğ‘›ğ‘›âŠ¤,ğ‘ğ‘âŠ¤)âŠ¤ is the PlÃ¼cker coordinates of the ray ğ‘™ğ‘™=(ğ‘–,ğ‘—,ğ‘¢,ğ‘£)âŠ¤ captured by an LFC. As mentioned in Sect. 3.1, ğ‘›ğ‘›=(ğ‘–,ğ‘—,0)âŠ¤Ã—(ğ‘¢,ğ‘£,1)âŠ¤=(ğ‘—,âˆ’ğ‘–,ğ‘–ğ‘£âˆ’ğ‘—ğ‘¢)âŠ¤ and ğ‘ğ‘=(ğ‘¢,ğ‘£,1)âŠ¤ indicate the moment and direction vectors of the PlÃ¼cker ray îˆ¸.

Ray-Space Projection Matrix
According to Zhang et al. (2019a), with the introduction of PlÃ¼cker parameterization, the ray-space projection (RSP) matrix ğ‘ƒğ‘ƒâˆˆâ„6Ã—6 is proposed for an LFC to describe the ray-ray transformation from the ray îˆ¸=(ğ‘›ğ‘›âŠ¤,ğ‘ğ‘âŠ¤)âŠ¤ captured by an LFC to the generalized ray îˆ¾=(ğ‘šğ‘šâŠ¤,ğ‘ğ‘âŠ¤)âŠ¤ in 3D space,

îˆ¾=[ğ‘…ğ‘…ğ‘‚ğ‘‚3Ã—3ğ¸ğ¸ğ‘…ğ‘…]ğ¾ğ¾îˆ¸,
(6)
where ğ¸ğ¸=[ğ‘¡ğ‘¡]Ã—ğ‘…ğ‘… is the essential matrix. ğ‘…ğ‘…âˆˆğ‘†ğ‘‚(3) and ğ‘¡ğ‘¡âˆˆâ„3 refer to the rotation and translation of an LFC respectively. In addition, ğ¾ğ¾âˆˆâ„6Ã—6 is defined as the ray-space intrinsic matrix with the following format,

	(7)
which contains all six LFC intrinsic parameters (ğ‘˜ğ‘–, ğ‘˜ğ‘—, ğ‘˜ğ‘¢, ğ‘˜ğ‘£, ğ‘¢0, ğ‘£0), as shown in Fig. 3. (ğ‘˜ğ‘–,ğ‘˜ğ‘—) are the scale factors on view plane, namely baseline of an LFC. (ğ‘˜ğ‘¢,ğ‘˜ğ‘£) are the scale factors on image plane. (âˆ’ğ‘¢0ğ‘˜ğ‘¢,âˆ’ğ‘£0ğ‘˜ğ‘£) can be considered as the principle point of a sub-aperture image. It also implies the offset between the two-parallel-plane. This matrix describes the ray sampling of an LFC between light field coordinate frame and camera coordinate frame.

Fig. 3
figure 3
LFC intrinsic parameters. A ray is represented as its intersections on the view plane (green dot) and image plane (blue dot). (ğ‘–,ğ‘—)âŠ¤ on view plane indicates the view point. (ğ‘¢,ğ‘£)âŠ¤, which is relative to the intersection (black dot) of optical axis placed at (i, j, 0), denotes the direction of the ray. (ğ‘˜ğ‘–,ğ‘˜ğ‘—) are the scale factors on view plane (i.e. baseline of an LFC), and (ğ‘˜ğ‘¢,ğ‘˜ğ‘£) for the image plane (i.e. focal length of an LFC). (âˆ’ğ‘¢0ğ‘˜ğ‘¢,âˆ’ğ‘£0ğ‘˜ğ‘£) is the principle point of sub-aperture image, which implies the offset between view plane and image plane (Color figure online)

Full size image
Moreover, ğ¾ğ¾ can be decomposed as a lower triangular block matrix ğ¾ğ¾ğ‘–ğ‘—âˆˆâ„3Ã—3 and a upper triangular block matrix ğ¾ğ¾ğ‘¢ğ‘£âˆˆâ„3Ã—3. An important property of ğ¾ğ¾ can be observed for the equation derivation in Sect. 4,

Property 1
Block intrinsic matrices ğ¾ğ¾ğ‘–ğ‘— and ğ¾ğ¾ğ‘¢ğ‘£ are orthogonal, i.e. ğ¾ğ¾ğ‘–ğ‘—ğ¾ğ¾âŠ¤ğ‘¢ğ‘£=ğ¾ğ¾ğ‘¢ğ‘£ğ¾ğ¾âŠ¤ğ‘–ğ‘—=ğ‘˜ğ‘–ğ‘˜ğ‘£ğ¼ğ¼.

Ray-Space Homography Constraint
Instead of treating an LFC as a collection of perspective cameras independently for self-calibration, we develop a unified framework that considers all rays captured by an LFC as a whole and propose ray-space homography constraint.

Corollary 1
Consider rays îˆ¸ and îˆ¸â€² sampled by two light fields intersecting at a single point, the ray-space homography constraint (RSHC) is,

ğ‘ğ‘âŠ¤ğ¾ğ¾âˆ’1ğ‘–ğ‘—ğ‘…ğ‘…ğ¾ğ¾ğ‘–ğ‘—ğ‘›ğ‘›â€²+ğ‘ğ‘âŠ¤ğ¾ğ¾âˆ’1ğ‘–ğ‘—ğ¸ğ¸ğ¾ğ¾ğ‘¢ğ‘£ğ‘ğ‘â€²+ğ‘›ğ‘›âŠ¤ğ¾ğ¾âˆ’1ğ‘¢ğ‘£ğ‘…ğ‘…ğ¾ğ¾ğ‘¢ğ‘£ğ‘ğ‘â€²=0,
(8)
where îˆ¸=(ğ‘›ğ‘›âŠ¤,ğ‘ğ‘âŠ¤)âŠ¤ and îˆ¸â€²=(ğ‘›ğ‘›â€²âŠ¤,ğ‘ğ‘â€²âŠ¤)âŠ¤.

Proof
Given RSP matrices for two light field, the light field coordinate frame of the first light field is assumed as the reference,

ğ‘ƒğ‘ƒ=[ğ¼ğ¼ğ‘‚ğ‘‚ğ‘‚ğ‘‚ğ¼ğ¼]ğ¾ğ¾,   ğ‘ƒğ‘ƒâ€²=[ğ‘…ğ‘…ğ‘‚ğ‘‚ğ¸ğ¸ğ‘…ğ‘…]ğ¾ğ¾.
(9)
We first back-project a ray îˆ¸â€²2 in the second light field coordinate frame, and ray-trace to a ray îˆ¸2 in the first light field coordinate frame according to Eq. (9), named as ray-space homography ğ»ğ»=ğ‘ƒğ‘ƒâˆ’1ğ‘ƒğ‘ƒâ€²,

îˆ¸2=ğ¾ğ¾âˆ’1[ğ‘…ğ‘…ğ‘‚ğ‘‚ğ¸ğ¸ğ‘…ğ‘…]ğ¾ğ¾î„½î„¾î…î…‹î…‹î…‹î…‹î…‹î…‹=:ğ»ğ»îˆ¸â€²2,
(10)
which describes the rayâ€“ray transformation in 3D projective space â„™3, as shown in Fig. 4. In order to provide connivence for the self-calibration algorithm to calculate relative poses, we partition Eq. (10) into 2Ã—2 block matrices,

ğ»ğ»=[ğ»ğ»11ğ‘‚ğ‘‚3Ã—3ğ»ğ»12ğ»ğ»22]=[ğ¾ğ¾âˆ’1ğ‘–ğ‘—ğ‘…ğ‘…ğ¾ğ¾ğ‘–ğ‘—ğ‘‚ğ‘‚3Ã—3ğ¾ğ¾âˆ’1ğ‘–ğ‘—ğ¸ğ¸ğ¾ğ¾ğ‘¢ğ‘£ğ¾ğ¾âˆ’1ğ‘¢ğ‘£ğ‘…ğ‘…ğ¾ğ¾ğ‘¢ğ‘£],
(11)
where ğ»ğ»ğ‘–ğ‘— is a 3Ã—3 block matrix.

Then, let the re-traced ray îˆ¸2 intersect îˆ¸1 at 3D point ğ‘‹ğ‘‹. Substituting Eq. (10) into Eq. (4), we obtain RSHC and rewrite it in a block matrix form,

[ğ‘ğ‘âŠ¤ğ‘›ğ‘›âŠ¤]ğ¾ğ¾âˆ’1[ğ‘…ğ‘…ğ‘‚ğ‘‚ğ¸ğ¸ğ‘…ğ‘…]ğ¾ğ¾[ğ‘›ğ‘›â€²ğ‘ğ‘â€²]=0,
(12)
which needs to be satisfied by every rayâ€“ray correspondence îˆ¸â†”îˆ¸â€² intersecting at a 3D point. â—»

In geometry, the ray with PlÃ¼cker coordinates satisfies self-constraint of Klein quadric in â„™5. It can also be considered as a point on Klein quadric in â„™5. ğ»ğ» describes the rayâ€“ray projective transformation between different coordinate frames in â„™3. Geometrically, ğ»ğ» also represents the point-point hyper-transformation on Klein quadric in â„™5. Moreover, Bartoli and Sturm (2001, 2004) derive the 3D line motion matrix based on PlÃ¼cker coordinates to estimate the relative motion of the calibrated camera. They also analyze the linear representation of 3D lines under different transformations (e.g. Euclidean, similar, affine and homography), which is similar to ray-space homography of rays. According to the definition proposed by Bartoli and Sturm (2001, 2004) and Property 1, ray-space intrinsic matrix could be considered as a specialization of the 3D line homography matrix. Note that PlÃ¼cker transformation related to extrinsic parameters is Euclidean transformation, the geometric interpretation of ray-space homography is also defined as the 3D line homography matrix of the PlÃ¼cker ray between different coordinate frames.

Fig. 4
figure 4
Ray-space homography. Ray-space homography represents the transformation of a PlÃ¼cker ray between different light field coordinate frames. The second light field (on the left) may be rotated and corrected to simulate a pure translation. The ray-space homography ğ»ğ» can be divided into ray-space infinity homography ğ»ğ»âˆ (first) and ray-space translation homography ğ»ğ»ğ‘¡ğ‘¡(second)

Full size image
Ray-Space Infinity Homography
According to Eq. (10), the ray-space homography ğ»ğ» only depends on the intrinsic parameters of an LFC and relative pose. Given two arbitrary light fields captured by an LFC, we may rotate the LFC used for the second light field so that it is aligned with the first light field. This rotation may be simulated by applying a homography to the second light field. Then, we utilize the homography of pure translation to transform the two light fields in a uniform coordinate frame, as shown in Fig. 4. Consequently, according to the pure rotation and pure translation, ğ»ğ» can be divided into two parts,

îˆ¸=ğ¾ğ¾âˆ’1[ğ¼ğ¼ğ‘‚ğ‘‚[ğ‘¡ğ‘¡]Ã—ğ¼ğ¼]ğ¾ğ¾î„½î„¾î…î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹=:ğ»ğ»ğ‘¡ğ¾ğ¾âˆ’1[ğ‘…ğ‘…ğ‘‚ğ‘‚ğ‘‚ğ‘‚ğ‘…ğ‘…]ğ¾ğ¾î„½î„¾î…î…‹î…‹î…‹î…‹î…‹î…‹=:ğ»ğ»âˆîˆ¸â€²,
(13)
where one can see the decomposition into translation homography ğ»ğ»ğ‘¡ğ‘¡ (partitioned first) and rotation homography ğ»ğ»âˆ (partitioned second), as shown in Fig. 4. Note that ğ»ğ»ğ‘¡ğ‘¡ indicates the homography generated by pure translation and does not influence the direction of rays.

We then focus on the analysis of rotation homography ğ»ğ»âˆ. Consider (ğ‘‹ğ‘‹âŠ¤,0)âŠ¤ is the homogeneous coordinates of point on the plane at infinity in the first light field coordinate frame, îˆ¸â€² is the ray in the second light field coordinate frame which passes through this point. Substituting Eq. (13) into Eq. (3), we have,

[ğ‘‚ğ‘‚[ğ‘‹ğ‘‹]Ã—]ğ»ğ»ğ‘¡ğ‘¡ğ»ğ»âˆîˆ¸â€²=[ğ‘‚ğ‘‚[ğ‘‹ğ‘‹]Ã—]ğ»ğ»âˆîˆ¸â€²=00,
(14)
where ğ»ğ»ğ‘¡ğ‘¡ does not influence the direction vectors of rays from the plane at infinity, therefore it could be eliminated.

Remarks
we can conclude that, for any rayâ€“ray correspondences intersecting at points on the plane at infinity, RSHC does not rely on the translation, only on the rotation and LFC intrinsic parameters. Alternatively, ğ»ğ»âˆ is obtained if the translation ğ‘¡ğ‘¡ is 00, which corresponds to a rotation about the LFC. Thus ğ»ğ»âˆ is ray-space homography that relates arbitrary rays if the LFCâ€™s motion is a pure rotation.

In summary, the plane at infinity is a particularly important plane for self-calibration and metric reconstruction. The ray-space infinity homography ğ»ğ»âˆ represents the rayâ€“ray transformation on the plane at infinity. In addition, according to the definition of ğ»ğ»âˆ, i.e. Eq. (14), it is interesting to note that ğ»ğ»âˆ is a conjugate rotation which is important for self-calibration.

Rays of the Absolute Conic
The ray-space infinity homography gives additional insight into the LFC self-calibration. The absolute conic is on the plane at infinity such that a novel concept of â€œrays of the absolute conicâ€ (RAC) is defined, just as what has been developed for the traditional camera, namely,

Definition 1
The rays of the absolute conic (RAC) is the quadric ğœ”ğœ”=ğ¾ğ¾âŠ¤ğ¾ğ¾ in â„™5.

The RAC ğœ”ğœ” depends only on the intrinsic parameters ğ¾ğ¾ of an LFC, and it does not depend on the LFC orientation or position. Since ğœ”ğœ” is the rays of the absolute conic, it may be thought of as a convenient algebraic entity, and will be used in computations on LFC self-calibration.

According to the orthogonal rotation, we subsequently derive an important corollary of RAC ğœ”ğœ”,

Corollary 2
The projection of RAC ğœ”ğœ” under RSIH ğ»ğ»âˆ is equal to the RAC,

ğ»ğ»âŠ¤âˆğœ”ğœ”ğ»ğ»âˆ=ğœ”ğœ”.
(15)
Remarks
It is well known that the image of the absolute conic (IAC) is the key idea for the traditional self-calibration method of a pinhole camera, whereas for an LFC this role is played by the rays of the absolute conic (RAC). Eq. (15) could be utilized to calculate intrinsic parameters of an LFC once ğ»ğ»âˆ is estimated. In addition, the presences of ğ»ğ»âˆ may be expressed by saying that a RAC transforms invariantly. It is also worth noting that IAC for the traditional camera is a special case of RAC for the LFC when there is only one projection center on the view plane according to Eq. (15).

Self-Calibration Algorithm for LFC
For the traditional camera, infinity homography is the key to solve the self-calibration problem. It is estimated based on Modulus constraint which is a quartic polynomial or the special imaging condition (e.g. pure rotation). In contrast, considering that abundant and regular rays recorded by the LFC, we linearly establish RSHC and decompose RSIH for robust self-calibration. Also, RAC is retrieved from the RSIH. We finally design an effective self-calibration algorithm specifically for an LFC, including linear initialization and non-linear optimization.

Ray-Space Homography Estimation
Given a rayâ€“ray correspondence (ğ‘›ğ‘›âŠ¤,ğ‘ğ‘âŠ¤)âŠ¤â†”(ğ‘›ğ‘›â€²âŠ¤,ğ‘ğ‘â€²âŠ¤)âŠ¤, using Kronecker product operator âŠ—, we re-state Eq. (8) as,

(ğ‘ğ‘âŠ¤âŠ—ğ‘›ğ‘›â€²âŠ¤,ğ‘ğ‘âŠ¤âŠ—ğ‘ğ‘â€²âŠ¤,ğ‘›ğ‘›âŠ¤âŠ—ğ‘ğ‘â€²âŠ¤)ğ»ğ»â†’=0,
(16)
where ğ»ğ»â†’ refers to a 27-vector made up of the non-zero elements of ğ»ğ» in row-major order respectively. Considering N sets of ğ‘›Ã—ğ‘š rayâ€“ray correspondences (ğ‘Ã—ğ‘›Ã—ğ‘šâ‰¥26) in the form of Eq. (5), Eq. (16) is stacked as a homogeneous set of (ğ‘Ã—ğ‘›Ã—ğ‘š)Ã—27 linear equations, i.e., ğ´ğ´ğ»ğ»â†’=0. Ray-space homography estimation is numerical stability with sufficient rayâ€“ray correspondences. Then ğ»ğ»â†’ can only be determined up to a scale factor via standard SVD (Hartley and Zisserman 2003). Once ğ»ğ» is computed from considerable RSHCs, we can directly decompose RSIH ğ»ğ»âˆ according to Eq. (13).

Degeneracy It is worth noting that previous work (Li et al. 2008) on motion estimation from pre-calibrated generalized cameras proposes some degenerate cases, i.e. non-overlap multi-cameras and axial cameras, which can not be solved by standard SVD directly. For this reason, they propose a numerical method where first the essential matrix is recovered, from which one obtains the rotation using a decomposition step. However, the special design of the LFC permits the scene to be captured by different view points during a single shoot. Sub-aperture images share overlapping field-of-view and regularly arrange on a plane. For this reason, RSHCs generated by the rayâ€“ray correspondences can not arise these degeneracies.

In addition, RSHC also contains intrinsic matrix ğ¾ğ¾ compared with the generalized epipolar constraint, according to Eq. (8). It also decides the ambiguity of the solution will not happen in RSHCs. Consequently, a unique solution of Eq. (16) is readily solvable via the standard SVD method.

Normalization Considering the huge difference between angular resolution and spatial resolution of a light field, ray normalization specifically designed for an LFC is introduced to improve the numerical stability of the ray-space homography estimation. In a traditional camera, image normalization is utilized to improve accuracy and tackle less well-conditioned problems, like the linear estimation of the homography or the fundamental matrix. Similar to traditional normalization, two similarity transformations ğ‘‡ğ‘‡ and ğ‘‡ğ‘‡â€² on PlÃ¼cker coordinates, consisting of scale factors on view plane and image plane and a translation on image plane, are computed according to Eq. (7). Note that, the scale factors on view plane or image plane are identical. It is convenient to establish Eq. (7) which needs to satisfy the condition ğ‘˜ğ‘¢/ğ‘˜ğ‘£=ğ‘˜ğ‘–/ğ‘˜ğ‘—. The ray normalization is partly summarized in Alg. 1 and described in detail as follows,

NormalizeRays. Transform the rays îˆ¸ to a new sets of rays îˆ¸Ëœ, so do rays îˆ¸â€², namely îˆ¸Ëœ=ğ‘‡ğ‘‡îˆ¸ and îˆ¸Ëœâ€²=ğ‘‡ğ‘‡â€²îˆ¸â€².

EstimateRSH. Apply Eq. (16) to linearly estimate ğ»ğ»Ëœ via SVD according to rayâ€“ray correspondences {îˆ¸Ëœ}â†”{îˆ¸Ëœâ€²}.

DenormalizeRSH. Set the ray-space homography ğ»ğ»=1ğ‘¡â€²22ğ‘¡â€²44ğ‘‡ğ‘‡â€²âŠ¤ğ»ğ»Ëœğ‘‡ğ‘‡, where ğ‘¡â€²ğ‘–ğ‘— is i-th row and j-th column element of ğ‘‡ğ‘‡â€².

Ray normalization is an essential step in ray-space homography estimation. It must not be considered optional. In addition, this ray normalization can be applied to various linear estimation methods of light field imaging.

Ray-Space Infinity Homography Estimation After the computation of ğ»ğ» from rayâ€“ray correspondences, let us revisit the estimated RSIH ğ»ğ»^âˆ. As mentioned above, it has been linearly solved and decomposed up to a scale factor by Eq. (16). We first eliminate the scale factor based on conjugate condition. Specifically, a rotation matrix ğ‘…ğ‘… has eigenvalues (1,ğ‘’ğ‘–ğœƒ,ğ‘’âˆ’ğ‘–ğœƒ). ğœƒ refers to the angle of rotation about a rotation axis ğ‘£ğ‘£, which is satisfied by ğ‘…ğ‘…ğ‘£ğ‘£=ğ‘£ğ‘£ (Hartley and Zisserman 2003). The rotation can also be calculated from ğœƒ and ğ‘£ğ‘£. Given that ğ»ğ»âˆ is also a conjugate rotation (i.e., a similar matrix of rotation) according to Eq. (13), its eigenvalues are preserved under a conjugate relationship so the eigenvalues of ğ»ğ»^âˆ are also (1,ğ‘’ğ‘–ğœƒ,ğ‘’âˆ’ğ‘–ğœƒ,1,ğ‘’ğ‘–ğœƒ,ğ‘’âˆ’ğ‘–ğœƒ) up to a common scale. Subsequently, the scale factor is computed from the average of real eigenvalues of ğ»ğ»^âˆ. Overall, the accurate ğ»ğ»âˆ is solved without scale by the conjugate relationship, so does ğ»ğ». Note that, the complex eigenvalues also determine the angle ğœƒ through which the LFC rotates. It means the rotation can be directly solved with ğ»ğ»âˆ.

Special Imaging Conditions In this part, we begin the consideration of self-calibrating an LFC under special imaging conditions. The situation first considers here is the one in which the LFC rotates about its center but does not translate (ğ‘¡ğ‘¡=00), i.e. pure rotation. This situation occurs frequently. According to Eqs. (11) and (13), the ray-space homography ğ»ğ» is equivalent to RSIH ğ»ğ»âˆ, namely ğ»ğ»=ğ»ğ»âˆ. Consequently, we could directly estimate RSIH without scale based on Eq. (16) and conjugate rotation. In addition, pure rotation is a convenient motion to simplify the formulation of ray-space homography and further self-calibrate an LFC. In practice, when the LFC is not completely rotated about its center, the translation compared to the distance of scene points is small and then could be neglected. The constrained nature of the motion makes self-calibration of the LFC simpler. However, compared with complex infinity homography estimation for traditional self-calibration, the simplification for LFCâ€™s self-calibration algorithm is not significant. RSIH can be easily extracted from ray-space homography due to the special design of the LFC.

Secondly, a case of some practical importance is that of an LFC translating without rotation. Suppose the motion of an LFC is a pure translation, substituting ğ‘…ğ‘…=ğ¼ğ¼ into Eqs. (11) and (13), ğ»ğ» can be simplified as ray-space translation homography ğ»ğ»ğ‘¡ğ‘¡, that is ğ»ğ»=ğ»ğ»ğ‘¡ğ‘¡. However, according to Eq. (14), ğ»ğ»ğ‘¡ğ‘¡ does not affect the direction vectors of rays from the plane at infinity. It means that we can not use rayâ€“ray correspondences under pure translation to compute RSIH, which is all that is needed to further estimate RAC and self-calibrate an LFC. In practice, slightly rotating LFC to record light fields is necessary for self-calibration.

Closed-Form Initialization
It is easy to verify that Eq. (15) is not influenced by ğ‘˜ğ‘– and ğ‘˜ğ‘— according to Property 1. In general, the RAC ğœ”ğœ” is linearly solved in form of Kronecker product âŠ—. However, RAC ğœ”ğœ” is a symmetric matrix so that we revise Eq. (15) in the form of ğ´ğ´ğ‘ğ‘=00 for simplicity and robustness,

â¡â£â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â„211âˆ’1â„221â„11â„31â„21â„31â„231â„11â„21â„241âˆ’1â„242â„41â„43â„42â„43â„243â„41â„42â„212â„222âˆ’1â„12â„32â„22â„232â„12â„22â„251â„252âˆ’1â„51â„53â„52â„253â„51â„522â„11â„132â„21â„23â„11â„33+â„31â„13âˆ’1â„21â„33+â„31â„232â„31â„33â„11â„23+â„21â„132â„41â„612â„42â„62â„41â„63+â„43â„61âˆ’1â„42â„63+â„43â„622â„43â„63â„41â„62+â„42â„612â„12â„132â„22â„23â„12â„33+â„32â„13â„22â„33+â„32â„23âˆ’12â„32â„33â„12â„23+â„22â„132â„51â„612â„52â„62â„51â„63+â„53â„61â„52â„63+â„53â„62âˆ’12â„53â„63â„51â„62+â„52â„61â„213â„223â„13â„33â„23â„33â„233âˆ’1â„13â„23â„261â„262â„61â„63â„62â„63â„263âˆ’1â„61â„62â¤â¦â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¡â£â¢â¢â¢â¢â¢â¢ğ‘˜2ğ‘¢ğ‘˜2ğ‘£ğ‘˜ğ‘¢ğ‘¢0ğ‘˜ğ‘£ğ‘£01+ğ‘¢20+ğ‘£20â¤â¦â¥â¥â¥â¥â¥â¥=00,
(17)
where â„ğ‘–ğ‘— denotes the i-th row and j-th column element of ğ»ğ». ğ´ğ´ is a 12Ã—5 matrix whose rank is sufficient for solving ğ‘ğ‘ with an unknown scaling. It is interesting to note that a non-zero solution ğ‘ğ‘ can be obtained by at least one RSIH (estimated from a pair of light fields). Note that ğ‘ğ‘ includes 5 distinct non-zero elements of a symmetric matrix ğ¾ğ¾âŠ¤ğ‘¢ğ‘£ğ¾ğ¾ğ‘¢ğ‘£. ğ¾ğ¾^ğ‘¢ğ‘£ is linearly solved from ğ¾ğ¾âŠ¤ğ‘¢ğ‘£ğ¾ğ¾ğ‘¢ğ‘£ by Cholesky factorization (Hartley and Zisserman 2003).

As discussed in Sect. 3, ray-based RAC and RSIH could be regarded as the generalization of point-based IAC and infinity homography in the higher dimension. The traditional self-calibration algorithm is therefore the special case of the proposed algorithm when an LFC has only one view (i.e., traditional camera) according to Eq. (17). In the traditional self-calibration algorithm, 3Ã—3 infinity homography matrix is estimated from point-point correspondences and used to linearly calculate IAC and intrinsic parameters, as mentioned by Hartley and Zisserman (2003). It is common sense that traditional self-calibration is numerical instability, but the proposed self-calibration algorithm can provide a stable linear solution based on two reasons. Firstly, as discussed in Sect. 4.1, sufficient rayâ€“ray correspondences are used to stably and accurately compute ray-space homography. The more accurate ğ»ğ», the more stable RAC and intrinsic parameters can be obtained according to Eq. (17). Secondly, considering P denotes the number of RSIH, (12Ã—ğ‘ƒ)Ã—5 linear equations are solved to compute RAC, while the size of linear equations for traditional self-calibration is (6Ã—ğ‘ƒ)Ã—5. The higher dimension means that RAC estimation is a more stable solution compared with IAC estimation.

Based on the estimated intrinsic parameters ğ¾ğ¾^ğ‘¢ğ‘£ and ray-space homography ğ»ğ», rotation ğ‘…ğ‘… and translation ğ‘¡ğ‘¡ are further computed,

ğ‘…ğ‘…=12(ğ¾ğ¾^âˆ’âŠ¤ğ‘¢ğ‘£ğ»ğ»11ğ¾ğ¾^âŠ¤ğ‘¢ğ‘£+ğ¾ğ¾^ğ‘¢ğ‘£ğ»ğ»22ğ¾ğ¾^âˆ’1ğ‘¢ğ‘£),
(18)
[ğ‘¡ğ‘¡]Ã—=ğ¾ğ¾^ğ‘–ğ‘—ğ»ğ»12ğ¾ğ¾^âˆ’1ğ‘¢ğ‘£ğ‘…ğ‘…âŠ¤=ğœ†ğ¾ğ¾^âˆ’âŠ¤ğ‘¢ğ‘£ğ»ğ»12ğ¾ğ¾^âˆ’1ğ‘¢ğ‘£ğ‘…ğ‘…âŠ¤,
(19)
where ğ»ğ»ğ‘–ğ‘— indicates the i-th row and j-th column 3Ã—3 block matrix of ğ»ğ», as shown in Eq. (11). According to Property 1, ğœ†=ğ‘˜ğ‘–ğ‘˜ğ‘£. Considering ğ»ğ»âˆ and ğ¾ğ¾ğ‘¢ğ‘£ are accurate without scaling, each part of Eq. (18) is already an orthogonal rotation matrix with determinant unit. Therefore, there is no need to orthogonalize the estimated rotation. The rotation averaging in Eq. (18) can be computed according to the method proposed by Hartley et al. (2013).

Remarks
ğœ† is an empirical parameter without physical meaning that helps us to uniform the relative translation between each pair of light fields to global scaling. Since the traditional self-calibration method cannot recover a uniform scaling directly, the translation between the first and second cameras sets to a unit vector. However, due to special design of an LFC, the baseline (i.e., intrinsic parameters ğ‘˜ğ‘– and ğ‘˜ğ‘—) could be considered as the translation between neighboring sub-aperture images (Bok et al. 2017; Zhang et al. 2019c). More importantly, it keeps constant during the self-calibration of an LFC, so ğœ† is constant. Consequently, compared with the traditional self-calibration, the proposed LFC self-calibration is easy to estimate the translation up to a uniform scaling for 3D metric reconstruction. In addition, since the Euclidean distance of static scenes is not provided in advance, ğ‘˜ğ‘– and ğ‘˜ğ‘— as the translation between sub-aperture images cannot be recovered, as shown in Eq. (17). According to the observation about LFC calibration results, we conclude that ğ‘˜ğ‘¢ğ‘˜ğ‘–=ğ‘˜ğ‘£ğ‘˜ğ‘—=ğ‘Ÿğ‘š, where ğ‘Ÿğ‘š denotes the radius of the micro-lens in pixels. Consequently, we empirically set ğœ† to ğ‘˜ğ‘¢ğ‘˜ğ‘£ğ‘Ÿğ‘š.

Non-linear Optimization
The initial solution is then refined via non-linear optimization. Considering RSHC constrains the intrinsic and extrinsic parameters well, we minimize the geometrically more meaningful Sampson error based on RSHC and {îˆ¸ğ‘–}ğ‘›â†”{îˆ¸â€²ğ‘—}ğ‘š of N 3D points,

âˆ‘ğ‘âˆ‘ğ‘–ğ‘šâˆ‘ğ‘—ğ‘›âˆ£âˆ£(ğ‘ğ‘âŠ¤ğ‘–,ğ‘›ğ‘›âŠ¤ğ‘–)ğ»ğ»(ğ‘›ğ‘›â€²âŠ¤ğ‘—,ğ‘ğ‘â€²âŠ¤ğ‘—)âŠ¤âˆ£âˆ£â€–â€–ğ»ğ»âŠ¤(ğ‘ğ‘âŠ¤ğ‘–,ğ‘›ğ‘›âŠ¤ğ‘–)âŠ¤â€–â€–+â€–â€–ğ»ğ»(ğ‘›ğ‘›â€²âŠ¤ğ‘—,ğ‘ğ‘â€²âŠ¤ğ‘—)âŠ¤â€–â€–,
(20)
where â€–â‹…â€– denotes ğ¿2-norm, and ğ»ğ» is formulated by ğ¾ğ¾, ğ‘…ğ‘… and ğ‘¡ğ‘¡ according to Eq. (10). Compared with the re-projection error (Zhang et al. 2019c) or ray-projection error (Dansereau et al. 2013), Sampson error does not depend on the unstable reconstructed 3D points within a light field. Also, compared with algebraic distance RSHC, the Sampson distance is the first-order approximation of the rayâ€“ray geometric distance. According to the geometry definition of PlÃ¼cker coordinates, Eq. (20) which describes the rayâ€“ray Sampson distance in â„™3 is also geometrically equivalent to the point-point Sampson distance in â„™5. Moreover, the rayâ€“ray Sampson distance in Eq. (20) for light fields is also applied to outliers detection within a RANSAC framework (Fischler and Bolles 1981). We linearly estimated the ray-space homography matrix from random rayâ€“ray correspondences. The Sampson distances of all rayâ€“ray correspondences are then calculated, and the outliers are distinguished and discarded with a given threshold. The radial distortion caused by main lens is neglected in the proposed self-calibration method. Consequently, the non-linear optimization excludes the distortion coefficients.

Considering the assumption of constant intrinsic parameters during self-calibration, multiple light fields are recorded to improve the effectiveness and robustness of the proposed self-calibration method. In order to extend Eq. (20) to multiple light fields, we calculate rayâ€“ray Sampson distances from random pairs of light fields to select arbitrary light field in the pair with minimum distances as the reference light field. In practice, we capture ğ‘ƒ+1 light fields using a same LFC. For each pair of reference light field and p-th light field, 1â©½ğ‘â©½ğ‘ƒ, the RSIH is first estimated. With the increasing RSIHs, Eq. (17) is then stacked as 12Ã—ğ‘ƒ linear equations to obtain robust intrinsic parameters. The relative pose of p-th light field, consisting of ğ‘…ğ‘…ğ‘ and ğ‘¡ğ‘¡ğ‘, is subsequently estimated. For each pair of light fields, a non-linear cost function is established according to Eq. (20). Finally, P cost functions are accumulated together to optimize intrinsic and extrinsic parameters. To minimize the above non-linear functions, we parameterize rotation ğ‘…ğ‘… with its Rodrigues form (Faugeras 1993). Then we utilize Levenberg-Marquardt optimization solver ğ—…ğ—Œğ—Šğ—‡ğ—ˆğ—‡ğ—…ğ—‚ğ—‡ in Matlab.

Once the LFC intrinsic and extrinsic parameters are determined, the ray-space projection matrices can be rebuilt according to Eq. (7). Subsequently, the rayâ€“ray correspondences of a 3D point are transformed in a common camera coordinate frame via Eq. (10). For a certain 3D point observed by generalized rays, according to Eq. (3), it can be reconstructed,

([ğ‘ğ‘]Ã—ğ‘šğ‘š)[ğ‘‹ğ‘‹1]=0.
(21)
Although we have removed most mismatched rayâ€“ray correspondences, considering the small baseline of an LFC, the triangulation is adopted from all rayâ€“ray correspondences according to Eq. (21) within a RANSAC framework based on midpoint method (Hartley and Sturm 1997). Similarly, we employ the Levenberg-Marquardt algorithm to refine the triangulated 3D points via minimizing the re-projection error. The self-calibration and 3D metric reconstruction algorithm for an LFC is summarized in Alg. 1.

figure a
Experiments
In this section, we experimentally evaluate the proposed self-calibration algorithm on both synthetic LFCs and commercial LFCs. To evaluate the performance of the proposed method, similar to Li et al. (2008), direction errors of rotation and translation are defined when ground truth data is available,

ğ‘’ğ‘…ğ‘…=arccos(trace(ğ‘…ğ‘…âŠ¤ğ‘…ğ‘…ğºğ‘‡)âˆ’1)/2,
(22)
ğ‘’ğ‘¡ğ‘¡=arccos(ğ‘¡ğ‘¡âŠ¤ğ‘¡ğ‘¡ğºğ‘‡/(â€–ğ‘¡ğ‘¡â€–â€–ğ‘¡ğ‘¡ğºğ‘‡â€–)).
(23)
Simulated Data
In order to evaluate the performance of the proposed method, we simulate a realistic LFC, close to a Lytro Illum, with 11Ã—11 views, a baseline of 0.36mm, a focal length of 500, and the sub-aperture image resolution of 540Ã—360. The rotation angles between a couple of light fields are randomly generated from âˆ’30âˆ˜ to 30âˆ˜, while the translation ğ‘¡ğ‘¡ is randomly chosen in the cube [âˆ’0.1,0.1]3. Besides, the depth of 3D points is set to a range between 0.2m and 0.8m. We randomly generate rayâ€“ray correspondences from these 3D points based on camera parameters so that we obtain plausible input close to real-world scenarios.

Numerical Stability.

In this experiment, we evaluate the numerical stability of the proposed closed-form initialization. We generate random but feasible noise (0.1-1.0 pixels) simulated problem instances. Geometrically realistic rayâ€“ray correspondences between two light fields are involved in the linear solution. Figure 5 presents the distribution of the log10 relative errors of intrinsic parameters and the histogram of rotation and translation direction errors for 10, 000 instances. As shown in Fig. 5, three combinations of 3D points and rayâ€“ray correspondences of each 3D point are performed. We can see that the numerical stability and accuracy are obviously influenced by the number of rayâ€“ray correspondences (i.e. the number of 3D points multiple the number of rayâ€“ray correspondences of each 3D point). We use log10 to evaluate the relative error of intrinsic parameters. As shown in Fig. 5, the peaks of error distributions are increased with the number of rayâ€“ray correspondences. Moreover, as shown in Fig. 5, the more rayâ€“ray correspondences, the higher distribution of small direction errors. All results demonstrate the numerical stability of the proposed linear initialization. The mean errors of each parameter are also listed in Table 2. The relative errors of intrinsic parameters and direction errors of extrinsic parameters are decreased with the number of rayâ€“ray correspondences, which verifies the accuracy of the proposed linear initialization. Besides, Table 2 also shows the mean execution time of the linear initialization. According to Eqs. (16) and (17), the main time complexity is spent on the solution of ğ»ğ» from different rayâ€“ray correspondences. The execution time of the linear solution increases with the rayâ€“ray correspondences when the number of light field pairs is constant. In summary, these linear solutions show that the proposed linear algorithm does not suffer from numerical instability and is a good enough starting guess for the non-linear optimization Eq. (20).

Table 2 Mean relative errors of intrinsic parameters, mean direction errors of extrinsic parameters and mean execution time of linear initialization under different number of 3D points and rayâ€“ray correspondences of each 3D point
Full size table
Fig. 5
figure 5
Distribution of relative errors of intrinsic parameters and direction errors of rotation and translation for 10, 000 random simulated linear solution instances

Full size image
Noise Resilience. In this experiment, we generate one pair of light fields to examine the noise resilience on the proposed method. Depending on the experiment, different levels of white Gaussian noises varying from 0.1 to 1.0 pixels with a 0.1 pixels step are then added to the direction of projected rays. For each noise level, we carry out 150 trials, each of which includes three combinations of 3D points and rayâ€“ray correspondences, as shown in Fig. 6. Figure 6 summarizes the non-linear optimized results compared with ground truth, including mean relative errors of intrinsic parameters and mean direction errors of rotation and translation. It certifies that the errors increase almost linearly with the noise level. Compared with linear solutions, the mean errors of each parameter descend obviously, which verifies the effectiveness of non-linear optimization. Meanwhile, the errors reduce with the number of RSHCs (i.e. points Ã— rayâ€“ray correspondences). Specifically, for ğœ=0.5 pixels which is larger than normal noise in commercial LFCs, the relative error of (ğ‘˜ğ‘¢,ğ‘˜ğ‘£) and (ğ‘¢0,ğ‘£0) and direction errors of ğ‘…ğ‘… and ğ‘¡ğ‘¡ are less than 0.45%, 0.8%, 0.15âˆ˜ and 1.5âˆ˜ respectively. It also verifies that the proposed non-linear optimization remains robust at high noise.

Fig. 6
figure 6
Performance evaluation of intrinsic and extrinsic parameters on the simulated data with different levels of noise ğœ

Full size image
Number of Constraints In this experiment, we investigate the influence of the number of constraints on the accuracy of the proposed method. To this end, we vary the number of light field pairs from 1 to 7. Similarly, three combinations of the number of 3D points and the rayâ€“ray correspondences from each point are involved. We execute 100 independent trials, each of which added with 0.5 pixels Gaussian noise. The mean relative errors of intrinsic parameters and mean direction errors of rotation and translation with increasing light field pairs are shown in Fig. 7. We can see that the errors of intrinsic parameters decrease significantly, while the direction errors are roughly constant. The reason why the performance of intrinsic parameters is better is related to increasing equations result stable linear solutions according to Eq. (17) and hence convergence into better minima. While the better intrinsic parameters lead to the small improvement of rotation and translation as shown in Fig. 7. With the increasing constraints, the proposed method presents better solutions. When the number of light field pairs is more than 4, the errors are descending slower. In summary, all results demonstrate the effectiveness of the proposed method with increasing constraints.

Fig. 7
figure 7
Performance evaluation of intrinsic and extrinsic parameters on the simulated data with different number of light field pairs

Full size image
Real Scene
To further substantiate the proposed self-calibration algorithm that experiments on real scene light fields are performed. Using a Lytro Illum, two real scene light field datasets, named as â€œBoard-1â€ and â€œBoard-2â€, are collected from different scenes with checkerboard shown in Fig. 9a. Given that the proposed algorithm is the first attempt to self-calibrate an LFC, the checkerboard can help to quantitatively compare the effectiveness of the proposed method on intrinsic and extrinsic estimation with the state-of-the-art LFC calibration method (Zhang et al. 2019c). Considering the checkerboard may cause concerns on self-calibration, another six datasets â€œToy-1â€, â€œToy-2â€, â€œToy-3â€, â€œTeemo-1â€, â€œTeemo-2â€ and â€œDeskâ€ are also captured to demonstrate the estimated results (both camera parameters and reconstructed 3D structures), as shown in Fig. 10a.

The number of light fields on each dataset is listed in the second column of Table 3. Taken the small baseline of an LFC into consideration, the depth of real scenes from an LFC ranges from 0.3m to 0.8m. In order to demonstrate the performance of the proposed algorithm, LFC configurations, such as focal length and zoom factor, are different between different datasets. Note that, the LFC configurations are constant in a dataset to facilitate self-calibration.

Table 3 Inliers proportion (unit: %) on the collected datasets
Full size table
Pre-processing
The pre-processing before LFC self-calibration includes the raw light field decoding, extraction of rayâ€“ray correspondence and inliers detection.

The raw micro-lens image recorded by an LFC can be decoded using an open-source toolbox (Dansereau et al. 2013) or Lytro Power Tool (Lytro 2011). However, compared with the open-source toolbox, Lytro Power Tool also applies rectification, reducing the appearance of lens distortion. As mentioned in Sect. 4, the main lens distortion has been neglected in the proposed method. Consequently, we utilize Lytro Power Tool to decode raw data to rectified light field. The raw data is first de-bayered and pixel-aligned to an orthogonal grid of sub-images. It is easy to load and interpret as a 2D array of 2D sub-images. There are 14Ã—14 pixels per sub-image and about 541Ã—376 sub-images. In addition to de-bayering and aligning, the Lytro Power Tool also applies rectification to reduce the appearance of lens distortion. Considering that marginal sub-aperture images suffer from severe vignetting and aberrations, the middle 11Ã—11 sub-aperture images are used.

To self-calibrate an LFC, sets of rays which correspond to the same 3D point among light fields are first extracted. The sub-images of raw data and sub-aperture images of view points are different visualizations of light field recorded by an LFC and easy to be generated to describe the rays, as shown in Ng (2006). However, it is difficult to extract accurate rays in small sub-images. Therefore, similar to methods in Johannsen et al. (2016) and Nousias et al. (2019), we extract sparse features from every sub-aperture image in a light field via Difference of Gaussians (DoG). Different from the feature extraction for traditional images, light field is equivalent to a collection of sub-aperture image. The feature (u, v) extracted on a sub-aperture image of view (i, j) refers to a ray (i, j, u, v). The features of the central sub-aperture image are subsequently matched with those of other sub-aperture images via SIFT (Lowe 2004). Given that the view points of an LFC are regularly arranged on a plane, we filter the rays according to the invariant depth and generate sets of rays in a light field. After extracting the sets of rays in light fields, the rayâ€“ray correspondences are then matched between different light fields via SIFT. For efficiency, only the features of the central sub-aperture images are matched to associate sets of rays between light fields.

As mentioned in Sect. 4, the Sampson distance of RSHC can be used to discard the outliers based on a RANSAC framework. The proportions of inlier rayâ€“ray correspondences are summarized in Table 3. The proposed RANSAC framework with Sampson distance produces the reliable rayâ€“ray correspondences for self-calibration. Fig. 8 also partially illustrates the result of inliers detection on datasets â€œToy-2â€. Fig. 8 randomly marks 40 rayâ€“ray correspondences on arbitrary sub-aperture images of a pair of light fields. It can be seen that the rays within a light field preserve the depth invariant (i.e. same disparity), and the rayâ€“ray correspondences between light fields lie in the similar pixel of sub-aperture images without outliers. Table 3 and Fig. 8 quantitatively and qualitatively verify the performance of the proposed RSHC and its Sampson distance on inliers detection, respectively. In order to intuitively express rayâ€“ray correspondences emanating from the same 3D scene point, we also randomly draw 5 sets of rays with 3D reconstruction in line form. As shown in Fig. 8, all rays corresponding to a 3D scene point in both light fields are utilized for 3D reconstruction. Moreover, datasets â€œBoard-1â€ and â€œBoard-2â€ combined with a checkerboard may cause concerns about the rayâ€“ray correspondences. It provides sufficient rayâ€“ray correspondences however introduces more outliers on the checkerboard due to the similar local structures. It is also demonstrated in Table 3, from which we can see the proportions of inliers on datasets â€œBoard-1â€ and â€œBoard-2â€ are less than those on datasets â€œToy-1â€, â€œToy-2â€ and â€œToy-3â€ with similar scenes.

Fig. 8
figure 8
Inliers detection on â€œToy-2â€ based on ray-space homography estimation and its Sampson distance. 40 random inliers are marked on arbitrary sub-aperture images with colors, wherein 5 sets of rayâ€“ray correspondences connected to the corresponding 3D reconstructed points are drawn in dashed line form

Full size image
Self-Calibration
The checkerboards on datasets â€œBoard-1â€ and â€œBoard-2â€ make it possible to compare the proposed self-calibration meth-od with state-of-the-art calibration method represented by MPC (Zhang et al. 2019c), treating the latter as the gold standard. Note that, compared with the isometric parameters obtained by MPC, the proposed LFC self-calibration algorithm estimates metric parameters due to static scenes without a known physical size. Neither accurate rayâ€“ray correspondences of corners nor Euclidean distance could be provided by the checkerboard for self-calibration. Consequently, baselines ğ‘˜ğ‘– and ğ‘˜ğ‘— which decide the magnitude of reconstruction are not compared. In addition to MPC, baseline methods proposed by Dansereau et al. (2013) and Bok et al. (2017) are other common LFC calibration methods using checkerboard. The reasons why the proposed method is not compared with other baseline methods have three. Firstly, the MPC outperforms compared with other baseline methods, as demonstrated by Zhang et al. (2019c). Secondly, the 12-free-parameter model provided by Dansereau et al. (2013) has redundancy and dependency. Intrinsic parameters estimated by Dansereau et al. (2013) can not be compared with the results of the proposed self-calibration. Thirdly, the baseline method proposed by Bok et al. (2017) uses line features on sub-images to calibrate an LFC. Although it can provide similar 6 intrinsic parameters compared with the proposed method, the checkerboard should be captured under an unfocused status to make the line feature detectable.

Table 4 presents the differences of intrinsic parameters and relative poses, measured with relative errors (%) and direction errors (deg), respectively. Overall, the errors in Table 4 are closed to the gold standard except the direction error of translation. As shown in Eq. (18), the translation is decomposed from the estimated essential matrix, which includes the rotation. It results in that the estimated rotation is more accurate than translation, which is also demonstrated in simulated data. Besides, taken the noise of rayâ€“ray correspondences into consideration, the results are acceptable. Moreover, the relative comparisons in Table 4 also demonstrate the performance of RSHCs to constrain the intrinsic and extrinsic parameters. In addition, Table 5 illustrates intrinsic parameters estimated by the proposed method and MPC calibration method on datasets â€œBoard-1â€ and â€œBoard-2â€.

Table 4 Differences of intrinsic and extrinsic parameters obtained by the proposed self-calibration method compared with state-of-the-art calibration (Zhang et al. 2019c) on datasets with a checkerboard
Full size table
Table 5 The comparison of intrinsic parameters of the proposed self-calibration with that of state-of-the-art calibration
Full size table
Fig. 9
figure 9
The central sub-aperture image of the reference light field. The comparison of pose estimation of the proposed self-calibration (colored solid lines) with that of state-of-the-art MPC calibration (colored dotted lines) (Color figure online)

Full size image
As mentioned in Zhang et al. (2019c), (âˆ’ğ‘˜ğ‘–ğ‘–, âˆ’ğ‘˜ğ‘—ğ‘—,0)âŠ¤ also indicates the translation between sub-aperture images within a light field which remains constant during self-calibration. For this reason, it is easy to constrain the translation between light fields up to a uniform scaling according to Eq. (19). In order to qualitatively visualize the differences of relative poses on datasets â€œBoard-1â€ and â€œBoard-2â€, we respectively illustrate the poses calculated by the proposed self-calibration and MPC calibration, as shown in Fig. 9b. Since the proposed method is metrically estimated, the translation vectors of MPC are scaled so that the translation vectors of two methods have the same norm. Clearly, the poses of the proposed self-calibration method and MPC are very similar. Although the direction errors of translation are larger than that of rotation in Table 4, we can see in Fig. 9b that the direction errors of translation have a smaller effect on pose visualization and 3D reconstruction compared with rotation.

Table 6 Average rayâ€“ray correspondences of each light field pair and mean Sampson errors (unit: 10âˆ’3) for the estimation of LFC parameters on the collected datasets
Full size table
Table 7 Intrinsic parameters estimated by the proposed method
Full size table
3D Reconstruction
The checkerboard on previous datasets is convenient to compare the proposed method with calibration method, but it may cause concern that corners on the checkerboard may provide sufficient and accurate rayâ€“ray correspondences for self-calibration. Consequently, we further validate the self-calibration on the datasets without any specific calibration targets to reconstruct 3D scenes. Considering that there is little self-calibration method designed for an LFC, we first use the Sampson errors of RSHCs to evaluate the effectiveness of the proposed self-calibration. Table 6 summarizes average rayâ€“ray correspondences of each pair of light fields and the mean Sampson errors on the collected datasets. The Sampson distance is a close approximation to the geometric distance between the ray and its corresponding ray after the transformation established by LFC parameters. Compared with the algebraic error, it is reasonable to utilize Sampson error with geometric meaning to represent the distance of rayâ€“ray correspondences for optimization. As shown in Table 6, the ultra-small Sampson errors on collected datasets can verify the effectiveness of the proposed method for the estimation of LFC parameters. Specifically, we can see that the Sampson errors of each datasets have fluctuations with the number of rayâ€“ray correspondences. In addition, Table 7 illustrates the results of intrinsic parameters estimation, where ğ‘˜ğ‘– and ğ‘˜ğ‘— are also listed. As discussed in Sect. 4.2, since the Euclidean distance of static scenes is not provided in advance, ğ‘˜ğ‘– and ğ‘˜ğ‘— as the translation between sub-aperture images cannot be estimated but help to constrain the relative translation between each pair of light fields up to a uniform scaling, so the LFC self-calibration recovers metric structure. Here, we empirically set the uniform scale to ğ‘˜ğ‘¢ğ‘˜ğ‘–=ğ‘˜ğ‘£ğ‘˜ğ‘—=5, which is the radius of view points.

Fig. 10
figure 10
The central sub-aperture image of the reference light field, 3D metric reconstruction and LFC pose comparison on collected datasets. The proposed LFC self-calibration (colored solid lines) is compared with stratified self-calibration (colored dotted lines) (Color figure online)

Full size image
In order to further quantify the performance of intrinsic and extrinsic parameters estimation, we compared the output of the proposed self-calibration algorithm with the traditional stratified self-calibration method provided by Pollefeys and Van Gool (1999). Considering an LFC can be considered as a collection of traditional cameras, the stratified self-calibration treats each sub-aperture image independently, not accounting for the special design of the LFC. We note that a medium collected dataset of 10 light fields contains 1210 images, which is too large for traditional self-calibration. Consequently, we only use 3Ã—3 sub-aperture images regularly arranged in the light field to perform stratified self-calibration. Table 8 summarizes the differences of intrinsic and extrinsic parameters, measured with relative errors (%) and direction errors (deg) respectively. Since the stratified self-calibration cannot recover a uniform scaling of translations directly, we scale the translation between center sub-aperture images of first and second light fields to the same norm with that of the LFC self-calibration method. To fair comparison with the stratified self-calibration, we perform the LFC self-calibration from the light fields with the same view sampling in the experiments of Table 8. Besides, Fig. 10c qualitatively presents the LFC pose comparison between the LFC self-calibration and the stratified self-calibration. All results demonstrate the performance of the proposed self-calibration method.

Table 8 Differences of intrinsic and extrinsic parameters obtained by the proposed self-calibration method compared with the stratified self-calibration (Pollefeys et al. 1999) on the collected datasets
Full size table
Table 9 3D reconstructed points and mean re-projection errors (unit: pixels) of the reconstructed structures on the collected datasets
Full size table
Once the LFC intrinsic and extrinsic parameters are obtained, the 3D metric reconstruction can be computed. Figure 10 qualitatively exhibits 3D reconstruction results and the estimated poses on the collected datasets. The median point of the reconstructed scene is set as the origin of the coordinate frame. The rotation and translation of the reference light field are set to the identity matrix and zero vector, respectively. Even if the physical magnitude of the scene is unknown, the relative poses and 3D scene reconstruction are still estimated with a common scaling. In addition, Table 9 summaries the number of 3D reconstructed points and the mean re-projection errors according to the reconstructed points. We can see that the re-projection errors is deduced with the increasing 3D points. Specifically, according to Table 6, the background on datasets â€œToy-1â€ and â€œTeemo-1â€ could provide more rayâ€“ray correspondences to reconstruct 3D points. More 3D points for optimization will help to reduce the re-projection errors. The light fields of large-scale scenes on dataset â€œDeskâ€ also extract sufficient rayâ€“ray correspondences to increase accuracy of reconstruction, as shown in Tables 6 and 9. Moreover, we can also see from Fig. 10a that the central sub-aperture image on dataset â€œToy-3â€ has more noise than the other two datasets â€œToy-1â€ and â€œToy-2â€ with similar scenes. It is another reason why the re-projection error on dataset â€œToy-3â€ is larger than datasets â€œToy-1â€ and â€œToy-2â€. In summary, all results have verified the effectiveness of the proposed self-calibration algorithm.

Limitations
In this part, we analyze the limitations of the proposed self-calibration algorithm to better understand the utility in practice. The main limitation of our algorithm is that the depth range of the scenes is limited due to the ultra-small baseline of the LFC. The disparity (pixel difference between neighboring sub-aperture images) which is defined by the depth of the scene point is also limited. Suppose the scene points lie at distance larger than 3m from an LFC so that their disparities are less than 0.1 pixels. This may cause inaccurate detection of rays in a light field, which is a common failure mode in methods that use rayâ€“ray correspondences of light fields to estimate LFC pose. Therefore, when we reconstruct 3D scenes or estimate relative pose using an LFC in practice, the scene should not be too far from the LFC.

As discussed in Sect. 4.1, if there is no rotation between two light fields then the ray-space infinity homography cannot be estimated. This can be seen from Eq. (13), in the case of pure translation, the ray-space homography decomposes the ray-space translation homography and ignores the ray-space infinity homography. Consequently, when we capture light fields for self-calibration in practice, it is necessary to have the rotation between two light fields.

Closing Remarks
Light field cameras have gained increasing popularity and have been applied to a wide range of computer vision tasks, including 3D reconstruction from multiple views. Although using one single light field from an LFC, one is already able to compute a disparity map (despite suffering from very narrow baselines), recent researches have shown that taking multiple light fields significantly improves the 3D reconstruction accuracy. For multi-view LFCs, an easy-to-use and accurate self-calibration algorithm specifically designed for an LFC will be proven handy in practice. We have proposed in this paper a novel, compact, accurate and stable LFC self-calibration method, which is to the best of our knowledge the first of the kind in the literature. More importantly, while it is a commonly held opinion that self-calibration algorithm is usually fragile numerically no matter how elegant the theory is, in this paper we have demonstrated that this is not the case for the light-field camera, because of the rich redundancies and regularities presented in the ray-space of LFCs. For the future work, we will explore the correction of lens distortion induced by the main lens, whose effect has been neglected in the present work.