In this paper, we deal with the issue of implicit monitoring of perceptual responses to product design through electroencephalography (EEG) and eye tracking. Four evaluation factors, namely, preference, luxury, complexity, and harmony are considered to investigate how people perceive the car design. In particular, the quantified perceptual responses are predicted based on EEG and gaze data. Average root-mean-square errors of 0.210 and 1.215 are obtained from subject-dependent and subject-independent regressions on a 7-point score scale, respectively, which demonstrates that perception of car design can be predicted via implicit monitoring.
SECTION 1Introduction
In general, the user experience of products includes the experiences of usability and emotion [1]. The experience of usability is related to the functional capability of products such as the effectiveness, productivity, understandability, and operability, which is the primary demand for products [2]. Therefore, the experience of usability has been actively studied [3], [4]. On the contrary, the affective user experience for the product design such as preference and aesthetics is less explored, although the affective responses of users are also regarded as an important component of the user experience with products [1], [5], [6].

In fact, the design of a product has great influence on its success. The product design is a way to attract the user attention, to assign aesthetic characteristics to the product, and to provide sensory pleasure for users [7]. Therefore, a good design can induce a favorable attitude toward the product and a willingness to pay a higher price for the product [8].

Methods to evaluate the user experience including product design can be categorized into two approaches depending on the channel for obtaining user responses, namely, an explicit and an implicit approaches. In the explicit approach, users are asked to verbally describe their experience with the product and sometimes requested to assign numerical scores via questionnaire and interview. This is a straightforward way to obtain the user response and traditionally has been employed in various studies investigating human perception.

For example, the harmony, typicality, and pleasantness of DVD player designs were investigated by using a 7-point Likert scale in [9]. It was revealed that the typicality significantly influences on the users’ view on the harmony. The products having the moderate level of harmony were felt pleasantly when the product design was typical. However, if the product design was atypical, the subjects perceived the products with the highest harmony as pleasant than those with the moderate harmony. In [6], the influence of social, altruistic, functional, emotional, and economic values of car designs on the brand affection was investigated via questionnaires with a 10-point Likert scale. It was revealed that the emotional aspects of the designs significantly changed the perception of the brand compared to the other aspects.

In contrast, the implicit approach does not ask users about their experience but passively observes physiological or behavioral cues, which are expected to contain the users’ natural response to a given stimulus. Implicit responses include not only visually observable ones such as facial expression, gaze, and gesture, but also physiological signals such as neural activity, galvanic skin response (GSR), respiration, heart rate, and skin temperature.

Recently, the implicit approach has received a considerable amount of attention with the noticeable popularity of mobile and wearable devices equipped with various sensors. For example, mobile phones have been used for emotion recognition [10], facial expression recognition [11], affective speech recognition [12], and so on. Wearable devices such as smart watches [13] and smart glasses [14] also enable to obtain implicit measures of the user response without any interruption of users’ current states. As a result, the implicit approach appears feasible in various applications, including personalized multimedia content delivery and recommendation, user monitoring in virtual reality, and implicit control for disabled users, as well as product design evaluation [15].

The implicit approach has several advantages over the explicit approach. First, the implicit method enables real-time monitoring of the user experience, whereas the explicit evaluation is typically implemented after the presentation of a stimulus. Second, the explicit approach may be prone to the bias arising while users recall, conceptualize, and verbalize their experience, but the implicit approach is relatively free from such bias. Third, the implicit method can minimize the influence of the experimenters. For example, in the explicit approach, the ability (i.e., interviewing skill and knowledge) and reactivity of an experimenter can be sources of errors [16]. The implicit approach does not suffer from such influence. In [17], the benefit of the implicit approach was demonstrated. While it was possible to predict the market success of beverages by using the explicit questionnaires alone, the prediction performance was significantly improved by additionally integrating the implicit measure (i.e., facial expression).

The user experience of aesthetic designs of products has been investigated through neural activities, which are expected to provide the extensive information of the user experience. In [18], products with aesthetic designs were compared with standard products based on event-related brain responses. Pictures of electronic products such as computers, digital cameras, and mobile phones were presented in company with scripts describing their performance one by one, and subjects were asked to make a purchase decision. It was revealed that users tended to buy products with aesthetic designs even when the products were functionally inferior, and neural activities at 200-300 ms after the presentation of products were related to the perception of product designs. The relationship between purchase decisions and neural activities was also investigated via functional magnetic resonance imaging (fMRI) in [19] and [20]. In [19], it was observed that the aesthetic package designs triggered the activation of the reward system in the brain, and the subjects tended to buy the products despite of higher prices than standard products. In [20], the purchase decisions were predicted based on neural activities in the brain regions that are significantly activated during the decision making process of purchase by using a support vector machine (SVM). As a result, a prediction accuracy of 71 percent was achieved, and it was revealed that the neural activities in medial and superior frontal cortices were useful for the prediction.

Eye tracking signals also have been measured to implicitly capture the user experience. In [21], an eye tracking study was conducted for mobile phones. It was revealed that more positive appearance and apparent usability were related to larger numbers of fixation and longer durations of fixations. The relationship between eye tracking signals and the aesthetic aspect of product designs was explored in [22]. The beauty of product designs was measured by using the number of fixations and the duration of fixations. Moreover, the level of pleasure induced by the design of openers was evaluated in [23] by using the pupil size, which is a measure of users’ interests and affective perceptions. As a result, the significant relationship between pupil sizes and affective feelings of product designs was found. Interestingly, while the pupil became larger in the transition from neutral feelings to negative feelings with conventional affective images, the affective experience of product designs induced the opposite change.

Cars are a particular example where their design significantly influences their sales and success [24], [25]. Only a few studies conducted the implicit analysis of human responses for car design. In [26], the user responses to the red or blue colored car were studied by using electroencephalography (EEG) signals. The red car induced higher peaks than the blue car, which indicated a more excited and nervous user experience. However, this study considered only a specific aspect of the car design, i.e., color. The overall preference of car design was evaluated using EEG signals in [27]. It was revealed that the alpha peak frequency, the frequency within the alpha band (8-12 Hz) at which the highest amplitude is observed, was significantly related to the preference. However, the preference prediction was implemented in a pair-wise comparison scheme, which means that the prediction system identifies only the superiority in liking between a pair of stimuli. In [28], the aesthetic pleasure and complexity of front views of cars were investigated using eye tracking signals. The average fixation durations and the number of fixations were positively correlated with the aesthetic pleasure and the complexity, respectively. However, this study also considered limited aspects of the car design.

Most of the studies that investigated the user experience of product design, including the aforementioned studies [6], [9], [19], [20], [21], [22], [23], [26], [27], [28], used photos instead of real products. This is mainly because of practical limitations, i.e., using real products requires more significant effort, cost, and even space in comparison to photos. If we use photos instead of real products, it becomes easier to modify shapes or colors and add or remove certain design elements. Furthermore, using real products complicates the setting of experimental environments and procedures because the real products are space-consuming compared to the photos, in particular, for cars.

Despite the benefits of experiments with photos, however, it needs to be verified whether the user responses to photos are the same to those to real products. As our ultimate goal is to understand the user experience of real products, studies with photos can provide us correct understanding only when real products and photos are similar in the viewpoint of design perception. Particularly, the implicit measure of the user experience is often more sensitive to a small amount of changes such as the dimensionality of the given stimulus [29], [30]. Therefore, it should be verified whether there is a significant difference between the implicit user experience with photos and real products.

In this paper, we investigate the perceptual responses to the car design using real cars in a comprehensive manner through the questionnaire, EEG, and eye tracking. Distinguished contributions of our work can be summarized as follows:

We compare the affective user experience of real products and photos, and verify the perceptual difference between them, which has not been adequately investigated previously except for our preliminary results presented in [31]. We examine the EEG and gaze patterns of viewers for the two cases and demonstrate the necessity of using real products for proper analysis of the user experience. Based on that, we use real products in our work, which is the first attempt for implicit product design evaluation to our best knowledge.

We analyze the affective user experience of the car design based on the questionnaire results in various design aspects, namely, preference, luxury, complexity, and harmony, and examine how they are related with each other. In particular, we include luxury as an important design aspect of cars; although the influence of luxury on the consumption behavior has been investigated for clothing [32] or in general [33], [34], the physiological responses to the luxury of product designs have been rarely investigated.

We demonstrate the effectiveness of EEG and gaze signals as measures of the affective user experience by showing the feasibility of the user experience prediction based on these signals. We build prediction systems by using EEG or gaze data and also via fusion of the two modalities. Furthermore, we evaluate the prediction performance for both subject-dependent and subject-independent schemes. These allow a thorough investigation of the physiological measures of affective user experience of product designs.

The remainder of this paper is organized as follows. In Section 2, we compare the perceptual experience for the photo and real car based on EEG and gaze patterns. Section 3 explains the four design factors considered in our work. Section 4 describes details of the experiment to obtain data of user responses. We present the results of in-depth analysis of the questionnaire in Section 5. Results of prediction of the user experience are described in Section 6.3. We conclude this study and present future works in Section 7.

SECTION 2Comparison of Real Product and Photo
2.1 Experimental Procedure
An experiment was conducted to verify the existence of perceptual difference in the affective user experience between a real product and its photo. The experiment consists of two sessions: one with the real car and the other with the photo. A front view, which is representative of the car design, of a black colored car was employed. In both sessions, no particular instruction, e.g., to rate the quality of the car design, was given to the subjects, so that the recorded EEG and gaze signals reflect natural responses of the subjects.

Twelve subjects, ten males and two females, participated in the first session. After the EEG recording device and eye tracking system were equipped and calibrated, a subject was instructed to stand in front of the car and move as little as possible to prevent movement artifacts in EEG and gaze signals. The subject closed the eyes to capture baseline signals for five seconds, then opened the eyes and watched the car for 20 seconds.

In the second session, four subjects (three males and one female) participated. An 84-inch LCD monitor having a full HD resolution was used for displaying the photo captured in a full HD resolution. The photo was compressed by JPEG to avoid the time delay of image presentation but carefully examined to verify that there is no noticeable noise due to the compression. Each subject was instructed to sit on a chair located in front of the monitor and do not move as much as possible. After the EEG device and eye tracking system were set and calibrated, a gray screen was shown for five seconds to capture the baseline signals, then a photo of the front view of the car was shown for 20 seconds.

All subjects self-reported normal or corrected-to-normal vision. No subject had owned the car used in the experiment, but they all had driving experience.

2.2 Equipment
We used Emotiv Epoc+ and Dikablis Eye Tracking Glasses for the recording of EEG and gaze signals, respectively. The Emotive Epoc+ has 14 electrodes and recorded the signals at a sampling rate of 128 Hz. The positions of the electrodes follow the international 10-20 system. The Dikablis Eye Tracking Glasses is a glass-type device having a sampling rate of 60 Hz.

2.3 Processing of EEG and Gaze Signals
The recorded EEG signals are processed as follows. First, one-second-long signals are removed both at the beginning and end of the entire signal to preserve only stable signals [35]. Then, the obtained EEG signals are divided into three-second-long segments without overlapping, which is determined based on previous studies [22], [36], [37], [38], [39]. Next, bandpass filtering is conducted with the segmented EEG signals to eliminate too high or too low-frequency noises and keep only frequency components within 2-64 Hz. And, eye blinking and movement artifacts are removed by using independent component analysis (ICA) [40]. Then, a common average reference method is employed to normalize the EEG signals, i.e., the average over all electrodes is subtracted from the EEG signals. Finally, the power spectral density (PSD), which represents the neural activation level, is calculated for each electrode. The PSD is averaged across each of the theta (3-7 Hz), alpha (8-13 Hz), beta (14-29 Hz), and gamma (30-47 Hz) frequency bands, and subtracted by the PSD of the corresponding baseline signal.

To process the eye tracking data, the effect of head movements is corrected first. Then, the gaze points are classified into fixations and saccades by using the EyeMMV toolbox [41]. Finally, the total number of fixations, total duration of fixations, standard deviation of fixation durations, and total length of scanpath are calculated from the fixation points. The total length of scanpath is normalized with the width of the car in the viewing scene.

2.4 EEG Results
2.4.1 Activation Pattern Analysis
Entire patterns of the neural activities are investigated via topographies and similarity measures of the PSD values. The former provides a qualitative overview of the spatial similarity of neural activations induced by the real car and photo. The latter is a quantitative indicator of the overall similarity.

The PSD values are visualized for each frequency band in Fig. 1. The figure shows that there is a noticeable amount of agreement between neural activation patterns induced by the real car and photo in the beta frequency band. That is, the negative activation of the occipital area is consistent between the two cases throughout the entire duration. The steady negative activation of the occipital lobe is also observed in the gamma frequency band for both of the real car and photo, but activations of the frontal and parietal lobes are shown in the same frequency only for the photo. Only partial similarity is observed in the alpha and theta frequency bands, for example, the occipital lobe of the alpha frequency band in segments 1 to 2 and the frontal lobe of the theta frequency band in segment 3.


Fig. 1.
EEG topographies of PSDs. The position of electrodes is represented as dots. The level of neural activation is described by colors, i.e., the red or blue color indicates the most positively or negatively activated EEG signal, respectively.

Show All

Table 1 summarizes the Spearman's rank correlation coefficient (SROCC) and the sign similarity (SS) values between the EEG signals obtained for the real product and photo. The SROCC allows measuring the similarity of the PSD values obtained for the real product and photo by comparing the relative strength of neural activities. The SS examines whether brain regions consistently show the negative or positive activations across the real car-based and photo-based sessions, which is defined as follows:
SS(x,y)=1n∑i=1nsign(xi)×sign(yi),(1)
View Sourcewhere n is the number of EEG electrodes and sign outputs 1 if the given value is larger than zero and −1 otherwise.

TABLE 1 Spearman's Rank Correlation Coefficients (SROCCs) and Sign Similarities (SSs) Between Neural Activation Levels Obtained from the Real Car-Based and Photo-Based Sessions

A tendency similar to that observed in Fig. 1 is found in Table 1. Most of the high SROCCs are obtained from the beta frequency band, and the signs of the PSD values of the beta frequency band perfectly agree. Temporal changes of neural activities also can be found in Table 1. The SROCC and SS values are relatively low in the last segment, not only for the beta frequency band but also for the other frequency bands compared to the first and second segments. This probably indicates that whereas the user responses at the early stage of the viewing are mainly induced by the visual information that is almost identical for the real car and photo, the neural activities in the last stage reflect the perceptual difference of the real car and photo.

2.4.2 Individual Electrode Analysis
The activation patterns for the real car and photo are compared in terms of the most activated electrodes in Table 2. The positions of the electrodes are visualized in Fig. 2. While there are some cases showing agreement between the two sessions, significant differences are also observed in the table. In particular, we can observe the electrodes that are left-right inversed in the two sessions (underlined). In the analysis based on Fig. 1, negative activations in the occipital area were similar in the two sessions. However, the analysis of individual electrodes reveals that these activations appear in a left-right inversed manner.


Fig. 2.
Positions of the EEG electrodes. F means frontal; AF means anterior-frontal; C means central; and O means occipital. An odd or even number indicates the left or right side of the brain, respectively.

Show All

TABLE 2 Most Activated EEG Electrodes

2.5 Eye Tracking Results
Fig. 3 compares the eye tracking features of the two sessions. Although the statistical significance is not found between the real car and the photo by nonparametric Mann-Whitney tests except for the total duration of fixations (U=4, effect size r=0.358, p<0.05), the real car results in less numbers of fixations, longer durations of fixations, and larger variations in fixation durations than the photo, which means that the subjects spent the limited viewing time (20 seconds) for fewer regions in the real car session. Furthermore, the length of scanpath is shorter in the case of the real car. That is, the regions that attract the users’ attention are prominent for the real car, whereas the gaze wanders in the case of the photo.

Fig. 3. - 
Comparison of the eye tracking features averaged across subjects. Error bars show the standard deviation values, and an asterisk indicates statistical significance of the difference ($p<0.05$p<0.05).
Fig. 3.
Comparison of the eye tracking features averaged across subjects. Error bars show the standard deviation values, and an asterisk indicates statistical significance of the difference (p<0.05).

Show All

Fig. 4 shows an example of the eye tracking data of the two sessions. It can be noticed that the subject concentrated on fewer locations in the real car session than the photo session. Moreover, the fixation points for the real car are more clustered. The subject's gaze stays mainly at three locations: upper left corner, center, and upper right corner of the car, which roughly correspond to headlamps, grille, and side view mirrors, respectively.


Fig. 4.
Example gaze patterns observed in the real car (upper panel) and photo (lower panel) sessions. A circle indicates a fixation, and its radius and color represent the duration of the fixation (a cyan corresponds to the shortest duration and a red indicates the longest duration).

Show All

2.6 Discussion
The EEG-based results demonstrate that the perceptual responses to the photo and real car are considerably different. The beta and gamma frequency bands of the EEG signals obtained in the two cases are highly correlated, but the other frequency bands have low SROCC and SS values. Moreover, it is revealed that the most negatively or positively activated electrodes in the two cases often appear left-right inversely. As the two hemispheres of the brain have different functions, the left-right asymmetry of neural activations has been investigated not only for medical usages but also for analysis of perceptual responses such as cognitive processes [42], [43] and behavior [44].

Particularly, the left-right inversion of the most negatively or positively activated electrodes is mainly observed in the alpha and beta frequency bands. In general, the EEG asymmetry of the alpha frequency band is highly related to affective processes [45], [46]. For example, it was revealed that the EEG asymmetry of the alpha frequency band is significantly related to the feeling of pleasure during e-learning [47] and the interestingness of news [48]. Therefore, the left-right inversion of the alpha frequency band probably implies the difference between the affective user experiences of the photo and real car cases.

Furthermore, the neural activities of the beta frequency band that are completely left-right inversed in the two cases was revealed as an important indicator of the immersive user experience from previous studies. In [49], it was shown that the level of activation of the beta frequency band contains useful information to predict the users’ sense of reality. The beta frequency band is also related to the emotion in the immersive environment, i.e., the neural activities of the beta frequency band are significantly changed depending on the emotion of given facial expressions in virtual reality [50]. Therefore, the left-right inversion of beta activities in our results can be considered as an outcome of the different immersive user experience in the two cases such as the different level of immersiveness and different emotional responses.

The perceptual difference between the real car and photo is also revealed from the eye tracking analysis. The subjects tend to concentrate on a fewer number of points of the real car, which results in a smaller number of fixations, longer duration of fixations, larger standard deviation values of duration of fixations, and shorter scanpath. The previous study in [28] reported a positive relationship between the number of fixations and the visual complexity, and that between the average duration of fixations and the aesthetic pleasure. Thus, our results indicate that the real car can be regarded as less complex and more aesthetically pleasant compared to the photo. This is reasonable because the real product is flawless compared to the photo, and its visual complexity is reduced by introducing the depth dimension to describe the same amount of information to the photo.

As a result, the differences of EEG and gaze signals between the real product and the photo make it questionable to use a photo of a real product as an alternative choice to the real product for analysis of user experience. It is believed that these differences are mainly due to the different sense of reality for the real product and photo, which becomes more critical when a product has large size and volume. Cars are such a case, i.e., the car used in this experiment has about a width of 2 m, a height of 1.5 m, and a length of 5 m. Therefore, we consider that using a real product is desirable for the better and more accurate understanding of the user experience, and consequently, real cars are employed in the following.

SECTION 3Definition of Evaluation Factors
This section defines the factors to evaluate and predict the user experience of the car design. Note that we consider the target experience of this study as affective responses of users induced by the appearance of cars. Although the product design may include not only visual aesthetics but also function-related attributes [7], [21], the car design presented in this paper indicates only the visual aspects of cars. Therefore, our experiment does not include any operation of the cars, and the subjects were only allowed to watch the cars.

A few studies tried to understand the perceptual responses based on the design elements such as color, size, shape, and position due to the clarity of their concepts and measurability [51], [52]. However, these design elements provide low-level information, whereas the final response of people is typically influenced by the higher-level perception. That is, direct measurement of the high-level perceptual responses is more desirable to observe precise perception [53]. Therefore, we employ high-level perceptual aspects as design factors to be measured.

In [54], the perceptual responses to the product design are categorized into three types: semantic interpretation, aesthetic impression, and symbolic association. The semantic interpretation indicates the perception about its functionality and quality, which is not considered in this paper as aforementioned. The aesthetic impression refers to the feeling induced by the perception of aesthetic aspects, and the symbolic association is defined as what the product design describes about its owner or user. Considering these, we define four evaluation factors of the car design as preference, luxury, complexity, and harmony.

A comprehensive response of the aesthetic impression is evaluated as the preference, which indicates overall liking or disliking of the product design. Preference is frequently considered as a final output of the user responses [15], and plays a critical role in decision making processes such as the decision of purchase.

The symbolic association of car design is represented by luxury. Some people choose a luxurious product only for its symbolic value. Luxury can be described as excellent quality, very high price, scarcity and uniqueness, aesthetics and polysensuality, ancestral heritage and personal history, and superfluousness [55].

The perceptual response of aesthetic impression is subdivided into complexity and harmony based on the study [56] that suggests three aspects of the aesthetic sensibility as the complexity (decoration), harmony, and naturalism. Note that the naturalism is excluded in our study because a car is an artificial product and therefore it may be ambiguous to define the naturalism.

Complexity has been considered to have an inverted U-curve relationship with preference, i.e., neither too simple nor too complex stimuli are preferred [57], [58], [59], [60]. Harmonious visual stimuli are generally preferred than disharmonious ones, and such tendency is found in various aspects such as color, shape, and spatial location [61].

SECTION 4Experiment for User Experience Measurement
Based on the results in Section 2, we design an experiment to measure the user experience of car design by employing real cars.

4.1 Stimuli
Three cars from different manufacturers, denoted as A, B, and C, were used for the experiment. Particularly, all the cars were selected from sedans to exclude the functional characteristic of product designs because cars in significantly different shapes (e.g., sedan versus truck) would give different impressions of functionalities to users. The employed cars spanned a wide price range, i.e., the car with the highest price was approximately three times as expensive as the car with the lowest price. The exteriors of the cars were all black. The interior of a car was black and white, and those of the others were brown.

As subjects’ body movements can induce severe noise in the EEG signals and degrade the accuracy of eye tracking measurement, the car designs to be evaluated should be confined to scenes from single views. We chose three scenes that represented the exterior, interior, and steering wheel designs. The exterior design was defined as the scene from the front view of a car. The interior design was described as the view from the driver's seat, which was not a front view of the entire interior design, but a natural viewing condition. The design of a steering wheel was also evaluated while subjects sat in the driver's seat.

4.2 Procedure
Twelve subjects (ten males and two females) with self-reported normal or corrected-to-normal vision participated in the experiment. All subjects had driving experience, and no subject had owned the cars used in the experiment.

The same EEG and eye tracking devices used in Section 2, Emotive Epoc+ and Dikablis Eye Tracking Glasses, were also employed. After they were equipped, the subject was instructed to stand in front of a car and not to move as much as possible to avoid movement artifacts. The subject closed the eyes for five seconds to obtain the baseline signal, then was allowed to watch the car freely for 20 seconds. After that, the subject sat in the driver's seat. The EEG and eye tracking devices were re-calibrated in this step to ensure their accuracies. The measurements were repeated for the interior and steering wheel separately. For the evaluation of the interior design, the subjects were allowed to move their heads to observe the entire area of the car interior.

The entire steps are described in Fig. 5, which was conducted on the three cars one by one. Although the presentation order of the cars was fixed due to practical issues of the space and time limitations, we scheduled the presentations to be separated by at least an hour to several days to minimize the order influence.

Fig. 5. - 
Experimental procedure for EEG recording and eye tracking.
Fig. 5.
Experimental procedure for EEG recording and eye tracking.

Show All

4.3 Subjective Questionnaire
After the EEG and eye tracking measurements, the subjects were asked to rate the car designs in terms of preference, luxury, complexity, and harmony while they were allowed to watch the cars as much as they wanted. In general, many perceptual factors, for example, the environment and purpose, affect the preference in a complicated way [15]. Therefore, to suppress such influence, subjects did the rating without any scenario. The four evaluation factors were rated with a 7-point scoring system, which ranges from 1, meaning “strongly dislike” (preference), “very substandard” (luxury), “very simple” (complexity), and “very disharmonious” (harmony), to 7, meaning “strongly like” (preference), “very luxurious” (luxury), “very complex” (complexity), and “very harmonious” (harmony).

SECTION 5Analysis of Subjective Questionnaire
The obtained rating scores are summarized in Fig. 6. We conducted ANOVA tests to compare the obtained scores with respect to cars and scene types. Although the differences of subjective scores depending on the car are not statistically significant (preference: F(2,99)=0.548, p=0.580; luxury: F(2,99)=2.070, p=0.132; complexity: F(2,99)=0.784), p=0.460; harmony: F(2,99)=0.922, p=0.401), the interaction between the cars and scene types is found significant for the complexity scores (preference: F(4,99)=1.362, p=0.252; luxury: F(4,99)=0.654, p=0.626; complexity: F(4,99)=5.580, p<0.005; harmony: F(4,99)=1.951, p=0.108). The scene type significantly influences the preference, luxury, and harmony scores (preference: F(2,99)=10.54, p<0.0001; luxury: F(2,99)=15.060, p<0.0001; complexity: F(2,99)=2.435, p=0.093; harmony: F(2,99)=9.806, p<0.0001), and according to Tukey tests, the differences between the interior and the steering wheel are revealed to be significant for car C (preference: q=5.690, p<0.005; luxury: q=5.274, p<0.01; harmony: q=5.535, p<0.005).


Fig. 6.
Box plots of the obtained subjective scores. The exterior, interior, and steering wheel views are indicated as EX, IN, and STR, respectively. A line in each box indicates the median, and a ‘x’ mark corresponds to the average. An upper or lower line of the box indicates the upper or lower quartile. Circles represent the outliers that are larger or smaller than 1.5 times the upper or lower quartile. An upper or lower whisker indicates the maximum or minimum value excluding the outliers.

Show All

We can observe a couple of tendencies depending on the scene types. First, the steering wheels obtained relatively low scores in comparison to the other two scenes. This can be understood as an outcome of the scene characteristic; the exterior and interior refer to almost entire views of the cars, but the steering wheels are only part of the cars. Therefore, the steering wheels are probably insufficient to present the design characteristics. Second, the scores obtained with the interior scene are more varying depending on the car than the others. There can be several causes, but one of the considerable reasons is that the characteristics of the manufacturers’ designs are more presented in the interior design, while the exterior design has technical constraints [62].

The questionnaire results are further analyzed to investigate the correlations between the evaluation factors. Table 3 shows PCCs between the preference, luxury, complexity, and harmony scores for all cars and subjects. The largest PCC (0.776) is obtained between the preference and luxury. This is because luxurious products are typically considered to have high quality and be pleasure-inducing [33], [55]. The harmony also has a relatively high correlation with the preference (PCC = 0.621) and luxury (PCC = 0.614), which is consistent with the previous study [61].

TABLE 3 Pearson Correlation Coefficients (PCCs) Between Questionnaire Scores
Table 3- 
Pearson Correlation Coefficients (PCCs) Between Questionnaire Scores
The relationship between the preference and complexity scores is shown in Fig. 7, which shows that the obtained scores do not satisfy the inverted U-shape relationship mentioned in Section 3. Probably, the range of complexity of the employed car designs is insufficient to present such relationship. If there are more complicated stimuli, we may observe a decline of the preference score after the peak at the moderate complexity.

Fig. 7. - 
Relationship between preference and complexity scores. Each point corresponds to a rating score. The second-order polynomial curve fitted to the points are also shown to examine whether the obtained preference and complexity scores have the inverted U-shape relationship.
Fig. 7.
Relationship between preference and complexity scores. Each point corresponds to a rating score. The second-order polynomial curve fitted to the points are also shown to examine whether the obtained preference and complexity scores have the inverted U-shape relationship.

Show All

We additionally examine the influence of gender on the subjective scores. Fig. 8 shows averages and standard deviations of the scores depending on the gender of subjects. As only two females participated in the experiment, the scores are compared by using the nonparametric Mann-Whitney test. We find no significant difference between the subjective scores of female and male subjects except for the harmony scores of the exterior design of car B (U=20, effect size r=0.479, p<0.05). In that case, the male subjects evaluated the exterior design of car B as less harmonious compared with the female subjects.


Fig. 8.
Comparison of subjective scores depending on the gender. An asterisk indicates statistical significance of the difference (p<0.05).

Show All

SECTION 6User Response Prediction
6.1 Pre-Processing and Feature Extraction
The obtained EEG signals pass through the same pre-processing described in Section 2.3: After removing unstable signals, the EEG signals are divided into three-second-long segments. Then, the bandpass filtering and ICA analysis are conducted to remove artifacts. Next, the EEG signals are normalized by using the common average reference method. Finally, the PSD features are calculated from the EEG signals for the theta, alpha, beta, and gamma frequency bands.

The eye tracking data are also pre-processed as explained in Section 2.3, i.e., the removal of the head movement effect and extraction of fixations and saccades. Then, the eye tracking data are divided in the same way to the EEG signals (i.e., into three-second-long segments) to enable integration of the two modalities for the perceptual response prediction. Finally, 19 features are extracted for each segment [41], which are listed in Table 4.

TABLE 4 Eye Tracking Features
Table 4- 
Eye Tracking Features
6.2 Regression Methods
The subjective scores of the evaluation factors of car design are predicted based on the EEG or gaze signals by using a support vector regression (SVR) method implemented with the LIBSVM toolbox [63]. A radial basis function kernel is employed, and the parameters of the SVR (the penalty parameter and the width of the radial basis function) are optimized by a logarithmic grid search.

The regression is conducted with both subject-dependent and subject-independent schemes. The leave-one-out cross-validation method is adopted for the subject-dependent regression. That is, when the number of data for each subject is N, the learning model is trained with N−1 data and tested with the remaining data. Then, this is repeated N times so that all data are tested. For the subject-independent scheme, the leave-one-subject-out cross-validation method is employed. When the number of subjects is M, the learning model is trained using the data of M−1 subjects and tested using the data of the remaining subject. Then, this process is repeated M times.

Furthermore, the two regression systems constructed with EEG and eye tracking features are integrated to obtain enhanced regression performance. In particular, a decision fusion (or late fusion) method is employed, where a weighted sum of the predicted scores based on EEG and eye tracking features is regarded as a final prediction result [35], [64]. The weights of the two modalities are between 0 and 1, and determined for the training data by using a grid search while their sum is kept as one.

6.3 Prediction Results
Fig. 9 shows the prediction results in terms of root-mean-square errors (RMSEs) between the ground truth subjective scores and the scores predicted by SVR using EEG, eye tracking data, or both.

Fig. 9. - 
Average root-mean-square errors (RMSEs) of the perceptual response prediction. Dotted lines indicate average RMSE values across the four evaluation factors.
Fig. 9.
Average root-mean-square errors (RMSEs) of the perceptual response prediction. Dotted lines indicate average RMSE values across the four evaluation factors.

Show All

6.3.1 EEG
By using the EEG signals, we obtain RMSE values of 0.210 and 1.338 on average for the subject-dependent and subject-independent schemes, respectively. The errors obtained with the subject-dependent scheme are much smaller than a half of the scoring interval, i.e., 0.5, for all the evaluation factors. In addition, although the subject-independent prediction is not as accurate as the subject-dependent prediction (its RMSE values are larger than 0.5), it can identify a binary response, for example liking (above 4) or disliking (below 4), because its RMSE values are smaller than a quarter of the scoring range (i.e., 1.5). These results demonstrate that the perceptual responses of car design can be predicted by using EEG signals.

6.3.2 Eye Tracking
The feasibility for predicting the perceptual responses is also observed in the case of eye tracking. The prediction using the gaze features result in comparable values of RMSE with EEG in the subject-independent regression (1.366 on average). However, the subject-dependent prediction based on eye tracking is poorer than that based on EEG, showing an RMSE value of 0.990 on average.

6.3.3 Fusion
The results obtained from the fusion of EEG and gaze data are shown in Fig. 9c. Although the integration does not show any improvement over EEG in the subject-dependent scheme, the performance for the subject-independent scheme is enhanced through fusion. We obtain an average RMSE of 1.215, which corresponds to a relative improvement by 11 percent on average.

The weighting values for the eye tracking modality for the subject-independent regression are shown with respect to the factor, view, and subject in Fig. 10. We can observe that the gaze signals are importantly used for the subject-independent regression; the average weight values are all over 0.5. Significant differences are found between the weight values for the three types of views by an ANOVA test (F(2,141)=31.61, p<0.0001), while no statistical significance is found in terms of factors (F(3,140)=1.024, p=0.384) and subjects (F(11,132)=0.590, p=0.835). In addition, pair-wise differences of the weight values are confirmed by Tukey tests. Particularly, highly significant differences are observed in the cases of exterior versus interior (q=10.983, p<0.0001) and interior versus steering wheel (q=7.614, p<0.0001). This is probably because of the varying gaze patterns for the interior view. While there were common regions that dominantly attracted subjects’ attention in the exterior and steering wheel views such as headlights and buttons on the steering wheel, various regions can attract visual attention differently across the subjects. Therefore, the gaze signals are relatively useful to predict the perceptual experience of the interior view.

Fig. 10. - 
Average weight values of the gaze signals for bimodal subject-independent regression. Standard deviation values are also shown with error bars. Statistical significance of the difference between the weight values is denoted using asterisks (*: $p<0.05$p<0.05; ****: $p<0.0001$p<0.0001).
Fig. 10.
Average weight values of the gaze signals for bimodal subject-independent regression. Standard deviation values are also shown with error bars. Statistical significance of the difference between the weight values is denoted using asterisks (*: p<0.05; ****: p<0.0001).

Show All

6.4 Discussion
Consistent superiority of the regression performance among the evaluation factors is observed in Fig. 9. The performance is better in the order of luxury, harmony, preference, and complexity, which is exactly the same to the ascending order of the standard deviations of the subjective scores. A smaller standard deviation indicates that the evaluation criteria for the corresponding design aspect are similar across the subjects. Therefore, it can be inferred that the accordance of evaluation criteria, which induces strong agreement of subjective evaluation, also influences on the EEG and eye tracking data so that they have similar patterns that are relatively easy to learn for SVR.

Furthermore, the ranking of the subjects in terms of regression performance is examined in Tables 5 and 6. The prediction performance with EEG features considerably varies across the subjects. This accords with the previous study [65] that examined canonical correlations between emotional scores of images and event-related brain responses of the theta, alpha, and gamma frequency bands. In that study, the canonical correlations were not statistically significant for some subjects, whereas the EEG signals of the other subjects were significantly related with the emotional scores, which indicates that EEG signals have different levels of discrminability depending on the subject. In addition, the variation of regression performance is also observed from the prediction results using the eye tracking features.

TABLE 5 Ranking of the Subjects in an Increasing Order of the Average RMSE (Shown in the Parentheses) for the Subject-Dependent Scheme

TABLE 6 Ranking of the Subjects in an Increasing Order of the Average RMSE (Shown in the Parentheses) for the Subject-Independent Scheme
Table 6- 
Ranking of the Subjects in an Increasing Order of the Average RMSE (Shown in the Parentheses) for the Subject-Independent Scheme
Interestingly, the order of the subjects in terms of regression performance is relatively constant among the modalities. SROCCs of 0.825 and 0.853 are obtained between EEG and eye tracking results of the subject-dependent and subject-independent schemes, respectively. The consistently high or low performance of the user experience prediction implies that the EEG and eye tracking patterns learned by SVR have similar discriminability. In other words, if the perceptual response of a subject is well predicted based on one modality, it also can be predicted successfully with the other modality. The visual attention of the subject can be one of the sources of such a phenomenon. The gaze pattern is obviously an explicit indicator of the visual attention, and the EEG signal is also closely related to the visual attention, which was demonstrated in several previous studies [66], [67]. Therefore, if the subject shows different patterns of the visual attention depending on the level of the design quality, such difference is reflected in both EEG and eye tracking data.

SECTION 7Conclusion
In this paper, we analyzed the user experience of real cars in terms of preference, luxury, complexity, and harmony based on EEG and eye tracking data. First, we compared the perceptual responses induced by the photo and real car and verified the existence of perceptual difference between them. Then, we conducted the prediction of user responses by using SVR. It was shown that the EEG and gaze signals can be utilized to predict the user experience. Furthermore, the fusion of the two regression models improves the prediction performance for the subject-independent regression scheme. Particularly, the gaze signals significantly contribute to the prediction of the perceptual responses to the interior design. We found that the evaluation factor with higher agreement among the subjects is predicted with higher accuracy. Finally, we observed significant differences in the prediction performance across subjects, and consistency of the performance of the two modalities.

Although we showed the significance of the obtained results throughout the paper, this work was implemented with a limited number of subjects. Therefore, a greater number of subjects, particularly from a larger pool of age, experience, etc., will enable to provide more generalized results and analyze the individual characteristics in depth. It will be also interesting to perform the evaluation of product design in virtual reality environments.