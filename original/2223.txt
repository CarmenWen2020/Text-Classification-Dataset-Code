In this paper we deal with the initialization problem of a visual-inertial odometry system with rolling shutter cameras. Initialization is a prerequisite for using inertial signals and fusing them with visual data. We propose a novel statistical solution to the initialization problem on visual and inertial data simultaneously, by casting it into the renormalization scheme of Kanatani. The renormalization is an optimization scheme which intends to reduce the inherent statistical bias of common linear systems. We derive and present the necessary steps and methodology specific to the initialization problem. Extensive evaluations on ground truth exhibit superior performance and a gain in accuracy of up to 20% over the originally proposed Least Squares solution. The renormalization performs similarly to the optimal Maximum Likelihood estimate, despite arriving at the solution by different means. With this paper we are adding to the set of Computer Vision problems which can be cast into the renormalization scheme.

Access provided by University of Auckland Library

Introduction
Real time pose estimation of a moving camera has been an active topic in Computer Vision and Robotics community for decades, but with the advent of Augmented Reality, the topic experiences a new hype. Augmented Reality draws new requirements on pose estimation performance as on the energy consumption side as well as on the accuracy and robustness. Mobile phones, wearable smart glasses or watches use in-built rigs with a mono or stereo camera and an IMU as a de facto standard hardware. This stems from the fact that combining the two sensor modalities, the visual and inertial one, has been proven to be an ultimate solution towards compensating each others drawbacks. Common development toolkits natively support fusion of both sensors, e.g. ARCore (Google 2018) and ARKit (Apple 2015).

There are two important practical challenges to be considered. First, cameras in mobile devices are in majority rolling shutter cameras. These are cheaper and possess higher dynamic range than standard global shutter cameras. Majority of research has been, however, devoted to the standard global shutter camera models. Rolling shutter geometry has started catching the attention with the rise of mobile phones and smart glasses (Meingast et al. 2005; Hedborg et al. 2012; Albl et al. 2015; Dai et al. 2016; Albl et al. 2016). Second, IMU sensors do measure linear acceleration and angular velocity which are the second and the first derivatives of the desired position and orientation, respectively. In order to estimate the position of an IMU over time, the integration of both signals needs to be performed. Such an integration requires knowing the initial conditions, i.e. the initial velocity and gravity direction. However, the IMU data alone is insufficient to estimate these initial conditions. For instance, the IMU delivers zero inertial acceleration signal when it is either static or moving with constant velocity. Without proper initial conditions, the integration leads to the same static pose. The remedy lies in fusion of the inertial with visual data as the visual cues clearly distinguish these two cases.

Fig. 1
figure 1
Rolling shutter (stereo) camera with IMU rig in motion. This paper deals with the simultaneous estimation of the unknown initial velocity ð¯0 and the gravity ð 0 from the IMU and camera data streams

Full size image
Yet, most systems assume that the mobile device is static at the beginning of its operation and as such, the initial velocity can be set to zero and the initial gravity direction can be deduced from the accelerometer. While this assumption may be safe in many situations, it is violated when triggering the start of a Visual-Inertial Odometry (VIO) system under motion, e.g. when walking or bicycling.

Contribution
In this paper we aim at estimating the initial velocity and gravity direction of a moving rig, equipped with rolling shutter cameras and an IMU, as depicted in Fig. 1. We consolidate the closed-form minimal solver of Martinelli (2013) for a general case with multiple rolling shutter cameras and partial tracks. As the main contribution, we introduce a more accurate solution by casting the original formulation into the renormalization scheme of Kanatani (1996). Namely, we reduce the problem of the original solver by Shur complement based elimination and present noise propagation analysis on the reduced problem in order to arrive at the renormalization scheme.

The renormalization scheme of Kanatani is a statistical method for certain type of problems. We show that the initialization problem can be brought by the proposed operations into the renormalization scheme. The proposed solution has superior performance to the least squares solver of Martinelli (2013) while both defined on top of the same linear system. The renormalization scheme performs comparably and sometimes outperforms the optimal Maximum Likelihood (ML) estimator which minimizes the re-projection error. Compared to the least squares, the renormalization scheme removes its inherent bias, and explicitly provides the covariance of the estimate. The renormalization scheme may suffice to solve the problem in most cases, however, it can initialize ML to enforce faster convergence.

It is known that ML entails statistical bias in the presence of what is known as nuisance parameters. Various studies exist for analyzing and removing bias in the ML solution, e.g. by Okatani and Deguchi (2009). An optimal ML solution is usually given by a nonlinear optimization which is time-consuming when solved by numerical search. It often requires extra nuisance parameters, initial values and solving iteratively large, although sparse, linear systems. On the contrary, the renormalization procedure requires neither a priori knowledge of the initial values nor the noise level which is estimated a posteriori as a result of the renormalization itself. It consists of iterated computations of eigenvalues and eigenvectors of small matrices and bias-correction steps.

This paper adds a new problem into the set of Computer Vision problems which can be cast into the renormalization scheme. Kanatani et al. (2016) formalized the renormalization scheme for many geometric computations in computer vision, e.g. ellipse, homography, fundamental matrix fitting, triangulation, and 3D reconstruction. These techniques show superior performance under some circumstances on many problems to the Gold Standard Methods of Hartley and Zisserman (2004) and are viable alternatives in many practical use cases.

The paper is structured as follows. First, the related work for VIO initialization and structure from motion systems as well as positioning the renormalization scheme is reviewed in Sect. 2. Then, the main concept is presented in Sect. 3. Its main parts include geometric relation of a camera and an IMU in Sect. 3.1; rolling shutter image formation in Sect. 3.2; the closed-form minimal and overconstrained solver, adjusted for rolling shutter cameras and partial feature tracks in Sect. 3.3; its reduced form in Sect. 3.4, cast as the renormalization scheme outlined and applied in Sect. 3.5. Bundle adjustment is shortly discussed and compared to the renormalization in Sect. 3.6. Finally, an extensive experimental evaluation is presented in Sect. 4, followed by the conclusion in Sect. 5.

Related Work
VIO Initialization
The most relevant paper to our method is the closed-form solution for initial velocity and gravity direction by Martinelli (2013). The method assumes a mono global shutter camera and complete tracks. They propose to relate corresponding visual observations through the camera baseline, which linearly depends on the unknown state parameters, that is, the velocity, the gravity in the IMU frame and the accelerometer bias. Each visual correspondence contributes three linear equations, while the distances between map points and the cameras become unknown parameters too. The resulting linear system is solved with the constraint on the gravity magnitude. The robustness of the method against biased IMU readings was investigated by Kaiser et al. (2017) and, to account for the gyroscope bias, a non-linear refinement method was proposed. Campos et al. (2019) then built on Martinelli (2013) and Kaiser et al. (2017), and improved the method via multiple loops of visual-inertial bundle adjustments and consensus tests. Our solution improves the least square solution and could be directly used for the bundle adjustment initialization of Campos et al. (2019) or Mur-Artal and TardÃ³s (2017). The proposed methodology could also be applied to the reduced linear solver for initial velocity and gravity direction by Evangelidis and Micusik (2021).

The above methods adopt an early fusion approach, i.e. a tightly-coupled fusion. Instead, the visual SfM problem can be first solved and the IMU data can be later integrated in a more loosely-coupled framework of Kneip et al. (2011); Mur-Artal and TardÃ³s (2017); Huang et al. (2020). In this context, Kneip et al. (2011) suggested using visual SfM to obtain camera velocity differences which are then combined with integrated IMU data to recover the scale and gravity direction. The initialization part of Mur-Artal and TardÃ³s (2017) used scaleless poses from ORB-SLAM of Mur-Artal et al. (2015) and then solved several sub-problems to initialize the state and the biases along with the absolute scale. This multi-step solution for the parameter initialization was then adapted in Qin and Shen (2017).

The initialization problem becomes harder when the device is uncalibrated (Dong-Si and Mourikis 2012; Huang et al. 2020). Even if the biases are known or ignored, the unknown orientation between the camera and the IMU makes the model non-linear and iterative optimization is necessary. Dong-Si and Mourikis (2012) propose two solutions to estimate the unknown orientation, thus allowing solving a linear system which, in turn, initializes a non-linear estimator. Instead, Huang et al. (2020) builds on the mutli-step approach of Mur-Artal and TardÃ³s (2017) to jointly calibrate the extrinsics and initialize the state parameters. In a real scenario, however, the joint solution of calibration and initialization problem using only the very first few frames might make the pose tracking algorithm prone to diverge.

It is worth noting that all the above works assume that visual observations come from a global-shutter sensor. Consumer devices, however, are mostly equipped with rolling shutter cameras and rolling-shutter effects need to be handled. Proper treatment of the rolling shutter camera in connection to visual-inertial odometry can be found in work of Hedborg et al. (2012); Li et al. (2013); Patron-Perez et al. (2015); Bapat et al. (2018); Ling et al. (2018); Schubert et al. (2018, 2019). However, neither of the works copes with the initialization problem.

Renormalization
The renormalization of Kanatani (1996) was at first not well accepted by the computer vision community. This was due to the generally held preconception that parameter estimation should minimize some cost function. Scientists wondered what renormalization was minimizing. In this line of thought, Chojnacki et al. (2001) interpreted renormalization as an approximation to ML. Optimal estimation does not necessarily imply minimizing a cost function and as such the renormalization is an effort to improve accuracy by a direct mean (Kanatani 2014). The mathematical foundation of the optimal correction techniques of Kanatani et al. (2016) is also discussed in the broader scope of photogrammetric statistical geometric computations by FÃ¶rstner and Wrobel (2016). It is the non-minimization formalism based on error analysis which intuitive meaning is often difficult to grasp, as we will see in the following.

Regarding re-projection error minimization as the ultimate method, or the Gold Standard, the fact that the accuracy of ML can be improved was rather surprising (Kanatani 2008; Okatani and Deguchi 2009). For hyperaccurate correction, however, one first needs to obtain the ML solution by an iterative method such as Fundamental Numerical Scheme (FNS) of Chojnacki et al. (2000) on Sampson Error or Heteroscedastic Error-In-Variables (HEIV) method of Leedan and Meer (2000) and also estimate the noise level. However, it is possible to directly compute the corrected solution from the beginning, by modifying the FNS iterations if one adopts the non-minimization approach of geometric estimation of Kanatani (2014).

Concept
Geometry
A 3D point ð—ð‘– expressed in the local coordinate system of the IMU at time ðœð‘–, projected into the coordinate system of the IMU at time ðœ0 reads as

ð—0=ðš0ð‘–ð—ð‘–+ð­0ð‘–,
(1)
where ðš0ð‘– and ð­0ð‘– stand for the rotation matrix and the translation vector to perform this transformation. Let us assume that a camera attached to the IMU rig observes the 3D point ð—0 at time ðœð‘– as

Î»ð‘–ð®ð‘–=ð™º(ðšCIMUðšð‘–0Î»ð‘–ðš0ð‘–ðšIMUCð™ºâˆ’1ð®ð‘–î„½î„¾î…î…‹î…‹î…‹î…‹ð©Ìƒ ð‘–+ð­0ð‘–+ðš0ð‘–ð­IMUC=ð—0+ðšCIMUð­ð‘–0+ð­CIMU)ð—0
(2)
where ðšIMUC, ð­IMUC is the known fixed relative pose from the camera to the IMU, and ð™º is the known camera calibration matrix. Image coordinates of the 3D point ð—0, being tracked in multiple views, are denoted ð®ð‘–, and Î»ð‘– are unknown scales, the depths, of their projection rays ð™ºâˆ’1ð®ð‘–.

The IMU pose ðš0ð‘–, ð­0ð‘– at time ðœð‘– is calculated as

ðš0ð‘–=âˆð‘˜=0ð‘–âˆ’1ðšð‘˜ð‘˜+1=âˆð‘˜=0ð‘–âˆ’1Î©(ðœ”ðœ”ð‘˜ð›¥ðœ),
(3)
ð­0ð‘–=ð­0+ð‘–ð¯0ð›¥ðœ+(âˆ‘ð‘˜=0ð‘–âˆ’1ð›½ð‘˜,ð‘–ðš0ð‘˜ðšð‘˜+ð‘–2ð 0)ð›¥ðœ22,
(4)
where

ð›½ð‘˜,ð‘–=2ð‘–âˆ’2ð‘˜âˆ’1.
(5)
The 3 element vector ðšð‘˜ and ðœ”ðœ”ð‘˜ is the accelerometer and the gyroscope readout measurements of the IMU at time ðœð‘˜, respectively. The exponential map Î©(.) gives a rotation matrix from the argument vector. The time between two IMU samples is denoted by ð›¥ðœ. Without loss of generality, we set the origin into the coordinate system of the first IMU, thus the translation ð­0=0. The initial velocity ð¯0 and the gravity vector ð 0 at time ðœ0, expressed in the origin, are the unknowns and subjects to estimation. For the sake of simplicity, we assume for now that the measurements are corrected for biases. The compensation of the biases is discussed later in Sect. 3.7. The biases may vary over time, and can be included in a final non-linear refinement step. We further assume that the IMU and the cameras are temporarily synchronized.

It is to be noted that unless ð¯0 and ð 0 are known, the IMU data cannot be integrated in order to get IMU poses in the above chosen origin. Most visual-inertial systems assume that the camera-IMU rig is static at start and it can be assumed that the initial velocity ð¯0=0 and the initial gravity ð 0 is determined from the acceleration readout. However, in many practical situations this is violated, the system is in motion at start, e.g. a person rides a bicycle or walks.

Rolling shutter image formation
A rolling shutter camera is, in its principle, a moving line camera. When moving along a line, it falls into a class of linear pushbroom cameras, see (Gupta and Hartley 1997). Each scanline is read out one after the other and all of them are stacked into an image buffer. Note that indeed the pose of the IMU in Eq.(2) differs for each i. The readout time of a scanline of the rolling shutter camera is constant even when camera exposure varies. We can therefore safely choose ð›¥ðœ=ðœð‘–+1âˆ’ðœð‘– to be exactly the readout time of one line of the camera. The IMU data can be upsampled, e.g. for VGA resolution from a typical sampling IMU rate of 800Hz to 47.6kHz, and integrated, called the interpolate-then-integrate approach. As such, for each scanline of the image, we have one pose, ðš0ð‘– and ð­0ð‘–. Alternatively, the integration is performed on the original IMU sample rate and then the poses are interpolated for each scanline, the integrate-then-interpolate approach. We found the first approach to give slightly better results for the initialization problem. This is expected because of the non-linear dependency of translation ð­0ð‘– on gyroscope readout ðœ”ðœ”ð‘˜ in Eq.(4) and Eq.(3). Upsampling the signals first and then integrating through a non-linearity is typically recommended.

Linear Solver
Let us assume that a (stereo) camera with the IMU moves and observations of some 3D points in multiple images are available. If ð®ð‘– and ð®ð‘— are the homogeneous image observations of a point ð—0 in two views, then we can write Eq.(2) for each point separately. By eliminating ð—0 we obtain

Î»ð‘–ð©ð‘–+ð­0ð‘–+ðš0ð‘–ð­IMUC=Î»ð‘—ð©ð‘—+ð­0ð‘—+ðš0ð‘—ð­IMUC,
(6)
such that the 3 element calibrated vector ð©ð‘–=îˆº(ð©Ìƒ ð‘–)=îˆº(ðš0ð‘–ðšIMUCð™ºâˆ’1ð®ð‘–), where îˆº(ð±) normalizes the vector ð± by its third coordinate to the homogeneous coordinates. Substituting Eq.(4) into Eq.(6) yields

âŽ¡âŽ£âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢ðœ‰ð‘–ð‘—ð™¸3â‹®ðœ‰ð‘–ð‘˜ð™¸3â‹®ðœ‰ð‘˜ð‘™ð™¸3 ðœ‡ð‘–ð‘—ð™¸3  ðœ‡ð‘–ð‘˜ð™¸3  ðœ‡ð‘˜ð‘™ð™¸3 ðœ…ðœ…ð‘–ð‘—ðœ…ðœ…ð‘–ð‘˜ðœ…ðœ…ð‘˜ð‘™î„½î„¾î…î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹ðš‚ð©ð‘– â‹®ð©ð‘– â‹®.. ð©ð‘— .. .. .. ð©ð‘˜ ð©ð‘˜ â€¦â€¦â€¦ .. .. ð©ð‘™î„½î„¾î…î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹ð™¿âŽ¤âŽ¦âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¡âŽ£âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢âŽ¢ð¯0ð 01Î»ð‘–Î»ð‘—Î»ð‘˜â‹®Î»ð‘™âŽ¤âŽ¦âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥âŽ¥=0,
(7)
where

ðœ‰ð‘–ð‘—ðœ‡ð‘–ð‘—ðœ…ðœ…ð‘–ð‘—=(ð‘–âˆ’ð‘—)ð›¥ðœ,=(ð‘–2âˆ’ð‘—2)ð›¥ðœ22,=ðš0ð‘–ð­ð‘–Câˆ’ðš0ð‘—ð­ð‘—C++(âˆ‘ð‘˜=0ð‘–âˆ’1ð›½ð‘˜,ð‘–ðš0ð‘˜ðšð‘˜âˆ’âˆ‘ð‘˜=0ð‘—âˆ’1ð›½ð‘˜,ð‘—ðš0ð‘˜ðšð‘˜)ð›¥ðœ22.
(8)
In the matrix form, the Eq.(7) can be written as

[ðš‚  ð™¿]ð±=0,
(9)
which is a linear equation system. It can be solved, for instance, in the least squares sense. It is worth noting that the error which is minimized by the above least squares solution has a geometric meaning. It relates to the distance between 3D points which are obtained through Î»ð‘–ð©ð‘–, as shown in Fig. 2. We tried to formulate the initialization problem on the angular error on projective rays instead of the distance. The angular error is often used in standard epipolar geometry solvers (Hartley and Zisserman 2004), and also has been used in the relative pose for the rolling shutter camera in Dai et al. (2016). For static or slow motion the error degenerates as is too sensitive to image noise. Overall, the angular error is inferior to the presented distance based error.

Fig. 2
figure 2
Distance error ðœ– being minimized by the naÃ¯ve least square estimator

Full size image
Each matching pair of image points adds three equations which constrain the shared unknown initial velocity and gravity (fixed six unknowns), but adds additional unknown Î»â€™s per ray (always two new unknowns). Provided that a single point is tracked in all views, then each new image observation adds only one Î»ð‘–, and the minimum number of frames is 5 (4 pairs). The unknown Î»â€™s are shared between multiple views as shown in Eq.(7), if a ray is used in multiple pairs. There, for the (i, j) and (i, k) pairs, Î»ð‘– is shared as the corresponding 3D point is projected into three views. This explicit sharing of Î»â€™s better constraints the system and reduces the growth of unknowns. Similar derivations to Eq.(7) for the global shutter camera can be found in Martinelli (2013).

Reduced Linear Solver
We propose to eliminate the unknown Î»â€™s form Eq.(9). This can be done with the Schur complement based elimination of the ð™¿ matrix in Eq.(9) such that it becomes

[ðš‚âˆ’ð™¿(ð™¿âŠ¤ð™¿)âˆ’1ð™¿âŠ¤î„½î„¾î…î…‹î…‹ð™¶ðš‚] ð²=0,
(10)
 ð²=0,
(11)
ð™± âŽ¡âŽ£âŽ¢âŽ¢âŽ¢ð¯0ð 01âŽ¤âŽ¦âŽ¥âŽ¥âŽ¥=0,
(12)
where the matrix ð™±=(ð™¸3âˆ’ð™¶)ðš‚ is 3ð‘Ã—7, N is the number of pairs of point matches and ð²=[ð¯âŠ¤0 ð âŠ¤0 1]âŠ¤ is the unknown 7 element vector. The matrix ð™¶ is an idempotent ð‘Ã—ð‘ projection matrix. Solving the reduced linear problem in Eq.(12) in the least square sense, yields the same result as (Eq.7). Depending on the sparsity of the matrix ð™¿, one or another can be faster, and should be chosen accordingly for specific practical conditions.

The reduced form simplifies the noise analysis in order to arrive to the solver presented in the next. The advantage of the reduced form in Eq.(12) is that the unknown solution vector is of fixed size. It contains the initial velocity and gravity only, and no longer the depth multipliers Î»â€²ð‘ .

At the first look, it might look as if the rolling shutter camera adds difficulties in the equations in comparison to the global shutter case. However, from the geometric point of view, the opposite can be claimed. Each camera line has a different center of projection when moving and so the rays put into the triangulation equation constrain better the solution. On the other side, the rolling shutter effect adds image artifacts as the long line segments may get projected as bent under a fast motion. However, as we experimentally observed, this is negligible for a feature tracker which uses a small image patch. Overall, the rolling shutter is a beneficial feature which implicitly encodes motion of the camera and makes it directly observable (Bapat et al. 2018).

Both Eqs.(7) and (12) treat all the data as equally valuable and fall into the class of algebraic least squares estimators. In the next section we propose an improvement by involving a proper noise perturbation analysis to individually weight the point matches.

Renormalization Scheme
Class of problems like Eq.(12), where a geometric relationship in high dimensions, expressed as an implicit equation, is fitted, is called geometric fitting and has been studied by Kanatani (1996). The matrix ð™± in Eq.(12) is filled from the IMU sensor data and from the image point correspondences over multiple views ð®{ð‘–,ð‘—,â€¦} via their projective rays ð©{ð‘–,ð‘—,â€¦}. We consider short integration time in which the effect of noise on the IMU data is negligible to the noise on the point correspondences. We experimentally verified very little accuracy gain when considering noise in the IMU data. Therefore, in the next we perform noise perturbation analysis when considering noise purely on the point correspondences.

Each image point correspondence pair ð®ð‘–â†”ð®ð‘— in Eq.(12) contributes three equations to the matrix ð™± and can be written as

(ð›(ð‘ )(ð®ð‘–,ð®ð‘—),ð²)=0,ð‘ =1â€¦3,
where ð›(ð‘ )(.,.) is one row of the matrix ð™± and (ðš,ð›)=ðšâŠ¤ð› stands for the inner product. The three equations are linearly dependent, so we see the same as in Eq.(9) that 6 is the minimal number of point correspondences to guarantee ð‘Ÿð‘Žð‘›ð‘˜(ð™±)=6.

The coordinates of the image point correspondences ð®ð‘–,ð®ð‘— are not perfect. This is caused by the image operations, specifically the feature detection and patch based tracking on noisy image data signal. We model this uncertainty in statistical means. We assume that the observed image point ð®ð‘– stems from perturbation of the true value ð®Â¯ð‘– by independent random Gaussian variable ð›¥ð®ð‘– of zero-mean and with the covariance matrix ðš…[ð®ð‘–], such that

ð®ð‘–=ð®Â¯ð‘–+ð›¥ð®ð‘–.
We experimentally validated that Gaussian noise is a feasible assumption in practical situations with an off-the-shelf feature detector and a feature tracker, see Fig. 3 for more details. We assume a 2Ã—2 covariance matrix, known up to noise level ðœŽ,

ðš…[ð®ð‘–]=ðœŽ2ðš…0[ð®ð‘–],
(13)
where the known normalized covariance matrix ðš…0[ð®ð‘–] describes the orientation dependence of uncertainty in relative terms. The covariance matrix can come from uncertainty of the employed feature detector and the tracker. In all our experiments we assume ðš…0[ð®ð‘–] be the identity matrix.

Fig. 3
figure 3
Half-normal distribution of the positional error of detected FAST corners of Rosten et al. (2010) and ECC tracked feature points by Evangelidis and Psarakis (2008). The error is defined as the distance between a feature point and its ground truth location on a synthetically rendered sequence with no additionally added image noise. It can be seen that it obeys Gaussian distribution under a perfect image formation model. For real images we silently assume similar behavior

Full size image
If the observations ð®ð‘–, ð®ð‘— are regarded as random variables, their nonlinear mapping ð›(ð‘ )(ð®ð‘–,ð®ð‘—), which we write ð›(ð‘ )ð‘–ð‘—, or ð›(ð‘ )ð›¼ for short, is also a random variable. The linear index ð›¼ steps over the row triplets in the matrix ð™± in Eq.(12). Each ð›¼ represents a frame pair ij and we use them exchangeably. Missing superscript in ð›ð‘–ð‘— means all three rows, i.e. a 3Ã—7 matrix. Its covariance matrix is

ðš…(ð‘ ð‘¡)[ð›ð‘–ð‘—]=ðœŽ2ðš…(ð‘ ð‘¡)0[ð›ð‘–ð‘—],
(14)
where ð‘ ,ð‘¡=1â€¦3 to combine mutually the rows of the three equations per correspondence, yielding nine matrices per each ij combination (or ð›¼). The covariance matrix is evaluated to first approximation in terms of the Jacobians ð™¹(ð‘ ) and ð™¹(ð‘¡) of the mapping ð›ð‘–ð‘— as follows

ðš…(ð‘ ð‘¡)0[ð›ð‘–ð‘—]7Ã—7=ð™¹(ð‘ )ð‘–ð‘—[ðœŽ2ðš…0[ð®ð‘–]ðŸ¶ðŸ¶ðœŽ2ðš…0[ð®ð‘—]]4Ã—4ð™¹(ð‘¡)âŠ¤ð‘–ð‘—.
(15)
If the noise in the ð®-space is assumed Gaussian, the corresponding noise in the transformed ð›-space is no longer Gaussian. However, our numerical experiments have shown that in the noise range of typical feature detector and tracker, i.e. ðœŽâˆˆ[0,0.5] pixels, such an assumption is feasible. In order to stay in the safe range, removal of systematic error like outliers prior to estimation is crucial. Correction for higher order noise terms can be omitted, as we observed that the Hyper-renormalization of Kanatani et al. (2016) brings only small accuracy gain for the increased computational burden.

Solver
The standard Least Squares (LS) solution to Eq.(12)

ðœ–2=1ð‘âˆ‘ð›¼=1ð‘âˆ‘ð‘ ,ð‘¡=13(ð›(ð‘ )ð›¼,ð²)(ð›(ð‘¡)ð›¼,ð²)
(16)
=(ð²,(1ð‘âˆ‘ð›¼=1ð‘âˆ‘ð‘ ,ð‘¡=13ð›(ð‘ )ð›¼ð›(ð‘¡)ð›¼âŠ¤)ð²)=(ð²,ð™¼LSð²)
(17)
minimizes the mean square error ðœ–2. Fig. 2 depicts the geometric meaning of the error. The solution can be obtained as an eigenvalue fit of the 7Ã—7 matrix ð™¼LS of

ð™¼LSð²=Î»ð².
Weighting each pair i, j differently, LS would turn, for small accuracy gain, into iterative re-weighted LS. More importantly, both can be fairly improved by Taubin (1991), as modification of LS and even slightly more by Kanatani (2008). Our experiments validate what has been demonstrated in the ellipse fitting problem by Kanatani (2008), that the error on the estimated entities can be sorted as naÃ¯ve LS > weighted LS â‰« Taubin > renormalization, see 4.1 and Fig. 5.

Taubin (1991) proposed to include higher noise error terms to remove the bias of LS, and such, to first order approximation of the algebraic mean square error it yields a generalized eigenvalue fit. Kanatani further improved upon this idea and proposed to iteratively re-weight the Taubin method, therefore called renormalization (Kanatani 1996). In the following we present the renormalization scheme applied to the initialization of a VIO system.

Renormalization Scheme

1.
Let ð²0=0 and ð‘¤(ð‘ ð‘¡)ð›¼=ð›¿ð‘ ð‘¡, ð›¼=1â€¦ð‘, ð‘ ,ð‘¡=1,2,3, where ð›¿ð‘ ð‘¡ is the Kronecker delta, equal 1 if ð‘ =ð‘¡ and 0 otherwise.

2.
Compute 7Ã—7 matrices

ð™¼=1ð‘âˆ‘ð›¼=1ð‘âˆ‘ð‘ ,ð‘¡=13ð‘¤(ð‘ ð‘¡)ð›¼ð›(ð‘ )ð›¼ð›(ð‘¡)ð›¼âŠ¤
(18)
ð™½=1ð‘âˆ‘ð›¼=1ð‘âˆ‘ð‘ ,ð‘¡=13ð‘¤(ð‘ ð‘¡)ð›¼ðš…(ð‘ ð‘¡)0[ð›ð›¼],
(19)
where ð‘¤(ð‘ ð‘¡)ð›¼ is the element of the matrix ðš†ð›¼ at the row s and column t.

3.
Solve the generalized eigenvalue problem

ð™¼ð²=ð›¾ð™½ð²
(20)
and compute the unit eigenvector ð² for the smallest eigenvalue ð›¾.

4.
If ð²â‰ˆð²0 up to sign, continue to Step 5. Else, update

ðš†ð›¼ð²0â†âŽ¡âŽ£âŽ¢âŽ¢âŽ¢(ð²,ðš…(11)0[ð›ð›¼]ð²)(ð²,ðš…(21)0[ð›ð›¼]ð²)(ð²,ðš…(31)0[ð›ð›¼]ð²)(ð²,ðš…(12)0[ð›ð›¼]ð²)(ð²,ðš…(22)0[ð›ð›¼]ð²)(ð²,ðš…(32)0[ð›ð›¼]ð²)(ð²,ðš…(13)0[ð›ð›¼]ð²)(ð²,ðš…(23)0[ð›ð›¼]ð²)(ð²,ðš…(33)0[ð›ð›¼]ð²)âŽ¤âŽ¦âŽ¥âŽ¥âŽ¥âˆ’{1,2}â†ð²
(21)
and go back to Step 2. The expression [ðš„]âˆ’{1,2} is the pseudoinverse with truncated rank 2 or 1. The truncation to rank 2 is done iff ðœŽ2ðœŽ1>0.1, where ðœŽ1 and ðœŽ2 is the first and the second largest singular value of ðš„ respectively. Otherwise, the truncation to rank 1 is performed.

5.
Return ð² composed of ð¯0 and ð 0, its covariance matrix ðš…0[ð²], and the noise level ðœŽ

ðš…0[ð²]=ðœŽ2ð‘ð™¹ð»ð™¼âˆ’1ð™¹âŠ¤ð»,ðœŽ2=ð²âŠ¤ð™¼ð²2âˆ’6/ð‘
(22)
with ð™¹ð» being the Jacobian of the transformation from a homogeneous to Euclidean vector, see (FÃ¶rstner and Wrobel 2016, Eq.(10.32)),

ð™¹ð»=1ð²2(7)[ð²(7)ð™¸6 | âˆ’ð²(1:6)].
Justification of estimating the noise level ðœŽ can be seen in Eq. (6.46) in Kanatani et al. (2016).

The matrix ð™¼ determines the covariance of the final estimate of ð², while the matrix ð™½ controls the bias of ð². The contribution of the renormalization scheme is the matrix ð™½. Its combination with the matrix ð™¼ compensates for the statistical bias which is inherent in Least Squares solution (Kanatani 2008).

Least Squares choose ð² which minimizes the cost function ðœ–2 in Eq.(17). In renormalization scheme there is no explicit cost function which is minimized. The estimated ð² is obtained by solving a set of equations in order to reduce the dominant bias of optimally weighted Least Squares, such that it reaches Kanatani-Cramer-Rao lower bound (Kanatani 1996).

The fourth step of the above algorithm deserves more attention due to switching of the pseudoinverseâ€™s truncated rank. Based on type of the problem, typically, the rank of the pseudoinverse is kept constant during the renormalization scheme. For instance, that is the case in the most similar algorithm to ours for optimal Homography estimation of Kanatani et al. (2016). In that problem also three equations contribute to building the pseudoinverse of the weight matrix ðš†ð›¼ and this matrix is naturally of rank 2. This comes from the fact that only two equations out of three which go into this matrix are linearly independent. In our case, the situation is similar, but not that straightforward. The 3ð‘Ã—7 matrix ð™± in Eq.(12) has rank 6 with many linearly dependent rows. Each row triplet which goes into the matrix ð™± is created through the elimination of lambdas in Eq.(10). How the original equations from ðš‚, ð™¿ matrices are used for eliminating Î»â€™s depends on the structure of the matrix ð™¿ and noise conditions. This drops the rank, either in most cases to 2, but occasionally to 1. When not treating the edge case of rank 1 this way, the weight matrix for the corresponding triplet may get very large weights and may cause divergence. The ratio of 0.1 was achieved empirically in order to get good performance on all the tested sequences. We leave more rigorous theoretical understanding of this step for future work.

Jacobians
In order to compute the covariance matrix ðš…(ð‘ ð‘¡)0[ð›ð‘–ð‘—] in Eq.(15), the Jacobian matrices ð™¹(ð‘ )ð‘–ð‘— and ð™¹(ð‘¡)ð‘–ð‘— need to be computed. Each 7Ã—4 Jacobian matrix is factored into four matrices

ð™¹(ð‘ )ð‘–ð‘—=ð™¹(ð‘ )4ð‘–ð‘—ð™¹(ð‘ )3ð‘–ð‘—ð™¹(ð‘ )2ð‘–ð‘—ð™¹(ð‘ )1ð‘–ð‘—.
(23)
The first Jacobian captures the transformation of the point from homogeneous coordinates to the calibrated ray,

ð™¹(ð‘ )1ð‘–ð‘—=[1ð‘“ð‘–ð™¸2ðŸ¶ðŸ¶1ð‘“ð‘—ð™¸2]4Ã—4,
(24)
where ð‘“ð‘– stands for the focal length of the camera which observes ð®ð‘– and ð™¸ for the identity matrix.

The second Jacobian captures rotation of the vector. Denoting ðšÌƒ ð‘–=ðš0ð‘–ðšIMUC and ðšÌƒ ð‘—=ðš0ð‘—ðšIMUC, then

ð™¹(ð‘ )2ð‘–ð‘—=[ðšÌƒ ð‘–(:,1:2)ðŸ¶ðŸ¶ðšÌƒ ð‘—(:,1:2)]6Ã—4,
(25)
where ðšÌƒ ð‘–(:,1:2) is 3Ã—2 matrix composed of the first two columns of the rotation matrix ðšÌƒ ð‘–.

The third Jacobian captures the transformation to homogeneous coordinates. This would not be in general needed, however, from computational point of view, one avoids the need of derivative w.r.t. the ð‘Ìƒ ð‘§. Introducing this extra non-linearity is in practice not affecting the solution. Considering ð©Ìƒ ð‘–=ðš0ð‘–ðšIMUCð™ºâˆ’1ð®ð‘– from Eq.(2), then

	(26)
where ð©Ìƒ ð‘–=[ð‘Ìƒ ð‘–,ð‘¥ ð‘Ìƒ ð‘–,ð‘¦ ð‘Ìƒ ð‘–,ð‘§]âŠ¤, and ð©ð‘–=îˆº(ð©Ìƒ ð‘–)=[ð©âŠ¤ð‘–,(1:2) 1]âŠ¤.

The fourth Jacobian captures the Schur complement based elimination of Eq.(12),

ð™¹(ð‘ )4ð‘–ð‘—=[âˆ‚ð›(ð‘ )ð‘–ð‘—âˆ‚ð‘ð‘–,ð‘¥  âˆ‚ð›(ð‘ )ð‘–ð‘—âˆ‚ð‘ð‘–,ð‘¦  âˆ‚ð›(ð‘ )ð‘–ð‘—âˆ‚ð‘ð‘—,ð‘¥  âˆ‚ð›(ð‘ )ð‘–ð‘—âˆ‚ð‘ð‘—,ð‘¦]7Ã—4.
(27)
The second dimension of four is due to the trick with homogeneous coordinates in Eq.(26), otherwise, it would be six. It brings an important saving as computing this Jacobian is computationally the most demanding part of the whole algorithm. This Jacobian requires to access the whole matrix ð™±. Let us further investigate the partial derivative w.r.t. to the first component ð‘ð‘–,ð‘¥

âˆ‚ð™±âˆ‚ð‘ð‘–,ð‘¥=âˆ‚(ð™¸3âˆ’ð™¶)ðš‚âˆ‚ð‘ð‘–,ð‘¥=âˆ’âˆ‚ð™¶âˆ‚ð‘ð‘–,ð‘¥ðš‚,
(28)
as outcome from derivative of Eq.(11). It is analogous for the rest three components. Recall that ð™¶=ð™¿(ð™¿âŠ¤ð™¿)âˆ’1ð™¿âŠ¤. For any non-singular square matrix ð™° the following holds (Golub and van Loan 2013)

âˆ‚ð™°âˆ’1âˆ‚ð›¼=âˆ’ð™°âˆ’1âˆ‚ð™°âˆ‚ð›¼ð™°âˆ’1.
This allows to split inversion and derivative of the matrix. It can be computed only once as it is independent on the ð›¼. Since ð™¶ is a regular idempotent projection matrix, then we can apply it to get

âˆ‚ð™¶âˆ‚ð‘ð‘–,ð‘¥=âˆ‚ð™¿âˆ‚ð‘ð‘–,ð‘¥ð™¿Ìƒ ð™¿âŠ¤+ð™¿ð™¿Ìƒ âˆ‚ð™¿âŠ¤âˆ‚ð‘ð‘–,ð‘¥âˆ’ð™¿ð™¿Ìƒ âˆ‚(ð™¿âŠ¤ð™¿)âˆ‚ð‘ð‘–,ð‘¥ð™¿Ìƒ ð™¿âŠ¤,
(29)
where ð™¿Ìƒ =(ð™¿âŠ¤ð™¿)âˆ’1. The factors ð™¿Ìƒ ð™¿âŠ¤, ð™¿ð™¿Ìƒ  are computed only once for all the correspondences. The three partial derivatives are correspondence dependent as they depend on i and j. Since the matrix ð™¿ is very sparse and linear in ð©, the derivative matrices contain only few 1â€™s depending how often ð®ð‘– appears in the correspondence pairs. Overall, using factorization in Eq.(29) and sparse matrix calculus, the total Jacobian in Eq.(23) can be calculated very efficiently.

Renormalization versus Bundle Adjustment
In order to demonstrate performance of the renormalization w.r.t. to the optimal Maximum Likelihood estimator, we employ the Bundle Adjustement (BA) framework. We use the solution of Eq.(11) in Eq.(7) to compute Î»â€™s and we then average the multiple reconstructions per point to estimate the initial points ð—. The BA algorithm minimizes the total re-projection error âˆ‘ð‘–â€–ð®ð‘–âˆ’ð®Ì‚ ð‘–(.)â€–2, where ð®Ì‚ ð‘–(.) is the resulting non-linear mapping of ð¯0, ð 0 and the auxiliary variable ð—, while index i runs over all the observations. Note that our goal is to use a standard framework as a baseline to evaluate the performance of the proposed estimator. Therefore, we stay with the same and necessary parameters of velocity and gravity and we do not augment the set of unknowns with the sensor biases. To refine the parameters, the Levenberg-Marquardt algorithm is used, similar to the visual BA framework of Lourakis and Argyros (2005).

The renormalization, despite not being an optimal ML estimator, can in practical situations well replace BA, as will be demonstrated in Sect. 4. The accuracy of both methods is very comparable, but the computational burden differs. There are multiple advantages of the renormalization over BA, as the renormalization

does not need auxiliary variables to be introduced as are the 3D points ð— for BA.

needs no initial conditions. Renormalization in its first iteration starts with the Taubin (1991) method and then iteratively renormalizes the matrices. BA needs a good starting point.

solves in each iteration a generalized eigenvalue problem of size 7Ã—7 which is very fast and can be solved within microseconds. BA solves iteratively a linear system of normal equations of the matrices âˆ¼450Ã—450 in case âˆ¼150 feature points are tracked. Despite the sparsity of the problem, the computational time is by two magnitudes higher, and goes to milliseconds.

converges in no more than 2-5 iterations. BA needs typically at least 15 iterations.

provides the covariance matrix of ð¯0 and ð 0 explicitly without any extra computations and this is directly encoded in the matrix ð™¼ in Eq.(18). BA computes the covariance matrix implicitly.

provides an estimate of the noise level on the feature points in Eq.(22). In BA, one cannot explicitly estimate the noise level.

Accelerometer and Gyroscope Bias
Recall that we assume a calibrated device and any estimated offset has been removed from the IMU data. However, a small and slowly varying bias may still be present, while it can be modeled as a constant offset owing to the short integration time. For completeness, we show how the biases can be added.

As shown in Martinelli (2013), a constant accelerometer bias can be modeled in a linear way. Such a bias can be likewise inserted into the solver of Eq.(7), that is, ðœ…ðœ…ð‘–ð‘— can be replaced by

ðœ…Ì‚ ðœ…Ì‚ ð‘–ð‘—=ðœ…ðœ…ð‘–ð‘—+ðœðœð‘–ð‘—ðžð‘Ž
(30)
where

ðœðœð‘–ð‘—=(âˆ‘ð‘˜=0ð‘–âˆ’1ð›½ð‘˜,ð‘–ðš0ð‘˜âˆ’âˆ‘ð‘˜=0ð‘—âˆ’1ð›½ð‘˜,ð‘—ðš0ð‘˜)ð›¥ðœ22 ,
(31)
and ðžð‘Ž denotes the accelerometer bias. It is straightforward to show that ðœðœð‘–ð‘—â†’ðœ‡ð‘–ð‘—ð™¸ when the system does not rotate. As a result, ðžð‘Ž is not always identifiable, and separable from ð 0.

Instead, ðœ…ðœ…ð‘–ð‘—, ð©ð‘– and ð©ð‘— depend on the gyroscope bias in a non-linear way. The small bias magnitude let us though use a first-order approximation, that is, ðœ…ðœ…ð‘–ð‘— can be now replaced by

ðœ…Ì‚ ðœ…Ì‚ ð‘–ð‘—â‰ƒðœ…ðœ…ð‘–ð‘—+âˆ‚ðœ…ðœ…ð‘–ð‘—âˆ‚ðžðœ”ðžðœ”
(32)
and likewise

ð©Ì‚ ð‘–â‰ƒð©ð‘–+âˆ‚ð©ð‘–âˆ‚ðžðœ”ðžðœ”,
(33)
where ðžðœ” is the constant gyroscope bias and âˆ‚ðœ…ðœ…ð‘–ð‘—âˆ‚ðžðœ”, âˆ‚ð©ð‘–âˆ‚ðžðœ” are the respective Jacobians. Note that the gyroscope bias directly affects the rotation, that is, biased gyroscope data is integrated in Eq.(3). In order to compute âˆ‚ðœ…ðœ…ð‘–ð‘—âˆ‚ðžðœ”, some useful properties of the exponential map, see (Forster et al. 2017), thus leading to the following approximations

âˆ‚(ðš0ð‘–ð­ð‘–C)âˆ‚ðžðœ”â‰ƒâˆ’ðš0ð‘–[ð­ð‘–C]Ã—âˆ‚ðš0ð‘–âˆ‚ðžðœ”
(34)
and

âˆ‚(âˆ‘ð‘–âˆ’1ð‘˜=0ð›½ð‘˜,ð‘–ðš0ð‘˜ðšð‘˜)âˆ‚ðžðœ”â‰ƒâˆ’âˆ‘ð‘˜=0ð‘–âˆ’1ð›½ð‘˜,ð‘–ðš0ð‘˜[ðšð‘˜]Ã—âˆ‚ðš0ð‘–âˆ‚ðžðœ” ,
(35)
where

âˆ‚ðš0ð‘–âˆ‚ðžðœ”â‰ƒâˆ‘ð‘˜=0ð‘–âˆ’1ðšð‘–ð‘˜+1ð™¹ð‘˜ð›¥ðœ
(36)
with ð™¹ð‘˜ being the right Jacobian of SO3 at ðœ”ðœ”ð‘˜ (see Eq.(8) in Forster et al. (2017)). The notation [.]Ã— denotes the skew symmetric matrix. Based on Eq.(34), the Jacobian âˆ‚ð©ð‘–âˆ‚ðžðœ” can be computed by

âˆ‚ð©ð‘–âˆ‚ðžðœ”â‰ƒâˆ’ð™¹îˆºðš0ð‘–[ðšIMUCð™ºâˆ’1ð®ð‘–]Ã—âˆ‚ðš0ð‘–âˆ‚ðžðœ”,
(37)
where ð™¹îˆº is the Jacobian of the transformation îˆº(ð±) and is given by the first block of ð™¹(ð‘ 3)ð‘–ð‘— in Eq.(26).

When both the biases need to be modeled, Eq.(30) can be combined with Eq.(32), while the cross dependence of biases can be ignored.

Adding biases into the renormalization scheme by involving the above equations is rather straightforward. In short, in case of the accelerometer bias, the matrix ðš‚ in Eq.(7) would contain three additional columns before the last column of ðœ…ðœ…â€™s. The solution vector ð± would contain the unknown ðžð‘Ž. As entries into these columns do not depend on ð®ð‘–, nothing substantial changes. In case of the gyroscope bias, three extra columns would be again added into the matrix ðš‚ and the unknown ðžðœ” into the solution vector ð±. The entries into ðš‚ now depend on ð®ð‘–, see Eq.(33), so the matrix ð™± in Eq.(12) has different form. Its partial derivative in Eq.(28) needs to take into account the derivative of the matrix ðš‚ as well. The Jacobian in Eq.(23) changes to size 10Ã—4. If both biases are considered, the size of the Jacobian is 13Ã—4.

Kaiser et al. (2017) tested the robustness of Martinelli (2013) against biased IMU readings. As far as the accelerometer bias is concerned, when it is identifiable, the initialization remains unaffected. In particular, their experiments show that even large unrealistic bias magnitudes can be well compensated. Therefore, we only expect a minor refinement through the renormalization scheme.

On the contrary, the initializer may be affected from a gyroscope bias when its magnitude is relatively large and the integration time is long (Kaiser et al. 2017). However, the rolling-shutter camera allows short integration times and the initializer would not benefit much from modeling a gyroscope bias of low magnitude. As such, it is advised to leave estimation of the biases for the followed VIO system which considers much longer temporal window allowing to model their distributions more properly.

Experiments
The proposed modeling is valid with either a monocular or a multiocular sensor. What is different though is the integration time needed to reliably initialize the state, because the reliability grows with the number of images. The stereo baseline leads to larger camera displacements, which in turn leads to better visual constraint via triangulation. For instance, given two successive stereo frames, the displacement from the current left to the next left camera is most of the times smaller than the distance between the current left and the next right camera. Considering more frames or widening their baseline means increasing integration time of IMU signals. This in general would be preferable, however, it means gathering more noise and making IMU contribution less trustworthy. A stereo setup allows for a good trade-off, to utilize visual information even when the camera displacement is small and the integration time of IMU signals is short. The stereo setup has significant advantage such that even in case of no motion, the stereo baseline still allows that the triangulation constraint to be effective and to correctly estimate zero velocity. We provide comparison of mono vs. stereo to support these arguments, however, we stick in our experiments to the stereo setup as being practically much more interesting and a suitable option, and a de facto gold-standard in wearable smart glasses.

Synthetic Data
Fig. 4
figure 4
Synthetic noise analysis. The vertical error bars depict the standard deviation over hundreds of realizations at the particular ðœŽ across a whole sequence. The shorter error horizontal bars on the RNM and BA are from the estimated covariances, while the longer ones are the empirical ones, computed as standard deviation on corresponding errors

Full size image
Fig. 5
figure 5
Comparison of the naÃ¯ve LS method, its iterative reweight modification, Taubin method, and its iterative RNM modification. See Fig. 4 for more details on axis meaning

Full size image
In this section we perform quantitative synthetic analysis to investigate influence of noise on the final estimate of ð¯0 and ð 0. In order to get realistic data with ground truth (GT) structure and poses, we process data from Snap Spectacles glasses with IMU BMI160. States resulting from a Kalman filter on visual-inertial data play the role of GT states and high-order splines on the IMU data provide ideal gyroscope and acceleration readings, such that a continuous integrator perfectly interpolates between the states. The IMU data are then sampled at 800Hz and finally, noise and time varying biases are added based on the calibrated variances of the used device. The device was moved forward 9 m along a straight trajectory with repeatedly changing viewpoint rotation from left to right. The shape of the trajectory and velocity can be seen in Fig. 9c. We simulate a stereo camera with a baseline of 14 cm attached to the IMU. During the data acquisition, the glasses were shortly static at the beginning such that we could safely initialize the IMU state with the static motion assumption. It allows to integrate the signals to get the ground truth poses.

To produce the image correspondences, we generate 50 random feature points in the first left stereo image, assign them random depths in the range [1, 15] m and project the 3D points into the other views. We then perturb the feature points with Gaussian noise ðœŽ={0,0.1,â€¦,0.5}pixels, the accelerometer with standard deviation of 0.005msâˆ’2 and the rotations ðš0ð‘– computed from the gyroscope data with 0.02deg at random orientation. At each ðœŽ we repeat 100 random realizations. The evaluated errors are defined as the norm on the velocity difference vector and the angle between the gravity vectors, i.e.

ðœ–ð¯0ðœ–ð 0=â€–ð¯0âˆ’ð¯GT0â€–2,=âˆ (ð 0,ð GT0)
(38)
for one realization. We repeat the same procedure for each five-tuple of stereo images, which is slid along the whole sequence at 22 consecutive camera positions. In all the experiments, we use consecutive five stereo cameras at 10 fps. This means five tuple of images in 0.5 s and thus the movement of 0â€“0.3 m.To show the final statistics, at each ðœŽ we compute mean and standard deviation.

Recall that the visual constraints are fed into the solver in Eq.(7) as image pairs, as shown for ij, ik, kl. Let us denote the cameras in the order: first left, first right, second left, second right and so on as {L1,R1}, {L2,R2}, {L3,R3}, {L4,R4}, {L5,R5}. Then we feed the following camera pairs into the matrix: L1âˆ’R2, L1âˆ’R3, L1âˆ’R4, L1âˆ’R5, L2âˆ’R3, L2âˆ’R4, L2âˆ’R5, L3âˆ’R4, L3âˆ’R5, L4âˆ’R5. We experimented with various combinations, and chose this as a trade-off between speed and accuracy. In case of a mono camera, the links would be between L cameras only.

The results can be seen in Fig. 4. We compare three methods, (i) the Least Squares of Sect. 3.3, LS, (ii) the proposed renormalization of Sect. 3.5, RNM, (iii) Bundle Adjustment as ML with Levenberg-Marquardt, BA, detailed in Sect. 3.6, initialized by LS. Initializing BA by RNM rapidly speeds up the convergence, but does not improve the accuracy. For the two latter methods, RNM and BA, we can compute standard deviations of the estimated ð¯0 and ð 0 from the theoretical covariance matrices. For RNM, see Eq.(22), for BA, see Eq. (A6.10) (Hartley and Zisserman 2004). They both require knowing the noise level ðœŽ, see Eq.(13). To fairly compare, we set it to the ground truth ðœŽ at which the corresponding simulation is performed. However, we confirmed that the estimated noise level ðœŽ by the renormalization in Eq.(22) is very tight to the ground truth. As can be seen, the theoretical values are very well aligned to the empirical ones and can be well utilized in practice, to know how much to trust the final estimate.

As expected, LS is by far the worst estimation, fairly improved by the renormalization, and very slightly polished by ML of BA. Moreover, renormalization returns estimate of the noise level of the feature detector/tracker. Due to perturbation with the ideal Gaussian noise, the minimization of the re-projection error is a perfect Maximum Likelihood estimate. Using real data, this might be slightly violated and the BA is not ML in its strict sense. We will see that with the real data it may result in RNM sometimes outperforming BA.

Fig. 6
figure 6
Effect of Global Shutter (GS) versus Rolling Shutter (RS) camera modeling. Solid lines show the baseline LS method of Martinelli (2013), our proposed RNM method, and the BA when GS camera model is used on RS camera data. Dashed lines represent the correct modeling from Fig. 4, review it for more details

Full size image
Fig. 7
figure 7
Mono versus Stereo. Solid lines show the baseline LS method of Martinelli (2013), our proposed RNM method, and the BA when monocular camera is used. Dashed lines represent the stereo camera setup from Fig. 4, review it for more details

Full size image
LS Variant Methods
We show the performance of the proposed renormalization method in comparison to previously introduced techniques which improve the naÃ¯ve LS. First, the well known iterative modification of LS (Iterative Reweight or weighted LS) is tested. The Iterative Reweight sets the matrix ð™½ in Eq.(20) to identity matrix. Second, the Taubin method, where both weights ð‘¤(ð‘ ð‘¡)ð›¼ in Eq.(18) and Eq.(19) are dropped. Recall that the presented renormalization is its iterative modification. This experiment validates the claim of Kanatani (2008), that the error on the estimated entities can be sorted as naÃ¯ve LS > weighted LS â‰« Taubin > renormalization, see Fig. 5. Both LS and Taubin are both non-iterative methods which are interesting when computational resources are limited. The plots give intuition how much accuracy can be gained when running 5 iterations. Each additional iteration costs the same as the iteration of the baseline method, i.e. of LS for iterative reweight and of Taubin for the renormalization.

Global vs. Rolling Shutter
We show in Fig. 6 the systematic error, imposed by using Global Shutter camera model on Rolling Shutter camera imagery. GS camera is modeled such that a whole frame is assigned one single pose, the rotation and the translation of the middle row of the RS image. As already stated, we used trajectory reported in Fig. 9c where the average velocity is roughly 0.7 m/s. Our proposed method demonstrates superior and still a reasonable performance also in this case when the camera model does not fully explain the data. In connection to VIO systems, the fact that neglecting the RS effect in camera modeling yields drift even for moderately moving walking sequences has been shown by Li et al. (2013); Patron-Perez et al. (2015); Schubert et al. (2018, 2019).

Mono vs. Stereo
We compare in Fig. 7 a mono to a stereo camera case with the same frame rate, that is, the same integration time. As can be seen, the monocular case is much more sensitive to noise on the image points. Note that in common use cases a camera moves forward with epipoles being close to the image center which makes the triangulation weakly constrained. To overcome this, it would require to decrease the frame rate and thus to increase the integration time which may, however, gather too much noise. The stereo setup on the other hand keeps the visual constraint still well enforceable, independently on the motion, and provides much superior performance. Note that renormalization and BA in comparison to LS still deliver meaningful results even for the mono case, although BA needs 4 times more iterations.

More vs. Less Frames
We show in Fig. 7 comparison of more vs. less frames used for all three methods. Less frames means to still use five stereo camera frames, but considering only the pairs with the first camera only, i.e. L1âˆ’R2, L1âˆ’R3, L1âˆ’R4, L1âˆ’R5. For LS and RNM it means 4 frame pairs instead of 10 which yields less entries into the input matrices ðš‚ and ð™¿ in Eq.(7). For BA it means 5 observations per 3D point instead of 8. Less constraints imply lower accuracy, however, RNM and BA gain a speed-up of 3Ã— and 1.2Ã—, respectively, for a small accuracy drop. Important note is that the proposed RNM does not need that many observations as LS due to the proper weighting which suppresses less confident measurements. The baseline LS needs many more observations to statistically cancel the noise instead Fig. 8.

Fig. 8
figure 8
More vs. Less frames. Solid lines show the baseline LS method of Martinelli (2013), our proposed RNM method with 4 pairs, and the BA when 5 frames are used. Dashed lines represent the stereo camera setup from Fig. 4 with 10 frame pairs and 8 frames, respectively

Full size image
Table 1 Quantitative results. Each column shows the name of the sequence, type of the motion, mean of the absolute distance error on the initial velocity / mean of the angular error on the gravity to the baseline Least Squares method LS in Eq.(38). For the RNM and BA improvements in percentage are shown
Full size table
Synthetic experiments presented in this section allow us to perform noise perturbation analysis and to give the reader better intuition on different configurations. We skip such detailed comparisons for real sequences, as we see analogous behavior which leads to the same conclusions. Therefore, for following qualitative as well as quantitative results on image sequences we use the best configuration, i.e. RS stereo with more frames.

Rendered Data
We perform qualitative comparison on realistic rendered image data, as this gives us perfect ground truth to compare to. We deploy Unreal Engine of Epic Games (2019) for rendering the images. We obtained the trajectories and the IMU data the same way as described in the previous section, for various types of walking trajectories of Snap Spectacles glasses. We simulate two virtual VGA rolling shutter cameras with noisy sensors, with the baseline of 14 cm, and readout time of 10 ms. As an input into the initializer, the IMU data is perturbed by Gaussian noise and biases on accelerometer and gyroscope with random walk noise. The features are detected by the FAST corners of Rosten et al. (2010) and further tracked by the ECC tracker of Evangelidis and Psarakis (2008). In order to prune outliers we use vanilla RANSAC with the minimal solver of Sect. 3.4. To confirm the feasibility of the statistical assumption, we plot the error distribution of the tracked features which can be obtained through known depth values of the rendered images. As the Fig. 3 depicts, the distribution is Gaussian with subpixel accuracy. Based on this observation, we believe that Gaussian distribution on the image correspondences is a reasonable assumption , Table 1.

We report quantitative results in 1 for the six sequences, shown in Figs. 9, 10, and 11. The â€œforwardâ€ trajectory is shown in Fig. 9, the â€œloopâ€ trajectory in Fig. 10. The â€œfast shakingâ€ trajectory is 0.5 m wide left-right shaking motion with rapid acceleration and average velocity of 0.9msâˆ’1. The â€œfor/back-wardâ€ trajectory is 14 m straight forward, followed by 180âˆ˜ turn and back to the start with the average speed 1.8msâˆ’1. We captured these typical motions of a person when wearing smart glasses when moving in the office space shown in Fig. 12.

We present detailed qualitative results for two sequences. The first sequence, SUBWAYTRAIN is a forward 9 m long sequence inside a static subway train, see Fig. 9. The second sequence, TRAPCAM is a loop shaped 25 m long sequence outdoors, see Fig. 10.

The results confirm the observation from the Synthetic experiment that LS method can be improved by the renormalization RNM which is comparable and sometimes better to ML estimation of BA. In most cases, the initial velocity ð¯0 and gravity ð 0 are both improved w.r.t. the LS, and this by roughly 20% and 8%, respectively. This is a significant improvement.

Fig. 9
figure 9
SUBWAYTRAIN sequence. a The first and b the last left stereo image of the sequence. c Shape of the trajectory (top) and magnitude of the velocity during the motion (bottom). d The distance error of the estimated and the ground truth initial velocity ð¯0 (top). The angular error of the estimated and the ground truth gravity ð 0 (bottom)

Full size image
Fig. 10
figure 10
TRAPCAM sequence. Left stereo image (a) at the start and (b) in the middle of the sequence. See Fig. 9 for the remaining caption

Full size image
Real Data
We use real data from the Snap Spectacles glasses, as stereo images as well as IMU readings. We do not posses ground truth for these sequences. Instead, we run a typical VIO system based on the temporal Extended Kalman Filter, similar to Mourikis and Roumeliotis (2007); Li et al. (2013). The filter framework fuses inertial and visual data in iterative updating procedure for maximum a posteriori probability of a linear dynamical system. The filter uses a strong prior that the sequences are static at the beginning, copes with a rolling shutter stereo camera and optimizes also for both accelerometer and gyroscope biases. For the proposed solver, though, we do not include the biases as we found that their magnitude is low in the used device.

The first is the OFFICELOOP, a loop-shaped 25 m long sequence in a typical open space office. Since there is only negligible drift between the end and starting position, we can consider the used VIO as a reasonably accurate baseline to compare to. The second WALK is a forward 36 m long sequence outdoors. Both sequences are acquired during a walk.

Fig. 11
figure 11
Example images of the rendered sequences

Full size image
The results align with the previous synthetic and rendered experiments; the renormalization RNM is similar to ML estimation of BA, both outperforming the Least Squares LS. As mentioned, we do not have the ground truth and the comparison for these sequences might not be representative. What should be noticed and taken from these results is that the renormalization and ML estimator perform very similarly to each other, although, arriving to the solution by different means.

Complexity
The renormalization scheme and Bundle Adjustment require different operation flow which yields different complexity. We give hints to the expected performance by pinpointing the most time consuming parts during the computations.

Fig. 12
figure 12
OFFICELOOP sequence. Left stereo image (a) at the start and (b) in the middle of the sequence. Trajectory is the same as in Fig. 10c. See Fig. 9 for the remaining caption

Full size image
Fig. 13
figure 13
WALK sequence. Left stereo image (a) at the start and (b) in the middle of the sequence. See Fig. 9 for the remaining caption

Full size image
Renormalization
Complexity of renormalization is driven by computation of the partial derivatives in Eq.(29) which is needed for the covariance matrix in Eq.(15) to fill ð™¼ and ð™½ matrices. The involved matrices in Eq.(29) are sparse with derivatives of ð™¿ consisting of a few ones (4 entries for a point tracked in 5 frames). Taking this into account yields many savings in computation. The generalized eigenvalue problem on 7Ã—7 matrix itself is negligible, and typically only 3 iterations suffices Fig. 13.

Bundle Adjustment
Complexity in Levenberg-Marquardt optimizer is spread roughly equally into three parts. First, building a sparse linear system of normal equations with 2ð‘Ã—(3ð‘€+6) matrix and its corresponding right hand side vector, where N is the number of observations and M the number of auxiliary 3D points. Second, making the matrix square by left multiplying with its transpose. Third, running a sparse linear solver. Typically, 15 iterations are needed.

With our MATLAB implementations, the tests on the presented rendered and real sequences show that the RNM method takes on average around 70% of the time of BA, depending on the number of considered frame pairs and length of the tracks. Our C++ implementation of the baseline LS method takes on average âˆ¼6ms and of BA âˆ¼25ms on an i7@2.6GHz CPU, given input inlier observations, considering five stereo frames with their pairing detailed in 4.1.

Conclusion
We presented a novel way to solve the initialization problem of the inertial-visual odometry system. We derived a novel solver through proper statistical modeling and we cast the problem into the renormalization scheme of Kanatani. We incorporated proper noise propagation thus yielding a solution which exhibits higher accuracy over the original Least Squares solution. The extensive evaluation shows that the renormalization scheme performs very closely to the ML estimator which is statistically optimal in case of Gaussian noise. As such, the renormalization can serve to get a very good initial point for the ML, or fully replace it, as the additional improvement is rather small for the cost of more computations.

With this paper, we add a new problem into the set of problems in Computer Vision which can be beneficially solved by the renormalization scheme. As the set of problems where the renormalization improves Gold Standards grows, the renormalization scheme is slowly finding its way into the Computer Vision community.