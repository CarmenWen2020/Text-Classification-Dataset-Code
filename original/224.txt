Strategies aimed at keeping the user's interest in using computer applications are being studied to provide greater user engagement, and can influence how people interact with computers. One of the approaches that can promote user engagement is Affective Computing (AC), based on the premise of recognizing the user's emotional state and adjusting the computer application to respond to such state in real-time. Although it is a relatively new area, over the past few years many research works have investigated the use of AC in various activities and objectives. To provide an overview on the use of AC in computer applications, this article presents a systematic literature review based on available articles on the main scientific databases of the Computer Science area. The main contribution of this review is the analysis of different types of applications. Based on the 58 articles analyzed, the main emotion recognition techniques and approaches to the adaptation of computer applications, as well as the limitations and challenges to be overcome were compiled. Our conclusions present the limitations and challenges still to be overcome in the area of automatic adaptation of computer applications by means of AC.

SECTION 1Introduction
Considering the increasing presence of technological devices in people's lives, one of the concerns of Human-Computer Interaction (HCI) researchers relies on providing forms and techniques that optimize the process of software interaction. One of the main approaches in this regards is the software adaptation, which can be made based on techniques such as user-centered design [1] or emotion recognition, among others. Such strategies are characteristics that are able to influence action and the decision-making in human beings.

The importance of the user's emotional state has been studied by professionals and researchers of several areas. In Computer Science, researchers investigate the consequences of the user's emotional state during the use of software to enhance the user's experience [2]. Affective Computing (AC), a term proposed by Picard [3], aims to define techniques that allow computational systems to recognize and react to human emotions with the help of computer interfaces.

Additionally, some researchers believe that if a device can understand and physiologically express an emotion, it will be possible to stimulate emotions on users [4]. In [5] the authors reinforce the importance of this investigation by pointing out that many users interact with computers as if such devices were also human beings.

The possibilities provided using AC attract the interest of many HCI researchers [6], especially due to the promising proposal to enhance the use experience of computational systems. Usually, the AC applications consist of adapting software according to the user's emotional state and content recommendation [6], [7]. However, AC techniques have been studied in several scenarios, such as the detection of a student's frustration [8], the adaptation of educational virtual environments [9], in recommendation of products or services [7], and the emotion recognition robots designed to assist people with special needs [10].

Although other literature reviews have already been published on this subject [6], [11], they are usually focused on a minor scope. However, in this article the differential is the analysis of research works that discuss both emotion recognition and manners to adapt the software, but not limited to such approaches, which allows achieving greater cohesion between the steps involving the use of AC. Additionally, such reviews were made a long time ago. Thus, new techniques, approaches and challenges might have appeared as a result of past years’ scientific and technological advances. In this sense, although in [12] a recent literature review about the use of affective adaptation in computer games is presented, the scope limitation might disregard important investigations in other software domains. For this reason, the review presented here is more comprehensive, while addressing more in-depth topics such as emotion recognition techniques and adaptation methods.

Considering the possible effects of using AC to improve the quality of HCI, as well as the aforementioned scenario, the goal of this article is to present a systematic review about the use of AC techniques for software adaptation or computational content, thus discussing emotion recognition techniques and methods for the adaptation of software in real-time.

The remaining content of this paper is divided into the following sections: the concepts of AC and software adaptation are discussed in Section 2. Section 3 presents the systematic review protocol. Techniques for emotion recognition and approaches for adaptation of software are presented in Sections 4 and 5, respectively. A discussion about affective adaptation aspects is presented in Section 6. The limitations and challenges found are presented and discussed in Section 7. The conclusion of this paper is presented in Section 8.

SECTION 2Concepts
2.1 Affective Computing
The term “Affective Computing” was originally coined by Rosalind Picard [3], who defined it as the area that studies how computational systems can recognize and react to human emotions, expressing them by means of a computational interface. This field of study considers two important characteristics in relation to human emotions: the capacity to recognize another individual's emotional state and the social experience in which the individual has the feeling that his/her emotional state is understood by other people [13]. Research works have also pointed out the fact that psychological factors influence decision-making and how human beings interact with each other. In [5] it was verified that human beings often interact with computers considering that these devices are also human and, therefore, they would be able to recognize their emotions.

Benefits that could be reached by using AC concepts have attracted the attention of many researchers, especially those doing research on HCI [6]. The effects perceived by the use of AC concepts in software have led many researchers to study their effects in different scenarios, such as the personalized virtual educational environments [9], the detection of student's frustration during the learning process [8], the generation of anthologies for the recommendation of services or products [7] and, more recently, the emotion recognition in robots intended to assist people with special needs [10] and decision-making as per the population's wish in smart cities [14].

In a hypothetical situation, knowing the user's emotional state enables to develop software that considers this information in order to, for example, recommend the most adequate content. For example, a movie content provider could recommend to the user a comedy film when he/she is sad. This type of approaches usually makes human-computer interaction more interesting, enjoyable and affective.

Additionally, such software interventions are very important because they allow, among other factors, the software to adapt to the user, while generally the user must adapt to the software. Personalization tends to enable the user to take better advantage of the software resources. In some specific cases, such as software used in rehabilitation processes, the adaptation according to the user's emotional state is even more important for considering that an exaggerated level of difficulty or an inadequate situation can make the user take the wrong way or even cause complications to his/her health state. Thus, the main uses of AC consist of personalized software that is based on the user's emotional state, significantly expanding the user experience [4], in addition to the recommendation of products based on the individual's profile [15]. The AC concepts can, for example, be applied in games adapted to the user's profile [16].

2.2 Automatic Adaptation of Software
Software adaptation is a way to ensure that the software is adjusted to the users’ needs. A common use of adaptation are the tools to personalize web pages that allow the user to change, for example, font size and background color for better readability, among other characteristics. Although simple, these adaptations allow people with different visual abilities to read the content published. However, the adaptation exemplified is not automatic: it is necessary that the user learns to configure the adjustments. The user experience would be optimized if the web browser could recognize the user's difficulty in reading and then automatically made the necessary adjustments to font size or background color.

This type of automatic intervention is called self-adaptation [17]. According to Oreizy et al.[17], self-adaptive software is that which modifies its behavior in response to changes in its operating environment, which encompasses the user's inputs up to external devices such as sensors, for example. However, as pointed out in [18], currently there is no consensus among researchers about the terms to be used in relation to software adaptation. Many terms are used to name systems with such characteristics, which imply some difficulty to categorize the research works and analyze the scientific development in this area. The proposal presented in [18] differentiates an adaptive system from an adaptable system. While adaptability is defined as a system with the capacity to adapt in response to external interventions, in a non-active participation of the system, adaptability is a characteristic of a computational system that allows it to perform autonomous updates, without the intervention of external agents [18], [19].

The automatic adaptation of software also makes the system to recognize — without any intervention by the user — the user's difficulties, it then takes the necessary measures to enhance the user experience. However, there are numerous difficulties to develop self-adaptive software. One of the main hurdles is the need to consider that the adaptation to be made depends on each type of software. A social network application will most likely be adaptation that is different from the adaptation to be made in an educational environment, for example.

However, it should be noted that the benefits resulting from automatic software adaptation can be extremely advantageous, especially in contexts in which the user's involvement with the application is crucial to reach the software's objectives. This area has prompted investigations that seek to find different techniques and approaches that allow the automatic software adaptation. In general, such adaptations collect data for the interaction to check the user's behavior while using the system or infer the user's emotional state, which occurs when AC techniques are used.

SECTION 3Materials and Methods
The Systematic Review (SR) presented in this article was conducted in three steps – Planning, Selection and Critical Analysis of Results, as suggested in [20]. In the first step (Planning), we defined a protocol and the research questions presented in Table 1.

TABLE 1 Research Questions Defined in the Protocol
Table 1- 
Research Questions Defined in the Protocol
To gather elements to define the research protocol, an exploratory analysis was carried out using Google Scholar [21] to identify articles that could present AC concepts and techniques, based on the model shown in [20]. These articles were used as a control group and contributed to the definition of keywords and sources that would be used in the search.

The following Search databases were defined: IEEE (Institute of Electrical and Electronic Engineers) [22], ACM (Association for Computing Machinery) [23], PubMed [24] and Scopus [25]. We adopted the following keywords: affective, computing, game, adaptation, adaptative, adaptive.

In the Selection step, we adopted the following inclusion (I) and exclusion (E) criteria:

(I1) Articles that address the affective adaptation of software or games, explaining from emotion recognition up to the adaptations made;

(I2) Articles published and fully available on scientific databases;

(E1) Articles that did not use AC techniques;

(E2) Articles that did not use such techniques for the adaptation of software/games.

Additionally, we defined the following quality criterion: only works that clearly describe the methodology process of emotion recognition (including the techniques considered) and/or the adaptation approach were included. This criterion was applied in the Extraction step, during the full reading of the text. In Table 2, the studies [26], [27] do not present a technique. However, we decided to include them because the authors propose interesting models to support the development of affective computing applications. There are not techniques because no implementation was presented. However, all the steps necessary for implementation are available in these papers. The protocol is available at http://e.usp.br/bjt.

TABLE 2 Included Articles in the Systematic Review
Table 2- 
Included Articles in the Systematic Review
During the SR, 2,179 articles were found (363 duplicated). During the Selection step, 137 articles were approved. Next, during the Extraction step, 79 articles were excluded, thus a total of 58 articles were included. Fig. 1 shows the steps of this process. It is important to emphasize that the objective of this SR is to analyze studies that use emotion recognition in software adaptation. In fact, there are many articles that describe only emotion recognition techniques or strategies to adapt software automatically, but they did not meet the criteria established in the protocol.


Fig. 1.
Overview of the systematic review process.

Show All

Similarly, some articles investigated affective adaptation with manual interventions [28], [29], which is also outside of the context of this review. Also, in articles such as [30], the affective adaptation consists of a simulation, carried out in the exclusion of this type of article. These facts explain the difference between the number of articles found in the Selection step and the number of included articles in the Extraction step.

Table 2 presents the main data extracted from the included articles.

SECTION 4Emotion Recognition Techniques
There are several techniques that allow recognizing the emotions expressed by an individual. In the classification suggested in [87], the emotion recognition techniques fall under two categories: based on visible inputs (BVI) and based on invisible inputs (BII). Visible inputs are those that can be observed with the naked eye, without the use of computer or technological resources. Techniques based on invisible inputs, in turn, analyze mainly signals and electrical impulses, leading to the use of specific sensors. In [88], the techniques are classified as intrusive or non-intrusive. In the first category, sensors tend to be far from the users, avoiding inconveniences; in the second category, the user's body is generally in direct contact with the sensors.

There is not necessarily a direct relationship between the two taxonomies proposed. The technique based on visible signals can be classified as intrusive or non-intrusive. For example, the monitoring of gestures can be non-intrusive if it uses a camera located far from the user, but it can be intrusive if the camera is attached to the user's body. In this review, we will detail the techniques mentioned on the articles included, considering the classification as visible and invisible inputs.

In the next sections, according to the information found in the articles, we will present more details about these emotion recognition techniques. It is important to emphasize that the emotions recognition techniques that we present in this section are the most used techniques cited by the included articles. They are not necessarily the best or the most efficient techniques. It is possible that the use of some techniques (facial expressions analysis, for example) can be explained by the ease or availability of software libraries for this purpose. More aspects about this will be discussed in Section 6.

4.1 Techniques Based on Invisible Inputs
This category gathers emotion recognition techniques that capture unavailable visual information. In general, these techniques use sensors attached to the user's body. Because of the sensors are in contact with the user's body, their use may cause discomfort or feel awkward.

The main BII techniques for emotion recognition consist of the analysis of electroencephalogram, electrocardiogram and analysis of the electrodermal activity.

4.1.1 Analysis of the Electrodermal Activity
The analysis of the electrodermal activity (EDA) was identified in 36 percent of the included articles (21 articles). This technique enables obtaining the skin conductance level and the level of galvanic skin response. These signals are generated by the electrical activity of glands that produce sweat in the fingertips and palms, identifying situations that trigger the user's stress.

While in [39], [41], [42], [43], [44], [45], [52], [53], [61], [65], [66], [67], [68], [69], [70], [72], [74], [75], [76], [78], [80] EDA was used together with a set of other techniques (such as electrocardiogram) to measure the user's emotional state, only one study [53] used this information as the single data source.

In this context, the authors in [70] justify their choice for EDA declaring that this “is one of the most reliable and usable psycho physiological parameter of the human body for monitoring the emotional state”. This is an interesting consultation, but it is noteworthy that in [53] the authors state that, although EDA is a great emotion recognition technique, the place where the sensor is located influences data capture, suggesting that an analysis of the heart rate should be used together with EDA to amplify the data accuracy.

4.1.2 Analysis of the Electrocardiogram
The heart rate captured by electrocardiogram (ECG) was used to indicate the user's emotional state in 31 percent (18) of the total of articles [39], [41], [42], [43], [45], [52], [59], [60], [61], [65], [66], [67], [68], [69], [71], [73], [74], [80].

Despite its wide use, only in [73] and [71] ECG was used alone. Most of the works used this signal together with other data, specifically the analysis of electrodermal activity. In [73], the authors state that the ECG was used particularly because of the need to obtain the R peak, characterized by the authors as the most important characteristic of the ECG signal. The interval between two R peaks allows measuring the period between heartbeats.

In [43] the authors state that it is impossible to prevent recognizing the wrong emotional state in some situations. However, they highlight the recommendation to use more than one technique or processing methodology of physiological signals, such as the grouping of facial expression and physiological signals usually increases the accuracy in recognizing emotions, which justified the grouping of techniques reported by the articles.

4.1.3 Analysis of Electroencephalogram
A technique little used in the analyzed studies, found only in 19 percent (11) of the articles, the electroencephalogram (EEG) enables recording brain activity. The data capture occurs by the reading the information issued by sensors placed on the user's scalp. There are some difficulties related to the use of EEG such as, for example, fixing the sensors in the correct location.

In the context of AC, there are few models that allow inferring the emotions considering the signals obtained by the EEG, classifying them according to the rules. In the articles analyzed in this review, the EEG was used as the single data input in 12 percent of the analyzed articles [51], [55], [56], [57], [62], [77], [81], and it was used together with other techniques in [59], [60], [63], [78] (7 percent of the analyzed articles). In [59] the authors concluded that the heart rate analysis was more accurate than the data analysis obtained with the EEG.

4.1.4 Other Techniques
Other techniques that are more rarely cited in the articles analyzed are:

Respiration Analysis (RA): this approach considers data regarding the user's respiration, such as the ratio of expiration to inspiration. It was used in 6 articles (10 percent) [44], [45], [72], [80], [82], [84]. In most cases, this technique was used coupled to other techniques, such as EDA and ECG. Only in [82], [84] RA was used alone for affective adaptation;

Electromyography (EMG): technique that allows evaluating the electrical activity produced by skeletal muscles. The use of EMG was identified in [39], [58], [61], [74], [78], which corresponds to 9 percent of the total of articles included. In all the three cases EMG was used together with EDA and ECG;

Electrooculography (EOG): identified only in [45], EOG is a technique that allows measuring eye movements. In this article EOG was used together with ECG, EDA and RA [45];

Photoplethysmogram (PPG): identified only in [72], this approach considers the size of an organ. It was used coupled to EDA and RA to infer the user's motivation level. In this work the authors explain that the sensor used to collect these data was not invasive;

Hemoencephalography (HEG): aimed to measure the blood oxygenation, this technique was used in [47], together with techniques to measure user behavior (Section 4.2.3).

4.2 Techniques Based on Visible Inputs
The main advantage of the techniques based on visible inputs (BVI) relies on the fact that usually they do not require the user to be in direct contact with a sensor. In this type of technique, the users’ emotional state is usually recognized by their facial expression, speed of mouse and keyboard handling, behavior in the virtual environment, and other factors.

4.2.1 Analysis of Facial Expressions
Facial expressions (FE) can be considered as the most common form of body language [87] and are induced by the human emotion [89]. Emotion recognition with the analysis of facial expressions is possible by models that use moving control points on the human face to form the facial expression of an emotion. The location of such control points enables inferring the user's emotional state. An example of this model is the Facial Action Coding System (FACS) [90].

Among the articles analyzed in this review, 24 percent (14 articles) use facial expressions as input data [35], [36], [38], [42], [46], [49], [54], [64], [70], [75], [76], [79], [85], [86]. Each article considered a different approach to classify the data collected, but it is noteworthy that [42] and [38] used software developed by a third-party, such as FaceReader [91] and Realtime FaceDe-tector (provided by Fraunhofer Institute for Integrated Circuits [92]), respectively, to analyze the facial expression and identify an emotion. The use of third-party software can reduce the implementation cost, as discussed in Section 6.

Although it is an advantageous technique because it does not require the user to have direct contact with a sensor, some studies show that emotion recognition by facial expressions might not exhibit high accuracy, as different individuals can express emotions in different ways. However, this assertion is refuted by the theory of FACS [90], who states that individuals move the same control points for the same emotions. Therefore, the lack of accuracy might be caused by a failure on the algorithms or due to the intrinsic characteristic of image acquisition, such as low resolution or inadequate lighting.

4.2.2 Recognition by Analysis of Activities with Mouse and Keyboard
This category encompasses 9 percent (five) of the articles, where information about the individual's emotional state are obtained based on the typing speed, movement speed, and firing rate of the mouse buttons (clicks), among other factors related to the individual's interaction with mouse and keyboard (IMK).

The feasibility of using data interpretation related to the use of mouse to measure the emotional state together with other techniques was investigated in [32]. In [48] the data input by the keyboard was considered, and an algorithm analyzed information such as typing speed and the number of words to classify an emotion. The analysis of text input was also carried out in [59], [60] to classify the user's emotion.

In [63], mouse events were considered, together with the physiological signals, to measure the user's emotional state in a case study in which the PacMan game was adjusted according to the user's emotional state.

4.2.3 Other Techniques
Other techniques less frequently cited in the articles analyzed are:

User Behavior (UB): identified in only 9 percent (five) of the articles, User Behavior (UB) technique analyzes the user's behavior while using the system [31], [34], [40], [47], [85]. The use of this technique is generally supported by Artificial Intelligence tools that allow inferring the users’ emotional state from their actions in the system, such as, for example, the performance of certain functions and total of hits, in the case of games;

Gesture Recognition (GR): the recognition of gestures to decide on a person's emotional state was used in 7 percent (four) of the articles included. In [32], the authors considered the recognition of gestures together with physiological signals and interpretation of mouse events. In [54] voice recognition and facial expression analysis were used together with GR. In [33] and [37], in turn, the recognition of gestures was the unique input considered. According to the authors, the latter exhibited high accuracy, and the emotional state of children was accurately measured in over 82 percent of the cases, thus a promising technique. However, there are no recent articles using this technique to measure the emotional state;

Voice recognition (VR): identified only in 5 percent (three articles) [46], [54], [83], VR is a technique that can be easily used, especially in software where voice command is regarded as a means of interaction. According to [93], about 30 factors such as frequency and intensity can enable identifying emotion in the voice. None of the articles analyzed in the review used exclusively voice recognition. The authors of [46] considered the use of facial expression recognition together with VR;

Textual analysis (TA): used only in [50], the TA technique analyzes the text typed by the user to infer the emotional state. The study shows that by using classifiers, the number of emotions that can be identified is inversely proportional to the recognition accuracy, i.e., the higher the number of emotions to identify, the lower the recognition accuracy. This is noteworthy because it shows that, possibly, there are subtle differences among certain emotions and discrepancies among certain emotions, which usually complicates recognizing the emotional state;

Eye tracking (ET): consists in obtaining information by monitoring the user's gaze. Identified only in [32], eye tracking was used together with other techniques, including BII techniques.

4.3 Coupling Techniques to Recognize Emotions
One of the factors that may have stimulated the development of investigations involving BII techniques is the creation of new sensors, possibly cheaper and more comfortable for the user. However, it is noteworthy that the two modalities are still studied and, in some cases, used together, which shows the feasibility of both approaches.

Fig. 2 shows the use of more than one technique in the articles. In this figure, the bubbles contain the number of articles that used the techniques expressed in X-axis and Y-axis. Initially, it is possible to identify that 14 articles used ECG with EDA. This can be explained by the fact that the use of more than one technique can provide more accuracy in emotion recognition, resulting in a better quality of the affective adaptation.

Fig. 2. - 
Use of emotion recognition techniques in the reviewed studies. The size of the bubbles indicates the number of articles that combine the techniques presented in each axis. Legends: Electrodermal activity (EDA), Electrocardiogram (ECG), Electroencephalogram (EEG), Electromyography (EMG), Respiration Analysis (RA), Electrooculography (EOG), Photoplethysmogram (PPG), Hemoencephalography (HEG), Facial expressions (FE), Interaction with mouse and keyboard (IMK), User Behavior (UB), Gestures Recognition (GR), Voice recognition (VR), Eye tracking (ET).
Fig. 2.
Use of emotion recognition techniques in the reviewed studies. The size of the bubbles indicates the number of articles that combine the techniques presented in each axis. Legends: Electrodermal activity (EDA), Electrocardiogram (ECG), Electroencephalogram (EEG), Electromyography (EMG), Respiration Analysis (RA), Electrooculography (EOG), Photoplethysmogram (PPG), Hemoencephalography (HEG), Facial expressions (FE), Interaction with mouse and keyboard (IMK), User Behavior (UB), Gestures Recognition (GR), Voice recognition (VR), Eye tracking (ET).

Show All

Additionally, we noted that GR, VR and ET were utilized with only BVI techniques, while FE and IMK were used with both types of techniques. In the first case, it is possible that these articles consider that the software may not be invasive or uncomfortable for the user. In the second case, when BVI techniques were used with BII techniques, possibly the most important aspect was to improve emotion recognition accuracy and not the user's comfort.

4.4 Techniques and Application Areas
Fig. 3 presents the relationship between techniques to recognize the user's emotional state and the application areas of the articles analyzed. Only articles that have shown applications in certain areas were considered in this graph.


Fig. 3.
Relationship between emotion recognition techniques and application areas. Legends: Electrodermal activity (EDA), Electrocardiogram (ECG), Electroencephalogram (EEG), Respiration Analysis (RA), Electrooculography (EOG), Photoplethysmogram (PPG), Hemoencephalography (HEG), Facial expressions (FE), User Behavior (UB), Gestures Recognition (GR), Voice recognition (VR), Textual analysis (TA). The size of the bubbles indicates the number of articles that combine the techniques presented in X-axis and the application areas presented in Y-axis.

Show All

As shown in Fig. 3, research works that made applications in Arts used mostly BVI techniques, such as FE. In the case of applications in Education, both EDA (BII technique) and FE (BVI) were used in four studies. On the other hand, applications in the Health area used mainly BII techniques. This can be justified by the fact that even though BII techniques cause discomfort, collecting data from patients during exams is a natural process in applications of the Health area. In relation to Security applications, it is important to emphasize that although techniques like FE and VR were not considered in this group of applications, these techniques could be very interesting to analyze people with suspicious behavior in public places.

In general, it is possible to state that the selection of emotion recognition techniques could be strongly influenced by the area in which the software will be used. In Section 6, we discuss a set of aspects that could influence selecting an emotion recognition technique.

SECTION 5Elements Adapted in Software
The reviewed articles some adaptations executed in different software elements developed, especially considering their functions and target public. Here we categorized the articles according to the object adapted in the software: graphic interface, difficulty level, sound effects and software content. Considering that a classification of adaptive interventions was not identified in the literature, we created this classification in order to provide an overview of the interventions considered in the articles included.

As it occurred with the emotion recognition techniques, more than one element is considered for software adaptation in a same research work. This fact shows that efforts are being made to both present higher accuracy in emotion recognition and provide a better response to the user's emotional state.

It is important to emphasize that the categorization of the elements adapted that we present in this section are the most cited in the articles included. Thus, they are not necessarily the most efficient ones. The main goal of this section is to present the main information related to the elements adapted in the articles. A deeper discussion about these and other aspects related to software adaptation is presented in Section 6.

5.1 Adaptation in the Graphic Interface
In this review, we consider a graphic interface (GI) adaptation as any change in the visualization of the software. This approach can be applied in many ways, by changing only the color of an interface or, for example, by controlling the insertion time and display, and also such as illumination intensity.

In 64 percent (37) of the reviewed articles, interventions were made in the software GI [27], [31], [32], [33], [34], [35], [36], [38], [40], [42], [45], [46], [47], [48], [50], [53], [55], [56], [58], [59], [60], [62], [63], [64], [65], [67], [68], [70], [71], [73], [74], [75], [76], [77], [80], [81], [82]. In [53], for example, the authors changed the graphic representation of the weather in a car-racing game (increasing or decreasing the breeze and, consequently, the visibility). In [48] the authors changed the color of the GI of an educational environment. The authors of [50] also presented the adaptation of an educational software, but changing a virtual agent that interacts with the students. In [60], the emotional state to control the position and the number of times that a character was shown in a horror game were considered.

5.2 Adaptation of the Difficulty Level
The adaptation of the difficulty level (DL) based on the emotional state aims to customize the software for each user, according to a user's needs, identified by their reactions. This approach has been used especially in the case of serious games that, in addition to entertaining, aim to teach a content or assist in the acquisition of one's ability [94]. Such games and their adaptations are being applied in Education, Training, and Health Care. With this approach it is possible, for example, to reduce the difficulty of games when the user is stressed or sad, and increase the degree of difficulty when the user is happy and motivated for a length of time.

Among the included works, 47 percent (27 articles) presented adaptations in the difficulty level after analyzing the user's emotional state. In [37], [39], [41], [43], [44], [51], [52], [57], [61], [66], [69], [72], [78], [79], [84], [86] adaptations were made only in relation to the software's difficulty level. These levels are usually present in the game context and the changes refer to the game rules and the gameplay. On the other hand, in [49], [53], [56], [58], [63], [67], [70], [74], [76], [82], [83], besides the difficulty level, other adaptations were made, such as adaptation of the GI and adaptations in the software's sound elements.

In [41], the change in the games’ difficulty level considered elements such as the speed to perform an activity, while [61] used several elements, such as the avatar's direction, speed and health, in addition to generate elements that make up the games’ scenario.

5.3 Sound Effects Adaptations
Another possibility considered in the articles analyzed in this review was the change of background music or sound effects (SE) that make up the adaptive software. Identified in 12 percent (seven articles) of the studies, changes in the sound effects were used only in [26], which were used together with other techniques and approaches in [42], [63], [74], [77], [82], [83].

In [26], the authors exemplify the software of a framework with the creation of an affective player to play the song. However, the experiments results were not presented. In [63], the rhythm of the song was increased when the user was in a state of meditation; however, data related to the evaluation of users was not presented.

5.4 Content Adaptation
Another kind of adaptation indicated in the reviewed articles consists of making changes in the software content (SC). This approach can be used, for example, in educational software to give a student a less difficult exercise when an undesirable emotional state is detected.

This approach was identified in [40], [47], [49], [54], [62], [71], [77], [80], [85] (16 percent of the articles). In [49], for example, learning contents about Chinese characters were adapted in three stages, according to the user's emotional state.

SECTION 6Discussion
Despite the increased number of studies in software adaptation from the emotion recognition area, this is a broad field and there are still several open issues that deserve further development. The challenges and limitations presented below are divided into topics, according to the subjects already presented.

6.1 Quantitative Analysis
Fig. 4 shows the number of articles included in the review by year of publication. An increase in the number of publications can be noted regarding the adaptation of software with AC in recent years. The increased number of publications over the years can also represent the evolution of the area, such as the term Affective Computing, coined in 1997 [3], which refers to a relatively new field of research.


Fig. 4.
Total of articles published by year.

Show All

When analyzing the number of articles published over time, it can be noted that there is an increasing interest in relation to the subject by researchers. However, there are many limitations and underexplored topics, which shows the importance of carrying out new investigations in this area. Investigations in AC already have resulted in high impacts on usability, showing a level of maturity in the research works.

Fig. 5 presents the most frequent application areas according to the studies: Education (13 or 22 percent of the total) [34], [37], [40], [44], [49], [50], [52], [54], [57], [66], [75], [83], [85], followed by Health (six or 10 percent of the total) [45], [69], [72], [79], [84], [86], Arts (five or 9 percent of the total) [35], [41], [46], [47], [77] and Security (two or 3 percent of the total) [31], [43].

Fig. 5. - 
Percentage of application of software with Affective Computing in other knowledge areas.
Fig. 5.
Percentage of application of software with Affective Computing in other knowledge areas.

Show All

Also, regarding the application areas of the studies, Fig. 6 shows that especially in the Education area, there is a predominance of software characterized as games. This fact shows that the use of AC has received special attention by developers of digital education games, an activity that tends to bring great benefits with the personalization according to the students’ profile and emotional state.


Fig. 6.
Comparison between software categories and areas of application.

Show All

In the studies that carried out experiments, there is a higher incidence of articles that investigated AC in games. The proportion of research works that conducted experiments by software category (games or not), including the application areas, is presented in Fig. 7.

Fig. 7. - 
Comparison between categories of software developed and the experimental evaluations in the study.
Fig. 7.
Comparison between categories of software developed and the experimental evaluations in the study.

Show All

Regarding the experiments, in five articles (9 percent of the total) [34], [35], [45], [52], [57] that made applications in another areas, experiments with users to evaluate the effectiveness of the approach proposed in the research is neither declared nor described. This can be an indication that these research works aim at discussing gaps, but still with no effective results.

6.2 Emotion Recognition
Considering that the correct recognition of the user's emotional state is a crucial part to guarantee the success of the software adaptation, below we discuss some factors that must be observed during implementations.

6.2.1 Emotion Categories
In Table 2 we present a list of the emotions considered in each included paper. Thus, we analyzed the emotions recognized in the research works, in order to identify the most popular emotion categorization considered in these AC studies. According to the Affect Theory [95], human emotions can be analyzed by two different categories: discrete and continuous (or dimensional) emotions. In the first category, the emotions are usually classified into discrete word labels, such as happiness and sadness. In the continuous classification, the emotion is usually classified as neutral, positive or negative [96]. In both categories, the emotions labels can be different according to the model adopted. In the case of discrete emotions, for example, Ekman and Friesen [90] proposed a representation of emotions in these labels: happiness, sadness, surprise, anger, fear, disgust and neutral. Although the approach proposed by Ekman and Friesen is very popular, the literature has cited other models that must be considered.

In this sense, it is not possible to establish a relationship between each emotion recognition technique and the recognized emotions without the risk of making mistakes. Besides the fact that each included paper considers only emotions that have interest for its research, most of these articles used more than one emotion recognition technique. Additionally this list of articles is not exhaustive on the topic, since it is within the scope of this review. It must be highlighted that some emotion recognition techniques (for example facial expression), which can provide information about discrete emotions, can also be used to recognize continuous emotions.

In a general scenario, 71 percent of the included papers [31], [34], [35], [37], [39], [40], [41], [42], [44], [45], [46], [47], [50], [51], [52], [53], [54], [55], [58], [59], [60], [61], [63], [65], [66], [67], [68], [71], [72], [73], [74], [75], [77], [78], [80], [81], [82], [83], [84], [85], [86] considered continuous emotions, 16 percent considered discrete emotions [33], [36], [38], [43], [48], [49], [56], [62], [79], and 10 percent did not explicit the kind of emotion adopted [26], [27], [32], [57], [64], [69].

When we analyze papers with discrete emotions (nine articles, 16 percent), four studies [36], [38], [49], [79] consider FE as the emotion recognition technique. In all these cases, the authors adopted FE as the only technique to recognize emotions. Other studies used different emotion recognition techniques, such as GR and IMK. In relation to the continuous emotions, a large part of the studies used EDA and ECG as emotion recognition techniques. Twelve articles used both techniques together [39], [41], [42], [45], [52], [61], [65], [66], [67], [68], [74], [80]. Differently, the studies that consider continuous and discrete emotions [70], [76] used FE and EDA together to recognize the user's emotional state.

Although these study techniques may not represent the best approaches, we can conclude that the authors consider FE as interesting to recognize discrete emotions and EDA or ECG as interesting for continuous emotions. Thus, although FE can be used to recognize continuous emotions, an interesting approach is to use FE with EDA or ECG when discrete and continuous emotions should be considered.

In the case of affective adaptation, our opinion is that the use of continuous emotions can be more interesting, since the user's general state (as a positive or negative) can be enough to analyze whether an affective adaptation should be performed in the software. Based on our perception, this is the most important factor that explains the predominance of the use of continuous emotions in the analyzed papers. Additionally, in the development of new affective computing researches, the choice of an emotion recognition technique must consider the adaptation needs. If the research scope requires that the discrete emotions (as happiness, sadness, disgust, fear, and surprise) should be recognized, for example, a technique such as facial expression analysis could be very interesting, in contrast to Respiration Analysis, for example.

6.2.2 Performance of the Techniques
Although accuracy and reliability of the emotion recognition techniques are important topics, in only 19 percent of the articles [37], [45], [54], [58], [61], [66], [73], [75], [81], [83], [85] the authors provide some information about some type of performance. In the case of [58], [75], [81], [85], the authors declared an accuracy of about 80 percent in the emotion recognition. In [54], the authors reported an accuracy variation of 40 to 71 percent, depending on the number of recognized emotions.

In this sense, a full comparison between the accuracy of the emotion recognition techniques requires more information about the methods adopted in each research. Many emotion recognition techniques use Artificial Intelligence approaches as well as parameterized classifiers. Usually, the processes consider different environment conditions, which can influence the accuracy of the software. In the case of the included papers, there was a large variation between the methods adopted, the number of users in experimental evaluations, the different databases, among other aspects. However, all of this information was not available in the articles, which makes it hard to compare the performance of these techniques.

In a general analysis, regarding emotion recognition, a great part of the reviewed studies (25 articles or 43 percent) used BII techniques to collect the user's information - and 13 articles (22 percent) used both types of techniques. Considering that the most analyzed articles did not include accuracy rates in the presented results, it is possible this choice is related to the availability of devices or the experience of the authors. However, these justifications are not in the articles.

Although the literature does not specify a value that is considered as accurate, some researchers consider that the implementation of the emotion recognition technique presents good results when its accuracy exceeds 80 percent, i.e., when the amount of signals correctly recognized is equal to or greater than this percentage. The accuracy of the emotion recognition with BII and BVI techniques should be deeper explored in new studies, especially when looking for greater accuracy in classification algorithms. The analysis of emotions by means of facial expressions, for example, can have its accuracy changed according to the ambient lighting, the distance between the user and the camera, and the individual's ethnic characteristic, among many other factors. We found that most software libraries available for facial expression recognition cannot be adapted to such aspects. Therefore, these and other factors should be considered in the algorithms, which are important research topics. Additionally, it is noteworthy that BII techniques are also subject to failures, such as the analysis of electrodermal activity, in which sweat can damage the sensor fixation and the consequent data capture.

In both cases, a possibility that was greatly explored by the articles to reduce the likelihood of errors consists of using the combination of more than one recognition technique. In this sense, in 29 articles the authors used more than one emotion recognition technique. Within this set of articles, 13 articles explored emotion recognition using both BVI and BII techniques. This fact can indicate that the improvement of the accuracy is one of the main concerns of these articles, regardless of the type of technique used.

Thus, we believe that a great contribution to the AC area is the development of studies in order to compare the accuracy of these emotion recognition techniques using the same methods, datasets, and parameters. Additionally, another aspect related to the accuracy that can be investigated is the effect of using coupled techniques to increase the performance.

6.2.3 Critical Technical Elements
The main disadvantage of the use of physiological signals shown in the articles included consists precisely of the coupling of sensors in the user's body, which tends to be uncomfortable, particularly in software that requires long-time use. Thus, the choice of BII techniques for recognizing the emotional state should be also influenced by the software's characteristics. As a practical example, a software with affective adaptation intended for children should prioritize the use of non-intrusive BVI techniques, allowing the user's freedom of movement.

For this reason, in the articles analyzed, choosing the technique to recognize the emotional state usually considered the purpose of the software to be developed. In [42], for example, the goal was to develop a software that simulated a virtual mirror, the authors chose BVI techniques, such as facial expressions. The use of electroencephalogram, in this case, would certainly make the software uncomfortable, which is not consistent with a mirror.

6.3 Implementation Aspects
In this review, the adaptation architectures were categorized into two groups: intrusive and semi-intrusive. In the intrusive adaptation category, the affective adaptation is programmed in the software's source code. Thus, the software's code includes emotion recognition and decision-making modules. In the semi-intrusive adaptation, the software with affective adaptation does not include modules for recognition of the user's emotional state or decision-making. An external software is responsible for collecting the users’ data and measuring their emotional states. Similarly, another external software can be used to define which action will be performed.

Thus, the use of external software for emotion recognition can both reduce the implementation cost and dismiss experiments to calculate the recognition accuracy. Authors of libraries as Affectiva SDK [97] and FaceReader [91] reported that they have already made exhaustive tests with different databases, which can increase the reliability of these softwares.

However, some critical issues of the most external libraries are: (1) the absence of modules that allow performing tests to identify the accuracy with different databases makes difficult to confirm their performance, (2) the discontinuity of these libraries can cause an interruption in the software use and (3) the cost of some libraries can impact the cost of the project. Even with these concerns, this type of approach usually has a lower implementation cost.

Finally, it is expected that new investigations will focus on the development or the use of more comfortable sensors for invisible data collection, which could minimize the user's discomfort while using them. In relation to BVI techniques, it is expected that the algorithms will be increasingly enhanced to allow higher accuracy in the recognition of the user's emotional state, making the process more reliable and pleasant.

6.4 Affective Adaptation Impacts in the User Experience
An important aspect related to the affective adaptation is the effect perceived in the user's experience. Among the articles that conducted experimental evaluations with people, 30 articles (57 percent) [31], [33], [34], [36], [37], [38], [39], [42], [44], [46], [49], [50], [53], [55], [59], [66], [70], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], declare achieving positive effects in the user's experience. Usually, the authors of these articles used questionnaires and self-reports to analyze the effect of affective adaptation (subjective evaluation). Some research works use the tracking of emotions (registered in a log file) and the user's performance to improve the analysis of the affective adaptation effect on the user's experience (objective evaluation).

In [42] the authors identified that the use of affective adaptation could also induce positive emotions on users. Additionally, the research concluded that users have better performance when performing activities accompanied by a friend. Similarly, in [70] the authors stated that the content adaptation had great results in an educational application. The authors of [49] concluded that in the experimental evaluation the adaptation of the difficulty level in a game presented greater effects than the software content adaptation with respect to motivation and satisfaction. In the case of sound effects, users confirmed that the sound elicited anxiety and suspense in the use of a survival horror game investigated in [59]. The use of GI adaptation had a great effect on the user's experience according to [31].

The above mentioned findings can indicate that affective adaptation can improve significantly the user's experience. As observed in the included studies, the adaptation process usually considers more than one element to be changed in the software. Thus, the combined use of the different types of adaptations (GI, SE, SC and DL), when possible, can contribute to involve the users and improve their experiences.

Another important issue observed in [42] is that most of the users who participated in the experiments alleged that the initial use of the software with affective adaptation aroused greater interest than subsequent sessions. This users’ perception can show that, in this case, maintaining the flow state was not a requirement achieved. This fact is a characteristic to be highlighted and observed in future studies about user experience: does maintaining the flow state in games with AC continue even after its continuous use?

To obtain a response, the authors of future investigations can analyze which types of adaptations can cause greater user engagement, especially considering the challenge imbedded in the software that will take the affective adaptation. In endless race games, for example, does increasing or decreasing the vehicle's speed and other components related to the DL make the user feel more motivated than changing the background music? The answers to this question can vary according to the user. Thus, investigating categories of users and their motivations could be an interesting topic for future development of research works in the area. Additionally, the user's lack of interest in a software over time may be related to the absence of new features. There is evidence that the adaptation cannot be repetitive. Consequently, another topic of interest is checking how many and which types of new additions can be included in the software according to the possible profiles of users.

6.5 Data Measurement
It can be noted there is a predominance of investigations on affective adaptation in computer games, which is shown in Fig. 7. The significant number of articles in this sense reinforces the importance of the motivational character of games, but it can also show that there is a gap in relation to the automatic adaptation of software that are not characterized as games, especially using the techniques and approaches of AC.

Possibly, the largest use of software characterized as games in the investigations is related to the evaluation approach regarding the adaptation effect on the individual's emotional state. As games typically provide information such as score and play time, such information can also be used to measure the user's engagement, which was accomplished in several articles, in some cases together with questionnaires (subjective and objective evaluations).

Following this logic, the application of Education concepts can also show that the users’ academic rates were considered in the evaluation of the proposal's effectiveness, i.e., the research works used approaches that usually provide measurable data. It is noteworthy that of the 41 articles characterized as games, only 11 did not carry out experiments with users. Theses finding offer evidence that games can provide elements to collect data related to the users’ performance when compared to other types of software.

6.6 How Can We Choose a Technique to Emotion Recognition?
As seen throughout this article, the inference of the user's emotional state can be crucial for the affective adaptation. The choice of a technique or a set of techniques to effectively accomplish this task must consider several characteristics. To clarify this, we divided these characteristics into three categories: individual, device, and process.

First, we must consider the characteristics of individuals that will use the software with affective adaptation. In this context, the first aspect to be observed is the feasibility of using sensors, since they can cause discomfort for some types of individuals. Although sensors coupled to the user's body cannot result in a problem in a software developed for physical preparation of athletes, for example, this situation can be different if the target public is composed of an individual with psychiatric disorders. In this case, it is advisable using other techniques that do not require devices directly in contact with the user.

Although we already mentioned this characteristic, it is important to reinforce that a software with affective adaptation usually aims at maintaining the user's level of engagement during the execution of an activity. Techniques that make this process less comfortable and less ubiquitous can naturally reduce the use of a software. Thus, the use of additional sensors should be applied with caution, since generally they are not natural to the interaction.

Second, in relation to the devices, the major problem is related to the availability of devices to capture information about the user's emotional status. During scientific research, experimental evaluations can be conducted with devices to collect ECG and EEG data, for example, given that coupling this type of devices in a computer and using them daily is not a trivial task. Even webcams used for facial recognition, popular in devices such as smartphones, maybe are not available in desktop computers in environments such as schools and hospitals, for example. The availability of non-conventional devices to capture signals is a factor that requires a comprehensive study so as to not render unfeasible the use of the software.

Another aspect to be considered is the interference caused by the presence of other individuals or noise emitters in the environment. Voice recognition, for example, is a technique that is highly dependent on a controlled environment. Facial recognition can present failures when the lighting is not adequate or when there is the presence of more individuals in the environment. Also concerning facial recognition, its precision can be decreased when used in individuals with facial deformities or whose expressions are subtle, for instance.

Lastly, in relation to the process, some techniques presented in Section 4 can require previous preparation or calibration steps. When sensors are used for capturing physiological signals, for example, it may require the use of some products, such as gel, to place the sensor on the body's user. Additionally, such sensors must be sanitized at the end of each use, demanding effort and resources.

In fact, choosing a technique for emotion recognition is not a trivial task, especially because each technique presents advantages and limitations. In order to assist in this process, in Table 3 we present some criteria that are important in this decision. The criterion “Availability” indicates if the software will be used by several individuals simultaneously. In “Cost”, we analyzed the financial cost the technique can require. “Ease of Use” refers to the facility to apply the technique, including availability of devices as well as practicality in the daily use of the technique coupled with the software. Finally, “Discomfort” considers how much the technique can cause annoyance to the user, making the use of the software less natural.

TABLE 3 Relationship between Emotion Recognition Techniques and Factors to Be Considered When Choosing a Technique
Table 3- 
Relationship between Emotion Recognition Techniques and Factors to Be Considered When Choosing a Technique
In each cell of Table 3 we present a level of classification (Low, Medium, High) for each aspect and each technique. Low level indicates that we consider the factor difficult for that technique. For example, “Availability” has a low level for ECG because we consider it is not a device that every software developer or user can easily access. Moreover, we consider that “Availability” has a high level for UB because the analysis of user behavior could use information that does not need specific sensors, as the number of times that a user visited a specific page or content, for example. Although this classification can raise questions depending on the interpretation and the reality of each research center, we think it is a starting guide aiming at helping researchers in their choices.

SECTION 7Limitations, Challenges and Gaps
Although the adaptations that can be made in a particular software are directly related to their characteristics, it is interesting to investigate the effect each target element of adaptation has on the user's motivation, such as GI and sound aspects. Other areas of knowledge, such as Psychology, can contribute to greater knowledge regarding the effects caused by each type of adaptation, allowing to better select the adaptations that will be available in each software and the effects these adaptations can have on the behavior and performance of users.

Another area that offers assistance to this type of investigation is Sociology, which involves cultural and social issues, such as political and religious aspects. Thus, studies can be carried out that investigate emotion recognition in collaborative software — a context with human-human interaction and human-computer interaction. Can the emotional behavior of a user be different when there is a human-human interaction? And what is the influence of the geographic distance in this context (are the individuals in the same location or in different places)? What is the influence of the technological means between individuals? Another issue is the interface element of the software that interacts directly with the user. For example, studies can be conducted when there is an interaction with a graphical element that is represented by a person; and when there is an interaction with another graphical element, checking the relationship between empathy and emotions.

The use of machine learning techniques could strongly contribute toward adaptive computational systems to identify by themselves other characteristics related to the users and then propose adaptations that are consistent with this profile. Another possibility related to adaptation consists of considering the information about the users that is available on digital social networks. Considering information, for example, concerning the music most listened by the user, it would be possible to infer one's musical preferences and, during the affective adaptation, suggest a musical intervention with a type of music that is among the user's music preference.

Machine learning can also be used to compose a knowledge database with the users’ profiles and their emotions, thus allowing to accurately identify future users, and improving the user experience after each human-computer interaction session with previous notice. In this case, computer techniques to analyze similarities based on emotions and profiles must be implemented, as well as techniques for analyzing a big data set. In the case of games development, the use of scores (hits, errors and time) combined to human-computer interaction aspects (clicks, body movements, device movements, etc.) to define the users’ profiles and their emotions can be an option, creating categories of players.

Another challenge of software development with automatic affective adaptation is productivity. In this case, the area of Software Engineering can help by means of diagrams, design techniques, software architecture as well as software testing techniques in order to implement more reliable software in a faster way. It is an underexplored topic in the literature that can generate important contributions for the research area explored in this article.

From our perception, the main challenges related to the Affective Computing applications are:

Study of the effect produced for each type of adaptation made in a software on the user's behavior, specifically related to the user's engagement;

Investigation about the effect that cultural differences can have on the use of affective adaptation;

Use of user's personal characteristics to enhance Affective Computing systems;

Definition of standards for the development of Affective Computing software.

SECTION 8Final Remarks
Considering the importance of automatic software adaptation within the HCI area, this article presented a systematic literature review on the use of AC techniques in the automatic software adaptation process based on the user's emotional state, describing an overview of the state of the art to assist researchers during the development of new investigations. The analysis of the articles included allows concluding that the most used emotion recognition approach consists of data obtained by means of physiological signals.

With respect to the adaptation of software, most research works promoted adaptations in the software's GI. Even in cases when such softwares were games, there was a predominance of graphic adaptation instead of the DL adaptation. We also realized that it is difficult to adapt software in a semi-intrusive way, which can constitute an important research topic.

Moreover, it is possible to conclude that the use of AC techniques for the adaptation of software is a promising field, as it has received much attention by a significant and growing amount of research works generated in recent years. New approaches, both in emotion recognition and adaptation must be investigated in future articles. This topic, therefore, contains many open themes, which generate rich research opportunities.