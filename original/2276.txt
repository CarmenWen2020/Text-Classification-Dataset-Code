A mathematical model to measure the shape of a 3D surface using angle measurements from embedded sensors is presented. The surface is known in a reference configuration and is assumed to have deformed inextensibly to its current shape. An inextensibility condition is enforced through a discretization of the metric tensor generating a finite number of constraints. This model allows to parameterize the shape of the surface using a small number of unknowns which leads to a small number of sensors. We study the singularities of the equations and derive necessary conditions for the problem to be well-posed as well as limitations of the algorithm. Simulations and experiments are performed on developable surfaces under relatively small deformations to analyze the performance of the method and to show the influence of the parameters used in our algorithm. Overall, the proposed method outperforms the current state-of-the-art by almost an order of magnitude.

Access provided by University of Auckland Library

Introduction
Recovering the shape of a 3D surface often requires a measurement system with a certain depth of view. Cameras, scanning lasers or radars are often used to generate a point cloud of the surface. Methods exist to convert this cloud into a more or less smooth 3D surface [1, 2].

Many solutions focus on reconstructing the shape of a surface from a set of measurements and a reference configuration (also called a template). The 3D shape of the reference is known either from a previous measurement or from the method of construction of the structure. For instance, the surface depicted in Fig. 1 is known to be a sheet of paper and its dimensions are dictated by a predefined printed pattern. Monocular reconstruction of a surface is a well-known method [3,4,5,6,7,8,9,10]. For instance, Shape-from-Template (SfT) which preserves geodesic distances is widely used to reconstruct shapes by matching features in a picture of the surface and a template while allowing isometric deformation of the structure from the template. Other methods also integrate the measurement of the direction of the normal to the surface implicitly from images [8,9,10]. Such methods include Shape-from-Shading (SfS) that uses the reflection of light from the surface.

There are inherent limitations to these methods. For instance, the camera has to be held in front of the surface at a distance sufficient to accommodate the field of view or range of the system. Rigs of cameras can extend the depth of view by having each camera look at a different part of the structure and hence closer to it but add complexity and still require a minimum distance from the surface. There may be insufficient space available in front of the structure, or holding the camera may be very difficult, e.g. in the case of large space structures or rapidly moving objects. In the former case, while it is possible to attach a camera to a deployable boom or have a second spacecraft follow the primary structure, such solutions add mass and complexity to the system. Finally, camera-based methods such as Shape-from-Template require a pattern to be drawn on the surface which may be undesirable in some situations. For instance, a flexible solar array is covered with photovoltaic cells and drawing a pattern on top would decrease the efficiency of the array.

Fig. 1
figure 1
Example of images used for monocular, template-based reconstruction of inextensible surface [4]. The left image shows a flat sheet of paper (reference configuration) and the other images show bent and crumpled configurations to be reconstructed

Full size image
Fig. 2
figure 2
Definition of the problem. The surface is parametrized by two coordinates (u, v). The 3D surface is a mapping of the 2D coordinates to 3D. The shape of the reference configuration is known while the current configuration needs to be reconstructed

Full size image
The approach investigated in this paper is based on embedding angle sensors directly on the surface to be reconstructed.

Different technologies exist to perform such measurements. Most state-of-the-art technologies use inertial sensors (a combination of accelerometers and magnetometers) to measure angles from the gravity vector and Earthâ€™s magnetic North and have been investigated to reconstruct both 3D curves and surfaces [11,12,13,14,15,16]. Note that if the surface experiences large accelerations, the accelerometers fail to detect the direction of gravity. Magnetic fields are easily affected by magnets, currents, or ferrous materials, which limits the usage of magnetometers.

Sun sensors have recently been studied mostly for space applications where gravity is near-zero [17,18,19]. Different sensor technologies exist. The simplest ones use quad-photodiodes behind an aperture, effectively acting as a 4-pixel pinhole camera [19]. More complex architectures involve cameras with a large photosensor array that locate the centroid of the spot created by the light source using image-processing algorithms [20]. They can also identify features in the image (such as stars) to improve their accuracy.

The angle measurements of these sensors are fed in an algorithm that will be described in this paper, and the algorithm reconstructs the shape of an inextensible support surface that holds the sensors.

This study is limited to inextensible deformations, also called isometric deformations as the surface cannot stretch or contract. The term inextensible will be used in this paper, as it is widely used in the field of structural mechanics. This requires a reference configuration, also called template in the literature, to be fully known in order to define the conservation of lengths upon deformation.

The overall problem is described in Fig. 2. Imposing inextensibility of the deformation of the surface usually serves two purposes: (1) to eliminate singularities in the algorithms and (2) to improve the results by adding some knowledge of the deformation. Many methods used to reconstruct inextensible surfaces employ a triangular [5, 21] or quadrilateral [22] mesh to map the surface. Each edge of the mesh can be defined as a straight, rigid line which implicitly enforces inextensibility. This method requires a fine mesh in order to achieve a smooth mapping; this means that many degrees of freedom must be computed from a large amount of data (for instance, high resolution images) which can be computationally expensive. Tangential and normal vectors are undefined at the intersection of edges which can cause issues in defining angles. Note that different methods exist to reduce the number of variables of a fine mesh [23] with some guaranteeing inextensibility of the deformation [24], eventually preserving details of the template. However, they add complexity to the reconstruction algorithm. Previous research involving embedded sensors does not strongly impose inextensibility of the deformation. The surface is reconstructed by integrating along inextensible lines where the angle sensors are placed uniformly [11, 14, 15]. The inextensibility is either imposed explicitly, by enforcing conservation of lengths between sensors, or implicitly by connecting sensors by means of rigid lines. The surface is then filled by different techniques such as Coonâ€™s methods in [13] or using a quad mesh in [11]. While inextensibility is imposed along the lines of integration, it is usually constrained by the placement of sensors and incomplete as shear is not taken into account.

Our approach is to reconstruct the relatively smooth shape of the surface in its current configuration by only assuming an inextensible transformation from the reference configuration (or template) and the measurement of angles at discrete locations along the structure. Because the number of sensors that can be placed on a structure is limited, constraining the amount of variables to define the shape of the surface, only smooth shapes are considered in this paper.

In order to estimate the shape of a surface, we parameterize it on a set of basis functions. This is presented in Sect. 2. Different sets of basis functions relevant to this problem are introduced. We define the inextensibility of the deformation in Sect. 3 using the conservation of the metric tensor. The general mathematical relations are discretized in order to generate a finite set of constraints. The singularities associated with this first system of equations are analyzed. A set of angle measurements is defined in Sect. 4. Their singularities are analyzed separately from the inextensibility conditions, and we especially investigate requirements on the placement of the sensors. The complete system of equations including inextensibility and angle measurements is obtained in Sect. 5. It is generally an overconstrained system whose least error solution can be found, given an initial estimate, using the Levenberg-Marquardt algorithm. Singularities of this complete system are studied based on the remarks done on the singularities of each set of equations. The approach is tested on simulations of a developable surface with a conical shape, in Sect. 6. A complete study analyzing the overall error of the reconstructed shapes, the inextensibility, the influence of sensor noise and different parameters of the algorithm are investigated. In Sect. 7, the presented method is compared to the current state of the art, which uses Inertial Measurement Units (IMUs) as sensors. It is shown that the presented method outperforms current methods. Finally, Sect. 8 shows the results of an experimental demonstration. Sub-millimeter accuracy was achieved on a 1.2Ã—0.2 m2 structure under relatively small deformations, as predicted from simulations. The nomenclature used throughout this paper is shown Table 1.

Table 1 Nomenclature
Full size table
Surface Model
Definition of Parametric Surface
A 3D surface can be described explicitly by the mapping ğ‘Ÿğ‘Ÿ:ğ‘‹âŠ‚â„2â†’â„3. Only two curvilinear coordinates (u, v) are needed to uniquely define a point on the surfaces as shown in Fig. 2. The image of this two-coordinate point through the mapping represents the location of that point in 3D space.

For instance, a flat surface (or plane) can be represented by:

ğ‘Ÿğ‘Ÿ(ğ‘¢,ğ‘£)=â¡â£â¢â¢ğ‘¢ğ‘£0â¤â¦â¥â¥
(1)
A cylindrical surface of radius R along the z-axis can be represented by:

ğ‘Ÿğ‘Ÿ(ğ‘¢,ğ‘£)=â¡â£â¢â¢ğ‘…cosğ‘¢ğ‘…sinğ‘¢ğ‘£â¤â¦â¥â¥
(2)
Basis Function Decomposition
We consider a finite dimension mapping defined by basis functions. The mapping ğ‘Ÿğ‘Ÿ can be written as:

ğ‘Ÿğ‘Ÿ:ğ‘‹âŠ‚â„2âŸ¶â„3(ğ‘¢,ğ‘£)âŸ¼ğ‘Ÿğ‘Ÿ(ğ‘¢,ğ‘£)=âˆ‘ğ‘˜=1ğ‘ğ‘ğ‘ğ‘˜ğ‘˜ğœ™ğ‘˜(ğ‘¢,ğ‘£)
(3)
where ğœ™ğ‘˜:ğ‘‹â†’â„ are basis functions, ğ‘ğ‘ğ‘˜ğ‘˜ are unknown 3D points called control points and define the weight of the basis functions, and N is the dimension of the function space.

Fig. 3
figure 3
Parameterized mapping defining the surface to be reconstructed. Circles represent the 3D position of the control points

Full size image
This basis representation is common for such problems [4, 5, 25, 26]. Many sets of functions can be used to describe the mapping ğ‘Ÿğ‘Ÿ. Perriollat et al. [4] use Thin-Plate Splines, Metaxas et al. [25] use Finite Element basis functions which are piecewise polynomials defined over local supports. B-Splines are used to fit a surface to data points [27]. Note that B-Splines and the more complicated 2D Non-Uniform Rational Basis Splines (NURBS) are often used in computer-aided design to draw complex surfaces. Other basis functions such as rational Gaussian functions can also be used [28]. They have the advantage of being able to capture both global and local deformations with one set of basis functions by varying the standard deviation of each Gaussian. Simple polynomial series have also been used in [17].

In order to define angles of the surface at specific locations (see Sect. 4), the basis functions used in our problem need to be differentiable. We limit this study to simple polynomial basis functions: 2D Lagrange polynomials. They are defined over a grid of control points aligned with the curvilinear coordinates (see Fig. 3). Let ğ‘ğ‘¢ and ğ‘ğ‘£ be the size of the grid in each direction and note that ğ‘=ğ‘ğ‘¢Ã—ğ‘ğ‘£. We can rewrite Eq. (3) as:

ğ‘Ÿğ‘Ÿ(ğ‘¢,ğ‘£)=âˆ‘ğ‘˜=1ğ‘ğ‘¢âˆ‘ğ‘™=1ğ‘ğ‘£ğ‘ğ‘ğ‘˜,ğ‘™ğ‘˜,ğ‘™ğœ™ğ‘˜,ğ‘™(ğ‘¢,ğ‘£)
(4)
Fig. 4
figure 4
Lagrange basis function ğœ™4,3(ğ‘¢,ğ‘£)=ğ¿ğ‘¢4(ğ‘¢)ğ¿ğ‘£3(ğ‘£) on a regular grid of interpolation coordinates [ğ‘¢ğ‘¢ğ‘˜ğ‘˜]=[ğ‘£ğ‘£ğ‘™ğ‘™]=(âˆ’2,âˆ’1,0,1,2)

Full size image
Lagrange polynomials are often used to interpolate functions based on known values at discrete locations [29]. They are easy to compute and physically understandable as the control points lie on the surface to be reconstructed. Unfortunately, for a large number of control points, which corresponds to a large polynomial order, they are susceptible to Rungeâ€™s phenomenon where a function can have large oscillations near the boundaries of the domain [30]. The basis functions are written as:

ğœ™ğ‘˜,ğ‘™(ğ‘¢,ğ‘£)=ğ¿ğ‘¢ğ‘˜(ğ‘¢)ğ¿ğ‘£ğ‘™(ğ‘£)
(5)
where ğ¿ğ‘¢ğ‘˜ (resp. ğ¿ğ‘£ğ‘™) is the Lagrange polynomial in the u-direction (resp. v-direction):

ğ¿ğ‘¢ğ‘˜(ğ‘¢)=âˆğ‘=1ğ‘â‰ ğ‘˜ğ‘ğ‘¢ğ‘¢âˆ’ğ‘¢ğ‘ğ‘¢ğ‘˜âˆ’ğ‘¢ğ‘andğ¿ğ‘£ğ‘™(ğ‘£)=âˆğ‘=1ğ‘â‰ ğ‘™ğ‘ğ‘£ğ‘£âˆ’ğ‘£ğ‘ğ‘£ğ‘™âˆ’ğ‘£ğ‘
(6)
where ğ‘¢ğ‘˜ (resp. ğ‘£ğ‘™) are interpolation coordinates defined in the uv-plane. Figure 4 shows the Lagrange basis function ğœ™4,3(ğ‘¢,ğ‘£)=ğ¿ğ‘¢4(ğ‘¢)ğ¿ğ‘£3(ğ‘£) on a uniform grid of interpolation coordinates [ğ‘¢ğ‘¢ğ‘˜ğ‘˜]=[ğ‘£ğ‘£ğ‘™ğ‘™]=(âˆ’2,âˆ’1,0,1,2).

Inextensibility Constraints
Definition of the Constraints
Fig. 5
figure 5
Inextensibility constraints on the grid defined by [ğ‘¢ğ‘¢^ğ‘–ğ‘–] and [ğ‘£ğ‘£^ğ‘—ğ‘—]. The red and blue segments remain the same length after deformation. The angle around the node defined by the green arc also remains the same

Full size image
Curvilinear distances on a surface in 3D Euclidian space can be calculated using the metric tensor [31, 32]. It is the tensor representation of the first fundamental form in differential geometry [33]. For the parametric surface defined in Eq. (4), the associated metric tensor is:

ğŒ(ğ‘¢,ğ‘£)=â¡â£â¢â¢â¢âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£â¤â¦â¥â¥â¥
(7)
where ğ‘ğ‘â‹…ğ‘ğ‘ is the inner product between vectors ğ‘ğ‘ and ğ‘ğ‘.

The length of a curve defined in the uv-space by (u(t), v(t)), ğ‘¡âˆˆ[ğ‘¡0,ğ‘¡1] can be calculated as:

ğ‘ =âˆ«ğ‘¡1ğ‘¡0[ğ‘¢â€²(ğ‘¡),ğ‘£â€²(ğ‘¡)]ğŒ(ğ‘¢(ğ‘¡),ğ‘£(ğ‘¡))[ğ‘¢â€²(ğ‘¡)ğ‘£â€²(ğ‘¡)]â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆšğ‘‘ğ‘¡
(8)
As a result, the deformation between two surfaces defined by ğ‘Ÿğ‘Ÿ00 and ğ‘Ÿğ‘Ÿ is inextensible if any curve has the same length on both surfaces, or if and only if the metric tensor is conserved upon deformation ğŒ=ğŒ0:

â¡â£â¢â¢â¢âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£â¤â¦â¥â¥â¥=â¡â£â¢â¢â¢âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£â‹…âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£â¤â¦â¥â¥â¥
(9)
Note that ğŒ0 is fully known since the reference configuration is known. The inextensibility of the transformation leads to the following 3 equations:

âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢=â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â€–â€–â€–2=â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢â€–â€–â€–2
(10)
âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£=â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£â€–â€–â€–2=â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£â€–â€–â€–2
(11)
âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£=âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢â‹…âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£
(12)
Equations (10) and (11) impose the condition that the square of the local strain in both directions u and v is zero. Equation (12) imposes the condition that the angle between the two tangent directions remains constant.

Equations (10)â€“(12) form a system of three non-linear differential equations for three unknowns (the components of ğ‘Ÿğ‘Ÿ). The family of solutions represents all possible inextensible deformations from the initial configuration ğ‘Ÿğ‘Ÿ00. The complexity of this system makes it impossible to solve analytically. As a result we derive a finite subset of constraints inspired from these PDEs.

We define a regular grid called inextensibility grid aligned with the curvilinear coordinates u and v. It is parameterized by the coordinates [ğ‘¢ğ‘¢^ğ‘–ğ‘–]=(ğ‘¢Ì‚ 1,...,ğ‘¢Ì‚ ğ‘–,...,ğ‘¢Ì‚ ğ‘Ì‚ ğ‘¢) and [ğ‘£ğ‘£^ğ‘—ğ‘—]=(ğ‘£Ì‚ 1,...,ğ‘£Ì‚ ğ‘—,...,ğ‘£Ì‚ ğ‘Ì‚ ğ‘£). This grid is shown in Fig. 5. It is usually different from the grid used to define the Lagrange polynomials shown in figure 3.

Equations (10)â€“(12) are discretized into a finite number of constraints on this grid. The strain constraints are applied on average between two nodes of the grid. This is equivalent to conserving the length of each edge of the grid. The dot product constraint is taken at the nodes of the grid. This leads to the following equations:

âˆ«ğ‘¢Ì‚ ğ‘–+1ğ‘¢Ì‚ ğ‘–â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–â€–ğ‘‘ğ‘¢=âˆ«ğ‘¢Ì‚ ğ‘–+1ğ‘¢Ì‚ ğ‘–â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–â€–ğ‘‘ğ‘¢
(13)
âˆ«ğ‘£Ì‚ ğ‘—+1ğ‘£Ì‚ ğ‘—â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–â€–ğ‘‘ğ‘£=âˆ«ğ‘£Ì‚ ğ‘—+1ğ‘£Ì‚ ğ‘—â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–â€–ğ‘‘ğ‘£
(14)
âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢ğ‘‡(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)=âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢ğ‘‡(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)
(15)
where the right hand-side is known.

These constraints can be physically interpreted by considering a 2D structure made of rods and rigid joints. The length constraints represent the inextensibility of the rods while the angle constraints represent the fixed angles between rods imposed by the joints.

A similar approach is used in [3, 7, 8]. The metric tensor is constrained to remain constant upon deformation at discrete locations on the surface (nodes of a grid). The length constraints in Eqs. (13) and (14) are replaced by simply imposing the norm of the tangent vectors to remain constant. Using lengths in the constraints as opposed to the norm of the tangent vectors makes it easier to define the reference configuration, especially for more complex geometries. Distances are well defined quantities while the norm of the tangent vectors highly depends on the mapping used to define the reference configuration.

Rank Deficiencies
The inextensibility conditions defined in Eqs. (13)â€“(15) applied over the whole inextensibility grid define a system of 3ğ‘Ì‚ ğ‘¢ğ‘Ì‚ ğ‘£âˆ’ğ‘Ì‚ ğ‘¢âˆ’ğ‘Ì‚ ğ‘£ equations

ğ‘“ğ‘“(ğ‘ğ‘11,...,ğ‘ğ‘ğ‘ğ‘)=0
(16)
where ğ‘“ğ‘“ is a vector containing all the inextensibility conditions, written as:

ğ‘“ğ‘¢,ğ‘–,ğ‘—=âˆ«ğ‘¢Ì‚ ğ‘–+1ğ‘¢Ì‚ ğ‘–â€–â€–â€–â€–âˆ‘ğ‘˜=1ğ‘ğ‘ğ‘ğ‘˜ğ‘˜âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–â€–â€–ğ‘‘ğ‘¢âˆ’âˆ«ğ‘¢Ì‚ ğ‘–+1ğ‘¢Ì‚ ğ‘–â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–â€–ğ‘‘ğ‘¢=0
(17)
ğ‘“ğ‘£,ğ‘–,ğ‘—=âˆ«ğ‘£Ì‚ ğ‘—+1ğ‘£Ì‚ ğ‘—â€–â€–â€–â€–âˆ‘ğ‘˜=1ğ‘ğ‘ğ‘ğ‘˜ğ‘˜âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–â€–â€–ğ‘‘ğ‘£âˆ’âˆ«ğ‘£Ì‚ ğ‘—+1ğ‘£Ì‚ ğ‘—â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–â€–ğ‘‘ğ‘£=0
(18)
ğ‘“ğ´,ğ‘–,ğ‘—=âˆ‘ğ‘˜=1ğ‘âˆ‘ğ‘™=1ğ‘ğ‘ğ‘ğ‘˜ğ‘˜ğ‘‡ğ‘ğ‘ğ‘™ğ‘™âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ‚ğœ™ğ‘™âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ’âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢ğ‘‡(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)=0
(19)
The jacobian of this system of equations is defined as the tensor:

ğ‰=[âˆ‚ğ‘“ğ‘“âˆ‚ğ‘ğ‘11...âˆ‚ğ‘“ğ‘“âˆ‚ğ‘ğ‘ğ‘ğ‘]
(20)
Let (ğ‘ğ‘âˆ—âˆ—11,...,ğ‘ğ‘âˆ—âˆ—ğ‘ğ‘) be a solution of Eq. (16) and ğ‘Ÿğ‘Ÿâˆ—âˆ— the associated surface. Let ğ‘ğ‘ğ‘˜ğ‘˜=ğ‘ğ‘âˆ—âˆ—ğ‘˜ğ‘˜+ğ›¿ğ›¿ğ‘ğ‘ğ‘˜ğ‘˜ with â€–ğ›¿ğ›¿ğ‘ğ‘ğ‘˜ğ‘˜â€–â‰ª1. One can calculate âˆ‚ğ‘“ğ‘“âˆ‚ğ‘ğ‘ğ‘˜ğ‘˜ by calculating the first order term of the Taylor expansion of ğ‘“ğ‘“(ğ‘ğ‘âˆ—âˆ—11,...,ğ‘ğ‘âˆ—âˆ—ğ‘˜ğ‘˜+ğ›¿ğ›¿ğ‘ğ‘âˆ—âˆ—ğ‘˜ğ‘˜,...,ğ‘ğ‘âˆ—âˆ—ğ‘ğ‘). This leads to:

âˆ‚ğ‘“ğ‘¢,ğ‘–,ğ‘—âˆ‚ğ‘ğ‘ğ‘˜ğ‘˜=âˆ«ğ‘¢Ì‚ ğ‘–+1ğ‘¢Ì‚ ğ‘–âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)ğ‘‘ğ‘¢
(21)
âˆ‚ğ‘“ğ‘£,ğ‘–,ğ‘—âˆ‚ğ‘ğ‘ğ‘˜ğ‘˜=âˆ«ğ‘£Ì‚ ğ‘–+1ğ‘£Ì‚ ğ‘–âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)ğ‘‘ğ‘£
(22)
âˆ‚ğ‘“ğ´,ğ‘–,ğ‘—âˆ‚ğ‘ğ‘ğ‘˜ğ‘˜=(âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘¢+âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘£)(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)
(23)
Singularities of the jacobian (deformations associated with a null singular value) describe the possible isometric motions of the surface around the current configuration.

Because Eqs. (21)â€“(23) are functions of the basis function derivatives in u and v, the inextensibility grid has to cover the whole surface. The values of the basis function derivatives decrease as the distance from a control point increases. If the grid is localized in a certain region, the motion of a control point far from this region can create a numerical singularity as Eqs. (21)â€“(23) become close to 0.

Rigid-body translations and rotations are obvious singularities of the jacobian which can be shown from Eqs. (21)â€“(23). Additionally to rigid body motions, it is possible to have non-rigid singularities. These are important since they correspond to actual deformations of the surface. They are dependent on the current shape ğ‘Ÿğ‘Ÿâˆ—âˆ—.

Table 2 shows the number of singularities for different shapes, number of control points and size of inextensibility grids, calculated numerically using MATLAB. Lagrange polynomials cannot exactly represent circular surfaces such as cylinders, cones, sphere, etc. These shapes were generated by placing the control points evenly on these mathematically defined surfaces. The inextensibility grid was also evenly spaced and mapped to the whole surface delimited by the control points. Different parameters where used to create the shapes (such as radii, cone opening angle, etc.) and the results were identical. Finally, the number of singularities was calculated using the MATLAB rank function on the jacobian of the system with the default tolerance parameter.

The plane yields the largest number of singularities, and the numerically calculated values are equal to 3+ğ‘ğ‘¢ğ‘ğ‘£. This result holds also for larger grids, as it is possible to see from Eqs. (21)â€“(23) that the motion of each control point perpendicular to the plane creates a singularity. This set includes the rigid translation normal to the plane and the two rotations whose axes lie within the plane. The in-plane rigid translations and the rigid rotation around the normal are the 3 additional singularities, hence yielding the number 3+ğ‘ğ‘¢ğ‘ğ‘£.

Table 2 shows that for all non-planar shapes, the actual number of singularities is much smaller than 3+ğ‘ğ‘¢ğ‘ğ‘£.

Table 2 Numerically calculated number of singularities of the inextensibility constraints
Full size table
Angle Measurement Constraints
Definition of the Measurement
In order to measure the deformation of the surface, we introduce local angle measurements at several points on the surface. These measurements determine the angles between the normal to the surface and a specific direction.

We assume that the angles are measured to the line from the sensor location and the origin of â„3 which coincides with the vector ğ‘Ÿğ‘Ÿ. This can be done in practice by placing a light source at the origin and light sensors on the surface.

At each sensor location, two angles ğ›¼,ğ›½ are measured along the curvilinear coordinates, that is along âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢ and âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£ from the normal of the surface as, shown in Fig. 6.

Fig. 6
figure 6
Definition of the angles in the local coordinate system of a sensor. ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†) represents the direction to which the angles are measured. Note that the angle ğ›½ is negative in the figure (positive angles are defined from ğ‘›ğ‘› to âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢)

Full size image
The location of the sensors is defined by (ğ‘¢ğ‘†,ğ‘£ğ‘†)âˆˆâ„ğ‘ğ‘†Ã—2 where ğ‘ğ‘† is the total number of sensors. They do not need to lie on a specific grid as required by previous research [11, 14, 15]. Figure 7 shows an example of the location of the sensors in the uv-space and their position in the current configuration. The local coordinate system at the location of a sensor is also shown.

Fig. 7
figure 7
Example position of the angle sensors on the surface (green circles). The vector defining the position of a sensor ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†) is collinear with the light ray seen by the sensor (the light source is positioned at the origin). The local coordinate system at that sensor location is also shown

Full size image
The angles at a sensor location (ğ‘¢ğ‘†,ğ‘£ğ‘†) are defined as:

tanğ›¼ğ‘†=ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–
(24)
tanğ›½ğ‘†=âˆ’ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–
(25)
where ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†) is the normal to the surface:

ğ‘›ğ‘›=âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢Ã—âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£
(26)
Note that the normal of the surface needs to remain relatively close to the measurement direction, otherwise the denominator of the previous equations will approach zero. In practice, light sensors have a limited field-of-view which would limit the the measured angle in Eqs. (24) and (25) to less than 90âˆ˜.

Similar equations can be written when the angle measurement is taken from a fixed direction such as an infinitely distant light source along the vector ğ‘§ğ‘§. Then Eqs. (24) and (25) become:

tanğ›¼ğ‘†=ğ‘§ğ‘§â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)ğ‘§ğ‘§â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–
(27)
tanğ›½ğ‘†=âˆ’ğ‘§ğ‘§â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)ğ‘§ğ‘§â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–
(28)
Rank Deficiencies
The Eqs. (24) and (25) are invariant for any rotation around the origin. This is because multiplying ğ‘Ÿğ‘Ÿ by a rotation matrix also multiplies the local tangent and normal vectors. The dot products and norms are invariant by rotation. Uniform scaling (multiplying ğ‘Ÿğ‘Ÿ by a non-zero coefficient) also creates a singularity.

Numerical rank deficiencies (singular values of the jacobian close to 0) can occur when sensors are concentrated on a specific part of the structure. This has similar effect to localizing the inextensibility grid on one part of the surface (see Sect. 3.2). The shape functions only have a localized influence and if no sensor is located on a specific region of the structure then it can deform without modifying the measurement of the sensors.

To show this, we calculate the derivatives of the Eqs. (24) and (25) with respect to ğ‘ğ‘ğ‘˜ğ‘˜. Because of the complexity of these equations, it is assumed that the deformation is perfectly inextensible. This means that â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢â€–â€–, â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£â€–â€–, and â€–ğ‘›ğ‘›â€– are constant. Without loss of generality, they are set to 1. Additionally, the light source is assumed to be very far from the surface and along the z-direction (Eqs. (27) and (28)).

With these simplifications, one can show that the derivatives about an initial shape ğ‘Ÿğ‘Ÿâˆ—âˆ— can be written as:

âˆ‚tanğ›¼ğ‘†âˆ‚ğ‘ğ‘ğ‘˜ğ‘˜=tanğ›¼âˆ—ğ‘†ğ‘§ğ‘§â‹…ğ‘›ğ‘›âˆ—âˆ—â¡â£â¢â¢â¢â¢âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘£âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢âˆ’âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘¢âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘¢âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£âˆ’âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘£âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢1tanğ›¼âˆ—ğ‘†âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£â¤â¦â¥â¥â¥â¥
(29)
âˆ‚tanğ›½ğ‘†âˆ‚ğ‘ğ‘ğ‘˜ğ‘˜=tanğ›½âˆ—ğ‘†ğ‘§ğ‘§â‹…ğ‘›ğ‘›âˆ—âˆ—â¡â£â¢â¢â¢â¢âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘£âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢âˆ’âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘¢âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘¢âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£âˆ’âˆ‚ğ‘Ÿğ‘Ÿâˆ—âˆ—âˆ‚ğ‘£âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢1tanğ›½âˆ—ğ‘†âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢â¤â¦â¥â¥â¥â¥
(30)
From these equations, we can see that if â€–â€–âˆ‚ğœ™ğ‘˜âˆ‚ğ‘¢â€–â€–â‰ª1 and/or â€–â€–âˆ‚ğœ™ğ‘˜âˆ‚ğ‘£â€–â€–â‰ª1 for all (ğ‘¢ğ‘†,ğ‘£ğ‘†)âˆˆâ„ğ‘ğ‘†Ã—2 then both derivatives have components close to 0 and some columns of the jacobian will be close to 0 leading to a numerical singularity. This would be the case if, for example, only a part of the surface is covered with angle sensors. The shape functions associated with the control points located far away from the sensors will have near-zero derivatives at the sensor locations.

Surface Reconstruction as a Least-Squares Problem
The numerous constraints detailed in the previous Sects. 3 and 4 (Eqs. (13), (14), (15), (24), and (25)) are used to determine the shape of a surface parametrized with 2D Lagrange Polynomials (Sect. 2). This algorithm can be written as follows:

figure a
Here, the function RetrieveMeasurements() collects the angle measurement from all sensors (or creates random measurements in the case of simulations), GetCPLocations() is a minimization function described in the next Sect. 5.1 and GetShape() is simply Eq. (3). The algorithm loops indefinitely as long as measurements are available. A result, i.e., a shape of the structure is given at the end of each loop. GetCPLocations() gets initiated by the result of the previous loop except for the first loop where an initial guess is given.

System of Equations
Eqs. (13), (14), (15), (24), and (25) form a system that solves the problem of reconstructing a surface from angle measurements undergoing an inextensible deformation from a template:

âˆ«ğ‘¢Ì‚ ğ‘–+1ğ‘¢Ì‚ ğ‘–â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–â€–ğ‘‘ğ‘¢âˆ’âˆ«ğ‘¢Ì‚ ğ‘–+1ğ‘¢Ì‚ ğ‘–â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢(ğ‘¢,ğ‘£Ì‚ ğ‘—)â€–â€–â€–ğ‘‘ğ‘¢=0âˆ€ğ‘–=1,...,ğ‘Ì‚ ğ‘¢âˆ’1,âˆ€ğ‘—=1,...,ğ‘Ì‚ ğ‘£âˆ«ğ‘£Ì‚ ğ‘—+1ğ‘£Ì‚ ğ‘—â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–â€–ğ‘‘ğ‘£âˆ’âˆ«ğ‘£Ì‚ ğ‘—+1ğ‘£Ì‚ ğ‘—â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£)â€–â€–â€–ğ‘‘ğ‘£=0âˆ€ğ‘–=1,...,ğ‘Ì‚ ğ‘¢,âˆ€ğ‘—=1,...,ğ‘Ì‚ ğ‘£âˆ’1âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢ğ‘‡(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)=âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘¢ğ‘‡(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ‚ğ‘Ÿğ‘Ÿ00âˆ‚ğ‘£(ğ‘¢Ì‚ ğ‘–,ğ‘£Ì‚ ğ‘—)âˆ€ğ‘–=1,...,ğ‘Ì‚ ğ‘¢,âˆ€ğ‘—=1,...,ğ‘Ì‚ ğ‘£tanğ›¼âˆ’ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–=0âˆ€ğ‘†=1,...,ğ‘ğ‘†tanğ›½+ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)ğ‘Ÿğ‘Ÿ(ğ‘¢ğ‘†,ğ‘£ğ‘†)â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–=0âˆ€ğ‘†=1,...,ğ‘ğ‘†
(31)
Replacing ğ‘Ÿğ‘Ÿ with Eq. (3) everywhere, the system is a function of the unknown control point coordinates, and can be written as:

ğ‘“ğ‘˜(ğ‘ğ‘Â¯)=0âˆ€ğ‘˜=1,...,ğ‘ğ‘’ğ‘
(32)
where ğ‘“ğ‘˜(â‹…) represents the equations defined in (31), ğ‘ğ‘’ğ‘=3ğ‘Ì‚ ğ‘¢ğ‘Ì‚ ğ‘£âˆ’ğ‘Ì‚ ğ‘¢âˆ’ğ‘Ì‚ ğ‘£+2ğ‘ğ‘† is the number of equations in the system, and ğ‘ğ‘Â¯ is the unknown vector defined as the vertical concatenation of the control points. Since this system is (usually) overconstrained, we rewrite the problem as a least-squares minimization:

ğ‘ğ‘Â¯âˆ—=argminğ‘ğ‘Â¯âˆ‘ğ‘˜=1ğ‘ğ‘’ğ‘ğ‘“2ğ‘˜(ğ‘ğ‘Â¯)=argminğ‘ğ‘Â¯â€–ğ‘“ğ‘“(ğ‘ğ‘Â¯)â€–2
(33)
where ğ‘“ğ‘“(ğ‘ğ‘Â¯)=[ğ‘“1(ğ‘ğ‘Â¯),...,ğ‘“ğ‘ğ‘’ğ‘(ğ‘ğ‘Â¯)]ğ‘‡.

Solution of Overconstrained System
In order to solve the least-squares problem defined in Eq. (33), a locally optimal solution, given an initial guess can be found using the Levenberg-Marquardt method in MATLAB [34].

This iterative algorithm starts with an initial guess ğ‘ğ‘Â¯0 (for which details are provided in Sect. 6.5) , finds increments of the unknown vector, ğ›¿ğ›¿ğ‘ğ‘Â¯ğ‘˜ğ‘˜, such that at the next step, ğ‘ğ‘Â¯ğ‘˜+1=ğ‘ğ‘Â¯ğ‘˜+ğ›¿ğ›¿ğ‘ğ‘Â¯ğ‘˜ğ‘˜. The increment at each step solves the equation:

(ğ‰ğ‘‡ğ‰+ğœ†ğ‘˜ğˆ)ğ›¿ğ›¿ğ‘ğ‘Â¯ğ‘˜ğ‘˜=âˆ’ğ‰ğ‘‡ğ‘“ğ‘“(ğ‘ğ‘Â¯ğ‘˜)
(34)
where ğ‰=âˆ‚ğ‘“ğ‘“âˆ‚ğ‘ğ‘Â¯ is the jacobian of the system and ğœ†ğ‘˜ is a non-negative damping factor that is optimized at each step to maximize the decrease in the residual. If ğœ†ğ‘˜=0 this algorithm is equivalent to the Gauss-Newton algorithm (GNA). It is however more robust than GNA when the initial guess is far from the solution. When ğœ†ğ‘˜â†’âˆ, the algorithm tends to the gradient descent algorithm. As a result, the Levenberg-Marquardt method is a hybrid of the two algorithms.

The Levenberg-Marquardt algorithm stops when the increment is smaller than a prescribed tolerance , i.e. when:

â€–ğ›¿ğ›¿ğ‘ğ‘Â¯ğ‘˜ğ‘˜â€–<ğœ–
(35)
It is important to note that since the system is over-constrained and the stopping criterion involves the norm of the increment, the scaling of the Eqs. (31) matters. This will be shown through examples in the next section.

Rank Deficiencies
The jacobian of the system can be calculated as the vertical concatenation of the jacobian studied in sub-sect. 3.2 and 4.2. In order to use the Levenberg-Marquardt algorithm, the jacobian needs to be full rank, i.e., its columns need to be independent.

A first requirement is to have more equations than unknowns: ğ‘ğ‘’ğ‘=3ğ‘Ì‚ ğ‘¢ğ‘Ì‚ ğ‘£âˆ’ğ‘Ì‚ ğ‘¢âˆ’ğ‘Ì‚ ğ‘£+2ğ‘ğ‘†>3ğ‘ğ‘¢ğ‘ğ‘£. This is only a necessary condition, observations from sub-sects. 3.2 and 4.2 show that the jacobian remains singular under certain motions.

All equations are invariant for rigid-body rotations around the origin. Without loss of generality, we constrain 3 coordinates among the control points to be fixed. For instance, one point is restrained from moving along the x-axis and y-axis, and another point is constrained from moving along the x-axis.

Additionally, the inextensibility conditions can have up to ğ‘ğ‘¢ğ‘ğ‘£ singularities as explained in sub-sect. 3.2. These are mutually exclusive with the singularities of the angle equations. As a result, a minimum of ğ‘ğ‘¢ğ‘ğ‘£ angle measurements are needed to have a full rank jacobian, i.e. at least as many angle measurements as control points.

It is important to notice that when the distance from the origin to the surface becomes large, another numerical singularity emerges. It corresponds to a spherical motion. Figure 8 shows a schematic of this singularity in 2D. A line perpendicular to the light source can conform to any circle, hence there are infinitely many solutions. In 3D, this is not a singularity as its associated singular value is not exactly 0: conforming a section of a sphere to a sphere of different radius is an extensible deformation. This singularity is however orders of magnitude lower than the next higher which causes numerical issues. We call this singularity a spherical singularity.

To remedy this issue, the distance of a point on the surface to the origin can be fixed or bounded. This would ensure that the solution remains at a relative distance from the light source, removing the effect of the spherical singularity which allows large translation with relative small shape deformations.

In the case where the direction of the angle measurement is fixed (Eqs. (27) and (28)), this numerical singularity becomes an actual singularity corresponding to the rigid-body translation along that direction. Fixing a point in 3D space can be done without loss of generality.

Fig. 8
figure 8
2D representation of the spherical singularity of the system of equations. The black and red lines have the same length and angles to the light source but their shapes are different

Full size image
Simulation Results
A set of simulations is performed to better understand the performance of the proposed method and highlight its limitations.

The surface to reconstruct is a piece of paper of size A4 (297Ã—210 mm2).The sheet is initially flat (reference configuration). It is deformed to a conical shape located 1 m away from the light source. It is assumed that the sensors have a 90âˆ˜ field of view so that the surface can bend to large angles relative to the light. They are also assumed to be small so that they do not constrain the deformation of the sheet otherwise.

Unless specified, a grid of 7Ã—5 control points is used to generate the Lagrange shape functions. An identical grid is used for the inextensible grid and each vertex is the location of a sensor. Each sensor has gaussian noise which is assumed identical for all sensors and set to a standard deviation of 10 arcminutes (3ğœ of 0.5âˆ˜). The effect of the noise on the reconstructed shape will be studied. A total of 500 measurements is generated in order to get statistically accurate results.

Reconstruction accuracy. The error of the reconstruction is calculated as the norm of the vector joining the points with equal coordinates (u, v) in the reconstructed and exact shapes:

Error(ğ‘¢,ğ‘£)=â€–ğ‘Ÿğ‘Ÿ(ğ‘¢,ğ‘£)âˆ’ğ‘Ÿğ‘Ÿ~(ğ‘¢,ğ‘£)â€–
(36)
To characterize the accuracy of the method over the whole surface for many different reconstructions, the mean error, which corresponds to the average distance between the reconstructed and true shapes is calculated:

ğ‘’=1|ğ´|âˆ«ğ´â€–ğ‘Ÿğ‘Ÿ(ğ‘¢,ğ‘£)âˆ’ğ‘Ÿğ‘Ÿ~(ğ‘¢,ğ‘£)â€–ğ‘‘ğ‘¢ğ‘‘ğ‘£
(37)
where A is the surface area of the sheet of paper.

Inextensibility. The isometry of the surface deformation is evaluated by plotting the error of the 3 elements of the metric tensor from their nominal values defined in Eqs. (10)â€“ (12). Note that in this case, ğŒ0=ğˆ, the 2Ã—2 identity tensor (developable surface).

To better understand the elements of the tensor, we plot the Lagrangian normal and shear strains of the surface [35]. They are given by:

ğœ–ğ‘¢=12(ğŒ11âˆ’1)
(38)
ğœ–ğ‘£=12(ğŒ22âˆ’1)
(39)
ğ›¾ğ‘¢ğ‘£=ğŒ12
(40)
Fig. 9
figure 9
Actual and reconstructed conical shapes viewed from the light source located 1 m in front of the structure

Full size image
Reconstruction Errors
Figure 9 shows the average reconstructed shape from the 500 generated measurements of the angle sensors as well as the actual conical shape. They agree well qualitatively as little to no difference can be seen.

Fig. 10
figure 10
RMS error of reconstructed conical shapes based on 500 simulated sensor measurements

Full size image
To further understand the accuracy of the method, the RMS error of the reconstructed shapes along the curvilinear coordinates is calculated and shown in Fig. 10. Note that rigid-body motions between the reconstructed and actual shapes were removed. The error is maximum towards the top of the sheet which is where the curvature is maximum. This is due to the fact that polynomial shape functions cannot perfectly reconstruct circular segments, which introduce errors in the reconstruction. The mean error of the reconstructions is equal to 0.3Â±0.03 mm (standard deviation from all the reconstructed surfaces).

To analyze the effect of the inextensibility constraints, the normal and shear strains are plotted in Fig. 11. The values correspond to the average strains over the 500 reconstructed shapes.

The normal strains are close to 0 on average along each segment of the inextensibility grid. However, they still vary across the surface. A similar observation can be made for the shear strains that are also close to 0 at each node of the inextensibility grid but are non-zero elsewhere.

The normal strain in the u-direction is dominant and increases as the curvature increases. Since Lagrange polynomials cannot perfectly reconstruct circular segments, the algorithm needs to stretch the surface in order for the measured angles to better match their set values. More precisely, the algorithm does a tradeoff between slightly stretching the surface and adding some bias to the measured angles.

The shear strain variation is related to the normal strains: the small non-uniform accumulated strain displaces the points of the surface forcing it to shear.

These results are similar to some monocular template-based surface reconstruction algorithm such as Second Order Cone Programs (SOCP) [6]. Some algorithms out-perform the one presented in this paper as denser meshes can be used to represent the surface since more measurement data is available.

Fig. 11
figure 11
Average strains of reconstructed conical shapes

Full size image
Effect of Sensor Noise
Fig. 12
figure 12
Mean error of reconstructed conical shapes

Full size image
Figure 12 shows the evolution of the mean error across the surface in function of the 3ğœ noise of the sensors.

For the studied structure and shape, the error rapidly increases with the noise of the sensor. For sufficiently low noise, the error does not vary significantly as it is limited by the efficiency of the shape functions to accurately represent the shape of the surface. In this case, the minimum error considering perfect sensors is 0.26 mm. This sets a bound on the accuracy of the sensors. There is no need for very accurate sensors (3ğœ noise below 0.1âˆ˜) as they do not provide significantly better results. More accurate shape functions (such as NURBS) could decrease this minimum error and justify the use of more precise sensors.

The uncertainty of the reconstructed shape shown in Fig. 12 by the gray area which represents the standard deviation of the mean error also increases as the noise of the sensors increase: not only the accuracy gets worse, it is also less predictable.

Convergence of Solution
To verify the convergence of the solution, the number of control points was increase effectively increasing the order of the Lagrange polynomials. To avoid rank deficiencies, the number of sensors needs to be increased. The same grid was used for the interpolation points of the Lagrange polynomials, inextensibility constraints and angle measurements. Its size was increased using the following sequence: 5Ã—3, 7Ã—5, 9Ã—7, 11Ã—7, 13Ã—9, 15Ã—11, and 17Ã—13.

Fig. 13
figure 13
Variation of the mean error between reconstructed and actual shapes by varying the grids size

Full size image
The convergence results for the conical shape are shown in Fig. 13. The x-axis shows the size of the grid while the y-axis shows the mean error (solid line) and standard deviation (gray area) from 500 sensor measurements. It can be seen that, as the grid gets more refined, the accuracy of the algorithm is improved, as expected.

Note that convergence issues arise for denser grids. The initial shape is modified to be close to the solution by positioning each control points at its location on the conical shape (Fig. 9a). More details are presented in sub-sect. 6.5. Sparse grids do not show convergence issues based on the initial shape.

Fig. 14
figure 14
Mean error of reconstructed shapes while varying different parameters of the algorithm using a 7Ã—5 grid of control points

Full size image
Variation of Algorithm Parameters
For a fixed number of control points, the solution depends on three sets of parameters: the number and position of the angle sensors, the coordinates of the inextensibility grid, and the weight of each equation of system (31). By changing these parameters, the algorithm converges to different solutions that will have different errors. All parameters were varied for a fixed 7Ã—5 grid of control points, and their impact on the mean error of the reconstructed cone have been studied. The results are shown in Fig. 14.

The size of the inextensibility grid was varied from 5Ã—5 to 17Ã—13. The minimum grid size was dictated by the minimum number of equations needed in order to have a well-posed problem. The results of varying this grid size are shown in Fig. 14a. The curve is not monotonic and there exists an optimum grid size that provides the lowest mean error.

Varying the number of angle measurements was performed by spreading the sensors on a uniform grid whose size ranges from 5Ã—5 to 15Ã—11 while using fixed 7Ã—5 control points and inextensibility grids. The results are shown in Fig. 14b. Similarly, an optimal grid of sensors provides the lowest mean error.

As stated in sub-sect. 5.2, the weight of each equation of the system is important. We investigate the difference of weight between the first 3 equations, which relate to the inextensibility of the surface and the last two, which impose constraints on the measured angles. Note that the first two equations of system (31) were made adimensional by dividing by the length of the edges of the inextensibility grid in the reference configuration. The other constraints are properly scaled and do not depend on the size of the grids. Figure 14c shows the influence of scaling the constraints. The inextensibility conditions were multiplied by a scaling factor ğœ†ğ¼=1 and the angle constraints by ğœ†ğ´ which varies from 10âˆ’2 to 102. An optimal gain (ğœ†ğ´=1) yields an optimal reconstruction.

All graphs show similar results. The error evolves as a function of the parameters. It gets higher for more sparse and denser grids and reaches a minimum in-between. This can be explained by the fact that the shape is approximated by Lagrange shape functions. Because of this approximation, the reconstructed shape is neither perfectly inextensible, nor it perfectly matches the angle measurements. Some relaxation of the constraints is needed. As a result, increasing the size of the grids leads to many constraints that cannot be met by the approximated shape. Inversely, smaller grids give more weights to the other equations. Varying the scaling of the equations forces the algorithm to enforce constraints more or less tightly.

An optimization program could be developed to optimize the parameters of the algorithm to minimize the mean error of its solution to desired shapes. Results presented in this paper show that matching the inextensibility grid with the control points and the angle sensors leads to a near optimal scheme.

Influence of the Initial Shape
As mentioned in the previous section, the initialization of the algorithm may affect the results as the cost function is non-convex. To illustrate this point, we study the case of 9Ã—7 grids for control points, inextensibility grids and sensor locations. It was noticed that all initial shapes for sparser grids lead to a converged solution. We study the result of the algorithm from different initial shapes ranging from a flat one (used as the initial shape in sub-sect. 6.1) to the solution (Fig. 9a):

Initial Shape=ğ›¼[Flat]+(1âˆ’ğ›¼)[Conical Solution]
(41)
where ğ›¼ ranges from 0 to 1.

Results are shown in Fig. 15. The algorithm does not converge for high values of ğ›¼ (close to the flat shape) but eventually converges when the initial shape is close enough to the solution. Note that the curve is not monotonic which may be due to the non-convexity of the problem.

Fig. 15
figure 15
Mean error of reconstructed shapes using 9Ã—7 grids depending on the initial shape

Full size image
Fig. 16
figure 16
Actual and reconstructed conical shapes using IMUs and different algorithms

Full size image
Fig. 17
figure 17
Average normal strain in the u-direction using IMUs and different algorithms

Full size image
To circumvent this issue, a simple solution obtained from a small number of control points can be solved first as it appears to be more reliable and less dependent on the initial shape. This solution can be used as a starting point for denser grids of control points. This can be done recursively. Once converged, the algorithm does not appear to have problems following changes in sensor inputs.

Computation Time
The computation time is dependent on the number of constraints and control points. Both influence the size of the jacobian matrix used in the Levenberg-Marquardt algorithm which eventually has to be inverted. No particular effort was made to optimize the speed of the algorithm except pre-computing the values of the Lagrange shape functions and its derivatives at the different locations on the surface (the different integrations used in the isometry constraints were performed using Simpsonâ€™s rule).

Having the initial shape relatively far also increases the computation time as many iterations need to be performed. Once converged, the reconstructed shape can be used as the initial point for the next reconstruction using a new set of measurements. This next iteration of the algorithm becomes much quicker.

To compute the reconstructed shapes shown in Fig. 9b, the algorithm was run using MATLAB on an Intel Core i5-6200 CPU. The first iteration of the algorithm takes about 5 s to run as the initial shape is far from the solution. The subsequent steps take 50 ms on average as only a couple loops of the Levenberg-Marquardt method are needed.

Comparison to the State-of-the-Art
To the knowledge of the authors, no other methodology exists to reconstruct the shape of a surface with embedded local angle measurements such as light sensors. However, related research has used another type of sensor, Inertial Measurement Units (IMUs), which measure the direction of Earthâ€™s gravity and magnetic field, not by measuring angles but by measuring the coordinates of these vectors along the 3 axes of the sensor which correspond to the 3 local axes of the surface. The measurement equations are similar to Eqs. (27) and (28) which can be re-written to express the unit vector collinear with the light direction in the local reference system of the sensor:

ğ‘§ğ‘§ğ‘†=â¡â£â¢â¢â¢â¢â¢tanğ›¼ğ‘†1+tan2ğ›¼ğ‘†+tan2ğ›½ğ‘†âˆšâˆ’tanğ›½ğ‘†1+tan2ğ›¼ğ‘†+tan2ğ›½ğ‘†âˆš11+tan2ğ›¼ğ‘†+tan2ğ›½ğ‘†âˆšâ¤â¦â¥â¥â¥â¥â¥=â¡â£â¢â¢â¢â¢â¢â¢ğ‘§ğ‘§â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–ğ‘§ğ‘§â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–ğ‘§ğ‘§â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â¤â¦â¥â¥â¥â¥â¥â¥
(42)
This expression is equivalent to Eqs. (27) and (28) as it carries two independent pieces of information since all vectors are unit vectors (including ğ‘§ğ‘§). In the case of an IMU, two directions are measured directly:

ğ‘”ğ‘”ğ‘ ğ‘ =â¡â£â¢â¢â¢â¢â¢â¢ğ‘”ğ‘”â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–ğ‘”ğ‘”â‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–ğ‘”ğ‘”â‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â¤â¦â¥â¥â¥â¥â¥â¥
(43)
ğµğµğ‘†ğ‘†=â¡â£â¢â¢â¢â¢â¢â¢ğµğµâ‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘¢(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–ğµğµâ‹…âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–âˆ‚ğ‘Ÿğ‘Ÿâˆ‚ğ‘£(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â€–ğµğµâ‹…ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–ğ‘›ğ‘›(ğ‘¢ğ‘†,ğ‘£ğ‘†)â€–â¤â¦â¥â¥â¥â¥â¥â¥
(44)
where ğ‘”ğ‘”ğ‘ ğ‘  (resp. ğµğµğ‘†ğ‘†) is Earthâ€™s gravity (resp. magnetic field) measured by the sensor and ğ‘”ğ‘” (resp. ğµğµ) is the direction of Earthâ€™s gravity (resp. magnetic field) in the global reference system (all unit vectors).

Fig. 18
figure 18
Average normal strain in the u-direction using IMUs and different algorithms

Full size image
Equations (43) and (44) were used instead of the previously introduced angle measurements (Eqs. (27) and (28)). They are very similar in nature except that two non-collinear directions are measured instead of one and the measurement is better behaved as coordinates stay bounded, unlike the tangent function.

These new measurement equations were integrated in the algorithm and simulations based on this approach were used to evaluate the performance of the presently proposed method. The results are compared to two state-of-the-art algorithms [11] and [14]. The same size of surface, location of sensors, noise of sensors, inextensibility grid and control points as the simulation in the previous section are used.

Hermanis et al. [11] propose a linear algorithm to reconstruct the shape. The two measured vectors (ğ‘”ğ‘”ğ‘†ğ‘† and ğµğµğ‘†ğ‘†) are used to compute the tangent vectors of the surface at each sensor location without ambiguity. It is then assumed that the sensors are connected by means of rigid bars. The position of each sensor is then calculated by integrating the tangent vectors, effectively using a midpoint integration rule. The position of each sensor is calculated as the average result from two different integration schemes: (1) the position of the sensors placed on the central row is calculated by integrating along u and using the central sensor as a reference (clamped to the origin of the coordinate system). The position of the other sensors are calculated by integrating along v using the position of the sensors on the central row as reference. (2) The position of the sensors on the central column are calculated first then the ones on each row. The rest of the surface is calculated from the position of each sensor using a bilinear interpolation scheme.

Fig. 19
figure 19
Average normal strain in the u-direction using IMUs and different algorithms

Full size image
Fig. 20
figure 20
Average shear strain using IMUs and different algorithms

Full size image
Saguin-Sprynski et al. [14] use a more complex integration scheme. The tangent vectors at each sensor location are also inferred from the measurements. Then the bottom and left edge of the surface (aligned with the bottom left sensor) are calculated by integrating the tangent vector which is interpolated from the sensor data using cubic splines on the sphere [36]. The location of the other sensors is calculated iteratively from a constrained minimization problem that enforces isometry along the curves between sensors while matching the sensor data. The surface is finally reconstructed using a partially bi-cubically blended Coons process [37].

Reconstruction Errors
The shapes reconstructed by each algorithm are shown in Fig. 16. Each method is able to capture the overall shape of the structure. Figure 18d shows the RMS error of the reconstructions across the surface. Different amounts of error between algorithms are clearly visible. The one from Hermanis et al. [11] is the less accurate with a mean error of 2.01Â±0.01 mm. While the error on the curves between sensors is relatively small, the simple filling method creates large errors when the curvature increases. The algorithm from Saguin-Sprynski et al. [14] yields a mean error of 1.3Â±0.06 mm. While smoother, this method reconstructs the surface from the bottom left corner to the top right while strictly enforcing inextensibility on the curves between sensors. As a result, the error is maximal on the top right corner as the noise of the sensors and errors in the integration method propagates. One can see in Fig. 16c that the surface slightly shears to the right which is a consequence of the strict length constraints. Finally our proposed method has a mean error of 0.26Â±0.01 mm. Note that this value is a bit lower than the mean error of 0.3Â±0.03 obtained from light sensors, quoted in Sect. 6.1, because each IMU provides four pieces of information instead of two. Also note that the overall pattern of the RMS error, in Fig. 18a, is very similar to Fig. 10. Overall, this result is better than the state-of-the-art by almost an order of magnitude under the same conditions.

Fig. 21
figure 21
Mean error of reconstructed shapes using IMUs and different algorithms

Full size image
Figures 18, 19 and 20 show the average strain components of the reconstructed shapes. The normal strains are similar in terms of amplitude and overall shape for all different algorithms. They are largest at the top where the curvature is largest as the parameterization of the shapes cannot perfectly capture this effect. The main difference occurs for the shear strain. Our method outperforms the other by a factor of 2.5 or more. This is to be expected as our method includes the shear strains in the inextensibility formulation of the surface. This limits the propagation of an in-plane shift that can be seen in the reconstructed shape in Fig. 16c.

Effect of Sensor Noise
As in the previous section, the mean error of each algorithm is studied as a function of the noise of the sensors. The results are shown in Fig. 21 in logarithmic scale to compare the shape of each curve while the results are an order of magnitude different. The accuracy of each method is monotonic with the noise of the sensor, eventually reaching a plateau for low noise which corresponds to the minimum error possible with perfect sensors. This number is intrinsic to each algorithm and characterizes the efficiency of the method. In this respect, our algorithm does a much better job, as its asymptote is about an order of magnitude lower than the other ones. However, the error increases faster when the 3ğœ noise is greater than 1âˆ˜ which shows the importance of using precise sensors for our proposed method.

Convergence of Solution
The convergence of each method is studied by increasing the number of sensors. The results are shown in Fig. 22. For our method, we also increase the number of control points and size of inextensibility grid such that they all coincide as in sub-sect. 6.3. The mean error of the reconstructed shape using the algorithm presented in this paper decreases more rapidly as the density of sensors increases compared to the other methods. This means that adding even a few sensors has a much greater impact on the error, which can be very beneficial in practical applications. The error of the two other methods remains higher and eventually the two methods converge, as the linear integration along the curves between sensors used in Hermanis et al. [11] is a good approximation for the higher-order integration method in Saguin-Sprynski et al. [14].

Computation Time
Each algorithm was implemented following the explanations given in their respective paper. No particular effort was taken to optimize their speed.

Table 3 shows the time taken by each algorithm to reconstruct a shape. Each shape is used to initialize the next step, to accelerate the process. The method proposed by Hermanis et al. [11] is the fastest by two orders of magnitude as it is based on linear calculations. The method proposed by Saguin-Sprynski et al. [14] is the slowest as it has to solve a non-linear, constrained minimization algorithm to compute the position of 24 out of the 35 sensor locations. The method proposed in this paper involves a non-linear unconstrained minimization, and yields faster results than [14] by a factor of 3.

Results for Multiple Reconstructions
To further show the net increase of performance of the proposed solution against the current state-of-the-art, each algorithm is used to reconstruct a set of random paper deformations, generated from the algorithm described in [38]. A set of 3 guiding rulings are randomly placed on the sheet of paper. The rotation angles along the rulings are randomly selected withing the Â±10âˆ˜ interval. This creates shapes with angular deformations greater than 45âˆ˜. Ten extra rulings are used to create a smooth surface. From this shape generation algorithm, the position of each point on the paper as well as the jacobian of the deformation at each sensor location are retrieved. The latter is used to compute the sensor data which also includes 0.5âˆ˜ noise. A total of 100 shapes are generated and 10 sensors measurements are simulated for each shape yielding 1000 different reconstructions from each algorithm. All parameters used in the previous subsections remain identical. The error of each method is shown in Table 4. Similarly to the results gathered from the reconstruction of a cone, the proposed solution performed better on average. Note that the algorithm from Saguin-Sprynski et al. [14] is much less stable and resulted in a higher error overall.

Fig. 22
figure 22
Variation of the mean error between reconstructed and actual shapes by varying the grids size using IMUs and different algorithms

Full size image
Table 3 Reconstruction errors using different reconstruction algorithms over 100 randomly generated surfaces
Full size table
Surface Reconstruction with Real Data and Small Deformations
An experiment was conducted to validate the proposed solution method using real data.

Table 4 Computation time of different reconstruction algorithms using 7Ã—5 IMU sensors
Full size table
Fig. 23
figure 23
Photo of the experiment. The plate with a black and white Digital Image Correlation (DIC) pattern holds 14 sensors placed on rigid supports. The plate is held by tensioned spring cables at each end and two linear actuators in the middle (the actuator attached to the center of the structure is not visible)

Full size image
Fig. 24
figure 24
Results from the experiments

Full size image
Fig. 25
figure 25
RMS error of the reconstructed shapes

Full size image
Light sensors were developed using a quad-photodiode (OPR5911) with a square aperture placed on top, effectively creating a 4-pixel pinhole camera [39, 40]. A total of 14 sensors were placed on a 50â€ x 10â€ (1.27 m Ã— 0.254 m) aluminum sheet in two rows of 7 separated by 8â€ (20.32 cm) in all directions. The accuracy of the sensors was 0.5âˆ˜ (3ğœ).

A LED light source was placed about 2 m in front of the aluminum sheet. A random black and white pattern was painted on the sheet in order to measure its shape with a precise Digital Image Correlation system (DIC) from Correlated Solutions, as shown in Fig. 23. This system has an accuracy of about 50 ğœ‡ğ‘š, an order of magnitude better than the expected accuracy of the light sensor system. As a result, it can be used as a ground truth to estimate the performance of the proposed solution.

Two different types of deformation are imposed on the structure: a 2 cm deflection and a 5âˆ˜ twist. Figure 24 shows the deformation of the sheet in both cases, as measured by the DIC and as computed by the presented algorithm using the light sensor data. The shape retrieved from the DIC system only images the central part of the sheet as the sensors and cables obstruct the view of the pattern. Our method can however reconstruct the whole surface and Figs. 24c and 24d show an excellent qualitative agreement between shapes.

The RMS error between the two shapes is shown in Fig. 25. A total of 1000 sets of measurements were taken in order to generate 1000 reconstructed shapes and thus provide statistically accurate results. The RMS error is lower than 1 mm on average (0.6 mm for both cases) and is localized to regions of the sheet that have more localized deformations. The proposed methodology can best reconstruct relatively smooth surfaces as the errors increase when the deformation becomes more localized. A finite-element based reconstruction algorithm that is more accurate for such cases and also for larger deformations, at the expense of much lengthier solution times, is provided in [40].

Simulations were performed by first computing the shape of the sheet from a mechanical model of the experimental setup using the commercial finite-element software Abaqus. The same algorithm was then used to estimate the accuracy of the sensor system, assuming a zero-mean, 0.5âˆ˜ (3ğœ) gaussian noise for each sensor. Such simulations predicted a 0.65 mm RMS error for the 2 cm deflection case and 1.2 mm for the 5âˆ˜ twist case. These results are very close to those of the experiment.

Conclusion and Discussion
We have presented a mathematical model to reconstruct the shape of a 3D surface based on a template and the angle measurements from embedded sensors. The template is a known configuration of the surface and it is assumed that it deforms inextensibly to its current configuration.

The performance of this method which is suitable for situations where holding a camera in front of a surface is not practical has been tested and validated through simulations and experiments. The formulation yields better results than the state-of-the-art using embedded IMU sensors.

The formulation is similar to SfT-SfS algorithms which also assume inextensibility of the deformation from a template and integrate the shape from the computation of the surface normal. More work could be done to use the explicit measurement of the normal from the embedded sensors together with these algorithms which are usually energy-based.

Aerospace is one of the application areas for this method. Sun sensors are already widely used in this industry for attitude control, and together with this algorithm, could be used to measure the shape of a deployable or reconfigurable structure in space (such as solar sails or large antenna arrays). Wearable technologies used for augmented reality, medical purposes or robotics are other applications of this method using such sensors (usually IMUs).

The choice of shape functions used to define the shape of the surface can also limit the accuracy of the algorithm. More work could be done to study a wider range of functions such as NURBS or dense, mesh-based functions.

Only developable surfaces have been considered in this study. More work should be done to understand the performance of the presented algorithm on more complex shapes such as doubly curved surfaces and surfaces with localized deformations like kinks or buckles.

