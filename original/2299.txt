We propose novel first-order stochastic approximation algorithms for canonical
correlation analysis (CCA). Algorithms presented are instances of inexact matrix
stochastic gradient (MSG) and inexact matrix exponentiated gradient (MEG), and
achieve ✏-suboptimality in the population objective in poly( 1
✏ ) iterations. We also
consider practical variants of the proposed algorithms and compare them with other
methods for CCA both theoretically and empirically.
1 Introduction
Canonical Correlation Analysis (CCA) [11] is a ubiquitous statistical technique for finding maximally
correlated linear components of two sets of random variables. CCA can be posed as the following
stochastic optimization problem: given a pair of random vectors (x, y) 2 Rdx ⇥ Rdy , with some
(unknown) joint distribution D, find the k-dimensional subspaces where the projections of x and y
are maximally correlated, i.e. find matrices U˜ 2 Rdx⇥k and V˜ 2 Rdy⇥k that
maximize Ex,y[x>U˜V˜ >y] subject to U˜ >Ex[xx>]U=I ˜ k, V˜ >Ey[yy>]V=I ˜ k. (1)
CCA-based techniques have recently met with success at unsupervised representation learning where
multiple “views” of data are used to learn improved representations for each of the views [3, 5, 13,
23]. The different views often contain complementary information, and CCA-based “multiview”
representation learning methods can take advantage of this information to learn features that are
useful for understanding the structure of the data and that are beneficial for downstream tasks.
Unsupervised learning techniques leverage unlabeled data which is often plentiful. Accordingly,
in this paper, we are interested in first-order stochastic Approximation (SA) algorithms for solving
Problem (1) that can easily scale to very large datasets. A stochastic approximation algorithm is an
iterative algorithm, where in each iteration a single sample from the population is used to perform an
update, as in stochastic gradient descent (SGD), the classic SA algorithm.
There are several computational challenges associated with solving Problem (1). A first challenge
stems from the fact that Problem (1) is non-convex. Nevertheless, akin to related spectral methods
such as principal component analysis (PCA), the solution to CCA can be given in terms of a
generalized eigenvalue problem. In other words, despite being non-convex, CCA admits a tractable
31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.
algorithm. In particular, numerical techniques based on power iteration method and its variants can
be applied to these problems to find globally optimal solutions. Much recent work, therefore, has
focused on analyzing optimization error for power iteration method for the generalized eigenvalue
problem [1, 8, 24]. However, these analyses are on numerical (empirical) optimization error for
finding left and right singular vectors of a fixed given matrix based on empirical estimates of the
covariance matrices, and not on the population ✏suboptimality (aka bound in terms of population
objective) of Problem (1) which is the focus here.
The second challenge, which is our main concern here, presents when designing first order stochastic
approximation algorithms for CCA. The main difficulty here, compared to PCA, and most other
machine learning problems, is that the constraints also involve stochastic quantities that depend on the
unknown distribution D. Put differently, the CCA objective does not decompose over samples. To see
this, consider the case for k = 1. The CCA problem then can be posed equivalently as maximizing
the correlation objective ⇢(uT x, vT y) = Ex,y
⇥
u>xy>v
⇤
/(
pEx [u>xx>u] pEy [v>yy>v]). This
yields an unconstrained optimization problem. However, the objective is no longer an expectation,
but is instead a ratio of expectations. If we were to solve the empirical version of this problem,
it is easy to check that the objective ties all the samples together. This departs significantly from
typical stochastic approximation scenario. Crucially, with a single sample, it is not possible to get an
unbiased estimate of the gradient of the objective ⇢(uT x, vT y). Therefore, we consider a first-order
oracle that provides inexact estimates of the gradient with a norm bound on the additive noise, and
focus on inexact proximal gradient descent algorithms for CCA.
Finally, it can be shown that the CCA problem given in Problem (1) is ill-posed if the population
auto-covariance matrices Ex
⇥
xx>⇤
or Ey
⇥
yy>⇤
are ill-conditioned. This observation follows from
the fact that if there exists a direction in the kernel of Ex
⇥
xx>⇤
or Ey
⇥
yy>⇤
in which x and y
exhibit non-zero covariance, then the objective of Problem (1) is unbounded. We would like to avoid
recovering such directions of spurious correlation and therefore assume that the smallest eigenvalues
of the auto-covariance matrices and their empirical estimates are bounded below by some positive
constant. Formally, we assume that Cx ⌫ rxI and Cy ⌫ ryI. This is the typical assumption made in
analyzing CCA [1, 7, 8].
1.1 Notation
Scalars, vectors and matrices are represented by normal, Roman and capital Roman letters respectively,
e.g. x, x, and X. Ik denotes identity matrix of size k ⇥ k, where we drop the subscript whenever the
size is clear from the context. The `2-norm of a vector x is denoted by kxk. For any matrix X, spectral
norm, nuclear norm, and Frobenius norm are represented by kXk2, kXk⇤, and kXkF respectively.
The trace of a square matrix X is denoted by Tr(X). Given two matrices X 2 Rk⇥d, Y 2 Rk⇥d, the
standard inner-product between the two is given as hX, Yi = Tr
X>Y

; we use the two notations
interchangeably. For symmetric matrices X and Y, we say X ⌫ Y if X  Y is positive semi-definite
(PSD). Let x 2 Rdx and y 2 Rdy denote two sets of centered random variables jointly distributed as
D with corresponding auto-covariance matrices Cx = Ex[xx>], Cy = Ey[yy>], and cross-covariance
matrix Cxy = E(x,y)[xy>], and define d := max{dx, dy}. Finally, X 2 Rdx⇥n and Y 2 Rdy⇥n
denote data matrices with n corresponding samples from view 1 and view 2, respectively.
1.2 Problem Formulation
Given paired samples (x1, y1),...,(xT , yT ), drawn i.i.d. from D, the goal is to find a maximally
correlated subspace of D, i.e. in terms of the population objective. A simple change of variables in
Problem (1), with U=C1/2 x U˜ and V=C1/2 y V˜ , yields the following equivalent problem:
maximize Tr ⇣
U>C 1
2 x Cxy C 1
2 y V
⌘
s.t. U>U=I, V>V=I. (2)
To ensure that Problem 2 is well-posed, we assume that r := min{rx, ry} > 0, where rx = min(Cx)
and ry = min(Cy) are smallest eigenvalues of the population auto-covariance matrices. Furthermore,
we assume that with probability one, for (x, y) ⇠ D, we have that max{kxk
2 , kyk
2
}  B. Let
 2 Rdx⇥k and 2 Rdy⇥k denote the top-k left and right singular vectors, respectively, of the
population cross-covariance matrix of the whitened views T := C1/2 x CxyC1/2 y . It is easy to check
that the optimum of Problem (1) is achieved at U⇤ = C1/2 x , V⇤ = C1/2 y . Therefore, a natural
2
approach, given a training dataset, is to estimate empirical auto-covariance and cross-covariance
matrices to compute Tb, an empirical estimate of T; matrices U⇤ and V⇤ can then be estimated
using the top-k left and right singular vectors of Tb. This approach is referred to as sample average
approximation (SAA) or empirical risk minimization (ERM).
In this paper, we consider the following equivalent re-parameterization of Problem (2) given by the
variable substitution M = UV>, also referred to as lifting. Find M 2 Rdx⇥dy that
maximize hM, C 1
2 x CxyC 1
2 y i s.t. i(M) 2 {0, 1}, i = 1,..., min{dx, dy}, rank (M)  k. (3)
We are interested in designing SA algorithms that, for any bounded distribution D with minimum
eigenvalue of the auto-covariance matrices bounded below by r, are guaranteed to find an ✏-suboptimal
solution on the population objective (3), from which, we can extract a good solution for Problem (1).
1.3 Related Work
There has been a flurry of recent work on scalable approaches to the empirical CCA problem,
i.e. methods for numerical optimization of the empirical CCA objective on a fixed data set [1, 8, 14,
15, 24]. These are typically batch approaches which use the entire data set at each iteration, either for
performing a power iteration [1, 8] or for optimizing the alternative empirical objective [14, 15, 24]:
minimize 1
2nkU˜ >X  V˜ >Yk2
F + xkU˜ k2
F + ykV˜ k2
F s.t. U˜ >Cx,nU=I ˜ , V˜ >Cy,nV=I ˜ , (4)
where Cx,n and Cy,n are the empirical estimates of covariance matrices for the n samples stacked
in the matrices X 2 Rdx⇥n and Y 2 Rdy⇥n, using alternating least squares [14], projected gradient
descent (AppaGrad, [15]) or alternating SVRG combined with shift-and-invert pre-conditioning [24].
However, all the works above focus only on the empirical problem, and can all be seen as instances of
SAA (ERM) approach to the stochastic optimization (learning) problem (1). In particular, the analyses
in these works bounds suboptimality on the training objective, not the population objective (1).
The only relevant work we are aware of that studies algorithms for CCA as a population problem is a
parallel work by [7]. However, there are several key differences. First, the objective considered in [7]
is different from ours. The focus in [7] is on finding a solution U, V that is very similar (has high
alignment with) the optimal population solution U⇤, V⇤. In order for this to be possible, [7] must rely
on an "eigengap" between the singular values of the cross-correlation matrix Cxy. In contrast, since
we are only concerned with finding a solution that is good in terms of the population objective (2),
we need not, and do not, depend on such an eigengap. If there is no eigengap in the cross-correlation
matrix, the population optimal solution is not well-defined, but that is fine for us – we are happy to
return any optimal (or nearly optimal) solution.
Furthermore, given such an eigengap, the emphasis in [7] is on the guaranteed overall runtime of their
method. Their core algorithm is very efficient in terms of runtime, but is not a streaming algorithm
and cannot be viewed as an SA algorithm. They do also provide a streaming version, which is runtime
and memory efficient, but is still not a “natural” SA algorithm, in that it does not work by making
a small update to the solution at each iteration. In contrast, here we present a more “natural” SA
algorithm and put more emphasis on its iteration complexity, i.e. the number of samples processed.
We do provide polynomial runtime guarantees, but rely on a heuristic capping in order to achieve
good runtime performance in practice.
Finally, [7] only consider obtaining the top correlated direction (k = 1) and it is not clear how to
extend their approach to Problem (1) of finding the top k  1 correlated directions. Our methods
handle the general problem, with k  1, naturally and all our guarantees are valid for any number of
desired directions k.
1.4 Contributions
The goal in this paper is to directly optimize the CCA “population objective” based on i.i.d. draws
from the population rather than capturing the sample, i.e. the training objective. This view justifies
and favors stochastic approximation approaches that are far from optimal on the sample but are
essentially as good as the sample average approximation approach on the population. Such a view
3
has been advocated in supervised machine learning [6, 18]; here, we carry over the same view to the
rich world of unsupervised learning. The main contributions of the paper are as follows.
• We give a convex relaxation of the CCA optimization problem. We present two stochastic
approximation algorithms for solving the resulting problem. These algorithms work in a
streaming setting, i.e. they process one sample at a time, requiring only a single pass through
the data, and can easily scale to large datasets.
• The proposed algorithms are instances of inexact stochastic mirror descent with the choice
of potential function being Frobenius norm and von Neumann entropy, respectively. Prior
work on inexact proximal gradient descent suggests a lower bound on the size of the noise
required to guarantee convergence for inexact updates [16]. While that condition is violated
here for the CCA problem, we give a tighter analysis of our algorithms with noisy gradients
establishing sub-linear convergence rates.
• We give precise iteration complexity bounds for our algorithms, i.e. we give upper bounds
on iterations needed to guarantee a user-specified ✏-suboptimality (w.r.t. population) for
CCA. These bounds do not depend on the eigengap in the cross-correlation matrix. To the
best of our knowledge this is a first such characterization of CCA in terms of generalization.
• We show empirically that the proposed algorithms outperform existing state-of-the-art
methods for CCA on a real dataset. We make our implementation of the proposed algorithms
and existing competing techniques available online1.
2 Matrix Stochastic Gradient for CCA (MSG-CCA)
Problem (3) is a non-convex optimization problem, however, it admits a simple convex relaxation.
Taking the convex hull of the constraint set in Problem 3 gives the following convex relaxation:
maximize hM, C 1
2 x CxyC 1
2 y i s.t. kMk2  1, kMk⇤  k. (5)
While our updates are designed for Problem (5), our algorithm returns a rank-k solution, through a
simple rounding procedure ([27, Algorithm 4]; see more details below), which has the same objective
in expectation. This allows us to guarantee ✏-suboptimality of the output of the algorithm on the
original non-convex Problem (3), and equivalently Problem (2).
Similar relaxations have been considered previously to design stochastic approximation (SA) algorithms for principal component analysis (PCA) [2] and partial least squares (PLS) [4]. These
SA algorithms are instances of stochastic gradient descent – a popular choice for convex learning
problems. However, designing similar updates for the CCA problem is challenging since the gradient
of the CCA objective (see Problem (5)) w.r.t. M is g := C1/2 x CxyC1/2 y , and it is not at all clear
how one can design an unbiased estimator, gt, of the gradient g unless one knows the marginal
distributions of x and y. Therefore, we consider an instance of inexact proximal gradient method [16]
which requires access to a first-order oracle with noisy estimates, @t, of gt. We show that an oracle
with bound on E[
PT
t=1 kgt  @tk] of O(
p
T) ensures convergence of the proximal gradient method.
Furthermore, we propose a first order oracle with the above property which instantiates the inexact
gradient as
@t := Wx,txty>
t Wy,t ⇡ gt, (6)
where Wx,t,Wy,t are empirical estimates of whitening transformation based on training data seen
until time t. This leads to the following stochastic inexact gradient update:
Mt+1 = PF (Mt + ⌘t@t), (7)
where PF is the projection operator onto the constraint set of Problem (5).
Algorithm 1 provides the pseudocode for the proposed method which we term inexact matrix
stochastic gradient method for CCA (MSG-CCA). At each iteration, we receive a new sample
(xt, yt), update the empirical estimates of the whitening transformations which define the inexact
gradient @t. This is followed by a gradient update with step-size ⌘, and projection onto the set of
constraints of Problem (5) with respect to the Frobenius norm through the operator PF (·) [2]. After
T iterations, the algorithm returns a rank-k matrix after a simple rounding procedure [27].
1
https://www.dropbox.com/sh/dkz4zgkevfyzif3/AABK9JlUvIUYtHvLPCBXLlpha?dl=0
4
Algorithm 1 Matrix Stochastic Gradient for CCA (MSG-CCA)
Input: Training data {(xt, yt)}T
t=1, step size ⌘, auxiliary training data {(x0
i, y0
i)}⌧
i=1
Output: M˜
1: Initialize: M1 0, Cx,0 1
⌧
P⌧
i=1 x0
ix0
i
>, Cy,0 1
⌧
P⌧
i=1 y0
iy0
i
>
2: for t = 1, ··· , T do
3: Cx,t t+⌧1
t+⌧ Cx,t1 + 1
t+⌧ xtx>
t , Wx,t C 1
2
x,t
4: Cy,t t+⌧1
t+⌧ Cy,t1 + 1
t+⌧ yty>
t , Wy,t C 1
2
y,t
5: @t Wx,txty>
t Wy,t
6: Mt+1 PF (Mt + ⌘@t) % Projection given in [2]
7: end for
8: M = ¯ 1
T
PT
t=1 Mt
9: M = ˜ rounding(M) ¯ % Algorithm 2 in [27]
We denote the empirical estimates of auto-covariance matrices based on the first t samples by Cx,t
and Cy,t. Our analysis of MSG-CCA follows a two-step procedure. First, we show that the empirical
estimates of the whitening transform matrices, i.e. Wx,t := C1/2
x,t , Wy,t := C1/2
y,t , guarantee that the
expected error in the “inexact” estimate, @t, converges to zero as O(1/
pt). Next, we show that the
resulting noisy stochastic gradient method converges to the optimum as O(1/
p
T). In what follows,
we will denote the true whitening transforms by Wx := C1/2 x and Wy := C1/2 y .
Since Algorithm 1 requires inverting empirical auto-covariance matrices, we need to ensure that the
smallest eigenvalues of Cx,t and Cy,t are bounded away from zero. Our first technical result shows
that in this happens with high probability for all iterates.
Lemma 2.1. With probability 1   with respect to training data drawn i.i.d. from D, it holds
uniformly for all t that min(Cx,t)  rx
2 and min(Cy,t)  ry
2 whenever:
⌧  max{ 1
cx
log
0
@
2dx
log ⇣ 1
1
⌘
1
A  1,
1
c x
log (2dx), 1
cy
log
0
@
2dy
log ⇣ 1
1
⌘
1
A  1,
1
c y
log (2dy)}.
Here cx = 3r2
x
6B2+Brx , cy = 3r2
y
6B2+Bry .
We denote by At the event that for all j = 1, .., t  1 the empirical cross-covariance matrices
Cx,j and Cy,j have their smallest eigenvalues bounded from below by rx and ry, respectively.
Lemma 2.1 above, guarantees that this event occurs with probability at least 1  , as long as there
are ⌧ = ⌦
✓
B2
r2 log ✓
2d
log( 1
1 )
◆◆ samples in the auxiliary dataset.
Lemma 2.2. Assume that the event At occurs, and that with probability one, for (x, y) ⇠ D, we
have max{kxk
2 , kyk
2
}  B. Then, for  := 8B2p2 log(d)
r2 , the following holds for all t:
ED [kgt  @tk2 | At] 

pt
.
The result above bounds the size of the expected noise in the estimate of the inexact gradient. Not
surprisingly, the error decays as our estimates of the whitening transformation improve with more
data. Moreover, the rate at which the error decreases is sufficient to bound the suboptimality of the
MSG-CCA algorithm even with noisy biased stochastic gradients.
Theorem 2.3. After T iterations of MSG-CCA (Algorithm 1) with step size ⌘ = 2
pk
GpT , auxiliary
sample of size ⌧ = ⌦( B2
r2 log( 2d
log( p
p T
T1 )
)), and initializing M1 = 0, the following holds:
hM⇤, C 1
2 x CxyC 1
2 y i  E[hM˜ , C 1
2 x CxyC 1
2 y i] 
2
p
kG + 2k + kB/r
p
T , (8)
5
where the expectation is with respect to the i.i.d. samples and rounding,  is as defined in Lemma 2.2,
M⇤ is the optimum of (3), M˜ is the rank-k output of MSG-CCA, and G = 2B
prxry .
While Theorem 2.3 gives a bound on the objective of Problem (3), it implies a bound on the original
CCA objective of Problem (1). In particular, given a rank-k factorization of M := UV ˜ >, such that
U>U=Ik and V>V=Ik, we construct
U=C ˜  1
2
x,T U, V := C ˜  1
2
y,T V. (9)
We then have the following generalization bound.
Theorem 2.4. After T iterations of MSG-CCA (Algorithm 1) with step size ⌘ = 2
pk
GpT , auxiliary
sample of size ⌧ = ⌦( B2
r2 log( 2d
log( T
T1 ) )), and initializing M1 = 0, the following holds
Tr(U>
⇤ CxyV⇤)E[Tr(U˜ >CxyV)] ˜ 
2
p
kG + 2k
p
T
+
kB
rT +
2kB
r2
 r2B2
T log (d) + 2B
3T log (d)
!
,
E[kU˜ >CxU˜  Ik2] 
B
r2
x
 r2B2
T log (dx) + 2B
3T log (dx)
!
+
B + 1
T ,
E[kV˜ >CyV˜  Ik2] 
B
r2
y
 r2B2
T log (dy) + 2B
3T log (dy)
!
+
B + 1
T ,
where the expectation is with respect to the i.i.d. samples and rounding, the pair (U⇤, V⇤) is
the optimum of (1), (U, ˜ V˜ ) are the factors (defined in (9)) of the rank-k output of MSG-CCA,
r := min{rx, ry}, d := max{dx, dy},  is as given in Lemma 2.2, and G = 2B
prxry .
All proofs are deferred to the Appendix in the supplementary material. Few remarks are in order.
Convexity: In our design and analysis of MSG-CCA, we have leveraged the following observations:
(i) since the objective is linear, an optimum of (5) is always attained at an extreme point, corresponding
to an optimum of (3); (ii) the exact convex relaxation (5) is tractable (this is not often the case for
non-convex problems); and (iii) although (5) might also have optima not on extreme points, we have
an efficient randomized method, called rounding, to extract from any feasible point of (5) a solution
of (3) that has the same value in expectation [27].
Eigengap free bound: Theorem 2.3 and 2.4 do not require an eigengap in the cross-correlation
matrix Cxy, and in particular the error bound, and thus the implied iteration complexity to achieve a
desired suboptimality does not depend on an eigengap.
Comparison with [7]: It is not straightforward to compare with the results of [7]. As discussed in
Section 1.3, authors in [7] consider only the case k = 1 and their objective is different than ours. They
seek (u, v) that have high alignment with the optimal (u⇤, v⇤) as measured through the alignment
(¯u, ¯v) := 1
2

¯u>Cxu⇤ + ¯v>Cyv⇤

. Furthermore, the analysis in [7] is dependent on the eigengap
 = 1  2 between the top two singular values 1, 2 of the population cross-correlation matrix T.
Nevertheless, one can relate their objective (u, v) to ours and ask what their guarantees ensure in
terms of our objective, namely achieving ✏-suboptimality for Problem (3). For the case k = 1, and
in the presence of an eigengap , the method of [7] can be used to find an ✏-suboptimal solution to
Problem (3) with O(log2(d)
✏2 ) samples.
Capped MSG-CCA: Although MSG-CCA comes with good theoretical guarantees, the computational cost per iteration can be O(d3). Therefore, we consider a practical variant of MSG-CCA
that explicitly controls the rank of the iterates. To ensure computational efficiency, we recommend
imposing a hard constraint on the rank of the iterates of MSG-CCA, following an approach similar to
previous works on PCA [2] and PLS [4]:
maximize hM, C 1
2 x CxyC 1
2 y i s.t. kMk2  1, kMk⇤  k,rank (M)  K. (10)
For estimates of the whitening transformations, at each iteration, we set the smallest dK eigenvalues
of the covariance matrices to a constant (of the order of the estimated smallest eigenvalue of the
6
covariance matrix). This allows us to efficiently compute the whitening transformations since the
covariance matrices decompose into a sum of a low-rank matrix and a scaled identity matrix, bringing
down the computational cost per iteration to O(dK2). We observe empirically on a real dataset
(see Section 4) that this procedure along with capping the rank of MSG iterates does not hurt the
convergence of MSG-CCA.
3 Matrix Exponentiated Gradient for CCA (MEG-CCA)
In this section, we consider matrix multiplicative weight updates for CCA. Multiplicative weights
method is a generic algorithmic technique in which one updates a distribution over a set of interest
by iteratively multiplying probability mass of elements [12]. In our setting, the set is that of d kdimensional (paired) subspaces and the multiplicative algorithm is an instance of matrix exponentiated
gradient (MEG) update. A motivation for considering MEG is the fact that for related problems,
including principal component analysis (PCA) and partial least squares (PLS), MEG has been shown
to yield fast optimistic rates [4, 22, 26]. Unfortunately we are not able to recover such optimistic
rates for CCA as the error in the inexact gradient decreases too slowly.
Our development of MEG requires the symmetrization of Problem (3). Recall that g :=
C1/2 x CxyC1/2 y . Consider the following symmetric matrix C :=  0 g
g 0
of size d ⇥ d, where
d = dx + dy. The matrix C is referred to as the self-adjoint dilation of the matrix g [20]. Given the
SVD of g = U⌃V> with no repeated singular values, the eigen-decomposition of C is given as
C = 1
2
✓
U U
V V
◆ ✓⌃ 0
0 ⌃
◆ ✓U U
V V
◆>
.
In other words, the top-k left and right singular vectors of C1/2 x CxyC1/2 y , which comprise the CCA
solution we seek, are encoded in top and bottom rows, respectively, of the top-k eigenvectors of its
dilation. This suggests the following scaled re-parameterization of Problem (3): find M 2 Rd⇥d that
maximize hM, Ci s.t. i(M) 2 {0, 1}, i = 1, . . . , d, rank (M) = k. (11)
As in Section 2, we take the convex hull of the constraint set to get a convex relaxation to Problem (11).
maximize hM, Ci s.t. M ⌫ 0, kMk2  1, Tr(M) = k. (12)
Stochastic mirror descent on Problem (12) with the choice of potential function being the quantum
relative entropy gives the following updates [4, 27]:
Mb t = exp (log (Mt1) + ⌘Ct)
Tr(exp (log (Mt1) + ⌘Ct)), Mt = P
⇣
Mb t
⌘
, (13)
where Ct is the self-adjoint dilation of unbiased instantaneous gradient gt, andP denotes the Bregman
projection [10] onto the convex set of constraints in Problem (12). As discussed in Section 2 we
only need an inexact gradient estimate C˜t of Ct with a bound on E[
PT
t=1 kCt  C˜tk|AT ] of O(
p
T).
Setting C˜t to be the self-adjoint dilation of @t, defined in Section 2, guarantees such a bound.
Lemma 3.1. Assume that the event At occurs,gt  @t has no repeated singular values and that with
probability one, for (x, y) ⇠ D, we have max{kxk
2 , kyk
2
}  B. Then, for  defined in lemma 2.2,
we have that, Ext,yt hMt1  M⇤, Ct  C˜t|Ati  2
p
k
t , where M⇤ is the optimum of Problem (11).
Using the bound above, we can bound the suboptimality gap in the population objective between the
true rank-k CCA solution and the rank-k solution returned by MEG-CCA.
Theorem 3.2. After T iterations of MEG-CCA (see Algorithm 2 in Appendix) with step size ⌘ =
1
G log ✓
1 + qlog(d)
GT ◆
, auxiliary sample of size ⌧ = ⌦( B2
r2 log( 2d
log( p
p T
T1 )
)) and initializing M0 = 1
d I,
the following holds:
hM⇤, Ci  E[hM˜ , Ci]  2k
rG2 log (d)
T + 2
k
p
T ,
7
where the conditional expectation is taken with respect to the distribution and the internal randomization of the algorithm, M⇤ is the optimum of Problem (11), M˜ is the rank-k output of MEG-CCA after
rounding, G = 2B
prxry and  is defined in Lemma 2.2.
All of our remarks regarding latent convexity of the problem and practical variants from Section 2
apply to MEG-CCA as well. We note, however, that without additional assumptions like eigengap for
T we are not able to recover projections to the canonical subspaces as done in Theorem 2.4.
4 Experiments
We provide experimental results for our proposed methods, in particular we compare capped-MSG
which is the practical variant of Algorithm 1 with capping as defined in equation (10), and MEG
(Algorithm 2 in the Appendix), on a real dataset, Mediamill [19], consisting of paired observations
of videos and corresponding commentary. We compare our algorithms against CCALin of [8], ALS
CCA of [24]
2, and SAA, which is denoted by “batch” in Figure 1. All of the comparisons are given
in terms of the CCA objective as a function of either CPU runtime or number of iterations. The
target dimensionality in our experiments is k 2 {1, 2, 4}. The choice of k is dictated largely by the
fact that the spectrum of the Mediamill dataset decays exponentially. To ensure that the problem
is well-conditioned, we add I for  = 0.1 to the empirical estimates of the covariance matrices on
Mediamill dataset. For both MSG and MEG we set the step size at iteration t to be ⌘t = 0
p.1
t .
Mediamill is a multiview dataset consisting of n = 10, 000 corresponding videos and text annotations with labels representing semantic concepts [19]. The image view consists of 120-dimensional
visual features extracted from representative frames selected from videos, and the textual features are
100-dimensional. We give the competing algorithms, both CCALin and ALS CCA, the advantage of
the knowledge of the eigengap at k. In particular, we estimate the spectrum of the matrix Tb for the
Mediamill dataset and set the gap-dependent parameters in CCALin and ALS CCA accordingly.
We note, however, that estimating the eigengap to set the parameters is impractical in real scenarios.
Both CCALin and ALS CCA will therefore require additional tuning compared to MSG and MEG
algorithms proposed here. In the experiments, we observe that CCALin and ALS CCA outperform
MEG and capped-MSG when recovering the top CCA component, in terms of progress per-iteration.
However, capped-MSG is the best in terms of the overall runtime. The plots are shown in Figure 1.
5 Discussion
We study CCA as a stochastic optimization problem and show that it is efficiently learnable by
providing analysis for two stochastic approximation algorithms. In particular, the proposed algorithms
achieve ✏-suboptimality in population objective in iterations O( 1
✏2 ).
Note that both of our Algorithms, MSG-CCA in Algorithm 1 and MEG-CCA in Algorithm 2
in Appendix B are instances of inexact proximal-gradient method which was studied in [16]. In
particular, both algorithms receive a noisy gradient @t = gt + Et at iteration t and perform exact
proximal steps (Bregman projections in equations (7) and (13)). The main result in [16] provides an
O(E2/T) convergence rate, where E = PT
t=1 kEtk is the partial sum of the errors in the gradients.
It is shown that E = o(
p
T) is a necessary condition to obtain convergence. However, for the CCA
problem that we are considering in this paper, our lemma A.6 shows that E = O(
p
T). In fact, it is
easy to see that E = ⇥(
p
T). Our analysis yields O( p
1
T ) convergence rates for both Algorithms 1
and 2. This perhaps warrants further investigation into the more general problem of inexact proximal
gradient method.
In empirical comparisons, we found the capped version of the proposed MSG algorithm to outperform
other methods including MEG in terms of overall runtime needed to reach an ✏-suboptimal solution.
Future work will focus on gaining a better theoretical understanding of capped MSG.
2
We run ALS only for k = 1 as the algorithm and the current implementation from the authors does not
handle k  1.
8
(a) k = 1 (b) k = 2 (c) k = 4
102 103
Iteration
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Objective
CAPPED-MSG
MEG
CCALin
batch
ALSCCA
Max Objective
102 103
Iteration
0
0.1
0.2
0.3
0.4
0.5
Objective
102 103
Iteration
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Objective
100 102
Runtime (in seconds)
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Objective
100 102
Runtime (in seconds)
0
0.1
0.2
0.3
0.4
0.5
Objective
100 101 102
Runtime (in seconds)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Objective
Figure 1: Comparisons of CCA-Lin, CCA-ALS, MSG, and MEG for CCA optimization on the MediaMill
dataset, in terms of the objective value as a function of iteration (top) and as a function of CPU runtime (bottom).