In this paper, we propose an accelerated first-order method for geodesically convex
optimization, which is the generalization of the standard Nesterov’s accelerated
method from Euclidean space to nonlinear Riemannian space. We first derive two
equations and obtain two nonlinear operators for geodesically convex optimization
instead of the linear extrapolation step in Euclidean space. In particular, we analyze
the global convergence properties of our accelerated method for geodesically
strongly-convex problems, which show that our method improves the convergence
rate from O((1−µ/L)
k
) to O((1−
p
µ/L)
k
). Moreover, our method also improves
the global convergence rate on geodesically general convex problems from O(1/k)
to O(1/k2
). Finally, we give a specific iterative scheme for matrix Karcher mean
problems, and validate our theoretical results with experiments.
1 Introduction
In this paper, we study the following Riemannian optimization problem:
min f(x) such that x ∈ X ⊂ M, (1)
where (M, %) denotes a Riemannian manifold with the Riemannian metric %, X ⊂M is a nonempty,
compact, geodesically convex set, and f :X → R is geodesically convex (G-convex) and geodesically
L-smooth (G-L-smooth). Here, G-convex functions may be non-convex in the usual Euclidean space
but convex along the manifold, and thus can be solved by a global optimization solver. [5] presented
G-convexity and G-convex optimization on geodesic metric spaces, though without any attention
to global complexity analysis. As discussed in [11], the topic of "geometric programming" may be
viewed as a special case of G-convex optimization. [25] developed theoretical tools to recognize
and generate G-convex functions as well as cone theoretic fixed point optimization algorithms.
However, none of these three works provided a global convergence rate analysis for their algorithms.
Very recently, [31] provided the global complexity analysis of first-order algorithms for G-convex
optimization, and designed the following Riemannian gradient descent rule:
xk+1 = Expxk
(−η gradf(xk)),
where k is the iterate index, Expxk
is an exponential map at xk (see Section 2 for details), η is a
step-size or learning rate, and gradf(xk) is the Riemannian gradient of f at xk ∈X .
∗Corresponding author.
31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.
In this paper, we extend the Nesterov’s accelerated gradient descent method [19] from Euclidean
space to nonlinear Riemannian space. Below, we first introduce the Nesterov’s method and its variants
for convex optimization on Euclidean space, which can be viewed as a special case of our method,
when M=R
d
, and % is the Euclidean inner product. Nowadays many real-world applications involve
large data sets. As data sets and problems are getting larger in size, accelerating first-order methods
is of both practical and theoretical interests. The earliest first-order method for minimizing a convex
function f is perhaps the gradient method. Thirty years ago, Nesterov [19] proposed an accelerated
gradient method, which takes the following form: starting with x0 and y0 =x0, and for any k≥1,
xk = yk−1 − η∇f(yk−1),
yk = xk + τk(xk − xk−1),
(2)
where 0 ≤ τk ≤ 1 is the momentum parameter. For a fixed step-size η = 1/L, where L is the
Lipschitz constant of ∇f, this scheme with τk = (k−1)/(k+2) exhibits the optimal convergence
rate, f(xk)−f(x?) ≤ O(
Lkx?−x0k
2
k2 ), for general convex (or non-strongly convex) problems [20],
where x? is any minimizer of f. In contrast, standard gradient descent methods can only achieve
a convergence rate of O(1/k). We can see that this improvement relies on the introduction of the
momentum term τk(xk − xk−1) as well as the particularly tuned coefficient (k−1)/(k+2)≈1−3/k.
Inspired by the success of the Nesterov’s momentum, there has been much work on the development
of first-order accelerated methods, see [2, 8, 21, 26, 27] for example. In addition, for strongly convex
problems and setting τk ≡(1−
p
µ/L)/(1+p
µ/L), Nesterov’s accelerated gradient method attains
a convergence rate of O((1−
p
µ/L)
k
), while standard gradient descent methods achieve a linear
convergence rate of O((1−µ/L)
k
). It is then natural to ask whether our accelerated method in
nonlinear Riemannian space has the same convergence rates as its Euclidean space counterparts (e.g.,
Nesterov’s accelerated method [20])?
1.1 Motivation and Challenges
Zhang and Sra [31] proposed an efficient Riemannian gradient descent (RGD) method, which
attains the convergence rates of O((1 − µ/L)
k
) and O(1/k) for geodesically strongly-convex and
geodesically convex problems, respectively. Hence, there still remain gaps in convergence rates
between RGD and the Nesterov’s accelerated method.
As discussed in [31], a long-time question is whether the famous Nesterov’s accelerated gradient
descent algorithm has a counterpart in nonlinear Riemannian spaces. Compared with standard
gradient descent methods in Euclidean space, Nesterov’s accelerated gradient method involves a
linear extrapolation step: yk = xk +τk(xk −xk−1), which can improve its convergence rates for both
strongly convex and non-strongly convex problems. It is clear that ϕk(x) := f(yk)+h∇f(yk), x−yki
is a linear function in Euclidean space, while its counterpart in nonlinear space, e.g., ϕk(x) :=
f(yk) + hgradf(yk), Exp−1
yk
(x)iyk
, is a nonlinear function, where Exp−1
yk
is the inverse of the
exponential map Expyk
, and h·, ·iy is the inner product (see Section 2 for details). Therefore, in
nonlinear Riemannian spaces, there is no trivial analogy of such a linear extrapolation step. In
other words, although Riemannian geometry provides tools that enable generalization of Euclidean
algorithms mentioned above [1], we must overcome some fundamental geometric hurdles to analyze
the global convergence properties of our accelerated method as in [31].
1.2 Contributions
To answer the above-mentioned open problem in [31], in this paper we propose a general accelerated
first-order method for nonlinear Riemannian spaces, which is in essence the generalization of the
standard Nesterov’s accelerated method. We summarize the key contributions of this paper as follows.
• We first present a general Nesterov’s accelerated iterative scheme in nonlinear Riemannian
spaces, where the linear extrapolation step in (2) is replaced by a nonlinear operator. Furthermore, we derive two equations and obtain two corresponding nonlinear operators for
both geodesically strongly-convex and geodesically convex cases, respectively.
• We provide the global convergence analysis of our accelerated algorithms, which shows
that our algorithms attain the convergence rates of O((1−
p
µ/L)
k
) and O(1/k2
) for
geodesically strongly-convex and geodesically convex objectives, respectively.
2
• Finally, we present a specific iterative scheme for matrix Karcher mean problems. Our
experimental results verify the effectiveness and efficiency of our accelerated method.
2 Notation and Preliminaries
We first introduce some key notations and definitions about Riemannian geometry (see [23, 30] for
details). A Riemannian manifold (M, %) is a real smooth manifold M equipped with a Riemannian
metric %. Let hw1, w2ix =%x(w1, w2) denote the inner product of w1, w2 ∈ TxM; and the norm of
w ∈TxM is defined as kwkx =
p
%x(w, w), where the metric % induces an inner product structure
in each tangent space TxM associated with every x ∈ M. A geodesic is a constant speed curve
γ : [0, 1]→M that is locally distance minimizing. Let y ∈M and w ∈TxM, then an exponential
map y = Expx
(w) :TxM→M maps w to y on M, such that there is a geodesic γ with γ(0) =x,
γ(1) = y and γ˙(0) = w. If there is a unique geodesic between any two points in X ⊂ M, the
exponential map has inverse Exp−1
x
:X →TxM, i.e., w = Exp−1
x
(y), and the geodesic is the unique
shortest path with kExp−1
x
(y)kx =kExp−1
y
(x)ky = d(x, y), where d(x, y) is the geodesic distance
between x, y ∈ X . Parallel transport Γ
y
x
: TxM→TyM maps a vector w ∈TxM to Γ
y
xw ∈TyM,
and preserves inner products and norm, that is, hw1, w2ix =hΓ
y
xw1, Γ
y
xw2iy and kw1kx =kΓ
y
xw1ky,
where w1, w2∈TxM.
For any x, y ∈ X and any geodesic γ with γ(0) = x, γ(1) = y and γ(t) ∈ X for t ∈ [0, 1] such
that f(γ(t)) ≤ (1 − t)f(x) + tf(y), then f is geodesically convex (G-convex), and an equivalent
definition is formulated as follows:
f(y) ≥ f(x) + hgradf(x), Exp−1
x
(y)ix,
where gradf(x) is the Riemannian gradient of f at x. A function f : X →R is called geodesically
µ-strongly convex (µ-strongly G-convex) if for any x, y∈X , the following inequality holds
f(y) ≥ f(x) + hgradf(x), Exp−1
x
(y)ix +
µ
2
kExp−1
x
(y)k
2
x
.
A differential function f is geodesically L-smooth (G-L-smooth) if its gradient is L-Lipschitz, i.e.,
f(y) ≤ f(x) + hgradf(x), Exp−1
x
(y)ix +
L
2
kExp−1
x
(y)k
2
x
.
3 An Accelerated Method for Geodesically Convex Optimization
In this section, we propose a general acceleration method for geodesically convex optimization,
which can be viewed as a generalization of the famous Nesterov’s accelerated method from Euclidean
space to Riemannian space. Nesterov’s accelerated method involves a linear extrapolation step as
in (2), while in nonlinear Riemannian spaces, we do not have a simple way to find an analogy to
such a linear extrapolation. Therefore, some standard analysis techniques do not work in nonlinear
space. Motivated by this, we derive two equations to bridge the gap for both geodesically stronglyconvex and geodesically convex cases, and then generalized Nesterov’s algorithms are proposed for
geodesically convex optimization by solving these two equations.
We first propose to replace the classical Nesterov’s scheme in (2) with the following update rules for
geodesically convex optimization in Riemannian space:
xk = Expyk−1
(−η gradf(yk−1)),
yk = S(yk−1, xk, xk−1),
(3)
where yk, xk ∈ X , S denotes a nonlinear operator, and yk = S(yk−1, xk, xk−1) can be obtained by
solving the two proposed equations (see (4) and (5) below, which can be used to deduce the key
analysis tools for our convergence analysis) for strongly G-convex and general G-convex cases, respectively. Different from the Riemannian gradient descent rule (e.g., xk+1 =Expxk
(−ηgradf(xk))),
the Nesterov’s accelerated technique is introduced into our update rule of yk. Compared with the
Nesterov’s scheme in (2), the main difference is the update rule of yk. That is, our update rule for yk
is an implicit iteration process as shown below, while that of (2) is an explicit iteration one.
3
Figure 1: Illustration of geometric interpretation for Equations (4) and (5).
Algorithm 1 Accelerated method for strongly G-convex optimization
Input: µ, L
Initialize: x0, y0, η.
1: for k = 1, 2, . . . , K do
2: Computing the gradient at yk−1: gk−1 = gradf(yk−1);
3: xk = Expyk−1
(−ηgk−1);
4: yk = S(yk−1, xk, xk−1) by solving (4).
5: end for
Output: xK
3.1 Geodesically Strongly Convex Cases
We first design the following equation with respect to yk ∈X for the µ-strongly G-convex case:

1 −
p
µ/L
Γ
yk−1
yk
Exp−1
yk
(xk) − βΓ
yk−1
yk
gradf(yk) = 
1 −
p
µ/L3/2
Exp−1
yk−1
(xk−1), (4)
where β = 4/
√
µL−1/L > 0. Figure 1(a) illustrates the geometric interpretation of the proposed
equation (4) for the strongly G-convex case, where uk = (1−
p
µ/L)Exp−1
yk
(xk), vk =−βgradf(yk),
and wk−1 = (1−
p
µ/L)
3/2Exp−1
yk−1
(xk−1). The vectors uk, vk ∈ TykM are parallel transported
to Tyk−1M, and the sum of their parallel translations is equal to wk−1 ∈ Tyk−1M, which means
that the equation (4) holds. We design an accelerated first-order algorithm for solving geodesically
strongly-convex problems, as shown in Algorithm 1. In real applications, the proposed equation
(4) can be manipulated into simpler forms. For example, we will give a specific equation for the
averaging real symmetric positive definite matrices problem below.
3.2 Geodesically Convex Cases
Let f be G-convex and G-L-smooth, the diameter of X be bounded by D (i.e., maxx,y∈X d(x, y) ≤
D), the variable yk ∈ X can be obtained by solving the following equation:
Γ
yk−1
yk

k
α−1
Exp−1
yk
(xk)−Dgbk

=
k−1
α−1
Exp−1
yk−1
(xk−1)−Dgbk−1 +
(k+α−2)η
α − 1
gk−1, (5)
where gk−1 = gradf(yk−1), and gbk = gk/kgkkyk
, and α ≥ 3 is a given constant. Figure 1(b)
illustrates the geometric interpretation of the proposed equation (5) for the G-convex case, where
uk =
k
α−1
Exp−1
yk
(xk)−Dgbk, and vk−1 =
(k+α−2)η
α−1
gk−1. We also present an accelerated first-order
algorithm for solving geodesically convex problems, as shown in Algorithm 2.
3.3 Key Lemmas
For the Nesterov’s accelerated scheme in (2) with τk =
k−1
k+2 (for example, the general convex case)
in Euclidean space, the following result in [3, 20] plays a key role in the convergence analysis of
Nesterov’s accelerated algorithm.
2
k+2
h∇f(yk), zk−x?i − η
2
k∇f(yk)k
2 =
2
η(k+2)2

kzk − x?k
2 − kzk+1− x?k
2

, (6)
4  
Algorithm 2 Accelerated method for general G-convex optimization
Input: L, D, α
Initialize: x0, y0, η.
1: for k = 1, 2, . . . , K do
2: Computing the gradient at yk−1: gk−1 = gradf(yk−1) and gˆk−1 = gk−1/kgk−1kyk−1
;
3: xk = Expyk−1
(−ηgk−1);
4: yk = S(yk−1, xk, xk−1) by solving (5).
5: end for
Output: xK
where zk = (k+2)yk/2 − (k/2)xk. Correspondingly, we can also obtain the following analysis tools
for our convergence analysis using the proposed equations (4) and (5). In other words, the following
equations (7) and (8) can be viewed as the Riemannian space counterparts of (6).
Lemma 1 (Strongly G-convex). If f : X → R is geodesically µ-strongly convex and G-L-smooth,
and {yk} satisfies the equation (4), and zk is defined as follows:
zk =

1 −
p
µ/L
Exp−1
yk
(xk) ∈ TykM.
Then the following results hold:
Γ
yk−1
yk
(zk − βgradf(yk)) = 
1 −
p
µ/L1/2
zk−1,
−hgradf(yk), zkiyk +
β
2
kgradf(yk)k
2
yk =
1
2β

1 −
p
µ/L
kzk−1k
2
yk−1 −
1
2β
kzkk
2
yk
. (7)
For general G-convex objectives, we have the following result.
Lemma 2 (General G-convex). If f : X → R is G-convex and G-L-smooth, the diameter of X is
bounded by D, and {yk} satisfies the equation (5), and zk is defined as
zk =
k
α − 1
Exp−1
yk
(xk) − Dgbk ∈ TykM.
Then the following results hold:
Γ
yk
yk+1
zk+1 = zk +
(k + α − 1)η
α − 1
gradf(yk),
α−1
k+α−1
hgradf(yk), −zkiyk −
η
2
kgradf(yk)k
2
yk =
2(α−1)2
η(k+α−1)2

kzkk
2
yk − kzk+1k
2
yk+1 
. (8)
The proofs of Lemmas 1 and 2 are provided in the Supplementary Materials.
4 Convergence Analysis
In this section, we analyze the global convergence properties of the proposed algorithms (i.e.,
Algorithms 1 and 2) for both geodesically strongly convex and general convex problems.
Lemma 3. If f : X → R is G-convex and G-L-smooth for any x ∈ X , and {xk} is the sequence
produced by Algorithms 1 and 2 with η ≤ 1/L, then the following result holds:
f(xk+1) ≤ f(x) + hgradf(yk), −Exp−1
yk
(x)iyk −
η
2
kgradf(yk)k
2
yk
.
The proof of this lemma can be found in the Supplementary Materials. For the geodesically strongly
convex case, we have the following result.
Theorem 1 (Strongly G-convex). Let x? be the optimal solution of Problem (1), and {xk} be the
sequence produced by Algorithm 1. If f : X → R is geodesically µ-strongly convex and G-L-smooth,
then the following result holds
f(xk+1) − f(x?) ≤

1 −
p
µ/Lk

f(x0) − f(x?) + 1
2β

1 −
p
µ/L
kz0k
2
y0

,
where z0 is defined in Lemma 1.
5
Table 1: Comparison of convergence rates for geodesically convex optimization algorithms.
Algorithms RGD [31] RSGD [31] Ours
Strongly G-convex and smooth O

(1 − min{
1
c
,
µ
L
})
k

O (1/k) O

(1 −
pµ
L
)
k

General G-convex and smooth O

c
c + k

O

1/
√
k

O

1/k2

The proof of Theorem 1 can be found in the Supplementary Materials. From this theorem, we can see
that the proposed algorithm attains a linear convergence rate of O((1−
p
µ/L)
k
) for geodesically
strongly convex problems, which is the same as that of its Euclidean space counterparts and significantly faster than that of non-accelerated algorithms such as [31] (i.e., O((1−µ/L)
k
)), as shown in
Table 1. For the geodesically non-strongly convex case, we have the following result.
Theorem 2 (General G-convex). Let {xk} be the sequence produced by Algorithm 2. If f :X → R
is G-convex and G-L-smooth, and the diameter of X is bounded by D, then
f(xk+1) − f(x?) ≤
(α − 1)2
2η(k + α − 2)2
kz0k
2
y0
,
where z0 = −Dgb0, as defined in Lemma 2.
The proof of Theorem 2 can be found in the Supplementary Materials. Theorem 2 shows that for
general G-convex objectives, our acceleration method improves the theoretical convergence rate from
O(1/k) (e.g., RGD [31]) to O(1/k2
), which matches the optimal rate for general convex settings in
Euclidean space. Please see the detail in Table 1, where the parameter c is defined in [31].
5 Application for Matrix Karcher Mean Problems
In this section, we give a specific accelerated scheme for a type of conic geometric optimization
problems [25], e.g., the matrix Karcher mean problem. Specifically, the loss function of the Karcher
mean problem for a set of N symmetric positive definite (SPD) matrices {Wi}
N
i=1 is defined as
f(X) := 1
2N
X
N
i=1
klog(X−1/2WiX−1/2
)k
2
F , (9)
where X ∈ P := {Z ∈ R
d×d
, s.t., Z = Z
T  0}. The loss function f is known to be non-convex
in Euclidean space but geodesically 2N-strongly convex. The inner product of two tangent vectors at
point X on the manifold is given by
hζ, ξiX = tr(ζX−1
ξX−1
), ζ, ξ ∈ TXP, (10)
where tr(·) is the trace of a real square matrix. For any matrices X, Y ∈ P, the Riemannian distance
is defined as follows:
d(X, Y ) = klog(X− 1
2 Y X− 1
2 )kF .
5.1 Computation of Yk
For the accelerated update rules in (3) for Algorithm 1, we need to compute Yk via solving the
equation (4). However, for the specific problem in (9) with the inner product in (10), we can derive a
simpler form to solve Yk below. We first give the following properties:
Property 1. For the loss function f in (9) with the inner product in (10), we have
1. Exp−1
Yk
(Xk) = Y
1/2
k
log(Y
−1/2
k XkY
−1/2
k
)Y
1/2
k
;
2. gradf(Yk) = 1
N
PN
i=1 Y
1/2
k
log(Y
1/2
k W−1
i Y
1/2
k
)Y
1/2
k
;
3. 

gradf(Yk), Exp−1
Yk
(Xk)

Yk
= hU, V i;
4. kgradf(Yk)k
2
Yk = kUk
2
F
,   
where U =
1
N
PN
i=1log(Y
1/2
k W−1
i Y
1/2
k
) ∈ R
d×d
, and V =log(Y
−1/2
k XkY
−1/2
k
) ∈ R
d×d
.
Proof. In this part, we only provide the proof of Result 1 in Property 1, and the proofs of the other
results are provided in the Supplementary Materials. The inner product in (10) on the Riemannian
manifold leads to the following exponential map:
ExpX(ξX) = X
1
2 exp(X− 1
2 ξXX− 1
2 )X
1
2 , (11)
where ξX ∈TXP denotes the tangent vector with the geometry, and tangent vectors ξX are expressed
as follows (see [17] for details):
ξX = X
1
2 sym(∆)X
1
2 , ∆ ∈ R
d×d
,
where sym(·) extracts the symmetric part of its argument, that is, sym(A)= (AT +A)/2. Then we
can set Exp−1
Yk
(Xk) = Y
1/2
k
sym(∆Xk
)Y
1/2
k ∈ TYk P. By the definition of Exp−1
Yk
(Xk), we have
ExpYk
(Exp−1
Yk
(Xk)) = Xk, that is,
ExpYk
(Y
1/2
k
sym(∆Xk
)Y
1/2
k
) = Xk. (12)
Using (11) and (12), we have
sym(∆Xk
) = log(Y
−1/2
k XkY
−1/2
k
) ∈ R
d×d
.
Therefore, we have
Exp−1
Yk
(Xk) = Y
1/2
k
sym(∆Xk
)Y
1/2
k = Y
1/2
k
log(Y
−1/2
k XkY
−1/2
k
)Y
1/2
k = −Yk log(X
−1
k
Yk),
where the last equality holds due to the fact that log(X−1Y X) = X−1
log(Y )X.
Result 3 in Property 1 shows that the inner product of two tangent vectors at Yk is equal to the
Euclidean inner-product of two vectors U, V ∈ R
d×d
. Thus, we can reformulate (4) as follows:

1−
r
µ
L

log(Y
− 1
2
k XkY
− 1
2
k
) −
β
N
X
N
i=1
log(Y
1
2
k W−1
i Y
1
2
k
)=
1−
r
µ
L
3
2
log(Y
− 1
2
k−1X
−1
k−1
Y
− 1
2
k−1
),
(13)
where β = 4/
√
µL−1/L. Then Yk can be obtained by solving (13). From a numerical perspective,
log(Y
1
2
k W−1
i Y
1
2
k
) can be approximated by log(Y
1
2
k−1W−1
i Y
1
2
k−1
), and then Yk is given by
Yk = X
1
2
k
exp−1
"
1 −
r
µ
L
1
2
log(Y
− 1
2
k−1Xk−1Y
− 1
2
k−1
) + δβ
N
X
N
i=1
log(Y
1
2
k−1W−1
i Y
1
2
k−1
)
#
X
1
2
k
,
(14)
where δ = 1/(1−
p
µ/L), and Yk ∈ P.
6 Experiments
In this section, we validate the performance of our accelerated method for averaging SPD matrices
under the Riemannian metric, e.g., the matrix Karcher mean problem (9), and also compare our
method against the state-of-the-art methods: Riemannian gradient descent (RGD) [31] and limitedmemory Riemannian BFGS (LRBFGS) [29]. The matrix Karcher mean problem has been widely
applied to many real-world applications such as elasticity [18], radar signal and image processing [6,
15, 22], and medical imaging [9, 7, 13]. In fact, this problem is geodesically strongly convex, but
non-convex in Euclidean space.
Other methods for solving this problem include the relaxed Richardson iteration algorithm [10],
the approximated joint diagonalization algorithm [12], and Riemannian stochastic gradient descent
(RSGD) [31]. Since all the three methods achieve similar performance to RGD, especially in data
science applications where N is large and relatively small optimization error is not required [31], we
only report the experimental results of RGD. The step-size η of both RGD and LRBFGS is selected
with a line search method as in [29] (see [29] for details), while η of our accelerated method is set to
1/L. For the algorithms, we initialize X using the arithmetic mean of the data set as in [29].
7
0 20 40 60
10−10
10−5
100
Number of iterations
dist(
X∗,Xk)
RGD
LRBFGS
Ours
0 5 10 15 20
10−10
10−5
100
Running time (s)
dist(
X∗,Xk)
RGD
LRBFGS
Ours
0 20 40 60
10−10
10−5
100
Number of iterations
dist(
X∗,Xk)
RGD
LRBFGS
Ours
0 20 40 60 80 100
10−10
10−5
100
Running time (s)
dist(
X∗,Xk)
RGD
LRBFGS
Ours
Figure 2: Comparison of RGD, LRBFGS and our accelerated method for solving geodesically
strongly convex Karcher mean problems on data sets with d = 100 (the first row) and d = 200 (the
second row). The vertical axis represents the distance in log scale, and the horizontal axis denotes the
number of iterations (left) or running time (right).
The input synthetic data are random SPD matrices of size 100×100 or 200×200 generated by using
the technique in [29] or the matrix mean toolbox [10], and all matrices are explicitly normalized so
that their norms are all equal to 1. We report the experimental results of RGD, LRBFGS and our
accelerated method on the two data sets in Figure 2, where N is set to 100, and the condition number
C of each matrix {Wi}
N
i=1 is set to 102
. Figure 2 shows the evolution of the distance between the
exact Karcher mean and current iterate (i.e., dist(X∗, Xk)) of the methods with respect to number
of iterations and running time (seconds), where X∗ is the exact Karcher mean. We can observe that
our method consistently converges much faster than RGD, which empirically verifies our theoretical
result in Theorem 1 that our accelerated method has a much faster convergence rate than RGD.
Although LRBFGS outperforms our method in terms of number of iterations, our accelerated method
converges much faster than LRBFGS in terms of running time.
7 Conclusions
In this paper, we proposed a general Nesterov’s accelerated gradient method for nonlinear Riemannian
space, which is a generalization of the famous Nesterov’s accelerated method for Euclidean space.
We derived two equations and presented two accelerated algorithms for geodesically strongly-convex
and general convex optimization problems, respectively. In particular, our theoretical results show
that our accelerated method attains the same convergence rates as the standard Nesterov’s accelerated
method in Euclidean space for both strongly G-convex and G-convex cases. Finally, we presented a
special iteration scheme for solving matrix Karcher mean problems, which in essence is non-convex
in Euclidean space, and the numerical results verify the efficiency of our accelerated method.
We can extend our accelerated method to the stochastic setting using variance reduction techniques [14,
16, 24, 28], and apply our method to solve more geodesically convex problems in the future, e.g.,
the general G-convex problem with a non-smooth regularization term as in [4]. In addition, we
can replace exponential mapping by computationally cheap retractions together with corresponding
theoretical guarantees [31]. An interesting direction of future work is to design accelerated schemes
for non-convex optimization in Riemannian space.