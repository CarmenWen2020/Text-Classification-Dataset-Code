The existence of singularities often affects the learning dynamics in feedforward neural
networks. In this paper, based on theoretical analysis results, we numerically analyze the
learning dynamics of radial basis function (RBF) networks near singularities to understand
to what extent singularities influence the learning dynamics. First, we show the explicit
expression of the Fisher information matrix for RBF networks. Second, we demonstrate
through numerical simulations that the singularities have a significant impact on the learning dynamics of RBF networks. Our results show that overlap singularities mainly have
influence on the low dimensional RBF networks and elimination singularities have a more
significant impact to the learning processes than overlap singularities in both low and high
dimensional RBF networks, whereas the plateau phenomena are mainly caused by the
elimination singularities. The results can also be the foundation to investigate the singular
learning dynamics in deep feedforward neural networks.
Keywords: RBF networks, Singularity, Learning dynamics, Numerical analysis, Deep
learning

1. Introduction
The results in (Watanabe, 2007) indicate that the parameter spaces of almost all types of
learning machines have singular regions where the Fisher information matrices degenerate,
including layered neural networks, normal mixtures, binomial mixtures, Bayes networks,
hidden Markov models, Boltzmann machines, stochastic context-free grammars, and reduced rank regressions. For the widely used feedforward neural networks, researchers have
found that the learning dynamics are affected by the existing singularities. Some strange
behaviors occur in the learning process, such as learning dynamics often become very slow
and the learning process is trapped in plateaus.
Researchers have realized that such plateau phenomena arise from the singular structure of the parameter space and the Fisher information matrix degenerates at singularities (Fukumizu, 1996; Fukumizu and Amari, 2000; Amari and Ozeki, 2001; Amari et al.,
2009). The geometrical structure of such statistical models has been studied by information
geometry (Amari and Nagaoka, 2000). The standard statistical paradigm of the CramerRao theorem does not hold at singularities and the model selection criteria, such as Akaike
information criterion (AIC), Bayes information criterion (BIC) and minimum description
length (MDL), may fail due to the existence of singularities (Amari et al., 2006). The effect of singularity in Bayesian inference was studied in (Watanabe, 2001a,b, 2010; Aoyagi,
2010), and a widely applicable Bayesian information criterion (WBIC) was proposed which
remains efficient for the singular model (Watanabe, 2013). Mononen (2015) applied the
WBIC to the analytically solvable Gaussian process regression case.
The error function was used instead of traditional log-sigmoid function to investigate
online learning dynamics of the multilayer perceptrons (MLPs)(Biehl and Schwarze, 1995;
Saad and A.Solla, 1995; Park et al., 2003). Cousseau et al. (2008) used the error function
to discuss the learning dynamics of a toy model of MLPs near singularities. Guo et al.
(2014, 2015) obtained the analytical expression of averaged learning equations and took the
theoretical analysis of learning dynamics near overlap singularities of MLPs. For the Gaussian mixtures, Park and Ozeki (2009) analyzed the dynamics of the EM algorithm around
singularities. Radial basis function (RBF) networks are typical feedforward neural networks
which have been applied in many fields. Wei et al. (2008) gave a general mathematical analysis of the learning dynamics near singularities in layered networks, and obtained universal
trajectories of learning near the overlap singularities. By using the methods in (Wei et al.,
2008), Wei and Amari (2008) obtained the averaged learning equations of RBF networks,
analyzed the learning dynamics near overlap singularities, and revealed the mechanism of
plateau phenomena near the singularities. Nitta (2013, 2015) discussed the singular learning dynamics of complex-valued neural networks. Due to the existence of singularities, the
standard gradient method is not Fisher efficient and the gradient descent direction is no
longer the steepest descent direction. In order to overcome this problem, natural gradient
method was proposed to accelerate the learning dynamics (Rattray et al., 1998; Amari,
1998; Amari et al., 2000; Park et al., 2000; Heskes, 2000; Pascanu and Bengio, 2014; Zhao
et al., 2015a).
In recent years, deep learning has become a very hot topic in the machine learning
community. Deep neural networks are designed based on traditional neural networks; however, it is very difficult to train deep neural networks by using the Backpropagation (BP)
2
Numerical Analysis near Singularities in RBF Networks
algorithm. The training is computationally expensive and often presents vanishing gradient problems (Bengio et al., 1994). Till Hinton et al. (2006) proposed deep belief networks to overcome the difficulties by constructing multilayer restricted Boltzmann machines
and training them layer-by-layer in a greedy fashion, many types of deep neural networks,
including deep Boltzmann machine, deep convolutional neural networks, deep recurrent
neural networks etc, have been applied to various fields successively, such as computer vision, pattern classification, natural language processing, nonlinear system identification,
etc (Schmidhuber, 2015; Goodfellow et al., 2016).
Due to the much larger number of hidden layers and architecture size, training deep
neural networks also faces many challenges (van Hasselt et al., 2016; Gulcehre et al., 2017).
On the other hand, the robustness of the training effect cannot be guaranteed, even with
a pre-training process (Erhan et al., 2009). Researchers are very interested in what causes
the difficulties in training the deep neural networks and various analytical tools are used
to study this problem. Goodfellow et al. (2014) provided some empirical evidence that
the learning processes did not seem to encounter significant obstacles on a straight path
from initialization to solution (obtained via gradient descent method). However, they also
puzzled why the training of large models remained slow despite the scarcity of obstacles.
Dauphin et al. (2014) came to the conclusion that the training difficulties were originated
from the proliferation of saddle points and local minima with high error are exponentially
rare in high dimensions. The saddle points caused the long plateaus in the training process.
Choromanska et al. (2015) obtained the results that the gradient descent converge to the
band of low critical points, and that all critical points found there are local minima of high
quality. Lipton (2016) thought that large flat basins in the parameter space were the barrier
to training the networks.
From the point of view of singularities in the parameter space, the above results have
a certain rationality. From the theoretical results in previous literature and simulation
results in this paper, we can find that the points in the elimination singularity are saddles,
the points in the overlap singularity are local minima (in the batch mode learning) and
the generalization error surface near the overlap singularity is very flat. It would be much
clearer if the analytical form of Fisher information matrix of such deep neural networks is
obtained.
Besides, Saxe et al. (2014) investigated the deep linear neural networks and found that
the error did not change under a scaling transformation. This would cause the training
difficulty which was called scaling symmetries in (Dauphin et al., 2014). The scaling symmetries are very similar to elimination singularities which will be discussed in Section 3.
These results can be applied to a more general case. For instance, deep belief nets are
based on the restricted Boltzmann machine. However, the restricted Boltzmann machine is
singular, which implies the learning dynamics of deep belief nets may be seriously affected
by the singularities. The learning processes of deep convolutional neural networks and deep
multilayer perceptrons also face this problem. The analytical results of learning dynamics
near singularities in shallow neural networks can be generalized to the deep neural networks
and improve the learning efficiency. Due to overfitting issues in deep learning and the singular structure of the learning machine, it is worthy to analyze the influence of singularities
in the deep neural networks in the future.
3
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
Currently, the effects of singularities to the learning dynamics of neural networks are still
unknown and, therefore, it is important to examine the learning dynamics near singularities.
As there are only two types of singularities (i.e. overlap and elimination singularities) in the
parameter space of RBF networks and Wei and Amari (2008) has obtained the analytical
form of averaged learning equations, we choose the RBF networks as the research objective
in this paper. Based on the theoretical analysis results, we numerically analyze the learning
dynamics near singularities through a large number of simulation experiments. From the
results in (Wei and Amari, 2008; Park and Ozeki, 2009; Guo et al., 2015), it can be seen that
the learning dynamics near singularities are similar in RBF networks, multilayer perceptrons
and Gaussian mixtures. Thus, though the analysis is taken based on RBF networks in this
paper, the statistical results can also reflect other feedforward neural networks.
For typical RBF networks with k hidden units:
f(x, θ) = X
k
i=1
wiφ(x, Ji), (1)
where x ∈ Rn denotes the input vector, Ji ∈ Rn
is the center vector for neuron i, and wi
is
the weight of neuron i in the linear output neuron. φ(·) denotes the Gaussian function and
φ(x, Ji) = exp(−
kx − Jik
2
2σ
2
), θ = {J1, · · · , Jk, w1, · · · , wk} represents all the parameters
of the model.
Next we introduce two types of singularities. If two hidden units i and j overlap, i.e.
Ji = Jj , then wiφ(x, Ji) + wjφ(x, Jj ) = (wi + wj )φ(x, Ji) remains the same value when
wi + wj takes a fixed value, regardless of particular values of wi and wj . Therefore, we can
identify their sum w = wi + wj , nevertheless, each of wi and wj remains unidentifiable.
When one output weight wi = 0, wiφ(x, Ji) = 0, whatever value Ji takes. These are the
only two types of singularities existed in the parameter space of RBF networks (Fukumizu,
1996; Wei and Amari, 2008):
(1) Overlap singularity:
R1 = {θ|Ji = Jj},
(2) Elimination singularity:
R2 = {θ|wi = 0}.
In this paper, we first derive the explicit expression of the Fisher information matrix for
RBF networks. Secondly, we use the average learning equations (ALEs) to investigate the
batch mode learning dynamics of RBF networks. A large number of numerical simulations
are conducted. By judging whether the Fisher information matrix degenerates and tracing
important variables of numerical simulations, we evaluate the learning processes which are
seriously affected by the two types of singularities. We also examine the effects of the
existence of singularities to RBF networks.
The rest of the paper is organized as follows. Section 2 shows the analytical expression
of Fisher information matrix of RBF networks. Section 3 contains the numerical analysis
near singularities for various specific cases. Finally, Section 4 presents our conclusions.
4
Numerical Analysis near Singularities in RBF Networks
2. Analytical Expression of Fisher Information Matrix in RBF Networks
As the singularities are the regions where the Fisher information matrix of system parameters degenerates, the Fisher information matrix can be seen as an important indicator to
judge whether the learning process has arrived to the singularities. We show the explicit
expression of the Fisher information matrix in this section.
In the case of regression, we have a number of observed data (x1, y1), . . . ,(xt
, yt), which
are generated by an unknown teacher function:
y = f0(x) + ε, (2)
where ε is an additive noise, usually subject to Gaussian distribution with zero mean.
We also assume that the training input is subject to a Gaussian distribution with zero
mean and a covariance matrix Σ:
q(x) = (√
2π)
−n
|Σ|
− 1
2 exp 
−
1
2
x
T Σ−1x

. (3)
As the covariance matrix plays a constant term role in the numerical analysis process and
does not essentially influence the analytical results, without loss of generality, we choose the
covariance to be the identity matrix, namely Σ = I. q(x) can be generalized as an uniform
distribution (Wei and Amari, 2008).
For the RBF networks (1), the Fisher information matrix is defined as follows (Amari
and Nagaoka, 2000):
F(θ) = 
∂f(x, θ)
∂θ
∂f(x, θ)
∂θ
T

, (4)
where h·i denotes the expectation with respect to the teacher distribution. The teacher
distribution is given by:
p0(y, x) = q(x)
1
√
2πσ0
exp 
−
(y − f0(x))2
2σ
2
0

. (5)
Then by using the results obtained in (Wei and Amari, 2008) and taking further calculations, we can obtain the following theorem:
Theorem 1 The explicit expression of Fisher information matrix for RBF networks is:
F(θ) = 
∂f(x, θ)
∂θ
∂f(x, θ)
∂θ
T

=










F11 · · · F1k F1(k+1) · · · F1(2k)
.
.
.
.
.
.
.
.
.
.
.
.
Fk1 · · · Fkk Fk(k+1) · · · Fk(2k)
F(k+1)1 · · · F(k+1)k F(k+1)(k+1) · · · F(k+1)(2k)
.
.
.
.
.
.
.
.
.
.
.
.
F(2k)1 · · · F(2k)k F(2k)(k+1) · · · F(2k)(2k)










, (6)
where:
C(Ji
, Jj ) = 
σ
2
σ
2 + 2 N
2
exp 
−
σ
2
(kJik
2 + kJjk
2
) + kJi − Jjk
2
2σ
2(σ
2 + 2) 
, (7)
5
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
B(Ji
, Jj ) = −
σ
2Jj − (Ji − Jj )
σ
2(σ
2 + 2) , (8)
*
∂φ(x, Ji)
∂Ji
∂φ(x, Jj )
∂J
T
j
+
=
C(Ji
, Jj )
σ
2(σ
2 + 2)

In + (Jj − (σ
2 + 1)Ji)B
T
(Ji
, Jj )

, (9)
In is the compatable identity matrix. (10)
For 1 ≤ i ≤ k, 1 ≤ j ≤ k,
Fij =
*
∂f(x, θ)
∂Ji
∂f(x, θ)
∂J
T
j
+
= wiwj
*
∂φ(x, Ji)
∂Ji
∂φ(x, Jj )
∂J
T
j
+
= wiwj
C(Ji
, Jj )
σ
2(σ
2 + 2)

In + (Jj − (σ
2 + 1)Ji)B
T
(Ji
, Jj )

. (11)
For 1 ≤ i ≤ k, k + 1 ≤ j ≤ 2k,
Fij =

∂f(x, θ)
∂Ji
∂f(x, θ)
∂wj−k

= wi

∂φ(x, Ji)
∂Ji
φ(x, Jj−k)

= wiC(Ji
, Jj−k)B(Ji
, Jj−k). (12)
For k + 1 ≤ i ≤ 2k, 1 ≤ j ≤ k,
Fij =
*
∂f(x, θ)
∂wi−k
∂f(x, θ)
∂J
T
j
+
= F
T
ji. (13)
For k + 1 ≤ i ≤ 2k, k + 1 ≤ j ≤ 2k,
Fij =

∂f(x, θ)
∂wi−k
∂f(x, θ)
∂wj−k

= hφ(x, Ji−k)φ(x, Jj−k)i
= C(Ji−k, Jj−k). (14)
Remark 1: When the Fisher information matrix is near singular, the condition value
of the matrix becomes very large, namely, the inverse of the condition value is near to
0. Thus the inverse of the condition value can be used to measure how close the system
parameters are to the singularities. In the following numerical analysis, we record the inverse
of condition value of the Fisher information matrix to show the influence of singularities on
the learning process more clearly.
Remark 2: By adding the inverse of Fisher information matrix as an coefficient to the
weights update in the standard gradient descent algorithm, researchers proposed the natural
gradient descent method to overcome or decrease the serious influence of the singularities.
Thus the Fisher information matrix plays a key role in natural gradient descent method.
This means that besides being the fundamental in the following numerical analysis, obtaining the analytical form of Fisher information matrix can greatly help us in designing the
modified natural gradient descent algorithms with better performance in the future.  
Numerical Analysis near Singularities in RBF Networks
3. Numerical Analysis near Singularities
After having obtained the analytical form of Fisher information matrix in Theorem 1, we
numerically analyzed the learning dynamics of RBF networks by taking four experiments
in this section, where the specific learning dynamics influenced by different types of singularities are shown and the experiment results are statistically analyzed. In Section 3.1
and Section 3.2, we conduct artificial experiments for low and medium dimensional cases,
where the input distribution is known. For these cases, the Fisher information matrix can
be obtained by using Theorem 1, and the relation between the stage where the singular
learning dynamics occur and the stage where the Fisher information matrix degenerates
can be clearly observed. In Section 3.3, the experiment for high dimensional case is carried
out by a real data set to investigate the effects of the singularities.
3.1 Two-hidden-unit RBF Networks
The results obtained in (Wei and Amari, 2008) indicate that the batch mode learning dynamics are very similar to the averaged learning dynamics and we can use the averaged
learning equations (ALEs) to investigate the dynamics in batch mode learning. Moreover,
the ALEs do not depend on any specific sample data set which can overcome the disturbance
caused by randomness of the model noise. Besides, as the ALEs are ordinary differential
equations (ODEs), and for the given teacher parameters and initial values of student parameters, the learning processes of the student parameters can be obtained by solving ODEs.
Thus, in this section, we use the ALEs to perform the experiments, where the analytical
form of ALEs in RBF networks has been obtained in (Wei and Amari, 2008).
The student RBF network is defined in Eq.(1). We also assume that the teacher function
is described by a RBF network with s hidden units:
f0(x) = f(x, θ0) + ε =
Xs
i=1
viφ(x, ti) + ε, (15)
where ε denotes zero mean Gaussian additive noise that is uncorrelated with training input
x. When the true teacher function f0(x) cannot be represented by a RBF network, f(x, θ0)
is assumed to be its best approximation by the RBF network.
The analytical form of ALEs is as follows (Wei and Amari, 2008):
J˙
i = ηwi


Xs
j=1
vjC(tj , Ji)B(tj , Ji) −
X
k
j=1
wjC(Jj , Ji)B(Jj , Ji)

 , (16)
w˙i = η


Xs
j=1
vjC(tj , Ji) −
X
k
j=1
wjC(Jj , Ji)

 , (17)
where i = 1, 2, · · · , k. C(t, J) and B(t, J) have the same meanings with Eq.(7) and Eq.(8),
respectively.
7
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
The generalization error is:
L(θ) = 
1
2
(f(x, θ0) − f(x, θ))2

=
1
2
X
i,j
vivjC(ti
, tj ) −
X
i,j
viwjC(ti
, Jj ) + 1
2
X
i,j
wiwjC(Ji
, Jj ). (18)
Results in (Wei and Amari, 2008) indicate that investigating the model with two hidden
units is enough to capture the essence of the learning dynamics near singularities. Therefore,
we first perform the numerical analysis of the RBF networks with two hidden units, and
we then analyze the RBF networks in a more general case in the following sections. The
learning dynamics of RBF networks are all obtained by solving ALEs for the given teacher
parameters and initial student parameters.
In this subsection we analyze the case where the teacher and student models both have
two hidden units.
The student model has the following form:
f(x, θ) = w1φ(x, J1) + w2φ(x, J2). (19)
The teacher model is also described by a RBF network with two hidden units:
f(x, θ0) = v1φ(x, t1) + v2φ(x, t2) + ε. (20)
We choose the spread constant σ = 0.5.
In order to investigate the influence of the singularities in the learning process of RBF
networks more accurately, we mainly focus on input x with dimension 1. For this type of
RBF networks, the global minimum is the point where the generalization error is 0, which
makes easier to analyze the simulation results.
3.1.1 Toy Model of RBF Networks
In order to visually represent the learning trajectories of parameters in the loss error surface
and given that a 3D figure can only show three parameters, we initially focus on a special
case of RBF networks, where part of the student parameters will remain invariable in the
training process.
In the case of overlap singularity, we choose the teacher model parameters v1 and v2
to be the initial state of w1 and w2, and only J1 and J2 will be modified in the learning
process. In all the other cases, the weights J2 and w2 are fixed to be the same as the
teacher parameters t2 and v2, and therefore, only J1 and w1 will be modified in the learning
process. Thus, for all cases, there are only two variable parameters: J1-J2 or J1-w1. When
the learning process has been completed, we can plot the learning trajectories of parameters
through the generalization error surface in a 3D figure. Although the student model is a
toy model, the simulation results can show the influence of singularities during the learning
process in a direct and visual manner.
In what follows, the teacher model is chosen as: t1 = −1.95, t2 = −0.90, v1 = 1.35,
v2 = 1.72, the width spread σ = 0.5. The main reason behind only choosing one teacher
function is to illustrate that the learning process of a RBF network can be affected by all
8
Numerical Analysis near Singularities in RBF Networks
the types of singularities under different initial states. For a given initial state of student
parameters, the learning trajectories of Ji and wi can be obtained by solving Eqs.(16) and
(17). The generalization error trajectory and error surface can also be obtained from Eq.(18)
after Ji and wi have been calculated.
By analyzing the simulation results, we list all the cases of learning processes as follows.
In the following figures, ’◦’ and ’×’ represent the initial state and final state, respectively.
Case 1 (Fast convergence) : The learning process converges to the global minimum
fast.
In this case, the singularities do not affect the learning process and the learning dynamics
quickly converge to the global minimum after the beginning of learning process. An example
is provided in Figure 1, which represents the trajectories in a log scale of the inverse of the
condition number, generalization error and learning trajectory in the generalization error
surface, respectively. In the training process, J2 and w2 remain invariable. As shown in
Figure 1, the parameters J1 and w1 directly converge to the global minimum (Figure 1(c))
and the Fisher information matrix remains regular (Figure 1(a)).
Case 2 (Overlap singularity) :The learning process is significantly affected by overlap
singularity.
In this case, the learning trajectories of parameters J1 and J2 arrive at the overlap
singularity, namely J1 = J2. An example is given in Figure 2, which shows the trajectories
of log scale of inverse of condition number, generalization error, weights Ji and learning
trajectory in the generalization error surface, respectively. In the training process, w1 and
w2 remain invariable.
From Figure 2(a), we can see that the inverse of the condition number of Fisher information matrix gets closer and closer to 0 as the training process runs, and finally smaller than
10e − 15 which means that the Fisher information matrix nearly degenerates. Meanwhile,
J1 and J2 nearly equal to each other (Figure 2(c)), namely the parameters arrive at the
overlap singularity. The generalization error descents fast at the beginning of the learning
process, and after J1 and J2 nearly overlap, the generalization error changes slightly. As
shown in Figure 2(d), the generalization error surface is very flat near the final state of J1
and J2, which indicates that the parameters present difficulties escaping from the overlap
singularity. In order to explore what causes the difficulties in training large-scale networks,
(Lipton, 2016) revealed the high degree of nonlinearity in the learning path by analyzing
the learning trajectories using the 2D PCA and thought that the large flat regions of the
weight space hinder the learning process. From Figure 2(d), we can see that the error surface near the overlap singularity is very flat. Due to the so flat error surface around the
overlap singularity, the learning may become very slow even if the two hidden units do not
equal to each other exactly.
Remark 3: It can be seen that the log scale of the inverse of the condition number
obviously fluctuates at the end of the learning process (Figure 2(a)). We think this is
mainly because the value is too small (smaller than 10e − 15), and even a slight change of
the parameters would cause the obvious fluctuation of the condition number of the Fisher
information matrix due to the limit to the degree of accuracy of computer.
Case 3 (Cross elimination singularity): The learning process crosses the elimination and reaches the global optimum after training.
9
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
0 50 100 150 200 250 300
t
-4.5
-4
-3.5
-3
-2.5
-2
-1.5
Log Scale of Inverse of Condition Value
(a) Trajectory of log scale of inverse of condition value
0 50 100 150 200 250 300
t
0
0.01
0.02
0.03
0.04
Generalization Error
(b) Time evolution of generalization error
0
2
1
0.2
1
0.4
0
Generalization Error
w1 J
1
0
0.6
-1
0.8
-1 -2
-2 -3
Error Surface
Learning Trajectory
Initial State
Final State (c) Learning trajectory in generalization error surface
Figure 1: Case 1 (Fast convergence) in toy model of RBF networks
The initial student parameters are J
(0)
1 = 0.30, w
(0)
1 = 0.57, J
(0)
2 = t2, w
(0)
2 = v2.
In the training process J2 and w2 remain invariable. The final student parameters
are J1 = −1.95 and w1 = 1.35.
10
Numerical Analysis near Singularities in RBF Networks
0 300 600 900 1200 1500 1800
t
-20
-18
-16
-14
-12
-10
-8
-6
-4
-2
0
Log Scale of Inverse of Condition Value
(a) Trajectory of log scale of inverse of condition value
0 300 600 900 1200 1500 1800
t
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
Generalization Error
20 40 60 80
0.4
0.6
0.8
1
1.2
(b) Time evolution of generalization error
0 300 600 900 1200 1500 1800
t
1
2
3
4
5
J
(c) Time evolution of J1 and J2
0
-4
-2
0
J
2
0.5
2 6
4
J
1
4 2
0
Generalization Error
6 -2
1
1.5
Error Surface
Learning Trajectory
Line J1=J2
Global minimum
Initial state
Final state
(d) Learning trajectory in generalization error surface
Figure 2: Case 2 (Overlap singularity) in toy model of RBF networks
The initial student parameters are J
(0)
1 = 1.60, J
(0)
2 = 0.95, w
(0)
1 = v1, w
(0)
2 = v2.
In the training process w1 and w2 remain invariable. The final student parameters
are J1 = 4.7504 and J2 = 4.7504.
11
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
When the learning process arrives at the elimination singularity, e.g. w1 = 0, the term
w1φ(x, J1) vanishes. Hence J1 does not affect the behavior of f(x, θ) and is not identifiable
on the subspace w1 = 0. An example is shown in Figure 3, where the learning process
arrived at the elimination singularity and finally reached the global optimum after crossing
it. Figure 3 shows the trajectories of the inverse of the condition number, generalization
error, weight w1 and learning trajectory in the generalization error surface, respectively.
0 500 1000 1500 2000 2500 3000
t
0
0.005
0.01
0.015
0.02
0.025
Inverse of Condition Value
10 20 30 40
0
0.01
0.02
0.03
(a) Trajectory of inverse of condition value
0 500 1000 1500 2000 2500 3000
t
0
0.05
0.1
0.15
0.2
Generalization Error
10 20 30 40
0.05
0.1
0.15
0.2
(b) Time evolution of generalization error
0 500 1000 1500 2000 2500 3000
t
-1
-0.5
0
0.5
1
1.5
w1
50 100
-1
-0.5
0
(c) Time evolution of w1
-1
-0.5
0
0
w1
6 0.5
0.1
4
2
J
1
1
0.2
0
Generaliazation Error
-2 1.5
0.3
-4 -6
0.4
0.5
Error Surface
Learning Trajectory
Line w1=0
Final State
Initial State
(d) Learning trajectory in generalization error surface
Figure 3: Case 3 (Cross elimination singularity) in toy model of RBF networks
The initial student parameters are J
(0)
1 = 0.18, w
(0)
1 = −0.85, J
(0)
2 = t2, w
(0)
2 = v2.
In the training process J2 and w2 remain invariable. The final student parameters
are J1 = −1.95 and w1 = 1.35.
From the trajectory of the inverse of the condition value of Fisher information matrix
in Figure 3(a), the Fisher information became nearly singular at the early stage of training
and remain so for some time. w1 nearly equaled 0 at this stage (Figure 3(c)) which means
12
Numerical Analysis near Singularities in RBF Networks
that the learning process has arrived at the elimination singularity. It can be clearly seen
from Figure 3(d) that the points on the line w1 = 0 are all saddle points. Then the student
parameters randomly walked around w1 = 0 and finally the learning process skipped the
elimination singularity and the student model exactly learned the teacher model. An obvious
plateau phenomenon can be observed during the learning process as shown in Figure 3(b).
Case 4 (Near elimination singularity): When the student parameters are near the
elimination singularity in the training, the learning process is significantly affected by the
elimination singularity.
In our simulation experiments, we observed another case in which, when w1 is close
to 0 but not equal to 0, the learning process is also significantly affected by elimination
singularity. Then the parameters do not skip the elimination singularity and reach the
global optimal points. Figure 4 shows the trajectories of the inverse of the condition number,
generalization error, weight w1 and learning trajectory in the generalization error surface,
respectively.
The two learning processes are similar to each other by comparing Figure 4(a) with
Figure 3(a) and Figure 4(b) with Figure 3(b), respectively. However, the trajectory of w1
in Figure 4(c) shows that w1 is close to 0 during the training process but does not equal
0. During the stage where w1 approaches 0 and departs from it, the learning process is
significantly affected and a plateau phenomenon can clearly be observed. This means that
the elimination singularity will significantly affect the learning process even if the parameters
are only near to it.
By investigating the deep linear neural networks, (Saxe et al., 2014) obtained a case
similar to the elimination singularity that slows down the learning process. The equation
of error E is derived as E(a, b) = 1
2τ
(s − ab)
2
, where τ represents the inverse of the learning
rate, s represents the input-output correlation information, a represents the weight from
the input node to the hidden layer and b represents the weight from the hidden layer to
the output node. Obviously b = 0 represents the elimination singularity. It can be seen
that the error did not change under the scaling transformations a → λa, b → b
λ
. a = 0,
b = 0 is also a fixed point. As shown in Figure 2 in (Saxe et al., 2014), we can see that
certain directions of the learning point to a = 0, b = 0 which implies the parameters will
converge to the point at first under an appropriate initial state. As the point a = 0, b = 0 is
not stable, the parameters will escape from it and finally converge to the global minimum.
During this process, long plateau can be observed. This is basically the same as with the
learning trajectories in Figure 3(d) and Figure 4(d). The results illustrate the importance
of investigating the singularities in deep neural networks.
Case 5 (Output weight 0) : After training, output weight w1 becomes nearly equal
to 0.
In the simulation experiments, we also observe that sometimes the output weight w1
becomes nearly equal to 0 after training. Even if the training process lasts longer, the weight
also remains nearly 0. We give an example of this case in Figure 5. Figure 5 shows the
trajectories of log scale of the inverse of the condition number, generalization error, weight
w1 and learning trajectory in the generalization error surface, respectively.
From Figure 5(d), it can be seen that w1 quickly drops to 0 at the beginning of the
training, and does not escape from it till the end. Even if we continue the training process
for a longer time, the student parameters remain almost unchanged. This is mainly because
13
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
0 1000 2000 3000 4000
t
0
0.005
0.01
0.015
0.02
0.025
Inverse of Condition Value
20 40 60 80
0
0.01
0.02
0.03
(a) Trajectory of inverse of condition value
0 1000 2000 3000 4000
t
0
0.02
0.04
0.06
0.08
0.1
0.12
Generalization Error
20 40 60 80
0.06
0.08
0.1
0.12
(b) Time evolution of generalization error
0 1000 2000 3000 4000
t
0
0.2
0.4
0.6
0.8
1
1.2
1.4
w1
20 40 60 80
0
0.1
0.2
0.3
(c) Time evolution of w1
0
1.5
1
0.2
0.5 5
w1
0
Generalization Error
J
1
-0.5 0
-1
0.4
-5
Error Surface
Learning Trajectory
Line w1=0
Final State
Initial State
(d) Learning trajectory in generalization error surface
Figure 4: Case 4 (Near elimination singularity) in toy model of RBF networks
The initial student parameters are J
(0)
1 = 0.30, w
(0)
1 = 0.57, J
(0)
2 = t2, w
(0)
2 = v2.
In the training process J2 and w2 remain invariable. The final student parameters
are J1 = −1.95 and w1 = 1.35.
14
Numerical Analysis near Singularities in RBF Networks
0 200 400 600 800
t
-10
-8
-6
-4
-2
0
Log Scale of Inverse of Condition Value
(a) Trajectory of inverse of condition value
0 200 400 600 800
t
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Generalization Error
20 40 60 80
0.05
0.15
0.25
0.35
(b) Time evolution of generalization error
0 200 400 600 800
t
0
0.4
0.8
1.2
1.6
w1
(c) Time evolution of w1
w1
J
1
0
1.5
1
0.5
0.2
0
-0.5 6
4
2
-1
Generalization Error
0
-2 -4 -6
0.4
0.6
Error Surface
Learning Trajectory
Line w1=0
Global Minimum
Initial State
Final State
(d) Learning trajectory in generalization error surface
Figure 5: Case 5 (Output weight 0) in toy model of RBF networks
The initial student parameters are J
(0)
1 = 0.95, w
(0)
1 = 1.55, J
(0)
2 = t2, w
(0)
2 = v2.
In the training process J2 and w2 remain invariable. The final student parameters
are J1 = 1.6192 and w1 = 0.
15
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
the radial basis function has little effect on a region that far from the center. When the
centers of the teacher and the student are very far from each other, the student cannot
exactly approximate the teacher and the output weight w1 will become zero in order to
avoid a bigger error. In this example, the initial student center J1 is far away from the
teacher center t1, and w1 is close to 0 after training. In this case, the student model is
trapped in local optimum after the training process.
Hitherto, four cases of interesting learning processes in RBF networks have been visually
introduced. In addition to the overlap singularity case, the other cases are actually onehidden-unit RBF network to approximate one-hidden-unit RBF network. Even under only
one hidden unit situation, the learning dynamics of RBF networks are still seriously affected
by singularities.
In summary, 1) in the overlap singularity case, as the generalization error surface is very
flat around the overlap singularity, the parameters cannot escape from it once they have
been affected by overlap singularity. 2) For the elimination singularity case, it can be seen
that the points in the elimination singularity are saddles, where part of the region is in a local
minimum direction and another part of the region is in a local maximum direction. When
the learning process arrives near the elimination singularity by local minimum direction,
the parameters walk randomly on the singularity till they arrive at the local maximum
direction, then the parameters converge to the global minimum. During the random walk
stage, a plateau phenomenon can be obviously observed. If the parameters can not walk
to the local maximum direction (mainly because the student center is far from the teacher
center), the output weight finally nearly equals 0.
In the following subsection, we investigate the case of two-hidden-unit RBF networks
approximated by normal two-hidden-unit RBF networks.
3.1.2 RBF Networks with Two Hidden Units
In this subsection, we consider three cases of v1 and v2: (1) v1 and v2 are both positive; (2)
v1 and v2 are both negative; and (3) v1 and v2 have opposite sign, respectively. For each
case of v1 and v2, we consider three cases of w1 and w2: (1) w1 and w2 are both positive;
(2) w1 and w2 are both negative and (3) w1 and w2 have opposite sign. Therefore, there
are 9 cases of the teacher parameters.
The procedure followed for the numerical analysis is given as:
Step 1: The teacher parameters are generated uniformly in the interval [−2, 2]. There are
9 cases. For each case, we generate 500 groups of teacher parameters.
Step 2: After each group of teacher parameters is generated, 20 groups of initial student
parameters are generated uniformly in the interval [−2, 2].
Step 3: For each group of teacher parameters and initial student parameters, we use the
ALEs to accomplish the learning process. Some important variables, such as the generalization error, or the student parameters Ji and wi
, are traced and recorded.
Step 4: For each learning process, as the student parameters have been traced, the Fisher
information matrix can be obtained. Then we record the inverse of the condition number
of the Fisher information matrix.
Step 5: After the inverse of the condition value of the Fisher information value is recorded,
a primary screening can be taken to judge whether the inverse of the condition number of
16
Numerical Analysis near Singularities in RBF Networks
the Fisher information matrix of the learning processes has been close to 0.
Step 6: After this primary screening, we make a further analysis. If weight wi was nearly
equal to 0 in the process, then the process was affected by elimination singularity. If the
two weights J1 and J2 nearly overlapped after training, the learning process was affected
by overlap singularity. We count the numbers of the learning processes which were affected
by elimination singularities and overlap singularities, respectively.
In this experiment, we totally accomplish the learning processes 90000 (3×3×500×20)
times. Given that the cases which are affected by the singularities in this subsection are
exactly the same with those in Section 3.1.1, in order to keep the paper more concise, we do
not show the learning trajectories belong to these cases in this subsection. Next, we count
the number of learning processes which contain one of the cases above and focus on the
ratio of learning processes influenced by different singularities. As the learning processes
are both affected by elimination singularities in case 3 and case 4, we view case 3 and case
4 as one case in the counting process. The statistical results are shown in Table 1.
Number of total experiments 90000
Number of case 1 (Fast convergence) 61299
Number of case 2 (Overlap singularity) 6786
Number of case 3 and case 4 (Elimination singularity) 11288
Number of case 5 (Output weight 0) 10627
Table 1: Statistical results of two-hidden-unit RBF networks
From the 4 cases of observed behaviors and the statistical results shown in Table 1, we
can obtain some conclusions as follows:
1) Many researchers have noticed the plateau phenomenon in the learning dynamics
of feedforward neural networks (Amari et al., 2006; Saad and A.Solla, 1995; Biehl and
Schwarze, 1995; Fukumizu and Amari, 2000). However, the reason why the plateau phenomenon occurs remains controversial. From the experimental results in Figure 3 and Figure
4, we found that the existence of singularities in the student parameter space results in the
plateaus.
2) As shown in Table 1, nearly 68 percent of all the experiments did not get affected by
the singularities and the learning dynamics converged to the global minimum fast. Almost
7.5 percent of experiments have been affected by overlap singularities and 12.5 percent of
experiments have been affected by the elimination singularities. The data indicates that
the singularities have a great impact on the learning processes of RBF networks. In light of
the wide application of the RBF networks in practice, the influence of singularities ought
to attract more attention of researchers. For the two-hidden-unit RBF networks, the initial
center of the student model may be often relatively too far from the center of the teacher
model, which causes the output weight of the student model to be nearly 0 after training.
This case has been observed and mentioned in (Wei et al., 2007). From the results in Table
1, nearly 12 percent of experiments belong to this case.
3) From the statistical results shown in Table 1, it can be seen that the elimination singularities have much more influence in the learning dynamics than the overlap singularities.
However, by now, few results in analyzing the elimination singularities have been obtained,
which forms a sharp contrast to the overlap singularities. Due to the serious influence of
17
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
elimination singularities on the learning dynamics, it is worthy to take a theoretical analysis
of elimination singularities.
3.2 RBF Networks in a General Case
In the previous subsection, we showed the results for the RBF networks with two hidden
units. In this subsection, we generalize these results for the general RBF networks.
Without loss of generality, we introduce the student as a ten-hidden-unit model, namely:
f(x, θ) = X
k
i=1
wiφ(x, Ji), (21)
where k = 10.
We also assume that the teacher model is represented by a RBF network with 10 units,
namely:
f(x, θ0) = Xs
i=1
viφ(x, ti) + ε, (22)
where s = 10.
We choose the spread constant σ = 0.5 and the input dimension n = 2.
When the number of hidden units in the student model is larger than that of the teacher,
the redundant case exists. This implies that the teacher parameter might be on the singularity and the learning processes are basically affected by the singularity. In order to
overcome this problem and avoid the overlap of the teacher units, we choose the minimal
distance between the teacher units ti and tj to be bigger than 2σ
2
. The main reason behind
this choice are based on the results obtained in (Wei and Amari, 2008). (Wei and Amari,
2008) obtained that the two teacher units are well separated when the distance between
two hidden units is bigger than 2σ
2
.
In our experiments, the teacher parameters ti
, vi
, are uniformly generated in the interval
[−4, 4] and we generate 50 groups of teacher parameters. After each group of teacher
parameters is generated, 20 groups of initial student parameters J
(0)
i
, w
(0)
i
are generated
uniformly in the interval [−4, 4]. We use the ALEs to accomplish the learning processes.
The experiment procedure is similar to that in Section 3.1.2.
By analyzing the simulation results, the cases where the learning processes present the
undesirable behaviors are similar to those of RBF networks with two hidden units. To
make the paper concise, the teacher parameters, the initial student parameters and the
final student parameters of the following cases are listed in Appendix A. In the following
figures, ’◦’ and ’×’ represent the initial state and final state, respectively.
Case 1 (Fast convergence): The learning process quickly converges to the global minimum and the singularities do not affect the learning process.
We provide an example of this case. Figure 6 shows the trajectories of the inverse of
the condition number, generalization error, and weights wi
, respectively.
From Figure 6(a), the Fisher information matrix did not become singular during the
learning process. Meanwhile, the generalization error dropped fast after the beginning of
the learning process, and the singularity did not obviously affect the learning process. After
the training process, the student model has converged to the global minimum.
18
Numerical Analysis near Singularities in RBF Networks
0 1000 2000 3000 4000 5000
0
1
2
3
4
5
x 10−6
t
Inverse of Condition Value
(a) Trajectory of inverse of condition value
0 1000 2000 3000 4000 5000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
t
Generalization Error
(b) Time evolution of generalization error
0 1000 2000 3000 4000 5000
−4
−3
−2
−1
0
1
2
3
4
t
w
(c) Time evolution of w
Figure 6: Case 1 (Fast convergence) in RBF networks of general case
19
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
Case 2 (Overlap singularity): The learning process is affected by overlap singularity.
In this case, the learning processes are trapped in overlap singularities after training.
An example belonging to this case is shown in Figure 7.
By analyzing the simulation results, it can be seen that, apart from the case where two
student hidden units overlapped exactly after training, the phenomenon that two hidden
units did not exactly overlap sometimes occurs. For the multidimensional parameters, we
adopt the variable h(i, j) = 1
2
kJi −Jjk
2
to indicate the distance between Ji and Jj . When
Ji and Jj nearly overlap, h(i, j) nearly equals 0. Figure 7 shows the trajectories of the
inverse of the condition number, generalization error, h(4, 8), weights wi
, respectively.
From Figure 7(a), the inverse of the condition value reduced to nearly 0 at the early stage
of training process which implies that the Fisher information matrix nearly degenerated,
and therefore this state remains till the end. Meanwhile, h(4, 8) (shown in Figure 7(c))
dropped to a very small value which implied J4 and J8 nearly overlapped, and the learning
process is trapped in overlap singularities. From the final state of J, it can be seen that
J4 and J8 are close to each other, but do not exactly overlap. However, the gradient of
the generalization error L(θ) respect to the final student parameters is nearly 0, which is
too small to influence the learning process, and the student parameters will remain almost
unchanged even though the learning process lasts longer. This is mainly because the error
surface of RBF networks in a general case near overlap singularities is very flat. When the
learning process arrives at the neighborhood of overlap singularities, although the student
units have not overlapped completely, the student units will slightly change as the result of
the relatively unchanged error in the remaining stage. The trajectories in Figure 7(a) and
Figure 7(b) are similar to the corresponding trajectories in Figure 2(a) and Figure 2(b),
respectively.
Case 3 (Elimination singularity): The learning process is affected by the elimination
singularity and a plateau phenomenon can be observed.
In this case, the learning process is significantly affected by the elimination singularity.
This case is similar to cases 3 or 4 in Section 3.1.2. A plateau phenomenon can be observed
during the learning process. We give an example of this case in Figure 8, which shows the
trajectories of the inverse of the condition number, generalization error, and weights wi
.
As shown in Figure 8(a), the Fisher information matrix became nearly singular at an
early stage of the learning process, and then became regular again. From the trajectories
in Figure 8(b), it can be observed that w5 (the wider line) skipped 0 when the Fisher
information matrix became singular and then regular. This means that the learning process
was affected by the elimination singularity. A plateau phenomenon can be observed in the
trajectory of the generalization error as shown in Figure 8(b).
Case 4 (Output weight 0): After training, one of output weights wi becomes nearly
equal to 0.
This case is similar to case 5 in Section 3.1.2. When the initial student center is too far
from the center of the teacher model, the output weight wi of the student model usually
becomes nearly 0 after the training process. An example is shown in Figure 9.
Figure 9 shows the trajectories of the inverse of the condition number, generalization
error, and weights wi
, respectively. From Figure 9(c), w5 (the wider line) has become nearly
0 after training.
20
Numerical Analysis near Singularities in RBF Networks
0 1000 2000 3000 4000 5000
t
-10
-9
-8
-7
-6
Log Scale of Inverse of Condition Value
(a) Trajectory of inverse of condition value
0 1000 2000 3000 4000 5000
0.05
0.1
0.15
0.2
0.25
t
Generalization Error
(b) Time evolution of generalization error
0 1000 2000 3000 4000 5000
0
0.2
0.4
0.6
0.8
1
1.2
1.4
t
h(4,8)
(c) Time evolution of h(4, 8)
0 1000 2000 3000 4000 5000
−4
−3
−2
−1
0
1
2
3
4
t
w
(d) Time evolution of w
Figure 7: Case 2 (Overlap singularity) in RBF networks of general case
21
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
0 1000 2000 3000 4000 5000
0
0.5
1
1.5
2
x 10−8
t
Inverse of Condition Value
(a) Trajectory of inverse of condition value
0 1000 2000 3000 4000 5000
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
t
Generalization Error
(b) Time evolution of generalization error
0 1000 2000 3000 4000 5000
−4
−3
−2
−1
0
1
2
3
4
t
w
(c) Time evolution of w
Figure 8: Case 3 (Elimination singularity) in RBF networks of general case
22
Numerical Analysis near Singularities in RBF Networks
0 1000 2000 3000 4000 5000
t
0
0.5
1
1.5
Inverse of Condition Value
×10-4
(a) Trajectory of inverse of condition value
0 1000 2000 3000 4000 5000
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
t
Generalization Error
(b) Time evolution of generalization error
0 1000 2000 3000 4000 5000
−3
−2
−1
0
1
2
3
4
t
w
(c) Time evolution of w
Figure 9: Case 4 (Output weight 0) in RBF networks of general case
23
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
Case 5 (Overlap and elimination singularity): The learning process is affected by
not only the overlap singularity but also the elimination singularity.
Different from the case of RBF with two hidden units, we find that sometimes the learning process in a more general case is simultaneously affected by the elimination singularity
and the overlap singularities. We give an example of this case in Figure 10, which shows the
trajectories of log scale of the inverse of the condition number, generalization error, h(1, 9),
and weights wi
, respectively.
From Figure 10(a), the Fisher information matrix became singular at the early stage of
the learning process, and as a result the learning process arrived in singularities. As shown
in Figure 10(b), a plateau phenomenon can be obviously observed. From Figure 10(d), it
can be seen that w3 (the wider line) crossed 0 when the plateau phenomenon occurred,
namely the learning process crossed the elimination singularity. From Figure 10(c), h(1, 9)
became very small along the training process. After training, J1 = [2.4494, − 2.1973]T
and J9 = [2.4020, − 2.2118]T
, i.e. J1 and J9 nearly equaled to each other, so the learning
process was trapped in an overlap singularity.
Case 6 (Elimination singularity and output weight 0): The learning process is
affected by elimination singularity and one of the output weights wi becomes nearly 0
after the learning process.
In addition to the case above, we also find a case where the learning dynamics are affected
by the elimination singularities during the learning process, one of the weights wi becomes
nearly 0 after training and the student parameters are trapped in an local minimum. We
give an example that belongs to this case in Figure 11.
Figure 11 shows the trajectories of the inverse of the condition number, generalization
error, and weights wi
, respectively. From Figure 11(b) and Figure 11(c), at the stage where
w3 crossed 0, a plateau phenomenon occurred and the learning process was affected by the
elimination singularity. After training, w5 = −0.0004, which is nearly equal to 0.
In comparison with the analysis results in Section 3.1.2, the RBF networks in a more
general case have similar singular behaviors as those in RBF networks with two hidden
units. The statistical results are summarized in Table 2.
Number of total experiments 1000
Number of case 1 (Fast convergence) 675
Number of case 2 (Overlap singularity) 109
Number of case 3 (Elimination singularity) 56
Number of case 4 (Output weight 0) 123
Number of case 5 (Overlap and elimination singularity) 16
Number of case 6 (Elimination singularity and output weight 0) 21
Table 2: Statistical results of RBF networks in a general case
From the results shown in Table 2, 67.5 percent of experiments did not get affected by
the singularities and the learning dynamics converged to the global minimum fast. On the
other hand, 20.2 percent of the learning processes are affected by the singularities. This
ratio is close to the one for RBF networks with two hidden units, which implies that the
existence of singularities indeed significantly affects the learning process of RBF networks.
12.3 percent of the experiments belong to case 4, which implies that the case should attract
24
Numerical Analysis near Singularities in RBF Networks
0 2000 4000 6000 8000
t
-14
-12
-10
-8
-6
-4
Log Scale of Inverse of Condition Value
(a) Trajectory of inverse of condition value
0 2000 4000 6000 8000
t
0.42
0.44
0.46
0.48
Generalization Error
(b) Time evolution of generalization error
0 2000 4000 6000 8000
t
0
0.2
0.4
0.6
0.8
1
h(1,9)
(c) Time evolution of h(1, 9)
0 2000 4000 6000 8000
t
-4
-2
0
2
4
w
(d) Time evolution of w
Figure 10: Case 5 (Overlap and elimination singularity) in RBF networks of general case
25
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
0 1000 2000 3000 4000 5000
t
0
2
4
6
8
10
Inverse of Condition Value
×10-7
0 30 60 100
0
0.3
0.6
1
×10-6
(a) Trajectory of inverse of condition value
0 1000 2000 3000 4000 5000
0
0.05
0.1
0.15
0.2
0.25
t
Generalization Error
(b) Time evolution of generalization error
0 1000 2000 3000 4000 5000
−4
−3
−2
−1
0
1
2
3
4
t
w
w5
w3
(c) Time evolution of w
Figure 11: Case 6 (Elimination singularity and output weight 0) in RBF networks of general
case
26
Numerical Analysis near Singularities in RBF Networks
more attention. In case 5 and case 6, plateau phenomenons can be obviously observed where
the learning dynamics are affected by the elimination singularities.
3.3 Extended Complex Scene Saliency Data set (ECSSD)
In the above experiments, we use artificial examples. We now perform an experiment by
using a factual data set. Salient object detection plays a key role in many image analysis
tasks that identifies important locations and structure in the visual field (Borji and Itti,
2013; Zhang et al., 2017). In recent years researchers utilize deep learning to improve the
performance of saliency detection (Zhao et al., 2015b; Lee et al., 2016). As a benchmark data
set in saliency detection community, extended complex scene saliency data set (ECSSD) has
been widely used since its release in 2013 (Yan et al., 2013). In this experiment, we use the
method proposed in (Zhang et al., 2014) to extract the features of the images in ECSSD
data set as the input of the RBF networks. We get three conspicuity maps in both the
rarity and the distinctiveness factors, and one conspicuity map in central bias factor. Thus
the number of the nodes in the input layer is 7. The output of the training samples is ’1’
or ’0’, where ’1’ represents this part of the image is salient and ’0’ represents this part of
the image is not salient.
As the distribution of input data is unknown in this experiment, we cannot obtain the
analytical form of both ALEs of the training process and the Fisher information matrix.
Thus we use batch mode learning to accomplish the experiment. By using a trial-and-error
method, we choose the number of hidden unit in the student model to be k = 90 and the
spread constant σ = 0.5, such that the student RBF network for the input x is given by:
f(x, θ) = X
90
i=1
wiφ(x, Ji). (23)
We use 200 samples to train the RBF network. For the learning rate η = 0.002 , the
model is trained by the gradient algorithm for 15000 times and the sum squared training
error E =
1
2
200
P
i=1
(yi −
P
90
j=1
wjφ(xi
, Jj ))2
is used to replace the generalization error. Then we
clone it 200 times. Each clone is trained with different random initial weights. The initial
student parameters J
(0)
i
and w
(0)
i
are uniformly generated in the interval [−2, 2].
By analyzing the simulation results, the different types of learning processes are listed
as follows. In the following figures, ’◦’ and ’×’ represent the initial state and final state,
respectively.
Case 1 (Fast convergence): The learning process is not affected by singularities.
We give an example of this case in Figure 12, which shows the trajectories of the training
error and part of output weights w. From Figure 12(a), we can see that the training error
comes down to a small number after the training starts and remains small till the learning
stops. We do not observe that the singularities have affected the training process.
Case 2 (Overlap singularity): The learning process is affected by overlap singularity.
We give an example of this case in Figure 13, which shows the trajectories of the training
error and h(18, 90). From Figure 13(b), the Euclid distance between J18 and J90 became
nearly 0, which means J18 and J90 nearly overlapped after learning.
27
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
0 5000 10000 15000
Iteration
0
10
20
30
40
50
Training Error
0 50 100
10
30
50
(a) Trajectory of training error (b) Trajectory of w
Figure 12: Case 1 (Fast convergence) in approximating ECSSD data set
0 5000 10000 15000
Iteration
0
10
20
30
40
50
60
Training Error
0 35 70 100
0
30
60
(a) Trajectory of training error
0 5000 10000 15000
Iteration
0
0.5
1
1.5
2
2.5
h(18,90)
(b) Trajectory of h(18, 90)
Figure 13: Case 2 (Overlap singularity) in approximating ECSSD data set
The initial state is:
J
(0)
18 = [−0.4159, − 1.0079, − 0.3436, 0.1162, 0.6212, 0.3521, 0.9892]T
,
J
(0)
90 = [−0.1619, 0.0519, 0.1225, 0.6200, − 0.8639, − 0.0874, 0.8953]T
.
The final state is:
J18 = [−0.2480, 0.0515, − 0.1948, 0.2474, 0.0130, 0.0531, 1.2120]T
,
J90 = [−0.2353, 0.0871, − 0.1995, 0.2585, − 0.0267, 0.0538, 1.1964]T
.
28
Numerical Analysis near Singularities in RBF Networks
Case 3 (Elimination singularity): The learning process is affected by elimination
singularity.
We give an example of this case. Figure 14 shows the trajectories of the training error
and output weight w64. We can see that during the stage where w64 crosses 0 (Figure
14(b)), a plateau phenomenon can be observed (Figure 14(a)). The learning process is,
thus, significantly affected by the elimination singularity.
0 2000 4000 6000 8000 10000
Iteration
5
10
20
30
40
Training Error
(a) Trajectory of training error
0 2000 4000 6000 8000 10000
Iteration
-0.5
0
0.5
1.5
2.5
w64
(b) Trajectory of w64
Figure 14: Case 3 (Elimination singularity) in approximating ECSSD data set
Case 4 (Output weight 0): After training, one of the output weights wi nearly equals
to 0.
We give an example of this case. Figure 15 shows the trajectories of the training error
and part of output weights w. From the trajectory in Figure 15(b), it can be seen that w80
(the wider line) became nearly 0 after the training process.
Next, we count the learning processes which belong to each of the three cases and show
them in Table 3.
Number of total experiments 200
Number of case 1 (Fast convergence) 153
Number of case 2 (Overlap singularity) 3
Number of case 3 (Elimination singularity) 42
Number of case 4 (Output weight 0) 2
Table 3: Statistical results of RBF networks in approximating ECSSD data set
It can be seen from the statistical results in Table 3 that as many as 22.5 percent of
the experiments were seriously affected by the different types of singularity. There are only
three experiments affected by the overlap singularity. On the other hand, we can see that 21
percent of the experiments were affected by elimination singularities. The results indicate
that, in a high dimensional data scenario, the learning process is more likely affected by
the elimination singularity. Therefore, it is worthy to pay more attention to investigating
29
GUO, WEI, ONG, HERVAS, ZHAO, WANG and ZHANG
0 5000 10000 15000
Iteration
0
10
20
30
40
50
Training Error
0 50 100
10
30
50
(a) Trajectory of training error (b) Trajectory of w
Figure 15: Case 4 (Output weight 0) in approximating ECSSD data set
the elimination singularity. Moreover, different from our other earlier simulation results,
only 1 percent of the experiments belong to case 4. The ratio is much less than those of
the former experiments. The main reason is that a factual function can be represented by
different suboptimal RBF networks which are equivalent to each other and the case where
the initial center of the student model is far away from the center of teacher model becomes
infrequent.
The statistical results confirm the previous results investigating the training difficulties
in large networks from another view of point. (Dauphin et al., 2014) concluded that the
local minima with high error were rare in high dimensions and the training difficulties
were mainly caused by saddle points. From Table 3, we can see that the experiments
affected by the overlap singularities (local minimum case) are much less than those in low
dimensional networks. However, nearly all of the singular learning dynamics are affected by
the elimination singularities (saddle point case). The results are in accordance with those
obtained in (Dauphin et al., 2014).
4. Conclusion
Many previous works have demonstrated that the learning dynamics of feedforward neural
networks are affected by the existence of singularities, but which type of singularity has
more influence on the learning dynamics remains unclear. RBF networks are typical feedforward neural networks, and the learning dynamics near overlap singularities have been
theoretically analyzed. Based on the obtained results, we have focused on the relationship
between the existence of singularities and the learning dynamics of RBF networks in this
paper. We have presented the analytical expression of the Fisher information matrix for
RBF networks, as the singularities are the subspaces of the parameter space where the
Fisher information matrix degenerates.
30
Numerical Analysis near Singularities in RBF Networks
From the learning trajectories of the parameters in the generalization error surface, it
can be clearly seen that the learning dynamics of RBF networks are affected by the singularities. Through a large number of numerical simulation experiments for RBF networks with
two hidden units, we have identified 4 cases presenting strange learning behaviors. Nearly
7.5 percent and 12.5 percent of our experiments have shown significant effects of the overlap singularities and the elimination singularities, respectively. The points in the overlap
singularity are local minima and the points in the elimination singularity are saddle points.
The elimination singularities have a more significant impact to the learning processes than
the overlap singularities. Our experimental results have also indicated that the plateau
phenomena are mainly caused by the elimination singularities. Moreover, about 12 percent
of our experiments have shown that one of the output weights of RBF networks could be
close to zero after training and the student parameters are trapped into local minimum.
Through numerical simulation experiments for large scale RBF networks using a practice
data set, we have found that the results are some different. Nearly all singular cases belong
to the elimination singularity case and the overlap singularity case rarely occurred. This
means that the large scale networks are more likely affected by the saddle points. The cases
that converge to a local minimum with high error rarely appeared and the networks mainly
converge to the global minimum or local minimum with good performance. The results
are in accordance with the previous findings in large scale neural networks (Dauphin et al.,
2014; Saxe et al., 2014; Choromanska et al., 2015).
In summary, we conclude that:
1) Overlap singularities lead to genuine local minima and elimination singularities lead
to saddle points. The plateau phenomena are mainly caused by the elimination singularities.
2) The elimination singularities have a more significant impact to the learning processes
than the overlap singularities. The overlap singularities mainly influence the learning dynamics of neural networks with low dimension. The large scale networks predominantly
suffer from elimination singularities (saddle point case) and local minima with high error
have rare influence.
Future research should pay more attention to the elimination singularities, and special
treatments should be designed both for the traditional feedforward neural networks and
deep neural networks to deal with the existence of singularities.