We propose a two-stage penalized least squares method to build large systems of structural
equations based on the instrumental variables view of the classical two-stage least squares
method. We show that, with large numbers of endogenous and exogenous variables, the
system can be constructed via consistent estimation of a set of conditional expectations
at the first stage, and consistent selection of regulatory effects at the second stage. While
the consistent estimation at the first stage can be obtained via the ridge regression, the
adaptive lasso is employed at the second stage to achieve the consistent selection. This
method is computationally fast and allows for parallel implementation. We demonstrate
its effectiveness via simulation studies and real data analysis.
Keywords: graphical model, high-dimensional data, reciprocal graphical model, simultaneous equation model, structural equation model
1. Introduction
We consider a linear system with p endogenous and q exogenous variables. With a sample of
n observations from this system, we denote the observed values of endogenous and exogenous
variables by YnÃ—p = (Y1, Â· Â· Â· , Yp) and XnÃ—q = (X1, Â· Â· Â· , Xq), respectively. The interactions
among endogenous variables and the direct causal effects by exogenous variables can be
described by a system of structural equations,
Y = YÎ“ + XÎ¨ + , (1)
where the p Ã— p matrix Î“ has zero diagonal elements and contains regulatory effects, the
q Ã— p matrix Î¨ contains causal effects, and  is an n Ã— p matrix of error terms. We assume
that X and  are independent of each other, and each component of  is independently
distributed as normal with zero mean while rows of  are identically distributed.
With gene expression levels and genotypic values as endogenous and exogenous variables,
respectively, the model (1) has been used to represent a gene regulatory network with

each equation modeling the regulatory genetic effects as well as the causal genomic effects
from cis-eQTL (i.e., expression quantitative trait loci located within the regions of their
target genes) on a given gene, see Xiong et al. (2004), and Liu et al. (2008), among others.
Genetical genomics experiments, which collect genome-wide gene expressions and genotypic
values, have been widely undertaken to construct gene regulatory networks (Jansen and
Nap, 2001; Schadt et al., 2003). However, fitting a system of structural equations in (1)
to genetical genomics data for the purpose of revealing a whole-genome gene regulatory
network is still hindered by lack of an effective statistical method which addresses issues
brought by large numbers of endogenous and exogenous variables.
Several efforts have been made to construct the system (1) with genetical genomics
data. Xiong et al. (2004) proposed to use a genetic algorithm to search for genetic networks
which minimize the Akaike Information Criterion (AIC; Akaike, 1974), and Liu et al. (2008)
instead proposed to minimize the Bayesian Information Criterion (BIC; Schwartz, 1978)
and its modification (Broman and Speed, 2002) for the optimal genetic networks. Both
AIC and BIC are applicable to inferring networks for only a small number of endogenous
variables. For a large system with many endogenous and exogenous variables, Cai et al.
(2013) proposed to maximize a penalized likelihood to construct a sparse system. However,
it is computationally formidable to fit a large system based on the likelihood function of the
complete model. Logsdon and Mezey (2010) instead proposed to apply the adaptive lasso
(Zou, 2006) to fitting each structural equation separately, and then recover the network
relying on additional assumption on unique exogenous variables. However, Cai et al. (2013)
demonstrated its inferior performance via simulation studies, which is consistent with our
conclusion.
Instead of the full information model specified in (1), we seek to establish the large
system via constructing a large number of limited information models, each for one endogenous variable (Schmidt, 1976). For example, when the k-th endogenous variable is
concerned, we focus on the k-th structural equation in (1) which models the regulatory
effects of other endogenous variables and direct causal effects of exogenous variables, and
ignore the system structures contained in other structural equations, leading to the following
limited-information model,

Yk = Yâˆ’kÎ³k + XÏˆk + k,
Yâˆ’k = XÏ€âˆ’k + Î¾âˆ’k
.
(2)
Here Yâˆ’k refers to Y excluding the k-th column, Î³k
refers to the k-th column of Î“ excluding
the diagonal zero, and Ïˆk and k refer to the k-th columns of Î¨ and  respectively. The
second part of the model (2) is from the following reduced model by excluding the k-th
reduced-form equation, with Ï€ = Î¨(I âˆ’ Î“)
âˆ’1 and Î¾ = (I âˆ’ Î“)
âˆ’1
,
Y = XÏ€ + Î¾. (3)
In a classical low-dimensional setting, applying the ordinary least squares method to
the first equation in (2) leads to underestimated Î³k and Ïˆk due to correlated Yâˆ’k and k.
Instead, the reduced-form equations in (2) are fitted to obtain least squares estimator Ï€Ë† âˆ’k
of Ï€âˆ’k, and least squares estimators of Î³k and Ïˆk are further obtained by regressing Yk
against YË† âˆ’k = XÏ€Ë† âˆ’k and X. This procedure is widely known as the two-stage least squares
2
Two-Stage Penalized Least Squares
(2SLS) method which can produce consistent estimates of the parameters when the system
is identifiable. The 2SLS estimator was originally proposed by Theil (1953a,b, 1961) and,
independently, Basmann (1957), and can be restated as the instrumental variables estimator
(ReiersÃ¸l, 1941, 1945).
As in a typical genetical genomics experiment, we are interested in constructing a large
system with the number of endogenous variables p possibly larger than the sample size n.
Such a high-dimensional and small sample size data set makes it infeasible to directly apply
the 2SLS method. Indeed, p â‰¥ n may result in perfect fits of reduced-form equations at the
first stage, which implies that we regress against the observed values of endogenous variables
at the second stage and therefore obtain ordinary least squares estimates of the parameters.
It is well known that such ordinary least squares estimates are inconsistent. Furthermore,
constructing a large system demands, at the second stage, selecting regulatory endogenous
variables among massive candidates, i.e., variable selection in fitting high-dimensional linear
models.
In the setting of selecting instrumental variables (IVs) among a large number of candidates, L1 regularized least squares estimators have been recently proposed to replace the
ordinary least squares estimator at the first stage of 2SLS (Belloni et al., 2012; Lin et al.,
2015; Zhu, 2015). Belloni et al. (2012) applied lasso-based methods to select IVs and obtain consistent estimations at the first stage when the first stage is approximately sparse.
For sparse instrumental variables models, Zhu (2015) proposed to replace with lasso-based
methods at both stages of 2SLS and Lin et al. (2015) considered the representative L1
regularization methods and a class of concave regularization methods for both stages. All
of these methods assume that each endogenous variable is only associated to a relatively
small set of exogenous variables, i.e., each row of Ï€ in (3) only has a small set of nonzero
components.
Here we consider to construct a general system of structural equations, which allows
us to model nonrecursive or even cyclic relationships between endogenous variables. With
the instrumental variables view of the two-stage approach, we observed that successful
identification and consistent estimation of model parameters rely on consistent estimation
of a set of conditional expectations which are optimal instruments. Therefore, establishing
the system (1) in a high-dimensional setting is contingent on obtaining consistent estimation
of these conditional expectations at the first stage, and effectively selecting and estimating
of regulatory effects out of a large number of candidates at the second stage. Accordingly,
we propose a two-stage penalized least squares (2SPLS) method to fit regularized linear
models at each stage, with L2 regularized linear models at the first stage and L1 regularized
linear models at the second stage.
The proposed method addresses three challenging issues in constructing a large system
of structural equations, i.e., memory capacity, computational time, and statistical power.
First, the limited information models are considered to develop the algorithm. In this way,
we avoid working with full information models which may consist of many subnetworks and
involve a massive number of endogenous variables. Second, allowing us to fit one linear
model for each endogenous variable at each stage makes the algorithm computationally
fast. It also makes it feasible to parallelize the large number of model fittings at each stage.
Finally, the oracle properties of the resultant estimates show that the proposed method
can achieve optimal power in identifying and estimating regulatory effects. Furthermore,
3
Chen, Ren, Zhang, and Zhang
the efficient computation makes it feasible to use the bootstrap method to evaluate the
significance of regulatory effects.
The rest of this paper is organized as follows. First, we state an identifiable model in
Section 2. Section 3 revisits the instrumental variables view on the classical 2SLS method,
which motivates our development of the 2SPLS method in Section 4. We show in Section 5
the theoretical properties of the estimates from 2SPLS, with the proof included in the
Appendix. Simulation studies are carried out in Section 6 to evaluate the performance
of 2SPLS. An application to a real data set to infer a yeast gene regulatory network is
presented in Section 7. We conclude this paper with a discussion in Section 8.
2. The Identifiable Model
We follow the practice of constructing system (1) in analyzing genetical genomics data
(Logsdon and Mezey, 2010; Cai et al., 2013), and assume that each endogenous variable is
affected by a unique set of exogenous variables, that is, the structural equation in (2) has
known zero elements of Ïˆk
. Explicitly, we use Sk to denote the set of row indices of known
nonzero elements in Ïˆk
. Then we have known sets Sk, k = 1, 2, Â· Â· Â· , p, which dissect the set
{1, 2, Â· Â· Â· , q}. We explicitly state this assumption in the below.
Assumption A. Sk 6= âˆ… for k = 1, Â· Â· Â· , p, but Sj âˆ© Sk = âˆ… as long as j 6= k.
The above assumption satisfies the rank condition (Schmidt, 1976), which is a sufficient
condition for model identification. Since each Ïˆk has a set of known zero components, from
this point forward we ignore them and rewrite the structural equation in the model (2) as,
Yk = Yâˆ’kÎ³k + XSkÏˆSk + k, k âˆ¼ N(0, Ïƒ2
k
In), (4)
where XSk
refers to X including only columns indicated by Sk, and ÏˆSk
refers to Ïˆk
including only elements indicated by Sk.
3. The Instrumental Variables View of the Two-Stage Least Squares
Method
Because Yâˆ’k and k are correlated, fitting merely the model (4) results in biased estimates
of Î³k and ÏˆSk
. However, the following two sets of variables are independent,

Zâˆ’k = E[Yâˆ’k|X] = XÏ€âˆ’k,
Îµk = k + Î¾âˆ’kÎ³k
.
Consequently, consistent estimates of Î³k and ÏˆSk
can be obtained by applying least squares
method to the following model,
Yk = Zâˆ’kÎ³k + XSkÏˆSk + Îµk. (5)
Observing Yâˆ’k instead of Zâˆ’k = E[Yâˆ’k|X] naturally leads to application of the instrumental variables method (ReiersÃ¸l, 1941, 1945), that is, replacing Zâˆ’k = XÏ€âˆ’k with its
estimate ZË† âˆ’k = XÏ€Ë† âˆ’k in fitting the linear model (5). When a âˆš
n-consistent least squares
4
Two-Stage Penalized Least Squares
estimator of Ï€j is obtained by fitting each equation in (3) for j = 1, Â· Â· Â· , p, the resultant
estimators of Î³k and ÏˆSk
are exactly the 2SLS estimators by Theil (1953a,b, 1961) and
Basmann (1957).
Suppose that the matrix X satisfies the assumption in the below. It is easy to prove
that, in a low-dimensional setting, we can obtain consistent estimators for the model (5)
with any consistent estimate of Ï€âˆ’k.
Assumption B. n
âˆ’1XT X â†’ C, where C is a positive definite matrix.
Proposition 3.1 Suppose Assumptions A and B are satisfied for the system (1) with fixed
p  n and q  n. When there exists a consistent estimator Ï€Ë† âˆ’k of Ï€âˆ’k, the ordinary
least squares estimators of (Î³k
, ÏˆSk
) obtained by regressing Yk against (XÏ€Ë† âˆ’k, XSk
) are
also consistent.
The above instrumental variables view implies that the conditional expectation Zâˆ’k =
E[Yâˆ’k|X] serves as the optimal instrument for Yâˆ’k. Although, in a low-dimensional setting,
any consistent estimator Ï€Ë† âˆ’k leads to the instrument ZË† âˆ’k = XÏ€Ë† âˆ’k, an efficient estimate
of Ï€âˆ’k should be used to produce efficient estimates of Î³k and ÏˆSk
. In the following
section, we build up on this view and construct the high-dimensional system (1) by first
fitting high-dimensional linear models to consistently estimate the conditional expectations
of endogenous variables given exogenous variables.
4. The Two-Stage Penalized Least Squares Method
To construct the limited-information model (2), we can obtain consistent estimates of the
conditional expectations of endogenous variables given exogenous variables by fitting highdimensional linear models, and then conduct a high-dimensional variable selection following
our view on the model (5). Accordingly, we propose a two-stage penalized least squares
(2SPLS) procedure to construct each model in (2) so as to establish the large system (1).
4.1 The Method
At the first stage, we use the ridge regression to fit each reduced-form equation in (3) to
obtain consistent estimates of the conditional expectations of endogenous variables given
exogenous variables, that is, for each j = 1, 2, Â· Â· Â· , p, we obtain the ridge regression estimator
of Ï€j by minimizing the following penalized sum of squares,
kYj âˆ’ XÏ€jk
2
2 + Ï„jkÏ€jk
2
2
, (6)
where k Â· k2 is the L2 norm, and Ï„j > 0 is a tuning parameter that controls the strength
of the penalty. The solution to the minimization problem is Ï€Ë†j = (XT X + Ï„jI)
âˆ’1XT Yj ,
which leads to a consistent estimate of Zj ,
ZË†
j = PÏ„jYj ,
where PÏ„j = X(XT X + Ï„jI)
âˆ’1XT
. With a proper choice of Ï„j , the ridge regression has a
good estimation performance as shown in the next section.
5
Chen, Ren, Zhang, and Zhang
At the second stage, we replace Zâˆ’k with ZË† âˆ’k in model (5) to derive estimates of Î³k
and ÏˆSk
, specifically, we minimize the following penalized error squares to obtain estimates
of Î³k and ÏˆSk
,
1
2
kYk âˆ’ ZË† âˆ’kÎ³k âˆ’ XSkÏˆSk
k
2
2 + Î»kÏ‰
T
k
|Î³k
|, (7)
where |Î³k
| denotes componentwise absolute value of Î³k
, Ï‰k is a known weight vector, and
Î»k > 0 is a tuning parameter.
Minimizing for ÏˆSk
in (7) leads to
ÏˆË†
Sk = (XT
SkXSk
)
âˆ’1XT
Sk
(Yk âˆ’ ZË† âˆ’kÎ³k
),
where XSk
is usually of low dimension, and the above least squares estimator of ÏˆSk
is easy
to obtain.
Plugging ÏˆË†
Sk
into (7), we can solve the following minimization problem to obtain an
estimate of Î³k
,
Î³Ë†k = arg min
Î³k

1
2
(Yk âˆ’ ZË† âˆ’kÎ³k
)
T Hk(Yk âˆ’ ZË† âˆ’kÎ³k
) + Î»kÏ‰
T
k
|Î³k
|

, (8)
where Hk = I âˆ’ XSk
(XT
SkXSk
)
âˆ’1XT
Sk
, this is equivalent to a variable selection problem in
regressing HkYk against high-dimensional HkZË† âˆ’k. We will resort to adaptive lasso to select
nonzero components of Î³k and estimate them. Specifically, picking up a Î´ > 0 and obtaining
Î³Ëœk as a âˆš
n-consistent estimate of Î³k
, we calculate the weight vector Ï‰k with components
inversely proportional to components of |Î³Ëœk
|
Î´
. The above minimization problem (8) is a
convex optimization problem which is computationally efficient.
4.2 Tuning Parameter Selection
In this method, we need to select tuning parameters at each stage. At the first stage, we
propose to choose each Ï„j in (6) by the method of generalized cross-validation (GCV; Golub
et al., 1979), that is,
Ï„j = arg min
Ï„>0
Gj (Ï„ ) = arg min
Ï„>0
(Yj âˆ’ PÏ„Yj )
T
(Yj âˆ’ PÏ„Yj )
(n âˆ’ tr{PÏ„ })
2
.
It is a rotation-invariant version of ordinary cross-validation, and leads to an approximately
optimal estimate of the conditional expectation Zj . At the second stage, the tuning parameter Î»k in (8) is obtained via K-fold cross validation.
5. Theoretical Properties
5.1 The Number of Endogenous Variables is Fixed
As an extension of the classical 2SLS method to high dimensions, the proposed 2SPLS
method also has some good theoretical properties. In this section, we will show that the
2SPLS estimates enjoy the oracle properties. As the second-stage estimation relies on the
6
Two-Stage Penalized Least Squares
ridge estimates ZË† âˆ’k obtained from the first stage, we start with the theoretical properties
of ZË† âˆ’k.
As mentioned previously, each Ï„j in (6) is obtained by GCV. Interestingly, as stated by
Golub et al. (1979), such a Ï„j is closely related to the one minimizing
Tj (Ï„ ) = (Zj âˆ’ PÏ„Yj )
T
(Zj âˆ’ PÏ„Yj ).
We have the following result similar to Theorem 2 of Golub et al. (1979).
Theorem 5.1 Suppose that all components of Ï€j are i.i.d. with mean zero and variance
Ïƒ
2
Ï€, then
arg min
Ï„>0
E [E[Gj (Ï„ )|Ï€j ]] = arg min
Ï„>0
E [E[Tj (Ï„ )|Ï€j ]] = Ïƒ
2
Î¾j

Ïƒ
2
Ï€,
where Ïƒ
2
Î¾j
is the variance component of Î¾j
in model (2).
This theorem implies that the GCV estimate ZË†
j = PÏ„jYj is approximately the optimal
estimate of the conditional expectation Zj ; furthermore, as the optimal tuning parameter approximates a constant determined by the variance components ratio, we make the
following assumption on Ï„j .
Assumption C. Ï„j/
âˆš
n â†’ 0 as n â†’ âˆž, for j = 1, Â· Â· Â· , p.
We then have the following properties on ZË† âˆ’k.
Theorem 5.2 For k = 1, . . . , p, let Mk = Ï€
T
âˆ’k
(Câˆ’Câ€¢SkC
âˆ’1
Sk,Sk
CSkâ€¢)Ï€âˆ’k where each CSrSc
is a submatrix of C identified with row indices in Sr and column indices in Sc (the dot implies
all rows or columns). Then, under Assumptions A, B, and C,
a. n
âˆ’1ZË†T
âˆ’kHkZË† âˆ’k â†’p Mk, as n â†’ âˆž;
b. n
âˆ’1/2
(Yk âˆ’ ZË† âˆ’kÎ³k
)
T HkZË† âˆ’k â†’d N(0, Ïƒ2
kMk), as n â†’ âˆž.
Since n
âˆ’1Z
T
âˆ’kHkZâˆ’k â†’ Mk, Theorem 5.2.a states that ZË†T
âˆ’kHkZË† âˆ’k is a good approximation to Z
T
âˆ’kHkZâˆ’k. On the other hand, Hk(Yk âˆ’ ZË† âˆ’kÎ³k
) is the error term in regressing
HkYk against HkZË† âˆ’k, and Theorem 5.2.b implies that n
âˆ’1
(Yk âˆ’ ZË† âˆ’kÎ³k
)
T HkZË† âˆ’k â†’d 0.
Thus ZË† âˆ’k results in regression errors with good properties, i.e., the error effects on the
2SPLS estimators will vanish when the sample size gets sufficiently large.
In summary, the above theorem indicates that ZË† âˆ’k behaves the same way as Zâˆ’k asymptotically, which makes it reasonable to replace Zâˆ’k with ZË† âˆ’k at the second stage. Denote
the j-th elements of Î³k and Î³Ë†k as Î³kj and Ë†Î³kj , respectively. Then, the properties of ZË† âˆ’k
in Theorem 5.2, together with the oracle properties of the adaptive lasso, will lead to the
following oracle properties of our proposed estimates.
Theorem 5.3 (Oracle Properties) Let Ak = {j : Î³kj 6= 0, j 6= k} and AË†
k = {j : Ë†Î³kj 6= 0, j 6= k}.
Further index both rows and columns of Mk with 1, Â· Â· Â· , k âˆ’ 1, k + 1, Â· Â· Â· , p, and let Mk,Ak
be the submatrix of Mk identified with both row and column indices in Ak. Suppose that
Î»k/
âˆš
n â†’ 0 and Î»kn
(Î´âˆ’1)/2 â†’ âˆž. Then, under Assumptions A, B, and C, the estimates
from the proposed 2SPLS method satisfy the following properties,
7
Chen, Ren, Zhang, and Zhang
a. Consistency in variable selection: limnâ†’âˆž P(AË†
k = Ak) = 1;
b. Asymptotic normality: âˆš
n(Î³Ë†k,Ak âˆ’ Î³k,Ak
) â†’d N(0, Ïƒ2
kMâˆ’1
k,Ak
), as n â†’ âˆž.
It is worth mentioning that Theorem 5.2 plays an essential role in establishing the oracle
properties of 2SPLS. In fact, as long as the properties in Theorem 5.2 hold true for the firststage estimates of Zâˆ’k, the oracle properties can be expected from the adaptive lasso (Zou,
2006) at the second stage. On the other hand, we can also generalize the second-stage
regularization to a wide class of regularization methods (Fan and Li, 2001; Huang et al.,
2011; Zhang, 2010), the theoretical properties, of which, can still be inherited due to the
results in Theorem 5.2.
5.2 The Number of Endogenous Variables is Divergent
In this section, we investigate the theoretical properties of 2SPLS with a divergent p. That
is, per Assumption A, both p and q may grow with sample size n at the the same order. The
theoretical properties will be described by a prespecified sequence fn = o(n) but fn â†’ âˆž.
We first update Assumptions B and C for the divergent p and q.
Assumption B0
. Both p and q grow at the same order of o(n), i.e., p  q = o(n).
Furthermore, the singular values of I âˆ’ Î“ are positively bounded from below, and
there exist positive constants c1 and c2 such that, for any vector Î´ with kÎ´k2 = 1,
c1 â‰¥ n
âˆ’1/2 kXÎ´k2 â‰¥ c2.
Assumption C0
. rnk , Ï„
2
k
kÏ€kk
2
2
/n = o(n).
We have the following properties on the ridge regression estimator of Ï€k from the first
stage.
Theorem 5.4 Under Assumptions A, B0
, and C0
, for each ridge regression estimator Ï€Ë† k,
there exist constants C1 and C2 such that, with probability at least 1 âˆ’ e
âˆ’fn ,
(a) kÏ€Ë† k âˆ’ Ï€kk
2
2 â‰¤ C1 (rnk âˆ¨ q âˆ¨ fn) /n;
(b) n
âˆ’1 kX(Ï€Ë† k âˆ’ Ï€k)k
2
2 â‰¤ C2 (rnk âˆ¨ q âˆ¨ fn) /n.
Denote rmax = max1â‰¤kâ‰¤p rnk. Then the system-wise losses in both kÏ€Ë† k âˆ’ Ï€kk
2
2
and
n
âˆ’1 kX(Ï€Ë† k âˆ’ Ï€k)k
2
2
have upper bounds in the same order as (rmax âˆ¨ q âˆ¨ fn)/n, with probability at least 1 âˆ’ e
âˆ’(fnâˆ’log(p)). With p = o(n), we henceforth select fn to dominate log(p),
i.e. fn âˆ’ log(p) â†’ âˆž, to guarantee the well-controlled losses over the whole system.
Denote Ak = {j : Î³kj 6= 0, j 6= k}. Indexing all rows and columns with only j =
1, Â· Â· Â· , k âˆ’ 1, k + 1, Â· Â· Â· , p, we define the restricted eigenvalue for a (p âˆ’ 1) Ã— (p âˆ’ 1) matrix
M as
Ï†k
(M) = min n
n
âˆ’1/2
kMÎ³k2
kÎ³Ak
k
âˆ’1
2
:

Î³Ac
k


1
â‰¤ 3 kÎ³Ak
k1
o
.
We further define k Â· kâˆž and k Â· kâˆ’âˆž to be the maximum and minimum absolute values of
the components of a vector, respectively. For a matrix, kÂ· kâˆž is defined to be the maximum
absolute row sum of the matrix.
We further make the following assumption on the tuning parameter Î»k of the adaptive
lasso at the second stage.
8
Two-Stage Penalized Least Squares
Assumption D. The adaptive tuning parameter Î»k is at the same order as kÏ‰kk
âˆ’1
âˆ’âˆž kÎ“k1
kÏ€k1
p
n(rmax âˆ¨ q âˆ¨ fn) log p.
We then have the consistency property of estimator Î³Ë†k
.
Theorem 5.5 (Estimation Consistency) Suppose that, for each node k, both inequalities
kÏ‰k,Ak
kâˆžkÏ‰k,Ac
k
k
âˆ’1
âˆ’âˆž â‰¤ 1 and p
(rmax âˆ¨ q âˆ¨ fn)/n + c1 kÏ€k1 â‰¤
q
c
2
1
kÏ€k
2
1 + Ï†
2
0

64C2|Ak|
hold, and there exists a positive constant Ï†0 such that Ï†k
(HkXÏ€âˆ’k) â‰¥ Ï†0. Denote hn =
(kÎ“k
2
1 âˆ§ 1) h
(
n
q
kÏ€k
2
1
) âˆ§ (rmax âˆ¨ q âˆ¨ fn)
i
log p. Under Assumptions A, B0
, C0
, and D, there
exist constants C3 > 0 and C4 > 0 such that, with probability at least 1 âˆ’ e
âˆ’C3hn+log(4pq) âˆ’
e
âˆ’fn+log(p)
, each 2SPLS estimator Î³Ë†k
satisfies that
1. kÎ³Ë†k âˆ’ Î³kk1 â‰¤ 8C4
kÏ‰k,Ak
kâˆžkÏ€k1kÎ“k1
Ï†
2
0
kÏ‰kkâˆ’âˆž
|Ak|
q
(rmaxâˆ¨qâˆ¨fn) log p
n
;
2. n
âˆ’1



HkZË† âˆ’k(Î³Ë†k âˆ’ Î³k
)



2
2
â‰¤
C2
4
kÏ‰k,Ak
k
2âˆžkÏ€k
2
1kÎ“k
2
1
Ï†
2
0
kÏ‰kk
2
âˆ’âˆž
|Ak|
(rmaxâˆ¨qâˆ¨fn) log p
n
.
Note that the system-wide upper bounds, defined by replacing |Ak| with maxk |Ak|, can
also be achieved with probability at least 1 âˆ’ e
âˆ’C3hn+log(4q)+2 log(p) âˆ’ e
âˆ’fn+2 log(p)
.
Let Wk = diag{Ï‰k} and Vk = (vij )(pâˆ’1)Ã—(pâˆ’1) ,
1
n
Ï€
T
âˆ’kXT HkXÏ€âˆ’k. Further denote
Wk,Ak = diag{Ï‰k,Ak
}, Wk,Ac
k
= diag{Ï‰k,Ac
k
}, Vk,21 = (vij )iâˆˆAc
k
,jâˆˆAk
, Vk,11 = (vij )iâˆˆAk,jâˆˆAk
,
and Î¸k =



V
âˆ’1
k,11Wk,Ak



âˆž
. We then have the following selection property.
Theorem 5.6 (Selection Consistency) Suppose that, for each node k, Vk,11 is invertible,
and p
(rmax âˆ¨ q âˆ¨ fn)/n+c1 kÏ€k1 â‰¤
q
c
2
1
kÏ€k
2
1 + min(Ï†
2
0
/64, Î¶(4 âˆ’ Î¶)âˆ’1kÏ‰kkâˆ’âˆž/Î¸k)/(C2|Ak|).
Further assume that there exists a positive constant Î¶ âˆˆ (0, 1) such that min
jâˆˆAk
|Î³kj | >
2Î»kÎ¸k
n(2âˆ’Î¶)
and



Wâˆ’1
k,Ac
k
Vk,21V
âˆ’1
k,11Wk,Ak



âˆž
< 1âˆ’Î¶. Under Assumptions A, B0
, C0
, and D, there exists a
2SPLS estimator Î³Ë†k satisfying that, with probability at least 1âˆ’e
âˆ’C5hn+log(4pq) âˆ’e
âˆ’fn+log(p)
for some constant C5 > 0, AË†
k = Ak with AË†
k = {j : Ë†Î³kj 6= 0, j 6= k}.
6. Simulation Studies
We conducted simulation studies to compare 2SPLS with the adaptive lasso based algorithm
(AL) by Logsdon and Mezey (2010), and the sparsity-aware maximum likelihood algorithm
(SML) by Cai et al. (2013). To investigate whether it is necessary to select instrumental
variables at the first stage as proposed in Belloni et al. (2012), Lin et al. (2015), and Zhu
(2015), we also consider a method which replaces the ridge regression at the first stage
of 2SPLS with the adaptive lasso, that is, the two-stage adaptive lasso (2SAL) method.
Both acyclic networks and cyclic networks were simulated, each involving 300 endogenous
variables. Each endogenous variable was simulated to have, on average, one regulatory
effect for sparse networks, or three regulatory effects for dense networks. The regulatory
effects were independently simulated from a uniform distribution over (âˆ’1, âˆ’0.5) âˆª (0.5, 1).
To allow the use of AL and SML, every endogenous variable in the same network was
9
Chen, Ren, Zhang, and Zhang
simulated to have the same number (either one or three) of nonzero exogenous effects
(EEs) by the exogenous variables, with all effects equal to one. Each exogenous variable
was simulated to take values 0, 1 and 2 with probabilities 0.25, 0.5 and 0.25, respectively,
emulating genotypes of an F2 cross in a genetical genomics experiment. All error terms
were independently simulated from N(0, 0.1
2
), and the sample size n varied from 100 to
1, 000. For each network setup, we simulated 100 data sets and applied all four algorithms
to calculate the power and false discovery rate (FDR).
For inferring acyclic networks, the power and FDR of the four different algorithms are
plotted in Figure 1. 2SPLS has greater power than the other three algorithms to infer both
sparse and dense acyclic networks when the sample size is small or moderate. When the
sample size is large, 2SPLS, SML, and 2SAL are comparable for constructing both sparse
and dense acyclic networks. In any case, AL has much lower power than other methods.
Specifically, AL provides power as low as under 10% when the sample size is small, and its
power is still under 50% even when the sample size increases to 1, 000. On the other hand,
2SPLS provides power over 80% for small sample sizes, and over 90% for moderate to large
sample sizes.
As shown in Figure 1, 2SPLS controls the FDR under 20% except for the case which has
three available EEs with small sample sizes (n = 100). Although SML controls the FDR as
low as under 5% for sparse acyclic networks when the sample sizes are large, it reports large
FDRs when the sample sizes are small. For example, when the sample sizes are under 200,
SML reports FDR over 40% for dense acyclic networks. In general, both 2SPLS and SML
outperform AL and 2SAL in terms of FDR. Only in the case when inferring sparse acyclic
networks with one available EE from data sets of moderate or large sample sizes, AL and
2SAL report FDR lower than 2SPLS.
Plotted in Figure 2 are the power and FDR of the four different algorithms when inferring
cyclic networks. Similar to the results on acyclic networks, 2SPLS has greater power than
SML and AL across all sample sizes and has lower FDR when the sample size is small.
2SPLS has greater power than 2SAL in most scenarios and has much lower FDR than
2SAL except for the case when inferring sparse cyclic networks from data sets of large
sample sizes. SML provides power competitive to 2SPLS for sparse cyclic networks, but
its power is much lower than that of 2SPLS for dense cyclic networks. Similar to the case
of acyclic networks, SML reports much higher FDR for inferring dense networks from data
sets with small sample sizes though it reports small FDR when the sample sizes are large.
2SAL reports the highest FDR, especially for networks with three available EEs.
Although not performing as well as 2SPLS, 2SAL reports competitive power to SML
when inferring either acyclic or cyclic networks. For the acyclic sparse network with one
EE, 2SAL can control FDR at a similar level to 2SPLS because each endogenous variable
may be associated to a very small set of exogenous variables in (3). However, we observed
high FDR of 2SAL in Figure 1.b for the acyclic sparse network with three EEs which triples
the average number of exogenous variables associated to each endogenous variable. The
similar phenomenon of 2SAL appears in Figure 2.b for the cyclic sparse networks. The
dense networks also triple the average number of regulatory effects for each endogenous
variable, which implies an increased number of exogenous variables associated to each endogenous variable in (3). Therefore, we unsurprisingly observed even higher FDR of 2SAL
in Figure 1.d and Figure 2.d, where the FDR is over 0.8. In summary, variable selection at
10
Two-Stage Penalized Least Squares
a. Power of Sparse Networks b. FDR of Sparse Networks
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
Power
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
FDR
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
c. Power of Dense Networks d. FDR of Dense Networks
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
Power
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
FDR
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
Figure 1: Performance of 2SPLS, AL, SML, and 2SAL when identifying regulatory effects
in acyclic networks with one EE or three EEs.
the first stage seems work well when each endogenous variable is associated to a small set
of exogenous variables in (3), but may compromise the identification of regulatory effects
at the second stage when the number of exogenous variables associated to an endogenous
variable increases.
Both 2SPLS and 2SAL are two-stage methods developed based on the limited-information
model (2), instead of the full-information model used by SML, leading to fast computation
and potential implementation of parallel computing. To demonstrate the computational
advantage of 2SPLS and 2SAL, we recorded the computing time of all algorithms when
inferring the same networks from small data sets (n = 100). Each algorithm analyzed the
same data set using only one CPU in a server with Quad-Core AMD OpteronTM Processor
8380. Reported in Table 1 are the running times of all four algorithms for inferring different
networks. AL is the fastest although it performs with the least power. The running time of
2SPLS usually doubles or triples that of AL, but the computation time of 2SAL generally
triples that of 2SPLS because 2SAL employed K-fold cross-validation to choose the tuning
11
Chen, Ren, Zhang, and Zhang
a. Power of Sparse Networks b. FDR of Sparse Networks
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
Power
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
FDR
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
c. Power of Dense Networks d. FDR of Dense Networks
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
Power
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
0.0
0.2
0.4
0.6
0.8
1.0
100 200 400 600 800 1000
Sample Size
FDR
2SPLS, 1 EE
2SPLS, 3 EEs
AL, 1 EE
AL, 3 EEs
SML, 1 EE
SML, 3 EEs
2SAL, 1 EE
2SAL, 3 EEs
Figure 2: Performance of 2SPLS, AL, SML, and 2SAL when identifying regulatory effects
in cyclic networks with one EE or three EEs.
parameter at the first stage. SML is the slowest algorithm which generally takes more than
40 times longer than 2SPLS to infer different networks. In particular, SML is almost 200
times slower than 2SPLS when inferring acyclic sparse networks.
Acyclic Cyclic
Sparse Dense Sparse Dense
1 EE 3 EEs 1 EE 3 EEs 1 EE 3 EEs 1 EE 3 EEs
2SPLS 1303 1332 1127 1112 1297 1337 1125 1165
AL 405 652 404 637 443 659 430 781
SML 258875 195739 58509 43118 49393 58716 67949 68081
2SAL 3239 4726 3398 5357 3135 4681 3686 5651
Table 1: The running time (in seconds) of inferring networks from a data set with n = 100.
12
Two-Stage Penalized Least Squares
The robustness of 2SPLS was also evaluated from different aspects: (i) its robustness to
different noise levels by doubling or even quadrupling the error variance; (ii) its robustness to
non-normality of error terms by simulating errors sampled from a t-distribution, i.e., t(3);
(iii) its robustness to uncertainty in the connections between exogenous and endogenous
variables by simulating three exogenous effects for each endogenous variable (to emulate the
genetical genomics experiment, the three exogenous variables are correlated with correlation
coefficients at 0.8, and have effects at 1, 0.5, and -0.3, respectively) but including only
one exogenous variable with the strongest estimated effects for each endogenous variable;
(iv) its robustness to existence of hub nodes by simulating networks with six hub nodes
having five regulatory effects on average while other endogenous variables having on average
one regulatory effect for sparse networks, or three regulatory effects for dense networks.
All networks include 300 endogenous variables, and the networks with errors following
N(0, 0.01) are the same as those shown in Figure 1. As shown in Figure 3, the 2SPLS
method demonstrated robust power while the FDR was slightly affected when the error
variance doubled. When the error variance quadrupled, a higher FDR was reported as
expected. With errors from t(3), we observed similar power and slightly increased FDR
of 2SPLS, which confirms the robustness of 2SPLS to non-normality. The uncertainty in
the connections between exogenous and endogenous variables had almost no effect on the
power of 2SPLS, and only slightly increased the FDR in constructing sparse networks. The
existence of hub nodes rarely affected construction of dense networks, but decreased the
FDR in constructing sparse networks. Overall, the performance of 2SPLS is remarkable in
demonstrating robustness under a variety of realistic data structures.
7. Real Data Analysis
We analyzed a yeast data set with 112 segregants from a cross between two strains BY4716
and RM11-la (Brem and Kruglyak, 2005). A total of 5,727 genes were measured for their
expression values, and 2,956 markers were genotyped. Each marker within a genetic region
(including 1kb upstream and downstream regions) was evaluated for its association with
the corresponding gene expression, yielding 722 genes with marginally significant cis-eQTL
(p-value < 0.05). The set of cis-eQTL for each gene was filtered to control a pairwise
correlation under 0.90, and then further filtered to keep up to three cis-eQTL which have
the strongest association with the corresponding gene expression.
With 112 observations of 722 endogenous variables and 732 exogenous variables, we applied 2SPLS to infer the gene regulatory network in yeast. The constructed network includes
7,300 regulatory effects in total. To evaluate the reliability of constructed gene regulations,
we generated 10,000 bootstrap data sets (each with n = 112) by randomly sampling the
original data with replacement, and applied 2SPLS to each data set to infer the gene regulatory network. Among the 7,300 regulatory effects, 323 effects were repeatedly identified
in more than 80% of the 10,000 data sets, and Figure 4 shows the three largest subnetworks
formed by these 323 effects. Specifically, the largest subnetwork consists of 22 endogenous
variables and 26 regulatory effects, the second largest one includes 14 endogenous variables
and 18 regulatory effects, and the third largest one has 11 endogenous variables and 16
regulatory effects.
13
Chen, Ren, Zhang, and Zhang
a. Power of Sparse Networks b. FDR of Sparse Networks
0.5
0.6
0.7
0.8
0.9
1.0
100 200 400 600 800 1000
Sample Size
Power
error~N(0,0.01)
error~N(0,0.02)
error~N(0,0.04)
error~0.1*t(3)
uncertainty in EEs
existence of hub nodes 0.0
0.1
0.2
0.3
0.4
0.5
100 200 400 600 800 1000
Sample Size
FDR
error~N(0,0.01)
error~N(0,0.02)
error~N(0,0.04)
error~0.1*t(3)
uncertainty in EEs
existence of hub nodes
c. Power of Dense Networks d. FDR of Dense Networks
0.5
0.6
0.7
0.8
0.9
1.0
100 200 400 600 800 1000
Sample Size
Power
error~N(0,0.01)
error~N(0,0.02)
error~N(0,0.04)
error~0.1*t(3)
uncertainty in EEs
existence of hub nodes 0.0
0.1
0.2
0.3
0.4
0.5
100 200 400 600 800 1000
Sample Size
FDR
error~N(0,0.01)
error~N(0,0.02)
error~N(0,0.04)
error~0.1*t(3)
uncertainty in EEs
existence of hub nodes
Figure 3: Performance of 2SPLS in robustness tests when identifying regulatory effects in
acyclic networks with one EE.
A gene-enrichment analysis with DAVID (Huang et al., 2009) showed that the three
subnetworks are enriched in different gene clusters (controlling p-values from Fisherâ€™s exact
tests under 0.01). A total of six gene clusters are enriched with genes from the first subnetwork, and four of them are related to either methylation or methyltransferase. Six of 22
genes in the first subnetwork are found in a gene cluster which is related to none-coding
RNA processing. The second subnetwork is enriched in nine gene clusters. While three of
the clusters are related to electron, one cluster includes half of the genes from the second
subnetwork and is related to oxidation reduction. The third subnetwork is also enriched in
nine different gene clusters, with seven clusters related to proteasome.
A total of 18 regulations were constructed from each of the 10,000 bootstrap data sets,
and are shown in Figure 5. There are seven pairs of genes which regulate each other. It
is interesting to observe that all regulatory genes up-regulate the target genes except two
genes, namely, YCL018W and YEL021W.
14
Two-Stage Penalized Least Squares
a.
b. c.
Figure 4: Three gene regulatory subnetworks in yeast (the dotted, dashed, and solid arrows
implied that the corresponding regulations were constructed respectively from
over 80%, 90%, and 95% of the bootstrap data sets).
Figure 5: The yeast gene regulatory subnetworks constructed in each of 10,000 bootstrap
data sets (with arrow- and bar-headed lines implying up and down regulations,
respectively).
15
Chen, Ren, Zhang, and Zhang
8. Discussion
In a classical setting with small numbers of endogenous/exogenous variables, constructing a
system of structural equations has been well studied since Haavelmo (1943, 1944). Anderson
and Rubin (1949) first proposed to estimate the parameters of a single structural equation
with the limited information maximum likelihood estimator. Later, Theil (1953a,b, 1961)
and Basmann (1957) independently developed the 2SLS estimator, which is the simplest
and most common estimation method for fitting a system of structural equations. However,
genetical genomics experiments usually collect data in which both the number of endogenous
variables and the number of exogenous variables can be very large, invalidating the classical methods for building gene regulatory networks. It is noteworthy that, although each
structural equation modeling gene regulation has few exogenous variables, the genome-wide
gene regulatory network consists of a large number of structural equations and therefore
has a large number of exogenous variables.
The instrumental variables view of 2SLS sheds light on the consistency of 2SLS estimators which is guaranteed by good estimation of the conditional expectations of endogenous
variables given exogenous variables. For large systems, we proposed to estimate these conditional expectations via ridge regression coupled with GCV so as to address possible overfitting issues brought by a large number of exogenous variables. We obtained approximately
optimal estimation of these conditional expectations at the first stage. At the second stage,
we could adopt results from high-dimensional variable selection, e.g., Fan and Li (2001),
Zou (2006), Zhang (2010), and Huang et al. (2011), to consistently identify and further
estimate the regulatory effects of the endogenous variables. As a high-dimensional extension of the classical 2SLS method, the 2SPLS method is also computationally fast and easy
to implement. As shown in constructing a genome-wide gene regulatory network of yeast,
the high computational efficiency of 2SPLS allows us to employ the bootstrap method to
calculate the p-values of the regulatory effects.
Our simulation studies show a seemingly counterintuitive result that our moment-based
method 2SPLS provides higher power than the likelihood-based method SML, because the
maximum likelihood method is usually the most efficient method, and dominates moment
methods. However, as evidenced in Bollen (1996) and Kennedy (1985) (p.134), 2SLS can
perform better than the maximum likelihood method in small samples. Furthermore, SML
is not a pure likelihood method but rather a penalized likelihood method, and 2SPLS is not
a pure moment method but rather a penalized moment method. Therefore, the theoretical
advantage of likelihood methods over moment methods may not carry over to comparing
penalized likelihood methods versus penalized moment methods. In fact, SML uses an L1
penalty to penalize nonzero regulatory effects, but 2SPLS employs an L2 penalty on the
regression coefficients of the reduced models at the first stage and an L1 penalty on the
regulatory effects at the second stage. We conjecture that the different choice of penalty
terms may also distinguish the two different methods as shown in the advantage of the
elastic net (Zou and Hastie, 2005) over lasso (Tibshirani, 1996).
Although applicable to diverse fields, our development of 2SPLS is motivated by constructing gene regulatory networks using genetical genomics data. The algorithm is applicable to any population-based studies with either experimental crosses or natural populations.
Assumption A means that each gene under investigation has at least one unique polymor16
Two-Stage Penalized Least Squares
phism from its cis-eQTL, which can be detected with classical eQTL mapping methods, e.g.,
Kendziorski et al. (2006), Gelfond et al. (2007), and Jia and Xu (2007). Trans-eQTL (i.e.,
eQTL outside the regions of their target genes) hold the key to our understanding of gene
regulation because their indirect regulations are likely caused by interactions among genes.
When the gene regulatory network is modeled with a system of structural equations, classical eQTL mapping methods essentially identify both cis-eQTL and trans-eQTL involved
in each reduced-form equation in the reduced model (3). Nonetheless, it is challenging, if
not impossible, to recover a large system from the reduced model.
An alternative strategy to construct the whole system is to build undirected graphs first
(Spirtes et al., 2001; Shipley, 2002; de la Fuente et al., 2004) and then locally orient the edges
in the graphs (Aten et al., 2008; Neto et al., 2008). While constructing a small network is
much easier and more robust than constructing a large system, we here intend to construct
large networks, such as whole-genome gene regulatory networks from genetical genomics
data. Furthermore, application of the alternative strategy is contingent on whether the
underlying system is composed of unconnected subsystems, because ignoring the regulatory
effects from other genes outside a subset of genes may lead to false regulatory interaction
(Neto et al., 2008; de la Fuente et al., 2004). Instead, 2SPLS allows to construct a subset
of structural equations inside the whole system, ignoring many other structural equations.
Therefore, we can apply 2SPLS to investigate the interactive regulation among a subset of
genes as well as how these genes are regulated by others.
It is evidenced in different species that effects of trans-eQTL are weaker than those
of cis-eQTL and trans-eQTL are more difficult to identify than cis-eQTL (Schadt et al.,
2003; Dixon et al., 2007). On the other hand, a system of structural equations modeling
genome-wide gene regulation may induce a large number of trans-eQTL to each reducedform equation in (3). While constructing the system is contingent on the accuracy of
predicting each endogenous variable on the basis of the corresponding reduced-form equation in (3), the weak effects of a large number of trans-eQTL privilege the use of ridge
regression at the first stage of 2SPLS for constructing gene regulatory networks (Frank and
Friedman, 1993). By comparing 2SPLS with 2SAL, our simulation studies demonstrated
the superiority of using ridge regression over the adaptive lasso at the first stage. In fact,
when some genes have a relatively large number of trans-eQTL, selecting variables at the
first stage may compromise the identification of regulatory effects at the second stage.
