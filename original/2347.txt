Markov blanket (Mb) and Markov boundary (MB) are two key concepts in Bayesian networks
(BNs). In this paper, we study the problem of Mb and MB for multiple variables. First, we show
that Mb possesses the additivity property under the local intersection assumption, that is, an Mb of
multiple targets can be constructed by simply taking the union of Mbs of the individual targets and
removing the targets themselves. MB is also proven to have additivity under the local intersection
assumption. Second, we analyze the cases of violating additivity of Mb and MB and then put
forward the notions of Markov blanket supplementary (MbS) and Markov boundary supplementary
(MBS). The properties of MbS and MBS are studied in detail. Third, we build two MB discovery
algorithms and prove their correctness under the local composition assumption. We also discuss
the ways of practically doing conditional independence tests and analyze the complexities of the
algorithms. Finally, we make a benchmarking study based on six synthetic BNs and then apply
MB discovery to multi-class prediction based on a real data set. The experimental results reveal
our algorithms have higher accuracies and lower complexities than existing algorithms.
Keywords: Markov blanket, Markov boundary, Markov blanket supplementary, Markov boundary
supplementary, Bayesian network
1. Introduction
Bayesian networks (BNs) are graphical structures used to represent the probabilistic relations
among a large number of variables and to make the associated probabilistic inferences (Neapolitan,
2004; Pearl, 1988). In recent years, BNs have become one of the most powerful tools in encoding
uncertain expert knowledge in expert systems (Daly et al., 2011; Parviainen and Koivisto, 2013) and
also deeply influenced on many other actual domains such as medical diagnosis, financial analysis,
bioinformatics, and industrial applications (Zhang and Guo, 2006).
∗. Corresponding Author.
⃝c 2018 Xu-Qing Liu and Xin-Sheng Liu.
License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at
http://jmlr.org/papers/v19/14-033.html.
Liu and Liu
As two important concepts in BNs, Markov blanket (Mb) and Markov boundary (MB) play a
key role in feature selection (FS; Fu and Desmarais, 2010; Pellet and Elisseeff, 2008; Aliferis et al.,
2010a,b). Mathematically, Pearl (1988, pp. 218–221) showed the conditional probability for the
target given other variables can be replaced by the MB as the conditional set. Pellet and Elisseeff
(2008, pp. 1299, 1302) proved that an MB is the theoretically optimal set of features. Further,
under certain assumptions about the learner and the loss function, MB is the solution to the variable
selection problem (Tsamardinos and Aliferis, 2003; Statnikov et al., 2013).
So far most authors have focused on the problem of Mb or MB for a single variable. In this paper,
we consider the problem of Mb and MB for multiple variables. This occurs if, for example, one
wants to compute the joint probability of two or more variables conditioned on all other variables.
The basic question for Mb of multiple variables is whether the additivity property holds, that is, can
an Mb of multiple variables be constructed by simply taking the union of the Mbs of the individual
variables and removing the target variables themselves? The same question is for MB. Further, if
the additivity property is violated in some situation, how can we do it?
In the literature, there have been lots of MB discovery algorithms, such as the Koller-Sahami
(KS) algorithm (Koller and Sahami, 1996), the grow-shrink (GS) algorithm (Margaritis and Thrun,
1999, 2000), the incremental association Markov boundary (IAMB) algorithm (Tsamardinos et al.,
2003) and its several variants, the HITON algorithm (Aliferis et al., 2003), the max-min Markov
boundary (MMMB) algorithm (Tsamardinos et al., 2006), the parents and children based Markov
boundary (PCMB) algorithm and KIAMB algorithms (Pena et al. ˜ , 2007), the BFMB algorithm (Fu and
Desmarais, 2007), the algorithmic framework called generalized local learning (GLL, Aliferis et al.,
2010a), and some others (Fu and Desmarais, 2010; Schluter ¨ , 2014). For a single target variable,
most of these algorithms are efficient to seek an approximate MB; for multiple target variables, if
simply regarding them as a multivariate variable, these algorithms seem to be feasible. However,
this will lead to low accuracies and high computational complexities. Hence, it is necessary to
design more efficient MB discovery algorithms for multiple variables.
The remainder of this paper is organized as follows. Section 2 presents necessary preliminaries
and the motivations of this paper. Subsection 3.1 shows additivity of Mb and MB under the local
intersection assumption. In Subsection 3.2, we first analyze when additivity is violated and then put
forward the notions of Markov blanket supplementary (MbS) and Markov boundary supplementary
(MBS). The properties of MbS and MBS are studied detailedly. In Section 4, we design two MB
discovery algorithms for multiple variables, and prove their correctness under the local composition
assumption. In addition, we discuss the ways of practically doing conditional independence (CI)
tests and analyze the complexities of the algorithms. Section 5 makes a benchmarking study based
on six synthetic BNs, and Section 6 considers a practical application. The experimental results
show the superiority of our algorithms with higher accuracies and lower complexities than existing
algorithms. Section 7 concludes this paper and presents three remarks.
2. Preliminaries and Motivations
In the paper, we denote a variable and its value by upper-case and lower-case letters in italics
(e.g., X, x), a set of variables and its value by upper-case and lower-case bold letters in italics (e.g.,
X, x). The difference between X and Y is denoted by X \ Y. For brevity, we write (X \ Y) \ Z as
X \ Y \ Z. In addition, we use |X| to denote the number of variables involved in X.
2
Markov Blanket and Markov Boundary of Multiple Variables
2.1 Preliminaries
Suppose we have a joint probability distribution P over V ≜ {X1, · · · , Xp} and a directed acyclic
graph (DAG) G with the variables in V as its nodes. We say (G, P) satisfies the Markov condition
if every X ∈ V is conditionally independent of its nondescendants given its parents; Further, (G, P)
is called a Bayesian network (BN) if it satisfies the Markov condition; Furthermore, (G, P) satisfies
the faithfulness condition if, based on the Markov condition, G entails all and only conditional
independences (CIs) in P (Pearl, 1988; Neapolitan, 2004).
We write X y Y | Z (X ̸y Y | Z), if X and Y are conditionally independent (dependent) given
Z with respect to P. The following properties describe the relations among CI statements (Pearl,
1988; Pena et al. ˜ , 2007; Statnikov et al., 2013). For any X, Y, Z,W ⊆ V, we have (i) symmetry:
X y Y | Z is equivalent to Y y X | Z; (ii) decomposition: X y Y ∪ W | Z implies X y Y | Z and
X y W | Z; (iii) weak union: X y Y ∪W | Z implies X y Y | Z ∪W; (iv) contraction: X y Y | Z ∪W
and X y W | Z imply X y Y ∪ W | Z; (v) self-conditioning: X y Y | Y ∪ Z. Further, if P is strictly
positive, then besides (i)∼(v) we also have (vi) intersection: X y Y | Z ∪ W and X y W | Z ∪ Y
imply X y Y ∪ W | Z. Furthermore, if P is faithful to a DAG G, then besides (i)∼(vi) we also have
(vii) composition: X y Y | Z and X y W | Z imply X y Y ∪ W | Z.
Among these properties, intersection and composition are two global ones. Statnikov et al.
(2013, p. 504) provided a relaxed version for composition called local composition: one says T ⊆ V
satisfies the local composition property, if T y X | Z and T y Y | Z imply T y X ∪ Y | Z for any
X, Y, Z ⊆ V \ T. We will provide a relaxed version for the intersection property.
Conditional mutual information (CMI) is one of the basic tools for testing CIs. Denote the CMI
between X and Y conditioned on Z by I(X; Y | Z). Then I(X; Y | Z) ⩾ 0, with equality holding if
and only if X y Y | Z (Zhang and Guo, 2006). For a practical problem, we cannot access to the true
CMI; instead, we use its empirical estimate, denoted by ID(X; Y | Z), based on the data D (Cheng
et al., 2002). Note that ID(X; Y | Z) ⩾ 0 also holds for any X, Y, Z ⊆ V.
The chain rule for CMI (Cover and Thomas, 2006) is useful to prove the main results of this
paper: I(X; Y1 ∪ Y2 | Z) = I(X; Y1 | Z) + I(X; Y2 | Z ∪ Y1) holds for any four sets of variables X, Y1,
Y2, and Z from V.
Another notion closely related to CI is d-separation (Pearl, 1988, p. 117). For a DAG G over
V, letting X, Y, Z ⊆ V be disjoint, we say Z d-separates X and Y if it blocks every path between
X and Y, and if this is the case we write X ⊥ Y | Z. Here, Z blocking a path c means that c has a
head-to-tail node or a tail-to-tail node belonging to Z, or that c has a head-to-head node C such that
C and its all descendants are not in Z. As well known, X ⊥ Y | Z ⇒ X y Y | Z, if (G, P) is a BN
(Neapolitan, 2004, p. 74). This implication provides a convenient way of identifying CIs.
For example, consider a BN with the graph presented in Figure 1 as its DAG. It follows that: X2
and X8 are d-separated by {X4, X5}, meaning X2 ⊥ X8 | {X4, X5} and thus X2 y X8 | {X4, X5}; X3 and
X4 are d-separated by Ø, meaning X3 ⊥ X4, so X3 y X4. Note that these two probabilistic CIs can
not be directly derived from the Markov condition.
In what follows, the concepts of Mb and MB are presented. They are a direct extension of Mb
and MB for a single target variable (Pearl, 1988, p. 97; Neapolitan, 2004, pp. 108–109): an Mb
of T is a set of variables shielding T from all other variables, so it carries all information of T that
cannot be obtained from other variables, while an MB is a minimal Mb.
Definition 1 Let T ⊆ V and M ⊆ V\T. We call M a Markov blanket (Mb) of T if T y V\ M\T | M.
Further, a Markov boundary (MB) of T is any Mb such that none of its proper subsets is an Mb.
3
Liu and Liu
When |T| = 1, the following results are well known in the literature (Pearl, 1988; Neapolitan,
2004; Statnikov et al., 2013): (a) if (G, P) is a BN, then for T ∈ V the set of its all parents, children,
and spouses is an Mb of T (denoted by MT ); (b) if P satisfies the intersection property, then T has
a unique MB; (c) if (G, P) satisfies the faithfulness condition, then MT is the unique MB of T.
Consider again the BN with the graph presented in Figure 1 as its DAG. In this BN, it is seen
that MX4 ≜ {X2, X6, X3} is an Mb of X4; further, MX4
is the unique MB of X4 if the faithfulness
condition is satisfied. Similarly, MX2 ≜ {X4, X5} is the unique MB of X2 under the faithfulness
condition.
The above result (b) points out that if the uniqueness of MB is violated, then the intersection
property must be violated. Lemeire (2007) provided a case of violating intersection called information equivalence: X and Y are called information equivalent with respect to T if T ̸y X, T ̸y Y,
T y X | Y, and T y Y | X. A related notion is conditional information equivalence (Lemeire et al.,
2012; Statnikov et al., 2013): X and Y are called to be conditionally information equivalent with
respect to T given Z ⊆ V \ X \ Y \ T, if T ̸y X | Z, T ̸y Y | Z, T y X | Y ∪ Z, and T y Y | X ∪ Z.
Lemeire et al. (2012, pp. 1309–1311) showed that (conditional) information equivalence is one of
the two major cases in which adjacency faithfulness is violated. Here, the adjacency faithfulness
condition (Ramsey et al., 2006; Lemeire et al., 2012) is defined as: if X and Y are adjacent, then
X ̸y Y | Z for any Z ⊆ V \ {X, Y}. Statnikov et al. (2013, p. 503) provided a local version for
adjacency faithfulness by focusing on a specific variable.
Here, we employ the information flow metaphor (Cheng et al., 2002) to intuitively explain
information equivalence: we can view a BN as a network of information channels, where each
node is a valve that is either active or inactive; the valves are connected by information channels;
information can flow through an active valve but not an inactive one; instantiating a node means this
valve becomes inactive. We extend this metaphor by viewing a clique of one or more nodes as a
valve. In this sense, a CI relation X y Y | Z means all the channels between X and Y are cut off by Z
and thus the information between X and Y can not flow once Z becomes inactive. When information
equivalence occurs, we further extend this information flow metaphor as follows: if X and Y are
information equivalent with respect to T given Z, then there exists an information equivalent valve,
denoted by δX,Y; T | Z, which connects T and X and connects T and Y; δX,Y; T | Z is active when and
only when both X and Y are active. Then, the relation “X and Y are information equivalent with
respect to T given Z” can be presented in Figure 2.
Information equivalence represents all the possible situations leading to the nonuniqueness of
MB. In fact, we can show the following result, which indicates that violating the uniqueness of MB
implies the presence of information equivalence. The proof is presented in Section B.
Lemma 1 The intersection property holds if and only if no information equivalence occurs.
Markov Blanket and Markov Boundary of Multiple Variables
114 The following lemma presents the well-known chain rule for CMI (Cover & Thomas, 2006,
115 Theorem 2.5.2), which is very useful to prove the main results of this paper.
116 Lemma 1 (Chain Rule for CMI) The formula I(X; Y1 ∪ Y2 |Z) = I(X; Y1 |Z) + I(X; Y2 |Z ∪ Y1) holds
117 for any four sets of variables X, Y1, Y2, and Z from V. The same formula also holds for ID(·).
118 ❉ Directed Separation and Directed Connection. The notions of directed separation (D-separation)
119 and directed connection (D-connection) provide a convenient way of identifying the CIs in
120 a BN: For the DAG G, X and Y are d-separated by Z, denoted by X ⊥ Y |Z, if every chain
121 between X and Y, saying c, is blocked by Z (Pearl, 1988, p. 117; Neapolitan, 2004, p. 72).
122 Here, Z blocking c means either (i) c has a serial node (head-to-tail) or a diverging node
123 (tail-to-tail) belonging to Z, or (ii) c has a converging node C (head-to-head) such that C and
124 its all descendants are not in Z. Further, X and Y are d-connected by Z, denoted by X 6⊥ Y |Z, if
125 X and Y are not d-separated by Z. For example, considering the DAG presented in (1): X2 and
126 X8 are d-separated by {X4, X5}, meaning X2 ⊥ X8 | {X4, X5}; X4 and X5 are d-separated by X2,
127 meaning X4 ⊥ X5 | X2; X3 and X4 are d-separated by Ø but d-connected by X6 or X7, meaning
128 X3 ⊥ X4 but X3 6⊥ X4 | X6 and X3 6⊥ X4 | X7.
X1

X2
uu

X4

X3
 X5
~~
X6
vv (
X7 X8
129 (1)
X1

X2
uu

X4

X3
 X5
}}
X6
vv (
X7 X8
Figure 1:
Figure 1: A simple DAG used to illustrate d-separation.
4
Markov Blanket and Markov Boundary of Multiple Variables 147 under the local intersection assumption. The proof is presented in Appendix B.
148 Lemma 2 For T ⊆ V, assume the type-II local condition in Definition 2 holds. Then T has a unique Mb.
149 To facilitate the identification of information equivalence, Lemeire (2007) introduced the notions
150 of target partition (T-partition) and equivalent partition (E-partition), and then provided a relation
151 among information equivalence, T-partition, and E-partition.
4
125 is violated. Here, the adjacency faithfulness condition (Ramsey et al., 2006; Lemeire et al., 2012) is
126 defined as: if X and Y are adjacent, then X 6y Y |Z for any Z ⊆ V \ {X,Y}.
127 Here, we employ the metaphor that Cheng et al. (2002) used: we can view a BN as a network
128 of information channels, where each node is a valve that is either active or inactive; the valves
129 are connected by information channels; information can flow through an active valve but not an
130 inactive one; instantiating a node means this valve becomes inactive. We extend this metaphor by
131 viewing a clique of one or more nodes as a valve.
Z
X T Y
δX,Y;T |Z
132
133 Information equivalence represents all the possible situations leading to the nonuniqueness of
134 Mb. In fact, we can show the following result, which indicates that violating the uniqueness of Mb
135 implies the presence of information equivalence. The proof is presented in Appendix B.
136 Lemma 1 The intersection property holds if and only if no information equivalence occurs.
137 By analyzing the proof of Lemma 1, we present a relaxed version for the intersection property
138 called local intersection as follows.
139 Definition 2 (Local Intersection) Letting T ⊆ V, we say T satisfies the local intersection property, if the
140 following two types of local conditions hold simultaneously: (i) type-I local condition: in the case of |T| > 2,
4
Figure 2: An intuitive illustration for information equivalence.
By analyzing the proof of Lemma 1, we present a relaxed version for the intersection property
called local intersection as follows.
Definition 2 (Local Intersection) Letting T ⊆ V, we say T satisfies the local intersection property,
if the following two types of local conditions hold simultaneously: (i) type-I local condition: in the
case of |T| ⩾ 2, for any disjoint T1, T2 ⊆ T, there are no disjoint X, Y ⊆ V \ T such that T1 and
T2 are information equivalent with respect to X conditioned on Y; and (ii) type-II local condition:
there are no disjoint X, Y, Z ⊆ V \ T such that X and Y are information equivalent with respect to
T conditioned on Z.
Clearly, intersection implies local intersection but not vice versa, because the former requires
no any information equivalence while the latter only requires no information equivalence between
the targets and the remaining variables. Here, we give a lemma concerning the uniqueness of MB
under the local intersection assumption. The proof is presented in Appendix B.
Lemma 2 For T ⊆ V, assume the type-II local condition defined in Definition 2 holds. Then T has
a unique MB.
To facilitate the identification of information equivalence, Lemeire (2007) ever introduced the
notions of target partition (T-partition) and equivalent partition (E-partition), and then provided a
relation among information equivalence, T-partition, and E-partition.
• T-partition: The domain, Xdom, of X can be partitioned into disjoint subsets X
(k)
dom for which
P(T | x) is the same for all x ∈ X
(k)
dom. This is called the T-partition of Xdom with respect to T.
• E-partition: A relation R ⊂ X ⊗ Y defines an E-partition in Ydom to a partition of Xdom, if: (i)
¬(x2Ry1
) holds for any x1, x2 ∈ Xdom belonging to different partitions and for any y1 ∈ Ydom
with x1Ry1
; and (ii) for every X
(k)
dom, there exist x1 ∈ X
(k)
dom and y1 ∈ Ydom such that x1Ry1
.
• Relation among information equivalence, T-partition, and E-partition: If T̸y X and T yY | X,
then T y X | Y (meaning X and Y are information equivalent with respect to T) if and only if
the relation xRy defined by P(x, y) > 0 with x ∈ Xdom and y ∈ Ydom defines an E-partition in
Ydom to the T-partition of Xdom with respect to T.
The graph shown in Figure 3, originally presented by Statnikov and Aliferis (2010), makes an
intuitive illustration on T-partition and E-partition. As seen, {1, 2} and {3} constitute the T-partition
of Adom ≜ {1, 2, 3} with respect to C; {1, 2} and {3} are the E-partition of Bdom ≜ {1, 2, 3} to the
T-partition of Adom, Therefore, A and B are information equivalent with respect to C if C ̸y A, since
C y B | A holds inherently because of the Markov condition.
5
Liu and Liu (
3
185 is the only parent of C and (ii) B is a nondescendant of C.
B A o /C /D
1 1 o
}}
(
1
(

2 2
a
66
o 1
2
66
(
3 3 o
66
(
2
3
66
CC
186 (2)
y1 ∈ Ydom such that x1Ry1
171 .
172 By Lemeire (2007, p. 99), E-partition can be intuitively explained as follows: for an E-partition,
every partition X
(k)
dom corresponds to a partition Y
(`)
dom 173 . More specifically, if an element of Ydom is
174 related to an element of a partition of Xdom, then it is not related to an element of another partition;
175 and each partition of Xdom has at least one element that is related to a partition of Ydom.
176 Lemma 3 If T 6y X and T y Y | X, then T y X | Y (meaning X and Y contain equivalent information about
177 T) if and only if the relation xRy defined by P(x, y) > 0 with x ∈ Xdom and y ∈ Ydom defines an E-partition
178 in Ydom to the T-partition of Xdom with respect to T.
179 This lemma characterizes exactly when the intersection property (and thus uniqueness of Mb)
180 is violated. Also, it gives a direct method for justifying if two sets of variables contain equivalent
181 information about the target. The DAG shown in (2), originally presented by Statnikov & Aliferis
(2010), makes an intuitive illustration on T-partition and E-partition. 182
2 As seen, {1, 2} and {3} are the
183 E-partition of Bdom , {1, 2, 3} to the T-partition, {1, 2} and {3}, of Adom , {1, 2, 3} with respect to C.
184 Therefore, A and B contain equivalent information about C, since C 6y A and C y B | A because (i) A
185 is the only parent of C and (ii) B is a nondescendant of C.
B A o /C /D
1 1 o
}}
(
1
(

2 2
a
66
o 1
2
66
(
3 3 o
66
(
2
3
66
CC
186 (2)
2. By Statnikov et al. (2013), (2) represents a BN over V = {A, B,C, D} with each variable taking {1, 2, 3} except for D taking
{1, 2}, in which dashed arrows denote all non-zero conditional probabilities of each variable given its parents.
5
Figure 2:
187 The following two definitions will be used in Example 6, via the property (stated in Equation 2.1)
188 of context-independent equivalent information (Statnikov et al., 2013, p. 506) in structuring new
189 MBs for target variables.
190 ❉ Conditional Equivalent Information. Two sets of variables, X and Y, from V are said to contain
191 equivalent information about T (⊆ V) conditioned on a non-empty set of variables W, if the
192 following four conditions hold: T 6y X | W, T 6y Y |W, T y X | W ∪ Y, and T y Y | W ∪ X.
193 ❉ Context-Independent Equivalent Information. Two sets of variables, X and Y, from V are said
194 to contain context-independent equivalent information about T (⊆ V), if X and Y contain
195 equivalent information about T conditioned on any subset of variables from V \ X \ Y \ T.
196 Lemma 4 If M is an MB of T (⊆ V) containing a set X, and there is a subset of variables Y such that X and
197 Y contain context-independent equivalent information about T, then (M \ X) ∪ Y is also an MB of T.
198 As seen, intersection and composition are two global properties of probability distributions.
199 Statnikov et al. (2013, p. 504) provided a relaxed version of composition called local composition,
200 which extends applications of several Mb discovery algorithms, such as IAMB and KIAMB, to the case
201 when composition of its global version is violated. We give the definition of local composition with
202 a slightly generalization with respect to the target as follows.
203 Definition 4 (Local Composition) Assume P is a joint probability distribution over V, and T is a given
204 set of variables from V. We say T satisfies the local composition property with respect to P, if T y X |Z and
205 T y Y |Z imply T y X ∪ Y |Z for any three sets of variables X, Y, and Z from V.
206 Likewise, the intersection property may also be violated in some situations. For the sake of
207 subsequent theoretical analysis, we introduce two relaxed versions of intersection as follows:
6
Figure 2:
187 The following two definitions will be used in Example 6, via the property (stated in Figure 2.1)
188 of context-independent equivalent information (Statnikov et al., 2013, p. 506) in structuring new
189 MBs for target variables.
190 ❉ Conditional Equivalent Information. Two sets of variables, X and Y, from V are said to contain
191 equivalent information about T (⊆ V) conditioned on a non-empty set of variables W, if the
192 following four conditions hold: T 6y X | W, T 6y Y |W, T y X | W ∪ Y, and T y Y | W ∪ X.
193 ❉ Context-Independent Equivalent Information. Two sets of variables, X and Y, from V are said
194 to contain context-independent equivalent information about T (⊆ V), if X and Y contain
195 equivalent information about T conditioned on any subset of variables from V \ X \ Y \ T.
196 Lemma 4 If M is an MB of T (⊆ V) containing a set X, and there is a subset of variables Y such that X and
197 Y contain context-independent equivalent information about T, then (M \ X) ∪ Y is also an MB of T.
198 As seen, intersection and composition are two global properties of probability distributions.
199 Statnikov et al. (2013, p. 504) provided a relaxed version of composition called local composition,
200 which extends applications of several Mb discovery algorithms, such as IAMB and KIAMB, to the case
201 when composition of its global version is violated. We give the definition of local composition with
202 a slightly generalization with respect to the target as follows.
203 Definition 4 (Local Composition) Assume P is a joint probability distribution over V, and T is a given
204 set of variables from V. We say T satisfies the local composition property with respect to P, if T y X |Z and
205 T y Y |Z imply T y X ∪ Y |Z for any three sets of variables X, Y, and Z from V.
206 Likewise, the intersection property may also be violated in some situations. For the sake of
207 subsequent theoretical analysis, we introduce two relaxed versions of intersection as follows:
6
Figure 2: An intuitive illustration on T-partition and E-partition: in the DAG “B ← A → C → D”,
all variables take {1, 2, 3} except for D taking {1, 2}, and dotted arrows denote all non-zero
conditional probabilities of each variable given its parents.
B A o /C /D
1 1 o
}}
(
1
(

2 2
a
66
o 1
2
66
(
3 3 o
66
(
2
3
66
CC
159 (1)
160 Finally, the notion of context-independent information equivalence given by Statnikov et al. (2013)
161 will be used in Example 6: X and Y are called context-independent information equivalent with
162 respect to T, if X and Y are information equivalent with respect to T given any Z ⊆ V \X \Y \T. For
163 this notion, Statnikov et al. (2013) proved the following conclusion: if M is an MB of T with X ⊆ M,
164 and there is some Y ⊆ V \ M \ T such that X and Y are context-independent information equivalent
165 with respect to T, then (M \ X) ∪ Y is also an MB of T.
166 2.2 Two Typical Algorithms: IAMB and KIAMB
167 In this subsection, we concisely present two typical Mb discovery algorithms: IAMB (Tsamardinos
168 et al., 2003) and KIAMB (Pena et al. ˜ , 2007). We select them because of their high adaptability and time
169 efficiency: (i) the correctness of IAMB and KIAMB requires only the local composition assumption,
170 while the correctness of the parents and children based algorithms, such as PCMB and the algorithms
171 in the GLL framework, usually requires the faithfulness condition (Pena et al. ˜ , 2007, Theorem 6;
172 and Aliferis et al., 2010a, Theorem 1); (ii) IAMB and KIAMB are time efficient and thus suitable for
173 the problem of Mb for multiple variables, while the parents and children based algorithms have
174 exponential complexities (Aliferis et al., 2010a, pp. 199–200), so that they are hard to work when
175 applied to the problem of Mb for multiple variables.
176 IAMB is an enhanced variant of GS. In 2003, Tsamardinos et al. pointed out that GS uses a static
177 and potentially inefficient heuristic in the growing phase, and then proposed IAMB by employing a
178 dynamic heuristic. Tsamardinos et al. (2003) showed the correctness of IAMB under the faithfulness
179 condition; Pena et al. ˜ (2007) relaxed the condition to the composition assumption; Statnikov et al.
180 (2013) further relaxed the condition to the local composition assumption. Algorithm 7 describes
181 the pseudo code for a modified version of IAMB. Here, the modification means that the shrinking
182 phase incorporates a similar dynamic heuristic to that of the growing phase.
5
Figure 3: An illustration on T-partition and E-partition: in the DAG “B ← A → C → D”, all
variables take {1, 2, 3} except for D taking {1, 2}, and dotted arrows denote all non-zero
conditional probabilities of each variable given its parents.
Finally, the notion of context-independent information equivalence given by Statnikov et al.
(2013) will be used in Example 2. X and Y are called context-independent information equivalent
with respect to T, if X and Y are information equivalent with respect to T given any Z ⊆ V\X\Y\T.
For this notion, Statnikov et al. (2013) proved the following conclusion: if M is an Mb of T with
X ⊆ M, and there is some Y ⊆ V \ M \ T such that X and Y are context-independent information
equivalent with respect to T, then (M \ X) ∪ Y is also an Mb of T.
2.2 Two Typical Algorithms: IAMB and KIAMB
This subsection concisely presents two typical MB discovery algorithms: IAMB (Tsamardinos
et al., 2003) and KIAMB (Pena et al. ˜ , 2007). We select them because of their high adaptability and
time efficiency: (i) correctness of IAMB and KIAMB requires only the local composition assumption
(Statnikov et al., 2013), while the correctness of the parents and children based algorithms, such
as PCMB and the algorithms in the GLL framework, usually requires the faithfulness condition (Pena˜
et al., 2007, Theorem 6; and Aliferis et al., 2010a, Theorem 1); (ii) IAMB and KIAMB are time efficient
and thus suitable for the problem of MB for multiple variables, while the parents and children based
algorithms have exponential complexities (Aliferis et al., 2010a, pp. 199–200), so they are hard
to work when too many variables are involved, such as the problem of MB discovery for multiple
variables.
IAMB is an enhanced variant of GS. In 2003, Tsamardinos et al. pointed out that GS uses a static
and potentially inefficient heuristic in the growing phase, and then proposed IAMB by employing a
dynamic heuristic. Tsamardinos et al. (2003) showed the correctness of IAMB under the faithfulness
condition; Pena et al. ˜ (2007) relaxed the condition to the composition assumption; Statnikov et al.
(2013) further relaxed the condition to the local composition assumption. Algorithm 3 describes the
pseudo code for IAMB. See Appendix A for details.
In the algorithm, there is a function fD (Line 3 of IAMB in Algorithm 3) denoting a heuristic
used to measure the association between variables (Tsamardinos et al., 2003; Pena et al. ˜ , 2007).
Two widely used selections for fD are CMI (Cheng et al., 2002; Tsamardinos et al., 2003) and the
negative p-value (Tsamardinos et al., 2006; Aliferis et al., 2010a,b; Statnikov et al., 2013). Also,
Yaramakala (2004, p. 41) suggested an equivalent version of the negative p-value. Subsection 4.3
will make a discussion about the ways of practically doing CI tests and the selections for fD.
6
Markov Blanket and Markov Boundary of Multiple Variables
KIAMB is a stochastic extension of IAMB. It embeds a randomization parameter K ∈ [0, 1] which
specifies the trade-off between greediness and randomness. If taking K = 1, KIAMB reduces to IAMB.
Pena et al. ˜ (2007) proved the correctness of KIAMB under the composition assumption. By the proof,
the local composition assumption is sufficient for KIAMB to be correct. Algorithm 3 describes the
pseudo code for KIAMB.
For the case of |T| ⩾ 2, IAMB and KIAMB can remain correct if strengthening the precondition.
We present the correctness of them as follows, without presenting the proof since it is similar to that
of the original IAMB and KIAMB (Tsamardinos et al., 2003; Pena et al. ˜ , 2007; Statnikov et al., 2013).
In what follows, we say a CI test for a hypothesis is correct if the statistical decision is correctly
made by using a testing method. Subsection 4.3 gives a further discussion on this issue.
Theorem 1 (Correctness of IAMB and KIAMB) Assume T satisfies the local composition property,
and all CI tests are correct. Then (i) IAMB outputs an MB of T; (ii) KIAMB outputs an MB of T for
any K ∈ [0, 1].
2.3 Motivations
This subsection provides three motivations of this paper.
Let M be an MB of T. Then P(T |V \ {T}) = P(T | M). In other words, all information for
predicting T is carried by M. Further, M is a solution to the FS problem, if the algorithm that
constructs the prediction model can learn any probability distribution, and the performance metric
is strictly decreasing with the mean-squared loss with a preference for smaller subsets (Tsamardinos
and Aliferis, 2003, Proposition 3). For this reason, MB for a single variable is sufficient.
However, there are the situations where MB for multiple variables is preferred. This occurs if
we need the probability distribution of more than one variables given all the others. Let Mi be an
MB of Ti for i = 1, 2. Denoting T = {T1, T2}, it follows that
P(T |V \ T) =
{
P(T1 | M1)P(T2 | M2) if T1 < M2 or T2 < M1
P(T1, T2,V \ T) /
∑
t1, t2
P(t1, t2,V \ T) if T1 ∈ M2 and T2 ∈ M1
As seen, in the case of T1 ∈ M2 and T2 ∈ M1, the computation is intractable, especially when the
dimension is high. Nevertheless, if we have an MB for T, denoted by M, then P(T |V\T) = P(T | M)
follows immediately, so the problem is simplified greatly. In this sense, it is meaningful to consider
the problem of MB for multiple variables.
The second motivation is that we want to know whether the prediction for T will be affected if
the observed values of some variables outside T (in a new observation) are missing. Denote these
missing variables by Vm. This problem can be considered as follows: find an approximate MB
(denoted by Mm) of T in V \ Vm by means of some method, then check if Mm is an Mb in V via
some criterion (e.g., a criterion based on Lemma 2 given by Statnikov et al., 2013); and finally
assert T will not be affected if the above checking result is “yes”. In this sense, it is also preferred
to consider MB for multiple variables.
Figure 4 represents the DAG for the ALARM network (Beinlich et al., 1989), which is well
known in the literature. Take T1 ≜ X22 and T2 ≜ X23. Then, MTi
is the unique MB of Ti for i = 1, 2
under the faithfulness condition, with
MT1 ≜ {X1, X4, X15, X21, X23, X27, X29} and MT2 ≜ {X2, X22, X24, X25, X27, X29}, (1)
7
Liu and Liu
24 23
2
25
27 22
26 8
4
9
15 13
7
5
6 11
34
32
36 35
1 29 21 19 20 14 31 12 37 33
3 30 28 18 17 16 10 ALARM Network
Figure 4: ALARM network (37 nodes and 46 edges): a logical alarm reduction mechanism.
respectively. This leads to intractable computations on the joint probability distribution of T1 and
T2 given all other variables, consider that T1 ∈ MT2
and T2 ∈ MT1
. Further, if the observed
values of some variables (e.g., Xj for j = 32, 33, · · · , 37) in a new observation are missing, can
this observation be used any more for predicting T1 and T2? Furthermore, we have to face similar
problems if three or more target variables are considered.
The third motivation concerns MB discovery algorithms. By Theorem 1, IAMB and KIAMB can be
applied to the problem of MB for multiple variables if simply regarding the targets as a multivariate
vector, under the strengthened local composition assumption. However, the assumption of local
composition imposed on multiple targets may have more occasions to become invalid than imposed
on single targets, due to the synergy effect in the sense that neither X nor Y carries information of T
but together they contain some information of T (Rauh et al., 2014).
Here is an illustration: considering the BN with the graph in Figure 5 as its DAG, by direct
computations using the FullBNT toolbox (Murphy, 2007), we find that
A y C, A y D, and A y {C, D};
B y C, B y D, and B y {C, D};
{A, B} y C, {A, B} y D, but {A, B} ̸y {C, D}.
By this illustration, the idea of applying the existing MB discovery algorithms to multiple targets
seems to be practically improper although it is theoretically feasible, because synergy effects may
lead to potential inefficiency and even incorrectness. This motivates us to build some algorithms
which are resistant to synergy effects and, further, are time efficient.
X A
D
Y
E B
W C Z
X A
D
Y
E B
W C Z
X A
D
Y
E B
W C Z
Figure 5: An illustration on synergy effects: each of {X, Y, Z, W} takes {1, 2} equiprobably; each of
{A, B,C, D} takes 1 with probabilities p1, p2, p3, p4 and takes 2 with probabilities 1 − p1,
1 − p2, 1 − p3, 1 − p4 given its parents, with p4 = p1 − p2 + p3; E has an arbitrary
distribution.
8
Markov Blanket and Markov Boundary of Multiple Variables
3. Markov Blanket and Markov Boundary for Multiple Variables
This section presents the theoretical results on the problem of Mb and MB for multiple variables
when the local intersection property is satisfied and when this property is violated. We study this
problem following this way because we are trying to find a suitable approach to transform the
problem of Mb and MB from multiple case to single cases, based on which we can build efficient
algorithms with high accuracies and low complexities.
3.1 Additivity under Local Intersection
In this subsection, we consider the problem of Mb and MB for multiple variables under the
local intersection assumption. We prove Mb and MB possess an ideal property called additivity.
That is, an Mb of multiple variables can be constructed by simply taking the union of the Mbs of the
individual variables and removing the target variables themselves (the same for MB). The results
are presented in Theorem 2 and Theorem 3, respectively. Appendix B gives their proofs.
Theorem 2 (Additivity of Mb) Let (G, P) be a BN over V. The following two statements hold:
(i) Let Mi be an Mb of Ti ⊆ V for i = 1, 2, and assume T1 ∪ T2 satisfies the local intersection
assumption. Then, (M1 ∪ M2) \ (T1 ∪ T2) is an Mb of T1 ∪ T2.
(ii) Let Mi be an Mb of Ti ∈ V for i = 1, · · · , k, and assume T ≜ {T1, · · · , Tk} satisfies the local
intersection assumption. Then, ∪k
i=1 Mi \ T is an Mb of T.
The additivity property of Mb can be intuitively described by the information flow metaphor
(Cheng et al., 2002) using Figure 6: (M1 ∪ M2) \ (T1 ∪ T2) is enough to cut off all information
channels from T1 ∪ T2 to other valves, when no information equivalence associated with T1 ∪ T2
occurs.
Let T ⊆ V be the set of target variables. As we know, in the case of |T| = 1 (denoting T = {T}),
the set MT composed of the parents, children, and spouses of T is an Mb of it (Pearl, 1988), since
MT d-separates T from all other variables. For the case of |T| ⩾ 2 (denoting T = {T1, · · · , Tk}),
Theorem 2 indicates that the union of all MTi
’s with T1, · · · , Tk excluded is an Mb of T.
Considering the ALARM network presented in Figure 4, we put T1 ≜ X22 and T2 ≜ X23. Then
MTi
is an Mb of Ti for i = 1, 2, where MT1
and MT2
are defined in (1). Assume T1, 2 ≜ {T1, T2}
satisfies the local intersection property. It follows from Theorem 2 that
(MT1 ∪ MT2
) \ T1, 2 = {X1, X2, X4, X15, X21, X24, X25, X27, X29} ≜ M1, 2 (2)
is an Mb of T1, 2. Those variables outside M1, 2 contain no information about T1, 2 conditioned on
M1, 2 and thereby P(T1, 2 |V \ T1, 2) reduces to P(T1, 2 | M1, 2). Further, if the observed values of
Markov Blanket and Markov Boundary of Multiple Variables
289 For additivity of MB shown in (i) of Theorem 2, we have a useful remark (used to simplify our
290 algorithms in Section 4), based on the fact that if M is an MB of T then M ∪ M0 is also an MB of T
291 for any M0 ⊆ V \ M \ T. By the remark, the local intersection assumption for additivity of MB is not
292 required in some special cases. The proof of this remark is given in Appendix B.
293 Remark 1 In the case of either T1 ⊆ V \ M2 or T2 ⊆ V \ M1, the conclusion of (i) in Theorem 2 holds
294 without requiring the local intersection assumption.
295 Theorem 2 shows the additivity of MB. A natural idea is to wonder if additivity is possessed
296 by Mb. Theorem 3 affirms this. Appendix B provides the proof. Note that the statements about the
297 uniqueness of Mb in this theorem follow from Lemma 2.
298 Theorem 3 (Additivity of Mb) Let (G, P) be a BN over V. The following two statements hold:
(i) Assume T1 ∪ T2 satisfies the local intersection assumption. Let Mi be the unique Mb of Ti
299 for i = 1, 2.
300 Then, (M1 ∪ M2) \ (T1 ∪ T2) is the unique Mb of T1 ∪ T2.
(ii) Assume T , {T1, · · · , Tk} satisfies the local intersection assumption. Let Mi be the unique Mb of Ti
301 for
i = 1, · · · , k. Then, Sk
302 i=1 Mi \ T is the uniqe Mb of T.
303 According to Theorem 3, M1, 2 defined in (2) is not only an MB but also the unique Mb of T1, 2
304 in the ALARM network if the faithfulness condition is satisfied. Further, M1, 2, 3 defined in (3) is the
305 unique Mb of T1, 2, 3.
V \ N \ T
M1 \ T2 M2 \ T1
T1 T2
306
V \ N \ T V \ (N ∪ S) \ T
M1 \ T2 M2 \ T1
+3 M1 \ T2 S M2 \ T1
T1δT1T2;V\N\T|NT2T1δT1T2;S|NT2307
Figure 6: An illustration for additivity of Mb and MB with T = T1 ∪ T2 and N = (M1 ∪ M2) \ T.
9
Liu and Liu
Xj for j = 32, · · · , 37 in a new observation are missing, this observation can still be used without
affecting the prediction on T1, 2. Further, MT3 ≜ {X15, X19, X20, X22, X29} is an Mb of T3 ≜ X21.
Assume T1, 2, 3 ≜ {T1, T2, T3} satisfies the local intersection property. Then Theorem 2 shows
MT1 ∪ MT2 ∪ MT3
\ T1, 2, 3 = {X1, X2, X4, X15, X19, X20, X24, X25, X27, X29} ≜ M1, 2, 3 (3)
is an Mb of T1, 2, 3.
For additivity of Mb shown in (i) of Theorem 2, we have a useful remark (used to simplify our
algorithms in Section 4), based on the fact that if M is an Mb of T then M ∪ M0 is also an Mb of T
for any M0 ⊆ V \ M \ T. By the remark, the local intersection assumption for additivity of Mb is
not required in some special cases. The proof of this remark is given in Appendix B.
Remark 1 In the case of either T1 ⊆ V \ M2 or T2 ⊆ V \ M1, the conclusion of (i) in Theorem 2
holds without requiring the local intersection assumption.
Theorem 2 shows the additivity of Mb. A natural idea is to wonder if additivity is possessed by
MB. Theorem 3 affirms this. Appendix B provides the proof. Note that the statements about the
uniqueness of MB in this theorem follow from Lemma 2.
Theorem 3 (Additivity of MB) Let (G, P) be a BN over V. The following two statements hold:
(i) Assume T1 ∪ T2 satisfies the local intersection assumption. Let Mi be the unique MB of Ti
for i = 1, 2. Then, (M1 ∪ M2) \ (T1 ∪ T2) is the unique MB of T1 ∪ T2.
(ii) Assume T ≜ {T1, · · · , Tk} satisfies the local intersection assumption. Let Mi be the unique
MB of Ti
for i = 1, · · · , k. Then, ∪k
i=1 Mi \ T is the uniqe MB of T.
According to Theorem 3, M1, 2 defined in (2) is not only an Mb but also the unique MB of T1, 2
in the ALARM network if the faithfulness condition is satisfied. Further, M1, 2, 3 defined in (3) is
the unique MB of T1, 2, 3.
3.2 Theoretical Results in the General Case
Let (G, P) be a BN over V, and assume Ti ⊆ V with |Ti
| ⩾ 1 has an Mb or MB, Mi
, for i = 1, 2.
Denote T = T1 ∪ T2 and N = (M1 ∪ M2) \ T. In the case that Mi
is an MB of Ti
, Theorem 3
reveals that N is an MB of T if T satisfies the local intersection assumption. However, when the
local intersection assumption does not hold (meaning information equivalence occurs, as Lemma 1
shows), N may be no longer an MB of T, due to one of the following reasons: (i) N may be an Mb
but it may not possess minimality, as shown by Example 2; (ii) N may be insufficient to shield T1
and T2 from all other variables, so it is no longer an Mb in this case, and some extra variables are
required to enter into N. Example 1 provides an illustration.
For the first case, we need only to optimize N by simply removing redundant variables from N;
however, for the second case, the additivity property of MB is thoroughly broken, and the problem
of constructing an MB for T based on M1 and M2 becomes complex. On the one hand, there are
some variables in V \ N \ T needing to enter into N; on the other hand, there may be some variables
in N becoming redundant once some new members supplement N. What we concern are which
variables should enter into N and how we find them.
10
Markov Blanket and Markov Boundary of Multiple Variables \\M1 \ T2 M2 \ T1
T1 T2
306
V \ N \ T V \ (N ∪ S) \ T
M1 \ T2 M2 \ T1
+3 M1 \ T2 S M2 \ T1
T1 δT1,T2;V\N\T | N T2 T1 δT1,T2; S | N T2
307
308 3.2 Theoretical Results in the General Case
Let (G, P) be a BN over V, and assume Ti ⊆ V with |T| > 1 has an MB or Mb, Mi 309 , for i = 1, 2.
Denote T = T1 ∪T2 and N = (M1 ∪M2) \T. In the case that Mi is an Mb of Ti 310 , Theorem 3 reveals that
311 N is an Mb of T if T satisfies the local intersection assumption. However, when the local intersection
312 assumption does not hold (meaning information equivalence occurs, as Lemma 1 shows), N may
313 be no longer an Mb of T, due to one of the following reasons: (i) N may be an MB but it may not
314 possess minimality, as shown by Example 2; (ii) N may be insufficient to shield T1 and T2 from all
315 other variables, so it is no longer an MB in this case, and some extra variables are required to enter
316 into N. Example 1 provides an illustration.
9
Figure 7: An illustration for the case of violating additivity of Mb and MB, caused by information
equivalence.
Assume N is no longer an Mb of T. Then, it is easily shown that
V \ N \ T ̸y T1 | N, but V \ N \ T y T1 | N ∪ T2,
V \ N \ T ̸y T2 | N, but V \ N \ T y T2 | N ∪ T1.
That is, T1 and T2 contain equivalent information about V \ N \ T given N. See Figure 7 for an
illustration: the valves M1 \ T2 and M2 \ T1 can not cut off all information channels between T and
V \ N \ T, because some information can flow through δT1,T2;V\N\T | N, an information equivalent
valve of T1 and T2 with respect to V \ N \ T given N. In other words, T1 and T2 may exchange
information directly; besides, they also share the equivalent information about V \ N \ T. This
indicates we should continue to turn off some valves, S ⊆ V \ N \ T, besides M1 \ T2 and M2 \ T1
such that T1 and T2 no longer exchange information through external valves and thus such that T
has no information exchange with remaining valves.
This analysis motivates us to give the following definition:
Definition 3 With the notations above, we call S (⊆ V \ N \ T) a Markov blanket supplementary
(MbS) (of T to N), if N ∪ S is an Mb of T. Further, a Markov boundary supplementary (MBS) is
any MbS such that none of its proper subsets is an MbS.
In what follows, we give the properties of MbS and MBS.
Theorem 4 Assume S ⊆ V \ N \ T. Then, the following statements are equivalent:
(i) S is an MbS;
(ii) I(T1; T2 | N ∪ S) = minS
′⊆V\N\T I(T1; T2 | N ∪ S
′
);
(iii) I(T; S | N) = maxS
′⊆V\N\T I(T; S
′
| N);
(iv) N ∪ S is an Mb of T1 in V \ T2 (or N ∪ S is an Mb of T2 in V \ T1).
In addition, if S is an MbS, then it is also an MBS if and only if T1 ̸y Y | N ∪ (S \ {Y}) or
T2 ̸y Y | N ∪ (S \ {Y}) holds for any Y ∈ S.
The proof of this theorem is presented in Appendix B.
As seen, (ii) and (iii) of Theorem 4 explain the implication of MbS that the information flow
metaphor illustrates in Figure 7: finding an MbS is equivalent to turning off some valves such that
T1 and T2 no longer exchange information through external valves, or equivalent to finding all
remaining equivalent information contained by T1 and T2; (iv) and the property of MBS provide a
practical way of building MBS discovery algorithms.
Here, we use an example to demonstrate the notions of MbS and MBS and their properties.
11
Liu and Liu
Example 1 Consider the BN (G, P) over V = {A, B,C, D} presented in Figure 8, in which A, B,
and C take {1, 2, 3} while D takes {1, 2}. Put T = {T1, T2}, N = (M1 ∪ M2) \ T = Ø, and S = {C},
S0 = {C, D} with T1 = A, T2 = B, M1 = {B}, M2 = {A}. Using the theory of information equivalence
(Lemeire, 2007), we can show the following results (see Appendix B for the proofs):
(i) M1 is an MB of T1 in V: I(A;C, D | B) = 0 and I(A;C, D) > 0;
(ii) M2 is an MB of T2 in V: I(B;C, D | A) = 0 and I(B;C, D) > 0;
(iii) N ∪ S is an Mb of T in V, so S is an MbS: I(A, B; D |C) = 0;
(iv) I(T1; T2 | N ∪ S) = minS
′⊆V\N\T I(T1; T2 | N ∪ S
′
), because of I(A; B |C) = I(A; B |C, D),
I(A; B |C) ⩽ I(A; B | D), and I(A; B |C) ⩽ I(A; B);
(v) I(T; S | N) = maxS
′⊆V\N\T I(T; S
′
| N);
(vi) N ∪ S is an MB of T1 in V \ {T2}: I(A;C, D) > 0 and I(A; D |C) = 0;
(vii) N ∪ S is an MB of T2 in V \ {T1}: I(B;C, D) > 0 and I(B; D |C) = 0;
(viii) S is an MBS; S0 is an MbS (not an MBS): I(A, B;C, D) > 0 and I(A; B |C, D) = I(A; B |C).
By Example 1, A and B share the equivalent information about C, so turning off the valve A (or
B) means cutting off all the channels from B (or A) to C. This is why they can screen off each other
from C. However, A and B lose the shield if they are integrated into a whole. In this case, we have to
turn C off such that A and B no longer exchange information through external valves. This example
reveals that an MBS is a minimal set of variables, S ⊆ V \ N \ T, such that T1 and T2 contain no
equivalent information about the remaining variables given N ∪ S.
When finding an MBS, S, and letting the variables in S supplement N, there may be some
variables in N becoming redundant. In addition, N may be redundant even before supplementing S.
Example 2 gives an illustration. For both cases, we need to remove the redundant variables.
Example 2 Consider the BN presented in Figure 9, in which any one variable from {A, B,C} and
another from {D, E, F} (denoted by X and Y, respectively) contain context-independent equivalent
information about G (see Statnikov et al., 2013, Example 3). Then, {X, Y} is an MB of G. Put now
T1 = {C, F} and T2 = {G}, and take M1 = {B, E} and M2 = {B, D}. Note that T1 ⊆ V \ M2 (and
also T2 ⊆ V \ M1). It concludes that N = {B, D, E} is not an MB but only an Mb of T1 ∪ T2, since
its proper subset {B, E} is also an Mb (and also an MB) of T1 ∪ T2. This shows why the process of
refining N is necessary.
P(A=1)=0.3
P(A=2)=0.3
P(A=3)=0.4
A
 P(B=1|A=1)=0.4; P(B=1|A=2)=0.8; P(B=1|A=3)=0.0
 P(B=2|A=1)=0.6; P(B=2|A=2)=0.2; P(B=2|A=3)=0.0
 P(B=3|A=1)=0.0; P(B=3|A=2)=0.0; P(B=3|A=3)=1.0
B
P(C=1|A=1)=1.0; P(C=1|A=2)=1.0; P(C=1|A=3)=0.0
P(C=2|A=1)=0.0; P(C=2|A=2)=0.0; P(C=2|A=3)=0.9
P(C=3|A=1)=0.0; P(C=3|A=2)=0.0; P(C=3|A=3)=0.1
P(D=1|C=1)=1.0; P(D=1|C=2)=0.0; P(D=1|C=3)=0.7
P(D=2|C=1)=0.0; P(D=2|C=2)=1.0; P(D=2|C=3)=0.3
C
D
Figure 8: BN (G, P): P is a joint probability distribution over V = {A, B,C, D} with each variable
taking values {1, 2, 3} except for D taking {1, 2}; G is a DAG over V.
12
Markov Blanket and Markov Boundary of Multiple Variables
P(A=1)=0.3
P(A=2)=0.7 A
 P(B=1|A=1)=1.0; P(B=1|A=2)=0.0
 P(B=2|A=1)=0.0; P(B=2|A=2)=1.0 B
 P(C=1|B=1)=1.0; P(C=1|B=2)=0.0
 P(C=2|B=1)=0.0; P(C=2|B=2)=1.0 C
P(D=1)=0.6
P(D=2)=0.4
 P(E=1|D=1)=1.0; P(E=1|D=2)=0.0
 P(E=2|D=1)=0.0; P(E=2|D=2)=1.0
 P(F=1|E=1)=1.0; P(F=1|E=2)=0.0
 P(F=2|E=1)=0.0; P(F=2|E=2)=1.0
 P(G=1|C=1, F=1)=0.2; P(G=1|C=1, F=2)=0.8
 P(G=2|C=1, F=1)=0.8; P(G=2|C=1, F=2)=0.2 G
 P(G=1|C=2, F=1)=0.2; P(G=1|C=2, F=2)=0.8
 P(G=2|C=2, F=1)=0.8; P(G=2|C=2, F=2)=0.2
D
E
F
Figure 9: BN (G, P): P is a joint probability distribution over V = {A, B,C, D, E, F,G} with all
variables taking values {1, 2}, G is a DAG with the variables in V as its nodes.
3.3 An Alternative Approach
Before building MB discovery algorithms for multiple targets, this subsection concisely presents
an alternative approach to the additivity based and MBS based methods. In Section 5, we will apply
this method as an FS strategy in multi-class prediction problems.
Let T ≜ {T1, · · · , Tk} be the targets of interest and T be T’s merged version, taking values
{1, · · · , t} with t ⩾ 3. This procedure transforms the MB discovery for multiple targets T into the
MB discovery for single target T, so all the existing MB discovery algorithms can be employed
theoretically if the required conditions are satisfied. However, if t is large, selecting features of T or
T directly will be difficult. Subsection 3.1 and Subsection 3.2 provide a way of solving this problem
in different situations. In this case, an alternative strategy is to further convert T into a set of dummy
variables denoted by {
T
(d)
j
}t
j=1
, where T
(d)
j
is a 0-1 variable defined as
T
(d)
j =
{
1, if T = j
0, if T , j
This transformation produces a multiple-target T
(d) ≜
(
T
(d)
1
, · · · , T
(d)
t
)
. Clearly, T, T, and T
(d)
have
the same MBs. In what follows, we show the MB of T
(d)
can be derived by simply taking the union
of MBs of T
(d)
1
, · · · , T
(d)
t and then removing the redundant variables in an efficient way. The proof
will be given in Appendix B.
Theorem 5 Let Mj be an MB of T
(d)
j
in V \ T for j = 1, · · · , t. Then, M ≜ ∪
k
j=1Mj
is an Mb of T.
Further, M is an MB of T iff for any X ∈ M there is some j such that T
(d)
j
̸y X | M \ {X}.
For why this transformative method is efficient, the fourth concluding remark in Section 7 will
make a brief explanation.
4. Algorithms
This section builds MB discovery algorithms for multiple targets, {T1, · · · , Tk} ≜ T.
13
Liu and Liu
Let A be an MB discovery algorithm, assumed to perform well when used to discover an MB
for a single target. In this paper, we employ IAMB and KIAMB as A. Clearly, A can be directly used
to find an MB for T if simply regarding T as the input of A. Usually, this will lead to low accuracies
and high complexities.
By Theorem 4, the MB discovery problem for multiple targets can be translated equivalently
into a number of MB discovery problems for single targets, according to the following way: (i) use
A to find an MB of Ti
in V for i = 1, · · · , k, denoted by Mi
; (ii) find an Mb of T2 in V \ {T1} based
on (M1 ∪ M2) \ {T1, T2}, and then get an MB of {T1, T2}, written as M1,2; (iii) find an Mb of T3
in V \ {T1, T2} based on (M1,2 ∪ M3) \ {T1, T2, T3}, and then get an MB of {T1, T2, T3}, written as
M1,2,3; (iv) the rest can be done in a similar manner. Following this way, the input of A for each use
is a single variable, so this idea successfully avoids assigning an multivariate input to A. Note that
in the above process the equivalent information is extracted in a stepwise manner.
4.1 IAMBS and KIAMBS
Let (G, P) be a BN over V, and assume Ti ⊆ V with |Ti
| ⩾ 1 has an MB, Mi
, for i = 1, 2. Denote
N = (M1 ∪ M2) \ (T1 ∪ T2). This subsection presents the algorithms for discovering an MB of
T1 ∪ T2. To design one such algorithm, we note that there may be some variables in N becoming
redundant once an MBS, S, is supplemented. Therefore, we need to first find S by setting N as a
whitelist in A and then refine N.
Applying this idea to IAMB and KIAMB, we obtain two algorithms called IAMBS and KIAMBS,
in which “S” refers to as “supplementary”. Their pseudo codes are presented in Algorithm 1. In
order to differentiate these two algorithms, we set K in the KIAMBS algorithm as K ∈ [0, 1). It is
mentioned here that S2 is a random subset of S1 with size max{1,⌊|S1| · K⌋} in Line 5 of KIAMBS.
As seen, these two algorithms first find an MbS, S, in the growing phase and then refine S and N in
sequence in the shrinking phase.
For example, based on a data set drawn from the BN in Example 1, the unique MB, {C}, of
{A, B} can be discovered by calling IAMBS or KIAMBS only once.
Theorem 1 presents the correctness of IAMB and KIAMB under the assumption that T1 ∪ T2
satisfies the local composition property. The theorem below shows IAMBS and KIAMBS are correct
if T2 (instead of T1 ∪ T2) satisfies the local composition property. Appendix B gives the proof.
Theorem 6 (Correctness of IAMBS and KIAMBS) Assume that T2 satisfies the local composition
property, and that all CI tests are correct. Then (i) IAMBS outputs an MB of T1 ∪ T2; (ii) KIAMBS
outputs an MB of T1 ∪ T2 for any K ∈ [0, 1).
The following remark presents a relation among local intersection, local composition, and the
adjacency faithfulness condition, under the orientation faithfulness condition. The proof is given in
Appendix B. Here, the orientation faithfulness condition (Ramsey et al., 2006; Lemeire et al., 2012)
is defined as: for any X, Y, Z ∈ V such that X and Z are adjacent to Y but X is not adjacent to Z, (i)
if X → Y ← Z, then X ̸y Z |W holds for any W ⊆ V \ {X, Z} with Y ∈ W; (ii) otherwise, X ̸y Z |W
holds for any W ⊆ V \ {X, Y, Z}.
Remark 2 The following two statements hold: (a) violating local intersection implies violating
adjacency faithfulness; (b) under the orientation faithfulness condition, violating local composition
at the end of the first phase of IAMB or KIAMB or IAMBS or KIAMBS means violating adjacency
faithfulness.
14
Markov Blanket and Markov Boundary of Multiple Variables
In addition, the lemma below is useful to explain the succeeding remarks.
Lemma 3 (a) If there is P ⊆ M1 \ T2 such that T1 y P | (N \ P) ∪ T2, then (N \ P) ∪ T2 is an Mb
of T1; (b) If there is Q ⊆ N \ P such that T1 y Q | (N \ P \ Q) ∪ T2 and T2 y Q | (N \ P \ Q) ∪ T1,
then (N \ P \ Q) ∪ T2 is an Mb of T1, and (N \ P \ Q) ∪ T1 is an Mb of T2.
For Algorithm 1, we have three remarks below:
(i) In these two algorithms, the two CI tests for adding members to S and for refining S are based
on T2 instead of T, while the CI test for refining N is based on T instead of T2. (a) For the first
two CI tests, T2 can be replaced with T without affecting the correctness of the algorithms,
since T2 y X | N ∪S
′ ⇔ T y X | N ∪S
′
holds for any S
′ ⊆ V \ N \T and X ⊆ V \ (N ∪S
′
) \T.
However, if we replace T2 with T, the resulting algorithms will need much longer time to run.
This is why we use T2 in stead of T in these two places. (b) For the third CI test, T can not
be replaced with T2, because of T2 y X | (N \ X) ∪ S ⇏ T y X | (N \ X) ∪ S.
(ii) According to Remark 2, there may be some situations in which both local intersection and
local composition are simultaneously violated. In this case, IAMBS and KIAMBS may not
Algorithm 1: IAMBS and KIAMBS
Procedure: M←IAMBS(D; T1, T2; M1, M2)
Input: a data matrix D; two sets of targets T1
and T2; an MB Mi of Ti for i = 1, 2.
Output: an MB, M, of T ≜ T1 ∪ T2.
//Forward: Growing Phase
1 S ← Ø
2 while S has changed do
3 M ← N ∪ S
4 Y ← arg maxX∈V\M\T fD(T2; X | M)
5 if T2 ̸y Y | M then
6 S ← S ∪ {Y}
7 end
8 end
//Backward: Shrinking Phase
9 foreach X ∈ S do
10 if T2 y Y | N ∪ (S \ {Y}) then
11 S ← S \ {Y}
12 end
13 end
14 foreach Y ∈ N do
15 if T y Y | (N \ {Y}) ∪ S then
16 N ← N \ {Y}
17 end
18 end
19 return M ← N ∪ S
Procedure: M←KIAMBS(D;T1,T2; M1, M2;K)
Input: Besides {D, Ti
, Mi}, K ∈ [0, 1) is a
randomization parameter.
Output: an MB, M, of T ≜ T1 ∪ T2.
//Forward: Growing Phase
1 S ← Ø
2 while S has changed do
3 M ← N ∪ S
4 if S1 ← {X ∈V\M\T: T2 ̸yX | M},Ø then
5 Y ← arg maxX∈S2
fD(T2; X | M)
6 S ← S ∪ {Y}
7 end
8 end
//Backward: Shrinking Phase
9 foreach X ∈ S do
10 if T2 y Y | N ∪ (S \ {Y}) then
11 S ← S \ {Y}
12 end
13 end
14 foreach Y ∈ N do
15 if T y Y | (N \ {Y}) ∪ S then
16 N ← N \ {Y}
17 end
18 end
19 return M ← N ∪ S
15
Liu and Liu
correctly work. Specifically, the violation of local intersection means T1 and T2 contain
equivalent information about V \ N \ T given N; while the violation of local composition
indicates not all equivalent information are successfully extracted by N. Let P and Q be
defined as in Lemma 3, and assume P ∪ Q , Ø. Then, it can be shown that T1 and T2
contain equivalent information about P ∪ Q given N \ (P ∪ Q). This means some equivalent
information about P ∪ Q shared by T1 and T2 conditioned on N \ (P ∪ Q) may mask some
equivalent information about V \ N \ T contained by T1 and T2 conditioned on N. This may
be why not all equivalent information can be extracted by N. According to this analysis, a
potential remedy is to run IAMBS or KIAMBS by replacing N with a superset of N \ (P ∪ Q)
that is a subset of N.
(iii) By Remark 1, if T1 ⊆ V\ M2 or T2 ⊆ V\ M1, N must be an Mb of T, so Lines 2∼14 of IAMBS
and KIAMBS can be omitted. In this case, however, it is still necessary to refine N, because N
may not possess minimality. Example 2 illustrates this necessity.
In addition, another problem that we concern is whether we can refine N before seeking S and,
if this is the case, which variables in N can be removed directly. We consider this problem because
any redundant variable in N can lead to unnecessary inaccuracies when using N as a part of the
conditional set in practical computations. Lemma 3 indicates we can do like this. However, to
avoid the danger of missing the information about P ∪ Q (this occurs if the equivalent information
involved in P∪Q given N\P\Q is different in some sense from any part of the equivalent information
involved in V \ N \ T given N), we recommend to first search the members of S in V \ N \ T and
then check if some variables in P ∪ Q are necessary to enter into S when implementing Lines 2∼8
of IAMBS and KIAMBS. Note that this will increase the total running time.
4.2 MIAMB and MKIAMB
In this subsection, we present two multivariate Markov boundary discovery algorithms, called
MIAMB and MKIAMB, respectively.
Let {T1, · · · , Tk} ∈ V with Mi as its an MB for i = 1, · · · , k. If the local intersection property is
satisfied, Theorem 3 shows ∪k
i=1 Mi \ T is an MB of T ≜ {T1, · · · , Tk}. Otherwise, M may be no
longer an MB. In this case, we use MIAMB or MKIAMB to seek an MB for T. Given an ordering of
T1, · · · , Tk, saying τ ≜ {i1, · · · , ik}, which determines the priorities of the variables in T entering into
the queue whose an MB will be sought in the current step, we denote an MB of {Ti1
, · · · , Tiℓ
} ≜ T
∗
iℓ
by M ∗
ij
.
With these notations, MIAMB and MKIAMB are pseudo-coded in Algorithm 2. Their correctness,
shown by Theorem 7, is a direct consequence of Theorem 1 and Theorem 6. As seen, MIAMB or
MKIAMB uses the following stepwise idea: it first finds an MB of two targets {Ti1
, Ti2
} = {Ti1
} ∪ {Ti2
},
and then finds an MB of three targets {Ti1
, Ti2
, Ti3
} = {Ti1
, Ti2
} ∪ {Ti3
}; the rest can be done in a
similar manner until all the k target variables are considered.
Theorem 7 (Correctness of MIAMB and MKIAMB) Assume that Ti satisfies the local composition
property for i = 1, · · · , k, and that all CI tests are correct. Denote T ≜ {T1, · · · , Tk}. Then (i)
MIAMB outputs an MB of T; (ii) MKIAMB outputs an MB of T for any K ∈ [0, 1).
As we know, for any real data, those preconditions (such as faithfulness or local composition)
required by a learning algorithm are hard to hold exactly. However, our algorithms can be seen as
an improvement over earlier methods. Specifically, IAMB/KIAMB algorithms require faithfulness or
16
Markov Blanket and Markov Boundary of Multiple Variables
local composition for multiple targets when used for MB discovery of multiple targets, while our
MIAMB/MKIAMB only need local composition for single targets, which may be more close to real
situations than faithfulness or local composition for multiple targets.
For MIAMB or MKIAMB, an ordering τ is set in Algorithm 2 mainly because different orderings
may lead to different computational complexities. In Subsection 4.4, we will make a complexity
analysis about the algorithms, based on which we present a feasible way of selecting τ, under the
expectation that our algorithms should be run as quickly as possible. When |T| = 2, however, τ is
not necessary.
Besides MIAMB/MKIAMB algorithms (which are MBS based), we can consider additivity based
(Theorem 3) and dummy variables based (Theorem 5) algorithms: (a) the additivity based MIAMB
or MKIAMB simply takes the union of outputs of IAMB/KIAMB with respect to all single targets as the
output; its correctness requires the conditions in Theorem 7 plus Theorem 3; and (b) the dummy
(variables based) MIAMB/MKIAMB takes the union of the outputs of IAMB/KIAMB with respect to
every dummy variable and removes redundant variables; its correctness requires the same condition
as in Theorem 7. Throughout this paper, unless specified, MIAMB/MKIAMB denote the MBS based
algorithms.
4.3 A Discussion on CI Test
As argued by Aliferis et al. (2010a, p. 200), the quality of an MB discovery algorithm highly
depends on the selected CI testing methods. In this subsection, we discuss the ways of practically
doing CI tests. Usually, the Pearson’s X
2
test or the log-likelihood ratio G
2
test can be employed for
this purpose (Yaramakala, 2004; Bromberg and Margaritis, 2009; Aliferis et al., 2010b; Statnikov
et al., 2013). Here, the X
2
statistic and the G
2
statistic have the same asymptotic χ
2 distribution. We
can also use some experimental testing methods such as the Akaike information criterion-based test
(Cressie and Read, 1989; Scutari, 2010).
Algorithm 2: MIAMB and MKIAMB
Procedure: M ← MIAMB(D; T; τ)
Input: a data matrix D; a target set
T≜{T1, · · · , Tk}; and an ordering
τ ≜ {i1 · · · , ik}.
Output: an MB, M, of T.
// MIAMB: M ← MIAMB(D; T; τ)
1 for ℓ ← 1 to k do
2 Miℓ ← IAMB(D; {Tiℓ
})
3 end
4 for ℓ ← 2 to k do
5 M ∗
iℓ ← IAMBS(D; T
∗
iℓ−1
, {Tiℓ
}; M ∗
iℓ−1
, Miℓ
)
6 end
7 return M ← M ∗
ik
Procedure: M ← MKIAMB(D; T; K; τ)
Input: a data matrix D; a target set T; a
randomization parameter K ∈ [0, 1);
and an ordering τ.
Output: an MB, M, of T.
// MKIAMB: M ← MKIAMB(D; T; K; τ)
1 for ℓ ← 1 to k do
2 Miℓ ← KIAMB(D; {Tiℓ
}; K)
3 end
4 for ℓ ← 2 to k do
5 M ∗
iℓ ←
KIAMBS(D; T
∗
iℓ−1
, {Tiℓ
}; M ∗
iℓ−1
, Miℓ
; K)
6 end
7 return M ← M ∗
ik
17
Liu and Liu
Recall that we are dealing with the MB discovery problem for multiple target variables. When
the target set, namely T, contains only a few variables (e.g., 1 or 2), the X
2
test or the G
2
test
performs quite well in most situations. Unfortunately, when T contains too many variables (e.g.,
5 or 6 or even more), X
2 or G
2 may not work well due to the overmany degrees of freedom. See
Appendix C for a detailed discussion. In fact, as Cochran (1954, p. 420) recommended about the
working rules for X
2
(also applicable to G
2
), these two testing methods are unreliable if more than
20% of the cells in contingency tables have an expected count of less than 5 data points; however,
such cases frequently arise in practice (Bromberg and Margaritis, 2009; Yaramakala, 2004).
Many authors have considered improving X
2
and G
2 by adjusting the statistics. Lawley (1956)
showed that such tests can be improved by multiplying with a suitable scale factor; Hosmane (1986,
1987, 1990) and the pioneer scholars recommended the following two adjustment procedures (i)
replace zero observed counts by a positive constant, leaving nonzero counts intact; and (ii) add a
positive constant to all the observed counts. Brin et al. (1997) and Silverstein et al. (1998) used two
heuristic “solutions” to the problem of low expected counts as follows: (i) simply ignore these cells
when calculating X
2 or G
2
; and (ii) use what is called contingency table support (CT-support): a set
of items S has CT-support s at the t% level if at least t% of the cells in the contingency table for S
have value s. Aliferis et al. (2010b) considered a similar heuristic called heuristic power size, which
denotes the smallest sample size per cell in the contingency table of a reliable CI test.
The above ideas can lead to improvements on X
2
and G
2
to varying degrees if the dimensions
are not very high. However, when working on the MB discovery problem for multiple targets, we
need more suitable methods to do CI tests. For this reason, we suggest the following practical
operation: when |T| ⩽ 2, we can (i) use X
2 or G
2 or their variants mentioned above to do CI tests;
otherwise, we consider the following testing method: (ii) use CMI and an experimental threshold,
ε, to make statistical decisions as Cheng et al. (2002) did, in the sense that ID(X; Y | Z) ⩾ ε asserts
X ̸y Y | Z while ID(X; Y | Z) < ε concludes X y Y | Z, where ε ≜ |T|
a1
·
100 a2
n
· log2
v is related to
the the sample size, the average number of values that each variable takes, and the number of targets
(denoted by n, v, and |T|, respectively), in which a1 and a2 are two adjusting factors (a1 = 0.5 and
a2 ∈ (0.1, 0.5) are recommended). The association function, fD, can be selected as
fD(X; Y | Z) = ID(X; Y | Z) ≜ f
(2)
D
(X; Y | Z). (4)
Besides this experimental method, we can (iii) improve X
2 or G
2 by adjusting the number of the
theoretical degrees of freedom.
For the above (iii), to be clear, we consider the G
2
statistic, G
2
(X; Y | Z) ≜ 2n · ID(X; Y | Z),
which approximates to the chi-square variate with r ≜ (rX −1)(rY −1)rZ degrees of freedom, namely
χ
2
(r), where rξ represents the number of configurations for ξ (de Campos, 2006, p. 2158). Denote
the p-value by
p(X; Y | Z) = P{χ
2
(r) ⩾ G
2
(X; Y | Z)}.
Then, the G
2
test asserts X y Y | Z if p(X; Y | Z) > α for a significance level α, and concludes
X ̸y Y | Z if p(X; Y | Z) ⩽ α. In this paper, α is set to be 0.05. Aliferis et al. (2010a, pp. 200–201)
provided a further discussion about this. Accordingly, the negative p-value is used as the association
function, fD, as Tsamardinos et al. (2006), Aliferis et al. (2010a,b), and Statnikov et al. (2013) did:
fD(X; Y | Z) = −p(X; Y | Z) = −P{χ
2
(r) ⩾ G
2
(X; Y | Z)} ≜ f
(1)
D
(X; Y | Z). (5)
18
Markov Blanket and Markov Boundary of Multiple Variables
Replace the theoretical value of r in p(X; Y | Z) with its a damped version of the form
gn,κ(r) ≜ r
(
1 − e
−
n
κr
)
, (6)
where κ > 0 is a constant, based on which n
κ measures the amount of valid cells that n sample
instances can support. For convenience, we will call the resulted p-value, denoted by pg(X; Y | Z)
instead of p(X; Y | Z), and the resulted testing method to be the damped p-value and the damped
log-likelihood ratio test (or damped G
2
test). Further, we use the the following association function:
fD(X; Y | Z) = −pg(X; Y | Z) = −P{χ
2
(gn,κ(r)) ⩾ G
2
(X; Y | Z)} ≜ f
(3)
D
(X; Y | Z). (7)
In Appendix C, we will provide the details for this damping procedure, and give some numerical
illustrations about its reasonability. Clearly, the damped G
2
test approximately degenerates into the
ordinary G
2
test when taking κ as a very small positive number.
4.4 Complexity Analysis
In the following, we analyze the computational complexities of the four algorithms: IAMB,
KIAMB, MIAMB, and MKIAMB. Usually, the number of CI tests can be employed to measure the
complexity of a CI-based MB discovery algorithm (Tsamardinos et al., 2003, 2006; Aliferis et al.,
2010a), considering there exists efficient implementations of the CMI-based test or the association
computation taking time O(n log n) if the conditional set is small. However, Aliferis et al. (2010a)
also mentioned that the running time, denoted by tn,q, for computing per CMI-based statistic is
linear to the sample size, n, and exponential to the number, q, of variables in the conditional set.
This means we should take tn,q into account, not simply using O(n log n) to measure the complexity.
Assume we are seeking an MB for T ≜ {T1, · · · , Tk} according to the ordering τ. Without loss
of generality, we assume τ = {1, · · · , k}. Consider the case of k = 2. Suppose Mi
is an MB of Ti
with |Mi
| = mi ⩾ 1, and S is an MBS for N ≜ M1 ∪ M2 \ {T1, T2} with |S| = s ⩾ 0. By Remark 1,
we assume T1 ∈ M2 and T2 ∈ M1. Recall that the number of all variables is p. It follows that:
• In view of |N∪S| = m1+m2+s−2 ≜ m, IAMB takes time O[(mp+m)tn,m] to finish an execution.
Thus, the complexity of IAMB is O(m ptn,m). KIAMB has almost the same complexity.
• For MIAMB, it first takes time O[(m1 p + m1)tn,m1 + (m2 p + m2)tn,m2
] to find M1 and M2; then it
seeks S and refines N taking time O{[s(p − m1 − m2 + 2) + m]tn,m}. Hence, MIAMB needs time
O{(m1 p + m1)tn,m1 + (m2 p + m2)tn,m2 + [s(p − m1 − m2 + 2) + m]tn,m} to finish an execution, so
its complexity is O(m1 ptn,m1 + m2 ptn,m2 + s ptn,m). MKIAMB has almost the same complexity.
By this analysis, the complexity of MIAMB or MKIAMB is lower than that of IAMB or KIAMB. In
fact, noting tn,q is exponential to q (⩽ m; meaning tn,q ≪ tn,m in most situations) for q = m1, m2,
this implies MIAMB/MKIAMB are expected to need much less time to run than IAMB/KIAMB, especially
when T contains many variables. The evaluation section (Figure 15) confirms this expectation in
the case of moderately large sample size.
For the general case, using the notations in Subsection 4.2 with |Mi
| = mi (i = 1, · · · , k),
we assume Si be an MBS for M ∗
i−1
and Mi
, with |Si
| = si (i = 2, · · · , k). Denote m
∗
i ≜
∑i
j=1 mj +
∑i
j=2
sj−i. Note that, in general, tn,ma ≪ tn,m∗
a ≪ tn,m∗
b
for a < b. Then, the IAMB or KIAMB algorithm
has the complexity O(m
∗
k
ptn,m∗
k
), while MIAMB or MKIAMB has a lower complexity O(
∑k
i=1 miptn,mi +
∑k
i=2
si ptn,m∗
i
).
19
Liu and Liu
According to this theoretical result on complexities, we can use the ordering, τ ≜ {i1 · · · , ik}, in
MIAMB or MKIAMB such that mi1 ⩽ · · · ⩽ mik
. This can reduce the complexities to some extent.
Besides, the additivity based MIAMB/MKIAMB algorithms have almost the same complexity as the
MBS based MIAMB/MKIAMB, while the dummy MIAMB/MKIAMB have the complexity O(m rT ptn,m),
where m =
∑k
j=1 mj
, rT =
∏k
j=1
rT j
, rξ denotes the number of configurations for ξ. It will be seen
from Section 6 that, although the dummy MIAMB/MKIAMB are of high complexity theoretically, they
usually perform well in multi-class prediction problems.
5. Benchmarking Study
This section makes a benchmarking study based on the data sets of six synthetic BNs. These
data sets, generated by Tsamardinos et al. (2006) and Aliferis et al. (2010a), and the BNs are briefly
described in Table 1. As Tsamardinos et al. (2006) and Aliferis et al. (2010a) stated, these BNs are
representatives of a wide range of problem domains. Also, these BNs have different complexities
(according to the number of nodes, the number of edges, maximal in-degree, maximal out-degree,
and domain range). More details about the BNs and the used data sets are provided by Tsamardinos
et al. (2006) and Aliferis et al. (2010a).
The following items are clarified before presenting the experimental results:
• Measurements: The primary measurement for the performance of an MB discovery algorithm
used in our experiment is the weighted accuracy (WA), which is the average of the rate of true
members and that of true nonmembers of an MB with respect to the truth. We also compute
what we call the weighted precision (WP) as the average of the rate of true members and that
of true nonmembers of an MB with respect to the output. In addition, we record the running
time (RT) for every data set of each algorithm and for each BN. Here, RT refers to the single
CPU time implemented on an Intel i7-3612QM 2.1 GHz and Windows 7 with 64 bits.
BN Num.
Nodes
Num.
Edges
Maximal
In-degree
Maximal
Out-degree
Domain
Range Selected Targets Sizes of
Data Sets
Total RT
(Hours)
Child10 200 257 2 7 2 ∼ 6
X131, X132, X98, X194,
X184, X22, X135, X60
5 × 500 3.4297
1 × 5000 8.2220
ALARM10 370 570 4 7 2 ∼ 4
X341, X48, X37, X249,
X209, X188, X192, X161
5 × 500 4.6547
1 × 5000 6.3721
Pigs 441 592 2 39 3 ∼ 3
X390, X357, X180, X400,
X199, X241, X228, X176
5 × 500 11.7651
1 × 5000 15.8443
Link 724 1125 3 14 2 ∼ 4
X369, X293, X303, X457,
X399, X512, X183, X501
5 × 500 9.7932
1 × 5000 16.1046
Lung Cancer 800 1476 4 28 2 ∼ 3
X1, X416, X345, X641,
X513, X198, X78, X746
5 × 500 16.0301
1 × 5000 16.3790
Gene 801 977 4 10 3 ∼ 5
X801, X301, X569, X317,
X185, X622, X516, X577
5 × 500 17.2465
1 × 5000 35.6790
Table 1: BNs and data sets.
20
Markov Blanket and Markov Boundary of Multiple Variables
2 3 4 5 6 7 8
0.49
0.53
0.57
0.61
Number of Target Variables
Average Weighted Accuracy
Child10: 200 Nodes and 257 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.50
0.55
0.60
0.65
Number of Target Variables
Average Weighted Accuracy
ALARM10: 370 Nodes and 570 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.49
0.61
0.73
0.85
Number of Target Variables
Average Weighted Accuracy
Pigs: 441 Nodes and 592 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.50
0.53
0.56
0.59
Number of Target Variables
Average Weighted Accuracy
Link: 724 Nodes and 1125 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.49
0.55
0.61
0.67
Number of Target Variables
Average Weighted Accuracy
Lung Cancer: 800 Nodes and 1476 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.52
0.58
0.64
0.70
Number of Target Variables
Average Weighted Accuracy
Gene: 801 Nodes and 977 Edges
IAMB
KIAMB
MIAMB
MKIAMB
Figure 10: Average WA of the algorithms versus |T| with respect to the data sets of size 500
• Algorithms: Four algorithms are used: IAMB, KIAMB, MIAMB, and MKIAMB. We take K = 0.8
as the randomization parameter in KIAMB and MKIAMB due to the following two reasons: (i)
Pena et al. ˜ (2007, p. 227) asserted that K ∈ [0.7, 0.9] performs best; and (ii) K = 0.8 is an
appropriate tradeoff between WA (or WP) and RT.
• Used CI Test: Following the practical operation suggested in Subsection 4.3, we implemented
the algorithms via the G
2
test, and found G
2
is suitable for small |T| but is not very suitable
and even no longer works for large |T|. Then, we used the experimental CMI-based test with
a relatively rough ε ≈
√
|T| · ε0, in which ε0 = 0.05 if n = 500 and ε0 = 0.01 if n = 5000;
after that, we used the damped G
2
test by setting κ = 5. The results indicate both alternatives
are desirable. Considering the association function, f
(2)
D
defined in (4) corresponding to the
CMI-based test, contains no the average number, v, of values that each variable takes, we may
need to reselect ε0 for a BN with a very different v. For these reasons, we eventually decided
to use the damped G
2
test for the four algorithms in our experiment.
• Data: We use the data sets of sizes 500 and 5000, generated by Tsamardinos et al. (2006)
and Aliferis et al. (2010a), which are available at http://www.nyuinformatics.org/
downloads/supplements/JMLR2009/index.html.
• Targets: We employ eight of those variables selected by Aliferis et al. (2010a, p. 226) as the
potential targets for each BN. See Table 1 for details. Then, T is any possible combination of
k targets for k = 2, · · · , 8.
• Steps: For each BN with eight selected targets, the steps of making simulation based on the
data set of size 5000 are as follows: (a) for k = 2, · · · , 8, call the four algorithms to obtain four
MBs of T ≜ {Ti1
, · · · , Tik
}; (b) compute their WAs and WPs, and record the respective RTs;
(c) take the average values of these (
8
k
)
WAs or WPs or RTs for each of the four algorithms.
For the five data sets of size 500, each reported WA or WP or RT is the average value of the
corresponding five results of an algorithm derived by (a) ∼ (c) above.
21
Liu and Liu
2 3 4 5 6 7 8
0.49
0.55
0.61
0.67
Number of Target Variables
Average Weighted Accuracy
Child10: 200 Nodes and 257 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.51
0.58
0.65
0.72
Number of Target Variables
Average Weighted Accuracy
ALARM10: 370 Nodes and 570 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.50
0.60
0.70
0.80
Number of Target Variables
Average Weighted Accuracy
Pigs: 441 Nodes and 592 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.50
0.54
0.58
0.62
Number of Target Variables
Average Weighted Accuracy
Link: 724 Nodes and 1125 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.49
0.57
0.65
0.73
Number of Target Variables
Average Weighted Accuracy
Lung Cancer: 800 Nodes and 1476 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.49
0.58
0.67
0.76
Number of Target Variables
Average Weighted Accuracy
Gene: 801 Nodes and 977 Edges
IAMB
KIAMB
MIAMB
MKIAMB
Figure 11: Average WA of the algorithms versus |T| with respect to the data sets of size 5000
2 3 4 5 6 7 8
0.45
0.51
0.57
0.63
Number of Target Variables
Average Weighted Precision
Child10: 200 Nodes and 257 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.50
0.61
0.72
0.83
Number of Target Variables
Average Weighted Precision
ALARM10: 370 Nodes and 570 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.48
0.57
0.66
0.75
Number of Target Variables
Average Weighted Precision
Pigs: 441 Nodes and 592 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.49
0.55
0.61
0.67
Number of Target Variables
Average Weighted Precision
Link: 724 Nodes and 1125 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.48
0.58
0.68
0.78
Number of Target Variables
Average Weighted Precision
Lung Cancer: 800 Nodes and 1476 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.50
0.56
0.62
0.68
Number of Target Variables
Average Weighted Precision
Gene: 801 Nodes and 977 Edges
IAMB
KIAMB
MIAMB
MKIAMB
Figure 12: Average WP of the algorithms versus |T| with respect to the data sets of size 500
According to the above description, we make computations with the aid of FullBNT (Murphy,
2007) and MIToolbox (Brown et al., 2012). The results of the WAs are presented in Figure 10 and
Figure 11; the results of the WPs are given in Figure 12 and Figure 13; and the results of the RTs
are shown in Figure 14, and Figure 15. The total RTs are presented in Table 1. By these figures, it
is concluded that, on the whole, our MIAMB and MKIAMB have higher computational accuracies and
lower time complexities than the existing IAMB and KIAMB.
Specifically, we have:
22
Markov Blanket and Markov Boundary of Multiple Variables
2 3 4 5 6 7 8
0.47
0.55
0.63
0.71
Number of Target Variables
Average Weighted Precision
Child10: 200 Nodes and 257 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.48
0.65
0.82
0.99
Number of Target Variables
Average Weighted Precision
ALARM10: 370 Nodes and 570 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.46
0.59
0.72
0.85
Number of Target Variables
Average Weighted Precision
Pigs: 441 Nodes and 592 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.48
0.55
0.62
0.69
Number of Target Variables
Average Weighted Precision
Link: 724 Nodes and 1125 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.49
0.62
0.75
0.88
Number of Target Variables
Average Weighted Precision
Lung Cancer: 800 Nodes and 1476 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.49
0.58
0.67
0.76
Number of Target Variables
Average Weighted Precision
Gene: 801 Nodes and 977 Edges
IAMB
KIAMB
MIAMB
MKIAMB
Figure 13: Average WP of the algorithms versus |T| with respect to the data sets of size 5000
2 3 4 5 6 7 8
0.02
0.04
0.06
0.08
Number of Target Variables
Average Running Time (Minutes)
Child10: 200 Nodes and 257 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.02
0.05
0.08
0.11
Number of Target Variables
Average Running Time (Minutes)
ALARM10: 370 Nodes and 570 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.05
0.14
0.23
0.32
Number of Target Variables
Average Running Time (Minutes)
Pigs: 441 Nodes and 592 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.05
0.12
0.19
0.26
Number of Target Variables
Average Running Time (Minutes)
Link: 724 Nodes and 1125 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.08
0.20
0.32
0.44
Number of Target Variables
Average Running Time (Minutes)
Lung Cancer: 800 Nodes and 1476 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.09
0.21
0.33
0.45
Number of Target Variables
Average Running Time (Minutes)
Gene: 801 Nodes and 977 Edges
IAMB
KIAMB
MIAMB
MKIAMB
Figure 14: Average RT of the algorithms versus |T| with respect to the data sets of size 500
(i) Performance on WA: (a) MIAMB and MKIAMB have larger WAs than IAMB and KIAMB for all
the six BNs in any case of |T|; (b) when |T| increases, WA declines quickly for IAMB and
KIAMB, but it decreases gently for MIAMB and MKIAMB; and (c) the improvements of MIAMB
and MKIAMB over IAMB and KIAMB tend to be gradually noticeable and then reduce slightly as
|T| increases. The performance degradation along with the increase of |T| can be attributed
to two possible aspects: one is that the local composition assumption may be more apt to be
violated for a larger |T| because of synergy effects; and the other is that the assumption about
23
Liu and Liu
2 3 4 5 6 7 8
0.01
1.35
2.69
4.03
Number of Target Variables
Average Running Time (Minutes)
Child10: 200 Nodes and 257 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.02
0.74
1.46
2.18
Number of Target Variables
Average Running Time (Minutes)
ALARM10: 370 Nodes and 570 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.09
3.08
6.07
9.06
Number of Target Variables
Average Running Time (Minutes)
Pigs: 441 Nodes and 592 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.12
1.97
3.82
5.67
Number of Target Variables
Average Running Time (Minutes)
Link: 724 Nodes and 1125 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.23
1.64
3.05
4.46
Number of Target Variables
Average Running Time (Minutes)
Lung Cancer: 800 Nodes and 1476 Edges
IAMB
KIAMB
MIAMB
MKIAMB
2 3 4 5 6 7 8
0.30
6.40
12.5
18.6
Number of Target Variables
Average Running Time (Minutes)
Gene: 801 Nodes and 977 Edges
IAMB
KIAMB
MIAMB
MKIAMB
Figure 15: Average RT of the algorithms versus |T| with respect to the data sets of size 5000
the correctness of CI tests may also be more apt to be violated for a larger |T|, due to the
accumulation and propagation of the cascading errors (Bromberg and Margaritis, 2009). It is
mentioned that (a)(b)(c) appear more evidently for the case of n = 5000 than for the case of
n = 500.
(ii) Performance on WP: The similar interpretations to (a)(c) of (i) are valid.
(iii) Performance on RT: Here, we note that the real RT of an MB discovery algorithm is composed
of two parts, in which the part (I) is for CI tests, and the part (II) is for all other computations.
The part (I) is the major part used to measure the complexity of the MB discovery algorithm.
Note also that the RT, tn,q, of per CI test is linear to the sample size, n, and exponential to the
number, q, of variables in the conditional set (see Subsection 4.4 for details).
This means that the part (II) of the real RT may dominate the part (I) if n is not large (for
example, n = 500).
Let us now observe Figure 14 and Figure 15. First, both figures show the real RT that each
algorithm needs is increasing along with the increase of |T|. Also, Figure 14 indicates MIAMB
and MKIAMB need slightly longer time to run than IAMB and KIAMB, because the running for CI
tests is dominated by the running for all other computations in the case of a small sample size,
while Figure 15 reveals that the real RTs of IAMB and KIAMB increase sharply as |T| increases
and that the real RTs of MIAMB and MKIAMB increase slowly, just like the theoretical analyses
about the complexities of the four algorithms show in Subsection 4.4.
In summary, the existing MB discovery algorithms, IAMB and KIAMB, can be approximately
applied to the problem of MB discovery for multiple target variables when |T| is small, but they
will perform poorly if |T| is moderately large. In comparison, our MIAMB and MKIAMB have higher
accuracies and lower complexities for this problem, especially when |T| is large.
24
Markov Blanket and Markov Boundary of Multiple Variables
6. Application to FS in Multi-Class Prediction Problems
In this section, we apply the MB discovery for multiple targets to FS in multi-class prediction
problems based on a real data set, HIVA. This data set is very challenging in WCCI 2006 (http://
www.modelselect.inf.ethz.ch) and IJCNN 2007 (http://www.agnostic.inf.ethz.ch),
because it contains many very unbalanced variables.
Let T ∈ V be a target variable taking values {1, · · · , t}, t ⩾ 3. The multi-class prediction problem
is to select features of T from V \ {T} such that T can be predicted as accurately as possible based
on the chosen features. Let T
(d) ≜
(
T
(d)
1
, · · · , T
(d)
t
)
be the dummy version of T. Theoretically, T
(d)
and T have the same MBs.
With these notations, the experiment is designed as follows:
• Data: HIVA contains 4229 data points and 1618 variables.
• Targets: In view of the fact that almost all variables in HIVA are binary, we randomly take
k 2-class variables (k = 2, · · · , 5) to create a merged 2k
-class target, T. Accordingly, we
rearrange the original data to get a data set that is used only for FS of T. Repeat this step
n ≜ 200 times. Denote the resulting targets and their dummy versions by T1, · · · , Tn and
T
(d)
1
, · · · , T
(d)
n
, respectively.
• Algorithms: We use the following 10 MB discovery algorithms to get the features for each T j
or T
(d)
j ≜
(
T
(d)
j1
, · · · , T
(d)
jtk
)
with tk ≜ 2
k
, j = 1, · · · , n:
a) IAMB/KIAMB-I: the IAMB/KIAMB algorithms working on T j directly;
b) IAMB/KIAMB-II: the IAMB/KIAMB algorithms working on T
(d)
j
(that is, with T
(d)
j
as its
multiple targets);
c) MIAMB/MKIAMB-I: the additivity based MIAMB/MKIAMB algorithms, taking the union of
the outputs of IAMB/KIAMB with respect to T
(d)
ji (i = 1, · · · , tk) as its output;
d) MIAMB/MKIAMB-II: the MBS based MIAMB/MKIAMB algorithms, which are pseudo-coded
in Algorithm 2;
e) MIAMB/MKIAMB-III: the dummy MIAMB/MKIAMB algorithms, which take the union of the
outputs of IAMB/KIAMB with respect to T
(d)
ji (i = 1, · · · , tk) and removing redundant
variables.
• Classifier: After making a number of preliminary experiments on the six benchmarking BNs,
we found that the support vector machines (SVMs; implemented via LibSVM v3.22) perform
the best in demonstrating the optimality of MBs for FS. This coincides with the assertion of
Statnikov et al. (2013). Therefore, we use SVMs for our multi-class prediction problems. All
the classifications are performed by 10-fold cross-validation.
• Measurement of an algorithm: For each target, the predictive quality of an MB is measured
by the balanced accuracy defined as τ ≜
1
tk
∑tk
ℓ=1
(
cℓℓ/∑tk
i=1
ciℓ
)
, where C ≜
(
ciℓ
)
denotes
the associated confusion matrix. As seen, τ is equal to one minus the balanced error rate used
in WCCI 2006 and IJCNN 2007. We choose to use τ (instead of ordinary accuracy) because
it trades off all values of the target in the sense that any unbalanced value (that the target
25
Liu and Liu
Problem
IAMB MIAMB
I II I II III
4-class 0.9295 ± 0.08200.9020 ± 0.11390.9414 ± 0.06820.9366 ± 0.07350.9507 ± 0.0572
8-class 0.9016 ± 0.10250.8666 ± 0.13330.9237 ± 0.09130.9277 ± 0.08730.9348 ± 0.0771
16-class 0.8878 ± 0.10560.8461 ± 0.14380.9131 ± 0.08740.9167 ± 0.08620.9256 ± 0.0750
32-class 0.8683 ± 0.11320.8179 ± 0.15790.9118 ± 0.07840.9139 ± 0.07810.9242 ± 0.0674
Table 2: Balanced accuracy of IAMB/MIAMB algorithms in the form of “(mean ± std)”.
Problem
KIAMB MKIAMB
I II I II III
4-class 0.9283 ± 0.08520.8972 ± 0.12400.9281 ± 0.09280.9444 ± 0.06680.9501 ± 0.0589
8-class 0.9007 ± 0.10550.8631 ± 0.14490.9245 ± 0.08900.9280 ± 0.08280.9340 ± 0.0786
16-class 0.8886 ± 0.10620.8494 ± 0.14250.9159 ± 0.08480.9168 ± 0.08640.9263 ± 0.0755
32-class 0.8687 ± 0.11400.8241 ± 0.15120.9111 ± 0.08120.9151 ± 0.07670.9239 ± 0.0688
Table 3: Balanced accuracy of KIAMB/MKIAMB algorithms in the form of “(mean ± std)”.
takes) should not impact on the accuracy too much.1 On the other hand, when two outputs
of algorithms have the same total numbers of “true positives + true negatives”, the balanced
accuracy can identify the output that prefers to protect the scarce class as the better one, while
the ordinary accuracy cannot. Finally, we compute the mean and standard deviation (std) of
the n values of balanced accuracy, denoting them in the form of “(mean ± std)”.
The experiment is then performed following the above procedures. Its results are summarized
in Table 2 and Table 3. In these two tables, the backcolor indicates the performance of algorithms
with black corresponding to the best while light blue to the worst. By the results, it can be seen that
MIAMB/MKIAMB outperform IAMB/KIAMB in most situations. Specifically, we have:
• IAMB/KIAMB algorithms: IAMB/KIAMB-I are much more preferred than IAMB/KIAMB-II.
• MIAMB/MKIAMB algorithms: MKIAMB-I has almost equal performance to KIAMB-I in 4-class
problems, and they performs slightly better than IAMB/KIAMB-I in 16- and 32-class problems;
1. For example, consider an unbalanced target T and its classification with the following two confusion matrices (the
left is extremely bad, while the right is very good):
Test Truth T = 1 T = 2
T = 1 948 49
T = 2 2 1
Test Truth T = 1 T = 2
T = 1 899 0
T = 2 51 50
Then, we have: (a) for the left bad confusion matrix, the ordinary accuracy equals 94.90% (meaning it is impacted
deeply by the unbalanced value 1 of T ), while its balanced accuracy equals 50.89%; (b) for the right good confusion
matrix, its ordinary accuracy also equals 94.90%, but its balanced accuracy equals 97.32%. This means balanced
accuracy is more reasonable than ordinary accuracy to measure classification performance for a practical problem
containing unbalanced variables (note that such problems may frequently occur in practice).
26
Markov Blanket and Markov Boundary of Multiple Variables
Null hypothesis (H0)
Problem
4-class 8-class 16-class 32-class
MIAMB-I ≼ IAMB-I 2.0349 × 10−4 1.3225 × 10−7 1.3816 × 10−10 4.0634 × 10−19
MIAMB-II ≼ IAMB-I 1.4772 × 10−2 9.3393 × 10−10 4.0911 × 10−12 8.2111 × 10−21
MIAMB-III ≼ IAMB-I 2.1276 × 10−10 9.5876 × 10−16 1.8800 × 10−20 9.1061 × 10−30
MKIAMB-I ≼ KIAMB-I 0.6221 4.9365 × 10−9 5.9117 × 10−12 2.0651 × 10−19
MKIAMB-I = KIAMB-I 0.7558 —— —— ——
MKIAMB-II ≼ KIAMB-I 2.2839 × 10−6 5.9538 × 10−11 5.4564 × 10−12 2.7021 × 10−22
MKIAMB-III ≼ KIAMB-I 4.5857 × 10−10 1.1261 × 10−15 4.7802 × 10−20 6.4206 × 10−30
Table 4: p-values on paired t-test for comparison between MIAMB/MKIAMB and IAMB/KIAMB. Here,
the notations are defined as follows: letting A1 and A2 be two algorithms and P be a
problem, if A1 is better (in the sense of possessing higher accuracy) than A2 when used
to solve P, we denote it by A1 ≻ A2 (w.r.t. P); otherwise, we write it as A1 ≼ A2. In
addition, we use A1 = A2 to denote A1 ≼ A2 and A1 ≽ A2.
MIAMB/MKIAMB-II significantly improve IAMB/KIAMB and even MIAMB/MKIAMB-I in most cases
(although MIAMB/MKIAMB-II have larger std values than MIAMB/MKIAMB-I in some cases, the
differences are slight). MIAMB/MKIAMB-III perform the best in all situations, with the highest
mean values and the smallest std values.
Further, for any two algorithms, denote their balanced accuracy values as n (= 200) paired
data points. Then, we can compute the p-values of paired t-test of associated hypotheses for
one algorithm to be better (in the sense of possessing higher accuracy) than the other. The
results are presented in Table 4. This table quantificationally shows the statistical significance
of how much MIAMB/MKIAMB improve IAMB/KIAMB: in most cases, the improvement is more
and more significant as the classification complex increases.
• The performance of each algorithm degrades with the increase of classification complexity.
However, the degenerations of MIAMB/MKIAMB are slower than that of IAMB/KIAMB.
To compare IAMB/KIAMB and MIAMB/MKIAMB detailedly, we take the results of IAMB/KIAMB-I
and MIAMB/MKIAMB-III to make a further analysis. For the 4-class prediction problem, denote the
results of IAMB-I and MIAMB-III by τ
(IAMB)
i
and τ
(MIAMB)
i
for i = 1, · · · , n, and draw them in (a) of
Figure 16. Put
I1 =
{
i ∈ {1, · · · , n} : τ
(IAMB)
i > τ(MIAMB)
i
}
,
I2 =
{
i ∈ {1, · · · , n} : τ
(IAMB)
i = τ
(MIAMB)
i
}
,
I3 =
{
i ∈ {1, · · · , n} : τ
(IAMB)
i < τ(MIAMB)
i
}
.
Draw the scatters of τ
(IAMB)
i
and τ
(MIAMB)
i
for i ∈ Ij
in (aj) of Figure 16. In addition, the information
about (mean ± std) of IAMB-I vs that of MIAMB-III is annotated in each title. For other three K-class
prediction problems (K = 8, 16, 32), repeat the above steps to get the scatters drawn in the other
subplots of Figure 16. Similarly, Figure 17 draws the results of KIAMB-I versus MKIAMB-III.
27
Liu and Liu
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a) 4-Class: All Cases
(0.9295±0.0820) vs
(0.9507±0.0572)
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a1) 4-Class: Case 1
(0.9525±0.0402) vs
(0.9355±0.0509)
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a2) 4-Class: Case 2
(0.9682±0.0530) vs
(0.9682±0.0530)
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a3) 4-Class: Case 3
(0.8624±0.0862) vs
(0.9279±0.0566)
0.6
0.8
1
IAMB MIAMB
Accuracy
(b) 8-Class: All Cases
(0.9016±0.1025) vs
(0.9348±0.0771)
0.6
0.8
1
IAMB MIAMB
Accuracy
(b1) 8-Class: Case 1
(0.9264±0.0734) vs
(0.9022±0.1034)
0.6
0.8
1
IAMB MIAMB
Accuracy
(b2) 8-Class: Case 2
(0.9746±0.0380) vs
(0.9746±0.0380)
0.6
0.8
1
IAMB MIAMB
Accuracy
(b3) 8-Class: Case 3
(0.8457±0.1049) vs
(0.9139±0.0802)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(c) 16-Class: All Cases
(0.8878±0.1056) vs
(0.9256±0.0750)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(c1) 16-Class: Case 1
(0.9369±0.0525) vs
(0.9259±0.0592)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(c2) 16-Class: Case 2
(0.9728±0.0403) vs
(0.9728±0.0403)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(c3) 16-Class: Case 3
(0.8455±0.1055) vs
(0.9055±0.0793)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(d) 32-Class: All Cases
(0.8683±0.1132) vs
(0.9242±0.0674)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(d1) 32-Class: Case 1
(0.9559±0.0432) vs
(0.9441±0.0460)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(d2) 32-Class: Case 2
(0.9779±0.0269) vs
(0.9779±0.0269)
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(d3) 32-Class: Case 3
(0.8326±0.1095) vs
(0.9097±0.0695)
Figure 16: Balanced accuracy results on IAMB/MIAMB algorithms applied to 200 K-class prediction
problems (K = 4, 8, 16, 32): the subplots in the first column for all the 200 results; the
ones in the second column for the results that IAMB performs better than MIAMB; the ones
in the third column for the results that IAMB and MIAMB perform equally well; the ones
in the last column for the results that MIAMB performs better than IAMB.
28
Markov Blanket and Markov Boundary of Multiple Variables
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(a) 4-Class: All Cases
(0.9283±0.0852) vs
(0.9501±0.0589)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(a1) 4-Class: Case 1
(0.9515±0.0440) vs
(0.9333±0.0576)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(a2) 4-Class: Case 2
(0.9683±0.0536) vs
(0.9683±0.0536)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(a3) 4-Class: Case 3
(0.8591±0.0914) vs
(0.9269±0.0584)
0.6
0.8
1
KIAMB MKIAMB
Accuracy
(b) 8-Class: All Cases
(0.9007±0.1055) vs
(0.9340±0.0786)
0.6
0.8
1
KIAMB MKIAMB
Accuracy
(b1) 8-Class: Case 1
(0.9261±0.0732) vs
(0.9022±0.1005)
0.6
0.8
1
KIAMB MKIAMB
Accuracy
(b2) 8-Class: Case 2
(0.9754±0.0358) vs
(0.9754±0.0358)
0.6
0.8
1
KIAMB MKIAMB
Accuracy
(b3) 8-Class: Case 3
(0.8436±0.1095) vs
(0.9119±0.0836)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(c) 16-Class: All Cases
(0.8886±0.1062) vs
(0.9263±0.0755)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(c1) 16-Class: Case 1
(0.9393±0.0512) vs
(0.9283±0.0598)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(c2) 16-Class: Case 2
(0.9725±0.0403) vs
(0.9725±0.0403)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(c3) 16-Class: Case 3
(0.8465±0.1068) vs
(0.9064±0.0803)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(d) 32-Class: All Cases
(0.8687±0.1140) vs
(0.9239±0.0688)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(d1) 32-Class: Case 1
(0.9536±0.0468) vs
(0.9411±0.0507)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(d2) 32-Class: Case 2
(0.9766±0.0287) vs
(0.9766±0.0287)
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(d3) 32-Class: Case 3
(0.8337±0.1112) vs
(0.9099±0.0712)
Figure 17: Balanced accuracy results on KIAMB/MKIAMB applied to 200 K-class prediction problems
(K = 4, 8, 16, 32): the subplots in the first column for all the 200 results; the ones in
the second column for the results that KIAMB performs better than MKIAMB; the ones in
the third column for the results that KIAMB and MKIAMB perform equally well; the ones
in the last column for the results that MKIAMB performs better than KIAMB.
29
Liu and Liu
0.5
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a) 64-Class: All Cases
(0.7897±0.1376) vs
(0.8983±0.0792)
0.5
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a1) 64-Class: Case 1
(0.9514±0.0723) vs
(0.9433±0.0706)
0.5
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a2) 64-Class: Case 2
(0.9808±0.0284) vs
(0.9808±0.0284)
0.5
0.6
0.7
0.8
0.9
1
IAMB MIAMB
Accuracy
(a3) 64-Class: Case 3
(0.7632±0.1262) vs
(0.8886±0.0780)
0.5
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(b) 64-Class: All Cases
(0.7885±0.1430) vs
(0.8977±0.0810)
0.5
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(b1) 64-Class: Case 1
(0.9557±0.0598) vs
(0.9474±0.0582)
0.5
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(b2) 64-Class: Case 2
(0.9823±0.0251) vs
(0.9823±0.0251)
0.5
0.6
0.7
0.8
0.9
1
KIAMB MKIAMB
Accuracy
(b3) 64-Class: Case 3
(0.7614±0.1324) vs
(0.8874±0.0803)
Figure 18: Balanced accuracy results on IAMB/MIAMB and KIAMB/MKIAMB applied to 100 64-class
prediction problems: MIAMB/MKIAMB can improve IAMB/KIAMB substantially.
Figure 16 indicates that: (i) In most cases, MIAMB can improve IAMB to various degrees: MIAMB
has higher mean values of balanced accuracy and smaller std values as well. Although there are a
few of situations in which IAMB performs better than MIAMB, the difference of performance between
them is very slight. In addition, there are some situations in which the two algorithms perform
equally well (with very high mean and small std). (ii) MIAMB is more resistant to the classification
complexity than IAMB: the improvements of MIAMB over IAMB become more and more visible with
the increase of K (from 4 to 32). Figure 17 shows similar conclusions.
In brief, an FS problem for multi-class prediction can be transformed into a problem of MB
discovery for multiple targets, and then get a more efficient solution. This idea may be particularly
useful when the classification complexity is high or very high. To check this imagination, we apply
the same procedures to 100 64-class prediction problems (also taken from the HIVA data set). The
results are summarized in Figure 18, in which (a) and (aj) are for IAMB/MIAMB while (b) and (bj)
are for KIAMB/MKIAMB, j = 1, 2, 3. By the figure, the improvement (nearly 14% on accuracy) of
MIAMB/MKIAMB algorithms over IAMB/KIAMB is really desirable in the case of high classification
complexity.
Finally, we apply LibSVM and the random forest (RF) algorithm (Breiman, 2001) to the whole
HIVA data without any FS, considering LibSVM is of high classification performance while RF is
a state-of-the-art FS algorithm. The results can be served as a baseline to see why FS (or equivalently, MB discovery) is necessary for a complex classification problem. Recall that HIVA contains
many unbalanced variables, which enhance the classification complexity. Figure 19 draws the 95%
confidence bands of LibSVM and FS, respectively.
By the figure, it follows that:
30
Markov Blanket and Markov Boundary of Multiple Variables
4 8 16 32 64
0.50
0.59
0.68
0.77
LibSVM Based on Whole Data
Number of Target Classes
Accuracy
4 8 16 32 64
0.73
0.81
0.87
0.97
RF Based on Whole Data
Number of Target Classes
Accuracy
4 8 16 32 64
0.87
0.90
0.93
0.96
LibSVM Based on MIAMB
Number of Target Classes
Accuracy
4 8 16 32 64
0.87
0.90
0.93
0.96
LibSVM Based on MKIAMB
Number of Target Classes
Accuracy
Figure 19: The 95% confidence bands of LibSVM and RF.
• Without any FS, LibSVM performs undesirably in all situations. This may be because too
many noisy variables can lead to masking effects upon those unbalanced features such that
LibSVM cannot classify targets expectedly. This shows the necessity of FS. In other words,
LibSVM may not be suitable for some high-dimension problems, especially when there are
many unbalanced variables.
• Without any FS, RF performs quite well when the classification complexity is not very high.
However, with the increase of classification complexity, the performance of RF decreases
gradually and then sharply. In other words, RF may not be suitable for those problems with
too high complexity, especially when there are many unbalanced variables.
To observe why this happens, we check the results and then randomly take some targets (with
extraordinarily low accuracy) to implement LibSVM and RF again by appropriately adjusting the
algorithmic setting of LibSVM and increasing the number of trees of RF from 100 to 1000. However,
the results change very little.
To make an intuitive comparison, the 95% confidence bands of MIAMB/MKIAMB-based LibSVM
are also drawn in Figure 19. As seen, all methods degenerate with the increase of the classification
complexity, but our methods degenerate far slower than LibSVM/RF based on the whole data. In a
word, MB discovery (or equivalently, FS) is important to make classification, especially when the
problem is of high dimension and of high complexity.
31
Liu and Liu
7. Concluding Remarks
In this paper, we considered the problem of Mb and MB of multiple variables. We first addressed
their additivity under the local intersection assumption, and then studied this problem in the general
case. The two algorithms that we proposed , MIAMB and MKIAMB, were proven to be correct under
the local composition assumption with respect to single targets. The benchmarking study based on
six synthetic BNs showed that MIAMB and MKIAMB have higher accuracies and lower complexities
than the existing IAMB and KIAMB.
Before ending this paper, we present four concluding remarks as follows:
(i) The first remark concerns a method of using MIAMB and MKIAMB to find an MB for a single
variable. Such an idea is motivated by the following two aspects: (a) the local composition
assumption may be violated in practice, and if this is the case, IAMB and KIAMB may perform
not very well in MB discovery even for a single variable; (b) randomness of a data set may
result in a violation to the assumption that all the CI tests involved are correct. Naturally, it is
useful to take a remedy for these two situations. One remedial strategy is described as follows:
letting T ∈ V be the target variable, and M1 be a potential MB discovered by IAMB or KIAMB,
take T0 ≜ arg maxX∈M1
f
(ℓ)
D
(T; X | M1 \{X}) as a co-target of T for ℓ = 1 or 2 or 3; then, employ
MIAMB or MKIAMB to find a potential MB for {T, T0}, saying M2. Finally, refine {T0} ∪ M2 to
obtain M, by virtue of the shrinking phase of IAMB or KIAMB, since this phase needs no the
local composition precondition.
(ii) Our MIAMB and MKIAMB contain an ordering τ, which may affect the RT and even the WA or
WP. A question arises here: is there an optimal selection of τ such that MIAMB or MKIAMB has
the highest accuracy and the lowest complexity?
(iii) All the considered algorithms (IAMB, KIAMB, MIAMB, and MKIAMB) need the local composition
assumption to theoretically guarantee their correctness. However, this precondition may be
violated in practice and in this case only an approximate MB can be obtained by means of one
of the above algorithms. Subsection 4.1 provides a potential remedy. We note that MIAMB and
MKIAMB transform the problem of MB discovery for multiple targets into the ones for single
targets. This idea provides a facilitation to use some stochastic optimization methods such as
the particle swarm optimization algorithm (Kennedy and Eberhart, 1995, 1997).
(iv) In Subsection 3.3, we provided a method for MB discovery of a complex single variable based
on an MB discovery of some simple multiple variables. Let us now explain why this transformation method is efficient. With the notations used in Subsection 3.3, let
MBT = MBT
(d) ≜ M.
Then, a variable X can enter and stay in M (in the sense of MBT ) if T ̸y X | M \ {X}. On
the other hand, by Theorem 5, X can enter and stay in M (in the sense of MBT
(d) ) only if
T
(d)
j
̸y X | M \ {X} holds for some j. That is, we need to test the following two pairs of
hypotheses:
H
(1)
0
: T y X | M \ {X} ↔ H
(1)
1
: T ̸y X | M \ {X};
H
(2)
0
: T
(d)
j y X | M \ {X} ↔ H
(2)
1
: T
(d)
j
̸y X | M \ {X}.
32
Markov Blanket and Markov Boundary of Multiple Variables
Clearly, when T is high-dimensional, the test for H
(1)
0 ↔ H
(1)
1
requires far more data points
than that for H
(2)
0 ↔ H
(2)
1
, since the test statistic for the first pair of hypotheses contains far
more free parameters than that for the second. In addition, the transformation from T to T
(d)
can be easily made, with almost no running time. This explains why Theorem 5 is useful.
