There has been considerable interest in making Bayesian inference more scalable. In
big data settings, most of the focus has been on reducing the computing time per iteration rather than reducing the number of iterations needed in Markov chain Monte Carlo
(MCMC). This article considers data augmentation MCMC (DA-MCMC), a widely used
technique. DA-MCMC samples tend to become highly autocorrelated in large samples,
due to a mis-calibration problem in which conditional posterior distributions given augmented data are too concentrated. This makes it necessary to collect very long MCMC
paths to obtain acceptably low MC error. To combat this inefficiency, we propose a family
of calibrated data augmentation algorithms, which appropriately adjust the variance of
conditional posterior distributions. A Metropolis-Hastings step is used to eliminate bias
in the stationary distribution of the resulting sampler. Compared to existing alternatives,
this approach can dramatically reduce MC error by reducing autocorrelation and increasing
the effective number of DA-MCMC samples per unit of computing time. The approach is
simple and applicable to a broad variety of existing data augmentation algorithms. We
focus on three popular generalized linear models: probit, logistic and Poisson log-linear.
Dramatic gains in computational efficiency are shown in applications.
Keywords: Bayesian Probit, Biased subsampling, Big n, Data augmentation, Log-linear
model, Logistic regression, Maximal correlation, Polya-Gamma
1. Introduction
With the deluge of data in many modern application areas, there is pressing need for scalable
computational algorithms for inference from such data, including uncertainty quantification
(UQ). Somewhat surprisingly, even as the volume of data increases, uncertainty often remains sizable. Examples in which this phenomenon occurs include financial fraud detection
(Ngai et al., 2011), disease mapping (Wakefield, 2007) and online click-through tracking
(Wang et al., 2010). Bayesian approaches provide a useful paradigm for quantifying uncertainty in these and other settings.
The standard approach to Bayesian posterior computation is Markov chain Monte Carlo
(MCMC) and related sampling algorithms. However, conventional MCMC algorithms often
scale poorly in problem size and complexity. Due to its sequential nature, the computational
cost of MCMC is the product of two factors: the evaluation cost at each sampling iteration
and the total number of iterations needed to obtain an acceptably low Monte Carlo (MC)
error. While a substantial literature has developed focusing on decreasing computational
cost per iteration in ‚Äúbig data‚Äù (large sample) settings (Minsker et al. (2017); Maclaurin
and Adams (2015); Srivastava et al. (2015); Conrad et al. (2016) among others), there
has been less focus on reducing the required number of MCMC iterations. This contrasts
with a historical focus in the statistics and probability literature on improving mixing and
convergence of MCMC in more traditional small to moderate sample size problems, and
suggests the opportunity for improved performance in big data settings through a renewed
focus on improving mixing.
A major concern in applying MCMC algorithms in big data problems is that the level of
autocorrelation in the MCMC path may increase with the size of the data. Markov chains
with high autocorrelation have low effective sample size (ESS) per unit computational time,
which we refer to informally as the slow mixing problem. The ESS compares the asymptotic
variance of the MCMC time averaging estimate to a gold standard Monte Carlo algorithm
that collects independent samples. For example, if the number of effective samples in 1,000
MCMC iterations is only 10, then the MCMC algorithm will need to be run 100 times as
long as an ordinary MC algorithm to obtain the same MC error for time averages. Such a
scenario is not unusual in big data problems, leading MCMC algorithms to face a double
burden, with the time per iteration increasing and it becoming necessary to collect more
iterations as sample size increases.
This double burden has led many members of the machine learning community to abandon MCMC in favor of more easily scalable alternatives, such as variational approximations.
Unfortunately, these approaches typically lack theoretical guarantees and often badly underestimate posterior uncertainty. Hence, there has been substantial interest in recent years in
designing scalable MCMC algorithms. The focus of this paper is a popular and broad class
of Data Augmentation (DA)-MCMC algorithms. DA-MCMC algorithms are used routinely
in many classes of models, with the algorithms of Albert and Chib (1993) for probit models
and Polson et al. (2013) for logistic models being particularly popular. Our focus is on
improving the performance of such algorithms in big data settings in which poor scalability
occurs both because of high cost per iteration and deterioration of mixing as sample size
increases. We focus here on the slow mixing problem.
2
Calibrated Data Augmentation
Johndrow et al. (2018) demonstrate that popular DA-MCMC algorithms have small effective sample sizes in large data settings involving imbalanced data. For example, data may
be binary with a high proportion of zeros. A key insight is that this problem results from
a discrepancy in the rates at which Gibbs step sizes and the width of the high-probability
region of the posterior converge to zero as n increases. In particular, the conditional posterior given the augmented data may simply be too concentrated relative to the marginal
posterior, with this problem amplified as the data sample size increases. There is a rich
literature on methods for accelerating mixing in DA-MCMC algorithms using tricks ranging
from reparameterization to parameter-expansion (Liu and Wu, 1999; Meng and Van Dyk,
1999; Papaspiliopoulos et al., 2007). However, we find that such approaches fail to address the miscalibration problem and have no impact on the worsening mixing rate with
increasing data sample size n.
This article proposes a general new class of algorithms that addresses the miscalibration of step sizes in DA. The idea underlying these calibrated DA (CDA) algorithms is to
introduce auxiliary parameters that change the variance of full conditional distributions for
one or more parameters. These auxiliary parameters can adapt with the data sample size
n to correct the typical step sizes of the CDA algorithm to match the rate at which the
high probability region of the posterior contracts as n increases. In general, the invariant measure of CDA-MCMC ‚Äì which typically does exist and is unique ‚Äì differs from the
posterior of interest. Thus, CDA-MCMC is a computationally more efficient perturbation
of the original Markov chain, and the bias can be eliminated using Metropolis-Hastings.
Compared to other adaptive Metropolis-Hastings algorithms, which often require carefully
chosen multivariate proposals and complicated adaptation with multiple chains (Tran et al.,
2016), CDA-MCMC only requires a simple modification to Gibbs sampling steps to generate proposals. We show the auxiliary parameters can be efficiently adapted for each type of
data augmentation via minimizing the difference between Fisher information of conditional
and marginal distributions.
2. Calibrated Data Augmentation
Data augmentation Gibbs samplers alternate between sampling latent data z from their
conditional posterior distribution given model parameters Œ∏ and observed data y, and sampling parameters Œ∏ given z and y; either of these steps can be further broken down into
a series of full conditional sampling steps but we focus for simplicity on algorithms of the
form:
z | Œ∏, y ‚àº œÄ(z; Œ∏, y) (1)
Œ∏ | z, y ‚àº f(Œ∏; z, y),
where f belongs to a location-scale family, such as the Gaussian. Popular data augmentation algorithms are designed so that both of these sampling steps can be conducted
easily and efficiently; e.g., sampling the latent data for each subject independently and
then drawing Œ∏ simultaneously (or at least in blocks) from a multivariate Gaussian or other
standard distribution. This effectively avoids the need for tuning, which is a major issue
for Metropolis-Hastings algorithms, particularly when Œ∏ is high-dimensional. Data augmentation algorithms are particularly common for generalized linear models (GLMs), with
3
Duan, Johndrow and Dunson
E(yi
| xi
, Œ∏) = g
‚àí1
(xiŒ∏) and a conditionally Gaussian prior distribution chosen for Œ∏. We focus in particular on Poisson log-linear, binomial logistic, and binomial probit as motivating
examples.
Consider a Markov kernel K((Œ∏, z); ¬∑) with invariant measure Œ† and update rule of the
form (1), and a Markov chain (Œ∏t
, zt) on a state space Œò √ó Z evolving according to K.
We will abuse notation in writing Œ†(dŒ∏) = R
z‚ààZ Œ†(dŒ∏, dz). The lag-1 autocorrelation for
a function h : Œò ‚Üí R at stationarity can be expressed as the Bayesian fraction of missing
information (Papaspiliopoulos et al. (2007), Rubin (2004), Liu (1994b))
Œ≥g = 1 ‚àí
E[var(h(Œ∏) | z)]
var(h(Œ∏)) , (2)
where the integrals in the numerator are with respect to Œ†(dŒ∏, dz) and in the denominator
with respect to Œ†(dŒ∏). Let
L2(Œ†) = 
h : Œò ‚Üí R,
Z
Œ∏‚ààŒò
{h(Œ∏)}
2Œ†(dŒ∏) < ‚àû

be the set of real-valued, Œ† square-integrable functions. The maximal autocorrelation
Œ≥ = sup
h‚ààL2(Œ†)
Œ≥h = 1 ‚àí inf
h‚ààL2(Œ†)
E[var(h(Œ∏) | z)]
var(h(Œ∏))
is equal to the geometric convergence rate of the data augmentation Gibbs sampler (Liu
(1994b)). For h(Œ∏) = Œ∏j a coordinate projection, the numerator of the last term of (2)
is, informally, the average squared step size for the augmentation algorithm at stationarity
in direction j, while the denominator is the squared width of the bulk of the posterior in
direction j. Consequently, Œ≥ will be close to 1 whenever the average step size at stationarity
is small relative to the width of the bulk of the posterior.
The purpose of CDA is to introduce additional parameters that allow us to control
the step size relative to the posterior width ‚Äì roughly speaking, the ratio in (2) ‚Äì with
greater flexibility than reparametrization or parameter expansion. The flexibility gains
are achieved by allowing the invariant measure to change as a result of the introduced
parameters. The additional parameters, which we denote (r, b), correspond to a collection
of reparametrizations, each of which defines a proper (but distinct) likelihood Lr,b(Œ∏; y), and
for which there exists a Gibbs update rule of the form (1). In general, r is a vector of scale
parameters that are tuned to increase E[var(h(Œ∏) | z)]{var(h(Œ∏))}
‚àí1 ‚Äì usually for coordinate
projections h(Œ∏) = Œ∏j ‚Äì although the exact way in which they enter the likelihood and
corresponding Gibbs update depend on the application; b are location parameters that shift
the high posterior region of Lr,b(Œ∏; y) to better approximate L(Œ∏; y). The reparametrization
also has the property that L1,0(Œ∏; y) = L(Œ∏; y), the original likelihood. The resulting Gibbs
sampler, which we refer to as CDA Gibbs, has Œ∏-marginal invariant measure Œ†r,b(Œ∏; y) ‚àù
Lr,b(Œ∏; y)Œ†0
(Œ∏), where Œ†0
(Œ∏) is the prior. Ultimately, we are interested in Œ†1,0(Œ∏; y), so we
use CDA Gibbs as an efficient proposal for Metropolis-Hastings. That is, we propose Œ∏
‚àó
from q(Œ∏
‚àó
; Œ∏) with
q(Œ∏
‚àó
; Œ∏) = Z
z‚ààZ
œÄr,b(z; Œ∏, y)fr,b(Œ∏
‚àó
; z, y)dz, (3)
4
Calibrated Data Augmentation
where œÄr,b and fr,b denote the conditional densities of z and Œ∏ in the Gibbs sampler with
invariant measure Œ†r,b. By tuning (r, b) during an adaptation phase to reduce the autocorrelations and increase the Metropolis-Hastings acceptance rate, we can obtain a computationally efficient algorithm. Tuning is facilitated by the fact that the MH acceptance ratios
using this proposal kernel have a convenient form, which is a nice feature of using Gibbs to
generate MH proposals.
Remark 1 The CDA MH acceptance ratio is given by
Œ±(Œ∏, Œ∏‚àó
) = min 
1,
L(Œ∏
‚àó
; y)Œ†0
(Œ∏
‚àó
)q(Œ∏; Œ∏
‚àó
)
L(Œ∏; y)Œ†0(Œ∏)q(Œ∏
‚àó; Œ∏)

= min 
1,
L(Œ∏
‚àó
; y)Lr,b(Œ∏; y)
L(Œ∏; y)Lr,b(Œ∏
‚àó; y)

. (4)
A general strategy for tuning is given in Section 4.
We give a basic convergence guarantee that holds for CDA MH under weak assumptions
on Lr,b, which is based on Roberts and Smith (1994). Basically, one needs Œ†(¬∑)  Œ†r,b(¬∑)
for all r, b, where for two probability measures ¬µ, ŒΩ, ¬µ(¬∑)  ŒΩ(¬∑) means ¬µ is absolutely
continuous with respect to ŒΩ.
Remark 2 (Ergodicity) Assume that Œ†(dŒ∏) and Œ†r,b(dŒ∏) have densities with respect to
Lebesgue measure on R
p
, and that Kr,b((Œ∏, z); (Œ∏
0
, z0
)) > 0 ‚àÄ ((Œ∏, z),(Œ∏
0
, z0
)) ‚àà (Œò√ó Z)√ó(Œò√ó
Z). Then,
‚Ä¢ For fixed r, b, CDA Gibbs is ergodic with invariant measure Œ†r,b(dŒ∏, dz).
‚Ä¢ A Metropolis-Hastings algorithm with proposal kernel qr,b(Œ∏
0
; Œ∏) as defined in (3) with
fixed r, b is ergodic with invariant measure Œ†(dŒ∏).
Proofs are located in the Appendix.
2.1. Initial Example: Probit with Intercept Only
To illustrate the CDA algorithm, we first present a toy example of the probit regression
with intercept only.
yi ‚àº Bernoulli(pi), pi = Œ¶(Œ∏) i = 1, . . . , n
and improper prior Œ†0
(Œ∏) ‚àù 1. The data augmentation algorithm (Tanner and Wong, 1987;
Albert and Chib, 1993) is based on the following integral
L(yi
; Œ∏) =  R ‚àû
0
f(zi
; Œ∏, 1)dzi
if yi = 1
R 0
‚àí‚àû f(zi
; Œ∏, 1)dzi
if yi = 0 i = 1, . . . , n
where f(z; ¬µ, œÉ2
) is the density for normal distribution No(¬µ, œÉ2
).
This leads to the update rule
zi
| Œ∏, yi ‚àº

No[0,‚àû)
(Œ∏, 1) if yi = 1
No(‚àí‚àû,0](Œ∏, 1) if yi = 0 i = 1, . . . , n
5
Duan, Johndrow and Dunson
Œ∏ | z, y ‚àº No
n
‚àí1X
i
zi
, n‚àí1
!
,
where the subscript in No[a,b]
(¬µ, œÉ2
) denotes the truncation to the interval [a, b]. Johndrow
et al. (2018) show that when P
i
yi = 1, var(Œ∏t
| Œ∏t‚àí1) is approximately n
‚àí1
log n, while
the width of the high probability region of the posterior is order (log n)
‚àí1
, leading to slow
mixing.
We introduce a scale parameter ri
in the update for zi
, and adjust the conditional mean
by a location parameter bi
. This is equivalent to changing the scale of zi
| Œ∏, yi from 1 to ri
and the mean from Œ∏ to Œ∏ + bi
. These adjustments yield
Pr(yi = 1|Œ∏, ri
, bi) = Z ‚àû
0
1
‚àö
2œÄri
exp 
‚àí
(zi ‚àí Œ∏ ‚àí bi)
2
2r
2
i

dzi
= Œ¶
Œ∏ + bi
‚àö
ri

. (5)
In this simple example, we set the tuning parameters to be all the same: ri = r0 and bi = b0
over i = 1, . . . , n, with r0 and b0 two scalars. This leads to the modified data augmentation
algorithm
zi
| Œ∏, yi ‚àº

No[0,‚àû)
(Œ∏ + b0, r0) if yi = 1
No(‚àí‚àû,0](Œ∏ + b0, r0) if yi = 0 i = 1, . . . , n (6)
Œ∏ | z, y ‚àº No
n
‚àí1X
i
(zi ‚àí b0), n‚àí1
r0
!
.
To achieve step sizes consistent with the width of the high posterior probability region,
we need n
‚àí1
r0 ‚âà (log n)
‚àí1
, so r0 ‚âà n/ log n. To preserve the original target, we use (6) to
generate an MH proposal Œ∏
‚àó
. By Remark 1, the MH acceptance probability is given by (4)
with Lr,b(Œ∏; yi) = Œ¶
(Œ∏ + b0)r0
‚àí1/2
yiŒ¶

‚àí (Œ∏ + b0)r0
‚àí1/2
(1‚àíyi)
and L(Œ∏; yi) = L1,0(Œ∏; yi).
Setting r0 = 1 and b0 = 0 leads to acceptance rate of 1, which corresponds to the original
Gibbs sampler.
To illustrate, we consider P
i
yi = 1 and n = 104
. Letting r0 = n/ log n, we then choose
b0 to increase the acceptance rate in the MH step. In this simple example, it is easy to
compute a ‚Äúgood‚Äù value of b0, since b0 = ‚àí3.7(‚àö
r ‚àí 1) results in Pr(yi = 1) = Œ¶(‚àí3.7) =
n
‚àí1 P
i
yi ‚âà 10‚àí4
in the proposal distribution, centering the proposals near the MLE for pi
.
We perform computation for these data with different values of r0 ranging from r0 = 1
to r0 = 5, 000, with r0 = 1, 000 ‚âà n/ log n corresponding to the theoretically optimal value.
Figure 1(a) plots autocorrelation functions (ACFs) for these different samplers without MH
adjustment. Autocorrelation is very high even at lag 40 for r0 = 1, while increasing r0 leads
to dramatic improvements in mixing. There are no further gains in increasing r0 from the
theoretically optimal value of r0 = 1, 000 to r0 = 5, 000. Figure 1(b) shows kernel-smoothed
density estimates of the posterior of Œ∏ without MH adjustment for different values of r0
and based on long chains to minimize the impact of Monte Carlo error; the posteriors are
all centered on the same values but with variance increasing somewhat with r0. With MH
adjustment such differences are removed; the MH step has acceptance probability close to
one for r0 = 10 and r0 = 100, about 0.6 for r0 = 1, 000, and 0.2 for r0 = 5, 000.  
Calibrated Data Augmentation
0.00
0.25
0.50
0.75
1.00
0 10 20 30 40
r
1
10
100
1000
5000
-0.25
Lag
ACF
(a) ACF for CDA without MH
adjustment.
0.0
0.5
1.0
1.5
‚àí8 ‚àí6 ‚àí4 ‚àí2 0
theta
density
r
1
10
100
1000
5000
(b) Posterior density estimates
without MH adjustment.
‚àí0.25
0.00
0.25
0.50
0.75
1.00
0 10 20 30 40
Lag
ACF
r
1
10
100
1000
5000
(c) ACF for CDA with MH adjustment
Figure 1: Autocorrelation functions (ACFs) and kernel-smoothed density estimates for different CDA samplers in intercept-only probit model.
We also study a common hierarchical Gaussian example in appendix C.
3. Specific Algorithms
In this section, we describe CDA algorithms for general probit and logistic regression.
3.1. Probit Regression
Consider the probit regression:
yi ‚àº Bernoulli(pi), pi = Œ¶(xiŒ∏) i = 1, . . . , n
with improper prior Œ†0
(Œ∏) ‚àù 1. The data augmentation sampler (Tanner and Wong, 1987;
Albert and Chib, 1993) has the update rule
zi
| Œ∏, xi
, yi ‚àº

No[0,‚àû)
(xiŒ∏, 1) if yi = 1
No(‚àí‚àû,0](xiŒ∏, 1) if yi = 0 i = 1, . . . , n
Œ∏ | z, x, y ‚àº No((X0X)
‚àí1X0
z,(X0X)
‚àí1
).
Liu and Wu (1999) and Meng and Van Dyk (1999), among others, previously studied this
algorithm and proposed to rescale Œ∏ through parameter expansion. However, this modification does not impact the conditional variance of Œ∏ and thus does not directly increase
typical step sizes.
Our approach is fundamentally different, since we directly adjust the conditional variance. Similar to the intercept only model, we modify var(Œ∏|z) by changing the scale of each
zi
. This yields the update rule
zi
| Œ∏, xi
, yi ‚àº

No[0,‚àû)
(xiŒ∏ + bi
, ri) if yi = 1
No(‚àí‚àû,0](xiŒ∏ + bi
, ri) if yi = 0 i = 1, . . . , n (7)
Œ∏ | z, X ‚àº No((X0R
‚àí1X)
‚àí1X0R
‚àí1
(z ‚àí b),(X0R
‚àí1X)
‚àí1
),
where R = diag(r1, . . . , rn), b = (b1, . . . , bn)
0
. Under the Bernoulli likelihood, we have
Pr(yi = 1|Œ∏, xi
, ri
, bi) = Z ‚àû
0
1
‚àö
2œÄri
exp 
‚àí
(zi ‚àí xiŒ∏ ‚àí bi)
2
2ri

dzi
7
Duan, Johndrow and Dunson
= Œ¶
xiŒ∏ + bi
‚àö
ri

. (8)
For fixed r = (r1, . . . , rn) and b = (b1, . . . , bn), (8) defines a proper Bernoulli likelihood for
yi conditional on parameters, and therefore the transition kernel Qr,b((Œ∏, z); ¬∑) defined by
the Gibbs update rule in (7) would have a unique invariant measure for fixed r, b, which we
denote Œ†r,b(Œ∏, z | y).
For insight into the relationship between r and step size, consider the Œ∏-marginal autocovariance in a Gibbs sampler evolving according to Kr,b
covr,b(Œ∏t
| Œ∏t‚àí1, X, z, y)
=(X0R
‚àí1X)
‚àí1 + (X0R
‚àí1X)
‚àí1X0R
‚àí1
cov(z ‚àí b|R)R
‚àí1X(X0R
‚àí1X)
‚àí1
‚â•(X0R
‚àí1X)
‚àí1
.
In the special case where ri = r0 for all i, we have
covr,b(Œ∏t
| Œ∏t‚àí1, X, z, y) ‚â• r0(X0X)
‚àí1
,
so that all of the conditional variances are increased by at least a factor of r0. This holds
uniformly over the entire state space, so it follows that
EŒ†r,b [var(Œ∏j | z)] ‚â• r0EŒ†[var(Œ∏j | z)].
The key to CDA is to choose r, b to make EŒ†r,b [var(Œ∏j | z)] close to varŒ†r,b (Œ∏j | z), while
additionally maximizing the MH acceptance probability. We defer the details of tuning
algorithm for r, b to the next section.
For illustration, we consider a simulation study for probit regression with an intercept
and two predictors xi,1, xi,2 ‚àº No(1, 1), with Œ∏ = (‚àí5, 1, ‚àí1)0
, generating P
i
yi ‚âà 20 among
n = 10, 000. The Albert and Chib (1993) DA algorithm mixes slowly (Figure 2(a) and
2(b)). We also show the results of the parameter expansion algorithm (PX-DA) proposed
by Liu and Wu (1999). PX-DA only mildly reduces the correlation, as it does not solve the
small step size problem. After tuning, CDA reaches a satisfactory acceptance rate of 0.6
and leads to dramatically better mixing.
8
Calibrated Data Augmentation
‚àí4.5
‚àí5.0
‚àí5.5
‚àí6.0
‚àí4.5
‚àí5.0
‚àí5.5
‚àí6.0
‚àí4.5
‚àí5.0
‚àí5.5
‚àí6.0
DA PX‚àíDA CDA
0 100 200 300 400 500
Iteration
(a) Traceplot for the original DA, parameter expanded DA and CDA algorithms.
0.00
0.25
0.50
0.75
1.00
0 10 20 30 40 Lag
ACF
Method
DA
PX‚àíDA
CDA
(b) ACF for original DA, parameter expanded
DA and CDA algorithms.
Figure 2: Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement in CDA by correcting the variance mis-match in probit
regression with rare event data, compared with the original (Albert and Chib,
1993) and parameter-expanded methods (Liu and Wu, 1999).
3.2. Logistic Regression
In the second example, we focus on the logistic regression model with
yi ‚àº Bernoulli(pi), pi =
exp(xiŒ∏)
1 + exp(xiŒ∏)
i = 1, . . . , n (9)
and improper prior Œ†0
(Œ∏) ‚àù 1. For this model, Polson et al. (2013) proposed Polya-Gamma
data augmentation:
zi ‚àº PG(1, |xiŒ∏|) i = 1, . . . , n,
Œ∏ ‚àº No
(X0ZX)
‚àí1X0
(y ‚àí 0.5),(X0ZX)
‚àí1

,
where Z = diag(z1, . . . , zn). This algorithm relies on expressing the logistic regression
likelihood as
L(xiŒ∏; yi) = Z ‚àû
0
exp{xiŒ∏(yi ‚àí 1/2)} exp 
‚àí
zi(xiŒ∏)
2
2

PG(zi
| 1, 0)dzi
,
where PG(a1, a2) denotes the density of the Polya-Gamma distribution with parameters
a1, a2, with Ezi = a1/(2a2) tanh(a2/2).
Since our goal is to increase the conditional variance (X0ZX)
‚àí1
, we can achieve this
stochastically by reducing the mean Ezi
. We replace PG(zi
| 1, 0) with PG(zi
| ri
, 0) in
the step for updating the latent data. Adding the location term bi to the linear predictor
Œ∑i = xiŒ∏ leads to
Lr,b(xiŒ∏; yi) = Z ‚àû
0
exp{(xiŒ∏ + bi)(yi ‚àí ri/2)} exp 
‚àí
zi(xiŒ∏ + bi)
2
2

PG(zi
| ri
, 0)dzi
=
exp{(xiŒ∏ + bi)yi}
{1 + exp(xiŒ∏ + bi)}
ri
, (10)
 
Duan, Johndrow and Dunson
and the update rule for the CDA Gibbs sampler is then
zi ‚àº PG(ri
, |xiŒ∏ + bi
|) i = 1, . . . , n,
Œ∏
0 ‚àº No
(X0ZX)
‚àí1X0
(y ‚àí r/2 ‚àí Zb),(X0ZX)
‚àí1

,
where r = (r1, . . . , rn)
0 and b = (b1, . . . , bn)
0
. We again defer the tuning details for r and b
to the next section.
For illustration, we use a two-parameter intercept-slope model with xi1
iid‚àº No(0, 1) and
Œ∏ = (‚àí8, 1)0
. With n = 105
, we obtain rare outcome data with Pyi ‚âà 50. In CDA, after
tuning, it reaches an acceptance rate of 0.8. Shown in Figure 3, DA mixes slowly, exhibiting
strong autocorrelation even at lag 40, while CDA has dramatically better mixing. DA CDA
0 100 200 300 400 500
‚àí7
‚àí8
‚àí9
‚àí10
‚àí7
‚àí8
‚àí9
‚àí10
Iteration
(a) Traceplots for DA and CDA.
0.00
0.25
0.50
0.75
1.00
0 10 20 30 40
Lag
ACF
Method
DA
CDA
(b) ACF for DA and CDA.
Figure 3: Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement of CDA in logistic regression with rare event data, compared
with the original DA (Polson et al., 2013).
4. Automatic Tuning of Calibration Parameters
As illustrated in the previous subsection, efficiency of CDA is dependent on good choices
of the calibration parameters r and b. We propose a simple and efficient algorithm for
calculating ‚Äúgood‚Äù values of these parameters utilizing the Fisher information and empirical
MH acceptance rate. Although our choice of calibration parameters relies on large sample
approximations, we find that this calibration approach also works well for modest sample
size.
Our goal is to adjust the conditional variance under calibration of (r, b) to approximately match the marginal variance under the exact target distribution, while maintaining
a reasonable MH acceptance rate.
1 
Calibrated Data Augmentation
To approximate the marginal variance, we use the inverse of the observed Fisher information (Efron and Hinkley, 1978):
var(Œ∏ | y) ‚âà I‚àí1
(
ÀÜŒ∏)

I(
ÀÜŒ∏)

i,j
=

‚àÇ
‚àÇŒ∏i
log L(Œ∏; y)
  ‚àÇ
‚àÇŒ∏j
log L(Œ∏; y)
 



Œ∏=Œ∏ÀÜ
for i = 1, . . . , p, j = 1, . . . , p, where ÀÜŒ∏ is the Maximum a Posteriori (MAP) estimate of Œ∏.
Recall that the CDA proposal has density
q(Œ∏
‚àó
; Œ∏) = Z
fr,b(Œ∏
‚àó
; z, y)œÄr,b(z; Œ∏, y)dz,
and the conditional variance has lower bound var(Œ∏
‚àó
| Œ∏) ‚â• Ez|Œ∏var(Œ∏
‚àó
| z). We use the
inverse of the observed Fisher information to approximate var(Œ∏
‚àó
| z) via
Ez|Œ∏var(Œ∏
‚àó
| z) ‚âà Ez|Œ∏I
‚àí1
(
ÀÜŒ∏; r, b, z) ‚âà I‚àí1
(
ÀÜŒ∏; r, b, zÀú(
ÀÜŒ∏))

I(
ÀÜŒ∏; r, b, z)

i,j
=

‚àÇ
‚àÇŒ∏‚àó
i
log fr,b(Œ∏
‚àó
; y, z)

‚àÇ
‚àÇŒ∏‚àó
j
log fr,b(Œ∏
‚àó
; y, z)
! 



Œ∏
‚àó=Œ∏ÀÜ
.
Since Ez|Œ∏I
‚àí1
(
ÀÜŒ∏; r, b, z) is often intractable or cumbersome to compute, we instead use the
second approximation, the Fisher information evaluated at Àúz(
ÀÜŒ∏), the conditional mean or
mode of œÄr,b(z;
ÀÜŒ∏, y). The choice between mean and mode depends on which has a closedform expression.
One can now adjust r, b to reduce the distance
d1(r, b) = Dist 
I
‚àí1
(
ÀÜŒ∏), I
‚àí1
(
ÀÜŒ∏; r, b, zÀú(
ÀÜŒ∏))
, (11)
where Dist(M1, M2) is a distance between two matrices, such as kM1 ‚àí M2kF or kM‚àí1
1 ‚àí
M‚àí1
2
kF , the Frobenius norm of the difference.
However, the increase in proposal variance only results in an increase in the variance
of the Metropolis-Hastings transition density so long as the acceptance probability is not
substantially depressed (relative to the DA Gibbs sampler, which has acceptance probability
one). Therefore, one also needs to adjust (r, b) both to optimize the acceptance rate Œ±(Œ∏, Œ∏‚àó
)
and the proposal variance. Considering the average acceptance rate (on the negative-log
scale), with expectation over proposal density q(Œ∏
‚àó
; Œ∏) and posterior œÄ(Œ∏ | y)
EŒ∏|yEŒ∏
‚àó|Œ∏

‚àí log Œ±(Œ∏, Œ∏‚àó
)

=EŒ∏|yEŒ∏
‚àó|zEz|Œ∏ max 
‚àí log L(Œ∏
‚àó
; y)
Lr,b(Œ∏
‚àó; y)
+ log L(Œ∏; y)
Lr,b(Œ∏; y)
, 0

.
To provide tractable computation, we again use the functions evaluated at the conditional
mean or mode to approximate the three expectations. This yields
d2(r, b) = max 
‚àí log L(
ÀúŒ∏
‚àó
(Àúz(
ÀÜŒ∏)); y)
Lr,b(
ÀúŒ∏
‚àó(Àúz(
ÀÜŒ∏)); y)
+ log L(
ÀÜŒ∏; y)
Lr,b(
ÀÜŒ∏; y)
, 0

, (12)
11  
Duan, Johndrow and Dunson
with ÀÜŒ∏ the MAP of Œ∏, Àúz(Œ∏) the mean or mode of œÄr,b(z; Œ∏, y), ÀúŒ∏
‚àó
the mean or mode of
fr,b(Œ∏
‚àó
; z, y).
Combining (11) and (12), this yields the optimal tuning parameters under those two
criteria:
(ÀÜr, ÀÜb) = min
r,b

d1(r, b) + Œªd2(r, b)

. (13)
The optional parameter Œª > 0 allows for differential weighting of the acceptance rate and
variance, although the default Œª = 1 works well for all of our applications.
To facilitate automatic tuning in generic cases, we exploit the automatic differentiation
and optimization software, TensorFlow, to compute the Fisher information and optimize
for (ÀÜr, ÀÜb). One only needs to provide the densities Lr,b(Œ∏; y), fr,b(Œ∏
‚àó
; z, y), œÄr,b(z; Œ∏, y) and
two conditional estimators Àúz(Œ∏) and ÀúŒ∏
‚àó
(z).
We now provide the tuning details for probit and logistic regression. The likelihood
and update densities Lr,b(Œ∏; y), fr,b(Œ∏
‚àó
; z, y), œÄr,b(z; Œ∏, y) are already given, we present the
conditional estimators. For probit regression, the two conditional modes for œÄr,b(z; Œ∏, y), ÀúŒ∏
‚àó
and fr,b(Œ∏
‚àó
; z, y) are available in closed form, viz
zÀúi(Œ∏) = 
xiŒ∏ + bi
if (yi ‚àí 0.5)(xiŒ∏ + bi) > 0
0 otherwise for i = 1, . . . , n,
ÀúŒ∏
‚àó
(z) =(X0R
‚àí1X)
‚àí1X0R
‚àí1
(z ‚àí b).
For logistic regression, the conditional means for œÄr,b(z; Œ∏, y), ÀúŒ∏
‚àó and fr,b(Œ∏
‚àó
; z, y) all have
closed-form expressions given by
zÀúi(Œ∏) = ri
2|xiŒ∏i + bi
|
tanh(|xiŒ∏i + bi
|
2
) i = 1, . . . , n,
ÀúŒ∏
‚àó
(z) =(X0ZX)
‚àí1X0
(y ‚àí r/2 ‚àí Zb).
5. Geometric convergence rates for CDA-MH and CDA-Gibbs
Although Remark 2 gives a basic guarantee of convergence of the usual time-averaging
estimators commonly used in MCMC, the goal of CDA-MH is to improve upon the convergence rate of the usual DA Gibbs. Motivation for CDA is provided by the results of
Johndrow et al. (2018), which studied the special case of intercept-only logistic and probit regression when y = 1 and n ‚Üí ‚àû so that the data grow increasingly imbalanced as
the sample size increases. Johndrow et al. (2018) showed that in this setting, the spectral
gap of DA converges to zero at least as fast as n
‚àí1/2
(log n)
k
for k ‚â§ 5.5, while randomwalk Metropolis has spectral gap order (log n)
3 or larger. This suggests the superiority of
Metropolis algorithms in the large sample imbalanced data setting. However, to implement
Metropolis effectively with moderate to large numbers of covariates, one needs an efficient
way to construct proposals, which is the goal of CDA.
We now give a result on the convergence rates of CDA and CDA-MH for imbalanced
intercept-only logistic regression. The result shows that the spectral gap is larger than that
for DA (as a function of n), and comparable to MH with optimally tuned proposals when y
grows no faster than log n. While this is a special case, we note that the result in Johndrow
et al. (2018) is given only for fixed y = 1, and thus our result is more general. The difficulty
12  
Calibrated Data Augmentation
of obtaining quantitative estimates of the rate at which the spectral gap converges to zero
as n grows is underscored by the length and complexity of the arguments in Johndrow et al.
(2018).
Consider intercept-only logistic regression from (9) with xi = 1 for i = 1, . . . , n and
prior Œ∏ ‚àº No(0, œÉ2
). As all pi
‚Äôs are the same, we use a single scalar ri = r and bi = b for all
i. With r, b fixed, the update rule for CDA-Gibbs is
œÄr,b(z | Œ∏) = PG(nr, |Œ∏ + b|)
fr,b(Œ∏
0
| z) = No(m,Œõ)
where Œõ = (z + 1/œÉ2
)
‚àí1
, m = Œõa ‚àí b and a =
P
i
yi ‚àí nr/2 + b/œÉ2
.
Theorem 3 Consider intercept-only logistic regression with n observations. Then
1. CDA-Gibbs is uniformly ergodic
2. CDA-MH is uniformly ergodic
3. If P
i
yi = o(log n), there exist choices for r, b such that CDA-MH has spectral gap
Œ∫ = O(n
‚àí
2.5+2 log 2
œÉ2 ).
Thus, for œÉ
2 > 5 + 4 log 2 ‚âà 7.77, the spectral gap of CDA-MH goes to zero more slowly
with increasing n than DA-Gibbs. Moreover, if we choose the prior œÉ
2 = log n, the spectral
gap of CDA-MH is independent of n. It follows that CDA-MH mixes rapidly as n ‚Üí ‚àû in
the large-sample imbalanced setting, unlike DA-Gibbs, which has spectral gap converging
to zero at rate n
‚àí1/2 or faster (ignoring logarithmic factors).
To show that the result is borne out empirically, we conduct simulations as in Johndrow
et al. (2018), with fixed P
i
yi = 1 and increasing n from 101
to a massive 1014. Figure 4
compares the effective sample size per 1, 000 steps using DA and CDA. The deterioration of
DA shows up as early as n = 102
; its slow-down becomes critical at n = 104 with effective
sample size close to 0. CDA performs exceptionally well, even at n = 1014 (we stop at 1014
as 1/n reaches the limit of floating point accuracy).
13
Duan, Johndrow and Dunson
0
100
200
300
400
1 2 3 4 5 6 7 8 9 10 11 12 13 14
Sample Size (in log10n)
Effective Sample Size
Method
DA
CDA
Figure 4: Effective sample size (with 95% pointwise confidence interval) per 1, 000 steps
with different sample size n from 10 to 1014, using logistic regression model with
intercept.
6. Simulation Study
In this section, we compare the performance of CDA against popular alternative algorithms.
6.1. Comparison with Downsampling Algorithm
As motivated in the introduction, two factors are necessary for MCMC to be practically
useful: a low computing cost in each iteration and a high effective sample size within a
small number of iterations.
One potential issue for data augmentation in general is the large number of latent variables to sample in each iteration. A common strategy is to avoid sampling latent variables
for every observation by approximating the Markov transition kernel using subsamples (Korattikara et al., 2014; Quiroz et al., 2018; Bardenet et al., 2017). Unlike other alternative
algorithms we consider here, this changes the invariant measure. Finding a suitable subsample size while controlling the approximation error is challenging and usually problemspecific (Johndrow et al., 2017; Rudolf et al., 2018), and we do not consider it here. Instead,
our goal is to show sub-sampling alone does not address the low ESS of DA; whereas one
can trivially combine our proposed CDA strategy with subsampling to scale DA-MCMC up
to enormous data sample sizes. We illustrate this strategy here.
We consider the same two-parameter intercept-slope model in logistic regression as described above, except we now vary data sample size from n = 105
to 108
. We simulate
Bernoulli outcomes yi ‚àº Bernoulli
(1 + exp(‚àíxiŒ∏))‚àí1

with xi = (1, wi) for wi
iid‚àº No(0, 1)
and Œ∏ = (‚àíŒ∏0, 1)0
. We vary Œ∏0 to obtain Pyi ‚âà 10 for each n. We utilize the minibatch
Polya-Gamma algorithm described by Johndrow et al. (2017), and apply CDA to calibrate
1 
Calibrated Data Augmentation
the variance discrepancy. Since y is highly imbalanced, we apply biased sampling by including all data with yi = 1, while sub-sampling 1% of data with yi = 0.
Denoting the set of all data with yi = 1 as V1 and a random subset with yi = 0 as V0, we
adjust the likelihood contribution from yi = 0 via a power of (n ‚àí |V1|)/|V0| to compensate
for the downsampling, leading to an approximate likelihood
L(Œ∏; y) = Y
i‚ààV1
exp(xiŒ∏)
1 + exp(xiŒ∏)
Ô£´
Ô£≠
Y
i‚ààV0
1
1 + exp(xiŒ∏)
Ô£∂
Ô£∏
n‚àí|V1|
|V0|
.
The number of latent variables is reduced to n0 ‚â° |V0| + |V1|; since n0 is still large, slow
mixing remains a problem and calibration is needed. The algorithmic details are presented
in the appendix.
Figure 5 compares the performance of the two approximating algorithms, one combining
CDA and sub-sampling, and one using sub-sampling alone. Clearly, sub-sampling alone still
results in very small effective sample size, while using CDA and sub-sampling together can
produce excellent computational performance.
‚óè ‚óè ‚óè ‚óè 0
100
200
300
5 6 7 8
Sample Size (in log10n)
Effective Sample Size
Method
‚óè DA‚àíSubsampling
CDA‚àíSubsampling
Figure 5: Comparing the performance of CDA and DA, coupled with sub-sampling approximation to reduce the number of sampled latent variables.
6.2. Comparison with Independence Metropolis-Hastings
In the CDA-MH algorithm, we utilize the marginal quantities ÀÜŒ∏ and I(
ÀÜŒ∏) to tune the
(r, b) parameters. We compare the performance of the CDA proposal against alternative
MH proposal with access to the same information. Specifically, we analyze MH using
independent multivariate t proposals with mean ÀÜŒ∏ and variance I
‚àí1
(
ÀÜŒ∏). We show that this
algorithm has very low acceptance rate relative to CDA-MH.
The general form of the MH acceptance rate is given by
Œ±(Œ∏, Œ∏‚àó
) = min 
1,
L(Œ∏
‚àó
; y)q(Œ∏; Œ∏
‚àó
)
q(Œ∏
‚àó; Œ∏)L(Œ∏; y)
Œ†0
(Œ∏
‚àó
)
Œ†0(Œ∏)

.
Assuming the prior Œ†0
(Œ∏) has negligible impact when n is large, the key to a high acceptance
rate is to have L(Œ∏; y)/q(Œ∏; Œ∏
‚àó
) close to a constant in the high posterior density region of the
15
Duan, Johndrow and Dunson
parameter space. However, for computational convenience, one often has to use a proposal
that is easy to sample. The density mis-match between L(Œ∏; y) and q(Œ∏; Œ∏
‚àó
) can cause the
ratio to decrease rapidly moving away from the posterior mode of Œ∏, resulting in a high
rejection rate.
To illustrate, we consider the independent multivariate t-distribution proposal for logistic
regression:
q(Œ∏
‚àó
, Œ∏) = q(Œ∏) = tŒΩ
n
Œ∏;
ÀÜŒ∏,(ŒΩ ‚àí 2)ŒΩ
‚àí1
I
‚àí1
(
ÀÜŒ∏)
o
,
where ŒΩ > 2 and I(
ÀÜŒ∏) = XT diag[exp(xi
ÀÜŒ∏){1 + exp(xi
ÀÜŒ∏)}
‚àí2
]X. The second parameter is set
to have var(Œ∏) = I
‚àí1
(
ÀÜŒ∏) exactly. We choose ŒΩ = 3 to induce a tail heavier than the target
likelihood, which is a necessary condition for geometric ergodicity of MH with independent
proposals (Mengersen et al., 1996).
The density ratio is
L(Œ∏; y)
q(Œ∏)
= c1
(Y
i
exp(yixiŒ∏)
1 + exp(xiŒ∏)
) 
1 +
1
ŒΩ ‚àí 2
(Œ∏ ‚àí ÀÜŒ∏)
TI(
ÀÜŒ∏)(Œ∏ ‚àí ÀÜŒ∏)
(ŒΩ+p)/2
= c1
exp(P
i
yixiŒ∏)
Q
i
{1 + exp(xiŒ∏)}
"
1 +X
i
1
ŒΩ ‚àí 2
(xiŒ∏ ‚àí xi
ÀÜŒ∏)
2
exp(xi
ÀÜŒ∏){1 + exp(xi
ÀÜŒ∏)}
‚àí2
#(ŒΩ+p)/2
,
(14)
where c1 denotes the constant part. We give an approximation of the acceptance ratio.
We focus on the case Pyi  n, where the mixing is slow for DA-Gibbs. This results
in exp(xi
ÀÜŒ∏) ‚âà 0 for most i. Assuming the high posterior density region is a neighborhood
{Œ∏ : |xiŒ∏ ‚àí xi
ÀÜŒ∏| < Œ∑ for all i}, where Œ∑ is a bounded constant, the second term in (14)
is close to a constant, while the first term is approximately equal to its numerator. The
acceptance ratio is thus approximately
L(Œ∏
‚àó
; y)q(Œ∏)
q(Œ∏
‚àó)L(Œ∏; y)
‚âà exp (X
i
yixi(Œ∏
‚àó ‚àí Œ∏)
)
,
which decreases exponentially away from the current state.
In contrast, since the CDA proposal density is similar to the target, with calibration the
density ratio can be made close to a constant in the neighborhood of the mode. Consider
the density ratio in the logistic CDA proposal:
L(Œ∏; y)
Lr,b(Œ∏; y)
= c2
Y
i
{1 + exp(xiŒ∏ + bi)}
ri
1 + exp(xiŒ∏)
,
where c2 is a constant. Minimizing the Fisher information distance gives approximately
ri ‚âà exp(xi
ÀÜŒ∏) and bi ‚âà ‚àíxi
ÀÜŒ∏, so the density ratio is approximately c2. Thus the acceptance
ratio
L(Œ∏
‚àó
; y)Lr,b(Œ∏; y)
Lr,b(Œ∏
‚àó; y)L(Œ∏; y)
‚âà 1.
We compare the performance of MH algorithms with t3 and CDA proposals, using
the two-parameter intercept-slope example described in Section 6.1. Figure 6 shows the
acceptance ratio at different intercept values Œ∏0, which is approximately the average of xiŒ∏.
16
Calibrated Data Augmentation
The acceptance rate drops rapidly to 0 for the t3 proposal, and is close to one for the CDA
proposal.
0.00
0.25
0.50
0.75
1.00
0 ‚àí5 ‚àí10
-theta0
Acceptance.Rate
Proposal
CDA
t3
Figure 6: Comparing the acceptance ratios using the multivariate t-distribution and CDA
proposals in logistic regression, with variance fixed at the inverse Fisher information. CDA has a much higher acceptance ratio than the multivariate t proposal.
7. Data Applications
7.1. Bernoulli Latent Factor Model with Group Intercepts for Network
Modeling
We now apply CDA to accelerate estimation of group intercepts in a latent factor model.
The dataset is a large sparse network from the Human Connectome Project (Marcus et al.,
2011). The network data under consideration is an adjacency matrix representing the
connectivity among V = 1015 macroscopic regions of one human brain. The matrix
{Aij}(i,j)‚àà{1...V }
2 is binary and symmetric. For i 6= j, Aij = 1 if regions i and j are
connected, Aij = 0 otherwise; Aii are missing as self-connections are ignored. Therefore,
there are effectively n = V (V ‚àí 1)/2 = 514, 605 observed binary outcomes.
There are 507 regions located in the left (L) and 508 in the right hemisphere (R). There
are many more connections within each hemisphere (PAi‚ààL,j‚ààL,i>j = 2, 280, PAi‚ààR,j‚ààR,i>j
= 2, 443), than across hemispheres (PAi‚ààL,j‚ààR = 23). To quantify this phenomenon, we
use two intercepts Œ≤0 and Œ≤1 to represent the within- and across-hemisphere fixed effects
17
Duan, Johndrow and Dunson
within the following Bernoulli probit latent factor model
Aij ‚àº Bernoulli(pij ), pij = Œ¶(œàij ),
œàij =
X
d
r=1
uirvrujr + Œ≤0wij + Œ≤1(1 ‚àí wij ) for i = 2 . . . V, j < i,
œÄ(U) ‚àù 1, UTU = Id,
vr ‚àº No(0,‚àû)
(0, œÉ2
) for r = 1, . . . , d,
Œ≤0 ‚àº No(0, 100), Œ≤1 ‚àº No(0, 100), œÉ2 ‚àº Inverse-Gamma(2, 1),
where wij = 0 if i ‚àà L and j ‚àà R, otherwise wij = 1; U = {uir} is a V -by-d matrix
of latent factors. Following Hoff (2009), we assign U a uniform prior on Stiefel manifold
S
V √ód = {U : U
TU = Id}, and set the latent dimension at d = 10. The latent variable
updates in the probit data augmentation algorithm are given by
zij ‚àº

No(0,‚àû)
(œàij , 1) if Aij = 1
No(‚àí‚àû,0)(œàij , 1) if Aij = 0 for i = 2 . . . V, j < i,
zji = zij .
Because the connection data are highly imbalanced ‚Äì fewer than 5,000 connections out of
a possible 514,605 ‚Äì the intercepts Œ≤0 and Œ≤1 mix slowly in an ordinary DA Gibbs algorithm
(Figure 7(a)). Without using DA, efficient MH proposals are difficult to develop due to the
restriction that U ‚àà S
V √ód
. The DA-Gibbs relies on the full conditional distribution
U | Œ≤0, Œ≤1, Z ‚àº Bingham({zij ‚àí Œ≤0wij ‚àí Œ≤1(1 ‚àí wij )}, diag{vr/2}).
‚àí0.25
0
0.25
0.5
0.75
1
0 10 20 30 40
Lag
ACF
Parameter
beta0
beta1
(a) ACFs of the parameters Œ≤0 and Œ≤1 using DA.
‚àí0.25
0
0.25
0.5
0.75
1
0 10 20 30 40
Lag
ACF
Parameter
beta0
beta1
(b) ACFs of the parameters Œ≤0 and Œ≤1 using CDA.
Figure 7: ACFs show the mixing performance of Œ≤0 and Œ≤1 in modeling average sparsity in
network connectivity of a brain.
18
Calibrated Data Augmentation
We use CDA to calibrate the updates of Œ≤0 and Œ≤1, while keeping the other Gibbs
sampling steps unchanged, i.e.
z
‚àó
ij ‚àº

No(0,‚àû)
(œàij + bij , rij ) if Aij = 1
No(‚àí‚àû,0)(œàij + bij , rij ) if Aij = 0 for i = 2 . . . V, j < i,
Œ≤
‚àó
0 ‚àº No
[
X
j<i
wij
rij
]
‚àí1X
j<i
wij
rij
(z
‚àó
ij ‚àí bij ‚àí
X
d
r=1
uirvrujr)

, [
X
j<i
wij
rij
]
‚àí1

,
Œ≤
‚àó
1 ‚àº No
[
X
j<i
1 ‚àí wij
rij
]
‚àí1X
j<i
1 ‚àí wij
rij
(z
‚àó
ij ‚àí bij ‚àí
X
d
r=1
uirvrujr)

, [
X
j<i
1 ‚àí wij
rij
]
‚àí1

.
Then Œ≤
‚àó
0
and Œ≤
‚àó
1
are accepted via MH step with calibrated conditional density
Lr,b(Œ≤0, Œ≤1 | U, V, A) = Y
j<i
Œ¶(œàij )
Aij [1 ‚àí Œ¶(œàij )](1‚àíAij )
œàij = r
‚àí1
ij [
X
d
r=1
uirvrujr + Œ≤0wij + Œ≤1(1 ‚àí wij ) + bij ]
The tuning parameters are optimized using the approach described in Section 4, except
with xiŒ∏ replaced by Pd
r=1 uirvrujr + Œ≤0wij + Œ≤1(1 ‚àí wij ).
DA CDA
Œ≤0 -2.09 (-2.10, -2.08) -2.09 (-2.10, -2.08)
Œ≤1 -3.68 (-3.72, -3.64) -3.75 (-3.86, -3.66)
Fitted AUC 90.5% 92.1%
Tef f /T 0.008 0.142
Avg Computing Time / T 2.0 sec 2.0 sec
Avg Computing Time / Tef f 251 sec 14.1 sec
Table 1: Parameter estimates and computing speed of DA and CDA in Bernoulli latent
factor modeling of a brain network.
We run DA for 30, 000 steps and CDA for 2, 000 steps, so that they have approximately
the same effective sample size (calculated with the CODA package in R). Both algorithms
are initialized at the MAP estimates. CDA leads to significant reduction in autocorrelation
(Figure 7(b)) and about 18 times lower computing time per effective sample size. We also
compare the in-sample fitted AUCs, computed based on Aij and the posterior mean of pij .
The CDA estimates clearly have a better fit to the data.
7.2. Poisson Log-Normal Model for Web Traffic Prediction
As a second application, we apply CDA to an online browsing activity dataset obtained
from a computational advertising company. The dataset contains a two-way table of visit
count by users who browsed one of 96 websites belonging to clients of the computational
advertising agency, and one of the n = 59, 792 high-traffic sites during the same browsing
19    
Duan, Johndrow and Dunson
session. We refer to visiting more than one site during the same session as co-browsing. For
each of the client websites, it is of commercial interest to identify the high-traffic sites with
relatively high co-browsing rates, so that ads can be more effectively placed. In computational advertising, it is also valuable to understand the co-browsing behavior and predict
the traffic pattern of users.
We consider a Poisson regression model for co-browsing. We use the co-browsing count
of a single client website as the outcome yi and the log of one plus the co-browsing count
of the other 95 websites as the predictors, i.e. xij = log(x
‚àó
ij + 1) for i = 1, . . . , 59792 and
j = 1, . . . , 95, where x
‚àó
is the raw co-browsing count for high-traffic site i and client site j.
A Gaussian random effect is included to account for over-dispersion relative to the Poisson
distribution, leading to a Poisson log-normal regression model:
yi ‚àº Poisson (exp(xiŒ≤ + œÑi)), œÑi
iid‚àº No(œÑ0, ŒΩ2
), i = 1 . . . n
Œ≤ ‚àº No(0, IœÉ2
Œ≤
), œÑ0 ‚àº No(0, œÉ2
œÑ
) ŒΩ
2 ‚àº œÄ(ŒΩ
2
).
We assign a weakly informative prior for Œ≤ and œÑ0 with œÉ
2
Œ≤ = œÉ
2
œÑ = 100. For the overdispersion parameter ŒΩ
2
, we assign a non-informative flat prior on (0, ‚àû).
When Œ≤ and œÑ are sampled separately, the random effects œÑ = {œÑ1, . . . , œÑn} mix slowly.
Instead, we sample Œ≤ and œÑ jointly. Letting XÀú be the n√ó(n+p) matrix given by XÀú = [In X],
and Œ∑i = xiŒ≤ + œÑi the linear predictor, Œ∏ = {œÑ, Œ≤}
0
can be sampled jointly in a block. An
explanation of improved mixing with blocked sampling can be found in Liu (1994a).
We now focus on the mixing behavior of data augmentation. We first review data
augmentation for the Poisson log-normal model. Zhou et al. (2012) proposed to treat
Poisson(Œ∑i) as the limit of the negative binomial NB
Œª, Œ∑i/(Œª + Œ∑i)

with Œª ‚Üí ‚àû, and used
moderate Œª = 1, 000 for approximation. The limit relationship, omitting constants, is given
by
L(Œ∑i
; yi) = exp(yiŒ∑i}
exp{exp(Œ∑i)}
= lim
Œª‚Üí‚àû
exp(yiŒ∑i)
{1 + exp(Œ∑i)/Œª}
Œª
. (15)
With finite Œª approximation, the posterior can be sampled using Polya-Gamma data
augmentation
zi
| Œ∑i ‚àº PG(Œª, Œ∑i ‚àí log Œª) i = 1 . . . n
Œ∏ | z, y ‚àº No
XÀú0ZXÀú +

1/ŒΩ2
¬∑ In 0
0 1/œÉ2
Œ≤
¬∑ Ip
 ‚àí1

XÀú0

y ‚àí Œª/2 + Z log Œª

+

œÑ0/ŒΩ21n
0p
 ,

XÀú0ZXÀú +

1/ŒΩ2
¬∑ In 0
0 1/œÉ2
Œ≤
¬∑ Ip
 ‚àí1

,
where Z = diag{z1, . . . , zn}, 1n = {1, . . . , 1}
0 and 0p = {0, . . . 0}
0
.
However, this approximation-based data augmentation is inherently problematic. For
example, setting Œª = 1, 000 leads to large approximation error. As in (15), the approximating denominator has (1 + exp (Œ∑i)/Œª)
Œª
= exp{exp(Œ∑i) + O(exp(2Œ∑i)/Œª)}; for moderately
large Œ∑i ‚âà 10, Œª needs to be at least 109
to make exp(2Œ∑i)/Œª close to 0. This large error
  
Calibrated Data Augmentation
cannot be corrected with an additional MH step, since the acceptance rate would be too
low. On the other hand, it is not practical to use a large Œª in a Gibbs sampler, as it would
create extremely large zi (associated with small conditional covariance for Œ∏), resulting in
slow mixing.
We use CDA to circumvent this issue. We first choose a very large Œª (109
) to control the
approximation error, then use a small fractional ri multiplying to Œª for calibration. This
leads to a proposal likelihood similar to the logistic CDA:
Lr,b(xiŒ∏; yi) = exp(Œ∑i ‚àí log Œª + bi)
yi
{1 + exp(Œ∑i ‚àí log Œª + bi)}
riŒª
,
with ri ‚â• (yi ‚àí 1)/Œª +  for proper likelihood, and proposal update rule:
zi ‚àº PG(riŒª, Œ∑i ‚àí log Œª + bi) i = 1 . . . n
Œ∏
‚àó ‚àº No
XÀú0ZXÀú +

1/ŒΩ2
¬∑ In 0
0 1/œÉ2
Œ≤
¬∑ Ip
 ‚àí1
n
XÀú0

y ‚àí rŒª/2 + Z log(Œª ‚àí b)

+

œÑ0/ŒΩ21n
0p
 o
,

XÀú0ZXÀú +

1/ŒΩ2
¬∑ In 0
0 1/œÉ2
Œ≤
¬∑ Ip
 ‚àí1

Letting Œ∑
‚àó
i = XŒ∏ Àú ‚àó
, the proposal is accepted with probability (based on the Poisson density
and the approximation Lr,b(xiŒ∏; yi)):
min 
1,
Y
i
exp{exp(Œ∑i)}
exp{exp(Œ∑
‚àó
i
)}
{1 + exp(Œ∑
‚àó
i ‚àí log Œª + bi)}
riŒª
{1 + exp(Œ∑i ‚àí log Œª + bi)}
riŒª

.
The tuning parameters are then optimized as described in Section 4, using
zÀúi(Œ∏) = Œªri
2|Œ∑i ‚àí log Œª + bi
|
tanh 
|Œ∑i ‚àí log Œª + bi
|
2

i = 1, . . . , n,
ÀúŒ∏
‚àó
(z) =
XÀú0ZXÀú +

1/ŒΩ2
¬∑ In 0
0 1/œÉ2
Œ≤
¬∑ Ip
 ‚àí1
n
XÀú0

y ‚àí rŒª/2 + Z log(Œª ‚àí b)

+

œÑ0/ŒΩ21n
0p
 o
.
After Œ∏ is updated, the other parameters can be sampled via œÑ0 ‚àº No
(n/ŒΩ2 + 1/œÉ2
œÑ
)
‚àí1
P
i
œÑi/ŒΩ2
,(n/ŒΩ2 + 1/œÉ2
œÑ
)
‚àí1

and ŒΩ
2 ‚àº Inverse-Gamma(n/2 ‚àí 1,
P
i
(œÑi ‚àí œÑ0)
2/2).
We ran the ordinary DA algorithm with Œª = 1, 000, CDA with Œª = 109 and Hamiltonian
Monte Carlo with No-U-Turn sampler under the default tuning setting (as implemented in
STAN 2.17). All algorithms are initialized at the MAP. We ran DA for 200, 000 steps,
CDA for 2, 000 steps and HMC for 20, 000 steps so that they have approximately the same
effective sample size. For CDA, we used the first 1, 000 steps for adapting r and b. Figure 8
shows empirical autocorrelations for DA, CDA and HMC. Even with small Œª = 1, 000 in DA,
all of the parameters mix poorly; HMC seemed to be affected by the presence of random   
Duan, Johndrow and Dunson
effects, and most of parameters remain highly correlated within 40 lags; CDA substantially
improves the mixing. Table 2 compares all three algorithms. CDA has the most efficient
computing time per effective sample, and is about 30 ‚àí 300 times more efficient than the
other two algorithms.
‚àí0.25
0.00
0.25
0.50
0.75
1.00
0 5 10 15 20 25 30 35 40
Lag
ACF
(a) Autocorrelation of the parameters from DA.
‚àí0.25
0.00
0.25
0.50
0.75
1.00
0 5 10 15 20 25 30 35 40
Lag
ACF
(b) Autocorrelation of the parameters from CDA.
‚àí0.25
0.00
0.25
0.50
0.75
1.00
0 5 10 15 20 25 30 35 40
Lag
ACF
(c) Autocorrelation of the parameters from HMC.
Figure 8: CDA significantly improves the mixing of the parameters in the Poisson lognormal.
To evaluate predictive performance, we use another co-browsing count table for the same
high traffic and client sites, collected during a different time period. We use the high traffic
co-browsing count x
‚Ä†‚àó
ij and their log transform x
‚Ä†
ij = log(x
‚Ä†‚àó
ij + 1) for the j = 1, . . . , 95 clients
to predict the count for the client of interest y
‚Ä†
i
, over the high traffic site i = 1, . . . , 59792.
We predict using ÀÜy
‚Ä†
i = EŒ≤,œÑ|y,xy
‚Ä†
i = EŒ≤,œÑ|y,x exp(x
‚Ä†
i
Œ≤ + œÑi) on the client site. The expectation
is approximated using the MCMC sample path for Œ≤, œÑ | y, x obtained using training set
{y, x}, as discussed above. Cross-validation root-mean-squared error P
i
(ÀÜy
‚Ä†
i ‚àí y
‚Ä†
i
)
2/n1/2
between the prediction and actual count y
‚Ä†
i
‚Äôs is computed. As shown in Table 2, slow mixing
in DA and HMC cause poor estimation of the parameters and high prediction error, while
CDA has significantly lower error.
DA CDA HMC
P
P
Œ≤j/95 0.072 (0.071, 0.075) -0.041 (-0.042, -0.038) -0.010 (-0.042, -0.037)
Œ≤
2
P
j /95 0.0034 (0.0033, 0.0035) 0.231 (0.219 0.244) 0.232 (0.216 0.244)
PœÑi/n -0.405 (-0.642, -0.155) -1.292 (-2.351, -0.446) -1.297 (-2.354, -0.451)
œÑ
2
i /n 1.126 (0.968, 1.339) 3.608 (0.696, 7.928) 3.589 (0.678, 8.011)
Prediction RMSE 33.21 8.52 13.18
Teff /T 0.0037 (0.0011 0.0096) 0.3348 (0.0279, 0.699) 0.0173 (0.0065, 0.0655)
Avg Comp. Time / T 1.3 sec 1.3 sec 56 sec
Avg Comp. Time / Teff 346.4 sec 11.5 sec 3240.6 sec
Table 2: Parameter estimates, prediction error and computing speed of the DA, CDA and
HMC in Poisson regression model.
2 
Calibrated Data Augmentation
8. Discussion
Data augmentation (DA) is a technique routinely used to enable implementation of simple
Gibbs samplers, avoiding the need for expensive and complex tuning of Metropolis-Hastings
algorithms. Despite the convenience, DA mixes slowly when the conditional posterior variance given the augmented data is substantially smaller than the marginal variance. When
the data sample size is massive, this problem arises when the rates of convergence of the augmented and marginal posterior differ. There is a rich literature on strategies for improving
mixing rates of Gibbs samplers, with centered or non-centered re-parameterizations (Papaspiliopoulos et al., 2007) and parameter-expansion (Liu and Wu, 1999) leading to some
improvements. However, existing approaches do not solve large sample mixing problems
because they do not address the fundamental rate mismatch issue.
To tackle this problem, we propose to calibrate data augmentation by directly adjusting the conditional variance (which is associated with step size). CDA adds a small cost
for likelihood evaluation, which is often negligible when compared to the random number
generation required at each iteration of DA. In this article, we demonstrate that calibration
is generally applicable when Œ∏ | z belongs to a location-scale family. We expect it to be also
useful outside of location-scale families, but have not pursued that here.
As both CDA and HMC involve MH steps, we draw some further comparison between
the two. Both methods rely on finding a good proposal by searching a region far from
the current state. One key difference lies in the computing efficiency. Although HMC is
more generally applicable beyond data augmentation, it is computationally intensive since
Hamiltonian dynamics often requires multiple numeric steps. CDA only requires one step
of calibrated Gibbs sampling, which is often much more efficient, leveraging on existing
data augmentation algorithms. The idea of using an auxiliary Gibbs chain to generate MH
proposals seems generally promising (Tran et al., 2016), yet has received little attention in
the literature.
In this work, we focused on cases when the sample size n is large, with the parameter
dimension p moderate. One limitation of CDA-MH is that when p grows, in order to
maintain a reasonable acceptance rate, the range to increase the conditional variance has
to decrease. This is a common problem for general MH algorithms. Therefore, solutions to
high dimensionality require further study.
Appendix A. Proof of Remark 1
Proof Since qr,b(Œ∏; Œ∏
0
) is the Œ∏ marginal of a Gibbs transition kernel, and Gibbs is reversible
on its margins, we have
q(Œ∏; Œ∏
‚àó
)Œ†r,b(Œ∏
‚àó
) = q(Œ∏
‚àó
; Œ∏)Œ†r,b(Œ∏),
and so
L(Œ∏
‚àó
; y)Œ†0
(Œ∏
‚àó
)q(Œ∏; Œ∏
‚àó
)
L(Œ∏; y)Œ†0(Œ∏)q(Œ∏
‚àó; Œ∏)
=
L(Œ∏
‚àó
; y)Œ†0
(Œ∏
‚àó
)Lr,b(Œ∏; y)Œ†0
(Œ∏)
L(Œ∏; y)Œ†0(Œ∏)Lr,b(Œ∏
‚àó; y)Œ†0(Œ∏
‚àó)
=
L(Œ∏
‚àó
; y)Lr,b(Œ∏; y)
L(Œ∏; y)Lr,b(Œ∏
‚àó; y)
.
23
Duan, Johndrow and Dunson
Appendix B. Proof of Remark 2
Proof For any r, b, the conditionals Œ†r,b(z | Œ∏) and Œ†r,b(Œ∏ | z) are well-defined for all
z ‚àà Z, Œ∏ ‚àà Œò, and therefore the Gibbs transition kernel Kr,b((Œ∏, z); ¬∑) and corresponding
marginal kernels Qr,b(Œ∏; ¬∑) are well-defined. Moreover, for any (z, Œ∏) ‚àà Z √ó Œò, we have
P[(Œ∏
0
, z0
) ‚àà A | (Œ∏, z)] > 0 by assumption. Thus Kr,b is aperiodic and Œ†r,b-irreducible (see
the discussion following Corollary 1 in Roberts and Smith (1994)).
Qr,b(Œ∏
0
; Œ∏) is aperiodic and Œ†r,b(Œ∏)-irreducible, since it is the Œ∏ marginal transition kernel
induced by Kr,b((Œ∏, z); ¬∑). Thus, it is also Œ†(Œ∏)-irreducible so long as Œ†  Œ†r,b, where for two
measure ¬µ, ŒΩ, ¬µ  ŒΩ indicates absolute continuity. Since Œ†, Œ†r,b have densities with respect
to Lebesgue measure, Œ†r,b-irreducibility implies Œ† irreducibility. Moreover, q(Œ∏; Œ∏
0
) > 0 for
all Œ∏ ‚àà Œò. Thus, by Theorem 3 of Roberts and Smith (1994), CDA MH is Œ†-irreducible
and aperiodic.
Appendix C. Toy example: Hierarchical Normal
To demonstrate the effects of r, b, we use a toy example commonly used in the data augmentation literature (Liu and Wu, 1999). Consider a marginal Normal model
yi ‚àº No(Œ∏, œÉ2 + 1) i = 1, . . . , n
with œÉ
2 known and improper prior œÄ(Œ∏) ‚àù 1. This can be considered as a hierarchical model
yi ‚àº No(zi
, œÉ2
), zi ‚àº No(Œ∏, 1), i = 1, . . . , n, (16)
where z = {z1, . . . , zn} are augmented data. The standard data augmentation algorithm
has the update rule
zi
| y, Œ∏ ‚àº No 
yiœÉ
‚àí2 + Œ∏
œÉ‚àí2 + 1
,
1
œÉ‚àí2 + 1
i = 1, . . . , n
Œ∏ | z ‚àº No(n
‚àí1X
i
zi
, n‚àí1
).
Thanks to the simple form, it is straightforward to compute the marginal variance of
Œ∏, var(Œ∏ | y) = n
‚àí1
(1 + œÉ
2
). Clearly, this is larger than the conditional variance Ezvar(Œ∏
0
|
z) = n
‚àí1
, when œÉ
2
is large.
To be able to adjust the conditional variance, we consider an alternative hierarchical
model
yi ‚àº No(zi
, œÉ2
), zi ‚àº No(Œ∏ + b0, r0), i = 1, . . . , n,
24
Calibrated Data Augmentation
with update rule
zi
| y, Œ∏ ‚àº No 
yiœÉ
‚àí2 + (Œ∏ + b0)r
‚àí1
0
œÉ‚àí2 + r
‚àí1
0
,
1
œÉ‚àí2 + r
‚àí1
0

i = 1, . . . , n
Œ∏
‚àó
| z ‚àº No(n
‚àí1X
i
zi ‚àí b0, n‚àí1
r0).
(17)
To correct the deviation caused by the alternative model, we treat Œ∏
‚àó as a proposal to
the target model (16), using M-H as in Remark 1 with Lr,b(Œ∏; y) = (r0 + œÉ
2
)
‚àí1/2œÜ[(r0 +
œÉ
2
)
‚àí1/2
(yi ‚àí Œ∏ ‚àí b0)] and œÜ the standard normal density. We can choose r0 so that the
proposal variance equals to the target marginal variance varr,b(Œ∏
0
| z) = var(Œ∏ | y); this
yields
r0 = 1 + œÉ
2
.
Note the proposal mean has
E(Œ∏
‚àó
| Œ∏) = Ez|Œ∏EŒ∏
‚àó|z
(Œ∏
‚àó
| z) = Œ∏ +
n
‚àí1 P
i
yir0
œÉ
2 + r0
‚àí
(b0 + Œ∏)r0
œÉ
2 + r0
Intuitively, one way to improve the acceptance rate is to have the proposal centered at the
current Œ∏ in the high posterior density region. That is, E(Œ∏
‚àó
| Œ∏) ‚âà Œ∏ for Œ∏ near the MAP
ÀÜŒ∏ = n
‚àí1 P
i
yi
. This yields one choice for b0
n
‚àí1 P
i
yir0
œÉ
2 + r0
‚àí
(b0 + ÀÜŒ∏)r0
œÉ
2 + r0
= 0 ‚áí b0 = 0
We use œÉ
2 = 100, Œ∏ = 1 to simulate n = 1000 data. Figure 9 compares the mixing
performance, in terms of traceplots and autocorrelation plots (ACF) for the original DA and
calibrated DA. Each algorithm was initiated at the MAP ÀÜŒ∏ = n
‚àí1 P
i
yi
. CDA significantly
improves the mixing performance, with acceptance rate approximately 0.9. DA CDA
0 250 500 750 1000
0.5
1.0
1.5
2.0
0.5
1.0
1.5
2.0
Iteration
Value
(a) Traceplot for DA and CDA.
0.00
0.25
0.50
0.75
1.00
0 10 20 30 40
Lag
Value
Method
DA
CDA
(b) ACF for DA and CDA.
Figure 9: Trace and autocorrelation plots for DA and CDA in hierarchical normal model.
25
Duan, Johndrow and Dunson
Note in this special example, instead of relying on varr,b(Œ∏
‚àó
| z), one could directly
adjust varr,b(Œ∏
‚àó
| Œ∏) = [r
2
0 + 2r0œÉ
2
]/[n(r0 + œÉ
2
0
)] to match var(Œ∏ | y). However, in general
non-Gaussian cases, varr,b(Œ∏
‚àó
| Œ∏) is intractable, so we expect adjusting var(Œ∏
‚àó
| z) to be
more useful.
Appendix D. Calibrated Polya-Gamma Algorithm with Sub-sampling
Adapting based on Johndrow et al. (2017), we first randomly sample a subset of indices
V of size |V |. This algorithm generates proposals from
V = V1 ‚à™ V0, V1 = {i ‚àà {1, . . . , n} : yi = 1}, V0 ‚àº Subset(|V |, {i ‚àà {1, . . . , n} : yi = 0})
zi ‚àº PG(kiri
, |xiŒ∏ + bi
|) i ‚àà V,
Œ∏
‚àó ‚àº No
(X0
V ZV XV )
‚àí1X0
V
(yV ‚àí kV rV /2 ‚àí ZV bV ),(X0
V ZV XV )
‚àí1

,
where subscript .V indicates the sub-matrix or sub-vector corresponding to the sub-sample;
ki = 1 if yi = 1, and ki = (n ‚àí |V1|)/|V0|. We accept Œ∏
‚àó
in an MH step using calibrated
likelihood
Lr,b(Œ∏; y) = Y
i‚ààV1
exp(xiŒ∏ + bi)
{1 + exp(xiŒ∏ + bi)}
ri
(
Y
i‚ààV0
1
{1 + exp(xiŒ∏ + bi)}
ri
)
n‚àí|V1|
|V0|
,
with target approximate likelihood L1,0(Œ∏; y).
Appendix E. Proof of Theorem 1
Proof Let Q be the proposal kernel for CDA-MH, which is identically the transition kernel
for CDA-Gibbs, and let P be the Markov transition semigroup of CDA-MH.
Both have densities with respect to Lebesgue measure given by
q(Œ∏, Œ∏0
) = Z
Z
fr,b(Œ∏
0
| z, y)œÄr,b(z | Œ∏, y)dz
p(Œ∏, Œ∏0
) = Œ±(Œ∏, Œ∏0
)q(Œ∏, Œ∏0
) + Œ¥Œ∏(Œ∏
0
)

1 ‚àí
Z
Œ±(Œ∏, ÀúŒ∏)q(Œ∏, ÀúŒ∏)d
ÀúŒ∏

,
respectively.
We seek a constant c > 0 and a density g such that
inf
Œ∏‚ààŒò
p(Œ∏, Œ∏0
) > cg(Œ∏
0
)
We proceed in the following steps:
1. Show that there exists a constant c1 > 0 and a density g such that R
Œò
g(Œ∏)dŒ∏ = 1 for
which
inf
Œ∏‚ààŒò
q(Œ∏, Œ∏0
) ‚â• c1g(Œ∏
0
);
conclude that CDA-Gibbs is uniformly ergodic.
2 
Calibrated Data Augmentation
2. Show that there exists S ‚äÇ Œò and a constant c2 > 0 such that
inf
Œ∏‚ààŒò,Œ∏0‚ààS
Œ±(Œ∏, Œ∏0
) > c2.
3. Combine 1 and 2 to show p(Œ∏, Œ∏0
) ‚â• Œ∫gS(Œ∏
0
), where Œ∫ = c1c2c3 with
c3 =
Z
S
g(Œ∏)dŒ∏, gS(Œ∏) = c
‚àí1
3
g(Œ∏)1{Œ∏ ‚àà S}
the restriction of g to S. Conclude that CDA-MH is uniformly ergodic with spectral
gap Œ∫.
4. Find values (r0, b0, S0) of the tuning parameters r, b, S so that Œ∫ goes to zero slowly
as n ‚Üí ‚àû.
1. Show that q(Œ∏, Œ∏0
) ‚â• c1g(Œ∏
0
). First we bound œÄr,b(Œ∏
0
| z) by a constant times a
function depending on z
œÄr,b(Œ∏
0
| z) = (2œÄ)
‚àí1/2
(z + 1/œÉ2
)
1/2
exp 
‚àí
1
2
(Œ∏
0 ‚àí m)(z + 1/œÉ2
)(Œ∏
0 ‚àí m)

=(2œÄ)
‚àí1/2
(z + 1/œÉ2
)
1/2
exp 
‚àí
1
2

(Œ∏
0 + b)(z + 1/œÉ2
)(Œ∏
0 + b) ‚àí 2a(Œ∏
0 + b) + a
2
z + 1/œÉ2

>(2œÄ)
‚àí1/2
(1/œÉ2
)
1/2
exp 
‚àí
1
2

(Œ∏
0 + b)(z + 1/œÉ2
)(Œ∏
0 + b) ‚àí 2a(Œ∏
0 + b) + a
2
1/œÉ2

=(2œÄ)
‚àí1/2œÉ
‚àí1
exp 
‚àí
1
2

(Œ∏
0 + b)
2
/œÉ2 ‚àí 2a(Œ∏
0 + b) + a
2œÉ
2
 exp 
‚àí
1
2

(Œ∏
0 + b)
2
z

(18)
in which the inequality holds since z > 0.
Using the Laplace transform of œâ ‚àº PG(Œ±, Œ≤)
E[exp(‚àíœât)] = coshŒ±
(Œ≤/2)
coshŒ±
(
p
(Œ≤
2/2 + t)/2)
,
we proceed to bound the expectation of (18) with respect to z
Z ‚àû
0
exp 
‚àí
1
2

(Œ∏
0 + b)
2
z
œÄr,b(z | Œ∏)dz = coshnr(
|Œ∏ + b|
2
)cosh‚àínr(
p
((Œ∏ + b)
2 + (Œ∏
0 + b)
2)
2
)
‚â• coshnr(
|Œ∏ + b|
2
)cosh‚àínr(
(|Œ∏ + b| + |Œ∏
0 + b|)
2
)
‚â• 2
‚àínrcoshnr(
|Œ∏ + b|
2
)cosh‚àínr(
|Œ∏ + b|
2
)cosh‚àínr(
|Œ∏
0 + b|
2
)
= 2‚àínr cosh‚àínr(
|Œ∏
0 + b|
2
)
‚â• 2
‚àínr exp 
‚àí
nr|Œ∏
0 + b|
2

27
Duan, Johndrow and Dunson
‚â• 2
‚àínr exp 
‚àí
nr[(Œ∏
0 + b)
2 + 1]
4

where the first inequality uses a
2 +b
2 ‚â§ (|a|+|b|)
2
; the second uses Lemma 3.2 of Choi and
Hobert (2013); the third uses the property of cosh; and the fourth uses |a| ‚â§ (1 + a
2
)/2.
We combine to obtain q(Œ∏, Œ∏0
) > c1g(Œ∏
0
), viz
q(Œ∏, Œ∏0
) = Z ‚àû
0
œÄr,b(Œ∏
0
| z, y1:n)œÄr,b(z | Œ∏, y1:n)dz
>(2œÄ)
‚àí1/2œÉ
‚àí1
exp 
‚àí
1
2

(Œ∏
0 + b)
2
/œÉ2 ‚àí 2a(Œ∏
0 + b) + a
2œÉ
2
2
‚àínr exp 
‚àí
nr[(Œ∏
0 + b)
2 + 1]
4

=(2œÄ)
‚àí1/2œÉ
‚àí1
2
‚àínr exp 
‚àí
1
2

(Œ∏
0 + b)
2
(
1
œÉ
2
+
nr
2
) ‚àí 2a(Œ∏
0 + b)
 exp 
‚àí
nr
4
‚àí
a
2œÉ
2
2

=œÉ
‚àí1
2
‚àínr(
1
œÉ
2
+
nr
2
)
‚àí1/2
exp 
‚àí
nr
4
‚àí
a
2œÉ
2
2

exp 
1
2
a
2
(
1
œÉ
2
+
nr
2
)
‚àí1

(2œÄ)
‚àí1/2
(
1
œÉ
2
+
nr
2
)
1/2
exp 
‚àí
1
2

Œ∏
0 + b ‚àí (
1
œÉ
2
+
nr
2
)
‚àí1
a
2
(
1
œÉ
2
+
nr
2
)

=c1g(Œ∏
0
)
where
c1 = œÉ
‚àí1
2
‚àínr(
1
œÉ
2
+
nr
2
)
‚àí1/2
exp 
‚àí
nr
4
‚àí
a
2œÉ
2
2

exp 
1
2
a
2
(
1
œÉ
2
+
nr
2
)
‚àí1

g(Œ∏
0
) = No
Œ∏
0
| (
1
œÉ
2
+
nr
2
)
‚àí1
a ‚àí b,(
1
œÉ
2
+
nr
2
)
‚àí1

.
This completes the first part.
2. Show that infŒ∏‚ààŒò,Œ∏0‚ààS Œ±(Œ∏, Œ∏0
) > c2 for some set S.
The acceptance ratio is
Œ±(Œ∏, Œ∏0
) = min Œ±0(Œ∏
0
)
Œ±0(Œ∏)
n
, 1

, Œ±0(x) = {1 + exp(x + b)}
r
1 + exp(x)
Differentiating with respect to x we obtain
‚àÇŒ±0(x)
‚àÇx =
e
x

e
b+x + 1r‚àí1
(r ‚àí 1)e
b
e
x + e
b
r ‚àí 1

(e
x + 1)2
,
Assuming that r < 1 and e
b
r > 1, since
e
x

e
b+x + 1r‚àí1
(e
x + 1)2 > 0
and there is only one root on (‚àí‚àû, ‚àû) for
(r ‚àí 1)e
b
e
x + e
b
r ‚àí 1 = 0 =‚áí x = log(e
b
r ‚àí 1
1 ‚àí r
) ‚àí b ‚â° ÀÜŒ∏   
Calibrated Data Augmentation
(r ‚àí 1)e
b
e
x + e
b
r ‚àí 1 < 0 =‚áí x > ÀÜŒ∏
(r ‚àí 1)e
b
e
x + e
b
r ‚àí 1 > 0 =‚áí x < ÀÜŒ∏
Therefore, ÀÜŒ∏ is the unique mode of Œ±0, and Œ±0 is (1) monotonically increasing for x < ÀÜŒ∏ and
monotonically decreasing for x > ÀÜŒ∏.
For convenience, we write b = ‚àí log(r) + Œæ with Œæ > 0, so that 1 + exp(ÀÜŒ∏ + b) =
(e
Œæ ‚àí r)/(1 ‚àí r). Now set S = (s1, s2). We now show that Œ±(Œ∏, Œ∏0
) > c2 for Œ∏
0 ‚àà S. We
proceed in two cases.
1. Case 1: Œ∏ ‚â§ ÀÜŒ∏. We have three subcases
(a) If Œ∏ < Œ∏0 ‚â§ ÀÜŒ∏, then Œ±0(Œ∏
0
) ‚â• Œ±0(Œ∏), Œ±(Œ∏, Œ∏0
) = 1.
(b) If s1 < Œ∏0 ‚â§ Œ∏ ‚â§ ÀÜŒ∏ then
Œ±(Œ∏, Œ∏0
) =
1 + exp(Œ∏)
1 + exp(Œ∏
0)
n
1 + exp(Œ∏
0 + b)
1 + exp(Œ∏ + b)
rn
‚â•1 √ó

1
1 + exp(ÀÜŒ∏ + b)
rn
=

1 ‚àí r
e
Œæ ‚àí r
rn
(c) If Œ∏ ‚â§ ÀÜŒ∏ < Œ∏0 < s2,
Œ±(Œ∏, Œ∏0
) =
1 + exp(Œ∏)
1 + exp(Œ∏
0)
n
1 + exp(Œ∏
0 + b)
1 + exp(Œ∏ + b)
rn
‚â•

1
1 + exp(Œ∏
0)
n
√ó 1 ‚â•

1
1 + exp(s2)
n
where we used that Œ∏
0 > Œ∏ so the second term is bounded below by 1, and that
1 +e
Œ∏ > 1. If s2 ‚â§ ÀÜŒ∏, then Œ∏
0 < ÀÜŒ∏, we only need to consider the condition (a) and
(b).
2. Case 2: Œ∏ > ÀÜŒ∏,
(a) If ÀÜŒ∏ < Œ∏0 ‚â§ Œ∏, then Œ±0(Œ∏
0
) ‚â• Œ±0(Œ∏), Œ±(Œ∏, Œ∏0
) = 1.
(b) If s1 < Œ∏0 ‚â§ ÀÜŒ∏ < Œ∏, because Œ±0 is monotone nondecreasing on (‚àí‚àû,
ÀÜŒ∏), we have:
Œ±0(Œ∏
0
) = {1 + exp(Œ∏
0 + b)}
r
1 + exp(Œ∏
0)
‚â• lim
Œ∏
0‚Üí‚àí‚àû
Œ±0(Œ∏
0
) = 1,
Further, because Œ±0 is monotone nonincreasing on (ÀÜŒ∏, ‚àû) we have
1
Œ±0(Œ∏)
=
1 + exp(Œ∏)
{1 + exp(Œ∏ + b)}
r
‚â•
1
Œ±0(
ÀÜŒ∏)
Œ±(Œ∏, Œ∏0
) = Œ±0(Œ∏
0
)
1
Œ±0(Œ∏)
29
Duan, Johndrow and Dunson
‚â• 1 √ó
1
Œ±0(
ÀÜŒ∏)
=
{1 + exp(ÀÜŒ∏)}
n
{1 + exp(ÀÜŒ∏ + b)}
rn
‚â•
1
{1 + exp(ÀÜŒ∏ + b)}
rn
=

1 ‚àí r
e
Œæ ‚àí r
rn
(c) If ÀÜŒ∏ < Œ∏ < Œ∏0 < s2,
Œ±(Œ∏, Œ∏0
) = 
1 + exp(Œ∏)
1 + exp(Œ∏
0)
n
1 + exp(Œ∏
0 + b)
1 + exp(Œ∏ + b)
rn
‚â•

1
1 + exp(Œ∏
0)
n
√ó 1 = 
1
1 + exp(s2)
n
If s2 ‚â§ ÀÜŒ∏, then Œ∏
0 < ÀÜŒ∏ and we only need to consider the condition (b).
Combining (1) and (2), even when s2 ‚â§ ÀÜŒ∏, the lower bound still has:

1 ‚àí r
e
Œæ ‚àí r
rn
‚â• min  1 ‚àí r
e
Œæ ‚àí r
rn
,

1
1 + exp(s2)
n
Therefore we have the common lower bound:
Œ±(Œ∏, Œ∏0
) ‚â• c2, c2 = min  1 ‚àí r
e
Œæ ‚àí r
rn
,

1
1 + exp(s2)
n
for Œ∏
0 ‚àà (s1, s2). Since this does not depend on s1, we take s1 = ‚àí‚àû.
3. Combine to show p(Œ∏, Œ∏0
) ‚â• c1c2c3gS(Œ∏
0
)
Since
p(Œ∏, Œ∏0
) = Œ±(Œ∏, Œ∏0
)q(Œ∏, Œ∏0
) + Œ¥Œ∏(Œ∏
0
)

1 ‚àí
Z
Œ±(Œ∏, ÀúŒ∏)q(Œ∏, ÀúŒ∏)d
ÀúŒ∏

,
‚â• Œ±(Œ∏, Œ∏0
)q(Œ∏, Œ∏0
),
parts (1) and (2) establish the bound
inf
Œ∏‚ààŒò
p(Œ∏, Œ∏0
) ‚â• c1c2g(Œ∏
0
)1{Œ∏
0 ‚àà S}
= c1c2c3c
‚àí1
3
g(Œ∏
0
)1{Œ∏
0 ‚àà S},
where
c3 =
Z
g(Œ∏
0
)1{Œ∏
0 ‚àà S},
so that gS(Œ∏
0
) = c
‚àí1
3
g(Œ∏
0
)1{Œ∏
0 ‚àà S} is a density. Specifically we have
gS(Œ∏
0
) = c
‚àí1
3

1
œÉ
2
+
nr
2
1/2
œÜ

Œ∏
0 ‚àí

(
1
œÉ2 +
nr
2
)
‚àí1a ‚àí b

(
1
œÉ2 +
nr
2
)‚àí1/2
!
1{Œ∏
0 ‚àà S}
3 
Calibrated Data Augmentation
for œÜ(¬∑) the standard Gaussian density, where
c3 = Œ¶ (
1
œÉ
2
+
nr
2
1/2 
s2 ‚àí (
1
œÉ
2
+
nr
2
)
‚àí1
a + b
)
= Œ¶ "
1
œÉ
2
+
rn
2
1/2
(s2 + b) ‚àí

1
œÉ
2
+
rn
2
‚àí1/2
a
#
.
It follows that P is uniformly ergodic with spectral gap at least Œ∫ = c1c2c3.
4. Tune constants so that Œ∫ ‚Üí 0 slowly as n ‚Üí ‚àû
We now may choose r, b, S in such a way as to minimize the rate at which the spectal
gap goes to zero, subject to the constraints on r, b from part (2) and
Œ∫(r, b, S) = c1c2c3
= œÉ
‚àí1
2
‚àínr(
1
œÉ
2
+
nr
2
)
‚àí1/2
exp 
‚àí
nr
4
‚àí
a
2œÉ
2
2

exp 
1
2
a
2

1
œÉ
2
+
nr
2
‚àí1 
√ó min  1 ‚àí r
e
Œæ ‚àí r
rn
,

1
1 + exp(s2)
n
√ó Œ¶
"
1
œÉ
2
+
rn
2
1/2
(s2 + b) ‚àí

1
œÉ
2
+
rn
2
‚àí1/2
a
#
First, we note that because b = Œæ ‚àí log r, tuning of r, Œæ is equivalent to tuning of r, b, so we
elect to do the former.
First, to reduce the effect of n, we set r = w/n, with 0 < w < n. Noting exp(‚àía
2œÉ
2/2)
decreases rapidly in a and recalling a =
P
i
yi ‚àí nr/2 + b/œÉ2 and b = Œæ ‚àí log r, we solve for
w to make a = 0
X
i
yi ‚àí w/2 + (‚àí log(w) + log(n) + Œæ)/œÉ2 = 0
log w
œÉ
2
+
w
2
=
X
i
yi +
log n
œÉ
2
+
Œæ
œÉ
2
assuming Pyi + Œæ/œÉ2 = o(log(n)), we have
w = 2 log(n)/œÉ2 + o(log(n)).
Second, we make c3 a constant independent of y, n, by choosing s2 such that
(
1
œÉ
2
+
rn
2
)
1/2
(s2 + b) ‚àí (
1
œÉ
2
+
rn
2
)
‚àí1/2
a = 0
(
1
œÉ
2
+
rn
2
)
1/2
(s2 + b) = 0
s2 = ‚àíb = log(w) ‚àí log(n) ‚àí Œæ.
which yields c3 = 0.5.
31
Duan, Johndrow and Dunson
Third, choose Œæ so that
Œæ ‚â§ log n1 ‚àí
w
n

e +
w
n
o
=‚áí log 
e
Œæ ‚àí w/n
1 ‚àí w/n 
‚â§ 1
meaning

1 ‚àí r
e
Œæ ‚àí r
rn
=

1 ‚àí w/n
e
Œæ ‚àí w/nw
= exp 
‚àíw log 
e
Œæ ‚àí w/n
1 ‚àí w/n  ‚â• e
‚àíw
and

1
1 + exp(s2)
n
=

1
1 + we‚àíŒæ/nn
‚â• exp(‚àíwe‚àíŒæ
) ‚â• e
‚àíw
We have
c2 = min  1 ‚àí r
e
Œæ ‚àí r
rn
,

1
1 + exp(s2)
n
‚â• exp(‚àíw).
Combining results and choosing r = r0 = w/n, b = b0 = ‚àí log(w) + log(n) + Œæ, S =
S0 = (‚àí‚àû, log(w) ‚àí log(n) ‚àí Œæ), with (w, Œæ) : P
i
yi ‚àí w/2 + (‚àí log(w) + log(n) + Œæ)/œÉ2 =
0, Œæ ‚â§ log[(1 ‚àí w/n)e + w/n], we have
Œ∫(r0, b0, S0) =œÉ
‚àí1
2
‚àíw‚àí1
(
1
œÉ
2
+
w
2
)
‚àí1/2
exp 
‚àí
w
4

exp(‚àíw)
=O

exp
‚àí (
5
4
+ log 2)w


=O

n
‚àí
5/2+2 log 2
œÉ2

.
