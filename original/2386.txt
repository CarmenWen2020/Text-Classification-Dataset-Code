This article presents a collaborative neurodynamic optimization (CNO) approach to multivehicle task assignments (TAs). The original combinatorial quadratic optimization problem for TA is reformulated as a quadratic unconstrained binary optimization (QUBO) problem with a quadratic utility function and a penalty function for handling load capacity and cooperation constraints. In the framework of CNO with a population of discrete Hopfield networks (DHNs), a TA algorithm is proposed for solving the formulated QUBO problem. Superior experimental results in four typical multivehicle operation scenarios are reported to substantiate the efficacy of the proposed neurodynamics-based TA approach.

SECTION I.Introduction
In recent years, autonomous vehicles have become very popular research topic areas and fast-growing modern technologies. Operating on the ground, in the air, or at sea in form of self-driving cars, autopilot trucks, automatic guided vehicles, unmanned aerial vehicles, autonomous surface vehicles, and autonomous underwater vehicles, autonomous vehicles are versatile and can accomplish many important missions. Due to the limitations on load capacity and coverage of an individual vehicle, many complex missions entail the employment and cooperation of multiple vehicles to complete tasks within a given time window [1]–[2][3][4].

Multivehicle task assignment or allocation (TA) refers to the allocation of multiple vehicles to multiple tasks with the maximum utility under various practical constraints. The multivehicle TA is a fundamental module for many unmanned systems, such as search and rescue systems [2], tracking systems [1], and parcel delivery systems [3]. Except for a very few special cases, such as the linear assignment problem [5], typical multivehicle TA problems are NP-hard due to their combinatorial nature [6].

There are many TA problems arising in various applications [1], [3], [7]–[8][9][10][11]. For example, robust multivehicle TA is addressed in [7] by using a conflict resolution mechanism. Multirobot orchestral music playing is investigated based on TA [8]. Multivehicle TA with partially unreachable targets is discussed in [11] based on the marginal-cost principle. With the widespread applications of functionally heterogeneous autonomous vehicles with limited capacities, optimal multivehicle TA subject to cooperation and load capacity constraints becomes critically important [1], [3].

Many computation methods are available for multivehicle/robot TA. For example, classic algorithms, such as market-based auction algorithms [1], [5], [7] and the Hungarian method [8], are proposed for multirobot assignment. Heuristic algorithms are also available; e.g., a heuristic auction method is proposed for multivehicle TA [2]. In addition, metaheuristic algorithms, such as particle swarm optimization (PSO), is used for multivehicle assignment [12]. Moreover, methods based on neural networks are available for multivehicle TA. For example, self-organizing map and k-winners-take-all neural network are applied for TA in multivehicle/robot systems [10], [13].

Prior to the inception of autonomous vehicle research, neural network research is coming along a winding path since eight decades ago. In his seminal articles [14], [15], John Hopfield points out that the networks of simple and similar neurons collectively can serve as powerful computation models (known as Hopfield networks). In particular, the discrete and continuous Hopfield networks in [14], [15] are applied for linear programming and combinatorial computation, such as a traveling salesman problem [16]–[17][18]. Since 1990s, numerous neurodynamic models are developed for solving various optimization problems, such as linear and nonlinear programming (e.g., [16], [19]–[20][21][22][23][24][25][26][27][28][29][30]), nonsmooth optimization problems (e.g., [31], [32]), generalized convex optimization problems (e.g., [33], [34]), minimax optimization problems (e.g., [35], [36]), complex-valued optimization problems (e.g., [37]), distributed optimization problems (e.g., [38], [39]), bilevel optimization problems (e.g., [40]), and combinatorial optimization (e.g., [41], [42]). In recent years, collaborative neurodynamic optimization (CNO) becomes viable for global and combinatorial optimization [43]–[44][45][46]. For example, CNO approaches to global optimization are proposed [43], [44]. CNO-based global and combinatorial optimization methods based on three-layer projection neural networks are developed [45]. Recently, a CNO approach based on two-timescale multilayer recurrent neural networks is developed for global optimization [47]. In the CNO framework, multiple neurodynamic models work in parallel in search for local optimal solutions to a given optimization problem until convergence and the search processes repeat with updated initial states by using a metaheuristic rule (e.g., PSO) in search for a globally optimal solution. It is proven theoretically and demonstrated experimentally that CNO approaches are almost surely convergent to global optima of global and combinatorial optimization problems [43]–[44][45]. In particular, recently, CNO with three-layer projection neural networks is customized and applied for multivehicle TA [3].

In this article, we propose a CNO approach to TA for multivehicle systems based on discrete Hopfield networks (DHNs). The multivehicle TA is first formulated as a combinatorial optimization problem with a quadratic utility function and a set of affine equality and inequality constraints, where the utility function to be maximized is a score metric of completed tasks and the linear equality/inequality constraints’ model cooperation among vehicles and load capacities of individual vehicles. Then, a collaborative neurodynamic approach with multiple DHNs reinitialized repeatedly by using a PSO update rule is developed for achieving globally optimal TAs by solving the formulated combinatorial optimization problem.

The TA approach herein is based on DHNs operating synchronously in batches, whereas the approach in [3] is based on continuous-time projection neural networks though both are in the framework of CNO [44]. Because the DHNs operate in the binary state space on the vertexes of a hypercube, whereas the state space is the whole hypercube in [3]. Hence, the TA approach herein is more time-efficient. In addition, the method herein employs a larger population of neural networks than that in [3] for searching global optimal assignment with expedited convergence. As a result, the quality of the solutions is much higher in the present approach than that in [3]. In contrast to the CNO-based algorithms in [43], [44], [48], and [45], the algorithm herein is customized for TA based on CNO with DHNs.

The remainder of this article is organized as follows. Section II provides necessary preliminary information. Section III states the problem formulation. Section IV presents the proposed neurodynamics-based TA approach. Section V reports experimental results in four scenarios. Section VI concludes this article.

SECTION II.Background Knowledge
A. Discrete Hopfield Network (DHN)
The DHN is a classic recurrent neural network characterized by its binary or bipolar states and activation function operating in discrete time [14]
u(t+1)=x(t)=Wx(t)−θσ(u(t))(1)(2)
View SourceRight-click on figure for MathML and additional features.where u∈Rn is the net-input vector, x∈Rn is the state vector, W∈Rn×n is the connection weight matrix, θ∈Rn is the threshold vector, and σ(⋅) is a vector-valued discontinuous activation function defined elementwisely as follows:
σ(ui)={10if ui(t)≥0if ui(t)<0.
View SourceRight-click on figure for MathML and additional features.It is shown in [14] that the state of the DHN (2) is locally stable if the connection weight matrix is symmetric (i.e., W=WT ), the main diagonal elements of W are zeros (i.e., wii=0∀i ), and the neurons are activated asynchronously. It is also shown [14] that, if the above sufficient conditions hold, then the DHN (2) is globally convergent to a local optimum of the following combinatorial optimization problem with binary decision variables:
min−12xTWx+θTx or max 12xTWx−θTxs.t. x∈{0,1}n.(3)
View SourceRight-click on figure for MathML and additional features.That is, an equilibrium x¯ is a local optimum of the optimization problem above. Note that the right-hand side of (1) is equal to the positive gradient of the objective function to be maximized or the negative gradient of the objective function to be minimized. In other words, the DHN neurodynamics form a discrete gradient flow moving among vertices of the unit hypercube coordinatewisely.

In view of the binary nature of state variable xi∈{0,1} , x2i=xi for i=1,2,…,n . As a result, the diagonal elements of the weight matrix in the quadratic term of (1) can always set to be zeros and add an equivalently linear term diag(w11,…,wnn)x . As a result, the asynchronously activated DHN (2) is guaranteed to be locally stable.

To expedite the DHN convergence, several methods are available to synchronize the neuronal activation in batches, e.g., [49]–[50][51][52][53]. Among the batch-mode synchronous activation methods, the one in [53] seems to be the easiest to implement: partition the DHN neurons according to their local connectivity such that there is no direct connection among the neurons within each batch. The neurons can then be activated in batch with assured local stability and monotonic nonincreasing/nondecreasing of the objective function value in (3).

B. Particle Swarm Optimization (PSO)
PSO is a class of meta-heuristic optimization algorithms. Like scattered search, a population of candidate solutions (so-called particles) searches better solutions by exchanging information among them according to their momentum and best known solutions from their individual and grouped particles.

Let N denote the number of the particles in the swarm, pi∈Rn denote the position vector of the ith particle (candidate solution), p∗i denote the best position found by the ith particle individually (i=1,2,…,N ), and p∗ denote the best position known to the swarm (solution set). The velocity vi and the position pi are updated by the following rules. For i=1,2,…,N
vi(t+1)=pi(t+1)=c0vi(t)+c1r1(p∗i−pi(t))+c2r2(p∗−pi(t))pi(t)+vi(t+1)(4)(5)
View SourceRight-click on figure for MathML and additional features.where c0∈[0,1] is an inertia parameter, c1,c2∈[0,1] are two acceleration constants, and r1,r2∈[0,1] are two random numbers.

C. Collaborative Neurodynamic Optimization (CNO)
It is challenging for an individual neurodynamic model to solve complex optimization problems, such as global optimization problems with nonconvex objective functions or constraints and combinatorial optimization problems with binary variables. In recent years, several CNO approaches with multiple neurodynamic models are developed for solving distributed optimization problems (e.g., [38], [39]), nonconvex and global optimization problems (e.g., [43]–[44][45], [54]), multiobjective optimization (e.g., [39], [55]), and combinatorial optimization problems (e.g., [45], [46]).

CNO is a framework of hybrid intelligence that is designed for solving global optimization problems. It integrates the local search ability of individual neurodynamic models together with the global search ability of PSO. For global, combinatorial, and multiobjective optimization, initial states of a group of neurodynamic models are repetitively updated by using metaheuristics, such as PSO. It is proven that collaborative neurodynamic approaches are almost surely convergent to the global optimal solutions of the optimization problems [43]–[44][45][46], [54].

SECTION III.Problem Formulations
A. Notations, Assumptions, and Definitions
The decision variable is defined as follows. ∀i∈V and ∀j∈T
xij={1,0,if vehicle i is assigned to task jotherwise.
View SourceRight-click on figure for MathML and additional features.

Nomenclature lists most of the notations used herein and is explained as follows. Tl indexes all single-vehicle tasks, i.e., the tasks indexed in Tl can only be completed by a vehicle indexed in Vl . TC indexes lmax -vehicle tasks, i.e., the tasks indexed in TC require heterogeneous vehicles of lmax types to complete cooperatively.

Without loss of generality, we assume hereafter that lmax≥2 and Vl≠∅ for l=1,…,lmax , ∪lmaxl=1Vl=V , Vl∩Vm=∅ for l≠m , and T∖TC=∪lmaxl=1Tl . We also assume that all cooperations take place between or among lmax vehicles.

Similar to [7], score of vehicle i for completing task j is defined as sij(Si)=sjδ(τij(Si)) for i∈V and j∈T∖TC , where an exponential discount function is defined in [1] as follows:
δ(τij(Si))=e−γiτij(Si)
View SourceRight-click on figure for MathML and additional features.γi is a positive discount constant, and the time delay is defined as [7]
τij(Si)={tij(Si)−tstartj,0,tij(Si)>tstartjotherwise.(6)
View SourceRight-click on figure for MathML and additional features.tij(Si) is computed according to Si with given vehicle speeds [7]. Similar to [1], score sikj is defined as follows:
sikj(Si,Sk)={s′ij(Si)+s′′kj(Sk),0,iin mathcal V_1, kin mathcal Vsetminus mathcal V_1otherwise(7)
View SourceRight-click on figure for MathML and additional features.where s′ij(Si)=w′ijsjδ(τij(Si)) for i∈V1 , j∈TC , s′′ij(Sk)=w′′ijsjδ(τij(Si)) for i∈V∖V1 and j∈TC , and w′ij and w′′kj are positive weights.

B. Task Sequence Generation
Let s(Si) be a scalar function defined as follows:
s(Si)={0,∑j∈pis~ij(Si),if mathcal S_i=emptyset otherwise (8)
View SourceRight-click on figure for MathML and additional features.where
s~ij(Si)=⎧⎩⎨⎪⎪⎪⎪⎪⎪sij(Si),s′ij(Si),s′′ij(Si),j∈T∖TCiin mathcal V_1, j in mathcal T_Ciin mathcal Vsetminus mathcal V_1, j in mathcal T_C.
View SourceRight-click on figure for MathML and additional features.

Let Si⊕k{j} denote an ordered task index set obtained by inserting j into the k th slot of Si , where k=1,…,|Si|+1 . A procedure for computing task sequences is detailed in Algorithm 1, and its main steps are explained as follows. Lines 3–10 are to generate task sequence Si for vehicle i . Lines 4–5 are to find task j∗ for assigning to task sequence Si by using s(Si) . Line 6 is to add the index of vehicle-task pair (i,j∗) to the index set of invalid assignments D to eliminate task j∗ that cannot be allocated to sequence Si , as in [1]. Lines 7 and 8 are to add task j∗ in sequence Si . Line 9 is to delete task j∗ from the index set of remaining tasks Ai . Line 14 is to remove an invalid multivehicle assignment from sequence index sets and reset the corresponding decision variables. Line 16 is to reset the decision variables for invalid single-vehicle assignments.

Algorithm 1 - Task Sequence Generation
Algorithm 1
Task Sequence Generation

Show All

C. Original Formulations
Let the matrix of decision variables be defined as X=[xij]∈{0,1}nV×nT . A multivehicle TA problem is formulated as follows [3]:
maxX∑j∈T∖TC∑i∈Vsij(Si)xij+1lmax−1∑j∈TC∑i∈V1∑k∈V,k≠isikj(Si,Sk)xkjxijs.t. ∑j∈Txij≤ℓi,i∈V∑i∈Vlxij≤1,j∈Tl, l=1,…,lmax∑i∈Vlxij≤1,j∈TC, l=1,…,lmax∑i∈V∖Vlxij=0,j∈Tl, l=1,…,lmax∑l=1lmax∑i∈Vlxij∈{0,lmax},j∈TCxij∈{0,1},i∈V, j∈T.(9a)(9b)(9c)(9d)(9e)(9f)(9g)
View SourceRight-click on figure for MathML and additional features.

The first term of the pseudo-Boolean objective function in (9a) is the total score of completed single-vehicle tasks, and the second term is the total score of completed lmax -vehicle tasks. Constraint (9b) is the load capacity constraint. Constraints (9c) and (9e) ensure that single-vehicle tasks are completed by vehicles in accordance with their types. Constraints (9d) and (9f) ensure that tasks in TC are completed by vehicles of lmax types. Constraints (9b) and (9e) are equivalent reformulations of those in [3].

Since there are quadratic terms in its utility function, the multivehicle TA problem in (9) is NP-hard [56].

D. Proposed Reformulation
On the way to solving constrained binary quadratic optimization problem (9), the three inequality and two equality constraints in (9) are to be converted into a quadratic penalty function with five terms. There are two ways to convert them to penalty terms: the first way is straightforward to convert the three inequalities to equalities by adding slack variables, to move the right-hand sides to the left of equalities, and then to square the resulting five equalities as the penalty terms, as will be shown in the following. The second way is to use some existing transformation techniques (e.g., [57], [58]) without adding slack variables to define quadratic penalty terms for inequalities in view of xij=x2ij herein.

As the value of the left-hand side of each inequality constraint in (9b) is always an integer, by introducing a binary slack variable yik∈{0,1} with k=0,…,⌊log2(ℓi)⌋ for being expanded in a weighted sum as an integer to fill the gap in inequality constraint i , the inequality constraint (9b) is converted to an equality constraint as follows:
∑j∈Txij+∑k=0⌊log2(ℓi)⌋2kyik=ℓi,i∈V(10)
View SourceRight-click on figure for MathML and additional features.where ⌊⋅⌋ is the floor operator. The total number of slack variables in (10) is ∑i∈V(⌊log2(ℓi)⌋+1) . A quadratic penalty term for equality constraint (10) is then defined as
pb(X,Y)=12∑i∈V(∑j∈Txij+∑k=0⌊log2(ℓi)⌋2kyik−ℓi)2
View SourceRight-click on figure for MathML and additional features.where Y=[yij]∈{0,1}nV×(maxi⌊log2(ℓi)⌋+1) is a matrix of slack variables.

Instead of adding slack variables, similar to a transformation technique in [58], two quadratic penalty terms for constraints (9c) and (9d) can be directly defined as follows:
pc(X)=pd(X)=12∑j∈Tl∑l=1lmax∑i∈Vl∑k<ixijxkj12∑j∈TC∑l=1lmax∑i∈Vl∑k<ixijxkj.
View SourceRight-click on figure for MathML and additional features.

A penalty term for equality constraints in (9e) is simply
pe(X)=∑l=1lmax∑j∈Tl∑i∈V∖Vlxij.
View SourceRight-click on figure for MathML and additional features.

In an implementation, it can practically be replaced by setting xij=0 for i∈V∖Vl,j∈Tl,l=1,…,lmax .

By introducing a binary instrumental variable zj∈{0,1} , constraints in (9f) become
∑l=1lmax∑i∈Vlxij−lmaxzj=0, j∈TC(11)
View SourceRight-click on figure for MathML and additional features.where zj is a binary selection variable for constraint j in (9f). The total number of slack variables in (11) is |TC| . A penalty term for constraint (11) is
pf(X,z)=12∑j∈TC(∑l=1lmax∑i∈Vlxij−lmaxzj)2
View SourceRight-click on figure for MathML and additional features.where z=[z1,…,z|TC|]T .

Let the pseudo-Boolean objective function in (9a) be redefined as
f(X):=∑j∈T∖TC∑i∈Vsij(Si)xij+1lmax−1∑j∈TC∑i∈V1∑k∈V,k≠isikj(Si,Sk)xkjxij.
View SourceRight-click on figure for MathML and additional features.

With the five quadratic penalty terms and objective function to be maximized, a penalty function and a penalized or augmented utility function are defined as follows:
p(X,Y,z)=fρ(X,Y,z)=pb(X,Y)+pc(X)+pd(X)+pe(X)+pf(X,z)f(X)−ρp(X,Y,z)(12)(13)
View SourceRight-click on figure for MathML and additional features.where ρ is a positive penalty parameter, X∈{0,1}nV×nT , Y∈{0,1}nV×(maxi⌊log2(ℓi)⌋+1) , and z∈{0,1}|TC| .

Based on the penalty function (12) and the penalized utility function (13), the original problem in (9) is expressed as follows:
max fρ(X,Y,z)s.t. X∈{0,1}nV×nTY∈{0,1}nV×(maxi⌊log2(ℓi)⌋+1)z∈{0,1}|TC|.(14a)(14b)(14c)(14d)
View SourceRight-click on figure for MathML and additional features.

Problems (9) and (14) are equivalent in terms of their optimal solutions if the penalty parameter is sufficiently large [57], [58].

SECTION IV.Neurodynamic Task Assignment
Since the utility function of the formulated optimization problem is nonconcave and feasible region is discrete, there are inevitably numerous local maxima of the utility function in the solution space. In view of the features of the problem, a population of DHNs is employed for scattered local search, instead of the continuous projection networks in [3]. In the CNO framework, the basic PSO rule is used for repetitive state reinitialization to escape from local maxima toward global optimal solutions.

Let three types of decision variables (namely, X , Y , and z ) be consolidated as X~=col([X,Y],z~T)∈Rn¯V×n¯T , where col denotes column concatenation operation, n¯V=nV+1 , n¯T=nT+maxi⌊log2(ℓi)⌋+1 , z~=[zT,0T]T , and 0 is an (n¯T−|TC| )-vector of zeros. In view of the matrix-valued decision variables in the formulated unconstrained binary quadratic programming problem (14), similar to [59], the DHN can be expressed as a gradient flow in a matrix form. For i=1,2,…,N
{Ui(t+1)=∇fρ(Xi~(t))Xi~(t+1)=σ(Ui(t+1))(15)
View SourceRight-click on figure for MathML and additional features.where N denotes the number of DHNs and ∇fρ(X~) is the gradient of fρ(X~) composed of a matrix of partial derivative of the utility function with respect to all elements of X~ .

In using the PSO rule in (4) and (5) for the state reinitialization of DHNs, the real values of the PSO rule need to be mapped to the vertices of a unit hypercube in the solution space. It can be done by thresholding to make the DHN initial states to be binary: x~ij(0)=1 if x~ij(0)≥0.5 or 0 otherwise.

In the collaborative neurodynamic TA approach, two hyperparameters need to be determined in an ad hoc manner, the population size of the DHNs, and the termination criterion as they depend on the inherent complexity of the problem at hand and the desired spatial and temporal complexities of the solution method. In general, the larger the population size N is, the faster the CNO approach converges to optimal or acceptable high-quality solutions. Therefore, it is a tradeoff between the spatial and temporal complexities. The termination criterion denoted by M is the minimum number of consecutive stationariness of the utility function value. Due to the stochastic nature of PSO-initialized multistart scattered search, M needs to be set with a fair value to reach the theoretically proven almost-sure convergence.

The DHN-based collaborative neurodynamic TA approach is detailed in Algorithm 2. Its main steps are explained as follows. In line 2, if there is no direct connection between the first two neurons, then add the first two neurons in the same batch; otherwise, put them in two different batches. For the following neuron, if there is no direct connection between it and all neurons in one of the batches, then put it in the batch; otherwise, put it into a new batch. Repeat the process for other neurons until all the neurons are put in batches. Lines 5–11 are for obtaining the equilibrium of a DHN. In line 6, a DHN is deemed to have converged if the neuronal state matrix remains unchanged. In line 12, the shuffle operation randomly changes the order of the sequence of neuronal activation in every iteration to diversify the state transition in the population of the DHNs. Line 16 updates the best solution of a single DHN. Line 21 updates the best solution for the group. Line 22 resets the counter. Lines 26–30 are for updating the initial states of the DHNs in the group.

Algorithm 2 - DHN-Based Collaborative Neurodyanmic Task Assignment
Algorithm 2
DHN-Based Collaborative Neurodyanmic Task Assignment

Show All

SECTION V.Experimental Results
A. Experiment Setups
The experiments are based on four applications: multivehicle TA for search and rescue, tracking and attacking, parcel delivery, and cooperative surveillance. Table I lists the parameters of the experiments, where some parameters are randomly generated within the given ranges similar to [2], [3], [7]. As in [1], [2], [7], and [3], the initial positions of vehicles and tasks in each experiment are randomly generated within 3-D spaces. One-third and two-thirds of tasks are set as single-vehicle tasks and lmax -vehicle tasks, respectively. In the literature, a common practice is to choose a number of pairs (nV,nT) with increased values [1], [2]. Without loss of generality, in the article, the values of (nV,nT) are set according to the common practice. As in [3], discount constants γi=0.05 for i∈V , w′ij∈(0,1) is randomly generated for i∈V1 , j∈TC , and w′′ij=1−w′ij for i∈V∖V1 and j∈TC .

TABLE I List of Parameters, Where SR Denotes Search and Rescue, TAT Denotes Tracking and Attacking, PD Denotes Parcel Delivery, and CS Denotes Cooperative Surveillance
Table I- 
List of Parameters, Where SR Denotes Search and Rescue, TAT Denotes Tracking and Attacking, PD Denotes Parcel Delivery, and CS Denotes Cooperative Surveillance
In Algorithm 2, the penalty parameter is set to 200, which is sufficiently large for the problems herein, and it works well on the four TA applications. The PSO parameters are set as c0=1 and c1=c2=0.1 . An elbow method for selecting two hyperparameters N (the size of the DHN population) and M (the termination criterion) in Algorithm 2 is used based on Monte Carlo tests with 100-run random initial states on the search and rescue dataset with (nV,nT)=(7,21) . As shown in Fig. 1, the objective function values reach its ceiling at 50 for most runs with N≥300 and M≥30 . As a result, the two hyperparameters are set as N=500 and M=50 in all experiments.

Fig. 1. - Monte Carlo test results for selecting hyperparameters 
$(N,M)$
 with 
$(n_{V},n_{T})=(7,21)$
 for search and rescue.
Fig. 1.
Monte Carlo test results for selecting hyperparameters (N,M) with (nV,nT)=(7,21) for search and rescue.

Show All

For the four applications with each pair of (nV,nT) , Monte Carlo test results with ten random initial conditions are averaged. In addition to the proposed approach CNO-H, CNO-P with three projection neural networks [3], PSO with penalty function (PSOP) [60], interior point method (IPM) [61] with multistart (MS) [62] and global-search (GS) [62], the consensus-based bundle algorithm (CBBA) [1], CBBA with task elimination (CBBATE) [1], and online Hungarian algorithm (OHA) [8] are used as baselines for performance comparisons with the same parameters for vehicles and tasks. In CNO-P and PSOP, the parameters are set the same as that in [3]. In IPMMS, 20 initial points for MultiStart macro and default parameters for fmincon macro in MATLAB are used. In IPMGS, default parameters in GlobalSearch and fmincon macros in MATLAB are used. In CBBA and CBBATE, the parameters are the same as the implementation in the webpage http://acl.mit.edu/projects/consensus-based-bundle-algorithm. In OHA, the planning horizons are divided evenly into maxi(ℓi) time windows so that the capacity requirements can be fulfilled. The reported experimental results in the ensuing tables are final values upon the convergence of all the competing algorithms.

B. Search and Rescue Applications
Search and rescue in urban/rural/marine areas are of critical importance for saving survivors. Heterogeneous vehicles are capable of completing the search and rescue tasks [2]. In search and rescue, two types of vehicles are considered. For example, one type of vehicle is used for providing medical services, and another type is for carrying the survivals. Suppose that there are three types of survivals: one type needs medical service, one type needs to be delivered away, and the third type needs medical service and to be delivered away at the same time.

Fig. 2 depicts four snapshots of dynamic behaviors of a DHN, including neuronal states, objective function, penalty function, and penalized utility function for search and rescue, where the neuronal states reach their equilibria within 70 iterations, and the penalty function and the utility function monotonically decrease to zero and increase to their maximum, respectively. Fig. 3 depicts a snapshot of iterative utilities of 500 DNHs in the CNO-based TA for search and rescue. Fig. 4 depicts iterative utilities of the ten-run Monte Carlo test for search and rescue, where the convergence for every run can be seen within 150 iterations of PSO-based reinitialization. Fig. 5 depicts CNO-generated time schedules for search and rescue. Table II shows the ten-run Monte Carlo test results, where five scores out of six are the highest with zero standard deviation much better than the scores by other baselines. It seems that the global maxima are reached there by each of the 500 DHNs.

TABLE II Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Search and Rescue, Where the Best Results are Boldfaced
Table II- 
Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Search and Rescue, Where the Best Results are Boldfaced
Fig. 2. - Four snapshots of dynamic behaviors of a DHN and its associated functions for search and rescue with 
$(n_{V},n_{T})=(7,21)$
.
Fig. 2.
Four snapshots of dynamic behaviors of a DHN and its associated functions for search and rescue with (nV,nT)=(7,21) .

Show All

Fig. 3. - Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for search and rescue with 
$(n_{V},n_{T})=(7,21)$
.
Fig. 3.
Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for search and rescue with (nV,nT)=(7,21) .

Show All

Fig. 4. - Iterative utilities of the CNO for search and rescue.
Fig. 4.
Iterative utilities of the CNO for search and rescue.

Show All

Fig. 5. - CNO-generated vehicle schedules for search and rescue. Tasks 
$t_{11}$
, 
$t_{12}$
, 
$t_{15}$
, 
$t_{16}$
, 
$t_{17}$
, and 
$t_{18}$
 correspond to survivals. They needs medical services and delivery services. They are completed by medical service providing vehicles (
$v_{1}$
, 
$v_{2}$
, and 
$v_{3}$
) and delivery service providing vehicles (
$v_{4}$
, 
$v_{5}$
, and 
$v_{6}$
).
Fig. 5.
CNO-generated vehicle schedules for search and rescue. Tasks t11 , t12 , t15 , t16 , t17 , and t18 correspond to survivals. They needs medical services and delivery services. They are completed by medical service providing vehicles (v1 , v2 , and v3 ) and delivery service providing vehicles (v4 , v5 , and v6 ).

Show All

C. Tracking and Attacking Applications
Tracking and attacking are to track targets and strike them, which can be done by using autonomous vehicles [1], [3]. There are two types of vehicles: one used for tracking targets; another for attacking the targets. There are three types of tasks: one needs to be tracked; another needs to be attacked; and the third needs to be tracked and attacked simultaneously.

Fig. 6 depicts four snapshots of dynamic behaviors of a DHN for tracking and attacking, where the neuronal states reach their equilibria within 100 iterations. Fig. 7 depicts a snapshot of iterative utilities of 500 DNHs in the CNO for tracking and attacking. Fig. 8 depicts iterative utilities of the ten-run Monte Carlo tests for tracking and attacking, where the convergence of every run can be seen after about 200 iterations of PSO-based reinitialization. Fig. 9 depicts a snapshot of time schedules of vehicles for tracking and attacking. Table III shows the ten-run Monte Carlo test results.

TABLE III Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Tracking and Attacking, Where the Best Results are Boldfaced
Table III- 
Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Tracking and Attacking, Where the Best Results are Boldfaced
Fig. 6. - Four snapshots of dynamic behaviors of a DHN and its associated functions for tracking and attacking with 
$n_{V}=4$
 and 
$n_{T}=23$
.
Fig. 6.
Four snapshots of dynamic behaviors of a DHN and its associated functions for tracking and attacking with nV=4 and nT=23 .

Show All

Fig. 7. - Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for tracking and attacking with 
$n_{V}=4$
 and 
$n_{T}=23$
.
Fig. 7.
Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for tracking and attacking with nV=4 and nT=23 .

Show All

Fig. 8. - Iterative utilities of the CNO-based task assignment for tracking and attacking.
Fig. 8.
Iterative utilities of the CNO-based task assignment for tracking and attacking.

Show All

Fig. 9. - CNO-generated vehicle schedules in completing tracking and attacking tasks. 
$v_{1}$
 and 
$v_{2}$
 are tracking vehicles. 
$v_{3}$
 and 
$v_{4}$
 are attacking vehicles. Tasks 
$t_{15}$
, 
$t_{16}$
, 
$t_{17}$
, 
$t_{19}$
, 
$t_{20}$
, 
$t_{21}$
, and 
$t_{23}$
 are tracked and attacked cooperatively.
Fig. 9.
CNO-generated vehicle schedules in completing tracking and attacking tasks. v1 and v2 are tracking vehicles. v3 and v4 are attacking vehicles. Tasks t15 , t16 , t17 , t19 , t20 , t21 , and t23 are tracked and attacked cooperatively.

Show All

D. Parcel Delivery Applications
Autonomous vehicles, such as UAVs, are deemed to be of critical importance for future parcel delivery [63]. Consider a TA problem with parcel load tasks [3]. There are multiple vehicles and parcels. Multiple vehicles cooperatively load parcels into a vehicle for delivery to destinations. There are also single-vehicle load tasks, which can be completed by a single vehicle.

Fig. 10 depicts four snapshots of dynamic behaviors of a DHN for parcel delivery, where the neuronal states reach their equilibria within 30 iterations. Fig. 11 depicts a snapshot of iterative utilities of 500 DNHs in CNO for parcel delivery. Fig. 12 depicts iterative utilities of the ten-run Monte Carlo tests for parcel delivery, where the convergence of every run can be seen within the first couple of iterations of PSO-based reinitialization. Fig. 13 depicts a snapshot of time schedules for parcel delivery. Table IV shows the ten-run Monte Carlo test results.

TABLE IV Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Parcel Delivery, Where the Best Results are Boldfaced
Table IV- 
Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Parcel Delivery, Where the Best Results are Boldfaced
Fig. 10. - Snapshot of dynamic behaviors of a DHN and its associated functions for parcel delivery with 
$(n_{V},n_{T})=(8,6)$
.
Fig. 10.
Snapshot of dynamic behaviors of a DHN and its associated functions for parcel delivery with (nV,nT)=(8,6) .

Show All

Fig. 11. - Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for parcel delivery with 
$(n_{V},n_{T})=(8,6)$
.
Fig. 11.
Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for parcel delivery with (nV,nT)=(8,6) .

Show All

Fig. 12. - Iterative utilities of the CNO-based tasked assignment for parcel delivery.
Fig. 12.
Iterative utilities of the CNO-based tasked assignment for parcel delivery.

Show All

Fig. 13. - CNO-generated vehicle schedules for parcel delivery, where two parcel load tasks 
$t_{6}$
 and 
$t_{4}$
 are cooperatively completed by six types of vehicles in an order from vehicles 
$v_{1}$
 to 
$v_{6}$
.
Fig. 13.
CNO-generated vehicle schedules for parcel delivery, where two parcel load tasks t6 and t4 are cooperatively completed by six types of vehicles in an order from vehicles v1 to v6 .

Show All

E. Cooperative Surveillance Applications
Unmanned vehicles can be used for cooperative surveillance of areas of interest [64]. Multiple vehicles (e.g., unmanned aerial vehicles) with devices (e.g., infrared detectors and cameras) are required to remain in an area at multiple time frames to cover the area for surveillance. Cooperation among two types of vehicles is able to increase the quality of surveillance. Surveillance tasks requiring single vehicles to complete are also available.

Fig. 14 depicts four snapshots of dynamic behaviors of a DHN for cooperative surveillance, where the neuronal states reach their equilibria in about 50 iterations. Fig. 15 depicts a snapshot of iterative utilities of 500 DNHs in CNO for cooperative surveillance. Fig. 16 depicts iterative utilities of the ten-run Monte Carlo tests, where the convergence of every run can be seen within around 60 iterations of PSO-based reinitialization. Fig. 17 depicts a snapshot of time schedules of vehicles for completing surveillance tasks. Table V shows the Monte Carlo test results, where three scores out of six (a half) reach the highest with zero standard deviation.

TABLE V Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Cooperative Surveillance, Where the Best Results are Boldfaced
Table V- 
Monte Carlo Test Results in Terms of Mean Values and Standard Deviations of Task Assignment Scores for Cooperative Surveillance, Where the Best Results are Boldfaced
Fig. 14. - Four snapshots of dynamic behaviors of a DHN and its associated functions for cooperative surveillance with 
$n_{V}=7$
 and 
$n_{T}=21$
.
Fig. 14.
Four snapshots of dynamic behaviors of a DHN and its associated functions for cooperative surveillance with nV=7 and nT=21 .

Show All

Fig. 15. - Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for cooperative surveillance with 
$n_{V}=7$
 and 
$n_{T}=21$
.
Fig. 15.
Snapshot of iterative utilities of 500 HNs in the CNO-based task assignment for cooperative surveillance with nV=7 and nT=21 .

Show All

Fig. 16. - Iterative utilities of the CNO-based task assignment for surveillance.
Fig. 16.
Iterative utilities of the CNO-based task assignment for surveillance.

Show All

Fig. 17. - CNO-generated vehicle schedules in completing cooperative surveillance tasks. Two coverages are formed at two time frames for surveillance. In particular, 
$t_{15}$
, 
$t_{13}$
, 
$t_{16}$
, 
$t_{18}$
, 
$t_{21}$
, and 
$t_{20}$
 are cooperatively completed by two types of vehicles 
$v_{1}$
, 
$v_{2}$
, 
$v_{3}$
, 
$v_{5}$
, 
$v_{6}$
, and 
$v_{7}$
 to increase surveillance quality. Tasks 
$t_{1}$
 and 
$t_{2}$
 are single-vehicle surveillance tasks completed by vehicle 
$v_{4}$
 with the first type.
Fig. 17.
CNO-generated vehicle schedules in completing cooperative surveillance tasks. Two coverages are formed at two time frames for surveillance. In particular, t15 , t13 , t16 , t18 , t21 , and t20 are cooperatively completed by two types of vehicles v1 , v2 , v3 , v5 , v6 , and v7 to increase surveillance quality. Tasks t1 and t2 are single-vehicle surveillance tasks completed by vehicle v4 with the first type.

Show All

In the four TA applications, all DHNs converge within one hundred iterations, as shown in Figs. 2, 6, 10, and 14. In addition, the CNO-based TA algorithm converges within around 110 iterations, as shown in Figs. 4, 8, 12, and 16. Moreover, the assignments fulfill the requirements of the capacity and schedule for the vehicles to cooperatively complete tasks, as shown in Figs. 5, 9, 13, and 17.

SECTION VI.Conclusion
In this article, a collaborative neurodynamic approach with multiple DHNs is proposed for the TA in multivehicle systems. The TA problem is formulated as a constrained binary quadratic programming problem and is reformulated as an unconstrained binary quadratic program via a penalty function converted from equality and inequality constraints. In a collaboration neurodynamic optimization framework, multiple DHNs are repetitively reinitialized by using the PSO rule in a scattered search for global optimal solutions to TA. The superior performance of the CNO-based multivehicle TA approach is substantiated with Monte Carlo experimental results in four typical applications for search and rescue, tracking and attacking, parcel delivery, and cooperative surveillance, in comparison to several existing TA approaches.