For a target task where the labeled data are unavailable, domain adaptation can transfer a learner from a different source domain. Previous deep domain adaptation methods mainly learn a global domain shift, i.e., align the global source and target distributions without considering the relationships between two subdomains within the same category of different domains, leading to unsatisfying transfer learning performance without capturing the fine-grained information. Recently, more and more researchers pay attention to subdomain adaptation that focuses on accurately aligning the distributions of the relevant subdomains. However, most of them are adversarial methods that contain several loss functions and converge slowly. Based on this, we present a deep subdomain adaptation network (DSAN) that learns a transfer network by aligning the relevant subdomain distributions of domain-specific layer activations across different domains based on a local maximum mean discrepancy (LMMD). Our DSAN is very simple but effective, which does not need adversarial training and converges fast. The adaptation can be achieved easily with most feedforward network models by extending them with LMMD loss, which can be trained efficiently via backpropagation. Experiments demonstrate that DSAN can achieve remarkable results on both object recognition tasks and digit classification tasks. Our code will be available at https://github.com/easezyc/deep-transfer-learning.

SECTION I.Introduction
In recent years, deep learning methods have achieved impressive success in computer vision [1], which, however, usually needs large amounts of labeled data to train a good deep network. In the real world, it is often expensive and laborsome to collect enough labeled data. For a target task with the shortage of labeled data, there is a strong motivation to build effective learners that can leverage rich labeled data from a related source domain. However, this learning paradigm suffers from the shift of data distributions across different domains, which will undermine the generalization ability of machine learning models [2], [3].

Learning a discriminative model in the presence of the shift between the training and test data distributions is known as domain adaptation or transfer learning [2], [4], [5]. Previous shallow domain adaptation methods bridge the source and target domains by learning invariant feature representa- tions [6]–[7][8] or estimate instance importance without using target labels [9]. Recent studies have shown that deep networks can learn more transferable features for domain adaptation [10], [11], by disentangling explanatory factors of variations behind domains. The latest advantages have been achieved by embedding domain adaptation modules in the pipeline of deep feature learning to extract domain-invariant representations [12]–[13][14][15][16].

The previous deep domain adaptation methods [13], [16], [17] mainly learn a global domain shift, i.e., aligning the global source and target distributions without considering the relationships between two subdomains in both domains (a subdomain contains the samples within the same class.). As a result, not only all the data from the source and target domains will be confused, but also the discriminative structures can be mixed up. This might loss the fine-grained information for each category. An intuitive example is shown in Fig. 1 (left). After global domain adaptation, the distributions of the two domains are approximately the same, but the data in different subdomains are too close to be classified accurately. This is a common problem in previous global domain adaptation methods. Hence, matching the global source and target domains may not work well for diverse scenarios.


Fig. 1.
Left: global domain adaptation might lose some fine-grained information. Right: relevant subdomain adaptation can exploit the local affinity to capture the fine-grained information for each category.

Show All

With regard to the challenge of global domain shift, recently, more and more researchers [14], [15], [18]–[19][20][21] pay attention to subdomain adaptation (also called semantic alignment or matching conditional distribution) which is centered on learning a local domain shift, i.e., accurately aligning the distribution of the relevant subdomains within the same category in the source and target domains. An intuitive example is shown in Fig. 1 (right). After subdomain adaptation, with the local distribution that is approximately the same, the global distribution is also approximately the same. However, all of them are adversarial methods that contain several loss functions and converge slowly. We list the comparison of the subdomain adaptation methods in Experiment IV.

Based on the subdomain adaptation, we propose a deep subdomain adaptation network (DSAN) to align the relevant subdomain distributions of activations in multiple domain-specific layers across domains for unsupervised domain adaptation. DSAN extends the feature representation ability of deep adaptation networks (DANs) by aligning relevant subdomain distributions as mentioned earlier. A key improvement over previous domain adaptation methods is the capability of subdomain adaptation to capture the fine-grained information for each category, which can be trained in an end-to-end framework. To enable proper alignment, we design a local maximum mean discrepancy (LMMD), which measures the Hilbert–Schmidt norm between kernel mean embedding of empirical distributions of the relevant subdomains in source and target domains with considering the weight of different samples. The LMMD method can be achieved with most feedforward network models and can be trained efficiently using standard backpropagation. In addition, our DSAN is very simple and easy to implement. Note that the most remarkable results are achieved by adversarial methods recently. Experiments show that DSAN, which is a nonadversarial method, can obtain the remarkable results for standard domain adaptation on both object recognition tasks and digit classification tasks.

The contributions of this article are summarized as follows.

We propose a novel deep neural network architecture for subdomain adaptation, which can extend the ability of DANs by capturing the fine-grained information for each category.

We show that DSAN, which is a nonadversarial method, can achieve the remarkable results. In addition, our DSAN is very simple and easy to implement.

We propose LMMD to measure the discrepancy between kernel mean embedding relevant subdomains in source and target domains and successfully apply it to DSAN.

A new local distribution discrepancy measure dAL is proposed to estimate the discrepancy between two subdomain distributions.

SECTION II.Related Work
In this section, we will introduce the related work in three aspects: domain adaptation, maximum mean discrepancy (MMD), and subdomain adaptation methods.

1) Domain Adaptation:
Recent years have witnessed many approaches to solve the visual domain adaptation problem, which is also commonly framed as the visual data set bias problem [2], [3]. Previous shallow methods for domain adaptation include reweighting the training data so that they can more closely reflect those in the test distribution [22], and finding a transformation in a lower dimensional manifold that draws the source and target subspaces closer [6]–[7][8], [23], [24].

Recent studies have shown that deep networks can learn more transferable features for domain adaptation [10], [11], by disentangling explanatory factors of variations behind domains. The latest advances have been achieved by embedding domain adaptation modules in the pipeline of deep feature learning to extract domain-invariant representa- tions [12]–[13][14][15][16], [25]. Two main approaches are identified among the literature. The first is statistic moment matching-based approach, i.e., MMD [13], [26], [27], central moment discrepancy (CMD) [28], and second-order statistics matching [16]. The second commonly used approach is based on an adversarial loss, which encourages samples from different domains to be nondiscriminative with respect to domain labels, i.e., domain adversarial net-based adaptation methods [17], [29], [30] borrowing the idea of GAN. Generally, the adversarial approaches can achieve better performance than the statistic moment matching-based approaches. In addition, most state-of-the-art approaches [14], [29], [31] are domain adversarial net-based adaptation methods. Our DSAN is an MMD-based method. We show that DSAN without adversarial loss can achieve remarkable results.

2) Maximum Mean Discrepancy:
MMD has been adopted in many approaches [8], [13], [27] for domain adaptation. In addition, there are some extensions of MMD [7], [26]. Conditional MMD [7] and joint MMD [26] measure the Hilbert–Schmidt norm between kernel mean embedding of empirical conditional and joint distributions of the source and target data, respectively. Weighted MMD [32] alleviates the class weight bias by assigning class-specific weights to source data. However, our local MMD measures the discrepancy between kernel mean embedding relevant subdomains in source and target domains with considering the weight of different samples. CMMD [7], [23], [33] is a special case of our LMMD.

3) Subdomain Adaptation:
Recently, we have witnessed considerable interest and research [14], [15], [18], [20] for subdomain adaptation that focuses on accurately aligning the distributions of the relevant subdomains. Multiadversarial domain adaptation (MADA) [15] captures the multimode structures to enable fine-grained alignment of different data distributions based on multiple-domain discriminators. Moving semantic transfer network (MSTN) [20] learns the semantic representations for unlabeled target samples by aligning labeled source centroid and pseudolabeled target centroid. CDAN [14] conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Co-DA [18] constructs multiple diverse feature spaces and aligns source and target distributions in each of them individually while encouraging that alignments agree with each other with regard to the class predictions on the unlabeled target examples. The adversarial loss is adopted by all of them. However, compared DSAN with them, our DSAN that is more simple and easy to implement can achieve better performance without adversarial loss.

SECTION III.Deep Subdomain Adaptation Network
In unsupervised domain adaptation, we are given a source domain Ds={(xsi,ysi)}nsi=1 of ns labeled samples (ysi∈RC is an one-hot vector indicating the label of xsi , i.e., ysij=1 means xsi belonging to the j th class, where C is the number of classes.) and a target domain Dt={xtj}ntj=1 of nt unlabeled samples. Ds and Dt are sampled from different data distributions p and q , respectively, and p≠q . The goal of deep domain adaptation is to design a deep neural network y=f(x) that formally reduces the shifts in the distributions of the relevant subdomains in different domains and learns transferable representations simultaneously such that the target risk Rt(f)=E(x,y)q[f(x)≠y] can be bounded by leveraging the source domain supervised data.

Recent studies reveal that deep networks [34] can learn more transferable representations than traditional handcrafted features [11], [35]. The favorable transferability of deep features leads to several popular deep transfer learning methods [12], [13], [26], [36], which mainly use adaptation layers with a global domain adaptation loss to jointly learn a representation. The formal representation can be
minf1ns∑i=1nsJ(f(xsi),ysi)+λd^(p,q)(1)
View Sourcewhere J(⋅,⋅) is the cross-entropy loss function (classification loss) and d^(⋅,⋅) is domain adaptation loss. λ>0 is the tradeoff parameter of the domain adaptation loss and the classification loss.

The common problem with these methods is that they mainly focus on aligning the global source and target distributions without considering the relationships between subdomains within the same category of different domains. These methods derive a global domain shift for the source and target domains, and the global distribution of the two domains is approximately the same after adaptation. However, the global alignment may lead to some irrelevant data too close to be classified accurately. Actually, while by exploiting the relationships between the subdomains in different domains, just aligning the relevant subdomain distributions can not only match the global distributions but also the local distributions mentioned earlier. Therefore, subdomain adaptation that exploits the relationships between two subdomains to overcome the limitation of aligning global distributions is necessary.

To divide the source and target domains into multiple subdomains that contain the samples within the same class, the relationships between the samples should be exploited. It is well known that the samples within the same category are more relevant. However, data in the target domain is unlabeled. Hence, we would use the output of the networks as the pseudolabels of target domain data, which will be detailed later. According to the category, we divide Ds and Dt into C subdomains D(c)s and D(c)t where c∈{1,2,…,C} denotes the class label, and the distributions of D(c)s and D(c)t are p(c) and q(c) , respectively. The aim of subdomain adaptation is to align the distributions of relevant subdomains that have samples with the same label. Combining the classification loss and subdomain adaptation loss, the loss of subdomain adaptation method is formulated as
minf1ns∑i=1nsJ(f(xsi),ysi)+λEc[d^(p(c),q(c))](2)
View Sourcewhere Ec[⋅] is the mathematical expectation of the class. To compute the discrepancy in 2 between the relevant subdomain distributions based on MMD [37] that is a nonparametric measure, we propose LMMD to estimate the distribution discrepancy between subdomains.

A. Maximum Mean Discrepancy
MMD [37] is a kernel two-sample test, which rejects or accepts the null hypothesis p=q based on the observed samples. The basic idea behind MMD is that if the generating distributions are identical, all the statistics are the same. Formally, MMD defines the following difference measure:
dH(p,q)≜∥Ep[ϕ(xs)]−Eq[ϕ(xt)]∥2H(3)
View Source

where H is the reproducing kernel Hillbert space (RKHS) endowed with a characteristic kernel k . Here, ϕ(⋅) denotes some feature map to map the original samples to RKHS and the kernel k means k(xs,xt)=⟨ϕ(xs),ϕ(xt)⟩ , where ⟨⋅,⋅⟩ represents inner product of vectors. The main theoretical result is that p=q if and only if DH(p,q)=0 [37]. In practice, an estimate of the MMD compares the square distance between the empirical kernel mean embeddings as
d^H(p,q)==∥∥∥∥1ns∑xi∈Dsϕ(xi)−1nt∑xj∈Dtϕ(xj)∥∥∥∥2H1n2s∑i=1ns∑j=1nsk(xsi,xsj)+1n2t∑i=1nt∑j=1ntk(xti,xtj)−2nsnt∑i=1ns∑j=1ntk(xsi,xtj)(4)
View Sourcewhere d^H(p,q) is an unbiased estimator of dH(p,q) .

B. Local Maximum Mean Discrepancy
As a nonparametric distance estimate between two distributions, MMD has been widely applied to measure the discrepancy between the source and target distributions. Previous deep MMD-based methods [13], [26], [38] mainly focus on the alignment of the global distributions, ignoring the relationships between two subdomains within the same category. Taking the relationships of the relevant subdomains into consideration, it is important to align the distributions of the relevant subdomains within the same category in source and target domains. With the desire to align distributions of the relevant subdomains, we propose the LMMD as
dH(p,q)≜Ec∥Ep(c)[ϕ(xs)]−Eq(c)[ϕ(xt)]∥2H(5)
View Sourcewhere xs and xt are the instances in Ds and Dt , and p(c) and q(c) are the distributions of D(c)s and D(c)t , respectively. Different from MMD that focuses on the discrepancy of global distributions, 5 can measure the discrepancy of local distributions. By minimizing 5 in deep networks, the distributions of relevant subdomains within the same category are drawn close. Therefore, the fine-grained information is exploited for domain adaptation.

We assume that each sample belongs to each class according to weight wc . Then, we formulate an unbiased estimator of 5 as
d^H(p,q)=1C∑c=1C∥∥∥∥∑xsi∈Dswsciϕ(xsi)−∑xtj∈Dtwtcjϕ(xtj)∥∥∥∥2H(6)
View Sourcewhere wsci and wtcj denote the weight of xsi and xtj belonging to class c , respectively. Note that ∑nsi=1wsci and ∑ntj=1wtcj are both equal to one, and ∑xi∈Dwciϕ(xi) is a weighted sum on category c . We compute wci for the sample xi as
wci=yic∑(xj,yj)∈Dyjc(7)
View Sourcewhere yic is the c th entry of vector yi . For samples in the source domain, we use the true label ysi as a one-hot vector to compute wsci for each sample. However, in unsupervised adaptation where the target domain has no labeled data, we can not calculate 6 directly with the ytj unavailable. We find that the output of the deep neural network y^i=f(xi) is a probability distribution that well characterizes the probability of assigning xi to each of the C classes. Thus, for target domain Dt without labels, it is a natural idea to use y^ti as the probability of assigning xti to each of the C classes. Then, we can calculate wtcj for each target sample. Finally, we can calculate 6.

It is easy to access the labels of the source domain, while for the target domain, the label predicted (hard prediction) by the model might be wrong, and using this wrong label might degrade the performance. Hence, using the probability prediction (soft prediction) might alleviate the negative impact. Note that CMMD, which assumes that each sample has the same weight, is a special case of LMMD, whereas LMMD takes the uncertainty of target samples into consideration.

To adapt feature layers, we need the activations in the layers. Given source domain Ds with ns labeled instances and target domain Dt with nt unlabeled points drawn independent identically distributed (i.i.d.) from p and q , respectively, the deep networks will generate activations in layers l as {zsli}nsi=1 and {ztlj}ntj=1 . In addition, we cannot compute the ϕ(⋅) directly. Then, we reformulate 6 as
d^l(p,q)=1C∑c=1C[∑i=1ns∑j=1nswsciwscjk(zsli,zslj)+∑i=1nt∑j=1ntwtciwtcjk(ztli,ztlj)−2∑i=1ns∑j=1ntwsciwtcjk(zsli,ztlj)](8)
View Sourcewhere zl is the l th (l∈L={1,2,…,|L|} ) layer activation. Equation 8 can be used as the adaptation loss in 2 directly, and the LMMD can be achieved with most feedforward network models.

C. Deep Subdomain Adaptation Network
Based on LMMD, we propose DSAN as shown in Fig. 2. Different from previous global adaptation methods, DSAN not only aligns the global source and target distributions but also aligns the distributions of the relevant subdomains by integrating deep feature learning and feature adaptation in an end-to-end deep learning model. We try to reduce the discrepancy between the relevant subdomain distributions of the activations in layers L . We use the LMMD in (8) over the domain-specific layers L as the subdomain adaptation loss in the following equation:
minf1ns∑i=1nsJ(f(xsi),ysi)+λ∑l∈Ld^l(p,q).(9)
View SourceSince training deep CNNs requires a large amount of labeled data that are prohibitive for many domain adaptation applications, we start with the CNN models pretrained on the ImageNet 2012 data and fine-tune it as [26]. The training of DSAN mainly follows standard minibatch stochastic gradient descent (SGD) algorithm. It is worth noting that, with DSAN iteration, the labeling for target samples usually becomes more accurate. This EM-like pseudolabel refinement procedure is empirically effective, as shown in the experiments.


Fig. 2.
Left: architecture of DSAN. DSAN will formally reduce the discrepancy between the relevant subdomain distributions of the activations in layers L by using LMMD minimization. Right: LMMD module needs four inputs: the activations zsl and ztl where l∈L , the ground-truth label ys , and the predicted label y^t .

Show All

Remark:
The theory of domain adaptation [39], [40] suggests A -distance as a measure of distribution discrepancy, which, together with the source risk, will bound the target risk. The proxy A -distance is defined as dA=2(1−2ϵ) , where ϵ is the generalization error of a classifier (e.g., kernel SVM) trained on the binary problem of discriminating the source and target. The A -distance just focuses on the global distribution discrepancy; hence, we propose the AL -distance to estimate the subdomain distribution discrepancy. First, we define dA of class c as dAc=2(1−2ϵc) , where ϵc is the generalization error of a classifier trained on the same class in different domains. Then, we define dAL=E[dAc]=2E[1−2ϵc]=2∑Cc=1p(c)(1−2ϵc) , where E[⋅] denotes the mathematical expectation and p(c) denotes the probability of class c in the target domain.

D. Theoretical Analysis
In this section, we give an analysis of the effectiveness of using the classifier predictions on the target samples, making use of the theory of domain adaptation [39], [41].

Theorem 1:
Let H be the hypothesis space. Given two domains S and T , we have
∀h∈H,RT(h)≤RS(h)+12dHΔH(S,T)+C(10)
View Sourcewhere RS(h) and RT(h) are the expected error on the source samples and target samples, respectively. RS(h) can be minimized easily with source label information. Besides, dHΔH(S,T) is the domain divergence measure by a discrepancy distance between two distributions S and T . Actually, there are many approaches to minimize dHΔH(S,T) , such as adversarial learning [12], MMD [13], and Coral [16]. C is the shared expected loss and is expected to be negligibly small, thus usually disregarded by previous methods [12], [13]. However, it is possible that C tends to be large when the cross-domain category alignment is not explicitly enforced. Hence, C needs to be bounded as well. Unfortunately, we cannot directly measure C without target true labels. Therefore, we utilize the pseudolabels to give the approximate evaluation and minimization.

Definition 1:
C is defined as
C=minh∈HRS(h,fS)+RT(h,fT)(11)
View Sourcewhere fS and fT are true labeling functions for source and target domain, respectively.

We show our DSAN is trying to optimize the upper bound for C . From [39], for any labeling functions f1,f2 , and f3 , we have
R(f1,f2)≤R(f1,f3)+R(f2,f3).(12)
View SourceThen, we have
C=≤≤minh∈HRS(h,fS)+RT(h,fT)minh∈HRS(h,fS)+RT(h,fS)+RT(fS,fT)minh∈HRS(h,fS)+RT(h,fS)+RT(fS,fT^)+RT(fT,fT^)(13)
View Sourcewhere fT^ is pseudolabeling function for target domain. The first term RS(h,fS) and the second term RT(h,fS) denotes the disagreement between h and the source labeling function fS on source and target samples, respectively. Since h is learned with the labeled source samples, the gap between them can be very small. The last term RT(fT,fT^) denotes the discrepancy between the ideal target labeling function fT and the pseudolabeling function fT^ , which would be minimized as learning proceeds. Then, we should focus on the third term RT(fS,fT^)=Ex∼T[l(fS(x),fT^(x))] , where l(⋅,⋅) is typically 0–1 loss function. The source samples of class k would be predicted with label k by the source labeling function fS . If the feature of target samples in class k is similar with the source feature in class k , the target samples can be predicted the same as the pseudotarget labeling function. Therefore, if the distributions of subdomains in different domain are matching, RT(fS,fT^) is expected to be small.

In summary, by aligning relevant subdomain distributions, our DSAN could further minimize the shared expected loss C . Hence, utilizing the prediction of the target samples is effective for unsupervised domain adaptation.

SECTION IV.Experiment
We evaluate DSAN against competitive transfer learning baselines on object recognition and digit classification. The four data sets, including ImageCLEF-DA, Office-31, Office-Home, and VisDA-2017, are used for object recognition task, while for digit classification, we construct the transfer tasks from MNIST, USPS, and SVHN. We denote all transfer tasks as source domain → target domain.

A. Setup
ImageCLEF-DA1 is a benchmark data set for ImageCLEF 2014 domain adaptation challenge, which is organized by selecting 12 common categories shared by the following three public data sets, each is considered as a domain: Caltech-256 (C), ImageNet ILSVRC 2012 (I), and Pascal VOC 2012 (P). There are 50 images in each category and 600 images in each domain. We use all domain combinations and build six transfer tasks: I→ P, P→ I, I→ C, C→ I, C→ P, P→ C.

Office-31 [43] is a benchmark data set for domain adaptation, comprising 4110 images in 31 classes collected from three distinct domains: Amazon (A), which contains images downloaded from amazon.com, and Webcam (W) and DSLR (D), which contain images taken by Web camera and digital SLR camera with different photographical settings, respectively. To enable unbiased evaluation, we evaluate all methods on all six transfer tasks A→ W, D→ W, W→ D, A→ D, D→ A, W→ A as in [12], [26], and [38].

Office-Home [44] is a new data set, which consists of 15588 images and is much larger than Office-31 and ImageCLEF-DA. It consists of images from four different domains: artistic images (A), clip art (C), product images (P), and real-world images (R). For each domain, the data set contains the images of 65 object categories collected in office and home settings. Similarly, we use all domain combinations and construct 12 transfer tasks.

VisDA-2017 [45] is a challenging simulation-to-real data set, with two very distinct domains: synthetic, renderings of 3-D models from different angles and with different lightning conditions, and real, natural images. It contains over 280k images across 12 classes in the training, validation, and test domains.

MNIST-USPS-SVHN: We explore three digit data sets: MNIST [46], USPS, and SVHN [47] for transfer digit classification. Different from Office-31, MNIST contains gray digit images of size 28×28 , USPS contains 16×16 gray digits, and SVHN contains color 32×32 digits images that might contain more than one digit in each image. We conduct experiments on three transfer tasks MNIST → USPS, USPS → MNIST, and SVHN → MNIST.

Baseline Methods: For ImageCLEF-DA and Office-31, we compare our model DSAN with several standard deep learning methods and deep transfer learning methods: deep convolutional neural network (ResNet) [1], deep domain confusion (DDC) [38], DAN [13], Deep CORAL (D-CORAL) [16], domain adversarial neural networks (DANNs) [17], residual transfer network (RTN) [26], adversarial discriminative domain adaptation (ADDA) [30], joint adaptation networks (JANs) [26], MADA [15], collaborative and adversarial network (CAN and iCAN) [31], generate to adapt (GTA) [42], and conditional adversarial domain adaptation (CDAN and CDAN+E) [14]. For Office-Home, we compare DSAN with ResNet, DAN, DANN, JAN, and CDAN, and the results of all baselines are extracted from [14] and [15]. For VisDA-2017, we compare DSAN with ResNet, DANN, DAN, JAN, and MCD [48], and the results of all baselines are extracted from [49].

For MNIST-USPS-SVHN, we compare DSAN with DANNs [17], deep reconstruction classification networks (DRCNs) [50], coupled generative adversarial networks (CoGANs) [51], ADDA [30], unsupervised image-to-image translation networks (UNIT) [], asymmetric tritraining domain adaptation (ATDA) [53], GTA [42], and MSTN [20]. The results of SourceOnly, DANN, DRCN, CoGAN, ADDA, and GTA are extracted from [42]. For the rest, we refer to the results in their original articles.

Implementation Details For object recognition tasks, we employed the ResNet [1]. Following CDAN [14], a bottleneck layer fcb with 256 units is added after the last average pooling layer for safe transfer representation learning. We use the output of fcb as inputs to the LMMD. Note that, it is easy to add LMMD in multiple layers and we only add LMMD to one layer. Also, image random flipping and cropping are adopted following JAN [26]. For a fair comparison, all baselines use the same architecture (for VisDA-2017, we use ResNet101 [1], whereas ResNet50 for others). We fine-tune all convolutional and pooling layers from ImageNet pretrained models and train the classifier layer via back-propagation. Since the classifier is trained from scratch, we set its learning rate to be ten times that of the other layers. For digit classification tasks, we follow the protocols in ADDA [30] and use the same architecture with ADDA.

For all tasks, we use minibatch SGD with a momentum of 0.9 and the learning rate annealing strategy in Revgrad [12]; the learning rate is not selected by a grid search due to high computational cost, it is adjusted during SGD using the following formula: ηθ=η0/(1+αθ)β , where θ is the training progress linearly changing from 0 to 1, η0=0.01 , α=10 , and β=0.75 . To suppress noisy activations at the early stages of training, instead of fixing the adaptation factor λ , we gradually change it from 0 to 1 by a progressive schedule: λθ=2/exp(−γθ)−1 , and γ=10 is fixed throughout the experiments [12].

We implement DSAN in PyTorch and report the average classification accuracy and standard error of three random trials. For all MMD-based methods [13], [26], [38] including DSAN, we adopt Gaussian kernel with bandwidth set to median pairwise squared distances on the training data [37].

B. Results
1) Object Recognition:
The classification results of ImageCLEF-DA, Office-31, Office-Home, and VisDA-2017 are, respectively, shown in Tables I–IV. DSAN outperforms all compared methods on most transfer tasks. In particular, DSAN substantially improves the average accuracy by large margins (more than 3%) on Image-CLEF, Office-Home, and VisDA-2017. The encouraging results indicate the importance of subdomain adaptation and show that DSAN is able to learn more transferable representations.

TABLE I Accuracy (%) on ImageCLEF-DA for Unsupervised Domain Adaptation (ResNet50)

TABLE II Accuracy (%) on Office-31 for Unsupervised Domain Adaptation (ResNet50)

TABLE III Accuracy (%) on Office-Home for Unsupervised Domain Adaptation (ResNet50)

TABLE IV Accuracy (%) on VisDA-2017 for Unsupervised Domain Adaptation (ResNet101)

The experimental results further reveal several insightful observations.

In standard domain adaptation, subdomain adaptation methods (MADA [15], CDAN [14], and our DSAN) outperform previous global domain adaptation methods. The improvement from previous global domain adaptation methods to subdomain adaptation methods is crucial for domain adaptation; previous methods align global distribution without considering the relationship between subdomains, whereas DSAN accurately aligns the relevant subdomain distributions, which can capture more fine-grained information for each category.

In particular, comparing DSAN with the most recent subdomain adaptation methods [14], [15], DSAN achieves better performance. This verifies the effectiveness of our model.

Comparing DSAN with the nonadversarial methods [13], [16], [26], [38], DSAN also largely improves the average performance on 24 object recognition tasks (6.65% higher than JAN [26]).

Comparing DSAN with LMMD, DAN with MMD, and JAN with JMMD, DSAN achieves the best performance, which implies that LMMD is more suitable for aligning distributions than MMD and JMMD.

2) Digit Classification:
The classification results of three tasks of MNIST–USPS–SVHN are shown in Table V. Except for DRCN [50], all other baselines are adversarial ones. DSAN largely outperforms all baselines except SVHN → MNIST task. Comparing DSAN with MSTN [20] which is also a subdomain adaptation method, DSAN achieves better average accuracy and more stable results with lower standard error.

TABLE V Accuracy (%) on Digit Recognition Tasks for Unsupervised Domain Adaptation. (“− ” Means That We Did Not Find the Result on the Task)

Overall, all the abovementioned results demonstrate the effectiveness of the proposed model.

C. Analysis
1) Feature Visualization:
We visualize in Fig. 3(a) and (b) the network activations of task A→ W learned by JAN and DSAN (both use Gaussian kernel) using t-SNE embeddings [10]. Red points are source samples and blue are target samples. Fig. 3(a) shows the result for JAN [26], which is a typical statistic moment matching-based approach using JMMD. We can find that the source and target domains are not aligned very well and some points are hard to classify. In contrast, Fig. 3(b) shows the representations learned by our DSAN using LMMD. It is observed that the source and target domains are aligned very well. We not only can see that the subdomains in different domains with the same class are very close but also the subdomains with different classes are dispersed. This result suggests that our model DSAN is able to capture more fine-grained information for each category than JAN, and LMMD is more effective than JMMD to align the distributions.


Fig. 3.
(a) and (b) Visualizations of the learned representations using t-SNE for JAN and DSAN on task A→W , respectively. Red points are source samples and blue are target samples. (c) A -distance and AL -distance on task A→W . (d) MMD and (e) LMMD on task A→W .

Show All

2) Distribution Discrepancy:
We use A -distance and AL -distance mentioned in Section III-C to measure global distribution discrepancy and the subdomain distribution discrepancy. Fig. 3(c) shows dA and dAL on task A→ W with representations of CNN, JAN, and DSAN. We observe that dA and dAL using DSAN are much smaller than the ones using CNN and JAN, which shows that DSAN can not only close the cross-domain gap but also one of relevant subdomains more effectively.

MMD is a method to measure the discrepancy of global distributions, whereas LMMD is a method to measure the discrepancy of local subdomain distributions. We compute MMD and LMMD across domains on task A→ W using CNN, JAN, and DSAN based on the features in pool layer and ground-truth labels. Fig. 3(d) shows that both MMD and LMMD using DSAN activations are much smaller than using CNN and JAN activations, which again validates that DSAN successfully reduces the discrepancy of global and local distributions. In addition, LMMD is smaller than MMD for the reason that LMMD can estimate the distribution discrepancy by eliminating the irrelevant data.

3) Convergence:
We testify the convergence of CDAN, CDAN+E, and DSAN, with the test errors on task D → A (Office31) shown in Fig. 4. From Fig. 4(a), with the same number of iterations, DSAN achieves faster convergence than CDAN and CDAN+E. From Fig. 4(b), with the same period, DSAN also converges faster. Besides, the results further reveal that for each iteration, DSAN runs faster than CDAN and CDAN+E.


Fig. 4.
On task D → A (Office31), we further analyze the convergence. (a) Convergence (iteration). (b) Convergence (time).

Show All

4) Discussion on the Advantage of DSAN:
To give an overview of the results, we further compare our DSAN with several adversarial subdomain adaptation methods [14], [15], [18], [20] in Table VI and find some insightful observations. First, the adversarial subdomain adaptation methods usually have several loss functions, while DSAN only needs one classification loss and one LMMD loss. In addition, DSAN only has one hyperparameter, whereas MSTN [20] and Co-DA [18] have several hyperparameters. DSAN has fewer loss terms and hyperparameter, which also indicates the easy implementation. Second, comparing DSAN with MADA [15] and CDAN [14], DSAN also takes less time to converge. Third, DSAN achieves the best performance. Especially, DSAN achieves 3% accuracy higher than CDAN [14] which is one of the most recent subdomain adaptation methods. Overall, all the results again validate the advantage of our model DSAN.

TABLE VI Comparison of the Subdomain Adaptation Methods. K in MADA Means the Number of Classes. Parameter Means the Number of Hyperparameters in the Methods. Time Means the Average Convergence Time on the ImageCLEF-DA Data Set (Seconds). Time Is Measured on a GeForce GTX 1080 Ti GPU by Ourselves. Accuracy Means the Average Accuracy on the ImageCLEF-DA Data Set. “− ” Means That We Dose Not Find the Results From the Original Article

SECTION V.Conclusion
Unlike the previous methods that align the global source and target distributions, subdomain adaptation can accurately align the distributions of relevant subdomains within the same category of the source and target domains. However, most recent subdomain adaptation methods are adversarial approaches that contain several loss functions and converge slowly. Based on this, we proposed a new method DSAN, which is a nonadversarial method and very simple and easy to implement. Furthermore, to measure the discrepancy between relevant subdomains within the same category of different domains, we proposed a new local distribution discrepancy measure LMMD. Extensive experiments conducted on both object recognition and digit classification tasks demonstrate the effectiveness of the proposed model.
