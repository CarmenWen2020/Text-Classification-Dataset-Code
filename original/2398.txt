Brain tumor is one of the most dangerous cancers in people of all ages, and its grade recognition is a challenging problem for radiologists in health monitoring and automated diagnosis. Recently, numerous methods based on deep learning have been presented in the literature for brain tumor classification (BTC) in order to assist radiologists for a better diagnostic analysis. In this overview, we present an in-depth review of the surveys published so far and recent deep learning-based methods for BTC. Our survey covers the main steps of deep learning-based BTC methods, including preprocessing, features extraction, and classification, along with their achievements and limitations. We also investigate the state-of-the-art convolutional neural network models for BTC by performing extensive experiments using transfer learning with and without data augmentation. Furthermore, this overview describes available benchmark data sets used for the evaluation of BTC. Finally, this survey does not only look into the past literature on the topic but also steps on it to delve into the future of this area and enumerates some research directions that should be followed in the future, especially for personalized and smart healthcare.

SECTION I.Introduction
The past decades of image processing and computer vision arena [1]–[2][3] have helped humanity in the identification of various diseases through automated diagnostic processes [1], [4]–[5][6]. These processes in the medical domain have hitherto-assisted medical staff and specialists by providing a second option in many diagnostic procedures [7]–[8][9][10]. Among all hazardous diseases, cancer is considered as a threat to mankind due to its fatal nature. Traditionally, a specialist analyzes medical images and, manually, estimates the probability of developing a tumor [11]. Manually identifying a tumor’s sign and relying on this decision for the prescription of subsequent medical treatments is an option that most of the medical practitioners would avoid because of the lethal nature of the brain tumor [12]. The most sophisticated and safest way of analyzing the medical images is through computer vision techniques [13], [14]. It includes fleeting images through various software with built-in algorithms for tumor detection and classification. These algorithms can also be adjusted for implementing tumor segmentation, which denotes the process of separating the infected regions from healthy areas of a medical image under observation [15], [16].

The early detection and classification of a brain tumor are of utmost necessity for the effective and timely treatment of a patient [17], [18]. The human visual cortex is known to be limited in its capability to decide between different levels of gray, as present in magnetic resonance imaging (MRI) [19]. This gives birth to computer-aided diagnosis (CAD) or brain tumor classification (BTC) methods that are suitable for supporting radiologists in visualizing and defining tumor types. These automated processes for brain tumor detection, segmentation, and classification play a vital role in serving humanity by reducing the chances of surgery (biopsy) [15], [20]–[21][22]. Whenever radiologists get confused about the nature of the tumor, or they want to visually inspect it in depth, these methods are always there to help them [23], [24]. Image processing and computer vision scientists are interested in providing precise and efficient methods for automatic detection, classification, and segmentation of tumors.

These methods are broadly divided into two categories: traditional machine learning methods and deep learning methods [25]. Traditional BTC methods are based on low-level features and on the application of statistical learning approaches for the classification of a brain tumor [26]–[27][28][29]. Segmentation methods falling within this category focus on the estimation of the tumor’s boundaries and its localization, which involves some preprocessing steps, such as contrast enhancement, image sharpening, and edge detection/refining. The basic workflow of traditional BTC methods follows image acquisition, preprocessing, ROI segmentation, feature extraction and selection, dimensionality reduction, classification, and performance evaluation, as visually summarized in Fig. 1 [30]. In contrast to traditional approaches, deep learning-based methods mainly depend on the training data with significantly fewer preprocessing needs than traditional counterparts. It is evident from the literature related to deep learning that the accuracy of a system is highly dependent on the amount of data, particularly in the domain of BTC [31], [32]. Most deep learning methods in BTC rely on convolutional neural networks (CNNs). Indeed, the increased usage of CNNs for several computer vision problems in various domains [33]–[34][35][36] motivates adopting them for BTC, particularly for smart health monitoring. Therefore, in what follows, we focus on this branch of deep learning methods.


Fig. 1.
Basic workflow of the traditional BTC and analysis methods.

Show All

CNNs-based BTC methods follow a three-step process toward predicting the presence of a brain tumor or its grade, as shown in Fig. 2. The first preprocessing step includes noise removal and segmentation methods to segment the tumor from the MRI. The second step is training, where labels and learned features of each image from the data set are provided to the classifier for training. The classifier learns the patterns of different grades/classes of tumors from the labeled training data. The testing phase applies the same feature extraction strategy applied in the training phase, but it only extracts features from a single query image. This feature vector is passed/fed to the trained classifier for the final prediction of brain tumor class/grade, depending on the trained classifier. The accuracy of CNN classifiers is significantly higher compared with traditional approaches, making them suitable for radiologists in real-world clinical practice [37], [38].


Fig. 2.
General flow of deep learning (CNN)-based methods for BTC. The overall flow consists of three steps: 1) preprocessing; 2) training; and 3) testing. Additional steps can be added and/or adjusted as per the requirements of the target users.

Show All

This overview capitalizes on the magnificent momentum featured by deep learning for BTC by comprehensively reviewing the literature related to CNN and BTC. We critically examine advances reported so far at this crossroads and provide a solid knowledge base to support a prospect of future research topics that remain insufficiently explored to date. Furthermore, we complement our survey by providing empirical evidence of the potential of CNN-based BTC by investigating different CNN models to gauge the tradeoff between accuracy and time complexity. The models presented can balance trade among these conflicting objectives, depending on the situation under consideration. Due to the lack of annotated data that often underlies practical experiences with deep learning-based BTC, we conduct several experiments where this issue is addressed through data augmentation. Specifically, we discuss several investigated models over two publicly accessible data sets: multigrade brain tumor data set [32] and brain tumor public data set [31]. The original contributions of our survey can be summarized as follows.

In this survey, we cover all existing CNNs-based BTC methods, discussing their achievements and limitations. We explore the overall literature of BTC and highlight its major domains, research trends, and niches, as well as benchmark data sets available for experimentation.

Inspired by recent achievements of deep learning models in image classification, we investigate and fine-tune several pretrained CNN models for BTC using two different data sets with and without data augmentation. We provide detailed statistics of these models with various parameters, which can be used by different researchers and radiologists for further investigation and diagnostic assistance.

With the recent increase in the usage of smart devices and cloud/fog/edge computing in smart cities, it is feasible to use these technologies for healthcare systems. Therefore, in this survey, we highlight the personalized usage of BTC for patients, remote specialists, and medical centers for smart healthcare services. This can make its integration into the current smart city ecosystem easier and its widespread deployment and adoption more sustainable.

This survey identifies the current challenges of the BTC domain and summarizes the overall deep learning-based literature in a single perspective overview. Moreover, we provide recommendations and future directions to motivate other scientists for further research in this domain.

The remainder of this article is divided into seven sections. Existing surveys and their critique are discussed in Section II. The coverage of our survey with detailed analysis is given in Section III. The available data sets and transfer learning techniques in BTC are addressed in Sections IV and V, respectively. A comparative study of different CNN models is given and discussed in Section VI. BTC challenges and future research directions are identified in Section VII. Conclusions and an outlook on the field are given in Section VIII.

SECTION II.Existing Surveys
In this section, we review five different existing BTC surveys ranging from 2014 to 2019, with their details given in Table I. The major parts reviewed in this survey are publication year, literature coverage, number of reviewed articles, and several remarks to highlight the overall impact of each survey and its weaknesses.

TABLE I Detailed Analysis and Comparison of Our Study With Existing Surveys

There are several limitations of existing surveys, which are addressed in our survey. Among them, the most limiting issue is their lack of detailed reviews to highlight the limitations of other studies and motivations for a new survey. Second, the majority of BTC surveys do not provide detailed future research directions, which is a compulsory section for any survey, encouraging researchers to depart from the state of the art in valuable directions. More specifically, existing surveys focus on brain tumor segmentation and/or classification using handcrafted representation-based methods. Thus, this area lacks a comprehensive study of learned representations-based methods for BTC.

With these motivations in mind, we conduct this survey for CNNs-based multigrade tumor classification methods. We first detach our overview from existing surveys by providing a comprehensive comparison and detailed analysis with their pros and cons. The second issue stated earlier is solved by introducing a separate section (see Section VII) with current challenges of BTC and detailed future directions for further research. An overview of BTC methods with an emphasis on CNN-assisted approaches is depicted in Fig. 3. The temporal distribution of the CNN-based BTC literature is given in Fig. 4.


Fig. 3.
Overall distribution of deep learning-based BTC methods. Our survey focuses exclusively on deep learning-based methods.

Show All


Fig. 4.
Significance of the surveyed learned representation-based BTC methods in terms of aggregated citations per year. These statistics are collected from Google Scholar on February 24, 2020.

Show All

SECTION III.Reviewed BTC Methods
In this section, we briefly discuss the architectures and overall methodologies of the existing literature, as given in Table II. As illustrated in Fig. 2, segmentation of the tumor region is the primary step in the general pipeline of BTC, which is mostly targeted by existing segmentation techniques [32], [39]–[40][41][42]. On the other hand, some methods used end-to-end models for both segmentation and classification [43]–[44][45][46][47]. Since the focus of this study is on BTC, we will cover only BTC approaches or those methods using segmentation followed by classification.

TABLE II Detailed Description of the Deep Learning Based Methods With Their Respective Segmentation, Features, Classifiers, and Total Number of Classified Classes

In the reviewed literature, several tumor segmentation methods [48]–[49][50][51][52] are used as the primary step prior to classification. For instance, Akkus et al. [39] classified the brain tumor using three steps: 1) registration of images with a cubic b-spline interpolation technique; 2) tumor segmentation with a semiautomatic LGG software; and 3) classification into 1p/19q status using a CNN model. This method is evaluated with MRI data of 159 patients, with proven 1p/19q status. Different data augmentation techniques are used to balance the data distribution. Likewise, Paul et al. [53] presented two types of neural networks for the classification of brain tumors with data augmentation to improve the performance of their method. Another approach presented by Ahmed et al. [54] utilized pretrained AlexNet model for the detection of Glioblastoma Multiforme and the estimation of the survival time of patients with this disease. Balasooriya and Nawarathna [55] developed their own custom CNN for BTC. They evaluated their method using TCIA [56] data set that is divided into five different classes: Astrocytoma, Gliobastoma Multiforme, Oligodendroglioma, healthy tissue, and unidentified tumor. Wong et al. [40] proposed a medical image classifier for 3-D brain images. They extracted features from the segmentation network (M-Net) and fed them into a pretrained VGG-16 model for three-class brain tumor types classification. Mohsen et al. [41] segmented the tumor regions from 2-D brain MRI images using Fuzzy C-mean clustering and then extracted discrete wavelet transform (DWT) features, followed by principal component analysis (PCA) for feature compression. They passed the compressed features on to a deep neural network (DNN), having seven hidden layers for classification.

Compared with the aforementioned studies, certain methods focused only on BTC. For example, Afshar et al. [57] attempted to address the major two problems of CNNs for the BTC problem, i.e., the need for large volumes of training data and the lack of significant capability to handle transformations. They explored Capsule Networks (CapsNets) with four main objectives, i.e., achieving maximum accuracy for BTC, investigation of the overfitting problem, the suitability of CapsNets for only segmented tumor regions or whole MRI images, and visualization of MRI learned features for better understanding. CapsNets work well for BTC. However, they are highly sensitive to the miscellaneous image background. In follow-up work, Afshar et al. [62] elaborated on this problem by proposing a modified CapsNets model, which considers the tumor’s boundaries during its main pipeline for BTC.

Ge et al. [45] proposed a 3-D multiscale CNN model for the classification of glioma tumors into high- and low-level grades. They introduced a feature fusion scheme, which further refined the multiscale features to enhance tumor regions. In another work, Ge et al. [46] used 2-D-CNN with feature aggregation to enhance the performance of classification. Decuyper et al. [63] used pretrained VGG model and extracted features from the first fully connected layer for the classification of glioma into high- and low-level grades. Banerjee et al. [64] presented a deep CNN-based CAD system for gliomas classification. Pereira et al. [42] first extracted the tumor regions using a 3-D-U-Net model and then fed them into their proposed Glioma grading CNN after resizing the images. In their proposed CNN model, global average pooling is used to summarize each feature map, followed by a cascade of 1×1×1 convolutional layer, which acts as a fully connected layer.

Still, on the usage of CNNs, Anaraki et al. [65] recently proposed a CNN model, which was evolved using a genetic algorithm for classification of Glioma into three grades. Similarly, Sajjad et al. [32] first segmented the tumor regions using deep features and then fine-tuned a VGG-19 pretrained model to classify the tumor into four grades. They used eight different data augmentation techniques with a total of 30 parameters to extend the existing data sets for training. More recently, six new methods have been reported in the area of BTC using MRI. The detailed information about these new studies and all previous methods in terms of segmentation, employed features, classifier, data set, and target classes are shown in Table II.

SECTION IV.Data Sets
In the literature related to BTC, several data sets have been furnished within the community, targeting both binary and multiclass classification problems. Among all the publicly available data sets, representative data sets are covered in this section. The majority of BTC data sets are from local hospitals or laboratories that are not publicly available for the research community. The publicly available data sets are multigrade brain tumor data set [32], Brain tumor public data set [31], The Cancer Imaging Archive (TCIA) [56], BRATS 2015 [66], Harvard (AANLIB) [67], and the Internet brain segmentation repository (IBSR) [68], whose details are given in Sections IV-A–IV-F, respectively.

A. Multigrade Brain Tumor Data Set [32]
There are two variants of this data set: the original one that consists of 121 MRI instances and the augmented data set, containing 3630 MRI instances created from the original images. The overall data set is divided into four different grades according to the standard classification of WHO tumors of the Central Nervous System [77]. The overall distribution and statistics of this data set are given in Table III, and sample images are visualized in Fig. 5(a).The information about data augmentation and other necessary details are given in [32].

TABLE III Statistics of Multigrade Brain Tumor Data Set [32] Grades With and Without Augmentation


Fig. 5.
Sample images from both data sets. (a) Multigrade brain tumor data set. (b) Brain tumor public data set.

Show All

B. Brain Tumor Public Data Set [31]
This data set was captured from two different hospitals in China in the duration of 2005–2010. It consists of 3064 T1-weighed CE-MRI slices, collected from 233 different patients. The size of each slice in this data set is 512×512 , with 6 and 1 mm, slice thickness and gap, respectively. The tumor region inside each slice is segmented manually by three experienced radiologists. This data set is divided into three classes, i.e., Meningiomas, Gliomas, and Pituitary tumors. The complete statistics of this data set are given in Table IV, while representative slices from each class are shown in Fig. 5(b).

TABLE IV Brain Tumor Public Data Set [31] Statistics for Each Class, With and Without Augmentation

C. Cancer Imaging Archive (TCIA) [56]
This repository contains several collections of cancer imagery, but only a few of them are related to our problem of BTC. The concerned group with our problem in this repository is BRAIN-DSC-MRI, which contains two types of brain tumors: low- and high-grade gliomas. The data is collected from 49 patients of different ages.

D. BRATS 2015 [66]
The BRATS 2015 data set is created for brain tumor segmentation. However, in several contributions [78]–[79][80], it has been used for tumor classification. It consists of two types of tumors: low- and high-grade gliomas. The overall data set consists of 274 MR scans with 220 and 54 for high- and low-grade glioma, respectively. The MRI scanning is performed using four modalities: T1, T1c, T2, and Flair, with an image size of 240×240×155 .

E. Harvard (AANLIB) [67]
The whole-brain Atlas or ANNLIB is an online repository for MRI of the Central Nervous System. This database is available online, consisting of more than 13 000 brain MRIs of 30 different cases. These MRIs contain a large variety of normal and tumor images including different types of stroke or brain attacks, several types of gliomas, Alzheimer’s, and infectious diseases.

F. Internet Brain Segmentation Repository [68]
IBSR is an open-source repository for brain tumor segmentation and classification. This data set consists of 18 T1 3-D MRI scans. Each of the MRI scans contains 60–65 slices, with a resolution of 256×256 pixels. The data is collected from 14 male and four female patients aged seven to 71 years, covering a large variability of brain anatomies.

SECTION V.Transfer Learning for Medical Image Analysis
Due to the advancement in deep learning, transfer learning techniques have been integral to almost every field of computer vision, i.e., multimedia [81], surveillance [82], and medical [83]. Among these domains, transfer learning in medical imaging is the most prominent, where the weights of standard models, trained on nonmedical images or natural image classification data sets, particularly ImageNet [84], are fine-tuned on medical imaging data. This transfer learning process is adopted in almost every modality of medical imaging, including X-rays, CT scans, pathological images, positron emission tomography (PET), and MRI [85].

In this section, our main target is to review transfer learning techniques based on MR images, especially brain tumor segmentation, classification, and retrieval. The detailed descriptions of each method including publication year, pretrained model, and data set with its main target, are given in Table V. The range of these methods is from 2015 to 2019, starting from traditional machine learning techniques to state-of-the-art deep learning models. In addition, we also review a few transfer learning methods, focusing on breast cancer recognition and prostate cancer classification, to show the importance of transfer learning in the medical imaging domain, i.e., MR images.

TABLE V Detailed Description of Medical Imaging With a Focus on MRI Transfer Learning Techniques

SECTION VI.Comparative Study of Different CNNs
As discussed in Section III, several CNNs and their variants, such as VGG-16, VGG-19, and CapsNets, have been already explored in the literature for BTC. However, the baseline and most popular CNN architectures have not been deeply investigated for this problem. Furthermore, some of the existing studies have used a single data set for experiments and validation of BTC results. For instance, [43] and [44] investigated CapsNets for BTC but using only a single data set introduced in [106]. Due to these reasons, it is important to investigate the baseline and recent CNN models for BTC using multiple data sets. To this end, this section compares several state-of-the-art CNNs for BTC using two data sets, i.e., [32] as “Data set 1” and [31] as “Data set 2.” The remaining four data sets are either not freely available or contain 3-D images that are different from the first two data sets and cannot be processed by the CNNs under consideration. The CNNs used for the comparison are AlexNet [107], GoogleNet [105], VGG [70], SqueezeNet [108], MobileNet [109], and ResNet [110]. The system used for the implementation of these CNNs is equipped with an NVidia GetForce TITAN X (Pascal) GPU. Furthermore, we use Caffe [111] deep learning framework with NVidia DIGITS [112] for the evaluation. During the training process of each model, several options about different parameters are considered due to which the output accuracy varies. These parameters include the number of epochs, which affects the accuracy positively up to a certain limit. As per the current training setup, we selected 30 epochs because the accuracy stops increasing after this limit. Another important parameter for consideration is the learning rate, which is opted as 0.001 as optimal after exhaustive experiments. The next parameter affecting accuracy is the solver type, which was selected to be stochastic gradient descent due to its better performance [113]. The final parameter is Softmax loss function, which computes the multinomial logistic loss of the Softmax classifier [114].

The detailed results of all CNNs over Data set 1 and Data set 2 are given in Table VI. Three evaluation metrics, including accuracy, frames per second (fps), and model size, are used during experiments for comparison. Accuracy shows the correct predictions of each BTC approach, while fps refers to the processing speed of each method under consideration. The model size is the amount of memory needed for the deployment of the final prediction architecture. The first metric “accuracy” is considered in the majority of the studies for comparison than the latter two metrics “fps” and “model size.” We considered all metrics for comparison to show the strength of each architecture under consideration, considering their performance and practicality.

TABLE VI Experimental Results of Different CNN Models Over Data Set 1 and Data Set 2 With Accuracy and Necessary Details. The Terms “WOA” and “WA” Used in This Table Refer to “Without Augmentation” and “With Augmentation,” Respectively

It can be observed from the obtained results that SqueezeNet achieved the best fps and model size due to its efficiency. However, in most cases, the model is overfit, i.e., completely biased toward a single class on both data sets. AlexNet and GoogleNet achieved almost similar results but not higher enough for consideration in the CAD system due to its critical nature. Furthermore, the results of MobileNet and ResNet are also low and are not trustworthy enough for their implementation in real-world BTC systems. Results show that VGGNet obtained the best accuracy compared with all other CNNs under consideration, with a similar average fps but larger model size than other CNNs. These results are insightful to both industry and hospitals in the sense that they can select a method of their choice, considering their requirements, accuracy, deployment environment, and other constraints.

SECTION VII.Challenges, Recommendations, and Future Research Directions
Processing and analyzing MRI data of brain tumors are among the most challenging tasks for computer vision scientists. MRI is an advanced technique for producing high-quality images of the human body parts [115]. It plays a key role in processing and detecting the right stage and in deciding the correct therapy for the tumor-infected person. To accomplish this task, researchers have proposed many automatic techniques by using MRI (T1, T2, and FLAIR) [116], [117]. The main reason is that these MRIs are not affected by radiations, and their contrast is better compared with other modalities. This point is taken into consideration in medical image analysis, as several parameters, including similarity measures, modality, image contents, transformation, implementation, and optimization of algorithms, affect the performance. Similarly, the selection of a machine learning method for BTC is also a crucial step, requiring a careful assessment. Most machine learning methods resort to features extracted from images via traditional strategies, followed by their classification. This process can be overly complex and time-consuming if the extracted features are highly dimensional. Other problems associated with machine learning approaches include the diversity of classes and challenges associated with distance measurement between images. It can also be observed that medical images are usually affected by low-light contrast, deteriorating their quality, which consequently affects the classification accuracy.

Recently, methods relying on learned representations (deep learning, especially CNNs) have gained momentum for BTC problems at the expense of handcrafted feature-based methods [41]. Despite their strength and huge popularity, CNN-based methods encounter many challenges. For instance, they require a huge amount of data for training, which can be either not available for each domain, or it can be very challenging to get the desired accuracy for a target problem [118]. Also, increasing the number of layers in a CNN model cannot guarantee an increase in classification accuracy. Similarly, deep learning models are computationally expensive due to their underlying running hardware devices (GPU and RAM). Thus, deploying these models in real scenarios, especially in clinical practice, remains an unsolved challenge [119]. Concluding the challenges faced by the current research community, there are several recommendations and future directions for research scientists. Achieving higher accuracy is always the priority while dealing with problems related to healthcare with CAD techniques. The literature of BTC is richer in terms of studies; however, certain areas still need further extensive research. The future recommendations of BTC literature are schematically represented in Fig. 6 with a focus on personalized and smart healthcare that is briefly discussed in Sections VII-A–VII-J.


Fig. 6.
Generic diagram for future research recommendations, where the MRI generated data are processed through GAN to create new images and the newly created data set plus the existing data are passed to an end-to-end deep learning model, generating the detailed results. The output data are distributed to various places, where it can be analyzed further for different purposes. Considering the available resources and required users’ services, the optimal computing platform can be used for analysis. This provides personalized medical services, leading to smart healthcare.

Show All

A. Public Availability of BTC Data Sets
The main issue with the BTC literature is the scarcity of public data sets. Many researchers are passionate to work in this field, but there are still a severely limited number of publicly available data repositories. This restricts the experimentation and testing of new BTC methods and their maturity compared with other domains, where data sets can be accessed freely (e.g., ImageNet data set [120]). As mentioned previously, the major requirement of any deep learning model is the huge amount of annotated data for achieving better accuracy scores. Unfortunately, most of the existing BTC data sets contain a limited number of images for each class, resulting in lower accuracy levels for the implemented methods. For this reason, we used data augmentation in our experiments in Section VI. Furthermore, the majority of already available data sets only provide data for high-level classification, with no focus on further grades of brain tumors that can be very helpful to radiologists for early diagnosis. Therefore, it is highly recommended to create challenging data sets with detailed grading of each image in future research and ensure their availability for the benefit of the entire research community.

B. End-to-End Deep Learning Models
Although the majority of the recent techniques are based on deep learning, they use different models for detection, classification, and segmentation, as discussed in Section III. This increases the computational complexity of the implemented methods, making them less suitable for their consideration in clinical practice. Currently, there is no end-to-end deep learning model, which can detect a tumor in the input MRI image, segment it, and classify its nature as a final output. Thus, both industry and academia are highly encouraged to further investigate deep learning models for the problem of BTC in this context. This can greatly reduce the overall running time of the target BTC model, ultimately matching the practical constraints of smart healthcare and clinical practice.

C. Edge Intelligence for MRI Data Analysis
Edge intelligence is used on a wide scale in different domains [121], [122] because of its numerous advantages, such as reduced bandwidth and threats, minimal latency, improved consistency, compliance, and lower cost. For instance, Chen et al. [123] presented a deep learning and edge intelligence-assisted system for distributed video surveillance applications. Their system processes data at network edges instead of network centers, reducing communication overhead, thereby providing accurate video analysis results with elastic and scalable computing power. Similarly, Pace et al. [124] proposed “BodyEdge,” a framework for supporting healthcare applications in industry 4.0 with the main focus on reducing the data load toward the Internet. In the field of BTC, the MRI data are normally collected in the Digital Imaging and Communications in Medicine (DICOM) format, which is manually converted into slices for further analysis. This process is time-consuming and tedious with comparatively higher changes of errors. Through edge intelligence, the DICOM images can be automatically processed over the capturing device for efficient analysis with better accuracy. Currently, there is no such a concept of edge intelligence for the specific problem of BTC, which can be a new trend for further research in this domain.

D. Merging Fog and Cloud Computing With Federated Learning: A New Dawn for BTC
Fog computing is an extension of cloud computing performed over the edge through a distributed network. Fog computing makes it easy to facilitate the regular processing and generates the output fast enough by using capabilities of edge network [125]. In the medical field, the data collected from a specific MRI capturing device should be quickly formulated and processed over different cloud and fog layers for efficient analysis. This can be possible by exploring fog and cloud computing with an extensive investigation of the new emerging framework of AI “Federated Learning” (FA) for BTC in future studies. In FA architecture, models use the distributed mobile/edge devices for computation due to their recently improved capabilities for executing a machine learning model. Using this hybrid computing platform, a model can be improved by training it locally via the data collected by the concerned edge device, and the changes in terms of model parameters and weights can be reported to cloud through a secure communication link, e.g., homomorphic encryption as employed by Feng et al. [126] for outsourcing big data in the federated cloud environment. The most important aspect of FA is the preservation of user’s privacy, which is utterly important in the medical domain. In the case of BTC, the output of brain tumors, classified into various grades, will be generated directly over the cloud or fog, making the overall process smarter and more feasible compared with manual lengthy processes.

E. Advanced Data-Enrichment Techniques
Data augmentation can be used to generate data up to an extent, which can be used for training deep learning BTC systems. However, the quality of generated data stalls or even degrades after a certain level of augmentation is reached. Thus, more advanced data-enrichment techniques need to be investigated for BTC. Generative adversarial networks (GANs) are among the advanced data-enrichment techniques and are widely used for many applications in diverse domains, such as medical image synthesis [127], [128], compressive sensing MRI [129], [130], superresolution [130], security [131], classification [132], image-to-image transformation [133], and many other useful purposes. GAN creates new data instances from the existing data, realistically complying with the distribution of the input data. As mentioned earlier, the main problem in the BTC literature is the lack of data, which is currently handled through various data augmentation techniques. GAN has still not been explored yet for the problem of BTC, which can easily handle the limited data problem by generating new similar data from the input images. Thus, it is recommended for scientists working in BTC domain to utilize GANs for new data generation to effectively solve the limited data problem and possibly improve the performance of state-of-the-art methods.

F. Sequential Learning in DICOM Images
DICOM images are sequences of slices captured in an order, where some slices have a small size, while others have a large size of tumors [134]. The appearance of a brain tumor varies in size and angle in different slices. When these slices are converted into normal image formats, we may not locate the exact position of a brain tumor. Singular 2-D image data cannot provide enough information that can be used in further treatment of tumors using laser therapy. This problem is not addressed in the current literature, needing special attention from both industry and academia. In future work, the DICOM image slices in a group should be analyzed sequentially, which can give enough information in the 3-D form to find the exact location of the brain tumor. Thus, it can directly help and facilitate specialists in various diagnosis processes that are applied after finding the exact location of a brain tumor.

G. Effective Methods for Commercial Clinical Applications
There is a special need for trustworthy methods in the BTC literature, which can be implemented in clinics and hospitals on a commercial scale and can be extended to smart healthcare [135]. The accuracy achieved by deep learning-based BTC methods is better than traditional methods and convincing enough to be considered as a second opinion for medical specialists. However, it still needs improvements in terms of accuracy, execution time, flexibility, cost, and scalability for commercialization and practicability in real-world medical applications.

H. Confidence and Explainability in Learning-Based BTC
Another crucial aspect when undertaking BTC via machine learning methods is to also consider the usability of the developed methods by medical practitioners. Indeed, the performance (accuracy) of the model when detecting and estimating the severity of a tumor is of pivotal importance due to the relevance and consequences of decisions to be made upon the model’s output. However, for the medical community to embrace the benefits of deep learning methods used for this purpose, there are far more aspects to be considered beyond model performance. Usability aspects, such as the confidence of the output, must be also placed under the spotlight for the developed models to be actionable. The reliability of the produced predictions (as estimated, for instance, by methods such as test dropout [136] or Bayesian deep learning methods [137]) can, indeed, make the medical specialist feel more confident with decisions supported by black-box deep learning models.

Likewise, there is a rising concern with assessing what deep learning models eventually learn to observe from data, particularly in the medical domain. Reasons span beyond the usability of the model: recently reported cases confirm that there is little knowledge about what models surpassing human performance in the diagnosis of certain diseases are learning from data [138], [139]. Posthoc techniques for eXplainable Artificial Intelligence [140], [141] can give the clue needed not only to disentangle the knowledge learned by these powerful methods but also to open up new medical research directions.

I. Internet of Medical Things
Recently, the Internet of Medical Things (IoMT) attracted more attention of the researchers due to the rapid development in intelligent technologies and real-time data sharing using the Internet of Things (IoT) [142], [143]. Due to the efficient data sharing and communication technologies, the concept of the IoT has been adopted by almost every field of research, i.e., smart networking [144], energy management [145], business [146], healthcare [147], and medical [148]. Among these areas, the medical domain especially dealing with brain diseases is considered the most severe case due to the life-threatening issues of patients. Considering this aspect, BTC can be implemented in IoMT, which will minimize the life risk of brain tumor patients by providing the necessary precaution online and informing them about their grade of the tumor. The main advantage of BTS integration with the IoMT is to treat the patients in remote areas, i.e., those who have limited access to medical services. The reported performance of existing reviewed methods and models is good enough to be considered in real-time scenarios. However, there are still several challenges for researchers to present a complete IoMT environment for taking decisions in real-time. These challenges include privacy preservation [149], the computational complexity of deep learning models [150], the latency of deployed networks [151], and the compatibility of smart devices with existing technologies [152], all needing effective solutions for smooth integration with existing medical and patients management systems for smart and personalized healthcare.

J. Synergies With Other Areas of Computational Intelligence
The interest in deep learning has propelled intense research efforts around this family of machine learning models in the last few years, yielding countless applications such as the one targeted in this overview. However, many issues underneath the use of deep learning methods still remain insufficiently addressed to date. Renowned practical caveats include the difficult architectural design of deep learning models, the slow convergence of backpropagation for highly complex deep architectures, their relative lack of interpretability, or the burdensome hyperparameter tuning phase required for such models to perform optimally for a given task [153]. The wide acknowledgment of the research community around these problems has ignited a shift of focus toward hybridizing deep learning models with elements from other areas of computational intelligence [154], with an emphasis lately placed on the use of evolutionary computation and swarm intelligence.

Indeed, a growing number of research works have focused on different flavors of bio-inspired optimization heuristics to overcome problems inherently deriving from deep learning as the ones exemplified earlier. For instance, the use of different forms of evolutionary programming has given rise to tools to automate the design and configuration of complex neural architectures [155], much like a fresh renaissance of old concepts intersecting neural and evolutionary computation (e.g., NEAT). In this same line of reasoning, bio-inspired heuristics specially devoted to undertake large-scale global optimization problems can be thought today to be a serious competitor to the classical gradient backpropagation algorithm that dominates the spectrum of training algorithms for deep architectures [156]. Further intersections between these two areas include a more effective transfer of the learned knowledge between different classification tasks that, for the medical area, can be a catalyst to allow using deep learning models in new scenarios with scarcely available data [156].

We believe that as in any other specific application area, deep learning models empowered with evolutionary computation, edge and swarm intelligence, and FA will expedite and increase the quality of its results when facing new problems in multigrade brain tumor detection and characterization, eventually reaching unprecedented levels of self-configurability, knowledge transferability, and accuracy. For this to occur, newcomers to the field should steer their efforts toward this expectedly profitable research avenue.

SECTION VIII.Conclusion
Considering the recent development in the domain of BTC and the limitations of existing studies, we presented a comprehensive survey of deep learning-based BTC methods. Deep learning technologies accurately assist radiologists in predicting the tumor regions and further classifying them into their respective types. Many researchers contributed to the field of BTC, but many challenges remain therein. Therefore, we conducted this study to provide the overall literature of deep learning-based BTC methods in a single survey and to draw the attention of both academia and industry toward the necessary development in this domain. This article comprehensively discussed all deep learning-based BTC methods, with their achievements and weaknesses, followed by complete information about the existing publicly available data sets with their respective resources. In order to empirically inform the conclusions drawn from our literature study, we experimentally analyze various deep learning models by performing extensive experiments over BTC data sets and highlighted the suitable option for consideration in smart health care. Finally, this study highlighted key challenges, such as lack of public data sets and end-to-end deep learning models, and suggested detailed directions for further research in BTC domain, i.e., exploring edge/fog/cloud computing with FA, advanced data-enrichment techniques, model confidence and explainability, IoMT, and deep investigation of sequential and transfer learning strategies. This can increase the maturity level of BTC methods with better applicability for commercial clinical applications and their smooth integration with smart healthcare.

The brain is an intriguing system whose complexity demands sophisticated means to understand and characterize its behavior. The unrivaled learning capability of deep learning models has made them the standard choice to detect and classify brain tumors from MRI images and other monitored data alike, spawning a flurry of research activity overviewed in this survey. We hope that the numerous research paths outlined in our overview will serve as supportive material for the research community currently working on this field and a stimulating read for newcomers to this domain.