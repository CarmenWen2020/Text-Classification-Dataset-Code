This paper proposes an enhanced robot skill learning system considering both motion generation and trajectory tracking. During robot learning demonstrations, dynamic movement primitives (DMPs) are used to model robotic motion. Each DMP consists of a set of dynamic systems that enhances the stability of the generated motion toward the goal. A Gaussian mixture model and Gaussian mixture regression are integrated to improve the learning performance of the DMP, such that more features of the skill can be extracted from multiple demonstrations. The motion generated from the learned model can be scaled in space and time. Besides, a neural-network-based controller is designed for the robot to track the trajectories generated from the motion model. In this controller, a radial basis function neural network is used to compensate for the effect caused by the dynamic environments. The experiments have been performed using a Baxter robot and the results have confirmed the validity of the proposed methods.

SECTION I.Introduction
Recently, robots have been widely applied in various fields, especially in manufacturing. Adaptable robots are required due to the increasingly fast updates of the manufactured products. Hence, it is necessary to develop methods for enhancing robot learning. Robot learning from demonstration (LfD) is a valuable technique to simplify the strategy of robot learning [1], [2]. The human tutor shows the way to complete a task and then the robot learns, via motion modeling, to reproduce the skill. Therefore, it is essential to consider how to model motions effectively.

The dynamic system (DS) is a powerful tool for motion modeling [3]. Compared to the conventional methods, e.g., interpolation techniques, DS offers a flexible solution to model stable and extensible trajectories. In addition, the motion encoded with the DS is robust to perturbations. An approach based on DS was used to learn human motions [4], where the unknown mapping of the DS was approximated using a neural network (NN) called extreme learning machine [5]. The learned model showed adequate stability and generalization. However, this DS-based method required considerable demonstration data for training. In contrast, the dynamic movement primitive (DMP), which is based on a nonlinear DS [6], only requires one demonstration to model motion; here, the DMP models the movement trajectory as a spring-damper system integrated with an unknown function to be learned. The inherent property of the spring-damper system enhances the stability and robustness (to perturbations) of the generated motion.

DMPs have been often employed to solve robot learning problems because of their flexibility. In [7], DMPs were modified to model fast movement inherent in hitting motion. Another study used reinforcement learning to combine DMP sequences so that the robot could perform more complex tasks [8]. While both these studies employed multiple DMPs to compose a complete action, another study [9] used multiple DMPs to model style-adaptive trajectory, where the style of the generated motion could be changed by modulating the weight parameters that were coupled with the goals. As mentioned in [10], optimal demonstration is difficult to obtain and multiple demonstrations can encode the ideal trajectory implicitly. Therefore, we consider integrating multiple demonstrations into one DMP model in this paper.

Probabilistic approaches have shown good performance in motion encoding [11]–[12][13]. The inherent variability of the demonstrations can be extracted, and thus, more features of the demonstrations can be preserved. In [14], an LfD framework using a Gaussian mixture model (GMM) and a Bernoulli mixture model was used to extract the features from multiple demonstrations. A new motion was generated through Gaussian mixture regression (GMR). In contrast with the above-mentioned methods, GMM combined with GMR can provide additional motion information for robots when learning from multiple demonstrations. In [3], a learning approach named stable estimator of dynamical systems (SEDS) was proposed for motion modeling, where an unknown function was modeled using GMR. DS-GMR is another method that combines the DS with the statistical learning approach [15]. Both methods exploit the robustness and generalization capability of the DS as well as the excellent learning performance of the probabilistic methods.

To take advantage of the performance of the DS and the probabilistic approach, we integrate DMP and GMM into our proposed system, where the nonlinear function of DMP is modeled with GMM and its estimate is retrieved through GMR. This modification enables the robot to extract more features of the motions from multiple demonstrations and to generate motions that synthesize these features. The original DMP was learned using the locally weighted regression (LWR) [16], and the locally weighted projection regression [17] was employed to optimize the bandwidth of each kernel of LWR. Despite the added complexity of the learning procedure, these methods enable the DMP to learn from only one demonstration. Reservoir computing [18] is another method used to approximate the nonlinear function, but its computing efficiency is less than that of GMR.

The imitation performance of robots also depends on the accuracy of the trajectory tracking controller that involves the robot dynamics. Generally, a model-based control performs better if the model is accurate enough [19]. However, an accurate dynamic model of a manipulator cannot be obtained in advance due to some uncertainties, e.g., unknown payload. The approximation-based controllers have been designed to overcome such uncertainties. They utilize function approximation tools to learn the nonlinear characteristics of the robot dynamics. NNs have been widely used in controller design because of their approximation ability [20]–[21][22]. In [23], the backpropagation NN (BPNN) was utilized to approximate the unknown nonlinear function in the model of the vibration suppression device, while in [24], the radial basis function NN (RBFNN) was utilized to approximate the unknown nonlinearity of the telerobot system. Compared to BPNN, the learning procedure of RBFNN is based on local approximation; thus, RBFNN can avoid getting stuck in the local optimum and has a faster convergence rate. Besides, the number of hidden layer units of RBFNN can be adaptively adjusted during the training phase, making NN more flexible and adaptive. Therefore, RBFNN is more appropriate for the design of real-time control.

In this paper, an NN-based controller is designed to guarantee the tracking performance of the manipulator in joint space, where RBFNN is employed to approximate the nonlinear functions of the robot dynamics. The stability of the controller is guaranteed by the Lyapunov stability theory. As shown in Fig. 1, the robot learning system consists of the motion generation component and the trajectory tracking component. The former utilizes the motion model based on DMP to learn and generalize motion skills; these, in turn, are represented as a set of trajectories in joint space. The latter employs the adaptive controller to track the trajectories generated from the former, and RBFNN is incorporated to compensate for the uncertain dynamics.


Fig. 1.
Block diagram of the proposed system.

Show All

Here, we present a novel and complete robot learning framework that considers the performance of both motion generation and trajectory tracking. The SEDS presented in [3] is similar to our DMP-based model. However, the constraints that guarantee the stability of SEDS are derived by the Lyapunov theory that increases the complexity of the learning. In contrast to [3] and [25] which considered only motion modeling, our system is enhanced by an NN-based controller and the effect caused by the dynamic environments can be compensated by neural learning. This design enables the robot to perform the learned motions steadily and more robustly in the real world.

The remainder of this paper is organized as follows. Section II introduces the DMP and its relevant characteristics. The learning process of the motion model is introduced in Section III. In Section IV, the concept of RBFNN is introduced, and the controller using RBFNN is designed with the proof of stability. The experiments are presented in Section V. Section VI concludes this paper.

SECTION II.Basic Model of Discrete Movement
Motion skills can be classified into point-to-point and periodic movements in accordance with brain activation [1]. While using DS to model motions, these two types correspond to point attractor and limit cycle attractor, respectively. In this paper, we focus on point-to-point movements and use the discrete DMP as the basic motion model, which is composed of a spring-damper system and a nonlinear function.

DMP can be employed to model motions in joint space or Cartesian space. The motions in both spaces are regarded as a set of 1-D trajectories, and each trajectory is represented as one DMP model. For concision, we only discuss the modeling problem of the motions in joint space.

The DMP model is defined as follows [26]:
τsξ1˙=τsξ2˙=τsξ3˙=ξ2l1(θg−ξ1)−l2ξ2+(θg−θ0)ξ3f(ξ3)−α1ξ3(1)(2)
View Sourcewhere ξ1∈R represents the joint position and ξ2/τs∈R and ξ2˙/τs∈R denote the joint velocity and the joint acceleration, respectively. ξ3>0 is regarded as a phase variable that is exponentially decaying. l1 , l2 , and α1 are the positive constants. θ0 is the start position, θg is the goal, and (θg−θ0) serves as the spatial scaling term. τs>0 is the time constant. The nonlinear term f:R→R is assumed to be a continuous bounded function in terms of ξ3 .

The system (1) is a spring-damper system perturbed by a nonlinear term. Generally, we choose l1=l22/4 to make the former critically damped. The initial state of system (2) can be chosen as ξ0=1 . The stability of the whole model is clear; the nonlinear term will converge to zero since the state ξ3 will converge to zero and the nonlinear function f(ξ3) is bounded. Then, the system (1) becomes a stable spring-damper system, whose state converges to the goal θg .

The large initial acceleration of the original spring-damper part [Fig. 2(a)] is not desirable for robots in practice. Moreover, the large variation in the acceleration will lead to a complex external forcing term, which is adverse to the learning of the model. Therefore, we replace the goal θg in the spring-damper part with the state of another exponential decay system [27]
τsξ4˙=−α2(ξ4−θg)(3)
View Sourcewhere α2 is a positive constant and the initial value of ξ4 is set as θ0 . Consequently, the system (1) is rewritten as follows [27]:
τsξ1˙=τsξ2˙=ξ2l1(ξ4−ξ1)−l2ξ2+(θg−θ0)ξ3f(ξ3).(4)
View SourceAs shown in Fig. 2(a), the acceleration of the modified system becomes moderate. The evolution of the system (4) with f=0 is shown in Fig. 2(b). Since the state ξ4 will converge to θg , the modified model is still stable toward the goal.


Fig. 2.
(a) Accelerations of the original spring-damper part in (1) and the modified one in (4). (b) Evolutions of the systems (1) and (4) without an external forcing term (f=0 ).

Show All

The DMP model is chosen as the basic motion model because of its concise formulation and excellent generalizability. Since the DMP model is always stable toward θg , the motion modeled can be scaled spatially by modulating θg and θ0 without destabilizing the model. The spatial scaling term (θg−θ0) ensures that the profile of the motion is maintained and its duration can be changed by modulating τs .

SECTION III.Learning of the Motion Model
A. Problem Description
DMP assumes that the motion is generated from the nonlinear DS (4), whose uncertain part is the nonlinear function f(ξ3) . Therefore, the learning problem of DMP is how to approximate this function, which compensates for the difference between the actual acceleration of the spring-damper part and the expected acceleration to reproduce the demonstrated movement (Fig. 3). Assuming that a 1-D demonstration trajectory is captured and encoded as a time series {(θt,θ˙t,θ¨t)|t=1,2,…,T} , where θt , θ˙t , and θ¨t describe the position, velocity, and acceleration of the trajectory at time step t , respectively, and T is the duration of the demonstration, the expected value of f at time step t is computed using the following equation [26]:
ft=τ2sθ¨t−[l1(ξ4,t−θt)−l2τsθ˙t](θT−θ1)ξ3,t(5)
View Sourcewhere ξ3,t and ξ4,t are the values of ξ3 and ξ4 at time step t , respectively. Equation (5) is an inverse process of the reproduction. Since f(ξ3) is a function of ξ3 , we can exploit the data set {(ξ3,t,ft)|t=1,2,…,T} to approximate the function.


Fig. 3.
(a) Actual acceleration of the spring-damper part and the expected acceleration to reproduce the demonstration (a sine curve). (b) Difference between two accelerations in (a), which is compensated by the nonlinear function f(ξ3) .

Show All

In the original DMP model, the function f(ξ3) is defined as [26]
f(ξ3)=∑i=1Nsγiϕi(ξ3)(6)
View Sourcewhere γi∈R is the weight of ϕi(s) and ϕi(s) is the normalized Gaussian basis function, defined as
ϕi(ξ3)=exp(−hi(ξ3−ci)2)∑Nsj=1exp(−hj(ξ3−cj)2)(7)
View Sourcewhere hi>0 is the width and ci>0 is the center of the i th Gaussian functions; Ns is the number of the Gaussian functions. With this formulation, the LWR can be employed to learn the model. Nevertheless, the solution is only applicable to a single demonstration, and multiple demonstrations will be encoded as multiple independent DMP models. Thus, the features of the demonstrations of multiple specific tasks cannot be integrated into one DMP model. To solve this problem, GMM is introduced to model the intermediate data, and then GMR is employed to estimate the nonlinear function.

B. Learning From Multiple Demonstrations
Given Nd demonstrations {(θt,n,θ˙t,n,θ¨t,n)|t=1,2,…,T;n=1,2,…,Nd} of a specific task, we can obtain the data set {(ξ3,t,ft,n)|t=1,2,…,T;n=1,2,…,Nd} using (5). Then, we need to take advantage of the whole data set to estimate the function f(ξ3) of one DMP model. The learning procedures can be broken down into two steps, as shown in Fig. 4. For concision, we use {ξi,fo} to denote the data set.


Fig. 4.
(a) Demonstrations. (b) Data set {ξi,fo} calculated from (a). (c) Data set is encoded with the GMM. (d) Estimate of the function f(ξ3) is retrieved using the GMR.

Show All

Step 1: Use GMM to encode the data set {ξi,fo} . This model assumes that the data set is generated from multiple Gaussian distributions. The joint probability density of GMM is defined as follows [28]:
p(ξi,fo)=∑k=1KαkN(ξi,fo;μk,Σk)(8)
View Sourcewhere
∑k=1Kαk=1(9)
View Sourceand
μk=[μξi,kμfo,k], Σk=[Σξi,kΣfoξi,kΣξifo,kΣfo,k](10)
View Sourceand N is the Gaussian probability distribution defined as follows:
=N(ξi,fo;μk,Σk)exp[−0.5([ξi,fo]T−μk)TΣ−1k([ξi,fo]T−μk)]2π|Σk|−−−√.(11)
View SourceHere, K is the number of Gaussian distributions, αk≥0 is the weight, and μk∈R2×1 and Σk∈R2×2 denote the mean and the covariance matrix of the k th Gaussian component.

αk,μk , and Σk are the parameters to be learned. We can estimate their values and learn GMM from the given data set using the following procedures.

1) Parameter Initialization:
The expectation–maximization (EM) algorithm used for parameter estimation is sensitive to the initial values. Hence, the k-means algorithm [29] is utilized to initialize the unknown parameters αk,μk , and Σk . This algorithm divides the data set into multiple sets and aims to find a partition D={D1,D2,…,DK} to minimize the sum of the squared deviation of each set [29]
D^=argminD∑k=1K∑x∈Dk∥x−mk∥2(12)
View Sourcewhere x=[x1,x2]T∈R2×1 is the data vector corresponding to [ξ3,t,ft,n]T , mk∈R2×1 is the mean of the data distributed in Dk , and ⋃Kk=1Dk={ξi,fo} . The algorithm repeats the assignment and update steps until that partition no longer changes. Then, the initial values of the unknown parameters are assigned as [14]
αk=μk=|Dk|∑Ki=1|Di|mk, Σk=[Σx1Σx2x1Σx1x2Σx2]x∈Dk.(13)(14)
View Source

2) Parameter Estimation:
The EM algorithm is an appropriate method for estimating the parameters of GMM. This algorithm aims to find parameters πk=(αk,μk,Σk) so as to maximize the log-likelihood function [30]
π^k=argmaxπklog(p(ξi,fo|πk)).(15)
View Source

3) Model Selection:
The number of the Gaussian components will affect the fitting performance of GMM. GMM can represent the data set better if more components are selected, but it may lead to overfitting and too many parameters. A compromise is reached using the Bayesian information criterion (BIC) to determine the number of components. The BIC score is defined as follows [14]:
SBIC(K)=−2log(p(ξi,fo|πk))+(6K−1)log(Nd)(16)
View Sourcewhere Nd is the size of the data set and K represents the number of components. The number of components is finally selected as Kms=argminSBIC(K) , and the upper bound of Kms is determined by the designer.

Step 2: Use GMR to estimate the function f(ξ3) . According to [28], the probability density (8) can be rewritten as
p(ξi,fo)=∑k=1KαkN(fo;η^k,σ^2k)N(ξi;μξi,k,Σξi,k)(17)
View Sourcewhere
η^k(ξi)=μfo,k+Σfoξi,k(Σξi,k)−1(ξi−μξi,k)(18)
View Sourceand
σ^2k=Σfo,k−Σfoξi,k(Σξi,k)−1Σξifo,k.(19)
View SourceThe marginal density of ξi is calculated as follows [28]:
p(ξi)==∫p(ξi,fo)dfo∑k=1KαkN(ξi;μξi,k,Σξi,k).(20)
View SourceAccording to (17) and (20), the conditional probability density of fo given ξi is
p(fo|ξi)=∑k=1Kβk(ξi)N(fo;η^k,σ^2k)(21)
View Sourcewhere
βk(ξi)=αkN(ξi;μξi,k,Σξi,k)∑Kk=1αkN(ξi;μξi,k,Σξi,k).(22)
View SourceThen, we can obtain the GMR function as follows [28]:
R(ξi)=E(fo|ξi)=∑k=1Kβk(ξi)η^k(ξi).(23)
View SourceIn addition, the estimate of function f(ξ3) is
f^(ξ3)=∑k=1Kβk(ξ3)η^k(ξ3).(24)
View SourceIn comparison to (6), this estimate is multiplied by an additional term η^k(ξ3) in form; thus, this method enables the motion model to extract more features from multiple demonstrations.

SECTION IV.Adaptive Neural Control of the Robot Manipulator
In practice, robot manipulators have to interact with various payloads. To account for the influence of the unknown payload on the manipulator dynamics, an NN-based controller is designed to track the reference trajectory generated from the motion model in joint space.

A. Dynamics Description
The dynamics of a robot manipulator with n -link is described as follows:
M(θ)θ¨+C(θ,θ˙)θ˙+G0(θ)+τp=τ(25)
View Sourcewhere θ∈Rn , θ˙∈Rn , and θ¨∈Rn are the joint position, joint velocity, and joint acceleration, respectively. τ is the control torque and τp is the torque caused by the payload. M(θ)∈Rn×n denotes the inertia matrix, which is symmetric positive definite. C(θ,θ˙)∈Rn×n represents the Coriolis and centripetal torque matrix and G0(θ)∈Rn is the gravity vector. According to [31], the matrices M(θ) and C(θ,θ˙) satisfy
sT(M˙−2C)s=0,∀s∈Rn.(26)
View Source

B. RBFNN
RBFNN is an effective tool to approximate any continuous function g:Rm→R as follows [32]:
g(ϑ)=WTS(ϑ)+ε(ϑ),  ∀ϑ∈Ωϑ(27)
View Sourcewhere ϑ∈Ωϑ⊂Rm denotes the input vector, W=[ω1,ω2,…,ωN]T∈RN is the ideal NN weight vector, and N is the number of NN nodes. The approximation error ε(ϑ) is bounded. S(ϑ)=[s1(ϑ),s2(ϑ),…,sN(ϑ)]T is a nonlinear vector function, where si(ϑ) is defined as the Gaussian function
si(ϑ)=exp[−(ϑ−κi)T(ϑ−κi)χ2i], i=1,2,…,N(28)
View Sourcewhere κi=[κi1,κi2,…,κim]T∈Rm represents the center of the Gaussian function and χ2i is the variance. The ideal weight vector W is defined as follows:
W=argminW^∈RN{supϑ∈Ωϑ|g(ϑ)−W^TS(ϑ)|}(29)
View Sourcewhich minimizes the approximation error for all ϑ∈Ωϑ .

C. Controller Design
The controller design includes the design of the joint position controller and the joint velocity controller, as shown in Fig. 1. RBFNN is used in the latter to approximate the uncertain dynamics.

1) Joint Position Controller:
The joint position tracking error is defined as ep=[ep1,ep2,…,epn]T=θ−θd , where θd=[θd1,θd2,…,θdn]T∈Rn is the reference trajectory, which is smooth and bounded. The error transformation function [33] is introduced as follows:
epi(t)=δ(t)Hi(Li(epi(t)δ(t))),i=1,2,…,n(30)
View Sourcewhere δ(t)=(δ0−δ∞)e−at+δ∞ represents the tracking performance requirement, and Hi(z) is defined as
Hi(z)=⎧⎩⎨⎪⎪⎪⎪⎪⎪ez−σ1+ez,σez−11+ez,epi(0)≥0epi(0)<0(31)
View Sourceand Li(z) is the inverse function of Hi(z)
Li(z)=⎧⎩⎨⎪⎪⎪⎪⎪⎪lnz+σ1−z,lnz+1σ−z,epi(0)≥0epi(0)<0.(32)
View SourceThe parameters δ0 , δ∞<δ0 , a , and σ are the positive constants, which are used to adjust the control performance. The joint position controller is used to generate the desired joint velocity, which is designed as [24]
vdi=−k1δ(t)ϕi(t)+θ˙di(t)+δ˙(t)δ(t)epi(t)(33)
View Sourcewhere
ϕi(t)=Li(epi(t)δ(t)).(34)
View SourceAccording to [24], if ϕi(t) is bounded, then the following is obtained:
{−σδ(t)<epi(t)<δ(t),−δ(t)<epi(t)<σδ(t),epi(0)>0epi(0)<0.(35)
View SourceTherefore, the function δ(t) determines the bound of error epi(t) and the transient performance of the controller.

2) Joint Velocity Controller:
The joint velocity controller aims to generate the control torque so as to track the desired joint velocity vd=[vd1,vd2,…,vdn]T . Let us define the joint velocity error as ev=θ˙−vd and G(θ)=G0(θ)+τp . Then, the control torque is designed as follows [24]:
τ=−k2ev−Q˙(ϕ(t))ϕ(t)δ(t)+M^v˙d+C^vd+G^+r^(36)
View Sourcewhere
Q˙(ϕ(t))=ϕ(t)=diag(L˙1(H1(ϕ1(t))),…,L˙n(Hn(ϕn(t))))[ϕ1(t),ϕ2(t),…,ϕn(t)]T.(37)
View SourceThe matrices M^(θ) , C^(θ,θ˙) , G^(θ) , and r^(θ,θ˙,vd,v˙d) are the estimates of M(θ) , C(θ,θ˙) , G(θ) , and r(θ,θ˙,vd,v˙d) , respectively, where r(θ,θ˙,vd,v˙d) is defined later in (40).

Substituting (36) into (25), we can obtain the closed-loop dynamics equation
=Me˙v+Cev+k2ev+Q˙(ϕ(t))ϕ(t)δ(t)−r^−(M−M^)v˙d−(C−C^)vd−(G−G^).(38)
View Source

Then, RBFNN is utilized to approximate M(θ) , C(θ,θ˙) , G(θ) , and r(θ,θ˙,vd,v˙d)
M(θ)=C(θ,θ˙)=G(θ)=r(θ,θ˙,vd,v˙d)=WTMSM(θ)+εMWTCSC(θ,θ˙)+εCWTGSG(θ)+εGWTrSr(θ,θ˙,vd,v˙d)+εr(39)
View Sourcewhere WM∈RnN×n , WC∈R2nN×n , WG∈RnN×n , and Wr∈R4nN×n are the ideal NN weight matrices. SM(θ)∈RnN×n , SC(θ,θ˙)∈R2nN×n , SG(θ)∈RnN×n , and Sr(θ,θ˙,vd,v˙d)∈R4nN×n are the RBF matrices. εM , εC , εG , and εr are the approximation errors. The function r(θ,θ˙,vd,v˙d) is defined as
r(θ,θ˙,vd,v˙d)=εMv˙d+εCvd+εG.(40)
View Source

The estimates of M , C , G , and r are written as follows:
M^(θ)=C^(θ,θ˙)=G^(θ)=r^(θ,θ˙,vd,v˙d)=W^TMSM(θ)W^TCSC(θ,θ˙)W^TGSG(θ)W^TrSr(θ,θ˙,vd,v˙d).(41)
View Source

Substituting (41) into (38) and defining W~(⋅)=W(⋅)−W^(⋅) , we have
=Me˙v+Cev+k2ev+Q˙(ϕ(t))ϕ(t)δ(t)−W~TMSMv˙d−W~TCSCvd−W~TGSG−W~TrSr−εr.(42)
View Source

D. Stability Analysis
We follow the stability analysis in [24] to prove the stability of the designed controller. Consider a Lyapunov function as follows:
V=V1+V2(43)
View Sourcewith
V1=12ϕT(t)ϕ(t)(44)
View Sourceand
V2=12eTvMev+12tr(W~TMΓ−1MW~M+W~TCΓ−1CW~C)+12tr(W~TGΓ−1GW~G+W~TrΓ−1rW~r)(45)
View Sourcewhere Γ−1M , Γ−1C , Γ−1G , and Γ−1r are the positive definite matrices.

Taking the derivatives of V1 and V2 , we have
V˙1=ϕT(t)Q˙(ϕ(t))ev(t)δ(t)−k1ϕT(t)Q˙(ϕ(t))ϕ(t)(46)
View Sourceand
V˙2=−eTvk2ev−eTvεr−ϕT(t)Q˙(ϕ(t))ev(t)δ(t)−tr[W~TM(SMv˙deTv+Γ−1MW^˙M)]−tr[W~TC(SCvdeTv+Γ−1CW^˙C)]−tr[W~TG(SGeTv+Γ−1GW^˙G)]−tr[W~Tr(SreTv+Γ−1rW^˙r)].(47)
View Source

Let us design the update law of the NN weights as follows:
W^˙M=W^˙C=W^˙G=W^˙r=−ΓM(SMv˙deTv+ρMW^M)−ΓC(SCvdeTv+ρCW^C)−ΓG(SGeTv+ρGW^G)−Γr(SreTv+ρrW^r)(48)
View Sourcewhere ρM , ρC , ρG , and ρr are the positive constants. Then, the derivative of V is written as follows:
V˙=−eTvk2ev−eTvεr−k1ϕT(t)Q˙(ϕ(t))ϕ(t)+tr[ρMW~TMW^M]+tr[ρCW~TCW^C]+tr[ρGW~TGW^G]+tr[ρrW~TrW^r].(49)
View Source

We can obtain the following inequality according to the definition of Q˙(ϕ(t)) :
ϕT(t)Q˙(ϕ(t))ϕ(t)≥2(1+σ)∥ϕ(t)∥2.(50)
View Source

Using Young’s inequality, we have
V˙≤−2k1(1+σ)∥ϕ(t)∥2−(k2−12)∥ev∥2+ϖ−ρM2∥W~M∥2F−ρC2∥W~C∥2F−ρG2∥W~G∥2F−ρr2∥W~r∥2F(51)
View Sourcewith
ϖ=ρM2∥WM∥2F+ρC2∥WC∥2F+ρG2∥WG∥2F+ρr2∥Wr∥2F+12κ2r(52)
View Sourcewhere κr is the upper bound of ∥εr∥ over Ω .

We have V˙≤0 if W~M , W~C , W~G , W~r , ϕ(t) , and ev satisfy the inequality as follows:
ϱ=2k1(1+σ)∥ϕ(t)∥2+(k2−12)∥ev∥2+ρM2∥W~M∥2F+ρC2∥W~C∥2F+ρG2∥W~G∥2F+ρr2∥W~r∥2F≥ϖ.(53)
View Source

According to the LaSalles theorem, all closed-loop signals of the DS composed of (25), (36), and (48) are semiglobal uniformly bounded if the input signals θd and θ˙d are bounded. Besides, ϕ(t) and ev will converge to an invariant set Ωi⊆Ω [24]
Ωi={(∥ϕ(t)∥,∥ev∥,∥WM∥,∥WC∥, ∥WG∥,∥Wr∥)|ϱ/ϖ≤1}.(54)
View Source

Since the signal ϕ(t) is bounded, the transient performance and the stability of the controller are guaranteed.

SECTION V.Experiments
The proposed system is tested by two groups of experiments: the test of the NN-based controller and the test of the DMP-based motion model.

A. Test of the NN-Based Controller
In this group of experiments, the performance of NN learning is tested, which compensates for the uncertain manipulator dynamics caused by the payload. The experiments are performed on the Baxter robot that has two seven degrees-of-freedom arms. The joints from the shoulder to end-effector are named as s0 , s1 , e0 , e1 , w0 , w1 , and w2 in this paper. The experiment setup is shown in Fig. 5. The payload is attached using the left gripper of the robot, which weighs 0.94 kg. The robot is required to track a circular trajectory defined as [X,Y,Z]=[0.65+0.1sin(2πt/4),0.2+0.1cos(2πt/4),0.2] (m) with the orientation fixed. The corresponding trajectories in joint space are obtained through the inverse kinematics, which are taken as the inputs of the proposed controller.


Fig. 5.
Experimental setup for testing the NN-based controller.

Show All

We select three nodes for each input dimension of NN, and the centers of the nodes are distributed evenly within the limits of the joint position and joint velocity. There are N=2187 NN nodes selected for M^(θ) and G^(θ) , 2N nodes for C^(θ,θ˙) , and 4N nodes for r^(θ,θ˙,vd,v˙d) . In addition, the NN weight matrices are initialized as W^M=0∈RnN×n , W^C=0∈R2nN×n , W^G=0∈RnN×n , and W^r=0∈R4nN×n with n=7 . The parameters of the error transformation function are set as δ0=0.2 , δ∞=0.04 , a=1 , and σ=1 .

The manipulator is controlled by the controller without NN learning in the first experiment, and the actual joint angles are recorded. Then, the controller with the proposed NN learning is employed to control the manipulator in the second experiment. The reference and actual joint angles in both experiments are shown in Fig. 6, and the corresponding tracking errors are shown in Fig. 7. The tracking errors are relatively high when NN learning is disabled, which is caused by the payload that the gripper holds, while in the second experiment, each joint of the manipulator tracks the reference trajectory very well and all tracking errors reduce into the interval [−0.04, 0.04](rad) with the compensation torque increasing, which is shown in Fig. 8(a). The gravity term of the manipulator dynamics is the main part that the payload affects, and hence, we particularly show the norm of each column of W^G in Fig. 8(b). We can see that the norm of each column vector of the weight matrix W^G rises incrementally because the torque generated by NN still cannot compensate for the effect of the unknown dynamics. However, the rising speeds of all norms decrease with the increment in torque compensation.


Fig. 6.
Reference joint angles (dashed lines) and actual joint angles (solid lines) when NN learning is (a) disabled and (b) enabled. The lines of different colors represent different joints.

Show All


Fig. 7.
Tracking errors when NN learning is (a) disabled and (b) enabled.

Show All


Fig. 8.
(a) Compensation torque. (b) Norm of each column of the weight matrix W^G .

Show All

B. Test of the DMP-Based Motion Model
The second group of experiments aims to validate the DMP-based motion model. The ability of generalization and the learning performance are tested. In these experiments, the demonstrations are performed by guiding the robot manipulator.

1) Ability of Generalization:
In this experiment, the tutor demonstrates how to pour water into a cup placed on the table, as shown in Fig. 9. The demonstration process is repeated five times. The joints w0 , w1 , s0 , and e1 are moved while the others are fixed. The joint angles are recorded and used for learning the modified DMP. The parameters of the DMP model are set as τs=1 , l1=25 , l2=10 , and α1=α2=8 .


Fig. 9.
Demonstration process of a pouring task.

Show All

The learning results are shown in Fig. 10. The motions of the four joints are reproduced from the demonstrations, which synthesize the features of these demonstrations and enable the robot to complete the pouring task successfully. Subsequently, the target of the motion is modulated to the other cup. As shown in Fig. 11, the movement trajectory of each joint angle converges to the new goal and the profile of each reproduction is retained. We test the reproduced motion and the generalized motion on the robot. As shown in Fig. 12(a), the robot completes the pouring task successfully, and as shown in Fig. 12(b), the robot can pour water into the other cup.


Fig. 10.
Learning results using the DMP-based motion model in a pouring task of (a) joint s0 , (b) joint e1 , (c) joint w0 , and (d) joint w1 .

Show All


Fig. 11.
Generalization results using the DMP-based motion model in a pouring task of (a) joint s0 , (b) joint e1 , (c) joint w0 , and (d) joint w1 .

Show All


Fig. 12.
(a) Robot performs the pouring task with the regenerated motion. (b) Robot pours water into the other cup with the generalized motion.

Show All

2) Learning Performance:
To further validate the learning performance of the DMP-based motion model, we design a drawing task for the robot; the experimental setup is shown in Fig. 13(a). Here, the robot is required to draw an image of a sinusoid on paper after the tutor demonstrates the task five times. As shown in Fig. 13(b), the demonstrations are defective and the curves are irregular. One of the reasons is that the demonstrator is drawing on this paper indirectly by holding the robot’s wrist, which affects the exertion of the drawing skill. The demonstrations are modeled in the task space, and the robot performs the drawing task after learning (Fig. 14). As shown in Fig. 15(a), a smooth curve is reproduced by the motion model given multiple demonstrations. We can also see that the recorded trajectories are distorted due to measurement errors of the sensors. As shown in Fig. 15(b), the curve that the robot draws is smoother than those of the demonstrations, thus validating the learning performance of the DMP-based motion model.


Fig. 13.
(a) Experiment setup for the drawing task. (b) Demonstration trajectories of the drawing task.

Show All


Fig. 14.
Robot performs the drawing task with the learned motion.

Show All


Fig. 15.
(a) Learning result using the DMP-based motion model in a drawing task. The motions are modeled in the task space. (b) Result of drawing. The blue curve is drawn by the robot after learning.

Show All

SECTION VI.Conclusion
In this paper, a novel robot learning system comprised of motion generation and trajectory tracking is developed. A DMP model is chosen as the basis of the motion model because of its generalization ability. To improve the learning performance, GMM and GMR are employed for estimating the nonlinear function of the motion model. With this modification, the model can extract more motion features from multiple demonstrations of a specific task and generate motions that synthesize these additional features. Besides, an NN-based controller is designed to overcome the impact of the unknown payload so that the manipulator is able to track the generated motions more accurately. Several experiments have been performed on the Baxter robot to test the performance of our proposed methods, which can be used to facilitate robot learning at a higher level. In the future work, we will further integrate the reinforcement learning into our system to improve the learning capacity of the robot.