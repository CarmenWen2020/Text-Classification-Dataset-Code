Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)-machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives.

SECTION I.Introduction
The need for novel healthcare solutions and continuous efforts in understating the biological bases of pathologies has pushed extensive research in biological sciences over the last two centuries [1]. Recent technological advancements in life sciences have opened up possibilities not only to study biological systems from a holistic perspective, but provided unprecedented access to molecular details of living organisms [2], [3]. Novel tools for DNA sequencing [4], gene expression (GE) [5], bioimaging [6], neuroimaging [7], and brain–machine interfaces [8] are now available to the scientific community. However, considering the inherent complexity of biological systems together with the high dimensionality, diversity, and noise contaminations, inferring meaningful conclusion from such data is a huge challenge [9]. Therefore, novel instruments are required to process and analyze biological big data that must be robust, reliable, reusable, and accurate [10]. This has encouraged numerous scientists from life and computing sciences disciplines to embark in a multidisciplinary approach to demystify functions and dynamics of living organisms, with remarkable progress reported in biological and biomedical research [11]. Thus, many techniques of artificial intelligence (AI), in particular machine learning (ML), have been proposed over time to facilitate recognition, classification, and prediction of patterns in biological data [12].

Conventional ML techniques can be broadly categorized in two large sets— supervised and unsupervised. The methods pertaining to the supervised learning paradigm classify objects in a pool using a set of known annotations/attributes/features. On the other hand, the unsupervised learning techniques form groups/clusters among the objects in a pool by identifying their similarity, and then use them for classifying the unknowns. Further, the other category, reinforcement learning (RL), allows a system to learn from the experiences it gains through interacting with its environment (see Section II-B for details).

Popular supervised methods include artificial neural networks (ANN) [13] and their variants [e.g., multilayer perceptron (MLP)], support vector machines (SVMs) [14], linear classifiers [15], Bayesian statistics [16], k-nearest neighbors (kNNs) [17], hidden Markov model (HMM) [18], and decision trees [19]. Popular unsupervised methods include autoencoders [20], expectation maximization [21], self-organizing maps [22], k-means [23], fuzzy [24], and density-based [25] clustering.

A large body of evidence shows that the above-mentioned methods and their respective variants can be successfully applied to biological data coming from various sources, e.g., Omics (covers data from genetics and (gen/transcript/epigen/prote/metabol)omics [26]), Bioimaging (covers data from (sub)cellular images acquired by diverse imaging techniques [27]), Medical Imaging (covers data from (medical/clinical/health) imaging mainly through diagnostic imaging techniques [28]), and (brain/body)–machine interfaces (BMIs) (covers electrical signals generated by the brain and the muscles and acquired using appropriate sensors [29], [30]).

Broadly, AI can be thought to have evolved parallelly in two main directions—expert systems (ES) and ML [see Fig. 1(h)]. Focusing on the latter, ML extracts features from training data set(s) and make models with minimal or no human intervention. These models provide predicted outputs based on test data. Deep learning (DL), being a subdivision of ML, extracts more abstract features from a larger set of training data mostly without human supervision. RL, being the other subdivision of ML, is inspired by psychology. It provides a software agent that gathers experience based on interactions with the environment through some actions and aims to maximize the cumulative performance.


Fig. 1.
Possible representation of the DL, RL, and deep RL frameworks for biological applications. (a)–(f) Popular DL architectures. (g) Schematic of the learning framework as a part of AI. Broadly, AI can be thought to have evolved parallelly in two main directions—ES and ML. ES takes expert decisions from given factual data using rule-based inferences. ML extracts features from data mainly through statistical modeling and provides predictive output when applied to unknown data. DL, being a subdivision of ML, extracts more abstract features from a larger set of training data mostly in a hierarchical fashion resembling the working principle of our brain. The other subdivision, RL, provides a software agent that gathers experience based on interactions with the environment through some actions and aims to maximize the cumulative performance. (h) Possible applications of AI to biological data.

Show All

In recent years, DL, RL, and deep RL methods are poised to reshape the future of ML [31]. Over the last decade, works pertaining to DL, RL, and deep RL were extensively reviewed from different perspectives. In a topical review, Schmidhuber [32] provided a detailed time line of significant DL developments (for both supervised and unsupervised), RL and evolutionary computation, and DL in feedforward and recurrent neural networks (RNNs) for RL. Other reviews are focusing on the applications of DL in health informatics [33], biomedicine [34], and bioinformatics [35]. On the other hand, Kaelbling et al. [36] discussed RL from the perspective of the tradeoff between exploitation and exploration, RL’s foundation via Markov decision theory, the learning mechanism using delayed reinforcement, construction of empirical learning models, use of generalization and hierarchy, and reported some exemplifying RL systems implementations. Glorennec [37] provides a brief overview of the basis of RL with explicit descriptions of Q- and fuzzy Q-learning. With respect to applications in solving dynamic optimization problems, Gosavi [38] surveys Q-learning, temporal differences (TDs), semi-Markov decision problems, stochastic games, policy gradients, and hierarchical RL with the detailed underlying mathematics. In addition, Li [39] analyzed the recent advances of deep RL on—deep Q-network (DQN) with its extensions, asynchronous methods, policy optimization, reward, and planning as well as different applications, including games (e.g., AlphaGo, robotics, and chatbot), neural architecture design, natural language processing, personalized Web services, healthcare, and finance.

Despite the popularity of the topic and application potential to diverse disciplines, a comprehensive review is missing that focuses on data from different Biological application domains while providing a performance comparison across techniques. This review is intended to fill this gap: it provides a brief overview on DL, RL, and deep RL concepts, followed by the state-of-the-art applications of these techniques and performance comparison between various DL approaches. Finally, it identifies and outlines some open issues and speculates about future perspectives.

As for the organization of the rest of this paper, Section II provides a conceptual overview of DL, RL, and deep RL techniques, introducing the reader to underlying theory. Section III presents state-of-the-art applications of these techniques to various biological domains. Section IV presents test results and performance comparison of DL techniques applied on data sets pertaining to different biological domains. Section V highlights open issues and future perspectives, and, finally, Section VI presents some concluding remarks.

SECTION II.Conceptual Overview
A. Deep Learning
The core concept of DL is to learn data representations through increasing abstraction levels. Almost in all levels, more abstract representations at a higher level are learned by defining them in terms of less abstract representations at lower levels. This type of hierarchical learning process is very powerful as it allows a system to comprehend and learn complex representations directly from the raw data [40], making it useful in many disciplines [41].

Several DL architectures have been reported in the literature, including deep neural network (DNN), RNN, convolutional neural network (CNN), deep autoencoder (DA), deep Boltzmann machine (DBM), deep belief network (DBN), deep residual network, deep convolutional inverse graphics network, and so on. For the sake of brevity, only the ones widely used with biological data are briefly summarized in the following. However, interested readers are directed to the references mentioned in each section for concrete mathematical details behind each architecture.

1) Deep Neural Network:
DNN [Fig. 1(a)] [42] is inspired by the brain’s visual input processing mechanism, which takes place at multiple levels (i.e., starting with cortical area “V1” and then passing to area “V2” and so on) [32]. The standard neural network (NN) is extended to have multiple hidden layers with nonlinear modules embodied in each hidden layer allowing it to learn part-hole of the representations. Though this formulation has been successfully used in many applications, the training process is slow and cumbersome.

2) Recurrent Neural Network:
RNN [Fig. 1(b)] [43] is an NN model designed to detect structures in streams of data [44]. Unlike feedforward NN that performs computations unidirectionally from input to output, an RNN computes the current state’s output depending on the outputs of the previous states. Due to this “memory-like” property, despite learning problems related to vanishing and exploding gradients, RNN applications have gained popularity in many fields involving streaming data (e.g., text mining, time series, and genomes). In recent years, two main variants, such as bidirectional RNN [45] and long short-term memory (LSTM) [46], have also been developed and increasingly applied in biological applications [47], [48].

3) Convolutional Neural Network:
CNN [Fig. 1(c)] [49] is a multilayer NN model [50], inspired by the neurobiology of visual cortex, that consists of convolutional layer(s) followed by fully connected layer(s). In between these two types of layers, there may exist subsampling steps. They get the better of DNNs, which have difficulty in scaling well with multidimensional locally correlated input data. Therefore, the main application of the CNN has been in data sets, where the number of nodes and parameters required to be trained is relatively large (e.g., image analysis). Exploiting the “stationary” property of an image, convolution filters (CFs) can learn data-driven kernels. Applying such a CF along with a suitable pooling function reduces the features that are supplied to the fully connected network to classify. However, in case of large data sets, even this can be daunting and can be solved using sparsely connected networks. Some of the popular CNN configurations include AlexNet [51], VGGNet [52], and GoogLeNet [53].

4) Deep Autoencoder:
DA architecture [Fig. 1(d)] [54] is obtained by stacking a number of autoencoders that are data driven NN models (i.e., unsupervised) designed to reduce data dimension by automatically projecting incoming representations to a lesser dimensional space than that of the input. In an autoencoder, an equal amount of units are used in the input/output layers and less units in the hidden layers. (Non)linear transformations are embodied in the hidden layer units to encode the given input into smaller dimensions [55]. Despite that it requires a pretraining stage and suffers from vanishing error, this architecture is popular for its data compression capability and have many variants, e.g., denoising autoencoder [54], sparse autoencoder [56], variational autoencoder [57], and contractive autoencoder [58].

5) (Restricted) Boltzmann Machine:
A (restricted) Boltzmann machine [(R)BM] is an undirected probabilistic generative model representing specific probability distributions [59]. It is also considered as a nonlinear feature detector. The learning process of (R)BM is based on optimizing its parameters for a set of given observations to obtain the best possible fit of the probability distribution through Gibbs sampling (a Markov chain Monte Carlo (MC) method [60]) [61]. BM has symmetrical connections among its units and has one visible layer with (multiple) hidden layers. Usually, the learning process of a BM is slow and computationally expensive and, thus, requires long to reach equilibrium statistics [40]. By restricting the intralayer units of a BM to connect among themselves, a bipartite graph is formed (i.e., an RBM has a visible and a hidden layer), where the learning inefficiency is solved [59]. Stacking multiple RBMs as learning elements yields the following two DL architectures.

a) Deep Boltzmann Machine:
DBM [Fig. 1(e)] [62] is a stack of undirected RBMs. Being undirected, there is a feedback process among the layers, where feature inference from higher level units affect the inference of lower level units. Despite this powerful inference mechanism that allows an input’s alternative interpretations through concurrent competition at all levels of the model, estimating model parameters from data remains difficult. Gradient-based methods (e.g., persistent contrastive divergence [63]) fail to explore the model parameters sufficiently [62]. Though this learning problem is overcome by pretraining each RBM in a layerwise greedy fashion, with outputs of the hidden variables from lower layers as input to upper layers [59], the time complexity remains high and may not be suitable for large training data sets [64].

b) Deep Belief Network:
DBN [Fig. 1(f)] [65] is formed by ordering several RBMs in a way that one RBM’s latent layer is linked to the subsequent RBM’s visible layer. The connections of DBN are downward directed to its immediate lower layer, except that the upper two layers are undirected [65]. Thus, a DBN is a hybrid model with the first two layers as undirected graphical model and the rest being directed generative model. The different layers are learned in a layerwise greedy fashion and fine-tuned based on required output [33]; however, the training procedure is computationally demanding.

B. Reinforcement Learning
Rooted in behavioral psychology, RL is a distinctive member of the ML family. An RL problem is solved by learning new experiences through trial-and-error. An RL agent is trained; as such, its actions to interact with the environment maximize the cumulative reward resulting from the interactions. Generally, RL problems are modeled and solved using Markov decision processes (MDPs) theory through MC and dynamic programming (DP) [66].

The learning of an agent is a continuous process, where interactions with the environment occur at discrete time steps. In a typical RL cycle (at time t ), the agent receives the environment’s state (i.e., state, st ) and selects an action (at ) to interact. The environment responds to the action and progresses to a new state (st+1 ). The reward (rt+1 ) that the agent either receives or not for the selected action associated with the transition (st , at , st+1 ) is also determined [66]. Accordingly, after each cycle, the agent updates the value function V(s) or action-value function Q(s,a) based on a certain policy, where policy (π ) is a function that maps states s∈S to actions a∈A , i.e., π:S→A⇒a=π(s) [36].

A possible way to solve the RL problem is to describe the environment as MDP with a set of state-value function pairs, a set of actions, a policy, and a reward function. The value function can be separated to solve state-value function (V ) or action-value function (Q ). In the state-value function, the expected outcome, of being in state s following policy π , is determined by sum of the rewards at future time steps with a given discount factor (γ∈[0,1] ), i.e., Vπ(s)=Eπ(∑∞k=0γkrt+k+1|st=s) . And in the action-value function, the expected outcome, of being in state s taking action a following policy π , is determined by sum of the rewards for each state action pairs, i.e., Qπ(s,a)=Eπ(∑∞k=0γkrt+k+1|st=s,at=a) .

The MDP can be solved, and the optimum policy can be achieved through DP by: either starting with an initial policy or improving it iteratively (policy iteration), or starting with arbitrary value function and recursively refining an estimate of an improved state-value or action-value function to compute an optimal policy and its value (value iteration) [67]. In the simplest case, the state-value function for a given policy can be estimated using the Bellman expectation equation as: Vπ(s)=Eπ(rt+1+γVπ(st+1)|st=s) . Considering this as a policy evaluation process, an improved and eventually optimal policy (π∗ ) can be achieved by taking actions greedily that maximizes the state-action value. But in scenarios with unknown environments, modelfree methods are to be used without the MDP. In such cases, instead of the state-value function, the action-value function can be maximized to find the optimal policy (π∗ ) using a similar policy evaluation and improvement process, i.e., Qπ(s,a)=Eπ(rt+1+γQπ(st+1,at+1)|st=s,at=a) . There are several learning techniques, e.g., MC, TD, and state-action-reward-state-action (SARSA), which describe various aspects of the modelfree policy evaluation and improvement process [68].

However, in real-world RL problems, the state-action space is very large, and storing a separate value function for every possible state is cumbersome. In such situations, generalization of the value function through function approximation is required. For example, the Q value function approximation is able to generalize to unknown states by calculating a function (Q^ ) for a given state action pair (s,a ), i.e., Q^(s,a,w)≈Qπ(s,a)=x(s,a)⊤w . In other words, a rough approximation of the Q function is obtained from the feature vector representing (s,a) pair (x ) and the provided parameter (w which is updated using MC or TD learning) [69]. This approximation allows to improve the Q function by minimizing the loss between the true and approximated values (e.g., using gradient descent), i.e., J(w)=Eπ((Qπ(s,a)−Q^(s,a,w))2) . Examples of differentiable function approximators include NN, linear combinations of features, decision tree, nearest neighbor, and Fourier bases [70].

C. Deep Reinforcement Learning
The autonomic capability to learn without any feature crafting makes RL a powerful tool applicable to many disciplines, but it falls short in cases when the data dimensionality is large and the environment is nonstationary [71]. Also, DL’s capability to learn complex patterns is sometimes prone to misclassification [72]. To mitigate, in recent years, RL algorithms have been successfully combined with a deep NN [39] giving rise to novel learning strategies. This integration has been used either in approximating RL functions using deep NN architectures or in training deep NN using RL.

The first notable example of such an integration is the DQN [31], which combines Q-learning with a deep NN. The DQN agent, when presented with high-dimensional inputs, can successfully learn policies using RL. The action-value function is approximated for optimality using the deep CNN. The deep CNN, using experience replay and target network, overcomes the instability and divergence sometimes experienced while approximating Q-function with shallow NN.

Another deep RL algorithm is the double DQN, which is an extension of the DQN algorithm [73]. In certain situations, the DQN suffers from substantial overestimations inherited from the implemented Q-learning, which are overcome by replacing the Q-learning of the DQN with a double Q-learning algorithm [74]. The DQN learns two value functions, by assigning an experience randomly to update one of them, resulting in two sets of weights. During every update, one set determines the greedy policy, while the other determines its value. Other deep RL algorithms include deep deterministic policy gradient, continuous DQN, asynchronous N -step Q-learning, Dueling network DQN, prioritized experience replay, deep SARSA, asynchronous advantage actor-critic, and actor-critic with experience replay [39].

SECTION III.Applications to Biological Data
The above-outlined techniques, also available as open-source tools (see [75] for a mini review of tools based on DL), have been used in mining biological data. The applications, as reported in literature, are provided in the following for data from each of the application domains.

Table I summarizes state-of-the-art applications of DL and RL to biological data [see Fig. 1(h)]. It also reports on individual applications in each of these domains and the data type on which the methods have been applied.

TABLE I Summary of (Deep) (Reinforcement) Learning Applications to Biological Data

A. Omics
Some DL and RL methods have been extensively used in Omics (such as genomics, proteomics, or metabolomics) research to extract features, functions, structure, and molecular dynamics from the raw biological sequence data (e.g., DNA, RNA, and amino acids). Specifically, mining sequence data is a challenging task. Different analyses (e.g., GE profiling, splicing junction prediction, sequence specificity prediction, transcription factor determination, and protein–protein interaction evaluation) dealing with different types of sequence data have been reported in the literature.

To identify splicing junction at the DNA level, a tedious job to do manually, Lee and Yoon [79] proposed a DBN-based unsupervised method to perform the autoprediction. Profiling GE is a demanding job. Chen et al. [83] exploited a DNN-based method for GE profiling on RNA-seq and microarray-based GE Omnibus data set. The ChIP-seq data were preprocessed, using CNN, into a 2-D matrix where each row denoted a gene’s transcription factor activity profile [92]. Also, somatic point mutation-based cancer classification was performed using the DNN [90]. In addition, DA-based methods have been used for feature extraction in cancer diagnosis and classification (Fakoor et al. [76] used the sparse DA method) in combination with related gene identification (Danaee et al. [77] used stacked denoising DA) from GE data.

Alipanahi et al. [93] used a deep CNN structure to predict DNA- and RNA-binding proteins’ [(D/R)BPs] role in alternative splicing and examined the effect of disease associated genetic variants (GVs) on transcription factor binding and GE. Zhang et al. [84] developed a DNN framework to model structural features of RBPs. Pan and Shen [82] proposed a hybrid CNN-DBN model to predict RBP interaction sites and motifs on RNAs. Quang et al. [86] proposed a DNN model to annotate and identify pathogenicity in GV.

Identifying the best discriminative genes/microRNAs (miRNAs) is a challenging task. Ibrahim et al. [80] proposed a group feature selection method from genes/miRNAs based on expression profile using DBN and active learning. CNN was used to interpret noncoding genome by annotating them [94]. Also, Zeng et al. [95] employed CNN to predict the binding between DNA and protein. Zhou and Troyanskaya [96] proposed a CNN-based approach to identify noncoding GV, which was also used by Huang et al. [97] for a similar purpose. Park et al. [99] proposed an LSTM-based tool to automatically predict miRNA precursor. Also, Lee et al. [100] presented a deep RNN framework for automatic miRNA target prediction.

DNA methylation (DM) causes DNA segment activity alteration without affecting the sequence, and thus, detecting its state in a sequence is important. Angermueller et al. [85] used a DNN-based method to estimate a DM state by predicting the changes in single nucleotides and uncovering sequence motifs.

Proteomics pose many complex computational problems to solve. Estimating complete protein structures from biological sequences, in 3-D space, is a complex and NP-hard problem. Alternatively, the protein structures can be divided into independent subproblems (e.g., torsion angle, access surface area, and dihedral angles) and solved in parallel, and estimate the secondary protein structures (2-PS). Predicting compound–protein interaction (CPI) is very interesting from drug discovery point of view and tough to solve.

Heffernan et al. [87] proposed an iterative DNN scheme to solve these subproblems for 2-PS. Wang et al. [98] utilized a deep CNN to predict 2-PS. Li [78] proposed the DA learning-based model to reconstruct a protein structure based on a template. Also, DNN-based methods to predict CPI [88], [89], [91] have also been reported.

In medicine, model organisms are often used for translational research. Chen et al. [81] used bimodal DBNs to predict responses of human cells under certain stimuli based on responses of rat cells obtained with the same stimuli.

RL has also been used in omics, for example, Chuang et al. [101] used binary particle swarm optimization (PSO) and RL to predict bacterial genomes, Ralha et al. [102] used RL through a system called BioAgent to increase the accuracy of biological sequence annotation, and Bocicor et al. [103] solved the problem of DNA fragment assembly using the RL-based framework. Zhu et al. [104] proposed a hybrid RL method, with text mining, for constructing protein–protein interaction networks.

B. Bioimaging
In biology, DL architectures targeted on pixel levels of a biological image to train the NN. Ning et al. [108] used CNN for pixelwise image segmentation of nucleus, cytoplasm, cell, and nuclear membranes using electron microscope image (EMI). Reduced pixel noise and better abstract features of biological images can be obtained by adding multiple layers. Ciresan et al. [109], [110] employed deep CNNs to identify mitosis in histology images of the breast, and a similar architecture was also used to find neuronal membranes and automatically segment neuronal structures in EMI. Xu et al. [105] used a stacked sparse DA architecture to identify nuclei in the histopathology images of the breast cancer. Xu et al. [106] classified colon cancer images using multiple instance learning (MIL) from DNN learned features.

Besides pixel-level analysis, DL has also been applied to cell- and tissue-level analysis. Chen et al. [107] employed DNN in labelfree cell classification. Parnamaa and Parts [111] used the CNN to automatically detect fluorescent protein in various subcellular localization patterns using microscopy images of yeast. Ferrari et al. [112] used CNNs to count bacterial colonies in agar plates. Kraus et al. [113] integrated both the segmentation and the classification in a model, which can be utilized to classify the microscopy images of the yeast. Flow cytometry is used in cellular biology through a cycle analysis to monitor different stages of a cell cycle. Eulenberg et al. [114] proposed a deep flow model, combining nonlinear dimension reduction with CNN, to analyze single-cell flow cytometry images. Furthermore, a CNN architecture was employed to segment and recognize neural stem cells in images taken by bright field microscope [115], and DBN for analyzing gold immunochromatographic strip [197].

C. Medical Imaging
DL and RL architectures have been widely used in analyzing medical images obtained from—magnetic resonance [(f/s)MRI], CT scan, positron emission tomography (PET), radiography/fundus (e.g., X-ray and CFI), microscope, ultrasound (UlS)—to denoise, segment, classify, detect anomalies, and diseases from these images.

Segmentation is a process of partitioning an image based on some specific patterns. Sirinukunwattana et al. [156] reported the results of the gland segmentation competition from colon histology images. Kamnitsas et al. [130] proposed a 3-D dual pathway CNN to simultaneously process multichannel MRI and segment lesions related to tumors, traumatic injuries, and ischemic stroke. Stollenga et al. [131] segmented neuronal structures from 3-D EMI and brain MRI using multidimensional RNN. Fritscher et al. [134] used a deep CNN for volume segmentation from head-neck region’s CT scans. Havaei et al. [123], [125] segmented brain tumor from MRI using CNN and DNN. Brosch and Tam [119] proposed a DBN-based manifold learning method of 3-D brain MRI. Cardiac MRIs were segmented for heart’s left ventricle using the DBN [145], and blood pool (BP) and myocardium (MC) using the CNN [157]. Mansoor et al. [116] automatically segmented anterior visual pathway from MRI sequences using a stacked DA model. Lerouge et al. [133] proposed the DNN-based method to label CT scans.

Success of many medical image analysis methods depends on image denoising. Gondara [144] proposed a denoising technique utilizing convolutional denoising DA, and validated it with mammograms and dental radiography, while Agostinelli et al. presented an adaptive multicolumn stacked sparse denoising DA method for image denoising, which was validated using CT scan images of the head [132].

Detecting anomaly in medical images is widely used for disease diagnosis. Several models were applied to detect Alzheimer’s disease (AD) and mild cognitive impairment (MCI) from MRI and PET scans, including DA [117], [118], DBM [120], RBM [121], and multimodal stacked deep polynomial network (MStDPN) [124].

Due to its facilitating structure, a CNN has been the most popular DL architecture for an image analysis. The CNN was applied to classify breast masses from mammograms (MMM) [151]–[152][153][154][155], diagnose AD using different neuroimages (e.g., brain MRI [126], brain CT scans [135], and (f)MRIs [128]), and rheumatoid arthritis from hand radiographs [150]. The CNN was also used extensively: on CT scans to detect anatomical structure [136], sclerotic metastases of spine along with colonic polyps and lymph nodes (LNs) [137], thoracoabdominal LN and interstitial lung disease (ILD) [139], pulmonary nodules [138], [140], [141]; on (f)MRI and diffusion tensor images to extract deep features for brain tumor patients’ survival time prediction [129]; on MRI to detect neuroendocrine carcinoma [127]; on UlS images to diagnose breast lesions [138] and ILD [147]; on CFI to detect hemorrhages [148]; on endoscopy images to diagnose digestive organ-related diseases [149]; and on PET images to identify oesophagal carcinoma and predict responses of neoadjuvant chemotherapy [143].

In addition, a DBN was successfully applied to identify attention deficit hyperactivity disorder [142], and schizophrenia and Huntington disease from (f/s)MRI [122]. And, a DNN-based method was proposed to successfully identify the fetal abdominal standard plane in UlS images [146].

RL was used in segmenting transrectal UlS images to estimate location and volume of the prostate [158].

D. (Brain/Body)–Machine Interfaces
DL and RL methods have been applied to BMI signals [e.g., electroencephalogram (EEG), electrocardiogram (ECG), and electromyogram (EMG)] mainly from (brain) function decoding and anomaly detection perspectives.

Various DL architectures have been used in classifying EEG signals to decode Motor Imagery (MoI). The CNN was applied in the classification pipeline using—augmented common spatial pattern (CSP) features which covered various frequency ranges [172], features based on combined selective location, time, and frequency attributes, which were then classified using DA [173], and signal’s dynamic energy representation [174]. The DBN was also employed—in combination with softmax regression to classify signal frequency information as features [161] and in conjunction with Ada-boost algorithm to classify single channels [162]. DNN was used with variance-based CSP features to classify MoI EEG [171] and to find neural patterns occurring at each time points in single trials, where the input heatmaps were created with a layerwise relevance propagation technique [170]. In addition, MoI EEG signals were classified by denoising DA using multifractal attribute features [159].

The DBN was used by Li et al. [163] to extract low-dimensional latent features as well as critical channel selection that led to an early framework for affective state classification using EEG signals. In a similar work, Jia et al. [164] used a semisupervised approach with active learning to train DBN and generative RBMs for the classification. Later, using differential entropy as features to train the DBN, Zheng and Lu examined dominant frequency bands and channels of EEG in an emotion recognition system [165]. Jirayucharoensak et al. used principal component analysis (PCA) extracted power spectral densities from each EEG channel, which were corrected by covariate shift adaptation to reduce nonstationarity, as features to stacked DA to detect emotion [160]. Tripathi et al. [175] explored the DNN (with Softmax activator and Dropout) and CNN [198] (with Tan Hyperbolic, Max Pooling, Dropout, and Softplus) for emotion classification from the DEAP data set using EEG signals and response face video. Using the similar data from the MAHNOB-HCI data set, Soleymani et al. [178] detected continuous emotion using the LSTM-RNN. Channelwise CNN and its variant with RBM [176], and autoregressive-model based features with sparse-DBN [169], was used to estimate driver’s cognitive states using EEG data.

In another approach to model cognitive events, EEG signals were transformed to time-lagged multispectral images and fed to the CNN for learning the spectral and spatial representations of each image, followed by an adapted LSTM to find the temporal patterns in the image sequence [179].

The DBN has been employed in classifying EEG signals for anomaly detection in diverse scenarios, including online waveform classification [166], AD diagnosis [167], integrated with HMM to understand sleep phases [168]. To detect and predict seizures, the CNN was used for classification of synchronization patterns [177]; RNN predicted specific signal features related to seizure after being trained with data preprocessed by wavelet decomposition [180]. Also, a lapse of responsiveness warning system was proposed using the LSTM [181].

Using the CNN, Atzori et al. [184] and Park and Lee [185] decoded hand movements from EMG signals.

ECG arrhythmias were successfully detected using the DBN [188] and DNN [189]. The DBN was also used to classify ECG signals acquired with two leads [187], and in combination with nonlinear SVM and Gaussian kernel [186].

RL has also been applied in the BMI research. Concentrating mainly on controlling (prosthetic/robotic) devices, several studies have been reported, including mapping neural activity to intended behavior through coadaptive BMI [using TD(λ )] [190], symbiotic BMI (using actor-critic) [191], a testbed targeting center-out reaching task in primates for creating more realistic BMI control models [192], Hebbian RL for adaptive control by mapping neural states to prosthetic actions [193], BMI for unsupervised decoding of cortical spikes in multistep goal-directed tracking task [using Q(λ )] [194], adaptive BMI capable of adjusting to dramatic reorganizing neural activities with minimal training and stable performance over long duration (using actor-critic) [195], and BMI for efficient nonlinear mapping of neural states to actions through sparsification of state-action mapping space using quantized attention-gated kernel RL as an approximator [196]. Also, Lampe et al. [182] proposed BMI capable of transmitting imaginary movement-evoked EEG signals over the Internet to remotely control a robotic device, and Bauer and Gharabaghi [183] combined RL with the Bayesian model to select dynamic thresholds for an improved performance of restorative BMI.

SECTION IV.Performance Analysis and Comparison
Comparative test results, in the form of performances/ accuracies of each DL technique when applied to the data coming from Omics (Fig. 2), Bioimaging (Fig. 3), Medical Imaging (Fig. 4), and BMIs (Fig. 5), are summarized in the following to facilitate the reader in selecting the appropriate method for h(is/er) research. The reported performances can be regarded as a metric to evaluate the strengths/weaknesses of a particular technique with a given set of parameters on a specific data set. It should be noted that several factors (e.g., data preprocessing, network architecture, feature selection and learning, and parameters’ optimization) collectively determine the accuracy of a method.


Fig. 2.
Performance comparison of representative DL techniques when applied to Omics data in (a) predicting splice junction, (b) CPIs, (c) secondary/tertiary structures of proteins, (d) analyzing GE data and classifying and detecting cancers from them, (e) predicting DNA- and RNA-sequence specificity (details about DREAM5 can be found in [201] and [202]), (f) RNA binding proteins, and (g) micro-RNA precursors. Ray et al.’s method [199].

Show All


Fig. 3.
Performance comparison of some DL and conventional ML techniques when applied to bioimaging application domain. (a) Performances in classifying EMIs for cell compartments, cell cycles, and cells. (b) Performances in analyzing images to automatically annotate features and detect mitosis and cell nuclei.

Show All


Fig. 4.
Performance comparison of representative DL techniques when applied to medical imaging. (a) Performance of image segmentation techniques in segmenting tumors (BT: brain tumor), and different organ parts (ON: optic nerve, GL: gland, LV: left ventricle of heart, BP: blood pool, and MC: myocardium). (b) Image denoising techniques to improve image quality during the presence of GN, PN, SPN, and SN. (c) Detecting anomalies and diseases in mammograms. (d) Classification and detection of AD and MCI, along with healthy controls (NC). (e) Performance of prominent techniques for LNC, organ classification, brain tumor detection, colon polyp detection, and chemotherapy response detection.

Show All


Fig. 5.
Accuracy comparison of DL and conventional ML techniques when applied to BMI signals. (a) Performance comparison in detecting motor imagery, recognizing emotion and cognitive states (ER), and detecting anomaly (AnD) from EEG signals. (b) Accuracies of MD from EMG signals. (c) Accuracies of ECG signal classification.

Show All

In Figs. 2–5, each group of bars indicates the accuracies/ performances of comparable DL or non-DL techniques when applied to the same data and reported in an individual study. And, each bar in a group shows the (mean) performance of different runs of a technique on either multiple subjects/data sets (for means, error bar is ± standard deviation). Many of the acronyms used in the performance comparison are defined in the legends of the figures.

A. Omics
Fig. 2(a) reports that DBN outperforms other methods in predicting splice junction when applied to two data sets from Whole Human Genome database (GWH-donor and GWH-acceptor) and two from UCSC genome database (UCSC-hg19 and UCSC-hg38) [79]. In the GWH data sets, the DBN-based method achieved superior F1-score (0.81 and 0.75) against the SVM-based methods with radial basis (SVM-RBF; 0.77 and 0.67), sigmoid (SVM-SF; 0.71 and 0.56) functions, and other splicing techniques, such as gene splicer (GS; 0.74 and 0.75) and splice machine (SM; 0.77 and 0.73). Also, in the UCSC data sets, the DBN achieved highest classification accuracy (0.88 and 0.88) in comparison with SVM-RBF (0.868 and 0.867) and SVM-SF (0.864 and 0.861).

Performance comparison of CPI is shown in Fig. 2(b). Tested over two CPI data sets, a DNN-based method (DNN*) achieved superior prediction accuracy (93.2% in data set 1 and 93.8% in data set 2) compared with other methods based on RF (83.9% and 86.6%), logistic regression (88.3% using LR-L1 and 89.9% using LR-L2), and SVM (88.7% and 90.3% using SVM3) [88]. In another study, a similar DNN* was applied on the DUD-E data set, where it achieved higher accuracy (99.6%) over RF-based (99.58%) and CNN-based (89.5%) methods [89]. As per the accuracies reported in [88], the RF-based method had lower values in comparison with the LR- and SVM-based methods, which had similar values. When applied on DUD-E data set (reported in [89]), the RF-based method outperforms the CNN-based method. This may be attributed to the fact that, classification problems are data dependent and despite being one of the best classifiers [200], RF performs poorly on the DUD-E data set.

In predicting 2-PS, DL-based methods outperform other methods [see Fig. 2(c)]. When applied on two data sets (CASP11 and TS1199), the stacked sparse autoencoder (StSAE)-based method achieved superior prediction accuracy (80.8% and 81.8%) in comparison with other NN-based methods (FFNN: 79.9% and 82%, MSNN: 78.8% and 81%, and PSIPRED: 78.8% and 79.7%) [87]. Another DL method with conditional neural fields, when tested on five different data sets (CullPDB53, CB513, CASP1054, CASP1155, and CAMEO), better predicted the 2-PS (Q8 accuracy: 75.2%, 68.3%, 71.8%, 72.3%, and 72.1%) in comparison with other nontemplate-based methods (SSPro: 66.6%, 63.5%, 64.9%, 65.6%, and 63.5% and CNF: 69.7%, 64.9%, 64.8%, 65.1%, and 66.2%) [98]. However, when a template of solved protein structure from protein data bank (PDB) was used, the SSpro with template obtained the best accuracy (SSProT: 85.1%, 89.9%, 75.9%, 66.7%, and 65.7%).

To annotate GV in identifying pathogenic variants from two data sets [TS and CVESP in Fig. 2(d)], a DNN-based method performed better (72.2% and 94.6%) than LR-based (63.5% and 95.2%) and SVM-based (63.1% and 93%) methods. Another CNN-based approach to predict DNA sequence accessibility was tested on data from ENCODE and REC databases and was reported to outperform gapped k-mer SVM method (a mean area under the receiver operating characteristic curve or AUC of 0.89 versus 0.78) [94]. In classifying cancer based on somatic point mutation using raw TCGA data containing 12 cancer types, a DNN-based method outperformed non-DL methods [60.1% versus (SVM: 52.7%, kNN: 40.4%, and Naive Bayes (NB): 9.8%)] [90]. To detect breast cancer using GE data from the TCGA database, a stacked denoising autoencoder (StDAE) was employed to extract features. According to the reported accuracies of non-DL classifiers (ANN, SVM, and SVM-RBF), StDAE outperformed other feature extraction methods, such as PCA and kernel-PCA (SVM-RBF classification accuracies for StDAE, PCA, and kernel-PCA were 98.26%, 89.13%, and 97.32%, respectively) [77]. Also, deeply connected genes were better classified with StDAE extracted features (accuracies—ANN: 91.74%, SVM: 91.74%, and SVM-RBF: 94.78%) [77]. Another study on classifying cancer, using 13 different GE data sets taken from the literature, reported that the use of PCA in data dimensionality reduction, before applying SAE, StAE, and StAE-FT for feature extraction, facilitates more accurate extraction of features [except AC and OV in Fig. 2(d)] for classification using SVM with Gaussian kernel [76].

Sequence specificities of (D/R)BPs prediction was performed more accurately using a deep CNN-based method in comparison with other non-DL methods that participated at the DREAM51 challenge [93]. As seen in Fig. 2(e), the CNN based method (DeepBind-CNN or DBCNN) outperformed other methods in ChIP AUC values (top two values- DBCNN: 0.726 versus BEEML-PBM_sec: 0.714) and PBM scores (two top scores- DBCNN: 0.998 versus FeatureREDUCE: 0.985) [201], [202].

Moreover, in predicting RBP, DL-based methods outperformed non-DL methods, as seen in Fig. 2(f). As reported using CLIP AUC values, the DBCNN outperforms Ray et al. (0.825 versus 0.759) [93], multimodal DBN outperforms GraphProt (0.902 versus 0.887) [84], and DBN-CNN hybrid outperforms NMF-based methods (0.9 versus 0.85) [82].

Also, in predicting miRNA precursor Fig. 2(g), an RNN with DA outperformed other non-DL methods [RNNAE: 0.97 versus (MIL: 0.58, PFM: 0.77, PFM: 0.59, PBM: 0.58, EN: 0.71, and MDS: 0.64)] [100]. And LSTM outperformed SVM methods [LSTM: 0.93 versus (Boost-SVM: 0.89, CSHMM: 0.65, SVM-LSS: 0.79, SVM-MFE: 0.86, and RBS: 0.8)] [99].

B. Bioimaging
A DNN was used for detecting 12 different cellular compartments from microscopy images and reported to have achieved a classification accuracy of 87% compared to 75% for RF [111]. The mean performance of the detection was 83.24% ± 5.18% using the DNN and 69.85% ± 6.33% using the RF [Fig. 3(a)]. In classifying flow cytometry images for cell-cycle phases, a deep CNN with nonlinear dimension reduction outperformed boosting (98.73% ± 0.16% versus 93.1% ± 0.5%) [Fig. 3(a)] [114]. The DNN, trained using a genetic algorithm with AUC as a cost function, performed labelfree cell classification at higher accuracy (95.5%±0.9%) than SVM with Gaussian kernel (94.4% ± 2.1%), LR (93.5% ± 0.9%), NB (93.4% ± 1%), and DNN trained with cross entropy (88.7% ± 1.6%) [Fig. 3(a)] [107].

Colon histopathology images were classified with higher accuracy using the DNN and MIL (97.44%) compared with K-means clustering (89.43%) [106] [Fig. 3(b)]. Deep max-pooling CNN detected mitosis in breast histology images with higher accuracy (88%) in comparison with statistical-feature-based classification (70%) [Fig. 3(b)] [109]. Using StSAE with softmax classifier (SMC), nuclei were more accurately detected from breast cancer histopathology images (88.8% ± 2.7%) when compared with other techniques with SMC–CNN (88.3% ± 2.7%), three-layer SAE (88.3% ± 1.9%), StAE (83.7% ± 1.9%), SAE (84.5% ± 3.8%), AE (83.5% ± 3.3%), SMC alone (78.1% ± 4%), and EM (66.4% ± 4%) [Fig. 3(b)] [105].

C. Medical Imaging
Comparative test results on the performance of various DL/non-DL techniques in segmenting medical images to detect pathology or organ parts are reported in Fig. 4(a). A multiscale, dual pathway, 11-layered, 3-D CNN-based method with conditional random fields outperformed an RF method (DSC metric values: 63±16.3 versus 54.8±18.5) when segmenting brain lesion in MRIs obtained from the TBI database. The classifier’s accuracy improved when three similar networks were ensembled (i.e., used as an ensembled method) and their outputs were averaged (64.5±16.3 versus 63±16.3) [130]. In a similar task, a (two pathway/cascaded) CNN trained using a two-phase training procedure, with local and global features, outperformed other methods participating at the MCCAI-BRATS20132 as reported using Dice coefficients (InputCascadeCNN: 0.88 versus Tustison: 0.87) [125]. The StAE-based method performed similarly or superior to other non-DL methods [see “ON” in Fig. 4(a), DSC values–StAE: 0.79 versus (MAF: 0.77, MAF: 0.76, and SVM: 0.73)] in segmenting optic nerve from MRI data [116]. Several DL methods were evaluated for identifying glands in colon histology images, and a DCAN-based method outperformed other CNN-based methods at the GlaS contest3 [DCAN: 0.839 versus (MPCNN1: 0.834, UCNN-MHF: 0.831, MFR-FCN: 0.833, MPCNN2: 0.819, and UCNN-CCL: 0.829)] [156]. Also, left ventricles were segmented from cardiac MRI, where a CNN-StAE-based method outperformed other methods [CNN-StAE: 0.94 versus (TLVSF: 0.9, DRLS-DBN: 0.89, GMM-DP: 0.89, MF-GVF: 0.86, and TSST-RRDP: 0.88)] [204]. In segmenting volumetric medical images for BP and MC, CNN-based methods outperformed other methods as reported using Dice coefficients—BP (MAF: 0.88, DCNN: 0.93, 3DMRF: 0.87, TVRF: 0.79, 3DUNet: 0.926, and 3DDSN: 0.928) and MC (MAF: 0.75, DCNN: 0.8, 3DMRF: 0.61, TVRF: 0.5, 3DUNet: 0.69, and 3DDSN: 0.74) [157].

DL-based methods outperformed other methods in denoising MMM and dental radiographs [144], and brain CT scans [132] [Fig. 4(b)]. StDAE-CNN performed more accurate denoising in the presence of Gaussian noise (GN)/Poisson noise (PN) as reported using structural SIMilarity (SSIM) index scores (Noisy: 0.63, NL Means: 0.62, MedFilt: 0.8, CNNDAEa: 0.89, and CNNDAEb: 0.9) [144]. Adaptive MCStSDA outperformed MCStSDA in denoising CT images as reported using peak signal-to-noise ratio (PSNR) values for GN, salt and pepper (SPN), and speckle noise (SN) (SSIM4 scores—GN: 26.5 versus 22.7, SPN: 25.5 versus 22.1, and SN: 26.6 versus 25.1) [132].

CNN-based methods performed very well in detecting breast mass and lesion in MMM obtained from different data sets [see Fig. 4(c)]. For MMM obtained from the FFDM database, trained with labeled and unlabeled features, CNN outperformed other methods (CNN-LU: 87.9%, SVM-LU: 85.4%, ANN-LU: 84%, SVM-L: 82.5%, and ANN-L: 81.9%) [153]. In detecting masses in MMM from the BCDR database, the CNN with two convolution layers and one fully connected layer (CNN3) performed similar to other methods (CNN3:82%, HGD: 83%, HOG: 81%, and DeCAF: 82%), and the CNN with one convolution layer and one fully connected layer performed poorly (CNN2: 78%) [151]. Pretrained CNN with RF outperformed other methods [e.g., RF with handcrafted features and sequential forward selection with linear discriminant analysis (LDA)] while analyzing MMM from the INBreast database (RF-CNNPT: 95%, CNNPT: 91%, RF-HF: 90%, and SFS-LDA: 89%) [155]. In yet another study, the CNN with a linear SVM outperformed other methods on MMM from the DDSM database (CNN-LSVM: 96.7%, SVM-ELM: 95.7%, SSVM: 91.4%, AANN: 91%, SCNN: 88.8%, and SVM: 83.9%) [152]. However, for the MMM from the MIAS database, a DWT with backpropagating NN outperformed its SVM/CNN counterparts (DWT-GMB: 97.4% versus SVM-MLP: 93.8%) [152].

Despite having been all applied on images from the ADNI database, reported methods displayed different performances in detecting and classifying “AD versus NC” and “MCI versus NC” (AD and MCI, in short) varied greatly [see Fig. 4(d)]. An approach employing deep-supervised-adaptable 3-D-CNN (DSA-3-D-CNN) outperformed other DL and non-DL methods, as reported using their accuracies, in detecting AD and MCI [AD, MCI—DSA-3-D-CNN: 99.3%, 94.2% versus (DSAE: 95.9% and 85%, DBM: 95.4% and 85.7%, SAE-3-D-CNN: 95.3% and 92.1%, SAE: 94.7% and 86.3%, DSAE-SLR: 91.4% and 82.1%, MK-SVM: 96% and 80.3%, ISML: 93.8% and 89.1%, and DDL: 91.4% and 77.4%)] [126]. A stacked RBM with dropout-based method outperformed the same method without dropout and multikernel-based SVM method in detecting AD and MCI [AD, MCI—SRBMDO: 91.4% and 77.4% versus (SRBMWODO: 84.2% and 73.1% and MK-SVM: 85.3% and 76.9%)] [121]. In another method with StAE extracted features, MK-SVM was more accurate than SK-SVM method [(AD, MCI)—MK-SVM: 85.3% and 76.9% versus SK-SVM: 95.9% and 85%)] [117]. Another method, where features from MRI and PET were fused and learned using MStDPN algorithm, outperformed other multimodal learning methods in detecting AD and MCI (AD, MCI—MTL: 95.38% and 82.99%, StSDAE: 91.95% and 83.72%, MStDPN-SVM: 97.13% and 87.24%, and MStDPN-LC: 96.93% and 86.99%) [124].

Different techniques reported varying accuracies in detecting a range of anomalies from different medical images [Fig. 4(e)]. The CNN had a better accuracy in classifying ILD (85.61%) when compared with RF (78.09%), kNN (73.33%), and SVM-RBF (71.52%) [147]. Lung nodule classification (LNC) was accurately done using StDAE (95%) compared with RT-SVM (72.5%) and CT-SVM (77%) [138]. Multicrop CNN achieved a better accuracy (87.14%) than the DAE with binary DT (80.29%) and quantitative radiomics-based approach (83.21%) in LNC [140]. MTANNs outperformed CNNs variants in LNC [MTANN: 88.06% versus (SCNN: 77.09%, LeNet: 75.86%, RDCNN: 78.13%, AlexNet: 76.85%, and FT-AlexNet: 77.55%)] [141]. A hierarchical CNN with extreme learning machine (ELM) outperformed other CNN and SVM methods [HCNN-NELM: 97.23% versus (SIFT-SVM: 89.79%, CNN: 95%, and CNN-SVM: 97.05%)] in classifying digestive organs [149]. A multichannel CNN with PCA and handcrafted features better detected BT (89.85%) in comparison with 2-D-CNN (81.25%), scale-invariant transform (78.35%), and manual classification with handcrafted features (62.8%) [129]. A 2-D-CNN-based method trained with stochastic gradient descent learning outperformed other non-DL methods [AUC values—CNN: 0.93 versus (HoG-SVM: 0.87 and RF-SVM: 0.76)] in detecting colon polyp from CT colonographs [137]. In addition, 3Slice-CNN was successfully employed to detect chemotherapy response in PET images, which outperformed other shallow methods (3S-CNN: 73.4% ± 5.3%, 1S-CNN: 66.4%±5.9%, GB: 66.7%±5.2%, RF: 57.3%±7.8%, SVM: 55.9%±8.1%, GB-PCA: 66.7%±6%, RF-PCA: 65.7%±5.6%, and SVM-PCA: 60.5% ± 8%) [143].

D. (Brain/Body)–Machine Interfaces
Test results in the form of performance comparison of DL/non-DL methods applied to EEG data to detect MoI, emotion and affective state, and anomaly are shown in Fig. 5(a).

A linear parallel CNN with MLP classified EEG energy dynamics more accurately (70.6%) than SVM (67%), MLP (65.8%), and CNN (69.6%) to detect MoI from the BCI Competition (BCIC) IV-2a data set [174]. A CNN better classified frequency complementary feature maps of augmented CSP and SFM as features (68.5% and 69.3%) than filter-bank CSP (67%) to detect MoI from the BCIC IV-2a data set [172]. CNN, StAE, and their combination (CNN-StAE) were tested in classifying MoI from BCIC IV-2b EEG data. Using time, frequency, and location information as features, CNN-StAE achieved best accuracy (77.6% ± 2.1%) in comparison with SVM (72.4% ± 5.7%), CNN (74.8% ± 2.3%), and StAE (57.7% ± 5.5%) [173]. A DBN with Ada-boost-based classifier had higher accuracy (~81%) than SVM (~76%) in classifying hand movements from EEG [162]. Another DBN-based method reported better accuracy (0.84) using frequency representations of EEG (using FFT and wavelet package decomposition) rather than FCSP (0.8), and CSP (0.76) in classifying MoI [161]. A DNN-based method, with layerwise relevance propagation heatmaps, performed comparably (75%) with CSP-LDA (82%) in MoI classification [170].

A deep learning network (DLN) was built using StAE with PCA and covariate shift adaptation to classify valence and arousal states from DEAP EEG data with multichannel power spectral densities as features. The mean accuracy of the DLN was 52.7% ± 9.7% compared with SVM (40.1% ± 7.9%) [160]. A supervised DBN-based method classified affective states more accurately (75.6% ± 4.5%) when compared with SVM (64.7% ± 4.6%) by extracting deep features from thousands of low-level features using the DEAP EEG data [163]. A DBN-based method, with differential entropy as features, explored critical frequency bands and channels in EEG, and classified three emotions (positive, neutral, and negative) with higher accuracy (86.1%) than SVM (83.9%) [165]. As reported through Az-score, in predicting driver’s drowsy and alert state from EEG data, CCNN and CNNR methods outperformed (79.6% and 82.8%, respectively) other DL (CNN: 71.4% ± 7.5% and DNN: 76.5% ± 4.4%) and non-DL (LDA: 52.8% ± 4% and SVM: 50.4% ± 2.5%) methods [176].

A DBN was used to model, classify, and detect anomalies from EEG waveforms. It has been reported that using raw data, a comparable classification and superior anomaly detection accuracy (50% ± 3%) can be achieved compared with SVM (48% ± 2%) and kNN (40% ± 2%) classifiers [166]. Another DBN- and HMM-based method performed comparable sleep stage classification from raw EEG data (67.4%±12.9%) with respect to DBN with HMM and features (72.2%±9.7%) and Gaussian observation HMM with features (63.9% ± 10.8%) [168].

Fig. 5(b) shows the performances of various methods in movement decoding (MD) from (s)EMG. A CNN-based method’s hand movement classification accuracy using three sEMG data sets (from the Ninapro database) were comparable with other methods [CNN versus (kNN, SVM, RF)]—data set 1: 66.6% ± 6.4% versus (60% ± 8%, 62.1% ± 6.1%, and 75.3%±5.7%), data set 2: 60.3%±7.7% versus (68%±7%, 75%±5.8%, and 75.3%±7.8%), and data set 3: 38.1%±14.3% versus (38.8% ± 11.9%, 46.3% ± 7.9%, and 46.3% ± 7.9%) [184]. Another method, a user-adaptive one, using CNN with deep feature learning, decoded movements more accurately compared with SVM (95% ± 2% versus 80% ± 10%) [185].

Fig. 5(c) compares different techniques’ performances in classifying ECG signals from MIT-BIH arrhythmia database and detecting anomalies in them. A nonlinear SVM with Gaussian kernel (DBN1) outperformed (98.5%) NN (97.5%), LDA (96.2%), SVM with genetic algorithm (SVM1: 96%), SVM with kNN (SVM2: 98%), Wavelet with PSO (88.8%), and CA (94.3%) in classifying ECG features extracted using the DBN [186]. Comparable accuracy in classifying ECG beats was obtained using the DBN with softmax (DBN2: 98.8%) compared to SVM with Wavelet and independent component analysis (ICA) (SVM3: 99.7%), SVM with higher order statistics and Hermite coefficients (SVM4: 98.1%), SVM with ICA (SVM5: 98.8%), DT (96.1%), and Dynamic Bayesian network (DyBN: 98%) [187]. Using the DBN (with contrastive divergence and persistent contrastive divergence learning), arrhythmias were classified more accurately (98.6%) in comparison with block NN1 (98.1%), feedforward-based NN with PSO (NN2: 97.0%), mixture of experts (97.6%), and LDA (95.5%) [188].

SECTION V.Open Issues and Future Perspectives
Overall, it is believed that the brain solves problems through reinforcement learning and neuronal networks organized as hierarchical processing systems. Though since the 1950s the field of AI has been trying to adopt and implement this strategy in computers, notable progress has been seen only recently due to our better understanding about learning systems, increase of computational power, decline of computing costs, and last but not least, the seamless integration of different technological and technical breakthroughs. However, there are still situations where these methods fail, underperform against traditional methods, and, therefore, must be improved. In the following, we outline, what in our opinion are, the shortcomings of current techniques and existing open research challenges, and speculate about some future perspectives that will facilitate further development and advancement of the field.

The combined computational capability and flexibility provided by the two prominent ML methods (i.e., DL and RL) also has limitations [33]. Both of these methods require heavy computing power and memory, and therefore, are not worthy of being applied to moderate size data sets. Additionally, the theory of DL is not completely understood, making the high-level outcomes obscure and difficult to interpret. This turns into a situation when the models are considered as “Black box” [206]. In addition, like other ML techniques, DL is also susceptible to misclassification [72] and overclassification [207]. Furthermore, in representing action-value pairs in RL, it is not possible to use all nonlinear approximators, which may cause instability or even divergence in some cases [31]. Also, bootstrapping makes many of the RL algorithms NP-hard and inapplicable to real-time applications, as they are too slow to converge and in some cases too dangerous (e.g., autonomous driving). Moreover, very few of the existing techniques support harnessing the potential power of distributed and parallel computation through cloud computing. Arguably, in case of cloud, distributed, and parallel computing, data privacy and security concerns are still prevailing [208], and real-time processing capability of the gigantic amount of experimentally acquired data is still underdeveloped [209], [210].

To proceed toward mitigating shortcomings and addressing open issues, firstly, improving the existing theoretical foundations of DL on the basis of experimental data becomes crucial to be able to quantify the performances of individual NN models [211]. These improvements should be able to address issues, such as specific assessment of an individual model’s computational complexity and learning efficiency in relation to well-defined parameter tuning strategies, and the ability to generalize and topologically self-organize based on data-driven properties. Also, novel data visualization techniques should be incorporated so that the interpretation of data becomes intuitive and less cumbersome. In terms of learning strategies, updated hybrid on- and off-policy with new advances in optimization techniques is required. The problems pertaining to observability of RL are yet to be completely solved, and optimal action selection is still a huge challenge.

As seen in Table I, there are timely opportunities to employ deep RL in biological data mining, for example, deriving dynamic information from biological data coming from multiple levels to reduce data redundancy and discover novel biomarkers for disease detection and prevention. Also, new unsupervised learning for deep RL methods is required to shrink the necessity of large sets of labeled data at the training phase. Multitasking and multiagent learning paradigm should advance in order to cope with dynamically changing problems.

In addition, to keep up with the rapid pace of data growth in biological application domains, computational infrastructures in terms of distributed and parallel computing tailored to those applications are needed.

SECTION VI.Conclusion
The recent bliss of technological advancement in life sciences came with the huge challenge of mining the multimodal, multidimentional, and complex biological data. Triggered by that call, interdisciplinary approaches have resulted in the development of cutting edge machine learning-based analytical tools. The success stories of ANN, deep architectures, and reinforcement learning in making machines more intelligent are well known. Furthermore, computational costs have dropped, computing power has surged, and quasi-unlimited solid-state storage is available at a reasonable price. These factors have allowed to combine these learning techniques to reshape machines’ capabilities to understand and decipher complex patterns from biological data. To facilitate wider deployment of such techniques and to serve as a reference point for the community, this paper provides a comprehensive survey of the literature of techniques’ usability with different biological data. Further, a comparative study is presented on performances of various DL techniques, when applied to data from different biological application domains, as reported in the literature. Finally, some open issues and future perspectives are highlighted.