This article addresses the problem of distributed path following of multiple under-actuated autonomous surface vehicles (ASVs) with completely unknown kinetic models. An integrated distributed guidance and learning control architecture is proposed for achieving a time-varying formation. Specifically, a robust distributed guidance law at the kinematic level is developed based on a consensus approach, a path-following mechanism, and an extended state observer. At the kinetic level, a model-free kinetic control law based on data-driven neural predictors via integral concurrent learning is designed such that the kinetic model can be learned by using recorded data. The advantage of the proposed method is two-folds. First, the proposed formation controllers are able to achieve various time-varying formations without using the velocities of neighboring vehicles. Second, the proposed control law is model-free without any parameter information on kinetic models. Simulation results substantiate the effectiveness of the proposed robust distributed guidance and model-free control laws for multiple under-actuated ASVs with fully unknown kinetic models.

SECTION I.Introduction
Cooperative control of autonomous surface vehicles (ASVs) has drawn considerable attention due to its wide range of applications in military and civilian fields [1]–[2][3][4]. In the published literature, there are several formation control methods including a graph-based method [5], a behavioral method [6], a virtual structure mechanism [7], an artificial potential field method [8], and a leader–follower method [9], [10]. In particular, the graph-based method is broadly explored [11], [12]. Typical formation control scenarios using a graph-based method include cooperative path following [13], [14] and cooperative trajectory tracking [15], [16]. In contrast to cooperative trajectory tracking, the objective of cooperative path following is to track parameterized paths whose evolutions are to be designed. This provides extra freedom to achieve the desired formation behaviors [17], [18].

Cooperative path following with full parameterized paths is considered in the literature [11], [19]–[20][21][22]. For example, a passivity-based synchronization method is proposed for synchronized path following [11]. In [19], the problem of cooperative path following with parametric uncertainty and environmental disturbance is considered. A cooperative path-following controller is developed under discrete time communications [20]. In [11], [19], and [20], the formation is achieved by synchronizing the path variables. In [21], the problem of cooperative path following along one parameterized path is studied, and a path variable containment method is proposed such a queue formation can be reached. The cooperative path following over a ring-networked topology is addressed and the symmetric formation on a closed curve is achieved [22]. In the literature above, each vehicle should be assigned a parameterized path. In case the reference path is available to a small fraction of vehicles, distributed path following of marine surface vehicles is considered [23]–[24][25][26]. In [23], a distributed path following controller guided by multiple parameterized paths is designed and the ASVs are able to follow a convex hull spanned by the multiple paths. The result in [23] is extended to an output feedback case [24], where an echo-state-network-based observer is used to recover the unmeasurable velocities and model uncertainties. Distributed path-following control guided by one parameterized path is addressed [27]–[28][29]. In [27], a neurodynamic optimization and fuzzy approximation method is presented to address the problem of state-constrained path following of ASVs subject to uncertainties. A time-varying formation controller is developed such that the collision avoidance and connectivity preservation can be guaranteed [28]. It is worth mentioning that the cooperative path-following controllers in [23]–[24][25], [27], and [28] are designed for full-actuated marine vehicles, and cannot be applied to under-actuated ASVs, which limits their applications in practical applications since most marine vehicles are designed in under-actuation. On the other hand, the control input gain or the inertia matrix addressed in [19]–[20][21][22][23][24][25][26][27][28][29] is assumed to be known. If the inertia matrix is not available or the inertia matrix varies due to load changes or actuator faults, the methods in [19]–[20][21][22][23][24][25][26][27][28][29] are not applicable.

Concurrent learning is a recently developed adaptive estimation scheme which can guarantee parameter convergence without requiring persistent excitation. The pioneering work of concurrent learning can be found in [30] and [31], where the parameter convergence is assured provided that a finite excitation condition is satisfied. However, the methods in [30] and [31] require the knowledge of state derivatives. In [32], a concurrent learning adaptive control method is proposed based on a dynamic state-derivative estimator. To overcome the complexity difficulty resulting from the state derivative estimation, an integral concurrent learning method is developed in [33], and numerical integration is used to circumvent the need of state derivatives. In [34], the integral concurrent learning control approach is applied to trajectory tracking of a fully-actuated ASV, where only the parametric uncertainties are considered. Also, it is worthwhile mentioning that the issue about unknown input gains is not addressed in these studies [33], [34].

Based on the above observations, in this article, we investigate the distributed path following of multiple under-actuated ASVs subject to kinetic uncertainties, ocean disturbances, and an unknown inertia matrix. At the kinematic level, a robust distributed guidance law is proposed by using an extended state observer, such that the time-varying formation can be achieved without using the velocity information of neighboring vehicles. At the kinetic level, a model-free kinetic controller is developed based on data-driven neural predictors via integral concurrent learning, under which internal/external disturbances and unknown input gains can be estimated. The closed-loop distributed path-following control system is proved to be input-to-state stable. Simulation results are provided to illustrate the effectiveness of the presented robust distributed guidance and model-free control methods based on data-driven neural predictors via integral concurrent learning. The main features of the proposed distributed guidance and model-free control laws are as follows.

A robust distributed guidance law based on an extended state observer is developed such that the velocity information of neighboring vehicles is not needed, thereby reducing network burden. In contrast, the distributed path-following methods in [23]–[24][25][26][27][28][29] require the velocities of neighboring ASVs to be known by each node.

The proposed data-driven neural predictor is capable of estimating the unknown input gains, in addition to the internal model uncertainties and external ocean disturbances. However, the cooperative path-following methods in [23]–[24][25], [27], and [28] require the control input gains to be known in advance.

The proposed data-driven neural predictor via integral concurrent learning can ensure the estimation convergence under finite excitation. By contrast, the parameter estimation is convergent under the condition of the persistence of excitation in the neural-network-based controllers [21], [23], [24], [27], [35]–[36][37][38][39][40].

The proposed distributed path-following controllers are designed for under-actuated ASVs, which are more general than fully actuated ASVs. An error transformation is introduced to deal with the under-actuation herein. By contrast, the cooperative path following controllers in [23]–[24][25], [27], and [28] are designed for full-actuated marine vehicles only.

The remainder of this article is organized as follows. The problem is formulated in Section II. In Section III, a robust kinematic controller and a model-free kinetic controller are developed, and stability of the cascade system is analyzed. Simulation results are given in Section IV to demonstrate the validity of the distributed formation control method. Section V draws a conclusion.

SECTION II.Problem Formulation
A. Problem Formulation
Consider the following system consisting of M under-actuated ASVs with kinematics described by
⎧⎩⎨⎪⎪x˙i=uicosψi−visinψiy˙i=uisinψi+vicosψiψ˙i=ri(1)
View Sourcewhere (xi,yi) is the position in a body-fixed frame and ψi is the yaw angle; and ui , vi , and ri denote the surge velocity, sway velocity, and angular velocity, respectively. The kinetics of the i th ASV are given by
⎧⎩⎨miuu˙i=fiu(ui,vi,ri)+τiu+τiuwmivv˙i=fiv(ui,vi,ri)+τivwmirr˙i=fir(ui,vi,ri)+τir+τirw(2)
View Sourcewhere miu , miv , and mir are inertia parameters which are unknown; fiu(⋅) , fiv(⋅) , and fir(⋅) are unknown nonlinear functions including Coriolis/centripetal force and hydrodynamic damping effects; τiu and τir are control inputs of surge force and yaw moment. τiuw , τivw , and τirw are the time-varying environmental disturbances. Since miu , miv , and mir and fiu(⋅) , fiv(⋅) , and fir(⋅) are totally unknown, the considered problem is more difficult than the one in [19]–[20][21][22][23][24][25][26][27][28][29].

For an under-actuated ASV, the rank of the control component of the kinetic motion model is less than its degrees of freedom [41]. In the vehicle model (2), the sway direction is not actuated and the ASV in consideration is under-actuated.

Consider a virtual leader moving along a parameterized path
p0(θ)=[x0(θ),y0(θ)]T∈R2(3)
View Sourcewith θ∈R being a path variable and pθ0(θ)=∂p0(θ)/∂θ .

A graph G={V,E} is used to describe the topology among the M vehicles and the virtual leader. V={n0,…,nM} is a node set and E={(i,j)∈V×V} is an edge set. The pair (ni,nj) denotes the communication from node j to node i . An adjacency matrix is defined as A=[aij]∈RM×M . If an edge (nj,ni)∈E , then aij=1 ; otherwise, aij=0 . Define Ni as the neighboring set of the i th ASV excluding the node 0, and N¯i as the neighboring set of the i th ASV. The following assumption is needed.

Assumption 1:
The graph G contains a spanning tree with the root node being the node n0 .

A geometrical illustration of the distributed path following of ASVs is shown in Fig. 1. The desired path is a parameterized one with θ being the path parameter. For distributed path following, only a small number of ASVs have access to the parameterized path, and a predefined formation is achieved by multiple ASVs based on the neighboring information. The control objective of the distributed path following is divided into a geometric task and a dynamic task.

Geometric task: To force the ASVs to follow a parameterized path while achieving the desired formation
limt→∞∥pi(t)−pid(t)−p0(θ(t))∥≤l1(4)
View Sourcewhere pi=[xi,yi]T ; pid(t)∈R2 is a deviation relative to the virtual leader on the parameterized path; l1∈R is a positive constant.

Dynamic task: To force the path update speed θ˙(t) to converge to the desired value
limt→∞|θ˙(t)−vs(t)|≤l2(5)
View Sourcewhere vs(t)∈R is a desired speed and l2∈R is a positive constant.


Fig. 1.
Geometrical illustration of distributed path following of ASVs.

Show All

The desired path is a parameterized one, which only determines the spatial constraints. A desired speed vs is introduced as the update speed for the path parameter θ , and it determines the temporary constraints. As a result, the spatial and temporary constraints are decoupled. On one hand, the path and the desired motion along the path can be designed individually, which provides extra flexibility. On the other hand, since the desired motion along the path can be shaped by state feedback, it will result in better transient motion than that of trajectory tracking.

To move on, the following assumptions are needed.

Assumption 2 [49], [50]:
The solution of (2) exists, that is, there exist positive constants u∗ , v∗ , and r∗ such that |ui|≤u∗ , |vi|≤v∗ , and |ri|≤r∗ . The accelerations of the ASV are bounded, that is, |u˙i|≤u∗d , |v˙i|≤v∗d , and |r˙i|≤r∗d with u∗d , v∗d , and r∗d being positive constants.

Assumption 3:
The desired deviation pid satisfies that ∥p˙id∥≤p∗d and ∥p¨id∥≤p∗dd with p∗d and p∗dd being positive constants.

Note that the ASV is a mechanical system subject to the Newton’s second law, and its velocities and accelerations are naturally bounded. Therefore, Assumption 2 is reasonable, and the similar assumption is used in [49] and [50].

SECTION III.Design and Analysis
As shown in Fig. 2, the entire control architecture includes a distributed kinematic controller and a model-free kinetic controller. The distributed kinematic controller is to prescribe guidance signals of surge speed and yaw rate according to a desired time-varying formation. The model-free kinetic controller is responsible for tracking the prescribed guidance signals while accounting for model uncertainties, external ocean disturbances, and unknown input gains.


Fig. 2.
Visualization of the proposed distributed guidance and control architecture.

Show All

A. Kinematic Controller Design
In this section, we develop a robust distributed kinematic guidance law based on relative positions and heading of ASVs such that a time-varying formation can be achieved regardless of the unavailable velocities of neighboring ASVs. Define a distributed formation error as
zi=RTi(ψi)[∑j=1Maij(pi−pj−pijd)+ai0(pi−p0(θ)−pid)](6)
View Sourcewhere pijd=pid−pjd∈R2 . The rotation matrix Ri(ψi) is expressed as
Ri(ψi)=[cosψisinψi−sinψicosψi].
View Source

Let θ˙=vs−ϖ , where ϖ is a variable to be designed later. Taking the time derivative of (6) yields
z˙i=−riSzi+d¯i[ui,vi]T−∑j=1MaijRTi(ψi)Rj(ψj)[uj,vj]T−ai0RTi(ψi)pθ0(θ)(vs−ϖ)−∑j=0MaijRTi(ψi)p˙ijd(7)
View Sourcewhere d¯i=∑Mj=0aij and S is given by
S=[01−10].
View Source

In order to address the under-actuation, an error transformation is introduced as follows:
z¯i=zi+[δ0,0]T∈R2(8)
View Sourcewhere δ0∈R is an positive constant. Substituting (8) into (7), it follows that:
z¯˙i=hi[ui,ri]T−ai0RTi(ψi)pθ0(vs−ϖ)−riSz¯i+σi(9)
View Sourcewhere hi=diag{d¯i,δ0} , σi=−Σj∈NiaijRTi(ψi)Rj(ψj)[uj,vj]T−Σj∈N¯iaijRTi(ψi)p˙ijd+[0,d¯ivi]T .

Note that σi is totally unknown due to the unavailable neighboring velocities uj and vj . To estimate it, an extended state observer is proposed as
{z¯^˙iσ^˙i=ϑi+σ^i−ki1z¯~i=−ki2z¯~i(10)
View Sourcewhere z¯~i=z¯^i−z¯i is the estimation error and ϑi=hi[ui,ri]T−ai0RTi(ψi)pθ0(θ)(vs−ϖ)−riSz¯i .

From (9) and (10), it follows that:
{z¯~˙iσ~˙i=σ~i−ki1z¯~i=−ki2z¯~i−σ˙i(11)
View Sourcewhich is reshaped into
E˙i1=AiEi1+Bi(12)
View Sourcewhere Ei1=[z¯~i,σ~i]T , and
A=[−ki1−ki210],B=[02σ˙i].(13)
View Source

Based on the extended state observer, a robust distributed kinematic guidance law is developed as
[uicric]=h−1i(−Kiz¯i∥z¯i∥2+϶2i−−−−−−−−√+ai0vsRTi(ψi)pθ0(θ)+riSz¯i−σ^i)(14)
View Sourcewhere Ki=diag{kix,kiy}∈R2×2 with kix∈R and kiy∈R being positive constants; ϶i∈R is a positive constant. An update law for ϖ is given as
ϖ˙=−λ(ϖ+μ∑i=1Mai0(pθ0(θ))TRi(ψi)z¯i)(15)
View Sourcewhere λ∈R and μ∈R are positive constants.

Substituting (14) into (9), the kinetic error dynamics can be expressed as
⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪z¯˙i=−Kiz¯i∥z¯i∥2+϶2i−−−−−−−−√+ai0RTi(ψi)pθ0ϖ−σ~iϖ˙=−λ(ϖ+μ∑i=1Mai0(pθ0)TRi(ψi)z¯i).(16)
View Source

Remark 1:
Distributed control without using velocity information is considered in [22], [29], and [42]–[43][44][45][46][47]. Specifically, the position-measurement-based velocity observers proposed in [29], [42], and [43] are to estimate its own velocity. The neighboring-information-based distributed velocity observers proposed in [29], [42], and [43] are to estimate the average velocities of leaders. However, the communication of estimated velocity information is needed in [22], [29], and [42]–[43][44][45]. In [46], the future velocity sequence is calculated based on the position state predictions. In [47], a distributed filter is proposed for estimating the velocities of neighbors for each follower vehicle. By contrast, an extended state observer based on distributed position errors is developed herein to estimate the unknown term related to the unavailable velocities of neighbors. In addition, the communication of the velocities is not required.

B. Kinetic Controller Design
In this section, a model-free kinetic controller is designed based on a data-driven neural predictor via integral concurrent learning. Let biu=1/miu and bir=1/mir . From (2), the kinetic model of the i th ASV is expressed as
{u˙i=f¯iu+biuτiur˙i=f¯ir+birτir(17)
View Sourcewhere f¯iu=biu[fiu(ui,vi,ri)+τiuw] and f¯ir=bir[fir(ui,vi,ri)+τirw] .

The unknown functions f¯iu and f¯ir can be approximated by neural networks as follows:
{f¯iu=WTiuXiu(ξiu)+εiuf¯ir=WTirXir(ξir)+εir(18)
View Sourcewhere Wiu∈Rn and Wir∈Rn are the unknown weight matrices satisfying ∥Wiu∥≤W∗iu and ∥Wir∥≤W∗ir with W∗iu and W∗ir being positive constants; Xiu and Xir are known activation functions; ξiu and ξir are inputs of neural networks. εiu and εir are the approximation errors satisfying |εiu|≤ε∗iu and |εir|≤ε∗ir with ε∗iu and ε∗ir being positive constants.

Let u^i and r^i be the estimates of ui and ri ; W^iu and W^ir are the estimates of Wiu and Wir ; b^iu and b^ir are the estimates of biu and bir . Then, two data-driven neural predictors are proposed as follows:
⎧⎩⎨u^˙i=W^TiuXiu(ξiu)+b^iuτiu−(kiu+κiu)u~ir^˙i=W^TirXir(ξir)+b^irτir−(kir+κir)r~i(19)
View Sourcewhere u~i=u^i−ui and r~i=r^i−ri ; kiu , kir , κiu , and κir are positive constants. With the aid of the data-driven neural predictors, the transient learning performance can be improved without compromising the convergence rates of tracking errors.

The update laws for W^iu , W^ir , b^iu , and b^ir are designed via integral concurrent learning as follows:
[W^˙iub^˙iu]=−ΓiuProj{[W^iub^iu],[Xiu(ξiu)τiu]u~i−ciu∑k=1N{[ΦkiuTkiu][ui(tk)−ui(tk−Δt)−W^TiuΦkiu−b^iuTkiu]}}(20)
View Sourceand
[W^˙irb^˙ir]=−ΓirProj{[W^irb^ir],[Xir(ξir)τir]r~i−cir∑k=1N{[ΦkirTkir][ri(tk)−ri(tk−Δt)−W^TirΦkir−b^irTkir]}}(21)
View Sourcewhere Proj denotes the projection operator [48]; Γiu , Γir∈R(n+1)×(n+1) and ciu , cir∈R(n+1)×(n+1) are adaptive parameters; Φkiu≜Φiu(tk) , Φkir≜Φir(tk) , Tkiu≜Tiu(tk) , and Tkir≜Tir(tk) , which are given by
⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪Φiu(t)=∫tmax{t−Δt,0}Xiu(ξiu)dtΦir(t)=∫tmax{t−Δt,0}Xir(ξir)dtTiu(t)=∫tmax{t−Δt,0}τiudtTir(t)=∫tmax{t−Δt,0}τirdt(22)
View Sourcewhere tk∈[t−td,t] is the time point over a period of time in the past. Note that the concurrent-learning-based update laws record the data from a past time point to current time. As the recorded data is limited, the proposed method is easy to implement in digital processors.

Let ϵiu=∫tt−Δtεiudt and ϵiu=∫tt−Δtεirdt . There exists a positive constant ϵ∗ satisfying that ϵiu≤ϵ∗ and ϵir≤ϵ∗ . By using (18) and integrating (17), we obtain that
⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪∫tt−Δtu˙idt∫tt−Δtr˙idt=WTiu∫tt−ΔtXiu(ξiu)dt +biu∫tt−Δtτiudt+ϵiu=WTir∫tt−ΔtXir(ξir)dt +bir∫tt−Δtτirdt+ϵir(23)
View Sourcewhich can be further put into
{ui(t)−ui(t−Δt)=WTiuΦiu+biuTiu+ϵiuri(t)−ri(t−Δt)=WTirΦir+birTir+ϵir(24)
View Source∀t>Δt .

Remark 2:
The neural adaptive control methods for nonlinear systems subject to uncertainties are presented in [51]–[52][53][54][55][56][57][58][59][60][61]. In [51]–[52][53][54][55][56][57][58][59][60][61], the neural adaptive control methods assume that the control input gains are known in advance. In [62] and [63], adaptive neural control methods based on Nussbaum gain technique are proposed, such that the unknown control gain signs are compensated. In [61] and [64], model-free neural adaptive control methods are proposed under the assumption that unknown control input gains are locally Lipschitz unknown functions. As a result, the above neural adaptive control methods cannot be applied to the case where the control input gain is completely unknown.

Remark 3:
Various adaptive laws are developed in the existing results in [51]–[52][53][54][55][56][57][58][59]. Specifically, in [51]–[52][53][54][55][56][57][58][59], direct neural adaptive laws are proposed, whereas oscillations will increase with the adaptation gain. To overcome this problem, indirect neural adaptive laws by using prediction errors methods are developed in [60] and [61], such that the transient learning performance can be improved. However, the above neural adaptive laws in [51]–[52][53][54][55][56][57][58][59][60][61] cannot ensure the estimated parameters converge to their true value. By contrast, by introducing historical data into the adaptive update laws, data-driven neural predictors are proposed such that the estimated parameters can converge to their true value under finite excitation only.

The following assumption is needed in stability analysis.

Assumption 3:
The system is sufficiently excited over a finite duration. Specifically, there exist γ>0 and T>Δt such that
⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪λmin⎧⎩⎨∑Nk=1[ΦkiuTkiu][ΦkiuTkiu]T⎫⎭⎬>γλmin⎧⎩⎨∑Nk=1[ΦkirTkir][ΦkirTkir]T⎫⎭⎬>γ(25)
View Source∀t≥T .

Substituting (24) into (20) yields
[W^˙iub^˙iu]=−ΓiuProj{[W^iub^iu],[Xiu(ξiu)τiu]u~i−ciu∑k=1N{[ΦkiuTkiu][ΦkiuTkiu]T[W~iub~iu] +[ΦkiuTkiu]ϵiu}}(26)
View Sourceand
[W^˙irb^˙ir]=−ΓirProj{[W^irb^ir],[Xir(ξir)τir]r~i−cir∑k=1N{[ΦkirTkir][ΦkirTkir]T[W~irb~ir]+[ΦkirTkir]ϵir}}(27)
View Sourcewhere W~iu=W^iu−Wiu , W~ir=W^ir−Wir , b~iu=b^iu−biu , and b~ir=b^ir−bir . The dynamics of u~i and r~i can be expressed as
{u~˙ir~˙i=W~iuXiu(ξiu)+b~iuτiu−(kiu+κiu)u~i=W~irXir(ξir)+b~irτir−(kir+κir)r~i.(28)
View Source

In addition, the error dynamics of W~iu , W~ir , b~iu , and b~ir are given by
[W~˙iub~˙iu]=−ΓiuProj{[W^iub^iu],[Xiu(ξiu)τiu]u~i−ciu∑k=1N{[ΦkiuTkiu][ΦkiuTkiu]T[W~iub~iu] +[ΦkiuTkiu]ϵiu}}(29)
View Sourceand
[W~˙irb~˙ir]=−ΓirProj{[W^irb^ir],[Xir(ξir)τir]r~i−cir∑k=1N{[ΦkirTkir][ΦkirTkir]T[W~irb~ir] +[ΦkirTkir]ϵir}}.(30)
View Source

Define ziu=u^i−uic and zir=r^i−ric , whose time derivatives with (19) are given by
⎧⎩⎨z˙iu=z˙ir=b^iuτiu+W^TiuXiu(ξiu)−(kiu+κiu)u~i−udicb^irτir+W^TirXir(ξir)−(kir+κir)r~i−rdic(31)
View Sourcewith udic and rdic being the derivatives of uic and ric , respectively.

Let uie=ui−uic and rie=ri−ric . Based on the data-driven neural predictors, an adaptive kinetic controller is designed as
⎧⎩⎨τiu=(−kiuuie+udic−W^TiuXiu(ξiu))/b^iuτir=(−kirrie+rdic−W^TirXir(ξir))/b^ir.(32)
View Source

Note that b^iu and b^ir are nonzero due to the property of the projection operator.

Finally, the resulting error subsystem in terms of z¯i , ϖ , ziu , and zir can be expressed by
⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪z¯˙i=−Kiz¯i∥z¯i∥2+϶2i−−−−−−−−√+ai0RTi(ψi)pθ0ϖ+σ~iϖ˙=−λ(ϖ+μ∑i=1Mai0(pθ0)TRi(ψi)z¯i)z˙iu=−κiuziu−kiuu~iz˙ir=−κirzir−kirr~i.(33)
View Source

Remark 4:
Compared with the model-free adaptive control method proposed in [65] and [66], where the estimated parameters cannot converge to their true value, the parameter estimation is convergent without the persistence of exciting herein, thanks to the proposed data-driven neural predictors via integral concurrent learning.

C. Stability Analysis
In this section, we analyze the stability of the cascade system consisting of subsystem (12), subsystem (28)–(30) and subsystem (33) using cascade theory.

Lemma 1:
The subsystem (12), viewed as a system with the states being z¯~i , σ~i , the inputs being σ˙i , is input-to-state stable.

Proof:
Consider the following Lyapunov function:
V˙i1=ETi1PiEi1(34)
View Sourcewith Pi being a positive definite matrix satisfying
ATiPi+PTiAi+I2≤0.
View Source

Taking the time derivative of (46) along (12) yields
V˙i1≤−ETi1Ei1+ETi1PiBiσ˙i.(35)
View Source

Since
∥Ei1∥≥∥PiBi∥∥σ˙i∥θ¯i1(36)
View Sourceit follows that
V˙i1≤−(1−θ¯i1)∥Ei1∥2(37)
View Sourcewhere 0<θ¯i1<1 . Hence, the subsystem (28)–(30) with respect to the input σ˙i is input-to-state stable, and
∥Ei1(t)∥≤λmax(Pi)λmin(Pi)−−−−−−−−√max{∥Ei1(t0)∥e−γi1(t−t0),∥PiBi∥σ∗θ¯i1}∀t≥t0(38)
View Sourcewhere γi1=(1−θ¯i1)/λmax(Pi) .

The boundness of the control inputs σ˙i is stated as follows. Taking the time derivative of σi yields
σ˙i=≤−Σj∈NiaijR˙Ti(ψi)riRj(ψj)[uj,vj]T−Σj∈NiaijRTi(ψi)R˙j(ψj)rj[uj,vj]T−Σj∈NiaijRTi(ψi)Rj(ψj)[u˙j,v˙j]T−Σj∈N¯iaijR˙Ti(ψi)rip˙ijd−Σj∈N¯iaijRTi(ψi)p¨ijd+[0,d¯iv˙j]Tdir∗[u∗,v∗]T+dir∗[u∗,v∗]T+di[u∗d,v∗d]T+d¯ir∗[p∗d,p∗d]T+d¯i[p∗dd,p∗dd]T+[0,d¯iv∗d]T(39)
View Sourcewhere di=∑Mj=1aij . Therefore, ∥σ˙i∥≤σ∗ with σ∗=dmr∗um+dmr∗um+dmudm+d¯mr∗p∗d+d¯mp∗dd+d¯mv∗d . Here dm=max{d1,…,dM} , d¯m=max{d¯1,…,d¯M} , um=max{u∗,v∗} , and udm=max{u∗d,v∗d} .

Lemma 2:
The subsystem (28)–(30), viewed as a system with the states being u~i , r~i , W~iu , W~ir , b~iu , and b~ir , the inputs being ϵiu , ϵir , is input-to-state stable.

Proof:
Construct a Lyapunov function candidate as
V˙i2=12u~2i+12r~2i+[W~iub~iu]TΓiu[W~iub~iu]+[W~irb~ir]TΓir[W~irb~ir](40)
View Sourcewhose time derivative along (28)–(30) is given by
V˙i2=≤−(kiu+κiu)u~2i−(kir+κir)r~2i−ciu[W~iub~iu]T∑k=1N{[ΦkiuTkiu][ΦkiuTkiu]T[W~iub~iu]+[ΦkiuTkiu]ϵiu}−cir[W~irb~ir]T∑k=1N{[ΦkirTkir][ΦkirTkir]T[W~irb~ir]+[ΦkirTkir]ϵir}−(kiu+κiu)u~2i−(kir+κir)r~2i−ciuγ∥W~iu∥2−ciuγ∥b~iu∥2+ℓiu∥W~iu∥|ϵiu|+ℓiu∥b~iu∥|ϵiu|−cirγ∥W~ir∥2−cirγ∥b~ir∥2+ℓir∥W~ir∥|ϵir|+ℓir∥b~ir∥|ϵir|(41)
View Sourcewhere ℓiu=maxk=1,…,N(Φkiu(1),…,Φkiu(N),Tkiu)>0 , ℓir=maxk=1,…,N(Φkir(1),…,Φkir(N),Tkir)>0 .

It can be further derived that
V˙i2≤−ℏi1∥Ei2∥2+ℓi1∥Ei2∥∥ζi∥(42)
View Sourcewhere ℏi1=min(kiu+κiu,kir+κir,ciuγ,cirγ) , Ei2=[u~i,r~i,∥W~iu∥,∥W~ir∥,∥b~iu∥,∥b~ir∥]T , ζi=[ϵiu,ϵir]T , ℓi1=max(ℓiu,ℓir) .

Since
∥Ei2∥≥ℓi1|ϵiu|θ¯i2ℏi1+ℓi1|ϵir|θ¯i2ℏi1≥ℓi1∥ζi∥θ¯i2ℏi1(43)
View Sourcewe have that
V˙i2≤−(1−θ¯i2)ℏi1∥Ei2∥2(44)
View Sourcewhere 0<θ¯i2<1 . It follows that subsystem (28)–(30) is input-to-state stable, and
∥Ei2(t)∥≤λmax(Pio)λmin(Pio)−−−−−−−−√max{∥Ei2(t0)∥e−γi2(t−t0),ℓi1ϵ∗θ¯i2ℏi1}∀t≥t0(45)
View Sourcewhere Pio=diag{1,Γ−1iu,Γ−1ir} and γi2=2ℏi1(1−θ¯i2)/λmax(Pio) .

Lemma 3:
The error subsystem (33), viewed as a system with the states being z¯i , ϖ , ziu , and zir , the inputs being σ~i , u~i , and r~i , is input-to-state stable.

Proof:
Consider the following Lyapunov function
V3=12∑i=1M{z¯Tiz¯i+z2iu+z2ir}+ϖ22λμ.(46)
View Source

Taking the time derivative of (46) with (33) yields
V˙3=∑i=1M{−z¯TiK′iz¯i−κiuz2iu−κirz2ir−kiuziuu~i−kirzirr~i+z¯Tiσ~i}−ϖ2μ(47)
View Sourcewhere K′i=Ki/(∥z¯i∥2+϶2i)1/2 .

Define z¯=[zT1,…,zTM]T , zu=[z1u,…,zMu]T , zr=[z1r,…,zMr]T , E3=[z¯T,zTu,zTr,ϖ]T , ℏ2=mini=1,…,M(λmin(K′i),κiu,κir,1/μ) , and ℓi2=maxi=1,…,M(κiu,κir) . Then one has that
V˙3≤−ℏ2∥E3∥2+∥E3∥∑i=1M(∥Ei1∥+ℓi2∥Ei2∥).(48)
View Source

Since
∥E3∥≥∑Mi=1(∥Ei1∥+ℓi2∥Ei2∥)ℏ2θ¯3(49)
View Sourceone further obtains that
V˙3≤−ℏ2(1−θ¯3)∥E3∥2(50)
View Sourcefrom which one can conclude that subsystem (33) is input-to-state stable, and
∥E3(t)∥≤λmax(Pc)λmin(Pc)−−−−−−−−√max{∥E3(t0)∥e−γi3(t−t0),×∑Mi=1(∥Ei1∥+ℓi2∥Ei2∥)ℏ2θ¯3}∀t≥t0(51)
View Sourcewhere Pc=diag{1,1/λμ} and γi3=2ℏ2(1−θ¯3)/λmax(Pc) .

We are now in a position to state the main result of this article.

Theorem 1:
Consider the ASV kinematics (1) and kinetics (2), together with the distributed kinematic guidance law (14), the path parameter update law (15), the data-driven neural predictor (19), the integral concurrent learning update law (20), and the model-free kinetic control law (52). Under Assumptions 1–3, all signals in the closed-loop system are uniformly ultimately bounded.

Proof:
According to the cascade system stability [67] and using Lemmas 1–3, it can be concluded that the closed-loop system consisting of subsystem (12) subsystem (28)–(30) and subsystem (33) is input-to-state stable. From (38), (45), and (51), ∥E3∥ is ultimately bounded by
∥E3(t)∥≤λmax(Pc)λmin(Pc)−−−−−−−−√∑i=1M{∥PiBi∥σ∗ℏ2θ¯i1θ¯3+ℓi1ℓi2ϵ∗ℏi1ℏ2θ¯i2θ¯3}.
View Source

This proof is complete.

The proposed distributed path-following algorithm is summed up in Table I.

TABLE I Model-Free Distributed Path Following Algorithm

SECTION IV.Simulation Results
In this section, simulation results are provided to illustrate the distributed path-following controllers for multiple under-actuated ASVs being lack of full model information.

Consider a networked system consisting of five ASVs and one parameterized path given as p0(θ)=[0.15θ+2,0.15θ+2]T . The model parameters of the ASVs are set to miu=25.8kg , miv=33.8kg , mir=2.76kg⋅m2 , fiu(⋅)=−5.87u3−1.33|u|u−0.72u+mivvr+1.0948r2 , fiv(⋅)=−36.5|v|v−0.8896v−0.805v|r|−miuur , and fir(⋅)=−0.75|r|r−1.90r+0.08|v|r+(miu−miv)uv−1.0948ur . The initial states of five ASVs are given as p1=[−1,−1]T , p2=[−3,3]T , p3=[3,−3]T , p4=[−7,5]T , and p5=[6,−6]T . The desired formation patterns are set as p1d=[0,0]T , p2d=[−4,2]T , p3d=[2,−4]T , p4d=[−8,4]T , and p5d=[4,−8]T , when t<200 , and p1d=[0,0]T , p2d=[−2,2]T , p3d=[2,−2]T , p4d=[−4,4]T , and p5d=[4,−4]T , when t>200 . The parameters for the distributed path following controllers are Ki=diag{0.1,0.1} , δ0=0.1 , λ=10 , ϵi=0.01 , μ=10 , Γiu=900 , Γir=900 , ciu=0.33 , and cir=0.33 , kiu=2 , kir=2 , κiu=30 , and κir=30 .

The simulation results of the model-free distributed path-following controllers are given in Figs. 3–7. Fig. 3 shows that a time-varying formation is achieved by five ASVs using the proposed distributed controller based on data-driven neural predictors. The formation tracking control errors are depicted in Fig. 4, and it can be observed that the tracking errors are converge to a small neighborhood of zero regardless of unknown input gains, model uncertainties, and environmental disturbances. Fig. 5 depicts the estimation performance of the unknown control input gains by using the proposed data-driven neural predictors. The parameter N in the integral concurrent learning law (20) is set to N=50 , N=100 , and N=200 , which means that mounted data is recorded to update the neural network weights. It can be observed that the unknown input gains can be recovered under different parameters. The converge speed can be faster by recording more data, while the complexity will also increase. At 200 s, the control input gains are changed, and the proposed neural predictors can converge to the new value. Fig. 6 shows the uncertainty estimation performance by using the proposed data-driven neural predictors with different parameters. It can be observed that the estimated uncertainties approach to the real model uncertainties after a short transient process. Fig. 7 depicts the surge force and yaw moment of multiple ASVs, and they are bounded and implementable. To illustrate, the proposed control method based on data-driven neural predictors is compared with a model-based control method. The model-based controller is given as follows:
{τiu=(−kiuuie+udic−fiu)/biuτir=(−kirrie+rdic−fir)/bir.(52)
View Source


Fig. 3.
Formation pattern of five ASVs.

Show All


Fig. 4.
Formation tracking errors.

Show All


Fig. 5.
Estimation performance of the control input gain by using the proposed data-driven neural predictor.

Show All


Fig. 6.
Uncertainty estimation performance by using the proposed data-driven neural predictor.

Show All


Fig. 7.
Surge force and yaw moment of the ASVs.

Show All

Comparison result is shown in Fig. 8. Over the time interval [0, 200], the tracking errors of the two methods are almost the same. However, over the time interval [200, 400], the model-based control method exhibits the poor tracking performance since it is unable to capture the variations of control input gains.


Fig. 8.
Comparisons of the tracking errors using the proposed method and model-based control.

Show All

SECTION V.Conclusion
This article presents a design method for distributed path following of a fleet of under-actuated ASVs with completely unknown kinetic models. At the kinematic level, a robust distributed guidance law is developed for each vehicle based on a consensus approach, a path-following mechanism, and an extended state observer. At the kinetic level, a learning kinetic control law based on a data-driven neural predictor is designed via integral concurrent learning such that model uncertainties and unknown input gains can be accurately learned based on online recorded data. The proposed formation control method is model-free since no parameter information on kinetic model is required. Besides, the velocity information of neighboring vehicles is not required. Simulation results substantiate the effectiveness of the proposed integrated guidance and model-free control method for under-actuated ASVs with completely unknown kinetic models.

Serval avenues are open for further investigations. First, it is desirable to study the distributed path following of multiple ASVs in the presence of measurement noise [68], [69] and sensor faults [70], [71]. Second, it will be interesting to implement the proposed distributed path-following algorithm in a real-world multi-ASV system.