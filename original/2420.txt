Time series classification (TSC) has been addressed and analysed through a wide spectrum of algorithms. Nevertheless, few have considered the notion of spiking or non-spiking neural networks (NNs) and their performance in TSC tasks. Seminal Reservoir Computing (s-RC) with random connected recurrent neural networks is categorized among the fastest and most efficient end-to-end NNs that have been applied to TSC problems. Although the s-RC architecture is absolutely suited for dynamic (temporal) data processing, it fails to achieve significant improvement compared to state-of-the-art fully trainable NNs. Along this thread, the present study proposes a novel algorithm for training the reservoir by fusing nonlinear optimal control theory with reservoir computing (RC) theory, which opens a new approach to optimizing RC predicted values (estimated class) in a specific timestamp along the desired trajectory (true class). For this purpose, TSC tasks were reformulated as a nonlinear optimal control problem, conducive to an approximate solution to a learning rule for the reservoir of spiking or non-spiking neurons, using the adaptive/approximate dynamic programming (ADP) method. The proposed framework that known as Trainable Reservoir Computing (t-RC) involves an online actor–critic method which is used to project the effect of the output error into the reservoir’s parameters adjusting rule so as to ensure the classification error is minimized. To evaluate the TSC adaptability of the newly proposed RC framework and state-of-the-art NN-based methods, varying experiments on 22 univariate and multivariate time series datasets (UCR and UEA datasets) were performed. The findings divulge that the proposed framework outperforms other RC methods in learning capacity and accuracy and attains classification accuracy comparable with the best fully trainable deep neural networks.

Introduction
Time series data (TSD) are a sequence of observations indexed in order of time. TSD have been widely used in various fields such as engineering, economics, neuroinformatics, environment, and medicine and has opened new directions for significant researches conducted with the aim of assigning a label to the TSD. TSC methods can be divided into two main categories: classical methods and deep NN-based methods [1]. The scope of this paper is limited to Reservoir Computing, which can be considered one of the main subcategories of deep NN-based methods.

Classical methods can be aggregated into three subcategories: model-based, distance-based, and feature-based [2]. The key idea of model-based methods is building a model for each class by fitting its parameters to that class like auto-regressive (AR) model which is limited to stationary time series. The distance-based methods rely on developing pre-defined distance functions to measure the similarity between any given two time series for instance as k-Nearest Neighbors (k-NN) [3], dynamic time warping (DTW) [4], and support vector machine (SVM) [5, 6]. The key idea of feature-based methods is extracting a set of meaningful features from the time series patterns such as Bag-of-features framework (TSBF) [7], Bag-of-SFA-Symbols (BOSS) [8], and Learned Shapelets [9]. Typically, classical methods have a major shortcoming that they generally require heavy crafting on data preprocessing, discretization, and manual feature engineering or distance measure. In addition, high computational complexity is another problem that is often seen in classical methods, especially in distance-based methods. Since classical methods are not among the desirable methods considered for investigation in this study, the details of the mentioned methods are referred to existing comprehensive reviews such as [2, 10, 11].

However, due to the current availability of data and the rapid development of neural networks, different kinds of deep neural network models have been employed for TSC tasks. These approaches harness the ability of NNs to learn complex functions in order to automatic feature extraction. Multi-Layer Perceptron (MLP) [12], Multi-scale convolutional neural network (MCNN) [13], Residual Network (ResNet) [14], FCN [15], Recurrent Neural Network (RNN) [16] and Reservoir Computing (RC) [17, 18] are the most successful deep NN-based approaches that have been applied to TSC tasks.

Despite certain achievements, deep NN-based methods are still many shortcomings that have not been addressed. The MLP was proposed as a discriminative classifier; thus, temporal data are missed and the features learned are no longer time-invariant. Among the automatic feature-based approaches using deep NN-based methods, CNN-based methods are the most common and successful, but in the meantime, MCNN uses heavy preprocessing such as down-sampling, skip sampling, sliding window, and a large set of hyper-parameters that make it complicated to deploy. On the contrary, FCN and ResNet do not need heavy preprocessing or feature engineering on TSD.

Above all, the feedforward architectures with non-spiking neurons such as MLP, MCNN, ResNet, and FCN are mainly suited for non-temporal (static) data processing, as individual input data are independently processed even in the case of sequentially fed input. As a result, such models are not fit to embed temporal dependencies within input data. On the other hand, network architectures with recurrently connected spiking or non-spiking neurons such as RNNs are uniquely suited for dynamic (temporal) data processing. One of the faculties provided by these models is the ability to represent temporal dependency of the inputs in terms of their dynamical behavior. However, these types of networks realize a high capacity memory for the input dynamic data processing, particularly for the task of time series classification. Moreover, the training processes of the recurrent weights algorithm, suchlike backpropagation through time (BPTT) [19] or real-time recurrent learning (RTRL) [20] are complex and call for special measures to solve the vanishing and exploding gradient problems, and are difficult to interpret from a biological perspective. Another significant challenge involves the elaborate process of training neural networks with spiking neurons, where adapting backpropagation is not feasible since the spiking neuron’s output is a Dirac delta function.

RCs avoid this problem by means of a random dynamical system as the hidden layer. This layer is left untrained after initialization, subject to asymptotic stability conditions of the corresponding dynamical system. Consequently, the training process is limited to a decoder layer in a supervised fashion. The input sequence in such networks works by exciting the neurons in the reservoir, and the neuron states, in turn, are used as features for any further processing. RC models have been successfully applied to many temporal computational problems, such as temporal pattern classification [17, 21, 22], temporal pattern prediction [23, 24] and temporal pattern generation [25]. However, the seminal RC (s-RC) with a random hidden layer and a shallow trainable neural network usually fails to provide sufficient capacity required by complicated or online tasks. In this regard, [26, 27] proposed certain models to improve the decoding capability by substituting the linear output layer with a nonlinear layer such as SVM and deep NNs as the decoder layer. Despite the use of a nonlinear decoder to improve RCs performance, experiments evidence that this is not a general rule. Nonlinear decoders, as proven in many cases, are not significantly superior to linear decoders, and in certain instances, are in fact inferior to linear decoders. Many observations show that if the reservoir is rich enough to provide a linearly separable representation, then the nonlinear decoder might offer almost no particular advantage and in fact may increase susceptibility to over-fitting. On the contrary, where the reservoir structure and parameters are not chosen properly to provide a suitable representation of input data, a nonlinear decoder with a sufficiently large dataset for training the nonlinear decoder might yield better results. On this basis, it can be inferred that s-RC performance is highly subject to an appropriate initialization of the parameters of the reservoir. Thus, many methods such as experience-based [28], heuristic search [29], and grid search [30] have been proposed to address this issue. Although these methods are useful in practice, they do not guarantee the optimality of the reservoir parameters and are therefore inapt to deal with online problems.

Despite s-RCs sole focus on training the decoder weights and finding an appropriate initial reservoir for an individual task; recent endeavors have found growing interest in tuning the reservoir parameters on unsupervised and supervised modes. A particular case of this involves the application of unsupervised learning in a type of Liquid State Machine (LSM), called NeuCube [18, 31, 32]. For this purpose, Rank Order (RO) [33] and Spike-Timing Dependent Plasticity (STDP) [34] learning rules are applied to organize NeuCube synaptic weights to recognize spatio-temporal patterns. As the findings demonstrated, a reservoir with leaky integrate and fire (LIF) neurons and simple synapses could be trained with an unsupervised learning rule to increase the performance of s-RC in temporal classification and forecasting tasks. The researchers claimed superiority of the NeuCube over traditional machine learning algorithms such as KNN, SVM, and MLP on TSC problems.

In spite of the achievements that NeuCube has had on temporal classification and forecasting, unsupervised learning may not be efficient enough to train a reservoir with a large number of parameters or to be used for complex problems. Thus, few approaches such as Neural Engineering Framework (NEF) [35], FORCE [36], and Feedback-based Online Local Learning Of Weights (FOLLOW) [37] have been proposed to train the reservoir in supervised mode, with successful applications in temporal pattern forecasting and temporal pattern generation. It is however quite rare to find successful implementations of such models for temporal pattern classification tasks.

Despite the theoretical capability of the RCs to process temporal data, numerous RC-based methods still fail to achieve comparable accuracies with state-of-the-art time series classifiers. It seems that one of the shortcomings of the previous RC-based approaches involves an oversighting of the inherent characteristics of dynamical systems found in RCs [38]. To address the aforementioned limitation, the main motivation of this study is to make it possible to use the maximum capacity of RC-based methods in TSC tasks. With this background, the present study introduces a new formulation of the reservoir parameters tuning in the form of a nonlinear dynamical system to overcome this particular shortcoming. Consequently, principles of nonlinear optimal control theory may be applied to derive a learning rule (optimal control law) for the reservoir.

In this study, we aim to further analyze the role of the reservoir’s parameters on TSC tasks by proposing a framework based on nonlinear control theory. For this purpose, a learning rule is considered that minimizes classification error in each timestamp given a RC as a dynamical system, analogous to a tracking problem. From a mathematical perspective, the proposed learning rule is based on the solution of the underlying Hamilton–Jacobi-Bellman (HJB) equation. HJB gives a necessary and sufficient condition for the optimality of a learning rule (control law) with respect to a given loss function. However, that is very difficult or even impossible to solve given the reservoir dynamics. Thus, adaptive dynamic programming (ADP), known as a new formulation of reinforcement learning (RL), was used to obtain solutions for the HJB and achieve a learning rule for the reservoir. It should be noted that the proposed learning rule needs the output errors and the neuron’s state to be observable. These variables are fed back to the reservoir using ADP to estimate the true parameters to minimize the classification (tracking) error. Once the reservoir parameters have been learned (at least approximately), the feedback is set to disable.

Evaluations on 22 different univariate and multivariate UCI and UEA datasets confirm that the proposed framework improves the accuracy of the s-RC and achieves performance rates parallel to state-of-the-art methods such as ResNet and FCN in TSC tasks. The main contributions of this paper are as follows:

Introduction of a new framework obtained via the fusion of nonlinear optimal control theory and reservoir computing, to improve temporal data processing.

Proposition of a new biologically plausible learning method based on reinforcement learning for the reservoir. As far as is known, this is the first time ADP is applied to train a reservoir.

Employment of the proposed framework to early event prediction.

The remainder of this paper is structured as follows. Section 2 briefly describes relevant works in the literature. Section 3 elaborates on the proposed network architecture and learning method in detail. Experiments on 22 benchmark datasets are reported in Sect. 4, and finally, conclusions and future work are presented in Sect. 5.

Background
Since the scope of this paper is focused on using reservoir computing and nonlinear optimal control theory for temporal data processing, the following briefly describes the necessary definitions, theories, and neural network architectures closely linked to the proposed framework.

Time series (Temporal) data classification
Time series classification (TSC) is an important and challenging problem in data mining that is used to gain insight into the mechanisms that generate the time series and can be employed to predict given time series labels. A time series data is a sequential set of data points, measured typically over successive points in time. It is mathematically defined by a triplet (𝑋(𝑡).𝑌(𝑡).𝐹(⋅)), where 𝑋(𝑡)=[𝑥1(𝑡).𝑥2(𝑡).⋯.𝑥𝑚(𝑡)] is a set of variables measured over time 𝑡=1.2.⋯.𝑛; 𝑌(𝑡)=[𝑦1(𝑡).𝑦2(𝑡).⋯.𝑦𝑘(𝑡)] is the set of dependent output variables (labels), and 𝐹(∙) is an unknown association function with respect to the input data𝑋(𝑡), each of which is sampled in a time windowΔ𝑡, with the output variables belonging to 𝑌(𝑡), such that:

𝑌(𝑡)=𝐹(𝑋(Δ𝑡))
(1)
Therefore, in the classification task and for each timestamp (element) in the time series a dataset 𝐷={(𝑋1(𝑡).𝑌1(𝑡)).⋯.(𝑋𝑛(𝑡).𝑌𝑛(𝑡))} could be defined. For a dataset containing 𝑘 classes,𝑌𝑗 is a one-hot vector with length 𝑘, where each element 𝑋𝑖 belonging to class 𝑗∈[0.𝑘] contributes to 𝑗 equal to 1, otherwise 0.

During recent years, a variety of classical machine learning techniques such as k-NN [3], DTW [4], Learned Shapelets [9], and deep NN-based methods such as MLP [12], Residual Network [14], Encoder [15], RNN [16], and RC [17, 18] have been developed for TSC. Many comprehensives overviews of these recent developments on classical and deep methods can be found in [10, 14], and [1]. Further in-depth details about the mentioned methods, however, lie outside the scope of this paper.

Reservoir computing for time series classification
A RC network is a neural information processing system that treats data in a temporal (dynamic) form. Original RC models were proposed independently in the early 2000s in echo state networks (ESN) [39] and liquid state machines (LSM) [40] forms. The two models primarily differ in that ESN uses rate-based neurons such as Sigmoid, Tanh, and Relu. In contrast, LSM uses spike-based neurons like Leaky Integrate-and-Fire (LIF), Hodgkin-Huxley (HH), Izhikevich (IZ), etc. Consequently, LSM makes use of spikes for information transmission between neurons, which is more biologically plausible. As concerning architecture, both RC models are similarly composed of an input layer, a hidden recurrent layer called reservoir that allows RC to capture dynamic information where information fades out over time, and an output layer called decoder or readout, as shown in Fig. 1. The main characteristic of s-RC is that the input weights 𝑊𝐸 and the weights of the recurrent connections within the reservoir 𝑊𝑟 are left untrained and only the decoder weights 𝑊𝐷 are trained with a conventional learning algorithm such as linear regression and gradient descent. Hence, the functionality of a s-RC model for a given input data can be expressed via the following procedures:

Input data are transformed into spatiotemporal patterns in a high-dimensional space by an RNN in the reservoir (encoded into spike trains necessary for LSMs).

Supervised learning is performed in the decoder.

The model is recalled on new data.

Fig. 1
figure 1
A seminal RC (s-RC) system with an RNN-based reservoir as in ESNs and LSMs, where the reservoir weights are random and fixed and only the decoder weights (red arrows) are trained

Full size image
In the last few years, a large body of research has focused on improving the performance of RCs. Some studies such as experience-based [28], heuristic search [29], and grid search [30] have geared towards selecting an appropriate initial reservoir. Other studies suggest the application of deep and multi reservoirs [41, 42]. Another approach seeks to improve decoding capability by replacing the linear output with a nonlinear output layer [26, 27]. Recently, NeuCube [18, 31, 32] has been proposed to capture time and space characteristics of spatiotemporal data in a spiking neural network (SNN) architecture. The structure of the proposed model resembles the structure of a LSM, consisting of an input data encoding layer, that encodes continuous input data into spike trains, a hidden 3D recurrent SNN cube layer called SNNcube, and a SNN classifier layer that learns in a supervised mode to classify spatiotemporal patterns of the SNNcube activities. The important point about the NeuCube is that on the contrary to the s-RC, where the reservoir parameters are set at random and constant, the NeuCube utilizes unsupervised learning to enhance performance. A block diagram of the architecture is provided in Fig. 2. The process of learning and recall in a NeuCube model for a given input data is based on the following steps:

a.
Encoding continuous input values into spike trains and maps in a SNN reservoir.

b.
Unsupervised learning of temporal patterns from data in a SNN reservoir.

c.
Training an evolving SNN decoder in supervised mode.

d.
Model optimization through several iterations of steps a–c above for different parameter values until maximum accuracy is achieved.

e.
Model recall on new data.

Fig. 2
figure 2
A principle diagram of a NeuCube [18]

Full size image
There are various types of the NeuCube including NeuCube(R) [32], Neucube(G) [43], and NeuCube(RT) [44], which have been developed to enhance the performance of the seminal NeuCube. These models apply different methods such as Graph input mapping, Grid search, Genetic Algorithm, Quantum-inspired evolutionary, and Graph Matching to achieve higher performance.

Finally, it is widely accepted that RC-based NN is a powerful method to process temporal (dynamic) data [38], which can theoretically achieve high performance. However, the capacity of this network yet to be used effectively.

Adaptive/approximate dynamic programming
Dynamic systems and temporal data are universal in nature. Therefore, the study of these systems becomes theoretically and practically significant. Over the years, stability and optimal control in these systems have emerged as major research topics in control theory. As a result, solving the Hamilton–Jacobi–Bellman (HJB) equation, which provides the necessary and sufficient conditions for optimality, plays a crucial role in acquiring optimal control. Nevertheless, there is no explicit rule for solving the HJB equation for all systems. In this way, optimal control for a system that is modelled by linear dynamic and with consideration of a quadratic cost function to be minimized is acquired through linear feedback. Thus, the equivalent of this HJB is the well-known standard Riccati equation. However, for the system that is modelled by nonlinear dynamics, the resulting HJB equation is a nonlinear partial differential equation (PDE), the solution to which is generally difficult or impossible to obtain [45]. Given that almost all systems including RCs are nonlinear, thus solving the HJB for nonlinear systems is a vital issue.

ADP is a novel approximate optimal control scheme, which has recently become a hot topic in the field of optimal control. This approach aims to approximate the value of states, control policy, and obtain nearly optimal solutions for HJB equations with large state spaces. The basic architecture of ADP is mainly composed of the critic and actor networks. The two networks are parameterized, where the weights need to be trained in either an online or offline manner. The critic NN is utilized to evaluate the current action based on the value function that provides direction for action improvement. The actor NN is used to implement the control action. In other words, the critic NN acts as a function to approximate the cost function, while the actor NN is used to achieve an approximation of the optimal control policy.

In the past few years, numerous investigations have been conducted into the theoretical and practical development of ADP. Several of these cases have achieved significant performance on different optimal control problems, especially nonlinear systems. For instance, Werbos [46] developed actor-critic techniques for feedback control of discrete-time dynamical systems that learn optimal policies online in real-time using data measured along the system trajectories. Vamvoudakis and Lewis [47] have also used an online AC strategy to solve the infinite horizon optimal control problem for nonlinear systems. The authors proposed an online adaptive algorithm that involves simultaneous tuning of both actor and critic neural networks. Kiumarsi and Lewis proposed [48], an Actor-Critic (AC) NNs based algorithm to solve the optimal tracking of partially unknown discrete nonlinear systems. [49] presented an ADP method for linear systems with unknown dynamics. An online approach to solving infinite-horizon tracking continuous-time nonlinear systems was proposed by Kamalapurkar et al. [50]. Zhao developed an optimal tracking control for uncertain continuous-time nonlinear partially unknown systems [51]. Recently, a considerable number of researches, such as the Advanced Actor-Critic algorithm [52], deploy a series of advanced methods including deep neural networks, information entropy, and self-confidence-based exploration to improve the accuracy of the conventional Actor-Critic method in more complex tasks.

Proposed framework
The proposed approach in this study proceeds to classify temporal data based on a combination of Reservoir Computing and Nonlinear optimal control theory. The overall schema of the proposed approach is shown in Fig. 3.

Fig. 3
figure 3
A schematic of the proposed architecture (plastic weights in red). a The feedforward pathway consists of an encoding layer with fix and random parameters, a reservoir with trainable parameter and a decoder layer, which is trained in the pre-training process and stay constant during the reservoir training process. b In the feedback pathway, the nonlinear optimal control is applied for estimating reservoir parameters. It consists of actor and critic neural networks. c The bottom subplot shows the reference trajectories (true classes), and the top subplot shows the learned trajectories (predicted classes) (color figure online)

Full size image
In the proposed framework, TSC is reformulated as an optimal tracking problem. For this purpose, the one-hot output vector representing the true class of each time series pattern is imitated, similar to the length of each time series pattern, and is considered the reference trajectory as illustrated in Fig. 3 (C) bottom subplot. The reservoir is a special class of high-dimensional nonlinear dynamic systems, where both state and time are continuous. Therefore, the continuous-time formulation of HJB equation and ADP can be applied to derive the learning rule (optimal control law). The derived learning rule forces the proposed framework's output (predicted class) to mimic the reference trajectory (true class). The following subsections elaborate on the network architecture, and the learning rule in further detail.

Network architecture and dynamics
The proposed framework consists of a feedforward and a feedback pathway. The main parts of the feedforward module are:

Input data encoding layer.

Reservoir (recurrent neural network).

Linear classifier (output function).

The feedback module is composed of:

Critic neural network.

Actor neural network.

Figure 3 shows the block diagram of the proposed framework architecture. The significant point about the proposed framework is that on the contrary to the s-RC, where the reservoir parameters are set at fixed and random, the Trainable Reservoir Computing (t-RC) utilizes trainable parameters to improve performance. In addition, contrary to the NeuCube that the reservoir learning mechanism is in the unsupervised fashion the t-RC uses an effective supervised learning mechanism. The functionality of the proposed architecture is based on the following steps:

a.
The encoding layer projects input patterns 𝑥(𝑡) into the reservoir. In spiking neural networks, each real-value of a data vector is converted into discrete spike trains, suitable for processing in the spike reservoir as spike neural networks can only process discrete spike trains.

b.
In the pre-training (Mandatory) and post-training (Optional) processes, a supervised learning algorithm like Gradient descent, etc., is employed to adjust the decoder parameters associated with each training sample. Once the decoder is trained, it is considered constant during the reservoir training process.

c.
In the reservoir training process. An RL-based algorithm proposed in subsection 3.2 is applied to make the reservoir learn temporal relations between the input patterns 𝑥(𝑡) and desired output 𝑦(𝑡) by adjusting the parameters in the reservoir using ADP. In the ADP mechanism, two neural networks called actor and critic are utilized to approximate true reservoir parameters.

d.
Model recall on new data.

The feedforward pathway resembles the structure of LSM and ESN; however, the methodology of the particular feedback pathway proposed in this study differs significantly from classical artificial intelligence approaches.

Remark 1
For the sake of brevity, time dependence is suppressed while denoting variables of dynamical systems. For instance, the notations 𝑥(𝑡),𝑦(𝑡),𝑢(𝑡), 𝑣(𝑡) and 𝑒(𝑡) are rewritten as 𝑥, 𝑦,𝑢, 𝑣 and 𝑒. Moreover, all math symbols used in this study are listed in Table 1.

Table 1 The math symbols used in this paper and corresponding meanings
Full size table
As illustrated in Fig. 3, the central element of the proposed framework is a reservoir, i.e., a recurrent network with a structure denoted by the adjacency matrix 𝑊𝑟∈ℝ𝑛𝑟×𝑛𝑟. Here, the reservoir consists of 𝑛𝑟 neurons, for which the membrane potential dynamics are described as:

𝜐˙𝑖=𝜓(𝑣𝑖)+I𝑖
(2)
𝐼𝑖=𝑊𝐸𝑖∅(𝑞𝐸)+𝑊𝑟𝑖∅(𝑞𝑟)
(3)
where 𝜐=[𝜐1.⋯.𝜐𝑛𝑟]∈ℝ𝑛𝑟 is the state or membrane potential of the reservoir neurons,∅(∙) is a Lipschitz nonlinear dendrite such as 𝑆𝑖𝑔𝑚𝑜𝑖𝑑(∙).𝑇𝑎𝑛ℎ(∙), ψ(𝜐):ℝ𝑛𝑟→ℝ𝑛𝑟 is a Lipschitz leak-term function. 𝑞𝐸,𝑞𝑟 in non-spiking neurons are equal to input and reservoir state respectively, but in spiking neurons qi shows the filtered spike activity of neuron 𝑖. 𝑆𝑖(𝑡) is the spike train of the neuron 𝑖:

𝑞𝑖=(𝑆𝑖∗𝜅)(𝑡)=∫𝑡−∞𝑆𝑖(𝑠)𝜅(𝑡−𝑠)𝑑𝑠
(4)
𝜅(𝑡)=exp(−𝑡/𝜏)/𝜏
(5)
Moreover, a linear decoder is assumed as:

𝑦̂ =ℎ(𝑣)=𝑊𝐷𝑣
(6)
Learning rule
Equation (1) shows that the reservoir has characteristics of a dynamical system. Consequently, principles of optimal control theory can be applied to derive a learning rule (optimal control law). For this purpose, it is necessary to reformulate the time series classification as a control problem. Thus, the output error was considered as follows:

𝑒=𝑦̂ −𝑦∈ℝ𝑐
(7)
where 𝑐 is a number of classes, 𝑦∈ℝ𝑐 denotes the desired output for the input pattern at time 𝑡, and 𝑦ˆ∈ℝ𝑐 is the corresponding predicted output. By derivation of Eq. (6) with respect to 𝑡, the error dynamics can be described as:

𝑒˙=𝑦̂ ˙−𝑦˙∈ℝ𝑐
(8)
Given that the decoder weights 𝑊𝐷 are assumed constant during the reservoir training process, the classification error dynamics only depend on the reservoir dynamics. Rewriting the neural Eqs. (1) and (2) in the form, Eq. (7) gives:

𝑒˙=𝑊𝐷𝑣˙=𝑊𝐷(𝜓(𝑣)+𝑊𝐸∅(𝑞𝐸)+𝑊𝑟∅(𝑞𝑟))
(9)
The control input is then considered as a parameter of the reservoir:

𝑢=𝑣𝑒𝑐(𝑊𝑟)∈ℝ𝑁𝑟=𝑛𝑟×𝑛𝑟
(10)
in which 𝑁𝑟 is the number of reservoir parameters and 𝑣𝑒𝑐(∙) is vectored form of a matrix, concluding:

𝑓(𝑣)=ψ(𝑣)+𝑊𝐸∅(𝑞𝐸)
(11)
Thus, the following nonlinear continuous-time equation can be considered as the system dynamics of the control theory:

𝑒˙=𝑊𝐷𝑣˙=𝑊𝐷(𝑓(𝑣)+𝑔(𝑣)𝑢)
(12)
wherein 𝑓(𝑣):ℝ𝑛𝑟→ℝ𝑛𝑟 is the drift dynamic of the system, and 𝑔(𝑣):ℝ𝑛𝑟→ℝ𝑛𝑟×𝑁𝑟 is the input dynamic of the system. A common and recommended action in this regard is to add noise into 𝑢 and 𝑔(𝜐) to realize the Persistence of Excitation (PE) condition [47] for the sake of collecting more system state data and making 𝑔(𝜐) full rank.

For the TSC problem, the goal of learning is to adapt the reservoir’s parameters 𝑊𝑟 such that the error in each timestamp of the input pattern is minimized and the reservoir’s parameters or control input remains bounded. Thus, the following cost function was defined:

min𝑢(⋅)∈𝑈ℑ(𝑢(⋅)⋅𝑒(⋅))=∫𝑡𝑓𝑡ℓ(𝑒(𝜏)⋅𝑢(𝜏))𝑑𝜏
(13)
ℓ(𝑒.𝑢)=𝜂𝑒𝑇𝑒+𝑢𝑇𝑢
(14)
where l(∙.∙) is the utility function,𝑡𝑓 is the last element of input patterns, 𝜂 is a constant positive hyper-parameter for ensuring that the error in cost function is sufficiently effective. Hence, the optimal value function can be written:

𝑉(𝑣)=𝐼𝑛𝑓𝑢(⋅)∈𝑈ℑ(𝑢⋅𝑒)
(15)
Under typical assumptions, 𝑓(0)=0 and 𝑓(𝑣)+𝑔(𝑣)𝑢 is a continuous Lipschitz on a set of Ω𝜖ℝ𝑛. Ultimately, it is desirable to achieve an optimal input control (weight update law) 𝑢∗ that stabilizes the system Eq. (11) and minimizes the cost function Eq. (14). This type of control input is known as an admissible control [53].

Now, the learning rule has been formulated given the error dynamic in Eq. (11) and the cost function Eq. (14). To solve this dynamic optimization problem, the HJB equation is utilized, so the Hamiltonian of the cost function Eq. (14) associated with control input 𝑢 is defined as:

(𝑒.𝑢.𝑉𝑣)=ℓ(𝑒.𝑢)+𝑉𝑇𝜐(𝜐˙)
(16)
where 𝑉𝑣=∂𝑉/∂𝑣 is the partial derivative of the cost function, for admissible control policy 𝜇 we have:

(𝑒.𝜇.𝑉𝑣)=0
(17)
The present study assumed that the solution to Eq. (16) is smooth giving the optimal cost function:

𝑉∗(𝑣)=min𝑢(∫𝑡𝑡𝑓ℓ(𝑢(𝜏).𝑒(𝜏))𝑑𝜏)
(18)
which satisfies the HJB equation

min𝑢(𝑒.𝑢.𝑉∗𝑣)=0
(19)
The optimal reservoir weights update (optimal control) can be obtained by solving a differentiated Hamiltonian with respect to 𝑢 and setting the derivative to zero as:

𝑢∗(𝑣)=−12𝑔𝑇(𝑣)𝑉∗𝜐
(20)
The optimal value function can be obtained as:

𝑉∗(𝑣)=min𝑢(∫𝑡𝑓𝑡𝜂𝑒𝑇𝑒+𝑢∗𝑇𝑢∗𝑑𝜏)
(21)
Inserting this optimal learning rule Eq. (19) into nonlinear Lyapunov equation Eq. (15) gives the formulation of the HJB equation Eq. (18) in terms of 𝑉∗𝜐

0=𝜂𝑒𝑇𝑒+𝑉∗𝑇𝑣(𝑣)𝑓(𝑣)−14𝑉∗𝑇𝑣(𝑣)𝑔(𝑣)𝑔𝑇(𝑣)𝑉∗𝑣(𝑣)
(22)
Finding the learning rule for the reservoir requires solving the HJB equation for the value function and then substituting the solution to obtain the desired learning rule. Although HJB gives the necessary and sufficient condition for optimality of a learning rule (control law) with respect to a loss function; Unfortunately, due to the nonlinear characteristics of the reservoir, solving the HJB equation in explicit form is difficult or even impossible to derive for systems of interest in practice. Thus, the proposed framework focuses on the ADP method to approximate its solution.

Therefore, an online actor–critic algorithm proposed by [47] was utilized to approximate the optimal reservoir weight update (optimal control). As evident in Fig. 3, the proposed method consists of two neural networks called critic NN and action NN. In the mentioned model, the objective of tuning the critic weights is to minimize the Bellman equation error and the objective of adjusting the actor weights is to minimize the approximate value. The weight updating laws of the critic NN and the action NN are given by Eqs. (22) and (23), respectively.

𝑊̂ ˙1=−𝛼1𝜎1(𝜎𝑇1𝜎1+1)2(𝜎𝑇1𝑊̂ 1+𝜂𝑒𝑇𝑒+𝑢𝑇2𝑢2)
(23)
where 𝛼1>0 is the learning rate,𝜎1=𝜙1𝑣(𝑓+𝑔𝑢2), ∅1 is the activation function, and ∅1𝑣=∅1/∂𝑣,.

The actor NN weights may be tuned as:

𝑊̂ ˙2=−𝛼2{(𝐹2𝑊̂ 2−𝐹1𝜎⎯⎯⎯𝑇1𝑊̂ 1)−14𝐷⎯⎯⎯⎯⎯1(𝑣)𝑊̂ 2𝑚𝑇(𝑣)𝑊̂ 1}𝑤ℎ𝑒𝑟𝑒𝑚𝑠=𝜎𝑇1𝜎1+1𝜎⎯⎯⎯1=𝜎1𝑚𝑠𝐷⎯⎯⎯⎯⎯1(𝑣)≡𝜙1𝑣(𝑣)𝑔(𝑣)𝑔𝑇(𝑣)𝜙𝑇1𝑣(𝑣)𝑚≡𝜎1𝑚2𝑠
(24)
and 𝛼2>0 is the learning rate and 𝐹1.𝐹2>0 representing the tuning parameters. For brevity of this article, the reader is referred to the reference article. Finally, with respect to [47], the reservoir parameters update rule can be derived as follows:

𝑣𝑒𝑐(𝑊̂ 𝑟)=𝑢2(𝜐)=−12𝑔𝑇(𝑣)𝜙𝑇1𝑣𝑊̂ 2
(25)
This completes the reservoir learning rule.

During the reservoir learning, the feedback pathway via actor-critic NNs forces the output of the network (estimated class) to follow the reference trajectory (true class), an effect that is widely used in control theory. After a sufficiently long learning time, the feedforward pathway without feedback can classify input patterns with an acceptable accuracy.

Results and discussion
This section provides the description of datasets, a short definition of baseline deep learning models, and experimental results of the proposed framework on TSC problems.

Datasets
To evaluate the performance of the proposed method, experiments were performed on the UCR/UEA time series classification archive [54]. The UCR/UEA archive contains more than 97 publicly available time series datasets that vary by the number of classes, number of variables, dataset types, number of samples, length of each sample, size of training, and test data. Each dataset was split into training and testing sets. A total of 22 datasets were selected with different characteristics for experimental purposes. Details of the datasets are described in Table 2.

Table 2 Properties of UCR/UEA datasets from [54]
Full size table
Details on benchmarks
The following approaches were selected from a large body of proposed methods to be compared with the proposed framework. These include end-to-end methods which require no handcrafted features based on neural networks with state-of-the-art results on at least one of the benchmark datasets [1, 14] include:

Multi-layer perceptron (MLP) [12]
MLP is plain baseline architecture for TSC which consists of 4 layers in total where each one is fully connected to the output of its previous layer. The final layer is a softmax classifier, which is fully connected to its previous layer’s output and contains a number of neurons equal to the number of classes in a dataset. All hidden layers are composed of 500 neurons with ReLU as the activation function. Each layer is preceded by a dropout operation with a rate equal to 0.1, 0.2, 0.2, and 0.3 for, respectively, the first to fourth layer. The MLP was trained with 6000 epochs and the batch size is equal to 16.

Convolutional neural network (CNN)
The network is composed of two convolution blocks with sigmoid activation function and average pooling. The convolution contains 6 and 12 filters with the same filter length equal to 7. Finally, we flatten the output of the second convolutional layer to an output layer with sigmoid neurons. It was trained with 2000 epochs, and the batch size is equal to 16.

Fully convolutional neural network (FCN) [14]
The network is built by stacking three convolutional blocks where each block contains three operations: a convolution followed by a batch normalization whose result is fed to a ReLU activation function. The output of the third convolutional block is averaged over the whole time dimension which corresponds to the GAP layer. Finally, a traditional softmax classifier is fully connected to the GAP layer’s output. Each convolutional blocks consists {128, 256, 128} filters and filters length is equal to {8, 5, 3} respectively. The network was trained with 3000 epochs and the batch size is equal to 16.

Multi-scale convolutional neural network (MCNN) [13]
MCNN’s architecture is composed of two convolutions blocks followed by a fully connected layer, and a softmax layer. MCNN uses identity mapping, down-sampling, skip sampling and window sliding (WS) to preprocess the data. Each convolution blocks use 256 filters with the sigmoid activation function and followed by a max-pooling operation. The network was trained with 250 epochs.

Time convolutional neural network [55]
The network is composed of two consecutive convolutional layers with, respectively, 6 and 12 filters followed by a local average pooling operation of length 3. The convolutions adopt the sigmoid as the activation function. Finally, a fully connected layer whose number of neurons is equal to the number of classes in a dataset is used as the output layer. It was trained with 2000 epochs and the batch size is equal to 16.

Time Le-Net (t-LeNet) [56]
t-LeNet is made of two convolutions layers, each followed by a sub-sampling step performed through max-pooling followed by fully connected layers and a final softmax classifier enable to match extracted features with class labels to be predicted. The first convolution contains five filters of temporal span equal to five, followed by a max-pooling of size 2. Then, a second convolution layer is made of 20 filters with the same time span as the previous ones and a final max pooling of size 4 is used. For both convolutions, the ReLU activation function is used. It was trained with 1500 epochs and the batch size is equal to 256.

Residual network (ResNet) [14]
The network is built by stacking three residual blocks followed by a GAP (Globally Average Polling) layer and a final softmax classifier with a number of neurons that are equal to the number of classes in the dataset. Each residual block is composed of three FCN convolutional blocks with 64 filters for all convolutions whose output is added to the residual block’s input and then fed to the next block.

Seminal reservoir computing (s-RC)
As shown in Fig. 1, the s-RC is made of a fixed and random recurrent network as the reservoir and a linear decoder. The reservoir is composed of 1000 smooth LIF neurons with 𝑇𝑎𝑛ℎ synapses and 70 percent connectivity.

NeuCube
The network architecture is described in subsection 2.2. In this study, a Cube with 1000 LIF neurons and a deSNN network with a weighted k Nearest Neighbors (wkNN) classifier is considered as the decoder.

t-RC (proposed framework)
The network architecture consists of a recurrent network as the reservoir and a linear decoder, where the reservoir parameters are trained with the proposed learning rule described in subsection 3.2. The reservoir was composed of 650 smooth LIF neurons with 𝑇𝑎𝑛ℎ synapses and 70 percent connectivity initializations then the reservoir was trained with 10 epochs, which was implemented on the NengoDL simulator that is based on Tensorflow software library [57]. Due to the limited number of training samples on benchmark datasets and the computational resources, training of the entire reservoir parameters is difficult. Thus, the training process was tailored to 𝑂(𝑛) parameters considering the characteristics of the datasets, and the remaining parameters were assumed fixed and random. It should be mentioned, the proposed learning rule consists of five hyper-parameters that must be chosen to make the following matrix positive definite and consequently make the derivative of the Lyapunov function negative for each tasks. For a complete exposition, the reader is referred to [47].

⎡⎣⎢⎢⎢⎢𝜂𝐼000𝐼−12𝐹1−(18𝑚𝑠𝐷⎯⎯⎯⎯⎯1𝑊1)0(−12𝐹1−(18𝑚𝑠𝐷⎯⎯⎯⎯⎯1𝑊1))𝑇𝐹2−18(𝐷⎯⎯⎯⎯⎯1𝑊1𝑚+𝑚𝑊𝑇1𝐷⎯⎯⎯⎯⎯1)⎤⎦⎥⎥⎥⎥
(26)
where 𝐼 is identity matrix with appropriate size. For instance, 𝐹1=1.𝐹2=100.𝜂=105.𝛼1=10−3.𝛼2=10−4 with Adam learning rate optimizer is a proper setting, which can stabilize the model, i.e. that the error decreases to a bounded compact region in experiments. Surely, in order to find appropriate accuracy, it is necessary to experimentally examine different valid values of the hyper-parameters for different tasks.

All simulations and experiments were executed on an Intel Core i7-6700 K, 3.40-GHz CPU, 16-GB RAM and a GeForce GTX 1650-O4GD6 GPU.

Performance on benchmark datasets
The proposed experiments contemplated different characteristics of the proposed framework, such as training property, early event prediction, and classification performance on the benchmark datasets.

At first glance, it is recognized that the proposed learning method is slightly different from conventional learning methods. In this algorithm, due to the error feedback, the predicted class is constrained to closely follow the true class in each timestamp after observing sufficient quantities of input patterns throughout the learning process. This behavior is illustrated in Fig. 4 for the CBF dataset. Consequently, as can be seen in Fig. 5, the classification error on nearly all training epochs is close to zero.

Fig. 4
figure 4
Convergence of estimated output to desired output on the part of 10 training iteration of the CBF dataset. See Remark 2 for further details about the figure

Full size image
Fig. 5
figure 5
Training classification error of the simulation Fig. 4 (color figure online)

Full size image
Remark 2
Figures 4, 6, and 7 are composed of three subfigures. The bottom subfigure (input signal subfigure) represents the input patterns through time. The middle subfigure (true class subfigure) shows the probability of true classes. Since each input pattern is assigned to a class, only the probability of one class is equal to 1 and the others are equal to 0. In addition, these values are repeatedly used for each pattern during its mapping to the reservoir, i.e. words equal to pattern length. The top subfigure (predicted class subfigure) depicts the decoded activity of neurons of the reservoir, which are cast to probability-like values. Generally, the beginning and the end of each input pattern and class are separated by purple vertical dash lines, and each class is marked with a unique color.

Fig. 6
figure 6
Evaluation of the proposed framework on the CBF data set during the test process. The pink dot boxes correspond to the learned explicit discriminative region. See Remark 2 for further details about the figure

Full size image
Fig. 7
figure 7
Evaluation of the proposed framework on the Wafer data set during the test process. There is no explicit discriminative region. See Remark 2 for further details about the figure

Full size image
Further experiments were conducted to evaluate the proposed framework on the benchmark test sets. Figures 6 and 7 clearly show how the proposed framework is taking the classification decision in each observed timestamp on different datasets. As can be observed in Fig. 7, there is a sequence of events at just the beginning of the input patterns, identified as a discriminative area by the proposed framework (depicted by the pink dot boxes in different input samples). The results indicate that the proposed framework is able to find and use the existing discriminative regions to classify input patterns with high accuracy.

Despite that, observations on other datasets fail to confirm the existence of explicit discriminative regions in all tasks. Nevertheless, the proposed framework can classify input patterns by observing the appropriate amount of input data, which is evidence for the proposed framework’s capability of using long-term temporal dependency to classify input patterns with acceptable accuracy. Figure 7 shows an experimental result on the Wafer dataset with no explicit discriminative area.

Another interesting deduction that can be made is that in contrast to the majority of models that are restricted to process static vectors, the proposed framework can process temporal data in time. Therefore, it is quite possible that the proposed framework can classify the input data by observing limited information. Figures 6 and 7 show that the proposed framework presumably has early event prediction capability, albeit early event prediction is not the primary goal of this study. Given the fact that the ability to forecast event occurrences at future time points with only limited available information is an important problem in many applications such as natural disaster warning, weather, medicine forecasting, financial crisis, and criminal investigations, the proposed model was also evaluated through an analysis of classification accuracy in cases where the model only observed 30, 50, 70, 90, and 100 percent of the input pattern. The results of the early event prediction on benchmark datasets by the proposed framework are presented in Table 3. According to these results, the average ratio of early event prediction's accuracy to the classification's accuracy when the entire input pattern was observed for all the evaluated datasets is higher than the expected linear relationship. For instance, this ratio, for 30, 50, 70, and 90 percent of input patterns observed, was equal to 62.51, 75.91, 85.24, and 94.83 percent, respectively. The results confirm that the proposed framework with only limited available information can classify input patterns; a capability that is available in only few models.

Table 3 Comparative analysis on UCR/UEA classification early event prediction accuracy
Full size table
Performance comparison with deep learning baselines
In this experiment, the mean and standard deviation of classification accuracy of the proposed framework and baseline methods are compared and depicted in Fig. 8. To be thorough, the results of the evaluation on the benchmark datasets are summarized in Table 4. According to Fig. 8, the accuracy of the proposed framework is significantly higher than other reservoir-based methods, specifically s-RC and NeuCube. Therefore, it can be deduced that the proposed learning rule for tuning reservoir parameters could be effective in improving RCs performance in TSC problems, which is the main objective of this study. Additionally, t-RC consistently outperforms most deep learning models but in the case of FCN and ResNet has comparable performance. Some evidence reveal that dataset characteristics may be effective in reducing the proposed framework's performance compared to other models. As shown in Table 4, the proposed framework has better performance on the datasets with meaningful temporal relationships between states, such as Earthquakes, ECG200, and Lightning2. On the contrary, it has poor performance on datasets with meaningless temporal relationships between states, for instance, Adiac, ArrowHead, etc. The principal cause of this observation can be investigated in terms of differences between the learning method used in the traditional methods and the proposed framework. The conventional learning methods are designed to process static vector data; thus, non-temporal features are used for TSC problems as well, as is common in image classification. Consequently, the existence or the lack of temporal relationships does not significantly affect their performance. Counter-wise, the proposed framework with the new learning method derived from nonlinear optimal control would enable a better ability to represent temporally correlated and varied data, as the connectivity of a trained reservoir would reflect on the temporal relationship in the dynamic data. As a result, the absence of a meaningful temporal relationship can be effective in reducing its performance.

Fig. 8
figure 8
Comparison of the average accuracy results obtained from all benchmark models on benchmark data sets

Full size image
Table 4 Results on UCR/UEA classification
Full size table
Results on the effect of the number of reservoir neurons
Here, the effect of the number of reservoir neurons on the accuracy of the proposed framework and s-RC is investigated. The results, in terms of classification accuracy and the number of neurons, are shown in Fig. 9. According to this figure, there is a direct relationship between the number of reservoir neurons and accuracy. For the majority of evaluated benchmark datasets, the accuracy steadily increases until the number of neurons reaches 450, after which two major trends can be observed. In some datasets, the accuracy remains incremental such as for the ECG dataset in Fig. 9, while for some other datasets like CBF, the changes are insignificant. Therefore, it can be deduced that the accuracy of t-RC can be improved by increasing the number of reservoir neurons. However, when the number of neurons transgresses beyond a specific value, the improvements become insignificant. Our findings suggest that for certain datasets, a series of characteristics such as train size and input pattern length are the most important determinants of the appropriate number of neurons in the reservoir. Such deduction can be extended for s-RC for some datasets like CBF and ECG200 in Fig. 9, but in several datasets such as ECG, increasing the number of neurons merely leads to fluctuations in model accuracy. For a few number of datasets such as Wafer, an insignificant improvement in accuracy is observed.

Fig. 9
figure 9
The accuracy vs. number of neurons in s-RC and t-RC (proposed framework). The t-RC in green, s-RC with 90% connectivity in red, and s-RC with 70% connectivity in blue

Full size image
Results on the effect of deep decoder
Although a linear decoder is assumed in the proposed framework; nevertheless, the present study proceeded to empirically investigate how a t-RC implemented by a nonlinear decoder influences classification accuracy. Three MLP architectures including one to three hidden fully connected layers were used as nonlinear decoders. These three MLP architectures were examined twice using 50 and 100 neurons in each fully connected layer on the benchmark datasets. Finally, the difference between the best result of the six aforementioned nonlinear decoders and the linear decoder on benchmark datasets is sketched in Fig. 10. As can be seen in this figure, there is a negative relationship between the number of reservoir neurons and improvement in nonlinear decoder accuracy. This means that as the number of neurons increases, the effectiveness of the nonlinear decoder in improving accuracy decreases. As shown in Fig. 10, the nonlinear decoder improvement for the reservoir with 50 neurons is much higher than the reservoirs with 350 and 650 neurons. The results on benchmark datasets show that the nonlinear decoder is more effective on Adiac, ArrowHead, Car, FaceAll, FaceFour, NetFlow, and some other remaining datasets. This in all likelihood is interpreted in terms of the size of the training set and the richness of the reservoir. Where the proposed framework collapses to provide a linear separable representation, using the nonlinear decoders with a large enough training set might yield better results. For other datasets, the results slightly improve as the decoder is altered.

Fig. 10
figure 10
Box plot of the difference between the best accuracy obtained from t-RC (proposed framework) with the six nonlinear decoders and the linear decoder on benchmark datasets listed in Table 1. Bars indicate standard deviation

Full size image
Conclusion and future work
The present study proposed a framework for dynamic (temporal) data processing which exploits the merits of reservoir computing and nonlinear optimal control theory. For this purpose, the typical classification problem was reformulated as an optimal tracking control problem and solved using ADP to obtain the reservoir’s learning rule. The obtained learning rule is a RL-based algorithm that forces the system’s output (predicted class) to follow the reference trajectory (true class) closely. Moreover, this framework provides a systematic way to study the convergence and stability properties of the learning rule. The learning rule is provenly stable, with errors converging to zero under a few reasonable assumptions. The resulting framework exhibits important characteristics such as discriminative property, generative property, fading memory, high-dimensionality, nonlinearity, input history-dependent response. To examine the effect of mentioned characteristics in TSC problems, the proposed framework was evaluated on different conditions for several real-world data sets. Although the performance was not ideal, the results show that RC equipped with the proposed learning rule presents far better accuracy than other RC-based models and achieves comparable accuracy with state-of-the-art time series classifiers such as FCN and ResNet. These results empirically prove the effectiveness of the proposed model.

The absence of a generic and rich structure for critic and actor NNs to satisfy the Weierstrass higher-order condition; and high memory consumption are two shortcomings of the intended framework that can deteriorate the accuracy and computational complexity. For prospective studies, we plan to overcome these deficiencies with the help of reservoir computing and reformulation of the feedback pathway, respectively.

Finally, it should be noted that the proposed framework with the new learning method would enable an appropriate ability to model dynamical systems and temporally correlated data, as the connectivity of a trained reservoir would reflect the temporal relationship in the dynamic data. However, the present study mainly focused on the discriminative characteristic of the proposed framework; hence, experiments were confined to TSC problems. Nevertheless, the proposed framework can indubitably be extended to deal with different online and offline engineering applications. Since the proposed ADP-based learning rule is derived from nonlinear control theory, it would have a more significant improvement on generative and nonlinearity properties than the discriminative property. Due to this issue, the proposed framework is believed to be more effective on time series prediction, pattern generation, nonlinear control applications where the output needs to adapt to unknown dynamics beyond the TSC problem. Hence, future studies are encouraged to address these issues by optimizing the proposed framework and experiments for these problems.