Many modern techniques for analyzing time-varying longitudinal data rely on parametric models to interrogate the time-courses of univariate or multivariate processes. Typical analytic objectives include utilizing retrospective observations to model current trends, predict prospective trajectories, derive categorical traits, or characterize various relations. Among the many mathematical, statistical, and computational strategies for analyzing longitudinal data, tensor-based linear modeling offers a unique algebraic approach that encodes different characterizations of the observed measurements in terms of state indices. This paper introduces a new method of representing, modeling, and analyzing repeated-measurement longitudinal data using a generalization of event order from the positive reals to the complex plane. Using complex time (kime), we transform classical time-varying signals as 2D manifolds called kimesurfaces. This kime characterization extends the classical protocols for analyzing time-series data and offers unique opportunities to design novel inference, prediction, classification, and regression techniques based on the corresponding kimesurface manifolds. We define complex time and illustrate alternative time-series to kimesurface transformations. Using the Laplace transform and its inverse, we demonstrate the bijective mapping between time-series and kimesurfaces. A proposed general tensor regression based linear model is validated using functional Magnetic Resonance Imaging data. This kimesurface representation method can be used with a wide range of machine learning algorithms, artificial intelligence tools, analytical approaches, and inferential techniques to interrogate multivariate, complex-domain, and complex-range longitudinal processes.

Introduction
Contemporary scientific studies rely on large volumes of multi-source, heterogeneous, and incomplete data anchored at specific spatiotemporal locations. Many state-of-the-art methods for handling time-varying longitudinal data involve parametric models that enable investigation of retrospective, current, and prospective process characterizations. Participant outcomes, experimental conditions (e.g., treatments or exposures), cross-sectional characteristics, and other information is often tracked at multiple points in time. Common strategies for analyzing repeated longitudinal measurements include mixed linear modeling, time-series analysis, growth and decay modeling, forecasting or prospective outcomes, prognostication, causality, survival analysis, and time-to-event inference [1,2,3,4,5].

To account for low signal-to-noise ratio, many study-designs employ repeated data acquisition at controlled experimental conditions. For each unit in the experiment, this leads to assembling multiple samples representing scalar, vector, matrix, or tensor data. In the simplest case, univariate data is collected for a longitudinal process and the goal is to predict the prospective behavior of the process using the observed retrospective (training) data. In more pragmatic settings, the data are represented as a (time) dynamic multi-dimensional array generalizing the classical samples×variables matrix format. In this paper, we build on the notion of complex time (kime) [6] to generalize the classical temporal time-series representation of repeated longitudinal data. Specifically, we model the observed repeated-measurement longitudinal data as 2D kime surfaces. The structure (e.g., geometry and topology) of these higher dimensional manifolds carries more information compared to the original time-series corresponding to cross-sectional kimesurface foliation curves. Model-based methods, such as tensor-based linear modeling [7], and model-free artificial intelligence (AI) approaches, such as unsupervised clustering and classification [3, 8, 9], can then be designed and applied to the kimesurface representations of the time-varying processes.

The main drivers of examining longitudinal data include (1) direct identification of intra-individual change (and stability) and/or of inter-individual differences (similarity); and (2) analysis of interrelationships in behavioral change, causes (determinants) of intra-individual change, and/or of determinants of inter-individual differences [10, 11]. Time-series methods for modeling continuous responses include analysis of response profiles, linear mixed-effects models, hierarchical linear model, and support vector regression [12, 13]. Response profile analysis is typically employed with a relatively small number of repeated measurements, obtained on a common set of occasions [12]. Linear mixed-effects models are generally applicable for data with expected interdependencies, or presence of explicit or implicit hierarchical structure [14]. Mathematical modeling and statistical inference on longitudinal data involves preprocessing to ensure stationary, proper representation of seasonal and non-seasonal effects, accounting for known interventions and outliers, regression estimation and classification analysis. The classical goals of time-series analysis include model fitting, parameter estimation, diagnostic checks, forecasting, and inference [15]. Many model-based approaches rely on autoregressive integrated moving averaging (ARIMA); however, there are different classes of techniques for joint modeling of multivariate longitudinal data, e.g., models of evolution of the measured outcomes, marginal models, and models for latent evolution of latent variables [16]. Recent mathematical advances propose using geometric and topological techniques to represent, track, model, and analyze time-series and longitudinal processes [17,18,19]. Other machine learning and artificial intelligence techniques for time-series analysis include recurrent neural networks, long short-term memory networks, and deep Boltzmann machines [3, 20].

Functional Magnetic Resonance Imaging (fMRI) represents an example of time-varying data that requires careful assessment of underlying model assumptions, method limitations, and data processing challenges associated with longitudinal designs, e.g., task design, sampling strategies, and within subject and cohort-level analyses [13, 21, 22]. Changes in the fMRI time-course corresponds to neuronal activity tracked as variations of the ratio of oxygenated to deoxygenated blood levels, subject to a mediating process known as the Hemodynamic Response Function (HRF). Under various stimuli, e.g., audio, visual, and tactile, a change in the observed fMRI signal is detected in the relevant brain region, subject to HRF mediation with certain response delay, e.g., 2–3 s. Magnetic resonance scanners are extremely sensitive to electromagnetic fields and can be used to track brain anatomical structure, tissue spectral composition, and functional network activity. Brain functional activation is a proxy of the level of oxygenated blood hemoglobin molecule, which contains four iron atoms whose magnetization response depends on their oxygen binding; hence oxygenated vs. deoxygenated blood have distinct diamagnetic and paramagnetic properties. As the concentration of oxygenated blood in a brain region reflects changes (increases or decreases) of neuronal activation in response to a specific stimulus, the regional fMRI signal is a proxy indicator highly correlated with the associated brain area processing the specific stimulation task [23].

Tensor-based linear modeling represents longitudinal data using higher-dimensional arrays (tensors) that encode different characterizations of the observed measurements in terms of state indices, e.g.,

Conditions×Repetitionexperimental\,design×SpaceX×SpaceY×SpaceZ×Timespatial-temporal\,characterization×…⏟other⋅
For each given tensor element, the observed data may be a (coupled) scalar, vector, matrix, or another tensor. In general, the typical goals of tensor-based linear modeling (TLM) involve obtaining computed class-labels, deriving prospective trajectory forecasts, estimating Bayesian posterior predictive probabilities, and predicting of an outcome tensor 𝕐 of dimension 𝑄1×⋯×𝑄𝑀 from another observed tensor 𝕏 of dimension 𝑁×𝑃1×⋯×𝑃𝐿, where 𝑁 is the number of observations [7]. One example of TLM inference is the prediction of several facial attributes from a set of recorded images [24]. In this application, the outcome tensor 𝕐:Faces×Attributes is predicted using data in the observed feature tensor 𝕏:Faces×𝑋×𝑌×ColorChannels [25]. Another application is the prediction of EEG from fMRI data [26]. Typically, EEG has low spatial but high-temporal resolution along the brain cortical surface, whereas fMRI provides better spatial but poorer temporal resolution over the entire 3D spatial domain. TLM allows predicting the association between these two non-invasive functional neuroimaging modalities. Such TLM can be used to enhance derived neuroimaging biomarkers, impute missing or incomplete spatiotemporal information, and derive better prediction for normal and pathological conditions [27, 28].

Appendix A provides some additional background on the tensor definition, representation, and operations. Tensors naturally provide a mechanism for extending unconstrained or regularized linear models for prediction and inference based on high-dimensional and longitudinal data. Consider an observed (training data) outcome 𝕐:𝑁×𝑄1×⋯×𝑄𝑀 and a corresponding observed covariate tensor 𝕏:𝑁×𝑃1×⋯×𝑃𝐿. Then we can perform (tensor) linear-model fitting:

𝕐=⟨𝕏,𝔹⟩𝐿+𝔼.
where the two new tensors are @:𝑃1×⋯×𝑃𝐿×𝑄1×⋯×𝑄𝑀, representing the TLM coefficient (effect-size) tensor, and 𝔼:𝑁×𝑄1×⋯×𝑄𝑀, denoting the residual error tensor. Note that the first 𝐿 modes of 𝔹 contract the dimensions of the covariate tensor, 𝕏, which are not in the outcome tensor 𝕐, and the last 𝑀 modes of 𝔹 expand along the outcome 𝕐 tensor modes in 𝕐 not present in the covariate tensor 𝕏. Assuming we have sufficient data to fit this model and estimate the effect tensor 𝔹 and the residual error tensor 𝔼, then we can perform prediction and forecasting of the outcome tensor using classical linear modeling strategies. For a given outcome tensor index-set (𝑞1,…𝑞𝑀) the TLM prediction of the outcome tensor element for each case 1≤𝑛≤𝑁 is:

𝕐[𝑛,𝑞1,…,𝑞𝑀]≅∑𝑝1=1𝑃1⋯∑𝑝𝐿=1𝑃𝐿𝕏[𝑛,𝑝1,…,𝑝𝐿]𝔹[𝑝1,…,𝑝𝐿;𝑞1,…,𝑞𝑀].
To simplify the notation, the TLM model excludes the static tensor-intercept term and assumes that the observed data tensors 𝕐 and 𝕏 are centralized.

This paper is focused on representing, modeling, and analyzing repeated-measurement longitudinal data as complex time (kime) surfaces. This characterization of time-varying information facilitates the analysis of classical time-series as higher-dimensional kimesurface manifolds. The manuscript is organized as follows. In Sect. 2, we define complex time and present alternative time-series to kimesurface transformations. The following Sect. 3 describes the general tensor regression-based linear modeling approach. Section 4 includes applications of spacekime TLM analytics to functional Magnetic Resonance Imaging (fMRI). Finally, in Sect. 5, we summarize the spacekime analytics approach and interpret the reported findings. The supplementary materials section ("Appendix") contains specific implementation details and additional examples.

Complex-time (kime) and spacekime representation
Complex time (kime) extends the familiar notion of event order (time) to the complex plane. The kime representation of longitudinal data involves indexing measurements by 𝜅=𝑡𝑒𝑖𝜃, where 𝑡 and 𝜃 represent the longitudinal event order (time) and a directional kime-phase (repetition index), respectively. The kime-phase 𝜃 is indirectly related to the classical repeated random (independent and identically distributed) sampling during the process of recurrent measurement. The rationale for this extension of time from the positive reals (ℝ) to the complex plane (ℂ) is threefold. First, in a classical mathematical sense, the longitudinal axis of spacetime represents only a positive cone over the field of the real numbers [29]. The time dimension forms a subgroup of the multiplicative group of the reals, however it’s not closed under addition. On the other hand, complex-time describes an algebraic prime field [30] that naturally extends the reals and hence, the classical temporal domain. Although time is ordered, whereas kime is not, the intrinsic time ordering is preserved in the kime magnitude. Second, the kime dimensionality lift addresses some of the physical problems of time [31]. Third, repeated-measurement longitudinal data are represented in terms of kime as 2D manifolds. This enables a higher-dimensional view of longitudinal processes and offers unique opportunities to design and validate innovative data-driven artificial intelligence (AI) and statistical approaches for modeling, analysis, inference, and prediction on temporal signals [6].

Although there are multiple strategies to transform longitudinal processes to kimesurfaces, we will demonstrate this transformation using two specific kimesurface representation methods [6]. Both methods can translate observed time-varying signals, such as spacetime fMRI data, into spacekime kimesurfaces. The first empirical strategy is based on discretely estimating the “missing/unobserved” kime-phases and directly mapping the observed longitudinal-indexed time-series into kime-indexed surfaces. The second analytical strategy for mapping between time-domain data and kime-domain data utilizes the Laplace Transformation [32].

For more specificity, we will explicate both time-series to kimesurface transformation strategies in terms of a finger-tapping fMRI experiment. In the empirical strategy, the longitudinal (time) indexing, (t), includes one epoch of the fMRI design. The second component, kime-phase indexing, (φ), runs over the number of epochs of one specific stimulus (e.g., finger-tapping or rest). These phase directions are generally unknown and may be randomly drawn (or estimated) from the appropriate kime-phase distribution for the specific stimulus condition. Figure 1 shows a direct mapping between fMRI time-series and their corresponding kimesurface counterparts. The entire fMRI time course is spliced and arranged according to the epoch curves into an approximate piecewise parametric surface indexed over kime with complex-time intensities derived from the corresponding complex-valued fMRI signal. The complex-value of the function 𝑓(𝑡,𝜑)=𝐴𝑒𝑖𝜃 is in the range-space and has magnitude 𝐴=𝐴(𝑡,𝜑) and (range) phase 𝜃=𝜃(𝑡,𝜑) that correspond to the polar coordinate representation of complex time (kime), i.e., (t, φ).

Fig. 1
figure 1
Schematic diagram of an empirical mapping between an fMRI time-series and its corresponding kimesurface

Full size image
Figure 2 demonstrates two views of the same 3D scenes depicting an empirical kimesurface reconstruction of the on (stimulus) versus off (rest) fMRI signal. The graphs show the kime domain areas where the on versus off differences are small (surface valleys) or large (extreme high or low surface peaks). The former indicate kime ranges where the voxel location corresponding to the kimesurface does not exhibit significant brain activation. Whereas the latter, surface peak regions, correspond to kime areas of potentially statistically significant on versus off brain activation associated with the cognitive stimuli. Note that the practical and statistical significance of these peaks and valleys can be evaluated using Gaussian random field theory of the excursion sets above certain threshold values [33, 34].

Fig. 2
figure 2
A pair of 3D surface renditions of the ON–OFF fMRI kimesurface differences at a fixed spatial location. Blue and yellow colors indicate positive and negative kimesurface differences, respectively (Color figure online)

Full size image
To map longitudinal time-series into kimesurfaces using an alternative analytical strategy, we can employ the Laplace Transform (LT). LT converts complex-valued functions of positive real variables (e.g., time) to complex-valued functions defined on complex variables (e.g., kime). In general, for a function 𝑓(𝑡):ℝ+→ℂ, the continuous LT is defined by:

𝐹(𝑧)≡(𝑓)(𝑧)=∫0∞𝑓(𝑡)𝑒−𝑧𝑡𝑑𝑡:ℂ→ℂ.
In our situation, complex-valued fMRI time-series signal 𝑓(𝑡):ℝ+→ℂ can be represented as an ordered (discrete) sequence of complex-valued fMRI BOLD intensities:

{𝑓(𝑡)=𝑎𝑡+𝑖𝑏𝑡:1≤𝑡≤𝑇}.
The discrete LT of 𝑓 is represented as an infinite series corresponding to the discretized LT integral above. For a specified step-size 𝜂>0, the discrete Laplace transform (𝑓) is computed by:

𝜂(𝑓)(𝑧)=𝜂∑𝑘=0∞𝑒−𝑧𝑘𝜂𝑓(𝑘𝜂).
To demonstrate the Laplace Transform-based analytical strategy, we apply the Inverse Laplace Transform (ILT) on an fMRI kimesurface and then convert it back to the original fMRI time-series, see Fig. 3. Given a complex function 𝐹(𝑧), which represents a kimesurface, and a positive real argument 𝑡, the ILT algorithm, developed by Valsa and Brancik [35], involves iterative continuous approximations to generate an approximation of the output 𝑓(𝑡)=−1(𝐹)(𝑡). This iterative approximation approach estimates the exponential term 𝑒−𝑧𝑡 using a series where each term is a Bromwich integral obtained through residue calculus [36]:

𝑓(𝑡)===−1(𝐹)(𝑡)=12π𝑖lim𝑇→∞∫γ−𝑖𝑇γ+𝑖𝑇𝑒𝑧𝑡𝐹(𝑧)𝑑𝑧=𝑓𝑐(𝑡,𝑎)+𝑂(𝑒−2𝑎)𝑒𝑎2𝑖∫γ−𝑖∞γ+𝑖∞(𝐹(𝑧)∑𝑛=0∞[(−1)𝑛(𝑛+12)(𝑛+12)2π2+(𝑎−𝑧𝑡)2])𝑑𝑠+𝑂(𝑒−2𝑎)−𝑒𝑎𝑡∑𝑛=0∞(−1)𝑛Im{𝐹[𝑎𝑡+𝑗(𝑛+12)𝜋𝑡]}+𝑂(𝑒−2𝑎),
where a>0 is a parameter that can be chosen arbitrarily large to control the error rate, and the subscript 𝑐 stands for cosh(⋅), which is involved in the intermediate steps. In practice, the Euler transformation [37] may be used to accelerate the convergence of the alternating series above.

Fig. 3
figure 3
The duality between a real fMRI time-series (red curve on the right panel), its corresponding kimesurface (left panel), and the reconstructed fMRI time-source using the ILT on the kimesurface (blue scatterplot on the right panel) (Color figure online)

Full size image
Methods
Datasets
We tested the process of mapping observed time-series data to kimesurfaces, reconstruction of the time-series process, the subsequent analytical modeling, and statistical inference using real Functional Magnetic Resonance imaging (fMRI) data.

Specifically, we describe the results of a neuroimaging study using an “on–off” fMRI finger-tapping experiment, which models the brain response via an oscillatory step-wise characteristic function with a delayed correlation to the on–off stimulus paradigm. The observed data represents complex-valued fMRI time-series of the blood oxygenation dependent (BOLD) response to a dichotomous finger-tapping “on versus off” (activation vs. rest) event-related experiment [38, 39]. The raw signal is acquired in the Fourier k-space over a period of 8-min tracking the functional BOLD signal of a normal volunteer during the finger-tapping “on–off” task. Using the inverse Fourier transform, the data were mapped into spacetime and stored as a 4D double-precision array of complex-valued intensities. The size of the data is about ½ GB (gigabytes) and the dimensions of the data are 64𝑥×64𝑦×40𝑧3D spatial voxel,𝜈×160𝑡⏟time. Each epoch of the longitudinal (time) finger-tapping task represents a basic pattern of 10 ON (activation) time-points followed by 10 OFF (rest) time-points. The ON and OFF epochs are intertwined and repeated 8 times for a total of 160 time-points, each of about 3 s. We applied an established fMRI data preprocessing protocol, e.g., using the R package fmri, to motion-correct, skull-strip, register, and normalize the raw fMRI signal [40, 41]. The target of the registration was the LONI Probabilistic brain atlas [42], which allows anatomically parcellating the functional brain data into 28 left and 28 right hemisphere cortical regions. This last step was important for the subsequent three-phase statistical inference aiming to identify the spatial locations in the brain, {𝜈=(𝑥,𝑦,𝑧)}, associated with the finger-tapping motor task.

Tensor-based linear modeling
In order to detect brain activated areas associated with the finger-tapping somatosensory motor task, we apply tensor-based linear modeling to the spacekime represented fMRI data. Our analytical protocol includes three phases. In phase 1, classical statistical methods are used to raw fMRI data in order to identify any Regions of Interest (ROIs) that may be activated by the external stimulus. In phase 2, we apply tensor regression to the corresponding kimesurface representations of the fMRI data. And finally, to reduce the false-positive rate, in phase 3, we apply post-hoc correction to the p-values computed in phase 2.

In the preprocessing step, the real- or complex-valued fMRI data can be co-registered or aligned with a specific brain atlas using linear or nonlinear transformation techniques [42,43,44]. Then, we continued partitioning the brain anatomy into Regions of Interest (ROIs) by using the probabilistic atlas, which assigns likelihoods to be inside any 56 ROIs [42]. In this way, each voxel is effectively tagged with a label representing its most likely ROI anatomical localization. In this case, we used the LONI probabilistic brain atlas to tessellate the entire brain anatomical space into 56 complementary ROIs.

The aim of phase 1 analysis is to select important ROI candidates that can subsequently be interrogated voxel-by-voxel to further localize the statistical significance maps reflecting the activated brain areas associated with the finger-tapping task. We used a measure called temporal Contrast-to-noise Ratio (tCNR) [45] to represent the average signal‐change or task‐related variability relative to the non‐task‐related variability over time. In fMRI studies, two strategies are commonly used the estimate the tCNR [46]. The first one is based ion modeling the known stimulus design and utilizing the hemodynamic response function. The second strategy involves low-pass filtering and assumes only that most high-frequency fMRI components contain temporal noise. For a fixed ROI, the most general form of the tCNR is represented by:

tCNR=Δ𝑆𝜎𝑡noise,
where the numerator Δ𝑆 is the average signal-change reflecting task-related variability and the denominator 𝜎𝑡noise represents the non-task-related variability over time. Strong tCNR evidence of a task-specific effect within an ROI is indicated by tCNR≫1, whereas tCNR≈1 suggests the regional may not be involved in stimulus processing. We compute an estimate of the true fMRI signal at a given voxel location 𝜈 by using polynomial regression, low-pass filtering, or a convolution with a smoothing kernel. This smoother fMRI signal is used to compute the numerator, Δ𝑆𝜈, and the variability of the time-series noise, 𝜎𝑡𝜈,noise, is estimated as the difference between the observed and smoothed fMRI signals. The overall ROI tCNR is computed by pooling the local estimates, tCNR𝜈=Δ𝑆𝜈𝜎𝑡𝜈,noise, over all voxels 𝜈∈ROI.

Parametric or nonparametric statistical tests, such as t-test and Wilcoxon test [47], can be used to quantify the ROI-wise stimulus related to brain activation. In our case, we used a t-test to assess the statistical significance in each of the 56 ROIs independently. The test-statistics can be computed using the observed tCNR vector (tCNR1,tCNR2,…,tCNR𝑁)𝑇, where N is the number of voxels in the ROI. To control the type-I (false-positive) error rate, we used Bonferroni correction for multiple testing to adjust the resulting ROI p values (α = 0.000892).

In phase 2, the tensor linear regression models were estimated separately on each of the 56 ROIs to obtain efficient model parameter estimates. For each (irregularly shaped) ROI, we first encapsulated it with the smallest bounding box. This facilitates the tensor arithmetic by padding the fMRI intensities with zeros outside of the ROI boundaries. We can denote the general dimensions of the smallest bounding box for each ROI by 𝑎×𝑏×𝑐. Suppose 𝕐:𝑡×𝑎×𝑏×𝑐 is the response tensor, i.e., fMRI intensity and 𝕏:𝑡×𝑝×1 is the predictor tensor. Thus, the proposed tensor-based linear model is given by:

𝕐=⟨𝕏,𝔹⟩𝐿tensorproduct+𝔼,
where 𝔹:𝑝×1×𝑎×𝑏×𝑐 is a tensor linear model coefficient and 𝔼:𝑡×𝑎×𝑏×𝑐 is the residual error tensor.

The design tensor 𝕏 contains the information corresponding to the on–off stimulus, i.e., finger-tapping task indicator {+1(On),−1(Off)}, adjusted by the Hemodynamic Response Function (HRF) which models the expected blood oxygen level dependent (BOLD) response. In addition, 𝕏 includes a pair of polynomial drift terms; one of order one (linear) and the other of order two (quadratic) to adjust for low-frequency noise.

We fitted this model by using the R package MultiwayRegression [25], which estimates coefficients using penalized least-squares. Then, parametric or nonparametric statistical tests can be applied to the estimated BOLD coefficients 𝛽̂  to enable statistical inference. In this case, we used t-tests on the estimated coefficients 𝛽̂  in each ROI. The smaller the corresponding p-values are, the more significant the neuro-activation is in the respective brain area.

Phase 3 of the protocol involves post-hoc analysis, which is necessary for filtering potential false positive discoveries and only exposing true-positive brain activation regions. In this final phase of the analysis protocol, we used a twofold strategy. First, we applied a false discovery rate (FDR) correction to account for multiple testing [48], and second, we used a spatial clustering filter to control for the size of the activation region [49]. The pair of post-hoc correction strategies used in this phase are designed to temper erratic noise (FDR), as well as, to annihilate smaller-in-size regions of activated voxels (clustering), which are more likely to represent sporadic random activations.

Applications
To compare classical space–time analytics vs. spacekime inference, we applied this three-phase tensor-based analytical protocol to the original spacetime fMRI finger-tapping task, as well as to its corresponding spacekime representation. Then we contrasted the statistical significance maps, i.e., computed and compared the p values corresponding to the on–off stimulus. The results were visualized in terms of the ROI cluster size and the p values corresponding to brain activation blocks within the specific ROIs, see Fig. 4.

Fig. 4
figure 4
Results of the three-phase statistical analysis protocol on native fMRI time-series data (left) and the corresponding fMRI kimesurface representations (right). The 3D renderings illustrate different point-of-view orientations. Note: The Phase 1 results for the classical (left) and proposed space-kime analytics are identical, as the ROI-analytics are done on the raw space–time data

Full size image
The results on Fig. 4 show some important advantages of our three-phase tensor-based analytical protocol. First, unlike traditional voxel-by-voxel statistical inference on fMRI data, our method takes spatial correlation into consideration by using tensor regression, which is more in line with the fact that the signal at a particular voxel is likely to be similar to the signals of nearby neighboring voxels. Second, this method substantially reduces the dimensionality of fMRI data, which leads to efficient estimation and prediction. In addition, the comparison of the results obtained using the time-series and kimesurface analyses clearly indicates that spacekime represented fMRI data can retain more information than the raw fMRI time-courses. This suggests that kimesurface representation and spacekime analytics may provide more reliable activation brain maps. The activated brain areas revealed by the tensor-based statistical analysis of the kimesurfaces associated with the finger-tapping task paradigm are consistent with the evidence of observing such activation in the somatosensory cortex (motor area), which validates the performance of the spacekime analytical strategy for modeling, inference and prediction based on fMRI signals. Appendix B provides some additional renditions of 3D scenes showing the results of each phase of the 3-tier spacekime analytical protocol.

Conclusions and discussion
Introducing complex-time provides a foundation to address many interesting scientific challenges, including proposing novel techniques for interrogating time-varying longitudinal data, addressing some of the problems of time, and extending and generalizing mathematical equations describing natural laws of physics. The kime representation of longitudinal observations lifts the familiar notion of event order (time) to the complex plane. The induced spacekime representation expands the longitudinal dimension of time and generalizes the classical 4D universal spacetime to a 5D spacekime manifold whose topological structure facilitates novel data analytics. Spacekime representation of data can be used to design, test, and validate novel statistical models for risk estimation, probabilistic modeling, trajectory forecasting, parametric and non-parametric inference, as well as supervised and unsupervised artificial intelligence.

In this paper, we proposed discrete and continuous kimesurface representation strategies for transforming longitudinal data into kimesurfaces. Applying general tensor regression to the resulting kimesurfaces allows the comparison and contrasting of classical time-series analysis with tensor regression on kimesurfaces. Using fMRI data, we presented a three-phase tensor-based analytical protocol for the spacetime and spacekime represented data. We showed that this protocol substantially reduces the dimensionality of fMRI data, which leads to efficient estimation and prediction. We also showed that spacekime fMRI data representation can retain more information than spacetime represented fMRI data, thus revealing more activated brain areas. Therefore, one advantage of kimesurface is its ability to potentially expose supplemental information that may enhance traditional spacetime observation-based scientific inference, improve data-driven predictions, and refine evidence-based decision-making processes.

The main contribution of this article revolves around the introduction of a tensor-based linear model applicable for representation, analysis, and inference of repeated-measure longitudinal data following a transformation from the linear (positive real) time domain to the (complex) kime plane. Two alternative strategies for mapping time-series data to kimesurface manifolds are presented and tested on neuroimaging fMRI data. This spacekime analytical technique offers a new mechanism to represent time-varying and high-dimensional datasets and provides a foundation for developing innovative ML/AI methods that capitalize on the intrinsic topological structure of the spacekime data manifolds. In addition to applications in biomedical sciences [50], econometrics [51], and environmental sciences [52], the spacekime representation and tensor analytics may be useful in a number of biophysics studies [53], thermoelastic diffusion solutions [54], and boundary value problems [55].

As firm supporters of open-science, we have documented, packaged and released the source-code in a time complexity and inferential uncertainty (TCIU) R-package. The source code, the TCIU package, vignettes and documentation are available on GitHub (https://github.com/SOCR/TCIU) and CRAN (https://cran.r-project.org/web/packages/TCIU/). More information, interactive demonstrations, and additional materials are available on the spacekime website (https://spacekime.org). Community input is always welcome.