Phishing is an attack that deceit online users by means of masquerading as a genuine website to pilfer their classified or personal information. This is one among the recognized cybercrime. Disparate phishing website detection systems were recently developed for the purpose of detecting the phishing websites. However, they fail to attain the desired output and are suffered from countless drawbacks like lower accuracy and higher training time. For trouncing such drawbacks, this paper proposes an effectual Hybrid Deep Learning (HDL)-centric Phishing Detection System (PDS) using the MCS-DNN classifier. At first, pre-processing is done on the input dataset for ameliorating its quality. Subsequently, clustering and feature selection (FS) are performed to lessen the processing time and elevate the accuracy using CoK-means and CM-WOA, respectively. The features which are chosen during FS are fed into the MCS-DNN classifier, which classifies the legitimate websites and phishing websites. Lastly, the K-fold cross-validations (KCV) are employed for effectively predicting the proposed systemâ€™s accurateness. The outcomes highlight the robustness and predictive ability of the proposed PDS to distinguish the phishing as well as legitimate sites.

Introduction
World Wide Web has taken a chief role in the present years, on account of the internetâ€™s flexibility. But, such an advantage comes with a cost, i.e., cyberattacks [1]. Phishing means a kind of Internet cyber-attack, in which the false webpage masquerades itself as a legitimate webpage in order to scam user to give their personal data, like username, password, bank account, or else credit card details, etc. [2, 3]. Phishing is the scam method in which personal data is attained by means of impersonating as a legitimating one for attaining financial or own benefit [4]. These attacks are inescapable and also aim at organizations at anytime and anywhere [5].

Phishing is executed in disparate means: email-to-email, email-to-website, website-to-website, along with browser-to-website [6]. An exemplification of Phishing: an e-mail appears to be as of recognized web sites, as of a customer`s credit card company, bank, e-mail, or Internet service provider. Usually, personal information, for example, credit card password or number is requested to update accounts. These e-mails hold a URL link that forward the users to a disparate website (fake website). When the user visits this site, they are requested to give their personal information, to be advanced to the phishing attacker [7], which brings about identification theft along with financial failure. As per an investigation, the number of financial losses that occurred was over 'three' billion dollar yearly by merely phishing attacks [8].

The report that the APWG published in 2019 (second quarter) reported that the number of phishing attacks augmented by 30% as of the preceding quarter [9]. In 2004 (fourth quarter), they perceived around 1609 attacks (phishing) per month. In 2016 (fourth quarter), the APWG perceived a typical of 92,564 attacks (phishing) per month, establishing an augmentation of 5753% greater than the last 12 years [10]. Phishing has turned to be a pernicious issue that innumerable researchers have dedicated an augmenting interest in controlling it since 2004 [11]. Phishing is increasing extensively, pressuring people to think about how to stop it. Figure 1 demonstrates the importance together with the urgency of phishing recognition in contemporary civilization, which is centered on a phishing website statement in 2019 (fourth quarter) (Table 1).

Fig. 1
figure 1
Work flow of proposed methodology

Full size image
Table 1 APWG Phishing reports, 2019 [9]
Full size table
Detecting whether a webpage is legal or phishing is an extremely difficult issue for the reason that a phishing attack has a semantics-centered structure and also mostly cash in on the computer users' vulnerabilities [12]. Some anti-phishing system was introduced, which utilize Heuristic, Blacklist, Content along with Machine learning-centered approaches [13, 14]. However, these approaches still undergo higher false positives, bad accuracy, along with real-time solutions, causing insufficiency in online transactions on account of its low-level efficiency [15]. Therefore, there stands a requirement for a capable methodology for effectively detecting the existing phishing sites that are hosted on servers (compromised) [16]. This document contributes a total, automatic, real-time structure to find a phishing URL. Other contributions of this document are,

Effective pre-processing together with grouping scheme for managing the dataset to lessen the processing time and enhance the accuracy.

Regarding FS, an amalgamation of whale optimization with genetic algorithm to augment the systemâ€™s performance.

Employing an algorithm termed deep learning neural networks (DNN) for effectively detecting the existing phishing sites.

The organization of this work is as: Sect. 2 elucidates the literature works with a concise outline of the contributions given in the past. Section 3 expounds the proposed PDS in a detailed manner with suitable schematic representations. Section 4 renders the comparison-based study utilizing different metrics and methods, and the detailed conclusion in Sect. 5.

Literature review
Rao et al. [17] rendered a classification framework, grounded on heuristic features that were taken as of source code, URL, and third-party services. The model was assessed centered on eight disparate ML algorithms, and from which, the random forest (RF) approach shown 99.310% accuracy. Its chief drawback was its higher training time.

Pham et al. [18] modeled a neuro-fuzzy framework (dubbed Fi-NFN) to effectually avertPhishing Attacks (PAs). Grounded on the approach, the anti-PDS (Phishing Detection System) was modeled for transparently observing and protecting fog users as of PAs. The Fi-NFN classification framework ameliorated the classification accurateness to 98.36% and enhanced the convergence of the training phase.

Chiew et al. [19] propounded a hybrid ensembles- FS for ML-centric PDS. In this propounded approach, a cumulative distribution function- gradient (CDF-g) algorithm was initially exploited for producing primary feature subsets, and the secondary phase developed baseline features as of the secondary ones by utilizing a perturbation ensemble. But its accuracy was affected on account of some obsolete features.

Gutierrez et al. [20] modeled SAFEPC (Semi-Automatic Feature generations for the Phish Classification) for feature extraction and elevating to ameliorated features, that were meant to combat common phishing e-mail detection schemes. It extracted features as of the message's header and message's body, imbued with a structural understanding of phishing e-mails. Then, it was employed to a RUSBoost classifier utilizing phishing and legal e-mails.

Marchal et al. [21] put forward an automatic PDS termed PhishStorm for identifying possible phishing sites. This scheme was grounded on the intra-URL relation. This sort of relatedness reflected the relation among the words blended onto a URL and specifically into the freely defined URL part and the registered domain. Moreover, the conducted experiment attained the outcomes of 94.9% classification accurateness together with 1.44% (lower-level) false-positive rates (FPRs) which was preeminent when weighed against the other previous approaches.

Gunikhan Sonowal and K S Kuppusamy [22] introduced a multilayered design titled PDS utilizing multifilter Approach. This recommended approach incorporates layers like (a) URL feature, (b) Auto upgrade white-list, (c) String matching, (d) Accessibility Scores-comparison, as well as (e) Lexical signature layers. This recommended approachâ€™s prototype implementation was done with the best accessible interface in order that visually impaired humans could easily access it.

Xiao et al. [23] introduced an approach via integrating a convolutional neural network (CNN) with Multi-Head Self-Attention (MHSA) for ameliorating the PDS accurateness. This introduced approach first regarded URL strings as input and supplied it onto a CNN for extracting its features. Moreover, MHSA was employed for exploiting characters' relations in the URL for evaluating the equivalent weights for the CNN learned features. Lastly, CNN-MHSA could create highly precise detection outcomes for a URL object by incorporating its features and weights.

Ozcan et al. [24] offered HDL models for identifying phishing uniform resource locators centered on long short-term memory (LSTM) along with DNN techniques and assessed the models' performance on phishing databases. The HDL methodologies being proffered had been amalgamated the feature embedding with natural language processing (NLP) characteristics, allowing them to leverage deep character linkages while also showing high-level NLP connections. In terms of accuracy, the presented models outperformed the other phishing detection models, according to the findings of the experiments. The dataset used in this work was considered precise complete and devoid of noise which affected the trustworthiness of its performance.

Hybrid deep learning-based phishing detection system
A type of cyber-attack that targets young online users and discloses sensitive data is termed phishing [25, 26]. In this, the message that is transmitted to the victim emerges to be as of a trusted source. This sort of attack is mostly performed to make the victim provide their classified information into a fraud website. It is vital to detect this sort of attack as they are augmenting swiftly. Here, the deep learning-centered PDS is modeled for effectively detecting phishing attacks on web sites centered on the URL features. Specific steps are required to be executed for designing an effective PDS model. A correct means to formulate a system that renders correct and also precise outcomes must be taken. These steps are elucidated below meticulously. Figure 1 exhibits the flow and the working of every block.

URLs and URL features
A URL is utilized to locate the resources. A URLâ€™s structure is rendered in the Fig. 2.

Fig. 2
figure 2
Structure of URL

Full size image
As of Fig. 2, the URL: http://www.example-url.com/info/index.php, encompasses the subsequent elements: (1) Protocol is http, (2) Subdomain is www, (3) second level domains are example-url, (4) Top-Level Domains is .com, (5) Path is info, as well as (6) Filename is index.php. Phishers typically endeavor to create the Internet addresses (URL) of phishing sites equivalent to genuine sites to fool online users. For instance, in Fig. 3, the â€œmyuniversity.edu/renewalâ€ URL was altered to â€œmyuniversity.edurenewal.comâ€. Similarities betwixt the â€˜twoâ€™ addresses proffer the sense of a safe link, making the recipient oblivious to the attack that is happening.

Fig. 3
figure 3
Example of legitimate URL and phishing URL

Full size image
The legitimate sitesâ€™ URL will be registered, thus, the attackers cannot reuse them. The differences among a legitimate and a phishing URL centered on an assortment of features of URL are recognized. Here, the legitimate along with phishing website centered on 30 features are recognized.

Input features acquisition
The inputted URL datasets: Phishing Websites Data-set #1, as well as Phishing Websites Data-set #2, is gathered as of the University of Huddersfield website, which is publically accessible online. The proposed design takes the decision centered on thirty features that could well be extracted as of phishing as well as legitimate website URL along with web content. The â€˜30â€™ extracted features are IP address, URL length, â€˜@â€™ symbol, Tiny URL, Favicon, Redirection using â€˜//â€™, â€˜-â€™ symbol, Subdomain, and Multi subdomain, Domain registration length, Nonstandard port, URL of anchor, HTTP token in the URLâ€™s domain part, Request URL, Links inâ€‰<â€‰metaâ€‰>,â€‰<â€‰scriptâ€‰>â€‰andâ€‰<â€‰Linkâ€‰>â€‰tags, Server Form Handler, Abnormal URL, Submitting Information to E-mail, Customization of Status Bar, Website Forwarding, Disabling the Right Click, IFrame Redirection, Utilizing Pop-up Window, Age of Domain, Page Rank, Website Traffic, Google Index, DNS Record, Statistical-Reportsâ€“centric Feature and Number of Links which Points to Page. The pre-processing is executed on features for lessening the systemâ€™s processing time and elevating the accuracy level.

Pre-processing
This is a necessary phase in attack detection, which will ameliorate the datasetâ€™s quality by changing the data to a format that would be extra simple and effectually processed in favor of the user. A pre-processing hold â€˜twoâ€™ step: The first eliminate the recurring data as of the dataset. The separation phase classifies the dataset character into â€˜fourâ€™ classes.

(i)
Removal of repeated data

Here, the recurring data as of the dataset are eradicated, since, for the same data, the same outcome will be attained. And also it consumes a longer time to process the whole dataset. Thus, by doing this, the system's processing time is also lessened.

(ii)
Separation

Here, the dataset features are bifurcated into â€˜fourâ€™ classes: Address Bar-based Features (AdBF), Abnormal-Based Features (AdF), HTML and JavaScript-based Features (HtmlF), Domain-based Features (DF), centered on the featuresâ€™ types. Here, first '12' features come under Address-based features, subsequent 'six' features come under AdF, after that 'five' features come under JavaScript and HTML-centered features, and remaining 'seven' features come under DF.

Grouping utilizing CoK-means clustering algorithm
Subsequent to pre-processing, the information is grouped centered on the attribute values of all features. The proposed methods clustered the data by utilizing covariance centered K-means clustering (KMC) algorithm. The archetypal KMC groups the data by evaluating Euclidean distance (ED). However, ED merely makes sense when every dimension contains similar units (say, meters) since it involves adding the squared value of them. Thus, to stay away as of such an issue, it attains covariance in-relation, which assists in calculating the strength/similarity betwixt two disparate data objects. The algorithmic steps concerned in Co-K means are demonstrated as,

Step 1 Signify the number of clusters K then initialize the N number of data points (feature values) as ğ‘¥ğ‘–={ğ‘¥1,ğ‘¥2,â€¦,ğ‘¥ğ‘} and set of cluster centroid as ğ‘ğ‘—={ğ‘1,ğ‘2,â€¦,ğ‘ğ¾}.

Step 2 Choose K points at random as cluster centers.

Step 3 Calculate the distance (Eluğ‘‘) of every point as of every cluster by means of computing its distance as of the equivalent cluster mean and cluster center,

Eluğ‘‘=âˆ‘ğ‘–=1ğ¾âˆ‘ğ‘—=1ğ‘âˆ£âˆ£ğ‘¥ğ‘–âˆ’ğ‘ğ‘—âˆ£âˆ£2Ã—CoV,
(1)
CoV=(ğ‘¥ğ‘–âˆ’ğ‘ğ‘—)ğ‘‡ğ‘€âˆ’1ğ‘¥(ğ‘¥ğ‘–âˆ’ğ‘ğ‘—)â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆš,
(2)
wherein CoV is the covariance betwixt the centroid and data point, ğ‘€âˆ’1ğ‘¥ is the covariance matrix.

The inverse of the covariance matrix gets a variance-normalized distance equation. The covariance will be higher if the variables in the database are highly coordinated. The distance is decreased effectively by partitioning a huge covariance.

Step 4 Allot objects to the adjacent cluster center as per the ED function.

Step 5 Compute the mean or centroid of the entire objects in every cluster.

Step 6 Redo steps 2, 3, 4, and 5 until the same points are allotted to every cluster in successive rounds.

Only three clusters are chosen as the features had the values of 1, 0, and âˆ’ 1 as their attribute value. Based on this attribute value, the features are clustered. The last clustering outcomes contains â€˜threeâ€™ clusters (K1, K2 and K3). K1 cluster encompasses the features with â€˜0â€™ value. Features that encompass â€˜1â€™ are clustered into K2 cluster, and then, the features having â€˜âˆ’ 1â€™ are clustered into K3 cluster. This clustering algorithm averts the loss of valuable time and enhances classification accuracy via sequentially arranging the dataset. This is due to the fact that clustering transforms the data to a higher dimension which in turn increases the classifier.

Feature selection utilizing CM-WOA
During FS, the unwanted features that contribute too less at the time of classification are filtered out, and instead the false-negative rates (FNR) are elevated by providing incorrectly classified results. Here, the proposed model chooses the features with the utilization of whale optimization algorithm (WOA). However, the populace will be moving toward an optimal individual area continuously with the augment in the number of iterations. Therefore, the possibility for discovering the other positions in the space will be loosed, which in turn results in the loss of diversity in the populace. Hence, WOA and crossover mutation (CM) operators are hybridized to get excellent exploration ability. With this hybridization, an algorithm termed â€˜CM-based WOAâ€™ (CM-WOA) is presented. The CM-WOA could be expounded using the work flow proffered in Fig. 4.

Fig. 4
figure 4
Work flow of CM-WOA

Full size image
This algorithm is the simulation of the social behavior of humpback whales. The CM-WOA utilizes a set of arbitrary candidate solutions (population). It employs three rules like (a) encircling prey, (b) spiral updating position, and (c) search for prey, for updating and enhancing the population position in each step. They are detailed below,

Encircling Prey: if (ğ‘<0.5 andâˆ£âˆ£ğ‘„âƒ— âˆ£âˆ£<1)

Here, the WOA regards the current optimum solution as the required targeted prey. Other whales update their corresponding positions toward this optimum position. This encircling prey behavior (ğœ‰â‡€) is evaluated as:

ğœ‰âƒ— =âˆ£âˆ£ğ‘ƒâƒ— â‹…ğ‘Šâƒ— âˆ—âˆ’ğ‘Šâƒ— (ğ‘¡)âˆ£âˆ£,
(3)
ğ‘Šâƒ— (ğ‘¡+1)=âˆ£âˆ£ğ‘Šâƒ— âˆ—(ğ‘¡)âˆ’ğ‘„âƒ— â‹…ğœ‰âƒ— âˆ£âˆ£,
(4)
where, ğ‘¡ is the current iteration, ğ‘Šâƒ— âˆ— is the best solutionâ€™s position vector, ğ‘Šâƒ—  is the position vector of a solution, || is the absolute value, ğ‘ƒâƒ—  and ğ‘„âƒ—  are the coefficient vectors, â‹… is the element by element multiplication.

It is observed that ğ‘Šâƒ— âˆ— should be updated in every single iteration, if there is a better solution.

ğ‘ƒâƒ—  as well as ğ‘„âƒ—  are evaluated as,

ğ‘ƒâƒ— =2ğ‘Ÿâƒ— ,
(5)
ğ‘„âƒ— =2ğ‘âƒ— ğ‘Ÿâƒ— âˆ’ğ‘âƒ— ,
(6)
where ğ‘âƒ—  is the linearly lessened as of 2 to 0 (in exploration together with exploitation phases), ğ‘Ÿâƒ—  is the random vector in [0, 1].

It is observed that it is feasible to attain any location in the search space positioned betwixt the key points by proffering the ğ‘Ÿâƒ— . Consequently, Eq. (4) permits the search agent to update its location in the current best solutionâ€™s vicinity along with simulates around the prey.

Searching Prey: if (ğ‘<0.5andâˆ£âˆ£ğ‘„âƒ— âˆ£âˆ£â‰¥1)

It is almost the same as encircling prey, but while searching prey instead of ğ‘„âƒ— , a random candidate solution, ğ‘„âƒ— rand, is chosen for guiding the search. It is mathematically evaluated as,

ğœ‰âƒ— =âˆ£âˆ£ğ‘ƒâƒ— â‹…ğ‘Šâƒ— randâˆ’ğ‘Šâƒ— (ğ‘¡)âˆ£âˆ£,
(7)
ğ‘Šâƒ— (ğ‘¡+1)=âˆ£âˆ£ğ‘Šâƒ— rand(ğ‘¡)âˆ’ğ‘„âƒ— â‹…ğœ‰âƒ— âˆ£âˆ£,
(8)
where ğ‘Šâƒ— ğ‘Ÿğ‘ğ‘›ğ‘‘ is the random position vector selected as of the present populace.

Searching for prey is utilized during exploration and facilitates WOA to execute a global search.

Spiral Updating Position: if (ğ‘â‰¥0.5)

Here, for mimicking the helical-shaped moves of humpback whales, a spiral equation between the positions of prey and whale is generated as follows:

ğ‘Šâƒ— (ğ‘¡+1)=ğœ‰âƒ— â€².ğ‘’ğ‘ğ‘™.cos(2ğœ‹ğ‘™)+ğ‘Šâƒ— âˆ—,
(9)
ğœ‰âƒ— â€²=âˆ£âˆ£ğ‘Šâƒ— âˆ—âˆ’ğ‘Šâƒ— (ğ‘¡)âˆ£âˆ£.
(10)
During exploitation in CM-WOA, both spiral updating position rule and encircling prey rule are utilized ğœ‰âƒ— â€²=âˆ£âˆ£ğ‘Šâƒ— âˆ—âˆ’ğ‘Šâƒ— (ğ‘¡)âˆ£âˆ£ signifies the distance between ğ‘– th candidate solution and the best solution of the current generation, b indicates a constant, whereas, ğ‘™âˆˆ[0,1].

Grounded on the random value (ğ‘), the algorithm starts updating ğ‘Šâƒ—  utilizing either Eqs. (4) or (8) or (9). Then, with a crossover as well as mutation operators, the algorithm could push the pollen individuals toward its "fittest-and-closest'' neighbor. The â€˜twoâ€™ crossover points like (ğ‘ğ‘š,ğ‘ğ‘›) are utilized during crossover.

ğ‘ğ‘š=âˆ£âˆ£ğ‘Šâƒ— (ğ‘¡+1)âˆ£âˆ£3,
(11)
ğ‘ğ‘›=ğ‘ğ‘š+âˆ£âˆ£ğ‘Šâƒ— (ğ‘¡+1)âˆ£âˆ£3.
(12)
During mutation, the worst solution is isolated centered on the fitness value and replace it with a generated new random solution. Then, fitness is evaluated for this new solution. Lastly, the algorithm returns the best solution attained as an approximation of the global optimum. In this manner, the optimal features are picked. Moreover, the below expression indicates the selected optimal features,

ğ¹â€²â€²opm={ğ¹â€²â€²1,ğ¹â€²â€²2,ğ¹â€²â€²3,â€¦ğ¹â€²â€²ğ‘,
(13)
where ğ¹â€²â€²opm is the set of optimal features.

Phishing attack detection employing MCS-DNN classifier
Here, a hybrid robust and accurate MCS-DNN classifier is utilized to categorize the legitimate and phishy websites. The proposed MCS-DNN is the integration of Modified Crow Search (MCS) and DNN. In MCS-DNN, each ğ¹â€²â€²opm value is inputted to a discrete node prevailing in the input region of the classifier. Each input is connected with arbitrarily allotted weight values. It has a hidden layer (HL) as the successive layer. In DNN, the weight between an input layer and HL, HL, and output layer was optimized with the utilization of MCS algorithm. As random weight value provides more backpropagation to attain the outcome, an optimized weight value was generated. The general structure of the MCS-DNN classifier is evinced in Fig. 5. The algorithmic steps that are embraced in the MCS-DNN design are proffered below.

Fig. 5
figure 5
Structure of MCS-DNN classifier

Full size image
Input layer The optimal feature set ğ¹â€²â€²opm is inputted to the MCS-DNN classifier.

Weight value initialization Each feature in ğ¹â€²â€²opm has its individual weight value and is initialized as,

ğ‘Šâ€²â€²ğ‘–={ğ‘Š1,ğ‘Š2,ğ‘Š3â€¦ğ‘Šğ‘}.
(14)
These values are arbitrarily generated. As this randomness might affect the prediction level, these weights are well-optimized utilizing the MCS algorithm by this proposed model. This algorithm is inspired by the crowsâ€™ intelligence behavior. Here, the optimized weight value is attained by following the storing process of crows. The process of weight optimization of the CS algorithm is elucidated below,

Weight optimization Consider a flock of ğ‘ weights and here, the weight number ğ‘– has position at iteration ğ‘¡ is ğ‘Šâ€²â€²ğ‘–,ğ‘¡.

ğ‘Šâ€²â€²ğ‘–,ğ‘¡={ğ‘Š1ğ‘–,ğ‘¡,ğ‘Š2ğ‘–,ğ‘¡,ğ‘Š3ğ‘–,ğ‘¡,â€¦,ğ‘Šğ‘ğ‘–,ğ‘¡}.
(15)
The process of weight updation utilizing CS is expressed as,

ğ‘Šâ€²â€²ğ‘–,ğ‘¡+1={ğ‘Šâ€²â€²ğ‘–,ğ‘¡+ğ‘Ÿğ‘‘ğ‘–Ã—ğ‘“ğ‘™ğ‘–,ğ‘¡Ã—(ğ‘”â€²â€²ğ‘—,ğ‘¡âˆ’ğ‘Šâ€²â€²ğ‘–,ğ‘¡)ğ‘Ÿğ‘‘ğ‘–â‰¥ğ´ğœŒrandomotherwise.
(16)
The flight length ğ‘“ğ‘™ğ‘–,ğ‘¡ parameter signifies the magnitude of movement as of crow ğ‘Šâ€²â€²ğ‘–,ğ‘¡ toward the best position ğ‘”â€²â€²ğ‘—,ğ‘¡ of crow ğ‘—. The updation process type is ascertained by an awareness probability ğ´ğœŒ. Here, ğ‘Ÿğ‘‘ğ‘– indicates the random value ğ‘Ÿğ‘‘ğ‘–âˆˆ[0,1]. If ğ‘Ÿğ‘‘ğ‘–â€‰â‰¥â€‰ğ´ğœŒ, behavior 1 is applied, otherwise situation two is chosen. But the random movement directly influences this updation process. This random movement may lead to weights that can be very low or high. This can lead to the problem of vanishing gradient (or) exploding gradient. So, Brownian motion is employed here instead of random movement. For this modification, this algorithm is termed as â€˜Modified CSâ€™. The weight optimization of MCS is computed as,

ğ‘Šâ€²â€²opm=â§â©â¨âªâªâªâªğ‘Šâ€²â€²ğ‘–,ğ‘¡+ğ‘Ÿğ‘‘ğ‘–Ã—ğ‘“ğ‘™ğ‘–,ğ‘¡Ã—(ğ‘”â€²â€²ğ‘—,ğ‘¡âˆ’ğ‘Šâ€²â€²ğ‘–,ğ‘¡)ğ‘Ÿğ‘‘ğ‘–â‰¥ğ´ğœŒğ‘Šâ€²â€²ğ‘–,ğ‘¡+âˆ«0ğ‘¡maxğ‘”â€²â€²ğ‘—,ğ‘¡dğ‘¡otherwise.
(17)
Here, ğ‘Šâ€²â€²opm is the optimized weight value.

Hidden layer Here, the input ğ¹â€²â€²opm values and optimized weight values ğ‘Šâ€²â€²opm are individually multiplied and then those values are totally summated.

ğ»ğ‘–=âˆ‘ğ‘–=1ğ‘ğ¹â€²â€²opmğ‘Šâ€²â€²opm,
(18)
where ğ»ğ‘– is the HLâ€™s output value.

After inputting to the HL, the activation function (AF) is determined. It is mathematically evaluated as,

AF=ğ‘“(âˆ‘ğ‘–=1ğ‘›ğ¹â€²â€²opmğ‘Šâ€²â€²opm).
(19)
The AF type utilized in this DNN is the Gaussian function.

ğ‘“(ğ‘…)=ğ‘’âˆ’ğ¹â€²â€²2opm=AFğ‘–.
(20)
The AF of a node proffers the output of that node that is given in the form of the input or set of inputs. The output of first HL is expressed as,

ğ»(ğ‘œ)1=ğ‘ğ‘–+âˆ‘AFğ‘–ğ‘Šâ€²â€²opm,
(21)
where, ğ‘ğ‘– is the bias value of the HL, AFğ‘– is the values modified by the application of the AF.

Here, the above 'three' steps are executed for each DNN layer.

Output layer The output unit is lastly evaluated. Here, the entire input signalsâ€™ weights are added for attaining the output layer neuronsâ€™ value,

ğ‘‚(ğ‘œ)ğ‘–=ğ‘ğ‘–+âˆ‘ğ»(ğ‘œ)ğ‘–ğ‘Šâ€²â€²ğ‘—.
(22)
Here, ğ»(ğ‘œ)ğ‘– is the value of the layer that precedes the output one, ğ‘Šâ€²â€²ğ‘— is the weights of the HL, ğ‘‚(ğ‘œ)ğ‘– is the classifier output unit.

The MCS-DNN could be detailed using pseudo-code proffered in Fig. 6.

Fig. 6
figure 6
Pseudo-code of MCS-DNN

Full size image
By utilizing Eq. (22), the MCS-DNN ascertains whether the website is phishy or a legitimate one. KCV is performed for ascertaining the modelâ€™s accurateness.

K-fold cross-validation
It stands as the very last step involved in implementing the proposed system and is done for statistically evaluating the results. In addition, this step finds the degree of prediction accurateness of this model. It targets to scrutinize the competency of the proposed system in forecasting the new data that are not deployed during estimation.

A single round of KCV technique involves arbitrary division of the data set into ğ‘˜ folds or groups of approximately equal size. The first fold is regarded for testing and the model is trained on ğ‘˜âˆ’1 folds. Fit a proposed model on a training set and assess it on a test set. Re-execute the process ğ‘˜ times, and each time, disparate fold or group of data points are utilized for validation. For diminishing the variability, the proposed system employs a 'tenfold cross-validation'. By executing the process ğ‘˜ (ğ‘˜=10) times, ğ‘˜ times Mean Square Error (MSE) is attained as MSE1,MSE2,â€¦,MSEğ‘˜, so KCV error is evaluated by computing an average of those MSE over ğ‘˜ folds,

CV(ğ‘˜)error=1ğ‘˜âˆ‘ğ‘˜=110MSEavg.
(23)
Here, CV(ğ‘˜)error is the cross-validation error, MSEavg is the average of the MSE over ğ‘˜ folds.

CV(ğ‘˜)error is computed for estimating the analytical performance proffered by the proposed model. The higher CV(ğ‘˜)error value causes the model to lose its predictive performance.

Experimental results
Here, the performance rendered by the proposed algorithms for disparate datasets is discussed for the detailed evaluation. The proposed PDSis employed in JAVA with the succeeding machine configuration,

OS: Windows 7

Processor: Intel i5/core i7

RAM: 4GB

CPU Speed: 3.2GHz

Data collection
For validating the proposed PDSâ€™s effectiveness, the experiments were made by collecting the data sets containing both legitimate and phishing websites. For this implementation, the Phishing Websites-Dataset #1 and -Dataset #2 are gathered from the publicly available University of Huddersfield website. These datasets comprise â€˜30â€™ URL features, which are taken as of various legitimate as well as phishing URLs.

Performance analysis of MCS-DNN
Here, the proposed MCS-DNN's detection level is determined by contrasting the proposed PDS and the existing (a) adaptive network-based fuzzy inference system (ANFISs), (b) k-nearest neighbor (KNNs), (c) artificial neural network (ANN), as well as (d) support-vector machine (SVMs) techniques under 'nine' disparate quality metrics like True Positive Rates (TPRs), True Negative Rate (TNR), FPR, FNR, Mathews correlation coefficient (MCC), precision, accuracy, F-score and recall. These metrics are evaluated centered on parameters like (1) true positive (ğ‘¡(ğ‘)), (2) true negative (ğ‘¡(ğ‘›)), (3) false positive (ğ‘“(ğ‘)), together with (4) false negative (ğ‘“(ğ‘›)). For a better system, ğ‘“(ğ‘) should be minimum and ğ‘¡(ğ‘) should be maximum.

TPR: The rate of correctly detected phishing websites.

TPR=ğ‘¡(ğ‘)ğ‘¡(ğ‘)+ğ‘“(ğ‘›).
(24)
TNR: It is regarded as the rate of correctly detected legitimate websites.

TNR=ğ‘¡(ğ‘›)ğ‘“(ğ‘)+ğ‘¡(ğ‘›).
(25)
FPR: It is evaluated by dividing the number of legitimate websites categorized as phishing by the entire legitimate websites.

FPR=ğ‘“(ğ‘)ğ‘“(ğ‘)+ğ‘¡(ğ‘›).
(26)
FNR: It is evaluated by dividing the incorrectly predicted phishing sites by the total phishing sites.

FNR=ğ‘“(ğ‘›)ğ‘¡(ğ‘)+ğ‘“(ğ‘›).
(27)
MCC: It is basically a correlation coefficient of the predicted and observed binary classifications.

MCC=ğ‘¡(ğ‘)ğ‘¡(ğ‘›)âˆ’ğ‘“(ğ‘)ğ‘“(ğ‘›)((ğ‘¡(ğ‘)+ğ‘“(ğ‘))(ğ‘¡(ğ‘)+ğ‘“(ğ‘›))(ğ‘¡(ğ‘›)+ğ‘“(ğ‘))(ğ‘¡(ğ‘›)+ğ‘“(ğ‘›)))1/2.
(28)
precision: The rate of correctly detected phishing websites in respect of all websites which are recognized as phishing.

precision=ğ‘¡(ğ‘)ğ‘¡(ğ‘)+ğ‘“(ğ‘).
(29)
recall: The percentage of predicted phishing websites versus all presented phishing websites.

recall=ğ‘¡(ğ‘)ğ‘¡(ğ‘)+ğ‘“(ğ‘›).
(30)
accuracy: The rate of correctly detected websites.

accuracy=ğ‘¡(ğ‘)+ğ‘¡(ğ‘›)ğ‘¡(ğ‘ ).
(31)
ğ¹{-}score: It is evaluated by taking the harmonic mean of the recall as well as the precision.

ğ¹{-}score=2Ã—precisionÃ—recallprecision+recall.
(32)
The MCS-DNN's performance is subsequently evaluated using datasets like Phishing Websites-Dataset #1 as well as -Dataset #2. The parameter values of the proposed method are depicted in Table 2.

Table 2 Parameters and its values
Full size table
Performance evaluation of MCS-DNN with Dataset #1
In this section, the MCS-DNN performance evaluation is carried out using Dataset #1. The performance is evaluated centered on the aforesaid metrics. Data ranging as of 100 to 500 are taken for evaluation. The performance rendered by various phishing detection approaches is evaluated in respect of the 100 to 500 data and is proffered in Fig. 7.

Fig. 7
figure 7figure 7
Performance analysis of proposed and existing techniques with Dataset #1

Full size image
Figure 7a evaluates the performance rendered by the proposed and existing classifiers concerning the recall, F-score, precision, accuracy, FPR, FNR, and MCC for data set #1. For 100 data, the MCS-DNN has 93.52% precision. In the precision analysis, the existing ANFIS renders low precision contrasted to the other techniques. Concerning the recall, the proposed MCS-DNN has 94.32%, whereas, the existing ANFIS, KNN, ANN, and SVM have 86.33%, 88.63%, 93.12%, and 90.25%, respectively, which are lower when contrasted to the proposed MCS-DNN. Likewise, the proposed MCS-DNN attains 95.63% accuracy and 93.65% F-measure, 91.25% TPR, 92.36% TNR, and 92.32% MCC which is higher when contrasted to the exiting techniques. Accuracy is an imperative measure in all attack detection systems. Hence, the proposed MCS-DNN spots the attacks accurately than other techniques. In terms of other metrics, the proposed method attained 94.32% of recall, 93.65% of F-score, 92.3658% of TPR, 92.3654% of TNR, and 92.3256% of MCC while the other considered methods attained inferior values. These 'seven' metrics are computed for 500 data as proffered in Fig. 7b. Also, the proposed MCS-DNN proffers preeminent performance on considering other techniques for 500 data that is confirmed as of the values of 93.24%, 95.12%, 94.32%, 96.54%, 91.25%, 96.2657%, and 93.2541% for precision, recall, F-score, accuracy, TPR, TNR, and MCC, respectively.

The FNR and FPR of the existing and proposed techniques for data set #1 are provided in Fig. 7c, d. Here, the performance evaluation is done for 100 and 500 data. The proposed MCS-DNN has FNR 6.21% (for 100 data) but the existing ones have eminently higher values when contrasted to the proposed technique's FNR value. The higher FNR values degrade system performance. Hence, it is perceived that the proposed MCS-DNN has a top-level performance. Likewise, for FPR value analysis, the proposed one has a lower FPR value. The MCS-DNN has FPR 4.21%. For 500 data, the proposed MCS-DNN renders a lower FPR of 4.32% and FNR of 4.98% on considering other techniques, which is proffered in Fig. 7d. Therefore, it is inferred that the proposed MCS-DNN exhibits substantial improvement in considering the existing PDS.

Performance evaluation of MCS-DNN with Dataset #2
In this section, the performance rendered by the proposed technique is evaluated using dataset #2. The same metrics, which are calculated in dataset #1, are calculated for this dataset.

Figure 8a, b evinces the performance rendered by the proposed MCS-DNN and the existing KNN, SVM, ANFIS, and ANN-centered on recall, accuracy, F-score, precision, TNR, TPR, and MCC. Recall and precision made access to the classifierâ€™s performance on the minority class possible. These quantities are associated to the F-score. From Fig. 8a, the exiting ANFIS proffer low-level performance, which has 86.54% precision, 88.25% recall, 86.84% accuracy, 88.32% F-score, 79.85% TPR, 81.32% TNR, and 63.12% MCC but the proposed one attains 94.35% precision, 96.58% recall, 96.32% accuracy, 94.35% F-score, 93.64% TPR, 94.32% TNR, and 93.65% MCC. And also on considering the existing ones, proposed MCS-DNN has a higher recall, F-score, precision, accuracy TPR, TNR, and MCC values. Thus, it is perceived that the proposed MCS-DNN rendered an excellent outcome for all mentioned measures when contrasted to the existing phishing detection approaches. For 500 data, the proposed method attained 97.87% of accuracy, 95.35% of precision, 96.85% of recall, 96.35% of F-score, 93.87% of TPR, 96.85% of TNR, and 92.36% of MCC while the ANFIS proffers low-level performance, which has 88.12% of accuracy, 87.32% of precision, 88.12% of recall, 88.12% of F-score, 83.65% of TPR, 85.63% of TNR, and 65.96% of MCC. From the analysis, it is known that the proposed works showed superior performance to other existing methods.

Fig. 8
figure 8figure 8
Performance analysis of proposed and existing techniques with Dataset #2

Full size image
Figure 8c, d contrasted the performance proffered by the proposed MCS-DNN with the existing ANFIS, KNN, ANN, and SVM in respect of FNR and FPR. The low FNR and FPR values ameliorate system performance. It is perceived that the proposed attains 4.21% FPR, but the existing ANFIS, KNN, ANN, and SVM have 22.12%, 17.23%, 10.45%, and 12.78% FPR, respectively, which is higher when contrasted to the proposed FPR. For FNR, the proposed MCS-DNN has only 5.78%, but the exiting techniques have higher FNR than the proposed one. This analysis is displayed in Fig. 8c for 100 data. On analyzing Fig. 8d existing approaches have a high FNR of 4.21% and FPR of 3.05% than the proposed MCS-DNN for 500 data. Consequently, it is inferred that the proposed MCS-DNN has attained higher performance when contrasted to the existing ones.

Similarly, the performance rendered by the proposed and existing technique for 200, 300, and 400 data is analyzed. The proposed MCS-DNN gives preeminent results and the existing ones offer poor performance under all 200, 300, and 400 data.

Performance analysis of CM-WOA
From the group of features, a random feature is selected together with given to the classifier. The finest accuracy offered by the random feature in a particular number of iteration is termed fitness. Here, the proposed CM-WOA algorithm is contrasted to â€˜fourâ€™ popular optimization algorithms: ant bee colony (ABC), particle swarm optimizations (PSOs), WOA, and genetic algorithm to confirm the proposed optimization methodâ€™s effectiveness. The fitness comparison in respect of the varying iteration is summarized using Table 3.

Table 3 Fitness comparison
Full size table
On examining Table 3, it is perceived that the proposed CM-WOA has the topmost fitness function. The higher fitness value signifies that the optimization approach is extremely efficient to pick the wanted features as of the dataset. Proposed CM-WOA gives fitness level of 61 for five iterations, where the traditional approaches like ABC, PSO, GA, and WOA render fitness levels of 31, 36, 42, and 55, respectively, which is less on considering the proposed CM-WOA. For 10, 15, 20, and 25 iterations, the proposed one has 76, 85, 94, and 103 fitness values, respectively. The existing techniques have low fitness values than CM-WOA. Thus, it is perceived that the proposed CM-WOA renders a better fitness value when contrasted to other optimization approaches.

Conclusion
The paper proposed a neural network-centered PDS in an effectual manner. This work aims to utilize significant features for enhancing the detection accuracy and designing an automated, complete, real-time PDS. Pre-processing, clustering, features selection, classification, and KCV are the phases embraced in the proposed PDS. Each phase utilizes disparate algorithms for accurate phishing detection. The performance shown by the proposed MCS-DNN classifier is contrasted to the existing ANN, KNN, and SVM techniques centered on some metrics like recall, accuracy, F-score, precision, FNR, TNR, FPR, MCC, and TPR. The experiment outcomes evinced that the proposed methods rendered a better accuracy level on considering the existing techniques, and it attained 96.54% classification accuracy with low FPR of 4.320% for dataset #1 and yielded 96.32% classification accuracy with lower FPR of 3.05% for dataset #2. The proposed PDS is more accurate, efficient, and stable when contrasted to the previous phishing detection approaches. More features can well be embraced in the proposed PDS model in the future to accomplish better performance.