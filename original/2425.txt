Concrete is one of the most essential construction materials used in construction industry. For assessment of concrete strength and quality, compressive strength is the most frequently utilized parameter. This paper establishes the application of Gaussian process, M5P model, random forest and random tree techniques for appropriate proportioning of the concrete mixes. The models proposed were based on six input parameters, namely cement, sand, coarse aggregate, water, curing period and fineness modulus, while the compressive strength was an output parameter. Five most popular statistical parameters such as Pearson correlation coefficient, mean absolute error, root mean square error, Scattering Index and Nash–Sutcliffe model efficiency were used for the assessment of the developed models. On comparison, it was found that better results were achieved with Radial bases kernel function based Gaussian process regression model as compared to other applied models. The suggested models are expected to save cost of materials, cost of labor work, time and contribute to greater accuracy. The concrete designed is anticipated to have more durability and therefore be more economical.

Introduction
Concrete is the most extensively utilized construction material in the construction industry which comprises a mixture of paste and aggregates. Due to its flow ability in utmost complex form and its strength development-related features after hardening, concrete is said to be a complex mix. In concrete mix design and quality control, the compressive strength of concrete is considered as the most important and frequently used property. The compressive strength is influenced by a number of factors such as the type of material used, environmental factors, type of method employed for its manufacturing and others. It is based on the principles of workability of fresh concrete, required strength and durability of hardened concrete. The strength of the concrete is determined by the characteristics of the mortar, coarse aggregate and the interface. Forecasting of the accurate compressive strength of concrete is a relatively tough task to model. The most accurate ways of determining the concrete strength are the destructive methods in which cube or cylindrical samples are prepared from fresh concrete or core samples extracted from structural concrete, but they too have their own limitations. Generally, the compressive strength of concrete is taken on 7th, 21st and 28th days from the date of placing the concrete, but the standard is taken at 28th day.

In the recent years, artificial intelligence has established its competency in simulating and forecasting the behavior of various physical phenomena in most of the engineering fields such as civil engineering, computer science, information technology, electronics, aerospace and others. Various artificial intelligence techniques such as artificial neural network (ANN), fuzzy logic (FL), genetic algorithm (GA), M5P models, random tree, random forest, ANFIS, support vector machines (SVM), genetic programming and others have become very popular and widely used by many researchers throughout the world [1, 3, 5, 10, 12, 13, 15, 19,20,21,22, 27, 33, 35, 36, 38,39,40]. These days, artificial intelligence is getting more consideration from the building and infrastructure industry for aiding the decision-making process in the areas like diagnostics, design, maintenance, repair and rehabilitation. In concrete technology, design of concrete mix is a difficult and a complex process which required careful examination and proportioning of the materials used. Since the traditional method for determining the concrete mix design is based on uncertainty and expert ideas, artificial intelligence can be used for predicting the accurate results.

Researchers firstly have utilized classical regression techniques [13, 19, 33, 38, 39]. In the field of civil engineering, some authors have focused on hybridizing prediction techniques. Breiman [7] presented the use of random forests, SVM, ANN and discriminant analysis in his study. It was concluded from his study that random forests performed better in comparison with other techniques, such as SVM and ANN discriminant analysis, and also overcome the over fitting problem. Deepa et al. [11] conducted a study for the prediction of the compressive strength of high-performance concrete mix using tree based modeling such as random forests, random tree and M5 modeling techniques. To predict the compressive strength of concrete, Atici [3] had applied multiple regression analysis and ANN techniques. The results of the study showed that the ANN models performed better than multiple regression analysis models for finding out the compressive strength of concrete. Ali et al. [2] used the random forests and decision trees in their analysis and compared the results of the same. Mehdipour et al. [25] compared the various methods for statistical modeling of particulate matter in Iran. They utilized the decision tree method, Bayesian network and SVM methods for finding out the effect of particulate matter on human health in Tehran. Competences of the models were compared to each other, and the SVM was found to be the best performing model based on the evaluation criteria of the study. Singh et al. [32] estimated the compressive strength of high strength concrete by utilizing random forest and M5P model tree approaches. The results obtained from the study found that random forest regression was more accurate in comparison with the M5P model tree approach. Shabani et al. [29] utilized in their study four machine learning methods, namely Gaussian process regression (GPR), K-nearest neighbors (KNN), random forest (RF) and SVM, for predicting the pan evaporation which is one of the most crucial factors in hydrological, water resources, agricultural and meteorological studies. Chakraborty [9] used genetic programming approach to solid oxide fuel cell modeling and simulation. The accuracy of the methods was found out using the statistical indices of root mean squared error (RMSE), correlation coefficient (R) and mean absolute error (MAE).

The literature studies revealed that the data mining techniques have a suitable application in estimating the compressive strength of concrete in different conditions [10, 12]. Gaidhane et al., [18] compared the performance of support vector machine, linear and nonlinear regression and artificial neural network using cement strength data set collected from the cement industry for 2-day, 7-day and 28-day samples. The data in the present study have been obtained from various published creditable journals and researchers who have experimentally found the compressive strength of concrete with the varying input parameters [5, 15, 20, 21]. Accurate prediction of concrete compressive strength is an important issue and development of prediction models for this issue leads to saving time, costs, equipment and allow making a successful mixture. As such, in the present study the ability of four data mining methods, namely Gaussian process, M5P model tree, random forest and random tree, is studied in estimating the compressive strength at different ages of concrete and then the results of the four methods are compared.

Soft-computing techniques
Gaussian process (GP)
Gaussian process (GP) is a set of random variables, in which some variables have a multi-variable Gaussian distribution. The chief objective of GP is to develop systems that can predict variables on the basis of past experience or historical data. This technique is used widely in medicine, engineering, physical sciences, chemistry and others. GP is based on the probability that makes estimation of input data easier and gives accuracy for probable variances. The statistical significance of the prediction is elevated extensively by these estimated variances. GP can extend in vast dimensionality and produces data by using random domain of subset ranges. During the training process of GP models, the choice of the suitable covariance function and its parameters is important because the main role in the GP belongs to the covariance function which embeds the geometric structure of the training samples. For producing accurate estimates, the mean and covariance functions must be forecasted from the used data, known as hyperparameters [29, 31].

A GP is defined as a collection of random variables, any finite number of which has a joint multivariate Gaussian distribution. Let 𝜒×𝛾 represent the domains of inputs and outputs, respectively, from which n pairs (𝑥𝑖,𝑦𝑖) are drawn independently and identically distributed. For regression, assume that 𝑦⊆ℜ; then, a GP on 𝜒 is defined by a mean function 𝜇:𝜒→ℜ and a covariance function 𝑘:𝜒×𝜒→ℜ.

The main assumption of GP regression is that y is given by 𝑦=𝑓(𝑥)+𝜉, where 𝜉 N(0,𝜎2). The symbol ~ in statistics means sampling for. In GP regression, for every input x there is an associated random variable f(x), which is the value of the stochastic function f at that location. In this work, it is assumed that the observational error 𝜉 is normal independent and identically distributed, with a mean value of zero (𝜇(𝑥)=0), a variance of 𝜎2 and 𝑓(𝑥) drawn from the Gaussian process on 𝜒 specified by k. That is,

𝑌=(𝑦1,.......,𝑦𝑛)∼N(0,𝐾+𝜎2𝐈),
(1)
where 𝐾𝑖𝑗=𝑘(𝑥𝑖,𝑥𝑗), and I is the identity matrix.

Because 𝑌/𝑋∼N(0,𝐾+𝜎2𝐈) is normal, so is the conditional distribution of test labels given the training and test data of 𝑝(𝑌∗/.). Then, one has 𝑌∗/,, where.

𝜇=𝐾(𝑋∗,𝑋)(𝐾(𝑋,𝑋)+𝜎2𝐈)−1𝑌,
(2)
Σ=𝐾(𝑋∗,𝑋∗)−𝜎2𝐈−𝐾(𝑋∗,𝑋)(𝐾(𝑋,𝑋)+𝜎2𝐈))−1𝐾(𝑋,𝑋∗),
(3)
If there are n training data and 𝑛∗ test data, then 𝐾(𝑋,𝑋∗) represents the 𝑛×𝑛∗ matrix of covariances evaluated at all pairs of training and test data sets, and this is similarly true for the other values of 𝐾(𝑋,𝑋), 𝐾(𝑋∗,𝑋) and 𝐾(𝑋∗,𝑋∗); here X and Y are the vector of the training data and training data labels 𝑦𝑖, whereas 𝑋∗ is the vector of the test data.

A specified covariance function is required to generate a positive semi-definite covariance matrix K, where 𝐾𝑖𝑗=𝑘(𝑥𝑖,𝑥𝑗). The term of the kernel function used in SVM is equivalent to the covariance function used in GP regression. With the known values of kernel k and degree of noise 𝜎2, Eqs. (2) and (3) would be enough for inference.

During the training process of GP regression models, one needs to choose a suitable covariance function as well as its parameters. In the case of GP regression with a fixed value of Gaussian noise, a GP model can be trained by applying Bayesian inference, i.e., maximizing the marginal likelihood. This leads to the minimization of the negative log-posterior:

𝑝(𝜎2,𝑘)=12y𝑇(𝐾+𝜎2𝐈)−1y+12log∣∣K+𝜎2𝐈∣∣−log𝑝(𝜎2)−log𝑝(𝑘),
(4)
To find the hyperparameters, the partial derived of Eq. 4 can be obtained with respect to 𝜎2 and k, and minimization can be achieved by gradient descent. For more details about GP regression and different covariance functions readers are referred to Kuss [23].

M5P model tree (M5P)
M5P model tree uses linear regression, where continuous numerical attributes are anticipated. The model tree is generated in two stages, i.e., splitting and then removal of over-fitting. M5P is a regression-based decision tree algorithm and is formed using a divide-and-conquer method. It constructs a model tree which is navigated from top to bottom until one gets a leaf node. Based on the test condition at each node in the tree, a decision is taken for trailing a specific branch related with that node [17]. The tree is known as a model tree because of the fact that each leaf node comprises of a linear regression model for obtaining the predicted output [37]. M5P tree can be complex at times, and therefore, it may be pruned for simplifying purpose without losing its elementary functionality. The error is estimated for the linear model at every node, starting from the bottom of the tree to the top. The sub-tree for that particular node is pruned for which the error comes out to be less than the model sub-tree owned by the node itself. The splitting standard for the M5 model tree algorithm is based on treating the standard deviation of the class values that achieve to the node as a calculate of the error at that node, and measuring the accepted reduction in this error as a result of testing every attribute at that node. The method to calculate the standard deviation reduction (SDR) is:

SDR=sd(𝑀)−Σ|𝑀𝑗||𝑀|𝑠𝑠𝑑𝑑(𝑀𝑖)
(5)
where M represents a set of examples that reach the node; Mi represents the subset of examples that have the ith outcome of the potential set; and sd represents the standard deviation. The main advantage of M5Ps are that they are much smaller regression trees, the strength of the decision is clear, and the regression functions do not generally comprise of many variables [4, 14, 26, 32].

Random forest (RF)
A well-arranged collection of tree predictors created from input vectors using random vector samples is termed an RF approach. Different variables are arranged at each node to develop a tree using arbitrarily chosen input parameters. A training data set is drawn from randomly selected parameters for constructing particular trees and a Gini index used to measure the impurity of parameters compared to the output [8]. RF regression requires two pre-defined user variables, an input parameter (m) to be used at a separate node to produce a tree and the number of trees grown (k) [6]. The approach is based on hit and trial method, the variables being selected through the best split. RF method builds random forests by trapping a group of random trees [16]. It builds various individual classification trees using random samples of the data (i.e., bagging) and then find out the most popular class by voting [7]. RF is a hybrid of the bagging algorithm and the random sub-space method, and uses decision trees as the base classifier. This method is suitable for high-dimensional data modeling as it can handle missing values as well as continuous, categorical and binary data. There are various advantages of RF such as high accuracy in predicting the results, interpretable and nonparametric for various types of datasets. Accurate predictions and better generalizations are attained because of the use of collective strategies and random sampling. RF mostly shows a substantial performance enhancement in comparison with a single tree classifier. The discrepancy in the data is found out in an entirely different way on this method which is different from the usual distance functions [2, 16, 28,29,30].

Random tree (RT)
Decision tree algorithms are effective as they offer human-readable rules of classification. In the recent years, there has been an extensive research over random trees in the field of machine learning. Though, its use in the field of construction is still in its inception stage. Random tree is also known as a regression-based decision tree algorithm. In the RT process, trees that are built consider K randomly selected attributes at each node (without pruning). A random tree is a tree that is formed by a stochastic process. Additionally, this method has a choice of allowing the assessment of class probabilities (or target mean in case of regression) based on a hold-out set (backfitting) [16].

Performance evaluation parameters
In the training phase, once the essential accuracy was achieved, then the models were exposed to testing datasets. The performance of each model was assessed based on the Pearson correlation coefficient (CC), mean absolute error (MAE), root mean square error (RMSE), Scattering Index (SI) and Nash–Sutcliffe model efficiency (E) parameters [24].

CC=∑𝑛𝑖=1𝑥𝑖𝑦𝑖−1𝑛∑𝑛𝑖=1𝑥𝑖∑𝑛𝑖=1𝑦𝑖[∑𝑛𝑖=1𝑥2𝑖−1𝑛(∑𝑛𝑖=1𝑥𝑖)2]‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾√[∑𝑛𝑖=1𝑦2𝑖−1𝑛(∑𝑛𝑖=1𝑦𝑖)2]‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾√
(6)
RMSE=1𝑛∑𝑖=1𝑛(𝑥𝑖−𝑦𝑖)2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷
(7)
MAE=1𝑛∑𝑖=1𝑛∣∣𝑥𝑖−𝑦𝑖∣∣
(8)
𝑆𝐼=RMSE𝑥⎯⎯⎯𝑖
(9)
𝐸=1−∑𝑛𝑖=1(𝑥𝑖−𝑦𝑖)2∑𝑛𝑖=1(𝑥𝑖−𝑥⎯⎯⎯𝑖)2
(10)
Here, n = number of observations; xi and yi are observed and estimated values; and 𝑥⎯⎯⎯𝑖 is the mean of observed values.

The collective utilization of CC, RMSE, MAE, SI and E offers a suitable assessment of each model’s performance and permits a comparison of the precision of the modeling techniques used in the present study. Additionally, Taylor diagrams were employed in the present study for inspecting the accuracy of the implemented models.

Database
A total of 165 experimental observations were used for this study. Experiments were carried out in Material testing Laboratory, Amity University, Gurugram, India. The total data set was divided randomly into two dissimilar parts, i.e., training and testing dataset. The larger part having 113 observations was used for the model development (training), and the smaller part consisting of 52 observations was used for validation of the developed models (testing). The main input data comprise the following parameters for the prediction of the compressive strength of concrete:

Cement

Sand

Coarse aggregates

Water

Curing period

Fineness modulus

Cement (kg/m3), sand (kg/m3), coarse aggregates (kg/m3), water (mL), fineness modulus and curing period (days) are independent variable so, these are selected as input variables, whereas compressive strength (MPa) is considered as output in model development and validation process. The compressive strength testing was performed at 7 days and 28 days of curing after casting.

To compare the performance of different modeling approaches, various performance evaluation parameters were considered using the testing dataset. The predictive performance various models depend on the choice of the optimal value of user-defined parameters. A large number of trials were carried out to find the optimal value of different user defined parameters by comparing the values [correlation coefficient (CC), root mean square error (RMSE), and mean absolute error (MAE)] with test dataset using various algorithms.

The minimum and the maximum values of the parameters, i.e., the range and features of both the training and testing datasets, are extracted using Excel software and illustrated in Table 1.

Table 1 Statistics of the data used in the model development and validation process
Full size table
Results and discussion
Model development process in GP model is a trial and error process. Large number of trial were performed for the optimum model development. In this study, three different kernel functions were used for model development (Poly kernel function (Poly), Pearson VII kernel function (PUK) and radial basis kernel function (RBF)) and the data are presented in Table 1. Gaussian noise (0.1) was kept constant for the fair comparison among all the kernel function-based models. It can be seen that based on the obtained results (Table 2), the RBF kernel function GP model is working better than Poly and PUK kernel function-based models for the prediction of compressive strength of concrete (MPa). To examine the accuracy of the developed models, agreement plots for both training and testing periods are shown in Fig. 1. Five most popular statistical performance evaluation parameters were used for the assessment of the developed models. Result of performance evaluation parameters (CC, MAE, RMSE, SI and E) concludes that RBF kernel function-based model is outperforming than other applied models. The higher the value of CC and E, the lower the values of MAE, RMSE and SI, indicating that model is better performing than other applied models. The CC values of RBF, Poly and PUK kernel functions-based GP models were attained 0.9364, 0.9686,0.9762 for training period and 0.9160, 0.8620, 0.8964 for testing period, correspondingly. Figure 1 shows that predicted values using RBF kernel function-based model lies closer to the line of perfect agreement than other GP-based models in testing stage. Assessing Table 2 and Fig. 1 concludes that GP_RBF model is more appropriate than other kernel functions-based GP models for predicting the compressive strength of concrete (MPa).

Table 2 Performance evaluation parameters of applied models using training and testing data sets
Full size table
Fig. 1
figure 1
Agreement plot among actual and predicted values of GP-based model: a training data set and b testing data set

Full size image
RF-, RT- and M5P-based model development is a similar process of GP-based model development. All these models are tree-based models. Figure 2 shows the plot among actual and predicted values of compressive strength of concrete (MPa) using RT- and RF-based model for both training and testing stages. The results of performance evaluation parameters of RF and RT- and M5P-based models are presented in Table 2. RF-based model performs better than RT- and M5P-based models with CC = 0.8960, MAE = 2.1212, RMSE = 2.7184, SI = 0.1078 and E = 0.8381 for testing stages, respectively. From Fig. 2 and Table 2, the overall performance of RF-based developed model is superior to M5P (CC = 0.8362, MAE = 2.6397, RMSE = 3.3675, SI = 0.1322 and E = 0.6974) and RT (CC = 0.8714, MAE = 2.4219, RMSE = 3.0743, SI = 0.1222 and E = 0.7478) for testing stages-based models for predicting of compressive strength of concrete (MPa) for this data set.

Fig. 2
figure 2
Agreement plot among actual and predicted values of RF-, M5P- and RT-based models: a training data set and b testing data set

Full size image
Comparison among applied models
Last few years soft computing methods are successfully used in several engineering-related fields such as aerospace, civil, mechanical, information technology, computer science and others. In this study, the performance of GP- and tree-based models was assessed for predicting the compressive strength of concrete (MPa). The development of soft-computing-based model is purely based on the past data accuracy. The performances of all the models are listed in Table 2 for both training and testing stages. The performances of all applied models in terms of statistical performance evaluation parameters are shown in Fig. 4 and 5 using testing data set. Agreement plots, performance and relative error plots are drawn in Fig. 3 for the comparison of all applied models using training and testing data sets. Figures 3, 4 and Table 2 conclude that GP_RBF-based model works better than other aforementioned models. Figure 4 (a) shows that GP_RBF-based model has higher value of CC, E, and Fig. 4b, c indicates that GP_RBF-based model has lower value of MAE, RMSE and SI as compared to other above-mentioned models. In Fig. 5, uncertainty analysis plot is shown and this figure indicates that GP_RBF-based model is performing better than other above-mentioned models with lower uncertainty in errors. In tree-based models, RT-based model works better than M5P-based model with CC = 0.8714, MAE = 2.4219, RMSE = 3.0743, SI = 0.1222 and E = 0.7478 for testing stage. In Gaussian process, PUK kernel function-based model performance is better than Poly kernel function-based GP model with CC = 0.8964, MAE = 2.1500, RMSE = 2.7337, SI = 0.1094 and E = 0.8006 in the prediction of compressive strength of concrete.

Fig. 3
figure 3
Performance of all applied models for the prediction of compressive strength of concrete: a training, b testing, c performance and d relative error

Full size image
Fig. 4
figure 4
Performance evaluation parameters of all applied models using testing data set: a CC and E, b MAE and RMSE and c SI

Full size image
Fig. 5
figure 5
Uncertainty in errors of all applied models using testing data set

Full size image
For the deep evaluation of the obtained results, box plot (Fig. 6) was plotted, in which overall error distribution was shown. As a result, the negative and positive error values correspond to the over-estimation and under-estimation behavior of the models, respectively. The interquartile range in Fig. 6 indicates that the error is centered on zero. The values of minimum error, median, maximum error, first quartile and third quartile are listed in Table 3 for all applied models. The lower quartile value in the GP_RBF is -0.7692 which is lower than all other discussed models. On the other hand, in upper quartile (Q75), the GP_RBF with Q75 = 1.3713 performed better than other discussed models. It can be seen in Fig. 6 and Table 3 that the maximum and minimum errors in GP_RBF model were -6.9190 and 5.4220, respectively, which verify the capacity of GP_RBF to predict compressive strength of concrete. Lower box width in the GP_RBF models confirms the maximum errors around the zero. Figure 7 shows the Taylor's diagram for all applied models. Taylor diagram was used to illustrate schematically the performance of the applied models [34]. Three statistic parameters including standard deviation, correlation and RMSE, evaluated the degree of compliance of compressive strength of concrete among actual and predicted values. Figure 7 suggests that GP_RBF model achieves higher correlation with minimum RMSE values. Taylor diagram also confirms that GP_RBF model is performing better than other applied models.

Fig. 6
figure 6
Box plot of applied models error distribution using test data set

Full size image
Table 3 The values of minimum error, maximum error, first quartile, third quartile, median and mean errors
Full size table
Fig. 7
figure 7
Taylor diagram showing a statistical comparison of the above-mentioned models in the prediction of compressive strength of concrete (MPa)

Full size image
The present computational analysis confirmed the formulated research hypothesis that the performance of all respective soft computing models remained satisfactory during the training and testing stages, but the most important outcome from this study was that GP_RBF-based model outperformed other models. Results of proposed models are helpful in designing the appropriate mix design which achieves desirable strength. Proper knowledge of compressive strength of any concrete is necessary for economical and safety aspect of the structure. Experimentally estimation of strength is very time-consuming, tedious, laborious and costly, whereas proposed models give us exact values within reduced time. Even, there will be no need to carry out mechanical testing for the strength. These soft computing-based models are simple, and their running time is also very less as compared to mathematical calculation or experimental observation.

Conclusion
Concrete plays a very important role in the construction industry, and determination of its strength-related properties becomes vital for assessing the quality of concrete. With this aim, the present study was conducted on a sample of 165 dataset using various soft-computing techniques such as random forests, random tree, M5P method and Gaussian process. Result of performance evaluation parameters, i.e., CC, MAE, RMSE, SI and E, concludes that RBF kernel function-based model is outperforming than other applied models in Gaussian process. On assessing the data and the results, it was found that GP_RBF model is more appropriate than other GP models for predicting the compressive strength of concrete (MPa). On comparison of the various tree models, it was concluded that RF-based model performs better than RT and M5P-based models with CC = 0.8960, MAE = 2.1212, RMSE = 2.7184, SI = 0.1078 and E = 0.8381 for testing stages, respectively. On further comparison of all the models, i.e., GP, RF, RT and M5P models, it was found that GP_RBF-based model works better than others. GP_RBF-based model has higher value of CC, E and lower value of MAE, RMSE and SI as compared to other models. In the uncertainty analysis plot GP_RBF-based model is performing better than others with lower uncertainty in errors. In tree-based models, RT-based model works better than M5P-based model. In Gaussian process, PUK kernel function-based model performance is better than Poly kernel function-based GP model in the prediction of compressive strength of concrete. The results of the study also suggest that GP_RBF model achieves higher correlation with minimum RMSE values. Taylor diagram also confirms that GP_RBF model is performing better than other applied models. Hence, it is concluded that the proposed models reduce design cost and save time as well as money for the trial experiments for finalizing the material to achieve desire strength.