Mango leaf diseases have a negative impact on mango quality and yield. It is difficult to make an accurate diagnosis of mango leaf disease diagnosis with the naked eye. A lot of computer-aided and machine learning techniques have recently been used by researchers for the classification of mango leaf diseases. However, it has been reported that these approaches have some limitations to their performance which can be attributed to problems due to higher feature dimensionality, overfitting, computational complexity, and lack of feature qualities. To overcome these issues, we proposed a novel framework for mango leaves disease classification. The images were taken from Andhra Pradesh, the largest mango cultivating land in India. The proposed framework is categorized into four stages: data preparation stage, feature selection stage, learning and classification stage, and the performance evaluation stage. We selected 380 images from the categories of healthy and diseased (Mango Anthracnose, Bacterial black spot, and Sooty mold). Different data augmentation techniques are applied to prevent overfitting and improve generalization. Next, a convolutional neural network with crossover-based levy flight distribution is applied for better feature selection. Further, the pre-trained MobileNetV2 model is used for the learning stage and leaves diseases classification is done via support vector machine at the final stage of the MobileNetV2 model. The experimental results demonstrate superior classification performances over other state-of-art methods.

Introduction
Agriculture is the economic backbone of each country. In India, agriculture is growing rapidly and our economy majorly depends upon the cultivation and growth of crops. The Indian farmer cultivates different kinds of crops such as grains, vegetables, and fruits. Modern technology improves food yields and quality, but leaf diseases and the usage of more pesticides have reduced agricultural production[1]. The mango, whose botanical name is Mangifera indica, is one of the most popular fruits all over the world and particularly in India. Several pathological disorders, severe diseases, pesticide usages overwhelm the mango crop yields. Diseases in mango plant leaves can be caused by adverse climatic conditions, parasites, fungus, viruses, and bacteria. Mango plant diseases include Alternaria leaf spots, anthracnose, stem miner, mango malformation, Webber attack, red rust, powdery mildew, bacterial canker, phoma blight, dieback, and bacterial leaf spot [2]. The detection of mango leaf disease is carried out by agricultural experts on a regular basis.

The rust disease is visible in the bark of the young twigs and rusty red spots are mostly found on leaves, where the spots become velvety in texture and greenish-gray in color [3]. These kinds of diseases degrade mango quality and affect mango production. Plant disease is responsible for the majority of agricultural production losses, both in terms of quality and quantity. These losses impact the stakeholder's profit and production costs in agriculture. Based on the experiences, the plant pathologist and farmers detect and decide plant diseases using their eyes. Sometimes, it is biased and inaccurate in which early detection is the cure [4].

Early detection of mango leave disease and its prevention is a major challenging issue for farmers. Visual inspection is the most common method used by experts to recognize and categorize objects. Due to a lack of communication between experts and farmers, increased time consumption, and higher expense, visual inspection is inefficient for vast agricultural fields [5,6,7,8,9,10,11,12,13,14]. For mango leaf disease categorization, researchers [15,16,17,18,19,20,21] have provided a variety of advanced computer-aided techniques, deep learning techniques, artificial intelligence technologies, and machine learning approaches with optimization algorithms. These solutions provide a significant platform for mango plant enhancement, maintenance, management, disease identification, and productivity improvement [22].

Several shortcomings, including computational complexity, overfitting, increased time consumption, fewer feature considerations, a lack of feature quality, lower segmentation outcomes, and higher feature dimensionality leads to inaccurate mango leaf disease identification results. Hence, we proposed a novel framework for mango leaves disease classification, which involves four major stages such as data preparation, feature selection, learning with classification, and performance measure stage. The major contribution of this paper is summarized as below:

The four classes such as healthy, Mango Anthracnose, Bacterial black spot, and Sooty mold are chosen from the mango leaf images obtained from Andhra Pradesh.

Different kinds of image augmentation results are applied in which the original input image size 512√ó512 is resized into 256√ó256 pixels for better results.

The CNN architecture with CROLFD algorithm effectively selects the features from the mango leaves.

The MobileNetV2 and SVM perform better learning performance with mango leaf disease classification.

The rest of the paper is organized as follows: The related works are delineated in Sect. 2. Section 3 describes the proposed works followed by the application and result discussions in Sect. 4. Finally, Sect. 5 concludes the paper.

Review of related works
The neural network and support vector machine was proposed by Mia et al. [23] for mango leaf disease recognition. The symptom of mango leaf diseases is identified by developing a machine learning model. The experimental results demonstrate 80% accuracy, meet the demand of the global market, and increasing the production of mango. Different kinds of data were taken 100% left rotate, 120% right rotate, 140% up rotate, and 160% down rotate for matching the disease. They didn‚Äôt consider the color and texture base features, which lead to a lower recognition rate. Kumari et al. [24] proposed a back-propagation-based Discriminant classifier (BBDC) for mango fruit image classification. The fuzzy-based K-means clustering and maximally correlated principle component analysis (MCPCA) are used for segmentation and feature selection. The PCA extracts the color, texture, and geometric features. The BBDC classifies the poor quality mango, average quality mango, and good quality mango. While compared with existing methods, the BBDC yields 99.68% accuracy.

The advanced machine learning (ML) technique of the pre-trained VGG-16 deep learning model was proposed by Kusrini et al. [25]. The last layer with a fully connected network is supplemented by this deep learning model. For effective deep learning network training, the application of the data augmentation process addresses the sparsity of the dataset availability. The accuracy of 13.43% on the testing data is enhanced by augmenting the transformation function. Multilayer convolutional neural network (MCNN) was proposed by Singh et al. [26] to classify the Anthracnose disease-affected mango leaves. The dataset details were collected from Shri Mata Vaishno Devi University, India in which 1070 images are chosen for experimental evaluation. The MCNN model accomplished 97.13% accuracy, is cost-effective, and is computationally effective than other state-of-art approaches including radial basis function neural network (RBFNN), support vector machine (SVM), and particle swarm optimization (PSO).

The artificial neural network was carried out by Pham et al. [27] for early detection of mango leaves diseases. The image features are successfully selected with the help of a wrapper-based feature selection algorithm. The ANN outperformed better results than other CNN methods such as ResNet-50, VGG16, and AlexNet. Low-end devices such as smartphones implement this ANN model for mango leaves detection. An artificial intelligence technique was proposed by Nathaniel et al. [28] to identify the mango leaves disease. Moreover, the mango variety in the Philippines is classified by implementing K- nearest neighbor and fuzzy logic. The accurate identification results are ensured by applying necessary image processing methods to combine the mango plant leave images. This method involves image improvements to fit in favor of few morphological features analyzing and extracting from binary images including major leaf axis length and minor axis length.

Arivazhagan et al. [29] proposed a convolutional neural network for mango leaves disease identification. This CNN model effectively classifies five mango leave diseases including Leaf burn of Mango, Leaf Webber, Leaf Gall, Alternaria leaf spots, and Anthracnose thereby providing96.67% classification accuracy with better feasibility outcomes. The K-means and multiclass SVM algorithms were proposed by Srunitha et al. [30] in which the unhealthy mango leaves regions are effectively detected. The experimental result demonstrates a higher classification accuracy of 96.67% and speed. Nevertheless, the higher computational cost with the feature such are shape, color, and texture segmentation is complex.

Mishra et al. [31] introduced a wavelet transform-based segmentation and wavelet neural network model to classify mango leaf disease. This model needed fewer hidden nodes with a faster convergence speed, according to the results of the experiments. During convergence, this technique needed additional processing time. For mango leaf disease classification, Deeba et al. [32] suggested ResNet-based deep neural network architecture. The experimental analysis provided 98% classification accuracy. The accuracy was higher with a lower execution time, however, the computational cost is higher. The summary of the literary works related to mango leaf disease classification is delineated in Table 1.

Table 1 A summary of the approaches utilized in existing literary works to classify mango leaf diseases
Full size table
Proposed approach
This section reveals the mango leaves disease classification process. We have selected four kinds of mango leaves such as healthy, Mango Anthracnose, Bacterial black spot, and Sooty mold. Figure 1 explains the proposed architecture of mango leaves disease classification. The proposed method involves four major stages namely the data preparation stage, feature selection stage, learning stage, and classification stages. These steps are explained in the following section.

Fig. 1
figure 1
Proposed workflow diagram

Full size image
Data preparation stage
We have chosen 380 mango leaves samples for disease classification in which both healthy and unhealthy images were present in the samples. The healthy class consists of 80 samples and the remaining 300 samples are unhealthy class among 380 mango leaves samples. Most of the machine learning algorithms don‚Äôt handle the classification effectively [23, 25, 27]. After cutting each image, the healthy class samples are increased with random copying of a few images in which random copying never affects the CNN architecture to dataset overfitting [33]. The unhealthy mango leaves dataset is categorized into training, testing, and validation sets. Where, 70%, 15%, and the remaining 15% of samples are used for the training set, testing set, and validation set. The generalization improvement and overfitting reduction are carried out by increasing the number of training samples [27] thereby applying various augmentation techniques such as horizontal flip, vertical flip, zooming, shearing, shift, height, width shift, rotation, and brightness. Apply 512√ó512 input image size, which is 256√ó256 resized into pixels for further process.

Feature selection stage
After the data preparation stage, the transfer learning technique carries a similar structure to the pre-trained network. The CROLFD algorithm effectively handles the feature selection stage. The CNN architecture has few shortcomings in terms of image batch size, dropout layer rate, and the number of neurons in the dense layer during feature selection. But, the CROLFD algorithm effectively optimizes these hyperparameters such as image batch size, dropout layer rate, and the number of neurons in the dense layer [34]. The feature selection process handling using CROLFD algorithms steps delineate as follows:

CROLFD algorithm
Levy flight distribution algorithm
The inspiration and mathematical model of levy flight distribution (LFD) is explained in the following sub-section.

(i)
Inspiration

Several physical inspired and natural inspired phenomena inspire levy flights. The levy flight (LF) motion with wireless sensor networks environment is the major inspiration of the LFD algorithm. The resource searches efficiency is increased by showing LF in uncertain environments. For LF inspirations, the physically inspire phenomenon considers the diffusion of fluorescent molecules. When compared to the Brownian random walks, the LF is more effective in exploring unknown larger search spaces [35].

(ii)
Mathematical model

This section illustrates the mathematical modeling of LFD in which the Euclidian distance among every two adjacent nodes is calculated. According to the Euclidian distance, the LFD determines whether the sensor node is in its original location. The LFs model performs another position in which close to the sensor node the new position will place. Two characteristics such as step walk length and direction are generated for implementing LFs. Equation (1) express the step length S based on Mantegna‚Äôs algorithm [36].

ùêø=ùëÉ|ùëÑ|1/ùõæ
(1)
where ùõæ is the levy distribution tends to 0<ùõæ‚â§2 the interval in which ùëÉ and ùëÑ are explained as below:

ùëã‚àºùëÄ(0,ùúé2ùëã),ùëå‚àºùëÄ(0,ùúé2ùëå)
(2)
Equation (2) defines the standard deviations ùúéùëã and ùúéùëå.

ùúéùëã={Œì(1+ùõæ)√ósin(ùúãùõæ/2)Œì[(1+ùõæ)/2]√óùõæ√ó2(ùõæ‚àí1)/ùõæ}
(3)
ùúéùëå=1
(4)
The gamma function defines in Eq. (4) for an integer z.

Œì(ùëß)=‚à´0‚àûùëòùëß‚àí1ùëí‚àíùëòùëëùëò
(5)
The LFD algorithm calculates the ED among the initial two adjacent agents such as ùëåùëö and ùëåùëõ.

ùê∏ùê∑(ùëåùëö,ùëåùëõ)=(ùëåùëö‚àíùëåùëõ)2+(ùëçùëö‚àíùëçùëõ)2‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚àö
(6)
where the position coordinates of ùëåùëö and ùëåùëõ is (ùëåùëö,ùëçùëö) and (ùëåùëõ,ùëçùëõ). The Euclidian distance is compared to the given threshold until the agents reach the specified number of iterations. If the distance outcome is less than the threshold, Eq. (6) modifies the positions of the agents.

ùëåùëõ(ùëò+1)=ùêøùêπ(ùëåùëö(ùëò),ùëåLeader,ùëàùêµ,ùêøùêµ)
(7)
where k is the index for the number of iterations in which direction and step length of levy flights are executed with the usage of the LF function. Where,ùêøùêµ and ùëàùêµ are the lowest and highest boundary values based on 2D search space dimensions. The agent ùëåùëõ is moving toward the agent position by using Eq. (8).

ùëåùëõ(ùëò+1)=ùêøùêµ+(ùëàùêµ‚àíùêøùêµ)random()
(8)
The random function (random()) generates the random value in the interval [1]. To updates ùëåùëõ the position in the new search space region if there are no other agents.

ùëÖ=random(),ùëÜùêøùëâ=0.5
(9)
The comparative scalar value is ùëÜùêøùëâ and each update for the position ùëåùëõ is R. Updates the sensor node position ùëåùëõ in which each iteration evaluates R-values. By varying the algorithm solutions to enhance exploration ability.

ùëåùëö(ùëò+1)=ùëáùëÉ+ùëè1√óùëáùêπneighbours+random()√óùëè2√ó(ùëáùëÉ+ùëè3ùëåLeader)/2‚àíùëåùëö(ùë°))
(10)
ùëåNewùëö(ùëò+1)=ùêøùêπ(ùëåùëö(ùëò+1),ùëáùëÉ,ùëàùêµ,ùêøùêµ)
(11)
Equation (10) and (11) calculates the new position ùëåùëõ and the final position ùëåùëõ. The solution position ùëáùëÉ achieves the excellent fitness value in which the random numbers tend to the interval 0<ùõΩ1,ùõΩ2,ùõΩ3‚â§10. Here, ùëáùêπneighbours is the overall neighbor target fitness.

ùëáùêπneighbours=‚àëùëó=1ùëÄùëÄùê∏(ùëó)√óùëåùëóùëÄùëÄ
(12)
ùëáùêπneighbours=ùëÄùëñùëõ(ùê∏ùëüùëüùëúùëü)
(13)
In Eq. (12),ùëåùëó is the neighbor position ùëåùëö(ùëò). For each neighbor ùê∏(ùëó), ùëåùëó is the neighbor's position ùëåùëö(ùëò).

ùê∏(ùëó)=‚àÇ1(ùëÑ‚àíMin(ùëÑ))ùëÄùëéùë•(ùëÑ)‚àíMin(ùëÑ)+‚àÇ2
(14)
ùëà=ùêπùëñùë°(ùëåùëö(ùëò))ùêπùëñùë°(ùëåùëö(ùëò),0<‚àÇ1ùëéùëõùëë‚àÇ2‚â§1
(15)
Eqs. (1) to (15) are repeated in each iteration of the LFD algorithm for optimal outputs.

figure a
Crossover operator
According to the LFD algorithm, the Euclidian distance updates each solution position in the search process. The population diversity is maintained by a search mechanism. The LFD algorithm has few weaknesses due to lower convergence speed, lower balancing ability between exploitation and exploration, lower exploitation ability, and more processing time. The exploitation ability of LFD is improved by crossover the operation and the newly developed model is named crossover-based levy flight distribution (CROLFD). The differences are obtained by selecting two distinct random solutions ùëåùëòùëù,1=[ùëåùëòùëù1,1+ùëåùëòùëù2,1,...,ùëåùëòùëù1,ùëó.....ùëåùëòùëù2,ùê∏] and ùëåùëòùëù,1=[ùëåùëòùëù2,2+ùëåùëòùëù2,2,...,ùëåùëòùëù2,ùëó.....ùëåùëòùëù2,ùê∏]

ùëâùëòùëñ,ùëó=+random(0,1)√ó(ùëåùëòùëù1,ùëó‚àíùëåùëòùëù2,ùëó)
(16)
In Eq. (16), ùëìùëéùë¶ùëó represents the jth global optimal solution achieved, the mutant solution is represented as ùëâùêæùêº=[ùëâùëòùëñ,1,ùëâùëòùëñ,2,......,ùëâùëòùêºùëñ,ùëó,...,ùëâùëòùëñ,ùê∏], ùëñ=1,2,....,ùëÅùëÉ and ùëó=1,2,....,ùê∑. Equation (17) explains the CROLFD operation.

ùëåùëò+1ùëñ,ùëó={ùêøùêπ(ùëåùëö(ùëò+1),ùëáùëÉ,ùëàùêµ,ùêøùêµ),ùëñùëìrandom(0,1)<CRTùëìùëéùë¶ùëó+random(0,1)√ó(ùëåùëòùëù1,ùëó‚àíùëåùëòùëù2,ùëó)otherwise
(17)
where CRT is the rate of crossover that manages the inheriting probability from the new position. The CRT algorithm established the best exploration and exploitation ability than the LFD algorithm. The CROLFD algorithm effectively optimizes these hyperparameters such as image batch size, dropout layer rate, and the number of neurons in the dense layer. Algorithm 1 explains the CROLFD algorithm description for hyperparameters optimization.

Learning and classification stage
The MobileNetV2 is taken for the learning stage thereafter the optimal feature selection stage. One of the deep learning models and low hardware cost device used model is MobileNetV2, which is widely used for classification, segmentation, and object identification. The well-known model of MobileNetV1 develops the MobileNetV2 model. This MobileNetV2 model offers major contributions to the linearity issues among layers when compared to the MobileNetV2 model with the previous version. The problem is fixed in this version with shortcuts if linear bottlenecks occur between the layers. The blocks involved in MobileNetV2 architecture for the learning stage are depicted in Fig. 2. The input image size of 512√ó512 pixels and the in-depth activation maps present in the MobileNetV2 architecture contains extracted features, which are fed to the next layer. The MobileNetV2 model has pooling layers. The smaller dimension is the conversion of matrices obtained through these layers [37]. Here, we considered the MobileNetV2 model as a pre-trained MobileNetV2 model and support vector machine for leaf disease classification. Table 2 illustrates the parameters used for the pre-trained MobileNetV2 model.

Fig. 2
figure 2
Architectural design of MobileNetV2 model

Full size image
Table 2 Parameters of pre-trained MobileNetV2 model
Full size table
The commonly used machine learning model for classification and regression is the support vector machine (SVM). The feature in the data classes is separated by SVM hyperplane lines in the classification process. The line is determined by choosing the location away from the class features. According to the hyper-parameter determined, the SVM method measures each class distance in which the highest score of voting is fed to the labeled class.

Equation (19‚Äì21) shows the mathematical operations of SVM. In the hyper-plane, the feature coordinate points are expressed as Y and Z. Further, the bias and margin width values are denoted as b and w [38]. During each iteration, this SVM model provides a better and faster training process, lower cost and it randomly determines the images.

ùëà=ùëß‚Üí.ùë¶‚Üí‚àíùëé
(19)
12‚Äñ‚Äñùëß‚Üí‚Äñ‚Äñ2
(20)
ùë•ùëó(ùëß‚Üí.ùë¶ùëó‚Üí‚àíùëé)‚â•1,‚àÄùëó
(21)
Equation (22) expresses the extracted features in the Y and Z input images. Where the learning rate is ùõΩ [39].

Œòùëò=Œòùëò‚àí1‚àíùõΩ‚àáŒòùêº(Œò;ùë•ùëó,ùë¶ùëó)
(22)
Performance measurement stage
The proposed work performance is validated by using six performance measures such as accuracy, precision, recall, confusion matrix, and F1 score. One of the most remarkable criteria to evaluate the classification model is accuracy. Equation (23) shows the proportion among accurately categorized samples to the entire number of samples. The accuracy complement is the error rate. Equation (24) calculates the misclassified sample models [39].

ùê¥ccuracy=Truepositive+TruenegativeTruepositive+Truenegative+Falsepositive+Falsenegative
(23)
Rateoferror=1‚àíùê¥ccuracy
(24)
Hence, the positive or healthy mango leaves samples P and the positive or unhealthy mango leaves samples is N. The specificity and sensitivity equations are delineated as below:

ùëÜpecificity=TruepositiveTruepositive+Falsenegative
(25)
ùëÜensitivity=TruenegativeTruenegative+Falsepositive
(26)
The number of true positives and false positives divides the number of true positives in which Eq. (25) shows the precision. The rigor classifier measure considers precision. The larger numbers of false positives are indicated with low precision [40].

ùëÉrecison=TruepositiveTruepositive+Falsepositive
(27)
The number of positive class values in the test set divides the number of positive predictions. Equation (26) termed the recall measure in which several false negatives are indicated by using low recall.

ùëÖecall=TruepositiveTruepositive+Falsenegative
(28)
Equation (27) calculates the F-score which is the function of recall and precision. In terms of the prediction outcomes summary, the confusion matrix [41] depicts the classification problem.

ùêπ1score=2‚àóùëÉrecison‚àóùëÖecallùëÉrecison+ùëÖecall
(29)
Application and result discussions
In this section, the proposed mango leave diseases classification model performance is validated by using various kinds of evaluation criteria with a state-of-art comparison. The dataset details were obtained from Andhra Pradesh, which is one of the largest mango production places in India [42]. The leaf images were taken in an early stage when the appearance of blobs or discolorations was noted. Every image of the dataset was taken in a two-day difference avoiding the complex backgrounds and focusing on a single leaf per image. The Sony Alpha a6600 camera was set up to take these images. To remove the shadow of the leaves and other obstacles light sources were placed beside the camera. The mango leaves disease classification is executed in MATLAB software. This dataset consist of 380 mango leaves images belonging to four different types such as healthy, Mango Anthracnose, Bacterial black spot, and Sooty mold leaves. The camera captures the image with no background and in the resolution of 512√ó512 pixels under various lighting conditions. Table 3 describes the parameters involved in the proposed work.

Table 3 Parameters involved in proposed work
Full size table
Data augmentation results
The data augmentation results are discussed in this section. Initially, Fig. 3 depicts the sample dataset images with data augmentation results. The first row displays the original images for each category, while the second row expresses the data augmentation results for each image.

Fig. 3
figure 3
Sample dataset images with data augmentation results (first row-original images and second row-data augmented images); a healthy images b Mango Anthacnose, c Bacterial black spot and d Sooty mold

Full size image
Table 4 illustrates the data augmentation techniques with their ranges. Here, we have applies various kinds of data augmentation techniques such as horizontal flip, vertical flip, fill mode, featurewise standard deviation normalization, featurewise center, brightness, rotation, height shift, width shift, zooming, and shearing. Figure 4 explains the data augmentation against training data performances. The multi-class classification framework is carried out in which performance of classification against the training data quantity. Without the use of a data augmentation framework, the application of affine transform and contrast against the y-axis and x-axis resulted in a 13.43% improvement over the baseline evaluation. In multi-class classification, the best performance is achieved by evaluating the required quantity of training data. For every 80 images from the training dataset, the angle of rotation in the y-axis and x-axis is analytically performed. The dataset resultant was filtered against transpose images for each of the transformations and 88% classification performance is saturated. The performance of the multi-class classification framework is saturated as the amount of training data grows, forcing it to apply different angle modifications in order to achieve the lowest computation time.

Table 4 Data augmentation models with different ranges
Full size table
Fig. 4
figure 4
Data augmentation against training data performance

Full size image
Performance evaluation
The proposed work performance is validated using Fig. 5. Each class performance is depicted in Fig. 5a‚Äìd. The different number of iteration with each class accuracy performance is validated in this section. The training and validation accuracy is performed out of 350 iterations. For each experimental run, the graphical representation of training and validation accuracy of healthy, Mango Anthracnose, Bacterial black spot, and Sooty mold classes are as depicted in Fig. 5a‚Äìd, respectively.

Fig. 5
figure 5
Accuracy evaluation concerning different class; a Healthy images b Mango Anthracnose, c Bacterial black spot and d Sooty mold

Full size image
According to MobileNetV2, Table 5 delineates the Confusion matrix with performance measure values. This experiment is conducted for classes such as healthy, Mango Anthracnose, Bacterial black spot, and Sooty mold with different performance measures including accuracy, specificity, sensitivity, precision, recall, and F1-score. Best and optimal output values are obtained in each class. The confusion matrix values with four classes are plotted in Fig. 6. The green color represents the accuracy of each class.

Table 5 Confusion matrix with performance measure values based on MobileNetV2
Full size table
Fig. 6
figure 6
Confusion matrix performance with different classes

Full size image
The different classes with performance measure results are depicted in Fig. 7. Four classes including healthy, Mango Anthracnose, Bacterial black spot, and Sooty mold with precision, recall, and F1 scores are used for this experiment. The healthy images provide 96.52% recall, 100% precision, and 96.3% recall results. For Mango Anthracnose images, 98.42% recall, 92.40% precision, and 97.73% recall results are obtained. Similarly, the Bacterial black spot images accomplish 98.23% recall, 99.24% precision, and 98.23% F1-score results. Finally, we have obtained 97.34%, 97.35%, and 98.01% recall, precision, and F1-score values for Sooty mold images.

Fig. 7
figure 7
Different classes with performance measure results

Full size image
State-of-art comparison
Figure 8 illustrates the convergence performance Vs state-of-art methods. The state-of-art methods such as genetic algorithm (GA) [43], differential evaluation (DE) [43], modified firefly optimization (MFO) [44], whale optimization algorithm (WOA) [43], grasshopper optimization algorithm (GOA) [44], levy flight distribution (LFD) [45] and proposed crossover-based levy flight distribution (CROLFD). In all tested dimensions, the CROLFD algorithm exhibits good exploitation capability with optimal results for each function. Compared to other metaheuristic algorithms, the proposed CROLFD accomplishes optimal convergence performances with better exploitation results.

Fig. 8
figure 8
State-of-art comparison with convergence performances

Full size image
Figure 9 depicts the learning stage performance with the state-of-art comparison. Here, we have selected five state-of-art models including AlextNet [27], SqueezeNet [46], ResNet [27], VGG-16 [27] and proposed MobileNetV2 with precision, recall and F1-scores. The AlexNet yields 92% recall, 90% precision, and 89.01% F1-score results. Likewise, SqueezeNet provides 91.45% recall, 88.06% precision and 92.81% F1-score results. For ResNet, we have obtained 88.45% recall, 90.06% precision, and 89.40% F1-score results. The values of 90.56%, 82.05%, and 92.05% recall precision and F-score are achieved for VGG-16. Finally, the proposed MobileNetV2 provides 98.03% recall, 99.56% precision and 95.67% F-score values. Ultimately, the proposed MobileNetV2 model provides superior learning stage performances than other state-of-art methods.

Fig. 9
figure 9
State-of-art comparison of learning stage performance

Full size image
Figure 10 explains the classification performance concerning the state-of-art comparison. The evaluation criterions such as accuracy, specificity, and sensitivity with different methods such as NN and SVM [23], Deep learning model [25], MCNN [26], MSVM [30], and proposed model are used in this experiment. The MCNN method yields very low accuracy, specificity, and sensitivity result. The NN with SVM and MSVM provides superior classification performances than the other two methods such as deep learning and MCNN. Nevertheless, the proposed model accomplished higher and better classification results such as 94.5% accuracy, 99.81% specificity, and 97.34% sensitivity than other state-of-art methods namely NN with SVM, Deep Learning, MCNN, and MSVM.

Fig. 10
figure 10
State-of-art comparison of accuracy with classification results

Full size image
Table 6 explains the state-of-art comparison with classification performances. In this experiment, we have used NN with SVM [23], BBDC [24], ML [25], MCNN [26], ANN [27], CNN [29] and proposed method. Each method delivers better classification results in terms of mango leaves diseases. The proposed model achieves 94.5% accuracy, 99.81% specificity and 97.34% sensitivity, 98.03% recalls, 99.56% precision and 95.67% F1-score values. Finally, the proposed method accomplished superior classification performances in terms of each measure than exiting methods such as NN with SVM, BBDC, ML, MCNN, ANN, and CNN.

Table 6 State-of-art comparison with classification performances
Full size table
Conclusion
This article proposed a novel framework for mango leaves disease classification. The dataset images were collected from Andhra Pradesh which is the largest mango cultivation land in India. The MATLAB software is used for implementation works. Different kinds of data augmentation techniques such as horizontal flip, vertical flip, fill mode, featurewise standard deviation normalization, featurewise center, brightness, rotation, height shift, width shift, zooming, and shearing with different ranges are applied to the input image. The data augmentation is against training data performance. The four classes such as Healthy images, Mango Anthracnose, Bacterial black spot, and Sooty mold provided better classification accuracy with minimum computation time results. The proposed CROLFD algorithm accomplishes good exploitation with optimal results than existing meta-heuristic algorithms such as GA, DE, MFO, WOA, GOA, and LFD. According to the confusion matrix, the CROLFD-optimized MobileNetV2 obtains higher accuracy and better results. In terms of classification performance, the proposed method outperforms existing approaches such as NN with SVM, BBDC, ML, MCNN, ANN, and CNN. In future, we intend to use deep learning techniques in conjunction with an optimization model to increase classification speed and accuracy.

Keywords
Mango leaves
Convolutional neural network
MobileNetV2
Crossover-based levy flight distribution
Support vector machine
