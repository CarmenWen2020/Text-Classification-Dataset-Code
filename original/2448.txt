During the last decade, deep learning (DL) techniques have demonstrated the capabilities in various applications with a large number of labeled samples. Unfortunately, it is normally difficult to obtain such large amounts of samples in practice. As one of the most promising research directions of data generation in DL, generative adversarial network (GAN) can process not only images but also time-series signals. Unfortunately, it is easy to lose the time-dependence information from the latter due to characteristics of GAN, which increases the challenge of signal generation. Besides, the existing evaluation methods cannot evaluate the performance of GAN comprehensively. Therefore, this paper summarizes the current work of time-series signals generation based on GAN and the existing evaluation methods of GAN. As compared to existing GAN-related review work, this paper claims four unique points: (1) we specify the difficulties of GAN for time-series generation, particularly for the biological signal generation with potential solutions; (2) we analyze drawbacks of existing evaluation methods, and propose feasible solutions; (3) some suggestions are provided for the further research of robust time-series signal generation, especially for biological signal generation; (4) we provide a preliminary experiment to demonstrate the effectiveness of GANs for time-series signals generation, particularly, electroencephalogram (EEG).

Introduction
During the last decade, big data has been a hot topic arising with the explosive growth of informative data and the rapid development of network computing technology. It drives the further development of artificial intelligence (AI) [1, 2]; meanwhile, AI turns big data into knowledge or productivity, appearing in various different aspects of our lives, including computing [3, 4], medicine [5, 6], education [7, 8] and so on. Machine learning (ML) [9, 10], considered as the foundation of AI, is a multidisciplinary subject that specializes in how computers simulate learning behaviors from human to acquire new knowledge or skills and reorganize existing knowledge structures to improve their performance continuously. Unfortunately, traditional ML or shallow network models such as supporter vector machine (SVM), multilayer perceptron (MLP) normally struggles to process or learn big data due to its high temporal and spatial complexity [11], resulting in poor performance of AI. As the part of ML, deep network or deep learning (DL) [12] has been developed to handle such data and achieved huge success in different domains including brainâ€“computer interface (BCI) [13, 14], natural language processing (NLP) [15, 16], affective computing [17, 18], games [19, 20], and so on. However, such technology is heavily dependent on sample size, i.e., big data is necessary, and substantial computational efforts are needed to train models with huge capacity, whereas it normally takes a lot of efforts to obtain such amount of training samples, especially in medical and military fields [21]; on the other hand, the following two cases may still be considered insufficient amount of samples/small samples even if the size is large enough, i.e., big data: large amount of data but with small amount of targeting/expecting samples (meaningless/less features), for example, for identification of weak blood vessel in magnetic resonance angiography (MRA) images, due to its low proportion in such image, it is difficult for a ML-based model to be fully trained to identify such vessels even though the sample size is sufficient [22]; large amount of samples without labels or with small number of labels. Therefore, numerous methods have been developed on small sample size issue in another perspective including few-shot learning models [23,24,25,26,27] and generative models [28,29,30]. The former mainly consists of mode-based model [25], metric-based model [26], and optimization-based model [27], whereas the generative models generally encompass auto-regressive models, variational auto-encoding (VAE) [28], generative adversarial networks (GANs) [29] and flow-based models [30], as illustrated in Fig. 1.

Fig. 1
figure 1
A general picture of small sample methods for DL

Full size image
Comparably, generative models have become more favorable for data/sample generation and have demonstrated their usefulness in various fields, particularly on natural samples such as images [31,32,33,34,35,36,37], video [28,29,30,31,32,33,34,35,36,37,38,39,40], music [41,42,43], speech [44, 45] and other research fields such as medical images [46,47,48], security [49, 50], wearing collocation [51, 52], time-series prediction [53], and anomaly detection [54,55,56].

Among them, GAN and its variants provide an alternative approach to sample generation and have demonstrated their capabilities of coping with not only images [54,55,56,57,58] but also time-series signals related applications such as music [42, 59,60,61,62], speech [63, 64] and biological signal. However, there are still more challenging to generate time-series signals than images due to three reasons: (1) most of GANs are built via the Full Connection (FC) layer and 2DCNN. These network layers are unable to model the changes of time-series signals, which results in the generation of fake sample; (2) in the task of time-series signal generation, the output data of the generator are discrete, which result in inability to calculate the gradient directly; (3) traditional GANs may fail to capture characteristics of time-series signals and the complex correlation between the related attributes, which results in the loss of the time-dependence of real signals.

There are a number of approaches that can further evaluate quality of the generated signals and GAN models. The approaches consist of two parts: (1) evaluation based on empiricism and (2) evaluation based on computation. Usually, both will be combined to get the evaluation results. Part (1) is very useful for visual/audio signals that require human-level interaction and evaluation, e.g., images [34, 35], music [59, 60] and speech [63]. So far they have achieved promising results. It is one necessary step since they can directly filter the â€˜obviousâ€™ signals for reducing both risks of misleading and evaluation time. For other signals such as biological signals, there are also temptations [65,66,67,68,69] but without human-level interaction, this is due to the characteristics of the signals. For part (2), at present, commonly used evaluation methods include the probability distribution measurement [70, 71], quality measurement [72,73,74,75], and classification measurement [76, 77] by calculating the similarity, clarity and diversity of generative samples, respectively. Unfortunately, there is not individual method that is capable of providing a comprehensive solution, i.e., GAN cannot be evaluated efficiently.

In this paper, we mainly focus on the GAN-related methods for time-series signal generation and corresponding evaluation methods. As compared to existing GAN-related review work [21, 78,79,80,81,82,83,84], this paper highlights three unique points: (1) we mainly summarize the applications of GAN in time-series signals in recent years, especially in the complex biological signals, which enables the development of BCI systems using less subjects and better personalization; (2) we specify difficulties and causes of GANs for time-series signal generation, which may help to improve effectiveness and robustness of GANs; (3) we analyze drawbacks of existing evaluation methods for the signals, e.g., they are lack of capabilities of automatic combination and decision-making, which may help to improve evaluation methods, so as to better generative models.

The rest of the paper is structured as follows: in Sect. 2, various GANs on time-series signals are introduced. Existing evaluation techniques for the GANs are highlighted in Sect. 3. In Sect. 4, GANs and corresponding evaluation techniques are discussed based on time-series signals and followed by suggestions in future research work. Conclusive remarks are provided in Sect. 5.

GANs on time-series signals
The GAN proposed by Goodfellow et al. [29] is a novel framework inspired by the minimax game theory for generating models through adversarial process estimation. Basically, it consists of two parts: a generator (G) and a discriminator (D). The latter performs adversarial training based on real samples and the former generates new samples by capturing the distribution of the real samples. GAN has been applied in various fields due to its capabilities of reliable model generation and enhancement. However, the standard GAN has drawbacks of training instability because of gradient disappearance and mode collapse [85,86,87]. A large number of GANâ€™s variants have been developed in order to improve the stability, which are implemented either by theory-based approaches such as changing the loss function [85,86,87], or frame (structure)-based approaches including interior structure [88, 89] or even adding the other conditions for input [90].

For the loss function changes, Mao et al. [91] proposed least squares GAN (LSGAN) by replacing least squares loss function to improve stability and converging speed. Martin et al. [85] theoretically analyzed the problem of the standard GAN, which was further highlighted by Wasserstein GAN (WGAN). WGAN solves mode collapse with Wasserstein Distance (WD) as the loss function. Moreover, WGAN applies weight clipping method to ensure Lipschitz restriction, but the method may cause gradient vanishing or gradient exploding. To improve the situation, Ishaan et al. presented WGAN-GP [92] by adding a Gradient Penalty (GP) into WGAN.

For interior structure changes, Alec et al. [88] proposed an unsupervised learning deep convolutional GAN (DCGAN) by integrating convolutional neural networks (CNN) [93] with GAN to achieve a more stable framework. Tero et al. [89] suggested a progressive growing GAN (PGGAN) using gradual growth approach to generate high-resolution samples. For condition setup, Mirza et al. [90] presented conditional GAN (CGAN) by adding conditional variables in random noise for input to solve training freedom. However, it is still unable to improve existing problem of traditional GAN.

The GANs discussed above mainly take images processing into consideration, but the fundamental structures provided can also be applied to other time-series signals with modification in various applications. Recently, there have been several models that can be applied to anomaly detection in the area of nonlinear systems. For example, in order to process time-series data, MAD-GAN [94] constructs the generator and discriminator of GAN into Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN). However, when the dataset is small, it can cause a larger discriminator to overfit easily, and a shallow generator cannot generate data that is realistic enough to defeat the discriminator. Similar to MAD-GAN, TAnoGAN [95] embeds LSTM into generator and discriminator models to process time-series data. The difference is that TAnoGAN uses different effective architectures to detect anomalies in small datasets, but the original formula for standard loss-fighting causes problems of gradient instability and schema collapse. Geiger et al. improve the problems by developing TadGAN [96] that combines Wasserstein Loss and Cycle Consistency to achieve the final minmax target. They use several new methods to calculate reconstruction error, as well as different methods to combine the reconstruction error with the output of the discriminant to calculate the anomaly score. Moreover, there are some generative models working on natural signals and biological signals [97,98,99].

In this work, we mainly focus on time-series signal generation including natural signals (music, speech, text) and biological signals (EEG, EOG, ECG) since there are huge demands in extensive applications such as film-making, movie dubbing, music synthesis, and neuroscience. The following subsections introduce GAN and its variants based on the applications, respectively.

We categorize the GAN-based methods in time-series signals based on their application fields, which are introduced in the following subsections. GANs on music are introduced in Sect. 2.1. Section 2.2 presents the framework of GANs in speech enhancement. GANs on biological signals are introduced in Sect. 2.3.

Music
In recent years, there have been huge demands on music generation including films and videos [44,45,46]. However, such generation is inherently difficult because music contains a wide range of source information, and there are complex coherences between different sources; thus, it is difficult to develop such an effective mathematical model to deal with music signal [100,101,102]. GAN-based models have the capabilities for such music signal generation with supervised and even unsupervised learning techniques. They include continuous recurrent neural networks GAN (C-RNN-GAN) [59], sequence GAN (SeqGAN) [100], objective-reinforced GAN (ORGAN) [42], MuseGAN [101], WaveGAN [60], conditional WaveGAN (cWaveGAN) [61], GANSynth [46]. The following subsections discuss the techniques, respectively.

Continuous recurrent neural networks GAN
C-RNN-GAN [59] is a kind of continuous recurrent neural network (RNN) [102] that performs confrontation training on the basis of long short-term memory (LSTM) [103, 104]. It directly extracts whole sequences and then increases variety of generative samples by using feature matching approach. Moreover, it replaces the loss function LG with standard G in order to avoid overfitting of D. Both loss functions LD and LG are defined as seen in Eqs. (1) and (2), respectively, where R is the representation from the last layer before the final logistic classification layer in D, z(i) is a sequence of uniform random vectors in [0,1]k, k indicates dimensionality from the random sequence, and x(i) is a sequence from the training samples.

ğ¿ğº=1ğ‘šâˆ‘ğ‘–=1ğ‘š(ğ‘…(ğ‘¥(ğ‘–))âˆ’ğ‘…(ğº(ğ‘§(ğ‘–))))2
(1)
ğ¿ğ·=1ğ‘šâˆ‘ğ‘–=1ğ‘š[âˆ’logğ·(ğ‘¥(ğ‘–))âˆ’(log(1âˆ’ğ·(ğº(ğ‘§(ğ‘–)))))]
(2)
Typically, G is to maximize the error produced by the D. When performing feature matching, the target becomes an internal representation that matches the actual samples at some level in the D. If either D or G is excessively powerful during training, it may cause model collapse. If it takes place, C-RNN-GAN will stop training the powerful party.

Sequence GAN
SeqGAN [100] generates time-series signals by combining GAN via policy gradient with reinforcement learning (RL) [105], where G is regarded as an agent in RL, state is the current produced tokens, and action is the next token for selecting G to generate sample. In the pre-training, sequence dataset was pretreated with maximum likelihood estimate (MLE) [104]. For each token, D uses Monte Carlo (MC) search [106] with a roll-out policy to explore a reward for the entire samples and return the current location. Algorithm 1 shows full details of SeqGAN, where the reward guides G to generate samples and guide D to be dynamically updated in order to further improve the generative model iteratively, as shown in Eq. (3):

ğ‘„ğºğœƒğ·ğœ‘(ğ‘ =ğ‘Œ1:ğ‘¡âˆ’1,ğ‘=ğ‘¦ğ‘¡)=â§â©â¨âªâª1ğ‘âˆ‘ğ‘›=1ğ‘ğ·ğœ‘(ğ‘Œğ‘›1:ğ‘‡),ğ‘Œğ‘›1:ğ‘‡âˆˆğ‘€ğ¶ğºğ›½(ğ‘Œ1:ğ‘¡;ğ‘)ğ·ğœ‘(ğ‘Œ1:ğ‘¡)forğ‘¡<ğ‘‡forğ‘¡=ğ‘‡ 
(3)
where ğ‘„ğºğœƒğ·ğœ‘ is the action-value function that represents the reward at state s of taking action a, s is state, a is taking action, GÎ¸ is following policy, GÎ² is the roll-out policy, and DÏ• is discriminator policy.

figure a
SeqGAN is one of the first extended GANs to generate music and has demonstrated its excellent performance. Unfortunately, during experiments issues on GAN such as gradient disappearance and model collapse still remain, so quality of the generative music can still be doubted.

Objective-reinforced GAN
ORGAN [42] combines GAN, expert reward with RL to improve quality of generative samples based on the framework of SeqGAN. The G of ORGAN is also regarded as an agent. However, ORGAN adds a reward function R(Y1:T) defined for full length sequences to replace DÏ•, and the action-value function is shown as Eq. (4). When given an incomplete sequence Y1:tâ€‰=â€‰(y1,y2,â€¦,yt), also referred to a state, G produces an action a, along with the next token yt+1. Moreover, to improve the stability of learning, WD is adopted to avoid problems of GAN convergence like â€˜perfect discriminator.â€™

ğ‘„(ğ‘Œ1:ğ‘¡âˆ’1,ğ‘¦ğ‘¡)=â§â©â¨âªâªâªâª1ğ‘âˆ‘ğ‘›=1...ğ‘ğ‘…(ğ‘Œğ‘›1:ğ‘‡),with ğ‘Œğ‘›1:ğ‘‡âˆˆğ‘€ğ¶ğºğ›½(ğ‘Œğ‘›1:ğ‘¡;ğ‘),ifğ‘¡<ğ‘‡. ğ‘…(ğ‘Œ1:ğ‘‡),ifğ‘¡=ğ‘‡. 
(4)
ORGAN can not only generate qualitative samples, but also retain essential information obtained from real samples. As compared to SeqGAN, it is capable of achieving better quality of samples and maintaining their diversities. Unfortunately, ORGAN has not integrated the choice of heuristic into the method to further improve its performance, e.g., an approach to choose a more effective loss function.

MuseGAN
MuseGAN [99] proposed a novel model of multi-generator and single-discriminator to generate multi-track polyphonic music signal. It divides the G into the shared temporary structure generator Gtemp, the private temporary structure generator Gtemp,i, and the bar generator Gbar. Both Gtemp and Gtemp,i accept the noise of temporal dependency and inter-track, respectively. Finally, the outputs from Gtemp and Gtemp,i are concatenated into the Gbar which can generate piano-rolls sequentially. The generative process is shown as Eq. (5):

ğº(ğ‘§â¯â¯â¯)={ğºbar,ğ‘–(ğ‘§,ğºtemp(ğ‘§ğ‘¡)(ğ‘¡),ğ‘§ğ‘–,ğºtemp,ğ‘–(ğ‘§ğ‘–,ğ‘¡)(ğ‘¡))}ğ‘€,ğ‘‡ğ‘–,ğ‘¡=1
(5)
where i is inter-track, t indicates temporal dependency, M represents the number of tracks, and T is the number of bar.

Compared with other music GANs, MuseGAN can generate more unified rhythm and even clearer musical structure multi-track piano-rolls. However, esthetically, it still lags behind the level of human musicians.

WaveGAN
WaveGAN [60] is the first attempt at applying GANs to unsupervised audio generation. It is based on DCGAN [88] in terms of same parameters and numerical operations, but it has a different structure that is achieved by flattening 2D convolutions of DCGAN into 1D convolution (e.g., 4â€‰Ã—â€‰4 2D convolution becomes 16â€‰Ã—â€‰1 1D) for generating music as illustrated in Fig. 2.

Fig. 2
figure 2
Depiction of the transposed convolution operation from DCGAN to WaveGAN. (e.g., 4â€‰Ã—â€‰4 2D convolution becomes 16â€‰Ã—â€‰1 1D)

Full size image
Moreover, it adopts the WD as loss function to improve the stability. The function is shown in Eq. (6), where DÏ‰ is the 1-Lipschitz of WD, x represents real samples, and z is random noise.

ğ‘‰(ğ·ğœ”,ğº)=ğ¸ğ‘¥âˆ¼ğ‘ƒğ‘¥[ğ·ğœ”(ğ‘¥)]âˆ’ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§[ğ·ğœ”(ğº(ğ‘§))]
(6)
WaveGAN is fully parallelizable and can generate hours of audio in a few seconds [60]. As compared to other GANs for music, it is capable of generating more realistic music by using both waveform and spectrogram strategies. However, the generative music cannot be used in real applications such as movie dubbing because of the inflexibility and uncertainty of length of generative samples using unsupervised learning.

Conditional WaveGAN
As compared to WaveGAN discussed in Sect. 2.1.4, cWaveGAN [61] is designed based on supervised learning to generate audio samples. Basically, two hyper-parameter tuning methods are added as conditions in the system as illustrated in Fig. 3: (a) it embeds/concatenates conditioning information into an input feature vector; (b) it then scales hidden layers by initially mapping conditioning information to a scaling vector and then multiplying it with the input vector for both D and G.

Fig. 3
figure 3
cWaveGAN workflow: (a) adding conditioning information; (b) scaling hidden layers

Full size image
With the conditions, cWaveGAN can generate music and audio as expected and be better controlled by human. Unfortunately, the conditions added increase the training time.

GANSynth
GANSynth [62] was developed based on structure of PGGAN [89] by gradually applying samples from a single vector to a complete music through convolution. Similar to WaveGAN [86], it is trained by progressive variants which increase dimensions of channel to generate more music in parallel. In this way, the speed of generating samples on modern GPUs is faster than other generative frameworks. The activation function x of G is also normalized as shown in Eq. (7), where C indicates the total number of channels, and n, h, w, and c refer to the batch, height, width, and channel dimensions, respectively.

ğ‘¥=ğ‘¥ğ‘›â„ğ‘¤ğ‘/(1ğ¶âˆ‘ğ‘ğ‘¥2ğ‘›â„ğ‘¤ğ‘)0.5
(7)
The GANSynth is able to generate music faster than other generative models, but it is only experimented based on NSynth dataset [41]; more datasets may be needed for evaluation. In addition, as GANSynth cannot capture the full data distribution well, mode collapse and issue of diversity still exist.

Brief summary on various GANs for music
In this subsection, GANs discussed above for music generation are summarized in Table 1 regarding their individual advantages and disadvantages.

Table 1 Advantages and disadvantages of GANs on music generation
Full size table
Speech
Speech processing is one of the most straightforward methods for humanâ€“computer interaction, but there is a lot of noise in the naturally collected speech, which affect processing results [85]. Many denoising methods [87, 107] can be used to process speech, but it may lose the important information. GAN and its variants can provide a novel approach to process speech for conserving the important information and denoising, e.g., Speech Enhancement GAN (SEGAN) [63] and Variational Auto-encoding Wasserstein GAN (VAWGAN) [64]. The following subsections introduce the techniques, respectively.

Speech enhancement GAN
SEGAN [63] provides an end-to-end structure, in which G and D share the same underlying structure. G is fully convolutional, so that dense layer is not needed at all. This enforces the network to pay close attention to the time correlations in the input signal and throughout the whole layering process. Its input is fed into both the speech signals with noise and the latent representation; the output is an enhanced speech signal. With reference to CGAN [90], SEGAN adds the LSGAN [91] and replaces the loss function by binary coding to perform mapping and classification, respectively, i.e., in order to further stabilize the training and improve the quality of the generative samples. The loss functions of G and D can be found in Eqs. (8) and (9) accordingly, where Î» is a parameter that controls the size of the L1 norm, c denotes the value that G and D to believe for fake samples, and ğ‘¥Ìƒ  is the noisy signal which needs to be enhanced.

minğ·ğ‘‰ğ¿ğ‘†ğºğ´ğ‘(ğ·)=12ğ¸ğ‘¥,ğ‘¥ğ¶âˆ¼ğ‘data(ğ‘¥,ğ‘¥ğ¶)[(ğ·(ğ‘¥,ğ‘¥ğ¶)âˆ’1)2]+12ğ¸ğ‘§âˆ¼ğ‘ğ‘§(ğ‘§),ğ‘¥ğ¶âˆ¼ğ‘data(ğ‘¥ğ¶)[ğ·(ğº(ğ‘§,ğ‘¥ğ¶),ğ‘¥ğ¶)2]
(8)
minğºğ‘‰ğ¿ğ‘†ğºğ´ğ‘(ğº)=12ğ¸ğ‘‹Ìƒ âˆ¼ğ‘ğ‘‘ğ‘ğ‘¡ğ‘(ğ‘¥Ìƒ ),ğ‘§âˆ¼ğ‘ğ‘§(ğ‘§)[(ğ·(ğº(ğ‘§,ğ‘¥Ìƒ ),ğ‘¥Ìƒ )âˆ’1)2]+ğœ†||ğº(ğ‘§,ğ‘¥Ìƒ )âˆ’ğ‘¥||1
(9)
As compared with other models, SEGAN can reduce the operation speed of denoising waveform significantly [63], but there may be some high-frequency artifacts during speech enhancement [52].

Variational auto-encoding wasserstein GAN
VAWGAN [62] is a non-parallel voice convert (VC) system [107] combining VAE [28] with WGAN [108]. It is divided into three parts for implementing VC system: a conditional VAE (C-VAE) [107] reconstructs the tone, GAN is applied to improve the over-simplified C-VAE, and WGAN explicitly considers VC in the training objectives.

It is highlighted in Eq. (10), where qÏ† is the expectation of z, Î± is a coefficient which emphasizes the loss of WGAN, pt* is distribution for real samples, and DÏˆ is the discriminator.

ğ½ğ‘£ğ‘ğ‘¤ğ‘”ğ‘ğ‘›=âˆ’ğ·ğ¾ğ¿(ğ‘ğœ‘(ğ‘§ğ‘›|ğ‘¥ğ‘›)||ğ‘(ğ‘§ğ‘›))+ğ¸ğ‘§âˆ¼ğ‘ğœ‘(ğ‘§|ğ‘¥)[logğ‘ğœƒ(ğ‘¥|ğ‘§,ğ‘¦)]+ğ›¼ğ¸ğ‘¥âˆ¼ğ‘âˆ—ğ‘¡[ğ·ğœ“(ğ‘¥)]âˆ’ğ›¼ğ¸ğ‘§âˆ¼ğ‘ğœ‘(ğ‘§|ğ‘¥)[ğ·ğœ“(ğœğœƒ(ğ‘§,ğ‘¦ğ‘¡))]
(10)
Moreover, in the system, VAE encodes the content z of the speech signal, and the decoder generates the converted target voice Î¶Î¸ by giving a target speaker information y.

VAWGAN is the first GAN to implement a non-parallel VC and generate more realistic samples. However, the effectiveness of the conversion needs to be improved.

Brief summary on various GANs for speech generation
In the subsection, the GANs discussed above on speech generation are summarized in Table 2 in terms of individual advantages and disadvantages.

Table 2 Overview of GANs for speech generation
Full size table
Biological signal
Biological signal can assist to detect physiological status of human being, and related research has become a hot topic in many fields such as medicine and computer science. Unlike computer vision or traditional medical imaging which requires thousands of data, in the EEG signal analysis, it is very rare and difficult obtain such amount of biological signals with significant pathological characteristics (such as epilepsy, depression, etc.) for effective training models. Therefore, it is meaningful to generate biological signals in this case. However, since biological signals are multi-channel with strong nonlinear, the generator may not capture the characteristics of these signals effectively. During the past few years, GAN and its variants have been applied to EEG generation to optimize the classification models, such as EEG-GAN [107], Recurrent GAN (RGAN) [65], Conditional WGAN (CWGAN) [109], and Class Conditional WGAN-GP (CC-WGAN-GP) [110]. The following subsections introduce the techniques, respectively.

EEG-GAN
As far as we know, EEG-GAN [107] is the first framework to apply GAN to EEG signal generation. It takes the structure of DCGAN and replaces its loss function by WGAN, which improves the stability and interpretability of the generative framework. The loss function is defined as seen in Eq. (11), where Pdata and PG represent the probability distribution of real samples and generative samples, respectively.

ğ‘Š(ğ‘ƒğ‘¥,ğ‘ƒğº)â‰ˆmaxğ·âˆˆ1 - Lipschitz{ğ¸ğ‘¥âˆ¼ğ‘ƒğ‘¥[ğ·(ğ‘¥)]âˆ’ğ¸ğ‘¥âˆ¼ğ‘ƒğº[ğ·(ğ‘¥)]
(11)
In term of model training, EEG-GAN training starts with low resolution and gradually increases to all EEG signals in order to reduce the artifacts during sampling process. It generates EEG signals with similar frequency to real samples, which proves that GAN can be applied to EEG generation tasks. However, there are also high frequency artifacts in generative samples.

Recurrent GAN
RGAN [65] does not only effectively learn the characteristics of EEG signals, but also augment EEG signals. It replaces the full connection (FC) layer [111] in GAN by RNN [104]. This will help GAN to generate samples more accurately since RNN is able to capture time dependencies in the EEG signals. RGAN is presented as Eq. (12):

minğºmaxğ·ğ‘‰(ğ·,ğº)=ğ¸ğ‘¥âˆ¼ğ‘ƒğ‘¥[logğ·(ğ‘¥;ğœƒğ·)]âˆ’ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§[log(1âˆ’ğ·(ğº(ğ‘§;ğœƒğº)))]
(12)
where Î¸G is the parameter set of the G function, Î¸D is the parameter set of the D function, z is random noise, and D classifies real samples and generative samples by minimizing the mean square error (MSE) [112, 113].

RGAN has shown its capability of generating EEG signals effectively, but it has been only evaluated with BCI2000 datasets [114]; thus, the generalization ability is doubted.

Conditional WGAN
CWGAN [109] generates EEG signals with WGAN-GP to improve the ability of EEG-based emotion recognition. Different from other frameworks of EEG generation, it generates differential entropy (DE) features that suite for EEG-based emotion recognition tasks [115]. To generate multiple emotion categories, an auxiliary label Yr is fed into both D and G, where Yr instructs the G to generate various kinds of samples and controls the kinds of generative samples in D. The proposed CWGAN can be formulated by Eq. (13):

minğœƒğºmaxğœƒğ·ğ¿(ğ‘‹ğ‘Ÿ,ğ‘‹ğ‘”,ğ‘Œğ‘Ÿ)=ğ¸ğ‘¥ğ‘Ÿâˆ¼ğ‘‹ğ‘Ÿ,ğ‘¦ğ‘Ÿâˆ¼ğ‘Œğ‘Ÿ[ğ·(ğ‘¥ğ‘Ÿ|ğ‘¦ğ‘Ÿ)]âˆ’ğ¸ğ‘¥ğ‘”âˆ¼ğ‘‹ğ‘”,ğ‘¦ğ‘Ÿâˆ¼ğ‘Œğ‘Ÿ[ğ·(ğ‘¥ğ‘”|ğ‘¦ğ‘Ÿ)]âˆ’ğœ†ğ¸ğ‘¥Ì‚ âˆ¼ğ‘‹Ì‚ ,ğ‘¦ğ‘Ÿâˆ¼ğ‘Œğ‘Ÿ[(||âˆ‡ğ‘¥Ì‚ |ğ‘¦ğ‘Ÿğ·(ğ‘¥Ì‚ |ğ‘¦ğ‘Ÿ)||2âˆ’1)2]
(13)
where Î¸g and Î¸d represent the parameters of the G and D, Î» is a hyper-parameter controlling the trade-off between original objective and gradient penalty, and ğ‘¥Ì‚  denotes the data points sampled from the straight line between real distribution Xr and generative distribution Xg.

CWGAN sufficiently preserves the diversity of generative samples. However, CWGAN only generates DE instead of EEG signals. Therefore, it can only be used in the field of EEG signal classification.

Class conditional WGAN-GP
Similar to CWGAN, CC-WGAN-GP [90] generates high-quality multi-channel EEG signals based on WGAN-GP. The difference is that CC-WGAN-GP adds a classifier (C) to the D to improve the ability of GAN for EEG classification, as shown in Fig. 4. Specifically, both D/C share parameters Ï•s at the lower layers (S), but have a unique discriminator branch Ï•D and a classifier branch Ï•C at the output of S.

Fig. 4
figure 4
The structure of CC-WGAN-GP

Full size image
In addition, the G generates samples Ï‡f conditioned on the class labels yf that can be served as target labels of C. The loss function is presented as Eq. (14).

ğ¿ğº(ğœ‘ğº,ğœ‘âˆ—ğ·,ğœ‘âˆ—ğ¶,ğœ‘âˆ—ğ‘ )=ğ¸ğœ’ğ‘“âˆ¼Pğ‘“[ğ·ğœ‘âˆ—ğ·(ğºğœ‘ğº(ğ‘§,ğ‘¦ğ‘“))]+ğ¿ğ¶(ğœ‘ğº,ğœ‘âˆ—ğ¶,ğœ‘âˆ—ğ‘ )
(14)
CC-WGAN-GP improves the classification ability of the model by training G and C with a unified loss. Meanwhile, it reduces the high frequency artifacts of the generative samples. However, the generative samples are only applicable to classification models.

Brief summary on various GANs for EEG generation
In this subsection, the GANs discussed above for EEG generation are summarized in Table 3 in terms of individual advantages and disadvantages.

Table 3 Overview of GANs on EEG generation
Full size table
A summary on GANs to process time-series signals
In this section, we will focus on analyzing the reasons that various GAN may fail. Moreover, we provide a comprehensive relationship of GAN and its variants in different applications.

Difficulties in processing time-series signals with GANs
Table 4 summarizes the difficulties of GANs in generating samples of time-series signals including music, voice and EEG.

Table 4 Overview of GANs on time-series signals
Full size table
A summary of GANs with time-series signals
It is known that the original GAN has drawbacks such as training instability and lack of diversity because of gradient disappearance and mode collapse. Its variants are developed and applied in time-series signal by changing either frames or theories in order to fit individual applications and improve the generation ability. Figure 5 summarizes the development of GANs for time-series signal generation. It is seen that the GANs (second row) were developed based on the original GAN and some GANs that were originally used for image processing (first row). The GANs in the first row are divided into frame based and theory based; the GANs in second row are categorized into application based in terms of music (yellow), speech (in brown) and EEG (in gray) accordingly.

Fig. 5
figure 5
Relationship between the GAN and its variants for time-series signal processing

Full size image
Due to the network structure of traditional GAN, it is easy to destroy the time dependence information of time-series signals, which increases the difficulty of applying GAN to time-series signals. In recent years, many researchers have made attempts on different time-series signals. So far, GAN has demonstrated good performance in music and speech processing, and gradually applied to more complex biological signals. In 2016, researchers made a preliminary attempt to use relatively simple single track music signal in C-RNN-GAN. In the following year, SeqGAN and ORGAN being combined with reinforcement learning further improved music signal generation quality in multi-track long-time continuous music samples. In 2018, MuseGAN was designed with multiple generators and discriminators to generate superimposed music signals. Since then, more generation frameworks have improved the generation efficiency in terms of the framework architecture and loss function, such as WaveGAN, cWaveGAN and GANsynth. On the other hand, GAN has been applied to the speech signal enhancement with more time dependence information. In 2017, SEGAN and VAWGAN were developed for speech enhancement. In 2019, GAN-TTS [116] generated higher fidelity speech signals than other models. Moreover, since 2018, several frameworks with GAN have been proposed for generating EEG signals, from single channel such as EEG-GAN to multi-channel such as RGAN, CWGAN, and CC-WGAN-GP. Figure 6 summarizes the trends of developing GANs for time-series signal generation against the publication years and publication sources of exiting works.

Fig. 6
figure 6
The trend of the GAN for time-series signals

Full size image
To further illustrate the performance of GAN in time-series signals, we select the results of representative models (GANSynth, VAW-GAN, and EEG-GAN) in music, speech and EEG signals, as shown in Fig. 7a, b, and c. In Fig. 7a, the illustrative results indicate that the real samples and generative samples in GANSynth have coherent waveforms that result in strong consistent colors for each harmonic. Figure 7b implies that the Global Variance (GV) of VAW-GAN may not generate better samples than real sample, but the higher values of which demonstrate its capability of diversity. In Fig. 7c, the generative/fake samples have similar waveform to the real samples in terms of the mean and standard deviation using EEG-GAN. The above results show that GAN and its variants can generate similar or even better samples than real samples. They have opened up a new way for the development of time-series signals.

Fig. 7
figure 7
Some results of representative GANs on time-series signals

Full size image
Evaluation methods
Evaluation and comparison of samples generated by various GANs have always been challenging [77, 116, 117]. Part of the reasons is that the existing evaluation methods may misjudge in some scenarios [118]. Therefore, evaluation of the samples still needs manual decision-making, which is time-consuming and may produce subjective results. Moreover, existing evaluation methods have some limitations, each of which only takes into account some indicators including information entropy, similarity, clarity, variety, and accuracy. Therefore, it is necessary to improve them by quantifying the GANs for time-series signals [77, 118] in terms of applicability and generalization ability.

Evaluation methods for GANs
In addition to subjectively evaluating the quality of the generated model, various evaluation methods/features have been used to evaluate the generative samples in terms of information entropy, clarity and variety, similarity, accuracy. Generally, entropy is obtained with indicators such as Kullbackâ€“Leibler Divergence (KLD) [119, 120] and Jensenâ€“Shannon Divergence (JSD) [121]; clarity and variety are achievable with indicators like Inception Score (IS) [72], FrÃ©chet Inception Distance (FID) [73] and Mode Score (MS) [118]; similarity can be obtained with distance-based indicators such as WD [122], Kernel MMD [74], and ED [75]; accuracy is achievable with 1-NN classifier [76]. More details on the methods are introduced in the following subsections.

Kullbackâ€“Leibler divergence
KLD [120], also called relative entropy, is equivalent to the difference between two probability distributions (P and Q) in cross-entropy as shown in Eq. (15), where P and Q are the probability distribution of real samples and generative samples accordingly. The cross-entropy is shown in Eq. (16).

ğ¾ğ¿(ğ‘ƒ||ğ‘„)=ğ»(ğ‘ƒ)âˆ’ğ»(ğ‘ƒ,ğ‘„)=âˆ‘ğ‘ƒ(ğ‘¥)logğ‘ƒ(ğ‘¥)ğ‘„(ğ‘¥)
(15)
ğ»(ğ‘ƒ,ğ‘„)=âˆ‘ğ‘¥ğ‘ƒ(ğ‘¥)â‹…log(1ğ‘„(ğ‘¥))
(16)
As the optimization and evaluation method for standard GAN, KLD is asymmetric, i.e., KLD(P||Q)â€‰â‰ â€‰KLD(Q||P), which implies that it could only evaluate the information entropy in one perspective. So KLD has uncertainty.

Jensenâ€“Shannon divergence
JSD [121] is proposed to improve KLD as defined in Eq. (17). It calculates both two distributions the KLD (P, Q) and the mean of two distributions.

JS(ğ‘ƒ||ğ‘„)=12KL(ğ‘ƒ||ğ‘ƒ+ğ‘„2)+12KL(ğ‘„||ğ‘ƒ+ğ‘„2)
(17)
Compared with KLD, there is a problem in the measurement of KLD and JSD: if the distributions of P and Q do not overlap or overlap a little, then KLD and JSD become meaningless. Therefore, WD is recommended.

Wasserstein distance
WD [122], also known as earth-mover distance (EMD), is to measure the distance between two distributions. It is defined in Eq. (18):

ğ‘Š(ğ‘ƒğ‘Ÿ,ğ‘ƒğ‘”)=infğ›¾âˆ¼âˆ(ğ‘ƒğ‘Ÿ,ğ‘ƒğ‘”)ğ¸(ğ‘¥ğ‘Ÿ,ğ‘¥ğ‘”)âˆ¼ğ›¾[||ğ‘¥ğ‘Ÿâˆ’ğ‘¥ğ‘”||]
(18)
where Î (Pr, Pg) denotes the set of all joint distributions (i.e., probabilistic couplings), Î³ is each possible joint distribution, and ||xrâˆ’xg|| denotes the base distance between two samples.

WD can not only solve the problem of unstable training, but also provide a reliable indicator during training process. Moreover, compared with KLD and JSD, it produces superior smoothness, so as to theoretically solve the problem of gradient disappearance. However, calculating WD becomes more complicated when the number of samples is increasing; thus, it is difficult to achieve expected results in reality.

Inception score
IS [72] originated from Inception Net [123] was initially applied to evaluate the clarity and diversity of the generative image.IS as defined in Eq. (19) calculates the KLD between p(y|x) and p(y), where p(y|x) denotes distribution of the label y by x obtained by prediction, and p(y)â€‰=â€‰âˆ«xp(y|x)dpg.

ğ¼ğ‘†(ğ‘ƒğ‘”)=ğ‘’ğ¸ğ‘¥âˆ¼ğ‘ğ‘”[ğ·ğ¾ğ¿(ğ‘(ğ‘¦|ğ‘¥)||ğ‘(ğ‘¦)}
(19)
If clarity in generative sample x is large enough, it may be classified easily, i.e., the entropy in p(y|x) is low. Moreover, if variety in the generative sample is large enough, it should be evenly distributed across all categories, i.e., the entropy in p(y) is high.

IS is able to quantify the diversity and clarity of generative samples. However, it is highly sensitive to noise and entirely relies on the final probability of classifier.

FrÃ©chet inception distance
FID [73] approximates the Inception activation values of real samples and generative samples as Gaussian distribution [124], so the difference between the two samples can be obtained with the calculation of their mean and variance. The lower the FID indicates the higher the quality of the samples and the better the diversity. It is expressed in Eq. (20):

ğ¹ğ¼ğ·(ğ‘¥,ğ‘”)=||ğœ‡ğ‘¥âˆ’ğœ‡ğ‘”||22+ğ‘‡ğ‘Ÿ(ğ¶ğ‘¥+ğ¶ğ‘”âˆ’2(ğ¶ğ‘¥ğ¶ğ‘”)12)
(20)
where x is a real sample and g is a generative sample, Î¼x and Î¼g are means of real samples and generative samples, Cx and Cg are sample covariance, and the Tr represents the sum of the elements on the diagonal of the matrix.

Compared with IS, FID is more sensitive to model collapse and more robust to noise. However, neither FID nor IS can detect the overfitting of GAN.

Mode score
MS [118] makes an improvement based on the defect that IS does not consider the relationship between the generative samples and the real samples, as shown in Eq. (21). Compared with IS, MS calculates the KLD of the real samples distribution p(y) and the sample label distribution p(y*), which could be closer to the real sample distribution.

ğ‘€ğ‘†(ğ‘ƒğ‘”)=ğ‘’ğ¸ğ‘¥âˆ¼ğ‘ƒğ‘”[ğ¾ğ¿(ğ‘ğ‘€(ğ‘¦|ğ‘¥)||ğ‘ğ‘€(ğ‘¦))âˆ’ğ¾ğ¿(ğ‘ğ‘€(ğ‘¦)||ğ‘ğ‘€(ğ‘¦âˆ—))]
(21)
MS cannot only evaluate the quality and diversity of generative samples, but also pay more attention to the similarity between real samples and generative samples. However, MS cannot detect the over fitting phenomenon in the training process of GAN.

Euclidean distance
ED [75] evaluates the similarity between the generative samples and the real samples. In the optimal case, the minimum EDmin between two samples should be equivalent to the minimum distance distribution. It is defined as Eq. (22), where ED is the Euclidean distance between two distribution A(x1,x2,â€¦,xn) and B(y1,y2,â€¦,yn), xi and yi represent the characteristics of A and B, respectively.

ED==(ğ‘¥ğ‘›âˆ’ğ‘¦ğ‘›)2+â‹¯+(ğ‘¥2âˆ’ğ‘¥1)2+(ğ‘¦2âˆ’ğ‘¦1)2â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆšâˆ‘ğ‘–=1ğ‘›(ğ‘¥ğ‘–âˆ’ğ‘¦ğ‘–)2â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾î€â·î€€î€€
(22)
ED is the simplest method to evaluate the similarity of samples. However, when the samples have multiple attributes, it tends to produce random fluctuations of varying sizes resulting in inaccurate results.

Kernel maximum mean discrepancy
Kernel MMD [74, 116] measures the dissimilarity between real samples Pr and generative samples Pg by giving some fixed kernel function k as defined as Eq. (23), where Xr indicates real samples and Xg indicates generative samples, they are sampled from Pr and Pg, and MMD can be calculated by the expected approximation between two distributions.

ğ‘€ğ‘€ğ·2(ğ‘ƒğ‘Ÿ,ğ‘ƒğ‘”)=ğ¸ğ‘‹ğ‘Ÿ,ğ‘‹â€²ğ‘Ÿâˆ¼ğ‘ƒğ‘Ÿ,ğ‘‹ğ‘”,ğ‘‹â€²ğ‘”âˆ¼ğ‘ƒğ‘”[ğ‘˜(ğ‘‹ğ‘Ÿ,ğ‘‹â€²ğ‘Ÿ)âˆ’2ğ‘˜(ğ‘‹ğ‘Ÿ,ğ‘‹ğ‘”)+ğ‘˜(ğ‘‹ğ‘”,ğ‘‹â€²ğ‘”)]
(23)
The two distributions have equal mean values for the corresponding outputs on the function k, which indicates that the distributions can be considered as the same one.

The sample complexity and computational complexity of Kernel MMD are relatively low. However, the evaluation results may be biased.

1-Nearest neighbor accuracy
1-NN classifier [76] was used to evaluate whether the two distributions were identical in the two-sample test, as defined in Eq. (24), where Sr and Sg denote real samples and generative samples, respectively.

ğ‘†ğ‘Ÿâˆ¼ğ‘ƒğ‘›ğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘†ğ‘”âˆ¼ğ‘ƒğ‘šğ‘”,ğ‘¤ğ‘–ğ‘¡â„|ğ‘†ğ‘Ÿ|=|ğ‘†ğ‘”|
(24)
When Sg matches Sr, the optimal scores can be obtained. Different from the most commonly used measure of accuracy, 1-NN classifier correlates the accuracy with Leave-One-Out (LOO) accuracy under certain condition [125]. It not only has all the advantages of other indicators, but also can detect the mode collapse. However, the training process of 1-NN classifier is complex and consumes a lot of memory.

Summary of evaluation methods
Existing evaluation methods evaluate the quality of generative samples according to the indicators including information entropy, similarity, clarity, diversity, and accuracy. Among them, KLD and JSD are used for evaluating information entropy; however, if the two distributions are far apart, or no overlap, they can be meaningless. WD, SWD, ED, and the Kernel MMD have been used to evaluate the similarity of generative samples. Among the four methods, WD has the highest time complexity, while Kernel MMD has the lowest one. In terms of image clarity and diversity, IS, FID and MS are able to provide better results, but they have only been applied to image evaluation. Finally, 1-NN classifier is capable of classifying samples easily with excellent accuracy. Table 5 summarizes the evaluation methods from different perspectives.

Table 5 Comparison of various evaluation methods
Full size table
Preliminary experiment
In this section, we analyzed the performance of WGAN-GP to generate EEG signals on a publicly available dataset Bi2015a [127]. The dataset includes EEG recordings of 50 subjects playing a visual P300 BCI video game called â€œBrain Invaders.â€ It recorded EEG signals from 32 channels in the 10â€“10 international system at sampling frequency of 512 Hz. After preliminary screening, we deleted the data with corrupted channels, so 35 subjects were selected; meanwhile, compared with the characteristics of P300 among all 32 channels, it is found that C3 has the most significant characteristics. Therefore, data of C3 channel from 35 subjects were used in the experiment. In this study, two different networks were performed to accordingly construct the generative models: (1) CNN, and (2) LSTM. The models were then evaluated using two evaluation metrics including SWD and MS, respectively. The former is used to evaluate the similarity of the model, and the latter is used to evaluate its diversity. The results are shown in Table 6.

Table 6 The quantitative evaluation results of generative EEG by different frameworks
Full size table
According to the evaluation results, the SWD values of WGAN-GP (GDDD) and WGAN-GP (GLDL) were 3.37 and 1.90, respectively, indicating that the generated samples from WGAN-GP (GLDL) are more similar to the real EEG. In addition, the MS values of WGAN-GP (GDDD) and WGAN-GP (GLDL) are 12.25 and 3.95, respectively. The result indicates that WGAN-GP (GDDD) can generate more diverse samples than WGAN-GP (GLDL).

We further evaluated the quality of the generative EEG from a visual perspective. As illustrated in Figs. 8 and 9, it is observed that the range of the EEG signals generated by WGAN-GP (GDDD) is obviously inconsistent with that of the real EEG. In Fig. 9, the range of EEG signals generated by WGAN-GP (GLDL) is closer to the range of real EEG. Therefore, considering the similarity, diversity and visual observation, WGAN-GP (GLDL) has demonstrated significant performance for EEG signal generation.

Fig. 8
figure 8
The generative EEG of WGAN-GP(GDDD)

Full size image
Fig. 9
figure 9
The generative EEG of WGAN-GP(GLDL)

Full size image
Discussion and future work
During the last few years, GAN and its variants have been achieving massive success in terms of generative models, for not only images generation [55,56,57,58] but also time-series signal generation [42,43,44,45,46,47,48,49]. Unfortunately, it is difficult to apply to all time-series signals, particularly on biological signal such as EEG signals. This may be due to the following reasons:

(1)
As compared with natural time-series signals such as music and audio signals, EEG signal generation and processing are much more complex due to its unreadable information hidden in multi-channel. Multi-channel may cause G to fail to generate specific features at one particular channel, whereas unreadable information reduces possibility of detection of neural correlation and activities. Moreover, manual intervention is not efficient enough to achieve convincing evaluation results. Therefore, it is essential to have a generalized and robust GAN for EEG generation and evaluation.

(2)
Since the standard GAN needs a series of sampling and convolution operations, it can destroy the continuity of the time-series signal. It also causes the loss of information in the signal, resulting in D unable to guide G to improve the generative ability through discrete information. Furthermore, issues like the gradient disappearance and mode collapse affect the quality of the generation since Nash equilibrium is hard to be achieved [73, 119]. Therefore, it is important to choose either more suitable loss functions or the framework.

(3)
Quality of generative models is still doubted. There are various evaluation methods (e.g., information entropy, clarity, variety, similarity, and accuracy [72,73,74,75,76]) for evaluating the GANs and generative models. However, none of them is capable of fully representing the quality with confidence; in other words, each of them only focuses on individual perspectives, so the GANs cannot be evaluated adequately. Unfortunately, they may raise some questions:

(a)
Manual selection of indicators by the user. This approach is subjective and time-consuming; quality of the generative models is heavily dependent on individual preference; if this is the case, one questions will be how it can be implemented automatically.

(b)
Lack of clear decision-making criteria. When the indicators are providing conflict solutions, it is almost impossible for users to make decision and provide weights manually; if this is the case, one question will be which one or more should be given more attention than others;

(c)
Lack of human expertise intervention for EEG signals. It has been demonstrated that existing indicators are capable of performing image and audio signal generation better than EEG signal, because their outcomes can be evaluated by human experts based on visual and auditory recognition, but this is not the case for EEG signal; one question will be how the generative EEG signals can be evaluated by neuroscientists even though information is hidden.

Based on the questions addressed above, potential further work can be proposed:

(1)
Development of a novel framework for EEG signal generation to handle robustness and stability. It is able to reduce the possibility of gradient disappearance and curse of multi-dimensions. This may be achieved by designing a novel loss function [91, 92, 108] such as adding appropriate super-parameters to improve stability, changing other networks (e.g., LSTM, RNN) [101, 102], and even changing the random noise [127].

(2)
Development of a more intelligent and adaptive evaluation system to provide robust evaluation solution. This can be implemented with existing and/or modified unsupervised learning techniques such as cluster learning [128, 129] and Ricci Flow method [130], so that individual indicator will be assigned weights automatically and adaptively based on the contribution in the system.

Conclusion
This paper provides a comprehensive review on time-series signal generation with GAN-related framework and evaluation methods for the generated signals. Various state-of-the-art GANs are introduced and analyzed on how they are modified to fit in different applications such as music, speech and EEG signals. The techniques developed mainly focus on issues of unstable training on mode collapse and gradient disappearance. Moreover, existing evaluation methods are lack of clear decision-making criteria, especially when different indicators have provided conflict solutions. Compared with current review papers, four unique findings are addressed: (1) few related studies specifically focus on time-series signals generation due to limitation of GAN for time-series signals; (2) we clearly point out the difficulties of traditional GAN for time-series signals; (3) existing evaluation methods may fail to provide representative and comprehensive results on GANs due to lack of correlation between individual method and capability of automation on decision-making criteria. Based on the findings, we propose possible solutions to improve quality of GANs and a more intelligent and adaptive evaluation system; (4) we demonstrate the effectiveness of GANs by generating EEG signals using a Bi2015a dataset, followed by quality checking using two evaluation metrics including SWD and MS. Above all, in spite of the defects in GANs on time-series signal generation, they have still gained great prospects in future research in various applications.

Keywords
Deep learning
Generative adversarial networks
Time-series signals
Evaluation methods
Data generation
Generative model