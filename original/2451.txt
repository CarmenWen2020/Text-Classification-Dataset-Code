Classification of respiratory diseases using X-ray and CT scan images of lungs is currently practised and used by many medical practitioners for clinical diagnosis. Respiratory disease classification, using breathing and wheezing sounds, remains scarce in the research field and is slowly upcoming. In this work, robust respiratory disease classification using breathing sounds (RRDCBS) is implemented by extracting multiple features from sounds, creating multiple modelling techniques, and experimental identification of diseases using appropriate testing procedures for multi-class and binary classification of respiratory diseases. Decision level fusion of features for Vector quantisation (VQ) modelling technique has provided 100% accuracy for classifying five respiratory diseases and healthy subjects. Decision level fusion of indices on the features has provided 100% accuracy for VQ, support vector machine (SVM), and K-nearest neighbour (KNN) modelling techniques to perform binary classification of the respiratory disease against healthy data sound. Deep recurrent and convolutional neural networks are also evaluated for multiple/binary classification of respiratory diseases.

Introduction
Respiratory diseases are the leading causes of death and disability across the world. Early detection and prevention are required to reduce the mortality rate. People are affected with different types of respiratory diseases, namely Asthma, Pneumonia, Lower respiratory tract infection (LRTI), upper respiratory tract infection (URTI), Bronchitis, Bronchiectasis, and Chronic obstructive pulmonary disease (COPD) at all ages. The polluted air we inhale will affect the functioning of the lungs, leading to these respiratory diseases. Some of the respiratory diseases may be due to inheritance. Seasonal respiratory diseases are due to inclement weather conditions and unusual climatic changes. Even infants die due to respiratory diseases. Respiratory diseases are classified based on X-ray and CT scan images of lungs. Respiratory sound recorded by stethoscopes can also be used for respiratory disease classification. It is a non-invasive method that does not affect the patients at later stages. Frequent exposure of patients to X-ray and CT scan tools may be harming the patients later.

Respiratory sound recording is done by placing the stethoscope at various chest locations, breathing and wheezing sounds, indexed, labelled, and stored as data files. Two methods are implemented [1], one with a pre-trained convolutional neural network (CNN) for feature extraction and SVM for classification of lung diseases and the other with spectrogram-based CNN for classifying lung diseases. Classification of COPD and normal subjects [2] is done based on respiratory sound analysis and machine learning techniques. Mel frequency cepstral coefficients (MFCC) are used as a feature & SVM as a classifier and spectrogram with CNN to model and classify lung diseases [2, 3] from breathing sounds. The effectiveness of CNN [3, 4] is explored to detect abnormal heart and lung sounds. MFCC statistics and local binary patterns [4, 5] are used as features, and SVM, KNN and Gaussian mixed models (GMM) classify lung sounds [5–10]. Spectrogram-based CNN is also used to classify lung sounds.

Linear classifier [5] is used to classify asthma and COPD, chronic respiratory diseases from sounds [11–18]. Classification of wheeze, crackle and normal sounds [3, 10] uses deep residual networks. Morphological embedded complexities [6] are calculated in terms of lacunarity, entropy, skewness, kurtosis, and classification of respiratory diseases subjects against healthy subjects using SVM and extreme learning classifier. Power spectral density, Eigenvalues, Power spectral density of univariate and multivariate autoregressive (AR) models [7, 12] are applied to the supervised neural networks to do the binary classification of lung diseases against healthy subjects. Integrated power and spectral features with KNN, SVM, and ensemble classifiers [5, 8, 14] analyse asthma severity in patients using wheezing sounds. Recording and analysing lung acoustic signals [9] would help in pulmonary diagnosis. Detection of asthma in patients [10, 16] uses MFCC as a feature and SVM classifier. Automatic detection of asthma in breathing sounds [11] uses spectral envelope and tonality index as features and SVM as classifier. Wavelet higher-order spectral features [6, 19] discriminate asthma and COPD through breathing sounds.

This work on multi-class/binary class classification of respiratory diseases is split into sections. Section 2 describes the analysis of respiratory sounds. Section 3 indicates the details about the database used, and Sect. 4 depicts the implementation of the multi-class classification system for classifying respiratory diseases. Section 5 enumerates the results of the multi-class classification system, and Sect. 6 describes the results of the binary classification of respiratory disease against healthy subjects. Finally, Sect. 7 summarises the multi-class and binary classification system's implementation details for classifying respiratory diseases from breathing sounds.

Categorical analysis of respiratory sounds
Respiratory sounds corresponding to the diseases are analysed to characterise the diseases qualitatively based on the recording of the breathing and wheezing sounds of the patients suffering from pulmonary diseases. Figure 1 indicates the time variation of the sound signals in pertinent respiratory diseases URTI, Pneumonia and Bronchitis.

Fig. 1
figure 1
Time variation—signals for the respiratory diseases (URTI-Pneumonia-Bronchitis) respiratory sounds

Full size image
Figure 2 depicts the time domain signal for the sounds corresponding to the subjects with respiratory diseases Bronchiectasis & COPD and Healthy.

Fig. 2
figure 2
Time variation—signals for respiratory diseases (Bronchiectasis & COPD) and healthy respiratory sounds

Full size image
Correlation analysis is done to assess the sounds of respiratory diseases with healthy sounds. Figure 3 summarises the correlation between the patients' respiratory sounds with URTI & pneumonia and healthy sound.

Fig. 3
figure 3
Correlation analysis between URTI and Pneumonia with healthy respiratory sounds

Full size image
Figure 4 depicts the correlation analysis results between the respiratory sounds of the patients with bronchitis, bronchiectasis and COPD, and the healthy person's sound.

Fig. 4
figure 4
Correlation analysis between bronchitis, bronchiectasis and COPD with healthy respiratory sounds

Full size image
Figure 5 indicates the correlation coefficient computation between the patients' sounds affected by respiratory diseases and healthy subjects. A positive correlation coefficient indicates the similarity between the signals and the variation would be in the same direction. Conversely, negative correlation coefficient values indicate the variation of the signals in the opposite direction. Therefore, there is a forecast that most healthy subjects' test sound segments would be misclassified with URTI respiratory sound.

Fig. 5
figure 5
Analysis—Correlation coefficient between signals of the respiratory disease sounds with healthy respiratory sound

Full size image
Description of the database used
This respiratory sound database (https://www.kaggle.com/vbookshelf/respiratory-sound-database) contains the patients' sound samples with respiratory diseases and healthy subjects. File names for each sound sample indicate the information about the patient number, recording index, chest location ((Trachea (Tc), {Anterior (A), Posterior (P), Lateral (L)}{left (l), right (r)}), acquisition mode (sequential/single channel (sc), simultaneous/multichannel (mc)), and details of the recording equipment(AKG C417L Microphone, 3 M Littmann Classic II SE Stethoscope, 3 M Littmann 3200 Electronic Stethoscope, WelchAllynMeditron Master Elite Electronic Stethoscope). Sound samples in pertinent respiratory diseases are grouped and taken for performing respiratory disease multi-classification, including healthy subjects and two-class classification of respiratory disease against healthy subjects.

Implementation of Robust respiratory disease classification using breathing sounds(RRDCBS)
This work on multi-class/binary classification of respiratory diseases is designed by the modules such as feature extraction, template creation and testing & evaluation. Features used in this work are perceptual features and gamma tone energy features with filters calibrated in equivalent rectangular bandwidth (ERB), MEL and BARK scales, MFCC, Modified group delay cepstrum, Discrete orthogonal Stockwell features, Spectrogram and MEL spectrogram. Features extracted from the training set of sounds in pertinent respiratory disease are applied to the VQ models, SVM models, and RNN models for creating training disease templates. For testing, features extracted from the test set of sounds are applied to the models. Based on the respective testing procedure, test sound is identified as one among the respiratory diseases, including healthy subjects.

Spectrogram and MEL spectrogram, the two-dimensional visual features extracted from the training set of sounds corresponding to the respiratory diseases with healthy subjects, are applied to the CNN for creating CNN templates. Spectrogram and MEL spectrogram features extracted from the test set of sounds are applied to the CNN models, and respiratory diseases are classified. The two-class classification of respiratory disease with healthy sounds is implemented by applying the test features to the respiratory disease and healthy model. Test sound is classified as corresponding to the respiratory disease or healthy subject based on the testing criterion.

Description—feature extraction from respiratory sounds
Air pressure from the lungs will inhibit vocal cords' movement; excitation of the vocal tract by the vibration of vocal cords will make the sounds radiate through the mouth or nostrils. Sound is considered as an acoustic pressure variation as a function of time. The doctors may analyse breathing and wheezing sounds recorded from patients to diagnose possible respiratory disease. An automated system to discriminate the respiratory diseases may help diagnose the patients for the correct respiratory diseases, and subsequently, correct treatment may be suggested/imparted. Sounds cannot be directly taken for comparison by an automated system to classify respiratory disease. Sounds are required to be converted into features revealing less dimensionality. Extracted features from the sounds should reveal the characteristics of respiratory disease. It should be as consistent as possible for the sounds of the same respiratory disease. There should be considerable variation in extracted features between the sounds of the different respiratory diseases.

Gamma tone energy feature extraction
The set of utterances in pertinent respiratory disease and healthy subjects are concatenated, and voiced frames are retained by performing voice activity detection. Pre-emphasis is done to smooth the signal in the spectral domain. Frame blocking is performed to convert the voiced speech vector into 16 ms duration segments with an 8 ms shift between the segments. Windowing on each speech segment is done by raising the cosine Hamming window to remove the signal discontinuities. FFT filtering is done with gamma tone filters spaced in ERB, MEL and BARK scales, and gamma tone energy features are extracted and distinguished in different non-linear frequency scales. Figure 6 depicts the processes involved in gamma tone energy feature extraction [12, 13, 20].

Fig. 6
figure 6
Gamma Tone Energy Feature Extraction

Full size image
MGDFC extraction
Short-time phase spectra of a speech signal can also extract Cepstral features. Group delay is obtained from pre-processed speech and modified called a modified group delay. Cepstral features are derived for the logarithm of the energy of the modified group delay spectra called a modified group delay cepstrum. Figure 7 shows a description about the modules for MGDFC extraction [8, 21].

Fig. 7
figure 7
MGDFC extraction

Full size image
DOSTC/DCSTC extraction
The extraction of Stockwell features [8, 21] is indicated in Fig. 8. A respiratory sound one-dimensional signal goes through a voice activity detection block to remove the insignificant frames in a signal. Discrete Fourier transforms/discrete cosine transform (DFT/DCT) block for transformation in the frequency domain, partitioning bandwidth block, and inverse transformation on the signal's selected frames by performing Inverse Discrete Fourier transform/inverse discrete cosine transform (IDFT/IDCT). Inverse discrete orthogonal Stockwell transform/inverse discrete sosine Stockwell transform (IDOST/IDCST) techniques are applied to derive the cepstral features.

Fig. 8
figure 8
DOSTC/DCSTC Extraction

Full size image
MFCC extraction
Mel frequency cepstrum (MFCC) [14, 22] features are commonly used for any speech-based identification. After conventional pre-processing techniques, speech segments must pass through the filter back with the filter's frequency responses calibrated in the MEL scale. The power spectrum of the output is obtained for each filter in the filter bank. IDCT is performed on the logarithm of the energy values, and the first thirteen coefficients are retained and known as MFCC coefficients. Figure 9 indicates the modules used for MFCC extraction.

Fig. 9
figure 9
MFCC Extraction

Full size image
Perceptual features extraction
Perceptual features [12, 13, 20] carrying perceptually important speech characteristics are derived by modelling the auditory speech spectrum. After conventional pre-processing techniques, speech segments pass through a Fast Fourier Transform (FFT), compute the power spectrum. Auditory spectral analysis is done by multiplying the power spectrum of speech segments with a spectrum of the critical band filters with filters calibrated in ERB, MEL and BARK scales. Each filter output spectrum will undergo loudness equalisation and cube root compression to simulate the power law of hearing. Then, IFFT is performed on the cube root compression block's output; the regressive auto process extracts LPC coefficients. LPC coefficients are converted into cepstrum known as perceptual features with filters spaced in ERB, MEL and BARK scales. The number of critical bands is derived based on the frequency scale used. Figure 10 shows the modules used for perceptual features extraction.

Fig. 10
figure 10
Perceptual Features Extraction

Full size image
The relationship between frequency in Bark, MEL & ERB scale and frequency in Hz is specified as in (1), (2) and (3)

𝑓(Bark)=6×arc𝑠𝑖𝑛ℎ(𝑓(𝐻𝑧)/600)
(1)
𝑓(MEL)=2595×log10(1+𝑓(𝐻𝑧)/700)
(2)
𝑓(erb)=21.4×log10(4.37𝑒−3×𝐻𝑧+1)
(3)
Template/model creation techniques
This work on the multiclass classification of respiratory diseases and two-class classification of respiratory disease with healthy subjects, VQ, KNN, SVM, CNN, and RNN machine learning techniques create templates for respiratory diseases and healthy subjects. VQ modelling technique [14, 22] creates a set of clusters against the amount of training data. It forms the cluster set with centroids as a representative of a set of training vectors. It is an unsupervised machine learning technique to group the training set of data points. Each training data point is classified as associated with a cluster centre, which is the closest to it. Data points in each cluster would have similar properties. So, the training set of a data partition into a homogenous cluster is done using clustering-based machine learning algorithms. SVM [14, 15, 22] is a supervised machine learning technique used for creating SVM models for each training set of vectors associated with the set of class labels. SVM classifier classifies each row of the test data on the respiratory disease sounds using the information in a support vector machine classifier structure. The outcome of this experiment is class labels assigned for each test vector. CNN and RNN modelling techniques used for respiratory disease classification are detailed as follows.

Using convolutional neural network (CNN)
The classification task is performed by applying test features to the templates created due to deep machine learning neural networks. The deep neural network is a feed-forward neural network containing hidden layers based on a specific application. Each hidden layer is constituted to have neurons. Each of which operates on the previous outputs by multiplication operation between the neurons' inputs and weights, and multiplied results are added together to pass through a sigmoid activation function. For example, the convolutional neural network (CNN) [9, 11, 16, 17, 23–25] can be regarded as a variant of the standard deep learning neural network consisting of an input layer with the application of two-dimensional feature maps, convolution layer with several filters associated with filter coefficients, pooling layer, fully connected layer with several outputs and softmax layer meant for classification problems. Figure 11 shows the architecture of CNN for respiratory disease multiclass/binary classification.

Fig. 11
figure 11
CNN Architecture for Respiratory disease classification

Full size image
Convolution layer
In the CNN network, input data organisation as two-dimensional feature maps must be done before applying to the two-dimensional convolution layer. The convolution layer is organised with many filters, and each filter is represented with a set of filter coefficients. The convolution operation maps the input layer with CNN's subsequent convolution layer, as seen in signal processing. The convolution feature maps 𝑦𝑗 can be represented as in (4)

𝑦𝑗=𝜎(∑𝑖=1𝐼𝑥𝑖∗𝑊𝑖,𝑗)
(4)
∗ Indicates convolution operator and 𝑊𝑖,𝑗 indicates the weight matrix between every input feature and convolution feature map.

A convolution layer is a hidden layer representing the characteristics of the input received from the previous layer. According to the feature maps from the respective lower layer of the CNN, the self-organisation of neurons in the convolution layer takes place to share the same weights between the layers.

Pooling layer
The pooling layer is also organised into a feature map of the convolution layer with a smaller size. Reduction in resolution is caused by the pooling layer. The previous convolution layer's feature map is generalised, and each generalisation is localised in frequency and remains unchanged due to small changes in location. The pooling size is fixed to maintain the resolution of the feature map. It performs a maximisation or averaging function, and based on that, it is called a max-pooling layer or average pooling layer. The pooling function does the independent assessment of the convolution feature map. Definition of the pooling layer based on maximum pooling function is as in (5).

𝑃𝑖,𝑚=𝑚𝑎𝑥𝐺𝑛=1𝑦𝑖,(𝑚−1)×𝑠+𝑛
(5)
Where 𝐺 and 𝑠. determine the pooling size and shift size, which indicates the overlapping of adjacent pooling windows. Similarly, the output is calculated as in (6) by using the average function.

𝑃𝑖,𝑚=𝑟∑𝑛=1𝐺𝑦𝑖,(𝑚−1)×𝑠+𝑛
(6)
𝑟 is a scaling factor that can be learnt. The final output is generated by applying this non-linear activation function to the above 𝑃𝑖,𝑚. Division of input into the rectangular regions is by max-pooling layer to output the maximum of each region.

Fully connected layer
The flattened data from the final pooling or convolutional layer is applied to the fully connected layer. This layer contains neurons, weights and biases. All the input neurons are connected to each activation function of the next unit neurons in a fully connected layer. Each neuron performs the following calculation as in (7)

𝐹𝑖=𝜎(𝑃𝑖∗𝑊+𝑏)
(7)
𝑃𝑖.–All input from the previous neuron unit. W–Weight matrix. b–Bias vector.

Softmax layer
The last layer of CNN is the softmax layer. It exists at the end of fully connected networks. After passing through the fully connected layers, this layer uses the softmax activation function. This layer calculates the probability of each class for multiclass/binary classification of respiratory disease. It is expressed as in (8)

𝑆𝑖=exp(𝐹𝑖)∑𝑗𝐹𝑗
(8)
So, CNN imbibes layers' organisation to classify respiratory diseases based on breathing and wheezing sounds.

Using recurrent neural network (RNN)
Deep learning neural network has more hidden layers in a network. For example, RNN is commonly used to identify context-based pattern tasks, such as speech recognition. In RNN, each neuron holds a memory cell during all the processes. The long short term memory (LSTM) [18] is a recurrent network architecture developed to resolve long-term dependencies. The RNN architecture using the LSTM network for classifying respiratory diseases is shown in Fig. 12.

Fig. 12
figure 12
Architecture of RNN network for respiratory disease classification

Full size image
Hidden layer
A hidden layer of LSTM consists of a series of connected memory blocks. The structure of the LSTM layer is shown in Fig. 13. The internal operation of the hidden node is displayed in Fig. 14. The hidden layer contains the following states: forget gate state, input gate state, update state, and output gate state.

Fig. 13
figure 13
Structure of LSTM layer

Full size image
Fig. 14
figure 14
Internal operation of hidden neutron

Full size image
The essential to LSTM is the cell state. The LSTM can add or remove the data to the cell state. The first stage of LSTM is to determine what data to be thrown away from the cell state. This information is made by the sigmoid layer called forget gate state. It can be represented as in (9),

𝑓𝑁=𝜎(𝑤𝑓.[𝑥𝑁,h𝑁−1]+𝑏𝑓)
(9)
The second stage of LSTM is to evaluate which data we can place in the cell state. Two sections achieve it. First, a sigmoid layer called the input gate layer nes what values we will upgrade. Then, a tanh layer generates a vector that could be added to the state with new values 𝐶𝑁⎯⎯⎯⎯⎯⎯⎯⎯. These two sections are combined to update the state in the next step. These two sections are expressed as in (10) and (11).

𝑖𝑁=𝜎(𝑤𝑖.[𝑥𝑁,h𝑁−1]+𝑏𝑖)
(10)
𝐶𝑁⎯⎯⎯⎯⎯⎯⎯⎯=𝑡𝑎𝑛h(𝑤𝑐.[𝑥𝑁,h𝑁−1]+𝑏𝑐)
(11)
The old cell state 𝐶𝑁−1 is updated to the new cell state 𝐶𝑁., which is obtained by multiplying the old cell state with 𝑓𝑁. and add 𝑖𝑁∗𝐶𝑁⎯⎯⎯⎯⎯⎯⎯⎯. It is represented in (12)

𝐶𝑁=𝑓𝑁∗𝐶𝑁−1+𝑖𝑁×𝐶𝑁⎯⎯⎯⎯⎯⎯⎯⎯
(12)
The output of the hidden unit is based on the cell state. First, execute a sigmoid layer that determines which parts of the cell state are connected to the output. Then bring the cell state through tanh and multiply it with sigmoid gate output to the desired sections. These are represented in (13) and (14).

𝑂𝑁=𝜎(𝑤𝑜.[𝑥𝑁,h𝑁−1]+𝑏𝑜)
(13)
h𝑁=𝑂𝑁×tanh(𝐶𝑁)
(14)
Fully connected layer
The final LSTM or hidden layer data is flattened and then fed into the fully connected layer. This layer contains neurons, weights and biases. All the input neurons are connected to each activation function of the next unit neurons in a fully connected layer. Each neuron performs the following calculation as in (15).

𝐹𝑖=𝜎(𝑃𝑖∗𝑊+𝑏)
(15)
𝑃𝑖-–All input from the previous neuron unit.𝑊–Weight matrix.𝑏–Bias vector.

Softmax layer
The last layer of the LSTM network is the softmax layer. It exists at the end of fully connected networks. After passing through the fully connected layers, this layer uses the softmax activation function. The softmax layer calculates the probability of performing multiclass/binary classification of respiratory diseases. It is expressed as in (16).

𝑆𝑖=exp(𝐹𝑖)∑𝑗𝐹𝑗
(16)
Thus, the RNN machine learning technique utilises layers and neurons in layers to identify respiratory diseases based on sounds.

Testing for respiratory disease classification with breathing and wheezing sounds
In the training data set, respiratory sounds in pertinent respiratory diseases are concatenated for extracting the proposed features. Models for each respiratory disease are created by applying the features to the modelling techniques. Test features are extracted and applied to the models and based on the respective classification procedures; test sound is identified to correspond to the respiratory disease. Figure 15 indicates the VQ machine learning-based respiratory disease performance and healthy classification. Based on sounds for the proposed features such as perceptual features and gamma tone energy features with filters calibrated in ERB, MEL and BARK scales, MFCC, modified group delay cepstrum, discrete orthogonal Stockwell features. Integration of all features for the decision-level fusion of indices has provided 100% accuracy for the VQ-based machine learning technique. Perceptual feature with filters in the MEL scale has yielded a better overall average accuracy of 79.3% than all the other features. On the other hand, all the features have provided relatively low accuracy for URTI sounds and healthy sounds compared to other respiratory diseases.

Fig. 15
figure 15
Performance of the respiratory disease classification system—VQ-based machine learning technique

Full size image
The confusion matrix in Table 1 gives the details about the multi-class classification of respiratory diseases and healthy subjects for the perceptual feature with filters in the ERB scale. Most of the test segments for healthy sounds are misclassified with sounds for URTI disease. So, the accuracy is relatively poor for healthy respiratory sounds.

Table 1 Confusion matrix-ERBPLPC feature for VQ-based machine learning
Full size table
Figure 16 depicts the performance of the RNN-based respiratory disease classification system for decision level fusion of perceptual features and gamma tone energy features with filters spaced in ERB, MEL and BARK scale.

Fig. 16
figure 16
Performance of the respiratory disease classification system—RNN-based deep machine learning technique

Full size image
Table 2 indicates the average performance of the system for the features with RNN for modelling and classification. The number of epochs has been increased to create RNN models, and test sounds are given to the models for classification. As a result, average performance is relatively better for some of the features.

Table 2 Average performance of the features—Comparison to epochs for RNN-based deep learning
Full size table
Figure 17 indicates the system's performance for SVM-based machine learning technique for the decision level fusion of features. SVM-based classifier does provide good results for all the respiratory diseases except bronchitis and healthy subjects.

Fig. 17
figure 17
Decision level fusion of the features for respiratory disease classification—SVM-based machine learning technique with Gaussian Kernel

Full size image
Table 3 indicates the SVM-based respiratory disease classification's comparative performance with variations in Kernels used for creating SVM structures.

Table 3 Performance—Respiratory disease multi-classification with SVM Kernels
Full size table
Table 4 indicates the confusion matrix drawn for SVM-based respiratory disease classification and healthy sounds using the ERBPLPC feature. Most of the test sound segments for healthy sounds are misclassified with URTI.

Table 4 Confusion matrix for ERBPLPC feature with SVM models
Full size table
Figure 18 indicates the system's performance for the KNN machine learning classifier. This technique provides accuracy for all respiratory diseases except URTI and healthy sounds.

Fig. 18
figure 18
Decision level fusion of features for respiratory disease classification—KNN-based machine learning technique

Full size image
Figure 19 indicates the performance of the multi-class classification of respiratory diseases and healthy subjects with respiratory sound data. Spectrogram visual representation of respiratory sound data has provided better URTI and pneumonia results, but MEL spectrogram visual representation has provided better accuracy for bronchitis, bronchiectasis, COPD, and healthy. Integration of both features has yielded an overall accuracy of 83%.

Fig. 19
figure 19
Multi-class Respiratory disease classification—CNN machine learning technique

Full size image
Results and discussion—binary classification of respiratory diseases
These features and modelling techniques are tested to determine true positive cases for respiratory disease compared to healthy subjects. Figure 20 describes the system's respiratory diseases performance compared to the healthy subjects for the VQ-based machine learning technique. Perceptual features with filters in MEL and BARK scales provide better accuracy for respiratory diseases than other features. Decision level fusion of features has given 100% accuracy for all respiratory diseases against healthy subjects.

Fig. 20
figure 20
Binary Classification-True positive rate—VQ-based respiratory disease classification system

Full size image
Performance of the respiratory disease classification as against healthy subjects is measured in terms of True positive rate (TPR), False positive rate (FPR), True negative rate (TNR), False negative rate (FNR), sensitivity, specificity, F1 score, and Mathews correlation coefficient (MCC). Table 5 depicts the respiratory disease URTI classification performance against healthy subjects for RNN deep machine learning technique and perceptual features and gamma tone energy features with filters in different frequency scales for URTI. The system's performance is analysed in sensitivity, specificity, F1 score, and Mathew’s correlation coefficient (MCC).

Sensitivity=(𝑇𝑃𝑅𝑇𝑃𝑅+𝐹𝑁𝑅)×100andSpecificity=(𝑇𝑁𝑅𝑇𝑁𝑅+𝐹𝑃𝑅)×100
𝐹1Score=2(𝑇𝑃𝑅)2(𝑇𝑃𝑅)+𝐹𝑃𝑅+𝐹𝑁𝑅𝑀𝐶𝐶=(𝑇𝑃𝑅)(𝑇𝑁𝑅)−(𝐹𝑃𝑅)∗(𝐹𝑁𝑅)(𝑇𝑃𝑅+𝐹𝑃𝑅)(𝑇𝑃𝑅+𝐹𝑁𝑅)(𝑇𝑁𝑅+𝐹𝑃𝑅)(𝑇𝑁𝑅+𝐹𝑁𝑅)‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾√
𝑤ℎ𝑒𝑟𝑒𝑇𝑃𝑅−Truepositiverate,𝐹𝑃𝑅−Falsepositiverate,𝑇𝑁𝑅−Truenegativerate,𝐹𝑁𝑅−Falsenegativerate
Table 5 Performance analysis – RNN Machine learning technique—URTI & Healthy
Full size table
The performance evaluation of the COPD classification with healthy subjects using RNN deep learning networks is indicated in Table 6. Perceptual features and gamma tone energy features in different frequency scales are evaluated to recognise COPD's respiratory disease. It is observed that TPR and TNR for all the features are relatively better than gamma tone energy features with filters in the ERB scale.

Table 6 Performance analysis—RNN machine learning technique—COPD & Healthy
Full size table
Table 7 describes the performance analysis based on the RNN machine learning technique for the respiratory disease Pneumonia against healthy subjects.

Table 7 Performance analysis—RNN machine learning technique—Pneumonia& Healthy
Full size table
Table 8 indicates respiratory disease Bronchitis classification performance against healthy subjects for perceptual and gamma tone energy features with filters spaced in different non-linear frequency scales.

Table 8 Performance analysis—RNN machine learning technique—Bronchitis & Healthy
Full size table
Performance analysis of the respiratory disease bronchiectasis system against healthy subjects is indicated in Table 9 for the perceptual and gamma tone energy features with the RNN machine learning technique.

Table 9 Performance analysis—RNN machine learning technique—Bronchiectasis & Healthy
Full size table
Thus, RNN-based machine learning technique for performing binary classification of respiratory diseases has ensured relatively better accuracy for all the diseases except URTI. SVM supervised machine learning technique is applied to evaluate respiratory diseases' classification against healthy subjects with sound input. Figure 21 shows the performance of the SVM-based classification system. It is observed that MFCC has provided 100% accuracy for all respiratory diseases compared to healthy subjects.

Fig. 21
figure 21
Performance evaluation of respiratory disease binary classification—SVM machine learning technique

Full size image
KNN machine learning-based system is assessed to analyse the respiratory disease classification performance against healthy subjects, and the performance evaluation is depicted in Fig. 22. It is observed that MFPLPC has given relatively better accuracy for all respiratory diseases. Furthermore, KNN classifier has a better performance than the minimum distance classifier used in the VQ-based machine learning technique.

Fig. 22
figure 22
Performance evaluation of respiratory disease binary classification—KNN machine learning technique

Full size image
Table 10 depicts the classification of respiratory diseases against healthy subjects using the CNN machine learning technique with a visual representation of spectrogram.

Table 10 Binary classification—Respiratory disease—CNN machine learning technique with Spectrogram feature
Full size table
Table 11 indicates the classification of respiratory diseases against healthy subjects using the CNN machine learning technique with MEL spectrogram visual representation.

Table 11 Binary classification—Respiratory disease—CNN machine learning technique with MEL Spectrogram feature
Full size table
Integration of Spectrogram and MEL spectrogram for evaluating CNN-based binary respiratory disease classification system is depicted in Table 12.

Table 12 Binary classification—Respiratory disease—CNN machine learning technique with Integration of Spectrogram and MEL Spectrogram feature
Full size table
Thus, integration of spectrogram and MEL spectrogram has provided better TPR and TNR for the binary classification of all respiratory diseases against healthy subjects.

Conclusions
In this paper, comprehensively, it is discussed that multiple features and modelling techniques are implemented to evaluate the multi-class classification of respiratory diseases and the two-class classification of respiratory diseases with healthy subjects. Features considered in this work are perceptual, and gamma tone energy features with filters in ERB, MEL and BARK scales, MFCC, MGDFC, discrete orthogonal Stockwell features. Features extracted from the training set of respiratory sounds for different diseases are given to the machine learning models. Based on the classification procedure, the respiratory sound is identified as one on respiratory diseases, namely URTI, Pneumonia, bronchitis, bronchiectasis & COPD, and healthy subjects. These features and machine learning techniques are also evaluated to classify respiratory disease against healthy subjects. It is observed that the VQ-based modelling technique has provided better accuracy for multi-class classification of respiratory diseases as compared to other machine learning techniques. CNN has performed better than RNN for multi-class classification and binary classification of respiratory diseases.

Keywords
Respiratory diseases
Multiple/binary classification
Respiratory sounds
Features
Models
Machine learning techniques