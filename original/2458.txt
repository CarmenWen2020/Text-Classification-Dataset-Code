Various language identification tools and methods have been used in the real world. These applications can detect language using text or images. However, there is no speech-based language automated identification tool available. Therefore, many studies have been presented to overcome this problem. This work presents an automated high accurate language identification model and developed a new corpus for language identification. The developed language identification model uses two novel methods: (i) polymer pattern (PP) and (ii) tent maximum absolute pooling (TMAP). These methods help to extract both low- and high-frequency features. In order to choose the most informative features, a threshold-based iterative feature selector is presented. The proposed PP- and TMAP-based model has attained an accuracy of 97.87% and 99.70% using our newly developed and VoxForge datasets, respectively, with kNN classifier with tenfold cross-validation.

Introduction
With the development of technology, different applications are emerging every day in social media. By using social media applications, the size of shared multimedia data (voices, speeches, texts, images, and videos) has been increased marginally [1]. Each of these data is shared with the language of that region [2]. However, there are approximately 6500 languages in the world [3]. Each of these languages has its own rules and alphabet. The definition of these languages is one of today’s important research areas. Thus, determining the language in various areas such as call centers, determining the source of data obtained from different Internet-based applications, and providing customer guidance can be achieved using an automated system [4,5,6]. Automatic language recognition is divided into written and spoken [7, 8], and in this study, we have used spoken language for identification. Spoken language identification is the process of identifying a language from a random expression. It is the process of identifying a language from a short sound signal by reducing language complexity [9, 10].

The main language widely used in the world and on the Internet is English. However, even the English language seems to differ for various regions [11]. It is very difficult to determine this difference with spoken language identification systems, and automatic language recognition should be able to observe this distinction. Language identification systems should have a structure that can detect the differences in a language such as phonemes, grammar, syllable structure, and lexical words. For this purpose, advanced systems with different acoustic properties are designed [12]. The performance of these systems depends on good feature extractor, selector, and classification method. The performance of appropriate feature extraction, selection, and classification methods depends on factors such as the samples, number of language data, and the availability of computational resources [13]. Different spoken language identification methods have been proposed in the literature [14,15,16]. These methods can be shaped by using different techniques together. In this study, a handcrafted spoken language identification method is proposed.

Motivation and our method
The speech-based language identification/classification has two primary problems: (i) obtaining high classification performance using the proposed method and availability of huge dataset. To solve the first problem, the authors have been proposing deep learning-based networks. However, parameters setting for deep learning methods is a big problem. Therefore, many researchers have used pre-trained convolutional neural networks (CNNs) [17], but these networks are trained using ImageNet dataset. Therefore, they were constructed for computer vision and they may not be able to yield high classification performance for speech classification tasks. The second problem is the availability of limited public databases. In order to solve the problem, we have created our own new dataset from the open-source Web application.

In order to overcome the first problem, we have proposed polymer pattern (PP) and tent maximum absolute pooling (TMAP) techniques to generate unique features from the speech signals. The PP is considered as main feature extraction function which is designed using a polymer shape. To the best of our knowledge, we are the first group to use polymer shape-based feature extractor for language classification using speech signals. The deep learning networks generally use pooling functions for decompression or layer creation. However, they have routing problem. To overcome this routing problem, in his work, we have used TMAP. In the feature selection section, a new model is presented and this model is an improved version of neighborhood component analysis (NCA) [18]. Traditional classifiers are used to evaluate the strength of the presented PP- and TMAP-based feature extraction and the proposed neighborhood component analysis, and iterative neighborhood component analysis (NCAINCA) feature selector. A graphical snapshot of the presented method is shown in Fig. 1.

Fig. 1
figure 1
Block diagram of the proposed PP-TMAP and NCAINCA based language identification method

Full size image
Literature review
Table 1 shows the summary of works carried out on automated detection of language using speech signals. It can be noted from the table that most of the authors have used limited datasets and used deep learning methods. Also, they did not get high classification performance.

Table1 Summary of works carried out on automated detection of language using speech signals
Full size table
Novelties
In this work, two novel methods are presented and they are as follows:

A novel speech dataset is collected and published publicly

New pooling decomposition method is presented (TMAP) to solve routing problem

Molecular graph of polymer is used as local feature generator

A new two-layered feature selector NCAINCA which is an improved version of NCA feature selector is proposed.

Key contributions
There are two main problems in the automated language identification using speech signals. This work helps to overcome these two limitations. The main contributions of our work are given below:

There are limited public datasets available, and these datasets contain a limited number of languages. Hence, a private speech dataset containing 4500 speech files belonging to 45 languages is created. To the best of our knowledge, we are the first group to propose polymer pattern which is a new local and histogram-based feature generation function

A nonparametric and handcrafted features-based automated language identification model is presented. This model uses TMAP, handcrafted polymer pattern, and NCA together. TMAP is presented to obtain multileveled features, and it is presented to solve routing problem of the pooling methods. Polymer pattern is presented to extract salient features from speech signals, and it generates features of both speech signal and generated sub-bands using TMAP. Hence, we will be able to obtain low- and high-frequency details from the speech signals. Our proposed model is able to classify the 45 speech signals with an accuracy of 97.87% and 16 speech signals with an accuracy of 99.70% using our proposed method

Datasets
In this work, we have used two corpora to develop the automated language detection model. We have developed a private dataset by collecting the data, and another public dataset named VoxForge corpus is also used. VoxForge corpus is a widely preferred dataset for language classification. Therefore, the presented model is developed using VoxForge dataset to compare the performance with the state-of-the-art techniques. The details of the collected dataset are given below.

Collected dataset (LI45)
The collected dataset includes speeches of 45 languages. Therefore, it is named LI45 (language identification 45). This dataset was collected from https://localingual.com/ Web application. We have collected 100 speeches belonging to 45 languages. We have saved these speeches as mp3 and wav files and sampled at a rate of 48 kHz. The names of language used and the number of speeches of collected LI45 speech dataset are Arabic (100), Breton (100), Catalan (100), Hakha Chinese (100), Czech (100), Chuvash (100), Welsh (100), German (100), Divehi (100), Greek (100), Esperanto (100), Spanish (100), Estonian (100), Basque (100), Persian (100), French (100), Frisan (100), Irish (100), Interlingua (100), Indonesian (100), Italian (100), Japanese (100), Kabyle (100), Kyrgyz (100), Latvian (100), Mongolian (100), Maltese (100), Dutch (100), Pali (100), Portuguese (100), Romance Vallader (100), Romanian (100), Russian (100), Rwandan (100), Sakha (100), Slovenian (100), Swedish (100), Tamil (100), Turkish (100), Tatar (100), Ukrainian (100), Chinese—China (100), Chinese—Taiwan (100), Chinese—Hong Kong (100), and English (100).

Our collected LI45 can also be downloaded using https://www.kaggle.com/turkertuncer/language-identification-45-languages-li45 URL by users.

VoxForge
VoxForge is one of the widely used dataset for language identification. Sixteen languages are selected from this dataset, and they are Albanian, Croatian, English, Spanish, French, German, Greek, Hebrew, Italian, Catalan, Netherlands, Persian, Portuguese, Russian, Turkish, and Ukrainian. The used VoxForge dataset contains 1650 speeches [20,21,22]. The names of language and the number of sample sound files of the collected LI45 speech dataset are Albanian (105), Croatian (107), English (106), Spanish (102), French (100), German (100), Greek (107), Hebrew (100), Italian (108), Catalan (100), Netherlands (100), Persian (103), Portuguese (100), Russian (100), Turkish (107), and Ukrainian (105).

The presented polymer pattern
Local feature generation methods are effective methods for image classification and signal processing. Therefore, a new local feature generator is presented in this work. To construct pattern, a polymer shape is used and is shown in Fig. 2. We are inspired by a molecular structure of a hydrocarbon polymer.

Fig. 2
figure 2
Proposed polymer pattern. To create polymer shape pattern, a directed graph is used. The used directions (edges) denote the relations between the values. This polymer graph has 28 edges, and hence 28 bits are generated using this polymer graph

Full size image
The steps involved in the generation of polymer pattern (PP) are given as follows:

1.
Feed/load the speech signal.

2.
Divide the speech signal into 66 sized overlapping windows. This is because the presented pattern (see Fig. 2) uses 6 × 11 sized matrix.

3.
Transform the overlapped window to 6 × 11 matrix.

4.
Assign the used values (see Fig. 2).

5.
Generate bits using signum function shown in arrows.

𝑆(𝑥,𝑦)={0,𝑥−𝑦<01,𝑥−𝑦≥0
(1)
where 𝑆(.,.) represents the signum function and 𝑥,𝑦 are the input values of the signum function. As seen from Eq. (1), signum function extracts bits by using the values of the matrix (𝑚𝑡𝑟). For instance, the first bit is extracted using 𝑆(𝑚𝑡𝑟(2,1),𝑚𝑡𝑟(3,2)) function.

6.
Divide the generated 28 bits into three groups, and these groups are named left, middle, and right with a length of 9, 10, and 9, respectively.

𝑏𝑙(𝑖)=bit(𝑖),𝑖∈{1,2,…,9}
(2)
𝑏𝑚(𝑗)=bit(𝑗+9),𝑗∈{1,2,…,10}
(3)
𝑏𝑟(𝑖)=bit(𝑖+19)
(4)
where 𝑏𝑙,𝑏𝑚,𝑏𝑟 are left bits, middle bits, and right bits, respectively.

7.
Create left, middle, and right map signals by transforming 𝑏𝑙,𝑏𝑚,𝑏𝑟 to decimal values.

left(𝑘)=∑𝑖=19𝑏𝑙(𝑖)∗2𝑖−1,𝑘∈{1,2,…,len−65}
(5)
middle(𝑘)=∑𝑗=110𝑏𝑚(𝑗)∗2𝑗−1
(6)
right(𝑘)=∑𝑖=19𝑏𝑟(𝑖)∗2𝑖−1
(7)
where 𝑙𝑒𝑛 is the length of the sound.

8.
Generate histogram of the left, middle, and right map signals. According to Eqs. (5–7), these signals are coded by 9, 10, and 9 bits, respectively. Therefore, sizes of the histograms are found as 512, 1024, and 512 for left, middle, and right signals, respectively.

9.
Merge the generated histograms and obtain feature vector of length 512 + 1024 + 512 = 2048.

These nine steps defined the presented polymer pattern. The polymer pattern is utilized as prime feature generation function in this research. To better explain the recommended polymer pattern-based language identification, 𝑃𝑃(.) function is used to represent this function.

Tent maximum pooling method
Pooling methods have been widely preferred in the convolution neural networks (CNNs). By using maximum, minimum, or average pooling methods, layers are created. In the present pooling method, only peak values are routed by employing maximum pooling and they use fix-sized non-overlapping blocks. Therefore, a new pooling method named TMAP is presented. It uses variable-sized non-overlapping blocks. In this work, 2-, 3-, 5-, 7-, and 11-sized non-overlapping blocks are used. To route both minimum and peak values, maximum absolute pooling (MAP) is presented. Pseudocode of the MAP is shown in Algorithm 1.

figure a
In TMAP, variable-sized MAPs are used together. In this work, 𝑀𝐴𝑃(𝑆𝑖𝑔,2), 𝑀𝐴𝑃(𝑆𝑖𝑔,3), 𝑀𝐴𝑃(𝑆𝑖𝑔,5), 𝑀𝐴𝑃(𝑆𝑖𝑔,7), and 𝑀𝐴𝑃(𝑆𝑖𝑔,11) functions are used together for generating decomposed signals.

The proposed polymer pattern and tent maximum absolute pooling-based language identification model
The primary objective of the presented polymer pattern- and TMAP-based model is to classify languages automatically with the highest performance. In order to denote universal accuracy of the presented identification model, two speech corpora have been used. Moreover, this developed model is lightweight language identification model yielding the highest classification performance for more number of language classes. The proposed polymer pattern- and TMAP-based language identification method consists of PP- and TMAP-based feature extraction, feature selection using NCAINCA, and classification. This model reported high classification performance using speech signals for language identification. The other objectives of the presented PP- and NCAINCA-based model are as follows:

To demonstrate feature generation ability of polymer-shaped structure. Nowadays, graph-based learning models are popular and solved some problems better than other deep learning models. Therefore, graph neural networks and graph convolutional neural networks have been used in various research area [42,43,44,45]. Moreover, AlphaFold2 [46] has been presented to solve protein folding problem using a graph-based model. However, there are a limited number of graph-based handcrafted feature generation-based models in the literature. Hand-modeled/handcrafted models have low time burden. Hence, we have used a new nature-inspired model in this work.

Deep networks extract features in multilayers, and they can generate features in both low and high levels, although hand-modeled methods can generate features in low level. In order to improve feature generation abilities of the hand-modeled methods, multileveled feature generation should be implemented. Hence, a new effective TMAP decomposition model is presented.

We have used a combination of PP, TMAP, and NCAINCA as an alternative to deep learning method which needs more data for training. This model also has low time burden 𝑂(𝑛). Hence, it can be used to develop new-generation lightweight implementation. Our developed model can be employed in mobile language identification applications.

The TMAP solves routing problem and provides multilevel feature generation to obtain both low- and high-level features. The polymer pattern is a simple model and generates salient features, and NCAINCA selector chooses highly significant features automatically. Therefore, these models are used together to obtain highly accurate speech identification model with low time burden. The snapshot of the presented PP-TMAP- and NCAINCA-based model is shown in Fig. 3.

Fig. 3
figure 3
Graphical demonstration of the proposed PP and NCAINCA method. Note: S denotes the speech signal and blocks written with 2, 3, 5, 7, 11 digits imply the used sizes of non-overlapping windows. By using 3, 5, 7, 11, TMAP is created. PP is polymer pattern generator. S1, S2, S3, and S4 are decomposed signals obtained using MAP of size 2

Full size image
As seen from Fig. 3, the presented feature generator has five layers and 5 × 2048 = 10,240 features are generated from each level. In total, 10,240 × 5 = 51,200 features are generated. NCAINCA selects the most valuable features. Figure 3 summarizes the proposed language identification model. This model consists of feature extraction, feature selection, and classification phases. The details of this phases are given in subsections.

Feature extraction
In the feature extraction phase, polymer pattern, TMAP, and feature merging are used together. The main purpose of this phase is to create discriminative features from speech signals. The feature generation step is given below.

Step 1: Extract features using PP- and TMAP-based feature generation model. The pseudocode of this feature generation method is given in Algorithm 2.

figure b
According to this algorithm (see Algorithm 2), 51,200 features are generated from a speech. Polymer pattern generates 2048 features from a signal. The proposed PP-TMAP feature generator extracts 25 feature vectors using polymer pattern, and these feature vectors are merged. The length of the final feature vector is calculated as 51,200. Moreover, mathematical explanation of the PP-TMAP feature generator is given below.

𝑆𝑝𝑘+1=MAP(𝑆𝑝𝑘,2𝑘),𝑘∈{1,2,3,4}
(8)
In Eq. (9), 𝑆𝑝1 is original/raw speech and 𝑆𝑝𝑡,2≤𝑡≤5 are compressed speeches using MAP function with a 2-sized non-overlapping block. Herein, four compressed speeches are obtained. TMAP is applied to these compressed signals.

𝑆𝑗=MAP(𝑆𝑝𝑘,𝑝𝑘),𝑝∈{3,5,7,11},𝑘∈{1,2,…,5},𝑗∈{1,2,…,20}
(9)
where 𝑆 defines sub-bands of the TMAP decompositions and 20 sub-bands are created in this work. Because TMAP generates four sub-bands from each speech, PP extracts features from 𝑆𝑝 and 𝑆 signals.

𝑓𝑣𝑘=𝑃𝑃(𝑆𝑝𝑘),𝑘∈{1,2,…,5},
(10)
𝑓𝑣𝑗+5=𝑃𝑃(𝑆𝑗),𝑗∈{1,2,…,20}
(11)
Herein, 25 feature vectors (𝑓𝑣) are generated using PP feature extractor and these vectors are merged to obtain final feature vector (𝑓𝑓). The merging process is explained in Eq. (12):

𝑓(𝑡+2048×(𝑞−1))=𝑓𝑣𝑞(𝑡),𝑡∈{1,2,…,2048},𝑞∈{1,2,…,25}
(12)
By deploying Eq. 13, 𝑓𝑓 with a length of 51,200 is obtained from a speech signal.

Feature selection
Herein, NCAINCA selector is proposed to choose the most discriminative features. In the feature generation phase, 51,200 features are created. Therefore, we need an effective feature selector. NCA is one of the effective feature selectors in the literature [47], but has one important limitation. The limitation of NCA is to select most appropriate features manually. (Trial-and-error method needs to be used to select the most appropriate number of features.) Thus, both threshold-based NCA and iterative NCA are used together in this NCAINCA feature selector. Details of the NCAINCA are given below.

Step 2: Use NCA to feature vector and calculate weights.

𝑤𝑁=NCA(𝑓,𝑦)
(13)
where 𝑤𝑁 represents the NCA weights, 𝑁𝐶𝐴(.,.) is the NCA weight generation function, and 𝑦 is real outputs.

Step 3: Choose features using a threshold point. In this work, threshold point is chosen as 1e-5.

𝑓𝑡(:,𝑐𝑛𝑡)=𝑓(:,𝑖)Λ𝑐𝑛𝑡=𝑐𝑛𝑡+1𝑖𝑓𝑓𝑤𝑁>10−5
(14)
where 𝑓𝑡 is the chosen features and 𝑐𝑛𝑡 describes the counter.

Step 4: Use INCA to 𝑓𝑡 and select the most appropriate features. The pseudocode of INCA function is shown as below [48].

figure c
The steps 2—4 define the application of NCAINCA feature selector. The NCAINCA selector aims to select more valuable features than INCA using NCA function.

Classification
The last phase of the proposed TMAP- and PP-based LI method is classification. The selected features by NCAINCA are classified by three shallow classifiers to demonstrate the feature creation and selection capability of our proposed model. It is briefly explained below.

Step 5: Classify the selected features (𝑓𝑓) using conventional classifiers, namely k-nearest neighbor (kNN), support vector machine (SVM), and linear discriminant (LD). The properties of the used classifiers are given below:

kNN: k value of 1 and distance metric of Spearman [49] are chosen.

LD: Linear discriminant type is chosen, gamma value of 0 is selected, and fill coefficient setting is set to off [50].

SVM: In this work, we have used third-degree polynomial kernelled (cubic) SVM. The kernel scale, box constraint level, and coding settings are selected as auto, three, and one-vs-all, respectively [51, 52].

All the classifiers are developed using tenfold cross-validation strategy.

Experimental results
Two datasets were used to develop the automated language detection model. This presented PP- and NCAINCA-based model was developed using MATLAB (2020a). Five MATLAB functions, namely main, PP, MAP (defined to create TMAP decomposition), NCAINCA, and classification, are created. The tuning parameters used in each function of the proposed model are listed in Table 2.

Table 2 Tuning parameters used for each function of the proposed model
Full size table
The used two language corpora are tested using these parameters. Here, any parallel programming method or GPU core was not used.

The performance parameters, namely accuracy, geometric mean, precision, F1-score, Cohen’s kappa, and Mathew correlation coefficient (MCC), are given in Table 3 and Table 4 using LI45 [53,54,55] and VoxForge datasets, respectively, with various classifiers.

Table 3 Summary of performance measures obtained with LI45 dataset using various classifiers
Full size table
Table 4 Summary of performance measures obtained with VoxForge dataset using various classifiers
Full size table
Figure 4 indicates the accuracies (%) obtained for each fold of tenfold cross-validation using LD, SVM, and kNN classifiers with LI45 dataset.

Fig. 4
figure 4
F1-scores obtained for each class of LD, SVM, and kNN classifiers using LI45 dataset

Full size image
Figure 5 shows the accuracies (%) obtained for each fold of tenfold cross-validation using LD, SVM, and kNN classifiers with LI45 dataset.

Fig. 5
figure 5
Accuracies (%) obtained for each fold of tenfold cross-validation using LD, SVM, and kNN classifiers with LI45 dataset

Full size image
Figure 6 shows the F1-scores obtained for each class of LD, SVM, and kNN classifiers using VoxForge dataset.

Fig. 6
figure 6
F1-scores obtained for each class of LD, SVM, and kNN classifiers using VoxForge dataset

Full size image
It can be noted from the results that we have obtained the highest classification accuracy of 97.87% in classifying 45 classes of private database using our proposed model. Our same model yielded the classification accuracy of 99.70% for the public database in classifying 16 classes.

Discussions
Two novel methods, namely PP and TMAP, are presented in this work to automatically detect the language identification. We have developed our model using public and private databases developed by us (called LI45). The novelty of this work is the use of PP and TMAP for feature generation and NCAINCA to select the most informative features. The selected features are fed to LD, SVM, and kNN classifiers to choose the optimum performing features. Our presented model is developed on two language identification corpora. The NCAINCA selected 303 and 375 features for LI45 and VoxForge datasets, respectively. By using NCAINCA, high-accuracy ratios have been calculated using small feature vectors. Iterative feature selection process of the NCAINCA is also denoted in Fig. 7.

Fig. 7
figure 7
Iterative feature selection process obtained using NCAINCA for both datasets

Full size image
Figure 7 denotes the misclassification rates obtained using iterative feature selection process for two datasets.

Tables 3 and 4 summarize the performance measures obtained with LI45 and VoxForge datasets, respectively, using various classifiers.

Five separation ratios have been used in this work, and they are 90:10 (training and testing ratios), 80:20, 70:30, 60:40, and 50:50. These tests were implemented 100 times to obtain general results. The calculated general results (average ± standard deviation) are equal to 98.01% ± 0.61%, 97.45% ± 0.46%, 97.12% ± 0.41%, 96.59% ± 0.53%, and 95.91% ± 0.39% for 90:10, 80:20, 70:30, 60:40, and 50:50 separation ratios, respectively, using LI45 dataset. Also, 99.56% ± 0.46%, 99.44% ± 0.56%, 99.55% ± 0.52%, 99.48% ± 0.53%, and 99.52% ± 0.69% accuracy rates are reported using 90:10, 80:20, 70:30, 60:40, and 50:50 separation ratios, respectively, with VoxForge dataset. Box plot analysis of the calculated accuracies is also denoted in Fig. 8.

Fig. 8
figure 8
Box plot of accuracy obtained using various cross-validation ratios

Full size image
We have obtained maximum accuracy rates of 99.56%, 98.44%, 97.93%, 97.50%, and 97.02% for 90:10, 80:20, 70:30, 60:40, and 50:50 cross-validation ratios, respectively, for LI45 dataset. The presented polymer pattern- and TMAP-based model reached 100% accuracies for all cross-validation ratios using VoxForge dataset.

However, we have classified 16 and 45 languages and obtained higher classification performance than the other reported works. These results clearly justify the superiority of our proposed PP-TMAP feature generation and NCAINCA selector language identification model. Also, our model yielded higher results than deep learning-based models (see Table 1).

Moreover, t test has been implemented on the generated features. The LI45 and VoxForge corpora contained 45 and 16 classes, respectively. Therefore, p values of 990 and 120 couples are calculated and listed in Table 5.

Table 5 Results of p values of generated features obtained using our proposed polymer pattern- and TMAP-based language identification model
Full size table
Table 5 clearly denotes the discriminative properties of the generated features based on the Student’s t test. Figure 9 denotes the frequency of features with p value less than 0.05, and these results denote high classification capability of generated features.

Fig. 9
figure 9
Number of features in each couple with p value less than 0.05 for both datasets

Full size image
We have compared the performance of our developed model with other state-of-the-art works. As can be seen in Table 1, the first deep learning-based language identification model was proposed by Montavon [19] in 2009. Montavon used VoxForge and reported an accuracy of 80.10% using three languages. In 2019, Revay and Teschke [32] applied a residual CNN (ResNet) to classify commonly used six languages (English, Spanish, French, German, Italian, and Russian) using VoxForge dataset. They extracted spectrogram images from the speech signals and fed as input to the ResNet and attained an accuracy of 89%. Baba et al. [34] proposed log mel spectrogram-based image extraction and a CNN model to classify the images. They reached an accuracy of 89.10% in classifying three languages with VoxForge dataset. In our proposed hand-modeled language identification model, we used classified 16 languages with VoxForge dataset and obtained an accuracy rate of 99.70%. Therefore, our model can be used instead of deep models to identify languages using speech signals.

The benefits of our PP-TMAP feature generation and NCAINCA selector-based language identification model are given below:

A novel automated language classification model is developed

The proposed model is developed using two (VoxForge and LI45) databases

Selecting the most appropriate pattern is one of the challenging tasks for local feature generators. In this work, we have proposed a novel one-dimensional feature generator using a polymer shape

A novel multiple-sized non-overlapping window-based decomposition model TMAP is suggested

The presented PP-TMAP feature generation and NCAINCA selector-based language identification model is a handcrafted features-based model. Therefore, many parameters setting are not needed. Hence, it is superior to deep learning models for automated language identification. The future directions of our proposed method are as follows:

More datasets can be used to validate the developed model

We used polymer shape to create a pattern (PP). Other shapes or molecular structures can also be used to generate new features

TMAP is a new and effective decomposition method used for feature generation. In the future, quantum computing-based decomposition models can be used for speech processing

Speech-based language identification tools can be presented by using our model, and speech-to-speech translation applications can be developed

Novel polymer pattern-based deep learning models can be employed to overcome the limitations of existing deep models for speech classification

Conclusions
Automated identification of language using speech signals is a challenging problem. In this paper, we have developed an accurate language identification model using new polymer pattern (PP) and tent maximum absolute pooling (TMAP) methods. Our model is developed using public (VoxForge) and private (LI45) databases comprising 16 and 45 languages, respectively. Our proposed system yielded an accuracy of 97.87% and 99.70% for LI45 and VoxForge datasets, respectively. Furthermore, holdout validation techniques were used to calculate classification results and this speech identification model attained 98.01% ± 0.61% and 99.56% ± 0.46% accuracies with 90:10 separation ratio on LI45 and VoxForge, respectively. In the future, we intend to validate our developed model with bigger database and more number of classes.

In the future, we plan to propose more graph-based feature extraction methods and use graphs of other molecular structures for automated language identification. We also intend to find the structural graph of other molecules or polymers from PubChem and novel polymer-based feature extractors to solve signal processing and computer vision problems.

Keywords
Polymer pattern
Speech language classification dataset
Machine learning
Artificial intelligence